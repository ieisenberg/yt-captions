[
  {
    "start": "0",
    "end": "104000"
  },
  {
    "text": "uh good afternoon everyone Um my name is KD Singh I'm a solutions architect with",
    "start": "480",
    "end": "6400"
  },
  {
    "text": "Amazon Web Services Uh this session is about uh big data uh and analytics on",
    "start": "6400",
    "end": "11679"
  },
  {
    "text": "AWS Um it's right after lunch Hopefully you had coffee Um so I am going to uh",
    "start": "11679",
    "end": "19680"
  },
  {
    "text": "present this session along with Marco Merren Uh Marco is the head of analytics",
    "start": "19680",
    "end": "24720"
  },
  {
    "text": "of international civil aviation organization uh came here from Montreal",
    "start": "24720",
    "end": "30080"
  },
  {
    "text": "So um we'll uh divide up the session In the first part of the session my goal is to",
    "start": "30080",
    "end": "36640"
  },
  {
    "text": "uh give you an overview of the big data uh field Uh tell you more about the AWS",
    "start": "36640",
    "end": "42480"
  },
  {
    "text": "services related to big data Uh sort of give you an idea of uh how to architect",
    "start": "42480",
    "end": "48399"
  },
  {
    "text": "a big data solution and then give you a real world example of how to put these different blocks together to build a",
    "start": "48399",
    "end": "54399"
  },
  {
    "text": "real world pipeline on big data Um and I have 30 minutes for that Uh so I can't",
    "start": "54399",
    "end": "60879"
  },
  {
    "text": "go down in the weeds but I don't want this to be marketing exercise uh either So hopefully you're going to find this",
    "start": "60879",
    "end": "66640"
  },
  {
    "text": "useful U AWS training actually has a 3-day big data training that covers all",
    "start": "66640",
    "end": "73280"
  },
  {
    "text": "these topics in much more detail for those of you who are interested Uh after I'm done in about 30 minutes Marco is",
    "start": "73280",
    "end": "79680"
  },
  {
    "text": "going to come up and he's going to show how his agency was able to use AWS",
    "start": "79680",
    "end": "85200"
  },
  {
    "text": "services to solve their big data problem And uh then I have a demo It's a it's a six-minute uh video Uh after Marco is",
    "start": "85200",
    "end": "92000"
  },
  {
    "text": "done if we have time I'm going to play that demo and it's going to show you how I put these services together to build",
    "start": "92000",
    "end": "97119"
  },
  {
    "text": "something useful So let's get",
    "start": "97119",
    "end": "101439"
  },
  {
    "start": "104000",
    "end": "220000"
  },
  {
    "text": "started Okay So big data is uh no longer a buzzword Uh you know it used to be",
    "start": "104119",
    "end": "110159"
  },
  {
    "text": "that uh uh you know big data uh this and big data that but now pretty much",
    "start": "110159",
    "end": "115360"
  },
  {
    "text": "everybody knows that there is a great amount of value in data Nobody is throwing away their data anymore Uh",
    "start": "115360",
    "end": "121200"
  },
  {
    "text": "people know that in that data is hidden lots of useful information and knowledge that can help in their decision- making",
    "start": "121200",
    "end": "128000"
  },
  {
    "text": "to do things more efficiently to save money you know to do a lot of different kinds of things So uh and when we talk",
    "start": "128000",
    "end": "134560"
  },
  {
    "text": "about big data uh you know many of us have heard about the three Vs of big data like the volume of big data how how",
    "start": "134560",
    "end": "141760"
  },
  {
    "text": "big it is the velocity of big data how quickly is the data changing the variety",
    "start": "141760",
    "end": "147599"
  },
  {
    "text": "of data how many different types of data are bundled together in my data store Uh but there are other parameters Uh on",
    "start": "147599",
    "end": "154560"
  },
  {
    "text": "this slide you see some of the parameters that help define the problem space",
    "start": "154560",
    "end": "160040"
  },
  {
    "text": "Uh but the bottom line is big data is different things to different people Uh",
    "start": "160040",
    "end": "165680"
  },
  {
    "text": "you know people uh think about you know what what really is big data is a gigabyte big data a terabyte big data a",
    "start": "165680",
    "end": "172480"
  },
  {
    "text": "pabyte big data xabyte big data The real answer is that any or all of that could",
    "start": "172480",
    "end": "178480"
  },
  {
    "text": "be big data uh you know it just depends if you're talking about sensors in the field in in scientific computing in in",
    "start": "178480",
    "end": "184879"
  },
  {
    "text": "in the federal space NASA and all where the compute power is limited you know even megabytes could be big data because",
    "start": "184879",
    "end": "191360"
  },
  {
    "text": "you don't have the processing power and when you're talking about cloudscale things you know people have xabytes",
    "start": "191360",
    "end": "197840"
  },
  {
    "text": "worth of data in there uh the bottom line is anytime you have to um think",
    "start": "197840",
    "end": "203360"
  },
  {
    "text": "about or redesign how you are uh how you",
    "start": "203360",
    "end": "208560"
  },
  {
    "text": "are accessing your data how you're storing your data how you're anal analys how your analysis works and how you're",
    "start": "208560",
    "end": "214239"
  },
  {
    "text": "visualizing your data Anytime you have to change that you're probably dealing with a big data problem And uh for those of us uh who",
    "start": "214239",
    "end": "223120"
  },
  {
    "start": "220000",
    "end": "284000"
  },
  {
    "text": "know this space um there are just a lot of tools in the ecosystem Uh this this",
    "start": "223120",
    "end": "229599"
  },
  {
    "text": "is just a very very small samplings There are hundreds if not thousands of tools in the ecosystem And when somebody",
    "start": "229599",
    "end": "236879"
  },
  {
    "text": "first first gets introduced to the field the first challenge is you know how do I break this up How do I even think about",
    "start": "236879",
    "end": "245360"
  },
  {
    "text": "hey should I be looking at Daimo or should I be looking at Cassandra What is Cassandra You know uh where do I go What",
    "start": "245360",
    "end": "252560"
  },
  {
    "text": "is a data warehouse What what what is hive What is pig What's the difference What is map There are just too many",
    "start": "252560",
    "end": "258479"
  },
  {
    "text": "things uh and you know to to make things a little bit simpler to put some structure around it I think it's best if",
    "start": "258479",
    "end": "265919"
  },
  {
    "text": "we think of big data processing as a as a pipeline as a pipeline of things uh or",
    "start": "265919",
    "end": "272479"
  },
  {
    "text": "stages that you have to go through to solve your problem The different uh stages in the pipeline are",
    "start": "272479",
    "end": "281360"
  },
  {
    "text": "um okay so on the left you have your incoming data and on the right you have",
    "start": "282360",
    "end": "289280"
  },
  {
    "text": "your answers in this particular pipeline The very first thing that you need to do",
    "start": "289280",
    "end": "294479"
  },
  {
    "text": "is to uh ingest your data You have to consume it Uh after your data is in your",
    "start": "294479",
    "end": "301040"
  },
  {
    "text": "hands you have ingested it You then have to store it After you store it you",
    "start": "301040",
    "end": "306160"
  },
  {
    "text": "analyze it you process on it And this is an iterative process Uh when you analyze something you have to store the partial",
    "start": "306160",
    "end": "312639"
  },
  {
    "text": "results back You want to keep your data for longer So storage and analysis it's it's iterative There is a feedback loop",
    "start": "312639",
    "end": "318880"
  },
  {
    "text": "in there And finally after the analysis is done you know then comes the part of visualization of data You have to see",
    "start": "318880",
    "end": "325919"
  },
  {
    "text": "the results in some way shape or form When you see results you might have to go back and analyze again change some",
    "start": "325919",
    "end": "331680"
  },
  {
    "text": "parameter again So it's a iterative process as well but the bottom line is injection storage analysis and",
    "start": "331680",
    "end": "338919"
  },
  {
    "text": "visualization almost all big data pipelines can be broken down like this Uh you might have some other components",
    "start": "338919",
    "end": "345600"
  },
  {
    "text": "you might have fewer components than this but this is like the de facto starting point of when when somebody",
    "start": "345600",
    "end": "351199"
  },
  {
    "text": "like me starts architecting a big data solution This is how we break down things Uh now that we have uh broken",
    "start": "351199",
    "end": "357919"
  },
  {
    "start": "356000",
    "end": "426000"
  },
  {
    "text": "down uh things we can uh all the tools the NASCAR slide we saw about the big",
    "start": "357919",
    "end": "363440"
  },
  {
    "text": "data tools we can now make it a little bit more structured So now we have four",
    "start": "363440",
    "end": "368479"
  },
  {
    "text": "buckets in which we can throw things We have the injection bucket the storage bucket the analysis bucket and the",
    "start": "368479",
    "end": "374000"
  },
  {
    "text": "visualization buckets And now these tools they they line up in one of those",
    "start": "374000",
    "end": "379039"
  },
  {
    "text": "buckets There are some that span different things but more or less these are the four different buckets in which",
    "start": "379039",
    "end": "385280"
  },
  {
    "text": "you throw things Now you can break up the problem and start looking at the choices within a particular",
    "start": "385280",
    "end": "391000"
  },
  {
    "text": "bucket Uh there are still a lot of tools hundreds of thousands as I said So in this talk what I'm going to do is look",
    "start": "391000",
    "end": "398400"
  },
  {
    "text": "at the managed services that Amazon Web Services provides that deal with big",
    "start": "398400",
    "end": "403840"
  },
  {
    "text": "data kind of problems And these are the services that I'm going to uh some of you know I can't go through all of them",
    "start": "403840",
    "end": "409840"
  },
  {
    "text": "uh 30 minutes um and 50 Amazon services or close to 50 Amazon services so can't",
    "start": "409840",
    "end": "415520"
  },
  {
    "text": "spend too much time on that I'm going to cover a few of these services uh related to these topics",
    "start": "415520",
    "end": "422759"
  },
  {
    "text": "Um this is my um only marketing slide I promise Uh",
    "start": "422759",
    "end": "429280"
  },
  {
    "start": "426000",
    "end": "454000"
  },
  {
    "text": "just shows you uh who is using big data You know if you're wondering whether this is",
    "start": "429280",
    "end": "435199"
  },
  {
    "text": "relevant for me or not it probably is because a lot of different kinds of",
    "start": "435199",
    "end": "440560"
  },
  {
    "text": "customers doing a lot of different kinds of things chalk and cheese kind of things they all uh use big data kind of",
    "start": "440560",
    "end": "448319"
  },
  {
    "text": "solutions So uh and uh uh draw really good uh value out of it as well So now",
    "start": "448319",
    "end": "454639"
  },
  {
    "start": "454000",
    "end": "552000"
  },
  {
    "text": "let's start looking at those four stages of pipeline one by one and then start looking at some of the technical details",
    "start": "454639",
    "end": "460880"
  },
  {
    "text": "in them In injection the idea is I have to consume",
    "start": "460880",
    "end": "466479"
  },
  {
    "text": "the data So what are the different kinds of data that you might have to consume",
    "start": "466479",
    "end": "471840"
  },
  {
    "text": "That's going to then um tell you what kind of tools you need",
    "start": "471840",
    "end": "477360"
  },
  {
    "text": "to solve that problem Uh your your data could be transaction kind of data",
    "start": "477360",
    "end": "482960"
  },
  {
    "text": "database reads and writes sequential database uh reads and writes kind of uh data transactional and then it could be",
    "start": "482960",
    "end": "489520"
  },
  {
    "text": "file kind of data You have media files you have log files you know simple files could be document files or anything Uh",
    "start": "489520",
    "end": "496800"
  },
  {
    "text": "and finally there could be stream kind of data Stream type of data is the you know is the most challenging data to",
    "start": "496800",
    "end": "503440"
  },
  {
    "text": "deal with because it's uh it's real time The streams never stop coming You know Twitter feeds people tweet a lot That",
    "start": "503440",
    "end": "510800"
  },
  {
    "text": "data does not stop There is a lot of value out of um that you can derive out",
    "start": "510800",
    "end": "516320"
  },
  {
    "text": "of social media feeds like that things like sensor data internet of things the fridge talking to the TV there is just a",
    "start": "516320",
    "end": "522479"
  },
  {
    "text": "lot of data that's going to get generated and it's getting generated That kind of data is never ending So stream uh ingestion of streams is um is",
    "start": "522479",
    "end": "531360"
  },
  {
    "text": "not a easy problem to solve So uh so in this session I'm going to uh talk about",
    "start": "531360",
    "end": "537279"
  },
  {
    "text": "Amazon Kinesis which is a service that deals with uh uh stream processing or",
    "start": "537279",
    "end": "543760"
  },
  {
    "text": "ingestion of stream uh streams of data So let's look at",
    "start": "543760",
    "end": "550160"
  },
  {
    "start": "552000",
    "end": "732000"
  },
  {
    "text": "that Okay Amazon uh Kinesis it's a it's a fully managed service you know uh",
    "start": "552120",
    "end": "558399"
  },
  {
    "text": "before I start talking about Amazon service the first thing I'm going to say is that anything that Amazon is offering as",
    "start": "558399",
    "end": "566959"
  },
  {
    "text": "a managed service whether it's elastic map reduce or red shift or um or Dynamo",
    "start": "566959",
    "end": "574160"
  },
  {
    "text": "DB or anything uh you can set up equivalent services on your own you can",
    "start": "574160",
    "end": "581360"
  },
  {
    "text": "of course do that you can launch you know uh I'm assuming all of you know what EC2 is what S3 is What ELB is you",
    "start": "581360",
    "end": "588000"
  },
  {
    "text": "can use those uh different services to come up with your own uh services uh the",
    "start": "588000",
    "end": "594000"
  },
  {
    "text": "fundamental services to build up higher level services and you can also use the open-source tools in the ecosystem or",
    "start": "594000",
    "end": "600000"
  },
  {
    "text": "partner or ISV tools as well The reason I like the managed",
    "start": "600000",
    "end": "605040"
  },
  {
    "text": "services like Kinesis that I'm going to talk about is that it takes care of the undifferiated heavy lifting you know if",
    "start": "605040",
    "end": "611440"
  },
  {
    "text": "I'm a if I'm if I'm managing a project my mission is not to set up a cluster my",
    "start": "611440",
    "end": "617360"
  },
  {
    "text": "mission is to derive the analysis and the uh useful information out of it so you know managed services take care of",
    "start": "617360",
    "end": "624240"
  },
  {
    "text": "uh those kinds of undifferiated heavy lifting so I like them but if there is some feature that a service is missing",
    "start": "624240",
    "end": "629839"
  },
  {
    "text": "you can always launch your own uh service or use something from the ecosystem or a partner um so Kinesis is",
    "start": "629839",
    "end": "636240"
  },
  {
    "text": "a managed service you fire it and it it it handles a lot things for you Uh it is",
    "start": "636240",
    "end": "642000"
  },
  {
    "text": "in the real time data processing uh field Uh you can uh when you use Kinesis",
    "start": "642000",
    "end": "649120"
  },
  {
    "text": "the key idea is you set up Kinesis streams A Kinesis stream when you set it",
    "start": "649120",
    "end": "655440"
  },
  {
    "text": "up uh you can put records in it Records are blobs of data Kinesis stream you put",
    "start": "655440",
    "end": "662480"
  },
  {
    "text": "records in it What Kinesis is going to do is it's going to keep the records that you give it give to Kinesis around",
    "start": "662480",
    "end": "669680"
  },
  {
    "text": "for 24 hours It's going to order those records and put them around safely for",
    "start": "669680",
    "end": "675200"
  },
  {
    "text": "24 hours Within those 24 hours your application you know the next stage of",
    "start": "675200",
    "end": "680399"
  },
  {
    "text": "the pipeline which is either storage uh or analysis is going to come in get the",
    "start": "680399",
    "end": "686480"
  },
  {
    "text": "data out of the records and work on it And after that you can either throw the data away or you can store it in a more",
    "start": "686480",
    "end": "693680"
  },
  {
    "text": "durable storage like S3 But Kinesis it gives you enough capacity so that you",
    "start": "693680",
    "end": "699120"
  },
  {
    "text": "don't lose any data Data is coming fast What you do in Kinesis is you set up shards A shard in Kinesis a kinesis",
    "start": "699120",
    "end": "706680"
  },
  {
    "text": "shard can consume data at 1 megabyte per second and it can emit data at 2",
    "start": "706680",
    "end": "713279"
  },
  {
    "text": "megabytes per second So and if you need more throughput than that your data is",
    "start": "713279",
    "end": "718399"
  },
  {
    "text": "moving faster than that you just provision more shards So you you provision the number of shards that you need to input all",
    "start": "718399",
    "end": "725200"
  },
  {
    "text": "your data All the records are in there Uh Kinesis offers what we call uh different",
    "start": "725200",
    "end": "733040"
  },
  {
    "start": "732000",
    "end": "784000"
  },
  {
    "text": "libraries You can use the APIs directly but there are libraries the producer library connector library and the client",
    "start": "733040",
    "end": "738560"
  },
  {
    "text": "library from Kinesis You can use those libraries to write applications that",
    "start": "738560",
    "end": "744160"
  },
  {
    "text": "consumes data from records or that put data as records or that connect to other durable stores like Dynamo DB S3 or red",
    "start": "744160",
    "end": "751680"
  },
  {
    "text": "shift The cool thing about using Amazon managed services is that they all talk",
    "start": "751680",
    "end": "756800"
  },
  {
    "text": "to each other very well So it's very seamless Um but you you know to recap",
    "start": "756800",
    "end": "762959"
  },
  {
    "text": "you have a stream of data records are coming in shards are consuming that data data is kept around for 24 hours you",
    "start": "762959",
    "end": "769519"
  },
  {
    "text": "consume data in the in those 24 hours and either discard it from kinesis or put it in a durable",
    "start": "769519",
    "end": "774920"
  },
  {
    "text": "storage So um using that you can uh get sensor or real-time data very easily Um",
    "start": "774920",
    "end": "783639"
  },
  {
    "text": "and Kinesis uh there are actually other uh tools in the ecosystem for those of",
    "start": "783639",
    "end": "789040"
  },
  {
    "start": "784000",
    "end": "810000"
  },
  {
    "text": "us who deal with this field Uh things like extract transform and load ETL uh",
    "start": "789040",
    "end": "794399"
  },
  {
    "text": "kind of things are closely related to ingestion That's when you do ETL when you ingest things in So a lot of uh",
    "start": "794399",
    "end": "800399"
  },
  {
    "text": "partner u tools BI tools uh and tools from ISVS uh they work very well uh with",
    "start": "800399",
    "end": "806959"
  },
  {
    "text": "Kinesis and you can leverage them as well So let's go to the next stage in the",
    "start": "806959",
    "end": "812720"
  },
  {
    "start": "810000",
    "end": "893000"
  },
  {
    "text": "pipeline The next stage is storage Before I start talking about storage services I'm going to talk about an",
    "start": "812720",
    "end": "820519"
  },
  {
    "text": "anti-attern So it used to be till some years ago that u companies used to have",
    "start": "820519",
    "end": "829600"
  },
  {
    "text": "uh a relational database store data store which is RDBMS of some kind you",
    "start": "829600",
    "end": "834720"
  },
  {
    "text": "know people have their favorite uh and and then you know that used to be their source of truth their data lake Every",
    "start": "834720",
    "end": "842800"
  },
  {
    "text": "kind of data used to go in that store Uh and so it was like a Swiss army knife",
    "start": "842800",
    "end": "848880"
  },
  {
    "text": "but it was unwieldy Swiss Army knife because those of us who know databases we know that they they are a pain after",
    "start": "848880",
    "end": "855680"
  },
  {
    "text": "some time They have been around for a long time and people know them really well Uh there is a reason why NoSQL",
    "start": "855680",
    "end": "861920"
  },
  {
    "text": "stores also let you write SQL queries for the most part because SQL is really well known and used and I'm big fan of",
    "start": "861920",
    "end": "868079"
  },
  {
    "text": "using relational databases as long as they can satisfy my needs but they are",
    "start": "868079",
    "end": "873760"
  },
  {
    "text": "not a good match for everything and people use were trying to use them for that and then they dealt with things",
    "start": "873760",
    "end": "879440"
  },
  {
    "text": "like hey scaling oh how do I scale it let me shard it or let me reindex it and",
    "start": "879440",
    "end": "884959"
  },
  {
    "text": "you know it was painful u so that's why What started happening is that uh it's",
    "start": "884959",
    "end": "892800"
  },
  {
    "text": "it's better if you think about what kind of data are you trying to store Not all data is created equal and not all data",
    "start": "892800",
    "end": "900639"
  },
  {
    "start": "893000",
    "end": "957000"
  },
  {
    "text": "has the same kind of requirements on the store where it's sitting Uh there are different kinds of data that you uh that",
    "start": "900639",
    "end": "906959"
  },
  {
    "text": "you are dealing with There is caching kind of data for those of you who use memcache or radius to speed up your data",
    "start": "906959",
    "end": "913839"
  },
  {
    "text": "stores uh or key value stores There is caching kind of data uh there is uh file store kind of data or blob data Uh there",
    "start": "913839",
    "end": "921279"
  },
  {
    "text": "is uh key value stores or document stores which fall in the NoSQL uh kind of space Uh and uh there is archival uh",
    "start": "921279",
    "end": "930320"
  },
  {
    "text": "kind of data and there are there are file system kinds of uh data stores as well Uh I mentioned Hadoop distributed",
    "start": "930320",
    "end": "936959"
  },
  {
    "text": "file system because that's part of the Hadoop ecosystem that I'm going to talk about but there could be",
    "start": "936959",
    "end": "942279"
  },
  {
    "text": "others Storage should match data's needs there is search kind of data as well",
    "start": "942279",
    "end": "947600"
  },
  {
    "text": "which is also very popular in the big data space So u once you break up your uh",
    "start": "947600",
    "end": "954240"
  },
  {
    "text": "data storage needs like this now you can try to match the right service that",
    "start": "954240",
    "end": "959759"
  },
  {
    "start": "957000",
    "end": "1006000"
  },
  {
    "text": "would handle that kind of need If you are just storing files if it's just blob",
    "start": "959759",
    "end": "964800"
  },
  {
    "text": "data why are you why do you need to put it in a relational data store You can just put in something like S3 If it's",
    "start": "964800",
    "end": "970880"
  },
  {
    "text": "archival hey you know you don't put it in relational databases at all You put it in Glacier or something like an",
    "start": "970880",
    "end": "978160"
  },
  {
    "text": "archival service like it Uh similarly for caching Amazon these are Amazon",
    "start": "978160",
    "end": "983519"
  },
  {
    "text": "services that correspond to those kinds of data storage needs Uh we have RDS which is the relational data store uh",
    "start": "983519",
    "end": "990959"
  },
  {
    "text": "service which gives you relational databases I'm going to talk about that Dynamob is NoSQL data store I'm going to",
    "start": "990959",
    "end": "996959"
  },
  {
    "text": "talk about that Uh EMR or elastic map reduce is managed Hadoop clusters etc So",
    "start": "996959",
    "end": "1004720"
  },
  {
    "text": "um so let's look at some of these storage services S3 simple storage",
    "start": "1005240",
    "end": "1010800"
  },
  {
    "start": "1006000",
    "end": "1128000"
  },
  {
    "text": "service I'm pretty sure uh all all know almost all if not all of you know what",
    "start": "1010800",
    "end": "1016560"
  },
  {
    "text": "S3 is I'm not going to spend too much time on it Uh but it's uh it's a object store uh which is uh you know which",
    "start": "1016560",
    "end": "1024959"
  },
  {
    "text": "scales very well It's very durable It's designed for 11 9 of durability but more",
    "start": "1024959",
    "end": "1030480"
  },
  {
    "text": "importantly it has some uh key uh features uh that make it very useful for",
    "start": "1030480",
    "end": "1036959"
  },
  {
    "text": "the big data space which is what we are focusing on uh features like versioning",
    "start": "1036959",
    "end": "1042160"
  },
  {
    "text": "and life cycle management So once you bring your data in you can version it",
    "start": "1042160",
    "end": "1047600"
  },
  {
    "text": "and then you can write life cycle policies so that data transitions into",
    "start": "1047600",
    "end": "1052640"
  },
  {
    "text": "glacier after some time uh it has uh things like security is important So uh",
    "start": "1052640",
    "end": "1058720"
  },
  {
    "text": "encryption of data at rest as well as in transit It's a feature that you can",
    "start": "1058720",
    "end": "1064000"
  },
  {
    "text": "leverage from S3 And then it has event notifications as well So when some new",
    "start": "1064000",
    "end": "1069360"
  },
  {
    "text": "data comes into S3 you can get notified using SQS simple queuing service SNS",
    "start": "1069360",
    "end": "1074960"
  },
  {
    "text": "simple notification service or using Lambda events Uh Lambda is another cool service I don't have time to cover it",
    "start": "1074960",
    "end": "1081280"
  },
  {
    "text": "today but it means that when data comes in you can kickstart new things So uh",
    "start": "1081280",
    "end": "1088400"
  },
  {
    "text": "your pipeline can be more automatic that way So S3 u you know I have designed",
    "start": "1088400",
    "end": "1093679"
  },
  {
    "text": "I've been a architect with Amazon for for around three years now I've designed hundreds of architectures I've still not",
    "start": "1093679",
    "end": "1100080"
  },
  {
    "text": "designed any solution that did not have S3 in it It's just like um very useful",
    "start": "1100080",
    "end": "1105440"
  },
  {
    "text": "in in a lot of different scenarios including big data Okay so let's look at Dynamo DB DynamoB",
    "start": "1105440",
    "end": "1112640"
  },
  {
    "text": "is a uh fully managed NoSQL service Again uh it's it's managed for you What",
    "start": "1112640",
    "end": "1118160"
  },
  {
    "text": "is managed is things like Oh thank",
    "start": "1118160",
    "end": "1124440"
  },
  {
    "text": "you So uh yes Okay here I am",
    "start": "1124440",
    "end": "1131799"
  },
  {
    "start": "1128000",
    "end": "1338000"
  },
  {
    "text": "Okay got ahead of myself Okay so uh what",
    "start": "1131799",
    "end": "1137280"
  },
  {
    "text": "is banished for you in this NoSQL service is the underlying infrastructure uh the software on it and the patching",
    "start": "1137280",
    "end": "1143919"
  },
  {
    "text": "of it the scaling of infrastructure when you're throwing more data at it the patching of of the u uh of the software",
    "start": "1143919",
    "end": "1150880"
  },
  {
    "text": "as well as u uh sharding or whatever is required behind the scene it's managed for you you just give it your data it's",
    "start": "1150880",
    "end": "1157039"
  },
  {
    "text": "bottomless you provision the amount of throughput you need and you get it um it",
    "start": "1157039",
    "end": "1162240"
  },
  {
    "text": "is useful for both uh key value kind of uh data as well as document uh kind of",
    "start": "1162240",
    "end": "1168960"
  },
  {
    "text": "data I normally like to keep it more interactive but in this kind of scenario that's not possible But uh the key idea",
    "start": "1168960",
    "end": "1175840"
  },
  {
    "text": "of a key value store is that u when you have some data in which you can um uh",
    "start": "1175840",
    "end": "1183679"
  },
  {
    "text": "you can divide up into key and value you know uh this is my data element this is the key and this is the corresponding",
    "start": "1183679",
    "end": "1189919"
  },
  {
    "text": "value when I ask when I give you the key give me back the data or the value that's the key notion of a key value",
    "start": "1189919",
    "end": "1196080"
  },
  {
    "text": "store and a lot of data out there is is just like that uh and document uh store",
    "start": "1196080",
    "end": "1201440"
  },
  {
    "text": "is things like if you have uh to to do some um storing querying or updating of",
    "start": "1201440",
    "end": "1207919"
  },
  {
    "text": "documents in XML JSON or XML format that's when or HTML that's when uh",
    "start": "1207919",
    "end": "1214400"
  },
  {
    "text": "document stores become uh important and Dynamob is is a data store that handles",
    "start": "1214400",
    "end": "1219440"
  },
  {
    "text": "both key value stores as well as uh NoSQL stores Um you know in in 30",
    "start": "1219440",
    "end": "1225280"
  },
  {
    "text": "seconds the key idea of a NoSQL store is that uh most relational databases are asset",
    "start": "1225280",
    "end": "1232400"
  },
  {
    "text": "compliance So they offer a lot of functionality uh and and full SQL kind",
    "start": "1232400",
    "end": "1238400"
  },
  {
    "text": "of compatibility but in a lot of circumstances you don't really need that full SQL kind of uh capacity You don't",
    "start": "1238400",
    "end": "1246000"
  },
  {
    "text": "need to uh write all kinds of SQL commands and you don't need full asset compliance unless you're doing financial",
    "start": "1246000",
    "end": "1252000"
  },
  {
    "text": "transactions etc In those cases it makes a ton of sense to use a NoSQL data store",
    "start": "1252000",
    "end": "1258159"
  },
  {
    "text": "which scales very easily and to a really big extent uh over and above what a",
    "start": "1258159",
    "end": "1264080"
  },
  {
    "text": "relational data store can do So that's where stores like uh Dynamob come into picture and there are others in the",
    "start": "1264080",
    "end": "1270480"
  },
  {
    "text": "space There are probably more than 100 NoSQL stores out there like Cassandra and that you can set up on Amazon",
    "start": "1270480",
    "end": "1276960"
  },
  {
    "text": "as well Dynamob is just managed for you Uh real quick uh some key terms related",
    "start": "1276960",
    "end": "1283760"
  },
  {
    "text": "to Dynamo DB Uh it has tables as well Just like in relational data stores",
    "start": "1283760",
    "end": "1288880"
  },
  {
    "text": "there are tables but instead of rows that we have in relational data stores in Dynamo we call them items Each row is",
    "start": "1288880",
    "end": "1296080"
  },
  {
    "text": "an item Each item has attributes Instead of column values we have attributes",
    "start": "1296080",
    "end": "1301840"
  },
  {
    "text": "within an item A bunch of attributes combined together to give you one item An item can be up to 400 kilobyte in",
    "start": "1301840",
    "end": "1309120"
  },
  {
    "text": "size That's the limit But you can have as many attributes as you want and different uh items can have different",
    "start": "1309120",
    "end": "1316320"
  },
  {
    "text": "number of attributes So there is no real schema It's very very flexible All you need to do is specify one primary key",
    "start": "1316320",
    "end": "1322480"
  },
  {
    "text": "Once you have that primary key which uniquely identifies an item across your table the rest of it is very flexible So",
    "start": "1322480",
    "end": "1329280"
  },
  {
    "text": "you can throw a lot of different kinds of data in there",
    "start": "1329280",
    "end": "1334600"
  },
  {
    "start": "1338000",
    "end": "1432000"
  },
  {
    "text": "So I I I want to reiterate that relational databases still have a place",
    "start": "1340640",
    "end": "1347440"
  },
  {
    "text": "in big data space I'm a big fan of keep using relational databases simply",
    "start": "1347440",
    "end": "1352559"
  },
  {
    "text": "because they have been around for years and years A lot of people have expertise on them and they are known to work well",
    "start": "1352559",
    "end": "1358400"
  },
  {
    "text": "Unless you're feeling pain around it or your data sizes are not that big or not scaling or changing very fast relational",
    "start": "1358400",
    "end": "1364240"
  },
  {
    "text": "databases do have a place uh in this space uh and uh RDS uh relational",
    "start": "1364240",
    "end": "1369520"
  },
  {
    "text": "database service is a managed service from Amazon It offers you choice of five different database engines You can",
    "start": "1369520",
    "end": "1375280"
  },
  {
    "text": "choose between MySQL Postgress SQL Microsoft SQL Server Oracle and Aurora",
    "start": "1375280",
    "end": "1382480"
  },
  {
    "text": "which is a homegrown uh kind of engine Uh Aurora is actually uh MySQL",
    "start": "1382480",
    "end": "1387600"
  },
  {
    "text": "compatible but uh they have uh done some uh unique engineering which makes it uh",
    "start": "1387600",
    "end": "1392960"
  },
  {
    "text": "scale much faster and perform much better um than than vanilla MySQL would do uh with RDS uh you can provision",
    "start": "1392960",
    "end": "1400320"
  },
  {
    "text": "these databases or RDS can provision these kinds of databases for you and do a lot of uh low-level things like",
    "start": "1400320",
    "end": "1408400"
  },
  {
    "text": "patching or backups or snapshots or launching databases in multi-AZ for",
    "start": "1408400",
    "end": "1413919"
  },
  {
    "text": "failover kind of things they are managed for you So RDS is a cool service as well So let's look at the uh next stage",
    "start": "1413919",
    "end": "1420960"
  },
  {
    "text": "which is around processing and analysis",
    "start": "1420960",
    "end": "1425559"
  },
  {
    "start": "1432000",
    "end": "1567000"
  },
  {
    "text": "Okay I don't know how to go back but um uh there are two kinds of uh",
    "start": "1433120",
    "end": "1439440"
  },
  {
    "text": "processing frameworks Uh there is batch processing and there is stream processing The key idea of a batch",
    "start": "1439440",
    "end": "1446400"
  },
  {
    "text": "processing framework is that you are working in batches You have some cold",
    "start": "1446400",
    "end": "1452080"
  },
  {
    "text": "data you chunk it up together maybe in terabytes worth of data and you work on",
    "start": "1452080",
    "end": "1457200"
  },
  {
    "text": "it together and the results they can come back in minutes or maybe hours You know it does not really matter You are",
    "start": "1457200",
    "end": "1463360"
  },
  {
    "text": "working batch by batch And a good example of batch processing kind of uh workloads is when you are creating daily",
    "start": "1463360",
    "end": "1469760"
  },
  {
    "text": "weekly or monthly reports Uh that that's typically when you're doing batch processing Stream processing is real",
    "start": "1469760",
    "end": "1476240"
  },
  {
    "text": "time It's like you know the stream injection that we were talking about that you have to work in in pseudo real",
    "start": "1476240",
    "end": "1482159"
  },
  {
    "text": "time You want results back in seconds So you can't really chunk up a lot of data It's hot data It's changing very fast",
    "start": "1482159",
    "end": "1489200"
  },
  {
    "text": "And a good example of stream processing is um you know one minute metrics when",
    "start": "1489200",
    "end": "1494400"
  },
  {
    "text": "you have to uh find some uh log information or click stream analysis or bidding or lots of applications uh want",
    "start": "1494400",
    "end": "1502400"
  },
  {
    "text": "your processing to be really fast and that's where uh stream processing frameworks come into picture",
    "start": "1502400",
    "end": "1509520"
  },
  {
    "text": "uh and this slide shows you uh some of the tools in the ecosystem for batch",
    "start": "1509520",
    "end": "1514880"
  },
  {
    "text": "processing kind of workloads and this is where I'm going to focus today We have red shift which is a data warehousing",
    "start": "1514880",
    "end": "1521600"
  },
  {
    "text": "solution I'm going to get into what data warehouses are We have elastic map producer EMR Uh and then there are a lot",
    "start": "1521600",
    "end": "1529200"
  },
  {
    "text": "of tools in the ecosystem in the Hadoop ecosystem There is pig and hive and presto and pala There is spark uh spark",
    "start": "1529200",
    "end": "1535600"
  },
  {
    "text": "streaming There are a ton of things there And for stream processing uh we have",
    "start": "1535600",
    "end": "1541080"
  },
  {
    "text": "um open source tools like Apache storm project We have spark streaming and then",
    "start": "1541080",
    "end": "1547279"
  },
  {
    "text": "we have uh uh you know with kinesis there comes the kinesis client library So you can write your processing",
    "start": "1547279",
    "end": "1553760"
  },
  {
    "text": "application using uh KCL as well Uh so I'm not going to focus on uh Kinesis",
    "start": "1553760",
    "end": "1559440"
  },
  {
    "text": "because we talked about it already Next I'm going to talk about Redshift and uh uh",
    "start": "1559440",
    "end": "1566240"
  },
  {
    "start": "1567000",
    "end": "1704000"
  },
  {
    "text": "EMR Okay uh data warehouses uh you know",
    "start": "1567400",
    "end": "1574760"
  },
  {
    "text": "you're the the key idea of a um you know Amazon red shift it offers you a fully",
    "start": "1574760",
    "end": "1581440"
  },
  {
    "text": "managed data warehousing solution it's a columner store the key difference between a relational database store",
    "start": "1581440",
    "end": "1587520"
  },
  {
    "text": "which under many circumstances many people are using as their warehouses as well which is fine but when we are",
    "start": "1587520",
    "end": "1593840"
  },
  {
    "text": "talking about enterprise enterprise scale data warehouses which scale to terabyte or pabytes",
    "start": "1593840",
    "end": "1600080"
  },
  {
    "text": "size data your relational data stores no longer cut it So all the uh good",
    "start": "1600080",
    "end": "1605919"
  },
  {
    "text": "enterprise data warehouses out there are column net data stores for the most part and they are typically used for OLAP or",
    "start": "1605919",
    "end": "1613120"
  },
  {
    "text": "online analytic processing uh as opposed to OLTP or online transaction processing",
    "start": "1613120",
    "end": "1618559"
  },
  {
    "text": "for which relational data stores are mainly used uh they are columnar data store which essentially means that when",
    "start": "1618559",
    "end": "1625200"
  },
  {
    "text": "the data in your tables is stored on the storage device say a hard drive it's",
    "start": "1625200",
    "end": "1631600"
  },
  {
    "text": "stored column by column a relational database would typically store data rowby row instead of column by column",
    "start": "1631600",
    "end": "1638480"
  },
  {
    "text": "storing data column-wise makes sense in analytic processing kind of workloads",
    "start": "1638480",
    "end": "1643679"
  },
  {
    "text": "because the kind of queries both use SQL uh by the way both can use SQL but the",
    "start": "1643679",
    "end": "1648720"
  },
  {
    "text": "kind of queries that you write against them are different analysis queries An example is things like for the uh you",
    "start": "1648720",
    "end": "1656400"
  },
  {
    "text": "know for the United States in the uh state of Virginia in the district of",
    "start": "1656400",
    "end": "1662760"
  },
  {
    "text": "Fairfax find all the uh citizens who are women between age this and this which",
    "start": "1662760",
    "end": "1668400"
  },
  {
    "text": "means that you have to scan the whole column to find that piece of information",
    "start": "1668400",
    "end": "1673520"
  },
  {
    "text": "uh because that's how data is typically laid out in a in a table If the data is stored column by column when you're",
    "start": "1673520",
    "end": "1679679"
  },
  {
    "text": "consuming or reading data from the data store the block that you get back would have all that information in one go and",
    "start": "1679679",
    "end": "1685679"
  },
  {
    "text": "you can easily process on it If it's rowby row you'll just have to read a lot of data just to get to the information",
    "start": "1685679",
    "end": "1691520"
  },
  {
    "text": "you're getting trying to get to in the analytic pipelines So that's why relational data warehouses are typically",
    "start": "1691520",
    "end": "1697919"
  },
  {
    "text": "columner store and uh red shift is as you know it also has um some other uh very cool",
    "start": "1697919",
    "end": "1706480"
  },
  {
    "start": "1704000",
    "end": "1848000"
  },
  {
    "text": "features uh things like it has a massively parallel pipeline when you launch red shift you're essentially",
    "start": "1706480",
    "end": "1713360"
  },
  {
    "text": "launching a cluster you're actually launching a cluster with a leader node and child nodes and when you write a SQL",
    "start": "1713360",
    "end": "1720480"
  },
  {
    "text": "query uh it gets mapped into uh things that each of these children nodes do in",
    "start": "1720480",
    "end": "1726640"
  },
  {
    "text": "parallel So it's a cluster of things trying to run your query in parallel and then uh it does compression of your data",
    "start": "1726640",
    "end": "1733600"
  },
  {
    "text": "When you store data column by column as you can imagine data sitting next to",
    "start": "1733600",
    "end": "1738960"
  },
  {
    "text": "each other is all of the same kind If it's int it's int If it's string it's string Unlike in row where things can",
    "start": "1738960",
    "end": "1745520"
  },
  {
    "text": "mix and match in a column they are all of the same kind So compressing data",
    "start": "1745520",
    "end": "1751360"
  },
  {
    "text": "becomes much more easier So you can get 3x 5x kind of compression Uh so that way",
    "start": "1751360",
    "end": "1756880"
  },
  {
    "text": "when you read the data back with a single read you get a lot of data back in the same uh read So these kinds of",
    "start": "1756880",
    "end": "1763039"
  },
  {
    "text": "optimizations make uh red shift go really fast Uh so it's it's great uh",
    "start": "1763039",
    "end": "1768720"
  },
  {
    "text": "tool for uh batch processing kind of things Uh people do nightly writes to it and then they write their analytic",
    "start": "1768720",
    "end": "1774720"
  },
  {
    "text": "queries against Redshift It comes in two different flavors There is dense storage",
    "start": "1774720",
    "end": "1780399"
  },
  {
    "text": "nodes in red shift and there is dense compute nodes in in red shift Dense uh",
    "start": "1780399",
    "end": "1785440"
  },
  {
    "text": "storage nodes are hard drive based uh and uh they scale up to 1.6",
    "start": "1785440",
    "end": "1792120"
  },
  {
    "text": "pabyte in one cluster in one red shift cluster and then you have multiple red shift clusters as well So we're talking",
    "start": "1792120",
    "end": "1797520"
  },
  {
    "text": "about really big sizes here and dense compute they just have a lot of RAM uh",
    "start": "1797520",
    "end": "1802799"
  },
  {
    "text": "and latest generation processors as well as SSD drives So they compute really fast So the results come back much",
    "start": "1802799",
    "end": "1809279"
  },
  {
    "text": "faster So you can choose uh either or Um but you know the bottom line is uh data",
    "start": "1809279",
    "end": "1815360"
  },
  {
    "text": "warehouses the main problem is they are great but they are very costly Uh red shift solves that problem You can start",
    "start": "1815360",
    "end": "1821039"
  },
  {
    "text": "at 25 cents an hour and then you know you can uh get to the rates like $1,000",
    "start": "1821039",
    "end": "1827840"
  },
  {
    "text": "per terabyte per year And if you if you know about data warehouses their licenses can run in six figures So it",
    "start": "1827840",
    "end": "1833840"
  },
  {
    "text": "just levels the playing field a lot Um and uh piece of trivia red shift is",
    "start": "1833840",
    "end": "1839279"
  },
  {
    "text": "the fastest growing AWS service you know since its launch Uh it's the fastest growing lots of need for",
    "start": "1839279",
    "end": "1847360"
  },
  {
    "start": "1848000",
    "end": "2106000"
  },
  {
    "text": "it All right So let's uh uh let's look at uh map reduce briefly Um so elastic",
    "start": "1848039",
    "end": "1855279"
  },
  {
    "text": "map reduce uh or EMR it enables uh businesses researchers data analysts you",
    "start": "1855279",
    "end": "1861360"
  },
  {
    "text": "know all kinds of users to uh easily and cost effectively process a lot of data",
    "start": "1861360",
    "end": "1868880"
  },
  {
    "text": "um which might be unstructured We have not talked about uh unstructured versus structured data but uh a lot of",
    "start": "1868880",
    "end": "1874960"
  },
  {
    "text": "different kinds of datas using uh commodity hardware It actually um behind",
    "start": "1874960",
    "end": "1880799"
  },
  {
    "text": "the U scene uses stock Apache Hadoop project uh uh implementation uh there",
    "start": "1880799",
    "end": "1887760"
  },
  {
    "text": "are partner implementations from companies as well like map R but uh the",
    "start": "1887760",
    "end": "1892880"
  },
  {
    "text": "EMR uh service by default gives you stock uh Apache Hadoop things and the um",
    "start": "1892880",
    "end": "1899919"
  },
  {
    "text": "Apache Hadoop you know it's a distributed data processing engine",
    "start": "1899919",
    "end": "1905240"
  },
  {
    "text": "um and distributed data processing engine uh it you it's Java based uh and",
    "start": "1905240",
    "end": "1911039"
  },
  {
    "text": "the the key idea there is uh there is uh something called map reduce uh the",
    "start": "1911039",
    "end": "1916799"
  },
  {
    "text": "notion of map produce is uh you divide your data up into uh many you know many",
    "start": "1916799",
    "end": "1923360"
  },
  {
    "text": "small fragments that can be worked on in parallel So you break up your problem into two stages The first stage is",
    "start": "1923360",
    "end": "1930320"
  },
  {
    "text": "called map and the second stage is called uh reduced uh you know I don't",
    "start": "1930320",
    "end": "1935360"
  },
  {
    "text": "have too much time but the hello world example of of this space is the word",
    "start": "1935360",
    "end": "1940480"
  },
  {
    "text": "count kind of example The idea is you have um thousands or maybe millions of",
    "start": "1940480",
    "end": "1945919"
  },
  {
    "text": "files and you are trying to count how many times a particular word appears",
    "start": "1945919",
    "end": "1950960"
  },
  {
    "text": "across all of them You know uh the first thing that you can think about is that",
    "start": "1950960",
    "end": "1957039"
  },
  {
    "text": "hey I don't need a single compute node to work serially all on those files You",
    "start": "1957039",
    "end": "1962159"
  },
  {
    "text": "know I can divide up each say if I have uh if I have 10 files and 10 different",
    "start": "1962159",
    "end": "1967760"
  },
  {
    "text": "compute nodes I can have one compute node at look at each file and then determine how many words are there in",
    "start": "1967760",
    "end": "1974399"
  },
  {
    "text": "that file of a particular kind like how many times the appears or how many times um Washington DC appears etc And then I",
    "start": "1974399",
    "end": "1981840"
  },
  {
    "text": "have to add them all up to come up with the final number But the bottom line is initial processing is all parallel It's",
    "start": "1981840",
    "end": "1989440"
  },
  {
    "text": "all independent And that's the key idea of map reduce You divide up your problem to have two stages Map stage in which",
    "start": "1989440",
    "end": "1995519"
  },
  {
    "text": "things can all happen in parallel So uh Hadoop clusters can span thousands of",
    "start": "1995519",
    "end": "2001120"
  },
  {
    "text": "nodes as well and and you know lots and lots of data can be consumed by it And then there's the reduced stage in which",
    "start": "2001120",
    "end": "2007760"
  },
  {
    "text": "the final results are are accumulated across all the different nodes Uh and uh",
    "start": "2007760",
    "end": "2013279"
  },
  {
    "text": "EMR implements that very nicely And the here is a typical uh",
    "start": "2013279",
    "end": "2018960"
  },
  {
    "text": "design pattern of uh of how EMR uh works Your input data is in S3 Uh you launch a",
    "start": "2018960",
    "end": "2026799"
  },
  {
    "text": "EMR cluster You know in the end when I play my demo after Marco is done uh you'll see uh you know EMR in action a",
    "start": "2026799",
    "end": "2034559"
  },
  {
    "text": "little bit but you um you launch the cluster tell the number of nodes you want you tell the using bootstrap steps",
    "start": "2034559",
    "end": "2042159"
  },
  {
    "text": "what kind of software you want on it uh your uh uh software can uh include uh",
    "start": "2042159",
    "end": "2048000"
  },
  {
    "text": "you know all the popular things in the ecosystem including hive and pig and impala etc EMR installs them for you",
    "start": "2048000",
    "end": "2055440"
  },
  {
    "text": "Ganglia etc And um then you write your mapper or reducer Uh you can use the map",
    "start": "2055440",
    "end": "2062480"
  },
  {
    "text": "and reduce codes in the ecosystem as well And finally your results come back to S3 So that's one pattern But you can",
    "start": "2062480",
    "end": "2068960"
  },
  {
    "text": "do things like you can resize your cluster very easily You started with five compute nodes Hey you know I it's a",
    "start": "2068960",
    "end": "2076158"
  },
  {
    "text": "parallel application I can add more nodes and and get done quickly So you add more nodes and EMR resizes things",
    "start": "2076159",
    "end": "2082960"
  },
  {
    "text": "for you It works very well with spot pricing For those of you who know spot pricing you bid against unused AWS",
    "start": "2082960",
    "end": "2089919"
  },
  {
    "text": "capacity Behind the scene EMR using is using EC2 and S3 Those are the services",
    "start": "2089919",
    "end": "2095839"
  },
  {
    "text": "it's leveraging It's it's transparent about it So it can bid on your behalf on unused capacity and use spot pricing",
    "start": "2095839",
    "end": "2102560"
  },
  {
    "text": "very well to to optimize on costs Um and again it uh works very well with",
    "start": "2102560",
    "end": "2109520"
  },
  {
    "start": "2106000",
    "end": "2158000"
  },
  {
    "text": "a lot of uh tools in that ecosystem The last part of um of my talk is about",
    "start": "2109520",
    "end": "2116520"
  },
  {
    "text": "visualization Amazon does not have any any service in this space simply because",
    "start": "2116520",
    "end": "2122240"
  },
  {
    "text": "the uh partners and the ISVS that we have Uh there are a lot of tools out",
    "start": "2122240",
    "end": "2127680"
  },
  {
    "text": "there that people already use and love a lot and all of those tools work very well uh they work very well because",
    "start": "2127680",
    "end": "2134560"
  },
  {
    "text": "things like red shift they expose standard JDBC and OBC connect connectors to which all of these tools can talk to",
    "start": "2134560",
    "end": "2141280"
  },
  {
    "text": "so there is nothing proprietary there so it's the ecosystem is very rich you can use uh any of the tools in my demo I'm",
    "start": "2141280",
    "end": "2147839"
  },
  {
    "text": "showing how to use Pantaho which has just started just started using but you can use Tableau or Jasperoft or any",
    "start": "2147839",
    "end": "2153920"
  },
  {
    "text": "other tools that you like as well and and this is my final slide before",
    "start": "2153920",
    "end": "2161920"
  },
  {
    "start": "2158000",
    "end": "2247000"
  },
  {
    "text": "Marco comes comes in and in this I'm just putting everything back together So we started with a lot of different tools",
    "start": "2161920",
    "end": "2169040"
  },
  {
    "text": "in the ecosystem and then we said let's create a pipeline with different stages We looked at injection part of pipeline",
    "start": "2169040",
    "end": "2175920"
  },
  {
    "text": "and there are several tools in it We looked at that data could be transactional data could be file or data",
    "start": "2175920",
    "end": "2182960"
  },
  {
    "text": "could be um uh stream kind of data and there are tools for that And then for storage we",
    "start": "2182960",
    "end": "2189839"
  },
  {
    "text": "looked at your storage has different options because you could be using caching data you could be using search",
    "start": "2189839",
    "end": "2195920"
  },
  {
    "text": "data file store data relational store data NoSQL kind of data data warehousing kind of data or file kind of data and",
    "start": "2195920",
    "end": "2203200"
  },
  {
    "text": "there are storage options for that Then we looked at processing part of the pipeline We said that there are two",
    "start": "2203200",
    "end": "2209680"
  },
  {
    "text": "kinds of frameworks There is batch processing that you do with things like red shift or EMR and there are stream",
    "start": "2209680",
    "end": "2215520"
  },
  {
    "text": "processing that you do do with things like storm Apache Storm or with Kinesis client libraries And finally we have the",
    "start": "2215520",
    "end": "2221440"
  },
  {
    "text": "visualization buckets and there are lots of tools in that ecosystem BI tools that you can uh also uh",
    "start": "2221440",
    "end": "2228359"
  },
  {
    "text": "leverage So uh I'm going to skip this This is what my demo is We are going to",
    "start": "2228359",
    "end": "2234000"
  },
  {
    "text": "go to Marco and come back to it in the end if you have time",
    "start": "2234000",
    "end": "2239160"
  },
  {
    "text": "Thanks Kitty",
    "start": "2239280",
    "end": "2242599"
  },
  {
    "start": "2247000",
    "end": "2335000"
  },
  {
    "text": "Yeah thank thanks Kitty for that So um yeah so actually Katie asked me to uh",
    "start": "2248000",
    "end": "2254240"
  },
  {
    "text": "to give you a kind of real life example of uh of what I'm doing So I'm um I'm",
    "start": "2254240",
    "end": "2260960"
  },
  {
    "text": "running um the uh aviation analysis department in the international civil",
    "start": "2260960",
    "end": "2267040"
  },
  {
    "text": "aviation organization So um um the example I will give you it's about",
    "start": "2267040",
    "end": "2272720"
  },
  {
    "text": "accident things you know but if you hear about AO it's like you know accidents are really kind of rare events nowadays",
    "start": "2272720",
    "end": "2278880"
  },
  {
    "text": "you know but if you if something happens now it's kind of exceptional you know like there's a plane lost some in the",
    "start": "2278880",
    "end": "2285200"
  },
  {
    "text": "Pacific okay people ask yourselves okay how is it possible we cannot find the plane okay um IO gets done into place",
    "start": "2285200",
    "end": "2292960"
  },
  {
    "text": "and um so so for those those who know so I'm from Montreal",
    "start": "2292960",
    "end": "2298560"
  },
  {
    "text": "And um yeah we are using uh we using uh AWS now in the cloud for maybe six years",
    "start": "2298560",
    "end": "2306839"
  },
  {
    "text": "now and um yeah we have different offices around the world different what we call regional regional offices So um",
    "start": "2306839",
    "end": "2314720"
  },
  {
    "text": "since we since we used the Amazon cloud everything has come really faster So uh our office for example in uh in Thailand",
    "start": "2314720",
    "end": "2323200"
  },
  {
    "text": "um they uh when they access our data and our analysis I mean everything has",
    "start": "2323200",
    "end": "2328320"
  },
  {
    "text": "become much faster than before where everything was stored in Montreal and people had to connect to it and all the all of this Um so to go a little bit",
    "start": "2328320",
    "end": "2336800"
  },
  {
    "start": "2335000",
    "end": "2451000"
  },
  {
    "text": "about the about the cloud So what what what we think is that if the data we",
    "start": "2336800",
    "end": "2343440"
  },
  {
    "text": "produce it's really just meant to be used inside our organization generally",
    "start": "2343440",
    "end": "2348880"
  },
  {
    "text": "we would prefer keeping it you know that's a finance things or human resource stuff medical things so uh but",
    "start": "2348880",
    "end": "2355680"
  },
  {
    "text": "it's meant to be shared uh so distributed well we we definitely we definitely put it on the uh on the cloud",
    "start": "2355680",
    "end": "2363280"
  },
  {
    "text": "but if it's collected uh internally we try to kind of synchronize give you an",
    "start": "2363280",
    "end": "2368560"
  },
  {
    "text": "example of this and because Kadia actually actually very much said it all",
    "start": "2368560",
    "end": "2374079"
  },
  {
    "text": "is about collection storage analysis and visualization Okay So and the collection",
    "start": "2374079",
    "end": "2380880"
  },
  {
    "text": "piece actually very much starts like for my organization it starts with the person who who gets something put",
    "start": "2380880",
    "end": "2386720"
  },
  {
    "text": "something from paper maybe into a database you know and I think everybody of you has probably someone like that Okay So these people are using something",
    "start": "2386720",
    "end": "2394400"
  },
  {
    "text": "which is very often not very fancy and um but it which works okay it can be",
    "start": "2394400",
    "end": "2400000"
  },
  {
    "text": "local they don't need to access it from their iPad when they're on the train okay so uh on the other side you have",
    "start": "2400000",
    "end": "2406640"
  },
  {
    "text": "people who are looking at data who looking at metrics at graphs while those ones they must have access to it from",
    "start": "2406640",
    "end": "2412079"
  },
  {
    "text": "anywhere from any device and uh yeah from the iPad on the train uh but it's",
    "start": "2412079",
    "end": "2418800"
  },
  {
    "text": "not the same people so we try to segregate those and when I talk analysis",
    "start": "2418800",
    "end": "2424000"
  },
  {
    "text": "I talk what is there on the right side okay what is on the left side is part of the collection piece so that can be very",
    "start": "2424000",
    "end": "2429200"
  },
  {
    "text": "old very whatever uh I don't touch it okay uh so I I think you have pieces",
    "start": "2429200",
    "end": "2435920"
  },
  {
    "text": "like that in your building you know when you think oh I this guy he's working on an old database maybe we can put that in",
    "start": "2435920",
    "end": "2441359"
  },
  {
    "text": "the cloud you just forget it okay he knows how it works just leave it okay just get the data h just get what you",
    "start": "2441359",
    "end": "2447680"
  },
  {
    "text": "need and then you do something with it Um so I'll give you an example here of",
    "start": "2447680",
    "end": "2454800"
  },
  {
    "start": "2451000",
    "end": "2558000"
  },
  {
    "text": "an u of a map reduceuced job uh we run every night uh in AO So the idea was we",
    "start": "2454800",
    "end": "2461280"
  },
  {
    "text": "we had a few years ago is that why would we not build something really real time Well real time for an organization like",
    "start": "2461280",
    "end": "2466640"
  },
  {
    "text": "mine is daily Okay it's not by the minute but daily that's for for an",
    "start": "2466640",
    "end": "2471760"
  },
  {
    "text": "international organization is kind of almost real time you know it's like spooky stuff Uh if you're used to",
    "start": "2471760",
    "end": "2478400"
  },
  {
    "text": "publishing publishing reports once a year okay so something every day that's already real time Um so we wanted to put",
    "start": "2478400",
    "end": "2486000"
  },
  {
    "text": "data on accidents together So we wanted to have every morning uh an aggregated",
    "start": "2486000",
    "end": "2491280"
  },
  {
    "text": "set of what happened yesterday and all the information we can have uh on what happened yesterday You know we want to",
    "start": "2491280",
    "end": "2497520"
  },
  {
    "text": "have it on our screens and when we get in the morning Um so at the end of the",
    "start": "2497520",
    "end": "2503280"
  },
  {
    "text": "day we are producing a page which looks like this So this is now an example of an accident of some uh yeah some foca 50",
    "start": "2503280",
    "end": "2511680"
  },
  {
    "text": "which happened in Somalia and we have like four sources of",
    "start": "2511680",
    "end": "2516920"
  },
  {
    "text": "um four sources of information for this you know so there are um data we buy or",
    "start": "2516920",
    "end": "2523440"
  },
  {
    "text": "there are some geeks around the world who run a database which is actually very good but it's still not perfect",
    "start": "2523440",
    "end": "2528680"
  },
  {
    "text": "Okay so we connect to that database and then we collect the stuff from there So",
    "start": "2528680",
    "end": "2534400"
  },
  {
    "text": "all the the work we have to do is actually put all these different pieces together and see what is double and",
    "start": "2534400",
    "end": "2542079"
  },
  {
    "text": "calculate some uh some values for example categorizations and yeah we have to do",
    "start": "2542079",
    "end": "2547920"
  },
  {
    "text": "that every every day Okay and sometimes we're getting information we already had so we have to know that we have to",
    "start": "2547920",
    "end": "2554560"
  },
  {
    "text": "identify those and we have to replace it Okay Um so we use a elastic map we use",
    "start": "2554560",
    "end": "2562160"
  },
  {
    "start": "2558000",
    "end": "2659000"
  },
  {
    "text": "for this So actually to be very useful so um first talking when we are",
    "start": "2562160",
    "end": "2571119"
  },
  {
    "text": "getting the collection of the data um you will see if you have already done this if you ask someone okay you send me",
    "start": "2571119",
    "end": "2578319"
  },
  {
    "text": "your data well they will not send you the data as the other guy who just asked",
    "start": "2578319",
    "end": "2584079"
  },
  {
    "text": "okay they're all different So for example we're getting data in an XML format from one of our sources and in a",
    "start": "2584079",
    "end": "2591280"
  },
  {
    "text": "CSV format from another one Okay When I want to use EMR EMR likes when the data",
    "start": "2591280",
    "end": "2598319"
  },
  {
    "text": "is in a line and it can be any kind of format but has to be in a line XML files",
    "start": "2598319",
    "end": "2603520"
  },
  {
    "text": "are generally not in a line Okay And CSV files generally have a header Okay So we",
    "start": "2603520",
    "end": "2610160"
  },
  {
    "text": "have to get rid of that header because EMR doesn't know what to do with that Okay So that means that we have to sort of a pre-treating things So so when we",
    "start": "2610160",
    "end": "2617520"
  },
  {
    "text": "when we collect in our collection process so we connect to these different sources and we're just running a small",
    "start": "2617520",
    "end": "2624079"
  },
  {
    "text": "script and the script identifies okay what's kind of the format of this and then we put everything in a line format",
    "start": "2624079",
    "end": "2630960"
  },
  {
    "text": "okay so that it can be ingested by EMR okay and very often the people think",
    "start": "2630960",
    "end": "2636960"
  },
  {
    "text": "well that's not useful well very often when you get the data you will see that that's not exactly how EMR will take it",
    "start": "2636960",
    "end": "2642880"
  },
  {
    "text": "okay so we pre-process it and then we put it into S3 So what is in S3 is per",
    "start": "2642880",
    "end": "2651119"
  },
  {
    "text": "line It can be like XML snippet or CSV kind of things but EMR will take care of",
    "start": "2651119",
    "end": "2656880"
  },
  {
    "text": "that but must be in a line So at the end of the day we have a combined file a",
    "start": "2656880",
    "end": "2662640"
  },
  {
    "start": "2659000",
    "end": "2759000"
  },
  {
    "text": "kind of huge file with anything which came from different sources and different formats and um so we're launching our um",
    "start": "2662640",
    "end": "2671839"
  },
  {
    "text": "our EMR and um it's really easy just like a scripting line like this",
    "start": "2671839",
    "end": "2678960"
  },
  {
    "text": "um I'm just highlighted something because we are not um well I'm kind of",
    "start": "2678960",
    "end": "2684640"
  },
  {
    "text": "an I didn't say I'm a JavaScript guy Okay maybe some people still think that's not programming language Okay but",
    "start": "2684640",
    "end": "2691040"
  },
  {
    "text": "for me it's a programming language I mean I'm an engineer and I'm lazy by by trade Okay so if I can go around with",
    "start": "2691040",
    "end": "2697599"
  },
  {
    "text": "one language I do it Okay and I uh so JavaScript actually turned out to",
    "start": "2697599",
    "end": "2703200"
  },
  {
    "text": "be very nice because I can use it for my client side my back end and I even have a database which runs through JavaScript",
    "start": "2703200",
    "end": "2709040"
  },
  {
    "text": "using MongoDB Okay so so I'm using MongoDB So to shuffle my my results from",
    "start": "2709040",
    "end": "2715040"
  },
  {
    "text": "EMR into MongoDB I need to have a connection So and that's why EMR is actually very nice So I can give it my",
    "start": "2715040",
    "end": "2721160"
  },
  {
    "text": "key So I have to send it my key and EMR connects them to my database and puts",
    "start": "2721160",
    "end": "2726880"
  },
  {
    "text": "puts the stuff there Um yeah so this is the configuration file just to to show you",
    "start": "2726880",
    "end": "2733599"
  },
  {
    "text": "that it's it's really not not very difficult So you just define the steps what you want to do So we having my",
    "start": "2733599",
    "end": "2740720"
  },
  {
    "text": "input files and at the end when everything's finished I tell EMR okay you have everything there and then just",
    "start": "2740720",
    "end": "2746640"
  },
  {
    "text": "shovel it into my database because I gave it the key to it so it's",
    "start": "2746640",
    "end": "2752040"
  },
  {
    "text": "fine Um so all of that is just like this configurations on on some sort of Linux",
    "start": "2752040",
    "end": "2758400"
  },
  {
    "text": "server So uh my mapper what is my mapper doing",
    "start": "2758400",
    "end": "2764160"
  },
  {
    "start": "2759000",
    "end": "2915000"
  },
  {
    "text": "Well as an input he gets a bunch of lines bunch of lines which are different formats So some has uh a certain number",
    "start": "2764160",
    "end": "2771599"
  },
  {
    "text": "of fields the other one coming from another source the fields are different So the mapper has to find out first So",
    "start": "2771599",
    "end": "2778560"
  },
  {
    "text": "again you see it's JavaScript I already told you I like that So mappers I can write them in JavaScript Uh so I do that",
    "start": "2778560",
    "end": "2787480"
  },
  {
    "text": "Um so here I'm going through all the lines and then see okay what is it Is it XML or what is it Is it CSV or JSON or",
    "start": "2787480",
    "end": "2794680"
  },
  {
    "text": "whatever And then I pick out the the values I want to keep For example the",
    "start": "2794680",
    "end": "2800079"
  },
  {
    "text": "model of the plane the date where the accident happened the location and a certain number of fields I want",
    "start": "2800079",
    "end": "2806240"
  },
  {
    "text": "Sometimes the source didn't didn't provide me that information So I will not take it Okay So at the end of this",
    "start": "2806240",
    "end": "2813599"
  },
  {
    "text": "uh and uh and KD actually mentioned it it's all about the key Okay It's an key",
    "start": "2813599",
    "end": "2818640"
  },
  {
    "text": "store So we have to build the key And the key for me is the registration number and the date Okay It's actually",
    "start": "2818640",
    "end": "2826240"
  },
  {
    "text": "maybe it has happened once in the last 50 years I have seen it once The same plane having two accidents the same day",
    "start": "2826240",
    "end": "2834119"
  },
  {
    "text": "Okay Well I think I'm able to filter that out manually Okay So I think so for",
    "start": "2834119",
    "end": "2840640"
  },
  {
    "text": "this examples and it actually worked fine for now and they're saying that a same plane has one accident per day So",
    "start": "2840640",
    "end": "2847200"
  },
  {
    "text": "that works fine So it's actually simplifies my my key thing here Okay But I I agree with you that if that would",
    "start": "2847200",
    "end": "2853440"
  },
  {
    "text": "not be the case I would have a problem Okay Anyway for now that's fine Okay So that's my key",
    "start": "2853440",
    "end": "2860920"
  },
  {
    "text": "Um once I getting into my uh my reducer yeah my reducer so takes",
    "start": "2860920",
    "end": "2867119"
  },
  {
    "text": "everything and then will put all the keys together So why would I find different entries if",
    "start": "2867119",
    "end": "2873680"
  },
  {
    "text": "I say that there's only one exam one accident per day Well the thing is that I have my different sources and they all",
    "start": "2873680",
    "end": "2879119"
  },
  {
    "text": "gave me the information on that same thing Okay so I will have three or four or maybe two uh sets of information on",
    "start": "2879119",
    "end": "2887359"
  },
  {
    "text": "the same event So the reducer will put them together for me and then I will just need to take decisions on who's who",
    "start": "2887359",
    "end": "2894160"
  },
  {
    "text": "I will choose and um do my calculations For example using the registration",
    "start": "2894160",
    "end": "2900400"
  },
  {
    "text": "number I'm able to find the country uh through some through some mappings and",
    "start": "2900400",
    "end": "2906640"
  },
  {
    "text": "I'm also calculating some weights and different different things So that's all my reducer will do that",
    "start": "2906640",
    "end": "2914200"
  },
  {
    "text": "uh so at the end I have I have a reduced data set with my values and exactly",
    "start": "2914200",
    "end": "2922240"
  },
  {
    "start": "2915000",
    "end": "2996000"
  },
  {
    "text": "actually I have only kept exactly what I need to do my visualizations and that's actually very powerful from the from the",
    "start": "2922240",
    "end": "2928640"
  },
  {
    "text": "EMR point of view is that you can you can run those things and you only keep what you really need at the end",
    "start": "2928640",
    "end": "2935480"
  },
  {
    "text": "okay so um for me the visualization piece or kind I called it publishing but",
    "start": "2935480",
    "end": "2941520"
  },
  {
    "text": "it's the same it's the same So it's put into my MongoDB and then",
    "start": "2941520",
    "end": "2947040"
  },
  {
    "text": "with uh with node which is well again JavaScript I'm I'm I'm building APIs",
    "start": "2947040",
    "end": "2952640"
  },
  {
    "text": "which then feeding uh uh other JavaScript u graphing tools like for",
    "start": "2952640",
    "end": "2957839"
  },
  {
    "text": "example the I think the third one here is D3 the first one is R and the other",
    "start": "2957839",
    "end": "2963200"
  },
  {
    "text": "one are high charts so that's all the JavaScript libraries and so this is all on our websites on the aro websites so",
    "start": "2963200",
    "end": "2970720"
  },
  {
    "text": "every day these graphs they just connect to uh to the cloud to to my node server",
    "start": "2970720",
    "end": "2976800"
  },
  {
    "text": "request the new data and the data has been calculated overnight by my EMR job",
    "start": "2976800",
    "end": "2982160"
  },
  {
    "text": "and the servers for that are created and deleted when the job is finished so I don't need to maintain anything it just",
    "start": "2982160",
    "end": "2988960"
  },
  {
    "text": "it just actually works you know and I think that's that's also what I like for for all this it just",
    "start": "2988960",
    "end": "2996240"
  },
  {
    "start": "2996000",
    "end": "3316000"
  },
  {
    "text": "works okay I think KD wanted to show you some other thing we some",
    "start": "2996760",
    "end": "3003880"
  },
  {
    "text": "timeh doing an example Thanks",
    "start": "3003880",
    "end": "3009640"
  },
  {
    "text": "We don't really have any time U I'm what I'm going to do is I'm going to uh play",
    "start": "3012079",
    "end": "3019200"
  },
  {
    "text": "this If if you have to leave please leave If you want to ask any questions or see what the demo is about please uh",
    "start": "3019200",
    "end": "3025440"
  },
  {
    "text": "feel free to I'm I'm going to hang around for some time Okay So",
    "start": "3025440",
    "end": "3031319"
  },
  {
    "text": "uh oh it already started Thank you Uh so what's happening in this uh particular",
    "start": "3031319",
    "end": "3036400"
  },
  {
    "text": "demo is uh we have um public data sets in Amazon that are hosted for free in S3",
    "start": "3036400",
    "end": "3042720"
  },
  {
    "text": "One of those public data sets is the Wikipedia access data set That data set tells us which Wikipedia page was",
    "start": "3042720",
    "end": "3050240"
  },
  {
    "text": "accessed how many times in a particular day Uh all of that data is in S3 What I'm doing is bringing that data from S3",
    "start": "3050240",
    "end": "3057680"
  },
  {
    "text": "into EMR when that data is in EMR",
    "start": "3057680",
    "end": "3063480"
  },
  {
    "text": "Uh can you pause that real quick please I'm going to start it again shortly U",
    "start": "3063480",
    "end": "3069280"
  },
  {
    "text": "once that data is in EMR um in EMR there is a tool called Hive Uh Hive makes EMR",
    "start": "3069280",
    "end": "3077599"
  },
  {
    "text": "or Hadoop distributed file system backend store look like a sequential store So you can write some SQL queries",
    "start": "3077599",
    "end": "3084480"
  },
  {
    "text": "on it uh that Wikipedia log access data is missing the date piece as part of the",
    "start": "3084480",
    "end": "3090079"
  },
  {
    "text": "data set that's just missing So using hive I am now inserting that piece of",
    "start": "3090079",
    "end": "3096640"
  },
  {
    "text": "information back into my data store and then storing it Um and once that data is",
    "start": "3096640",
    "end": "3102640"
  },
  {
    "text": "uh put back in all of that new data with this missing piece is brought into Redshift from Redshift I'm now writing u",
    "start": "3102640",
    "end": "3111440"
  },
  {
    "text": "uh I'm now using panto visualize the data So you know the the four steps here",
    "start": "3111440",
    "end": "3116880"
  },
  {
    "text": "are injection of data from S3 into red shift and then there is processing of adding more inserting more data using",
    "start": "3116880",
    "end": "3123520"
  },
  {
    "text": "hive into that data store and then I store it back in uh EMR After that I am",
    "start": "3123520",
    "end": "3130240"
  },
  {
    "text": "again uh ingesting that data from EMR into uh now Redshift and Redshift is",
    "start": "3130240",
    "end": "3137040"
  },
  {
    "text": "analyzing that data and for visualization I'm using Panaho So that's the four steps here and in this video",
    "start": "3137040",
    "end": "3143839"
  },
  {
    "text": "I'm showing you all of these components one by one Uh so if we play that video again",
    "start": "3143839",
    "end": "3153800"
  },
  {
    "text": "u so uh what we you know initially what I saw in this you saw in this video is uh I",
    "start": "3155040",
    "end": "3161520"
  },
  {
    "text": "went to the AWS management console which is like uh your control room for Amazon cloud All your services are laid down",
    "start": "3161520",
    "end": "3167760"
  },
  {
    "text": "there I went to the EMR service I showed that it's easy to resize EMR and uh then",
    "start": "3167760",
    "end": "3174800"
  },
  {
    "text": "you know there is a tool called Hue Hue is a visual UI tool that EMR provides or",
    "start": "3174800",
    "end": "3181440"
  },
  {
    "text": "it's a tool in the ecosystem that lets you uh do things on EMR cluster using a",
    "start": "3181440",
    "end": "3186559"
  },
  {
    "text": "graphical interface U I showed Hugh it it's already gone but Hugh showed you uh",
    "start": "3186559",
    "end": "3192000"
  },
  {
    "text": "how to write Hive queries and execute uh high SQL queries directly uh after that",
    "start": "3192000",
    "end": "3197760"
  },
  {
    "text": "you know I'm showing that when you launch a red shift cluster redshift gives you S SQL functionality so you can",
    "start": "3197760",
    "end": "3205280"
  },
  {
    "text": "write you can use your uh SQL tools like I'm using SQL workbench right here many",
    "start": "3205280",
    "end": "3211040"
  },
  {
    "text": "of you are familiar with it SQL workbench can now interface with uh red shift directly and uh this right here is",
    "start": "3211040",
    "end": "3218880"
  },
  {
    "text": "uh the Panaho BI tool I just started using it it's very easy to use but you can use others as well in here I I'm",
    "start": "3218880",
    "end": "3226559"
  },
  {
    "text": "using it's uh uh it has two uh it has many different uh components but the two",
    "start": "3226559",
    "end": "3231599"
  },
  {
    "text": "I use was were called data integration which lets you write ETL trans ETL",
    "start": "3231599",
    "end": "3236640"
  },
  {
    "text": "pipelines on uh on your data sitting in red shift from panaho So that's the first one in in doing ETL you have to",
    "start": "3236640",
    "end": "3243440"
  },
  {
    "text": "specify the source of your data the transformation on that data and then the output part of the data So those are the",
    "start": "3243440",
    "end": "3249280"
  },
  {
    "text": "three stages Uh this is Pentaho standard functionality This is their community edition which is open source I'm using",
    "start": "3249280",
    "end": "3256559"
  },
  {
    "text": "that to uh get data from Redshift uh transform it by replacing some string",
    "start": "3256559",
    "end": "3263119"
  },
  {
    "text": "and then writing back to S3 This is just an example I'm not going to execute it But the bottom line is this data",
    "start": "3263119",
    "end": "3268240"
  },
  {
    "text": "integration tool can let me transform my data very easily Uh and uh after this is",
    "start": "3268240",
    "end": "3275200"
  },
  {
    "text": "done what I'm going to show is there is a tool called uh report generator within panaho Report generator lets you create",
    "start": "3275200",
    "end": "3283119"
  },
  {
    "text": "uh uh reports that you can uh leverage uh you know in your day-to-day work The",
    "start": "3283119",
    "end": "3289280"
  },
  {
    "text": "report that I'm generating gives me a bar chart Uh and uh you know this is something that's already been uh done So",
    "start": "3289280",
    "end": "3296880"
  },
  {
    "text": "it shows you the graphs and you can export it as PDFs and and use it Uh or",
    "start": "3296880",
    "end": "3302240"
  },
  {
    "text": "you can uh create uh new reports by selecting the charts etc So that's all I",
    "start": "3302240",
    "end": "3307599"
  },
  {
    "text": "had Uh I'm happy to answer any questions I'll be uh hanging around But thank you for your time",
    "start": "3307599",
    "end": "3315079"
  }
]
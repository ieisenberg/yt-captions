[
  {
    "start": "0",
    "end": "56000"
  },
  {
    "text": "there's a very famous quote in bhagat Gita what is yours today belonged to",
    "start": "1040",
    "end": "6960"
  },
  {
    "text": "someone else yesterday and will belong to someone else The Day After Tomorrow",
    "start": "6960",
    "end": "12599"
  },
  {
    "text": "you are enjoying the fact that this is yours and I think it completely applies",
    "start": "12599",
    "end": "19080"
  },
  {
    "text": "to AWS spot instances if you are wondering how you will definitely get the answer in this",
    "start": "19080",
    "end": "25760"
  },
  {
    "text": "presentation good afternoon everyone my name is chuny Gupta and he is my colleague David we are software engineers at Yelp and",
    "start": "25760",
    "end": "32599"
  },
  {
    "text": "today we will talk about how Yelp saved millions of dollars using spot",
    "start": "32599",
    "end": "40200"
  },
  {
    "text": "Fleet first we will talk about seagull which is our in-house distribute system",
    "start": "40200",
    "end": "46360"
  },
  {
    "text": "then we will talk about Fleet Miser which is our in-house Autos scaling engine and we will finish off with the",
    "start": "46360",
    "end": "53199"
  },
  {
    "text": "future of seal and Fleet Miser before going into that I would",
    "start": "53199",
    "end": "59399"
  },
  {
    "start": "56000",
    "end": "56000"
  },
  {
    "text": "love to share with you all what Yelp is Yelp is a company which provides a",
    "start": "59399",
    "end": "65400"
  },
  {
    "text": "platform for people to read or write reviews and help them connect with great",
    "start": "65400",
    "end": "70960"
  },
  {
    "text": "local businesses as of Q3 2016 we have over",
    "start": "70960",
    "end": "76680"
  },
  {
    "text": "100 million reviews and this number is continuously",
    "start": "76680",
    "end": "82399"
  },
  {
    "text": "increasing oops it looks like we have to stay at here Yelp talk more about",
    "start": "86040",
    "end": "93520"
  },
  {
    "text": "Yelp all right okay I will just yeah I will just",
    "start": "95240",
    "end": "100640"
  },
  {
    "start": "96000",
    "end": "96000"
  },
  {
    "text": "use that all right so these are some of the terminologies which we will be using a",
    "start": "100640",
    "end": "106799"
  },
  {
    "text": "lot during our presentation we will represent a cluster of on demand reserved and spot instances",
    "start": "106799",
    "end": "114560"
  },
  {
    "text": "with the blocks of blue gray and green colors this small scent symbol will",
    "start": "114560",
    "end": "120360"
  },
  {
    "text": "represent a single spot instance one spot Market is basically a",
    "start": "120360",
    "end": "126439"
  },
  {
    "text": "combination of and a z availability Zone instance type and instance size so what",
    "start": "126439",
    "end": "134080"
  },
  {
    "text": "we have here is three three spot markets in some of our graphs we will",
    "start": "134080",
    "end": "141480"
  },
  {
    "text": "use resource unit a lot and for Simplicity you can assume",
    "start": "141480",
    "end": "147319"
  },
  {
    "text": "one resource unit is one CPU a bundle or executor is simply a packet",
    "start": "147319",
    "end": "155879"
  },
  {
    "text": "which contains set of tasks those tasks can be a test case test method or an",
    "start": "155879",
    "end": "161800"
  },
  {
    "text": "image URL depending on depending on what kind of job we are",
    "start": "161800",
    "end": "167480"
  },
  {
    "text": "running",
    "start": "170040",
    "end": "173040"
  },
  {
    "text": "oops so what is seagull seagull is our in-house",
    "start": "177000",
    "end": "182760"
  },
  {
    "text": "distribute system which we have built in last 2 or 3 years and we use seagull to",
    "start": "182760",
    "end": "190120"
  },
  {
    "text": "run jobs with huge",
    "start": "190120",
    "end": "193440"
  },
  {
    "text": "concurrency we run over 25 million tests in a day and they spin up more than 2.5",
    "start": "196319",
    "end": "204400"
  },
  {
    "text": "million Docker containers in a day classifying photos based on",
    "start": "204400",
    "end": "210680"
  },
  {
    "text": "different classifier models is also done on seagull and we",
    "start": "210680",
    "end": "216040"
  },
  {
    "text": "classify around T of millions of photos in less than a day so classifying photos",
    "start": "216040",
    "end": "223599"
  },
  {
    "text": "and running tests are much faster and cheaper in seagull so we are continu",
    "start": "223599",
    "end": "229319"
  },
  {
    "text": "continuously working on adding more applications in",
    "start": "229319",
    "end": "234560"
  },
  {
    "start": "235000",
    "end": "235000"
  },
  {
    "text": "seagull this is a high architectural diagram of seagull where developer triggers jobs or",
    "start": "236599",
    "end": "245079"
  },
  {
    "text": "we can say run we internally call Seagull runs so seal first creates multiple",
    "start": "245079",
    "end": "252040"
  },
  {
    "text": "bundles number of bundles depends upon how many tasks are there in the bundle",
    "start": "252040",
    "end": "257079"
  },
  {
    "text": "in that job so those bundles are then passed to",
    "start": "257079",
    "end": "263479"
  },
  {
    "text": "schul and schedular is just running on top of misos schul checks with misos",
    "start": "263479",
    "end": "270560"
  },
  {
    "text": "are there enough resources available to run these bundles on the cluster let's assume in this case there",
    "start": "270560",
    "end": "279240"
  },
  {
    "text": "are enough resources available to run all these bundles in the cluster so all",
    "start": "279240",
    "end": "284840"
  },
  {
    "text": "the bundles will now be scheduled across the cluster so one thing to notice here",
    "start": "284840",
    "end": "292240"
  },
  {
    "text": "is bundles from different jobs can be run on the same Slave at any point of",
    "start": "292240",
    "end": "298720"
  },
  {
    "text": "time so if if you are wondering like if you",
    "start": "298720",
    "end": "304240"
  },
  {
    "text": "are interested in knowing more about seagull because seagull is a system with various other",
    "start": "304240",
    "end": "309520"
  },
  {
    "text": "components so I will highly recommend you guys to go over to a last year's reinvent talk on",
    "start": "309520",
    "end": "317440"
  },
  {
    "start": "318000",
    "end": "318000"
  },
  {
    "text": "seal now let's talk about the history of seal cluster when we started with seagull we",
    "start": "319240",
    "end": "326880"
  },
  {
    "text": "were on 100% On Demand instances and if I remember correctly until May or",
    "start": "326880",
    "end": "334759"
  },
  {
    "text": "June 2015 we were we were on on",
    "start": "334759",
    "end": "341199"
  },
  {
    "text": "demand and around July we decided to use spot",
    "start": "341199",
    "end": "346520"
  },
  {
    "text": "instances so we created another Autos scaling group with spot instances in it and we started using 75% spot instanes",
    "start": "346520",
    "end": "355600"
  },
  {
    "text": "and 25% reserved instanes in our cluster doing this change was relatively easy we",
    "start": "355600",
    "end": "362759"
  },
  {
    "text": "just had to make some API call changes so once we moved from on demand",
    "start": "362759",
    "end": "369160"
  },
  {
    "text": "to spot we faced some challenges because as you might know if you're are dealing",
    "start": "369160",
    "end": "376840"
  },
  {
    "text": "with spot there is a risk of stability and availability that we will talk about",
    "start": "376840",
    "end": "383280"
  },
  {
    "text": "later so in December after working on those challenges we started using Amazon",
    "start": "383280",
    "end": "390000"
  },
  {
    "text": "ec2 spot Fleet with the same percentage of 75% spot and 25% reserved along with",
    "start": "390000",
    "end": "397880"
  },
  {
    "text": "that we also started using our Auto scaling engine which we call Fleet Meer",
    "start": "397880",
    "end": "405160"
  },
  {
    "text": "D David will talk more about Fleet meiser later so in February 2016 what we did we",
    "start": "405160",
    "end": "414680"
  },
  {
    "text": "moved to 100% spot with that Autos scaling engine enabled so if you look at",
    "start": "414680",
    "end": "421400"
  },
  {
    "text": "this slide from May 2015 100% On Demand",
    "start": "421400",
    "end": "427319"
  },
  {
    "text": "to February 2016 we are 100% spot and we are not risking the stability and",
    "start": "427319",
    "end": "434720"
  },
  {
    "text": "availability of the cluster this was one very interesting fact we will talk about",
    "start": "434720",
    "end": "440160"
  },
  {
    "text": "how we solve the issues of uh stability and availability by using",
    "start": "440160",
    "end": "447680"
  },
  {
    "text": "spot let's look into to the numbers initially when we moved from on",
    "start": "448000",
    "end": "454479"
  },
  {
    "text": "demand to reserve plus spot we saved around",
    "start": "454479",
    "end": "459599"
  },
  {
    "text": "55% in cost and later or earlier in 2016 when",
    "start": "459599",
    "end": "466240"
  },
  {
    "text": "we moved to 100% spot with Autos scaling engine we saved another 60% in",
    "start": "466240",
    "end": "473919"
  },
  {
    "text": "cost so overall we saved around 85% in our legal cluster",
    "start": "473919",
    "end": "482080"
  },
  {
    "start": "483000",
    "end": "483000"
  },
  {
    "text": "cost so you must be thinking or You Must Be Wondering Why why we decided to start",
    "start": "483080",
    "end": "488800"
  },
  {
    "text": "using spot suddenly so as I mentioned around May or June",
    "start": "488800",
    "end": "495560"
  },
  {
    "text": "2015 when we started horizontally scaling our cluster one thing we",
    "start": "495560",
    "end": "501479"
  },
  {
    "text": "observed we saw our AWS bill for seal cluster was",
    "start": "501479",
    "end": "508440"
  },
  {
    "text": "increasing that was pretty obvious",
    "start": "508440",
    "end": "513640"
  },
  {
    "text": "but we said is there a way we can save some money and scale our cluster",
    "start": "513640",
    "end": "523159"
  },
  {
    "text": "continuously so we knew it will not be an easy work to do",
    "start": "523560",
    "end": "529120"
  },
  {
    "text": "because we know on demand comes with stability and you will never risk losing",
    "start": "529120",
    "end": "535480"
  },
  {
    "text": "that on demand instance so we decided okay let's let's",
    "start": "535480",
    "end": "541279"
  },
  {
    "text": "explore other options let's explore options other than on demand so our first option which we",
    "start": "541279",
    "end": "550200"
  },
  {
    "text": "considered was using reserved instances reserved instances are like",
    "start": "550200",
    "end": "556839"
  },
  {
    "text": "you reserve an instance for a particular period of time but you pay the cost",
    "start": "556839",
    "end": "564240"
  },
  {
    "text": "upfront as as of a seal cluster usage was pretty volatile and we could easily",
    "start": "564640",
    "end": "570760"
  },
  {
    "text": "leverage our in-house Autos scaling engine Fleet Miser so we decided let's",
    "start": "570760",
    "end": "576720"
  },
  {
    "text": "not pay the cost up front and only pay what we use",
    "start": "576720",
    "end": "582560"
  },
  {
    "text": "for so the other option which we had was spot",
    "start": "582560",
    "end": "588320"
  },
  {
    "text": "instances with spot you can think spot as like a",
    "start": "588320",
    "end": "593640"
  },
  {
    "text": "Two-Face man if if you're just following some",
    "start": "593640",
    "end": "598880"
  },
  {
    "text": "simple r rules this man will be nice to you and you and your cluster will live",
    "start": "598880",
    "end": "604480"
  },
  {
    "text": "happily but a knif strategy in this case might",
    "start": "604480",
    "end": "610320"
  },
  {
    "text": "make this man turn his face and bite you by that I mean you might end up paying",
    "start": "610320",
    "end": "616880"
  },
  {
    "text": "more than on demand for a period of time we will look into it",
    "start": "616880",
    "end": "622120"
  },
  {
    "text": "later how is it possible I will share with you what",
    "start": "622120",
    "end": "627760"
  },
  {
    "text": "simple rules We are following and saving 80 to 90% in",
    "start": "627760",
    "end": "634160"
  },
  {
    "start": "633000",
    "end": "633000"
  },
  {
    "text": "cost before diving into that let's us see how spot price actually",
    "start": "634279",
    "end": "641560"
  },
  {
    "text": "works suppose in this there is one spot Market where there are seven instances",
    "start": "641560",
    "end": "646600"
  },
  {
    "text": "available and there are three users user a user B and user C and they are bidding",
    "start": "646600",
    "end": "652800"
  },
  {
    "text": "$10 $5 and $1 respectively and the need is three instances to instances and four",
    "start": "652800",
    "end": "661399"
  },
  {
    "text": "instances so what AWS will start doing is AWS will first start fulfilling the",
    "start": "661399",
    "end": "668880"
  },
  {
    "text": "requirement for a user who is bidding higher so in this case user a and user B",
    "start": "668880",
    "end": "676279"
  },
  {
    "text": "will get all the instances they needed but user c will only get one two",
    "start": "676279",
    "end": "682720"
  },
  {
    "text": "instances so most of the time AWS is good enough to provide all the",
    "start": "682720",
    "end": "690160"
  },
  {
    "text": "instances you need but there are",
    "start": "690160",
    "end": "695200"
  },
  {
    "text": "times when AWS do want to take back",
    "start": "695200",
    "end": "700959"
  },
  {
    "text": "instances one thing to one thing to notice in",
    "start": "701000",
    "end": "706079"
  },
  {
    "text": "that oops so one thing to notice here is the",
    "start": "707399",
    "end": "713680"
  },
  {
    "text": "spot price is $1 so spot price is decided by by the",
    "start": "713680",
    "end": "719560"
  },
  {
    "text": "last fulfilled bid so in this case the last fulfilled bid was for user C which",
    "start": "719560",
    "end": "725600"
  },
  {
    "text": "is $1 so now let's assume AWS wants to take back three",
    "start": "725600",
    "end": "732160"
  },
  {
    "text": "instances so to do to do that AWS will first start taking terminating instances",
    "start": "732160",
    "end": "739440"
  },
  {
    "text": "from users who are bidding less so what we just saw user 3 lost",
    "start": "739440",
    "end": "746639"
  },
  {
    "text": "both the instances and user B lost that one instance and one very important thing if",
    "start": "746639",
    "end": "754720"
  },
  {
    "text": "you have noticed the spot price is now $5 which is the last fulfilled bid of",
    "start": "754720",
    "end": "761959"
  },
  {
    "text": "user B so user A and B both are now",
    "start": "761959",
    "end": "767040"
  },
  {
    "text": "paying $5 for each instance rather than $1 which they were paying",
    "start": "767040",
    "end": "773000"
  },
  {
    "text": "earlier so as I was talking about the spot price increase this is a publicly",
    "start": "773000",
    "end": "779760"
  },
  {
    "start": "778000",
    "end": "778000"
  },
  {
    "text": "available uh spot price history of c3x large so most of the time the spot price",
    "start": "779760",
    "end": "788279"
  },
  {
    "text": "is 80 to 90% cheaper than on demand but sometimes it goes way above",
    "start": "788279",
    "end": "794720"
  },
  {
    "text": "than on demand so in this case it went up to $16 for some period of",
    "start": "794720",
    "end": "801279"
  },
  {
    "text": "time so in scenarios when you lose an instant lose",
    "start": "801279",
    "end": "807760"
  },
  {
    "text": "an instance when when you get outbid you have to plan for",
    "start": "807760",
    "end": "813680"
  },
  {
    "text": "termination you have to have a highly fall tolerance",
    "start": "813680",
    "end": "819480"
  },
  {
    "text": "system by that I mean your application and your cluster should be resilient",
    "start": "819480",
    "end": "826920"
  },
  {
    "text": "towards an instance",
    "start": "826920",
    "end": "830000"
  },
  {
    "start": "830000",
    "end": "830000"
  },
  {
    "text": "loss as I mentioned before seagull was a very or is a very highly fall tolerant",
    "start": "834920",
    "end": "841680"
  },
  {
    "text": "system this graph or this image shows one seal run where there are around 300",
    "start": "841680",
    "end": "848839"
  },
  {
    "text": "different bundles and the each each bar represents one bundle so the green bar represents a",
    "start": "848839",
    "end": "857480"
  },
  {
    "text": "successfully finished bundle and the yellow one represents a failed bundle",
    "start": "857480",
    "end": "863600"
  },
  {
    "text": "and it failed because we got outbid where that bundle was running and we lost that instance",
    "start": "863600",
    "end": "870000"
  },
  {
    "text": "so what in this case seal will do seagull will reschedule that bundle",
    "start": "870000",
    "end": "875279"
  },
  {
    "text": "again on any different host what if it happen again happens again we lose the instance again seal",
    "start": "875279",
    "end": "882399"
  },
  {
    "text": "will reschedule it again so in this way seagull or this",
    "start": "882399",
    "end": "888480"
  },
  {
    "text": "application is handling any instance loss we",
    "start": "888480",
    "end": "894120"
  },
  {
    "start": "894000",
    "end": "894000"
  },
  {
    "text": "have so in the previous example of user a b and c",
    "start": "894600",
    "end": "900480"
  },
  {
    "text": "we saw user B and C were not having the required capacity in the cluster user B",
    "start": "900480",
    "end": "906639"
  },
  {
    "text": "was having one and user C was having none in",
    "start": "906639",
    "end": "911880"
  },
  {
    "text": "none this shows that there is a need for a system to handle this",
    "start": "911880",
    "end": "919160"
  },
  {
    "text": "failure there is a need for a system to fulfill the requirement even",
    "start": "919160",
    "end": "925480"
  },
  {
    "text": "in case you lose some lose some instances in any spot market so for us that system was AWS ec2",
    "start": "925480",
    "end": "935399"
  },
  {
    "text": "spot Fleet it makes youres your cluster is highly available let's see how it",
    "start": "935399",
    "end": "944160"
  },
  {
    "text": "works suppose here there is one user who needs nine instances in his cluster and",
    "start": "944959",
    "end": "951160"
  },
  {
    "text": "he is in three markets usw 2 a 2 B and 2 C let's assume this is for C3 at x",
    "start": "951160",
    "end": "957920"
  },
  {
    "text": "large the spot price for in these spot markets are there in the lower left",
    "start": "957920",
    "end": "966240"
  },
  {
    "text": "corner so initially he got all the instances from",
    "start": "966240",
    "end": "971959"
  },
  {
    "text": "those three different markets so in this case when USV 2A spot",
    "start": "971959",
    "end": "977839"
  },
  {
    "text": "price goes up AWS will take back those three",
    "start": "977839",
    "end": "983800"
  },
  {
    "text": "instances but spot Fleet will bring up",
    "start": "983800",
    "end": "989600"
  },
  {
    "text": "new three new instances from other markets so for this",
    "start": "989600",
    "end": "994759"
  },
  {
    "text": "user there will be a time for a few minutes when the capacity was only six",
    "start": "994759",
    "end": "1000800"
  },
  {
    "text": "but his eventual capacity of the cluster will remain intact so for",
    "start": "1000800",
    "end": "1006519"
  },
  {
    "text": "him his cluster is highly available if he is not worried about those few",
    "start": "1006519",
    "end": "1013279"
  },
  {
    "text": "minutes when he lost those three incenses so you must be thinking my",
    "start": "1013279",
    "end": "1019440"
  },
  {
    "start": "1019000",
    "end": "1019000"
  },
  {
    "text": "application is highly fall tolerant my cluster is available I'm in three Market",
    "start": "1019440",
    "end": "1024558"
  },
  {
    "text": "I don't risk the ability to lose the instances",
    "start": "1024559",
    "end": "1032000"
  },
  {
    "text": "so let's look let's look into one example or let's look into a use case or",
    "start": "1032079",
    "end": "1037918"
  },
  {
    "text": "a case when this change in brid price happens very",
    "start": "1037919",
    "end": "1043520"
  },
  {
    "text": "frequently let's assume now usvs 2 B price goes up and 2A price",
    "start": "1043760",
    "end": "1050840"
  },
  {
    "text": "comes down so again the cluster capacity is nine but the user is not having any",
    "start": "1050840",
    "end": "1057880"
  },
  {
    "text": "instance in 2B if it happens again in this",
    "start": "1057880",
    "end": "1063679"
  },
  {
    "text": "case user does not have to worry about it because he is having nine instances",
    "start": "1063679",
    "end": "1070120"
  },
  {
    "text": "what he needed but one thing to notice here is",
    "start": "1070120",
    "end": "1075320"
  },
  {
    "text": "he is only in one a which is little risky if you are talking about a talking",
    "start": "1075320",
    "end": "1082880"
  },
  {
    "text": "about our scale another thing what can happen now is suppose usw 2B price again goes up",
    "start": "1082880",
    "end": "1092640"
  },
  {
    "text": "and 2 sorry 2 C price again goes up and 2B price comes down along with that user",
    "start": "1092640",
    "end": "1100760"
  },
  {
    "text": "2B does not have enough capacity to fulfill the N9 senses so in that case",
    "start": "1100760",
    "end": "1108039"
  },
  {
    "text": "the user is now having six instances but he needs nine",
    "start": "1108039",
    "end": "1114120"
  },
  {
    "text": "instances so the question is even if I'm using spot Fleet there might be a chance most of",
    "start": "1114120",
    "end": "1121400"
  },
  {
    "text": "the time AWS or the bid price does not fluctuate or does not uh increase very",
    "start": "1121400",
    "end": "1127400"
  },
  {
    "text": "frequently but sometimes it can happen that you have less capacity as you",
    "start": "1127400",
    "end": "1133679"
  },
  {
    "text": "needed to be in the cluster so this actually happened back in July this year",
    "start": "1133679",
    "end": "1139760"
  },
  {
    "text": "when spot price for C3 ATX large was changing very",
    "start": "1139760",
    "end": "1146200"
  },
  {
    "text": "frequently so in these cases there are two challenges which you",
    "start": "1146520",
    "end": "1152559"
  },
  {
    "text": "have to think about first is",
    "start": "1152559",
    "end": "1160280"
  },
  {
    "text": "availability as we saw in the previous Slide the user was only having six",
    "start": "1160280",
    "end": "1165640"
  },
  {
    "text": "instances but he needed nine so you have to think about how you will handle this",
    "start": "1165640",
    "end": "1173360"
  },
  {
    "text": "availability issue in your cluster and the second problem is or the second challenge you have which you have",
    "start": "1173360",
    "end": "1179919"
  },
  {
    "text": "to think about is reliability one thing which you could do",
    "start": "1179919",
    "end": "1186320"
  },
  {
    "text": "here is you can easily set you can easily set your spot price to $12.5 or",
    "start": "1186320",
    "end": "1195520"
  },
  {
    "text": "more and you will not face an issue you will not have any Interruption because",
    "start": "1195520",
    "end": "1200559"
  },
  {
    "text": "of this fluctuation but I don't think you would want to do that for an instance whose on",
    "start": "1200559",
    "end": "1208520"
  },
  {
    "text": "demand price is $1.6 and spot price mostly is 050 cents",
    "start": "1208520",
    "end": "1215600"
  },
  {
    "text": "I don't think you would ever want to bid $12.5 for that",
    "start": "1215600",
    "end": "1221159"
  },
  {
    "text": "instance so you have to think about how would you",
    "start": "1221159",
    "end": "1226960"
  },
  {
    "text": "handle too much interruption because bidding higher is not a way to",
    "start": "1226960",
    "end": "1234120"
  },
  {
    "text": "handle Interruption so when we had this",
    "start": "1234120",
    "end": "1239559"
  },
  {
    "text": "issue we applied a naive strategy we moved back to on demand for a few days",
    "start": "1239559",
    "end": "1247640"
  },
  {
    "start": "1240000",
    "end": "1240000"
  },
  {
    "text": "and thought let's be in on demand and wait for the fluctuation to",
    "start": "1247640",
    "end": "1253720"
  },
  {
    "text": "stop and honestly it didn't turn out to be a very good option for for us because",
    "start": "1253720",
    "end": "1260799"
  },
  {
    "text": "we burned our months of saving just by moving back to on demand for a few",
    "start": "1260799",
    "end": "1266720"
  },
  {
    "text": "days I agree on demand incenses comes with stability and availability you will",
    "start": "1266720",
    "end": "1273760"
  },
  {
    "text": "not lose them your applications will not have any issues but on the other hand as we were",
    "start": "1273760",
    "end": "1282440"
  },
  {
    "text": "used to using spot and paying cheap cluster",
    "start": "1282440",
    "end": "1287520"
  },
  {
    "text": "cost we didn't want to use on demand again we had to come up with another",
    "start": "1287520",
    "end": "1295240"
  },
  {
    "text": "solution and start using spot instances again so we sat down as a team and said",
    "start": "1295240",
    "end": "1302720"
  },
  {
    "text": "how would we handle this issue is there a way we can again start using spot and",
    "start": "1302720",
    "end": "1309840"
  },
  {
    "text": "go back to the same cluster cost which we were paying before so we came up with another simple",
    "start": "1309840",
    "end": "1317520"
  },
  {
    "text": "solution but this time a stronger",
    "start": "1317520",
    "end": "1322520"
  },
  {
    "text": "one we came up with diversification what it means is this",
    "start": "1323240",
    "end": "1329080"
  },
  {
    "text": "graph shows the colored time series are resource units or the capacity of",
    "start": "1329080",
    "end": "1336520"
  },
  {
    "text": "individual spot market and the dotted one is the total cluster",
    "start": "1336520",
    "end": "1342600"
  },
  {
    "text": "capacity so we used to have only three spot markets in our cluster",
    "start": "1342600",
    "end": "1349880"
  },
  {
    "text": "what we have here are 30 different spot markets in our",
    "start": "1349880",
    "end": "1355039"
  },
  {
    "text": "cluster and even if we get outbid in three four or any small number of spot",
    "start": "1355039",
    "end": "1361760"
  },
  {
    "text": "markets our cluster total capacity is remaining intact as you can",
    "start": "1361760",
    "end": "1368159"
  },
  {
    "text": "see in three spot markets we got out bid but the total cluster capacity didn't",
    "start": "1368159",
    "end": "1375360"
  },
  {
    "text": "hurt so now the question is is",
    "start": "1375360",
    "end": "1380840"
  },
  {
    "text": "diversification very simple to do it was not an easy task for",
    "start": "1380840",
    "end": "1388320"
  },
  {
    "start": "1386000",
    "end": "1386000"
  },
  {
    "text": "us seagull was not very compatible with some of the instance types in spot",
    "start": "1388559",
    "end": "1397000"
  },
  {
    "text": "market and we had to use spot because the those",
    "start": "1398559",
    "end": "1405960"
  },
  {
    "text": "spot instances on which seagull was not compatible they were also 80 to 90%",
    "start": "1405960",
    "end": "1411679"
  },
  {
    "text": "cheaper than on demand so making seagull compatible was",
    "start": "1411679",
    "end": "1419400"
  },
  {
    "text": "worth spending time for us so we made seagull compatible with",
    "start": "1419400",
    "end": "1425600"
  },
  {
    "text": "those instances and then we didn't have issues of stability and",
    "start": "1425600",
    "end": "1433279"
  },
  {
    "text": "availability now you must be thinking my now my cluster is",
    "start": "1433520",
    "end": "1440240"
  },
  {
    "text": "stable I'm divers I Diversified my spot Fleet and my application is also fall",
    "start": "1440240",
    "end": "1446760"
  },
  {
    "text": "tolerant we should go back to home and sleep no incidents no cluster loss no",
    "start": "1446760",
    "end": "1452000"
  },
  {
    "text": "instance loss that's true but as we all",
    "start": "1452000",
    "end": "1458240"
  },
  {
    "text": "know everything comes up with a trade-off so as this graph",
    "start": "1458240",
    "end": "1466840"
  },
  {
    "text": "shows the shows the performance of different bundles in terms of execution",
    "start": "1466840",
    "end": "1475919"
  },
  {
    "text": "time on on different instance types so on some instance types or bundles were",
    "start": "1475919",
    "end": "1481880"
  },
  {
    "text": "taking longer as compared to other instance types so we had to trade performance for",
    "start": "1481880",
    "end": "1490960"
  },
  {
    "text": "diversification or I should say we had to trade performance for scalability",
    "start": "1490960",
    "end": "1496760"
  },
  {
    "text": "availability and cost effective cluster we decided that's fine",
    "start": "1496760",
    "end": "1503960"
  },
  {
    "text": "let's keep it there because this performance was not hurting us a",
    "start": "1503960",
    "end": "1509919"
  },
  {
    "text": "lot so if anyone of you is planning to use spot Fleet or is already using spot",
    "start": "1510320",
    "end": "1517760"
  },
  {
    "text": "Fleet so we recommend you all to not have any complex building",
    "start": "1517760",
    "end": "1525760"
  },
  {
    "text": "strategies just be simple bid a number and two more",
    "start": "1525760",
    "end": "1532679"
  },
  {
    "text": "things don't bid higher than what you are willing to pay for that",
    "start": "1532679",
    "end": "1537880"
  },
  {
    "text": "instance and last but not the least diversify your",
    "start": "1537880",
    "end": "1543679"
  },
  {
    "text": "cluster because diversification is the key of using spot",
    "start": "1543679",
    "end": "1549760"
  },
  {
    "text": "Fleet so now David will talk about Fleet Meer which is our in-house Autos Skilling engine David thanks chunky",
    "start": "1550600",
    "end": "1559760"
  },
  {
    "text": "um so yeah as chunky mentioned chunky spent a lot of time talking about spot Fleet and one of the reasons why we",
    "start": "1559760",
    "end": "1566440"
  },
  {
    "text": "wanted to use spot Fleet is to take advantage of the fact that we could add",
    "start": "1566440",
    "end": "1571960"
  },
  {
    "text": "and remove instances dynamically and so I'm going to spend some time talking about Fleet meiser which is our in-house",
    "start": "1571960",
    "end": "1578159"
  },
  {
    "text": "engine to actually do that now you might be wondering why do we need any sort of",
    "start": "1578159",
    "end": "1584600"
  },
  {
    "text": "autoscaling engine in the first place and so this graph shows a example of what happens at Yelp in a",
    "start": "1584600",
    "end": "1593080"
  },
  {
    "text": "in a average day so this graph shows the number of seagull runs that are triggered by our developers in the",
    "start": "1593080",
    "end": "1599960"
  },
  {
    "text": "course of Performing tests on our website and you can see that most of the activity is between 9:00 a.m. and about",
    "start": "1599960",
    "end": "1607320"
  },
  {
    "text": "700 p.m. in other words when people are actually at work um there are some uh",
    "start": "1607320",
    "end": "1613840"
  },
  {
    "text": "that are outside of that time window uh we do have some offices in Europe um and so some of those runs are triggered by",
    "start": "1613840",
    "end": "1619840"
  },
  {
    "text": "people in Europe or people who are working late but you can see that the load on our cluster is very volatile um",
    "start": "1619840",
    "end": "1628000"
  },
  {
    "text": "we need a lot of capacity during business hours and we don't need so much capacity the rest of the",
    "start": "1628000",
    "end": "1635080"
  },
  {
    "text": "time the load is also very predictable um we need this capacity during business",
    "start": "1635080",
    "end": "1640960"
  },
  {
    "text": "hours during the week on the weekends and at night we don't need so much capacity and so this makes our",
    "start": "1640960",
    "end": "1646799"
  },
  {
    "text": "application a prime candidate for autoscaling which allows us to save even more money on our compute",
    "start": "1646799",
    "end": "1654799"
  },
  {
    "text": "costs so I want to give you a quick overview of how Fleet meiser actually",
    "start": "1654799",
    "end": "1660720"
  },
  {
    "text": "works this diagram shows all of the different components that we take advantage of so fleet meiser has a",
    "start": "1660720",
    "end": "1668480"
  },
  {
    "text": "number of autoscaling signals that take information from elastic search from Dynamo Dynamo DB um and it calculates",
    "start": "1668480",
    "end": "1677240"
  },
  {
    "text": "various metrics and statistics as to when we need to scale",
    "start": "1677240",
    "end": "1682480"
  },
  {
    "text": "our cluster up and down it uses the results of those autoscaling signals to actually",
    "start": "1682480",
    "end": "1688840"
  },
  {
    "text": "interface with the AWS spot Fleet and tell it hey scale up scale down add some",
    "start": "1688840",
    "end": "1694960"
  },
  {
    "text": "instances remove some instances Etc it also then reports back all of the",
    "start": "1694960",
    "end": "1700919"
  },
  {
    "text": "information about the current state of our cluster to our metrics and monitoring component so we store",
    "start": "1700919",
    "end": "1706720"
  },
  {
    "text": "information into elastic search in Dynamo DB this creates a nice feedback loop into our autoscaling signals we",
    "start": "1706720",
    "end": "1714120"
  },
  {
    "text": "also monitor the operation of our cluster and also Fleet meiser using",
    "start": "1714120",
    "end": "1719919"
  },
  {
    "text": "signal effects and senu so we can track how the cluster is scaling up and down what signals are controlling the cluster",
    "start": "1719919",
    "end": "1727679"
  },
  {
    "text": "scaling and so on and so forth finally we do store a little bit",
    "start": "1727679",
    "end": "1732919"
  },
  {
    "text": "of State in Zookeeper uh these are things like the current Ami that we're using for our CL cluster um the spot",
    "start": "1732919",
    "end": "1739440"
  },
  {
    "text": "Fleet request ID I'm not really going to go into that detail but there is some state that we store",
    "start": "1739440",
    "end": "1745919"
  },
  {
    "text": "there so on this graph I want to show you that hey our autoscaling engine actually works um this graph is showing",
    "start": "1745919",
    "end": "1753600"
  },
  {
    "start": "1747000",
    "end": "1747000"
  },
  {
    "text": "the capacity of our cluster in resource units and as you'll recall uh chunky said that a resource unit you can think",
    "start": "1753600",
    "end": "1760159"
  },
  {
    "text": "of as approximately one CPU and so you can see that uh our Peak capacity is",
    "start": "1760159",
    "end": "1766320"
  },
  {
    "text": "between 12:00 p.m. and 7:00 p.m. this is when again most of our work is being",
    "start": "1766320",
    "end": "1771519"
  },
  {
    "text": "done we have around 1,00 resource units uh at this time um and then after 7 p.m.",
    "start": "1771519",
    "end": "1778159"
  },
  {
    "text": "we start scaling back down there's a small bump around 4:00 in the morning uh",
    "start": "1778159",
    "end": "1784399"
  },
  {
    "text": "this is when a lot of our developers in Europe are doing some uh pushes and",
    "start": "1784399",
    "end": "1790600"
  },
  {
    "text": "deploys and so we scale up a little bit there and then we scale back down in preparation for uh the start of the next",
    "start": "1790600",
    "end": "1798080"
  },
  {
    "text": "next day so this graph hopefully convinces you that we're doing what we're supposed to be doing and so I want",
    "start": "1798080",
    "end": "1804240"
  },
  {
    "text": "to talk a little bit about how we actually control the behavior of our autoscaling to do that I want to look",
    "start": "1804240",
    "end": "1811320"
  },
  {
    "text": "more in detail at our autoscaling signals so fleet meiser has a really",
    "start": "1811320",
    "end": "1816880"
  },
  {
    "start": "1816000",
    "end": "1816000"
  },
  {
    "text": "nice plug-in based architecture for scaling signals so there's two parts but there's really three parts to this um",
    "start": "1816880",
    "end": "1823559"
  },
  {
    "text": "there's the data that is stored in elastic search and Dynamo DB there there's a configuration file you can see",
    "start": "1823559",
    "end": "1829760"
  },
  {
    "text": "an example of this on this slide um that specifies how the signal should operate",
    "start": "1829760",
    "end": "1835519"
  },
  {
    "text": "and then each autoscaling signal is just a very small amount of python code that",
    "start": "1835519",
    "end": "1840799"
  },
  {
    "text": "actually checks to see what our cluster should be doing so here's an example of a cluster",
    "start": "1840799",
    "end": "1848240"
  },
  {
    "text": "over utilized signal this is what it might look like in our configuration file I'm not showing the python code",
    "start": "1848240",
    "end": "1854399"
  },
  {
    "text": "here the python code really is just looking to see what our CPU utilization",
    "start": "1854399",
    "end": "1859840"
  },
  {
    "text": "in the cluster actually is is it too high if so then maybe we're running close to the limits of our cluster and",
    "start": "1859840",
    "end": "1866279"
  },
  {
    "text": "we need to scale up a little bit and our configuration file controls what to high",
    "start": "1866279",
    "end": "1871880"
  },
  {
    "text": "means and how much we should scale up so we've got a parameter in there query period which says that we want to look",
    "start": "1871880",
    "end": "1878480"
  },
  {
    "text": "back at the cluster utilization over the last 10 minutes we want to check the average CPU utilization and see if it's",
    "start": "1878480",
    "end": "1885760"
  },
  {
    "text": "above our scale up threshold which in this case is 65% if it is then we want to add 100",
    "start": "1885760",
    "end": "1892600"
  },
  {
    "text": "units to our cluster the last parameter in here that I haven't talked about yet is our",
    "start": "1892600",
    "end": "1898639"
  },
  {
    "text": "priority the way that our signals interface with each other is through this priority so each signal is required",
    "start": "1898639",
    "end": "1905480"
  },
  {
    "text": "to have a priority value and we evaluate each signal in increasing priority order",
    "start": "1905480",
    "end": "1910880"
  },
  {
    "text": "and we just use a first come first serve rule so the first signal that fires that says hey we need to do something to our",
    "start": "1910880",
    "end": "1916440"
  },
  {
    "text": "cluster we take that one we do whatever it says so in this case we might have a uh",
    "start": "1916440",
    "end": "1923000"
  },
  {
    "text": "cluster underutilized signal which does the converse it says that you know if there's too little CPU utilization then",
    "start": "1923000",
    "end": "1930919"
  },
  {
    "text": "we want to start scaling down if that one is at priority three then that one will only fire if the cluster over",
    "start": "1930919",
    "end": "1937120"
  },
  {
    "text": "utilized signal does not fire and again each of our signals it's like 10 maybe 15 lines of python code so",
    "start": "1937120",
    "end": "1945559"
  },
  {
    "start": "1942000",
    "end": "1942000"
  },
  {
    "text": "using this architecture we're able to very powerfully control the behavior of our cluster with a very small amount of",
    "start": "1945559",
    "end": "1953240"
  },
  {
    "text": "code so this graph shows three of the four different signals that we're using right now um unfortunately I couldn't",
    "start": "1953240",
    "end": "1960120"
  },
  {
    "text": "find a period in time where you could see all four of the signals operating at once but we'll go over all four of them",
    "start": "1960120",
    "end": "1966080"
  },
  {
    "text": "anyways so the first three bars on this graph are then this light orange color",
    "start": "1966080",
    "end": "1971360"
  },
  {
    "text": "um which is our cluster underutilized signal the uh Orange Line the orange",
    "start": "1971360",
    "end": "1977399"
  },
  {
    "text": "Time series series on this graph is showing our cluster capacity as uh it responds to these various autoscaling",
    "start": "1977399",
    "end": "1984159"
  },
  {
    "text": "signals and so in the first three cases the signals are saying hey we are not using our cluster very much let's scale",
    "start": "1984159",
    "end": "1991440"
  },
  {
    "text": "down and you can see that the cluster capacity over this period of time is",
    "start": "1991440",
    "end": "1996880"
  },
  {
    "text": "actually scaling down as these signals are firing we do have a minimum capacity on",
    "start": "1996880",
    "end": "2003279"
  },
  {
    "text": "our cluster which is around 150 units and so you can see that after after that third bar we don't scale down any",
    "start": "2003279",
    "end": "2010120"
  },
  {
    "text": "further because we've hit our minimum capacity we want to make sure that we have some availability at all times",
    "start": "2010120",
    "end": "2016600"
  },
  {
    "text": "regardless of how much it's being used or not now the next bar this light purple",
    "start": "2016600",
    "end": "2022519"
  },
  {
    "text": "bar is an indication that some of our developers have submitted batch jobs or",
    "start": "2022519",
    "end": "2027960"
  },
  {
    "text": "seagull runs now the way that our seagull run process works is there's a whole bunch of steps that we have to go",
    "start": "2027960",
    "end": "2034279"
  },
  {
    "text": "through before the job can be scheduled onto our cluster so we build a bunch of",
    "start": "2034279",
    "end": "2039440"
  },
  {
    "text": "code we compile some things we compress some things down all of this stuff has to happen before we can start doing any",
    "start": "2039440",
    "end": "2046519"
  },
  {
    "text": "actual testing work on it and during that time we can check to see if our",
    "start": "2046519",
    "end": "2052158"
  },
  {
    "text": "cluster has enough capacity to be able to handle runs that are going to be coming so this blue or this light purple",
    "start": "2052159",
    "end": "2059240"
  },
  {
    "text": "Bar says hey some of our developers have triggered seagull runs do we have enough capacity they haven't been scheduled yet",
    "start": "2059240",
    "end": "2066079"
  },
  {
    "text": "do we have enough capacity to handle them in the next five minutes or so now the first time the purple the the",
    "start": "2066079",
    "end": "2074520"
  },
  {
    "text": "uh this purple bar shows up you can see that the cluster capacity doesn't change",
    "start": "2074520",
    "end": "2079720"
  },
  {
    "text": "and so what this means is that the signal said oh yeah we're not really doing very much on the cluster right now",
    "start": "2079720",
    "end": "2085358"
  },
  {
    "text": "we've got plenty of capacity to handle our batch jobs the second time that this purple",
    "start": "2085359",
    "end": "2091480"
  },
  {
    "text": "bar shows up that this signal fires we've already had a number of things scheduled on our cluster we're doing",
    "start": "2091480",
    "end": "2097118"
  },
  {
    "text": "some work and now it says oh we don't have enough capacity on our cluster to",
    "start": "2097119",
    "end": "2102839"
  },
  {
    "text": "be able to handle the incoming work so let's start scaling up now so that we don't impact the performance of these",
    "start": "2102839",
    "end": "2109079"
  },
  {
    "text": "incoming jobs the two green bars that are on the",
    "start": "2109079",
    "end": "2114200"
  },
  {
    "text": "very right hand side of this plot are our cluster overutilize signal I already talked about this on our last side it",
    "start": "2114200",
    "end": "2119920"
  },
  {
    "text": "says Hey we've got a lot of stuff going on on our cluster right now let's just scale up some more to make sure that we",
    "start": "2119920",
    "end": "2125320"
  },
  {
    "text": "can handle all of the work that we're trying to do and then finally I don't show this signal here but we do have a historical",
    "start": "2125320",
    "end": "2132880"
  },
  {
    "text": "usage signal we track the usage and the size of our cluster over the past month",
    "start": "2132880",
    "end": "2139599"
  },
  {
    "text": "and we can tell that oh every fourth Thursday there's a uh emergency build",
    "start": "2139599",
    "end": "2147280"
  },
  {
    "text": "that happens for example that we need to be able to scale up for um this isn't a",
    "start": "2147280",
    "end": "2152599"
  },
  {
    "text": "regular I mean it is a regular thing but it doesn't happen every week and so we have a signal that is able to track the",
    "start": "2152599",
    "end": "2158160"
  },
  {
    "text": "history and say hey it's the fourth Thursday of the month we don't have any",
    "start": "2158160",
    "end": "2164200"
  },
  {
    "text": "Capac or we don't have any jobs scheduled right now but based on our historical usage we know we're going to",
    "start": "2164200",
    "end": "2170079"
  },
  {
    "text": "need some and so we'll scale up anyways so this is how uh our cluster",
    "start": "2170079",
    "end": "2176880"
  },
  {
    "text": "scaling signals work what I want to do next is I want to talk about how we actually interface with our spot Fleet",
    "start": "2176880",
    "end": "2185359"
  },
  {
    "text": "cluster so there's two parts to this the first is how do we scale up and the second is how do we scale down let's",
    "start": "2185359",
    "end": "2191560"
  },
  {
    "text": "talk about scaling up first scaling up is quite straightforward when you create your",
    "start": "2191560",
    "end": "2198359"
  },
  {
    "start": "2195000",
    "end": "2195000"
  },
  {
    "text": "spot Fleet there's a parameter that's your allocation strategy and you've got a couple of options for that you can",
    "start": "2198359",
    "end": "2204520"
  },
  {
    "text": "choose a minimum price allocation so that whenever you add a new unit to your spot Fleet it tries to find the unit",
    "start": "2204520",
    "end": "2212440"
  },
  {
    "text": "that lowers your cost the most or you can choose the Diversified Strat",
    "start": "2212440",
    "end": "2218760"
  },
  {
    "text": "and as chunk talked about in his portion of the talk diversification is really really important uh it's more important",
    "start": "2218760",
    "end": "2225720"
  },
  {
    "text": "to us than making sure that we get the minimum price instance every single time and so we use the Diversified allocation",
    "start": "2225720",
    "end": "2234280"
  },
  {
    "text": "strategy now the way this works is suppose that Fleet meiser says a signal has fired and we want to add 48 units to",
    "start": "2234280",
    "end": "2242359"
  },
  {
    "text": "our cluster so all we do is we call call",
    "start": "2242359",
    "end": "2248599"
  },
  {
    "text": "the spot Fleet and we say modify the modify the fleet capacity and add 48",
    "start": "2248599",
    "end": "2254319"
  },
  {
    "text": "units because we've created our spot Fleet request with the Diversified allocation",
    "start": "2254319",
    "end": "2259720"
  },
  {
    "text": "strategy we don't have to do any additional work it will attempt to create new instances in all of our",
    "start": "2259720",
    "end": "2267000"
  },
  {
    "text": "different spot markets so in this example it might launch one instance with 16 units in each of uswest 2A",
    "start": "2267000",
    "end": "2274560"
  },
  {
    "text": "uswest 2B and US West 2C very very simple very",
    "start": "2274560",
    "end": "2280480"
  },
  {
    "text": "straightforward scaling down on the other hand is a little bit more complicated and the reason for this is",
    "start": "2280480",
    "end": "2287079"
  },
  {
    "start": "2282000",
    "end": "2282000"
  },
  {
    "text": "that we need to have very precise control over what instances get terminated we don't want to for example",
    "start": "2287079",
    "end": "2293920"
  },
  {
    "text": "terminate any instances that are currently doing work because this is going to impact our developers",
    "start": "2293920",
    "end": "2300160"
  },
  {
    "text": "productivity and then we're going to hear about it so the way that we do this let's",
    "start": "2300160",
    "end": "2305720"
  },
  {
    "text": "suppose that a signal has and said uh our cluster is not being used very much",
    "start": "2305720",
    "end": "2311720"
  },
  {
    "text": "so let's scale down so we want to terminate 48 units the first thing that we do is we",
    "start": "2311720",
    "end": "2319480"
  },
  {
    "text": "collect all of the instances in our cluster that are currently idle and",
    "start": "2319480",
    "end": "2324760"
  },
  {
    "text": "let's suppose that there are four instances in this case there are two instances in US West 2A one has 32 units",
    "start": "2324760",
    "end": "2331000"
  },
  {
    "text": "one has 16 units and then there's one idle instance in uswest 2B and one idle",
    "start": "2331000",
    "end": "2336240"
  },
  {
    "text": "instance in uswest 2C see with 16 units each so now the question is okay we're",
    "start": "2336240",
    "end": "2342640"
  },
  {
    "text": "going to kill some of these which ones do we kill again we want to maintain cluster",
    "start": "2342640",
    "end": "2349200"
  },
  {
    "text": "diversity we want to maintain it while we scale up and we want to maintain it while we scale down and there's",
    "start": "2349200",
    "end": "2355200"
  },
  {
    "text": "no Converse to the allocation strategy of when you scale down so we have to",
    "start": "2355200",
    "end": "2362599"
  },
  {
    "text": "actually figure out which instances to kill ourselves in order to maintain our our diversity",
    "start": "2362599",
    "end": "2368560"
  },
  {
    "text": "and so what do we do we look at the markets that currently have the most",
    "start": "2368560",
    "end": "2373800"
  },
  {
    "text": "number of units in them and so in this case suppose that Us West 2A is the",
    "start": "2373800",
    "end": "2379160"
  },
  {
    "text": "market that has the most number of units and we pick the instances to kill from that market first and so we might kill",
    "start": "2379160",
    "end": "2385319"
  },
  {
    "text": "the 32 unit instance in US West 2A",
    "start": "2385319",
    "end": "2390359"
  },
  {
    "text": "now our three Market our three markets that we're considering maybe they have an equal number of units we still need",
    "start": "2390359",
    "end": "2396839"
  },
  {
    "text": "to kill off 16 more units because that's what Fleet Meer requested and so at this point we just pick one arbitrarily and",
    "start": "2396839",
    "end": "2403079"
  },
  {
    "text": "so maybe we kill off this instance in US West 2C by doing this we're able to maintain",
    "start": "2403079",
    "end": "2409160"
  },
  {
    "text": "the diversity of our cluster as we scale up and as we scale down this next graph",
    "start": "2409160",
    "end": "2415160"
  },
  {
    "text": "is going to show a picture of this this is the same graph that chunky showed you earlier in the talk this shows the",
    "start": "2415160",
    "end": "2421359"
  },
  {
    "start": "2416000",
    "end": "2416000"
  },
  {
    "text": "number of units in our cluster each of the colored time series is a different spot market and the D line is the total",
    "start": "2421359",
    "end": "2428839"
  },
  {
    "text": "capacity of our cluster and you can see that at around 7",
    "start": "2428839",
    "end": "2434920"
  },
  {
    "text": "8 o00 we start scaling down and the number of units that we remove from each",
    "start": "2434920",
    "end": "2440880"
  },
  {
    "text": "of our different spot markets is roughly the same so as we scale down we maintain the",
    "start": "2440880",
    "end": "2448000"
  },
  {
    "text": "right or we maintain diversity across our Fleet in preparation for the next morning when we scale back up and you",
    "start": "2448000",
    "end": "2454200"
  },
  {
    "text": "can see as the scale up that the divers ification strategy is doing its",
    "start": "2454200",
    "end": "2461760"
  },
  {
    "text": "job now some of you might be aware that earlier this year Amazon released an",
    "start": "2461760",
    "end": "2467319"
  },
  {
    "start": "2464000",
    "end": "2464000"
  },
  {
    "text": "autoscaling feature for their spot fleets um this is something that as a part of your spot Fleet request you can",
    "start": "2467319",
    "end": "2474000"
  },
  {
    "text": "just go in and you can say I want to autoscale my fleet according to this policy um there's a link to the blog",
    "start": "2474000",
    "end": "2481280"
  },
  {
    "text": "post about that on our slide um which you can find after the talk but for right now I just want to talk about some",
    "start": "2481280",
    "end": "2487040"
  },
  {
    "text": "of the uh differences and similarities between Amazon's spot Fleet scaling",
    "start": "2487040",
    "end": "2493400"
  },
  {
    "text": "feature and our in-house fleeter scaling so first Amazon spot Fleet",
    "start": "2493400",
    "end": "2499560"
  },
  {
    "text": "scaling is driven by cloudwatch metrics so anything that you want to put into",
    "start": "2499560",
    "end": "2505119"
  },
  {
    "text": "Cloud watch you can alert on and use that as a trigger to scale your spot Fleet up and down and as we went through",
    "start": "2505119",
    "end": "2512440"
  },
  {
    "text": "earlier in the talk Fleet meiser uses these custom uh python scaling plugins",
    "start": "2512440",
    "end": "2517760"
  },
  {
    "text": "to determine the fleet capacity for the Amazon spot Fleet",
    "start": "2517760",
    "end": "2523599"
  },
  {
    "text": "scaling you can instruct your spot Fleet to scale by a constant amount so you can",
    "start": "2523599",
    "end": "2529319"
  },
  {
    "text": "say that when this metric fires you want to add 10 units 20 units whatever you",
    "start": "2529319",
    "end": "2535160"
  },
  {
    "text": "can scale by a percentage so you want to add 10% of your current cluster capacity",
    "start": "2535160",
    "end": "2540200"
  },
  {
    "text": "or you want to remove 15% of your current cluster capacity or you can scale by a step function so you can say",
    "start": "2540200",
    "end": "2547400"
  },
  {
    "text": "that if the value of your signal is between zero and 10 you want to add five",
    "start": "2547400",
    "end": "2552559"
  },
  {
    "text": "units if it's between 10 and 20 you want to add 15 units and if it's greater than",
    "start": "2552559",
    "end": "2557800"
  },
  {
    "text": "20 you want to add 50 units fleet meiser has a slightly more",
    "start": "2557800",
    "end": "2565520"
  },
  {
    "text": "flexible uh capability here you can scale by any arbitrary amount that you want to put in your python code so in",
    "start": "2565520",
    "end": "2572559"
  },
  {
    "text": "particular you can Scale based on some complicated function of your signal input we actually take advantage of this",
    "start": "2572559",
    "end": "2580160"
  },
  {
    "text": "when we use our batch job scaling we have to convert the number of batch jobs",
    "start": "2580160",
    "end": "2586200"
  },
  {
    "text": "into an expected number of units that we need and then we compare that to our",
    "start": "2586200",
    "end": "2591319"
  },
  {
    "text": "current cluster capacity uh to determine how much to scale",
    "start": "2591319",
    "end": "2597079"
  },
  {
    "text": "up the big reason why we are continuing to remain with fleeter for the time",
    "start": "2597200",
    "end": "2602280"
  },
  {
    "text": "being is that the Amazon spot Fleet scaling doesn't give you the capab ability to control how you scale down",
    "start": "2602280",
    "end": "2609480"
  },
  {
    "text": "you can scale down but we can't say something like don't kill off instances",
    "start": "2609480",
    "end": "2614640"
  },
  {
    "text": "that are currently doing work and this is really really important to us and as you saw in Fleet meiser you can actually",
    "start": "2614640",
    "end": "2621359"
  },
  {
    "text": "specify what instances specifically you want to kill off so if you're going to use spot Fleet",
    "start": "2621359",
    "end": "2629520"
  },
  {
    "text": "or maybe you're using spot Fleet right now and you want to start autoscaling I definitely recommend that",
    "start": "2629520",
    "end": "2635800"
  },
  {
    "text": "you use that you start off with the Amazon spot Fleet feature or the Amazon spot Fleet scaling feature uh this is a",
    "start": "2635800",
    "end": "2642880"
  },
  {
    "text": "really easy way to get your cluster Auto scaling it uses a lot of technologies that I'm sure you're already using in",
    "start": "2642880",
    "end": "2649240"
  },
  {
    "text": "cloudwatch however if you need any very sophisticated scaling logic such as what",
    "start": "2649240",
    "end": "2655760"
  },
  {
    "text": "we use in Fleet meiser then it might be time for you to start thinking about building something in",
    "start": "2655760",
    "end": "2662520"
  },
  {
    "text": "house so this is everything that I want to talk about with respect to the current state of seagull and with Fleet",
    "start": "2662599",
    "end": "2669559"
  },
  {
    "text": "meiser I want to spend the last few minutes of our talk discussing what are some future goals and challenges that we",
    "start": "2669559",
    "end": "2676880"
  },
  {
    "text": "hope to overcome with uh these products so one goal that we have we",
    "start": "2676880",
    "end": "2683240"
  },
  {
    "start": "2680000",
    "end": "2680000"
  },
  {
    "text": "would like to diversify our spot markets even further as chunky mentioned we're doing",
    "start": "2683240",
    "end": "2688359"
  },
  {
    "text": "a lot of photo classification work and so maybe we want to start adding in some",
    "start": "2688359",
    "end": "2693680"
  },
  {
    "text": "GPU instances to be able to handle that photo classif ific those photo classification",
    "start": "2693680",
    "end": "2700359"
  },
  {
    "text": "jobs we also would really really like to start using some of the larger instance types for example the X1 32x large has",
    "start": "2700359",
    "end": "2708119"
  },
  {
    "text": "the capability of scheduling 53 simultaneous bundles at the same time",
    "start": "2708119",
    "end": "2715040"
  },
  {
    "text": "and we actually had the X1 32x large in our cluster for a while and it was",
    "start": "2715040",
    "end": "2720640"
  },
  {
    "text": "really cool we were able to do a lot of work on it the problem that we had is that each one of those 53",
    "start": "2720640",
    "end": "2727599"
  },
  {
    "text": "bundles was talking to a single instance of a Docker Damon uh each bundle spins",
    "start": "2727599",
    "end": "2733400"
  },
  {
    "text": "up a bunch of Docker containers and when you have 53 of them talking to",
    "start": "2733400",
    "end": "2739359"
  },
  {
    "text": "one Docker Damon on one host then everything kind of goes haywire and it",
    "start": "2739359",
    "end": "2744960"
  },
  {
    "text": "turned out that x132 x large just ate Docker and so we are not actually using",
    "start": "2744960",
    "end": "2750240"
  },
  {
    "text": "x132 x large right now but we are trying to figure out how can we make it how can",
    "start": "2750240",
    "end": "2755960"
  },
  {
    "text": "we make our bu talk with Docker in a better way so that we can get this instance back in our cluster because it",
    "start": "2755960",
    "end": "2761960"
  },
  {
    "text": "was really cool another goal that we would really like to add in to Fleet meiser is we'd",
    "start": "2761960",
    "end": "2768200"
  },
  {
    "start": "2764000",
    "end": "2764000"
  },
  {
    "text": "like to be able to combine and control multiple different spot fleets",
    "start": "2768200",
    "end": "2773760"
  },
  {
    "text": "and autoscaling groups all as the part of the same cluster so you might have an application where you want to have some",
    "start": "2773760",
    "end": "2780079"
  },
  {
    "text": "minimum capacity that's always available maybe you want that on demand or reserved instance or whatever",
    "start": "2780079",
    "end": "2787680"
  },
  {
    "text": "and then you have two or three different spot Fleet requests that you want to also control we have a few situations",
    "start": "2787680",
    "end": "2793880"
  },
  {
    "text": "where we'd like to be able to do functionality like this and right now Fleet Meer doesn't have the capability to do this so this is something that we",
    "start": "2793880",
    "end": "2799680"
  },
  {
    "text": "would really like to add in another goal that we're going to be",
    "start": "2799680",
    "end": "2805280"
  },
  {
    "text": "working on is how can we extend the scale down logic in Fleet meiser so if you recall in the example",
    "start": "2805280",
    "end": "2812599"
  },
  {
    "text": "that I showed you before we first we kill off the 32 unit instance which is",
    "start": "2812599",
    "end": "2817920"
  },
  {
    "text": "just fine this allows us to maintain diversity but then I said we pick the",
    "start": "2817920",
    "end": "2823280"
  },
  {
    "text": "next instances to kill off somewhat arbitrarily and maybe we'd like to do something a little bit more intelligent",
    "start": "2823280",
    "end": "2829319"
  },
  {
    "text": "for example looking at the cost of the various instances so you can see here maybe at",
    "start": "2829319",
    "end": "2836200"
  },
  {
    "text": "this point in time the instances in uswest 2A and US West 2B are currently",
    "start": "2836200",
    "end": "2842040"
  },
  {
    "text": "more expensive than the instance in uswest 2C in the old example if we",
    "start": "2842040",
    "end": "2847280"
  },
  {
    "text": "killed off the instance in US West 2C then we'd be paying more than if we killed off one of the instances in US",
    "start": "2847280",
    "end": "2853559"
  },
  {
    "text": "West 2A or 2B and so maybe we can start taking advantage of some pricing information into uh our scal down logic",
    "start": "2853559",
    "end": "2861480"
  },
  {
    "text": "so that we can actually kill off instances that are costing us more",
    "start": "2861480",
    "end": "2866440"
  },
  {
    "text": "money the last goll that uh I'm really excited about this is a project that",
    "start": "2866920",
    "end": "2872200"
  },
  {
    "start": "2868000",
    "end": "2868000"
  },
  {
    "text": "I've been working on and will be continuing to work on through the next year is is to actually figure out better",
    "start": "2872200",
    "end": "2879480"
  },
  {
    "text": "ways to schedule our tasks onto seagull this will allow us to take better advantage of the resources that we have",
    "start": "2879480",
    "end": "2887119"
  },
  {
    "text": "as a part of our AWS spot Fleet cluster and so what does this look like I'm just",
    "start": "2887119",
    "end": "2892200"
  },
  {
    "text": "going to give you a brief highlight about it and then maybe I'll come back here next year and I can talk about all the cool stuff that I've done but the",
    "start": "2892200",
    "end": "2898440"
  },
  {
    "text": "idea is pretty simple we have a bunch of tasks they have various resource requirements so maybe task a needs 100",
    "start": "2898440",
    "end": "2905240"
  },
  {
    "text": "Megs of ram it needs 3 CPUs and maybe it has dependencies on some various services so it calls out to you know",
    "start": "2905240",
    "end": "2912760"
  },
  {
    "text": "Dynamo DB maybe it calls out to some other external apis or some internal services at",
    "start": "2912760",
    "end": "2918200"
  },
  {
    "text": "Yelp we have another task that has many fewer resources it only needs 10 meges of ram it only needs one CPU and it has",
    "start": "2918200",
    "end": "2925599"
  },
  {
    "text": "a different set of service requirements what we'd like to be able to do is group tasks together in a way",
    "start": "2925599",
    "end": "2934799"
  },
  {
    "text": "that combines the resource requirements and the service requirements so in this",
    "start": "2934799",
    "end": "2940400"
  },
  {
    "text": "example maybe host one is a host that has a lot of CPUs available to it it has a lot of memory",
    "start": "2940400",
    "end": "2946559"
  },
  {
    "text": "available and so we schedule our more resource intensive tasks on that host",
    "start": "2946559",
    "end": "2952079"
  },
  {
    "text": "and we also try to schedule tasks that depend on similar Services together and",
    "start": "2952079",
    "end": "2957880"
  },
  {
    "text": "then here we have host 2 maybe it has a smaller uh number of resources and so we",
    "start": "2957880",
    "end": "2963319"
  },
  {
    "text": "schedule tasks that don't have as high of resource requirement and again we're trying to group by various services and",
    "start": "2963319",
    "end": "2970799"
  },
  {
    "text": "the hope is that this will allow us to schedule more stuff on our existing",
    "start": "2970799",
    "end": "2977160"
  },
  {
    "text": "cluster so that we can do more work with the same amount of resources and then",
    "start": "2977160",
    "end": "2983680"
  },
  {
    "text": "leverage even further the uh spot Fleet cluster that we have so in conclusion I just like to",
    "start": "2983680",
    "end": "2991079"
  },
  {
    "text": "give you yelp's simple mantra for saving money on your compute costs first thing to do you need to make",
    "start": "2991079",
    "end": "2997559"
  },
  {
    "start": "2992000",
    "end": "2992000"
  },
  {
    "text": "sure you have a fault tolerant application as chunky talked about you need to have application Level fault tolerance because you don't know when",
    "start": "2997559",
    "end": "3003559"
  },
  {
    "text": "instances might get taken away from you and you also want to make sure that you have cluster level fault tolerance",
    "start": "3003559",
    "end": "3009000"
  },
  {
    "text": "cluster level fault tolerance just means diversification second thing if you know",
    "start": "3009000",
    "end": "3015839"
  },
  {
    "text": "that your uh application or your use is very volatile you might want to consider",
    "start": "3015839",
    "end": "3021960"
  },
  {
    "text": "using some sort of an autoscaling engine whether this is the engine that's provided by Amazon or if you need",
    "start": "3021960",
    "end": "3027720"
  },
  {
    "text": "something a little bit more complex and you need to come up with something inhouse uh but this these two features",
    "start": "3027720",
    "end": "3033920"
  },
  {
    "text": "will allow you to save a lot of money on your compute costs if you'd like to find out any more information about the stuff",
    "start": "3033920",
    "end": "3040280"
  },
  {
    "text": "that we're working on whether it's seagull or Fleet meiser or anything else you can follow us on Facebook and",
    "start": "3040280",
    "end": "3045920"
  },
  {
    "text": "Twitter we have an engineering blog where we regularly release information about products that we're working on and",
    "start": "3045920",
    "end": "3052640"
  },
  {
    "text": "we also maintain a lot of Open Source Code which you can find on GitHub so that is everything we have to talk",
    "start": "3052640",
    "end": "3058720"
  },
  {
    "text": "about thank you very much and please remember to complete your [Applause]",
    "start": "3058720",
    "end": "3065480"
  },
  {
    "text": "evaluations",
    "start": "3065480",
    "end": "3068480"
  }
]
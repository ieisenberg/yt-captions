[
  {
    "start": "0",
    "end": "33000"
  },
  {
    "text": "thank you very much for coming along today what I'm going to talk about today",
    "start": "3960",
    "end": "8969"
  },
  {
    "text": "is well logging originally this track or this session was called log analysis at",
    "start": "8969",
    "end": "16080"
  },
  {
    "text": "scale but then as I sat down and started to write my content and think about how I wanted to approach this I realized",
    "start": "16080",
    "end": "23279"
  },
  {
    "text": "that before even getting to the analysis stage it's really there's a lot to do so",
    "start": "23279",
    "end": "29070"
  },
  {
    "text": "what I want to do today is I want to talk about logging at scale now logging",
    "start": "29070",
    "end": "34290"
  },
  {
    "start": "33000",
    "end": "78000"
  },
  {
    "text": "is difficult and I knew this when I started because my background is building big platforms and I kind of",
    "start": "34290",
    "end": "40109"
  },
  {
    "text": "knew this so i thought i knew this but when I actually sat down and thought about it and I thought about the scale",
    "start": "40109",
    "end": "46589"
  },
  {
    "text": "at which you have to operate it it's incredible so when we build platforms",
    "start": "46589",
    "end": "52170"
  },
  {
    "text": "that go from no users to within five minutes it goes up to 80,000 requests per second the platforms that you need",
    "start": "52170",
    "end": "59820"
  },
  {
    "text": "to build to actually manage this kind of infrastructure are incredible because",
    "start": "59820",
    "end": "65040"
  },
  {
    "text": "you have to take this data in if you're working in somewhere where this very logging data will actually affect your",
    "start": "65040",
    "end": "72240"
  },
  {
    "text": "ability to build your customers you can't simply just go okay well I'll discard half the messages but it really",
    "start": "72240",
    "end": "79799"
  },
  {
    "text": "is difficult to capture process store and deal with this volume of data",
    "start": "79799",
    "end": "84829"
  },
  {
    "text": "reliably time and time again we can break these problems or these",
    "start": "84829",
    "end": "90270"
  },
  {
    "text": "opportunities into four major areas first of all you need to store them temporarily somewhere you need to then",
    "start": "90270",
    "end": "96450"
  },
  {
    "text": "capture them off those instances you need to permanently Lee have somewhere",
    "start": "96450",
    "end": "101820"
  },
  {
    "text": "for those to live and finally you need to be able to visualize or actually address that log data in the interest of",
    "start": "101820",
    "end": "110549"
  },
  {
    "text": "scaling myself I've decided to steal a large amount of content this is joel",
    "start": "110549",
    "end": "115590"
  },
  {
    "text": "williams a solutions architect for amazon web services based out of the us at our global conference reinvent he",
    "start": "115590",
    "end": "122429"
  },
  {
    "text": "talked about scaling to your first 10 million users i recommend anybody have a look at that if you're building large",
    "start": "122429",
    "end": "127829"
  },
  {
    "text": "platforms I provided a bitly link to the talk there which is hosted on YouTube what he talks about there is the ability",
    "start": "127829",
    "end": "135000"
  },
  {
    "text": "to grow every component of your architecture often your architecture your platform when you",
    "start": "135000",
    "end": "141250"
  },
  {
    "text": "are one user or around one user will start out looking a lot like this it's a very simple single server setup maybe",
    "start": "141250",
    "end": "149080"
  },
  {
    "text": "you use amazon route 53 maybe you have a single elastic IP address but you have",
    "start": "149080",
    "end": "154540"
  },
  {
    "text": "everything on one instance you have your database server your web server your application server all in one instance",
    "start": "154540",
    "end": "160590"
  },
  {
    "text": "so with one place one instance it's a single place to read logs from and with",
    "start": "160590",
    "end": "167290"
  },
  {
    "text": "a single place to read logs from you can get away with a lot so my background is",
    "start": "167290",
    "end": "173320"
  },
  {
    "text": "bad shell scripting and if you look at some of the things that you tend to write in your history it'll be things",
    "start": "173320",
    "end": "179050"
  },
  {
    "text": "that my ex-colleagues some of whom are here today will call Alex Jes hacks these are hack together bits of all",
    "start": "179050",
    "end": "185020"
  },
  {
    "text": "congrats and pearl that eventually get you in sight like it's very common with Apache to see what are my top URLs or",
    "start": "185020",
    "end": "191970"
  },
  {
    "text": "what's the most common HTTP response code or my top user agents now all of",
    "start": "191970",
    "end": "197950"
  },
  {
    "text": "these are very easy for you to fetch in because you're only dealing with one server hey you could even write a little",
    "start": "197950",
    "end": "203410"
  },
  {
    "text": "more complex bit of pearl and look at request lines per second this is easy when you have only one server to deal",
    "start": "203410",
    "end": "209230"
  },
  {
    "text": "with or in fact with a couple of servers cluster SSH a bunch of terminals you",
    "start": "209230",
    "end": "215140"
  },
  {
    "text": "look a little bit like the movie hackers and it works but when it comes to dealing with larger infrastructures or",
    "start": "215140",
    "end": "221290"
  },
  {
    "text": "real life it's never that easy because the the architectures tend to look like",
    "start": "221290",
    "end": "226630"
  },
  {
    "text": "this and that's true whether you're dealing with the million users or whether you're dealing with one user so",
    "start": "226630",
    "end": "233230"
  },
  {
    "text": "when you go back to your simple architecture you think wow I could use all those hacks there it works really well you can't when it comes to the",
    "start": "233230",
    "end": "239830"
  },
  {
    "text": "actual production and this is true whether you're dealing with a million users or even 10,000 because as your",
    "start": "239830",
    "end": "245890"
  },
  {
    "text": "architecture as your platform becomes more complex you spend more time building these disparate systems and",
    "start": "245890",
    "end": "252640"
  },
  {
    "text": "that's more data that you then need to evaluate and all of this is at the server level we're not even thinking",
    "start": "252640",
    "end": "258820"
  },
  {
    "text": "about the users themselves if you're dealing on a video on demand site or a social network or anything in fact",
    "start": "258820",
    "end": "264970"
  },
  {
    "text": "within mobile application or a website you're getting norma's amounts of data in from the",
    "start": "264970",
    "end": "270970"
  },
  {
    "text": "clients itself are you actually capturing these because we can't ignore that so with all these different bits to",
    "start": "270970",
    "end": "277570"
  },
  {
    "text": "bring into the platform we end up with these problems now I hope to walk",
    "start": "277570",
    "end": "282910"
  },
  {
    "text": "through various different ways for us to deal with the problems and unlock a simple piece of insight from each of",
    "start": "282910",
    "end": "288190"
  },
  {
    "text": "them so I'm going to start with the temporary storage now what I mean by that is when the logs are actually",
    "start": "288190",
    "end": "295660"
  },
  {
    "text": "written you've got a few different options here because your application could just write it straight out over to",
    "start": "295660",
    "end": "302260"
  },
  {
    "text": "the network you can temporarily stage it to a local disk and there you have a",
    "start": "302260",
    "end": "307270"
  },
  {
    "text": "couple of options about how you actually address that in amazon web services you",
    "start": "307270",
    "end": "312520"
  },
  {
    "text": "have ephemeral volumes these are very low cost because they are free they do",
    "start": "312520",
    "end": "317830"
  },
  {
    "text": "not persist across reboots but they are directly attached this allows you to very quickly write gigabytes of log",
    "start": "317830",
    "end": "324580"
  },
  {
    "text": "files however in the event of the loss of a system then you lose your data if you're working in banking or anything",
    "start": "324580",
    "end": "331780"
  },
  {
    "text": "where forensic data will be required this wouldn't work for your kind of use cases so to get around that we have the",
    "start": "331780",
    "end": "337960"
  },
  {
    "text": "elastic block store which I hope given this is a 300-level track many of you are familiar with now this has a range",
    "start": "337960",
    "end": "343870"
  },
  {
    "text": "of different storage options by default many people will go with gp2 or general-purpose disks but we recently at",
    "start": "343870",
    "end": "351340"
  },
  {
    "text": "the Chicago summit a couple of weeks ago announced a new form of magnetic hard",
    "start": "351340",
    "end": "356349"
  },
  {
    "text": "drive called the st1 or SC 1 depending on your warmness level this gives you",
    "start": "356349",
    "end": "362050"
  },
  {
    "text": "the ability to do much higher megabytes per second at lower I ops meaning actually for things like logging this is",
    "start": "362050",
    "end": "368590"
  },
  {
    "text": "ideal so I recommend when we look at where your for temporarily storing your logs actually looking at an EBS volume",
    "start": "368590",
    "end": "375460"
  },
  {
    "text": "but some of the cheaper options there may well be the right choice there's nothing to say in an application you",
    "start": "375460",
    "end": "380979"
  },
  {
    "text": "can't immediately right over that network but if you're using something like a UDP transports keep in mind that",
    "start": "380979",
    "end": "386979"
  },
  {
    "text": "that is inherently unreliable and if you're relying on this data for billing keeping a copy of the log file somewhere",
    "start": "386979",
    "end": "392770"
  },
  {
    "text": "locally where you can be recovered is very important so now we've addressed",
    "start": "392770",
    "end": "398409"
  },
  {
    "text": "the storage we need to think about how we actually get these off the in distances themselves so I was going to",
    "start": "398409",
    "end": "404530"
  },
  {
    "text": "talk about capture now but first I want to get the thing somewhere to live and then I'll walk through the capture and",
    "start": "404530",
    "end": "410650"
  },
  {
    "text": "how to get it over there this will have a few live demos just before all you",
    "start": "410650",
    "end": "415870"
  },
  {
    "text": "guys came in my internet worked fine then you guys came in and it stopped working fine so I'm a little bit nervous",
    "start": "415870",
    "end": "421030"
  },
  {
    "text": "now but it's okay because what I'm going to talk about here is the problems of persistence and by that point it should",
    "start": "421030",
    "end": "426700"
  },
  {
    "text": "all be okay so there's three main issues with persistence and in this context the",
    "start": "426700",
    "end": "432130"
  },
  {
    "text": "persistence of logs first of all it's somewhere to stage those locks now when",
    "start": "432130",
    "end": "438220"
  },
  {
    "text": "we think about staging it's the temporary storage place it's the here it lives before I actually process it off",
    "start": "438220",
    "end": "444550"
  },
  {
    "text": "the instance but before its final resting place I need the final resting place itself and that needs to be",
    "start": "444550",
    "end": "452110"
  },
  {
    "text": "scalable it needs to be accessible it needs to be the kind of thing that I can",
    "start": "452110",
    "end": "457300"
  },
  {
    "text": "grow as my platform growth and finally I need a way to search my data it's no use",
    "start": "457300",
    "end": "463120"
  },
  {
    "text": "having terabytes of log files in tapes in a warehouse because I don't have any",
    "start": "463120",
    "end": "469180"
  },
  {
    "text": "access to that data now many of you be could be looking at this and thinking well surely that's a really good fit to",
    "start": "469180",
    "end": "476080"
  },
  {
    "text": "a no sequel database and I'm back to stealing content from the architecture talk here well some phones won't like",
    "start": "476080",
    "end": "483310"
  },
  {
    "start": "481000",
    "end": "800000"
  },
  {
    "text": "this approach but start with sequel databases even npp sequel databases like",
    "start": "483310",
    "end": "489130"
  },
  {
    "text": "red shift and as a good reason for this well sequel is incredibly well established there's tool chains that",
    "start": "489130",
    "end": "495910"
  },
  {
    "text": "exist for it there's a huge amount of knowledge available on the internet or even in your teams today in the best way",
    "start": "495910",
    "end": "501820"
  },
  {
    "text": "to manage and build schemas for sequel databases and to be frank unless you are",
    "start": "501820",
    "end": "507669"
  },
  {
    "text": "doing incredibly strange things with your data you aren't going to break a sequel database in your first 10 million users and of course because this is very",
    "start": "507669",
    "end": "515140"
  },
  {
    "text": "established it's easy to scale big this may be through things like sharding",
    "start": "515140",
    "end": "520240"
  },
  {
    "text": "which fit incredibly well into an analytic sweet now there's a small caveat here which is sometimes I'm",
    "start": "520240",
    "end": "526330"
  },
  {
    "text": "looking outside of logging but sometimes a no sequel database is the right choice and that may be where you have",
    "start": "526330",
    "end": "533190"
  },
  {
    "text": "things that you were doing very strangely with the data or its data which is so unrelated it doesn't",
    "start": "533190",
    "end": "538920"
  },
  {
    "text": "actually have any reason to sit within that constraint or if you have massive amounts of data to process now at this",
    "start": "538920",
    "end": "546060"
  },
  {
    "text": "point people often go aha you said the word massive I have huge amounts of data now let's think about what you actually",
    "start": "546060",
    "end": "552390"
  },
  {
    "text": "mean by huge amounts of data because in a no sequel database you end up having",
    "start": "552390",
    "end": "557820"
  },
  {
    "text": "to manage many many more components of a platform that you may not be familiar with now within things like red shift",
    "start": "557820",
    "end": "565350"
  },
  {
    "text": "our NPP datas warehouse you can scale to petabytes of storage so don't get too",
    "start": "565350",
    "end": "571740"
  },
  {
    "text": "worried about the size of your data today think about this path to scalability because if you look at the",
    "start": "571740",
    "end": "578190"
  },
  {
    "text": "reasons for no sequel super low latency applications which don't apply to log in",
    "start": "578190",
    "end": "583860"
  },
  {
    "text": "jest meta very meta data driven not so much here either and your data tends to",
    "start": "583860",
    "end": "589290"
  },
  {
    "text": "have relationships so ruling those out where you need scheme lyst constructs",
    "start": "589290",
    "end": "594780"
  },
  {
    "text": "where you need to ingest large amounts of data where you need to do that quickly that can still be done through",
    "start": "594780",
    "end": "600540"
  },
  {
    "text": "different services which amazon offer today so let's look again at these three",
    "start": "600540",
    "end": "607980"
  },
  {
    "text": "areas of persistence and break them down one by one and I'll map an Amazon component to it and we can talk about",
    "start": "607980",
    "end": "614370"
  },
  {
    "text": "and maybe even set up internet connection willing that's a particular service so let's start with the actual",
    "start": "614370",
    "end": "622290"
  },
  {
    "text": "architecture of log dispatcher because you do need somewhere for the logs to actually be staged today I'm going to",
    "start": "622290",
    "end": "628320"
  },
  {
    "text": "talk very specifically about the Kinesis firehose section of this infrastructure so on your instances you may have a",
    "start": "628320",
    "end": "635430"
  },
  {
    "text": "dispatcher blog stash folder or or an agent which sends those logs off but they need somewhere to live so in this",
    "start": "635430",
    "end": "642300"
  },
  {
    "text": "architecture I've talks about the app server sending to canisius fios but at that point the logs still need somewhere",
    "start": "642300",
    "end": "648750"
  },
  {
    "text": "to be staged s3 is the simple storage service from amazon it scales to",
    "start": "648750",
    "end": "654390"
  },
  {
    "text": "virtually unlimited amounts of storage very easily and you only pay for the storage use it also has support for AWS",
    "start": "654390",
    "end": "661530"
  },
  {
    "text": "lambda which is talked about in the very next taught by Marco the event-driven",
    "start": "661530",
    "end": "666660"
  },
  {
    "text": "computing nature of lambda allows you to do operations as files come in this means",
    "start": "666660",
    "end": "671770"
  },
  {
    "text": "that you no longer need to worry about watch folders or long-running batch jobs that just pick up files as they come in",
    "start": "671770",
    "end": "677290"
  },
  {
    "text": "this is automated for you and s3 is fantastically integrated with services",
    "start": "677290",
    "end": "682690"
  },
  {
    "text": "like redshift services like firehouse so this makes your life easier as you're building a storage driven architecture",
    "start": "682690",
    "end": "689880"
  },
  {
    "text": "so I'm going to assume s3 is my staging area so my next option is somewhere to live and specifically somewhere for the",
    "start": "689880",
    "end": "696370"
  },
  {
    "text": "long tail to live and this is where redshift comes in red shift is a",
    "start": "696370",
    "end": "701830"
  },
  {
    "text": "petabyte scale data warehouse it can scale to a quarter of an exabyte this is",
    "start": "701830",
    "end": "707560"
  },
  {
    "text": "a the lowest price point for a large scale data warehouse this is also",
    "start": "707560",
    "end": "712900"
  },
  {
    "text": "postgres based this means that you can continue to use many of the business intelligence tools that you're familiar",
    "start": "712900",
    "end": "717970"
  },
  {
    "text": "with today and your data scientist your data engineers can continue to use a lot of the platforms that they have already",
    "start": "717970",
    "end": "724420"
  },
  {
    "text": "grown their career through we give you a choice of nodes depending on your workload type sometimes it's very dense",
    "start": "724420",
    "end": "730810"
  },
  {
    "text": "compute you need to process a lot sometimes it's very dense storage when actually you have more things that need to live cold and this can ingest from s3",
    "start": "730810",
    "end": "739390"
  },
  {
    "text": "whether that's stored in CSV or JSON or any other form so now I've decided where",
    "start": "739390",
    "end": "745330"
  },
  {
    "text": "it's going to live I need an index I need some way to search it and this is",
    "start": "745330",
    "end": "750430"
  },
  {
    "text": "what I'm going to talk about elasticsearch so elastic search ALK is a",
    "start": "750430",
    "end": "756100"
  },
  {
    "text": "very common choice when it comes to logging elastic search service was",
    "start": "756100",
    "end": "762310"
  },
  {
    "text": "offered last year at reinvent it allows you to very easily run an elastic search",
    "start": "762310",
    "end": "767650"
  },
  {
    "text": "cluster on AWS much like RDS the relational database service we take care",
    "start": "767650",
    "end": "773200"
  },
  {
    "text": "of the installation management and upkeep of an elastic search cluster we",
    "start": "773200",
    "end": "778210"
  },
  {
    "text": "also prepackaged it with cabana for visualizations we integrate it with I am",
    "start": "778210",
    "end": "783940"
  },
  {
    "text": "roles to make it more simple for you to manage and control access inbound to your platform and it has built-in",
    "start": "783940",
    "end": "789580"
  },
  {
    "text": "support for things like Kinesis fire hose for the actual data loading in the first place so with all three of those",
    "start": "789580",
    "end": "795940"
  },
  {
    "text": "problems hopefully addressed by one of these services now I'm going to actually theoretically very quickly demonstrate",
    "start": "795940",
    "end": "802980"
  },
  {
    "start": "800000",
    "end": "1015000"
  },
  {
    "text": "the setup of elastic search service itself so to do this I'm going to switch",
    "start": "802980",
    "end": "808529"
  },
  {
    "text": "over to a browser window there we go for",
    "start": "808529",
    "end": "818970"
  },
  {
    "text": "those of you familiar this was the AWS console may look a little bit different yes this is the AWS console as of today",
    "start": "818970",
    "end": "826130"
  },
  {
    "text": "you can see I've already created one elasticsearch service cluster but this I'm going to create a new domain to",
    "start": "826130",
    "end": "832649"
  },
  {
    "text": "allow us to just run through this demo it's very much as simple as creating your domain choosing some of the",
    "start": "832649",
    "end": "839190"
  },
  {
    "text": "characteristics about it and provisioning we allow you to predetermine the size of your cluster if",
    "start": "839190",
    "end": "845160"
  },
  {
    "text": "you know you're going to be loading a lot of data in upfront or alternatively you can change the size of a cluster",
    "start": "845160",
    "end": "850860"
  },
  {
    "text": "after its provisioned depending on your change your very data as time goes on so",
    "start": "850860",
    "end": "857010"
  },
  {
    "text": "by default I'm just going to leave this as a single instance however there's a couple of things I want to draw your attention to elasticsearch allows you to",
    "start": "857010",
    "end": "864300"
  },
  {
    "text": "have a dedicated master which we recommend for production deployments this offloads a large amount of the",
    "start": "864300",
    "end": "870089"
  },
  {
    "text": "processing onto a separate section of the cluster for instance helping you with visualization section we also have",
    "start": "870089",
    "end": "876870"
  },
  {
    "text": "zone awareness zone awareness means that you can use the same model of availability zones the same model of",
    "start": "876870",
    "end": "882089"
  },
  {
    "text": "high availability that we have in all of the other amazon components you do need to take this into account when you're",
    "start": "882089",
    "end": "887819"
  },
  {
    "text": "building your elasticsearch compatible applications but for things like fire hose it's dealt with automatically so",
    "start": "887819",
    "end": "895079"
  },
  {
    "text": "with that I will skip through very quickly and just talk about the access policies I said one of the best bits was",
    "start": "895079",
    "end": "900899"
  },
  {
    "text": "how I am access is built in which is fantastic so what I can actually do is I can just say allow access to my AWS",
    "start": "900899",
    "end": "908399"
  },
  {
    "text": "account i can add my account ID in here and it pre generates an access policy",
    "start": "908399",
    "end": "914880"
  },
  {
    "text": "for me to allow me to actually control access in there and only restricted from",
    "start": "914880",
    "end": "920250"
  },
  {
    "text": "my account now what I can also do is if I wanted more public access to say",
    "start": "920250",
    "end": "925920"
  },
  {
    "text": "cabana the visualization front-end I can modify that policy",
    "start": "925920",
    "end": "932730"
  },
  {
    "text": "to my principal my god I can modify that",
    "start": "932730",
    "end": "940920"
  },
  {
    "text": "policy to have multiple statements in this case the first of which allows access to access from the I am address",
    "start": "940920",
    "end": "948209"
  },
  {
    "text": "and then a second one access from the IP address I can mix and match this and it",
    "start": "948209",
    "end": "953519"
  },
  {
    "text": "means that I can integrate non IAM compatible components of a platform which allows backwards compatibility",
    "start": "953519",
    "end": "959040"
  },
  {
    "text": "with things like on-premise so with that I've determined the size of my cluster I've created my instances I've created",
    "start": "959040",
    "end": "965820"
  },
  {
    "text": "my zones so I'm going to press confirm and create I've hit my account limits",
    "start": "965820",
    "end": "972089"
  },
  {
    "text": "because I didn't set this up properly so what I will now do is I will talk about the one I created earlier as I always do",
    "start": "972089",
    "end": "978029"
  },
  {
    "text": "in a blue peter cell way so the one who created earlier thank you good timing on",
    "start": "978029",
    "end": "985560"
  },
  {
    "text": "the laughter there the one I created earlier is available here what I've got",
    "start": "985560",
    "end": "990630"
  },
  {
    "text": "here is this very similar domains the one I just walked through with the very same kind of access policy the only",
    "start": "990630",
    "end": "996240"
  },
  {
    "text": "difference is i'm already ingesting data into here so now I've got somewhere for my dates to actually come into so I'm",
    "start": "996240",
    "end": "1002600"
  },
  {
    "text": "going to switch back to my powerpoint I'm just going to talk about getting the data there in the first place",
    "start": "1002600",
    "end": "1008380"
  },
  {
    "start": "1015000",
    "end": "1093000"
  },
  {
    "text": "now once the data actually comes in and for the purpose of this demo I'm going to always use apache log files a very",
    "start": "1015540",
    "end": "1022270"
  },
  {
    "text": "easy and very common requirement when data comes in to elasticsearch we treat",
    "start": "1022270",
    "end": "1027370"
  },
  {
    "text": "it as a time series data now with this we need to be able to analyze the date",
    "start": "1027370",
    "end": "1032949"
  },
  {
    "text": "format and the other components of that so I just want to highlight a couple of things about elasticsearch mappings or",
    "start": "1032949",
    "end": "1039610"
  },
  {
    "text": "types these are ways that we pass the incoming data and actually evaluate it within our index now what you can see",
    "start": "1039610",
    "end": "1046780"
  },
  {
    "text": "here is I've isolated the date and I've also isolated the user agent there's two",
    "start": "1046780",
    "end": "1052750"
  },
  {
    "text": "things I want to raise them first of all if you're processing this in a real world scenario you're using the same",
    "start": "1052750",
    "end": "1058780"
  },
  {
    "text": "kind of setup I'm talking about please make sure that you actually pass your date time properly if it comes in as a",
    "start": "1058780",
    "end": "1064990"
  },
  {
    "text": "string you can't treat it like a filter or treat it like a searchable fault searchable of field secondly when data",
    "start": "1064990",
    "end": "1072520"
  },
  {
    "text": "comes in to elasticsearch by default it's run through a parser separates into different English words if you intend to",
    "start": "1072520",
    "end": "1078850"
  },
  {
    "text": "use things as a filter on user agents on paths on anything like that it doesn't work well you can individually set the",
    "start": "1078850",
    "end": "1084910"
  },
  {
    "text": "fields to not be analyzed so when you create your mapping please do keep this in mind I believe these slides will be",
    "start": "1084910",
    "end": "1090880"
  },
  {
    "text": "shared afterwards so just have a look at those so with now I've got somewhere to store my data I actually need to get it",
    "start": "1090880",
    "end": "1097360"
  },
  {
    "start": "1093000",
    "end": "1236000"
  },
  {
    "text": "off of the instance in the first place and how do I do that what's choice what",
    "start": "1097360",
    "end": "1102910"
  },
  {
    "text": "approach do I use so many of you will be familiar with things like the log stash forwarder or even building things into",
    "start": "1102910",
    "end": "1109809"
  },
  {
    "text": "your application going back to my logging architecture there's two components I'm going to talk about here",
    "start": "1109809",
    "end": "1115679"
  },
  {
    "text": "because there's two very difficult problems the first is sending data off of your instance reliably but the second",
    "start": "1115679",
    "end": "1122950"
  },
  {
    "text": "is having somewhere to send that data that can scale from zero to ten thousand requests per second in five seconds so",
    "start": "1122950",
    "end": "1131260"
  },
  {
    "text": "what I'm going to talk about is first of all amazon kinesis you may be familiar with the service a stream processing",
    "start": "1131260",
    "end": "1138429"
  },
  {
    "text": "service it allows you to very quickly scale to huge amounts of JSON objects in",
    "start": "1138429",
    "end": "1143740"
  },
  {
    "text": "coming and you can write applications and what we call kcl the Kinesis library to take data off that stream and",
    "start": "1143740",
    "end": "1150530"
  },
  {
    "text": "actually pass it apps can be written in Java or many of their lambda compatible",
    "start": "1150530",
    "end": "1155780"
  },
  {
    "text": "languages like Python or node and this is fantastic however you still have to",
    "start": "1155780",
    "end": "1161000"
  },
  {
    "text": "write an application so it reinvent last year we released and updated Kinesis",
    "start": "1161000",
    "end": "1166100"
  },
  {
    "text": "Kinesis is now conesus streams or the classic nieces you still have the flexibility you can still write your",
    "start": "1166100",
    "end": "1172460"
  },
  {
    "text": "innovative apps but we've also created Kinesis fire hose conesus firehouse is a",
    "start": "1172460",
    "end": "1177590"
  },
  {
    "text": "completely managed data ingest service given an HTTP endpoint you send data in and it persists it to red shift to",
    "start": "1177590",
    "end": "1185450"
  },
  {
    "text": "elasticsearch or to s3 and sometimes in some cases you can do more than one at",
    "start": "1185450",
    "end": "1191930"
  },
  {
    "text": "once and that's it it's incredibly easy to use however you still needed to write",
    "start": "1191930",
    "end": "1197570"
  },
  {
    "text": "an application to talk to this and my use all my shell hacks earlier they're terrible I'm not a developer which is",
    "start": "1197570",
    "end": "1204350"
  },
  {
    "text": "great we released the two weeks ago as I was writing my slides something that meant I didn't have to write any code",
    "start": "1204350",
    "end": "1209740"
  },
  {
    "text": "the AWS Kinesis agent allows you to read log files and manage log files and in",
    "start": "1209740",
    "end": "1215450"
  },
  {
    "text": "send them in cikini tusfiles it's a java application it's open source it's easily",
    "start": "1215450",
    "end": "1220490"
  },
  {
    "text": "available and it's ready today what you can do is you can take in things like",
    "start": "1220490",
    "end": "1226690"
  },
  {
    "text": "single line files you can take in CSV but most importantly for me is you can take in log files and it will",
    "start": "1226690",
    "end": "1232640"
  },
  {
    "text": "automatically convert them to a JSON object for import and it actually",
    "start": "1232640",
    "end": "1237800"
  },
  {
    "start": "1236000",
    "end": "1632000"
  },
  {
    "text": "supports apache logs like we're dealing with today so again pray for me people",
    "start": "1237800",
    "end": "1243920"
  },
  {
    "text": "what I'm going to do now is very quickly run through the setup of first of all fire hose the endpoints and secondly",
    "start": "1243920",
    "end": "1249320"
  },
  {
    "text": "I'll talk through how the ingest agent works so if I just go to the console",
    "start": "1249320",
    "end": "1255740"
  },
  {
    "text": "once more and I have a look at PI house fire hose is split up into different",
    "start": "1255740",
    "end": "1262070"
  },
  {
    "text": "delivery streams which are an interest point and an output point in this case",
    "start": "1262070",
    "end": "1267110"
  },
  {
    "text": "you define an index in the elastic search domain for me to actually possess the data to for my delivery stream I've",
    "start": "1267110",
    "end": "1273290"
  },
  {
    "text": "already created one but i'll just quickly show you some of the options we have so we can select s3 redshift or",
    "start": "1273290",
    "end": "1278600"
  },
  {
    "text": "elastic search in this case we want to use elastic search I'm going to use the delivery stream",
    "start": "1278600",
    "end": "1283960"
  },
  {
    "text": "name Alex yes demo life I can choose my existing elasticsearch demo and I can",
    "start": "1283960",
    "end": "1289480"
  },
  {
    "text": "choose a new or existing index and here i will choose a level we also support",
    "start": "1289480",
    "end": "1296020"
  },
  {
    "text": "rotation of indexes so if you have data that's only valid for a day or a week or a month you can automatically cycle this",
    "start": "1296020",
    "end": "1302080"
  },
  {
    "text": "out in a batch one of the best bits of fire hose is it deals with failure really well if you have a connectivity",
    "start": "1302080",
    "end": "1309520"
  },
  {
    "text": "issue between your log aggregation server and your log persistence destination you're in trouble fire hose",
    "start": "1309520",
    "end": "1315610"
  },
  {
    "text": "deals with that piece entirely for you and also in the event of a log message",
    "start": "1315610",
    "end": "1320710"
  },
  {
    "text": "coming in that's malformed you still need to be aware of that fire hose allows you to persist failed documents",
    "start": "1320710",
    "end": "1326620"
  },
  {
    "text": "or alternatively all documents into s3 and earlier when I mentioned that you could output two places at once using",
    "start": "1326620",
    "end": "1334180"
  },
  {
    "text": "fire hose to both right to an elastic search cluster and also persist data to s3 means you can then use that s 3 data",
    "start": "1334180",
    "end": "1341140"
  },
  {
    "text": "to load into red shift or your are DBMS of choice all messages are output as",
    "start": "1341140",
    "end": "1346840"
  },
  {
    "text": "JSON files in aggregated blobs so with that I'm just going to quickly go back",
    "start": "1346840",
    "end": "1352180"
  },
  {
    "text": "to my already created fire hose delivery stream now the output for this is my",
    "start": "1352180",
    "end": "1358810"
  },
  {
    "text": "earlier created elasticsearch domain but I do need some way to send data to it so",
    "start": "1358810",
    "end": "1364420"
  },
  {
    "text": "what I have here what I have here is a",
    "start": "1364420",
    "end": "1373690"
  },
  {
    "text": "terminal and I will log on to a Bastian host as many of you will know it's best",
    "start": "1373690",
    "end": "1379900"
  },
  {
    "text": "if you can have your web servers with no public internet access I've already set up a web server which is available now",
    "start": "1379900",
    "end": "1386020"
  },
  {
    "text": "you can see I've got some amounts of traffic coming in lots of requests from",
    "start": "1386020",
    "end": "1393520"
  },
  {
    "text": "my load test machine and that is running right now but I still don't have any way",
    "start": "1393520",
    "end": "1400810"
  },
  {
    "text": "to get these logs off so I choose to install the AWS Kinesis agent that's",
    "start": "1400810",
    "end": "1409270"
  },
  {
    "text": "available with Amazon linux but also available on github and we provide packages there",
    "start": "1409270",
    "end": "1415870"
  },
  {
    "text": "as that installs I can then just write an aging configuration which has a",
    "start": "1415870",
    "end": "1423200"
  },
  {
    "text": "couple of components and i will use one that i have prepackaged here so in this",
    "start": "1423200",
    "end": "1432110"
  },
  {
    "text": "what we have is a few different pieces first of all we deal with the files or specify the files we want to deal with",
    "start": "1432110",
    "end": "1437960"
  },
  {
    "text": "this takes patterns if you have files which automatically rotate all you want fios to handle that rotation for you we",
    "start": "1437960",
    "end": "1445910"
  },
  {
    "text": "also specify the delivery streetman in my case i called it as I go back to",
    "start": "1445910",
    "end": "1451340"
  },
  {
    "text": "wards here",
    "start": "1451340",
    "end": "1453970"
  },
  {
    "text": "logging at scale hyphen demo so I will remove that and I specified the way I",
    "start": "1464809",
    "end": "1472380"
  },
  {
    "text": "want to treat my data so in my case I chose to convert the log file into a JSON object and I use the log format",
    "start": "1472380",
    "end": "1478529"
  },
  {
    "text": "combined Apache log so that's very familiar for those of you who use ncsa apache logs now there's one more",
    "start": "1478529",
    "end": "1484890"
  },
  {
    "text": "important thing and that's credentials how do I stop anybody just sending data in now if you're familiar with I am",
    "start": "1484890",
    "end": "1491309"
  },
  {
    "text": "roles for ec2 they're incredibly easy way for you to grant an ec2 instance itself access to do things now this axis",
    "start": "1491309",
    "end": "1500130"
  },
  {
    "text": "might be writing to different services it might be manipulating the ec2 instance itself so within this web",
    "start": "1500130",
    "end": "1506309"
  },
  {
    "text": "server I've applied a role that allows me to write out files sorry to access my",
    "start": "1506309",
    "end": "1511409"
  },
  {
    "text": "elasticsearch cluster finally I'm just going to check the permissions so in the",
    "start": "1511409",
    "end": "1516570"
  },
  {
    "text": "HTTP directory I have it is owned by Apache and it's the log file to world",
    "start": "1516570",
    "end": "1522929"
  },
  {
    "text": "readable so with that I should be able to start my Kinesis agents starts the",
    "start": "1522929",
    "end": "1530909"
  },
  {
    "text": "java application up and then in the agent log file it takes about 30 seconds",
    "start": "1530909",
    "end": "1538409"
  },
  {
    "text": "start processing these it dispatches data in every 30 seconds and then fire hose starts to buff about so while that",
    "start": "1538409",
    "end": "1545309"
  },
  {
    "text": "starts to buffer I'm just going to quickly go back to my delivery stream and just show you a couple of the stats around here as well so within the",
    "start": "1545309",
    "end": "1552270"
  },
  {
    "text": "monitoring section what you can see is the kind of data that's coming in the freshness with s3 and AWS canisius agent",
    "start": "1552270",
    "end": "1559080"
  },
  {
    "text": "also supports cloud watch metrics so in the event but dispatch failure you can get an alerting through that using the",
    "start": "1559080",
    "end": "1564990"
  },
  {
    "text": "same kind of model you may do for the rest of your AWS platform now because",
    "start": "1564990",
    "end": "1571890"
  },
  {
    "text": "I've got a large amount of data here the Kinesis agents has gone I'm already behind I need to catch up you can see",
    "start": "1571890",
    "end": "1577350"
  },
  {
    "text": "here that it's processed 100,000 records already and it's desperately trying to send this data in to catch up that gets",
    "start": "1577350",
    "end": "1583470"
  },
  {
    "text": "added into my existing elastic search index so in the event of an instance becoming and available we don't miss",
    "start": "1583470",
    "end": "1588960"
  },
  {
    "text": "anything we still can bring that data back now I've got my data coming in it's",
    "start": "1588960",
    "end": "1594240"
  },
  {
    "text": "reliable and it's scalable so now I need to think about what I'm going to do with my data and how he can actually see it so let's go",
    "start": "1594240",
    "end": "1601029"
  },
  {
    "text": "back to the PowerPoint and let's just continue running through that so once",
    "start": "1601029",
    "end": "1606820"
  },
  {
    "text": "I've got my data in i persist it to s3 and I also load it into elasticsearch as",
    "start": "1606820",
    "end": "1611860"
  },
  {
    "text": "I mentioned this get stores as Jason blobs in s3 I can load this into redshift very easily and it's easily",
    "start": "1611860",
    "end": "1617950"
  },
  {
    "text": "available within elasticsearch my index keeps growing when I took the screenshot a couple of days ago I had 700,000 now",
    "start": "1617950",
    "end": "1624700"
  },
  {
    "text": "I'm up to 3 plus million that continues to scale and I can see my utilization I can see my growth now once I've got this",
    "start": "1624700",
    "end": "1632739"
  },
  {
    "start": "1632000",
    "end": "1692000"
  },
  {
    "text": "data I do need to visualize it I actually do need to do something with it so how can i address that piece well I",
    "start": "1632739",
    "end": "1639489"
  },
  {
    "text": "want to talk about gabbana Cabana is actually pre integrated with the elastic search service this makes life much much",
    "start": "1639489",
    "end": "1646239"
  },
  {
    "text": "easier when you're trying to manage it because it's all within that same application gabbana also doesn't deal",
    "start": "1646239",
    "end": "1652450"
  },
  {
    "text": "that well with very high latency networks so by co-locating them both with in AWS you reduce the complexity",
    "start": "1652450",
    "end": "1658330"
  },
  {
    "text": "and improve the performance we think about it's very easy to quickly visualize and play about with your grass",
    "start": "1658330",
    "end": "1664690"
  },
  {
    "text": "and get very quick insight and what you're trying to do but that doesn't",
    "start": "1664690",
    "end": "1669970"
  },
  {
    "text": "have to end there you can continue to use your same BI tools many of you will be using things like click view or",
    "start": "1669970",
    "end": "1676059"
  },
  {
    "text": "tableau or tibco or pent-up now these have ways for you to access into",
    "start": "1676059",
    "end": "1681070"
  },
  {
    "text": "redshift redshift has sequel drivers available for almost all of the major bi",
    "start": "1681070",
    "end": "1687309"
  },
  {
    "text": "vendors so if you're already using these integration should be quite simple now",
    "start": "1687309",
    "end": "1692859"
  },
  {
    "text": "I'm not going to spend too much time on this because I really want to just point out some of the very quick graphs that",
    "start": "1692859",
    "end": "1697989"
  },
  {
    "text": "I've already rendered in cabana so if I just go back to my cabana installation",
    "start": "1697989",
    "end": "1707129"
  },
  {
    "text": "first of all I want to talk about the security of Cabana so Cabana is in this",
    "start": "1707940",
    "end": "1713259"
  },
  {
    "text": "case IP secured so if i try to open this i will get an error saying actually you",
    "start": "1713259",
    "end": "1718929"
  },
  {
    "text": "haven't authenticated me you're not allowed now as I mentioned earlier I was running this through a bastion host so",
    "start": "1718929",
    "end": "1725529"
  },
  {
    "text": "that does allow me access in over an IP whitelist cabana will precash a lot of",
    "start": "1725529",
    "end": "1731139"
  },
  {
    "text": "it index for me so it's nice and easy for me to have that pre-loaded and then when once that's registered what you can see",
    "start": "1731139",
    "end": "1737410"
  },
  {
    "text": "is the same data that we saw on that ec2 instance this is serialized from a logline into a JSON object and each of",
    "start": "1737410",
    "end": "1745720"
  },
  {
    "text": "the components is split up here it's very easy for you to do filters on different sections to do quick",
    "start": "1745720",
    "end": "1751600"
  },
  {
    "text": "visualizations or even just explore and discover your data so for instance I've got a load balancer and I want to make",
    "start": "1751600",
    "end": "1757780"
  },
  {
    "text": "sure that the traffic coming in is reasonably distributed between those two well I can see of the last 500 it's",
    "start": "1757780",
    "end": "1763840"
  },
  {
    "text": "about 5050 so yes it's working well but when I want to start doing more visualizations I've got a range of",
    "start": "1763840",
    "end": "1770500"
  },
  {
    "text": "options available to me that I can quickly create if I want to create a line bar just based on traffic over time",
    "start": "1770500",
    "end": "1782620"
  },
  {
    "text": "I can do that with I think that was five clicks and then this same data is",
    "start": "1782620",
    "end": "1789310"
  },
  {
    "text": "available to me to do a wide range of different things and some of the talks do you'll see today around IOT and other",
    "start": "1789310",
    "end": "1795370"
  },
  {
    "text": "components use the same approach to show completely different kinds of data and",
    "start": "1795370",
    "end": "1800880"
  },
  {
    "text": "once I've built several visualizations I can load this into a dashboard that dashboard becomes incredibly easy for me",
    "start": "1800880",
    "end": "1807670"
  },
  {
    "text": "to then have as my network operation center dashboard or even something my",
    "start": "1807670",
    "end": "1813190"
  },
  {
    "text": "developers use to know the health of their instances it uses the same visualizations that I created in the",
    "start": "1813190",
    "end": "1818860"
  },
  {
    "text": "other section of cabana and they load into an easily customizable dashboard so",
    "start": "1818860",
    "end": "1823990"
  },
  {
    "text": "with that with that I want to try and",
    "start": "1823990",
    "end": "1830590"
  },
  {
    "start": "1828000",
    "end": "1921000"
  },
  {
    "text": "wrap up now so I feel like we've dealt with the technical problems but what this doesn't deal with is the inside you",
    "start": "1830590",
    "end": "1837730"
  },
  {
    "text": "as an organization still need to provide insight into your data you can provide these tools you can use the existing bi",
    "start": "1837730",
    "end": "1843940"
  },
  {
    "text": "tools but you still need the data engineers you still need the data scientists to do this but hopefully by",
    "start": "1843940",
    "end": "1849490"
  },
  {
    "text": "doing things like this you remove the barriers to actually taking a data in and passing it so to recap I still think",
    "start": "1849490",
    "end": "1858010"
  },
  {
    "text": "logging is incredibly hard we make life easier we provide you plugins we provide you software we provide age",
    "start": "1858010",
    "end": "1864610"
  },
  {
    "text": "to take that data off and very scalable services for you to add a Turing but it's still hard to do if you use tools",
    "start": "1864610",
    "end": "1871929"
  },
  {
    "text": "like fire hose the Kinesis agent elasticsearch service or even redshift it does deal with a lot of those call",
    "start": "1871929",
    "end": "1878170"
  },
  {
    "text": "components and make life easier but where you can you should re use the data so send to multiple fire hose end points",
    "start": "1878170",
    "end": "1884620"
  },
  {
    "text": "at once we use the tools if you already have visualization tools endpoints",
    "start": "1884620",
    "end": "1889750"
  },
  {
    "text": "things like that and reuse the people don't think just because you're moving to cabana you get rid of your data science group and please again don't be",
    "start": "1889750",
    "end": "1897130"
  },
  {
    "text": "big data dog use your time cleverly and know what you actually need to do so",
    "start": "1897130",
    "end": "1902770"
  },
  {
    "text": "with that as I said in my earlier torque amazon is a human company we're based for Asia Pacific headquarters in",
    "start": "1902770",
    "end": "1908320"
  },
  {
    "text": "Singapore we have drop-ins almost every other week in the office we have the AWS user group which is incredibly popular",
    "start": "1908320",
    "end": "1914020"
  },
  {
    "text": "please do come by talk and learn",
    "start": "1914020",
    "end": "1918480"
  }
]
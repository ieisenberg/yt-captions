[
  {
    "start": "0",
    "end": "112000"
  },
  {
    "text": "well I guess that's my sign the music stopped must mean I have to start him it's only six fifty-eight but you know",
    "start": "60",
    "end": "6410"
  },
  {
    "text": "okay it depends on the clock this one says 658 credit to all of you guys for",
    "start": "6410",
    "end": "12509"
  },
  {
    "text": "coming today I I don't know how they picked the time slots for these things when I saw it was seven o'clock on Tuesday I was like really this is this",
    "start": "12509",
    "end": "19020"
  },
  {
    "text": "is the slot we get but there's some random draw system and I don't know how it works the mere fact that you're all here after happy hour upstairs",
    "start": "19020",
    "end": "25890"
  },
  {
    "text": "I mean I'm impressed but I wish I had you know take a beer to offer in the",
    "start": "25890",
    "end": "31230"
  },
  {
    "text": "back but you know what can you do there's there's coke that really counts I'm not sure at anyway bit of an",
    "start": "31230",
    "end": "36719"
  },
  {
    "text": "introduction my name is John Woodford I am a program manager with obviously AWS",
    "start": "36719",
    "end": "41790"
  },
  {
    "text": "I put in my background I actually was involved in the launch of the database migration service way back at reinvent",
    "start": "41790",
    "end": "48420"
  },
  {
    "text": "three years ago that was when we announced it the fact is it didn't actually go GA until March as is the way",
    "start": "48420",
    "end": "54420"
  },
  {
    "text": "these things go so needless to say I've been with the product for some time and have been involved in a lot of database",
    "start": "54420",
    "end": "60750"
  },
  {
    "text": "migrations I'm assuming based on on the title here you know everyone's interested in learning about database",
    "start": "60750",
    "end": "67049"
  },
  {
    "text": "migrations I like to start things off with just a bit of a survey has anybody actually used DMS or SCT yet all right",
    "start": "67049",
    "end": "74280"
  },
  {
    "text": "so we've got a few in the crowd that's good hopefully everyone is actually interested in migrating because we're",
    "start": "74280",
    "end": "79439"
  },
  {
    "text": "gonna spend an hour talking about it but I promise you one thing it's not going to be death by PowerPoint I know that is",
    "start": "79439",
    "end": "85380"
  },
  {
    "text": "a little boring especially when you've probably been this may be your sixth session today or something like that you",
    "start": "85380",
    "end": "90479"
  },
  {
    "text": "maybe had enough of them I've got a quite a long demo plans or actually get you know so-called hands-on with a",
    "start": "90479",
    "end": "97110"
  },
  {
    "text": "product at least I will be and with that you get the the joy of watching me and hopefully nothing goes wrong because you",
    "start": "97110",
    "end": "102750"
  },
  {
    "text": "know demos that's just how it goes but hopefully that will be of interest but",
    "start": "102750",
    "end": "108240"
  },
  {
    "text": "we're gonna dive in and talk about well well let's just start with what we are going to talk about a bit of an agenda",
    "start": "108240",
    "end": "114600"
  },
  {
    "start": "112000",
    "end": "191000"
  },
  {
    "text": "we're gonna say okay what's in with the cloud it's one thing to talk about a",
    "start": "114600",
    "end": "119610"
  },
  {
    "text": "sales pitch it's another thing to actually do it you know how is it I can actually do a migration and then with",
    "start": "119610",
    "end": "125729"
  },
  {
    "text": "respect to the tools that we're talking about today when should you use them they're not always the right solution for your problems so it's important to",
    "start": "125729",
    "end": "132360"
  },
  {
    "text": "understand just when you should think about using our particular migration tools and when you should look at using something else now I'm assuming",
    "start": "132360",
    "end": "140220"
  },
  {
    "text": "everyone in the room is pretty technically inclined you probably wanna know how this thing works behind the covers I'm gonna dive into just a little",
    "start": "140220",
    "end": "147240"
  },
  {
    "text": "bit of the depth as to how it works don't worry there's gonna be no new Java code flashing up on the screen or anything but will will talk into you",
    "start": "147240",
    "end": "154800"
  },
  {
    "text": "know how the migration process works what are some of the technologies we use behind the scenes to actually make it happen",
    "start": "154800",
    "end": "159840"
  },
  {
    "text": "and of course if you have more detailed questions at the end feel free to fire them along I'm actually expecting some of my team members from the actual",
    "start": "159840",
    "end": "166920"
  },
  {
    "text": "development group to appear in here at some point they're probably busy enjoying the beers themselves in the moment as I said big demo that'll be",
    "start": "166920",
    "end": "174840"
  },
  {
    "text": "coming up and then a little bit of a talk about what some other customers have done with respect to database",
    "start": "174840",
    "end": "180209"
  },
  {
    "text": "migrations it's been out for a while so we have some good examples and then of course where can you go for more",
    "start": "180209",
    "end": "186239"
  },
  {
    "text": "information where can you go for help and really how do you get started all",
    "start": "186239",
    "end": "191580"
  },
  {
    "text": "right so as I said kicking off with the cloud benefits this isn't an RDS session but I",
    "start": "191580",
    "end": "198930"
  },
  {
    "text": "always like to start off with a bit of an overview of RDS in case anybody has not used it before migrate into the",
    "start": "198930",
    "end": "206130"
  },
  {
    "text": "cloud if you're going from on-premise if you were to just go and do the basics and buy the basics I mean go and install",
    "start": "206130",
    "end": "214590"
  },
  {
    "text": "database software on ec2 and run it there you're already miles ahead of where you were you don't have to go and procure",
    "start": "214590",
    "end": "220739"
  },
  {
    "text": "your own hardware install operating systems that sort of thing but if you really want to take things to the next",
    "start": "220739",
    "end": "226079"
  },
  {
    "text": "level you should have a look at RDS RDS allows you to basically abstract",
    "start": "226079",
    "end": "234090"
  },
  {
    "text": "yourself from a lot of the ongoing maintenance and operations type events",
    "start": "234090",
    "end": "239519"
  },
  {
    "text": "you would have to do with a database to give you an idea if you haven't looked at it before instead of having to go and",
    "start": "239519",
    "end": "245130"
  },
  {
    "text": "install your own database software configure it set up backups you know do monitoring that sort of thing",
    "start": "245130",
    "end": "251100"
  },
  {
    "text": "RDS does all of that with a click of a button in fact if I have a bit of time well I'm probably not gonna have quite",
    "start": "251100",
    "end": "256169"
  },
  {
    "text": "enough time but you can launch an RDS instance in literally you know the mouse clicks take about 20 seconds and the",
    "start": "256169",
    "end": "263340"
  },
  {
    "text": "instance will be launched within 4 minutes so if you think about how long it takes you to spin up a date basse instance RDS definitely is faster",
    "start": "263340",
    "end": "271810"
  },
  {
    "text": "Amazon is pretty big about platform-agnostic as you can see across the bottom already s works with a range",
    "start": "271810",
    "end": "277370"
  },
  {
    "text": "of engines both open source and commercial and of course we have our own flavors of these engines as well with",
    "start": "277370",
    "end": "283760"
  },
  {
    "text": "respect to the Amazon Aurora RDS platform alright that's enough of a RDS",
    "start": "283760",
    "end": "290450"
  },
  {
    "start": "288000",
    "end": "375000"
  },
  {
    "text": "pitch except I'll just tell about little more details with respect to some of the",
    "start": "290450",
    "end": "296180"
  },
  {
    "text": "things you can do on the cloud as I said lower total cost of ownership because we",
    "start": "296180",
    "end": "301220"
  },
  {
    "text": "manage it if you look at RDS okay my notes say take six minutes I said for",
    "start": "301220",
    "end": "307160"
  },
  {
    "text": "whatever it's pretty quick you can do things like deploy multi availability zones so for those of you that don't",
    "start": "307160",
    "end": "313100"
  },
  {
    "text": "know a region at AWS consists of multiple availability zones and at an",
    "start": "313100",
    "end": "319400"
  },
  {
    "text": "abstract sense you can think of an availability zone as a data center so in any given region will have multiple",
    "start": "319400",
    "end": "326330"
  },
  {
    "text": "availability zones and they'll be geographically dispersed around generally a major metropolitan area",
    "start": "326330",
    "end": "332240"
  },
  {
    "text": "they'll be quite far apart such that if was something to ever happen to one of",
    "start": "332240",
    "end": "337280"
  },
  {
    "text": "them the other two three four will still be available so when you deploy the",
    "start": "337280",
    "end": "342470"
  },
  {
    "text": "multi a-z option with RDS what's happening behind the scenes is we're spinning up one copy of a database in",
    "start": "342470",
    "end": "348140"
  },
  {
    "text": "one availability zone and another in another zone such that if anything ever happens you get an automatic failover",
    "start": "348140",
    "end": "353690"
  },
  {
    "text": "from one to another so basically what it comes down to is it's dr with a single mouse click pretty neat stuff you can do",
    "start": "353690",
    "end": "360800"
  },
  {
    "text": "other things like spin up regretful cuz obviously you get backups you know with a click of a mouse and you get other",
    "start": "360800",
    "end": "367850"
  },
  {
    "text": "neat things like if you decide to start a database well you don't have to maintain those shards cuz RDS will do it all for you",
    "start": "367850",
    "end": "374470"
  },
  {
    "text": "alright so the journey about database migration how do we get here so we have",
    "start": "374470",
    "end": "381200"
  },
  {
    "start": "375000",
    "end": "414000"
  },
  {
    "text": "this neat products on the cloud you can run your databases on ec2 you can run them on RDS that all sounds very good",
    "start": "381200",
    "end": "388430"
  },
  {
    "text": "you probably know a bit of history about AWS a large number of our early adopters",
    "start": "388430",
    "end": "394580"
  },
  {
    "text": "were startups these startups found it easy to incubate their ideas on the",
    "start": "394580",
    "end": "399710"
  },
  {
    "text": "cloud and scale up as needed but what about existing enterprises enterprises that",
    "start": "399710",
    "end": "406160"
  },
  {
    "text": "have been around for many years have their own either data centers in-house or through a third party how is it they",
    "start": "406160",
    "end": "412850"
  },
  {
    "text": "can actually migrate to the cloud well the day WS we believe in being responsive to our customers customers",
    "start": "412850",
    "end": "418460"
  },
  {
    "start": "414000",
    "end": "461000"
  },
  {
    "text": "have asked us to make these migrations easier and less intrusive they want to be able to migrate with a minimal",
    "start": "418460",
    "end": "423860"
  },
  {
    "text": "downtime and have the flexibility to go to any RTS engine type that they want once that migration is complete people",
    "start": "423860",
    "end": "431510"
  },
  {
    "text": "have asked us for ongoing synchronization that is the ability to keep a source and a target in sync they",
    "start": "431510",
    "end": "437150"
  },
  {
    "text": "want to be able to do that sync not only between engines that are the same but engines that are different and possibly",
    "start": "437150",
    "end": "443270"
  },
  {
    "text": "between on-premise and the cloud or say two instances in the cloud and it's this",
    "start": "443270",
    "end": "448280"
  },
  {
    "text": "mobility that addresses one of the number-one requests that we have that is the ability to migrate off commercial",
    "start": "448280",
    "end": "454370"
  },
  {
    "text": "license intensive database engines onto cloud native open source solutions so we",
    "start": "454370",
    "end": "463370"
  },
  {
    "start": "461000",
    "end": "508000"
  },
  {
    "text": "all know we're gonna talk about DMS and SCT today but pre DMS if you wanted to do those sorts of things you didn't have",
    "start": "463370",
    "end": "469820"
  },
  {
    "text": "a lot in the way of options you could go out and buy costly license intensive replication software these things often",
    "start": "469820",
    "end": "475790"
  },
  {
    "text": "came with five figure price tags they weren't easy to set up or they required the use of expert resources to do so if",
    "start": "475790",
    "end": "484220"
  },
  {
    "text": "you didn't want to do that well you had to have a long downtime to the Year migration it was really the only option out there and then if you wanted to",
    "start": "484220",
    "end": "491090"
  },
  {
    "text": "actually switch between engines you needed to find somebody who knew all about one engine all about the other and",
    "start": "491090",
    "end": "496970"
  },
  {
    "text": "could actually write the code to do the migration between the two and that is update the schema of the engine you know",
    "start": "496970",
    "end": "503060"
  },
  {
    "text": "the the triggers the functions the procedures needless to say they're pretty hard things to do so that brought",
    "start": "503060",
    "end": "510350"
  },
  {
    "text": "us to DMS and SCT we developed the service we designed to be simple you can",
    "start": "510350",
    "end": "515570"
  },
  {
    "text": "get started in less than 10 minutes and we designed it to enable near zero downtime migration basically we are",
    "start": "515570",
    "end": "521630"
  },
  {
    "text": "looking to make a bit of a migration slash replication Swiss Army knife to give you the ability to replicate",
    "start": "521630",
    "end": "526700"
  },
  {
    "text": "between on-premise systems RDS ec2 and across database engine types",
    "start": "526700",
    "end": "532720"
  },
  {
    "text": "Kinzie has been pretty successful we have migrated over 45,000 unique databases that number keeps growing day",
    "start": "532720",
    "end": "538569"
  },
  {
    "text": "by day and people are pretty happy with it as it just keeps ramping up now I",
    "start": "538569",
    "end": "545649"
  },
  {
    "start": "545000",
    "end": "661000"
  },
  {
    "text": "mentioned this a little bit earlier these products are not always your best",
    "start": "545649",
    "end": "552730"
  },
  {
    "text": "answer and that sounds funny you think I'd be here pushing my own product well when we get to the pricing slide later",
    "start": "552730",
    "end": "558220"
  },
  {
    "text": "on you'll see that DMS is not a money-making thing for AWS it's an enabler we want to make it easy for you",
    "start": "558220",
    "end": "564279"
  },
  {
    "text": "to migrate to the cloud we're not trying to make money off you while you're doing your migration what that also means is",
    "start": "564279",
    "end": "570279"
  },
  {
    "text": "you should look at other tools too in particular if you're not switching engines so DMS is real strength is what",
    "start": "570279",
    "end": "577720"
  },
  {
    "text": "we call a heterogeneous migration that is switching between one engine and another but if you're not switching engines there might might be a better",
    "start": "577720",
    "end": "585339"
  },
  {
    "text": "way to do it so sequel server say you were going to RDS sequel server a couple",
    "start": "585339",
    "end": "590769"
  },
  {
    "text": "months back they introduced the ability to import a native back file so that is you can take a back file export from",
    "start": "590769",
    "end": "596949"
  },
  {
    "text": "your sequel server put an s3 and tell the RDS sequel server engine to just go and ingest it you're doing my sequel",
    "start": "596949",
    "end": "604420"
  },
  {
    "text": "just think about are doing a read replica it's gonna be a much easier quicker way to go about it and with the",
    "start": "604420",
    "end": "609850"
  },
  {
    "text": "other engines you've got some other options too you do a PG dump PG import for Postgres but again it depends on",
    "start": "609850",
    "end": "615819"
  },
  {
    "text": "what your exact requirements are not all of these options here give you ongoing replications so what you can also do is",
    "start": "615819",
    "end": "622480"
  },
  {
    "text": "merge some solutions so say you wanted to do a sequel server minimal downtime migration and stick with sequel server",
    "start": "622480",
    "end": "628660"
  },
  {
    "text": "you could take that back file export to get your lump sum of data so to speak where it is up until now and then use",
    "start": "628660",
    "end": "635559"
  },
  {
    "text": "DMS just to replicate the changes that have happened during that time that it takes you to move the back file across",
    "start": "635559",
    "end": "641559"
  },
  {
    "text": "and import it into RDS so just have a consideration don't just jump in blindly",
    "start": "641559",
    "end": "647740"
  },
  {
    "text": "and say this is the solution there might be a better way but DMS like I said is very much a",
    "start": "647740",
    "end": "653559"
  },
  {
    "text": "replication Swiss Army knife and it will likely be involved in your plans in some ways perform so a bit more detail but when",
    "start": "653559",
    "end": "662660"
  },
  {
    "start": "661000",
    "end": "822000"
  },
  {
    "text": "you should use DMS and SCT three mean scenarios one modernize you're looking",
    "start": "662660",
    "end": "669769"
  },
  {
    "text": "to convert from one database engine to the other and update The Associated application code using code conversion",
    "start": "669769",
    "end": "675709"
  },
  {
    "text": "features of SCT so SCT can both convert your database schema and help convert",
    "start": "675709",
    "end": "681980"
  },
  {
    "text": "your application code the obvious answer is a migration so as I said earlier its",
    "start": "681980",
    "end": "688939"
  },
  {
    "text": "primary focus is heterogeneous migrations you can also use it for homogeneous migrations but it may or may",
    "start": "688939",
    "end": "695179"
  },
  {
    "text": "not be the best solution some other neat things people have done you can see up on the screen they're people that have",
    "start": "695179",
    "end": "701239"
  },
  {
    "text": "been with Amazon for a while know that the original network and infrastructure we launched with many years ago we now",
    "start": "701239",
    "end": "706970"
  },
  {
    "text": "refer to as classic a few years back we launched what's called VP see there's not a great way to move between the two",
    "start": "706970",
    "end": "713149"
  },
  {
    "text": "networking infrastructures but DMS can help DMS actually can reach out to pretty much anywhere and pull in data as",
    "start": "713149",
    "end": "719660"
  },
  {
    "text": "long as it can make a network connection you'll see when we get into the demo a bit later basically if you think of DMS",
    "start": "719660",
    "end": "725509"
  },
  {
    "text": "is a query tool as long as you can make a connection with your favorite query tool to your database VMs can pull the",
    "start": "725509",
    "end": "730759"
  },
  {
    "text": "data out so it's really good and mean it'll move information between different networks and that sort of thing",
    "start": "730759",
    "end": "736999"
  },
  {
    "text": "other people have used it to do minor version upgrades so if we go back to RDS RDS can handle minor version upgrades",
    "start": "736999",
    "end": "744079"
  },
  {
    "text": "with the simple mouse click you go okay change from I don't know 95 to 96 but to",
    "start": "744079",
    "end": "749269"
  },
  {
    "text": "do that upgrade it does take a small outage right it'll be down for 3-4 minutes as it reboots for some people",
    "start": "749269",
    "end": "754999"
  },
  {
    "text": "that outage is just not viable they can't handle it so what ends up happening is you can spin out a new",
    "start": "754999",
    "end": "762019"
  },
  {
    "text": "database with the newest version whatever it is and then use DMS to just replicate between the two and just take",
    "start": "762019",
    "end": "769279"
  },
  {
    "text": "a very small outage for the amount of time it takes you to update a DNS record so some neat use cases you can do with",
    "start": "769279",
    "end": "775429"
  },
  {
    "text": "that replication there's some systems that don't support cross regenerated",
    "start": "775429",
    "end": "780649"
  },
  {
    "text": "replicas so DMS can help set that up and the other big areas are things like data",
    "start": "780649",
    "end": "786319"
  },
  {
    "text": "warehousing so people will use it for ongoing replication to pull save financial reporting figures",
    "start": "786319",
    "end": "791900"
  },
  {
    "text": "from their online transactional database into a data warehouse there's some caveats with the read replicas and using",
    "start": "791900",
    "end": "799400"
  },
  {
    "text": "DMS as a dr solution DMS doesn't replicate full DDL so it will replicate",
    "start": "799400",
    "end": "804710"
  },
  {
    "text": "changes to your table you add a new column or something like that it will replicate that but it will not replicate",
    "start": "804710",
    "end": "810260"
  },
  {
    "text": "changes to say a stored procedure they make so you know there's there's some limitations as to exactly when you want",
    "start": "810260",
    "end": "816110"
  },
  {
    "text": "to use it generally based along how frequently your schema changes so a bit",
    "start": "816110",
    "end": "824090"
  },
  {
    "start": "822000",
    "end": "987000"
  },
  {
    "text": "more detail when to use DMS and SCT well the big one is of course when you realize you can move between database",
    "start": "824090",
    "end": "830450"
  },
  {
    "text": "engines and database platforms I want to highlight it you see some arrows on the screen here the fact is it's important",
    "start": "830450",
    "end": "837740"
  },
  {
    "text": "to highlight especially with the relational engines you can move data in both directions so say you can go as you can see on the",
    "start": "837740",
    "end": "845270"
  },
  {
    "text": "screen from Postgres to my sequel you could just as easily go back from my sequel to Postgres the key one that some",
    "start": "845270",
    "end": "851750"
  },
  {
    "text": "of our competitors like to point out is they go okay amazon aurora it's some proprietary engine AWS is gonna lock you in that's actually not the case you can",
    "start": "851750",
    "end": "859040"
  },
  {
    "text": "use DMS to migrate data right back out of amazon arora into oracle if you wanted to now I can tell you from scene",
    "start": "859040",
    "end": "865070"
  },
  {
    "text": "of the anonymous usage statistics reports that I get every day that doesn't happen very often and other neat",
    "start": "865070",
    "end": "872090"
  },
  {
    "text": "things we've got some hooks into things like s3 now so you can basically pull data out of any system put it into s3 in",
    "start": "872090",
    "end": "878570"
  },
  {
    "text": "a text file format and use it for all sorts of integration purposes you know sky's the limit when you when you think",
    "start": "878570",
    "end": "884570"
  },
  {
    "text": "about putting your data into that that format and of course you can also use it to modernize your data warehouse so it",
    "start": "884570",
    "end": "890540"
  },
  {
    "text": "gets a little bit different depending on the on the targets but you can use a combination of DMS and SCT to migrate",
    "start": "890540",
    "end": "896240"
  },
  {
    "text": "from any of those warehouses you see on the screen to Amazon redshift a little",
    "start": "896240",
    "end": "901580"
  },
  {
    "text": "bit different as I said with the warehouses we have this thing we call the SCT extractors as data warehouses",
    "start": "901580",
    "end": "908720"
  },
  {
    "text": "don't change as frequently as a database these SCT extractors actually are more",
    "start": "908720",
    "end": "913970"
  },
  {
    "text": "of a point in time dump from the database and it'll upload it to s3 where",
    "start": "913970",
    "end": "919100"
  },
  {
    "text": "it gets ingested automatically into redshift so it doesn't do a streaming transaction thing the way DMS does",
    "start": "919100",
    "end": "925490"
  },
  {
    "text": "but it will definitely help you move your databases along the other thing I should mention there's a session on",
    "start": "925490",
    "end": "931880"
  },
  {
    "text": "Thursday where we're going to demo our latest feature release for SCT and DMS",
    "start": "931880",
    "end": "938510"
  },
  {
    "text": "that is the integration with snowball so for really large datasets you can now",
    "start": "938510",
    "end": "944870"
  },
  {
    "text": "use snowball to dump your data to disk which the snowball in essence locally in your data center ship that by UPS or",
    "start": "944870",
    "end": "951860"
  },
  {
    "text": "FedEx to AWS but at the same time automatically will have set up a DMS",
    "start": "951860",
    "end": "957830"
  },
  {
    "text": "stream to replicate any changes that have occurred on the database during transit so once that snowball makes it",
    "start": "957830",
    "end": "963800"
  },
  {
    "text": "to the data center it gets ingested in and then will apply all the changes that happen during that time using DMS to",
    "start": "963800",
    "end": "970310"
  },
  {
    "text": "your target database so that's pretty neat and on top of that it's not just",
    "start": "970310",
    "end": "975350"
  },
  {
    "text": "for singular large databases you could use it for an entire fleet of databases",
    "start": "975350",
    "end": "980570"
  },
  {
    "text": "so you could put 20 different databases on that snowball and ship it and away you go",
    "start": "980570",
    "end": "986680"
  },
  {
    "start": "987000",
    "end": "1105000"
  },
  {
    "text": "so in summary why would you use DMS and SCT brings a lot of advantages to the",
    "start": "987070",
    "end": "993680"
  },
  {
    "text": "market and makes it easier for you to move to the cloud as I mentioned it's very cost effective if when we get to",
    "start": "993680",
    "end": "999800"
  },
  {
    "text": "look at the price list I runs on the order of a couple dollars a day and one of the things that's changed recently is",
    "start": "999800",
    "end": "1005649"
  },
  {
    "text": "we now offer free DMS if your targets are Amazon Aurora dynamo DB or redshift",
    "start": "1005649",
    "end": "1011470"
  },
  {
    "text": "so becomes really really effective when you look at that yeah",
    "start": "1011470",
    "end": "1018779"
  },
  {
    "text": "yeah it's it's not any instant size up to like the 4x larges but it's it's it",
    "start": "1021780",
    "end": "1028810"
  },
  {
    "text": "is both the T 2 s and the C 4 is just not the very largest of ones a its document on our website you think I can remember exactly the sizes off the top",
    "start": "1028810",
    "end": "1034839"
  },
  {
    "text": "my head but most of them most of them and after that brings up a good point t2 micros that's the smallest instance",
    "start": "1034839",
    "end": "1041770"
  },
  {
    "text": "size are free for the first year they always have been but I highly recommend",
    "start": "1041770",
    "end": "1047380"
  },
  {
    "text": "that if you're doing a production migration you do not use a t2 micro because it will just take a very very",
    "start": "1047380",
    "end": "1052900"
  },
  {
    "text": "long time it's an interesting thing actually when you're deciding what replication is in",
    "start": "1052900",
    "end": "1058060"
  },
  {
    "text": "size to use with DMS we've done some testing and we've actually found that if you use a bigger instance which",
    "start": "1058060",
    "end": "1064330"
  },
  {
    "text": "technically cost more money per hour you'll finish finish so much faster than you will with the smaller instances but",
    "start": "1064330",
    "end": "1070390"
  },
  {
    "text": "you'll actually save money so there's a fine balancing act there and as far as limits and size that's something I",
    "start": "1070390",
    "end": "1076120"
  },
  {
    "text": "should mention there's no upper limit on how large database you can move with DMS especially now a snowball you know sky",
    "start": "1076120",
    "end": "1083140"
  },
  {
    "text": "is really limit but as far as what I mean by limit as far as how much you would move over the wire we kind of",
    "start": "1083140",
    "end": "1089860"
  },
  {
    "text": "recommend about 5 terabytes as a top there's nothing in the code that stops you if had people move 15 terabytes but",
    "start": "1089860",
    "end": "1096070"
  },
  {
    "text": "it really comes down to how long you're able to wait what your internet bandwidth capacity are is and that sort",
    "start": "1096070",
    "end": "1101860"
  },
  {
    "text": "of thing so how does it work",
    "start": "1101860",
    "end": "1109140"
  },
  {
    "start": "1105000",
    "end": "1175000"
  },
  {
    "text": "all right the database migration process as I mentioned earlier we have both the schema conversion tool and the database",
    "start": "1109970",
    "end": "1116060"
  },
  {
    "text": "migration service these things are close cousins they'll probably come even more closer as time progresses but the",
    "start": "1116060",
    "end": "1122120"
  },
  {
    "text": "general idea is you use SCT to move your schema first and then you use DMS to",
    "start": "1122120",
    "end": "1127610"
  },
  {
    "text": "move your data now the example we've got up on the screen is a heterogeneous",
    "start": "1127610",
    "end": "1133490"
  },
  {
    "text": "migration it's important to note that these tools can also help you in homogeneous migrations SCT can a copy a",
    "start": "1133490",
    "end": "1140690"
  },
  {
    "text": "schema so it can copy an Oracle schema to an Oracle schema it may not be your best option again just to highlight for",
    "start": "1140690",
    "end": "1146810"
  },
  {
    "text": "homogeneous migrations there might be other easier ways to go about it but it doesn't need stuff if you use SCT and",
    "start": "1146810",
    "end": "1153170"
  },
  {
    "text": "run a report on your Oracle database with the optimization flag it will",
    "start": "1153170",
    "end": "1158630"
  },
  {
    "text": "suggest to you based on looking at the metadata of your Oracle database whether or not you could downgrade to say a",
    "start": "1158630",
    "end": "1164690"
  },
  {
    "text": "cheaper license so has some some extra niceties in there so again copy your",
    "start": "1164690",
    "end": "1170990"
  },
  {
    "text": "scheme with SCT then use DMS to move your data flip over so a bit more detail",
    "start": "1170990",
    "end": "1176960"
  },
  {
    "start": "1175000",
    "end": "1224000"
  },
  {
    "text": "about SCT what it does it converts the database schema it converts a data warehouse schema it also converts",
    "start": "1176960",
    "end": "1183080"
  },
  {
    "text": "application sequel and this is something that people are off to miss so you go and you convert your your whole schema",
    "start": "1183080",
    "end": "1189170"
  },
  {
    "text": "and you move your data across but all of your apps are still probably coded to",
    "start": "1189170",
    "end": "1194540"
  },
  {
    "text": "work with your original database engine it's not going to get everything but what it can do is it can scan your",
    "start": "1194540",
    "end": "1201260"
  },
  {
    "text": "source code repository and search for embedded sequel statements and convert those from say pl/sql to PG pl/sql it'll",
    "start": "1201260",
    "end": "1210380"
  },
  {
    "text": "work generally speaking if your sequel statements are in plain text as opposed to using some library to get input from",
    "start": "1210380",
    "end": "1217790"
  },
  {
    "text": "the database but it can really help with the automation we've had some good feedback on that the other thing it does",
    "start": "1217790",
    "end": "1224960"
  },
  {
    "start": "1224000",
    "end": "1284000"
  },
  {
    "text": "is run an assessment report so if you're just thinking about doing a migration",
    "start": "1224960",
    "end": "1229970"
  },
  {
    "text": "there's no need to make a commitment SCT is a free tool so you can download SCT",
    "start": "1229970",
    "end": "1236090"
  },
  {
    "text": "and point it to your database and it will it's literally read only it will read your database and look at it and go",
    "start": "1236090",
    "end": "1242909"
  },
  {
    "text": "well you've got so many tables so many procedures so many functions this is the",
    "start": "1242909",
    "end": "1248639"
  },
  {
    "text": "percentage that I can automatically convert to say my sequel or to Aurora my sequel or to Postgres and then you can",
    "start": "1248639",
    "end": "1256259"
  },
  {
    "text": "make a decision based on the outcome as to which of the target database engines you might want to consider using now",
    "start": "1256259",
    "end": "1262320"
  },
  {
    "text": "you're going to want to balance other things in your decision-making criteria of course if your staff knows absolutely",
    "start": "1262320",
    "end": "1267389"
  },
  {
    "text": "nothing about my sequel but they happen to know something of a book about Postgres you're probably gonna want to choose that even if say my sook will had",
    "start": "1267389",
    "end": "1274109"
  },
  {
    "text": "a better conversion rate so you know there's some things to think about there but anything is it kind of gives you a",
    "start": "1274109",
    "end": "1280229"
  },
  {
    "text": "starting point as to where you might want to go with your migrations what is SCT actually look like it looks like an",
    "start": "1280229",
    "end": "1287609"
  },
  {
    "start": "1284000",
    "end": "1371000"
  },
  {
    "text": "integrated development environment and if nobody here if you haven't looked at this before you might be a bit surprised",
    "start": "1287609",
    "end": "1293879"
  },
  {
    "text": "because AWS is a Stoneham for cloud software right this is a client-side tool so it's a complete anomaly out",
    "start": "1293879",
    "end": "1300840"
  },
  {
    "text": "there in fact when we developed it I hunted around to our UX groups at AWS",
    "start": "1300840",
    "end": "1307139"
  },
  {
    "text": "and I said look I need some feedback on our design of this thing and they just went to me went huh we don't we don't",
    "start": "1307139",
    "end": "1312960"
  },
  {
    "text": "even know what to do they were all about giving us feedback on on web consoles and and that sort of thing they it's",
    "start": "1312960",
    "end": "1318479"
  },
  {
    "text": "just not up their alley but it made a lot of sense to have it as a client-side tool because you're doing a lot of back-and-forth stew generally an",
    "start": "1318479",
    "end": "1324629"
  },
  {
    "text": "on-premise database looking at all the metadata the structure and probably doing multiple iterations of it so we",
    "start": "1324629",
    "end": "1331109"
  },
  {
    "text": "just decided to use it as a client tool it's available for four different operating systems so take your pick as",
    "start": "1331109",
    "end": "1336149"
  },
  {
    "text": "to what you want to use and now comes it didn't have this lunch but it now has what we call the extractors that I",
    "start": "1336149",
    "end": "1343320"
  },
  {
    "text": "mentioned earlier to help dump data from data warehouses as well as this most recent release that came out ten days",
    "start": "1343320",
    "end": "1348749"
  },
  {
    "text": "ago can of course talk to a snowball device that you plug into your local network so st is really really growing",
    "start": "1348749",
    "end": "1354599"
  },
  {
    "text": "up and has a has a fair few bells and whistles to it now I'll get into showing how it works during the demo but the",
    "start": "1354599",
    "end": "1360840"
  },
  {
    "text": "general idea is the left side tree is your source database tree the right side is your target and then in the middle",
    "start": "1360840",
    "end": "1367019"
  },
  {
    "text": "are the components that you're working on converting so DMS how does it work",
    "start": "1367019",
    "end": "1375000"
  },
  {
    "start": "1371000",
    "end": "1653000"
  },
  {
    "text": "so the diagram is well we've had it up for a couple years but I still think it's the best way to demonstrate how it",
    "start": "1375000",
    "end": "1381340"
  },
  {
    "text": "works on the left it says customer premise on the right it says AWS you really just need to look at this as a",
    "start": "1381340",
    "end": "1387100"
  },
  {
    "text": "source and target so remember how I mentioned we don't believe in vendor lock-in you could easily be going from",
    "start": "1387100",
    "end": "1392680"
  },
  {
    "text": "AWS back to customer premise here or you could be going from RDS to ec2 or vice-versa",
    "start": "1392680",
    "end": "1397960"
  },
  {
    "text": "the only restriction on AWS is that you can't go from on-premise to home premise one end of the migration has to be",
    "start": "1397960",
    "end": "1404050"
  },
  {
    "text": "somewhere and they'd have an AWS cloud so you kick things off by starting a replication instance now there's a",
    "start": "1404050",
    "end": "1410830"
  },
  {
    "text": "question earlier on replication instant sizes at the moment DMS supports T 2's and C fours we just did a bit of",
    "start": "1410830",
    "end": "1418600"
  },
  {
    "text": "analysis and figured those were the the best instance sizes to target that's probably gonna change fairly soon",
    "start": "1418600",
    "end": "1423730"
  },
  {
    "text": "because as AWS launches new instance instance types it makes sense for all the services to adopt the ones that are",
    "start": "1423730",
    "end": "1430150"
  },
  {
    "text": "most applicable to them but basically right now we recommend T to use for dev tests see for us for production and all",
    "start": "1430150",
    "end": "1436870"
  },
  {
    "text": "these boxes are there actually ec2 instances that we manage for you and we have replication software installed",
    "start": "1436870",
    "end": "1443350"
  },
  {
    "text": "you never log on to the Box directly you interact with it through the API the CLI or of course the AWS console once that",
    "start": "1443350",
    "end": "1451210"
  },
  {
    "text": "box is up and running you define your endpoints so you should think of a",
    "start": "1451210",
    "end": "1456580"
  },
  {
    "text": "replication server as essentially a big CPU that just processes migration data so you can have as many different",
    "start": "1456580",
    "end": "1463180"
  },
  {
    "text": "sources and targets defined as you want you could be moving data from an Oracle database to a Postgres database at the",
    "start": "1463180",
    "end": "1469690"
  },
  {
    "text": "same time you're removing information from say sequel server to my sequel it just moves data around any which way so",
    "start": "1469690",
    "end": "1476560"
  },
  {
    "text": "you can have many different endpoints defined for this diagram in essence you just have to a source and a target and",
    "start": "1476560",
    "end": "1482830"
  },
  {
    "text": "then you define tasks so this task I haven't mentioned it before now but DMS",
    "start": "1482830",
    "end": "1489100"
  },
  {
    "text": "is what we call a logical replication product or a piece of software what that",
    "start": "1489100",
    "end": "1494620"
  },
  {
    "text": "means is we don't move things at the bit level we don't just go and start reading all the blocks of your database moving",
    "start": "1494620",
    "end": "1500320"
  },
  {
    "text": "it across we literally go select star from your table and move it across and",
    "start": "1500320",
    "end": "1506140"
  },
  {
    "text": "the advantages of that bring is that you don't have to move your whole database you could move some",
    "start": "1506140",
    "end": "1511960"
  },
  {
    "text": "tables all tables or even certain rows in tables or certain schemas so it",
    "start": "1511960",
    "end": "1517090"
  },
  {
    "text": "really allows you to filter out what it is you need to move and that's why it becomes useful for data warehousing and",
    "start": "1517090",
    "end": "1522840"
  },
  {
    "text": "ongoing replication tasks as well so once you've defined what it is you want",
    "start": "1522840",
    "end": "1527860"
  },
  {
    "text": "to move you just sit back relax and watch DMS move the data across and if",
    "start": "1527860",
    "end": "1532900"
  },
  {
    "text": "you've enabled the option it will keep it in sync from source to target now this is another key thing to mention DMS",
    "start": "1532900",
    "end": "1539500"
  },
  {
    "text": "does one way synchronization there's nothing stopping you from setting up a sync going back the other way but you're",
    "start": "1539500",
    "end": "1545080"
  },
  {
    "text": "gonna get some very interesting behavior if you try it I don't recommend it we we basically don't have conflict resolution",
    "start": "1545080",
    "end": "1550480"
  },
  {
    "text": "built into the system so it's a one-way sync this is some exceptions there if you were migrating from one group of",
    "start": "1550480",
    "end": "1556929"
  },
  {
    "text": "tables to the same group of tables on your target and a completely separate set of tables going back the other",
    "start": "1556929",
    "end": "1562150"
  },
  {
    "text": "direction that would actually work fine but just generally speaking if you had some troubles with that and you called",
    "start": "1562150",
    "end": "1567460"
  },
  {
    "text": "up support they just go whoa what are you doing all right so that's is it a high level how DMS works oh and I forgot",
    "start": "1567460",
    "end": "1574450"
  },
  {
    "text": "to mention once things are in sync and you're happy with it you've done your testing you just sit back flip your DNS",
    "start": "1574450",
    "end": "1580750"
  },
  {
    "text": "entry to point to your new database and off you go",
    "start": "1580750",
    "end": "1585059"
  },
  {
    "text": "so a little bit more detail the load happens table by table because it's",
    "start": "1588730",
    "end": "1594400"
  },
  {
    "text": "logical it just kind of works through the task list and starts migrating information across it sets up the",
    "start": "1594400",
    "end": "1600010"
  },
  {
    "text": "metadata required at the target DMS will create the table for you but it will only create the table with",
    "start": "1600010",
    "end": "1605800"
  },
  {
    "text": "the the same table name and the same columns and the same datatypes",
    "start": "1605800",
    "end": "1611230"
  },
  {
    "text": "it doesn't do all the other stuff like trigger is foreign key constraints that sort of thing that's why you actually",
    "start": "1611230",
    "end": "1616360"
  },
  {
    "text": "want to use SCT to pre create your table for you the MS is just kind of creates what it needs and that's about it goes",
    "start": "1616360",
    "end": "1623020"
  },
  {
    "text": "through by default moves I believe it's eight tables at a time you can customize that however you please and of course you can set up",
    "start": "1623020",
    "end": "1629890"
  },
  {
    "text": "multiple replication tasks as things are going you can pause it at any time it'll reload or restart from where it",
    "start": "1629890",
    "end": "1636310"
  },
  {
    "text": "left off if you want to resume it of course also handles it you know interruptions it'll keep on trying to",
    "start": "1636310",
    "end": "1642280"
  },
  {
    "text": "resume if you've enabled the multi a-z option for the DMS instance it'll of course failover if for whatever reason",
    "start": "1642280",
    "end": "1649300"
  },
  {
    "text": "an availability zone goes down with AWS how does this ongoing replication work",
    "start": "1649300",
    "end": "1657340"
  },
  {
    "start": "1653000",
    "end": "1709000"
  },
  {
    "text": "well ongoing replication has another name that is change data capture there's absolutely no real magic here what",
    "start": "1657340",
    "end": "1664570"
  },
  {
    "text": "happens behind the scenes as I'm sure most people know in the room is the database has a transaction log changes",
    "start": "1664570",
    "end": "1669790"
  },
  {
    "text": "are written to the log so all we are doing is using the native api's of the",
    "start": "1669790",
    "end": "1674800"
  },
  {
    "text": "database engine to read the changes that have happened in that log and replicate that across to the target that is also",
    "start": "1674800",
    "end": "1681670"
  },
  {
    "text": "why we don't support really old database engines because really old database engines don't have this api's and we",
    "start": "1681670",
    "end": "1687700"
  },
  {
    "text": "can't get the changes now in order to enable this there of course needs to be something done on the database all that",
    "start": "1687700",
    "end": "1695410"
  },
  {
    "text": "is is enabling logins so Oracle turn on supplemental logging Postgres we need access the wall log but the neat thing",
    "start": "1695410",
    "end": "1701560"
  },
  {
    "text": "about this sort of thing is we don't need an agent there's no software needed on-premise to use DMS well what else can",
    "start": "1701560",
    "end": "1711220"
  },
  {
    "start": "1709000",
    "end": "1782000"
  },
  {
    "text": "you do it's many things it's not just about migration this is consolidation right",
    "start": "1711220",
    "end": "1716710"
  },
  {
    "text": "you can take information from three different databases or more you might almost say and databases and consolidated all into",
    "start": "1716710",
    "end": "1723110"
  },
  {
    "text": "a single target the common scenario in this case is my sequel shard consolidation anybody that's used my",
    "start": "1723110",
    "end": "1728659"
  },
  {
    "text": "sequel for the years knows that it doesn't scale particularly well and eventually you need to shard it these",
    "start": "1728659",
    "end": "1735710"
  },
  {
    "text": "days we have Aurora Aurora scales amazingly well so what we're having lots of people do because consolidate all",
    "start": "1735710",
    "end": "1741919"
  },
  {
    "text": "their my sequel shards into a single Aurora instance and not only that they're saving money as part of the process because Aurora handles those",
    "start": "1741919",
    "end": "1748460"
  },
  {
    "text": "loads really well they can use a smaller instance size class and roar than they were even using for those my sequel",
    "start": "1748460",
    "end": "1753679"
  },
  {
    "text": "shards but you know the other scenario looking to this would be if you imagine the targets a data warehouse so you",
    "start": "1753679",
    "end": "1759049"
  },
  {
    "text": "taking information from your finance system your CRM system and maybe some order inventory or something like that",
    "start": "1759049",
    "end": "1764630"
  },
  {
    "text": "and putting it all in a bi system for analysis you can do the reverse you've",
    "start": "1764630",
    "end": "1770270"
  },
  {
    "text": "got some giant ASAP system and you want to put bits of information in other databases for you know microservices or",
    "start": "1770270",
    "end": "1777740"
  },
  {
    "text": "something like that you can pull the information held with DMS or like I",
    "start": "1777740",
    "end": "1783500"
  },
  {
    "start": "1782000",
    "end": "1849000"
  },
  {
    "text": "mentioned earlier with DMS you don't have to take it all so you can take slices of a table essentially applying",
    "start": "1783500",
    "end": "1788779"
  },
  {
    "text": "where clauses to your filters so you pull out sets of data what's a pretty common scenario is people when they're",
    "start": "1788779",
    "end": "1795110"
  },
  {
    "text": "migrating they realize they don't need all the historical data so they maybe only grab the last seven years of data",
    "start": "1795110",
    "end": "1800960"
  },
  {
    "text": "as they need for financial purposes and leave everything else behind a neat scenario I heard just the other day from",
    "start": "1800960",
    "end": "1807159"
  },
  {
    "text": "the product manager out of Athena is he's had customers take my sequel",
    "start": "1807159",
    "end": "1813649"
  },
  {
    "text": "backups and put those back up files on s3 and because they're basically text",
    "start": "1813649",
    "end": "1818779"
  },
  {
    "text": "files he uses that for archival purposes and if they ever need to look at some historical data they can use Athena to",
    "start": "1818779",
    "end": "1825529"
  },
  {
    "text": "query the backup files directly on s3 to pull out the historical data at the cost of I don't remember what Athena cost but",
    "start": "1825529",
    "end": "1831559"
  },
  {
    "text": "it's like hundredths of a cent per query it's essentially nothing and then they've used DMS just to take filter out",
    "start": "1831559",
    "end": "1837470"
  },
  {
    "text": "the new information and keep that in there live transactional database so kind of a neat combination of what you",
    "start": "1837470",
    "end": "1843230"
  },
  {
    "text": "can do with the services thereby allowing you to run a much smaller database server so just to reiterate DMS",
    "start": "1843230",
    "end": "1851510"
  },
  {
    "text": "can move your data from pretty much any source to any target whether that's homogeneous heterogeneous or connecting into something like Amazon",
    "start": "1851510",
    "end": "1859040"
  },
  {
    "text": "s3 and s3 can be used as both a source and a target for a little bit more",
    "start": "1859040",
    "end": "1865010"
  },
  {
    "text": "detail on how you can do migrations we're trying to make it easy there's lots of blogs out there you can read there's also something we just released",
    "start": "1865010",
    "end": "1871280"
  },
  {
    "text": "the other day we're kind of calling it a cookbook if you will you'll see the link on our website and in particular for",
    "start": "1871280",
    "end": "1876620"
  },
  {
    "text": "Oracle to Postgres migrations there is hundreds of pages of detail as to pretty much every scenario you can encounter",
    "start": "1876620",
    "end": "1883040"
  },
  {
    "text": "during a migration and what are the best practices and how you can handle them and move forward so that's been a fair",
    "start": "1883040",
    "end": "1890030"
  },
  {
    "text": "bit of me talking just got unlock my computer here and get into the demo",
    "start": "1890030",
    "end": "1898060"
  },
  {
    "text": "alright so we'll do that that wasn't",
    "start": "1898540",
    "end": "1905870"
  },
  {
    "text": "technology great there we go up and running so a demo I want to do today is an interesting one some of you that have",
    "start": "1905870",
    "end": "1912830"
  },
  {
    "text": "used Oracle in the past may have heard about swing bench swing bench is a performance testing tool load testing",
    "start": "1912830",
    "end": "1919730"
  },
  {
    "text": "tool that gets used on Oracle can emulate thousands of users hitting your",
    "start": "1919730",
    "end": "1924950"
  },
  {
    "text": "database so what I'm going to use I'm going to use one of the demonstration schemas they come with that system it's",
    "start": "1924950",
    "end": "1931190"
  },
  {
    "text": "called the sales order entry schema and I'm going to migrate it from Oracle to Arora Postgres migrate the data across",
    "start": "1931190",
    "end": "1939620"
  },
  {
    "text": "and once that data has been moved across that's the full load step as we call it I'm gonna hit it with swing bench and",
    "start": "1939620",
    "end": "1946100"
  },
  {
    "text": "generate a high load of transactions and demonstrate to you that DMS can replicate those changes across from the",
    "start": "1946100",
    "end": "1952580"
  },
  {
    "text": "source to the target other things I'm gonna show during the demo in addition to how to do the conversion is I'm going",
    "start": "1952580",
    "end": "1958520"
  },
  {
    "text": "to show some of the new features that we've released with respect to data validation to make sure that your migration actually will complete",
    "start": "1958520",
    "end": "1964310"
  },
  {
    "text": "successfully and did complete successfully so to kick things off you",
    "start": "1964310",
    "end": "1969890"
  },
  {
    "text": "can see I'm just here I'm using an ec2 server that I have launched in uswest again you can be anywhere you want",
    "start": "1969890",
    "end": "1976160"
  },
  {
    "text": "doesn't really matter TMS is available in every region around the world today and I'm just going to start off by",
    "start": "1976160",
    "end": "1983120"
  },
  {
    "text": "showing you my source and target databases so I'm just going to use a free queer",
    "start": "1983120",
    "end": "1988280"
  },
  {
    "start": "1985000",
    "end": "2055000"
  },
  {
    "text": "d beaver again you're totally welcome to use whatever tools you want to read it",
    "start": "1988280",
    "end": "1993620"
  },
  {
    "text": "from your databases I personally like D beaver simply because it is an inversion but I'll just ignore that it works with",
    "start": "1993620",
    "end": "2000610"
  },
  {
    "text": "all different database engines so you can see here on the Left I have set up connections to a range of databases so",
    "start": "2000610",
    "end": "2007330"
  },
  {
    "text": "what team quick look at is Oracle database as I mentioned there is this SOE schema sales order entry and it has",
    "start": "2007330",
    "end": "2015280"
  },
  {
    "text": "quite a range of tables it's not too huge really but you can go have a look",
    "start": "2015280",
    "end": "2020770"
  },
  {
    "text": "at it and say if we check out the customer table we'll read the information and you see there's a bunch",
    "start": "2020770",
    "end": "2026740"
  },
  {
    "text": "of customers now it's obviously just generated information I don't think there's too many people with these exact",
    "start": "2026740",
    "end": "2032679"
  },
  {
    "text": "names I've never met anybody with the last name of Rutter before but nonetheless we'll get that migrated across to our Arora target just to prove",
    "start": "2032679",
    "end": "2040900"
  },
  {
    "text": "there's no funny business going on if I look at my Arora Postgres target you can see in here I have in essence an empty",
    "start": "2040900",
    "end": "2048158"
  },
  {
    "text": "database just some default schemas that get created when you launch Aurora there's nothing there so let's kick",
    "start": "2048159",
    "end": "2055840"
  },
  {
    "start": "2055000",
    "end": "2095000"
  },
  {
    "text": "things off as I mentioned the schema conversion tool is the first step for any database migration so it's free",
    "start": "2055840",
    "end": "2062500"
  },
  {
    "text": "download available on our website I'm just gonna launch it it this version of",
    "start": "2062500",
    "end": "2068200"
  },
  {
    "text": "course I'm running on Windows but it works on Mac and Linux no worries at all if you do download it the only thing to",
    "start": "2068200",
    "end": "2075940"
  },
  {
    "text": "know is you need to install the JDBC driver for the database engines you're working with the lawyers told us we",
    "start": "2075940",
    "end": "2081250"
  },
  {
    "text": "couldn't distribute it because they weren't our drivers so that's just the one little bit of technical stuff you",
    "start": "2081250",
    "end": "2086470"
  },
  {
    "text": "need to do to get her get it writing so I'm going to kick things off you know",
    "start": "2086470",
    "end": "2092020"
  },
  {
    "text": "your new project and what is it I'm going to do remember I mentioned SCT can",
    "start": "2092020",
    "end": "2098230"
  },
  {
    "start": "2095000",
    "end": "2135000"
  },
  {
    "text": "boat handle both transactional database conversions as well as data warehouse conversions so if I switch that tab",
    "start": "2098230",
    "end": "2103450"
  },
  {
    "text": "there you can see I now get my range of data warehouses it has a green comb what have you to convert but I'm going to do",
    "start": "2103450",
    "end": "2110920"
  },
  {
    "text": "database and I'm going to go from Oracle and as you can see we can go from a range of engines to a bra or Postgres",
    "start": "2110920",
    "end": "2118820"
  },
  {
    "text": "and hit okay so what I wants you to do is define your connections to the",
    "start": "2118820",
    "end": "2124710"
  },
  {
    "text": "databases so your you guys are all gonna laugh at this it's super secure but you know what it's a demo database I don't",
    "start": "2124710",
    "end": "2130500"
  },
  {
    "text": "care if you connect to it and I'm gonna connect to my database you can see I've",
    "start": "2130500",
    "end": "2135630"
  },
  {
    "start": "2135000",
    "end": "2280000"
  },
  {
    "text": "done it before it's remembered some of the parameters but it doesn't save your password for obvious reasons connect in",
    "start": "2135630",
    "end": "2145910"
  },
  {
    "text": "and I can connect minor or instance on the other side all right so there's that",
    "start": "2145910",
    "end": "2154860"
  },
  {
    "text": "screenshot you saw from earlier so my target as you can see not much there and",
    "start": "2154860",
    "end": "2159990"
  },
  {
    "text": "my source there's a fair bit of stuff so I'm going to do an analysis on the SOE",
    "start": "2159990",
    "end": "2166860"
  },
  {
    "text": "schema go here and I'll just start",
    "start": "2166860",
    "end": "2172080"
  },
  {
    "text": "things off by asking it to create a report",
    "start": "2172080",
    "end": "2177230"
  },
  {
    "text": "and this is that assessment report I mentioned earlier so this one's gonna be a bit of a cut-down version because I've",
    "start": "2180240",
    "end": "2186240"
  },
  {
    "text": "already told it that I'm going to Aurora Postgres but normally there'd be a couple extra sections of the bottom",
    "start": "2186240",
    "end": "2191490"
  },
  {
    "text": "saying okay this is what it would look like if you went to Aurora my sequel or my sequel give it a second here there we",
    "start": "2191490",
    "end": "2202680"
  },
  {
    "text": "go eventually",
    "start": "2202680",
    "end": "2210740"
  },
  {
    "text": "so it's looking through all the metadata on that schema looking at every every procedure every table figuring out how",
    "start": "2213410",
    "end": "2221090"
  },
  {
    "text": "it's going to convert it and here we have that assessment report so it says what my source was",
    "start": "2221090",
    "end": "2226340"
  },
  {
    "text": "and that's Oracle 11g obviously and gives you a nice executive summary which",
    "start": "2226340",
    "end": "2231500"
  },
  {
    "text": "you know you could send off to whoever actually likes to read these things it says what it's going to convert and because we're going to Postgres you can",
    "start": "2231500",
    "end": "2238610"
  },
  {
    "text": "see we're actually gonna have a pretty good conversion ratio so our schema is looking pretty good our tables and",
    "start": "2238610",
    "end": "2244490"
  },
  {
    "text": "constraints are good a little bit rougher when you get down to the the code objects sorry about that but you",
    "start": "2244490",
    "end": "2251780"
  },
  {
    "text": "know overall not too bad so it's important to note that database migration is always a project it's not",
    "start": "2251780",
    "end": "2257270"
  },
  {
    "text": "just gonna be click button so there's gonna be some manual work in here but statistically speaking based on the usage that we have seen we find that if",
    "start": "2257270",
    "end": "2264260"
  },
  {
    "text": "we look at this particular example or our called the Postgres we get about 85% conversion ratio alright and then if you",
    "start": "2264260",
    "end": "2271970"
  },
  {
    "text": "switch the action items you can see it tells you all the things that it needs you to actually fix manually so if we",
    "start": "2271970",
    "end": "2280490"
  },
  {
    "text": "expand this out a little bit you can see here's our tables there's some issues with the views but let's just go and",
    "start": "2280490",
    "end": "2287000"
  },
  {
    "text": "click on that customer table we were using earlier and you can see here actually hold on let me change the view",
    "start": "2287000",
    "end": "2293000"
  },
  {
    "text": "here view main view alright so here's the customer table",
    "start": "2293000",
    "end": "2299170"
  },
  {
    "text": "let me just apply that to the target all right now I need to convert it sorry my",
    "start": "2299170",
    "end": "2304760"
  },
  {
    "text": "bad convert schema yes",
    "start": "2304760",
    "end": "2310330"
  },
  {
    "text": "alright go back to that customer table at the top this is what the table looked",
    "start": "2313470",
    "end": "2320950"
  },
  {
    "text": "like in Oracle and at the bottom here's what that same table looks like in Postgres and I can do that for any table",
    "start": "2320950",
    "end": "2328110"
  },
  {
    "text": "exactly how it converts right then same goes for the views triggers procedures",
    "start": "2328110",
    "end": "2334090"
  },
  {
    "text": "basically you can go through each of the objects and see what it looked like on the source and what its gonna look like on the target and the general idea is",
    "start": "2334090",
    "end": "2340120"
  },
  {
    "text": "when you're happy with it you can right click and apply it to the database I just want to highlight you can also save",
    "start": "2340120",
    "end": "2345190"
  },
  {
    "text": "it as sequel so if you don't want to apply it to your database you can just dump it as an SQL file which you can",
    "start": "2345190",
    "end": "2350920"
  },
  {
    "text": "either edit and/or apply manually at a later point in time so I'm gonna apply",
    "start": "2350920",
    "end": "2356800"
  },
  {
    "text": "that target and when I've applied that target I just want to highlight a couple things I will quickly go back to my",
    "start": "2356800",
    "end": "2364870"
  },
  {
    "text": "query tool although I could do it in SCT do a refresh here and you'll see now I",
    "start": "2364870",
    "end": "2372640"
  },
  {
    "text": "have my SOE schema on Aurora but if I go in and look at this you'll",
    "start": "2372640",
    "end": "2378700"
  },
  {
    "text": "see two things first off everything's lower case because in Postgres things by default are lower case Oracle it's",
    "start": "2378700",
    "end": "2383830"
  },
  {
    "text": "uppercase so it's just what difference and of course if I look at this table here a custom table is no data so",
    "start": "2383830",
    "end": "2390130"
  },
  {
    "text": "remember step one SCT you convert your schema step two DMS move your data the",
    "start": "2390130",
    "end": "2396160"
  },
  {
    "text": "other thing to highlight is this little thing that appeared here AWS Oracle ext",
    "start": "2396160",
    "end": "2401980"
  },
  {
    "text": "what this is this is an extension pack that we install on the target database and all it is is a library of functions",
    "start": "2401980",
    "end": "2409020"
  },
  {
    "text": "to help map find things that exist in this case an Oracle to things that maybe don't exist in Postgres so trying to",
    "start": "2409020",
    "end": "2416470"
  },
  {
    "text": "replicate some of the functionality so if we look at it and go into say procedures you can see we've got a whole",
    "start": "2416470",
    "end": "2421720"
  },
  {
    "text": "range of procedures here that help replicate Oracle information and what this does is it prevents us when we're",
    "start": "2421720",
    "end": "2428050"
  },
  {
    "text": "converting your schema from your source to your target atom to rewrite the same thing again and again and again and you",
    "start": "2428050",
    "end": "2434290"
  },
  {
    "text": "just I don't know pick an example anything like you see we've got some two chars to handle some character mapping",
    "start": "2434290",
    "end": "2439960"
  },
  {
    "text": "and that sort of stuff all right so now just to show some other",
    "start": "2439960",
    "end": "2446529"
  },
  {
    "start": "2445000",
    "end": "2565000"
  },
  {
    "text": "stuff I've got some neat queries here if we look at Oracle let's just have a look",
    "start": "2446529",
    "end": "2451839"
  },
  {
    "text": "at this kind of data that we're looking at moving go back to D beaver and",
    "start": "2451839",
    "end": "2457779"
  },
  {
    "text": "connect to my Oracle database SOE",
    "start": "2457779",
    "end": "2463640"
  },
  {
    "text": "[Music] alright let's read the data paste that",
    "start": "2463640",
    "end": "2470589"
  },
  {
    "text": "in there change my schema and run so you",
    "start": "2470589",
    "end": "2477819"
  },
  {
    "text": "can see we're looking about moving you know big and a half of data give or take okay the other thing I need to do is",
    "start": "2477819",
    "end": "2484809"
  },
  {
    "text": "drop my foreign keys so as part of a migration if you've got foreign key constraints you're gonna get some",
    "start": "2484809",
    "end": "2489999"
  },
  {
    "text": "interesting behavior you don't want that to break you know if you're not moving things in exactly the right order you'll",
    "start": "2489999",
    "end": "2496569"
  },
  {
    "text": "get some errors with your migrations so I've just got this script that I've got off the internet you can find it similar",
    "start": "2496569",
    "end": "2501879"
  },
  {
    "text": "things million different places and I'm just gonna go and run it against my Arora Postgres target",
    "start": "2501879",
    "end": "2508499"
  },
  {
    "text": "make sure I'm looking at the right thing SOE schema going and what it does is I",
    "start": "2514630",
    "end": "2521780"
  },
  {
    "text": "create a temporary table to hold these foreign keys and constraints so that if I need to recreate them later I can have",
    "start": "2521780",
    "end": "2528890"
  },
  {
    "text": "a run this run that here off it goes and",
    "start": "2528890",
    "end": "2534410"
  },
  {
    "text": "if I do a refresh you can see I have this dropped foreign keys table and",
    "start": "2534410",
    "end": "2541810"
  },
  {
    "text": "there's all the foreign keys that were dropped from my Postgres database that I can essentially execute every one of",
    "start": "2541810",
    "end": "2549200"
  },
  {
    "text": "these statements in the table once the migrations completed to put them back on alright so just uh just a bit of a",
    "start": "2549200",
    "end": "2555140"
  },
  {
    "text": "precondition step you can do some database engines like my sequel you can add a parameter to the connection string",
    "start": "2555140",
    "end": "2560300"
  },
  {
    "text": "which just disables them in general but Postgres doesn't have that so I need to do that manually alright so now I",
    "start": "2560300",
    "end": "2568940"
  },
  {
    "start": "2565000",
    "end": "2605000"
  },
  {
    "text": "mentioned the DMS and SCT have very tight integration I can go and create the migration tasks inside DMS but I can",
    "start": "2568940",
    "end": "2575630"
  },
  {
    "text": "also do it straight from SCT so I can just right click here and I go create DMS tasks I have to give it a name so",
    "start": "2575630",
    "end": "2584420"
  },
  {
    "text": "let's just call this Tuesday night just because that's what it is which replication server I want to use",
    "start": "2584420",
    "end": "2591320"
  },
  {
    "text": "and it already found by endpoints my Oracle source and my Aurora target and I want to migrate the existing data which",
    "start": "2591320",
    "end": "2597620"
  },
  {
    "text": "is what we call full load as I move the data as it stands now but I also want to replicate the ongoing changes and a few",
    "start": "2597620",
    "end": "2605150"
  },
  {
    "start": "2605000",
    "end": "2685000"
  },
  {
    "text": "other options don't really need to worry about it right now and hit create so as",
    "start": "2605150",
    "end": "2610490"
  },
  {
    "text": "I do that if I go here to AWS to the console I'm gonna sign in go to DMS and",
    "start": "2610490",
    "end": "2620050"
  },
  {
    "text": "you'll see if we go down to tasks I have this task creating here so it's",
    "start": "2620050",
    "end": "2627380"
  },
  {
    "text": "automatically connected to my replication server and is creating the task for me once it's complete we need",
    "start": "2627380",
    "end": "2635750"
  },
  {
    "text": "to make a small edit to it and this is always the fun bits with demos is you know how do you kill time while things",
    "start": "2635750",
    "end": "2642380"
  },
  {
    "text": "are happening but it creates pretty quickly if I hit a refresh now if they were go looks like it's ready I'm going to",
    "start": "2642380",
    "end": "2650240"
  },
  {
    "text": "actually go and modify it and one of the reasons I'm going to modify it is because there's just one thing that we",
    "start": "2650240",
    "end": "2655520"
  },
  {
    "text": "need to add to the system and that is another transformation role so with a",
    "start": "2655520",
    "end": "2660560"
  },
  {
    "text": "DMS task I should actually show you guys exactly what it is your task specifies",
    "start": "2660560",
    "end": "2668830"
  },
  {
    "text": "what it is you're moving so I'm going to as I said before I am going to make sure",
    "start": "2668830",
    "end": "2676750"
  },
  {
    "text": "logging is enabled I think I showed that and also enable data validation I know I said I was going to show data validation",
    "start": "2676750",
    "end": "2682580"
  },
  {
    "text": "which make sure things work properly so turn that on and what it says this is",
    "start": "2682580",
    "end": "2688070"
  },
  {
    "text": "what SCT created for me automatically it's saying grab all the data from SCT no matter what the table name is and",
    "start": "2688070",
    "end": "2693950"
  },
  {
    "text": "included so this is I mentioned earlier you can filter out certain records this is where you would edit that and narrow",
    "start": "2693950",
    "end": "2699560"
  },
  {
    "text": "it down if you wanted it automatically adds some transformation rules again like I said earlier everything Oracle is",
    "start": "2699560",
    "end": "2705320"
  },
  {
    "text": "uppercase so it transforms the schema from upper to lower case as well as the table from upper to lower case but I",
    "start": "2705320",
    "end": "2711140"
  },
  {
    "text": "need to add one more little rule in there and that is I'm going to scroll down for my columns on my SOE schema for",
    "start": "2711140",
    "end": "2729470"
  },
  {
    "text": "all tables actually you know what I'll just leave it as a wild-card and doesn't really matter does it for all tables for",
    "start": "2729470",
    "end": "2737270"
  },
  {
    "text": "all schemas for all columns I want to make it lower case and the reason it",
    "start": "2737270",
    "end": "2742910"
  },
  {
    "text": "didn't do that is you don't need to worry about transforming your two tables to lowercase unless you have a task that",
    "start": "2742910",
    "end": "2748610"
  },
  {
    "text": "replicates changes because we never touched the columns with an update statement otherwise so that's why it's",
    "start": "2748610",
    "end": "2753980"
  },
  {
    "text": "not in SCT by default the other thing that's going to do is let me assure it's",
    "start": "2753980",
    "end": "2761090"
  },
  {
    "text": "not going to start start tasks on modify I do not want to start it I'm just gonna hit OK I'm probably gonna get an",
    "start": "2761090",
    "end": "2766910"
  },
  {
    "start": "2765000",
    "end": "2865000"
  },
  {
    "text": "interesting message here all right so it's modifying the tasks I've got 13",
    "start": "2766910",
    "end": "2772760"
  },
  {
    "text": "minutes to go I just want to highlight a new feature that we have out there now as soon as the modifying is complete",
    "start": "2772760",
    "end": "2781690"
  },
  {
    "text": "there's two parts to data validation so you want to know whether things are going to work before you start a",
    "start": "2782440",
    "end": "2788960"
  },
  {
    "text": "migration task and you want to know that they work when you finish so what were you actually added in the last couple",
    "start": "2788960",
    "end": "2794330"
  },
  {
    "text": "weeks is the ability to check all your data types before you kick off a migration and that's what this assess",
    "start": "2794330",
    "end": "2800690"
  },
  {
    "text": "option is here before that it was possible that if a data type wasn't supported between source and target you",
    "start": "2800690",
    "end": "2807050"
  },
  {
    "text": "might not find out until you actually got to the point of hitting that data type but now with DMS you can optionally",
    "start": "2807050",
    "end": "2813200"
  },
  {
    "text": "I do a query on the database ahead of time and see what is supported and what is not so now that it's been modern the",
    "start": "2813200",
    "end": "2819800"
  },
  {
    "text": "task has been modified I can run the assessment and check out all of the data",
    "start": "2819800",
    "end": "2825500"
  },
  {
    "text": "types in the database to make sure they're going to work when going from Oracle to Postgres so this takes a",
    "start": "2825500",
    "end": "2831710"
  },
  {
    "text": "minute or so to run but what it does is",
    "start": "2831710",
    "end": "2839300"
  },
  {
    "text": "it just ensures that during a large migration that you're not going to encounter problems you know 10 hours",
    "start": "2839300",
    "end": "2848180"
  },
  {
    "text": "into things that's just not not a good scenario so this is some of the feedback that we got from customers that we built",
    "start": "2848180",
    "end": "2854060"
  },
  {
    "text": "into the system to try to make the migrations smoother as I said it does",
    "start": "2854060",
    "end": "2860089"
  },
  {
    "text": "take about a minute or so to run but it's a minute well-spent later yeah you have a question the sequel server again",
    "start": "2860089",
    "end": "2870830"
  },
  {
    "start": "2865000",
    "end": "2935000"
  },
  {
    "text": "depends on your target but it's sort of in this in the 75 range it's not quite as good but yeah to Postgres but what's",
    "start": "2870830",
    "end": "2877790"
  },
  {
    "text": "interesting about it is we collect anonymous usage statistics and we sort of see where it is that people are",
    "start": "2877790",
    "end": "2883220"
  },
  {
    "text": "having trouble and one thing that's quite neat about SCT is we have new releases roughly speaking in every four",
    "start": "2883220",
    "end": "2889820"
  },
  {
    "text": "weeks so every four weeks you're likely to get a higher conversion ratio than you did before I'm not gonna see you",
    "start": "2889820",
    "end": "2894859"
  },
  {
    "text": "want to work wait forever because you're never gonna hit 100% it's just not realistic to ever expect it but it is",
    "start": "2894859",
    "end": "2900770"
  },
  {
    "text": "definitely been improving as time goes on yeah",
    "start": "2900770",
    "end": "2906970"
  },
  {
    "text": "okay so by default it's it's set down to about two minutes but you can actually",
    "start": "2907110",
    "end": "2913000"
  },
  {
    "text": "expect it more in the neighborhood of 30 seconds and what's interesting depending on your system configuration we see",
    "start": "2913000",
    "end": "2919120"
  },
  {
    "text": "those those changes flowing through within five seconds sometimes but you know we'd say two minutes just for a",
    "start": "2919120",
    "end": "2924730"
  },
  {
    "text": "safety bet or a safety buffer I should say but what you'll see when I get to it in the demo is it's much much faster",
    "start": "2924730",
    "end": "2930460"
  },
  {
    "text": "than that all right let's just see if this thing is up to date go in here go",
    "start": "2930460",
    "end": "2939610"
  },
  {
    "text": "to assessment results now it really is still thinking yep yeah yeah that's",
    "start": "2939610",
    "end": "2952480"
  },
  {
    "text": "supported yes",
    "start": "2952480",
    "end": "2956250"
  },
  {
    "text": "exactly yes we mined the logs through the native api's that are available from the database engine itself yeah yeah",
    "start": "2959329",
    "end": "2971460"
  },
  {
    "text": "it's all I've got a slide on it and a little bit of a little bit later I don't want to tell you the wrong thing but yeah there's definitely versions that",
    "start": "2971460",
    "end": "2977430"
  },
  {
    "text": "are supported if you have sequel mm you're out of luck but most of the newer ones you should be alright yes I mean",
    "start": "2977430",
    "end": "2992729"
  },
  {
    "text": "can everyone hear the questions or do want to Mike okay yeah good point good",
    "start": "2992729",
    "end": "2998069"
  },
  {
    "text": "point quick question just want to know why the sauce because we find that the",
    "start": "2998069",
    "end": "3004039"
  },
  {
    "text": "sauce that does not have a redshift how come you can I use us rescued by the sauce ah that that's where SCT comes in",
    "start": "3004039",
    "end": "3011359"
  },
  {
    "text": "so again when you're talking warehouses you you need to use the schema conversion tool to do the migration but",
    "start": "3011359",
    "end": "3018769"
  },
  {
    "text": "if you're going from a relational database you can use redshift as a target sorry did you ask redshift as a",
    "start": "3018769",
    "end": "3024259"
  },
  {
    "text": "source ah no these products don't support redshift as a source but registers own methods of",
    "start": "3024259",
    "end": "3030499"
  },
  {
    "text": "dumping data out its redshift as a target or density can only be a packet",
    "start": "3030499",
    "end": "3036619"
  },
  {
    "text": "cannot be a sauce yes correct for redshift Richards the bit of an asterisks on there if you will but but all the other engines like",
    "start": "3036619",
    "end": "3042499"
  },
  {
    "text": "Oracle's sequel server my sequel they're all source and target yes",
    "start": "3042499",
    "end": "3049509"
  },
  {
    "text": "nope none whatsoever in fact we encourage ongoing replication as long as you have enabled multiple availability",
    "start": "3053330",
    "end": "3059220"
  },
  {
    "text": "zone now there's a few more questions but I see the report has finished we'll have time for some more questions at the",
    "start": "3059220",
    "end": "3064830"
  },
  {
    "text": "end I just wanna make sure we get through the demo so you can see now the reports finished if I hit open you can see which data",
    "start": "3064830",
    "end": "3072750"
  },
  {
    "text": "types are supported in which are not now what's interesting this is this is version 1 of this feature it was only",
    "start": "3072750",
    "end": "3078180"
  },
  {
    "text": "released about 10 days back it looks at the entire schema on the database as",
    "start": "3078180",
    "end": "3083280"
  },
  {
    "text": "opposed to just the schema we're looking at so if you look at these unsupported data types you'll see they're all in the",
    "start": "3083280",
    "end": "3088619"
  },
  {
    "text": "system schema so what that means is it's gonna work fine from a data type point of view okay so no other reports run I'm",
    "start": "3088619",
    "end": "3096990"
  },
  {
    "start": "3095000",
    "end": "3600000"
  },
  {
    "text": "going to actually kick it off all right",
    "start": "3096990",
    "end": "3102930"
  },
  {
    "text": "so task is selected I'm going to go and hit start so task gets running and if we",
    "start": "3102930",
    "end": "3111540"
  },
  {
    "text": "give it a second or two and we look at the table statistics tab scroll up a",
    "start": "3111540",
    "end": "3117060"
  },
  {
    "text": "little bit it's never as fast as you",
    "start": "3117060",
    "end": "3123180"
  },
  {
    "text": "want it to be during the demo we should see this appearing pretty quickly",
    "start": "3123180",
    "end": "3130020"
  },
  {
    "text": "it still says starting there we go so you can see I make us a little bit",
    "start": "3130020",
    "end": "3136950"
  },
  {
    "text": "bigger for you guys oh she had better resolution to share but here we have all the tables migrating across it knows how",
    "start": "3136950",
    "end": "3143910"
  },
  {
    "text": "many rows we're going to migrate and it also tells you how many records were going to validate so you remember when I",
    "start": "3143910",
    "end": "3150630"
  },
  {
    "text": "went and modified that task I turned on the check box that says enable validation so because I did that you see",
    "start": "3150630",
    "end": "3155700"
  },
  {
    "text": "these pending records to validate here what you also see are the inserts deletes and updates those are gonna all",
    "start": "3155700",
    "end": "3162720"
  },
  {
    "text": "stay at zero for the moment but what that is is for the change data capture component of a migration you'll see how",
    "start": "3162720",
    "end": "3169440"
  },
  {
    "text": "many of these statements have been run reflecting changes that have happened on database so as this runs I should be",
    "start": "3169440",
    "end": "3177180"
  },
  {
    "text": "able to it's probably already moved most of the data in all honesty is pretty quick yet so you see I just did a",
    "start": "3177180",
    "end": "3182280"
  },
  {
    "text": "refresh there so you can see now that we've actually already moved some data and validated some so this last",
    "start": "3182280",
    "end": "3188610"
  },
  {
    "text": "column here was pending records left to validate so you can see we have validated all 1,000 records it doesn't validate records where there",
    "start": "3188610",
    "end": "3195270"
  },
  {
    "text": "is no primary key so at the moment our data validation is dependent on you having a primary key on your table so",
    "start": "3195270",
    "end": "3201150"
  },
  {
    "text": "you see it won't do those but if I just leave that alone for a minute and I flip back to the database query",
    "start": "3201150",
    "end": "3207690"
  },
  {
    "text": "tool what will probably find if I read the data you can see there we have our",
    "start": "3207690",
    "end": "3214200"
  },
  {
    "text": "data in Aurora or Postgres so it's the same customer table from Oracle hasn't been might have migrated across to",
    "start": "3214200",
    "end": "3219990"
  },
  {
    "text": "Aurora Postgres now the last little bit of a demo I want a little bit of demo I want to do is kick off swing bench to",
    "start": "3219990",
    "end": "3226230"
  },
  {
    "text": "show that a load will happen on the system so just do a refresh here we",
    "start": "3226230",
    "end": "3231420"
  },
  {
    "text": "should probably see most everything's moved across yeah you can see here we've got our million rows of order items and",
    "start": "3231420",
    "end": "3237780"
  },
  {
    "text": "you know 700 thousand of orders everything's gone across so I'm gonna kick off swing bench to actually",
    "start": "3237780",
    "end": "3243000"
  },
  {
    "text": "generate load to show you that the c-d-c component of it works that is the change data capture so to",
    "start": "3243000",
    "end": "3249450"
  },
  {
    "text": "kick off swing bench I just need to go to my desktop and launch the tool so",
    "start": "3249450",
    "end": "3257430"
  },
  {
    "text": "again swing bench a free tool written by an Oracle developer ironically enough and I can go here and generate load on",
    "start": "3257430",
    "end": "3264180"
  },
  {
    "text": "my Oracle system just make sure I can still connect to it there we go and I'm",
    "start": "3264180",
    "end": "3270000"
  },
  {
    "text": "gonna make some performance changes if you will so I'm gonna say let's put I don't know 4 users on the system at once",
    "start": "3270000",
    "end": "3277010"
  },
  {
    "text": "it's gonna create a fair bit of load you can split up the ratio based on which",
    "start": "3277010",
    "end": "3282330"
  },
  {
    "text": "the tables you want it to hit but I'm gonna keep it pretty simple for the sake of demo and just kick that off here and",
    "start": "3282330",
    "end": "3288480"
  },
  {
    "text": "we should see these graphs going and there you can see it we're getting you know a couple hundred transactions per",
    "start": "3288480",
    "end": "3293760"
  },
  {
    "text": "minute or transactions per second depends which ratio you want to look at and then what we'll see if I go back to",
    "start": "3293760",
    "end": "3300180"
  },
  {
    "text": "DMS if I do a refresh on this but it'll",
    "start": "3300180",
    "end": "3305580"
  },
  {
    "text": "refresh on this table you can see now I've got inserts updates happening so DMS replicates these changes across and",
    "start": "3305580",
    "end": "3313080"
  },
  {
    "text": "to your earlier question about latency well that wasn't 30 seconds or two minutes that's just",
    "start": "3313080",
    "end": "3318180"
  },
  {
    "text": "that the canline i like to use it replicates almost instantly again depending on the load of your database",
    "start": "3318180",
    "end": "3323940"
  },
  {
    "text": "and the bandwidth and your connectivity right so there we have it DMS has",
    "start": "3323940",
    "end": "3328950"
  },
  {
    "text": "migrated information across for a bulk load and is replicating changes so I'm",
    "start": "3328950",
    "end": "3335100"
  },
  {
    "text": "just gonna switch back now to the PowerPoint look at that yeah so dbo dmoz",
    "start": "3335100",
    "end": "3344610"
  },
  {
    "text": "replicates some DDL to get into exactly which statements again look at our documentation but basically what it",
    "start": "3344610",
    "end": "3350640"
  },
  {
    "text": "replicates is DDL changes to the table so if you add a new column or you add a new table that'll get replicated across",
    "start": "3350640",
    "end": "3356610"
  },
  {
    "text": "but if you were to say make a change to a trigger on the table that doesn't at present get replicated across it's",
    "start": "3356610",
    "end": "3362670"
  },
  {
    "text": "something we're looking at alright so we did the demo whatever other customers",
    "start": "3362670",
    "end": "3369000"
  },
  {
    "text": "done but we all see these slides I'm not gonna go into great detail needless to say we've had a lot of people with a lot",
    "start": "3369000",
    "end": "3374940"
  },
  {
    "text": "of success doing database migration there's some names you probably recognize up there on the board they've done all sorts of very variety",
    "start": "3374940",
    "end": "3381090"
  },
  {
    "text": "of things whether it's minor version upgrades through to migrations from Oracle to open source or possibly things",
    "start": "3381090",
    "end": "3388620"
  },
  {
    "text": "like data warehouses so lots of interesting stuff there I did mention that I was going to talk about other",
    "start": "3388620",
    "end": "3395460"
  },
  {
    "text": "things you can do with DMS here's some good examples you can do classic of EPC",
    "start": "3395460",
    "end": "3400530"
  },
  {
    "text": "I said that earlier and analytics in the cloud is another really big one so it's",
    "start": "3400530",
    "end": "3406050"
  },
  {
    "text": "also good to highlight cheap read replicas DMS very inexpensive service unless you go and fire for the biggest",
    "start": "3406050",
    "end": "3411870"
  },
  {
    "text": "of biggest instances it's dollars a day it's it's very very inexpensive and in fact in about two slides from now we're",
    "start": "3411870",
    "end": "3418650"
  },
  {
    "text": "going to see the prices supported databases quite a range some of them are",
    "start": "3418650",
    "end": "3425310"
  },
  {
    "text": "definitely more popular than others so there's a question on which versions of sequel server are supported that's right up there on the screen as well as it",
    "start": "3425310",
    "end": "3431970"
  },
  {
    "text": "varies a little bit based on whether it's an ec2 on-premise or RDS instance all of this information is on our",
    "start": "3431970",
    "end": "3438570"
  },
  {
    "text": "website and gets updated frequently sources and targets vary slightly so",
    "start": "3438570",
    "end": "3444450"
  },
  {
    "text": "that was sources we saw earlier the the variation is because some of those older database engines don't have an ability",
    "start": "3444450",
    "end": "3450990"
  },
  {
    "text": "for us to read from the transaction blog that's the only reason there's the difference although in reality I can't imagine you",
    "start": "3450990",
    "end": "3457030"
  },
  {
    "text": "would migrate to an older version just because we support as a target but you know it's there anyways pricing pricing",
    "start": "3457030",
    "end": "3464400"
  },
  {
    "text": "again our website is the best place to go for this this is just an example of the pricing in u.s. East you can see",
    "start": "3464400",
    "end": "3470920"
  },
  {
    "text": "it's pretty minimal only if you get to the really big instances are you even getting into the dollars per hour so we",
    "start": "3470920",
    "end": "3477790"
  },
  {
    "text": "really like to say you can migrate a terabyte for you know five dollars or so and that's the case like I mentioned",
    "start": "3477790",
    "end": "3483280"
  },
  {
    "text": "earlier free DMS is something that we launched fairly recently if your target is an aurora engine dynamo or why am i",
    "start": "3483280",
    "end": "3492280"
  },
  {
    "text": "blanking out a redshift it's free right so so no worries there with your",
    "start": "3492280",
    "end": "3497410"
  },
  {
    "text": "migrations resources available okay me",
    "start": "3497410",
    "end": "3502900"
  },
  {
    "text": "I'm here but I disappear for other quickly so where can you go for help after this obviously our website this is",
    "start": "3502900",
    "end": "3509560"
  },
  {
    "text": "right on the console you can see there are links here it's documentation getting started and that sort of thing",
    "start": "3509560",
    "end": "3514950"
  },
  {
    "text": "always read the manual sounds obvious but many people don't a lot of the",
    "start": "3514950",
    "end": "3520000"
  },
  {
    "text": "questions that you will ask are there features benefits that's just some fun",
    "start": "3520000",
    "end": "3525970"
  },
  {
    "text": "marketing stuff pricing how much is it really going to cost support I always",
    "start": "3525970",
    "end": "3531070"
  },
  {
    "text": "want to highlight the support forums every service a day that mobis is different our service we actually use",
    "start": "3531070",
    "end": "3536260"
  },
  {
    "text": "our forums and if you post a question there there's a good chance a database engineer from the service team is going",
    "start": "3536260",
    "end": "3541540"
  },
  {
    "text": "to answer it so that's a little backdoor into getting quick responses on any problems you may have you want any",
    "start": "3541540",
    "end": "3548830"
  },
  {
    "text": "things programmatically you can always do more programmatically with services at Amazon than you can through the",
    "start": "3548830",
    "end": "3554410"
  },
  {
    "text": "console more features available there so if you want to automate it we replicate hundreds of databases that are essentially the same I recommend you",
    "start": "3554410",
    "end": "3560350"
  },
  {
    "text": "script it out using the SDK SCT very",
    "start": "3560350",
    "end": "3565810"
  },
  {
    "text": "much the same thing there's a user guide you can download the files as I said it is totally free to use SCT and of course",
    "start": "3565810",
    "end": "3573280"
  },
  {
    "text": "we have a forum as well for SCT so the two products are related but they do",
    "start": "3573280",
    "end": "3578680"
  },
  {
    "text": "have two separate forums definitely go there for information and if you need help if you need help",
    "start": "3578680",
    "end": "3584850"
  },
  {
    "text": "there are partners that can help you with your migration they have all done mini and can use our products and as I",
    "start": "3584850",
    "end": "3590460"
  },
  {
    "text": "said any other tool in the toolbox that you may want to use to migrate we don't really mind which products you use we",
    "start": "3590460",
    "end": "3596490"
  },
  {
    "text": "just want you to migrate to the clouds so these guys are the ones to help you with it and with that I have one second left and",
    "start": "3596490",
    "end": "3602820"
  },
  {
    "text": "we're at the point of questions so that's pretty good timing yes and",
    "start": "3602820",
    "end": "3612020"
  },
  {
    "text": "actually I was told me the microphone can record I have to I have the microphone so DMS uses JDBC underneath",
    "start": "3612020",
    "end": "3622980"
  },
  {
    "text": "so well what would you say about the performance of our migrating large-scale database and then so what should I use",
    "start": "3622980",
    "end": "3628100"
  },
  {
    "text": "what size of database should I use using JDBC and then where should I move over to the choosing the the SCT client with",
    "start": "3628100",
    "end": "3638100"
  },
  {
    "text": "snowball right so that there's no upper limit on the size you can use with DMS we've had people successfully move up to",
    "start": "3638100",
    "end": "3644400"
  },
  {
    "text": "15 terabytes five terabytes is kind of our recommended rule of thumb you probably don't want to go much longer",
    "start": "3644400",
    "end": "3649710"
  },
  {
    "text": "than that larger than that I should say but it really comes down to your exact scenarios what sort of bandwidth you",
    "start": "3649710",
    "end": "3655950"
  },
  {
    "text": "have available and also how your data is structured I didn't mention that earlier if your database has like one giant",
    "start": "3655950",
    "end": "3662520"
  },
  {
    "text": "table with thousands of logs in it yeah you might have some issues moving that over the wire um anybody who originally",
    "start": "3662520",
    "end": "3669510"
  },
  {
    "text": "thought it was a great idea to put videos inside a database you know just I don't know why but you know some of",
    "start": "3669510",
    "end": "3675720"
  },
  {
    "text": "those things can limit how big you are really able to move over the wire with DMS but for a five terabyte what is it",
    "start": "3675720",
    "end": "3683270"
  },
  {
    "text": "what the performance numbers would be it varies so much based on on your",
    "start": "3683270",
    "end": "3689310"
  },
  {
    "text": "environment your infrastructure how hot your database is you know it's our rule of thumb we don't actually have anything",
    "start": "3689310",
    "end": "3695760"
  },
  {
    "text": "on paper on our website because it varies so much but you know we kind of say a terabyte every 12 hours or so",
    "start": "3695760",
    "end": "3701790"
  },
  {
    "text": "that's a rough rule of thumb gets microphone next",
    "start": "3701790",
    "end": "3708710"
  },
  {
    "text": "yeah I don't yeah it does",
    "start": "3713539",
    "end": "3721189"
  },
  {
    "text": "yes kini auto-scale the other instances there so DMS instance you can definitely",
    "start": "3721189",
    "end": "3727549"
  },
  {
    "text": "scale it up but you have to do it manually so you'll have to you know go in there and modify the instance and increase the size it doesn't do it",
    "start": "3727549",
    "end": "3733909"
  },
  {
    "text": "automatically on the fly based on load yeah yeah of course you descriptive how",
    "start": "3733909",
    "end": "3739549"
  },
  {
    "text": "does the charge that I change you to capture then does it make sense to have a larger instance when you're loading the initial load and then for change to",
    "start": "3739549",
    "end": "3745909"
  },
  {
    "text": "recap you have to manually change yeah I know I mentioned earlier the TTS our dev test and C for production migrations",
    "start": "3745909",
    "end": "3752059"
  },
  {
    "text": "actually what we find a lot of is people are using the T 2's for ongoing replication tasks just because the load",
    "start": "3752059",
    "end": "3757669"
  },
  {
    "text": "is not as big yeah there's no point having a C for extra large for a replication but we're actually working",
    "start": "3757669",
    "end": "3763189"
  },
  {
    "text": "on you on the task execution sorry was that so the pair our sort of charges that you have is the only charges when",
    "start": "3763189",
    "end": "3770299"
  },
  {
    "text": "your event or task is running know the the hourly charges for DMS are while the instance is running so definitely when",
    "start": "3770299",
    "end": "3777139"
  },
  {
    "text": "you're done your migration turn the thing off okay yeah all right yeah",
    "start": "3777139",
    "end": "3786739"
  },
  {
    "text": "definitely DMS is really region agnostic you can you can pull data from US East and insert it into Narita if you want to",
    "start": "3786739",
    "end": "3795549"
  },
  {
    "text": "yeah but you remember I mentioned you don't want to go bi-directional because then you start getting some other being",
    "start": "3795609",
    "end": "3800859"
  },
  {
    "text": "yeah yeah no worries",
    "start": "3800859",
    "end": "3805058"
  },
  {
    "text": "so if you don't use SCT for your schema DMS will create tables for you on your",
    "start": "3811370",
    "end": "3818010"
  },
  {
    "text": "target that it needs to do a migration but it's just going to create the basic table it's not going to do any triggers",
    "start": "3818010",
    "end": "3823950"
  },
  {
    "text": "or foreign keys it's not going to do procedures but it will create the table for you it's always always using JDBC -",
    "start": "3823950",
    "end": "3838320"
  },
  {
    "text": "well during the replication it's actually reading the using the API for the source database engine and getting",
    "start": "3838320",
    "end": "3845070"
  },
  {
    "text": "the information out that way for all the sources we support yeah yeah I mean",
    "start": "3845070",
    "end": "3850980"
  },
  {
    "text": "there's there's some limitations on there like today we don't support ongoing replication if RDS sequel server",
    "start": "3850980",
    "end": "3856380"
  },
  {
    "text": "is a source but you know these are the things that change as we develop new capabilities no so redshifts not a",
    "start": "3856380",
    "end": "3864540"
  },
  {
    "text": "source yeah redshift is a target yeah you bet if you're reading from an Oracle",
    "start": "3864540",
    "end": "3870120"
  },
  {
    "text": "database feeding into redshift will replicate those changes across",
    "start": "3870120",
    "end": "3874580"
  },
  {
    "text": "yeah so I mean some of the things were beholden to the the target database engine and what it supports behind the",
    "start": "3883680",
    "end": "3890170"
  },
  {
    "text": "scenes with redshift is a target we actually do use s3 so we'll extract information out from whatever the source",
    "start": "3890170",
    "end": "3895449"
  },
  {
    "text": "database engine is we'll create files we put in your s3 bucket and then we call the ridge of copy command to ingest the",
    "start": "3895449",
    "end": "3901359"
  },
  {
    "text": "information in its it's definitely not as performant as if you're using a relational database as a target yeah so",
    "start": "3901359",
    "end": "3909999"
  },
  {
    "text": "for a chief did does it automatically also create a sort key disk keys yeah actually that's a good point I didn't",
    "start": "3909999",
    "end": "3916119"
  },
  {
    "text": "mention that purely due to time constraints but with redshift we actually analyze especially in the data",
    "start": "3916119",
    "end": "3923529"
  },
  {
    "text": "warehouse space we analyze your your your usage of it if you will using the various metadata components that are",
    "start": "3923529",
    "end": "3930430"
  },
  {
    "text": "there and we create excuse me sort and distribution keys automatically in the range of target and on top of that if",
    "start": "3930430",
    "end": "3936279"
  },
  {
    "text": "you already have a redshift instance we can optimize that redshift instance so you can point SCT at an existing",
    "start": "3936279",
    "end": "3941709"
  },
  {
    "text": "redshift instance and will recommend optimized distributions or keys and there's some dials you can twit twirl",
    "start": "3941709",
    "end": "3948069"
  },
  {
    "text": "inside SCT to sort of indicate some of your preferences if you will during that",
    "start": "3948069",
    "end": "3953589"
  },
  {
    "text": "process Oh like like column compression and other things I can yeah dude yeah so yeah we definitely it's pretty similar",
    "start": "3953589",
    "end": "3960099"
  },
  {
    "text": "anything else yes",
    "start": "3960099",
    "end": "3964289"
  },
  {
    "text": "so again the replication is one way so it's not so much of a compare but as",
    "start": "3968710",
    "end": "3974089"
  },
  {
    "text": "long as the log information is still available on the source we're just gonna read through yeah exactly",
    "start": "3974089",
    "end": "3981880"
  },
  {
    "text": "sorry is there any what yeah so for every database if you look in our",
    "start": "3985000",
    "end": "3991010"
  },
  {
    "text": "documentation we specify the exact permissions that are required obviously you can't you can't feed a",
    "start": "3991010",
    "end": "3996859"
  },
  {
    "text": "replication stream if you just have very very basic read permissions but you don't need complete superuser either",
    "start": "3996859",
    "end": "4005130"
  },
  {
    "text": "yeah I mean there's again as I said every database engine has different permissions and privileges required it's",
    "start": "4009300",
    "end": "4014980"
  },
  {
    "text": "all documented other things that are documented are if you're going to do ongoing replication we specify how it is",
    "start": "4014980",
    "end": "4020890"
  },
  {
    "text": "you need to configure database you know how you enable the transaction logging so the DMS can read the information out",
    "start": "4020890",
    "end": "4027990"
  },
  {
    "text": "no there's there's nothing that sort of says when you should use snowball versus not I mean ya know we don't have that",
    "start": "4051690",
    "end": "4063550"
  },
  {
    "text": "yet as I said we don't actually have any real limits because it varies really on",
    "start": "4063550",
    "end": "4069130"
  },
  {
    "text": "your architecture and I understand what you're saying you know can we pull and then give a recommendation from there at present all I have is those rules rules",
    "start": "4069130",
    "end": "4075880"
  },
  {
    "text": "of thumb to offer you knowing that we have had people move up to 15 terabytes over the wire frankly for the for the",
    "start": "4075880",
    "end": "4082150"
  },
  {
    "text": "price of snowball and you know the the time it takes to ship the data you really want to make sure you have a you",
    "start": "4082150",
    "end": "4087220"
  },
  {
    "text": "balance that correctly before you go down that path yeah yeah of course",
    "start": "4087220",
    "end": "4093490"
  },
  {
    "text": "of course yeah",
    "start": "4093490",
    "end": "4099660"
  },
  {
    "text": "yeah no they did it does it does take an outage if you will so you've got transactions transactions going you know",
    "start": "4107119",
    "end": "4113659"
  },
  {
    "text": "they'll pause and you'll have to resume once it's subscales yeah the the the",
    "start": "4113659",
    "end": "4126650"
  },
  {
    "text": "information the metadata if you will like behind the scenes DMS keeps track of where it's at in in a collection of",
    "start": "4126650",
    "end": "4131988"
  },
  {
    "text": "tables so when you when it starts up again it knows where it left off sorry",
    "start": "4131989",
    "end": "4141258"
  },
  {
    "text": "is there what I don't think so but",
    "start": "4141259",
    "end": "4151520"
  },
  {
    "text": "actually Illya do you know",
    "start": "4151520",
    "end": "4154810"
  },
  {
    "text": "alright I think that's that's it so thank you very much everyone appreciate you coming especially after beer o'clock [Applause]",
    "start": "4169150",
    "end": "4176789"
  }
]
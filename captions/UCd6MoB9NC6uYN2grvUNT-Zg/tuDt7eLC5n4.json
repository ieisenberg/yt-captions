[
  {
    "text": "thank you everyone for coming of full pack my name is Robin Alta I'm I've been",
    "start": "60",
    "end": "5640"
  },
  {
    "text": "with Amazon Web Services for four plus years I started with Amazon as a",
    "start": "5640",
    "end": "10650"
  },
  {
    "text": "solution architect sudo data engineer data scientist working on with different",
    "start": "10650",
    "end": "16350"
  },
  {
    "text": "technology on AWS and today I'm part of our business development group so we",
    "start": "16350",
    "end": "22769"
  },
  {
    "text": "sometimes need to wear suits but we still techie and I cover our Canisius business worldwide and together leave we",
    "start": "22769",
    "end": "30269"
  },
  {
    "text": "have a John Bennett is a senior software engineer from Netflix so welcome for the session I'm just the opening act so I'm",
    "start": "30269",
    "end": "37500"
  },
  {
    "text": "just going to talk about few words about Amazon Kinesis I'll ask you some one question we'll talk about log analytics",
    "start": "37500",
    "end": "43559"
  },
  {
    "text": "use case because that would be a good starting point for Netflix this case of what they do with with Amazon Kinesis",
    "start": "43559",
    "end": "50760"
  },
  {
    "text": "data streams and if you have time questions so I want to ask you a question who is here that sits here or",
    "start": "50760",
    "end": "58289"
  },
  {
    "text": "the guys on the podcast is AWS customer and he's not using Genesis today raise your hand okay so you're probably all",
    "start": "58289",
    "end": "71520"
  },
  {
    "text": "using Kinesis so and the reason is that",
    "start": "71520",
    "end": "77939"
  },
  {
    "text": "and we were not quite vocal about it but some of you know but Amazon Kinesis was",
    "start": "77939",
    "end": "84000"
  },
  {
    "text": "born as a foundation service at AWS and many of services that they are using to",
    "start": "84000",
    "end": "89189"
  },
  {
    "text": "their own AWS are built on top of Amazon Kinesis last year at reinvent our AWS",
    "start": "89189",
    "end": "94200"
  },
  {
    "text": "metering team talked about how they process hundred millions events for metering event on AWS so every time",
    "start": "94200",
    "end": "99540"
  },
  {
    "text": "there is a data transfer in that result you create an instance all these events needs to be metered and they are using",
    "start": "99540",
    "end": "105810"
  },
  {
    "text": "Canisius under the hood here using Amazon s3 event to use Kinesis here using I am cloud blogs even every unit",
    "start": "105810",
    "end": "112950"
  },
  {
    "text": "at Amazon like amazon.com the catalog they're using Kinesis so so we always in",
    "start": "112950",
    "end": "118020"
  },
  {
    "text": "Canisius and the reason I'm mentioning it because there's no such awareness about and it's a foundational service so",
    "start": "118020",
    "end": "123540"
  },
  {
    "text": "we are using it for really deal with large scale of streaming data ingestion",
    "start": "123540",
    "end": "128759"
  },
  {
    "text": "and processing and this is a 400 level session so I'm not going to cover like what is Kinesis what",
    "start": "128759",
    "end": "136049"
  },
  {
    "text": "does he do I assume that you're familiar if not happy to talk to you afterwards",
    "start": "136049",
    "end": "141719"
  },
  {
    "text": "we had several many sessions it's a 400 level sessions we're going to dive deep especially we've been it on how to use",
    "start": "141719",
    "end": "148530"
  },
  {
    "text": "kinases but really the notion of real-time streaming is is really moving from from batch to stream processing",
    "start": "148530",
    "end": "156540"
  },
  {
    "text": "right there is a phrase that there is no such thing as nostalgia right what happens five days ago its history and",
    "start": "156540",
    "end": "162870"
  },
  {
    "text": "you know you tweet something after five minutes its historical and companies today an organization wants to analyze",
    "start": "162870",
    "end": "168959"
  },
  {
    "text": "their business metrics in real time and when I say real time your real time millisecond seconds this is type of the",
    "start": "168959",
    "end": "176780"
  },
  {
    "text": "throughput or latency that you want to handle so thank you so Amazon Kinesis is",
    "start": "176780",
    "end": "189299"
  },
  {
    "text": "is today as a platform and as you heard at and X key notes we are very happy to",
    "start": "189299",
    "end": "195299"
  },
  {
    "text": "announce and a general availability of Kinesis video streams so there was some",
    "start": "195299",
    "end": "200430"
  },
  {
    "text": "renamed of the existing Canisius services so we have a Kinesis data streams that you can build your own",
    "start": "200430",
    "end": "206189"
  },
  {
    "text": "custom application for those are here familiar with Kafka very similar to the concept is just you don't have to paint",
    "start": "206189",
    "end": "212549"
  },
  {
    "text": "to manage zookeeper and all that so Kinesis data stream is a way for you to",
    "start": "212549",
    "end": "217590"
  },
  {
    "text": "build multiple application processing data and stream kinases farah data firehose is a service that if you want",
    "start": "217590",
    "end": "224909"
  },
  {
    "text": "you can just fan out all your data from your Canisius streams or data that sits",
    "start": "224909",
    "end": "230159"
  },
  {
    "text": "in logs and ship it today we have four destination you can send out the data to",
    "start": "230159",
    "end": "235500"
  },
  {
    "text": "Amazon s3 you can fan out the data to Amazon Elastic search Amazon redshift and three invent we announced also a new",
    "start": "235500",
    "end": "242430"
  },
  {
    "text": "destination which is plunk so if you are startup you might not use ton but many enterprise organization are using Splunk",
    "start": "242430",
    "end": "249389"
  },
  {
    "text": "and it's a very popular destination so you can actually for the data the fourth service is Genesis data analytics if you",
    "start": "249389",
    "end": "256440"
  },
  {
    "text": "want to do some machine learning like anomaly detection or you want to build application using sequel language so you",
    "start": "256440",
    "end": "262320"
  },
  {
    "text": "can use chemists they don't as a way to process the data aggregated",
    "start": "262320",
    "end": "268280"
  },
  {
    "text": "data we had several workshops are this week's hopefully you had the chance to attend and of course Kinesis video",
    "start": "268280",
    "end": "276470"
  },
  {
    "text": "stream so yeah data we talk about small data sets but what about video right if",
    "start": "276470",
    "end": "281900"
  },
  {
    "text": "I want to now take a video and running the deep learning model using tester florica fair mix net you have Kinesis",
    "start": "281900",
    "end": "289400"
  },
  {
    "text": "video streams that allows you to ingest data from video data from millions of IP",
    "start": "289400",
    "end": "295550"
  },
  {
    "text": "devices and stream it actually after this session we have a chalk talk I will be there again talk about Kinesis video",
    "start": "295550",
    "end": "302120"
  },
  {
    "text": "stream so I'm just commercial for the next one but so before we have a John on",
    "start": "302120",
    "end": "307970"
  },
  {
    "text": "on stage right I want to emphasize log analytics uski so so when Kinesis",
    "start": "307970",
    "end": "315020"
  },
  {
    "text": "started back in 2013 we had Kinesis streams right you you have a publisher",
    "start": "315020",
    "end": "322580"
  },
  {
    "text": "you push data into Kinesis stream and then you have a consumer using KCl read the data but over the years what we've",
    "start": "322580",
    "end": "329720"
  },
  {
    "text": "seen what customers are doing using Kinesis for change data capture taking some events from database from logs from",
    "start": "329720",
    "end": "336890"
  },
  {
    "text": "telemetry like IOT devices and and log analytics this case is a very popular use case where you want to take",
    "start": "336890",
    "end": "343790"
  },
  {
    "text": "application logs aggregate it process it and build your own insight so what we",
    "start": "343790",
    "end": "350480"
  },
  {
    "text": "did this year we created some several solutions that are available for you to use so for example if you have cloud",
    "start": "350480",
    "end": "356030"
  },
  {
    "text": "rate cloud trail event logs this is an architecture as an example and I put the",
    "start": "356030",
    "end": "361100"
  },
  {
    "text": "URL so later on when you download you don't need to take a picture you can just hit the link but how you ingest AWS",
    "start": "361100",
    "end": "367400"
  },
  {
    "text": "cloud trail with Amazon Cloud watch trigger throw your heals weaknesses to",
    "start": "367400",
    "end": "373430"
  },
  {
    "text": "s3 and you can use Kinesis data analytics to build your queries using lambda function and have a nice",
    "start": "373430",
    "end": "380030"
  },
  {
    "text": "dashboard in UI to look at real time some dashboard about your application logs",
    "start": "380030",
    "end": "385720"
  },
  {
    "text": "Kinesis has a robust connector library so you can use flume flow and D from the",
    "start": "385720",
    "end": "390800"
  },
  {
    "text": "producer side on the consumer side you can use fleeing spark our own as decay",
    "start": "390800",
    "end": "396890"
  },
  {
    "text": "of course but one of the popular integrations with lambda again it's become turned like",
    "start": "396890",
    "end": "402740"
  },
  {
    "text": "even if you're running something on your data center you have Kinesis agents that you can put install in your machines and",
    "start": "402740",
    "end": "409610"
  },
  {
    "text": "it listening to a log we have customers that are using both Kafka and Kinesis earlier this year actually five months",
    "start": "409610",
    "end": "417620"
  },
  {
    "text": "ago we released an open source on Kinesis sorry Kafka to Canisius connector in",
    "start": "417620",
    "end": "423350"
  },
  {
    "text": "github we're using the Kafka connect so for example if you have a cough can you want to listen to a topic and fan out",
    "start": "423350",
    "end": "428780"
  },
  {
    "text": "the data to redshift or to s3 you can use the open source library it's just a listener to your topic and the further",
    "start": "428780",
    "end": "435200"
  },
  {
    "text": "you can stream it through Kinesis to our destinations so quite excited so you can use both sometimes where for example if",
    "start": "435200",
    "end": "442370"
  },
  {
    "text": "you're a cover cluster running in our data center you can use kinases firehose just to forward this data so I am a fan",
    "start": "442370",
    "end": "452030"
  },
  {
    "text": "of this show and when me and Bennett talk sorry I mean John we talked about the session I said you know what we",
    "start": "452030",
    "end": "457940"
  },
  {
    "text": "should call it stranger streams right because it's cool so and then I said now",
    "start": "457940",
    "end": "463550"
  },
  {
    "text": "let's do marketing kanessa streams but in short I'm honor and pleasure to",
    "start": "463550",
    "end": "469160"
  },
  {
    "text": "introduce John to talk about how Netflix use Canisius data streams to analyze seven million plus Network events per",
    "start": "469160",
    "end": "476300"
  },
  {
    "text": "second so that's me and the stage is yours thank you",
    "start": "476300",
    "end": "481990"
  },
  {
    "text": "[Applause]",
    "start": "481990",
    "end": "489860"
  },
  {
    "text": "thanks Roy so up until about several a few months",
    "start": "489860",
    "end": "496530"
  },
  {
    "text": "ago when I was on call there were three questions that I hated getting what is",
    "start": "496530",
    "end": "502650"
  },
  {
    "text": "wrong with a network god I hate that one",
    "start": "502650",
    "end": "507890"
  },
  {
    "text": "right even if you take seasoned systems engineers app developers SR trees and",
    "start": "507890",
    "end": "515669"
  },
  {
    "text": "you put them in a room and you try to get down to the bottom of an issue if things are intermittent or hard to",
    "start": "515669",
    "end": "522810"
  },
  {
    "text": "reproduce right oftentimes they'll just throw their hands up and go well that was a network glitch and as a network",
    "start": "522810",
    "end": "532350"
  },
  {
    "text": "focused sre it's frustrating when we're not actually able to answer these types",
    "start": "532350",
    "end": "537840"
  },
  {
    "text": "of questions but really what can we do to start chipping away at that right because the",
    "start": "537840",
    "end": "543840"
  },
  {
    "text": "second worst question why is the network so slow god even worse what we find is",
    "start": "543840",
    "end": "552510"
  },
  {
    "text": "that even when application developers are building their systems they may not",
    "start": "552510",
    "end": "559080"
  },
  {
    "text": "be familiar with things like network topology or how traffic you know is",
    "start": "559080",
    "end": "564090"
  },
  {
    "text": "shifted around throughout a device's ecosystem and they may be taking",
    "start": "564090",
    "end": "569340"
  },
  {
    "text": "suboptimal paths right they may be going from one region to another without even knowing it so how do we actually figure",
    "start": "569340",
    "end": "576660"
  },
  {
    "text": "out if that's the case no data I guess",
    "start": "576660",
    "end": "581670"
  },
  {
    "text": "this is more of a comment less of a less of a question my service can't connect to his dependencies all right well for the most part a lot",
    "start": "581670",
    "end": "589350"
  },
  {
    "text": "of application developers don't even know what their full dependency graph looks like right they may know what",
    "start": "589350",
    "end": "594780"
  },
  {
    "text": "their like primary and secondary dependencies look like but do they know there are full dependencies and then how",
    "start": "594780",
    "end": "601140"
  },
  {
    "text": "do they know that they can actually are able to connect to that or aren't even set up to do that all right one of the",
    "start": "601140",
    "end": "607440"
  },
  {
    "text": "things that we've been trying to focus on is what can we do to build some sort of data set that can give us insight",
    "start": "607440",
    "end": "612810"
  },
  {
    "text": "into these starts at be able to answer these types of questions and before I go",
    "start": "612810",
    "end": "617880"
  },
  {
    "text": "into that what I thought is I a little bit of context about what it's like trying to answer these questions at",
    "start": "617880",
    "end": "623220"
  },
  {
    "text": "Netflix so spoiler alert Netflix is big",
    "start": "623220",
    "end": "629180"
  },
  {
    "text": "we have over 100 minutes prescribers we're spread across the globe and every",
    "start": "629180",
    "end": "634830"
  },
  {
    "text": "day we're getting bigger and bigger right and under the hood there's dozens of accounts thousands of micro services",
    "start": "634830",
    "end": "642000"
  },
  {
    "text": "and they're all scaling up and down to adjust to diurnal traffic patterns",
    "start": "642000",
    "end": "647790"
  },
  {
    "text": "increasing load that sort of thing I think Wesley Ivan it's almost over a",
    "start": "647790",
    "end": "652920"
  },
  {
    "text": "hundred and fifty thousand instances I don't know but you can kind of see that",
    "start": "652920",
    "end": "658500"
  },
  {
    "text": "within our system things are very very dynamic so of course we got to make the",
    "start": "658500",
    "end": "664230"
  },
  {
    "text": "matters worse right we have no access to the underlying network so typically when you are operating and say like a data",
    "start": "664230",
    "end": "671279"
  },
  {
    "text": "center environment you may use data sources like s flow or net flow to kind",
    "start": "671279",
    "end": "677040"
  },
  {
    "text": "of be able to understand network traffic logs but we can't do that in AWS",
    "start": "677040",
    "end": "682880"
  },
  {
    "text": "additionally right we have this huge volume of network traffic how do we even",
    "start": "682880",
    "end": "688650"
  },
  {
    "text": "begin to deal with billions of flows a day right you're talking gigabytes per second not only that most of our logs",
    "start": "688650",
    "end": "697230"
  },
  {
    "text": "end up coming down to hey this IP address talk to this IP address at this time right totally worthless for us",
    "start": "697230",
    "end": "704490"
  },
  {
    "text": "because IPS are assigned dynamically they're assigned randomly right an IP",
    "start": "704490",
    "end": "710339"
  },
  {
    "text": "may map to some service called foo at one time but then maybe further down the",
    "start": "710339",
    "end": "715709"
  },
  {
    "text": "line it gets mapped to say a lambda function and it's unpredictable on how",
    "start": "715709",
    "end": "720990"
  },
  {
    "text": "this IP assignment is done within the V PC environment so what are these traffic",
    "start": "720990",
    "end": "726660"
  },
  {
    "text": "logs even mean for us fortunately for us a device provides great tool called an",
    "start": "726660",
    "end": "732930"
  },
  {
    "text": "ATM sbpc flow logs and it has like this wide level of coverage you can basically",
    "start": "732930",
    "end": "738959"
  },
  {
    "text": "tap all the network traffic logs for all of your network interfaces within a V PC and it's really good because it's",
    "start": "738959",
    "end": "745440"
  },
  {
    "text": "consolidated there's like a single point to where you can ask for it for data but just like everything else in life right",
    "start": "745440",
    "end": "751380"
  },
  {
    "text": "it's not perfect so even though it has core identifying information like source and destination IP it's got this ten-minute capture",
    "start": "751380",
    "end": "758450"
  },
  {
    "text": "window so that means that when a traffic flow happens and when you can actually observe it in our in your flow logs",
    "start": "758450",
    "end": "764269"
  },
  {
    "text": "there could be up to 10 minutes right not great if you're trying to do things like really real time and of course even",
    "start": "764269",
    "end": "771380"
  },
  {
    "text": "worse there's no state so you actually have no idea whether the traffic is going from one IP to another as a",
    "start": "771380",
    "end": "778070"
  },
  {
    "text": "request or a response in something like a TCP protocol I'll actually go a little bit over this later so just to kind of",
    "start": "778070",
    "end": "785959"
  },
  {
    "text": "give you a better understanding what that looks like right if the log line shows that some source IP is talking to",
    "start": "785959",
    "end": "793010"
  },
  {
    "text": "a destination IP at time T that doesn't really help us because we don't know what those IPS mean at that time but",
    "start": "793010",
    "end": "800300"
  },
  {
    "text": "really what we'd love to turn it into is can we understand what service is talking to another is a talking to B",
    "start": "800300",
    "end": "806720"
  },
  {
    "text": "what accounts do those map to what zones were they in now we're actually mapping",
    "start": "806720",
    "end": "813260"
  },
  {
    "text": "these IP addresses to things that are much longer live than IP addresses right services account zones those are long",
    "start": "813260",
    "end": "819860"
  },
  {
    "text": "lived right there they're not a part of something that's constantly changing so",
    "start": "819860",
    "end": "826000"
  },
  {
    "text": "what we want to do was build this data source that can drive this sort of",
    "start": "826000",
    "end": "831680"
  },
  {
    "text": "analytical processing so that we understand the kind of dimensions that we care about some of them are Netflix",
    "start": "831680",
    "end": "837529"
  },
  {
    "text": "centric some of them are a SS centric but we want to be able to do like really fast aggregations so we don't have to",
    "start": "837529",
    "end": "843800"
  },
  {
    "text": "submit a query and wait minutes or hours for results these kind of things are",
    "start": "843800",
    "end": "848959"
  },
  {
    "text": "what we call OLAP queries or essentially slicing and dicing and turning this multi-dimensional cube around and",
    "start": "848959",
    "end": "856120"
  },
  {
    "text": "ultimately what we want to do is add this kind of level of observability at a high level for network traffic in our",
    "start": "856120",
    "end": "862910"
  },
  {
    "text": "system and that's why we built this tool called reg what it does is they enriches",
    "start": "862910",
    "end": "868130"
  },
  {
    "text": "and aggregates of this VPC flow logs into this multi dimensional network data set then we can sort of ask the kind of",
    "start": "868130",
    "end": "874880"
  },
  {
    "text": "interesting queries that help us troubleshoot and improve the system and optimize so early on we knew that one of",
    "start": "874880",
    "end": "885470"
  },
  {
    "text": "the biggest hurdles that we were have to get over was the volume of data right how are we gonna get all of these",
    "start": "885470",
    "end": "893450"
  },
  {
    "text": "flow logs from all of these accounts all of these regions and process them in a timely way that is going to be useful to",
    "start": "893450",
    "end": "899300"
  },
  {
    "text": "us and that's what we turn to Amazon Kinesis one of the biggest benefits by",
    "start": "899300",
    "end": "906740"
  },
  {
    "text": "using Kinesis is that there's tight integration with other other services right including BBC flow logs s3",
    "start": "906740",
    "end": "914240"
  },
  {
    "text": "elasticsearch roy mentioned redshift and it can scale and we don't have to worry",
    "start": "914240",
    "end": "920750"
  },
  {
    "text": "about the operational burden of maintaining this stream at the same time",
    "start": "920750",
    "end": "927200"
  },
  {
    "text": "it provides this great convenient client library it's not that big of a pain to",
    "start": "927200",
    "end": "932510"
  },
  {
    "text": "use right and in the end it's gonna lower our TCO and I'll dig into each of these in a bit so in the beginning we",
    "start": "932510",
    "end": "942140"
  },
  {
    "text": "actually had no idea how much traffic we were gonna dealing with are we talking megabytes gigabytes terabytes no idea",
    "start": "942140",
    "end": "948110"
  },
  {
    "text": "and so by choosing the Amazon Kinesis family we were able to experiment with",
    "start": "948110",
    "end": "954560"
  },
  {
    "text": "different architectures different systems to process that data right we're gonna be dealing with it in a batch",
    "start": "954560",
    "end": "960110"
  },
  {
    "text": "format we're gonna be dueling it streaming right what are would we even be able to do things in a streaming",
    "start": "960110",
    "end": "966560"
  },
  {
    "text": "fashion and it's really flexible because now we can actually choose to use maybe",
    "start": "966560",
    "end": "972890"
  },
  {
    "text": "Amazon Kinesis fire hose and shoot things to s3 right so that we can process them out of band or we may be",
    "start": "972890",
    "end": "981170"
  },
  {
    "text": "I'm sitting out to elasticsearch we can do like some sort of intermediate data store and run query is there that sort",
    "start": "981170",
    "end": "987920"
  },
  {
    "text": "of gave us confidence that by processing data in a batch format we understood",
    "start": "987920",
    "end": "994220"
  },
  {
    "text": "more about the requirements if we were gonna try and do this in real time and that's the kind of process that I think",
    "start": "994220",
    "end": "999670"
  },
  {
    "text": "most people should go about solving their data processing problems that way you can understand what kind of",
    "start": "999670",
    "end": "1005380"
  },
  {
    "text": "trade-offs there would be versus batch versus real-time so I mentioned",
    "start": "1005380",
    "end": "1012300"
  },
  {
    "text": "integration with other aid EMS services and this diagram card shows you how we're able to collect all these flow",
    "start": "1012300",
    "end": "1019390"
  },
  {
    "text": "logs from multiple accounts and regions using what we call cross account log sharing right every",
    "start": "1019390",
    "end": "1026319"
  },
  {
    "text": "account is generating these flow logs in every region but we don't have to build",
    "start": "1026320",
    "end": "1031540"
  },
  {
    "text": "a system to deal with each of the logs individually for each account region pair so we can do is while these logs",
    "start": "1031540",
    "end": "1037839"
  },
  {
    "text": "are being published a cloud watch we can set up regional destinations right and",
    "start": "1037840",
    "end": "1043030"
  },
  {
    "text": "have each of those regional destinations for that data to a singled stream that",
    "start": "1043030",
    "end": "1048700"
  },
  {
    "text": "makes our data processing much simpler the architecture isn't complicated by the amount of accounts the amount of",
    "start": "1048700",
    "end": "1055120"
  },
  {
    "text": "regions everything ends up being fanning into the single account reach single stream the cool thing is we actually",
    "start": "1055120",
    "end": "1062230"
  },
  {
    "text": "wrote zero code to do this right this is three API calls to me that's a huge win",
    "start": "1062230",
    "end": "1068290"
  },
  {
    "text": "because now we can focus on processing the data and not shipping it around to",
    "start": "1068290",
    "end": "1073750"
  },
  {
    "text": "where I can eventually process the data so really big win I mentioned scale",
    "start": "1073750",
    "end": "1079660"
  },
  {
    "text": "earlier this is a graph that kind of shows you the level of traffic that's",
    "start": "1079660",
    "end": "1085510"
  },
  {
    "text": "being sent to that centralized Kinesis stream and this is over a week so you can see the evident like diurnal pattern",
    "start": "1085510",
    "end": "1091000"
  },
  {
    "text": "there where we're seeing peaks and troughs for every day and Kinesis has",
    "start": "1091000",
    "end": "1096280"
  },
  {
    "text": "been able to scale with that without a problem we haven't noticed any issues one of the",
    "start": "1096280",
    "end": "1103180"
  },
  {
    "text": "things that we thought we were gonna have to trade off by adopting Kinesis was how hard is it going to be able to",
    "start": "1103180",
    "end": "1108640"
  },
  {
    "text": "access this data right typically there's got to be some catch right who's gonna what kind of penalty are we gonna pay",
    "start": "1108640",
    "end": "1115440"
  },
  {
    "text": "but actually the Kinesis client library ended up being a great fit for us it's",
    "start": "1115440",
    "end": "1120780"
  },
  {
    "text": "convenient it's simple plus it takes a care of all the boring work things like",
    "start": "1120780",
    "end": "1126400"
  },
  {
    "text": "check pointing and load balancing like I don't wanna have to deal with any of that right that's completely orthogonal",
    "start": "1126400",
    "end": "1132220"
  },
  {
    "text": "to the problem that I'm trying to solve so that's really where I feel something",
    "start": "1132220",
    "end": "1137830"
  },
  {
    "text": "like Kinesis fire hose and Kinesis data streams is really gonna shine right",
    "start": "1137830",
    "end": "1143080"
  },
  {
    "text": "because it allows you to focus right I don't want to have to deal with handling",
    "start": "1143080",
    "end": "1148510"
  },
  {
    "text": "and operating a stream right I just want to process the data that's what matters to me",
    "start": "1148510",
    "end": "1155050"
  },
  {
    "text": "and when we talk about the overall cost of opera ownership it's very little",
    "start": "1155050",
    "end": "1160730"
  },
  {
    "text": "because like I said we're not operating and managing the stream we're not upgrading and managing patches we're not",
    "start": "1160730",
    "end": "1165980"
  },
  {
    "text": "troubleshooting the system making sure that's highly available in the end we just need to use a few utilities to",
    "start": "1165980",
    "end": "1172280"
  },
  {
    "text": "maybe able to scale the stream up and down based on load and there's definitely no overhead when you end up",
    "start": "1172280",
    "end": "1178100"
  },
  {
    "text": "subscribing to something like Canisius firehose but because things are completely managed but just like",
    "start": "1178100",
    "end": "1184940"
  },
  {
    "text": "everything else again Kinesis is not perfect right you have limits that are based on shards so once you start",
    "start": "1184940",
    "end": "1193430"
  },
  {
    "text": "hitting those sort of readwrite limits the first thing you're gonna have to do is decide hey can I increase the amount",
    "start": "1193430",
    "end": "1198710"
  },
  {
    "text": "of charge this dream to be able to maintain either the required read limit or the required write throughput and",
    "start": "1198710",
    "end": "1206410"
  },
  {
    "text": "depending on whether the volume of your traffic that may be either too costly or it may end up complicating things for",
    "start": "1206410",
    "end": "1213920"
  },
  {
    "text": "your system processing I would say probably the biggest fault for us that",
    "start": "1213920",
    "end": "1220010"
  },
  {
    "text": "makes it not usable in all situations is that there's no log compassion that log",
    "start": "1220010",
    "end": "1225590"
  },
  {
    "text": "compaction that's built in T Kinesis there is a tool that can archive",
    "start": "1225590",
    "end": "1230890"
  },
  {
    "text": "directly to something like dynamo DB but by default you have the 7-day maximum",
    "start": "1230890",
    "end": "1236750"
  },
  {
    "text": "retention period so if you wanted to have a data stream and I don't know you're storing logs you can only have",
    "start": "1236750",
    "end": "1243320"
  },
  {
    "text": "seven days of logs on that stream you won't be able to go all the way to the very beginning of time so you have to make that call and",
    "start": "1243320",
    "end": "1251000"
  },
  {
    "text": "whether or not that's gonna be important to you you need to access data that's older than a week that may or may not",
    "start": "1251000",
    "end": "1256460"
  },
  {
    "text": "work for you so it doesn't really work when we're trying to maybe keep data for",
    "start": "1256460",
    "end": "1261950"
  },
  {
    "text": "much longer than a week it may ended up being months or even years so I've",
    "start": "1261950",
    "end": "1271160"
  },
  {
    "text": "talked a lot about Network data and IP addresses and things like that I imagine",
    "start": "1271160",
    "end": "1276770"
  },
  {
    "text": "that's probably boring for most of the crowd I think what I'm gonna try and do is talk about different patterns that",
    "start": "1276770",
    "end": "1283250"
  },
  {
    "text": "you can use in your own domain that can give you different trade-offs and",
    "start": "1283250",
    "end": "1288570"
  },
  {
    "text": "benefits when it comes to processing large volumes of data in a stream oriented fashion so even though I'll",
    "start": "1288570",
    "end": "1297630"
  },
  {
    "text": "continue to use the network traffic log as an example hopefully you can apply",
    "start": "1297630",
    "end": "1303419"
  },
  {
    "text": "these same patterns to your own data set so really when I talk about taking",
    "start": "1303419",
    "end": "1309840"
  },
  {
    "text": "network traffic logs and making them so that we can actually have more value and they're attached to something like services and accounts really that just a",
    "start": "1309840",
    "end": "1318059"
  },
  {
    "text": "matter of enhancing one data set with another data stream so say for instance you're dealing with like financial",
    "start": "1318059",
    "end": "1324780"
  },
  {
    "text": "transactions right you may have one stream of financial transactions and say another stream of like tax rates I don't",
    "start": "1324780",
    "end": "1331950"
  },
  {
    "text": "know or maybe you're in the IOT space and you have sensor data and you want to",
    "start": "1331950",
    "end": "1338190"
  },
  {
    "text": "be able to marry that with say environmental data right something like that is still applicable here so just to",
    "start": "1338190",
    "end": "1346470"
  },
  {
    "text": "back up this is what we're trying to do right we had these original flow logs that have a source and destination IP we",
    "start": "1346470",
    "end": "1353100"
  },
  {
    "text": "need to process them somehow that's gonna be a lot of hand waving that's what the red box is for and out we want",
    "start": "1353100",
    "end": "1359220"
  },
  {
    "text": "is this enriched flow log right beyond these IP addresses what are the source",
    "start": "1359220",
    "end": "1364530"
  },
  {
    "text": "and destination applications involved in this flow in this case would be foo and bar so how do we get there",
    "start": "1364530",
    "end": "1371750"
  },
  {
    "text": "one way to do it is batch typically you'll do some sort of like daily batch",
    "start": "1371750",
    "end": "1378059"
  },
  {
    "text": "interval and you can judge your batch oriented system based on how quickly it",
    "start": "1378059",
    "end": "1385289"
  },
  {
    "text": "can churn through like a bounded fixed size input right how can it how quickly",
    "start": "1385289",
    "end": "1390630"
  },
  {
    "text": "kind of crank through some set amount of data per second probably the biggest",
    "start": "1390630",
    "end": "1397370"
  },
  {
    "text": "downside to bachelor in a bachelor engine systems is you've got this inherent delay between the time that",
    "start": "1397370",
    "end": "1404340"
  },
  {
    "text": "data is generated and between the time that you process the data and now the data is exposed to the user right if you",
    "start": "1404340",
    "end": "1412830"
  },
  {
    "text": "start with 24 hours it might end up being the case where you're gonna process data announce the values has",
    "start": "1412830",
    "end": "1419040"
  },
  {
    "text": "decayed over time and now it not really all that useful or you may end up reducing that interval to say",
    "start": "1419040",
    "end": "1425480"
  },
  {
    "text": "several hours but maybe that's not enough but this way should start right because then you can start to build that",
    "start": "1425480",
    "end": "1431180"
  },
  {
    "text": "use case for both the business and the technical that can tell you hey this is",
    "start": "1431180",
    "end": "1436250"
  },
  {
    "text": "worth it I should do this actually faster now there's a couple of the",
    "start": "1436250",
    "end": "1441470"
  },
  {
    "text": "meditations that apply to batch even if you're gonna be doing streaming the same thing one if you're gonna be connecting",
    "start": "1441470",
    "end": "1448370"
  },
  {
    "text": "to some sort of remote database you're gonna have to do some sort of network round-trip right and depending on the",
    "start": "1448370",
    "end": "1454940"
  },
  {
    "text": "volume of data that you're gonna be crunching through how do you make sure that you can bridge the gap in terms of",
    "start": "1454940",
    "end": "1460550"
  },
  {
    "text": "a request volume if you're getting saved millions of events a second are you",
    "start": "1460550",
    "end": "1466550"
  },
  {
    "text": "gonna be able to do millions of queries a second to a remote database if not what are you gonna have to do to scale",
    "start": "1466550",
    "end": "1472880"
  },
  {
    "text": "that database to make it viable right that might be too costly or you end up",
    "start": "1472880",
    "end": "1478700"
  },
  {
    "text": "caching the data and then you've got to deal with our favorite problem right cache cache validation or you may end up",
    "start": "1478700",
    "end": "1486740"
  },
  {
    "text": "deciding to store a local copy of the database when you process the data right that's a lot better",
    "start": "1486740",
    "end": "1492440"
  },
  {
    "text": "the story ends up being much easier to swallow because then you don't have to worry about network round-trips",
    "start": "1492440",
    "end": "1498620"
  },
  {
    "text": "you don't have to worry about contending but this may be difficult to do for you so let's look at a diagram of how that",
    "start": "1498620",
    "end": "1505730"
  },
  {
    "text": "might look over there on the right what we're talking about is we're capturing",
    "start": "1505730",
    "end": "1511430"
  },
  {
    "text": "these changes in metadata these metadata change events and so we're gonna store it and some sort of meta data store so",
    "start": "1511430",
    "end": "1518690"
  },
  {
    "text": "this is where we're sort of storing how meta data is changing for like a given IP and on the left is where our real",
    "start": "1518690",
    "end": "1526730"
  },
  {
    "text": "focus is at we're collecting these vpz flow logs and if you wanted to do in this batch oriented process you could",
    "start": "1526730",
    "end": "1533060"
  },
  {
    "text": "send them all directly the storage you know see I'm not gonna do this in real time we just push it to storage and",
    "start": "1533060",
    "end": "1538820"
  },
  {
    "text": "we'll process it out of band and later on it's some interval I don't know every",
    "start": "1538820",
    "end": "1543920"
  },
  {
    "text": "day well pick data out of storage will process it and then when I'm rich it you",
    "start": "1543920",
    "end": "1548990"
  },
  {
    "text": "could do this totally and this is where you should start and if you want to use a the best tool",
    "start": "1548990",
    "end": "1555509"
  },
  {
    "text": "so we want to do it right you could use Amazon cases fire hose and you could shoot it to say an s3 bucket on the",
    "start": "1555509",
    "end": "1562950"
  },
  {
    "text": "changelog side maybe you have some custom ec2 instances and they're shoving",
    "start": "1562950",
    "end": "1568350"
  },
  {
    "text": "its data and to say like DynamoDB ultimately they get picked up with a",
    "start": "1568350",
    "end": "1573960"
  },
  {
    "text": "batch processor processor some sort of service function computer on a man like lambda and you can send that to where",
    "start": "1573960",
    "end": "1580710"
  },
  {
    "text": "you need to go from there this is where we started one of the things that we",
    "start": "1580710",
    "end": "1588600"
  },
  {
    "text": "found as we were sending data to s3 and processing it what lambda is the",
    "start": "1588600",
    "end": "1596879"
  },
  {
    "text": "problems that you think you're avoiding by doing things in batch actually end up rearing their heads but in different",
    "start": "1596879",
    "end": "1602580"
  },
  {
    "text": "ways right depending on how much you've how much volume of data you're",
    "start": "1602580",
    "end": "1608129"
  },
  {
    "text": "processing and the the size of your Kinesis stream you're gonna be firing up a batch processor for every shard so say",
    "start": "1608129",
    "end": "1615840"
  },
  {
    "text": "you've got hundreds of shards there's gonna be a lambda function for every single shard right and each lambda",
    "start": "1615840",
    "end": "1621749"
  },
  {
    "text": "function is gonna take away other resources so things like ian is last elastic network interfaces each one's",
    "start": "1621749",
    "end": "1628769"
  },
  {
    "text": "gonna get an IP address so it's gonna eat into your IP address utilization and",
    "start": "1628769",
    "end": "1634499"
  },
  {
    "text": "at the same time you've still got to figure out hey how do I know whether or",
    "start": "1634499",
    "end": "1640470"
  },
  {
    "text": "not I'm keeping up with the volume of data that's in this s3 bucket so this is",
    "start": "1640470",
    "end": "1647039"
  },
  {
    "text": "all there's these all these sorts of problems that come with this batch or inter process but it's totally doable and this is where you need to figure out",
    "start": "1647039",
    "end": "1653429"
  },
  {
    "text": "whether or not these trade-offs are worth it for you eventually we evolved from batch and we",
    "start": "1653429",
    "end": "1660779"
  },
  {
    "text": "moved to streaming so like I mentioned the batch process may end up having some",
    "start": "1660779",
    "end": "1666600"
  },
  {
    "text": "sort of interval that's daily 24 hours but with streaming we can get this delayed down to somewhere around 7",
    "start": "1666600",
    "end": "1672119"
  },
  {
    "text": "minutes that's because of that capture window that I'd mentioned a little bit earlier from vpg flow logs on average we",
    "start": "1672119",
    "end": "1679259"
  },
  {
    "text": "see data coming in that's maybe about 4 or 5 minutes old and then it takes a couple of minutes to process in our",
    "start": "1679259",
    "end": "1684809"
  },
  {
    "text": "system from end to end now we're not dealing with things that are fixed size and",
    "start": "1684809",
    "end": "1690879"
  },
  {
    "text": "bounded now we're talking about unbounded infinite data streams and you can measure whether or not your system",
    "start": "1690879",
    "end": "1696399"
  },
  {
    "text": "is performing well by measuring how far behind the end of the stream it's out",
    "start": "1696399",
    "end": "1701679"
  },
  {
    "text": "and all the same limitations apply right if there's a remote data base that you",
    "start": "1701679",
    "end": "1706749"
  },
  {
    "text": "need to connect to while processing your data you still have to bridge that that volume gap or you need to connect to",
    "start": "1706749",
    "end": "1714460"
  },
  {
    "text": "some sort of cache and still deal with cache invalidation or you can have some",
    "start": "1714460",
    "end": "1719979"
  },
  {
    "text": "local data database replicas so how would that look like compared to our",
    "start": "1719979",
    "end": "1725080"
  },
  {
    "text": "batch system now we're gonna have this stream processor that's consuming this",
    "start": "1725080",
    "end": "1730239"
  },
  {
    "text": "stream of vbt flow logs and as it's processing these flows right it's gonna",
    "start": "1730239",
    "end": "1736359"
  },
  {
    "text": "look into our meta data store to tell us hey given this IP address can you tell",
    "start": "1736359",
    "end": "1741580"
  },
  {
    "text": "me what it mapped to maps to at this particular time we still got same problems if we're talking millions of",
    "start": "1741580",
    "end": "1747879"
  },
  {
    "text": "BBC flow logs per second that means we're gonna have to do millions of read",
    "start": "1747879",
    "end": "1753009"
  },
  {
    "text": "queries to this meta data store per second right not entirely sure that was terrible and not it wasn't for us but if",
    "start": "1753009",
    "end": "1760690"
  },
  {
    "text": "you want to use a double yes tools to do this you can still use streams instead of firehose you're still processing your",
    "start": "1760690",
    "end": "1767889"
  },
  {
    "text": "changelog with ec2 instances but now you can have this custom Amazon Kinesis",
    "start": "1767889",
    "end": "1772989"
  },
  {
    "text": "application that's processing that stream from Kinesis once we got to this",
    "start": "1772989",
    "end": "1780369"
  },
  {
    "text": "point you might question hey if you're heating some remote database and you're",
    "start": "1780369",
    "end": "1786129"
  },
  {
    "text": "worried that the database isn't gonna keep up what do you do right typically you'll create some some sort of index or",
    "start": "1786129",
    "end": "1792369"
  },
  {
    "text": "you'll create a secondary index something so that you can something that's much more read optimized so that",
    "start": "1792369",
    "end": "1798039"
  },
  {
    "text": "can handle the kind of queries that you're gonna head you're gonna send over its way or you may end up putting a",
    "start": "1798039",
    "end": "1804519"
  },
  {
    "text": "cache in front of it right that's just another way of taking the original",
    "start": "1804519",
    "end": "1810940"
  },
  {
    "text": "stream of metadata changes and deriving it in such a way that it's optimized for",
    "start": "1810940",
    "end": "1817419"
  },
  {
    "text": "reading so if you wanted to use a SS tools to do that everything still applies",
    "start": "1817419",
    "end": "1823500"
  },
  {
    "text": "using Kinesis streams you're gonna process that streaming data but now in",
    "start": "1823500",
    "end": "1828900"
  },
  {
    "text": "the processor you're gonna actually end up hitting say something like a memcache D cluster but how do you deal with cache",
    "start": "1828900",
    "end": "1836670"
  },
  {
    "text": "invalidation right as you're processing the data really what you want to do is",
    "start": "1836670",
    "end": "1843780"
  },
  {
    "text": "make sure that you're accurately saying I have this original stream of data I want to join it with this other stream",
    "start": "1843780",
    "end": "1849900"
  },
  {
    "text": "of data but if different processes are actually seeing data differently based on when cache invalidation happens now",
    "start": "1849900",
    "end": "1857790"
  },
  {
    "text": "you're gonna introduce all kinds of inaccuracy into the system or actually what happens when you try to invalidate",
    "start": "1857790",
    "end": "1863820"
  },
  {
    "text": "the cache and that fails so now you're gonna be ending up joining it with",
    "start": "1863820",
    "end": "1869100"
  },
  {
    "text": "another data stream or data data set on memcache D that's either out-of-date",
    "start": "1869100",
    "end": "1874550"
  },
  {
    "text": "completely stale or inaccurate and then how do you measure for that and optimize that right that just seems like a whole",
    "start": "1874550",
    "end": "1882420"
  },
  {
    "text": "nother can of worms to open that doesn't seem like the problem that you're trying to solve so what are the key insights",
    "start": "1882420",
    "end": "1890660"
  },
  {
    "text": "that an engineer named Martin Clubman came up with is that when you look at it",
    "start": "1890660",
    "end": "1896450"
  },
  {
    "text": "all of these things that we do to make databases faster for us to query and",
    "start": "1896450",
    "end": "1902460"
  },
  {
    "text": "perform we'd read queries database indexes caches materialized views these",
    "start": "1902460",
    "end": "1908430"
  },
  {
    "text": "are all derived data right when you think about your database that you're querying it's receiving say a bunch of",
    "start": "1908430",
    "end": "1916530"
  },
  {
    "text": "inserts in some order and when you query that database that order and that of",
    "start": "1916530",
    "end": "1922710"
  },
  {
    "text": "that stream of changes is completely opaque to you but really things like",
    "start": "1922710",
    "end": "1929520"
  },
  {
    "text": "indexes and materialized views can all be computed if you were had access to",
    "start": "1929520",
    "end": "1935280"
  },
  {
    "text": "that stream of data so they're all come from the source of truth but they're all",
    "start": "1935280",
    "end": "1941370"
  },
  {
    "text": "meant to make it so that we can query this database faster and it's optimized for us to read so he talks about this",
    "start": "1941370",
    "end": "1949980"
  },
  {
    "text": "thing called change data capture right if you use some sort of log based message broker like Kinesis or Kafka you",
    "start": "1949980",
    "end": "1958200"
  },
  {
    "text": "can actually expose that stream of changes to the processor directly instead of forcing them to query some",
    "start": "1958200",
    "end": "1965880"
  },
  {
    "text": "database where that stream of changes is completely missing it's gonna become",
    "start": "1965880",
    "end": "1973080"
  },
  {
    "text": "this first-class citizen now and so really what we end up doing is we end up consuming multiple streams and joining",
    "start": "1973080",
    "end": "1980190"
  },
  {
    "text": "them together instead of querying a database so I'll confess the first time",
    "start": "1980190",
    "end": "1986190"
  },
  {
    "text": "I read that I I was reluctant I understand querying a database that's",
    "start": "1986190",
    "end": "1995220"
  },
  {
    "text": "straightforward I think for me it may be",
    "start": "1995220",
    "end": "2000470"
  },
  {
    "text": "uncomfortable to say I was gonna take on the burden of making sure that I could",
    "start": "2000470",
    "end": "2005600"
  },
  {
    "text": "expose this stream of changes directly to myself it was almost as if I would",
    "start": "2005600",
    "end": "2012140"
  },
  {
    "text": "rather have hidden all that away into the database and not have to deal with it but when you start to accept the kind",
    "start": "2012140",
    "end": "2020990"
  },
  {
    "text": "of benefits that you get from doing it the story gets a lot better right because now you can set up that stream",
    "start": "2020990",
    "end": "2027950"
  },
  {
    "text": "of changes completely custom to your to your to your processor you can optimize",
    "start": "2027950",
    "end": "2033230"
  },
  {
    "text": "it in a way that uses some sort of data structure that is very relevant to your",
    "start": "2033230",
    "end": "2038480"
  },
  {
    "text": "processing technique we don't have to worry about doing Network round-trips because now that stream of data is going",
    "start": "2038480",
    "end": "2045320"
  },
  {
    "text": "to live side by side by the other stream of data that you're processing essentially what we're gonna get is this",
    "start": "2045320",
    "end": "2051710"
  },
  {
    "text": "precomputed cache right we don't have to worry about cache invalidation we don't have to worry about contending with",
    "start": "2051710",
    "end": "2057320"
  },
  {
    "text": "other processors all of that data is gonna live locally so just to kind of",
    "start": "2057320",
    "end": "2062870"
  },
  {
    "text": "illustrate it a little bit more right we have these two streams of data we have flow logs and we have the stream of",
    "start": "2062870",
    "end": "2068659"
  },
  {
    "text": "metadata changes both of these are happening in parallel by an hour",
    "start": "2068660",
    "end": "2073970"
  },
  {
    "text": "processor we can use something simple like a hash table and given some IP address we can keep a list of all the",
    "start": "2073970",
    "end": "2080240"
  },
  {
    "text": "changes that happen to it over time we didn't have to turn to some sort of",
    "start": "2080240",
    "end": "2085740"
  },
  {
    "text": "exotic data structure like a radix tree premix tree just something like a simple",
    "start": "2085740",
    "end": "2091349"
  },
  {
    "text": "map so that when we're processing the data we don't actually have to go out to some remote database and query for this",
    "start": "2091349",
    "end": "2098670"
  },
  {
    "text": "remote this metadata application so every time we want to look it up we can",
    "start": "2098670",
    "end": "2104789"
  },
  {
    "text": "just go to this map anytime we receive an update we can update that same data structure this is key to understanding",
    "start": "2104789",
    "end": "2112559"
  },
  {
    "text": "how to do something like change data capture for your application so I guess",
    "start": "2112559",
    "end": "2118049"
  },
  {
    "text": "going back to how this might work in some other domain right these keys could be say I don't know account identifier",
    "start": "2118049",
    "end": "2127680"
  },
  {
    "text": "and the list of values could be all transactions right or it could be based",
    "start": "2127680",
    "end": "2134880"
  },
  {
    "text": "on some sensor ID and then the values can all be different environmental",
    "start": "2134880",
    "end": "2139920"
  },
  {
    "text": "readings something like that could work so let's take and take that change that",
    "start": "2139920",
    "end": "2147059"
  },
  {
    "text": "our change data capture approach and apply to architecture things get much simpler so now we have this stream",
    "start": "2147059",
    "end": "2154920"
  },
  {
    "text": "processor that's consuming both flow logs and the stream of metadata change events there's no data base there's no",
    "start": "2154920",
    "end": "2161700"
  },
  {
    "text": "cash no materialized views everything just lives within this stream processor",
    "start": "2161700",
    "end": "2168200"
  },
  {
    "text": "right and anytime we're processing the data all we have to do is refer to this",
    "start": "2168200",
    "end": "2173809"
  },
  {
    "text": "pre-optimized computing cache this is a huge win because now we don't have to",
    "start": "2173809",
    "end": "2179609"
  },
  {
    "text": "worry about bridging that gap that I talked to you about right we don't have to worry about the volume of stream",
    "start": "2179609",
    "end": "2186059"
  },
  {
    "text": "streaming information on the event side and we don't have to worry about making sure that everything is in sync when it",
    "start": "2186059",
    "end": "2192869"
  },
  {
    "text": "comes to joining it with that remote database so you'll notice in this",
    "start": "2192869",
    "end": "2199769"
  },
  {
    "text": "architecture that has both Kinesis and Kafka and the reason why that is is",
    "start": "2199769",
    "end": "2206670"
  },
  {
    "text": "because of the limitation that I had mentioned earlier since Canisius isn't able to have a longer retention period",
    "start": "2206670",
    "end": "2213660"
  },
  {
    "text": "we have to turn to something like Kafka so that we can use something like log compaction then we",
    "start": "2213660",
    "end": "2219720"
  },
  {
    "text": "can keep the entire history of all changes to an IP alt all IP addresses",
    "start": "2219720",
    "end": "2224780"
  },
  {
    "text": "this is key if your change log stream is much longer than key niece's Kinesis is",
    "start": "2224780",
    "end": "2230640"
  },
  {
    "text": "retention period all right so we talked",
    "start": "2230640",
    "end": "2236430"
  },
  {
    "text": "a lot about networking talked a lot about stream processing after we were able to handle all this large volume of",
    "start": "2236430",
    "end": "2243480"
  },
  {
    "text": "data process it analyzed it with this stream processor what do we have so",
    "start": "2243480",
    "end": "2250110"
  },
  {
    "text": "we're able to be able to analyze more than 7 million Network flows per second on average a flow can happen in our",
    "start": "2250110",
    "end": "2258930"
  },
  {
    "text": "system and we've analyzed it and sent it along to his final destination in about 5 minutes and there's only a single",
    "start": "2258930",
    "end": "2265290"
  },
  {
    "text": "Kinesis stream with a several hundred shards and that scales up and down based",
    "start": "2265290",
    "end": "2272760"
  },
  {
    "text": "on the volume one of the biggest outputs that we were",
    "start": "2272760",
    "end": "2279300"
  },
  {
    "text": "able to produce from going through this process is give our power users some",
    "start": "2279300",
    "end": "2287010"
  },
  {
    "text": "sort of exploratory UI so that they can dig into the data set themselves this is",
    "start": "2287010",
    "end": "2292320"
  },
  {
    "text": "a demonstration of how this tool called pivot it was open sourced by Yahoo",
    "start": "2292320",
    "end": "2297750"
  },
  {
    "text": "called Swift it was built by the folks that built a data store called druid which is column-oriented and what you",
    "start": "2297750",
    "end": "2305280"
  },
  {
    "text": "can see is on the left there are multiple dimensions things like account application load balancer name both",
    "start": "2305280",
    "end": "2315000"
  },
  {
    "text": "foreign and local and you can see how easy it is for someone who doesn't",
    "start": "2315000",
    "end": "2320160"
  },
  {
    "text": "necessarily know anything about the network topology how traffic flows through the system to query data in",
    "start": "2320160",
    "end": "2325920"
  },
  {
    "text": "terms of to be able to understand say given a particular service who does it",
    "start": "2325920",
    "end": "2331170"
  },
  {
    "text": "talk to or who talks to it and how does that change over time and what if I want",
    "start": "2331170",
    "end": "2337410"
  },
  {
    "text": "to zoom in to say a particular range of hours am i able to understand how",
    "start": "2337410",
    "end": "2342780"
  },
  {
    "text": "traffic patterns have changed and this doesn't mention anything at all about IP addresses V pcs or subnets if you don't",
    "start": "2342780",
    "end": "2351090"
  },
  {
    "text": "actually care about right this gets down to making sure that we expose this data set in such a way",
    "start": "2351090",
    "end": "2357120"
  },
  {
    "text": "that it can be consumed that understood by app developers and systems engineers",
    "start": "2357120",
    "end": "2363050"
  },
  {
    "text": "so this has been a bit of humor stand traffic patterns within our system at a",
    "start": "2363050",
    "end": "2369120"
  },
  {
    "text": "very high level so let's go back to some of those questions that we face a little",
    "start": "2369120",
    "end": "2375060"
  },
  {
    "text": "bit earlier hi what's wrong with the network so in the",
    "start": "2375060",
    "end": "2380940"
  },
  {
    "text": "network world that they have this term called mean time to innocence which basically just means how quickly can we",
    "start": "2380940",
    "end": "2386940"
  },
  {
    "text": "absolve the network of blame right it's somebody else's fault and we can use",
    "start": "2386940",
    "end": "2394590"
  },
  {
    "text": "dredges data set to help us try to understand that right if we're now that",
    "start": "2394590",
    "end": "2400740"
  },
  {
    "text": "we know traffic is going from say a particular account or zone in a given",
    "start": "2400740",
    "end": "2406140"
  },
  {
    "text": "region we can start to understand and group things into what we call fault domains right they all share",
    "start": "2406140",
    "end": "2413640"
  },
  {
    "text": "maybe these same characteristics so if service a is talking to service D and",
    "start": "2413640",
    "end": "2420420"
  },
  {
    "text": "they can't communicate was that a bad code push right or is it a whole network",
    "start": "2420420",
    "end": "2426510"
  },
  {
    "text": "outage because everything within that shared fault domain also has the same problem with connectivity and this could",
    "start": "2426510",
    "end": "2434490"
  },
  {
    "text": "be a boon for something like site reliability right well you can quickly isolate hey what is this a problem with",
    "start": "2434490",
    "end": "2441780"
  },
  {
    "text": "a specific application or we actually having some sort of like system level outage getting be able to be able to",
    "start": "2441780",
    "end": "2449100"
  },
  {
    "text": "reduce the scope of what you're investigating quickly is really what we want to try to enable here",
    "start": "2449100",
    "end": "2454530"
  },
  {
    "text": "oh and that other question why is the network so slow well now we have this",
    "start": "2454530",
    "end": "2462000"
  },
  {
    "text": "data set that can tell us given a specific application are you communicating over a network path that",
    "start": "2462000",
    "end": "2468750"
  },
  {
    "text": "has high latency say between two disparate regions because when you're",
    "start": "2468750",
    "end": "2475410"
  },
  {
    "text": "communicating say between the same zone you can expect traffic time round-trip",
    "start": "2475410",
    "end": "2483090"
  },
  {
    "text": "times to be less than a millisecond the order of microseconds but if you're",
    "start": "2483090",
    "end": "2489850"
  },
  {
    "text": "gonna be going between zones that may balloon up to two milliseconds maybe",
    "start": "2489850",
    "end": "2494860"
  },
  {
    "text": "that doesn't make a difference for your applications but for latency-sensitive operations that could but what happens",
    "start": "2494860",
    "end": "2503350"
  },
  {
    "text": "when you actually end up doing crosses region that's problematic it could be",
    "start": "2503350",
    "end": "2508930"
  },
  {
    "text": "several hundred milliseconds for round-trip times and now we're gonna have what is perceived as slowness and",
    "start": "2508930",
    "end": "2516820"
  },
  {
    "text": "even if you don't directly communicate with something that is a cross region",
    "start": "2516820",
    "end": "2522310"
  },
  {
    "text": "what happens when you're communicating with another service that's communicating cross region right that's",
    "start": "2522310",
    "end": "2527860"
  },
  {
    "text": "completely hidden to you as the as sale if you were a service a but now we had this data set that can tell us who is",
    "start": "2527860",
    "end": "2535360"
  },
  {
    "text": "actually impacted by these high latency network paths what we found initially is",
    "start": "2535360",
    "end": "2541960"
  },
  {
    "text": "that at almost 1/4 of our traffic was doing cross zone communication so",
    "start": "2541960",
    "end": "2548410"
  },
  {
    "text": "essentially a whole quarter of our traffic we are already adding a latency",
    "start": "2548410",
    "end": "2554080"
  },
  {
    "text": "penalty by default just by going between zones about 14% ends up doing cross",
    "start": "2554080",
    "end": "2561340"
  },
  {
    "text": "region some of it intentional some of it not I won't name any culprits here and",
    "start": "2561340",
    "end": "2569190"
  },
  {
    "text": "then we have this more interesting and harder question to solve my service",
    "start": "2569190",
    "end": "2574450"
  },
  {
    "text": "can't connect to his dependencies when our dredge is sort of understanding all",
    "start": "2574450",
    "end": "2580180"
  },
  {
    "text": "network traffic within a V PC so we can understand who is talking to who and",
    "start": "2580180",
    "end": "2585670"
  },
  {
    "text": "when and how by how much I wanted to do a quick background and give you a little",
    "start": "2585670",
    "end": "2593170"
  },
  {
    "text": "bit of sense of how we do that today internally we have a tool called this out it does distributed tracing which is",
    "start": "2593170",
    "end": "2600040"
  },
  {
    "text": "very similar to Google tapper and if there's a sort of naive sampling but it's very JVM centric and this helps us",
    "start": "2600040",
    "end": "2608260"
  },
  {
    "text": "understand given a request what other services does it touch along the way as",
    "start": "2608260",
    "end": "2613450"
  },
  {
    "text": "it makes its way through the request tree this is great",
    "start": "2613450",
    "end": "2619380"
  },
  {
    "text": "for the mole for the most part it's very very accurate and highly usable but it",
    "start": "2619380",
    "end": "2625210"
  },
  {
    "text": "lacks in things like coverage if it's not JVM say if it's a Python application",
    "start": "2625210",
    "end": "2632079"
  },
  {
    "text": "or a node app is it going to be covered by itself if not how much more work do",
    "start": "2632079",
    "end": "2637359"
  },
  {
    "text": "we need to be able to increase that coverage essentially we're relying on service developers to instrument these",
    "start": "2637359",
    "end": "2644619"
  },
  {
    "text": "calls and if they miss it now we have complete blindness in terms of that",
    "start": "2644619",
    "end": "2649780"
  },
  {
    "text": "communication path if we're just relying on distributed tracing so compared to",
    "start": "2649780",
    "end": "2657369"
  },
  {
    "text": "tracing how does dredge do right initially it's a given a tracing output of say service a we know that you might",
    "start": "2657369",
    "end": "2664000"
  },
  {
    "text": "talk to it Cassandra cluster and maybe a memcache D cluster but we start using traffic logs now we understand that",
    "start": "2664000",
    "end": "2670750"
  },
  {
    "text": "actually is quitting talking to cook quite a bit more it's talking to the discovery service target their Kafka",
    "start": "2670750",
    "end": "2676480"
  },
  {
    "text": "cluster it's talking to a three sqs there's no other way to make sure that",
    "start": "2676480",
    "end": "2685319"
  },
  {
    "text": "we have a high level of coverage when we try to build these large dependency graphs",
    "start": "2685319",
    "end": "2690750"
  },
  {
    "text": "everybody's systems are changing so fast that dependencies get introduced daily",
    "start": "2690750",
    "end": "2695789"
  },
  {
    "text": "and what we found is that there is a consistent level of discrepancy between dredge and so unsurprisingly rate",
    "start": "2695789",
    "end": "2703779"
  },
  {
    "text": "because now we're not relying on some proactive instrumentation of a call",
    "start": "2703779",
    "end": "2710140"
  },
  {
    "text": "between say service a and service B we're just gonna figure it out based on what we see on the network as my",
    "start": "2710140",
    "end": "2716260"
  },
  {
    "text": "colleagues like to say the network doesn't lie at the same time we're able",
    "start": "2716260",
    "end": "2722559"
  },
  {
    "text": "to increase the kind of consistency right and now we have this higher level coverage some other use cases that have",
    "start": "2722559",
    "end": "2730210"
  },
  {
    "text": "been really interesting is Netflix is built on a principle called freedom and",
    "start": "2730210",
    "end": "2735940"
  },
  {
    "text": "responsibility and that sort of has opened up the gates for application",
    "start": "2735940",
    "end": "2741309"
  },
  {
    "text": "developers and infrastructure owners to be able to set up these security groups and control access between services in a",
    "start": "2741309",
    "end": "2749230"
  },
  {
    "text": "lot of cases these things are maybe too open or an too permissive so it could be the",
    "start": "2749230",
    "end": "2756680"
  },
  {
    "text": "case that say an instance ends up getting compromised and now the blast radius for that communication is much",
    "start": "2756680",
    "end": "2762800"
  },
  {
    "text": "bigger than it needs to be VP T flow logs is very unique and that is the only",
    "start": "2762800",
    "end": "2769609"
  },
  {
    "text": "source of data provided by an AWS that can tell you whether or not a flow was",
    "start": "2769609",
    "end": "2775550"
  },
  {
    "text": "rejected based on security group rules there's nothing else out there and flow",
    "start": "2775550",
    "end": "2781700"
  },
  {
    "text": "laws can actually tell you which instances are communicating with the public Internet very helpful for our security centric",
    "start": "2781700",
    "end": "2788540"
  },
  {
    "text": "folks now we could do things like say threat detection and port scanning and",
    "start": "2788540",
    "end": "2793990"
  },
  {
    "text": "we can understand what kind of resources are being exposed that could be risky so",
    "start": "2793990",
    "end": "2801800"
  },
  {
    "text": "what are we going to do next for a lot of folks they might consider Network",
    "start": "2801800",
    "end": "2806930"
  },
  {
    "text": "level traffic like this being very low level I would say probably for the network perspective that's very high",
    "start": "2806930",
    "end": "2811940"
  },
  {
    "text": "level we consider like this 10,000 foot view a very MACUL macro high level view",
    "start": "2811940",
    "end": "2817130"
  },
  {
    "text": "we want to get much deeper we want to understand what's happening in the kernel maybe write some ebf tools so we",
    "start": "2817130",
    "end": "2824240"
  },
  {
    "text": "can understand how say the inner workings of the TCP stack are working and then we can sample using dynamic",
    "start": "2824240",
    "end": "2831280"
  },
  {
    "text": "rates and this sort of helps us find a way to like minimize variability because",
    "start": "2831280",
    "end": "2839589"
  },
  {
    "text": "when we're processing Kinesis streams and and BBC flow logs all of that flows",
    "start": "2839589",
    "end": "2844880"
  },
  {
    "text": "are all being logged into a single stream so all our processors are processing uneven amounts of data we",
    "start": "2844880",
    "end": "2852140"
  },
  {
    "text": "might be able to eliminate that sort of variability make things much more consistent just to wrap up what we found",
    "start": "2852140",
    "end": "2862010"
  },
  {
    "text": "is that even though it took a lot of effort and the country through a lot of data if we enriched and aggregate these",
    "start": "2862010",
    "end": "2869780"
  },
  {
    "text": "network traffic logs we can build this very useful data set that can tell us a lot about our systems that we didn't",
    "start": "2869780",
    "end": "2875480"
  },
  {
    "text": "know about helps us on the visibility side Kinesis streams and firehose are",
    "start": "2875480",
    "end": "2881770"
  },
  {
    "text": "perfect if you want to be able to experiment using either batch or stream or enterprise",
    "start": "2881770",
    "end": "2887140"
  },
  {
    "text": "it really helps us focus on the problem that we're trying to solve which is not",
    "start": "2887140",
    "end": "2892430"
  },
  {
    "text": "pushing bits through some sort of data stream its extracting value from that data and when you use this sort of",
    "start": "2892430",
    "end": "2900770"
  },
  {
    "text": "change data capture approach even though it can be scary at first by consuming and joining streams you alleviate some",
    "start": "2900770",
    "end": "2907940"
  },
  {
    "text": "of the problems that can come up by doing something by communicating with something remote then you can have this",
    "start": "2907940",
    "end": "2914900"
  },
  {
    "text": "sort of read optimize data structure and process your data more efficiently and",
    "start": "2914900",
    "end": "2919940"
  },
  {
    "text": "that's it here's my contact information if you have any questions if you feel free to reach out we probably won't be",
    "start": "2919940",
    "end": "2925730"
  },
  {
    "text": "doing some QA here but I'll hang out by the podium for a bit and maybe meet you guys outside in the hallway thank you",
    "start": "2925730",
    "end": "2931610"
  },
  {
    "text": "very much [Applause]",
    "start": "2931610",
    "end": "2940518"
  }
]
[
  {
    "text": "hey all thank you very much for uh joining us for today's session on how to build a big data analytics data Lake on",
    "start": "1400",
    "end": "8240"
  },
  {
    "text": "AWS my name is NJ Varma I'm a Solutions architect with AWS been here with Amazon",
    "start": "8240",
    "end": "14280"
  },
  {
    "text": "for two and a half years joining me today um in the session is SAR mahanti",
    "start": "14280",
    "end": "20640"
  },
  {
    "text": "who's a senior manager information system at amen Sor would be talking",
    "start": "20640",
    "end": "26000"
  },
  {
    "text": "about their journey to data Lake and their implementation of data Lake and",
    "start": "26000",
    "end": "31560"
  },
  {
    "text": "towards the last section of this talk um we would uh talk Dario rera who's my",
    "start": "31560",
    "end": "38480"
  },
  {
    "text": "colleague solution architect based out of honden office will walk you through on how to deploy a working prototype of",
    "start": "38480",
    "end": "45200"
  },
  {
    "text": "a data Lake in your own account AWS so we'll do a bit of demo so again uh first",
    "start": "45200",
    "end": "51360"
  },
  {
    "text": "section mostly about a little bit of concept around what is data Lake getting our arms around that what are the",
    "start": "51360",
    "end": "56559"
  },
  {
    "text": "important components of a data Lake I will also go a little bit into how do you build this bare minimum components",
    "start": "56559",
    "end": "61920"
  },
  {
    "text": "for a data Lake leveraging AWS services and uh again the second section",
    "start": "61920",
    "end": "68040"
  },
  {
    "text": "mg data Lake initiative and lastly how to build data Lake in your database account so with that let's get",
    "start": "68040",
    "end": "74880"
  },
  {
    "text": "started so what is the data Lake right so today is organizations are tasked",
    "start": "74880",
    "end": "80799"
  },
  {
    "text": "with managing multiple types of data coming from wide variety of sources and",
    "start": "80799",
    "end": "86840"
  },
  {
    "text": "facing massive volumes and heterogeneous type of data organizations are finding that in order",
    "start": "86840",
    "end": "93600"
  },
  {
    "text": "to provide timely insights into this data they need solutions that offer better flexibility and Agility than what",
    "start": "93600",
    "end": "101759"
  },
  {
    "text": "we have today with the traditional data management systems uh so D is again a new way to",
    "start": "101759",
    "end": "108840"
  },
  {
    "text": "store and analyze massive volumes of heterogeneous data you bring in this",
    "start": "108840",
    "end": "113920"
  },
  {
    "text": "massive data into the Central Storage repository and then make it available for different compute app applications",
    "start": "113920",
    "end": "120719"
  },
  {
    "text": "you know you want to do descriptive analytics you want to go Predictive Analytics data science machine learning",
    "start": "120719",
    "end": "126520"
  },
  {
    "text": "and that we'll talk about a little bit more about in terms of you know contrasting it with those traditional",
    "start": "126520",
    "end": "132040"
  },
  {
    "text": "data management systems and how we are now better off in terms of agility and flexibility the first question you know",
    "start": "132040",
    "end": "139519"
  },
  {
    "text": "if you are working on data management systems and you're trying to get your",
    "start": "139519",
    "end": "145000"
  },
  {
    "text": "arms around you know structured data unstructured data coming in from s like",
    "start": "145000",
    "end": "150280"
  },
  {
    "text": "social media becoming more and more important now because you know it's good to have the transactional data from your",
    "start": "150280",
    "end": "156480"
  },
  {
    "text": "databases and online transactional system manufacturing system but what if",
    "start": "156480",
    "end": "161519"
  },
  {
    "text": "you can enrich that with other data that is coming in which is probably not as structured right so the the question is",
    "start": "161519",
    "end": "167280"
  },
  {
    "text": "how do I bring all this data very quickly into my central repository and then be able to start you know exploring",
    "start": "167280",
    "end": "174519"
  },
  {
    "text": "it uh you know reducing my time to value in terms of exploring insights so a data",
    "start": "174519",
    "end": "180200"
  },
  {
    "text": "Lake allows you to quickly ingest all kinds of data structured as well as unstructured in its raw format very",
    "start": "180200",
    "end": "187360"
  },
  {
    "text": "quickly and make it available for data Discovery so that's the first attribute",
    "start": "187360",
    "end": "192920"
  },
  {
    "text": "of a data Lake and with the economies of scale you could uh you know and the storage cost",
    "start": "192920",
    "end": "200319"
  },
  {
    "text": "you can now bring in all that massive volumes more so on the cloud-based solution without having to worry about",
    "start": "200319",
    "end": "207239"
  },
  {
    "text": "you know per unit cost of storing that data and keep it as long as you want maybe down the line you know you will",
    "start": "207239",
    "end": "213200"
  },
  {
    "text": "discover new questions that you haven't thought about today you know with the existing systems with the storage cost",
    "start": "213200",
    "end": "219760"
  },
  {
    "text": "of the you know data warehousing and and and compute cost you know they joined at H you often have to scrub the data and",
    "start": "219760",
    "end": "227200"
  },
  {
    "text": "only pick up the attributes that are more interesting to you and and push it into a predefined schema into your",
    "start": "227200",
    "end": "232599"
  },
  {
    "text": "system so with data Lake you don't have to do that up front you bring in all your data and then do the ETL and do you",
    "start": "232599",
    "end": "240599"
  },
  {
    "text": "know all the computation based on the use case that best fits your",
    "start": "240599",
    "end": "246280"
  },
  {
    "text": "requirement the second attribute is today you find that your data in your organization is in different silos you",
    "start": "246280",
    "end": "254200"
  },
  {
    "text": "know um customers care has their data and CRM systems you know accounting has",
    "start": "254200",
    "end": "260440"
  },
  {
    "text": "in the accountable systems and you so on so forth so with data Lake you know you",
    "start": "260440",
    "end": "265520"
  },
  {
    "text": "can store all disparate set of data and collocate that data so that you can",
    "start": "265520",
    "end": "272720"
  },
  {
    "text": "drive connections right once it's easily available to you and you can swipe across the data Maybe marry some data",
    "start": "272720",
    "end": "279520"
  },
  {
    "text": "sets you can get to the insights more quickly that you would do in a",
    "start": "279520",
    "end": "285639"
  },
  {
    "text": "traditional way so that's the second attribute thirdly I touched briefly on",
    "start": "285639",
    "end": "290800"
  },
  {
    "text": "storage and storage versus compute traditional data management systems are kind of married at you know",
    "start": "290800",
    "end": "297520"
  },
  {
    "text": "at hip in terms of storage and compute so when you think about this massive volumes of data coming in your question",
    "start": "297520",
    "end": "302880"
  },
  {
    "text": "is well you know how do I scale what do I keep what do I drop well with the data L concept you can have a decoupling of",
    "start": "302880",
    "end": "312600"
  },
  {
    "text": "storage and compute so you can scale your storage based on the data that's coming in and apply the right amount of",
    "start": "312600",
    "end": "319759"
  },
  {
    "text": "compute right so you don't have to buy higher number of CES just because you",
    "start": "319759",
    "end": "324960"
  },
  {
    "text": "have now massive volumes of data set that you want to analyze you can bring them in and again as you need as best",
    "start": "324960",
    "end": "331160"
  },
  {
    "text": "fits you need you bring the right kind of compute to this and lastly this is this is probably the most important",
    "start": "331160",
    "end": "337080"
  },
  {
    "text": "attribute in terms of agility right so the question um organizations are asking",
    "start": "337080",
    "end": "344000"
  },
  {
    "text": "is there a way I can do some quick ad hoc analysis can I do multiple analysis",
    "start": "344000",
    "end": "349080"
  },
  {
    "text": "on the same data at the same time data Lake a functional data link allows you",
    "start": "349080",
    "end": "355120"
  },
  {
    "text": "to do that because you are not waiting to again transform data into a",
    "start": "355120",
    "end": "361319"
  },
  {
    "text": "predefined schema and losing some of the important information bits um you have",
    "start": "361319",
    "end": "367280"
  },
  {
    "text": "all the data it's decoupled from the compute you bring in the right kind of analysis to that storage layer and do",
    "start": "367280",
    "end": "374639"
  },
  {
    "text": "schema on read apply your schema on the Fly and discover insights it's sort of",
    "start": "374639",
    "end": "381440"
  },
  {
    "text": "saying that now you can find answer to the questions that you haven't thought about before with the data warehousing",
    "start": "381440",
    "end": "387560"
  },
  {
    "text": "solution you you have to again think already about what kind of questions I need to answer and you purposely then",
    "start": "387560",
    "end": "394919"
  },
  {
    "text": "design your system according to be you know faster queries on that this is not to say that data warehousing does not",
    "start": "394919",
    "end": "400080"
  },
  {
    "text": "have a place it's definitely data Lake complements data warehousing does not replace it because data warehouses are",
    "start": "400080",
    "end": "406560"
  },
  {
    "text": "pretty good in terms of faster queries Aggregates summary statistics so a",
    "start": "406560",
    "end": "411800"
  },
  {
    "text": "functional data L could be a source for structured data or unstructured data that again after right kind of Discovery",
    "start": "411800",
    "end": "420080"
  },
  {
    "text": "and exploration you could push into a data warehouse for faster queries and dashboards and all that all that stuff",
    "start": "420080",
    "end": "426639"
  },
  {
    "text": "so we talked about what data lake is what the key attributes of data Lake are let's also talk about the bare minimum",
    "start": "426639",
    "end": "433360"
  },
  {
    "text": "components of a data link right it's good to have all the data you know in one place how to make it more functional",
    "start": "433360",
    "end": "439039"
  },
  {
    "text": "and more usable for the end user so first thing obviously storage makes the",
    "start": "439039",
    "end": "444560"
  },
  {
    "text": "backbone right we need to have a quick way to bring in all sort of data in its",
    "start": "444560",
    "end": "449680"
  },
  {
    "text": "native format ability to keep it there so that we can you know ask questions",
    "start": "449680",
    "end": "454960"
  },
  {
    "text": "second thing the data set itself all the data need to have",
    "start": "454960",
    "end": "460560"
  },
  {
    "text": "information about that data so that it easily discoverable you know otherwise if you don't have that catalog of data",
    "start": "460560",
    "end": "467520"
  },
  {
    "text": "the rich metadata about the data sitting in the data Lake it becomes more like based on tribal knowledge you know",
    "start": "467520",
    "end": "473759"
  },
  {
    "text": "people in the no will know that this these this files you know this data sets are meant for this kind of use casape",
    "start": "473759",
    "end": "479520"
  },
  {
    "text": "and you know so forth so you want not only want to have the rich metadata you want to build the search capability so",
    "start": "479520",
    "end": "485319"
  },
  {
    "text": "you know your users even the business analyst can go in and search for the right kind of data and and start doing",
    "start": "485319",
    "end": "491560"
  },
  {
    "text": "their on the- fly Discovery and exploration of the data in the data",
    "start": "491560",
    "end": "496599"
  },
  {
    "text": "Lake protect and secure obviously we want to make sure there's the right kind of security and protection I'll go a",
    "start": "496599",
    "end": "502199"
  },
  {
    "text": "little bit more detail in this later in a dedicated slide uh and lastly uh the Del has to be available to Downstream",
    "start": "502199",
    "end": "509360"
  },
  {
    "text": "application and the users who want to discover data sets now all these component these are the bare minimum",
    "start": "509360",
    "end": "515680"
  },
  {
    "text": "components right obviously we would talk about what other additional add-on capabilities you can build on top of the",
    "start": "515680",
    "end": "521640"
  },
  {
    "text": "data Lake all these components they are you know that you",
    "start": "521640",
    "end": "527279"
  },
  {
    "text": "can build them with open- Source Solutions you can build them with uh off-the-shelf uh products that uh many",
    "start": "527279",
    "end": "534959"
  },
  {
    "text": "of our AWS Partners offer you could also leverage our services man managed offerings that are built to quickly be",
    "start": "534959",
    "end": "543560"
  },
  {
    "text": "able to deploy at a low cost and and pay as you go basis so what I'm going to do",
    "start": "543560",
    "end": "550120"
  },
  {
    "text": "I'm going to take a look at how to build this four components I talked about using native AWS building blocks and of",
    "start": "550120",
    "end": "558360"
  },
  {
    "text": "course again uh what disclaimer here is you can build it the way you deem fit for your use case AWS",
    "start": "558360",
    "end": "567120"
  },
  {
    "text": "is a flexible platform you can tailor your approach to building the data Lake architecture on it you can mix and match",
    "start": "567120",
    "end": "573519"
  },
  {
    "text": "so you could be running Hadoop clusters from cloud daa or mapar you know on on",
    "start": "573519",
    "end": "579160"
  },
  {
    "text": "on ec2 instances that are easy and quick to deploy you could be leveraging our EMR offering elastic map reduce which is",
    "start": "579160",
    "end": "587519"
  },
  {
    "text": "fast way to have flexible compute capacity to run your Hado",
    "start": "587519",
    "end": "592720"
  },
  {
    "text": "clusters you can use our Kinesis service for bringing in streaming data or you can using ccon ec2 instances so with",
    "start": "592720",
    "end": "600120"
  },
  {
    "text": "that let's go into one by one into those four components I talked about the first being ingest and store so any storage",
    "start": "600120",
    "end": "609519"
  },
  {
    "text": "solution here has to be able to quickly ingest data and be able to provide those connectors those functionality so that",
    "start": "609519",
    "end": "616120"
  },
  {
    "text": "you can bring in not only the batch data you want to bring in the real-time data you want it to be uh accessible durable",
    "start": "616120",
    "end": "623480"
  },
  {
    "text": "so Amazon S3 simple storage service offers a perfect match for",
    "start": "623480",
    "end": "630079"
  },
  {
    "text": "long-term durable scalable lowcost storage option um that is designed to be",
    "start": "630079",
    "end": "637440"
  },
  {
    "text": "easily accessible with various application via apis um and and other interfaces",
    "start": "637440",
    "end": "643360"
  },
  {
    "text": "available to you and it's integrated with multiple ads services in terms of bringing in the",
    "start": "643360",
    "end": "650200"
  },
  {
    "text": "data into S3 you can bring in realtime data by Amazon Kinesis you could use U",
    "start": "650200",
    "end": "657800"
  },
  {
    "text": "secure devices such as snowball where you can batch ingest lots of data um you",
    "start": "657800",
    "end": "663519"
  },
  {
    "text": "could uh have a direct connect which is a private connectivity from your current",
    "start": "663519",
    "end": "668959"
  },
  {
    "text": "data center um storage systems back into AWS environment or you can use AWS",
    "start": "668959",
    "end": "676480"
  },
  {
    "text": "storage Gateway that sits in as a software Appliance into your environment",
    "start": "676480",
    "end": "681680"
  },
  {
    "text": "connecting back to the cloud storage and of course there are isv connectors available there from uh technology",
    "start": "681680",
    "end": "688200"
  },
  {
    "text": "partners the third attribute of Amazon S3 is its integration to have a",
    "start": "688200",
    "end": "695200"
  },
  {
    "text": "frictionless integration with you know compute capacity other use cases you want to bring it you can like I",
    "start": "695200",
    "end": "700800"
  },
  {
    "text": "mentioned bring in EMR to do the computation you can do integrate with Amazon machine learning to do different",
    "start": "700800",
    "end": "708120"
  },
  {
    "text": "machine learning algorithms build your models do discovery on data in S3 or you",
    "start": "708120",
    "end": "713800"
  },
  {
    "text": "can use our petabyte scale data warehousing solution Amazon red shift for the data that we already massaged",
    "start": "713800",
    "end": "720600"
  },
  {
    "text": "and you already know that this is something we're going to need for faster query and make available to business users you can push that to the uh red",
    "start": "720600",
    "end": "729440"
  },
  {
    "text": "shift in terms of catalog and search capability you could build a serverless",
    "start": "729440",
    "end": "735680"
  },
  {
    "text": "architecture for the data that is in the in the Amazon S3 by creating uh the",
    "start": "735680",
    "end": "741959"
  },
  {
    "text": "metadata and storing that metadata in a fast and durable uh nosql database",
    "start": "741959",
    "end": "748320"
  },
  {
    "text": "Amazon dyn DB is easily can scale to single millisecond uh latency and to",
    "start": "748320",
    "end": "755320"
  },
  {
    "text": "keep your catalog up to dat you can use even driven Computing using Amazon",
    "start": "755320",
    "end": "762600"
  },
  {
    "text": "Lambda which is our function in the cloud where you don't have to worry about the underlying infrastructure you",
    "start": "762600",
    "end": "768480"
  },
  {
    "text": "just write the code that gets triggered as the new data streams in or new batch",
    "start": "768480",
    "end": "773560"
  },
  {
    "text": "of data comes in that can go through the data and push the metadata index into",
    "start": "773560",
    "end": "779120"
  },
  {
    "text": "the Dynamo DB you also want to make this Index searchable right so you want to do aggregate searches you want to do wild",
    "start": "779120",
    "end": "785720"
  },
  {
    "text": "card searches on the data you want to do fuzzy searching so then what you could",
    "start": "785720",
    "end": "791600"
  },
  {
    "text": "do you can further trigger update of the search index using again AWS Lambda into",
    "start": "791600",
    "end": "798079"
  },
  {
    "text": "elastic search providing easy way for users to search the data in terms of data protection and",
    "start": "798079",
    "end": "806120"
  },
  {
    "text": "security of course it's really important so when you become a customer of AWS you",
    "start": "806120",
    "end": "812279"
  },
  {
    "text": "get access to this highly secure Cloud infrastructure where you know by Design",
    "start": "812279",
    "end": "819600"
  },
  {
    "text": "you get access to a deep Suite of security services that you can you know",
    "start": "819600",
    "end": "825240"
  },
  {
    "text": "bring to bear for Access Control for data protection encryption in transit",
    "start": "825240",
    "end": "831120"
  },
  {
    "text": "encryption of data at rest with just a clicker button right so you can there's",
    "start": "831120",
    "end": "836279"
  },
  {
    "text": "a lot of flexibility built in into the key management offering awms you could",
    "start": "836279",
    "end": "841920"
  },
  {
    "text": "have secure access to S3 buckets within your VPC through the private endpoints",
    "start": "841920",
    "end": "847639"
  },
  {
    "text": "um or you could uh you know go granular to the Bucket Level object level as to",
    "start": "847639",
    "end": "853720"
  },
  {
    "text": "who can access what data based on the profile you could build integration with",
    "start": "853720",
    "end": "859040"
  },
  {
    "text": "in terms of front end with Federation integration with your existing active directory or alup directory where your",
    "start": "859040",
    "end": "866560"
  },
  {
    "text": "existing authorization information is so you get access to secure platform you",
    "start": "866560",
    "end": "872320"
  },
  {
    "text": "get all these deep Security Solutions knobs and levers that you can leverage and also Amazon manages over dozen",
    "start": "872320",
    "end": "881120"
  },
  {
    "text": "compliance programs for our infrastructure giving you guys a leg up for complying on your end with various",
    "start": "881120",
    "end": "888600"
  },
  {
    "text": "uh compliant requirements such as Hippa PCI uh or sock one sock",
    "start": "888600",
    "end": "894560"
  },
  {
    "text": "2 in terms of uh making data Lake available to end users and appli applications you could",
    "start": "894560",
    "end": "901480"
  },
  {
    "text": "leverage a simple website running out of Amazon S3 with Dynamic components",
    "start": "901480",
    "end": "909120"
  },
  {
    "text": "actually back ended by API Gateway which essentially is having the functions",
    "start": "909120",
    "end": "915560"
  },
  {
    "text": "exposing again functions written in AWS Lambda that goes back and searches into elastic search or Dynamo DB so you could",
    "start": "915560",
    "end": "922920"
  },
  {
    "text": "you could have this and I have example here and Dario will kind of show this running demo of all these things I'm",
    "start": "922920",
    "end": "928959"
  },
  {
    "text": "talking about how to kind of put it together and demonstrate so this could be as simple as this right how do you",
    "start": "928959",
    "end": "934079"
  },
  {
    "text": "bring in and again Federate this information in so you put all this together you know get this picture of a",
    "start": "934079",
    "end": "941680"
  },
  {
    "text": "working functional data L capability you have injust you have data",
    "start": "941680",
    "end": "947319"
  },
  {
    "text": "management you have security and you have catalog and search",
    "start": "947319",
    "end": "953959"
  },
  {
    "text": "on on the on the left side my left side your right side this is where you bring",
    "start": "953959",
    "end": "959160"
  },
  {
    "text": "various computation analytics capabilities into the data Lake again leveraging those the functionalities we",
    "start": "959160",
    "end": "965600"
  },
  {
    "text": "have quickly built using uh AWS basic building blocks for instance you can use",
    "start": "965600",
    "end": "971680"
  },
  {
    "text": "Quick site Amazon quick site to do quick discovery of your data in S3 and and build your graphic",
    "start": "971680",
    "end": "979040"
  },
  {
    "text": "interface so that was the basic you know things we put together in terms of bare",
    "start": "979040",
    "end": "984600"
  },
  {
    "text": "minimum there are some of the add-on things as we talk to customer that you can build on the data Lake you could uh",
    "start": "984600",
    "end": "991199"
  },
  {
    "text": "as you go through your journey of data Lake after you have the basic capability up and running you can have a backend",
    "start": "991199",
    "end": "996399"
  },
  {
    "text": "ETL processes buil so that again you you you can format the data in a certain",
    "start": "996399",
    "end": "1001680"
  },
  {
    "text": "fashion maybe you're getting CSV files may you want to make it available in a compressed format par or other format to",
    "start": "1001680",
    "end": "1008319"
  },
  {
    "text": "uh your processing engines you can do that you can build uh process Gates into",
    "start": "1008319",
    "end": "1013800"
  },
  {
    "text": "the data Lake in terms of who can access the data sets right maybe users have to go through certain training before",
    "start": "1013800",
    "end": "1019920"
  },
  {
    "text": "getting to confidential data sets um so those those things you can build in line with your business process you could",
    "start": "1019920",
    "end": "1026760"
  },
  {
    "text": "also do based on knowled your knowledge of your existing data and and and",
    "start": "1026760",
    "end": "1032438"
  },
  {
    "text": "business you could build some machine Lear learning algorithms to draw connections between the data sets that",
    "start": "1032439",
    "end": "1038839"
  },
  {
    "text": "probably going to make it easier for your end users to discover data better right so you're kind of building this",
    "start": "1038839",
    "end": "1044839"
  },
  {
    "text": "capability making data L more and more functional for end users as in when more data comes in streaming in from",
    "start": "1044839",
    "end": "1051440"
  },
  {
    "text": "different sources your data capability is only going to mature your your metadata is going to be richer your",
    "start": "1051440",
    "end": "1057360"
  },
  {
    "text": "search capabil is going to be better you're going to learn how to build these add-on capabilities so that it's it's",
    "start": "1057360",
    "end": "1063360"
  },
  {
    "text": "just more functional the last uh on the right side icon here is that as new data",
    "start": "1063360",
    "end": "1069240"
  },
  {
    "text": "come in you also want to build a way so that this data now is made available to",
    "start": "1069240",
    "end": "1074679"
  },
  {
    "text": "the existing compute that's already running on the data like maybe there's a close poer that's analyzing the data so",
    "start": "1074679",
    "end": "1080919"
  },
  {
    "text": "you can write some code things like AWS Lambda that will present that new data set detect it and presented to the new",
    "start": "1080919",
    "end": "1087159"
  },
  {
    "text": "compute environments so data lake is a journey it's it's not",
    "start": "1087159",
    "end": "1094039"
  },
  {
    "text": "a pattern that you'll say okay you know we we we we're done with just you know if you had these 10 things we're done",
    "start": "1094039",
    "end": "1100200"
  },
  {
    "text": "with the data link you're going to discover new capabilities you're going to build new capabilities you're going",
    "start": "1100200",
    "end": "1106360"
  },
  {
    "text": "to use open source tools you're going to use AWS Services you're going to off the shell tool your use case going to",
    "start": "1106360",
    "end": "1114000"
  },
  {
    "text": "determine what how you approach and what you build with your data Lake",
    "start": "1114000",
    "end": "1119400"
  },
  {
    "text": "capability so with that I'd like to invite SAR mahanti to talk to us about",
    "start": "1119400",
    "end": "1126360"
  },
  {
    "text": "their Journey for MJ dat like",
    "start": "1126360",
    "end": "1132760"
  },
  {
    "text": "oh thank you",
    "start": "1132760",
    "end": "1140000"
  },
  {
    "text": "good afternoon everyone and uh thank you NJ for the introduction um so n just covered what",
    "start": "1140000",
    "end": "1146960"
  },
  {
    "text": "the data Lake concept is its different uh its architecture and uh one of the",
    "start": "1146960",
    "end": "1152320"
  },
  {
    "text": "patterns on how to build uh a data Lake uh but he he also said that there are",
    "start": "1152320",
    "end": "1157799"
  },
  {
    "text": "multiple implementation patterns for a data Lake and I will uh briefly cover uh",
    "start": "1157799",
    "end": "1163240"
  },
  {
    "text": "real life implementation of an Enterprise data lake at amen I'll try and focus mostly on the value our",
    "start": "1163240",
    "end": "1169440"
  },
  {
    "text": "business users have been getting after we deployed the data",
    "start": "1169440",
    "end": "1174640"
  },
  {
    "text": "Lake um so amen is a biotechnology company located in uh Thousand Oaks",
    "start": "1174640",
    "end": "1182000"
  },
  {
    "text": "California just about 40 Mi north of Los Angeles and uh we are one of the",
    "start": "1182000",
    "end": "1188360"
  },
  {
    "text": "Pioneers in the science of using uh living cells to make biological",
    "start": "1188360",
    "end": "1194720"
  },
  {
    "text": "medicines um for over 35 years we we've been one of the leaders in the",
    "start": "1194720",
    "end": "1200480"
  },
  {
    "text": "biotechnology research space as well as clinical development and biologics",
    "start": "1200480",
    "end": "1206760"
  },
  {
    "text": "Manufacturing and over the last few years we're seeing that the uh role of",
    "start": "1206760",
    "end": "1212600"
  },
  {
    "text": "data and analytics is becoming very very critical in the success of these business functions so at amen I manage",
    "start": "1212600",
    "end": "1221039"
  },
  {
    "text": "uh the Big Data Engineering Group and my group along with a um a set of other",
    "start": "1221039",
    "end": "1227240"
  },
  {
    "text": "partner services uh provide this Enterprise data Lake platform to our business users and",
    "start": "1227240",
    "end": "1233880"
  },
  {
    "text": "functional uh functional units so um our journey started about 2",
    "start": "1233880",
    "end": "1240919"
  },
  {
    "text": "years ago when a couple of our uh key business units were going through some",
    "start": "1240919",
    "end": "1246400"
  },
  {
    "text": "significant transformation uh the first unit was our process Development Group now the",
    "start": "1246400",
    "end": "1251760"
  },
  {
    "text": "process Development Group is group of scientists who are looking at um data",
    "start": "1251760",
    "end": "1257840"
  },
  {
    "text": "from from our um our Laboratories our manufacturing lines or Biore reactors",
    "start": "1257840",
    "end": "1264240"
  },
  {
    "text": "all the time in order to improve and optimize our manufacturing processes our",
    "start": "1264240",
    "end": "1269440"
  },
  {
    "text": "operations processes uh the second group is our observational research group and",
    "start": "1269440",
    "end": "1275400"
  },
  {
    "text": "uh this group is uh essentially statisticians and epidemiologists who",
    "start": "1275400",
    "end": "1280480"
  },
  {
    "text": "look at uh real world evidence or um electronic medical records electronic",
    "start": "1280480",
    "end": "1286440"
  },
  {
    "text": "health records claims Etc and omized data uh in order to do observational",
    "start": "1286440",
    "end": "1291559"
  },
  {
    "text": "studies uh so that they can you know look at the safety efficacy and um you",
    "start": "1291559",
    "end": "1299440"
  },
  {
    "text": "know economic value of Ament products so as part of their transformation they um",
    "start": "1299440",
    "end": "1306159"
  },
  {
    "text": "were asking for a new type of analytics um much and more and more data you know",
    "start": "1306159",
    "end": "1313080"
  },
  {
    "text": "types of data that we had not uh used earlier we hadn't you know managed",
    "start": "1313080",
    "end": "1318240"
  },
  {
    "text": "earlier and uh within is we quickly realized that we need a a different kind of solution our traditional data",
    "start": "1318240",
    "end": "1324799"
  },
  {
    "text": "warehouse uh solutions would not number one scale up to handle the volumes we",
    "start": "1324799",
    "end": "1330000"
  },
  {
    "text": "were expecting and number two they would not uh they they would not provide the",
    "start": "1330000",
    "end": "1335320"
  },
  {
    "text": "capabilities or the features our uh business users were asking um apart from that our it leaders",
    "start": "1335320",
    "end": "1342919"
  },
  {
    "text": "were also asking us to move more towards a cloud-based infrastructure uh trying to leverage more um open- Source",
    "start": "1342919",
    "end": "1350840"
  },
  {
    "text": "Technologies Big Data Technologies um microservices devops",
    "start": "1350840",
    "end": "1356120"
  },
  {
    "text": "Etc so we came up with this idea of building a data Lake okay uh a single",
    "start": "1356120",
    "end": "1363279"
  },
  {
    "text": "data Lake in concept which uh would serve multiple business functions right",
    "start": "1363279",
    "end": "1369720"
  },
  {
    "text": "uh not just our process development and uh uh observational research groups but",
    "start": "1369720",
    "end": "1374919"
  },
  {
    "text": "other groups in the future as well uh it would would have shared features so as",
    "start": "1374919",
    "end": "1379960"
  },
  {
    "text": "in when we deployed one capability whether it's uh search or in memory analytics or any new capability it would",
    "start": "1379960",
    "end": "1387159"
  },
  {
    "text": "be shared across all all units who would be using the data Lake uh it would have",
    "start": "1387159",
    "end": "1392679"
  },
  {
    "text": "a common shared infrastructure uh scalable infrastructure but with the ability to be deployed not only on the",
    "start": "1392679",
    "end": "1398919"
  },
  {
    "text": "cloud but also on our on- premise uh data centers uh and then we came to that with",
    "start": "1398919",
    "end": "1405520"
  },
  {
    "text": "you know one code base easier to maintain low cost all of those good things right so we called it our data",
    "start": "1405520",
    "end": "1411200"
  },
  {
    "text": "Lake platform so the the bottom layer is uh you know our overall data Lake",
    "start": "1411200",
    "end": "1417960"
  },
  {
    "text": "ecosystem that comprises of our core Hadoop platform as well as all the other",
    "start": "1417960",
    "end": "1423320"
  },
  {
    "text": "Associated Technologies and I'll get a little bit into the details of what this platform looks like uh the second layer",
    "start": "1423320",
    "end": "1430360"
  },
  {
    "text": "is the common tools and capabilities so these are you know search data processing visualization Etc um once the",
    "start": "1430360",
    "end": "1437880"
  },
  {
    "text": "these capabilities were available our business users started loading the um",
    "start": "1437880",
    "end": "1445039"
  },
  {
    "text": "raw data or you know the uh what we call a common data layer so from our",
    "start": "1445039",
    "end": "1450320"
  },
  {
    "text": "manufacturing uh group they started loading data from our Mees systems um",
    "start": "1450320",
    "end": "1455600"
  },
  {
    "text": "laboratory Information Management Systems uh lab notebook systems um then we had uh the real world",
    "start": "1455600",
    "end": "1464080"
  },
  {
    "text": "evidence data being loaded by our observational research team and then next year we are having our commercial",
    "start": "1464080",
    "end": "1470240"
  },
  {
    "text": "uh organization bringing in the sales and marketing data as well after this uh",
    "start": "1470240",
    "end": "1476399"
  },
  {
    "text": "common data layer of raw data it was available um various other groups",
    "start": "1476399",
    "end": "1482279"
  },
  {
    "text": "subgroups and even even manifacturing and uh C4 we building these uh",
    "start": "1482279",
    "end": "1488039"
  },
  {
    "text": "analytical applications so the pillars you see here are very focused uh",
    "start": "1488039",
    "end": "1493200"
  },
  {
    "text": "applications built to meet a specific um analytical purpose typically we would",
    "start": "1493200",
    "end": "1500520"
  },
  {
    "text": "have built a data Mark for uh building for these kind of applications and they",
    "start": "1500520",
    "end": "1505799"
  },
  {
    "text": "would be separate data marks spread all over the organization now we are able to build these within the data Lake itself",
    "start": "1505799",
    "end": "1513919"
  },
  {
    "text": "um using using all the different types of uh tools I'll cover in the next",
    "start": "1513919",
    "end": "1520278"
  },
  {
    "text": "slide so this is our high level architecture for the data Lake um it's",
    "start": "1522440",
    "end": "1528760"
  },
  {
    "text": "at a at a high level it is very similar to what NJ covered um in terms of the big boxes and",
    "start": "1528760",
    "end": "1537279"
  },
  {
    "text": "what I'll do is uh for each of these uh sections I will uh try and articulate",
    "start": "1537279",
    "end": "1544720"
  },
  {
    "text": "what the business value or the actual use of these components has been at",
    "start": "1544720",
    "end": "1551600"
  },
  {
    "text": "Amun okay so our core layer is our uh storage and processing layer this is",
    "start": "1552120",
    "end": "1558080"
  },
  {
    "text": "basically our Workhorse uh it contains all the data and the ability to um to uh",
    "start": "1558080",
    "end": "1566320"
  },
  {
    "text": "manipulate and transform the data right so initially we had rolled it out on a",
    "start": "1566320",
    "end": "1571399"
  },
  {
    "text": "Hadoop platform using hdfs um but now we've also added Amazon",
    "start": "1571399",
    "end": "1578399"
  },
  {
    "text": "S3 and uh we offer our clients the option of uh you know cost versus",
    "start": "1578399",
    "end": "1585120"
  },
  {
    "text": "performance balance whatever suits their their application their need uh we had",
    "start": "1585120",
    "end": "1590440"
  },
  {
    "text": "started off with uh yarn and map reduce we're slowly moving off of that and",
    "start": "1590440",
    "end": "1595880"
  },
  {
    "text": "introducing more and more spark applications and having the storage and processing capability on AWS has been uh",
    "start": "1595880",
    "end": "1604840"
  },
  {
    "text": "very helpful because it's fairly easy for us to readjust and reconfigure our",
    "start": "1604840",
    "end": "1611480"
  },
  {
    "text": "um AWS machines on ec2 when we need more memory for spark for instance we're",
    "start": "1611480",
    "end": "1616559"
  },
  {
    "text": "easily able to do that that um so the value our business has uh",
    "start": "1616559",
    "end": "1623960"
  },
  {
    "text": "got from the storage and processing um layer before the data Lake our um",
    "start": "1623960",
    "end": "1632120"
  },
  {
    "text": "observational research team would go in and buy these external data sets uh uh",
    "start": "1632120",
    "end": "1637559"
  },
  {
    "text": "electronic medical uh record sets which would range from about 100 GB to maybe 5",
    "start": "1637559",
    "end": "1644520"
  },
  {
    "text": "to 10 terabytes right but before they could actually even use that data set they had to figure out how to load it",
    "start": "1644520",
    "end": "1651320"
  },
  {
    "text": "into our SAS grid which was heavily used and uh there was always some activity or",
    "start": "1651320",
    "end": "1656799"
  },
  {
    "text": "the other going on on the sasd so the first thing they had to figure out was negotiating with other groups to so that",
    "start": "1656799",
    "end": "1664399"
  },
  {
    "text": "other groups can finish their analytics free up that much space and then they would load their data in uh in the SAS",
    "start": "1664399",
    "end": "1671320"
  },
  {
    "text": "grid and they could start their analytics this process used to take about um 2 to 3 months",
    "start": "1671320",
    "end": "1678039"
  },
  {
    "text": "so imagine buying the data and then after 3 months you really actually get to see it after we've put in the data",
    "start": "1678039",
    "end": "1684240"
  },
  {
    "text": "Lake that process has reduced to uh about one week right we get the data we",
    "start": "1684240",
    "end": "1691000"
  },
  {
    "text": "load it immediately into Hadoop apart from that we also spin up an elastic compute capability in red shift load the",
    "start": "1691000",
    "end": "1697640"
  },
  {
    "text": "data there run a whole bunch of metrics uh and data quality checks and by the",
    "start": "1697640",
    "end": "1703360"
  },
  {
    "text": "end of the week when we publish the data back to our end users it's uh it's",
    "start": "1703360",
    "end": "1709919"
  },
  {
    "text": "already loaded it's been data quality checked and uh they already have metrics",
    "start": "1709919",
    "end": "1715519"
  },
  {
    "text": "that they were looking for um in order to start their analytics right so we've reduced the cycle time from um 2 to 3",
    "start": "1715519",
    "end": "1723320"
  },
  {
    "text": "months to about a week apart from that because our SAS environment was a shared",
    "start": "1723320",
    "end": "1729159"
  },
  {
    "text": "environment uh queries you would take you know 20 to 30 hours now most of our",
    "start": "1729159",
    "end": "1734600"
  },
  {
    "text": "queries run within 15 minutes uh so they are getting significant performance",
    "start": "1734600",
    "end": "1740120"
  },
  {
    "text": "benefits on this and um you know their their throughput has increased quite a",
    "start": "1740120",
    "end": "1746919"
  },
  {
    "text": "lot so the next layer is our procure and ingest layer this is how we get data",
    "start": "1748360",
    "end": "1753760"
  },
  {
    "text": "into the data Lake um we have four different patterns the first one is your",
    "start": "1753760",
    "end": "1759120"
  },
  {
    "text": "standard structured data which is coming from either um um databases or flat",
    "start": "1759120",
    "end": "1766480"
  },
  {
    "text": "files structured flat files the second one is uh real-time data ingestion this is either a um a real time connection",
    "start": "1766480",
    "end": "1775600"
  },
  {
    "text": "with a source system or streaming data from our um benchtop instruments and",
    "start": "1775600",
    "end": "1782559"
  },
  {
    "text": "various sensors in our um uh manufacturing lines so we use Kafka and",
    "start": "1782559",
    "end": "1789760"
  },
  {
    "text": "Spark streaming for doing that then uh we also have a lot of unstructured data",
    "start": "1789760",
    "end": "1795760"
  },
  {
    "text": "so um especially in the process development space Pro the scientists",
    "start": "1795760",
    "end": "1800880"
  },
  {
    "text": "they conduct a lot of experiments and the experiments actually have",
    "start": "1800880",
    "end": "1806159"
  },
  {
    "text": "uh the the recipe for the experiment what materials are used what kind of",
    "start": "1806159",
    "end": "1811360"
  },
  {
    "text": "steps they took for conducting those experiments and then finally um the",
    "start": "1811360",
    "end": "1816519"
  },
  {
    "text": "results and their conclusions right so that's all in a PDF document um and then finally we have uh",
    "start": "1816519",
    "end": "1823519"
  },
  {
    "text": "cloud data integration pattern excuse me",
    "start": "1823519",
    "end": "1829240"
  },
  {
    "text": "to do my little Mark thing um so the value our process development scientists",
    "start": "1834279",
    "end": "1840360"
  },
  {
    "text": "have been getting out of this uh uh ingestion layer is before the data Lake",
    "start": "1840360",
    "end": "1847559"
  },
  {
    "text": "if they had to do a root cause analysis of any incident so let's say there was a",
    "start": "1847559",
    "end": "1853679"
  },
  {
    "text": "particular um value that they were tracking for for a for a a lot and uh",
    "start": "1853679",
    "end": "1860760"
  },
  {
    "text": "that was going off the boundaries and they needed to do a root cause analysis the first thing they had to do was go",
    "start": "1860760",
    "end": "1865960"
  },
  {
    "text": "through our document Management Systems uh hundreds of documents just to figure",
    "start": "1865960",
    "end": "1871120"
  },
  {
    "text": "out what data sets they needed once they found the data sets then they had to call up the owners of those data sets in",
    "start": "1871120",
    "end": "1877960"
  },
  {
    "text": "order to have that emailed to them right only then they could start their",
    "start": "1877960",
    "end": "1883240"
  },
  {
    "text": "analysis now with our structured data ingestion real time inje an unstructured data pipeline we have uh 20 data sets",
    "start": "1883240",
    "end": "1890960"
  },
  {
    "text": "coming in from our Manufacturing Systems real-time injection of more than 4,000",
    "start": "1890960",
    "end": "1897240"
  },
  {
    "text": "messages per second from our uh sensors and all the lab notebook data",
    "start": "1897240",
    "end": "1904039"
  },
  {
    "text": "and uh uh document repositories uh crawled into our data Lake Artic um",
    "start": "1904039",
    "end": "1910600"
  },
  {
    "text": "annotated and a search index available for that right that whole the original",
    "start": "1910600",
    "end": "1916799"
  },
  {
    "text": "process would take anywhere between 10 to 12 weeks now they are able to do the same thing in literally a day and once",
    "start": "1916799",
    "end": "1923960"
  },
  {
    "text": "they find out what data they need they can use any product any tool visualization tool like Spotfire or any",
    "start": "1923960",
    "end": "1931240"
  },
  {
    "text": "obbc compliant uh tool to go and query that data in the data",
    "start": "1931240",
    "end": "1937960"
  },
  {
    "text": "Lake okay the next layer is uh the curate and enrichment layer um this is I",
    "start": "1941120",
    "end": "1948200"
  },
  {
    "text": "talked about this earlier uh this is basically the data Mart concept that uh",
    "start": "1948200",
    "end": "1953679"
  },
  {
    "text": "is you know mainly targeted applications that are used by only a focused group of",
    "start": "1953679",
    "end": "1959880"
  },
  {
    "text": "users uh and they basically sit on the data Lake the reference data linkage is an interesting thing uh we found that",
    "start": "1959880",
    "end": "1968120"
  },
  {
    "text": "once you have data from various sources uh whether it's structured or",
    "start": "1968120",
    "end": "1973159"
  },
  {
    "text": "unstructured you uh at some point need to have an easy way of linking that data",
    "start": "1973159",
    "end": "1980159"
  },
  {
    "text": "across uh systems and enriching that data with uh ontologies and vocabularies",
    "start": "1980159",
    "end": "1985760"
  },
  {
    "text": "for instance um a typical product goes through so many different names right it",
    "start": "1985760",
    "end": "1992360"
  },
  {
    "text": "starts with a scientific name then it gets a uh code name like an AMG name",
    "start": "1992360",
    "end": "1998960"
  },
  {
    "text": "then finally it gets launched and it has marketing name so when somebody like a process development scientist is doing a",
    "start": "1998960",
    "end": "2005600"
  },
  {
    "text": "root cause analysis they shouldn't have to know all these different names right and what we do",
    "start": "2005600",
    "end": "2013360"
  },
  {
    "text": "with uh the reference data linkage is connect this data to our um uh ontology",
    "start": "2013360",
    "end": "2019960"
  },
  {
    "text": "systems on semaphore and uh you know their search",
    "start": "2019960",
    "end": "2025080"
  },
  {
    "text": "results are always consistent no matter what uh um what name they use the other",
    "start": "2025080",
    "end": "2031600"
  },
  {
    "text": "thing that we are building out is a data catalog uh we have an initial data catalog but uh we we see the need for",
    "start": "2031600",
    "end": "2038200"
  },
  {
    "text": "actually having a more robust data catalog um we're still about a year year and a half old by the time we have a lot",
    "start": "2038200",
    "end": "2046080"
  },
  {
    "text": "more data in a few years uh this is going to be the make or break system for",
    "start": "2046080",
    "end": "2051440"
  },
  {
    "text": "the success of the data Lake um finally we have uh a single",
    "start": "2051440",
    "end": "2058878"
  },
  {
    "text": "layer um that an access portal that allows users to connect to the data Lake",
    "start": "2058879",
    "end": "2066000"
  },
  {
    "text": "uh all the data in uh in the lake is uh secured using uh keros so all the",
    "start": "2066000",
    "end": "2072638"
  },
  {
    "text": "systems that have to connect to the data Lake you know use u a common keros",
    "start": "2072639",
    "end": "2078800"
  },
  {
    "text": "authentication and uh um from a user point of view all they have to do is log",
    "start": "2078800",
    "end": "2084398"
  },
  {
    "text": "onto the access portal and then from there they have access to all of these different types of analytics so apart",
    "start": "2084399",
    "end": "2091040"
  },
  {
    "text": "from having you know your basic analytics and visualization in Spotfire and SAS Etc uh we are seeing a lot of",
    "start": "2091040",
    "end": "2099000"
  },
  {
    "text": "demand for more data science like tools right so you know using R Jupiter um",
    "start": "2099000",
    "end": "2107240"
  },
  {
    "text": "various notebooks and this demand for doing self-service analytics is getting more",
    "start": "2107240",
    "end": "2113640"
  },
  {
    "text": "and more uh common uh among our user group and then finally we have uh the",
    "start": "2113640",
    "end": "2119000"
  },
  {
    "text": "ability to build more focused applications um using you know things",
    "start": "2119000",
    "end": "2124400"
  },
  {
    "text": "like graph databases neo4j uh building specific visualizations uh on that data using",
    "start": "2124400",
    "end": "2132040"
  },
  {
    "text": "things like uh",
    "start": "2132040",
    "end": "2135000"
  },
  {
    "text": "d3js so that's a lot of work right I mean",
    "start": "2138320",
    "end": "2143680"
  },
  {
    "text": "what I just covered was not just here's Hadoop that's your data link right you",
    "start": "2143680",
    "end": "2149240"
  },
  {
    "text": "do have to do a lot of figuring out how do you handle security how do you handle connectivity right all of those things",
    "start": "2149240",
    "end": "2155920"
  },
  {
    "text": "are very very important and we took about a year and a half to figure it out right so I'm going to hand",
    "start": "2155920",
    "end": "2162680"
  },
  {
    "text": "it over to Dario and he's going to show you a better way of doing it thank",
    "start": "2162680",
    "end": "2170720"
  },
  {
    "text": "you you hear me okay hi my name is Dario Rivera I'm a Solutions architect with",
    "start": "2171119",
    "end": "2176560"
  },
  {
    "text": "AWS I've been with AWS about four years and uh you know sarv went through",
    "start": "2176560",
    "end": "2181920"
  },
  {
    "text": "essentially am Jen's Journey on how they built data Lake and as uh we saw there",
    "start": "2181920",
    "end": "2186960"
  },
  {
    "text": "was a lot of complexity and a lot of thought that went into making sure that they're building the right types of",
    "start": "2186960",
    "end": "2192760"
  },
  {
    "text": "tools the right types of solutions to assure that they're getting the best value for their users Amgen scientists",
    "start": "2192760",
    "end": "2199680"
  },
  {
    "text": "Amgen uh data analytics folks uh to really get the true value of the data",
    "start": "2199680",
    "end": "2205359"
  },
  {
    "text": "that they're collecting and uh that was a very very excellent solution I",
    "start": "2205359",
    "end": "2210560"
  },
  {
    "text": "wouldn't say that what we're going to be presenting now is uh any better but it at least allows you to get started quick",
    "start": "2210560",
    "end": "2216680"
  },
  {
    "text": "quicker and be up and running with a data Lake um in essentially a matter of",
    "start": "2216680",
    "end": "2222280"
  },
  {
    "text": "minutes so what we're going to be introducing to you today is something called the data Lake solution uh this is",
    "start": "2222280",
    "end": "2229480"
  },
  {
    "text": "something that we uh within Amazon have been recognizing as having a lot of",
    "start": "2229480",
    "end": "2234839"
  },
  {
    "text": "value for our customers the fact that um they're not necessarily Services even",
    "start": "2234839",
    "end": "2240839"
  },
  {
    "text": "though we could have presented this as a service but more a sort of starter kit to help you go um we know that",
    "start": "2240839",
    "end": "2248200"
  },
  {
    "text": "especially as we looked at the complexity that Amgen brought forth as part of their data Lake you want the",
    "start": "2248200",
    "end": "2254119"
  },
  {
    "text": "capability of getting some core functionality out of something like data lake or any other sort of major concept",
    "start": "2254119",
    "end": "2261119"
  },
  {
    "text": "but still have the flexibility to be able to uh do what you need within your organization add a certain typ of",
    "start": "2261119",
    "end": "2267319"
  },
  {
    "text": "security structure that represents the uniqueness of uh what you want Associated to your Enterprise or be able",
    "start": "2267319",
    "end": "2274280"
  },
  {
    "text": "to uh add other value on top of the kind of core capability that we've already been talking about so what the data Lake",
    "start": "2274280",
    "end": "2282160"
  },
  {
    "text": "solution uh defined by the data l or the solution Builders team which is an",
    "start": "2282160",
    "end": "2287800"
  },
  {
    "text": "internal team within Amazon there's actually another talk um where Sean sior is going to be talking about with the",
    "start": "2287800",
    "end": "2292839"
  },
  {
    "text": "solution Builder team they've uh collaborated together with some of the AWS SAS uh who have insights into what",
    "start": "2292839",
    "end": "2299400"
  },
  {
    "text": "the customers are doing and said hey we need to do something better than just give them an implementation guide we",
    "start": "2299400",
    "end": "2306079"
  },
  {
    "text": "need to doing something better than just saying hey look at this reference architecture and you'll kind of figure",
    "start": "2306079",
    "end": "2311319"
  },
  {
    "text": "it out by yourself we need to give them comprehensive capability that allows",
    "start": "2311319",
    "end": "2316440"
  },
  {
    "text": "them to after a push of a button be able to get an up and running data Lake and",
    "start": "2316440",
    "end": "2321720"
  },
  {
    "text": "then after looking at what that data lake is about saying you know we could do this or we could do that and make it",
    "start": "2321720",
    "end": "2328079"
  },
  {
    "text": "better or we can find ways to integrated into what we do here at XYZ organization",
    "start": "2328079",
    "end": "2334040"
  },
  {
    "text": "that's going to really benefit us and that move moves the needle from literally maybe a year a year and a half",
    "start": "2334040",
    "end": "2340119"
  },
  {
    "text": "worth of development that has a lot of entropy behind it and making it",
    "start": "2340119",
    "end": "2345319"
  },
  {
    "text": "difficult to really move forward or even a VP going uh that's too long let's not even bother because that's too much",
    "start": "2345319",
    "end": "2351079"
  },
  {
    "text": "resources to now say wow this is really of high value we can really do something",
    "start": "2351079",
    "end": "2357119"
  },
  {
    "text": "with making data Lake a viable solution within our Enterprise so what is data",
    "start": "2357119",
    "end": "2362160"
  },
  {
    "text": "Lake it's essentially a cloud formation script uh Associated to a number of resources that are built within the",
    "start": "2362160",
    "end": "2368440"
  },
  {
    "text": "region that uh give you an up and running data Lake website it's uh within",
    "start": "2368440",
    "end": "2374680"
  },
  {
    "text": "your account it's essentially um a representation of a lot of serverless",
    "start": "2374680",
    "end": "2382440"
  },
  {
    "text": "capability that Amazon offers and we're going to go into a little bit about what that means uh it's essentially a",
    "start": "2382440",
    "end": "2388040"
  },
  {
    "text": "serverless data Lake solution there are no ec2 instances running that you have",
    "start": "2388040",
    "end": "2393160"
  },
  {
    "text": "to manage there's no patching capability that you have to worry about obviously uh depending on your security needs you",
    "start": "2393160",
    "end": "2399800"
  },
  {
    "text": "would be wanting to know how to take some of these capabilities and build your own security platform on top of",
    "start": "2399800",
    "end": "2405839"
  },
  {
    "text": "that but essentially as I mentioned it's a starter kit to get you going um it",
    "start": "2405839",
    "end": "2411280"
  },
  {
    "text": "starts out with S3 um as Naraj mentioned this is the foundation of data Lake this",
    "start": "2411280",
    "end": "2418480"
  },
  {
    "text": "is where all the data sets are hosted um and you have the ability to Now package",
    "start": "2418480",
    "end": "2424920"
  },
  {
    "text": "a solution around those data sets that represent some of the core capability that we talked about previously the",
    "start": "2424920",
    "end": "2430800"
  },
  {
    "text": "thing like catalog and search uh stuff like uh being able to um build a",
    "start": "2430800",
    "end": "2436920"
  },
  {
    "text": "environment that allows you to ingest those data sets into something that you can do high-end analytics on uh the",
    "start": "2436920",
    "end": "2443560"
  },
  {
    "text": "capability of doing um correlations across many different data sets to",
    "start": "2443560",
    "end": "2448880"
  },
  {
    "text": "understand how they work together so this is uh sort of the representation of",
    "start": "2448880",
    "end": "2454319"
  },
  {
    "text": "the environment that the cloud information script is going to be given you as it shows here it's two buckets uh",
    "start": "2454319",
    "end": "2461240"
  },
  {
    "text": "one's Associated to the static website hosting the other one gives you a primary data Lake for uh where all your",
    "start": "2461240",
    "end": "2467839"
  },
  {
    "text": "data will be stored and that bucket is really just up to you in terms of what you want to do or where you want to put",
    "start": "2467839",
    "end": "2474640"
  },
  {
    "text": "it you have an API Gateway that is the micr services layer that's built on top of this whole solution and represents",
    "start": "2474640",
    "end": "2482400"
  },
  {
    "text": "how you will be interfacing with the functionality of the data Lake Dynamo DB",
    "start": "2482400",
    "end": "2487640"
  },
  {
    "text": "um seven tables that uh Define all the intricacies of what's going to be done",
    "start": "2487640",
    "end": "2494000"
  },
  {
    "text": "to manage the data Lake and manage the metadata that represents the data sets hosted within your data Lake uh a",
    "start": "2494000",
    "end": "2501160"
  },
  {
    "text": "Cognito user pool to manage the users that you would be building a bunch of Lambda functions an elastic search",
    "start": "2501160",
    "end": "2507079"
  },
  {
    "text": "cluster and then obviously identity and access management to control all of that",
    "start": "2507079",
    "end": "2512520"
  },
  {
    "text": "so let's go through a run through of what this actually looks like and you're going to go hold on you're uh",
    "start": "2512520",
    "end": "2519079"
  },
  {
    "text": "faking it I don't know if I like that because it's a video and yes it is a",
    "start": "2519079",
    "end": "2524200"
  },
  {
    "text": "video and the reason it's a video is because if I did this live You' be paying more attention to me clicking",
    "start": "2524200",
    "end": "2530359"
  },
  {
    "text": "buttons and less on what the capability of the data lake is so I'm ensure that this runs smoothly and take the demo",
    "start": "2530359",
    "end": "2537119"
  },
  {
    "text": "Gods out out of it I'm going to be showing you the video but once you uh",
    "start": "2537119",
    "end": "2542680"
  },
  {
    "text": "get access to the solution everything that I show in this video you will immediately be able to do within your",
    "start": "2542680",
    "end": "2547920"
  },
  {
    "text": "AWS account when you actually run the cloud formation script and build it within your environment so if you want",
    "start": "2547920",
    "end": "2554960"
  },
  {
    "text": "access to this video it's already live on that URL and obviously like all the presentations you'll have here at",
    "start": "2554960",
    "end": "2560800"
  },
  {
    "text": "reinvent uh the slides will be available to you as well as the videos on YouTube probably in around two weeks time frame",
    "start": "2560800",
    "end": "2567880"
  },
  {
    "text": "so let's take a look um here it is somebody actually signing in this is going to be a guest and uh the you the",
    "start": "2567880",
    "end": "2576319"
  },
  {
    "text": "guest email was already registered preand and uh now the guest is signing in so this is what the data Lake looks",
    "start": "2576319",
    "end": "2583800"
  },
  {
    "text": "like you have the ability to uh search on existing resources uh within the data",
    "start": "2583800",
    "end": "2589480"
  },
  {
    "text": "Lake and now you get a search result the search result allows you to see uh an",
    "start": "2589480",
    "end": "2595119"
  },
  {
    "text": "overview of the data set let's pause it here for a second and as you see here you have a package ID a package name a",
    "start": "2595119",
    "end": "2601599"
  },
  {
    "text": "package is essentially the representation within this solution of data set but a package represents",
    "start": "2601599",
    "end": "2609599"
  },
  {
    "text": "essentially the metadata that the data set is about so data set obviously is raw data probably hosted within S3 uh",
    "start": "2609599",
    "end": "2616839"
  },
  {
    "text": "the package represents um the sort of dictionary uh representation of what",
    "start": "2616839",
    "end": "2622920"
  },
  {
    "text": "that data set is and you have a package name and you have a description that you have the ability uh to see more insights",
    "start": "2622920",
    "end": "2629480"
  },
  {
    "text": "into what this data set is all about so you can also see contents and",
    "start": "2629480",
    "end": "2634680"
  },
  {
    "text": "the contents represent all the individual files that represent the data set um moving forward you also actually",
    "start": "2634680",
    "end": "2642880"
  },
  {
    "text": "are also get to see history so when the data set was created you also uh have",
    "start": "2642880",
    "end": "2648480"
  },
  {
    "text": "the ability to see who is accessing the data set in terms of when they actually download it from your S3 bucket into",
    "start": "2648480",
    "end": "2655359"
  },
  {
    "text": "their own environment so you get full audit Trail capability especially thinking about highly regulated",
    "start": "2655359",
    "end": "2660400"
  },
  {
    "text": "environments this is really important so uh it works a lot like",
    "start": "2660400",
    "end": "2667359"
  },
  {
    "text": "amazon.com hint hint um what happens here is you add uh the ability to get",
    "start": "2667359",
    "end": "2673640"
  },
  {
    "text": "what's called a manifest file and put it into your cart the Manifest file uh once",
    "start": "2673640",
    "end": "2679280"
  },
  {
    "text": "it's added to the cart represents the capability of downloading a file that is",
    "start": "2679280",
    "end": "2684599"
  },
  {
    "text": "a Json formatted file of all the S3 Paths of the data set that you uh just",
    "start": "2684599",
    "end": "2691680"
  },
  {
    "text": "put into your cart so we're going to show how this is being done now user is adding a data set to his cart then you",
    "start": "2691680",
    "end": "2698720"
  },
  {
    "text": "actually go to the cart and you see that you have one one",
    "start": "2698720",
    "end": "2705359"
  },
  {
    "text": "man uh one uh item in your cart you're downloading the ability to create a",
    "start": "2705359",
    "end": "2710720"
  },
  {
    "text": "manifest file and this will probably change in the near future but right now you have the ability to use signed URLs",
    "start": "2710720",
    "end": "2718680"
  },
  {
    "text": "or actually a Json file representing the true path of the S3 file and the reason",
    "start": "2718680",
    "end": "2724480"
  },
  {
    "text": "why we wanted to give you this capability is specifically from a um Insight perspective around security so",
    "start": "2724480",
    "end": "2730720"
  },
  {
    "text": "sometimes the people using uh this um capability of the Manifest file may want",
    "start": "2730720",
    "end": "2737359"
  },
  {
    "text": "to get access directly from the S3 uh path itself but sometimes uh because of the nature of the structure of your S3",
    "start": "2737359",
    "end": "2743960"
  },
  {
    "text": "bucket you may be wanting to hide certain uh aspects of the structure of that S3 bucket so creating a signed URL",
    "start": "2743960",
    "end": "2752079"
  },
  {
    "text": "kind of U obus skates that path of of of what actually is within your S3 bucket",
    "start": "2752079",
    "end": "2758000"
  },
  {
    "text": "and so when the when the Manifest file is created in your Json all they see is",
    "start": "2758000",
    "end": "2763400"
  },
  {
    "text": "essentially a bunch of gobbly cook that represents the actual data set and not the true path of the bucket",
    "start": "2763400",
    "end": "2770960"
  },
  {
    "text": "itself so as uh now we're going to download the Manifest file and we have download leaks that are automatically",
    "start": "2773839",
    "end": "2781119"
  },
  {
    "text": "created um now it's downloading locally the Manifest file and as you can see",
    "start": "2781119",
    "end": "2786559"
  },
  {
    "text": "here um I just showed you what a structured Json file looks like uh representing the Manifest Paths of your",
    "start": "2786559",
    "end": "2794520"
  },
  {
    "text": "data set so what this means is that now you can take this manifest file put it",
    "start": "2794520",
    "end": "2800520"
  },
  {
    "text": "into something like a red shift cluster and then be able to automatically load the data representative in this manifest",
    "start": "2800520",
    "end": "2806400"
  },
  {
    "text": "file into the red shift cluster to be up and running within an analytics",
    "start": "2806400",
    "end": "2812078"
  },
  {
    "text": "environment so we continue on um you have the ability to uh sign in as a guest but also as an administrator if",
    "start": "2812839",
    "end": "2819760"
  },
  {
    "text": "you're an administrator you get a little bit more control over what you do within your data",
    "start": "2819760",
    "end": "2825319"
  },
  {
    "text": "lake so you're going to go into settings and as you can see here settings give you a number of different components of",
    "start": "2825319",
    "end": "2832040"
  },
  {
    "text": "the resources that are used within your data lake so you get a little bit more insight into what's actually being built",
    "start": "2832040",
    "end": "2838000"
  },
  {
    "text": "within your account you also have the concept of",
    "start": "2838000",
    "end": "2844400"
  },
  {
    "text": "governance so the reason why we wanted to include this is because um without cataloging and",
    "start": "2844400",
    "end": "2851599"
  },
  {
    "text": "search capability of your data sets your data lake is a data swamp it's based off",
    "start": "2851599",
    "end": "2857240"
  },
  {
    "text": "of tribal knowledge and you have fairly limited control over of the insights",
    "start": "2857240",
    "end": "2862760"
  },
  {
    "text": "into what your data lake is hosting so what governance does is allow you to",
    "start": "2862760",
    "end": "2868280"
  },
  {
    "text": "apply tags that are either mandatory or optional that can be applied to a data",
    "start": "2868280",
    "end": "2874280"
  },
  {
    "text": "set when it's created so across your data Lake you can create mandatory tags",
    "start": "2874280",
    "end": "2880000"
  },
  {
    "text": "that represent um what every data set within your data Lake should have and then you can also create optional tags",
    "start": "2880000",
    "end": "2886760"
  },
  {
    "text": "to say if the user wanted to when he created data sets they can add the",
    "start": "2886760",
    "end": "2891920"
  },
  {
    "text": "information about that particular tag in there but they don't have to you also have the ability to add um",
    "start": "2891920",
    "end": "2898920"
  },
  {
    "text": "you know data set specific tags as necessary but we wanted to make sure that across the whole data Lake there",
    "start": "2898920",
    "end": "2904200"
  },
  {
    "text": "was a concept of an optional and required that are built upon upon it so now we're going to actually create a",
    "start": "2904200",
    "end": "2910559"
  },
  {
    "text": "data lake so here I'm working from healthdata.gov and I'm just going to be copy and pasting the title and the",
    "start": "2910559",
    "end": "2916520"
  },
  {
    "text": "description of this data Lake um and then be taking the information provided in this uh public data set and putting",
    "start": "2916520",
    "end": "2924240"
  },
  {
    "text": "it into the data Lake",
    "start": "2924240",
    "end": "2927480"
  },
  {
    "text": "solution so just adding a name adding the",
    "start": "2931799",
    "end": "2940480"
  },
  {
    "text": "description and as you can see here those optional and mandatory tags are automatically included if it's a",
    "start": "2940920",
    "end": "2946920"
  },
  {
    "text": "mandatory tag it'll have a star on it given what you would expect from most websites and we're adding an optional",
    "start": "2946920",
    "end": "2954160"
  },
  {
    "text": "value to a tag and now I create the",
    "start": "2954160",
    "end": "2958000"
  },
  {
    "text": "package so as you can see here this is just a package created there's no content in it and as you can see in the",
    "start": "2960040",
    "end": "2966720"
  },
  {
    "text": "tab there it says content zero so we actually have to add some content but before we do that we're going to add",
    "start": "2966720",
    "end": "2972000"
  },
  {
    "text": "some optional metadata so here you have the ability to",
    "start": "2972000",
    "end": "2977559"
  },
  {
    "text": "add specific uh data sets or or metadata you could also have the ability to change or remove the package after you",
    "start": "2977559",
    "end": "2984839"
  },
  {
    "text": "create it as necessary so when I actually search",
    "start": "2984839",
    "end": "2990079"
  },
  {
    "text": "against the data set using the key term stroke since we know that's in the title",
    "start": "2990079",
    "end": "2995119"
  },
  {
    "text": "I see that it shows up as part of my",
    "start": "2995119",
    "end": "2998960"
  },
  {
    "text": "search so now I'm going to add some content to the metadata or to the data set",
    "start": "3002599",
    "end": "3009760"
  },
  {
    "text": "package and I'm going to publish a local file what this means is I have something on my laptop and I'm going to add that",
    "start": "3011359",
    "end": "3018240"
  },
  {
    "text": "into the S3 bucket that's being managed by the data L solution and it's going to reference that into the data pack data",
    "start": "3018240",
    "end": "3025040"
  },
  {
    "text": "set package which I just created so here I just added that that local data in and",
    "start": "3025040",
    "end": "3030400"
  },
  {
    "text": "now I'll be able to see it so the nice thing about the data link solution is that you have the ability to",
    "start": "3030400",
    "end": "3037520"
  },
  {
    "text": "uh manage users at will creating admins and guests as needed and we're showing",
    "start": "3037520",
    "end": "3043359"
  },
  {
    "text": "here how you have the ability to create a user so right now we're creating an admin and this new admin shows up and",
    "start": "3043359",
    "end": "3051799"
  },
  {
    "text": "the idea is it's all based off of the email so when you create a new user",
    "start": "3051799",
    "end": "3057160"
  },
  {
    "text": "using that person's email an automatic email will be sent to that user's email account and it'll have the temporary",
    "start": "3057160",
    "end": "3064200"
  },
  {
    "text": "password that that user can use to log in so uh it also has the the the URL",
    "start": "3064200",
    "end": "3070240"
  },
  {
    "text": "representative of the data lake so now the new user the new admin is is uh going into the data Lake for the first",
    "start": "3070240",
    "end": "3077400"
  },
  {
    "text": "time and using that temporary password he's going to be asked to change his password to a password that he decides",
    "start": "3077400",
    "end": "3084200"
  },
  {
    "text": "or she decides",
    "start": "3084200",
    "end": "3087359"
  },
  {
    "text": "and now he's in so the new user has access to create data sets and do",
    "start": "3091160",
    "end": "3096640"
  },
  {
    "text": "everything that normal admins do so this is all great but it's useful to a",
    "start": "3096640",
    "end": "3103079"
  },
  {
    "text": "certain point without having a CLI or a command line interface API application",
    "start": "3103079",
    "end": "3108920"
  },
  {
    "text": "programming interface obviously what this means is that this is just a website data set data lake is great if a",
    "start": "3108920",
    "end": "3116799"
  },
  {
    "text": "user needs to interact with it but what about if you have this whizbang application that you want to also be",
    "start": "3116799",
    "end": "3122240"
  },
  {
    "text": "able to search on data sets and then be able to automatically take those data sets and put it into its environment so",
    "start": "3122240",
    "end": "3129480"
  },
  {
    "text": "the nice thing about the data L solution is that it offers you the capability of",
    "start": "3129480",
    "end": "3134640"
  },
  {
    "text": "uh interacting with it strictly from an API or CLI standpoint so we're going to show a demo of that now you actually",
    "start": "3134640",
    "end": "3141040"
  },
  {
    "text": "have to generate an API access key every time uh a user is created and they want API access as well as a secret key that",
    "start": "3141040",
    "end": "3149680"
  },
  {
    "text": "is going to be used when they want to log in to the CLI and make it available",
    "start": "3149680",
    "end": "3156520"
  },
  {
    "text": "so we've copied and pasted the uh access key and secret key very similar to what you do when you create um a CLI capable",
    "start": "3156520",
    "end": "3164520"
  },
  {
    "text": "uh AWS interface you also have you know full documentation on how to do all this",
    "start": "3164520",
    "end": "3169760"
  },
  {
    "text": "stuff and here you see a representation of what's required in a Linux environment in order to to uh be able to",
    "start": "3169760",
    "end": "3176079"
  },
  {
    "text": "be up and running um with your CLI in a Linux environment so I'm putting into my",
    "start": "3176079",
    "end": "3182040"
  },
  {
    "text": "ec2 Linux environment and I'm going to be taking the secret key and access key that I",
    "start": "3182040",
    "end": "3188240"
  },
  {
    "text": "just created and uh being able to um make it available in the data Lake CLI",
    "start": "3188240",
    "end": "3195280"
  },
  {
    "text": "as you can see I pre-installed the data Lake CLI package into this Linux environment I'm adding the credentials",
    "start": "3195280",
    "end": "3201480"
  },
  {
    "text": "to make the data Lake CLI available to my data Lake that I have within this AWS",
    "start": "3201480",
    "end": "3208920"
  },
  {
    "text": "account and to show a little bit of capability I just searched off of stroke",
    "start": "3214280",
    "end": "3219640"
  },
  {
    "text": "and I got a stroke uh result and so what we're going to show you is how that's being done with the",
    "start": "3219640",
    "end": "3227240"
  },
  {
    "text": "CLI so here you see I just wrote data L Search uh-- terms with quotation stroke",
    "start": "3228400",
    "end": "3235720"
  },
  {
    "text": "and I put it into a Json um parser and with the results Associated to that",
    "start": "3235720",
    "end": "3242240"
  },
  {
    "text": "represent essentially the same kind of capability that I was able to get from",
    "start": "3242240",
    "end": "3247559"
  },
  {
    "text": "the uh website so that's really useful let's do um something different",
    "start": "3247559",
    "end": "3254960"
  },
  {
    "text": "like look at the contents of the stroke data set right now we see that we have",
    "start": "3254960",
    "end": "3260720"
  },
  {
    "text": "four um files representing that data set and clearing it out and now I say",
    "start": "3260720",
    "end": "3267000"
  },
  {
    "text": "describe package data sets of the package ID um and I want some Json",
    "start": "3267000",
    "end": "3273440"
  },
  {
    "text": "telling me the contents of that data set and as you can see here uh even",
    "start": "3273440",
    "end": "3279520"
  },
  {
    "text": "though it scrolled through pretty quickly this is some of the contents that represent the data set",
    "start": "3279520",
    "end": "3284799"
  },
  {
    "text": "itself so this is very useful information you can get up and running very quickly so what I'm going to be",
    "start": "3284799",
    "end": "3291200"
  },
  {
    "text": "doing is now being uh running a red shift cluster uh being able to um create",
    "start": "3291200",
    "end": "3298200"
  },
  {
    "text": "a table structure and then as you can see here I am taking the est3 path",
    "start": "3298200",
    "end": "3304599"
  },
  {
    "text": "defined in that Json file that was in the Manifest and I'm going to be loading that data into the table I just created",
    "start": "3304599",
    "end": "3311359"
  },
  {
    "text": "within my red shift cluster so it just recorded 39,000",
    "start": "3311359",
    "end": "3319000"
  },
  {
    "text": "records and I'm doing a simple uh query statement that is going to give me the",
    "start": "3319000",
    "end": "3324599"
  },
  {
    "text": "relative counts of all the unique records and showing the total overall",
    "start": "3324599",
    "end": "3330440"
  },
  {
    "text": "for um a specific uh wear Clause I also can get get a select top of the",
    "start": "3330440",
    "end": "3337559"
  },
  {
    "text": "capability and the reason why I wanted to show you that was I went from raw data hosted within an S3 bucket with no",
    "start": "3337559",
    "end": "3345119"
  },
  {
    "text": "context behind it being able to apply the STA Lake Solution on top of it and",
    "start": "3345119",
    "end": "3350440"
  },
  {
    "text": "now getting a manifest file because of the data L solution that turns into a a comprehensive analytics environment that",
    "start": "3350440",
    "end": "3357280"
  },
  {
    "text": "you can run in red shift so you see Soup To Nuts how this capability goes from very very raw data to something of high",
    "start": "3357280",
    "end": "3364359"
  },
  {
    "text": "value that your Enterprise can use so this uh data lake is uh we we try to",
    "start": "3364359",
    "end": "3371440"
  },
  {
    "text": "simplify the costing it's actually less than that but we wanted to make it something simple that you can remember essentially it's about a dollar an hour",
    "start": "3371440",
    "end": "3377319"
  },
  {
    "text": "to run um depending on how you use the data Lake you have to represent the amount of data hosted with an S3 that",
    "start": "3377319",
    "end": "3383720"
  },
  {
    "text": "the data lake is managing as well as any analytics computer environments that run on top of it so those are something that",
    "start": "3383720",
    "end": "3389359"
  },
  {
    "text": "keep in mind and even though this says Q4 which is hopefully sometime very soon",
    "start": "3389359",
    "end": "3395720"
  },
  {
    "text": "this will be available tomorrow so you can go to aws.amazon.com",
    "start": "3395720",
    "end": "3401000"
  },
  {
    "text": "aners and go to the big data portion of that website and be able to get the data",
    "start": "3401000",
    "end": "3406160"
  },
  {
    "text": "L solution up and running uh right right away so that's the end of our talk we don't have any time for questions and",
    "start": "3406160",
    "end": "3411559"
  },
  {
    "text": "answers but if you want to see us we'll be available in the front of the stage thank you very much",
    "start": "3411559",
    "end": "3416880"
  },
  {
    "text": "sh",
    "start": "3417880",
    "end": "3420880"
  }
]
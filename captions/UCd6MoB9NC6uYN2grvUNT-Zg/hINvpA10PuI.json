[
  {
    "start": "0",
    "end": "56000"
  },
  {
    "text": "thank you very much so welcome everyone and a big congratulations for getting",
    "start": "30",
    "end": "7890"
  },
  {
    "text": "through to the end of the day I don't know if anyone else is tired but in a happy way I'm tired because it's been",
    "start": "7890",
    "end": "14190"
  },
  {
    "text": "great to chat to you all today we've got half an hour to get through about 40 minutes of content and I also want to",
    "start": "14190",
    "end": "19770"
  },
  {
    "text": "give you a demo so we'd better jump in research computing is is is an",
    "start": "19770",
    "end": "26550"
  },
  {
    "text": "interesting topic I get asked what is research computing all the time people say oh you're the",
    "start": "26550",
    "end": "31859"
  },
  {
    "text": "HPC guy or are you do big data or no you must be the machine learning person and",
    "start": "31859",
    "end": "37670"
  },
  {
    "text": "what I would say is research computing is all of those things and more research computing is actually a collection of",
    "start": "37670",
    "end": "43410"
  },
  {
    "text": "tools collection of very powerful tools and it's important that we have flexible",
    "start": "43410",
    "end": "49649"
  },
  {
    "text": "tools at our fingertips to fit into the way that we work because one tool is not",
    "start": "49649",
    "end": "55079"
  },
  {
    "text": "enough as researchers we are working in workflows we typically have a number of",
    "start": "55079",
    "end": "60660"
  },
  {
    "start": "56000",
    "end": "56000"
  },
  {
    "text": "steps that we follow and if we're dealing with data I've kind of shown a canonical workflow at the top here which",
    "start": "60660",
    "end": "66600"
  },
  {
    "text": "is pretty representative of what a lot of data scientists or researchers or in different domains do every day and so",
    "start": "66600",
    "end": "74369"
  },
  {
    "text": "typically we are collecting data at some point this might be from traditional data sources like databases perhaps",
    "start": "74369",
    "end": "80340"
  },
  {
    "text": "we're doing earth observation work and we're maybe collecting data directly from satellites or down links from",
    "start": "80340",
    "end": "85650"
  },
  {
    "text": "satellites perhaps we have Internet of Things sensors in the field that we're",
    "start": "85650",
    "end": "90659"
  },
  {
    "text": "collecting data from and so on you get the idea but then we're also generating events we're either generating the",
    "start": "90659",
    "end": "96990"
  },
  {
    "text": "events in reaction to data streams that are coming through perhaps we're putting data into s3 and events are being",
    "start": "96990",
    "end": "102299"
  },
  {
    "text": "generated that way maybe we're using our software development kits to generate events based on changes that are",
    "start": "102299",
    "end": "108810"
  },
  {
    "text": "happening in in data streams or we're capturing real-time feeds of information through a service like Amazon Kinesis",
    "start": "108810",
    "end": "115530"
  },
  {
    "text": "and then we have the concept of workflows where we're running analysis and there are two main models we see the",
    "start": "115530",
    "end": "121890"
  },
  {
    "text": "first is batch batch workflows are typically not time-sensitive this is where it's okay for you to wait several",
    "start": "121890",
    "end": "128489"
  },
  {
    "text": "hours or maybe several days for a results we have customers that do very calm",
    "start": "128489",
    "end": "133740"
  },
  {
    "text": "analysis in the cloud and they can sometimes wake wait several weeks for a results so the point is that what they",
    "start": "133740",
    "end": "139800"
  },
  {
    "text": "do what they typically do is land data into s3 as a storage service they then",
    "start": "139800",
    "end": "144870"
  },
  {
    "text": "spin up tools like HPC clusters like Hadoop clusters using add abuse batch",
    "start": "144870",
    "end": "151800"
  },
  {
    "text": "potentially to do some kind of analysis that is time-consuming that is batch driven and then they write",
    "start": "151800",
    "end": "157800"
  },
  {
    "text": "the results back out to s3 so that's one model that we see another model that we see commonly is real-time workflow",
    "start": "157800",
    "end": "164910"
  },
  {
    "text": "so this is where time to a result is much more important perhaps we're asking questions of data that we need results",
    "start": "164910",
    "end": "172050"
  },
  {
    "text": "in seconds too or perhaps we're doing real-time analysis of streaming data perhaps we're looking at window analysis",
    "start": "172050",
    "end": "178650"
  },
  {
    "text": "those kinds of things and so here I've represented common tools that are used by our research community like SPARC",
    "start": "178650",
    "end": "184890"
  },
  {
    "text": "Apache spark that's trivial to run on a mrl elastic MapReduce service which is a",
    "start": "184890",
    "end": "190380"
  },
  {
    "text": "managed to dupe platform on the cloud okay it's a checkbox when you want to create a spark cluster to be able to do",
    "start": "190380",
    "end": "196080"
  },
  {
    "text": "that kind of work or maybe we're using lambda a service platform to react to",
    "start": "196080",
    "end": "201240"
  },
  {
    "text": "events and process data as they come through in a stream and so on but then ultimately what we're doing with those",
    "start": "201240",
    "end": "206970"
  },
  {
    "text": "results all those answers or those secondary data products is we want to share them and we want to collaborate",
    "start": "206970",
    "end": "212250"
  },
  {
    "text": "and we also want to be able to make those results available so other people can validate them and so we may use",
    "start": "212250",
    "end": "218520"
  },
  {
    "text": "tools like Jupiter notebooks or maybe we're using Zeppelin on top of Hadoop to start doing some kind of interactive",
    "start": "218520",
    "end": "224790"
  },
  {
    "text": "analysis of our results you get the idea now where does HPC fit into this where",
    "start": "224790",
    "end": "230880"
  },
  {
    "text": "does machine-learning fit into this it is a tool in a workflow and it's important that you choose the right",
    "start": "230880",
    "end": "237000"
  },
  {
    "text": "tools that are flexible enough to be able to be strung together to suit your evolving workflows as a research",
    "start": "237000",
    "end": "243390"
  },
  {
    "text": "community and that's one thing we spent a lot of time thinking about carefully at AWS so let's talk a little bit about",
    "start": "243390",
    "end": "249240"
  },
  {
    "start": "248000",
    "end": "248000"
  },
  {
    "text": "clusters clusters in the cloud are an ephemeral tool now what do I mean by",
    "start": "249240",
    "end": "254370"
  },
  {
    "text": "that well it's very common for data to come in from from sources that we've talked about a little bit already and",
    "start": "254370",
    "end": "261090"
  },
  {
    "text": "land that into s3 because s3 is durable it's very scalable and",
    "start": "261090",
    "end": "266570"
  },
  {
    "text": "it's actually very cost-effective so it's very common to use that as the sync for your data and then we can generate",
    "start": "266570",
    "end": "273110"
  },
  {
    "text": "an event and spin up a cluster on demand so we can actually in a completely automated way spin up a fully fledged",
    "start": "273110",
    "end": "280460"
  },
  {
    "text": "HPC cluster to do high throughput computing or high-performance computing on that is just hours no one else is",
    "start": "280460",
    "end": "286670"
  },
  {
    "text": "sharing it and we can have that for as long as we need to we can pulled we can",
    "start": "286670",
    "end": "291800"
  },
  {
    "text": "connect to that over RDP or remote desktop or VNC or SSH usual methods we",
    "start": "291800",
    "end": "297050"
  },
  {
    "text": "can connect to a login node and then we can pull data into the shared storage environment of that cluster we can do our processing in a batch driven fashion",
    "start": "297050",
    "end": "304400"
  },
  {
    "text": "perhaps on that cluster we can write the results back out to s3 and then what do",
    "start": "304400",
    "end": "310250"
  },
  {
    "text": "we do with the cluster we can get rid of it we don't need it the cloud presents a",
    "start": "310250",
    "end": "315680"
  },
  {
    "text": "model where you only need to to spin up the resources that you need and you only need them for the time to do that to the",
    "start": "315680",
    "end": "323000"
  },
  {
    "text": "investigation and when you couple that with an on demand model for how you pay for these resources you start thinking",
    "start": "323000",
    "end": "328730"
  },
  {
    "text": "about these tools is just being ephemeral steps in a workflow it's very different to an on-premise environment",
    "start": "328730",
    "end": "334940"
  },
  {
    "text": "where you have a shared infrastructure that lots of different people are using and you're trying to perhaps get in a",
    "start": "334940",
    "end": "342350"
  },
  {
    "text": "queue or trying to change the job specification to run on the cluster faster or only use a part of the cluster",
    "start": "342350",
    "end": "348290"
  },
  {
    "text": "and you're invariably fitting your job to fit the infrastructure here we're able to get infrastructure quickly and",
    "start": "348290",
    "end": "354500"
  },
  {
    "text": "automate that and the infrastructure gets out of the way so we can do our research now the clouds also pretty",
    "start": "354500",
    "end": "361910"
  },
  {
    "text": "interesting because it gives us a huge ecosystem of tools and compute environments and compute types so it's",
    "start": "361910",
    "end": "368660"
  },
  {
    "text": "very flexible in that sense and here I've shown what we typically call our instance families we have general",
    "start": "368660",
    "end": "373880"
  },
  {
    "text": "purpose computer we have compute optimized storage optimized you get the picture we even have more modern",
    "start": "373880",
    "end": "379640"
  },
  {
    "text": "instances that give you accelerate options give you GPU for general-purpose GPU compute using CUDA or OpenCL and we",
    "start": "379640",
    "end": "387500"
  },
  {
    "text": "also have more recently an instance type that gives you FPGAs on the server and",
    "start": "387500",
    "end": "393290"
  },
  {
    "text": "so we're seeing our researchers in some cases move towards these accelerator options to speed up their processing",
    "start": "393290",
    "end": "400270"
  },
  {
    "text": "and so what this means in the cloud on AWS is that you can build fit for purpose clusters so if I'm going to do",
    "start": "400270",
    "end": "407920"
  },
  {
    "text": "deep learning work and I know that I can accelerate the training of my deep learning models with GPUs then I can",
    "start": "407920",
    "end": "414280"
  },
  {
    "text": "spin up a cluster based on GPUs for the period of time that I'm doing my training maybe that's a few hours maybe",
    "start": "414280",
    "end": "419350"
  },
  {
    "text": "that's a few days maybe that's a few weeks but then when I'm done I shut it down well maybe I know that my",
    "start": "419350",
    "end": "426210"
  },
  {
    "text": "computationally intensive workload maybe I'm doing weather modeling and I know that I can take advantage of the latest",
    "start": "426210",
    "end": "432220"
  },
  {
    "text": "Intel Architecture based on skylake okay maybe there are extensions to the",
    "start": "432220",
    "end": "437290"
  },
  {
    "text": "architecture that let me go faster for my my processing and we can use the c-5",
    "start": "437290",
    "end": "442510"
  },
  {
    "text": "instance family which is an instant family we've pre announced that will support skylake the new Intel Xeon",
    "start": "442510",
    "end": "448740"
  },
  {
    "text": "architecture and so you can start thinking carefully about your workloads most of you understand what what",
    "start": "448740",
    "end": "455290"
  },
  {
    "text": "workloads require what infrastructure and you can build fit for purpose clusters for that okay and this this",
    "start": "455290",
    "end": "461620"
  },
  {
    "text": "arrives at better efficiencies than trying to share a shared environment even if that shared environment is heterogeneous ok this is your tool this",
    "start": "461620",
    "end": "469030"
  },
  {
    "text": "is your cluster and you can use it how you see fit within ok of just skipped",
    "start": "469030",
    "end": "476200"
  },
  {
    "text": "over something here ok within families we have different types",
    "start": "476200",
    "end": "483250"
  },
  {
    "start": "478000",
    "end": "478000"
  },
  {
    "text": "of instances you've probably familiar with this we have this is the r4 family that's memory optimized this lets us",
    "start": "483250",
    "end": "490410"
  },
  {
    "text": "choose small instances with just a couple of CPUs and at the top end gives",
    "start": "490410",
    "end": "495640"
  },
  {
    "text": "us half a terabyte of RAM per node what you'll also notice there though is network i/o performance scales with",
    "start": "495640",
    "end": "502540"
  },
  {
    "text": "instance type as they get larger and so at the top end we're giving you 25",
    "start": "502540",
    "end": "507970"
  },
  {
    "text": "gigabits per second performance now I believe it was 20 and that now we've released 25 gigabits performance and",
    "start": "507970",
    "end": "514450"
  },
  {
    "text": "that's Ethernet and that's excellent throughput for each node so when you're doing high throughput computing in a",
    "start": "514450",
    "end": "519460"
  },
  {
    "text": "cluster you can get that kind of interconnectivity as well I'm going",
    "start": "519460",
    "end": "524830"
  },
  {
    "text": "backwards sorry guys a little bit about our accelerate accelerator options so the p2 instance",
    "start": "524830",
    "end": "530980"
  },
  {
    "start": "525000",
    "end": "525000"
  },
  {
    "text": "family gives you K 80 GPUs NVIDIA ket GPUs and these are commonly",
    "start": "530980",
    "end": "537260"
  },
  {
    "text": "used for modeling financial simulation deep learning anything that you can offload to do general-purpose kind of",
    "start": "537260",
    "end": "544339"
  },
  {
    "text": "computer on a GPU and we give you up to 16 of these actually on a single instance and we give you very good",
    "start": "544339",
    "end": "550250"
  },
  {
    "text": "interconnects between those GPUs so that you can start doing multi-gpu work I don't know about you but I only have one",
    "start": "550250",
    "end": "556730"
  },
  {
    "text": "GPU in my laptop and even if I go and buy a workstation it's hard to get 16 of these they're they're they're",
    "start": "556730",
    "end": "562899"
  },
  {
    "text": "industrial-strength GPUs and we're also going to be supporting Volta when that's released later in the year the FPGA",
    "start": "562899",
    "end": "569990"
  },
  {
    "text": "instance type the f1 instance type gives you Xilinx FPGA is similar idea except",
    "start": "569990",
    "end": "575899"
  },
  {
    "text": "you're writing your own using it's sort of a high description language a hardware description language you're",
    "start": "575899",
    "end": "582079"
  },
  {
    "text": "writing your own code that you're deploying to the to the FPGA and we give you a software development kit and a",
    "start": "582079",
    "end": "587389"
  },
  {
    "text": "hardware development kit to be able to do that easily and we also take care of the i/o mapping so that you're just focusing on the core logic that you",
    "start": "587389",
    "end": "593209"
  },
  {
    "text": "deploy to a jeep to an FPGA we have partners that are using that instance",
    "start": "593209",
    "end": "598550"
  },
  {
    "text": "type actually edco is one of our partners that has released a FPGA enabled product into our marketplace and",
    "start": "598550",
    "end": "606339"
  },
  {
    "text": "this is for genomic processing so they've they've optimized some of the",
    "start": "606339",
    "end": "611959"
  },
  {
    "text": "pipelines that they run typically for analysis of genomes and they've made that entire toolset available in the",
    "start": "611959",
    "end": "619519"
  },
  {
    "text": "marketplace accelerated with FPGAs who's",
    "start": "619519",
    "end": "624920"
  },
  {
    "start": "623000",
    "end": "623000"
  },
  {
    "text": "heard of elasticity we've all heard this term elasticity we've talked about it in terms of web environments and and other",
    "start": "624920",
    "end": "630889"
  },
  {
    "text": "environments API designs and what have you it makes sense in in scientific",
    "start": "630889",
    "end": "636380"
  },
  {
    "text": "computing as well so we can we can scale the clusters that we use right here I've got a cluster that has you know a head",
    "start": "636380",
    "end": "643699"
  },
  {
    "text": "node some storage some compute nodes and it's doing a unit of work right it's doing a you know of work for a unit of",
    "start": "643699",
    "end": "648860"
  },
  {
    "text": "cost but if I want to address a larger data set I can scale in terms of space I",
    "start": "648860",
    "end": "654110"
  },
  {
    "text": "can add more nodes that might let me address more data it might let me do more complex analysis and I'm doing any",
    "start": "654110",
    "end": "662060"
  },
  {
    "text": "units of work for any units of costs but what if I don't have any work to do",
    "start": "662060",
    "end": "667160"
  },
  {
    "text": "what's the largest cluster size it's about zero or it's a login node with some shared storage I could even tear",
    "start": "667160",
    "end": "674180"
  },
  {
    "text": "the cluster down like I showed earlier but maybe I want that cluster around with shared storage available with",
    "start": "674180",
    "end": "679279"
  },
  {
    "text": "datasets on it and I scale the compute nodes down all together so that's maybe to go bigger but I've got another",
    "start": "679279",
    "end": "684680"
  },
  {
    "text": "dimension I can scale in terms of I can scale in terms of time right so this is like a time traveling cluster so what I",
    "start": "684680",
    "end": "691579"
  },
  {
    "text": "can do is I can say look for that cluster I'm going to do some work over a period of time and in the case where I'm",
    "start": "691579",
    "end": "698149"
  },
  {
    "text": "adding more nodes well maybe I don't address more data or do more sophisticated you know processing maybe",
    "start": "698149",
    "end": "703699"
  },
  {
    "text": "I just process much much faster I get to my result faster and if my software scales appropriately that's another sort",
    "start": "703699",
    "end": "710720"
  },
  {
    "text": "of dial that I can turn and again with an empty cluster there's no argument about what work we're doing in what time",
    "start": "710720",
    "end": "716689"
  },
  {
    "text": "but you get the idea so you can think about how you optimize for a problem you either go bigger and more complex or you",
    "start": "716689",
    "end": "723199"
  },
  {
    "text": "go faster and elasticity lets you do that no talk about you know research",
    "start": "723199",
    "end": "731240"
  },
  {
    "text": "computing would be complete without talking about data and specifically about how data is consumed so I've been",
    "start": "731240",
    "end": "738380"
  },
  {
    "text": "a little cheeky here and I've taken something that we a phrase that we bandy about has anyone heard the phrase data",
    "start": "738380",
    "end": "743899"
  },
  {
    "text": "has gravity everyone has hopefully everybody has so I've taken the Newtonian model of gravity here and I've",
    "start": "743899",
    "end": "750680"
  },
  {
    "text": "mapped these are mangled it and turned into a discussion about data so it's kind of it's kind of curious but what",
    "start": "750680",
    "end": "757459"
  },
  {
    "text": "I'm saying here is that there are some characteristics that we care about when we're thinking about data in the context of research they are how much data do I",
    "start": "757459",
    "end": "764360"
  },
  {
    "text": "have how much data do I have in relation to other datasets because often I'm mashing datasets together or I'm doing",
    "start": "764360",
    "end": "770029"
  },
  {
    "text": "correlation or I'm looking at variants or I'm doing work where I want to compare against other datasets and then",
    "start": "770029",
    "end": "775730"
  },
  {
    "text": "how accessible is that data so maybe it's not inversely proportional like this but if I have to wait two weeks to",
    "start": "775730",
    "end": "782029"
  },
  {
    "text": "go and get a data set and give somebody a hard disk and they go and retrieve it out of a basement and give it to me and if my iteration cycle is something like",
    "start": "782029",
    "end": "788360"
  },
  {
    "text": "a week or two then maybe the pragmatic value of that data is reduced so we have to think carefully about how far away",
    "start": "788360",
    "end": "794420"
  },
  {
    "text": "our data is how accessible it is and how large it is now in the cloud in",
    "start": "794420",
    "end": "800540"
  },
  {
    "text": "AWS it's generally true that almost everybody consumes s3 at some point this",
    "start": "800540",
    "end": "807290"
  },
  {
    "text": "is a pattern we encourage our research community to follow we're generating data we land it into s3 as quickly as",
    "start": "807290",
    "end": "813590"
  },
  {
    "text": "possible and then we consume it out of s3 so in the case of EMR our Hadoop",
    "start": "813590",
    "end": "818720"
  },
  {
    "text": "service we have a native integration with s3 that replaces HDFS with s3 it",
    "start": "818720",
    "end": "824150"
  },
  {
    "text": "scales its throughput is fantastic and it integrates nicely and then we have the ecosystem of Hadoop tools on top of",
    "start": "824150",
    "end": "831530"
  },
  {
    "text": "that like spark and tears and pig and what-have-you at our fingertips but even in the HPC world where we want POSIX",
    "start": "831530",
    "end": "839570"
  },
  {
    "text": "compliant file systems and we want POSIX API s we can do something similar we can",
    "start": "839570",
    "end": "845300"
  },
  {
    "text": "still land data on s3 and we can then pre stage the data and move that into our maybe a clustered file system Intel",
    "start": "845300",
    "end": "852410"
  },
  {
    "text": "lustre is in the AWS marketplace B GFS EFS is our managed in fSV for service that does a similar thing all giving you",
    "start": "852410",
    "end": "859750"
  },
  {
    "text": "commonly used POSIX compliant type interfaces that we can then use from clusters may be on on AWS out of ec2 and",
    "start": "859750",
    "end": "868550"
  },
  {
    "text": "so on we keep storage simple though a lot of",
    "start": "868550",
    "end": "874070"
  },
  {
    "start": "871000",
    "end": "871000"
  },
  {
    "text": "you have told me that you can't natively integrate with s3 because it's an object storage service you need POSIX well in",
    "start": "874070",
    "end": "880250"
  },
  {
    "text": "that case let's take something like ABI GFS scale-out clustered file system architecture and let's do something",
    "start": "880250",
    "end": "887060"
  },
  {
    "text": "where we treat that as a long-lived POSIX cache so we keep our data in s3",
    "start": "887060",
    "end": "893030"
  },
  {
    "text": "we have a V PC here in a subnet with an s3 endpoint that lets us get it data",
    "start": "893030",
    "end": "898280"
  },
  {
    "text": "quickly and and securely we have a management host in that subnet that manages the scale-out clustered file",
    "start": "898280",
    "end": "904400"
  },
  {
    "text": "system and then in B GFS there are two types of servers there's a metadata service that does name lookup when I",
    "start": "904400",
    "end": "910040"
  },
  {
    "text": "asked for a file it knows which storage service to go and retrieve it from and they scale out in a redundant and then I",
    "start": "910040",
    "end": "915590"
  },
  {
    "text": "have storage servers as well with block devices attached maybe SSD backed storage so it's fast",
    "start": "915590",
    "end": "921530"
  },
  {
    "text": "and they also scale out now what I can do is I can lifecycle data as part of a research project out of s3 into a",
    "start": "921530",
    "end": "928430"
  },
  {
    "text": "clustered file system like this I can access it from clusters that want POSIX from services that one",
    "start": "928430",
    "end": "934400"
  },
  {
    "text": "to complain interfaces I can do my processing at speed at scale quickly reading and writing data to that shared",
    "start": "934400",
    "end": "941600"
  },
  {
    "text": "file system and then when I'm done I can move the data back out into s3 and I can shut down the file system and we have",
    "start": "941600",
    "end": "948560"
  },
  {
    "text": "automated tools that will build clustered file systems like this view so there's a new model there I'll quickly",
    "start": "948560",
    "end": "954800"
  },
  {
    "text": "talk about some HPC and some high throughput tools on the Left we have CF",
    "start": "954800",
    "end": "960650"
  },
  {
    "start": "959000",
    "end": "959000"
  },
  {
    "text": "and cluster analysis flights CF and cluster is one of the tools we've created it's open source it's in github",
    "start": "960650",
    "end": "965720"
  },
  {
    "text": "there's a Python command line wrapper for it to make it easy to use and it lets you spin up your own",
    "start": "965720",
    "end": "971350"
  },
  {
    "text": "high-performance computing cluster lets you choose the scheduler that you want the number of nodes and it auto scales",
    "start": "971350",
    "end": "977750"
  },
  {
    "text": "for you as well so it does all the plumbing and all the automation of what is a fairly sophisticated",
    "start": "977750",
    "end": "982760"
  },
  {
    "text": "piece of kit or tool for you and that takes about 10 or 15 minutes to get that cluster Alice's flight is one of our",
    "start": "982760",
    "end": "989570"
  },
  {
    "text": "partner products in the marketplace it's a little similar to CF in cluster but what makes it different is it's much",
    "start": "989570",
    "end": "995510"
  },
  {
    "text": "easier to use and it's also bundle bundles up over a thousand commonly used scientific computing applications and",
    "start": "995510",
    "end": "1001660"
  },
  {
    "text": "I'll demo that in a couple of minutes batch is really focused on more of that",
    "start": "1001660",
    "end": "1007240"
  },
  {
    "text": "batch processing model and it gives you the ability to define your software in",
    "start": "1007240",
    "end": "1012370"
  },
  {
    "text": "docker containers deploy that to batch as a service batch manages the distribution of work across that using a",
    "start": "1012370",
    "end": "1019030"
  },
  {
    "text": "scheduler and gives you concept of queues and it uses it can you spot fleet",
    "start": "1019030",
    "end": "1024310"
  },
  {
    "text": "under the hood to reduce cut cost by using spot and Amazon EMR is our managed to dupe service and you get spark and",
    "start": "1024310",
    "end": "1031120"
  },
  {
    "text": "all the ecosystem tools on top of that so a little bit on flight because I'm about to demo it fly it's great because",
    "start": "1031120",
    "end": "1038260"
  },
  {
    "start": "1034000",
    "end": "1034000"
  },
  {
    "text": "it gives you lots and lots of applications so it's one thing to get a cluster but it's one thing to",
    "start": "1038260",
    "end": "1043480"
  },
  {
    "text": "immediately be able to do something interesting on that cluster with software and so that's the difference here it also supports slurm as the",
    "start": "1043480",
    "end": "1050170"
  },
  {
    "text": "default scheduler it supports docker it also supports singularity which is interesting for some of our HPC",
    "start": "1050170",
    "end": "1056140"
  },
  {
    "text": "customers and the really cool thing is it's available via marketplace so it's literally a couple of clicks to deploy",
    "start": "1056140",
    "end": "1061690"
  },
  {
    "text": "one of these things so what I want to do",
    "start": "1061690",
    "end": "1066730"
  },
  {
    "text": "is kind of take you to a in a second and I want to pose the the question what if it was as easy as",
    "start": "1066730",
    "end": "1073900"
  },
  {
    "text": "pushing a button to get an HPC cluster we could call it push-button HPC perhaps",
    "start": "1073900",
    "end": "1079120"
  },
  {
    "text": "and any of you that have been talking to us for a while have probably seen one of these things it's an IOT button right I",
    "start": "1079120",
    "end": "1086260"
  },
  {
    "text": "don't know if any of you have programmed one of these it's really easy but what it what it effectively lets you do is",
    "start": "1086260",
    "end": "1092340"
  },
  {
    "text": "hook up a lambda function to the push of a button it's about as complex as that and that",
    "start": "1092340",
    "end": "1098410"
  },
  {
    "text": "lambda function can do anything so why not make that lambda function call cloud",
    "start": "1098410",
    "end": "1103540"
  },
  {
    "text": "formation to build an HPC cluster based on else's flight so what I'm going to do here is I'm actually going to push this",
    "start": "1103540",
    "end": "1110470"
  },
  {
    "text": "button that's blinking white and it's gone green which means it can connect to the Wi-Fi so we've passed that hurdle",
    "start": "1110470",
    "end": "1115980"
  },
  {
    "text": "but then hopefully something interesting is happening on the other side of that so if we can flick to the laptop so what",
    "start": "1115980",
    "end": "1124630"
  },
  {
    "text": "I have here is cloud formation and I've just refreshed it and what it's showing us is that we have a brand new cloud",
    "start": "1124630",
    "end": "1130809"
  },
  {
    "text": "formation stack that's just being created now this is no simple stack okay",
    "start": "1130809",
    "end": "1136809"
  },
  {
    "text": "this isn't just spitting up a load balancer in a couple of web servers what this thing is actually going to go and do is create an entire clustered",
    "start": "1136809",
    "end": "1145090"
  },
  {
    "text": "environment for me but that's not enough it's going to also go and make sure that",
    "start": "1145090",
    "end": "1150669"
  },
  {
    "text": "I have over a thousand scientific computing applications at my fingertips and then I can do whatever I want with",
    "start": "1150669",
    "end": "1155830"
  },
  {
    "text": "this cluster I can do things that my existing cluster admin would never let me do I can log into the the head node",
    "start": "1155830",
    "end": "1163630"
  },
  {
    "text": "and I can install software I can run you know GUI applications I could do all sorts of crazy things because maybe I",
    "start": "1163630",
    "end": "1171130"
  },
  {
    "text": "want to do that maybe I'm testing something that does sound crazy maybe I do want to try an experiment that no one",
    "start": "1171130",
    "end": "1176169"
  },
  {
    "text": "else has tried before so using a model like this I'm able to have complete control of that so it takes about five",
    "start": "1176169",
    "end": "1184059"
  },
  {
    "text": "to ten minutes to go off and create a cluster and so of course what I did earlier was you know prepare one and so",
    "start": "1184059",
    "end": "1190480"
  },
  {
    "text": "I'm going to actually log on to it and show you what that looks like so I'm already logged on but what i'm doing",
    "start": "1190480",
    "end": "1197860"
  },
  {
    "text": "here is SS aging to the to the head node i get some nice ASCII art of course because",
    "start": "1197860",
    "end": "1203669"
  },
  {
    "text": "we're connecting to an HPC cluster and I get a lot of sort of help text here that sort of gives me some guidance on what I",
    "start": "1203669",
    "end": "1209820"
  },
  {
    "text": "might want to do initially and one of the things that's interesting is to look at something called grid where grid",
    "start": "1209820",
    "end": "1216090"
  },
  {
    "text": "where is this location or a repository that gives me access to a ton of tools a",
    "start": "1216090",
    "end": "1223350"
  },
  {
    "text": "lot of these tools when I show researchers this this this interface a",
    "start": "1223350",
    "end": "1228419"
  },
  {
    "text": "lot of these tools are familiar there are people that will say yeah I use blast or beast or bowtie or I'm using",
    "start": "1228419",
    "end": "1235519"
  },
  {
    "text": "open foam to do computational fluid dynamics or I'm using bio conductor or bioperl we support",
    "start": "1235519",
    "end": "1242429"
  },
  {
    "text": "well else√≠s supports through this interface lots of different research domains and it's as simple as say",
    "start": "1242429",
    "end": "1248639"
  },
  {
    "text": "choosing one of these things let's say we want to try and install by a",
    "start": "1248639",
    "end": "1253649"
  },
  {
    "text": "conductor it's as simple as saying elseis grid where install by a conductor",
    "start": "1253649",
    "end": "1264299"
  },
  {
    "text": "and what it'll do is it will say look there's some dependencies do you want to go in and install those and I say yes",
    "start": "1264299",
    "end": "1269369"
  },
  {
    "text": "and then it'll will work out all the dependency mapping it'll go to go and download those from a pre compiled",
    "start": "1269369",
    "end": "1274919"
  },
  {
    "text": "repository of modules and it will install that across my cluster for me in",
    "start": "1274919",
    "end": "1280049"
  },
  {
    "text": "a you know a sane and complete way and it will use the module system to enable",
    "start": "1280049",
    "end": "1285299"
  },
  {
    "text": "me to turn these on and off and I can even have different versions of the same packages installed I can extend this",
    "start": "1285299",
    "end": "1291210"
  },
  {
    "text": "with my own repositories in my own software and it's really as easy as that when I want to go and start doing some",
    "start": "1291210",
    "end": "1297269"
  },
  {
    "text": "some work I should have probably tested this one before I tried it because it looks like it's going to take a while ok",
    "start": "1297269",
    "end": "1303869"
  },
  {
    "text": "it's worked and so then I can do module avail what have I got available and lo",
    "start": "1303869",
    "end": "1309749"
  },
  {
    "text": "and behold I've got by a conductor I've now got are installed in bowtie and a whole bunch of other things that are dependencies for that to work and then I",
    "start": "1309749",
    "end": "1316590"
  },
  {
    "text": "can just turn those modules on and use that software but that's actually not what I wanted to show you today what I",
    "start": "1316590",
    "end": "1323940"
  },
  {
    "text": "wanted to show you I'm sorry I'll just change to slideshow from here briefly",
    "start": "1323940",
    "end": "1329220"
  },
  {
    "text": "what I wanted to show you in the last couple of minutes was how to work with",
    "start": "1329220",
    "end": "1335129"
  },
  {
    "text": "something so one of our partners has built-in in Australia which is to sort of take",
    "start": "1335129",
    "end": "1340650"
  },
  {
    "text": "advantage of drone imagery and do some processing of that in a cluster and so",
    "start": "1340650",
    "end": "1345750"
  },
  {
    "start": "1341000",
    "end": "1341000"
  },
  {
    "text": "the cluster that we've we've spun up lets us use something called open drone map it's all it's all installed forests",
    "start": "1345750",
    "end": "1352650"
  },
  {
    "text": "it's been installed in a docker container and in fact it's already running across my cluster in docker with",
    "start": "1352650",
    "end": "1358500"
  },
  {
    "text": "all the libraries and dependencies that I need and what it does is it lets us open draw a map for those of you that",
    "start": "1358500",
    "end": "1364470"
  },
  {
    "text": "aren't familiar lets us take lots of different disparate images of an area build a mosaic out of those and also",
    "start": "1364470",
    "end": "1371130"
  },
  {
    "text": "rectify them and that it also generates a point cloud as well based off the imagery that we've supplied to it and so",
    "start": "1371130",
    "end": "1377760"
  },
  {
    "text": "what what we can do with Alice's flight is we can send one job to one node it's in another job to another node we can scale in a kind of a pleasing",
    "start": "1377760",
    "end": "1384470"
  },
  {
    "text": "embarrassingly parallel fashion across multiple nodes so what we'll do is we'll",
    "start": "1384470",
    "end": "1389640"
  },
  {
    "text": "get back to our cluster and we'll actually look at it s info oops I'll just go back to and get out of",
    "start": "1389640",
    "end": "1396180"
  },
  {
    "text": "presentation mode and so if I my screen",
    "start": "1396180",
    "end": "1401520"
  },
  {
    "text": "wakes up what I'll do is I'll I'll type s info and that queries the slow modular",
    "start": "1401520",
    "end": "1407520"
  },
  {
    "text": "on the cluster and says how many nodes do I have well I have four are four eight extra larges and that's giving me",
    "start": "1407520",
    "end": "1413940"
  },
  {
    "text": "some decent capacity and I can also see what's running on the on the cluster by typing sq and there's nothing running at",
    "start": "1413940",
    "end": "1420150"
  },
  {
    "text": "the moment what I've done is I've taken the liberty of kind of pulling some data on to this cluster already and there are",
    "start": "1420150",
    "end": "1428340"
  },
  {
    "text": "already a set of data sets that I can work with these are just part of the project so what it can do is do bash",
    "start": "1428340",
    "end": "1435810"
  },
  {
    "text": "odium actually yeah I'll just I'll just run this bash rhodium runner and I can",
    "start": "1435810",
    "end": "1442080"
  },
  {
    "text": "just pick one of these projects and you",
    "start": "1442080",
    "end": "1447480"
  },
  {
    "text": "can see that a job is being submitted to the cluster now if I look at sq you can",
    "start": "1447480",
    "end": "1454500"
  },
  {
    "text": "see that I'll just move that up on the screen a bit you can see that I have a running job the status is running its",
    "start": "1454500",
    "end": "1461750"
  },
  {
    "text": "using the alysus username and we know exactly what node it's running on and if I kick off a bunch of these jobs then",
    "start": "1461750",
    "end": "1468610"
  },
  {
    "text": "the cello will just go and send those across different note members okay in fact if we start queuing up the the",
    "start": "1468610",
    "end": "1475090"
  },
  {
    "text": "cluster with more and more work then the cluster will actually Auto scale and we'll start adding more of these big memory nodes and subsequent jobs will",
    "start": "1475090",
    "end": "1482470"
  },
  {
    "text": "just get farmed out to those to those nodes now this actually takes about three hours to run it's computationally",
    "start": "1482470",
    "end": "1488470"
  },
  {
    "text": "intensive so what I've done is I've prepared something earlier and this is",
    "start": "1488470",
    "end": "1495039"
  },
  {
    "text": "the mosaic that's also rectified that it generates for us I don't know if you can see on the screen I'll just make that window a",
    "start": "1495039",
    "end": "1502419"
  },
  {
    "text": "little larger so you can see something that looks like a you know a bunch of drone images that are being joined",
    "start": "1502419",
    "end": "1507490"
  },
  {
    "text": "together and it's it's done some calculations to work out how to do that properly and in a sense that's you know",
    "start": "1507490",
    "end": "1514450"
  },
  {
    "text": "that that's you know keeps the integrity of the geospatial data as well the the",
    "start": "1514450",
    "end": "1520360"
  },
  {
    "text": "other cool thing that it's that it's done for us is its generated a point cloud so this point cloud looks a little",
    "start": "1520360",
    "end": "1525399"
  },
  {
    "text": "bit like the the mosaic that we just saw but what I can do with it is I can I can",
    "start": "1525399",
    "end": "1532360"
  },
  {
    "text": "actually zoom in so I can move around I can I can look at this a similar view",
    "start": "1532360",
    "end": "1537970"
  },
  {
    "text": "of what we had before I can I can maybe say tilt it around and I can look at the",
    "start": "1537970",
    "end": "1543580"
  },
  {
    "text": "foliage and I can look at maybe the elevation that it's determined based off the algorithm algorithms that it's using",
    "start": "1543580",
    "end": "1550059"
  },
  {
    "text": "it's worked out foliage height I can do land mass calculations this way or biomass I can look for land subsidence I",
    "start": "1550059",
    "end": "1557649"
  },
  {
    "text": "can start generating these point clouds over time and then look at differences in in sort of contours and things like",
    "start": "1557649",
    "end": "1564850"
  },
  {
    "text": "that so so this is actually a real-world example of how you can use a cluster to speed up the processing that you're",
    "start": "1564850",
    "end": "1570429"
  },
  {
    "text": "doing now if we can go back to the presentation quickly I'll have to finish",
    "start": "1570429",
    "end": "1575950"
  },
  {
    "text": "fairly quickly how much did this cost well we had a login node we had four of",
    "start": "1575950",
    "end": "1582159"
  },
  {
    "start": "1576000",
    "end": "1576000"
  },
  {
    "text": "these large compute nodes I had a terabyte of you know SSD storage I had a little bit of egress cost for",
    "start": "1582159",
    "end": "1588880"
  },
  {
    "text": "data moving around it cost me about five dollars six dollars that's the price of",
    "start": "1588880",
    "end": "1594760"
  },
  {
    "text": "a cup of coffee in Sydney right so for three hours or three and a half hours of processing I am able",
    "start": "1594760",
    "end": "1602090"
  },
  {
    "text": "do some interesting work and remember unable to put this into a workflow where this tool is created automatically for",
    "start": "1602090",
    "end": "1609320"
  },
  {
    "text": "me as part of a and maybe an event-driven workflow where data lands in a bucket I spin up a cluster I do",
    "start": "1609320",
    "end": "1614390"
  },
  {
    "text": "this work and I shut it down and persist the data elsewhere I don't expect many of you will go off and you know start",
    "start": "1614390",
    "end": "1620570"
  },
  {
    "text": "launching clusters from IOT buttons I will when I show the demo to future customers because it's kind of a cool",
    "start": "1620570",
    "end": "1625820"
  },
  {
    "text": "neat trick but in the real world you'll actually be integrating this into workflows now quickly evolving the",
    "start": "1625820",
    "end": "1631820"
  },
  {
    "text": "paradigm some future some some ideas about the future where we see research pushing the compute paradigm I'm not",
    "start": "1631820",
    "end": "1638899"
  },
  {
    "start": "1638000",
    "end": "1638000"
  },
  {
    "text": "going to talk about physical or virtualization containerization is interesting and I guess it's been around",
    "start": "1638899",
    "end": "1644149"
  },
  {
    "text": "for a long time too and docker has certainly made it a lot easier to use but I think where are things get much",
    "start": "1644149",
    "end": "1649399"
  },
  {
    "text": "more interesting is where we remove the server from the picture altogether and anybody that attended the keynote this morning heard the story from from the",
    "start": "1649399",
    "end": "1657020"
  },
  {
    "text": "genome Institute of Singapore who are starting to investigate work like this and the benefit of thinking about",
    "start": "1657020",
    "end": "1662210"
  },
  {
    "text": "service is we're actually not thinking about servers we're not thinking about operating systems we're thinking in the",
    "start": "1662210",
    "end": "1667730"
  },
  {
    "text": "paradigm of software we're writing code to solve a research problem and so and lamdaur in the case of AWS is going to",
    "start": "1667730",
    "end": "1674570"
  },
  {
    "text": "run that code for us at scale and that frees us up to focus on our research problem and as researchers that's really",
    "start": "1674570",
    "end": "1680720"
  },
  {
    "text": "what we want to be doing we don't really want to be building clusters or thinking about operating systems or patching or",
    "start": "1680720",
    "end": "1686240"
  },
  {
    "text": "life cycle you get the idea actually Verna Vogel's our CTO has great",
    "start": "1686240",
    "end": "1692000"
  },
  {
    "start": "1689000",
    "end": "1689000"
  },
  {
    "text": "phrase no server is easier to manage than no server and HPC on lambda is it",
    "start": "1692000",
    "end": "1699230"
  },
  {
    "text": "possible yeah it actually is so we heard from the genome Institute of Singapore this morning in the keynote in Australia",
    "start": "1699230",
    "end": "1706070"
  },
  {
    "text": "we have the CSIRO eHealth group working on similar problems they've implemented",
    "start": "1706070",
    "end": "1711590"
  },
  {
    "text": "a completely service pipeline using lambda and come and talk to me if you want to know more about that it's a it's",
    "start": "1711590",
    "end": "1717590"
  },
  {
    "text": "a very nice cloud native way to do what it is traditionally a big HPC search problem and UC Berkeley rise live out of",
    "start": "1717590",
    "end": "1725750"
  },
  {
    "text": "UC Berkeley have built something called pyrin which takes your existing Python code and farms there out across many",
    "start": "1725750",
    "end": "1731590"
  },
  {
    "text": "workers running on lambda and they've done some benchmarking and they achieve up to 40 teraflops peak",
    "start": "1731590",
    "end": "1737990"
  },
  {
    "text": "compute which is actually a very respectable compute number and the benchmark test 3 and they're seeing",
    "start": "1737990",
    "end": "1743330"
  },
  {
    "text": "performance around 80 gigabytes per second out of s3 that's about it that's getting close to a terabit throughput",
    "start": "1743330",
    "end": "1749809"
  },
  {
    "text": "that's serious throughput I said s3 scales it really does so we do have customers doing this it is real it's not",
    "start": "1749809",
    "end": "1756740"
  },
  {
    "text": "going to solve all your problems but there is a sub sub set or a class of problems where lambda can make some of",
    "start": "1756740",
    "end": "1762799"
  },
  {
    "text": "your compute Kalen jizz as a researcher tractable and and lower the cost at the same time so two things before you go",
    "start": "1762799",
    "end": "1769450"
  },
  {
    "text": "I'd love you to to go and register for our cloud program we have the research",
    "start": "1769450",
    "end": "1775909"
  },
  {
    "text": "cloud program it lets you download a researchers handbook this handbook is written in the in your language as a",
    "start": "1775909",
    "end": "1781940"
  },
  {
    "text": "researcher you will understand what we're talking about and then I want you to go and try launching your own personal cluster because I think you'll",
    "start": "1781940",
    "end": "1788419"
  },
  {
    "text": "be pleased at how easy it is and and what you can get done with it we have lots more information I'm Way over time",
    "start": "1788419",
    "end": "1795140"
  },
  {
    "text": "but please come and speak to me afterwards and I'd love to hear about what you're doing in research and how we might help and thank you so much for",
    "start": "1795140",
    "end": "1801620"
  },
  {
    "text": "your attention today I hope it's been good thanks",
    "start": "1801620",
    "end": "1805419"
  }
]
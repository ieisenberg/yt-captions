[
  {
    "start": "0",
    "end": "38000"
  },
  {
    "text": "good afternoon everybody thanks for coming out my name is John handler I'm a",
    "start": "269",
    "end": "6450"
  },
  {
    "text": "principal Solutions Architect with AWS and I focus on our search services I'll",
    "start": "6450",
    "end": "12269"
  },
  {
    "text": "be joined today by Andy and AJ from NBC Sports Engine we got a great session for",
    "start": "12269",
    "end": "17789"
  },
  {
    "text": "you we have first half we're going to talk about some best practices and and things that you can do to optimize your",
    "start": "17789",
    "end": "24390"
  },
  {
    "text": "usage of Amazon Elastic search service second half AJ and Andy have a great story about how they got to the optimal",
    "start": "24390",
    "end": "30720"
  },
  {
    "text": "multi-tenant solution and great touching on a lot of cool stuff so we will roll",
    "start": "30720",
    "end": "37770"
  },
  {
    "text": "right in and get started so if you are not familiar with elasticsearch",
    "start": "37770",
    "end": "42800"
  },
  {
    "start": "38000",
    "end": "84000"
  },
  {
    "text": "elasticsearch sits in the databases world fundamentally because it's the kind of thing where I send my data in",
    "start": "42800",
    "end": "49410"
  },
  {
    "text": "there and I run queries to get results out of it elastic search is a tremendously tremendously popular piece",
    "start": "49410",
    "end": "56430"
  },
  {
    "text": "of software you can see this is from DB engines this is the ranking of database",
    "start": "56430",
    "end": "62129"
  },
  {
    "text": "software elasticsearch sitting at number eight along with much larger things like Oracle MySQL post-grad all of those so",
    "start": "62129",
    "end": "69360"
  },
  {
    "text": "tremendously tremendously popular fundamentally because it's fairly simple to deploy it it's fairly easy to get",
    "start": "69360",
    "end": "75060"
  },
  {
    "text": "data into it and once you have data in there it's fairly easy to get value out of it and so elasticsearch really",
    "start": "75060",
    "end": "82320"
  },
  {
    "text": "tremendously popular growing in popularity as we look at it there are two fundamental ways that you use",
    "start": "82320",
    "end": "88680"
  },
  {
    "text": "elastic search elastic search is a search engine so it supports text-based search free text",
    "start": "88680",
    "end": "96329"
  },
  {
    "text": "search / natural language kind of text you use it in conjunction with your application to provide search for your",
    "start": "96329",
    "end": "103860"
  },
  {
    "text": "customers say in an e-commerce kind of scenario over the data and say your CRM",
    "start": "103860",
    "end": "109590"
  },
  {
    "text": "system elastic search allows you to put all that data in and then run queries on",
    "start": "109590",
    "end": "114960"
  },
  {
    "text": "that data to pull out relevant results and what happened is elastic search came",
    "start": "114960",
    "end": "121500"
  },
  {
    "text": "out in 2009 and you saw a lot of system administrators running large deployments",
    "start": "121500",
    "end": "128399"
  },
  {
    "text": "of servers generating tons and tons of log data and something would go wrong",
    "start": "128399",
    "end": "133680"
  },
  {
    "text": "and then they'd have to figure out okay well what went wrong well do I really at 3:00 in the morning when everything is melting down want to log into 10000",
    "start": "133680",
    "end": "141239"
  },
  {
    "text": "servers and try to grep the logs for exactly what's wrong no of course I don't so instead I can flow all that log",
    "start": "141239",
    "end": "148650"
  },
  {
    "text": "data into a search engine and then I can just run a quick search figure out what the error is and solve it so sending my",
    "start": "148650",
    "end": "157379"
  },
  {
    "text": "log data into elasticsearch really provided a good way for me to not to",
    "start": "157379",
    "end": "163379"
  },
  {
    "text": "figure out what was going wrong and elasticsearch grew a an open-source",
    "start": "163379",
    "end": "169079"
  },
  {
    "text": "ecosystem to support that so technology called log stash which brings data from",
    "start": "169079",
    "end": "174629"
  },
  {
    "text": "point A to point B basically log data from your servers into elasticsearch and then Cabana a thin web client that will",
    "start": "174629",
    "end": "181980"
  },
  {
    "text": "use the data in elasticsearch to build visualizations so we have those two use cases we have a full-text search we have",
    "start": "181980",
    "end": "188400"
  },
  {
    "text": "log analytics we see tons and tons of customers doing both of those things and",
    "start": "188400",
    "end": "193819"
  },
  {
    "text": "if we look at it sort of schematically just a quick sort of AM architecture",
    "start": "193819",
    "end": "198989"
  },
  {
    "start": "194000",
    "end": "234000"
  },
  {
    "text": "view you're taking data from your servers from your application from your networking from your AWS infrastructure",
    "start": "198989",
    "end": "205650"
  },
  {
    "text": "and you send that data into elasticsearch service number of different ways or perhaps you have a",
    "start": "205650",
    "end": "212639"
  },
  {
    "text": "relational database usually your application is backed by some kind of database so you're taking data your",
    "start": "212639",
    "end": "219060"
  },
  {
    "text": "application data itself pushing it into elastic search as Jason elastic search",
    "start": "219060",
    "end": "224790"
  },
  {
    "text": "then indexes that data and provides search ability across it and at the other end you send queries to pull out",
    "start": "224790",
    "end": "231629"
  },
  {
    "text": "the results fairly straightforward and what we find is that as you scale",
    "start": "231629",
    "end": "238079"
  },
  {
    "start": "234000",
    "end": "257000"
  },
  {
    "text": "elastic search up it becomes more and more difficult to size correctly to",
    "start": "238079",
    "end": "243269"
  },
  {
    "text": "maintain to do the operational work of keeping that cluster running so we came",
    "start": "243269",
    "end": "248819"
  },
  {
    "text": "out with Amazon elastic search service as a managed service that makes it easy for you to run elastic search in the AWS",
    "start": "248819",
    "end": "255299"
  },
  {
    "text": "cloud just a couple of the things that we provide number one you can use all of the open",
    "start": "255299",
    "end": "261659"
  },
  {
    "start": "257000",
    "end": "376000"
  },
  {
    "text": "source tools that you're already using if you're already using dick search with Amazon Elastic search service you can easily deploy elastic",
    "start": "261659",
    "end": "269960"
  },
  {
    "text": "search elastic versus a clustered distributed algorithm it takes a number of different instances you could set",
    "start": "269960",
    "end": "276590"
  },
  {
    "text": "that up on your own but with the service it's a single API call you tell us what to deploy and we deploy it you can scale",
    "start": "276590",
    "end": "284030"
  },
  {
    "text": "your cluster as well so you're not locked into a particular cluster deployment we provide an API that allows",
    "start": "284030",
    "end": "290600"
  },
  {
    "text": "you to tell us I want more instances I want different instances I want different storage we seamlessly in the",
    "start": "290600",
    "end": "297050"
  },
  {
    "text": "backend and bring in new instances migrate data across and do all of that while your search application is still",
    "start": "297050",
    "end": "303800"
  },
  {
    "text": "up and running you can also secure your elastic search service domain we provide",
    "start": "303800",
    "end": "309919"
  },
  {
    "text": "a number of different integrations that make that easier to do so you can use VPC you can launch your elastic search",
    "start": "309919",
    "end": "316550"
  },
  {
    "text": "service domain in a V PC you can use I am for fine-grained access control and",
    "start": "316550",
    "end": "321860"
  },
  {
    "text": "you can use kognito for a login experience with Cabana you can make your elastic search cluster",
    "start": "321860",
    "end": "328400"
  },
  {
    "text": "more highly available we have a multi a-z check box basically it makes it",
    "start": "328400",
    "end": "333530"
  },
  {
    "text": "really simple just to say yeah spread my data and nodes across availability zones and finally you can use other AWS",
    "start": "333530",
    "end": "341030"
  },
  {
    "text": "services that are integrated with elastic search service to get your data into elastic search service amongst them",
    "start": "341030",
    "end": "347479"
  },
  {
    "text": "you can use Kinesis data firehose to send data to elastic search you can send data from cloud watch logs to elastic",
    "start": "347479",
    "end": "353510"
  },
  {
    "text": "search you can use database migration service to migrate data from your database to elastic search service",
    "start": "353510",
    "end": "360130"
  },
  {
    "text": "amongst others on the other end we provide integration with cloud watch we send cluster metrics to cloud watch so",
    "start": "360130",
    "end": "367789"
  },
  {
    "text": "you can monitor what's going on with your cluster and you can make decisions about scale and sizing so that's my",
    "start": "367789",
    "end": "376400"
  },
  {
    "start": "376000",
    "end": "399000"
  },
  {
    "text": "high-level overview of elastic search if you don't know what it is we're gonna dive in now and we have",
    "start": "376400",
    "end": "381740"
  },
  {
    "text": "three topics that we're going to cover the first of those is we're gonna look at optimization for cost and performance",
    "start": "381740",
    "end": "388479"
  },
  {
    "text": "then I'm going to recommend to you to use I three instances where you can and then I'm going to talk about the Refresh",
    "start": "388479",
    "end": "395270"
  },
  {
    "text": "interval what it is and how it helps you so as we look at sizing sizing is a",
    "start": "395270",
    "end": "402910"
  },
  {
    "start": "399000",
    "end": "413000"
  },
  {
    "text": "perennial topic for me I talk to lots and lots and lots of customers most customers need a little help thinking",
    "start": "402910",
    "end": "409700"
  },
  {
    "text": "about sizing and figuring out how to get to the right size and it's really important to sized correctly sizing",
    "start": "409700",
    "end": "416780"
  },
  {
    "text": "correctly will improve your performance and also will reduce your cost so that's",
    "start": "416780",
    "end": "422960"
  },
  {
    "text": "what we're going to use to dive in and figure out how to optimize so there are",
    "start": "422960",
    "end": "429500"
  },
  {
    "text": "two dimensions that Amazon elasticsearch charges on actually are three but the main two are instance hours for the",
    "start": "429500",
    "end": "437750"
  },
  {
    "text": "distributed cluster that we're running if you choose to use EBS for your storage then we charge for storage as",
    "start": "437750",
    "end": "444170"
  },
  {
    "text": "well the one that's not on the slide is data transfer now we also charge data transfer out",
    "start": "444170",
    "end": "450010"
  },
  {
    "text": "things that drive that are there are a couple of things that drive that number",
    "start": "450010",
    "end": "456590"
  },
  {
    "text": "one as you're pushing data into elasticsearch service we're elasticsearch is creating indexes that gets stored on disk and so the amount of",
    "start": "456590",
    "end": "464240"
  },
  {
    "text": "data that you push in controls how much disk you need to deploy and then on top",
    "start": "464240",
    "end": "471650"
  },
  {
    "text": "of that as you're sending updates and queries to elasticsearch there's a processing requirement CPU requirement",
    "start": "471650",
    "end": "478010"
  },
  {
    "text": "so the kind and quantity of traffic that you send in also drives the number of",
    "start": "478010",
    "end": "484220"
  },
  {
    "text": "instances that you choose we'll talk a lot about tenancy and AJ and Andy will",
    "start": "484220",
    "end": "489500"
  },
  {
    "text": "really get deep into tenancy tenancy can also drive you your usage higher so",
    "start": "489500",
    "end": "495470"
  },
  {
    "text": "handling tenancy correctly is important and your mapping which is the schema",
    "start": "495470",
    "end": "500690"
  },
  {
    "text": "that you give to elasticsearch to tell it how to index your data controls to some extent the size of your indexes so",
    "start": "500690",
    "end": "507350"
  },
  {
    "text": "again that's a storage component and we'll dive into that before we do let's have a quick look at how elasticsearch",
    "start": "507350",
    "end": "514880"
  },
  {
    "start": "511000",
    "end": "588000"
  },
  {
    "text": "handles data as I mentioned it's a clustered distributed algorithm so we have a number of instances when I'm",
    "start": "514880",
    "end": "521360"
  },
  {
    "text": "pushing data into elasticsearch I specify an index that will hold that data that's a construct that is across",
    "start": "521360",
    "end": "528980"
  },
  {
    "text": "the full data set now the actual documents are indexed into what we call shards we specify the",
    "start": "528980",
    "end": "536690"
  },
  {
    "text": "number of shards when we create the index and elasticsearch distributes the data by default randomly across that set",
    "start": "536690",
    "end": "544220"
  },
  {
    "text": "of shards the shards then can either be primary so we always have a primary",
    "start": "544220",
    "end": "550250"
  },
  {
    "text": "shard but then we can also add a dynamic number of replica shards that are copies",
    "start": "550250",
    "end": "555589"
  },
  {
    "text": "of the primaries you use replica shards the for the first one for redundancy and",
    "start": "555589",
    "end": "560990"
  },
  {
    "text": "then for additional copies usually for search throughput but it's a reasonable",
    "start": "560990",
    "end": "566660"
  },
  {
    "text": "expectation that you'll have one primary in one replica of each shard the shards are really important because they are",
    "start": "566660",
    "end": "573740"
  },
  {
    "text": "the things that do the compute and do the storage so as you look at scaling and sizing how the shards are mapped",
    "start": "573740",
    "end": "580730"
  },
  {
    "text": "onto the instances is what controls how you're using your resources excuse me so",
    "start": "580730",
    "end": "590139"
  },
  {
    "start": "588000",
    "end": "652000"
  },
  {
    "text": "storage is actually a fairly straightforward way to look at the sizing needs I have a magic formula here",
    "start": "590139",
    "end": "598250"
  },
  {
    "text": "it's not right for you probably but it is directional so we can look at the components of it in and understand them",
    "start": "598250",
    "end": "605050"
  },
  {
    "text": "the first thing is we have an index that's going to be on disk that is",
    "start": "605050",
    "end": "610819"
  },
  {
    "text": "probably larger than the amount of source data it depends on a bunch of things that we're going to see so that",
    "start": "610819",
    "end": "616579"
  },
  {
    "text": "first one point one there says okay well give me a 10% inflation then each",
    "start": "616579",
    "end": "623389"
  },
  {
    "text": "replica is an additional copy of the data by one primary one replica I need twice I need to multiply by two",
    "start": "623389",
    "end": "630920"
  },
  {
    "text": "in most situations for log analytics you'll retain some number of days of data so if I my data source is per day",
    "start": "630920",
    "end": "638600"
  },
  {
    "text": "then I multiply by the number of days that I want to keep and then I add a 15% overhead that prevents me from hitting",
    "start": "638600",
    "end": "645350"
  },
  {
    "text": "some of the watermarks and elasticsearch that caused it to stop indexing data so",
    "start": "645350",
    "end": "653360"
  },
  {
    "start": "652000",
    "end": "679000"
  },
  {
    "text": "one of the key places that you can intervene to reduce the amount of storage that you need is looking at your",
    "start": "653360",
    "end": "659089"
  },
  {
    "text": "source fundamentally you only want to put into elasticsearch what you on a search or what you want to",
    "start": "659089",
    "end": "665630"
  },
  {
    "text": "visualize so if you can strip out unwanted or unused data you'll have a direct effect on how much storage you",
    "start": "665630",
    "end": "672380"
  },
  {
    "text": "need which will if will directly affect your bottom line and also your performance so only it's only send what",
    "start": "672380",
    "end": "678320"
  },
  {
    "text": "you intend to search I did some testing to kind of prove out this point I have",
    "start": "678320",
    "end": "684140"
  },
  {
    "start": "679000",
    "end": "712000"
  },
  {
    "text": "three data sets the first of those is BoardGameGeek I am a board game geek so",
    "start": "684140",
    "end": "689510"
  },
  {
    "text": "I used that one second one of those is the jargon file if you haven't heard of the jargon file jargon file was running",
    "start": "689510",
    "end": "695900"
  },
  {
    "text": "around MIT in the 60s and 70s this is a hacker dictionary it's just word",
    "start": "695900",
    "end": "700910"
  },
  {
    "text": "definition so this is a full text example the BoardGameGeek is a mixed",
    "start": "700910",
    "end": "706310"
  },
  {
    "text": "metadata and text and then the third one I used was a patchy web logs public data",
    "start": "706310",
    "end": "711680"
  },
  {
    "text": "set from NASA then I have a couple of different conditions I used log stashes default template and",
    "start": "711680",
    "end": "717850"
  },
  {
    "text": "I in later versions of log stash they've been doing the job of optimizing how it",
    "start": "717850",
    "end": "724010"
  },
  {
    "text": "stores stuff and they turn on best compression by default so for comparison I said okay let's turn off the best",
    "start": "724010",
    "end": "729650"
  },
  {
    "text": "compression and then I removed that message so log stash when it's send your",
    "start": "729650",
    "end": "734900"
  },
  {
    "text": "log data in includes the original log line in the actual Jason that it sends",
    "start": "734900",
    "end": "740360"
  },
  {
    "text": "that original log line has a huge impact on how much is stored so I turned off",
    "start": "740360",
    "end": "745640"
  },
  {
    "text": "the message field to see what would happen in the green section I also tested with a hand coded mapping I",
    "start": "745640",
    "end": "755710"
  },
  {
    "text": "removed the message and then I took a cut at the smallest possible by disabling a couple of features and to",
    "start": "755710",
    "end": "763610"
  },
  {
    "text": "see what kind of storage I would get so let's look at what happens when I remove",
    "start": "763610",
    "end": "769040"
  },
  {
    "text": "the message field I have my three data sets the orange is NASA",
    "start": "769040",
    "end": "774260"
  },
  {
    "text": "the blue is BoardGameGeek the gray is jargon jargon is tiny so I multiplied by",
    "start": "774260",
    "end": "779360"
  },
  {
    "text": "a hundred means the absolute value is wrong but the relative values are correct if I look at the left that is",
    "start": "779360",
    "end": "787280"
  },
  {
    "text": "removing the message field the center is what you get with logstash out-of-the-box so if you look at the",
    "start": "787280",
    "end": "793550"
  },
  {
    "text": "nasa and this is the the logging use case if you look at the nasa logs I started at about 250 megabytes just",
    "start": "793550",
    "end": "800690"
  },
  {
    "text": "turning off message I got down to 50 megabytes that's an 80% reduction that's huge and",
    "start": "800690",
    "end": "806900"
  },
  {
    "text": "if you do that again 80% reduction in storage translates to 80% reduction in the amount of instances",
    "start": "806900",
    "end": "813110"
  },
  {
    "text": "I need to store I need to spin up and cost second piece here that we can look",
    "start": "813110",
    "end": "819770"
  },
  {
    "start": "817000",
    "end": "907000"
  },
  {
    "text": "at is this inflation percentage between your source data and the index size and",
    "start": "819770",
    "end": "825650"
  },
  {
    "text": "what's really controlling that is your mapping that you're setting and the features in your mapping that you're using so source is the number one thing",
    "start": "825650",
    "end": "835700"
  },
  {
    "text": "that you can control to reduce size elasticsearch stores the source data of",
    "start": "835700",
    "end": "841880"
  },
  {
    "text": "every line you pass in along with the indexes for that line if you don't need",
    "start": "841880",
    "end": "848360"
  },
  {
    "text": "the source data and what you use it for is to reenact to do things like highlighting number things that",
    "start": "848360",
    "end": "855200"
  },
  {
    "text": "generally in a log use case you wouldn't do so you can disable source either globally or individually on fields again",
    "start": "855200",
    "end": "863510"
  },
  {
    "text": "to reduce the amount of storage that you need log stash by default also defines for you a keyword field for every text",
    "start": "863510",
    "end": "870710"
  },
  {
    "text": "field so I'm sending in a text field that's an analyzed field it's one that I",
    "start": "870710",
    "end": "875840"
  },
  {
    "text": "want to search word by word so logstash helpfully adds a keyword version which is an exact match field well if I don't",
    "start": "875840",
    "end": "882680"
  },
  {
    "text": "actually need the text version or the keyword version I can disable those and I'll save a bunch of space also",
    "start": "882680",
    "end": "889090"
  },
  {
    "text": "elasticsearch computes some statistical values at indexing time that it keeps along with the fields to to do scoring",
    "start": "889090",
    "end": "897140"
  },
  {
    "text": "those are called norms if you just those norms are actually fairly large you can",
    "start": "897140",
    "end": "902270"
  },
  {
    "text": "disable those norms too again to reduce sizing so if I look at the effects of",
    "start": "902270",
    "end": "909260"
  },
  {
    "start": "907000",
    "end": "983000"
  },
  {
    "text": "that on the Left again I have my three data sets here orange is NASA blue is",
    "start": "909260",
    "end": "914330"
  },
  {
    "text": "BoardGameGeek and gray is jargon on the Left I have the original source data",
    "start": "914330",
    "end": "919490"
  },
  {
    "text": "size and then I have a baseline which is my hand coded mapping that I used with",
    "start": "919490",
    "end": "925550"
  },
  {
    "text": "all of the features enabled so that's what you would get sort of out of the box I enabled best compress",
    "start": "925550",
    "end": "931200"
  },
  {
    "text": "I did it with no source data I did it with a message disabled and then I did a",
    "start": "931200",
    "end": "937440"
  },
  {
    "text": "smallest which is not even index that's everything shut off totally useless but interesting as that's as small as you",
    "start": "937440",
    "end": "943380"
  },
  {
    "text": "can go if you look at the BoardGameGeek here that is the mixed metadata full",
    "start": "943380",
    "end": "949440"
  },
  {
    "text": "text use case and simply by turning off the source I go from 260 thousand to approximately",
    "start": "949440",
    "end": "957480"
  },
  {
    "text": "90,000 so again disabling source provides you of like 50 60 percent",
    "start": "957480",
    "end": "963060"
  },
  {
    "text": "reduction possibly in the amount of data that you're storing you can do that either globally or per field and so",
    "start": "963060",
    "end": "970620"
  },
  {
    "text": "that's a great way to reduce the amount of storage you used also you can see best compression is a good one to turn",
    "start": "970620",
    "end": "976560"
  },
  {
    "text": "on that buys me quite a bit and disabling the message as we already knew",
    "start": "976560",
    "end": "983000"
  },
  {
    "text": "so to wrap this kind of section you can remove the message field this is how you",
    "start": "983000",
    "end": "988920"
  },
  {
    "text": "do it you put it in your mapping you say at message enabled false you can disable",
    "start": "988920",
    "end": "994050"
  },
  {
    "text": "source to disable it globally you say in the mapping source enabled false to",
    "start": "994050",
    "end": "999959"
  },
  {
    "text": "disable it for particular fields you can use this source include exclude and finally enable best compression so in",
    "start": "999959",
    "end": "1008029"
  },
  {
    "text": "your settings for your index use codec best compression okay so that's how we",
    "start": "1008029",
    "end": "1016790"
  },
  {
    "text": "deal with optimizing storage now we'll talk a little bit about optimizing compute and we have to handle our two",
    "start": "1016790",
    "end": "1025579"
  },
  {
    "start": "1023000",
    "end": "1230000"
  },
  {
    "text": "different workloads a little bit differently so again recap they have there are two different kinds of workloads I have I have a full",
    "start": "1025579",
    "end": "1031938"
  },
  {
    "text": "text workload or I have a logs workload in the full text case I usually have one index that's holding my data right",
    "start": "1031939",
    "end": "1038808"
  },
  {
    "text": "that's all my product catalog that's whatever for streaming logs we usually have one index which is today's index",
    "start": "1038809",
    "end": "1045798"
  },
  {
    "text": "which is receiving tons of updates then we have a long tail of indexes that hold yesterday the day before the day before",
    "start": "1045799",
    "end": "1052130"
  },
  {
    "text": "right so what I would encourage you to think about is in both cases we have one",
    "start": "1052130",
    "end": "1058790"
  },
  {
    "text": "index that's primarily active the old logs indexes receive some traffic",
    "start": "1058790",
    "end": "1064890"
  },
  {
    "text": "not a time so squinting our eyes we can kind of ignore a little bit those older indexes and we think about sizing we can",
    "start": "1064890",
    "end": "1071910"
  },
  {
    "text": "think about what's active right now as I",
    "start": "1071910",
    "end": "1077970"
  },
  {
    "text": "said the shards get then distributed across the instances in the cluster if",
    "start": "1077970",
    "end": "1083490"
  },
  {
    "text": "we have our streaming case here we have three primaries three replicas seven days those are distributed across four",
    "start": "1083490",
    "end": "1089970"
  },
  {
    "text": "nodes in the search we have one primary and three replicas distributed across six nodes as I send updates into the",
    "start": "1089970",
    "end": "1099930"
  },
  {
    "text": "clusters so for the logs use case I'm gonna have that one active index my",
    "start": "1099930",
    "end": "1106250"
  },
  {
    "text": "request is processed by the primaries path to the replicas so I have",
    "start": "1106250",
    "end": "1111270"
  },
  {
    "text": "essentially six processes that need to run to index that data in the search use",
    "start": "1111270",
    "end": "1119490"
  },
  {
    "text": "case I send to the primaries then the primaries are gonna send to the replicas the high-level point here is there's a",
    "start": "1119490",
    "end": "1126480"
  },
  {
    "text": "multiplicative factor one request generates CPU usage that's n times as",
    "start": "1126480",
    "end": "1131820"
  },
  {
    "text": "big right four queries I send in a query",
    "start": "1131820",
    "end": "1137940"
  },
  {
    "text": "and it hits one of all of the shards in the index so in the logs use case I'm",
    "start": "1137940",
    "end": "1145680"
  },
  {
    "text": "going to hit some number of primaries could be some number of replicas it's an",
    "start": "1145680",
    "end": "1151710"
  },
  {
    "text": "again but it's not as big and same thing for the search use case so one important",
    "start": "1151710",
    "end": "1159930"
  },
  {
    "text": "point as you're scaling and sizing it those requests are running in shards",
    "start": "1159930",
    "end": "1165450"
  },
  {
    "text": "that need CPUs so if you look at the distribution of shards two nodes and",
    "start": "1165450",
    "end": "1170790"
  },
  {
    "text": "compare with how many CPUs you have you can get a starting point for how to scale your cluster and the active shards",
    "start": "1170790",
    "end": "1178710"
  },
  {
    "text": "to CPU ratio should be less than about one your mileage will certainly vary",
    "start": "1178710",
    "end": "1184800"
  },
  {
    "text": "from this but again this is a good starting point it needs to be less than one because there are other tasks that",
    "start": "1184800",
    "end": "1191100"
  },
  {
    "text": "run on the cluster so you can't fill up all the CPUs a hundred percent",
    "start": "1191100",
    "end": "1196220"
  },
  {
    "text": "second point your total shards in your cluster should be less than well 25 per",
    "start": "1196470",
    "end": "1204539"
  },
  {
    "text": "gigabyte of JVM well we see usually is that customers who have less than a thousand shards do well customers with",
    "start": "1204539",
    "end": "1211350"
  },
  {
    "text": "more than a thousand charges tend to get into a yellow area customers with more than twenty or so thousand",
    "start": "1211350",
    "end": "1217080"
  },
  {
    "text": "shards those clusters are not often successful so keeping your overall shard",
    "start": "1217080",
    "end": "1222630"
  },
  {
    "text": "count down and your shard to CPU ratio in line are important for your",
    "start": "1222630",
    "end": "1227789"
  },
  {
    "text": "performance just to let you know how to",
    "start": "1227789",
    "end": "1233280"
  },
  {
    "text": "set the shard count you set the shard count when you create the index and it's",
    "start": "1233280",
    "end": "1238770"
  },
  {
    "text": "you can change it it's somewhat difficult so you can directly create an index with the left hand with the left",
    "start": "1238770",
    "end": "1245280"
  },
  {
    "text": "hand rest call and you just say index number of shards five number of replicas",
    "start": "1245280",
    "end": "1250440"
  },
  {
    "text": "zero you can also put other settings and mappings and all sorts of stuff can go in there the better way to do it",
    "start": "1250440",
    "end": "1256200"
  },
  {
    "text": "especially for log analytics use case is to set a template elasticsearch lets you set templates where settings are applied",
    "start": "1256200",
    "end": "1263520"
  },
  {
    "text": "to any index created that matches the wild card in that template so in this",
    "start": "1263520",
    "end": "1268530"
  },
  {
    "text": "case templates star means match every new index that's created and then with your settings I'm going to set my number",
    "start": "1268530",
    "end": "1274830"
  },
  {
    "text": "of shards a number of replicas and then every new index I get that this is",
    "start": "1274830",
    "end": "1279960"
  },
  {
    "text": "particularly good for log analytics because if you're sending data in and your data volume is growing then you can",
    "start": "1279960",
    "end": "1287760"
  },
  {
    "text": "just change your template tomorrow's index will have more shards right and you want to again look at storage for",
    "start": "1287760",
    "end": "1295919"
  },
  {
    "text": "how many shards to set that's your baseline so we would like to see shards",
    "start": "1295919",
    "end": "1301679"
  },
  {
    "text": "that are 50 gigabytes are smaller if I have a terabyte of index I would like to",
    "start": "1301679",
    "end": "1307350"
  },
  {
    "text": "see oh geez I can't do the math 20 shards just divided by 50 that should be",
    "start": "1307350",
    "end": "1313320"
  },
  {
    "text": "your primary shard count so we're going",
    "start": "1313320",
    "end": "1318809"
  },
  {
    "text": "to talk a little bit about I three instances in terms of cost and performance in the service we support a",
    "start": "1318809",
    "end": "1325200"
  },
  {
    "text": "number of different instance types we have AI 3s are effective in terms of",
    "start": "1325200",
    "end": "1331409"
  },
  {
    "start": "1327000",
    "end": "1422000"
  },
  {
    "text": "price performance ratios so what I've done here is I've taken the total",
    "start": "1331409",
    "end": "1336570"
  },
  {
    "text": "monthly cost of the instance I've added in an EBS cost if it's an EBS instance",
    "start": "1336570",
    "end": "1342600"
  },
  {
    "text": "and I've assumed that the maximum size EBS volume is deployed that gives me a",
    "start": "1342600",
    "end": "1348690"
  },
  {
    "text": "total monthly cost and I can divide by that to get a price per gigabyte per",
    "start": "1348690",
    "end": "1353760"
  },
  {
    "text": "month of that particular instance type and what I'd highlight here is we have",
    "start": "1353760",
    "end": "1359010"
  },
  {
    "text": "m4 and r4 are less costly 28 32 and 35",
    "start": "1359010",
    "end": "1364590"
  },
  {
    "text": "cents but the I threes are right behind them in terms of their price per gigabyte 39 cents given that I've died",
    "start": "1364590",
    "end": "1373049"
  },
  {
    "text": "threes have nvme storage and you're not using EBS so you'll get better performance out of them their price per",
    "start": "1373049",
    "end": "1379740"
  },
  {
    "text": "gigabyte is very competitive and we do think these are the best instances given what we support right now however at the",
    "start": "1379740",
    "end": "1389909"
  },
  {
    "text": "low end the I 3s can be more expensive and we like to say it's about 3 terabytes so if you're less than 3",
    "start": "1389909",
    "end": "1397019"
  },
  {
    "text": "terabytes you can use the m4s and our 4s with smaller EBS volumes to get a lower",
    "start": "1397019",
    "end": "1402990"
  },
  {
    "text": "overall cost but as soon as you start to hit that 5 terabyte terabyte line you'll",
    "start": "1402990",
    "end": "1408659"
  },
  {
    "text": "see the i3 instances come in and that's where they're they become price performance effective of course if you",
    "start": "1408659",
    "end": "1415350"
  },
  {
    "text": "need the extra performance of the nvme SSD then of course the I threes make sense at any scale quick question do you",
    "start": "1415350",
    "end": "1424409"
  },
  {
    "start": "1422000",
    "end": "1469000"
  },
  {
    "text": "need PI ops short answer no and we'll talk about AJ and Andy will really touch",
    "start": "1424409",
    "end": "1430529"
  },
  {
    "text": "on some of these these points with EBS you get 3i ops per gigabyte of deployed",
    "start": "1430529",
    "end": "1440039"
  },
  {
    "text": "volume elasticsearch does not drive the disk particularly hard so that tends to",
    "start": "1440039",
    "end": "1447510"
  },
  {
    "text": "be enough unless you're in a highly multi-tenant situation and you have a ton of concurrency then you're driving",
    "start": "1447510",
    "end": "1453809"
  },
  {
    "text": "more disk that way so generally speaking look at your cloud watch metrics and you",
    "start": "1453809",
    "end": "1460509"
  },
  {
    "text": "see how much how many eye ops you're using and dollars to donuts unless you're in one of these highly",
    "start": "1460509",
    "end": "1465669"
  },
  {
    "text": "multi-tenant situations you won't need pi ops let's talk about",
    "start": "1465669",
    "end": "1471549"
  },
  {
    "start": "1469000",
    "end": "1488000"
  },
  {
    "text": "refresh interval so refresh interval can buy you additional indexing capacity it",
    "start": "1471549",
    "end": "1478059"
  },
  {
    "text": "depends on your workload of course but 50% 60% those are not unreasonable",
    "start": "1478059",
    "end": "1483699"
  },
  {
    "text": "expectations of additional capacity which means you need 50% less hardware so what is refresh interval well as",
    "start": "1483699",
    "end": "1491859"
  },
  {
    "start": "1488000",
    "end": "1567000"
  },
  {
    "text": "documents are coming in to elasticsearch for indexing they are their past two",
    "start": "1491859",
    "end": "1497049"
  },
  {
    "text": "leucine leucine is a Java library that creates indexes they go to leucine which indexes amande creates a ram version of",
    "start": "1497049",
    "end": "1504039"
  },
  {
    "text": "the index that's called a segment every refresh interval that segment is written",
    "start": "1504039",
    "end": "1509469"
  },
  {
    "text": "to disk when you get enough segments leucine merges them down into a smaller",
    "start": "1509469",
    "end": "1516039"
  },
  {
    "text": "set of larger segments so the more I'm doing refresh the more segments I'm",
    "start": "1516039",
    "end": "1522099"
  },
  {
    "text": "creating the more I'm spending time merging those segments together and the merging of the segments takes CPU away",
    "start": "1522099",
    "end": "1529089"
  },
  {
    "text": "from indexing so by increasing my refresh interval I hold the data in RAM",
    "start": "1529089",
    "end": "1534339"
  },
  {
    "text": "longer don't flush it to disk and then I have less work to do down the line so",
    "start": "1534339",
    "end": "1541239"
  },
  {
    "text": "this is this is actually again a 50% potentially of additional capacity that",
    "start": "1541239",
    "end": "1547269"
  },
  {
    "text": "you can gain by pushing your refresh interval to 30 seconds or 60 seconds the",
    "start": "1547269",
    "end": "1553419"
  },
  {
    "text": "flipside is then that data is not available for search or visualization so it adds latency into your update chain",
    "start": "1553419",
    "end": "1559389"
  },
  {
    "text": "so that's the trade-off that you make if you push it up a little bit you'll get additional capacity at a not so bad",
    "start": "1559389",
    "end": "1565179"
  },
  {
    "text": "latency trade-off so you can set your refresh interval in much of the same way",
    "start": "1565179",
    "end": "1572679"
  },
  {
    "start": "1567000",
    "end": "1626000"
  },
  {
    "text": "that you set your shard count you set your refresh interval if at index creation by putting it into the settings",
    "start": "1572679",
    "end": "1581169"
  },
  {
    "text": "and also you can put it in your template so that it gets automatically applied",
    "start": "1581169",
    "end": "1587249"
  },
  {
    "text": "important point you can dynamically change your refresh interval so if you set it to like one second you can also",
    "start": "1587249",
    "end": "1594560"
  },
  {
    "text": "increase or decrease it dynamically by sending this API call which comes in",
    "start": "1594560",
    "end": "1600500"
  },
  {
    "text": "handy if you have a large data load you can actually set your refresh interval negative 1 to turn it off and then",
    "start": "1600500",
    "end": "1607130"
  },
  {
    "text": "everything is just indexed in RAM send your number of replicas down to zero and",
    "start": "1607130",
    "end": "1612860"
  },
  {
    "text": "then you can dump a ton of data on the cluster and once everything stabilizes",
    "start": "1612860",
    "end": "1617990"
  },
  {
    "text": "you can push a refresh interval back up and start sending updates so if you have a data load that's a performant way to",
    "start": "1617990",
    "end": "1624680"
  },
  {
    "text": "do it one last little tidbit to share we",
    "start": "1624680",
    "end": "1631820"
  },
  {
    "start": "1626000",
    "end": "1703000"
  },
  {
    "text": "do charge for data transfer out as I mentioned when you post to the bulk API elasticsearch helpfully responds with an",
    "start": "1631820",
    "end": "1638660"
  },
  {
    "text": "enormous response that has the status of each of the indexing each of the",
    "start": "1638660",
    "end": "1645080"
  },
  {
    "text": "documents that it tried to index that's great but it can get very costly to transfer all that data out of",
    "start": "1645080",
    "end": "1650990"
  },
  {
    "text": "elasticsearch you can disable that by using the filter path parameter filter",
    "start": "1650990",
    "end": "1656870"
  },
  {
    "text": "path is available at a global level you can use it for any API call to filter in",
    "start": "1656870",
    "end": "1662000"
  },
  {
    "text": "or out pieces of the response so if you remove the items from your filter path",
    "start": "1662000",
    "end": "1668450"
  },
  {
    "text": "you get a response that looks like the one on the bottom how long did it take in how many errors that I have that's",
    "start": "1668450",
    "end": "1674260"
  },
  {
    "text": "99% smaller than what you would have gotten if you got a line-by-line report",
    "start": "1674260",
    "end": "1679270"
  },
  {
    "text": "you lose the fidelity though so it's a trade-off here then you don't know for a",
    "start": "1679270",
    "end": "1685580"
  },
  {
    "text": "fact which things failed if things failed in your indexing so if you're",
    "start": "1685580",
    "end": "1690800"
  },
  {
    "text": "pushing log data in and and you're more cost-conscious you can disable this that'll buy you some cost at the at the",
    "start": "1690800",
    "end": "1699080"
  },
  {
    "text": "cost of a little bit of fidelity in knowing what's happening so a little bit",
    "start": "1699080",
    "end": "1704960"
  },
  {
    "start": "1703000",
    "end": "1743000"
  },
  {
    "text": "of a mini wrap we talked about three things we talked about how to optimize your storage just a few things that you",
    "start": "1704960",
    "end": "1711560"
  },
  {
    "text": "can set fairly easy to do that will buy you a ton of additional additional storage we recommended the I three",
    "start": "1711560",
    "end": "1718970"
  },
  {
    "text": "instances as the best kind of cost performance accepted of smaller scale and then we talked about increasing",
    "start": "1718970",
    "end": "1725870"
  },
  {
    "text": "refresh interval to add additional indexing capacity to your cluster so I'm",
    "start": "1725870",
    "end": "1731020"
  },
  {
    "text": "gonna turn it over to AJ and Andy and thanks very much alright everybody can",
    "start": "1731020",
    "end": "1746800"
  },
  {
    "text": "hear me now good okay so we're from Sports Engine my name is Andy Fleenor I'm the senior platform",
    "start": "1746800",
    "end": "1752950"
  },
  {
    "text": "operations manager at sports engine I lead a team that's tasked with keeping our platform up and running and I'm here",
    "start": "1752950",
    "end": "1758590"
  },
  {
    "text": "with my coworker hi everyone my name's AJ Steven Berg I am the lead software engineer for the member management product where what you're gonna hear",
    "start": "1758590",
    "end": "1764830"
  },
  {
    "text": "about here in a little bit for the purposes of the post-mortems you're about to hear about consider me a contributing condition yeah so it's",
    "start": "1764830",
    "end": "1773050"
  },
  {
    "text": "interesting the first time that AJ and I actually met John we were on a conference call with them where we were sort of describing this use case that",
    "start": "1773050",
    "end": "1778450"
  },
  {
    "text": "we're about to explain to you all and he said congratulations you have the worst use case for elasticsearch so that's",
    "start": "1778450",
    "end": "1785380"
  },
  {
    "text": "just the sign of things to come so a little bit about sports engine sports engine is a youth sports",
    "start": "1785380",
    "end": "1791040"
  },
  {
    "text": "technology organization that basically services all as many of most of the",
    "start": "1791040",
    "end": "1797290"
  },
  {
    "text": "youth sports organizations throughout the US so we we deal with like Little",
    "start": "1797290",
    "end": "1802780"
  },
  {
    "text": "League baseball hockey all kinds of all any sport you can think of we've been on",
    "start": "1802780",
    "end": "1808300"
  },
  {
    "text": "a bit of an acquisition spree so over the last three years we've acquired 12 companies lots of companies in sport",
    "start": "1808300",
    "end": "1814690"
  },
  {
    "text": "verticals as well as background screening so we care a lot about keeping kids safe and so the other thing is we",
    "start": "1814690",
    "end": "1821290"
  },
  {
    "text": "actually got acquired by NBC Sports and so we've gone from a startup when I started of 70 people so now we have 450",
    "start": "1821290",
    "end": "1829000"
  },
  {
    "text": "employees thoughts throughout the US and also in Canada so what do we do we",
    "start": "1829000",
    "end": "1836140"
  },
  {
    "start": "1834000",
    "end": "1863000"
  },
  {
    "text": "service thousands of organizations millions of athletes were 100% on AWS so",
    "start": "1836140",
    "end": "1841600"
  },
  {
    "text": "we have 60 distinct services throughout our platform 650 plus AWS instances and",
    "start": "1841600",
    "end": "1848050"
  },
  {
    "text": "we we have 20 different AWS accounts so a little bit of that when you acquire 12 companies you start to get acquiring",
    "start": "1848050",
    "end": "1854950"
  },
  {
    "text": "extra AWS accounts fun fun thing that we deal with so what",
    "start": "1854950",
    "end": "1860850"
  },
  {
    "text": "we're gonna talk about today is is sort of the challenges that we ran into as we",
    "start": "1860850",
    "end": "1867690"
  },
  {
    "start": "1863000",
    "end": "1963000"
  },
  {
    "text": "started to build out this use case so this use case is so we collect we do",
    "start": "1867690",
    "end": "1873720"
  },
  {
    "text": "registrations is one of our primary products that we offer so registration for signing up for a little eager or",
    "start": "1873720",
    "end": "1879590"
  },
  {
    "text": "youth hockey or whatever it is and so when we when you sign up for it those",
    "start": "1879590",
    "end": "1884850"
  },
  {
    "text": "organizations that we service our customers their goal is is really to you",
    "start": "1884850",
    "end": "1891750"
  },
  {
    "text": "know understand all the people that are signing up and they want to understand them from like almost like a CRM level",
    "start": "1891750",
    "end": "1897000"
  },
  {
    "text": "right they're really trying to figure out how to reach out to new parents to understand how they can you know get",
    "start": "1897000",
    "end": "1903330"
  },
  {
    "text": "more people signed up and playing you sports and so the key challenges we had were around so tenancy right so one",
    "start": "1903330",
    "end": "1910470"
  },
  {
    "text": "organization only cares about all the data for that organization they don't care about anyone elses organization and",
    "start": "1910470",
    "end": "1916350"
  },
  {
    "text": "so we went through multiple iterations of figuring out how to do this tenancy model with elasticsearch the other thing",
    "start": "1916350",
    "end": "1922740"
  },
  {
    "text": "we're gonna talk about is what happens when you dynamically map fields with a never-ending amount of fields that can",
    "start": "1922740",
    "end": "1928830"
  },
  {
    "text": "be created so this registration product we basically allow our customers to create questions to ask the people",
    "start": "1928830",
    "end": "1934830"
  },
  {
    "text": "registering for their programs like whatever they want to ask them right t-shirt size anything you know help even",
    "start": "1934830",
    "end": "1943380"
  },
  {
    "text": "even like health information understanding if they got physicals and all that stuff and then the other thing that was really",
    "start": "1943380",
    "end": "1949799"
  },
  {
    "text": "important to us is we wanted to ensure that our customers could continue to search that information all the time so",
    "start": "1949799",
    "end": "1957780"
  },
  {
    "text": "we had zero we had we had a zero downtime re-indexing requirement that we wanted to build so as the administrator",
    "start": "1957780",
    "end": "1966059"
  },
  {
    "text": "of our youth sports organization I'm running my organization more like a business every day I need to understand this end he said churn I need to see new",
    "start": "1966059",
    "end": "1972809"
  },
  {
    "text": "people who signed up reach out to new hockey parents people that may be new to gymnastics that might need a little extra help and and I'm fundamentally",
    "start": "1972809",
    "end": "1979320"
  },
  {
    "text": "rallying around the idea of how can I organize thousands of athletes when you go all the way to even like an NGB level",
    "start": "1979320",
    "end": "1985950"
  },
  {
    "text": "or a national governing body level they're managing the play of tens of thousands of and they need to understand all of the",
    "start": "1985950",
    "end": "1992650"
  },
  {
    "text": "people that are registering so as any mentioned we have a registration product where we're ingesting massive amounts of",
    "start": "1992650",
    "end": "1998230"
  },
  {
    "text": "data every season an organization may have two or three of these as they're collecting information for tryouts for",
    "start": "1998230",
    "end": "2003960"
  },
  {
    "text": "traveling teams or for tournament interest but we need a way to surfer the surface in a way that makes sense so",
    "start": "2003960",
    "end": "2010200"
  },
  {
    "text": "before we dive in and tell you the architecture what I'm gonna do is show you a little bit about the product itself so as an administrator of Edina",
    "start": "2010200",
    "end": "2017010"
  },
  {
    "start": "2014000",
    "end": "2116000"
  },
  {
    "text": "Hockey Association when I log in to my sports legend headquarters this is the view that I get you can see right away",
    "start": "2017010",
    "end": "2022830"
  },
  {
    "text": "that I've got a big filter button on the top it's a whole table and it shows initially by default first name last",
    "start": "2022830",
    "end": "2029220"
  },
  {
    "text": "name and email address so a really common use case that we had to solve what this was who registered last year",
    "start": "2029220",
    "end": "2035610"
  },
  {
    "text": "who hasn't signed up yet right who might be at risk of churning so what I'll do here is I'll set up a filter that does",
    "start": "2035610",
    "end": "2042510"
  },
  {
    "text": "exactly this so I can filter across registration sessions which is a new thing in this product that elasticsearch allowed us to do so I can say okay from",
    "start": "2042510",
    "end": "2049350"
  },
  {
    "text": "last year's session who signed up and the new hasn't signed up yet this year so this product there this platform that",
    "start": "2049350",
    "end": "2055169"
  },
  {
    "text": "we've built out on top of elasticsearch has a lot of other product verticals on top of it including messaging a payment",
    "start": "2055169",
    "end": "2061260"
  },
  {
    "text": "app feature that allows you to collect payments from parents for things like tournaments and travel",
    "start": "2061260",
    "end": "2066570"
  },
  {
    "text": "it has rostering tools which lets let me assign players and all this other stuff but just filtering and searching and",
    "start": "2066570",
    "end": "2072750"
  },
  {
    "text": "sorting isn't quite enough what I've done here is add two additional columns from completely different registrations",
    "start": "2072750",
    "end": "2078600"
  },
  {
    "text": "so if I am a the administrative Edina hockey what I want to know right now is okay who's new to hockey did this person",
    "start": "2078600",
    "end": "2085350"
  },
  {
    "text": "sign up last year or not this is a custom question that one of our administrator administrators add it to their registration and I can easily see",
    "start": "2085350",
    "end": "2091560"
  },
  {
    "text": "here okay some said yes some said no I can target messaging to the people that said no or the Blitz and yes I've also",
    "start": "2091560",
    "end": "2097230"
  },
  {
    "text": "added another column from the new registration session which is what what level of play did you play at are you",
    "start": "2097230",
    "end": "2102570"
  },
  {
    "text": "boys Bantam did you play girls mites so I can maybe find people that are that are new or find people that maybe are",
    "start": "2102570",
    "end": "2109320"
  },
  {
    "text": "playing up this year maybe in the new level of competitiveness that requires extra touch points so this is what the product does let's talk about how it's",
    "start": "2109320",
    "end": "2116070"
  },
  {
    "start": "2116000",
    "end": "2157000"
  },
  {
    "text": "built yeah so we tried to figure out what our optimal tenancy model is right",
    "start": "2116070",
    "end": "2122490"
  },
  {
    "text": "I think you could probably imagine there's a handful of different ways that we could do this from having you know a single",
    "start": "2122490",
    "end": "2130350"
  },
  {
    "text": "organization with its own cluster being the like biggest hammer that you could drop to you know having an index per",
    "start": "2130350",
    "end": "2136530"
  },
  {
    "text": "organization to having one index that all organizations use really what you",
    "start": "2136530",
    "end": "2143400"
  },
  {
    "text": "need to have tenancy at it's very root is just a key that is the tenancy like the tenant ID right and so you could go",
    "start": "2143400",
    "end": "2149850"
  },
  {
    "text": "as simple as that and be able to solve this problem that way so then whenever you're doing the searching all you're",
    "start": "2149850",
    "end": "2154860"
  },
  {
    "text": "looking at is a specific organization so to understand how we ended up on the right tenancy model I want to give you",
    "start": "2154860",
    "end": "2161370"
  },
  {
    "start": "2157000",
    "end": "2183000"
  },
  {
    "text": "an idea of our workload characteristics so we have 20,000 organizations and that",
    "start": "2161370",
    "end": "2167010"
  },
  {
    "text": "number is continuing least continuously growing we never need to search more than one organization at a time so",
    "start": "2167010",
    "end": "2173160"
  },
  {
    "text": "that's that allows us to do things like you know provide a tenant ID and only search for that tenant ID so really it",
    "start": "2173160",
    "end": "2179730"
  },
  {
    "text": "was it was what what our decisions here about how we want to do this so when",
    "start": "2179730",
    "end": "2185880"
  },
  {
    "start": "2183000",
    "end": "2241000"
  },
  {
    "text": "that's for registration for product first took off what we had done was the kind of thing that every good startup does let's throw my sequel at it so what",
    "start": "2185880",
    "end": "2193110"
  },
  {
    "text": "we had initially was we would create dynamically inside of RDS create a brand new table for every registration session",
    "start": "2193110",
    "end": "2198720"
  },
  {
    "text": "that was open at a column for every question and just blast answers into it it actually worked really well and it was our go-to solution for a pretty long",
    "start": "2198720",
    "end": "2205170"
  },
  {
    "text": "time but eventually it just wasn't satisfying the needs of our customers there was no real learning here I",
    "start": "2205170",
    "end": "2210330"
  },
  {
    "text": "couldn't look back on last year and see beyond counts right how many people signed up last year versus this year so",
    "start": "2210330",
    "end": "2215820"
  },
  {
    "text": "it'd be really hard to identify people that churned or people that have been lifelong members of my organization there's no shared context the the",
    "start": "2215820",
    "end": "2222480"
  },
  {
    "text": "application we were looking at earlier pulls data from all sorts of different data sources including people teams",
    "start": "2222480",
    "end": "2227940"
  },
  {
    "text": "rosters sports stats all this other stuff but in my registration session all I have is what you wrote when you signed",
    "start": "2227940",
    "end": "2234150"
  },
  {
    "text": "up I don't get to see things like maybe your zip code if you didn't ask for it so there's no shared context to understand this information",
    "start": "2234150",
    "end": "2240000"
  },
  {
    "text": "there's also again no history and there's really just no way I can make",
    "start": "2240000",
    "end": "2245550"
  },
  {
    "start": "2241000",
    "end": "2305000"
  },
  {
    "text": "any really good business decisions on this data so the first thing we thought of was all right let's use the elastic",
    "start": "2245550",
    "end": "2250590"
  },
  {
    "text": "search this should work right we had already been using elastic search for a back-end user search tool so we had kind of",
    "start": "2250590",
    "end": "2257200"
  },
  {
    "text": "followed the same pattern we had initially in our Ruby on Rails app we'll use the active record pattern because that kind of comes naturally will create",
    "start": "2257200",
    "end": "2262749"
  },
  {
    "text": "one index we'll call it organizations or tenants and we're just gonna put a tenant ID on every single document in this case the document represents a",
    "start": "2262749",
    "end": "2268839"
  },
  {
    "text": "person in this entire cluster and that's great right no problem we left elasticsearch set at the default which",
    "start": "2268839",
    "end": "2274960"
  },
  {
    "text": "is just index everything I throw it at a new field for it and we'll understand",
    "start": "2274960",
    "end": "2280150"
  },
  {
    "text": "our data later later we really didn't have any plans for expansion at this point and the product was really wrapped around how can I understand all the",
    "start": "2280150",
    "end": "2286359"
  },
  {
    "text": "people in my organization that maybe didn't get here through the registration product yeah so you know at this point",
    "start": "2286359",
    "end": "2292599"
  },
  {
    "text": "we already had that elasticsearch cluster so we were just using him structure we already had so from an operational standpoint this was easy for",
    "start": "2292599",
    "end": "2298720"
  },
  {
    "text": "us because all we need to do was provision a new index and then we were good to go really got us off the ground quick and got us moving in the right",
    "start": "2298720",
    "end": "2305829"
  },
  {
    "start": "2305000",
    "end": "2405000"
  },
  {
    "text": "direction why it failed epically is is it sort of impossible to re index one",
    "start": "2305829",
    "end": "2312730"
  },
  {
    "text": "index effectively right so there's no way to do this without downtime just because of the like the application",
    "start": "2312730",
    "end": "2320170"
  },
  {
    "text": "design we were always focused on just using that specific index so what we'd have to do - re indexes we'd have to take the whole thing down and then",
    "start": "2320170",
    "end": "2325569"
  },
  {
    "text": "rebuild it again the mappings were effectively permanent right so like when you're using dynamic mappings it's",
    "start": "2325569",
    "end": "2331690"
  },
  {
    "text": "difficult for you to do anything play with those mappings once they're in there they're there you can't do anything about it it's just very",
    "start": "2331690",
    "end": "2337720"
  },
  {
    "text": "resistant to change we didn't have very many options about how to experiment with this product and really build it",
    "start": "2337720",
    "end": "2343630"
  },
  {
    "text": "out in a way that we wanted to be successful and so that that's really the theme of this journey is like we had to",
    "start": "2343630",
    "end": "2350019"
  },
  {
    "text": "figure out ways to find things that were changeable and really finding ways to",
    "start": "2350019",
    "end": "2356130"
  },
  {
    "text": "affect only a small percentage or maybe in a single organization and be able to",
    "start": "2356130",
    "end": "2361480"
  },
  {
    "text": "experiment on on that organization to understand what the right way to do this was so eventually this sort of just fell",
    "start": "2361480",
    "end": "2366940"
  },
  {
    "text": "over we had about ten organizations I think before it fell over which isn't very many the data was just constantly",
    "start": "2366940",
    "end": "2373779"
  },
  {
    "text": "sinking so there's a lot of data changing frequently we have you can imagine a large sports organizations got",
    "start": "2373779",
    "end": "2379140"
  },
  {
    "text": "thousands of athletes and during a busy registration season so let's say it's",
    "start": "2379140",
    "end": "2384279"
  },
  {
    "text": "it's hockey season and so we're in in the month of September everybody's trying to get there children enrolled in hockey it's all",
    "start": "2384279",
    "end": "2391000"
  },
  {
    "text": "happening at the same time so we're getting lots and lots of rights all happening at the same time and so it was just too much data syncing against a",
    "start": "2391000",
    "end": "2397960"
  },
  {
    "text": "single index because it that that data inserting was affecting everyone throughout that was involved in this",
    "start": "2397960",
    "end": "2404470"
  },
  {
    "text": "sort of beta yeah that was mostly due to our usage of it the active record pattern was regenerating the entire",
    "start": "2404470",
    "end": "2409570"
  },
  {
    "text": "person persona document at the time of a change which just wasn't an efficient way to write software but regardless you",
    "start": "2409570",
    "end": "2416770"
  },
  {
    "text": "know we stepped up and we decided to tackle this and my first thought was well if we can't make any changes when",
    "start": "2416770",
    "end": "2421900"
  },
  {
    "text": "we have one index for everybody let's put every single tenant in their own index what could possibly go wrong here",
    "start": "2421900",
    "end": "2426970"
  },
  {
    "text": "right what we did was we decided since each organizations had different registration questions and we're running",
    "start": "2426970",
    "end": "2432670"
  },
  {
    "text": "different registrations collecting different a different people that'll be easy because then we can just have one one tenant port per index with their own",
    "start": "2432670",
    "end": "2440590"
  },
  {
    "text": "mapping so as John touched on the mapping is how elasticsearch understands",
    "start": "2440590",
    "end": "2445690"
  },
  {
    "text": "your data it's the schema for your your elasticsearch data as it's being indexed so this was an easy way for us to",
    "start": "2445690",
    "end": "2451450"
  },
  {
    "text": "abstract that between our tenants which was great at this time we also added support for most multiple clusters the goal here was like let's just get this",
    "start": "2451450",
    "end": "2457540"
  },
  {
    "text": "out fast so money's cheap times expensive let's roll this thing out the door we were using elastic search",
    "start": "2457540",
    "end": "2464880"
  },
  {
    "text": "supports this technology called a index aliasing which lets you actually create",
    "start": "2464880",
    "end": "2470050"
  },
  {
    "text": "one index alias and point to different indices and using their update alias API to change between it and that is what",
    "start": "2470050",
    "end": "2475930"
  },
  {
    "text": "gave us the ability to do zero down timely indexing which I'll talk about in a little bit that was the really big",
    "start": "2475930",
    "end": "2481090"
  },
  {
    "text": "gain from this aeration and so at this point we also added support for multiple clusters so we added a second cluster",
    "start": "2481090",
    "end": "2486430"
  },
  {
    "text": "this gives us even more options along with index aliasing we actually had to build the business logic within our like",
    "start": "2486430",
    "end": "2492670"
  },
  {
    "text": "application about where that index lived and what was the name of that index and all that so why did this fail epically",
    "start": "2492670",
    "end": "2501190"
  },
  {
    "start": "2498000",
    "end": "2568000"
  },
  {
    "text": "I think from listening to John earlier you probably understand that whenever you get upwards of a thousand two",
    "start": "2501190",
    "end": "2509350"
  },
  {
    "text": "thousand ten thousand four thousand like shards we start to have a problem in",
    "start": "2509350",
    "end": "2515020"
  },
  {
    "text": "this case it was actually more about the number of indexes and the the creating of indexes actually",
    "start": "2515020",
    "end": "2522450"
  },
  {
    "text": "triggers cluster events and cluster events are only processed by the master node so in elasticsearch highly",
    "start": "2522450",
    "end": "2528719"
  },
  {
    "text": "recommend you have prot like dedicated master nodes right in that situation",
    "start": "2528719",
    "end": "2534450"
  },
  {
    "text": "only one of them is actually doing work and so you have this resource of constraint of the amount of CPU that you",
    "start": "2534450",
    "end": "2540210"
  },
  {
    "text": "can get these sort of cluster events to complete is just limited to that one instance that you're running and so",
    "start": "2540210",
    "end": "2546029"
  },
  {
    "text": "while the mappings were being updated and waiting on these cluster events to complete you can't write any data to the data nodes that are using that index so",
    "start": "2546029",
    "end": "2553319"
  },
  {
    "text": "it's basically just in this constant state of change that that allowed us that did not allow us to continue to",
    "start": "2553319",
    "end": "2559109"
  },
  {
    "text": "update data and so that was sort of a significant problem major failure point yeah let's take a little bit closer look",
    "start": "2559109",
    "end": "2565769"
  },
  {
    "text": "on what this data looks like inside of elasticsearch on the Left what you're seeing is the persona document in this",
    "start": "2565769",
    "end": "2570930"
  },
  {
    "start": "2568000",
    "end": "2639000"
  },
  {
    "text": "case it's my information on the right is the mapping that's the schema again how elasticsearch understands your information so my document has a sub",
    "start": "2570930",
    "end": "2579599"
  },
  {
    "text": "document called answers which are all these answers on a registration session it's part of what's called a nested document so I have first name for this",
    "start": "2579599",
    "end": "2585989"
  },
  {
    "text": "one was AJ last name Steven burg there's my email and this kind of long unintelligible string you see is the",
    "start": "2585989",
    "end": "2592289"
  },
  {
    "text": "identifier of the question element that I answered in this case I had two decimal type questions right and I answered 10.5 and another 1.0 so the",
    "start": "2592289",
    "end": "2601289"
  },
  {
    "text": "mapping on the mapping file is understood as okay so they have a first name question I need to have a first",
    "start": "2601289",
    "end": "2606690"
  },
  {
    "text": "name mapping they have a last name question okay that's a string two emails also a string this question elements a",
    "start": "2606690",
    "end": "2612059"
  },
  {
    "text": "decimal etc etc so for those of you who have follow along with our you know explosion of mappings you can see how if",
    "start": "2612059",
    "end": "2617160"
  },
  {
    "text": "I add a new registration and say I ask a thousand questions suddenly I have 1,000 new mapping inserts to perform when I",
    "start": "2617160",
    "end": "2624900"
  },
  {
    "text": "index this data and eventually with our largest customer customers indexes were flying around with a hundred thousand",
    "start": "2624900",
    "end": "2630930"
  },
  {
    "text": "fields which that amount of state to maintain for the entire cluster is what caused this huge number of cluster",
    "start": "2630930",
    "end": "2636599"
  },
  {
    "text": "events in this explosion so we had this idea of course like how can we prevent",
    "start": "2636599",
    "end": "2643559"
  },
  {
    "start": "2639000",
    "end": "2701000"
  },
  {
    "text": "this from blowing up on a phone call with John he highly encouraged us to find a way to model our dynamic data in",
    "start": "2643559",
    "end": "2649440"
  },
  {
    "text": "a way that is mapped statically so we spent some time scratching our heads anything about it and what we did was we reduced",
    "start": "2649440",
    "end": "2654450"
  },
  {
    "text": "our mappings to the generic types of the questions we allowed customers to ask this is a key understanding here when I",
    "start": "2654450",
    "end": "2660420"
  },
  {
    "text": "add a new question to a registration instead of adding a new mapping what I'm actually doing is adding a new part of a",
    "start": "2660420",
    "end": "2665880"
  },
  {
    "text": "sub document that includes the type of the question and and that results down to one of my last exertion types then",
    "start": "2665880",
    "end": "2673349"
  },
  {
    "text": "what we did was we would use an and query or a must match query to say what I want to find the answer to this",
    "start": "2673349",
    "end": "2678839"
  },
  {
    "text": "question from this person what I'll do is I'll say okay it has to map the key for this specific question which could",
    "start": "2678839",
    "end": "2684720"
  },
  {
    "text": "be qul one two three four five or first name and the value to that answer must be AJ for example this allowed us to",
    "start": "2684720",
    "end": "2692430"
  },
  {
    "text": "only use the insert mapping API to add new mappings when we were doing new development or working on new features and we were able to avoid dynamic",
    "start": "2692430",
    "end": "2699359"
  },
  {
    "text": "mapping entirely so let's take a look what that actually looks like in our in our cluster at this point you can see",
    "start": "2699359",
    "end": "2705599"
  },
  {
    "text": "that the the document is holding pairs of information right instead of having the the field be the name of the",
    "start": "2705599",
    "end": "2712499"
  },
  {
    "text": "question element and the value being the answer what I have is a field named key which is you can see from the right a",
    "start": "2712499",
    "end": "2718289"
  },
  {
    "text": "keyword as John explained that must be match entirely we were doing that in our middleware layer in code and then under",
    "start": "2718289",
    "end": "2724380"
  },
  {
    "text": "that is the string value so when a query would come in for find everyone whose document matches first-name AJ all you",
    "start": "2724380",
    "end": "2730470"
  },
  {
    "text": "would do is split out the first-name and go and find okay find any part of this document where the key is first-name",
    "start": "2730470",
    "end": "2737009"
  },
  {
    "text": "string and we know that the string value then must be AJ and then return that document if it matches so as you see",
    "start": "2737009",
    "end": "2743730"
  },
  {
    "text": "here for those two decimals or the the one decimal on this slide we only need one entry for decimal value in the",
    "start": "2743730",
    "end": "2749519"
  },
  {
    "text": "mapping file even though I might ask a decimal question a hundred times on our registration so every time a new question gets answered we are no longer",
    "start": "2749519",
    "end": "2756450"
  },
  {
    "text": "adding new mappings what we're actually doing is just adding new documents to this nested document right so we were",
    "start": "2756450",
    "end": "2764730"
  },
  {
    "text": "pretty excited about the static mapping break through we were fairly confident that this was gonna make a big impact",
    "start": "2764730",
    "end": "2769859"
  },
  {
    "text": "and we were maybe a little too overconfident because as soon as the product manager heard that we thought we",
    "start": "2769859",
    "end": "2775079"
  },
  {
    "start": "2770000",
    "end": "2790000"
  },
  {
    "text": "had solved all our problems they're like great let's roll it out everywhere I think we had about a hundred organizations yeah using using the",
    "start": "2775079",
    "end": "2781410"
  },
  {
    "text": "product at the time and so we were you know pretty excited to see what happens as we start to roll out two more organizations and and we",
    "start": "2781410",
    "end": "2788749"
  },
  {
    "text": "felt pretty good so we did that we did that and then everything sort of fell apart so what's what's going on these",
    "start": "2788749",
    "end": "2796130"
  },
  {
    "start": "2790000",
    "end": "2917000"
  },
  {
    "text": "graphs here is so that the top-right graph over here is the it's it's the",
    "start": "2796130",
    "end": "2804289"
  },
  {
    "text": "cluster health so cluster help is an important thing to monitor with an",
    "start": "2804289",
    "end": "2809450"
  },
  {
    "text": "elastic search when it's not green that's bad so there's a green yellow",
    "start": "2809450",
    "end": "2814849"
  },
  {
    "text": "which means that you have unassigned shards and those shards need to move around and be flush to disk when it's",
    "start": "2814849",
    "end": "2822170"
  },
  {
    "text": "red it means that you have failed charts failed charts are very bad that that's a there's a little blip there that you can",
    "start": "2822170",
    "end": "2828769"
  },
  {
    "text": "see where we had some red shards and had to completely rebuild the index to get those shards working again the graph",
    "start": "2828769",
    "end": "2835160"
  },
  {
    "text": "directly below that is the unassigned shards so you'll you'll notice that as the as the cluster health changed to",
    "start": "2835160",
    "end": "2840619"
  },
  {
    "text": "orange which was actually yellow we it",
    "start": "2840619",
    "end": "2845779"
  },
  {
    "text": "was all of these unassigned charts and these these shards never got fully assigned throughout this whole process they were just sitting in this unassigned State eventually they would",
    "start": "2845779",
    "end": "2852680"
  },
  {
    "text": "write some of them and then we get more that would become on a unassigned the last the last graph there is the thread",
    "start": "2852680",
    "end": "2861499"
  },
  {
    "text": "pool snapshot queue so we were trying to do to snapshot out all these indexes so",
    "start": "2861499",
    "end": "2867470"
  },
  {
    "text": "index staff shotting is a useful tool it allows you to recreate an index from an",
    "start": "2867470",
    "end": "2872749"
  },
  {
    "text": "existing state build it put it into a new cluster or whatever you want to do with it and so there's automated snapshots that",
    "start": "2872749",
    "end": "2879769"
  },
  {
    "text": "happen as part of the Amazon Elastic search service it's very useful you snapshot a cluster turn it off you",
    "start": "2879769",
    "end": "2884779"
  },
  {
    "text": "can boot it back up again from a snapshot it's pretty great but there's a bug in elasticsearch 5 that whenever you",
    "start": "2884779",
    "end": "2893480"
  },
  {
    "text": "have so many shards snapshots can't complete effectively and so we had a",
    "start": "2893480",
    "end": "2900380"
  },
  {
    "text": "snapshot that ran for over a day before actually completed and so you'll see all",
    "start": "2900380",
    "end": "2905630"
  },
  {
    "text": "of the pending tasks there so those pinning casts are like a signing char are just two nodes basically as well as",
    "start": "2905630",
    "end": "2912140"
  },
  {
    "text": "so the the the snapshot was actually preventing those shards from getting assigned so that was fun",
    "start": "2912140",
    "end": "2917839"
  },
  {
    "start": "2917000",
    "end": "2951000"
  },
  {
    "text": "so why did it fail epic Phil definitely because we had 40,000 shards across two clusters cost went",
    "start": "2917839",
    "end": "2924609"
  },
  {
    "text": "through the roof so the the the only solution when you're in this state effectively is to add as many nodes as",
    "start": "2924609",
    "end": "2929859"
  },
  {
    "text": "you can to get enough resources to get things under control",
    "start": "2929859",
    "end": "2934990"
  },
  {
    "text": "so we said earlier that money is cheap and time is expensive money isn't that",
    "start": "2934990",
    "end": "2940089"
  },
  {
    "text": "cheap and so you can't solve every problem with it and then that bug in es5",
    "start": "2940089",
    "end": "2945390"
  },
  {
    "text": "is was a significant problem for us it eventually it eventually resolved and we",
    "start": "2945390",
    "end": "2950680"
  },
  {
    "text": "were able to move on so once again back to the architectural drawing board the",
    "start": "2950680",
    "end": "2956349"
  },
  {
    "start": "2951000",
    "end": "3179000"
  },
  {
    "text": "real kicker is that we actually again had another phone call of John and we knew we had to get to this place where we had some indices in or some tenants",
    "start": "2956349",
    "end": "2963190"
  },
  {
    "text": "in the same index as other tenants right we had to get to this point we had combined indices is what we called them",
    "start": "2963190",
    "end": "2968619"
  },
  {
    "text": "we had that solution basically all ready to rock about a week before this critical incident everything went bad so it was a real timing timing bummer but",
    "start": "2968619",
    "end": "2976300"
  },
  {
    "text": "we ended up going with this architecture pattern so what you see here are a couple of clusters and inside each",
    "start": "2976300",
    "end": "2982180"
  },
  {
    "text": "cluster is one or two indexes for example index one just has one tenant index two may have 30 we really needed",
    "start": "2982180",
    "end": "2989020"
  },
  {
    "text": "to go to this architecture because we do have several enterprise level clients that have far different demands right they might have 50 60 people logging in",
    "start": "2989020",
    "end": "2996190"
  },
  {
    "text": "to do rostering during a really large tournament and they're gonna be writing a lot of queries and updating data very",
    "start": "2996190",
    "end": "3001920"
  },
  {
    "text": "quickly and that sort of thing kind of demands its own index we also have beta customers that are going to be trying",
    "start": "3001920",
    "end": "3007140"
  },
  {
    "text": "new features new mappings and tools builds on top of this platform they're gonna need to be rebuilt more frequently as we're adding and changing mappings",
    "start": "3007140",
    "end": "3013290"
  },
  {
    "text": "around so you need to have support to still have one index for your larger your special tenants but you also need a",
    "start": "3013290",
    "end": "3019020"
  },
  {
    "text": "way for those free trial people to be able to use your application without it costing you too much money and that's where this combined index thing comes in",
    "start": "3019020",
    "end": "3025740"
  },
  {
    "text": "so at this point we had the ability to do both and do both really effectively",
    "start": "3025740",
    "end": "3031920"
  },
  {
    "text": "we additionally in an area in addition to supporting multiple tenants per index we also developed a Bluegreen deployment",
    "start": "3031920",
    "end": "3038760"
  },
  {
    "text": "that could move organizations across indices and across clusters so if we knew that one cluster was in a bad state",
    "start": "3038760",
    "end": "3044849"
  },
  {
    "text": "or during this incident right we were able to roll people off of one unhealthy cluster to a new healthy cluster where",
    "start": "3044849",
    "end": "3050609"
  },
  {
    "text": "rights and everything we're working and reasonable working and they could actually use their data we're",
    "start": "3050609",
    "end": "3055789"
  },
  {
    "text": "gonna talk about that in a little bit so we did add a third cluster and summary",
    "start": "3055789",
    "end": "3061910"
  },
  {
    "text": "sort of our goal with adding a third cluster was was to effectively start clean and we started this Bluegreen",
    "start": "3061910",
    "end": "3067609"
  },
  {
    "text": "deployment process of just moving some of our largest indexes or our largest",
    "start": "3067609",
    "end": "3074089"
  },
  {
    "text": "customers off on to their own cluster in this new format and then starting to combine those indices along the way and",
    "start": "3074089",
    "end": "3080930"
  },
  {
    "text": "then we when we did that we you know massively shrunk the shard count so you",
    "start": "3080930",
    "end": "3086180"
  },
  {
    "text": "can imagine the moment you add a thousand organizations to a single index you cut down you know humongous amounts",
    "start": "3086180",
    "end": "3092720"
  },
  {
    "text": "of shards super quick so what does it look like when you want to build zero downtime we indexing in a SAS product",
    "start": "3092720",
    "end": "3099440"
  },
  {
    "text": "with multi-tenancy what we're looking at here is two different cases on the bottom we've got a right case in a ring",
    "start": "3099440",
    "end": "3105470"
  },
  {
    "text": "case and on the top is sort of an infrastructure slash architecture diagram so because we are using a",
    "start": "3105470",
    "end": "3111799"
  },
  {
    "text": "multiple cluster deployment we had to model our tenant assignment in some place other than elasticsearch so at",
    "start": "3111799",
    "end": "3117440"
  },
  {
    "text": "this point we were no longer really using the index aliasing blueberry indexing instead what we were using was this small table it has a tenant ID it",
    "start": "3117440",
    "end": "3123710"
  },
  {
    "text": "has a destination index name it has where the which cluster this index lives so the applications know where to go to",
    "start": "3123710",
    "end": "3129440"
  },
  {
    "text": "the cluster to find the index to find the data and it has this boolean that's called locked so when we need to rebuild",
    "start": "3129440",
    "end": "3135140"
  },
  {
    "text": "an index or move a customer across clusters are across the indices what we first do is set this boolean locked to",
    "start": "3135140",
    "end": "3142190"
  },
  {
    "text": "true at this point rights are disabled so we might have rights coming in from 7",
    "start": "3142190",
    "end": "3147289"
  },
  {
    "text": "8 9 different applications generally the patterns to do this in a background job at this point what would happen is the",
    "start": "3147289",
    "end": "3152900"
  },
  {
    "text": "sq sq or worker would pick up this message of SQS try to index some new data and the API would come back and say",
    "start": "3152900",
    "end": "3159890"
  },
  {
    "text": "ah this index is locked you're going to have to wait so we would exponentially back off in a retry now for a user they",
    "start": "3159890",
    "end": "3166069"
  },
  {
    "text": "still need to search their data even if it's a few minutes out of sync so all read operations are still going to this",
    "start": "3166069",
    "end": "3171079"
  },
  {
    "text": "index that we're about to replace at this next stage what we're doing here is",
    "start": "3171079",
    "end": "3177579"
  },
  {
    "text": "we're observing what we're doing here is we've kicked off a job that will create",
    "start": "3177579",
    "end": "3183890"
  },
  {
    "text": "a new slot or a new new destination for this data sometimes it's a brand new index other times it's",
    "start": "3183890",
    "end": "3189380"
  },
  {
    "text": "an existing index with other tenants in it and other times again it's a brand new cluster and a brand new index and that job will go off and it will ping",
    "start": "3189380",
    "end": "3195530"
  },
  {
    "text": "all these other services it'll say ok I need all these people I need the team's information needs stats I need the registration data it aggregates this at",
    "start": "3195530",
    "end": "3202370"
  },
  {
    "text": "an application level and then it uses the bulkinsert API to insert this data into elasticsearch at this point it's",
    "start": "3202370",
    "end": "3208220"
  },
  {
    "text": "important to remember right so the previous index are still disabled so if data changes we haven't actually lost anything yet after that initial job of",
    "start": "3208220",
    "end": "3216800"
  },
  {
    "text": "rebuilding the clients index has been complete what we do is we update the index alias in the cluster assignments",
    "start": "3216800",
    "end": "3222440"
  },
  {
    "text": "table pointing to the new index or the new cluster here I've moved tenant 1 to",
    "start": "3222440",
    "end": "3227660"
  },
  {
    "text": "index 5 on cluster 1 and what I do is I simply unlock the index so once once the",
    "start": "3227660",
    "end": "3233570"
  },
  {
    "text": "index is unlocked in this table all of those rights are able to flush through a process and at this time again the the",
    "start": "3233570",
    "end": "3241130"
  },
  {
    "text": "user who's doing reads is now hitting the brand new index with the brand new data potentially new mappings or new",
    "start": "3241130",
    "end": "3246710"
  },
  {
    "text": "ways to understand the organization so success so you know as you can see we",
    "start": "3246710",
    "end": "3253520"
  },
  {
    "start": "3249000",
    "end": "3323000"
  },
  {
    "text": "went through you know four different iterations on how to how to actually do this how to create a product that would",
    "start": "3253520",
    "end": "3259610"
  },
  {
    "text": "be successful we got to the point where we fully rolled this out to all 20,000 of our organizations they're loving this",
    "start": "3259610",
    "end": "3266390"
  },
  {
    "text": "new product that they get it's it's you know all new features and really providing them that's the customer",
    "start": "3266390",
    "end": "3272320"
  },
  {
    "text": "relationship management thing that they're trying to go after I'm happy because my clusters not falling over and",
    "start": "3272320",
    "end": "3278840"
  },
  {
    "text": "I'm not getting paged at 3:00 in the morning or whatever it is I'm happy because Andy's happy exactly and we",
    "start": "3278840",
    "end": "3284660"
  },
  {
    "text": "actually ended up and so once we got to this state reducing that shard count significantly and getting down to just",
    "start": "3284660",
    "end": "3291650"
  },
  {
    "text": "50 indices we only needed one cluster so we have all of this like application logic built in that allows us to be able",
    "start": "3291650",
    "end": "3299000"
  },
  {
    "text": "to move things around and reassign into indexes and and you know combine it two",
    "start": "3299000",
    "end": "3305060"
  },
  {
    "text": "indexes together and all this stuff we have all these great things built into our application but now we're on a small cluster in a pretty stable State we've",
    "start": "3305060",
    "end": "3313160"
  },
  {
    "text": "got 260 million documents into that cluster and and the data is already at a",
    "start": "3313160",
    "end": "3318780"
  },
  {
    "text": "terabyte and a half and it's continuing to grow every day every time a new athlete gets registered onto our platform so let's take a quick look at",
    "start": "3318780",
    "end": "3325290"
  },
  {
    "start": "3323000",
    "end": "3504000"
  },
  {
    "text": "the architectural recommendations we made over the course of this talk the very first one is use more than one index but don't use too many indices you",
    "start": "3325290",
    "end": "3332220"
  },
  {
    "text": "need to build this into your application logic so your application understands that you're going to be moving people",
    "start": "3332220",
    "end": "3337380"
  },
  {
    "text": "around that's really important the next thing is make sure you're using static mappings it's worth the time to",
    "start": "3337380",
    "end": "3342990"
  },
  {
    "text": "understand your data and develop some sort of structured way to represent all of your dynamic data that your customers",
    "start": "3342990",
    "end": "3349230"
  },
  {
    "text": "may be using if you're scaling your mappings linearly you're gonna have a bad time if you're like us and you're",
    "start": "3349230",
    "end": "3354930"
  },
  {
    "text": "scaling and exponentially the bad time is gonna happen earlier additionally into that one one really great way to do",
    "start": "3354930",
    "end": "3361950"
  },
  {
    "text": "zero downtime or indexing is just to build an application level support for the blue-green nixing using aliases if",
    "start": "3361950",
    "end": "3370680"
  },
  {
    "text": "you do need to support a multiple clusters scenario which does make things like upgrades and testing new features",
    "start": "3370680",
    "end": "3376650"
  },
  {
    "text": "inside of Alaska starts really easy you're gonna need to model that elsewhere finally definitely leverage the Amazon",
    "start": "3376650",
    "end": "3383760"
  },
  {
    "text": "Elastic search service to scale when you need to add write capacity capacity yeah exactly so for for write capacity just",
    "start": "3383760",
    "end": "3390930"
  },
  {
    "text": "adding more data notes will give you more write throughput for for recap acity additional replica shards just",
    "start": "3390930",
    "end": "3397589"
  },
  {
    "text": "straight-up gives you more read throughput and so the one of the big",
    "start": "3397589",
    "end": "3403470"
  },
  {
    "text": "recommendations as a distributed systems nerd I want to tell you is always use three dedicated master nodes and the",
    "start": "3403470",
    "end": "3410640"
  },
  {
    "text": "reason for that is if you're if you're putting your master election on your data nodes any resource utilization",
    "start": "3410640",
    "end": "3416579"
  },
  {
    "text": "problems that are impacting those data no it's good effect your leader election and that's not a good thing",
    "start": "3416579",
    "end": "3422160"
  },
  {
    "text": "leader leader election problems are bad don't never use two master nodes because then they'll both think that their",
    "start": "3422160",
    "end": "3427950"
  },
  {
    "text": "master node don't do that that's also bad and having one is bad because if it dies then your cluster is dead so use",
    "start": "3427950",
    "end": "3434670"
  },
  {
    "text": "three master nodes consider investing in a multi cluster application support write like consider what it's like to",
    "start": "3434670",
    "end": "3442730"
  },
  {
    "text": "have the flexibility of okay we're gonna upgrade to a new version of elasticsearch I'm gonna spin up a whole",
    "start": "3442730",
    "end": "3448140"
  },
  {
    "text": "new cluster that is on new version of elasticsearch I'm gonna bring my first demo organization that I want to test out in production over to",
    "start": "3448140",
    "end": "3454800"
  },
  {
    "text": "that new version and kick the tires see what works are we getting the query performance that we expect are we getting all those things and it's just a",
    "start": "3454800",
    "end": "3461670"
  },
  {
    "text": "super useful tool for being able to experiment and understand the state of your cluster understand whether you're",
    "start": "3461670",
    "end": "3467850"
  },
  {
    "text": "getting the right value out of it or not yeah definitely treat your Amazon alhasan search service cluster as you",
    "start": "3467850",
    "end": "3473580"
  },
  {
    "text": "know cattle not pets it's something that we probably take through all the rest of our infrastructure and it very much applies here yeah yeah I mean really the",
    "start": "3473580",
    "end": "3480210"
  },
  {
    "text": "powers that you have an API that you can use to create new clusters if you wanted to right so you could go you could go",
    "start": "3480210",
    "end": "3485760"
  },
  {
    "text": "even more we didn't quite get that far I mean we're using things like terraform and Confirmation to like provision those",
    "start": "3485760",
    "end": "3491430"
  },
  {
    "text": "to that infrastructure but you can go even farther and use your application to provision a whole new cluster if you wanted to",
    "start": "3491430",
    "end": "3498410"
  },
  {
    "text": "[Applause]",
    "start": "3500140",
    "end": "3506659"
  }
]
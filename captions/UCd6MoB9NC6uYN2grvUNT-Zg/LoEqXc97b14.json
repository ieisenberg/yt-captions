[
  {
    "start": "0",
    "end": "18000"
  },
  {
    "text": "hello",
    "start": "80",
    "end": "1120"
  },
  {
    "text": "my name is saili jojin",
    "start": "1120",
    "end": "3199"
  },
  {
    "text": "i am a senior analytics specialist essay",
    "start": "3199",
    "end": "5520"
  },
  {
    "text": "at aws",
    "start": "5520",
    "end": "7359"
  },
  {
    "text": "in this video we will see how you can",
    "start": "7359",
    "end": "9760"
  },
  {
    "text": "configure error handling for registered",
    "start": "9760",
    "end": "12559"
  },
  {
    "text": "spectrum data",
    "start": "12559",
    "end": "14080"
  },
  {
    "text": "using the new user user-defined data",
    "start": "14080",
    "end": "16000"
  },
  {
    "text": "handling properties",
    "start": "16000",
    "end": "18960"
  },
  {
    "start": "18000",
    "end": "59000"
  },
  {
    "text": "wretched spectrum is a feature of amazon",
    "start": "18960",
    "end": "21520"
  },
  {
    "text": "redshift that allows users to query data",
    "start": "21520",
    "end": "24960"
  },
  {
    "text": "residing on s3",
    "start": "24960",
    "end": "27680"
  },
  {
    "text": "s3 datalake has the potential to store",
    "start": "27680",
    "end": "30240"
  },
  {
    "text": "exabytes of data",
    "start": "30240",
    "end": "31920"
  },
  {
    "text": "and with spectrum amazon redshift can",
    "start": "31920",
    "end": "34320"
  },
  {
    "text": "query it all",
    "start": "34320",
    "end": "36399"
  },
  {
    "text": "this enables enterprises to discover and",
    "start": "36399",
    "end": "39120"
  },
  {
    "text": "analyze their extended datasets",
    "start": "39120",
    "end": "42640"
  },
  {
    "text": "it is important to note that this",
    "start": "42640",
    "end": "44719"
  },
  {
    "text": "external data is queried in place",
    "start": "44719",
    "end": "47440"
  },
  {
    "text": "without having to load it into the",
    "start": "47440",
    "end": "49680"
  },
  {
    "text": "amazon redshift cluster",
    "start": "49680",
    "end": "53039"
  },
  {
    "text": "to access the s3 data you need to create",
    "start": "53120",
    "end": "55840"
  },
  {
    "text": "external tables on redshift database",
    "start": "55840",
    "end": "60000"
  },
  {
    "start": "59000",
    "end": "132000"
  },
  {
    "text": "previously on spectrum there was a",
    "start": "60000",
    "end": "62239"
  },
  {
    "text": "default behavior to manage external data",
    "start": "62239",
    "end": "65198"
  },
  {
    "text": "values with errors",
    "start": "65199",
    "end": "67119"
  },
  {
    "text": "for example spectrum would insert null",
    "start": "67119",
    "end": "69680"
  },
  {
    "text": "values for the fields that contained",
    "start": "69680",
    "end": "71840"
  },
  {
    "text": "invalid utf-8 characters",
    "start": "71840",
    "end": "74880"
  },
  {
    "text": "in order to successfully retrieve these",
    "start": "74880",
    "end": "77200"
  },
  {
    "text": "values in redshift spectrum customers",
    "start": "77200",
    "end": "79840"
  },
  {
    "text": "would transform these data files before",
    "start": "79840",
    "end": "82159"
  },
  {
    "text": "querying",
    "start": "82159",
    "end": "83600"
  },
  {
    "text": "driven by use cases that demand eld",
    "start": "83600",
    "end": "86320"
  },
  {
    "text": "approach and faster access to data",
    "start": "86320",
    "end": "89200"
  },
  {
    "text": "customers were looking for options to",
    "start": "89200",
    "end": "91360"
  },
  {
    "text": "set dynamic data handling configurations",
    "start": "91360",
    "end": "94000"
  },
  {
    "text": "on redshift spectrum",
    "start": "94000",
    "end": "96400"
  },
  {
    "text": "using the new user-defined data handling",
    "start": "96400",
    "end": "98960"
  },
  {
    "text": "properties you can now choose from",
    "start": "98960",
    "end": "101439"
  },
  {
    "text": "multiple options to determine how",
    "start": "101439",
    "end": "103840"
  },
  {
    "text": "spectrum should handle certain data",
    "start": "103840",
    "end": "105759"
  },
  {
    "text": "values",
    "start": "105759",
    "end": "107360"
  },
  {
    "text": "as of today you can manage invalid utf-8",
    "start": "107360",
    "end": "110560"
  },
  {
    "text": "characters surplus characters and",
    "start": "110560",
    "end": "113439"
  },
  {
    "text": "numeric overflow values",
    "start": "113439",
    "end": "116240"
  },
  {
    "text": "users can also choose to abort the query",
    "start": "116240",
    "end": "119040"
  },
  {
    "text": "if specific number of errors are",
    "start": "119040",
    "end": "121200"
  },
  {
    "text": "encountered with the source data",
    "start": "121200",
    "end": "124399"
  },
  {
    "text": "additionally svl spectrum scan error",
    "start": "124399",
    "end": "127680"
  },
  {
    "text": "system table will log the error details",
    "start": "127680",
    "end": "130959"
  },
  {
    "text": "for further troubleshooting",
    "start": "130959",
    "end": "133200"
  },
  {
    "start": "132000",
    "end": "291000"
  },
  {
    "text": "now let's see how you can configure",
    "start": "133200",
    "end": "135280"
  },
  {
    "text": "user-defined data handling properties on",
    "start": "135280",
    "end": "137599"
  },
  {
    "text": "external table",
    "start": "137599",
    "end": "139599"
  },
  {
    "text": "this is the redshift console where i",
    "start": "139599",
    "end": "141440"
  },
  {
    "text": "have a cluster launched",
    "start": "141440",
    "end": "143680"
  },
  {
    "text": "to connect and run queries on this",
    "start": "143680",
    "end": "145599"
  },
  {
    "text": "cluster we will use the new query editor",
    "start": "145599",
    "end": "147840"
  },
  {
    "text": "v2",
    "start": "147840",
    "end": "149599"
  },
  {
    "text": "i have created a database name demo in",
    "start": "149599",
    "end": "152160"
  },
  {
    "text": "which i will first create an external",
    "start": "152160",
    "end": "154160"
  },
  {
    "text": "schema named spectrumdemo using the sql",
    "start": "154160",
    "end": "157120"
  },
  {
    "text": "script as seen on screen",
    "start": "157120",
    "end": "160160"
  },
  {
    "text": "now i can create an external table but",
    "start": "160160",
    "end": "162560"
  },
  {
    "text": "before we do that let's take a look at",
    "start": "162560",
    "end": "165120"
  },
  {
    "text": "the source data file which i have",
    "start": "165120",
    "end": "166959"
  },
  {
    "text": "uploaded to amazon s3 bucket",
    "start": "166959",
    "end": "170800"
  },
  {
    "text": "as you can see the file contains values",
    "start": "170800",
    "end": "173120"
  },
  {
    "text": "with special characters",
    "start": "173120",
    "end": "175120"
  },
  {
    "text": "particularly note the two values between",
    "start": "175120",
    "end": "177360"
  },
  {
    "text": "ranks 90 and 100 for alice and club",
    "start": "177360",
    "end": "180319"
  },
  {
    "text": "america",
    "start": "180319",
    "end": "182800"
  },
  {
    "text": "now let's go ahead and create the",
    "start": "182800",
    "end": "184239"
  },
  {
    "text": "external table on top of this file with",
    "start": "184239",
    "end": "186560"
  },
  {
    "text": "designated data types and general",
    "start": "186560",
    "end": "188480"
  },
  {
    "text": "parameters",
    "start": "188480",
    "end": "190959"
  },
  {
    "text": "when i run a select query to read from",
    "start": "190959",
    "end": "193040"
  },
  {
    "text": "this external table i can see that",
    "start": "193040",
    "end": "195599"
  },
  {
    "text": "spectrum by default have displayed null",
    "start": "195599",
    "end": "197840"
  },
  {
    "text": "values here",
    "start": "197840",
    "end": "200319"
  },
  {
    "text": "now let's try the data handling",
    "start": "200319",
    "end": "202000"
  },
  {
    "text": "properties by modifying the table",
    "start": "202000",
    "end": "203840"
  },
  {
    "text": "definition",
    "start": "203840",
    "end": "205920"
  },
  {
    "text": "you can use the alt table command to",
    "start": "205920",
    "end": "208159"
  },
  {
    "text": "apply these properties if not specified",
    "start": "208159",
    "end": "210560"
  },
  {
    "text": "during table creation",
    "start": "210560",
    "end": "213280"
  },
  {
    "text": "we will see the outcome for all three",
    "start": "213280",
    "end": "215280"
  },
  {
    "text": "options starting with fail",
    "start": "215280",
    "end": "217680"
  },
  {
    "text": "in this case the query will fail when",
    "start": "217680",
    "end": "219840"
  },
  {
    "text": "spectrum encounters invalid characters",
    "start": "219840",
    "end": "222239"
  },
  {
    "text": "for this table",
    "start": "222239",
    "end": "224799"
  },
  {
    "text": "next if you want to eliminate rows with",
    "start": "224799",
    "end": "226959"
  },
  {
    "text": "invalid data you can choose the drop row",
    "start": "226959",
    "end": "229920"
  },
  {
    "text": "option",
    "start": "229920",
    "end": "231519"
  },
  {
    "text": "note the data cleansing enabled",
    "start": "231519",
    "end": "233280"
  },
  {
    "text": "parameter",
    "start": "233280",
    "end": "235120"
  },
  {
    "text": "this value enables the data handling",
    "start": "235120",
    "end": "237040"
  },
  {
    "text": "properties for the table if set to true",
    "start": "237040",
    "end": "240879"
  },
  {
    "text": "as we can see the two rows with invalid",
    "start": "240879",
    "end": "243599"
  },
  {
    "text": "characters have been dropped",
    "start": "243599",
    "end": "245599"
  },
  {
    "text": "we now have 9 instead of 11 rows in our",
    "start": "245599",
    "end": "248640"
  },
  {
    "text": "result set",
    "start": "248640",
    "end": "250560"
  },
  {
    "text": "in some cases you want to include the",
    "start": "250560",
    "end": "252879"
  },
  {
    "text": "invalid character fields but replace",
    "start": "252879",
    "end": "255519"
  },
  {
    "text": "with another character of your choice",
    "start": "255519",
    "end": "258239"
  },
  {
    "text": "you can use the replace option for same",
    "start": "258239",
    "end": "261680"
  },
  {
    "text": "here we are using the hash character",
    "start": "261680",
    "end": "265759"
  },
  {
    "text": "now when we run the query on external",
    "start": "265759",
    "end": "267680"
  },
  {
    "text": "table",
    "start": "267680",
    "end": "268479"
  },
  {
    "text": "we see that the invalid characters in",
    "start": "268479",
    "end": "271360"
  },
  {
    "text": "the table values are replaced by a hash",
    "start": "271360",
    "end": "275918"
  },
  {
    "text": "similarly you can configure these",
    "start": "276080",
    "end": "278080"
  },
  {
    "text": "options for handling surplus characters",
    "start": "278080",
    "end": "280320"
  },
  {
    "text": "and numeric overflow",
    "start": "280320",
    "end": "282880"
  },
  {
    "text": "please watch out our blog space for more",
    "start": "282880",
    "end": "285120"
  },
  {
    "text": "details on this feature i hope you found",
    "start": "285120",
    "end": "287680"
  },
  {
    "text": "this video helpful and thank you for",
    "start": "287680",
    "end": "289840"
  },
  {
    "text": "watching",
    "start": "289840",
    "end": "292840"
  }
]
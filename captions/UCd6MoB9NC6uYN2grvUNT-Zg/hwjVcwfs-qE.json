[
  {
    "text": "- Hello, everyone.",
    "start": "720",
    "end": "1560"
  },
  {
    "text": "My name is Arun Lakshmanan.",
    "start": "1560",
    "end": "2790"
  },
  {
    "text": "I'm a OpenSearch-focused\nanalytical specialist",
    "start": "2790",
    "end": "5190"
  },
  {
    "text": "at Amazon Web Services.",
    "start": "5190",
    "end": "7170"
  },
  {
    "text": "Today, we are going to\ntalk about the tools",
    "start": "7170",
    "end": "9120"
  },
  {
    "text": "that are available for\nus to transform the data",
    "start": "9120",
    "end": "11790"
  },
  {
    "text": "and analyze in OpenSearch.",
    "start": "11790",
    "end": "13520"
  },
  {
    "text": "Amazon OpenSearch service",
    "start": "14580",
    "end": "15720"
  },
  {
    "text": "is a fully managed\nservice that makes it easy",
    "start": "15720",
    "end": "17850"
  },
  {
    "text": "for you to deploy, operate,\nscale OpenSearch cluster.",
    "start": "17850",
    "end": "20970"
  },
  {
    "text": "It also supports 19 different versions",
    "start": "20970",
    "end": "22859"
  },
  {
    "text": "of legacy Elasticsearch\nclusters in the AWS cloud.",
    "start": "22860",
    "end": "26373"
  },
  {
    "text": "OpenSearch is a fully open\nsource community-driven",
    "start": "27253",
    "end": "31410"
  },
  {
    "text": "search and analytical suit derived",
    "start": "31410",
    "end": "33150"
  },
  {
    "text": "from the Elasticsearch\n7.10.2 and Kibana 7.10.2.",
    "start": "33150",
    "end": "38150"
  },
  {
    "text": "The OpenSearch project\nconsists of a search engine,",
    "start": "39210",
    "end": "41640"
  },
  {
    "text": "that's OpenSearch.",
    "start": "41640",
    "end": "42780"
  },
  {
    "text": "A visualization engine,\nthat's OpenSearch Dashboards.",
    "start": "42780",
    "end": "46050"
  },
  {
    "text": "As well as a set of tools,\nplugins and client libraries",
    "start": "46050",
    "end": "49440"
  },
  {
    "text": "that helps easy for you to\ninteract with OpenSearch cluster.",
    "start": "49440",
    "end": "52743"
  },
  {
    "text": "The basic interaction\nflow works in this way.",
    "start": "54300",
    "end": "56489"
  },
  {
    "text": "You have your source data that\ncomes from various sources",
    "start": "56490",
    "end": "60150"
  },
  {
    "text": "that gets converted to JSON\ndocuments by these tools",
    "start": "60150",
    "end": "63360"
  },
  {
    "text": "and it gets ingested\ninto OpenSearch cluster.",
    "start": "63360",
    "end": "66180"
  },
  {
    "text": "Once it is indexed, they\nbecome searchable instantly.",
    "start": "66180",
    "end": "69570"
  },
  {
    "text": "With the provider API clients\nand OpenSearch dashboard,",
    "start": "69570",
    "end": "72570"
  },
  {
    "text": "you can access the index data\nin the OpenSearch cluster.",
    "start": "72570",
    "end": "76113"
  },
  {
    "text": "So the data sources can\nbe like very deep of range",
    "start": "77226",
    "end": "80520"
  },
  {
    "text": "in different size and shapes.",
    "start": "80520",
    "end": "82229"
  },
  {
    "text": "Like the static resources\nlike your application data",
    "start": "82230",
    "end": "84840"
  },
  {
    "text": "from your web application microservices",
    "start": "84840",
    "end": "87590"
  },
  {
    "text": "or your business\napplication databases, etc.",
    "start": "87590",
    "end": "90450"
  },
  {
    "text": "Or it can be coming from a\nstreaming like your automotive",
    "start": "90450",
    "end": "94259"
  },
  {
    "text": "or home devices or manufacturing pipeline,",
    "start": "94260",
    "end": "97140"
  },
  {
    "text": "or it can be a simple application data",
    "start": "97140",
    "end": "99150"
  },
  {
    "text": "that sits in the databases.",
    "start": "99150",
    "end": "101253"
  },
  {
    "text": "You need transformation\nwhen you are sending",
    "start": "103020",
    "end": "105240"
  },
  {
    "text": "this data to OpenSearch cluster.",
    "start": "105240",
    "end": "106770"
  },
  {
    "text": "What you need transformation\nis basically the sources",
    "start": "106770",
    "end": "111030"
  },
  {
    "text": "can be verbose or noisy in nature.",
    "start": "111030",
    "end": "113760"
  },
  {
    "text": "You want to filter out the noises",
    "start": "113760",
    "end": "115800"
  },
  {
    "text": "and you want to ingest\nand analyze the data point",
    "start": "115800",
    "end": "118740"
  },
  {
    "text": "which matters to you the most.",
    "start": "118740",
    "end": "120780"
  },
  {
    "text": "Along the way, you might\nwant to enrich your data",
    "start": "120780",
    "end": "123600"
  },
  {
    "text": "by adding metadata like the instance name",
    "start": "123600",
    "end": "127020"
  },
  {
    "text": "from where it gets generated",
    "start": "127020",
    "end": "128489"
  },
  {
    "text": "or you can use tags that\ntag your environment name",
    "start": "128490",
    "end": "132210"
  },
  {
    "text": "or application name,\nor you might want to do",
    "start": "132210",
    "end": "134400"
  },
  {
    "text": "some kind of computation or simply,",
    "start": "134400",
    "end": "137189"
  },
  {
    "text": "you want to enrich your data",
    "start": "137190",
    "end": "139080"
  },
  {
    "text": "with a third-party system,\nlike adding a geo information",
    "start": "139080",
    "end": "142620"
  },
  {
    "text": "to the IP address for\nyour access logs, etc.",
    "start": "142620",
    "end": "145562"
  },
  {
    "text": "So one option is to Data Prepper.",
    "start": "147330",
    "end": "150232"
  },
  {
    "text": "Data Prepper comes from\nOpenSearch project.",
    "start": "150232",
    "end": "154200"
  },
  {
    "text": "It helps you to simplify the collection",
    "start": "154200",
    "end": "157080"
  },
  {
    "text": "and analysis of logs, traces, and metrics.",
    "start": "157080",
    "end": "161070"
  },
  {
    "text": "It is a fully open source",
    "start": "161070",
    "end": "162930"
  },
  {
    "text": "with the Apache license version 2.0",
    "start": "162930",
    "end": "165700"
  },
  {
    "text": "Fluentd is one of the\npopular option in this tool.",
    "start": "166920",
    "end": "171308"
  },
  {
    "text": "Fluentd is a open source data collector.",
    "start": "171309",
    "end": "173370"
  },
  {
    "text": "It is a high performance and\nit has built-in resilience.",
    "start": "173370",
    "end": "175950"
  },
  {
    "text": "It can handle buffer in the\nmemory or in the file system.",
    "start": "175950",
    "end": "180120"
  },
  {
    "text": "Since it is written in a plugin ecosystem,",
    "start": "180120",
    "end": "182370"
  },
  {
    "text": "the community has like over 1,000 plugins",
    "start": "182370",
    "end": "184769"
  },
  {
    "text": "that are available for\nus to transform our data.",
    "start": "184770",
    "end": "187173"
  },
  {
    "text": "It also supports streaming at the edge.",
    "start": "188160",
    "end": "190980"
  },
  {
    "text": "It uses common SQL language process",
    "start": "190980",
    "end": "194430"
  },
  {
    "text": "to access the stream of logs.",
    "start": "194430",
    "end": "196982"
  },
  {
    "text": "If you have a strict memory requirements,",
    "start": "198450",
    "end": "202260"
  },
  {
    "text": "you can consider Fluent Bit.",
    "start": "202260",
    "end": "204090"
  },
  {
    "text": "Fluent Bit and Fluentd\nshare the same concepts",
    "start": "204090",
    "end": "207269"
  },
  {
    "text": "except the fact it's written in C.",
    "start": "207270",
    "end": "209100"
  },
  {
    "text": "It is very suitable to\ndeploy and collect the logs",
    "start": "209100",
    "end": "212460"
  },
  {
    "text": "and metrics from the Kubernetes cluster.",
    "start": "212460",
    "end": "214460"
  },
  {
    "text": "You can forward the logs from Fluent Bit",
    "start": "216390",
    "end": "219660"
  },
  {
    "text": "to Fluentd to process in a scale way.",
    "start": "219660",
    "end": "222900"
  },
  {
    "text": "It also has SQL streaming\nprocess that helps you",
    "start": "222900",
    "end": "226409"
  },
  {
    "text": "do streaming at the edge.",
    "start": "226410",
    "end": "227763"
  },
  {
    "text": "The other popular option is Logstash",
    "start": "230580",
    "end": "233280"
  },
  {
    "text": "which is popular for a very long time.",
    "start": "233280",
    "end": "235413"
  },
  {
    "text": "You can construct a complex transformation",
    "start": "236280",
    "end": "240510"
  },
  {
    "text": "like you can filter, you can\ndrop, you can add metadata.",
    "start": "240510",
    "end": "245159"
  },
  {
    "text": "All of them you can do with Logstash.",
    "start": "245160",
    "end": "247010"
  },
  {
    "text": "It also supports out-of-the-box",
    "start": "247890",
    "end": "251010"
  },
  {
    "text": "but most common log\ntypes like Apache common",
    "start": "251010",
    "end": "253769"
  },
  {
    "text": "or error logs or combined\nlogs or NGINX logs",
    "start": "253770",
    "end": "257070"
  },
  {
    "text": "and it handles the batch as well.",
    "start": "257070",
    "end": "259533"
  },
  {
    "text": "The one common con of this architecture",
    "start": "260400",
    "end": "264419"
  },
  {
    "text": "is you might need to run\nthis in the own hardware.",
    "start": "264420",
    "end": "268713"
  },
  {
    "text": "You can also use a Lambda,\nwhich is a serverless",
    "start": "270630",
    "end": "273780"
  },
  {
    "text": "native AWS solution.",
    "start": "273780",
    "end": "275790"
  },
  {
    "text": "That's a big benefit over Logstash.",
    "start": "275790",
    "end": "278460"
  },
  {
    "text": "You don't really have to manage.",
    "start": "278460",
    "end": "280270"
  },
  {
    "text": "It is serverless.",
    "start": "280270",
    "end": "282270"
  },
  {
    "text": "The biggest downside is that\nyou have to write everything",
    "start": "282270",
    "end": "285210"
  },
  {
    "text": "that Logstash is doing,",
    "start": "285210",
    "end": "286889"
  },
  {
    "text": "and you have to do everything in the code.",
    "start": "286890",
    "end": "289860"
  },
  {
    "text": "So that it could be significant challenge",
    "start": "289860",
    "end": "291479"
  },
  {
    "text": "especially for a complex log lines",
    "start": "291480",
    "end": "294030"
  },
  {
    "text": "and given that Logstash is a\ncomplex piece of technology",
    "start": "294030",
    "end": "297480"
  },
  {
    "text": "that is there a lot in Logstash.",
    "start": "297480",
    "end": "300270"
  },
  {
    "text": "And the other thing that\nI have already mentioned",
    "start": "300270",
    "end": "302430"
  },
  {
    "text": "is the concurrency.",
    "start": "302430",
    "end": "303723"
  },
  {
    "text": "It drive too much concurrency\nto the OpenSearch cluster.",
    "start": "305935",
    "end": "309507"
  },
  {
    "text": "And there is no built-in\nerror handling mechanism.",
    "start": "311010",
    "end": "313620"
  },
  {
    "text": "All you need to do is in the code.",
    "start": "313620",
    "end": "315990"
  },
  {
    "text": "You have to handle the errors.",
    "start": "315990",
    "end": "319050"
  },
  {
    "text": "The other option is to write a\ncustom code from the scratch.",
    "start": "319050",
    "end": "323879"
  },
  {
    "text": "If none of these tools\nare working for you,",
    "start": "323880",
    "end": "325890"
  },
  {
    "text": "probably you can write\na fully custom code.",
    "start": "325890",
    "end": "328440"
  },
  {
    "text": "Or if you have a data\ncollected in the streaming,",
    "start": "328440",
    "end": "331680"
  },
  {
    "text": "like MSK or Kinesis (indistinct) system.",
    "start": "331680",
    "end": "334473"
  },
  {
    "text": "You can use Amazon Glue",
    "start": "335465",
    "end": "336990"
  },
  {
    "text": "to process your data and\nsend it to OpenSearch.",
    "start": "336990",
    "end": "340067"
  },
  {
    "text": "Or you can use a Flink\nConnector for OpenSearch",
    "start": "340067",
    "end": "342974"
  },
  {
    "text": "or Kafka Connector for OpenSearch.",
    "start": "342974",
    "end": "345600"
  },
  {
    "text": "For some of these operations,\nyou can use a managed services",
    "start": "345600",
    "end": "349140"
  },
  {
    "text": "like Amazon Glue or MSK\nConnect to send data",
    "start": "349140",
    "end": "354140"
  },
  {
    "text": "from Kafka to OpenSearch.",
    "start": "354240",
    "end": "357488"
  },
  {
    "text": "The main con is you may need to write",
    "start": "357489",
    "end": "361260"
  },
  {
    "text": "a lot of complex code\nand manage on your own.",
    "start": "361260",
    "end": "364170"
  },
  {
    "text": "In this demo, I'm going to start",
    "start": "364170",
    "end": "365730"
  },
  {
    "text": "with a simple event processing",
    "start": "365730",
    "end": "367290"
  },
  {
    "text": "with Apache access log events.",
    "start": "367290",
    "end": "369240"
  },
  {
    "text": "Then enriching the log\nevents with geo information",
    "start": "369240",
    "end": "372479"
  },
  {
    "text": "the third, filtering out the\nevents and send the events",
    "start": "372480",
    "end": "375840"
  },
  {
    "text": "to two different\ndestinations in OpenSearch.",
    "start": "375840",
    "end": "378750"
  },
  {
    "text": "Finally, with streaming at the edge,",
    "start": "378750",
    "end": "381120"
  },
  {
    "text": "I will be aggregating the events",
    "start": "381120",
    "end": "383340"
  },
  {
    "text": "based on custom enriched\nattributes of the event into that.",
    "start": "383340",
    "end": "387962"
  },
  {
    "text": "Before we get into the\ndemo, let's take a look",
    "start": "389340",
    "end": "391440"
  },
  {
    "text": "at the structure of the\nFluent Bit data pipeline.",
    "start": "391440",
    "end": "394800"
  },
  {
    "text": "It has three major components.",
    "start": "394800",
    "end": "396870"
  },
  {
    "text": "One is input that are your sources.",
    "start": "396870",
    "end": "398790"
  },
  {
    "text": "Filter is basically for processing.",
    "start": "398790",
    "end": "400920"
  },
  {
    "text": "And then you can emit\nyour processed records",
    "start": "400920",
    "end": "404520"
  },
  {
    "text": "to multiple destinations.",
    "start": "404520",
    "end": "406440"
  },
  {
    "text": "Optionally, once it hits the storage tier",
    "start": "406440",
    "end": "408780"
  },
  {
    "text": "you can have an independent\nstream processes subsystem",
    "start": "408780",
    "end": "412200"
  },
  {
    "text": "which is a very powerful feature,",
    "start": "412200",
    "end": "413490"
  },
  {
    "text": "which we will see in the demo.",
    "start": "413490",
    "end": "414870"
  },
  {
    "text": "Where you can perform streaming operation",
    "start": "414870",
    "end": "417180"
  },
  {
    "text": "at the edge that will\ngreatly reduces the stress",
    "start": "417180",
    "end": "419550"
  },
  {
    "text": "on the backend system.",
    "start": "419550",
    "end": "420840"
  },
  {
    "text": "Which is open source in our case.",
    "start": "420840",
    "end": "422370"
  },
  {
    "text": "For this demo, I'm using\nAmazon Linux on EC2 instance.",
    "start": "422370",
    "end": "426180"
  },
  {
    "text": "I'm going to run the\nsingle line install command",
    "start": "426180",
    "end": "428220"
  },
  {
    "text": "on my EC2 to install full deck.",
    "start": "428220",
    "end": "430323"
  },
  {
    "text": "Now it gets installed.",
    "start": "432240",
    "end": "433470"
  },
  {
    "text": "Let's go to the demo directory.",
    "start": "433470",
    "end": "435020"
  },
  {
    "text": "Let's take a look at the sample file.",
    "start": "437430",
    "end": "439280"
  },
  {
    "text": "So this is the typical Apache access log",
    "start": "442110",
    "end": "445199"
  },
  {
    "text": "which we will be processing.",
    "start": "445200",
    "end": "446370"
  },
  {
    "text": "It has about 3,000 lines in it.",
    "start": "446370",
    "end": "448350"
  },
  {
    "text": "Fluent Bit comes with prebuilt parsers",
    "start": "448350",
    "end": "450780"
  },
  {
    "text": "for most common log patents",
    "start": "450780",
    "end": "453300"
  },
  {
    "text": "like Apache logs, header logs, and NGINX,",
    "start": "453300",
    "end": "455548"
  },
  {
    "text": "Kubernetes, MongoDB.",
    "start": "455549",
    "end": "457597"
  },
  {
    "text": "And you can write your own\nparts according to your data.",
    "start": "457597",
    "end": "461310"
  },
  {
    "text": "Let's take a look at the\nFluent Bit data pipeline.",
    "start": "461310",
    "end": "463110"
  },
  {
    "text": "So the first section is a service section",
    "start": "463110",
    "end": "464819"
  },
  {
    "text": "that's a service level configuration",
    "start": "464820",
    "end": "466930"
  },
  {
    "text": "where our parser files is.",
    "start": "468121",
    "end": "469830"
  },
  {
    "text": "And I have my input.",
    "start": "469830",
    "end": "472199"
  },
  {
    "text": "Input I'm tailing the sample\nlog file from the head.",
    "start": "472200",
    "end": "476073"
  },
  {
    "text": "And I'm filtering it with\nthe Apache to log parser.",
    "start": "477060",
    "end": "481983"
  },
  {
    "text": "And I'm outputting it to\nmy OpenSearch cluster.",
    "start": "483630",
    "end": "487860"
  },
  {
    "text": "I'm leaving the log stage format on",
    "start": "487860",
    "end": "489840"
  },
  {
    "text": "which helps to rotate the index daily",
    "start": "489840",
    "end": "494220"
  },
  {
    "text": "based on the event timestamp.",
    "start": "494220",
    "end": "496230"
  },
  {
    "text": "And the log test prefix is my index name.",
    "start": "496230",
    "end": "499080"
  },
  {
    "text": "I'm disabling the output here",
    "start": "499080",
    "end": "500849"
  },
  {
    "text": "because the output can be enabled",
    "start": "500850",
    "end": "502380"
  },
  {
    "text": "during the development of this pipeline.",
    "start": "502380",
    "end": "504360"
  },
  {
    "text": "Once it is stable, you\ncan actually disable.",
    "start": "504360",
    "end": "508110"
  },
  {
    "text": "Otherwise, it'll be very\nverbose in production.",
    "start": "508110",
    "end": "510060"
  },
  {
    "text": "Before I run this, I\nwant to watch the index",
    "start": "510060",
    "end": "513599"
  },
  {
    "text": "in my OpenSearch cluster.",
    "start": "513600",
    "end": "515789"
  },
  {
    "text": "So I'm going to watch.",
    "start": "515790",
    "end": "517503"
  },
  {
    "text": "Secondly, I have three in indexes.",
    "start": "520560",
    "end": "522930"
  },
  {
    "text": "Those are all like ecosystem\nand that's in OpenSearch.",
    "start": "522930",
    "end": "525210"
  },
  {
    "text": "Let's run this minus C where\nmy configuration file is.",
    "start": "525210",
    "end": "529713"
  },
  {
    "text": "So the moment I run this,",
    "start": "536831",
    "end": "538410"
  },
  {
    "text": "you can see a new index\nthat's been created",
    "start": "538410",
    "end": "541230"
  },
  {
    "text": "based on the event timestamp.",
    "start": "541230",
    "end": "542733"
  },
  {
    "text": "Let's close this.",
    "start": "544440",
    "end": "545670"
  },
  {
    "text": "So the next demo is to\nenrich the log lines",
    "start": "545670",
    "end": "548850"
  },
  {
    "text": "with the geo information.",
    "start": "548850",
    "end": "549959"
  },
  {
    "text": "For this, you need to download.",
    "start": "549960",
    "end": "552330"
  },
  {
    "text": "For this, I'm using GeoLite.",
    "start": "552330",
    "end": "554880"
  },
  {
    "text": "I can download this from MaxMind.",
    "start": "554880",
    "end": "557250"
  },
  {
    "text": "Here is my geo database.",
    "start": "557250",
    "end": "559350"
  },
  {
    "text": "Let's take a look at the configuration",
    "start": "559350",
    "end": "561060"
  },
  {
    "text": "that uses this file.",
    "start": "561060",
    "end": "562293"
  },
  {
    "text": "Here, I have the additional filter section",
    "start": "563610",
    "end": "565709"
  },
  {
    "text": "for geoip2 that matches the tag Apache log",
    "start": "565710",
    "end": "569310"
  },
  {
    "text": "where my geo database is.",
    "start": "569310",
    "end": "572010"
  },
  {
    "text": "And which key I should look\nfor the host IP address?",
    "start": "572010",
    "end": "576630"
  },
  {
    "text": "In this case, it is a host.",
    "start": "576630",
    "end": "578010"
  },
  {
    "text": "Once it is resolved, I'm\ncreating a new attribute",
    "start": "578010",
    "end": "581850"
  },
  {
    "text": "in the data called country\nwith a country name in English",
    "start": "581850",
    "end": "585269"
  },
  {
    "text": "and the country code as ISO code.",
    "start": "585270",
    "end": "588210"
  },
  {
    "text": "And I'm emitting this to a new index.",
    "start": "588210",
    "end": "591780"
  },
  {
    "text": "Let's run this.",
    "start": "591780",
    "end": "592713"
  },
  {
    "text": "Now you have this index created.",
    "start": "595290",
    "end": "597720"
  },
  {
    "text": "Let's take a look at how\nthis has been created.",
    "start": "597720",
    "end": "600092"
  },
  {
    "text": "I'm going to the dev tools.",
    "start": "600930",
    "end": "602703"
  },
  {
    "text": "Run this command.",
    "start": "604080",
    "end": "605160"
  },
  {
    "text": "Now I have this new index created.",
    "start": "605160",
    "end": "607443"
  },
  {
    "text": "You can see a new attribute\nhas been added to the index",
    "start": "615750",
    "end": "619590"
  },
  {
    "text": "with a country and ISO\ncode based on this host.",
    "start": "619590",
    "end": "623100"
  },
  {
    "text": "Let's look at the third one.",
    "start": "623100",
    "end": "625139"
  },
  {
    "text": "The third demo, we are\ngoing to filter events",
    "start": "625140",
    "end": "628260"
  },
  {
    "text": "based on the status quo.",
    "start": "628260",
    "end": "629490"
  },
  {
    "text": "For this, I'm going to use a stream.",
    "start": "629490",
    "end": "631653"
  },
  {
    "text": "So here is my streaming configuration.",
    "start": "632687",
    "end": "633520"
  },
  {
    "text": "Since in this configuration,\nI'm creating a stream task",
    "start": "633520",
    "end": "637410"
  },
  {
    "text": "with a name http_code_401,",
    "start": "637410",
    "end": "639509"
  },
  {
    "text": "I'm creating a new stream\nwith a name http401",
    "start": "639510",
    "end": "642400"
  },
  {
    "text": "and tag the stream as http401.",
    "start": "643650",
    "end": "646383"
  },
  {
    "text": "And selecting everything from Apache log,",
    "start": "648180",
    "end": "653180"
  },
  {
    "text": "which is our sample log\nwhere the code is 401.",
    "start": "654270",
    "end": "659160"
  },
  {
    "text": "Let's take a look at the data pipeline.",
    "start": "659160",
    "end": "661803"
  },
  {
    "text": "I'm using the stream file\nas a service configuration",
    "start": "664650",
    "end": "669090"
  },
  {
    "text": "the stream creates that tag, http401.",
    "start": "669090",
    "end": "673080"
  },
  {
    "text": "We are matching it in our output",
    "start": "673080",
    "end": "675420"
  },
  {
    "text": "and sending it to a new index.",
    "start": "675420",
    "end": "678300"
  },
  {
    "text": "So now, we are collecting all\nthe events that are collected",
    "start": "678300",
    "end": "681899"
  },
  {
    "text": "in a stream to a separate\nindex in OpenSearch.",
    "start": "681900",
    "end": "685080"
  },
  {
    "text": "I'm just outputting it for our\nunderstanding in this demo.",
    "start": "685080",
    "end": "688530"
  },
  {
    "text": "Let's run this configuration with jq.",
    "start": "688530",
    "end": "690843"
  },
  {
    "text": "Now all the events with the\nstatus code 401 are collected",
    "start": "693840",
    "end": "698430"
  },
  {
    "text": "in a separate index here.",
    "start": "698430",
    "end": "701399"
  },
  {
    "text": "Let's take a look at the fourth one.",
    "start": "701400",
    "end": "702780"
  },
  {
    "text": "Here, I'm creating a new\nstream that is country stream",
    "start": "702780",
    "end": "706800"
  },
  {
    "text": "with the tag country data.",
    "start": "706800",
    "end": "710130"
  },
  {
    "text": "I'm selecting country as a country name",
    "start": "710130",
    "end": "713070"
  },
  {
    "text": "and counting all the events",
    "start": "713070",
    "end": "715590"
  },
  {
    "text": "as a total number from the tag Apache log",
    "start": "715590",
    "end": "718800"
  },
  {
    "text": "in every five seconds\nwindow, group by country.",
    "start": "718800",
    "end": "721860"
  },
  {
    "text": "Let's take a look at the\ndata pipeline for this.",
    "start": "721860",
    "end": "724260"
  },
  {
    "text": "In this pipeline,",
    "start": "725340",
    "end": "726483"
  },
  {
    "text": "everything, the data on the standard out,",
    "start": "728550",
    "end": "732000"
  },
  {
    "text": "if it matches country data.",
    "start": "732000",
    "end": "734160"
  },
  {
    "text": "Let's run this.",
    "start": "734160",
    "end": "734993"
  },
  {
    "text": "Let's run this command.",
    "start": "740340",
    "end": "741490"
  },
  {
    "text": "After five seconds,",
    "start": "744720",
    "end": "746310"
  },
  {
    "text": "you can see the events\nhave aggregated by country",
    "start": "746310",
    "end": "750120"
  },
  {
    "text": "and the count.",
    "start": "750120",
    "end": "751083"
  },
  {
    "text": "This concludes the demo.",
    "start": "755970",
    "end": "757500"
  },
  {
    "text": "Now you have a fair understanding\nof how Fluent Bit works",
    "start": "757500",
    "end": "760680"
  },
  {
    "text": "and how you can filter process",
    "start": "760680",
    "end": "762390"
  },
  {
    "text": "and enrich your events\nwith its plugin ecosystem",
    "start": "762390",
    "end": "765030"
  },
  {
    "text": "and powerful stream\nprocessing at the edge.",
    "start": "765030",
    "end": "767520"
  },
  {
    "text": "You can also write custom\nprocesses, parsers and plugins.",
    "start": "767520",
    "end": "772520"
  },
  {
    "text": "So since there are multiple\ntools are available,",
    "start": "772530",
    "end": "776130"
  },
  {
    "text": "you can choose wisely.",
    "start": "776130",
    "end": "778620"
  },
  {
    "text": "Thank you.",
    "start": "778620",
    "end": "779453"
  }
]
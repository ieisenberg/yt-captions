[
  {
    "start": "0",
    "end": "80000"
  },
  {
    "text": "in an hour so just keep that in mind please and also just a little bit of housekeeping here I'm making several",
    "start": "660",
    "end": "6839"
  },
  {
    "text": "assumptions I'm gonna assume that you're already familiar with the sage maker dashboard actually the overview of sage",
    "start": "6839",
    "end": "12330"
  },
  {
    "text": "maker and I'm also going to assume you're already familiar with tubed or notebooks so I'm not going to spend a lot of time covering those and I've",
    "start": "12330",
    "end": "19050"
  },
  {
    "text": "built in a couple of sessions if you will a couple of time slots for questions when sage maker goes off to",
    "start": "19050",
    "end": "25349"
  },
  {
    "text": "train this dataset I've timed it at about 9 to 10 minutes so there would be some information I cover there but I",
    "start": "25349",
    "end": "31349"
  },
  {
    "text": "also want to take an opportunity to answer questions then and then when sage maker deploys the production endpoint",
    "start": "31349",
    "end": "37469"
  },
  {
    "text": "that's about six or seven minutes where we'll do the same thing so as Chris mentioned you know type your questions into there and then he'll corral those",
    "start": "37469",
    "end": "43980"
  },
  {
    "text": "for us oh and by the way if you confused my name is Chris burns and the other speaker is Chris scrin AK with a K so if",
    "start": "43980",
    "end": "51449"
  },
  {
    "text": "you want to work AWS and machine learning you have to team Chris so I don't know if anybody on here is I was also named Chris but um that's uh that's",
    "start": "51449",
    "end": "58890"
  },
  {
    "text": "that's the criteria so there's number one criteria so with that I'm gonna get started I got a short PowerPoint here as",
    "start": "58890",
    "end": "65040"
  },
  {
    "text": "I said I want to I want to give you some context around image classification I don't want to just stand here and read",
    "start": "65040",
    "end": "70110"
  },
  {
    "text": "instructions or documentation to you that doesn't do anybody any good and the first thing I want to talk about is is",
    "start": "70110",
    "end": "76200"
  },
  {
    "text": "the data set which is the most critical component of that so here's here's the",
    "start": "76200",
    "end": "81480"
  },
  {
    "start": "80000",
    "end": "98000"
  },
  {
    "text": "agenda for the day or for the hour lots and lots lots of stuff to cover so I'm going to move relatively quickly this is",
    "start": "81480",
    "end": "86970"
  },
  {
    "text": "gonna be recorded so hopefully I don't stutter and stammer too much so that if I say something that you didn't quite",
    "start": "86970",
    "end": "92130"
  },
  {
    "text": "understand that it will be recorded you can come back in and review this again",
    "start": "92130",
    "end": "97820"
  },
  {
    "start": "98000",
    "end": "172000"
  },
  {
    "text": "so so building a data set everything-everything is dependent on what i'd like to call it clean a clean",
    "start": "98420",
    "end": "104940"
  },
  {
    "text": "data set it's a it's a vague term it's an umbrella term you could put a lot of different words in there but clean means",
    "start": "104940",
    "end": "110270"
  },
  {
    "text": "no corrupt files images are dimensionally consistent and you have",
    "start": "110270",
    "end": "116640"
  },
  {
    "text": "relevant images I'm gonna go over some best practices on putting a kameez data set together I also have a bit of source",
    "start": "116640",
    "end": "122370"
  },
  {
    "text": "code that's pending legal review and once that's done I had hoped it would be done today it's not I apologize I want",
    "start": "122370",
    "end": "128550"
  },
  {
    "text": "to share that and it helps automate the process of putting an image data set together even if it's just for train",
    "start": "128550",
    "end": "134430"
  },
  {
    "text": "purposes this is not something I would recommend you put into production but I do recommend that you build your data pipelines around collecting images",
    "start": "134430",
    "end": "141230"
  },
  {
    "text": "automatically now some professionals they insist on 10,000 images per class a",
    "start": "141230",
    "end": "146519"
  },
  {
    "text": "class is of course one object that you want to identify and today we're going to identify 10 what I would call iconic",
    "start": "146519",
    "end": "152549"
  },
  {
    "text": "cars 10 different types of automobiles again it's a smaller data set but one",
    "start": "152549",
    "end": "157620"
  },
  {
    "text": "hour so there you go and my recommendation is if you're going to do any kind of image classification you should have about a thousand images if",
    "start": "157620",
    "end": "164040"
  },
  {
    "text": "you don't have a thousand images I think you're gonna run into some problems in in you know in production now we've all",
    "start": "164040",
    "end": "173730"
  },
  {
    "start": "172000",
    "end": "227000"
  },
  {
    "text": "heard the we've all heard the phrase about you know garbage in garbage out in the snow that's not it's not it can't be",
    "start": "173730",
    "end": "179159"
  },
  {
    "text": "any more true than here in machine learning so this is a an excuse me this data set it's gotta be I'm sorry was our",
    "start": "179159",
    "end": "185400"
  },
  {
    "text": "question okay so what I did here is",
    "start": "185400",
    "end": "191099"
  },
  {
    "text": "let's talk about the source code real quick I'm doing a real high level overview it essentially does two primary tasks one",
    "start": "191099",
    "end": "197159"
  },
  {
    "text": "it goes out to either a Google or a Bing search engine using an API key in a",
    "start": "197159",
    "end": "202379"
  },
  {
    "text": "downloads images about a topic so this what you see here on the screen here is I've just made a list just a text file",
    "start": "202379",
    "end": "208739"
  },
  {
    "text": "of 10 different automobiles and what the source code does it takes one of those at a time it goes out and tries to find",
    "start": "208739",
    "end": "213959"
  },
  {
    "text": "1,000 images of that subjects that object now obviously I don't know what",
    "start": "213959",
    "end": "219180"
  },
  {
    "text": "I'm gonna get when I when I download this so there's some steps put in place here to help clean this up so the first",
    "start": "219180",
    "end": "227909"
  },
  {
    "start": "227000",
    "end": "295000"
  },
  {
    "text": "step in building image data says you want to discard your unusable images now again I'm gonna preface this a with some",
    "start": "227909",
    "end": "233909"
  },
  {
    "text": "was a little bit more information here this dataset was put together specifically for this webinar so it's",
    "start": "233909",
    "end": "240329"
  },
  {
    "text": "very unlikely that you'll encounter a production scenario where you have to do something like this so again I want you to take that with a grain of salt most",
    "start": "240329",
    "end": "246509"
  },
  {
    "text": "image classification situations in a production environment your customers are going to have a great deal of images",
    "start": "246509",
    "end": "252689"
  },
  {
    "text": "hopefully hopefully if not then you would probably assemble those in some more controlled manner you wouldn't simply go out and do a a search on a",
    "start": "252689",
    "end": "259139"
  },
  {
    "text": "search engine and collect images but for day four today we did that and I also want to demonstrate the you know the",
    "start": "259139",
    "end": "264900"
  },
  {
    "text": "power of the transfer earning option in the image classification algorithm so when you start with your data set what and we'll",
    "start": "264900",
    "end": "271470"
  },
  {
    "text": "go back to that word clean you want to make sure you discard unusable images and grew a great way to find unusable",
    "start": "271470",
    "end": "277650"
  },
  {
    "text": "images are going to be the ones that are very very small in size they're gonna be you know less than a less than a",
    "start": "277650",
    "end": "282780"
  },
  {
    "text": "kilobyte they're gonna be unable to be viewed in your operating system or they will be unable to be opened in open CV",
    "start": "282780",
    "end": "289979"
  },
  {
    "text": "that's a Python library for image manipulation now another aspect of an",
    "start": "289979",
    "end": "297870"
  },
  {
    "start": "295000",
    "end": "331000"
  },
  {
    "text": "image is called viewpoint variation now I'm gonna be very very strict with my",
    "start": "297870",
    "end": "303509"
  },
  {
    "text": "images on this data set now obviously that's the car everybody can tell it's a car but for my training purposes I don't",
    "start": "303509",
    "end": "309330"
  },
  {
    "text": "want to use this image because I'm not ready to tell my algorithm that that's a car upside down I want to make sure that",
    "start": "309330",
    "end": "314460"
  },
  {
    "text": "the vector variation the viewpoint variation from images are all oriented like they would normally be seen it",
    "start": "314460",
    "end": "320099"
  },
  {
    "text": "would be very rare that you see a car upside down like that but technically speaking we would want our algorithm to identify a car regardless of the angle",
    "start": "320099",
    "end": "326659"
  },
  {
    "text": "so a viewpoint variation very very important to consider second his scale",
    "start": "326659",
    "end": "332219"
  },
  {
    "text": "we can cruise here this is a this is a picture of a car but I don't want to train on this because the car the the",
    "start": "332219",
    "end": "337979"
  },
  {
    "text": "region of interest that surrounds the car is far too small as is compared to the picture now I could crop this out",
    "start": "337979",
    "end": "343800"
  },
  {
    "text": "but there's probably not enough data there I could crop out the UH essentials just to zoom in on the car but I'd",
    "start": "343800",
    "end": "349199"
  },
  {
    "text": "rather just discard this for training purposes and bring this back later for retraining another aspect of image",
    "start": "349199",
    "end": "356969"
  },
  {
    "start": "356000",
    "end": "374000"
  },
  {
    "text": "classification is what's called occlusion you want to make sure that the image is not obstructed by any other",
    "start": "356969",
    "end": "362430"
  },
  {
    "text": "obstacles or even shadows sometimes that can play an important part in error and that's a consideration when you're in",
    "start": "362430",
    "end": "367740"
  },
  {
    "text": "production and you have outdoor lighting to keep it to a consideration",
    "start": "367740",
    "end": "373339"
  },
  {
    "text": "another one is deformation now I've made a little bit of a I don't mean to make light of this accident hopefully that",
    "start": "373339",
    "end": "379349"
  },
  {
    "start": "374000",
    "end": "406000"
  },
  {
    "text": "person was perfectly fine but we can see this is a car but I don't want to train on this for the same reason I don't want",
    "start": "379349",
    "end": "384419"
  },
  {
    "text": "to train on the image that was very very small and scale this is not formed correctly this algorithm is going to",
    "start": "384419",
    "end": "390089"
  },
  {
    "text": "generalize on the shape of a this is the Prius that's one of the ten cars and so by feeding it this in the training I'm",
    "start": "390089",
    "end": "396899"
  },
  {
    "text": "sort of cheating the algorithm of a opportunity to understand the correct pattern the correct generalization of",
    "start": "396899",
    "end": "402700"
  },
  {
    "text": "what a Prius looks like an illumination illumination is a hard one to control",
    "start": "402700",
    "end": "410170"
  },
  {
    "start": "406000",
    "end": "434000"
  },
  {
    "text": "simply because the time of day the lighting in rooms change its so when",
    "start": "410170",
    "end": "416440"
  },
  {
    "text": "you're in production you want to pay close attention to it to illumination there are methods with an open CV and",
    "start": "416440",
    "end": "421450"
  },
  {
    "text": "other image manipulation programs that help you control the lighting and the aspect ratio brightness and contrast and",
    "start": "421450",
    "end": "428170"
  },
  {
    "text": "such so that might be something that you want to pay extra close attention to when you're putting this into production and if finally we have background",
    "start": "428170",
    "end": "435160"
  },
  {
    "start": "434000",
    "end": "455000"
  },
  {
    "text": "clutter now obviously we know that's a car as humans but I don't want to train on this picture there's there's all my",
    "start": "435160",
    "end": "442450"
  },
  {
    "text": "images are RGB we're getting the color color schemes in just a moment but there's just too much busy busy",
    "start": "442450",
    "end": "449200"
  },
  {
    "text": "background on this image at home and I'm gonna kick it out I don't want to train on this one alright so once I have my",
    "start": "449200",
    "end": "456490"
  },
  {
    "start": "455000",
    "end": "507000"
  },
  {
    "text": "data set and I've kicked out all the images that I don't want to train on we want to make sure we also kick out the",
    "start": "456490",
    "end": "461500"
  },
  {
    "text": "duplicates you don't want duplicates you know in your training data you actually don't want to placate at all I don't",
    "start": "461500",
    "end": "467919"
  },
  {
    "text": "think you should want those in your validation set or your test set you wanna you wanna keep duplicates to an absolute minimum and the easy the good",
    "start": "467919",
    "end": "474880"
  },
  {
    "text": "news there is it can you can create it easy hashing hashing function excuse me and so you get back just a vector there",
    "start": "474880",
    "end": "481120"
  },
  {
    "text": "and you can database that you can use in the memory database use dynamodb whatever whatever you need to use and",
    "start": "481120",
    "end": "486250"
  },
  {
    "text": "when you come across that hash again you kick out that image and so what I was able to do is create a data set of a I",
    "start": "486250",
    "end": "491530"
  },
  {
    "text": "tried to go for a thousand per class after duplicates and after corrupt images and such like it was all whittled",
    "start": "491530",
    "end": "498280"
  },
  {
    "text": "down to about 600 per class and we'll see a few minutes there and why the transfer learning is as powerful now I",
    "start": "498280",
    "end": "507910"
  },
  {
    "start": "507000",
    "end": "546000"
  },
  {
    "text": "haven't mentioned labeling yet because my program does that for me labeling is it's one of the one of the",
    "start": "507910",
    "end": "513969"
  },
  {
    "text": "soul destroying aspects of creating data set because sometimes you'll get these images piecemeal you won't be able have",
    "start": "513969",
    "end": "519820"
  },
  {
    "text": "the opportunity to write some some source code that automates this entire process and my recommendation there is",
    "start": "519820",
    "end": "525610"
  },
  {
    "text": "label the folder the directory that these images are going to be in don't worry about labeling each and every each",
    "start": "525610",
    "end": "530890"
  },
  {
    "text": "and every image so if I were it's obviously a picture but if I were to drill down into one of these folders we'd see it's just eight eight eight",
    "start": "530890",
    "end": "537670"
  },
  {
    "text": "places of zeros all the way up to you know 688 for the image names now what I",
    "start": "537670",
    "end": "548830"
  },
  {
    "start": "546000",
    "end": "605000"
  },
  {
    "text": "did with my data set also in the source code was I convert all the images to a standard format which I chose jpg some",
    "start": "548830",
    "end": "555010"
  },
  {
    "text": "of them came down in PNG some of them came down in a couple of newer formats like iPhones new format the HEI C or",
    "start": "555010",
    "end": "560710"
  },
  {
    "text": "something like that you want to train on all the same the same format OpenCV does a great job of train up translating",
    "start": "560710",
    "end": "567370"
  },
  {
    "text": "those or can sorry converting those into a standard format you want to pay attention here to the color depth that's",
    "start": "567370",
    "end": "573160"
  },
  {
    "text": "your RGB value when you're training that's very very important you don't want to mix black and white with color",
    "start": "573160",
    "end": "578200"
  },
  {
    "text": "well you can but that first training data said I want to keep it like I said very very strict and there's also ICC",
    "start": "578200",
    "end": "583780"
  },
  {
    "text": "profiles which are kind of a pain but something you need to be very cognizant of PNG files usually you'll you'll see",
    "start": "583780",
    "end": "590890"
  },
  {
    "text": "that they can't convert because ICC profiles so that's just something to keep in mind you'll want to you don't want to discard a lot of good images",
    "start": "590890",
    "end": "596589"
  },
  {
    "text": "simply because the ICC profile wasn't converted as well because that's an easy that's an easy conversion simply an",
    "start": "596589",
    "end": "601900"
  },
  {
    "text": "extra step just a couple more moments on the dataset and we're gonna jump into",
    "start": "601900",
    "end": "607540"
  },
  {
    "start": "605000",
    "end": "682000"
  },
  {
    "text": "into sage maker now the last step that my source code does is it resizes all",
    "start": "607540",
    "end": "612700"
  },
  {
    "text": "images to a standard dimension you see in the top picture there that these images came down in all sorts of",
    "start": "612700",
    "end": "617710"
  },
  {
    "text": "different formats I had anything from 32 by 32 all the way up to 16 by 1200 and",
    "start": "617710",
    "end": "622810"
  },
  {
    "text": "there's three primary means to to right-size these cropping resizing and",
    "start": "622810",
    "end": "628720"
  },
  {
    "text": "padding now I've got an example here where I resized an image if you the large image I'm down over here on the",
    "start": "628720",
    "end": "634900"
  },
  {
    "text": "left and then I padded what would have been just blank space because I wanted to keep that dimension when you're working with CNN's now the image",
    "start": "634900",
    "end": "641560"
  },
  {
    "text": "classifier the built-in image classifier is a resonate derivative probably dense net by now and it's hopefully gonna have",
    "start": "641560",
    "end": "648040"
  },
  {
    "text": "inception at some point in the future but what we'll see we'll see what the what the robot votes for that so this",
    "start": "648040",
    "end": "655030"
  },
  {
    "text": "image has been it's been resized and then padded and now I use open CV there",
    "start": "655030",
    "end": "660130"
  },
  {
    "text": "and it essentially just takes the the pixels at the edge and sort of extend those out so you and I can see that this",
    "start": "660130",
    "end": "665470"
  },
  {
    "text": "clear really not not a correct picture but when the when the kernel you know trace",
    "start": "665470",
    "end": "671440"
  },
  {
    "text": "is over this in the CNN it's gonna just think it's part of the trees because I think the bottom is part of the road so",
    "start": "671440",
    "end": "677230"
  },
  {
    "text": "it's gonna blend in nicely as far as our cnn's concerned and then that last step",
    "start": "677230",
    "end": "683680"
  },
  {
    "start": "682000",
    "end": "711000"
  },
  {
    "text": "unfortunately as a manual step I've not found a way to automate this just yet it was very quickly even though I had",
    "start": "683680",
    "end": "688720"
  },
  {
    "text": "thousands of images I was able very very quickly probably two minutes three minutes per class go through and just",
    "start": "688720",
    "end": "693760"
  },
  {
    "text": "simply delete images that were valid images they were resized properly but they were irrelevant to me so here you",
    "start": "693760",
    "end": "699340"
  },
  {
    "text": "see that the search was for Corvette and I accidentally got some interior pictures of the Corvette which is a",
    "start": "699340",
    "end": "705250"
  },
  {
    "text": "valid is correct but for our training purposes we wanted to kick those down",
    "start": "705250",
    "end": "710339"
  },
  {
    "text": "alright so for this example the built in classifier we're using a record i/o",
    "start": "710610",
    "end": "716230"
  },
  {
    "start": "711000",
    "end": "829000"
  },
  {
    "text": "format and MX net provides a tool called im2 wreck IM to re si double PI thon",
    "start": "716230",
    "end": "722800"
  },
  {
    "text": "it's a Python script that helps you prepare this data set so it can be downloaded from github it's a very very",
    "start": "722800",
    "end": "728920"
  },
  {
    "text": "handy tool it helps you create your your training and validation sets as well as the actual binary re C file I like re se",
    "start": "728920",
    "end": "736480"
  },
  {
    "text": "because I could transfer that to other formats there's a future webinars we're gonna have about onyx where you can take",
    "start": "736480",
    "end": "742540"
  },
  {
    "text": "you know one platform and converts another platform and convert MX net to tensorflow MX net the cafe so you want to be able",
    "start": "742540",
    "end": "750040"
  },
  {
    "text": "to make sure that your your data sets portable as well so I didn't I chose to not use the jpg native format I chose",
    "start": "750040",
    "end": "757150"
  },
  {
    "text": "the record i/o format now a couple notes here about what I did when I created my",
    "start": "757150",
    "end": "762280"
  },
  {
    "text": "training in my validation sets if you see the command here is you'd for you know I am to wreck my issue the list",
    "start": "762280",
    "end": "768460"
  },
  {
    "text": "command and then the recursive command list means I'm going to make my LST file think of it as a manifest file that's a",
    "start": "768460",
    "end": "775030"
  },
  {
    "text": "list of all the files that's gonna go into that data set and then recursive because I wanted to iterate through all",
    "start": "775030",
    "end": "781060"
  },
  {
    "text": "these subfolders I had in my in my dataset folder and the subfolders correspond to one of the ten classes or",
    "start": "781060",
    "end": "787420"
  },
  {
    "text": "one of the ten automobiles so the best practices are really all over the place",
    "start": "787420",
    "end": "793150"
  },
  {
    "text": "so I approached it and used the term best practice but I like to put almost all of my data in the training and",
    "start": "793150",
    "end": "798790"
  },
  {
    "text": "validation testing is going to come you later if I if I test on a hundred images and I'm at",
    "start": "798790",
    "end": "804430"
  },
  {
    "text": "95% accuracy I can correlate that out to a thousand images so I can get a good generalization of what my accuracy is",
    "start": "804430",
    "end": "811030"
  },
  {
    "text": "gonna be so I like to put all my images into my training in my validation because that's the only opportunity my algorithm has to generalize if I keep",
    "start": "811030",
    "end": "817930"
  },
  {
    "text": "too much for testing I might have a super super super accurate test result wheel with plus or minus 1% but I may",
    "start": "817930",
    "end": "824410"
  },
  {
    "text": "have miss an opportunity to give some extra images in there for training now it's a little bit hacky but what I like",
    "start": "824410",
    "end": "831670"
  },
  {
    "text": "to do is I run it I am to rec command with the with the list parameter first on the entire data set so in my case I",
    "start": "831670",
    "end": "839320"
  },
  {
    "text": "think I had five five thousand eight hundred eighty-eight pictures so this picture on the left is a snippet of the",
    "start": "839320",
    "end": "845110"
  },
  {
    "text": "top twenty entries in an LST file the column on the left there is really an index but one of the things that I am",
    "start": "845110",
    "end": "851860"
  },
  {
    "text": "correct does for us is it shuffles those indexes for us which is very very handy so if those numbers seem out of order",
    "start": "851860",
    "end": "857110"
  },
  {
    "text": "that's because they are out of order so that that's it's not a it's an it's not a mystery the second column is which",
    "start": "857110",
    "end": "863470"
  },
  {
    "text": "class that image belongs to in this case is going to be zero through nine for our ten classes and then finally we see the",
    "start": "863470",
    "end": "870400"
  },
  {
    "text": "actual subdirectory and image that that came from so what I like to do here is I",
    "start": "870400",
    "end": "875590"
  },
  {
    "text": "do a little bit of it like I said it's a little hacky I create LST file with all my images then just with a bit of math I",
    "start": "875590",
    "end": "881050"
  },
  {
    "text": "say okay I want 70% for my training but I want 29% for my validation so I'm",
    "start": "881050",
    "end": "886720"
  },
  {
    "text": "gonna just cut and paste with it with the with the word editor for sex editor you know 29% of these whatever that",
    "start": "886720",
    "end": "892480"
  },
  {
    "text": "number is and I'm going to cut those out into a separate LST file and then finally I'm gonna take 1% of them and",
    "start": "892480",
    "end": "898870"
  },
  {
    "text": "put them in at a third LST file for testing now what that does is when I run the command again for IMT rec it's going",
    "start": "898870",
    "end": "905980"
  },
  {
    "text": "to create a re see a binary file only for the files in LST file so I have my",
    "start": "905980",
    "end": "911620"
  },
  {
    "text": "training at my validation and of my tests now here's why I do this I've I've worked very hard to eliminate any kind",
    "start": "911620",
    "end": "918910"
  },
  {
    "text": "of bias and if you think there's not human bias in image classification you would you'd be remiss so what I was",
    "start": "918910",
    "end": "925630"
  },
  {
    "text": "doing when I was testing this some couple years ago is I was picking images and I was subconsciously picking images",
    "start": "925630",
    "end": "930850"
  },
  {
    "text": "I knew would have a higher rate of so for instance in this car dataset I",
    "start": "930850",
    "end": "935960"
  },
  {
    "text": "would pick images where that's a super-clean profile from the side of the car and what I wanted realize what I",
    "start": "935960",
    "end": "941660"
  },
  {
    "text": "wanted was I wanted sometimes I wanted to see the back of the car I wanted to see the car from separate angles so when I what I let I am to wreck a shuffle",
    "start": "941660",
    "end": "948200"
  },
  {
    "text": "this for me and I simply just pick one percent of these out of here it's there they're shuffled I have no idea one want",
    "start": "948200",
    "end": "953390"
  },
  {
    "text": "to get and it eliminates my opportunity to enter a bias into my test images and",
    "start": "953390",
    "end": "962780"
  },
  {
    "text": "we see here this is simply I took my LST files that I'd saved and created the RAC",
    "start": "962780",
    "end": "969830"
  },
  {
    "text": "files uploaded the s3 and that's what we're gonna jump into into sage maker so",
    "start": "969830",
    "end": "981290"
  },
  {
    "text": "I'm gonna I'm gonna end the slideshow here one moment while I rearrange",
    "start": "981290",
    "end": "988629"
  },
  {
    "start": "988000",
    "end": "1065000"
  },
  {
    "text": "Windows okay so I'm in Sage maker I'm going to create a new file a new Jupiter",
    "start": "988720",
    "end": "994550"
  },
  {
    "text": "notebook with MX net Python 3.6 now the",
    "start": "994550",
    "end": "1001510"
  },
  {
    "text": "save time here I'm gonna cut and paste in here as I talk so the first step is",
    "start": "1001510",
    "end": "1015250"
  },
  {
    "text": "we're gonna initialize our execution object we're going to identify the bucket in s3 that are there record sets",
    "start": "1015250",
    "end": "1020530"
  },
  {
    "text": "are in our data sets and now just a note about these containers obviously there's five containers here but we're only",
    "start": "1020530",
    "end": "1025990"
  },
  {
    "text": "going to use one well we built this works of this notebook excuse me we didn't know who was going to be using it",
    "start": "1025990",
    "end": "1031000"
  },
  {
    "text": "where they're gonna be at so it's just a two-step process here where we create an array of all the containers available and then we map it to the region that",
    "start": "1031000",
    "end": "1037540"
  },
  {
    "text": "you're in with your Botto session so if you see that there's you know more than one container there that's what's going",
    "start": "1037540",
    "end": "1043480"
  },
  {
    "text": "on right there now whoops also this",
    "start": "1043480",
    "end": "1049990"
  },
  {
    "text": "image classification that's what's telling sage maker that we're going to use the built-in image classifier we",
    "start": "1049990",
    "end": "1055060"
  },
  {
    "text": "have a dedicated a dedicated container image for this algorithm and again this is running MX net hopefully I made that",
    "start": "1055060",
    "end": "1061420"
  },
  {
    "text": "I made that clear so once we've identified the container",
    "start": "1061420",
    "end": "1067510"
  },
  {
    "start": "1065000",
    "end": "1268000"
  },
  {
    "text": "in our s3 bucket as well as the algorithm we're gonna begin to set up essentially our hyper parameters",
    "start": "1067510",
    "end": "1074380"
  },
  {
    "text": "I'm not gonna spend a lot of time on this I'm going to come back to talk about these when we kick off the training job so if you have any",
    "start": "1074380",
    "end": "1081370"
  },
  {
    "text": "questions about those go ahead and type those in now and we'll get back to those in just a couple of minutes also a",
    "start": "1081370",
    "end": "1091000"
  },
  {
    "text": "couple of notes here see this command in Python it's just the percent % is we",
    "start": "1091000",
    "end": "1096460"
  },
  {
    "text": "want no we don't pipe the output - you know console out essentially more than normal in Python you have to issue a",
    "start": "1096460",
    "end": "1102040"
  },
  {
    "text": "print command that % % dumps everything here so that we can see the output and also wall time just in case we have some",
    "start": "1102040",
    "end": "1109179"
  },
  {
    "text": "Python users that aren't familiar with that you could really means like wall clock time and 702 milliseconds is the",
    "start": "1109179",
    "end": "1116110"
  },
  {
    "text": "time it took this entire cell to run so that's when you see wall time that's",
    "start": "1116110",
    "end": "1121450"
  },
  {
    "text": "what that means all right so I'm gonna",
    "start": "1121450",
    "end": "1130480"
  },
  {
    "text": "begin to set up my training job I'm going to name this now give this a meaningful name here I've put a little",
    "start": "1130480",
    "end": "1136870"
  },
  {
    "text": "bit of my my algorithm in here 18 layers and 12 that box so that we can see that I easily identify that later because",
    "start": "1136870",
    "end": "1143110"
  },
  {
    "text": "it's also there's gonna be an s3 subfolder named after this training job now this is not kicking off the training",
    "start": "1143110",
    "end": "1149320"
  },
  {
    "text": "job I'm just beginning to set up the parameters that I'm gonna pass to Sage maker to do my training",
    "start": "1149320",
    "end": "1156030"
  },
  {
    "text": "all right now identified or my job name now the training primer is I'm going to",
    "start": "1166030",
    "end": "1171980"
  },
  {
    "text": "create a Python dictionary here and I'll walk through some of these very very briefly but again I'm going to come back to these while we're training so we can",
    "start": "1171980",
    "end": "1178370"
  },
  {
    "text": "use that time more wisely this is a simple dictionary object in Python that contains all the parameters that the",
    "start": "1178370",
    "end": "1184460"
  },
  {
    "text": "training job requires here identify the instance that I'm going to train on that's the host how many of those",
    "start": "1184460",
    "end": "1191809"
  },
  {
    "text": "instances I'm going to train on any extra gigabytes that I might need now I probably don't need that that's kind of",
    "start": "1191809",
    "end": "1197390"
  },
  {
    "text": "the default 50 because our data set is really maybe one gig hyper parameters",
    "start": "1197390",
    "end": "1202910"
  },
  {
    "text": "now we're just taking the variables that we've already disturb lished up here and",
    "start": "1202910",
    "end": "1208669"
  },
  {
    "text": "placing them here now this is just a best practice coding wise that we cooker and change these variables we want to",
    "start": "1208669",
    "end": "1214880"
  },
  {
    "text": "rerun this for training we can set a maximum time we wanted to Train I've seen instances where training is gone",
    "start": "1214880",
    "end": "1220549"
  },
  {
    "text": "off the rails and gotten into some kind of you know cyclical loop where it would just train forever yeah so we don't want",
    "start": "1220549",
    "end": "1225919"
  },
  {
    "text": "that especially is a you know when you consume a cloud resources and then our input channels this is important the",
    "start": "1225919",
    "end": "1232490"
  },
  {
    "text": "built-ins are going to look for our training data in a subdirectory of s3 called Train same goes for validation so",
    "start": "1232490",
    "end": "1239210"
  },
  {
    "text": "I don't believe I jumped to two-stage maker or I'm sorry s3 but bring this",
    "start": "1239210",
    "end": "1247040"
  },
  {
    "text": "over really quick and we see in our s3 folder we have our our training",
    "start": "1247040",
    "end": "1252410"
  },
  {
    "text": "subdirectory with our binary and then these are some of the test images that",
    "start": "1252410",
    "end": "1258530"
  },
  {
    "text": "I've pre that pre-identified from my test a hell st file so again still have",
    "start": "1258530",
    "end": "1269270"
  },
  {
    "start": "1268000",
    "end": "1319000"
  },
  {
    "text": "not kicked off training we're simply setting up the parameters that we were required for training",
    "start": "1269270",
    "end": "1275799"
  },
  {
    "text": "now this source code this will kick off our training job so we're going to make",
    "start": "1278230",
    "end": "1284600"
  },
  {
    "text": "a call here to sage maker and here's the here's where the magic happens create training job now again if you're not",
    "start": "1284600",
    "end": "1290480"
  },
  {
    "text": "familiar with Python this double a strict is really it's allowing me to pass this entire Python dictionary called training",
    "start": "1290480",
    "end": "1297230"
  },
  {
    "text": "params to this parameter wherein whereas it could be possible that I would type these parameter at a time in the method",
    "start": "1297230",
    "end": "1304160"
  },
  {
    "text": "call and this is just simply more efficient so then this is actually just code that's going to query the training",
    "start": "1304160",
    "end": "1311690"
  },
  {
    "text": "job end point or the training job you know Damon if you will and give us our output so I'm gonna kick this off this",
    "start": "1311690",
    "end": "1319460"
  },
  {
    "start": "1319000",
    "end": "1403000"
  },
  {
    "text": "is gonna take about nine minutes so what I wanted to do in this time is I wanted to go back check my notes here and I'm",
    "start": "1319460",
    "end": "1328550"
  },
  {
    "text": "gonna first won't explain what's happening in this training job so if we go to the sage maker dashboard and we",
    "start": "1328550",
    "end": "1338840"
  },
  {
    "text": "come in here to training jobs we see here it's in progress one of the features of sage maker is it saves these",
    "start": "1338840",
    "end": "1345020"
  },
  {
    "text": "training jobs so that you can come back and you can rerun these right on datasets was there a question that was just",
    "start": "1345020",
    "end": "1354470"
  },
  {
    "text": "feedback okay all right so these training jobs are saved we can dig into",
    "start": "1354470",
    "end": "1359990"
  },
  {
    "text": "our training job here and it's going to demo it's going to reflect to us recap for us all of our hyper parameters now",
    "start": "1359990",
    "end": "1365600"
  },
  {
    "text": "we do have hyper parameter optimization available today unfortunately not going to get into that you know in this one",
    "start": "1365600",
    "end": "1371000"
  },
  {
    "text": "hour that probably an entire hour unto itself so there's some hyper parameter optimization that can be automated it's",
    "start": "1371000",
    "end": "1377000"
  },
  {
    "text": "very very handy if you're working with transfer learning as we'll see here and over them in a moment it's very very",
    "start": "1377000",
    "end": "1383950"
  },
  {
    "text": "it's very powerful I've been trying to find professional words to describe it but Friday I was I was like a kid in a",
    "start": "1383950",
    "end": "1389930"
  },
  {
    "text": "candy store when I first time ideas transfer learning myself on a job and I was expecting them to give some very",
    "start": "1389930",
    "end": "1396200"
  },
  {
    "text": "very low accuracy with this and I just cobbled together from the internet but I guess some I got some fantastic results",
    "start": "1396200",
    "end": "1401780"
  },
  {
    "text": "that I'll be sharing with you here in a moment so the training job what's happening here we kicked off sage maker",
    "start": "1401780",
    "end": "1407710"
  },
  {
    "start": "1403000",
    "end": "1477000"
  },
  {
    "text": "create training job Janice Goodwin is gone now this ten minutes but I want to I want to sort of defense age maker here",
    "start": "1407710",
    "end": "1413510"
  },
  {
    "text": "because it's not really ten minutes it takes 10 minutes to first spin up the ec2 host in our case we chose a p3",
    "start": "1413510",
    "end": "1419660"
  },
  {
    "text": "instance and then it has to copy down the container for the training that we with the training parameters on it so as",
    "start": "1419660",
    "end": "1426290"
  },
  {
    "text": "another you know a bit of time and then it actually caught moves the data from s3 and then",
    "start": "1426290",
    "end": "1431330"
  },
  {
    "text": "begins the training process so when it's done we're gonna jump into the cloud watch logs and it's going to be better a better outline there but the ten minutes",
    "start": "1431330",
    "end": "1438620"
  },
  {
    "text": "is actually half of that is probably provisioning time and the other half is train train time remember Sage maker was",
    "start": "1438620",
    "end": "1444530"
  },
  {
    "text": "built for infinitely sized data sets we we don't use that word accidentally infinitely size as much data as you can",
    "start": "1444530",
    "end": "1451010"
  },
  {
    "text": "pass to it so if you if you imagine a one terabyte size data set the transfer",
    "start": "1451010",
    "end": "1456350"
  },
  {
    "text": "time alone would be measured you know who knows what this can be measured in training time given the number of epochs",
    "start": "1456350",
    "end": "1461990"
  },
  {
    "text": "you're gonna run could be a day so when you're thinking about a few minutes to set up the job it's really sort of",
    "start": "1461990",
    "end": "1467780"
  },
  {
    "text": "trivial and what what I'm doing here is I'm using sage maker as a hammer like a five pound sledge to kind of drive a",
    "start": "1467780",
    "end": "1473810"
  },
  {
    "text": "finish nail if I could use that that analogy so I also wanted to go back and",
    "start": "1473810",
    "end": "1480050"
  },
  {
    "start": "1477000",
    "end": "1932000"
  },
  {
    "text": "talk about the hybrid parameters real quick and I'll try to keep an eye here on the status of our training job so",
    "start": "1480050",
    "end": "1490490"
  },
  {
    "text": "hyper parameters as I mentioned briefly I don't know if you caught it or not but the image classifier we use is based on",
    "start": "1490490",
    "end": "1497150"
  },
  {
    "text": "res net or actually dense net probably now res Nets about four or five years old now dense nets and the new iteration",
    "start": "1497150",
    "end": "1502490"
  },
  {
    "text": "of that and you can choose a number of layers that you put in the CNN now the number of layers gonna be different",
    "start": "1502490",
    "end": "1508160"
  },
  {
    "text": "based on your use case because we're using transfer learning which I did forget to point out right here what I",
    "start": "1508160",
    "end": "1514400"
  },
  {
    "text": "didn't forget to point I'll get that in a moment here use pre trained model equals yes so I'm going 18 layers",
    "start": "1514400",
    "end": "1519920"
  },
  {
    "text": "because you want to start simple first when you go deeper you're going to have you know different issues are going to",
    "start": "1519920",
    "end": "1527150"
  },
  {
    "text": "occur you're gonna have especially the backpropagation you're gonna have a you know another short the rim you're gonna",
    "start": "1527150",
    "end": "1533750"
  },
  {
    "text": "you're gonna lose fidelity so the images that you are going to use for the layers need to match up with a number of layers",
    "start": "1533750",
    "end": "1539360"
  },
  {
    "text": "that you're going to use the image shape I'm passing this off to the algorithm",
    "start": "1539360",
    "end": "1545030"
  },
  {
    "text": "and now three represents RGB three color channels and then 600-800 those are the dimensions that my source code chose as",
    "start": "1545030",
    "end": "1552410"
  },
  {
    "text": "the best dimensions so that the most images could be set to that size without losing any data or as little data as",
    "start": "1552410",
    "end": "1558680"
  },
  {
    "text": "possible obviously we saw in some ins says it had to add a bit of padding number of training samples 41:22 out of",
    "start": "1558680",
    "end": "1565850"
  },
  {
    "text": "our a total of 588 number of classes that's how many instances are how many objects I want to identify in this case",
    "start": "1565850",
    "end": "1572180"
  },
  {
    "text": "it's just ten this is just a demo now batch size so these three are probably obviously these first four you have to",
    "start": "1572180",
    "end": "1579410"
  },
  {
    "text": "have they're required but these next three are we're sort of the we'll call it the magic happens batch size epics",
    "start": "1579410",
    "end": "1585200"
  },
  {
    "text": "and learning rate the batch size represents the number of images we're passing into the network at once we",
    "start": "1585200",
    "end": "1590390"
  },
  {
    "text": "don't want to pass the entire network over to the GPUs at one time so we break it up into 128 that's the default that's",
    "start": "1590390",
    "end": "1596720"
  },
  {
    "text": "the default I've got great results with that so I left it there but you can play with that batch size number of epochs each epoch is when the network has gone",
    "start": "1596720",
    "end": "1603710"
  },
  {
    "text": "from beginning to end and then back from end to beginning so all the way forward all the way back through the network and",
    "start": "1603710",
    "end": "1609260"
  },
  {
    "text": "then learning rate is the amount by which we vary our weights and balances for each epoch so what this means is I'm",
    "start": "1609260",
    "end": "1616070"
  },
  {
    "text": "going to go 12 epochs and each time I'm going to interact my learning rate by 0.1% and what the learning rate is",
    "start": "1616070",
    "end": "1621080"
  },
  {
    "text": "remember we're generalizing I'll show a graph here in just a minute we're generalizing we went our error rate to",
    "start": "1621080",
    "end": "1626120"
  },
  {
    "text": "be minimized and we want to converge on basically the the vector of our image so",
    "start": "1626120",
    "end": "1631670"
  },
  {
    "text": "if this is simply a mathematical calculation to help us move those weights and those biases and then the",
    "start": "1631670",
    "end": "1638420"
  },
  {
    "text": "top k2 this this is really just going to give us a it's going to give us a view",
    "start": "1638420",
    "end": "1643790"
  },
  {
    "text": "at the top to accuracies when we look at the cloud watch log so it's going to be a trade the testing I'm sorry a training",
    "start": "1643790",
    "end": "1650030"
  },
  {
    "text": "accuracy and a validation accuracy and that top K equals to B's we're just taking the top to check that accuracy",
    "start": "1650030",
    "end": "1656180"
  },
  {
    "text": "this is probably a safe setting here I've seen a very little need to ever to ever move this into and to into more",
    "start": "1656180",
    "end": "1662780"
  },
  {
    "text": "than two and so I'm going to check on our ok so we're still training I did",
    "start": "1662780",
    "end": "1669260"
  },
  {
    "text": "forget to check the time when I kicked that off but I want to go now and see if we have any Chris we haven't you have",
    "start": "1669260",
    "end": "1675320"
  },
  {
    "text": "any questions there we go yes we do",
    "start": "1675320",
    "end": "1680870"
  },
  {
    "text": "first of all is I am to rec exclusively for images or can use it on flat files",
    "start": "1680870",
    "end": "1688450"
  },
  {
    "text": "is you could probably s that's open source code you could probably alter that code because",
    "start": "1688450",
    "end": "1694190"
  },
  {
    "text": "was gonna do is it's going to convert that JPEG or whichever for what you do into a binary file so you might have to",
    "start": "1694190",
    "end": "1700220"
  },
  {
    "text": "play with the method within I am to wreck that actually does the binary conversion but you can still use all the plumbing around that that lets it output",
    "start": "1700220",
    "end": "1707240"
  },
  {
    "text": "at LST file so that's um that's a question is it's kind of a yes with the caveat the oh yes you could but the",
    "start": "1707240",
    "end": "1713600"
  },
  {
    "text": "caveat is you might have to write a bit of code yourself because it needs to know how to serialize what's what's in",
    "start": "1713600",
    "end": "1719179"
  },
  {
    "text": "the five the original file out to a re C file next up how many images can I am to",
    "start": "1719179",
    "end": "1728450"
  },
  {
    "text": "rec handle I believe it works sequentially it does work sequentially",
    "start": "1728450",
    "end": "1733519"
  },
  {
    "text": "and what it does is it it'll ingest either a subdirectory at once or",
    "start": "1733519",
    "end": "1738909"
  },
  {
    "text": "multiple subjects at once and it batches it up into like chunks of 1000 or 10,000 because that's how it works with with",
    "start": "1738909",
    "end": "1745279"
  },
  {
    "text": "the shuffle and so I don't know what the maximum is I've used it on I have a",
    "start": "1745279",
    "end": "1750409"
  },
  {
    "text": "separate data set that I really wanted to use for this demo but legal told me I wasn't allowed because the copyright",
    "start": "1750409",
    "end": "1755570"
  },
  {
    "text": "issues so um whatever but it had it had it was about ten gig and had 20,000 images in it and",
    "start": "1755570",
    "end": "1763850"
  },
  {
    "text": "they were able to I'm sorry got twenty thousand two hundred thousand images in it and I am Tareq was able to shuffle those up just fine on my workstation",
    "start": "1763850",
    "end": "1770570"
  },
  {
    "text": "here which is a quad Zeon so I've not seen any limitations at IMT rec now",
    "start": "1770570",
    "end": "1775759"
  },
  {
    "text": "obviously when you get into the millions you may have had some issues there where you may want to chunk that up myself",
    "start": "1775759",
    "end": "1784370"
  },
  {
    "text": "when I say chunk it up I mean use I am to wreak upon a subset of your data set and then another subset and then maybe",
    "start": "1784370",
    "end": "1790370"
  },
  {
    "text": "combine those LST files so that you can get that all into one data set from processing and you mind swimming in on",
    "start": "1790370",
    "end": "1797779"
  },
  {
    "text": "your browser just a bit you know ctrl + once or twice there we go I just built the screen of you with are there",
    "start": "1797779",
    "end": "1805580"
  },
  {
    "text": "any good tricks for handling imbalanced classes in image classification apart",
    "start": "1805580",
    "end": "1811070"
  },
  {
    "text": "from augmenting the smaller classes hmm I may need some more information here imbalanced classes so when I see",
    "start": "1811070",
    "end": "1819289"
  },
  {
    "text": "imbalance classes I'm thinking that maybe you know in this in this case I might have three cars or four cars",
    "start": "1819289",
    "end": "1826140"
  },
  {
    "text": "then I have a dog so when I think is that what they mean by imbalance classes well I'm you know I've handled this",
    "start": "1826140",
    "end": "1833430"
  },
  {
    "text": "problem so let's say you're doing pedestrian detection and you know you",
    "start": "1833430",
    "end": "1838440"
  },
  {
    "text": "have 800 images of you know people crossing the street but only 20 of them",
    "start": "1838440",
    "end": "1845160"
  },
  {
    "text": "are in a wheelchair and you you want to make sure you get adequate wheelchair representation got it",
    "start": "1845160",
    "end": "1854040"
  },
  {
    "text": "so augmenting the smaller images you want to avoid augmentation of your ROI",
    "start": "1854040",
    "end": "1862140"
  },
  {
    "text": "your region of interest you you want your algorithm to generalize on that pattern as it sees it in the real world",
    "start": "1862140",
    "end": "1868670"
  },
  {
    "text": "so I mean I think I need to need more information about this question here because I'm not sure how you would",
    "start": "1868670",
    "end": "1874260"
  },
  {
    "text": "augment other than maybe supplement maybe do another query with individuals",
    "start": "1874260",
    "end": "1880080"
  },
  {
    "text": "in wheelchairs and add that to your data set maybe maybe these individuals wheelchairs aren't on the crosswalk I",
    "start": "1880080",
    "end": "1885480"
  },
  {
    "text": "mean you take them from some other way so you don't have to use the same source for your image files as long as the",
    "start": "1885480",
    "end": "1891930"
  },
  {
    "text": "region of interest in the image files that you use is something that might be seen in the real world when you put this into production so if you don't mind so",
    "start": "1891930",
    "end": "1899850"
  },
  {
    "text": "what I've done if you don't mind an anecdote Chris know what I've done with those images is flip them scaled them",
    "start": "1899850",
    "end": "1907140"
  },
  {
    "text": "because I want to get like 200 of those and you could potentially transform any image just by ordinary flipping you know",
    "start": "1907140",
    "end": "1915810"
  },
  {
    "text": "what I mean is a horizontal flip scaling and rotating the images he could",
    "start": "1915810",
    "end": "1922020"
  },
  {
    "text": "potentially get eight images out of every single image just by doing those simple OpenCV manipulations thank you",
    "start": "1922020",
    "end": "1934500"
  },
  {
    "start": "1932000",
    "end": "2160000"
  },
  {
    "text": "Chris and so our our training is done and",
    "start": "1934500",
    "end": "1939860"
  },
  {
    "text": "before I jump into the next session after training I didn't want to go into cloud watch just for one moment",
    "start": "1939860",
    "end": "1947570"
  },
  {
    "text": "head into our logs training jobs and",
    "start": "1950810",
    "end": "1956250"
  },
  {
    "text": "we're going to look at our log file from the training session that we just executed and here we would see",
    "start": "1956250",
    "end": "1962310"
  },
  {
    "text": "everything that would pipe to the console if we're doing this doing this locally and we can see here that we are",
    "start": "1962310",
    "end": "1970140"
  },
  {
    "text": "training accuracy in the in the first epoch 49% not very accurate but by the time we get down to the twelfth 0.96",
    "start": "1970140",
    "end": "1980400"
  },
  {
    "text": "nine I'd really hoped for a nine seven it looks like it looks like I want one epic too long here it looks like I I",
    "start": "1980400",
    "end": "1987240"
  },
  {
    "text": "began to overfit a little bit here so you got to play with that now obviously you know point zero one",
    "start": "1987240",
    "end": "1994110"
  },
  {
    "text": "percent accuracy on the over the course of forty one hundred images it is pretty",
    "start": "1994110",
    "end": "1999210"
  },
  {
    "text": "pretty miniscule but when you put this into production you're going to want to fight for every Hance you're gonna fight for every one on a one hundred",
    "start": "1999210",
    "end": "2004760"
  },
  {
    "text": "thousandth of an accuracy so one of these show that this log is here that's",
    "start": "2004760",
    "end": "2009980"
  },
  {
    "text": "our validation accuracy and I got that on forty one hundred images over the course of ten classes so that's where",
    "start": "2009980",
    "end": "2015950"
  },
  {
    "text": "the transfer learning the power the transfer learning comes in and I want to jump right back to the PowerPoint real",
    "start": "2015950",
    "end": "2021110"
  },
  {
    "text": "quick and just talk briefly so earlier I",
    "start": "2021110",
    "end": "2026870"
  },
  {
    "text": "talked about epics I talked about learning rate and I talked about the UM you know the number of iterations and",
    "start": "2026870",
    "end": "2031880"
  },
  {
    "text": "the number of epochs so what what happened there to me was really this right here the overfitting I want one",
    "start": "2031880",
    "end": "2038960"
  },
  {
    "text": "epic to long and now this squiggly line here is it's obviously it's an exaggeration we want we want our error",
    "start": "2038960",
    "end": "2045440"
  },
  {
    "text": "rate minimize so that it converges with the path of the standard deviation",
    "start": "2045440",
    "end": "2052158"
  },
  {
    "text": "remember this is SGD so a CNN such as ResNet excuse me dense net uses",
    "start": "2052159",
    "end": "2057800"
  },
  {
    "text": "stochastic gradient descent and that's an iterative process that's why it's important to make sure that you're you get a number of epochs in there that are",
    "start": "2057800",
    "end": "2065230"
  },
  {
    "text": "enough to shake out where you're overfitting where you're under fitting so what I would try say is you actually",
    "start": "2065230",
    "end": "2070669"
  },
  {
    "text": "want to train until you see an overfitting and then back off so if I were to do this again if I run",
    "start": "2070669",
    "end": "2075710"
  },
  {
    "text": "production I'd probably back this off one epic retrain and review my results",
    "start": "2075710",
    "end": "2081000"
  },
  {
    "text": "so preparing for this for this webinar I played with some different variables and",
    "start": "2081000",
    "end": "2087179"
  },
  {
    "text": "this is just a quick history of what I did here you see in the first floor I did not use transfer learning on this",
    "start": "2087179",
    "end": "2093840"
  },
  {
    "text": "exact same data set and you see my validation accuracy is simply miserable 0.28 1% if you think about it with 10",
    "start": "2093840",
    "end": "2101040"
  },
  {
    "text": "images a blind guess has a 10% chance of being accurate so 0.281",
    "start": "2101040",
    "end": "2106619"
  },
  {
    "text": "is is not very good at all and what I did here was I flipped it to transfer learning I did add a couple images when",
    "start": "2106619",
    "end": "2113940"
  },
  {
    "text": "I minimize my test set so not not many you know 120 images or whatever and we",
    "start": "2113940",
    "end": "2119310"
  },
  {
    "text": "see the accuracy here it's just skyrocketed because I want to just take a moment and talk about that point that",
    "start": "2119310",
    "end": "2124500"
  },
  {
    "text": "out for me to just grab some images off the internet throw them into sage maker with this built in and achieve that type",
    "start": "2124500",
    "end": "2131640"
  },
  {
    "text": "of accuracy and if you look at these times to train six minutes seven minutes 10 minutes this is all done on the p3 as",
    "start": "2131640",
    "end": "2139099"
  },
  {
    "text": "$12.24 per hour so it's 1/10 of that so for a dollar 20 per attempt this is what",
    "start": "2139099",
    "end": "2146520"
  },
  {
    "text": "I was able to get so if you scale this into a in the production setting a hundred dollars a thousand dollars I mean it's it's irrelevant it's it's it's",
    "start": "2146520",
    "end": "2153060"
  },
  {
    "text": "really the cost is is so small it's eventually the rolls its excuse me comes",
    "start": "2153060",
    "end": "2158670"
  },
  {
    "text": "out the pennies all right so I'm gonna jump back into Sage maker so we can get this get this finish and test and",
    "start": "2158670",
    "end": "2165330"
  },
  {
    "text": "hopefully hopefully the demo the demo gods are on my side today so what I'm",
    "start": "2165330",
    "end": "2171210"
  },
  {
    "text": "doing here now oh no oh I have to create",
    "start": "2171210",
    "end": "2177480"
  },
  {
    "text": "a unique name for my model sorry about",
    "start": "2177480",
    "end": "2182940"
  },
  {
    "text": "that so the model of the model that I was trying to create was already named",
    "start": "2182940",
    "end": "2188339"
  },
  {
    "text": "remember we keep those models those endpoint configurations and those endpoints and those models are stored for us when you come back and get those",
    "start": "2188339",
    "end": "2194250"
  },
  {
    "text": "at any time and what's gonna do is going to create here's that directory that sub directories telling you about that we",
    "start": "2194250",
    "end": "2199260"
  },
  {
    "text": "use our job name for and if we go to s3 we're gonna find this model that's hard at GZ file now that's going to contain",
    "start": "2199260",
    "end": "2205140"
  },
  {
    "text": "our parameter file in our network file the dot Jason so sage maker is very component based it's compartmentalized",
    "start": "2205140",
    "end": "2211800"
  },
  {
    "text": "we don't have to deploy to Sage maker obviously a lot of benefits to deploying the sage maker but if we wanted to take",
    "start": "2211800",
    "end": "2217219"
  },
  {
    "text": "that model from s3 and put it into our production processes elsewhere we could call it with with Python code or whatever could we wanted to call just as",
    "start": "2217219",
    "end": "2223670"
  },
  {
    "text": "easily as the sage maker endpoint calls for us now that sage maker endpoint it does create an API nice API for us to",
    "start": "2223670",
    "end": "2230449"
  },
  {
    "text": "call so does a lot of work creates the container environment for us lots and",
    "start": "2230449",
    "end": "2235759"
  },
  {
    "text": "lots of benefits to using the sage make your endpoint but what I've done here",
    "start": "2235759",
    "end": "2242319"
  },
  {
    "text": "actually what I'm going to do is I'm going to begin this up the endpoint configuration think of an endpoint configuration like an auto scaling",
    "start": "2242319",
    "end": "2248959"
  },
  {
    "text": "configuration auto scaling configuration is separate from actual auto scaling job so that this is an endpoint",
    "start": "2248959",
    "end": "2255019"
  },
  {
    "text": "configuration that's going to detail what kind of hosts I want to I want to host this on how many of those hosts and",
    "start": "2255019",
    "end": "2262309"
  },
  {
    "text": "how about my traffic to be distributed across the instances so in this case I have one host all traffic going to that",
    "start": "2262309",
    "end": "2268729"
  },
  {
    "text": "one host man actually gonna kick off the",
    "start": "2268729",
    "end": "2280880"
  },
  {
    "text": "endpoint I'll kick this off and I'm gonna talk very briefly about what's",
    "start": "2280880",
    "end": "2289130"
  },
  {
    "text": "happening behind the scenes here again this is very similar to the training job it's going and creating an ec2 instance it's pulling down a container image for",
    "start": "2289130",
    "end": "2296689"
  },
  {
    "text": "my endpoint configuration and then it's going to deploy that endpoint to that create an API around it and then give me",
    "start": "2296689",
    "end": "2302839"
  },
  {
    "text": "back the API that I would need to call to do inference against this model so",
    "start": "2302839",
    "end": "2308179"
  },
  {
    "text": "this is in process it's gonna be taking six or seven minutes so also what I wanted to do here",
    "start": "2308179",
    "end": "2313609"
  },
  {
    "text": "give mindful of the time I'll jump back into this PowerPoint real quick I'm going to talk about a very common",
    "start": "2313609",
    "end": "2320479"
  },
  {
    "text": "question we get as essays you know how many inferences per second can sage maker do and there's not a standard",
    "start": "2320479",
    "end": "2326509"
  },
  {
    "text": "answer for that because there's not a standard model size there's not a standard we'll call it image size we're",
    "start": "2326509",
    "end": "2332599"
  },
  {
    "text": "working with models here could very well easily be a text file or a voice file so I want to draw attention to this first",
    "start": "2332599",
    "end": "2339319"
  },
  {
    "text": "column here this was from a demo station I did this reinvent last year for instance this vgg net I think we ran",
    "start": "2339319",
    "end": "2346750"
  },
  {
    "text": "us on image net and it was 550 Meg so our network file was 550 Meg so our demo here today ten classes very",
    "start": "2346750",
    "end": "2354550"
  },
  {
    "text": "small I think it's about 20 Meg so our differences per second would be very robust if we were to call that",
    "start": "2354550",
    "end": "2361390"
  },
  {
    "text": "provider that we we streamlined our JPEGs that were passing to it we chose an instance with with adequate network",
    "start": "2361390",
    "end": "2367900"
  },
  {
    "text": "bandwidth these are all factors that go into debt so you have to be mindful of your model size you have to be mindful",
    "start": "2367900",
    "end": "2374260"
  },
  {
    "text": "of what you're passing to your model to be inferred against if you're mindful of the network bandwidth that you've given",
    "start": "2374260",
    "end": "2379750"
  },
  {
    "text": "your model to use those are all factors so unfortunately can't just simply publish a static variable of how many",
    "start": "2379750",
    "end": "2385480"
  },
  {
    "text": "inferences per second can we get against sage maker and so hopefully that sheds a little bit of light on that question and",
    "start": "2385480",
    "end": "2394720"
  },
  {
    "start": "2394000",
    "end": "2620000"
  },
  {
    "text": "then I have here another okay so let's go back Chris do we have any any new questions",
    "start": "2394720",
    "end": "2403320"
  },
  {
    "text": "no new questions so just put it out to the crowd there feel free to chat with",
    "start": "2403320",
    "end": "2409150"
  },
  {
    "text": "us in the chat window it's on the right side of your screen if it's collapsed just click on the little chat cloud and",
    "start": "2409150",
    "end": "2418990"
  },
  {
    "text": "then I'll just offer while we're waiting for this to execute that all of the",
    "start": "2418990",
    "end": "2426850"
  },
  {
    "text": "commands that are in the sage maker sdk such as create endpoint as we've been",
    "start": "2426850",
    "end": "2434440"
  },
  {
    "text": "seeing and to display the job those are all available from bash so if you have",
    "start": "2434440",
    "end": "2439810"
  },
  {
    "text": "downloaded the AWS CLI sage maker is one of the components in that CLI it's just",
    "start": "2439810",
    "end": "2445630"
  },
  {
    "text": "pip install AWS CLI so you can type AWS sage maker and then something like list",
    "start": "2445630",
    "end": "2452980"
  },
  {
    "text": "endpoints or display it's the command for displaying when the training job is",
    "start": "2452980",
    "end": "2458920"
  },
  {
    "text": "running and display chaining jobs okay we have a few more questions coming in next up how would I do this if I wanted",
    "start": "2458920",
    "end": "2465880"
  },
  {
    "text": "to use our instead of Python well Jupiter Notebook supports are just as",
    "start": "2465880",
    "end": "2472630"
  },
  {
    "text": "well I guess the question comes in I am NOT an AR expert so when it comes time to deploy an hour",
    "start": "2472630",
    "end": "2480819"
  },
  {
    "text": "generative model you would have to have your own custom container with the necessary code around it to pass the",
    "start": "2480819",
    "end": "2487779"
  },
  {
    "text": "inference object to the our kernel in the container so just to repeat that in",
    "start": "2487779",
    "end": "2493569"
  },
  {
    "text": "a different way what sage maker has done for me is it knows this is that an MX net so it has a container pre-built for",
    "start": "2493569",
    "end": "2500319"
  },
  {
    "text": "my endpoint hosting that has all the information I would need in order to call an MX net endpoint you have to",
    "start": "2500319",
    "end": "2506470"
  },
  {
    "text": "recreate that that model that I'm sorry that image that container image around an R generated model so again I'm not",
    "start": "2506470",
    "end": "2515739"
  },
  {
    "text": "our expert so I know that can be done I don't know the details as to how that would be done but that's really the I",
    "start": "2515739",
    "end": "2521529"
  },
  {
    "text": "don't want to trivialize it because it's a bit of work but it does make it relatively simple you would simply if we",
    "start": "2521529",
    "end": "2528309"
  },
  {
    "text": "go here to X our duper notebooks here these are endpoint pre-built container",
    "start": "2528309",
    "end": "2535089"
  },
  {
    "text": "images for MX net models endpoint hosting you would replace this image",
    "start": "2535089",
    "end": "2540640"
  },
  {
    "text": "with your custom image with the code necessary to call an R generative model so hopefully that answered that question",
    "start": "2540640",
    "end": "2548819"
  },
  {
    "text": "that sense about right next up compression of the model is that done by",
    "start": "2548819",
    "end": "2554049"
  },
  {
    "text": "sage maker this model is not compressed the slide I showed to had the that had",
    "start": "2554049",
    "end": "2560230"
  },
  {
    "text": "the compressed the compression was part of our presentation that reinvent we're talking about ml at the edge so I wanna",
    "start": "2560230",
    "end": "2567220"
  },
  {
    "text": "make sure I don't mix those two streams here today is it possible to reuse",
    "start": "2567220",
    "end": "2573150"
  },
  {
    "text": "checkpoints for retraining if the training job failed so far retraining",
    "start": "2573150",
    "end": "2578890"
  },
  {
    "text": "has only worked for me when my previous training job was completed well you",
    "start": "2578890",
    "end": "2585460"
  },
  {
    "text": "would that might be a that might be a feature that is contained in our pre-configured container images for Sage",
    "start": "2585460",
    "end": "2592900"
  },
  {
    "text": "Maker so that's a great question though because you want to be able to put checkpoints in at your you know at your",
    "start": "2592900",
    "end": "2598599"
  },
  {
    "text": "discretion rather than at the discretion of the of the pre-built container so what I'm going to do I don't want to",
    "start": "2598599",
    "end": "2604569"
  },
  {
    "text": "give you a wrong answer there because I feel like that's something you should be able to do so I'm gonna take it back to the service team and get a proper answer",
    "start": "2604569",
    "end": "2610800"
  },
  {
    "text": "so if we could if you could please reach out to me and make sure I know who it was ask that question I'll make sure I",
    "start": "2610800",
    "end": "2616740"
  },
  {
    "text": "get you a definitive answer yeah I'll",
    "start": "2616740",
    "end": "2621750"
  },
  {
    "start": "2620000",
    "end": "2655000"
  },
  {
    "text": "just add everyone on this call this is this is an exclusive training session everyone on the call is a partner this",
    "start": "2621750",
    "end": "2629430"
  },
  {
    "text": "offer only went out to partners Chris and I as segment specialists machine",
    "start": "2629430",
    "end": "2634950"
  },
  {
    "text": "learning segments specialists can go right to the service teams with questions like this detailed questions I",
    "start": "2634950",
    "end": "2641520"
  },
  {
    "text": "don't know the answer to this question either by the way and we can get responses to you relatively quickly and",
    "start": "2641520",
    "end": "2647760"
  },
  {
    "text": "that's that's part of our job and it's one of the benefits of being in the Amazon partner network query this end",
    "start": "2647760",
    "end": "2658140"
  },
  {
    "start": "2655000",
    "end": "2775000"
  },
  {
    "text": "point all right it's in service so now we can actually get to testing so I did",
    "start": "2658140",
    "end": "2665970"
  },
  {
    "text": "place 10 to 15 images in s3 from my testa Hellas T file and all this snippet",
    "start": "2665970",
    "end": "2671940"
  },
  {
    "text": "of code is doing is going out to that s3 bucket and grabbing one of these test images so just to reiterate our training",
    "start": "2671940",
    "end": "2679020"
  },
  {
    "text": "did not see this image during training or validation and I want to visualize",
    "start": "2679020",
    "end": "2684300"
  },
  {
    "text": "the image here and this was a perfect example of what I was talking about how do I pick my test images manually I",
    "start": "2684300",
    "end": "2689340"
  },
  {
    "text": "would not have picked this I think you know subconsciously I said ads it's the back of the car it's not a good clean",
    "start": "2689340",
    "end": "2695310"
  },
  {
    "text": "profile from the side or front so I'm not gonna I'm not gonna run that and what I'm gonna do now is just put a",
    "start": "2695310",
    "end": "2702390"
  },
  {
    "text": "snippet of code in here that calls that endpoint I'm simply reading this file off the notebook instance into a byte",
    "start": "2702390",
    "end": "2708180"
  },
  {
    "text": "array I'm gonna pass it you know as the proper content type X dot image and see",
    "start": "2708180",
    "end": "2715890"
  },
  {
    "text": "what we get so very quickly came back with with a correct correct identification of Corvette and it's the",
    "start": "2715890",
    "end": "2722550"
  },
  {
    "text": "0.97 for probability so that's um you know that's it's a very high level of",
    "start": "2722550",
    "end": "2728040"
  },
  {
    "text": "confidence so if I go back here and just grab another file name let's see",
    "start": "2728040",
    "end": "2737720"
  },
  {
    "text": "I'm showing my age a little bit but this was a for some reason I really love to",
    "start": "2739020",
    "end": "2745380"
  },
  {
    "text": "look at this look at this car when I was young the gremlin hits a hideous car but let's",
    "start": "2745380",
    "end": "2753119"
  },
  {
    "text": "see if it uh yeah what ninety-two percent and I actually",
    "start": "2753119",
    "end": "2759150"
  },
  {
    "text": "had one one more I would give one more and this is again this this kind of",
    "start": "2759150",
    "end": "2766140"
  },
  {
    "text": "speaks to the point I made about not handpicking your your test images Oh",
    "start": "2766140",
    "end": "2773810"
  },
  {
    "start": "2775000",
    "end": "2900000"
  },
  {
    "text": "also this is also here's a great learning lesson I hope this data set on a Windows box and Windows does not care",
    "start": "2776180",
    "end": "2784380"
  },
  {
    "text": "about capitalization however s3 does so I have a Chevelle lower score JPEG is",
    "start": "2784380",
    "end": "2791280"
  },
  {
    "text": "different to Chevelle upper score JPEG okay this is not the image that I thought it was so I apologize what's",
    "start": "2791280",
    "end": "2800010"
  },
  {
    "text": "this one OK ROCK effect at the same time",
    "start": "2800010",
    "end": "2807240"
  },
  {
    "text": "essentially it was a modified the car",
    "start": "2807240",
    "end": "2812430"
  },
  {
    "text": "was was heavily modified here we go so it is charger Boise has lowered ground",
    "start": "2812430",
    "end": "2817890"
  },
  {
    "text": "effects you know big block blown engine and I thought I thought certainly even",
    "start": "2817890",
    "end": "2823619"
  },
  {
    "text": "with my padding here certainly the algorithm will miss this one but we see",
    "start": "2823619",
    "end": "2831810"
  },
  {
    "text": "that the confidence score has been cut in half but it still identifies it as a charger so that's when I got yeah I",
    "start": "2831810",
    "end": "2837180"
  },
  {
    "text": "think I was messaging Chris you should see what this the transfer learning does great stuff so that's you know that's",
    "start": "2837180",
    "end": "2842910"
  },
  {
    "text": "that's really hit I wanted to make sure that I refer to check my notes here I",
    "start": "2842910",
    "end": "2849960"
  },
  {
    "text": "apologize this is not a scripted webinar so a little bit of um a little bit of",
    "start": "2849960",
    "end": "2857100"
  },
  {
    "text": "ad-hoc talking here in my part but we still have you know we have a full ten minutes left I want to make sure if",
    "start": "2857100",
    "end": "2863340"
  },
  {
    "text": "there's any other questions we get those asked now so we could try to get you know some group learning going on and",
    "start": "2863340",
    "end": "2869450"
  },
  {
    "text": "and that was really all I had today so you know too our eyes I'm showcasing here the I would",
    "start": "2869450",
    "end": "2876690"
  },
  {
    "text": "call the power of this built-in algorithm because I use that transfer learning I had options for high programmer",
    "start": "2876690",
    "end": "2882240"
  },
  {
    "text": "optimization had that been an issue for me realize I was able to just use my own experience and do six or seven training",
    "start": "2882240",
    "end": "2888990"
  },
  {
    "text": "jobs and guide guide that training over a few training sessions but if this were",
    "start": "2888990",
    "end": "2894180"
  },
  {
    "text": "a more complex data set obviously I'd want to use the the tools available to me to handle the hyper parameter optimization so Chris said",
    "start": "2894180",
    "end": "2902640"
  },
  {
    "text": "maybe maybe I'll just ask you a few questions and let's see if we get any from our audience as well but what do you think",
    "start": "2902640",
    "end": "2909510"
  },
  {
    "text": "the use case is I mean this looks really powerful I mean you're you're identifying car models I brought up the",
    "start": "2909510",
    "end": "2916319"
  },
  {
    "text": "issue of pedestrian detection before I mean what are though what do you think the use cases are for not using the",
    "start": "2916319",
    "end": "2923099"
  },
  {
    "text": "built-in image image classifier well there are use cases for that and they would really need to be very very",
    "start": "2923099",
    "end": "2929490"
  },
  {
    "text": "specific like for instance we had a use case at AWS where a catering company I'm",
    "start": "2929490",
    "end": "2934890"
  },
  {
    "text": "sorry a food service company wanted to use computer vision to automatically identify what was on a tray and then",
    "start": "2934890",
    "end": "2941190"
  },
  {
    "text": "bill accordingly and so they try to take pictures of the contents of the plates and try identify the food now that's an",
    "start": "2941190",
    "end": "2948660"
  },
  {
    "text": "instance where I don't know if transfer learning would would help you I don't",
    "start": "2948660",
    "end": "2954059"
  },
  {
    "text": "know if the built-in would help you because you would need to amass a data set of very highly detailed pictures of",
    "start": "2954059",
    "end": "2960630"
  },
  {
    "text": "this of each type of food and also they couldn't be duplicates so there's a lot opportunity there for like mentation as",
    "start": "2960630",
    "end": "2966720"
  },
  {
    "text": "you said rotating make eight from one so that's probably the only use case I've",
    "start": "2966720",
    "end": "2972329"
  },
  {
    "text": "seen where transfer learning and the built in was not was not a good",
    "start": "2972329",
    "end": "2978089"
  },
  {
    "text": "candidate because it really has to be super highly specialized mostly we just",
    "start": "2978089",
    "end": "2984359"
  },
  {
    "text": "got a question for the scoring you have it running on a different easy to distance yes so I currently I'm",
    "start": "2984359",
    "end": "2992309"
  },
  {
    "text": "currently consuming to two billable resources in Amazon Sage maker right now my notebook instance is still running so",
    "start": "2992309",
    "end": "2999450"
  },
  {
    "text": "whenever I'm using my notebook instance obviously I'm going to consume resources there and I said m-series it's because I",
    "start": "2999450",
    "end": "3005359"
  },
  {
    "text": "knew I'm not going to of a lot of resource heavy computing in my Jupiter notebook it's a really",
    "start": "3005359",
    "end": "3011820"
  },
  {
    "text": "relatively small image we can even do freeze free tier with the teen size instances my training environment is",
    "start": "3011820",
    "end": "3017700"
  },
  {
    "text": "gone it tears itself down immediately so I'm only billed for the amount of time that I trained which in this case was 9 minutes and now my endpoint",
    "start": "3017700",
    "end": "3024900"
  },
  {
    "text": "configuration is up and running so I am being billed for that M for instance that the stage make your endpoint is",
    "start": "3024900",
    "end": "3031050"
  },
  {
    "text": "hosted on so to answer the question yes it's a separate ec2 instance within the sage maker environment and I chose the M",
    "start": "3031050",
    "end": "3038280"
  },
  {
    "text": "for size but because you can save your sage maker configure 8 I was your endpoint configurations I can shut that",
    "start": "3038280",
    "end": "3043890"
  },
  {
    "text": "down it's not in use so all the normal elasticity configurations in ideas",
    "start": "3043890",
    "end": "3049320"
  },
  {
    "text": "around cloud apply to that so I went",
    "start": "3049320",
    "end": "3055320"
  },
  {
    "start": "3055000",
    "end": "3110000"
  },
  {
    "text": "ahead and and posted the sage maker pricing model it's really important to",
    "start": "3055320",
    "end": "3060720"
  },
  {
    "text": "understand especially if you're familiar with Jupiter notebooks that the machine",
    "start": "3060720",
    "end": "3065910"
  },
  {
    "text": "and the pricing of running your notebook as Chris just said he's running that on an m4 you could even do it on a t2 which",
    "start": "3065910",
    "end": "3072569"
  },
  {
    "text": "is I think something like you know point zero zero nine cents per hour if you all",
    "start": "3072569",
    "end": "3077760"
  },
  {
    "text": "you're doing is hosting a notebook there right when you do the training job that goes off to a completely separate",
    "start": "3077760",
    "end": "3082859"
  },
  {
    "text": "machine in this case our p3s which are the most expensive but they only run for",
    "start": "3082859",
    "end": "3088109"
  },
  {
    "text": "a few minutes so you really optimize your billing now deployment of your",
    "start": "3088109",
    "end": "3093450"
  },
  {
    "text": "endpoint at scale that's a you know that's an Amazon a globally accessible endpoint so the pricing for that is",
    "start": "3093450",
    "end": "3101069"
  },
  {
    "text": "different too and if you click on the pricing model there you'll see that the pricing is different in different regions as well so here's a question to",
    "start": "3101069",
    "end": "3112859"
  },
  {
    "start": "3110000",
    "end": "3175000"
  },
  {
    "text": "just come in can I describe how transfer learning differs from other types of they'll also transfer learning essentially what transfer learning is",
    "start": "3112859",
    "end": "3118740"
  },
  {
    "text": "summarized it I'm using a network the dense net the built-in algorithm that's",
    "start": "3118740",
    "end": "3124319"
  },
  {
    "text": "already been trained it's probably been trained on image net is probably been trained on a couple of other you know",
    "start": "3124319",
    "end": "3129540"
  },
  {
    "text": "common data sets that we see today with images and so it already knows the idea",
    "start": "3129540",
    "end": "3135030"
  },
  {
    "text": "of a pattern so I guarantee you it's already seen automobiles and that could be why I'm getting the results that I'm getting",
    "start": "3135030",
    "end": "3140430"
  },
  {
    "text": "so it's better to start with an algorithm that's already been trained almost an almost in all use cases so",
    "start": "3140430",
    "end": "3147900"
  },
  {
    "text": "especially these these uh these algorithms been trained on image nets where you have a thousand different images there's Caltech with 256",
    "start": "3147900",
    "end": "3154380"
  },
  {
    "text": "different I'm sorry hundred eighty some different classes so there's these image data sets out there already trained in",
    "start": "3154380",
    "end": "3160860"
  },
  {
    "text": "to be honest I really am hard-pressed to think of a use case where you would not start with one of those but that food",
    "start": "3160860",
    "end": "3167970"
  },
  {
    "text": "the food example is probably doing what I could think of it's another question",
    "start": "3167970",
    "end": "3178440"
  },
  {
    "start": "3175000",
    "end": "3225000"
  },
  {
    "text": "here how feasible is transfer learning across customer ISM I think it's absolutely feasible I think you know the",
    "start": "3178440",
    "end": "3186480"
  },
  {
    "text": "the great thing about this machine learning model is if you're training on a proprietary something with you know",
    "start": "3186480",
    "end": "3193410"
  },
  {
    "text": "you know intellectual property and then you retrain on something else that IP that was the secret sauce of the first",
    "start": "3193410",
    "end": "3200640"
  },
  {
    "text": "customer is not gonna transfer to second customer it's not gonna it's not gonna automatically say hey I think this is",
    "start": "3200640",
    "end": "3206640"
  },
  {
    "text": "this with this IP attached to it so I would not be I wouldn't be concerned about transfer learning across customers",
    "start": "3206640",
    "end": "3212490"
  },
  {
    "text": "at all what you wanted to obviously make sure is that you're you be mindful of multi-tenant endpoints you want probably",
    "start": "3212490",
    "end": "3219660"
  },
  {
    "text": "each customer would have their own dedicated endpoint",
    "start": "3219660",
    "end": "3223730"
  },
  {
    "text": "we're coming up to the top of the hour here Chris and so we're running out of time in questions maybe if you don't",
    "start": "3227859",
    "end": "3234970"
  },
  {
    "text": "mind just if you have some concluding comments we can put them in there and before we do that I just want to thank",
    "start": "3234970",
    "end": "3242319"
  },
  {
    "text": "everyone for attending here today there will be a recording of this session available and also there may be a survey",
    "start": "3242319",
    "end": "3249759"
  },
  {
    "text": "that you might be asked to fill out when you when you get the email notifying you",
    "start": "3249759",
    "end": "3256089"
  },
  {
    "text": "where the recording is so obviously we we do seek always to improve our work",
    "start": "3256089",
    "end": "3262660"
  },
  {
    "text": "what we're doing those surveys or the number one way that we get a chance to do that so first of all Chris you did a",
    "start": "3262660",
    "end": "3268119"
  },
  {
    "text": "phenomenal job here really impressive stuff and there's it looks like we have one more question maybe you might want",
    "start": "3268119",
    "end": "3273759"
  },
  {
    "text": "to handle that and then and then we're at the top of the hour yeah so the",
    "start": "3273759",
    "end": "3279670"
  },
  {
    "text": "question here is have I seen transferring with medical images I have not but I know it exists I have not personally seen a use case but but I do",
    "start": "3279670",
    "end": "3286539"
  },
  {
    "text": "know it exists the medical imaging we now we're getting into HIPAA we're getting into some",
    "start": "3286539",
    "end": "3292799"
  },
  {
    "text": "private privacy right I forget what's called you know patient privacy information so there's a lot of the the",
    "start": "3292799",
    "end": "3300460"
  },
  {
    "text": "democracy of machine learning sort of ends when it gets into the medical image world because it's very difficult to",
    "start": "3300460",
    "end": "3305499"
  },
  {
    "text": "share data there it's very difficult to anonymize patient information so but there are a couple data sets out there",
    "start": "3305499",
    "end": "3311259"
  },
  {
    "text": "that that have anonymized it the patient name so I know for a fact transfer",
    "start": "3311259",
    "end": "3316420"
  },
  {
    "text": "learning exists and so Chris thank you very much for for emceeing for me I appreciate it a couple times you saved",
    "start": "3316420",
    "end": "3323410"
  },
  {
    "text": "me there got me back on track again I'll say thank you to everybody that joined today I know our time is super valuable",
    "start": "3323410",
    "end": "3328599"
  },
  {
    "text": "and there's you know Monday lots of stuff to get to so thank you very much for spending time with me here's my email address on the screen if you have",
    "start": "3328599",
    "end": "3335619"
  },
  {
    "text": "any questions you know feel free to reach out to me directly we're all your all your all our partners here you're all in the ml competency so I can't wait",
    "start": "3335619",
    "end": "3342160"
  },
  {
    "text": "to see some of the great things that you build with these tools and that's it you know thanks again for your time",
    "start": "3342160",
    "end": "3349650"
  },
  {
    "text": "and so",
    "start": "3354150",
    "end": "3357299"
  }
]
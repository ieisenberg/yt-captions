[
  {
    "text": "welcome and good evening I recognize on a Wednesday night in Las Vegas at 7:00",
    "start": "60",
    "end": "5790"
  },
  {
    "text": "p.m. there's a lot of places that you could be and so I really appreciate you all turning out this evening and",
    "start": "5790",
    "end": "11130"
  },
  {
    "text": "hopefully we've got some interesting stuff for you as we talk about amazon.com and how amazon.com is in a",
    "start": "11130",
    "end": "16350"
  },
  {
    "text": "huge transition to use all AWS technologies and we'll talk about that going forward in the presentation that",
    "start": "16350",
    "end": "22890"
  },
  {
    "text": "we've got I'm going to focus on kind of three things we're gonna start talking a little bit about why and then we're gonna talk a little bit about what and",
    "start": "22890",
    "end": "29340"
  },
  {
    "text": "then about how and I wanted to start with the why because I think that the industry in the data warehousing",
    "start": "29340",
    "end": "34680"
  },
  {
    "text": "industry is in the midst of massive change and I wanted to spend just a little bit of time talking about why",
    "start": "34680",
    "end": "40020"
  },
  {
    "text": "that change is occurring first let me start and I'll just kind of give you a reference point if you were new to data",
    "start": "40020",
    "end": "46350"
  },
  {
    "text": "warehousing and you went to Wikipedia and you typed in data warehousing this",
    "start": "46350",
    "end": "51570"
  },
  {
    "text": "is the page in the diagram that you would see in in this originally in databases we started off with online",
    "start": "51570",
    "end": "58199"
  },
  {
    "text": "transaction processing systems which here are represented as the data sources on the left-hand side of this chart and",
    "start": "58199",
    "end": "63690"
  },
  {
    "text": "they were very good at doing transactions but if you did a lot of analysis on the data that you were",
    "start": "63690",
    "end": "70530"
  },
  {
    "text": "collecting in that system you would mess up the response times of the transaction processing systems so what people did",
    "start": "70530",
    "end": "76439"
  },
  {
    "text": "was they took the data out of those original systems and they would move them over into something that got",
    "start": "76439",
    "end": "81659"
  },
  {
    "text": "created that was called a data warehouse and from that they would build these larger data database systems that would",
    "start": "81659",
    "end": "87810"
  },
  {
    "text": "incorporate sales information and marketing information all of the stuff",
    "start": "87810",
    "end": "92820"
  },
  {
    "text": "from all of the different source systems and then some in some environments you",
    "start": "92820",
    "end": "98100"
  },
  {
    "text": "would run the queries directly against the data warehouse and in other environments depending on the technology you would take the data out of the data",
    "start": "98100",
    "end": "104579"
  },
  {
    "text": "warehouse and you would populate something called the data Mart and the data Mart could be independent an independent data Mart would maybe go",
    "start": "104579",
    "end": "111540"
  },
  {
    "text": "directly to the source systems for some data or you could do a dependent data Mart that would basically get fed all of",
    "start": "111540",
    "end": "117030"
  },
  {
    "text": "its data from the data warehouse and then user communities could either run their queries against the data warehouse",
    "start": "117030",
    "end": "122759"
  },
  {
    "text": "or they could go against any of these different data Mart's so there is 30 years of data warehousing in one chart",
    "start": "122759",
    "end": "128369"
  },
  {
    "text": "one kind of high-level just as a starting reference point all right and no it's not that simple",
    "start": "128369",
    "end": "134030"
  },
  {
    "text": "now a little while back I got asked to give a presentation and the question was should we be doing data warehousing or",
    "start": "134030",
    "end": "141030"
  },
  {
    "text": "should we just be completely focused on Big Data and so as we're talking a little bit about the why I wanted to",
    "start": "141030",
    "end": "146159"
  },
  {
    "text": "share with you some thoughts on some of the different trade-offs between the two environments and Big Data is here and",
    "start": "146159",
    "end": "151799"
  },
  {
    "text": "it's here to stay and I think you all recognize that and one of my favorite examples and I just",
    "start": "151799",
    "end": "156870"
  },
  {
    "text": "want to talk about the ubiquity of big data going forward and how many of you have seen these before these are smart",
    "start": "156870",
    "end": "162090"
  },
  {
    "text": "trash cans can you imagine a device dumber than a trash can right but",
    "start": "162090",
    "end": "167730"
  },
  {
    "text": "somebody had the great idea why don't I put a little solar cell a Raspberry Pi and a modem and I'll measure how full",
    "start": "167730",
    "end": "174659"
  },
  {
    "text": "the trash cans are and I'll send back information once every hour about how full it is and now instead of having to",
    "start": "174659",
    "end": "181260"
  },
  {
    "text": "visit every trashcan every day with a truck to empty it and maybe it's empty I only need to go pick up the trash cans",
    "start": "181260",
    "end": "187200"
  },
  {
    "text": "that are full right now here in this conference there's tons of IOT examples this is a very simple one but the point",
    "start": "187200",
    "end": "194040"
  },
  {
    "text": "I want to get across is this is going to be everywhere around us a couple years back there was a conference at UC San",
    "start": "194040",
    "end": "199799"
  },
  {
    "text": "Diego and the title of the conference was the trillion sensor world and they talked about this reference point was",
    "start": "199799",
    "end": "206280"
  },
  {
    "text": "two years ago but five to ten years in the future that it would cost less than",
    "start": "206280",
    "end": "211440"
  },
  {
    "text": "a quarter to print a sensor and that sensors are going to be everywhere around us you know and one example I'd",
    "start": "211440",
    "end": "217590"
  },
  {
    "text": "love to give as my wife chooses to put a Fitbit on her on her hand right and it's constant it's monitoring her heart rate",
    "start": "217590",
    "end": "223650"
  },
  {
    "text": "how active she is it tells her to get up and move around if she's been sitting for too long this is another example of",
    "start": "223650",
    "end": "228659"
  },
  {
    "text": "the IOT world and all of the data that's going to be everywhere around us coming back into systems to do analytics on in",
    "start": "228659",
    "end": "237229"
  },
  {
    "text": "this data is a little bit different than the traditional data that we've been putting in the data warehouse and this",
    "start": "237229",
    "end": "243810"
  },
  {
    "text": "is a chart from the industry and it kind of divides the data up into four quadrants the first is you're going to",
    "start": "243810",
    "end": "249180"
  },
  {
    "text": "have data that's internal to your company and that's on the south side and data that's from external sources and on",
    "start": "249180",
    "end": "255659"
  },
  {
    "text": "the left-hand side you're going to have the traditional structured data this is where you have columns and fields that",
    "start": "255659",
    "end": "260729"
  },
  {
    "text": "you put into your data warehouse and that's kind of been the historic domain of the data warehouse Big Data also",
    "start": "260729",
    "end": "267120"
  },
  {
    "text": "brings into the unstructured and so that's what's on the right hand side and so this is JSON",
    "start": "267120",
    "end": "272790"
  },
  {
    "text": "type information that's the most common that you see in the unstructured world and it's really important for these IOT",
    "start": "272790",
    "end": "279090"
  },
  {
    "text": "sensors because you may take that Fitbit and you may want to do something new and",
    "start": "279090",
    "end": "284100"
  },
  {
    "text": "download a new piece of software to it and be able to start collecting new data that you've never gathered in the past",
    "start": "284100",
    "end": "289490"
  },
  {
    "text": "and you want to be able to bring that data back into your systems and you want it in that JSON format so that you can",
    "start": "289490",
    "end": "295860"
  },
  {
    "text": "add those new fields and not have to go to your database which may have trillions of rows in it and do an alter",
    "start": "295860",
    "end": "301800"
  },
  {
    "text": "table to add the new fields and so there are a lot of similar terry's similarities with the traditional",
    "start": "301800",
    "end": "307110"
  },
  {
    "text": "databases but there's also some new capabilities that are really interesting with the unstructured world now if you",
    "start": "307110",
    "end": "314610"
  },
  {
    "text": "went to Google and you said show me with patterns for data growth right here are four different examples that all",
    "start": "314610",
    "end": "320550"
  },
  {
    "text": "basically say the same thing and what it's showing is that the amount of",
    "start": "320550",
    "end": "325800"
  },
  {
    "text": "growth in structured right and it's shown basically in the top and the two on the right the amount of growth in",
    "start": "325800",
    "end": "332610"
  },
  {
    "text": "unstructured data is continuing to grow really fast but it's nothing compared to",
    "start": "332610",
    "end": "337890"
  },
  {
    "text": "the amount of data that's in the unstructured world and so one of the challenges if you've been a traditional",
    "start": "337890",
    "end": "343290"
  },
  {
    "text": "data warehousing vendor you look at that structured world and you see it continuing to grow and you kind of ask",
    "start": "343290",
    "end": "350310"
  },
  {
    "text": "yourself right this is still a good business I still have really good price points really good margins right do I want to",
    "start": "350310",
    "end": "358020"
  },
  {
    "text": "go after all of that unstructured data typically the unstructured data is at a lower value right or price point what",
    "start": "358020",
    "end": "365310"
  },
  {
    "text": "people are willing to pay to store it then the historical financial transaction data type information and so",
    "start": "365310",
    "end": "371610"
  },
  {
    "text": "the vendors are put in this really weird spot do I want to change my price point on my traditional product and go after",
    "start": "371610",
    "end": "378570"
  },
  {
    "text": "ten or a hundred times as much data but get a lower price point per bit or do I",
    "start": "378570",
    "end": "384270"
  },
  {
    "text": "want to continue to have my data warehouse go after this good market right growing twelve to thirty percent",
    "start": "384270",
    "end": "389310"
  },
  {
    "text": "and allow other products to come into the market place to go after the unstructured data and so it's a very",
    "start": "389310",
    "end": "395490"
  },
  {
    "text": "interesting quandary for those those past data warehousing vendors",
    "start": "395490",
    "end": "400570"
  },
  {
    "text": "and part of the reason that this is problem exists is we all recognize right and you saw it in this previous charts",
    "start": "400570",
    "end": "406570"
  },
  {
    "text": "the amount of data that people want to gather and do analytics on is growing exponentially the amount of data that",
    "start": "406570",
    "end": "414250"
  },
  {
    "text": "you're putting in your data warehouse is typically growing ten to thirty to forty percent per year the average IT budget",
    "start": "414250",
    "end": "421720"
  },
  {
    "text": "over the last few years have been flat to down so here's the really hard problem if your data is growing",
    "start": "421720",
    "end": "429760"
  },
  {
    "text": "exponentially and your budget is flat to down how do you solve that problem how",
    "start": "429760",
    "end": "435040"
  },
  {
    "text": "many of you in here recognize are experiencing that in your daily job right the amount of data how am I going",
    "start": "435040",
    "end": "441130"
  },
  {
    "text": "to store that my Trisha traditional data warehouse there's a lot of people trying",
    "start": "441130",
    "end": "447670"
  },
  {
    "text": "to produce answers so this is a standard chart from the industry about the big data landscape it's been produced for",
    "start": "447670",
    "end": "453040"
  },
  {
    "text": "three or four years I am NOT going to go through and describe this in any level of detail but the point I want to make",
    "start": "453040",
    "end": "458380"
  },
  {
    "text": "here is that the valley and the investment community has been investing billions of dollars over the last few",
    "start": "458380",
    "end": "464350"
  },
  {
    "text": "years to try to build the products to try to bring and reconcile these two things right and it's an interesting",
    "start": "464350",
    "end": "471430"
  },
  {
    "text": "world because some of the past products that we use for data warehousing were very good at a wide range of things and",
    "start": "471430",
    "end": "477190"
  },
  {
    "text": "so if you were in their sweet spot they were great if you got a little bit outside of their sweet spot they were still good but in these products if",
    "start": "477190",
    "end": "484630"
  },
  {
    "text": "you're in their sweet spot they're fantastic they rock and roll but you start to get a little bit outside of",
    "start": "484630",
    "end": "490060"
  },
  {
    "text": "their sweet spot mmm it might not work at all so it's a very interesting time",
    "start": "490060",
    "end": "495250"
  },
  {
    "text": "that you really have to bring together and package a lot of these things to build it an entire solution so that's my",
    "start": "495250",
    "end": "503320"
  },
  {
    "text": "quick background on why I think the world is changing and particularly in the data warehousing space and I just",
    "start": "503320",
    "end": "509860"
  },
  {
    "text": "wanted to cover that a little bit before we launched into a little bit about Amazon now we're here for AWS but I come",
    "start": "509860",
    "end": "516610"
  },
  {
    "text": "from the dot-com side and kind of the overall business side and so just real quick if you're not familiar with Amazon",
    "start": "516610",
    "end": "522400"
  },
  {
    "text": "and I assume that you are here's our kind of our corporate statement and the really key thing here is we want to find",
    "start": "522400",
    "end": "528880"
  },
  {
    "text": "and discover anything that you might want to buy online okay there's lots of great text here but that",
    "start": "528880",
    "end": "534340"
  },
  {
    "text": "the point I want to get across and here's just an example of the Amazon Front webpage I was looking at hammers",
    "start": "534340",
    "end": "541210"
  },
  {
    "text": "and bought a new hammer so that's why there's hammers on the page but you know",
    "start": "541210",
    "end": "546430"
  },
  {
    "text": "I just wanted to kind of remind you that most people when they think of Amazon outside of AWS are thinking about going",
    "start": "546430",
    "end": "551710"
  },
  {
    "text": "to the website and buying some stuff and from inside the business here's a",
    "start": "551710",
    "end": "557170"
  },
  {
    "text": "picture of one of our fulfillment centers if you ever get a chance to go to the fulfillment center I highly recommend it it really is an amazing",
    "start": "557170",
    "end": "564160"
  },
  {
    "text": "place where an amazing amount of stuff is coming in through the loading docks",
    "start": "564160",
    "end": "570160"
  },
  {
    "text": "it's being packaged and put on shelves it's like a three or four storey library that's basically on multiple football",
    "start": "570160",
    "end": "576490"
  },
  {
    "text": "fields and everything is packed randomly which was a little bit crazy to me when I first first went there and saw that",
    "start": "576490",
    "end": "583470"
  },
  {
    "text": "but it's it's packed for density they want to get as much in these places and when you go to pick something you get a",
    "start": "583470",
    "end": "590170"
  },
  {
    "text": "little machine that tells you and it gives you like library coordinates and you go and you find a box that's about this big and you open it up and when",
    "start": "590170",
    "end": "597580"
  },
  {
    "text": "it's random finding the thing that you're looking for like maybe a bottle of lotion it's really simple when it's",
    "start": "597580",
    "end": "603190"
  },
  {
    "text": "in there with like a tire for a lawnmower and a bunch of book and other stuff when you open it up it's like",
    "start": "603190",
    "end": "608650"
  },
  {
    "text": "really obvious which one you're looking for and it actually really helps with the speed of picking but when you walk in and it's like somebody went to a",
    "start": "608650",
    "end": "615370"
  },
  {
    "text": "Walmart and shook it right everything is just completely randomized right impact",
    "start": "615370",
    "end": "620680"
  },
  {
    "text": "a lot more densely so that's the business that we're in and on the data warehouse side we work with a lot of",
    "start": "620680",
    "end": "627880"
  },
  {
    "text": "different teams inside Amazon and we collect a lot of data we have tables",
    "start": "627880",
    "end": "633070"
  },
  {
    "text": "with hundreds of trillions of rows and we'll talk about this in a little bit but there's a lot of businesses that are",
    "start": "633070",
    "end": "638140"
  },
  {
    "text": "really huge some of the businesses that we work with inside Amazon and I'll give you an example here in a couple of charts some of them are as big as",
    "start": "638140",
    "end": "645070"
  },
  {
    "text": "fortune 500 companies even fortune 200 100 type companies some of the teams",
    "start": "645070",
    "end": "650410"
  },
  {
    "text": "inside Amazon and then there's a lot of startups right that are very small and just getting going and so there's a huge",
    "start": "650410",
    "end": "657040"
  },
  {
    "text": "amount of difference in the different teams that we get to work with so let me",
    "start": "657040",
    "end": "662440"
  },
  {
    "text": "talk a little bit about the good of our legacy data warehouse the legacy data warehouse",
    "start": "662440",
    "end": "668170"
  },
  {
    "text": "the most comprehensive set of cleansed and curated data inside the company it feeds many and I'm talking thousands",
    "start": "668170",
    "end": "674560"
  },
  {
    "text": "of downstream systems and it reaches back into thousands of source systems it",
    "start": "674560",
    "end": "680170"
  },
  {
    "text": "does primarily batch processing it does do reporting in ad hoc but the vast",
    "start": "680170",
    "end": "685240"
  },
  {
    "text": "majority of the work that's going on is batch processing because it's going to do that batch processing on the huge data sets and then feed it out to data",
    "start": "685240",
    "end": "691720"
  },
  {
    "text": "Mart's for people to do a lot of the query workloads we do do about a half a million load jobs a day and about",
    "start": "691720",
    "end": "698199"
  },
  {
    "text": "200,000 queries each day our system has about 20,000 active tables which",
    "start": "698199",
    "end": "703600"
  },
  {
    "text": "compared to some of the other data warehouses I worked out before Amazon it's really not a large number of tables but the tables are really really big and",
    "start": "703600",
    "end": "711269"
  },
  {
    "text": "we're loading and this is kind of a low number I'll call it 10 billion roads",
    "start": "711269",
    "end": "717940"
  },
  {
    "text": "rows a day right and I don't want to get into anything that could get us into the",
    "start": "717940",
    "end": "724510"
  },
  {
    "text": "problems with forward-looking statements on that sort of stuff so I'm just gonna leave it real simple at 10 billion rows a day the data set size is about 5",
    "start": "724510",
    "end": "733390"
  },
  {
    "text": "petabytes compressed and we're getting four to five X compression and I will",
    "start": "733390",
    "end": "739510"
  },
  {
    "text": "tell you the amount of data inside Amazon is multiples of that but that's the data that we've chosen to put into",
    "start": "739510",
    "end": "744970"
  },
  {
    "text": "the legacy data warehouse and when we add it up across multiple systems and we",
    "start": "744970",
    "end": "750310"
  },
  {
    "text": "have lots of systems for effectively getting lots of Korea work done it's",
    "start": "750310",
    "end": "755680"
  },
  {
    "text": "about 35 petabytes of spinning storage that we have online at this point in time in our legacy environment and I had",
    "start": "755680",
    "end": "763029"
  },
  {
    "text": "the opportunity not too long after I started at Amazon two years ago to go and meet with the legacy vendor and I",
    "start": "763029",
    "end": "768640"
  },
  {
    "text": "kind of challenged him that I thought that the system was quite a bit larger than any other customer and I said it was two orders of magnitude bigger and",
    "start": "768640",
    "end": "775800"
  },
  {
    "text": "that the VP of engineering looked at me and said no it's three orders of magnitude it's a thousand times bigger",
    "start": "775800",
    "end": "781240"
  },
  {
    "text": "than any other customer that we have and a couple things one I think that's a",
    "start": "781240",
    "end": "787600"
  },
  {
    "text": "little bit of exaggeration I don't really think that we're a thousand times bigger but the thing I want to get across is if you're a customer and your",
    "start": "787600",
    "end": "796600"
  },
  {
    "text": "vendor is telling you that you're a thousand times bigger than any other customer do you think that's a good spot to be in",
    "start": "796600",
    "end": "803130"
  },
  {
    "text": "what what what is their test environment like and who is it targeted at and are you ever going to fit into that test",
    "start": "803130",
    "end": "809050"
  },
  {
    "text": "profile right so there's some real challenges with that and we do have",
    "start": "809050",
    "end": "814630"
  },
  {
    "text": "internally a really significant use of redshift it was here it was already there when I started but at this point",
    "start": "814630",
    "end": "820720"
  },
  {
    "text": "in time we literally had thousands of redshift in the EMR systems that are in use we'll come back and talk some more",
    "start": "820720",
    "end": "825730"
  },
  {
    "text": "facts and figures that I'll give you some details about some of the stuff that I described and where we stand today but these systems can range from",
    "start": "825730",
    "end": "832600"
  },
  {
    "text": "very small where somebody just stands up a single node system they're doing a project-based analysis they're going to",
    "start": "832600",
    "end": "837970"
  },
  {
    "text": "use it for a couple weeks and then return it into the cloud - some of these are instantiated systems they are",
    "start": "837970",
    "end": "843279"
  },
  {
    "text": "significant size hundreds if not thousands of nodes in there running multi-billion dollar businesses right so",
    "start": "843279",
    "end": "850839"
  },
  {
    "text": "there's a very very wide range and I brought this chart in just to kind of give you a feel of one of our customers",
    "start": "850839",
    "end": "858420"
  },
  {
    "text": "inside Amazon this is a team that works with vendors and they do about two",
    "start": "858420",
    "end": "865420"
  },
  {
    "text": "hundred and thirty-five million CPU minutes per month that's one of the metrics that we use internals internally",
    "start": "865420",
    "end": "870510"
  },
  {
    "text": "they support a hundred and seventy teams they have thousands of users they run",
    "start": "870510",
    "end": "876100"
  },
  {
    "text": "about 10,000 profiles in a profile think of that as a parameterised query that could take a whole bunch of different",
    "start": "876100",
    "end": "882490"
  },
  {
    "text": "parameters and we could run it hundreds or thousands of times a day with different parameters right different",
    "start": "882490",
    "end": "888670"
  },
  {
    "text": "regions different time zones different things like that this particular team",
    "start": "888670",
    "end": "893890"
  },
  {
    "text": "works with about 2,800 tables or about a petabyte of information is there working set and they produce in one of their",
    "start": "893890",
    "end": "901120"
  },
  {
    "text": "down streams as some BI tools that support 3,000 users 650 which are non",
    "start": "901120",
    "end": "906339"
  },
  {
    "text": "tech and hundreds of dashboards and again this is just one of the customers",
    "start": "906339",
    "end": "911350"
  },
  {
    "text": "that we deal with right one of the larger ones now most of you are probably",
    "start": "911350",
    "end": "917649"
  },
  {
    "text": "familiar with this chart and I am NOT here to endorse this as the definition of big data but I did want to talk about",
    "start": "917649",
    "end": "924130"
  },
  {
    "text": "it because it represents some of the challenges that we were having with our legacy environment one thing was volume",
    "start": "924130",
    "end": "930370"
  },
  {
    "text": "we have huge datasets right and there's absolutely no question that we have huge data sets but some of the data sets that",
    "start": "930370",
    "end": "937779"
  },
  {
    "text": "you might want are too large to fit into that environment it's not at a cost point that we're willing to pay so an",
    "start": "937779",
    "end": "943360"
  },
  {
    "text": "example would be clickstream right we keep a couple of months of worth of the click stream from all of the website in",
    "start": "943360",
    "end": "950589"
  },
  {
    "text": "the data warehouse but we'd like to keep two years we just can't afford to keep two years so there is another team that",
    "start": "950589",
    "end": "957639"
  },
  {
    "text": "has set up a huge EMR based infrastructure to manage two years worth of click stream and a lot of people to",
    "start": "957639",
    "end": "962980"
  },
  {
    "text": "do that analysis and we've limited the amount of data that we put in the data warehouse to fit within our means in",
    "start": "962980",
    "end": "968519"
  },
  {
    "text": "terms of velocity there are many real-time systems inside",
    "start": "968519",
    "end": "973720"
  },
  {
    "text": "Amazon there's real-time pricing where we're looking at the pricing across the web on different components and",
    "start": "973720",
    "end": "979329"
  },
  {
    "text": "adjusting prices in real-time but those systems don't go through the data warehouse the data warehouse is a 24",
    "start": "979329",
    "end": "986170"
  },
  {
    "text": "hour batch and as we find that my experience from the industry before I came to Amazon that's kind of an outlier",
    "start": "986170",
    "end": "993190"
  },
  {
    "text": "at this point most retailers really went to near real-time on most of their",
    "start": "993190",
    "end": "998259"
  },
  {
    "text": "systems probably five to ten years ago right and so that's one of the things that we're very actively working on as",
    "start": "998259",
    "end": "1004290"
  },
  {
    "text": "we're creating our new environment is making sure that our velocity is much better than where it has been in the past in terms of variety",
    "start": "1004290",
    "end": "1011760"
  },
  {
    "text": "we're very structured in terms of the data warehouse so it's tables columns and rows and a lot of that very rich",
    "start": "1011760",
    "end": "1019829"
  },
  {
    "text": "data that we're seeing from other systems the JSON data internally we use a format that's very much like JSON or a",
    "start": "1019829",
    "end": "1026428"
  },
  {
    "text": "structured JSON that we call eye on that AWS is going to be releasing has released and will be incorporating into",
    "start": "1026429",
    "end": "1032400"
  },
  {
    "text": "a lot of their different products in the future ion is if you're familiar with  and you know Bice on ion is a lot",
    "start": "1032400",
    "end": "1037860"
  },
  {
    "text": "like python it's basically a typed Jason language and we want to be able to",
    "start": "1037860",
    "end": "1043380"
  },
  {
    "text": "incorporate all of the richness of the source systems when they add a new field an hour ago we want to be able to",
    "start": "1043380",
    "end": "1049080"
  },
  {
    "text": "capture that and not lose the data that we're doing now as we're loading it into our legacy environment and then the last",
    "start": "1049080",
    "end": "1056190"
  },
  {
    "text": "of the four V's is the voracity we spend a lot of time making sure our data is very good quality but like in every",
    "start": "1056190",
    "end": "1062909"
  },
  {
    "text": "environment we do have challenges and we're always we're looking to make that better and that's one of the things that we're looking for",
    "start": "1062909",
    "end": "1068520"
  },
  {
    "text": "or big improvements as we move forward and in one picture I wanted to summarize",
    "start": "1068520",
    "end": "1075720"
  },
  {
    "text": "kind of the our legacy environment right",
    "start": "1075720",
    "end": "1081150"
  },
  {
    "text": "and it's kind of the Swiss Army knife it does everything right and it's got all",
    "start": "1081150",
    "end": "1086250"
  },
  {
    "text": "of these wonderful tools in it and I guess the question I would look for when",
    "start": "1086250",
    "end": "1092190"
  },
  {
    "text": "you think about this it's a great thing to have in your pocket and be able to have a tool when you need it but if a",
    "start": "1092190",
    "end": "1098790"
  },
  {
    "text": "craftsman came to your house to do some piece of work and he whipped out a Swiss Army knife what would you think right",
    "start": "1098790",
    "end": "1107610"
  },
  {
    "text": "it's probably not the best scissors it's not the best pliers it's not the best knife it's not the best of any of those",
    "start": "1107610",
    "end": "1113700"
  },
  {
    "text": "things it's not really the tool that you might want to be using but it's relatively good at just about everything",
    "start": "1113700",
    "end": "1121790"
  },
  {
    "text": "so I joined two years ago and we had lots of long discussions about what it",
    "start": "1122570",
    "end": "1127920"
  },
  {
    "text": "is that we wanted to do and how we wanted to involve devolve this legacy environment and here's kind of some of",
    "start": "1127920",
    "end": "1133860"
  },
  {
    "text": "the core things that we were really looking for and what Jeff Wilkie challenged me with the first and most",
    "start": "1133860",
    "end": "1139650"
  },
  {
    "text": "obvious thing is the legacy environment was not scaling with the Amazon business and Jeff Wilkie the CEO of consumer",
    "start": "1139650",
    "end": "1147330"
  },
  {
    "text": "basically spends a lot of his time thinking about we're growing at a very rapid rate we've been doing that for a",
    "start": "1147330",
    "end": "1152880"
  },
  {
    "text": "long time we hope to continue to do it what are the things that could prevent that level of growth from continuing and",
    "start": "1152880",
    "end": "1158910"
  },
  {
    "text": "one of the things that he had identified was the analytic environment and so his",
    "start": "1158910",
    "end": "1163980"
  },
  {
    "text": "number-one mission for us was I need an environment that scales with the",
    "start": "1163980",
    "end": "1169500"
  },
  {
    "text": "business the second thing is we want to be good partners to AWS we want to help",
    "start": "1169500",
    "end": "1175800"
  },
  {
    "text": "AWS scale in they're fantastic partners to us I have absolutely nothing to say about the work that they're doing and",
    "start": "1175800",
    "end": "1181500"
  },
  {
    "text": "all of the great partnerships that we have and we really want to improve these technologies and we want to dogfood them",
    "start": "1181500",
    "end": "1188370"
  },
  {
    "text": "so when your business is at MSI on size and scale and when you're trying to solve some of these problems we've",
    "start": "1188370",
    "end": "1194160"
  },
  {
    "text": "already pre tested it and we've already scaled it and we already make have made sure that it works at Amazon scale and",
    "start": "1194160",
    "end": "1199380"
  },
  {
    "text": "then we can work with effectively any company in the world and be able to solve their enterprise problems we also saw unique",
    "start": "1199380",
    "end": "1207360"
  },
  {
    "text": "user groups one of the user groups very business focused wants to continue to have SQL wants to continue to use",
    "start": "1207360",
    "end": "1213570"
  },
  {
    "text": "business tools but emerging is people who want to do analytic applications and",
    "start": "1213570",
    "end": "1219270"
  },
  {
    "text": "approaches including things like machine learning and programmatic analysis that was not well supported in our legacy",
    "start": "1219270",
    "end": "1225000"
  },
  {
    "text": "environment and so we want to make sure as we produce the new environment that we fully meet all of the requirements",
    "start": "1225000",
    "end": "1230460"
  },
  {
    "text": "for the people who want to do that and that's a really key another portion of having Amazon scale long term is to have",
    "start": "1230460",
    "end": "1237630"
  },
  {
    "text": "more and more of what used to be human processes be accounted for in the software and this is one of the things",
    "start": "1237630",
    "end": "1243420"
  },
  {
    "text": "that enabled it and the last thing and I'm going to create a couple of terms here the old environment I'm going to",
    "start": "1243420",
    "end": "1250590"
  },
  {
    "text": "call bring your own query and what I mean by that was we had a web page and you could take a piece of SQL and you",
    "start": "1250590",
    "end": "1256650"
  },
  {
    "text": "could submit it to that web page and you could schedule it and we would run it for you and send you the results in several different formats right and so",
    "start": "1256650",
    "end": "1264270"
  },
  {
    "text": "you kind of bring your query to the system we ran it for you and we give you the results that's a good model but it's",
    "start": "1264270",
    "end": "1270000"
  },
  {
    "text": "a very centralized model to that model we wanted to add bring your own cluster and bring your own cluster basically",
    "start": "1270000",
    "end": "1276990"
  },
  {
    "text": "says you as a business unit you can decide how much performance you can decide how much compute you can size the",
    "start": "1276990",
    "end": "1283680"
  },
  {
    "text": "system to your business needs we'll get you the data but you can bring your own clusters into that environment we can do",
    "start": "1283680",
    "end": "1290130"
  },
  {
    "text": "the job scheduling we can help you run the queries but you get to pick how much compute that you bring and so overall we",
    "start": "1290130",
    "end": "1297150"
  },
  {
    "text": "call that bring your own cluster and that was definitely something that we wanted to support so at a high level",
    "start": "1297150",
    "end": "1304010"
  },
  {
    "text": "this is the environment that we're trying to build and we are layering all of the AWS utilities on top of that as",
    "start": "1304010",
    "end": "1310470"
  },
  {
    "text": "our tool set ok and as a basis what we",
    "start": "1310470",
    "end": "1317670"
  },
  {
    "text": "want to do is create a data Lake and we wanted to do that in s3 in the key thing",
    "start": "1317670",
    "end": "1324720"
  },
  {
    "text": "that we want to do is separate storage from compute so we are able to scale the",
    "start": "1324720",
    "end": "1330690"
  },
  {
    "text": "compute for every team completely independent of the storage infrastructure that was not",
    "start": "1330690",
    "end": "1337280"
  },
  {
    "text": "possible in the old environment we had to scale the storage and the compute in parallel in all of the different systems",
    "start": "1337280",
    "end": "1343340"
  },
  {
    "text": "that we were using now the next part here some of you will take a little bit of offense to it I'm going to keep it at",
    "start": "1343340",
    "end": "1350360"
  },
  {
    "text": "a very high level and I understand that this is not absolutely true but I think it's mostly true in terms of Amazon",
    "start": "1350360",
    "end": "1357710"
  },
  {
    "text": "redshift we really want to use that for the people who are interested in SQL analysis ok redshift can do much more",
    "start": "1357710",
    "end": "1364670"
  },
  {
    "text": "than that but for the most part redshift is really where we're going to have the business users and the business tools",
    "start": "1364670",
    "end": "1370250"
  },
  {
    "text": "going and then separately from that to people who want to do the programmatic access and the functional programming",
    "start": "1370250",
    "end": "1375680"
  },
  {
    "text": "they will be biased towards and the machine learning they will be biased towards EMR now I recognize that",
    "start": "1375680",
    "end": "1381440"
  },
  {
    "text": "redshift can do some machine learning but overall most of the most of the work going on will be going on at EMR in that",
    "start": "1381440",
    "end": "1387590"
  },
  {
    "text": "space in what we have done in what we",
    "start": "1387590",
    "end": "1393770"
  },
  {
    "text": "have been working on is creating the Amazon data Lake which internally we call an DS and the goal for the Amazon",
    "start": "1393770",
    "end": "1400880"
  },
  {
    "text": "data Lake is we want to be this the place that people go to to the data",
    "start": "1400880",
    "end": "1406310"
  },
  {
    "text": "producers this is the place where they go to put their data and data consumers this is the place where they go to find",
    "start": "1406310",
    "end": "1412670"
  },
  {
    "text": "the data that it is that they're looking for an EMR can without having to load",
    "start": "1412670",
    "end": "1419540"
  },
  {
    "text": "into HDFS EMR can directly access the data inside the data Lake and so we can",
    "start": "1419540",
    "end": "1424580"
  },
  {
    "text": "have many EMR systems going directly against the data Lake redshifted a effectively has two modes the one that",
    "start": "1424580",
    "end": "1431870"
  },
  {
    "text": "we have been using is loading the data into redshift and putting it in its file system but a few months back redshift",
    "start": "1431870",
    "end": "1438350"
  },
  {
    "text": "introduced a feature called spectrum and it's been talked about here in the show and many different places spectrum",
    "start": "1438350",
    "end": "1443930"
  },
  {
    "text": "allows us to keep the data in the data lake and be able to use redshift but access the data as it exists in the data",
    "start": "1443930",
    "end": "1449450"
  },
  {
    "text": "Lake so in our environment we have been working with the redshift team we've got betas going on right now so some early",
    "start": "1449450",
    "end": "1456560"
  },
  {
    "text": "prototypes and beta activity going on and we expect to release that at the beginning of the year in real production",
    "start": "1456560",
    "end": "1462350"
  },
  {
    "text": "and real scale now this is an interesting chart and I'm going to come",
    "start": "1462350",
    "end": "1467600"
  },
  {
    "text": "at this for a couple angles first of all if the right hand side looks a little blurry that is on purpose",
    "start": "1467600",
    "end": "1473250"
  },
  {
    "text": "the lawyers asked me to blur it and I also have trimmed off the the on the outside ring they were table names and",
    "start": "1473250",
    "end": "1479940"
  },
  {
    "text": "so I have purposely truncated them so that you can't see the actual table names but that is a d3 chart each of",
    "start": "1479940",
    "end": "1487680"
  },
  {
    "text": "those data points on the outside is a table name in each of the blue lines on the inside of the chart is a join that",
    "start": "1487680",
    "end": "1495510"
  },
  {
    "text": "goes on with that table and so one of the things that we did in trying to analyze the data like and whether or not",
    "start": "1495510",
    "end": "1501240"
  },
  {
    "text": "this environment would work was we went through every community of our legacy environment in there were 2,300",
    "start": "1501240",
    "end": "1507900"
  },
  {
    "text": "different user communities and we looked at every query that they had run in the last year and we analyzed what tables",
    "start": "1507900",
    "end": "1513930"
  },
  {
    "text": "they looked at and we and what tables they joined with and we found something",
    "start": "1513930",
    "end": "1519210"
  },
  {
    "text": "that was both very important and very real now I'm aware of data warehouses",
    "start": "1519210",
    "end": "1525000"
  },
  {
    "text": "out there in the industry that have a million tables ok right and I don't think that that's really that odd but",
    "start": "1525000",
    "end": "1530670"
  },
  {
    "text": "can I ask you how many of you can keep track of a million tables how many of you could figure out which of those",
    "start": "1530670",
    "end": "1535800"
  },
  {
    "text": "million tables that you would need to use and the answer is of millions a really big number right and in fact the",
    "start": "1535800",
    "end": "1543090"
  },
  {
    "text": "20,000 number that I talked about before in the Amazon legacy environment that's also a really big number in a lot of",
    "start": "1543090",
    "end": "1550470"
  },
  {
    "text": "environments they create something called a semantic layer and a semantic layer goes into a particular user",
    "start": "1550470",
    "end": "1556350"
  },
  {
    "text": "community and it gives them the subset of the tables that they're really interested in and that's the effect that",
    "start": "1556350",
    "end": "1561930"
  },
  {
    "text": "we saw here on the way that the legacy environment was being used these 2300",
    "start": "1561930",
    "end": "1567180"
  },
  {
    "text": "different user communities right on average each user community and there",
    "start": "1567180",
    "end": "1572670"
  },
  {
    "text": "could be hundreds of people in a user community right on average they look at 49 tables the",
    "start": "1572670",
    "end": "1579630"
  },
  {
    "text": "max the outlier was 598 tables so it",
    "start": "1579630",
    "end": "1584880"
  },
  {
    "text": "might not be possible to put all of this stuff on one system but if we are using",
    "start": "1584880",
    "end": "1592560"
  },
  {
    "text": "these systems not as trying to build an enterprise data warehouse but if we're using the data Lake as the enterprise",
    "start": "1592560",
    "end": "1599040"
  },
  {
    "text": "data warehouse and we're using dependent data Mart's as primary engine for people to go do query",
    "start": "1599040",
    "end": "1604440"
  },
  {
    "text": "workloads if they're only looking at 600 or less tables now of a sudden that's that's not only doable it's easy and so",
    "start": "1604440",
    "end": "1612900"
  },
  {
    "text": "this is a really key learning that you know effectively teams don't need access to all of the tables and they don't need",
    "start": "1612900",
    "end": "1619020"
  },
  {
    "text": "to build thousand node systems for all of the tables they need to be build the systems at the size that they hold the",
    "start": "1619020",
    "end": "1624780"
  },
  {
    "text": "data that they're interested in I'll use the forward button and not the back",
    "start": "1624780",
    "end": "1630750"
  },
  {
    "text": "button okay so remember back to that data warehousing chart I showed you the very first one on the history of data",
    "start": "1630750",
    "end": "1636840"
  },
  {
    "text": "warehousing so the chart has evolved a little bit but not all that much on the left-hand side we have lots of great AWS",
    "start": "1636840",
    "end": "1644840"
  },
  {
    "text": "source systems and we're using Amazon DynamoDB right all of our critical systems inside",
    "start": "1644840",
    "end": "1652050"
  },
  {
    "text": "Amazon are moving to Amazon DynamoDB we're using Postgres for not non-critical systems",
    "start": "1652050",
    "end": "1658200"
  },
  {
    "text": "we're also interfacing with Kinesis that we can start that streaming environment and a lot of people have data stored",
    "start": "1658200",
    "end": "1664110"
  },
  {
    "text": "that they produce through a variety of means already an s3 we want to be able to tap into all of those and in the past",
    "start": "1664110",
    "end": "1671160"
  },
  {
    "text": "we kind of did what I'll call a log scraping method where we would go to each system and say give me all the rows that have changed since the last time I",
    "start": "1671160",
    "end": "1676800"
  },
  {
    "text": "went and checked with you and that environment worked okay but the system that we're going to be building out in",
    "start": "1676800",
    "end": "1682230"
  },
  {
    "text": "the future and right now that we have in beta with four different teams that will released early next year will be all",
    "start": "1682230",
    "end": "1687810"
  },
  {
    "text": "change data capture so all of these systems have changed data capture mechanisms we're going to basically tee",
    "start": "1687810",
    "end": "1693780"
  },
  {
    "text": "into the change data capture mechanisms that already exists that we can keep secondary systems up-to-date and we're",
    "start": "1693780",
    "end": "1699420"
  },
  {
    "text": "going to feed that basically streaming or mini-batch into the data into the data like once the data is in the data",
    "start": "1699420",
    "end": "1706590"
  },
  {
    "text": "like then we're going to spend in the next few slides talking about a new mechanism that we created to make it",
    "start": "1706590",
    "end": "1713190"
  },
  {
    "text": "easy for teams to populate their data Mart's so we'll come back to that in a second but basically teams will bring",
    "start": "1713190",
    "end": "1719670"
  },
  {
    "text": "their own cluster right or clusters and whether it be a EMR or redshift and",
    "start": "1719670",
    "end": "1725190"
  },
  {
    "text": "they'll bring them to the data lake they'll get their source systems and then they'll be able to run their queries against those and on the right",
    "start": "1725190",
    "end": "1731280"
  },
  {
    "text": "hand side that top figure is meant to represent services immediately below that is user community this would be people",
    "start": "1731280",
    "end": "1737610"
  },
  {
    "text": "bringing SQL or Python or Scala or SPARC whatever language that they like to the",
    "start": "1737610",
    "end": "1744240"
  },
  {
    "text": "the system of their choice and being able to ask any query that they would want on the data that they need we're",
    "start": "1744240",
    "end": "1749850"
  },
  {
    "text": "also using quick site for some graphic analysis we're using Amazon Athena as a",
    "start": "1749850",
    "end": "1755880"
  },
  {
    "text": "user interface into EMR systems and of course we've got lots of teams doing machine learning across the Amazon okay",
    "start": "1755880",
    "end": "1763290"
  },
  {
    "text": "so this is kind of how that data warehousing architecture of the past has evolved and coming back to one of the",
    "start": "1763290",
    "end": "1770490"
  },
  {
    "text": "original questions it's not really a choice between the data warehouse and Big Data maybe five years down the road",
    "start": "1770490",
    "end": "1776550"
  },
  {
    "text": "or ten years down the road we'll all converge but as it stands right now we really need both environments for all",
    "start": "1776550",
    "end": "1781860"
  },
  {
    "text": "the analysis that we want to do so what's an end it's taking the the beauty of redshift from the data warehousing",
    "start": "1781860",
    "end": "1786900"
  },
  {
    "text": "approach and combining it with the beauty of EMR and being able to get access to all of the big data techniques",
    "start": "1786900",
    "end": "1792180"
  },
  {
    "text": "that are going on in the industry and with one good copy of the data in the data Lake that's fully maintained and in",
    "start": "1792180",
    "end": "1798330"
  },
  {
    "text": "moving to real-time that sets up all of these systems to be dependent data Mart's and get all of their data",
    "start": "1798330",
    "end": "1803970"
  },
  {
    "text": "refreshed automatically from the data Lake now historically when you do large number of data Mart's that's where the",
    "start": "1803970",
    "end": "1809880"
  },
  {
    "text": "whole system kind of breaks down right keeping the data marts refreshed and having scores of data engineers running",
    "start": "1809880",
    "end": "1816270"
  },
  {
    "text": "around trying to keep your data marts up-to-date so let me give you a quick analogy I showed you this picture before",
    "start": "1816270",
    "end": "1822840"
  },
  {
    "text": "this is the Amazon webpage and when you click on something behind-the-scenes we",
    "start": "1822840",
    "end": "1829680"
  },
  {
    "text": "have an interaction in the interaction when you buy something when you click on the purchase button you are entering a",
    "start": "1829680",
    "end": "1836520"
  },
  {
    "text": "contract and that contract is a multi-party contract the seller is agreeing to sell something the buyer is",
    "start": "1836520",
    "end": "1843780"
  },
  {
    "text": "agreeing to buy something the shipper is agreeing to ship it at a certain price",
    "start": "1843780",
    "end": "1849420"
  },
  {
    "text": "and deliver it at a certain point in time there's tax implications there's tax subsystems all of these things go",
    "start": "1849420",
    "end": "1855150"
  },
  {
    "text": "into a purchase contract and all of the infrastructure to coordinate this deal is what the Amazon Web site does when we",
    "start": "1855150",
    "end": "1863850"
  },
  {
    "text": "set out to make the this new data Lake easy-to-use we knew that we're going to have a huge",
    "start": "1863850",
    "end": "1870230"
  },
  {
    "text": "number of data sets and we knew that we needed to help with what we call discovery and I'll come back and talk about discovery in a little bit but what",
    "start": "1870230",
    "end": "1877970"
  },
  {
    "text": "we wanted to do and this is kind of the original chart this is the vision amazon has the concept of working backwards and",
    "start": "1877970",
    "end": "1883490"
  },
  {
    "text": "this was the kind of the original vision chart of what we wanted to do from discovery and what you see here is",
    "start": "1883490",
    "end": "1888980"
  },
  {
    "text": "something that looks very much like the Amazon webpage but you will notice it's not products it's data sets and so you",
    "start": "1888980",
    "end": "1896450"
  },
  {
    "text": "can go to the search bar and you can type in the name of a table the name of a field the name of a business term and",
    "start": "1896450",
    "end": "1902780"
  },
  {
    "text": "you can hit search and we are going to show you the tables that match that from",
    "start": "1902780",
    "end": "1908810"
  },
  {
    "text": "there you can click on a table you can see the schema right and you can decide whether or not that's the table that",
    "start": "1908810",
    "end": "1915200"
  },
  {
    "text": "you're interested in and it contains the data that you're that you would like then you can click on the subscribe",
    "start": "1915200",
    "end": "1920930"
  },
  {
    "text": "button and when you click on the subscribe button it's going to ask where you want the data to go and you can give",
    "start": "1920930",
    "end": "1927620"
  },
  {
    "text": "the name of an EMR catalog or you can give the name of a redshift system and from that point forward if you have",
    "start": "1927620",
    "end": "1933380"
  },
  {
    "text": "access and permissions to read that data from that point forward every time somebody updates the data and the data Lake we will automatically update your",
    "start": "1933380",
    "end": "1940730"
  },
  {
    "text": "subscription in your system okay and we're doing it through this user interface that looks very much like the",
    "start": "1940730",
    "end": "1947360"
  },
  {
    "text": "Amazon website now behind the scenes right one of our principle engineers",
    "start": "1947360",
    "end": "1954260"
  },
  {
    "text": "made the analogy that we're really doing exactly the same thing that the website is doing there is a data producer there",
    "start": "1954260",
    "end": "1960170"
  },
  {
    "text": "is a data consumer and the subscription is the mechanism to document the relationship between the two and Big",
    "start": "1960170",
    "end": "1966530"
  },
  {
    "text": "Data technologies that's our team is going to be responsible for administrating that contract and so you",
    "start": "1966530",
    "end": "1973760"
  },
  {
    "text": "might wonder what goes into that contract well that's some of the work that we're doing right now but it's things like how frequently does the data",
    "start": "1973760",
    "end": "1980540"
  },
  {
    "text": "come from the source system is it a real-time stream is that mini batch it's every five minutes or is it once a day",
    "start": "1980540",
    "end": "1986860"
  },
  {
    "text": "what sort of support policy is on this data right the team that originates the",
    "start": "1986860",
    "end": "1992810"
  },
  {
    "text": "data will they take a if you call them between 8:00 and 5:00 we'll take they take the phone call and go work on",
    "start": "1992810",
    "end": "1998870"
  },
  {
    "text": "fixing it or will they support it 24 hours a day right the source team and the consumer",
    "start": "1998870",
    "end": "2005110"
  },
  {
    "text": "team get to decide what is the right thing for that data set and it's a contract and the other great thing about",
    "start": "2005110",
    "end": "2011890"
  },
  {
    "text": "the contract is its documented so now we know every producer and every consumer",
    "start": "2011890",
    "end": "2017890"
  },
  {
    "text": "downstream and we understand the relationship between the two and we can mine this data to see exactly what's",
    "start": "2017890",
    "end": "2023080"
  },
  {
    "text": "going on and who's using the data and if they want to make changes to the data or deprecated a particular table we can",
    "start": "2023080",
    "end": "2028720"
  },
  {
    "text": "look and see who are all the downstream consumers that might be affected so",
    "start": "2028720",
    "end": "2033600"
  },
  {
    "text": "we've done a little bit about the why we've done a little bit about the what and now I'm going to talk a little bit",
    "start": "2033929",
    "end": "2039610"
  },
  {
    "text": "about the how so in the state of chain we want to be able to collect data store",
    "start": "2039610",
    "end": "2046090"
  },
  {
    "text": "data discover subscribe deliver it and analyze and we'll go through each of these steps so the first thing is",
    "start": "2046090",
    "end": "2052810"
  },
  {
    "text": "collect and we want to have a value proposition that allows producers to want to put their data in the data link",
    "start": "2052810",
    "end": "2058868"
  },
  {
    "text": "and the value proposition has a couple of different things one is it has to be super easy so we talked about today",
    "start": "2058869",
    "end": "2065320"
  },
  {
    "text": "we're kind of intrusive on source systems and we log in maybe once maybe multiple times a day and we put extra",
    "start": "2065320",
    "end": "2072368"
  },
  {
    "text": "workload on it and say basically give me all your rows that have changed since the last time I wouldn't queried you right and that's a fairly expensive",
    "start": "2072369",
    "end": "2079480"
  },
  {
    "text": "query and can impact performance and so what we want to do is we're already doing the change data capture to support",
    "start": "2079480",
    "end": "2086080"
  },
  {
    "text": "the secondary system we want to tap into that change due to capture and basically be able to tee that off and send it",
    "start": "2086080",
    "end": "2092648"
  },
  {
    "text": "directly into the andis data lake so that makes it really simple as an",
    "start": "2092649",
    "end": "2097690"
  },
  {
    "text": "onboarding process the other key thing is we want to make it easy for teams that if they put data in the data lake",
    "start": "2097690",
    "end": "2104170"
  },
  {
    "text": "and they've data about if they validate that the data is correct right and we'll give them the tools to do that",
    "start": "2104170",
    "end": "2109599"
  },
  {
    "text": "validation will handle all the downstream consumers once they put the data in the data lake and said that it's",
    "start": "2109599",
    "end": "2115300"
  },
  {
    "text": "good they don't have to worry about whether they have one downstream customer or a thousand downstream customers we as Big Data technologies",
    "start": "2115300",
    "end": "2122050"
  },
  {
    "text": "will take care of it from that point on right and we would only go back to the source team if we questioned whether or",
    "start": "2122050",
    "end": "2127480"
  },
  {
    "text": "not the data is actually correct and we are working right now and we've got prototypes going on where we can go to",
    "start": "2127480",
    "end": "2134770"
  },
  {
    "text": "either RDS or Aurora Postgres we can get data from DynamoDB we can get data from",
    "start": "2134770",
    "end": "2140650"
  },
  {
    "text": "Kinesis streams and we can get data from s3 and load that data and keep it in in our andes data like the actual data lake",
    "start": "2140650",
    "end": "2150340"
  },
  {
    "text": "is based on the s3 it's highly durable and it's great on scale in terms of",
    "start": "2150340",
    "end": "2155350"
  },
  {
    "text": "scalability s3 has good permissions and we have put some extra permission levels on top of that so that we can make sure",
    "start": "2155350",
    "end": "2161740"
  },
  {
    "text": "we're tracking what sort of data is going into these tables and make sure that the right people have access to it and the people who don't have axes of",
    "start": "2161740",
    "end": "2168130"
  },
  {
    "text": "access to it are not able to get at it we're also producing tools that will",
    "start": "2168130",
    "end": "2173200"
  },
  {
    "text": "allow teams to do data quality quality checks so that when they write data into the data Lake that they can at that",
    "start": "2173200",
    "end": "2180430"
  },
  {
    "text": "point in time validate that it is the correct data and that the data that they want there is the data that is there and",
    "start": "2180430",
    "end": "2186490"
  },
  {
    "text": "the other thing is we put in software that allows us to validate schemas so if a table does have a schema we want to",
    "start": "2186490",
    "end": "2192700"
  },
  {
    "text": "make sure that the data that you're putting in works against that schema so that although the down streams are able to successfully use it in terms of",
    "start": "2192700",
    "end": "2201490"
  },
  {
    "text": "discovery again I showed you that we call it the hoot interface the food is the website internally that we use to",
    "start": "2201490",
    "end": "2207640"
  },
  {
    "text": "allow teams to go and find the information that it is that they're looking for so again it's modeled after",
    "start": "2207640",
    "end": "2213490"
  },
  {
    "text": "the Amazon web page you can go in and very quickly find the information that you're looking for and we want to make",
    "start": "2213490",
    "end": "2219310"
  },
  {
    "text": "sure that you there's lots of useful information about those data sets so some of the stuff that we have today is",
    "start": "2219310",
    "end": "2224500"
  },
  {
    "text": "the full schema you can see what the size of the tables are in the future we will be adding things like in the the",
    "start": "2224500",
    "end": "2230380"
  },
  {
    "text": "looking forward vision we had the 5-star rating system that you know from the website we want people to be able to",
    "start": "2230380",
    "end": "2235810"
  },
  {
    "text": "rate datasets and put comments at data sets it's very important for say the machine learning community to say this",
    "start": "2235810",
    "end": "2241180"
  },
  {
    "text": "is a validated data set for the following functions and be able to track that and we want people to be able to go",
    "start": "2241180",
    "end": "2247030"
  },
  {
    "text": "in and add information like that it adds a lot of value to the entire ecosystem",
    "start": "2247030",
    "end": "2252180"
  },
  {
    "text": "in the other key thing about discovery is we want to set up a place where producers can communicate with the",
    "start": "2252180",
    "end": "2258520"
  },
  {
    "text": "consumers right so they can go in and see who are the downstreams who are using the data set that they have",
    "start": "2258520",
    "end": "2263530"
  },
  {
    "text": "produced and that the people who are consumers of it can find out if theirs",
    "start": "2263530",
    "end": "2268750"
  },
  {
    "text": "a problem with the data set or they're questioning whether or not some of the data is accurate that they know who to contact and be able to go back to the",
    "start": "2268750",
    "end": "2275260"
  },
  {
    "text": "source team and be able to work with them on what's going on once you have",
    "start": "2275260",
    "end": "2280960"
  },
  {
    "text": "found the data set you're looking for you click on subscribe' and once you click on subscribe' again all of the",
    "start": "2280960",
    "end": "2287770"
  },
  {
    "text": "data from that point forward that goes into the the @ table inside the data lake is going to get replicated to all",
    "start": "2287770",
    "end": "2293560"
  },
  {
    "text": "of the systems that have expressed interest in that that particular table and some of the work that we have done",
    "start": "2293560",
    "end": "2298600"
  },
  {
    "text": "is we allow teams to we've created AWS CloudFormation templates so people can",
    "start": "2298600",
    "end": "2304420"
  },
  {
    "text": "very quickly set up a system that has all of the right security and permissions and all of all of that sort",
    "start": "2304420",
    "end": "2310060"
  },
  {
    "text": "of encryption all of that sort of good stuff and use that that cloud formation template and then immediately be able to",
    "start": "2310060",
    "end": "2316030"
  },
  {
    "text": "start loading data into that system we have not quite scripted this all out but",
    "start": "2316030",
    "end": "2321160"
  },
  {
    "text": "one of the things that we will be doing in the future particularly for some of the systems that smaller teams that will",
    "start": "2321160",
    "end": "2326830"
  },
  {
    "text": "need help moving off of the the legacy data warehouse environment we're actually I think we have all of",
    "start": "2326830",
    "end": "2332290"
  },
  {
    "text": "the api's where we could script creating a system going through the queries that they've run for the last year finding",
    "start": "2332290",
    "end": "2338860"
  },
  {
    "text": "the tables that they have accessed creating the subscriptions programmatically and loading the data",
    "start": "2338860",
    "end": "2345220"
  },
  {
    "text": "all of the data that they would be interested in onto their data Mart then being able to go get all the queries",
    "start": "2345220",
    "end": "2350560"
  },
  {
    "text": "that they've got scheduled to be running and run it through we use the AWS tools for the schema conversion tool and in",
    "start": "2350560",
    "end": "2356800"
  },
  {
    "text": "the query convertor and automatically run all of the queries through that tool it will not get a hundred percent you",
    "start": "2356800",
    "end": "2363340"
  },
  {
    "text": "may have been using functions that were specific to the legacy environment it may not convert a hundred percent of the",
    "start": "2363340",
    "end": "2368500"
  },
  {
    "text": "queries successfully but we're seeing very good rates 60 80 percent of the queries convert automatically in this",
    "start": "2368500",
    "end": "2373720"
  },
  {
    "text": "new environment so that's some of the work that that we'll be working on in the not-too-distant future once we've",
    "start": "2373720",
    "end": "2382240"
  },
  {
    "text": "delivered the data we want to make it available and again we want to keep it in sync with anything that's going on",
    "start": "2382240",
    "end": "2388150"
  },
  {
    "text": "inside the data Lake and a key aspect is we want to be able to allow ourselves to",
    "start": "2388150",
    "end": "2393370"
  },
  {
    "text": "monitor what's going on and we want to allow the owner of the data Mart system to be able to do that and the data",
    "start": "2393370",
    "end": "2398920"
  },
  {
    "text": "movement can actually come in two forms one is in particular for redshift we're doing",
    "start": "2398920",
    "end": "2404060"
  },
  {
    "text": "this right now we're loading it into the redshift file system and so we will move all of the data into that we do allow",
    "start": "2404060",
    "end": "2410030"
  },
  {
    "text": "filtering so you can say instead of 25 years worth of data I really am only interested in the last six months or a year and so you can take",
    "start": "2410030",
    "end": "2416570"
  },
  {
    "text": "subsets of the data but what we're really looking forward to and what we do with EMR today is metadata only sinks",
    "start": "2416570",
    "end": "2423320"
  },
  {
    "text": "and so the data stays in the data lake we don't actually move the data into the target system we just move where the",
    "start": "2423320",
    "end": "2429740"
  },
  {
    "text": "blocks are on s3 into the catalog and",
    "start": "2429740",
    "end": "2435230"
  },
  {
    "text": "once the data is there then the teams can use either redshift or EMR and all of their glory and be able to do any of",
    "start": "2435230",
    "end": "2441920"
  },
  {
    "text": "the work that you would expect in those environments and the other key thing and I mentioned this before but I'll",
    "start": "2441920",
    "end": "2448040"
  },
  {
    "text": "emphasize it again we want each business team to be able to size and control their own system and control their own",
    "start": "2448040",
    "end": "2453740"
  },
  {
    "text": "environment so there is not one centralized set of resources that we are trying to manage to the peak of all of",
    "start": "2453740",
    "end": "2459350"
  },
  {
    "text": "the different teams each team has complete control over their environment they get to optimize the cost if they",
    "start": "2459350",
    "end": "2464810"
  },
  {
    "text": "need it to run faster they can pay for it to run faster they get to determine what their SLA s and what their business needs are and they can scale to meet",
    "start": "2464810",
    "end": "2471860"
  },
  {
    "text": "their own peaks which may be independent of other teams Peaks",
    "start": "2471860",
    "end": "2476380"
  },
  {
    "text": "and so again that just kind of summarized this is the value chain of how we see the environment that we're",
    "start": "2478030",
    "end": "2483950"
  },
  {
    "text": "trying to set up and have set up and let me let me first go back and take a look",
    "start": "2483950",
    "end": "2488990"
  },
  {
    "text": "and see some of the goals that we set out and hopefully you'll agree with me that that we're on the path to validate",
    "start": "2488990",
    "end": "2495200"
  },
  {
    "text": "these one will the scale with the business yes because we can handle effectively an infinite amount of data",
    "start": "2495200",
    "end": "2501020"
  },
  {
    "text": "marts coming off of the data lake we're using all AWS technologies we do both",
    "start": "2501020",
    "end": "2506540"
  },
  {
    "text": "SQL and the programmatic approach and we can do both types of bring your own cluster and bring your own queries in",
    "start": "2506540",
    "end": "2512180"
  },
  {
    "text": "this environment where are we today how much of this is real well the answer is",
    "start": "2512180",
    "end": "2518420"
  },
  {
    "text": "a lot of it there's a lot of features that we want to continue to add but today we have twenty thousand tables",
    "start": "2518420",
    "end": "2524690"
  },
  {
    "text": "that are maintained at the same frequency they were in our legacy environment the fun thing for me is we",
    "start": "2524690",
    "end": "2531050"
  },
  {
    "text": "are starting to see people who never had data in the legacy data warehouse there's put data in the data link right and so",
    "start": "2531050",
    "end": "2538790"
  },
  {
    "text": "we're starting to see just a groundswell it's relatively small at this point but",
    "start": "2538790",
    "end": "2543980"
  },
  {
    "text": "we expect this to continue to grow we release this environment in the",
    "start": "2543980",
    "end": "2549590"
  },
  {
    "text": "subscriptions environment for beta in March and we made it generally available in June and here we are in November and",
    "start": "2549590",
    "end": "2556369"
  },
  {
    "text": "we have 950 systems are already using the subscriptions mechanism and they're",
    "start": "2556369",
    "end": "2564260"
  },
  {
    "text": "sinking about 20,000 total tables and we do 40 about 40,000 sink jobs a day",
    "start": "2564260",
    "end": "2570109"
  },
  {
    "text": "because a lot of the tables have multiple sink jobs in terms of our legacy environment the new environment",
    "start": "2570109",
    "end": "2578000"
  },
  {
    "text": "it took three years to run a hundred thousand queries a day in the new environment right that was 2014 2015 and",
    "start": "2578000",
    "end": "2586160"
  },
  {
    "text": "2016 in this year alone so far this year we have grown that from a hundred to",
    "start": "2586160",
    "end": "2591740"
  },
  {
    "text": "three hundred thousand so we effectively have two hundred percent growth we've tripled the size and the amount of work that's going on in the new environment",
    "start": "2591740",
    "end": "2598070"
  },
  {
    "text": "and while that seems like a lot to me it's nothing to compare to what we're going to do in the next year right as we",
    "start": "2598070",
    "end": "2604730"
  },
  {
    "text": "really transition into this new environment and this is my last chart",
    "start": "2604730",
    "end": "2610550"
  },
  {
    "text": "and we'll have time for some questions on the left-hand side you may be familiar with the virtuous cycle of",
    "start": "2610550",
    "end": "2616940"
  },
  {
    "text": "Amazon and amazon.com the idea here is that a positive customer experience",
    "start": "2616940",
    "end": "2622630"
  },
  {
    "text": "increases traffic traffic attracts sellers into the marketplace attracting",
    "start": "2622630",
    "end": "2628670"
  },
  {
    "text": "sellers into the marketplace creates additional selection as we see this wheel start to go around we can",
    "start": "2628670",
    "end": "2635630"
  },
  {
    "text": "lower the cost structure in the lower cost structure allows us to lower prices and this is the virtuous cycle and we",
    "start": "2635630",
    "end": "2642349"
  },
  {
    "text": "see the same virtuous cycle in terms of our data Lake and analytics inside Amazon we think a positive customer",
    "start": "2642349",
    "end": "2649640"
  },
  {
    "text": "experience will increase data sharing data sharing will increase the number of providers who are using and putting data",
    "start": "2649640",
    "end": "2655910"
  },
  {
    "text": "into the environment as that happens we will get more data set diversity and we will get teams that had never used the",
    "start": "2655910",
    "end": "2662089"
  },
  {
    "text": "legacy environment to start to put data in in the andes data lake we are already seeing operational efficiencies and the",
    "start": "2662089",
    "end": "2668960"
  },
  {
    "text": "tea has really come along and a great and improved our pace of innovation and those things the flywheel is starting to",
    "start": "2668960",
    "end": "2675600"
  },
  {
    "text": "turn and in the next year it really is going to take off and so that's that's",
    "start": "2675600",
    "end": "2680850"
  },
  {
    "text": "my story and I want to give thanks to we've got quite a few people here if you have some more technical questions I'm",
    "start": "2680850",
    "end": "2687420"
  },
  {
    "text": "happy to take them but we've got the real experts sitting here at the front of the room and I think that we can handle anything that you can throw at us",
    "start": "2687420",
    "end": "2694790"
  },
  {
    "text": "question yeah so the question is ETL alt",
    "start": "2699470",
    "end": "2713910"
  },
  {
    "text": "and schema evolution that's one of the things that we are working right now in",
    "start": "2713910",
    "end": "2719070"
  },
  {
    "text": "fact as I was reading email earlier today we have a team that is working on",
    "start": "2719070",
    "end": "2724280"
  },
  {
    "text": "basically a set of rules that we can apply we we have the rules of the past",
    "start": "2724280",
    "end": "2729360"
  },
  {
    "text": "and we're finding that they're insufficient for the the new environment and so we are working right now to be",
    "start": "2729360",
    "end": "2735120"
  },
  {
    "text": "able to determine you know what is the right way to do it and how that flows through our entire system and so we have",
    "start": "2735120",
    "end": "2740820"
  },
  {
    "text": "answers today we're not happy with those answers and we're working on the next generation of that so it's a very interesting problem question yeah so the",
    "start": "2740820",
    "end": "2756390"
  },
  {
    "text": "question is did we build it from the ground up and I would say it's a mix there were things from our existing",
    "start": "2756390",
    "end": "2762660"
  },
  {
    "text": "legacy environment that we're definitely using we didn't feel and I'll give you an example we didn't feel that we could",
    "start": "2762660",
    "end": "2767700"
  },
  {
    "text": "change all of the load infrastructure and move all of the consumers at the same time right we just felt that that",
    "start": "2767700",
    "end": "2774000"
  },
  {
    "text": "would be too much churn so we left the load infrastructure in place and that has some problems but that's what we",
    "start": "2774000",
    "end": "2779220"
  },
  {
    "text": "chose to do we've got all the data landed in the data Lake and effectively that becomes our new API for the data",
    "start": "2779220",
    "end": "2784590"
  },
  {
    "text": "and so now consumers are migrating from the old environment to the data and the data lake and then in parallel you heard",
    "start": "2784590",
    "end": "2791100"
  },
  {
    "text": "me talk about moving from the kind of the log scraping environment to the change data capture environment so over",
    "start": "2791100",
    "end": "2796470"
  },
  {
    "text": "the next six months to a year we will be going and kind of reengineering all of that data feed into the environment but",
    "start": "2796470",
    "end": "2802350"
  },
  {
    "text": "the downstream Zoomers we're not going to see that they're simply going to see that the more up-to-date data in the andes data",
    "start": "2802350",
    "end": "2808380"
  },
  {
    "text": "lake yeah i was gonna say did that answer your question",
    "start": "2808380",
    "end": "2814010"
  },
  {
    "text": "mm-hmm yes so the question is how does",
    "start": "2814010",
    "end": "2822990"
  },
  {
    "text": "it affect the source systems right now we have really have not changed that much and so we're still doing kind of",
    "start": "2822990",
    "end": "2829020"
  },
  {
    "text": "what I'll call the log striping methodology but as we change the CDC we're actually going to take work off of",
    "start": "2829020",
    "end": "2834270"
  },
  {
    "text": "the source systems yeah so it will be a positive benefit for them there was a",
    "start": "2834270",
    "end": "2841620"
  },
  {
    "text": "question over here yep",
    "start": "2841620",
    "end": "2851810"
  },
  {
    "text": "yeah so think of the the debt the datamart as effectively a cache of data right and",
    "start": "2860810",
    "end": "2869070"
  },
  {
    "text": "so it is a read-only cache the data could be rested in s3 or we could put it",
    "start": "2869070",
    "end": "2874320"
  },
  {
    "text": "in the filesystem whether it be HDFS or the redshift filesystem but it's basically a read-only copy and so we're",
    "start": "2874320",
    "end": "2880470"
  },
  {
    "text": "going to win the data becomes available we're going to update that system we have mechanisms in place that if",
    "start": "2880470",
    "end": "2886470"
  },
  {
    "text": "somebody says I want to run a query every night after the data gets refreshed we will monitor that and we",
    "start": "2886470",
    "end": "2892829"
  },
  {
    "text": "won't kick off the query job until the load jobs have completed and so that",
    "start": "2892829",
    "end": "2897900"
  },
  {
    "text": "allows us to kind of maintain the integrity and write an in the scheduling and so we will refresh the data on the",
    "start": "2897900",
    "end": "2904800"
  },
  {
    "text": "data Mart will run the queries when the data has been refreshed for the following day right or hour or whatever the time",
    "start": "2904800",
    "end": "2911579"
  },
  {
    "text": "period that people want and people can create new data sets in their data Mart and you know join tables together and",
    "start": "2911579",
    "end": "2918030"
  },
  {
    "text": "creats create something new but what we want them to do is to write that back out to the data like particularly if",
    "start": "2918030",
    "end": "2923460"
  },
  {
    "text": "some other team is going to make use of it did that answer your question not not",
    "start": "2923460",
    "end": "2928950"
  },
  {
    "text": "quite try me again",
    "start": "2928950",
    "end": "2932240"
  },
  {
    "text": "yeah and the answer is it can depend on one what was in the legacy environment",
    "start": "2936470",
    "end": "2942300"
  },
  {
    "text": "into what people want on their in their data Mart so it could be star schema it",
    "start": "2942300",
    "end": "2947790"
  },
  {
    "text": "could be a lot of different things it could be a more normalized model different tables have different access",
    "start": "2947790",
    "end": "2952980"
  },
  {
    "text": "patterns and we've done different solutions for performance both in the old environment and in the new environment was that closer to the",
    "start": "2952980",
    "end": "2959250"
  },
  {
    "text": "answer you were looking for it okay yes",
    "start": "2959250",
    "end": "2964130"
  },
  {
    "text": "yeah some of the things that we have been working on include the schema validation check we have also been going",
    "start": "2969739",
    "end": "2977549"
  },
  {
    "text": "back to the legacy environment and comparing data sets to the legacy environment we've been working more",
    "start": "2977549",
    "end": "2985049"
  },
  {
    "text": "recently with a machine the machine learning teams who have created some more kind of streaming real-time data",
    "start": "2985049",
    "end": "2991109"
  },
  {
    "text": "quality checks and so we're working with them right now to kind of institute those so those would be looking at",
    "start": "2991109",
    "end": "2996390"
  },
  {
    "text": "things like well two days ago you loaded 50,000 rows and yesterday you loaded 50,000 rows and today you loaded 30,000",
    "start": "2996390",
    "end": "3002960"
  },
  {
    "text": "rows is that a reasonable thing or somebody check on that and we're trying to do some machine science and that's",
    "start": "3002960",
    "end": "3008630"
  },
  {
    "text": "that's a simple example and we're looking you know if people put ranges on data can't a max value in a min value we",
    "start": "3008630",
    "end": "3015710"
  },
  {
    "text": "check against those things so I would say it's relatively simplistic but we are really moving into the machine",
    "start": "3015710",
    "end": "3020839"
  },
  {
    "text": "learning world to try to do some more sophisticated checks did that answer your question great question here yes",
    "start": "3020839",
    "end": "3035079"
  },
  {
    "text": "you know in the history kind of the legacy environment it was mostly preset",
    "start": "3042400",
    "end": "3047560"
  },
  {
    "text": "we do allow teams to do different manipulations of the data when it goes into their data Mart so one example that",
    "start": "3047560",
    "end": "3054170"
  },
  {
    "text": "I gave prior was you know pick do me six months six months worth of data not 25 years worth of data right because I",
    "start": "3054170",
    "end": "3060440"
  },
  {
    "text": "don't want to store all of that my query set doesn't need that we also allow people to pick sort and distribution keys and things like that and we're",
    "start": "3060440",
    "end": "3068150"
  },
  {
    "text": "always interested in learning what other performance tricks teams might be looking for so that we could incorporate that in and make that part of the",
    "start": "3068150",
    "end": "3074270"
  },
  {
    "text": "subscription process as well yeah",
    "start": "3074270",
    "end": "3080770"
  },
  {
    "text": "mm-hmm yeah in that's one of the places again",
    "start": "3092059",
    "end": "3100180"
  },
  {
    "text": "that's very big inside Amazon but people have been doing that with kind of the source systems and setting up their own",
    "start": "3100180",
    "end": "3105490"
  },
  {
    "text": "infrastructure for that and they have not used the historic the legacy data warehouse just would not have worked in",
    "start": "3105490",
    "end": "3110770"
  },
  {
    "text": "that environment and so in the world that I came from there was a lot more real-time data warehousing than currently exists at",
    "start": "3110770",
    "end": "3117310"
  },
  {
    "text": "Amazon but I see as we go forward that we're going to kind of be able to bridge those worlds and there's some design patterns like being able to not only",
    "start": "3117310",
    "end": "3124030"
  },
  {
    "text": "have Kinesis land data in there but have Kinesis be able to feed other downstream systems and I don't know that we're",
    "start": "3124030",
    "end": "3129940"
  },
  {
    "text": "going to force we're not going to force people to go back and rewrite existing systems particularly when they're working but I think that will give some",
    "start": "3129940",
    "end": "3134980"
  },
  {
    "text": "other design patterns and make it available that haven't been available in the past question back here yes",
    "start": "3134980",
    "end": "3149430"
  },
  {
    "text": "yeah so the question is about SaaS and it's an excellent one what we are",
    "start": "3160830",
    "end": "3166290"
  },
  {
    "text": "finding is that the legacy data warehouse environment had a lot of problems in terms of latency and getting",
    "start": "3166290",
    "end": "3172080"
  },
  {
    "text": "these very large data sets processed and so by moving a lot of that work to redshift we have greatly shortened the",
    "start": "3172080",
    "end": "3179160"
  },
  {
    "text": "pipeline's and even though there may be an extra hop to be able to get the data",
    "start": "3179160",
    "end": "3184350"
  },
  {
    "text": "out into the data Mart we are finding that having moved the in the",
    "start": "3184350",
    "end": "3189840"
  },
  {
    "text": "infrastructure of curating the data into redshift has bought us enough time to be able to still meet the SLA s that were",
    "start": "3189840",
    "end": "3196230"
  },
  {
    "text": "there historically now I put a P with those SL A's when I started some of the",
    "start": "3196230",
    "end": "3202740"
  },
  {
    "text": "SLA some of the key tables wouldn't show up until 2:00 or 3:00 in the afternoon you know and if you've got really",
    "start": "3202740",
    "end": "3208200"
  },
  {
    "text": "expensive data scientists right at 8 o'clock in the morning and they can't get their data to 2:00 or 3:00 in the afternoon that's obviously a problem and",
    "start": "3208200",
    "end": "3215310"
  },
  {
    "text": "we're now seeing some of those same data sets come back much before 8:00 in the morning with some of the work that we've",
    "start": "3215310",
    "end": "3220740"
  },
  {
    "text": "done and so we're very aware of that we have a lot of monitoring mechanisms to ensure that the SLA s and we're working",
    "start": "3220740",
    "end": "3226950"
  },
  {
    "text": "on enhancing those mechanisms but right now we think that we bought enough time compared to the past infrastructure that",
    "start": "3226950",
    "end": "3232650"
  },
  {
    "text": "we're ok the other thing is as we start to stream the data into the data lake we",
    "start": "3232650",
    "end": "3238110"
  },
  {
    "text": "don't need to do things on a 24 hour batch basis which has been the history and so we won't be doing one huge data",
    "start": "3238110",
    "end": "3243780"
  },
  {
    "text": "set that takes a long time we can be doing it incrementally throughout the day and that also will help in the very",
    "start": "3243780",
    "end": "3249840"
  },
  {
    "text": "back yes",
    "start": "3249840",
    "end": "3254600"
  },
  {
    "text": "yeah we're using it as a quasi hdf we're using s3 as a quasi HDFS file system so",
    "start": "3267570",
    "end": "3274800"
  },
  {
    "text": "that's one of the key capabilities of the EMR is that you don't have to move the data from the data lake into HDFS on",
    "start": "3274800",
    "end": "3281010"
  },
  {
    "text": "on the nodes and so when you run a query we're effectively reaching out to the data like and reading the data in there",
    "start": "3281010",
    "end": "3287040"
  },
  {
    "text": "and so when what we're doing is we're pop like populating the glue the AWS data catalog with the information about",
    "start": "3287040",
    "end": "3293910"
  },
  {
    "text": "where the blocks are and s3 and so we populate the catalog with the information about the blocks not",
    "start": "3293910",
    "end": "3299760"
  },
  {
    "text": "actually move the data into HDFS did that answer your question",
    "start": "3299760",
    "end": "3304580"
  },
  {
    "text": "yeah I think that's a little bit more complex question maybe we can talk offline afterwards a lot of the time",
    "start": "3314690",
    "end": "3320400"
  },
  {
    "text": "what we are doing and what we will be doing is creating a compacted data set that will be kind of optimized for both",
    "start": "3320400",
    "end": "3326910"
  },
  {
    "text": "spectrum and for the the EMR solution this question yeah",
    "start": "3326910",
    "end": "3337578"
  },
  {
    "text": "right now it's an internal tool that I will tell you in our partnership with some of the AWS people and some of the",
    "start": "3341220",
    "end": "3346980"
  },
  {
    "text": "field people from AWS see some value in that for other customers and so that's",
    "start": "3346980",
    "end": "3352619"
  },
  {
    "text": "one of the things that we will be working with them on I'm not going to give you a timeline or anything like that but I can tell you that you know",
    "start": "3352619",
    "end": "3359190"
  },
  {
    "text": "I've been meeting with on a continual basis but just yesterday as a data point and they're very interested in some of",
    "start": "3359190",
    "end": "3364440"
  },
  {
    "text": "that technology that we've been working on how about over here",
    "start": "3364440",
    "end": "3369140"
  },
  {
    "text": "yeah yes yeah that's a good question so",
    "start": "3371480",
    "end": "3385829"
  },
  {
    "text": "they're going to write the data back out to the data like they would post that as a transaction that our internal monitoring software would be able to",
    "start": "3385829",
    "end": "3391920"
  },
  {
    "text": "pick up and see and then it would look to see what contracts are on that new data set and be able to allow other down",
    "start": "3391920",
    "end": "3397859"
  },
  {
    "text": "streams to be able to trigger off of that and so we do have kind of our historic scheduling system that we have",
    "start": "3397859",
    "end": "3403650"
  },
  {
    "text": "been enhancing for this and that would handle all of those kind of transactions in that coordination",
    "start": "3403650",
    "end": "3410180"
  },
  {
    "text": "what we would do is that we would show the immediate predecessor and the immediate successors but one of the things that we're working on is to be",
    "start": "3417599",
    "end": "3424200"
  },
  {
    "text": "able to trace that back all the way to the source systems right and be able to show what the entire pipeline looks like",
    "start": "3424200",
    "end": "3429480"
  },
  {
    "text": "and be able to show the entire lineage we're not there today but that's a very key thing that we'll be working on in",
    "start": "3429480",
    "end": "3435539"
  },
  {
    "text": "2018 how about back here please",
    "start": "3435539",
    "end": "3441859"
  },
  {
    "text": "Yeah right now so the question is about regionalization right now we are deployed to a single region within that single region we do",
    "start": "3448160",
    "end": "3454640"
  },
  {
    "text": "have sub regions right and so the data can be separated out by that and that's another project that we will be working",
    "start": "3454640",
    "end": "3460520"
  },
  {
    "text": "on in the not-too-distant future question absolutely well in the redshift",
    "start": "3460520",
    "end": "3482660"
  },
  {
    "text": "world today so the question is about partition collisions and a great example would be if you're looking at transact transactions the team that manages the",
    "start": "3482660",
    "end": "3489950"
  },
  {
    "text": "vendors is probably going to want it distributed by vendor and the team that manages customers is probably the one it distributed by customer is it just a",
    "start": "3489950",
    "end": "3496220"
  },
  {
    "text": "really simple example and for performance reasons both of them are right and so we could create another",
    "start": "3496220",
    "end": "3502339"
  },
  {
    "text": "copy of the data partition differently that's one solution or when a team reads it in they can read it in with the difference at a distribution Keys yeah",
    "start": "3502339",
    "end": "3513400"
  },
  {
    "text": "how about over here sir yeah so the",
    "start": "3513400",
    "end": "3522440"
  },
  {
    "text": "question is on CDC and the answer is there's a variety right so post Chris",
    "start": "3522440",
    "end": "3528289"
  },
  {
    "text": "has a set of tools our legacy environment has a set of tools and we are able to tap into the Dynamo and I",
    "start": "3528289",
    "end": "3536059"
  },
  {
    "text": "don't know that there's a public tool to do that we have an internal tool to do that and be able to get the information",
    "start": "3536059",
    "end": "3541309"
  },
  {
    "text": "coming out of dynamo as the the records are being transacted and that'll be something else that we would be working",
    "start": "3541309",
    "end": "3546950"
  },
  {
    "text": "with for on the AWS side to make sure they have that facility for everybody thank you yes",
    "start": "3546950",
    "end": "3558309"
  },
  {
    "text": "[Music] yeah one of our solution architects has",
    "start": "3559670",
    "end": "3565369"
  },
  {
    "text": "basically said don't think of as a table anymore think of it as an event stream right and I think that's where you're",
    "start": "3565369",
    "end": "3570410"
  },
  {
    "text": "going with your question is it changed it to capture or is it really kind of each row at an individual point in time",
    "start": "3570410",
    "end": "3576670"
  },
  {
    "text": "yeah well and that ties back to the",
    "start": "3576670",
    "end": "3583790"
  },
  {
    "text": "question that we were asking over here that was asked over here so schema evolution right now we would pick one of",
    "start": "3583790",
    "end": "3590510"
  },
  {
    "text": "the source environment so it might be redshift it might be EMR it might be our legacy environment you can go and make the change there and then we can rebuild",
    "start": "3590510",
    "end": "3597140"
  },
  {
    "text": "the table in the data like that's one option but we're not happy with that and so one of the things that we're working",
    "start": "3597140",
    "end": "3602720"
  },
  {
    "text": "on right now is a true evolution scheme where basically we would create two copies of the table right you would have",
    "start": "3602720",
    "end": "3608690"
  },
  {
    "text": "the one that you're currently running on inactive queries could continue to run while we're doing whatever manipulation",
    "start": "3608690",
    "end": "3613849"
  },
  {
    "text": "needs to be done for the schema evolution we could repopulate that and then we do a table flip all right",
    "start": "3613849",
    "end": "3621800"
  },
  {
    "text": "I think officially I'm happy to stick around and I know the theme here would be happy to stick around if you have follow-on questions I'll take one last",
    "start": "3621800",
    "end": "3628190"
  },
  {
    "text": "one yeah",
    "start": "3628190",
    "end": "3635800"
  },
  {
    "text": "yeah so a couple different questions there in general spectrum what do we see",
    "start": "3647810",
    "end": "3654210"
  },
  {
    "text": "is the value we see the value as we don't have to load the data into a lot of different data Mart's right and",
    "start": "3654210",
    "end": "3660930"
  },
  {
    "text": "people would be able to for an infrequently used table right they would be able to leave it in the data lake and",
    "start": "3660930",
    "end": "3667380"
  },
  {
    "text": "not have to load it into their environment some of these data sets are really really large and so somebody may",
    "start": "3667380",
    "end": "3674280"
  },
  {
    "text": "up the size of the red shift environment just to be able to hold the data and not",
    "start": "3674280",
    "end": "3679650"
  },
  {
    "text": "need all of the compute that goes along with it with spectrum we can take the larger tables and we can make them available",
    "start": "3679650",
    "end": "3685670"
  },
  {
    "text": "through spectrum and then teams would be able to use a smaller redshift footprint and be able to get access to all of the",
    "start": "3685670",
    "end": "3692790"
  },
  {
    "text": "data through spectrum did that answer your question partitioning is another level though",
    "start": "3692790",
    "end": "3698400"
  },
  {
    "text": "that we would have to talk about all right thank you all very much I really appreciate the great questions and again",
    "start": "3698400",
    "end": "3708599"
  },
  {
    "text": "thank you very much for coming out on a Wednesday night",
    "start": "3708599",
    "end": "3713029"
  }
]
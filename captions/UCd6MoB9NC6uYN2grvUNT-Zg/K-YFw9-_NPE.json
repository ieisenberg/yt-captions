[
  {
    "text": "well good afternoon everyone that is how you don't want to start a reinvent talk apologies about that I thought it",
    "start": "5680",
    "end": "12000"
  },
  {
    "text": "started at 2:00 I just got told it starts at quarter past so let's see how this goes I was in the speaker room",
    "start": "12000",
    "end": "17720"
  },
  {
    "text": "preparing um so I'm Dave Brown I'm the director of elastic load balancing uh I've been with Amazon for just over a",
    "start": "17720",
    "end": "24039"
  },
  {
    "text": "little little over seven years now uh I started off with the Amazon ec2 team in Cape Town South Africa um back in the",
    "start": "24039",
    "end": "30359"
  },
  {
    "text": "days when even the ec2 team was wondering what exactly were we building and how was this thing going to turn out",
    "start": "30359",
    "end": "36079"
  },
  {
    "text": "um about 2 and a half years ago I moved to Seattle um where I am now and I've been leading the the elb team for about",
    "start": "36079",
    "end": "41879"
  },
  {
    "text": "the last two years so this is a deep dive session into elb and uh we're going to do a couple of things we're going to",
    "start": "41879",
    "end": "48320"
  },
  {
    "text": "cover some of the basics on elb very very briefly I promise I know it's a 400 level and then we're going to go deeper",
    "start": "48320",
    "end": "54800"
  },
  {
    "text": "than I think we've been before publicly uh on some of the areas of elb so in some of the sections I think you say hey",
    "start": "54800",
    "end": "60280"
  },
  {
    "text": "I know about health checks or I know about this but listen for the Little Gems um what I'm trying to do here is",
    "start": "60280",
    "end": "65799"
  },
  {
    "text": "expose a lot of the internal details that I think are important to developers things like um do we persist health",
    "start": "65799",
    "end": "71400"
  },
  {
    "text": "check connections those sorts of things so we give you a lot of that information and then I think we've we we've learned a lot uh on the elb team over the last",
    "start": "71400",
    "end": "79240"
  },
  {
    "text": "two years about how to run a service at scale elb as you can imagine is is is a",
    "start": "79240",
    "end": "84280"
  },
  {
    "text": "fairly large service um sure a lot of you guys have load balances with us um and making sure that those load balances",
    "start": "84280",
    "end": "90079"
  },
  {
    "text": "are highly available for each individual customer is critically important and I'll share some of the details on exactly how we do",
    "start": "90079",
    "end": "96479"
  },
  {
    "text": "that so elastic load balancing we'll spend two seconds here is a load balancer for Amazon",
    "start": "96479",
    "end": "103960"
  },
  {
    "text": "ec2 some of the benefits uh we we are elastic um the idea behind that is really you create a load balancer you",
    "start": "103960",
    "end": "110680"
  },
  {
    "text": "don't have to create another load balancer if you scale the load balancer will scale up to meet the demands of your application and we do that by",
    "start": "110680",
    "end": "117119"
  },
  {
    "text": "watching throughput on the load balancer we watch number of connections memory all the different metrics that go into",
    "start": "117119",
    "end": "122960"
  },
  {
    "text": "making sure that we need a scale to handle your request load secondly we're secure big part of what I'm going to",
    "start": "122960",
    "end": "128280"
  },
  {
    "text": "talk about later Is How We Do SSL we want to take care of the mark of handling SSL so that that you can worry",
    "start": "128280",
    "end": "134040"
  },
  {
    "text": "more about dealing with the the details of your application and less about SSL which has become somewhat of a Hot Topic",
    "start": "134040",
    "end": "139760"
  },
  {
    "text": "recently um we're integrated we integrated with other a services including aut scaling cloudfront uh",
    "start": "139760",
    "end": "146840"
  },
  {
    "text": "cloudwatch uh obviously Amazon ec2 and then we're cost effective uh it is",
    "start": "146840",
    "end": "152879"
  },
  {
    "text": "significantly cheaper to run an elb than it would be to to run your own load",
    "start": "152879",
    "end": "157920"
  },
  {
    "text": "balancer using Amazon ec2 instances um so the pr price point is lower it's around $18.50 per month and then there's",
    "start": "157920",
    "end": "164080"
  },
  {
    "text": "a a bandwidth charge that goes on top of that and that price point actually elb becomes cheaper with scale so the larger",
    "start": "164080",
    "end": "169519"
  },
  {
    "text": "you get the difference between running your own and using elb gets",
    "start": "169519",
    "end": "175159"
  },
  {
    "text": "larger so um I'm hoping none of you guys identify with this architecture you we",
    "start": "175159",
    "end": "180319"
  },
  {
    "text": "have a customer uh using an Amazon ec2 instance however I think we've all started here this is probably where most",
    "start": "180319",
    "end": "185680"
  },
  {
    "text": "of our applications start out with some idea but really what you want to be doing is running a load balancer in front of that so you've got an elb there",
    "start": "185680",
    "end": "192480"
  },
  {
    "text": "and then three ec2 instances behind it now for this talk I just want to call it the really two types of load",
    "start": "192480",
    "end": "199120"
  },
  {
    "text": "balancers um we we have a ec2 classic load balancer which is for classic",
    "start": "199120",
    "end": "204720"
  },
  {
    "text": "instances and we have an easy2 VPC load balancer now if you only started using Amazon in 20133 or later you have what",
    "start": "204720",
    "end": "212599"
  },
  {
    "text": "we call a VPC only account which means you don't have access to Classic um but VPC looks a lot like classic does to",
    "start": "212599",
    "end": "219319"
  },
  {
    "text": "Classic customers uh classic load balances as you can see only load balance over classic ec2 instances",
    "start": "219319",
    "end": "225080"
  },
  {
    "text": "classic ec2 instance is essentially one large big flat sub subnet um so if you're in classic you have no control",
    "start": "225080",
    "end": "231720"
  },
  {
    "text": "over um the network you really get a a 10.2 IP address um you can map elastic",
    "start": "231720",
    "end": "237239"
  },
  {
    "text": "IPS but you don't have a lot of the other functionality that we get from VPC um with VPC you obviously use VPC",
    "start": "237239",
    "end": "242439"
  },
  {
    "text": "instances classic only has support for public IPS so you you cannot have an internal private load balancer which you",
    "start": "242439",
    "end": "248519"
  },
  {
    "text": "can have with VPC uh and then no control over load balance is Security Group in classic so classic you open up Port 80",
    "start": "248519",
    "end": "255439"
  },
  {
    "text": "it's open to the world with VPC if you decide you only want to open up Port 80 to a very specific cider group you can",
    "start": "255439",
    "end": "261919"
  },
  {
    "text": "do that and then it's also a tightly integrated uh with VPC as well on the",
    "start": "261919",
    "end": "266960"
  },
  {
    "text": "VPC side so let's talk a little bit about the architecture of elb so what does elb",
    "start": "266960",
    "end": "274280"
  },
  {
    "text": "look like and how should you think about it in in in when you think about your application so yeah we have a customer VPC and the blue lines indicate subnets",
    "start": "274280",
    "end": "282440"
  },
  {
    "text": "we have E2 instance uh at the top subnet and at the bottom the dotted lines indicate in the availability zone so",
    "start": "282440",
    "end": "289120"
  },
  {
    "text": "that is that is your application we add elb to that so what elb will do is it actually puts creates another VPC on on",
    "start": "289120",
    "end": "296360"
  },
  {
    "text": "a separate account from yours and it has an elb node running in a subnet that that one availability Zone and an EB",
    "start": "296360",
    "end": "303639"
  },
  {
    "text": "node running in the other availability Zone then what we ask you to do when you create the vpcb is we actually ask you",
    "start": "303639",
    "end": "310960"
  },
  {
    "text": "to give us a subnet and ideally we would like to see you give us one Subnet in two",
    "start": "310960",
    "end": "316880"
  },
  {
    "text": "availability zones so so one Subnet in 1 a and one Subnet in 1 B and I'll talk a bit more about why we do that later what",
    "start": "316880",
    "end": "323680"
  },
  {
    "text": "we do with that subnet is we actually take an eni elastic network interface out of the subnet that you gave us and",
    "start": "323680",
    "end": "329880"
  },
  {
    "text": "we attach it to our EB node that essentially means your network interface is attached to our load balancer that's",
    "start": "329880",
    "end": "336840"
  },
  {
    "text": "the reason why you can control security groups because the security groups are attached to your network interface but",
    "start": "336840",
    "end": "342360"
  },
  {
    "text": "it's also why you can control we we get very very secure access into your network if it's a public load balancer",
    "start": "342360",
    "end": "349560"
  },
  {
    "text": "we would put a public IP address on that EB node and if it's a private load balancer or an internal load balancer",
    "start": "349560",
    "end": "355560"
  },
  {
    "text": "we'd put a private IP address on that if it's private it would only have access so you'd only have access to that load",
    "start": "355560",
    "end": "360919"
  },
  {
    "text": "balancer within your VPC the other thing we do is we use",
    "start": "360919",
    "end": "366599"
  },
  {
    "text": "Amazon Route 53 we we we are big big supporters of Amazon Route 53 it does a lot for elb and we'll see a bit more",
    "start": "366599",
    "end": "372919"
  },
  {
    "text": "about that later so each elb node would have an IP address uh each one would have a public IP and we'd put those into",
    "start": "372919",
    "end": "379440"
  },
  {
    "text": "Route 53 and what you would get the the elb DNS name that is served to you via",
    "start": "379440",
    "end": "384639"
  },
  {
    "text": "the API that is actually a rod 53 DNS name that you can either see name to or you can the r 53 Alias",
    "start": "384639",
    "end": "392800"
  },
  {
    "text": "feature so obviously one of the first things you have to do with a load balancer is create a listener so you",
    "start": "394400",
    "end": "399840"
  },
  {
    "text": "need something that you're going to accept traffic on Port 80 and then you're going to route that traffic to maybe port 8080 or accept traffic on 443",
    "start": "399840",
    "end": "406160"
  },
  {
    "text": "and route that to the back end well today elb supports two uh types of listeners TCP or",
    "start": "406160",
    "end": "413400"
  },
  {
    "text": "SSL first type and HTTP or https is the second type and some of the key differences here so firstly on the the",
    "start": "413400",
    "end": "419680"
  },
  {
    "text": "TCP side every request that comes in from the client is terminated on the load balancer but directly bound to a",
    "start": "419680",
    "end": "426039"
  },
  {
    "text": "request to the server so we don't do any sort of connection pooling between the load balancer and the back end so every",
    "start": "426039",
    "end": "432039"
  },
  {
    "text": "client Connection in TCP is a direct connection to the back end and RAR it's just a straight pass through any request",
    "start": "432039",
    "end": "437680"
  },
  {
    "text": "that comes in we do not look at that request we just send it straight to the back end that's what you get at TCP if you're using SSL you you can do SSL",
    "start": "437680",
    "end": "445080"
  },
  {
    "text": "offloading on the load balancer using TCP if you want to do SSL offloading on the back end we not do it on the elb you",
    "start": "445080",
    "end": "451560"
  },
  {
    "text": "can just set up a TCP load balancer straight through on the front end and to the back end and then you can handle the",
    "start": "451560",
    "end": "457039"
  },
  {
    "text": "SSL yourself the other ones around headers so with TCP as I said we don't look at that request we don't we don't",
    "start": "457039",
    "end": "462319"
  },
  {
    "text": "crack it open we don't do anything with it we just send it through a is so there's no modification to the headers with a TCP listener with HTP we do",
    "start": "462319",
    "end": "470280"
  },
  {
    "text": "things like add X forward and forward there might be some header manipulation there we are actually looking at the contents of the request proxy protocol",
    "start": "470280",
    "end": "477840"
  },
  {
    "text": "is a feature that we launch in 2013 uh for TCP it's it's a protocol that comes",
    "start": "477840",
    "end": "483240"
  },
  {
    "text": "out of the ha proxy uh service and really what it does is it append The Source IP destination IP in the source",
    "start": "483240",
    "end": "489720"
  },
  {
    "text": "port to the front of the TCP packet so if you want to get Source IP on a TCP",
    "start": "489720",
    "end": "496080"
  },
  {
    "text": "connection you can use proxy protocol one thing we're seeing here is elb does not offer support for websockets today",
    "start": "496080",
    "end": "502479"
  },
  {
    "text": "but we see a lot of customers doing websocket like functionality using TCP listeners with proxy protocol and they",
    "start": "502479",
    "end": "509560"
  },
  {
    "text": "very long timeouts on another feature I'll talk about uh the idle timeout times and then keep Al lives to",
    "start": "509560",
    "end": "514719"
  },
  {
    "text": "basically keep those TCB connections alive x fored four obviously on the HTTP side if you want the source IP comes",
    "start": "514719",
    "end": "520640"
  },
  {
    "text": "with an x fored 4 header interesting on the TCP side we use round robin round robin algorithm",
    "start": "520640",
    "end": "527560"
  },
  {
    "text": "which basically means each machine gets one request and we just round robin between them the reason for that is we obviously have no connection pooling we",
    "start": "527560",
    "end": "533920"
  },
  {
    "text": "don't look at the request um we can't do least cons in that fashion so we do round robin using TCP and then on the uh",
    "start": "533920",
    "end": "540839"
  },
  {
    "text": "least outstanding request on the sorry HTTP side we use least outstanding request algorithm which basically means",
    "start": "540839",
    "end": "547000"
  },
  {
    "text": "each load balancer will receive a request the one with the fewest outstanding requests will receive the next one and then we do offer sticky",
    "start": "547000",
    "end": "553200"
  },
  {
    "text": "sessions although we don't normally recommend that people use sticky sessions um but there are a lot of customers that would like to use them so",
    "start": "553200",
    "end": "559440"
  },
  {
    "text": "we do offer that it's much better to look at using elastic cache or one of those other features and some sort of distributed cache rather than doing",
    "start": "559440",
    "end": "565519"
  },
  {
    "text": "sticky sessions and having a dependency on any one of your backend machines",
    "start": "565519",
    "end": "571360"
  },
  {
    "text": "health checks let's talk a little bit about health checks so with each of those listeners you can configure a set",
    "start": "572519",
    "end": "577560"
  },
  {
    "text": "of health checks to your backend instances and for these health checks there are a couple of things you can configure well let me show you firstly",
    "start": "577560",
    "end": "582880"
  },
  {
    "text": "how they work so we have a set of E2 instances here processing requests I've added the CPU on the side there you can",
    "start": "582880",
    "end": "589440"
  },
  {
    "text": "see one of those machines starts to have some performance issues um the health check is is executing at an interval",
    "start": "589440",
    "end": "596399"
  },
  {
    "text": "that you can specify so it it might be every 6 seconds and you say we want a health check to fail twice before you",
    "start": "596399",
    "end": "602120"
  },
  {
    "text": "shift traffic away from it if that health check fails uh and a fail means anything other than a 200 response so",
    "start": "602120",
    "end": "609120"
  },
  {
    "text": "that that machine starts to time out starts to return 53s any other Response Code that health check will fail and",
    "start": "609120",
    "end": "615000"
  },
  {
    "text": "you'll be able shift the traffic away from that instance and as you can see what will happen is that request load",
    "start": "615000",
    "end": "620279"
  },
  {
    "text": "that was being served by three instances is now going to be served by two machines so you will start to see some",
    "start": "620279",
    "end": "625480"
  },
  {
    "text": "increased CPU or utilization on the remaining machines you go in and realize",
    "start": "625480",
    "end": "630640"
  },
  {
    "text": "that you've got a health check problem you sort it out health check starts succeeding and we shift traffic back",
    "start": "630640",
    "end": "635920"
  },
  {
    "text": "very very important feature obviously mitigating any sort of failed backend instance is critically important and",
    "start": "635920",
    "end": "641120"
  },
  {
    "text": "that's something that the elb does covered most of what's on this",
    "start": "641120",
    "end": "647839"
  },
  {
    "text": "slide with two types of health checks again you got TCP health checks and HTTP health checks TCP health check there are",
    "start": "647839",
    "end": "653959"
  },
  {
    "text": "a lot of customers that use TCP health checks and I think one of the reasons is often they didn't get the HTTP ones to work with the application you do need to",
    "start": "653959",
    "end": "660720"
  },
  {
    "text": "be careful with a TCP health check the the bar for success is very very low you basically need power to the network card",
    "start": "660720",
    "end": "667320"
  },
  {
    "text": "um so to get an icmp ping to work uh there's there's not much of not much required so there's a good chance that",
    "start": "667320",
    "end": "673639"
  },
  {
    "text": "your TCP health check might be working um but your application stack is actually down and you sending traffic to",
    "start": "673639",
    "end": "679000"
  },
  {
    "text": "a machine that's failing so very important that you think about that if you do see failed health checks logging",
    "start": "679000",
    "end": "684040"
  },
  {
    "text": "in and changing to TCP is not a way to fix them because often you'll see TCP oh my health checks and I healthy um be",
    "start": "684040",
    "end": "690240"
  },
  {
    "text": "careful with that rather Implement an HTTP health check the last point on that slide there uh says consider the depth",
    "start": "690240",
    "end": "696440"
  },
  {
    "text": "of your health checks and this is I think you could probably do a whole study on this separately probably do a talk on this separately but how deep",
    "start": "696440",
    "end": "703079"
  },
  {
    "text": "should a health check go and really what you want to do is you want to make sure that your health check is good enough so that it'll remove an individual server",
    "start": "703079",
    "end": "709440"
  },
  {
    "text": "from service when it fails if you have health checks that go all the way to your database and execute the entire",
    "start": "709440",
    "end": "714959"
  },
  {
    "text": "call path that a customer would do when that database fails that has the great feature of of removing all machines from",
    "start": "714959",
    "end": "720800"
  },
  {
    "text": "service immediately and returning 53s to your customer that's not a great feature so you don't want to be doing that the",
    "start": "720800",
    "end": "726680"
  },
  {
    "text": "other thing is if you have any dependencies on other services with your health checks it might be within ec2 it",
    "start": "726680",
    "end": "731720"
  },
  {
    "text": "might be even outside of ec2 any sort of problem with that dependency can cause all of your machines to fail if all of",
    "start": "731720",
    "end": "737680"
  },
  {
    "text": "your machines fail we will return 503s so think think very carefully about the depth of your health checks and if you",
    "start": "737680",
    "end": "743519"
  },
  {
    "text": "ever do have a situation where you removed all your machines from service go back and when you do the cause of error analysis trying to understand hey",
    "start": "743519",
    "end": "750000"
  },
  {
    "text": "did the health check fail do we have some sort of shared dependency with our health checks that's actually a risk to the service because we could remove",
    "start": "750000",
    "end": "755240"
  },
  {
    "text": "everything from service idle timeouts this was launched earlier this year we launched support",
    "start": "755240",
    "end": "760720"
  },
  {
    "text": "for idle timeouts we've always had them in elb they've always been 60 seconds um but what we launched earlier this year was the ability to control them so idle",
    "start": "760720",
    "end": "768040"
  },
  {
    "text": "time out is really the length of time that we should keep a connection open uh while uh it doesn't have any traffic",
    "start": "768040",
    "end": "774279"
  },
  {
    "text": "flowing on it so a common example would be somebody sends you an API request and",
    "start": "774279",
    "end": "779320"
  },
  {
    "text": "that API request takes some time for you to process let's say it takes you 30 seconds to go and return some information or retrieve some information",
    "start": "779320",
    "end": "785920"
  },
  {
    "text": "from Dynamo or a database that connection is sitting waiting for a response uh and that that's the idle",
    "start": "785920",
    "end": "791639"
  },
  {
    "text": "timeout so you may decide that you don't want to wait with 30 seconds 30 seconds you want to tell the client to go away",
    "start": "791639",
    "end": "796720"
  },
  {
    "text": "um so by default I said it's 60 seconds um but we do have the ability now to set it anywhere uh in the console API from 1",
    "start": "796720",
    "end": "803600"
  },
  {
    "text": "second to 3,600 seconds so an hour as I mentioned earlier with the proxy protocol comment said it to 3,600",
    "start": "803600",
    "end": "810399"
  },
  {
    "text": "seconds is one way of doing sort of Long Live persistent connections with TCP proxy protocol and",
    "start": "810399",
    "end": "816120"
  },
  {
    "text": "elb um one of the little things we've learned the hard way uh on ec2 uh and",
    "start": "816120",
    "end": "821880"
  },
  {
    "text": "elb is the timeout should really decrease as you go up the stack and one thing you want to think about when you",
    "start": "821880",
    "end": "827360"
  },
  {
    "text": "set your timeouts is how long is my client going to wait for because we all have busy systems we all dealing with",
    "start": "827360",
    "end": "833399"
  },
  {
    "text": "systems that are scaling if we're giving resources in our system to to work that",
    "start": "833399",
    "end": "839160"
  },
  {
    "text": "the customer's actually gone away the client has given up so by default the SDK uh the ec2 and elb sdks actually",
    "start": "839160",
    "end": "845680"
  },
  {
    "text": "only wait for 15 seconds so after 15 seconds the client's going to give up and",
    "start": "845680",
    "end": "850880"
  },
  {
    "text": "retry so if if you're if you're processing requests for longer than 30 seconds or 15 seconds you're actually",
    "start": "850880",
    "end": "856199"
  },
  {
    "text": "doing work in the system and when you turn around and complete it nobody's going to be there to give it back to it's actually it's wasted work and we",
    "start": "856199",
    "end": "862360"
  },
  {
    "text": "actually had a very interesting issue on ec2 some time back on the control plan um we received an alarm and we could see",
    "start": "862360",
    "end": "867920"
  },
  {
    "text": "that something wasn't right in system and we could see that it was moving around the system and we couldn't find it there's nowhere to be seen couldn't",
    "start": "867920",
    "end": "874759"
  },
  {
    "text": "track this thing down there was nothing in our logs and 70 minutes later we found a request and there was a single",
    "start": "874759",
    "end": "880680"
  },
  {
    "text": "request that took 70 minutes to process and the whole system happily just kept tryed on this one one request for 70",
    "start": "880680",
    "end": "887079"
  },
  {
    "text": "minutes and eventually after 70 minutes gave up and and logged something on the way out and what we realized from that",
    "start": "887079",
    "end": "892320"
  },
  {
    "text": "is anything that takes longer than your client timeout you should really think about it as an error you should really",
    "start": "892320",
    "end": "897639"
  },
  {
    "text": "say hey I Define my errors as either I return a 503 or it takes longer than 15 seconds or 10 seconds and when you start",
    "start": "897639",
    "end": "904160"
  },
  {
    "text": "to get your engineers to think like that you end up giving up on work that's taking longer than your client would take so that's just something",
    "start": "904160",
    "end": "910399"
  },
  {
    "text": "interesting thing we've learned along and something you can do with EB in certain new idle",
    "start": "910399",
    "end": "915519"
  },
  {
    "text": "timeouts and I had a diagram",
    "start": "916399",
    "end": "920399"
  },
  {
    "text": "there sorry",
    "start": "921680",
    "end": "925680"
  },
  {
    "text": "okay let's move on to using a multiple avability zones so obviously I mean you've heard it said Verner said it in",
    "start": "935279",
    "end": "941199"
  },
  {
    "text": "his talk this morning he asked everybody's using multiple availability zones for all of their applications I'm sure all of you all of you uh agreed",
    "start": "941199",
    "end": "948199"
  },
  {
    "text": "that that was the case um so so we we we highly recommend that you always use multiple availability zes now this is",
    "start": "948199",
    "end": "953880"
  },
  {
    "text": "the elb architecture diagram and what you can see there is um we the dotted line indicates avail zones so we have",
    "start": "953880",
    "end": "960120"
  },
  {
    "text": "multiple zones there um what's what's critically important is Route 53 up on the top left um you can see that we",
    "start": "960120",
    "end": "967680"
  },
  {
    "text": "actually use Route 53 to do the load balancing between the availability zones so in this diagram elb would put two IP",
    "start": "967680",
    "end": "974399"
  },
  {
    "text": "addresses into Route 53 and Route 53 would use weighted round robin or round robin to to round robin clients between",
    "start": "974399",
    "end": "981000"
  },
  {
    "text": "those IPS it works relatively well as long as the clients are resolving DNS and we'll talk a little bit more about",
    "start": "981000",
    "end": "987240"
  },
  {
    "text": "that we believe so strongly in multiple a multi-az support that elb does",
    "start": "987240",
    "end": "992759"
  },
  {
    "text": "multi-az even if you don't so if you have a load balancer and and you have a test application and you",
    "start": "992759",
    "end": "999920"
  },
  {
    "text": "have backend instances in one availability Zone EB will not take that risk elb will still use two availability",
    "start": "999920",
    "end": "1008079"
  },
  {
    "text": "zones and coming back to a point I made earlier for elb to use two availability zones we need to have a subnet in each",
    "start": "1008079",
    "end": "1016279"
  },
  {
    "text": "availability Zone from you so in the coming weeks we're actually busy with a feature where in the console you'll",
    "start": "1016279",
    "end": "1021560"
  },
  {
    "text": "start to see us prompt for a second availability Zone because we're really trying to encourage customers to do this now if you don't have any instances in",
    "start": "1021560",
    "end": "1027798"
  },
  {
    "text": "that availability Zone that's okay that's that's a risk that we wouldn't re wouldn't recommend you take but there's",
    "start": "1027799",
    "end": "1033798"
  },
  {
    "text": "some applications where that may Mak sense um but it's always worthwhile creating a second subnet and attaching",
    "start": "1033799",
    "end": "1039438"
  },
  {
    "text": "that to the elb and that immediately means that if any one of those elb nodes has problems we will actually shift",
    "start": "1039439",
    "end": "1045240"
  },
  {
    "text": "traffic automatically using Route 53 to the other node and there's absolutely you know impact to your application",
    "start": "1045240",
    "end": "1050280"
  },
  {
    "text": "because we'll do that across zone so if you haven't given us two two subnets one in each a um go ahead and do that and",
    "start": "1050280",
    "end": "1057960"
  },
  {
    "text": "that was the next slide we always associate two or more subnets in different zones with each load",
    "start": "1057960",
    "end": "1064000"
  },
  {
    "text": "balancer there are a few challenges I'm sure some of you guys when I spoke about Route 53 and clients resolving DNS you",
    "start": "1064000",
    "end": "1069720"
  },
  {
    "text": "you may have laughed a bit and said well a lot of clients don't do that and we talk a little bit about that now now some of the challenges there is",
    "start": "1069720",
    "end": "1075679"
  },
  {
    "text": "obviously firstly traffic imbalances um so so we do see you know we've seen this",
    "start": "1075679",
    "end": "1080760"
  },
  {
    "text": "with customers where uh certainly some of the the older clients might be TVs or there might be um you know lot of the",
    "start": "1080760",
    "end": "1086840"
  },
  {
    "text": "tablets out there even Java actually itself is pretty bad at resolving DNS um you you'll see you get a Hotpot where",
    "start": "1086840",
    "end": "1092559"
  },
  {
    "text": "you've got one or two clients that are targeting the availability Zone there in green and you can see one Zone's running",
    "start": "1092559",
    "end": "1098320"
  },
  {
    "text": "really hot now the problem with this is you need to go and add more backend capacity behind the load balances so",
    "start": "1098320",
    "end": "1104000"
  },
  {
    "text": "you're constantly running around trying to move capacity around to handle you know where your clients are going based on DNA",
    "start": "1104000",
    "end": "1109320"
  },
  {
    "text": "so that was that was one of the challenges um with with the this approach the other one is obviously uh",
    "start": "1109320",
    "end": "1115360"
  },
  {
    "text": "capacity uh in each zone so in this diagram it's a little subtle but you can see that in 1 a the top Zone we've got",
    "start": "1115360",
    "end": "1121520"
  },
  {
    "text": "one ec2 instance and and 1 B the bottom Zone we've actually got three ec2 instances and you can see that there's",
    "start": "1121520",
    "end": "1126960"
  },
  {
    "text": "this imbalance in in in traffic so even though the traffic is coming in 50% 50% across two zones you can see that the",
    "start": "1126960",
    "end": "1133919"
  },
  {
    "text": "top zone is actually running pretty hot because you're sending 50% of your traffic to one instance um and then the",
    "start": "1133919",
    "end": "1139039"
  },
  {
    "text": "other 50% is going to three instances and this you know some customers may run like this um but a lot of customers you",
    "start": "1139039",
    "end": "1144600"
  },
  {
    "text": "might just have had some some problems with the instances in one 1A you may be doing a deployment in 1A you're doing a",
    "start": "1144600",
    "end": "1150440"
  },
  {
    "text": "roll in deployment and you know you have to decrease your number of instances so ideally you want to make sure that that traffic is spread evenly across all of",
    "start": "1150440",
    "end": "1156919"
  },
  {
    "text": "the availability lines and we launched a feature called cross Zone load balancing uh earlier",
    "start": "1156919",
    "end": "1162480"
  },
  {
    "text": "this or pretty much a year ago um which it solves this problem so what it does is it actually sends traffic from every",
    "start": "1162480",
    "end": "1168960"
  },
  {
    "text": "availability Zone to every other availability Zone and that has a great effect in evenly even in out that load",
    "start": "1168960",
    "end": "1174960"
  },
  {
    "text": "um when you're in the situation and essentially What's Happening Here is if your client does not obey DNS if you've",
    "start": "1174960",
    "end": "1180760"
  },
  {
    "text": "got a particularly badly behaved client um elb will scale up and absorb that load so elb is actually absorbing the",
    "start": "1180760",
    "end": "1188159"
  },
  {
    "text": "imbalance so in this situation I could have a very very badly behaved client and maybe one only one of them that's",
    "start": "1188159",
    "end": "1193559"
  },
  {
    "text": "hitting me in one availability Zone at scale and what elb will do is we'll scale up and absorb that and you will",
    "start": "1193559",
    "end": "1198760"
  },
  {
    "text": "see 25% of the traffic hit each instance cuz there four instances there um at all",
    "start": "1198760",
    "end": "1203960"
  },
  {
    "text": "times so El be a will scale up and absorb that it was actually a great feature to launch um we put it out there",
    "start": "1203960",
    "end": "1209039"
  },
  {
    "text": "we got a lot of very very positive feedback um from customers and we actually had a couple of these graphs",
    "start": "1209039",
    "end": "1214360"
  },
  {
    "text": "show up on Twitter we always watch Twitter very very keenly to see what people are saying both good and bad and",
    "start": "1214360",
    "end": "1220000"
  },
  {
    "text": "uh seeing this was was great to see just customers that had this imbalance load and had a metric showing it turn on",
    "start": "1220000",
    "end": "1225760"
  },
  {
    "text": "crossone load balancing and you see the the lines converge um so a lot of people have asked me well Dave why why don't",
    "start": "1225760",
    "end": "1232080"
  },
  {
    "text": "you just turn this on for all the lbs this seems like such a good thing well the other question they asked me is why shouldn't I turn on crossone load",
    "start": "1232080",
    "end": "1238120"
  },
  {
    "text": "balancing because when we launched the feature we said you will you need to go and turn this on and the reason we said",
    "start": "1238120",
    "end": "1243720"
  },
  {
    "text": "you needed to go turn this on is really twofold the first one is there is a risk if you have a very low connection limit",
    "start": "1243720",
    "end": "1249559"
  },
  {
    "text": "on your back ends let's say you're running Apache and you only you know allow for a connection limit of four in",
    "start": "1249559",
    "end": "1255559"
  },
  {
    "text": "that case when you do cross Zone you will see more connections coming coming from the load balances from other availability zones so you do want to go",
    "start": "1255559",
    "end": "1262000"
  },
  {
    "text": "and check your connection limit before you turn on crossone load balancing the other thing uh the reason we don't do it",
    "start": "1262000",
    "end": "1267799"
  },
  {
    "text": "is is we really don't like make we don't like to make configuration changes to your stack it's something that's",
    "start": "1267799",
    "end": "1274360"
  },
  {
    "text": "incredibly risky so we will not do it and we would rather um you know make it very easy for you to log in when you",
    "start": "1274360",
    "end": "1281640"
  },
  {
    "text": "want to make a change you you you know you have your system Engineers whoever you need to make the change everybody's",
    "start": "1281640",
    "end": "1287000"
  },
  {
    "text": "ready and you make the change and make sure there's no problems we don't want to be doing that behind your back and then you're wondering you know what changed with the system if by chance",
    "start": "1287000",
    "end": "1293840"
  },
  {
    "text": "there is some issue so those are the two reasons why you don't see us do things by",
    "start": "1293840",
    "end": "1299559"
  },
  {
    "text": "default so I spoke a lot about this slide um the one important thing on that slide that I haven't mentioned is as you",
    "start": "1299559",
    "end": "1305440"
  },
  {
    "text": "know ec2 does charge for inter Zone traffic so some of you may have thought well when I spoke about crossone load",
    "start": "1305440",
    "end": "1311159"
  },
  {
    "text": "balancing well hey that's great but I'm actually going to be now paying a penny per gig between zones um well when you",
    "start": "1311159",
    "end": "1317919"
  },
  {
    "text": "do it with elb it's actually free so we managed to convince the ec2 team to do that so your traffic that gets balanced",
    "start": "1317919",
    "end": "1324080"
  },
  {
    "text": "across the zones doesn't occur any additional bandwidth charge um by doing that at the load",
    "start": "1324080",
    "end": "1331480"
  },
  {
    "text": "balancer so let's talk a little bit about understanding so we've spoken a bit about this so each load balancer has",
    "start": "1333360",
    "end": "1339440"
  },
  {
    "text": "one or more air records um you will never see a load balancer with less than two even if you don't give us a second",
    "start": "1339440",
    "end": "1345240"
  },
  {
    "text": "subnet we will actually put two instance or two e nodes into one zone slightly",
    "start": "1345240",
    "end": "1351240"
  },
  {
    "text": "better to have two nodes there but still not what we want we rely like that second subnet um and then we use the",
    "start": "1351240",
    "end": "1357080"
  },
  {
    "text": "round robin uh to to load balance across those at the DNS level um very important",
    "start": "1357080",
    "end": "1363400"
  },
  {
    "text": "thing with elb is DNS records will change over time so if you watch your elb at times you'll see those DNS",
    "start": "1363400",
    "end": "1370320"
  },
  {
    "text": "records change so question is well when does elb change DNS records elb does not change DNS records when nodes fail so if",
    "start": "1370320",
    "end": "1377400"
  },
  {
    "text": "a node fails for whatever reason and our system detects it and we replace it the IPS will stay the CH the same where we",
    "start": "1377400",
    "end": "1383559"
  },
  {
    "text": "do change the UNS records is when we scale so if we need to scale a node either make the node bigger or add more",
    "start": "1383559",
    "end": "1389440"
  },
  {
    "text": "nodes we will add IPS into DNS the reason we we changed those records is we",
    "start": "1389440",
    "end": "1395000"
  },
  {
    "text": "actually drain the old IP so it's not that that IP's disappeared and your customers have just been disconnected we",
    "start": "1395000",
    "end": "1401640"
  },
  {
    "text": "actually keep it for up to 7 days so we push that machine onto the side and we watch it and when we watch the traffic",
    "start": "1401640",
    "end": "1407400"
  },
  {
    "text": "on it and then some customers where the level it stays there for a long time we see it dropping over time and eventually we can take it out of service and then",
    "start": "1407400",
    "end": "1413720"
  },
  {
    "text": "it goes into additional quarantine before that IP comes back into a service either for your load balancer and eventually another quarantine to other",
    "start": "1413720",
    "end": "1419760"
  },
  {
    "text": "load balancers so there's there's quite some time before these IPS get recycled and quite some time we we allow these",
    "start": "1419760",
    "end": "1425039"
  },
  {
    "text": "customers or client connections to drain off one of the things we've seen this is",
    "start": "1425039",
    "end": "1430600"
  },
  {
    "text": "a an interesting hack uh elegant hack shall I say um that we we've seen with DNS and it's something that quite a few",
    "start": "1430600",
    "end": "1436480"
  },
  {
    "text": "of the tablet teams use um so basically sometimes you'll have some clients that just never ever re resolve DNS they",
    "start": "1436480",
    "end": "1442799"
  },
  {
    "text": "they're quite happy to once they've got an IP they'll just keep using that forever and maybe they'll the other the other big problem with this is um these",
    "start": "1442799",
    "end": "1450200"
  },
  {
    "text": "these clients tend to isps sometimes tend to cash it's a particular problem in the mobile space where um youve you",
    "start": "1450200",
    "end": "1456120"
  },
  {
    "text": "did a resolution and your client's doing the right thing um but your your ISP is is caching the 8 IPS or two IPS that EB",
    "start": "1456120",
    "end": "1463440"
  },
  {
    "text": "gave you and never re resolving because they're quite happy with the cach version that they have um what this does is you can actually go and create a wild",
    "start": "1463440",
    "end": "1469480"
  },
  {
    "text": "card C name or or uh alias in Route 53 and the Wild Card one really just means",
    "start": "1469480",
    "end": "1474919"
  },
  {
    "text": "that the start of the name has a star a little wild card and then what you can do is when you do your lookup in your",
    "start": "1474919",
    "end": "1480760"
  },
  {
    "text": "client to application this obviously doesn't work on on web browsers but when you're using whatever application or mobile device you've got every time you",
    "start": "1480760",
    "end": "1487159"
  },
  {
    "text": "do that lookup you just add a uu ID at the front of it so you just add 128bit random number that something that you",
    "start": "1487159",
    "end": "1493760"
  },
  {
    "text": "know hasn't been cached before and then your client does it every 60 seconds and basically you get in a the caching issue",
    "start": "1493760",
    "end": "1499600"
  },
  {
    "text": "that that the ISP is having so quite a few I know tablet customers do those to get around some",
    "start": "1499600",
    "end": "1505760"
  },
  {
    "text": "issues it's been a SSL offloading SSL I think if if nobody knew about SSL 6",
    "start": "1505760",
    "end": "1512279"
  },
  {
    "text": "months ago almost everybody knows about SSL now and we were fortunate um earlier",
    "start": "1512279",
    "end": "1519399"
  },
  {
    "text": "this year on elb 2014 we we launched a feature called SSL improvements um with perfect forward secrecy and elliptical",
    "start": "1519399",
    "end": "1525880"
  },
  {
    "text": "curve ciphers um but behind the scenes we actually did a lot in our SSL stack to to Really prepare for that feature it",
    "start": "1525880",
    "end": "1531120"
  },
  {
    "text": "was a good thing we did um had we known what was coming our way um so we offer both SSL and https as I said earlier uh",
    "start": "1531120",
    "end": "1538919"
  },
  {
    "text": "and then I said you know perfect forward secrecy and elliptical curve ciphers um and then we we offer full customization",
    "start": "1538919",
    "end": "1546320"
  },
  {
    "text": "uh of these ciphers so if you if you log into the console I know this is the 400 talk if you use the command line tool uh",
    "start": "1546320",
    "end": "1552520"
  },
  {
    "text": "you can see all of the all of the policies and ciphers that we offer our documentation documents documents them very well as well and if you have a",
    "start": "1552520",
    "end": "1559360"
  },
  {
    "text": "specific set of ciphers that you have to use because it's dictated by your company or by pcidss or whatever it might be you can log in and you can go",
    "start": "1559360",
    "end": "1565799"
  },
  {
    "text": "and configure both the ciphers and protocols for your application if you're like me uh I I know way too much about",
    "start": "1565799",
    "end": "1571679"
  },
  {
    "text": "SSL now than I thought I would ever know um and it's it's it's a lot of complexity uh involved in there um and",
    "start": "1571679",
    "end": "1577320"
  },
  {
    "text": "you just say hey elb I'd like you to take care of that well we do offer SSL negotiation suets cyer Suites that you",
    "start": "1577320",
    "end": "1584399"
  },
  {
    "text": "can go and select and we actually publish these at regular intervals so we published one in January of this year and we published another one uh on the",
    "start": "1584399",
    "end": "1591039"
  },
  {
    "text": "10th uh on sorry in October 201410 is the name of the cipher and what we actually do with these is these provide",
    "start": "1591039",
    "end": "1597520"
  },
  {
    "text": "a set of ciphers and protocols that elb believes are sort of the the current best practices based on industry",
    "start": "1597520",
    "end": "1604399"
  },
  {
    "text": "standards and um now one of the things is if you if you follow what the security teams are telling you to do if",
    "start": "1604399",
    "end": "1610080"
  },
  {
    "text": "you follow exactly it's very secure the problem is none of your customers can connect to you CU nobody yet supports",
    "start": "1610080",
    "end": "1615760"
  },
  {
    "text": "the ciphers and protocols that many of them recommend we actually had that problem we ended up deploying a cipher internally that no web browser supported",
    "start": "1615760",
    "end": "1622880"
  },
  {
    "text": "um and so SSL negotiation policies what we actually did is you said well we've got this amazon.com website um and",
    "start": "1622880",
    "end": "1629440"
  },
  {
    "text": "there's quite a few user agents out there that connect to amazon.com so what if we take the best practices that the industry is telling us and we take all",
    "start": "1629440",
    "end": "1636240"
  },
  {
    "text": "the traffic from amazon.com and we just merge the two and we test it and see and now when we did that we were able to put",
    "start": "1636240",
    "end": "1642039"
  },
  {
    "text": "cers in and see what different user agents chose and take ciphers out and see how many clients were getting",
    "start": "1642039",
    "end": "1647240"
  },
  {
    "text": "negotiation failure go in and understand who they were and why they were getting those failures and make a call as to do",
    "start": "1647240",
    "end": "1652320"
  },
  {
    "text": "we want to rely on that traffic or have that traffic or not so when you go and select the default SSL policy for elb",
    "start": "1652320",
    "end": "1659840"
  },
  {
    "text": "what you're getting is basically the very best Cipher Suite that we've tested against all of amazon.com's traffic and",
    "start": "1659840",
    "end": "1665640"
  },
  {
    "text": "we think you know that's something we're really committed to keeping up to date that's something that we do default for all new load balancers so when you",
    "start": "1665640",
    "end": "1671320"
  },
  {
    "text": "create a new load balancer you always get that so the ease of use was tested uh a little while ago it was the 15th of",
    "start": "1671320",
    "end": "1678320"
  },
  {
    "text": "October if I remember correctly 3:30 p.m. PST um we we had the poodle",
    "start": "1678320",
    "end": "1683600"
  },
  {
    "text": "mitigation uh or the poodle issue was announced um and that was where sslv3 U",
    "start": "1683600",
    "end": "1689440"
  },
  {
    "text": "there was a vulnerability in sslv3 and it had been proven and everybody needed to go and disable sslv3 which was the",
    "start": "1689440",
    "end": "1696039"
  },
  {
    "text": "the final blow for I6 um and what we saw there is we we ended up releasing a new ciphers policy",
    "start": "1696039",
    "end": "1703080"
  },
  {
    "text": "uh within about 30 minutes after the release so almost immediately every new load balancer over after that point in",
    "start": "1703080",
    "end": "1709039"
  },
  {
    "text": "time uh had sslv3 disabled immediately so if you created a new load Balan so you weren't vulnerable and we emailed",
    "start": "1709039",
    "end": "1715080"
  },
  {
    "text": "our customers and we saw 62% of all load balances migrate within 24 hours to a",
    "start": "1715080",
    "end": "1720760"
  },
  {
    "text": "policy that didn't support sslv3 and we actually had a couple of customers again on Twitter telling us um",
    "start": "1720760",
    "end": "1726799"
  },
  {
    "text": "just sort of how pleased they were and how easy it was and this customer said Thank you to AWS for making it so easy",
    "start": "1726799",
    "end": "1732080"
  },
  {
    "text": "to prevent sslv3 and poodle it took three Mouse clicks again you could have done it via the command line tools",
    "start": "1732080",
    "end": "1739919"
  },
  {
    "text": "so we've spoken a lot about the the architecture of elb uh a little bit about some of the features we have the",
    "start": "1740640",
    "end": "1745799"
  },
  {
    "text": "health checks and I hope I'm giving you some of the internal insights a little bit more depth than you may have had previously one of the things we need to",
    "start": "1745799",
    "end": "1752919"
  },
  {
    "text": "talk about is is cloudwatch metric um I'm amazed at times is just how many customers aren't aware of the cloud wch",
    "start": "1752919",
    "end": "1759080"
  },
  {
    "text": "metric that elb exposes it provides you know 13 different metrics um for the load balancer but it's a lot of good",
    "start": "1759080",
    "end": "1765399"
  },
  {
    "text": "insight into how your application doing um we provide them via cloudwatch and uh many cloudwatch metrics are 5 minutes by",
    "start": "1765399",
    "end": "1772080"
  },
  {
    "text": "default and you can opt into one minute with elb it's actually 1 minute by default um all the time so all of the",
    "start": "1772080",
    "end": "1778360"
  },
  {
    "text": "metrics are provided at the one minute granularity I just going to go through a",
    "start": "1778360",
    "end": "1784679"
  },
  {
    "text": "few of them here so one of the metrics we have is actually two metrics one of them is called healthy host count and the other one is called unhealthy host",
    "start": "1784679",
    "end": "1790880"
  },
  {
    "text": "count and you can probably understand how they work together so the sum of them should always be the number of hosts that you have behind the elb and",
    "start": "1790880",
    "end": "1797480"
  },
  {
    "text": "when we say host host yeah we talking about back in instances so healthy host count is the count of healthy instances",
    "start": "1797480",
    "end": "1803919"
  },
  {
    "text": "um behind the load balancer an unhealthy host count will be unhealthy instances it comes back to the health check functionality we were talking about",
    "start": "1803919",
    "end": "1810200"
  },
  {
    "text": "earlier um the most common cause that we see uh on the elb team when customers",
    "start": "1810200",
    "end": "1815399"
  },
  {
    "text": "contact us of unhealthy host count is timeouts so you've set a timeout for your health check I think default is 5",
    "start": "1815399",
    "end": "1821360"
  },
  {
    "text": "Seconds and you're actually taking longer than 5 Seconds to process the health check so the reason customers",
    "start": "1821360",
    "end": "1826559"
  },
  {
    "text": "contact us in that case is uh it looks to them like their health check suceeding because they can see they sent a response but it actually took longer",
    "start": "1826559",
    "end": "1833279"
  },
  {
    "text": "than than we were prepared to wait so make sure that you're working with in the timeout making sure that you return of 200 nothing else um the uh one good",
    "start": "1833279",
    "end": "1841640"
  },
  {
    "text": "thing to do is to test from another ec2 instance uh and just see what that Health check's doing and you can understand why it's failing obviously",
    "start": "1841640",
    "end": "1847559"
  },
  {
    "text": "anytime you see unhealthy hosts on your load balancer it's it's it's not a good thing you should always try and make sure they always",
    "start": "1847559",
    "end": "1853039"
  },
  {
    "text": "healthy latency is the other really interesting one um you know some of us might not have latency metric ourselves",
    "start": "1853039",
    "end": "1859440"
  },
  {
    "text": "um that we track on our on our application um so the load balancer will show you latency to your application and",
    "start": "1859440",
    "end": "1864600"
  },
  {
    "text": "what it's actually measuring there is the time after which we sent the first bite to the application and then",
    "start": "1864600",
    "end": "1870600"
  },
  {
    "text": "processed by the application and the time that it came back so it's actually not measuring the applicate the the uh load balancer time so it really is",
    "start": "1870600",
    "end": "1876799"
  },
  {
    "text": "actually application latency and not load balancer latency now that said there's also this thing called the E2",
    "start": "1876799",
    "end": "1882159"
  },
  {
    "text": "Network between the load balancer and the application so we do see times where customers are confused is it my application I don't see any impact and",
    "start": "1882159",
    "end": "1888519"
  },
  {
    "text": "we do have to work with them um but 99% of the time it's a good indication of latency to your application and and with",
    "start": "1888519",
    "end": "1895000"
  },
  {
    "text": "that one you can use uh you know cloudwatch statistics so you can do the Min the average and the max it's a really good indication uh of of how your",
    "start": "1895000",
    "end": "1902720"
  },
  {
    "text": "how your application's doing the one that we launched uh late last year is called surge cues and",
    "start": "1902720",
    "end": "1908480"
  },
  {
    "text": "spillovers those of you that you familiar with some of the other load balances are probably very familiar with surge cues and spillovers it's it's very",
    "start": "1908480",
    "end": "1914360"
  },
  {
    "text": "common terminology um really what what a surge Q is it's a it's a queue stored in the load balancer where we will cue",
    "start": "1914360",
    "end": "1921200"
  },
  {
    "text": "requests if you don't have enough backend capacity for us to send it to you right now so your backends may be",
    "start": "1921200",
    "end": "1926399"
  },
  {
    "text": "overloaded maybe we aren't able to establish connections to your back ends um so we will actually cue these requests in The Surge queue now the size",
    "start": "1926399",
    "end": "1933399"
  },
  {
    "text": "of the surge Q is 1,24 requests in in the search queue after which we'll actually start returning",
    "start": "1933399",
    "end": "1939600"
  },
  {
    "text": "503s just just a little note at Amazon we actually don't use surge cues internally uh Amazon's actually gone and",
    "start": "1939600",
    "end": "1945360"
  },
  {
    "text": "turned off a lot of the surge cues and at some point will offer functionality in elb to control your surge queue um",
    "start": "1945360",
    "end": "1950799"
  },
  {
    "text": "and one of the reasons there is sometimes you can see clients actually timing out waiting on a surge queue and it can have distributed impact so on",
    "start": "1950799",
    "end": "1957200"
  },
  {
    "text": "this one uh if you see any surge queing it's a really good metric to watch and set an alarm on if you see any surge",
    "start": "1957200",
    "end": "1962639"
  },
  {
    "text": "queing with your load balance it's an indication that you may be unders scaled on the back end um so you want to think about adding",
    "start": "1962639",
    "end": "1969960"
  },
  {
    "text": "capacity one thing I just wanted to mention quickly here was cloudwatch and Order scaling so uh elb has great integ",
    "start": "1970600",
    "end": "1977320"
  },
  {
    "text": "integration with Auto scaling you can use an auto scaling group add machines and then register them with a load balancer um you can actually use all of",
    "start": "1977320",
    "end": "1983679"
  },
  {
    "text": "the elb matrics uh together with cloudwatch to actually that sorry that elb publishes to cloudwatch to actually",
    "start": "1983679",
    "end": "1989360"
  },
  {
    "text": "do aut scaling so you might want to aut scale on surge cues it might be a little late by the time you see in sege cues",
    "start": "1989360",
    "end": "1994399"
  },
  {
    "text": "but maybe latency is a good one um so you know you may want to consider using some of those one of the things we see",
    "start": "1994399",
    "end": "1999880"
  },
  {
    "text": "with customers and Autos scaling that can sometimes catch us out is um often we'll talk about our application and say",
    "start": "1999880",
    "end": "2006360"
  },
  {
    "text": "oh I'm I'm I'm you know I'm at Peak at the moment so I'm at my highest load and I think we all see that if you have an",
    "start": "2006360",
    "end": "2011399"
  },
  {
    "text": "application that has sort of the daily curve or hourly curve or whatever it might be you talk about being at the peak of the curve when you order scaling",
    "start": "2011399",
    "end": "2018039"
  },
  {
    "text": "one of the things to keep in mind is you add you're removing machines and adding machines all the way through that curve",
    "start": "2018039",
    "end": "2023440"
  },
  {
    "text": "so depending on how much capacity or how much Headroom you're leaving you could actually always be at Peak so we see",
    "start": "2023440",
    "end": "2028919"
  },
  {
    "text": "some customers that are actually surprised because they see a performance issue at the bottom of their curve but actually it's all relative they've removed more capacity than they should",
    "start": "2028919",
    "end": "2035159"
  },
  {
    "text": "have when they got to the bottom of the curve um so if you are order scaling just keep in mind that you need to be watching how you're doing throughout the",
    "start": "2035159",
    "end": "2041320"
  },
  {
    "text": "curve and not just you know how much capacity do I have at Peak because you may actually be in more trouble during a trough than you would be at the peak the",
    "start": "2041320",
    "end": "2047799"
  },
  {
    "text": "other thing is when you Autos scale on something like CPU make sure you're watching memory and connections and all",
    "start": "2047799",
    "end": "2053520"
  },
  {
    "text": "of the other metrics as well um we do see people watch CPU CPU and then you know they run into memory issues or they",
    "start": "2053520",
    "end": "2059000"
  },
  {
    "text": "run into connection limits or something like that on their back end instance so it's very important that you keep an eye on all of the available metrics which",
    "start": "2059000",
    "end": "2064960"
  },
  {
    "text": "are all available in cloudwatch a feature we launched uh earlier this",
    "start": "2064960",
    "end": "2070919"
  },
  {
    "text": "year called access logs uh this is a really really useful one um so you know if if you see for example let's say we",
    "start": "2070919",
    "end": "2077079"
  },
  {
    "text": "have a very high latency we seen High latency if we look at our Max latency on our load balancer we've seen some",
    "start": "2077079",
    "end": "2082800"
  },
  {
    "text": "requests take 60 seconds um and now we don't know how many they are there might just be one of them every every minute",
    "start": "2082800",
    "end": "2089800"
  },
  {
    "text": "um but would be great to know which one it is and and why it is so what you can do is you can go in and enable access",
    "start": "2089800",
    "end": "2095280"
  },
  {
    "text": "logs and what access logs is it it records every single request made through your load balancer and actually",
    "start": "2095280",
    "end": "2101760"
  },
  {
    "text": "sends those to S3 so you can think of it as essentially cloud trail for your EB so every request that's made by your",
    "start": "2101760",
    "end": "2107800"
  },
  {
    "text": "customers through your load balancer will be delivered to S3 either every 5 minutes or every hour and then we've",
    "start": "2107800",
    "end": "2113480"
  },
  {
    "text": "integrated with a whole lot of other log providers like Splunk consumer logic that actually offer direct integration",
    "start": "2113480",
    "end": "2118520"
  },
  {
    "text": "with elb access logs so you can essentially get really really detailed Matrix almost immediately by just",
    "start": "2118520",
    "end": "2123599"
  },
  {
    "text": "enabling access logs and using one of those providers or we also have an EMR map reduce uh tutorial and a Blog on how",
    "start": "2123599",
    "end": "2130680"
  },
  {
    "text": "to use elastic map reduce together with Hive to actually search these logs so if you saw a latency Spike you'd be able to",
    "start": "2130680",
    "end": "2136320"
  },
  {
    "text": "enable access logs and actually find the request that saw High latency and diagnose what happened and we see a lot of customers doing that highly",
    "start": "2136320",
    "end": "2143520"
  },
  {
    "text": "recommended as I said access logs are delivered directly from the load balancer 2 S3 and we include a lot of",
    "start": "2143520",
    "end": "2149760"
  },
  {
    "text": "information in the actual file name one of the things we put in the file name is the IP address of the EB node so you can",
    "start": "2149760",
    "end": "2156240"
  },
  {
    "text": "actually identify which IP in DNS uh was actually giving problems so you might have a client saying I connected to this",
    "start": "2156240",
    "end": "2162000"
  },
  {
    "text": "IP you can go look at the access logs for that IP so there is a way of mapping it back and then we do provide more",
    "start": "2162000",
    "end": "2167839"
  },
  {
    "text": "information than we provide via the latency metric for example in cloudwatch so the request processing time backend",
    "start": "2167839",
    "end": "2173680"
  },
  {
    "text": "processing time and response processing time um the request processing time is time in the load balancer on the request",
    "start": "2173680",
    "end": "2179640"
  },
  {
    "text": "and you got the back end which is the same as the latency metric and then you've got the time in the load balancer on the response so you get much much",
    "start": "2179640",
    "end": "2185800"
  },
  {
    "text": "more detailed um metric and we do plan over time to continue to add um to the access logs functionality to give you",
    "start": "2185800",
    "end": "2191720"
  },
  {
    "text": "more and more functionality there has a good saying uh another one",
    "start": "2191720",
    "end": "2198280"
  },
  {
    "text": "from verer everything fails all the time um and it's not necessarily that everything",
    "start": "2198280",
    "end": "2204400"
  },
  {
    "text": "fails all the time thank goodness um but it's more that we should approach things with that attitude so if we're expecting",
    "start": "2204400",
    "end": "2209440"
  },
  {
    "text": "things to fail um then we think about our architecture in a different way and what I'm going to share with you now is",
    "start": "2209440",
    "end": "2214480"
  },
  {
    "text": "some some of the things we've done on elb um to to really make sure that we can deal with any sort of event um at",
    "start": "2214480",
    "end": "2222240"
  },
  {
    "text": "scale uh and what's super important for us is we can't allow our scale to impact our recovery times for an individual",
    "start": "2222240",
    "end": "2228920"
  },
  {
    "text": "customer I'm saying hey it took us several hours to recover because we got so many load balances it's just not not an acceptable excuse it needs to be the",
    "start": "2228920",
    "end": "2236000"
  },
  {
    "text": "same time for every customer and guaranteed so that's one of the challenges we have so um the first thing that we",
    "start": "2236000",
    "end": "2242000"
  },
  {
    "text": "say is be prepared to do nothing so when you lose an availability Zone be prepared to do nothing if you",
    "start": "2242000",
    "end": "2248960"
  },
  {
    "text": "have to do anything if you have to call an API or go and do something manually",
    "start": "2248960",
    "end": "2254119"
  },
  {
    "text": "like that's all just a risk no matter how highly available those apis may be or you believe they are having to do",
    "start": "2254119",
    "end": "2260119"
  },
  {
    "text": "anything when something fails is a risk so you've got to do as much preparation ahead of time to make sure that when",
    "start": "2260119",
    "end": "2266240"
  },
  {
    "text": "something fails you you don't have to engage people or engage systems to do things and one of the things we do on",
    "start": "2266240",
    "end": "2271599"
  },
  {
    "text": "elb and we talk about it shortly is the way we scale all of these load balances we've got enough capacity in the system to remove an availability Zone at any",
    "start": "2271599",
    "end": "2278240"
  },
  {
    "text": "point in time and be happy that that traffic shifts over there's nothing in the system that's going to have to launch replacement instances or do",
    "start": "2278240",
    "end": "2284720"
  },
  {
    "text": "anything the only thing that happens is a Route 53 health check shifts",
    "start": "2284720",
    "end": "2289760"
  },
  {
    "text": "over then we have three three phases of an LSC or large large scale event the",
    "start": "2290520",
    "end": "2296200"
  },
  {
    "text": "first one is mitigation how do we shift traffic how do we we've just had some impact to customers how do we make sure",
    "start": "2296200",
    "end": "2301960"
  },
  {
    "text": "that that impact doesn't last the second one is isolation how do we make sure that that impact only stays within a",
    "start": "2301960",
    "end": "2307520"
  },
  {
    "text": "single availability on and the last one is restoring redundancy how do we bring the system back into working",
    "start": "2307520",
    "end": "2315078"
  },
  {
    "text": "order on on mitigation as I said earlier all load balances are scaled to handle",
    "start": "2315160",
    "end": "2320319"
  },
  {
    "text": "the loss of a single availability zone so we make sure if you're in two availability zones we are going to double up in the capacity in either one",
    "start": "2320319",
    "end": "2326720"
  },
  {
    "text": "so we can handle the load if we lost one if you're in three you can work it out we'll add extra capacity in those zones",
    "start": "2326720",
    "end": "2332319"
  },
  {
    "text": "so we always make sure we have the capacity available and then something I highly recommend you use in all of your",
    "start": "2332319",
    "end": "2337680"
  },
  {
    "text": "own application Stacks as well as the Route 53 health checks so Route 53 can execute health checks every few minutes",
    "start": "2337680",
    "end": "2344000"
  },
  {
    "text": "and those health checks will actually oh sorry every few seconds and if we have enough failures we'll actually stop serving that IP Works incredibly well so",
    "start": "2344000",
    "end": "2351040"
  },
  {
    "text": "mitigation for our customers is completed within 15 seconds so if we have any problem with an IP address or a",
    "start": "2351040",
    "end": "2356560"
  },
  {
    "text": "large number of load balances within 150 seconds and 90 seconds for some of the newer load balances we'll have shifted",
    "start": "2356560",
    "end": "2362119"
  },
  {
    "text": "traffic out of that zone so you should expect to see up to 150 seconds of latency SE and errors but after that it",
    "start": "2362119",
    "end": "2368440"
  },
  {
    "text": "should all recover cuz we've shifted the traffic out no and absolutely no dependencies on",
    "start": "2368440",
    "end": "2374280"
  },
  {
    "text": "control planes I don't have to do anything there's nothing that elbs to call there's no instances to launch just",
    "start": "2374280",
    "end": "2379359"
  },
  {
    "text": "the DNS shift and that mitigates the impact the second one's isolation so in",
    "start": "2379359",
    "end": "2385160"
  },
  {
    "text": "a system like this you you've really got to make sure that your other zones remain unaffected so if we have a",
    "start": "2385160",
    "end": "2390599"
  },
  {
    "text": "problem in one zone and you can't go in a register an instance in another Zone that's going to be a problem for customers so we've got to make sure that",
    "start": "2390599",
    "end": "2396839"
  },
  {
    "text": "registration creation all the things that you can do with a lad balancer continue to work in the apis and that",
    "start": "2396839",
    "end": "2401880"
  },
  {
    "text": "the lad balances in the other zones remain completely healthy one of the things that is interesting to think",
    "start": "2401880",
    "end": "2408040"
  },
  {
    "text": "about is how much work does an event like this generate for the system if you have a system that says I've just lost",
    "start": "2408040",
    "end": "2415560"
  },
  {
    "text": "I've just lost a Zone okay well let me go and launch replacement instances in another Zone well let me frantically go",
    "start": "2415560",
    "end": "2421079"
  },
  {
    "text": "and try and connect to these instances and bring them back to health like how much work does a failure generate for",
    "start": "2421079",
    "end": "2426440"
  },
  {
    "text": "the system and we've seen many many systems where the work that a failure generates actually causes additional",
    "start": "2426440",
    "end": "2432520"
  },
  {
    "text": "problems so you want to generate as little work as possible uh and actually throttle that work back and not need to",
    "start": "2432520",
    "end": "2437839"
  },
  {
    "text": "do that and operating at reduced capacity once we've mitigated that's okay you just had reduced capacity",
    "start": "2437839",
    "end": "2444119"
  },
  {
    "text": "obviously at more risk now because you're down to two availability zones that three but you should be able to stay at that State while you focus on",
    "start": "2444119",
    "end": "2450240"
  },
  {
    "text": "restoring the system one of the important things we do is sort of uh in elb is we we do we do",
    "start": "2450240",
    "end": "2457760"
  },
  {
    "text": "constant work so one of the things that might introduce extra work for the system is if you if you have something",
    "start": "2457760",
    "end": "2463680"
  },
  {
    "text": "where every time it finds a failed node it goes and puts something on a que and then goes and replaces that and works on",
    "start": "2463680",
    "end": "2469359"
  },
  {
    "text": "that and says okay I just saw a failed node I'm going to process my queue now you suddenly see 50,000 failed nodes and",
    "start": "2469359",
    "end": "2474720"
  },
  {
    "text": "your queue is 50,000 deep and you can't take anything but those events and you don't have enough workers and you",
    "start": "2474720",
    "end": "2480160"
  },
  {
    "text": "flooded the system so we don't do that model what we do is we we will do constant work so every single load",
    "start": "2480160",
    "end": "2485560"
  },
  {
    "text": "balancer tells us its health every few seconds and they all say we're healthy we're healthy we're healthy so we always",
    "start": "2485560",
    "end": "2491359"
  },
  {
    "text": "processing the full Fleet at the last minute we'll just say a few of them will start saying okay we're unhealthy but it's no extra work for us there's no",
    "start": "2491359",
    "end": "2496880"
  },
  {
    "text": "more requests in the system we always handle in full scale and then the last one is restoring",
    "start": "2496880",
    "end": "2502720"
  },
  {
    "text": "the system back to full capacity and as I said you don't want to generate too much work for the system and make it unstable so you're actually happy for",
    "start": "2502720",
    "end": "2509240"
  },
  {
    "text": "this to take a while because you've mitigated you're actually stable and you want to bring back that capacity and",
    "start": "2509240",
    "end": "2514760"
  },
  {
    "text": "what you'll see with elb is as IPS will start to shift shft back into the failed",
    "start": "2514760",
    "end": "2520599"
  },
  {
    "text": "zone so we haven't had time to dive into a lot more areas I've tried to dive into quite a few of the areas um with the elb",
    "start": "2523880",
    "end": "2530680"
  },
  {
    "text": "and go a little bit deeper than we've been before give you some more information than you'd see in our documentation I do hope it was valuable",
    "start": "2530680",
    "end": "2536760"
  },
  {
    "text": "I will be around afterwards for questions if they are any so thank you very much for your time",
    "start": "2536760",
    "end": "2543160"
  }
]
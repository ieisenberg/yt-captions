[
  {
    "start": "0",
    "end": "102000"
  },
  {
    "text": "welcome everyone how are you enjoying reinvent so far",
    "start": "800",
    "end": "6710"
  },
  {
    "text": "adds the spirit so my name is Vlad Lazcano I'm a Solutions Architect with Amazon Web Services and with me today I",
    "start": "6710",
    "end": "14759"
  },
  {
    "text": "have Ganesh Subramanyam from fulfillment with by Amazon and Brandon cup from",
    "start": "14759",
    "end": "20580"
  },
  {
    "text": "scope Lee who will also speak about their experience with AWS I ask that you hold your questions until",
    "start": "20580",
    "end": "27869"
  },
  {
    "text": "the end we have microphones over there so everybody can hear them",
    "start": "27869",
    "end": "32810"
  },
  {
    "text": "so just by a quick show of hands how many of you are using serverless architectures are several s technologies",
    "start": "33440",
    "end": "40170"
  },
  {
    "text": "today ok so a few of you that means that at least a couple of you",
    "start": "40170",
    "end": "47219"
  },
  {
    "text": "are wondering why we're having a server less talk in the databases track in many ways the answer to that question",
    "start": "47219",
    "end": "54539"
  },
  {
    "text": "comes from the tremendous adoption that we've seen with certain serverless technologies over the last two years and",
    "start": "54539",
    "end": "61230"
  },
  {
    "text": "for every imaginable use case and the versatility of these architectures are",
    "start": "61230",
    "end": "67680"
  },
  {
    "text": "very compelling and why would high performance data be any different",
    "start": "67680",
    "end": "75530"
  },
  {
    "text": "today we'll cover a quick overview on serverless architectures and the",
    "start": "75530",
    "end": "81600"
  },
  {
    "text": "patterns that we see in high-performance data use cases and then we'll hear from",
    "start": "81600",
    "end": "87330"
  },
  {
    "text": "the folks from fulfillment by Amazon and scope Lee how serverless architectures",
    "start": "87330",
    "end": "92820"
  },
  {
    "text": "help them be more agile and optimize their costs",
    "start": "92820",
    "end": "101090"
  },
  {
    "text": "so just starting from the beginning serverless architectures are here to",
    "start": "101600",
    "end": "107759"
  },
  {
    "start": "102000",
    "end": "102000"
  },
  {
    "text": "help you build applications and services I know that's no surprise to any of you",
    "start": "107759",
    "end": "112799"
  },
  {
    "text": "here in the room but only do that without managing any sort of or",
    "start": "112799",
    "end": "120570"
  },
  {
    "text": "having to manage any sort of infrastructure no hardware no virtual",
    "start": "120570",
    "end": "125610"
  },
  {
    "text": "machines or no containers that you have to manage so you can run your services on all your applications",
    "start": "125610",
    "end": "133280"
  },
  {
    "text": "oops and you do that by changing what the",
    "start": "133280",
    "end": "139680"
  },
  {
    "text": "computational unit of scale is it's no longer server hosting a monolithic",
    "start": "139680",
    "end": "145710"
  },
  {
    "text": "application or a micro service of some kind it's the single purpose function that's",
    "start": "145710",
    "end": "153930"
  },
  {
    "text": "the computational unit of scale everything else is abstracted from the",
    "start": "153930",
    "end": "160200"
  },
  {
    "text": "hardware all the way up to the language runtime so you can just focus on the",
    "start": "160200",
    "end": "166080"
  },
  {
    "text": "code that you have to run and this um this has some compelling benefits for",
    "start": "166080",
    "end": "173160"
  },
  {
    "text": "once there's less development develop development and operational complexity that you have to deal with",
    "start": "173160",
    "end": "179610"
  },
  {
    "text": "and in turn that increases your agility and you only execute those functions",
    "start": "179610",
    "end": "186030"
  },
  {
    "text": "when you when they really need it which optimizes the own cost because you're",
    "start": "186030",
    "end": "191220"
  },
  {
    "text": "actually only paying for the time and a number of invocations for those functions",
    "start": "191220",
    "end": "196400"
  },
  {
    "text": "this is game changing because functional units and applications fundamentally",
    "start": "196400",
    "end": "201930"
  },
  {
    "text": "have vastly different utilization profiles in scaling needs",
    "start": "201930",
    "end": "208489"
  },
  {
    "text": "so naturally at the center of any server less architecture is a WS lambda the",
    "start": "209420",
    "end": "216780"
  },
  {
    "start": "210000",
    "end": "210000"
  },
  {
    "text": "service that allows you to run such functions in the cloud only it's the whole ecosystem of",
    "start": "216780",
    "end": "225860"
  },
  {
    "text": "services and components that interact with AWS lambda that actually make that",
    "start": "225860",
    "end": "234290"
  },
  {
    "text": "server less architecture and make it such a compelling proposition you've got",
    "start": "234290",
    "end": "239400"
  },
  {
    "text": "triggers and event sources for functions you've got streaming data that's being",
    "start": "239400",
    "end": "245850"
  },
  {
    "text": "processed by lambda function you've got data persistent services so data can be",
    "start": "245850",
    "end": "251430"
  },
  {
    "text": "persisted anything that gets processed by those lambda function you've got integration points with other AWS",
    "start": "251430",
    "end": "258000"
  },
  {
    "text": "services with third-party services integration with your V PC so you can access any sort of",
    "start": "258000",
    "end": "265020"
  },
  {
    "text": "resources that are in to your you know affected to your internet to",
    "start": "265020",
    "end": "270790"
  },
  {
    "text": "your in virtual private cloud or legacy applications",
    "start": "270790",
    "end": "276630"
  },
  {
    "text": "and with all these components of a serverless architecture data is always",
    "start": "276630",
    "end": "283690"
  },
  {
    "start": "277000",
    "end": "277000"
  },
  {
    "text": "the key part of that architecture whether that you know when you're looking at it you know you your",
    "start": "283690",
    "end": "290200"
  },
  {
    "text": "functions are acting on data data is the input and then there's",
    "start": "290200",
    "end": "295680"
  },
  {
    "text": "your functions are actual processing data or if yelling that data or",
    "start": "295680",
    "end": "301650"
  },
  {
    "text": "manipulating it in any sort of way to match the business logic and then you know that data then gets persistent",
    "start": "301650",
    "end": "307690"
  },
  {
    "text": "somewhere or gets returned back part of your functional response",
    "start": "307690",
    "end": "315450"
  },
  {
    "text": "and these create repeatable abstractions",
    "start": "315450",
    "end": "321040"
  },
  {
    "start": "316000",
    "end": "316000"
  },
  {
    "text": "that are central to how AWS lambda interacts with data you've got lambda",
    "start": "321040",
    "end": "327130"
  },
  {
    "text": "functions that are event handlers and these for these types of functions you know the",
    "start": "327130",
    "end": "332910"
  },
  {
    "text": "the computational purpose of that function is to do something with an incoming event type and only",
    "start": "332910",
    "end": "340740"
  },
  {
    "text": "events matching that specific type you've got lambda functions that are",
    "start": "340740",
    "end": "347620"
  },
  {
    "text": "acting as serverless backends and in that case the abstraction is that API",
    "start": "347620",
    "end": "352840"
  },
  {
    "text": "call or the path of that API and that function is only designed to act on that",
    "start": "352840",
    "end": "358440"
  },
  {
    "text": "structure on that specific restful pattern and then you have lambda",
    "start": "358440",
    "end": "364240"
  },
  {
    "text": "functions in streaming data use cases",
    "start": "364240",
    "end": "369870"
  },
  {
    "text": "data processing are very strong use cases for lambda the abstraction there",
    "start": "369870",
    "end": "374950"
  },
  {
    "text": "is a record or a data type again the function will process only data of that",
    "start": "374950",
    "end": "380590"
  },
  {
    "text": "type on that specific format so this will only helps maintainability",
    "start": "380590",
    "end": "388110"
  },
  {
    "text": "but it puts a clearer focus on the data that needs to be handled by any given",
    "start": "388110",
    "end": "394870"
  },
  {
    "text": "function process or flow it becomes really really tough in that kind of an invite armen to build spaghetti code or",
    "start": "394870",
    "end": "402010"
  },
  {
    "text": "monolithic applications and with this in mind we see two",
    "start": "402010",
    "end": "409030"
  },
  {
    "start": "407000",
    "end": "407000"
  },
  {
    "text": "patterns and two main patterns of adoption for serverless architectures in",
    "start": "409030",
    "end": "414940"
  },
  {
    "text": "high-performance data use cases so one of them is where lambda is actually",
    "start": "414940",
    "end": "420160"
  },
  {
    "text": "playing an active role this is where lambda is used part of the workload itself its front and center",
    "start": "420160",
    "end": "427450"
  },
  {
    "text": "they're processing your data you know scaling on demand based on how",
    "start": "427450",
    "end": "433120"
  },
  {
    "text": "much data is flowing into that system its API driven and those used to process",
    "start": "433120",
    "end": "439120"
  },
  {
    "text": "data potentially part of an ETL orchestration framework but in either of those cases its front and center there",
    "start": "439120",
    "end": "446200"
  },
  {
    "text": "is the central part that's driving your business logic so the advantages in",
    "start": "446200",
    "end": "452320"
  },
  {
    "text": "these case we see around reducing operational complexities you've got",
    "start": "452320",
    "end": "457890"
  },
  {
    "text": "functions that are scaling independently decoupled of other functions in your application and you're only paying for",
    "start": "457890",
    "end": "465220"
  },
  {
    "text": "the code that's actually running at that point rather than paying for a host or a service we're not necessarily all the",
    "start": "465220",
    "end": "471790"
  },
  {
    "text": "code paths might be active at any given point in time now not everyone of course can build",
    "start": "471790",
    "end": "479800"
  },
  {
    "text": "applications from scratch matching these serverless architectures",
    "start": "479800",
    "end": "485070"
  },
  {
    "text": "and many of us have applications that's been running for several years now you",
    "start": "485070",
    "end": "490990"
  },
  {
    "text": "know they're not necessarily at the point where they can completely redesign everything and that's okay so in those",
    "start": "490990",
    "end": "499300"
  },
  {
    "text": "kinds of use cases we see lambda working in a support role",
    "start": "499300",
    "end": "505170"
  },
  {
    "text": "so this is where lambda is used in some form or fashion to optimize a pre-existing workload the pre-existing",
    "start": "505170",
    "end": "511810"
  },
  {
    "text": "application there's many really ways you can do that we've seen use cases where",
    "start": "511810",
    "end": "517180"
  },
  {
    "text": "lambda assists with database utilization we've seen lambda use cases where as assists with scaling over legacy",
    "start": "517180",
    "end": "523780"
  },
  {
    "text": "application we've seen lambda where as assist with anomaly detection ensuring",
    "start": "523780",
    "end": "528970"
  },
  {
    "text": "that you know the application works correctly or data accesses",
    "start": "528970",
    "end": "534130"
  },
  {
    "text": "correct we've seen lambda assisting in monitoring and logging solutions so",
    "start": "534130",
    "end": "539470"
  },
  {
    "text": "these are all cases well where lambda is still their server unless architectures",
    "start": "539470",
    "end": "545110"
  },
  {
    "text": "are still there but they're in the support role just making sure that the application that you're mainly running is running as effectively as possible",
    "start": "545110",
    "end": "552730"
  },
  {
    "text": "so indirectly you're still benefiting from cost optimizations right you're",
    "start": "552730",
    "end": "558250"
  },
  {
    "text": "having a situation where you know because your applications run where it",
    "start": "558250",
    "end": "563470"
  },
  {
    "text": "runs more effectively you're saving you're saving and optimizing on cost",
    "start": "563470",
    "end": "571290"
  },
  {
    "text": "there's also a couple of other types of advantages in disguise these kinds of use cases you know your applications are",
    "start": "571290",
    "end": "578769"
  },
  {
    "text": "more resilient there's something there watching it 24/7 and ensuring that it's working correctly and potentially can",
    "start": "578769",
    "end": "585130"
  },
  {
    "text": "also actually make it work even at higher higher performance and",
    "start": "585130",
    "end": "590490"
  },
  {
    "text": "to illustrate the use of lambda in both these rules we have Ganesh from",
    "start": "590490",
    "end": "597009"
  },
  {
    "text": "fulfillment by Amazon and we'll talk about their service architecture for the seller inventory authority platform and",
    "start": "597009",
    "end": "605319"
  },
  {
    "text": "then we'll have Brandon cuff from scope Lee will show you how they're using",
    "start": "605319",
    "end": "610630"
  },
  {
    "text": "lambda to detect and track hot keys in their applications and with this I want",
    "start": "610630",
    "end": "615939"
  },
  {
    "text": "to invite Ganesh to the stage",
    "start": "615939",
    "end": "619439"
  },
  {
    "text": "hello everyone my name is Ganesh I'm a senior engineer at Amazon working on",
    "start": "633120",
    "end": "638279"
  },
  {
    "text": "inventory systems and I'm here to talk about the inventory data platform that we",
    "start": "638279",
    "end": "644579"
  },
  {
    "text": "built with the serverless architecture with that I'm sure a lot of you have already done",
    "start": "644579",
    "end": "651660"
  },
  {
    "text": "your holiday shopping or you might have already started your holiday shopping show fans how many of you have heard the",
    "start": "651660",
    "end": "658079"
  },
  {
    "text": "term FBA quite a few so",
    "start": "658079",
    "end": "664370"
  },
  {
    "text": "here is an FBA item that is sold on",
    "start": "664370",
    "end": "670199"
  },
  {
    "text": "Amazon and the way to identify an FBI item is if you look at the seller on record it has a seller and next to it it",
    "start": "670199",
    "end": "677069"
  },
  {
    "text": "has fulfilled by Amazon and FBA items are eligible for free shipping as part",
    "start": "677069",
    "end": "682170"
  },
  {
    "text": "of Amazon Prime free two-day shipping as part of Amazon Prime and",
    "start": "682170",
    "end": "687199"
  },
  {
    "text": "let's look at how FBA works and what are the inventory challenges and in this",
    "start": "687860",
    "end": "693360"
  },
  {
    "text": "space FBA is a service offered by Amazon for sellers to sell their inventory through",
    "start": "693360",
    "end": "699600"
  },
  {
    "text": "Amazon by having them send their items into our Amazon warehouses where we",
    "start": "699600",
    "end": "705179"
  },
  {
    "text": "manage the inventory when the order comes in we pack and deliver it to the buyer so seller since their inventory we",
    "start": "705179",
    "end": "713939"
  },
  {
    "text": "send it to the buyer when the order comes in and we handle the customer service after the sales has happened",
    "start": "713939",
    "end": "720170"
  },
  {
    "text": "sailors don't have to worry about managing warehouses or doing the tedious task of",
    "start": "720170",
    "end": "727589"
  },
  {
    "text": "fulfilling the item buyers get the",
    "start": "727589",
    "end": "734269"
  },
  {
    "text": "experience that they always expect from Amazon fast shipping",
    "start": "734269",
    "end": "739519"
  },
  {
    "text": "great customer service and Amazon benefits from this by having increased",
    "start": "739519",
    "end": "744929"
  },
  {
    "text": "selection because sellers bring in a lot of items into the marketplace that might not have already been existing so it's a",
    "start": "744929",
    "end": "751829"
  },
  {
    "text": "truly win-win-win situation for the sellers the buyers and the Amazon in this platform so",
    "start": "751829",
    "end": "758688"
  },
  {
    "text": "sellers send their inventory to Amazon by indicating how many items they have",
    "start": "758959",
    "end": "764809"
  },
  {
    "text": "they go to sent and we receive it in our warehouses when",
    "start": "764809",
    "end": "770360"
  },
  {
    "text": "we received that it goes through multiple stages into in the warehouse we",
    "start": "770360",
    "end": "776470"
  },
  {
    "text": "receive it we might ranch ship it to another warehouse and then finally it might get stored in some place during",
    "start": "776470",
    "end": "783259"
  },
  {
    "text": "all this process the inventory level of the seller keeps fluctuating it the",
    "start": "783259",
    "end": "789459"
  },
  {
    "text": "inventory gets added into the account when we actually receive it the inventory will get subtracted when the",
    "start": "789459",
    "end": "795860"
  },
  {
    "text": "order is fulfilled or when we move items from one where else to another the",
    "start": "795860",
    "end": "801500"
  },
  {
    "text": "warehouse management system struck these different inventory movements but they are not responsible for providing an",
    "start": "801500",
    "end": "808639"
  },
  {
    "text": "aggregated view of the sellers inventory and that's where this data platform comes in we have a number of systems with an FBA",
    "start": "808639",
    "end": "816980"
  },
  {
    "text": "that use this inventory information and every system trying to aggregate all of this information would become a very",
    "start": "816980",
    "end": "823670"
  },
  {
    "text": "costly exercise to address this be built a data platform",
    "start": "823670",
    "end": "829519"
  },
  {
    "start": "826000",
    "end": "826000"
  },
  {
    "text": "with the following goals one it has to be a single source of sellers single source of truth for sellers inventory we",
    "start": "829519",
    "end": "836870"
  },
  {
    "text": "wanted to make sure that not every system has to aggregate all the different input the inventory movements",
    "start": "836870",
    "end": "843800"
  },
  {
    "text": "and trying to aggregate this number two we wanted to have a reconciled view of the inventory",
    "start": "843800",
    "end": "849310"
  },
  {
    "text": "we wanted to explain how the inventory changes from position 8x to position y",
    "start": "849310",
    "end": "855069"
  },
  {
    "text": "and lastly when we are not able to explain it we wanted surface and track",
    "start": "855069",
    "end": "860480"
  },
  {
    "text": "those discrepancies and that's the role of this data platform so if you look at what are the design",
    "start": "860480",
    "end": "868850"
  },
  {
    "start": "865000",
    "end": "865000"
  },
  {
    "text": "requirements for this data platform it should be able to handle a really high volume of input messages and it should",
    "start": "868850",
    "end": "877310"
  },
  {
    "text": "be able to be resilient to handle the hot key syndrome which is a very quick",
    "start": "877310",
    "end": "882410"
  },
  {
    "text": "burst of events or messages for a single key or a set of keys one key should not",
    "start": "882410",
    "end": "888819"
  },
  {
    "text": "or transactions for one key should not impact the rest of the processing it",
    "start": "888819",
    "end": "895610"
  },
  {
    "text": "should handle duplicate and out of order messages and we wanted to maintain a complete it ordered of every single",
    "start": "895610",
    "end": "902360"
  },
  {
    "text": "inventory change that happens so that we can go back and explain as to why the",
    "start": "902360",
    "end": "907760"
  },
  {
    "text": "inventory position is what it is and make sure that we have complete traceability through the entire pipeline",
    "start": "907760",
    "end": "915970"
  },
  {
    "start": "916000",
    "end": "916000"
  },
  {
    "text": "for when we started building this architecture we wanted to go with",
    "start": "916149",
    "end": "921380"
  },
  {
    "text": "completely managed services because it makes sense to avoid operational",
    "start": "921380",
    "end": "927670"
  },
  {
    "text": "pinpoints that you encounter when you manage your own hardware and posts and",
    "start": "927670",
    "end": "933770"
  },
  {
    "text": "everything so we chose lamda as the central",
    "start": "933770",
    "end": "938990"
  },
  {
    "text": "component of this architecture and Genesis is the stream",
    "start": "938990",
    "end": "947200"
  },
  {
    "text": "processing or the stream unit that manages all these events coming into our",
    "start": "947200",
    "end": "952730"
  },
  {
    "text": "pipeline the kinases lamda integration makes it really easy to",
    "start": "952730",
    "end": "958270"
  },
  {
    "text": "build these kinds of solutions so if you look at it we have various management",
    "start": "958270",
    "end": "964730"
  },
  {
    "text": "systems emitting different events into a transaction service we these messages",
    "start": "964730",
    "end": "971240"
  },
  {
    "text": "get queued up in the kinases streams and we have lambda processes that take each",
    "start": "971240",
    "end": "976760"
  },
  {
    "text": "event coming in the knesset stream and processing it and storing it in our dynamo DB store",
    "start": "976760",
    "end": "983890"
  },
  {
    "text": "once it gets into DynamoDB stores we have dynamodb update streams that emit",
    "start": "983890",
    "end": "989270"
  },
  {
    "text": "the changes coming from these records or persisted items in the",
    "start": "989270",
    "end": "995900"
  },
  {
    "text": "dynamodb that is further post process using additional lambda functions and we",
    "start": "995900",
    "end": "1001300"
  },
  {
    "text": "build an aggregated view of this inventory once the aggregated view of inventory is persisted again and dynamodb further it gets published into",
    "start": "1001300",
    "end": "1009130"
  },
  {
    "text": "elasticsearch so that we can easily search across aggregated sorted and do those kinds of",
    "start": "1009130",
    "end": "1016440"
  },
  {
    "text": "retrieval patterns that dynamodb is not really good at and then we use SNS to",
    "start": "1016440",
    "end": "1023800"
  },
  {
    "text": "publish notifications whenever any inventory position changes so that our clients can either get notified when",
    "start": "1023800",
    "end": "1031449"
  },
  {
    "text": "some inventory level changes or they can into the system and query from elasticsearch store to get the inventory",
    "start": "1031449",
    "end": "1039400"
  },
  {
    "text": "data that they need through all of these processes we have archival front and center we archive",
    "start": "1039400",
    "end": "1046660"
  },
  {
    "text": "both in s3 as well as in redshift s3 is used for typical traditional archiving",
    "start": "1046660",
    "end": "1051820"
  },
  {
    "text": "and redshift is used for operational management if we wanted to go and query what happened to a particular seller's",
    "start": "1051820",
    "end": "1058840"
  },
  {
    "text": "inventory it's easier to query in a redshift rather than trying to write an EMR script going against s3",
    "start": "1058840",
    "end": "1065490"
  },
  {
    "text": "for that we use lambda processes that publish the data into kinases firehoses",
    "start": "1065490",
    "end": "1071140"
  },
  {
    "text": "that finally gets into the final end state",
    "start": "1071140",
    "end": "1075960"
  },
  {
    "text": "so after building this system if you look back and what the",
    "start": "1076350",
    "end": "1082720"
  },
  {
    "text": "results of this journey was first because of the serverless",
    "start": "1082720",
    "end": "1088690"
  },
  {
    "text": "technology is because of lambda kinases DynamoDB all of them are a douglass managed services we don't really have to",
    "start": "1088690",
    "end": "1096300"
  },
  {
    "text": "spend too much time on operational overhead we were able to quantify a savings about",
    "start": "1096300",
    "end": "1103810"
  },
  {
    "text": "22 degrees across this entire platform because we don't have to worry about hosts monitoring load balancer",
    "start": "1103810",
    "end": "1111040"
  },
  {
    "text": "monitoring setting up alarms on hosts worrying about how to scale for the cue",
    "start": "1111040",
    "end": "1117250"
  },
  {
    "text": "for Holliday peak and then those kinds of things these are elastic services that we can scale easily without having",
    "start": "1117250",
    "end": "1123550"
  },
  {
    "text": "to spend a tremendous time and effort in doing this again because of using lambda which is",
    "start": "1123550",
    "end": "1131670"
  },
  {
    "text": "single purpose unit functions and built-in integration with the various",
    "start": "1131670",
    "end": "1136900"
  },
  {
    "text": "AWS services we were able to go from design to launch in less than four months which is a big success for this",
    "start": "1136900",
    "end": "1144610"
  },
  {
    "text": "platform with this architecture we were able to improve accuracy of our inventory",
    "start": "1144610",
    "end": "1150370"
  },
  {
    "text": "quantities and due to that we were able to save on cost of business operations",
    "start": "1150370",
    "end": "1156520"
  },
  {
    "text": "like seller contacts which could potentially lead to expensive bin checks where an associate has to go into the",
    "start": "1156520",
    "end": "1163300"
  },
  {
    "text": "warehouse and count every single inventory unit to answer a question coming from the cellar so because of the",
    "start": "1163300",
    "end": "1169630"
  },
  {
    "text": "accuracy in the inventory improvement and the accuracy of the inventory we were able to reduce those business operational costs and our team members",
    "start": "1169630",
    "end": "1177010"
  },
  {
    "text": "not working on the latest technologies using a diverse managed services",
    "start": "1177010",
    "end": "1182640"
  },
  {
    "text": "so now let me focus a little bit about what were the best practices that we",
    "start": "1182640",
    "end": "1188710"
  },
  {
    "start": "1183000",
    "end": "1183000"
  },
  {
    "text": "used while we built this platform and that might be useful for you so first we",
    "start": "1188710",
    "end": "1194620"
  },
  {
    "text": "took advantage of lambda container radius lambda is essentially a stateless execution environment but there is still",
    "start": "1194620",
    "end": "1203410"
  },
  {
    "text": "an opportunity for us to duke costly one-time activities outside",
    "start": "1203410",
    "end": "1211780"
  },
  {
    "text": "the scope of an execution for of a lambda instance by that I mean",
    "start": "1211780",
    "end": "1217930"
  },
  {
    "text": "for example we use Java and spring heavily for even processing and when you",
    "start": "1217930",
    "end": "1224950"
  },
  {
    "text": "use spring you have to build the dependency graph so that the injection happens by the container and and that we",
    "start": "1224950",
    "end": "1233260"
  },
  {
    "text": "were able to accomplish without having to do this for every single invocation of the lambda instance and we were able",
    "start": "1233260",
    "end": "1239380"
  },
  {
    "text": "to do it using the container reuse outside the scope of the event handler this helped improve our performance of",
    "start": "1239380",
    "end": "1246550"
  },
  {
    "text": "our execution units tremendously which greatly reduce a costume",
    "start": "1246550",
    "end": "1252870"
  },
  {
    "text": "next everybody is familiar with this we need",
    "start": "1252870",
    "end": "1258040"
  },
  {
    "text": "to instrument and monitor all our execution environments but lambda it's it's a little bit more important to do",
    "start": "1258040",
    "end": "1263650"
  },
  {
    "text": "it because unlike traditional computing infrastructure it's it's hard",
    "start": "1263650",
    "end": "1269200"
  },
  {
    "text": "to debug and trace in runtime but lambda you don't have access to runtime so we",
    "start": "1269200",
    "end": "1276490"
  },
  {
    "text": "spent a lot of effort trying to instrument our code make sure that we",
    "start": "1276490",
    "end": "1281650"
  },
  {
    "start": "1278000",
    "end": "1278000"
  },
  {
    "text": "have complete visibility during runtime through our own custom metrics and monitors that we have through our code",
    "start": "1281650",
    "end": "1289330"
  },
  {
    "text": "and we wrote a cloud watch reporter that essentially takes these custom metrics",
    "start": "1289330",
    "end": "1294760"
  },
  {
    "text": "and publishes in the cloud watch before the execution unit ends in lambda so",
    "start": "1294760",
    "end": "1301389"
  },
  {
    "text": "that helped us make sure that we know how our runtime is performing",
    "start": "1301389",
    "end": "1307889"
  },
  {
    "text": "the other important thing that we spend a lot of time as extracting the lambda",
    "start": "1308159",
    "end": "1314889"
  },
  {
    "text": "launch functions from a core entity processing function and the reason being",
    "start": "1314889",
    "end": "1320649"
  },
  {
    "text": "is that number one when we when we started this journey lambda was relatively new and we",
    "start": "1320649",
    "end": "1327009"
  },
  {
    "text": "were hedging updates we wanted to quickly quickly jump into KCl if we have any",
    "start": "1327009",
    "end": "1333099"
  },
  {
    "text": "launch issues with lambda that was one motivation the second motivation is that",
    "start": "1333099",
    "end": "1338139"
  },
  {
    "text": "we wanted to make sure that our lambda code is heavily unit tested and",
    "start": "1338139",
    "end": "1344190"
  },
  {
    "text": "by having separation of responsibilities in terms of the lambda launch",
    "start": "1344190",
    "end": "1349209"
  },
  {
    "text": "functionality from our entity processing makes our code easier to unit test",
    "start": "1349209",
    "end": "1354389"
  },
  {
    "text": "so two towards this we focused on building our own utilities one of them",
    "start": "1354389",
    "end": "1360700"
  },
  {
    "text": "is called the lambda launch helper which is responsible for initializing the dependency graph and making sure that",
    "start": "1360700",
    "end": "1367389"
  },
  {
    "text": "spring is ready and then invokes the event handler after deer sterilizing the",
    "start": "1367389",
    "end": "1373690"
  },
  {
    "text": "event that came from kinases or DynamoDB stream and invoking the event handler",
    "start": "1373690",
    "end": "1379119"
  },
  {
    "text": "with the entity so that the entity processor can process that this also",
    "start": "1379119",
    "end": "1385269"
  },
  {
    "text": "took care of the common error reporting and error handling so that not every",
    "start": "1385269",
    "end": "1390549"
  },
  {
    "text": "processor needs to worry about it and as and can also emit these custom metrics which greatly helps us in our",
    "start": "1390549",
    "end": "1396700"
  },
  {
    "text": "operational aspects and the last best practice I wanted to",
    "start": "1396700",
    "end": "1405609"
  },
  {
    "text": "share was we use cannery and cannery to",
    "start": "1405609",
    "end": "1410739"
  },
  {
    "text": "help us understand how our system is performing and make sure that our system",
    "start": "1410739",
    "end": "1415809"
  },
  {
    "text": "is meeting our SLA what I mean by cannery is that we regularly submit synthetic transactions",
    "start": "1415809",
    "end": "1422859"
  },
  {
    "start": "1419000",
    "end": "1419000"
  },
  {
    "text": "or test transactions into our pipeline so that we know we can measure when we",
    "start": "1422859",
    "end": "1427989"
  },
  {
    "text": "submitted the transaction and compare it against the end state and make sure that the transaction went through the pipeline as well as whether it matters",
    "start": "1427989",
    "end": "1434440"
  },
  {
    "text": "any so every few seconds we submit these transactions and it helps us monitor",
    "start": "1434440",
    "end": "1439840"
  },
  {
    "text": "whether there's a backlog somewhere because our test failed or whether it",
    "start": "1439840",
    "end": "1445059"
  },
  {
    "text": "meets SLA and this is a critical tool in our pipeline to make sure our health of",
    "start": "1445059",
    "end": "1450820"
  },
  {
    "text": "the system is really good we use canister shard level metrics to know",
    "start": "1450820",
    "end": "1456370"
  },
  {
    "text": "when a backlog is building and make sure that we have adequate monitors around it",
    "start": "1456370",
    "end": "1461410"
  },
  {
    "text": "here is a sample dashboard that we use some of the metrics that we use",
    "start": "1461410",
    "end": "1467549"
  },
  {
    "text": "average transaction processing time for the entervan system how many transactions how old are the",
    "start": "1467549",
    "end": "1475090"
  },
  {
    "text": "transactions in our backlog as well as what is the cannery processing time and if any of these fails we can be alerted",
    "start": "1475090",
    "end": "1481720"
  },
  {
    "text": "so that we can go and investigate intervals but this I will call Brandon who's going",
    "start": "1481720",
    "end": "1488230"
  },
  {
    "text": "to talk about the civiles architecture the table",
    "start": "1488230",
    "end": "1492780"
  },
  {
    "text": "okay hi everyone my name is Brandon I'm a",
    "start": "1509840",
    "end": "1517369"
  },
  {
    "text": "senior engineer from scope Lee so scope Lee is a mobile game company",
    "start": "1517369",
    "end": "1523419"
  },
  {
    "start": "1519000",
    "end": "1519000"
  },
  {
    "text": "we have several games but the ones I'm going to talk to you today about our Yahtzee with buddies dice with buddies",
    "start": "1523419",
    "end": "1530749"
  },
  {
    "text": "and wheel of fortune free play so Yahtzee and dice are pretty simple",
    "start": "1530749",
    "end": "1537019"
  },
  {
    "text": "games they're player versus player turn-based games so one guy takes his",
    "start": "1537019",
    "end": "1543289"
  },
  {
    "text": "mobile client he roll some dice he makes a choice submits it to the server server sends a push notification of the other",
    "start": "1543289",
    "end": "1549649"
  },
  {
    "text": "guy other guy plays his turn and then they go back and forth until the game's over and then maybe they win some",
    "start": "1549649",
    "end": "1556789"
  },
  {
    "text": "achievements or a tournament or a prize or some currency Wheel of Fortune has a similar game mode",
    "start": "1556789",
    "end": "1563239"
  },
  {
    "text": "but there's a longer duration between server trips because you're spinning wheels and guessing letters and things",
    "start": "1563239",
    "end": "1569239"
  },
  {
    "text": "which takes a little longer so we're not Netflix but we do have some",
    "start": "1569239",
    "end": "1575389"
  },
  {
    "text": "pretty decent traffic you know we have over six million daily active users million requests per minute",
    "start": "1575389",
    "end": "1582320"
  },
  {
    "text": "and you know 100 plus API servers",
    "start": "1582320",
    "end": "1587559"
  },
  {
    "start": "1588000",
    "end": "1588000"
  },
  {
    "text": "so here's a basically out of our architecture like Vlad said earlier we're not using lambda and our primary",
    "start": "1589570",
    "end": "1597559"
  },
  {
    "text": "role it's playing more of a supporting role but I'll get to that later so right now we're running ec2 instances",
    "start": "1597559",
    "end": "1604609"
  },
  {
    "text": "behind an EOB the mobile clients will make HTTP requests to the EOB and then",
    "start": "1604609",
    "end": "1610999"
  },
  {
    "text": "the instances will talk to memcached ElastiCache my sequel and dynamodb to",
    "start": "1610999",
    "end": "1617690"
  },
  {
    "text": "serve as a post so in order to serve a request the",
    "start": "1617690",
    "end": "1624440"
  },
  {
    "text": "application needs access to a couple different types of data some of it is just meta information so",
    "start": "1624440",
    "end": "1632929"
  },
  {
    "text": "this is stuff that's shared between all users it's like what tournaments are currently",
    "start": "1632929",
    "end": "1638629"
  },
  {
    "text": "running when they start when the end what achievements are configured that",
    "start": "1638629",
    "end": "1644239"
  },
  {
    "text": "sort of thing so this kind of stuff it's really small",
    "start": "1644239",
    "end": "1649840"
  },
  {
    "text": "the PM's configure it in the website so our application servers just pull it out",
    "start": "1649840",
    "end": "1655360"
  },
  {
    "text": "of my sequel every minute and then keep it in local memory so this kind of this",
    "start": "1655360",
    "end": "1660820"
  },
  {
    "text": "use case is really trivial and easy to scale well there's not really any scaling",
    "start": "1660820",
    "end": "1666809"
  },
  {
    "text": "our second type of data is more interesting it's our user specific data",
    "start": "1666809",
    "end": "1672299"
  },
  {
    "text": "so these are things like",
    "start": "1672299",
    "end": "1677369"
  },
  {
    "text": "the actual game documents that the users are playing on the achievements that they've completed",
    "start": "1677369",
    "end": "1684868"
  },
  {
    "text": "like what they scored in a tournament that sort of thing so anything that has to do that goes with the user we",
    "start": "1685230",
    "end": "1690999"
  },
  {
    "text": "typically put in DynamoDB because we have a lot of user data and",
    "start": "1690999",
    "end": "1698309"
  },
  {
    "text": "we don't really want to worry about getting up in the middle of the night and having to shut down our RDS instance",
    "start": "1698309",
    "end": "1703360"
  },
  {
    "text": "and upgrading it and that sort of thing we'd rather just go to DynamoDB or use a",
    "start": "1703360",
    "end": "1709059"
  },
  {
    "text": "tool that automatically scales up DynamoDB on-demand",
    "start": "1709059",
    "end": "1713549"
  },
  {
    "text": "cool so about dynamodb so theoretically you can",
    "start": "1715950",
    "end": "1722409"
  },
  {
    "start": "1716000",
    "end": "1716000"
  },
  {
    "text": "scale up as much as you want within a region and this is possible because under the",
    "start": "1722409",
    "end": "1729009"
  },
  {
    "text": "hood DynamoDB will break up your data into partitions so that multiple servers can actually work on that data and",
    "start": "1729009",
    "end": "1737279"
  },
  {
    "text": "then each record that you have in DynamoDB has what's called a hash key I",
    "start": "1737279",
    "end": "1743200"
  },
  {
    "text": "think they might call it a partition key now but that key tells",
    "start": "1743200",
    "end": "1748710"
  },
  {
    "text": "you DynamoDB uses that key to map a particular record into a partition",
    "start": "1748710",
    "end": "1754259"
  },
  {
    "text": "so when you provision a table in dynamodb these partitions are",
    "start": "1754259",
    "end": "1759309"
  },
  {
    "text": "transparent to you you just say hey DynamoDB I'd like to be able to read",
    "start": "1759309",
    "end": "1764460"
  },
  {
    "text": "4,000 records per second and dynamodb under-the-hood allocates enough",
    "start": "1764460",
    "end": "1770200"
  },
  {
    "text": "partitions to handle 4,000 requests per second but each partition has its own",
    "start": "1770200",
    "end": "1776860"
  },
  {
    "text": "upper bound upper how much throughput it can actually handle so when you",
    "start": "1776860",
    "end": "1783419"
  },
  {
    "text": "exceed the throughput of a particular partition you'll get a throttling error and then typically a client's will do an",
    "start": "1783419",
    "end": "1790839"
  },
  {
    "text": "exponential back-off or something so that to slow down but usually we like to avoid the",
    "start": "1790839",
    "end": "1798579"
  },
  {
    "text": "throttling errors to begin with so in this situation I have a table that",
    "start": "1798579",
    "end": "1803589"
  },
  {
    "text": "has 4,000 reads per second so if my client tries to get the record for user",
    "start": "1803589",
    "end": "1809889"
  },
  {
    "text": "1 2 3 you know 2,000 times per second even",
    "start": "1809889",
    "end": "1815169"
  },
  {
    "text": "though the table capacity is 4 thousand times per second it's still going to get throttling errors because it's exceeding the limit of its partition and that",
    "start": "1815169",
    "end": "1821769"
  },
  {
    "text": "record only lives on one partition so when when this happens we call it a",
    "start": "1821769",
    "end": "1828849"
  },
  {
    "text": "hotkey so a hotkey is like one one key that's",
    "start": "1828849",
    "end": "1834459"
  },
  {
    "text": "accessed more frequently than the other keys and in order for DynamoDB to work really well you have to sort of",
    "start": "1834459",
    "end": "1841629"
  },
  {
    "text": "distribute your your load across the keys evenly so that one partition",
    "start": "1841629",
    "end": "1846999"
  },
  {
    "text": "doesn't get overwhelmed while the other ones are just sitting idle and in this we have a couple of cloud watch",
    "start": "1846999",
    "end": "1854199"
  },
  {
    "text": "graphs on the slide the top one is showing that we're currently experiencing throttling errs on our kits",
    "start": "1854199",
    "end": "1861279"
  },
  {
    "text": "and the bottom one is showing see the red line is our provision capacity for a",
    "start": "1861279",
    "end": "1866889"
  },
  {
    "text": "dynamo table and the blue line is our actual consumed capacity so this is sort of the classic symptoms",
    "start": "1866889",
    "end": "1874479"
  },
  {
    "text": "of a hotkey we were under provisioned but we're",
    "start": "1874479",
    "end": "1879639"
  },
  {
    "text": "still seeing throttling so I don't know how many guys have have seen this sort of situation before cool yeah so this",
    "start": "1879639",
    "end": "1888399"
  },
  {
    "text": "happens a lot so see Oh",
    "start": "1888399",
    "end": "1895349"
  },
  {
    "start": "1896000",
    "end": "1896000"
  },
  {
    "text": "so it's Cokely since this happens all the time we try to come up with better",
    "start": "1897220",
    "end": "1903950"
  },
  {
    "text": "ways of attacking this problem so one way you can attack the problem is",
    "start": "1903950",
    "end": "1909890"
  },
  {
    "text": "to just put some cash nodes in front of it and that sort of works for a while but",
    "start": "1909890",
    "end": "1915940"
  },
  {
    "text": "generally when we run like memcache we run it in a cluster and you have you",
    "start": "1915940",
    "end": "1922160"
  },
  {
    "text": "know each key is gonna sit in a particular node in the cluster and you're gonna eventually overwhelm a particular cache node as well so that",
    "start": "1922160",
    "end": "1929240"
  },
  {
    "text": "doesn't really get you all the way there but it does it might work for a little while",
    "start": "1929240",
    "end": "1934990"
  },
  {
    "text": "another thing that you can do is you know the best thing to do is really",
    "start": "1934990",
    "end": "1940040"
  },
  {
    "text": "to solve the underlying problem and that can be sort of a whole bunch of",
    "start": "1940040",
    "end": "1945170"
  },
  {
    "text": "different things it's usually a bug of some kind or just an oversight but detecting it is usually the hard",
    "start": "1945170",
    "end": "1951770"
  },
  {
    "text": "thing because you have to assist you know in art I don't know about you guys but in art in our code we have like you",
    "start": "1951770",
    "end": "1957500"
  },
  {
    "text": "know millions of lines of code and sifting through it and finding like where this hotkey might be is kind of",
    "start": "1957500",
    "end": "1964490"
  },
  {
    "text": "difficult so it's it's really nice to know what the key is that really helps find the problem but the cloud watch",
    "start": "1964490",
    "end": "1972020"
  },
  {
    "text": "metrics don't tell you so that's unfortunate so",
    "start": "1972020",
    "end": "1977440"
  },
  {
    "text": "define the key we could do a couple of things I mean we could pop up Wireshark and try to sniff traffic and look for",
    "start": "1977440",
    "end": "1984110"
  },
  {
    "text": "the key and that doesn't really work over us a cell so it doesn't work for dynamo it does kind of work for memcache but it's not very convenient",
    "start": "1984110",
    "end": "1992410"
  },
  {
    "text": "another thing is you can put some code in your application to just log a key every time you request something but",
    "start": "1992410",
    "end": "1998810"
  },
  {
    "text": "that adds a ton of overhead and it takes up a lot of space in your you're logging",
    "start": "1998810",
    "end": "2003940"
  },
  {
    "text": "cluster so we really want is a solution that we can turn on all the time has minimal",
    "start": "2003940",
    "end": "2010600"
  },
  {
    "text": "performance overhead and doesn't cost a lot of money in storage",
    "start": "2010600",
    "end": "2016020"
  },
  {
    "start": "2016000",
    "end": "2016000"
  },
  {
    "text": "so we came up with this solution so we what we do is we have our",
    "start": "2016020",
    "end": "2023500"
  },
  {
    "text": "application servers have a bit of tracking code in it and it keeps track of the top ten most frequently seen keys",
    "start": "2023500",
    "end": "2031460"
  },
  {
    "text": "in our memcache client and in our DynamoDB wrapper client",
    "start": "2031460",
    "end": "2037460"
  },
  {
    "text": "so like the straightforward way of tracking the keys is maybe just to have like a hash map where you have the keys",
    "start": "2037460",
    "end": "2042590"
  },
  {
    "text": "the key and the value is account but if you have if you're running through like",
    "start": "2042590",
    "end": "2048079"
  },
  {
    "text": "100,000 requests per minute on a particular application server you have to use a lot of memory to to do that for",
    "start": "2048079",
    "end": "2054408"
  },
  {
    "text": "every period so we cheat a little bit we use a probabilistic algorithm which",
    "start": "2054409",
    "end": "2059658"
  },
  {
    "text": "called countenance sketch but this allows us to sort of sacrifice",
    "start": "2059659",
    "end": "2064790"
  },
  {
    "text": "a bit of accuracy and our accounts and the trade-off is that we can use a",
    "start": "2064790",
    "end": "2070069"
  },
  {
    "text": "fixed size of memory to track an unlimited number of keys it networks pretty well for us because all we really",
    "start": "2070069",
    "end": "2075800"
  },
  {
    "text": "need to know is the relative difference between like how hot one key is compared to the",
    "start": "2075800",
    "end": "2081378"
  },
  {
    "text": "average so here's a quick overview of our o so",
    "start": "2081379",
    "end": "2090319"
  },
  {
    "text": "like once we get those top ten keys in our logs it gets pushed into our logging",
    "start": "2090319",
    "end": "2095810"
  },
  {
    "start": "2095000",
    "end": "2095000"
  },
  {
    "text": "stack and this is what that looks like so this is sort of lambda in the supporting role we have our application",
    "start": "2095810",
    "end": "2103359"
  },
  {
    "text": "and we have a little sidecar process that runs on our application that aggregates our logs",
    "start": "2103359",
    "end": "2109359"
  },
  {
    "text": "and it shoves that into Kinesis then we have lambda that reads from this",
    "start": "2109359",
    "end": "2116359"
  },
  {
    "text": "Canisius and pulls out interesting information from the logs so all the typical things like the timestamp what",
    "start": "2116359",
    "end": "2122329"
  },
  {
    "text": "host it came from what game it came from another use case specific information",
    "start": "2122329",
    "end": "2127520"
  },
  {
    "text": "would like our hot key information so once it it pulls out and parses all",
    "start": "2127520",
    "end": "2135770"
  },
  {
    "text": "those logs it shoves the elasticsearch shoves the documents into the elastic search service and then we can use",
    "start": "2135770",
    "end": "2141589"
  },
  {
    "text": "kibana to build dashboards and have nice pretty graphs and that sort of thing to",
    "start": "2141589",
    "end": "2146780"
  },
  {
    "text": "give us some quick insight into what's going on and lambda works really well for this",
    "start": "2146780",
    "end": "2152960"
  },
  {
    "text": "scenario because there are have been several times where our application has some log",
    "start": "2152960",
    "end": "2159860"
  },
  {
    "text": "information but it's not indexed yet and it's really nice to be able to say oh hey I'd like to really index that up",
    "start": "2159860",
    "end": "2166490"
  },
  {
    "text": "that information and then make a graph out of it without having to wait for the",
    "start": "2166490",
    "end": "2171620"
  },
  {
    "text": "next sort of deployment cycle of our application so lemon makes it really easy because I",
    "start": "2171620",
    "end": "2177500"
  },
  {
    "text": "can just you know change out a regular expression to that code that pulls in",
    "start": "2177500",
    "end": "2183200"
  },
  {
    "text": "the values into into the document and then just hit deploy and within minutes I'm getting my menu indexing information",
    "start": "2183200",
    "end": "2191020"
  },
  {
    "text": "it also makes subscribing to Kinesis really trivial because you add shards to",
    "start": "2191020",
    "end": "2197780"
  },
  {
    "text": "Kinesis and it just you don't have to think about adding more subscribers and that sort of thing so that's really",
    "start": "2197780",
    "end": "2203600"
  },
  {
    "text": "convenient but back to the hot key detection so once we get our hot key events into",
    "start": "2203600",
    "end": "2210770"
  },
  {
    "start": "2206000",
    "end": "2206000"
  },
  {
    "text": "elasticsearch this is sort of what they look like I mean on the top you'll see the log line so that's what the",
    "start": "2210770",
    "end": "2217190"
  },
  {
    "text": "application server is actually log when they log the top ten keys and then this is the is elasticsearch document that",
    "start": "2217190",
    "end": "2225350"
  },
  {
    "text": "gets produced once the lambda is finished with it so then there we have like a category of",
    "start": "2225350",
    "end": "2230420"
  },
  {
    "text": "what what the hot key the thing is that we're tracking in this case it's gets on",
    "start": "2230420",
    "end": "2236930"
  },
  {
    "text": "memcache and then we have the key we have the estimate of how many times that",
    "start": "2236930",
    "end": "2244160"
  },
  {
    "text": "key was encountered and then the total count is the total count for the category for all keys and then the",
    "start": "2244160",
    "end": "2250610"
  },
  {
    "text": "frequency is the ratio of those two numbers so once we have all this stuff into an",
    "start": "2250610",
    "end": "2257450"
  },
  {
    "start": "2256000",
    "end": "2256000"
  },
  {
    "text": "elastic search we can build a dashboard that looks sort of like this and I'm going to show you how to build it",
    "start": "2257450",
    "end": "2263870"
  },
  {
    "text": "real quick okay so here I have a basic dashboard",
    "start": "2263870",
    "end": "2270440"
  },
  {
    "text": "already built out I don't know I do have that okay let's get rid of that but I we",
    "start": "2270440",
    "end": "2279710"
  },
  {
    "text": "have a couple of things in here already so we have like a date histogram of the log messages",
    "start": "2279710",
    "end": "2285220"
  },
  {
    "text": "which games the log messages came in the top hosts",
    "start": "2285220",
    "end": "2290599"
  },
  {
    "text": "but we don't have our hotkey information yet and also you'll notice that it looks kind of there's like an odd traffic",
    "start": "2290599",
    "end": "2297570"
  },
  {
    "text": "pattern to the logs and that's because for this demo I just wrote a lambda that gets invoked once a minute and it shoves",
    "start": "2297570",
    "end": "2303540"
  },
  {
    "text": "a bunch of fake hot key documents into elasticsearch but so this",
    "start": "2303540",
    "end": "2309180"
  },
  {
    "text": "isn't our actual production dashboard but so to make the hot key thing will go to",
    "start": "2309180",
    "end": "2318240"
  },
  {
    "text": "visualize and I'm going to use a data table since it's a little bit easier to see than the bar charts and what we want",
    "start": "2318240",
    "end": "2326730"
  },
  {
    "text": "to do is we want to add up the counts and then we want to break it",
    "start": "2326730",
    "end": "2333000"
  },
  {
    "text": "down using a terms aggregation on the keys",
    "start": "2333000",
    "end": "2339260"
  },
  {
    "text": "top ten then I'll hit that green button",
    "start": "2339560",
    "end": "2344660"
  },
  {
    "text": "and then right away we can see we have a couple of hot keys in there so user 0",
    "start": "2344660",
    "end": "2351570"
  },
  {
    "text": "and user got negative 1 or getting a lot more hits than the rest of the users",
    "start": "2351570",
    "end": "2358460"
  },
  {
    "text": "so I'll hit save on this guy",
    "start": "2358460",
    "end": "2362990"
  },
  {
    "text": "and then I can just add it on my dashboard",
    "start": "2367130",
    "end": "2372050"
  },
  {
    "text": "like so so it's pretty easy to build one of these things",
    "start": "2378070",
    "end": "2384510"
  },
  {
    "text": "and I don't go back",
    "start": "2384810",
    "end": "2390150"
  },
  {
    "text": "okay cool so results and lessons learned",
    "start": "2394250",
    "end": "2401650"
  },
  {
    "text": "one thing is we once we deployed this thing we found so many bugs way more",
    "start": "2401650",
    "end": "2408020"
  },
  {
    "text": "than we thought we did most of them were in memcache because memcache has a like of much higher",
    "start": "2408020",
    "end": "2413480"
  },
  {
    "text": "throughput sealing on the nodes so when we had a hot key in memcache we",
    "start": "2413480",
    "end": "2419000"
  },
  {
    "text": "didn't it went unnoticed for a long time but when we started playing with this dashboard we we fixed like five things",
    "start": "2419000",
    "end": "2425510"
  },
  {
    "text": "right away we had like special case user IDs like the one that I showed you in",
    "start": "2425510",
    "end": "2430910"
  },
  {
    "text": "the demo so we had some requests that would when you weren't playing against an actual person it would send you down",
    "start": "2430910",
    "end": "2437060"
  },
  {
    "text": "a user with an idea of negative one and we started requesting negative one our database and stuff so that and then",
    "start": "2437060",
    "end": "2443869"
  },
  {
    "text": "you'll see that we also had things like configuration objects that were instead of being cached locally in memory like",
    "start": "2443869",
    "end": "2449510"
  },
  {
    "text": "they should have been they were cached in memcache and they're all on the same node and you can see like we took a look at",
    "start": "2449510",
    "end": "2455630"
  },
  {
    "text": "our cloud watch metrics after we found this and then we noticed that hey look one of our nodes is sending a lot more",
    "start": "2455630",
    "end": "2461510"
  },
  {
    "text": "bytes out of it than the rest of the nodes so",
    "start": "2461510",
    "end": "2465849"
  },
  {
    "text": "we also discovered that large keys could be detected this way so we had",
    "start": "2467619",
    "end": "2474580"
  },
  {
    "text": "intermittent timeouts with on memcached and we kind of had a suspicion that it",
    "start": "2474580",
    "end": "2480230"
  },
  {
    "text": "was for very large objects that we stocked in there and so we used sort of the same hot key",
    "start": "2480230",
    "end": "2487310"
  },
  {
    "text": "detection technique and instead of we just made a slight tweak to it so instead of incrementing by one every",
    "start": "2487310",
    "end": "2493550"
  },
  {
    "text": "time we saw a key we incrementally pulled something out of memcache and",
    "start": "2493550",
    "end": "2499070"
  },
  {
    "text": "then that gave us a view into what the biggest objects were in our memcached system relative to the whole and we",
    "start": "2499070",
    "end": "2507349"
  },
  {
    "text": "found some interesting things like we had some users with a meta information",
    "start": "2507349",
    "end": "2513320"
  },
  {
    "text": "document for that user that had like a little embedded list in it of recently",
    "start": "2513320",
    "end": "2518780"
  },
  {
    "text": "recent users that you played with and that just kind of grew to infinity for some users so we just ended up fixing",
    "start": "2518780",
    "end": "2525349"
  },
  {
    "text": "that by trimming a list or move it's a different storage system but yeah the large key detection was",
    "start": "2525349",
    "end": "2531880"
  },
  {
    "text": "really useful for finding those sorts of problems we also caught a bot and",
    "start": "2531880",
    "end": "2537780"
  },
  {
    "text": "that was fun so like one one day after we had already built this thing",
    "start": "2537780",
    "end": "2543240"
  },
  {
    "text": "our average response time went up like crazy but our median response time was",
    "start": "2543240",
    "end": "2548530"
  },
  {
    "text": "okay so it was just a slice slice of traffic was was having really poor performance and we noticed a bunch of",
    "start": "2548530",
    "end": "2554890"
  },
  {
    "text": "throttling in DynamoDB but yet we're still under the under",
    "start": "2554890",
    "end": "2560860"
  },
  {
    "text": "provisioned and we took a look at our dashboard and we noticed hey this guy's user ID is showing up all over the place",
    "start": "2560860",
    "end": "2566250"
  },
  {
    "text": "we looked up his account and deleted it and you know kind of solved the problem right away and then we were able to play",
    "start": "2566250",
    "end": "2572710"
  },
  {
    "text": "we just play whack-a-mole with this guy for a while until the next release when we implemented",
    "start": "2572710",
    "end": "2579100"
  },
  {
    "text": "some rate limiting pretty per user request rate limiting that sort of took care of the problem for good",
    "start": "2579100",
    "end": "2586380"
  },
  {
    "text": "we also caught some bad client behavior so our OS client sort of did the right",
    "start": "2586920",
    "end": "2594760"
  },
  {
    "start": "2587000",
    "end": "2587000"
  },
  {
    "text": "thing when he had a you have a game list so it the iOS client would pull the game list and then when you actually wanted",
    "start": "2594760",
    "end": "2600820"
  },
  {
    "text": "to play the game it would load some extra game details that you needed to play the game so our Android client",
    "start": "2600820",
    "end": "2606580"
  },
  {
    "text": "would pull the game list then in the background it would make a request for every single game you had in your game",
    "start": "2606580",
    "end": "2612640"
  },
  {
    "text": "list and some users had thousands of active games running so every time they would refresh your game list they would",
    "start": "2612640",
    "end": "2617950"
  },
  {
    "text": "you know just it would hang forever and the server would also return a bunch",
    "start": "2617950",
    "end": "2623800"
  },
  {
    "text": "errors and they would get a bunch of nasty dialogs and that sort of thing and this one unnoticed for a lot of for a",
    "start": "2623800",
    "end": "2629680"
  },
  {
    "text": "long time because there weren't very many users that had that big of a game list to cause problems",
    "start": "2629680",
    "end": "2635550"
  },
  {
    "text": "but once after we got rid of all these hotkeys we noticed that some users were",
    "start": "2635550",
    "end": "2640870"
  },
  {
    "text": "still showing up in it and then we filtered it down by the client platform and we notice they were all happening on",
    "start": "2640870",
    "end": "2646450"
  },
  {
    "text": "Android so we kind of took a wild guess and say maybe you thought maybe it was poor client behavior and looked into it",
    "start": "2646450",
    "end": "2653170"
  },
  {
    "text": "and then talk to the client guys to fix the problem",
    "start": "2653170",
    "end": "2659580"
  },
  {
    "text": "anyways thanks for listening there's my email address if you have any",
    "start": "2659660",
    "end": "2665670"
  },
  {
    "text": "questions",
    "start": "2665670",
    "end": "2668059"
  },
  {
    "text": "alright thank you all for attending there's a really happy that is just to",
    "start": "2677240",
    "end": "2684270"
  },
  {
    "text": "spend the time with us before you go and we open up the floor for questions I wanted to remind you to kind of fill out",
    "start": "2684270",
    "end": "2689550"
  },
  {
    "text": "your evaluations your feedback is invaluable for us and it helps me grieve and better and there's a couple of",
    "start": "2689550",
    "end": "2696090"
  },
  {
    "start": "2695000",
    "end": "2695000"
  },
  {
    "text": "related sessions that might be interesting if you want to look more into serverless architectures patterns and",
    "start": "2696090",
    "end": "2702750"
  },
  {
    "text": "best practices or dive deeper into services such as DynamoDB and",
    "start": "2702750",
    "end": "2708680"
  },
  {
    "text": "ElastiCache and we're all random ganesh and i will be",
    "start": "2708680",
    "end": "2715020"
  },
  {
    "text": "here available for questions anybody that wants is interested in finding out more",
    "start": "2715020",
    "end": "2721520"
  },
  {
    "text": "and thank you so much",
    "start": "2721850",
    "end": "2725540"
  }
]
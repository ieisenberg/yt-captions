[
  {
    "start": "0",
    "end": "215000"
  },
  {
    "text": "good afternoon everyone excited to be",
    "start": "4650",
    "end": "7200"
  },
  {
    "text": "here today to talk to you about the",
    "start": "7200",
    "end": "9570"
  },
  {
    "text": "amazing things we're doing with natural",
    "start": "9570",
    "end": "12150"
  },
  {
    "text": "language processing and machine learning",
    "start": "12150",
    "end": "14309"
  },
  {
    "text": "to drive value for our clients",
    "start": "14309",
    "end": "16349"
  },
  {
    "text": "I'm Nate Storch the CEO and co-founder",
    "start": "16349",
    "end": "19439"
  },
  {
    "text": "of amenity analytics what an exciting",
    "start": "19439",
    "end": "23220"
  },
  {
    "text": "show it is today the migration to the",
    "start": "23220",
    "end": "26400"
  },
  {
    "text": "cloud is is on a path that's not stopped",
    "start": "26400",
    "end": "29940"
  },
  {
    "text": "abow in fact I would say the migration",
    "start": "29940",
    "end": "32699"
  },
  {
    "text": "has turned into a stampede",
    "start": "32699",
    "end": "34920"
  },
  {
    "text": "and one of the after-effects of this has",
    "start": "34920",
    "end": "38070"
  },
  {
    "text": "been that we're firmly entrenched in the",
    "start": "38070",
    "end": "41340"
  },
  {
    "text": "era of big data in today's competitive",
    "start": "41340",
    "end": "45239"
  },
  {
    "text": "world it's no longer an option to use a",
    "start": "45239",
    "end": "48750"
  },
  {
    "text": "data focused decision-making framework",
    "start": "48750",
    "end": "51059"
  },
  {
    "text": "to drive your most important business",
    "start": "51059",
    "end": "54090"
  },
  {
    "text": "decisions yet there's a problem with",
    "start": "54090",
    "end": "57600"
  },
  {
    "text": "this in order to make accurate decisions",
    "start": "57600",
    "end": "59930"
  },
  {
    "text": "so much information that you need is in",
    "start": "59930",
    "end": "63329"
  },
  {
    "text": "text and yet most of this information",
    "start": "63329",
    "end": "66720"
  },
  {
    "text": "goes unanalyzed why because today's",
    "start": "66720",
    "end": "71819"
  },
  {
    "text": "natural language processing options fall",
    "start": "71819",
    "end": "74789"
  },
  {
    "text": "short well our mission at amenity",
    "start": "74789",
    "end": "79470"
  },
  {
    "text": "analytics is to transform text into",
    "start": "79470",
    "end": "82470"
  },
  {
    "text": "valuable assets for the benefit of you",
    "start": "82470",
    "end": "84750"
  },
  {
    "text": "and your business your stakeholders and",
    "start": "84750",
    "end": "87119"
  },
  {
    "text": "society at large we've built a natural",
    "start": "87119",
    "end": "92009"
  },
  {
    "text": "language processing platform trained on",
    "start": "92009",
    "end": "94679"
  },
  {
    "text": "the language of business",
    "start": "94679",
    "end": "96110"
  },
  {
    "text": "we process news regulatory filings",
    "start": "96110",
    "end": "99750"
  },
  {
    "text": "earnings call transcripts research",
    "start": "99750",
    "end": "102240"
  },
  {
    "text": "reports and troves of internal documents",
    "start": "102240",
    "end": "105360"
  },
  {
    "text": "for our clients we turn that into",
    "start": "105360",
    "end": "108770"
  },
  {
    "text": "actionable insights we use that to drive",
    "start": "108770",
    "end": "111869"
  },
  {
    "text": "efficiency and ultimately better",
    "start": "111869",
    "end": "114300"
  },
  {
    "text": "decision makings and the result is a",
    "start": "114300",
    "end": "119099"
  },
  {
    "text": "paradigm shift from today where only the",
    "start": "119099",
    "end": "122789"
  },
  {
    "text": "most sophisticated organizations are",
    "start": "122789",
    "end": "125130"
  },
  {
    "text": "able to analyze the text that they want",
    "start": "125130",
    "end": "127950"
  },
  {
    "text": "to analyze and get the information that",
    "start": "127950",
    "end": "129660"
  },
  {
    "text": "they need to today where any",
    "start": "129660",
    "end": "133049"
  },
  {
    "text": "organization can work with us to get the",
    "start": "133049",
    "end": "135390"
  },
  {
    "text": "information that they need from",
    "start": "135390",
    "end": "139219"
  },
  {
    "text": "to take a step back a little bit about",
    "start": "139490",
    "end": "141930"
  },
  {
    "text": "amenity analytics we have about 60",
    "start": "141930",
    "end": "144030"
  },
  {
    "text": "employees now split between New York and",
    "start": "144030",
    "end": "146550"
  },
  {
    "text": "Tel Aviv we've raised about 26 million",
    "start": "146550",
    "end": "149250"
  },
  {
    "text": "dollars we're lucky to count Intel",
    "start": "149250",
    "end": "152130"
  },
  {
    "text": "Capital one of the world's leading",
    "start": "152130",
    "end": "153600"
  },
  {
    "text": "investors in AI technologies on our cap",
    "start": "153600",
    "end": "157140"
  },
  {
    "text": "table as well as state of mind ventures",
    "start": "157140",
    "end": "159000"
  },
  {
    "text": "and two of our clients in the insurance",
    "start": "159000",
    "end": "160590"
  },
  {
    "text": "space Allstate and Starr we're a very",
    "start": "160590",
    "end": "165210"
  },
  {
    "text": "customer centric organization and very",
    "start": "165210",
    "end": "167070"
  },
  {
    "text": "proud of the clients that we're working",
    "start": "167070",
    "end": "169500"
  },
  {
    "text": "with some of today's most sophisticated",
    "start": "169500",
    "end": "171770"
  },
  {
    "text": "organizations and so today we're here to",
    "start": "171770",
    "end": "177270"
  },
  {
    "text": "talk to you about one of our core",
    "start": "177270",
    "end": "179220"
  },
  {
    "text": "business processes every day we ingest",
    "start": "179220",
    "end": "182820"
  },
  {
    "text": "millions of documents which we transform",
    "start": "182820",
    "end": "185490"
  },
  {
    "text": "into billions of data points which we",
    "start": "185490",
    "end": "187860"
  },
  {
    "text": "then have to turn into actionable",
    "start": "187860",
    "end": "189960"
  },
  {
    "text": "insights and so our question that we ask",
    "start": "189960",
    "end": "193350"
  },
  {
    "text": "ourselves is how do we do this in a way",
    "start": "193350",
    "end": "196170"
  },
  {
    "text": "that produces more refined data that's",
    "start": "196170",
    "end": "199170"
  },
  {
    "text": "accurate we do it at lightning speed and",
    "start": "199170",
    "end": "202650"
  },
  {
    "text": "at a price that doesn't break the bank",
    "start": "202650",
    "end": "205370"
  },
  {
    "text": "well my colleague Roy Penn our VP of",
    "start": "205370",
    "end": "208740"
  },
  {
    "text": "engineering is here to talk to you in",
    "start": "208740",
    "end": "210240"
  },
  {
    "text": "more detail about exactly how we're",
    "start": "210240",
    "end": "212400"
  },
  {
    "text": "doing this so thank you very much okay",
    "start": "212400",
    "end": "221570"
  },
  {
    "text": "in the in humanity we have switched in",
    "start": "221570",
    "end": "225180"
  },
  {
    "text": "entire infrastructure to work from",
    "start": "225180",
    "end": "227580"
  },
  {
    "text": "docker container base to server lists we",
    "start": "227580",
    "end": "230220"
  },
  {
    "text": "use Amazon offers a myriad of solutions",
    "start": "230220",
    "end": "233400"
  },
  {
    "text": "for server list they offer a lambda in",
    "start": "233400",
    "end": "235470"
  },
  {
    "text": "Kinesis and overall ryan athena and SQS",
    "start": "235470",
    "end": "238680"
  },
  {
    "text": "and S&S we probably used all of them or",
    "start": "238680",
    "end": "241110"
  },
  {
    "text": "if not we're on our way to use all of",
    "start": "241110",
    "end": "242880"
  },
  {
    "text": "them and and our goals when we started",
    "start": "242880",
    "end": "251430"
  },
  {
    "text": "our we initiated our our change from our",
    "start": "251430",
    "end": "255060"
  },
  {
    "text": "evolution from server fool to server",
    "start": "255060",
    "end": "257850"
  },
  {
    "text": "less was that we're going to have to",
    "start": "257850",
    "end": "259709"
  },
  {
    "text": "support 100x more customers which we're",
    "start": "259710",
    "end": "262109"
  },
  {
    "text": "on our way to do we want to do it a",
    "start": "262109",
    "end": "264210"
  },
  {
    "text": "hundred x faster so update our data",
    "start": "264210",
    "end": "266669"
  },
  {
    "text": "every few seconds and not minutes or",
    "start": "266669",
    "end": "269310"
  },
  {
    "text": "hours or days the time is your",
    "start": "269310",
    "end": "271210"
  },
  {
    "text": "take to train an LP model and we want to",
    "start": "271210",
    "end": "273850"
  },
  {
    "text": "do it in 100x more more data when we",
    "start": "273850",
    "end": "276610"
  },
  {
    "text": "started our initiative we were",
    "start": "276610",
    "end": "278620"
  },
  {
    "text": "processing maybe 10 or 20 streams of",
    "start": "278620",
    "end": "282789"
  },
  {
    "text": "data now we're processing about 50,000",
    "start": "282789",
    "end": "285460"
  },
  {
    "text": "different channels and while we do that",
    "start": "285460",
    "end": "288880"
  },
  {
    "text": "we want to maintain the four core",
    "start": "288880",
    "end": "293069"
  },
  {
    "text": "methodologies for ourselves we want to",
    "start": "293069",
    "end": "295210"
  },
  {
    "text": "be agile so being able to deploy as",
    "start": "295210",
    "end": "298240"
  },
  {
    "text": "quickly as possible new solution right",
    "start": "298240",
    "end": "300430"
  },
  {
    "text": "now we Texas with the service",
    "start": "300430",
    "end": "301870"
  },
  {
    "text": "infrastructure about an hour to deploy",
    "start": "301870",
    "end": "303490"
  },
  {
    "text": "new code flexible scaling one actually",
    "start": "303490",
    "end": "307090"
  },
  {
    "text": "at lower cost would actually pay for",
    "start": "307090",
    "end": "308910"
  },
  {
    "text": "exactly the amount of resources we take",
    "start": "308910",
    "end": "311740"
  },
  {
    "text": "that we take a lot of time people say",
    "start": "311740",
    "end": "313900"
  },
  {
    "text": "just pay for the resources that you use",
    "start": "313900",
    "end": "315250"
  },
  {
    "text": "and what they actually mean is it takes",
    "start": "315250",
    "end": "316750"
  },
  {
    "text": "about two minutes to ramp up some",
    "start": "316750",
    "end": "319030"
  },
  {
    "text": "servers if you need a thousand of them",
    "start": "319030",
    "end": "320530"
  },
  {
    "text": "it takes more than that and then there's",
    "start": "320530",
    "end": "322240"
  },
  {
    "text": "a ramp down and with lambda functions we",
    "start": "322240",
    "end": "324909"
  },
  {
    "text": "can spin up tens of thousands or",
    "start": "324909",
    "end": "326409"
  },
  {
    "text": "hundreds thousands of them and we will",
    "start": "326409",
    "end": "329020"
  },
  {
    "text": "only pay for the a hundred milliseconds",
    "start": "329020",
    "end": "332110"
  },
  {
    "text": "they actually take to ramp up do the",
    "start": "332110",
    "end": "333909"
  },
  {
    "text": "thing and ramp down and that's amazing",
    "start": "333909",
    "end": "336099"
  },
  {
    "text": "for us this here talks about the",
    "start": "336099",
    "end": "341050"
  },
  {
    "text": "evolution that we made our previous",
    "start": "341050",
    "end": "342580"
  },
  {
    "text": "architecture was all Java docker again",
    "start": "342580",
    "end": "345849"
  },
  {
    "text": "an Amazon but ECS and we moved to Python",
    "start": "345849",
    "end": "348729"
  },
  {
    "text": "server list on Amazon lambda this is the",
    "start": "348729",
    "end": "352570"
  },
  {
    "text": "previous one this every every bucket",
    "start": "352570",
    "end": "355330"
  },
  {
    "text": "here every every bubble here is a micro",
    "start": "355330",
    "end": "357669"
  },
  {
    "text": "service we had about 40 of them running",
    "start": "357669",
    "end": "359680"
  },
  {
    "text": "around in a very star-shaped",
    "start": "359680",
    "end": "361240"
  },
  {
    "text": "architecture moving to your streamlined",
    "start": "361240",
    "end": "366070"
  },
  {
    "text": "look at this this is an architectural",
    "start": "366070",
    "end": "368139"
  },
  {
    "text": "pattern we're really proud of it's only",
    "start": "368139",
    "end": "370630"
  },
  {
    "text": "enabled because of AWS is tools you get",
    "start": "370630",
    "end": "374050"
  },
  {
    "text": "every micro service has the input as a",
    "start": "374050",
    "end": "376570"
  },
  {
    "text": "city as an sqs some love the function",
    "start": "376570",
    "end": "379389"
  },
  {
    "text": "doing something sometimes writes to a",
    "start": "379389",
    "end": "380830"
  },
  {
    "text": "database and then an SNS to send it to",
    "start": "380830",
    "end": "383789"
  },
  {
    "text": "the other step in line overall just six",
    "start": "383789",
    "end": "389320"
  },
  {
    "text": "micro services they each scale up and",
    "start": "389320",
    "end": "391570"
  },
  {
    "text": "down in order of seconds to several tens",
    "start": "391570",
    "end": "395409"
  },
  {
    "text": "of thousands of processes we ingest",
    "start": "395409",
    "end": "397900"
  },
  {
    "text": "about a million documents every day and",
    "start": "397900",
    "end": "400240"
  },
  {
    "text": "then the output on the other side really",
    "start": "400240",
    "end": "403389"
  },
  {
    "text": "depends on how many",
    "start": "403389",
    "end": "405159"
  },
  {
    "text": "and they'll be models you have as a",
    "start": "405159",
    "end": "406930"
  },
  {
    "text": "customer with us on the other side we",
    "start": "406930",
    "end": "409449"
  },
  {
    "text": "will output several billions of data",
    "start": "409449",
    "end": "411370"
  },
  {
    "text": "points really refined for what it is",
    "start": "411370",
    "end": "414220"
  },
  {
    "text": "that that our customers need this is how",
    "start": "414220",
    "end": "417879"
  },
  {
    "text": "a development experience look how we",
    "start": "417879",
    "end": "419470"
  },
  {
    "text": "built it you got several devs they would",
    "start": "419470",
    "end": "422080"
  },
  {
    "text": "all develop locally or on the cloud",
    "start": "422080",
    "end": "424599"
  },
  {
    "text": "wherever they're wherever their",
    "start": "424599",
    "end": "425620"
  },
  {
    "text": "environment is through get hooks they'll",
    "start": "425620",
    "end": "428470"
  },
  {
    "text": "deploy to an environment called ops and",
    "start": "428470",
    "end": "430840"
  },
  {
    "text": "that would assume role and do a staged",
    "start": "430840",
    "end": "433389"
  },
  {
    "text": "rollout so 10% of the users 20% 30% 40%",
    "start": "433389",
    "end": "436569"
  },
  {
    "text": "will keep track of errors will keep",
    "start": "436569",
    "end": "439330"
  },
  {
    "text": "track of optimizations of our metrics",
    "start": "439330",
    "end": "442629"
  },
  {
    "text": "and as we move from devastation to",
    "start": "442629",
    "end": "445360"
  },
  {
    "text": "production with a staged rollout each of",
    "start": "445360",
    "end": "448539"
  },
  {
    "text": "the developers will know that their",
    "start": "448539",
    "end": "450009"
  },
  {
    "text": "system is doing what is supposed to do",
    "start": "450009",
    "end": "452259"
  },
  {
    "text": "without breaking anything else this here",
    "start": "452259",
    "end": "457750"
  },
  {
    "text": "is an example of how we even used",
    "start": "457750",
    "end": "459819"
  },
  {
    "text": "architectural pattern to do log shipment",
    "start": "459819",
    "end": "462370"
  },
  {
    "text": "you have tens of thousands of lambdas",
    "start": "462370",
    "end": "464740"
  },
  {
    "text": "they all send logs to to cloud watch",
    "start": "464740",
    "end": "467800"
  },
  {
    "text": "obviously but if we want it all in logs",
    "start": "467800",
    "end": "471039"
  },
  {
    "text": "or in honeycomb we build the same",
    "start": "471039",
    "end": "473759"
  },
  {
    "text": "mechanism called conduit here the same",
    "start": "473759",
    "end": "476710"
  },
  {
    "text": "mechanism we have Sigma s NS s Q s",
    "start": "476710",
    "end": "478960"
  },
  {
    "text": "lambda log processor so even if we have",
    "start": "478960",
    "end": "481240"
  },
  {
    "text": "spikes in logs everything will still",
    "start": "481240",
    "end": "483340"
  },
  {
    "text": "flow smoothly into our logging servers",
    "start": "483340",
    "end": "485889"
  },
  {
    "text": "and it's so easy this is how Channel or",
    "start": "485889",
    "end": "489880"
  },
  {
    "text": "an air and patter would look like inside",
    "start": "489880",
    "end": "495610"
  },
  {
    "start": "493000",
    "end": "667000"
  },
  {
    "text": "that that was until now we just saw that",
    "start": "495610",
    "end": "497860"
  },
  {
    "text": "the ETL part process inside that there's",
    "start": "497860",
    "end": "501550"
  },
  {
    "text": "an NLP process that we need to run NLP",
    "start": "501550",
    "end": "503979"
  },
  {
    "text": "is notoriously known for taking a lot of",
    "start": "503979",
    "end": "508090"
  },
  {
    "text": "CPU we managed to break it down so that",
    "start": "508090",
    "end": "513339"
  },
  {
    "text": "it all runs on lambda functions previous",
    "start": "513339",
    "end": "516190"
  },
  {
    "text": "and LP basis was clear NLP this is how",
    "start": "516190",
    "end": "519459"
  },
  {
    "text": "our NLP process generally looks like you",
    "start": "519459",
    "end": "522190"
  },
  {
    "text": "can see about 12 steps some of them are",
    "start": "522190",
    "end": "525300"
  },
  {
    "text": "just known like tokenizer and lemma",
    "start": "525300",
    "end": "527769"
  },
  {
    "text": "tiser in their tags and some of them are",
    "start": "527769",
    "end": "531910"
  },
  {
    "text": "more specific to our use case none of",
    "start": "531910",
    "end": "535209"
  },
  {
    "text": "them we take off-the-shelf we always",
    "start": "535209",
    "end": "536949"
  },
  {
    "text": "have some",
    "start": "536949",
    "end": "537889"
  },
  {
    "text": "of manipulation to them in our process",
    "start": "537889",
    "end": "541480"
  },
  {
    "text": "we changed all of these from being",
    "start": "541480",
    "end": "546889"
  },
  {
    "text": "dependent on Java and clear NLP in a",
    "start": "546889",
    "end": "551269"
  },
  {
    "text": "docker container to being dependent on",
    "start": "551269",
    "end": "553850"
  },
  {
    "text": "Spacey we work with Python whenever we",
    "start": "553850",
    "end": "556879"
  },
  {
    "text": "need more optimization we go down to sea",
    "start": "556879",
    "end": "561319"
  },
  {
    "text": "or siphon in order to run an alum the",
    "start": "561319",
    "end": "563569"
  },
  {
    "text": "lambda functions have great limitations",
    "start": "563569",
    "end": "566540"
  },
  {
    "text": "you know you barely get one CPU and few",
    "start": "566540",
    "end": "569660"
  },
  {
    "text": "hundreds of megabytes of RAM you can you",
    "start": "569660",
    "end": "571910"
  },
  {
    "text": "can pull it to three gigs but if you do",
    "start": "571910",
    "end": "573679"
  },
  {
    "text": "that it's costly and you might not get",
    "start": "573679",
    "end": "575899"
  },
  {
    "text": "as many as you want so you want things",
    "start": "575899",
    "end": "578389"
  },
  {
    "text": "to be as efficient as possible that's",
    "start": "578389",
    "end": "580790"
  },
  {
    "text": "why you have to go well we had to go",
    "start": "580790",
    "end": "582139"
  },
  {
    "text": "down to see anyway this is an example of",
    "start": "582139",
    "end": "585290"
  },
  {
    "text": "a linguistic pattern that we that we one",
    "start": "585290",
    "end": "587839"
  },
  {
    "text": "of the Lucy patterns that we try to",
    "start": "587839",
    "end": "589329"
  },
  {
    "text": "extract says Taronga proposed",
    "start": "589329",
    "end": "592609"
  },
  {
    "text": "acquisition of Griffin mineral that",
    "start": "592609",
    "end": "594350"
  },
  {
    "text": "should be expected to close in October",
    "start": "594350",
    "end": "597439"
  },
  {
    "text": "that is a sentence that tells us that an",
    "start": "597439",
    "end": "600439"
  },
  {
    "text": "MA might happen and we want to baby we",
    "start": "600439",
    "end": "603499"
  },
  {
    "text": "want to be able to identify sentences",
    "start": "603499",
    "end": "606110"
  },
  {
    "text": "like this for example",
    "start": "606110",
    "end": "608239"
  },
  {
    "text": "and so we would take automatically we",
    "start": "608239",
    "end": "611660"
  },
  {
    "text": "would build a rule and then we would",
    "start": "611660",
    "end": "615079"
  },
  {
    "text": "there's a Weebly the machine that",
    "start": "615079",
    "end": "616790"
  },
  {
    "text": "automatically generates we will code it",
    "start": "616790",
    "end": "618649"
  },
  {
    "text": "automatically generates C code that runs",
    "start": "618649",
    "end": "621949"
  },
  {
    "text": "most of the time we were able to go from",
    "start": "621949",
    "end": "624259"
  },
  {
    "text": "o of n square to o of n or even O of one",
    "start": "624259",
    "end": "627160"
  },
  {
    "text": "complexity the execution actually",
    "start": "627160",
    "end": "630649"
  },
  {
    "text": "happens in size n so again very",
    "start": "630649",
    "end": "632569"
  },
  {
    "text": "efficient and we were able to run",
    "start": "632569",
    "end": "635329"
  },
  {
    "text": "everything I'll show you a few examples",
    "start": "635329",
    "end": "636860"
  },
  {
    "text": "in a minute but very optimized and all",
    "start": "636860",
    "end": "640759"
  },
  {
    "text": "in lambda code so all of us of our NLP",
    "start": "640759",
    "end": "644329"
  },
  {
    "text": "happens in lambda functions this is an",
    "start": "644329",
    "end": "647389"
  },
  {
    "text": "architectural Alderley dip dive you can",
    "start": "647389",
    "end": "650720"
  },
  {
    "text": "see again sqs tasks go to lambda lambda",
    "start": "650720",
    "end": "654019"
  },
  {
    "text": "would take between 3 to 15 seconds per",
    "start": "654019",
    "end": "657049"
  },
  {
    "text": "large task a few hundred milliseconds",
    "start": "657049",
    "end": "659779"
  },
  {
    "text": "for small tests and then again either",
    "start": "659779",
    "end": "661730"
  },
  {
    "text": "send it to the next lambda in line or",
    "start": "661730",
    "end": "664419"
  },
  {
    "text": "dynamo s3 or SNS there are some of the",
    "start": "664419",
    "end": "669319"
  },
  {
    "start": "667000",
    "end": "1097000"
  },
  {
    "text": "results that we've got this is the",
    "start": "669319",
    "end": "671059"
  },
  {
    "text": "legacy",
    "start": "671059",
    "end": "672250"
  },
  {
    "text": "architecture this is the server list",
    "start": "672250",
    "end": "675350"
  },
  {
    "text": "based architecture you can see muddled",
    "start": "675350",
    "end": "677240"
  },
  {
    "text": "and they'll be model loading time used",
    "start": "677240",
    "end": "679190"
  },
  {
    "text": "to take a few tens of seconds now it",
    "start": "679190",
    "end": "680660"
  },
  {
    "text": "takes a few hundreds of milliseconds we",
    "start": "680660",
    "end": "684080"
  },
  {
    "text": "can accomplish that in lambda because we",
    "start": "684080",
    "end": "685820"
  },
  {
    "text": "we took down the amount of RAM it",
    "start": "685820",
    "end": "688130"
  },
  {
    "text": "requires in order to load lambda is very",
    "start": "688130",
    "end": "691040"
  },
  {
    "text": "RAM sensitive this is running the model",
    "start": "691040",
    "end": "693740"
  },
  {
    "text": "at worst-case from one minute to 10",
    "start": "693740",
    "end": "696470"
  },
  {
    "text": "seconds mostly takes us about a hundred",
    "start": "696470",
    "end": "699380"
  },
  {
    "text": "to five hundred milliseconds and this is",
    "start": "699380",
    "end": "701540"
  },
  {
    "text": "a big deal of running it used to take",
    "start": "701540",
    "end": "703070"
  },
  {
    "text": "Edea bytes doesn't fit into a lambda now",
    "start": "703070",
    "end": "705590"
  },
  {
    "text": "takes 250 megabytes all in all combined",
    "start": "705590",
    "end": "708980"
  },
  {
    "text": "we can fit an LP into lambdas they take",
    "start": "708980",
    "end": "711500"
  },
  {
    "text": "512 megabytes which is essentially",
    "start": "711500",
    "end": "714830"
  },
  {
    "text": "almost a magic number for 4 lambda",
    "start": "714830",
    "end": "717170"
  },
  {
    "text": "function and our next our next goal in",
    "start": "717170",
    "end": "720830"
  },
  {
    "text": "line is to do well now right now we do a",
    "start": "720830",
    "end": "722630"
  },
  {
    "text": "million documents and they want to be",
    "start": "722630",
    "end": "725120"
  },
  {
    "text": "able to do about a billion documents",
    "start": "725120",
    "end": "726590"
  },
  {
    "text": "every hour by working with our solutions",
    "start": "726590",
    "end": "730910"
  },
  {
    "text": "you'll be able to delight your customers",
    "start": "730910",
    "end": "733550"
  },
  {
    "text": "as well so come see us so there that",
    "start": "733550",
    "end": "736130"
  },
  {
    "text": "transformation was two phases one is the",
    "start": "736130",
    "end": "739850"
  },
  {
    "text": "ATL and the other one is the an elite e",
    "start": "739850",
    "end": "741800"
  },
  {
    "text": "l took us about five months to move NLP",
    "start": "741800",
    "end": "746380"
  },
  {
    "text": "is still going on it's about six months",
    "start": "746380",
    "end": "749510"
  },
  {
    "text": "in we have about two months more to go",
    "start": "749510",
    "end": "753970"
  },
  {
    "text": "keoki also like awhile examples specific",
    "start": "756340",
    "end": "760420"
  },
  {
    "text": "example from the your case for example",
    "start": "760420",
    "end": "763370"
  },
  {
    "text": "what kind of application apply to all",
    "start": "763370",
    "end": "766400"
  },
  {
    "text": "states what kind of application you give",
    "start": "766400",
    "end": "769580"
  },
  {
    "text": "us like a1 pcs case successful business",
    "start": "769580",
    "end": "773180"
  },
  {
    "text": "case to use your technique yeah I think",
    "start": "773180",
    "end": "776600"
  },
  {
    "text": "I think Nate here can give a several",
    "start": "776600",
    "end": "778700"
  },
  {
    "text": "successful business cases",
    "start": "778700",
    "end": "781960"
  },
  {
    "text": "so today we're analyzing all sorts of",
    "start": "786690",
    "end": "790630"
  },
  {
    "text": "documents for the financial sector that",
    "start": "790630",
    "end": "792850"
  },
  {
    "text": "our clients use in order to both drive",
    "start": "792850",
    "end": "795720"
  },
  {
    "text": "decision-making as well as automated",
    "start": "795720",
    "end": "798400"
  },
  {
    "text": "trading decisions so one of our",
    "start": "798400",
    "end": "800050"
  },
  {
    "text": "specialties is earnings call transcripts",
    "start": "800050",
    "end": "802450"
  },
  {
    "text": "which are tricky because a lot of it is",
    "start": "802450",
    "end": "805300"
  },
  {
    "text": "very freeform text you know and that",
    "start": "805300",
    "end": "808540"
  },
  {
    "text": "there's a question and answer period",
    "start": "808540",
    "end": "810040"
  },
  {
    "text": "where it's off script and so that text",
    "start": "810040",
    "end": "812230"
  },
  {
    "text": "has a lot of linguistic difficulties so",
    "start": "812230",
    "end": "814360"
  },
  {
    "text": "being able to get very accurately very",
    "start": "814360",
    "end": "817900"
  },
  {
    "text": "accurately extract and analyze the",
    "start": "817900",
    "end": "819970"
  },
  {
    "text": "specific topics and events that are",
    "start": "819970",
    "end": "822370"
  },
  {
    "text": "being disclosed in that text presented a",
    "start": "822370",
    "end": "824350"
  },
  {
    "text": "challenge for us and we've been able to",
    "start": "824350",
    "end": "826300"
  },
  {
    "text": "deliver both api's as well as",
    "start": "826300",
    "end": "828700"
  },
  {
    "text": "visualization type type type of",
    "start": "828700",
    "end": "832060"
  },
  {
    "text": "solutions that have been successful for",
    "start": "832060",
    "end": "834279"
  },
  {
    "text": "both more quantitative investment",
    "start": "834279",
    "end": "836770"
  },
  {
    "text": "managers as well as as well as",
    "start": "836770",
    "end": "839980"
  },
  {
    "text": "discretionary investors as well a",
    "start": "839980",
    "end": "844290"
  },
  {
    "text": "similar question what are you extract in",
    "start": "846630",
    "end": "849430"
  },
  {
    "text": "10 seconds fair document what I do what",
    "start": "849430",
    "end": "852100"
  },
  {
    "text": "do you extract from the document in 10",
    "start": "852100",
    "end": "854050"
  },
  {
    "text": "seconds we extract well the the the",
    "start": "854050",
    "end": "857980"
  },
  {
    "text": "easiest way to say it is whatever is",
    "start": "857980",
    "end": "860110"
  },
  {
    "text": "interesting for the client",
    "start": "860110",
    "end": "861640"
  },
  {
    "text": "it could be guidance signal or M&A",
    "start": "861640",
    "end": "865300"
  },
  {
    "text": "signals or trading signals or deceptive",
    "start": "865300",
    "end": "868870"
  },
  {
    "text": "tone so thank you so this is the first",
    "start": "868870",
    "end": "874750"
  },
  {
    "text": "use case where you build the first data",
    "start": "874750",
    "end": "876790"
  },
  {
    "text": "warehouse extraction transformation",
    "start": "876790",
    "end": "878320"
  },
  {
    "text": "loading so then what happens when you're",
    "start": "878320",
    "end": "881320"
  },
  {
    "text": "actually appending creating a secondary",
    "start": "881320",
    "end": "883150"
  },
  {
    "text": "metadata repository how this is a",
    "start": "883150",
    "end": "885850"
  },
  {
    "text": "unidirectional workflow that you show",
    "start": "885850",
    "end": "887950"
  },
  {
    "text": "for optimization what happens when your",
    "start": "887950",
    "end": "890200"
  },
  {
    "text": "original legacy or source files are now",
    "start": "890200",
    "end": "892570"
  },
  {
    "text": "more dynamic they're also adding other",
    "start": "892570",
    "end": "895030"
  },
  {
    "text": "data sources that you didn't have in the",
    "start": "895030",
    "end": "897190"
  },
  {
    "text": "first ETL workflow how do you guarantee",
    "start": "897190",
    "end": "899770"
  },
  {
    "text": "this type of performance we add data",
    "start": "899770",
    "end": "902500"
  },
  {
    "text": "sources all the time we just everyday we",
    "start": "902500",
    "end": "905890"
  },
  {
    "text": "had more data flows and we have to rerun",
    "start": "905890",
    "end": "908050"
  },
  {
    "text": "maybe sometimes previous models on",
    "start": "908050",
    "end": "910029"
  },
  {
    "text": "previous data sources so you have to",
    "start": "910029",
    "end": "911470"
  },
  {
    "text": "rerun a batch of we just had over the",
    "start": "911470",
    "end": "913780"
  },
  {
    "text": "weekend had to run a batch of over a",
    "start": "913780",
    "end": "915400"
  },
  {
    "text": "quarter of a billion documents",
    "start": "915400",
    "end": "918160"
  },
  {
    "text": "it takes about five hours so that's my",
    "start": "918160",
    "end": "920959"
  },
  {
    "text": "question so if you know that only X",
    "start": "920959",
    "end": "922610"
  },
  {
    "text": "percent is being updated from the first",
    "start": "922610",
    "end": "924649"
  },
  {
    "text": "data warehouse installation and you now",
    "start": "924649",
    "end": "926899"
  },
  {
    "text": "have a dynamic data set how can I save",
    "start": "926899",
    "end": "930020"
  },
  {
    "text": "on performance if I only really want to",
    "start": "930020",
    "end": "932630"
  },
  {
    "text": "look at what changed prior to the first",
    "start": "932630",
    "end": "935089"
  },
  {
    "text": "installation are you doing this in terms",
    "start": "935089",
    "end": "937010"
  },
  {
    "text": "of creating other metadata repositories",
    "start": "937010",
    "end": "939620"
  },
  {
    "text": "that are more dynamic I'm not sure I'm",
    "start": "939620",
    "end": "943010"
  },
  {
    "text": "fooling the question I'll try to I'm",
    "start": "943010",
    "end": "944180"
  },
  {
    "text": "trying to answer",
    "start": "944180",
    "end": "944810"
  },
  {
    "text": "anyway all of the metadata is is",
    "start": "944810",
    "end": "948880"
  },
  {
    "text": "schema-less",
    "start": "948880",
    "end": "950089"
  },
  {
    "text": "and so we can track all the changes we",
    "start": "950089",
    "end": "952459"
  },
  {
    "text": "want and then reanalyze only the pieces",
    "start": "952459",
    "end": "955399"
  },
  {
    "text": "of the data that we want to reanalyze",
    "start": "955399",
    "end": "957290"
  },
  {
    "text": "and so if there's a change that we think",
    "start": "957290",
    "end": "959570"
  },
  {
    "text": "will only affect specific kind of",
    "start": "959570",
    "end": "961940"
  },
  {
    "text": "documents we will only pull those so",
    "start": "961940",
    "end": "964520"
  },
  {
    "text": "filter them out only pull those do some",
    "start": "964520",
    "end": "966800"
  },
  {
    "text": "additional fine-grained filtering and",
    "start": "966800",
    "end": "969260"
  },
  {
    "text": "only run them and when we update all the",
    "start": "969260",
    "end": "971209"
  },
  {
    "text": "data there's only one data lake right we",
    "start": "971209",
    "end": "973970"
  },
  {
    "text": "will just update records on top of it",
    "start": "973970",
    "end": "976490"
  },
  {
    "text": "and then you can be able to pull the",
    "start": "976490",
    "end": "978470"
  },
  {
    "text": "last one or the last one that is",
    "start": "978470",
    "end": "980120"
  },
  {
    "text": "actually yours because the same document",
    "start": "980120",
    "end": "982040"
  },
  {
    "text": "can serve multiple customers and within",
    "start": "982040",
    "end": "984050"
  },
  {
    "text": "a single customer it can serve multiple",
    "start": "984050",
    "end": "985520"
  },
  {
    "text": "use cases hi hi you mentioned the cost",
    "start": "985520",
    "end": "993200"
  },
  {
    "text": "savings it's cheaper than the Numa",
    "start": "993200",
    "end": "995060"
  },
  {
    "text": "architecture in terms of percentage of",
    "start": "995060",
    "end": "998180"
  },
  {
    "text": "what's the you know cost savings you you",
    "start": "998180",
    "end": "1001029"
  },
  {
    "text": "saw that what's the cost saving it's",
    "start": "1001029",
    "end": "1003160"
  },
  {
    "text": "about 80 to 90 percent cost saving per",
    "start": "1003160",
    "end": "1006640"
  },
  {
    "text": "unit of measure for a per unit of data",
    "start": "1006640",
    "end": "1008890"
  },
  {
    "text": "it could be even 98 percent but that's",
    "start": "1008890",
    "end": "1012670"
  },
  {
    "text": "the rough number would you apply to you",
    "start": "1012670",
    "end": "1016930"
  },
  {
    "text": "like foreign languages documents for",
    "start": "1016930",
    "end": "1019510"
  },
  {
    "text": "right now we're only English based okay",
    "start": "1019510",
    "end": "1024600"
  },
  {
    "text": "do you offer ap ice to integrate with",
    "start": "1026339",
    "end": "1029199"
  },
  {
    "text": "other applications API is for data ap",
    "start": "1029199",
    "end": "1033730"
  },
  {
    "text": "for your application like say we want",
    "start": "1033730",
    "end": "1036630"
  },
  {
    "text": "one of our products is API based you can",
    "start": "1036630",
    "end": "1039730"
  },
  {
    "text": "get all the the good ease of analysis",
    "start": "1039730",
    "end": "1041770"
  },
  {
    "text": "through an API yes absolutely",
    "start": "1041770",
    "end": "1045270"
  },
  {
    "text": "I actually have a question on the one",
    "start": "1047330",
    "end": "1050210"
  },
  {
    "text": "minute per document so I mean just show",
    "start": "1050210",
    "end": "1053450"
  },
  {
    "text": "what case where if you're looking for a",
    "start": "1053450",
    "end": "1055100"
  },
  {
    "text": "measure for an M&A case write in a",
    "start": "1055100",
    "end": "1057650"
  },
  {
    "text": "transcript that's like for example if",
    "start": "1057650",
    "end": "1060740"
  },
  {
    "text": "you search for that in a in a transcript",
    "start": "1060740",
    "end": "1062870"
  },
  {
    "text": "that takes one minute but let's say that",
    "start": "1062870",
    "end": "1064490"
  },
  {
    "text": "you want to like search for whether the",
    "start": "1064490",
    "end": "1067070"
  },
  {
    "text": "company's launching a new product yeah",
    "start": "1067070",
    "end": "1069410"
  },
  {
    "text": "do you have to actually like train the",
    "start": "1069410",
    "end": "1071120"
  },
  {
    "text": "model again and wait for that or how",
    "start": "1071120",
    "end": "1073130"
  },
  {
    "text": "does that actually work so our models",
    "start": "1073130",
    "end": "1075560"
  },
  {
    "text": "are built in a way that they have",
    "start": "1075560",
    "end": "1076910"
  },
  {
    "text": "they're like aggregating models and they",
    "start": "1076910",
    "end": "1078980"
  },
  {
    "text": "have different parts to them so the same",
    "start": "1078980",
    "end": "1080780"
  },
  {
    "text": "model would also would which would",
    "start": "1080780",
    "end": "1082660"
  },
  {
    "text": "analyze both for everything M&A a new",
    "start": "1082660",
    "end": "1086570"
  },
  {
    "text": "product launch guidance deception all of",
    "start": "1086570",
    "end": "1089120"
  },
  {
    "text": "that is the same then one minute we will",
    "start": "1089120",
    "end": "1090920"
  },
  {
    "text": "include everything",
    "start": "1090920",
    "end": "1093580"
  }
]
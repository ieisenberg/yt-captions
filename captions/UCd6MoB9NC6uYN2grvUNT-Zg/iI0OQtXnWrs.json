[
  {
    "text": "- Hi, I'm Andrea from AWS.",
    "start": "330",
    "end": "3120"
  },
  {
    "text": "- And I'm Marco from Turnitin.",
    "start": "3120",
    "end": "5009"
  },
  {
    "text": "And \"This is My Architecture.\"",
    "start": "5010",
    "end": "7510"
  },
  {
    "text": "- So we're here to talk about",
    "start": "15900",
    "end": "16980"
  },
  {
    "text": "an event-driven architecture,",
    "start": "16980",
    "end": "18539"
  },
  {
    "text": "that focuses on academic integrity.",
    "start": "18540",
    "end": "22290"
  },
  {
    "text": "What is that?",
    "start": "22290",
    "end": "23580"
  },
  {
    "text": "- So the use case, is to be able to detect",
    "start": "23580",
    "end": "26430"
  },
  {
    "text": "generative AI writing for,",
    "start": "26430",
    "end": "29100"
  },
  {
    "text": "in the academic world",
    "start": "29100",
    "end": "30000"
  },
  {
    "text": "using education technology.",
    "start": "30000",
    "end": "32430"
  },
  {
    "text": "- Awesome. So this is on AWS.\n- Yes.",
    "start": "32430",
    "end": "35547"
  },
  {
    "text": "- And let's walk through a workflow.",
    "start": "35547",
    "end": "37620"
  },
  {
    "text": "- Sure.\n- I'm a student.",
    "start": "37620",
    "end": "39450"
  },
  {
    "text": "I wanna upload my paper\nonto your platform.",
    "start": "39450",
    "end": "42660"
  },
  {
    "text": "So let's go through the example.",
    "start": "42660",
    "end": "44130"
  },
  {
    "text": "What's the first thing that happens?",
    "start": "44130",
    "end": "45450"
  },
  {
    "text": "- So, the student, here is our user,",
    "start": "45450",
    "end": "47820"
  },
  {
    "text": "would upload it to Turnitin,",
    "start": "47820",
    "end": "49560"
  },
  {
    "text": "our website. Either through\nan integration or directly.",
    "start": "49560",
    "end": "53100"
  },
  {
    "text": "And that will fire an SNS topic,",
    "start": "53100",
    "end": "56280"
  },
  {
    "text": "to indicate that a paper has come in,",
    "start": "56280",
    "end": "57960"
  },
  {
    "text": "and it's ready for processing.",
    "start": "57960",
    "end": "59879"
  },
  {
    "text": "- I see.",
    "start": "59880",
    "end": "60713"
  },
  {
    "text": "- And then we have an SQS queue of course,",
    "start": "60713",
    "end": "63030"
  },
  {
    "text": "that consumes that SNS,",
    "start": "63030",
    "end": "64229"
  },
  {
    "text": "so that we now can queue it up,",
    "start": "64230",
    "end": "65870"
  },
  {
    "text": "up and get ready for processing",
    "start": "65870",
    "end": "67530"
  },
  {
    "text": "for the generative AI detection.",
    "start": "67530",
    "end": "68940"
  },
  {
    "text": "- I see. What's the scale?",
    "start": "68940",
    "end": "70680"
  },
  {
    "text": "How many papers are you processing?",
    "start": "70680",
    "end": "71940"
  },
  {
    "text": "- So, we are processing\nup to 2 million a day.",
    "start": "71940",
    "end": "75030"
  },
  {
    "text": "- Wow.\n- Pretty much",
    "start": "75030",
    "end": "75863"
  },
  {
    "text": "day after day.",
    "start": "75863",
    "end": "76696"
  },
  {
    "text": "- Okay. So you're storing\nthese in the queue.",
    "start": "76696",
    "end": "79740"
  },
  {
    "text": "What happens next?",
    "start": "79740",
    "end": "81030"
  },
  {
    "text": "- So next, we have a Lambda",
    "start": "81030",
    "end": "84000"
  },
  {
    "text": "that will pick up the\nmessages from the queue,",
    "start": "84000",
    "end": "86850"
  },
  {
    "text": "and determine if we are processing.",
    "start": "86850",
    "end": "89610"
  },
  {
    "text": "We don't process 100% of the papers.",
    "start": "89610",
    "end": "91410"
  },
  {
    "text": "There are some papers",
    "start": "91410",
    "end": "92430"
  },
  {
    "text": "that we choose not to process,",
    "start": "92430",
    "end": "94140"
  },
  {
    "text": "because of language,\nbecause of size limitations.",
    "start": "94140",
    "end": "96510"
  },
  {
    "text": "If it's too short, we don't process it.",
    "start": "96510",
    "end": "97890"
  },
  {
    "text": "And also if it's too\nlong, we don't process it.",
    "start": "97890",
    "end": "99780"
  },
  {
    "text": "And so once it determines\nand processes it,",
    "start": "99780",
    "end": "102000"
  },
  {
    "text": "it will pass it off to a second Lambda,",
    "start": "102000",
    "end": "105000"
  },
  {
    "text": "that is going to look at the document,",
    "start": "105000",
    "end": "107010"
  },
  {
    "text": "and handle the, breaking\nit up into sentences.",
    "start": "107010",
    "end": "110460"
  },
  {
    "text": "And also remove things that\nare not what we call pros.",
    "start": "110460",
    "end": "114330"
  },
  {
    "text": "So it's only the actual writing.",
    "start": "114330",
    "end": "115800"
  },
  {
    "text": "So things like headers and footers",
    "start": "115800",
    "end": "117180"
  },
  {
    "text": "and all that type of-\n- Okay.",
    "start": "117180",
    "end": "118080"
  },
  {
    "text": "So the architecture pattern here,",
    "start": "118080",
    "end": "119550"
  },
  {
    "text": "is the first Lambda function,",
    "start": "119550",
    "end": "120870"
  },
  {
    "text": "is almost your rules engine.",
    "start": "120870",
    "end": "122460"
  },
  {
    "text": "- Yes.\n- Right?",
    "start": "122460",
    "end": "123360"
  },
  {
    "text": "And then the second one\nbreaks the synthesis up.",
    "start": "123360",
    "end": "126660"
  },
  {
    "text": "- Correct.\n- And then from there,",
    "start": "126660",
    "end": "128789"
  },
  {
    "text": "what do you do next?",
    "start": "128790",
    "end": "129780"
  },
  {
    "text": "- So then the second Lambda will send",
    "start": "129780",
    "end": "132840"
  },
  {
    "text": "a sliding window of sentences.",
    "start": "132840",
    "end": "134953"
  },
  {
    "text": "- Okay.\n- On to a SageMaker endpoint,",
    "start": "134953",
    "end": "138322"
  },
  {
    "text": "to do the inference of\nthat number of sentences.",
    "start": "138322",
    "end": "141180"
  },
  {
    "text": "And it does that in parallel.",
    "start": "141180",
    "end": "142500"
  },
  {
    "text": "So it'll send about 10 segments,",
    "start": "142500",
    "end": "144150"
  },
  {
    "text": "so that we can get-\n- Okay.",
    "start": "144150",
    "end": "145409"
  },
  {
    "text": "- Just for performance reasons,",
    "start": "145410",
    "end": "146520"
  },
  {
    "text": "we don't have to wait\n- I see.",
    "start": "146520",
    "end": "147390"
  },
  {
    "text": "- for each one in turn.",
    "start": "147390",
    "end": "148680"
  },
  {
    "text": "- With the scale you have with this,",
    "start": "148680",
    "end": "150510"
  },
  {
    "text": "you mentioned 2 million papers a day.",
    "start": "150510",
    "end": "152038"
  },
  {
    "text": "- Yes.\n- How, what type of Lambda",
    "start": "152038",
    "end": "155670"
  },
  {
    "text": "components are you running?",
    "start": "155670",
    "end": "156882"
  },
  {
    "text": "- Is it serverless?\n- Yeah, serverless.",
    "start": "156882",
    "end": "158088"
  },
  {
    "text": "- Or are you running-\n- Yeah.",
    "start": "158088",
    "end": "158920"
  },
  {
    "text": "- We were hoping to use\nSageMaker Serverless.",
    "start": "158921",
    "end": "160110"
  },
  {
    "text": "- Okay.\n- But the scale,",
    "start": "160110",
    "end": "161940"
  },
  {
    "text": "the current limitations\nprevented us from doing that.",
    "start": "161940",
    "end": "164430"
  },
  {
    "text": "So we had to use SageMaker EC2.",
    "start": "164430",
    "end": "166271"
  },
  {
    "text": "- Okay.\n- To get the concurrency",
    "start": "166272",
    "end": "167970"
  },
  {
    "text": "we needed, even though we have a queue,",
    "start": "167970",
    "end": "170910"
  },
  {
    "text": "it would just fall behind if",
    "start": "170910",
    "end": "171990"
  },
  {
    "text": "it can't run at full speed.",
    "start": "171990",
    "end": "173670"
  },
  {
    "text": "- I see. So you have a\nmachine learning model",
    "start": "173670",
    "end": "175950"
  },
  {
    "text": "that does inferencing?\n- Yes. Yes.",
    "start": "175950",
    "end": "177540"
  },
  {
    "text": "- So what do you capture?",
    "start": "177540",
    "end": "179370"
  },
  {
    "text": "- So the machine learning model",
    "start": "179370",
    "end": "180959"
  },
  {
    "text": "does the inferencing for the",
    "start": "180960",
    "end": "182370"
  },
  {
    "text": "segments of sentences,\n- Mm-hmm.",
    "start": "182370",
    "end": "184379"
  },
  {
    "text": "- And it will return that",
    "start": "184380",
    "end": "186000"
  },
  {
    "text": "back to the Lambda it last hit.\n- Okay.",
    "start": "186000",
    "end": "188550"
  },
  {
    "text": "- And this Lambda will\naggregate each segment,",
    "start": "188550",
    "end": "193140"
  },
  {
    "text": "to come up with a score for the document.",
    "start": "193140",
    "end": "195660"
  },
  {
    "text": "So at this point, we have\na score for every sentence,",
    "start": "195660",
    "end": "197730"
  },
  {
    "text": "and the overall document score.",
    "start": "197730",
    "end": "200099"
  },
  {
    "text": "- I see.\n- And that gets returned",
    "start": "200100",
    "end": "201780"
  },
  {
    "text": "to the first Lambda.\n- Okay.",
    "start": "201780",
    "end": "203370"
  },
  {
    "text": "- I should point out,\nobviously it's non-standard",
    "start": "203370",
    "end": "206280"
  },
  {
    "text": "to have a Lambda calling a Lambda.",
    "start": "206280",
    "end": "208860"
  },
  {
    "text": "And we do that intentionally because",
    "start": "208860",
    "end": "211200"
  },
  {
    "text": "the first Lambda, the orchestrator,",
    "start": "211200",
    "end": "214140"
  },
  {
    "text": "the rules engine was written\nby our production team.",
    "start": "214140",
    "end": "217064"
  },
  {
    "text": "It better suits itself to being in Java,",
    "start": "217064",
    "end": "219269"
  },
  {
    "text": "because we already have the libraries,",
    "start": "219270",
    "end": "220680"
  },
  {
    "text": "and everything to do this.",
    "start": "220680",
    "end": "222689"
  },
  {
    "text": "The second one was written by our AI team,",
    "start": "222690",
    "end": "224730"
  },
  {
    "text": "and it's written in Python.",
    "start": "224730",
    "end": "225720"
  },
  {
    "text": "- Oh, I see.\n- So it's hard to combine",
    "start": "225720",
    "end": "226920"
  },
  {
    "text": "Python and Java.",
    "start": "226920",
    "end": "228180"
  },
  {
    "text": "And so we went ahead and\njust did it separately,",
    "start": "228180",
    "end": "229799"
  },
  {
    "text": "because this logic more closely",
    "start": "229800",
    "end": "231600"
  },
  {
    "text": "relates itself to the model.\n- Okay.",
    "start": "231600",
    "end": "233880"
  },
  {
    "text": "- So we had to do that,",
    "start": "233880",
    "end": "234810"
  },
  {
    "text": "which still works out.\n- I see.",
    "start": "234810",
    "end": "235824"
  },
  {
    "text": "- Even though it's they're\nslightly not standard.",
    "start": "235824",
    "end": "237820"
  },
  {
    "text": "- Yeah. So the architecture\npattern you followed here,",
    "start": "237820",
    "end": "240150"
  },
  {
    "text": "is to help data scientists,",
    "start": "240150",
    "end": "241980"
  },
  {
    "text": "and those in the backend\n- Correct. Yes.",
    "start": "241980",
    "end": "243300"
  },
  {
    "text": "- Kind of work collaborative together.",
    "start": "243300",
    "end": "244890"
  },
  {
    "text": "Is that because you wanted to",
    "start": "244890",
    "end": "246330"
  },
  {
    "text": "persist the data somewhere?\n- Correct. Yes.",
    "start": "246330",
    "end": "247557"
  },
  {
    "text": "Because then this Lambda",
    "start": "247557",
    "end": "249600"
  },
  {
    "text": "will finally persist the data in DynamoDB.",
    "start": "249600",
    "end": "251940"
  },
  {
    "text": "- DynamoDB.",
    "start": "251940",
    "end": "253200"
  },
  {
    "text": "- And again, we have all the libraries,",
    "start": "253200",
    "end": "254340"
  },
  {
    "text": "and all the patterns written for that.",
    "start": "254340",
    "end": "255959"
  },
  {
    "text": "So that in DynamoDB we end up",
    "start": "255960",
    "end": "257850"
  },
  {
    "text": "with a record for every paper",
    "start": "257850",
    "end": "259530"
  },
  {
    "text": "at the sentence level, for all\nthe details stored in there.",
    "start": "259530",
    "end": "263130"
  },
  {
    "text": "- Okay.",
    "start": "263130",
    "end": "263970"
  },
  {
    "text": "- And then finally, we\nhave a micro front end,",
    "start": "263970",
    "end": "268380"
  },
  {
    "text": "which is a web component.\n- Okay.",
    "start": "268380",
    "end": "269341"
  },
  {
    "text": "- Which we were able to embed",
    "start": "269341",
    "end": "271140"
  },
  {
    "text": "in all our existing applications.",
    "start": "271140",
    "end": "273330"
  },
  {
    "text": "And that way we didn't have to",
    "start": "273330",
    "end": "274860"
  },
  {
    "text": "rewrite all the applications,",
    "start": "274860",
    "end": "276030"
  },
  {
    "text": "just embed the web component.\n- Okay.",
    "start": "276030",
    "end": "277410"
  },
  {
    "text": "- And this micro front end,",
    "start": "277410",
    "end": "279000"
  },
  {
    "text": "is able to call the Lambda,",
    "start": "279000",
    "end": "280890"
  },
  {
    "text": "to retrieve the data\nfor that one document,",
    "start": "280890",
    "end": "283950"
  },
  {
    "text": "to be able to display\nit to the instructor,",
    "start": "283950",
    "end": "286501"
  },
  {
    "text": "the indicator, and the\nvarious data needed.",
    "start": "286501",
    "end": "290100"
  },
  {
    "text": "- Okay. So the score per sentence,",
    "start": "290100",
    "end": "292020"
  },
  {
    "text": "and the document, and papers-",
    "start": "292020",
    "end": "293516"
  },
  {
    "text": "- Correct.\n- And the rules are persisted",
    "start": "293516",
    "end": "294930"
  },
  {
    "text": "in DynamoDB.\n- Correct. Yes.",
    "start": "294930",
    "end": "296789"
  },
  {
    "text": "- And then the teacher can then",
    "start": "296790",
    "end": "298590"
  },
  {
    "text": "acquire that information\nthrough their rep front end.",
    "start": "298590",
    "end": "301110"
  },
  {
    "text": "- Exactly. And then we\nwere able to release this",
    "start": "301110",
    "end": "303180"
  },
  {
    "text": "to all of our customers who opted in.",
    "start": "303180",
    "end": "305729"
  },
  {
    "text": "So a few opted out,",
    "start": "305730",
    "end": "306750"
  },
  {
    "text": "but we were able to release it",
    "start": "306750",
    "end": "307830"
  },
  {
    "text": "to everyone worldwide,\nliterally overnight,",
    "start": "307830",
    "end": "309780"
  },
  {
    "text": "by able to inject the-\n- Wonderful.",
    "start": "309780",
    "end": "311598"
  },
  {
    "text": "And Marco, in terms\nof, you know, locality,",
    "start": "311598",
    "end": "314639"
  },
  {
    "text": "do you offer this in North America?",
    "start": "314640",
    "end": "317310"
  },
  {
    "text": "- Yes. This is geo distributed.",
    "start": "317310",
    "end": "318810"
  },
  {
    "text": "- Okay.\n- So we have this system",
    "start": "318810",
    "end": "319889"
  },
  {
    "text": "repeated three times in Europe,",
    "start": "319890",
    "end": "322350"
  },
  {
    "text": "in Asia Pacific, and in the US,",
    "start": "322350",
    "end": "324870"
  },
  {
    "text": "for the customers based\non their geography.",
    "start": "324870",
    "end": "327300"
  },
  {
    "text": "- Awesome. I really\nlove this architecture.",
    "start": "327300",
    "end": "329430"
  },
  {
    "text": "Thanks you for sharing this",
    "start": "329430",
    "end": "330270"
  },
  {
    "text": "event-driven architecture\nwith this unique pattern.",
    "start": "330270",
    "end": "333300"
  },
  {
    "text": "- Thank you very much.",
    "start": "333300",
    "end": "334139"
  },
  {
    "text": "- And thanks again.",
    "start": "334140",
    "end": "335723"
  }
]
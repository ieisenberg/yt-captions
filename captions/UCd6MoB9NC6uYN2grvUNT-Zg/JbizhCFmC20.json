[
  {
    "text": "hello and welcome to video three of the",
    "start": "2320",
    "end": "5000"
  },
  {
    "text": "series best practices building",
    "start": "5000",
    "end": "7080"
  },
  {
    "text": "generative AI applications on",
    "start": "7080",
    "end": "9840"
  },
  {
    "text": "AWS my name is Dan stair I am an",
    "start": "9840",
    "end": "12559"
  },
  {
    "text": "analytic specialist Solutions architect",
    "start": "12559",
    "end": "15160"
  },
  {
    "text": "and this video series was built in",
    "start": "15160",
    "end": "17039"
  },
  {
    "text": "collaboration with my co-workers harap",
    "start": "17039",
    "end": "19920"
  },
  {
    "text": "partti and Felix huthmacher our",
    "start": "19920",
    "end": "22640"
  },
  {
    "text": "objective is to provide a One-Stop shop",
    "start": "22640",
    "end": "25080"
  },
  {
    "text": "for you to learn the essentials of",
    "start": "25080",
    "end": "26920"
  },
  {
    "text": "building generative AI applications on",
    "start": "26920",
    "end": "29519"
  },
  {
    "text": "aw us in our role we assist many",
    "start": "29519",
    "end": "33000"
  },
  {
    "text": "customers of different sizes in",
    "start": "33000",
    "end": "35040"
  },
  {
    "text": "realizing their vision for generative AI",
    "start": "35040",
    "end": "37520"
  },
  {
    "text": "applications since the technology is so",
    "start": "37520",
    "end": "39840"
  },
  {
    "text": "new we have seen many customers asking",
    "start": "39840",
    "end": "42280"
  },
  {
    "text": "AWS Solutions Architects for guidance in",
    "start": "42280",
    "end": "45000"
  },
  {
    "text": "building generative AI",
    "start": "45000",
    "end": "48160"
  },
  {
    "text": "applications this is video three in our",
    "start": "48160",
    "end": "50840"
  },
  {
    "text": "Series in videos one and two we provided",
    "start": "50840",
    "end": "54000"
  },
  {
    "text": "an overview of how to choose the right",
    "start": "54000",
    "end": "55920"
  },
  {
    "text": "large language model for your use case",
    "start": "55920",
    "end": "58719"
  },
  {
    "text": "in this video we will be covering how to",
    "start": "58719",
    "end": "61280"
  },
  {
    "text": "evaluate an llm system involving an llm",
    "start": "61280",
    "end": "65400"
  },
  {
    "text": "an embedding model and a vector store",
    "start": "65400",
    "end": "68040"
  },
  {
    "text": "and we will be covering appropriate",
    "start": "68040",
    "end": "70080"
  },
  {
    "text": "metrics for",
    "start": "70080",
    "end": "72240"
  },
  {
    "text": "each we Advocate a metrics driven",
    "start": "72240",
    "end": "75560"
  },
  {
    "text": "approach to llm system evaluation there",
    "start": "75560",
    "end": "78680"
  },
  {
    "text": "are many advantages of metric driven",
    "start": "78680",
    "end": "81560"
  },
  {
    "text": "development just as automated testing in",
    "start": "81560",
    "end": "84240"
  },
  {
    "text": "software development provides",
    "start": "84240",
    "end": "86040"
  },
  {
    "text": "objectivity speed and reduces time to",
    "start": "86040",
    "end": "88600"
  },
  {
    "text": "Market J metrics serve a similar",
    "start": "88600",
    "end": "92119"
  },
  {
    "text": "function first they are an objective",
    "start": "92119",
    "end": "94759"
  },
  {
    "text": "approach given a ground truth and Des",
    "start": "94759",
    "end": "98680"
  },
  {
    "text": "and test data we only change one",
    "start": "98680",
    "end": "102240"
  },
  {
    "text": "variable at a time for example chunk",
    "start": "102240",
    "end": "105079"
  },
  {
    "text": "size embedding model or large language",
    "start": "105079",
    "end": "109719"
  },
  {
    "text": "model metrics can change as business",
    "start": "109719",
    "end": "112719"
  },
  {
    "text": "needs change for example if a new",
    "start": "112719",
    "end": "115360"
  },
  {
    "text": "product requires extremely low",
    "start": "115360",
    "end": "117200"
  },
  {
    "text": "likelihood of",
    "start": "117200",
    "end": "118640"
  },
  {
    "text": "toxicity and and you can increase speed",
    "start": "118640",
    "end": "121640"
  },
  {
    "text": "and time to Market you can run an",
    "start": "121640",
    "end": "123640"
  },
  {
    "text": "automated test Suite much faster than",
    "start": "123640",
    "end": "126600"
  },
  {
    "text": "doing manual testing and this automated",
    "start": "126600",
    "end": "129479"
  },
  {
    "text": "test Suite coverage can be more",
    "start": "129479",
    "end": "132599"
  },
  {
    "text": "comprehensive now let's take a look at",
    "start": "132599",
    "end": "135560"
  },
  {
    "text": "precisely which metrics we will be",
    "start": "135560",
    "end": "137599"
  },
  {
    "text": "relying",
    "start": "137599",
    "end": "140040"
  },
  {
    "text": "on all of the llm system evaluation",
    "start": "141239",
    "end": "144640"
  },
  {
    "text": "metrics we will be covering measure four",
    "start": "144640",
    "end": "147239"
  },
  {
    "text": "core elements in relation to one another",
    "start": "147239",
    "end": "150080"
  },
  {
    "text": "these core elements are the question the",
    "start": "150080",
    "end": "153640"
  },
  {
    "text": "answer the context and the ground",
    "start": "153640",
    "end": "157680"
  },
  {
    "text": "truth on the left side we list",
    "start": "157680",
    "end": "160440"
  },
  {
    "text": "generation met metrics and on the right",
    "start": "160440",
    "end": "162760"
  },
  {
    "text": "side we will list our retrieval metrics",
    "start": "162760",
    "end": "165640"
  },
  {
    "text": "first looking at generation metrics we",
    "start": "165640",
    "end": "169040"
  },
  {
    "text": "have answer relevance which looks at if",
    "start": "169040",
    "end": "172440"
  },
  {
    "text": "the answer is relevant to the question",
    "start": "172440",
    "end": "174360"
  },
  {
    "text": "asked we will also look at",
    "start": "174360",
    "end": "177239"
  },
  {
    "text": "faithfulness which looks at the answer",
    "start": "177239",
    "end": "179640"
  },
  {
    "text": "to to see if it accurately reflects the",
    "start": "179640",
    "end": "181879"
  },
  {
    "text": "context given on the right side we have",
    "start": "181879",
    "end": "184879"
  },
  {
    "text": "our retrieval metrics including context",
    "start": "184879",
    "end": "188480"
  },
  {
    "text": "Precision which looks at if the context",
    "start": "188480",
    "end": "191280"
  },
  {
    "text": "is relevant to the question and context",
    "start": "191280",
    "end": "196080"
  },
  {
    "text": "recall which looks at based on the",
    "start": "196080",
    "end": "199080"
  },
  {
    "text": "ground truth answer can the system",
    "start": "199080",
    "end": "201879"
  },
  {
    "text": "retrieve most of the relevant context",
    "start": "201879",
    "end": "206799"
  },
  {
    "text": "available also not shown on this slide",
    "start": "206799",
    "end": "210640"
  },
  {
    "text": "we have our end to end metrics including",
    "start": "210640",
    "end": "213760"
  },
  {
    "text": "answer correctness which compares the",
    "start": "213760",
    "end": "215920"
  },
  {
    "text": "answer to the ground truth",
    "start": "215920",
    "end": "219280"
  },
  {
    "text": "answer this provides a conceptual",
    "start": "219280",
    "end": "221840"
  },
  {
    "text": "overview of generative AI metrics now",
    "start": "221840",
    "end": "225040"
  },
  {
    "text": "let's look at an example of a rag system",
    "start": "225040",
    "end": "227720"
  },
  {
    "text": "on",
    "start": "227720",
    "end": "230000"
  },
  {
    "text": "AWS in this diagram we have an open",
    "start": "230239",
    "end": "234319"
  },
  {
    "text": "search serverless Vector store and we",
    "start": "234319",
    "end": "236840"
  },
  {
    "text": "use Bedrock for our foundation model in",
    "start": "236840",
    "end": "239799"
  },
  {
    "text": "and embedding model to walk you through",
    "start": "239799",
    "end": "243400"
  },
  {
    "text": "the flow of this rag",
    "start": "243400",
    "end": "245680"
  },
  {
    "text": "system first a user asks a question that",
    "start": "245680",
    "end": "249439"
  },
  {
    "text": "question is sent to open",
    "start": "249439",
    "end": "252239"
  },
  {
    "text": "search open search then calls the",
    "start": "252239",
    "end": "255120"
  },
  {
    "text": "Bedrock embedding model API to convert",
    "start": "255120",
    "end": "257959"
  },
  {
    "text": "the question into a vector then it takes",
    "start": "257959",
    "end": "260759"
  },
  {
    "text": "that vector and does a search for",
    "start": "260759",
    "end": "262919"
  },
  {
    "text": "example using a k nearest neighbor",
    "start": "262919",
    "end": "265040"
  },
  {
    "text": "algorithm or approximate nearest neor",
    "start": "265040",
    "end": "267160"
  },
  {
    "text": "neighbor",
    "start": "267160",
    "end": "268320"
  },
  {
    "text": "algorithm that sech returns results",
    "start": "268320",
    "end": "271199"
  },
  {
    "text": "those results are converted from Vector",
    "start": "271199",
    "end": "275000"
  },
  {
    "text": "into text again via bedrock and then an",
    "start": "275000",
    "end": "279160"
  },
  {
    "text": "large language model will process those",
    "start": "279160",
    "end": "281759"
  },
  {
    "text": "words uh which are referred to as the",
    "start": "281759",
    "end": "284000"
  },
  {
    "text": "context and return an end answer to the",
    "start": "284000",
    "end": "288479"
  },
  {
    "text": "user so let's say the user asked a",
    "start": "288479",
    "end": "290880"
  },
  {
    "text": "question what was the weather yesterday",
    "start": "290880",
    "end": "293759"
  },
  {
    "text": "that question will be sent to open",
    "start": "293759",
    "end": "296400"
  },
  {
    "text": "search it will be vectorized search",
    "start": "296400",
    "end": "298639"
  },
  {
    "text": "results are returned",
    "start": "298639",
    "end": "300639"
  },
  {
    "text": "in this example the context given is it",
    "start": "300639",
    "end": "303960"
  },
  {
    "text": "was 78° and the sky was blue and the",
    "start": "303960",
    "end": "307199"
  },
  {
    "text": "large language model summarizes that",
    "start": "307199",
    "end": "309160"
  },
  {
    "text": "context and provides an answer it was a",
    "start": "309160",
    "end": "313080"
  },
  {
    "text": "sunny",
    "start": "313080",
    "end": "314680"
  },
  {
    "text": "78° let's take a deeper look at our",
    "start": "314680",
    "end": "317639"
  },
  {
    "text": "generation",
    "start": "317639",
    "end": "320280"
  },
  {
    "text": "metrics Our Generation metrics are",
    "start": "320520",
    "end": "322960"
  },
  {
    "text": "faithfulness and answer",
    "start": "322960",
    "end": "325520"
  },
  {
    "text": "relevance to go through this methodology",
    "start": "325520",
    "end": "328440"
  },
  {
    "text": "behind faithfulness first we will",
    "start": "328440",
    "end": "330880"
  },
  {
    "text": "separate out distinct claims in a given",
    "start": "330880",
    "end": "333560"
  },
  {
    "text": "answer then we will assess how many",
    "start": "333560",
    "end": "336039"
  },
  {
    "text": "claims are valid then we compare each",
    "start": "336039",
    "end": "338639"
  },
  {
    "text": "claim to the context",
    "start": "338639",
    "end": "340840"
  },
  {
    "text": "given and then we calculate faithfulness",
    "start": "340840",
    "end": "343919"
  },
  {
    "text": "which is the number of valid claims",
    "start": "343919",
    "end": "345800"
  },
  {
    "text": "divided by the number of total",
    "start": "345800",
    "end": "349240"
  },
  {
    "text": "claims going over the methodology for",
    "start": "349240",
    "end": "352639"
  },
  {
    "text": "answer relevance first we will generate",
    "start": "352639",
    "end": "356280"
  },
  {
    "text": "artificial questions based on the ground",
    "start": "356280",
    "end": "358639"
  },
  {
    "text": "truth answer then we will calculate the",
    "start": "358639",
    "end": "361759"
  },
  {
    "text": "similarity of the given answer to the",
    "start": "361759",
    "end": "364520"
  },
  {
    "text": "ground truth answer using cosine",
    "start": "364520",
    "end": "366479"
  },
  {
    "text": "similarity and finally we will average",
    "start": "366479",
    "end": "369880"
  },
  {
    "text": "the similarity of the three cosine",
    "start": "369880",
    "end": "371880"
  },
  {
    "text": "similarities and return a similarity",
    "start": "371880",
    "end": "375360"
  },
  {
    "text": "score typically between zero and",
    "start": "375360",
    "end": "378440"
  },
  {
    "text": "one it will help to look at a couple of",
    "start": "378440",
    "end": "380960"
  },
  {
    "text": "examples here starting with",
    "start": "380960",
    "end": "384440"
  },
  {
    "text": "faithfulness the given an let's take the",
    "start": "385199",
    "end": "387440"
  },
  {
    "text": "given answer it is 78°",
    "start": "387440",
    "end": "390160"
  },
  {
    "text": "and",
    "start": "390160",
    "end": "391520"
  },
  {
    "text": "sunny we'll separate that out into two",
    "start": "391520",
    "end": "394039"
  },
  {
    "text": "claims one it is 78° two it is",
    "start": "394039",
    "end": "398000"
  },
  {
    "text": "sunny now we'll compare each claim to",
    "start": "398000",
    "end": "400919"
  },
  {
    "text": "the context given the context given here",
    "start": "400919",
    "end": "403360"
  },
  {
    "text": "is it is a cloudy",
    "start": "403360",
    "end": "405120"
  },
  {
    "text": "78° so the faithfulness in this example",
    "start": "405120",
    "end": "408599"
  },
  {
    "text": "is one valid claim divided by two total",
    "start": "408599",
    "end": "411319"
  },
  {
    "text": "claims or",
    "start": "411319",
    "end": "413759"
  },
  {
    "text": "0.5 now let's look at an example for our",
    "start": "413759",
    "end": "416680"
  },
  {
    "text": "other generation metric answer relevance",
    "start": "416680",
    "end": "421520"
  },
  {
    "text": "first we generate artificial questions",
    "start": "423440",
    "end": "426080"
  },
  {
    "text": "based on the ground truth answer then we",
    "start": "426080",
    "end": "429160"
  },
  {
    "text": "calculate the mean cosine similarity of",
    "start": "429160",
    "end": "432400"
  },
  {
    "text": "the generated questions compared to the",
    "start": "432400",
    "end": "435240"
  },
  {
    "text": "actual question in this example our",
    "start": "435240",
    "end": "438120"
  },
  {
    "text": "cosine similarities are 0.6 0.7 and",
    "start": "438120",
    "end": "442280"
  },
  {
    "text": "0.8 finally we average the cosine",
    "start": "442280",
    "end": "445199"
  },
  {
    "text": "similarities to deliver a score for",
    "start": "445199",
    "end": "447840"
  },
  {
    "text": "answer relevance for this this example",
    "start": "447840",
    "end": "450879"
  },
  {
    "text": "our the score we are delivering is",
    "start": "450879",
    "end": "455960"
  },
  {
    "text": "0.7 now that we've covered generation",
    "start": "456000",
    "end": "458440"
  },
  {
    "text": "metrics let's look at our retrieval",
    "start": "458440",
    "end": "462599"
  },
  {
    "text": "metrics context Precision looks at the",
    "start": "463039",
    "end": "465680"
  },
  {
    "text": "given question the ground truth answer",
    "start": "465680",
    "end": "468240"
  },
  {
    "text": "and the context and determines if the",
    "start": "468240",
    "end": "470560"
  },
  {
    "text": "right contexts are present and are",
    "start": "470560",
    "end": "472440"
  },
  {
    "text": "ranked by relevance so for context",
    "start": "472440",
    "end": "475080"
  },
  {
    "text": "Precision a high score means that the",
    "start": "475080",
    "end": "477080"
  },
  {
    "text": "system is retrieving mostly relevant",
    "start": "477080",
    "end": "481159"
  },
  {
    "text": "information context recall takes the",
    "start": "481159",
    "end": "483800"
  },
  {
    "text": "number of sentences in the ground truth",
    "start": "483800",
    "end": "486120"
  },
  {
    "text": "answer which can be attributed to the",
    "start": "486120",
    "end": "488280"
  },
  {
    "text": "context and then divides by the total",
    "start": "488280",
    "end": "490639"
  },
  {
    "text": "number of sentences in the ground truth",
    "start": "490639",
    "end": "492639"
  },
  {
    "text": "answer so a high score means that the",
    "start": "492639",
    "end": "495759"
  },
  {
    "text": "system can retrieve most of the relevant",
    "start": "495759",
    "end": "498879"
  },
  {
    "text": "information",
    "start": "498879",
    "end": "500120"
  },
  {
    "text": "available there are trade-offs between",
    "start": "500120",
    "end": "502720"
  },
  {
    "text": "achieving High precision and achieving",
    "start": "502720",
    "end": "504720"
  },
  {
    "text": "High recall to illustrate these let's",
    "start": "504720",
    "end": "507800"
  },
  {
    "text": "look at an example",
    "start": "507800",
    "end": "511039"
  },
  {
    "text": "in our example we have a question what",
    "start": "511039",
    "end": "514320"
  },
  {
    "text": "information is in our address book for",
    "start": "514320",
    "end": "516599"
  },
  {
    "text": "Jane Doe we also have a ground truth",
    "start": "516599",
    "end": "519680"
  },
  {
    "text": "answer Jane Doe lives at 123 any Street",
    "start": "519680",
    "end": "522839"
  },
  {
    "text": "any Town USA and her phone number is",
    "start": "522839",
    "end": "527560"
  },
  {
    "text": "55510 now let's look at two different",
    "start": "527839",
    "end": "530279"
  },
  {
    "text": "answers one for high precision and one",
    "start": "530279",
    "end": "533240"
  },
  {
    "text": "for high",
    "start": "533240",
    "end": "534680"
  },
  {
    "text": "recall example answer",
    "start": "534680",
    "end": "537120"
  },
  {
    "text": "one pulls one result just for address",
    "start": "537120",
    "end": "541240"
  },
  {
    "text": "this is a high and and that's a correct",
    "start": "541240",
    "end": "543480"
  },
  {
    "text": "address for Jane Doe this is a high",
    "start": "543480",
    "end": "545720"
  },
  {
    "text": "Precision answer because all of the",
    "start": "545720",
    "end": "548279"
  },
  {
    "text": "results that were pulled were relevant",
    "start": "548279",
    "end": "550720"
  },
  {
    "text": "but it's a low recall answer because",
    "start": "550720",
    "end": "552560"
  },
  {
    "text": "we're not capturing all of the relevant",
    "start": "552560",
    "end": "554880"
  },
  {
    "text": "facts that are in our data store that",
    "start": "554880",
    "end": "558560"
  },
  {
    "text": "relate to J do example answer two is the",
    "start": "558560",
    "end": "563480"
  },
  {
    "text": "opposite we pull one result for address",
    "start": "563480",
    "end": "566800"
  },
  {
    "text": "one result for phone those are both for",
    "start": "566800",
    "end": "568680"
  },
  {
    "text": "Jane do and then we pull one result for",
    "start": "568680",
    "end": "570800"
  },
  {
    "text": "joho's address so we pull an irrelevant",
    "start": "570800",
    "end": "573160"
  },
  {
    "text": "address so this is lower Precision",
    "start": "573160",
    "end": "575600"
  },
  {
    "text": "because we've pulled an irrelevant",
    "start": "575600",
    "end": "576920"
  },
  {
    "text": "address but it's high recall because we",
    "start": "576920",
    "end": "579160"
  },
  {
    "text": "have captured all of the relevant",
    "start": "579160",
    "end": "581640"
  },
  {
    "text": "information for Jane do that exists in",
    "start": "581640",
    "end": "584399"
  },
  {
    "text": "our",
    "start": "584399",
    "end": "586040"
  },
  {
    "text": "database so you can see depending on",
    "start": "586040",
    "end": "588519"
  },
  {
    "text": "your goals you might want to optimize",
    "start": "588519",
    "end": "590360"
  },
  {
    "text": "for one or the",
    "start": "590360",
    "end": "592000"
  },
  {
    "text": "other now that we've covered Our",
    "start": "592000",
    "end": "594279"
  },
  {
    "text": "Generation and retrieval metrics let's",
    "start": "594279",
    "end": "596760"
  },
  {
    "text": "look at our end to end metric",
    "start": "596760",
    "end": "601160"
  },
  {
    "text": "which is answer correctness the high",
    "start": "601200",
    "end": "603600"
  },
  {
    "text": "level idea behind answer correctness is",
    "start": "603600",
    "end": "606200"
  },
  {
    "text": "we will compare the ground truth answer",
    "start": "606200",
    "end": "608279"
  },
  {
    "text": "to the given answer and score the",
    "start": "608279",
    "end": "611680"
  },
  {
    "text": "result first we will calculate semantic",
    "start": "611680",
    "end": "614839"
  },
  {
    "text": "similarity to do this we convert the",
    "start": "614839",
    "end": "617480"
  },
  {
    "text": "given answer to a vector and compare to",
    "start": "617480",
    "end": "619839"
  },
  {
    "text": "the ground truth answer Vector using",
    "start": "619839",
    "end": "621720"
  },
  {
    "text": "cosine similarity to take an example if",
    "start": "621720",
    "end": "624959"
  },
  {
    "text": "the question is what is the tallest",
    "start": "624959",
    "end": "626720"
  },
  {
    "text": "mountain in the United States and and",
    "start": "626720",
    "end": "629399"
  },
  {
    "text": "the given answer is Denali is the",
    "start": "629399",
    "end": "631920"
  },
  {
    "text": "tallest mountain in the United States we",
    "start": "631920",
    "end": "634320"
  },
  {
    "text": "would compare the vector form of that",
    "start": "634320",
    "end": "636920"
  },
  {
    "text": "given answer to the ground truth answer",
    "start": "636920",
    "end": "639240"
  },
  {
    "text": "at 20310 FT Denali in Alaska is the",
    "start": "639240",
    "end": "643120"
  },
  {
    "text": "tallest mountain in the United",
    "start": "643120",
    "end": "646040"
  },
  {
    "text": "States then we would calculate factual",
    "start": "646040",
    "end": "649360"
  },
  {
    "text": "similarity by comparing the ground truth",
    "start": "649360",
    "end": "651440"
  },
  {
    "text": "answer and the given answer we would",
    "start": "651440",
    "end": "654120"
  },
  {
    "text": "assess each statement in the answers as",
    "start": "654120",
    "end": "657560"
  },
  {
    "text": "a true positive false positive or false",
    "start": "657560",
    "end": "660399"
  },
  {
    "text": "negative and use that to calculate",
    "start": "660399",
    "end": "662760"
  },
  {
    "text": "Precision recall and F1",
    "start": "662760",
    "end": "665800"
  },
  {
    "text": "score in our example we have a true",
    "start": "665800",
    "end": "668760"
  },
  {
    "text": "positive statement the no is the tallest",
    "start": "668760",
    "end": "670920"
  },
  {
    "text": "mountain in the United States but we",
    "start": "670920",
    "end": "673079"
  },
  {
    "text": "also have two false negative statements",
    "start": "673079",
    "end": "675839"
  },
  {
    "text": "because only the ground truth answer",
    "start": "675839",
    "end": "677959"
  },
  {
    "text": "gives an altitude and a",
    "start": "677959",
    "end": "682320"
  },
  {
    "text": "state finally once we've calculated",
    "start": "682320",
    "end": "684720"
  },
  {
    "text": "semantic similarity and factual",
    "start": "684720",
    "end": "686600"
  },
  {
    "text": "similarity we return a weighted SC",
    "start": "686600",
    "end": "690519"
  },
  {
    "text": "score to read more about the ragus",
    "start": "690519",
    "end": "693160"
  },
  {
    "text": "implementation of any of the metrics we",
    "start": "693160",
    "end": "695279"
  },
  {
    "text": "have covered please refer to the",
    "start": "695279",
    "end": "697560"
  },
  {
    "text": "documentation listed",
    "start": "697560",
    "end": "701040"
  },
  {
    "text": "here in conclusion we have covered the",
    "start": "701560",
    "end": "704560"
  },
  {
    "text": "metrics needed to evaluate an llm system",
    "start": "704560",
    "end": "707519"
  },
  {
    "text": "end to end the generation metrics answer",
    "start": "707519",
    "end": "710760"
  },
  {
    "text": "relevance and faithfulness the retrieval",
    "start": "710760",
    "end": "712720"
  },
  {
    "text": "metrics contract precision and context",
    "start": "712720",
    "end": "715279"
  },
  {
    "text": "recall and the endtoend metric answer",
    "start": "715279",
    "end": "718000"
  },
  {
    "text": "correctness now I'm going to hand it",
    "start": "718000",
    "end": "720839"
  },
  {
    "text": "over to Felix to go over the Hands-On",
    "start": "720839",
    "end": "722959"
  },
  {
    "text": "implementation",
    "start": "722959",
    "end": "725959"
  }
]
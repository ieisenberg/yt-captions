[
  {
    "start": "0",
    "end": "37000"
  },
  {
    "text": "good evening everyone I'm Brian Barrett principal engineer in ec2 and today I'll",
    "start": "89",
    "end": "6509"
  },
  {
    "text": "be talking about scaling HPC applications in ec2 with elastic fabric",
    "start": "6509",
    "end": "11820"
  },
  {
    "text": "adapter which for the rest of the talk I'm just gonna shorten the EFA which is a new network device that we've built in",
    "start": "11820",
    "end": "19170"
  },
  {
    "text": "in AWS so a quick overview of the talk I'll start with what people are doing",
    "start": "19170",
    "end": "25500"
  },
  {
    "text": "with HPC and AWS today a little bit about what EFA is how to get started",
    "start": "25500",
    "end": "31410"
  },
  {
    "text": "using it and then we'll talk a little bit about how it actually works but",
    "start": "31410",
    "end": "37770"
  },
  {
    "start": "37000",
    "end": "37000"
  },
  {
    "text": "before we get started a couple of related talks the first is really a",
    "start": "37770",
    "end": "43500"
  },
  {
    "text": "state of Union talk on high performance computing in AWS that my boss in calais",
    "start": "43500",
    "end": "49140"
  },
  {
    "text": "who's the general manager for HP see an ec2 will be giving there's two versions",
    "start": "49140",
    "end": "55350"
  },
  {
    "text": "this is the first one is Wednesday tomorrow afternoon in Aria so hope you",
    "start": "55350",
    "end": "60570"
  },
  {
    "text": "guys all like walking and then there's a couple of breakout sessions these are just who I picked but if you search for",
    "start": "60570",
    "end": "66000"
  },
  {
    "text": "a wir sorry if you search for HPC in the session catalog you'll find a bunch of",
    "start": "66000",
    "end": "72060"
  },
  {
    "text": "great talks about work we're doing on HPC and AWS so getting started start",
    "start": "72060",
    "end": "79140"
  },
  {
    "text": "with what people are doing today so there's a variety of HPC applications",
    "start": "79140",
    "end": "85470"
  },
  {
    "start": "82000",
    "end": "82000"
  },
  {
    "text": "and for the purpose of this talk I'm going to define HPC a little loosely which is computation for the purpose of",
    "start": "85470",
    "end": "93180"
  },
  {
    "text": "learning something so scientific applications where you're trying to learn something about how say how the",
    "start": "93180",
    "end": "98520"
  },
  {
    "text": "weather works in this case this is the some some simulations we did using the",
    "start": "98520",
    "end": "104939"
  },
  {
    "text": "2.5 kilometer CONUS model and you can see some scaling results for C for one",
    "start": "104939",
    "end": "110820"
  },
  {
    "text": "of our previous instance types or for structural mechanics so understanding how jet engines work again some basic",
    "start": "110820",
    "end": "119219"
  },
  {
    "text": "scaling data or how to ride a bicycle in a pack and this is some work that track",
    "start": "119219",
    "end": "127469"
  },
  {
    "text": "and one of our partners rescale put together to understand how to best build a bike and",
    "start": "127469",
    "end": "133599"
  },
  {
    "text": "how to best right ride in a pack or fluid dynamics with some commercial",
    "start": "133599",
    "end": "139120"
  },
  {
    "text": "codes ances fluid in this case again on a previous instance type but simulating",
    "start": "139120",
    "end": "145000"
  },
  {
    "text": "fluid flow air flow over a race car and then finally my personal favorite",
    "start": "145000",
    "end": "152079"
  },
  {
    "text": "because I like airplanes there's a company a startup company in Denver in",
    "start": "152079",
    "end": "158500"
  },
  {
    "text": "Colorado called boom that as a name might suggest is trying to build a supersonic jet transport and the cool",
    "start": "158500",
    "end": "165790"
  },
  {
    "text": "thing about them is all their compute has been in AWS with rescale as a partner and so they they're able to",
    "start": "165790",
    "end": "173409"
  },
  {
    "text": "scale up and down their their compute needs as they go through the cycles of simulate build simulate build and",
    "start": "173409",
    "end": "181450"
  },
  {
    "text": "they're only paying for that HPC infrastructure one when they're actually in the simulate phase and then finally a",
    "start": "181450",
    "end": "188139"
  },
  {
    "start": "187000",
    "end": "187000"
  },
  {
    "text": "recent big simulation that was done in AWS was genomics processing an FPGA",
    "start": "188139",
    "end": "197340"
  },
  {
    "text": "simulating as it says fastest ever analysis of a thousand genomes using our",
    "start": "197340",
    "end": "205150"
  },
  {
    "text": "FPGA instance types so there's a variety of applications that we talk about when we say HPC they have a number of things",
    "start": "205150",
    "end": "212470"
  },
  {
    "text": "in common for the most part the examples that I listed here possibly with the exception of genomics are horizontally",
    "start": "212470",
    "end": "219579"
  },
  {
    "text": "scalable meaning you want to add more and more compute instances to reduce further the the runtime of the",
    "start": "219579",
    "end": "226150"
  },
  {
    "text": "application and and ideally when you add double the app the number of instances you have the runtime and so we start",
    "start": "226150",
    "end": "235000"
  },
  {
    "text": "with what is what is EFA that's why we're all here right so but before I get",
    "start": "235000",
    "end": "240970"
  },
  {
    "start": "240000",
    "end": "240000"
  },
  {
    "text": "there a quick introduction on how HPC is done in ec2 today so this slide if may",
    "start": "240970",
    "end": "248680"
  },
  {
    "text": "look familiar we've used it in a couple of places but this is kind of a notional diagram of what an ec2 instance and a",
    "start": "248680",
    "end": "255940"
  },
  {
    "text": "host look like so on the right you have hardware that's the actual physical hardware so",
    "start": "255940",
    "end": "261459"
  },
  {
    "text": "most of our instances not surprisingly have some memory they have a couple of Intel CPUs generally and then something",
    "start": "261459",
    "end": "268900"
  },
  {
    "text": "we call the nitro card which is the the system where we run all of our",
    "start": "268900",
    "end": "274349"
  },
  {
    "text": "hypervisor and this and then on there on the left side is the software which is",
    "start": "274349",
    "end": "282960"
  },
  {
    "text": "the the actual instance and so in this case we're talking about a c5 and 18x",
    "start": "282960",
    "end": "290560"
  },
  {
    "text": "large so you'd have some EBS exposed to nvme you'd have an ena adapter that",
    "start": "290560",
    "end": "296919"
  },
  {
    "text": "would be capable of driving a hundred gigabit per second over IP traffic you'd",
    "start": "296919",
    "end": "301960"
  },
  {
    "text": "have two processors and a hundred and ninety six gigabytes of memory and",
    "start": "301960",
    "end": "307240"
  },
  {
    "text": "there's a great talk from last year that you can find on YouTube from Anthony Liguori from AWS from reinvent last year",
    "start": "307240",
    "end": "315310"
  },
  {
    "text": "on c5 instance and the evolution of Amazon ec2 virtualization that goes into",
    "start": "315310",
    "end": "322630"
  },
  {
    "text": "all kinds of detail on how this diagram works so I'm going to assume that that",
    "start": "322630",
    "end": "327970"
  },
  {
    "text": "you guys all go watch the YouTube video and kind of skip over that because it's it's not important for the rest this",
    "start": "327970",
    "end": "333190"
  },
  {
    "text": "talk but the next part that's important is how these applications actually work so you start with an application let's",
    "start": "333190",
    "end": "341500"
  },
  {
    "text": "say an sis fluent the one that did cool car f1 car simulation underneath its",
    "start": "341500",
    "end": "346780"
  },
  {
    "text": "it's an MPI implementation and this is the networking library that HPC",
    "start": "346780",
    "end": "352599"
  },
  {
    "text": "customers tend to use it has send and receive primitives it has collectives it does all kinds of cool things if you're",
    "start": "352599",
    "end": "359020"
  },
  {
    "text": "a mathematician and then underneath that it's talking to the kernels tcp/ip stack",
    "start": "359020",
    "end": "365849"
  },
  {
    "text": "and then the that sack is talking to the ena network driver which eventually",
    "start": "365849",
    "end": "371259"
  },
  {
    "text": "talks to hardware so every message that you want to send ends up being and a",
    "start": "371259",
    "end": "376690"
  },
  {
    "text": "kernel trap and a bunch of TCP work and then finally the packet gets on the network and so we build a system you",
    "start": "376690",
    "end": "384099"
  },
  {
    "text": "know in our four node let's say our for instance cluster we might have an application on each instance and they",
    "start": "384099",
    "end": "391000"
  },
  {
    "text": "have kind of this shared wire and they can talk to each other and and everything just kind of works",
    "start": "391000",
    "end": "396290"
  },
  {
    "text": "and you end up with a performance graph that there's two graphs here we'll we'll",
    "start": "396290",
    "end": "402270"
  },
  {
    "text": "start on the left with the MPI latency and one of the things I wanted to call out is even before EFA every generation",
    "start": "402270",
    "end": "410790"
  },
  {
    "text": "of hardware that we've released we've been making incremental progress on latency so you can see this is MPI",
    "start": "410790",
    "end": "418980"
  },
  {
    "text": "latency measured with OSU latency a common MPI benchmark within a placement",
    "start": "418980",
    "end": "425730"
  },
  {
    "text": "group you know you guys can all launch two instances in placement group and you should get exactly these results and you",
    "start": "425730",
    "end": "432600"
  },
  {
    "text": "can see in every generation including from c5 to c5 n we've knocked off a little bit more latency and on the",
    "start": "432600",
    "end": "439500"
  },
  {
    "text": "bandwidth on the other side you can see C 3 and C 4 this too low lines were",
    "start": "439500",
    "end": "445100"
  },
  {
    "text": "limited by the fact that they were 10 gig instance types so you're driving about 10 gig this benchmark has a little",
    "start": "445100",
    "end": "451860"
  },
  {
    "text": "fuzzy so you can see the line goes a little above about 10 gig but it's it's an artifact to the benchmark and then we",
    "start": "451860",
    "end": "458490"
  },
  {
    "text": "released c5 which is 25 gig and you can see as you'd expect the lines two and a",
    "start": "458490",
    "end": "463740"
  },
  {
    "text": "half times fast higher and then you look at c5 n and again this is MPI benchmarks",
    "start": "463740",
    "end": "470310"
  },
  {
    "text": "and you see the line didn't go four times higher than c5 and the reason for",
    "start": "470310",
    "end": "476040"
  },
  {
    "text": "that is you can drive a hundred gigabit out of into and out of c5 and",
    "start": "476040",
    "end": "482180"
  },
  {
    "text": "simultaneously we've we've done it multiple times we have white papers on how to do it that we'll be making",
    "start": "482180",
    "end": "489090"
  },
  {
    "text": "available but for MPI it's really really challenging both because of artifacts of",
    "start": "489090",
    "end": "494880"
  },
  {
    "text": "the MPI implementation and all the optimizations that you have to do and",
    "start": "494880",
    "end": "499890"
  },
  {
    "text": "and most of NPI consumers are scientists they don't know much about networking that's not their area specialty what",
    "start": "499890",
    "end": "507030"
  },
  {
    "text": "they know is how to make do science and so they don't know this is the operating system tweak that I need to turn so that",
    "start": "507030",
    "end": "513570"
  },
  {
    "text": "can drive 100 gigabit and so where you end up is kind of this red line this is I just took stock out of the barrel you",
    "start": "513570",
    "end": "521099"
  },
  {
    "text": "know Amazon Linux to AMI and openmpi three one three and compiled the",
    "start": "521099",
    "end": "527640"
  },
  {
    "text": "you multiple multi bandwidth benchmark and these are the results I got but with",
    "start": "527640",
    "end": "534030"
  },
  {
    "start": "534000",
    "end": "534000"
  },
  {
    "text": "EFA we're gonna change the picture a little bit and now we're going to send",
    "start": "534030",
    "end": "539700"
  },
  {
    "text": "all that traffic all those messages instead of going through the Linux kernel and through the ena stack they're",
    "start": "539700",
    "end": "546600"
  },
  {
    "text": "gonna talk through this thing called Lib fabric that I'll talk about in a little bit but they're going to talk directly",
    "start": "546600",
    "end": "552360"
  },
  {
    "text": "to the EFA hardware and the whole kernel picture gets out of the way and kind of",
    "start": "552360",
    "end": "559200"
  },
  {
    "text": "that picture looks the same as before this picture looks the same as before to the application the pictures look",
    "start": "559200",
    "end": "565230"
  },
  {
    "text": "identical I typed MPI run I waited a couple of minutes and the application",
    "start": "565230",
    "end": "572130"
  },
  {
    "text": "started running right it's underneath the covers that we changed things and",
    "start": "572130",
    "end": "577230"
  },
  {
    "text": "the way we did that is we added another PCI device to our instance so we now have this this EFA instance or PCI",
    "start": "577230",
    "end": "585330"
  },
  {
    "text": "device this network device excuse me and it's still a c5n it's still the same",
    "start": "585330",
    "end": "593490"
  },
  {
    "text": "hardware as before it still has placement group support spot support",
    "start": "593490",
    "end": "599330"
  },
  {
    "text": "on-demand instant support our eyes fleet's EBS all the things that we know",
    "start": "599330",
    "end": "604980"
  },
  {
    "text": "and love but there's also this extra network device that lets us bypass the kernel for really fast community network",
    "start": "604980",
    "end": "611280"
  },
  {
    "text": "communication and this is same graph as before except we've added a couple of",
    "start": "611280",
    "end": "616650"
  },
  {
    "start": "612000",
    "end": "612000"
  },
  {
    "text": "lines for its bandwidth now you can see we're actually able to drive approximately a hundred gigabit it's",
    "start": "616650",
    "end": "624180"
  },
  {
    "text": "worth noting EFA is still in preview these are all early results the lines",
    "start": "624180",
    "end": "629610"
  },
  {
    "text": "will be higher before we go GA and likewise on the right is latency you can",
    "start": "629610",
    "end": "635550"
  },
  {
    "text": "see we've already taken a step out and this is still with a bunch of debugging on and so we're gonna be able to lower",
    "start": "635550",
    "end": "641040"
  },
  {
    "text": "this more before we release it GA and we'll talk about goals at the end of the",
    "start": "641040",
    "end": "648690"
  },
  {
    "text": "talk in terms of performance there but so the the bottom line is more bandwidth",
    "start": "648690",
    "end": "654810"
  },
  {
    "text": "easier to use lower latency and more consistent latency at that",
    "start": "654810",
    "end": "660370"
  },
  {
    "text": "so how do I use EFA right we've talked about how why it's great how do I",
    "start": "660370",
    "end": "666910"
  },
  {
    "text": "actually use it so you need a couple of",
    "start": "666910",
    "end": "671949"
  },
  {
    "start": "669000",
    "end": "669000"
  },
  {
    "text": "things first you need a supported platform and there's three instance",
    "start": "671949",
    "end": "677079"
  },
  {
    "text": "sizes that you can start with today see 518 X large c5n 18 X large sorry c5n 9x",
    "start": "677079",
    "end": "686319"
  },
  {
    "text": "large and p.3d n 24 x large we are going",
    "start": "686319",
    "end": "691660"
  },
  {
    "text": "to do network optimized versions of r5 and m5 sometime next year",
    "start": "691660",
    "end": "697660"
  },
  {
    "text": "and when we do release those you'll see EF a support on day of launch for those",
    "start": "697660",
    "end": "704100"
  },
  {
    "text": "and likewise we are going to continue to expand our metal offering and as we",
    "start": "704100",
    "end": "710980"
  },
  {
    "text": "expand the metal offering on the network optimize the N variants EF a will work",
    "start": "710980",
    "end": "716769"
  },
  {
    "text": "on day of launch for those so you need an instance and then you need a kernel",
    "start": "716769",
    "end": "722110"
  },
  {
    "text": "module and like I said we're in preview",
    "start": "722110",
    "end": "727179"
  },
  {
    "text": "right now there's a sign-up page we'll get to at the end during the preview you're gonna have to download it from",
    "start": "727179",
    "end": "732999"
  },
  {
    "text": "our github site and install the the kernel module when we go ga will have up streamed Amazon Linux and Amazon Linux 2",
    "start": "732999",
    "end": "740800"
  },
  {
    "text": "will just work out of the box we're working with canonical for a bun - SUSE",
    "start": "740800",
    "end": "746259"
  },
  {
    "text": "and and Red Hat for a net Red Hat Enterprise Linux to include EFA drivers",
    "start": "746259",
    "end": "752129"
  },
  {
    "text": "as part of the Ami's that are published in AWS it's a little bit of a race on on",
    "start": "752129",
    "end": "758470"
  },
  {
    "text": "whether we go GA first or they've ingested first but in the fullness of",
    "start": "758470",
    "end": "763870"
  },
  {
    "text": "time so sometime middle and next year they'll have all four all three of them",
    "start": "763870",
    "end": "769779"
  },
  {
    "text": "will also have the EFA bets just installed as part of the ami and you can always get the latest at our github site",
    "start": "769779",
    "end": "777149"
  },
  {
    "text": "github calm amazon amazon drivers where we have both the latest ena and EFA",
    "start": "777149",
    "end": "783129"
  },
  {
    "text": "drivers and then you need this lib fabric stack we'll talk a little bit about what that is in a minute",
    "start": "783129",
    "end": "788970"
  },
  {
    "text": "for the first half of 2018 it'll be a AWS custom",
    "start": "788970",
    "end": "794220"
  },
  {
    "text": "version and then when lib fabric releases it looks like 1.8 will be the",
    "start": "794220",
    "end": "800460"
  },
  {
    "text": "merge point sometime in the first half of 2019 lib fabric 1.8 will just include",
    "start": "800460",
    "end": "808740"
  },
  {
    "text": "EFA out of the box and so you can grab the lib fabric and and will include it",
    "start": "808740",
    "end": "814200"
  },
  {
    "text": "in amazon linux and amazon linux too and then lastly you need the part that you as an application user actually use",
    "start": "814200",
    "end": "820680"
  },
  {
    "text": "which is an MPI implementation or if you're doing machine learning Nichol and",
    "start": "820680",
    "end": "826530"
  },
  {
    "text": "videos nickel which is their machine learning library for distributed machine",
    "start": "826530",
    "end": "833790"
  },
  {
    "text": "learning using the Nvidia cards so initially we're gonna support openmpi",
    "start": "833790",
    "end": "838830"
  },
  {
    "text": "3.1.3 or later or nickel two point three",
    "start": "838830",
    "end": "844650"
  },
  {
    "text": "point eight or later so openmpi doesn't need anything else you can just grab",
    "start": "844650",
    "end": "849960"
  },
  {
    "text": "oaken MPI 3.1.3 build with the lib fabric driver and it'll all just work",
    "start": "849960",
    "end": "855840"
  },
  {
    "text": "with nickel you'll also need to grab an EF a driver which we've actually open",
    "start": "855840",
    "end": "863190"
  },
  {
    "text": "sourced yesterday so that you can use nickel over Lib fabric over EF a we are",
    "start": "863190",
    "end": "871050"
  },
  {
    "text": "working with both Intel and argon to add EF a through Lib fabric EF a support to",
    "start": "871050",
    "end": "879330"
  },
  {
    "text": "both Intel MPI and to MPI CH and details for all of this because no one's gonna",
    "start": "879330",
    "end": "886470"
  },
  {
    "text": "remember all these instructions will all be up on aws.amazon.com slash HP c",
    "start": "886470",
    "end": "893030"
  },
  {
    "text": "including like detail to get how to and any scripts we have to make this easier",
    "start": "893030",
    "end": "898170"
  },
  {
    "text": "as we go there are a couple constraints for EF a it's a special purpose device",
    "start": "898170",
    "end": "903930"
  },
  {
    "start": "899000",
    "end": "899000"
  },
  {
    "text": "right it's meant to make HPC applications go fast and so there's a couple of places where made some",
    "start": "903930",
    "end": "909720"
  },
  {
    "text": "trade-offs between the go-fast button and full-featured like you might expect",
    "start": "909720",
    "end": "915000"
  },
  {
    "text": "if you've been using ena the first one is EF a communication is",
    "start": "915000",
    "end": "920550"
  },
  {
    "text": "subnet local so if you have two instances in different subnets they can",
    "start": "920550",
    "end": "926490"
  },
  {
    "text": "both have the FA devices but they can't talk to each other if you have clusters that are",
    "start": "926490",
    "end": "933010"
  },
  {
    "text": "multi AZ you know all the all the instances in subnet one and AZ one can",
    "start": "933010",
    "end": "939520"
  },
  {
    "text": "talk to each other and all the instances in subnet two in AZ 2 2 can talk to each other but you can't cross the the subnet",
    "start": "939520",
    "end": "946660"
  },
  {
    "text": "boundaries so you can't cross the AZ boundary this may change in the fullness of time as we support more and more use",
    "start": "946660",
    "end": "953200"
  },
  {
    "text": "cases but initially when we're looking at those really tightly coupled workloads you know there's not a huge",
    "start": "953200",
    "end": "960310"
  },
  {
    "text": "demand for cross AZ for Freight for MPI applications the second is you have to",
    "start": "960310",
    "end": "968589"
  },
  {
    "text": "have both and allow all traffic within security group ingress and egress rule",
    "start": "968589",
    "end": "974230"
  },
  {
    "text": "so all security group rules for EFA are stateless and they can only refer to",
    "start": "974230",
    "end": "980290"
  },
  {
    "text": "other two security groups with their rule type so you know you allow all",
    "start": "980290",
    "end": "986140"
  },
  {
    "text": "traffic you can't just say 0/0 you actually have to give us something a security group ID and again that that",
    "start": "986140",
    "end": "993940"
  },
  {
    "text": "mostly has to do with that kind of performance flexibility trade-off it allowed us to optimize a little bit",
    "start": "993940",
    "end": "1000870"
  },
  {
    "text": "faster for the firewall you know keep in mind most HP's HPC systems don't have a",
    "start": "1000870",
    "end": "1007350"
  },
  {
    "text": "firewall inside of them and so again this is a use case that seemed to make sense the second or the third point is",
    "start": "1007350",
    "end": "1015330"
  },
  {
    "text": "at launch you're limited to one EF Ani per instance so you can have as many as",
    "start": "1015330",
    "end": "1022920"
  },
  {
    "text": "you want in your account but every instance can only have one and finally EF a n eyes can only be",
    "start": "1022920",
    "end": "1031920"
  },
  {
    "text": "added at instance launched or to a stopped instance so what we call cold or",
    "start": "1031920",
    "end": "1038850"
  },
  {
    "text": "warm attached you can't hot attach that is you can't add Annie and I to a running instance",
    "start": "1038850",
    "end": "1044250"
  },
  {
    "text": "you can always stop that instance add the EF AE and I and and and restart the",
    "start": "1044250",
    "end": "1049470"
  },
  {
    "text": "instance again for most HPC clusters particularly the way people are building them in the cloud where instances are",
    "start": "1049470",
    "end": "1056429"
  },
  {
    "text": "kind of mapped to single jobs this ends up not being a big impact but allows us to do some",
    "start": "1056429",
    "end": "1063060"
  },
  {
    "text": "optimizations behind the covers so let's",
    "start": "1063060",
    "end": "1069210"
  },
  {
    "start": "1066000",
    "end": "1066000"
  },
  {
    "text": "start with how do I build an IFA enabled cluster let's build a four node cluster so anyone who's used the EC to run",
    "start": "1069210",
    "end": "1078450"
  },
  {
    "text": "instances command this probably looks fairly familiar because other than you probably haven't launched c5n because we",
    "start": "1078450",
    "end": "1085560"
  },
  {
    "text": "launched it yesterday everything on here basically looks like how you how you'd",
    "start": "1085560",
    "end": "1091170"
  },
  {
    "text": "launch today you specify account we're gonna launch for a region we're gonna launch in Northern Virginia a image ID",
    "start": "1091170",
    "end": "1099420"
  },
  {
    "text": "obviously that one's made up an instance type placement group and then the",
    "start": "1099420",
    "end": "1104790"
  },
  {
    "text": "network interface most that should look familiar because it's all the same as has always been except for that last",
    "start": "1104790",
    "end": "1111090"
  },
  {
    "text": "little bit where it says interface type EF a and that is the extent of the magic",
    "start": "1111090",
    "end": "1116540"
  },
  {
    "text": "you put that little command in again don't try it today it won't work but",
    "start": "1116540",
    "end": "1122310"
  },
  {
    "text": "when we have general availability you add that and if you're the instance type",
    "start": "1122310",
    "end": "1127740"
  },
  {
    "text": "you specified is one that supports EF a you will get a you you will get an EF AE",
    "start": "1127740",
    "end": "1135510"
  },
  {
    "text": "and I when when the instance launches and I did call out you probably want to specify a security group unless your",
    "start": "1135510",
    "end": "1142530"
  },
  {
    "text": "default one hasn't allow all rule so you're probably going to have a security group for your cluster and well that's",
    "start": "1142530",
    "end": "1148500"
  },
  {
    "text": "launching because we would have gotten some JSON and then waited to ssh n12 quick Tim diagram of what we're building",
    "start": "1148500",
    "end": "1155370"
  },
  {
    "text": "right we have an AZ of course inside of that is a subnet we have our four c5",
    "start": "1155370",
    "end": "1162510"
  },
  {
    "text": "instances and each one of them will have an EF a II and I and that's the new EF",
    "start": "1162510",
    "end": "1168240"
  },
  {
    "text": "AE and I logo for you know the building HPC are building AWS infrastructure",
    "start": "1168240",
    "end": "1174900"
  },
  {
    "text": "diagrams so we've waited long enough and the machine is probably up now so we'll",
    "start": "1174900",
    "end": "1180210"
  },
  {
    "text": "ssh into it and the first thing we do because we're all HPC geeks is we'll run",
    "start": "1180210",
    "end": "1186390"
  },
  {
    "text": "LS PCI and we see the normal stuff that you'd see right a host bridge nice a",
    "start": "1186390",
    "end": "1192750"
  },
  {
    "text": "bridge a vga device an nvme controller because",
    "start": "1192750",
    "end": "1197890"
  },
  {
    "text": "that's our EBS root volume the the ena controller and then this other device",
    "start": "1197890",
    "end": "1203230"
  },
  {
    "text": "that's new we haven't seen before this EF a zero device and that's the magic",
    "start": "1203230",
    "end": "1209620"
  },
  {
    "text": "that's the the new EF a device and a",
    "start": "1209620",
    "end": "1215380"
  },
  {
    "text": "couple of things that are worth calling out here first this really is that easy",
    "start": "1215380",
    "end": "1220450"
  },
  {
    "text": "that's all that's going to be necessary to start any if a instance to placement",
    "start": "1220450",
    "end": "1225940"
  },
  {
    "text": "groups are still a good thing even with EF a you can launch outside of a placement group you just might get",
    "start": "1225940",
    "end": "1231670"
  },
  {
    "text": "larger Layton sees than if you launched with a placement group as long as they're in the same subnet EF a will be",
    "start": "1231670",
    "end": "1238810"
  },
  {
    "text": "able to work whether you're in a placement group or not and then finally like said there's two e to PCI devices",
    "start": "1238810",
    "end": "1245980"
  },
  {
    "text": "attack that are associated with your en I that we created the en a one that",
    "start": "1245980",
    "end": "1251080"
  },
  {
    "text": "speaks IP and the EF a one that speaks the OS bypass traffic the nice thing",
    "start": "1251080",
    "end": "1257080"
  },
  {
    "text": "about this is if you have an ami that works today with C 5 or c 5n that ami",
    "start": "1257080",
    "end": "1263440"
  },
  {
    "text": "will work even with EF a and you'll be able to log in IP will work you don't",
    "start": "1263440",
    "end": "1270040"
  },
  {
    "text": "have to do any of the IP over IB things that you might have to do with InfiniBand there's no need for for any",
    "start": "1270040",
    "end": "1276100"
  },
  {
    "text": "of the emulated stacks and then you can install the EF a driver to enable the OS bypass traffic so I talked about a",
    "start": "1276100",
    "end": "1284440"
  },
  {
    "start": "1283000",
    "end": "1283000"
  },
  {
    "text": "little bit about we need a kernel driver so the next thing we do is as HPC geeks",
    "start": "1284440",
    "end": "1289870"
  },
  {
    "text": "is we run LS mod and we see okay I've got an EF a device and it brought in this IB core thing I thought we a double",
    "start": "1289870",
    "end": "1297040"
  },
  {
    "text": "us didn't do InfiniBand and why is this ib core thing loaded so it turns out Mellanox was the who makes InfiniBand",
    "start": "1297040",
    "end": "1305110"
  },
  {
    "text": "cards was the one who did all the work to upstream an OS bypass network stack",
    "start": "1305110",
    "end": "1310450"
  },
  {
    "text": "into the Linux kernel and in in marketing genius they called it the",
    "start": "1310450",
    "end": "1316810"
  },
  {
    "text": "InfiniBand interface rather than saying our DMA interface and so the the core",
    "start": "1316810",
    "end": "1322480"
  },
  {
    "text": "library that everyone uses is still called IB core and the access for user space is still",
    "start": "1322480",
    "end": "1328159"
  },
  {
    "text": "called IBU verbs so we use both of those any F a and then you know we see we have",
    "start": "1328159",
    "end": "1335509"
  },
  {
    "text": "a kernel module that's up and running and then this next command is probably new for everybody fi info which is the lib fabric command",
    "start": "1335509",
    "end": "1344089"
  },
  {
    "text": "to make sure lib fabric is all wired up properly and we're looking for providers",
    "start": "1344089",
    "end": "1349579"
  },
  {
    "text": "which is their driver name their name for a driver we're looking for the EFA",
    "start": "1349579",
    "end": "1355579"
  },
  {
    "text": "provider and it spits out three things that we'll talk about in a follow-on slide and then finally the most",
    "start": "1355579",
    "end": "1363079"
  },
  {
    "text": "important part let's make sure MPI works so I'm a big fan of open MPI probably",
    "start": "1363079",
    "end": "1370189"
  },
  {
    "text": "because I've been working on it for 15 years now it has this nice command MP info that tells you all the drivers that",
    "start": "1370189",
    "end": "1376249"
  },
  {
    "text": "it has and the one we're looking for is o fi which is the Lib fabric driver and",
    "start": "1376249",
    "end": "1382249"
  },
  {
    "text": "we see that it's installed and then we're gonna run a hello world PR a ring program just to make sure everything's",
    "start": "1382249",
    "end": "1388459"
  },
  {
    "text": "wired up and sure enough we were able to pass messages in a ring ten times and",
    "start": "1388459",
    "end": "1396049"
  },
  {
    "text": "the whole thing worked so the next question we usually get is that's great",
    "start": "1396049",
    "end": "1403159"
  },
  {
    "text": "run instances is awesome but how do i integrate this with my higher-level",
    "start": "1403159",
    "end": "1408879"
  },
  {
    "text": "building blocks right I've got this you know application framework to build",
    "start": "1408879",
    "end": "1414679"
  },
  {
    "text": "my clusters how do i integrate with it and the answer is going to be a little tedious but because you're gonna hear",
    "start": "1414679",
    "end": "1422209"
  },
  {
    "text": "the same thing four times here whether you're using cloud formation or auto-scaling groups or spot or spot",
    "start": "1422209",
    "end": "1428869"
  },
  {
    "text": "fleet or fleet in general or AWS batch the answer is the same you start with a",
    "start": "1428869",
    "end": "1434209"
  },
  {
    "text": "launch template who here knows what launch templates are okay a couple of",
    "start": "1434209",
    "end": "1441319"
  },
  {
    "text": "people more than I expected but so launch templates are something we now we really / - here and the idea is that you",
    "start": "1441319",
    "end": "1451069"
  },
  {
    "text": "can specify a launch configuration and then use that across a whole bunch of places like say cloud formation auto",
    "start": "1451069",
    "end": "1458509"
  },
  {
    "text": "scaling groups and and AWS patch for example so the",
    "start": "1458509",
    "end": "1464210"
  },
  {
    "text": "answer to how to use all these things is to build a launch template that enables EFA and then pass that launch template",
    "start": "1464210",
    "end": "1472240"
  },
  {
    "text": "and for the launch template it's actually really simple just like run interfaces you add this interface type",
    "start": "1472240",
    "end": "1479450"
  },
  {
    "text": "EFA and you're off and running and so if we look at a quick example that I could",
    "start": "1479450",
    "end": "1486170"
  },
  {
    "start": "1483000",
    "end": "1483000"
  },
  {
    "text": "have used instead of all the run instances parameters earlier here's a quick example of how to build a launch",
    "start": "1486170",
    "end": "1492950"
  },
  {
    "text": "template to launch with EFA so again I have my network interface section where I say I don't need a public IP address",
    "start": "1492950",
    "end": "1499190"
  },
  {
    "text": "because I'm building an internal cluster I want it to be device 0 because it's",
    "start": "1499190",
    "end": "1504890"
  },
  {
    "text": "gonna be the only device in the instance I want it associated with a particular subnet and I want it to be EFA I want it",
    "start": "1504890",
    "end": "1512690"
  },
  {
    "text": "in a placement group usual Ami's and I want it to be a c5 and 18x large and",
    "start": "1512690",
    "end": "1518809"
  },
  {
    "text": "then a slightly unrelated diversion into launch templates and other cool things",
    "start": "1518809",
    "end": "1524990"
  },
  {
    "text": "you can do with ec2 for HPC one of the common questions we hear from HPC people",
    "start": "1524990",
    "end": "1532340"
  },
  {
    "text": "is well I don't like hyper threads how do I turn them off and for years our",
    "start": "1532340",
    "end": "1537800"
  },
  {
    "text": "answer has been to run a scripted boot that that essentially hot unplugs the",
    "start": "1537800",
    "end": "1545720"
  },
  {
    "text": "the second hyper thread on every core and that works great if you remember to",
    "start": "1545720",
    "end": "1550760"
  },
  {
    "text": "run that script at boot the other way that you can do it with some fear with a feature called CPU options that we",
    "start": "1550760",
    "end": "1557510"
  },
  {
    "text": "released this year is you can actually say I want your instance to have this",
    "start": "1557510",
    "end": "1562850"
  },
  {
    "text": "many cores and to have this many hyper threads per core now this was a feature",
    "start": "1562850",
    "end": "1568580"
  },
  {
    "text": "really developed to help licensing where you might have a license for 20 cores",
    "start": "1568580",
    "end": "1574360"
  },
  {
    "text": "but we only offer a 24 core instance you know we offer 12 or 24 neither of which",
    "start": "1574360",
    "end": "1580340"
  },
  {
    "text": "are xx and this allows you to say only put 20 cores in the instance but it also",
    "start": "1580340",
    "end": "1586640"
  },
  {
    "text": "allows you to say I want so many hyper threads per core and so as you can see I",
    "start": "1586640",
    "end": "1592790"
  },
  {
    "text": "said I want thirty-six cores but I only want one thread per core and and this will this",
    "start": "1592790",
    "end": "1599120"
  },
  {
    "text": "is another way that you can turn off hyper threads without having to remember to run a boot time script so now for the",
    "start": "1599120",
    "end": "1607130"
  },
  {
    "text": "part that people are probably actually interested in which is how does EFA",
    "start": "1607130",
    "end": "1613549"
  },
  {
    "text": "actually work so we started with a",
    "start": "1613549",
    "end": "1618700"
  },
  {
    "start": "1616000",
    "end": "1616000"
  },
  {
    "text": "diagram kind of this is how HPC applications and in kind of HPC",
    "start": "1618700",
    "end": "1625010"
  },
  {
    "text": "libraries are designed today so I have an application it sits on top of either an MPI implementation or for machine",
    "start": "1625010",
    "end": "1632480"
  },
  {
    "text": "learning Nicoll and some people really like openmpi yay some really like Intel MPI",
    "start": "1632480",
    "end": "1641260"
  },
  {
    "text": "some like Nvidia and nickel and if I'm a hardware vendor and I want to support a",
    "start": "1641260",
    "end": "1647240"
  },
  {
    "text": "new network interface I first go talk to the openmpi guys and try and convince",
    "start": "1647240",
    "end": "1652760"
  },
  {
    "text": "them that they should take my take support for my network adapter then I talked to Intel MPI and then I talked to",
    "start": "1652760",
    "end": "1659510"
  },
  {
    "text": "Nvidia and somewhere two years after I've launched everyone has support for",
    "start": "1659510",
    "end": "1665390"
  },
  {
    "text": "my network driver and if I'm an open it if I'm an open MPI developer I have a",
    "start": "1665390",
    "end": "1670820"
  },
  {
    "text": "similar problem right every time someone launches a new network device I've got to go write a driver for it and I",
    "start": "1670820",
    "end": "1677960"
  },
  {
    "text": "probably don't know how that Hardware works really well but I know how my MPI implementation works really well and so",
    "start": "1677960",
    "end": "1683929"
  },
  {
    "text": "you end up with a lot of duplicate effort across a wide variety wide part",
    "start": "1683929",
    "end": "1688970"
  },
  {
    "text": "of the commercial space and so what Lib fabric seeks to do is to kind of put an",
    "start": "1688970",
    "end": "1696860"
  },
  {
    "start": "1692000",
    "end": "1692000"
  },
  {
    "text": "interposer library in here we're live fabric exposes high-level constructs",
    "start": "1696860",
    "end": "1702200"
  },
  {
    "text": "that are exactly what MPI or Nikhil wants to run really really well and all",
    "start": "1702200",
    "end": "1710270"
  },
  {
    "text": "you have to do if you're a hardware provider is say okay I have to run right this one provider and I have to make it",
    "start": "1710270",
    "end": "1717140"
  },
  {
    "text": "work really really well and I understand how my hardware works so I can do that and if I'm an MPI implementer I have a",
    "start": "1717140",
    "end": "1723590"
  },
  {
    "text": "nice interface that very nicely matches what I wanted it has tagged matching in it it has all",
    "start": "1723590",
    "end": "1729379"
  },
  {
    "text": "the ordering semantics MPI has and so I have a fairly nice interface to write to",
    "start": "1729379",
    "end": "1734600"
  },
  {
    "text": "if I'm an MPI implementer I have a fairly nice interface to write to if I'm",
    "start": "1734600",
    "end": "1739669"
  },
  {
    "text": "a network provider and so the to meet in the middle and and you end up with an application stack in months instead of",
    "start": "1739669",
    "end": "1747529"
  },
  {
    "text": "years and so that that's great for the consumer or the customer largely because",
    "start": "1747529",
    "end": "1754519"
  },
  {
    "text": "you end up with support for your MPI implementation much sooner and if I ask",
    "start": "1754519",
    "end": "1761360"
  },
  {
    "text": "this room I'm sure I'd get at least six answers as to what their favorite MPI was and so this is just kind of a",
    "start": "1761360",
    "end": "1768320"
  },
  {
    "text": "diagram of what lib fabric looks internally it's really not important for most people just know there's a bunch of",
    "start": "1768320",
    "end": "1774259"
  },
  {
    "text": "layers and a bunch of abstractions that you can implement and then the big takeaway is lib fabric has support from",
    "start": "1774259",
    "end": "1781970"
  },
  {
    "text": "a wide variety of vendors including Cray Intel Cisco and now AWS and so it's it's",
    "start": "1781970",
    "end": "1790600"
  },
  {
    "text": "gaining market share and gaining you know has a stable platform of vendors",
    "start": "1790600",
    "end": "1796369"
  },
  {
    "text": "who are interested in continuing to make it work so jumping back to a slide to",
    "start": "1796369",
    "end": "1802999"
  },
  {
    "text": "some data I showed earlier about EFA so lib fabric has this concept of endpoints",
    "start": "1802999",
    "end": "1810320"
  },
  {
    "text": "and endpoints are communication types so just like you have TCP and UDP you can",
    "start": "1810320",
    "end": "1817309"
  },
  {
    "text": "have different communication types with lib fabrics so you can have reliable",
    "start": "1817309",
    "end": "1822379"
  },
  {
    "text": "data grams RDM you can have unreliable data grams d gram and you can have also",
    "start": "1822379",
    "end": "1829399"
  },
  {
    "text": "have a stream semantics and a message in an ordered message semantics so EFA",
    "start": "1829399",
    "end": "1837019"
  },
  {
    "text": "natively provides two types of communication a reliable Datagram and an",
    "start": "1837019",
    "end": "1842720"
  },
  {
    "text": "unreliable Datagram so those are the two top providers you see we also have a",
    "start": "1842720",
    "end": "1848950"
  },
  {
    "text": "what's called a utility provider which is a set of code that provides a higher",
    "start": "1848950",
    "end": "1854869"
  },
  {
    "text": "level abstraction that I'll talk about in the next slide that we built called rxr",
    "start": "1854869",
    "end": "1860210"
  },
  {
    "text": "to optimize our particular path through live fabric the other things that are",
    "start": "1860210",
    "end": "1865910"
  },
  {
    "text": "interesting to call out here first the addressing is based on your MAC address so it's the ipv6 encoded MAC address the",
    "start": "1865910",
    "end": "1876260"
  },
  {
    "text": "second that's probably most interesting to people is you'll notice our protocols are that we list free if a are a custom",
    "start": "1876260",
    "end": "1883610"
  },
  {
    "text": "protocol to us that we're calling in in Lib fabric we call FI proto EFA which",
    "start": "1883610",
    "end": "1891130"
  },
  {
    "text": "just means that it's a custom protocol internal to ec2 so our native modes are",
    "start": "1891130",
    "end": "1898700"
  },
  {
    "start": "1897000",
    "end": "1897000"
  },
  {
    "text": "reliable datagrams they are unordered you have Animax message size of 8",
    "start": "1898700",
    "end": "1904610"
  },
  {
    "text": "kilobytes I'll get to why this isn't a problem in a second it's a send/receive interface with no",
    "start": "1904610",
    "end": "1910400"
  },
  {
    "text": "tag matching so it's a very simple I send a pack May a message and I'm guaranteed to get that message not",
    "start": "1910400",
    "end": "1916940"
  },
  {
    "text": "necessarily in the order I sent it and it natively multipaths so there's no as",
    "start": "1916940",
    "end": "1923840"
  },
  {
    "text": "some of you might know ec2 has a flow limiter the biggest any tcp can a flow",
    "start": "1923840",
    "end": "1930080"
  },
  {
    "text": "can be in the ec2 network is 10 gigabit are the artyom channel bypasses that",
    "start": "1930080",
    "end": "1936260"
  },
  {
    "text": "limiter because it's natively spring traffic across our network and able to use it very efficiently we also have",
    "start": "1936260",
    "end": "1944360"
  },
  {
    "text": "Addie Graham provider which is unreliable and unordered so I won't guarantee it gets to you and I won't",
    "start": "1944360",
    "end": "1950990"
  },
  {
    "text": "guarantee it gets to you in the order I sent it you sent it again has 8 kilobyte",
    "start": "1950990",
    "end": "1956690"
  },
  {
    "text": "message size and send receive only interface it however is subject to that",
    "start": "1956690",
    "end": "1963230"
  },
  {
    "text": "same flow limiter that you see with tcp/ip and UDP IP / ena and then the",
    "start": "1963230",
    "end": "1970910"
  },
  {
    "start": "1970000",
    "end": "1970000"
  },
  {
    "text": "endpoint type that almost everyone this room is going to use is our XR which is",
    "start": "1970910",
    "end": "1976130"
  },
  {
    "text": "a utility stack that we built to to support EFA it's a support MPI and",
    "start": "1976130",
    "end": "1982340"
  },
  {
    "text": "nickel over EFA applications so it has ordering it has tag messaging so it does",
    "start": "1982340",
    "end": "1989540"
  },
  {
    "text": "all the MPI things to make it nice and fast it's max message size is - to this 64 - one I greater than system",
    "start": "1989540",
    "end": "1999080"
  },
  {
    "text": "memory size it supports large I of X it was developed by AWS as part of IFA in",
    "start": "1999080",
    "end": "2007810"
  },
  {
    "text": "the next week or two you'll see it up streamed posted publicly both on our",
    "start": "2007810",
    "end": "2015220"
  },
  {
    "text": "github site as well as starting the upstream process into the community Lib",
    "start": "2015220",
    "end": "2022570"
  },
  {
    "text": "fabric site and this is currently implemented mainly to support MPI",
    "start": "2022570",
    "end": "2028840"
  },
  {
    "text": "applications and nickel in the coming years you'll see us add support for RMA",
    "start": "2028840",
    "end": "2035080"
  },
  {
    "text": "and Atomics and kind of the rest of the interface that that's a little bit more esoteric for most of our customers the",
    "start": "2035080",
    "end": "2044350"
  },
  {
    "start": "2043000",
    "end": "2043000"
  },
  {
    "text": "really cool thing in EFA well there's two really cool things in EFA the first is 100 gigabit but you've probably all",
    "start": "2044350",
    "end": "2052179"
  },
  {
    "text": "heard peter talk about that and there's not much to say other than it's a hundred gigabit right",
    "start": "2052180",
    "end": "2057879"
  },
  {
    "text": "the other cool thing we have is the a new reliability protocol that we built",
    "start": "2057880",
    "end": "2063669"
  },
  {
    "text": "in AWS especially for AWS is unique data",
    "start": "2063670",
    "end": "2069010"
  },
  {
    "text": "center network that that works differently than than most data center networks so the reliability protocol",
    "start": "2069010",
    "end": "2076690"
  },
  {
    "text": "gives us a couple of things it gives us Network aware multipath routing so we're",
    "start": "2076690",
    "end": "2082480"
  },
  {
    "text": "always sending packets across multiple paths in the network so that we can respond very quickly when there's",
    "start": "2082480",
    "end": "2089590"
  },
  {
    "text": "Network events on a particular path we can very quickly route around that as a",
    "start": "2089590",
    "end": "2095379"
  },
  {
    "text": "matter of fact that's not an abnormal thing that's happening all the time that's how we know that code path works is we're always taking multiple paths",
    "start": "2095380",
    "end": "2103090"
  },
  {
    "text": "and so there's no like suddenly we discovered it didn't work problem it's guaranteed delivery the packet will get",
    "start": "2103090",
    "end": "2109780"
  },
  {
    "text": "there it might not get there in the order you sent it but it will get there and the reason that it isn't ordered is",
    "start": "2109780",
    "end": "2117070"
  },
  {
    "text": "when you really look it's if you look at open if you look at what MPI wants or",
    "start": "2117070",
    "end": "2123340"
  },
  {
    "text": "what Nichol wants they have an ordering semantics but it's not I need every packet in exactly the same order",
    "start": "2123340",
    "end": "2129410"
  },
  {
    "text": "that you sent it NPI has a very complex very rich ordering semantics that",
    "start": "2129410",
    "end": "2135500"
  },
  {
    "text": "doesn't require every packet arrived in order and nickel really just has no ordering requirements at all other than",
    "start": "2135500",
    "end": "2142900"
  },
  {
    "text": "you have to have the data delivered before you deliver a completion and so in both cases having strict packet",
    "start": "2142900",
    "end": "2149000"
  },
  {
    "text": "ordering is the wrong thing to do it imposes overhead for no gain and in",
    "start": "2149000",
    "end": "2154310"
  },
  {
    "text": "those couple of times where you do need strict ordering it turns out Intel spends billions of dollars every year to",
    "start": "2154310",
    "end": "2161270"
  },
  {
    "text": "make lick lists walking and and reordering really really fast and so",
    "start": "2161270",
    "end": "2167240"
  },
  {
    "text": "it's better just to do it in the Intel processor but we do the reliability in",
    "start": "2167240",
    "end": "2172730"
  },
  {
    "text": "our nitro card in in that offload car or in that daughter card that runs the",
    "start": "2172730",
    "end": "2178460"
  },
  {
    "text": "nitro hypervisor for a couple of reasons and the first is we wanted to drive down",
    "start": "2178460",
    "end": "2183740"
  },
  {
    "text": "tail latency and it turns out that tail latency or a dropped packet and having",
    "start": "2183740",
    "end": "2189800"
  },
  {
    "text": "to wait for the retransmit timer is driven largely by how consistently you",
    "start": "2189800",
    "end": "2195830"
  },
  {
    "text": "can depend on the remote side servicing your requests telling you that the packet got dropped or got that it",
    "start": "2195830",
    "end": "2203510"
  },
  {
    "text": "arrived how and so with a normal TCP",
    "start": "2203510",
    "end": "2209600"
  },
  {
    "text": "stack every time that to send an ACK the kernel has to wake up which means an",
    "start": "2209600",
    "end": "2215840"
  },
  {
    "text": "interrupt if you're doing interrupts coalescing you might to get better bandwidth you might have to wait for",
    "start": "2215840",
    "end": "2221840"
  },
  {
    "text": "many packets before the the card decides to wake the NIC up the NIC you know the",
    "start": "2221840",
    "end": "2228080"
  },
  {
    "text": "first thing the kernel does is it goes and looks as there are any really high priority tasks that I have to do some of",
    "start": "2228080",
    "end": "2233840"
  },
  {
    "text": "which can take multiple milliseconds and so where you end up is really practically speaking the fastest you can",
    "start": "2233840",
    "end": "2240980"
  },
  {
    "text": "run a retransmit timer with TCP and in a large network is about 50 milliseconds",
    "start": "2240980",
    "end": "2246590"
  },
  {
    "text": "and that's really pushing it in a lot of cases we can run orders of magnitude",
    "start": "2246590",
    "end": "2251780"
  },
  {
    "text": "faster than that because it's a polling mode device that doesn't have a general-purpose you know Linux OS",
    "start": "2251780",
    "end": "2257990"
  },
  {
    "text": "running customer codes it's you know we're not waiting for MPI to you know for the application to enter",
    "start": "2257990",
    "end": "2264910"
  },
  {
    "text": "the next MPI call we can very rapidly send that act and we can very rapidly",
    "start": "2264910",
    "end": "2270790"
  },
  {
    "text": "retransmit and so we go from you know best-case best cased 50 milliseconds to",
    "start": "2270790",
    "end": "2278070"
  },
  {
    "text": "you know hundreds of microseconds in in that tail latency so orders of magnitude",
    "start": "2278070",
    "end": "2283420"
  },
  {
    "text": "reduction like I said this is implemented as part of our third-generation nitro chip that's the",
    "start": "2283420",
    "end": "2290290"
  },
  {
    "text": "one that has the hundred gigabit capabilities and so we're able to use",
    "start": "2290290",
    "end": "2295330"
  },
  {
    "text": "this both for some internal services to get you better performance but also",
    "start": "2295330",
    "end": "2300580"
  },
  {
    "text": "expose the customers through through AFA and through that our DM channel in DFA",
    "start": "2300580",
    "end": "2306660"
  },
  {
    "text": "so when you ask for a reliable Datagram service from AFA what you're getting is",
    "start": "2306660",
    "end": "2314530"
  },
  {
    "text": "is this SR D and one cool place where this is really beneficial to the users",
    "start": "2314530",
    "end": "2320950"
  },
  {
    "start": "2318000",
    "end": "2318000"
  },
  {
    "text": "is what happens when a link fails right in in our network just like any other",
    "start": "2320950",
    "end": "2327640"
  },
  {
    "text": "network you know sometimes a data tech unplug the cable or you know an optical",
    "start": "2327640",
    "end": "2332860"
  },
  {
    "text": "transceiver fails or switch reboots and we're driving 20 gigabits in in this",
    "start": "2332860",
    "end": "2339220"
  },
  {
    "text": "simulation and we we unplug the network card our sorry a switch in between that",
    "start": "2339220",
    "end": "2345220"
  },
  {
    "text": "the link is that the packets are going across and and basically you wait until",
    "start": "2345220",
    "end": "2352660"
  },
  {
    "text": "we reconverge on a new path which can be hundreds of milliseconds and just",
    "start": "2352660",
    "end": "2358300"
  },
  {
    "text": "nothing happens when you're using TCP and then finally the networking rican verges and you're off and running with",
    "start": "2358300",
    "end": "2364770"
  },
  {
    "text": "with SRD or reliable data grams over EFA you end up with the the SRD picture",
    "start": "2364770",
    "end": "2371770"
  },
  {
    "text": "which is that exact same scenario we started 20 gigabit flow we unplugged a",
    "start": "2371770",
    "end": "2378070"
  },
  {
    "text": "hot link one of the links in use and you notice we don't go to zero and we don't",
    "start": "2378070",
    "end": "2384400"
  },
  {
    "text": "go to zero because we're always driving traffic across multiple paths in our net work so we do see a bandwidth drop as we",
    "start": "2384400",
    "end": "2392680"
  },
  {
    "text": "figure out oh wait I sent some packets that are never going to get there and I need to send them across a different path but it doesn't go to zero you're",
    "start": "2392680",
    "end": "2399670"
  },
  {
    "text": "always making progress and so this not only helps with the the tail latency",
    "start": "2399670",
    "end": "2405340"
  },
  {
    "text": "problem but also with the the random why did my network stop for a couple of milliseconds problem that you get with",
    "start": "2405340",
    "end": "2411400"
  },
  {
    "text": "HPC applications and then finally a couple of I'm just gonna ask and answer",
    "start": "2411400",
    "end": "2418900"
  },
  {
    "text": "some questions before you guys do just to get them out of the way so like I",
    "start": "2418900",
    "end": "2424540"
  },
  {
    "text": "said it's in preview right now there's a sign-up page on the from that you can",
    "start": "2424540",
    "end": "2430270"
  },
  {
    "text": "get to from the aws.amazon.com slash HPC but the question is when will it reach",
    "start": "2430270",
    "end": "2435520"
  },
  {
    "text": "general availability and the answer is first half of 2019 how do I sign up for",
    "start": "2435520",
    "end": "2442210"
  },
  {
    "text": "the preview there's the link what regions will we launch IFA in the answer",
    "start": "2442210",
    "end": "2449560"
  },
  {
    "text": "to this I'm being a little weasely here I get but anywhere that there's a c5n or",
    "start": "2449560",
    "end": "2455620"
  },
  {
    "text": "a p3 DN so c 5n we announced yesterday um is for commercial regions and gov",
    "start": "2455620",
    "end": "2464080"
  },
  {
    "text": "cloud and as that expands over time and as we expand the the network optimized",
    "start": "2464080",
    "end": "2470890"
  },
  {
    "text": "instance portfolios anywhere one of those exists IFA will work and then the final one that I know someone's gonna",
    "start": "2470890",
    "end": "2477970"
  },
  {
    "text": "ask what is the MPI latency our shipping goal is less than 15 microseconds half",
    "start": "2477970",
    "end": "2485170"
  },
  {
    "text": "round-trip time as measured by the OSU latency benchmark that's inside a",
    "start": "2485170",
    "end": "2490300"
  },
  {
    "text": "placement group pretty confident we're going to hit that and then we're going to constantly iterate on improving that",
    "start": "2490300",
    "end": "2497200"
  },
  {
    "text": "and there's a couple of things that are coming that will help including expanding the metal options which I",
    "start": "2497200",
    "end": "2504400"
  },
  {
    "text": "talked about earlier the the hypervisor lists options that we have which will support EFA and it turns out if you",
    "start": "2504400",
    "end": "2511330"
  },
  {
    "text": "disable if you're using one of those metal instances and you turn off the iommu which you're able to do from your",
    "start": "2511330",
    "end": "2520690"
  },
  {
    "text": "from basically it's a boot I'm option it's a grub Kampf option when you're running on the metal instances",
    "start": "2520690",
    "end": "2526710"
  },
  {
    "text": "you can save approximately two microseconds right there and so there's",
    "start": "2526710",
    "end": "2534250"
  },
  {
    "text": "a number of ways that we're going to continue to reduce that Lane see over the coming years the cool part",
    "start": "2534250",
    "end": "2539829"
  },
  {
    "text": "about EFA is we can do most of those with no change from you guys you continue running your application in",
    "start": "2539829",
    "end": "2546490"
  },
  {
    "text": "one day it gets a little faster and so a quick thank you both to everyone for for",
    "start": "2546490",
    "end": "2553089"
  },
  {
    "text": "listening to me ramble for 45 minutes and obviously I did not do all this",
    "start": "2553089",
    "end": "2558190"
  },
  {
    "text": "myself there's a number of teams in AWS who have been doing an amazing amount of",
    "start": "2558190",
    "end": "2565329"
  },
  {
    "text": "work over the last 18 months to build this offering and so a huge shout out to",
    "start": "2565329",
    "end": "2572140"
  },
  {
    "text": "all of them and as part before I get to questions I'm supposed to remind",
    "start": "2572140",
    "end": "2578109"
  },
  {
    "text": "everyone to complete the session survey in the mobile app and please be nice so",
    "start": "2578109",
    "end": "2584799"
  },
  {
    "text": "with that I'll open it to any questions that you guys have not all at once",
    "start": "2584799",
    "end": "2599369"
  },
  {
    "text": "all right what's that yeah I am competing with the pub crawl so with",
    "start": "2605480",
    "end": "2611510"
  },
  {
    "text": "that I guess we'll call it a night thank you [Applause]",
    "start": "2611510",
    "end": "2620619"
  }
]
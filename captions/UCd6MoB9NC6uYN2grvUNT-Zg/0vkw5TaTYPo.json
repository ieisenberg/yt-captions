[
  {
    "start": "0",
    "end": "138000"
  },
  {
    "text": "welcome to the AWS for AI",
    "start": "5600",
    "end": "9839"
  },
  {
    "text": "podcast welcome to AWS for AI the podcast where we explore cuttingedge AI",
    "start": "10920",
    "end": "16960"
  },
  {
    "text": "solutions and the innovators behind them i'm your host Hamza Mimi AWS solution",
    "start": "16960",
    "end": "22720"
  },
  {
    "text": "architects and today I'm thrilled to welcome a very special guest Julian Simo",
    "start": "22720",
    "end": "29679"
  },
  {
    "text": "VP and chief evangelist at RCAI i actually knew Julian from a past",
    "start": "29679",
    "end": "35760"
  },
  {
    "text": "life back in Paris when he was working for Huggginface and I was personally impressed with his depth of knowledge",
    "start": "35760",
    "end": "42960"
  },
  {
    "text": "helping hundreds of customers solve their AI challenges always sharing his",
    "start": "42960",
    "end": "48079"
  },
  {
    "text": "unique perspective julia is a strong advocate for open-source AI small language models and",
    "start": "48079",
    "end": "55520"
  },
  {
    "text": "is dedicated to helping enterprise clients develop top-notch and costefficient AI",
    "start": "55520",
    "end": "61320"
  },
  {
    "text": "solutions with over 30 years of tech experience including more than a decade in cloud computing and machine learning",
    "start": "61320",
    "end": "68960"
  },
  {
    "text": "Julia is committed to daily learning and is passionate about sharing his expertise through code demos blogs",
    "start": "68960",
    "end": "76400"
  },
  {
    "text": "YouTube videos and more at RCAI he's working on things like the RC Mirage",
    "start": "76400",
    "end": "82640"
  },
  {
    "text": "model an Arabic language model which consistently outperforms the",
    "start": "82640",
    "end": "88000"
  },
  {
    "text": "state-of-the-art models across most open Arabic large language benchmarks",
    "start": "88000",
    "end": "93520"
  },
  {
    "text": "showcasing remarkable improvements and securing top spot on HuggingFace leaderboard before joining RCAI Julian",
    "start": "93520",
    "end": "102240"
  },
  {
    "text": "was chief evangelist at HuggingFace and global AI evangelist at Amazon Web",
    "start": "102240",
    "end": "107640"
  },
  {
    "text": "Services he also serves at as a CEO at prominent",
    "start": "107640",
    "end": "112680"
  },
  {
    "text": "startups in 2021 Julian was ranked number one in the list of top 10 AI",
    "start": "112680",
    "end": "118560"
  },
  {
    "text": "evangelists worldwide by AI magazine with the likes of Flex Freedman Elia",
    "start": "118560",
    "end": "124000"
  },
  {
    "text": "Sutskiver and others shaping the industry julia It's a pleasure to have you today with",
    "start": "124000",
    "end": "130640"
  },
  {
    "text": "us it's a pleasure to be here very happy to be in Dubai and very happy to be your guest today thank you so before going",
    "start": "130640",
    "end": "138720"
  },
  {
    "start": "138000",
    "end": "400000"
  },
  {
    "text": "into the technical discussions and I'm sure you have a lot of things to say uh I want to go back to your personal story",
    "start": "138720",
    "end": "145280"
  },
  {
    "text": "getting into AI and now well AWS",
    "start": "145280",
    "end": "150480"
  },
  {
    "text": "uh hugging face RCA what brought to brought you to first to AI in general",
    "start": "150480",
    "end": "156000"
  },
  {
    "text": "and and then what's your story getting into rci it's it's a long story i I'll keep it",
    "start": "156000",
    "end": "161599"
  },
  {
    "text": "short and hopefully not boring uh it it all started with my SQL um you",
    "start": "161599",
    "end": "169599"
  },
  {
    "text": "know back in the early 2000s I was working in uh on web",
    "start": "169599",
    "end": "175160"
  },
  {
    "text": "platforms e-commerce websites you know that kind of thing and you know data was everywhere product catalogs we had to",
    "start": "175160",
    "end": "182239"
  },
  {
    "text": "manage that so you know my SQL posgress Oracle you name it right and then I",
    "start": "182239",
    "end": "189599"
  },
  {
    "text": "joined another company working in adtech where data was structured so still",
    "start": "189599",
    "end": "195920"
  },
  {
    "text": "databases but mostly unstructured you know web logs uh with uh ad displays and",
    "start": "195920",
    "end": "203640"
  },
  {
    "text": "clicks that kind of thing and uh and we were starting to use machine learning to",
    "start": "203640",
    "end": "210799"
  },
  {
    "text": "predict clicks you know click-through rate uh prediction and uh and we",
    "start": "210799",
    "end": "216720"
  },
  {
    "text": "actually built a very large Hadoop cluster uh multipetabyte cluster which was insanely large at the time and and I",
    "start": "216720",
    "end": "224640"
  },
  {
    "text": "started looking into into machine learning and I I have no formal training",
    "start": "224640",
    "end": "229840"
  },
  {
    "text": "in machine learning but I thought okay that's cool stuff you know uh trying to predict behavior from web logs that's",
    "start": "229840",
    "end": "237360"
  },
  {
    "text": "that's interesting so I started learning about it and and the ball you know has",
    "start": "237360",
    "end": "242480"
  },
  {
    "text": "has kept rolling since then and uh and at some point I decided",
    "start": "242480",
    "end": "248799"
  },
  {
    "text": "uh you know around 20 when I joined AWS actually around uh late 2015 2016 um",
    "start": "248799",
    "end": "257120"
  },
  {
    "text": "Amazon started AWS started launching their first um machine learning services",
    "start": "257120",
    "end": "262240"
  },
  {
    "text": "and AI services and I thought okay so deep learning what is this you know I'm",
    "start": "262240",
    "end": "268639"
  },
  {
    "text": "curious interesting and and you know and then keep kept on learning uh and",
    "start": "268639",
    "end": "273840"
  },
  {
    "text": "decided I wanted to focus about on this and convinced my boss to you know let me focus exclusively on a IML which you",
    "start": "273840",
    "end": "282800"
  },
  {
    "text": "know very few folks properly understood 10 years ago um and and they said yeah",
    "start": "282800",
    "end": "288880"
  },
  {
    "text": "yeah okay go go do your thing you know leave us alone and um and yeah that's that's how it went",
    "start": "288880",
    "end": "296479"
  },
  {
    "text": "learning every today um and starting to uh you know starting",
    "start": "296479",
    "end": "301759"
  },
  {
    "text": "from scratch and trying to figure out the the the use cases you know what's in",
    "start": "301759",
    "end": "307039"
  },
  {
    "text": "it for customers um not the agos not the theory that's useful but first you know",
    "start": "307039",
    "end": "314720"
  },
  {
    "text": "what can I do with this as an enterprise customer or startup customer what can I",
    "start": "314720",
    "end": "320560"
  },
  {
    "text": "build what can I solve how can I improve the user experience how can I improve",
    "start": "320560",
    "end": "326080"
  },
  {
    "text": "the agility of my company you know the the business challenges the the real life problems and and then you know",
    "start": "326080",
    "end": "334320"
  },
  {
    "text": "figuring out okay what technology is the best fit what model is the best for",
    "start": "334320",
    "end": "339560"
  },
  {
    "text": "this and it changes every day so you have to keep learning uh and uh keep",
    "start": "339560",
    "end": "345919"
  },
  {
    "text": "experimenting and that's how I describe my job you know I waste a lot of hours a lot of evenings uh learning or",
    "start": "345919",
    "end": "354840"
  },
  {
    "text": "unlearning sometime uh and figure out trying to figure out things so that you don't have to right because if I spend",
    "start": "354840",
    "end": "362320"
  },
  {
    "text": "you know 20 hours banging my head on on a problem and I can do maybe a YouTube",
    "start": "362320",
    "end": "368080"
  },
  {
    "text": "video to explain it properly hopefully and this gets you thousands or tens of",
    "start": "368080",
    "end": "373600"
  },
  {
    "text": "thousands of views and I did save hopefully a lot of time globally for for",
    "start": "373600",
    "end": "379120"
  },
  {
    "text": "the the user community and that's you know that's what I like and thousands that's my leverage",
    "start": "379120",
    "end": "384639"
  },
  {
    "text": "absolutely so now RCAI yes um can you",
    "start": "384639",
    "end": "390080"
  },
  {
    "text": "talk a little bit about what's RCAI mission what are some of the things that",
    "start": "390080",
    "end": "395759"
  },
  {
    "text": "you're working on and how are you trying to achieve that mission so I describe",
    "start": "395759",
    "end": "401280"
  },
  {
    "start": "400000",
    "end": "542000"
  },
  {
    "text": "RCA AI as the SLM champions and uh small language model",
    "start": "401280",
    "end": "406919"
  },
  {
    "text": "champions and and I I mean I mean that in two ways so first of all we are",
    "start": "406919",
    "end": "412759"
  },
  {
    "text": "championing you know SM we we we are convinced that uh customers will get",
    "start": "412759",
    "end": "419360"
  },
  {
    "text": "more value out of their services and products if they use small language",
    "start": "419360",
    "end": "425280"
  },
  {
    "text": "models versus large language models and I'm sure we'll double click on that so we're convinced this is the best way",
    "start": "425280",
    "end": "431919"
  },
  {
    "text": "forward and it looks like you know an increasing number of people uh agree",
    "start": "431919",
    "end": "436960"
  },
  {
    "text": "with that and we're also SLM champions because we are pretty good uh at",
    "start": "436960",
    "end": "444479"
  },
  {
    "text": "building models um so you mentioned Mirage which is our Arabic language",
    "start": "444479",
    "end": "450280"
  },
  {
    "text": "model um we we build models we start from the best open-source models",
    "start": "450280",
    "end": "456000"
  },
  {
    "text": "available today so which could be um you know llamas or mistrals or quens you",
    "start": "456000",
    "end": "462800"
  },
  {
    "text": "know quen 3 just came out so pretty sure we'll we'll have something to say about that in the in a few weeks and we we run",
    "start": "462800",
    "end": "470960"
  },
  {
    "text": "them through our uh post training stack um which again is is our own IP a it's a",
    "start": "470960",
    "end": "477599"
  },
  {
    "text": "list of uh open source libraries we've built and invented uh to um not only",
    "start": "477599",
    "end": "484160"
  },
  {
    "text": "build outperforming models but also build them in a very costefficient way",
    "start": "484160",
    "end": "490879"
  },
  {
    "text": "um so we're model builders we share some of the models back on hogging face we keep some of them for for for commercial",
    "start": "490879",
    "end": "497520"
  },
  {
    "text": "customers and we're also a platform builder so we take our models and we deploy them on SAS platforms uh for uh",
    "start": "497520",
    "end": "505360"
  },
  {
    "text": "for inference um with cool things like model routing maybe we'll talk about",
    "start": "505360",
    "end": "510919"
  },
  {
    "text": "that and uh and agentic workflows so you know trying to advance AI to the next",
    "start": "510919",
    "end": "518000"
  },
  {
    "text": "level um because we realize and our customers realize that no single model",
    "start": "518000",
    "end": "524720"
  },
  {
    "text": "can do the job right there there is no Swiss Army knife model Just like there",
    "start": "524720",
    "end": "529760"
  },
  {
    "text": "is no Swiss Army knife database or Swiss Army knife programming language you need to use the right tool for the job uh and",
    "start": "529760",
    "end": "536640"
  },
  {
    "text": "and we're trying to help customers do that so what are some of your customers",
    "start": "536640",
    "end": "542399"
  },
  {
    "start": "542000",
    "end": "619000"
  },
  {
    "text": "industries uh geographies where are you focusing right now so RC is a is an",
    "start": "542399",
    "end": "549200"
  },
  {
    "text": "American company most of the team is still based uh in the US uh there's a few of us in in Europe um I'm I'm based",
    "start": "549200",
    "end": "557920"
  },
  {
    "text": "in France i think I'm the only one still um so we have we have a US focus um",
    "start": "557920",
    "end": "565279"
  },
  {
    "text": "because that's the natural uh you know territory I would say for for for RC uh",
    "start": "565279",
    "end": "570640"
  },
  {
    "text": "having said that we we have international conversations um one of the reasons I'm here this week is",
    "start": "570640",
    "end": "576720"
  },
  {
    "text": "because I'm meeting with some uh some customers potential customers and",
    "start": "576720",
    "end": "582200"
  },
  {
    "text": "partners and um and by the time you watch this uh I'm sure you will have",
    "start": "582200",
    "end": "587600"
  },
  {
    "text": "heard of our our announcements uh with the with the the the GCC uh",
    "start": "587600",
    "end": "594080"
  },
  {
    "text": "region uh so we're uh pretty serious about uh uh about the region uh we see a",
    "start": "594080",
    "end": "601040"
  },
  {
    "text": "lot of AI activity here a lot of interesting customers and partners and um and we're hoping to help customers",
    "start": "601040",
    "end": "608080"
  },
  {
    "text": "here as well i I can only say I'm also seeing the same and it's really huge",
    "start": "608080",
    "end": "613920"
  },
  {
    "text": "here but it's huge everywhere but here in things are moving very fast yes um I",
    "start": "613920",
    "end": "619839"
  },
  {
    "start": "619000",
    "end": "900000"
  },
  {
    "text": "I want to talk a little bit about some of the use cases you obviously you work",
    "start": "619839",
    "end": "625519"
  },
  {
    "text": "with some uh customers on building sure uh small language models but you also have some products yes um maybe talk a",
    "start": "625519",
    "end": "633920"
  },
  {
    "text": "little bit about some of the use cases you're working with uh some of your customers um so if you know long story",
    "start": "633920",
    "end": "640720"
  },
  {
    "text": "short first we had LLMs and well um the",
    "start": "640720",
    "end": "646880"
  },
  {
    "text": "initial vision was you know one LLM to rule them all and you could do anything and everything with a single LLM that",
    "start": "646880",
    "end": "654880"
  },
  {
    "text": "didn't work out well uh especially for customers who have you know very strong privacy or or",
    "start": "654880",
    "end": "661880"
  },
  {
    "text": "very domain specific questions and then of course the open source community",
    "start": "661880",
    "end": "666959"
  },
  {
    "text": "started building great models and before we knew it we had you know a million models on on Hawking face and you know",
    "start": "666959",
    "end": "673040"
  },
  {
    "text": "probably 1.7 million by now u which is which is amazing but creates complexity",
    "start": "673040",
    "end": "680079"
  },
  {
    "text": "because which one do you use right um and and it's uh it can be a little bit uh paralyzing so and and everybody",
    "start": "680079",
    "end": "688560"
  },
  {
    "text": "started fine-tuning models trying to get um you know their own domain knowledge",
    "start": "688560",
    "end": "693600"
  },
  {
    "text": "embedded into the models and getting some success but probably not as much as they as they wanted and I think at the",
    "start": "693600",
    "end": "700800"
  },
  {
    "text": "end of the day um you know the again the the world is a little more complicated than that um and",
    "start": "700800",
    "end": "709320"
  },
  {
    "text": "uh building automated workflows or smart workflows is more than one model so yes",
    "start": "709320",
    "end": "717600"
  },
  {
    "text": "you need a collection of models and the smaller the better because small means",
    "start": "717600",
    "end": "722640"
  },
  {
    "text": "you know fast and less expensive etc more scalable but you need also IT IT",
    "start": "722640",
    "end": "729519"
  },
  {
    "text": "tools right you have interesting data in Salesforce you have interesting data in GitHub you have interesting data uh you",
    "start": "729519",
    "end": "736800"
  },
  {
    "text": "know in all your apps in your uh in your email server etc so trying to build a single model that",
    "start": "736800",
    "end": "745120"
  },
  {
    "text": "replicates all that knowledge is is very hard you know and it it fails most of",
    "start": "745120",
    "end": "750560"
  },
  {
    "text": "the time so the right approach which the one we advocate now is use models for",
    "start": "750560",
    "end": "755760"
  },
  {
    "text": "what they're really great at um so data analysis uh data conversion uh story",
    "start": "755760",
    "end": "762720"
  },
  {
    "text": "writing obviously and and use them with the data coming from your existing IT",
    "start": "762720",
    "end": "769440"
  },
  {
    "text": "systems where you have your customer knowledge or you have your documents etc",
    "start": "769440",
    "end": "774639"
  },
  {
    "text": "and you know use each bit for what it's it's great at and once you do that then the use cases become um I would say",
    "start": "774639",
    "end": "781720"
  },
  {
    "text": "infinite um because you're able to combine models and external tools",
    "start": "781720",
    "end": "789360"
  },
  {
    "text": "into an infinite uh number of combinations right instead of trying to",
    "start": "789360",
    "end": "795120"
  },
  {
    "text": "teach a single model to do you know customer support and uh and fraud",
    "start": "795120",
    "end": "801480"
  },
  {
    "text": "prevention and and you know all the usual uh all the usual document analysis",
    "start": "801480",
    "end": "806959"
  },
  {
    "text": "right all the usual suspects and I think that's uh you know at least that's what we mean by",
    "start": "806959",
    "end": "814000"
  },
  {
    "text": "agents you know I'm not quite sure what some people mean by agents what we mean",
    "start": "814000",
    "end": "819360"
  },
  {
    "text": "is com combining external tools um SAS or or or",
    "start": "819360",
    "end": "826560"
  },
  {
    "text": "APIs or ISVS etc combining them with models in in in smart and simple ways to",
    "start": "826560",
    "end": "835360"
  },
  {
    "text": "deliver automation and and you know augment the productivity of of your workers and um and yes the we work with",
    "start": "835360",
    "end": "843839"
  },
  {
    "text": "companies across the board you know from financial services to insurance to uh um",
    "start": "843839",
    "end": "849600"
  },
  {
    "text": "um you know retail there if you had asked me that question 10 years ago I would have told",
    "start": "849600",
    "end": "855279"
  },
  {
    "text": "you financial services and everybody else behind maybe retail um now we see",
    "start": "855279",
    "end": "861760"
  },
  {
    "text": "customers in in literally all verticals you know edtech and uh and even companies that are not that",
    "start": "861760",
    "end": "869000"
  },
  {
    "text": "sophisticated you know definitely not just tech companies folks who just have data and who need to automate and scale",
    "start": "869000",
    "end": "876720"
  },
  {
    "text": "and so pretty much everybody oh yeah AI across the board everywhere be more cost effective be faster who doesn't want",
    "start": "876720",
    "end": "883279"
  },
  {
    "text": "that absolutely um you also have some products um beyond the the ones that",
    "start": "883279",
    "end": "889680"
  },
  {
    "text": "you're working with your customers directly um things like conductor like orchestra like merge kit uh what what",
    "start": "889680",
    "end": "897760"
  },
  {
    "text": "kind of problems are you solving with these so initially RC started as a like",
    "start": "897760",
    "end": "902959"
  },
  {
    "start": "900000",
    "end": "1040000"
  },
  {
    "text": "I said as a model building company and and specifically as a um custom model",
    "start": "902959",
    "end": "908320"
  },
  {
    "text": "building so uh we work with the companies coming to us saying hey we need a model for this particular use",
    "start": "908320",
    "end": "915519"
  },
  {
    "text": "case in this particular industry we think we have good data can you help us and of course we we did so we did a we",
    "start": "915519",
    "end": "920639"
  },
  {
    "text": "did quite a few of those um and and again as I mentioned earlier uh I think",
    "start": "920639",
    "end": "925760"
  },
  {
    "text": "the we were successful because we didn't just grab the fine-tuning notebook from hugging face uh and run it right uh and",
    "start": "925760",
    "end": "935199"
  },
  {
    "text": "that's a good notebook you know no worries there you know Um hogging face is doing a lot of of amazing work",
    "start": "935199",
    "end": "942199"
  },
  {
    "text": "but things are more complicated than that um and uh and and we we realize",
    "start": "942199",
    "end": "948480"
  },
  {
    "text": "there's a different way to build models so yes you mentioned merge kit uh which is the model merging library we we",
    "start": "948480",
    "end": "957560"
  },
  {
    "text": "invented and uh and model merging is a crazy technique where instead of",
    "start": "957560",
    "end": "962800"
  },
  {
    "text": "training models you literally merge them and it's exactly what the the name says you know you take model A model B and",
    "start": "962800",
    "end": "969759"
  },
  {
    "text": "model C and you run a math operation literally um and it's almost model A",
    "start": "969759",
    "end": "975600"
  },
  {
    "text": "plus model B plus model C divided by three you know that's a a gross simplification but that's what it is so",
    "start": "975600",
    "end": "982160"
  },
  {
    "text": "there's no training involved i can run it on my laptop in a few minutes and you",
    "start": "982160",
    "end": "987519"
  },
  {
    "text": "can take single task models and merge them into you know multitask models that's one use case and if you look at",
    "start": "987519",
    "end": "994959"
  },
  {
    "text": "hug the hugging face leaderboard which you mentioned most if not all of the top performing models involve merging and uh",
    "start": "994959",
    "end": "1001920"
  },
  {
    "text": "and companies like you know uh Google uh mentioned that they use model merging for the gemma models etc etc so it's",
    "start": "1001920",
    "end": "1009279"
  },
  {
    "text": "it's a popular technique model distillation um is a is another great technique thanks to deepseek I guess now",
    "start": "1009279",
    "end": "1016320"
  },
  {
    "text": "people have heard of distillation so but we've been doing that for for a while as well so we have this stack which is I",
    "start": "1016320",
    "end": "1023120"
  },
  {
    "text": "would say sophisticated definitely not just vanilla techniques that uh that you can run in in a simple",
    "start": "1023120",
    "end": "1029720"
  },
  {
    "text": "notebook and and that's how we build great models um and then so we call that",
    "start": "1029720",
    "end": "1036160"
  },
  {
    "text": "post- trainining okay uh so that's that's the post- training element um then once we have those great models of",
    "start": "1036160",
    "end": "1042480"
  },
  {
    "start": "1040000",
    "end": "1155000"
  },
  {
    "text": "course we because I said earlier no single model even ours will solve everything um we built an inference",
    "start": "1042480",
    "end": "1050080"
  },
  {
    "text": "platform and you mentioned it's called conductor and so conductor involves model routing where every prompt you",
    "start": "1050080",
    "end": "1057520"
  },
  {
    "text": "send is analyzed by a tiny router model so we look at complexity we look at",
    "start": "1057520",
    "end": "1063840"
  },
  {
    "text": "domain and a few more things and based on that we make a really quick decision and send it to the most appropriate",
    "start": "1063840",
    "end": "1069840"
  },
  {
    "text": "model and hopefully you know we send that to the smallest model possible",
    "start": "1069840",
    "end": "1076240"
  },
  {
    "text": "because it's going to be faster it's going to be more scalable and it's going",
    "start": "1076240",
    "end": "1081440"
  },
  {
    "text": "to be more cost efficient if you need to write a meeting invite or if you need to",
    "start": "1081440",
    "end": "1086960"
  },
  {
    "text": "summarize a document or if you need to translate a document small models can do that extremely well",
    "start": "1086960",
    "end": "1094160"
  },
  {
    "text": "so if you send that to an LLM of course they will do a good job but they will do",
    "start": "1094160",
    "end": "1100400"
  },
  {
    "text": "it 100 or 200 times more expensive right you'll pay tens of dollars per",
    "start": "1100400",
    "end": "1107840"
  },
  {
    "text": "million tokens instead of paying you know fractions of fractions of fractions of a",
    "start": "1107840",
    "end": "1113160"
  },
  {
    "text": "cent so at scale you know it adds up very quickly so that's the the whole idea behind conductor find in real time",
    "start": "1113160",
    "end": "1120960"
  },
  {
    "text": "the best model for each prompt and um and optimize for cost efficiency and and",
    "start": "1120960",
    "end": "1128240"
  },
  {
    "text": "uh and I could show you some examples where you know small models do as good a job as the top you know models from um",
    "start": "1128240",
    "end": "1135520"
  },
  {
    "text": "open AI or anthropic but at a fraction of a cost so that's that's conductor and you know it's it's a really really cool",
    "start": "1135520",
    "end": "1142080"
  },
  {
    "text": "way to uh uh you know spend your money uh wisely right uh get more bang for",
    "start": "1142080",
    "end": "1150320"
  },
  {
    "text": "your DAM or dollars or euros um so and",
    "start": "1150320",
    "end": "1155440"
  },
  {
    "start": "1155000",
    "end": "1242000"
  },
  {
    "text": "then we have um quickly we have orchestra uh which is our agentic workflow platform um which is a uh has a",
    "start": "1155440",
    "end": "1163280"
  },
  {
    "text": "very simple you know UI where you drag and drop boxes uh so you know you want",
    "start": "1163280",
    "end": "1168640"
  },
  {
    "text": "to connect uh you know Salesforce as an input to an SLM and then you want to",
    "start": "1168640",
    "end": "1174400"
  },
  {
    "text": "have maybe a bit of uh custom code to do something else on top you know drag and",
    "start": "1174400",
    "end": "1179840"
  },
  {
    "text": "drop connect use the models run the workflows uh deploy deploy them as APIs",
    "start": "1179840",
    "end": "1185440"
  },
  {
    "text": "which your apps can invoke or trigger them through a chat interface if you want to expose that to your users so",
    "start": "1185440",
    "end": "1191679"
  },
  {
    "text": "it's always the same philosophy it's like no single model even the best open source model even the best RC model is",
    "start": "1191679",
    "end": "1197360"
  },
  {
    "text": "not enough so you need a collection of models um that you can use for the right",
    "start": "1197360",
    "end": "1203360"
  },
  {
    "text": "you know at the right time for the right thing uh and in some cases you know with conductor you let uh the platform itself",
    "start": "1203360",
    "end": "1210559"
  },
  {
    "text": "decide uh when to use which which is great because models change all the time",
    "start": "1210559",
    "end": "1215840"
  },
  {
    "text": "and nobody has enough time in their day um even if you have a large team to",
    "start": "1215840",
    "end": "1222080"
  },
  {
    "text": "evaluate everything constantly you know it changes overnight so we do that work",
    "start": "1222080",
    "end": "1227840"
  },
  {
    "text": "and we let customers focus on what's important which is you know take care of business take care of their daily",
    "start": "1227840",
    "end": "1233440"
  },
  {
    "text": "business and their operations and not run evaluation tests on models",
    "start": "1233440",
    "end": "1238640"
  },
  {
    "text": "constantly which is you know painful and timeconuming too many stuff to unpack",
    "start": "1238640",
    "end": "1244880"
  },
  {
    "start": "1242000",
    "end": "1409000"
  },
  {
    "text": "and yeah there's um I let let me double click on the model merging technique and",
    "start": "1244880",
    "end": "1250799"
  },
  {
    "text": "yes and generally how you actually build small language models so you talked",
    "start": "1250799",
    "end": "1257120"
  },
  {
    "text": "about distillation there is quantization yes merging uh and training from scratch",
    "start": "1257120",
    "end": "1263200"
  },
  {
    "text": "um how do you get the best small language model",
    "start": "1263200",
    "end": "1269080"
  },
  {
    "text": "so first I would say you know we we're really pragmatic we're",
    "start": "1269080",
    "end": "1275760"
  },
  {
    "text": "uh a fun way and a slightly cheeky way to say it would be you know some people",
    "start": "1275799",
    "end": "1281520"
  },
  {
    "text": "have spent billions of dollars building you know the again the mistrols",
    "start": "1281520",
    "end": "1287440"
  },
  {
    "text": "and the llamas and the quens and the fi models and the gemma models and they're",
    "start": "1287440",
    "end": "1292960"
  },
  {
    "text": "all great you know uh so let's start from there okay let's",
    "start": "1292960",
    "end": "1299760"
  },
  {
    "text": "start from those models and our research team you know spends a lot of time again evaluating those models uh they're",
    "start": "1299760",
    "end": "1307120"
  },
  {
    "text": "connected with a lot of those teams and so they they see that hey this new model",
    "start": "1307120",
    "end": "1312400"
  },
  {
    "text": "comes up and it's better at this particular set of tasks and or maybe it's better on that language or maybe",
    "start": "1312400",
    "end": "1318880"
  },
  {
    "text": "it's better at Python or you know or it's better on finance who knows uh and",
    "start": "1318880",
    "end": "1325280"
  },
  {
    "text": "that's that's useful information so then uh depending on what we're trying to build are we trying to build a customer",
    "start": "1325280",
    "end": "1331679"
  },
  {
    "text": "model or are we trying to build a general purpose model that we want to add to our platforms you know they can go and select the the right model and",
    "start": "1331679",
    "end": "1339280"
  },
  {
    "text": "then they run the post- trainining process which I mentioned Um and and we're able to do that uh repeatedly",
    "start": "1339280",
    "end": "1346400"
  },
  {
    "text": "because again we do it in a very costefficient way so we don't spend uh $100 million you know uh post training",
    "start": "1346400",
    "end": "1355520"
  },
  {
    "text": "quen whatever we don't have that money and uh you know if we had that money we'd use it for something else so so",
    "start": "1355520",
    "end": "1361760"
  },
  {
    "text": "that's the value of the of you know again model merging and model distillation and and and other techniques that we that we've",
    "start": "1361760",
    "end": "1368280"
  },
  {
    "text": "implemented and um and they so they're super costefficient and they've repeatedly",
    "start": "1368280",
    "end": "1375440"
  },
  {
    "text": "demonstrated that they were able to deliver outperforming models and in fact every time we published a model on",
    "start": "1375440",
    "end": "1382720"
  },
  {
    "text": "hogging face it was number one in its size category and then over time you",
    "start": "1382720",
    "end": "1388320"
  },
  {
    "text": "know it changes so if you're looking at at at at Hoging Fist today it's not probably not number one anymore you know",
    "start": "1388320",
    "end": "1394400"
  },
  {
    "text": "but every time that model was the best um and and I suspect you know the team",
    "start": "1394400",
    "end": "1400159"
  },
  {
    "text": "wouldn't release it if it wasn't anyway you know they worked very very hard to make sure it was the best and customers",
    "start": "1400159",
    "end": "1405840"
  },
  {
    "text": "would get a lot out of it and um and there are you know there are so many",
    "start": "1405840",
    "end": "1410880"
  },
  {
    "start": "1409000",
    "end": "1526000"
  },
  {
    "text": "ways you can uh you can you can improve those models so you know post training you know synthetic synthetic data you",
    "start": "1410880",
    "end": "1418559"
  },
  {
    "text": "know it's the topic no one ever discusses people are obsessed about transformer architectures and oh you",
    "start": "1418559",
    "end": "1425679"
  },
  {
    "text": "know this new attention layer or this new tweak on the attention layer and don't get me wrong I'm an engineer i",
    "start": "1425679",
    "end": "1432240"
  },
  {
    "text": "love that stuff you know I spend hours reading it trying to figure out the math again and hopefully doing those YouTube",
    "start": "1432240",
    "end": "1438240"
  },
  {
    "text": "videos that you you like but it's not you know like the data",
    "start": "1438240",
    "end": "1443919"
  },
  {
    "text": "the data matters and um and I remember very well you know when Falcon from from",
    "start": "1443919",
    "end": "1450640"
  },
  {
    "text": "TI came out uh that's a while ago um I mean yes they had tweaks on the model",
    "start": "1450640",
    "end": "1457200"
  },
  {
    "text": "architecture but it was specifically a better model because they had spent a ton of time uh cleaning and curating the",
    "start": "1457200",
    "end": "1465520"
  },
  {
    "text": "data the so-called refined web data set removing all the you know bad stuff that lives in public",
    "start": "1465520",
    "end": "1472960"
  },
  {
    "text": "internet data sets and and and and doing that is is is critical and uh and I can",
    "start": "1472960",
    "end": "1479360"
  },
  {
    "text": "never uh you know I can never uh say enough that if you are fine-tuning models uh if you're building your",
    "start": "1479360",
    "end": "1486480"
  },
  {
    "text": "question and answer data sets the quality the diversity the complexity of",
    "start": "1486480",
    "end": "1492320"
  },
  {
    "text": "your questions is critical you know don't think you can just take 100 Q&A pairs and fine-tune and get good results",
    "start": "1492320",
    "end": "1499440"
  },
  {
    "text": "you will have good results on those specific QA pairs but you know you and I we wouldn't ask our uh customer support",
    "start": "1499440",
    "end": "1508400"
  },
  {
    "text": "uh banking app the same well the same question in the same way right so",
    "start": "1508400",
    "end": "1513600"
  },
  {
    "text": "diversity is is important complexity is important and we again we spend a lot of time working on that um and uh and",
    "start": "1513600",
    "end": "1521679"
  },
  {
    "text": "that's you know if there is a secret sauce that that's it you know so most of",
    "start": "1521679",
    "end": "1527360"
  },
  {
    "start": "1526000",
    "end": "1684000"
  },
  {
    "text": "these techniques will require the models to be open source and I know you are very passionate about",
    "start": "1527360",
    "end": "1535440"
  },
  {
    "text": "this yes uh but I feel open source is not yet well defined in AI and in",
    "start": "1535440",
    "end": "1542240"
  },
  {
    "text": "generative AI in general it's yeah the term is is wrongly used i think it's still early age um we've we we're",
    "start": "1542240",
    "end": "1551600"
  },
  {
    "text": "starting to see obviously the open weights yeah open and there are some",
    "start": "1551600",
    "end": "1556960"
  },
  {
    "text": "other initiatives just want to maybe touch on what do you see from your perspective and obviously you also have",
    "start": "1556960",
    "end": "1563440"
  },
  {
    "text": "open source and commercial models sure and what what's your perspective on open",
    "start": "1563440",
    "end": "1569440"
  },
  {
    "text": "source on AI and where do you see this going forward so you're right i think I think we should really say open weights",
    "start": "1569440",
    "end": "1575919"
  },
  {
    "text": "because uh that's that's what the the hugging face models are you you have the model architecture you have the weights",
    "start": "1575919",
    "end": "1581760"
  },
  {
    "text": "you can load them with the the hugging face libraries um very very few models are actually open source you know if you",
    "start": "1581760",
    "end": "1588000"
  },
  {
    "text": "want to say a model is open source then everything needs to be open so you need to have the the training data set you",
    "start": "1588000",
    "end": "1595760"
  },
  {
    "text": "need to have the training code uh you need to have the maybe the post- training code uh the full recipe right",
    "start": "1595760",
    "end": "1603600"
  },
  {
    "text": "um I mean if I bake a cake and I tell you uh you know I tell you it's uh you",
    "start": "1603600",
    "end": "1610159"
  },
  {
    "text": "know it's an apple pie okay it's got an apple pie architecture and it's got you",
    "start": "1610159",
    "end": "1615520"
  },
  {
    "text": "know sugar and apples and flour i mean you know what I mean it's like it's not",
    "start": "1615520",
    "end": "1621120"
  },
  {
    "text": "enough to to actually bake yours you know you need the full recipe and uh and",
    "start": "1621120",
    "end": "1626400"
  },
  {
    "text": "and the all the tricks even the recipe doesn't have the the tricks that you know and the the knowhow that a a great",
    "start": "1626400",
    "end": "1632960"
  },
  {
    "text": "cook has so um so yeah I think we should really say open weights there are very",
    "start": "1632960",
    "end": "1638480"
  },
  {
    "text": "few models that qualify as open source i mean to their credit hogging face has built a few where they did share",
    "start": "1638480",
    "end": "1643919"
  },
  {
    "text": "absolutely everything uh and I think that's uh that's that's that's interesting just to contrast with what",
    "start": "1643919",
    "end": "1649919"
  },
  {
    "text": "you usually get i I think the uh the contribution of the community is is absolutely critical",
    "start": "1649919",
    "end": "1657679"
  },
  {
    "text": "and um and it's I think it's stronger than ever uh because you know it used to",
    "start": "1657679",
    "end": "1664960"
  },
  {
    "text": "be the first few meaningful open-source or open weights model came from you know",
    "start": "1664960",
    "end": "1671440"
  },
  {
    "text": "Stanford and you know Vikuna and Alpaka and then you know Meta joined the",
    "start": "1671440",
    "end": "1677039"
  },
  {
    "text": "the fund with the llama models and and then a lot of people started joining the fund so uh so again you know uh and we",
    "start": "1677039",
    "end": "1684880"
  },
  {
    "start": "1684000",
    "end": "1862000"
  },
  {
    "text": "see actors that are not just US actors you know TII joined and and well Alibaba",
    "start": "1684880",
    "end": "1690720"
  },
  {
    "text": "and the Quen models are very significant right now and I'm pretty sure before we know it we'll see great models from",
    "start": "1690720",
    "end": "1696799"
  },
  {
    "text": "India and and there are some models coming out of uh of um Asian",
    "start": "1696799",
    "end": "1702840"
  },
  {
    "text": "countries and and you know we'll see models coming out of Africa etc and that's that's great because I keep",
    "start": "1702840",
    "end": "1709600"
  },
  {
    "text": "telling everybody and I mean no disrespect to anyone but why would a US West Coast team of",
    "start": "1709600",
    "end": "1718600"
  },
  {
    "text": "engineers be the best people to build a Swahili model or or uh or a Tagalog",
    "start": "1718600",
    "end": "1727880"
  },
  {
    "text": "model not to mention you know Indonesia when I was in Singapore a while ago I say \"Oh yeah you know how's the support",
    "start": "1727880",
    "end": "1734480"
  },
  {
    "text": "for Indonesian?\" And they were people were laughing politely and saying did I say something stupid i said no no no but",
    "start": "1734480",
    "end": "1740000"
  },
  {
    "text": "you know we have 100 dialects in Indonesia alone and you know India is pretty complex and Africa is pretty",
    "start": "1740000",
    "end": "1746320"
  },
  {
    "text": "complex and so those not to mention the cultural differences you know which you",
    "start": "1746320",
    "end": "1753200"
  },
  {
    "text": "have to to account for uh I mean I'm from I live in Europe so I'm kind of in the middle if you look at the map so you",
    "start": "1753200",
    "end": "1760159"
  },
  {
    "text": "know I look east and I look west and I look south and I see different folks with different languages and different cultures and different religions",
    "start": "1760159",
    "end": "1765840"
  },
  {
    "text": "different everything and that's perfect that's the way it should be um but those",
    "start": "1765840",
    "end": "1771440"
  },
  {
    "text": "differences should also be reflected in in the models that you use and you know",
    "start": "1771440",
    "end": "1776559"
  },
  {
    "text": "it's it no one needs to judge that you know if you're in Dubai you know in Rome do as the Romans do right well in Dubai",
    "start": "1776559",
    "end": "1784799"
  },
  {
    "text": "do as they do in Dubai and in Singapore it's the same and you know it and it a",
    "start": "1784799",
    "end": "1790880"
  },
  {
    "text": "single company or a very small set of companies all of them in the US cannot be in charge of that so I'm I'm all for",
    "start": "1790880",
    "end": "1798480"
  },
  {
    "text": "local initiatives local languages local cultures local trainings so uh you know um I mean UAE",
    "start": "1798480",
    "end": "1807200"
  },
  {
    "text": "is doing pretty pretty well is very actively involved in that in some other parts of the world it's more complicated",
    "start": "1807200",
    "end": "1813440"
  },
  {
    "text": "they don't have the same resources um but you know we need to encourage that kind of uh of work and I think this",
    "start": "1813440",
    "end": "1820720"
  },
  {
    "text": "is more interesting to me the discussions on sovereignty you know sovereignty is a bit of an abstract word so if you tell me oh we need sovereign",
    "start": "1820720",
    "end": "1827039"
  },
  {
    "text": "models I'm not quite sure what that means if you tell me we need a model that we're comfortable",
    "start": "1827039",
    "end": "1833200"
  },
  {
    "text": "um um deploying in uh in schools from a",
    "start": "1833200",
    "end": "1838720"
  },
  {
    "text": "you know language a safety a cultural and even a religious perspective okay now I'm now I'm with you yeah okay and",
    "start": "1838720",
    "end": "1845440"
  },
  {
    "text": "it doesn't matter what I think because if I'm if I want to build a French model with the French way of life let's go do",
    "start": "1845440",
    "end": "1853039"
  },
  {
    "text": "that but if I'm going to build a model or help people in Singapore build a model for them you know their rules",
    "start": "1853039",
    "end": "1860000"
  },
  {
    "text": "exactly you know that's that's the way I look at it you you you touched on synthetic data and this also contrasts",
    "start": "1860000",
    "end": "1867279"
  },
  {
    "start": "1862000",
    "end": "2095000"
  },
  {
    "text": "with if you're using a large language model to generate that synthetic data that didn't have Yes those nuances yes",
    "start": "1867279",
    "end": "1875919"
  },
  {
    "text": "how is synthetic data useful in that scenario yeah it's it's it can be a vicious cir",
    "start": "1875919",
    "end": "1881760"
  },
  {
    "text": "it's like madco disease you know there's a risk uh you know feeding AI models too",
    "start": "1881760",
    "end": "1888720"
  },
  {
    "text": "much AI generated data you know when does that go wrong so I think you know I",
    "start": "1888720",
    "end": "1895440"
  },
  {
    "text": "think I think synthetic data is is a good way to multiply and diversify your data so",
    "start": "1895440",
    "end": "1904320"
  },
  {
    "text": "let you can ask your domain experts let's say you work at a telco or or bank",
    "start": "1904320",
    "end": "1909360"
  },
  {
    "text": "you know you can ask them okay what are the top 100 questions that our customers are asking you know then and then and",
    "start": "1909360",
    "end": "1916320"
  },
  {
    "text": "that our chatbot should be you know perfect they they'll come up with that you know everybody knows that and and",
    "start": "1916320",
    "end": "1923760"
  },
  {
    "text": "and you can write those now it's probably the 100 topics right but",
    "start": "1923760",
    "end": "1930120"
  },
  {
    "text": "again take 10 people in the street and tell them \"Okay you lost your credit",
    "start": "1930120",
    "end": "1935480"
  },
  {
    "text": "card how would you ask you know what would you ask your support app?\" Or you",
    "start": "1935480",
    "end": "1941120"
  },
  {
    "text": "want you're moving and you want to change the address on your phone bill or you know that kind of stuff even simple",
    "start": "1941120",
    "end": "1947679"
  },
  {
    "text": "questions people will have a very different way of asking them and and not",
    "start": "1947679",
    "end": "1953039"
  },
  {
    "text": "not everyone is a native speaker as well right even with text I'm not even discussing voice and accents but um so",
    "start": "1953039",
    "end": "1962080"
  },
  {
    "text": "uh so you know I I don't speak Arabic but let's say I if I was a basic Arabic speaker I would probably ask the",
    "start": "1962080",
    "end": "1968000"
  },
  {
    "text": "question in a very you know childish way you would ask it in a more elaborate way",
    "start": "1968000",
    "end": "1973679"
  },
  {
    "text": "obviously but I'm still looking for the same answer so models are great at doing",
    "start": "1973679",
    "end": "1979919"
  },
  {
    "text": "that uh you can tell them okay this top this question rewrite you know 50",
    "start": "1979919",
    "end": "1985360"
  },
  {
    "text": "versions of it accounting for I don't know anything you're",
    "start": "1985360",
    "end": "1990480"
  },
  {
    "text": "interested in you know cultural level or age you know how does a teenager ask that question how does a a senior person",
    "start": "1990480",
    "end": "1998320"
  },
  {
    "text": "ask that question etc etc so if you if you do it like that I think I think it's",
    "start": "1998320",
    "end": "2003840"
  },
  {
    "text": "actually very useful um and it's it helps you you know enrich and",
    "start": "2003840",
    "end": "2009760"
  },
  {
    "text": "complete your data sets in in in so in in in shorter time uh generating net new",
    "start": "2009760",
    "end": "2017919"
  },
  {
    "text": "data from scratch and relying too heavily on it um makes me you know makes",
    "start": "2017919",
    "end": "2024480"
  },
  {
    "text": "me nervous um because if that large model you're using to to do the enrichment and and",
    "start": "2024480",
    "end": "2032000"
  },
  {
    "text": "the generation if that model has a bias then",
    "start": "2032000",
    "end": "2037360"
  },
  {
    "text": "you know you're just it's it's it's in there right uh it's in there and it's very hard to detect and I don't know",
    "start": "2037360",
    "end": "2043360"
  },
  {
    "text": "it's like it's like bad code it's yeah it's difficult to fix it's technical",
    "start": "2043360",
    "end": "2048398"
  },
  {
    "text": "debt and I don't think you want technical debt in your data sets so I I",
    "start": "2048399",
    "end": "2053599"
  },
  {
    "text": "I want again to tackle on different topics so for the synthetic data the",
    "start": "2053599",
    "end": "2060000"
  },
  {
    "text": "point here is to use the large language model and this is the same also for small language model basically using",
    "start": "2060000",
    "end": "2066158"
  },
  {
    "text": "that knowledge that's already available and Get the human in the loop yes oh of",
    "start": "2066159",
    "end": "2071599"
  },
  {
    "text": "course always the Yeah and the tech and probably use several models like if you you know don't rely on on the same one",
    "start": "2071599",
    "end": "2078398"
  },
  {
    "text": "all the time use use different ones so that even if one of them has a slightly weird Yeah take on whatever topic you",
    "start": "2078399",
    "end": "2086000"
  },
  {
    "text": "know it it averages out uh and and be very critical and review them and and",
    "start": "2086000",
    "end": "2091520"
  },
  {
    "text": "yeah be be super critical on what the model is doing okay so let let me double",
    "start": "2091520",
    "end": "2096960"
  },
  {
    "start": "2095000",
    "end": "2193000"
  },
  {
    "text": "click on small language models now um this is an undefined topic",
    "start": "2096960",
    "end": "2104400"
  },
  {
    "text": "so I can give you my definition each person have their own definition i've",
    "start": "2104400",
    "end": "2110160"
  },
  {
    "text": "heard uh thresholds about the parameters about the the compute capacity about all",
    "start": "2110160",
    "end": "2117440"
  },
  {
    "text": "sorts of things uh what to you is a small language model",
    "start": "2117440",
    "end": "2123480"
  },
  {
    "text": "so I my definition and it's not academic and even internally at RC I think people",
    "start": "2123480",
    "end": "2129359"
  },
  {
    "text": "would disagree with me and that's okay you know I love disagreeing and debating my definition is anything you",
    "start": "2129359",
    "end": "2136240"
  },
  {
    "text": "can run on a single accelerator without having to split it",
    "start": "2136240",
    "end": "2141280"
  },
  {
    "text": "and chart it and do complex ML engineering what you can load on a single accelerator to me is is a small",
    "start": "2141280",
    "end": "2148000"
  },
  {
    "text": "language model so you could you could counter that well accelerators get bigger so yeah if if I have an",
    "start": "2148000",
    "end": "2153680"
  },
  {
    "text": "accelerator with 500 gigs of RAM you know is is that a small model so no I",
    "start": "2153680",
    "end": "2160280"
  },
  {
    "text": "think realistically uh you know anything larger than than 70 billions cannot be",
    "start": "2160280",
    "end": "2167200"
  },
  {
    "text": "cannot be called a small language model 70 70 I've heard seven",
    "start": "2167200",
    "end": "2172640"
  },
  {
    "text": "it depends i mean if you're if you're looking at you know what what's the target deployment for that if you're",
    "start": "2172640",
    "end": "2179280"
  },
  {
    "text": "looking at devices you know if you say oh you know I need something to run on phones of course you're looking at",
    "start": "2179280",
    "end": "2185119"
  },
  {
    "text": "singledigit uh billion models but you can very nicely run you know AWS has a",
    "start": "2185119",
    "end": "2192000"
  },
  {
    "text": "wide I'm putting my AWS cap on for a second sorry folks but AWS has a wide",
    "start": "2192000",
    "end": "2197680"
  },
  {
    "start": "2193000",
    "end": "2377000"
  },
  {
    "text": "range of um of accelerated instances okay so from yeah you have lots of",
    "start": "2197680",
    "end": "2204720"
  },
  {
    "text": "different GPUs and then you have you know the the AWS chips tranium and inferential so there's a there's a lot",
    "start": "2204720",
    "end": "2210000"
  },
  {
    "text": "of choice and uh and I'm always coming back to to you know cost efficiency and",
    "start": "2210000",
    "end": "2216880"
  },
  {
    "text": "um when I was at AWS I was telling customers please use the smallest EC2",
    "start": "2216880",
    "end": "2222320"
  },
  {
    "text": "instance you can you can find right uh if you you know if have you used T2 T2",
    "start": "2222320",
    "end": "2229040"
  },
  {
    "text": "micro was my catchphrase and and they were looking at me like I was an idiot and it's like well have you tried it you",
    "start": "2229040",
    "end": "2235280"
  },
  {
    "text": "know look at me and it's like h no I haven't tried it and say Okay try it it's not going to take long and maybe it",
    "start": "2235280",
    "end": "2241359"
  },
  {
    "text": "just works and it's going to cost you a few cents per hour instead of maybe a few dollars per hour and sometimes you",
    "start": "2241359",
    "end": "2247920"
  },
  {
    "text": "would come back to me and say \"Oh yeah well it's actually not bad.\" And okay good you can buy me a coffee now i saved",
    "start": "2247920",
    "end": "2254640"
  },
  {
    "text": "you thousands a month um but but seriously I think it's the same for AI i",
    "start": "2254640",
    "end": "2259680"
  },
  {
    "text": "think you you know obsessing over cost efficiency is is critical and um because",
    "start": "2259680",
    "end": "2265680"
  },
  {
    "text": "it's AI is all about scale m it's AI is all about automating things and",
    "start": "2265680",
    "end": "2273400"
  },
  {
    "text": "accelerating so maybe completely automating them end to end document processing you know or it's about",
    "start": "2273400",
    "end": "2280839"
  },
  {
    "text": "augmenting uh you know u business users or or developers right code generation",
    "start": "2280839",
    "end": "2288160"
  },
  {
    "text": "you know it's very very a very cool technique I use it every day um but you know um helping people just be more",
    "start": "2288160",
    "end": "2294960"
  },
  {
    "text": "productive and spend more time on what matters and get help them get rid of those silly you know low value tasks and",
    "start": "2294960",
    "end": "2304480"
  },
  {
    "text": "and free time to focus on what matters right so if doctors can spend less time",
    "start": "2304480",
    "end": "2310839"
  },
  {
    "text": "typing you know reports or reading reports and if they can spend more time with the patient great same for teachers",
    "start": "2310839",
    "end": "2317760"
  },
  {
    "text": "same for a lot of jobs actually more facetime with humans and less time on paperwork okay so if AI can do that",
    "start": "2317760",
    "end": "2324560"
  },
  {
    "text": "that's good but that means if it works you know it needs needs to scale and you need to free as much time as possible",
    "start": "2324560",
    "end": "2331599"
  },
  {
    "text": "for for humans to do their thing so cost is is you know scale equal costs",
    "start": "2331599",
    "end": "2339040"
  },
  {
    "text": "and and cost equal scale you know if you build AI that's used twice a day in your",
    "start": "2339040",
    "end": "2344320"
  },
  {
    "text": "organization what's the point you know to so you you really need to deploy this",
    "start": "2344320",
    "end": "2349680"
  },
  {
    "text": "to to the to every single in every possible location so the cost needs to",
    "start": "2349680",
    "end": "2354880"
  },
  {
    "text": "be minimal and for the cost to be minimal you need the least amount of infrastructure which for you know um AI",
    "start": "2354880",
    "end": "2362480"
  },
  {
    "text": "means uh the smallest um the smallest compute you can find",
    "start": "2362480",
    "end": "2368720"
  },
  {
    "text": "that gets the job done for for inference so either the smallest GPU or or even",
    "start": "2368720",
    "end": "2374720"
  },
  {
    "text": "CPU i mean I'm I'm a I'm a fan of CPU inference and yes you heard that right",
    "start": "2374720",
    "end": "2381280"
  },
  {
    "start": "2377000",
    "end": "2509000"
  },
  {
    "text": "cpu with a C uh I do a lot of stuff uh a lot of work on on that um and um and you",
    "start": "2381280",
    "end": "2389280"
  },
  {
    "text": "get fascinating results because the models get so small that um you know",
    "start": "2389280",
    "end": "2394640"
  },
  {
    "text": "it's it's it's a positive flywheel again you know Amazon loves flywheel so they get small you can run them on smaller",
    "start": "2394640",
    "end": "2400640"
  },
  {
    "text": "hardware uh because you can run them on smaller hardware you know you can run more of them for the same budget and so",
    "start": "2400640",
    "end": "2406400"
  },
  {
    "text": "you know you just amplify your your AI efforts so yeah small to me I The sweet",
    "start": "2406400",
    "end": "2413359"
  },
  {
    "text": "spot right now is around I would say 10 billion 8 to 10 um but it's it's",
    "start": "2413359",
    "end": "2419040"
  },
  {
    "text": "dropping and uh I can give you an example I mean we released in February I",
    "start": "2419040",
    "end": "2424079"
  },
  {
    "text": "think um a 10 billion parameter model which is called virtuoso light virtuoso",
    "start": "2424079",
    "end": "2429200"
  },
  {
    "text": "are the name uh the name of our general purpose uh models and this model so 10 billion",
    "start": "2429200",
    "end": "2436119"
  },
  {
    "text": "parameters is better than the 70",
    "start": "2436119",
    "end": "2441400"
  },
  {
    "text": "72b 72 billion parameter models were released last July and this one was when",
    "start": "2441400",
    "end": "2447440"
  },
  {
    "text": "it was released in July 24 was the best 72B model available on hugging face okay",
    "start": "2447440",
    "end": "2454880"
  },
  {
    "text": "so can I can I look at you in the eye and say 10B is the new 72B not really",
    "start": "2454880",
    "end": "2460800"
  },
  {
    "text": "because 72B models today are obviously better okay but it means for a lot of",
    "start": "2460800",
    "end": "2467200"
  },
  {
    "text": "business use cases where you would have needed a 72 or maybe a 34 billion",
    "start": "2467200",
    "end": "2472880"
  },
  {
    "text": "parameter model six or nine months ago you can get the same performance today the same business quality from maybe a",
    "start": "2472880",
    "end": "2480800"
  },
  {
    "text": "10 or maybe an 8 billion parameter now and it makes a world of difference in",
    "start": "2480800",
    "end": "2486079"
  },
  {
    "text": "terms of deployment because a 10 billion parameter model can run on the the smallest GPU instance available on AWS i",
    "start": "2486079",
    "end": "2494079"
  },
  {
    "text": "I've seen your uh demos on Graviton yes and you can run them on Graviton if you if you have small scale small scale use",
    "start": "2494079",
    "end": "2500960"
  },
  {
    "text": "cases so that's that's where we are um that's where we are and uh that's yeah",
    "start": "2500960",
    "end": "2506800"
  },
  {
    "text": "that's that's that's my prediction so what what's your uh advice then for",
    "start": "2506800",
    "end": "2512560"
  },
  {
    "start": "2509000",
    "end": "2738000"
  },
  {
    "text": "people starting to run their models how to evaluate the right size the right",
    "start": "2512560",
    "end": "2518720"
  },
  {
    "text": "model and the right infrastructure so I'm not going to say have you tried",
    "start": "2518720",
    "end": "2525599"
  },
  {
    "text": "T2 micro but I'm I'm going to say have you tried the best seven or 8B model",
    "start": "2525599",
    "end": "2531760"
  },
  {
    "text": "available today um go start there i mean there are you",
    "start": "2531760",
    "end": "2538480"
  },
  {
    "text": "have smaller models like you know you have Google GMA models that are very good or you know five models from Microsoft that are very good and a bit",
    "start": "2538480",
    "end": "2544960"
  },
  {
    "text": "smaller but I would say okay let's not be extreme let's be reasonable let's",
    "start": "2544960",
    "end": "2550880"
  },
  {
    "text": "start at seven eight uh run them on the smallest uh GPU",
    "start": "2550880",
    "end": "2558800"
  },
  {
    "text": "instance on AWS which is going to cost you something like a dollar an hour",
    "start": "2558800",
    "end": "2565839"
  },
  {
    "text": "uh maybe a dollar10 But that's the price range so the cost of experimentation is is very low and and you know build if",
    "start": "2565839",
    "end": "2574960"
  },
  {
    "text": "you have evaluation data sets if you already have Q&A uh data sets that reflect what your users would be doing",
    "start": "2574960",
    "end": "2581599"
  },
  {
    "text": "okay go and run that score uh with your uh internal metrics and of course do",
    "start": "2581599",
    "end": "2588079"
  },
  {
    "text": "human review as you said you know human in the loop ask your domain experts to look at the answers and tell you what",
    "start": "2588079",
    "end": "2594640"
  },
  {
    "text": "they think and if if if it's good I mean try shrinking if it works with the",
    "start": "2594640",
    "end": "2602960"
  },
  {
    "text": "7B or an 8B model try five try three take the best ones available",
    "start": "2602960",
    "end": "2609640"
  },
  {
    "text": "today 3b today goes a long way all right",
    "start": "2609640",
    "end": "2615720"
  },
  {
    "text": "so when when should you try graviton in production I think you should try so",
    "start": "2615720",
    "end": "2625640"
  },
  {
    "text": "um so first of all there are some scenarios where you have no GPUs",
    "start": "2626119",
    "end": "2631520"
  },
  {
    "text": "okay so some regions some some AWS regions and this is constantly in flux",
    "start": "2631520",
    "end": "2637599"
  },
  {
    "text": "okay but some AWS regions are not GPU rich okay let's put it this way so maybe",
    "start": "2637599",
    "end": "2644720"
  },
  {
    "text": "you don't have the latest generation of GPU instances maybe you have very few and It's very as a smaller customer it's",
    "start": "2644720",
    "end": "2651359"
  },
  {
    "text": "very difficult to to get you know quota you know I everybody's trying their best",
    "start": "2651359",
    "end": "2656880"
  },
  {
    "text": "I know and I know capacity planning is very hard so it's not a cheap shot at anyone it's just the reality you know",
    "start": "2656880",
    "end": "2662480"
  },
  {
    "text": "it's difficult to have the the right amount available everywhere all the time",
    "start": "2662480",
    "end": "2667680"
  },
  {
    "text": "for everyone okay it's a it's a it's a limited universe so there are some",
    "start": "2667680",
    "end": "2673280"
  },
  {
    "text": "regions where you cannot do that there are some scenarios and I know they're not for yes but there are scenarios where you're not in in the cloud you",
    "start": "2673280",
    "end": "2680079"
  },
  {
    "text": "know maybe you're uh you know maybe you have a chain of uh restaurants or uh",
    "start": "2680079",
    "end": "2686160"
  },
  {
    "text": "supermarkets and and you have a server or a you know you have a half an telco",
    "start": "2686160",
    "end": "2692400"
  },
  {
    "text": "rack somewhere in there and there's a server and you wondering whether you could run something locally okay uh so",
    "start": "2692400",
    "end": "2699359"
  },
  {
    "text": "the edge and of course you have devices okay so there there's a whole universe that doesn't really have GPUs and and in",
    "start": "2699359",
    "end": "2707839"
  },
  {
    "text": "that case um well if you have the right type of CPU and if you know how to",
    "start": "2707839",
    "end": "2714640"
  },
  {
    "text": "optimize models you can get really good results you know graviton are based on ARM uh technology so generally ARM ARM",
    "start": "2714640",
    "end": "2722960"
  },
  {
    "text": "CPUs are uh you know well supported by uh open",
    "start": "2722960",
    "end": "2728000"
  },
  {
    "text": "source tool to optimize models you mentioned quantization you know shrinking models so there's a whole bunch of techniques that that apply but",
    "start": "2728000",
    "end": "2735920"
  },
  {
    "text": "even you know coming back to my beloved cloud I think there are scenarios where",
    "start": "2735920",
    "end": "2741960"
  },
  {
    "start": "2738000",
    "end": "2882000"
  },
  {
    "text": "um it makes sense not to use GPUs uh you know everybody loves microservices and",
    "start": "2741960",
    "end": "2749040"
  },
  {
    "text": "everybody loves you know scale out etc and fine so and I see customers who are",
    "start": "2749040",
    "end": "2754640"
  },
  {
    "text": "building those kubernetes clusters with microservices and it's very nice and neat and you looks great hopefully it",
    "start": "2754640",
    "end": "2760880"
  },
  {
    "text": "runs great too but it looks great and then they send all the AI inference traffic to this huge single point of",
    "start": "2760880",
    "end": "2767680"
  },
  {
    "text": "failure into a single GPU instance or a couple and they only have a couple because they are expensive and they're",
    "start": "2767680",
    "end": "2773520"
  },
  {
    "text": "difficult to procure etc so I'm like oh no you know you everything was well",
    "start": "2773520",
    "end": "2779200"
  },
  {
    "text": "architected and then bam you you have this huge single point of failure so is",
    "start": "2779200",
    "end": "2785040"
  },
  {
    "text": "that really necessary can we not scale out inference in the same way can we not",
    "start": "2785040",
    "end": "2790880"
  },
  {
    "text": "for small scale workloads can we not embed maybe the models the optimized",
    "start": "2790880",
    "end": "2797400"
  },
  {
    "text": "SLMs on the same instances that run the application code",
    "start": "2797400",
    "end": "2802560"
  },
  {
    "text": "you know it's of course if you need 10,000 hits uh 10,000 inferences per",
    "start": "2802560",
    "end": "2807760"
  },
  {
    "text": "second of course this won't work but not everyone needs that and and and and you",
    "start": "2807760",
    "end": "2813920"
  },
  {
    "text": "know maybe sometimes you just need that local friendly uh model to do something",
    "start": "2813920",
    "end": "2819359"
  },
  {
    "text": "for you small scale and you can run this in place instead of having that GPU",
    "start": "2819359",
    "end": "2824400"
  },
  {
    "text": "instance even a small one that sits idle 99% of the time waiting for you to need",
    "start": "2824400",
    "end": "2829680"
  },
  {
    "text": "it but costing you money all the time so there are lots of I mean I keep saying there's a whole arch there's a GPUless",
    "start": "2829680",
    "end": "2837079"
  },
  {
    "text": "architecture to be invented so uh you know I'm putting the word out uh if folks are interested they know where to",
    "start": "2837079",
    "end": "2843520"
  },
  {
    "text": "find me and yes we'll still need GPUs and we'll still we'll need them from",
    "start": "2843520",
    "end": "2848640"
  },
  {
    "text": "different providers hopefully and we'll need the accelerators like Tranium and Inferentia we need all the options we",
    "start": "2848640",
    "end": "2855040"
  },
  {
    "text": "can we can get and because again we need the right tool for the job right there",
    "start": "2855040",
    "end": "2860640"
  },
  {
    "text": "is no single technical solution to anything sorry there's this famous paper there is no silver bullet",
    "start": "2860640",
    "end": "2867000"
  },
  {
    "text": "1986 i encourage you to read it it was true in in the 70s it was true in the",
    "start": "2867000",
    "end": "2873440"
  },
  {
    "text": "80s it was true in the 90s it'll be true when I'm long gone okay there is no",
    "start": "2873440",
    "end": "2878480"
  },
  {
    "text": "single tech solution to everything you you you mentioned you touched on the",
    "start": "2878480",
    "end": "2883520"
  },
  {
    "start": "2882000",
    "end": "3348000"
  },
  {
    "text": "hardware part and obviously for small language models edge scenarios are a",
    "start": "2883520",
    "end": "2889440"
  },
  {
    "text": "must sure but even when training uh models uh in the cloud um at rci you use",
    "start": "2889440",
    "end": "2898480"
  },
  {
    "text": "trrenium you reduced your cost by something like 98% yeah we we did use",
    "start": "2898480",
    "end": "2903760"
  },
  {
    "text": "tranium for uh for one of our uh customer projects um and yeah generally we uh",
    "start": "2903760",
    "end": "2910319"
  },
  {
    "text": "we've we've used and we're still using SageMaker HyperPod too mhm um what what",
    "start": "2910319",
    "end": "2917920"
  },
  {
    "text": "kind of so there is um the change from if you've been using CUDA uh in the past",
    "start": "2917920",
    "end": "2926240"
  },
  {
    "text": "yeah and need to change that uh there is also a learning curve how did you do",
    "start": "2926240",
    "end": "2932319"
  },
  {
    "text": "that what what do you advise people moving to so I think it's um I think there are two there are two",
    "start": "2932319",
    "end": "2939680"
  },
  {
    "text": "questions here the first one is how difficult is it to run large",
    "start": "2939680",
    "end": "2946240"
  },
  {
    "text": "training at at scale and the the answer is more than you",
    "start": "2946240",
    "end": "2952559"
  },
  {
    "text": "think uh and even on AWS uh you know which is rock solid as",
    "start": "2952559",
    "end": "2959760"
  },
  {
    "text": "we know and I've experienced it stuff breaks you know and when you run",
    "start": "2959760",
    "end": "2966079"
  },
  {
    "text": "hundreds or possibly thousands of GPUs over extended period of",
    "start": "2966079",
    "end": "2972280"
  },
  {
    "text": "times you know they die you know GPUs die instances go you know crazy and",
    "start": "2972280",
    "end": "2979680"
  },
  {
    "text": "become unreachable you know and and the problem is that you know the distributed",
    "start": "2979680",
    "end": "2985200"
  },
  {
    "text": "nature of those training jobs um makes makes them very fragile to any kind of",
    "start": "2985200",
    "end": "2991640"
  },
  {
    "text": "disruption so yes you can you can use checkpointing and yes you can you know",
    "start": "2991640",
    "end": "2996880"
  },
  {
    "text": "restart the job from the last checkpoint which could be hours ago or days ago",
    "start": "2996880",
    "end": "3004480"
  },
  {
    "text": "so but it's just extra overhead it's it's it's it's uh you know it's",
    "start": "3004480",
    "end": "3010079"
  },
  {
    "text": "difficult so I think hyperplot is interesting in that sense um and and you",
    "start": "3010079",
    "end": "3015760"
  },
  {
    "text": "know we were we were using it at at a hugging face as well because it it takes for the long",
    "start": "3015760",
    "end": "3021960"
  },
  {
    "text": "running you know sizable training jobs which not everybody runs um but the the",
    "start": "3021960",
    "end": "3028480"
  },
  {
    "text": "cluster management infrastructure is is is valuable just like you know when you",
    "start": "3028480",
    "end": "3034160"
  },
  {
    "text": "use ECS or EKS lots of things happen under the hood and yes you could run",
    "start": "3034160",
    "end": "3040720"
  },
  {
    "text": "your Docker cluster on EC2 and manage every tiny thing yourself but hey",
    "start": "3040720",
    "end": "3046400"
  },
  {
    "text": "service teams have done it okay um and I think they know what they're doing so so",
    "start": "3046400",
    "end": "3051440"
  },
  {
    "text": "you know the the the managed service story still works for training so hyper",
    "start": "3051440",
    "end": "3056640"
  },
  {
    "text": "pod But what problem does that solve for you obviously hardware fails and especially in training you have high",
    "start": "3056640",
    "end": "3063920"
  },
  {
    "text": "energy coming in high training jobs high CP high GPU usage yeah yeah sure so what",
    "start": "3063920",
    "end": "3069359"
  },
  {
    "text": "what does Hyperbot for people that does not know about Hyperbot sagemaker Hyperbot so I would say it's really it's",
    "start": "3069359",
    "end": "3075280"
  },
  {
    "text": "it's um it it's managing you know it's managing failures and restarts and and",
    "start": "3075280",
    "end": "3082720"
  },
  {
    "text": "it gives you you know monitoring and and observability into into large training",
    "start": "3082720",
    "end": "3088640"
  },
  {
    "text": "jobs which which yes you could build yourself but again uh is that is that",
    "start": "3088640",
    "end": "3094319"
  },
  {
    "text": "where the value lies i mean do you want to spend more time you know curating your data and and you know improving the",
    "start": "3094319",
    "end": "3101920"
  },
  {
    "text": "model or do you want to reinvent the wheel and I know I know what my answer",
    "start": "3101920",
    "end": "3107599"
  },
  {
    "text": "is you know and again I'm an engineer I love to build stuff but um you know your",
    "start": "3107599",
    "end": "3112800"
  },
  {
    "text": "primary mission is deliver a great model and uh and the elasticity and the res the resilience of hyperpod is is",
    "start": "3112800",
    "end": "3120480"
  },
  {
    "text": "valuable and when it comes to tranium I think tranium is a is an interesting option There is a learning curve you",
    "start": "3120480",
    "end": "3126559"
  },
  {
    "text": "know I'm I'm known for being brutally honest so there is a learning curve and",
    "start": "3126559",
    "end": "3132559"
  },
  {
    "text": "I'm brutally honest with the with the trainium team and and they're patient and they're they're listening uh but",
    "start": "3132559",
    "end": "3139359"
  },
  {
    "text": "there is a learning curve so I would say uh it generally if you work",
    "start": "3139359",
    "end": "3145319"
  },
  {
    "text": "with well-known architectures okay so you have a llama model or you have a you",
    "start": "3145319",
    "end": "3150640"
  },
  {
    "text": "know I don't know mistral model whatever you know something that is that has been out for a while and and that is well",
    "start": "3150640",
    "end": "3157760"
  },
  {
    "text": "supported well understood the learning curve is not that bad okay uh the learning curve is",
    "start": "3157760",
    "end": "3164880"
  },
  {
    "text": "not that bad you'll find some notebooks you'll find some examples and um and you",
    "start": "3164880",
    "end": "3171280"
  },
  {
    "text": "can you can you can train and and of course you will get support from your uh your account team etc so we've had some",
    "start": "3171280",
    "end": "3178640"
  },
  {
    "text": "you know we've had some successes we've had some failures and I've been you know longtime supporter of uh of training and",
    "start": "3178640",
    "end": "3185839"
  },
  {
    "text": "inferial i think no one has no one has more content out there than I have but",
    "start": "3185839",
    "end": "3192240"
  },
  {
    "text": "you know I think that gives me the right to complain from time to time but why should new",
    "start": "3192240",
    "end": "3199119"
  },
  {
    "text": "um startups do that learning curve what's the I think if you're if you're",
    "start": "3199119",
    "end": "3205119"
  },
  {
    "text": "looking for uh If you're looking for cost efficiency",
    "start": "3205119",
    "end": "3211160"
  },
  {
    "text": "um and and scaling you know you'll get it it's fair to say it's easier for AWS",
    "start": "3211160",
    "end": "3218319"
  },
  {
    "text": "to give you access to a a good number of tranium or",
    "start": "3218319",
    "end": "3224160"
  },
  {
    "text": "inferential chips um than it is for them to give you access to the latest P5 instances right",
    "start": "3224160",
    "end": "3231920"
  },
  {
    "text": "m um because on on on the former you know they have full control they build",
    "start": "3231920",
    "end": "3238800"
  },
  {
    "text": "the chips they deploy them they optimize them so the you know the value chain is shorter",
    "start": "3238800",
    "end": "3244800"
  },
  {
    "text": "um they have a strong incentive to be successful there and the latter well all depends on the Nvidia uh supply chain",
    "start": "3244800",
    "end": "3252400"
  },
  {
    "text": "which can be complicated at times um and and you know well obviously",
    "start": "3252400",
    "end": "3258319"
  },
  {
    "text": "Amazon is is training a lot of models themselves So they have experience doing that um and that was factored in you",
    "start": "3258319",
    "end": "3265599"
  },
  {
    "text": "know tranium as well so the the cost benefits are are real um you know we've",
    "start": "3265599",
    "end": "3273680"
  },
  {
    "text": "I saw them personally i mean I I saw them in organizations that I worked at i",
    "start": "3273680",
    "end": "3278720"
  },
  {
    "text": "heard it from customers um so if you're um if you're looking to cost optimize",
    "start": "3278720",
    "end": "3285040"
  },
  {
    "text": "from day one I think it's it's an interesting it's an interesting option if you really struggle with getting",
    "start": "3285040",
    "end": "3291280"
  },
  {
    "text": "access to the latest and greatest GPUs um well know that there are plenty of",
    "start": "3291280",
    "end": "3298000"
  },
  {
    "text": "Tranium chips depending on your region again I'm not uh I'm not up to speed on",
    "start": "3298000",
    "end": "3303520"
  },
  {
    "text": "on on the on the Dubai region uh so I wouldn't comment on that uh Trrenium 2",
    "start": "3303520",
    "end": "3309359"
  },
  {
    "text": "came out at reinvent so that's the next level up in terms of performance so yeah",
    "start": "3309359",
    "end": "3314480"
  },
  {
    "text": "it's worth uh it's worth a shot it's worth a shot if you're um if you're if you want to if you want to try something",
    "start": "3314480",
    "end": "3321359"
  },
  {
    "text": "a little bit different and uh and if you know you will have to scale and you want",
    "start": "3321359",
    "end": "3326800"
  },
  {
    "text": "to be independent of uh you know whatever Nvidia decides to",
    "start": "3326800",
    "end": "3332640"
  },
  {
    "text": "do or not to do next week um you know the world is getting complicated uh",
    "start": "3332640",
    "end": "3338559"
  },
  {
    "text": "there were some announcements today on on you know GPU exports that are a little bit worry and worrying so you",
    "start": "3338559",
    "end": "3346160"
  },
  {
    "text": "never know so be before we end I want to get some of your long long experience",
    "start": "3346160",
    "end": "3352319"
  },
  {
    "start": "3348000",
    "end": "3734000"
  },
  {
    "text": "working on AWS and if you talk today to",
    "start": "3352319",
    "end": "3357359"
  },
  {
    "text": "a new startup a public sector organization an enterprise starting from",
    "start": "3357359",
    "end": "3362480"
  },
  {
    "text": "scratch yes um I want to hear from you the the good the bad and the ugly what",
    "start": "3362480",
    "end": "3368720"
  },
  {
    "text": "things should they be looking at when building on AWS AI workloads",
    "start": "3368720",
    "end": "3375839"
  },
  {
    "text": "so I would say don't number one I don't know if",
    "start": "3375839",
    "end": "3381520"
  },
  {
    "text": "it's good bad or ugly but it's don't treat AI differently from your typical",
    "start": "3381520",
    "end": "3389119"
  },
  {
    "text": "software engineering efforts a model endpoint is an API you",
    "start": "3389119",
    "end": "3395200"
  },
  {
    "text": "know for all for all I know it's just another micros service okay so it's not different this",
    "start": "3395200",
    "end": "3401920"
  },
  {
    "text": "time it's it's never different this time so again you know cost scaling",
    "start": "3401920",
    "end": "3410400"
  },
  {
    "text": "monitoring uh observability security",
    "start": "3410400",
    "end": "3416799"
  },
  {
    "text": "uh compliance all the stuff that people don't want to focus on is what you",
    "start": "3416799",
    "end": "3425359"
  },
  {
    "text": "should focus on from day one because if you're just building and ignoring all the things I",
    "start": "3425359",
    "end": "3432040"
  },
  {
    "text": "said great you know um but it it will come and bite you at the worst possible",
    "start": "3432040",
    "end": "3439200"
  },
  {
    "text": "time i've seen so many customers you know coming and say ah you know we're",
    "start": "3439200",
    "end": "3445119"
  },
  {
    "text": "you know we we were fine in the sandbox but now in production yeah we're spending this or or we realize you know",
    "start": "3445119",
    "end": "3452160"
  },
  {
    "text": "we have this security thing that you know uh we have to implement in prod and",
    "start": "3452160",
    "end": "3457520"
  },
  {
    "text": "it's breaking the architecture like you have to not don't design for the sandbox",
    "start": "3457520",
    "end": "3462799"
  },
  {
    "text": "don't design for the P everything works in the sandbox okay",
    "start": "3462799",
    "end": "3468079"
  },
  {
    "text": "design for fraud for day one and that means talk to all the not really fun",
    "start": "3468079",
    "end": "3475839"
  },
  {
    "text": "people who will have to sign off on your deployment and even if you're a startup",
    "start": "3475839",
    "end": "3481920"
  },
  {
    "text": "maybe you don't have a compliance team and maybe you don't have a security officer but come on you you I mean you",
    "start": "3481920",
    "end": "3490079"
  },
  {
    "text": "know what to do you you know nobody wants to eat their vegetables but don't don't make",
    "start": "3490079",
    "end": "3499079"
  },
  {
    "text": "anybody you know don't make any don't make anybody force you to eat them because it will be at the worst possible",
    "start": "3499079",
    "end": "3505599"
  },
  {
    "text": "time it will be you know one week before you a round or something and you have a security problem and it makes the news",
    "start": "3505599",
    "end": "3511839"
  },
  {
    "text": "and you know so that's always my advice um there's way more to to building on",
    "start": "3511839",
    "end": "3519839"
  },
  {
    "text": "the cloud than just you clicking in the console and and and running like there's",
    "start": "3519839",
    "end": "3524960"
  },
  {
    "text": "no no tomorrow you you have all the tools you need on AWS to to implement",
    "start": "3524960",
    "end": "3530000"
  },
  {
    "text": "you know cost management and compliance and you know reasonable security from day one you know um and",
    "start": "3530000",
    "end": "3537839"
  },
  {
    "text": "when in doubt ask your essays i think that's probably advice number two um and",
    "start": "3537839",
    "end": "3543599"
  },
  {
    "text": "I'm sorry for saying this but you know solution architects are free they come for free they're here to help",
    "start": "3543599",
    "end": "3551200"
  },
  {
    "text": "uh they're not here to sell you more they're probably here to actually help",
    "start": "3551200",
    "end": "3557040"
  },
  {
    "text": "you spend less and do things right uh and and they've seen enough startups",
    "start": "3557040",
    "end": "3563680"
  },
  {
    "text": "to understand what is reasonable uh on your first few months of existence and",
    "start": "3563680",
    "end": "3569680"
  },
  {
    "text": "they'll start telling you after a little while that maybe you need to look at well architected reviews etc etc and and",
    "start": "3569680",
    "end": "3577359"
  },
  {
    "text": "and yes and uh again you know uh they know they know better they've seen",
    "start": "3577359",
    "end": "3584000"
  },
  {
    "text": "hundreds of uh of customers you know you you've seen hundreds of customers maybe more so you've seen those mistakes uh",
    "start": "3584000",
    "end": "3592400"
  },
  {
    "text": "you know when good enough is good enough and when it's not anymore yes um there",
    "start": "3592400",
    "end": "3599119"
  },
  {
    "text": "are some mistakes that will not kill a seed stage company uh there are mistakes",
    "start": "3599119",
    "end": "3606240"
  },
  {
    "text": "that will kill a series A or a series B company and and sometimes you don't know",
    "start": "3606240",
    "end": "3612480"
  },
  {
    "text": "because you've been so busy building so trust the teams",
    "start": "3612480",
    "end": "3617640"
  },
  {
    "text": "and automate automate automate automate don't click in the console please please",
    "start": "3617640",
    "end": "3625079"
  },
  {
    "text": "please so I don't care if you use cloud for I don't care if you use Terraform i",
    "start": "3625079",
    "end": "3630400"
  },
  {
    "text": "don't care if you use anything else but please automate you know immutable infrastructure and all that good stuff",
    "start": "3630400",
    "end": "3637920"
  },
  {
    "text": "again you know if you're not doing that you're you're making your life more difficult today tomorrow and forever and",
    "start": "3637920",
    "end": "3647359"
  },
  {
    "text": "you know right size right size right size so AWS consultants listening to me",
    "start": "3647359",
    "end": "3653359"
  },
  {
    "text": "will hate me for saying this because they have a really good business coming in and just you know solving the top",
    "start": "3653359",
    "end": "3660359"
  },
  {
    "text": "10 spending problems that a lot of customers do but again um there are lots",
    "start": "3660359",
    "end": "3666319"
  },
  {
    "text": "of silly things that uh you should avoid and and and spend too much on so I think",
    "start": "3666319",
    "end": "3672880"
  },
  {
    "text": "that's that's really you know that's really what I want to say uh eat your vegetables from day one",
    "start": "3672880",
    "end": "3680200"
  },
  {
    "text": "automate cost optimize and talk to and talk to it please please talk to essays",
    "start": "3680200",
    "end": "3686000"
  },
  {
    "text": "essays are the best you know I've met a lot of people at AWS and I'll go on record",
    "start": "3686000",
    "end": "3692359"
  },
  {
    "text": "but and okay feel free to disagree i don't think I ever met a solution",
    "start": "3692359",
    "end": "3698000"
  },
  {
    "text": "architect that I felt was bad i had a lot of fun with different AWS teams that",
    "start": "3698000",
    "end": "3703200"
  },
  {
    "text": "shall remain um unknown essays are are the best so if",
    "start": "3703200",
    "end": "3708799"
  },
  {
    "text": "you're not using them I keep them busy and they will help you more than you can think with that I think uh we're good",
    "start": "3708799",
    "end": "3717520"
  },
  {
    "text": "thank you very much it was really a pleasure talking it's a pleasure to again be there and uh and get a chance",
    "start": "3717520",
    "end": "3723440"
  },
  {
    "text": "to to uh to speak even virtually with with your audience i hope this was this",
    "start": "3723440",
    "end": "3729200"
  },
  {
    "text": "was useful it was very useful to me at least thank you so that brings us to the",
    "start": "3729200",
    "end": "3735040"
  },
  {
    "start": "3734000",
    "end": "3788000"
  },
  {
    "text": "end of today's fascinating episode of AWS for AI if you're interested in",
    "start": "3735040",
    "end": "3740319"
  },
  {
    "text": "learning more from Julian and RCI you can check out Julian's YouTube channel",
    "start": "3740319",
    "end": "3746000"
  },
  {
    "text": "and RCI website you can find links in our show notes along with resources for",
    "start": "3746000",
    "end": "3752079"
  },
  {
    "text": "exploring AWS services that we mentioned today don't forget to subscribe to AWS",
    "start": "3752079",
    "end": "3757680"
  },
  {
    "text": "forAI on your favorite podcast platform and leave us your feedback and thoughts",
    "start": "3757680",
    "end": "3763040"
  },
  {
    "text": "about today's discussion until next time this is Hamza Mimi",
    "start": "3763040",
    "end": "3768960"
  },
  {
    "text": "thanking you for listening keep exploring keep innovating and we'll",
    "start": "3768960",
    "end": "3774319"
  },
  {
    "text": "catch you on our next episode",
    "start": "3774319",
    "end": "3778680"
  },
  {
    "text": "[Music]",
    "start": "3783990",
    "end": "3788600"
  }
]
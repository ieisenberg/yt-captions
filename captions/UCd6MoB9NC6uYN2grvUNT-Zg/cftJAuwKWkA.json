[
  {
    "start": "0",
    "end": "78000"
  },
  {
    "text": "uh so thank you everybody for coming um my name is Leo dur and I'm a principal engineer in the AWS deep learning group",
    "start": "160",
    "end": "7600"
  },
  {
    "text": "and today uh I'm going to be talking to you about using mxnet our deep learning framework of choice for building",
    "start": "7600",
    "end": "14559"
  },
  {
    "text": "recommendations models at scale uh and uh in this session I hope to offer",
    "start": "14559",
    "end": "21400"
  },
  {
    "text": "something to everybody here even if you just barely heard of machine learning and don't really know how it works or uh",
    "start": "21400",
    "end": "28400"
  },
  {
    "text": "if you've been building deep learning models for a while and know a whole lot about neural networks I hope that uh",
    "start": "28400",
    "end": "33680"
  },
  {
    "text": "there's going to be something that everybody learns along the way and the converse of that is that there's some parts that you know not everybody's",
    "start": "33680",
    "end": "40399"
  },
  {
    "text": "going to appreciate but if we get to the end and you haven't learned anything uh come talk to me because I'd love to get",
    "start": "40399",
    "end": "46280"
  },
  {
    "text": "your take on uh on everything that I'm talking about here we're going to uh start out talking about machine learning",
    "start": "46280",
    "end": "51680"
  },
  {
    "text": "systems and recommender systems in general uh show you how to implement those using mxet on the P2 instances uh",
    "start": "51680",
    "end": "59559"
  },
  {
    "text": "using the Deep learning Ami and then go through uh three or four different kinds",
    "start": "59559",
    "end": "65280"
  },
  {
    "text": "of recommender systems and show you how to build each of them uh using mxnet uh",
    "start": "65280",
    "end": "70479"
  },
  {
    "text": "and along the way we're going to pick up some tricks for handling sparse data sets in mxnet and we'll tell you uh more",
    "start": "70479",
    "end": "76640"
  },
  {
    "text": "about what that means if you're not familiar with the term so to start with uh recommender systems and machine",
    "start": "76640",
    "end": "83000"
  },
  {
    "start": "78000",
    "end": "164000"
  },
  {
    "text": "learning so recommender systems uh kind of got their popular start with the Netflix prize in 2006 so is a great",
    "start": "83000",
    "end": "90680"
  },
  {
    "text": "customer of AWS and in 2006 they released a data set of movies that",
    "start": "90680",
    "end": "97200"
  },
  {
    "text": "people had watched and what they uh what customers had rated them and they offered a prize of a million dollars to",
    "start": "97200",
    "end": "104040"
  },
  {
    "text": "anybody who could outperform the recommender system that they had in house by more than 10% and it took three",
    "start": "104040",
    "end": "110000"
  },
  {
    "text": "years for anybody to claim that price they offered some uh some smaller prices along the way but this really uh set the",
    "start": "110000",
    "end": "116640"
  },
  {
    "text": "stage for a lot of the research that happened uh in scientific communities on recommender systems uh and so",
    "start": "116640",
    "end": "123240"
  },
  {
    "text": "recommending movies is kind of a staple and so how you frame that problem is uh",
    "start": "123240",
    "end": "129119"
  },
  {
    "text": "there there are a number of ways to do it but the way Netflix uh prize described it is pretty typical which is",
    "start": "129119",
    "end": "134200"
  },
  {
    "text": "to predict what star rating uh a user will give to a particular movie and so",
    "start": "134200",
    "end": "139800"
  },
  {
    "text": "to put that in code you can imagine a function which returns a floating Point number on the range of one to five for",
    "start": "139800",
    "end": "145239"
  },
  {
    "text": "for the number of stars uh that takes in a user and a movie Object",
    "start": "145239",
    "end": "150280"
  },
  {
    "text": "and somehow makes a prediction the question is how do you make that prediction what do you do with this user",
    "start": "150280",
    "end": "155840"
  },
  {
    "text": "object and this movie Object to to come up with uh with that number and well the answer is uh is machine learning so you",
    "start": "155840",
    "end": "163720"
  },
  {
    "text": "you use machine learning to come up with this model and then you run the model and you feed it in the user in the movie",
    "start": "163720",
    "end": "169360"
  },
  {
    "text": "Object and it gives you this floating Point number okay so what's that process like so very roughly you start with some",
    "start": "169360",
    "end": "176159"
  },
  {
    "text": "training data which are examples of the correct answer what is this what do you",
    "start": "176159",
    "end": "181280"
  },
  {
    "text": "want this system to do given a set of users in movies what what number do you want it to give out you run that through",
    "start": "181280",
    "end": "187799"
  },
  {
    "text": "a set a complex math that's really Compu intensive to get the uh to get the training um that process is called",
    "start": "187799",
    "end": "194120"
  },
  {
    "text": "training then you get the model and once you have the model you put that into production and you feed in the input",
    "start": "194120",
    "end": "199599"
  },
  {
    "text": "data and what comes out are predictions so these predictions come out you get a number and it's very",
    "start": "199599",
    "end": "205879"
  },
  {
    "text": "natural to ask the question how good is your model like is this meaningful is this useful uh and so the",
    "start": "205879",
    "end": "213959"
  },
  {
    "text": "understanding how you measure that is critical to any machine Learning System and what is typically done is you take all of your labeled data and labels are",
    "start": "213959",
    "end": "221120"
  },
  {
    "text": "the correct answers that you're trying to predict with the system and you divide it into a park you use most of it",
    "start": "221120",
    "end": "226200"
  },
  {
    "text": "as your training data but you leave a chunk of it off to the side and you put that training data through the training",
    "start": "226200",
    "end": "232200"
  },
  {
    "text": "system you come up with this trial model and once you have the trial model you take the remaining data you'd set aside",
    "start": "232200",
    "end": "237799"
  },
  {
    "text": "and we call that your test data your validation data means the same thing subtle difference but we'll treat them",
    "start": "237799",
    "end": "243000"
  },
  {
    "text": "the same here uh and you put that test data through your trial model and you",
    "start": "243000",
    "end": "248599"
  },
  {
    "text": "get an evaluation result and now something really interesting happens at this point because on that test data it",
    "start": "248599",
    "end": "255519"
  },
  {
    "text": "the so the trial model has never seen this data right you held it back and you you need to make sure that it has no",
    "start": "255519",
    "end": "261000"
  },
  {
    "text": "access to it so you can't cheat uh and your model when you when you feed the test data in you don't give it the right",
    "start": "261000",
    "end": "268320"
  },
  {
    "text": "answer you don't give it what customers actually did for those user movie pairs but we know the right answer because",
    "start": "268320",
    "end": "275360"
  },
  {
    "text": "it's labeled right it's from that original data set we have the right answers and so we can compare what the",
    "start": "275360",
    "end": "281280"
  },
  {
    "text": "result is that comes out of the model with what the correct answer was in the original data set and that gives us our",
    "start": "281280",
    "end": "287479"
  },
  {
    "text": "accuracy and this is the fundamental concept for uh for supervised machine learning is you you train a model which",
    "start": "287479",
    "end": "296160"
  },
  {
    "text": "attempts to generalize from the examples it's seen in order to predict well on examples that it hasn't seen and the",
    "start": "296160",
    "end": "303199"
  },
  {
    "text": "discrepancy between the predicted answer and the correct answer in the original data is your accuracy level and uh and",
    "start": "303199",
    "end": "310639"
  },
  {
    "text": "we'll be we'll be doing a bunch of graphs and talking about uh that accuracy and and the error which is the",
    "start": "310639",
    "end": "315759"
  },
  {
    "text": "the kind of the opposite of accuracy how many mistakes it makes uh Now movie data",
    "start": "315759",
    "end": "321440"
  },
  {
    "start": "318000",
    "end": "541000"
  },
  {
    "text": "uh and recommendations data are often sparse and what do I mean by that so you you think about the data set that is in",
    "start": "321440",
    "end": "328520"
  },
  {
    "text": "that Netflix prize uh data set you can think of it as a giant Matrix where I don't know if you can read that it's",
    "start": "328520",
    "end": "334560"
  },
  {
    "text": "it's a little small on the screen I apologize uh but the every column there",
    "start": "334560",
    "end": "339840"
  },
  {
    "text": "on the on the left side is the name of a movie uh sorry every row is the name of movie and then the uh the rows sorry the",
    "start": "339840",
    "end": "346639"
  },
  {
    "text": "columns correspond to uh to users and in the places where a given user has rated",
    "start": "346639",
    "end": "353240"
  },
  {
    "text": "a particular movie there's a number showing up a number from 1 to five and you see that most of those are blank and",
    "start": "353240",
    "end": "358639"
  },
  {
    "text": "this is why we call it sparse is because this data set is sparse it's mostly missing and we just have a few examples",
    "start": "358639",
    "end": "364520"
  },
  {
    "text": "of the correct answers that we're trying to get out of our model um and so let's",
    "start": "364520",
    "end": "369720"
  },
  {
    "text": "think about uh what a typical size of such a data set is so uh for a Vari of",
    "start": "369720",
    "end": "375639"
  },
  {
    "text": "reasons we're going to use the movie lens data set or the movie lens 20 million data set instead of the Netflix data set because it's it's uh it's a lot",
    "start": "375639",
    "end": "382280"
  },
  {
    "text": "easier to work with um and we're going to use the 20 million uh um uh example",
    "start": "382280",
    "end": "388639"
  },
  {
    "text": "version of this data set and in this data set there's 27,000 movies and they were rated by 138,000 users so you",
    "start": "388639",
    "end": "397240"
  },
  {
    "text": "multiply that out that's 3.7 billion possible ratings but of those 3.7 billion uh possible entries in that",
    "start": "397240",
    "end": "404440"
  },
  {
    "text": "giant spreadsheet or giant Matrix only 20 million of them are filled in so more",
    "start": "404440",
    "end": "409639"
  },
  {
    "text": "than 99% of the possible numbers in this giant matrics are missing they're blank",
    "start": "409639",
    "end": "415440"
  },
  {
    "text": "and that's what we're asking the machine learning model to predict is what are the values of those numbers that we've",
    "start": "415440",
    "end": "420680"
  },
  {
    "text": "never seen before um now let's think about what it would take uh computationally like put on our computer",
    "start": "420680",
    "end": "426759"
  },
  {
    "text": "science hat and think about storing this Matrix there's a couple different ways that you might do it you might just say",
    "start": "426759",
    "end": "432199"
  },
  {
    "text": "you know what it's a matrix I know how to do that it's a dou dimensioned array uh I'm going to allocate a single bite",
    "start": "432199",
    "end": "437520"
  },
  {
    "text": "for each entry and I'm going to put a zero where there's something missing and a 1 2 3 four or five integer where where",
    "start": "437520",
    "end": "443000"
  },
  {
    "text": "there is uh something and it's going to be almost 4 gabes um and you know we could deal with that that's that's big",
    "start": "443000",
    "end": "449039"
  },
  {
    "text": "but it's not totally unreasonable but you can store that much more efficiently if you just recognize that most of those",
    "start": "449039",
    "end": "455960"
  },
  {
    "text": "entries are are missing and instead of storing uh every value you just store",
    "start": "455960",
    "end": "461840"
  },
  {
    "text": "the positions of the non-zero entries uh and then uh I have a proposal for a way",
    "start": "461840",
    "end": "467840"
  },
  {
    "text": "to do it you use four-bit uh integers for the IDS of each position and then you still store a number for uh fore",
    "start": "467840",
    "end": "474240"
  },
  {
    "text": "trading and in this particular case the sparse representation is 20 times",
    "start": "474240",
    "end": "479440"
  },
  {
    "text": "smaller than the dense representation and that's a pretty big difference and 4",
    "start": "479440",
    "end": "484759"
  },
  {
    "text": "GB is maybe not so big that you're thinking I could you know I could deal with four gigabytes right but if your",
    "start": "484759",
    "end": "490919"
  },
  {
    "text": "catalog is huge if you have millions of entries if you have uh millions of uh of",
    "start": "490919",
    "end": "496000"
  },
  {
    "text": "users using a system you can easily see that uh the dense representation can get",
    "start": "496000",
    "end": "501520"
  },
  {
    "text": "completely intractable and moving all those zeros around it might seem simple but it it really pushes your uh your",
    "start": "501520",
    "end": "508120"
  },
  {
    "text": "computational system and and uh uh deep learning systems and uh in particular and generally any machine Learning",
    "start": "508120",
    "end": "514159"
  },
  {
    "text": "System uh Your computational Capacity is going to be stressed out so uh sparse representations of data are important uh",
    "start": "514159",
    "end": "522200"
  },
  {
    "text": "and I'm going to bookmark that uh for for a little bit and jump back to uh to the science so so there's a bunch of",
    "start": "522200",
    "end": "528240"
  },
  {
    "text": "complexity in dealing with sparse data but it's important because if you have a long tale of content or of users then",
    "start": "528240",
    "end": "535560"
  },
  {
    "text": "then you really need to do this in order to keep your uh your problem practic um uh tractable okay so how do you solve uh",
    "start": "535560",
    "end": "543440"
  },
  {
    "start": "541000",
    "end": "758000"
  },
  {
    "text": "this this problem how do you make those predictions you want to fill in those missing entries and try and predict what",
    "start": "543440",
    "end": "548480"
  },
  {
    "text": "uh what star rating a customer is going to give and the classic technique uh",
    "start": "548480",
    "end": "553920"
  },
  {
    "text": "that's that's very heavily studied and very well understood is called Matrix factorization uh and this is is math if",
    "start": "553920",
    "end": "560680"
  },
  {
    "text": "uh if you took linear algebra uh you'll remember that the if you have a big",
    "start": "560680",
    "end": "566000"
  },
  {
    "text": "Matrix like this you can uh you can approach proximate that as the product of two smaller matrices one tall skinny",
    "start": "566000",
    "end": "573480"
  },
  {
    "text": "Matrix and one short wide Matrix and there's standard algorithms for uh for",
    "start": "573480",
    "end": "579160"
  },
  {
    "text": "doing this approximation um but you can store those those tall skinny matrices",
    "start": "579160",
    "end": "585120"
  },
  {
    "text": "and those uh those short wide matrices again in a much smaller amount of space than than the very large uh Matrix and",
    "start": "585120",
    "end": "592959"
  },
  {
    "text": "the interesting thing is if you do that approximation correctly then the smaller",
    "start": "592959",
    "end": "598120"
  },
  {
    "text": "matrices have have actually summarized the important information that's in the big Matrix and they've summarized it in",
    "start": "598120",
    "end": "604720"
  },
  {
    "text": "a way that makes it tractable and really easy to work with uh for uh for future",
    "start": "604720",
    "end": "609959"
  },
  {
    "text": "analysis so if you have maybe 100,000 by 100,000 Matrix to start with then for",
    "start": "609959",
    "end": "616040"
  },
  {
    "text": "each of those items if we pick D to be like 64 is a pretty typical number for",
    "start": "616040",
    "end": "621440"
  },
  {
    "text": "uh for the reduced dimensionality then you have a 64 dimensional Vector for",
    "start": "621440",
    "end": "626880"
  },
  {
    "text": "each item for each movie in your data set you also have a 64 dimensional Vector for each user uh who's using your",
    "start": "626880",
    "end": "633600"
  },
  {
    "text": "system and these uh are are in the Deep learning par it's often called embeddings and uh you can look at them",
    "start": "633600",
    "end": "640720"
  },
  {
    "text": "you can go into that uh uh you can do this calculation and you can pull one out you can see okay what's the embedding for a movie like The Karate",
    "start": "640720",
    "end": "647880"
  },
  {
    "text": "Kid you say look well it's a bunch of numbers right they're they floating points what do they mean I don't know I",
    "start": "647880",
    "end": "656279"
  },
  {
    "text": "mean I I tend to think of these embeddings as kind of like hash codes right they they're something that uh the",
    "start": "656279",
    "end": "662880"
  },
  {
    "text": "machine understands the machine makes use of and you can look at them and you can see them but they're they're not",
    "start": "662880",
    "end": "669160"
  },
  {
    "text": "particularly intuitive there's not a lot you can get out of them directly but what you can do with them is you can",
    "start": "669160",
    "end": "675760"
  },
  {
    "text": "compare them so take Karate Kid and and a similar movie from that genre like",
    "start": "675760",
    "end": "681399"
  },
  {
    "text": "maybe Ferris Beer's day off right good classic 80s movies and you can look at both both the numbers and you can see",
    "start": "681399",
    "end": "687560"
  },
  {
    "text": "that in each dimension they're they're not too far apart from each other and you can pretty quickly uh and and pretty",
    "start": "687560",
    "end": "694600"
  },
  {
    "text": "uh without a lot of computation you can subtract those two from each other and you can get a distance and you can get a",
    "start": "694600",
    "end": "699680"
  },
  {
    "text": "single number now that tells you how similar any pair of uh uh of movies is",
    "start": "699680",
    "end": "706240"
  },
  {
    "text": "and as you can see for just 64 floats this is this is super quick and now uh",
    "start": "706240",
    "end": "711320"
  },
  {
    "text": "you can start to see how these embeddings are a useful tool for understanding uh this this really",
    "start": "711320",
    "end": "717680"
  },
  {
    "text": "complex data set we started with we started with this Matrix of 4 billion entries and now we've reduced it",
    "start": "717680",
    "end": "723519"
  },
  {
    "text": "meaningfully to a way that you can compare any set of movies and see how similar they are so for example if you",
    "start": "723519",
    "end": "729760"
  },
  {
    "text": "were to look at uh Kate kid versus a different movie like My Little Pony you'll see that they're much farther apart whereas one the the distance is",
    "start": "729760",
    "end": "736920"
  },
  {
    "text": "only 0.1 the other case distance is uh uh is one and a half uh and you can actually do the same thing with users in",
    "start": "736920",
    "end": "743800"
  },
  {
    "text": "this uh in this model the users in the movies are embedded into the same space that's where the term embeddings comes from so you can measure the distance",
    "start": "743800",
    "end": "750440"
  },
  {
    "text": "between a uh a user and any of the movies they might be interested in and that's the basic idea behind a matrix",
    "start": "750440",
    "end": "757320"
  },
  {
    "text": "factorization model so we're going to run uh this Matrix factorization uh technique using mxnet and uh if you've",
    "start": "757320",
    "end": "764560"
  },
  {
    "start": "758000",
    "end": "870000"
  },
  {
    "text": "been listening to our AI story this week uh you've probably heard of mxnet already but I'll give you a little",
    "start": "764560",
    "end": "769800"
  },
  {
    "text": "background uh it's an open source project it's been around for uh for a while it's a a year and a half or so",
    "start": "769800",
    "end": "776880"
  },
  {
    "text": "it's been uh been up on GitHub uh it's quite popular Amazon didn't invent it",
    "start": "776880",
    "end": "781959"
  },
  {
    "text": "but we are adopting it as our deep learning framework of choice there's lots of great deep learning Frameworks out there but we love mxnet for a bunch",
    "start": "781959",
    "end": "789279"
  },
  {
    "text": "of reasons it runs in lots of languages it's super fast uh you can you can run",
    "start": "789279",
    "end": "794839"
  },
  {
    "text": "it on high-end gpus on clusters of gpus it scales really well to to lots of",
    "start": "794839",
    "end": "800240"
  },
  {
    "text": "machines you can run it on mobile devices too um and uh you gpus are",
    "start": "800240",
    "end": "807000"
  },
  {
    "text": "important for deep learning mod because uh the math necessary to take that giant",
    "start": "807000",
    "end": "812880"
  },
  {
    "text": "data set and compress it down to the the summarization that that extracts of patterns is really computationally",
    "start": "812880",
    "end": "819199"
  },
  {
    "text": "intensive so we're going to run today on a p2x large instance uh and that",
    "start": "819199",
    "end": "825480"
  },
  {
    "text": "instance the k80 uh GPU in there is capable of over 4 trillion floating",
    "start": "825480",
    "end": "832160"
  },
  {
    "text": "Point operations per second uh which is kind of incredible it has uh it has a",
    "start": "832160",
    "end": "838320"
  },
  {
    "text": "two ,000 Cuda compute cores I think it's 2,000 uh compute cores running in parallel you know you've got your four",
    "start": "838320",
    "end": "843920"
  },
  {
    "text": "core machine you've got your your 32 large instance one of those gpus has thousands of instances in it and that's",
    "start": "843920",
    "end": "850759"
  },
  {
    "text": "or thousands of cores in it and that's how it's capable of achieving this ridiculously high throughput on floating",
    "start": "850759",
    "end": "856639"
  },
  {
    "text": "Point math but it's not a general purpose thing you're not going to run a database on it uh but they're excellent",
    "start": "856639",
    "end": "862560"
  },
  {
    "text": "at at math at Vector math uh and particularly these large Matrix computations which are the bread and",
    "start": "862560",
    "end": "868240"
  },
  {
    "text": "butter of uh deep learning systems and when you're programming uh a",
    "start": "868240",
    "end": "873399"
  },
  {
    "start": "870000",
    "end": "974000"
  },
  {
    "text": "GPU one of the uh one of the problems is actually keeping those thousands of",
    "start": "873399",
    "end": "878720"
  },
  {
    "text": "cores busy and uh GPU programmers refer to this problem as feeding the Beast there's thousands of cores that want to",
    "start": "878720",
    "end": "885279"
  },
  {
    "text": "work on a problem and so you have to get the data to those cores very quickly and in order to do that the gpus have their",
    "start": "885279",
    "end": "891759"
  },
  {
    "text": "own dedicated Ram uh and there's an incredibly fast bus uh between the gpus",
    "start": "891759",
    "end": "897360"
  },
  {
    "text": "RAM and the the GP course and that that bus is much slower sorry much faster",
    "start": "897360",
    "end": "903079"
  },
  {
    "text": "than the the buses the PCI bus which connects it to the CPU or the ethernet",
    "start": "903079",
    "end": "908279"
  },
  {
    "text": "which is going to connect it to uh to other machines um and that's this is for",
    "start": "908279",
    "end": "913480"
  },
  {
    "text": "a P2 XL for the P2 16x large we actually have 16 of those uh gpus connected over",
    "start": "913480",
    "end": "920279"
  },
  {
    "text": "that kind of medium speed PCI Express bus um and uh the I I point out all of",
    "start": "920279",
    "end": "927399"
  },
  {
    "text": "this because there 's a lot of complexity in getting those incredibly powerful instances to run efficiently",
    "start": "927399",
    "end": "934199"
  },
  {
    "text": "they are very very powerful but getting them feeding the Beast and getting the",
    "start": "934199",
    "end": "939440"
  },
  {
    "text": "data to those machines and scheduling all of this work is is very complex and this is something that mxet excels at",
    "start": "939440",
    "end": "945759"
  },
  {
    "text": "and uh so here's a chart on a uh a benchmark image analysis problem where",
    "start": "945759",
    "end": "951319"
  },
  {
    "text": "we're training a deep neural network using mxnet uh on for the first several",
    "start": "951319",
    "end": "957160"
  },
  {
    "text": "bars a single machine and then going to two four and eight machines uh and you",
    "start": "957160",
    "end": "962440"
  },
  {
    "text": "can see that the orange line which is how fast MXN is performing stays very very close to the theoretical ideal",
    "start": "962440",
    "end": "968519"
  },
  {
    "text": "speed up uh which uh is what you would uh expect to see on something that's scaling very",
    "start": "968519",
    "end": "974360"
  },
  {
    "start": "974000",
    "end": "1072000"
  },
  {
    "text": "well um so let's jump back to Matrix factorization and try and visualize what",
    "start": "974360",
    "end": "980680"
  },
  {
    "text": "Matrix factorization uh would look like as a neural network so neural networks start",
    "start": "980680",
    "end": "986199"
  },
  {
    "text": "with the input at the bottom and in our case we have the item or the movie uh on the left and the user on the right and",
    "start": "986199",
    "end": "992399"
  },
  {
    "text": "the first thing we do is embed them into this low-dimensional space and that embedding is uh is that tall skinny or",
    "start": "992399",
    "end": "1000519"
  },
  {
    "text": "or a short wide Matrix that we showed and then we compare the two of them uh by taking the vector dot product and",
    "start": "1000519",
    "end": "1006920"
  },
  {
    "text": "then we try to predict the rating as a number from one to five so the system's going to spit out a number and then",
    "start": "1006920",
    "end": "1012000"
  },
  {
    "text": "we're going to compare that to the correct answer which is what the user actually rated uh that um that movie As",
    "start": "1012000",
    "end": "1019079"
  },
  {
    "text": "and we're going to run this using the Deep learning Ami that uh that AWS maintains it has a bunch of uh deep",
    "start": "1019079",
    "end": "1025839"
  },
  {
    "text": "learning Frameworks installed on it we're going to use mxnet um and I'll say the the Ami uh we published it maybe it",
    "start": "1025839",
    "end": "1033558"
  },
  {
    "text": "was a little early but when we first released it it uh it didn't have every it didn't have all the stuff in uh",
    "start": "1033559",
    "end": "1039280"
  },
  {
    "text": "pre-installed it didn't have the uh the Cuda drivers and CNN and so if you go to the web page for the Deep learning Ami",
    "start": "1039280",
    "end": "1046120"
  },
  {
    "text": "you'll see some of the early people who tried it out they left some bad reviews which we deserved um and uh we fixed we",
    "start": "1046120",
    "end": "1053960"
  },
  {
    "text": "we addressed those concerns so I invite all of you to uh click past those initial bad reviews and try it for",
    "start": "1053960",
    "end": "1060080"
  },
  {
    "text": "yourself and if you like it consider leaving a a nice review for us um",
    "start": "1060080",
    "end": "1065880"
  },
  {
    "text": "because we we really have addressed I think every one of the concerns that those uh those initial reviews uh left",
    "start": "1065880",
    "end": "1071480"
  },
  {
    "text": "for us um and it comes with Jupiter and a bunch of python libraries and uh without further Ado let's go ahead and",
    "start": "1071480",
    "end": "1079559"
  },
  {
    "start": "1072000",
    "end": "1309000"
  },
  {
    "text": "try and run it all right what's going on is it working there we go okay so this is a Jupiter notebook um and Jupiter is",
    "start": "1079559",
    "end": "1086720"
  },
  {
    "text": "an interactive python shell so it runs in your browser and it's connected to a python kernel running on the P2 instance",
    "start": "1086720",
    "end": "1092760"
  },
  {
    "text": "and uh where's my mouse there we go and uh you can see the code and it's a",
    "start": "1092760",
    "end": "1098679"
  },
  {
    "text": "reppel loop so it reads EV evaluates and prints that's a loop and uh the code",
    "start": "1098679",
    "end": "1104880"
  },
  {
    "text": "starts out just importing a bunch of libraries uh mxnet and those other ones are uh the sample code for training The",
    "start": "1104880",
    "end": "1111679"
  },
  {
    "text": "Matrix factorization algorithm and all this is up on GitHub and I've got the link at the end of the presentation uh",
    "start": "1111679",
    "end": "1117240"
  },
  {
    "text": "and then next thing we do is we load the data set up and we count how many users so we're just going to use uh the",
    "start": "1117240",
    "end": "1122559"
  },
  {
    "text": "100,000 sample version of the data set now so we can actually run through this in a live demonstration rather than the",
    "start": "1122559",
    "end": "1128000"
  },
  {
    "text": "the bigger uh versions uh and there's so there's a thousand users and and not quite 2,000 movies and we're going to",
    "start": "1128000",
    "end": "1134960"
  },
  {
    "text": "Define this uh um Matrix factors ation model and the the lines of code that you",
    "start": "1134960",
    "end": "1141240"
  },
  {
    "text": "see right here are replicating that diagram I showed you and in fact uh at",
    "start": "1141240",
    "end": "1146280"
  },
  {
    "text": "the end that last line of plot network is going to show uh this is the machine",
    "start": "1146280",
    "end": "1151440"
  },
  {
    "text": "generated representation of the compute graph so the computation starts the bottom there's the user and the item",
    "start": "1151440",
    "end": "1157400"
  },
  {
    "text": "inputs We Run The embeddings we multiply we sum it up uh we flatten it and then",
    "start": "1157400",
    "end": "1162720"
  },
  {
    "text": "we compare it to the score with a linear regression uh loss function and that",
    "start": "1162720",
    "end": "1167760"
  },
  {
    "text": "loss function calculates the errors and it reports the rmse the root mean squared error which is uh a measure of",
    "start": "1167760",
    "end": "1174880"
  },
  {
    "text": "how badly the system did so we want that number to be as small as possible and let's go ahead and run the thing and so",
    "start": "1174880",
    "end": "1182520"
  },
  {
    "text": "now we're firing off those thousands of compute cores and oh well and uh you can",
    "start": "1182520",
    "end": "1189760"
  },
  {
    "text": "see the get this yeah you can see the network training as we go and it's",
    "start": "1189760",
    "end": "1196679"
  },
  {
    "text": "plotting this learning curve curve uh along the way there we go that's about",
    "start": "1196679",
    "end": "1201880"
  },
  {
    "text": "right uh and so you can see that over time uh as the as the network ran it",
    "start": "1201880",
    "end": "1207840"
  },
  {
    "text": "started out uh with an error uh rmsse error of over three and a half so on a",
    "start": "1207840",
    "end": "1213799"
  },
  {
    "text": "scale of 1 to five if your average error is about three and a half you're doing horribly but it very quickly uh started",
    "start": "1213799",
    "end": "1221440"
  },
  {
    "text": "to converge toward a good answer and then at the end you can see it was um it",
    "start": "1221440",
    "end": "1228600"
  },
  {
    "text": "got down to about one right um so uh",
    "start": "1228600",
    "end": "1233640"
  },
  {
    "text": "that's that's not bad on a scale of 1 to five um and so let me talk about these two lines here right so there's the that",
    "start": "1233640",
    "end": "1240400"
  },
  {
    "text": "thick green line and then there's the lighter blue line so the lighter blue line is the errors on the training data",
    "start": "1240400",
    "end": "1246919"
  },
  {
    "text": "and the green line is the errors on the test data or the the validation data and",
    "start": "1246919",
    "end": "1253400"
  },
  {
    "text": "as expected the system does better on the training data where it's seen the right answers and on the data where it's",
    "start": "1253400",
    "end": "1260120"
  },
  {
    "text": "never seen them before it's not doing quite as well um but they're actually pretty close to each other and that's",
    "start": "1260120",
    "end": "1265640"
  },
  {
    "text": "encouraging this is a sign of a machine Learning System that's actually working pretty well and uh I encourage any of",
    "start": "1265640",
    "end": "1274000"
  },
  {
    "text": "you as you're working in in machine learning to plot these learning curves is what they're these charts are called",
    "start": "1274000",
    "end": "1279480"
  },
  {
    "text": "and pay close attention to them because if you see something that looks roughly like this then that's actually a really",
    "start": "1279480",
    "end": "1285880"
  },
  {
    "text": "good sign that means your system is behav well uh your error starts out High",
    "start": "1285880",
    "end": "1291080"
  },
  {
    "text": "it goes down and it it flattens out this is this is actually a really good sign that your system is behaving correctly",
    "start": "1291080",
    "end": "1296640"
  },
  {
    "text": "and doing about what you want uh if for some reason you saw that the error on the test data was lower than the",
    "start": "1296640",
    "end": "1303520"
  },
  {
    "text": "training data you'd be pretty suspicious that there's you probably have a bug in your code if you if you see that so okay",
    "start": "1303520",
    "end": "1310120"
  },
  {
    "start": "1309000",
    "end": "1398000"
  },
  {
    "text": "so there is a basic Matrix factorization system um and I I wouldn't call that deep learning except for the fact that I",
    "start": "1310120",
    "end": "1316679"
  },
  {
    "text": "mean I really wouldn't it's running on G gpus and so you're running into a lot of the complexity of building a deep Learning System but a great thing about",
    "start": "1316679",
    "end": "1323320"
  },
  {
    "text": "running this stuff in mxet is that with just a couple extra lines of code we can add in a set of nonlinearity by adding a",
    "start": "1323320",
    "end": "1331360"
  },
  {
    "text": "reu layer and then another fully connected layer and we do that and now",
    "start": "1331360",
    "end": "1337200"
  },
  {
    "text": "we actually have a neural network so uh visually we've just added a couple more",
    "start": "1337200",
    "end": "1342840"
  },
  {
    "text": "compute nodes to the compute graph and now when we run it you'll see that uh",
    "start": "1342840",
    "end": "1350200"
  },
  {
    "text": "again the eror starts out high and I don't know if you can read this there's a three two one um and uh it it",
    "start": "1350200",
    "end": "1359080"
  },
  {
    "text": "converges much faster it gets down to uh to about one much more quickly and um",
    "start": "1359080",
    "end": "1366279"
  },
  {
    "text": "and you can see we actually got below one on this uh on this one so this one's doing better right um and that's not a",
    "start": "1366279",
    "end": "1373480"
  },
  {
    "text": "surprise generally when you add nonlinearity to a machine Learning System uh you are increasing the",
    "start": "1373480",
    "end": "1378919"
  },
  {
    "text": "expressive power of your machine Learning System it's able to find more complex um uh more complex patterns in",
    "start": "1378919",
    "end": "1386600"
  },
  {
    "text": "the original data the the tradeoff is that these systems are harder to train and they're they're more finicky but uh",
    "start": "1386600",
    "end": "1393600"
  },
  {
    "text": "with a nice powerful framework like mxnet you can paper paper over a lot of those differences so we saw that one did",
    "start": "1393600",
    "end": "1399799"
  },
  {
    "start": "1398000",
    "end": "1506000"
  },
  {
    "text": "better let's compare the results let's put them side by side on on top of each other and we can see that uh it becomes",
    "start": "1399799",
    "end": "1408279"
  },
  {
    "text": "very clear that the um that the the nonlinear model got to a better answer a",
    "start": "1408279",
    "end": "1414640"
  },
  {
    "text": "lower error so down is better here right um but you might be saying hey it it took longer right this x-axis is time",
    "start": "1414640",
    "end": "1420880"
  },
  {
    "text": "that's actually like wall clock time which is which is what matters even though they both had the same number of epochs they both had 15 passes through",
    "start": "1420880",
    "end": "1427400"
  },
  {
    "text": "the data but the computation was more intense for the neural network and so it took longer so you say hey that that",
    "start": "1427400",
    "end": "1433840"
  },
  {
    "text": "yellow line is still going down what if we let it keep going right it's perfectly Fair let's let's let it keep",
    "start": "1433840",
    "end": "1439279"
  },
  {
    "text": "going right um and uh and if we do that",
    "start": "1439279",
    "end": "1444520"
  },
  {
    "text": "well got to got to restart um but uh it's going to it's going to drop down",
    "start": "1444520",
    "end": "1449640"
  },
  {
    "text": "again and you're going to see that eventually whoa I'm messing this up get",
    "start": "1449640",
    "end": "1456240"
  },
  {
    "text": "back there there we go um and is it going to get down below one how far how",
    "start": "1456240",
    "end": "1461919"
  },
  {
    "text": "low did we get before we got to uh 95 or so right and here uh this one is I",
    "start": "1461919",
    "end": "1472799"
  },
  {
    "text": "got below one and it's still going and you know I'll I'll I'll tell you it does",
    "start": "1472799",
    "end": "1479080"
  },
  {
    "text": "it does keep going down but the thing is the optimizer that I'm using this case the standard SGD Optimizer uh which",
    "start": "1479080",
    "end": "1485880"
  },
  {
    "text": "pretty much everybody supports uh is not the fastest computational way to",
    "start": "1485880",
    "end": "1491120"
  },
  {
    "text": "optimize all those parameters and uh a good neural network framework will give you access to uh a better set of uh of",
    "start": "1491120",
    "end": "1499279"
  },
  {
    "text": "tools than that is it done yeah it finished so let's plot them against each other again and see how they do you see",
    "start": "1499279",
    "end": "1506159"
  },
  {
    "start": "1506000",
    "end": "1637000"
  },
  {
    "text": "yeah you know given long enough maybe it's going to get there but I want to speed this whole process up let's switch",
    "start": "1506159",
    "end": "1511919"
  },
  {
    "text": "to another notebook over here where we're using a uh a fancier optimizing",
    "start": "1511919",
    "end": "1518000"
  },
  {
    "text": "algorithm called atom that's built in and in mxnet all we have to do all this",
    "start": "1518000",
    "end": "1523080"
  },
  {
    "text": "top code's the same um produce the same uh model and all I is I just add this uh",
    "start": "1523080",
    "end": "1529559"
  },
  {
    "text": "this flag saying I want to use the atom Optimizer which is this adaptive rate Optimizer and uh and let it run and it's",
    "start": "1529559",
    "end": "1537760"
  },
  {
    "text": "going to get to the bottom much faster so this first one again is that linear Matrix factorization model and you see",
    "start": "1537760",
    "end": "1543600"
  },
  {
    "text": "it quickly gets down to uh to one and uh uh even gets below one and then you're",
    "start": "1543600",
    "end": "1550880"
  },
  {
    "text": "going to see something really interesting start to happen um which",
    "start": "1550880",
    "end": "1556679"
  },
  {
    "text": "is you see what's happening now that green line is flattened out and",
    "start": "1556679",
    "end": "1563440"
  },
  {
    "text": "it's starting to go up right and that blue line is going down down",
    "start": "1563440",
    "end": "1572039"
  },
  {
    "text": "down interesting right now again this is actually totally healthy and normal for",
    "start": "1572039",
    "end": "1578600"
  },
  {
    "text": "a machine Learning System and this phenomenon is known as overfitting and what you're seeing is that the system is",
    "start": "1578600",
    "end": "1585760"
  },
  {
    "text": "making really really good predictions on the blue data which is the training data where where it's seeing the right",
    "start": "1585760",
    "end": "1590799"
  },
  {
    "text": "answers over and over again and it's getting so good at that that it's not generalizing as well that the",
    "start": "1590799",
    "end": "1596399"
  },
  {
    "text": "predictions it's making are getting worse for the test data that it's never seen before and uh this phenomenon of",
    "start": "1596399",
    "end": "1602760"
  },
  {
    "text": "overfitting is really one of the really fundamental issues in any machine learning problem is is how do you control this how do you learn a model",
    "start": "1602760",
    "end": "1609559"
  },
  {
    "text": "that gen that learns patterns that don't just apply to the data it's seen but that generalize to uh to data that",
    "start": "1609559",
    "end": "1616880"
  },
  {
    "text": "hasn't seen in fact uh I'm sure uh uh all of you could come up with a machine learning model that gives perfect",
    "start": "1616880",
    "end": "1623600"
  },
  {
    "text": "answers on the training data you just use a hash table right you just say have I seen this before if so what was the",
    "start": "1623600",
    "end": "1629600"
  },
  {
    "text": "answer okay I'll spit that out again trivial right you get zero error on all of your training data but it doesn't",
    "start": "1629600",
    "end": "1635640"
  },
  {
    "text": "generalize at all it's totally not useful for making predictions on unseen data uh so controlling this overfitting",
    "start": "1635640",
    "end": "1641960"
  },
  {
    "start": "1637000",
    "end": "1693000"
  },
  {
    "text": "problem is one of the great uh um issues in in any machine Learning System so",
    "start": "1641960",
    "end": "1647080"
  },
  {
    "text": "let's try running again the same thing um uh using the atom Optimizer for the",
    "start": "1647080",
    "end": "1655760"
  },
  {
    "text": "um uh on the nonlinear neural network and while that runs I'm going to show",
    "start": "1655760",
    "end": "1661640"
  },
  {
    "text": "you an even fancier neural network so another great thing about uh using a",
    "start": "1661640",
    "end": "1667080"
  },
  {
    "text": "framework like mxet even for a simple problem like uh Matrix factorization is that you can easily pull in all these",
    "start": "1667080",
    "end": "1673760"
  },
  {
    "text": "ideas uh from elsewhere so I'm going to borrow some ideas from resnet which was the uh neural network design that won",
    "start": "1673760",
    "end": "1680480"
  },
  {
    "text": "the very competitive imag net competition um uh this last year and uh",
    "start": "1680480",
    "end": "1686279"
  },
  {
    "text": "I'm going to I'll show you what this uh what this neural network looks like as soon as this thing's done training",
    "start": "1686279",
    "end": "1693200"
  },
  {
    "start": "1693000",
    "end": "1803000"
  },
  {
    "text": "um uh and it's going to uh this is going to be a very deep uh neural network with",
    "start": "1693200",
    "end": "1698559"
  },
  {
    "text": "uh with a whole lot of layers and uh and Skip connections here it is um and you",
    "start": "1698559",
    "end": "1703840"
  },
  {
    "text": "can see that uh we start all the way down here we look up the embedding and",
    "start": "1703840",
    "end": "1709000"
  },
  {
    "text": "then we apply some nonlinearity we use this technique called Dropout which is a really uh aggressive regularizer",
    "start": "1709000",
    "end": "1715159"
  },
  {
    "text": "regularization is the key way to avoid this overfitting problem or it's it's really one of the fundamental building",
    "start": "1715159",
    "end": "1721279"
  },
  {
    "text": "blocks for doing that and so you can see there's this fairly comp uh complex computational graph with these skip",
    "start": "1721279",
    "end": "1726559"
  },
  {
    "text": "connections uh which allow it to compute the residuals which is the source and name the reset and now when we run this",
    "start": "1726559",
    "end": "1733519"
  },
  {
    "text": "one uh I use a slightly uh larger batch size to so the gpus can uh uh can run",
    "start": "1733519",
    "end": "1739640"
  },
  {
    "text": "more efficiently and we can uh you know actually see this thing go uh in the course of a demo um and it quickly gets",
    "start": "1739640",
    "end": "1747880"
  },
  {
    "text": "below one again and we'll actually see that with the",
    "start": "1747880",
    "end": "1754519"
  },
  {
    "text": "Dropout regularization uh even though the model is very complex it's not going to",
    "start": "1754519",
    "end": "1759960"
  },
  {
    "text": "overfit uh in fact it's going to slowly go down down down and we'll get to uh an",
    "start": "1759960",
    "end": "1766840"
  },
  {
    "text": "ultimate answer of about 92 or so uh which is significantly better than than",
    "start": "1766840",
    "end": "1772960"
  },
  {
    "text": "any of the others uh any of the other models get uh and this is a a pattern with Dropout and and uh that it can take",
    "start": "1772960",
    "end": "1781799"
  },
  {
    "text": "a very long time to train and uh and get your answer but it uh uh often gives you",
    "start": "1781799",
    "end": "1787960"
  },
  {
    "text": "very good results if you're willing to to wait that long and these are kind of the happy trade-offs right do I want to wait longer and get better results uh or",
    "start": "1787960",
    "end": "1795720"
  },
  {
    "text": "or not and sometimes you can wait longer and get worse results but uh uh there's a lot of playing around that you can do",
    "start": "1795720",
    "end": "1801399"
  },
  {
    "text": "uh you can do with this stuff so while this thing is running um I'm going to jump back to uh jump back to my slides",
    "start": "1801399",
    "end": "1809399"
  },
  {
    "start": "1803000",
    "end": "2019000"
  },
  {
    "text": "where are they there we go go",
    "start": "1809399",
    "end": "1816639"
  },
  {
    "text": "back um okay so all of that was framing the problem as predicting what star",
    "start": "1817000",
    "end": "1824279"
  },
  {
    "text": "rating a user would give to a movie and that's a fine way to frame the",
    "start": "1824279",
    "end": "1829960"
  },
  {
    "text": "problem but sometimes uh it makes more sense to frame the problem as a binary prediction problem uh which is to say",
    "start": "1829960",
    "end": "1835880"
  },
  {
    "text": "just would the user be interested in this movie or not yes or no not a one to five and the reason for that is that",
    "start": "1835880",
    "end": "1843519"
  },
  {
    "text": "well consider a movie like Xanadu with Olivia Newton John and uh and Jean Kelly",
    "start": "1843519",
    "end": "1850120"
  },
  {
    "text": "and um if you go and look at the ratings people give this movie on IMDb they are",
    "start": "1850120",
    "end": "1855799"
  },
  {
    "text": "not good um but sometimes you just want to watch",
    "start": "1855799",
    "end": "1860960"
  },
  {
    "text": "Olivia Newton John rolling around on on roller skates right even though people are probably going to give it one or two",
    "start": "1860960",
    "end": "1866080"
  },
  {
    "text": "stars you maybe that's what you're in the mood for and on the flip side of that uh take this movie which uh I think",
    "start": "1866080",
    "end": "1872840"
  },
  {
    "text": "is called Andre RAV apologies for anybody who actually speaks Russian pretty much everybody who watches this",
    "start": "1872840",
    "end": "1878799"
  },
  {
    "text": "movie gives it a four or five stars but not that many people watch this movie",
    "start": "1878799",
    "end": "1884600"
  },
  {
    "text": "right so if your goal is to try to predict what star rating somebody is going to give then Andre RAV is going to",
    "start": "1884600",
    "end": "1892399"
  },
  {
    "text": "get recommended to a whole bunch of people who have no interest in watching a movie about a Russian writer in the",
    "start": "1892399",
    "end": "1897480"
  },
  {
    "text": "60s right so reframing this problem as a binary prediction problem can often give",
    "start": "1897480",
    "end": "1902519"
  },
  {
    "text": "you uh give you better results so instead of having a one through five number uh we just replace all of those",
    "start": "1902519",
    "end": "1908120"
  },
  {
    "text": "numbers with one and in fact this makes a problem significantly easier in a",
    "start": "1908120",
    "end": "1913279"
  },
  {
    "text": "bunch of ways too and so consider like this subset of the data where you know I like my ' 80s Classics and those each",
    "start": "1913279",
    "end": "1920360"
  },
  {
    "text": "get a label of one and my daughter likes her cartoons and they each get a label of one and now think about building a",
    "start": "1920360",
    "end": "1926480"
  },
  {
    "text": "machine learning model that's going to predict this so now you're saying okay predict the score for a given user for a",
    "start": "1926480",
    "end": "1932639"
  },
  {
    "text": "given movie and you know what that's pretty trivial to write everything's one right and in fact if you fed that same",
    "start": "1932639",
    "end": "1939960"
  },
  {
    "text": "data into the machine Learning System it would very quickly figure out that this is the best model as well but that's not",
    "start": "1939960",
    "end": "1945600"
  },
  {
    "text": "useful right that's not what we want so the way around this is a technique called negative sampling so what you do",
    "start": "1945600",
    "end": "1953320"
  },
  {
    "text": "is you Shuffle the data um around so that we we infer zeros in places where",
    "start": "1953320",
    "end": "1960399"
  },
  {
    "text": "there were Blanks on uh on that Matrix before and the efficient way to do this",
    "start": "1960399",
    "end": "1966000"
  },
  {
    "text": "uh it's maybe not the it's definitely not the theoretically best way to do it uh is to just take the data in the",
    "start": "1966000",
    "end": "1971440"
  },
  {
    "text": "chunks that we read them off the file and we Shuffle each of those chunks uh and we replace a zero we replace the one",
    "start": "1971440",
    "end": "1978120"
  },
  {
    "text": "with a zero everywhere we shuffled it and mxet has a tool for doing this called the negative sampling data",
    "start": "1978120",
    "end": "1984240"
  },
  {
    "text": "iterator and so any data iterator that that you define and that's how you read your um read your data off of the dis uh",
    "start": "1984240",
    "end": "1992440"
  },
  {
    "text": "the negative sampling data iterator will Shuffle around the mini batches and uh replace them with a a a fraction of um",
    "start": "1992440",
    "end": "2001440"
  },
  {
    "text": "or or actually a multiple of examples of of negative case in this case you usually want more negative examples than",
    "start": "2001440",
    "end": "2008039"
  },
  {
    "text": "positive for I I don't actually exactly know why but in practice that that always seems to seems to help and so a",
    "start": "2008039",
    "end": "2014159"
  },
  {
    "text": "ratio of three or five or something like that sometimes people go as high as 20 uh uh seems to work well uh and so this",
    "start": "2014159",
    "end": "2020720"
  },
  {
    "text": "negative sampling data iterator helps with that and we can see that run uh in",
    "start": "2020720",
    "end": "2025799"
  },
  {
    "text": "another uh notebook here which way do I go I go over here there we go and so the",
    "start": "2025799",
    "end": "2031960"
  },
  {
    "text": "code again looks very similar uh we load up the uh um we load up the data just as",
    "start": "2031960",
    "end": "2039399"
  },
  {
    "text": "we did before and now we use The Decorator pattern we just wrap it we take the positive training data and we",
    "start": "2039399",
    "end": "2044919"
  },
  {
    "text": "wrap it in this uh negative sampling data iterator and we say we want the",
    "start": "2044919",
    "end": "2050320"
  },
  {
    "text": "sample ratio to be uh to be three um and",
    "start": "2050320",
    "end": "2056440"
  },
  {
    "text": "uh then we run we define basically the same neural network I'm using a cosine",
    "start": "2056440",
    "end": "2061679"
  },
  {
    "text": "loss layer instead of the um logistic regression loss that had before um and",
    "start": "2061679",
    "end": "2069839"
  },
  {
    "text": "I'm using which inserts these L2 normalization layers on the way and then we run it and now the scale has changed",
    "start": "2069839",
    "end": "2077118"
  },
  {
    "text": "so instead of being on a scale of uh of one to five now everything's zero one so",
    "start": "2077119",
    "end": "2082839"
  },
  {
    "text": "the the error numbers tend to be closer to a half and you can see",
    "start": "2082839",
    "end": "2088440"
  },
  {
    "text": "again that was maybe a bit too much um that it's learning along and we have",
    "start": "2088440",
    "end": "2095599"
  },
  {
    "text": "this nice learning curve which is about the shape you expect a learning curve to be so the uh errors are slightly higher",
    "start": "2095599",
    "end": "2102480"
  },
  {
    "text": "on the evaluation data that the system's never seen before um and so it's training so okay that's how uh that's",
    "start": "2102480",
    "end": "2111760"
  },
  {
    "text": "how negative sampling uh that's how negative sampling Works how am I doing on time oh not too badly",
    "start": "2111760",
    "end": "2119960"
  },
  {
    "text": "um and you could go and uh so the the neural network structure up here is",
    "start": "2119960",
    "end": "2126040"
  },
  {
    "start": "2120000",
    "end": "2255000"
  },
  {
    "text": "again pretty simple we don't have uh any nonlinearity in this place we don't have any explicit regularization but you you",
    "start": "2126040",
    "end": "2133079"
  },
  {
    "text": "could totally go and apply all of those tricks we did on the uh rating prediction case uh here and uh uh and",
    "start": "2133079",
    "end": "2141240"
  },
  {
    "text": "try and figure out what's uh what's going to work best in order to get that uh that validation uh error as low as",
    "start": "2141240",
    "end": "2147200"
  },
  {
    "text": "possible and I was I going to end up and end up down around 46 that's pretty good",
    "start": "2147200",
    "end": "2153119"
  },
  {
    "text": "okay so let me get out of here",
    "start": "2153119",
    "end": "2158799"
  },
  {
    "text": "yeah all right so let me repeat the the uh the question so there's a uh and I'll",
    "start": "2169040",
    "end": "2174400"
  },
  {
    "text": "rephrase it slightly there are some seemingly arbitrary choices that I made like picking the C uh the sampling ratio",
    "start": "2174400",
    "end": "2181200"
  },
  {
    "text": "to be three uh and the learning rate and and things like that the question is where did I I come from and the the uh",
    "start": "2181200",
    "end": "2189280"
  },
  {
    "text": "uh person asking the audience clearly knows uh knows the art a little bit just said did you cross validate um and uh I",
    "start": "2189280",
    "end": "2196079"
  },
  {
    "text": "I uh I haven't in this case um but that would be the the correct thing to do because just as you can overfit your uh",
    "start": "2196079",
    "end": "2204960"
  },
  {
    "text": "your your uh uh your training data if you spend too much time fiddling around",
    "start": "2204960",
    "end": "2210200"
  },
  {
    "text": "with all these arbitrary choices you can also start to overfit your testing data",
    "start": "2210200",
    "end": "2215960"
  },
  {
    "text": "and then you can convince yourself that you have this amazing answer because it reproduces that 25% you happen to hold",
    "start": "2215960",
    "end": "2223000"
  },
  {
    "text": "out really really well but you might just be getting lucky because you spent",
    "start": "2223000",
    "end": "2228079"
  },
  {
    "text": "so much time fiddling around with these numbers and that you you picked something that just happens to work very well for that so if you do spend a lot",
    "start": "2228079",
    "end": "2234480"
  },
  {
    "text": "of time fussing with these these numbers are called hyperparameters uh then you actually",
    "start": "2234480",
    "end": "2239520"
  },
  {
    "text": "need to hold out a third set of data you need to divide your data into three sets one for training one for validation to",
    "start": "2239520",
    "end": "2246079"
  },
  {
    "text": "see how well each individual model is and then a last one that you never touch until you're done futzing to see how",
    "start": "2246079",
    "end": "2252680"
  },
  {
    "text": "well uh the system is actually performing um so that's a that's a great question uh let's see if we can get back",
    "start": "2252680",
    "end": "2259720"
  },
  {
    "text": "to this demo or get back to the slides all right",
    "start": "2259720",
    "end": "2266079"
  },
  {
    "text": "so that's all well and good um if you if",
    "start": "2266079",
    "end": "2271200"
  },
  {
    "text": "the only thing that you know about your data are the interactions between the users and the movies but in the real",
    "start": "2271200",
    "end": "2278400"
  },
  {
    "text": "world we often know a bunch about our users and a bunch about the content that",
    "start": "2278400",
    "end": "2284240"
  },
  {
    "text": "they're interacting with Beyond just their unique identifiers because everything we've done so far the both",
    "start": "2284240",
    "end": "2289640"
  },
  {
    "text": "the users and the movies are represented just by unique IDs um but in the real",
    "start": "2289640",
    "end": "2295440"
  },
  {
    "text": "world we we know these behavioral interactions but we also know things like the names of uh of the movies and",
    "start": "2295440",
    "end": "2302200"
  },
  {
    "text": "so you might think to yourself uh the movie name my little Pony it's got the",
    "start": "2302200",
    "end": "2307560"
  },
  {
    "text": "word Pony in it and and so maybe the person who watches that movie might want to watch other movies that have the word",
    "start": "2307560",
    "end": "2313720"
  },
  {
    "text": "Pony in it or Ghostbusters and Ghostbusters to you don't need a bunch of training data for the system to",
    "start": "2313720",
    "end": "2319560"
  },
  {
    "text": "realize those two movies are probably related to each other uh similarly you usually have pictures for whatever it is",
    "start": "2319560",
    "end": "2326040"
  },
  {
    "text": "that you're recommending and nowadays with deep Learning Systems we have really powerful tools for semantically",
    "start": "2326040",
    "end": "2332200"
  },
  {
    "text": "understanding what pictures mean and what they represent um and and uh as far",
    "start": "2332200",
    "end": "2337359"
  },
  {
    "text": "as uh your users you know you probably know a bunch of things about your users but something that generalizes quite",
    "start": "2337359",
    "end": "2342400"
  },
  {
    "text": "well is the the words that they've searched for uh tend to capture a bunch of things that are meaningful about what",
    "start": "2342400",
    "end": "2349319"
  },
  {
    "text": "their preferences are um so you can imagine uh and we'll talk about this taking each of these things as inputs",
    "start": "2349319",
    "end": "2356119"
  },
  {
    "text": "into a recommender system in as a way to improve the quality of the recommender uh recommendations that come out and the",
    "start": "2356119",
    "end": "2363079"
  },
  {
    "text": "question is how do you represent each of these ideas as a neural network or sorry",
    "start": "2363079",
    "end": "2368319"
  },
  {
    "text": "in the neural network so neural networks they um they're fundamentally math right so to get to get them to consume",
    "start": "2368319",
    "end": "2375319"
  },
  {
    "text": "anything it needs to be numbers it needs to be in a vector form um and if you",
    "start": "2375319",
    "end": "2380400"
  },
  {
    "text": "have a unique identifier like we've been using for our users or our movies then an embedding is a great way to do it so",
    "start": "2380400",
    "end": "2386599"
  },
  {
    "text": "you have this this one hot representation where you just pick a dimension on your embedding Matrix and",
    "start": "2386599",
    "end": "2391640"
  },
  {
    "text": "that is their uh their identifier and then you learn that Vector representation for them um so we know",
    "start": "2391640",
    "end": "2397720"
  },
  {
    "text": "how to do that for images uh something called a convet which is for for a convolutional neural network have really",
    "start": "2397720",
    "end": "2404480"
  },
  {
    "text": "become the de facto way of processing images in the last several years because they just dramatically outperform uh",
    "start": "2404480",
    "end": "2411480"
  },
  {
    "text": "everything else that uh that people have been doing and again a nice thing about working in a deep learning package uh",
    "start": "2411480",
    "end": "2417520"
  },
  {
    "text": "like mxet is that these things are just ready off the shelf you just pull in a line of code uh and pay whatever",
    "start": "2417520",
    "end": "2424040"
  },
  {
    "text": "computational cost you have to um but in terms of coding it's very simple to pull in a convolutional neural network to",
    "start": "2424040",
    "end": "2430760"
  },
  {
    "text": "process your images uh similarly for text the standard way of processing text in a uh",
    "start": "2430760",
    "end": "2440000"
  },
  {
    "text": "a neural network these days that seems to perform best in generally across a variety of tasks is uh called the lstm",
    "start": "2440000",
    "end": "2446960"
  },
  {
    "text": "or long short-term memory which is a strange term they won't bother to explain um but this can take an",
    "start": "2446960",
    "end": "2452240"
  },
  {
    "text": "arbitrary sequence of things and uh and understand it and and and process it",
    "start": "2452240",
    "end": "2457440"
  },
  {
    "text": "these things are still they're they're not reduced to practice in the way that a convolutional neural network is",
    "start": "2457440",
    "end": "2463119"
  },
  {
    "text": "they're still kind of finicky to to work with and so here I'm going to suggest an alternate standard representation for",
    "start": "2463119",
    "end": "2469680"
  },
  {
    "text": "text which is called the bag of words and here we ignore order and we just say take all of the words in whatever it is",
    "start": "2469680",
    "end": "2475680"
  },
  {
    "text": "your search queries or your um uh or your movie title and you throw them in a bag and you count up how many times each",
    "start": "2475680",
    "end": "2483119"
  },
  {
    "text": "word shows up and again you make one of these sparse vectors where everything's zero uh except the words that show up",
    "start": "2483119",
    "end": "2489359"
  },
  {
    "text": "and you and you put a number there usually one or or you can count actually uh and that's that's a bag of words",
    "start": "2489359",
    "end": "2495119"
  },
  {
    "text": "representation and it's not as good as the lstm the recurrent neural network",
    "start": "2495119",
    "end": "2500359"
  },
  {
    "text": "representation but often it's good enough and it's a heck of lot easier to work with uh and when to put these",
    "start": "2500359",
    "end": "2507560"
  },
  {
    "start": "2505000",
    "end": "2595000"
  },
  {
    "text": "together we're going to use a neural network design pattern called The Deep structured semantic model and this is",
    "start": "2507560",
    "end": "2514280"
  },
  {
    "text": "really this is really a beautiful design pattern for uh for neural networks and I think it's really",
    "start": "2514280",
    "end": "2520280"
  },
  {
    "text": "underappreciated um out there like the convet and the lstm are things that that most people working in uh uh in deep",
    "start": "2520280",
    "end": "2527000"
  },
  {
    "text": "Nets are very familiar with the the dssm is a brilliant way to combine pretty",
    "start": "2527000",
    "end": "2534280"
  },
  {
    "text": "arbitrary sets of content you can represent your left object and your right object in our case it's the user",
    "start": "2534280",
    "end": "2541040"
  },
  {
    "text": "and the movie or the item with pretty much anything you want and you you come up with some way to uh to compress the",
    "start": "2541040",
    "end": "2548400"
  },
  {
    "text": "representation down to an embedding then you combine the individual embeddings for the different pieces to have a",
    "start": "2548400",
    "end": "2554720"
  },
  {
    "text": "combined embedding you measure the similarity and then you predict the label and this works across a really",
    "start": "2554720",
    "end": "2561040"
  },
  {
    "text": "wide variety of um of problem types and in this case we're going to use the coine loss layer that I mentioned very",
    "start": "2561040",
    "end": "2567640"
  },
  {
    "text": "uh briefly earlier which uh it's um it's a DOT product but it ignores the length",
    "start": "2567640",
    "end": "2573720"
  },
  {
    "text": "of the uh of the vectors and so it's just compar comparing how close they are if you think of the vectors as pointing",
    "start": "2573720",
    "end": "2578880"
  },
  {
    "text": "in a direction what is the coine of the angle between them and one minus to make it look like a loss so that when they're",
    "start": "2578880",
    "end": "2584359"
  },
  {
    "text": "pointing in the same direction you get zero and uh this is a uh another thing that's available uh in uh mxnet uh for",
    "start": "2584359",
    "end": "2592720"
  },
  {
    "text": "making recommendations uh systems I'll give you a very very kind of um brief demo of this I'm not actually going to",
    "start": "2592720",
    "end": "2600119"
  },
  {
    "start": "2595000",
    "end": "2755000"
  },
  {
    "text": "train a dssm because they are uh they're complicated they're rich I think they're",
    "start": "2600119",
    "end": "2605720"
  },
  {
    "text": "beautiful um but even finding a data set and getting one ready uh to do this would be",
    "start": "2605720",
    "end": "2611000"
  },
  {
    "text": "a chunk of work but I'll show you that with really just a few extra lines of code um you can start out with your",
    "start": "2611000",
    "end": "2618240"
  },
  {
    "text": "image and up here uh all I did was I just imported alexnet which is uh uh",
    "start": "2618240",
    "end": "2624559"
  },
  {
    "text": "probably the most well-known convolutional neural network it's not the best performing but it's uh it's",
    "start": "2624559",
    "end": "2629640"
  },
  {
    "text": "it's really wellknown and uh relatively simple and we we passed our image uh",
    "start": "2629640",
    "end": "2635599"
  },
  {
    "text": "through the Alex net to get the Futures we pass the title through the sparse bag of words projection layer um which is an",
    "start": "2635599",
    "end": "2643240"
  },
  {
    "text": "efficient way to take a very high dimensional sparse representation and compress it down to a medium dimensional",
    "start": "2643240",
    "end": "2648839"
  },
  {
    "text": "representation that you can easily work with on uh a GPU and a neural network and we do the same thing for uh the",
    "start": "2648839",
    "end": "2656160"
  },
  {
    "text": "user's queries uh and we put them together and I'll show you what this neural network looks like oops I hope I",
    "start": "2656160",
    "end": "2661680"
  },
  {
    "text": "didn't erase anything there no okay um and again the same pattern at the top",
    "start": "2661680",
    "end": "2668280"
  },
  {
    "text": "we're trying to predict the label we have some comparison uh and we get to uh",
    "start": "2668280",
    "end": "2673800"
  },
  {
    "text": "we get the two embeddings together but then you you go down further and you see that those embeddings are themselves a",
    "start": "2673800",
    "end": "2679880"
  },
  {
    "text": "combination of other embeddings which are generated from either the user ID or the search query or the the title words",
    "start": "2679880",
    "end": "2687920"
  },
  {
    "text": "in the movie or this one's the image and if you follow it all the way down this series of operations is that Alex net",
    "start": "2687920",
    "end": "2695480"
  },
  {
    "text": "and uh at the very bottom is the image itself which is the uh um which goes",
    "start": "2695480",
    "end": "2701880"
  },
  {
    "text": "through that convolutional neural network to semantically understand the content of the image uh and so this is a",
    "start": "2701880",
    "end": "2707680"
  },
  {
    "text": "this is a pretty complex neural network I'm not going to try and train it for you here today but uh the the idea is",
    "start": "2707680",
    "end": "2714760"
  },
  {
    "text": "that um using mxet it's really easy to express these highly complex ideas uh",
    "start": "2714760",
    "end": "2722160"
  },
  {
    "text": "for how to one of these days you'd think I'd figure out how to get the thing back again there we go um uh for for how to",
    "start": "2722160",
    "end": "2729480"
  },
  {
    "text": "combine these things using a a dssm and I've got a couple of inspirational references the canonical paper",
    "start": "2729480",
    "end": "2735599"
  },
  {
    "text": "describing dssm um the uh paper on YouTube recommendations that came out",
    "start": "2735599",
    "end": "2740960"
  },
  {
    "text": "recently uh uses a lot of these ideas and I I love that order embedding paper as a a different application of the dssm",
    "start": "2740960",
    "end": "2748240"
  },
  {
    "text": "you want take some pictures these slides will be available um somewhere I'll I'll I'll tweet them when they get up um uh",
    "start": "2748240",
    "end": "2756040"
  },
  {
    "start": "2755000",
    "end": "3056000"
  },
  {
    "text": "uh and this is like I say this is a great a great set of techniques if you really want to start pulling in diverse",
    "start": "2756040",
    "end": "2761880"
  },
  {
    "text": "sets of data in order to improve your recommendations uh another trick if you kind of want to go the other way away",
    "start": "2761880",
    "end": "2767680"
  },
  {
    "text": "from the highest possible quality but emphasize scale and uh computational",
    "start": "2767680",
    "end": "2773200"
  },
  {
    "text": "speed is to uh use user level modeling uh user level models now think about",
    "start": "2773200",
    "end": "2779559"
  },
  {
    "text": "when you've got those embeddings what are you going to do to make those predictions you need some function which",
    "start": "2779559",
    "end": "2784640"
  },
  {
    "text": "is to get the top us top movies for a user well like I said you have to compare the distance between your user",
    "start": "2784640",
    "end": "2790880"
  },
  {
    "text": "and each of your movies and you might think of this as kind of a geometric uh",
    "start": "2790880",
    "end": "2796200"
  },
  {
    "text": "search problem but when you get up to 64 Dimensions uh uh things like um uh KD",
    "start": "2796200",
    "end": "2801680"
  },
  {
    "text": "trees turn out to just not work and so what you need to do in practice uh typically is just go through every",
    "start": "2801680",
    "end": "2807720"
  },
  {
    "text": "single movie and run that comparison um to get the score and then you sort that",
    "start": "2807720",
    "end": "2813480"
  },
  {
    "text": "and you pick the top movies and this might seem like if you have a big catalog like it's going to be",
    "start": "2813480",
    "end": "2819359"
  },
  {
    "text": "computationally intensive and yeah it's it can be computationally intensive to do this so these embeddings based",
    "start": "2819359",
    "end": "2824559"
  },
  {
    "text": "strategies can be um difficult to work with at at Large Scale so uh wouldn't it",
    "start": "2824559",
    "end": "2830880"
  },
  {
    "text": "be nice to just get all of those predictions all at once train a single model which is uh takes in the user and",
    "start": "2830880",
    "end": "2837040"
  },
  {
    "text": "it spits out uh a a set of recommendations for every possible movie",
    "start": "2837040",
    "end": "2842599"
  },
  {
    "text": "that the uh that the user is interested in and then you just sort that and and you're done and",
    "start": "2842599",
    "end": "2850119"
  },
  {
    "text": "conceptually this this might seem like a bit of a cheat because that model might be doing the exact same thing under the",
    "start": "2850119",
    "end": "2856079"
  },
  {
    "text": "cover it might be going through that tight Loop of uh comparing every movie and in practice that's actually true but",
    "start": "2856079",
    "end": "2862960"
  },
  {
    "text": "remember again how these gpus work if that model is running once in in the GPU",
    "start": "2862960",
    "end": "2869280"
  },
  {
    "text": "using the highly optimized deep learning framework then that thing can run orders of magnitude faster than any control",
    "start": "2869280",
    "end": "2876000"
  },
  {
    "text": "language any python or jvm code that you're going to write is going to be dramatically slower than something",
    "start": "2876000",
    "end": "2881200"
  },
  {
    "text": "that's actually built into the model uh so having a single model that does all of this for you at once can give you",
    "start": "2881200",
    "end": "2888200"
  },
  {
    "text": "really big speed improvements and really big scale improvements uh and so what uh what that looks like um well there's a",
    "start": "2888200",
    "end": "2895400"
  },
  {
    "text": "bunch of ways you might formulate it but uh you might formulate it uh um as an",
    "start": "2895400",
    "end": "2901079"
  },
  {
    "text": "input bag of movies which is analogous to a bag of words and an output bag of movies and the question is then how do",
    "start": "2901079",
    "end": "2907240"
  },
  {
    "text": "you how do you represent what the user has done into an input and output and typically people will just pull uh put",
    "start": "2907240",
    "end": "2914359"
  },
  {
    "text": "some time based cut off like maybe you'll say pick a point in time and say everything before that is the input and you're trying to predict future uh movie",
    "start": "2914359",
    "end": "2921640"
  },
  {
    "text": "consumption in the output uh or you'll say let's try and predict just the very the very last movie that they watched or",
    "start": "2921640",
    "end": "2927520"
  },
  {
    "text": "the next five movies or something like that uh and you can run a a neural network like this and a key difference",
    "start": "2927520",
    "end": "2934799"
  },
  {
    "text": "here um is that now this is a multi-label neural network so instead of",
    "start": "2934799",
    "end": "2940799"
  },
  {
    "text": "just predicting a single number now we are predicting thousands of numbers we're predicting thousands of zeros or",
    "start": "2940799",
    "end": "2946799"
  },
  {
    "text": "ones and those output values are sparse just like the input values are",
    "start": "2946799",
    "end": "2952640"
  },
  {
    "text": "sparse uh and so you need some uh you need some special tools to uh to deal",
    "start": "2952640",
    "end": "2957960"
  },
  {
    "text": "with this uh efficiently and another thing that comes up is that with these",
    "start": "2957960",
    "end": "2963000"
  },
  {
    "text": "sparse data you have uh some number of movies in the input and some number of movies in the output and conceptually",
    "start": "2963000",
    "end": "2970000"
  },
  {
    "text": "we're just storing the IDS for each of them you you got a bunch of IDs in the input a bunch of IDs in the output uh",
    "start": "2970000",
    "end": "2975799"
  },
  {
    "text": "and you're going to feed all of these into the neural network now gpus like I say they love crunching on matrices",
    "start": "2975799",
    "end": "2982400"
  },
  {
    "text": "right matrices are rectangles and if you have a variable number of entries in uh",
    "start": "2982400",
    "end": "2988319"
  },
  {
    "text": "each row of your Matrix then it's it's not a rectangle anymore right it's got this kind of jagged edge so uh what you",
    "start": "2988319",
    "end": "2995079"
  },
  {
    "text": "have to do well uh one way and and a way that I recommend to to deal with this is you just Pat it out uh to the end uh",
    "start": "2995079",
    "end": "3003200"
  },
  {
    "text": "with something that indicates that it's supposed to be blank minus one is uh is what we've used in uh in our code um and",
    "start": "3003200",
    "end": "3011799"
  },
  {
    "text": "uh this means that in some cases you need to pick a cutoff value and you probably have some tail users that are",
    "start": "3011799",
    "end": "3018599"
  },
  {
    "text": "crazy and they watch you know hundreds or thousands of movies and you're not going to be able to uh represent everything they've done into the size of",
    "start": "3018599",
    "end": "3025200"
  },
  {
    "text": "Matrix and they're going to get clipped okay whatever uh they're the exceptions um and you're going to have some minus",
    "start": "3025200",
    "end": "3031240"
  },
  {
    "text": "ones on the end uh and uh this works well and on the output side uh you need",
    "start": "3031240",
    "end": "3037520"
  },
  {
    "text": "a different kind of loss label that can deal with these multiple uh prediction simultaneously and a good loss function",
    "start": "3037520",
    "end": "3044200"
  },
  {
    "text": "that we've introduced in this uh this package that uh uh that I'm sharing with you all is a cross entropy lost it's uh",
    "start": "3044200",
    "end": "3051440"
  },
  {
    "text": "good at making thousands of uh simultaneous predictions on on these binary labels so all of the stuff that I",
    "start": "3051440",
    "end": "3058359"
  },
  {
    "start": "3056000",
    "end": "3132000"
  },
  {
    "text": "showed you is available for you to try for yourself uh so here's a link to the",
    "start": "3058359",
    "end": "3063400"
  },
  {
    "text": "Deep learning Ami again I encourage you to uh try it before passing judgment",
    "start": "3063400",
    "end": "3068559"
  },
  {
    "text": "based on the early reviews um we do listen to feedback so if you do find anything wrong with it please do leave",
    "start": "3068559",
    "end": "3074920"
  },
  {
    "text": "us some leave us a review and we will address that as well but uh I really do think that we've gotten it to a pretty",
    "start": "3074920",
    "end": "3080280"
  },
  {
    "text": "darn good shape in fact we just added CPU support um uh so uh mxnet runs very",
    "start": "3080280",
    "end": "3087520"
  },
  {
    "text": "well on CPUs and with these new C5 instances with the Skylake uh G um uh",
    "start": "3087520",
    "end": "3093040"
  },
  {
    "text": "Skylake processors and the AVX 512 uh instructions you can actually get pretty",
    "start": "3093040",
    "end": "3098280"
  },
  {
    "text": "good floating Point performance uh out of a CP out of a CPU and we've got Intel's mkl blast Library pre-loaded um",
    "start": "3098280",
    "end": "3106240"
  },
  {
    "text": "and so you don't have to uh uh pay for an expensive uh GPU instance to uh to",
    "start": "3106240",
    "end": "3111440"
  },
  {
    "text": "run the stuff uh to try it out and all of the example code is is uh posted up on GitHub uh in the mxet example um",
    "start": "3111440",
    "end": "3119720"
  },
  {
    "text": "section under uh under recommenders and uh with that uh I will",
    "start": "3119720",
    "end": "3125880"
  },
  {
    "text": "thank",
    "start": "3125880",
    "end": "3128078"
  },
  {
    "text": "you",
    "start": "3131799",
    "end": "3134799"
  }
]
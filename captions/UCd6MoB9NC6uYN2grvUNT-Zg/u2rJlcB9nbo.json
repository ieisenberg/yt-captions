[
  {
    "start": "0",
    "end": "223000"
  },
  {
    "text": "hello everyone welcome to the broadcast today a little bit different broadcast",
    "start": "3480",
    "end": "9220"
  },
  {
    "text": "the new normal today normally we do a deep dive on a particular sage maker",
    "start": "9220",
    "end": "14889"
  },
  {
    "text": "built-in algorithm today's a little bit special we breaking from the norm and we have a couple of special again special guests so you",
    "start": "14889",
    "end": "21100"
  },
  {
    "text": "don't have the same presenters as normal my name is Chris burns if you've been on any of the broadcasts",
    "start": "21100",
    "end": "26320"
  },
  {
    "text": "in the past or have worked with us any length of time hopefully recognize the name I'm a Solutions Architect you're",
    "start": "26320",
    "end": "32648"
  },
  {
    "text": "focusing on AI and m/l partners and of course just reminder this is a special series just for you ml partners now you",
    "start": "32649",
    "end": "40390"
  },
  {
    "text": "have the competency so you get this these new special broadcasts to help you long down your path from machine",
    "start": "40390",
    "end": "46420"
  },
  {
    "text": "learning so with me today I have a I apologize in advance if I get",
    "start": "46420",
    "end": "51460"
  },
  {
    "text": "the pronunciations incorrect I have Simon coerced and Oliver a senior ml scientist I also have a Thomas Delta",
    "start": "51460",
    "end": "58420"
  },
  {
    "text": "applied scientist and what we're going to talk about today is more of a scenario rather than a single algorithm",
    "start": "58420",
    "end": "64540"
  },
  {
    "text": "it's a it's a pipeline if you will and it's going to deal with : OCR off of",
    "start": "64540",
    "end": "69759"
  },
  {
    "text": "pages that are a combination of handwritten as well as type text so when",
    "start": "69759",
    "end": "74890"
  },
  {
    "text": "we talk about OCR it's sort of old-school to talk about OCR but to do it very well",
    "start": "74890",
    "end": "80439"
  },
  {
    "text": "it's still very very difficult and to do it well with a combination of dense text",
    "start": "80439",
    "end": "85750"
  },
  {
    "text": "and sparse text and handwritten text and tight text this is still quite a challenge so today like I said it's a",
    "start": "85750",
    "end": "91899"
  },
  {
    "text": "scenario this is an experimental scenario so just to set expectations I want to make sure you don't understand",
    "start": "91899",
    "end": "97359"
  },
  {
    "text": "this is not something that's a pretty built service from AWS that you can just go and use this is a really a demonstration of how to pipeline some",
    "start": "97359",
    "end": "104439"
  },
  {
    "text": "algorithms into a nice process and so we're going to learn about today a little about some CNN's four-page",
    "start": "104439",
    "end": "110520"
  },
  {
    "text": "segmentation we're going to learn about some SSDs single shot multi box for line",
    "start": "110520",
    "end": "115960"
  },
  {
    "text": "detection and then a very clever use of CNN by lsdm so that's a bi-directional",
    "start": "115960",
    "end": "121140"
  },
  {
    "text": "lsdm for handwritten text recognition not almost spend too much more your time",
    "start": "121140",
    "end": "126549"
  },
  {
    "text": "when you get this over to Thomas and Simon mainly to the good stuff as usual if you have any questions please put",
    "start": "126549",
    "end": "132610"
  },
  {
    "text": "those into the questions box I'll be monitoring that and I'll try to splice those into the in the presentation when it's",
    "start": "132610",
    "end": "138040"
  },
  {
    "text": "appropriate and so with that Thomas and Simon I will hand it over to you thank",
    "start": "138040",
    "end": "144030"
  },
  {
    "text": "you so my name is Thomas and I'm gonna",
    "start": "144030",
    "end": "149110"
  },
  {
    "text": "present you the work that I've been collaborating on with Linton we had this",
    "start": "149110",
    "end": "154390"
  },
  {
    "text": "semi PhD candidate from the University of Toronto Jonathan Jonathan Chang and",
    "start": "154390",
    "end": "159940"
  },
  {
    "text": "the problem we asked him to work on and that problem that was brought by some of",
    "start": "159940",
    "end": "165519"
  },
  {
    "text": "our customers specifically working with sage maker is how can you extract text",
    "start": "165519",
    "end": "173620"
  },
  {
    "text": "from handwritten documents so if you if",
    "start": "173620",
    "end": "178810"
  },
  {
    "text": "you look at this kind of document here these are typically you have a lot of forms in the banking industry in the",
    "start": "178810",
    "end": "186489"
  },
  {
    "text": "healthcare industry is a low industry lots of data has been scanned and",
    "start": "186489",
    "end": "192849"
  },
  {
    "text": "digitized but inside the handwritten text has not been able to be extracting",
    "start": "192849",
    "end": "198640"
  },
  {
    "text": "a public fashion to be indexed and searchable and reused so we we looked at",
    "start": "198640",
    "end": "205630"
  },
  {
    "text": "this problem and we thought how can we solve that so first thing we did was to",
    "start": "205630",
    "end": "211359"
  },
  {
    "text": "gather a dataset 410 text recognition the world recognized dataset is called",
    "start": "211359",
    "end": "219609"
  },
  {
    "text": "the I am handwritten database it's made of six hundred and fifty seven different",
    "start": "219609",
    "end": "225579"
  },
  {
    "start": "223000",
    "end": "223000"
  },
  {
    "text": "writers more than 1500 page of scanned text and what's really interesting is",
    "start": "225579",
    "end": "230769"
  },
  {
    "text": "each of these pages have been segmented at the Forum level so we get a bounding",
    "start": "230769",
    "end": "238150"
  },
  {
    "text": "box around the forms we get bounding box around the lines and we get bonding",
    "start": "238150",
    "end": "243489"
  },
  {
    "text": "banks around the world themselves right so you can really build algorithms at",
    "start": "243489",
    "end": "249160"
  },
  {
    "text": "any level that you want what's really interesting about having about this data",
    "start": "249160",
    "end": "254380"
  },
  {
    "text": "set in my opinion is how many writers you have because detecting recognizing",
    "start": "254380",
    "end": "259709"
  },
  {
    "text": "like the handwritten text of a single",
    "start": "259709",
    "end": "264760"
  },
  {
    "text": "writer is not such a complicated task what's hard is to generalize at all the different",
    "start": "264760",
    "end": "270260"
  },
  {
    "text": "ways people use so people use cursive people your script people use a combination of the two so really the",
    "start": "270260",
    "end": "277550"
  },
  {
    "text": "difficulty lies in being able to develop an algorithm that capture as this",
    "start": "277550",
    "end": "283190"
  },
  {
    "text": "variety of handwriting's to keep to make sure it's",
    "start": "283190",
    "end": "289190"
  },
  {
    "text": "precise here when we split or training a know testing data and we split that by writer right so all the writers from the",
    "start": "289190",
    "end": "296720"
  },
  {
    "text": "testing set I've never been encountered in the training set okay so told you a bit more about the",
    "start": "296720",
    "end": "304880"
  },
  {
    "text": "solution we thought about so we thought instead of we try to break down the",
    "start": "304880",
    "end": "310490"
  },
  {
    "start": "308000",
    "end": "308000"
  },
  {
    "text": "problem into a series of different individual easier to solve problems the",
    "start": "310490",
    "end": "316820"
  },
  {
    "text": "first one was how can we detect handwritten blobs",
    "start": "316820",
    "end": "322190"
  },
  {
    "text": "so first uniform the objective was to find a single paragraph of text but",
    "start": "322190",
    "end": "332810"
  },
  {
    "text": "that's going to be the first part of the talk and I tell you how we solve that so in the second part we given a paragraph",
    "start": "332810",
    "end": "341330"
  },
  {
    "text": "we want to segment and get individual lines and that's necessary because of how we build or character recognition",
    "start": "341330",
    "end": "351340"
  },
  {
    "text": "algorithm and in its you we cannot have two lines one on top of each other so we",
    "start": "351340",
    "end": "356480"
  },
  {
    "text": "first have to segment either by line or by word once we've done that and we get the line segmented then we can do",
    "start": "356480",
    "end": "364840"
  },
  {
    "text": "handwriting recognition and then we have a mapping from line to line and then we can bring that back if we want back to",
    "start": "364840",
    "end": "372110"
  },
  {
    "text": "the original input image to have proper mapping of the text on the form to the",
    "start": "372110",
    "end": "377390"
  },
  {
    "text": "one we recognized and in this handwriting recognition is really made of two parts one is to recognize the",
    "start": "377390",
    "end": "384830"
  },
  {
    "text": "most likely characters but quite often that's not that's not enough because the",
    "start": "384830",
    "end": "390290"
  },
  {
    "text": "most likely character is not always the right character I'll show you a few example but sometimes you you could",
    "start": "390290",
    "end": "396140"
  },
  {
    "text": "swear taking along that letter for example either you but really it's an N",
    "start": "396140",
    "end": "402170"
  },
  {
    "text": "and only makes sense in context so you need a language model to correct the errors",
    "start": "402170",
    "end": "408580"
  },
  {
    "text": "that you character recognition algorithm as done so we're gonna see how we can",
    "start": "408580",
    "end": "415759"
  },
  {
    "text": "build this end-to-end pipeline using MX nets and specifically we use glue just",
    "start": "415759",
    "end": "422979"
  },
  {
    "text": "just a point to all the code of all these experiments I'm going to talk about is available online in a github",
    "start": "422979",
    "end": "430250"
  },
  {
    "text": "repo and I'll show the link in a few slides also we have pre train models for",
    "start": "430250",
    "end": "436490"
  },
  {
    "text": "each of these steps so you're really able if you want to just speak there is one notebook that does really end-to-end",
    "start": "436490",
    "end": "442690"
  },
  {
    "text": "inference from the form all the way to the text and you know very much welcome",
    "start": "442690",
    "end": "448490"
  },
  {
    "text": "to try that yourself and we make we made the free train models available as well",
    "start": "448490",
    "end": "454520"
  },
  {
    "text": "so the first part any any question so far okay so the first part page",
    "start": "454520",
    "end": "465139"
  },
  {
    "text": "segmentation so maybe this part is the one that's really kind of tailored to the I am data set so that the one that's",
    "start": "465139",
    "end": "471680"
  },
  {
    "text": "slightly less applicable in the generalized manner but if you see how we do like segmentation that's something",
    "start": "471680",
    "end": "478460"
  },
  {
    "text": "you could apply in a more general type of form so I was also the first task we",
    "start": "478460",
    "end": "483800"
  },
  {
    "start": "482000",
    "end": "482000"
  },
  {
    "text": "gave to Jonathan and he was ramping up with the use of MX net coming from the PI touch background and if I can quote",
    "start": "483800",
    "end": "493550"
  },
  {
    "text": "one of his comment was it was surprised how easy and how nice she was to work with MX and gluon he took him maybe a",
    "start": "493550",
    "end": "501139"
  },
  {
    "text": "day to ramp up and be up to speed on the API of MX net so why I say that this",
    "start": "501139",
    "end": "508400"
  },
  {
    "text": "kind of tailored to this task is because all these forms coming from the I am",
    "start": "508400",
    "end": "513768"
  },
  {
    "text": "database are structuring the same manner there is a written text at the top and then you have the handwriting hundreds",
    "start": "513769",
    "end": "522768"
  },
  {
    "text": "and transcript below it so it's not a milky object detection it's a single",
    "start": "522769",
    "end": "528589"
  },
  {
    "text": "object detection we try to approaches the first one we really want when we try",
    "start": "528589",
    "end": "534470"
  },
  {
    "text": "to solve this problem we really we had this was less of a research approach we",
    "start": "534470",
    "end": "541459"
  },
  {
    "text": "wanted to detect we wanted to solve the problem so we were not like trying to use the most cutting-edge solutions we",
    "start": "541459",
    "end": "548990"
  },
  {
    "text": "wanted to find the state-of-the-art the best solution that would get us to to",
    "start": "548990",
    "end": "555949"
  },
  {
    "text": "solution the fastest so we tried first deterministic approach using maximally",
    "start": "555949",
    "end": "562370"
  },
  {
    "start": "562000",
    "end": "562000"
  },
  {
    "text": "stable extreme operations so that's a purely deterministic approach it's available using open CV you can very",
    "start": "562370",
    "end": "570050"
  },
  {
    "text": "easily develop this algorithm the idea is quite simple you first detect blobs and you make rectangle around em and you",
    "start": "570050",
    "end": "579019"
  },
  {
    "text": "can use blob detection from fancy V and then you add the other hyper parameters",
    "start": "579019",
    "end": "584870"
  },
  {
    "text": "Delta by which you increase the boundary of these blobs and then you look at the",
    "start": "584870",
    "end": "590420"
  },
  {
    "text": "overlap between these regions and if you have an overlap greater than a specific",
    "start": "590420",
    "end": "596180"
  },
  {
    "text": "parameter then you merge the blobs and then it's an iterative process and you",
    "start": "596180",
    "end": "602689"
  },
  {
    "text": "can see it's actually decently good at capturing regions on the page but we had",
    "start": "602689",
    "end": "608480"
  },
  {
    "text": "two issues with this approach the first one was for every form we could find a",
    "start": "608480",
    "end": "614600"
  },
  {
    "text": "set of hyper parameters I would give us a perfect result however each of these",
    "start": "614600",
    "end": "620930"
  },
  {
    "text": "appearances were different from one form to another so we couldn't have it wasn't like a single solution we could apply",
    "start": "620930",
    "end": "627230"
  },
  {
    "text": "with hundred percent accuracy so the second issue was time it would on a like",
    "start": "627230",
    "end": "634579"
  },
  {
    "text": "normal machine I would use it would take maybe like 10 seconds to find all the",
    "start": "634579",
    "end": "640100"
  },
  {
    "text": "books so not something we could apply in real time for training so we decided to",
    "start": "640100",
    "end": "648050"
  },
  {
    "text": "take a second approach using a conditional neural network and really what since we knew we were only doing",
    "start": "648050",
    "end": "654290"
  },
  {
    "text": "single object detection what we are trying to predict where for values the",
    "start": "654290",
    "end": "659540"
  },
  {
    "text": "top left corner made of x and y coordinates and then the width and the height of the box around the text we",
    "start": "659540",
    "end": "667250"
  },
  {
    "text": "want to detect so for that we took a relatively simple as in an approach some",
    "start": "667250",
    "end": "675110"
  },
  {
    "text": "coalitional layer some pooling to but",
    "start": "675110",
    "end": "680749"
  },
  {
    "text": "not too much because we don't want to lose too much of the spatial resolution because here we had a problem that was",
    "start": "680749",
    "end": "687079"
  },
  {
    "text": "extremely specially correlated we knew we wanted a the box was kind of always",
    "start": "687079",
    "end": "695059"
  },
  {
    "text": "the same same area in our forms and then some free connected layers and then this",
    "start": "695059",
    "end": "701509"
  },
  {
    "text": "last four hidden units each of them with a sigmoid output we're anything between",
    "start": "701509",
    "end": "708470"
  },
  {
    "text": "zero and one because every we our coordinates are like relative right so",
    "start": "708470",
    "end": "715699"
  },
  {
    "text": "one would mean at the bottom or the right and zero via the top left top left",
    "start": "715699",
    "end": "722809"
  },
  {
    "text": "corner and same for wiesen heads really chief to the total size of the image and",
    "start": "722809",
    "end": "730149"
  },
  {
    "start": "729000",
    "end": "729000"
  },
  {
    "text": "so I thought that was pretty simple problem we had very good like training data and I thought it would works right",
    "start": "730149",
    "end": "737420"
  },
  {
    "text": "away and we actually had we found that we had difficulties to reach good accuracy on the testing set the reason",
    "start": "737420",
    "end": "744800"
  },
  {
    "text": "was the data set was a bit too uniform",
    "start": "744800",
    "end": "749949"
  },
  {
    "text": "so what we did was adding some data augmentation so if you can see here but",
    "start": "749949",
    "end": "756110"
  },
  {
    "text": "we shifted the forms a bit up and down adding some padding left and right just to make the values slightly less",
    "start": "756110",
    "end": "764389"
  },
  {
    "text": "predictable so he lays the same so the top left corner is not always at the same position and this increased a lot",
    "start": "764389",
    "end": "771379"
  },
  {
    "text": "the accuracy and another technique we used and was to first trying to minimize",
    "start": "771379",
    "end": "777949"
  },
  {
    "start": "773000",
    "end": "773000"
  },
  {
    "text": "the mean square error for all these values and when we reached a good enough",
    "start": "777949",
    "end": "783529"
  },
  {
    "text": "overlap that we can find you knew using the iou which is the intersection of a",
    "start": "783529",
    "end": "790040"
  },
  {
    "text": "union and why we don't do that at the very beginning because at the very beginning you might not have any",
    "start": "790040",
    "end": "796959"
  },
  {
    "text": "intersection and then you would have just consistently zero for your for your",
    "start": "796959",
    "end": "804170"
  },
  {
    "text": "IOU so if we look at the results I don't",
    "start": "804170",
    "end": "810149"
  },
  {
    "start": "808000",
    "end": "808000"
  },
  {
    "text": "know if you can see that clearly but the algorithm after a few hundred gbox learns really well and effectively if we",
    "start": "810149",
    "end": "822180"
  },
  {
    "text": "look at the quantitative analysis of the results we managed to capture every box",
    "start": "822180",
    "end": "828649"
  },
  {
    "text": "why why it's important and when you take a pipeline approach and I think it's",
    "start": "828649",
    "end": "835230"
  },
  {
    "text": "true for not just OCR but any kind of approach I been approached to do for",
    "start": "835230",
    "end": "841890"
  },
  {
    "text": "machine learning is you need to be extremely careful because each step introduced a loss that cannot be",
    "start": "841890",
    "end": "848910"
  },
  {
    "text": "recovered in any further step so for example here if you do a bad cropping of",
    "start": "848910",
    "end": "853950"
  },
  {
    "text": "your phone then it's data that you will never be able to analyze later so for",
    "start": "853950",
    "end": "860880"
  },
  {
    "text": "each of these preliminary pre-processing steps the we really strive to get 100%",
    "start": "860880",
    "end": "867300"
  },
  {
    "text": "accuracy because as seemingly simple problems but you really want to have",
    "start": "867300",
    "end": "875130"
  },
  {
    "text": "your loss on the character recognition no not on the text cropping so it's very important",
    "start": "875130",
    "end": "882000"
  },
  {
    "text": "to to a very robust algorithm there so any question on the page segmentation",
    "start": "882000",
    "end": "889440"
  },
  {
    "text": "part we do it one question Thomas the",
    "start": "889440",
    "end": "895470"
  },
  {
    "text": "other question was the pages appear to come all in landscape orientation if you",
    "start": "895470",
    "end": "902699"
  },
  {
    "text": "will I'm sorry I thought not masculine portrait if they were coming in landscape or rotated how does the",
    "start": "902699",
    "end": "908760"
  },
  {
    "text": "algorithm treat that text so in that case the issue you might have is you",
    "start": "908760",
    "end": "918630"
  },
  {
    "text": "could have shape means matching between for your deep neural networks so let's",
    "start": "918630",
    "end": "923970"
  },
  {
    "text": "say you're using a hybridized version of your model then you expect the input data to be in a specific shape so if you",
    "start": "923970",
    "end": "932850"
  },
  {
    "text": "rotate it and you don't like rotate back the image into the same",
    "start": "932850",
    "end": "938940"
  },
  {
    "text": "dimension that would be your first issue but it's not insurmountable it's not",
    "start": "938940",
    "end": "944130"
  },
  {
    "text": "even so two moons about issue you could for example rotate back your landscape to portrait and then probably you",
    "start": "944130",
    "end": "950970"
  },
  {
    "text": "couldn't use next straightaway is the",
    "start": "950970",
    "end": "955980"
  },
  {
    "text": "same pre-trained model but if you had enough training data that was both in",
    "start": "955980",
    "end": "961770"
  },
  {
    "text": "portrait and landscape then I assume it would work very well the alternative is",
    "start": "961770",
    "end": "968670"
  },
  {
    "text": "to pad your data to be square so you add some some white or black at the bottom",
    "start": "968670",
    "end": "978570"
  },
  {
    "text": "at the top or if it's in a lens ka if it's in a portrait the left and the",
    "start": "978570",
    "end": "984330"
  },
  {
    "text": "right and you get square input and that way you have you don't have you don't need to rotate your data and your",
    "start": "984330",
    "end": "992040"
  },
  {
    "text": "algorithm can pick up features that are consistently in the same orientation",
    "start": "992040",
    "end": "997220"
  },
  {
    "text": "because the issue when you rotate is then the features are going to be rotated as well that make sense okay so",
    "start": "997220",
    "end": "1010040"
  },
  {
    "text": "the next step once we have our forms that have been extracted so we have pure hundred handwritten text at that point",
    "start": "1010040",
    "end": "1016580"
  },
  {
    "text": "then we can do line segmentation so input is an image continuing honey and",
    "start": "1016580",
    "end": "1023090"
  },
  {
    "start": "1017000",
    "end": "1017000"
  },
  {
    "text": "written text an output is a bunch of bounding boxes for each hundred and nine so that's we in the realm of mutable",
    "start": "1023090",
    "end": "1030800"
  },
  {
    "text": "object detection and here we we tried two approaches the first one was using",
    "start": "1030800",
    "end": "1036410"
  },
  {
    "text": "SSD so single-shot meaty bugs detector so the M is missing from the name but",
    "start": "1036410",
    "end": "1041750"
  },
  {
    "text": "that's that's why it's called and using SSD for words directly so the single",
    "start": "1041750",
    "end": "1051380"
  },
  {
    "start": "1047000",
    "end": "1047000"
  },
  {
    "text": "shot meaty bug detector we took the base implementation that's available in",
    "start": "1051380",
    "end": "1056500"
  },
  {
    "text": "Korean TV sorry on TV it's a glue on computer vision it's a contribution toolkit",
    "start": "1056500",
    "end": "1061880"
  },
  {
    "text": "available for mix net it comes with several pre-trained and non pre-trained",
    "start": "1061880",
    "end": "1068929"
  },
  {
    "text": "algorithm for object detection image segmentation and in turn segmentation in okay sweetles",
    "start": "1068929",
    "end": "1075019"
  },
  {
    "text": "ESS the implementation for object segmentation and we customized a few steps first their data augmentation we",
    "start": "1075019",
    "end": "1082820"
  },
  {
    "text": "use the data commentation that's specific to our tasks and I'll I'll speak about that in a minute we used different default anchor",
    "start": "1082820",
    "end": "1090769"
  },
  {
    "text": "boxes so I kept existing incorporate prior in your in your own your model so",
    "start": "1090769",
    "end": "1098059"
  },
  {
    "text": "if you have a prior on what the object looks like that is where you put it we change the network architecture again to",
    "start": "1098059",
    "end": "1105320"
  },
  {
    "text": "fit better our problem and we tweak the NMS non maximum suppression thresholds",
    "start": "1105320",
    "end": "1112789"
  },
  {
    "text": "to get better results and that the combination of all these tweaking that",
    "start": "1112789",
    "end": "1118010"
  },
  {
    "text": "really gets us really good results because the base so maybe there is a lesson here which is sometimes you find",
    "start": "1118010",
    "end": "1125510"
  },
  {
    "text": "pre-trained model or you find pre-trained premade architectures and",
    "start": "1125510",
    "end": "1130610"
  },
  {
    "text": "you don't get good results I guess my the learning for us was keep tweaking",
    "start": "1130610",
    "end": "1138309"
  },
  {
    "text": "and incorporate problem specific changes to get better results so I said we use",
    "start": "1138309",
    "end": "1146690"
  },
  {
    "start": "1145000",
    "end": "1145000"
  },
  {
    "text": "specific data commentation effectively what we did was take some text some",
    "start": "1146690",
    "end": "1154549"
  },
  {
    "text": "lines and remove them so you see here we move that one here remove that one I was",
    "start": "1154549",
    "end": "1160580"
  },
  {
    "text": "just for the to make sure the algorithm doesn't same expect always who have all",
    "start": "1160580",
    "end": "1168139"
  },
  {
    "text": "the lines one after each other because we have some cases where it's not the case maybe some people if some space in",
    "start": "1168139",
    "end": "1173539"
  },
  {
    "text": "between few lines so it's important to to add a bit more noise in the training",
    "start": "1173539",
    "end": "1180230"
  },
  {
    "text": "data to avoid overfitting for the anchor boxes SSD how it works on every slide",
    "start": "1180230",
    "end": "1187700"
  },
  {
    "start": "1183000",
    "end": "1183000"
  },
  {
    "text": "just after that is the code more details so think about for every pixel of a",
    "start": "1187700",
    "end": "1193549"
  },
  {
    "text": "feature Maps when you're done when you have your feature as representation of your images you're gonna have unis try",
    "start": "1193549",
    "end": "1200600"
  },
  {
    "text": "to predict whether you you have a given",
    "start": "1200600",
    "end": "1206230"
  },
  {
    "text": "objects and and you're gonna what you're trying to predict with SSD is your",
    "start": "1206779",
    "end": "1211859"
  },
  {
    "text": "trained predict from a inputs pry your ankle box like one of these you're going",
    "start": "1211859",
    "end": "1218009"
  },
  {
    "text": "to try to predict how much you need to shift the box in X&Y and how much you",
    "start": "1218009",
    "end": "1224609"
  },
  {
    "text": "need to shift the width and the height and why why all that makes sense is",
    "start": "1224609",
    "end": "1234359"
  },
  {
    "text": "because you have also a loss trying to minimize this shift think you're doing so that's why the prior is important",
    "start": "1234359",
    "end": "1240690"
  },
  {
    "text": "because each anchor box is going to try to still kind of stick to the prior but",
    "start": "1240690",
    "end": "1246899"
  },
  {
    "text": "do the necessary modification to get the best prediction so if we look at this",
    "start": "1246899",
    "end": "1253529"
  },
  {
    "text": "example you have two objects we're trying to detect and here it's going to",
    "start": "1253529",
    "end": "1260279"
  },
  {
    "text": "be easier for example this anchor box here is prior anchor box to move to be",
    "start": "1260279",
    "end": "1266190"
  },
  {
    "text": "that one and this one are going to be easier to move to be that one then shifting that one to be the dog for",
    "start": "1266190",
    "end": "1273599"
  },
  {
    "text": "example because of this loss that's penalized by how much you changing a",
    "start": "1273599",
    "end": "1278989"
  },
  {
    "text": "priority box and you have thousands of them so speaker images here seventeen",
    "start": "1278989",
    "end": "1285330"
  },
  {
    "text": "seventeen seventeen thousan anchor boxes that each of them what they do is they",
    "start": "1285330",
    "end": "1290580"
  },
  {
    "text": "predict five things they predict the Delta in X&Y the Delta in weights and",
    "start": "1290580",
    "end": "1297450"
  },
  {
    "text": "hate and the class that this box should be right so when I say five really when",
    "start": "1297450",
    "end": "1307349"
  },
  {
    "text": "you look at the implementation it's four plus M as n the number of classes so",
    "start": "1307349",
    "end": "1312570"
  },
  {
    "text": "each of your class gets a specific value and then you apply softmax and then you get a distribution poverty of other the",
    "start": "1312570",
    "end": "1318809"
  },
  {
    "text": "classes that this anchor box is supposed to capture",
    "start": "1318809",
    "end": "1326029"
  },
  {
    "text": "okay so if we look at the network architecture we we get our image we take",
    "start": "1326380",
    "end": "1333970"
  },
  {
    "start": "1328000",
    "end": "1328000"
  },
  {
    "text": "resonate 34 which we found was a good compromise in it's a pre-trained model",
    "start": "1333970",
    "end": "1339880"
  },
  {
    "text": "on image net so it's data segment of million images with thousand different classes we use it pre-trained because it",
    "start": "1339880",
    "end": "1347230"
  },
  {
    "text": "has already learned to capture all the features all the patterns that are important to detect when you're doing",
    "start": "1347230",
    "end": "1354280"
  },
  {
    "text": "object detection an image specification and we remove the first layer why we do",
    "start": "1354280",
    "end": "1359409"
  },
  {
    "text": "that so it's again speaking of shape mismatch so this one is not in weights and hate",
    "start": "1359409",
    "end": "1365970"
  },
  {
    "text": "it's a mismatch in depth so resonates at",
    "start": "1365970",
    "end": "1372789"
  },
  {
    "text": "if all was trained with RGB images RGB",
    "start": "1372789",
    "end": "1378669"
  },
  {
    "text": "images make that the first layer your first commercial layer will have",
    "start": "1378669",
    "end": "1387210"
  },
  {
    "text": "coefficient on kernels which are which have three dimensions which are on the",
    "start": "1388409",
    "end": "1395559"
  },
  {
    "text": "depth dimension number three so one for each of your inputs layer so one kernel",
    "start": "1395559",
    "end": "1403000"
  },
  {
    "text": "for all one kernel for G one can therefore be in our case we have greyscale image the grayscale image is",
    "start": "1403000",
    "end": "1410650"
  },
  {
    "text": "only a depth of one so only values between zero and one on the gray scale",
    "start": "1410650",
    "end": "1416289"
  },
  {
    "text": "on the grayscale so here when you when you have this problem you have a few",
    "start": "1416289",
    "end": "1422169"
  },
  {
    "text": "ways to solve it you could just duplicate your grayscale value on the three RGB channel so you go back with an",
    "start": "1422169",
    "end": "1429640"
  },
  {
    "text": "RGB image which is basically three times the same grayscale image and in our dual",
    "start": "1429640",
    "end": "1437770"
  },
  {
    "text": "orientation you actually get the grayscale image but that's using more memory the alternative is to look at the",
    "start": "1437770",
    "end": "1444909"
  },
  {
    "text": "first layer and what you can do is either pick only one of the channels for",
    "start": "1444909",
    "end": "1452169"
  },
  {
    "text": "your filters so you can pick for example the channels on the green Channel other",
    "start": "1452169",
    "end": "1460090"
  },
  {
    "text": "red channel of the blue channel or what you can do alternatively is to just take the average of each of these channels",
    "start": "1460090",
    "end": "1467620"
  },
  {
    "text": "and get if you want grayscale kernels so that's we tried these three approaches",
    "start": "1467620",
    "end": "1476100"
  },
  {
    "text": "what we found was roughly the same performance however to us he made more",
    "start": "1476100",
    "end": "1485049"
  },
  {
    "text": "sense to take the average of the kernels and so we don't use extra memory to move",
    "start": "1485049",
    "end": "1491529"
  },
  {
    "text": "the input to RGB so that's what we did so we took the we took the pre-training",
    "start": "1491529",
    "end": "1497529"
  },
  {
    "text": "first layer and then we averaged the canal across the depth dimension so we left with grayscale channels for our",
    "start": "1497529",
    "end": "1505000"
  },
  {
    "text": "convolution then after the first pass of",
    "start": "1505000",
    "end": "1510520"
  },
  {
    "text": "ResNet we left with feature maps that were present the feature I'd version of",
    "start": "1510520",
    "end": "1517270"
  },
  {
    "text": "our image one thing we've seen is people",
    "start": "1517270",
    "end": "1522370"
  },
  {
    "text": "have different size of handwriting's some people write like this big letters",
    "start": "1522370",
    "end": "1527529"
  },
  {
    "text": "and people is monitors so to solve this issue and that's actually part of SSD",
    "start": "1527529",
    "end": "1533490"
  },
  {
    "text": "like this is the paper in the implementation we use different scales so we have some dense sampling steps",
    "start": "1533490",
    "end": "1540570"
  },
  {
    "text": "where we're going to reduce the spatial resolution of our feature maps and at",
    "start": "1540570",
    "end": "1546610"
  },
  {
    "text": "each step we do a bonding box prediction and category prediction for each of our",
    "start": "1546610",
    "end": "1553330"
  },
  {
    "text": "anchor boxes so the down sampler is relatively simple we are just doing some",
    "start": "1553330",
    "end": "1562000"
  },
  {
    "text": "collisions and then some max pooling so the divide the resolution by two and for",
    "start": "1562000",
    "end": "1571090"
  },
  {
    "text": "the categories Union what we do is",
    "start": "1571090",
    "end": "1576658"
  },
  {
    "text": "slightly is slightly different than what you're used to like usually",
    "start": "1577230",
    "end": "1583539"
  },
  {
    "text": "classification is done through a fully connected layer but if you do a",
    "start": "1583539",
    "end": "1590640"
  },
  {
    "text": "convolution with a certain number of good Channel and this number for example",
    "start": "1590640",
    "end": "1597040"
  },
  {
    "text": "correspond to your number of classes then you can see each of the conditional",
    "start": "1597040",
    "end": "1603550"
  },
  {
    "text": "operation on your feature maps as a prediction of belonging to this given class on this specific area of your",
    "start": "1603550",
    "end": "1611890"
  },
  {
    "text": "feature map so that's what we do and in",
    "start": "1611890",
    "end": "1617230"
  },
  {
    "text": "all case the number of classes is one",
    "start": "1617230",
    "end": "1623680"
  },
  {
    "text": "it's either aligned oh it's not aligned right so this gives us a bunch of",
    "start": "1623680",
    "end": "1632370"
  },
  {
    "text": "bounding box that have we have a threshold where you say okay it's open 5c spawning box with this shift in x and",
    "start": "1632370",
    "end": "1640510"
  },
  {
    "text": "y and whit's and hate is a good candidate and it probably contains the line but remember we start with almost",
    "start": "1640510",
    "end": "1648090"
  },
  {
    "text": "17,000 bounding boxes and also bunny boxes are going to end up like around the same area all predicting that this",
    "start": "1648090",
    "end": "1655120"
  },
  {
    "text": "is aligned so what you need to do is to do merge this bounding box merge them",
    "start": "1655120",
    "end": "1661780"
  },
  {
    "start": "1657000",
    "end": "1657000"
  },
  {
    "text": "all look at which one actually is slightly higher than the other with a big overlap so simply but you look if",
    "start": "1661780",
    "end": "1668380"
  },
  {
    "text": "there is an overlap and the overlap is big enough you cannot keep the one that has a highest prediction value and this",
    "start": "1668380",
    "end": "1676600"
  },
  {
    "text": "threshold that you're using you're using can be tricked and from the left to the",
    "start": "1676600",
    "end": "1684010"
  },
  {
    "text": "right you can see with when you don't put the non maximum suppression so you",
    "start": "1684010",
    "end": "1690280"
  },
  {
    "text": "can see lots of different prediction around the same areas and then when you do not maximum situation so lot cleaner",
    "start": "1690280",
    "end": "1696100"
  },
  {
    "text": "outputs so again here you can see that's",
    "start": "1696100",
    "end": "1701620"
  },
  {
    "start": "1700000",
    "end": "1700000"
  },
  {
    "text": "this visualization and I'll show you after afterwards is built with MX bold M",
    "start": "1701620",
    "end": "1709420"
  },
  {
    "text": "export it's a MX net plugin for 10 support so you can plot images losses",
    "start": "1709420",
    "end": "1716490"
  },
  {
    "text": "audio whatever all your different metrics you can plot them intense about",
    "start": "1716490",
    "end": "1723850"
  },
  {
    "text": "using MX bowl so that's how we got that and you can see the algorithm is slowly",
    "start": "1723850",
    "end": "1729520"
  },
  {
    "text": "learning to capture the lines so if we",
    "start": "1729520",
    "end": "1735760"
  },
  {
    "start": "1735000",
    "end": "1735000"
  },
  {
    "text": "look at the result and the IOU we got around nine point six she's",
    "start": "1735760",
    "end": "1742420"
  },
  {
    "text": "pretty good and in almost every cases we",
    "start": "1742420",
    "end": "1748230"
  },
  {
    "text": "we got the line in a good enough fashion that we could do the optical character",
    "start": "1748230",
    "end": "1755050"
  },
  {
    "text": "recognition but we had a few failure cases like for example this one you can",
    "start": "1755050",
    "end": "1761500"
  },
  {
    "text": "see exact because of how the non maximum separation works and he looks at overlaps we ended up sometimes with like",
    "start": "1761500",
    "end": "1768430"
  },
  {
    "text": "two regions like almost touching each other and if you remember what I said about pipelining you know like this line",
    "start": "1768430",
    "end": "1776080"
  },
  {
    "text": "we know that we never recognize it because we're splitting it in two and",
    "start": "1776080",
    "end": "1781180"
  },
  {
    "text": "then it would really mess up our own pipeline so even though we had maybe in",
    "start": "1781180",
    "end": "1787110"
  },
  {
    "text": "1998 99 percent of the cases you would work well enough and I wasn't good",
    "start": "1787110",
    "end": "1792820"
  },
  {
    "text": "enough for us so we will try the different approach and that approach was a mix of deterministic and deep learning",
    "start": "1792820",
    "end": "1800470"
  },
  {
    "start": "1796000",
    "end": "1796000"
  },
  {
    "text": "approach so we use the exact same algorithm as detecting four lines and we use that to detect words and then we",
    "start": "1800470",
    "end": "1807790"
  },
  {
    "text": "used a simple little mystic algorithm to create the lines the algorithm was look",
    "start": "1807790",
    "end": "1813190"
  },
  {
    "text": "at my box another box on the right if there is then you can open operate it in",
    "start": "1813190",
    "end": "1818740"
  },
  {
    "text": "the line and so on and so forth and you continue like that and it's very fast because you're only interesting over",
    "start": "1818740",
    "end": "1824020"
  },
  {
    "text": "bonding boxes and at most of like 50 of them 100 and the results were extremely",
    "start": "1824020",
    "end": "1831160"
  },
  {
    "text": "good so after that we managed to capture every line of forms so now we left with",
    "start": "1831160",
    "end": "1842700"
  },
  {
    "text": "well-defined lines of handwritten texts and we're going to move to a handwriting recognition but is there any question",
    "start": "1842700",
    "end": "1849700"
  },
  {
    "text": "before hand we do have a question Thomas",
    "start": "1849700",
    "end": "1855090"
  },
  {
    "text": "yep what was the language specifically trained",
    "start": "1855090",
    "end": "1860860"
  },
  {
    "text": "scenario is most likely English but what are the what are the implications of",
    "start": "1860860",
    "end": "1866200"
  },
  {
    "text": "training against different languages so right now until we reach that point I",
    "start": "1866200",
    "end": "1874150"
  },
  {
    "text": "would say very little for most Latin languages then I I'm not a linguist and",
    "start": "1874150",
    "end": "1886690"
  },
  {
    "text": "Simon Singh is here but I know some basically some languages you might learn",
    "start": "1886690",
    "end": "1892030"
  },
  {
    "text": "lie in the concept of line Mike might make less sense you might read from top",
    "start": "1892030",
    "end": "1897820"
  },
  {
    "text": "to bottom right to left and so on and so forth so you might need to have some",
    "start": "1897820",
    "end": "1904620"
  },
  {
    "text": "language specific training data but for most languages so far that works in a",
    "start": "1904620",
    "end": "1912660"
  },
  {
    "text": "line fashion and here we're not even talking left to right or right to left because it doesn't really matter for us",
    "start": "1912660",
    "end": "1919020"
  },
  {
    "text": "then that would work but when we come to the character recognition and I'm going",
    "start": "1919020",
    "end": "1925990"
  },
  {
    "text": "to speak to that in a bit on if you want I'll add something into the implication",
    "start": "1925990",
    "end": "1931030"
  },
  {
    "text": "of working with different vocabularies and different alphabets then yes it would change quite a few stuff so when",
    "start": "1931030",
    "end": "1945730"
  },
  {
    "start": "1945000",
    "end": "1945000"
  },
  {
    "text": "you come to handwriting recognition you get as inputs an image of a single line of handwritten texts and what you want",
    "start": "1945730",
    "end": "1954150"
  },
  {
    "text": "yeah there is a concept of time step so let me explain what the time step here",
    "start": "1954150",
    "end": "1959620"
  },
  {
    "text": "so we look at the image as a time in",
    "start": "1959620",
    "end": "1965440"
  },
  {
    "text": "quotes aligned data so they aligned in that case left to right so if we sliced",
    "start": "1965440",
    "end": "1972370"
  },
  {
    "text": "the input image in n slices let's say 50",
    "start": "1972370",
    "end": "1977429"
  },
  {
    "text": "then when I say time step I mean one of these vertical slice okay we're gonna",
    "start": "1977429",
    "end": "1985299"
  },
  {
    "text": "pass all these slices through all handwriting detection",
    "start": "1985299",
    "end": "1993330"
  },
  {
    "text": "model for each of these slices we're going to predict what character this",
    "start": "1994310",
    "end": "2000340"
  },
  {
    "text": "slice might be and character could be just the empty character like no character",
    "start": "2000340",
    "end": "2006160"
  },
  {
    "text": "and the output would be probability distribution over the alphabet and here",
    "start": "2006160",
    "end": "2013750"
  },
  {
    "text": "that's why it matters so I think for the English what English text we use like",
    "start": "2013750",
    "end": "2021070"
  },
  {
    "text": "upper case lower case and a bunch of special characters so what we what you",
    "start": "2021070",
    "end": "2030910"
  },
  {
    "text": "need to be careful here for example if you are trying to translate to do the",
    "start": "2030910",
    "end": "2036430"
  },
  {
    "text": "same way as a Chinese is your vocabulary of characters is extremely you know a",
    "start": "2036430",
    "end": "2044350"
  },
  {
    "text": "lot more a lot larger right like you would have thousands of these characters and maybe the approach wouldn't work",
    "start": "2044350",
    "end": "2049929"
  },
  {
    "text": "that well because you wouldn't have as many you would have a very imbalanced data sets what's here in that case it's",
    "start": "2049930",
    "end": "2057760"
  },
  {
    "text": "a lot easier to control how balanced your data searches because peony is picking of like sixty characters if you",
    "start": "2057760",
    "end": "2066520"
  },
  {
    "text": "if you work with the language that there's a lot of accents as well you",
    "start": "2066520",
    "end": "2072610"
  },
  {
    "text": "might have a very large vocabulary as well so you maybe you could look at",
    "start": "2072610",
    "end": "2078820"
  },
  {
    "text": "different approaches where you're trying to predict a letter and then maybe a different an accent at the same times so",
    "start": "2078820",
    "end": "2087510"
  },
  {
    "text": "English is maybe indeed one of the easiest one to apply this this technique",
    "start": "2087510",
    "end": "2095470"
  },
  {
    "text": "on and the one that most likely what's the best so traditionally we based our",
    "start": "2095470",
    "end": "2103720"
  },
  {
    "start": "2101000",
    "end": "2101000"
  },
  {
    "text": "web based approach on a paper that's using CNN and by Alyssia the idea is to",
    "start": "2103720",
    "end": "2110590"
  },
  {
    "text": "first do a pass with a combination only or networks that we extract features for",
    "start": "2110590",
    "end": "2117790"
  },
  {
    "text": "more images we start with a grayscale image and then we we end up with a bunch of feature maps that I've",
    "start": "2117790",
    "end": "2126150"
  },
  {
    "text": "inside the extracted features of the image that then we slice that in vertical slices like that each of them",
    "start": "2127060",
    "end": "2136120"
  },
  {
    "text": "being like a time step again I say time but that's because all data or signal is",
    "start": "2136120",
    "end": "2141910"
  },
  {
    "text": "a line from left to right because we're reading like left to right so we can be like like it's a time step and we pass",
    "start": "2141910",
    "end": "2149920"
  },
  {
    "text": "that through LSTA a by a last year so left to right and right to left",
    "start": "2149920",
    "end": "2155880"
  },
  {
    "text": "yeah so this are also inaccurate because you should also show that it goes on the",
    "start": "2156360",
    "end": "2162340"
  },
  {
    "text": "other side and then for each time step you gets a hidden state of your Alessia",
    "start": "2162340",
    "end": "2168480"
  },
  {
    "text": "these these hidden States you pass them through a fully connected layer but as",
    "start": "2168480",
    "end": "2175000"
  },
  {
    "text": "as many hidden unit as you have characters so for example here the",
    "start": "2175000",
    "end": "2180130"
  },
  {
    "text": "hidden units for M will give you 80%",
    "start": "2180130",
    "end": "2185710"
  },
  {
    "text": "probability that the first time step belongs to the M character so we went a",
    "start": "2185710",
    "end": "2196480"
  },
  {
    "start": "2192000",
    "end": "2192000"
  },
  {
    "text": "bit further we at this issue where some lines to now if you're trying to a line",
    "start": "2196480",
    "end": "2202630"
  },
  {
    "text": "again same dimensions and you need to stretch some lines and some of those less so you end up with different scales",
    "start": "2202630",
    "end": "2208930"
  },
  {
    "text": "of handwriting just some people write bigger some people write smaller so",
    "start": "2208930",
    "end": "2214060"
  },
  {
    "text": "which okay we took a trick from the SSD book I would say so we added a done",
    "start": "2214060",
    "end": "2220690"
  },
  {
    "text": "sampling step from the resonates feature extracting step where we had some image",
    "start": "2220690",
    "end": "2229300"
  },
  {
    "text": "features that we passed through by LST m and then we also did another done sampling step where we reduced again the",
    "start": "2229300",
    "end": "2236410"
  },
  {
    "text": "size of for future maps and a different LS diem was used and then the hidden say",
    "start": "2236410",
    "end": "2243820"
  },
  {
    "text": "for each time step is concatenated so each time step in the end is represented",
    "start": "2243820",
    "end": "2251290"
  },
  {
    "text": "as equal intonation of the hidden state of the LST m at two different scales so",
    "start": "2251290",
    "end": "2257680"
  },
  {
    "text": "I would say when you have when you have problems when you're doing",
    "start": "2257680",
    "end": "2263890"
  },
  {
    "text": "basic detection or even image classification and differencing like that it's always good to have this done",
    "start": "2263890",
    "end": "2269829"
  },
  {
    "text": "sampling step or taking features at different scales it really helps your",
    "start": "2269829",
    "end": "2275349"
  },
  {
    "text": "network to be able to to reuse this",
    "start": "2275349",
    "end": "2283509"
  },
  {
    "text": "information basically so we and then",
    "start": "2283509",
    "end": "2293380"
  },
  {
    "text": "like I said you have your your hidden states all and this orange stuff",
    "start": "2293380",
    "end": "2298749"
  },
  {
    "text": "represent a fully connected layer where each is a character and in that case we",
    "start": "2298749",
    "end": "2304539"
  },
  {
    "text": "can see if I can play the first time step highest probability is null point 23 okay so now you might think okay it's",
    "start": "2304539",
    "end": "2314019"
  },
  {
    "text": "speaking about time steps and he said hundreds of them and you predict H but then maybe H is over two or three times",
    "start": "2314019",
    "end": "2321099"
  },
  {
    "text": "steps for how do you do that right how do you align your label with your input",
    "start": "2321099",
    "end": "2326769"
  },
  {
    "text": "so that's that's a big issue in all case we don't want to we don't want to split",
    "start": "2326769",
    "end": "2331989"
  },
  {
    "text": "our image in 100 slices and then manually go and say hey that's nothing nothing nothing h @ h ee l I'll just",
    "start": "2331989",
    "end": "2340509"
  },
  {
    "text": "double l and so on and so forth so that's where the CPC loss comes in so",
    "start": "2340509",
    "end": "2347799"
  },
  {
    "start": "2344000",
    "end": "2344000"
  },
  {
    "text": "that's a problem where when you want to do alignments of sequences and you don't",
    "start": "2347799",
    "end": "2353739"
  },
  {
    "text": "have the arrayed alignment you just it",
    "start": "2353739",
    "end": "2358839"
  },
  {
    "text": "comes with a few constraints for example it's a monotonic many-to-one",
    "start": "2358839",
    "end": "2364839"
  },
  {
    "text": "which means your inputs the alignment in our case is its left or right needs to",
    "start": "2364839",
    "end": "2372039"
  },
  {
    "text": "be aligned with your outputs in the same order so that's the kind of the",
    "start": "2372039",
    "end": "2377559"
  },
  {
    "text": "monotonic ID it's it's it's as it's growing in the same direction so you",
    "start": "2377559",
    "end": "2383859"
  },
  {
    "text": "couldn't have hello written here and try to predict haleh right it wouldn't work",
    "start": "2383859",
    "end": "2390670"
  },
  {
    "text": "with the CDC also it's many-to-one which means you need more inputs than output okay",
    "start": "2390670",
    "end": "2398880"
  },
  {
    "text": "however despite this conference is extremely powerful because you don't",
    "start": "2398880",
    "end": "2405040"
  },
  {
    "text": "need to do alignments it all automatically learns the alignments of your input and your output and how it",
    "start": "2405040",
    "end": "2413950"
  },
  {
    "text": "does is define the collapse function so each of your time step each of these",
    "start": "2413950",
    "end": "2419380"
  },
  {
    "text": "slices can be pretty like I said HHH HHH ie nothing at all nothing L 0 0 and this",
    "start": "2419380",
    "end": "2426250"
  },
  {
    "text": "nothing is actually a special character it's necessary because files open when you have like double the same token the",
    "start": "2426250",
    "end": "2433599"
  },
  {
    "text": "double L well you need to you need to",
    "start": "2433599",
    "end": "2438760"
  },
  {
    "text": "distinguish that between HHH HHH train so the collapsing function says if you",
    "start": "2438760",
    "end": "2445150"
  },
  {
    "text": "have repeated characters then they collapse to a single character if you",
    "start": "2445150",
    "end": "2450700"
  },
  {
    "text": "have repeated character but separated it by the empty character symbol then they",
    "start": "2450700",
    "end": "2458410"
  },
  {
    "text": "collapse to two different characters right it's like a stop and then you start again so this has practical",
    "start": "2458410",
    "end": "2465819"
  },
  {
    "text": "implication for example when you deciding how many slices you should",
    "start": "2465819",
    "end": "2471369"
  },
  {
    "text": "slash your input because of something you decide you need to take into conduct you need for example for Double L to be",
    "start": "2471369",
    "end": "2478000"
  },
  {
    "text": "able to correctly predict Double L you need at least three slices right 1 L 1",
    "start": "2478000",
    "end": "2483329"
  },
  {
    "text": "stop character and 100 and the last bit of the correcting function is if you",
    "start": "2483329",
    "end": "2488800"
  },
  {
    "text": "change character then it's as if you had to stop in between right so it's gonna be L and then oh so that's that's how",
    "start": "2488800",
    "end": "2500470"
  },
  {
    "text": "the city CP collapsing function works and if you if you look at how we can",
    "start": "2500470",
    "end": "2509740"
  },
  {
    "text": "train or model so the beauty of the city sees that it's differentiable because",
    "start": "2509740",
    "end": "2515170"
  },
  {
    "text": "when you train your model and you want to detect hello you you have the ground",
    "start": "2515170",
    "end": "2523690"
  },
  {
    "text": "from the hello string and then you want to if you use for example the",
    "start": "2523690",
    "end": "2531869"
  },
  {
    "text": "cross and throw pillows you want to look at the poverty of predicting hello so",
    "start": "2531869",
    "end": "2537339"
  },
  {
    "text": "you don't need to care about it because obviously if you think that's the probability for each time each slices",
    "start": "2537339",
    "end": "2543099"
  },
  {
    "text": "each slice predict over the entire alphabet a distribution probability and then the next slice as well next class",
    "start": "2543099",
    "end": "2549520"
  },
  {
    "text": "as well so it's intractable if you try to compute the exact probability for",
    "start": "2549520",
    "end": "2555849"
  },
  {
    "text": "each string that can be predicted with this algorithm it's completely intractable and goes into the 80 to the",
    "start": "2555849",
    "end": "2564069"
  },
  {
    "text": "32 power of 80 or something like that it's not doable but we are only",
    "start": "2564069",
    "end": "2569770"
  },
  {
    "text": "interested in the probability of creating the correct the correct label",
    "start": "2569770",
    "end": "2579279"
  },
  {
    "text": "so the correct level there is only a finite amount of ways to get to the",
    "start": "2579279",
    "end": "2586240"
  },
  {
    "text": "correct label right so you might have h h e e l oh right and how the ctc",
    "start": "2586240",
    "end": "2596200"
  },
  {
    "text": "algorithm works to the system so I forgot connection is simple what sorry",
    "start": "2596200",
    "end": "2605760"
  },
  {
    "text": "classification loss is you don't actually try to go through the entire",
    "start": "2605760",
    "end": "2612760"
  },
  {
    "text": "tree every time it's saving the intermediate values of the publishes for",
    "start": "2612760",
    "end": "2618190"
  },
  {
    "text": "each of the step so in the end it is called dynamic programming it's using dynamic programming in order to make the",
    "start": "2618190",
    "end": "2624819"
  },
  {
    "text": "computation a lot more efficient and if you look at the actual operation you're",
    "start": "2624819",
    "end": "2630430"
  },
  {
    "text": "doing to get this final prediction accuracy for the Wrights label is so",
    "start": "2630430",
    "end": "2635770"
  },
  {
    "text": "many sums and multiplication right so quality of this won't play with the",
    "start": "2635770",
    "end": "2640930"
  },
  {
    "text": "purity of this one plus this one and so on so forth so it's different",
    "start": "2640930",
    "end": "2645940"
  },
  {
    "text": "differentiable because it's only multiplication and addition and if it's differentiable it means you can then",
    "start": "2645940",
    "end": "2651760"
  },
  {
    "text": "tweak the weights of your network according to the gradient of the loss",
    "start": "2651760",
    "end": "2657869"
  },
  {
    "text": "with so you get the gradient with respect of the lost city Silla also computed and",
    "start": "2657869",
    "end": "2664870"
  },
  {
    "text": "you modify the new algorithm to minimize that loss and so on and so forth so you can train it with a stochastic gradient",
    "start": "2664870",
    "end": "2670570"
  },
  {
    "text": "descent and that makes it extremely efficient to train so that was for",
    "start": "2670570",
    "end": "2678940"
  },
  {
    "start": "2677000",
    "end": "2677000"
  },
  {
    "text": "training training is easy we know we know the correct label and that's what we try to get the probability of",
    "start": "2678940",
    "end": "2684910"
  },
  {
    "text": "breaking a cable but for inference we're stuck because we don't know the correct level and if we wanted to get the real",
    "start": "2684910",
    "end": "2693630"
  },
  {
    "text": "probability for each of the possible label like I said it's intractable so there are different approaches to that",
    "start": "2693630",
    "end": "2699970"
  },
  {
    "text": "the simplest one is a greedy approach or the best path approach but that can lead",
    "start": "2699970",
    "end": "2706390"
  },
  {
    "text": "you to some kind of in weird situation just take this example you have an",
    "start": "2706390",
    "end": "2714220"
  },
  {
    "text": "alphabet made of a B and the empty character and let's say for the first",
    "start": "2714220",
    "end": "2719320"
  },
  {
    "text": "time slice we predict a null point for for a and 0.6 was the empty character",
    "start": "2719320",
    "end": "2726550"
  },
  {
    "text": "for the second time slice we predict null point for for a and 0.6 for the",
    "start": "2726550",
    "end": "2731950"
  },
  {
    "text": "empty character so if we take the greedy approach then okay first time slice we",
    "start": "2731950",
    "end": "2738880"
  },
  {
    "text": "say it's most likely to be an empty character second tie slaves is most likely to be an empty character then the",
    "start": "2738880",
    "end": "2746110"
  },
  {
    "text": "probability of the actually so there's a",
    "start": "2746110",
    "end": "2751180"
  },
  {
    "text": "result of implicit Renetta characters empty string so if total probability is 9.6 and 1.6 it's null point 36 however",
    "start": "2751180",
    "end": "2759640"
  },
  {
    "text": "if we look at the past I'd say a followed by empty character or a",
    "start": "2759640",
    "end": "2764770"
  },
  {
    "text": "followed or I'm terrified by a a followed by a which all resolved to the",
    "start": "2764770",
    "end": "2771600"
  },
  {
    "text": "string a and we sum these probabilities we get null point 64 so the greedy",
    "start": "2771600",
    "end": "2778120"
  },
  {
    "text": "approach where we take just for each time slice a maximum value doesn't",
    "start": "2778120",
    "end": "2784180"
  },
  {
    "text": "always give you the correct highest probability of the final label so you",
    "start": "2784180",
    "end": "2790900"
  },
  {
    "text": "need a heuristic or a technique so we'll",
    "start": "2790900",
    "end": "2797430"
  },
  {
    "text": "give you a balance between shaking every",
    "start": "2797430",
    "end": "2802869"
  },
  {
    "text": "path in the tree to get the real poverty and the one that just takes a greedy approach that the high authority of each",
    "start": "2802869",
    "end": "2809289"
  },
  {
    "text": "time sighs and the answer to that problem is being such so beam such what",
    "start": "2809289",
    "end": "2815589"
  },
  {
    "start": "2811000",
    "end": "2811000"
  },
  {
    "text": "it does is you keep a certain amount of s candidates and then you go from each",
    "start": "2815589",
    "end": "2821829"
  },
  {
    "text": "base candidate stage to the next stage you look at what a much is possible and you update the quality of your best",
    "start": "2821829",
    "end": "2828520"
  },
  {
    "text": "candidates so when you use the CTC low",
    "start": "2828520",
    "end": "2834400"
  },
  {
    "start": "2834000",
    "end": "2834000"
  },
  {
    "text": "the problem is like I said there is a collapsing function so for example if you have a and then followed by a you're",
    "start": "2834400",
    "end": "2841150"
  },
  {
    "text": "not going to get the string a a you still get the same string a because two characters of two x lives that have the",
    "start": "2841150",
    "end": "2849160"
  },
  {
    "text": "same predicted characters like we said we call up them into a single character so it's very similar each time step you",
    "start": "2849160",
    "end": "2858039"
  },
  {
    "text": "look at the extensions we look at how this extension collapse in two strings",
    "start": "2858039",
    "end": "2863859"
  },
  {
    "text": "we serve the priority of these same strings and so on and so forth right so it gives us in our case we use like 20",
    "start": "2863859",
    "end": "2871660"
  },
  {
    "text": "candidates and gives us a kind of good approximation of the best most probable",
    "start": "2871660",
    "end": "2877960"
  },
  {
    "text": "labels okay so that was one thing the",
    "start": "2877960",
    "end": "2886119"
  },
  {
    "start": "2881000",
    "end": "2881000"
  },
  {
    "text": "next thing we can think of because now we have our predicted tokens they people",
    "start": "2886119",
    "end": "2895390"
  },
  {
    "text": "don't write very well so some characters might be off and might really look like a different font so that's why we want",
    "start": "2895390",
    "end": "2901180"
  },
  {
    "text": "to have the language modeling come into play and the same place simplest language modeling you can do is you can",
    "start": "2901180",
    "end": "2906880"
  },
  {
    "text": "just try to do some spell checking so you look at the closest word so we used",
    "start": "2906880",
    "end": "2917109"
  },
  {
    "text": "a note of the Shelf like word correction",
    "start": "2917109",
    "end": "2922869"
  },
  {
    "text": "from I think energy ko spacing and you look at the Edit distance how many",
    "start": "2922869",
    "end": "2928359"
  },
  {
    "text": "insertion addition or swap you need to do in order",
    "start": "2928359",
    "end": "2934980"
  },
  {
    "text": "to get to a correct world and that's what you use as a as a weight to wait",
    "start": "2934980",
    "end": "2941910"
  },
  {
    "text": "just call like proposals however we found that this actually gave us worst result than the pure OCR what worked",
    "start": "2941910",
    "end": "2949980"
  },
  {
    "text": "really well is to weight each type of insertion deletion or swap by how how",
    "start": "2949980",
    "end": "2960540"
  },
  {
    "text": "much how similar letters are for example like I said U and n people tend to write",
    "start": "2960540",
    "end": "2966420"
  },
  {
    "text": "them very similarly or oh and a the very they look very similar so they have a",
    "start": "2966420",
    "end": "2971430"
  },
  {
    "text": "lower weight and this was the weight were computed by doing first trying to",
    "start": "2971430",
    "end": "2979470"
  },
  {
    "text": "align the prediction of the OCR with a real label and look at which character",
    "start": "2979470",
    "end": "2984750"
  },
  {
    "text": "where mismatch and that's how what we used if I go very quickly because I",
    "start": "2984750",
    "end": "2990869"
  },
  {
    "text": "think we may be running a bit out of time we get the output we contract we D",
    "start": "2990869",
    "end": "2999510"
  },
  {
    "text": "contract the text which means for example we replace don't with do not",
    "start": "2999510",
    "end": "3004720"
  },
  {
    "text": "tokenize this works as we have predicted look at each suggested word and for each",
    "start": "3004720",
    "end": "3010040"
  },
  {
    "text": "suggested word for we take the minimum the one with a minimum at this distance",
    "start": "3010040",
    "end": "3016820"
  },
  {
    "text": "with the distance like I said weighted by how similar the letters were swapping",
    "start": "3016820",
    "end": "3022490"
  },
  {
    "text": "off and then we D tokenize away means we we reconstruct the words that we had so",
    "start": "3022490",
    "end": "3035800"
  },
  {
    "start": "3034000",
    "end": "3034000"
  },
  {
    "text": "that was for the first approach kind of data slightly deterministic approach and",
    "start": "3035800",
    "end": "3040820"
  },
  {
    "text": "the second one you can do is use a language model so language model typically what it does is you give",
    "start": "3040820",
    "end": "3046480"
  },
  {
    "text": "context usually left context and you say given these strings this list of words",
    "start": "3046480",
    "end": "3053450"
  },
  {
    "text": "what is the most likely what is the description probability of the next word over the entire vocabulary so for",
    "start": "3053450",
    "end": "3062030"
  },
  {
    "text": "example if you say I am screaming in Indy it could be decisively that it's",
    "start": "3062030",
    "end": "3068380"
  },
  {
    "text": "like swimming pool or in the sea in the",
    "start": "3068380",
    "end": "3074000"
  },
  {
    "text": "lake but is unlikely that you say a table right I'm not swimming in the table so we - we use a language model in",
    "start": "3074000",
    "end": "3086390"
  },
  {
    "text": "order to score each of our proposal and high words is using a measure called",
    "start": "3086390",
    "end": "3092900"
  },
  {
    "text": "perplexity and the pegs city do we have you know the big city is a measure of",
    "start": "3092900",
    "end": "3099560"
  },
  {
    "text": "how likely a given sentence here is given a language model so let's say you train your language model on the billion",
    "start": "3099560",
    "end": "3106310"
  },
  {
    "text": "word copies from Google or you have like millions and millions of sentences and",
    "start": "3106310",
    "end": "3112160"
  },
  {
    "text": "you're going to give a bunch of your proposed sentences and the algorithm is gonna tell you well this one because",
    "start": "3112160",
    "end": "3119870"
  },
  {
    "text": "maybe some words are similar they make sense but they don't make sense in this",
    "start": "3119870",
    "end": "3124940"
  },
  {
    "text": "context so that's a way to capture the context of the entire sentence you're trying to predict and that's how we rank",
    "start": "3124940",
    "end": "3132620"
  },
  {
    "text": "the proposals so now let me give you a few sample I don't know if you can read",
    "start": "3132620",
    "end": "3138320"
  },
  {
    "start": "3134000",
    "end": "3134000"
  },
  {
    "text": "from there but we had this sentence",
    "start": "3138320",
    "end": "3144370"
  },
  {
    "text": "which sometimes very hard to read actually the data set got all these",
    "start": "3144370",
    "end": "3150550"
  },
  {
    "text": "lovely things she waved a or you can see a person actually wrote hopefully maybe made a",
    "start": "3150550",
    "end": "3158540"
  },
  {
    "text": "mistake and I cannot scratch it and then when you do the lexicon search out which",
    "start": "3158540",
    "end": "3166370"
  },
  {
    "text": "you got got a this lovely things she waved a and then when you add the beam",
    "start": "3166370",
    "end": "3172940"
  },
  {
    "text": "search plus the D concert and the language model you get a got all these lovely things she waved a so you know",
    "start": "3172940",
    "end": "3180380"
  },
  {
    "text": "you can see it's actually pretty good and we we looked at the cacti all right",
    "start": "3180380",
    "end": "3188000"
  },
  {
    "text": "and every time we added a you have the greedy search gives you 18.9 I mean your",
    "start": "3188000",
    "end": "3194420"
  },
  {
    "text": "lexicon search you go down a little bit and then you when you add the in search you go down again a bit more so it's pretty good still not perfect",
    "start": "3194420",
    "end": "3202550"
  },
  {
    "text": "you can see sometimes where photographers the beam search makes it worse rather than better",
    "start": "3202550",
    "end": "3208780"
  },
  {
    "text": "for example the service my so this one",
    "start": "3209470",
    "end": "3222590"
  },
  {
    "text": "has come for him to be taken seriously as I said one way it's been affixed but if you see here self as a stranger in",
    "start": "3222590",
    "end": "3230630"
  },
  {
    "text": "this oh and it doesn't find the box but again the handwriting is not so good so",
    "start": "3230630",
    "end": "3237520"
  },
  {
    "text": "I'm gonna show you I'm going to show you",
    "start": "3237520",
    "end": "3244130"
  },
  {
    "text": "quickly a bit of code a little bit of results so first let me show you the",
    "start": "3244130",
    "end": "3249670"
  },
  {
    "text": "riddle so this is MX bold MX both like I said is a plugin for things about where you can put your your data and here I",
    "start": "3249670",
    "end": "3256970"
  },
  {
    "text": "train the tickle character recognition part of the algorithm and you can see",
    "start": "3256970",
    "end": "3263720"
  },
  {
    "text": "the loss so the training loss keeps going down and then at some point the testing loss kind of stagnate and if we",
    "start": "3263720",
    "end": "3270050"
  },
  {
    "text": "look at the we can have images and here we have the test images and I'll zoom in",
    "start": "3270050",
    "end": "3276950"
  },
  {
    "text": "a bit so you can see the test results are pretty good like together you see",
    "start": "3276950",
    "end": "3282140"
  },
  {
    "text": "like together was pretty correctly the Potter brought both abroad here we can",
    "start": "3282140",
    "end": "3289550"
  },
  {
    "text": "see a issue where you didn't get the the space between no and matter where you",
    "start": "3289550",
    "end": "3296180"
  },
  {
    "text": "got no matter how one might so that's pretty good and remember that all these",
    "start": "3296180",
    "end": "3302240"
  },
  {
    "text": "writers have never been seen by the algorithm so it's we segregate writers",
    "start": "3302240",
    "end": "3307250"
  },
  {
    "text": "between training and testing set and that's the training data which is",
    "start": "3307250",
    "end": "3316280"
  },
  {
    "text": "actually a lot better but it will be so here hot chili I I think yeah I think",
    "start": "3316280",
    "end": "3324020"
  },
  {
    "text": "it's hurtling but you can see here's algorithm got you wrong right so",
    "start": "3324020",
    "end": "3330050"
  },
  {
    "text": "it's not perfect but definitely in a place where you can start using that for indexing your data and you will get like",
    "start": "3330050",
    "end": "3338240"
  },
  {
    "text": "most of the world out it's not yet perfect transcription and if we look at",
    "start": "3338240",
    "end": "3345350"
  },
  {
    "text": "the code I don't know how many of you are familiar with MX nets so I'll I'll go light on some parts one thing that",
    "start": "3345350",
    "end": "3354610"
  },
  {
    "text": "Jonathan did that's really useful if you're interested in OCR is it created a I am data set data set and it's a base",
    "start": "3354610",
    "end": "3362840"
  },
  {
    "text": "class data set is a base construct in glue that's so you can use it very",
    "start": "3362840",
    "end": "3371480"
  },
  {
    "text": "easily and you can request like the form so you can record the lines you can request the words that's you can use it",
    "start": "3371480",
    "end": "3381290"
  },
  {
    "text": "and for example straight away you get this and then this notebook that's",
    "start": "3381290",
    "end": "3388310"
  },
  {
    "text": "available in this in my repo you might get a rip or you can go to handwritten",
    "start": "3388310",
    "end": "3394430"
  },
  {
    "text": "text recognition MX net the one I'm showing here is a hand-to-hand pipeline so I quickly go over that one where you",
    "start": "3394430",
    "end": "3401690"
  },
  {
    "text": "see it's a segment thing there the text then here's a step where you're",
    "start": "3401690",
    "end": "3409640"
  },
  {
    "text": "signaling the words and from the words you get the lines and then from the",
    "start": "3409640",
    "end": "3415520"
  },
  {
    "text": "lines use and do the language modeling the entire pipeline that I described is here they can just read the code the",
    "start": "3415520",
    "end": "3427910"
  },
  {
    "text": "next for example here you can see that the Peck city I was talking about so I",
    "start": "3427910",
    "end": "3434360"
  },
  {
    "text": "want more eggs that's 7,000 in the complexity it's called and I want more",
    "start": "3434360",
    "end": "3440060"
  },
  {
    "text": "constitutional which don't remake sense is 30,000 and if you just put a bunch of",
    "start": "3440060",
    "end": "3445840"
  },
  {
    "text": "random words and you you you are really above this base lights you're like in",
    "start": "3445840",
    "end": "3452240"
  },
  {
    "text": "the millions and the perplexity is it's",
    "start": "3452240",
    "end": "3459740"
  },
  {
    "text": "a it's a normalized matrix so it's not the get more as you sentence gets longer so",
    "start": "3459740",
    "end": "3465620"
  },
  {
    "text": "for example here you know you're in love when you cannot fall asleep it's kind of it's quite likely sequence of words so",
    "start": "3465620",
    "end": "3473180"
  },
  {
    "text": "you see perplexity still even lower that I want more eggs so if we look at if we",
    "start": "3473180",
    "end": "3484280"
  },
  {
    "text": "look at some of the qualitative results if we look after the language modeling",
    "start": "3484280",
    "end": "3493990"
  },
  {
    "text": "so that's the entire pipeline we this",
    "start": "3493990",
    "end": "3500090"
  },
  {
    "text": "one okay ever been out in a submarine I'll give you two spin around on these",
    "start": "3500090",
    "end": "3506930"
  },
  {
    "text": "days if you like you could write it up Boulais made you know you still not",
    "start": "3506930",
    "end": "3517580"
  },
  {
    "text": "exactly there and we still have some work to do on language modeling but I think it's a usable in an indexing",
    "start": "3517580",
    "end": "3526370"
  },
  {
    "text": "context so on the training part I guess what I",
    "start": "3526370",
    "end": "3532010"
  },
  {
    "text": "want to show you is how easily you can",
    "start": "3532010",
    "end": "3538520"
  },
  {
    "text": "do the training in in gluon so given a",
    "start": "3538520",
    "end": "3545240"
  },
  {
    "text": "data loader which has been it with the dataset you said you pass the data in the",
    "start": "3545240",
    "end": "3553010"
  },
  {
    "text": "context in that case the GPU you pass the label in the GPU you under the auto",
    "start": "3553010",
    "end": "3558800"
  },
  {
    "text": "garage scope you recalled what's happening which means you're going to get automatic differentiation and like we said the loss is differentiable so",
    "start": "3558800",
    "end": "3565670"
  },
  {
    "text": "that's going to be taken care of for us so we we get the outputs of our network",
    "start": "3565670",
    "end": "3573650"
  },
  {
    "text": "so that's the entire step from the CNN",
    "start": "3573650",
    "end": "3580250"
  },
  {
    "text": "arrest um and then classification for each of our time size we compute the",
    "start": "3580250",
    "end": "3586010"
  },
  {
    "text": "loss we do a backward pass which is going to compute the gradient",
    "start": "3586010",
    "end": "3591680"
  },
  {
    "text": "effectively and then we update the weights according to this gradient we just calculated",
    "start": "3591680",
    "end": "3597320"
  },
  {
    "text": "then that's all some logic to some data to em export in order to get the",
    "start": "3597320",
    "end": "3602330"
  },
  {
    "text": "visualization I showed you just before and then we just keep track of all those and keep truffle for epoch loss and that",
    "start": "3602330",
    "end": "3610670"
  },
  {
    "text": "said the training loop and you run that",
    "start": "3610670",
    "end": "3616190"
  },
  {
    "text": "and then you can monitor the training there it's a very good workflow and the",
    "start": "3616190",
    "end": "3623360"
  },
  {
    "text": "ability to but images you're really seeing whether or not your network is training so we found this combination of",
    "start": "3623360",
    "end": "3633170"
  },
  {
    "text": "taking the time basically if I have an advice a conclusion here to give you in terms of how we train that is take the",
    "start": "3633170",
    "end": "3640220"
  },
  {
    "text": "time to put together the proper metrics in order to be able to take action",
    "start": "3640220",
    "end": "3647000"
  },
  {
    "text": "quickly you don't need to wait that your network is fully trained if you see that it's not training that it's only",
    "start": "3647000",
    "end": "3653230"
  },
  {
    "text": "predicting empty characters then you know you need to switch something so one",
    "start": "3653230",
    "end": "3659480"
  },
  {
    "text": "lesson is make sure that you track your training how its learning what it's",
    "start": "3659480",
    "end": "3664880"
  },
  {
    "text": "learning and use that to iterate quickly among different hypotheses because what I'm showing you here it's a result of a",
    "start": "3664880",
    "end": "3671510"
  },
  {
    "text": "lot of trial and error we have different hypotheses how many done something do we need to do and for that is very",
    "start": "3671510",
    "end": "3678710"
  },
  {
    "text": "important to do a parameter searches where you you try different ranges of parameters or you can use a sage maker a",
    "start": "3678710",
    "end": "3686540"
  },
  {
    "text": "parameter search as well with like ocean processes and makes it even easier so",
    "start": "3686540",
    "end": "3693310"
  },
  {
    "text": "yeah so that's what I wanted to show you the code is entirely available feel free",
    "start": "3693310",
    "end": "3698360"
  },
  {
    "text": "to play with it and if you have any issues reach out reach out to me create",
    "start": "3698360",
    "end": "3703670"
  },
  {
    "text": "an issue on the repo and getting edge in the MX net community as well so there is a discuss forum and you're more than",
    "start": "3703670",
    "end": "3710840"
  },
  {
    "text": "welcome to to post your question there I guess you already know about Amazon sage",
    "start": "3710840",
    "end": "3716390"
  },
  {
    "text": "maker and check out the docs and feel free to yeah they make snide specific",
    "start": "3716390",
    "end": "3722540"
  },
  {
    "text": "question to contact MX night - info at amazon.com so we'll be very much happy",
    "start": "3722540",
    "end": "3728690"
  },
  {
    "text": "to get in touch with you and help here with you and makes no troubles so",
    "start": "3728690",
    "end": "3734390"
  },
  {
    "text": "thank you very much was a pleasure to be there this morning and if you want to",
    "start": "3734390",
    "end": "3742370"
  },
  {
    "text": "follow up that's my email address feel free to send me emails and if you have any question or simply still have a bit",
    "start": "3742370",
    "end": "3748820"
  },
  {
    "text": "of time to take some now thank you",
    "start": "3748820",
    "end": "3752590"
  },
  {
    "text": "we do have a couple of questions that came in now one question appreciate",
    "start": "3754960",
    "end": "3760730"
  },
  {
    "text": "forward how long was he district training so when you had that I am he said what was the yes only pick two",
    "start": "3760730",
    "end": "3769250"
  },
  {
    "text": "train it's well we were kind of lucky here at Amazon we're training on a",
    "start": "3769250",
    "end": "3775280"
  },
  {
    "text": "nvidia v hundreds so I believe the the training for the last part is it's less",
    "start": "3775280",
    "end": "3782750"
  },
  {
    "text": "than an hour it's 30 minutes maybe to run 120 bucks okay great and then",
    "start": "3782750",
    "end": "3792320"
  },
  {
    "text": "another question was went back to the very first portion of the pipeline when",
    "start": "3792320",
    "end": "3798410"
  },
  {
    "text": "the CNN was used the question was where features are extracted from that is it",
    "start": "3798410",
    "end": "3803570"
  },
  {
    "text": "just a pixel data is it just pixel pixel data so so okay so that's something yeah",
    "start": "3803570",
    "end": "3816380"
  },
  {
    "text": "that's very good point I mean you're talking if she months ago in my car I",
    "start": "3816380",
    "end": "3822200"
  },
  {
    "text": "would also people we're struggling wizard some features and I can really understand why it's it's a it's",
    "start": "3822200",
    "end": "3831770"
  },
  {
    "text": "confusing so features what they are effectively what they are it's a it's a",
    "start": "3831770",
    "end": "3840490"
  },
  {
    "text": "values float values and they are in a",
    "start": "3840490",
    "end": "3846110"
  },
  {
    "text": "it's like a 10 so really if what they are they're it's a tensor with a",
    "start": "3846110",
    "end": "3851870"
  },
  {
    "text": "different depth that as float values and this rod values they are used they're",
    "start": "3851870",
    "end": "3857870"
  },
  {
    "text": "not humanly understandable but they used a signal by your network in order to do",
    "start": "3857870",
    "end": "3863810"
  },
  {
    "text": "prediction so you can have you can see them as activations so it's some signal that",
    "start": "3863810",
    "end": "3870150"
  },
  {
    "text": "activated some part of the network resulted on some higher values in some parts of the of the future Maps if you",
    "start": "3870150",
    "end": "3878580"
  },
  {
    "text": "look at the features at the very beginning of a CNN you will notice that you learn kind of low-level features",
    "start": "3878580",
    "end": "3886380"
  },
  {
    "text": "that are easily explainable for example you would see edge detection right so",
    "start": "3886380",
    "end": "3892950"
  },
  {
    "text": "edge detection sharpening filters unit work automatically learns these specific",
    "start": "3892950",
    "end": "3898860"
  },
  {
    "text": "filters that result in inversion of your image which is humanly understandable",
    "start": "3898860",
    "end": "3905820"
  },
  {
    "text": "but the lower you go the in the network the more filters you apply that combines",
    "start": "3905820",
    "end": "3912150"
  },
  {
    "text": "information across filters which across feature maps and typically less unless",
    "start": "3912150",
    "end": "3920520"
  },
  {
    "text": "you can actually understand what is as a human what is in the future maps if you",
    "start": "3920520",
    "end": "3925830"
  },
  {
    "text": "try to look at the values but your network learns what kind of combination what kind of correlation of activation",
    "start": "3925830",
    "end": "3932960"
  },
  {
    "text": "create specific signal that would make it more likely for example to predict",
    "start": "3932960",
    "end": "3939240"
  },
  {
    "text": "age rather than Jake some straight lines",
    "start": "3939240",
    "end": "3949109"
  },
  {
    "text": "and curvy bits and like horizontal lines yeah like like you can see that it's",
    "start": "3949109",
    "end": "3955290"
  },
  {
    "text": "figuring out how to piece all of those things together all of the little pieces that help you to recognize each character yeah so exactly I mean that's",
    "start": "3955290",
    "end": "3963869"
  },
  {
    "text": "the Simon's right that's the intuition that's how you can think about it exactly that and effectively these are",
    "start": "3963869",
    "end": "3974030"
  },
  {
    "text": "tensors that's are the result of your computer's node graph right and then no",
    "start": "3974030",
    "end": "3980250"
  },
  {
    "text": "longer pixels that make sense oh yeah I",
    "start": "3980250",
    "end": "3987330"
  },
  {
    "text": "did so thank you very much for that",
    "start": "3987330",
    "end": "3991609"
  },
  {
    "text": "any other questions I don't know there are no other questions so I think you've",
    "start": "3993630",
    "end": "4000120"
  },
  {
    "text": "already touched on how they can get in touch with you we've of course going to",
    "start": "4000120",
    "end": "4005940"
  },
  {
    "text": "distribute this webinar recording in a follow-up email so sue if you want to close it out for us",
    "start": "4005940",
    "end": "4011820"
  },
  {
    "text": "yeah thanks Chris and thanks Thomas this has been great it's fascinating topic and obviously lots of interest in this",
    "start": "4011820",
    "end": "4018390"
  },
  {
    "text": "topic we had a great number of people register who I'm sure will listen to the",
    "start": "4018390",
    "end": "4023520"
  },
  {
    "text": "replay if they weren't able to be on live today so in about six hours those of you who are still on are gonna get a",
    "start": "4023520",
    "end": "4029300"
  },
  {
    "text": "email it will contain a link to the replay so if you want to kind of you know go through here and look through",
    "start": "4029300",
    "end": "4035220"
  },
  {
    "text": "any of this content and kind of reabsorb some of it the other thing in that email",
    "start": "4035220",
    "end": "4040230"
  },
  {
    "text": "will be a link to register for the next webcast which is in three weeks it's October 4th and so please register for",
    "start": "4040230",
    "end": "4047490"
  },
  {
    "text": "the next webcast and thanks for coming today appreciate your attendance and hope to see you on another webcast in",
    "start": "4047490",
    "end": "4054210"
  },
  {
    "text": "the future thanks everyone",
    "start": "4054210",
    "end": "4058130"
  }
]
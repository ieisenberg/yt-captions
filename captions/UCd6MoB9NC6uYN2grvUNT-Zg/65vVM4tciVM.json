[
  {
    "text": "hi everyone this is kaval jit KMI",
    "start": "4560",
    "end": "6040"
  },
  {
    "text": "working as principal AML special",
    "start": "6040",
    "end": "7759"
  },
  {
    "text": "solution architect in this session we",
    "start": "7759",
    "end": "9639"
  },
  {
    "text": "will learn how you can pre-train from",
    "start": "9639",
    "end": "11400"
  },
  {
    "text": "scratch Mixel 8 into 7B model in a",
    "start": "11400",
    "end": "14280"
  },
  {
    "text": "highly scalable and cost effective",
    "start": "14280",
    "end": "15799"
  },
  {
    "text": "environment using sagemaker distributed",
    "start": "15799",
    "end": "17359"
  },
  {
    "text": "training libraries so let us get",
    "start": "17359",
    "end": "19720"
  },
  {
    "text": "started so our use case includes",
    "start": "19720",
    "end": "22080"
  },
  {
    "text": "training mixt 8 to 7B model we actually",
    "start": "22080",
    "end": "24720"
  },
  {
    "text": "pre-training this model and there could",
    "start": "24720",
    "end": "26000"
  },
  {
    "text": "be several reason you would like to",
    "start": "26000",
    "end": "27199"
  },
  {
    "text": "pre-train a model uh maybe your use case",
    "start": "27199",
    "end": "29599"
  },
  {
    "text": "incl udes uh a data set and a problem",
    "start": "29599",
    "end": "31599"
  },
  {
    "text": "domain which is not well represented in",
    "start": "31599",
    "end": "33399"
  },
  {
    "text": "the existing train models or uh maybe",
    "start": "33399",
    "end": "36040"
  },
  {
    "text": "your requirements are from industry like",
    "start": "36040",
    "end": "38320"
  },
  {
    "text": "medical or Finance where you want to",
    "start": "38320",
    "end": "40399"
  },
  {
    "text": "keep your model secure and protected now",
    "start": "40399",
    "end": "43320"
  },
  {
    "text": "mixture model is a type type of",
    "start": "43320",
    "end": "44840"
  },
  {
    "text": "Transformer model uh which uh Al also",
    "start": "44840",
    "end": "46960"
  },
  {
    "text": "called mixture of experts they have",
    "start": "46960",
    "end": "48360"
  },
  {
    "text": "multiple experts uh where these experts",
    "start": "48360",
    "end": "51199"
  },
  {
    "text": "are basically are neural networks and um",
    "start": "51199",
    "end": "53800"
  },
  {
    "text": "when you train these experts there is a",
    "start": "53800",
    "end": "56600"
  },
  {
    "text": "gate Network also called a router in",
    "start": "56600",
    "end": "58079"
  },
  {
    "text": "front of that and those Networks are",
    "start": "58079",
    "end": "60480"
  },
  {
    "text": "trained to map the incoming tokens to",
    "start": "60480",
    "end": "62760"
  },
  {
    "text": "one of these experts which make this",
    "start": "62760",
    "end": "64119"
  },
  {
    "text": "entire architecture very efficient in",
    "start": "64119",
    "end": "66320"
  },
  {
    "text": "terms of latency and",
    "start": "66320",
    "end": "67920"
  },
  {
    "text": "performance and uh we want to start our",
    "start": "67920",
    "end": "70560"
  },
  {
    "text": "training uh and experimentation with the",
    "start": "70560",
    "end": "72520"
  },
  {
    "text": "16 a100 uh gpus but we want a framework",
    "start": "72520",
    "end": "75479"
  },
  {
    "text": "which could help us extend to thousand",
    "start": "75479",
    "end": "76840"
  },
  {
    "text": "of gpus later and we will leverage",
    "start": "76840",
    "end": "79799"
  },
  {
    "text": "pytorch fstp scripts but we are pretty",
    "start": "79799",
    "end": "81799"
  },
  {
    "text": "open to see if these libraries could be",
    "start": "81799",
    "end": "83799"
  },
  {
    "text": "extended to accelerate our training",
    "start": "83799",
    "end": "86200"
  },
  {
    "text": "further and what we need from the",
    "start": "86200",
    "end": "88000"
  },
  {
    "text": "solution uh this solution should provide",
    "start": "88000",
    "end": "90000"
  },
  {
    "text": "us with a managed experience where uh we",
    "start": "90000",
    "end": "92880"
  },
  {
    "text": "uh it should be able to abstract away",
    "start": "92880",
    "end": "94200"
  },
  {
    "text": "the infrastructure complexity and uh we",
    "start": "94200",
    "end": "95960"
  },
  {
    "text": "should get more time to focus on our",
    "start": "95960",
    "end": "97640"
  },
  {
    "text": "code uh we want flexibility in the",
    "start": "97640",
    "end": "99520"
  },
  {
    "text": "choice of compute uh probably today uh",
    "start": "99520",
    "end": "101840"
  },
  {
    "text": "in this demo we'll be experimenting with",
    "start": "101840",
    "end": "103520"
  },
  {
    "text": "a100 but the same demo should be able to",
    "start": "103520",
    "end": "106799"
  },
  {
    "text": "replicate uh the results on h100s as",
    "start": "106799",
    "end": "109320"
  },
  {
    "text": "well and we also need flexibility in the",
    "start": "109320",
    "end": "111719"
  },
  {
    "text": "choice of Frameworks and libraries and",
    "start": "111719",
    "end": "114799"
  },
  {
    "text": "uh last we want a high performance",
    "start": "114799",
    "end": "116640"
  },
  {
    "text": "system uh which could accelerate our",
    "start": "116640",
    "end": "117960"
  },
  {
    "text": "training and could provide us with the",
    "start": "117960",
    "end": "121840"
  },
  {
    "text": "performance so let us let us see a",
    "start": "121840",
    "end": "124000"
  },
  {
    "text": "solution which could address these",
    "start": "124000",
    "end": "125240"
  },
  {
    "text": "requirements now as a machine learning",
    "start": "125240",
    "end": "127360"
  },
  {
    "text": "engineer or Builder I will make API",
    "start": "127360",
    "end": "130200"
  },
  {
    "text": "calls to sagemaker control plane and",
    "start": "130200",
    "end": "132400"
  },
  {
    "text": "sagemaker will help provision a cluster",
    "start": "132400",
    "end": "134640"
  },
  {
    "text": "with end nodes and then we'll use",
    "start": "134640",
    "end": "137040"
  },
  {
    "text": "sagemaker model parallel library and its",
    "start": "137040",
    "end": "139560"
  },
  {
    "text": "expert parallelism implementation to",
    "start": "139560",
    "end": "141800"
  },
  {
    "text": "split the experts across multiple gpus",
    "start": "141800",
    "end": "145120"
  },
  {
    "text": "now along with expert parallelism",
    "start": "145120",
    "end": "146760"
  },
  {
    "text": "implementation sagemaker model parallel",
    "start": "146760",
    "end": "149000"
  },
  {
    "text": "Library also provides a lot of different",
    "start": "149000",
    "end": "151239"
  },
  {
    "text": "Advanced uh distribution strategies and",
    "start": "151239",
    "end": "153080"
  },
  {
    "text": "memory saving techniques like uh mix",
    "start": "153080",
    "end": "155319"
  },
  {
    "text": "Precision with fp8 uh which take",
    "start": "155319",
    "end": "157160"
  },
  {
    "text": "advantage of P5 support of uh low",
    "start": "157160",
    "end": "160560"
  },
  {
    "text": "Precision uh data types um like fp8 to",
    "start": "160560",
    "end": "163280"
  },
  {
    "text": "accelerate the training uh other",
    "start": "163280",
    "end": "165080"
  },
  {
    "text": "strategies could include hybrid shy data",
    "start": "165080",
    "end": "167319"
  },
  {
    "text": "parallel uh which shorts your model par",
    "start": "167319",
    "end": "170319"
  },
  {
    "text": "parameters gradients and Optimizer",
    "start": "170319",
    "end": "172159"
  },
  {
    "text": "States across our gpus um there are",
    "start": "172159",
    "end": "174599"
  },
  {
    "text": "other strategies like tensor parallelism",
    "start": "174599",
    "end": "176560"
  },
  {
    "text": "activation checkpointing delayed",
    "start": "176560",
    "end": "178280"
  },
  {
    "text": "parameter initialization and many many",
    "start": "178280",
    "end": "179840"
  },
  {
    "text": "any more so along with providing support",
    "start": "179840",
    "end": "181920"
  },
  {
    "text": "for all of these Advanced distribution",
    "start": "181920",
    "end": "183599"
  },
  {
    "text": "strategies uh these libraries are",
    "start": "183599",
    "end": "185560"
  },
  {
    "text": "optimized for AWS Network infrastructure",
    "start": "185560",
    "end": "187920"
  },
  {
    "text": "and compute instances which can bring",
    "start": "187920",
    "end": "189760"
  },
  {
    "text": "down your training time and cost by",
    "start": "189760",
    "end": "191280"
  },
  {
    "text": "almost 20% and these libraries are",
    "start": "191280",
    "end": "193599"
  },
  {
    "text": "compatible with borch API so it becomes",
    "start": "193599",
    "end": "196120"
  },
  {
    "text": "very very convenient for you to adapt",
    "start": "196120",
    "end": "197920"
  },
  {
    "text": "your existing pytorch fsdp scripts to",
    "start": "197920",
    "end": "200480"
  },
  {
    "text": "take advantage of all the performance",
    "start": "200480",
    "end": "201920"
  },
  {
    "text": "improvements that sagemaker model parel",
    "start": "201920",
    "end": "204080"
  },
  {
    "text": "library has to offer now one thing to",
    "start": "204080",
    "end": "206400"
  },
  {
    "text": "note here is that when you scale up your",
    "start": "206400",
    "end": "208439"
  },
  {
    "text": "cluster so does the communication",
    "start": "208439",
    "end": "210360"
  },
  {
    "text": "overheads right they they go up as well",
    "start": "210360",
    "end": "212640"
  },
  {
    "text": "which kind of brings down your overall",
    "start": "212640",
    "end": "214560"
  },
  {
    "text": "computational performance now this is",
    "start": "214560",
    "end": "216400"
  },
  {
    "text": "where sagemaker data parallel Library",
    "start": "216400",
    "end": "218319"
  },
  {
    "text": "kind of helps in Saker data pel provides",
    "start": "218319",
    "end": "220840"
  },
  {
    "text": "a optimized implementation of all gather",
    "start": "220840",
    "end": "223680"
  },
  {
    "text": "Collective communication Library which",
    "start": "223680",
    "end": "225760"
  },
  {
    "text": "enhances and improves the communication",
    "start": "225760",
    "end": "227840"
  },
  {
    "text": "between nodes which accelerates your",
    "start": "227840",
    "end": "229720"
  },
  {
    "text": "training even",
    "start": "229720",
    "end": "231040"
  },
  {
    "text": "further so let us see all of this uh in",
    "start": "231040",
    "end": "234120"
  },
  {
    "text": "action through a demo so we'll use",
    "start": "234120",
    "end": "235720"
  },
  {
    "text": "stagemaker studio uh to spin up our",
    "start": "235720",
    "end": "237519"
  },
  {
    "text": "Jupiter lab application right so I have",
    "start": "237519",
    "end": "239879"
  },
  {
    "text": "G lab space here um and once the uh G",
    "start": "239879",
    "end": "243560"
  },
  {
    "text": "lab is up we will run this specific",
    "start": "243560",
    "end": "246280"
  },
  {
    "text": "notebook now before we get into the code",
    "start": "246280",
    "end": "249040"
  },
  {
    "text": "uh few things that I want to",
    "start": "249040",
    "end": "251239"
  },
  {
    "text": "highlight that there are two easy steps",
    "start": "251239",
    "end": "253480"
  },
  {
    "text": "to adapt your py fstp script uh to",
    "start": "253480",
    "end": "256120"
  },
  {
    "text": "sagemaker model P Library step one is",
    "start": "256120",
    "end": "258880"
  },
  {
    "text": "that we need to initialize sagemaker",
    "start": "258880",
    "end": "260320"
  },
  {
    "text": "model P Library by using this t.",
    "start": "260320",
    "end": "263120"
  },
  {
    "text": "sagemaker init function and second step",
    "start": "263120",
    "end": "265680"
  },
  {
    "text": "is that we will wrap this model that we",
    "start": "265680",
    "end": "268400"
  },
  {
    "text": "will get from hugging phase um apis",
    "start": "268400",
    "end": "271400"
  },
  {
    "text": "along with thee config which will",
    "start": "271400",
    "end": "273360"
  },
  {
    "text": "actually activate mixture of experts and",
    "start": "273360",
    "end": "275919"
  },
  {
    "text": "we will wrap this model and that Moe",
    "start": "275919",
    "end": "278560"
  },
  {
    "text": "config uh with the transform API which",
    "start": "278560",
    "end": "281440"
  },
  {
    "text": "basically will convert hugging phase",
    "start": "281440",
    "end": "283360"
  },
  {
    "text": "model into sagemaker model parallel",
    "start": "283360",
    "end": "285479"
  },
  {
    "text": "export implementation which is based on",
    "start": "285479",
    "end": "287600"
  },
  {
    "text": "Megatron",
    "start": "287600",
    "end": "288880"
  },
  {
    "text": "llm and the second step is when you when",
    "start": "288880",
    "end": "291880"
  },
  {
    "text": "you spin up a training cluster using pyo",
    "start": "291880",
    "end": "293800"
  },
  {
    "text": "estimator as we're going to see in just",
    "start": "293800",
    "end": "295560"
  },
  {
    "text": "few minutes you just have to pass uh",
    "start": "295560",
    "end": "297479"
  },
  {
    "text": "this particular configuration uh EXP",
    "start": "297479",
    "end": "300120"
  },
  {
    "text": "parallel degree uh which kind of",
    "start": "300120",
    "end": "301759"
  },
  {
    "text": "specifies how many gpus you want to",
    "start": "301759",
    "end": "304280"
  },
  {
    "text": "split your experts",
    "start": "304280",
    "end": "307440"
  },
  {
    "text": "across so we get started so we import uh",
    "start": "307440",
    "end": "309960"
  },
  {
    "text": "the libraries required U to run our",
    "start": "309960",
    "end": "312400"
  },
  {
    "text": "notebook uh we will continue to use",
    "start": "312400",
    "end": "313840"
  },
  {
    "text": "Saker python SDK as we have done in the",
    "start": "313840",
    "end": "315720"
  },
  {
    "text": "previous videos and we will use",
    "start": "315720",
    "end": "317320"
  },
  {
    "text": "sagemaker session uh to interact with",
    "start": "317320",
    "end": "319759"
  },
  {
    "text": "sagemaker",
    "start": "319759",
    "end": "321240"
  },
  {
    "text": "apis uh in this example we will use a",
    "start": "321240",
    "end": "323840"
  },
  {
    "text": "very small data set glue sst2 which is a",
    "start": "323840",
    "end": "326720"
  },
  {
    "text": "movie review sentiment data set um you",
    "start": "326720",
    "end": "329240"
  },
  {
    "text": "know in the previous videos we have kind",
    "start": "329240",
    "end": "330720"
  },
  {
    "text": "of gone very deep into how you can",
    "start": "330720",
    "end": "332600"
  },
  {
    "text": "process the data site in this video we",
    "start": "332600",
    "end": "334240"
  },
  {
    "text": "will just uh say at a very high level so",
    "start": "334240",
    "end": "336919"
  },
  {
    "text": "basically U we are using hugging phase",
    "start": "336919",
    "end": "339400"
  },
  {
    "text": "uh low data set API to create the",
    "start": "339400",
    "end": "342039"
  },
  {
    "text": "validation and uh train SL split and",
    "start": "342039",
    "end": "345440"
  },
  {
    "text": "then we will tokenize this data uh by",
    "start": "345440",
    "end": "347840"
  },
  {
    "text": "loading the tokenizer from hugging phase",
    "start": "347840",
    "end": "350720"
  },
  {
    "text": "um apis and then once the text is",
    "start": "350720",
    "end": "354440"
  },
  {
    "text": "converted into token format we will",
    "start": "354440",
    "end": "356560"
  },
  {
    "text": "group those tokens into a specific",
    "start": "356560",
    "end": "358120"
  },
  {
    "text": "sequence length here for for purposes of",
    "start": "358120",
    "end": "360319"
  },
  {
    "text": "this demo we have we are converting that",
    "start": "360319",
    "end": "362479"
  },
  {
    "text": "into 248 U seqence",
    "start": "362479",
    "end": "365599"
  },
  {
    "text": "length right as we have specified",
    "start": "365599",
    "end": "369280"
  },
  {
    "text": "here right and then um there are other",
    "start": "369280",
    "end": "372520"
  },
  {
    "text": "basic steps here where we will uh",
    "start": "372520",
    "end": "374560"
  },
  {
    "text": "configure um S3 as the data source to",
    "start": "374560",
    "end": "376960"
  },
  {
    "text": "our training cluster we will upload our",
    "start": "376960",
    "end": "378319"
  },
  {
    "text": "data to S3 and then we'll feed that data",
    "start": "378319",
    "end": "380639"
  },
  {
    "text": "into our training",
    "start": "380639",
    "end": "383080"
  },
  {
    "text": "environment uh this is where uh we will",
    "start": "383080",
    "end": "385360"
  },
  {
    "text": "set the configuration of s maker model",
    "start": "385360",
    "end": "387840"
  },
  {
    "text": "parallel right um here we have defined",
    "start": "387840",
    "end": "390280"
  },
  {
    "text": "say hybrid Shadow hybrid Shadow degree",
    "start": "390280",
    "end": "392919"
  },
  {
    "text": "um which is set to eight so if you're",
    "start": "392919",
    "end": "395160"
  },
  {
    "text": "using two p4d instances each Having",
    "start": "395160",
    "end": "397280"
  },
  {
    "text": "Eight gpus that means each of these",
    "start": "397280",
    "end": "399440"
  },
  {
    "text": "instances which H will have its own copy",
    "start": "399440",
    "end": "401360"
  },
  {
    "text": "of the model split across eight gpus and",
    "start": "401360",
    "end": "404440"
  },
  {
    "text": "then we have specified expert parallel",
    "start": "404440",
    "end": "406360"
  },
  {
    "text": "degree set two which means you further",
    "start": "406360",
    "end": "408479"
  },
  {
    "text": "split your experts across two gpus and",
    "start": "408479",
    "end": "411280"
  },
  {
    "text": "along with that there are other uh um",
    "start": "411280",
    "end": "413759"
  },
  {
    "text": "hyper parameters that you want to set",
    "start": "413759",
    "end": "415599"
  },
  {
    "text": "like whether you want to activate",
    "start": "415599",
    "end": "416800"
  },
  {
    "text": "activation checkpointing whether you",
    "start": "416800",
    "end": "419720"
  },
  {
    "text": "want to have a specific backward uh pre",
    "start": "419720",
    "end": "421960"
  },
  {
    "text": "fetch policy set the kind of uh sharing",
    "start": "421960",
    "end": "424960"
  },
  {
    "text": "strategy that you want to use in this",
    "start": "424960",
    "end": "426360"
  },
  {
    "text": "case we're using hybrid uh sharding",
    "start": "426360",
    "end": "428240"
  },
  {
    "text": "strategy And Then There are a mixture of",
    "start": "428240",
    "end": "431319"
  },
  {
    "text": "export uh conf specific configurations",
    "start": "431319",
    "end": "433440"
  },
  {
    "text": "as well where you can specify a load",
    "start": "433440",
    "end": "435879"
  },
  {
    "text": "balancer so in this case we are",
    "start": "435879",
    "end": "437960"
  },
  {
    "text": "specifying synon which is our default",
    "start": "437960",
    "end": "440160"
  },
  {
    "text": "option but there are other options as",
    "start": "440160",
    "end": "441919"
  },
  {
    "text": "well like ox loss or balanced and we're",
    "start": "441919",
    "end": "445199"
  },
  {
    "text": "using all to all uh communication which",
    "start": "445199",
    "end": "447240"
  },
  {
    "text": "is a effective communication when you'll",
    "start": "447240",
    "end": "449160"
  },
  {
    "text": "be training models which is optimized",
    "start": "449160",
    "end": "451560"
  },
  {
    "text": "for a",
    "start": "451560",
    "end": "453479"
  },
  {
    "text": "infrastructure so here we will be",
    "start": "453479",
    "end": "455599"
  },
  {
    "text": "creating uh two uh configurations for",
    "start": "455599",
    "end": "458000"
  },
  {
    "text": "mixt uh which we want to pre-train from",
    "start": "458000",
    "end": "460120"
  },
  {
    "text": "scratch um we have a small and large one",
    "start": "460120",
    "end": "462919"
  },
  {
    "text": "so when we will be experimenting you can",
    "start": "462919",
    "end": "464759"
  },
  {
    "text": "start with small but uh later on once",
    "start": "464759",
    "end": "466599"
  },
  {
    "text": "you want to run it at production scale",
    "start": "466599",
    "end": "468319"
  },
  {
    "text": "that's when you can leverage the large",
    "start": "468319",
    "end": "470159"
  },
  {
    "text": "configuration so here we have specified",
    "start": "470159",
    "end": "472759"
  },
  {
    "text": "uh the number of heads um which is part",
    "start": "472759",
    "end": "474840"
  },
  {
    "text": "of the multi-ad detention layer um these",
    "start": "474840",
    "end": "477319"
  },
  {
    "text": "are the number of layers that are",
    "start": "477319",
    "end": "478720"
  },
  {
    "text": "Transformer model will have and every",
    "start": "478720",
    "end": "480800"
  },
  {
    "text": "layer will have four",
    "start": "480800",
    "end": "484159"
  },
  {
    "text": "experts and then we will be training our",
    "start": "484159",
    "end": "486919"
  },
  {
    "text": "model on 2 p4d 24x large instance uh",
    "start": "486919",
    "end": "489720"
  },
  {
    "text": "each instance comes with 8 a100",
    "start": "489720",
    "end": "493879"
  },
  {
    "text": "gpus and then we will leverage pytorch",
    "start": "493879",
    "end": "496560"
  },
  {
    "text": "estimators as you have seen in previous",
    "start": "496560",
    "end": "498599"
  },
  {
    "text": "uh videos as well uh this is the uh API",
    "start": "498599",
    "end": "501360"
  },
  {
    "text": "which lets you spin up a training",
    "start": "501360",
    "end": "502479"
  },
  {
    "text": "cluster in this case we'll be spinning",
    "start": "502479",
    "end": "503879"
  },
  {
    "text": "up a cluster with two p4d instances and",
    "start": "503879",
    "end": "507520"
  },
  {
    "text": "the key parameters that I want to",
    "start": "507520",
    "end": "508919"
  },
  {
    "text": "highlight here is the distribution",
    "start": "508919",
    "end": "510680"
  },
  {
    "text": "parameter here uh we are setting tor.",
    "start": "510680",
    "end": "513680"
  },
  {
    "text": "distributed uh enabled to True uh this",
    "start": "513680",
    "end": "517039"
  },
  {
    "text": "will allow shmaker apis to use torch run",
    "start": "517039",
    "end": "520039"
  },
  {
    "text": "utility to spin up the py distributed",
    "start": "520039",
    "end": "522399"
  },
  {
    "text": "environment right so using that",
    "start": "522399",
    "end": "524159"
  },
  {
    "text": "environment um you can use uh the",
    "start": "524160",
    "end": "526320"
  },
  {
    "text": "environment variables like World size",
    "start": "526320",
    "end": "528200"
  },
  {
    "text": "rank to configure your training",
    "start": "528200",
    "end": "530600"
  },
  {
    "text": "script and then we are also using stemer",
    "start": "530600",
    "end": "533720"
  },
  {
    "text": "distributed a variable here we are",
    "start": "533720",
    "end": "536040"
  },
  {
    "text": "saying that we want to enable model",
    "start": "536040",
    "end": "537839"
  },
  {
    "text": "parallel library and um and these are",
    "start": "537839",
    "end": "540680"
  },
  {
    "text": "the configuration parameters that we",
    "start": "540680",
    "end": "542360"
  },
  {
    "text": "want to send to initialize our model P",
    "start": "542360",
    "end": "544959"
  },
  {
    "text": "Library uh this includes activation",
    "start": "544959",
    "end": "547120"
  },
  {
    "text": "loading Horizon which kind of defines",
    "start": "547120",
    "end": "549519"
  },
  {
    "text": "how soon you want to uh Bring Back Your",
    "start": "549519",
    "end": "552120"
  },
  {
    "text": "activations from CPU back to gpus uh",
    "start": "552120",
    "end": "555040"
  },
  {
    "text": "hybrid shed degree and expert parallel",
    "start": "555040",
    "end": "556800"
  },
  {
    "text": "degree as we have seen and the",
    "start": "556800",
    "end": "558600"
  },
  {
    "text": "activation offloading which is again one",
    "start": "558600",
    "end": "560200"
  },
  {
    "text": "of the memory saving techniques where",
    "start": "560200",
    "end": "562040"
  },
  {
    "text": "after you go through the forward pass",
    "start": "562040",
    "end": "564040"
  },
  {
    "text": "you actually offload your activation to",
    "start": "564040",
    "end": "565680"
  },
  {
    "text": "CPU and during the backward pass you",
    "start": "565680",
    "end": "568000"
  },
  {
    "text": "kind of bring that back up to GPU memory",
    "start": "568000",
    "end": "570240"
  },
  {
    "text": "and the loading Horizon kind of defines",
    "start": "570240",
    "end": "572160"
  },
  {
    "text": "how soon you want to do",
    "start": "572160",
    "end": "574040"
  },
  {
    "text": "that right so with that uh this is the",
    "start": "574040",
    "end": "577240"
  },
  {
    "text": "uh custom Training script uh that we",
    "start": "577240",
    "end": "579120"
  },
  {
    "text": "have specified as an entry point so",
    "start": "579120",
    "end": "580760"
  },
  {
    "text": "though we are using uh sagemaker managed",
    "start": "580760",
    "end": "583760"
  },
  {
    "text": "uh pytorch containers so if you go back",
    "start": "583760",
    "end": "586440"
  },
  {
    "text": "uh and look into this training script a",
    "start": "586440",
    "end": "588360"
  },
  {
    "text": "few things uh that uh we will see is",
    "start": "588360",
    "end": "593519"
  },
  {
    "text": "first thing down below in this notebook",
    "start": "593519",
    "end": "599720"
  },
  {
    "text": "we have uh initialized uh sbaker model",
    "start": "599720",
    "end": "603160"
  },
  {
    "text": "parallel library right this initializes",
    "start": "603160",
    "end": "604760"
  },
  {
    "text": "it in the Pyro TR script and all those",
    "start": "604760",
    "end": "606680"
  },
  {
    "text": "parameters that we have sent as part of",
    "start": "606680",
    "end": "608320"
  },
  {
    "text": "the estimator uh it will consider uh",
    "start": "608320",
    "end": "610800"
  },
  {
    "text": "those parameters while it initializes",
    "start": "610800",
    "end": "612440"
  },
  {
    "text": "itself so once the model parall Library",
    "start": "612440",
    "end": "615399"
  },
  {
    "text": "uh is initialized the next step is that",
    "start": "615399",
    "end": "618000"
  },
  {
    "text": "we create a model so we have passed the",
    "start": "618000",
    "end": "620160"
  },
  {
    "text": "mixtur configuration and that",
    "start": "620160",
    "end": "621880"
  },
  {
    "text": "configuration will be pulled in from the",
    "start": "621880",
    "end": "624120"
  },
  {
    "text": "hugging phase repository and um using",
    "start": "624120",
    "end": "627079"
  },
  {
    "text": "that we will create this model and then",
    "start": "627079",
    "end": "629560"
  },
  {
    "text": "there is thee config uh created right",
    "start": "629560",
    "end": "632920"
  },
  {
    "text": "here um which has the parameters like",
    "start": "632920",
    "end": "635600"
  },
  {
    "text": "whether you want to use H model parallel",
    "start": "635600",
    "end": "637399"
  },
  {
    "text": "for this config um the random C",
    "start": "637399",
    "end": "639720"
  },
  {
    "text": "generator that we want to use and the",
    "start": "639720",
    "end": "641560"
  },
  {
    "text": "load balancing uh parameter that we have",
    "start": "641560",
    "end": "643600"
  },
  {
    "text": "passed uh through the hyper parameter",
    "start": "643600",
    "end": "645880"
  },
  {
    "text": "now the model and this config will",
    "start": "645880",
    "end": "647680"
  },
  {
    "text": "finally be wrapped into the transform",
    "start": "647680",
    "end": "649839"
  },
  {
    "text": "API right now this is the API which",
    "start": "649839",
    "end": "652440"
  },
  {
    "text": "basically converts the hugging phase",
    "start": "652440",
    "end": "654160"
  },
  {
    "text": "model into the sbaker model parallelism",
    "start": "654160",
    "end": "656880"
  },
  {
    "text": "implementation which again is based on",
    "start": "656880",
    "end": "659440"
  },
  {
    "text": "Megatron as we have talked about",
    "start": "659440",
    "end": "662519"
  },
  {
    "text": "previously right so once you have done",
    "start": "662519",
    "end": "664720"
  },
  {
    "text": "this after this you can fall back to",
    "start": "664720",
    "end": "666920"
  },
  {
    "text": "your existing pytorch fstp uh code uh so",
    "start": "666920",
    "end": "670120"
  },
  {
    "text": "the model that we have created uh will",
    "start": "670120",
    "end": "672000"
  },
  {
    "text": "then be wrapped in the fstp along with",
    "start": "672000",
    "end": "675480"
  },
  {
    "text": "the other parameters that will Define",
    "start": "675480",
    "end": "677399"
  },
  {
    "text": "the behavior of your pyo distributed",
    "start": "677399",
    "end": "680440"
  },
  {
    "text": "training um here we are passing the you",
    "start": "680440",
    "end": "682680"
  },
  {
    "text": "know kind of R wrapping policy U mixed",
    "start": "682680",
    "end": "685279"
  },
  {
    "text": "Precision sharting strategy and others",
    "start": "685279",
    "end": "688240"
  },
  {
    "text": "and finally uh we will uh call our",
    "start": "688240",
    "end": "690800"
  },
  {
    "text": "training function right from here um",
    "start": "690800",
    "end": "693880"
  },
  {
    "text": "passing the model Optimizer uh that we",
    "start": "693880",
    "end": "696600"
  },
  {
    "text": "have initialized so I'll scroll back up",
    "start": "696600",
    "end": "700519"
  },
  {
    "text": "all the way up to the top of the",
    "start": "700519",
    "end": "702880"
  },
  {
    "text": "script right to look at our training run",
    "start": "702880",
    "end": "706720"
  },
  {
    "text": "which basically will call the training",
    "start": "706720",
    "end": "709639"
  },
  {
    "text": "step and then um we are feeding the",
    "start": "709639",
    "end": "712560"
  },
  {
    "text": "input ID tokens to the model uh we'll",
    "start": "712560",
    "end": "715920"
  },
  {
    "text": "get the loss and we run the backw pass",
    "start": "715920",
    "end": "718760"
  },
  {
    "text": "uh to Compu compute the gradients and",
    "start": "718760",
    "end": "720600"
  },
  {
    "text": "finally we use the optimizer do step to",
    "start": "720600",
    "end": "722639"
  },
  {
    "text": "update the",
    "start": "722639",
    "end": "724959"
  },
  {
    "text": "parameters so um Coming Back To The",
    "start": "724959",
    "end": "727240"
  },
  {
    "text": "Notebook so once we have defined the",
    "start": "727240",
    "end": "729480"
  },
  {
    "text": "estimator then we can call the fit",
    "start": "729480",
    "end": "731720"
  },
  {
    "text": "function and we pass the input data",
    "start": "731720",
    "end": "733519"
  },
  {
    "text": "channel here which is basically pulling",
    "start": "733519",
    "end": "735120"
  },
  {
    "text": "in the data from S3 so this is a run uh",
    "start": "735120",
    "end": "738480"
  },
  {
    "text": "on a very small data set um and then",
    "start": "738480",
    "end": "740720"
  },
  {
    "text": "there are libraries which you can use to",
    "start": "740720",
    "end": "743480"
  },
  {
    "text": "um check your GPU memory utilization",
    "start": "743480",
    "end": "746760"
  },
  {
    "text": "your CPU memory utilization and you can",
    "start": "746760",
    "end": "749399"
  },
  {
    "text": "tune your hyperparameters accordingly",
    "start": "749399",
    "end": "751720"
  },
  {
    "text": "and can experiment with it and finally",
    "start": "751720",
    "end": "753760"
  },
  {
    "text": "when the training is completed um you",
    "start": "753760",
    "end": "756480"
  },
  {
    "text": "would see that you buildable uh you are",
    "start": "756480",
    "end": "759279"
  },
  {
    "text": "built only to the second U to what the",
    "start": "759279",
    "end": "761800"
  },
  {
    "text": "training run is actually consuming and",
    "start": "761800",
    "end": "763920"
  },
  {
    "text": "after the training is completed your",
    "start": "763920",
    "end": "766160"
  },
  {
    "text": "trading cluster will be terminated by",
    "start": "766160",
    "end": "769879"
  },
  {
    "text": "sbaker so this concludes the demo uh",
    "start": "770639",
    "end": "773040"
  },
  {
    "text": "Amazon stagemaker provides you with a",
    "start": "773040",
    "end": "774600"
  },
  {
    "text": "manage experience it handles the setup",
    "start": "774600",
    "end": "776199"
  },
  {
    "text": "of management of compute cluster uh",
    "start": "776199",
    "end": "778199"
  },
  {
    "text": "which kind of breaks down total cost of",
    "start": "778199",
    "end": "779760"
  },
  {
    "text": "ownership and you get more time to focus",
    "start": "779760",
    "end": "781360"
  },
  {
    "text": "on your code it's very easy as we have",
    "start": "781360",
    "end": "783360"
  },
  {
    "text": "seen in this demo to adapt your existing",
    "start": "783360",
    "end": "785480"
  },
  {
    "text": "pyot script to take advantage of all the",
    "start": "785480",
    "end": "787360"
  },
  {
    "text": "performance improvements that Saker",
    "start": "787360",
    "end": "788839"
  },
  {
    "text": "model parallel has to offer to really",
    "start": "788839",
    "end": "790880"
  },
  {
    "text": "get a high performance uh compute",
    "start": "790880",
    "end": "792720"
  },
  {
    "text": "cluster so these are uh the resources",
    "start": "792720",
    "end": "795399"
  },
  {
    "text": "which you can refer to dive deep into",
    "start": "795399",
    "end": "797760"
  },
  {
    "text": "the example that we have covered today",
    "start": "797760",
    "end": "799519"
  },
  {
    "text": "and the documentation on sagemaker",
    "start": "799519",
    "end": "801760"
  },
  {
    "text": "distributed training libraries uh I hope",
    "start": "801760",
    "end": "804040"
  },
  {
    "text": "uh you have found this session helpful",
    "start": "804040",
    "end": "805440"
  },
  {
    "text": "we'll see you in the next video thank",
    "start": "805440",
    "end": "806839"
  },
  {
    "text": "you",
    "start": "806839",
    "end": "809839"
  }
]
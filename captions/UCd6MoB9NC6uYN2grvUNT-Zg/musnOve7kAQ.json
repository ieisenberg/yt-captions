[
  {
    "start": "0",
    "end": "23000"
  },
  {
    "text": "good afternoon ladies and gentlemen my name is Daniel and today I'm joined by",
    "start": "439",
    "end": "5520"
  },
  {
    "text": "my colleague mark and Tim bark from hello and",
    "start": "5520",
    "end": "10610"
  },
  {
    "text": "AWS IOT company and today we'll be looking at how to",
    "start": "10610",
    "end": "17400"
  },
  {
    "text": "leverage Amazon Kinesis in building an IOT analytics platform on AWS",
    "start": "17400",
    "end": "22580"
  },
  {
    "text": "so what are you going to get out of the session today well together we're going to explore two real use cases of an i/o",
    "start": "22580",
    "end": "30779"
  },
  {
    "start": "23000",
    "end": "23000"
  },
  {
    "text": "technique IOT analytics platform using the Amazon Kinesis family of services",
    "start": "30779",
    "end": "36360"
  },
  {
    "text": "and we'll see a demo of the IOT and Amazon Kinesis services in action and",
    "start": "36360",
    "end": "42090"
  },
  {
    "text": "then take a deep dive into a reference architecture of building an IOT analytics platform on AWS and then we'll",
    "start": "42090",
    "end": "51180"
  },
  {
    "text": "go and do a deep dive on the underlying architecture of the demo and then we'll",
    "start": "51180",
    "end": "57180"
  },
  {
    "text": "hear from Tim bard and he'll take you through hello's specific use case on AWS",
    "start": "57180",
    "end": "63439"
  },
  {
    "text": "and their journey and what they've been doing around their analytics and IOT",
    "start": "63439",
    "end": "69360"
  },
  {
    "text": "platform on AWS so by the end of the session you'll have",
    "start": "69360",
    "end": "74670"
  },
  {
    "text": "an appreciation of the AWS services required to build a service IOT analytics platform and you'll be able to",
    "start": "74670",
    "end": "81210"
  },
  {
    "text": "describe the functionality of Amazon Kinesis streams firehose and analytics",
    "start": "81210",
    "end": "87330"
  },
  {
    "text": "and understand how to acquire process and store IOT sensor data",
    "start": "87330",
    "end": "93079"
  },
  {
    "text": "all right so I'm going to hand it over to mark and he's going to take you through what you're about to see in the",
    "start": "93079",
    "end": "99780"
  },
  {
    "start": "96000",
    "end": "96000"
  },
  {
    "text": "demo thanks Daniel good afternoon ladies and gentlemen",
    "start": "99780",
    "end": "105470"
  },
  {
    "text": "so the example that you're going to see today is actually example that we built",
    "start": "105470",
    "end": "111149"
  },
  {
    "text": "for a boot camp here at reinvent that rebrand yesterday and it consists of a",
    "start": "111149",
    "end": "116189"
  },
  {
    "text": "number of environmental sensors and you can see here we've got some rainfall sensors temperature sensor little earth",
    "start": "116189",
    "end": "122729"
  },
  {
    "text": "with the arrows is a vibration sensor and a wind and wind direction sensor there's a weather station that collects",
    "start": "122729",
    "end": "129390"
  },
  {
    "text": "all this data together aggregates them does a little bit of process on an IOT",
    "start": "129390",
    "end": "134560"
  },
  {
    "text": "device and then forwards that data into the AWS platform for further processing",
    "start": "134560",
    "end": "141810"
  },
  {
    "text": "out of the AWS platform using a range of AWS services such as AWS API gateway",
    "start": "141810",
    "end": "149909"
  },
  {
    "text": "lamda kognito we provide a global weather view one of the demos you're going to see today is the end-to-end",
    "start": "149909",
    "end": "156579"
  },
  {
    "text": "user experience it's delivered by combining all of these services together",
    "start": "156579",
    "end": "162480"
  },
  {
    "text": "so the key services that we use to deliver the capability in the",
    "start": "162480",
    "end": "167650"
  },
  {
    "text": "acquisition phase the collection of data is the AWS IOT service within the AWS",
    "start": "167650",
    "end": "173319"
  },
  {
    "text": "IOT service there's some capabilities and we're using three key capabilities of the AWS IOT service in this",
    "start": "173319",
    "end": "180189"
  },
  {
    "text": "acquisition phase the first capability is the IOT rules the second capability",
    "start": "180189",
    "end": "186159"
  },
  {
    "text": "is the concept of an IOT thing and the third capability is an IOT action you'll",
    "start": "186159",
    "end": "191620"
  },
  {
    "text": "also notice that we're using Amazon SNS within the acquisition phase of the",
    "start": "191620",
    "end": "196930"
  },
  {
    "text": "architecture daniel will talk a little bit more throughout the presentation about how we use SNS as a fan-out",
    "start": "196930",
    "end": "204239"
  },
  {
    "text": "mechanism for IOT data and how that can be beneficial in collecting and sharing",
    "start": "204239",
    "end": "209290"
  },
  {
    "text": "that data across a range of AWS services within the processing component we use",
    "start": "209290",
    "end": "216519"
  },
  {
    "text": "some fantastic AWS services Amazon Aurora and Amazon redshift for data",
    "start": "216519",
    "end": "221949"
  },
  {
    "text": "basing capability Amazon s3 for object storage again Amazon SNS as part of the",
    "start": "221949",
    "end": "227829"
  },
  {
    "text": "fan-out methodologies that we use AWS Lamba our Xero administration service",
    "start": "227829",
    "end": "233500"
  },
  {
    "text": "compute platform and we make use of all three members of the Kinesis product family Kinesis streams Kinesis fire hose",
    "start": "233500",
    "end": "241840"
  },
  {
    "text": "and Kinesis analytics as we head into the UI component that makes",
    "start": "241840",
    "end": "248709"
  },
  {
    "text": "use of all the data that's being collected as I mentioned we use Amazon API gateway we make use of Amazon",
    "start": "248709",
    "end": "255579"
  },
  {
    "text": "ElastiCache again AWS lambda which seamlessly integrated with Amazon API",
    "start": "255579",
    "end": "260680"
  },
  {
    "text": "gateway AWS s3 Cognito for authentication and",
    "start": "260680",
    "end": "266620"
  },
  {
    "text": "authorized and we make use of the JavaScript SDK so when we show the demo",
    "start": "266620",
    "end": "271870"
  },
  {
    "text": "to you have some idea about all the services that are being used to drive this demo so",
    "start": "271870",
    "end": "278730"
  },
  {
    "text": "when we lay out all these services end-to-end across this high-level",
    "start": "278730",
    "end": "283830"
  },
  {
    "text": "concept that we're using today you can see this is an absolutely broad set of",
    "start": "283830",
    "end": "289300"
  },
  {
    "text": "architectures one of the nice things about this design is that it's tightly aligned with the AWS concept of service",
    "start": "289300",
    "end": "296620"
  },
  {
    "text": "and what this means is we're able to use ten AWS servers services and features but",
    "start": "296620",
    "end": "305650"
  },
  {
    "text": "within this architecture there are zero servers to manage and what does this mean it means a couple of things first",
    "start": "305650",
    "end": "313240"
  },
  {
    "text": "of all there's no need to administer manage or scale any of that compute",
    "start": "313240",
    "end": "319180"
  },
  {
    "text": "functionality yourself within the within the design secondly there's no need to",
    "start": "319180",
    "end": "324340"
  },
  {
    "text": "handle any of the scaling of these platforms yourself so the",
    "start": "324340",
    "end": "329490"
  },
  {
    "text": "ability for you to under provisions is removed from your administrative",
    "start": "329490",
    "end": "334600"
  },
  {
    "text": "overhead and AWS will take care of ensuring that the appropriate resources are available to your application in",
    "start": "334600",
    "end": "341350"
  },
  {
    "text": "your architecture on an as-needed basis and of course this being service the AWS",
    "start": "341350",
    "end": "347320"
  },
  {
    "text": "pricing model comes into play which is a utility excuse me a utility pricing model which means you'll only pay for",
    "start": "347320",
    "end": "353530"
  },
  {
    "text": "what you use so what I'd like to do is just take a few moments and share with you a demo of",
    "start": "353530",
    "end": "360190"
  },
  {
    "text": "this architecture and what the users actually get to see as a combination of all of these services together",
    "start": "360190",
    "end": "367690"
  },
  {
    "text": "[Music]",
    "start": "367690",
    "end": "370750"
  },
  {
    "text": "[Music]",
    "start": "374220",
    "end": "377359"
  },
  {
    "text": "[Music]",
    "start": "379590",
    "end": "393810"
  },
  {
    "text": "[Applause] [Music]",
    "start": "394470",
    "end": "414479"
  },
  {
    "text": "[Music]",
    "start": "416750",
    "end": "457839"
  },
  {
    "text": "[Music]",
    "start": "461250",
    "end": "464389"
  },
  {
    "text": "[Music]",
    "start": "466580",
    "end": "478328"
  },
  {
    "text": "[Music]",
    "start": "487400",
    "end": "501560"
  },
  {
    "text": "[Applause] [Music]",
    "start": "502230",
    "end": "521340"
  },
  {
    "text": "whenever I see that video I'm never sure whether to applause the music the content or the technology I think it's a",
    "start": "523510",
    "end": "529460"
  },
  {
    "text": "fantastic demonstration of what can be done when we tie together together these servos architectures and again this was",
    "start": "529460",
    "end": "535700"
  },
  {
    "text": "completely served and delivered in a serverless architecture so there were no not even web servers involved in",
    "start": "535700",
    "end": "541250"
  },
  {
    "text": "delivering that content now when we engage with our customers we like we a we love to get feedback but B",
    "start": "541250",
    "end": "548839"
  },
  {
    "text": "we love to be told what you need and we love to deliver on these needs and when we talk to customers about delivering",
    "start": "548839",
    "end": "555140"
  },
  {
    "text": "architectures like the ones we've just discussed we basically get four kiosks the customers ask us to help them with",
    "start": "555140",
    "end": "561740"
  },
  {
    "text": "the first one is can you help us ingest large volumes of real-time data from",
    "start": "561740",
    "end": "568040"
  },
  {
    "text": "large fleets of distributed devices and generally there's going to be IOT devices and to do that at scale and when",
    "start": "568040",
    "end": "574100"
  },
  {
    "text": "we talk about scale we're talking about global scale not hundreds not thousands or tens of thousands but millions of",
    "start": "574100",
    "end": "579560"
  },
  {
    "text": "devices and trillions of messages customers ask us to help them perform advanced analytics on this streaming",
    "start": "579560",
    "end": "586640"
  },
  {
    "text": "data and to be able to do this in real time so they don't need to manage that infrastructure and the complexity involved in doing that they also also",
    "start": "586640",
    "end": "593810"
  },
  {
    "text": "ask us to help them process this data and to store the large volume of data to",
    "start": "593810",
    "end": "599360"
  },
  {
    "text": "make it accessible for both real-time access but also historical access so we can go back and look at statistics and",
    "start": "599360",
    "end": "605959"
  },
  {
    "text": "trends over time and finally our customers ask us to deliver them solutions that eliminate capacity",
    "start": "605959",
    "end": "612470"
  },
  {
    "text": "planning scaling and the management of any infrastructure and the architectures that we've presented in the",
    "start": "612470",
    "end": "618050"
  },
  {
    "text": "architectures that our colleague Tim will talk about are ones that represent these asks that done you our customers",
    "start": "618050",
    "end": "624500"
  },
  {
    "text": "have asked for why are you our customers asking for",
    "start": "624500",
    "end": "629630"
  },
  {
    "text": "this you're asking because designing for failure in global real-time distributed",
    "start": "629630",
    "end": "637190"
  },
  {
    "start": "630000",
    "end": "630000"
  },
  {
    "text": "systems is really really hard it becomes extremely costly and require significant",
    "start": "637190",
    "end": "644810"
  },
  {
    "text": "infrastructure in order to achieve the level of scale and high availability that's required",
    "start": "644810",
    "end": "651430"
  },
  {
    "text": "secondly the infrastructure to build is extremely expensive and that",
    "start": "651430",
    "end": "657280"
  },
  {
    "text": "infrastructure that's required to process billions of devices sending trillions of messages is really",
    "start": "657280",
    "end": "663590"
  },
  {
    "text": "expensive what we mean there is only a global scale with a significantly large",
    "start": "663590",
    "end": "670010"
  },
  {
    "text": "customer base with diverse requirements allow you to build out this infrastructure in a way that serves",
    "start": "670010",
    "end": "675590"
  },
  {
    "text": "these needs thirdly that management overhead in managing these sort of",
    "start": "675590",
    "end": "681320"
  },
  {
    "text": "infrastructures and architectures that require high availability of global scale enforce a",
    "start": "681320",
    "end": "687590"
  },
  {
    "text": "level of management overhead and this scales that puts scale limitation on",
    "start": "687590",
    "end": "693530"
  },
  {
    "text": "organizations but it also impedes our organizational innovation and technology innovation within those organizations",
    "start": "693530",
    "end": "699160"
  },
  {
    "text": "because they become quite focused on managing the technology rather than delivering services capability and",
    "start": "699160",
    "end": "705380"
  },
  {
    "text": "functionality to their customers so AWS has taken onboard",
    "start": "705380",
    "end": "711670"
  },
  {
    "text": "the concept of doing all the undifferentiated heavy lifting for you our customers",
    "start": "711670",
    "end": "717070"
  },
  {
    "text": "this means that you can focus on delivering those things that you're really good at",
    "start": "717070",
    "end": "724010"
  },
  {
    "text": "and especially delivering value to your customers so what I'm going to do at the moment is",
    "start": "724010",
    "end": "730970"
  },
  {
    "text": "I'm going to walk you through quite quickly a reference model this reference model is the model that we use to build",
    "start": "730970",
    "end": "736370"
  },
  {
    "text": "out the architectures for the bootcamp they're reference models will be quite similar when you apply them for example",
    "start": "736370",
    "end": "741740"
  },
  {
    "text": "the architecture the Tim we'll talk through architecture from an AWS perspective",
    "start": "741740",
    "end": "747590"
  },
  {
    "text": "starts with security security is what we call it job zero it's the first thing we do when we wake up it's the last thing",
    "start": "747590",
    "end": "752840"
  },
  {
    "text": "that we do before we go to bed so any reference model from AWS will always have an extremely heavy security bin",
    "start": "752840",
    "end": "758600"
  },
  {
    "text": "we've got a rich suite of services and products that make security easy to implement and integrate into your own",
    "start": "758600",
    "end": "764930"
  },
  {
    "text": "environments secondly networking of course that will provide the connectivity between all the architectural components that's required",
    "start": "764930",
    "end": "772420"
  },
  {
    "text": "there is also compute capability that's required within a reference architecture this compute capability may be for",
    "start": "772420",
    "end": "779360"
  },
  {
    "text": "processing it may be for storage and may be for transforming and augmenting data of",
    "start": "779360",
    "end": "784720"
  },
  {
    "text": "course we're talking about Big Data and IOT he so we must have a data source",
    "start": "784720",
    "end": "790070"
  },
  {
    "text": "this data source could be as simple as a simple time stamped temperature value or",
    "start": "790070",
    "end": "795890"
  },
  {
    "text": "it could be really complex hot health sciences and health life sciences data things like real time blood glucose",
    "start": "795890",
    "end": "802670"
  },
  {
    "text": "monitoring data so you have to be able to handle a wide array of data in a wide",
    "start": "802670",
    "end": "808040"
  },
  {
    "text": "array of data formats the beauty of this architecture is when",
    "start": "808040",
    "end": "813800"
  },
  {
    "text": "we generalize we can abstract out the type of data and we could generalize it into just a simple concept of data and",
    "start": "813800",
    "end": "820070"
  },
  {
    "text": "ensure that our implementation is data agnostic in the way it deals with it we must be able to ingest this data in a",
    "start": "820070",
    "end": "827090"
  },
  {
    "text": "secure stable scalable environment we must be able to process this data in one one of",
    "start": "827090",
    "end": "834530"
  },
  {
    "text": "two or even both batch processing and real-time process processing excuse me",
    "start": "834530",
    "end": "839630"
  },
  {
    "text": "and we're actually going to look at both of these in detail a little bit later in the presentation we must be able to",
    "start": "839630",
    "end": "845540"
  },
  {
    "text": "analyze this data we must be able to turn data into meaningful insights we don't give a definition to what those",
    "start": "845540",
    "end": "852170"
  },
  {
    "text": "insights are meaningful means whatever is meaningful to you and your customers but we must have an engine capable of",
    "start": "852170",
    "end": "858920"
  },
  {
    "text": "turning data into information and even visualizing that information and then we",
    "start": "858920",
    "end": "864560"
  },
  {
    "text": "have to be able to store this so we can fetch this data back at any point in time in the future and we can look back",
    "start": "864560",
    "end": "870130"
  },
  {
    "text": "over time so this is our generalized reference architecture what happens when",
    "start": "870130",
    "end": "875360"
  },
  {
    "text": "we start overlaying the AWS services into this architecture well you get a generalized model that looks like this",
    "start": "875360",
    "end": "881600"
  },
  {
    "text": "Amazon VPC supplying the network capabilities in a secure cloud fashion",
    "start": "881600",
    "end": "887570"
  },
  {
    "text": "Amazon ec2 potentially or even lambda being used as in the compute layer AWS",
    "start": "887570",
    "end": "893540"
  },
  {
    "text": "IOT is your data source that data source can feed into the Kinesis suite of",
    "start": "893540",
    "end": "899960"
  },
  {
    "text": "families and we'll talk about how we do that in detail Kinesis firehose Kinesis streams provide the batch and the",
    "start": "899960",
    "end": "906980"
  },
  {
    "text": "real-time processing and Kinesis analytics enables us to run real-time analytics over this streaming or batched",
    "start": "906980",
    "end": "913760"
  },
  {
    "text": "data and then our suite of RDS databases and Amazon s3 allow us to store this",
    "start": "913760",
    "end": "921770"
  },
  {
    "text": "data so can access it overtime and of course security being job zero at AWS we",
    "start": "921770",
    "end": "927150"
  },
  {
    "text": "highly leveraged our identity access and management and other security products in our portfolio to wrap all this to",
    "start": "927150",
    "end": "934170"
  },
  {
    "text": "ensure this is a highly secure environment what we're going to focus on in today's",
    "start": "934170",
    "end": "940830"
  },
  {
    "text": "session is we're going to deep dive into those areas of the architecture that are highlighted in red so we're going to go",
    "start": "940830",
    "end": "946080"
  },
  {
    "text": "through Kinesis and we're going to go through all three of the Kinesis family members and we're going to go",
    "start": "946080",
    "end": "951360"
  },
  {
    "text": "into how we store this data so let's start to dig into iot a little",
    "start": "951360",
    "end": "957870"
  },
  {
    "text": "bit and you've heard me use the term thing and actually somebody even asked me this morning so what is IOT and",
    "start": "957870",
    "end": "963930"
  },
  {
    "text": "what's that this theme that you talk about this IOT thing there is no one",
    "start": "963930",
    "end": "969600"
  },
  {
    "text": "single answer to that an IOT thing could be something as simple as an iOS device",
    "start": "969600",
    "end": "977540"
  },
  {
    "text": "could be something as simple as a Kindle or a fire tablet we're seeing a",
    "start": "977540",
    "end": "983340"
  },
  {
    "text": "proliferation of IOT enabled embedded devices in the maker community like the",
    "start": "983340",
    "end": "988620"
  },
  {
    "text": "Arduino like the Raspberry Pi for those of you who are familiar with the Intel",
    "start": "988620",
    "end": "993720"
  },
  {
    "text": "Edison that's also considered an IOT thing embedded devices and wearables are",
    "start": "993720",
    "end": "999320"
  },
  {
    "text": "becoming incredibly popular most of us are now carrying heartrate monitors on",
    "start": "999320",
    "end": "1004730"
  },
  {
    "text": "our wrists that are watching our heartrate sending data to be analyzed in the cloud we're also seeing things being related",
    "start": "1004730",
    "end": "1012620"
  },
  {
    "text": "to the proliferation of the smart home the ability to instrument things like",
    "start": "1012620",
    "end": "1017990"
  },
  {
    "text": "smoke alarms temperature sensors light Globes and switches in our homes so we",
    "start": "1017990",
    "end": "1023450"
  },
  {
    "text": "see a thing being anything that's connected to the Internet from which we can acquire data process that data and",
    "start": "1023450",
    "end": "1029180"
  },
  {
    "text": "present that data there is a well known IOT framework",
    "start": "1029180",
    "end": "1035300"
  },
  {
    "start": "1032000",
    "end": "1032000"
  },
  {
    "text": "within AWS and it consists primarily of the seven elements you see on the board",
    "start": "1035300",
    "end": "1041870"
  },
  {
    "text": "I'm going to touch on each one of them but we're going to go deeper into only one of them today the AWS IOT device",
    "start": "1041870",
    "end": "1050630"
  },
  {
    "text": "gateway or message broker provides a secure mechanism for these",
    "start": "1050630",
    "end": "1056420"
  },
  {
    "text": "IOT things that we've just spoken about to publish and receive messages we use",
    "start": "1056420",
    "end": "1062810"
  },
  {
    "text": "the mqtt protocol to manage and to transport the the publication and",
    "start": "1062810",
    "end": "1068120"
  },
  {
    "text": "subscription to what we call topics upon which you'll receive and send data we use HTTPS as a transport methodology",
    "start": "1068120",
    "end": "1076060"
  },
  {
    "text": "this is effectively the AWS IOT endpoint it is also capable of doing WebSockets",
    "start": "1076060",
    "end": "1083900"
  },
  {
    "text": "and the real-time data that you saw in that demo that was coming and was actually coming from the iot web broker",
    "start": "1083900",
    "end": "1090530"
  },
  {
    "text": "through an authenticated connection using sig v4 signing down to a browser",
    "start": "1090530",
    "end": "1095840"
  },
  {
    "text": "in real time over WebSockets and that was raw mqtt data that had come all the",
    "start": "1095840",
    "end": "1101900"
  },
  {
    "text": "way through the AWS platform being delivered to the end-user the next thing I'd like to talk about is",
    "start": "1101900",
    "end": "1107660"
  },
  {
    "text": "the device Shadow the device Shadow is a unique concept in AWS IOT and it enables",
    "start": "1107660",
    "end": "1113840"
  },
  {
    "text": "the persistent state of information to be held within the thing even during",
    "start": "1113840",
    "end": "1119120"
  },
  {
    "text": "times of intermittent network connectivity so this is an extremely powerful capability that enables you to",
    "start": "1119120",
    "end": "1125210"
  },
  {
    "text": "control a IOT service and the things attached to that service even when the connectivity",
    "start": "1125210",
    "end": "1131720"
  },
  {
    "text": "to that device is intermittent or that device is not even connected when it",
    "start": "1131720",
    "end": "1137000"
  },
  {
    "text": "does connect optimistic locking will take care of ensuring that that device gets the",
    "start": "1137000",
    "end": "1142910"
  },
  {
    "text": "latest version of the state and the reported state and the desired states are synchronized so when the device",
    "start": "1142910",
    "end": "1148460"
  },
  {
    "text": "comes back online it should always have its latest state the rules engine in the AWS IOT service",
    "start": "1148460",
    "end": "1157600"
  },
  {
    "text": "enables us to take these MQTT messages that are flying around our architecture",
    "start": "1157600",
    "end": "1162980"
  },
  {
    "text": "and to transform these messages based on specific rules and then to be able to route these messages to other AWS",
    "start": "1162980",
    "end": "1170390"
  },
  {
    "text": "services or even to third-party services and this is the one that we're going to do a little bit of a deep dive into",
    "start": "1170390",
    "end": "1176470"
  },
  {
    "text": "so the AWS IOT rules engine gives your device the ability to interact with",
    "start": "1176470",
    "end": "1182450"
  },
  {
    "text": "other AWS services rules are analyzed and then actions are performed based on",
    "start": "1182450",
    "end": "1188000"
  },
  {
    "text": "the MQTT topic string and they can be routed to other services for example it",
    "start": "1188000",
    "end": "1193370"
  },
  {
    "text": "could be used to augment or filter data received from a specific device or a thing it could be used to write that",
    "start": "1193370",
    "end": "1200840"
  },
  {
    "text": "data to a DynamoDB table it could be used to save that data into Amazon s3",
    "start": "1200840",
    "end": "1206990"
  },
  {
    "text": "and it can even be used to republish that data to other MQTT topics that are",
    "start": "1206990",
    "end": "1213140"
  },
  {
    "text": "not even in your AWS account so this can be used to get mqtt and IOT T data IOT T",
    "start": "1213140",
    "end": "1219770"
  },
  {
    "text": "that's a new and IOT data between account so it's extremely powerful and it uses a sql-like language which means",
    "start": "1219770",
    "end": "1227300"
  },
  {
    "text": "most of us can get in there and start having a play with it because it's a very very familiar query language for us",
    "start": "1227300",
    "end": "1233240"
  },
  {
    "text": "to use authentication and authorization this is",
    "start": "1233240",
    "end": "1238790"
  },
  {
    "text": "a security layer of the IOT service and it provides security with mutual authentication and end-to-end encryption",
    "start": "1238790",
    "end": "1245180"
  },
  {
    "text": "I touched on before the cig v4 signing of of",
    "start": "1245180",
    "end": "1250540"
  },
  {
    "text": "requests it integrates nicely with the aid of the Amazon kognito service for",
    "start": "1250540",
    "end": "1255770"
  },
  {
    "text": "user pools and federated identities as well which means devices or things can",
    "start": "1255770",
    "end": "1261740"
  },
  {
    "text": "have policies and profiles that only allow them to either send or receive on specific IOT topics but also humans who",
    "start": "1261740",
    "end": "1269540"
  },
  {
    "text": "are into fact interfacing with browsers and logging into portals will also be able to get an IOT policy which allows",
    "start": "1269540",
    "end": "1276920"
  },
  {
    "text": "the IOT service to either send or not send or allow the user to interact with",
    "start": "1276920",
    "end": "1282170"
  },
  {
    "text": "certain MQTT streams from their browser that's where I'll end up I've given you",
    "start": "1282170",
    "end": "1288320"
  },
  {
    "start": "1285000",
    "end": "1285000"
  },
  {
    "text": "a high-level overview of the architecture a generalized architecture and a specific architecture daniel is",
    "start": "1288320",
    "end": "1293690"
  },
  {
    "text": "going to do a deep dive on the more complex areas thanks Dan right thanks mark all righty so what we're going to",
    "start": "1293690",
    "end": "1299390"
  },
  {
    "text": "do now we're going to take that reference architecture and apply it to the use case that mark went",
    "start": "1299390",
    "end": "1305930"
  },
  {
    "text": "through at the start of the presentation so the global weather service architecture so yesterday for those who have just",
    "start": "1305930",
    "end": "1313010"
  },
  {
    "text": "arrived we ran a bootcamp and we had a hundred attendees attend the bootcamp",
    "start": "1313010",
    "end": "1318920"
  },
  {
    "text": "where they were given an Intel Edison represented a weather station so we had weather stations that were allocated to",
    "start": "1318920",
    "end": "1325880"
  },
  {
    "text": "cities around the United States and each weather station had central environmental sensor data that was",
    "start": "1325880",
    "end": "1332270"
  },
  {
    "text": "getting aggregated to that weather station processed and then sent to the AWS IOT service and we had the challenge",
    "start": "1332270",
    "end": "1339860"
  },
  {
    "text": "of acquiring the sensor data from those weather stations at scale processing and",
    "start": "1339860",
    "end": "1346430"
  },
  {
    "text": "analyzing the data and then presenting the data and all of this using a service",
    "start": "1346430",
    "end": "1353180"
  },
  {
    "text": "architecture framework so having a look it's broken up into",
    "start": "1353180",
    "end": "1359080"
  },
  {
    "text": "three segments so on the left-hand side there at the top we have the acquisition",
    "start": "1359080",
    "end": "1365990"
  },
  {
    "text": "phase so we have the sensors and the data is getting sent to the weather station and then sent into the AWS iot",
    "start": "1365990",
    "end": "1373760"
  },
  {
    "text": "service so that's one sensor value per second per sensor so we had",
    "start": "1373760",
    "end": "1380810"
  },
  {
    "text": "four sensors so for per second and across all of the weather stations that was 400 readings a second and then the",
    "start": "1380810",
    "end": "1389300"
  },
  {
    "text": "bridge between the acquisition and the processing section was the SNS topic and I'll talk about why we use SNS there we",
    "start": "1389300",
    "end": "1396110"
  },
  {
    "text": "could have gone directly to the lambda function or the Kinesis firehose stream or the Kinesis stream and then the data",
    "start": "1396110",
    "end": "1403370"
  },
  {
    "text": "was processed and streamed into the data sources both for batch and real-time and",
    "start": "1403370",
    "end": "1408410"
  },
  {
    "text": "then from the demo that you saw earlier the user interface we use Cognito for the our authentication and authorization",
    "start": "1408410",
    "end": "1415990"
  },
  {
    "text": "to then access api gateway to them query historical weather data and the",
    "start": "1415990",
    "end": "1422390"
  },
  {
    "text": "summarized weather data coming out of Kinesis analytics and then the real-time MQTT data was sent over WebSockets to",
    "start": "1422390",
    "end": "1429830"
  },
  {
    "text": "that web application so a single page of web application running JavaScript",
    "start": "1429830",
    "end": "1437020"
  },
  {
    "text": "all right so what we're going to do today we're going to focus on the acquisition in the processing section we're not going to focus on the present",
    "start": "1437020",
    "end": "1443870"
  },
  {
    "text": "side of things but after the presentation today we'd be more than happy to talk about that",
    "start": "1443870",
    "end": "1451060"
  },
  {
    "text": "so let's dive into the Aqua so we had our four senses rain wind temperature",
    "start": "1451060",
    "end": "1457190"
  },
  {
    "start": "1452000",
    "end": "1452000"
  },
  {
    "text": "and vibration then we had the Intel Edison acting as the weather station and",
    "start": "1457190",
    "end": "1462950"
  },
  {
    "text": "that was aggravating the data processing it applying a Kalman filter and then the",
    "start": "1462950",
    "end": "1468380"
  },
  {
    "text": "data was being securely sent to the AWS IOT gateway so there was a certificate a unique certificate on each device and",
    "start": "1468380",
    "end": "1476390"
  },
  {
    "text": "then an IOT policy that was applied to that certificate on the IOT server side that allowed the weather station to",
    "start": "1476390",
    "end": "1482990"
  },
  {
    "text": "publish messages to a specific mu t topic or a set of topics and also",
    "start": "1482990",
    "end": "1488900"
  },
  {
    "text": "subscribe from there we applied an IOT rule to the",
    "start": "1488900",
    "end": "1494390"
  },
  {
    "text": "incoming sensor data so using the sequel query to transform that data and augment",
    "start": "1494390",
    "end": "1500210"
  },
  {
    "text": "it and then using an IOT action we sent it to an SNS topic we also which isn't",
    "start": "1500210",
    "end": "1507680"
  },
  {
    "text": "display here we also because all the sensor data was coming on four separate topics we actually also republish to a",
    "start": "1507680",
    "end": "1513860"
  },
  {
    "text": "single topic so we had all the sensor data streaming to a single topic for debugging",
    "start": "1513860",
    "end": "1520000"
  },
  {
    "text": "okay so now we're at the bridge so let's take a look at the processing section",
    "start": "1520000",
    "end": "1525560"
  },
  {
    "text": "and how that all fits together so the IOT action combined with the SNS",
    "start": "1525560",
    "end": "1531260"
  },
  {
    "text": "topic is the bridge and we can see that there's a lambda function subscribe to the SNS topic and",
    "start": "1531260",
    "end": "1538510"
  },
  {
    "text": "behind the scenes we're leveraging multiple lambda functions so that's so",
    "start": "1538510",
    "end": "1543710"
  },
  {
    "text": "we're using Amazon SNS to fan the data out so we could have different",
    "start": "1543710",
    "end": "1548900"
  },
  {
    "text": "applications consuming that data and processing that data at different speeds I'll get into that a little bit later",
    "start": "1548900",
    "end": "1554890"
  },
  {
    "text": "but first let's take a look at how we're using the IOT rule and how it's set up",
    "start": "1554890",
    "end": "1559940"
  },
  {
    "text": "so our incoming MQTT topic structure look like this so we had a prefix and in",
    "start": "1559940",
    "end": "1565100"
  },
  {
    "text": "total six segments in the topic where we had the state the weather station was in",
    "start": "1565100",
    "end": "1570950"
  },
  {
    "text": "the city the station ID the sensor type and the sensor ID so that was populated with this",
    "start": "1570950",
    "end": "1578110"
  },
  {
    "text": "appropriate census data then the sequel statement look like this",
    "start": "1578110",
    "end": "1583220"
  },
  {
    "text": "so we selected all the data from the incoming pay load and then what we did",
    "start": "1583220",
    "end": "1588630"
  },
  {
    "text": "we use some inbuilt functions so to extract the topic segments to then",
    "start": "1588630",
    "end": "1594150"
  },
  {
    "text": "transform and put into the output payload so we wanted the sensor ID the station ID the sensor type and then from",
    "start": "1594150",
    "end": "1601350"
  },
  {
    "text": "the incoming payload the sensor timestamp and then the various sensor values and we use the cast function to",
    "start": "1601350",
    "end": "1607169"
  },
  {
    "text": "make sure all the sensor values were in the same format all right so the incoming payload will",
    "start": "1607169",
    "end": "1614580"
  },
  {
    "text": "be something like this so that's the raw sensor data and then by applying the",
    "start": "1614580",
    "end": "1619740"
  },
  {
    "text": "sequel query so the IOT rule we can see at the top in bold is the topic segments",
    "start": "1619740",
    "end": "1626039"
  },
  {
    "text": "and then you can see the smooth we just highlighted one that we actually renamed that and also applied the cast function",
    "start": "1626039",
    "end": "1633380"
  },
  {
    "text": "all right so let's focus in on SNS and why we used it for fan-out",
    "start": "1633380",
    "end": "1639950"
  },
  {
    "start": "1634000",
    "end": "1634000"
  },
  {
    "text": "so we we were using multiple lambda functions in the bootcamp so for our use",
    "start": "1639950",
    "end": "1645870"
  },
  {
    "text": "case we had the participants building out this architecture end-to-end in",
    "start": "1645870",
    "end": "1651630"
  },
  {
    "text": "their own AWS account so we had a lambda function that was streaming the data and",
    "start": "1651630",
    "end": "1657270"
  },
  {
    "text": "processing the data into Kinesis fire hose and a Kinesis stream however on the",
    "start": "1657270",
    "end": "1663179"
  },
  {
    "text": "user interface we could also see the global weather view so a map of the United States and in in order to present",
    "start": "1663179",
    "end": "1669900"
  },
  {
    "text": "that map we needed to aggregate the data to a central AWS account so we had another lambda function that was",
    "start": "1669900",
    "end": "1675450"
  },
  {
    "text": "assuming a cross account role and then sending the data to a Kinesis stream and a Kinesis firehose stream in the global",
    "start": "1675450",
    "end": "1682140"
  },
  {
    "text": "weather service account and you could imagine if we were doing this in a real life scenario a weather station wouldn't",
    "start": "1682140",
    "end": "1688650"
  },
  {
    "text": "have an individual AWS account association it would be many weather stations associated with a single AWS",
    "start": "1688650",
    "end": "1695880"
  },
  {
    "text": "account so using the IOT service within a single account",
    "start": "1695880",
    "end": "1701720"
  },
  {
    "text": "so the first function we named the IOT loader so that loaded the data into the",
    "start": "1702320",
    "end": "1708210"
  },
  {
    "text": "fire hose delivery stream and the Kinesis stream and then we had another version of this called the cross account",
    "start": "1708210",
    "end": "1713549"
  },
  {
    "text": "IOT loader so using the Identity and Access Management Service and the secure talk and serve API it assumed across",
    "start": "1713549",
    "end": "1722490"
  },
  {
    "text": "account role from the global weather service account so there was a role and had policies defined that allowed the",
    "start": "1722490",
    "end": "1730860"
  },
  {
    "text": "assuming party to put records into the Kinesis streams then we had another",
    "start": "1730860",
    "end": "1736970"
  },
  {
    "text": "function called the RDS loader function and what this function did was load the raw sensor data into the Aurora database",
    "start": "1736970",
    "end": "1743759"
  },
  {
    "text": "and the samurai sensor data coming out of the Kinesis stream from the Kinesis",
    "start": "1743759",
    "end": "1748769"
  },
  {
    "text": "analytics application and one thing to note on the way in to the database we're using this lambda function to deegeu the",
    "start": "1748769",
    "end": "1755369"
  },
  {
    "text": "data because at scale services like SNS and IOT can deliver a message more than",
    "start": "1755369",
    "end": "1760980"
  },
  {
    "text": "once so from our API when we're querying the data in Aurora we want to make sure because we're doing aggregation and",
    "start": "1760980",
    "end": "1767009"
  },
  {
    "text": "summing and counting function functions we want to make sure that the data is consistent it's giving us an accurate",
    "start": "1767009",
    "end": "1772580"
  },
  {
    "text": "representation of that data now on the other hand with redshift you",
    "start": "1772580",
    "end": "1778169"
  },
  {
    "text": "know it doesn't matter if joobs are being delivered because it can process that data at scale we can easily create",
    "start": "1778169",
    "end": "1784590"
  },
  {
    "text": "a view and look at those results for reporting and analytics alright so this is where we're using all",
    "start": "1784590",
    "end": "1791820"
  },
  {
    "text": "the Kinesis services so let's take and a closer look at all the services and do a",
    "start": "1791820",
    "end": "1797159"
  },
  {
    "text": "quick recap so there's Kinesis streams and that's targeted towards technical developers so you can build your own",
    "start": "1797159",
    "end": "1803730"
  },
  {
    "text": "custom application that processes and analyze the streaming data in this fire",
    "start": "1803730",
    "end": "1809249"
  },
  {
    "text": "hose for ETL targeted towards data engineers so you can easily load massive",
    "start": "1809249",
    "end": "1814529"
  },
  {
    "text": "amounts of streaming data into s3 Amazon redshift and Amazon Elastic search and",
    "start": "1814529",
    "end": "1820529"
  },
  {
    "text": "then Kinesis analytics targeted towards developers and data scientists to easily analyze data just by writing sequel",
    "start": "1820529",
    "end": "1827909"
  },
  {
    "text": "query queries so let's look at key characteristics of the services kanessa",
    "start": "1827909",
    "end": "1834330"
  },
  {
    "text": "stream is for low latency streaming ingestion at scale knesset analytics for",
    "start": "1834330",
    "end": "1841759"
  },
  {
    "text": "near real-time analytics of streaming data so from a firehose delivery stream",
    "start": "1841759",
    "end": "1846929"
  },
  {
    "text": "or a Kinesis stream and it will deliver to an output stream and then fire hose for batch data delivery",
    "start": "1846929",
    "end": "1853679"
  },
  {
    "text": "so you can base the batch data delivery either on time or size and that goes",
    "start": "1853679",
    "end": "1859620"
  },
  {
    "text": "into s3 redshift and elasticsearch now why would you pick fire hose over a",
    "start": "1859620",
    "end": "1866309"
  },
  {
    "text": "Kinesis stream well looking at a Kinesis stream if you've got the requirement to",
    "start": "1866309",
    "end": "1872480"
  },
  {
    "text": "process data using a custom application of the incoming records with sub-second",
    "start": "1872480",
    "end": "1879269"
  },
  {
    "text": "latency and you're using your own framework then Kinesis streams would",
    "start": "1879269",
    "end": "1885330"
  },
  {
    "text": "probably be a good choice there if you were looking at Kinesis fire hose and",
    "start": "1885330",
    "end": "1890809"
  },
  {
    "text": "you were considering 0 administration and the ability to use existing analytics tools based on s3",
    "start": "1890809",
    "end": "1898009"
  },
  {
    "text": "redshift or elastic search and you were happy with the latency of 60 seconds or",
    "start": "1898009",
    "end": "1903029"
  },
  {
    "text": "greater to access the data in fire hose is a good choice and another thing to consider too when ingesting data with",
    "start": "1903029",
    "end": "1909749"
  },
  {
    "text": "fire hose you don't need to worry about scaling the incoming rate for the",
    "start": "1909749",
    "end": "1915779"
  },
  {
    "text": "ingestion on the service it does it automatically with konista streams",
    "start": "1915779",
    "end": "1920789"
  },
  {
    "text": "they're made up of shards so you need to take a look at the amount of data coming in and provision the amount of shards",
    "start": "1920789",
    "end": "1927749"
  },
  {
    "text": "that are required to handle that data rate on the incoming and the outgoing processing and to make that easy we've",
    "start": "1927749",
    "end": "1935309"
  },
  {
    "text": "just released a new API that makes it easy to scale up your shards in a",
    "start": "1935309",
    "end": "1941610"
  },
  {
    "text": "kanessa stream and there's a blog post on the big data and analytics AWS blog that goes into detail on how to do this",
    "start": "1941610",
    "end": "1948749"
  },
  {
    "text": "so using a cloud watch alarm to trigger a lambda function that then calls this new API to easily scale up your Kinesis",
    "start": "1948749",
    "end": "1956340"
  },
  {
    "text": "stream okay so looking at Kinesis analytics so",
    "start": "1956340",
    "end": "1962220"
  },
  {
    "text": "to set up a Kinesis analytics application we simply connect an incoming stream so that can be a",
    "start": "1962220",
    "end": "1967529"
  },
  {
    "text": "firehose stream or a Kinesis stream we write some sequel and then it will constantly deliver results out to an",
    "start": "1967529",
    "end": "1974970"
  },
  {
    "text": "output stream and that can be a Kinesis stream or a firehose stream",
    "start": "1974970",
    "end": "1980029"
  },
  {
    "text": "so this is where we're using the Kinesis analytics application you can be the",
    "start": "1980029",
    "end": "1985059"
  },
  {
    "text": "inputs stream in the output stream and then you can see the lambda function processing the output stream one thing",
    "start": "1985059",
    "end": "1990790"
  },
  {
    "text": "to note with lambda it supports different triggers so here we're using the Kinesis trigger which will batch",
    "start": "1990790",
    "end": "1998170"
  },
  {
    "text": "load data out of the Kinesis stream and you can define the batch size and that",
    "start": "1998170",
    "end": "2003360"
  },
  {
    "text": "will constantly check point where it's up to in processing the stream and delete and then you can process and",
    "start": "2003360",
    "end": "2008580"
  },
  {
    "text": "deliver the results to wherever you need to deliver them to so in this case Aurora",
    "start": "2008580",
    "end": "2013610"
  },
  {
    "start": "2012000",
    "end": "2012000"
  },
  {
    "text": "so looking at Kinesis analytics what questions are we trying to answer so if we go back to the user interface we saw",
    "start": "2013610",
    "end": "2019800"
  },
  {
    "text": "in the demo let's take a look at where the different data sources are coming from so we've got the current value with",
    "start": "2019800",
    "end": "2027600"
  },
  {
    "text": "a sensor and that's coming over WebSockets from the IOT gateway then we have the average value so that's",
    "start": "2027600",
    "end": "2036030"
  },
  {
    "text": "the average value over a specific time period so what we were doing we wanted to know the average value over the last",
    "start": "2036030",
    "end": "2042210"
  },
  {
    "text": "60 seconds so this was queried via the API you could easily use the IOT service",
    "start": "2042210",
    "end": "2047370"
  },
  {
    "text": "and use pub/sub to also get that value so you don't have to constantly poll an",
    "start": "2047370",
    "end": "2052618"
  },
  {
    "text": "API then for the minimum so observed value in the maximum observed value that was obtained via the API using a sequel",
    "start": "2052619",
    "end": "2060090"
  },
  {
    "text": "query and then the short-term graphing trendy that was acquired by MQTT data and then",
    "start": "2060090",
    "end": "2067770"
  },
  {
    "text": "on the other side we can see that we can there's a historical view of the data so",
    "start": "2067770",
    "end": "2073108"
  },
  {
    "text": "the average and that was obtained by querying the API and that was from the data delivered out from our Kinesis",
    "start": "2073109",
    "end": "2078990"
  },
  {
    "text": "analytics application and then finally we wanted to get some statistics around our sensor so the sensor up time the",
    "start": "2078990",
    "end": "2085530"
  },
  {
    "text": "message rate per minute so that was obtained from Kinesis analytics and also the total number of messages that",
    "start": "2085530",
    "end": "2092010"
  },
  {
    "text": "had been delivered to date so here's the Kinesis analytics web console and a sequel query when you",
    "start": "2092010",
    "end": "2099480"
  },
  {
    "start": "2093000",
    "end": "2093000"
  },
  {
    "text": "define one for Kinesis analytics is broken up into three parts so we the first part of the statement defines",
    "start": "2099480",
    "end": "2106440"
  },
  {
    "text": "what the output payload looks like and then we create a pump and to stream the",
    "start": "2106440",
    "end": "2112740"
  },
  {
    "text": "data to the destination stream and then over the incoming stream we select the data we want and and define the",
    "start": "2112740",
    "end": "2118770"
  },
  {
    "text": "functions we want to apply so we're averaging the sensor data summary it up so both for the smooth and non smooth",
    "start": "2118770",
    "end": "2124980"
  },
  {
    "text": "values and then counting the number of messages that we saw in that minute and it's over a window so here we can see",
    "start": "2124980",
    "end": "2132359"
  },
  {
    "text": "that we're using a tumbling window there's also a sliding window and where",
    "start": "2132359",
    "end": "2138690"
  },
  {
    "text": "we have group I that defines a tumbling window if it says window then it's sliding and so that's over a 60 second",
    "start": "2138690",
    "end": "2145400"
  },
  {
    "text": "period and you can see in the user interface here as well the real time data being delivered based on the sequel",
    "start": "2145400",
    "end": "2152820"
  },
  {
    "text": "query so you can test the queries Kinesis analytics is a declarative system so we just simply define the",
    "start": "2152820",
    "end": "2158760"
  },
  {
    "text": "sequel and takes care of the rest of processing and the delivery of the data and it also will discover the schemer of",
    "start": "2158760",
    "end": "2164490"
  },
  {
    "text": "the incoming data the first time you start up the application and the data can be in CSV format or Jason and you",
    "start": "2164490",
    "end": "2170339"
  },
  {
    "text": "can easily override the schemer if you need to alright so when the data was coming in",
    "start": "2170339",
    "end": "2176790"
  },
  {
    "text": "and into the Kinesis analytics application for each sensor we were collecting it",
    "start": "2176790",
    "end": "2182790"
  },
  {
    "text": "and then at the end of the window a single record would be emitted and it looked like there so it had the sensor",
    "start": "2182790",
    "end": "2187859"
  },
  {
    "text": "ID the sensor type the station ID and the--and the average values the some values and the message count so you can",
    "start": "2187859",
    "end": "2196020"
  },
  {
    "text": "see what the payload look like and then we loaded that directly into a database table ok let's take a look at the data stores",
    "start": "2196020",
    "end": "2203099"
  },
  {
    "text": "now so we've got redshift and Aurora alright so to recap we're using Aurora",
    "start": "2203099",
    "end": "2209640"
  },
  {
    "text": "for querying data via the API for the from the user interface so that's a",
    "start": "2209640",
    "end": "2215910"
  },
  {
    "text": "deduplicated raw sensor data and the summarized data so imagine scaling from",
    "start": "2215910",
    "end": "2222240"
  },
  {
    "text": "thousands to millions of API requests per minute and depending on the throughput requirement driven by the",
    "start": "2222240",
    "end": "2229109"
  },
  {
    "text": "global weather service at a certain point Aurora would be more cost effective over other solutions like",
    "start": "2229109",
    "end": "2235790"
  },
  {
    "text": "DynamoDB and let's look at the specific use case here",
    "start": "2235790",
    "end": "2241099"
  },
  {
    "text": "at an API level caching has very little benefit when you've got a whole lot of",
    "start": "2241099",
    "end": "2247170"
  },
  {
    "text": "disparate queries occurring over a large time period so if",
    "start": "2247170",
    "end": "2252230"
  },
  {
    "text": "you've got disparate queries over a 10-year period you may not have many cache hits however the last week or two",
    "start": "2252230",
    "end": "2258400"
  },
  {
    "text": "might be queried more frequently so that's where we're running occasionally",
    "start": "2258400",
    "end": "2264110"
  },
  {
    "text": "life elastic cache may have a benefit so what Aurora allows us to do is scale out",
    "start": "2264110",
    "end": "2269390"
  },
  {
    "text": "the reads really easily it supports a reader endpoint we can simply add additional read replicas and use that",
    "start": "2269390",
    "end": "2275450"
  },
  {
    "text": "reader endpoint our application I'd have to manage any complexity in our code in",
    "start": "2275450",
    "end": "2280520"
  },
  {
    "text": "adding and removing the read replicas so it makes it easy to scale out the reads and",
    "start": "2280520",
    "end": "2286660"
  },
  {
    "text": "the other good thing with Aurora is that we don't have to worry about scaling the",
    "start": "2286660",
    "end": "2292520"
  },
  {
    "text": "underlying storage because it uses s3 so we don't have to take any downtime to add more capacity there and when we have",
    "start": "2292520",
    "end": "2299600"
  },
  {
    "text": "our rear applicants running and a primary if it for whatever reason failed",
    "start": "2299600",
    "end": "2305240"
  },
  {
    "text": "or we need to fail over because it's got a consistent view of s3 because that's the underlying storage there's zero data",
    "start": "2305240",
    "end": "2311630"
  },
  {
    "text": "loss all right now let's take a look at redshift so we're using redshift for our",
    "start": "2311630",
    "end": "2318109"
  },
  {
    "text": "data warehouse and there are many use cases one use case could be correlating shopping trends",
    "start": "2318109",
    "end": "2325430"
  },
  {
    "text": "against whether you know data that's one use case and we could use redshift to",
    "start": "2325430",
    "end": "2331100"
  },
  {
    "text": "build a outputs and data and build a machine learning model so for in a",
    "start": "2331100",
    "end": "2336470"
  },
  {
    "text": "general example we could build a machine learning model so we could have ATMs",
    "start": "2336470",
    "end": "2341810"
  },
  {
    "text": "distributed around the country and we could be getting real-time data from those ATMs by the IOT service and we",
    "start": "2341810",
    "end": "2348590"
  },
  {
    "text": "could query the Amazon machine learning service directly and we could ask it you know how likely is this ATM",
    "start": "2348590",
    "end": "2355900"
  },
  {
    "text": "how likely is that this ATM will fail and it could return you know a 1 or a 0",
    "start": "2355900",
    "end": "2362330"
  },
  {
    "text": "or or on a scale and based off that we could make a decision to send an",
    "start": "2362330",
    "end": "2369140"
  },
  {
    "text": "engineer out to go and take a look at the ATM and repair it and and then that way we can minimize",
    "start": "2369140",
    "end": "2375690"
  },
  {
    "text": "customer impact with an outage alright so in summary let's take a look",
    "start": "2375690",
    "end": "2382440"
  },
  {
    "start": "2379000",
    "end": "2379000"
  },
  {
    "text": "at the data store so we've got s3 it's the basis for our data like the foundation where we're storing long-term",
    "start": "2382440",
    "end": "2389360"
  },
  {
    "text": "data where it's warm we can get to it quickly it's secure it's fully managed",
    "start": "2389360",
    "end": "2394470"
  },
  {
    "text": "there's lifecycle management so we can lifecycle the objects too infrequently access s3 glacier or delete objects",
    "start": "2394470",
    "end": "2402360"
  },
  {
    "text": "after we don't need them now at times there might be questions when we first get the data and we don't",
    "start": "2402360",
    "end": "2408960"
  },
  {
    "text": "know what to ask of that data so we can easily reprocess that data using a",
    "start": "2408960",
    "end": "2414060"
  },
  {
    "text": "supported framework framework that supports s3 and then use EMR to reprocess and load",
    "start": "2414060",
    "end": "2420660"
  },
  {
    "text": "it back into redshift to the query then we've got a redshift for an",
    "start": "2420660",
    "end": "2426810"
  },
  {
    "text": "optimized data warehouse and analytics platform so we can query large amounts of data really really fast with redshift",
    "start": "2426810",
    "end": "2433440"
  },
  {
    "text": "and we can easily scale by adding additional nodes there so for storage or",
    "start": "2433440",
    "end": "2439620"
  },
  {
    "text": "faster queries and it's fully managed so we don't have to manage any of the underlying infrastructure there and then",
    "start": "2439620",
    "end": "2446610"
  },
  {
    "text": "finally arora optimize for distributed data access and we can easily scale the",
    "start": "2446610",
    "end": "2451830"
  },
  {
    "text": "reed throughput and it's highly fault tolerant all right with that I'm going",
    "start": "2451830",
    "end": "2456840"
  },
  {
    "text": "to hand it over to Tim Bart from hello to talk about their specific use case and how they're using AWS services to",
    "start": "2456840",
    "end": "2464280"
  },
  {
    "text": "address their IOT analytics challenges around what they're doing with their",
    "start": "2464280",
    "end": "2470940"
  },
  {
    "text": "sensors for over to you Tim thanks yeah hi guys I'm Tim and today I'm going to",
    "start": "2470940",
    "end": "2478580"
  },
  {
    "text": "to you what hello doesn't the product that we've built over the last two years as you can see we're a company that is",
    "start": "2478580",
    "end": "2485690"
  },
  {
    "text": "hardware from where yes science and software and since the product that you see there is is intelligent sleep",
    "start": "2485690",
    "end": "2492200"
  },
  {
    "text": "tracking device you can see sensing it's a veted on the bed stand and a little",
    "start": "2492200",
    "end": "2497960"
  },
  {
    "text": "sleep pill that you clip to your pillow that will sleep the little pill on the pillow traction motion the sensors on",
    "start": "2497960",
    "end": "2505700"
  },
  {
    "text": "the table tracks the humidity the temperature that particulates the air quality the sound of the light in your",
    "start": "2505700",
    "end": "2511700"
  },
  {
    "text": "bedroom and we use all that data to kind of understand how you sleep when you",
    "start": "2511700",
    "end": "2517100"
  },
  {
    "text": "sleep well and when you don't sleep well and can we command you to take actions when the conditions are not perfect",
    "start": "2517100",
    "end": "2524110"
  },
  {
    "text": "so today I will zoom in on our use of Amazon Kinesis biote data hello which i",
    "start": "2524110",
    "end": "2530390"
  },
  {
    "text": "think is has been the most useful service from the AWS family that we're using",
    "start": "2530390",
    "end": "2535870"
  },
  {
    "text": "before you wade through those slides I'd like to mention that when we started building this product AWS IOT did not",
    "start": "2535870",
    "end": "2544220"
  },
  {
    "start": "2537000",
    "end": "2537000"
  },
  {
    "text": "exist and so we had to invent everything ourselves and wall everything ourselves",
    "start": "2544220",
    "end": "2549980"
  },
  {
    "text": "so here you can see on this diagram that we have our ingestion ELB which is the",
    "start": "2549980",
    "end": "2555770"
  },
  {
    "text": "elastic load balancer that receives all the data from where we from our devices",
    "start": "2555770",
    "end": "2560900"
  },
  {
    "text": "we have a fleet of ec2 instances processing the data verifying that the",
    "start": "2560900",
    "end": "2566000"
  },
  {
    "text": "device is authorized and that the integrity of the data has been correct and",
    "start": "2566000",
    "end": "2571540"
  },
  {
    "text": "then we publish that data to a bunch of Knesset streams and those kinases",
    "start": "2571540",
    "end": "2576650"
  },
  {
    "text": "streams are being processed by a few workers in the workers store the data into different data stores on the other",
    "start": "2576650",
    "end": "2584030"
  },
  {
    "text": "end we have mobile applications which use a regular HTTP JSON API to query the",
    "start": "2584030",
    "end": "2589400"
  },
  {
    "text": "data from different data stores like dynamo DB post squares and so on I'll zoom in on our use for of Amazon kenosis",
    "start": "2589400",
    "end": "2597320"
  },
  {
    "text": "and what it means to use kenosis for real-time processing and also like",
    "start": "2597320",
    "end": "2603250"
  },
  {
    "text": "machine learning model building so you can see on this on this diagram that we",
    "start": "2603250",
    "end": "2608570"
  },
  {
    "text": "have a bunch of sensor that you mediate particulate light sound all of that data",
    "start": "2608570",
    "end": "2613950"
  },
  {
    "text": "goes through through one can is the stream that stream is then being consumed by multiple workers one of this",
    "start": "2613950",
    "end": "2620190"
  },
  {
    "text": "worker is you know whose role is to store the data and dynamodb for easy",
    "start": "2620190",
    "end": "2625440"
  },
  {
    "text": "access for online queries so this is where we store the time series of all the data that each device has been",
    "start": "2625440",
    "end": "2630930"
  },
  {
    "text": "processed we have another worker with the role is to deserialize the binary data sent to our device and publishes to",
    "start": "2630930",
    "end": "2638280"
  },
  {
    "text": "kinases firehose stream the fire hose drops the data in s tray and also in redshift where we use redshift as a",
    "start": "2638280",
    "end": "2645120"
  },
  {
    "text": "source for data machine learning bit model building",
    "start": "2645120",
    "end": "2650300"
  },
  {
    "text": "that we can use to then recommend better conditions for you to sleep there are a few reasons why we chose to",
    "start": "2650300",
    "end": "2657870"
  },
  {
    "text": "use Amazon kinases and you know durability immutability and real-time",
    "start": "2657870",
    "end": "2663900"
  },
  {
    "text": "processing where the key parts of why we decide to go with it in terms of",
    "start": "2663900",
    "end": "2669540"
  },
  {
    "start": "2669000",
    "end": "2669000"
  },
  {
    "text": "durability it's very important for us to be able to offload the data as quickly as possible from your device or devices",
    "start": "2669540",
    "end": "2675180"
  },
  {
    "text": "have kilobytes of RAM and so we need to make sure that any data that has been",
    "start": "2675180",
    "end": "2680490"
  },
  {
    "text": "collected need to be uploaded and process and store drably and so what we",
    "start": "2680490",
    "end": "2686100"
  },
  {
    "text": "do is we do a synchronous put record call to Amazon Kinesis on every data upload it's synchronous on purpose once",
    "start": "2686100",
    "end": "2692550"
  },
  {
    "text": "we receive a sequence number back from the knesset service we know that the data has been processed and now we can",
    "start": "2692550",
    "end": "2698340"
  },
  {
    "text": "tell devices to reclaim memory in space and continue processing data we also send some other type of data which is",
    "start": "2698340",
    "end": "2704970"
  },
  {
    "text": "not sensor data but diagnostic logs which can be sent in batches so the",
    "start": "2704970",
    "end": "2710310"
  },
  {
    "text": "sensor data is being sent extremely often so very small payload at a very very high frequency then we have other",
    "start": "2710310",
    "end": "2716010"
  },
  {
    "text": "much bigger payloads are being sent at a slightly lower frequency and so we can by using a single",
    "start": "2716010",
    "end": "2722330"
  },
  {
    "text": "platform like Amazon kinases we can also process small and very frequent or",
    "start": "2722330",
    "end": "2727470"
  },
  {
    "text": "larger and less frequent data payload as we can potentially imagine through this",
    "start": "2727470",
    "end": "2733800"
  },
  {
    "text": "process it's possible for a device to to attempt to upload the same data over and over again and so what we've made sure",
    "start": "2733800",
    "end": "2740120"
  },
  {
    "text": "design is to have our databases the item point so any message that is being published more than once is being in",
    "start": "2740120",
    "end": "2746600"
  },
  {
    "text": "store only once in in our in our databases I will also recommend everybody to use a",
    "start": "2746600",
    "end": "2752780"
  },
  {
    "text": "7-day data retention for Canisius so if anything happens downstream we have about seven days to reprocess all the",
    "start": "2752780",
    "end": "2758780"
  },
  {
    "text": "data one of the reason why Kinesis is very different from other like messaging",
    "start": "2758780",
    "end": "2764360"
  },
  {
    "text": "system is the notion of immutability the message is published once and you can",
    "start": "2764360",
    "end": "2769550"
  },
  {
    "text": "have multiple consumers consuming the same message over and over again as a rule of thumb for every stream that we",
    "start": "2769550",
    "end": "2775580"
  },
  {
    "text": "have we have about 10 consumers those consumers for us run on ec2 using",
    "start": "2775580",
    "end": "2781640"
  },
  {
    "text": "the Amazon communities library and I will you know going to details about this in a few minutes but you can also",
    "start": "2781640",
    "end": "2787130"
  },
  {
    "text": "have consumers running on AWS lambda like marking and General presented today and you can obviously mix and match both",
    "start": "2787130",
    "end": "2793360"
  },
  {
    "text": "in addition sharing multiple consumers you can have a consumer that process multiple versions",
    "start": "2793360",
    "end": "2800420"
  },
  {
    "text": "of your algorithm so think of it of if you had an alerting system and you're interesting and trying a new way of",
    "start": "2800420",
    "end": "2806240"
  },
  {
    "text": "aggregating data and alerting you that something is abnormal then you can run version a B",
    "start": "2806240",
    "end": "2812300"
  },
  {
    "text": "and C in parallel and once you're confident that your new version is performing as well and as efficiently as",
    "start": "2812300",
    "end": "2817820"
  },
  {
    "text": "you thought it would all you have to do is stop the previous consumer you do not have to code to change any code you do",
    "start": "2817820",
    "end": "2823700"
  },
  {
    "text": "not have to have a single application that process and tries multiple algorithm you can do that fully",
    "start": "2823700",
    "end": "2829010"
  },
  {
    "text": "independently one of the very also very interesting use case of Amazon kinases is the",
    "start": "2829010",
    "end": "2835370"
  },
  {
    "text": "ability to process data in real time and today I'd like to walk you through like",
    "start": "2835370",
    "end": "2840740"
  },
  {
    "text": "one of the use cases that you might face when you're starting to operate a fleet of tens of thousands or hundreds of",
    "start": "2840740",
    "end": "2846500"
  },
  {
    "text": "thousands of devices like how do you know how many devices are online right now how do you know how many devices",
    "start": "2846500",
    "end": "2853610"
  },
  {
    "text": "uploaded data in the last 60 seconds when was the last time that this very specific device was seen and to answer",
    "start": "2853610",
    "end": "2860690"
  },
  {
    "text": "all those questions at first we decided to run sequel queries no database you know simple select distant camp from",
    "start": "2860690",
    "end": "2868100"
  },
  {
    "text": "sensor table and try to find what happened in last five minutes as you can imagine with billions of data points",
    "start": "2868100",
    "end": "2874410"
  },
  {
    "text": "that query was not really scaling very well and so we decided to you know build other consumers on top of the same can",
    "start": "2874410",
    "end": "2881760"
  },
  {
    "text": "is extreme to answer the one or two answers questions one of the reason why it's very easy to",
    "start": "2881760",
    "end": "2888150"
  },
  {
    "start": "2885000",
    "end": "2885000"
  },
  {
    "text": "build as consumers is because Amazon provides the key misses client library which is a library for kanessa streams",
    "start": "2888150",
    "end": "2895530"
  },
  {
    "text": "which implements which lets you implement a very simple interface that",
    "start": "2895530",
    "end": "2901079"
  },
  {
    "text": "you can see here and by implementing the three methods you get access to a fully",
    "start": "2901079",
    "end": "2906799"
  },
  {
    "text": "reliable synchronized Kinesis consumer and so today we'll we",
    "start": "2906799",
    "end": "2912450"
  },
  {
    "text": "spend some time looking at the process records method right in the middle which is where most of the application logic",
    "start": "2912450",
    "end": "2917790"
  },
  {
    "text": "lives so to answer the question of when was the last time we saw each device",
    "start": "2917790",
    "end": "2925190"
  },
  {
    "start": "2920000",
    "end": "2920000"
  },
  {
    "text": "we've decided to implement this on top of red is running on ElastiCache so what",
    "start": "2925190",
    "end": "2930900"
  },
  {
    "text": "the consumer does is you know for each record being provided by Amazon",
    "start": "2930900",
    "end": "2936020"
  },
  {
    "text": "KCl we parse the record it's binary data so we extract the fields that we want we",
    "start": "2936020",
    "end": "2942599"
  },
  {
    "text": "then store into a single key on Redis what doesn't what the sensor ID was and what a timestamp of the data uploaded",
    "start": "2942599",
    "end": "2949380"
  },
  {
    "text": "was and by just you know inserting this data into Redis and be able to query",
    "start": "2949380",
    "end": "2954809"
  },
  {
    "text": "that very efficiently we do not have the need for this sequel query that was not",
    "start": "2954809",
    "end": "2960030"
  },
  {
    "text": "scaling very well and we can answer questions that were really difficult to answer before like which devices as an",
    "start": "2960030",
    "end": "2966660"
  },
  {
    "text": "uploaded data in the last two hours this is pretty tricky to do in sequel",
    "start": "2966660",
    "end": "2971819"
  },
  {
    "text": "efficiently and so using a different storage for that solution on top of the",
    "start": "2971819",
    "end": "2977400"
  },
  {
    "text": "other consumers are like processing the data to DynamoDB and to the Canisius firehose let's just answer this question",
    "start": "2977400",
    "end": "2984270"
  },
  {
    "text": "most multiple times a second and have a real-time view of the entire fleet and once you have you know thousands",
    "start": "2984270",
    "end": "2990780"
  },
  {
    "text": "thousands of devices knowing that everything is running smoothly is pretty good and so baby to do to conclude I'll share",
    "start": "2990780",
    "end": "2999809"
  },
  {
    "start": "2996000",
    "end": "2996000"
  },
  {
    "text": "with you a few lessons that we've learned one thing I would highly recommend is to use the same stream for data archival",
    "start": "2999809",
    "end": "3006259"
  },
  {
    "text": "and analysis I am not suggesting using a single stream for everything but doing the same analytics on the same stream",
    "start": "3006259",
    "end": "3012680"
  },
  {
    "text": "guarantees that you have the same data source there is no mismatch or application that forgot to be updated",
    "start": "3012680",
    "end": "3018979"
  },
  {
    "text": "and where the data could be disparate if you operate on the same stream you have the same deal I will also advise you to",
    "start": "3018979",
    "end": "3025609"
  },
  {
    "text": "sleep your streams early the reason is even if you don't need the capacity",
    "start": "3025609",
    "end": "3030680"
  },
  {
    "text": "right now you never know how many consumers you're going to have in a near future and since it's short on Canada's",
    "start": "3030680",
    "end": "3037459"
  },
  {
    "text": "stream has a capacity limit you want to make sure that IDing a consumer is now MPD and built the entire scalability of",
    "start": "3037459",
    "end": "3044690"
  },
  {
    "text": "your system so if you can I suggest splitting your charts very old user",
    "start": "3044690",
    "end": "3050299"
  },
  {
    "text": "amazon kinases client library or the KCl if you can if you're on the JVM it's",
    "start": "3050299",
    "end": "3055880"
  },
  {
    "text": "really really trivial to to write a consumer application and Amazon takes care of short synchronization",
    "start": "3055880",
    "end": "3062709"
  },
  {
    "text": "checkpointing and really all you have to do is given a list of records store that",
    "start": "3062709",
    "end": "3067759"
  },
  {
    "text": "data will process that data the way you want it you can also run this on you know AWS lambda if you wanted to and I",
    "start": "3067759",
    "end": "3073940"
  },
  {
    "text": "think one of the key point is you can mix and match so if you need to prototype a device lambda you won't be",
    "start": "3073940",
    "end": "3080709"
  },
  {
    "text": "preventing another consumer from winning their message they all run in parallel and fully independently and so the last",
    "start": "3080709",
    "end": "3087769"
  },
  {
    "text": "point was like yes many independent consumers make writing those application extremely trivial they have one",
    "start": "3087769",
    "end": "3093949"
  },
  {
    "text": "responsibility they do it and they don't need to know about other consumers there is no synchronization required there and",
    "start": "3093949",
    "end": "3100900"
  },
  {
    "text": "the last few points are you know especially dear to me is choose your",
    "start": "3100900",
    "end": "3106039"
  },
  {
    "text": "sterilization protocol wisely we operate on devices that have a very tiny CPU and",
    "start": "3106039",
    "end": "3111170"
  },
  {
    "text": "very tiny amount of memory and so we show something that was really efficient for those devices which is Google",
    "start": "3111170",
    "end": "3116630"
  },
  {
    "text": "protocol buffer and it works very well for us the the only problem is like you",
    "start": "3116630",
    "end": "3122749"
  },
  {
    "text": "need a custom deserialize er to extract the binary data into something that other services can use and this is one",
    "start": "3122749",
    "end": "3129499"
  },
  {
    "text": "of the reason why we're not yet using Amazon Kim missus and now it exists week is we need to transfer that transform",
    "start": "3129499",
    "end": "3135809"
  },
  {
    "text": "the data from binary to a CSV format or a JSON format for it to be processed and the last point is I said earlier that",
    "start": "3135809",
    "end": "3143730"
  },
  {
    "text": "for every stream we have about ten consumers you might run into some of the",
    "start": "3143730",
    "end": "3149099"
  },
  {
    "text": "issues once you have too many consumers on the same stream there is a limit to five reach per second per shard and the",
    "start": "3149099",
    "end": "3157140"
  },
  {
    "text": "solution to that is to use a fan-out strategy similar to what Daniel",
    "start": "3157140",
    "end": "3162390"
  },
  {
    "start": "3161000",
    "end": "3161000"
  },
  {
    "text": "described today I would strongly recommend using the AWS member fan-out library which lets you fan-out one",
    "start": "3162390",
    "end": "3169020"
  },
  {
    "text": "kanessa stream into multiple AWS services either other kanessa stream or",
    "start": "3169020",
    "end": "3174089"
  },
  {
    "text": "sqs and another system and so with this event mark",
    "start": "3174089",
    "end": "3180440"
  },
  {
    "text": "thanks Tim I think it was fantastic to have a look at a second use case that's actually used at scale and in production",
    "start": "3182030",
    "end": "3189020"
  },
  {
    "text": "serving multiple tens of thousands of thousands of customers that was excellent thank you very much Tim",
    "start": "3189020",
    "end": "3195380"
  },
  {
    "text": "we've covered a lot of ground today we've covered a lot of Technology we've gone quite deep on some of them but",
    "start": "3195380",
    "end": "3202740"
  },
  {
    "text": "there are really three things that we want to leave you with as you continue your interesting reinvent journey over",
    "start": "3202740",
    "end": "3209520"
  },
  {
    "text": "the week the first one is that I ot with real-time analytics provides",
    "start": "3209520",
    "end": "3215089"
  },
  {
    "text": "information not just data and it's the Kinesis analytics component that we",
    "start": "3215089",
    "end": "3220380"
  },
  {
    "text": "spoke about in the first architecture that enables you to take raw data and turn that into meaningful insights",
    "start": "3220380",
    "end": "3227720"
  },
  {
    "text": "scale without intervention or cost using serverless architectures will enable you",
    "start": "3227720",
    "end": "3233880"
  },
  {
    "text": "to take your designs and not put a cap on the number of customers the number of",
    "start": "3233880",
    "end": "3240030"
  },
  {
    "text": "services that you can deliver and to do that without having to manually scale servers or platforms and finally",
    "start": "3240030",
    "end": "3249950"
  },
  {
    "text": "we want to deliver architectures that remove management and scaling overhead and accelerate innovation so the",
    "start": "3249950",
    "end": "3257190"
  },
  {
    "text": "technologies that we've covered today enable you to focus on delivering true value to your customers rather than",
    "start": "3257190",
    "end": "3263789"
  },
  {
    "text": "focusing on scaling up services and products so with that I'd like to say thank you",
    "start": "3263789",
    "end": "3270539"
  },
  {
    "text": "very much for your time it's been a pleasure spending some time with this afternoon",
    "start": "3270539",
    "end": "3276109"
  }
]
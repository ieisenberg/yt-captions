[
  {
    "start": "0",
    "end": "40000"
  },
  {
    "text": "thank you so much for showing up 5:30 there are plenty of options in Las Vegas",
    "start": "3750",
    "end": "10400"
  },
  {
    "text": "but apparently you chose to listen to tensorflow talk so you know I tip my hat",
    "start": "10400",
    "end": "16108"
  },
  {
    "text": "to you so my name is Julian I'm a tech evangelist with AWS and I focus on",
    "start": "16109",
    "end": "22470"
  },
  {
    "text": "machine learning in this session we're going to talk about tensorflow and we're",
    "start": "22470",
    "end": "28710"
  },
  {
    "text": "going to talk about stage maker and how to best run texture flow on stage maker and I will have a fairly pretty",
    "start": "28710",
    "end": "37680"
  },
  {
    "text": "extensive demo to run as well at the end so who's already using stage maker today",
    "start": "37680",
    "end": "44059"
  },
  {
    "start": "40000",
    "end": "100000"
  },
  {
    "text": "all right all right a few people ok who's already using tensorflow today all",
    "start": "44059",
    "end": "49890"
  },
  {
    "text": "right a few people too okay so there's hopefully there's something for everyone here whether you're already know sage",
    "start": "49890",
    "end": "55289"
  },
  {
    "text": "rector or not and whether you already know tensorflow or not so that's what we're going to do a very quick overview",
    "start": "55289",
    "end": "60449"
  },
  {
    "text": "of sage maker very quick order of your tensorflow then putting the two together",
    "start": "60449",
    "end": "65970"
  },
  {
    "text": "and you know I tend to believe interesting things happen when we mix those two technologies and then I'll go",
    "start": "65970",
    "end": "74130"
  },
  {
    "text": "through a pretty extensive demo where I will train a Kaos script using a custom",
    "start": "74130",
    "end": "81090"
  },
  {
    "text": "container and we'll do hyper parameter optimization and all kinds of things ok and of course we'll share some resources",
    "start": "81090",
    "end": "87659"
  },
  {
    "text": "for you to get you started and I will stay for as long as I need to to answer all the questions at the end and of",
    "start": "87659",
    "end": "94079"
  },
  {
    "text": "course you will get the video on YouTube in the next couple of days so let's",
    "start": "94079",
    "end": "100619"
  },
  {
    "start": "100000",
    "end": "162000"
  },
  {
    "text": "start with a quick recap of sage maker so sage maker was launched at reinvent",
    "start": "100619",
    "end": "106229"
  },
  {
    "text": "last year and it's it's trying to do one thing it's trying to help all of you",
    "start": "106229",
    "end": "111630"
  },
  {
    "text": "other developers there are scientists and whether your machine learning",
    "start": "111630",
    "end": "116880"
  },
  {
    "text": "experts or whether you're just starting with the thing it's trying to help you get from experimentation to production",
    "start": "116880",
    "end": "125820"
  },
  {
    "text": "as fast and as seamlessly as possible so we're trying to tear down all those",
    "start": "125820",
    "end": "131790"
  },
  {
    "text": "walls that machine learning projects complicated okay and again whether you're an expert",
    "start": "131790",
    "end": "138200"
  },
  {
    "text": "or whether you're just a newbie when it comes to machine learning you'll find that stage maker lets you do that I have",
    "start": "138200",
    "end": "145220"
  },
  {
    "text": "to mention stage maker is part of a free tier so you can you can use it up to a certain level totally for free for for",
    "start": "145220",
    "end": "152390"
  },
  {
    "text": "several months okay so if you've never tried stage maker before I recommend that you try it and of course I'll share",
    "start": "152390",
    "end": "159200"
  },
  {
    "text": "some resources at the end to help you do that so say maker is really it's a",
    "start": "159200",
    "end": "165410"
  },
  {
    "start": "162000",
    "end": "275000"
  },
  {
    "text": "collection under that stage maker name we find different things we found",
    "start": "165410",
    "end": "170630"
  },
  {
    "text": "different modules so to speak so the first one deals with building stuff right and it's the dev environment story",
    "start": "170630",
    "end": "178880"
  },
  {
    "text": "all over again if you want to embark on a machine learning project you need you need a sandbox you need you need a",
    "start": "178880",
    "end": "186260"
  },
  {
    "text": "server maybe a GPU server and you need to set it up with all the planning tools",
    "start": "186260",
    "end": "192290"
  },
  {
    "text": "and the jupiter notebooks and everything else so you know it's a drag to do over and over again and if you have large",
    "start": "192290",
    "end": "197900"
  },
  {
    "text": "teams it is extremely painful so we provide notebook instances and that's what I'm using today some fully managed",
    "start": "197900",
    "end": "204560"
  },
  {
    "text": "ec2 instance is pre-installed with everything that you need and then to help you build even faster there's a collection of built-in algorithms and",
    "start": "204560",
    "end": "211340"
  },
  {
    "text": "these solve typical problems like you know linear regression clustering",
    "start": "211340",
    "end": "217280"
  },
  {
    "text": "classification but also some more advanced stuff like time series natural",
    "start": "217280",
    "end": "223459"
  },
  {
    "text": "language processing etc so today we have 16 I'll goes 17 actually because one was just added today and again I encourage",
    "start": "223459",
    "end": "231170"
  },
  {
    "text": "you to start from those maybe your machine learning problem is close enough to one to what one of those algos can do",
    "start": "231170",
    "end": "237620"
  },
  {
    "text": "and and you'll save a lot of time by not writing machine learning code and using directly one of those algos we also",
    "start": "237620",
    "end": "244910"
  },
  {
    "text": "provide built in environments for for machine learning and deep learning libraries so MX net china tends to flow",
    "start": "244910",
    "end": "252230"
  },
  {
    "text": "Python and and I think more are coming I saw more notebooks being pushed to get",
    "start": "252230",
    "end": "258470"
  },
  {
    "text": "up today with a scikit-learn and SPARC ml so probably that's gonna be announced",
    "start": "258470",
    "end": "263930"
  },
  {
    "text": "pretty soon but you could really bring anything to our to sage maker and that's what I'm gonna do today I'm gonna build a custom",
    "start": "263930",
    "end": "270560"
  },
  {
    "text": "container to use Karis in here and then",
    "start": "270560",
    "end": "275800"
  },
  {
    "start": "275000",
    "end": "309000"
  },
  {
    "text": "once you are happy with your I'll go with the model you want to train it you",
    "start": "275800",
    "end": "280940"
  },
  {
    "text": "want to optimize it and and sage maker provides very simple API is to train at",
    "start": "280940",
    "end": "286490"
  },
  {
    "text": "any scale so one API call as you will see fires up a training cluster and you",
    "start": "286490",
    "end": "291740"
  },
  {
    "text": "get the model back and literally one API call fires up an automatic model tuning",
    "start": "291740",
    "end": "297610"
  },
  {
    "text": "job to figure out what the best parameters are etc etc so you really",
    "start": "297610",
    "end": "302900"
  },
  {
    "text": "spend no time messing with the lower level details you really focus on the machine learning tasks and we'll see all of this in a moment",
    "start": "302900",
    "end": "309080"
  },
  {
    "start": "309000",
    "end": "350000"
  },
  {
    "text": "and once you're happy with the performance the accuracy of the model then you can deploy okay and again it's",
    "start": "309080",
    "end": "315620"
  },
  {
    "text": "really one line of code thing there's a deploy API that deploys your model to a",
    "start": "315620",
    "end": "321620"
  },
  {
    "text": "fleet of web servers that are fully managed by a sage maker you can",
    "start": "321620",
    "end": "326900"
  },
  {
    "text": "implement auto scaling if you like and and those web servers will serve HTTP",
    "start": "326900",
    "end": "333160"
  },
  {
    "text": "predictions to your apps you can also do badge transform if you have no need for",
    "start": "333160",
    "end": "338350"
  },
  {
    "text": "HTTP based prediction so you can transform in batch mode your data set",
    "start": "338350",
    "end": "344000"
  },
  {
    "text": "and get your result back in s3 okay so different ways of predicting so sage",
    "start": "344000",
    "end": "350960"
  },
  {
    "start": "350000",
    "end": "413000"
  },
  {
    "text": "maker like I said what's really is last year it is it is really popular so it really seems to solve the pain points",
    "start": "350960",
    "end": "358340"
  },
  {
    "text": "that the customers asked us to solve making machine learning agile making",
    "start": "358340",
    "end": "363410"
  },
  {
    "text": "machine learning free of infrastructure problems and then we have lots of customers and it's an interesting mix of",
    "start": "363410",
    "end": "369980"
  },
  {
    "text": "I would say a large enterprise like GE do Jones into it etc and and and big web",
    "start": "369980",
    "end": "379730"
  },
  {
    "text": "startups and small ones stuff small wants to write so people who have either tons of enterprise data or people who",
    "start": "379730",
    "end": "386360"
  },
  {
    "text": "have tons of you know web and mobile data and they want to run all kinds of",
    "start": "386360",
    "end": "391880"
  },
  {
    "text": "machine learning models okay so if you're interested in those you can just you can go to the sage maker service",
    "start": "391880",
    "end": "397520"
  },
  {
    "text": "page and you we'll find lots of information on your suitcases but it's really you know it's",
    "start": "397520",
    "end": "403370"
  },
  {
    "text": "really for everybody it's not just for the big machine running experts or for the for the super crazy startups out",
    "start": "403370",
    "end": "409760"
  },
  {
    "text": "there you know everybody seems to find something that they like in here so let's talk about tensorflow now so as",
    "start": "409760",
    "end": "417410"
  },
  {
    "start": "413000",
    "end": "551000"
  },
  {
    "text": "you probably know it's a probably the the most popular deep learning library",
    "start": "417410",
    "end": "423860"
  },
  {
    "text": "out there it's open source the main API is Python and that's what I",
    "start": "423860",
    "end": "428990"
  },
  {
    "text": "will use today and you have some kind of support for other languages the nice",
    "start": "428990",
    "end": "435050"
  },
  {
    "text": "thing about tensorflow is that it has built-in support for all kinds of neural",
    "start": "435050",
    "end": "440720"
  },
  {
    "text": "network architectures so whether you're trying to build fully connected layer networks convolutional neural networks",
    "start": "440720",
    "end": "446960"
  },
  {
    "text": "or LST n networks or other kinds of networks you have some high-level API to",
    "start": "446960",
    "end": "452780"
  },
  {
    "text": "do that pretty pretty easily initially tensorflow use symbolic execution so",
    "start": "452780",
    "end": "458210"
  },
  {
    "text": "symbolic execution works in two steps you first define the model okay so you",
    "start": "458210",
    "end": "464420"
  },
  {
    "text": "define the the execution graph so to speak then it's frozen and then you train okay so it's a symbolic execution",
    "start": "464420",
    "end": "472190"
  },
  {
    "text": "is fast because since the graph is fully defined at training time you can apply all kinds of optimizations the downsides",
    "start": "472190",
    "end": "479780"
  },
  {
    "text": "to the downside to this is the graph is frozen and it cannot be changed during",
    "start": "479780",
    "end": "485690"
  },
  {
    "text": "execution so for advanced use cases where you would like to actually modify the network during training make it",
    "start": "485690",
    "end": "492080"
  },
  {
    "text": "deeper make it wider that kind of thing well you can't do that so tensorflow has added another way of working of training",
    "start": "492080",
    "end": "500630"
  },
  {
    "text": "with models called imperative execution where this time we don't have that two-phase process where we define a",
    "start": "500630",
    "end": "508010"
  },
  {
    "text": "network and then train it's actually all mixed so imperative code is what we write everyday when we use you know",
    "start": "508010",
    "end": "513800"
  },
  {
    "text": "Python Java C++ so we really define and train and we can modify the network",
    "start": "513800",
    "end": "520760"
  },
  {
    "text": "during execution okay tensorflow calls this eager execution okay",
    "start": "520760",
    "end": "527200"
  },
  {
    "text": "maybe one of the more popular features in terms of flow is the the Kaos API so",
    "start": "527200",
    "end": "532510"
  },
  {
    "text": "Kerris is a high-level Python API on top of tensorflow and it makes very very easy and really",
    "start": "532510",
    "end": "538959"
  },
  {
    "text": "fast to build models it has very I would say user-friendly API so that's great",
    "start": "538959",
    "end": "545019"
  },
  {
    "text": "documentation it has a lot of examples a lot of community support and it's a really it's really a popular choice so",
    "start": "545019",
    "end": "551709"
  },
  {
    "start": "551000",
    "end": "687000"
  },
  {
    "text": "let's look at a simple basic example you know in case you've never really tried to answer flow before that's what it",
    "start": "551709",
    "end": "559060"
  },
  {
    "text": "will like so here I'm using a toy data set close em call em nest which is as you can see a collection of digits and",
    "start": "559060",
    "end": "565360"
  },
  {
    "text": "the name of the game is to classify the digits in those 10 categories ok so this",
    "start": "565360",
    "end": "572290"
  },
  {
    "text": "is the full code I mean nothing's missing you could copy-paste this to your laptop and it would work so importance of flow",
    "start": "572290",
    "end": "579010"
  },
  {
    "text": "grab the EM nice data set from from carousel from tensorflow api's just",
    "start": "579010",
    "end": "587290"
  },
  {
    "text": "normalize the the pixel values who are normally between 0 and 255 so bring them",
    "start": "587290",
    "end": "593290"
  },
  {
    "text": "back to the 0 1 range okay that's that's good practice and then define a simple",
    "start": "593290",
    "end": "598510"
  },
  {
    "text": "fully connected Network where we start by flattening the image into a vector okay because fully connected networks",
    "start": "598510",
    "end": "605199"
  },
  {
    "text": "have flat input layers and then I have a first hidden layer with 512 neurons",
    "start": "605199",
    "end": "611410"
  },
  {
    "text": "activated by the real function then I apply dropout which is a way to combat overfitting and to slow down training",
    "start": "611410",
    "end": "620050"
  },
  {
    "text": "and to avoid learning too well and then an output layer with ten neurons because",
    "start": "620050",
    "end": "625690"
  },
  {
    "text": "I've got ten classes and this one is activated by the softmax function because I want those values to look like",
    "start": "625690",
    "end": "631600"
  },
  {
    "text": "probabilities so all those ten values should add up to ten for a given a given",
    "start": "631600",
    "end": "636730"
  },
  {
    "text": "picture and then I compile the model I used the atom optimizer which doesn't",
    "start": "636730",
    "end": "642010"
  },
  {
    "text": "require a learning rate it figures that the learning rate automatically I define a loss function here I want to build a",
    "start": "642010",
    "end": "648279"
  },
  {
    "text": "multi class classifier so I used that sparse categorical cross entropy function and the training metric here",
    "start": "648279",
    "end": "655390"
  },
  {
    "text": "should be accuracy okay and then I just trained for five epochs why not",
    "start": "655390",
    "end": "660490"
  },
  {
    "text": "I scored the model against the test set okay and that's all it takes okay and this gets to this is really",
    "start": "660490",
    "end": "666550"
  },
  {
    "text": "basic but this gets to decent accuracy okay so as you can see it's not about writing tons of code deep learning",
    "start": "666550",
    "end": "673839"
  },
  {
    "text": "generally doesn't need tons of code it needs a data set and it needs the right",
    "start": "673839",
    "end": "679990"
  },
  {
    "text": "structure for the model which is really the tricky thing to figure out but the API itself the code itself is generally",
    "start": "679990",
    "end": "686050"
  },
  {
    "text": "not a problem as it happens there's a lot of tensorflow running on AWS so this",
    "start": "686050",
    "end": "694000"
  },
  {
    "start": "687000",
    "end": "737000"
  },
  {
    "text": "is a report from from last year quite a quite a bit of a tensor flow workloads",
    "start": "694000",
    "end": "699370"
  },
  {
    "text": "and Andy mentioned it again in in the keynote this morning so it'll be less is really the preferred way to run tensor",
    "start": "699370",
    "end": "706360"
  },
  {
    "text": "flow tensor flow applications and pretty happy with that and well and",
    "start": "706360",
    "end": "712000"
  },
  {
    "text": "surprisingly we have lots of customers who are also running tensorflow on AWS so some of them are also to Sage maker",
    "start": "712000",
    "end": "718540"
  },
  {
    "text": "customers you'll find some of the names I mentioned before some other companies don't use sage maker there use ec2",
    "start": "718540",
    "end": "726430"
  },
  {
    "text": "instances to run tends to flow directly maybe they use the the c5 instances or the p3 instances and with the GPUs etc",
    "start": "726430",
    "end": "733440"
  },
  {
    "text": "but again we find all kinds of companies here I want to give you just a quick example so this is a company from",
    "start": "733440",
    "end": "740310"
  },
  {
    "start": "737000",
    "end": "803000"
  },
  {
    "text": "Colorado called matrix analytics and they use chance to flow to build image",
    "start": "740310",
    "end": "746320"
  },
  {
    "text": "recognition computer vision models so to speak on medical imaging and the try to",
    "start": "746320",
    "end": "751990"
  },
  {
    "text": "do cancer detection and they they actually do this extremely quickly and",
    "start": "751990",
    "end": "757709"
  },
  {
    "text": "with a much better accuracy than any other kind of to louder and well that",
    "start": "757709",
    "end": "764440"
  },
  {
    "text": "makes a difference for a lot of people obviously and this is all based on",
    "start": "764440",
    "end": "769470"
  },
  {
    "text": "tensor flow they don't use sage maker they use ec2 instances directly and they",
    "start": "769470",
    "end": "774970"
  },
  {
    "text": "actually use the deeper learning ami which you may have heard about the deep learning emma is the collection of deep",
    "start": "774970",
    "end": "781420"
  },
  {
    "text": "learning libraries and and and tools and drivers and VDI drivers etc completely",
    "start": "781420",
    "end": "787839"
  },
  {
    "text": "packaged completely pre-installed so that again you don't have to wait you don't have to deal with that you can",
    "start": "787839",
    "end": "793150"
  },
  {
    "text": "just focus on your machine learning tasks okay and we have lots of customers doing",
    "start": "793150",
    "end": "798330"
  },
  {
    "text": "that kind of thing very very advanced seniors like this one so what about",
    "start": "798330",
    "end": "804060"
  },
  {
    "start": "803000",
    "end": "814000"
  },
  {
    "text": "putting the two together now so okay Sara maker is kind of interesting tensorflow is kind of interesting you",
    "start": "804060",
    "end": "810540"
  },
  {
    "text": "know if you mix those two together then what happens so the first thing that you",
    "start": "810540",
    "end": "816150"
  },
  {
    "text": "should know is actually tensorflow is really a first-class citizen on sage maker which you know is it makes sense",
    "start": "816150",
    "end": "822480"
  },
  {
    "text": "because it is the most popular library out there so we provide deep lore we provide built in containers for for",
    "start": "822480",
    "end": "830400"
  },
  {
    "text": "training and prediction those containers are actually open source so you can go",
    "start": "830400",
    "end": "836550"
  },
  {
    "text": "and grab them from github you can you can compile them on your own machine run them on your own machine to make sure",
    "start": "836550",
    "end": "843150"
  },
  {
    "text": "your local dev environment behaves exactly the same as the sage maker will you can customize them if you need to",
    "start": "843150",
    "end": "849210"
  },
  {
    "text": "add extra dependencies your own homemade libraries and whatnot just do that",
    "start": "849210",
    "end": "855540"
  },
  {
    "text": "grab the containers build them modify them push them back to to ECR",
    "start": "855540",
    "end": "861900"
  },
  {
    "text": "our darker repository service and you can use them on sage maker",
    "start": "861900",
    "end": "868080"
  },
  {
    "text": "okay so plenty of flexibility here we support a bunch of versions so this is the slide that is always out of date",
    "start": "868080",
    "end": "875750"
  },
  {
    "text": "right so we'll keep following all the versions and we also we also add extra",
    "start": "875750",
    "end": "883560"
  },
  {
    "text": "functionality here so actually the tensorflow versions that run on Sage",
    "start": "883560",
    "end": "889650"
  },
  {
    "text": "Maker are optimized for CPU and GPU it's not just a vanilla version that you",
    "start": "889650",
    "end": "895410"
  },
  {
    "text": "could as the one you could find out there we actually spend a lot of time and effort optimising them I'll show you",
    "start": "895410",
    "end": "901020"
  },
  {
    "text": "an example in a minute we have distributed training out of the box okay and if you've tried to setup",
    "start": "901020",
    "end": "908190"
  },
  {
    "text": "distributed training in terms of from manually it's a bit of work it's a bit of work for any library you have to say",
    "start": "908190",
    "end": "914100"
  },
  {
    "text": "not specifically tensorflow and here as you will see it's as simple as saying hey please give me two",
    "start": "914100",
    "end": "920190"
  },
  {
    "text": "instances or three or five of 20 we have a thing called pipe mode I'll come back to that where we can stream infinitely",
    "start": "920190",
    "end": "927100"
  },
  {
    "text": "large data sets two instances and improve training performance you can use tensor board for visualization you can",
    "start": "927100",
    "end": "933820"
  },
  {
    "text": "use chaos and you can use automatic model tuning and we're gonna cover all those things okay we're going to dive",
    "start": "933820",
    "end": "939370"
  },
  {
    "text": "deeper this is a 400 level session or maybe a 500 level session today and so",
    "start": "939370",
    "end": "944650"
  },
  {
    "text": "we're gonna dive deeper on all those things before we do here's the out to",
    "start": "944650",
    "end": "950890"
  },
  {
    "start": "947000",
    "end": "1072000"
  },
  {
    "text": "the basic example right how do you train a tensor flow script on stage maker so",
    "start": "950890",
    "end": "958060"
  },
  {
    "text": "sage maker works with a Python SDK so sage Maker SDK and this is the the SDK",
    "start": "958060",
    "end": "965890"
  },
  {
    "text": "that gets everything going on sage maker training projection etc and what I like about it it's quite high level so we",
    "start": "965890",
    "end": "972940"
  },
  {
    "text": "provide high level objects like this tensorflow object that you see here so",
    "start": "972940",
    "end": "977980"
  },
  {
    "text": "all you have to do really is create that tensorflow object from the sage maker sdk pass the script",
    "start": "977980",
    "end": "984940"
  },
  {
    "text": "write your python script which could either be point python to Python 3 now",
    "start": "984940",
    "end": "990000"
  },
  {
    "text": "pass it to that chance of flow object pass a role because obviously sage maker",
    "start": "990000",
    "end": "995050"
  },
  {
    "text": "needs to access s3 where your data lives etc define the number of steps define",
    "start": "995050",
    "end": "1001560"
  },
  {
    "text": "how much infrastructure you need ok and that's really all it takes this is as much infrastructure as you will have to",
    "start": "1001560",
    "end": "1007020"
  },
  {
    "text": "to deal with when you work with sage maker if you want one p3 to XL instance",
    "start": "1007020",
    "end": "1012390"
  },
  {
    "text": "with a with a GPU that's that's all you do right if you need a hundred just replace one with a 100 and that's all it",
    "start": "1012390",
    "end": "1019350"
  },
  {
    "text": "takes okay so you you'll never mess with the training server again right which which",
    "start": "1019350",
    "end": "1025170"
  },
  {
    "text": "is good news I guess and then pointing you're the that estimator object that tensorflow object adds your date is",
    "start": "1025170",
    "end": "1032010"
  },
  {
    "text": "three you can train ok and this is strictly all there is to it okay bring",
    "start": "1032010",
    "end": "1037829"
  },
  {
    "text": "your tensorflow script which needs to implement obviously so some standard",
    "start": "1037830",
    "end": "1042900"
  },
  {
    "text": "functions but this is really the standard tensorflow way so unless you you know unless you didn't follow the",
    "start": "1042900",
    "end": "1049050"
  },
  {
    "text": "tensorflow conventions chances are your script already implements the model FN function and the Train",
    "start": "1049050",
    "end": "1054510"
  },
  {
    "text": "input function etc etc so really you can take that script it's really lifts and shifts for tensorflow right take that",
    "start": "1054510",
    "end": "1061800"
  },
  {
    "text": "script pass it to that tensorflow object and train okay no modifications required",
    "start": "1061800",
    "end": "1066900"
  },
  {
    "text": "no infrastructure work required okay great news so I mentioned optimization",
    "start": "1066900",
    "end": "1075240"
  },
  {
    "start": "1072000",
    "end": "1152000"
  },
  {
    "text": "right so let's look at this first example so this goes back to beginning of the year but I'm still very relevant",
    "start": "1075240",
    "end": "1081690"
  },
  {
    "text": "so here we're training multiple computer classic computer vision models so image",
    "start": "1081690",
    "end": "1089010"
  },
  {
    "text": "classification models on with tensorflow okay so ResNet fifty-year ResNet 152 etc",
    "start": "1089010",
    "end": "1095880"
  },
  {
    "text": "etc and we try two different configurations so the the blue bar is",
    "start": "1095880",
    "end": "1100980"
  },
  {
    "text": "done the vanilla tensorflow binary right is what you get if you just grab the",
    "start": "1100980",
    "end": "1107460"
  },
  {
    "text": "vanilla terms of flow package out there okay and we get those results okay if we",
    "start": "1107460",
    "end": "1113850"
  },
  {
    "text": "take the tensor flow version that has been optimized and it's available in the deep running ami and it's aged maker you",
    "start": "1113850",
    "end": "1121380"
  },
  {
    "text": "get the orange bars okay so the bottom line is you get 5 to 7 X speed-up okay",
    "start": "1121380",
    "end": "1130710"
  },
  {
    "text": "and this is really significant because it means if you had a large model that you were training for seven hours now",
    "start": "1130710",
    "end": "1136530"
  },
  {
    "text": "you can be down to one hour which means that in a workday you could be training many more models you could be optimizing",
    "start": "1136530",
    "end": "1143640"
  },
  {
    "text": "and trying different configurations and and getting to the best model faster",
    "start": "1143640",
    "end": "1149400"
  },
  {
    "text": "okay so this is really really significant this is a more recent",
    "start": "1149400",
    "end": "1154710"
  },
  {
    "text": "example where we trained a resonate 50 model so again one of those image",
    "start": "1154710",
    "end": "1161580"
  },
  {
    "text": "classification models on the optimized build for tensorflow 111 so the latest",
    "start": "1161580",
    "end": "1167760"
  },
  {
    "text": "version and we used a c 518 excel instance so this is the cpu based",
    "start": "1167760",
    "end": "1174420"
  },
  {
    "text": "instance one of the bigger ones and these times were 11 times faster ok so",
    "start": "1174420",
    "end": "1180540"
  },
  {
    "text": "we keep optimizing we keep improving how terms of flow runs on our ec2 instance",
    "start": "1180540",
    "end": "1187920"
  },
  {
    "text": "okay so those speed ups are super significant okay super significant if you train eleven times faster then maybe",
    "start": "1187920",
    "end": "1194790"
  },
  {
    "text": "you don't need to train on a GPU right maybe maybe it's fast enough to train on",
    "start": "1194790",
    "end": "1199800"
  },
  {
    "text": "that large c5 instance okay so it's fast and it's probably a little more cost",
    "start": "1199800",
    "end": "1206160"
  },
  {
    "text": "effective than the large GPU instance okay so you get to pick what your cost performance ratio should be the next",
    "start": "1206160",
    "end": "1216330"
  },
  {
    "start": "1213000",
    "end": "1257000"
  },
  {
    "text": "thing you could try actually is not train on an ec2 instance at all you can use you can use local mode which",
    "start": "1216330",
    "end": "1224960"
  },
  {
    "text": "basically will train on the notebook instance itself okay so the notebook instance itself is fully managed but",
    "start": "1224960",
    "end": "1232410"
  },
  {
    "text": "maybe you're experimenting maybe you want to go fast maybe you want to iterate fast enough and you don't want",
    "start": "1232410",
    "end": "1238080"
  },
  {
    "text": "to fire up training clusters so you can use local mode and just obviously save",
    "start": "1238080",
    "end": "1243150"
  },
  {
    "text": "time and money by not firing up the training instances and all it takes is",
    "start": "1243150",
    "end": "1248430"
  },
  {
    "text": "to use that special instance type called local okay and you can train on your notebook instance okay very very useful",
    "start": "1248430",
    "end": "1255420"
  },
  {
    "text": "for experimentation if you want to do distributed training okay",
    "start": "1255420",
    "end": "1260580"
  },
  {
    "start": "1257000",
    "end": "1288000"
  },
  {
    "text": "like I said the only change is to pass the right value to that training",
    "start": "1260580",
    "end": "1266310"
  },
  {
    "text": "instance count parameter and that's all there is to it right two four nine two",
    "start": "1266310",
    "end": "1271860"
  },
  {
    "text": "hundred instances that's all it takes okay that's all it takes so you can set",
    "start": "1271860",
    "end": "1277440"
  },
  {
    "text": "it up super easily right no no fuss this is much much simpler than having to set this stuff manually",
    "start": "1277440",
    "end": "1284490"
  },
  {
    "text": "you should try it once you'll know what I mean then what if you have infinitely",
    "start": "1284490",
    "end": "1292650"
  },
  {
    "text": "large data sets and well that's a weird way to put it okay so let me explain the",
    "start": "1292650",
    "end": "1300840"
  },
  {
    "text": "the default way for Sage Maker to to train on your data is to copy the data",
    "start": "1300840",
    "end": "1308730"
  },
  {
    "text": "to the training instances okay so if you have small and medium sized data sets I",
    "start": "1308730",
    "end": "1314790"
  },
  {
    "text": "guess that's okay you have enough storage on the training instances it doesn't take much time to copy that",
    "start": "1314790",
    "end": "1320940"
  },
  {
    "text": "from s32 to the instances so why not okay so it could be fully replicated and",
    "start": "1320940",
    "end": "1326550"
  },
  {
    "text": "could be shorted but okay there is the copy involved now imagine you have",
    "start": "1326550",
    "end": "1331650"
  },
  {
    "text": "datasets and you know tens of terabytes hundreds of terabytes maybe more and if",
    "start": "1331650",
    "end": "1337320"
  },
  {
    "text": "you're working with huge speech or video datasets you know that's gonna happen so",
    "start": "1337320",
    "end": "1342660"
  },
  {
    "text": "of course you'll never have enough space and and the time that you would take to",
    "start": "1342660",
    "end": "1347670"
  },
  {
    "text": "copy to the instances would just be silly so to solve that problem we came up with pipe mode and pipe mode is a way",
    "start": "1347670",
    "end": "1354780"
  },
  {
    "text": "for you to stream the data set to the instances so the two benefits are obviously you're not copying anything so",
    "start": "1354780",
    "end": "1363150"
  },
  {
    "text": "training starts faster ok the second there your training instance is up you",
    "start": "1363150",
    "end": "1369510"
  },
  {
    "text": "know it starts receiving data so it doesn't have to copy stuff and there is",
    "start": "1369510",
    "end": "1374610"
  },
  {
    "text": "really no limit to the size of the data set that you can use because again it is streaming so it doesn't really matter",
    "start": "1374610",
    "end": "1380429"
  },
  {
    "text": "how much storage you have it doesn't really matter how much memory you have in that instance it will receive batches",
    "start": "1380429",
    "end": "1385740"
  },
  {
    "text": "of data and it will just process them one after the other and if it needs to go this way for two petabytes then so be",
    "start": "1385740",
    "end": "1393840"
  },
  {
    "text": "it right how complicated is it to set it up well not not much input mode instead of",
    "start": "1393840",
    "end": "1400890"
  },
  {
    "text": "file which is the default mode should now be pipe ok and tensorflow supports",
    "start": "1400890",
    "end": "1407100"
  },
  {
    "text": "this out of the box ok so if you have large data sets no",
    "start": "1407100",
    "end": "1412800"
  },
  {
    "text": "worries ok if you're working with a TF record",
    "start": "1412800",
    "end": "1419400"
  },
  {
    "start": "1415000",
    "end": "1524000"
  },
  {
    "text": "files this is how what you would do so again let me explain imagine you have a data set with ten",
    "start": "1419400",
    "end": "1428520"
  },
  {
    "text": "million images ok and you want to train on that 10 million it would be 10 million files okay so it's not practical",
    "start": "1428520",
    "end": "1435990"
  },
  {
    "text": "to live with 10 million files it's not practical to load them it's not practical to copy them you know",
    "start": "1435990",
    "end": "1441600"
  },
  {
    "text": "everybody hates having 10 million files so what you usually do is you you use the TF record file format which",
    "start": "1441600",
    "end": "1449760"
  },
  {
    "text": "PACS the different sample of the different images into into our files",
    "start": "1449760",
    "end": "1456390"
  },
  {
    "text": "that have a record structure and the benefit here is obviously you have fewer files could see possibly one single file",
    "start": "1456390",
    "end": "1462900"
  },
  {
    "text": "containing all the data set and since it has a record structure it's easy to split right which obviously is what you",
    "start": "1462900",
    "end": "1469860"
  },
  {
    "text": "want to do if you were gonna distribute it to and stream it to different",
    "start": "1469860",
    "end": "1474990"
  },
  {
    "text": "instances okay so this is what you would do you you need to work with this pipe",
    "start": "1474990",
    "end": "1482730"
  },
  {
    "text": "mode data set object from the from the stage maker SDK and the only change I",
    "start": "1482730",
    "end": "1491040"
  },
  {
    "text": "guess would be in the trained input function so the training put function is the function that provides access to the",
    "start": "1491040",
    "end": "1497580"
  },
  {
    "text": "training set for your script okay so instead here of just reading files locally from from the local file system",
    "start": "1497580",
    "end": "1504390"
  },
  {
    "text": "as you would do if the data set had been copied locally you just iterate through",
    "start": "1504390",
    "end": "1510680"
  },
  {
    "text": "you just iterate through that through that data set you know fetching samples",
    "start": "1510680",
    "end": "1517350"
  },
  {
    "text": "batch by batch and returning them to the model for training okay so not a lot of",
    "start": "1517350",
    "end": "1522540"
  },
  {
    "text": "modifications here okay so we have different ways to train now we want to see what's going on while we train and",
    "start": "1522540",
    "end": "1529740"
  },
  {
    "start": "1524000",
    "end": "1603000"
  },
  {
    "text": "and there's a very nice tool called tense' board and tensor board is really",
    "start": "1529740",
    "end": "1534930"
  },
  {
    "text": "it's a visualization tool that lets you visualize training metrics and here are",
    "start": "1534930",
    "end": "1541830"
  },
  {
    "text": "some examples we see the training loss and these are the the x-axis is the",
    "start": "1541830",
    "end": "1548130"
  },
  {
    "text": "number of steps we see the training accuracy we see the learning rate if we",
    "start": "1548130",
    "end": "1553620"
  },
  {
    "text": "have learning rate scheduling happening over time so you get access to all those metrics you can also visualize the graph",
    "start": "1553620",
    "end": "1560760"
  },
  {
    "text": "so you can actually visualize the the tensor flow graph that has been built so the model itself so it's a cool tool",
    "start": "1560760",
    "end": "1566870"
  },
  {
    "text": "it's super easy to setup on the on sage maker as you can see all you need to do",
    "start": "1566870",
    "end": "1572580"
  },
  {
    "text": "is pass this parameter say hey please run 10 suppor locally and and then you",
    "start": "1572580",
    "end": "1578190"
  },
  {
    "text": "point your browser at port 6006 on your notebook instance",
    "start": "1578190",
    "end": "1583230"
  },
  {
    "text": "and voila as we say you you open Chancellor board and you can visualize",
    "start": "1583230",
    "end": "1588299"
  },
  {
    "text": "your metrics and the model and and understand if training is going is going well or",
    "start": "1588299",
    "end": "1593850"
  },
  {
    "text": "not okay super super nice there's another way to visualize training metrics and cloud watch now and I will",
    "start": "1593850",
    "end": "1600240"
  },
  {
    "text": "show it in my demo so okay we're happy with the model and now we want to deploy",
    "start": "1600240",
    "end": "1607950"
  },
  {
    "start": "1603000",
    "end": "1733000"
  },
  {
    "text": "it how complicated is that well not much is the answer again so you have two",
    "start": "1607950",
    "end": "1615240"
  },
  {
    "text": "scenarios here depending on whether you train the model on Sage maker or not",
    "start": "1615240",
    "end": "1621179"
  },
  {
    "text": "okay because like I said and sage maker is a collection of modules so it's totally okay if you train your model on",
    "start": "1621179",
    "end": "1628740"
  },
  {
    "text": "your laptop or on your on-premise server and you want to deploy it on Sage maker",
    "start": "1628740",
    "end": "1634320"
  },
  {
    "text": "okay so you don't have to do everything on say maker just pick the bits that solve your problems and use them so",
    "start": "1634320",
    "end": "1640950"
  },
  {
    "text": "assuming you trained on Sage maker okay so you would have used that tensorflow",
    "start": "1640950",
    "end": "1646380"
  },
  {
    "text": "object that estimator object like we've seen before trained it and then you",
    "start": "1646380",
    "end": "1652529"
  },
  {
    "text": "would just call the deploy API passing just a number of servers that the model",
    "start": "1652529",
    "end": "1657720"
  },
  {
    "text": "should be deployed on and there and the instance type okay and again if you need to deploy to 50 web servers just say 50",
    "start": "1657720",
    "end": "1665549"
  },
  {
    "text": "instead of one and that's about it okay you could you could have a slightly more elaborate configurations with auto",
    "start": "1665549",
    "end": "1670740"
  },
  {
    "text": "scaling and and multiple models per endpoint did you maybe Connery or green",
    "start": "1670740",
    "end": "1676529"
  },
  {
    "text": "blue deployments okay but it doesn't get much more complicated than this anyway if your model comes from outside okay",
    "start": "1676529",
    "end": "1684149"
  },
  {
    "text": "then again just copy to s3 use the",
    "start": "1684149",
    "end": "1690029"
  },
  {
    "text": "tensor flow model object to to load it and just call deploy exactly in the same",
    "start": "1690029",
    "end": "1696330"
  },
  {
    "text": "way so as you can see really the outsider the entry the entry cost to",
    "start": "1696330",
    "end": "1705450"
  },
  {
    "text": "Sage maker if you already have chance of low running is super low right you it's not like you're gonna need to rework",
    "start": "1705450",
    "end": "1711389"
  },
  {
    "text": "everything it's not like you need to throw away the code and rewrite you know chances are you don't need to",
    "start": "1711389",
    "end": "1718090"
  },
  {
    "text": "change anything in the script itself and just you're just gonna use a stage maker",
    "start": "1718090",
    "end": "1723129"
  },
  {
    "text": "SDK to orchestrate training and and tuning and deploying okay so it's very",
    "start": "1723129",
    "end": "1729669"
  },
  {
    "text": "very developer friendly if you ask me what about Karis so Karis as I've",
    "start": "1729669",
    "end": "1736450"
  },
  {
    "start": "1733000",
    "end": "1859000"
  },
  {
    "text": "mentioned is a really really popular API it actually supports multi multiple backends so initially chunks of flow",
    "start": "1736450",
    "end": "1743249"
  },
  {
    "text": "piano and now Apache MXN okay so it's actually an interesting thing to try as",
    "start": "1743249",
    "end": "1749229"
  },
  {
    "text": "a side note you just need to change one line in the config file for Karis to say",
    "start": "1749229",
    "end": "1754720"
  },
  {
    "text": "hey please now use MX net instead of Theano okay or of tensorflow and you can compare so actually the",
    "start": "1754720",
    "end": "1763960"
  },
  {
    "text": "Karis library so just becomes in two in",
    "start": "1763960",
    "end": "1768970"
  },
  {
    "text": "two flavors so tensorflow has native support for for some of the Karis API so",
    "start": "1768970",
    "end": "1776739"
  },
  {
    "text": "TF Chara's so you saw those layers in my analyst example before so the layers",
    "start": "1776739",
    "end": "1782950"
  },
  {
    "text": "themselves or are accessible in intensive flow but if you want to use",
    "start": "1782950",
    "end": "1789070"
  },
  {
    "text": "turns the Charis itself the Karis library itself we - which has extra features you know model zoo and all",
    "start": "1789070",
    "end": "1796389"
  },
  {
    "text": "kinds of very very useful api's then you have to build a custom container okay so",
    "start": "1796389",
    "end": "1801460"
  },
  {
    "text": "I'm hoping and I'm pushing for a native Kerris container but okay not there yet maybe it's gonna be announced tomorrow",
    "start": "1801460",
    "end": "1807849"
  },
  {
    "text": "and I don't know who knows but for now - the custom container and when I whenever",
    "start": "1807849",
    "end": "1813519"
  },
  {
    "text": "I said that people go oh no no no I don't know no I don't want to do that you know I don't want to build custom stuff and as you will see it is not",
    "start": "1813519",
    "end": "1821979"
  },
  {
    "text": "difficult at all right it's you know custom container sounds daunting but no it isn't as you will see the darker file",
    "start": "1821979",
    "end": "1829119"
  },
  {
    "text": "is super short so you need to write that docker file or reuse my builder container push it to Amazon ECR and just",
    "start": "1829119",
    "end": "1836769"
  },
  {
    "text": "train and deploy exactly in the same way okay so if you want to see that full thing",
    "start": "1836769",
    "end": "1842349"
  },
  {
    "text": "end-to-end I have an online video showing you that where I really go through each and every",
    "start": "1842349",
    "end": "1849440"
  },
  {
    "text": "step in detail I will go a little bit faster during my demo but okay you can go back to that video if you need all",
    "start": "1849440",
    "end": "1856760"
  },
  {
    "text": "the steps okay and one of the actually the last thing I want to talk to you",
    "start": "1856760",
    "end": "1862760"
  },
  {
    "start": "1859000",
    "end": "1920000"
  },
  {
    "text": "about I want to talk about before diving into the demo is of course D plans D",
    "start": "1862760",
    "end": "1869450"
  },
  {
    "text": "plans was launched last year and reinvent and initially it supported an",
    "start": "1869450",
    "end": "1875600"
  },
  {
    "text": "extant models but pretty quickly we added tensorflow support so you could train a tensorflow model in sage maker",
    "start": "1875600",
    "end": "1883610"
  },
  {
    "text": "let's say or you could use the pre-trained model and you can very",
    "start": "1883610",
    "end": "1888769"
  },
  {
    "text": "easily deploy that computer-vision model to D plans and build all kinds of funny things okay so you can grab any",
    "start": "1888769",
    "end": "1896919"
  },
  {
    "text": "architecture listed here ResNet or vgg or anything take a pre trend model or",
    "start": "1896919",
    "end": "1903620"
  },
  {
    "text": "fine-tune your model on stage maker and use green grass to deploy the model and",
    "start": "1903620",
    "end": "1908960"
  },
  {
    "text": "the lambda function running inference on the camera and it's it's it's pretty",
    "start": "1908960",
    "end": "1914779"
  },
  {
    "text": "easy right and you can do all kinds of funny things with T plans now you're you're all familiar with it okay so now",
    "start": "1914779",
    "end": "1921289"
  },
  {
    "start": "1920000",
    "end": "2032000"
  },
  {
    "text": "it's time to go into the demo so we're gonna do lots of things here so it's",
    "start": "1921289",
    "end": "1926870"
  },
  {
    "text": "good that I have plenty more time and I want to show you a mix of things so I",
    "start": "1926870",
    "end": "1932750"
  },
  {
    "text": "want to show you obviously how to train Kara's onstage maker okay so building a custom container how",
    "start": "1932750",
    "end": "1939590"
  },
  {
    "text": "do we pass hyper parameters from Sage maker to care us how do we get training",
    "start": "1939590",
    "end": "1946669"
  },
  {
    "text": "metrics in cloud watch but I want to show you maybe some cool chaos things as well like how do you set up image",
    "start": "1946669",
    "end": "1953539"
  },
  {
    "text": "segmentation to make the model even more accurate how do you define callbacks for",
    "start": "1953539",
    "end": "1959360"
  },
  {
    "text": "early stopping so avoiding training too long you know if your training doesn't",
    "start": "1959360",
    "end": "1964490"
  },
  {
    "text": "improve anymore there's no point going on so you want to stop and check pointing which saves the model after",
    "start": "1964490",
    "end": "1969950"
  },
  {
    "text": "each epoch so that once you have stopped training you can figure out which one is",
    "start": "1969950",
    "end": "1975590"
  },
  {
    "text": "the most accurate one and go grab that model okay so we're going to do that first and then we're going to",
    "start": "1975590",
    "end": "1981250"
  },
  {
    "text": "focus on optimizing that script okay so using automatic model tuning to run",
    "start": "1981250",
    "end": "1988350"
  },
  {
    "text": "optimization on a bunch of hyper parameters and I went pretty wild on on that one as you will see we're going to",
    "start": "1988350",
    "end": "1996039"
  },
  {
    "text": "define a custom a custom metric as well too to report how well we're doing on",
    "start": "1996039",
    "end": "2004710"
  },
  {
    "text": "that tuning we have a custom callback and I'm gonna show you how to plot results okay so plenty plenty of",
    "start": "2004710",
    "end": "2011309"
  },
  {
    "text": "different things in here so let me switch to the other machine",
    "start": "2011309",
    "end": "2017000"
  },
  {
    "text": "oh okay did we switch can you see that yeah okay",
    "start": "2031049",
    "end": "2040210"
  },
  {
    "start": "2032000",
    "end": "2097000"
  },
  {
    "text": "that worked alright so maybe a little bit of context first so what we're going",
    "start": "2040210",
    "end": "2047600"
  },
  {
    "text": "to do here we're going to build a simple convolutional neural network and we're",
    "start": "2047600",
    "end": "2052850"
  },
  {
    "text": "going to try to learn a data set so I'm not going to use em missed to the relief",
    "start": "2052850",
    "end": "2057950"
  },
  {
    "text": "of everyone who is getting really really tired of em list I'm going to use actually another dataset called fashion",
    "start": "2057950",
    "end": "2064580"
  },
  {
    "text": "M lists and fashion M nest is is a drop-in replacement for an list so it",
    "start": "2064580",
    "end": "2070610"
  },
  {
    "text": "has ten categories images of the same size etc etc and it was put two big",
    "start": "2070610",
    "end": "2078230"
  },
  {
    "text": "together by a company called Zalando right so and the categories as you can",
    "start": "2078230",
    "end": "2083480"
  },
  {
    "text": "see here are you know clothes and shoes etc and it is it it is a pretty challenging dataset unlike M list okay",
    "start": "2083480",
    "end": "2091179"
  },
  {
    "text": "so these are some of the samples that we're gonna try and classify okay so",
    "start": "2091180",
    "end": "2098680"
  },
  {
    "start": "2097000",
    "end": "2275000"
  },
  {
    "text": "let's get started so first of all obviously I need to import the sage",
    "start": "2098680",
    "end": "2103700"
  },
  {
    "text": "maker SDK and hopefully everybody can read this yeah it's all good all right",
    "start": "2103700",
    "end": "2109700"
  },
  {
    "text": "okay let me know if I need to zoom in a bit so I'm going to import the SDK I'm",
    "start": "2109700",
    "end": "2116150"
  },
  {
    "text": "gonna grab the role I'm gonna grab my account number and a few more things the region name I'm gonna need all that",
    "start": "2116150",
    "end": "2122330"
  },
  {
    "text": "stuff later on when I want to push my darker image to the to ECR okay so",
    "start": "2122330",
    "end": "2130490"
  },
  {
    "text": "here's the part that's supposedly so scary and I'm you're gonna see it's not scary at all even if you don't know",
    "start": "2130490",
    "end": "2136730"
  },
  {
    "text": "docker and you're gonna figure it out in no time okay so I'm gonna create a file called docker file or GPU because I want to",
    "start": "2136730",
    "end": "2143870"
  },
  {
    "text": "enable GPU support and this is what that file looks like that's the that's the",
    "start": "2143870",
    "end": "2151550"
  },
  {
    "text": "scary thing how many lines is that and you can count it can't be more than 12",
    "start": "2151550",
    "end": "2157580"
  },
  {
    "text": "or 15 lines this is all it takes so building the custom container for stage maker is not more complicated than",
    "start": "2157580",
    "end": "2163670"
  },
  {
    "text": "this so what do we do here we start from an existing image from a",
    "start": "2163670",
    "end": "2168859"
  },
  {
    "text": "Vidia with that embeds already all the Nvidia drivers all the CUDA programming",
    "start": "2168859",
    "end": "2173960"
  },
  {
    "text": "environment okay that is rather difficult to install manually I have to say so it's very good that we can we can",
    "start": "2173960",
    "end": "2181789"
  },
  {
    "text": "reuse that Nvidia image then and it is an Ubuntu based image okay so I'm",
    "start": "2181789",
    "end": "2187880"
  },
  {
    "text": "running a bit eager to update packages make sure I've got the latest python",
    "start": "2187880",
    "end": "2193569"
  },
  {
    "text": "install a version of tensorflow that supports cuda okay",
    "start": "2193569",
    "end": "2199029"
  },
  {
    "text": "install Kara's flee in a little bit and then I just copy my script which I'll",
    "start": "2199029",
    "end": "2206119"
  },
  {
    "text": "show you in a minute okay called M amnesty dot CNN and this underscore CNN",
    "start": "2206119",
    "end": "2211789"
  },
  {
    "text": "dot Phi copy that inside the container and it should be well actually it must be called /opt",
    "start": "2211789",
    "end": "2218420"
  },
  {
    "text": "slash program train okay that's the entry point if you don't use that name that stage maker doesn't know what to",
    "start": "2218420",
    "end": "2223910"
  },
  {
    "text": "invoke okay so I'm copying it with the right name with the right permissions",
    "start": "2223910",
    "end": "2229059"
  },
  {
    "text": "set some path and and environment variables done okay so no one should be",
    "start": "2229059",
    "end": "2238069"
  },
  {
    "text": "scared of building their own container if you want to build if you use are",
    "start": "2238069",
    "end": "2243140"
  },
  {
    "text": "anyone using are all right well okay if you need to build a container to run our",
    "start": "2243140",
    "end": "2248509"
  },
  {
    "text": "script on sage maker it's gonna be the same right so nothing's nothing scary I think we even provide an example on",
    "start": "2248509",
    "end": "2254779"
  },
  {
    "text": "Ganga tub if you have your super fancy custom secret C++ library for training",
    "start": "2254779",
    "end": "2260809"
  },
  {
    "text": "our prediction okay well just build a container and running on sage maker as well okay any kind of machine learning",
    "start": "2260809",
    "end": "2267680"
  },
  {
    "text": "workload can run so don't let that custom thing stop you because it's really you know it's not scary at all",
    "start": "2267680",
    "end": "2274160"
  },
  {
    "text": "okay so we will look at the script in a minute I just want to show you all the",
    "start": "2274160",
    "end": "2279980"
  },
  {
    "start": "2275000",
    "end": "2376000"
  },
  {
    "text": "way get to the point where we've built a container so I need to make sure I've",
    "start": "2279980",
    "end": "2285529"
  },
  {
    "text": "got a repository in ECR okay for for the image that I'm gonna build so define a",
    "start": "2285529",
    "end": "2292730"
  },
  {
    "text": "repository name an image name use the AWS CLI to create a repo if I don't have",
    "start": "2292730",
    "end": "2298549"
  },
  {
    "text": "one already okay login to that repo build my image okay",
    "start": "2298549",
    "end": "2306049"
  },
  {
    "text": "so I'm using darker build so now I'm back in standard darker territory okay",
    "start": "2306049",
    "end": "2312219"
  },
  {
    "text": "so in nature stuff time I've done that it takes a couple of minutes but I didn't want to waste them so after a few",
    "start": "2312219",
    "end": "2319400"
  },
  {
    "text": "minutes we have our local darker image on the notebook instance we tagged it",
    "start": "2319400",
    "end": "2324890"
  },
  {
    "text": "okay we can see it here and then I push it to ECR again using docker brush",
    "start": "2324890",
    "end": "2330679"
  },
  {
    "text": "standard doctor stuff okay and then then",
    "start": "2330679",
    "end": "2336019"
  },
  {
    "text": "I'm done okay and then I'm Kay I can use this container just like I would use the vanilla tensorflow container or any",
    "start": "2336019",
    "end": "2341959"
  },
  {
    "text": "other container okay and the last step is I want to upload my dataset to s3",
    "start": "2341959",
    "end": "2348769"
  },
  {
    "text": "because this is where sage maker will pick it up for training alright so let's",
    "start": "2348769",
    "end": "2354319"
  },
  {
    "text": "look at let's look at that script that M",
    "start": "2354319",
    "end": "2362089"
  },
  {
    "text": "this script and all of this is on github so you don't worry you will you can you",
    "start": "2362089",
    "end": "2370249"
  },
  {
    "text": "can use it alright I'll share it okay so here it is so it's a very it's a simple",
    "start": "2370249",
    "end": "2378289"
  },
  {
    "start": "2376000",
    "end": "2708000"
  },
  {
    "text": "convolutional neural network ok nothing nothing weird and I'm yeah and here I'm",
    "start": "2378289",
    "end": "2386449"
  },
  {
    "text": "using I'm using a Karis right Cara's dot star okay I'm not using the TF clara's",
    "start": "2386449",
    "end": "2393169"
  },
  {
    "text": "API so this is really native Kharis okay so the first thing to figure out is how",
    "start": "2393169",
    "end": "2401869"
  },
  {
    "text": "do I get hyper parameters right how the stage maker pass those hyper parameters to me okay",
    "start": "2401869",
    "end": "2407809"
  },
  {
    "text": "like you know the learning rate and and more so actually the way this works is quite simple the sage maker will copy",
    "start": "2407809",
    "end": "2414469"
  },
  {
    "text": "hyper parameters inside the container at startup time into a JSON file okay and",
    "start": "2414469",
    "end": "2420349"
  },
  {
    "text": "it has that hyper parameters dot JSON name which I guess makes sense so what",
    "start": "2420349",
    "end": "2426979"
  },
  {
    "text": "I'm gonna do here so I'm gonna need a function to load my data but mostly okay",
    "start": "2426979",
    "end": "2432650"
  },
  {
    "text": "I'm gonna read hyper parameters from that file okay so this might be one",
    "start": "2432650",
    "end": "2439170"
  },
  {
    "text": "of the things that you have to do in your in your native code if you want to",
    "start": "2439170",
    "end": "2444420"
  },
  {
    "text": "adapt for Sage maker okay depending on how you pass raipur parameters but and as you can see here I'm reading quite a",
    "start": "2444420",
    "end": "2450630"
  },
  {
    "text": "lot of hyper parameters so obvious things like learning rate batch size number of epochs but you can see hmm",
    "start": "2450630",
    "end": "2456980"
  },
  {
    "text": "down below you know I'm reading the number of filters for the convolutional layers and I'm reading the dropout value",
    "start": "2456980",
    "end": "2463890"
  },
  {
    "text": "for and even the number of of neurons for for the fully connected layer so",
    "start": "2463890",
    "end": "2469410"
  },
  {
    "text": "okay we'll get to that when we do tuning right so this is how you rely parameters",
    "start": "2469410",
    "end": "2475130"
  },
  {
    "text": "okay and the rest is really strictly",
    "start": "2475130",
    "end": "2480289"
  },
  {
    "text": "strictly Karis code okay that's it's actually the one of the vanilla examples for Karis and I didn't",
    "start": "2480289",
    "end": "2486779"
  },
  {
    "text": "change anything here the only thing that I'm doing here obviously is based on",
    "start": "2486779",
    "end": "2492240"
  },
  {
    "text": "some of the hyper parameters like drop out or off or a number of filters I'm",
    "start": "2492240",
    "end": "2498930"
  },
  {
    "text": "building right the model accordingly okay so initially I will use default values but then when we do hyper",
    "start": "2498930",
    "end": "2505440"
  },
  {
    "text": "parameter optimization of course we're gonna explore more okay but these are",
    "start": "2505440",
    "end": "2511109"
  },
  {
    "text": "the layers that I'm defining so there is a first convolution block with pooling and drop out there's another one",
    "start": "2511109",
    "end": "2518160"
  },
  {
    "text": "pooling and drop out and then I have a first fully connected block here okay",
    "start": "2518160",
    "end": "2524489"
  },
  {
    "text": "with drop out and then a second fully connected block so the that's what the",
    "start": "2524489",
    "end": "2531180"
  },
  {
    "text": "model looks like okay CNN sorry",
    "start": "2531180",
    "end": "2536339"
  },
  {
    "text": "convolution pooling drop out convolution pooling drop out and then two fully",
    "start": "2536339",
    "end": "2543569"
  },
  {
    "text": "connected layers bringing me to the output layer okay so a pretty canonical",
    "start": "2543569",
    "end": "2549089"
  },
  {
    "text": "example alright and then I'm compiling the model my I will optimize for",
    "start": "2549089",
    "end": "2555630"
  },
  {
    "text": "accuracy i define an early stopping callback deciding that if validation",
    "start": "2555630",
    "end": "2563789"
  },
  {
    "text": "accuracy hasn't improved in 30 epochs then stop it okay no need to keep",
    "start": "2563789",
    "end": "2569780"
  },
  {
    "text": "training if for 38 bucks we have an improved stop training okay this is this is the standard",
    "start": "2569780",
    "end": "2575330"
  },
  {
    "text": "callback in cars and I highly recommend that you use it we'll get back to the",
    "start": "2575330",
    "end": "2580610"
  },
  {
    "text": "custom call back later on and then I use a check pointing callback to save the",
    "start": "2580610",
    "end": "2589220"
  },
  {
    "text": "best model right each time we have a new model that is more accurate than the previous one then we save it okay and",
    "start": "2589220",
    "end": "2596600"
  },
  {
    "text": "this guarantees that I will only get the best okay so if I have early stopping if",
    "start": "2596600",
    "end": "2601760"
  },
  {
    "text": "early stopping seen at epoch 65 okay meaning the best one was probably thirty",
    "start": "2601760",
    "end": "2608270"
  },
  {
    "text": "five thirty eight box before then I know that the model that I saved is actually",
    "start": "2608270",
    "end": "2613940"
  },
  {
    "text": "that best model from epoch thirty-five okay so check early stopping a check",
    "start": "2613940",
    "end": "2619040"
  },
  {
    "text": "pointing are very very cool techniques and then I set up image augmentation",
    "start": "2619040",
    "end": "2624100"
  },
  {
    "text": "okay an image segmentation is a way to generate additional samples on the fly",
    "start": "2624100",
    "end": "2630320"
  },
  {
    "text": "okay so you saw those fashion and these samples but here I'm actually adding",
    "start": "2630320",
    "end": "2636140"
  },
  {
    "text": "more sample during training so I'm rotating them from minus 20 to plus 20",
    "start": "2636140",
    "end": "2642440"
  },
  {
    "text": "degrees I'm shifting them I'm shifting them horizontally and vertically up to",
    "start": "2642440",
    "end": "2647960"
  },
  {
    "text": "20 percent and I'm also flipping them horizontally okay so this is going to create plenty plenty",
    "start": "2647960",
    "end": "2653930"
  },
  {
    "text": "more samples that will slow down training for sure because I need to",
    "start": "2653930",
    "end": "2659000"
  },
  {
    "text": "train on many more samples but this creat this creates a more robust model",
    "start": "2659000",
    "end": "2664340"
  },
  {
    "text": "because it has it is now facing slightly weird looking samples so it's gonna",
    "start": "2664340",
    "end": "2669920"
  },
  {
    "text": "actually help okay and so I'm actually training I have a first round of",
    "start": "2669920",
    "end": "2677900"
  },
  {
    "text": "training using image segmentation okay",
    "start": "2677900",
    "end": "2683330"
  },
  {
    "text": "for a number of epochs and then I am training again this time with no image a",
    "start": "2683330",
    "end": "2689180"
  },
  {
    "text": "plantation just training again with the standard data set okay and we'll see",
    "start": "2689180",
    "end": "2695690"
  },
  {
    "text": "what that brings okay so there it is that's my script so how do we run this",
    "start": "2695690",
    "end": "2704470"
  },
  {
    "text": "okay so I mentioned earlier that you",
    "start": "2707530",
    "end": "2714830"
  },
  {
    "start": "2708000",
    "end": "2756000"
  },
  {
    "text": "know you could use tensor board to visualize things but now it's it's possible to use cloud watch actually you",
    "start": "2714830",
    "end": "2719930"
  },
  {
    "text": "can graph training metrics in cloud watch so for obviously you need to define what those metrics are and this",
    "start": "2719930",
    "end": "2726290"
  },
  {
    "text": "is how you do it define that simple dictionary with with the matrix the",
    "start": "2726290",
    "end": "2732650"
  },
  {
    "text": "matrix name and an erect that tells stage maker how to fetch the matrix in",
    "start": "2732650",
    "end": "2739760"
  },
  {
    "text": "the cloud watch log okay in the training log which is also available in cloud watch so the red X is okay this is what",
    "start": "2739760",
    "end": "2746420"
  },
  {
    "text": "you should be looking for so okay so in the chaos log we see those act lost valid values and this is how to extract",
    "start": "2746420",
    "end": "2753590"
  },
  {
    "text": "them okay so now we have everything we need to train and since we're using a",
    "start": "2753590",
    "end": "2760850"
  },
  {
    "text": "custom container we can't use that high-level tensorflow object like we've seen before we use that generic training",
    "start": "2760850",
    "end": "2768170"
  },
  {
    "text": "object which is called the estimator in stage maker okay and it works exactly the same as you can see the only",
    "start": "2768170",
    "end": "2774530"
  },
  {
    "text": "difference is the image name the first parameter is actually the name of that container in ECR okay so that's the",
    "start": "2774530",
    "end": "2783380"
  },
  {
    "text": "Charis container that I built and pushed okay and that's and you can see that name just under the cell right account",
    "start": "2783380",
    "end": "2791060"
  },
  {
    "text": "number dot g'kar except relaxation so that's the name that I'm using it's the only difference the other parameters are",
    "start": "2791060",
    "end": "2796910"
  },
  {
    "text": "the same the the instance count instance",
    "start": "2796910",
    "end": "2803030"
  },
  {
    "text": "died the role the output path to store the model etc okay and now you know in",
    "start": "2803030",
    "end": "2811610"
  },
  {
    "text": "for a first step I'm gonna set just I'm gonna set the basic hyper parameter so I'm gonna turn 408 box I'm gonna use one",
    "start": "2811610",
    "end": "2819410"
  },
  {
    "text": "GPU and I'm gonna use a batch size of 256 okay so everything else is set to",
    "start": "2819410",
    "end": "2825110"
  },
  {
    "text": "default values as defined by my script okay so remember stage maker is going to",
    "start": "2825110",
    "end": "2830330"
  },
  {
    "text": "take those values ride them to a JSON file inside the container so once",
    "start": "2830330",
    "end": "2835880"
  },
  {
    "text": "my script kicks in it's gonna read that file it's gonna find those three values and it's gonna use default stuff for",
    "start": "2835880",
    "end": "2843019"
  },
  {
    "text": "everything else okay so how do we do here so actually I run it again",
    "start": "2843019",
    "end": "2848180"
  },
  {
    "text": "hopefully it's it completed all right so",
    "start": "2848180",
    "end": "2853940"
  },
  {
    "text": "I train for again 108 box with image segmentation one other deck box without",
    "start": "2853940",
    "end": "2859599"
  },
  {
    "text": "okay so it trained for a total of 1600",
    "start": "2859599",
    "end": "2864950"
  },
  {
    "text": "and 15 seconds which is yeah which is a little we are don't know 25 minutes or",
    "start": "2864950",
    "end": "2870739"
  },
  {
    "text": "something like that right and the best accuracy that I got is 94% which is",
    "start": "2870739",
    "end": "2877160"
  },
  {
    "text": "actually quite good for fashion and list already okay so let's visualize some of those",
    "start": "2877160",
    "end": "2883690"
  },
  {
    "text": "metrics in cloud watch hopefully we can see them and let me maybe yeah go back",
    "start": "2883690",
    "end": "2893539"
  },
  {
    "text": "in time a bit okay and here I'm plotting",
    "start": "2893539",
    "end": "2898900"
  },
  {
    "text": "I'm plotting can I go to maybe no okay",
    "start": "2898900",
    "end": "2905959"
  },
  {
    "text": "one hour is the best thing we're gonna do okay so I can see so the blue line is",
    "start": "2905959",
    "end": "2913940"
  },
  {
    "text": "the training accuracy and the orange line is the validation accuracy okay and this corresponds exactly correspond",
    "start": "2913940",
    "end": "2920690"
  },
  {
    "text": "exactly to what we saw here right so",
    "start": "2920690",
    "end": "2926239"
  },
  {
    "text": "these are the metrics that I defined so sage maker is running the red X on the",
    "start": "2926239",
    "end": "2931339"
  },
  {
    "text": "training log and pushing the metrics to cloud watch okay and I can see that okay",
    "start": "2931339",
    "end": "2937640"
  },
  {
    "text": "I trained for a bit and and these are probably the first hundred a box with",
    "start": "2937640",
    "end": "2944779"
  },
  {
    "text": "image augmentation making it very difficult to learn okay and then once I train again without image augmentation",
    "start": "2944779",
    "end": "2951289"
  },
  {
    "text": "then accuracy jumps pretty quickly and we get to 94% for for the validation",
    "start": "2951289",
    "end": "2958069"
  },
  {
    "text": "accuracy and something like 97 for four training accuracy okay so 94%",
    "start": "2958069",
    "end": "2966920"
  },
  {
    "text": "not too bad right and I can see the other metrics I didn't plot them but if I look at the loss metrics right",
    "start": "2966920",
    "end": "2973750"
  },
  {
    "text": "accordingly I can see the training laws going down and I can see validation laws",
    "start": "2973750",
    "end": "2979670"
  },
  {
    "text": "actually increasing so I might have over fitted a bit you know we need to check that one okay so this is how you",
    "start": "2979670",
    "end": "2986900"
  },
  {
    "text": "actually push the metrics in file watching pretty easy okay ninety four percent so and the",
    "start": "2986900",
    "end": "2995540"
  },
  {
    "text": "training log let me just show you the log ok the training log is available in cloud watch as well right so you don't",
    "start": "2995540",
    "end": "3002859"
  },
  {
    "text": "have to actually read it in the notebook instance okay so this is good",
    "start": "3002859",
    "end": "3011770"
  },
  {
    "text": "ninety-four now what about optimizing this okay",
    "start": "3011770",
    "end": "3018250"
  },
  {
    "text": "because I don't know you know I have lots of default values here for some other parameters and now I want to run",
    "start": "3018250",
    "end": "3024280"
  },
  {
    "text": "hyper parameter optimization on the net on the structure itself so I want to figure out how many convolutional",
    "start": "3024280",
    "end": "3030579"
  },
  {
    "text": "filters I need in layer one and layer two I want to figure out dropout for all the layers I wanted to figure out how",
    "start": "3030579",
    "end": "3036369"
  },
  {
    "text": "many how wide those fully connected layers should be okay so I define all",
    "start": "3036369",
    "end": "3042069"
  },
  {
    "text": "those parameters there and I define whether they're integers or continuous parameters and I define the ranges okay",
    "start": "3042069",
    "end": "3049150"
  },
  {
    "text": "so for example for the first one I'm going to explore between thirty two convolutional filters and 128 filters",
    "start": "3049150",
    "end": "3055420"
  },
  {
    "text": "for the first layer and so on okay and hopefully Sage maker is gonna help",
    "start": "3055420",
    "end": "3060609"
  },
  {
    "text": "us figure out those values and get to improve the accuracy okay so I still set",
    "start": "3060609",
    "end": "3067990"
  },
  {
    "text": "you know at Box to 100 and and bite size to 256 okay I define the metrics that I",
    "start": "3067990",
    "end": "3076450"
  },
  {
    "text": "want to optimize on so here the the success right the best model should it",
    "start": "3076450",
    "end": "3082990"
  },
  {
    "text": "should be the one with the highest validation accuracy okay so I need to tell sage maker how to figure out this",
    "start": "3082990",
    "end": "3090369"
  },
  {
    "text": "information from the training log okay so once again I need to define a metric what the type of the metric is so here I",
    "start": "3090369",
    "end": "3097210"
  },
  {
    "text": "want to maximize accuracy I need to provide a reg X to help Sage",
    "start": "3097210",
    "end": "3103190"
  },
  {
    "text": "maker figure it out and this is where I need that custom call back in chaos because since I've got early stopping I",
    "start": "3103190",
    "end": "3111340"
  },
  {
    "text": "need to make sure it's not you can't just read the the accuracy for the last",
    "start": "3111340",
    "end": "3117020"
  },
  {
    "text": "epic because quite likely this is not the best one the best one came earlier",
    "start": "3117020",
    "end": "3122510"
  },
  {
    "text": "and then training went on for a little while because of our list because our very stopping so I need a custom call",
    "start": "3122510",
    "end": "3128450"
  },
  {
    "text": "back logging specifically the best validation accuracy for the best epoch and this is what sage maker grabs okay and then I'm",
    "start": "3128450",
    "end": "3136130"
  },
  {
    "text": "using the hyper parameter tuner object from Sage Maker passing the estimator so",
    "start": "3136130",
    "end": "3142580"
  },
  {
    "text": "the that estimator for the training job that we use earlier the metric name the",
    "start": "3142580",
    "end": "3148280"
  },
  {
    "text": "ranges and and how many jobs I want to run so here I'm going to run 30 jobs 3x3",
    "start": "3148280",
    "end": "3154070"
  },
  {
    "text": "okay and the way this works the stage maker is going to train three models using a combination of parameters and",
    "start": "3154070",
    "end": "3159560"
  },
  {
    "text": "then each time a job completes it's going to look at the accuracy that it gets and it applies optimization okay so",
    "start": "3159560",
    "end": "3165920"
  },
  {
    "text": "it's not a random search or grid search it is it's a technical version optimization where we try to approximate",
    "start": "3165920",
    "end": "3173050"
  },
  {
    "text": "we try to guess really what the next best set of parameters should be and we",
    "start": "3173050",
    "end": "3178670"
  },
  {
    "text": "we make that decision based on the last few training jobs that we that we had so",
    "start": "3178670",
    "end": "3184040"
  },
  {
    "text": "we're going to train three by three those three will complete pretty much at the same time and then those three data",
    "start": "3184040",
    "end": "3189800"
  },
  {
    "text": "points help sage make you decide what the next three should be etc etc okay so we're gonna run ten rounds three jobs at",
    "start": "3189800",
    "end": "3197330"
  },
  {
    "text": "a time okay so three training jobs in parallel okay and then we call fit to",
    "start": "3197330",
    "end": "3203390"
  },
  {
    "text": "train alright and so this takes a while",
    "start": "3203390",
    "end": "3209930"
  },
  {
    "text": "as you can imagine because each of those jobs takes about 26 minutes so obviously",
    "start": "3209930",
    "end": "3215240"
  },
  {
    "text": "I prepared for this and I should see yes so here's my here's my job actually I",
    "start": "3215240",
    "end": "3222790"
  },
  {
    "text": "can see the 30 jobs that have been trained okay yeah so took a while",
    "start": "3222790",
    "end": "3230130"
  },
  {
    "text": "but I'm not paying my edibles bills so it doesn't really matter but you should create an yeah some people say that's",
    "start": "3230130",
    "end": "3235650"
  },
  {
    "text": "the reason why I joined them but I don't listen to them okay and more importantly I can see the best",
    "start": "3235650",
    "end": "3242819"
  },
  {
    "text": "training job and I can see the best training job yielded an accuracy of ninety four point 61 okay and well",
    "start": "3242819",
    "end": "3251130"
  },
  {
    "text": "remember we got 94 from the previous job and now we got 90 460 okay that's a very",
    "start": "3251130",
    "end": "3257099"
  },
  {
    "text": "significant improvement and we can see the the actual hyper parameters that",
    "start": "3257099",
    "end": "3262470"
  },
  {
    "text": "were used right so I don't think anyone here would have thought of using dropout one set to an 0.1 155 or whatever I mean",
    "start": "3262470",
    "end": "3272519"
  },
  {
    "text": "those are non-intuitive values right but as it turns out based on those thirty jobs these are the values okay so the",
    "start": "3272519",
    "end": "3279869"
  },
  {
    "text": "dropout values and the the size of the fully connected layers and the number of",
    "start": "3279869",
    "end": "3285839"
  },
  {
    "text": "filters for the convolutional layers right these are the ones that work best okay so no one would have thought to use",
    "start": "3285839",
    "end": "3292099"
  },
  {
    "text": "108 filters in the first layer and another and 674 layers you know we just use power of two yeah we everybody uses",
    "start": "3292099",
    "end": "3299670"
  },
  {
    "text": "that 32 64 100 8 and we just we just pray that these are the right values but",
    "start": "3299670",
    "end": "3304920"
  },
  {
    "text": "as it turns out these are they're the best ones for this tuning job ok so you",
    "start": "3304920",
    "end": "3311579"
  },
  {
    "text": "can see all that stuff in the console but you can also you can also query you",
    "start": "3311579",
    "end": "3319589"
  },
  {
    "text": "can also query let's run those cells yeah so you can query those statistics",
    "start": "3319589",
    "end": "3326119"
  },
  {
    "text": "we can display we can display those",
    "start": "3326119",
    "end": "3332640"
  },
  {
    "text": "stats and we could plot okay so so this is",
    "start": "3332640",
    "end": "3342609"
  },
  {
    "start": "3338000",
    "end": "3600000"
  },
  {
    "text": "accuracy over time okay and I'm just just for the heck of it because I'm a",
    "start": "3342609",
    "end": "3348759"
  },
  {
    "text": "maniac I guess I'm fitting a linear regression line to this because I want",
    "start": "3348759",
    "end": "3354969"
  },
  {
    "text": "to see that line going up right I want to see the algo doing a good job at figuring out what the hyper parameters",
    "start": "3354969",
    "end": "3361539"
  },
  {
    "text": "are okay so it has a very flat slope I'll give you that but there is an",
    "start": "3361539",
    "end": "3368019"
  },
  {
    "text": "upwards trend right so you can see we are actually time model after model step",
    "start": "3368019",
    "end": "3373719"
  },
  {
    "text": "after step we're actually you know going towards higher performing models okay so",
    "start": "3373719",
    "end": "3380019"
  },
  {
    "text": "that's a good sign and we have a weirdo somewhere it would be interesting to look at that one we would learn what",
    "start": "3380019",
    "end": "3385749"
  },
  {
    "text": "that probably there was a very very negative parameter user we could plot",
    "start": "3385749",
    "end": "3391929"
  },
  {
    "text": "accuracy versus dropout okay so layer one dropout and yeah layer one",
    "start": "3391929",
    "end": "3399549"
  },
  {
    "text": "drop CNN layer one drop out CNN layer to drop out so do we learn anything here",
    "start": "3399549",
    "end": "3404999"
  },
  {
    "text": "well I would say the higher the higher performing models are probably the ones",
    "start": "3404999",
    "end": "3412420"
  },
  {
    "text": "on the left so that would probably mean don't use too much dropout in your first convolution layer which makes sense I",
    "start": "3412420",
    "end": "3419289"
  },
  {
    "text": "guess intuitively because if you have too much dropout then you're throwing too much information away and then it's",
    "start": "3419289",
    "end": "3425019"
  },
  {
    "text": "obviously difficult to do feature extraction if you if you kill too many too many features already on for the",
    "start": "3425019",
    "end": "3431920"
  },
  {
    "text": "second convolutional layer you know it's less it's less obvious it's less obvious",
    "start": "3431920",
    "end": "3437170"
  },
  {
    "text": "what the dropout value should be so if you use something in the middle you're probably safe and for the fully",
    "start": "3437170",
    "end": "3445449"
  },
  {
    "text": "connected layers you know again for the first one there is no clear trend so you",
    "start": "3445449",
    "end": "3454150"
  },
  {
    "text": "know that now I understand why people tend to use point four 0.5 because I guess it's it's a reasonable value for",
    "start": "3454150",
    "end": "3460709"
  },
  {
    "text": "the for the second layer we can see if we have excessive dropout we have you",
    "start": "3460709",
    "end": "3466959"
  },
  {
    "text": "know we are kind of lower accuracy but again somewhere in the middle is a is",
    "start": "3466959",
    "end": "3472900"
  },
  {
    "text": "acceptable okay and it's interesting because this when you do this you you understand why all those tutorials all",
    "start": "3472900",
    "end": "3479540"
  },
  {
    "text": "those all those samples they tend to use those typical values because the guys who wrote them they knew that right but",
    "start": "3479540",
    "end": "3486470"
  },
  {
    "text": "now now we can confirm it using hyper parameter tuning and let's let's do the",
    "start": "3486470",
    "end": "3492770"
  },
  {
    "text": "same for for kernel filters and so for the first layer I guess there's a bit of",
    "start": "3492770",
    "end": "3501770"
  },
  {
    "text": "a bias on the right so something like 90 or 100 filters work best and interestingly for the for the second",
    "start": "3501770",
    "end": "3508160"
  },
  {
    "text": "layer you can see we have we have probably the best accuracy when we have a not a lot of filters which makes sense",
    "start": "3508160",
    "end": "3514070"
  },
  {
    "text": "again because in that second convolutional neural layer you you extract higher level features right you",
    "start": "3514070",
    "end": "3520880"
  },
  {
    "text": "combine the low level features into higher level features so you can have so",
    "start": "3520880",
    "end": "3526070"
  },
  {
    "text": "many combinations that if you have more filters then you can actually figure out more more high level features and more",
    "start": "3526070",
    "end": "3532490"
  },
  {
    "text": "details so that makes sense I think and and the fully connected layers alright",
    "start": "3532490",
    "end": "3539600"
  },
  {
    "text": "okay more I guess more interesting models on the right right so more fully",
    "start": "3539600",
    "end": "3547340"
  },
  {
    "text": "connected neurons here help classify for the second layer you know it's not so",
    "start": "3547340",
    "end": "3553640"
  },
  {
    "text": "obvious okay so you could decide that well for the next hyper parameter tuning",
    "start": "3553640",
    "end": "3558740"
  },
  {
    "text": "job I can actually stop tuning some of these because there doesn't seem to be a big difference so you can settle for you",
    "start": "3558740",
    "end": "3566030"
  },
  {
    "text": "know like a median value and keep tuning on the other ones right keep tuning maybe on on the number of filters or",
    "start": "3566030",
    "end": "3572990"
  },
  {
    "text": "keep tuning on something else okay it's it's a highly iterative process okay so",
    "start": "3572990",
    "end": "3579860"
  },
  {
    "text": "there you go and if we wanted to deploy the best model we could do that very easily right",
    "start": "3579860",
    "end": "3585190"
  },
  {
    "text": "tune or deploy and this automatically deploys the best model and we're happy",
    "start": "3585190",
    "end": "3590840"
  },
  {
    "text": "because we have good performance okay",
    "start": "3590840",
    "end": "3596700"
  },
  {
    "text": "so as a conclusion we know we saw plenty",
    "start": "3596700",
    "end": "3602320"
  },
  {
    "text": "of things we so what sage maker was what tensorflow was how what happens when you",
    "start": "3602320",
    "end": "3610030"
  },
  {
    "text": "mix both and as you can see there is really a lot of features on sage maker",
    "start": "3610030",
    "end": "3615310"
  },
  {
    "text": "that make tensorflow even more efficient pipe mode distributed training etc etc",
    "start": "3615310",
    "end": "3622690"
  },
  {
    "text": "all the things that we saw and and you can still use your tensor board and all your favorite tools okay so and it",
    "start": "3622690",
    "end": "3629110"
  },
  {
    "text": "doesn't take a lot of effort to bring your tensor flow code to Sage Maker as we saw so if you want to get started",
    "start": "3629110",
    "end": "3635160"
  },
  {
    "text": "obviously that's the tensor flow and the Charis urls the the first github URL is",
    "start": "3635160",
    "end": "3644140"
  },
  {
    "text": "the collection of terms of of sage maker notebooks okay and it keeps growing and there are quite a few stands of row",
    "start": "3644140",
    "end": "3650710"
  },
  {
    "text": "examples in there so I would recommend that you you read them the sage maker SDK on github as well",
    "start": "3650710",
    "end": "3657100"
  },
  {
    "text": "okay with the documentation and that will help you write stuff just like I",
    "start": "3657100",
    "end": "3663010"
  },
  {
    "text": "wrote and that's my blog on medium if you are if you found this session interesting and you'd like to stay in",
    "start": "3663010",
    "end": "3669250"
  },
  {
    "text": "touch and read more about machine learning and deep learning you'll find it here okay I want to point out we've",
    "start": "3669250",
    "end": "3676570"
  },
  {
    "text": "got two repeats so this was the technical one without a customer we have",
    "start": "3676570",
    "end": "3682570"
  },
  {
    "text": "two repeats on Thursday and Friday where we will have customers on stage so if",
    "start": "3682570",
    "end": "3689530"
  },
  {
    "text": "you're interested in seeing what customers build well there you go you",
    "start": "3689530",
    "end": "3694540"
  },
  {
    "text": "can go and look at that one I will I will not be delivering the Thursday one that I will be delivering the Friday one",
    "start": "3694540",
    "end": "3700420"
  },
  {
    "text": "and if if you want to read about a super super crazy advanced use case I really",
    "start": "3700420",
    "end": "3705580"
  },
  {
    "text": "recommend the Friday's session those guys have built something really really cool thank you very much I really",
    "start": "3705580",
    "end": "3711970"
  },
  {
    "text": "appreciate your your presence on that last session of the day if you want to stay in touch later on this is my",
    "start": "3711970",
    "end": "3718810"
  },
  {
    "text": "twitter handle feel free to ping me ask questions ask for you know guidance or",
    "start": "3718810",
    "end": "3724990"
  },
  {
    "text": "whatever happy to help if you just saw just patient",
    "start": "3724990",
    "end": "3730010"
  },
  {
    "text": "because I'm not always answering in five seconds but I try to answer every one and if you build cool things and you like to share them please you know again",
    "start": "3730010",
    "end": "3737210"
  },
  {
    "text": "ping me and I'm more than happy to retweet and share everything ok thanks again and if you if you have feedback",
    "start": "3737210",
    "end": "3743390"
  },
  {
    "text": "please use the mobile app for the for the feedback on that session have a great night",
    "start": "3743390",
    "end": "3749710"
  }
]
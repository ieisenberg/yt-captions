[
  {
    "start": "0",
    "end": "32000"
  },
  {
    "text": "hi and welcome back my name is Matt Nill",
    "start": "3000",
    "end": "6200"
  },
  {
    "text": "I'm a senior generative AI Solutions",
    "start": "6200",
    "end": "8120"
  },
  {
    "text": "architect at AWS focusing on generative",
    "start": "8120",
    "end": "11200"
  },
  {
    "text": "AI training and inference in this video",
    "start": "11200",
    "end": "14120"
  },
  {
    "text": "we'll show training llama 7B using",
    "start": "14120",
    "end": "16278"
  },
  {
    "text": "sagemaker model parallelism libraries in",
    "start": "16279",
    "end": "18680"
  },
  {
    "text": "fp8 on sagemaker hyperpod at the end of",
    "start": "18680",
    "end": "21640"
  },
  {
    "text": "this video you should have an idea of",
    "start": "21640",
    "end": "23480"
  },
  {
    "text": "how to run distributed training on",
    "start": "23480",
    "end": "25560"
  },
  {
    "text": "sagemaker hyperpod as well as get a",
    "start": "25560",
    "end": "27880"
  },
  {
    "text": "sense of the core resiliency features",
    "start": "27880",
    "end": "30080"
  },
  {
    "text": "including autor resume on",
    "start": "30080",
    "end": "32398"
  },
  {
    "start": "32000",
    "end": "61000"
  },
  {
    "text": "hyperpod before jumping into the live",
    "start": "32399",
    "end": "34559"
  },
  {
    "text": "demo let's review the architecture which",
    "start": "34559",
    "end": "36559"
  },
  {
    "text": "we have deployed our hyperpod cluster",
    "start": "36559",
    "end": "38719"
  },
  {
    "text": "consists of a single M51 12x large as",
    "start": "38719",
    "end": "41280"
  },
  {
    "text": "the head node as well as four mlp5 48x",
    "start": "41280",
    "end": "45320"
  },
  {
    "text": "larges as the compute",
    "start": "45320",
    "end": "47079"
  },
  {
    "text": "nodes we've also provisioned a 1.2 teyte",
    "start": "47079",
    "end": "50199"
  },
  {
    "text": "FSX for luster file",
    "start": "50199",
    "end": "52640"
  },
  {
    "text": "system uh which is mounted to all of the",
    "start": "52640",
    "end": "54960"
  },
  {
    "text": "cluster nodes finally we'll SSH into the",
    "start": "54960",
    "end": "57960"
  },
  {
    "text": "head node to launch our jobs",
    "start": "57960",
    "end": "61920"
  },
  {
    "start": "61000",
    "end": "111000"
  },
  {
    "text": "so to start I'm going to clone our",
    "start": "62480",
    "end": "64239"
  },
  {
    "text": "awesome distributed training repository",
    "start": "64239",
    "end": "66479"
  },
  {
    "text": "which includes several test cases uh and",
    "start": "66479",
    "end": "70159"
  },
  {
    "text": "examples for today's demo we're going to",
    "start": "70159",
    "end": "72439"
  },
  {
    "text": "be following the sagemaker model",
    "start": "72439",
    "end": "73960"
  },
  {
    "text": "parallel V2",
    "start": "73960",
    "end": "77280"
  },
  {
    "text": "example so I'm going to head on over to",
    "start": "79600",
    "end": "82119"
  },
  {
    "text": "the Head node here I can see that I've",
    "start": "82119",
    "end": "83720"
  },
  {
    "text": "got four idle nodes within my P5 cluster",
    "start": "83720",
    "end": "87000"
  },
  {
    "text": "and I'm going to clone our Repository",
    "start": "87000",
    "end": "91680"
  },
  {
    "text": "awesome with the repository cloned now",
    "start": "101240",
    "end": "103280"
  },
  {
    "text": "I'm going to CD into awesome distributed",
    "start": "103280",
    "end": "105399"
  },
  {
    "text": "training and head over to test cases and",
    "start": "105399",
    "end": "108880"
  },
  {
    "text": "17 sagemaker model",
    "start": "108880",
    "end": "111360"
  },
  {
    "start": "111000",
    "end": "167000"
  },
  {
    "text": "parallel can feel free to follow along",
    "start": "111360",
    "end": "113680"
  },
  {
    "text": "on the readme uh the setup here is going",
    "start": "113680",
    "end": "115880"
  },
  {
    "text": "to be fairly simple uh in this case",
    "start": "115880",
    "end": "118119"
  },
  {
    "text": "we're going to follow the uh run",
    "start": "118119",
    "end": "120799"
  },
  {
    "text": "training using Docker and end rout on",
    "start": "120799",
    "end": "122759"
  },
  {
    "text": "slurm instructions so for starters we",
    "start": "122759",
    "end": "126520"
  },
  {
    "text": "will uh create a Docker file uh which",
    "start": "126520",
    "end": "130399"
  },
  {
    "text": "will then convert to a squash file using",
    "start": "130399",
    "end": "132599"
  },
  {
    "text": "n rot and pixies we'll reference this",
    "start": "132599",
    "end": "135080"
  },
  {
    "text": "file within our training script it's a",
    "start": "135080",
    "end": "137760"
  },
  {
    "text": "fairly simple script we're just using",
    "start": "137760",
    "end": "140000"
  },
  {
    "text": "ECR to fetch uh an",
    "start": "140000",
    "end": "143080"
  },
  {
    "text": "image um this is the sage maker model",
    "start": "143080",
    "end": "145920"
  },
  {
    "text": "parallel V2 image and then we're going",
    "start": "145920",
    "end": "147800"
  },
  {
    "text": "to use Docker build to build it and then",
    "start": "147800",
    "end": "150360"
  },
  {
    "text": "we'll use Nvidia en rout which comes",
    "start": "150360",
    "end": "152040"
  },
  {
    "text": "pre-installed on our hyperpod cluster to",
    "start": "152040",
    "end": "154640"
  },
  {
    "text": "convert this to a squash file and save",
    "start": "154640",
    "end": "156959"
  },
  {
    "text": "it to our local directory as SMP V2",
    "start": "156959",
    "end": "161200"
  },
  {
    "text": "we'll then be able to reference this",
    "start": "161200",
    "end": "162480"
  },
  {
    "text": "squash file in our distributed training",
    "start": "162480",
    "end": "166280"
  },
  {
    "start": "167000",
    "end": "235000"
  },
  {
    "text": "job great so let's head back over to our",
    "start": "167200",
    "end": "170200"
  },
  {
    "text": "cluster now it's best practice to build",
    "start": "170200",
    "end": "173599"
  },
  {
    "text": "any Docker containers uh on the",
    "start": "173599",
    "end": "176480"
  },
  {
    "text": "controller nodes um not only do the",
    "start": "176480",
    "end": "178680"
  },
  {
    "text": "controller nodes have more cores um",
    "start": "178680",
    "end": "181519"
  },
  {
    "text": "Docker is also installed uh into to use",
    "start": "181519",
    "end": "185680"
  },
  {
    "text": "nbme storage the 27 terabytes of nvme",
    "start": "185680",
    "end": "188680"
  },
  {
    "text": "storage on the P5",
    "start": "188680",
    "end": "190319"
  },
  {
    "text": "instances uh this is quite a lot of",
    "start": "190319",
    "end": "192120"
  },
  {
    "text": "storage but container these Docker",
    "start": "192120",
    "end": "194120"
  },
  {
    "text": "container images can be fairly large So",
    "start": "194120",
    "end": "195959"
  },
  {
    "text": "to avoid filling up disk space on the",
    "start": "195959",
    "end": "198760"
  },
  {
    "text": "controller node we're going to build our",
    "start": "198760",
    "end": "200440"
  },
  {
    "text": "image on the the compute node",
    "start": "200440",
    "end": "205720"
  },
  {
    "text": "great so I've just initiated the docker",
    "start": "222680",
    "end": "224239"
  },
  {
    "text": "build script this will take 10 to 15",
    "start": "224239",
    "end": "227239"
  },
  {
    "text": "minutes for the docker container to",
    "start": "227239",
    "end": "228680"
  },
  {
    "text": "build when it's done building we'll come",
    "start": "228680",
    "end": "230959"
  },
  {
    "text": "back and set up our distributed training",
    "start": "230959",
    "end": "235400"
  },
  {
    "start": "235000",
    "end": "264000"
  },
  {
    "text": "job hey welcome back it looks like our",
    "start": "235400",
    "end": "238439"
  },
  {
    "text": "Docker file has finished building uh so",
    "start": "238439",
    "end": "241040"
  },
  {
    "text": "we can resume following along our",
    "start": "241040",
    "end": "243120"
  },
  {
    "text": "example to use sagemaker model parallel",
    "start": "243120",
    "end": "245480"
  },
  {
    "text": "to train llama",
    "start": "245480",
    "end": "248560"
  },
  {
    "text": "70b now that we've run the docker build",
    "start": "248560",
    "end": "250879"
  },
  {
    "text": "script let's verify that the squash file",
    "start": "250879",
    "end": "254640"
  },
  {
    "text": "exists in our local",
    "start": "254640",
    "end": "256919"
  },
  {
    "text": "repository here we can see S&P v2.",
    "start": "256919",
    "end": "260680"
  },
  {
    "text": "sqsh 18 gbt",
    "start": "260680",
    "end": "264639"
  },
  {
    "text": "fantastic so the next step will be to",
    "start": "264639",
    "end": "268000"
  },
  {
    "text": "launch the distributed training. batch",
    "start": "268000",
    "end": "270000"
  },
  {
    "text": "script before we do so let's take a look",
    "start": "270000",
    "end": "272680"
  },
  {
    "text": "at that script and modify any parameters",
    "start": "272680",
    "end": "275000"
  },
  {
    "text": "as needed before launching our training",
    "start": "275000",
    "end": "278880"
  },
  {
    "text": "job I can confirm that the squash file",
    "start": "279440",
    "end": "282039"
  },
  {
    "text": "was properly written to my local",
    "start": "282039",
    "end": "283800"
  },
  {
    "text": "directory and it's about 18 gigabytes s",
    "start": "283800",
    "end": "286960"
  },
  {
    "text": "SMP v2.",
    "start": "286960",
    "end": "289919"
  },
  {
    "text": "sqsh now if I navigate to the launch",
    "start": "289919",
    "end": "292759"
  },
  {
    "text": "training and route. Sh script I'm going",
    "start": "292759",
    "end": "295039"
  },
  {
    "text": "to change a couple of default parameters",
    "start": "295039",
    "end": "296960"
  },
  {
    "text": "here for the sake of today's demo for",
    "start": "296960",
    "end": "299800"
  },
  {
    "text": "number of nodes I'm going to set the",
    "start": "299800",
    "end": "301360"
  },
  {
    "text": "number of nodes to four which is equal",
    "start": "301360",
    "end": "303280"
  },
  {
    "text": "to the amount of P5 nodes I have within",
    "start": "303280",
    "end": "305120"
  },
  {
    "text": "my slurm cluster I'll leave the other",
    "start": "305120",
    "end": "307680"
  },
  {
    "text": "sbatch parameters as default including",
    "start": "307680",
    "end": "310039"
  },
  {
    "text": "exclusive job node allocation to make",
    "start": "310039",
    "end": "312039"
  },
  {
    "text": "sure that this is the only job launched",
    "start": "312039",
    "end": "314120"
  },
  {
    "text": "by slurm onto my cluster",
    "start": "314120",
    "end": "316639"
  },
  {
    "text": "nodes for model size here I've set model",
    "start": "316639",
    "end": "320639"
  },
  {
    "text": "size equal to 7B uh and we're going to",
    "start": "320639",
    "end": "323240"
  },
  {
    "text": "be using the Llama V2",
    "start": "323240",
    "end": "325759"
  },
  {
    "text": "model I'm going to leave using synthetic",
    "start": "325759",
    "end": "328360"
  },
  {
    "text": "data equal to one as default this will",
    "start": "328360",
    "end": "330800"
  },
  {
    "text": "use synthetic data for the purposes of",
    "start": "330800",
    "end": "332639"
  },
  {
    "text": "My Demo um if I had my own training data",
    "start": "332639",
    "end": "336000"
  },
  {
    "text": "I would specify the path in the script",
    "start": "336000",
    "end": "338600"
  },
  {
    "text": "here lines 28 through 30 uh to my",
    "start": "338600",
    "end": "341400"
  },
  {
    "text": "training directory as well as my test",
    "start": "341400",
    "end": "343639"
  },
  {
    "text": "directory I've created a checkpoints",
    "start": "343639",
    "end": "345880"
  },
  {
    "text": "directory in the local directory I'm in",
    "start": "345880",
    "end": "348639"
  },
  {
    "text": "called checkpoints that will be",
    "start": "348639",
    "end": "350199"
  },
  {
    "text": "referenced to my script on line",
    "start": "350199",
    "end": "352840"
  },
  {
    "text": "30 and finally I have my squash file on",
    "start": "352840",
    "end": "355880"
  },
  {
    "text": "line 33 s SMP v2. sqsh from my local",
    "start": "355880",
    "end": "362160"
  },
  {
    "text": "directory scrolling down we have some",
    "start": "362360",
    "end": "364560"
  },
  {
    "text": "environment variables for nickel that",
    "start": "364560",
    "end": "366080"
  },
  {
    "text": "we're exporting including uh F fi EFA",
    "start": "366080",
    "end": "369759"
  },
  {
    "text": "used device RDMA which we're setting to",
    "start": "369759",
    "end": "371919"
  },
  {
    "text": "one this will ensure that EFA traffic is",
    "start": "371919",
    "end": "374560"
  },
  {
    "text": "using the uh device RDMA feature uh on",
    "start": "374560",
    "end": "378000"
  },
  {
    "text": "the P5",
    "start": "378000",
    "end": "380479"
  },
  {
    "text": "instances finally we have the number of",
    "start": "380479",
    "end": "382680"
  },
  {
    "text": "gpus equal to",
    "start": "382680",
    "end": "385440"
  },
  {
    "text": "8 scrolling down to the model parameters",
    "start": "385800",
    "end": "388639"
  },
  {
    "text": "we're using the 7 B model which will",
    "start": "388639",
    "end": "390560"
  },
  {
    "text": "have a default Shard degree equal to 8",
    "start": "390560",
    "end": "393000"
  },
  {
    "text": "and number of attention heads equal to",
    "start": "393000",
    "end": "396560"
  },
  {
    "text": "32 we've set our train batch size equal",
    "start": "397840",
    "end": "400720"
  },
  {
    "text": "to four Max steps to 10,000 and",
    "start": "400720",
    "end": "403560"
  },
  {
    "text": "checkpoint frequency will'll keep at",
    "start": "403560",
    "end": "406919"
  },
  {
    "text": "100 with these parameters set we should",
    "start": "406919",
    "end": "409919"
  },
  {
    "text": "be good to launch our",
    "start": "409919",
    "end": "412800"
  },
  {
    "text": "script let me check the status of the",
    "start": "413599",
    "end": "416120"
  },
  {
    "text": "cluster nodes I have four nodes idle",
    "start": "416120",
    "end": "420120"
  },
  {
    "text": "launch training and",
    "start": "420120",
    "end": "422759"
  },
  {
    "text": "root.sh and so now I've just kicked off",
    "start": "422759",
    "end": "425160"
  },
  {
    "text": "The slurm sbatch Script we'll come back",
    "start": "425160",
    "end": "427800"
  },
  {
    "text": "in just a few minutes to confirm that",
    "start": "427800",
    "end": "429599"
  },
  {
    "text": "we've written our first checkpoint after",
    "start": "429599",
    "end": "431800"
  },
  {
    "text": "which we'll simulate autor resume by",
    "start": "431800",
    "end": "433879"
  },
  {
    "text": "injecting a failure on one of the",
    "start": "433879",
    "end": "435120"
  },
  {
    "text": "cluster notes see you in just a few",
    "start": "435120",
    "end": "439280"
  },
  {
    "text": "minutes okay welcome back our training",
    "start": "439319",
    "end": "441840"
  },
  {
    "text": "job is kicked off we're currently on",
    "start": "441840",
    "end": "444479"
  },
  {
    "text": "about batch 30 uh we can see we're",
    "start": "444479",
    "end": "446520"
  },
  {
    "text": "running with fp8 at uh 420 T flops per",
    "start": "446520",
    "end": "451080"
  },
  {
    "text": "GPU and about 80 samples per second so",
    "start": "451080",
    "end": "454560"
  },
  {
    "text": "our training is already underway um I",
    "start": "454560",
    "end": "457199"
  },
  {
    "text": "want to verify that we've got a",
    "start": "457199",
    "end": "459319"
  },
  {
    "text": "checkpoint in our checkpoints directory",
    "start": "459319",
    "end": "462039"
  },
  {
    "text": "excellent so I can see we've got some",
    "start": "462039",
    "end": "463599"
  },
  {
    "text": "previous checkpoints written meaning",
    "start": "463599",
    "end": "465960"
  },
  {
    "text": "that uh we can go ahead with the",
    "start": "465960",
    "end": "468080"
  },
  {
    "text": "simulation of our autor resume to inject",
    "start": "468080",
    "end": "470240"
  },
  {
    "text": "a failure into one of the cluster nodes",
    "start": "470240",
    "end": "472960"
  },
  {
    "start": "472000",
    "end": "573000"
  },
  {
    "text": "and show how hyperpod will automatically",
    "start": "472960",
    "end": "475520"
  },
  {
    "text": "resume from the latest checkpoint uh to",
    "start": "475520",
    "end": "480479"
  },
  {
    "text": "uh recover from Hardware failure during",
    "start": "480479",
    "end": "482440"
  },
  {
    "text": "the training",
    "start": "482440",
    "end": "484639"
  },
  {
    "text": "process okay on the left hand side I'm",
    "start": "484639",
    "end": "487120"
  },
  {
    "text": "outputting the job logs and on the right",
    "start": "487120",
    "end": "489120"
  },
  {
    "text": "hand side I've sshed into one of the",
    "start": "489120",
    "end": "491120"
  },
  {
    "text": "nodes which my job is running on if I",
    "start": "491120",
    "end": "493360"
  },
  {
    "text": "run Nvidia SMI I can see that there are",
    "start": "493360",
    "end": "495800"
  },
  {
    "text": "processes running on the",
    "start": "495800",
    "end": "497360"
  },
  {
    "text": "gpus now I'm going to inject an ECC",
    "start": "497360",
    "end": "500479"
  },
  {
    "text": "error using Nvidia",
    "start": "500479",
    "end": "502840"
  },
  {
    "text": "dcgm into this node and then kill the",
    "start": "502840",
    "end": "506120"
  },
  {
    "text": "python processes which are running the",
    "start": "506120",
    "end": "507879"
  },
  {
    "text": "training job this will simulate a health",
    "start": "507879",
    "end": "510960"
  },
  {
    "text": "uh node",
    "start": "510960",
    "end": "513120"
  },
  {
    "text": "failure on this node during",
    "start": "513120",
    "end": "518279"
  },
  {
    "text": "training so I killed the python process",
    "start": "519560",
    "end": "522120"
  },
  {
    "text": "and on the left side you can see that",
    "start": "522120",
    "end": "524159"
  },
  {
    "text": "the job has failed and sagemaker",
    "start": "524159",
    "end": "526360"
  },
  {
    "text": "hyperpod autor resume is now running",
    "start": "526360",
    "end": "528360"
  },
  {
    "text": "checks on the cluster nodes to determine",
    "start": "528360",
    "end": "531640"
  },
  {
    "text": "if any of them are unhealthy",
    "start": "531640",
    "end": "535360"
  },
  {
    "text": "sagemaker cluster agent is currently",
    "start": "541320",
    "end": "543040"
  },
  {
    "text": "communicating with the cluster nodes now",
    "start": "543040",
    "end": "545680"
  },
  {
    "text": "it has Q job 7 and is waiting for",
    "start": "545680",
    "end": "548760"
  },
  {
    "text": "resources so node 101 4978 has been",
    "start": "548760",
    "end": "554160"
  },
  {
    "text": "removed from my training job the job has",
    "start": "554160",
    "end": "556680"
  },
  {
    "text": "been paused I've now been kicked out of",
    "start": "556680",
    "end": "559200"
  },
  {
    "text": "that node because sagemaker hyperpod has",
    "start": "559200",
    "end": "561200"
  },
  {
    "text": "terminated the node and hyperpod will",
    "start": "561200",
    "end": "564880"
  },
  {
    "text": "bring up a new replacement node execute",
    "start": "564880",
    "end": "567320"
  },
  {
    "text": "the life cycle scripts bring that Noe",
    "start": "567320",
    "end": "569560"
  },
  {
    "text": "into the cluster and resume the training",
    "start": "569560",
    "end": "571399"
  },
  {
    "text": "job without any manual intervention",
    "start": "571399",
    "end": "573640"
  },
  {
    "text": "we'll be back in just a few minutes to",
    "start": "573640",
    "end": "575320"
  },
  {
    "text": "view this job resuming from the latest",
    "start": "575320",
    "end": "578839"
  },
  {
    "text": "checkpoint okay welcome back we've been",
    "start": "578839",
    "end": "581640"
  },
  {
    "text": "tracking our job logs for our",
    "start": "581640",
    "end": "583360"
  },
  {
    "text": "distributed training job since we",
    "start": "583360",
    "end": "584959"
  },
  {
    "text": "injected the error on one of the cluster",
    "start": "584959",
    "end": "587839"
  },
  {
    "text": "nodes and we can see that the job is now",
    "start": "587839",
    "end": "590880"
  },
  {
    "text": "resuming uh so sagemaker hyperpod has",
    "start": "590880",
    "end": "594440"
  },
  {
    "text": "shrunk the job to three nodes and",
    "start": "594440",
    "end": "598079"
  },
  {
    "text": "then uh restarted the training job from",
    "start": "598079",
    "end": "601240"
  },
  {
    "text": "the latest",
    "start": "601240",
    "end": "602519"
  },
  {
    "text": "checkpoint here is a live output of the",
    "start": "602519",
    "end": "604680"
  },
  {
    "text": "job logs and on the left hand",
    "start": "604680",
    "end": "608839"
  },
  {
    "text": "side I can",
    "start": "608839",
    "end": "610720"
  },
  {
    "text": "run s info and SQ I see that job five",
    "start": "610720",
    "end": "616680"
  },
  {
    "text": "has resumed training on the right hand",
    "start": "616680",
    "end": "619480"
  },
  {
    "text": "side we have our iterations uh now",
    "start": "619480",
    "end": "623880"
  },
  {
    "text": "appearing again as well so this involved",
    "start": "623880",
    "end": "626839"
  },
  {
    "text": "no manual intervention on my part other",
    "start": "626839",
    "end": "629839"
  },
  {
    "text": "than injecting the job failure on the",
    "start": "629839",
    "end": "631760"
  },
  {
    "text": "Node sagemaker hyperpod detected the",
    "start": "631760",
    "end": "634760"
  },
  {
    "text": "failure isolated the bad node replace",
    "start": "634760",
    "end": "637760"
  },
  {
    "text": "the bad node and resume the training job",
    "start": "637760",
    "end": "640160"
  },
  {
    "text": "from the latest",
    "start": "640160",
    "end": "641959"
  },
  {
    "text": "checkpoint thanks for watching in this",
    "start": "641959",
    "end": "644440"
  },
  {
    "start": "642000",
    "end": "710000"
  },
  {
    "text": "video we demonstrated how to train llama",
    "start": "644440",
    "end": "647519"
  },
  {
    "text": "7B using sagemaker model parallel in fp8",
    "start": "647519",
    "end": "651240"
  },
  {
    "text": "on sagemaker hyperpod we also",
    "start": "651240",
    "end": "653480"
  },
  {
    "text": "demonstrated how to trigger an autor",
    "start": "653480",
    "end": "656399"
  },
  {
    "text": "resume action with sagemaker hyperpod by",
    "start": "656399",
    "end": "658560"
  },
  {
    "text": "injecting a fail on the Node and",
    "start": "658560",
    "end": "660360"
  },
  {
    "text": "watching the job resume gracefully from",
    "start": "660360",
    "end": "663040"
  },
  {
    "text": "the latest save checkpoint without any",
    "start": "663040",
    "end": "665440"
  },
  {
    "text": "manual intervention if you enjoyed the",
    "start": "665440",
    "end": "667480"
  },
  {
    "text": "uh content in this video please check",
    "start": "667480",
    "end": "669480"
  },
  {
    "text": "out the resources on this slide which",
    "start": "669480",
    "end": "671480"
  },
  {
    "text": "includes a overview of sagemaker",
    "start": "671480",
    "end": "673760"
  },
  {
    "text": "hyperpod as well as our sagemaker",
    "start": "673760",
    "end": "675480"
  },
  {
    "text": "hyperpod Workshop which contains all the",
    "start": "675480",
    "end": "677519"
  },
  {
    "text": "resources you need to get started",
    "start": "677519",
    "end": "679360"
  },
  {
    "text": "running distributed training on",
    "start": "679360",
    "end": "680639"
  },
  {
    "text": "sagemaker hyperpod today as well as a",
    "start": "680639",
    "end": "683279"
  },
  {
    "text": "plethora of best practices picked up uh",
    "start": "683279",
    "end": "686680"
  },
  {
    "text": "that that we our team shares with you",
    "start": "686680",
    "end": "689399"
  },
  {
    "text": "finally we link our awesome distributed",
    "start": "689399",
    "end": "691000"
  },
  {
    "text": "training repository which contains test",
    "start": "691000",
    "end": "693440"
  },
  {
    "text": "cases for a number of popular Frameworks",
    "start": "693440",
    "end": "695519"
  },
  {
    "text": "including deep speed P torch",
    "start": "695519",
    "end": "698200"
  },
  {
    "text": "fsdp sagemaker model parallel and",
    "start": "698200",
    "end": "700639"
  },
  {
    "text": "sagemaker distributed data parallel my",
    "start": "700639",
    "end": "703399"
  },
  {
    "text": "name is Matt Nill thanks so much for",
    "start": "703399",
    "end": "705000"
  },
  {
    "text": "watching today's video and happy",
    "start": "705000",
    "end": "706639"
  },
  {
    "text": "training",
    "start": "706639",
    "end": "709639"
  }
]
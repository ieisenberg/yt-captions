[
  {
    "text": "thanks for coming I'm Mike Franklin from UC Berkeley and I have with me mattei",
    "start": "0",
    "end": "5670"
  },
  {
    "text": "zaharia and we're going to talk to you today about a couple things we both",
    "start": "5670",
    "end": "14880"
  },
  {
    "text": "members of a group at Berkeley called the amp lab and amp lab is a is a big",
    "start": "14880",
    "end": "20520"
  },
  {
    "text": "data analytics research project and I mean that in the good way of research project not the bad way but we've been",
    "start": "20520",
    "end": "30300"
  },
  {
    "text": "developing a new software stack for big data analytics and what we're going to",
    "start": "30300",
    "end": "36120"
  },
  {
    "text": "do today is I want to tell you first a little bit about the amp lab what our mission is how we're organized what",
    "start": "36120",
    "end": "42899"
  },
  {
    "text": "we're trying to do and then matei is going to come up and tell you about two specific pieces of software that that",
    "start": "42899",
    "end": "50399"
  },
  {
    "text": "we've already released and that are starting to see increasing use spark",
    "start": "50399",
    "end": "55920"
  },
  {
    "text": "which is a analytics framework and then",
    "start": "55920",
    "end": "61050"
  },
  {
    "text": "shark which is a actually a port of the hive SQL processor on top of spark and",
    "start": "61050",
    "end": "68960"
  },
  {
    "text": "you'll see some more about those so when I just jump into it so I'm not gonna",
    "start": "68960",
    "end": "74700"
  },
  {
    "text": "spend a lot of time on this but where's big data coming from you know it's click streams and logs it's you know",
    "start": "74700",
    "end": "80729"
  },
  {
    "text": "user-generated content machine-to-machine sensors and things like that and also scientific computing",
    "start": "80729",
    "end": "87540"
  },
  {
    "text": "these are all very different types of applications but they all share the common issue that they're becoming more",
    "start": "87540",
    "end": "95040"
  },
  {
    "text": "and more data-driven and so what does this mean for technology the answer is",
    "start": "95040",
    "end": "101549"
  },
  {
    "text": "going to be I'll give you sort of the standard answer first and then I'll tell you the amp lab answer so the standard answer is the the 3 v's right so volume",
    "start": "101549",
    "end": "110280"
  },
  {
    "text": "in terms of more and more data that you have to understand variety in terms of the fact that the data is coming from",
    "start": "110280",
    "end": "116850"
  },
  {
    "text": "all sorts of places maybe it's not very well integrated maybe it's not complete maybe it's not a hundred percent",
    "start": "116850",
    "end": "123380"
  },
  {
    "text": "validated and then velocity the fact that you're getting more and more data as time goes on and in the amp lab",
    "start": "123380",
    "end": "133510"
  },
  {
    "text": "we're addressing all these problems but our view is is just slightly different and really what we're trying the problem",
    "start": "133510",
    "end": "139989"
  },
  {
    "text": "we're trying to solve is that we believe that if you're given more data you",
    "start": "139989",
    "end": "145810"
  },
  {
    "text": "should be happier right so if you're given more data you should get a better answer and that's just not really what",
    "start": "145810",
    "end": "152349"
  },
  {
    "text": "happens in a lot of situations right now and there's really two reasons why if you think about data is sort of a table",
    "start": "152349",
    "end": "158829"
  },
  {
    "text": "there's it can grow in two dimensions right so you can get more records right and get more rows of your table and in",
    "start": "158829",
    "end": "165849"
  },
  {
    "text": "that case you end up with sort of a standard scalability problem you have to be able to deal with more and more pieces of data to make sense of the",
    "start": "165849",
    "end": "172480"
  },
  {
    "text": "information okay but you can also and as you as you start doing more and more analysis and growing your applications",
    "start": "172480",
    "end": "179590"
  },
  {
    "text": "you also get horizontal growth you start getting more dimensions more columns and the scalability problem you get from",
    "start": "179590",
    "end": "185680"
  },
  {
    "text": "those additional dimensions is very different and what you end up with there",
    "start": "185680",
    "end": "191530"
  },
  {
    "text": "is more of an inference problem that as you collect more and more dimensions of",
    "start": "191530",
    "end": "197709"
  },
  {
    "text": "data about more and more things you can basically find yourself with evidence for pretty much any hypothesis you'd",
    "start": "197709",
    "end": "203620"
  },
  {
    "text": "like to try to find evidence for and so if you're not very careful the quality of your inference can can really degrade",
    "start": "203620",
    "end": "211269"
  },
  {
    "text": "to the point where you you're really not getting useful information out of the system and so you know it is a big",
    "start": "211269",
    "end": "217750"
  },
  {
    "text": "scalability problem in terms of dealing with you know the amount of data and and that's largely what we're going to talk",
    "start": "217750",
    "end": "224019"
  },
  {
    "text": "about today in terms of spark and shark but we're also focused on this inference problem and try and understand you know",
    "start": "224019",
    "end": "230019"
  },
  {
    "text": "how to deal with this problem of having just much more information about about",
    "start": "230019",
    "end": "235900"
  },
  {
    "text": "the things that you're trying to understand and what this ends up happening what this ends up turning into is really what you want to do is you",
    "start": "235900",
    "end": "243280"
  },
  {
    "text": "want to navigate this three dimensional space which is you have some problem you're trying to solve or some decision",
    "start": "243280",
    "end": "248379"
  },
  {
    "text": "you're trying to make and you have a certain you know budget that you can use to do your data analysis you have a",
    "start": "248379",
    "end": "254889"
  },
  {
    "text": "certain amount of time to make that decision and in order to make your decision with sufficient confidence you",
    "start": "254889",
    "end": "260349"
  },
  {
    "text": "have to have a certain you know answer quality and these things all trade off against each other you can spend more",
    "start": "260349",
    "end": "266260"
  },
  {
    "text": "money and get a faster answer you can be willing to accept an approximate answer and then get your",
    "start": "266260",
    "end": "272210"
  },
  {
    "text": "answer cheaper or faster and so the stack that we're building is going to allow users to make this trade-off in",
    "start": "272210",
    "end": "278810"
  },
  {
    "text": "these three dimensions and so our view of the big data problem is really these two things that you want to be able to handle both horizontal and physical",
    "start": "278810",
    "end": "285380"
  },
  {
    "text": "corazon ttle and vertical growth of your data and you want to be able to navigate this three dimensional space so that",
    "start": "285380",
    "end": "291290"
  },
  {
    "text": "people can get their problem solved now the project that we're involved in is is",
    "start": "291290",
    "end": "299000"
  },
  {
    "text": "a collaboration of people at Berkeley with support from both you know the",
    "start": "299000",
    "end": "304520"
  },
  {
    "text": "federal research organizations as well as a bunch of companies which I'll tell you about but I just wanted to mention",
    "start": "304520",
    "end": "310760"
  },
  {
    "text": "we were featured on some of you might know that in the spring the White House announced the big data research",
    "start": "310760",
    "end": "316310"
  },
  {
    "text": "initiative where they were trying to get a lot of the government agencies to start supporting more and more big data",
    "start": "316310",
    "end": "322460"
  },
  {
    "text": "research and the amp lab was featured in the White House announcement as one of the first projects that was basically",
    "start": "322460",
    "end": "329000"
  },
  {
    "text": "being funded under this under this initiative and so we have a key role in",
    "start": "329000",
    "end": "334070"
  },
  {
    "text": "in this Big Data initiative and our view is really that in order to make sense of",
    "start": "334070",
    "end": "344050"
  },
  {
    "text": "this massive and diverse data there's really three types of resources that you have and this is where the name of the",
    "start": "344050",
    "end": "350660"
  },
  {
    "text": "lab comes from you have algorithms in the form of you know machine learning",
    "start": "350660",
    "end": "356150"
  },
  {
    "text": "statistical processes and things like that you have machines in terms of cloud",
    "start": "356150",
    "end": "361400"
  },
  {
    "text": "computing cluster computing that's why we're here today and then the the P and amp lab is people so we also work with",
    "start": "361400",
    "end": "369230"
  },
  {
    "text": "Amazon Mechanical Turk to do crowdsourcing and human computation and",
    "start": "369230",
    "end": "374270"
  },
  {
    "text": "the idea is that we want to build an infrastructure that basically integrates these three very different types of",
    "start": "374270",
    "end": "380450"
  },
  {
    "text": "resources again to solve the big data problem that you know we just defined previously so that's really our",
    "start": "380450",
    "end": "387730"
  },
  {
    "text": "overarching goal is to build the system that's not just a faster you know SQL",
    "start": "387730",
    "end": "393500"
  },
  {
    "text": "system although today we're going to convince you hopefully that we have a faster SQL system but we want to really",
    "start": "393500",
    "end": "399650"
  },
  {
    "text": "integrate these very different resources to solve really hard analytical problems not just simple",
    "start": "399650",
    "end": "404939"
  },
  {
    "text": "reporting so we're making a few big bets it is a research project and our biggest",
    "start": "404939",
    "end": "411509"
  },
  {
    "text": "bed is really the following that even if you look at you know current no sequel stacks and and you know kind of line",
    "start": "411509",
    "end": "417569"
  },
  {
    "text": "those up say compared to something that like a traditional database architecture from you know 10 or 20 years ago you'll",
    "start": "417569",
    "end": "423180"
  },
  {
    "text": "see that the the organization of the software the architecture is really not that much different that you know you",
    "start": "423180",
    "end": "430020"
  },
  {
    "text": "have file systems you have you know some sort of indexing and so on and our",
    "start": "430020",
    "end": "436139"
  },
  {
    "text": "belief is that if you really want to solve this this analytics problem what you want to do is is is kind of start",
    "start": "436139",
    "end": "441779"
  },
  {
    "text": "from scratch and you really want to take you know a state-of-the-art machine",
    "start": "441779",
    "end": "446849"
  },
  {
    "text": "learning state-of-the-art systems processing state-of-the-art data management get people that understand",
    "start": "446849",
    "end": "452430"
  },
  {
    "text": "all these things together try to get them to work together and and think about what would the system you could",
    "start": "452430",
    "end": "457800"
  },
  {
    "text": "build if you could build things from scratch look like because you know we that's one of the luxuries we have of being at the university is we can do",
    "start": "457800",
    "end": "463919"
  },
  {
    "text": "that it's kind of our responsibility to do that and so we've structured the project in a way to get people with",
    "start": "463919",
    "end": "469110"
  },
  {
    "text": "these very different backgrounds to work together and I'll tell you just a little bit about how we do that in a second the",
    "start": "469110",
    "end": "474960"
  },
  {
    "text": "other thing is it's a great time to be doing this kind of work there are demands on systems it just aren't",
    "start": "474960",
    "end": "481050"
  },
  {
    "text": "currently met low latency being a big one the idea that people you know I'm a database guy by training you know",
    "start": "481050",
    "end": "487650"
  },
  {
    "text": "database people are always taught that there's a right answer and then all the other answers are wrong and that's",
    "start": "487650",
    "end": "492990"
  },
  {
    "text": "really not true in a lot of scenarios and so this is ability to provide variable consistency the fact that we",
    "start": "492990",
    "end": "500789"
  },
  {
    "text": "have the cloud and we have elastic resources gives us tremendous ability to take on harder problems scale up the",
    "start": "500789",
    "end": "507779"
  },
  {
    "text": "resources when we need them scale them back down when we don't and really there's just something that I haven't",
    "start": "507779",
    "end": "513659"
  },
  {
    "text": "seen in a couple decades I've been working in this field it's just this tremendous willingness for people you",
    "start": "513659",
    "end": "518880"
  },
  {
    "text": "know even in mission-critical applications to try new technology and so it's a great time to be you know",
    "start": "518880",
    "end": "524699"
  },
  {
    "text": "doing doing work building systems you know throwing it over to the fence and trying to get trying to get people to",
    "start": "524699",
    "end": "529800"
  },
  {
    "text": "use it because you get a very quick traction and and Matteo tell you",
    "start": "529800",
    "end": "534870"
  },
  {
    "text": "little bit about how we're doing in that regard so you know it's a lot of opportunities that have come together to",
    "start": "534870",
    "end": "540120"
  },
  {
    "text": "make this work feasible and then the other big bet we're making which is in a longer term is as I was mentioning you",
    "start": "540120",
    "end": "547200"
  },
  {
    "text": "know if you could bring people in through a system like Mechanical Turk or other crowd sourcing platforms you know",
    "start": "547200",
    "end": "552750"
  },
  {
    "text": "how do you use that very very expensive very kind of finicky resource in the",
    "start": "552750",
    "end": "558510"
  },
  {
    "text": "best way so that you can problems that current computers and current machine learning algorithms just can't solve and",
    "start": "558510",
    "end": "563520"
  },
  {
    "text": "so you want to build a hybrid system that can do this so those are our big bets and just a little bit about how we",
    "start": "563520",
    "end": "570620"
  },
  {
    "text": "organize the lab in order to make this happen we grabbed a bunch of people from a bunch of different areas so you know",
    "start": "570620",
    "end": "577020"
  },
  {
    "text": "databases systems networking machine learning and so on and we actually put",
    "start": "577020",
    "end": "582210"
  },
  {
    "text": "them all in a single room so we had a bunch of these professors that I've listed up here all agree to give up",
    "start": "582210",
    "end": "588390"
  },
  {
    "text": "their officers move into a common space with about 50 grad students and postdocs",
    "start": "588390",
    "end": "594089"
  },
  {
    "text": "and the idea is to get these people who have very different interest in training",
    "start": "594089",
    "end": "599700"
  },
  {
    "text": "and background to all work together to solve this hard problem so we've set things up that way physically we also",
    "start": "599700",
    "end": "605430"
  },
  {
    "text": "set things up in a way we have where we have continuous interaction and collaboration with our industrial",
    "start": "605430",
    "end": "611040"
  },
  {
    "text": "partners and this is an example I have a picture here of one of our by annual or",
    "start": "611040",
    "end": "617430"
  },
  {
    "text": "semiannual research retreats where we get about a hundred and fifty people together to you know talk about the",
    "start": "617430",
    "end": "622560"
  },
  {
    "text": "current state of the project in the current state of big data in general and",
    "start": "622560",
    "end": "628279"
  },
  {
    "text": "so we launched the beginning of last year it's a six year project amazon web",
    "start": "628279",
    "end": "634890"
  },
  {
    "text": "services is one of our major sponsors that's one of the reasons we're here today along with google + sa p and then",
    "start": "634890",
    "end": "641580"
  },
  {
    "text": "a bunch of other companies have also signed on to sponsor the labs we currently have 17 there's actually an",
    "start": "641580",
    "end": "646950"
  },
  {
    "text": "18th company that's just joined but we have very excellent interaction with",
    "start": "646950",
    "end": "652350"
  },
  {
    "text": "these companies we get a lot of feedback from them and we have a lot of collaboration with them so we're very focused on working with industry we have",
    "start": "652350",
    "end": "659490"
  },
  {
    "text": "this role that we're playing in the Big Data initiative which I told you about and so we're really you know combining",
    "start": "659490",
    "end": "665550"
  },
  {
    "text": "the the government and industrial sponsorship in this project and what we're doing and that's what",
    "start": "665550",
    "end": "671730"
  },
  {
    "text": "matei is going to be telling you mostly about is we're releasing a software",
    "start": "671730",
    "end": "676740"
  },
  {
    "text": "stack the Berkeley data analytics system that we're releasing as open source",
    "start": "676740",
    "end": "681779"
  },
  {
    "text": "software trying to get as many people to use it as possible okay so in order to",
    "start": "681779",
    "end": "687990"
  },
  {
    "text": "do our work let me just tell you briefly about a couple applications that we're working on just to give you feel right",
    "start": "687990",
    "end": "693630"
  },
  {
    "text": "because if you want to do research on big data you have to have some big data applications and so one of the",
    "start": "693630",
    "end": "698700"
  },
  {
    "text": "applications that we've released is something called carrot and what carrot does is it's a collaborative system for",
    "start": "698700",
    "end": "705209"
  },
  {
    "text": "detecting problems with battery life on cell phones so you download the carrot application let me build this out it",
    "start": "705209",
    "end": "713180"
  },
  {
    "text": "periodically reports back to the cloud about what's going on in your phone in terms of what applications are running",
    "start": "713180",
    "end": "719430"
  },
  {
    "text": "are you moving around what's happening to your battery it collects that from all the people that are running the",
    "start": "719430",
    "end": "724500"
  },
  {
    "text": "application and currently we're up to about half a million downloads of this application and then it figures out",
    "start": "724500",
    "end": "729930"
  },
  {
    "text": "things are going on your in your phone that it says jeez you know you're running these applications these have",
    "start": "729930",
    "end": "735450"
  },
  {
    "text": "been correlated with with heavy battery drain on these other devices maybe you",
    "start": "735450",
    "end": "741209"
  },
  {
    "text": "should look at shutting that off and then it'll tell you you know if you do that we estimate you get about an hour",
    "start": "741209",
    "end": "746610"
  },
  {
    "text": "and a half of additional battery life out of your phone and it also tells you uh we know we're very careful so that it",
    "start": "746610",
    "end": "755550"
  },
  {
    "text": "doesn't use much battery but I guess it would tell you to kill itself if it did it also will look for things that are",
    "start": "755550",
    "end": "762089"
  },
  {
    "text": "happening on your phone there are anomalies and tell you hey you know you seem to have something misconfigured you know maybe your Google Maps application",
    "start": "762089",
    "end": "767490"
  },
  {
    "text": "needs to be reinstalled and so on so you know this is a great EMP application because you know it's doing the crowd",
    "start": "767490",
    "end": "774449"
  },
  {
    "text": "sourcing of the data it's bring it's bringing things into the cloud running machine learning algorithms on them and",
    "start": "774449",
    "end": "780209"
  },
  {
    "text": "then reporting that data back out that's one of our driving applications another one which you'll let me just build this",
    "start": "780209",
    "end": "789449"
  },
  {
    "text": "out sorry another one we're doing is we have a big effort on cancer tumor genomics and the short story there is",
    "start": "789449",
    "end": "796949"
  },
  {
    "text": "that the cost of sequencing genomes has been decreasing by about factor of 10 every two years which if",
    "start": "796949",
    "end": "802920"
  },
  {
    "text": "you're familiar with Moore's Law you'll realize is a lot faster than Moore's Law so basically what's happening in",
    "start": "802920",
    "end": "808680"
  },
  {
    "text": "genetics is that computers are getting slower and slower every year and this is turning into first of all the ability to",
    "start": "808680",
    "end": "815610"
  },
  {
    "text": "generate more and more data so it is a big data problem it's also a big computation problem because you want to",
    "start": "815610",
    "end": "821250"
  },
  {
    "text": "try to make sense of all this information and so we're collaborating with people at UCS UCSF which is medical",
    "start": "821250",
    "end": "828240"
  },
  {
    "text": "school at University of California and and other places to bring together a lot",
    "start": "828240",
    "end": "834480"
  },
  {
    "text": "of genomic information and to use you know Big Data technology to try to rethink what some of the basic",
    "start": "834480",
    "end": "841139"
  },
  {
    "text": "processing algorithms for bioinformatics should look like and Dave Patterson who",
    "start": "841139",
    "end": "847019"
  },
  {
    "text": "is sitting up in the front row here is giving a talk on this tomorrow and you",
    "start": "847019",
    "end": "852540"
  },
  {
    "text": "should make a note of that and she up to that talk he'll go into more detail on this so you know two very different",
    "start": "852540",
    "end": "857550"
  },
  {
    "text": "types of applications but they give you an idea of sort of the scope of what we're trying to do in the lab just to",
    "start": "857550",
    "end": "865050"
  },
  {
    "text": "look at the current state of the stack you know you kind of read it from the bottom up so I kind of went with the",
    "start": "865050",
    "end": "872399"
  },
  {
    "text": "Howard Johnson's coloring scheme here but that's kind of the default but you",
    "start": "872399",
    "end": "877529"
  },
  {
    "text": "know basically we interact with a bunch of third-party stuff which is the the stuff that's in white and then we've",
    "start": "877529",
    "end": "883440"
  },
  {
    "text": "already released the orange pieces and the blue pieces of things we're working on and so basically we're we're built on",
    "start": "883440",
    "end": "890339"
  },
  {
    "text": "the Hadoop file system we have the Mesa system which we're not going to talk about today which is a basically a",
    "start": "890339",
    "end": "895980"
  },
  {
    "text": "cluster virtualization layer which is actually in use in a number of places twitter is probably the heaviest user of",
    "start": "895980",
    "end": "901829"
  },
  {
    "text": "it they're running at last count I heard about 2,500 machines on it in production and it's an interesting system on its",
    "start": "901829",
    "end": "908760"
  },
  {
    "text": "own in its own right that you know you should look into spark and shark you're going to hear about next basically it's",
    "start": "908760",
    "end": "915690"
  },
  {
    "text": "a kind of a MapReduce and hive layer that it's basically optimized for low",
    "start": "915690",
    "end": "923699"
  },
  {
    "text": "latency interaction and for iterative computation so a lot of machine learning algorithms need to go over the data",
    "start": "923699",
    "end": "929760"
  },
  {
    "text": "continuously you know repeatedly it's a really bad use case for group for hadoop mapreduce and we've",
    "start": "929760",
    "end": "936799"
  },
  {
    "text": "optimized that and so spark and shark have been released and you'll be hearing more about that from matei in a minute",
    "start": "936799",
    "end": "942170"
  },
  {
    "text": "or two we're building streaming versions of those so that you can not only get low latency queries but you can also for",
    "start": "942170",
    "end": "949009"
  },
  {
    "text": "standing queries get you know instantaneous answers as the data is flowing in and spark we have a streaming",
    "start": "949009",
    "end": "955519"
  },
  {
    "text": "version of it running once we get shark running on top of that then we'll have a streaming SQL implementation which is a",
    "start": "955519",
    "end": "961850"
  },
  {
    "text": "pretty interesting thing on top of that we start moving more into the machine",
    "start": "961850",
    "end": "967549"
  },
  {
    "text": "learning realm and so blink DB is a is a system that's meant for doing that trade-off I was talking to you about of",
    "start": "967549",
    "end": "973429"
  },
  {
    "text": "answer quality versus time and cost and so with blink DB you can specify you",
    "start": "973429",
    "end": "978589"
  },
  {
    "text": "know either a deadline for when you want your answer or a requirement on answer",
    "start": "978589",
    "end": "983899"
  },
  {
    "text": "confidence and then the system will run as long as it takes you to get you that much confidence and so it's an approximate query answering system on",
    "start": "983899",
    "end": "990230"
  },
  {
    "text": "top of that we're building something called ml base which is basically supposed to allow machine learning to be",
    "start": "990230",
    "end": "996079"
  },
  {
    "text": "done by mere mortals so you specified a very high level in a declarative way what type of machine learning you want",
    "start": "996079",
    "end": "1003189"
  },
  {
    "text": "to do and then the system underneath the covers does optimisation that figures out which algorithms to run and that's",
    "start": "1003189",
    "end": "1008889"
  },
  {
    "text": "where we're going in the in the long term so today we're going to talk about spark and shark they're available Mesa",
    "start": "1008889",
    "end": "1015790"
  },
  {
    "text": "is available the other stuff is coming and our plans are to release it all as apache or bsd and so we want lots of",
    "start": "1015790",
    "end": "1022779"
  },
  {
    "text": "people to use it so basically where we're going you know is really we're going up the stack where you know trying",
    "start": "1022779",
    "end": "1029980"
  },
  {
    "text": "to support sampling in a very efficient way we're refactoring some things in the",
    "start": "1029980",
    "end": "1034990"
  },
  {
    "text": "memory layered matei will tell you about you know how we exploit memory to get things to go faster and so we're trying",
    "start": "1034990",
    "end": "1041260"
  },
  {
    "text": "to make that a shareable resource the streaming stuff I told you about we're integrating graph processing into the",
    "start": "1041260",
    "end": "1048820"
  },
  {
    "text": "system that didn't show on show on that picture that I showed yet because not quite put into the stack yet and the",
    "start": "1048820",
    "end": "1055419"
  },
  {
    "text": "declarative machine learning and then we're again going to refactor the code",
    "start": "1055419",
    "end": "1061330"
  },
  {
    "text": "so that we have some common libraries that you can do use for machine learning when that's the right thing",
    "start": "1061330",
    "end": "1066700"
  },
  {
    "text": "do for relational database query processing when that's the right thing to do but yet have a common optimization",
    "start": "1066700",
    "end": "1072490"
  },
  {
    "text": "infrastructure this is all stuff it's a six year project it's all stuff that's you know coming down the pike so with",
    "start": "1072490",
    "end": "1080440"
  },
  {
    "text": "that I think what I want to do is ask potato come up just I'll give a little",
    "start": "1080440",
    "end": "1086320"
  },
  {
    "text": "plug you know there's our website we try to keep that pretty up-to-date in terms",
    "start": "1086320",
    "end": "1091510"
  },
  {
    "text": "of what's going on in the lab and you know what software is being released and what research projects are going on we",
    "start": "1091510",
    "end": "1097420"
  },
  {
    "text": "have user groups and meetups for the release software that mckays going to",
    "start": "1097420",
    "end": "1102550"
  },
  {
    "text": "tell you about and then Matteo also i'm sure tell you how to get ahold of the stuff at github and so on so with that",
    "start": "1102550",
    "end": "1109900"
  },
  {
    "text": "the pain won't you come up okay thanks",
    "start": "1109900",
    "end": "1119440"
  },
  {
    "text": "Mike okay all right so I'm going to talk about two of the open source components",
    "start": "1119440",
    "end": "1125830"
  },
  {
    "text": "we've released so far spark and shark and these are both projects that are actually like starting to be used in",
    "start": "1125830",
    "end": "1131830"
  },
  {
    "text": "production at a number of companies and it's been very exciting to us to work with them and to work with the Hadoop",
    "start": "1131830",
    "end": "1137680"
  },
  {
    "text": "community to build these projects so let me start with with spark so spark is the",
    "start": "1137680",
    "end": "1145120"
  },
  {
    "text": "amp labs parallel computing platform meant to be a next generation system in",
    "start": "1145120",
    "end": "1151570"
  },
  {
    "text": "the line after things like mapreduce and it it achieves actually significantly higher performance than MapReduce in two",
    "start": "1151570",
    "end": "1160390"
  },
  {
    "text": "ways so one way is that it's designed to support in memory storage and quay",
    "start": "1160390",
    "end": "1165850"
  },
  {
    "text": "processing and this is important if you ever have a data set you're going over multiple times so it's important if you",
    "start": "1165850",
    "end": "1172240"
  },
  {
    "text": "have interactive you know quays you're asking about data the low latency ones we heard about before but it's also",
    "start": "1172240",
    "end": "1177730"
  },
  {
    "text": "important in a lot of the more sophisticated algorithms out there today that are iterative things like machine",
    "start": "1177730",
    "end": "1183850"
  },
  {
    "text": "learning page rank and so on that go over the data multiple times the second",
    "start": "1183850",
    "end": "1189100"
  },
  {
    "text": "thing that spark ads is a general execution graphs so it's not just map",
    "start": "1189100",
    "end": "1194620"
  },
  {
    "text": "and reduce and these provide some substantial speedups even if the data isn't in memory so as a whole",
    "start": "1194620",
    "end": "1201040"
  },
  {
    "text": "when you put these together we found that can go about a hundred times faster than hadoop in in real applications if",
    "start": "1201040",
    "end": "1206980"
  },
  {
    "text": "the data is in memory and also two to ten times faster if it's on disk and it is a new code base it's not like a",
    "start": "1206980",
    "end": "1213460"
  },
  {
    "text": "modified version of Hadoop but it's designed to be highly compatible so it supports HDFS HBase amazon s3 it runs",
    "start": "1213460",
    "end": "1221170"
  },
  {
    "text": "well on ec2 and is designed to be highly compatible with her do what is shark so",
    "start": "1221170",
    "end": "1228400"
  },
  {
    "text": "sharp you know if sparkies is great as a lower level thing for writing programs but we found a lot of users once to hunt",
    "start": "1228400",
    "end": "1234850"
  },
  {
    "text": "sequel and shark is is a sequel engine that runs on top of spark and in particular we did that by pointing",
    "start": "1234850",
    "end": "1241240"
  },
  {
    "text": "Apache hive so Apache hi vis you guys know is very popular and mature sequel",
    "start": "1241240",
    "end": "1246910"
  },
  {
    "text": "engine for Hadoop and by pointing a ton and spark were able to maintain compatibility with data that's in hive",
    "start": "1246910",
    "end": "1253540"
  },
  {
    "text": "and with squeeze and user-defined functions and basically all of the complex features that are in hive but at",
    "start": "1253540",
    "end": "1260260"
  },
  {
    "text": "the same time to make a ton a lot faster so the same speed ups I was talking about 2 100 x can can also be had in",
    "start": "1260260",
    "end": "1268030"
  },
  {
    "text": "hive and both of these components are open source spark has been around since",
    "start": "1268030",
    "end": "1274090"
  },
  {
    "text": "about three years ago we open source said in 2010 and shark was released in",
    "start": "1274090",
    "end": "1280270"
  },
  {
    "text": "april this year and we've also been you know fortunate that they've been picked",
    "start": "1280270",
    "end": "1285310"
  },
  {
    "text": "up and started to be used by a number of companies so yahoo cloud Foursquare",
    "start": "1285310",
    "end": "1290680"
  },
  {
    "text": "Airbnb are just some of the companies that are using these systems and we also",
    "start": "1290680",
    "end": "1296410"
  },
  {
    "text": "have a going user community we own a meetup in the Bay Area we have more than 400 people signed up for the meetup",
    "start": "1296410",
    "end": "1303220"
  },
  {
    "text": "group now and we have contributions from over 20 different developers so we're excited to go these open source projects",
    "start": "1303220",
    "end": "1309940"
  },
  {
    "text": "with you know with with our connections at companies okay so I'm going to go",
    "start": "1309940",
    "end": "1317140"
  },
  {
    "text": "next in into a spark itself just show you a bit about how it works and what",
    "start": "1317140",
    "end": "1322180"
  },
  {
    "text": "you can do with it so spark itself provides this high-level language",
    "start": "1322180",
    "end": "1327610"
  },
  {
    "text": "integrated API for hiding data parallel computations and it's available in Scala in Java and soon it will be available",
    "start": "1327610",
    "end": "1335110"
  },
  {
    "text": "in Python as well and one of the cool things is you can use it interactively from the Scala and Python shelves so you",
    "start": "1335110",
    "end": "1341320"
  },
  {
    "text": "can also type all these quays interactively and and really explore data that way and it is the key way it",
    "start": "1341320",
    "end": "1349900"
  },
  {
    "text": "works is it gives you these distributed collections that you can run operations on there called a zillion distributed",
    "start": "1349900",
    "end": "1356049"
  },
  {
    "text": "data sets or r dds and i'll show exactly how that works ok so in in in this",
    "start": "1356049",
    "end": "1365910"
  },
  {
    "text": "example here i'm going to show something you can do it spark interactively at the",
    "start": "1365910",
    "end": "1371049"
  },
  {
    "text": "scala console i'm going to show the examples in scala to begin with and this is so you have a log file in it in",
    "start": "1371049",
    "end": "1377559"
  },
  {
    "text": "amazon SD or HD FS and the summer is happening and you want to interactively search for hours so we have a cluster",
    "start": "1377559",
    "end": "1384429"
  },
  {
    "text": "here with a master and a bunch of workers so the first thing you type at the console is this this is a scholar",
    "start": "1384429",
    "end": "1391240"
  },
  {
    "text": "code to create a distributed data set representing your file and it you can see it can eat from HDFS and this gives",
    "start": "1391240",
    "end": "1398650"
  },
  {
    "text": "you one of these resilient distributed data sets or r dds next you can apply",
    "start": "1398650",
    "end": "1404020"
  },
  {
    "text": "different transformations on it that will happen in parallel so I'm going to apply a filter I'm this is a collection",
    "start": "1404020",
    "end": "1410230"
  },
  {
    "text": "of lines of text I'm going to filter out the ones that start with there and in there that codon in Redis color syntax",
    "start": "1410230",
    "end": "1417250"
  },
  {
    "text": "for function literal or closure and you can call any scholar or java function you want from in there so is any code",
    "start": "1417250",
    "end": "1423220"
  },
  {
    "text": "you want and so this gives us a transform data set next I'm going to do",
    "start": "1423220",
    "end": "1428559"
  },
  {
    "text": "a map maybe they're tab-separated fields and I want to pull out field number two and then I'm going to tell the system to",
    "start": "1428559",
    "end": "1435010"
  },
  {
    "text": "cache the result of these transformations so just the error message is not the file itself in memory",
    "start": "1435010",
    "end": "1440620"
  },
  {
    "text": "so so far these things have all just defined how we're going to build the data set it hasn't actually gone yet and",
    "start": "1440620",
    "end": "1447400"
  },
  {
    "text": "these things are all lazy they aren't the first time you actually do a query on it so let's do that next so now i'm",
    "start": "1447400",
    "end": "1453429"
  },
  {
    "text": "going to count how many of these error messages contain foo and what the system will do then is figure out where the",
    "start": "1453429",
    "end": "1460540"
  },
  {
    "text": "data is laid out across the cluster and you know this count is called an action and and since that's to the machines the",
    "start": "1460540",
    "end": "1467830"
  },
  {
    "text": "passes the block the elite process don't lock they'll return back results as in a standard MapReduce and they'll also build in",
    "start": "1467830",
    "end": "1475180"
  },
  {
    "text": "memory any partitions of cash datasets they've competed along the way so now those error messages are sitting in",
    "start": "1475180",
    "end": "1481570"
  },
  {
    "text": "memory so the next time you run away on this maybe foo wasn't the problem i searched for bar the tests are going to",
    "start": "1481570",
    "end": "1488620"
  },
  {
    "text": "be scheduled according to memory placement they'll hit the cash and you'll get back results a lot faster and",
    "start": "1488620",
    "end": "1494170"
  },
  {
    "text": "to give you a sense of how fast it is one of the tests we did is just full text you know boot for search of",
    "start": "1494170",
    "end": "1500080"
  },
  {
    "text": "Wikipedia on on 20 easy two nodes it's about 50 gigabytes of data and if you do",
    "start": "1500080",
    "end": "1505840"
  },
  {
    "text": "it with on disk data or with Hadoop it takes about 20 seconds to scan this this",
    "start": "1505840",
    "end": "1511090"
  },
  {
    "text": "data set if you do it with spark and memory it takes about half a second so this is the speed up you get from from",
    "start": "1511090",
    "end": "1517270"
  },
  {
    "text": "putting data and memory and you can imagine you can actually like type these questions into actively at the console",
    "start": "1517270",
    "end": "1522660"
  },
  {
    "text": "we also scaled it up to doing a terabyte of data in about five seconds and this",
    "start": "1522660",
    "end": "1528130"
  },
  {
    "text": "would take three minutes if you just used her do okay the other cool thing",
    "start": "1528130",
    "end": "1533650"
  },
  {
    "text": "about the IDS model that we have is that they automatically provide fault tolerance so I'm not going to go into a",
    "start": "1533650",
    "end": "1539830"
  },
  {
    "text": "ton of detail on this but basically sparkly remember is how you built each data set the filter and map we did here",
    "start": "1539830",
    "end": "1545530"
  },
  {
    "text": "and if one of the nodes go goes away it knows how to recompute that cash so you can really view this as a you know a",
    "start": "1545530",
    "end": "1552010"
  },
  {
    "text": "fault-tolerant collection of items that you can just ask operations on and it will work if you're Costas skills up and",
    "start": "1552010",
    "end": "1558790"
  },
  {
    "text": "down if you remove nodes if things fail and so on let me show one other example",
    "start": "1558790",
    "end": "1564760"
  },
  {
    "text": "which is one of these iterative algorithms and this is going to be just a prototypical machine learning",
    "start": "1564760",
    "end": "1570520"
  },
  {
    "text": "algorithm is this called logistic regression so here you basically have data points that are labeled like say",
    "start": "1570520",
    "end": "1577300"
  },
  {
    "text": "you have spam and non-spam messages and you represent them as vectors and you want to find a line or hyper plane that",
    "start": "1577300",
    "end": "1583750"
  },
  {
    "text": "separates these vectors so lots of machine algorithms are like this and the",
    "start": "1583750",
    "end": "1588940"
  },
  {
    "text": "way you do this is you don't know what the solution is you start with the random line and then you do what's",
    "start": "1588940",
    "end": "1593980"
  },
  {
    "text": "called gradient descent where you gradually improve it and to do that you do these iterations where each time you",
    "start": "1593980",
    "end": "1600550"
  },
  {
    "text": "compute a gradient function which is some over the points you can view it as each point sort of pushing or pulling",
    "start": "1600550",
    "end": "1605710"
  },
  {
    "text": "the line in a direction and that gives you a direction to move the line it so you get that you've done one you know",
    "start": "1605710",
    "end": "1612460"
  },
  {
    "text": "MapReduce job to compute that and parallel you've moved the line then you do that again you do that again and",
    "start": "1612460",
    "end": "1617799"
  },
  {
    "text": "gradually the line will converge oops sorry it will converge to the right separating line so lots of lots of",
    "start": "1617799",
    "end": "1625510"
  },
  {
    "text": "learning algorithms are like this here's what the code looks like in spark it's it's again very simple code by",
    "start": "1625510",
    "end": "1631690"
  },
  {
    "text": "leveraging Scala so there's kind of two pieces first we load the data from HDFS",
    "start": "1631690",
    "end": "1637390"
  },
  {
    "text": "using a map and we tell the system to keep it in memory and then second we hunt these maps and reduces on it oh",
    "start": "1637390",
    "end": "1643840"
  },
  {
    "text": "yeah we start with with the initial line which is a random line and then we hunt these maps and reduces on it to actually",
    "start": "1643840",
    "end": "1650470"
  },
  {
    "text": "do the gradient descent and you can see since this is an algorithm that goes over the data many times if you can keep",
    "start": "1650470",
    "end": "1656740"
  },
  {
    "text": "that data in memory it's going to be a lot faster so how much faster is it this",
    "start": "1656740",
    "end": "1662830"
  },
  {
    "text": "is a graph here that compares the results against Hadoop so we also implement the logistic regression in",
    "start": "1662830",
    "end": "1669309"
  },
  {
    "text": "Hadoop this is I think 100 gigabytes of data on 50 machines and so what you see",
    "start": "1669309",
    "end": "1674650"
  },
  {
    "text": "is in Hadoop every iteration is a MapReduce job and it takes about two minutes and that's you know to load the",
    "start": "1674650",
    "end": "1680799"
  },
  {
    "text": "data from HDFS do some processing and write the result back out in spark the",
    "start": "1680799",
    "end": "1686260"
  },
  {
    "text": "first iteration is 80 seconds but later iterations are only one second and the reason for that is that the math in this",
    "start": "1686260",
    "end": "1693070"
  },
  {
    "text": "job like the dot product and stuff we were doing and there is so much less expensive than the cost of of i/o in",
    "start": "1693070",
    "end": "1699460"
  },
  {
    "text": "Hadoop that really if you're learning this with Hadoop you're spending more than ninety percent of your time just",
    "start": "1699460",
    "end": "1704799"
  },
  {
    "text": "parsing and deserialising and reading data passing as to all these layers so if you can keep it in memory as a Java",
    "start": "1704799",
    "end": "1710650"
  },
  {
    "text": "object in spark you can go substantially faster and what's interesting about this",
    "start": "1710650",
    "end": "1715690"
  },
  {
    "text": "is you know lots of people on these types of algorithms on Hadoop and you either than MapReduce it will scale linearly it will look great you know it",
    "start": "1715690",
    "end": "1722980"
  },
  {
    "text": "will it will work on large volumes of data but you're still paying you know hundred times more CPU cycles and in",
    "start": "1722980",
    "end": "1730510"
  },
  {
    "text": "Amazon 100 times more money than you actually need to turn this computation so we're excited too",
    "start": "1730510",
    "end": "1736390"
  },
  {
    "text": "by this this platform as a better way to do machine learning that I've showed",
    "start": "1736390",
    "end": "1742390"
  },
  {
    "text": "scholar examples so far we also have a Java API that's out main difference in Java is you don't get the right closures",
    "start": "1742390",
    "end": "1749230"
  },
  {
    "text": "yet but you can pass in these little functions and you still get pretty concise codes and we're working on a",
    "start": "1749230",
    "end": "1754480"
  },
  {
    "text": "Python one you can find the development version but that supports all you know C Python it supports lambdas and it works",
    "start": "1754480",
    "end": "1762160"
  },
  {
    "text": "from the Python shell so we're pretty excited to offer that and finally I've shown some like sort of prototypical",
    "start": "1762160",
    "end": "1768550"
  },
  {
    "text": "examples we have a bunch of real applications as well and they range from more traditional kind of business",
    "start": "1768550",
    "end": "1775600"
  },
  {
    "text": "intelligence or analytics on Hadoop and hive data to interactive ways and data",
    "start": "1775600",
    "end": "1781210"
  },
  {
    "text": "streams or predictive analytics as a startup called quantifying that's using a spark to do that and we have research",
    "start": "1781210",
    "end": "1787630"
  },
  {
    "text": "applications as well that push it in different ways such as genomics just a picture you know the show it works there",
    "start": "1787630",
    "end": "1794170"
  },
  {
    "text": "too this is one of the applications from convey ba which is a large-scale video analytics company they would on these",
    "start": "1794170",
    "end": "1800920"
  },
  {
    "text": "geographical reports for who watched a video and the initial version in hive took about 20 hours on a 20 node cluster",
    "start": "1800920",
    "end": "1808810"
  },
  {
    "text": "to process a week's worth of data they implemented it in spark and because",
    "start": "1808810",
    "end": "1813910"
  },
  {
    "text": "there's so much shared across the quays they were able to earn it in half an hour on just a four node cluster and so",
    "start": "1813910",
    "end": "1820540"
  },
  {
    "text": "this is you know this is this is again the kind of speed ups I was mentioning before that can apply in these real",
    "start": "1820540",
    "end": "1825880"
  },
  {
    "text": "applications okay so that does no leads meter to sharks so hopefully you know",
    "start": "1825880",
    "end": "1832570"
  },
  {
    "text": "I've convinced you that spark itself as an engine is powerful and also as a programming interface is a nice way if",
    "start": "1832570",
    "end": "1838240"
  },
  {
    "text": "you have programmer to write applications but a lot of data users are not programmers or they don't want to",
    "start": "1838240",
    "end": "1844240"
  },
  {
    "text": "sit down and write Python for every question they have so they prefer to use sequel and I've Apache hive is great for",
    "start": "1844240",
    "end": "1851080"
  },
  {
    "text": "that but it's not a low latency system so we thought okay can we just can we take hive and extend it to run on top of",
    "start": "1851080",
    "end": "1858040"
  },
  {
    "text": "spark and luckily the architecture of hive made it possible to do this in a highly compatible way so hive consists",
    "start": "1858040",
    "end": "1865600"
  },
  {
    "text": "of two pieces really does the meta store which knows about your tables and metadata and there's the client which actually",
    "start": "1865600",
    "end": "1871900"
  },
  {
    "text": "gets the quay does some way planning and submitted for execution and then the execution happens on MapReduce and HDFS",
    "start": "1871900",
    "end": "1879780"
  },
  {
    "text": "in shark we keep the same meta store and we just modify the client so we changed",
    "start": "1879780",
    "end": "1886330"
  },
  {
    "text": "the quay optimizer and the quay planner in the clients to run on sparc instead of MapReduce in and we also added this",
    "start": "1886330",
    "end": "1893890"
  },
  {
    "text": "cache manager that lets hive load and keep tables in memory and the cool thing about this is it's compatible with all",
    "start": "1893890",
    "end": "1900490"
  },
  {
    "text": "existing hive data so with your existing hive meta story with your data and HDFS sdh base wherever it is you can just run",
    "start": "1900490",
    "end": "1908170"
  },
  {
    "text": "quays on it we also did quite a bit more to actually optimizes to make this on",
    "start": "1908170",
    "end": "1913390"
  },
  {
    "text": "fast so one of the key things that gives shark at speed is column-oriented storage just loading hive data naively",
    "start": "1913390",
    "end": "1922060"
  },
  {
    "text": "into memory is not good in terms of efficiency because java objects and even",
    "start": "1922060",
    "end": "1927670"
  },
  {
    "text": "the textual representation of hive data in HDFS are a lot bigger than they need",
    "start": "1927670",
    "end": "1932890"
  },
  {
    "text": "to be you waste a lot of memory so shark automatically converts the records into a race of primitive types so for example",
    "start": "1932890",
    "end": "1939730"
  },
  {
    "text": "if your data has you know an array of has an int and a string and a float in each record you get one or a events one",
    "start": "1939730",
    "end": "1946870"
  },
  {
    "text": "way of strings and one way of floats and that saves a lot of the memory that would otherwise be wasted with their",
    "start": "1946870",
    "end": "1953080"
  },
  {
    "text": "presentation as java objects on top of that it can also do column-oriented",
    "start": "1953080",
    "end": "1958720"
  },
  {
    "text": "compression and a lot of data sets are highly compressible when you look at them as columns and so you can actually",
    "start": "1958720",
    "end": "1964300"
  },
  {
    "text": "fit a quite a bit of data in memory using shark we have some other",
    "start": "1964300",
    "end": "1969730"
  },
  {
    "text": "optimizations in the engine as well so one of the the most frustrating kind of",
    "start": "1969730",
    "end": "1976210"
  },
  {
    "text": "sources of a bad performance in hive is joins and in particular picking the number of reduce tasks and the joint",
    "start": "1976210",
    "end": "1982540"
  },
  {
    "text": "algorithm shark can do that dynamically at one time so as it on stages of York",
    "start": "1982540",
    "end": "1987790"
  },
  {
    "text": "way it figures out how much data has come out at the end of the stage and it says okay I'm going to do a map site",
    "start": "1987790",
    "end": "1992980"
  },
  {
    "text": "join and i'm going to use stanley reduced as verses 20 and so on one of the other things that does as it loads",
    "start": "1992980",
    "end": "1998950"
  },
  {
    "text": "data and memory it computes statistics so as kind of a half index it knows which for",
    "start": "1998950",
    "end": "2004169"
  },
  {
    "text": "Isles actually contain data from each time range and so on it can boom politicians that that aren't relevant to",
    "start": "2004169",
    "end": "2009840"
  },
  {
    "text": "your Quay and finally it lets you control the layout of tables across nodes which is one of the key optimizations and fast relational",
    "start": "2009840",
    "end": "2017129"
  },
  {
    "text": "databases like vertica entire data to make it on well on a cluster and using",
    "start": "2017129",
    "end": "2024149"
  },
  {
    "text": "it is actually pretty easy there's really only one thing it adds the hive which is this ability to create in",
    "start": "2024149",
    "end": "2030119"
  },
  {
    "text": "memory tables so if you want you can run it on a you know standard table or you",
    "start": "2030119",
    "end": "2035369"
  },
  {
    "text": "can create these in-memory ones with table properties you know memory equals two and to do that you just select which",
    "start": "2035369",
    "end": "2041460"
  },
  {
    "text": "data you want to put in that table so it's basically a view and then you just aren't hive against it okay so how fast",
    "start": "2041460",
    "end": "2048868"
  },
  {
    "text": "does it go I'm going to show some benchmarks that recently when comparing it against hive and for these benchmarks",
    "start": "2048869",
    "end": "2055618"
  },
  {
    "text": "we picked actually this this data set and benchmark published a couple of years ago by pavlo at all and this is a",
    "start": "2055619",
    "end": "2062819"
  },
  {
    "text": "big comparison of MapReduce against database systems you might have heard about this you mike stone baker was also",
    "start": "2062819",
    "end": "2069059"
  },
  {
    "text": "involved in this where they found that MapReduce was a lot slower than databases so we wanted to see how fast",
    "start": "2069059",
    "end": "2074608"
  },
  {
    "text": "this strike on despues so I'm going to show seek ways first time is just a simple select and i'm showing here i'm",
    "start": "2074609",
    "end": "2082888"
  },
  {
    "text": "showing shark and memory which is in green shark on disk and type and we can see your hive takes about 90 seconds",
    "start": "2082889",
    "end": "2089849"
  },
  {
    "text": "shark on disk is already five times faster it's only 18 seconds and that's because of the more optimized execution",
    "start": "2089849",
    "end": "2096628"
  },
  {
    "text": "engine and then shark and memory is only one second is that little green bar down there so for these kinds of scanning",
    "start": "2096629",
    "end": "2103109"
  },
  {
    "text": "ways obviously putting the data and memory is going to help from next way is",
    "start": "2103109",
    "end": "2109230"
  },
  {
    "text": "a group by so this involves quite a bit of network communication as well but again shark offers some pretty",
    "start": "2109230",
    "end": "2115740"
  },
  {
    "text": "significant speed ups so here when you go from hive the Jets shark on this it's",
    "start": "2115740",
    "end": "2121859"
  },
  {
    "text": "about twice as fast this is mostly because I the execution engine has less",
    "start": "2121859",
    "end": "2127559"
  },
  {
    "text": "overhead and then when you go to in memory it becomes about I'd say yeah",
    "start": "2127559",
    "end": "2134549"
  },
  {
    "text": "about ten eight or ten times faster again then what it was before and again there's a substantial",
    "start": "2134549",
    "end": "2139980"
  },
  {
    "text": "benefit to actually doing these Gray's in memory finally I'm going to show some joints so is this is one of the more",
    "start": "2139980",
    "end": "2147359"
  },
  {
    "text": "complicated ways in the data set I'm not going to try to explain what it is but",
    "start": "2147359",
    "end": "2152880"
  },
  {
    "text": "I'm showing again hive here took about half an hour almost and I'm showing",
    "start": "2152880",
    "end": "2158760"
  },
  {
    "text": "three bars for shark one of them is just the default one on disk then we have the",
    "start": "2158760",
    "end": "2163859"
  },
  {
    "text": "one in memory which is the Dark Queen and then we have the one where I use that controllable partitioning of tables",
    "start": "2163859",
    "end": "2169380"
  },
  {
    "text": "to lay out the two tables that I'm going to join in the same way so that you know the hash partition together and that",
    "start": "2169380",
    "end": "2175589"
  },
  {
    "text": "avoids a lot of network traffic and so if you do that you can go down to just a hundred seconds and these speed ups and",
    "start": "2175589",
    "end": "2182280"
  },
  {
    "text": "all these squares are similar to what you get with really high-end high-performance database engines today",
    "start": "2182280",
    "end": "2187589"
  },
  {
    "text": "and they come with the benefit of running on commodity hardware and all the fault tolerance that you get from",
    "start": "2187589",
    "end": "2193319"
  },
  {
    "text": "hive and spark so these are some of these benchmark ways we also have some",
    "start": "2193319",
    "end": "2200250"
  },
  {
    "text": "users that have tried the system out and two of the early ones on yahoo and convey via and they report similar speed",
    "start": "2200250",
    "end": "2206309"
  },
  {
    "text": "ups to the ones we've seen in the quays so inconvenient like the group by one I",
    "start": "2206309",
    "end": "2214470"
  },
  {
    "text": "showed before and again they see speed of up to 100x when the data fits in memory and they also see substantial",
    "start": "2214470",
    "end": "2220950"
  },
  {
    "text": "speedups even if it's on disk because of the more optimized danger so we I should",
    "start": "2220950",
    "end": "2227130"
  },
  {
    "text": "also say you know this this is all open source and we're excited to have more people try it out as well so let me see",
    "start": "2227130",
    "end": "2234470"
  },
  {
    "text": "yeah okay enough time okay so next thing I'm going to do just to show you that",
    "start": "2234470",
    "end": "2240359"
  },
  {
    "text": "this stuff is real I want to try to show you a little demo of it as well and then",
    "start": "2240359",
    "end": "2245760"
  },
  {
    "text": "I think we'll just have time for questions so let me try to switch to that all right still up cool so yeah so",
    "start": "2245760",
    "end": "2254190"
  },
  {
    "text": "one of the key things we did with spark and shark early on is make them very easy to launch on ec2 and so I'm not",
    "start": "2254190",
    "end": "2261299"
  },
  {
    "text": "going to show how that happens but you can launch a cluster in about five minutes using a set of script that's",
    "start": "2261299",
    "end": "2266369"
  },
  {
    "text": "very similar to EMR and so I did that now and I launched",
    "start": "2266369",
    "end": "2271559"
  },
  {
    "text": "a cluster where I'm going to run shark this is a 20 node cluster and I loaded a 50 gigabyte Wikipedia data set onto it",
    "start": "2271559",
    "end": "2278910"
  },
  {
    "text": "and this is the shark shell in it which is basically you know Apache hive so",
    "start": "2278910",
    "end": "2285209"
  },
  {
    "text": "what I'm going to do first I'm going to actually set it to hang the quays on high one on MapReduce instead of running",
    "start": "2285209",
    "end": "2291660"
  },
  {
    "text": "them on spark so you can switch back to hive in the shell if you want by just",
    "start": "2291660",
    "end": "2296959"
  },
  {
    "text": "setting one of these properties and I'm",
    "start": "2296959",
    "end": "2302009"
  },
  {
    "text": "just going to see okay how long do some of these quays take using hive and i'm",
    "start": "2302009",
    "end": "2308369"
  },
  {
    "text": "going to ask a Quay i'm going to count how many wikipedia articles i have this",
    "start": "2308369",
    "end": "2315989"
  },
  {
    "text": "table wiki to which is all wikipedia articles oh sorry how many of these",
    "start": "2315989",
    "end": "2323969"
  },
  {
    "text": "articles contain berkeley because we just like to count these kinds of things",
    "start": "2323969",
    "end": "2330089"
  },
  {
    "text": "at Berkeley so let me let me just launched that on on hive don't worry i",
    "start": "2330089",
    "end": "2336359"
  },
  {
    "text": "can ask other ways too and so okay so this is running as I said it's about 50",
    "start": "2336359",
    "end": "2341429"
  },
  {
    "text": "gigabytes of data and 20 machines and it's submitted it as a MapReduce job and it's going to go along and do that so",
    "start": "2341429",
    "end": "2350819"
  },
  {
    "text": "let's just give this a bit of time to finish you know it is going along it's making progress yep",
    "start": "2350819",
    "end": "2365568"
  },
  {
    "text": "oh there we go i think it's almost done now that's Jesse okay so so it finished",
    "start": "2370030",
    "end": "2375280"
  },
  {
    "text": "it had a MapReduce job and the answer was this thing's down here thirteen thousand thirteen thousand articles",
    "start": "2375280",
    "end": "2381670"
  },
  {
    "text": "contain Berkeley but it took about 40 seconds so you know it's cool that we were able to do this on a big data sets",
    "start": "2381670",
    "end": "2387070"
  },
  {
    "text": "but it's not exactly what I'd call interactive so let's go back now and set",
    "start": "2387070",
    "end": "2392380"
  },
  {
    "text": "the execution mode to shark and we're going to hunt the same query on shark and this data isn't in memory it's just",
    "start": "2392380",
    "end": "2398410"
  },
  {
    "text": "sitting in HDFS so let's just on that okay so shark is a lot more silent at",
    "start": "2398410",
    "end": "2406330"
  },
  {
    "text": "least in this mode basically the log output can be either way for both surveys island but it turns and it gives",
    "start": "2406330",
    "end": "2412870"
  },
  {
    "text": "actually the same answer which is always a good sign but it only took about seven seconds so you know that's good that's",
    "start": "2412870",
    "end": "2420000"
  },
  {
    "text": "okay okay i'm not actually done it okay",
    "start": "2420000",
    "end": "2425170"
  },
  {
    "text": "right thanks so so that's cool that's a lot faster let me show you now how we can use the in-memory feature is also so",
    "start": "2425170",
    "end": "2431740"
  },
  {
    "text": "now i'm going to do i'm going to create one of these in memory tables not create",
    "start": "2431740",
    "end": "2437590"
  },
  {
    "text": "create ah oops i need to do this",
    "start": "2437590",
    "end": "2444960"
  },
  {
    "text": "oops quite a bit of stuff to type for this so I'm just going to select",
    "start": "2447490",
    "end": "2455420"
  },
  {
    "text": "everything from the wiki to table and put it in memory and this is now it's actually loading that stuff into memory",
    "start": "2455420",
    "end": "2461450"
  },
  {
    "text": "and it's creating this this cached table so it's going along and you know it took",
    "start": "2461450",
    "end": "2466640"
  },
  {
    "text": "about seven seconds to do that and now let me ask the same question on the in-memory table and see what the answer",
    "start": "2466640",
    "end": "2476599"
  },
  {
    "text": "is there and so now we've got the same answer in about two seconds and you know a lot of that is just compiling the",
    "start": "2476599",
    "end": "2482390"
  },
  {
    "text": "sequel Quay actually and just to show that we have other ways to Berkeley was",
    "start": "2482390",
    "end": "2487809"
  },
  {
    "text": "was thirteen thousand let's see how many contain Stanford and it's only",
    "start": "2487809",
    "end": "2493609"
  },
  {
    "text": "eleven-thirty so that's that's a great result station right okay so that's",
    "start": "2493609",
    "end": "2502040"
  },
  {
    "text": "that's a quick preview you know seeing what shark looks like oops keep going back with you okay so that's kind of",
    "start": "2502040",
    "end": "2509059"
  },
  {
    "text": "what I wanted to show last thing I want to say is that it is easy to get started with the system so if we've gone to a",
    "start": "2509059",
    "end": "2515510"
  },
  {
    "text": "great deal of work to make them well documented and make them very easy to lunch especially if you're using easy to",
    "start": "2515510",
    "end": "2521450"
  },
  {
    "text": "and you can get a cluster like the one I had in about five minutes and start running your own ways and so you can",
    "start": "2521450",
    "end": "2528530"
  },
  {
    "text": "find out about spark itself at spark project org you can find about the other",
    "start": "2528530",
    "end": "2533869"
  },
  {
    "text": "systems at the amp lab website and I'd be happy to take any questions along",
    "start": "2533869",
    "end": "2539000"
  },
  {
    "text": "with Mike",
    "start": "2539000",
    "end": "2541480"
  }
]
[
  {
    "text": "good afternoon everybody we're going to talk to you this afternoon about TIBCO",
    "start": "1460",
    "end": "6779"
  },
  {
    "text": "data science innovation with Amazon sage maker I'm Michael this is Stephen I will be",
    "start": "6779",
    "end": "13230"
  },
  {
    "text": "taking you through a presentation and a demonstration connecting TIBCO data science to a two stage maker so I",
    "start": "13230",
    "end": "21420"
  },
  {
    "text": "thought it'd be useful to understand what is an ideal data science platform look like well firstly you want to be",
    "start": "21420",
    "end": "26640"
  },
  {
    "text": "able to connect to data wherever that they may be in transactional stores streaming data Mart's you want to be",
    "start": "26640",
    "end": "33450"
  },
  {
    "text": "able to offer a citizen and data science interfaces both point-and-click as well",
    "start": "33450",
    "end": "38790"
  },
  {
    "text": "as coding interfaces for data access and prep along with modeling and I mean by",
    "start": "38790",
    "end": "44309"
  },
  {
    "text": "that machine learning a deep learning type modeling and you want to be able to deploy that out for for scoring in batch",
    "start": "44309",
    "end": "51059"
  },
  {
    "text": "and real-time to create live apps to create apps at the edge and all of those",
    "start": "51059",
    "end": "57570"
  },
  {
    "text": "to be powered by machine learning and data science the tooling and on the on the far right hand side of the screen",
    "start": "57570",
    "end": "64378"
  },
  {
    "text": "here to be able to inform business applications that really make a difference on the business so predicting",
    "start": "64379",
    "end": "70439"
  },
  {
    "text": "impending equipment failure offering cross sell products optimizing pricing preventing fraud things like that so",
    "start": "70439",
    "end": "76710"
  },
  {
    "text": "that's ideally what you want and we're going to take you through a journey where what we're at there with TIBCO",
    "start": "76710",
    "end": "82590"
  },
  {
    "text": "data science on the AWS marketplace the TIBCO connected intelligence cloud and our combination of TIBCO data science",
    "start": "82590",
    "end": "88829"
  },
  {
    "text": "with Amazon Sage Maker we're going to give you a live demonstration of anomaly detection and advanced process control",
    "start": "88829",
    "end": "94530"
  },
  {
    "text": "and show you where to get some assets to go on your own journey with our products combining our products with open source",
    "start": "94530",
    "end": "100500"
  },
  {
    "text": "and with with Amazon so if you think about where data comes from all data",
    "start": "100500",
    "end": "106290"
  },
  {
    "text": "begins as a real-time event now we trap those real-time events down into a data Lake we accumulate the data and we do",
    "start": "106290",
    "end": "113520"
  },
  {
    "text": "analytics on that and we get some insights you know but the insights are perishable you have to take action on",
    "start": "113520",
    "end": "119549"
  },
  {
    "text": "the insight the insight actually decays in value faster than the data doesn't so you want to be able to take action so",
    "start": "119549",
    "end": "124860"
  },
  {
    "text": "the TIBCO DNA is really all about finding and acting on critical business moments while you have a chance to do so",
    "start": "124860",
    "end": "131250"
  },
  {
    "text": "so getting a little bit of information just ahead time about the process with a little bit",
    "start": "131250",
    "end": "136350"
  },
  {
    "text": "of business context to take an action that really drives value so we you know analytics at the moment of truth we call",
    "start": "136350",
    "end": "142020"
  },
  {
    "text": "it a tip code for things like surveillance intervention for anomaly detection freaking impending equipment",
    "start": "142020",
    "end": "147840"
  },
  {
    "text": "failure we're going to focus on those two today with our demonstration but this same platform and idea applies to",
    "start": "147840",
    "end": "153510"
  },
  {
    "text": "customer interactions cross cell real-time inventory management price optimization fraud optimizing routes in",
    "start": "153510",
    "end": "160170"
  },
  {
    "text": "anticipating and handling your disruptions and if you think about some folks out there who are using",
    "start": "160170",
    "end": "165870"
  },
  {
    "text": "effectively TIBCO data science with AWS to do just that you know one company",
    "start": "165870",
    "end": "171780"
  },
  {
    "text": "comes to mind Latos and they have an offering called the their advanced analytics and data sharing platform cads",
    "start": "171780",
    "end": "177890"
  },
  {
    "text": "and they've effectively offered TIBCO data science across a range of healthcare applications particularly for",
    "start": "177890",
    "end": "185130"
  },
  {
    "text": "example the cdc is using us and they've been able to do but 20x more outbreaks",
    "start": "185130",
    "end": "190500"
  },
  {
    "text": "monitoring surveillance over the past couple years than before and that's led",
    "start": "190500",
    "end": "195660"
  },
  {
    "text": "to real-time monitoring of the opioid epidemic there's been a drug taken off the market by the FDA as part of that",
    "start": "195660",
    "end": "201840"
  },
  {
    "text": "data science work with the Center for Medicare and Medicaid benchmarking and",
    "start": "201840",
    "end": "206880"
  },
  {
    "text": "improving quality of care for Medicare and state Medicaid programs value-based care rather than fee-for-service and",
    "start": "206880",
    "end": "213120"
  },
  {
    "text": "most excitingly this week at least NASA where we're using our software to",
    "start": "213120",
    "end": "218400"
  },
  {
    "text": "understand the effects of time in space on astronauts health so analyzing the electronic medical record of a time of",
    "start": "218400",
    "end": "225450"
  },
  {
    "text": "the of the astronauts using a tip code data science to understand effects of time in space on the health of the",
    "start": "225450",
    "end": "232200"
  },
  {
    "text": "astronauts and there's a photo there from the Mars landing this week and we're on a journey to get to deep space and to Mars and one of the big factors",
    "start": "232200",
    "end": "238860"
  },
  {
    "text": "around that is the effective time in space on on the astronaut health so",
    "start": "238860",
    "end": "244049"
  },
  {
    "text": "there's a quick example of the with what we're showing today with a deployed customer using this to great effect okay",
    "start": "244049",
    "end": "251760"
  },
  {
    "text": "so with that is the ideal platform how do we stack up and what's our journey at TIBCO in realizing this vision so we",
    "start": "251760",
    "end": "258840"
  },
  {
    "text": "have this product tip code data science we've announced the exclusivity of this product on the AWS marketplace this week",
    "start": "258840",
    "end": "264770"
  },
  {
    "text": "press release comes out tomorrow morning but there's a big big news for us at TIBCO and right now we have the ability to do",
    "start": "264770",
    "end": "272729"
  },
  {
    "text": "most of those items on the ideal platform we can ingest data and prepare data from a variety of stores in fact we",
    "start": "272729",
    "end": "281310"
  },
  {
    "text": "do most of the computations down in the database engine whether that be Hadoop or spark or in a relational data store",
    "start": "281310",
    "end": "286830"
  },
  {
    "text": "or whatever the case may be and the interface is there for visual composition by a citizen data scientist",
    "start": "286830",
    "end": "293280"
  },
  {
    "text": "as well as a notebook environment that's embeddable on the on the canvas and when",
    "start": "293280",
    "end": "299460"
  },
  {
    "text": "you drag the notebook onto the canvas it int respects what's been done with the point-and-click work and gives the Python coder all of that context in in",
    "start": "299460",
    "end": "307139"
  },
  {
    "text": "picking up the pieces from the the data prep which can be done visually so this is an enables a data scientist a citizen",
    "start": "307139",
    "end": "314219"
  },
  {
    "text": "data scientist to work with data sources to do data prep feature engineering and build out models and then we have",
    "start": "314219",
    "end": "320639"
  },
  {
    "text": "componentry for deploying the model and managing the lifecycle of the model setting up a scoring service from the",
    "start": "320639",
    "end": "326610"
  },
  {
    "text": "model to allow Batchelor automation as well as real-time event processing and then feed into those business",
    "start": "326610",
    "end": "332520"
  },
  {
    "text": "applications that I talked about earlier for example that epidemic monitoring case that we had from Latos engineers",
    "start": "332520",
    "end": "339060"
  },
  {
    "text": "optimizing yield quants doing trading desk surveillance and reconciliation so",
    "start": "339060",
    "end": "344940"
  },
  {
    "text": "we're pretty far along the journey and if we double click down on this slide to each of those components we see this",
    "start": "344940",
    "end": "351719"
  },
  {
    "text": "ability as I mentioned to do the notebook piece on the top left the",
    "start": "351719",
    "end": "356879"
  },
  {
    "text": "visual composition piece on the on the bottom left there's a slew of operators you can drag into the canvas to do data",
    "start": "356879",
    "end": "362940"
  },
  {
    "text": "prep and and machine learning and combining that with connectivity into",
    "start": "362940",
    "end": "368099"
  },
  {
    "text": "the open source and other commercial products like Sage maker this is a really empowering set of tools for",
    "start": "368099",
    "end": "374250"
  },
  {
    "text": "citizen data scientists as well as data scientists now the connected and",
    "start": "374250",
    "end": "380039"
  },
  {
    "text": "collaboration part of the platform is a big thing we've invested in so folks can set you'll see in the demonstration you",
    "start": "380039",
    "end": "385979"
  },
  {
    "text": "can have citizens analysts managers data engineers all of those folks can be in a",
    "start": "385979",
    "end": "392009"
  },
  {
    "text": "collaborative environment it's like a Facebook style or should I say slack style environment for publishing up work",
    "start": "392009",
    "end": "397949"
  },
  {
    "text": "that's being done searching those artifacts as I mentioned the algorithms are all scalable we don't move any data we drive",
    "start": "397949",
    "end": "405120"
  },
  {
    "text": "sequel down into the data stores to run at scale in a distributed manner for",
    "start": "405120",
    "end": "411270"
  },
  {
    "text": "both data prep and for the ml we have an extension interface using PI spark and",
    "start": "411270",
    "end": "416820"
  },
  {
    "text": "Scala for customizing interfaces into that into those data sources and then",
    "start": "416820",
    "end": "423270"
  },
  {
    "text": "rapid deployment and management on cloud and on-premise and connector you'll see in the demonstration connectivity into",
    "start": "423270",
    "end": "428520"
  },
  {
    "text": "EMR redshift s3 and so on and there's the the visual interface so the",
    "start": "428520",
    "end": "434790"
  },
  {
    "text": "combination of this also with BI tools is pretty powerful so we're now 20th year anniversary of Spotfire this year",
    "start": "434790",
    "end": "440640"
  },
  {
    "text": "we kind of invented the data discovery space of those years ago and the ability",
    "start": "440640",
    "end": "445830"
  },
  {
    "text": "to do in database calculations both on the data science side on the left and also on the analytics side is a pretty",
    "start": "445830",
    "end": "453540"
  },
  {
    "text": "powerful combination big outer you'll see in the demonstration how we build out models we deploy models and we",
    "start": "453540",
    "end": "458760"
  },
  {
    "text": "infuse those results into a broader BI application combining data from different sources to do interactive data",
    "start": "458760",
    "end": "465600"
  },
  {
    "text": "discovery root cause analysis you know things like that and then finally this",
    "start": "465600",
    "end": "471420"
  },
  {
    "text": "bringing models into operations setting up models as a scoring service to embed predictive insights into business",
    "start": "471420",
    "end": "477150"
  },
  {
    "text": "applications visualize results push real time engines into AWS filled out live",
    "start": "477150",
    "end": "482790"
  },
  {
    "text": "apps add Japs we had a talk earlier in the week injecting some data science results into TIBCO flow NGO which is a",
    "start": "482790",
    "end": "489780"
  },
  {
    "text": "open source environment for in the golang for running a low code building low code apps that run in very low",
    "start": "489780",
    "end": "496710"
  },
  {
    "text": "footprint on on edge devices so all of these application areas powered by ml",
    "start": "496710",
    "end": "502650"
  },
  {
    "text": "and data science with apps that can make you know a difference on the business",
    "start": "502650",
    "end": "507770"
  },
  {
    "text": "now we've been at this for a while and AWS has we're a machine learning",
    "start": "507770",
    "end": "514159"
  },
  {
    "text": "competency partner and we're the only partner who has accreditation in two areas one for data services a lot of",
    "start": "514160",
    "end": "520800"
  },
  {
    "text": "those nodes to drag onto the canvas off a data prep you know some for machine",
    "start": "520800",
    "end": "526410"
  },
  {
    "text": "learning of course but the data prep part of this product and running at scale distributed is particularly powerful and we've gotta compensate",
    "start": "526410",
    "end": "532950"
  },
  {
    "text": "accreditation in that but also we have accreditation for platform solutions so the broader collection of tooling that",
    "start": "532950",
    "end": "539310"
  },
  {
    "text": "I've just been going through and then exciting announcement this morning in",
    "start": "539310",
    "end": "544680"
  },
  {
    "text": "the keynote this AWS marketplace for machine learning algorithms and we're participating in that we've published",
    "start": "544680",
    "end": "551460"
  },
  {
    "text": "three algorithms there the anomaly detection algorithm that you'll see today is up there you can use that in",
    "start": "551460",
    "end": "557430"
  },
  {
    "text": "sage maker or other notebook environments we have a hospital readmission algorithm that predicts you",
    "start": "557430",
    "end": "563610"
  },
  {
    "text": "know readmission rates from things like DRG codes and billing codes and then a text similarity similarity analyzer that",
    "start": "563610",
    "end": "569370"
  },
  {
    "text": "we used in that NASA project to set up a feature ization of a corpus of documents",
    "start": "569370",
    "end": "575580"
  },
  {
    "text": "and then compare a new document in terms of its similarity to documents in the corpus so these algorithms are all coded",
    "start": "575580",
    "end": "582810"
  },
  {
    "text": "in Python docker eyes to follow the AWS marketplace guidelines you can bring them in to your sage maker experience or",
    "start": "582810",
    "end": "588300"
  },
  {
    "text": "other notebook experiences and we're demonstrating this in the marketplace experience booth tomorrow as well over",
    "start": "588300",
    "end": "595440"
  },
  {
    "text": "in the Aria quad where there'll be other vendors who are participating in this machine learning marketplace so that's",
    "start": "595440",
    "end": "601860"
  },
  {
    "text": "something to keep a track of okay with that is kind of the set up for TIBCO data science what are we doing with sage",
    "start": "601860",
    "end": "608160"
  },
  {
    "text": "maker let me talk a bit about that and we'll get into the demo and how this fits in with our vision at TIBCO for",
    "start": "608160",
    "end": "614220"
  },
  {
    "text": "connected intelligence cloud powered by AWS so the TIBCO connected intelligence",
    "start": "614220",
    "end": "620940"
  },
  {
    "text": "portfolio really has two branches to it there's the analytics branch where we have products for data management data",
    "start": "620940",
    "end": "626490"
  },
  {
    "text": "science and data visualization you know data management we have a data virtualization product we have some",
    "start": "626490",
    "end": "631560"
  },
  {
    "text": "master data management products in the data science area we have TIBCO data science cloud-based distributed compute",
    "start": "631560",
    "end": "637380"
  },
  {
    "text": "as I mentioned there's also a workbench version of that for someone wants to bring the data into memory and do like a SAS style analysis and then on the",
    "start": "637380",
    "end": "645000"
  },
  {
    "text": "visualization side we have Spotfire which is our interactive data discovery data visualization application and also",
    "start": "645000",
    "end": "651240"
  },
  {
    "text": "jaspersoft which is also very popular on AWS for embedded reporting pixel-perfect bursting that kind of a thing so the",
    "start": "651240",
    "end": "658440"
  },
  {
    "text": "portfolio is fairly rich in that area the data science area also includes some of our streaming components so stream",
    "start": "658440",
    "end": "665430"
  },
  {
    "text": "base for real-time math on event streams business events is a state oisin for keeping track of events whether they're on or off across across",
    "start": "665430",
    "end": "671940"
  },
  {
    "text": "time so the portfolio has all of those elements on the analytics side and then on the interconnect side you know API",
    "start": "671940",
    "end": "678509"
  },
  {
    "text": "lead micro service based integration messaging event processing digital",
    "start": "678509",
    "end": "684269"
  },
  {
    "text": "process automation BPM that sort of thing and you'll see how the data science demo today will feed into a low",
    "start": "684269",
    "end": "690480"
  },
  {
    "text": "code BPM for case management of the identified anomalies from the data science model so we're",
    "start": "690480",
    "end": "698579"
  },
  {
    "text": "aggressively bringing all these products into our own a TIBCO connected intelligence cloud with a common set of",
    "start": "698579",
    "end": "703649"
  },
  {
    "text": "governance of billing customer services again powered by AWS and highly",
    "start": "703649",
    "end": "709410"
  },
  {
    "text": "interactive with with the other AWS components so you'll see we're marching along towards this ideal state this",
    "start": "709410",
    "end": "716279"
  },
  {
    "text": "vision that I mentioned bringing data sources in from anywhere our our real-time event processing messaging",
    "start": "716279",
    "end": "722930"
  },
  {
    "text": "business works products been doing this for many years real-time event based integration our batch integration",
    "start": "722930",
    "end": "730319"
  },
  {
    "text": "through our data virtualization product however you get the data in TIBCO data Sciences there in the middle playing this orchestration role connecting to",
    "start": "730319",
    "end": "737610"
  },
  {
    "text": "AMR red shift s3 for doing data science you'll see in the demonstration where",
    "start": "737610",
    "end": "743220"
  },
  {
    "text": "we're connecting a sage maker in through our visual notebook interface today at TIBCO data science how we're publishing",
    "start": "743220",
    "end": "749639"
  },
  {
    "text": "out the results and predictions and picking those up you know in a mash-up between redshift EMR and prediction",
    "start": "749639",
    "end": "756959"
  },
  {
    "text": "results from from the tensor flow model that we're running in Sage Maker and then pushing these out as the scoring",
    "start": "756959",
    "end": "763170"
  },
  {
    "text": "service into applications like TIBCO live apps in the bottom right hand corner invoked through the Chipko connected",
    "start": "763170",
    "end": "768420"
  },
  {
    "text": "intelligence cloud and flow go as I mentioned the low code golang environment for building edge",
    "start": "768420",
    "end": "773899"
  },
  {
    "text": "analytically informed applications that we presented earlier in the week on on Monday so that's how the things kind of",
    "start": "773899",
    "end": "780480"
  },
  {
    "text": "fit together and now getting into what we're going to see in the in the demonstration we're going to talk about",
    "start": "780480",
    "end": "786329"
  },
  {
    "text": "anomaly detection and surveillance and there's a lot of applications one reason we picked this algorithm the show and",
    "start": "786329",
    "end": "791880"
  },
  {
    "text": "feature at this conference and to put on the machine learning marketplace is that this algorithm has a lot of applications",
    "start": "791880",
    "end": "797370"
  },
  {
    "text": "so we are proud and excited to be using this in you know al sponsorship of",
    "start": "797370",
    "end": "802439"
  },
  {
    "text": "massage one who Mercedes f1 team which you know they just won both the driver",
    "start": "802439",
    "end": "807440"
  },
  {
    "text": "championship and the constructor championship you can actually if you go to our booth you can sit in the replica of the Formula One car you can see as",
    "start": "807440",
    "end": "813950"
  },
  {
    "text": "you're driving along the live visuals coming through in in Spotfire and Formula One guys are Mercedes of using a",
    "start": "813950",
    "end": "821270"
  },
  {
    "text": "lot of Spotfire and streaming products to identify anomalies configure the gearbox configure the car develop the",
    "start": "821270",
    "end": "828620"
  },
  {
    "text": "race strategy you know it takes about 15 milliseconds to change the gear and we get you know data on the nanosecond",
    "start": "828620",
    "end": "835820"
  },
  {
    "text": "level throughout that and we understand how to find the configuration of the gearbox that minimizes any slippage or",
    "start": "835820",
    "end": "842960"
  },
  {
    "text": "issues in changing gears Luas changes gives about three thousand times a race so we want to have that to be really really smooth and the idea of doing",
    "start": "842960",
    "end": "850160"
  },
  {
    "text": "anomaly detection both in data at rest and applying that you know to data in motion is a significant use case and",
    "start": "850160",
    "end": "856820"
  },
  {
    "text": "that's one of the reasons we chose it now in addition to that sort of glamorous use case around Formula One we",
    "start": "856820",
    "end": "862280"
  },
  {
    "text": "do this on a regular basis in the energy sector doing production surveillance that across wells for oil and gas doing",
    "start": "862280",
    "end": "868910"
  },
  {
    "text": "surveillance across grids optimising drilling operations and generally doing",
    "start": "868910",
    "end": "874790"
  },
  {
    "text": "equipment management predictive maintenance across a variety of sources including say manufacturing where we're",
    "start": "874790",
    "end": "880580"
  },
  {
    "text": "looking for maverick lots and things like that in financial services this algorithm has application in trade",
    "start": "880580",
    "end": "886520"
  },
  {
    "text": "surveillance fraud detection risk and compliance monitoring in healthcare for patient risk cardiac arrest sepsis",
    "start": "886520",
    "end": "893390"
  },
  {
    "text": "things like that and in customer analytics bio churn and cross-sell so what you're going to see in the",
    "start": "893390",
    "end": "898550"
  },
  {
    "text": "demonstration is bringing data connecting to data from a variety of sources using TIBCO data science",
    "start": "898550",
    "end": "905450"
  },
  {
    "text": "building out a model now actually we use a lot of tensorflow but we found it very convenient to run tensorflow models",
    "start": "905450",
    "end": "912110"
  },
  {
    "text": "through sage maker because sage maker is automatically set up to do the parallelization of the deep learning",
    "start": "912110",
    "end": "917870"
  },
  {
    "text": "model across a bunch of nodes and you kind of get that for free almost when you connect into sage maker to do that",
    "start": "917870",
    "end": "923030"
  },
  {
    "text": "as opposed to trying to rig up your own parallel implementation of of the Google",
    "start": "923030",
    "end": "929410"
  },
  {
    "text": "infrastructure that's why the little tensorflow there and logos on the on the first piece now the model then detects",
    "start": "929410",
    "end": "936170"
  },
  {
    "text": "the anomaly on on the data that you've trained up with that tensorflow model through sage",
    "start": "936170",
    "end": "941750"
  },
  {
    "text": "maker and then step three we bring that data the results you know in the",
    "start": "941750",
    "end": "946970"
  },
  {
    "text": "Spotfire we look at the incidence or the anomalies and and then figure out new",
    "start": "946970",
    "end": "953240"
  },
  {
    "text": "data that are coming in how do we score that and have a tip code live apps is a lightweight low code BPM application",
    "start": "953240",
    "end": "960590"
  },
  {
    "text": "where you can put an anomaly into a case management database and then you can assign it to an investigator to go and",
    "start": "960590",
    "end": "966410"
  },
  {
    "text": "investigate the anomalies that are true anomaly is it a false positive and once you can now label that you can go back",
    "start": "966410",
    "end": "972410"
  },
  {
    "text": "and complete the cycle and retrain the model so live apps is that low code lightweight BPM application that allows",
    "start": "972410",
    "end": "979820"
  },
  {
    "text": "you to do case management and resolution and that is a stitch together in a customized BPM process often times using",
    "start": "979820",
    "end": "987110"
  },
  {
    "text": "TIBCO cloud integration for combining some of the pieces there so the actual",
    "start": "987110",
    "end": "993590"
  },
  {
    "text": "demonstration we're going to get to it's a sense of data from a power plant on on",
    "start": "993590",
    "end": "998720"
  },
  {
    "text": "three minute intervals it's a you know dummy data set in you know in many ways but it is based on unreal real data",
    "start": "998720",
    "end": "1004800"
  },
  {
    "text": "we're using this unsupervised learning model to detect the anomalies from the model inputs cleaning up the data",
    "start": "1004800",
    "end": "1011320"
  },
  {
    "text": "preparing it for the training and scoring and we using a deep learning auto encoder to do the anomaly detection I'll talk about that in a moment and",
    "start": "1011320",
    "end": "1018340"
  },
  {
    "text": "we're using the reconstruction error as a to estimate the magnitude of the potential anomaly and then we're",
    "start": "1018340",
    "end": "1024730"
  },
  {
    "text": "building out the application in the cloud application and a framework scoring the ML model on incoming data",
    "start": "1024730",
    "end": "1029890"
  },
  {
    "text": "from sensors identifying potential anomalies visualizing the score data understanding any incidents that occur",
    "start": "1029890",
    "end": "1035530"
  },
  {
    "text": "across time and figuring out how to resolve those in in the case management system so while the data sources I",
    "start": "1035530",
    "end": "1043420"
  },
  {
    "text": "mentioned there's a five individual burners in this test data set three mils",
    "start": "1043420",
    "end": "1048610"
  },
  {
    "text": "per burner here's a quick spot for a visual there you've got the columns are the burners columns are the mills the",
    "start": "1048610",
    "end": "1056200"
  },
  {
    "text": "Roza are the burners and there's a couple of time slices there that we're showing and a couple of different there's a bunch of different sensor",
    "start": "1056200",
    "end": "1062950"
  },
  {
    "text": "readings that we have here and we pull out the data we extract out the the components of the time we normalize the",
    "start": "1062950",
    "end": "1069340"
  },
  {
    "text": "different data sources across the to make the analysis solid and we do some feature engineering that we then",
    "start": "1069340",
    "end": "1075460"
  },
  {
    "text": "bring into the the model now as I mentioned the model is a deep learning auto encoder now the way this works is",
    "start": "1075460",
    "end": "1081580"
  },
  {
    "text": "you might have say a hundred dimensions of sensors and you represent that in a",
    "start": "1081580",
    "end": "1086590"
  },
  {
    "text": "lower dimensional space maybe ten dimensions and you reconstruct the original data so you might have millions",
    "start": "1086590",
    "end": "1092410"
  },
  {
    "text": "of records that you reconstruct and the ones that are reconstructed well by the low-rank approximation to the input set",
    "start": "1092410",
    "end": "1099850"
  },
  {
    "text": "of dimensions data points that are in the center of the data so they're not going to really be anomalies the ones that aren't could reconstructed very",
    "start": "1099850",
    "end": "1106120"
  },
  {
    "text": "well by the low-rank approximation our potential outliers they're not really well approximated by the low-rank",
    "start": "1106120",
    "end": "1112390"
  },
  {
    "text": "approximation and they could be potential anomalies so we're using that reconstruction error as the measure of",
    "start": "1112390",
    "end": "1118450"
  },
  {
    "text": "the magnitude of the potential anomaly now the neural net architecture is highly configurable and we'll see when",
    "start": "1118450",
    "end": "1124210"
  },
  {
    "text": "Steven shows you the notebook you we've set up a four layer a neural network but",
    "start": "1124210",
    "end": "1129340"
  },
  {
    "text": "you can change that you can configure up the Train up a file that you push across some is highly configurable and then the",
    "start": "1129340",
    "end": "1135430"
  },
  {
    "text": "model understands the patterns reconstructs the data set and highlights the the anomalies and so you'll see that",
    "start": "1135430",
    "end": "1143260"
  },
  {
    "text": "the machine learning models the the reconstruction error is the output the engineer can then explore that versus",
    "start": "1143260",
    "end": "1149260"
  },
  {
    "text": "time we have a Spotfire analysis for bringing those predictions into spot",
    "start": "1149260",
    "end": "1154690"
  },
  {
    "text": "fire inside the TIBCO cloud and combining that with other contextual data that we have in redshift for",
    "start": "1154690",
    "end": "1160300"
  },
  {
    "text": "example we look at those anomalies versus time and you can see the the highlights here are the high reconstruction errors these are the",
    "start": "1160300",
    "end": "1167320"
  },
  {
    "text": "potential anomalies when they sort of occur together you've got an incident that you want to resolve and the engineer can then dig into that time",
    "start": "1167320",
    "end": "1173620"
  },
  {
    "text": "series and understand the root cause and so on of these of these results and then",
    "start": "1173620",
    "end": "1179890"
  },
  {
    "text": "taking near the anomalies that you flag sticking them and into a case management database and having a case manager",
    "start": "1179890",
    "end": "1185200"
  },
  {
    "text": "resolved that could be a variety of steps there involving that the the resolution we're not going to get into",
    "start": "1185200",
    "end": "1191740"
  },
  {
    "text": "the details of the case management in today's demonstration but you can configure this however you want for the business process that you have in mind",
    "start": "1191740",
    "end": "1198610"
  },
  {
    "text": "and then as you resolve that with an action may be a service technician goes and services the equipment",
    "start": "1198610",
    "end": "1204220"
  },
  {
    "text": "fixes the equipment and you resolve that whether it's an anomaly or not and go back and retrain your model now that",
    "start": "1204220",
    "end": "1210039"
  },
  {
    "text": "you've got some more labeled data from from the field so with that is setup I'm going to hand off to Steven to actually",
    "start": "1210039",
    "end": "1216519"
  },
  {
    "text": "take us through demonstration and TIBCO data science connecting sage maker to go through that anomaly detection news case",
    "start": "1216519",
    "end": "1222580"
  },
  {
    "text": "Phoenix okay so I'm going to show you a demonstration that's largely based",
    "start": "1222580",
    "end": "1227649"
  },
  {
    "text": "around the tip code data science platform it's not a functionality that I'm really going to focus on the machine",
    "start": "1227649",
    "end": "1233769"
  },
  {
    "text": "learning in the integration with AWS and specifically in terms of AWS we're the",
    "start": "1233769",
    "end": "1239440"
  },
  {
    "text": "EMR with redshift and width as Michael has mentioned the sage maker framework",
    "start": "1239440",
    "end": "1246690"
  },
  {
    "text": "the demo that I'm going to show you is based on a real world example of power",
    "start": "1246690",
    "end": "1252580"
  },
  {
    "text": "plant data in this case of course it's fabricated data to protect the innocent but this is a real-world example and",
    "start": "1252580",
    "end": "1259570"
  },
  {
    "text": "I'll give a couple more examples at the end of how you might use this now you",
    "start": "1259570",
    "end": "1265000"
  },
  {
    "text": "can actually see here within the TIBCO data science platform the activity over the last few days as we've put this",
    "start": "1265000",
    "end": "1271509"
  },
  {
    "text": "demonstration together so Marion has been working on the visual workflow that I'm going to be showing to you and she",
    "start": "1271509",
    "end": "1277000"
  },
  {
    "text": "was relying on the sage maker work that venkat was doing in Python notebooks and they were sort of talking together you",
    "start": "1277000",
    "end": "1282580"
  },
  {
    "text": "can think of Mary and maybe as sort of playing the role of a citizen data scientist and venkat data scientist more",
    "start": "1282580",
    "end": "1288159"
  },
  {
    "text": "focused on Python and then I swooped in at the end make things look pretty and",
    "start": "1288159",
    "end": "1293590"
  },
  {
    "text": "then get this stuff ready for the demonstration so the point is here we've got this little collaborative interface where the teams can work together",
    "start": "1293590",
    "end": "1300039"
  },
  {
    "text": "useless managers like me data scientists and engineers business analysts and so",
    "start": "1300039",
    "end": "1306100"
  },
  {
    "text": "on and as you see through the demo you'll see that there's different levels of expertise required for for using the",
    "start": "1306100",
    "end": "1311379"
  },
  {
    "text": "system and so it really is a sort of gathering place for people from across the analytics workflow however I'm not",
    "start": "1311379",
    "end": "1318250"
  },
  {
    "text": "really going to focus so much on there on the collaboration even there's a lot of functionality around governance and",
    "start": "1318250",
    "end": "1324730"
  },
  {
    "text": "security and versioning and auditing and so on really the activity is mostly here around their workforce where the team",
    "start": "1324730",
    "end": "1329919"
  },
  {
    "text": "comes together and works in multiple different paradigms here I'm really",
    "start": "1329919",
    "end": "1335320"
  },
  {
    "text": "focusing on two of those paradigms we've also got our integrations sequel scholar and so on really focus on here on Python",
    "start": "1335320",
    "end": "1342369"
  },
  {
    "text": "notebooks where we have the integration with sage maker and ultimately through downto to tensorflow",
    "start": "1342369",
    "end": "1349659"
  },
  {
    "text": "and then these visual workflows the visual workflow really drives everything in this particular application",
    "start": "1349659",
    "end": "1357999"
  },
  {
    "text": "it's got data on EMR and it's calling out ultimately to a whole array of",
    "start": "1357999",
    "end": "1364149"
  },
  {
    "text": "different processing operations but in particular it calls out to one of the Python notebooks where we have the sage",
    "start": "1364149",
    "end": "1371320"
  },
  {
    "text": "maker code calling tensorflow so that's sort of the high level architecture of the demo if you like but",
    "start": "1371320",
    "end": "1376659"
  },
  {
    "text": "it's really all driven by this visual workflow so that's where I'm going to focus now so let me open this up so this",
    "start": "1376659",
    "end": "1384219"
  },
  {
    "text": "workflow which Marian created and cats collaborating with me right as we speak",
    "start": "1384219",
    "end": "1391080"
  },
  {
    "text": "starts with that data set that is sitting on EMR and actually contains",
    "start": "1391080",
    "end": "1398139"
  },
  {
    "text": "this list of sensor readings that's coming from the power plants and no point am I going to move the data out of",
    "start": "1398139",
    "end": "1404259"
  },
  {
    "text": "EMR as michael has emphasized and I think it bears repeating at every point at each one of these nodes in this graph",
    "start": "1404259",
    "end": "1411609"
  },
  {
    "text": "we are pushing computations down into the underlying data system whether that's EMR or redshift or another",
    "start": "1411609",
    "end": "1417519"
  },
  {
    "text": "version of Hadoop or another relational database or spark or whatever it might be so the system's smart enough to know",
    "start": "1417519",
    "end": "1422799"
  },
  {
    "text": "this is where the data sits so I know how I the system should execute the compute in the most efficient way",
    "start": "1422799",
    "end": "1429039"
  },
  {
    "text": "possible to reduce or eliminate data movement so we've got this input data set here that contains the sensor",
    "start": "1429039",
    "end": "1434080"
  },
  {
    "text": "readings and so off we go and let's let's see what happens in this workflow well the first thing I want to do is",
    "start": "1434080",
    "end": "1439929"
  },
  {
    "text": "data scientists of course its construct my features here in this very simple example we're going to add in a couple new variables here these time of day",
    "start": "1439929",
    "end": "1446499"
  },
  {
    "text": "measurements we think these might be relevant for detecting anomalies and we also think we should probably normalize the variables so that's what I'm doing",
    "start": "1446499",
    "end": "1452799"
  },
  {
    "text": "here to make sure that no one variable dominates the the model training let me open up this one just as an example you",
    "start": "1452799",
    "end": "1458769"
  },
  {
    "text": "can see it's very easy I specify what type of normalization method I want to use some extra parameters choose the",
    "start": "1458769",
    "end": "1464849"
  },
  {
    "text": "variables that I want to have included in that normalization process so very",
    "start": "1464849",
    "end": "1469929"
  },
  {
    "text": "easy to do coding as we'll see later you can interject code a few if you want but minimal coding in a in a large array of",
    "start": "1469929",
    "end": "1477659"
  },
  {
    "text": "different operators but while it's very easy to use it's very sophisticated on the back end because we're again we're",
    "start": "1477659",
    "end": "1484320"
  },
  {
    "text": "pushing down the computations into the underlying data source so in this case",
    "start": "1484320",
    "end": "1489419"
  },
  {
    "text": "because it's sitting on EMR we're actually choosing to push down spark code or spark sequel code to execute",
    "start": "1489419",
    "end": "1495389"
  },
  {
    "text": "these operations and stringing those together and operating on the resulting data frames as they get passed through",
    "start": "1495389",
    "end": "1500459"
  },
  {
    "text": "the workflow now at some point now I want to build my model Michaels",
    "start": "1500459",
    "end": "1505709"
  },
  {
    "text": "described a little bit the type of model that we want to build now of course out of the box the data science platform has",
    "start": "1505709",
    "end": "1511169"
  },
  {
    "text": "a large array of different statistical and transformation and machine learning operators if I just focus down on the",
    "start": "1511169",
    "end": "1518609"
  },
  {
    "text": "modern ones you'll see here a lot of names that you recognize in terms of forests and trees and classification clustering and regression algorithms and",
    "start": "1518609",
    "end": "1524909"
  },
  {
    "text": "so on but we think for this particular application tensorflow is really great",
    "start": "1524909",
    "end": "1530639"
  },
  {
    "text": "it's got a solid reputation for doing this type of auto encoding using new",
    "start": "1530639",
    "end": "1535829"
  },
  {
    "text": "neural networks deep learning but of course tensorflow is written in Python so ultimately if we want to",
    "start": "1535829",
    "end": "1542339"
  },
  {
    "text": "execute this we're gonna have to execute some Python code and what we're able to do is we're able to interject Python",
    "start": "1542339",
    "end": "1548369"
  },
  {
    "text": "code into this largely visual code free work workflow we can add the Python code",
    "start": "1548369",
    "end": "1553969"
  },
  {
    "text": "very easily just by linking to one of the notebooks that I showed you in our collaborative workspace that venkat has",
    "start": "1553969",
    "end": "1560549"
  },
  {
    "text": "been working on at Marion's request now originally when we were building this demo we just had a single node",
    "start": "1560549",
    "end": "1566879"
  },
  {
    "text": "implementation of tense flow had to write a lot of code to get it to work it doesn't necessarily scale particularly",
    "start": "1566879",
    "end": "1572190"
  },
  {
    "text": "well but that's how we built the initial demo and what we were able to do is then to say to venkat well we really like to",
    "start": "1572190",
    "end": "1577259"
  },
  {
    "text": "run this in parallel we'd really like to leverage Sage Maker to simplify the structure of the Python code and so",
    "start": "1577259",
    "end": "1583529"
  },
  {
    "text": "that's what he ended up doing so now we're using sage maker if I open up the notebook that we're using here it is",
    "start": "1583529",
    "end": "1589559"
  },
  {
    "text": "back out in that in that workspace let me open this up so directly within the",
    "start": "1589559",
    "end": "1595139"
  },
  {
    "text": "workspace you see I've been able to open up visual workflows so that's one way you can work but I can also directly within the workspace open up the Python",
    "start": "1595139",
    "end": "1602519"
  },
  {
    "text": "notebook and so here you now see us building the Auto encoding model leveraging sage",
    "start": "1602519",
    "end": "1608830"
  },
  {
    "text": "maker to simplify the process of using tensor flow or it could of course be other algorithms that sage maker",
    "start": "1608830",
    "end": "1614350"
  },
  {
    "text": "supports so we start off by first of all selecting the data set the platform gives you a nice API for reaching out",
    "start": "1614350",
    "end": "1621250"
  },
  {
    "text": "and selecting those data sets I can even select them from a menu here of data",
    "start": "1621250",
    "end": "1626500"
  },
  {
    "text": "sets that the data type science team in this workspace is highlighted very easy to use even in that case this code is",
    "start": "1626500",
    "end": "1632140"
  },
  {
    "text": "auto-generated to point at that data set I then select the columns that I'm going",
    "start": "1632140",
    "end": "1637270"
  },
  {
    "text": "to use for training the model I open up the sage maker session here get that",
    "start": "1637270",
    "end": "1643150"
  },
  {
    "text": "started I need to define the parameters of the model the hidden layers and so on and so we've",
    "start": "1643150",
    "end": "1651010"
  },
  {
    "text": "got that defined in a Python file that's also in this workspace you probably saw it there the list at the bottom we got",
    "start": "1651010",
    "end": "1656140"
  },
  {
    "text": "this train dot PI Python that sits alongside this Python notebook so we download that again we use an API that",
    "start": "1656140",
    "end": "1662770"
  },
  {
    "text": "the platform provides you so you can download that file and feed that into tensorflow so it's very nice try to be",
    "start": "1662770",
    "end": "1667929"
  },
  {
    "text": "able to keep my visual workflow my Python notebooks my my tensor flow graph",
    "start": "1667929",
    "end": "1674380"
  },
  {
    "text": "configuration we're gonna see later dashboard sequel files all of that could be collected together and worked on in",
    "start": "1674380",
    "end": "1680320"
  },
  {
    "text": "the same collaborative environment and all the versioning and collaboration and note-taking happening at the same time",
    "start": "1680320",
    "end": "1686130"
  },
  {
    "text": "anyway so having downloaded the definition of the the tensor flow graph",
    "start": "1686130",
    "end": "1691570"
  },
  {
    "text": "in this train dot pi here I can now actually execute it using sage maker and sage maker makes it beautifully simple",
    "start": "1691570",
    "end": "1698679"
  },
  {
    "text": "in just a few lines of code to be able to execute tensorflow and not just execute it but then actually to fully",
    "start": "1698679",
    "end": "1705549"
  },
  {
    "text": "distribute that computation across multiple nodes and just handle all the configuration the setup required to do",
    "start": "1705549",
    "end": "1710980"
  },
  {
    "text": "that so in just a few lines of code I'm actually setting up three ml c4x large",
    "start": "1710980",
    "end": "1716440"
  },
  {
    "text": "clusters nodes in the cluster where sage maker is going to pass the Train dot PI",
    "start": "1716440",
    "end": "1722500"
  },
  {
    "text": "file and have tensorflow do its work so off it goes here you see the log file being generated here once the model gets",
    "start": "1722500",
    "end": "1729549"
  },
  {
    "text": "created essentially a protobuf file that contains the the weights and the biases",
    "start": "1729549",
    "end": "1735909"
  },
  {
    "text": "that have being trained by their being discovered during the training by the model I'm now going to take that back out of s3 unwrap",
    "start": "1735909",
    "end": "1741970"
  },
  {
    "text": "it and then ask tensorflow we could do this via tensorflow we can do it by a sage maker to make it easier",
    "start": "1741970",
    "end": "1748090"
  },
  {
    "text": "ask sage a stencil or ultimately to run the prediction on the input data set so",
    "start": "1748090",
    "end": "1754510"
  },
  {
    "text": "it seems perverse in some way we're running it directly it's everything data Sciences are taught not to do is run your model back on the original data set",
    "start": "1754510",
    "end": "1760360"
  },
  {
    "text": "but it serves this useful purpose now that we get to see how that gets reconstructed from the model after that",
    "start": "1760360",
    "end": "1766330"
  },
  {
    "text": "lower dimensionality passed through and then we can see whether these new predicted columns that the same columns",
    "start": "1766330",
    "end": "1772120"
  },
  {
    "text": "we had originally but these new predicted columns how they match back to the original data set so that's great",
    "start": "1772120",
    "end": "1777870"
  },
  {
    "text": "sage maker and tensorflow have done their work so let me hop out of here now",
    "start": "1777870",
    "end": "1783490"
  },
  {
    "text": "and go back to the visual workflow let me just emphasize there before I look at the downstream operations what we've",
    "start": "1783490",
    "end": "1789220"
  },
  {
    "text": "done here right we've got a vast array of algorithms we could use but in order",
    "start": "1789220",
    "end": "1795940"
  },
  {
    "text": "to do this tensor flow operation up until this point it would have been much more difficult than just dragging on one",
    "start": "1795940",
    "end": "1801430"
  },
  {
    "text": "of these operators as we've done with the others I have to write a lot of code but by using our Python notebook",
    "start": "1801430",
    "end": "1808240"
  },
  {
    "text": "integration with sage maker we've been able to make this essentially a template that the data scientist that Marion can",
    "start": "1808240",
    "end": "1815500"
  },
  {
    "text": "use here just drag it on choose that notebook and then run that algorithm leveraging sage maker through the",
    "start": "1815500",
    "end": "1822490"
  },
  {
    "text": "integration with the data science platform to make that as straightforward as possible if you ever worked with tensorflow before or some of these other",
    "start": "1822490",
    "end": "1828490"
  },
  {
    "text": "algorithms that sage maker works with you realize just how much sage maker affords you in terms of setting it up",
    "start": "1828490",
    "end": "1833920"
  },
  {
    "text": "and then the data science platform then makes that accessible really to the whole team okay so now we've got the",
    "start": "1833920",
    "end": "1839500"
  },
  {
    "text": "output of that auto-encoder model and you can see here these predicted columns that are the output of the model and we",
    "start": "1839500",
    "end": "1845650"
  },
  {
    "text": "want to match them back to what the original model looked like to find the anomalies where it's changed too much so",
    "start": "1845650",
    "end": "1851470"
  },
  {
    "text": "the first thing was we have to join back to the original data set and again that's very easy to do no code here's a",
    "start": "1851470",
    "end": "1856810"
  },
  {
    "text": "nice simple join where I'm joining back on the original sort of come composite primary key where it's the the plant and",
    "start": "1856810",
    "end": "1863350"
  },
  {
    "text": "the mill and the time of day one thing is interesting about this apart from the fact that you know it's this nice way of",
    "start": "1863350",
    "end": "1869110"
  },
  {
    "text": "doing joins by the way this join could be happening in redshift it could be happening in Aurora it could be happening on EMR it",
    "start": "1869110",
    "end": "1875890"
  },
  {
    "text": "could be happening on spark as a data scientist I don't care it's the same interface but it all gets pushed down in",
    "start": "1875890",
    "end": "1881830"
  },
  {
    "text": "the right way through spark sequel hive sequel whatever it might be but what's interesting here is you notice I think",
    "start": "1881830",
    "end": "1888429"
  },
  {
    "text": "this is a really nice feature in fact we've patented a or in the post patent to get where we can auto inspect the",
    "start": "1888429",
    "end": "1894850"
  },
  {
    "text": "structure of that Python notebook and we see what did Venkat used as his input data sets and what were the structure of",
    "start": "1894850",
    "end": "1900880"
  },
  {
    "text": "those and what did he generate at the end as the output and what was the structure of those so I know even if",
    "start": "1900880",
    "end": "1906909"
  },
  {
    "text": "before I've run it what the structure of the sage maker model is you can see here",
    "start": "1906909",
    "end": "1912460"
  },
  {
    "text": "there is my predicted columns and those are the ones that I've selected to include in my join so it's a very nice",
    "start": "1912460",
    "end": "1918970"
  },
  {
    "text": "way of being able to integrate with Python notebooks in a way that they become just these structured operators",
    "start": "1918970",
    "end": "1925059"
  },
  {
    "text": "like just like all of the others okay so having joined back to the original data sets now I've got all my input columns",
    "start": "1925059",
    "end": "1931030"
  },
  {
    "text": "and all my output columns with this prediction pred prefix here now I can",
    "start": "1931030",
    "end": "1937270"
  },
  {
    "text": "compute the reconstruction error essentially by computing a root mean square error distance I think it is between the input variables and the",
    "start": "1937270",
    "end": "1943150"
  },
  {
    "text": "output variables and there you see that metric here now by itself that's a useful data set but we'd really like to",
    "start": "1943150",
    "end": "1949059"
  },
  {
    "text": "visualize that and of course visualization is also part of the TIBCO platform so what I'm going to do is I'm",
    "start": "1949059",
    "end": "1956020"
  },
  {
    "text": "going to use Spotfire best visualization tool I know to to review these reconstruction areas and see how they",
    "start": "1956020",
    "end": "1962440"
  },
  {
    "text": "may be very overtime or in the context of a particular power plant or whatever it might be expose that to the end-user",
    "start": "1962440",
    "end": "1968080"
  },
  {
    "text": "basically as a dashboard now Spotify can actually connect directly to EMR and",
    "start": "1968080",
    "end": "1973090"
  },
  {
    "text": "just read this data set but it turns out for the purposes of the demo we've got some plant information these are the",
    "start": "1973090",
    "end": "1978850"
  },
  {
    "text": "processing plants they're power plants rather and we've got some basic geographical information that I'd like to join onto this that I can actually",
    "start": "1978850",
    "end": "1984490"
  },
  {
    "text": "map these outlet literally on on a geographic map and that's sitting on redshift so I copy the output of this",
    "start": "1984490",
    "end": "1990610"
  },
  {
    "text": "workflow I say we never move data sometimes we move data I copy that over to red shift from EMR I join that to my",
    "start": "1990610",
    "end": "1997270"
  },
  {
    "text": "location information and I've got a data set now that's ready for me to visualize so let me hop out of this",
    "start": "1997270",
    "end": "2004020"
  },
  {
    "text": "data science workflow and now I can launch a dashboard that's actually going to run on that redshift data set so here",
    "start": "2004020",
    "end": "2012570"
  },
  {
    "text": "alongside my Python notebooks and my Python definition file is this dashboard so let me launch that and so this is",
    "start": "2012570",
    "end": "2019170"
  },
  {
    "text": "Spotfire it's connecting to redshift so let me enter my redshift credentials which have been cached so this Spotify is also running as part",
    "start": "2019170",
    "end": "2026220"
  },
  {
    "text": "of the data science platform up in the cloud and it's connecting directly to redshift connecting directly in fact to",
    "start": "2026220",
    "end": "2033059"
  },
  {
    "text": "the data set that the workflow produced and here you see the map that shows the different plants and mills that were",
    "start": "2033059",
    "end": "2040320"
  },
  {
    "text": "mapping in this data set here we're using the location information to draw it out on this on this on this map and",
    "start": "2040320",
    "end": "2048960"
  },
  {
    "text": "here you see the histogram of the reconstruction errors so I can identify sort of the outliers here and as time",
    "start": "2048960",
    "end": "2055110"
  },
  {
    "text": "goes by we can show the reconstruction error here on the y axis over time so we",
    "start": "2055110",
    "end": "2061710"
  },
  {
    "text": "can see particular points so what I can do is I can just highlight those",
    "start": "2061710",
    "end": "2066720"
  },
  {
    "text": "outliers here or I can also use it and you see they're automatically",
    "start": "2066720",
    "end": "2072060"
  },
  {
    "text": "highlighted on the time series chart or I can actually focus on one particular point in time so if I just identified",
    "start": "2072060",
    "end": "2077790"
  },
  {
    "text": "that that's actually not only integrated with all the other charts on this dashboard but even on other tabs on the",
    "start": "2077790",
    "end": "2085169"
  },
  {
    "text": "dashboard I see how that relates to those charts as well here I'm looking at over time",
    "start": "2085169",
    "end": "2090388"
  },
  {
    "text": "each of those individual variables the pressure the temperature the production",
    "start": "2090389",
    "end": "2096628"
  },
  {
    "text": "readings and all those things that I had in my input data set I'm looking at each of those individually maybe this will",
    "start": "2096629",
    "end": "2101850"
  },
  {
    "text": "help me do a root cause analysis right so I know there was an anomaly here according to my model what might have",
    "start": "2101850",
    "end": "2108330"
  },
  {
    "text": "driven that well probably not things like put the gas emissions or the loss",
    "start": "2108330",
    "end": "2113609"
  },
  {
    "text": "of efficiency or the power these don't necessarily look particularly nominal as to me but look at all these differential pressures down here they all spiked at",
    "start": "2113609",
    "end": "2120240"
  },
  {
    "text": "exactly the same time that this anomaly happened so that's a clue that I might use in order to investigate what's going",
    "start": "2120240",
    "end": "2125400"
  },
  {
    "text": "on in the power plant we can even then take that information and pass that on to the technicians here in this map",
    "start": "2125400",
    "end": "2132390"
  },
  {
    "text": "we're actually identifying where the anomaly happened and which technicians are closest",
    "start": "2132390",
    "end": "2137550"
  },
  {
    "text": "to that so that they can go in and analyze what's going on with this particular anomaly",
    "start": "2137550",
    "end": "2143210"
  },
  {
    "text": "so what we've seen here is a mechanism really to make processing data from end",
    "start": "2143210",
    "end": "2151140"
  },
  {
    "text": "to end from taking the data cleansing it transforming it building complex models",
    "start": "2151140",
    "end": "2156800"
  },
  {
    "text": "pushing that out into a scored data set maybe into another repository and then",
    "start": "2156800",
    "end": "2163560"
  },
  {
    "text": "ultimately visualizing that all those different elements making that very easy a lot of drag-and-drop minimal coding",
    "start": "2163560",
    "end": "2168900"
  },
  {
    "text": "but using code when you need to break out of the constraints of the system got all those things together but very easy",
    "start": "2168900",
    "end": "2175260"
  },
  {
    "text": "to use and so we really do think of this integration between our data science platform and what Amazon has provided in",
    "start": "2175260",
    "end": "2181800"
  },
  {
    "text": "terms of their data platforms and their machine learning libraries and the machine learning framework is a really",
    "start": "2181800",
    "end": "2187920"
  },
  {
    "text": "powerful end-to-end system performing for performing these sorts of complex analyses in a collaborative setting and",
    "start": "2187920",
    "end": "2194910"
  },
  {
    "text": "it isn't as I said just a demo just recently in fact one of the healthcare companies with which TIBCO has worked",
    "start": "2194910",
    "end": "2200970"
  },
  {
    "text": "did analysis of clinical trials looking at genomic gene sequencing data and",
    "start": "2200970",
    "end": "2206520"
  },
  {
    "text": "looking at anomalies within the genomic data using precisely this mechanism",
    "start": "2206520",
    "end": "2211980"
  },
  {
    "text": "literally this software this template that we've created but just converting the data set to use gene sequencing data",
    "start": "2211980",
    "end": "2218310"
  },
  {
    "text": "which is actually much wider instead of say pressure readings and they've just got 45 minutes training in a week later",
    "start": "2218310",
    "end": "2224690"
  },
  {
    "text": "venkat told me they had this up and running so I think this'll astray --tz--",
    "start": "2224690",
    "end": "2230220"
  },
  {
    "text": "the fact that you really can simplify this process without losing the sophistication that you need in terms of",
    "start": "2230220",
    "end": "2235800"
  },
  {
    "text": "algorithms or scalability okay thanks Michael very good thanks for a great",
    "start": "2235800",
    "end": "2241050"
  },
  {
    "text": "demo",
    "start": "2241050",
    "end": "2243320"
  },
  {
    "text": "so as I mentioned this demo the data science piece can be set up as a scoring service and feed into identifying the",
    "start": "2248540",
    "end": "2255900"
  },
  {
    "text": "anomalies on an incoming data stream putting those into case management for for resolution and then tracking those",
    "start": "2255900",
    "end": "2263640"
  },
  {
    "text": "anomalies figuring out if one's a real anomaly or not a real anomaly going back with that new label data and updating",
    "start": "2263640",
    "end": "2270150"
  },
  {
    "text": "the model and this this set of artifacts is available for download from the TIBCO",
    "start": "2270150",
    "end": "2275760"
  },
  {
    "text": "community you can go play with this yourself build your own application there's a community doctor cocom there's",
    "start": "2275760",
    "end": "2282990"
  },
  {
    "text": "a bunch of materials for understanding how to build these things both on the",
    "start": "2282990",
    "end": "2288569"
  },
  {
    "text": "TIBCO data science side as well as the Spotfire side and then if you go to the exchange part of the community site this",
    "start": "2288569",
    "end": "2294599"
  },
  {
    "text": "part here this is where you can download some of these assets so as I mentioned the anomaly detection framework of",
    "start": "2294599",
    "end": "2301160"
  },
  {
    "text": "finding training a model on historical data applying that to new incoming data flagging the anomalies case map this is",
    "start": "2301160",
    "end": "2308460"
  },
  {
    "text": "a general pattern that we use for risk management we have used it for high tech manufacturing so if you're in the high",
    "start": "2308460",
    "end": "2314849"
  },
  {
    "text": "tech manufacturing sector download this accelerator and you'll get that same approach that we saw today applied to",
    "start": "2314849",
    "end": "2320310"
  },
  {
    "text": "high-tech manufacturing sequence if you're in financial services download the risk investigation application apply",
    "start": "2320310",
    "end": "2326970"
  },
  {
    "text": "that to things like anti money laundering of financial fraud accelerator",
    "start": "2326970",
    "end": "2332190"
  },
  {
    "text": "it's the anomaly detection stuff we've got availables templates in typical data science as well as in Spotfire and then",
    "start": "2332190",
    "end": "2338550"
  },
  {
    "text": "you can build your own application and the TIBCO connected intelligence cloud for your own use case so that's pretty",
    "start": "2338550",
    "end": "2344579"
  },
  {
    "text": "much what I wanted to cover today and I wanted to now open it up for any questions we've got a couple of microphones set up and you feel free to",
    "start": "2344579",
    "end": "2352260"
  },
  {
    "text": "contact me or Stephen for any detailed questions as follow-up but one to open the floor and see if we had any",
    "start": "2352260",
    "end": "2357450"
  },
  {
    "text": "discussion points that anyone want to raise as we have any microphones I'm not",
    "start": "2357450",
    "end": "2362700"
  },
  {
    "text": "sure if there's microphones stood up out there we can repeat the question I guess questions",
    "start": "2362700",
    "end": "2369500"
  },
  {
    "text": "kind of blind it up here I can't see if anyone's to really go to go to Christian fish we you know we're happy to to",
    "start": "2371110",
    "end": "2377630"
  },
  {
    "text": "interact there's a there's a guy there I'm sorry what yeah so you saw instead when Steven was",
    "start": "2377630",
    "end": "2384980"
  },
  {
    "text": "demonstrating repeat the question sorry repeat the question so yeah does this come with Spotfire built-in yeah so you",
    "start": "2384980",
    "end": "2391610"
  },
  {
    "text": "saw it's a very collaborative in bar environment so when you build out the connections you know the the scoring",
    "start": "2391610",
    "end": "2398300"
  },
  {
    "text": "service the Spotfire dashboard these are all part of this slack style tracking of things so there's a variety of ways to",
    "start": "2398300",
    "end": "2404990"
  },
  {
    "text": "consume this but typically you've got your Spotfire dashboard built from the results of the predictions combined",
    "start": "2404990",
    "end": "2410570"
  },
  {
    "text": "without a contextual data and tracked inside of the TIBCO data science collaborative platform yeah good",
    "start": "2410570",
    "end": "2417170"
  },
  {
    "text": "question so nicely everybody's probably running off to something else but if you",
    "start": "2417170",
    "end": "2423500"
  },
  {
    "text": "want to come up and ask Steven or any personal questions about what we showed today would be very open to that as well",
    "start": "2423500",
    "end": "2429410"
  },
  {
    "text": "and tomorrow we're over at the Aria quad in the in the morning working on showing",
    "start": "2429410",
    "end": "2437180"
  },
  {
    "text": "some of the algorithms in more detail some of the use cases in a little bit longer of a format and then if you want",
    "start": "2437180",
    "end": "2442880"
  },
  {
    "text": "to come drive the f1 car at the TIBCO booth we're sort of in the back too near the MongoDB booth and we've got a car",
    "start": "2442880",
    "end": "2450080"
  },
  {
    "text": "set up where you can drive the car you can see you know the data coming up on the screen and live in in Spotfire and",
    "start": "2450080",
    "end": "2455630"
  },
  {
    "text": "there's a competition going on for the lap time there right now so I guess",
    "start": "2455630",
    "end": "2461960"
  },
  {
    "text": "that's that's about it thanks everybody [Applause]",
    "start": "2461960",
    "end": "2468750"
  }
]
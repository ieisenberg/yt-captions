[
  {
    "start": "0",
    "end": "70000"
  },
  {
    "text": "hi everyone my name is amir basirat and i'm an analytics specialist solutions architect at aws",
    "start": "2240",
    "end": "9840"
  },
  {
    "text": "in this quick presentation which will be accompanied with a demo i will demonstrate the aws game analytics",
    "start": "9840",
    "end": "15839"
  },
  {
    "text": "pipeline solution that can help game developers launch a scalable serverless data",
    "start": "15839",
    "end": "21279"
  },
  {
    "text": "pipeline to ingest the store and analyze telemetry data generated from games and services",
    "start": "21279",
    "end": "27840"
  },
  {
    "text": "we know the games industry is increasing adoption of the games as a service operating model where games have become",
    "start": "27840",
    "end": "34160"
  },
  {
    "text": "more like a service than a product and revenue is frequently generated through in-app purchases",
    "start": "34160",
    "end": "40559"
  },
  {
    "text": "subscriptions and other techniques with this change it is critical to develop a deeper",
    "start": "40559",
    "end": "46160"
  },
  {
    "text": "understanding of how players use the features of games and related services",
    "start": "46160",
    "end": "51360"
  },
  {
    "text": "and this understanding allows us to continually adopt and make the necessary changes to keep players engaged",
    "start": "51360",
    "end": "58320"
  },
  {
    "text": "the solution that i'm going to present here supports the streaming ingestion of data while allowing users to gain insights",
    "start": "58320",
    "end": "65760"
  },
  {
    "text": "from their games and other applications within minutes first let's look at the",
    "start": "65760",
    "end": "72640"
  },
  {
    "start": "70000",
    "end": "497000"
  },
  {
    "text": "solution architecture and we will provide you with a cloudformation template that you can deploy",
    "start": "72640",
    "end": "78400"
  },
  {
    "text": "in your aws account and deploying the cloudformation template with the default",
    "start": "78400",
    "end": "83520"
  },
  {
    "text": "parameters builds this environment as you can see here in fact the aws cloudformation template",
    "start": "83520",
    "end": "90159"
  },
  {
    "text": "deploys all the required aws resources to enable the ingestion",
    "start": "90159",
    "end": "95759"
  },
  {
    "text": "analysis monitoring and reporting of game analytics data and sets up the infrastructure to",
    "start": "95759",
    "end": "102560"
  },
  {
    "text": "support a serverless data pipeline let's further zoom into each of our",
    "start": "102560",
    "end": "108240"
  },
  {
    "text": "solutions building blocks and discuss their functionality",
    "start": "108240",
    "end": "113840"
  },
  {
    "text": "data producers send telemetry data to amazon kinesis data streams or to amazon",
    "start": "113840",
    "end": "119600"
  },
  {
    "text": "api gateway with amazon api gateway average game analytics pipeline solution",
    "start": "119600",
    "end": "125600"
  },
  {
    "text": "launches a rest api that provides an events endpoint for sending telemetry data to the",
    "start": "125600",
    "end": "131920"
  },
  {
    "text": "pipeline this provides an um an integration option for applications that cannot integrate with",
    "start": "131920",
    "end": "139120"
  },
  {
    "text": "amazon can assist directly the api also provides configuration",
    "start": "139120",
    "end": "144160"
  },
  {
    "text": "endpoints for admins to use for registering their game applications with the solution and generating api",
    "start": "144160",
    "end": "151760"
  },
  {
    "text": "keys for developers to use when sending events to the rest api the telemetry data which is sent to the",
    "start": "151760",
    "end": "158640"
  },
  {
    "text": "api is then proxy to amazon can assist data streams",
    "start": "158640",
    "end": "164160"
  },
  {
    "text": "the game analytics pipeline solution uses amazon kinesis to ingest and process telemetry data from games",
    "start": "164160",
    "end": "171680"
  },
  {
    "text": "amazon kinesis data streams ingest the incoming data amazon can access data fire hose",
    "start": "171680",
    "end": "177599"
  },
  {
    "text": "consumes and delivers streaming data to amazon's simple storage service or amazon s3 and amazon",
    "start": "177599",
    "end": "184159"
  },
  {
    "text": "kinesis data analytics for sql applications generates real-time metrics using the",
    "start": "184159",
    "end": "190000"
  },
  {
    "text": "streaming sql queries and the kinesis data streams also uses aws key management service or aws kms",
    "start": "190000",
    "end": "198080"
  },
  {
    "text": "for encryption at rest the solution also uses aws lambda",
    "start": "198080",
    "end": "204480"
  },
  {
    "text": "functions to provide data processing transformation and validation for configuration data we",
    "start": "204480",
    "end": "211760"
  },
  {
    "text": "have an aws lambda function that provides back-end business logic for the solutions rest",
    "start": "211760",
    "end": "217280"
  },
  {
    "text": "api configuration endpoints this function stores newly created game application configurations in amazon",
    "start": "217280",
    "end": "224840"
  },
  {
    "text": "dynamodb and generates api key authorizations for developers to integrate with the rest api",
    "start": "224840",
    "end": "231519"
  },
  {
    "text": "events endpoint the solution uses amazon dynamodb tables to store application",
    "start": "231519",
    "end": "237519"
  },
  {
    "text": "configuration data each dynamodb table is provisioned using dynamodb",
    "start": "237519",
    "end": "243040"
  },
  {
    "text": "on demand capacity to provide flexible scaling and reduce costs for unpredictable",
    "start": "243040",
    "end": "248799"
  },
  {
    "text": "access patterns in dynamodb we will have two tables applications table",
    "start": "248799",
    "end": "254799"
  },
  {
    "text": "which is a table that contains data about the applications registered by data producers and it is",
    "start": "254799",
    "end": "261040"
  },
  {
    "text": "identified by application id and we will have authorizations table a",
    "start": "261040",
    "end": "266160"
  },
  {
    "text": "table that stores api keys identified by api key id with a mapping to an",
    "start": "266160",
    "end": "272720"
  },
  {
    "text": "application id within a streaming ingestion building block we have another lambda function",
    "start": "272720",
    "end": "279040"
  },
  {
    "text": "that validates transforms and processes input game events from kinesis data firehose",
    "start": "279040",
    "end": "285040"
  },
  {
    "text": "before events are loaded into amazon history this function invokes with a batch of",
    "start": "285040",
    "end": "290880"
  },
  {
    "text": "input event records and performs validation and processing before returning transform records back to",
    "start": "290880",
    "end": "298080"
  },
  {
    "text": "kinesis data firehouse for delivery to amazon s3 this function can also be modified to add additional",
    "start": "298080",
    "end": "304960"
  },
  {
    "text": "data processing is needed then within a streaming analytics",
    "start": "304960",
    "end": "310000"
  },
  {
    "text": "building block we have another aws lambda function that processes a batch of sql results from the kinesis data",
    "start": "310000",
    "end": "317199"
  },
  {
    "text": "analytics application and publishes them to amazon cloudwatch as custom metrics",
    "start": "317199",
    "end": "322800"
  },
  {
    "text": "this function can also be customized to accept different output formats or perform additional processing",
    "start": "322800",
    "end": "329199"
  },
  {
    "text": "and delivery to other destinations if needed the solution uses amazon's simple sword",
    "start": "329199",
    "end": "335440"
  },
  {
    "text": "service or amazon s3 to provide a scalable and cost-effective storage for raw and processed data sets",
    "start": "335440",
    "end": "342800"
  },
  {
    "text": "the amazon s3 buckets are configured with object lifecycle management policies",
    "start": "342800",
    "end": "348880"
  },
  {
    "text": "including amazon s3 intelligent tiering which provides cost savings for data sets with unknown",
    "start": "348880",
    "end": "355520"
  },
  {
    "text": "or changing changing access patterns such as data lakes",
    "start": "355520",
    "end": "362400"
  },
  {
    "text": "the solution also deploys aws glue resources for metadata storage and etl",
    "start": "363440",
    "end": "369039"
  },
  {
    "text": "processing we configure an aws glue data catalog we create an aws glue database to serve",
    "start": "369039",
    "end": "375759"
  },
  {
    "text": "as the metadata store for ingested data we deploy an aws glue etl job for",
    "start": "375759",
    "end": "381840"
  },
  {
    "text": "processing game events and we deploy an aws glue crawler to",
    "start": "381840",
    "end": "386960"
  },
  {
    "text": "update the glue data catalog with processing results i should also mention that",
    "start": "386960",
    "end": "392000"
  },
  {
    "text": "um the solution encrypts the aws glue data catalog using kms for metrics and notifications",
    "start": "392000",
    "end": "399919"
  },
  {
    "text": "you can use amazon cloudwatch and amazon's simple notification service or amazon sns",
    "start": "399919",
    "end": "406479"
  },
  {
    "text": "the solution uses amazon cloudwatch to monitor and lock the solutions resources and",
    "start": "406479",
    "end": "412000"
  },
  {
    "text": "provide a storage of real-time generated metrics from kinesis data analytics",
    "start": "412000",
    "end": "417199"
  },
  {
    "text": "the solution deploys cloudwatch alarms to track the usage of aws resources",
    "start": "417199",
    "end": "422639"
  },
  {
    "text": "and alert admin subscribers when issues are detected with amazon's sample notification",
    "start": "422639",
    "end": "428639"
  },
  {
    "text": "service or amazon sns you can also distribute notifications generated by amazon cloudwatch alarms",
    "start": "428639",
    "end": "435199"
  },
  {
    "text": "when resources are set above thresholds or errors are detected and the solutions",
    "start": "435199",
    "end": "440880"
  },
  {
    "text": "admin can also set up notifications for monitoring and troubleshooting purposes",
    "start": "440880",
    "end": "448240"
  },
  {
    "text": "for interactive analytics you can use amazon athena and amazon quake site",
    "start": "448240",
    "end": "453440"
  },
  {
    "text": "amazon athena enables you to run queries and reports and the game events data",
    "start": "453440",
    "end": "458639"
  },
  {
    "text": "stored in amazon street buckets you can also set up athena federated query connectors for dynamodb",
    "start": "458639",
    "end": "465520"
  },
  {
    "text": "or for cloudwatch metrics to extract that data the solution comes with a set of",
    "start": "465520",
    "end": "470879"
  },
  {
    "text": "pre-built saved queries that enable you to explore game events data",
    "start": "470879",
    "end": "476080"
  },
  {
    "text": "and it deploys the natino work group that enables you to create and save additional queries if you want",
    "start": "476080",
    "end": "482479"
  },
  {
    "text": "um you can also visualize game data using amazon quick site you can connect amazon quick site to",
    "start": "482479",
    "end": "488639"
  },
  {
    "text": "amazon athena to access your game data and you can create configure and",
    "start": "488639",
    "end": "493759"
  },
  {
    "text": "customize dashboards for deep data exploration okay let's",
    "start": "493759",
    "end": "498800"
  },
  {
    "start": "497000",
    "end": "765000"
  },
  {
    "text": "jump into aws management console so that i can show you the demo and walk you through the process of",
    "start": "498800",
    "end": "505919"
  },
  {
    "text": "setting up the environment and the steps involved",
    "start": "505919",
    "end": "510800"
  },
  {
    "text": "okay to get cloudformation template and deploy that cf template in your aws",
    "start": "512399",
    "end": "517839"
  },
  {
    "text": "account you have to first go to aws solutions implementations page where you can find",
    "start": "517839",
    "end": "524000"
  },
  {
    "text": "details of game analytics pipeline solution",
    "start": "524000",
    "end": "529040"
  },
  {
    "text": "i should mention that all aws solutions implementations listed here are wetted by aws architects and they",
    "start": "529040",
    "end": "536560"
  },
  {
    "text": "are designed to be operationally effective reliable secure and cost efficient every aws solutions",
    "start": "536560",
    "end": "543839"
  },
  {
    "text": "implementation including the one that we want to implement here comes with detailed architecture a deployment guide",
    "start": "543839",
    "end": "551760"
  },
  {
    "text": "implementation guide and instructions for both automated and manual deployment let's uh let's",
    "start": "551760",
    "end": "559120"
  },
  {
    "text": "launch the cloudformation template in aws console and this solution uses aws m cloud",
    "start": "559120",
    "end": "565519"
  },
  {
    "text": "formation to automate the deployment of game analytics pipeline solution in aws cloud",
    "start": "565519",
    "end": "571839"
  },
  {
    "text": "you can review the template parameters and adjust them if necessary",
    "start": "571839",
    "end": "577040"
  },
  {
    "text": "the template launches in the us east north virginia region by default but you",
    "start": "577040",
    "end": "582399"
  },
  {
    "text": "can change that if you want on the create stack box and verify that",
    "start": "582399",
    "end": "587760"
  },
  {
    "text": "the correct template url shows in the amazon s3 url text box and then choose next on the specify",
    "start": "587760",
    "end": "596560"
  },
  {
    "text": "stack details page assign a name to your solution stack i put game analytics",
    "start": "596560",
    "end": "605200"
  },
  {
    "text": "pipeline under parameters review the parameters",
    "start": "605200",
    "end": "612320"
  },
  {
    "text": "for the template and modify them as necessary",
    "start": "612320",
    "end": "617519"
  },
  {
    "text": "the enable streaming analytics temp parameter is set to true and this parameter determines whether",
    "start": "617519",
    "end": "624880"
  },
  {
    "text": "kinesis data analytics for sql is going to be deployed in the solution or not",
    "start": "624880",
    "end": "630399"
  },
  {
    "text": "and kinesis stream charts is set to one which sets the number of charts to",
    "start": "630399",
    "end": "635680"
  },
  {
    "text": "provision for canes data streams um solution admin email address is set",
    "start": "635680",
    "end": "640959"
  },
  {
    "text": "to false you can set that to true if you want to nominate an email address",
    "start": "640959",
    "end": "646399"
  },
  {
    "text": "to receive operational notifications generated by solutions resources and delivered by amazon cloudwatch the",
    "start": "646399",
    "end": "653839"
  },
  {
    "text": "default false parameter here disables the subscription to amazon sns topic",
    "start": "653839",
    "end": "659680"
  },
  {
    "text": "and then finally the solution mode parameter is set to depth so you can have two options here",
    "start": "659680",
    "end": "665279"
  },
  {
    "text": "you can have dev or prod dev mode reduces the kinesis data fire host",
    "start": "665279",
    "end": "670480"
  },
  {
    "text": "buffer interval to every one minute to speed up data delivery to amazon s3",
    "start": "670480",
    "end": "675839"
  },
  {
    "text": "during testing but this results in less optimized batching",
    "start": "675839",
    "end": "680880"
  },
  {
    "text": "and dev mode also deploys the sample athena queries and creates a sample application and api",
    "start": "680880",
    "end": "687600"
  },
  {
    "text": "key for testing purposes a few if you mention prod here prod mode configures can",
    "start": "687600",
    "end": "695440"
  },
  {
    "text": "assist data fire hose with a buffer interval of 15 minutes and doesn't deploy the sample athena",
    "start": "695440",
    "end": "701920"
  },
  {
    "text": "queries or sample application and api key so we'll leave it for that for our testing",
    "start": "701920",
    "end": "708000"
  },
  {
    "text": "purposes here and click next on the configure stack options page",
    "start": "708000",
    "end": "715519"
  },
  {
    "text": "simply choose next on the review page review and confirm the settings",
    "start": "715519",
    "end": "723040"
  },
  {
    "text": "check the check the boxes at the end the three boxes acknowledging that the",
    "start": "723040",
    "end": "728959"
  },
  {
    "text": "template will create um aws identity and access management",
    "start": "728959",
    "end": "734320"
  },
  {
    "text": "or im resources and then um choose create a stack um to to deploy",
    "start": "734320",
    "end": "740800"
  },
  {
    "text": "the stack and you can view um the status of the of the stack in the aws cloud formation",
    "start": "740800",
    "end": "747600"
  },
  {
    "text": "console in the status column um you should receive a status of",
    "start": "747600",
    "end": "753200"
  },
  {
    "text": "create complete in approximately five to ten minutes i stop my recording here and resume as",
    "start": "753200",
    "end": "759360"
  },
  {
    "text": "soon as the template is is deployed successfully bear with me",
    "start": "759360",
    "end": "765360"
  },
  {
    "text": "okay we can see that our cloudformation template is deployed successfully and now that",
    "start": "765680",
    "end": "772480"
  },
  {
    "text": "the stack is deployed we can navigate to the outputs tab where we can see a list of parameters",
    "start": "772480",
    "end": "780000"
  },
  {
    "text": "and values that cloudformation template has generated for us we need some of these values like game",
    "start": "780000",
    "end": "787360"
  },
  {
    "text": "events stream or test application id to generate sample game events",
    "start": "787360",
    "end": "794240"
  },
  {
    "text": "let's open the terminal and follow a few steps to generate sample",
    "start": "794240",
    "end": "799839"
  },
  {
    "text": "game events as part of average game analytics pipeline solution we also",
    "start": "799839",
    "end": "805760"
  },
  {
    "text": "provide you with a python demo script to generate sample game events data for",
    "start": "805760",
    "end": "811200"
  },
  {
    "text": "your testing and demonstration to run the python script you must have the latest version",
    "start": "811200",
    "end": "817279"
  },
  {
    "text": "of aws command line interface or aws cli um",
    "start": "817279",
    "end": "824560"
  },
  {
    "text": "so if please install aws cli if if you don't have aws cli",
    "start": "825440",
    "end": "831519"
  },
  {
    "text": "alternatively you can also simplify the deployment of this script by using an aws cloud 9 environment if",
    "start": "831519",
    "end": "838480"
  },
  {
    "text": "you want the first thing that we want to do is let's clone the github location",
    "start": "838480",
    "end": "843920"
  },
  {
    "text": "and download the python demo script first so this is the first thing that we need",
    "start": "843920",
    "end": "850240"
  },
  {
    "text": "to do cool um before running the python demo",
    "start": "850240",
    "end": "858399"
  },
  {
    "text": "script you have to run a few uh python commands to install the prerequisites",
    "start": "858399",
    "end": "864560"
  },
  {
    "text": "um let's first install um and upgrade pip for python3",
    "start": "864560",
    "end": "872480"
  },
  {
    "text": "now let's install another key python tool virtual environment this enables",
    "start": "878320",
    "end": "883600"
  },
  {
    "text": "you to create a series of controlled environments",
    "start": "883600",
    "end": "889040"
  },
  {
    "text": "or local environments where you can install and experiment um with python modules in",
    "start": "889040",
    "end": "896720"
  },
  {
    "text": "an isolated environment without upsetting any previously installed software",
    "start": "896720",
    "end": "903360"
  },
  {
    "text": "let's create and activate the virtual environment app",
    "start": "906000",
    "end": "913839"
  },
  {
    "text": "and let's activate it",
    "start": "921519",
    "end": "927839"
  },
  {
    "text": "cool um average solution uses aws sdk for python or boto3 to interact with",
    "start": "928560",
    "end": "935519"
  },
  {
    "text": "amazon kinesis and the solution also uses a numpy",
    "start": "935519",
    "end": "941519"
  },
  {
    "text": "uuid and arc parts to accept arguments and generate random sample game event data",
    "start": "941519",
    "end": "949600"
  },
  {
    "text": "so let's install those packages as well um for our solution",
    "start": "949600",
    "end": "969040"
  },
  {
    "text": "good",
    "start": "969040",
    "end": "971279"
  },
  {
    "text": "let's switch to source and demo and",
    "start": "979440",
    "end": "986959"
  },
  {
    "text": "now that they have navigated to this demo folder we can run this",
    "start": "986959",
    "end": "994320"
  },
  {
    "text": "python command we need to replace aws region with aws region code",
    "start": "994320",
    "end": "1002160"
  },
  {
    "text": "where the aws cloud formation stack is deployed in our case it would be",
    "start": "1002160",
    "end": "1009120"
  },
  {
    "text": "east one um a stream name um we need to replace that with",
    "start": "1009199",
    "end": "1016079"
  },
  {
    "text": "game events stream from the cloud formation um output tab so it would be this one",
    "start": "1016079",
    "end": "1023360"
  },
  {
    "text": "let's copy the whole thing and",
    "start": "1023360",
    "end": "1029120"
  },
  {
    "text": "paste it here and then the test application id the",
    "start": "1030160",
    "end": "1037038"
  },
  {
    "text": "same thing we have the value from the cloudformation output tab let's copy and",
    "start": "1037039",
    "end": "1043839"
  },
  {
    "text": "paste it here",
    "start": "1043839",
    "end": "1046798"
  },
  {
    "text": "good now we can take the whole command",
    "start": "1050840",
    "end": "1056559"
  },
  {
    "text": "and copy and paste it in the terminal",
    "start": "1056559",
    "end": "1062080"
  },
  {
    "text": "so these inputs configure this script to con to continuously generate batches of 100",
    "start": "1063360",
    "end": "1070559"
  },
  {
    "text": "random gave events for the provided application and and then um publishing the events to",
    "start": "1070559",
    "end": "1078240"
  },
  {
    "text": "amazon kinesis using the put records api um so as you can see we are generating",
    "start": "1078240",
    "end": "1086799"
  },
  {
    "text": "sample event data for every game analytics pipeline application now we can switch to aws management",
    "start": "1086799",
    "end": "1094160"
  },
  {
    "text": "console and test the sample queries in amazon athena",
    "start": "1094160",
    "end": "1100480"
  },
  {
    "start": "1101000",
    "end": "1315000"
  },
  {
    "text": "okay we can now switch to amazon athena service select the workgroup tab on top of the",
    "start": "1101919",
    "end": "1108240"
  },
  {
    "text": "page select the work group name game analytics work group and switch to that work group from your",
    "start": "1108240",
    "end": "1115360"
  },
  {
    "text": "primary work group with the help of work groups in athena you can separate workloads between users",
    "start": "1115360",
    "end": "1121360"
  },
  {
    "text": "or applications you can view query metrics and you can even enforce cost controls",
    "start": "1121360",
    "end": "1126720"
  },
  {
    "text": "if you want amazon athena has also recently enhanced general availability of a new query",
    "start": "1126720",
    "end": "1133520"
  },
  {
    "text": "engine version which is athena engine version 2 and this is the recommended engine version for your work groups",
    "start": "1133520",
    "end": "1140240"
  },
  {
    "text": "athena engine version 2 is based on presto version 0.217 and",
    "start": "1140240",
    "end": "1146480"
  },
  {
    "text": "it introduces a bunch of improvements and new features like support for federated queries",
    "start": "1146480",
    "end": "1152480"
  },
  {
    "text": "support for nested schemas and a lot of different performance improvements in terms of query execution",
    "start": "1152480",
    "end": "1159280"
  },
  {
    "text": "and query planning you can see that our work group is currently using athena engine version 1 to switch to athena",
    "start": "1159280",
    "end": "1166400"
  },
  {
    "text": "engine version 2. i can click on edit workgroup page come down here and manually choose",
    "start": "1166400",
    "end": "1174640"
  },
  {
    "text": "athena engine version 2 which is the recommended engine version and then save the changes",
    "start": "1174640",
    "end": "1182640"
  },
  {
    "text": "okay let's go back to athena let's click on saved queries tab and",
    "start": "1182640",
    "end": "1188960"
  },
  {
    "text": "then here we can see the list of our saved queries we can select one of these existing queries",
    "start": "1188960",
    "end": "1195600"
  },
  {
    "text": "to execute it and we can also customize the queries if we want so let's start with new users",
    "start": "1195600",
    "end": "1202960"
  },
  {
    "text": "last month query so if i run this query i can get the",
    "start": "1202960",
    "end": "1209200"
  },
  {
    "text": "number of user registrations for new weekends for last month for the month of november",
    "start": "1209200",
    "end": "1215840"
  },
  {
    "text": "and you can see that data here um let's go back to saved queries and",
    "start": "1215840",
    "end": "1222320"
  },
  {
    "text": "choose another query um let's look at the um",
    "start": "1222320",
    "end": "1227600"
  },
  {
    "text": "user reported reasons count and run this query and with the help of",
    "start": "1227600",
    "end": "1234480"
  },
  {
    "text": "this query we can get a list of report reasons and they can't have reports associated",
    "start": "1234480",
    "end": "1240400"
  },
  {
    "text": "with them let's look at another saved query for example",
    "start": "1240400",
    "end": "1245679"
  },
  {
    "text": "let's look at a level completion rate",
    "start": "1245679",
    "end": "1250158"
  },
  {
    "text": "here we can see the completion rate for each level and you can see that we got the response",
    "start": "1254000",
    "end": "1260559"
  },
  {
    "text": "in one 1.44 seconds and the amount of data is scanned by our query",
    "start": "1260559",
    "end": "1266080"
  },
  {
    "text": "uh is 3.18 megabyte of data um and you can see we we get the",
    "start": "1266080",
    "end": "1272960"
  },
  {
    "text": "response very fast that's pretty cool all right let's now test that in a",
    "start": "1272960",
    "end": "1278960"
  },
  {
    "text": "federated query with the with new athena engine version 2 you can now use federated query to run",
    "start": "1278960",
    "end": "1285360"
  },
  {
    "text": "sql queries across data stored in relational non-relational object and custom data",
    "start": "1285360",
    "end": "1291840"
  },
  {
    "text": "sources athena uses data source connectors that run on aws",
    "start": "1291840",
    "end": "1297039"
  },
  {
    "text": "lambda to run federated queries and a data source connector is just a piece of code",
    "start": "1297039",
    "end": "1302559"
  },
  {
    "text": "that can translate between your target data store and athena service so let me show you",
    "start": "1302559",
    "end": "1308960"
  },
  {
    "text": "how you can set up athena federated query connectors so to get us started i will first",
    "start": "1308960",
    "end": "1315520"
  },
  {
    "start": "1315000",
    "end": "1755000"
  },
  {
    "text": "navigate to serverless application repository which is our repository for serverless",
    "start": "1315520",
    "end": "1322240"
  },
  {
    "text": "applications i click on available applications i make sure that this box is ticked to",
    "start": "1322240",
    "end": "1328640"
  },
  {
    "text": "show apps that create custom im rules or resource policies then i search for athena federation",
    "start": "1328640",
    "end": "1337840"
  },
  {
    "text": "this is the name of the author that athena team uses when it publishes connectors to serverless application",
    "start": "1339840",
    "end": "1346480"
  },
  {
    "text": "repository and as you can see here it pulled up a list",
    "start": "1346480",
    "end": "1351760"
  },
  {
    "text": "of pre-built connectors here um we have a connector for documentdb for cloudwatch",
    "start": "1351760",
    "end": "1358480"
  },
  {
    "text": "metrics for dynamodb we have prebuilt connector for elasticsearch for elastic",
    "start": "1358480",
    "end": "1365200"
  },
  {
    "text": "readys for cloudwatch connector and if i go to the next page",
    "start": "1365200",
    "end": "1370400"
  },
  {
    "text": "you can see a bunch of other connectors like connector for athena jdbc connector",
    "start": "1370400",
    "end": "1376000"
  },
  {
    "text": "uh for uh for jdbc compliant data stores and the redshift um we have a connector",
    "start": "1376000",
    "end": "1383120"
  },
  {
    "text": "for at each base connector as well so um if you look at each of these",
    "start": "1383120",
    "end": "1389120"
  },
  {
    "text": "connectors you can see that each of these connectors has aws a verified other batch",
    "start": "1389120",
    "end": "1396240"
  },
  {
    "text": "when you see that badge you can be rest assured that the code that you're about to deploy is developed",
    "start": "1396240",
    "end": "1402000"
  },
  {
    "text": "and maintained by the affinity let's first set up a connector for our amazon",
    "start": "1402000",
    "end": "1407600"
  },
  {
    "text": "cloudwatch events which makes your cloudwatch metrics data to be accessible using sql",
    "start": "1407600",
    "end": "1414400"
  },
  {
    "text": "so i click on athena cloudwatch metrics connector when you connect to a connector you get",
    "start": "1414400",
    "end": "1421600"
  },
  {
    "text": "some information about it including details of what deploying this connector",
    "start": "1421600",
    "end": "1427440"
  },
  {
    "text": "will do in the form of a cloudformation template feta down you can see what permissions",
    "start": "1427440",
    "end": "1434400"
  },
  {
    "text": "this connector needs in the case of cloudwatch connector",
    "start": "1434400",
    "end": "1440400"
  },
  {
    "text": "it needs access to s3 for potentially spelling large responses",
    "start": "1440400",
    "end": "1446720"
  },
  {
    "text": "and then if you scroll down um you get a more detailed readme of what all the",
    "start": "1446720",
    "end": "1453200"
  },
  {
    "text": "configuration options are and how you can use this connector",
    "start": "1453200",
    "end": "1458559"
  },
  {
    "text": "on the right hand side we get some of the configurations that we can provide",
    "start": "1458559",
    "end": "1464080"
  },
  {
    "text": "for this connector we need a spill bucket so let's put an",
    "start": "1464080",
    "end": "1470240"
  },
  {
    "text": "um spill bucket that i've already created for this connector and this is my s3 spill location",
    "start": "1470240",
    "end": "1478400"
  },
  {
    "text": "um this s3 spill is useful where the response of your request exceeds the capacity of the lambda and",
    "start": "1478400",
    "end": "1486000"
  },
  {
    "text": "then you can easily spill this to fulfill your request because we tell athena the spill",
    "start": "1486000",
    "end": "1492080"
  },
  {
    "text": "location ahead of time at the time we want to set up these connectors the athena doesn't need to wait for",
    "start": "1492080",
    "end": "1498640"
  },
  {
    "text": "lambda function to complete before it can go and get that data athena can prefetch and watch that s3",
    "start": "1498640",
    "end": "1505600"
  },
  {
    "text": "location and as soon as data arrives it can process that",
    "start": "1505600",
    "end": "1510960"
  },
  {
    "text": "then we need a catalog name athena catalog name is in fact the function name or the name",
    "start": "1510960",
    "end": "1516640"
  },
  {
    "text": "you will give to this catalog um in athena let me put cloudwatch for my catalog",
    "start": "1516640",
    "end": "1524400"
  },
  {
    "text": "name speed location is uh is also encrypted by default and",
    "start": "1524400",
    "end": "1531200"
  },
  {
    "text": "you can disable that if you want and lambda memory and lambda",
    "start": "1531200",
    "end": "1538159"
  },
  {
    "text": "time ad values let's leave them as default values here as well you can also specify a prefix",
    "start": "1538159",
    "end": "1546400"
  },
  {
    "text": "within spill bucket for your lambda function let me put a cloud watch prefix for my",
    "start": "1546400",
    "end": "1553760"
  },
  {
    "text": "cloud which spill data and then um i take this box",
    "start": "1553760",
    "end": "1559279"
  },
  {
    "text": "i will check this box that gives serverless app repo permission to",
    "start": "1559279",
    "end": "1564400"
  },
  {
    "text": "create this scoped and iem roll um that connector needs and then i deploy",
    "start": "1564400",
    "end": "1570720"
  },
  {
    "text": "the connector and this process can take one to two minutes depending on the",
    "start": "1570720",
    "end": "1576320"
  },
  {
    "text": "complexity of the of the connector setup so let's wait for for a few seconds",
    "start": "1576320",
    "end": "1583679"
  },
  {
    "text": "hopefully the connector gets deployed very fast we can check the status of the",
    "start": "1583679",
    "end": "1590159"
  },
  {
    "text": "deployment here you can see that the deployment has already started the creation is in progress",
    "start": "1590159",
    "end": "1597360"
  },
  {
    "text": "you can also check the status of this deployment in cloud formation",
    "start": "1597360",
    "end": "1603840"
  },
  {
    "text": "we should have this lambda connector deployed very fast and then when this lambda",
    "start": "1605919",
    "end": "1612320"
  },
  {
    "text": "connector is deployed we can go back to athena and run our federated query for",
    "start": "1612320",
    "end": "1618720"
  },
  {
    "text": "cloudwatch metrics data",
    "start": "1618720",
    "end": "1622240"
  },
  {
    "text": "okay the connector is deployed uh very good let's go back to athena service",
    "start": "1624400",
    "end": "1631840"
  },
  {
    "text": "and uh ron ever federated korea for cloudwatch metrics data",
    "start": "1634320",
    "end": "1640880"
  },
  {
    "text": "this query lists cloudwatch metrics wherever namespace is pointing to amazon dynamodb",
    "start": "1640880",
    "end": "1649600"
  },
  {
    "text": "we should get the results back in a few",
    "start": "1653200",
    "end": "1657840"
  },
  {
    "text": "seconds cool very good",
    "start": "1666840",
    "end": "1672398"
  },
  {
    "text": "we can also set up another athena federated query for dynamodb if you want to extract our application",
    "start": "1674159",
    "end": "1680399"
  },
  {
    "text": "configuration data from applications table or authorization table let's do that",
    "start": "1680399",
    "end": "1685919"
  },
  {
    "text": "quickly as well we go back to serverless application repository again we search for athena",
    "start": "1685919",
    "end": "1694399"
  },
  {
    "text": "federation we look for athena dynamo db connector",
    "start": "1694840",
    "end": "1700960"
  },
  {
    "text": "and we fill in the parameters so again our spill bucket is the same spill",
    "start": "1701200",
    "end": "1706480"
  },
  {
    "text": "bucket that we use for our cloud watch metrics connector for catalog name we",
    "start": "1706480",
    "end": "1712080"
  },
  {
    "text": "can put dynamo here and leave the default values for a spill",
    "start": "1712080",
    "end": "1718559"
  },
  {
    "text": "encryption for lambda memory and for lambda timeout for spill prefix i can also set this prefix to to be",
    "start": "1718559",
    "end": "1726240"
  },
  {
    "text": "athena spelled dynamo and then i acknowledge",
    "start": "1726240",
    "end": "1731600"
  },
  {
    "text": "and i deploy the connector",
    "start": "1731840",
    "end": "1739840"
  },
  {
    "text": "let's wait until this connector gets deployed as well again we can check the status here and",
    "start": "1743840",
    "end": "1750880"
  },
  {
    "text": "creation is in progress you can see that if i go back to dynamodb",
    "start": "1750880",
    "end": "1757760"
  },
  {
    "start": "1755000",
    "end": "1767000"
  },
  {
    "text": "service you can see that in dynamodb as i as i explained before we have two",
    "start": "1757760",
    "end": "1763600"
  },
  {
    "text": "tables we have applications table and i have authorizations table so i can",
    "start": "1763600",
    "end": "1771200"
  },
  {
    "text": "run my federated query against each of these tables let's go back and check the status of",
    "start": "1771200",
    "end": "1777520"
  },
  {
    "text": "our connector the connector is already deployed very good we go back to athena now",
    "start": "1777520",
    "end": "1784559"
  },
  {
    "text": "and this time we run a federated query against a dynamodb data store so",
    "start": "1784559",
    "end": "1791840"
  },
  {
    "text": "i'm running this query against game analytics pipeline application stable",
    "start": "1791840",
    "end": "1809840"
  },
  {
    "text": "very good i can get the data from dynamodb as well okay now let's connect amazon athena to",
    "start": "1821120",
    "end": "1827200"
  },
  {
    "text": "amazon quickside so that we can access game data and create configure and customize",
    "start": "1827200",
    "end": "1832399"
  },
  {
    "text": "dashboards for deep data exploration",
    "start": "1832399",
    "end": "1837679"
  },
  {
    "text": "okay i navigate to amazon quick site i choose admin from the upper right corner i",
    "start": "1837679",
    "end": "1843039"
  },
  {
    "text": "select manage quick site i select security and permissions under",
    "start": "1843039",
    "end": "1848080"
  },
  {
    "text": "quick site access to aws services i click on add or remove",
    "start": "1848080",
    "end": "1854480"
  },
  {
    "text": "let's select amazon athena click next click finish we also need to select",
    "start": "1854799",
    "end": "1861919"
  },
  {
    "text": "amazon s3 select the game bucket resources that are created earlier by",
    "start": "1861919",
    "end": "1867120"
  },
  {
    "text": "aws cloud formation in the right permission column select the check box next to athena workgroup",
    "start": "1867120",
    "end": "1874320"
  },
  {
    "text": "and with that we are going to provide right permission for athena work group click finish and select",
    "start": "1874320",
    "end": "1881600"
  },
  {
    "text": "update now we select the quake site logo in the top left corner to navigate",
    "start": "1881600",
    "end": "1887519"
  },
  {
    "text": "to amazon quakesite console select data sets choose new data set",
    "start": "1887519",
    "end": "1894000"
  },
  {
    "text": "and then choose athena in the new athena data source dialog box",
    "start": "1894000",
    "end": "1900240"
  },
  {
    "text": "we need to enter a name let's put athena game analytics firefly in athena",
    "start": "1900240",
    "end": "1906080"
  },
  {
    "text": "work group field let's select the work group named the game analytics work group and",
    "start": "1906080",
    "end": "1913440"
  },
  {
    "text": "then validate the connection after the connection is validated choose create data source",
    "start": "1913440",
    "end": "1921840"
  },
  {
    "text": "in the choose your table dialog box for database field select the database that was deployed by",
    "start": "1923679",
    "end": "1930159"
  },
  {
    "text": "aws cloud formation and when you select that a list of available tables will populate",
    "start": "1930159",
    "end": "1936080"
  },
  {
    "text": "choose row events and then choose select on the finish data set creation dialog",
    "start": "1936080",
    "end": "1942559"
  },
  {
    "text": "box select directly query your data and then choose edit preview data",
    "start": "1942559",
    "end": "1949840"
  },
  {
    "text": "good we can now see the preview data let's create a calculated field",
    "start": "1957760",
    "end": "1964159"
  },
  {
    "text": "we select add calculated field we create a name for example we put",
    "start": "1964159",
    "end": "1972000"
  },
  {
    "text": "level id and in the formula field we enter the formula the part json",
    "start": "1972000",
    "end": "1979200"
  },
  {
    "text": "formula for level id and we choose save you can also repeat",
    "start": "1979200",
    "end": "1984880"
  },
  {
    "text": "these steps to create calculated fields for each data type that you want to extract",
    "start": "1984880",
    "end": "1990080"
  },
  {
    "text": "from event data now to build the amazon quick site dashboard we again navigate to amazon quick site console",
    "start": "1990080",
    "end": "1998799"
  },
  {
    "start": "1991000",
    "end": "2135000"
  },
  {
    "text": "this time we click on analysis new analysis and we choose our data set which is row",
    "start": "1998799",
    "end": "2005039"
  },
  {
    "text": "events and then we create analysis a new sheet with a blank visual will",
    "start": "2005039",
    "end": "2010880"
  },
  {
    "text": "display in the visual types pane let's select for example",
    "start": "2010880",
    "end": "2016159"
  },
  {
    "text": "line chart and amazon quick side will create the visualization for us",
    "start": "2016159",
    "end": "2022480"
  },
  {
    "text": "from the fields list let's select event timestamp time format",
    "start": "2022480",
    "end": "2033840"
  },
  {
    "text": "and let's drag event id",
    "start": "2036960",
    "end": "2041919"
  },
  {
    "text": "as well as event type",
    "start": "2043840",
    "end": "2047840"
  },
  {
    "text": "now for our even timestamp time format let's select the drop down arrow next to",
    "start": "2050560",
    "end": "2056398"
  },
  {
    "text": "that and change the aggregate from day to same minute",
    "start": "2056399",
    "end": "2063280"
  },
  {
    "text": "and we can also change the name of our sheet to cant of events",
    "start": "2065839",
    "end": "2075839"
  },
  {
    "text": "very good we can also add another visualization here if we want and say",
    "start": "2076159",
    "end": "2081919"
  },
  {
    "text": "for example drag and drop event type",
    "start": "2081919",
    "end": "2088800"
  },
  {
    "text": "or change visualization um as as we need um so as you can see",
    "start": "2088800",
    "end": "2095760"
  },
  {
    "text": "quakesite can help us create meaningful dashboards and",
    "start": "2095760",
    "end": "2100839"
  },
  {
    "text": "um a very you very powerful tool for deep data exploration um i've also",
    "start": "2100839",
    "end": "2107200"
  },
  {
    "text": "created a number of other dashboards for every game analytics pipeline application and that you can see here",
    "start": "2107200",
    "end": "2115520"
  },
  {
    "text": "and as you can see you can utilize quakesite to create a very powerful um",
    "start": "2115520",
    "end": "2123280"
  },
  {
    "text": "dashboard and visual visualization for your data exploration purposes",
    "start": "2123280",
    "end": "2131838"
  },
  {
    "text": "fantastic okay now that we have seen the demo let's",
    "start": "2133040",
    "end": "2138320"
  },
  {
    "start": "2135000",
    "end": "2185000"
  },
  {
    "text": "quickly discuss the features of average game analytics pipeline solution game developers",
    "start": "2138320",
    "end": "2144000"
  },
  {
    "text": "can now create a scalable serverless data pipeline in aws to ingest",
    "start": "2144000",
    "end": "2149440"
  },
  {
    "text": "store and analyze them game data generated from different services",
    "start": "2149440",
    "end": "2154640"
  },
  {
    "text": "you can organize and structure data in amazon s3 to provide data lake integration and configure aws glue to",
    "start": "2154640",
    "end": "2162320"
  },
  {
    "text": "catalog metadata for your data sets you can gain insights from games and",
    "start": "2162320",
    "end": "2167440"
  },
  {
    "text": "other applications within minutes from the streaming ingestion of data and you can also customize the solution to fit",
    "start": "2167440",
    "end": "2174400"
  },
  {
    "text": "your particular needs for example by editing the solution api and adapting",
    "start": "2174400",
    "end": "2179839"
  },
  {
    "text": "the processing workflows and real-time streaming analytics application if needed um",
    "start": "2179839",
    "end": "2186079"
  },
  {
    "start": "2185000",
    "end": "2224000"
  },
  {
    "text": "i hope this quick demo was useful for you to gain a better understanding of how you can utilize various aws services",
    "start": "2186079",
    "end": "2193599"
  },
  {
    "text": "to provide a framework for ingesting game events into your data lake for analytics and",
    "start": "2193599",
    "end": "2199520"
  },
  {
    "text": "storage you can find more information about average game analytics pipeline solution by checking",
    "start": "2199520",
    "end": "2205440"
  },
  {
    "text": "our aws solutions implementation page and as i explained before you can also",
    "start": "2205440",
    "end": "2210480"
  },
  {
    "text": "find a cloud formation template to build this solution along with detailed implementation and",
    "start": "2210480",
    "end": "2216560"
  },
  {
    "text": "developer guides thank you very much for your time and stay safe",
    "start": "2216560",
    "end": "2226480"
  }
]
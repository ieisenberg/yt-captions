[
  {
    "text": "hey first of all thank you so much to Amazon AWS for having me it's great to be here let's do a quick from the",
    "start": "170",
    "end": "7410"
  },
  {
    "text": "audience quick poll who's a data professional data analyst data scientist data engineer like half baby cool",
    "start": "7410",
    "end": "14269"
  },
  {
    "text": "software engineer yep yep IT",
    "start": "14269",
    "end": "19560"
  },
  {
    "text": "professional nobody ok well a couple people cool twenty haired boss middle",
    "start": "19560",
    "end": "25289"
  },
  {
    "text": "manager oh that's nice not that many it's cool I'm in this group I feel you you can see the people dressed like me",
    "start": "25289",
    "end": "31410"
  },
  {
    "text": "not in the t-shirts those are the middle managers yeah cool I want to open with a question really quick first of all can",
    "start": "31410",
    "end": "37680"
  },
  {
    "text": "everybody hear me in the back blue shirt you can hear me yep cool I'm very loud",
    "start": "37680",
    "end": "43309"
  },
  {
    "text": "so as a data professional roughly half the audience what's the value that you",
    "start": "43610",
    "end": "48660"
  },
  {
    "text": "bring to your organization why do your company why do your employer why hire you",
    "start": "48660",
    "end": "54090"
  },
  {
    "text": "why pay what I'm sure is a ton of money to hire you and employ you at this company what's the point give it a",
    "start": "54090",
    "end": "60090"
  },
  {
    "text": "second and think about it I want to know who's got an answer that's around",
    "start": "60090",
    "end": "65158"
  },
  {
    "text": "technical capabilities right I've got skills I can bring capabilities to a",
    "start": "65159",
    "end": "71220"
  },
  {
    "text": "company that the company didn't have before we're gonna do prediction modeling we're gonna do machine learning",
    "start": "71220",
    "end": "76340"
  },
  {
    "text": "we're gonna do all this analysis and teach the company things that the company didn't know before technical",
    "start": "76340",
    "end": "82320"
  },
  {
    "text": "capabilities who's that answer alright either nobody's paying attention or nobody thinks that's the value to the",
    "start": "82320",
    "end": "88080"
  },
  {
    "text": "company come on zero people all right one two a couple people out of guilt that's good who's got an answer out of",
    "start": "88080",
    "end": "94710"
  },
  {
    "text": "business outcomes right yeah here we go audiences are getting smarter I've found",
    "start": "94710",
    "end": "100549"
  },
  {
    "text": "we're gonna get more revenue we're gonna get more efficiency we're gonna get more profits because of the work that I do",
    "start": "100549",
    "end": "106500"
  },
  {
    "text": "this prediction modeling this artificial intelligence this machine learning it's gonna drive business outcomes that the",
    "start": "106500",
    "end": "113280"
  },
  {
    "text": "company wouldn't be able to get before and I'll pay for myself tenfold with these kinds of analyses hands back up",
    "start": "113280",
    "end": "118920"
  },
  {
    "text": "who thinks that's the answer all right mostly everyone and let me tell you I'm a CEO I love revenue I love profit it's",
    "start": "118920",
    "end": "126299"
  },
  {
    "text": "great what a great answer but I want to talk up for a second about possibly the most successful most advanced",
    "start": "126299",
    "end": "133980"
  },
  {
    "text": "Datta team full of data professionals in the world right this is a billion or",
    "start": "133980",
    "end": "139440"
  },
  {
    "text": "trillion dollar company and it's built primarily off the back of off the work of the data team they built a rancor and",
    "start": "139440",
    "end": "146519"
  },
  {
    "text": "this rancor shows you you know what your friends are doing what your family's",
    "start": "146519",
    "end": "151709"
  },
  {
    "text": "doing new photos from those groups of people and they do it so well and so effectively that they've driven this",
    "start": "151709",
    "end": "158160"
  },
  {
    "text": "business outcome that built a billion or trillion dollar company you'd have to say that this is probably the most",
    "start": "158160",
    "end": "164489"
  },
  {
    "text": "successful most advanced data team in the world fun fact I actually grew up at Google I worked at Google before",
    "start": "164489",
    "end": "169920"
  },
  {
    "text": "starting periscope data so maybe I'll say that this is the second most advanced data team in the world because they have to represent my friends from",
    "start": "169920",
    "end": "176010"
  },
  {
    "text": "Google but anyway what's really crazy about this is despite all of the amazing",
    "start": "176010",
    "end": "182280"
  },
  {
    "text": "business outcomes that they drove in the final analysis and the fullness of time we might remember this team for the",
    "start": "182280",
    "end": "189060"
  },
  {
    "text": "negative social outcomes that they drove and the negative societal outcomes that they drove because while they were doing",
    "start": "189060",
    "end": "195090"
  },
  {
    "text": "all of this advanced data work nobody knew certainly nobody on the team knew that what would happen is you would",
    "start": "195090",
    "end": "201150"
  },
  {
    "text": "filter the country into multiple groups of people show them only content from those particular groups and maybe even",
    "start": "201150",
    "end": "208440"
  },
  {
    "text": "rank content that was not true and full of falsehoods and drive a societal outcome in this country that whatever",
    "start": "208440",
    "end": "214799"
  },
  {
    "text": "your politics are you would have to agree is not a positive outcome right the increased polarization of the",
    "start": "214799",
    "end": "220769"
  },
  {
    "text": "country the spread of news and information that's actually not accurate and not true and this negative societal",
    "start": "220769",
    "end": "227430"
  },
  {
    "text": "outcome may actually come to dwarf the very positive business outcomes that",
    "start": "227430",
    "end": "232739"
  },
  {
    "text": "these teams Rove at so in light of that in light of the most successful most advanced data team in the world driving",
    "start": "232739",
    "end": "240780"
  },
  {
    "text": "these unexpected negative societal outcomes I want to ask again what's the",
    "start": "240780",
    "end": "246690"
  },
  {
    "text": "value that you bring to your company as a data professional if you were at Facebook when these algorithms were",
    "start": "246690",
    "end": "252870"
  },
  {
    "text": "being built what should you have done differently or what you would you have done differently and how would you have",
    "start": "252870",
    "end": "258510"
  },
  {
    "text": "turned this into a positive outcome and not a negative outcome because now we're in a place now we're in a place where",
    "start": "258510",
    "end": "265140"
  },
  {
    "text": "all of us at many companies are starting to do the work that was done at Facebook five or ten",
    "start": "265140",
    "end": "271020"
  },
  {
    "text": "years ago and are starting to build the kinds of prediction modeling and machine learning classifiers and rancors that",
    "start": "271020",
    "end": "277860"
  },
  {
    "text": "were built at Facebook five or ten years ago and if we're all doing it are we all headed for a societal outcome the way",
    "start": "277860",
    "end": "284340"
  },
  {
    "text": "that Facebook did or can we learn from this and can we do better and whose responsibility is that so before I get",
    "start": "284340",
    "end": "291479"
  },
  {
    "text": "into the answer and solve all the problems for you I want to talk about a few more contemporary examples this is",
    "start": "291479",
    "end": "298469"
  },
  {
    "text": "an AI system that is a it's a judge and it was developed in academia and the",
    "start": "298469",
    "end": "303990"
  },
  {
    "text": "idea is to bring an algorithmic approach to sentencing right and so we can look",
    "start": "303990",
    "end": "310349"
  },
  {
    "text": "at the last couple hundred years of jurisprudence in the United States and we can say based on what happened in the",
    "start": "310349",
    "end": "316889"
  },
  {
    "text": "last couple hundred years in courtrooms we can actually recommend this sentence without going through the whole human",
    "start": "316889",
    "end": "322020"
  },
  {
    "text": "process so based on you know the particular factors in the case and what we're charged with and the verdicts we",
    "start": "322020",
    "end": "327569"
  },
  {
    "text": "can say okay here's what the sentence we should be and we can do that totally automatically so we had half the",
    "start": "327569",
    "end": "333960"
  },
  {
    "text": "audience this day two professionals who knows what goes wrong yeah shout",
    "start": "333960",
    "end": "341870"
  },
  {
    "text": "biases exactly right the last 200 years of jurisprudence in the United States is",
    "start": "342639",
    "end": "348129"
  },
  {
    "text": "filled with tons of bad right we've got you know racism and sexism by",
    "start": "348129",
    "end": "354069"
  },
  {
    "text": "accident we've got racism and sexism on purpose we've got all kinds of individual human",
    "start": "354069",
    "end": "359439"
  },
  {
    "text": "biases on the part of judges a machine learning system will do a really really good job of replicating what happened in",
    "start": "359439",
    "end": "365650"
  },
  {
    "text": "the past but as a human building the system you have to be sure that replicating what happened in the past is",
    "start": "365650",
    "end": "370810"
  },
  {
    "text": "something that you want in this particular case we want to improve over time we want to say that every year",
    "start": "370810",
    "end": "377830"
  },
  {
    "text": "every decade as judges and juries we're going to get better and the system is trained on historical data is not going",
    "start": "377830",
    "end": "384340"
  },
  {
    "text": "to be able to do that in a room full of beta professionals that answer was arrived at like instantly right we all",
    "start": "384340",
    "end": "390310"
  },
  {
    "text": "work with data all day raw all day long we all know what's going to go wrong but the judges don't know that the judges",
    "start": "390310",
    "end": "395860"
  },
  {
    "text": "aren't machine learning or artificial intelligence engineers and so they just went hey I think we can make this more",
    "start": "395860",
    "end": "400990"
  },
  {
    "text": "efficient let's try it and so it's up to the data professional that works on this stuff to actually understand what are",
    "start": "400990",
    "end": "406900"
  },
  {
    "text": "the dynamics underlying this what are the bias T is going to be and then correct as necessary this is another",
    "start": "406900",
    "end": "414370"
  },
  {
    "text": "good one this is a system that can determine whether a crime is",
    "start": "414370",
    "end": "419650"
  },
  {
    "text": "gang-related and this was developed actually on contract for a police department to determine whether a crime",
    "start": "419650",
    "end": "425259"
  },
  {
    "text": "is gang-related simply by looking at some factors in the crime so it's a simple classifier and in fact the",
    "start": "425259",
    "end": "430330"
  },
  {
    "text": "features that ended up dominating the model are just you know where was the crime committed what geography and what",
    "start": "430330",
    "end": "436240"
  },
  {
    "text": "are some physical characteristics of that crime of that geography for example was it in an alleyway was it on a street corner and based on that we can get",
    "start": "436240",
    "end": "442930"
  },
  {
    "text": "really good precision on was this crime gang-related and then that effect sentencing outcomes down the line who",
    "start": "442930",
    "end": "449439"
  },
  {
    "text": "knows what went wrong here come on nobody what is a false positive look",
    "start": "449439",
    "end": "456159"
  },
  {
    "text": "like in this scenario no machine learning model has zero false positives right no human model has zero false",
    "start": "456159",
    "end": "461770"
  },
  {
    "text": "positives either but we are talking about baking in a system where a false positive that's arrived at automatically",
    "start": "461770",
    "end": "467469"
  },
  {
    "text": "classify someone's crime as gang-related when it wasn't gang-related that person now goes into the system they get a",
    "start": "467469",
    "end": "473740"
  },
  {
    "text": "really harsh sentence and we perpetuate the bed  that goes on rather than correcting the bad that goes on and so you",
    "start": "473740",
    "end": "479900"
  },
  {
    "text": "need a human approach to are we happy about false positives in this scenario do we want no false positives which",
    "start": "479900",
    "end": "485990"
  },
  {
    "text": "means we need human review this person by the way the engineer who built this said by very favourite thing that",
    "start": "485990",
    "end": "491509"
  },
  {
    "text": "engineer say I'm just an engineer when he was asked about this I mean come on if the engineer doesn't take",
    "start": "491509",
    "end": "498830"
  },
  {
    "text": "responsibility for this system who will the police department that contracted him does not have an understanding of",
    "start": "498830",
    "end": "503870"
  },
  {
    "text": "what are false positives and what are false negatives and what do we need to do about that it's the data professional",
    "start": "503870",
    "end": "509330"
  },
  {
    "text": "in this case the data engineer who understands those dynamics and needs to take responsibility for what's happening",
    "start": "509330",
    "end": "515768"
  },
  {
    "text": "this is a good one this is another academic model and it's developed it's a facial recognition system and the",
    "start": "515769",
    "end": "522349"
  },
  {
    "text": "proposal is to do away with the ID checks that you get in airports I flew here yesterday from SFO you stand in",
    "start": "522349",
    "end": "529160"
  },
  {
    "text": "this line you get to the front a TSA agent kind of squints at my you know passport and then kind of squints at me",
    "start": "529160",
    "end": "535310"
  },
  {
    "text": "and goes you know is this the same person do you look the same as you were when you were 18 come on guys who here",
    "start": "535310",
    "end": "541220"
  },
  {
    "text": "looks the same as they did when they were 18 I totally do absolutely it's easy and so we can replace this with a",
    "start": "541220",
    "end": "547520"
  },
  {
    "text": "facial recognition system right and this is you know low stakes maybe this is a good candidate for AI no one's going to",
    "start": "547520",
    "end": "553130"
  },
  {
    "text": "jail no one's getting a harsher sentence we can just walk you through the system faster by doing an all algorithmic",
    "start": "553130",
    "end": "558320"
  },
  {
    "text": "system this team that built this was composed of all white men all too common",
    "start": "558320",
    "end": "564980"
  },
  {
    "text": "in our industry and something that needs to change the system was really really good at differentiating Caucasian faces",
    "start": "564980",
    "end": "571570"
  },
  {
    "text": "but it thought that every East Asian face was the same face this is like",
    "start": "571570",
    "end": "577430"
  },
  {
    "text": "really solvable this is a very solvable problem but it's a human problem and it falls on the people who constructed the",
    "start": "577430",
    "end": "583579"
  },
  {
    "text": "team because I know how this happened right we're up late at night we have some new features we want to test we have an update to the model we want to",
    "start": "583579",
    "end": "589550"
  },
  {
    "text": "test yeah sure we'll run it through the whole you know we'll run it through the whole you know training set but first let's just try it on Jimmy's face real",
    "start": "589550",
    "end": "595970"
  },
  {
    "text": "quick and see if it's even an improvement those kinds of quick tests those kinds of quick improvements they",
    "start": "595970",
    "end": "601519"
  },
  {
    "text": "happen all the time and they're good things but if you don't have a diverse team that's thinking hard about this stuff you are going to run into these",
    "start": "601519",
    "end": "607640"
  },
  {
    "text": "very avoidable issues and so it falls on the person the manager or the leader who's constructing the data team to understand",
    "start": "607640",
    "end": "614120"
  },
  {
    "text": "how is this going to be used who is this going to be trained on and who is this going to run on in the final",
    "start": "614120",
    "end": "620149"
  },
  {
    "text": "analysis and therefore what do we want the team to look like and the team needs to be representative of the people who",
    "start": "620149",
    "end": "627170"
  },
  {
    "text": "are going to use this software at the end of the day and if the system is not representative if the team is just all",
    "start": "627170",
    "end": "632300"
  },
  {
    "text": "for example white guys you are going to have a problem like this and it's going to be really embarrassing and it's going",
    "start": "632300",
    "end": "637759"
  },
  {
    "text": "to lead to the failure of the system and also bad societal outcomes all right who knows this example from Target anybody",
    "start": "637759",
    "end": "644180"
  },
  {
    "text": "seen this already yeah exactly so this is tricky to fix but it's interesting what happened here is target has two",
    "start": "644180",
    "end": "651649"
  },
  {
    "text": "really great high-performing systems one of them recommends products that you should buy based on products that you've",
    "start": "651649",
    "end": "658040"
  },
  {
    "text": "already built really really simple a little bit of collaborative filtering and it happens to be really good at",
    "start": "658040",
    "end": "663889"
  },
  {
    "text": "recommending products for pregnant women right they get pregnant women buy a series of products on a pretty",
    "start": "663889",
    "end": "669860"
  },
  {
    "text": "predictable calendar and if you bought the first couple Target knows that you're going to want the next few and that's good news right that's improved",
    "start": "669860",
    "end": "676490"
  },
  {
    "text": "health for all of us target also has a second system and based on what it thinks you're going to buy it sends you",
    "start": "676490",
    "end": "682730"
  },
  {
    "text": "mailers to your home suggesting that you buy them this is also potentially good maybe you won't forget also it's good",
    "start": "682730",
    "end": "688220"
  },
  {
    "text": "for target right increased revenue but these teams are in totally different systems one is it a product team and one",
    "start": "688220",
    "end": "693589"
  },
  {
    "text": "is it a marketing team and they talk with this really narrowly defined construct and so nobody takes",
    "start": "693589",
    "end": "698750"
  },
  {
    "text": "responsibility for the overall system as a result some poor teenage girl who was",
    "start": "698750",
    "end": "704569"
  },
  {
    "text": "pregnant her dad found out that she was pregnant from a target mailer this is like really avoidable but target needs",
    "start": "704569",
    "end": "711800"
  },
  {
    "text": "to think holistically about how we organize our data teams somebody at target needs to take responsibility for",
    "start": "711800",
    "end": "717259"
  },
  {
    "text": "the use of data and the use of prediction and modeling systems overall this is a problem that gets solved when",
    "start": "717259",
    "end": "722899"
  },
  {
    "text": "you organize your teams in the right way and a problem that you fall into in a trap that you fall into when your teams",
    "start": "722899",
    "end": "728420"
  },
  {
    "text": "are organized in silos and nobody is charged with thinking holistically about the responsible use of data at our",
    "start": "728420",
    "end": "734420"
  },
  {
    "text": "company so I want to talk again about my original question right what is the",
    "start": "734420",
    "end": "741800"
  },
  {
    "text": "responsibility of the data team how should the data team approach their work and what's the value that you add",
    "start": "741800",
    "end": "746840"
  },
  {
    "text": "to your company really at the end of the day the use of data has a unique",
    "start": "746840",
    "end": "752440"
  },
  {
    "text": "scalable property this unique ability to drive us off in really bad directions if we're not careful and as we saw from",
    "start": "752440",
    "end": "760010"
  },
  {
    "text": "these previous examples it's the data professionals and the data teams who bear the ultimate responsibility because",
    "start": "760010",
    "end": "765650"
  },
  {
    "text": "you're the only ones who have this understanding you're the only ones who know what is the what is the ways that",
    "start": "765650",
    "end": "772760"
  },
  {
    "text": "this can go well and what are the ways that this can go poorly and how should we be thinking about this so at the end",
    "start": "772760",
    "end": "778100"
  },
  {
    "text": "of the day it's on you to take responsibility for this work alright so",
    "start": "778100",
    "end": "783320"
  },
  {
    "text": "who's this lecturing me at 11:00 a.m. about what I should do in my job so my name is Harry I'm the co-founder and",
    "start": "783320",
    "end": "789410"
  },
  {
    "text": "CEO of periscope data we're a tech startup in San Francisco and we make a platform for data teams I I cut my chops",
    "start": "789410",
    "end": "796580"
  },
  {
    "text": "to kugel I worked there for three or four years on the ads team we re ranked and RIA represented the ads on the",
    "start": "796580",
    "end": "802820"
  },
  {
    "text": "search results I made a couple billion dollars and it was the most data-driven organization I've ever been a part of",
    "start": "802820",
    "end": "808160"
  },
  {
    "text": "and it was also a team that thought very holistically about how should we work with this data to drive positive",
    "start": "808160",
    "end": "814190"
  },
  {
    "text": "outcomes you could imagine Google simply saying well we should make the ads really huge we'll make a bunch of money everybody",
    "start": "814190",
    "end": "819950"
  },
  {
    "text": "you'll click but we didn't do that we thought very hard about what's the right way to do this what do users really want",
    "start": "819950",
    "end": "825260"
  },
  {
    "text": "what will really benefit users and then I went out into the world and I found it a data company and we started to work",
    "start": "825260",
    "end": "831290"
  },
  {
    "text": "with data teams at many other companies uber is a customer of ours tinder is a customer of ours HBO and what we learned",
    "start": "831290",
    "end": "838190"
  },
  {
    "text": "was these teams need to maybe think more holistically about the work that they're doing then they are thinking and maybe",
    "start": "838190",
    "end": "844130"
  },
  {
    "text": "we can help them understand what's the right way I was down at the tinder headquarters recently and they're",
    "start": "844130",
    "end": "849290"
  },
  {
    "text": "talking about using a new kind of machine learning to optimize the matching of the tinder algorithm and I",
    "start": "849290",
    "end": "855110"
  },
  {
    "text": "go is this a good idea do we want that in tinder what are the what like what",
    "start": "855110",
    "end": "860810"
  },
  {
    "text": "are the long-term effects here for society if we match people you know using a machine learning algorithm",
    "start": "860810",
    "end": "865850"
  },
  {
    "text": "instead of using a more simple and more understandable algorithm nobody at tinder was thinking about that but props",
    "start": "865850",
    "end": "871250"
  },
  {
    "text": "to my guys at cinder they've come a long way and they're doing great but it's something that I think the industry",
    "start": "871250",
    "end": "876470"
  },
  {
    "text": "we've observed everybody really wants to get into AI everybody really wants to get into machine learning but that comes with a",
    "start": "876470",
    "end": "882259"
  },
  {
    "text": "responsibility to think holistically about how we should be doing that and what are the long-term outcomes and what",
    "start": "882259",
    "end": "887959"
  },
  {
    "text": "are the societal outcomes and that's something that the data team is uniquely positioned and frankly only the only",
    "start": "887959",
    "end": "893360"
  },
  {
    "text": "ones positions to make that change and think about that you know responsibly so",
    "start": "893360",
    "end": "901370"
  },
  {
    "text": "our mission at periscope data is to turn data teams into superheroes and I want to talk now about some positive examples",
    "start": "901370",
    "end": "906980"
  },
  {
    "text": "who are the superheroes who are doing this right how can we do this the right way how can we what can we take away",
    "start": "906980",
    "end": "912259"
  },
  {
    "text": "from this and who are some positive examples out there so this is one of my favorites this is also a periscope",
    "start": "912259",
    "end": "918230"
  },
  {
    "text": "customer their crisis text line and crisis text line is literally an app or",
    "start": "918230",
    "end": "923600"
  },
  {
    "text": "a number that you can text if you are in personal crisis so I'm from San Francisco and the crisis text line",
    "start": "923600",
    "end": "929029"
  },
  {
    "text": "number is actually stamped on the Golden Gate Bridge so if you're there and you're thinking of jumping you can text",
    "start": "929029",
    "end": "934430"
  },
  {
    "text": "crisis text line and a trained operator will text you back and try to talk you off the ledge it's a wonderful service",
    "start": "934430",
    "end": "940779"
  },
  {
    "text": "they have a model for the trained operators when they are responding to a text we'll have some suggestions about",
    "start": "940779",
    "end": "946850"
  },
  {
    "text": "what to text back based on what has worked historically in the past so we can make sure that we're doing a really good job in these text message",
    "start": "946850",
    "end": "953959"
  },
  {
    "text": "situations in these crisis situations I'm proud to say that model is trained and evaluated in periscope we're really",
    "start": "953959",
    "end": "959149"
  },
  {
    "text": "proud of that but more importantly I'm really proud of the team that that trains this model and how they think",
    "start": "959149",
    "end": "965089"
  },
  {
    "text": "about this holistically you know sometimes they think you know based on the semantic analysis we've done we can",
    "start": "965089",
    "end": "970250"
  },
  {
    "text": "push an improvement to the model and that'll give us an extra point of precision but it trades half a point of recall if you're working on something",
    "start": "970250",
    "end": "976819"
  },
  {
    "text": "really simple something really pure software a search results algorithm point a precision for",
    "start": "976819",
    "end": "982399"
  },
  {
    "text": "half a point a recall that sounds great let's do that but in this situation the loss of half a point of recall what is",
    "start": "982399",
    "end": "988129"
  },
  {
    "text": "that what does that mean out in the world well it means that for half a percent of the time somebody who would",
    "start": "988129",
    "end": "994249"
  },
  {
    "text": "have gotten the good response from the model is now going to get no response and what happened to that person when they Tex crisis text line and there's",
    "start": "994249",
    "end": "1000519"
  },
  {
    "text": "good there's a good response that doesn't they could have come back but didn't this is not a simple question a",
    "start": "1000519",
    "end": "1005529"
  },
  {
    "text": "point of precision is worth real human outcomes - but what I'm proud of about the team is that they they don't just",
    "start": "1005529",
    "end": "1010750"
  },
  {
    "text": "treat this a math problem this is a human problem right when I sit down and I say I'm",
    "start": "1010750",
    "end": "1016089"
  },
  {
    "text": "gonna make this change to the model what are the human factors and what are the human outcomes that happen here and are",
    "start": "1016089",
    "end": "1021369"
  },
  {
    "text": "we happy about that are we proud of the work that we're doing I don't think they have this down to a science yet I don't",
    "start": "1021369",
    "end": "1026620"
  },
  {
    "text": "know that they'll ever have it down to a science but what really works here is the team thinking hard about the human outcomes",
    "start": "1026620",
    "end": "1031928"
  },
  {
    "text": "and not just the mathematical or scientific outcomes the New York civic engagement table is another data team",
    "start": "1031929",
    "end": "1038110"
  },
  {
    "text": "I'm really proud of they use data to get more people civically engaged in the state of New York",
    "start": "1038110",
    "end": "1043750"
  },
  {
    "text": "be it voting be it volunteering be it running for office and they started as a lot of data team started simply saying",
    "start": "1043750",
    "end": "1050169"
  },
  {
    "text": "what are the best models that we can train do I want a neural net do I want a regression you know what's the best",
    "start": "1050169",
    "end": "1056139"
  },
  {
    "text": "technology here and what they learned was actually integrating more data sources is the most powerful thing that",
    "start": "1056139",
    "end": "1062830"
  },
  {
    "text": "we can do what's the algorithm matters a little bit but it doesn't matter a ton how much data can we get and can we get",
    "start": "1062830",
    "end": "1069279"
  },
  {
    "text": "data from really diverse and different data sources that's what matters a lot if they can get a data set of voters or",
    "start": "1069279",
    "end": "1074649"
  },
  {
    "text": "people who should be voters into the system that was never in the system before people who have never been",
    "start": "1074649",
    "end": "1079659"
  },
  {
    "text": "touched by this outreach before that turns out to be the most powerful thing that we can do not tuning our model or",
    "start": "1079659",
    "end": "1085779"
  },
  {
    "text": "doing a little more fun computer science as fun as that may be and so this goes to something I think we don't think enough about which are what are the",
    "start": "1085779",
    "end": "1091840"
  },
  {
    "text": "inputs what are the data sets how diverse candidate a set be and what outcomes will that drive for us more",
    "start": "1091840",
    "end": "1097240"
  },
  {
    "text": "than just sitting in front of our computers and tuning our models this team does a really good job of that one",
    "start": "1097240",
    "end": "1104409"
  },
  {
    "text": "quick shout out to my alma mater at Google this was in the news recently Google has a facial recognition system",
    "start": "1104409",
    "end": "1110590"
  },
  {
    "text": "that they use for ad targeting and they use for image search and it's really good it's been trained over a long period of time works really well for",
    "start": "1110590",
    "end": "1116320"
  },
  {
    "text": "image search and then some business teams at Google who are selling more and more enterprise software they went you",
    "start": "1116320",
    "end": "1122350"
  },
  {
    "text": "know I have another buyer for an image recognition system it's the United States Department of Defense and they'll",
    "start": "1122350",
    "end": "1127809"
  },
  {
    "text": "pay us a ton of money and and they will get the ability to automatically target",
    "start": "1127809",
    "end": "1133330"
  },
  {
    "text": "drones and use these drones to automatically target terrorists and this is really good because we'll get a lot",
    "start": "1133330",
    "end": "1139539"
  },
  {
    "text": "of money from the US Department of Defense and what really made me proud here is the engineers who worked on this system",
    "start": "1139539",
    "end": "1145590"
  },
  {
    "text": "and then many other engineers around the company raised their hands and the first debate was high-level and it was",
    "start": "1145590",
    "end": "1150990"
  },
  {
    "text": "political and some people said I don't want my work used for the killing of other human beings I'm not comfortable with that and on the other hand some",
    "start": "1150990",
    "end": "1158040"
  },
  {
    "text": "people said hang on in the world there are good guys and bad guys and the terrorists are bad guys and the United",
    "start": "1158040",
    "end": "1164550"
  },
  {
    "text": "States Department of Defense are the good guys and I'm happy to help the good guys personally I don't know what the",
    "start": "1164550",
    "end": "1169620"
  },
  {
    "text": "answer is here but what I'm really proud of is the team the engineering team built this thought hard about the",
    "start": "1169620",
    "end": "1176010"
  },
  {
    "text": "political outcomes of the social outcomes they didn't just think about making their facial recognition system work better and at the end of the day",
    "start": "1176010",
    "end": "1181830"
  },
  {
    "text": "some of the engineers raised their hands and said you know the precision recall trade-off the false positives and false",
    "start": "1181830",
    "end": "1187170"
  },
  {
    "text": "negatives that we were happy with an image search do not apply to the killing of other human beings we were happy with",
    "start": "1187170",
    "end": "1192270"
  },
  {
    "text": "false positives on image search because it's image search we're not happy with it when it's used for drone software and",
    "start": "1192270",
    "end": "1197640"
  },
  {
    "text": "we're not comfortable with this deal that we're doing and I believe that Google actually pulled this deal on the advice of the engineers that worked on",
    "start": "1197640",
    "end": "1204150"
  },
  {
    "text": "this system and so this this is a high-performing data team this is a data team that's thinking about the ultimate",
    "start": "1204150",
    "end": "1209910"
  },
  {
    "text": "outcomes of their work and not just did I build a good recognition system so",
    "start": "1209910",
    "end": "1215730"
  },
  {
    "text": "this for me this for us at periscope data is the increase in human intelligence that has to happen at least",
    "start": "1215730",
    "end": "1222420"
  },
  {
    "text": "as fast as the increases in artificial intelligence are happening if you are at a company that wasn't doing any AI as a",
    "start": "1222420",
    "end": "1228720"
  },
  {
    "text": "year ago and was only dabbling six months ago and that was pushing really cool really advanced systems into",
    "start": "1228720",
    "end": "1234450"
  },
  {
    "text": "production then you need to take responsibility for growing your human intelligence and growing the",
    "start": "1234450",
    "end": "1239670"
  },
  {
    "text": "responsibility and the care that you put into your long-term outcomes at least as fast as you're growing your technical",
    "start": "1239670",
    "end": "1245490"
  },
  {
    "text": "capabilities so I want to talk about three things that you can do three takeaways from our positive examples",
    "start": "1245490",
    "end": "1252120"
  },
  {
    "text": "that you can take back you go home in a couple of days all tired out from Vegas you crash you wake up you go to work and",
    "start": "1252120",
    "end": "1259290"
  },
  {
    "text": "you sit down at your terminal what are the three things that you should do what are the three things that you should think about number one is what metrics",
    "start": "1259290",
    "end": "1266730"
  },
  {
    "text": "are you evaluating your cell phone if you're evaluating yourself on technical metrics I threw out precision and recall",
    "start": "1266730",
    "end": "1273090"
  },
  {
    "text": "a lot here those are some if you're evaluating yourself and technical metrics you need to do better and if",
    "start": "1273090",
    "end": "1279750"
  },
  {
    "text": "you're evaluating yourselves on business outcomes that's a little bit better but you still need to do better take those",
    "start": "1279750",
    "end": "1285210"
  },
  {
    "text": "long-term outcomes and think to yourself what's a metric that really represents that don't just think about revenue",
    "start": "1285210",
    "end": "1292200"
  },
  {
    "text": "think about user engagement try to measure user happiness try to think about one of the negative outcomes that",
    "start": "1292200",
    "end": "1297360"
  },
  {
    "text": "could happen and put a metric behind it one trick I like at the very least is to pair your metrics if you can't measure",
    "start": "1297360",
    "end": "1302850"
  },
  {
    "text": "long-term societal outcomes which is really hard to measure at least pair your metrics say okay I want user",
    "start": "1302850",
    "end": "1308790"
  },
  {
    "text": "engagement but I also want to minimize spam and I want those to be my two metrics and that way I won't maximize",
    "start": "1308790",
    "end": "1314550"
  },
  {
    "text": "engagement simply by spamming my users and try to always pair those metrics to",
    "start": "1314550",
    "end": "1320520"
  },
  {
    "text": "is think hard about how you are building your team your team needs to represent the end group of people that you're your",
    "start": "1320520",
    "end": "1327330"
  },
  {
    "text": "algorithm will be used on if you are building a system for a consumer product that's going to be used by the entire",
    "start": "1327330",
    "end": "1333330"
  },
  {
    "text": "world audience really work hard on building your team to represent the entire world audience so you don't have",
    "start": "1333330",
    "end": "1338870"
  },
  {
    "text": "stupid mistakes and easily avoidable failures and things that end up setting society back quite a bit this is really",
    "start": "1338870",
    "end": "1345240"
  },
  {
    "text": "simple the research is really clear if you can build a team that is representative of the population and",
    "start": "1345240",
    "end": "1350760"
  },
  {
    "text": "then it's diverse the team will outperform other teams and the team will avoid these really negative societal",
    "start": "1350760",
    "end": "1356580"
  },
  {
    "text": "outcomes because you will build a lot of different backgrounds and a lot of different perspectives into your team",
    "start": "1356580",
    "end": "1361650"
  },
  {
    "text": "and finally think hard about the data that you are bringing into the system",
    "start": "1361650",
    "end": "1366900"
  },
  {
    "text": "it's not just the algorithm it's the training set and the evaluation set try to have multiple sources of data try to",
    "start": "1366900",
    "end": "1373440"
  },
  {
    "text": "have diverse sources of data and you're never going to eliminate all the bias from your data but at least know and",
    "start": "1373440",
    "end": "1379170"
  },
  {
    "text": "understand what the bias these are so that you can be conscious of them as you're working on the system and you can try to correct them as much as possible",
    "start": "1379170",
    "end": "1385860"
  },
  {
    "text": "think to yourself where did this data come from and what are the inherent biases likely to be can I correct for that in the system can I bring in",
    "start": "1385860",
    "end": "1392190"
  },
  {
    "text": "another source of data that will that will counterbalance that source of data and wherever possible have many many",
    "start": "1392190",
    "end": "1397830"
  },
  {
    "text": "sources of data not just the one one bonus idea and this is for the leaders",
    "start": "1397830",
    "end": "1403620"
  },
  {
    "text": "of the managers in this group think hard about what individual really owns this at your company",
    "start": "1403620",
    "end": "1409510"
  },
  {
    "text": "is your data team to data analysts in finance and one data analyst and product and one in marketing because those teams",
    "start": "1409510",
    "end": "1415810"
  },
  {
    "text": "are gonna adopt the biases of the particular organization that they're in and they will never come together to form a single source of truth and a",
    "start": "1415810",
    "end": "1422110"
  },
  {
    "text": "single conscience around this issue instead think about do I have a head of analytics a director of analytics or my",
    "start": "1422110",
    "end": "1428020"
  },
  {
    "text": "very favorite a chief data officer and can that person be charged with the overall responsibility for using data",
    "start": "1428020",
    "end": "1434620"
  },
  {
    "text": "well at this company so it's not just a scattershot set of data analysts of data scientists but it's one team and one",
    "start": "1434620",
    "end": "1442030"
  },
  {
    "text": "head who owns this responsibility and who is the conscience for this organization we have a number of teams",
    "start": "1442030",
    "end": "1449170"
  },
  {
    "text": "now that we work with that are starting to organize their teams this way and they quickly become the highest",
    "start": "1449170",
    "end": "1455020"
  },
  {
    "text": "performing organizations that we work with and not just the teams that take the most responsibility although that's",
    "start": "1455020",
    "end": "1460240"
  },
  {
    "text": "the most important thing but also the teams that do their best work on data because you will get all these great second-order effects you will get you",
    "start": "1460240",
    "end": "1467230"
  },
  {
    "text": "know a shared source of truth you will get an end to the fights over you know which source of data is accurate and you",
    "start": "1467230",
    "end": "1473320"
  },
  {
    "text": "will finally get a shared consciousness a shared understanding for how we should be looking at data at this company one",
    "start": "1473320",
    "end": "1480720"
  },
  {
    "text": "one an analogy that I like is comparing the chief data officer to the chief",
    "start": "1480720",
    "end": "1486130"
  },
  {
    "text": "security officer let's go all the way back to that Facebook example that I mentioned at the beginning of the talk right and one of the things that",
    "start": "1486130",
    "end": "1493060"
  },
  {
    "text": "happened in the wake of that incident at Facebook is the chief security officer at Facebook disagreed with how the",
    "start": "1493060",
    "end": "1498100"
  },
  {
    "text": "incident was handled and ultimately resigns that's because there's a culture that the chief security officer you know they",
    "start": "1498100",
    "end": "1503920"
  },
  {
    "text": "keep an eye on the networks and the firewalls yes but they don't just own InfoSec they have a responsibility for",
    "start": "1503920",
    "end": "1509080"
  },
  {
    "text": "responsible disclosure and interacting with the press around security issues and taking ultimate responsibility for",
    "start": "1509080",
    "end": "1515530"
  },
  {
    "text": "security in the organization the chief data officer needs to think about data the same way are we doing machine",
    "start": "1515530",
    "end": "1521980"
  },
  {
    "text": "learning an AI in a responsible way what are the long-term consequences here stepping up and saying you know what no",
    "start": "1521980",
    "end": "1527830"
  },
  {
    "text": "I know we could maximize revenue that way but it's going to be really bad five years from now and we shouldn't do it",
    "start": "1527830",
    "end": "1532960"
  },
  {
    "text": "that's something that the chief data officer needs to take ultimate responsibility for in your organization",
    "start": "1532960",
    "end": "1538060"
  },
  {
    "text": "and it's something that we see the highest performing organizations start to do is appoint a single person who",
    "start": "1538060",
    "end": "1543399"
  },
  {
    "text": "that responsibility holistically across the organization so bringing it all the",
    "start": "1543399",
    "end": "1549489"
  },
  {
    "text": "way back what is your value as a data professional your value as a data professional is to bring the conscience",
    "start": "1549489",
    "end": "1555279"
  },
  {
    "text": "of data to your organization not just math not just science and not just business outcomes but ultimately the",
    "start": "1555279",
    "end": "1561940"
  },
  {
    "text": "conscience for the use of data at the organization all right that's it",
    "start": "1561940",
    "end": "1567009"
  },
  {
    "text": "I'm Harry Glaser on Twitter we're periscope datacom I think there's questions maybe so we'll do that for a",
    "start": "1567009",
    "end": "1572830"
  },
  {
    "text": "little while but I really appreciate your time thank you yeah well flip over to some signup questions so you can read",
    "start": "1572830",
    "end": "1580119"
  },
  {
    "text": "them right here first question is what's your personal favorite use case to periscope data man I just used crisis",
    "start": "1580119",
    "end": "1586509"
  },
  {
    "text": "sex line in the talk so I can't use that one all right I'll use it I'll use a more",
    "start": "1586509",
    "end": "1591759"
  },
  {
    "text": "business E one so one of our customers is flex port and they they're a freight",
    "start": "1591759",
    "end": "1597519"
  },
  {
    "text": "forwarder and what that means this year if your Apple and you contract with a flex port flex port takes responsibility for moving your goods from Shenzhen to",
    "start": "1597519",
    "end": "1604869"
  },
  {
    "text": "the stores around the world and so their routing ships around the world and their routing planes in the air and all this",
    "start": "1604869",
    "end": "1609999"
  },
  {
    "text": "kinds of stuff we're more technically their routing goods on preexisting ships and planes one day my good friend",
    "start": "1609999",
    "end": "1615909"
  },
  {
    "text": "Patrick who is the director of data science at Flex port he wakes up and he's got a text message from his CEO Ryan there's a port strike in Amsterdam",
    "start": "1615909",
    "end": "1623289"
  },
  {
    "text": "we need to reroute all the goods come to an emergency executive meeting at noon with a recommendation cool no problem",
    "start": "1623289",
    "end": "1632289"
  },
  {
    "text": "and he goes he nerds out in periscope he runs a bunch of different scenarios for",
    "start": "1632289",
    "end": "1637690"
  },
  {
    "text": "what are all the different ways that we could route goods around the world they could use margin negative lanes to solve",
    "start": "1637690",
    "end": "1643659"
  },
  {
    "text": "this problem quickly by spending a bunch of money or they could sit tight and not too much but save their money and still be profitable or maybe there's some",
    "start": "1643659",
    "end": "1650259"
  },
  {
    "text": "Goldilocks in between option so he brings all HIDA stills those into three you know sort of net net outcomes brings",
    "start": "1650259",
    "end": "1656919"
  },
  {
    "text": "them to the executive team at noon flex port makes a decision at noon and reroutes goods the same day as a port",
    "start": "1656919",
    "end": "1662679"
  },
  {
    "text": "strike this is crazy freight forwarding is a very relationship business it's you know I",
    "start": "1662679",
    "end": "1668139"
  },
  {
    "text": "know a guy at the port in oakland's you know like that and flex port is reacting it's the same day two changes in market",
    "start": "1668139",
    "end": "1674320"
  },
  {
    "text": "conditions and that's why they're taking over that market that made me really proud as the use of periscope data when is when does",
    "start": "1674320",
    "end": "1683900"
  },
  {
    "text": "personalization become manipulation where's that fine line I'm not really sure how to answer this question well",
    "start": "1683900",
    "end": "1689780"
  },
  {
    "text": "you know seventy percent to weigh in when this personalization become manipulation I don't I don't necessarily",
    "start": "1689780",
    "end": "1697370"
  },
  {
    "text": "think of the question in those terms I think personalization can have positive outcomes and personalization can't have",
    "start": "1697370",
    "end": "1702710"
  },
  {
    "text": "negative outcomes and if it's overwhelmingly negative then yeah that's manipulation but what you really the way",
    "start": "1702710",
    "end": "1708830"
  },
  {
    "text": "you really want to think about this is what are the ultimate outcomes going to be and are am i comfortable with that and",
    "start": "1708830",
    "end": "1715100"
  },
  {
    "text": "also you want to keep an eye on it a lot of the time when personalization goes wrong it's an accident right we",
    "start": "1715100",
    "end": "1721040"
  },
  {
    "text": "didn't sit down with the intent to manipulate people we thought a personalization algorithm would be really cool and that noobs we polarized",
    "start": "1721040",
    "end": "1727310"
  },
  {
    "text": "the country and so what you want to do is watch your educators every step of the way and have some good intellectual",
    "start": "1727310",
    "end": "1733820"
  },
  {
    "text": "honesty on the team for what's really working and what's really not working and then make changes one of the things",
    "start": "1733820",
    "end": "1739760"
  },
  {
    "text": "that I think the industry actually needs to do better at is listen we're all somewhere starting on this journey we're",
    "start": "1739760",
    "end": "1745190"
  },
  {
    "text": "all going to make mistakes right the Facebook team is still one of the best data teams or the best data team out there you know more power to them but we",
    "start": "1745190",
    "end": "1752210"
  },
  {
    "text": "need to be comfortable with we're going to improve over time we're gonna make mistakes and we're going to correct them and we don't necessarily need to label",
    "start": "1752210",
    "end": "1758840"
  },
  {
    "text": "it manipulation when something goes wrong we just need to own up to it and correct it so you talked about",
    "start": "1758840",
    "end": "1765040"
  },
  {
    "text": "algorithms being biased so what does that mean I'm really talking about human biases and therefore should be work on bias prevention with engineers how do",
    "start": "1765040",
    "end": "1772310"
  },
  {
    "text": "you solve that from a human perspective yes we are talking about human biases of course when I say an algorithm is biased",
    "start": "1772310",
    "end": "1778790"
  },
  {
    "text": "what I mean is the algorithm or the data set has encoded the biases of the particular team that built it usually",
    "start": "1778790",
    "end": "1785210"
  },
  {
    "text": "unintentionally right and so the root solution is for the team to address its own bias and for the team also to work",
    "start": "1785210",
    "end": "1791780"
  },
  {
    "text": "hard on not being biased as a team we're all biased as individuals I grew up on",
    "start": "1791780",
    "end": "1796880"
  },
  {
    "text": "the East Coast I grew up you know white male and upper-middle class I bring a certain set of biases to decisions that",
    "start": "1796880",
    "end": "1803390"
  },
  {
    "text": "I make that are based on that I'm not going to eradicate all of my bias overnight but what I can do is construct",
    "start": "1803390",
    "end": "1808760"
  },
  {
    "text": "a team full of people from overseas people who grew up in different socioeconomic backgrounds people who had",
    "start": "1808760",
    "end": "1813890"
  },
  {
    "text": "very different life experiences for me and then when we all sit around and we say should I make this change to our data model should I make this change to",
    "start": "1813890",
    "end": "1820250"
  },
  {
    "text": "our system should I make this change to our organization we can have ideally a more unbiased team decision because the",
    "start": "1820250",
    "end": "1827600"
  },
  {
    "text": "team has different biases and not all the same biases they bring to the table when the bad really happens is when",
    "start": "1827600",
    "end": "1833450"
  },
  {
    "text": "you get 10 people from exactly the same background making a decision and then that bias that they all bring just gets",
    "start": "1833450",
    "end": "1839210"
  },
  {
    "text": "magnified so yeah what was the question again yeah we are talking about human",
    "start": "1839210",
    "end": "1844340"
  },
  {
    "text": "biases and we the root solution is to work on these biases with the engineers that work on this system absolutely",
    "start": "1844340",
    "end": "1851470"
  },
  {
    "text": "we're trying to paraphrase this question you're trying to calculate incentives and different paths the people get",
    "start": "1851470",
    "end": "1856970"
  },
  {
    "text": "different incentives how do you how to use data I kind of calculate that figure that out how do you how do you approach",
    "start": "1856970",
    "end": "1861980"
  },
  {
    "text": "that problem this is a great question right because a scientist a pure",
    "start": "1861980",
    "end": "1868520"
  },
  {
    "text": "mathematician a robot if you if you built an algorithm to optimize the incentives the algorithm would simply",
    "start": "1868520",
    "end": "1873860"
  },
  {
    "text": "say I'm gonna pay the middle-aged dude $50 or $100 or $500 and I'm gonna pay",
    "start": "1873860",
    "end": "1879370"
  },
  {
    "text": "the other class of person $30 sounds good I've gotten my outcomes and that's",
    "start": "1879370",
    "end": "1885260"
  },
  {
    "text": "the problem with evaluating this as a math problem or as a science problem right because you're not thinking hard about is this right do I feel good about",
    "start": "1885260",
    "end": "1892670"
  },
  {
    "text": "this is this ethical is this moral you're just thinking about optimizing and so you might say you know what an",
    "start": "1892670",
    "end": "1898070"
  },
  {
    "text": "optimizer a machine learning system is not right for this system instead I want a different system I want a very simple",
    "start": "1898070",
    "end": "1903800"
  },
  {
    "text": "heuristic that simply pays everyone the same or whatever you want to do so yeah I mean you're preaching to the choir rub",
    "start": "1903800",
    "end": "1909470"
  },
  {
    "text": "but I think absolutely this is a good example of where simply approaching it",
    "start": "1909470",
    "end": "1914840"
  },
  {
    "text": "as a technical question is not the right thing to do I'm gonna ask one question all right if you're hiring somebody for",
    "start": "1914840",
    "end": "1920570"
  },
  {
    "text": "a data role now it turns into more of a personal bike is your do you have the right personal backgrounds do you have",
    "start": "1920570",
    "end": "1925760"
  },
  {
    "text": "the right ethical backgrounds so what are questions you ask how do you vet someone we know how to do in a technical level now how do you do it on a personal",
    "start": "1925760",
    "end": "1932300"
  },
  {
    "text": "level to make sure they're the right fit yeah a few tricks first I will try to ask about moral and ethical situations",
    "start": "1932300",
    "end": "1939590"
  },
  {
    "text": "that they have faced in their career data scientists are a young profession and this idea that we should be thinking",
    "start": "1939590",
    "end": "1944690"
  },
  {
    "text": "about it this way it's not the pointy-haired bosses job to take responsibility for the ethics that idea is new so an a-plus answer is I've",
    "start": "1944690",
    "end": "1951049"
  },
  {
    "text": "confronted this problem in my career here's how I thought about it I construct my teams in a certain way i counteract bias using this other way",
    "start": "1951049",
    "end": "1957190"
  },
  {
    "text": "that's really great that's maybe one in a hundred people that can give you that answer and so then you pivot to tell me",
    "start": "1957190",
    "end": "1962690"
  },
  {
    "text": "about your life experience and tell me about how you should approach these problems and listen like I said everybody's on a journey",
    "start": "1962690",
    "end": "1968149"
  },
  {
    "text": "nobody's all the way there so it's okay to hire somebody that hasn't thought about this before or you know hasn't",
    "start": "1968149",
    "end": "1974539"
  },
  {
    "text": "removed bias from a model or thought long term about societal implications before but you should be able to in the",
    "start": "1974539",
    "end": "1979940"
  },
  {
    "text": "interview trigger an open discussion about that stuff and get them thinking about it and if they get animated and if",
    "start": "1979940",
    "end": "1986750"
  },
  {
    "text": "they start thinking yeah this really is a hard problem and oh my gosh I want to think about this differently that's",
    "start": "1986750",
    "end": "1992000"
  },
  {
    "text": "great news too if they go listen I'm just here for the math or that's somebody else's problem then you",
    "start": "1992000",
    "end": "1998929"
  },
  {
    "text": "know they may not be the right fit or Bay they may have some more learning to do before they're ready to be in a position of responsibility like this and",
    "start": "1998929",
    "end": "2005080"
  },
  {
    "text": "also something else that's changes data scientists used to just be able to work on the projects launch and be done with",
    "start": "2005080",
    "end": "2010090"
  },
  {
    "text": "now it's like you should be integrating each be looping in PR other people understand what the public response is",
    "start": "2010090",
    "end": "2016809"
  },
  {
    "text": "gonna be to this work how do you do that when do you do that the number one I want to push back on I love PR and you",
    "start": "2016809",
    "end": "2025539"
  },
  {
    "text": "should loop in PR but you should not treat ethical problems like they're PR problems and the PR the PR people",
    "start": "2025539",
    "end": "2031629"
  },
  {
    "text": "they're here to get you attention and they do a great job but they're not your Ephesus for hire and they're all you know treating it like a PR problem is a",
    "start": "2031629",
    "end": "2038620"
  },
  {
    "text": "good way to get things swept under the rug and stuff like that but you should engage in an open conversation with as",
    "start": "2038620",
    "end": "2044049"
  },
  {
    "text": "many people as possible about what are the short and long term implications of what we're doing here and bring you know",
    "start": "2044049",
    "end": "2049990"
  },
  {
    "text": "management says go build me an AI system that will optimize my purchase rate in my shopping cart cool let's go do that",
    "start": "2049990",
    "end": "2056618"
  },
  {
    "text": "a week later we come back and present our solution to management don't just present I estimated 10% uplift also",
    "start": "2056619",
    "end": "2062740"
  },
  {
    "text": "present here is how we're doing it and here is what's going to be good about that and here's what I'm worried about about that and I think we should take a",
    "start": "2062740",
    "end": "2068560"
  },
  {
    "text": "moment to have an open conversation about whether we really want it and whether it's worth a 10% uplift and what's going to happen five 10 years",
    "start": "2068560",
    "end": "2074378"
  },
  {
    "text": "from now after we've optimized the hell out of this thing it may be the right thing to do but it may not be the right thing to and I would have the open conversation",
    "start": "2074379",
    "end": "2080860"
  },
  {
    "text": "with as many people as possible and I would also take responsibility on the core team right nobody else is going to",
    "start": "2080860",
    "end": "2087070"
  },
  {
    "text": "understand these implications as well as you who built the thing are and so it's not for PR it's not for management it's",
    "start": "2087070",
    "end": "2092590"
  },
  {
    "text": "for you and you need to sit and have that conversation with your own teammates Harry I want to thank you very",
    "start": "2092590",
    "end": "2097930"
  },
  {
    "text": "much an applause for Harry [Applause]",
    "start": "2097930",
    "end": "2102919"
  }
]
[
  {
    "text": "good afternoon everyone thank you for joining us today in this session big data scale my name is gargy Singh shot",
    "start": "140",
    "end": "6359"
  },
  {
    "text": "wall and I'm an associate Solutions Architect with Amazon Web Services with me today presenting is also dr. Nathan",
    "start": "6359",
    "end": "12210"
  },
  {
    "text": "Nayak he is the chief technology officer at US Census Bureau as well as nanda",
    "start": "12210",
    "end": "17369"
  },
  {
    "text": "commercially watson senior Solutions Architect at Amazon Web Services I hope",
    "start": "17369",
    "end": "22859"
  },
  {
    "text": "all of you had a nice fulfilling lunch and is similarly energetic as I am with",
    "start": "22859",
    "end": "28859"
  },
  {
    "text": "that let's dive deep straight into it so today we are going to cover why big data",
    "start": "28859",
    "end": "34530"
  },
  {
    "text": "if you are an enterprise and you're dealing with your legacy applications or you're creating new ones why does big data matter to you then we",
    "start": "34530",
    "end": "42270"
  },
  {
    "text": "are going to see how to do big data processing on AWS which services you can utilize on AWS to create your enterprise",
    "start": "42270",
    "end": "49649"
  },
  {
    "text": "application next I would like to invite nanda to talk about a few of the",
    "start": "49649",
    "end": "54960"
  },
  {
    "text": "architectural patterns which we see in our customer space as well as I would like to invite dr. Nathan Nyak to talk",
    "start": "54960",
    "end": "60809"
  },
  {
    "text": "about how US Census is utilizing AWS services to create their enterprise data",
    "start": "60809",
    "end": "66119"
  },
  {
    "text": "Lake so why big data I'm a really",
    "start": "66119",
    "end": "72689"
  },
  {
    "text": "curious person to feed my curiosity I like to read a lot so in one of those readings prints which I call them I came",
    "start": "72689",
    "end": "79259"
  },
  {
    "text": "across a study known by International Data Corporation or IDC which talks",
    "start": "79259",
    "end": "84750"
  },
  {
    "text": "about the total size of the digital universe so think about it as every",
    "start": "84750",
    "end": "91350"
  },
  {
    "text": "digital platform that you know every device that you know every data that you know about it's by 2016 it was sixteen",
    "start": "91350",
    "end": "98460"
  },
  {
    "text": "point one zero byte and by the time we reach 2025 it is estimated to reach",
    "start": "98460",
    "end": "103890"
  },
  {
    "text": "around 163 is era bite just to give you a perspective of how much one 0 byte is",
    "start": "103890",
    "end": "111689"
  },
  {
    "text": "I think all of you in the room are aware of you know a 1 terabyte hard disk now",
    "start": "111689",
    "end": "117000"
  },
  {
    "text": "imagine 1 billion of those so when you stack them all together you might reach somewhere near around 1 0 byte so by the",
    "start": "117000",
    "end": "124020"
  },
  {
    "text": "time we reach 2025 think about 163 billion hard disk where you got to keep",
    "start": "124020",
    "end": "129239"
  },
  {
    "text": "them is it going to be a room location it could be your data warehouse but how much that can",
    "start": "129239",
    "end": "134280"
  },
  {
    "text": "or is it going to be something else so if I'm an enterprise and I'm either remodeling my legacy application or",
    "start": "134280",
    "end": "141270"
  },
  {
    "text": "creating a new application from scratch I would think am i architected to achieve this scale am I and it's not",
    "start": "141270",
    "end": "149610"
  },
  {
    "text": "just about the velocity it's also about the loss it's not just about the volume it's also about the velocity and the",
    "start": "149610",
    "end": "156540"
  },
  {
    "text": "variety with which we are you know producing this data and consuming this data think about your legacy",
    "start": "156540",
    "end": "162030"
  },
  {
    "text": "applications which used to have and now we have IOT devices ever-present you know in all phases of life it could",
    "start": "162030",
    "end": "168660"
  },
  {
    "text": "be the fitbit's you hear when you work out it could be the sensors which are in your cars when you move around for",
    "start": "168660",
    "end": "174959"
  },
  {
    "text": "example you know there are a lot of cars right now which are dealing with a lot of different sensors and different type of data which has been produced so if I",
    "start": "174959",
    "end": "182160"
  },
  {
    "text": "am an enterprise I would have those questions in my mind am I architected to handle this volume right velocity and variety of this data",
    "start": "182160",
    "end": "189390"
  },
  {
    "text": "as well so now let's talk about how you can handle all these three factors by",
    "start": "189390",
    "end": "195390"
  },
  {
    "text": "coming on to AWS and then using the AWS services my time working with big data",
    "start": "195390",
    "end": "204060"
  },
  {
    "text": "and as a big data engineer and then added abuse as well I've always believed that a successful big data application",
    "start": "204060",
    "end": "210980"
  },
  {
    "text": "follows a particular trend and then this trend is nothing but an actual pipeline and it starts with recognizing what data",
    "start": "210980",
    "end": "218940"
  },
  {
    "text": "you have and at the end of this pipeline are the answers which you are looking for now these answer could vary depending upon what are you looking for",
    "start": "218940",
    "end": "226130"
  },
  {
    "text": "this pipeline has multiple components to it starting with how are you going to",
    "start": "226130",
    "end": "231150"
  },
  {
    "text": "collect this data recognizing which applications are producing this data the next part of this pipeline is to",
    "start": "231150",
    "end": "237720"
  },
  {
    "text": "recognize how are you going to store this data because the data could be in different shapes sizes formats",
    "start": "237720",
    "end": "243630"
  },
  {
    "text": "structures it could be anything which you are looking for the next part of this pipeline is to recognize how are",
    "start": "243630",
    "end": "250620"
  },
  {
    "text": "you going to process and analyze this data do you want to do some kind of ETL on this do you want to do some kind of",
    "start": "250620",
    "end": "255870"
  },
  {
    "text": "conversions on this or do you want to do some basic analysis this step can repeat",
    "start": "255870",
    "end": "260910"
  },
  {
    "text": "itself based on the fact that how you want your data to be in a shape and",
    "start": "260910",
    "end": "266159"
  },
  {
    "text": "format at the end of this pipeline which is how you consume the data so these three steps well a lot of",
    "start": "266159",
    "end": "274740"
  },
  {
    "text": "time they repeat themselves based on the fact that how you want to reshape your data and how you want to consume it at",
    "start": "274740",
    "end": "279750"
  },
  {
    "text": "the end now let's just talk about each of these components one by one and see how you can achieve that on top of AWS",
    "start": "279750",
    "end": "287750"
  },
  {
    "text": "starting off with the collect phase so in this phase if you are enterprise you",
    "start": "287750",
    "end": "293160"
  },
  {
    "text": "are dealing with some kind of application it could be web applications it could be mobile applications",
    "start": "293160",
    "end": "298170"
  },
  {
    "text": "it could be enterprise applications which are running the core of your business if you are an enterprise you",
    "start": "298170",
    "end": "304170"
  },
  {
    "text": "also have requirements to store logging information it could be based of the auditing purposes it could be because of",
    "start": "304170",
    "end": "310410"
  },
  {
    "text": "networking purposes security purposes monitoring purposes and whatnot if you look at the services which alw offers",
    "start": "310410",
    "end": "316920"
  },
  {
    "text": "you can utilize AWS cloud trail which is our logging and ordering service if you",
    "start": "316920",
    "end": "323640"
  },
  {
    "text": "are running something on top of AWS utilizing AWS cloud trail you can log each and every request which is ever",
    "start": "323640",
    "end": "329970"
  },
  {
    "text": "made on the Erebus platform or the AWS resources you can also use Amazon Cloud",
    "start": "329970",
    "end": "336180"
  },
  {
    "text": "watch to monitor all the resources which are running on top of your AWS platform",
    "start": "336180",
    "end": "341690"
  },
  {
    "text": "we also support open source such as log4j log stash and flume I mentioned",
    "start": "341690",
    "end": "348210"
  },
  {
    "text": "earlier about IOT devices and their presence nowadays so if you have applications which are producing these",
    "start": "348210",
    "end": "354120"
  },
  {
    "text": "kind of streams or if you have devices within your applications which are producing these streams you can utilize",
    "start": "354120",
    "end": "360090"
  },
  {
    "text": "a WIP suit of solutions to deal with those kind of scenarios as well that",
    "start": "360090",
    "end": "367230"
  },
  {
    "text": "being said you know how you're going to collect this data but how are you going to move the data into AWS is a big",
    "start": "367230",
    "end": "373740"
  },
  {
    "text": "question now this data movement could be",
    "start": "373740",
    "end": "380010"
  },
  {
    "text": "either that you're moving the data into AWS or you have a hybrid model where your on-premise systems are talking with",
    "start": "380010",
    "end": "386100"
  },
  {
    "text": "AWS or vice-versa we have different suit of services that you can utilize to do this and achieve this as well starting",
    "start": "386100",
    "end": "392820"
  },
  {
    "text": "with Amazon Kinesis firehose and Amazon Kenya says it's really interesting service you will see it different times",
    "start": "392820",
    "end": "399180"
  },
  {
    "text": "within this pipeline itself and repeat Amazon kinases multiple times Amazon Kinesis firehose allows you to",
    "start": "399180",
    "end": "405870"
  },
  {
    "text": "seamlessly load massive amounts of data directly into a storage service or if",
    "start": "405870",
    "end": "411300"
  },
  {
    "text": "you are an enterprise you might have situations where you want to run some of your applications on Prem and some of",
    "start": "411300",
    "end": "417180"
  },
  {
    "text": "your applications move to the AWS cloud so for that you can utilize AWS Direct Connect which is a dedicated pipe",
    "start": "417180",
    "end": "423090"
  },
  {
    "text": "between your on-premise systems your data centers and the air abuse environment but what happens when the",
    "start": "423090",
    "end": "430080"
  },
  {
    "text": "data movement is too big it's too big too big going over the internet or even Direct Connect say it's terabyte",
    "start": "430080",
    "end": "437070"
  },
  {
    "text": "hundreds of terabytes of data or petabyte of data that you want to move over so for those kind of scenarios you",
    "start": "437070",
    "end": "442350"
  },
  {
    "text": "can utilize aw snowball aw snowball is an actual physical device which we send to your location you",
    "start": "442350",
    "end": "448980"
  },
  {
    "text": "connected in your own data centers you copy the data over and then you send it back to us where we connected on our",
    "start": "448980",
    "end": "454770"
  },
  {
    "text": "premise systems and then load it up into Amazon s3 which is our storage service well what if you have scenarios where",
    "start": "454770",
    "end": "462630"
  },
  {
    "text": "you want to run file formats such as NFS ice KC or other kind of storage to seamlessly integrate your on-premise",
    "start": "462630",
    "end": "469500"
  },
  {
    "text": "systems and the AWS storage you can utilize AWS Storage Gateway which allows you to handle those kind of file formats",
    "start": "469500",
    "end": "476220"
  },
  {
    "text": "such as NFS or ice cusine now that we have talked about how you can collect",
    "start": "476220",
    "end": "481440"
  },
  {
    "text": "the data and how you can move the data into AWS the next question is how are you going to save this data in which",
    "start": "481440",
    "end": "487260"
  },
  {
    "text": "structures in which format are you going to save this data so that it's you're able to process it onwards when I talk",
    "start": "487260",
    "end": "495480"
  },
  {
    "text": "about relational enterprises you see that they are dealing with a lot of data bases now this can be in the realm of",
    "start": "495480",
    "end": "501710"
  },
  {
    "text": "relational databases it could be in the realm of non-relational databases so for each of those we have multiple services",
    "start": "501710",
    "end": "507870"
  },
  {
    "text": "such as Amazon relational database service it's a fully managed service you don't have to take care of underlying",
    "start": "507870",
    "end": "513900"
  },
  {
    "text": "infrastructure you don't have to take care of them managing the patching and the software updates if you are dealing",
    "start": "513900",
    "end": "520469"
  },
  {
    "text": "with non-relational database such as MongoDB we have a fully managed service known as Amazon DynamoDB",
    "start": "520470",
    "end": "525750"
  },
  {
    "text": "which helps you achieve that as well but if you are enterprise you're not just",
    "start": "525750",
    "end": "530820"
  },
  {
    "text": "going to handle you know databases there is to be a lot of different kind of data it",
    "start": "530820",
    "end": "536470"
  },
  {
    "text": "could be multimedia files it could be images it could be text files it could be some other kind of blob so for all",
    "start": "536470",
    "end": "542800"
  },
  {
    "text": "that kind of storage you can utilize Amazon s3 which is a simple storage service Amazon s3 is highly scalable you",
    "start": "542800",
    "end": "550780"
  },
  {
    "text": "don't have a maximum limit of how much you can scale it it's it's massively scalable it offers you 11 lines of",
    "start": "550780",
    "end": "556690"
  },
  {
    "text": "durability so imagine that you're going to lose one file in about you know 10",
    "start": "556690",
    "end": "562150"
  },
  {
    "text": "million years that being said if I go back to the devices segment which I was",
    "start": "562150",
    "end": "570010"
  },
  {
    "text": "talking about earlier if you have some kind of applications which are generating streaming data you can",
    "start": "570010",
    "end": "575770"
  },
  {
    "text": "utilize the different services which we have to offer such as Amazon canisters fire hose Amazon Kinesis streams",
    "start": "575770",
    "end": "583170"
  },
  {
    "text": "dynamodb tables which allow your non-relational database table such as you know MongoDB or something like that",
    "start": "583170",
    "end": "589240"
  },
  {
    "text": "and convert those non-relational tables into a streaming structure where you can",
    "start": "589240",
    "end": "594670"
  },
  {
    "text": "directly stream from the tables itself we also support open source software's such as Apache Kafka which you can run",
    "start": "594670",
    "end": "601660"
  },
  {
    "text": "on top of ec2 which is an elastic cloud compute service now that we have",
    "start": "601660",
    "end": "608320"
  },
  {
    "text": "realized how are you going to save this data how how are you going to collect this data the next part of the pipeline",
    "start": "608320",
    "end": "615430"
  },
  {
    "text": "is to recognize how are you going to do the processing and analyzing of this data what kind of different processes",
    "start": "615430",
    "end": "620890"
  },
  {
    "text": "you can do and we believe that there are four major things that you always do with your data starting with data",
    "start": "620890",
    "end": "627160"
  },
  {
    "text": "enrichment you can add multiple data sets to one another to enrich the data",
    "start": "627160",
    "end": "632320"
  },
  {
    "text": "so that you can see what you have not yet seen in in your data itself we have a suit of different services which which",
    "start": "632320",
    "end": "638950"
  },
  {
    "text": "support this as well such as Amazon EMR which is an elastic MapReduce service Amazon Kinesis it obvious glue you can",
    "start": "638950",
    "end": "647710"
  },
  {
    "text": "do some kind of analysis it could be bash analysis it could be streaming analysis it could be interactive",
    "start": "647710",
    "end": "652870"
  },
  {
    "text": "analysis as well and we have a bunch of different services that you can utilize to do it to achieve that as well if I go",
    "start": "652870",
    "end": "660280"
  },
  {
    "text": "into the realm of ETL which is extract transform and load say you want to convert one of your JSON files into",
    "start": "660280",
    "end": "665740"
  },
  {
    "text": "park' or if you want to convert your CSV files into something we have a bunch of different services which help you support do that as well",
    "start": "665740",
    "end": "673540"
  },
  {
    "text": "one other thing I want to talk to you about today is a concept of derelict so",
    "start": "673540",
    "end": "679010"
  },
  {
    "text": "let's say if you are an organization which is doing some kind of genomic research one part of your scientific",
    "start": "679010",
    "end": "684830"
  },
  {
    "text": "group sees the data in a different way than the other part of your scientific group you don't want to create data",
    "start": "684830",
    "end": "690110"
  },
  {
    "text": "silos and reiterate the work which you have already done you don't want to ever go back and reinvent the wheel which the",
    "start": "690110",
    "end": "697490"
  },
  {
    "text": "data which is already already present so for that you can utilize a bunch of",
    "start": "697490",
    "end": "703160"
  },
  {
    "text": "different services which we have to create your own data like keeping all the data at a single location so that",
    "start": "703160",
    "end": "708650"
  },
  {
    "text": "multiple parts of your organization can view the data from the same place without having to reinvent the wheel",
    "start": "708650",
    "end": "714050"
  },
  {
    "text": "again as well now I'm going to talk about a few of these services in details",
    "start": "714050",
    "end": "720640"
  },
  {
    "text": "starting with Amazon EMR which is our elastic MapReduce service it's a fully",
    "start": "721780",
    "end": "727760"
  },
  {
    "text": "managed Hadoop cluster framework it suppose variety of big data frameworks such as - Paulo SPARC presto and many",
    "start": "727760",
    "end": "734900"
  },
  {
    "text": "more we see a lot of our federal agencies utilizing EMR in their production workloads where they're on",
    "start": "734900",
    "end": "741080"
  },
  {
    "text": "their patches spark or hive workloads on top of AWS what makes EMR difference is",
    "start": "741080",
    "end": "748520"
  },
  {
    "text": "the fact that it comes with something called as EMR FS which is elastic MapReduce file system that allows EMR to",
    "start": "748520",
    "end": "755060"
  },
  {
    "text": "efficiently and securely use Amazon s3 as the underlying storage so you don't have to worry about creating your HDFS",
    "start": "755060",
    "end": "762110"
  },
  {
    "text": "storage underneath your clusters anymore rather you can stream the data directly from s3 into your clusters to process it",
    "start": "762110",
    "end": "769000"
  },
  {
    "text": "it's natively integrated with Amazon s3 RDS redshift and any other JDBC",
    "start": "769000",
    "end": "774620"
  },
  {
    "text": "compliant datastore but if you're an organization you are not just going to",
    "start": "774620",
    "end": "780080"
  },
  {
    "text": "have the need for distributed computing you might want to run some kind of structured statistical analysis you",
    "start": "780080",
    "end": "787580"
  },
  {
    "text": "might want to go into the realm of data warehousing so for that you can utilize a service called as Amazon redshift",
    "start": "787580",
    "end": "794290"
  },
  {
    "text": "which is a fully managed relational data warehousing service it's massively",
    "start": "794290",
    "end": "799970"
  },
  {
    "text": "parallel it's better byte scale so you don't have to worry about the scale as your data is increasing or as",
    "start": "799970",
    "end": "805940"
  },
  {
    "text": "you're collecting more and more of that data Amazon redshift supports data",
    "start": "805940",
    "end": "811220"
  },
  {
    "text": "compression so it reduces your iOS massively so you are you get more insights out of the same amount of data",
    "start": "811220",
    "end": "817100"
  },
  {
    "text": "you already have it also support column in our data storage and it is designed for scale if you look at the pricing",
    "start": "817100",
    "end": "824990"
  },
  {
    "text": "model of Amazon redshift you will notice that it's one-tenth the cost of traditional data warehousing solutions",
    "start": "824990",
    "end": "830150"
  },
  {
    "text": "commercial off-the-shelf data warehousing solutions and it's only 1,000 per terabyte per year but for an",
    "start": "830150",
    "end": "838730"
  },
  {
    "text": "enterprise it's okay to have distributed computing it's okay to have data warehousing solutions well what if you",
    "start": "838730",
    "end": "845600"
  },
  {
    "text": "want to analyze the data as it's coming in you don't want to wait too much to analyze this data or even start up your",
    "start": "845600",
    "end": "852170"
  },
  {
    "text": "own clusters and then feed the data into those clusters and then you know do some kind of analysis so for that we have a",
    "start": "852170",
    "end": "859400"
  },
  {
    "text": "service known as Amazon Kinesis Amazon Kinesis is a managed service for",
    "start": "859400",
    "end": "864590"
  },
  {
    "text": "real-time big data processing it has three different variants to it the first one being Amazon kisses streams it",
    "start": "864590",
    "end": "871670"
  },
  {
    "text": "allows you to create the producer-consumer kind of streams wherein the data which has been produced",
    "start": "871670",
    "end": "877490"
  },
  {
    "text": "yeah you can consume it on the go itself you don't have to worry about the",
    "start": "877490",
    "end": "882530"
  },
  {
    "text": "underlying infrastructure or how it's going to match the throughput of the streams which is coming in as you can",
    "start": "882530",
    "end": "887750"
  },
  {
    "text": "elastically add and remove shards with in Amazon cases streams but what if you",
    "start": "887750",
    "end": "892940"
  },
  {
    "text": "just don't want to analyze it rather keep it somewhere so that you can do some other statistical analysis at a",
    "start": "892940",
    "end": "899330"
  },
  {
    "text": "later point of time for that you can use Amazon Canisius firehose that allows you",
    "start": "899330",
    "end": "905150"
  },
  {
    "text": "to massively load large amount of data into our storage services such as Amazon s3 or redshift that being said if you",
    "start": "905150",
    "end": "914870"
  },
  {
    "text": "want to do some kind of analysis say you are an enterprise and you want to see and create some kind of charts and",
    "start": "914870",
    "end": "921140"
  },
  {
    "text": "graphs or do some kind of data manipulation of the data itself as it's coming in you can utilize Genesis",
    "start": "921140",
    "end": "927770"
  },
  {
    "text": "analytics which allows you to do sequel type queries on the data as it comes in",
    "start": "927770",
    "end": "933020"
  },
  {
    "text": "you don't have to wait anymore to do those kind of analysis as well say you keep all the data in",
    "start": "933020",
    "end": "941690"
  },
  {
    "text": "Amazon s3 you have acheived distributed computing you have achieved data warehousing capabilities and you are",
    "start": "941690",
    "end": "947930"
  },
  {
    "text": "also dealing with the data as it comes in but what if I don't want to clear create my clusters anymore I want to run",
    "start": "947930",
    "end": "954830"
  },
  {
    "text": "some kind of data manipulation query or data visualization query without",
    "start": "954830",
    "end": "960890"
  },
  {
    "text": "creating my own clusters so for that you can utilize Amazon Athena which is an interactive query service that allows",
    "start": "960890",
    "end": "967970"
  },
  {
    "text": "you to directly query the underlying storage which is Amazon s3 without ever having to create any infrastructure it's",
    "start": "967970",
    "end": "975080"
  },
  {
    "text": "completely server less so you don't have any infrastructure or resources to manage it allows schema and read this is",
    "start": "975080",
    "end": "982700"
  },
  {
    "text": "a very interesting thing so say if you are a financial enterprise customer and you have the market data coming in from",
    "start": "982700",
    "end": "989090"
  },
  {
    "text": "various different sources one part of your analyst group can see the data in a different way than the other part of the",
    "start": "989090",
    "end": "994820"
  },
  {
    "text": "group you don't want to read it reiterate on the traditional silos of data rather you can utilize Amazon",
    "start": "994820",
    "end": "1002200"
  },
  {
    "text": "Athena to view the same data in many different shapes and forms that is the power of Amazon Athena which allows you",
    "start": "1002200",
    "end": "1008260"
  },
  {
    "text": "to do the scheme on Reed next obvious which I want to talk to you about today",
    "start": "1008260",
    "end": "1014470"
  },
  {
    "text": "is Amazon glue it is our data warehousing and when you are doing data",
    "start": "1014470",
    "end": "1020500"
  },
  {
    "text": "warehousing you create catalogs and when you are in the realm of going into data Lake you need those catalogs because you",
    "start": "1020500",
    "end": "1026980"
  },
  {
    "text": "want to differentiate between what is present within your data warehouse Amazon glue allows you to do that it",
    "start": "1026980",
    "end": "1034209"
  },
  {
    "text": "allows you to create data catalogs it creates high merest or compatible data",
    "start": "1034210",
    "end": "1040000"
  },
  {
    "text": "catalogs which has an ask functionality there's something called as AWS root crawlers they understand the underlying",
    "start": "1040000",
    "end": "1048339"
  },
  {
    "text": "data which you have in your s3 buckets and automatically extracts the mirror out of it creates a catalog and saves it",
    "start": "1048340",
    "end": "1054730"
  },
  {
    "text": "in a Robles clue so that you can use it again and again without having to create the whole process all over again",
    "start": "1054730",
    "end": "1061860"
  },
  {
    "text": "another part of AWS glue is that it's a managed transformation engine it auto",
    "start": "1061860",
    "end": "1067450"
  },
  {
    "text": "generates the ETL code now you can go into the console click a few you know buttons and",
    "start": "1067450",
    "end": "1072730"
  },
  {
    "text": "you will have an ETL code ready for you it's built on top of open frameworks such as Python and spark so you can make",
    "start": "1072730",
    "end": "1079480"
  },
  {
    "text": "modifications within that code itself you are not restricted or you're not bound to the code which is being created",
    "start": "1079480",
    "end": "1088080"
  },
  {
    "text": "another important service or part of AWS glue is that it's a it's a job scheduler",
    "start": "1092039",
    "end": "1098919"
  },
  {
    "text": "say you want to run those ETL jobs every hour every day every month you can do",
    "start": "1098919",
    "end": "1104409"
  },
  {
    "text": "that by creating automatically repeatable jobs using the aw screw job scheduler and you don't have to worry",
    "start": "1104409",
    "end": "1110320"
  },
  {
    "text": "about how the data is going to be matched in terms of the throughput it takes or how much data you have it's",
    "start": "1110320",
    "end": "1116590"
  },
  {
    "text": "massively parallel and it's massively scalable and you don't have to worry about how the infrastructure is going to",
    "start": "1116590",
    "end": "1121960"
  },
  {
    "text": "scale as your data is increasing also it's natively integrated with Amazon s3",
    "start": "1121960",
    "end": "1127360"
  },
  {
    "text": "EMR and many other AWS services as well",
    "start": "1127360",
    "end": "1131880"
  },
  {
    "text": "sorry now that we've talked about how you can do the collect process and store",
    "start": "1134760",
    "end": "1140740"
  },
  {
    "text": "phase the last important aspect is how are you going to make your data consumable now it could be various",
    "start": "1140740",
    "end": "1147010"
  },
  {
    "text": "different formats you can either create some app and services and expose them using api's or you can do some kind of analysis or",
    "start": "1147010",
    "end": "1154270"
  },
  {
    "text": "visualizations using traditional BI tools and one such tool is Amazon quick",
    "start": "1154270",
    "end": "1159580"
  },
  {
    "text": "site it's completely server less you don't have to manage any clusters it's a pay-as-you-go model so you're only",
    "start": "1159580",
    "end": "1165460"
  },
  {
    "text": "paying for what you use we also support open source such as cabana and partner tools such as MicroStrategy what if you",
    "start": "1165460",
    "end": "1173620"
  },
  {
    "text": "want to do some kind of machine learning on top of this data which you just processed say you converted your JSON",
    "start": "1173620",
    "end": "1180309"
  },
  {
    "text": "files into a parka format and now you want to do some kind of statistical analysis or some kind of machine",
    "start": "1180309",
    "end": "1185590"
  },
  {
    "text": "learning you can do that using open source such as Apache Zeppelin or ipython notebooks on top of AWS as well",
    "start": "1185590",
    "end": "1194070"
  },
  {
    "text": "so pulling together everything summarizing what I talked about starting from how are you going to collect this",
    "start": "1194070",
    "end": "1201070"
  },
  {
    "text": "data it could be different applications it could be different logging information that you were saving say for auditing",
    "start": "1201070",
    "end": "1207340"
  },
  {
    "text": "purposes when you are an enterprise of a security and networking purposes or it could be data which is produced by",
    "start": "1207340",
    "end": "1212860"
  },
  {
    "text": "streams next we talked about how are you going to save this data it could be",
    "start": "1212860",
    "end": "1218350"
  },
  {
    "text": "traditional databases which you might want to utilize it could be any kind of file structure multimedia files audio",
    "start": "1218350",
    "end": "1224560"
  },
  {
    "text": "images whatnot or it could be streams that you want to save as well next we saw how and what",
    "start": "1224560",
    "end": "1231280"
  },
  {
    "text": "kind of different process is an analyte analysis you can run onto all of this data it could be streaming analysis",
    "start": "1231280",
    "end": "1237460"
  },
  {
    "text": "it could be interactive analysis or it could be some kind of machine learning as well and at the end we saw how you",
    "start": "1237460",
    "end": "1243190"
  },
  {
    "text": "can make this data consumable it could be some kind of an API or an app and service which you are exposing it could",
    "start": "1243190",
    "end": "1249280"
  },
  {
    "text": "be some kind of analysis or visualization you can do by using some traditional BI tools or using Amazon",
    "start": "1249280",
    "end": "1256300"
  },
  {
    "text": "quick site which is our native business intelligence tool and also you can do some kind of machine learning as well",
    "start": "1256300",
    "end": "1262210"
  },
  {
    "text": "using open-source software or any other software as well so it does not matter",
    "start": "1262210",
    "end": "1269860"
  },
  {
    "text": "how much data you are dealing with it does not matter what kind of volume velocity or way right you are dealing",
    "start": "1269860",
    "end": "1275560"
  },
  {
    "text": "with you can use and mix and match a bunch of these services to create your next enterprise application at scale",
    "start": "1275560",
    "end": "1282220"
  },
  {
    "text": "using AWS and now I would like to invite Anandi to talk about a few of the architectural patterns which we see in",
    "start": "1282220",
    "end": "1288730"
  },
  {
    "text": "our customer space graph known everyone",
    "start": "1288730",
    "end": "1299320"
  },
  {
    "text": "thanks gargy for introducing me so I'm going to focus on you know whatever the",
    "start": "1299320",
    "end": "1305290"
  },
  {
    "text": "god we talked about on the AWS big error services and how our customers are using",
    "start": "1305290",
    "end": "1310690"
  },
  {
    "text": "it how some of the you know mission-critical applications been using some of the architectures and best",
    "start": "1310690",
    "end": "1316330"
  },
  {
    "text": "practices not I I'm not going to color not all of them but I'm going to take some few very interesting architectural",
    "start": "1316330",
    "end": "1322990"
  },
  {
    "text": "patterns the one I wanted to talk first is the how to build an even driven batch",
    "start": "1322990",
    "end": "1328900"
  },
  {
    "text": "analytics on it obvious right typically you have an enterprise agencies they produce data from various",
    "start": "1328900",
    "end": "1335740"
  },
  {
    "text": "formats from they stolen various data sources for example you know you have traditional",
    "start": "1335740",
    "end": "1340900"
  },
  {
    "text": "day you know like on from database you have clouded our business ideas and we also store data from various",
    "start": "1340900",
    "end": "1346480"
  },
  {
    "text": "applications like log files and JSON files and whatnot they all can be ingested and processed as godly said all",
    "start": "1346480",
    "end": "1355210"
  },
  {
    "text": "this data is produced in a different speed that means that you may have to process them in a different speed as",
    "start": "1355210",
    "end": "1362770"
  },
  {
    "text": "well not all of them can go in a batch process right so how do we combine and make it kind of even driven wear your",
    "start": "1362770",
    "end": "1369520"
  },
  {
    "text": "enterprises can look for business events and then the kicker of some of the best process you know using the in our Yama",
    "start": "1369520",
    "end": "1376120"
  },
  {
    "text": "your modern our stuff we will talk about it for the even driven programming so we",
    "start": "1376120",
    "end": "1381910"
  },
  {
    "text": "have a doubly as lambda de W is lambda as you all know or if you don't know any of this lambda is I said it's allows",
    "start": "1381910",
    "end": "1388870"
  },
  {
    "text": "developers to develop a piece of code that can be executed so ever less manner meaning that so you read a piece of",
    "start": "1388870",
    "end": "1395320"
  },
  {
    "text": "course is a function ok Java function or a Python or or you know like a dotnet or nodejs so that means that what it means",
    "start": "1395320",
    "end": "1403060"
  },
  {
    "text": "the power is you have a wide variety of developers wide variety of enterprise applications is developed using",
    "start": "1403060",
    "end": "1408190"
  },
  {
    "text": "different formats and you know platform so they all can take what you are you know you will work forces so they can",
    "start": "1408190",
    "end": "1414430"
  },
  {
    "text": "kind of reuse what you have assets bring them into your data analytical platform right and typically what we say right",
    "start": "1414430",
    "end": "1421180"
  },
  {
    "text": "all of this data can be moved into an s3 and also the lambda can be kind of",
    "start": "1421180",
    "end": "1426400"
  },
  {
    "text": "integrated with the even driven fashion where s3 is s3 can you know em it a lot of different are like events for example",
    "start": "1426400",
    "end": "1433450"
  },
  {
    "text": "it can emitter event on while the file is created while the file is updated or",
    "start": "1433450",
    "end": "1438640"
  },
  {
    "text": "while it's deleted so you can imagine you know how creative you all can be to use a lambda to process some kind of you",
    "start": "1438640",
    "end": "1445660"
  },
  {
    "text": "know any any type of process you can do right for example s and renders the data comes in from various sources on s3 then",
    "start": "1445660",
    "end": "1452920"
  },
  {
    "text": "you can kick off some lambda program that can for example the staging area to kind of a pre-processing area where you",
    "start": "1452920",
    "end": "1458770"
  },
  {
    "text": "can do some kind of input validations data conversions what naadi can take he can we can run those algorithms there",
    "start": "1458770",
    "end": "1466000"
  },
  {
    "text": "and then once you have some kind of a staging area in to prepare",
    "start": "1466000",
    "end": "1471030"
  },
  {
    "text": "then he can figure out you know what kind of data analytical jobs you want to run and what fish and you want right",
    "start": "1471030",
    "end": "1477030"
  },
  {
    "text": "right how do you want to combine both for example you wanted to have some of the very heavy lifting moving to like a",
    "start": "1477030",
    "end": "1482790"
  },
  {
    "text": "traditional you know Hadoop clusters some of them can be combination of Hadoop and as well as the like lambda",
    "start": "1482790",
    "end": "1489150"
  },
  {
    "text": "right for example sm there's a pre-processing that I area the file comes in you can pick up series of",
    "start": "1489150",
    "end": "1494910"
  },
  {
    "text": "lambda functions and also because it's stateless you could also create some kind of a state management to figure out",
    "start": "1494910",
    "end": "1501000"
  },
  {
    "text": "you know what's going on with your with your processing engines by kind of of bringing in a like a storage area where",
    "start": "1501000",
    "end": "1507420"
  },
  {
    "text": "it like RDS or something we can also manage it and then once you have figured",
    "start": "1507420",
    "end": "1513030"
  },
  {
    "text": "out you wanna kick off in a heavy lifting processing using EMR your mother and I elastic MapReduce that joins the",
    "start": "1513030",
    "end": "1519960"
  },
  {
    "text": "hive and Hadoop inspire clusters and also it can do it also supports a lot a lot of open source big enough frameworks",
    "start": "1519960",
    "end": "1526860"
  },
  {
    "text": "and also finally it can all end into a red ship that's the kind of a traditional downstream data warehousing",
    "start": "1526860",
    "end": "1533880"
  },
  {
    "text": "area but it can like paths them for further analytical purpose right this is kind of a very interesting I wanted to",
    "start": "1533880",
    "end": "1539910"
  },
  {
    "text": "talk because it gives a power of cloud right the power of cloud from AWS side is the s3 flexibility and you know scale",
    "start": "1539910",
    "end": "1546930"
  },
  {
    "text": "and also its innovation about the you know omitting the events where you can you don't have it in a traditional",
    "start": "1546930",
    "end": "1552240"
  },
  {
    "text": "storage you know area and also you can use lambda that can you know reuse all your assets to bring in a very powerful",
    "start": "1552240",
    "end": "1558800"
  },
  {
    "text": "they're up they're a platform that you can create right now like a jump and also one thing is because it's stateless",
    "start": "1558800",
    "end": "1566250"
  },
  {
    "text": "I wanted to highlight this we have a double yes I am which is call identity access management that's our kind of a",
    "start": "1566250",
    "end": "1573060"
  },
  {
    "text": "cool security principle where it allows you to give user access to the data and",
    "start": "1573060",
    "end": "1578610"
  },
  {
    "text": "user access control also role based access controls on your data plus data",
    "start": "1578610",
    "end": "1583980"
  },
  {
    "text": "security and also if you look at the down it's like a cloud watch a cloud watch is a monitoring tool that can",
    "start": "1583980",
    "end": "1589770"
  },
  {
    "text": "monitor all our AWS services ask for less you can write your own custom logging you can plug into cloud was so",
    "start": "1589770",
    "end": "1596100"
  },
  {
    "text": "we can have one dashboard that goes can monitor what's going on in your platform right now let's move it in one more",
    "start": "1596100",
    "end": "1602900"
  },
  {
    "text": "interesting pattern before I go other topics is you all heard about real-time and real-time batch processing",
    "start": "1602900",
    "end": "1610230"
  },
  {
    "text": "real-time processing as well as batch analytics for example you have your data sources comes in many different formats",
    "start": "1610230",
    "end": "1616740"
  },
  {
    "text": "now the the modern data data source is called data streaming so the lord of",
    "start": "1616740",
    "end": "1622340"
  },
  {
    "text": "enterprise to start producing data in a very real-time fashion and they also figured out they wanted to process the",
    "start": "1622340",
    "end": "1629070"
  },
  {
    "text": "data in real time as well for example think of like a scenario where your enterprise is producing data like market",
    "start": "1629070",
    "end": "1636000"
  },
  {
    "text": "research data where you are collecting the data like every minute at every second and you wanted to do a couple of",
    "start": "1636000",
    "end": "1642179"
  },
  {
    "text": "things right not just a one on one type of analytics so what we are offering from aid of their side is Amazon Kinesis",
    "start": "1642179",
    "end": "1648870"
  },
  {
    "text": "Amazon Kinesis is a platform where it allows you to stream the data from many",
    "start": "1648870",
    "end": "1654179"
  },
  {
    "text": "different data sources we have the Genesis client library that you can integrate with your programming",
    "start": "1654179",
    "end": "1660090"
  },
  {
    "text": "construct so that can make that program as like a like a data producing stream",
    "start": "1660090",
    "end": "1665549"
  },
  {
    "text": "stream and then that can also call Kenya ceasefire knows the Kenna ceasefire Rose",
    "start": "1665549",
    "end": "1671160"
  },
  {
    "text": "is a server less you know highly scalable data platform where it can move",
    "start": "1671160",
    "end": "1676950"
  },
  {
    "text": "the data from one source of data data source into different data sources for example it also natively supports all of",
    "start": "1676950",
    "end": "1683940"
  },
  {
    "text": "our AWS services for example s3 or you know sqs or RDS or DynamoDB so depending",
    "start": "1683940",
    "end": "1690750"
  },
  {
    "text": "on the use case whatever you want to do we can do here I want to highlight two different things here if you look at on",
    "start": "1690750",
    "end": "1696570"
  },
  {
    "text": "the left on the left on the right side it's like traditional data sources and also the streaming data comes in they",
    "start": "1696570",
    "end": "1702870"
  },
  {
    "text": "all can be plugged into like an ASIS firehouse the Kenyan ceasefire rows can move the data into different like",
    "start": "1702870",
    "end": "1709980"
  },
  {
    "text": "destinations based on what your use cases for example if you have a use case where you want to do that on things like",
    "start": "1709980",
    "end": "1715740"
  },
  {
    "text": "a batch processing way then you can move them into an s3 bucket with like it's kind of a traditional way of doing it",
    "start": "1715740",
    "end": "1721230"
  },
  {
    "text": "then that can kick off or you know are like a Hadoop or something you can run on top of it using EMR then if you look",
    "start": "1721230",
    "end": "1728730"
  },
  {
    "text": "at the bottom side of the picture where we have the speed layer what's call it so you can do tennessee's analytics as a",
    "start": "1728730",
    "end": "1736679"
  },
  {
    "text": "platform to do the real I'm processing of the data using connexxus analytics and then again",
    "start": "1736679",
    "end": "1742649"
  },
  {
    "text": "further it can move into different set of output areas by using Tennessee's FiOS this all can happen in the bottom",
    "start": "1742649",
    "end": "1749970"
  },
  {
    "text": "line if you at the bottom layer if you look on it all of them are server less you don't maintain any of your infrastructure we make it for you also",
    "start": "1749970",
    "end": "1757379"
  },
  {
    "text": "the can Isis fighters and the kinases monell digs it's basically a it scales",
    "start": "1757379",
    "end": "1763679"
  },
  {
    "text": "by itself if you have a throughput automatically a digest it and let's try it today around whatnot and then finally",
    "start": "1763679",
    "end": "1769889"
  },
  {
    "text": "you can you can look them into any of your bi tools you know why I like Athena is one example here you can also bring",
    "start": "1769889",
    "end": "1775889"
  },
  {
    "text": "the redshift and any of your databases to pull in and then our Amazon quick side is our bi tool and then you can",
    "start": "1775889",
    "end": "1782759"
  },
  {
    "text": "plug in with any other bi tool with that that you typically use it and then I",
    "start": "1782759",
    "end": "1788190"
  },
  {
    "text": "want to move into like a kind of a traditional you know data centric you know applications like Dara barrows you",
    "start": "1788190",
    "end": "1795960"
  },
  {
    "text": "all know all the enterprises one way one form or the other you all have the data warehousing solution right from aw site",
    "start": "1795960",
    "end": "1803570"
  },
  {
    "text": "we have a redshift rich of this a peg a bike scale data warehousing solution on",
    "start": "1803570",
    "end": "1810210"
  },
  {
    "text": "AWS and here if you look at the there's a backup ID scale so if you have terabytes of there are typically stored",
    "start": "1810210",
    "end": "1816360"
  },
  {
    "text": "in data barrows that's great what happen if you have data growing ever growing",
    "start": "1816360",
    "end": "1822299"
  },
  {
    "text": "and you have like exabyte of scale data so what the red suit spectrum is is",
    "start": "1822299",
    "end": "1828210"
  },
  {
    "text": "giving is basically the power of taking the redshift which is the pakka bite scale highly parallel hardware and then",
    "start": "1828210",
    "end": "1834869"
  },
  {
    "text": "you can take advantage of yes three which is highly scalable they were growing data storage which you",
    "start": "1834869",
    "end": "1840240"
  },
  {
    "text": "can create for your applications then you combine them both wherein you write a piece of you know like you were sequel",
    "start": "1840240",
    "end": "1846090"
  },
  {
    "text": "quarries on a hundred ship that can directly go against your data storage",
    "start": "1846090",
    "end": "1853100"
  },
  {
    "text": "but here what I see in this case you know s3 is for a Hollywood data so they're acid sir and then your red shift",
    "start": "1853940",
    "end": "1861269"
  },
  {
    "text": "is where we will be using to interface to interact with the data right uh Nick and then you can use any of the BI tools",
    "start": "1861269",
    "end": "1867710"
  },
  {
    "text": "now I'm going to talk the last one of the other interesting data pattern is the data leg which is",
    "start": "1867710",
    "end": "1873960"
  },
  {
    "text": "very common and popular these days everyone wants want to talk about that a leg so in inedibly ass we have data a",
    "start": "1873960",
    "end": "1882120"
  },
  {
    "text": "concept but the center of universe it starts with the s3 and then we have a aw",
    "start": "1882120",
    "end": "1887160"
  },
  {
    "text": "I will talk about it as you stroll so you have all your data coming from you",
    "start": "1887160",
    "end": "1892650"
  },
  {
    "text": "know all kind of different data sources can land the data into an s3 bucket that's kind of a center of the universe",
    "start": "1892650",
    "end": "1898590"
  },
  {
    "text": "for your data leg and then you can use AWS globe that's a double use glue is",
    "start": "1898590",
    "end": "1904230"
  },
  {
    "text": "that kind of a cataloging tool if you look at data like what the characteristic is you need to catalogue",
    "start": "1904230",
    "end": "1909660"
  },
  {
    "text": "the data you need to search the data you need to find the data also you have to secure the data by using role based",
    "start": "1909660",
    "end": "1916140"
  },
  {
    "text": "access control right so all of them is provided by the AWS glue using aw scatter blue catalog as well as a Tobias",
    "start": "1916140",
    "end": "1922740"
  },
  {
    "text": "glue crawlers the color is so kind of it calls your data and then it creates an inline data model that can be used for",
    "start": "1922740",
    "end": "1930630"
  },
  {
    "text": "their applications field if you're looking at the Athena EMR red suit spectrum they all can access your s3",
    "start": "1930630",
    "end": "1936750"
  },
  {
    "text": "data stored in s3 by a glue so that gives you the search capability of the data coordinates the data as well as you",
    "start": "1936750",
    "end": "1943800"
  },
  {
    "text": "know like a role based access control of the data right if you look at the glue so the glue glue util also you can run",
    "start": "1943800",
    "end": "1949560"
  },
  {
    "text": "it the glue also helps you to run some kind of a batch process and managing those batch process that's happening on",
    "start": "1949560",
    "end": "1955410"
  },
  {
    "text": "top of data like right so with that I wanna introduce Darden it's dr. Nathan",
    "start": "1955410",
    "end": "1960450"
  },
  {
    "text": "nog CTO of C US Census Bureau to talk about how he's US Census is using AWS to",
    "start": "1960450",
    "end": "1967260"
  },
  {
    "text": "build data Lake on AWS thank you [Applause]",
    "start": "1967260",
    "end": "1977000"
  },
  {
    "text": "thanks Gogi and Nunda so they set the stage for me now the question is I how",
    "start": "1977000",
    "end": "1983700"
  },
  {
    "text": "many of you folks are Enterprise managers of data data centers okay a few",
    "start": "1983700",
    "end": "1991470"
  },
  {
    "text": "of you so the question is what do you do with this from an enterprise perspective need to give you a little context so I",
    "start": "1991470",
    "end": "1999809"
  },
  {
    "text": "know every one of you is aware of the census where we have been collecting and",
    "start": "1999809",
    "end": "2005000"
  },
  {
    "text": "disseminating data since World War two and we are part of the Constitution so",
    "start": "2005000",
    "end": "2010280"
  },
  {
    "text": "we are required to collect data once every ten years of the population but",
    "start": "2010280",
    "end": "2015290"
  },
  {
    "text": "besides that we do a lot of other data collection we collect about another hundred and ten hundred and fifteen",
    "start": "2015290",
    "end": "2023120"
  },
  {
    "text": "surveys besides the census which we conduct once every ten years and so we put out",
    "start": "2023120",
    "end": "2030290"
  },
  {
    "text": "different forms we have we also do work for other agencies there's a huge you",
    "start": "2030290",
    "end": "2037790"
  },
  {
    "text": "know everyone who's working with data you're saying hey there's data being collected all over the place",
    "start": "2037790",
    "end": "2042860"
  },
  {
    "text": "yes we call that administrative records because that is not the official collection that was collected somewhere",
    "start": "2042860",
    "end": "2050419"
  },
  {
    "text": "else it's considered third-party data so what are people looking for",
    "start": "2050419",
    "end": "2057320"
  },
  {
    "text": "well we produce indicators we produce population estimates and those same",
    "start": "2057320",
    "end": "2063560"
  },
  {
    "text": "estimates those indicators are used not only by the federal government to make",
    "start": "2063560",
    "end": "2068780"
  },
  {
    "text": "decisions on populations voting rights all those sort of things but they are",
    "start": "2068780",
    "end": "2074480"
  },
  {
    "text": "also being used by the private sector Walmart uses it Starbucks uses it they",
    "start": "2074480",
    "end": "2079638"
  },
  {
    "text": "are trying to figure out a way to open units okay the stock market is using our business",
    "start": "2079639",
    "end": "2086450"
  },
  {
    "text": "data we put out economic indicators a second Tuesday of every month and then",
    "start": "2086450",
    "end": "2092419"
  },
  {
    "text": "the stock market uses that data to figure out where these things are going well one of the big problems they have",
    "start": "2092419",
    "end": "2098450"
  },
  {
    "text": "is the fact that they want us to produce faster they want us to produce more data",
    "start": "2098450",
    "end": "2103609"
  },
  {
    "text": "which is higher quality which gives them more you information so that is part of the",
    "start": "2103609",
    "end": "2109819"
  },
  {
    "text": "change that is taking place from the customer standpoint so real big data is",
    "start": "2109819",
    "end": "2116960"
  },
  {
    "text": "a buzzword it's now in the market census has been in big data for a long time",
    "start": "2116960",
    "end": "2122240"
  },
  {
    "text": "we've been going after it what we are trying to do now is say ok how can we",
    "start": "2122240",
    "end": "2128240"
  },
  {
    "text": "enhance the current survey methodology how can we reduce the respondent burden",
    "start": "2128240",
    "end": "2133720"
  },
  {
    "text": "by the way how many of you fill out our every survey you get in the mail ok well",
    "start": "2133720",
    "end": "2142700"
  },
  {
    "text": "we are trying our best we are trying our best to reduce the burden on you folks",
    "start": "2142700",
    "end": "2147790"
  },
  {
    "text": "ok we are trying to optimize the data quality process that's we are trying to",
    "start": "2147790",
    "end": "2153710"
  },
  {
    "text": "figure out how can we make sure that the data quality improves as much as possible and then I mentioned about the",
    "start": "2153710",
    "end": "2160849"
  },
  {
    "text": "timeliness data if our products are old outdated data is not useful because the",
    "start": "2160849",
    "end": "2167900"
  },
  {
    "text": "world is changing fast the other part is making sure we have granularity we have",
    "start": "2167900",
    "end": "2175490"
  },
  {
    "text": "certain amount of detail and then better information for unique situations so the",
    "start": "2175490",
    "end": "2183530"
  },
  {
    "text": "problem statement so nanda and gargy presented the tools so an organization",
    "start": "2183530",
    "end": "2190609"
  },
  {
    "text": "like mine says ok what are we trying to achieve how are we trying to use these",
    "start": "2190609",
    "end": "2198190"
  },
  {
    "text": "capabilities what is going to happen for us so being a CTO I always say what is",
    "start": "2198190",
    "end": "2205880"
  },
  {
    "text": "the business problem statement and so the business problem statement is basically in four parts the middle",
    "start": "2205880",
    "end": "2213770"
  },
  {
    "text": "graphic shows you that the various forms of data we collect how frequently we",
    "start": "2213770",
    "end": "2219049"
  },
  {
    "text": "collect and every one of those data's is in a silo there is a group a project",
    "start": "2219049",
    "end": "2224630"
  },
  {
    "text": "team which is managing that particular data set they are managing the logic associated with that so what that means",
    "start": "2224630",
    "end": "2231650"
  },
  {
    "text": "is that I have decentralized data management it's not that it is bad it's",
    "start": "2231650",
    "end": "2237109"
  },
  {
    "text": "just that it is inefficient we are producing the product but if I",
    "start": "2237109",
    "end": "2242350"
  },
  {
    "text": "want to enhance the process I have to address that business process it prevents me from linking data it",
    "start": "2242350",
    "end": "2249400"
  },
  {
    "text": "prevents me from getting more analytics done the next one was the processing the",
    "start": "2249400",
    "end": "2255160"
  },
  {
    "text": "processing approach has limitations because data processing is inconsistent",
    "start": "2255160",
    "end": "2260670"
  },
  {
    "text": "so we want to process data so what gargy showed is one form of how",
    "start": "2260670",
    "end": "2266830"
  },
  {
    "text": "data is used we have our own data cycle we have a data lifecycle which matches",
    "start": "2266830",
    "end": "2272680"
  },
  {
    "text": "our survey lifecycle we need to make sure we manage that we have security",
    "start": "2272680",
    "end": "2277990"
  },
  {
    "text": "limitations believe it or not we are",
    "start": "2277990",
    "end": "2283420"
  },
  {
    "text": "legally bound and I will show you a slide of what are the different types of security that we have to operate under",
    "start": "2283420",
    "end": "2289780"
  },
  {
    "text": "and then finally technology ok we cannot",
    "start": "2289780",
    "end": "2294820"
  },
  {
    "text": "keep building individual servers individual storage arrays you cannot manage all that in our data center we",
    "start": "2294820",
    "end": "2302320"
  },
  {
    "text": "need to look for new technology that can enable the business side to produce the",
    "start": "2302320",
    "end": "2307810"
  },
  {
    "text": "products faster and better talking about",
    "start": "2307810",
    "end": "2314050"
  },
  {
    "text": "security so how many folks here in the federal government ok so you may be",
    "start": "2314050",
    "end": "2324820"
  },
  {
    "text": "aware of this the first one we cannot use any environment which is not FedRAMP",
    "start": "2324820",
    "end": "2330220"
  },
  {
    "text": "certified FedRAMP certification mean means the environment has to be on US",
    "start": "2330220",
    "end": "2335800"
  },
  {
    "text": "soil it has to be managed by US citizens it has to be certified by GSA otherwise",
    "start": "2335800",
    "end": "2342520"
  },
  {
    "text": "we cannot use it so guess what that was a form of standardization across the",
    "start": "2342520",
    "end": "2348340"
  },
  {
    "text": "entire federal government the next one is FISMA this is the federal Information",
    "start": "2348340",
    "end": "2354100"
  },
  {
    "text": "Security Act which demands that we protect all your data as citizens we",
    "start": "2354100",
    "end": "2360820"
  },
  {
    "text": "have to protect it the last one is nest which produces the",
    "start": "2360820",
    "end": "2365890"
  },
  {
    "text": "standards they produce the standards the security standards of how we are going to manage the data",
    "start": "2365890",
    "end": "2373089"
  },
  {
    "text": "okay so guess what the bottom part is the bottom part is all the customers",
    "start": "2373089",
    "end": "2378789"
  },
  {
    "text": "they have laws so right in the middle you see over the very first one census",
    "start": "2378789",
    "end": "2385089"
  },
  {
    "text": "we have a law which says title 13 if we don't manage data we are criminally",
    "start": "2385089",
    "end": "2391029"
  },
  {
    "text": "liable the employees of the agency are criminally liable so we want to protect",
    "start": "2391029",
    "end": "2397359"
  },
  {
    "text": "the employees and make sure that we don't divulge your data the next one is",
    "start": "2397359",
    "end": "2402789"
  },
  {
    "text": "Treasury IRS has its laws we take tax data and we use that as part of our",
    "start": "2402789",
    "end": "2409419"
  },
  {
    "text": "process of producing the financial information well that has to be protected for their law so we have to",
    "start": "2409419",
    "end": "2416439"
  },
  {
    "text": "apply that same law to our environment we get a lot of health data epilator",
    "start": "2416439",
    "end": "2424349"
  },
  {
    "text": "guess what there's a lot to protect that and we have to manage that we are the",
    "start": "2424349",
    "end": "2430179"
  },
  {
    "text": "stewards of that data so we have to operate that and then finally there is a",
    "start": "2430179",
    "end": "2435249"
  },
  {
    "text": "law which says all statistical organizations or Department of Labor Department of Agriculture the Bureau of",
    "start": "2435249",
    "end": "2443469"
  },
  {
    "text": "Economic Analysis all their data is with us we have to protect that also because",
    "start": "2443469",
    "end": "2449259"
  },
  {
    "text": "there's a law for that so you can see the security controls the management of",
    "start": "2449259",
    "end": "2454719"
  },
  {
    "text": "all this is pretty important and if this day and age security and privacy is key",
    "start": "2454719",
    "end": "2461189"
  },
  {
    "text": "we are doing a great job it's just that we cannot keep sustaining it in silos so",
    "start": "2461189",
    "end": "2470519"
  },
  {
    "text": "based on the platforms and the architecture patterns that was presented before the proposal and where we are",
    "start": "2470519",
    "end": "2478299"
  },
  {
    "text": "going is basically we are going to create a data like ecosystem and we are",
    "start": "2478299",
    "end": "2484929"
  },
  {
    "text": "going to use this across the board what we are trying to do is the fact that we are centralizing our capability we are",
    "start": "2484929",
    "end": "2492609"
  },
  {
    "text": "centralizing a computational environment we are providing a repository where we",
    "start": "2492609",
    "end": "2498099"
  },
  {
    "text": "will keep the data and the code we will provide data as a service on top of",
    "start": "2498099",
    "end": "2504099"
  },
  {
    "text": "infrastructure as a service and platform-as-a-service and then we will",
    "start": "2504099",
    "end": "2509229"
  },
  {
    "text": "allow analytics on top of it now the proposal here is not just to use the",
    "start": "2509229",
    "end": "2515259"
  },
  {
    "text": "Amazon tools and I don't know how many of you may have attended my previous presentation we are also wanting to use",
    "start": "2515259",
    "end": "2522400"
  },
  {
    "text": "other open source and cots products so we are planning to use SAS we are planning to use Hortonworks",
    "start": "2522400",
    "end": "2528880"
  },
  {
    "text": "we are using other products in addition to what Amazon offers so that we can deliver this and have it capable of",
    "start": "2528880",
    "end": "2536410"
  },
  {
    "text": "moving from one cloud provider to another Amazon provides great services but we want to be flexible because we",
    "start": "2536410",
    "end": "2543700"
  },
  {
    "text": "want to continue to improve census is huge on innovation we are constantly wanting to innovate and improve and then",
    "start": "2543700",
    "end": "2552339"
  },
  {
    "text": "the last part also is a Content repository with the entire thing is",
    "start": "2552339",
    "end": "2558579"
  },
  {
    "text": "bound by what we call security as a service which is not an add-on one of",
    "start": "2558579",
    "end": "2564849"
  },
  {
    "text": "the things is the fact that there is a huge push that all security comes at the very end we want to do authority to",
    "start": "2564849",
    "end": "2572859"
  },
  {
    "text": "operate we want to do FISMA certification all that is at the end and we are saying now we are bringing it",
    "start": "2572859",
    "end": "2579940"
  },
  {
    "text": "right up front we are building it into the system and we are not going to go back and try to validate you know build",
    "start": "2579940",
    "end": "2587380"
  },
  {
    "text": "it for you it is going to be built once and we are going to keep improving that security as threats continue to evolve",
    "start": "2587380",
    "end": "2595089"
  },
  {
    "text": "so the as estate is the fact that we",
    "start": "2595089",
    "end": "2602259"
  },
  {
    "text": "have today the silos the way I picture this is you know you have your",
    "start": "2602259",
    "end": "2608289"
  },
  {
    "text": "individual houses and then you become part of a community an HOA when you have",
    "start": "2608289",
    "end": "2613930"
  },
  {
    "text": "your individual houses you have to manage everything you have to manage the water supply you have to manage your own",
    "start": "2613930",
    "end": "2621099"
  },
  {
    "text": "garbage collection you have to manage you get your doors while when you then",
    "start": "2621099",
    "end": "2626950"
  },
  {
    "text": "come into the enterprise system on top of the FedRAMP which has been certified",
    "start": "2626950",
    "end": "2634390"
  },
  {
    "text": "across the federal government censors will offer standardized cloud services",
    "start": "2634390",
    "end": "2640150"
  },
  {
    "text": "we will also offer standardized data services that are targeted for us and",
    "start": "2640150",
    "end": "2645340"
  },
  {
    "text": "then the individual business entities can do their own analytics on top of",
    "start": "2645340",
    "end": "2651310"
  },
  {
    "text": "that but we will manage it all in a logical way okay we don't want people to",
    "start": "2651310",
    "end": "2658750"
  },
  {
    "text": "say oh we have to convert everything to the same data format I don't need that we will provide all sorts of data format",
    "start": "2658750",
    "end": "2666490"
  },
  {
    "text": "support and that's the whole beauty of Big Data I can do schema a treat I can",
    "start": "2666490",
    "end": "2672940"
  },
  {
    "text": "store all types of files I can convert files using different tools and I have scalability and compute",
    "start": "2672940",
    "end": "2680530"
  },
  {
    "text": "and storage also they mentioned about glue one of the key things here is the",
    "start": "2680530",
    "end": "2688150"
  },
  {
    "text": "notion of we always keep track of the data we will keep track of every",
    "start": "2688150",
    "end": "2693940"
  },
  {
    "text": "instance of the data when it has changed but we will not make copies so if there",
    "start": "2693940",
    "end": "2700150"
  },
  {
    "text": "are five groups which want to use the same data we'll load at once and will allow the five people to use it at the",
    "start": "2700150",
    "end": "2706810"
  },
  {
    "text": "same time so with that want to open it up please let us know if you have any",
    "start": "2706810",
    "end": "2715270"
  },
  {
    "text": "questions we'll be here and we can take some now or we can talk to you after the",
    "start": "2715270",
    "end": "2721180"
  },
  {
    "text": "break session [Applause]",
    "start": "2721180",
    "end": "2730589"
  }
]
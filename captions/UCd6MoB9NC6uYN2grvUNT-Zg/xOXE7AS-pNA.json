[
  {
    "text": "In this video, you’ll see how to optimize Apache \nIceberg tables with AWS Glue Data Catalog.",
    "start": "80",
    "end": "6669"
  },
  {
    "text": "With this feature, you can automate \nthe heavy lifting to keep your Apache",
    "start": "7304",
    "end": "11080"
  },
  {
    "text": "Iceberg tables optimized, resulting in reduced \nstorage costs and enhanced query performance.",
    "start": "11080",
    "end": "17240"
  },
  {
    "text": "To begin, our architecture will \nhave a Glue Data Catalog database,",
    "start": "18200",
    "end": "21955"
  },
  {
    "text": "an Amazon S3 bucket, and an AWS \nGlue job that creates and modifies sample",
    "start": "21955",
    "end": "27440"
  },
  {
    "text": "customer data in the S3 bucket \nwith a trigger every 10 minutes.",
    "start": "27440",
    "end": "31612"
  },
  {
    "text": "We’ll then enable Iceberg table \noptimizers in AWS Glue Data Catalog",
    "start": "32600",
    "end": "37199"
  },
  {
    "text": "to enable managed retention and orphan \nfile deletion for storage optimization.",
    "start": "37200",
    "end": "41535"
  },
  {
    "text": "To create the resources, we deployed a \npublicly available AWS CloudFormation ",
    "start": "43680",
    "end": "48800"
  },
  {
    "text": "template, which can be found in the blog \nincluded in the description for this video.",
    "start": "48800",
    "end": "53287"
  },
  {
    "text": "Let’s look at the stack.",
    "start": "54000",
    "end": "55372"
  },
  {
    "text": "The S3 bucket stores customer \ntable data and metadata,  ",
    "start": "56120",
    "end": "59830"
  },
  {
    "text": "which is added \ncontinuously by the AWS Glue job.",
    "start": "59831",
    "end": "63396"
  },
  {
    "text": "The Glue job role manages \nAWS IAM access to the S3 bucket.",
    "start": "64440",
    "end": "69000"
  },
  {
    "text": "The Glue job adds approximately 10,000 sample",
    "start": "70030",
    "end": "72623"
  },
  {
    "text": "customer records to the \nS3 bucket every 10 minutes.",
    "start": "72623",
    "end": "75598"
  },
  {
    "text": "A Glue trigger and a database were \nalso created in the Glue Data Catalog.",
    "start": "76600",
    "end": "80715"
  },
  {
    "text": "Let’s view the job runs in the AWS Glue Studio.",
    "start": "81760",
    "end": "84906"
  },
  {
    "text": "For demonstration purposes, \nwe’ve been running jobs for a while.",
    "start": "85880",
    "end": "89218"
  },
  {
    "text": "Let’s view the objects in our S3 bucket.",
    "start": "90000",
    "end": "92520"
  },
  {
    "text": "In the data folder, we have the Parquet \ndata files added by the Glue jobs.",
    "start": "93560",
    "end": "97805"
  },
  {
    "text": "New snapshots are created for \nevery change to the data in the table.",
    "start": "98144",
    "end": "101801"
  },
  {
    "text": "The metadata folder stores the json and avro \nfiles created with each Iceberg transaction.",
    "start": "105400",
    "end": "110688"
  },
  {
    "text": "Now, let’s view the bucket metrics.",
    "start": "111690",
    "end": "113488"
  },
  {
    "text": "The total bucket size \nhas increased by the day.",
    "start": "114475",
    "end": "117165"
  },
  {
    "text": "Though the customer \nrecords are small in size,",
    "start": "117560",
    "end": "120000"
  },
  {
    "text": "the bucket is already storing \nmore than 4 terabytes of data.",
    "start": "120000",
    "end": "123624"
  },
  {
    "text": "Similarly, the number of objects \nkept has steadily increased.",
    "start": "124604",
    "end": "128218"
  },
  {
    "text": "Next, we’ll view the table \ndetails in the AWS Glue Console.",
    "start": "129179",
    "end": "132916"
  },
  {
    "text": "The customer table is stored in the \"iceberg \nblog db\" database in Apache Iceberg format.",
    "start": "133960",
    "end": "139165"
  },
  {
    "text": "The location is our S3 bucket.",
    "start": "139490",
    "end": "141528"
  },
  {
    "text": "We can view and manage the \ntable schema from this page.",
    "start": "142529",
    "end": "145501"
  },
  {
    "text": "The schema is simple, containing \nonly column names and data types.",
    "start": "146023",
    "end": "149782"
  },
  {
    "text": "Next, let’s look at the Table optimization tab.",
    "start": "150282",
    "end": "153242"
  },
  {
    "text": "This is where we can configure the optimizers.",
    "start": "154315",
    "end": "156715"
  },
  {
    "text": "We can selectively enable optimizers to \ncompact small S3 objects into larger objects,",
    "start": "157209",
    "end": "163009"
  },
  {
    "text": "to automatically delete expired \nsnapshots and files, or to delete orphan files.",
    "start": "163009",
    "end": "168130"
  },
  {
    "text": "In this case, we’ll enable \nall the optimizers at once.",
    "start": "170021",
    "end": "173064"
  },
  {
    "text": "Notice that all three \noptimization options are selected.",
    "start": "174941",
    "end": "177972"
  },
  {
    "text": "Next, we can select our \noptimization configuration.",
    "start": "179045",
    "end": "182433"
  },
  {
    "text": "When using the default settings,",
    "start": "183435",
    "end": "185235"
  },
  {
    "text": "Data Catalog retains snapshots for 5 \ndays and retains a minimum of 1 snapshot.",
    "start": "185235",
    "end": "190332"
  },
  {
    "text": "Files associated with expired \nsnapshots will be deleted,",
    "start": "190742",
    "end": "194111"
  },
  {
    "text": "and orphan files will be deleted after 3 days.",
    "start": "194111",
    "end": "197198"
  },
  {
    "text": "For this example, we’ll customize the settings.",
    "start": "197720",
    "end": "200233"
  },
  {
    "text": "First, we’ll specify the IAM role that \nhas access to the underlying S3 table.",
    "start": "201221",
    "end": "206390"
  },
  {
    "text": "Next, we’ll specify how many days \nwe want to retain the snapshot.",
    "start": "207365",
    "end": "210837"
  },
  {
    "text": "We’ll reduce the number of days we want to \nretain the snapshot from five days to one.",
    "start": "212840",
    "end": "217157"
  },
  {
    "text": "We’ll retain one snapshot and delete \nfiles associated with expired snapshots.",
    "start": "220600",
    "end": "225098"
  },
  {
    "text": "Next, we’ll reduce the number of days to keep",
    "start": "226551",
    "end": "228861"
  },
  {
    "text": "orphan files before deleting \nthem from three days to one.",
    "start": "228861",
    "end": "232181"
  },
  {
    "text": "We’ll acknowledge the caution \nand enable optimization.",
    "start": "234920",
    "end": "238111"
  },
  {
    "text": "In order to compare our table with \nand without optimization during the",
    "start": "241200",
    "end": "244840"
  },
  {
    "text": "same time period, we set up a replica \narchitecture in a different region.",
    "start": "244840",
    "end": "249181"
  },
  {
    "text": "Here are the optimization \ndetails for the customers table.",
    "start": "250198",
    "end": "253292"
  },
  {
    "text": "We’ve been running Glue jobs and \ncan view the optimizer history.",
    "start": "253560",
    "end": "256838"
  },
  {
    "text": "Let’s view all the details for \nthe orphan file deletion history.",
    "start": "257346",
    "end": "260593"
  },
  {
    "text": "These files are no longer referenced or identified \nby Iceberg, so they are eligible for expiration.",
    "start": "261609",
    "end": "267468"
  },
  {
    "text": "Our configuration runs the \noptimizers daily to clean up these files.",
    "start": "267864",
    "end": "272046"
  },
  {
    "text": "Now, let's see what the data \nlooks like with optimization.",
    "start": "272864",
    "end": "275769"
  },
  {
    "text": "With all three optimizers enabled, the \nbucket for the same customers table  ",
    "start": "277729",
    "end": "281680"
  },
  {
    "text": "running the same job for the same duration \nis now under one terabyte in total size.",
    "start": "281680",
    "end": "287327"
  },
  {
    "text": "The size will keep increasing because \nthe job is continuously adding more data.",
    "start": "288117",
    "end": "292360"
  },
  {
    "text": "However, by compacting the data and \nremoving unnecessary and unreferenced",
    "start": "292642",
    "end": "296520"
  },
  {
    "text": "files, it can maintain a \nmuch smaller bucket size.",
    "start": "296520",
    "end": "299908"
  },
  {
    "text": "Additionally, the total number of objects are \none tenth of what we had without optimizers.",
    "start": "300887",
    "end": "306059"
  },
  {
    "text": "With this set of optimizers, \nwe can save on storage costs,",
    "start": "306849",
    "end": "310529"
  },
  {
    "text": "and improve query performance since \nthere are fewer files to query from.",
    "start": "310529",
    "end": "314522"
  },
  {
    "text": "You’ve just seen how to optimize Apache \nIceberg tables with AWS Glue Data Catalog.",
    "start": "316640",
    "end": "321690"
  },
  {
    "text": "You can learn more about this topic in\nthe description and links for this video.",
    "start": "322890",
    "end": "326737"
  },
  {
    "text": "Thanks for watching. Now it's your turn to try.",
    "start": "327584",
    "end": "330486"
  }
]
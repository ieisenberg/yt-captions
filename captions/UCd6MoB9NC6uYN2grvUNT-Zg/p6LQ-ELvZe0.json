[
  {
    "start": "0",
    "end": "300000"
  },
  {
    "text": "good afternoon thank you for being back",
    "start": "1070",
    "end": "6109"
  },
  {
    "text": "so we we now have two sessions back-to-back the first one will be more",
    "start": "6109",
    "end": "12330"
  },
  {
    "text": "focus on architectures so how to use of all those building blocks that we saw",
    "start": "12330",
    "end": "18750"
  },
  {
    "text": "before to build architectures that can solve common use cases and the second",
    "start": "18750",
    "end": "24539"
  },
  {
    "text": "one will be focused on availability and global deployments of several several s architectures across the world so",
    "start": "24539",
    "end": "31050"
  },
  {
    "text": "something that in the past we're probably in the end of a very few very large companies now anybody can do",
    "start": "31050",
    "end": "36480"
  },
  {
    "text": "global deployments with serverless without incurring huge costs so it's twice quite an interesting use case so",
    "start": "36480",
    "end": "44190"
  },
  {
    "text": "let's start with the architectures so today we will see a review together a",
    "start": "44190",
    "end": "49620"
  },
  {
    "text": "few standard architectures that we've seen our customer are using a lot especially web applications we will",
    "start": "49620",
    "end": "56100"
  },
  {
    "text": "focus on things like how to manage authentication data like this is a key trend in all enterprise data processing",
    "start": "56100",
    "end": "64338"
  },
  {
    "text": "stream processing how to manage data in almost real-time we will focus a little",
    "start": "64339",
    "end": "70439"
  },
  {
    "text": "bit also in operations automation so how to automate those IT scripts that",
    "start": "70439",
    "end": "75479"
  },
  {
    "text": "normally will we run but maybe not in a reliable environment like lambda lambda",
    "start": "75479",
    "end": "80640"
  },
  {
    "text": "can be and the final one is a little is different it's not something that we've seen where our customer is more a new",
    "start": "80640",
    "end": "87060"
  },
  {
    "text": "key trend where we're launching new products now we've seen lots of interesting graph QL to provide a",
    "start": "87060",
    "end": "93750"
  },
  {
    "text": "different way to build web api's and graph QL allows you to build real-time",
    "start": "93750",
    "end": "100220"
  },
  {
    "text": "backends that can also help you work offline so if your client is not",
    "start": "100220",
    "end": "105450"
  },
  {
    "text": "connected you can still work and then we synchronize so I will give you a little bit some details on this new key trend",
    "start": "105450",
    "end": "111780"
  },
  {
    "text": "so that's more an advanced topic but I think it's interesting to understand",
    "start": "111780",
    "end": "116909"
  },
  {
    "text": "where we are going in that area before starting just our a cup of few best",
    "start": "116909",
    "end": "122159"
  },
  {
    "text": "practices that I think is important so to reduce the the cold star so the time",
    "start": "122159",
    "end": "129000"
  },
  {
    "text": "with we it takes to invoke lambda when you first have to create a container when we scale and we have to",
    "start": "129000",
    "end": "135420"
  },
  {
    "text": "create an additional container try to think meaning to minimize the package sights the dependencies and this is",
    "start": "135420",
    "end": "141330"
  },
  {
    "text": "especially true for people coming from enterprise development backgrounds like",
    "start": "141330",
    "end": "147270"
  },
  {
    "text": "Java or C sharp where you usually add 10 megabytes just for logging with libraries now it's better to have a",
    "start": "147270",
    "end": "154110"
  },
  {
    "text": "different approach also javascript is quite affected where you saw when I installed with NPM one dependency you",
    "start": "154110",
    "end": "160590"
  },
  {
    "text": "bring half of the web with you inside the node modules also from a security",
    "start": "160590",
    "end": "165630"
  },
  {
    "text": "perspective I think minimizing dependencies is not a good approach one",
    "start": "165630",
    "end": "171780"
  },
  {
    "text": "tip that I didn't give that it's really interesting separate the logic of your application from the lambda handler so",
    "start": "171780",
    "end": "177570"
  },
  {
    "text": "you saw there was this function that was processing the event especially if you want to test locally or if you want to",
    "start": "177570",
    "end": "184170"
  },
  {
    "text": "give different interfaces that are not lambda to the logic of your application used may be the lambda handler Morris of",
    "start": "184170",
    "end": "189900"
  },
  {
    "text": "wrapper that takes the event and set it into your internal data format and then call another function that is the main",
    "start": "189900",
    "end": "196440"
  },
  {
    "text": "entry point of your business logic it's better so you separate your custom implementation from the lambda",
    "start": "196440",
    "end": "202530"
  },
  {
    "text": "integration user very mental variables for having the same function across",
    "start": "202530",
    "end": "207900"
  },
  {
    "text": "different environments and encrypt using kms the cigarettes that you put into",
    "start": "207900",
    "end": "213900"
  },
  {
    "text": "those environmental variable so that they are the creep that only inside the memory of the environment where the",
    "start": "213900",
    "end": "219270"
  },
  {
    "text": "function is executed again manage the dependencies of the function carefully",
    "start": "219270",
    "end": "225720"
  },
  {
    "text": "and we saw how the memory gives you more CPU power but memory brings also",
    "start": "225720",
    "end": "232290"
  },
  {
    "text": "normally more cost unless your CPU is really your application is really CPU bound we have a matrix that you can see",
    "start": "232290",
    "end": "238890"
  },
  {
    "text": "from cloud watch that tells you how much max memory was used by your function you",
    "start": "238890",
    "end": "244739"
  },
  {
    "text": "can also see that in the in the console so use that as a tip to understand how",
    "start": "244739",
    "end": "249900"
  },
  {
    "text": "much memory you really need because otherwise you really don't have a starting point and every customer has 75",
    "start": "249900",
    "end": "257340"
  },
  {
    "text": "gigabyte of space in every region for all your lambda code normally that's",
    "start": "257340",
    "end": "262650"
  },
  {
    "text": "more than enough but especially if you start to keep in multiple versions or you have tools",
    "start": "262650",
    "end": "267660"
  },
  {
    "text": "automatically store new version every time you generate the updater function you can run out of that space and this",
    "start": "267660",
    "end": "273240"
  },
  {
    "text": "is a hard limit so we don't increase that so there are lots of scripts now that have been created by people that",
    "start": "273240",
    "end": "279510"
  },
  {
    "text": "can have to like delete the older versions of the functions you have but keep this in your mind because if you",
    "start": "279510",
    "end": "285150"
  },
  {
    "text": "discover it today you're going introduction it may be slowing down your your your development so let's start",
    "start": "285150",
    "end": "292560"
  },
  {
    "text": "with the first pattern so web application or any microt service with",
    "start": "292560",
    "end": "297900"
  },
  {
    "text": "api with a with a with a web front-end so this is the standard architecture of",
    "start": "297900",
    "end": "303300"
  },
  {
    "start": "300000",
    "end": "300000"
  },
  {
    "text": "a server less web application on the top we have the static content like the HTML",
    "start": "303300",
    "end": "309660"
  },
  {
    "text": "the the media content images stylesheet the javascript code that is run on the",
    "start": "309660",
    "end": "316230"
  },
  {
    "text": "on the browser on the client and normally this is stored on Amazon s3 our object storage and you can use",
    "start": "316230",
    "end": "322620"
  },
  {
    "text": "CloudFront our content delivery network to further announce the speed and reduce the latency when you download the static",
    "start": "322620",
    "end": "329040"
  },
  {
    "text": "content and and below we have the dynamics part of your website so the API",
    "start": "329040",
    "end": "335130"
  },
  {
    "text": "is for example that your single page application is calling and this can be",
    "start": "335130",
    "end": "340320"
  },
  {
    "text": "implemented as we saw using the Amazon API gateway that is running one or more lambda functions in the backend and this",
    "start": "340320",
    "end": "347130"
  },
  {
    "text": "lambda function can do anything normally you will need to persist information somewhere because lambda function they",
    "start": "347130",
    "end": "353520"
  },
  {
    "text": "don't store data by themselves so you know you use a database most of the time",
    "start": "353520",
    "end": "358800"
  },
  {
    "text": "and DynamoDB can be a good choice because it's again server less by itself but you can use any database or or you",
    "start": "358800",
    "end": "367620"
  },
  {
    "text": "can use another s3 bucket for storing the information and the data of your of your customers if there's unstructured",
    "start": "367620",
    "end": "374160"
  },
  {
    "text": "data that doesn't fit a normal database to manage the authentication and",
    "start": "374160",
    "end": "380760"
  },
  {
    "text": "authorization of the users there's multiple ways to do that what I suggest",
    "start": "380760",
    "end": "386460"
  },
  {
    "text": "is ever look at Hamid's incognito especially Cognito user pools is the easiest way that we develop over the",
    "start": "386460",
    "end": "392669"
  },
  {
    "text": "year and it's very well integrated now with other technologies so this is an",
    "start": "392669",
    "end": "398130"
  },
  {
    "text": "architecture that is really popular we have a lot of customers just to give you an example this is Buster it's is an obtain an",
    "start": "398130",
    "end": "405540"
  },
  {
    "text": "entertainment and lifestyle website targeting women it is content and they",
    "start": "405540",
    "end": "411870"
  },
  {
    "text": "basically reduce their costs by eighty four percent when they switched from the",
    "start": "411870",
    "end": "417120"
  },
  {
    "text": "traditional architecture to a server less approach with a similar architecture to what we saw and now they",
    "start": "417120",
    "end": "422610"
  },
  {
    "text": "feel that their engineers are really focusing on building innovation on in keeping the things and the lights on in",
    "start": "422610",
    "end": "429030"
  },
  {
    "text": "the in their infrastructure so how can we secure this architecture so starting",
    "start": "429030",
    "end": "434639"
  },
  {
    "start": "431000",
    "end": "431000"
  },
  {
    "text": "from the top on s3 buckets you can",
    "start": "434639",
    "end": "439860"
  },
  {
    "text": "create bucket policies that are policies similar to the policies that you give to a lambda function where you can define",
    "start": "439860",
    "end": "445560"
  },
  {
    "text": "who can have access to this the content of these buckets it can be very glad",
    "start": "445560",
    "end": "451560"
  },
  {
    "text": "granular so you can say this prefix is public disorder prefix is prefix is like",
    "start": "451560",
    "end": "456690"
  },
  {
    "text": "the directory is private and so on you can also define object level access",
    "start": "456690",
    "end": "462900"
  },
  {
    "text": "control list so a single object can be public private or can give you given access to a subset of other users be",
    "start": "462900",
    "end": "469740"
  },
  {
    "text": "careful because it's easy to make mistakes that's why we have lots of tools like Macy that can help you",
    "start": "469740",
    "end": "475050"
  },
  {
    "text": "monitor if you make a bucket public and also if you have something in your",
    "start": "475050",
    "end": "480990"
  },
  {
    "text": "bucket that is public we now integrated that also in the console so now the console visually tells you if this bucket has some public",
    "start": "480990",
    "end": "488220"
  },
  {
    "text": "content or not if you need to have public information and private information since buckets they don't",
    "start": "488220",
    "end": "494280"
  },
  {
    "text": "cost you pay only for the storage my suggestion is used two buckets one that does private content and one public so",
    "start": "494280",
    "end": "500760"
  },
  {
    "text": "that you avoid any possible human error in giving permissions you can avoid",
    "start": "500760",
    "end": "507270"
  },
  {
    "text": "giving access from outside to Amazon s3 completely because you can use origin",
    "start": "507270",
    "end": "512640"
  },
  {
    "text": "access identity it's a way to link accounts of distribution with Anna's three bucket in this way only cloud from",
    "start": "512640",
    "end": "518760"
  },
  {
    "text": "the content delivery network can read from or write from in this case I read",
    "start": "518760",
    "end": "524279"
  },
  {
    "text": "from Amazon s3 so that's a very good way is interpreted in a console and so this way you can have a private s3 bucket",
    "start": "524279",
    "end": "531959"
  },
  {
    "text": "that contains maybe the static component of your app web application and then CloudFront is doing the public distribution of the",
    "start": "531959",
    "end": "538410"
  },
  {
    "text": "content conference has lots of fine grained control that you can add so it implements jail restriction jail",
    "start": "538410",
    "end": "545490"
  },
  {
    "text": "restriction lightly the screen continued to work I don't have someone shut the",
    "start": "545490",
    "end": "551100"
  },
  {
    "text": "lights okay thanks so Joe restriction is normally used more",
    "start": "551100",
    "end": "556260"
  },
  {
    "text": "for licensing most of the time when you use a CDN you want to distribute content",
    "start": "556260",
    "end": "561510"
  },
  {
    "text": "that are some sort of licenses like media content so with G restriction you can say this content can be seen only in",
    "start": "561510",
    "end": "568140"
  },
  {
    "text": "these countries and we will check that the IP address is coming from one of those countries its feature then you can",
    "start": "568140",
    "end": "575310"
  },
  {
    "text": "sign content so you can give access to content only if it's signed with cookies or with specific URL that contain a sync",
    "start": "575310",
    "end": "582750"
  },
  {
    "text": "contain a signature so you can have private content that is shared only under those circumstances and you can",
    "start": "582750",
    "end": "588960"
  },
  {
    "text": "manage the signature for example with the API gateway that can generate the signature and give it back to the",
    "start": "588960",
    "end": "594510"
  },
  {
    "text": "application so that then you have a sign link that gives you access to private",
    "start": "594510",
    "end": "599730"
  },
  {
    "text": "content and as I already said before you cannot speak it also will transparently manage DDoS protection so you you don't",
    "start": "599730",
    "end": "606120"
  },
  {
    "text": "have any network connection with cloud from there it will be the viewer front end and it can absorb or block DDoS",
    "start": "606120",
    "end": "613860"
  },
  {
    "text": "attacks in multiple ways on the dynamic side usually you protect your database",
    "start": "613860",
    "end": "620520"
  },
  {
    "text": "if you use it DynamoDB in your lambda function using identity and access management roles as we saw today so you",
    "start": "620520",
    "end": "626940"
  },
  {
    "text": "have a role that tells what the lambda function can do and a role that tells who can call the lambda function so two",
    "start": "626940",
    "end": "633720"
  },
  {
    "text": "different roles and the Amazon API gateway is quite integrated for security",
    "start": "633720",
    "end": "639180"
  },
  {
    "text": "we will see that for authentication but generally you can check throttling caching of content it implements usage",
    "start": "639180",
    "end": "646590"
  },
  {
    "text": "plants so that you can give different usage plants to different tiers of customers that have different wrote link",
    "start": "646590",
    "end": "653310"
  },
  {
    "text": "and it's also integrated with our with the Amazon a certificate manager so you can deploy your own certificate",
    "start": "653310",
    "end": "659580"
  },
  {
    "text": "certificate for HTTP HTTPS so that you can use custom domains instead of those",
    "start": "659580",
    "end": "665370"
  },
  {
    "text": "hugly randomly generated domains you can use let's encrypt if you",
    "start": "665370",
    "end": "671490"
  },
  {
    "text": "want but it's completely integrated out of the box with our certificate manager",
    "start": "671490",
    "end": "676800"
  },
  {
    "text": "and we generate certificates for free so you don't pay anything and we also manage automatically the renewal of",
    "start": "676800",
    "end": "682020"
  },
  {
    "text": "certificates so that even if you forget we will automatically and transparently renew the HTTPS the SSL certificate for",
    "start": "682020",
    "end": "689370"
  },
  {
    "text": "you so there's no cost and and now you can the first version of a cm you should",
    "start": "689370",
    "end": "694980"
  },
  {
    "text": "like validate via email the new certificate now you can use the classical DNS validation of new",
    "start": "694980",
    "end": "700950"
  },
  {
    "text": "certificates so it's can be automated even if you have large lots of domains to manage you don't need to have emails",
    "start": "700950",
    "end": "707310"
  },
  {
    "text": "for the automatic renewal of the certificates for authentication and",
    "start": "707310",
    "end": "714060"
  },
  {
    "text": "authorization you can use kognito that can enter into the identity of the users",
    "start": "714060",
    "end": "720120"
  },
  {
    "text": "and give access to all or part of the api's of the Amazon API gateway so there",
    "start": "720120",
    "end": "727350"
  },
  {
    "start": "724000",
    "end": "724000"
  },
  {
    "text": "are different ways to do that so you can use I am but the way I would suggest is to use a custom authorizers and there",
    "start": "727350",
    "end": "734310"
  },
  {
    "text": "are two ways to use a custom authorizer one is the Credo user pool that we will",
    "start": "734310",
    "end": "740190"
  },
  {
    "text": "see later and one is to use the lambda function so the lambda function is a nice trick basically what you're saying",
    "start": "740190",
    "end": "746820"
  },
  {
    "text": "to the API gateway is I create a custom lambda function that you can write with",
    "start": "746820",
    "end": "751980"
  },
  {
    "text": "whatever code you want and this lambda function will check the authentication against any possible authentication",
    "start": "751980",
    "end": "758610"
  },
  {
    "text": "service that you want to use because it you can manage the integration and the customer Teresa can work in two ways",
    "start": "758610",
    "end": "764730"
  },
  {
    "text": "either with a token so token means that there is a token that is passed in the",
    "start": "764730",
    "end": "769980"
  },
  {
    "text": "header and this token is what the lambda function receives and you can use only the information in this token to decide",
    "start": "769980",
    "end": "775770"
  },
  {
    "text": "if this user is authenticated and who is this user or we more recently added the",
    "start": "775770",
    "end": "780930"
  },
  {
    "text": "full request access so now the lambda function can have access to all the payload of the HTTP request and",
    "start": "780930",
    "end": "786270"
  },
  {
    "text": "understand who is this user and if he has access or not to to my resources so",
    "start": "786270",
    "end": "792600"
  },
  {
    "text": "this is something that it's custom-built by you but it's completely flexible and the lambda function is not invoked for",
    "start": "792600",
    "end": "798330"
  },
  {
    "text": "every interaction so you can define like a time limit so if I a user you can say for some minutes or",
    "start": "798330",
    "end": "804660"
  },
  {
    "text": "hours is still authenticated with the permission that I give and then there's",
    "start": "804660",
    "end": "809700"
  },
  {
    "text": "and with the customer eraser you can also set context specific information that will be passed to the lambda",
    "start": "809700",
    "end": "815580"
  },
  {
    "text": "function so basically you can set information like the role or the security level of the person and this",
    "start": "815580",
    "end": "821880"
  },
  {
    "text": "information will be passed to the lambda function so that you have more cost context information on who is the person",
    "start": "821880",
    "end": "826980"
  },
  {
    "text": "accessing this API that customer ID is also integrated with need a user pool",
    "start": "826980",
    "end": "832470"
  },
  {
    "text": "some time ago it was basically we were automatically generating the lambda function for you but now it's completely",
    "start": "832470",
    "end": "839100"
  },
  {
    "text": "transparent so if you enable you you just can use Coconino user pool with users it's a user directory that you can",
    "start": "839100",
    "end": "845580"
  },
  {
    "text": "that we manage for you including the login password page so basically you",
    "start": "845580",
    "end": "851400"
  },
  {
    "text": "have a person you have a link where you can go and do the web authentication you can customize the login page if you want",
    "start": "851400",
    "end": "857030"
  },
  {
    "text": "so it's completely transparent there this is an overview all the possible",
    "start": "857030",
    "end": "862380"
  },
  {
    "start": "858000",
    "end": "858000"
  },
  {
    "text": "options so basically concrete or identity pool that it's the first features that we",
    "start": "862380",
    "end": "868890"
  },
  {
    "text": "lunch with kognito a few years ago usually works trusting a web identity provider such as",
    "start": "868890",
    "end": "874530"
  },
  {
    "text": "Facebook Twitter Amazon users open ID connect such as Salesforce for example",
    "start": "874530",
    "end": "883110"
  },
  {
    "text": "Google accounts so you can basically in this way you do the authentication using",
    "start": "883110",
    "end": "888750"
  },
  {
    "text": "the SDK on the third party like Facebook or Twitter and then you use the token",
    "start": "888750",
    "end": "893850"
  },
  {
    "text": "that they give to you you give the token to kokanee to--if Cognito is configured to trust that identity if will trust",
    "start": "893850",
    "end": "900450"
  },
  {
    "text": "them and you have facebook authentication very easy to implement or you can create your own user directory",
    "start": "900450",
    "end": "906300"
  },
  {
    "text": "weak agree the user pool and this user directory can work together with web identity so basically you can have users",
    "start": "906300",
    "end": "912900"
  },
  {
    "text": "from Facebook or users with your own users together or can go the direct route using the custom of eliezer with",
    "start": "912900",
    "end": "919730"
  },
  {
    "text": "with the API gateway I know there are different options but authentication is",
    "start": "919730",
    "end": "925170"
  },
  {
    "text": "something where every customer wants to do things differently so we implemented a lots of possibilities the default if",
    "start": "925170",
    "end": "931140"
  },
  {
    "text": "you start from scratch use Cognito user pool and go straight to the activity to the API gateway with the custom nicer for the user poor and this is just",
    "start": "931140",
    "end": "940650"
  },
  {
    "text": "a summary so in this way you can really find him so the web the web identity",
    "start": "940650",
    "end": "945720"
  },
  {
    "text": "provider that gives access to are also examples the user here can have access only to specific API if he comes from",
    "start": "945720",
    "end": "953460"
  },
  {
    "text": "cabrito user pool you can give access to other api and a different one is it comes from the directly from the user",
    "start": "953460",
    "end": "959670"
  },
  {
    "text": "pool now the as I mentioned before the API gateway that was only H optimized so",
    "start": "959670",
    "end": "966750"
  },
  {
    "start": "960000",
    "end": "960000"
  },
  {
    "text": "before this released a few months ago all api's were automatically distributed",
    "start": "966750",
    "end": "973050"
  },
  {
    "text": "to CloudFront through our content delivery network now you can create a regional level api's that run inside any",
    "start": "973050",
    "end": "980070"
  },
  {
    "text": "SS region and among other things this allows you to do interesting things with",
    "start": "980070",
    "end": "985800"
  },
  {
    "text": "the dns because if you want to control we will use this one we will build in",
    "start": "985800",
    "end": "991110"
  },
  {
    "text": "the next session the the globally distributed application your api as an",
    "start": "991110",
    "end": "997290"
  },
  {
    "text": "HTTP domain and this httpd domain must match the domain that people is using",
    "start": "997290",
    "end": "1004190"
  },
  {
    "text": "through the dns and the certificate that is inside the api gateway so if you want",
    "start": "1004190",
    "end": "1011120"
  },
  {
    "text": "everything to work correctly with your api and don't get those errors with the security on the browser with regional",
    "start": "1011120",
    "end": "1017570"
  },
  {
    "text": "level you can deploy the same certificate in multiple regions and then do load balancing for example from",
    "start": "1017570",
    "end": "1022670"
  },
  {
    "text": "outside this kind of things were simply not possible before because the certificate was at content delivery in",
    "start": "1022670",
    "end": "1028910"
  },
  {
    "text": "the content delivery distribution networks outside of the region and basically you couldn't control direct",
    "start": "1028910",
    "end": "1036890"
  },
  {
    "text": "access to for example my API in Europe versus my API in the US there's quite a",
    "start": "1036890",
    "end": "1045290"
  },
  {
    "text": "few frameworks that can help you if you want to start from from from scratch",
    "start": "1045290",
    "end": "1050800"
  },
  {
    "text": "those are the frameworks open source that we support as AWS because we",
    "start": "1050800",
    "end": "1056270"
  },
  {
    "text": "developed there are tones that are not here like the 7s framework for example",
    "start": "1056270",
    "end": "1061520"
  },
  {
    "text": "so Challis is very good if you come from if you develop in Python with tools like",
    "start": "1061520",
    "end": "1067790"
  },
  {
    "text": "flask or bottle so you we have the same syntax and there's also a couple of open-source projects that do",
    "start": "1067790",
    "end": "1074540"
  },
  {
    "text": "similar things and they are very good Zappa and Claudia Jas last time I was in",
    "start": "1074540",
    "end": "1080000"
  },
  {
    "text": "a conference a guy was doing his wedding and he built his wedding web site using",
    "start": "1080000",
    "end": "1085370"
  },
  {
    "text": "Django that runs on Python and since if you're not very popular your wedding",
    "start": "1085370",
    "end": "1091370"
  },
  {
    "text": "website doesn't really get so many hits it just uses app' to wrap everything and deploy it using a lambda function and",
    "start": "1091370",
    "end": "1098030"
  },
  {
    "text": "with zero cost because it was in the feed here he managed this wedding wedding website so nice story the",
    "start": "1098030",
    "end": "1106700"
  },
  {
    "text": "simplest Express framework helps you take node.js Express application and wrap it inside a",
    "start": "1106700",
    "end": "1113840"
  },
  {
    "text": "lambda function so with almost no change in your code almost because you can fine",
    "start": "1113840",
    "end": "1119660"
  },
  {
    "text": "tune something if you want to get the context from the API gateway but normally you don't need it you can really create take an unexpressed",
    "start": "1119660",
    "end": "1126140"
  },
  {
    "text": "application wrap it and run and have it all running inside the single lambda function so it's not very granular but",
    "start": "1126140",
    "end": "1132410"
  },
  {
    "text": "it works and similarly we have for Java so if you have servlets or spring",
    "start": "1132410",
    "end": "1140260"
  },
  {
    "text": "application in Java we can wrap them and have them run inside inside a lambda",
    "start": "1140260",
    "end": "1145550"
  },
  {
    "text": "function with these tools second pattern the data like so this is something we've",
    "start": "1145550",
    "end": "1151970"
  },
  {
    "text": "seen lots of interest so in the past building that analytics for companies",
    "start": "1151970",
    "end": "1158870"
  },
  {
    "text": "especially for enterprises was basically using an enterprise data warehouse where",
    "start": "1158870",
    "end": "1164030"
  },
  {
    "text": "you collect your data your graduate and you store in our analytical large database that is as a sort of relational",
    "start": "1164030",
    "end": "1171320"
  },
  {
    "text": "interface but normal internally works differently from traditional relational databases now we've seen there's lots of",
    "start": "1171320",
    "end": "1177740"
  },
  {
    "text": "interest in keeping more data simply because storage costs are very low think",
    "start": "1177740",
    "end": "1182960"
  },
  {
    "text": "of s3 with the left cycle you can store anything all the logs of your application all the phone calls that",
    "start": "1182960",
    "end": "1189860"
  },
  {
    "text": "your support receives all the picture that you take may be inside your shop to",
    "start": "1189860",
    "end": "1196220"
  },
  {
    "text": "understand if people is smiling or crying in a specific site of your retail space so you can keep this",
    "start": "1196220",
    "end": "1202320"
  },
  {
    "text": "information is not normal data anymore so the idea is that you want a place",
    "start": "1202320",
    "end": "1208260"
  },
  {
    "text": "where you can store any kind of data structure and data and completely unstructured data like images you want",
    "start": "1208260",
    "end": "1215640"
  },
  {
    "text": "to be able to run classical bi or even advanced AI machine learning algorithm",
    "start": "1215640",
    "end": "1222630"
  },
  {
    "text": "top of this data you want to have a very fast ingestion because here you have big volumes you want to have something like",
    "start": "1222630",
    "end": "1229710"
  },
  {
    "text": "schema read so since you are very flexible in the data that is put here you want to have some features like if I",
    "start": "1229710",
    "end": "1235350"
  },
  {
    "text": "want to read the data there should be some API that gives me the scheme of this data dynamically so that I don't have to put the schema inside my",
    "start": "1235350",
    "end": "1241470"
  },
  {
    "text": "application I can create something that discovers the kind of data this is a picture this is a record with this",
    "start": "1241470",
    "end": "1247590"
  },
  {
    "text": "structure is JSON escheat CSV this is normally complementary to the",
    "start": "1247590",
    "end": "1253140"
  },
  {
    "text": "traditional enterprise data warehouse that we've seen built over the years with company and another approach at",
    "start": "1253140",
    "end": "1259260"
  },
  {
    "text": "architectural level since you have lots of data and sometimes you run lots of computation but then sometimes you just",
    "start": "1259260",
    "end": "1265440"
  },
  {
    "text": "keep the data you want to decouple compute and storage in this architecture you want to store lots to date and then",
    "start": "1265440",
    "end": "1270690"
  },
  {
    "text": "sometimes you want to run some analytics and then you need tons of computing for a few hours or a few days and then you",
    "start": "1270690",
    "end": "1276660"
  },
  {
    "text": "release this computing so those two components should be the couplet so we see as the build main building block for",
    "start": "1276660",
    "end": "1283350"
  },
  {
    "text": "this kind of architecture Amazon s3 the object storage you can use lots of",
    "start": "1283350",
    "end": "1290010"
  },
  {
    "text": "different tools but specifically the Kinesis platform to manage the injection so to collect that and store data here",
    "start": "1290010",
    "end": "1296700"
  },
  {
    "text": "so we have streams firehose more recently we also launched kinases video that can help stream video data not to",
    "start": "1296700",
    "end": "1304740"
  },
  {
    "text": "a3 but to be processed in that case you can build a catalog using building",
    "start": "1304740",
    "end": "1310590"
  },
  {
    "text": "blocks like dynamo DB and elasticsearch the Amazon Elastic search service can be",
    "start": "1310590",
    "end": "1316410"
  },
  {
    "text": "the two main building blocks were dynamodb stores the information and elasticsearch provides you the",
    "start": "1316410",
    "end": "1322650"
  },
  {
    "text": "possibility to search for content that is stored and glue AWS glue is a service",
    "start": "1322650",
    "end": "1328710"
  },
  {
    "text": "that does lots of things it can how to discover the data formats you're using and Cameron",
    "start": "1328710",
    "end": "1333920"
  },
  {
    "text": "data pipelines so takes data from some sources process this data and then",
    "start": "1333920",
    "end": "1338930"
  },
  {
    "text": "stores the data in other components for analytics and processing we you can use",
    "start": "1338930",
    "end": "1345230"
  },
  {
    "text": "of course lambda on top of s3 when you store something on this tree you can trigger a lambda function that can be doing this processing or can start as a",
    "start": "1345230",
    "end": "1353810"
  },
  {
    "text": "processing processing of the data we have Amazon attina that you can use to run sequel query on a stream straight",
    "start": "1353810",
    "end": "1360830"
  },
  {
    "text": "without having any in any database so if we support a few formats and you can just run your queries quick site is a",
    "start": "1360830",
    "end": "1367820"
  },
  {
    "text": "business intelligence visualization tool that runs normally on top of a tina or",
    "start": "1367820",
    "end": "1373430"
  },
  {
    "text": "on top of most relational databases glue of already as I said can also process",
    "start": "1373430",
    "end": "1380360"
  },
  {
    "text": "the data and redshift edges spectrum are our own analytical databases that you",
    "start": "1380360",
    "end": "1385460"
  },
  {
    "text": "can use to run queries so red suit spectrum allows you to keep data inside redshift that is another columnar",
    "start": "1385460",
    "end": "1392870"
  },
  {
    "text": "analytical data base and also run queries with data that is honest tree so you can join data that is inside",
    "start": "1392870",
    "end": "1398780"
  },
  {
    "text": "redshift the database with data that is kept honest tree in the same query for",
    "start": "1398780",
    "end": "1406040"
  },
  {
    "text": "security and auditing of course you can protect everything with the usual permission so I am you can encrypt",
    "start": "1406040",
    "end": "1412640"
  },
  {
    "text": "anything honest tree with the key management service and you can also",
    "start": "1412640",
    "end": "1419360"
  },
  {
    "text": "audit who is accessing the data also who is reading the data using cloud trail",
    "start": "1419360",
    "end": "1424790"
  },
  {
    "text": "usually this is very important for compliance knowing who is has access to your data and we also have a service that is",
    "start": "1424790",
    "end": "1431510"
  },
  {
    "text": "called Amazon may see this is a mushroom learning service that will automatically analyze your data on s3 and classify the",
    "start": "1431510",
    "end": "1437900"
  },
  {
    "text": "data to see if there's some personal identification data so that it will",
    "start": "1437900",
    "end": "1443450"
  },
  {
    "text": "automatically tell you the kind and the security of the data that you have on s3 and it can also check other access to",
    "start": "1443450",
    "end": "1450680"
  },
  {
    "text": "the to your account for example when I enabled it I was on holidays in Italy I created an account and account created",
    "start": "1450680",
    "end": "1457790"
  },
  {
    "text": "from account really different from your usual country it just pop up in the console so I'm Adam as you can really",
    "start": "1457790",
    "end": "1463190"
  },
  {
    "text": "check your data and the activities on your data to see if there's something different than usual that pops out for a",
    "start": "1463190",
    "end": "1472030"
  },
  {
    "text": "building and interface to a data Lake so normally the user of a data Lake are not technical user you need to provide an",
    "start": "1472030",
    "end": "1478059"
  },
  {
    "text": "interface you can very easily build something with the API gateway in lambda a traditional web application that can",
    "start": "1478059",
    "end": "1484600"
  },
  {
    "text": "help you understand and use the data and your data Lake so s3 is the foundation",
    "start": "1484600",
    "end": "1489850"
  },
  {
    "start": "1487000",
    "end": "1487000"
  },
  {
    "text": "for multiple reasons so with a string you can store data without any limits I",
    "start": "1489850",
    "end": "1495480"
  },
  {
    "text": "think do you know who has never used s3 here so very little people so it's very",
    "start": "1495480",
    "end": "1502870"
  },
  {
    "text": "flexible you don't have limits in the number of objects you store that the sides of the object up to each object up",
    "start": "1502870",
    "end": "1508150"
  },
  {
    "text": "to 5 terabytes the bandwidth scales with the data so the more data you have the more bandwidth you have to analyze the",
    "start": "1508150",
    "end": "1514210"
  },
  {
    "text": "data we also implemented different storage classes and we can automatically move data across different storage",
    "start": "1514210",
    "end": "1520330"
  },
  {
    "text": "classes to chip to make it cheaper for you we implement versioning so you can store",
    "start": "1520330",
    "end": "1525820"
  },
  {
    "text": "multiple version of a single object and transparent encryption if you want new",
    "start": "1525820",
    "end": "1531370"
  },
  {
    "text": "features that we launched are claw trail data events so if you have sensitive",
    "start": "1531370",
    "end": "1536650"
  },
  {
    "text": "data you can have an auditing blog that tells you who has access and when to the data you have in specific s3 buckets",
    "start": "1536650",
    "end": "1543610"
  },
  {
    "text": "this is very important for compliance we have two features that we launched last",
    "start": "1543610",
    "end": "1549100"
  },
  {
    "text": "year but we're not so famous I think but very useful s3 Analytics will automatically assess how you use the",
    "start": "1549100",
    "end": "1556570"
  },
  {
    "text": "data on your s3 buckets and tell you if you should change your your storage",
    "start": "1556570",
    "end": "1563679"
  },
  {
    "text": "class to reduce your cost so maybe you take something online but you actually don't use it so much AWS config can also",
    "start": "1563679",
    "end": "1571570"
  },
  {
    "text": "implement automated checks for example if someone is changing the permission of an s3 bucket to give public access at",
    "start": "1571570",
    "end": "1578200"
  },
  {
    "text": "the breasts config can enforce a rule that will block this and notify the administrator that someone was trying to",
    "start": "1578200",
    "end": "1584200"
  },
  {
    "text": "make public a private bucket you can tag objects any file on s3 so adding",
    "start": "1584200",
    "end": "1590860"
  },
  {
    "text": "metadata for a data like usually is good and more recently for s3 and glaciers",
    "start": "1590860",
    "end": "1596860"
  },
  {
    "text": "it's our cold storage we launched a feature that is called select so now that means that the storage can",
    "start": "1596860",
    "end": "1603200"
  },
  {
    "text": "natively run select queries on the data and this is in these scales with s3 so",
    "start": "1603200",
    "end": "1608690"
  },
  {
    "text": "if you run unless I select on s3 it will be automatically distributed to all the compute nodes that s3 used so you can",
    "start": "1608690",
    "end": "1614809"
  },
  {
    "text": "really do interesting things here this is a standard architectural pattern that",
    "start": "1614809",
    "end": "1620570"
  },
  {
    "start": "1617000",
    "end": "1617000"
  },
  {
    "text": "we've seen a lot for analytics and it's using dynamo DB and elasticsearch",
    "start": "1620570",
    "end": "1626059"
  },
  {
    "text": "together so dynamodb gives you very high throughput query possibilities so if you",
    "start": "1626059",
    "end": "1632210"
  },
  {
    "text": "index data you can retrieve information by by key very quickly it asks some",
    "start": "1632210",
    "end": "1638389"
  },
  {
    "text": "indexing but it's not a search database so the idea here is that when you store data on s3 you can use you trigger a",
    "start": "1638389",
    "end": "1645980"
  },
  {
    "text": "lambda function that will index the most important meta data by key on DynamoDB",
    "start": "1645980",
    "end": "1652460"
  },
  {
    "text": "and this can also trigger another lambda function straight from s3 or from the",
    "start": "1652460",
    "end": "1657590"
  },
  {
    "text": "update to dynamo DB that will take this metadata information and store it on elasticsearch so that now you can search",
    "start": "1657590",
    "end": "1665360"
  },
  {
    "text": "for this data in any way you want and this lambda function will keep every metadata at the distortion animal to be",
    "start": "1665360",
    "end": "1671720"
  },
  {
    "text": "searchable on elasticsearch so you synchronize the two repository and you",
    "start": "1671720",
    "end": "1677090"
  },
  {
    "text": "can use both so know if you have high throughput data processing that needs to collect information by keyword you go on",
    "start": "1677090",
    "end": "1683899"
  },
  {
    "text": "dynamodb if you need to search all the files that mention a certain keyword you",
    "start": "1683899",
    "end": "1689210"
  },
  {
    "text": "can search that on Aleksey search and then get more information going back to",
    "start": "1689210",
    "end": "1694850"
  },
  {
    "text": "dynamodb so it's it's quite a pattern that we see having these two things",
    "start": "1694850",
    "end": "1700159"
  },
  {
    "text": "synchronize and we have our default lambda function to do that so you can you know need to write this lambda",
    "start": "1700159",
    "end": "1705499"
  },
  {
    "text": "function you can find it in the console I think we set up automatically if you want this is another example of how you",
    "start": "1705499",
    "end": "1716509"
  },
  {
    "text": "can use AWS glue so a double X blue is another service we launched it last year notice reinvent the previous one and it",
    "start": "1716509",
    "end": "1723619"
  },
  {
    "text": "does multiple things one things that it does is it has crawlers that can automatically look for the data you have",
    "start": "1723619",
    "end": "1730100"
  },
  {
    "text": "on s3 and then understand what kind of day and the structure of the data and create a data catalog that is compatible with",
    "start": "1730100",
    "end": "1737669"
  },
  {
    "text": "hive the open source project and this is the same standard that is used by Athena and redshift spectrum that means that",
    "start": "1737669",
    "end": "1744960"
  },
  {
    "text": "you put the data there it can be CSV Park a file lots of different formats",
    "start": "1744960",
    "end": "1750029"
  },
  {
    "text": "and this will be automatically discoverable by Athena or redshift spectrum to run queries on top so if you",
    "start": "1750029",
    "end": "1756179"
  },
  {
    "text": "want to run queries only on the data on s3 you can use a tina if you want to do a join between what's inside redshift",
    "start": "1756179",
    "end": "1762240"
  },
  {
    "text": "with data industry you can use redshift spectrum and in both cases you can use",
    "start": "1762240",
    "end": "1767250"
  },
  {
    "text": "quick side to have a graphical user interface that can help you navigate the",
    "start": "1767250",
    "end": "1772890"
  },
  {
    "text": "data I understand what's happening for analytic and processing you can use",
    "start": "1772890",
    "end": "1778919"
  },
  {
    "text": "again the tools that we saw I just want to add to the loop Amazon Elastic",
    "start": "1778919",
    "end": "1784080"
  },
  {
    "text": "MapReduce EMR so lots of people use spark or a dupe and those tools are",
    "start": "1784080",
    "end": "1789240"
  },
  {
    "text": "fully managed within EMR so they usually are very well integrated with kinases or h3 for data processing this is an",
    "start": "1789240",
    "end": "1797460"
  },
  {
    "text": "example of how you can run a Tina honest tree so in this case we run this query",
    "start": "1797460",
    "end": "1802710"
  },
  {
    "text": "it's on a standard database of ngrams of how you use words in documents and it's",
    "start": "1802710",
    "end": "1810390"
  },
  {
    "text": "processing 170 gigabyte of data you get the results in 44 or 45 seconds and",
    "start": "1810390",
    "end": "1817799"
  },
  {
    "text": "since with that ena you pay it only for the data you process in this case you",
    "start": "1817799",
    "end": "1822870"
  },
  {
    "text": "pay 85 cents for this query that it's processing all this information at ena",
    "start": "1822870",
    "end": "1829380"
  },
  {
    "text": "actually as I said you pay by the data you process when you run a query so instead of giving raw data you can",
    "start": "1829380",
    "end": "1835500"
  },
  {
    "text": "optimize the data so if you use partitioning so if you store that on this tree with this format so you use",
    "start": "1835500",
    "end": "1841590"
  },
  {
    "text": "folders where you have variable type equal value so you can have for example",
    "start": "1841590",
    "end": "1846899"
  },
  {
    "text": "years months and days if you store by date you can have any keywords depending",
    "start": "1846899",
    "end": "1852240"
  },
  {
    "text": "on your data this will be automatically used by Athena in the queries so instead",
    "start": "1852240",
    "end": "1857279"
  },
  {
    "text": "of processing 117 gigabyte you only process the folders where the data is so you put our clothes",
    "start": "1857279",
    "end": "1865320"
  },
  {
    "text": "where the Mount is January only the folders with month January will be processed you can also",
    "start": "1865320",
    "end": "1871050"
  },
  {
    "text": "use more optimized formats for attina its columnar format so that means that",
    "start": "1871050",
    "end": "1878700"
  },
  {
    "text": "the data stored so that you can only read the single columns of the data instead of all the records most of the",
    "start": "1878700",
    "end": "1884610"
  },
  {
    "text": "analytical queries you only process a subset of the columns so you can have records with lots of columns but you",
    "start": "1884610",
    "end": "1891450"
  },
  {
    "text": "need to filter and extract only a few of those so if you use Apache pircuit format add row or arc you get this",
    "start": "1891450",
    "end": "1899190"
  },
  {
    "text": "benefit automatically so maybe you already have software that can import or export those formats if you don't use",
    "start": "1899190",
    "end": "1905040"
  },
  {
    "text": "Parker or ork you can still compress the data if it's compressed you pay for the compressor sites so it's cheaper and",
    "start": "1905040",
    "end": "1912450"
  },
  {
    "text": "faster but you need to use splittable compression platform like bit zip to sew",
    "start": "1912450",
    "end": "1918090"
  },
  {
    "text": "gzip doesn't work with zip 2 and other tools allows you to read and split the",
    "start": "1918090",
    "end": "1924540"
  },
  {
    "text": "file in a better way and you have this blog post where we show how the same",
    "start": "1924540",
    "end": "1930720"
  },
  {
    "text": "files as depending on how you store them in different format gets different",
    "start": "1930720",
    "end": "1936360"
  },
  {
    "text": "performance and different cost for the same query so you can really optimize your cost and your speed a lot looking",
    "start": "1936360",
    "end": "1942420"
  },
  {
    "text": "at how you store your data with atheneum how can you process batch data if you",
    "start": "1942420",
    "end": "1949740"
  },
  {
    "start": "1944000",
    "end": "1944000"
  },
  {
    "text": "want to use lambda we already said lambdas a time out of 5 minutes so maybe you can't process the data that you put",
    "start": "1949740",
    "end": "1956160"
  },
  {
    "text": "on Alice 3 bucket in one minute because maybe it's a large file so their architectural pattern that we saw lots",
    "start": "1956160",
    "end": "1962460"
  },
  {
    "text": "of customer implement is the splitter so you can have a first function that is triggered by history looks at very big",
    "start": "1962460",
    "end": "1969720"
  },
  {
    "text": "file and then splits the data and lunch up technically up to 1000 function in",
    "start": "1969720",
    "end": "1977550"
  },
  {
    "text": "parallel to process the data and you don't need to actually split the data because s3 asked the range of operations",
    "start": "1977550",
    "end": "1984540"
  },
  {
    "text": "with s3 you can read only a subset of a range of a file so for example if you",
    "start": "1984540",
    "end": "1989730"
  },
  {
    "text": "upload one terabyte of data and this triggers a lambda function lambda function can seed the sides of the file",
    "start": "1989730",
    "end": "1995670"
  },
  {
    "text": "and then launch multiple lambda functions each function as a different range of bytes inside the file that will",
    "start": "1995670",
    "end": "2002180"
  },
  {
    "text": "be extracted and read by function so that each function can process the data within five minutes and usually store",
    "start": "2002180",
    "end": "2009950"
  },
  {
    "text": "the information in a central place where you can have a reducer that will collection collect all the information",
    "start": "2009950",
    "end": "2015260"
  },
  {
    "text": "back and provide a single result if you look at this architecture is a several s",
    "start": "2015260",
    "end": "2021050"
  },
  {
    "text": "implementation of the Map Reduce architecture that this was popularized",
    "start": "2021050",
    "end": "2026240"
  },
  {
    "text": "lots of years ago by a dupe and Google before of that and this is architectures",
    "start": "2026240",
    "end": "2031610"
  },
  {
    "start": "2030000",
    "end": "2030000"
  },
  {
    "text": "that are used actually in production a lot so this is Fannie Mae that I didn't",
    "start": "2031610",
    "end": "2036830"
  },
  {
    "text": "know but I discover it's the federal National Mortgage Association in the US so they basically do lots of analytics",
    "start": "2036830",
    "end": "2043190"
  },
  {
    "text": "to support the mortgage market in the US and they run Monte Carlo simulation Monte Carlo simulation means that they",
    "start": "2043190",
    "end": "2049490"
  },
  {
    "text": "use random simulation to understand the possible part of what can happen depending on the stock market and",
    "start": "2049490",
    "end": "2056560"
  },
  {
    "text": "everything in the financial market that can affect mortals and they run like",
    "start": "2056560",
    "end": "2063800"
  },
  {
    "text": "simulation of twenty million of mortgage and now it takes one point four hours",
    "start": "2063800",
    "end": "2069889"
  },
  {
    "text": "using this approach of serverless and parallel lambda function that is four times faster than it was before when",
    "start": "2069890",
    "end": "2077060"
  },
  {
    "text": "they were using a traditional architecture and it's much much easier to manage because now they can scale from one to 1,000 lambda function just",
    "start": "2077060",
    "end": "2084679"
  },
  {
    "text": "with with a trigger if you use Python there's this nice library",
    "start": "2084679",
    "end": "2091100"
  },
  {
    "text": "it's called PI run and basically the idea of this Python library is to provide you a framework where you can",
    "start": "2091100",
    "end": "2096530"
  },
  {
    "text": "take your Beast your computing logic in Python and run it in parallel on lots of",
    "start": "2096530",
    "end": "2101810"
  },
  {
    "text": "lambda functions and they achieved peak performance now with the limit of 1,000",
    "start": "2101810",
    "end": "2107450"
  },
  {
    "text": "concurrent functions that we are happy to increase but it's there you can get up to ten teraflops of computing power",
    "start": "2107450",
    "end": "2114910"
  },
  {
    "text": "it's it's a lot and they can read for example at speed like 60 or 50 gigabyte",
    "start": "2114910",
    "end": "2121250"
  },
  {
    "text": "per second read them right from history so to boots that normally requires lots of ultimate of optimization this comes",
    "start": "2121250",
    "end": "2128840"
  },
  {
    "text": "out of the box if you use their library third pattern",
    "start": "2128840",
    "end": "2134110"
  },
  {
    "text": "stream processing so this is different so now we want to process data almost in",
    "start": "2134110",
    "end": "2140300"
  },
  {
    "text": "real time the definition of stream processing is not very close so the",
    "start": "2140300",
    "end": "2145850"
  },
  {
    "text": "different interpretation for me we're talking about stream processing if you have a high interest rate and high is",
    "start": "2145850",
    "end": "2152840"
  },
  {
    "text": "relative that means something that you can manage with traditional architectures you have the purpose of",
    "start": "2152840",
    "end": "2160340"
  },
  {
    "text": "your architecture is to process this data with low latency so from data injection to getting the result of your",
    "start": "2160340",
    "end": "2166550"
  },
  {
    "text": "process this time should be as little as possible probably in the matter of",
    "start": "2166550",
    "end": "2171740"
  },
  {
    "text": "seconds or minutes if it's hours of days this is not streaming you can have spiky",
    "start": "2171740",
    "end": "2177980"
  },
  {
    "text": "traffic so you don't normally streaming application are sensitive to the source",
    "start": "2177980",
    "end": "2183770"
  },
  {
    "text": "of the stream sometimes the source of the stream can be IOT architecture or",
    "start": "2183770",
    "end": "2189730"
  },
  {
    "text": "business application either way you will have Peaks that then go down so the traffic is not steady and they usually",
    "start": "2189730",
    "end": "2197680"
  },
  {
    "text": "need two main characteristics so that message durability means that you don't lose any of the data that you receive",
    "start": "2197680",
    "end": "2204880"
  },
  {
    "text": "even if you have high volumes you still need to process exactly all the data that is sent and message",
    "start": "2204880",
    "end": "2211430"
  },
  {
    "text": "ordering is important so you can't process the data in a different order the order you receive and for people",
    "start": "2211430",
    "end": "2218210"
  },
  {
    "text": "that studied a little bit of distributed systems they know that durability ordering and distributed systems are",
    "start": "2218210",
    "end": "2223820"
  },
  {
    "text": "three things that normally don't work very well together you need to to put some sense to do that",
    "start": "2223820",
    "end": "2229160"
  },
  {
    "start": "2229000",
    "end": "2229000"
  },
  {
    "text": "so we overlay here created the Kinesis platform that can help you manage this",
    "start": "2229160",
    "end": "2235460"
  },
  {
    "text": "and it's still service because you don't need to manage any server and it's fully managed so normally you can have",
    "start": "2235460",
    "end": "2242300"
  },
  {
    "text": "architecture like this and for data injection we have a specific service within Kinesis that is kinases fire hose",
    "start": "2242300",
    "end": "2249050"
  },
  {
    "text": "that can help you store the data almost without writing any line of code so you",
    "start": "2249050",
    "end": "2254720"
  },
  {
    "text": "just need to put the record into a kinases virus delivery stream you can",
    "start": "2254720",
    "end": "2260450"
  },
  {
    "text": "use our SDK to do that we also have some agents that you can install if you need",
    "start": "2260450",
    "end": "2265730"
  },
  {
    "text": "to do that for example physical devices that have some limitations and when you receive",
    "start": "2265730",
    "end": "2271170"
  },
  {
    "text": "these records these records will automatically be buffered and written to",
    "start": "2271170",
    "end": "2276360"
  },
  {
    "text": "s3 so buffered means that if you receive 1 million of records and each record is",
    "start": "2276360",
    "end": "2281460"
  },
  {
    "text": "100 bytes you don't want to write 100 bytes files on a strip because then it would be crazy to read them process this",
    "start": "2281460",
    "end": "2287850"
  },
  {
    "text": "data but you can set up some buffering rules so that this data is aggregated in files and more much more manageable",
    "start": "2287850",
    "end": "2294480"
  },
  {
    "text": "honestly we can also automatically load the data on redshift our database so",
    "start": "2294480",
    "end": "2300180"
  },
  {
    "text": "that you can then run simple queries or store the data on elasticsearch where then you can run all the elastic shells",
    "start": "2300180",
    "end": "2307070"
  },
  {
    "text": "queries sometimes you want to pre-process the information so we have the possibility",
    "start": "2307070",
    "end": "2313800"
  },
  {
    "text": "to insert a lambda function that is use processing each record not each the",
    "start": "2313800",
    "end": "2320640"
  },
  {
    "text": "invocation is not for each record but we process the in micro batch so every 100",
    "start": "2320640",
    "end": "2325710"
  },
  {
    "text": "reg or 1000 record you invoke this lambda function it's automatic and this can do some processing or enrichment of",
    "start": "2325710",
    "end": "2332490"
  },
  {
    "text": "the data so you can check the syntax you can add more information you can even do lookups on external database to enrich",
    "start": "2332490",
    "end": "2340020"
  },
  {
    "text": "the information from your customer database or your IOT device repository",
    "start": "2340020",
    "end": "2345750"
  },
  {
    "text": "and then you have the transform records if you use this function and you transform the input data it's good",
    "start": "2345750",
    "end": "2352350"
  },
  {
    "text": "practice to enable the source record backup basically we will store also a",
    "start": "2352350",
    "end": "2357600"
  },
  {
    "text": "backup of the original records that you receive so that if something goes wrong with your lambda function you still have",
    "start": "2357600",
    "end": "2363570"
  },
  {
    "text": "the source data that you received and you can reprocess it and everything is stored as a metric on cloud much some",
    "start": "2363570",
    "end": "2370110"
  },
  {
    "text": "cloud works you can check the volumes of the data and you can check if you're keeping up with this data processing or",
    "start": "2370110",
    "end": "2375510"
  },
  {
    "text": "not because maybe your function is too slow and you're not able to keep up and then there's a different approach to",
    "start": "2375510",
    "end": "2382020"
  },
  {
    "text": "solve this kind of problem so as I said with firehose you can call lambda",
    "start": "2382020",
    "end": "2389070"
  },
  {
    "start": "2383000",
    "end": "2383000"
  },
  {
    "text": "functions with a buffer sites so normally the default is 100 that means",
    "start": "2389070",
    "end": "2394080"
  },
  {
    "text": "that every 100 record you receive you invoke the lambda function it receives this in the event a",
    "start": "2394080",
    "end": "2399710"
  },
  {
    "text": "list of 100 records and then you can process the records and send the output",
    "start": "2399710",
    "end": "2404859"
  },
  {
    "text": "normally playing with this witchcraft mystics can help you scale the function",
    "start": "2404859",
    "end": "2411890"
  },
  {
    "text": "better when you store the information on s3 you have two other parameters that",
    "start": "2411890",
    "end": "2417230"
  },
  {
    "text": "you can use and it's the buffer sides and the buffer interval so basically you can tell to firehose you receiving lots",
    "start": "2417230",
    "end": "2423440"
  },
  {
    "text": "of small records every time you reach and 100 megabyte or a size that you",
    "start": "2423440",
    "end": "2429380"
  },
  {
    "text": "specify or 15 minutes or one hour has passed so the first you reach you store",
    "start": "2429380",
    "end": "2435290"
  },
  {
    "text": "a file with all those records on a string so in this way you can buffer and group the data in a much more manageable",
    "start": "2435290",
    "end": "2440960"
  },
  {
    "text": "way on this tree and you can also transparency an ml compression so that the data can be stored compress it for",
    "start": "2440960",
    "end": "2448010"
  },
  {
    "text": "you on a stream if you store data straight to that shift it's a data base",
    "start": "2448010",
    "end": "2454820"
  },
  {
    "text": "so you have to be a little bit more careful so there's this link that you will get with the slides tells you more",
    "start": "2454820",
    "end": "2460640"
  },
  {
    "text": "information there's a blog article that gives you more information how you can optimize data to be stored on redshift",
    "start": "2460640",
    "end": "2466099"
  },
  {
    "text": "especially if you do time series of things like that or that I sorted you can you can have some tricks so that",
    "start": "2466099",
    "end": "2472910"
  },
  {
    "text": "that ice process in the most efficient way this is an example of a an",
    "start": "2472910",
    "end": "2478250"
  },
  {
    "start": "2475000",
    "end": "2475000"
  },
  {
    "text": "architecture it is quite common so you have IOT devices and you want to process the information from these IOT devices",
    "start": "2478250",
    "end": "2485240"
  },
  {
    "text": "in near-real-time so in this case we have lots of IOT sensors they use AWS IOT so they can",
    "start": "2485240",
    "end": "2491990"
  },
  {
    "text": "communicate using a machine to machine protocol like mqtt or we're now opening",
    "start": "2491990",
    "end": "2498170"
  },
  {
    "text": "a SS IOT to lower level protocols so that are usable by device that don't",
    "start": "2498170",
    "end": "2503570"
  },
  {
    "text": "even can do TLS on tcp so very low level devices so these sensors can send information to",
    "start": "2503570",
    "end": "2509359"
  },
  {
    "text": "database IOT platform and there you can set up rules that depending on the content of the record can send this data",
    "start": "2509359",
    "end": "2515750"
  },
  {
    "text": "for injection or processing to the SS cloud and you can either just store the",
    "start": "2515750",
    "end": "2521570"
  },
  {
    "text": "raw records but in this case you every record becomes an object on a stream so",
    "start": "2521570",
    "end": "2527180"
  },
  {
    "text": "if you have very small records is not efficient you can send this these two are kinases that",
    "start": "2527180",
    "end": "2533150"
  },
  {
    "text": "dream and here you can process the data with a lambda function or you can send",
    "start": "2533150",
    "end": "2538369"
  },
  {
    "text": "the data to a Kinesis virus delivery stream that stores the information on s3 and a trick is using buffering you can",
    "start": "2538369",
    "end": "2546500"
  },
  {
    "text": "create a file for example every five minutes or 15 minutes in this country there a lambda function that can process",
    "start": "2546500",
    "end": "2552140"
  },
  {
    "text": "the whole file together so it can be a good way if you don't need to be very low latency to optimize your cost this",
    "start": "2552140",
    "end": "2560329"
  },
  {
    "start": "2559000",
    "end": "2559000"
  },
  {
    "text": "is how you can do real-time analytics so from the producers you get the the",
    "start": "2560329",
    "end": "2568099"
  },
  {
    "text": "camisa stream that is ingested from the the iot devices or whoever is producing the data and sometimes you want to look",
    "start": "2568099",
    "end": "2575720"
  },
  {
    "text": "for example to some variables that need to be mooted over time so let's say that",
    "start": "2575720",
    "end": "2581329"
  },
  {
    "text": "you have sensors that gives you the temperature of lots of different places in your factories across all over the",
    "start": "2581329",
    "end": "2588170"
  },
  {
    "text": "world and if one of these rooms reach more than 40 degrees I want to act and",
    "start": "2588170",
    "end": "2593720"
  },
  {
    "text": "do something because it's too much but you can't trust a single data point so you can use Kinesis analytics that can",
    "start": "2593720",
    "end": "2601339"
  },
  {
    "text": "run and create a tumbling or a sliding window on the data and create an average",
    "start": "2601339",
    "end": "2606349"
  },
  {
    "text": "across a period of time so you can say take an average every minute and that's a tumbling window or you can say for",
    "start": "2606349",
    "end": "2613940"
  },
  {
    "text": "every data point take also the average across the last minute of data so that's a sliding window because for every data",
    "start": "2613940",
    "end": "2620420"
  },
  {
    "text": "point we use scroll the slide in the window to get smoother data missus",
    "start": "2620420",
    "end": "2626450"
  },
  {
    "text": "analytics can also do anomaly detection using the random cut forest algorithm so that means that based on the last on all",
    "start": "2626450",
    "end": "2634130"
  },
  {
    "text": "the data that you receive it can statistically infer if this data point is probable or not so basically you are",
    "start": "2634130",
    "end": "2641569"
  },
  {
    "text": "the probability to every reyga's that tells you this is a record that is 95% correct or this record is probably",
    "start": "2641569",
    "end": "2649309"
  },
  {
    "text": "coming from a sense of the descending from data because there were so many few records with this kind of information",
    "start": "2649309",
    "end": "2655250"
  },
  {
    "text": "maybe it's broken and the output of the keys is analytics platform that can be",
    "start": "2655250",
    "end": "2660890"
  },
  {
    "text": "aggregated so maybe here you receive millions of records but then you aggregate a",
    "start": "2660890",
    "end": "2666160"
  },
  {
    "text": "minute.this Kimmy's esteemed can then send the information problem the function that can check the average",
    "start": "2666160",
    "end": "2672500"
  },
  {
    "text": "temperature every minute from your millions of sensors and act only if",
    "start": "2672500",
    "end": "2677710"
  },
  {
    "text": "effectively the record was sent with multiple data points saying that this",
    "start": "2677710",
    "end": "2683570"
  },
  {
    "text": "room has this problem and maybe there were there were no anomalies in the device and then you can act maybe send",
    "start": "2683570",
    "end": "2690860"
  },
  {
    "text": "an SMS notification to a support team that can go there to recover the issue",
    "start": "2690860",
    "end": "2696340"
  },
  {
    "text": "Kimmy's Analytics will automatically infer and expect that the structure of",
    "start": "2696340",
    "end": "2702740"
  },
  {
    "text": "the data that you sent you can support JSON or CSV formats for example but",
    "start": "2702740",
    "end": "2707840"
  },
  {
    "text": "sometimes a few records may not respect this data format so you can automatically configure an error stream",
    "start": "2707840",
    "end": "2714440"
  },
  {
    "text": "where any record that you received at the syntactical is not correct is sent so that you can have your error records",
    "start": "2714440",
    "end": "2720710"
  },
  {
    "text": "to be processed maybe to a different platform now let's see how these windows",
    "start": "2720710",
    "end": "2727370"
  },
  {
    "text": "aggregation works so with kissies analytics you can use a syntax that is similar to normal sequel to aggregate",
    "start": "2727370",
    "end": "2733910"
  },
  {
    "start": "2729000",
    "end": "2729000"
  },
  {
    "text": "data so we run in our sequel not on a table but on a continuous stream of data so to do that we use the blue part to",
    "start": "2733910",
    "end": "2742220"
  },
  {
    "text": "define the input and output stream then we have the orange part that defines the",
    "start": "2742220",
    "end": "2750050"
  },
  {
    "text": "tumbling window so basically we're saying that we are using the raw time so the time where this record was in",
    "start": "2750050",
    "end": "2757160"
  },
  {
    "text": "injected in the platform and we are Gregg 8 by 1 minute but you can use any",
    "start": "2757160",
    "end": "2762320"
  },
  {
    "text": "syntax you want you can use seconds hours if you prefer and then on on this",
    "start": "2762320",
    "end": "2767840"
  },
  {
    "text": "data that is aggregated we can run the sum of a specific measurement so",
    "start": "2767840",
    "end": "2774480"
  },
  {
    "text": "maybe the sum of the temperature and we also count the samples and when you have",
    "start": "2774480",
    "end": "2779670"
  },
  {
    "text": "the sum and the number of samples it's very easy to build the average as a",
    "start": "2779670",
    "end": "2784710"
  },
  {
    "text": "consequence so this is an example of the syntax so apart from this blue parts that are a little bit specific to the",
    "start": "2784710",
    "end": "2792000"
  },
  {
    "text": "input and output stream the rest is mostly plain sequel and then there's this syntax to create tumbling or if you",
    "start": "2792000",
    "end": "2799109"
  },
  {
    "text": "prefer sliding window the difference is that tumbling window will reduce the",
    "start": "2799109",
    "end": "2804900"
  },
  {
    "text": "amount of data because that is aggregated so if you have lots of Records you aggregate every minute depending on the keys a sliding window",
    "start": "2804900",
    "end": "2812130"
  },
  {
    "text": "will output the same amount of records that you receive but will give you the average of a specific value over time so",
    "start": "2812130",
    "end": "2819000"
  },
  {
    "text": "usually they Smoot specific rates that you can read that you can receive from devices and this is the architecture we",
    "start": "2819000",
    "end": "2829680"
  },
  {
    "text": "saw let's see a little bit here the kinases stream part so this is the third",
    "start": "2829680",
    "end": "2836369"
  },
  {
    "start": "2833000",
    "end": "2833000"
  },
  {
    "text": "type of way you can invoke a lambda function you remember we said that when",
    "start": "2836369",
    "end": "2842640"
  },
  {
    "text": "you call a lambda function you can call it synchronously or asynchronously this is the third way that is designed to",
    "start": "2842640",
    "end": "2848819"
  },
  {
    "text": "preserve order in records so what happens is that when you create a keaney's stream you can scale adding",
    "start": "2848819",
    "end": "2855450"
  },
  {
    "text": "multiple shards it's sharp as a throughput of an input ingestion",
    "start": "2855450",
    "end": "2861059"
  },
  {
    "text": "throughput of one megabyte per second so if you need to receive more than one megabyte per second with kissies you create multiple shards",
    "start": "2861059",
    "end": "2868020"
  },
  {
    "text": "inside the same stream its just a configuration you can even have to scale it using lambda functions if you want",
    "start": "2868020",
    "end": "2874049"
  },
  {
    "text": "what we will do we will create a lambda function listening to each of your",
    "start": "2874049",
    "end": "2879539"
  },
  {
    "text": "shards so if you have three shards we will have three lambda function listening in this way each lambda",
    "start": "2879539",
    "end": "2885000"
  },
  {
    "text": "function receives data only from a shard and can preserve the order inside the shard of the record that you received",
    "start": "2885000",
    "end": "2890940"
  },
  {
    "text": "from sensors or databases or whatever so this means that you have basically two",
    "start": "2890940",
    "end": "2899789"
  },
  {
    "text": "ways to increase performance one is to increase the batch side so how much records at a time you want Kinesis to",
    "start": "2899789",
    "end": "2906819"
  },
  {
    "text": "send to its lambda function so it sharp so it's on lambda function the second",
    "start": "2906819",
    "end": "2912339"
  },
  {
    "text": "one is that you may need to increase the number of shots even if you don't need too much injection power because you",
    "start": "2912339",
    "end": "2917950"
  },
  {
    "text": "need more lambda function to process the data what we've seen also used by",
    "start": "2917950",
    "end": "2923680"
  },
  {
    "text": "customer is the fan-out pattern so the fan-out pattern is similar to this tree pattern that we saw before you have a",
    "start": "2923680",
    "end": "2929259"
  },
  {
    "text": "first lambda function that is not doing all the work but it's just taking the raw data and then starting in parallel",
    "start": "2929259",
    "end": "2935140"
  },
  {
    "text": "bootable and the functions to process the information this works but you lose",
    "start": "2935140",
    "end": "2940569"
  },
  {
    "text": "the order because each of these lambda function can invoke the synchronously so you lose the order so it can work for",
    "start": "2940569",
    "end": "2947470"
  },
  {
    "text": "some use cases for example this is the architecture this used by Thomson Reuters they have this product inside",
    "start": "2947470",
    "end": "2953259"
  },
  {
    "start": "2948000",
    "end": "2948000"
  },
  {
    "text": "where they collect all the information from how they the user are using their platform so all this business software",
    "start": "2953259",
    "end": "2959920"
  },
  {
    "text": "is sending information using Kinesis they normally have 4000 requests per",
    "start": "2959920",
    "end": "2964930"
  },
  {
    "text": "second but they reached 10,000 data points per second with this platform and",
    "start": "2964930",
    "end": "2971400"
  },
  {
    "text": "they have the data from when they enter it enters in Kinesis and it's in the",
    "start": "2971400",
    "end": "2977079"
  },
  {
    "text": "user dashboard in less than 10 seconds that means we have the real-time streaming performance so the the best",
    "start": "2977079",
    "end": "2987069"
  },
  {
    "text": "practices here are relief tune the batch side so how much records you want to be",
    "start": "2987069",
    "end": "2992559"
  },
  {
    "text": "to send at a time to from a stream of data to to the lambda function and this",
    "start": "2992559",
    "end": "2999579"
  },
  {
    "text": "usually goes from 100 to 10,000 records 10,000 I think is the limit now tune the",
    "start": "2999579",
    "end": "3006450"
  },
  {
    "text": "memory again the memory gives you more CPU so if you see that your Kinesis function is not able to keep up with the",
    "start": "3006450",
    "end": "3013829"
  },
  {
    "text": "data processing maybe if you give more memory and you have more CPU it will be able to process more information and if",
    "start": "3013829",
    "end": "3021450"
  },
  {
    "text": "you use specific device look at our producers library that can help you",
    "start": "3021450",
    "end": "3026609"
  },
  {
    "text": "create more compact records and be more efficient in data processing from the start last part or not before the final",
    "start": "3026609",
    "end": "3035460"
  },
  {
    "text": "one we'll graph QL i T we've seen lots of customer using lambda functions to optimize what they",
    "start": "3035460",
    "end": "3041510"
  },
  {
    "start": "3036000",
    "end": "3036000"
  },
  {
    "text": "do in their IT to respond to alarms to manage auditing so everything that we need to do to manage our IT organization",
    "start": "3041510",
    "end": "3049460"
  },
  {
    "text": "so this is the ops Automator is an example application that you can download we build it and it's available",
    "start": "3049460",
    "end": "3056300"
  },
  {
    "start": "3050000",
    "end": "3050000"
  },
  {
    "text": "on a website basically the idea here is that you can use cloud watch events to",
    "start": "3056300",
    "end": "3062180"
  },
  {
    "text": "fire a lambda function periodically every hour every day every 5 minutes this lambda function is getting tasks to",
    "start": "3062180",
    "end": "3069110"
  },
  {
    "text": "do from a DynamoDB table and currently is support doing the snapshot of ec2",
    "start": "3069110",
    "end": "3074390"
  },
  {
    "text": "instances or doing that a snapshot of redshift clusters and if you want to use",
    "start": "3074390",
    "end": "3081560"
  },
  {
    "text": "ec2 instance you just need to add a tag to the ac2 instance create the operations create snapshot and what",
    "start": "3081560",
    "end": "3088310"
  },
  {
    "text": "happens is this lambda function we look what to do it will trigger a task executors lambda function that we look",
    "start": "3088310",
    "end": "3094550"
  },
  {
    "text": "for this is c2 instances where they need to take the snapshot of the storage and",
    "start": "3094550",
    "end": "3100010"
  },
  {
    "text": "it will write everything it does in log so that you can understand if your backup is working or not this is an",
    "start": "3100010",
    "end": "3107240"
  },
  {
    "start": "3106000",
    "end": "3106000"
  },
  {
    "text": "example for image recognition and we will come back to this in the last session so if you want to process images",
    "start": "3107240",
    "end": "3114140"
  },
  {
    "text": "we have an artificial intelligence service that can look into an image and understand what's inside an image and",
    "start": "3114140",
    "end": "3121310"
  },
  {
    "text": "you can coordinate the the workflow using step functions we will see those",
    "start": "3121310",
    "end": "3127130"
  },
  {
    "text": "in the last session but step function can help you define a workflow that takes the input image and will extract",
    "start": "3127130",
    "end": "3134060"
  },
  {
    "text": "the image metadata will process the image with a mathematical condition create the thumbnail and then store the",
    "start": "3134060",
    "end": "3140390"
  },
  {
    "text": "metadata in DynamoDB all of this is managed through a workflow that you can",
    "start": "3140390",
    "end": "3146900"
  },
  {
    "start": "3146000",
    "end": "3146000"
  },
  {
    "text": "literally design and it can help you map complex workflows that if you put",
    "start": "3146900",
    "end": "3152390"
  },
  {
    "text": "everything inside a lambda function it could be more complex to build or it can be difficult to audit understand",
    "start": "3152390",
    "end": "3158900"
  },
  {
    "text": "everything is working correctly or if you're losing some data this is another example there's Capital One they",
    "start": "3158900",
    "end": "3166640"
  },
  {
    "start": "3162000",
    "end": "3162000"
  },
  {
    "text": "built an open-source project on top of this architecture and the idea is that you can use cloud watch events as your trigger for lambda",
    "start": "3166640",
    "end": "3173650"
  },
  {
    "text": "function and cloud watch events can tell you everything that is happening on AWS so for example if someone is creating a",
    "start": "3173650",
    "end": "3180610"
  },
  {
    "text": "security group that gives internet access to to one of your instances you",
    "start": "3180610",
    "end": "3186160"
  },
  {
    "text": "can check this event trigger a lambda function that can automatically remediate the error so close the port",
    "start": "3186160",
    "end": "3193960"
  },
  {
    "text": "and send an SMS email notification to the administrator that receive the notification and a final example on this",
    "start": "3193960",
    "end": "3204180"
  },
  {
    "start": "3200000",
    "end": "3200000"
  },
  {
    "text": "Autodesk they built an open-source tool that they call Taylor because they want",
    "start": "3204180",
    "end": "3209680"
  },
  {
    "text": "to create accounts for the developers so that a developer can have their own account within the bigger account with",
    "start": "3209680",
    "end": "3215830"
  },
  {
    "text": "everything set up with all the the corporate standards they'd have for",
    "start": "3215830",
    "end": "3222040"
  },
  {
    "text": "auditing configuration and networking and they created this tool that can automatically provision all the",
    "start": "3222040",
    "end": "3229090"
  },
  {
    "text": "resources using service functions for setting up an account in less than 10",
    "start": "3229090",
    "end": "3234370"
  },
  {
    "text": "minutes it's much faster than what they were used before so best practices for",
    "start": "3234370",
    "end": "3240190"
  },
  {
    "text": "for IT automation functions so if you",
    "start": "3240190",
    "end": "3245260"
  },
  {
    "text": "start to use a API is like ec2 API eyes that are not meant to be used by",
    "start": "3245260",
    "end": "3251590"
  },
  {
    "text": "consumers you can import link so we don't expect you to do easy to describe",
    "start": "3251590",
    "end": "3257140"
  },
  {
    "text": "instance more than 1000 so 1000 times per second is something that we control more fine-grain lee than what we do with",
    "start": "3257140",
    "end": "3264370"
  },
  {
    "text": "this tree so check that and our sdk will automatically retry if you get throttled use custom metrics to understand what",
    "start": "3264370",
    "end": "3272020"
  },
  {
    "text": "you're doing so post to cloud watch the information for example on the snapshot",
    "start": "3272020",
    "end": "3277210"
  },
  {
    "text": "you do so that you have a baseline to understand what is working and or not musics ray we already saw an example in",
    "start": "3277210",
    "end": "3283690"
  },
  {
    "text": "the previous presentation and probably you need to disable function if something goes wrong because this is IT",
    "start": "3283690",
    "end": "3290170"
  },
  {
    "text": "automation it's not something that maybe is double check like a traditional application that go in production the",
    "start": "3290170",
    "end": "3297070"
  },
  {
    "text": "best trick is just to give zero to the concurrency of a function and this will block any execution while us",
    "start": "3297070",
    "end": "3303020"
  },
  {
    "text": "what's happening otherwise you can disable the trigger and see why you have",
    "start": "3303020",
    "end": "3308030"
  },
  {
    "text": "a problem final and then we finish this quite packed our graph QL so we're",
    "start": "3308030",
    "end": "3315320"
  },
  {
    "text": "switching a little bit more on the development side here so normally when we build api's for the last ten if not",
    "start": "3315320",
    "end": "3323600"
  },
  {
    "text": "more years the rest model was the standard the rest us lots of advantages but it's also very granular and it's",
    "start": "3323600",
    "end": "3330470"
  },
  {
    "text": "difficult to express complex queries with rest that's why a few years ago Facebook designed this graphical model",
    "start": "3330470",
    "end": "3337640"
  },
  {
    "text": "internally then it make it available publicly now we've seen not just the Facebook SDK",
    "start": "3337640",
    "end": "3343940"
  },
  {
    "text": "but also get up I think they move to graph QL as a way to expose their API",
    "start": "3343940",
    "end": "3351100"
  },
  {
    "text": "and to make it available as a server less service we created this new service",
    "start": "3351100",
    "end": "3356150"
  },
  {
    "text": "that is currently in preview so you need to be accept that in the preview if you want to test it it's called up sync and",
    "start": "3356150",
    "end": "3362330"
  },
  {
    "text": "it can help you create real-time backends that can work also flying so the flow with graphic UL is that you can",
    "start": "3362330",
    "end": "3369140"
  },
  {
    "text": "create a schema so with rest there is no concept of schema but here you can really define how you want to manage",
    "start": "3369140",
    "end": "3374570"
  },
  {
    "text": "your data then you can connect data sources and data sources can be dynamo DB tables lambda functions or",
    "start": "3374570",
    "end": "3381740"
  },
  {
    "text": "elasticsearch databases and in this way you can map the schema to how the data",
    "start": "3381740",
    "end": "3389120"
  },
  {
    "text": "should be written read or write of written on the read or written on these",
    "start": "3389120",
    "end": "3395060"
  },
  {
    "text": "different data sources and the platform will manage that the graph QL manage",
    "start": "3395060",
    "end": "3400850"
  },
  {
    "text": "also subscriptions and subscription means that you can from your application say every time someone is changing this",
    "start": "3400850",
    "end": "3407060"
  },
  {
    "text": "data from any occur any client any mobile app any web application send me a",
    "start": "3407060",
    "end": "3412910"
  },
  {
    "text": "notification in real time so that I know that someone changed this data and we",
    "start": "3412910",
    "end": "3419330"
  },
  {
    "text": "use transparently WebSockets in the browser or in a mobile app to manage all",
    "start": "3419330",
    "end": "3424760"
  },
  {
    "text": "this complexity for you so that you can receive the notification in real time and normally you would just subscribe a",
    "start": "3424760",
    "end": "3430430"
  },
  {
    "text": "function to distribute every time it's changing some something so just to give you a very very quick view",
    "start": "3430430",
    "end": "3436460"
  },
  {
    "text": "on how this works this is the app sync",
    "start": "3436460",
    "end": "3442060"
  },
  {
    "text": "console and I have a demo application it's the default today I'm also if you",
    "start": "3442060",
    "end": "3447560"
  },
  {
    "text": "want you can when you are accepted you can test it so this is the how a schema",
    "start": "3447560",
    "end": "3453470"
  },
  {
    "text": "works for for a draft well so you have an entry point where you define queries",
    "start": "3453470",
    "end": "3459560"
  },
  {
    "text": "notations and subscriptions queries is the way you want to read your data mutational you want to update or insert",
    "start": "3459560",
    "end": "3466880"
  },
  {
    "text": "the new data and subscription is what you want to get notified in real time if someone is changing the data in this",
    "start": "3466880",
    "end": "3473510"
  },
  {
    "text": "case I'm using a true dynamodb table so if I go on the data sources I see that I have a comment table and an event table",
    "start": "3473510",
    "end": "3481609"
  },
  {
    "text": "so I can create events and then create comments on top of these events if we go",
    "start": "3481609",
    "end": "3486740"
  },
  {
    "text": "back here you see that I can define an event type so compared to the rest model I can really define a structure for my",
    "start": "3486740",
    "end": "3492830"
  },
  {
    "text": "data the exclamation mark means that this is a mandatory field all the other fields are not mandatory so I have an",
    "start": "3492830",
    "end": "3499040"
  },
  {
    "text": "event with a name a location a date a description and this can be linked to",
    "start": "3499040",
    "end": "3504380"
  },
  {
    "text": "paginate add list of comments in the comments if we look for them here they",
    "start": "3504380",
    "end": "3510650"
  },
  {
    "text": "can a link to an event they have an ID and they can have a content and a creation date so I'm not entering into",
    "start": "3510650",
    "end": "3517550"
  },
  {
    "text": "the tail of the protocols but this is the way you can define your data model and then you can define subscriptions",
    "start": "3517550",
    "end": "3523820"
  },
  {
    "text": "that in this case we have a subscription to the comments so every time there is a new comment on an event I want to",
    "start": "3523820",
    "end": "3531140"
  },
  {
    "text": "receive a notification you use this annotation syntax to say that I want to",
    "start": "3531140",
    "end": "3537080"
  },
  {
    "text": "be annotated by that so if you do that then we have an SDK that you can use and",
    "start": "3537080",
    "end": "3542330"
  },
  {
    "text": "this is for example at react application that we have on get up the the body",
    "start": "3542330",
    "end": "3549740"
  },
  {
    "text": "works that if you're in the right directory so let this is now already",
    "start": "3549740",
    "end": "3556550"
  },
  {
    "text": "starting so let's open another browser here",
    "start": "3556550",
    "end": "3561579"
  },
  {
    "text": "so I we now have a couple of browser and",
    "start": "3564200",
    "end": "3569569"
  },
  {
    "text": "this is the event the the web interface that is creating events and then you can comment on event so if I create an event",
    "start": "3569569",
    "end": "3576349"
  },
  {
    "text": "here so this is builders day in London",
    "start": "3576349",
    "end": "3583780"
  },
  {
    "text": "nice event I hope so and you remember events they didn't have",
    "start": "3583780",
    "end": "3589880"
  },
  {
    "text": "a real-time subscription so I need to reload in this case to see the event but",
    "start": "3589880",
    "end": "3594950"
  },
  {
    "text": "then I can click here on comments and since there is a subscription if I add a",
    "start": "3594950",
    "end": "3600020"
  },
  {
    "text": "comment so it was not so nice actually",
    "start": "3600020",
    "end": "3606369"
  },
  {
    "text": "and this is sent on the other side and then I say why and then you can explain",
    "start": "3606369",
    "end": "3615700"
  },
  {
    "text": "why and you saw how everything was built so there was in the code if you see the",
    "start": "3615700",
    "end": "3620780"
  },
  {
    "text": "code of the application there's no time everything is managed transparently you just need to say I want to use this subscription and if anything comes",
    "start": "3620780",
    "end": "3627490"
  },
  {
    "text": "trigger this function and then you can use this function to add comments or process the information so it's super",
    "start": "3627490",
    "end": "3633290"
  },
  {
    "text": "easy and the other side is also that this framework is designed to work offline so it's difficult to test but if",
    "start": "3633290",
    "end": "3639680"
  },
  {
    "text": "I disable the network both these browsers can click you can still create events and comments and then when you go",
    "start": "3639680",
    "end": "3646069"
  },
  {
    "text": "back online they will synchronize the data and there's conflict management in case of conflicts that you can do automatically",
    "start": "3646069",
    "end": "3652520"
  },
  {
    "text": "or on the client side depending on the business logic so it's very good to build web and mobile backends and it's a",
    "start": "3652520",
    "end": "3659480"
  },
  {
    "text": "key trend that I would suggest you to ever look at because I think more and more application will use graph QL to",
    "start": "3659480",
    "end": "3665540"
  },
  {
    "text": "build their back-end in the future that's a summary but we already went",
    "start": "3665540",
    "end": "3670700"
  },
  {
    "text": "through all of that there's lots of patterns that we have I try to share a few maybe it was some very interesting",
    "start": "3670700",
    "end": "3677210"
  },
  {
    "text": "episode where people were a little bit more on the board side but then I story",
    "start": "3677210",
    "end": "3683690"
  },
  {
    "text": "is that everything you want to build we have architectural patterns that we can share so that you can you can really go",
    "start": "3683690",
    "end": "3690230"
  },
  {
    "text": "into something that you need to invent and be the first to build these applications thank you we we take",
    "start": "3690230",
    "end": "3698140"
  },
  {
    "text": "we take a three minutes break because these two sessions are supposed to be one after the other but I think we",
    "start": "3701910",
    "end": "3707380"
  },
  {
    "text": "deserve three minutes and then we start",
    "start": "3707380",
    "end": "3711359"
  }
]
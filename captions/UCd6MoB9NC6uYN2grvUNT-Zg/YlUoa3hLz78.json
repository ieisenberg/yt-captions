[
  {
    "start": "0",
    "end": "103000"
  },
  {
    "text": "okay hi everybody again my name is hey guy I'm an engineering manager with Amazon AI I",
    "start": "4009",
    "end": "11040"
  },
  {
    "text": "work with my team on deep learning systems and today I'm going to talk to you about model serving for machine",
    "start": "11040",
    "end": "18600"
  },
  {
    "text": "learning with Apache MX net and AWS specifically talk about AWS Fargate but",
    "start": "18600",
    "end": "24300"
  },
  {
    "text": "you know model serving can be done as on other AWS technologies and before we get",
    "start": "24300",
    "end": "31769"
  },
  {
    "text": "started I'd like to get a good understanding of the audience so I'll",
    "start": "31769",
    "end": "37649"
  },
  {
    "text": "ask you a few questions so I can you know moderate my content based on that who here has ever built and trained the",
    "start": "37649",
    "end": "45780"
  },
  {
    "text": "machine learning model okay awesome",
    "start": "45780",
    "end": "50809"
  },
  {
    "text": "who had the built and trained a deep learning model in your network okay so",
    "start": "50809",
    "end": "60390"
  },
  {
    "text": "we'll talk a bit about deep learning who has ever deployed a machine learning or",
    "start": "60390",
    "end": "66000"
  },
  {
    "text": "a deep learning model in production okay fewer hands great so this talk is really",
    "start": "66000",
    "end": "72240"
  },
  {
    "text": "I think you'll enjoy this talk because in this talk you will learn about serving machine learning models and more",
    "start": "72240",
    "end": "79409"
  },
  {
    "text": "specifically deep learning with a focus on deep learning models and I guarantee",
    "start": "79409",
    "end": "84840"
  },
  {
    "text": "that if you pay attention to this talk and the end of this talk you'll be able to take a deep learning model deploy to",
    "start": "84840",
    "end": "90930"
  },
  {
    "text": "production in around 15 minutes okay that's fair and if it doesn't work come talk to me all right let's get going so",
    "start": "90930",
    "end": "99720"
  },
  {
    "text": "first of all just going over the machine learning stack at AWS just to give some context and orientation at a the press",
    "start": "99720",
    "end": "106829"
  },
  {
    "start": "103000",
    "end": "103000"
  },
  {
    "text": "we want to offer you know to give you guys the power to use machine learning for your applications and services and",
    "start": "106829",
    "end": "112979"
  },
  {
    "text": "we have a layered approach I start with the topmost layer those are AI services",
    "start": "112979",
    "end": "121009"
  },
  {
    "text": "that you can just consume state-of-the-art models without knowing anything about the actual underlying",
    "start": "121009",
    "end": "127020"
  },
  {
    "text": "models being used without worrying about it and this includes services for things",
    "start": "127020",
    "end": "133080"
  },
  {
    "text": "like V to Amazon recognition speech through Foley or transcribe language",
    "start": "133080",
    "end": "138959"
  },
  {
    "text": "translations chat BOTS and there is more coming if you go one layer below that",
    "start": "138959",
    "end": "145620"
  },
  {
    "text": "you have access to a ws machine learning platform and this includes things like",
    "start": "145620",
    "end": "151290"
  },
  {
    "text": "Amazon sage maker which is a platform I think you heard about earlier today for end-to-end you know training storing",
    "start": "151290",
    "end": "157800"
  },
  {
    "text": "deploying models there's also the plans there is the MTurk for data aggregation",
    "start": "157800",
    "end": "163800"
  },
  {
    "text": "and labeling all of that is part of our platform offering and one layer below",
    "start": "163800",
    "end": "169140"
  },
  {
    "text": "that is the machine learning frameworks most of these framework probably actually all of them are open-source but",
    "start": "169140",
    "end": "176820"
  },
  {
    "text": "Twitter WS are hard at work to make sure these frameworks work best and our super",
    "start": "176820",
    "end": "181980"
  },
  {
    "text": "performant on AWS so we actually go down to the source code of these frameworks",
    "start": "181980",
    "end": "187830"
  },
  {
    "text": "and we optimize them and we benchmark them and we make sure they run very well on AWS for you guys to use and what's",
    "start": "187830",
    "end": "196950"
  },
  {
    "text": "nice about this tiered approach is that even internally each layer we expose",
    "start": "196950",
    "end": "201959"
  },
  {
    "text": "it's built on top the layer below that so we are actually inside AWS who are actually customers of our own products",
    "start": "201959",
    "end": "208890"
  },
  {
    "text": "in that sense ok and MX net is highlighted there because in this talk so first of all my team focuses a lot on",
    "start": "208890",
    "end": "216540"
  },
  {
    "text": "MX nighttime accent is an open source framework I'll talk to you more about that but we contribute a lot to it and",
    "start": "216540",
    "end": "222420"
  },
  {
    "text": "in this talk I'll talk to you about serving MX net models and we'll get a notion about that ok so we start with",
    "start": "222420",
    "end": "230400"
  },
  {
    "text": "brief intro to deep learning looks like you guys are well-versed with machine learning and I'm sure you know you heard",
    "start": "230400",
    "end": "237299"
  },
  {
    "text": "a lot you read a lot about deep learning maybe you haven't had a chance to use it it's not much but we will go over that a",
    "start": "237299",
    "end": "243720"
  },
  {
    "text": "bit so first of all for some background and setting things in context we'll talk",
    "start": "243720",
    "end": "248910"
  },
  {
    "text": "about where deep learning fits so very broadly there is AI that's there's been",
    "start": "248910",
    "end": "254280"
  },
  {
    "text": "a you know research field and more generally public philosophical you know",
    "start": "254280",
    "end": "259859"
  },
  {
    "text": "discussion area for you know quite some time in the fifties it started to get",
    "start": "259859",
    "end": "265680"
  },
  {
    "text": "serious and I'm quoting here touring with maybe you know one of the creators of the",
    "start": "265680",
    "end": "271380"
  },
  {
    "text": "computer science field and also AI and he changed the context of the question from Ken machines think which is more of",
    "start": "271380",
    "end": "278520"
  },
  {
    "text": "a philosophical question to more practical engineering driven questions can machines do what us humans can write",
    "start": "278520",
    "end": "285240"
  },
  {
    "text": "and that's what we're trying to do with AI now in you know in technology within",
    "start": "285240",
    "end": "290880"
  },
  {
    "text": "AI there is a field called machine learning who rose to prominence probably in the 80s and 90s now is you know it's",
    "start": "290880",
    "end": "298560"
  },
  {
    "text": "all the rage and I think a nice way to look at what machine learning is is if",
    "start": "298560",
    "end": "304530"
  },
  {
    "text": "you look at traditional programming that's like the programming I learned at school we the programmers provide the",
    "start": "304530",
    "end": "313110"
  },
  {
    "text": "rules through this programming languages and provide the data and traditional",
    "start": "313110",
    "end": "318150"
  },
  {
    "text": "program just executes our rules on the data and gives us answers right that's the traditional programming machine",
    "start": "318150",
    "end": "324150"
  },
  {
    "text": "learning kind of changes that paradigm and as the humans we provide the data we",
    "start": "324150",
    "end": "333330"
  },
  {
    "text": "provide the answers and together it's usually called labeled data and the machine learning algorithm actually",
    "start": "333330",
    "end": "340229"
  },
  {
    "text": "figures out the rules by itself so we don't need to explicitly program rules anymore right and that's the big shift",
    "start": "340229",
    "end": "348360"
  },
  {
    "text": "in paradigm that machine learning gives us and that's why it's so powerful because it can actually solve very",
    "start": "348360",
    "end": "354449"
  },
  {
    "text": "complex problems you do that without us the program is actually specifying the actual rules and so within the within",
    "start": "354449",
    "end": "362430"
  },
  {
    "text": "machine learning there is a specific technique called deep learning machine learning includes lots of other techniques like gradient boosting",
    "start": "362430",
    "end": "369120"
  },
  {
    "text": "decision trees SVM's there's a bunch of these tools in that machine learning toolbox deep learning",
    "start": "369120",
    "end": "375900"
  },
  {
    "text": "is one of them but it's one that has become much very prominent and proven to be super powerful especially in solving",
    "start": "375900",
    "end": "382650"
  },
  {
    "text": "what we call cognitive problems so understanding images understanding video understanding just natural language and",
    "start": "382650",
    "end": "388770"
  },
  {
    "text": "understanding speech and it's gradually outperforming all the other tools in the machine learning toolbox and I'm going",
    "start": "388770",
    "end": "396300"
  },
  {
    "text": "to talk to you a bit more about that so again continuing the introduction",
    "start": "396300",
    "end": "403009"
  },
  {
    "start": "399000",
    "end": "399000"
  },
  {
    "text": "deep learning is really based on what we call artificial neurons they're inspired by the neurons you know we have in our",
    "start": "403009",
    "end": "410130"
  },
  {
    "text": "brain and you know it's very you know it's just inspired it's really not based",
    "start": "410130",
    "end": "415590"
  },
  {
    "text": "on it really but just to give some indication so our brains have around 100",
    "start": "415590",
    "end": "421860"
  },
  {
    "text": "billion neurons connected with around 1 quadrillion so that's 1,000 trillion synapses and that's what powers are a",
    "start": "421860",
    "end": "430319"
  },
  {
    "text": "lot of our both cognitive abilities and also more than that and if you look at",
    "start": "430319",
    "end": "439530"
  },
  {
    "text": "how this translates into artificial neurons in deep learning so again this",
    "start": "439530",
    "end": "445289"
  },
  {
    "text": "is just an inspiration because in fact the artificial neuron in deep learning",
    "start": "445289",
    "end": "450599"
  },
  {
    "text": "is much much simpler let's see if this works ok cool so we have a set of inputs",
    "start": "450599",
    "end": "457860"
  },
  {
    "text": "right which can be you know pixels in an image or some kind of other vector",
    "start": "457860",
    "end": "463740"
  },
  {
    "text": "representing our input it every input entry goes through weights and then there is a linear combination just a",
    "start": "463740",
    "end": "470130"
  },
  {
    "text": "simply a dot product between the vector of the inputs and a vector of the weights of that artifice pacific",
    "start": "470130",
    "end": "476190"
  },
  {
    "text": "artificial neuron dot product gives us some kind of scalar value which then goes through an activation function",
    "start": "476190",
    "end": "482820"
  },
  {
    "text": "which is nonlinear and then we get the value between 0 and 1 that's it it can",
    "start": "482820",
    "end": "489300"
  },
  {
    "text": "be framed in a very simple mathematical formula but that's pretty easy to",
    "start": "489300",
    "end": "494490"
  },
  {
    "text": "implement right that's the most basic notion that powers up and your network",
    "start": "494490",
    "end": "500639"
  },
  {
    "text": "and deep learning of course there's there's more but that's the basic that's the basic one and if we go from the artificial neuron",
    "start": "500639",
    "end": "508740"
  },
  {
    "start": "506000",
    "end": "506000"
  },
  {
    "text": "all all the way take a step back to the neural network then what we have in a neural network is really just a set of",
    "start": "508740",
    "end": "515550"
  },
  {
    "text": "layers each layer has a set of units",
    "start": "515550",
    "end": "522149"
  },
  {
    "text": "which are typically artificial neurons and every layer is interconnected to the next layer where every artificial neuron",
    "start": "522149",
    "end": "530430"
  },
  {
    "text": "in the input is connected to every other artificial urine in the output and then we have",
    "start": "530430",
    "end": "536480"
  },
  {
    "text": "many of these layers until we get to an output layer now the reason deep learning is termed as deep learning is because successful neural network are",
    "start": "536480",
    "end": "544040"
  },
  {
    "text": "those that are deep meaning they have lots of hidden layers right and just to give some indication one of the",
    "start": "544040",
    "end": "551630"
  },
  {
    "text": "state-of-the-art networks for image for object detection or for object",
    "start": "551630",
    "end": "557630"
  },
  {
    "text": "classification is called resident 1:52 it is 152 of these layers right so",
    "start": "557630",
    "end": "562790"
  },
  {
    "text": "that's what we call a a deep network we'll talk more about that in your network in a minute but that's the basic",
    "start": "562790",
    "end": "568910"
  },
  {
    "text": "idea behind your network of course there is much more there is layers like convolutional layers there is a",
    "start": "568910",
    "end": "574970"
  },
  {
    "text": "recurrent neural network with our NN unit and alasdairm units we won't go into that for now but that's the basic",
    "start": "574970",
    "end": "581600"
  },
  {
    "text": "idea now it's powerful first of all because it's nonlinear and really interesting and tough problem are usually modeling",
    "start": "581600",
    "end": "588070"
  },
  {
    "text": "non-linearity and with the activation function that I mentioned earlier that is in each artificial neuron with we get",
    "start": "588070",
    "end": "594560"
  },
  {
    "text": "a non-linearity which allows these models to model nonlinear problems it",
    "start": "594560",
    "end": "601310"
  },
  {
    "text": "has hierarchical feature learning in the sense that every layer here is feeds the",
    "start": "601310",
    "end": "608209"
  },
  {
    "text": "next layer which feeds the next layer which feeds the next layer this allows",
    "start": "608209",
    "end": "613760"
  },
  {
    "text": "for learning hierarchies of representations and I mean one intuition that is commonly used is you take some",
    "start": "613760",
    "end": "620300"
  },
  {
    "text": "kind of vision problem and every layer looks at different level of details in the input images the first layer will",
    "start": "620300",
    "end": "626959"
  },
  {
    "text": "just look at eight edges so very quick changes fast changes from in grayscale",
    "start": "626959",
    "end": "632990"
  },
  {
    "text": "values the next layer will actually combine different edges into what we call corners the next day will combine",
    "start": "632990",
    "end": "639110"
  },
  {
    "text": "corners into actually features in the image like if we're looking at face detection problem we look at you know",
    "start": "639110",
    "end": "644569"
  },
  {
    "text": "different features of the nose of the eyes etc and this hierarchy in learning",
    "start": "644569",
    "end": "651040"
  },
  {
    "text": "gives the neural network a lot of power because we can actually augment that hierarchy we can very easily add layers",
    "start": "651040",
    "end": "657440"
  },
  {
    "text": "we can add units in each layer to model more complex problems we can similarly reduce the complexity an expression",
    "start": "657440",
    "end": "664010"
  },
  {
    "text": "power of the net by reducing units reducing layers so as",
    "start": "664010",
    "end": "671060"
  },
  {
    "text": "I said this is the scalable architecture of the neural network and lastly it's very computationally intensive right I",
    "start": "671060",
    "end": "677780"
  },
  {
    "text": "spoke earlier about resident 152 which is used to be until recently a state of",
    "start": "677780",
    "end": "683360"
  },
  {
    "text": "the art network for object classification just one forward pass to",
    "start": "683360",
    "end": "688640"
  },
  {
    "text": "resonate 152 so taking an input of an image and getting all the way through the network until you get an output",
    "start": "688640",
    "end": "694390"
  },
  {
    "text": "takes a few billion floating-point operations just one pass now imagine if",
    "start": "694390",
    "end": "700580"
  },
  {
    "text": "you have you know serious production service serving maybe hundreds or",
    "start": "700580",
    "end": "707510"
  },
  {
    "text": "thousands of requests per second imagine the computational load on your back-end right so that's one you know",
    "start": "707510",
    "end": "715880"
  },
  {
    "text": "downside potentially of deep learning but with the amazing growth in the",
    "start": "715880",
    "end": "723050"
  },
  {
    "text": "capabilities of GPUs and also CPUs but primarily GPUs this this need is being",
    "start": "723050",
    "end": "730100"
  },
  {
    "text": "addressed rapidly okay by the way feel free to raise your hand if you have",
    "start": "730100",
    "end": "736520"
  },
  {
    "start": "735000",
    "end": "735000"
  },
  {
    "text": "questions happy to answer to you we also reserve some time at the end of the talk for more questions but if you want to",
    "start": "736520",
    "end": "743000"
  },
  {
    "text": "ask a question in context feel free okay now I want to talk to you about why deep learning is a big deal it has a growing",
    "start": "743000",
    "end": "750590"
  },
  {
    "text": "impact on our lives already if you look only in Amazon personalization logistics",
    "start": "750590",
    "end": "755840"
  },
  {
    "text": "voice autonomous vehicles in Amazon in case it's drones major aspects of how",
    "start": "755840",
    "end": "763400"
  },
  {
    "text": "these things work already today is powered by deep learning and if you look",
    "start": "763400",
    "end": "771230"
  },
  {
    "text": "outside of Amazon the revolution of self-driving cars is enabled a lot of it",
    "start": "771230",
    "end": "778040"
  },
  {
    "text": "is enabled through deep learning and there's lots of other examples so it's already impacting our lives and lastly",
    "start": "778040",
    "end": "783620"
  },
  {
    "text": "there is another reason why it's a big deal and it is how well it does compared",
    "start": "783620",
    "end": "788960"
  },
  {
    "text": "to other alternatives I mentioned object classification as",
    "start": "788960",
    "end": "796400"
  },
  {
    "text": "anyone here heard of imagenet competition okay so not",
    "start": "796400",
    "end": "801870"
  },
  {
    "text": "everyone is aware but in Madrid competition is a competition that happens every year I think they actually stopped it because the problem is",
    "start": "801870",
    "end": "807180"
  },
  {
    "text": "effectively being solved and that problem is of object classification given an input image and a set of 1000",
    "start": "807180",
    "end": "814800"
  },
  {
    "text": "classes identify the most prominent object in that image out of the classes",
    "start": "814800",
    "end": "821070"
  },
  {
    "text": "available right so in this case we have an image of a cat lying on bed what is",
    "start": "821070",
    "end": "827699"
  },
  {
    "text": "that object for assumes it's very easy right it's a cat this is to be very hard",
    "start": "827699",
    "end": "833639"
  },
  {
    "text": "problem in computer science and computer vision until the deep learning revolution of that problem is considered",
    "start": "833639",
    "end": "839310"
  },
  {
    "text": "to be solved and this just shows for this input an example of the output by",
    "start": "839310",
    "end": "845220"
  },
  {
    "text": "an algorithm and it says number one probability tabby tabby cat 57 percent",
    "start": "845220",
    "end": "850620"
  },
  {
    "text": "and and as the others interesting to you look at number five toilet seat one point six six percent but that's",
    "start": "850620",
    "end": "857670"
  },
  {
    "text": "probably not state-of-the-art results anyway so anyway that that's that's the object less if occasion now I think what's interesting is that first of all",
    "start": "857670",
    "end": "865560"
  },
  {
    "text": "in 2012 a deep learning based model from",
    "start": "865560",
    "end": "870600"
  },
  {
    "text": "Alex Khrushchev's key University of Toronto was able to beat the best algorithm to date by I think something",
    "start": "870600",
    "end": "876269"
  },
  {
    "text": "like thirty percent which was unheard of in terms of the improvement because until that time improvements in that",
    "start": "876269",
    "end": "883230"
  },
  {
    "text": "competition were you know in fraction of percentages so that was a big thing since 2012 every year the winner of that",
    "start": "883230",
    "end": "889380"
  },
  {
    "text": "competition is based on your networks but beyond deep learning beating the",
    "start": "889380",
    "end": "895620"
  },
  {
    "text": "other machine learning and machine vision techniques the idea interesting aspect is how well deep learning does",
    "start": "895620",
    "end": "901170"
  },
  {
    "text": "compared to us humans so this is a I took the screenshot out of a research",
    "start": "901170",
    "end": "906360"
  },
  {
    "text": "published last year which actually tries to measure that so they compared neural",
    "start": "906360",
    "end": "913319"
  },
  {
    "text": "networks for object classification actually none of these Alex net that's the one from 2012 Google net is maybe",
    "start": "913319",
    "end": "919829"
  },
  {
    "text": "twenty fourteen vdd 16 2015 none of this is state-of-the-art today but it",
    "start": "919829",
    "end": "925529"
  },
  {
    "text": "compared these networks to humans as you can see here where these humans around eighty seven percent",
    "start": "925529",
    "end": "931769"
  },
  {
    "text": "accuracy and look at these models so",
    "start": "931769",
    "end": "936979"
  },
  {
    "text": "point being deep learning is also doing better than humans and more and more tasks so deep learning is a big deal I",
    "start": "936979",
    "end": "946439"
  },
  {
    "text": "hope you would agree with me now",
    "start": "946439",
    "end": "949789"
  },
  {
    "text": "so the question is how did the comparison in the study work I'll give a",
    "start": "962960",
    "end": "969170"
  },
  {
    "text": "brief answer they took a problem similar to Aubry classification they took a set",
    "start": "969170",
    "end": "974300"
  },
  {
    "text": "of images let a set of humans look at it and provide their identification of the",
    "start": "974300",
    "end": "980360"
  },
  {
    "text": "different classes and fed the same images to different models and then compared the results for accuracy so",
    "start": "980360",
    "end": "986149"
  },
  {
    "text": "similar problem to this it wasn't the image net data set though it was a different set of images so now you agree",
    "start": "986149",
    "end": "994700"
  },
  {
    "text": "with me hopefully the deepening is a big deal it does better than machine learning techniques other machine learning techniques and humans and now",
    "start": "994700",
    "end": "1001240"
  },
  {
    "text": "you want to just go ahead and use it in production right okay because that's a",
    "start": "1001240",
    "end": "1007450"
  },
  {
    "start": "1005000",
    "end": "1005000"
  },
  {
    "text": "whole purpose of this stuff how do you use it in production so maybe we can start with the question ok so what does",
    "start": "1007450",
    "end": "1013209"
  },
  {
    "text": "the deployed model look like right how does you know what does it mean to take a model and deploy it to production",
    "start": "1013209",
    "end": "1018300"
  },
  {
    "text": "actually it's not very different than taking a web application and deploying into production first of all we have our",
    "start": "1018300",
    "end": "1023740"
  },
  {
    "text": "model and on the other end we have a bunch of clients that want to be able to call that model for prediction or for",
    "start": "1023740",
    "end": "1030069"
  },
  {
    "text": "inference this can be mobile desktop IOT other cloud services deploying model to",
    "start": "1030069",
    "end": "1037449"
  },
  {
    "text": "production basically means having a system in place that on one hand encapsulate that model or accesses that",
    "start": "1037449",
    "end": "1045010"
  },
  {
    "text": "model and then on the other end through the internet exposes an endpoint that these clients can call yeah that's very",
    "start": "1045010",
    "end": "1051940"
  },
  {
    "text": "simply put oh and maybe we want to see this set of boxes some kind of ability",
    "start": "1051940",
    "end": "1057370"
  },
  {
    "text": "to scale out right if our production service gets more and more traffic we want to scale out so we can still keep",
    "start": "1057370",
    "end": "1064840"
  },
  {
    "text": "low latency high throughput and address all of the needs so that's basically what what it means when we say deploying",
    "start": "1064840",
    "end": "1070900"
  },
  {
    "text": "a model to production it's really an engineering problem what so going into",
    "start": "1070900",
    "end": "1078850"
  },
  {
    "text": "more details there is what we call the undifferentiated heavy lifting of model serving right and by the way a lot of",
    "start": "1078850",
    "end": "1084400"
  },
  {
    "text": "AWS is based on the idea of handling undifferentiated heavy lifting making",
    "start": "1084400",
    "end": "1089590"
  },
  {
    "text": "developers not worry about you know setting up instances or hosts configuring them patching them",
    "start": "1089590",
    "end": "1096030"
  },
  {
    "text": "configuring networks all that stuff is undifferentiated every lifting us developers want to focus on the business",
    "start": "1096030",
    "end": "1102400"
  },
  {
    "text": "value you are adding AWS can solve out of the problem of you know just the set",
    "start": "1102400",
    "end": "1107890"
  },
  {
    "text": "up for you the infrastructure etc so monitoring also includes a lot of undifferentiated heavy lifting includes",
    "start": "1107890",
    "end": "1113890"
  },
  {
    "text": "things like performance we want to ensure the best performance just like when you use a web server you want that",
    "start": "1113890",
    "end": "1119110"
  },
  {
    "start": "1114000",
    "end": "1114000"
  },
  {
    "text": "web server to give you the best performance in rendering your web application with model serving you'd want that",
    "start": "1119110",
    "end": "1124900"
  },
  {
    "text": "server framework to squeeze out the best performance possible out of the boxes it",
    "start": "1124900",
    "end": "1131169"
  },
  {
    "text": "runs on availability right when you update your models you want the system",
    "start": "1131169",
    "end": "1137320"
  },
  {
    "text": "to maintain still high availability you don't want users to experience system being down you want the system to",
    "start": "1137320",
    "end": "1142990"
  },
  {
    "text": "automatically use networking to expose HTTP endpoints to expose rest interfaces you want to get monitoring so you know",
    "start": "1142990",
    "end": "1150400"
  },
  {
    "text": "how your service is doing you can get alerts or alarms when you know maybe latency thresholds or being going out of",
    "start": "1150400",
    "end": "1160510"
  },
  {
    "text": "the range or configuring you want to know how many requests are coming in how many requests are entering out etc very",
    "start": "1160510",
    "end": "1168130"
  },
  {
    "text": "importantly want to decouple your model from the actual serving infrastructure right we want the same server framework",
    "start": "1168130",
    "end": "1174700"
  },
  {
    "text": "to be able to serve model for identifying cuts in images or synthesizing speech or do other things",
    "start": "1174700",
    "end": "1181000"
  },
  {
    "text": "you don't want your model to be baked into your framework you want it the couple just like any good software",
    "start": "1181000",
    "end": "1187059"
  },
  {
    "text": "system and lastly you want it to support multiple frameworks because there's multiple frameworks out there right more",
    "start": "1187059",
    "end": "1193390"
  },
  {
    "text": "than just tensorflow or MX net and your data scientists or engineers might want",
    "start": "1193390",
    "end": "1199929"
  },
  {
    "text": "to use different frameworks for different models and you also want it cross-platform some services you might want to enable",
    "start": "1199929",
    "end": "1206290"
  },
  {
    "text": "to run on GPUs because it's more performant more cost-effective that way while others you might want to run on",
    "start": "1206290",
    "end": "1211630"
  },
  {
    "text": "CPUs you want that survey framework to handle all of that for you you don't want to handle it yourself because you",
    "start": "1211630",
    "end": "1217240"
  },
  {
    "text": "want to focus around your actual business problem that you're solving I'm",
    "start": "1217240",
    "end": "1223990"
  },
  {
    "text": "going to show you how model Suva for a mix net which is an open source solution by AWS not",
    "start": "1223990",
    "end": "1229270"
  },
  {
    "text": "my team contributes to how it addresses all of that and more and again at the end of this talk I want you to be able",
    "start": "1229270",
    "end": "1236350"
  },
  {
    "text": "within 10 to 15 minutes to actually take a model and just host it for inference yourselves so first I'll talk to you",
    "start": "1236350",
    "end": "1245260"
  },
  {
    "text": "about MX net who here is familiar with MX net okay who is familiar with",
    "start": "1245260",
    "end": "1253600"
  },
  {
    "text": "tensorflow okay cool so MX net is very",
    "start": "1253600",
    "end": "1259330"
  },
  {
    "text": "similar to tensorflow it's a it's an Apache open-source project that allows you to build train",
    "start": "1259330",
    "end": "1265480"
  },
  {
    "text": "and deploy a neural networks DNS deep",
    "start": "1265480",
    "end": "1270610"
  },
  {
    "text": "neural networks it was created originally by the academia as a collaboration between students at CMU",
    "start": "1270610",
    "end": "1276970"
  },
  {
    "text": "and university of washington and ada bless adopted it at some time 2016 as",
    "start": "1276970",
    "end": "1283210"
  },
  {
    "text": "the deep learning framework of choice now AWS it's very important to to you know",
    "start": "1283210",
    "end": "1289330"
  },
  {
    "text": "clearly stress that AWS supports whatever framework you the developers at",
    "start": "1289330",
    "end": "1294880"
  },
  {
    "start": "1292000",
    "end": "1292000"
  },
  {
    "text": "the rest users want to use and we make sure tends to flow care as MX net pi torch and other framework runs super",
    "start": "1294880",
    "end": "1301750"
  },
  {
    "text": "well on AWS who actually optimize all of these frameworks to run very fast on AWS but we support MX net because you",
    "start": "1301750",
    "end": "1310450"
  },
  {
    "text": "believe it adds a lot of value for customers who choose to use it right the",
    "start": "1310450",
    "end": "1315940"
  },
  {
    "text": "main reason why the Blessed chose MX net is because it's immensely scalable right",
    "start": "1315940",
    "end": "1321400"
  },
  {
    "text": "which goes well with our notion at AWS of giving the users best bang for their",
    "start": "1321400",
    "end": "1326680"
  },
  {
    "text": "buck in terms of how much performance you can squeeze out of your the hardware you use the infrastructure you used on",
    "start": "1326680",
    "end": "1332980"
  },
  {
    "text": "AWS so a bit more about the highlights of MX net ease of use it supports both",
    "start": "1332980",
    "end": "1338350"
  },
  {
    "start": "1335000",
    "end": "1335000"
  },
  {
    "text": "imperative symbolic and dynamic KPIs across different languages like Python",
    "start": "1338350",
    "end": "1343780"
  },
  {
    "text": "we have Scala API we're going to introduce the Java API as soon we have a C API we have a C++ most of these are",
    "start": "1343780",
    "end": "1352270"
  },
  {
    "text": "actually contributed by the open source community recently the open source community contributed closure API for MX",
    "start": "1352270",
    "end": "1359500"
  },
  {
    "text": "net which is pretty cool and there's a bunch of examples tutorials for the api's and for to do",
    "start": "1359500",
    "end": "1365080"
  },
  {
    "text": "training on one machine or multiple GPUs etc performance is one of the highlights",
    "start": "1365080",
    "end": "1370990"
  },
  {
    "text": "of MX net there's a lot of research or papers out there by different users",
    "start": "1370990",
    "end": "1376380"
  },
  {
    "text": "comparing you know different neural network frameworks like MX net to care us to do tensor flow we've seen most of",
    "start": "1376380",
    "end": "1384610"
  },
  {
    "text": "them that MX net performs better in most cases so scalability and performance is",
    "start": "1384610",
    "end": "1392620"
  },
  {
    "text": "one of the highlights of MX net and it also supports advanced features around performance like quantization spars and",
    "start": "1392620",
    "end": "1401920"
  },
  {
    "text": "other things and portability with MX net you can train on the cloud and predict",
    "start": "1401920",
    "end": "1407440"
  },
  {
    "text": "on edge and accent actually has versions of binaries that you can run on arm CPUs",
    "start": "1407440",
    "end": "1413820"
  },
  {
    "text": "we have a model serving framework that I'm talking to you about now and it has built in onyx support who here heard",
    "start": "1413820",
    "end": "1420430"
  },
  {
    "text": "about onyx ok I talk more about onyx later but it's an industry initiative",
    "start": "1420430",
    "end": "1426310"
  },
  {
    "text": "that AWS is also involved in together with Microsoft and Facebook and other companies to provide an interchangeable",
    "start": "1426310",
    "end": "1432790"
  },
  {
    "text": "format for neural networks that you can just use across different frameworks so we'll talk more about that",
    "start": "1432790",
    "end": "1439050"
  },
  {
    "start": "1439000",
    "end": "1439000"
  },
  {
    "text": "so at Amex net M except model server is a machine learning model server",
    "start": "1439050",
    "end": "1444070"
  },
  {
    "text": "addresses the needs I described earlier it serves MX net and onyx models it's",
    "start": "1444070",
    "end": "1449350"
  },
  {
    "text": "based on MX net is the underlying engine it automates the HTTP endpoint set up for you he taught of scales to all of",
    "start": "1449350",
    "end": "1455980"
  },
  {
    "text": "the available cpus and gpus you have it has pre-built and pre-configured containers you can just pull and run and",
    "start": "1455980",
    "end": "1463510"
  },
  {
    "text": "it has a command line interface to package model artifacts for serving I'll show you guys all of that in a bunch of",
    "start": "1463510",
    "end": "1468580"
  },
  {
    "text": "demos and also point you to resources you can use later to follow up yourself",
    "start": "1468580",
    "end": "1473650"
  },
  {
    "text": "and lastly it's an open source project and there are WS labs you can follow that URL model server dot IO you can",
    "start": "1473650",
    "end": "1480790"
  },
  {
    "text": "contribute code you can file issues you can ask questions we're happy to work",
    "start": "1480790",
    "end": "1487120"
  },
  {
    "text": "with you guys to make you successful with that ok it's demo time",
    "start": "1487120",
    "end": "1494790"
  },
  {
    "text": "I start with a quick demo of using a model server so I pre-recorded this",
    "start": "1495110",
    "end": "1503510"
  },
  {
    "text": "because you know demo is live demos never work yeah we have a question so",
    "start": "1503510",
    "end": "1516890"
  },
  {
    "text": "the question is if I choose frame okay maybe IMAX net what's the cost of me later migrating to another framework",
    "start": "1516890",
    "end": "1522770"
  },
  {
    "text": "framework being this it's a great question it really depends on the actual",
    "start": "1522770",
    "end": "1528590"
  },
  {
    "text": "model you're using and about things like whether the framework a support something like onyx",
    "start": "1528590",
    "end": "1534669"
  },
  {
    "text": "but based on my experience I'm seeing many practitioners edibles customers",
    "start": "1534669",
    "end": "1540710"
  },
  {
    "text": "using deep learning that have expertise and use multiple frameworks and they move between these frameworks although",
    "start": "1540710",
    "end": "1546799"
  },
  {
    "text": "having said that taking a modeling frame okay and translating it to framework P is not always a trivial task but it",
    "start": "1546799",
    "end": "1553880"
  },
  {
    "text": "really depends on your model if your model is simple enough and uses the basic building blocks that you know are",
    "start": "1553880",
    "end": "1559309"
  },
  {
    "text": "kind of mostly the same across frameworks that would be easy if you have complex models with that's a custom",
    "start": "1559309",
    "end": "1564919"
  },
  {
    "text": "operators custom layers is going to be a bit more investment to migrate okay you",
    "start": "1564919",
    "end": "1570230"
  },
  {
    "text": "feel free to drop by later on it we can talk more about that okay on to the demo",
    "start": "1570230",
    "end": "1575690"
  },
  {
    "text": "so we'll show you how to basically start using the model server now installing it is very easy just do a pip install MX",
    "start": "1575690",
    "end": "1582950"
  },
  {
    "text": "net model server that's it we use pi PI pythons packaging management tool to",
    "start": "1582950",
    "end": "1590360"
  },
  {
    "text": "pull in all of the dependencies and install model server and that's it you're done now if we do a peepshow MX",
    "start": "1590360",
    "end": "1599299"
  },
  {
    "text": "net model server we can see that it's installed and we can see this is version",
    "start": "1599299",
    "end": "1604610"
  },
  {
    "text": "zero one five it's a bit old version the latest version is 0.4 1.0 is coming",
    "start": "1604610",
    "end": "1610040"
  },
  {
    "text": "really soon but for the sake of the demo nothing changes it's still the same functionality in terms of how you use it",
    "start": "1610040",
    "end": "1617320"
  },
  {
    "text": "now now that we have it installed let's look at the CLI the command line interface so if we do a max net model",
    "start": "1617320",
    "end": "1623419"
  },
  {
    "text": "server - H we can see the different parameters we can use and there's really a bunch of them I",
    "start": "1623419",
    "end": "1629430"
  },
  {
    "text": "won't go over each and every one there is not enough time but really the important one is the - - models which is",
    "start": "1629430",
    "end": "1641480"
  },
  {
    "text": "this guy which allows us to specify key value pair for the different models we",
    "start": "1641480",
    "end": "1646920"
  },
  {
    "text": "want to deploy now we can deploy multiple models in the same server instance we give each model a key name",
    "start": "1646920",
    "end": "1652920"
  },
  {
    "text": "and then the value is a model archive that's a package that encapsulate everything we need to run our model",
    "start": "1652920",
    "end": "1659760"
  },
  {
    "text": "we'll look into that in more details now if you want to just use models to try it",
    "start": "1659760",
    "end": "1665040"
  },
  {
    "text": "out we actually have what we call a model Zoo on the github repository so if",
    "start": "1665040",
    "end": "1670500"
  },
  {
    "text": "you go to AWS labs MX net model server there's nice documentation explaining",
    "start": "1670500",
    "end": "1677790"
  },
  {
    "text": "everything I'm just talking to you about now but probably in much more details but one of the things you have there",
    "start": "1677790",
    "end": "1684090"
  },
  {
    "text": "under the docs folder is also a model zoo markdown file which contains a bunch of different models you can just go",
    "start": "1684090",
    "end": "1690390"
  },
  {
    "text": "ahead and use since I took this screencast that list is actually grown",
    "start": "1690390",
    "end": "1696390"
  },
  {
    "text": "there's pretty cool models there but in this example we start with a very simple model for image classification called",
    "start": "1696390",
    "end": "1702030"
  },
  {
    "text": "squeeze net I'm using it for the demo because it's only five Meg's in size it was designed for mobile devices where",
    "start": "1702030",
    "end": "1708510"
  },
  {
    "text": "you might not have a lot of space on the device we want to keep it small and the",
    "start": "1708510",
    "end": "1714300"
  },
  {
    "text": "models do you have a complete example of how to how to use it and we just do it",
    "start": "1714300",
    "end": "1719580"
  },
  {
    "text": "now so we start by just copying the URL to the model archive that dot model file",
    "start": "1719580",
    "end": "1725400"
  },
  {
    "text": "that's just the URL on s3 where that file is ID and to host and serve our",
    "start": "1725400",
    "end": "1731070"
  },
  {
    "text": "model we very simply do a mcsnack model server - - models squeeze net is the key",
    "start": "1731070",
    "end": "1736410"
  },
  {
    "text": "name we're choosing and then the URL hit enter and that's it MMS will fetch that model and pack it",
    "start": "1736410",
    "end": "1742830"
  },
  {
    "text": "locally and configure the endpoints configure the model configure a max net and everything is ready for us to",
    "start": "1742830",
    "end": "1749910"
  },
  {
    "text": "actually serve the model you can see running on localhost port 8080 which is the default toast important and now",
    "start": "1749910",
    "end": "1756240"
  },
  {
    "text": "let's do a curl command just to make sure our server is running Soaker localhost port 8080 slash bin that's an endpoint",
    "start": "1756240",
    "end": "1762789"
  },
  {
    "text": "for pinging and we can see we got a JSON response health healthy cool now it's",
    "start": "1762789",
    "end": "1769299"
  },
  {
    "text": "actually try to do a prediction so this is an image classification model it expects images as input will do a curl",
    "start": "1769299",
    "end": "1777909"
  },
  {
    "text": "command to download an image of guess what a cat we're following the tradition",
    "start": "1777909",
    "end": "1786759"
  },
  {
    "text": "of all the examples in deep learning involving cats and dogs so we just download the image we can open it just",
    "start": "1786759",
    "end": "1792429"
  },
  {
    "text": "to make sure it's indeed an image of a cat and yep it is an image of a cat and",
    "start": "1792429",
    "end": "1798909"
  },
  {
    "text": "now we want to do prediction so again we can use curl now what's nice about motor server it also handles the data",
    "start": "1798909",
    "end": "1804700"
  },
  {
    "text": "translation for you so you know neural networks they don't handle JPEG images they handle tensors right which is",
    "start": "1804700",
    "end": "1809860"
  },
  {
    "text": "multidimensional arrays but we can end our quest we can actually provide a JPEG",
    "start": "1809860",
    "end": "1815889"
  },
  {
    "text": "image to model server and it will convert it automatically into a tensor so we do curl - exposed squeezed net /",
    "start": "1815889",
    "end": "1823629"
  },
  {
    "text": "predict and then we just attach the image to the request we do data equals",
    "start": "1823629",
    "end": "1831639"
  },
  {
    "text": "at kitten dodge a JPEG and curl we'll make sure to include that and voila was",
    "start": "1831639",
    "end": "1838269"
  },
  {
    "text": "pretty fast but we got a prediction result and we can see that 85% probability that this is an Egyptian cat",
    "start": "1838269",
    "end": "1844269"
  },
  {
    "text": "I don't know what an Egyptian cat means but I trust the a model right it says it better than humans so alright so that",
    "start": "1844269",
    "end": "1853119"
  },
  {
    "text": "was the demo that's it I hope you see how easy it is to run into hosts models",
    "start": "1853119",
    "end": "1858450"
  },
  {
    "text": "there's a bit more complexity than that but are there any questions so far yeah",
    "start": "1858450",
    "end": "1867450"
  },
  {
    "text": "can you repeat the question take this and put it into your product how would you then take this exact model",
    "start": "1869549",
    "end": "1876490"
  },
  {
    "text": "exactly and then put into production what's your recommendation that's that's a great that's a great question",
    "start": "1876490",
    "end": "1881590"
  },
  {
    "text": "so so far if this dam was actually running I when I took the screencast actually ran it on my Mac you can take",
    "start": "1881590",
    "end": "1887860"
  },
  {
    "text": "exactly the same steps and run it on an ec2 instance actually it's already available for you on AWS DL ami the deep",
    "start": "1887860",
    "end": "1895150"
  },
  {
    "text": "learning AMI and it will work that can be your server however for production use cases where you expect the scale of you know tens or",
    "start": "1895150",
    "end": "1901809"
  },
  {
    "text": "hundreds of requests per second we recommend to use containers and we actually have a pretty build",
    "start": "1901809",
    "end": "1907270"
  },
  {
    "text": "pre-configured container images for you you can use we'll go over that in a minute okay all right let's go back to",
    "start": "1907270",
    "end": "1914169"
  },
  {
    "text": "our presentation okay",
    "start": "1914169",
    "end": "1922350"
  },
  {
    "text": "so I'll go over a few aspects of how you use the model server the first one is",
    "start": "1922350",
    "end": "1927940"
  },
  {
    "text": "the model archive mother Rock I was actually a key part because if you remember when we started model server we",
    "start": "1927940",
    "end": "1933340"
  },
  {
    "text": "gave it a key value pair the key was just the key name for the model the valley was URL it can also be a local",
    "start": "1933340",
    "end": "1939340"
  },
  {
    "text": "file system path for the model and that was pointing at the model archive but",
    "start": "1939340",
    "end": "1944620"
  },
  {
    "text": "what does this model archive actually means so we'll go over that in a minute so first of all it's a package a single",
    "start": "1944620",
    "end": "1950679"
  },
  {
    "start": "1947000",
    "end": "1947000"
  },
  {
    "text": "file that encapsulate a few things one way to think about it similar to a Java jar right the jar is a Java archive it",
    "start": "1950679",
    "end": "1957400"
  },
  {
    "text": "contains a bunch of things the Java needs in order to run your program so similarly a model archive we can maybe",
    "start": "1957400",
    "end": "1963820"
  },
  {
    "text": "call it mr but I don't know contains that everything the model server needs to run our model so first and foremost",
    "start": "1963820",
    "end": "1970059"
  },
  {
    "text": "it contains a train network right and there's a bunch of layers the parameters",
    "start": "1970059",
    "end": "1975640"
  },
  {
    "text": "the weights right that are associated with each artificial neuron in that layer it's all part of the network",
    "start": "1975640",
    "end": "1981179"
  },
  {
    "text": "beyond that it contains what we call a model signature model signature is simply a JSON file telling model server",
    "start": "1981179",
    "end": "1987370"
  },
  {
    "text": "what's our expected input of the model and expected output some other server can set up the HTTP endpoints request",
    "start": "1987370",
    "end": "1994750"
  },
  {
    "text": "handlers and response handler appropriately it contains potentially you don't have to add it but if you want",
    "start": "1994750",
    "end": "2001080"
  },
  {
    "text": "you can add custom and what we've learned internally in Amazon also speaking to their best customers real-world production models",
    "start": "2001080",
    "end": "2008250"
  },
  {
    "text": "always need some kind of pre-processing and post-processing code there's always image normalization to do",
    "start": "2008250",
    "end": "2014929"
  },
  {
    "text": "request validation to do there's different things you want to do and we",
    "start": "2014929",
    "end": "2020130"
  },
  {
    "text": "give you the ability to do that just by providing Python code we'll go over that in a minute and also you can include",
    "start": "2020130",
    "end": "2025559"
  },
  {
    "text": "whatever other auxiliary assets many Rosalia files you may want we don't mono",
    "start": "2025559",
    "end": "2032370"
  },
  {
    "text": "server doesn't hold you back and put whatever you want there usually you would put their assets that your custom",
    "start": "2032370",
    "end": "2038850"
  },
  {
    "text": "code needs at runtime we will show an example to that once you have all of these you just use the model export CLI",
    "start": "2038850",
    "end": "2045240"
  },
  {
    "text": "so that's a command line interface of model server to package everything up into a model archive now I'll tell you a",
    "start": "2045240",
    "end": "2050398"
  },
  {
    "text": "small secret this model archive is nothing but a zip file ok by the way",
    "start": "2050399",
    "end": "2056429"
  },
  {
    "text": "Java jar the job archive is exactly the same it's a zip file it's a zip file containing all of these assets plus some",
    "start": "2056429",
    "end": "2063290"
  },
  {
    "text": "manifest that is automatically generated web model server some other server knows how to parse the archive like you know",
    "start": "2063290",
    "end": "2069118"
  },
  {
    "text": "versioning and other information and that's it let's see how how this looks",
    "start": "2069119",
    "end": "2076020"
  },
  {
    "text": "[Music] how is the model archive",
    "start": "2076020",
    "end": "2083088"
  },
  {
    "text": "okay so this shows the directory squeeze",
    "start": "2089070",
    "end": "2095010"
  },
  {
    "text": "net and you can see the different assets there and we'll go over one by one so first one is quiz net we want one one",
    "start": "2095010",
    "end": "2100920"
  },
  {
    "text": "symbol adjacent that's MX net definition of the neural networks we don't need to dive into the",
    "start": "2100920",
    "end": "2108780"
  },
  {
    "text": "details here but it's just a simple JSON file saying okay what are the different layers in my network what are the",
    "start": "2108780",
    "end": "2113960"
  },
  {
    "text": "attributes of every layer you can see an activation function of type real oh and there's all of that you get that",
    "start": "2113960",
    "end": "2121380"
  },
  {
    "text": "automatically when you save an MX net model e-train into file okay next we",
    "start": "2121380",
    "end": "2128190"
  },
  {
    "text": "have the the signature that I mentioned earlier so it's very simple just a JSON",
    "start": "2128190",
    "end": "2134400"
  },
  {
    "text": "file saying okay these are my inputs my input node name is data it expects an",
    "start": "2134400",
    "end": "2139830"
  },
  {
    "text": "image of size 224 by 224 my output is a soft Max and oh this room is fast we",
    "start": "2139830",
    "end": "2148650"
  },
  {
    "text": "quickly go back",
    "start": "2148650",
    "end": "2151609"
  },
  {
    "text": "so my input data shape is 0-3 224 by 224",
    "start": "2156700",
    "end": "2162920"
  },
  {
    "text": "it's just a RGB representation of a 224 by 224 image that's the tensor my",
    "start": "2162920",
    "end": "2168740"
  },
  {
    "text": "network expect but we also tell the model server hey expect an input type of JPEG with that model server know is that",
    "start": "2168740",
    "end": "2175790"
  },
  {
    "text": "incoming requests should have a JPEG mime type is an attachment and convert that into the tensor to fit into the",
    "start": "2175790",
    "end": "2181850"
  },
  {
    "text": "network right and then the output the",
    "start": "2181850",
    "end": "2187040"
  },
  {
    "text": "output node name is softmax it will have a shape of 0 1000 because there's 1000",
    "start": "2187040",
    "end": "2193190"
  },
  {
    "text": "classes in image net right 1000 different classes and the output tab to",
    "start": "2193190",
    "end": "2198350"
  },
  {
    "text": "return over the wire is Jason okay that's how with this simple Jason file to actually explain to the model server",
    "start": "2198350",
    "end": "2204470"
  },
  {
    "text": "what kind of input to expend point to expose and how to do the basic pre-processing and request handling and",
    "start": "2204470",
    "end": "2210560"
  },
  {
    "text": "response handling for that model next",
    "start": "2210560",
    "end": "2218450"
  },
  {
    "text": "let's open a auxilary file called scene set of txt this is an auxilary file we",
    "start": "2218450",
    "end": "2223760"
  },
  {
    "text": "add which basically contains all of the image net classes that 1000 classes that the algorithm identifies objects based",
    "start": "2223760",
    "end": "2230300"
  },
  {
    "text": "on and you can see for example tabby tabby cat and most importantly probably",
    "start": "2230300",
    "end": "2237230"
  },
  {
    "text": "our custom code okay so this is the custom code you're providing for this service explain this just in a bit",
    "start": "2237230",
    "end": "2246170"
  },
  {
    "text": "details so you can see it's a Python code the class MX night-vision service",
    "start": "2246170",
    "end": "2252860"
  },
  {
    "text": "extends MX net-based service and with",
    "start": "2252860",
    "end": "2258260"
  },
  {
    "text": "the custom code we need to extend the base service and we need to override a few class methods if we want to do some",
    "start": "2258260",
    "end": "2266840"
  },
  {
    "text": "things like if you want to do pre-processing will override the pre process method and we can see in this example this code of the pre process",
    "start": "2266840",
    "end": "2273950"
  },
  {
    "text": "basically takes the the image reads it resizes it transforms the shape into",
    "start": "2273950",
    "end": "2280160"
  },
  {
    "text": "what the model expects we have the pre process method which basically does",
    "start": "2280160",
    "end": "2289250"
  },
  {
    "text": "probability meaning the our model returns the probability for each one of",
    "start": "2289250",
    "end": "2294860"
  },
  {
    "text": "these 1,000 Tessa's but our users don't really need 1,000 classes right they maybe want to top what we call top k so",
    "start": "2294860",
    "end": "2301550"
  },
  {
    "text": "top 5 in this case so this basically one line of code basically takes sorts the response",
    "start": "2301550",
    "end": "2307220"
  },
  {
    "text": "attaches the names of the labels from the since that file we've seen earlier and it turns that to the user over the",
    "start": "2307220",
    "end": "2314300"
  },
  {
    "text": "HTTP response that makes sense yeah it's",
    "start": "2314300",
    "end": "2331430"
  },
  {
    "text": "a great question so the question is does not the server stores the incoming image to fire before it processes it no so",
    "start": "2331430",
    "end": "2343130"
  },
  {
    "text": "mother server handles that for you in the pre process you have the data argument that includes all of the",
    "start": "2343130",
    "end": "2349010"
  },
  {
    "text": "incoming parameters within the request heat you can in your custom code save it",
    "start": "2349010",
    "end": "2354140"
  },
  {
    "text": "to file if you want you should have a good reason to do it because it will kill your performance so it's all in",
    "start": "2354140",
    "end": "2360020"
  },
  {
    "text": "memory by default it's all in memory okay that's a good question by the way",
    "start": "2360020",
    "end": "2365090"
  },
  {
    "text": "we've encountered the issue with the software stack we're using here where one of the layers we're using was",
    "start": "2365090",
    "end": "2370580"
  },
  {
    "text": "actually storing files from a given size into file and we've actually optimized that away so that's a very relevant",
    "start": "2370580",
    "end": "2377510"
  },
  {
    "text": "question okay and basically that's it",
    "start": "2377510",
    "end": "2382880"
  },
  {
    "text": "now we have all these files what we do next what we do next is want to use the",
    "start": "2382880",
    "end": "2392150"
  },
  {
    "text": "export utility so we do a max net model export model name we give it the name SN",
    "start": "2392150",
    "end": "2397640"
  },
  {
    "text": "force quiz net model path dot because it's the local file system and that's it",
    "start": "2397640",
    "end": "2402950"
  },
  {
    "text": "model survey we'll create a dot model file for us you can see it here it's",
    "start": "2402950",
    "end": "2407960"
  },
  {
    "text": "around 50 Meg's most of it is just the parameters of the network because that's",
    "start": "2407960",
    "end": "2415330"
  },
  {
    "text": "that's what's really heavy about your networks is the parameters you can see forty-nine point four MB so",
    "start": "2415330",
    "end": "2422390"
  },
  {
    "text": "4.9 MB is the squeeze net v11 params right that's the binary parameters using",
    "start": "2422390",
    "end": "2428150"
  },
  {
    "text": "the network and our model archive in total is 5.0 1 MB all most of it is just",
    "start": "2428150",
    "end": "2434000"
  },
  {
    "text": "the parameters but of course in terms of logic everything else is super important and we have a model archive and we can",
    "start": "2434000",
    "end": "2443480"
  },
  {
    "text": "serve that very easily like we've seen earlier a max net mother server - - models SN equals s n dot model we're",
    "start": "2443480",
    "end": "2451250"
  },
  {
    "text": "providing here a local file system path if you can see not a URL because we have it locally and model so you just load",
    "start": "2451250",
    "end": "2458390"
  },
  {
    "text": "that model locally put in your memory bind it create the endpoints and serve",
    "start": "2458390",
    "end": "2463700"
  },
  {
    "text": "it we don't need to do the demo again I think cool any questions guys all right",
    "start": "2463700",
    "end": "2473870"
  },
  {
    "text": "I told you it's going to be simple right well me two other things so rest and",
    "start": "2473870",
    "end": "2482180"
  },
  {
    "text": "open API I'll just skim through this model server basically exposed rest like",
    "start": "2482180",
    "end": "2487580"
  },
  {
    "start": "2485000",
    "end": "2485000"
  },
  {
    "text": "endpoint for we model loaded you have the model name you provide when you start not a service slash predict that's",
    "start": "2487580",
    "end": "2494030"
  },
  {
    "text": "the endpoint for making requests and it expects a post request these endpoints",
    "start": "2494030",
    "end": "2499880"
  },
  {
    "text": "also generated from the signature file by default it uses JSON encoding but you",
    "start": "2499880",
    "end": "2505190"
  },
  {
    "text": "can use other encodings like JPEG is I've seen earlier and actually with custom code you can handle whatever you",
    "start": "2505190",
    "end": "2510590"
  },
  {
    "text": "know encoding you choose to use we have some examples of model server on the model server website that use base64",
    "start": "2510590",
    "end": "2518120"
  },
  {
    "text": "encoding for inputs and outputs for face detection so you can use whatever you want",
    "start": "2518120",
    "end": "2524470"
  },
  {
    "text": "and we also support open API so if you you know in this examples I was using",
    "start": "2524470",
    "end": "2530870"
  },
  {
    "text": "curl for making the request but you know in a real software system you want to use curl you will use you know whatever",
    "start": "2530870",
    "end": "2536720"
  },
  {
    "text": "Java or Python or C++ to make the request but you can actually auto Jane",
    "start": "2536720",
    "end": "2543250"
  },
  {
    "text": "client code through the open API support I skip demoing it let's just move on to",
    "start": "2543250",
    "end": "2549980"
  },
  {
    "text": "containerization I think that's super interesting it was also raised before so actually for production use cases",
    "start": "2549980",
    "end": "2556150"
  },
  {
    "text": "or I'd start actually by a different angle for prototyping use cases I would recommend to do just the demo I show",
    "start": "2556150",
    "end": "2562420"
  },
  {
    "text": "just install it locally on your Linux box or a Mac or a Windows use it play",
    "start": "2562420",
    "end": "2567910"
  },
  {
    "text": "around with it make sure it's working as expected but for production when you have high scale service you want to",
    "start": "2567910",
    "end": "2574000"
  },
  {
    "text": "handle we recommend to use containers who is familiar with containers okay",
    "start": "2574000",
    "end": "2582430"
  },
  {
    "start": "2577000",
    "end": "2577000"
  },
  {
    "text": "yeah so containers is a well known technology kind of took the world by storm",
    "start": "2582430",
    "end": "2587500"
  },
  {
    "text": "and it provides it provides a an image",
    "start": "2587500",
    "end": "2595630"
  },
  {
    "text": "that you can then deploy on different hosts with exactly the same software's configuration",
    "start": "2595630",
    "end": "2601480"
  },
  {
    "text": "it has good support by production-ready orchestration tools like Amazon SES the",
    "start": "2601480",
    "end": "2607420"
  },
  {
    "text": "elastic container service docker of course Google's kubernetes all of them",
    "start": "2607420",
    "end": "2613090"
  },
  {
    "text": "are really provide a great support for container orchestration on the model",
    "start": "2613090",
    "end": "2619030"
  },
  {
    "text": "server side we just want you guys to be able to leverage these tools we don't try to reinvent these tools we do this",
    "start": "2619030",
    "end": "2624490"
  },
  {
    "text": "by actually some other white containers is good some other points very easy to scale out with containers right you need",
    "start": "2624490",
    "end": "2631480"
  },
  {
    "text": "to add more capacity in the model server use case you can just throw in more containers behind your load balancer and",
    "start": "2631480",
    "end": "2638500"
  },
  {
    "text": "you'll get more capacity we offer robust and scalable images these images",
    "start": "2638500",
    "end": "2645430"
  },
  {
    "text": "container images automatically leverage all GPUs and CPUs on the hosts so if for example you have you know an AWS c5 I",
    "start": "2645430",
    "end": "2657370"
  },
  {
    "text": "don't know eight extra-large image which has member how many maybe 16 CPUs or 32",
    "start": "2657370",
    "end": "2663520"
  },
  {
    "text": "CPUs the model server container will automatically use all of these CPUs for",
    "start": "2663520",
    "end": "2668980"
  },
  {
    "text": "you if you're using a p3 instance with multiple GPUs the container image will automatically leverage all these GPUs",
    "start": "2668980",
    "end": "2674560"
  },
  {
    "text": "for you you don't need to do anything and these images are available now on",
    "start": "2674560",
    "end": "2680950"
  },
  {
    "text": "docker hub so if you go to on docker hub to AWS deep learning teams - MMS CPU or",
    "start": "2680950",
    "end": "2686350"
  },
  {
    "text": "MMS GPU you can just download these images",
    "start": "2686350",
    "end": "2690750"
  },
  {
    "text": "what's happening when using the container image so and I'll show you them in a minute but you have the docker",
    "start": "2692920",
    "end": "2698840"
  },
  {
    "text": "image you either do a docker pool from docker hub or you do a build if you want",
    "start": "2698840",
    "end": "2704120"
  },
  {
    "text": "the docker image file is actually within the model server repository and after",
    "start": "2704120",
    "end": "2710240"
  },
  {
    "text": "that you do Quran and this is what you get you get on your favorite",
    "start": "2710240",
    "end": "2715520"
  },
  {
    "text": "orchestration tool of choice ECS or docker or other you have the container the cluster you need to set up",
    "start": "2715520",
    "end": "2721730"
  },
  {
    "text": "a load balancer but behind that you have a bunch of mms containers each one of them comes pre-configured with MMX net",
    "start": "2721730",
    "end": "2730040"
  },
  {
    "text": "with nginx as a reverse proxy and with the model server on top of that which is",
    "start": "2730040",
    "end": "2736040"
  },
  {
    "text": "it's a very easy way to get started but it's also very robust by having nginx as",
    "start": "2736040",
    "end": "2741770"
  },
  {
    "text": "a reverse proxy you get all the benefits of a reverse proxy like isolation from slow clients like very robust and useful",
    "start": "2741770",
    "end": "2752230"
  },
  {
    "text": "production features for setting up in our certificate or for limiting the request queue there's a bunch of these",
    "start": "2752230",
    "end": "2759380"
  },
  {
    "text": "things supported by nginx and of course behind that you have the model server connected handling the request yeah",
    "start": "2759380",
    "end": "2771250"
  },
  {
    "text": "okay it's a good question so the question is for the models do we share",
    "start": "2776440",
    "end": "2782680"
  },
  {
    "text": "them by some kind of remote storage or do we have them available locally you",
    "start": "2782680",
    "end": "2789850"
  },
  {
    "text": "can do both but at the end of the day for model server to load the model it has to be local so when you start model",
    "start": "2789850",
    "end": "2796210"
  },
  {
    "text": "server it is to contain our command line you need to give it some kind of either a URL or a file system path for the",
    "start": "2796210",
    "end": "2802540"
  },
  {
    "text": "model if it's a URL model server we'll go ahead download that model to locally so if you have let's say five container",
    "start": "2802540",
    "end": "2809440"
  },
  {
    "text": "images each one of them will download that model locally and locally it will unpack it load it into memory and start",
    "start": "2809440",
    "end": "2815590"
  },
  {
    "text": "serving it you can also within customers basically fetching models themselves",
    "start": "2815590",
    "end": "2821560"
  },
  {
    "text": "locally because they have some special pipeline requirements in that case model server will not fetch it of course it",
    "start": "2821560",
    "end": "2827320"
  },
  {
    "text": "will just unpack it locally and use it",
    "start": "2827320",
    "end": "2830850"
  },
  {
    "text": "yeah yeah so the question is okay we",
    "start": "2835320",
    "end": "2840850"
  },
  {
    "text": "every model goes through augmentation updates every once in a while how do we make sure all the model server are in",
    "start": "2840850",
    "end": "2846430"
  },
  {
    "text": "sync the recommended process is to have a one bucket for the",
    "start": "2846430",
    "end": "2852220"
  },
  {
    "text": "model and you just override that bucket when you have new version of the model and you restart the server to fetch the",
    "start": "2852220",
    "end": "2860530"
  },
  {
    "text": "updated model from the bucket now give you a spoiler in MMS version 1.0 you'll",
    "start": "2860530",
    "end": "2867370"
  },
  {
    "text": "have a control plane API you can just call that API and tell it hey please reload my model and without taking model",
    "start": "2867370",
    "end": "2874930"
  },
  {
    "text": "server down you just go ahead and update it so stay tuned what by the way model",
    "start": "2874930",
    "end": "2880240"
  },
  {
    "text": "server version 1.0 is going to be amazing performance is going to be an order of magnitude faster and you'll get",
    "start": "2880240",
    "end": "2886210"
  },
  {
    "text": "control plane API and it will also have support for more frameworks but it's not",
    "start": "2886210",
    "end": "2894550"
  },
  {
    "text": "released yet so you know we won't talk too much about it okay let's do a quick",
    "start": "2894550",
    "end": "2900730"
  },
  {
    "text": "demo if you thought that using model",
    "start": "2900730",
    "end": "2905830"
  },
  {
    "text": "server through command line was simple then it will be sir price you see that with containers it's",
    "start": "2905830",
    "end": "2911349"
  },
  {
    "text": "even simpler okay so let's start by wrong demo",
    "start": "2911349",
    "end": "2929609"
  },
  {
    "text": "okay okay let's start by actually going to docker hub I mentioned earlier we have pre-configured dr. images there",
    "start": "2933819",
    "end": "2940809"
  },
  {
    "text": "available is docker image file in the repository but also there available is built images on docker hub you have the",
    "start": "2940809",
    "end": "2948160"
  },
  {
    "text": "link there you have a nice a readme description telling how to explain how",
    "start": "2948160",
    "end": "2953890"
  },
  {
    "text": "to use it what's the configuration options etc with a quick start and all that stuff you can go over it later but",
    "start": "2953890",
    "end": "2963009"
  },
  {
    "text": "let's see how we how we use that image specifically in this case on CPU so we do a docker pool which pulls down the",
    "start": "2963009",
    "end": "2969039"
  },
  {
    "text": "docker image for us locally and then if we do the kilometers we can see that",
    "start": "2969039",
    "end": "2974739"
  },
  {
    "text": "image available there right and this",
    "start": "2974739",
    "end": "2979869"
  },
  {
    "text": "goes fast hold on and then what I did",
    "start": "2979869",
    "end": "2987369"
  },
  {
    "text": "here the command here I just did a very simple docker run command - now just",
    "start": "2987369",
    "end": "2993729"
  },
  {
    "text": "going quickly over the parameters - itd means it starts it in interactive detached mode so it runs in the in the",
    "start": "2993729",
    "end": "3001920"
  },
  {
    "text": "background detached for us the name I'm giving this docker image is MMS 4mx net",
    "start": "3001920",
    "end": "3008339"
  },
  {
    "text": "model server port binding I'm binding port 80 on my local host on my host to",
    "start": "3008339",
    "end": "3014819"
  },
  {
    "text": "port 88 in the container which is the default port model server is listening on so requests coming in to port 80 on",
    "start": "3014819",
    "end": "3020849"
  },
  {
    "text": "my host will be tunneled to 8080 the the",
    "start": "3020849",
    "end": "3026130"
  },
  {
    "text": "name of the image is MMS CPU and then I give it command line argument MX net",
    "start": "3026130",
    "end": "3032430"
  },
  {
    "text": "model server which is a command unavailable on that container image start is the command to start and - -",
    "start": "3032430",
    "end": "3038910"
  },
  {
    "text": "MMS config with a path to a configuration file now this configuration file is available for you by default with default parameters think",
    "start": "3038910",
    "end": "3046079"
  },
  {
    "text": "of it as the replay sorry replacement to the CLI arguments when you run it locally okay and you can see that this",
    "start": "3046079",
    "end": "3053609"
  },
  {
    "text": "command returned and we have this model running that's it now we have model",
    "start": "3053609",
    "end": "3059459"
  },
  {
    "text": "server running locally inside the container so if we do docker stats we",
    "start": "3059459",
    "end": "3065910"
  },
  {
    "text": "can see this this model running MMS it's",
    "start": "3065910",
    "end": "3072990"
  },
  {
    "text": "consuming single-digit CPU percentage which is fine and now let's do the curl",
    "start": "3072990",
    "end": "3078599"
  },
  {
    "text": "command so if we do a curl again like before localhost in this case we don't need to specify the port because it is",
    "start": "3078599",
    "end": "3085170"
  },
  {
    "text": "the saying by default slash ping we got a healthy response so it's running and again we can get an image if we do a",
    "start": "3085170",
    "end": "3091980"
  },
  {
    "text": "curl - OH",
    "start": "3091980",
    "end": "3094730"
  },
  {
    "text": "take an input image I think it's still a cat image it's downloaded and now we can",
    "start": "3097039",
    "end": "3104579"
  },
  {
    "text": "just do the curl request locally and for the server to process curl - ex post",
    "start": "3104579",
    "end": "3110000"
  },
  {
    "text": "local host by default it's port 80 squeeze net slash predict with the image",
    "start": "3110000",
    "end": "3120349"
  },
  {
    "text": "and boom move that the response back see",
    "start": "3123049",
    "end": "3128400"
  },
  {
    "text": "the prediction response again Egyptian cat 85 percent probability okay so",
    "start": "3128400",
    "end": "3134849"
  },
  {
    "text": "that's it that's that's the demo for using it of course at the end of the day",
    "start": "3134849",
    "end": "3139920"
  },
  {
    "text": "we need to do a dr. RM to remove that image and we're good to go",
    "start": "3139920",
    "end": "3145940"
  },
  {
    "text": "any questions on the container use case",
    "start": "3145940",
    "end": "3150619"
  },
  {
    "text": "okay we breathe through operational metrics one key thing if you ever own",
    "start": "3151460",
    "end": "3158789"
  },
  {
    "text": "the production service you always want to keep your tabs on your service at any given point in time how well it's doing",
    "start": "3158789",
    "end": "3164279"
  },
  {
    "text": "how many requests it's getting how many of them are failing what's the latency all that stuff with the model server",
    "start": "3164279",
    "end": "3170700"
  },
  {
    "text": "that's taken care of for you with a built-in integration with Amazon Cloud watch so the matrix you're getting or",
    "start": "3170700",
    "end": "3179160"
  },
  {
    "text": "covering request latency is resource utilization across different dimensions like the model name because you may have",
    "start": "3179160",
    "end": "3184920"
  },
  {
    "text": "multiple models on the same host but also hostname because your cluster will probably contain multiple hosts on the",
    "start": "3184920",
    "end": "3191220"
  },
  {
    "text": "cluster and you might want to be able to you know slice and dice your matrix based on different dimensions MMS out",
    "start": "3191220",
    "end": "3199500"
  },
  {
    "text": "the model server out of the Vox supports both log file metrics that you can then attach to on log processing",
    "start": "3199500",
    "end": "3206609"
  },
  {
    "text": "program running on the host or it can dump it into a CSV which is very useful",
    "start": "3206609",
    "end": "3211660"
  },
  {
    "text": "if you do like performance benchmarking but also it has built-in integration with AWS cloud watch through a WSS Bato",
    "start": "3211660",
    "end": "3219630"
  },
  {
    "text": "SDK and with just one command line flag or configuration flag you can",
    "start": "3219630",
    "end": "3226150"
  },
  {
    "text": "automatically get all the metrics from your cluster into cloud watch this is just an example",
    "start": "3226150",
    "end": "3232030"
  },
  {
    "text": "we ran at some point you can see the different metrics you get like resource utilization for CPU utilization disk",
    "start": "3232030",
    "end": "3239290"
  },
  {
    "text": "memory incoming prediction request count inference latency pre-process latency",
    "start": "3239290",
    "end": "3246070"
  },
  {
    "text": "and you get more metrics than that built-in for you with model server",
    "start": "3246070",
    "end": "3251260"
  },
  {
    "text": "version 1.0 you also get the ability to report custom metrics if you have special metrics you want to report",
    "start": "3251260",
    "end": "3256450"
  },
  {
    "text": "you'll get a Python API you can use your custom code to report this as well and there'll be tunnelled just the same to",
    "start": "3256450",
    "end": "3262210"
  },
  {
    "text": "all of the outputs right any questions on metrics okay and ionic support so",
    "start": "3262210",
    "end": "3273420"
  },
  {
    "start": "3273000",
    "end": "3273000"
  },
  {
    "text": "explain what Onix is briefly I'll explain it again actually the problem onyx is trying to solve deep learning",
    "start": "3273570",
    "end": "3280540"
  },
  {
    "text": "moves very rapidly and like every emerging technology or technology that is kind of relatively early on with",
    "start": "3280540",
    "end": "3289180"
  },
  {
    "text": "industry adoption there's really a lot of options to choose from right lots of different frameworks like MX net cafe PI",
    "start": "3289180",
    "end": "3295420"
  },
  {
    "text": "torch tensorflow lots of runtime frameworks like core ml for Apple tensor RT from Nvidia and",
    "start": "3295420",
    "end": "3302200"
  },
  {
    "text": "graph from Intel how can we use all of that effectively right if we want to",
    "start": "3302200",
    "end": "3309010"
  },
  {
    "text": "have every framework support every platform we get order of n ^ 2 pairs that's not sustainable",
    "start": "3309010",
    "end": "3314619"
  },
  {
    "text": "that's exactly what Onix is trying to solve it's a common IR and IR stands for",
    "start": "3314619",
    "end": "3320170"
  },
  {
    "text": "intermediate representation for neural networks which means basically you can",
    "start": "3320170",
    "end": "3325450"
  },
  {
    "text": "take a framework like PI torch which supports onyx you can export your PI",
    "start": "3325450",
    "end": "3330490"
  },
  {
    "text": "touch model into onyx and you can take that onyx model and load it in framework like MX net that supports onyx",
    "start": "3330490",
    "end": "3337069"
  },
  {
    "text": "and then it will just work the same onyx",
    "start": "3337069",
    "end": "3342980"
  },
  {
    "text": "is supported in MX net and also in the model server so you can take your onyx",
    "start": "3342980",
    "end": "3348140"
  },
  {
    "text": "models export it from PI torch or chain air or I don't know what you can package it up into a model archive with MX net",
    "start": "3348140",
    "end": "3355309"
  },
  {
    "text": "and model server and the model server will serve it which basically allows the",
    "start": "3355309",
    "end": "3360619"
  },
  {
    "text": "model server to support more than just one framework more than just MX net right onyx is yes yes so typically with",
    "start": "3360619",
    "end": "3383269"
  },
  {
    "text": "deep learning and Shin learning in general you have two main phases one phase is building and training or model the other phase is actually using it for",
    "start": "3383269",
    "end": "3391130"
  },
  {
    "text": "you know your actual use case which is typically called inference model server is a tool is used for the latter it's",
    "start": "3391130",
    "end": "3398480"
  },
  {
    "text": "used for inference it's not used for training in any way the assumption is when you start using model server you",
    "start": "3398480",
    "end": "3403489"
  },
  {
    "text": "have a trained model you want to use in production did answer your question oh",
    "start": "3403489",
    "end": "3409539"
  },
  {
    "text": "okay so this specific I'll just repeat the question for everyone so with regards to onyx specifically if I've",
    "start": "3415690",
    "end": "3422180"
  },
  {
    "text": "built and trained my model with let's say PI torch exported it to an excuse it on a mix net and I want to go back and",
    "start": "3422180",
    "end": "3427759"
  },
  {
    "text": "retrain my model with more data or maybe augment and s4 can I do it you can actually still do it with MX net if you",
    "start": "3427759",
    "end": "3434119"
  },
  {
    "text": "wish to because onyx preserves all of the layers including layers like you",
    "start": "3434119",
    "end": "3440119"
  },
  {
    "text": "know drop out for example is a layer which is not used for inference it's used only for training batch norm is a",
    "start": "3440119",
    "end": "3446150"
  },
  {
    "text": "layer that is used for training so onyx actually preserves even in all of these so you can actually use it in MX net the",
    "start": "3446150",
    "end": "3453230"
  },
  {
    "text": "question is do you want to if typically if you've used you know let's say PI toad for building our model and training",
    "start": "3453230",
    "end": "3458720"
  },
  {
    "text": "it you'll have all your setup for training with by torch sometimes there's less benefit in moving to M X net I have",
    "start": "3458720",
    "end": "3466160"
  },
  {
    "text": "seen customers doing it and that primarily if they want to reap the benefits of MX nets performance and",
    "start": "3466160",
    "end": "3471590"
  },
  {
    "text": "scalability they will continue training in MX net but mostly people will prefer",
    "start": "3471590",
    "end": "3476990"
  },
  {
    "text": "to continue training on the framework they started with cool",
    "start": "3476990",
    "end": "3482300"
  },
  {
    "text": "just one note about onyx onyx is a really wide industry initiative that is",
    "start": "3482300",
    "end": "3488300"
  },
  {
    "text": "driven by AWS Facebook and Microsoft and there's a growing community around it I",
    "start": "3488300",
    "end": "3495380"
  },
  {
    "text": "highly recommend check it out it's on onyx if you go to the Internet onyx oti",
    "start": "3495380",
    "end": "3500450"
  },
  {
    "text": "there's lots of details again it's an open-source Keita project you can you're welcome to contribute personally I think",
    "start": "3500450",
    "end": "3507110"
  },
  {
    "text": "it's an amazing initiative that just makes everyone's life easier okay next",
    "start": "3507110",
    "end": "3518060"
  },
  {
    "text": "we'll talk about using mana server with AWS Fargate who here is familiar with Fargate ok so far gate allows us to do",
    "start": "3518060",
    "end": "3530030"
  },
  {
    "text": "what we call server let's model serving right we don't need to have actual ec2 instances behind your server of course",
    "start": "3530030",
    "end": "3536570"
  },
  {
    "text": "they are available somewhere handling the request but you as the user you don't have to manually configure these",
    "start": "3536570",
    "end": "3541970"
  },
  {
    "text": "instances Fargate is an edibles technology that allows you to deploy",
    "start": "3541970",
    "end": "3547970"
  },
  {
    "text": "containers without managing hosts or clusters if you ever use dcs for docker",
    "start": "3547970",
    "end": "3553430"
  },
  {
    "text": "you know that you know as part of your configuration you also attach hosts either physical or virtual host to host",
    "start": "3553430",
    "end": "3560090"
  },
  {
    "text": "your containers with forget you don't need to do that the only thing you need to specify is the number of instances I'm sorry the number of feet recipe use",
    "start": "3560090",
    "end": "3567230"
  },
  {
    "text": "and the memory and Fargate will handle everything under the hood for you it",
    "start": "3567230",
    "end": "3573020"
  },
  {
    "text": "allows similar scaling you pay only for the CPU and memory you've consumed so it's also very cost efficient option and",
    "start": "3573020",
    "end": "3579950"
  },
  {
    "start": "3579000",
    "end": "3579000"
  },
  {
    "text": "you can use it with a model server now here's the architecture at the high level how this looks",
    "start": "3579950",
    "end": "3586300"
  },
  {
    "text": "first of all in to have your VPC inside your V PC you set up your ECS cluster",
    "start": "3586300",
    "end": "3592040"
  },
  {
    "text": "and service and within that you define multiple Fargate tasks basically define the tasks for every model here you want",
    "start": "3592040",
    "end": "3599030"
  },
  {
    "text": "to serve our set of models within these desks you configure them to use the MMS container image I've shown",
    "start": "3599030",
    "end": "3605299"
  },
  {
    "text": "you earlier which each one internally contains model server nginx and the AMEX",
    "start": "3605299",
    "end": "3612980"
  },
  {
    "text": "net framework you attach these to a load balancer which sits in front of your of",
    "start": "3612980",
    "end": "3620059"
  },
  {
    "text": "your cluster and exposes an endpoint in the internet and optionally you can also",
    "start": "3620059",
    "end": "3625220"
  },
  {
    "text": "configure a cloud watch integration which we just work seamlessly to get your metrics out of the system and",
    "start": "3625220",
    "end": "3632119"
  },
  {
    "text": "that's it you can do all of that to the Amazon ECS web dashboard or through the",
    "start": "3632119",
    "end": "3638690"
  },
  {
    "text": "CLI I won't go over these steps in specific just because there's a lot of",
    "start": "3638690",
    "end": "3644180"
  },
  {
    "text": "manual steps involved but the diagram I showed earlier and by the way this whole",
    "start": "3644180",
    "end": "3649490"
  },
  {
    "text": "deck will be available for you guys kind of shows how this set up what's the",
    "start": "3649490",
    "end": "3655849"
  },
  {
    "text": "architecture of the set up and on the model server github repository you have a step by step definition of how to",
    "start": "3655849",
    "end": "3661700"
  },
  {
    "text": "configure model server with Fargate which I encourage you guys to check out yeah yes so the question is is Fargate a",
    "start": "3661700",
    "end": "3675740"
  },
  {
    "text": "container orchestration framework the answer is yes Fargate is actually part of Amazon ECS ECS is Amazon's container",
    "start": "3675740",
    "end": "3683990"
  },
  {
    "text": "orchestration framework sense for elastic container service forget is a",
    "start": "3683990",
    "end": "3689540"
  },
  {
    "text": "way to use ECS which is server less right where you don't have to attach ec2",
    "start": "3689540",
    "end": "3695329"
  },
  {
    "text": "instances so it simplifies the workflow and it has other benefits like I mentioned like seamless scaling and also",
    "start": "3695329",
    "end": "3701960"
  },
  {
    "text": "you you pay for what you use so as far",
    "start": "3701960",
    "end": "3707599"
  },
  {
    "text": "as I know coburn it's somewhat similar to kubernetes the question is is Fargate",
    "start": "3707599",
    "end": "3713359"
  },
  {
    "text": "similar to kubernetes kubernetes is a framework it's not it's orchestration",
    "start": "3713359",
    "end": "3718970"
  },
  {
    "text": "framework it's not a managed service like ECS so with kubernetes gives you",
    "start": "3718970",
    "end": "3724099"
  },
  {
    "text": "great tools but you need to manually deploy and run this tool somewhere actually ECS recently launched a",
    "start": "3724099",
    "end": "3732049"
  },
  {
    "text": "kubernetes managed service which gives you that capable on AWS but kubernetes as far as I know",
    "start": "3732049",
    "end": "3737880"
  },
  {
    "text": "is not service so if you want the surveillance capability you want to abstract away they need to manage ec2",
    "start": "3737880",
    "end": "3744390"
  },
  {
    "text": "instances Fargate is a great way to go okay any other question yeah yes lastly",
    "start": "3744390",
    "end": "3753420"
  },
  {
    "text": "kubernetes service it's also part of the overall Amazon ECS but it's one that",
    "start": "3753420",
    "end": "3758430"
  },
  {
    "text": "specifically uses a flavor of communities under the hood you very",
    "start": "3758430",
    "end": "3776820"
  },
  {
    "text": "specifically to the model server yeah so",
    "start": "3776820",
    "end": "3783150"
  },
  {
    "text": "specifically you know with containers I mean first of all you are right there's always a lot of different ways to do a",
    "start": "3783150",
    "end": "3788520"
  },
  {
    "text": "different thing and it's also depends on your actual use case with containers",
    "start": "3788520",
    "end": "3793530"
  },
  {
    "text": "there's definitely times of for you to go containers are very popular there's a lot of good resources on the AWS website",
    "start": "3793530",
    "end": "3799980"
  },
  {
    "text": "under ACS which I encourage you to go check out specifically with the model server because it's a more narrow domain",
    "start": "3799980",
    "end": "3806460"
  },
  {
    "text": "if you go to the model server github repository you can just go to model",
    "start": "3806460",
    "end": "3811770"
  },
  {
    "text": "server dot IO and then it will take you there there's a specific documentation around setting up scalable inference",
    "start": "3811770",
    "end": "3818490"
  },
  {
    "text": "with containers that gives you a step-by-step recipe on how to set this up and that would be the way I would",
    "start": "3818490",
    "end": "3824010"
  },
  {
    "text": "recommend you to go assuming your needs are kind of generic if your needs are",
    "start": "3824010",
    "end": "3829109"
  },
  {
    "text": "more specific I mean I'm happy to chat and see how we can help out yeah okay",
    "start": "3829109",
    "end": "3834420"
  },
  {
    "text": "how much time do we have left so I'm",
    "start": "3834420",
    "end": "3840900"
  },
  {
    "text": "over I wanted to do another end-to-end demo with facial expression recognition",
    "start": "3840900",
    "end": "3847050"
  },
  {
    "text": "which is a really cool deep learning application identifying emotions in images you have this there is the link",
    "start": "3847050",
    "end": "3854760"
  },
  {
    "text": "below get up dot-com / talk AI facial motion recognition it's a talk I gave at",
    "start": "3854760",
    "end": "3860970"
  },
  {
    "text": "a meet-up earlier there's a nice computer notebook that shows you how to both build a model training and",
    "start": "3860970",
    "end": "3866910"
  },
  {
    "text": "deploying it with MMS for emotional Nishan supercool application of deep learning detecting emotions in images",
    "start": "3866910",
    "end": "3873870"
  },
  {
    "text": "lots of potential interesting Big Brother applications but but it's it's a",
    "start": "3873870",
    "end": "3879420"
  },
  {
    "text": "cool one and lastly if you want to learn more about using MX net on AWS",
    "start": "3879420",
    "end": "3884670"
  },
  {
    "text": "we actually have expert in Amazon AI that can you view your different in this case help you out consult there is an",
    "start": "3884670",
    "end": "3892200"
  },
  {
    "text": "email here and b-boss a feel free to take a picture or chat with me later we",
    "start": "3892200",
    "end": "3897780"
  },
  {
    "text": "want to hear from you we want to help you guys use AWS for deep learning use",
    "start": "3897780",
    "end": "3903090"
  },
  {
    "text": "MX net and we go at great lengths with different customers to add and to help",
    "start": "3903090",
    "end": "3908940"
  },
  {
    "text": "out someone C wants to take a picture go for it",
    "start": "3908940",
    "end": "3915950"
  },
  {
    "text": "and yeah beyond that I really enjoyed the talk I hope I you know we'd help my",
    "start": "3917240",
    "end": "3923850"
  },
  {
    "text": "or help my promise of enabling new guys to deploy models in you know 15 minutes to production and if I haven't come talk",
    "start": "3923850",
    "end": "3931380"
  },
  {
    "text": "to me I'm happy to see how we can help there's lots of great resources on model servers at i/o and the MX nada your",
    "start": "3931380",
    "end": "3938340"
  },
  {
    "text": "website that I encourage you to go and check out and we're always listening on you know github issues if you file",
    "start": "3938340",
    "end": "3945570"
  },
  {
    "text": "issues with your questions with feature requests with bugs we're following up with you quickly okay I think I need to",
    "start": "3945570",
    "end": "3953640"
  },
  {
    "text": "wrap up because I'm out of time I'll be available if you want to ask me more questions I should probably wrap up",
    "start": "3953640",
    "end": "3960150"
  },
  {
    "text": "right yeah okay thank you",
    "start": "3960150",
    "end": "3964400"
  }
]
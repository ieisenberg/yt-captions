[
  {
    "start": "0",
    "end": "40000"
  },
  {
    "text": "Hi, my name is Aansh Shah, and I'm \nan SDE with Alexa AI within Amazon.",
    "start": "0",
    "end": "5609"
  },
  {
    "text": "Within Alexa, we focus on providing \nas close to real-time data as possible,",
    "start": "6092",
    "end": "10058"
  },
  {
    "text": "and enable machine \nlearning use cases at scale.",
    "start": "10058",
    "end": "12424"
  },
  {
    "text": "Our belief is that providing real-time \ntransforming computation on streaming",
    "start": "12935",
    "end": "16711"
  },
  {
    "text": "data will provide greater value to Alexa \nas a whole, by unlocking faster ways to",
    "start": "16711",
    "end": "21437"
  },
  {
    "text": "train tasks and release production models \nto provide delightful customer experiences.",
    "start": "21437",
    "end": "26340"
  },
  {
    "text": "Today, I'll be talking about a platform\n we launched within Alexa called the",
    "start": "26567",
    "end": "30000"
  },
  {
    "text": "Continual Learning platform, and how\n we're leveraging Apache Flink using",
    "start": "30000",
    "end": "34198"
  },
  {
    "text": "Kinesis Data Analytics to power the \nstreaming aggregations and transformations.",
    "start": "34198",
    "end": "38487"
  },
  {
    "text": "In this presentation, we'll cover the following.",
    "start": "39396",
    "end": "42361"
  },
  {
    "start": "40000",
    "end": "40000"
  },
  {
    "text": "First, a background on what Continual \nLearning is, an overview of the platform",
    "start": "42602",
    "end": "47159"
  },
  {
    "text": "that we built for Alexa, how we \nleverage Kinesis Data Analytics and",
    "start": "47159",
    "end": "50898"
  },
  {
    "text": "Apache Flink, problems that we solved\n for some of our use cases using the",
    "start": "50898",
    "end": "55334"
  },
  {
    "text": "platform, challenges that we currently \nface, and what we're working on next.",
    "start": "55334",
    "end": "59139"
  },
  {
    "start": "60000",
    "end": "60000"
  },
  {
    "text": "To understand what Continual Learning is, we'll\n first go through what Continual Learning isn't.",
    "start": "60105",
    "end": "64401"
  },
  {
    "text": "A machine learning model is a \nlarge statistical model that makes",
    "start": "65168",
    "end": "68470"
  },
  {
    "text": "predictions and is built by showing a\n black-box algorithm millions of inputs.",
    "start": "68470",
    "end": "72856"
  },
  {
    "text": "As shown in the picture on the slides, \nin batch offline training workflows,",
    "start": "73296",
    "end": "77335"
  },
  {
    "text": "we generally do the following steps.",
    "start": "77335",
    "end": "79229"
  },
  {
    "text": "First, we train the model \non a large set of datapoints.",
    "start": "79628",
    "end": "82729"
  },
  {
    "text": "Second, we then validate the model \nusing datapoints that the model hasn't",
    "start": "82914",
    "end": "87085"
  },
  {
    "text": "seen before, to verify the \ncorrectness of the model's outputs.",
    "start": "87085",
    "end": "90885"
  },
  {
    "text": "Then we deploy the model in production.",
    "start": "91453",
    "end": "93679"
  },
  {
    "text": "And finally, we monitor the \nperformance of the model.",
    "start": "94048",
    "end": "96666"
  },
  {
    "text": "Once the model performance degrades, \nthe model hosted in production is refreshed.",
    "start": "96950",
    "end": "101932"
  },
  {
    "text": "In order to refresh the model, \nthe model needs to be retrained,",
    "start": "102514",
    "end": "105881"
  },
  {
    "text": "and that's frequently done on \nall the full historical input data.",
    "start": "105881",
    "end": "109885"
  },
  {
    "text": "So, now that we know what \nContinual Learning isn't, we can",
    "start": "110753",
    "end": "113890"
  },
  {
    "start": "111000",
    "end": "111000"
  },
  {
    "text": "talk about what Continual Learning is.",
    "start": "113890",
    "end": "115655"
  },
  {
    "text": "In Continual Learning, models are \ntrained and retrained in a continuous way.",
    "start": "115953",
    "end": "119864"
  },
  {
    "text": "The input data that is continually \nrefreshed, and the models that are",
    "start": "120588",
    "end": "124699"
  },
  {
    "text": "only retrained on a subset of the \ndata, instead of the entire history.",
    "start": "124699",
    "end": "129507"
  },
  {
    "text": "So in the pictures shown on the \nslides, you'll see a new arrow from the",
    "start": "129905",
    "end": "133181"
  },
  {
    "text": "deployed model in production to the \ntrained model, showing that the input",
    "start": "133181",
    "end": "138287"
  },
  {
    "text": "data for training is constantly \nrefreshed at some cadence.",
    "start": "138287",
    "end": "141728"
  },
  {
    "text": "Continual Learning is advantageous \nto us for primarily two reasons.",
    "start": "142694",
    "end": "146917"
  },
  {
    "text": "The first is adaptability to changing trends",
    "start": "147130",
    "end": "150081"
  },
  {
    "text": "and usage, and the \nsecond is for cost reduction.",
    "start": "150081",
    "end": "153027"
  },
  {
    "text": "So for adaptability, by training models \non a smaller amount of data that's",
    "start": "153339",
    "end": "158054"
  },
  {
    "text": "available more quickly, we're able to train \nmodels faster and get them into production.",
    "start": "158054",
    "end": "162743"
  },
  {
    "text": "This allows us to react to changes in \ncustomer requirements and behavior.",
    "start": "163197",
    "end": "167163"
  },
  {
    "text": "For instance, during Covid, customer \nusage patterns changed significantly,",
    "start": "167263",
    "end": "171596"
  },
  {
    "text": "and Continual Learning workflows can\n allow us to quickly refresh models to",
    "start": "171596",
    "end": "175129"
  },
  {
    "text": "provide the best experience \npossible to delight our customers.",
    "start": "175130",
    "end": "178172"
  },
  {
    "text": "Whereas, in batch offline workflows \nlike the one shown on the screen,",
    "start": "178867",
    "end": "182703"
  },
  {
    "text": "teams have to spend a long amount of \ntime on retraining because models are",
    "start": "182703",
    "end": "186394"
  },
  {
    "text": "retrained on the entire \nhistorical input dataset.",
    "start": "186394",
    "end": "189198"
  },
  {
    "text": "Second, for cost, Continual Learning-\nbased systems give us additional",
    "start": "190022",
    "end": "194643"
  },
  {
    "text": "opportunities at cost reduction and\nsaving, because we don't need large",
    "start": "194643",
    "end": "200176"
  },
  {
    "text": "datasets for training, as we're \ncontinuously refreshing our models.",
    "start": "200176",
    "end": "203588"
  },
  {
    "text": "Furthermore, we do not need \nto pay for long data retention,",
    "start": "205264",
    "end": "209538"
  },
  {
    "text": "so we spend less on compute \nclusters due to a reduction in the",
    "start": "209538",
    "end": "212754"
  },
  {
    "text": "amount of data that's processed\n compared to batch offline workflows.",
    "start": "212755",
    "end": "216775"
  },
  {
    "text": "Next, I'll talk about how our platform works.",
    "start": "217826",
    "end": "220547"
  },
  {
    "start": "218000",
    "end": "218000"
  },
  {
    "text": "First, data stream from the Alexa \nruntime to a datalake, where a specific",
    "start": "221130",
    "end": "226518"
  },
  {
    "text": "subset of interactions are then \navailable within about ten seconds of",
    "start": "226518",
    "end": "230916"
  },
  {
    "text": "the customer interaction with \nAlexa, for applying a transformation.",
    "start": "230916",
    "end": "235270"
  },
  {
    "text": "This group of transformation services \nare shown on the slides, in the green box.",
    "start": "235795",
    "end": "241399"
  },
  {
    "text": "The users of the platform are then able\nto perform a user-defined transformation",
    "start": "242421",
    "end": "247443"
  },
  {
    "text": "in SQL, Java, or Python, on a window of\n events in a purely configuration-driven way.",
    "start": "247443",
    "end": "254010"
  },
  {
    "text": "Users are able to optionally perform \nstreaming inference on the data,",
    "start": "254820",
    "end": "259433"
  },
  {
    "text": "using SageMaker inference hosting endpoints.",
    "start": "259433",
    "end": "262081"
  },
  {
    "text": "In other words, Alexa teams just \nprovide a doc or a container with a",
    "start": "262294",
    "end": "265532"
  },
  {
    "text": "model artifact, and easily perform \ninference on the stream within Kinesis",
    "start": "265532",
    "end": "271139"
  },
  {
    "text": "Data Analytics Flink applications.",
    "start": "271139",
    "end": "273265"
  },
  {
    "text": "Data is then streamed to a datastore,\n an online or offline feature store",
    "start": "274245",
    "end": "278906"
  },
  {
    "text": "that can be accessed for retraining \ninference evaluation and analysis.",
    "start": "278907",
    "end": "283633"
  },
  {
    "text": "We decided to use Flink on top of Kinesis \nData Analytics for a few key reasons.",
    "start": "284585",
    "end": "290176"
  },
  {
    "start": "285000",
    "end": "285000"
  },
  {
    "text": "Kinesis Data Analytics Flink applications",
    "start": "290630",
    "end": "292864"
  },
  {
    "text": "makes the process of generating \nwindows on a streaming data very easy.",
    "start": "292864",
    "end": "296748"
  },
  {
    "text": "Given that we're interested in\nimproving customer experience,",
    "start": "297075",
    "end": "300021"
  },
  {
    "text": "and that requires inspecting usage \npatterns, we want to be able to look at",
    "start": "300021",
    "end": "304260"
  },
  {
    "text": "the past few interactions that a user had \nwith Alexa, and execute some business logic.",
    "start": "304260",
    "end": "309194"
  },
  {
    "text": "And do this at scale.",
    "start": "309506",
    "end": "310766"
  },
  {
    "text": "Flink makes generating these windows\n very easy, with built-in window",
    "start": "311277",
    "end": "314778"
  },
  {
    "text": "operators and an interface for \nextending ones with custom logic.",
    "start": "314778",
    "end": "318971"
  },
  {
    "text": "Prior to using Flink, in order to find \nthe last couple of interactions,",
    "start": "319369",
    "end": "323382"
  },
  {
    "text": "we would need to have a large fleet \nof EC2 instances with a lot of custom",
    "start": "323382",
    "end": "328000"
  },
  {
    "text": "logic to express each use case.",
    "start": "328001",
    "end": "330022"
  },
  {
    "text": "For each new use case, we would \nneed to add more custom code,",
    "start": "330320",
    "end": "333876"
  },
  {
    "text": "introducing engineering dependency\n for scientists and modelers.",
    "start": "333876",
    "end": "338629"
  },
  {
    "text": "Our usage of Flink, with its easy \nwindowing through a SQL statement,",
    "start": "339169",
    "end": "342839"
  },
  {
    "text": "increases our scientist and modeler \nself-sufficiency to launch new features",
    "start": "342839",
    "end": "347228"
  },
  {
    "text": "themselves, by expressing these \nthrough simple SQL statements.",
    "start": "347228",
    "end": "352268"
  },
  {
    "text": "Second, Flink allows us to transform broad \ndata streams into other representations.",
    "start": "353121",
    "end": "358337"
  },
  {
    "text": "The data that comes out of the \nraw streams, like text and audio,",
    "start": "358522",
    "end": "361455"
  },
  {
    "text": "needs to be massaged \ninto other representations.",
    "start": "361455",
    "end": "363654"
  },
  {
    "text": "Our scientists and modelers like to play around\nwith different representations of that data.",
    "start": "364037",
    "end": "368158"
  },
  {
    "text": "For instance, scientists take a textual \nrepresentation of an interaction with",
    "start": "368442",
    "end": "372185"
  },
  {
    "text": "Alexa and then turn it into an \nimbedding to use in the training routine.",
    "start": "372186",
    "end": "376377"
  },
  {
    "text": "Finally, Kinesis Data Analytics Flink \napplications allows us to focus on",
    "start": "377130",
    "end": "381761"
  },
  {
    "text": "use case logic and not infrastructure.",
    "start": "381761",
    "end": "383923"
  },
  {
    "text": "We do not have to manage our own \napplication hosting infrastructure;",
    "start": "384265",
    "end": "387993"
  },
  {
    "text": "instead, we can define our business \nlogic for launching use cases.",
    "start": "387993",
    "end": "392029"
  },
  {
    "text": "This allows us to provide a force-\nmultiplying experience to accelerate",
    "start": "392327",
    "end": "395686"
  },
  {
    "text": "near-real-time streaming inference and \ntransformations within Alexa, while",
    "start": "395687",
    "end": "399942"
  },
  {
    "text": "minimizing the engineering capacity that \nwe have to invest handling operations.",
    "start": "399942",
    "end": "405000"
  },
  {
    "start": "406000",
    "end": "406000"
  },
  {
    "text": "Next, we'll talk about some problems that \nwe've solved for use cases on the platform.",
    "start": "406008",
    "end": "409916"
  },
  {
    "text": "I'll be focusing on the benchmarking \nmodel performance and how we",
    "start": "409916",
    "end": "412957"
  },
  {
    "text": "easily guardrail Alexa experiences and \nproduction using feedback detection.",
    "start": "412958",
    "end": "416972"
  },
  {
    "text": "First, I'll cover some background about \nhow Alexa uses feedback to provide",
    "start": "417327",
    "end": "420836"
  },
  {
    "text": "more delightful experiences, and then \ncover how those computed metrics",
    "start": "420836",
    "end": "424734"
  },
  {
    "text": "and statistics are computed on the platform.",
    "start": "424734",
    "end": "427265"
  },
  {
    "text": "Alexa provides a variety of proactive\nexperiences, including end-of-dialogue, by the way.",
    "start": "427975",
    "end": "433289"
  },
  {
    "text": "To determine what content to show \ncustomers across these channels",
    "start": "433857",
    "end": "437283"
  },
  {
    "text": "and guardrail these experiences, the \nsystems need data about Alexa's past",
    "start": "437283",
    "end": "441418"
  },
  {
    "text": "customer interactions, to decide \nwhich proactive experience to offer,",
    "start": "441419",
    "end": "445117"
  },
  {
    "text": "and data after an interaction to analyze how\nit went, in order to optimize future experiences.",
    "start": "445117",
    "end": "451548"
  },
  {
    "text": "For example, Alexa uses this \ninformation to make more",
    "start": "452045",
    "end": "454718"
  },
  {
    "text": "personalized decisions about \nwhether a news or a weather",
    "start": "454718",
    "end": "457475"
  },
  {
    "text": "experience may be more \nappropriate to display.",
    "start": "457476",
    "end": "460124"
  },
  {
    "text": "This also allows us to guardrail model \nexperiences and attributing a degraded",
    "start": "460607",
    "end": "465869"
  },
  {
    "text": "experience to a particular model in \nnear-real-time, and take fast action",
    "start": "465869",
    "end": "470602"
  },
  {
    "text": "to improve the end-to-\nend customer experience.",
    "start": "470602",
    "end": "473280"
  },
  {
    "text": "Our platform users can generate \nstreaming inference transforms",
    "start": "474317",
    "end": "477944"
  },
  {
    "start": "475000",
    "end": "475000"
  },
  {
    "text": "that label data near-real-\ntime, to detect feedback types.",
    "start": "477944",
    "end": "481349"
  },
  {
    "text": "So, using our managed machine \nlearning inference hosting solution,",
    "start": "481619",
    "end": "485056"
  },
  {
    "text": "teams can spin up Flink applications\n and use their ML models to attribute",
    "start": "485056",
    "end": "489322"
  },
  {
    "text": "feedback as a particular type, like \nunprompted or customer-initiated feedback.",
    "start": "489322",
    "end": "494018"
  },
  {
    "text": "That data is then used to update an \noptimized experience via telemetry service.",
    "start": "494289",
    "end": "499067"
  },
  {
    "text": "So as you see on the slide, teams are \nable to easily spin up Flink applications",
    "start": "499394",
    "end": "504836"
  },
  {
    "text": "using Kinesis Data Analytics through a \ncontrol plane, and specify their business logic.",
    "start": "504836",
    "end": "510332"
  },
  {
    "text": "And using their machine learning \nmodels, they're then easily able to generate",
    "start": "510829",
    "end": "516117"
  },
  {
    "text": "these streaming labels and combine \nthem to form an attribute feedback",
    "start": "516118",
    "end": "522490"
  },
  {
    "text": "to particular experiences.",
    "start": "522491",
    "end": "524167"
  },
  {
    "start": "525000",
    "end": "525000"
  },
  {
    "text": "With our successes using Flink on the \nplatform, we also faced a couple big",
    "start": "525147",
    "end": "528886"
  },
  {
    "text": "challenges in abstraction and \nsimplification of the platform",
    "start": "528887",
    "end": "532333"
  },
  {
    "text": "components to increase adoption \nas well as providing dataflow",
    "start": "532333",
    "end": "536003"
  },
  {
    "text": "transparency to users of the service.",
    "start": "536003",
    "end": "538216"
  },
  {
    "text": "Because Flink requires that users be \nfamiliar with streaming concepts like",
    "start": "538869",
    "end": "542862"
  },
  {
    "text": "windowing operations, there's a steep\nlearning curve that makes scientists",
    "start": "542862",
    "end": "546963"
  },
  {
    "text": "less willing to use the platform.",
    "start": "546963",
    "end": "548694"
  },
  {
    "text": "Furthermore, because there are many \nservice components within the platform,",
    "start": "549120",
    "end": "552299"
  },
  {
    "text": "like SageMaker inference hosting, \nteams are required to familiarize",
    "start": "552299",
    "end": "556178"
  },
  {
    "text": "themselves with a large vocabulary \nand manage the underlying components.",
    "start": "556178",
    "end": "559824"
  },
  {
    "text": "In addition, dataflow transparency \nis another challenge that we face.",
    "start": "560704",
    "end": "564156"
  },
  {
    "text": "Visualizing dataflow through the \ntasks and operators within Flink",
    "start": "564383",
    "end": "567681"
  },
  {
    "text": "requires a lot of context knowledge.",
    "start": "567681",
    "end": "569591"
  },
  {
    "text": "Because there are also interactions \nwith additional services like inference",
    "start": "569804",
    "end": "573304"
  },
  {
    "text": "endpoints, tracking data loss is difficult.",
    "start": "573304",
    "end": "576000"
  },
  {
    "text": "Over the next year, we're going to double \ndown on the success that we've had",
    "start": "576994",
    "end": "580177"
  },
  {
    "text": "using Kinesis Data Analytics and Flink to \nreplace components within our data storage.",
    "start": "580177",
    "end": "585000"
  },
  {
    "text": "In our offline storage layer \nthat saves data to S3 buckets",
    "start": "585738",
    "end": "589339"
  },
  {
    "text": "that are then available to query in bulk.",
    "start": "589340",
    "end": "591410"
  },
  {
    "text": "We currently leverage many AWS \nservices to stream, aggregate,",
    "start": "592077",
    "end": "596336"
  },
  {
    "text": "partition, and persist data to a dataset.",
    "start": "596336",
    "end": "599330"
  },
  {
    "text": "We're going to simplify that architecture",
    "start": "599728",
    "end": "601547"
  },
  {
    "text": "to use Flink applications for \naggregation and partitioning.",
    "start": "601547",
    "end": "605022"
  },
  {
    "text": "In our online storage layer that we use \nto retrieve data quickly, we use many",
    "start": "606000",
    "end": "610065"
  },
  {
    "text": "AWS services for loading and \nsaving features to the datastore.",
    "start": "610065",
    "end": "613905"
  },
  {
    "text": "We plan to improve the experience and \nspeed that we can add new features,",
    "start": "614246",
    "end": "618302"
  },
  {
    "text": "by moving the pre-materialized \nviews to the Flink application.",
    "start": "618302",
    "end": "621816"
  },
  {
    "text": "In other words, we'll be able to perform\n rollups, so calculations aggregated",
    "start": "622114",
    "end": "627268"
  },
  {
    "text": "over a past amount of time, so, \nthe past seven days, and additional",
    "start": "627268",
    "end": "632283"
  },
  {
    "text": "precomputation logic to features, \neliminating additional calculations",
    "start": "632283",
    "end": "636701"
  },
  {
    "text": "that are run during services runtimes \nprior to usage in an Alexa experience.",
    "start": "636701",
    "end": "642990"
  },
  {
    "text": "This will allow us to use more \nfeatures to provide a more",
    "start": "643573",
    "end": "647564"
  },
  {
    "text": "delightful experience to customers.",
    "start": "647564",
    "end": "649787"
  },
  {
    "text": "Thank you for watching the presentation.",
    "start": "650695",
    "end": "653199"
  }
]
[
  {
    "text": "good morning everybody thank you so much for uh joining us bright and early I",
    "start": "599",
    "end": "5759"
  },
  {
    "text": "hope uh you've had at least your first round of caffeine if not more already um",
    "start": "5759",
    "end": "11639"
  },
  {
    "text": "welcome this session is about getting started with streaming data uh my name",
    "start": "11639",
    "end": "17760"
  },
  {
    "text": "is AI and I run product for Amazon Kinesis which is Amazon web services",
    "start": "17760",
    "end": "23760"
  },
  {
    "text": "streaming data platform and I'm very very glad that we have with us today",
    "start": "23760",
    "end": "30519"
  },
  {
    "text": "uh Rick McFarland who is a VP and the chief data scientist at HST Corporation",
    "start": "30519",
    "end": "36520"
  },
  {
    "text": "so I am just the opening act uh and the headline today is going to be Rick and",
    "start": "36520",
    "end": "42200"
  },
  {
    "text": "all the great work that he's done uh so what we'll do today is I will try and",
    "start": "42200",
    "end": "47520"
  },
  {
    "text": "cover off some key streaming data scenarios for all of you uh by way of a",
    "start": "47520",
    "end": "52719"
  },
  {
    "text": "of a quick poll and I know some of you still streaming in uh no pun intended uh how many of you uh would say today have",
    "start": "52719",
    "end": "60680"
  },
  {
    "text": "performed some sort of streaming data processing in their businesses or organizations well that's a it's a",
    "start": "60680",
    "end": "67320"
  },
  {
    "text": "pretty uh healthy number for uh for this sample set all right uh so so hopefully",
    "start": "67320",
    "end": "73720"
  },
  {
    "text": "what you'll take away from The Talk today uh at least from my section is",
    "start": "73720",
    "end": "79200"
  },
  {
    "text": "going to be uh what how to think about Kines streams and kin's fire hose and we",
    "start": "79200",
    "end": "85000"
  },
  {
    "text": "have some exciting announcements coming today later in the keynote about uh new features an enhancement we built to the",
    "start": "85000",
    "end": "91479"
  },
  {
    "text": "services uh but really uh we will take a little bit more time getting into fire",
    "start": "91479",
    "end": "96799"
  },
  {
    "text": "hose uh which is a service we initially launched at reinvent of last year and uh",
    "start": "96799",
    "end": "103560"
  },
  {
    "text": "to really enable customers to capture and load streaming data into destinations like S3 and red shift for",
    "start": "103560",
    "end": "110640"
  },
  {
    "text": "Downstream processing and once I go through uh the first half of the stuff I'll hand over to Rick who will then",
    "start": "110640",
    "end": "117280"
  },
  {
    "text": "give you uh an expert and a practitioner's view of what does it mean",
    "start": "117280",
    "end": "123200"
  },
  {
    "text": "to design deploy and manage Enterprise grade uh streaming data and big data",
    "start": "123200",
    "end": "131200"
  },
  {
    "text": "infrastructures so Amazon Kinesis is actually three",
    "start": "131200",
    "end": "137040"
  },
  {
    "text": "services the first service that we launched uh back in reinvent 2013 is",
    "start": "137319",
    "end": "143480"
  },
  {
    "text": "called Amazon Kinesis streams think of it as a primitive or a building block",
    "start": "143480",
    "end": "149599"
  },
  {
    "text": "that enables developers to to have complete control and flexibility on how",
    "start": "149599",
    "end": "155160"
  },
  {
    "text": "to capture and build their own custom stream processing applications using the",
    "start": "155160",
    "end": "161000"
  },
  {
    "text": "tools of choice all of our experiences there led us to release Kinesis fire hose uh which",
    "start": "161000",
    "end": "168920"
  },
  {
    "text": "was this past reinvent which is really tailored towards making the task of",
    "start": "168920",
    "end": "175040"
  },
  {
    "text": "capture and delivery of streaming data into destinations like S3 and red shift",
    "start": "175040",
    "end": "181000"
  },
  {
    "text": "Ultra simple we also announced the third key",
    "start": "181000",
    "end": "186319"
  },
  {
    "text": "service in the Amazon Kinesis platform and that's Amazon Kinesis analytics",
    "start": "186319",
    "end": "191720"
  },
  {
    "text": "which is a string processing counterpart to Kinesis streams and fire hose that",
    "start": "191720",
    "end": "198080"
  },
  {
    "text": "enables all customers to express their stream processing applications in SQL the focus of this",
    "start": "198080",
    "end": "206280"
  },
  {
    "text": "stock however is going to be kin's fire host for today please please note that Kinesis analytics is still in preview",
    "start": "206280",
    "end": "213239"
  },
  {
    "text": "phase you can go up to the site and sign up and we will enable access uh down the",
    "start": "213239",
    "end": "220640"
  },
  {
    "text": "line so for several of you who are already practicing streaming data this might be a bit of an academic",
    "start": "221799",
    "end": "229560"
  },
  {
    "text": "slide but I want to share this with you to build context about the streaming data Journey that we've seen customers",
    "start": "229560",
    "end": "236560"
  },
  {
    "text": "go through now that we've had these services in Market um for three plus",
    "start": "236560",
    "end": "241959"
  },
  {
    "text": "years now agnostic of the kind of data that you're dealing with we've seen this",
    "start": "241959",
    "end": "248159"
  },
  {
    "text": "three-phase approach to how customers have engaged and dealt with streaming data the very first scenario and this is",
    "start": "248159",
    "end": "256519"
  },
  {
    "text": "common across industry verticals is a notion of accelerated ingestion with",
    "start": "256519",
    "end": "263080"
  },
  {
    "text": "minor to Major transformation and loading of that data into existing data",
    "start": "263080",
    "end": "268560"
  },
  {
    "text": "stores or analytic IAL systems it can take a variety of forms depending on",
    "start": "268560",
    "end": "273960"
  },
  {
    "text": "which industry segment or industry vertical you might belong to and here are a few examples so if you're in the",
    "start": "273960",
    "end": "280479"
  },
  {
    "text": "digital marketing or the at Tech space uh you might want to capture publisher data or bitter data and then capture",
    "start": "280479",
    "end": "288160"
  },
  {
    "text": "that stream data and load it perhaps into uh into something like Amazon S3",
    "start": "288160",
    "end": "293400"
  },
  {
    "text": "and to keep that durably persistent for as long as you need to if you are in the",
    "start": "293400",
    "end": "298840"
  },
  {
    "text": "iot space perhaps you want to capture all the individual events that your sensors or",
    "start": "298840",
    "end": "305600"
  },
  {
    "text": "devices have been emanating and then capture and perhaps persist them into a",
    "start": "305600",
    "end": "312199"
  },
  {
    "text": "uh into an easily searchable destination like elastic search if you are in the gaming vertical",
    "start": "312199",
    "end": "319080"
  },
  {
    "text": "then you want to capture your customers's engagement and click stream and tstream data as they engage with",
    "start": "319080",
    "end": "325880"
  },
  {
    "text": "your mobile gaming assets to understand uh apps down the line what it is and how",
    "start": "325880",
    "end": "331639"
  },
  {
    "text": "it is that they engage with your asset once the ability to easily capture",
    "start": "331639",
    "end": "338000"
  },
  {
    "text": "and load streaming data has been accomplished what we've noticed immediately is the desire to do",
    "start": "338000",
    "end": "343199"
  },
  {
    "text": "something else and that something else is typically generating metrics key",
    "start": "343199",
    "end": "348479"
  },
  {
    "text": "performance indicators or some such other uh uh some such other derived",
    "start": "348479",
    "end": "353800"
  },
  {
    "text": "values derived statistics of the raw data that is being computed and again",
    "start": "353800",
    "end": "358919"
  },
  {
    "text": "there are several examples depending on whichever industry segment you might belong to but",
    "start": "358919",
    "end": "364639"
  },
  {
    "text": "conceptually it's the same thing the Same by the same thing I mean the desire to go from a raw from a Raw event stream",
    "start": "364639",
    "end": "372720"
  },
  {
    "text": "into something that is suitable for you to engage in counting ultimately there",
    "start": "372720",
    "end": "378319"
  },
  {
    "text": "are a whole bunch of different kinds of Aggregates and counts that are generated off that streaming",
    "start": "378319",
    "end": "385759"
  },
  {
    "text": "data stage three if you will in the maturity model model of streaming data processing is when this realtime stream",
    "start": "385759",
    "end": "393720"
  },
  {
    "text": "data has not only been persisted has not only had metrics",
    "start": "393720",
    "end": "398840"
  },
  {
    "text": "extracted from it but is now being manifest into the Business Systems into",
    "start": "398840",
    "end": "405360"
  },
  {
    "text": "the technology infrastructure such that it can provide a feedback to help",
    "start": "405360",
    "end": "410400"
  },
  {
    "text": "improve let's say the customer experience so an example in uh uh in",
    "start": "410400",
    "end": "416160"
  },
  {
    "text": "gaming might be that you've got your customer engaging with your mobile game",
    "start": "416160",
    "end": "421199"
  },
  {
    "text": "and based on how you see them succeeding or failing in any given level having the",
    "start": "421199",
    "end": "427879"
  },
  {
    "text": "ability to give them feedback have the ability to perhaps pop up a uh a free",
    "start": "427879",
    "end": "433919"
  },
  {
    "text": "gift pop up a way for them to break through if they're getting stuck in that level uh if you are in the iot space you",
    "start": "433919",
    "end": "442080"
  },
  {
    "text": "might use that data to build a predictive model on is it likely that",
    "start": "442080",
    "end": "447160"
  },
  {
    "text": "sensors of this type are going to fail soon so that's the how that breaks down into",
    "start": "447160",
    "end": "454680"
  },
  {
    "text": "your specific vertical or use case might vary but the key takeaway here is that in this responsive data analytics World",
    "start": "454680",
    "end": "462440"
  },
  {
    "text": "your stream data is now not just a used for bi for reporting not just used for",
    "start": "462440",
    "end": "469080"
  },
  {
    "text": "long-term persistence and data science but is now manifested operationally in the way your business",
    "start": "469080",
    "end": "476639"
  },
  {
    "text": "operates all of the core Kinesis services will share these",
    "start": "477879",
    "end": "484400"
  },
  {
    "text": "properties in common traditionally building your own",
    "start": "484400",
    "end": "491039"
  },
  {
    "text": "streaming data infrastructure from scratch has been operationally complex",
    "start": "491039",
    "end": "496639"
  },
  {
    "text": "and burdensome to deal with at scale so the first order of business and this is true of many AWS",
    "start": "496639",
    "end": "504440"
  },
  {
    "text": "Services is that the core Services need to be very very simple to provision",
    "start": "504440",
    "end": "509560"
  },
  {
    "text": "deploy scale and manage the next key property and this is",
    "start": "509560",
    "end": "515159"
  },
  {
    "text": "particularly true for services that are operating on data is the ability to",
    "start": "515159",
    "end": "520560"
  },
  {
    "text": "elastically scale in response to incoming events and because we're dealing with",
    "start": "520560",
    "end": "526240"
  },
  {
    "text": "streaming data we want to make sure that the if you will the endtoend latency",
    "start": "526240",
    "end": "532399"
  },
  {
    "text": "with which we do something useful with that data is on the order of a few",
    "start": "532399",
    "end": "538320"
  },
  {
    "text": "single digigit seconds so when I I realize that the notion of",
    "start": "538320",
    "end": "543399"
  },
  {
    "text": "real-time latency might mean different things to different people but in our world uh the the world the the notion of",
    "start": "543399",
    "end": "549640"
  },
  {
    "text": "real time would be on the order of 1 second or 2 seconds or less depending on",
    "start": "549640",
    "end": "555680"
  },
  {
    "text": "on how the infrastructure gets rolled out so let's spend a couple of minutes",
    "start": "555680",
    "end": "562079"
  },
  {
    "text": "talking about Kinesis streams which was a service that started all of",
    "start": "562079",
    "end": "567800"
  },
  {
    "text": "this kinesis streams is for developers to build your own custom stream processing",
    "start": "567800",
    "end": "575040"
  },
  {
    "text": "applications it has easy Administration and by which we mean the ability to",
    "start": "575839",
    "end": "582880"
  },
  {
    "text": "create a scalable infrastructure that can capture and store your ordered",
    "start": "582880",
    "end": "589600"
  },
  {
    "text": "streaming data reliably is completely in your control",
    "start": "589600",
    "end": "595079"
  },
  {
    "text": "you indicate to the service how much capacity you want in terms of this unit",
    "start": "595079",
    "end": "600200"
  },
  {
    "text": "of scale called A Shard and you can add or remove shards and add or remove",
    "start": "600200",
    "end": "606000"
  },
  {
    "text": "capacity as a result of that once that infrastructure is created which can be changed at any point during",
    "start": "606000",
    "end": "613120"
  },
  {
    "text": "operation and you put data into your stream there are a world of technologies",
    "start": "613120",
    "end": "620279"
  },
  {
    "text": "that you can use to build your own stream processing applications as AWS we have",
    "start": "620279",
    "end": "627720"
  },
  {
    "text": "some for example the Kinesis client library is an open-source library that",
    "start": "627720",
    "end": "634360"
  },
  {
    "text": "developers can use to build their own stream processing applications we also have managed",
    "start": "634360",
    "end": "639839"
  },
  {
    "text": "services like Lambda that can consume from Kines streams without you as",
    "start": "639839",
    "end": "645279"
  },
  {
    "text": "developers and Architects having to build out any lower level platform code",
    "start": "645279",
    "end": "651200"
  },
  {
    "text": "or you can use any variety of Big Data open-source systems such as spark storm",
    "start": "651200",
    "end": "658959"
  },
  {
    "text": "Spark streaming and so on to connect with Kines streams and roll out your own",
    "start": "658959",
    "end": "664720"
  },
  {
    "text": "applications and because you have a lot of control over how you partition data how you scale your stream and how you",
    "start": "664720",
    "end": "671600"
  },
  {
    "text": "build your application really the notion of of cost come becomes completely under",
    "start": "671600",
    "end": "676959"
  },
  {
    "text": "control under your control and we have built Kinesis streams to be a very",
    "start": "676959",
    "end": "682040"
  },
  {
    "text": "lowcost streaming data ingestion environment to build your own stream processing",
    "start": "682040",
    "end": "688240"
  },
  {
    "text": "applications part of this control a part of this flexibility comes from the the variety of things that can put data into",
    "start": "688240",
    "end": "695320"
  },
  {
    "text": "your streams and the variety of ways you can build data to consume from your streams so putting or sending data into",
    "start": "695320",
    "end": "701600"
  },
  {
    "text": "your streams can be accomplished through a variety of different Technologies ranging from the core AWS sdks that we",
    "start": "701600",
    "end": "707800"
  },
  {
    "text": "event uh to a variety of open- source and third-party agents or modules",
    "start": "707800",
    "end": "712839"
  },
  {
    "text": "including log forj flume flu and d and more on the flip side where the interest",
    "start": "712839",
    "end": "718399"
  },
  {
    "text": "where the interesting stuff happens where you're building your applications you can go down to the most primitive",
    "start": "718399",
    "end": "724120"
  },
  {
    "text": "level so call into the get apis to retrieve your data and or you can use",
    "start": "724120",
    "end": "731160"
  },
  {
    "text": "something like the Kinesis client library that will make the task of writing your own at least once stream",
    "start": "731160",
    "end": "737639"
  },
  {
    "text": "processing applications a little easier or you could use something like Lambda a more event driven model where your code",
    "start": "737639",
    "end": "745120"
  },
  {
    "text": "where your function gets triggered or fired each time data is put into the",
    "start": "745120",
    "end": "750680"
  },
  {
    "text": "Kinesis stream or you could use uh some of the most uh richer Frameworks like",
    "start": "750680",
    "end": "757560"
  },
  {
    "text": "spark spark streaming and storm either running on your own infrastructure an ec2 or by using uh Amazon",
    "start": "757560",
    "end": "766160"
  },
  {
    "text": "EMR as a cluster infrastructure management tool to run your Frameworks",
    "start": "766160",
    "end": "772480"
  },
  {
    "text": "in so when you put data into a Kinesis stream each put gets automatically",
    "start": "772480",
    "end": "778760"
  },
  {
    "text": "replic ated across three availability zones so the notion of durability comes",
    "start": "778760",
    "end": "785839"
  },
  {
    "text": "from the fact that we're able to drive that three-way application by default there is no other State Management no",
    "start": "785839",
    "end": "794839"
  },
  {
    "text": "other distributed coordination service no other leader election algorithm and",
    "start": "794839",
    "end": "801079"
  },
  {
    "text": "I'm saying these things because as developers and Architects very often we have to wrestle with those kinds of",
    "start": "801079",
    "end": "808120"
  },
  {
    "text": "fundamental portions of the infrastructure and to design for scale and to design for",
    "start": "808120",
    "end": "813560"
  },
  {
    "text": "reliability and some of those tougher operational tasks which become harder at",
    "start": "813560",
    "end": "818600"
  },
  {
    "text": "scale are what Kines streams manages on your behalf as you put data the data",
    "start": "818600",
    "end": "825279"
  },
  {
    "text": "gets emitted as an ordered stream of events for you to then apply your",
    "start": "825279",
    "end": "830920"
  },
  {
    "text": "business logic under whatever specific application framework for yourself and so of the same stream of",
    "start": "830920",
    "end": "838079"
  },
  {
    "text": "data you can build multiple consuming applications that are mutually",
    "start": "838079",
    "end": "844120"
  },
  {
    "text": "independent have may have nothing to do with each other and they can each be consuming independently from their",
    "start": "844120",
    "end": "850000"
  },
  {
    "text": "stream to drive for their outcome and that in essence is the Hallmark of kesa",
    "start": "850000",
    "end": "856959"
  },
  {
    "text": "streams multiple producers that can feed multiple consuming applications Each of",
    "start": "856959",
    "end": "863759"
  },
  {
    "text": "which is independently but concurrently processing the stream or stream of",
    "start": "863759",
    "end": "871519"
  },
  {
    "text": "data so some of the new things that we've introduced uh over the last 6",
    "start": "871519",
    "end": "877399"
  },
  {
    "text": "months uh include uh brand new API for high scale uh We've introduced a",
    "start": "877399",
    "end": "883920"
  },
  {
    "text": "producer library that you can as developers and Architects build into your applications that are sending data",
    "start": "883920",
    "end": "891639"
  },
  {
    "text": "and it wraps up all the apis in an elegant fashion to get you to a high throughput system while minimizing the",
    "start": "891639",
    "end": "898839"
  },
  {
    "text": "work work that you have to do in writing very lowlevel code we've included new features like server side timestamps now",
    "start": "898839",
    "end": "906399"
  },
  {
    "text": "each record that is ingested into the stream has embedded within it an approximate arrival Tim stamp something",
    "start": "906399",
    "end": "913440"
  },
  {
    "text": "that you can then use to build your time window applications and all data stored",
    "start": "913440",
    "end": "920120"
  },
  {
    "text": "in the Kinesis stream is available for 24 hours but with a single API call you can",
    "start": "920120",
    "end": "927519"
  },
  {
    "text": "change that to up to seven days days in in Day Day increments so maybe you're stepping into a big launch and uh and",
    "start": "927519",
    "end": "935240"
  },
  {
    "text": "it's also a 3-day weekend and you want to make sure that in case there is an operational event you need to have the",
    "start": "935240",
    "end": "941240"
  },
  {
    "text": "data available then you can simply turn that API on and after 4 days once everybody's back and the risk has been",
    "start": "941240",
    "end": "948839"
  },
  {
    "text": "minimized you can turn it back to its default 24 hours and some other interesting use",
    "start": "948839",
    "end": "955000"
  },
  {
    "text": "cases happen as a result because now the data is persisted for up to 7 days which",
    "start": "955000",
    "end": "960120"
  },
  {
    "text": "means you instead of merely looking at it as an operational event Tool uh",
    "start": "960120",
    "end": "965639"
  },
  {
    "text": "feature you can start doing interesting things with an ordered event stream that",
    "start": "965639",
    "end": "970759"
  },
  {
    "text": "is up to 7 days old so now I'm going to skip to our",
    "start": "970759",
    "end": "977560"
  },
  {
    "text": "other service so we so far we spoke about streams uh lower level primitive",
    "start": "977560",
    "end": "983199"
  },
  {
    "text": "uh where you have complete control and flexibility to build your streaming data pipeline so the number one thing we we",
    "start": "983199",
    "end": "989040"
  },
  {
    "text": "learned with Kinesis streams is that the canonical use case for streaming data in",
    "start": "989040",
    "end": "994399"
  },
  {
    "text": "a massive stroke of irony is to batch it and then load it into a persistent",
    "start": "994399",
    "end": "1000880"
  },
  {
    "text": "store um now in true Amazon fashion you know the experience that we when we",
    "start": "1000880",
    "end": "1006399"
  },
  {
    "text": "heard customers build was that we do that time and time again and if I'm not",
    "start": "1006399",
    "end": "1011680"
  },
  {
    "text": "if I don't desire an absolute realtime processing infrastructure and what I care about is using my existing tools my",
    "start": "1011680",
    "end": "1019600"
  },
  {
    "text": "existing bi tools my existing analytical tools that either feed from S3 or Connect into red shift why don't you",
    "start": "1019600",
    "end": "1027360"
  },
  {
    "text": "make my life easier and thus fire hose respond it is a fully managed Service uh",
    "start": "1027360",
    "end": "1035400"
  },
  {
    "text": "to capture and load these streams of data into destinations like S3 and red",
    "start": "1035400",
    "end": "1041000"
  },
  {
    "text": "shift and in the future there will be other destinations that we'll support so unlike kesa streams you don't",
    "start": "1041000",
    "end": "1049320"
  },
  {
    "text": "build an application and you don't manage the notion of a stream or A Shard",
    "start": "1049320",
    "end": "1056160"
  },
  {
    "text": "you don't scale the stream up or down all of those elements are completely",
    "start": "1056160",
    "end": "1062360"
  },
  {
    "text": "managed and you interact with the service through the console or through a simple set of apis and have",
    "start": "1062360",
    "end": "1069120"
  },
  {
    "text": "configurations to instruct the service to do things like batch your data apply",
    "start": "1069120",
    "end": "1074559"
  },
  {
    "text": "a compression algorithm on the data uh provide encryption using KMS and then load the data into things like",
    "start": "1074559",
    "end": "1082120"
  },
  {
    "text": "S3 and red shift that entire pipeline scales elastically based on your",
    "start": "1082120",
    "end": "1087600"
  },
  {
    "text": "incoming workload so it's a as close to a zero touch platform uh as as as we can",
    "start": "1087600",
    "end": "1094280"
  },
  {
    "text": "get when it comes to dealing with streaming data much like with Kinesis streams",
    "start": "1094280",
    "end": "1100640"
  },
  {
    "text": "there are a variety of ways to put data into fire hose here are a few examples",
    "start": "1100640",
    "end": "1105799"
  },
  {
    "text": "all of our AWS sdks uh obviously support firose apis uh we've got an agent uh",
    "start": "1105799",
    "end": "1113640"
  },
  {
    "text": "that is that you can do a Pudo yam install right now because it's available in all uh Amazon uh Linux images a based",
    "start": "1113640",
    "end": "1123320"
  },
  {
    "text": "ec2 instances uh and you can start sending data from let's say those instances comprise your frontend Fleet",
    "start": "1123320",
    "end": "1129760"
  },
  {
    "text": "or a proxy Fleet to send that file oriented data into Kinesis fire host today and it also has a number of cool",
    "start": "1129760",
    "end": "1136159"
  },
  {
    "text": "features like doing transformations to convert to flatten Json convert into Json which can then make loads into red",
    "start": "1136159",
    "end": "1143120"
  },
  {
    "text": "shift a little easier uh so it's a fully managed service completely elastic and",
    "start": "1143120",
    "end": "1149159"
  },
  {
    "text": "uh the cost is 3 and5 cents per gigabyte of data transferred into that",
    "start": "1149159",
    "end": "1156600"
  },
  {
    "text": "destination so remember we went through this slide in some detail and and what we learned was how the the canonical use",
    "start": "1156600",
    "end": "1163600"
  },
  {
    "text": "case for streaming data was this capture load into my destination",
    "start": "1163600",
    "end": "1169559"
  },
  {
    "text": "and that use case is exactly what fire",
    "start": "1169559",
    "end": "1174600"
  },
  {
    "text": "hose intends to solve so",
    "start": "1174600",
    "end": "1179840"
  },
  {
    "text": "regardless so regardless of kind of data source if you intend to capture and",
    "start": "1180559",
    "end": "1186120"
  },
  {
    "text": "store your data into something like S3 and red shift then Kinesis fire hose um",
    "start": "1186120",
    "end": "1192280"
  },
  {
    "text": "is a great way to get started on that Journey let's look at the the customer",
    "start": "1192280",
    "end": "1197320"
  },
  {
    "text": "experience really quick uh very simple Concepts uh as I said earlier you're not",
    "start": "1197320",
    "end": "1202760"
  },
  {
    "text": "going to write any custom code using any framework um which means the only thing",
    "start": "1202760",
    "end": "1208919"
  },
  {
    "text": "you need to know is that there is a notion of a delivery stream whose uh job in life is to capture that data and",
    "start": "1208919",
    "end": "1215480"
  },
  {
    "text": "deliver it there are records this is the event or the raw data that you put into",
    "start": "1215480",
    "end": "1221480"
  },
  {
    "text": "that firose and then the data producer which could be uh which is which is the",
    "start": "1221480",
    "end": "1226799"
  },
  {
    "text": "entity that is generating that data this could be your application running on ec2 it could be your smartphone app it could",
    "start": "1226799",
    "end": "1232880"
  },
  {
    "text": "be a sensor a device so on so forth so data producers of which there are many",
    "start": "1232880",
    "end": "1238520"
  },
  {
    "text": "and numerous will send records into a delivery stream whose job in life is to",
    "start": "1238520",
    "end": "1245720"
  },
  {
    "text": "do a best practices load into the specified destination that you've",
    "start": "1245720",
    "end": "1251080"
  },
  {
    "text": "configured okay so in the console today if you go if you log in youve never use streams or fire hose you get presented",
    "start": "1251080",
    "end": "1258120"
  },
  {
    "text": "with these op options you pick something like fire hose and the first thing you'll do is hey where do you want the",
    "start": "1258120",
    "end": "1264039"
  },
  {
    "text": "data to go and you can pick I want S3 or I want dread shift you say S3 you give your stream a name uh and you you",
    "start": "1264039",
    "end": "1271480"
  },
  {
    "text": "instruct to it which bucket that you want your data delivered into and optionally you can specify a prefix that",
    "start": "1271480",
    "end": "1277559"
  },
  {
    "text": "you can then rely on for Downstream processing you hit next uh you get some",
    "start": "1277559",
    "end": "1282960"
  },
  {
    "text": "other options uh that you can optionally configure these include setting the buffer size in megabytes setting a",
    "start": "1282960",
    "end": "1289679"
  },
  {
    "text": "buffer interval optionally which is how how long do you want for fire hose to buffer your data before it emits it into",
    "start": "1289679",
    "end": "1297080"
  },
  {
    "text": "S3 or or instantiates a copy into red shift uh you can optionally also apply",
    "start": "1297080",
    "end": "1303440"
  },
  {
    "text": "compression and encryption and of course uh as with all things on on AWS IM am is",
    "start": "1303440",
    "end": "1308880"
  },
  {
    "text": "kind of the the important currency by which you grant and revoke permissions",
    "start": "1308880",
    "end": "1313960"
  },
  {
    "text": "for services to operate within your security context",
    "start": "1313960",
    "end": "1320480"
  },
  {
    "text": "red shift operates in a similar fashion in that fire hose will first emit or",
    "start": "1320480",
    "end": "1327679"
  },
  {
    "text": "stage the data in your S3 bucket and that's generally a good idea because a",
    "start": "1327679",
    "end": "1333640"
  },
  {
    "text": "number of things could be happening inside of your red shift cluster and you want for all of your",
    "start": "1333640",
    "end": "1339240"
  },
  {
    "text": "data to always be safe and durably stored in the event that there is for",
    "start": "1339240",
    "end": "1345760"
  },
  {
    "text": "whatever reason a red cluster being overloaded maybe there's a rogue query uh maybe you've uh maybe it's under",
    "start": "1345760",
    "end": "1352080"
  },
  {
    "text": "provision at that point in time you want peace of mind that the data always exists inside of S3 additionally what",
    "start": "1352080",
    "end": "1358799"
  },
  {
    "text": "we've noticed is that red shift can be used for several wonderful use cases uh but a variety of other uh tooling and",
    "start": "1358799",
    "end": "1367640"
  },
  {
    "text": "applications might be using S3 as its durable persistence store so in this",
    "start": "1367640",
    "end": "1373640"
  },
  {
    "text": "scenario you uh you provide the S3 bucket that phro data into and then",
    "start": "1373640",
    "end": "1380279"
  },
  {
    "text": "there and you provide the ret cluster details and the key thing here is that firose is executing a copy command that",
    "start": "1380279",
    "end": "1386840"
  },
  {
    "text": "you provide so using things like the agent you can get the data to a",
    "start": "1386840",
    "end": "1392039"
  },
  {
    "text": "relatively clean state but then right after that it is your copy command that",
    "start": "1392039",
    "end": "1397960"
  },
  {
    "text": "firehose will execute in a best practices manner to load the data into your red shift cluster including doing",
    "start": "1397960",
    "end": "1404679"
  },
  {
    "text": "things like retrying uh setting error notification and logging and a number of other features to make sure that that",
    "start": "1404679",
    "end": "1411080"
  },
  {
    "text": "headache is what fireos takes care of so I I spoke to you a little bit about um",
    "start": "1411080",
    "end": "1417679"
  },
  {
    "text": "about the agent uh and I won't go into many details uh it is software",
    "start": "1417679",
    "end": "1423039"
  },
  {
    "text": "pre-installed the source is available as well it behaves like many other agents do which is to make the task of capture",
    "start": "1423039",
    "end": "1430039"
  },
  {
    "text": "and sending buffering and sending data including doing Transformations uh",
    "start": "1430039",
    "end": "1436000"
  },
  {
    "text": "format conversion and log parsing easier on the box before it's sent and that's",
    "start": "1436000",
    "end": "1441200"
  },
  {
    "text": "super helpful when you're loading data into more structured if you will data",
    "start": "1441200",
    "end": "1446279"
  },
  {
    "text": "analytics destinations like red",
    "start": "1446279",
    "end": "1449960"
  },
  {
    "text": "shift again this's a simple pay too pricing which is three and a half cents per gigabyte and then for those of you",
    "start": "1451880",
    "end": "1457240"
  },
  {
    "text": "who are wondering should I use streams or fire hose before I hand it off to Rick um if you're looking to build",
    "start": "1457240",
    "end": "1463960"
  },
  {
    "text": "costume stream processing applications when you care about real ESS",
    "start": "1463960",
    "end": "1469600"
  },
  {
    "text": "you start with ginesa streams where if you are looking to only really capture",
    "start": "1469600",
    "end": "1475679"
  },
  {
    "text": "and deliver your stream data into those destinations start with fire hose and there are a number of good",
    "start": "1475679",
    "end": "1482039"
  },
  {
    "text": "reasons to use them together for their specific use cases uh that Rick will now",
    "start": "1482039",
    "end": "1489559"
  },
  {
    "text": "highlight and just I'll just leave you with one last thing uh Kinesis analytics as I mentioned before is a stream",
    "start": "1489559",
    "end": "1495960"
  },
  {
    "text": "processing service while it's not generally available able yet you can sign up for it and we opening up preview",
    "start": "1495960",
    "end": "1502000"
  },
  {
    "text": "and think about it as yet another consuming application except that instead of learning new programming",
    "start": "1502000",
    "end": "1508000"
  },
  {
    "text": "languages new Frameworks and then managing them it uses SQL so now finally I want to hand the",
    "start": "1508000",
    "end": "1515960"
  },
  {
    "text": "off uh to Rick who is the VP and chief data scientist at H Corporation um he",
    "start": "1515960",
    "end": "1522520"
  },
  {
    "text": "has over 25 years of experience in the data space uh both from an academic",
    "start": "1522520",
    "end": "1529880"
  },
  {
    "text": "perspective and from building designing and managing enterprise-wide uh data system so I",
    "start": "1529880",
    "end": "1537559"
  },
  {
    "text": "can't think of a better person to share his industry perspective as well as how",
    "start": "1537559",
    "end": "1542919"
  },
  {
    "text": "he has built and designed her uh Big Data Systems especially to deal with",
    "start": "1542919",
    "end": "1548159"
  },
  {
    "text": "clickstream analytics thanks AI hello thank you AI thanks AWS for having",
    "start": "1548159",
    "end": "1556399"
  },
  {
    "text": "me um I'm going to talk to you today on a more practical level on how at Hurst",
    "start": "1556399",
    "end": "1563480"
  },
  {
    "text": "we actually used all the stuff the Kinesis stream and all of the uh AWS uh",
    "start": "1563480",
    "end": "1569399"
  },
  {
    "text": "offerings to actually build a data stream as well as a product I'm going to share with you a product uh I'm going to",
    "start": "1569399",
    "end": "1576679"
  },
  {
    "text": "kind of walk through the pipeline development that we did uh and as I do that I'll share with",
    "start": "1576679",
    "end": "1582120"
  },
  {
    "text": "you Lessons Learned those of you that are trying to do this yourselves uh I want to be able to see if there's any",
    "start": "1582120",
    "end": "1588679"
  },
  {
    "text": "tips I can provide to maybe accelerate your process through that and then uh if we have any time at the end we'll do",
    "start": "1588679",
    "end": "1594440"
  },
  {
    "text": "we'll do some questions um and uh to keep track of",
    "start": "1594440",
    "end": "1600120"
  },
  {
    "text": "time here I I do have a couple of Preamble slides uh I know we've mentioned a lot about clickstream but I",
    "start": "1600120",
    "end": "1606200"
  },
  {
    "text": "do think uh it's important to um kind of ground the conversation around why is",
    "start": "1606200",
    "end": "1612520"
  },
  {
    "text": "clickstream important why do we care about it why is Hurst looking at it um",
    "start": "1612520",
    "end": "1617760"
  },
  {
    "text": "the way I look at the clickstream is it's really about chasing the customer um and I started as as aie",
    "start": "1617760",
    "end": "1625159"
  },
  {
    "text": "mentioned a long time ago and when I started the customer data that we had was collected through a survey how how",
    "start": "1625159",
    "end": "1630919"
  },
  {
    "text": "many of you remember surveys um you would get the discs once",
    "start": "1630919",
    "end": "1636240"
  },
  {
    "text": "a week or once a month and you would load that customer survey into your computer and do some analysis on it",
    "start": "1636240",
    "end": "1642520"
  },
  {
    "text": "right um so fast forward a few years uh in the 2000s we began to start to look",
    "start": "1642520",
    "end": "1649320"
  },
  {
    "text": "at clickstream data or web data a lot of the data that we used to follow the customer they they all migrated online",
    "start": "1649320",
    "end": "1656919"
  },
  {
    "text": "so we started tracking data uh through online behaviors through companies like omniture or Google",
    "start": "1656919",
    "end": "1664039"
  },
  {
    "text": "analytics or if you have your own if you have your own uh data collection",
    "start": "1664039",
    "end": "1669320"
  },
  {
    "text": "process um but now we've now migrated into actually a world where now every device I see everybody has maybe a",
    "start": "1669320",
    "end": "1675600"
  },
  {
    "text": "laptop and a computer here with them uh maybe even some of you have apple watches all these devices are",
    "start": "1675600",
    "end": "1682559"
  },
  {
    "text": "Distributing information about your customers and each one of these devices provide data back if you know how to",
    "start": "1682559",
    "end": "1689799"
  },
  {
    "text": "gather it and the challenge we have at Hurst is really what I think around",
    "start": "1689799",
    "end": "1695720"
  },
  {
    "text": "reassembling the customer how do I put them back together now that I have all these different devices uh that they're",
    "start": "1695720",
    "end": "1703440"
  },
  {
    "text": "using and maybe uh when will it stop what's the future",
    "start": "1703440",
    "end": "1708840"
  },
  {
    "text": "uh it may actually be thoughtstream data um there's a study about uh in",
    "start": "1708840",
    "end": "1714519"
  },
  {
    "text": "Australia where a person had some wiring on their heads and there was another guy",
    "start": "1714519",
    "end": "1719960"
  },
  {
    "text": "in uh in London and the guy in Australia thought lift your right hand and the guy",
    "start": "1719960",
    "end": "1725720"
  },
  {
    "text": "in London lifted his right hand arm so there is there is potential for",
    "start": "1725720",
    "end": "1732320"
  },
  {
    "text": "maybe transmitting thought data what will that look like I don't know um so anyway in the context of this",
    "start": "1732320",
    "end": "1740000"
  },
  {
    "text": "discussion and and what the way I view hurst's clickstream data is really the real-time transmission and collection of",
    "start": "1740000",
    "end": "1748039"
  },
  {
    "text": "data that actually allows me to get as close to the customer as I can with as much information about the customer as I",
    "start": "1748039",
    "end": "1753960"
  },
  {
    "text": "can get and I need to be able to stream this massive information back to my uh",
    "start": "1753960",
    "end": "1760799"
  },
  {
    "text": "warehouse and then build Products off of it",
    "start": "1760799",
    "end": "1767039"
  },
  {
    "text": "good so I like to start uh before I get really into the the warehouse and how we",
    "start": "1767039",
    "end": "1772880"
  },
  {
    "text": "built the pipeline uh asking the question of how many people have ever heard of Hurst how about the company",
    "start": "1772880",
    "end": "1780559"
  },
  {
    "text": "Hurst I have a joke my dad thinks it's heurst he forgets the tea um well that's",
    "start": "1780559",
    "end": "1786919"
  },
  {
    "text": "pretty good A lot of people have not heard of us but we're actually a very large Media company and we have uh 20",
    "start": "1786919",
    "end": "1795000"
  },
  {
    "text": "nearly 20 magazines uh in the uh United States but we have over 300 Publications",
    "start": "1795000",
    "end": "1800799"
  },
  {
    "text": "uh internationally we uh own 15 newspapers and 34 dailies you might recognize some",
    "start": "1800799",
    "end": "1807600"
  },
  {
    "text": "of these we have uh over 30 television stations each one of these stations have",
    "start": "1807600",
    "end": "1813840"
  },
  {
    "text": "websites and properties we're also into businessto business we uh own Fitch",
    "start": "1813840",
    "end": "1821720"
  },
  {
    "text": "ratings uh we have a lot of Automotive related data companies and uh we also",
    "start": "1821720",
    "end": "1826880"
  },
  {
    "text": "have some healthcare related data companies and a lot of us when you think of Hurst you probably thought in the",
    "start": "1826880",
    "end": "1832360"
  },
  {
    "text": "back of your head a publisher right or a media company um but I actually uh I actually",
    "start": "1832360",
    "end": "1840279"
  },
  {
    "text": "view hurst's 300 plus websites and companies as a data creation company I",
    "start": "1840279",
    "end": "1846000"
  },
  {
    "text": "believe that our business is around data creation um if you think about your",
    "start": "1846000",
    "end": "1853480"
  },
  {
    "text": "computers and and all the apps that are powering it and and maybe Facebook for example if you go back to the early",
    "start": "1853480",
    "end": "1859960"
  },
  {
    "text": "2000s when it was launched or 1995 it was just a white page with some blue",
    "start": "1859960",
    "end": "1865600"
  },
  {
    "text": "text very little in it go to Facebook today type in the word Cosmo or l or any",
    "start": "1865600",
    "end": "1871480"
  },
  {
    "text": "of these Publications and you'll start to see just how much uh our data",
    "start": "1871480",
    "end": "1876559"
  },
  {
    "text": "actually fuels the internet um your apps probably tell you how to get dressed in the morning what",
    "start": "1876559",
    "end": "1882919"
  },
  {
    "text": "the weather will be like what the school closings will be that all comes from our editors from our our websites um from",
    "start": "1882919",
    "end": "1889760"
  },
  {
    "text": "our newspaper sites that we have all over the world all over the",
    "start": "1889760",
    "end": "1894638"
  },
  {
    "text": "country so um so Hurst recognized that we're a big data company and we have a",
    "start": "1896360",
    "end": "1903440"
  },
  {
    "text": "lot of properties with a lot of data and they're all creating data and that's fueling the internet so what do we do",
    "start": "1903440",
    "end": "1909279"
  },
  {
    "text": "about it so uh four years ago we created a group called the heurst data services",
    "start": "1909279",
    "end": "1915000"
  },
  {
    "text": "team which I manage um we came up with the name data services because we feel that uh it's",
    "start": "1915000",
    "end": "1922799"
  },
  {
    "text": "not just data science it's not just data collection it's actually providing data as a service for the",
    "start": "1922799",
    "end": "1928480"
  },
  {
    "text": "organization uh my team is focused on unifying the pedabytes of data that Hurst creates developing a platform by",
    "start": "1928480",
    "end": "1937240"
  },
  {
    "text": "which we can then redistribute that data to the business and then promote product development on that on that",
    "start": "1937240",
    "end": "1944399"
  },
  {
    "text": "platform so what I wanted to share with you today with talked a lot about Kinesis and the fire hose I'm going to",
    "start": "1944399",
    "end": "1950880"
  },
  {
    "text": "sh walk you through a product development initiative that we've done at Hurst and the data pipeline which was",
    "start": "1950880",
    "end": "1957519"
  },
  {
    "text": "required to fuel to the engine for that product and show you each of the different AWS resources that we use to",
    "start": "1957519",
    "end": "1963960"
  },
  {
    "text": "build it so when you leave here I hopefully you'll feel confident that you can also build products in a pipeline in",
    "start": "1963960",
    "end": "1971440"
  },
  {
    "text": "your organization so I have a demo here to show you that uh is of a product that",
    "start": "1971440",
    "end": "1979639"
  },
  {
    "text": "our editors at Hurst use I think if we can we're going to do a little side uh",
    "start": "1979639",
    "end": "1986320"
  },
  {
    "text": "thing here where this is actually a a a view of our product how many of you have used uh Yahoo's web page for example the",
    "start": "1986320",
    "end": "1993799"
  },
  {
    "text": "homepage for Yahoo that's a curated news feed so Hurst has over 300 websites with",
    "start": "1993799",
    "end": "2001399"
  },
  {
    "text": "over we have thousands of editors around the world producing content and we wanted to create a",
    "start": "2001399",
    "end": "2007039"
  },
  {
    "text": "product that would allow the editors to see and curate our own content and feed it back",
    "start": "2007039",
    "end": "2012480"
  },
  {
    "text": "to the editors in a platform where they could sort the content uh on a scale",
    "start": "2012480",
    "end": "2018000"
  },
  {
    "text": "that was determined by our data scientists a special numeric metric that's valuable to us we can sort all of",
    "start": "2018000",
    "end": "2025200"
  },
  {
    "text": "our content so find out what's the most popular piece of content find out what it's trending on in real time and then",
    "start": "2025200",
    "end": "2031240"
  },
  {
    "text": "you can actually click on that content and if you're an L editor and you see a cosmo content you can republish that on",
    "start": "2031240",
    "end": "2040000"
  },
  {
    "text": "top of your l site you can take a piece of content that is trending and",
    "start": "2040000",
    "end": "2045799"
  },
  {
    "text": "repurpose it very quickly onto your website and exponentially grow the page views and the interest on that piece of",
    "start": "2045799",
    "end": "2052398"
  },
  {
    "text": "content so it's basically a re circulation engine that connects the whole company and allows the company to",
    "start": "2052399",
    "end": "2058919"
  },
  {
    "text": "redistribute content across our our 300 websites that generate over",
    "start": "2058919",
    "end": "2064118"
  },
  {
    "text": "350 million uniques a month um so as you can see it's a pretty",
    "start": "2064119",
    "end": "2072079"
  },
  {
    "text": "functional UI it's actually in my opinion my my wife actually likes it better than Yahoo uh because it has all",
    "start": "2072079",
    "end": "2078358"
  },
  {
    "text": "the really juicy stuff on it uh but I'm going to switch back to the to the uh presentation",
    "start": "2078359",
    "end": "2084560"
  },
  {
    "text": "now so what happened was is the uh Business Development Group came to me",
    "start": "2084560",
    "end": "2090280"
  },
  {
    "text": "the data services team and said we want to build this this do did not exist and I said I'm an engineer and said well I",
    "start": "2090280",
    "end": "2098240"
  },
  {
    "text": "need to convert this object into engineering requirements oh before I get there the",
    "start": "2098240",
    "end": "2106560"
  },
  {
    "text": "this product itself has already at hearsed grown our page we have 20 million 20 billion page views a year",
    "start": "2106560",
    "end": "2113040"
  },
  {
    "text": "we've increased our page views by 25% by taking our our best content and",
    "start": "2113040",
    "end": "2119520"
  },
  {
    "text": "distributing we've grown our visitor account by 15% and we have a lot of",
    "start": "2119520",
    "end": "2124720"
  },
  {
    "text": "visitors 350 million a month already so just creating a piece of just creating a",
    "start": "2124720",
    "end": "2130440"
  },
  {
    "text": "product that connects a business and is empowered by a data engine can really",
    "start": "2130440",
    "end": "2136240"
  },
  {
    "text": "accelerate the growth of your company if you're if you're a distributed company like ours",
    "start": "2136240",
    "end": "2141640"
  },
  {
    "text": "this so the product team came to me and say hey Rick we got to build this you got to connect we got to connect the",
    "start": "2141640",
    "end": "2147520"
  },
  {
    "text": "editors across the world I said wait a minute what are the requirements what are the engineering requirements and so",
    "start": "2147520",
    "end": "2154560"
  },
  {
    "text": "we sat down and they have this these were the goals the requirements they came up with they have a throughput goal",
    "start": "2154560",
    "end": "2159760"
  },
  {
    "text": "number one we have to be able to feed all 350 websites",
    "start": "2159760",
    "end": "2165960"
  },
  {
    "text": "internationally across the world into this tool we have a latency goal of under",
    "start": "2165960",
    "end": "2171760"
  },
  {
    "text": "five minutes that means when somebody publishes an article and it starts generating clicks within five minutes I",
    "start": "2171760",
    "end": "2177680"
  },
  {
    "text": "want that Editor to see what's going on uh we need to have an agile interface",
    "start": "2177680",
    "end": "2185400"
  },
  {
    "text": "so uh the the the front end has to be very flexible you have to be able to control the metrics so I need this data",
    "start": "2185400",
    "end": "2192119"
  },
  {
    "text": "engine to be very flexible so you can create a whole bunch of new metrics uh I got to create some unique",
    "start": "2192119",
    "end": "2198920"
  },
  {
    "text": "metrics because the data science guys have these very Advanced uh models that",
    "start": "2198920",
    "end": "2206000"
  },
  {
    "text": "they use to create that special metric on the left side of the stream and it's a it's actually a very massive formula",
    "start": "2206000",
    "end": "2212720"
  },
  {
    "text": "and so I need to be able to plug into this process data science which if you've familiar with your data science",
    "start": "2212720",
    "end": "2218960"
  },
  {
    "text": "teams that's not easy to do in in in a rapid environment uh we have reporting windows",
    "start": "2218960",
    "end": "2225200"
  },
  {
    "text": "so that the tool needs to be able to tell you me what's happened in the last hour the last week the last day and the",
    "start": "2225200",
    "end": "2231760"
  },
  {
    "text": "last week so it has to have ability to look at Windows of time the editor wants to",
    "start": "2231760",
    "end": "2237800"
  },
  {
    "text": "look at their article and the performance of that article in the last week for",
    "start": "2237800",
    "end": "2243040"
  },
  {
    "text": "example and uh it has to have a very flexible environment because the UI guys",
    "start": "2243040",
    "end": "2248640"
  },
  {
    "text": "are constantly tweaking the tool and so I need to be able to have the endpoint of my uh data pipeline be very flexible",
    "start": "2248640",
    "end": "2255280"
  },
  {
    "text": "to add variables and metrics finally you got to build this",
    "start": "2255280",
    "end": "2261839"
  },
  {
    "text": "thing Rick without interrupting the business as it is today so kind of like flying a plane and",
    "start": "2261839",
    "end": "2269960"
  },
  {
    "text": "changing the engines without Landing so what did I have to start with",
    "start": "2269960",
    "end": "2275359"
  },
  {
    "text": "I had I had a uh this is what I had to work with we have and this may be familiar to you we had",
    "start": "2275359",
    "end": "2282440"
  },
  {
    "text": "Adobe on our websites omat uh we had it on a few websites and Adobe would send",
    "start": "2282440",
    "end": "2288400"
  },
  {
    "text": "us data uh clickstream data and a data dump and it would go to our NAA",
    "start": "2288400",
    "end": "2294160"
  },
  {
    "text": "cluster and uh I could write my team could write some SQL on it and we would",
    "start": "2294160",
    "end": "2299200"
  },
  {
    "text": "put together PowerPoint presentations and deliver it to the to the businesses does that sound kind of familiar to your",
    "start": "2299200",
    "end": "2305640"
  },
  {
    "text": "if you're doing any business today used that model before so that's not a that's not a",
    "start": "2305640",
    "end": "2312280"
  },
  {
    "text": "rapid product environment is it so how do I go from this to what I need to do",
    "start": "2312280",
    "end": "2319400"
  },
  {
    "text": "and that's where you know we we started our journey with",
    "start": "2319400",
    "end": "2324838"
  },
  {
    "text": "AWS I'm going to walk through the data pipeline which is the engine behind this and how the data pipeline evolved and it",
    "start": "2325040",
    "end": "2332720"
  },
  {
    "text": "evolved in stages it wasn't just built beginning to end all at once it",
    "start": "2332720",
    "end": "2338040"
  },
  {
    "text": "was built in stages and if you're trying to build a data pipeline I highly recommend you follow this roll out",
    "start": "2338040",
    "end": "2344280"
  },
  {
    "text": "yourself uh because it you can't just do it all at once there's too many",
    "start": "2344280",
    "end": "2350280"
  },
  {
    "text": "steps so the first step in building a data pipeline is you got to first start at",
    "start": "2350280",
    "end": "2355880"
  },
  {
    "text": "the very beginning you have to start with inest you have to collect the data and this took a lot of effort and the reason that's why you start with it",
    "start": "2355880",
    "end": "2363119"
  },
  {
    "text": "first um we had to be able to collect data from our throughput goal from all 350",
    "start": "2363119",
    "end": "2369160"
  },
  {
    "text": "websites how do I get data streaming from all 350 websites and uh that's",
    "start": "2369160",
    "end": "2376240"
  },
  {
    "text": "where I met Kinesis so um the first thing I did",
    "start": "2376240",
    "end": "2381839"
  },
  {
    "text": "before I could even play with Kinesis is I had to control the JavaScript on the websites I had to get access to it",
    "start": "2381839",
    "end": "2387920"
  },
  {
    "text": "because I couldn't interrupt the engineers on those websites so I installed a tag manager I don't know are",
    "start": "2387920",
    "end": "2394160"
  },
  {
    "text": "you familiar with a tag manager anybody okay so your website has a bunch of",
    "start": "2394160",
    "end": "2399440"
  },
  {
    "text": "little JavaScript pieces on it that are called Tags that transmit data away uh so what we did is we created a",
    "start": "2399440",
    "end": "2406760"
  },
  {
    "text": "bucket a tag manager which is a bucket where you put all the tags and a tag manager is more than a tag management",
    "start": "2406760",
    "end": "2412880"
  },
  {
    "text": "system it's actually it actually gains access to the websites uh where you have a console a",
    "start": "2412880",
    "end": "2419720"
  },
  {
    "text": "centralized console where you can distribute JavaScript and uh data or code to all of the websites that have",
    "start": "2419720",
    "end": "2426119"
  },
  {
    "text": "the tag manager object on it so I first built a I first",
    "start": "2426119",
    "end": "2432960"
  },
  {
    "text": "introduced a tag management solution to Hurst put all of our tags into it and",
    "start": "2432960",
    "end": "2438480"
  },
  {
    "text": "created a centralized platform we used a company called insiten and uh that gave me access to",
    "start": "2438480",
    "end": "2445440"
  },
  {
    "text": "the websites what I was then able to do is I was then able to work with the AWS",
    "start": "2445440",
    "end": "2450480"
  },
  {
    "text": "Partners to create to put some JavaScript on all the websites that allowed us to put data into the Kinesis",
    "start": "2450480",
    "end": "2456800"
  },
  {
    "text": "stream so I transmitted all the data to a uh",
    "start": "2456800",
    "end": "2462440"
  },
  {
    "text": "bean stock elastic bean stock and then that at the time placed the data onto",
    "start": "2462440",
    "end": "2468119"
  },
  {
    "text": "the Kinesis stream so I was able to distribute code to all the websites and actually finally load data into the",
    "start": "2468119",
    "end": "2474960"
  },
  {
    "text": "Kinesis stream and at the time we used a KCl library to offload it into S3 you",
    "start": "2474960",
    "end": "2481440"
  },
  {
    "text": "can now use fire host it's a lot easier but essentially all I did collect all",
    "start": "2481440",
    "end": "2486640"
  },
  {
    "text": "the data from the websites and dump it into into storage nothing else full stop",
    "start": "2486640",
    "end": "2492160"
  },
  {
    "text": "start collecting the data make sure that you have all the websites lined up and you're streaming the data into",
    "start": "2492160",
    "end": "2499200"
  },
  {
    "text": "storage and rest so that's a lot of",
    "start": "2499200",
    "end": "2504520"
  },
  {
    "text": "work um couple of tips here Json formatting is uh extremely valuable uh",
    "start": "2504520",
    "end": "2512079"
  },
  {
    "text": "as you go down the stream it gives you maximum flexibility especially when you're dealing with red shift and with the constant adding and subtracting of",
    "start": "2512079",
    "end": "2519319"
  },
  {
    "text": "new variables we're constantly adding new variables into the Kinesis Stream So luckily we built a Json format which",
    "start": "2519319",
    "end": "2526200"
  },
  {
    "text": "doesn't break the process as you go Downstream um uh we use some very uh elastic uh",
    "start": "2526200",
    "end": "2536319"
  },
  {
    "text": "infrastructures that allows us to scale up and down very easily um as we uh grew",
    "start": "2536319",
    "end": "2542040"
  },
  {
    "text": "our websites as the roll out came out and also use S3 to dump your data and",
    "start": "2542040",
    "end": "2547599"
  },
  {
    "text": "store it so once you have a reliable process",
    "start": "2547599",
    "end": "2552760"
  },
  {
    "text": "in place for collecting the data you want to focus on ETL why",
    "start": "2552760",
    "end": "2558160"
  },
  {
    "text": "ETL the data scientists Downstream and the products Downstream processes Downstream need",
    "start": "2558160",
    "end": "2564960"
  },
  {
    "text": "clean data or they can be more efficient if the data is clean and the data off",
    "start": "2564960",
    "end": "2570240"
  },
  {
    "text": "streaming a lot of streaming data is not very clean and it could use a little ETL",
    "start": "2570240",
    "end": "2575720"
  },
  {
    "text": "a little love um so what we did is we created a Hadoop",
    "start": "2575720",
    "end": "2583000"
  },
  {
    "text": "cluster using EMR and pulled the data off of the S3 buckets into into small",
    "start": "2583000",
    "end": "2589599"
  },
  {
    "text": "into five minute buckets and cleaned it we wrote like 50 udfs userdefined",
    "start": "2589599",
    "end": "2596040"
  },
  {
    "text": "functions because Pig needs some help uh and that was our original",
    "start": "2596040",
    "end": "2602520"
  },
  {
    "text": "process and we noticed that that was running a little slow uh so then then we were introduced",
    "start": "2602520",
    "end": "2607839"
  },
  {
    "text": "to spark which uh Audi mentioned uh that's more of a memory it's it keeps",
    "start": "2607839",
    "end": "2613079"
  },
  {
    "text": "the data in memory it doesn't require you to Rite it to the hdfs environment",
    "start": "2613079",
    "end": "2618240"
  },
  {
    "text": "and you can do your processing in memory and faster the problem with spark was",
    "start": "2618240",
    "end": "2623559"
  },
  {
    "text": "Scala how many of you guys know Scala oh wow awesome that's good zero guys on my",
    "start": "2623559",
    "end": "2631079"
  },
  {
    "text": "team new Scala so um luckily we had a Java guy that we mutated a little bit so",
    "start": "2631079",
    "end": "2637480"
  },
  {
    "text": "anyway we took the pig script and it was a little timec consuming but it's not",
    "start": "2637480",
    "end": "2642559"
  },
  {
    "text": "that hard we converted all the udfs into Scala and uh we're able to actually",
    "start": "2642559",
    "end": "2648319"
  },
  {
    "text": "convert our ETL which it is still being done today in a in a spark environment",
    "start": "2648319",
    "end": "2654760"
  },
  {
    "text": "and that's running very robustly uh and it's a very fast and",
    "start": "2654760",
    "end": "2660559"
  },
  {
    "text": "Powerful environment so now the data has been cleaned etls done",
    "start": "2660559",
    "end": "2668000"
  },
  {
    "text": "now I bring in my data science team so I have data engineering under me and I have data science two different animals",
    "start": "2668000",
    "end": "2674720"
  },
  {
    "text": "so I think it's important to you know provide clean data to your data scientists so they can really focus on",
    "start": "2674720",
    "end": "2681559"
  },
  {
    "text": "the algorithms and not on the data cleaning if you're a data scientist you know what I'm talking about so after the",
    "start": "2681559",
    "end": "2690359"
  },
  {
    "text": "spark stage we have clean data that's been slightly aggregated we at the time",
    "start": "2690359",
    "end": "2696160"
  },
  {
    "text": "had a sass data scientist that uses SAS if you're familiar with SAS and um had it on a single node and",
    "start": "2696160",
    "end": "2704160"
  },
  {
    "text": "and he would pull the data down off S3 process it in SAS and then push it back",
    "start": "2704160",
    "end": "2709200"
  },
  {
    "text": "to to the to the cloud in a folder into a into an S3 bucket called processed and",
    "start": "2709200",
    "end": "2715200"
  },
  {
    "text": "in the processing he would add his e excellent new variables that everybody uses",
    "start": "2715200",
    "end": "2720960"
  },
  {
    "text": "Downstream problem with this is uh downloading the data to a single note and doing all the data science took like",
    "start": "2720960",
    "end": "2727440"
  },
  {
    "text": "5 minutes which broke my latency throughput requirement so I had to come up with another solution for",
    "start": "2727440",
    "end": "2734240"
  },
  {
    "text": "this so this is a solution that we came up with which I think is kind of uh kind of neat and",
    "start": "2734240",
    "end": "2740680"
  },
  {
    "text": "elegant we we still use SAS because that's what my team",
    "start": "2740680",
    "end": "2746040"
  },
  {
    "text": "uses and your data science team might use a different tool like our or whatever but we will still build the",
    "start": "2746040",
    "end": "2752480"
  },
  {
    "text": "models at a every 3 hours the the program pulls down the data and rebuilds",
    "start": "2752480",
    "end": "2758760"
  },
  {
    "text": "the regression models or the the different models that they're using to create these special metrics and then",
    "start": "2758760",
    "end": "2764400"
  },
  {
    "text": "what they'll do is they'll put the coefficients into S3 the model",
    "start": "2764400",
    "end": "2769800"
  },
  {
    "text": "results we then introduce redshift into the mix and what red shift does is it's",
    "start": "2769800",
    "end": "2775319"
  },
  {
    "text": "super fast at ingesting lots of data from S3 and processing and so our red",
    "start": "2775319",
    "end": "2780520"
  },
  {
    "text": "shift cluster pulls the data in from S3 and also pulls the model coefficients in",
    "start": "2780520",
    "end": "2786200"
  },
  {
    "text": "and it creates the it creates the predicted values in S3 and then shoves that process data",
    "start": "2786200",
    "end": "2792960"
  },
  {
    "text": "back into S3 and by doing it that way we were able to accelerate it to 100",
    "start": "2792960",
    "end": "2799960"
  },
  {
    "text": "seconds so we still have this the regression and the and the modeling being done down here but we're using S3",
    "start": "2799960",
    "end": "2806400"
  },
  {
    "text": "as kind of a storage department for our",
    "start": "2806400",
    "end": "2811480"
  },
  {
    "text": "models so finally to feed the the UI we",
    "start": "2811680",
    "end": "2817280"
  },
  {
    "text": "had to build an API all UI developers need a need an API to hit and call and",
    "start": "2817280",
    "end": "2824200"
  },
  {
    "text": "so uh we made the decision at the time to use the elastic search uh because it",
    "start": "2824200",
    "end": "2831040"
  },
  {
    "text": "out of the box an Amazon elastic search has an API in points already built in so",
    "start": "2831040",
    "end": "2836319"
  },
  {
    "text": "you spin up an elastic search cluster and you stream your data into a into an index you have an API at the front end",
    "start": "2836319",
    "end": "2842400"
  },
  {
    "text": "it's nice and convenient so what we ended up doing is processing all the data and reg shift",
    "start": "2842400",
    "end": "2847760"
  },
  {
    "text": "and then dumping it into uh it makes it API ready nice and clean and dumps it",
    "start": "2847760",
    "end": "2853240"
  },
  {
    "text": "into uh elastic this is our full data pipeline now so imagine ironing it out this is",
    "start": "2853240",
    "end": "2861000"
  },
  {
    "text": "what it looks like um you have all the data coming in through the front",
    "start": "2861000",
    "end": "2867119"
  },
  {
    "text": "door uh being stuck onto the Kinesis stream and it streams into spark ETL is",
    "start": "2867119",
    "end": "2873040"
  },
  {
    "text": "being done in spark models uh the fire hose feeds it into",
    "start": "2873040",
    "end": "2878079"
  },
  {
    "text": "S3 uh models are built and uh red shift comes into play grabs the data out of S3",
    "start": "2878079",
    "end": "2885760"
  },
  {
    "text": "and funnels it into elastic this whole process we start off with 100 gigabytes",
    "start": "2885760",
    "end": "2891040"
  },
  {
    "text": "a day coming in the front door comes out to be the little API endpoints have about a a gigabyte or megabyte a",
    "start": "2891040",
    "end": "2899000"
  },
  {
    "text": "gigabyte and the whole process takes about 105 seconds 135",
    "start": "2899000",
    "end": "2905200"
  },
  {
    "text": "seconds that's on full full load click to end point 135",
    "start": "2905200",
    "end": "2912319"
  },
  {
    "text": "seconds uh this is just a quick picture of like visualization so Kinesis basically is a bulldozer shoving uh Big",
    "start": "2912720",
    "end": "2920599"
  },
  {
    "text": "Data rock into the into the pipeline uh Apache spark is breaking",
    "start": "2920599",
    "end": "2927480"
  },
  {
    "text": "that rock apart and making it into a more useful granular or pieces Amazon red shift Scoops up uh day hour and week",
    "start": "2927480",
    "end": "2937240"
  },
  {
    "text": "collections of those gravel rocks and smashes it down to create a diamond and",
    "start": "2937240",
    "end": "2942559"
  },
  {
    "text": "the diamond is the endo's uh exit value so that's quick",
    "start": "2942559",
    "end": "2949240"
  },
  {
    "text": "visualization so does that sound",
    "start": "2949240",
    "end": "2954079"
  },
  {
    "text": "doable so here's a here's a quick Lessons Learned uh so if you decide to",
    "start": "2955079",
    "end": "2960160"
  },
  {
    "text": "do this yourself um ways that we found to accelerate our process um the Top Line",
    "start": "2960160",
    "end": "2966799"
  },
  {
    "text": "line you'll notice every step of the way I offloaded data into S3 very important",
    "start": "2966799",
    "end": "2972599"
  },
  {
    "text": "thing to do because you never know which of your processes are going to break or as you learn how to use EMR you learn",
    "start": "2972599",
    "end": "2979559"
  },
  {
    "text": "how to use spark just make sure everything's being offloaded into S3 so you have persistent storage and then you",
    "start": "2979559",
    "end": "2985960"
  },
  {
    "text": "can try new things new systems to grab the data from S3 so we tried Hadoop and",
    "start": "2985960",
    "end": "2992040"
  },
  {
    "text": "we timed it against spark and when spark won we turned off our Hadoop cluster but had them running in parallel for a",
    "start": "2992040",
    "end": "2998599"
  },
  {
    "text": "while and as you can see we have a lot of S3 offloads and by removing as we",
    "start": "2998599",
    "end": "3004799"
  },
  {
    "text": "streamlined our system we simply removed S3 offload steps and tried to get straight feeds from one step to the",
    "start": "3004799",
    "end": "3011640"
  },
  {
    "text": "another uh and our today's process sort of has it really has only one S3",
    "start": "3011640",
    "end": "3019040"
  },
  {
    "text": "offload and uh by doing that we were able to eliminate a lot of the a lot of",
    "start": "3019040",
    "end": "3025000"
  },
  {
    "text": "uh speed increas the speed and then finally our future we're actually",
    "start": "3025000",
    "end": "3030559"
  },
  {
    "text": "looking at um possibly combining the red shift and the the the data science step",
    "start": "3030559",
    "end": "3037760"
  },
  {
    "text": "and the uh ETL into one environment if we can um we're also playing around with",
    "start": "3037760",
    "end": "3045119"
  },
  {
    "text": "AWS Lambda which is kind of cool more of a trigger based method to get through",
    "start": "3045119",
    "end": "3051040"
  },
  {
    "text": "the uh to get through the pipeline so that'll be at the reinvent Maybe",
    "start": "3051040",
    "end": "3057640"
  },
  {
    "text": "um so now you're probably asking so how how many Engineers do you have on your team Rick how did you do this how much",
    "start": "3057640",
    "end": "3063960"
  },
  {
    "text": "did you spend um I'm going to share with you how many this is basically how much",
    "start": "3063960",
    "end": "3070599"
  },
  {
    "text": "I used and how many people I used to build this so I really did this with three people on my team to begin",
    "start": "3070599",
    "end": "3079319"
  },
  {
    "text": "with and I think to keep it running I actually only need one person today I",
    "start": "3079319",
    "end": "3084599"
  },
  {
    "text": "did it with some AWS proos serve support um I think you could probably build a",
    "start": "3084599",
    "end": "3091040"
  },
  {
    "text": "data pipeline if if your organization is anywhere near eyes size I think you could really do it with two to three",
    "start": "3091040",
    "end": "3096319"
  },
  {
    "text": "people or if you can find a unicorn who can do everything kind of tough because there's lots of different uh tool sets",
    "start": "3096319",
    "end": "3103160"
  },
  {
    "text": "that are needed uh and we just to give you an idea if I were to build this myself with",
    "start": "3103160",
    "end": "3110640"
  },
  {
    "text": "uh old school infrastructure with buying all the equipment and hiring Engineers to manage and host all that we came up",
    "start": "3110640",
    "end": "3117680"
  },
  {
    "text": "with a cost at Hearst that the data warehouse would require about $5",
    "start": "3117680",
    "end": "3122920"
  },
  {
    "text": "million um and I think uh today we can do this in under a million and this is",
    "start": "3122920",
    "end": "3128119"
  },
  {
    "text": "for Hurst where we have two babyes of data so that's pretty substantial cost",
    "start": "3128119",
    "end": "3133680"
  },
  {
    "text": "savings and I can build this with uh just a handful of",
    "start": "3133680",
    "end": "3139040"
  },
  {
    "text": "Engineers um because AWS allows me the opportunity to um you know utilize their services to",
    "start": "3139040",
    "end": "3147680"
  },
  {
    "text": "kind of act as an engineering department for me um so with that I have we have seven",
    "start": "3147680",
    "end": "3154520"
  },
  {
    "text": "minutes uh left to maybe answer some questions if you have about the",
    "start": "3154520",
    "end": "3160280"
  },
  {
    "text": "development or Kinesis yes I'm gonna have to repeat your we're gonna have to repeat your",
    "start": "3160280",
    "end": "3166440"
  },
  {
    "text": "question unless you want to come to the microphone question how much time it to",
    "start": "3166440",
    "end": "3172400"
  },
  {
    "text": "BU so how much time did it take to build the app or the or the",
    "start": "3172880",
    "end": "3178520"
  },
  {
    "text": "UI ah so we had it it was parallel so it's done in parallel the once the",
    "start": "3178520",
    "end": "3184319"
  },
  {
    "text": "design was made the UI guys had built it they uh they built the framework the",
    "start": "3184319",
    "end": "3189960"
  },
  {
    "text": "wireframe and they built it within a couple of months the the the the um the UI itself which didn't have any",
    "start": "3189960",
    "end": "3198599"
  },
  {
    "text": "data and uh we had to create the API front end which we just basically created a static API data we just put IC",
    "start": "3198599",
    "end": "3206839"
  },
  {
    "text": "data into and made an API we did that within a couple of weeks and it was the",
    "start": "3206839",
    "end": "3212440"
  },
  {
    "text": "the UI guy was building all of his stuff off of a static data set and",
    "start": "3212440",
    "end": "3218079"
  },
  {
    "text": "then and that's a good good practice because the problem is he kept changing his requirements on what he needed for",
    "start": "3218079",
    "end": "3224520"
  },
  {
    "text": "the API to do and there's a lot of little subtes that are needed so we had to constantly tweak that before we fully",
    "start": "3224520",
    "end": "3231160"
  },
  {
    "text": "automated it so I highly recommend you wait till the UI person is done before",
    "start": "3231160",
    "end": "3236400"
  },
  {
    "text": "before you automate so yes in the",
    "start": "3236400",
    "end": "3243279"
  },
  {
    "text": "back um it's come up a few times we've got a non",
    "start": "3261960",
    "end": "3267319"
  },
  {
    "text": "current version of it on GitHub called kite uh but I think we have a lot of",
    "start": "3267319",
    "end": "3273559"
  },
  {
    "text": "work ahead to bring it up to par uh with our current kind of API version Set uh",
    "start": "3273559",
    "end": "3278640"
  },
  {
    "text": "so the short answer is yes but I don't have a core ETA on it but we're hearing it a whole lot more now than we did even",
    "start": "3278640",
    "end": "3285240"
  },
  {
    "text": "a year ago next question",
    "start": "3285240",
    "end": "3292920"
  },
  {
    "text": "yes y yep uh in front of Kinesis I guess so the",
    "start": "3293400",
    "end": "3299839"
  },
  {
    "text": "question was can you use API Gateway as a proxy in front of Kinesis and the answer is yes actually it's we see a lot",
    "start": "3299839",
    "end": "3306119"
  },
  {
    "text": "of use cases for it now a lot more yeah we we actually funneled the data",
    "start": "3306119",
    "end": "3311280"
  },
  {
    "text": "originally not into elastic search but into Dynamo and put an API Gateway in front of",
    "start": "3311280",
    "end": "3316359"
  },
  {
    "text": "Dynamo uh but we needed a little bit of more of the capability to search for text and everything so we went to the we",
    "start": "3316359",
    "end": "3323039"
  },
  {
    "text": "switched to elastic search for more search capabilities",
    "start": "3323039",
    "end": "3328319"
  },
  {
    "text": "yes where I can say I want",
    "start": "3351359",
    "end": "3358240"
  },
  {
    "text": "um so I'm going to try and repay the question yeah this was about reducing",
    "start": "3369960",
    "end": "3376680"
  },
  {
    "text": "latency from put to get within a single",
    "start": "3376680",
    "end": "3382280"
  },
  {
    "text": "region and more specifically within a single zone in a single region so how",
    "start": "3382280",
    "end": "3387440"
  },
  {
    "text": "how can we do that U so I'll make a statement and then I'll I'll I'll answer your question so the uh so when we think",
    "start": "3387440",
    "end": "3394000"
  },
  {
    "text": "about replication across availability zones and for those of you who don't know it's just different data centers",
    "start": "3394000",
    "end": "3399839"
  },
  {
    "text": "physically different data centers but still part of the same region so Us East is one of our bigger regions Us East one",
    "start": "3399839",
    "end": "3407599"
  },
  {
    "text": "to be precise um the today the replication is just",
    "start": "3407599",
    "end": "3414760"
  },
  {
    "text": "enabled by default it is just kind of part of our design because it's part of our as you pointed out reliability and",
    "start": "3414760",
    "end": "3421520"
  },
  {
    "text": "durability play uh which we honestly optimized for because not losing the",
    "start": "3421520",
    "end": "3427200"
  },
  {
    "text": "data and not have not making it accessible for us would be uh a bigger",
    "start": "3427200",
    "end": "3433000"
  },
  {
    "text": "kind of a bigger diminishing of customer trust than getting it out sooner so that",
    "start": "3433000",
    "end": "3438680"
  },
  {
    "text": "was our guiding principle having said that uh we are thinking about reducing",
    "start": "3438680",
    "end": "3444640"
  },
  {
    "text": "put to get latencies put to get latencies right now uh should be on a",
    "start": "3444640",
    "end": "3451359"
  },
  {
    "text": "tp99 basis in the 300 millisecond route",
    "start": "3451359",
    "end": "3456799"
  },
  {
    "text": "uh customers have reported faster uh without doing anything specific about availability zones or or kind of putting",
    "start": "3456799",
    "end": "3463200"
  },
  {
    "text": "about in that region U I think we will continue to drive that slower uh sorry continue to drive that down and make",
    "start": "3463200",
    "end": "3470240"
  },
  {
    "text": "those endtoend latencies even lesser we have some things in the pipeline but",
    "start": "3470240",
    "end": "3475480"
  },
  {
    "text": "just to be you know right now though we haven't thought of Kinesis streams as being a single digigit millisecond",
    "start": "3475480",
    "end": "3481400"
  },
  {
    "text": "endtoend latency platform just yet we're still thinking that we'll play in the",
    "start": "3481400",
    "end": "3487000"
  },
  {
    "text": "dozens of millisecond space for now uh but based on this kind of feedback we'll go ahead and try to optimize in that",
    "start": "3487000",
    "end": "3495160"
  },
  {
    "text": "front yeah why don't you go there",
    "start": "3497520",
    "end": "3501400"
  },
  {
    "text": "yeah what data is still hosted at Hurst um",
    "start": "3505119",
    "end": "3510400"
  },
  {
    "text": "well so I kind of view as the data that is in Amazon as a hosted at Hurst as well because we have a virtual private",
    "start": "3510400",
    "end": "3516720"
  },
  {
    "text": "cloud and uh and also all of the S3 we put everything in S3 is is hurst's S3 so",
    "start": "3516720",
    "end": "3523920"
  },
  {
    "text": "I kind of view it as hosted it's not hosted at Hurst it's hosted in Amazon but it's you know we have multiactor and",
    "start": "3523920",
    "end": "3530359"
  },
  {
    "text": "all the other protections that um that you can have um so I would say",
    "start": "3530359",
    "end": "3537880"
  },
  {
    "text": "you know like I said we kind of built the enterprise-wide platform on top of the existing one so a lot of the a lot",
    "start": "3537880",
    "end": "3545520"
  },
  {
    "text": "of the current the old infrastructure of Hurst is slowly moving into Amazon we have a very big relationship with Amazon",
    "start": "3545520",
    "end": "3551760"
  },
  {
    "text": "but it's not all in Amazon's yet I'd say all of my data from the Enterprise wide",
    "start": "3551760",
    "end": "3558640"
  },
  {
    "text": "standpoint is in the cloud uh but there's probably still you know 50%",
    "start": "3558640",
    "end": "3564559"
  },
  {
    "text": "still in uh the data centers at Hurst you have to be able to build both",
    "start": "3564559",
    "end": "3569960"
  },
  {
    "text": "I think as you build As you move your company to the cloud there's going to be an overlap where you're going to be kind",
    "start": "3569960",
    "end": "3575359"
  },
  {
    "text": "of halfway um hope that answers your",
    "start": "3575359",
    "end": "3581559"
  },
  {
    "text": "question yes one",
    "start": "3581559",
    "end": "3585079"
  },
  {
    "text": "more yeah so he asked uh did we consider any other formats for the data to go into into Kinesis other",
    "start": "3594440",
    "end": "3600480"
  },
  {
    "text": "than Json uh yeah we did and at first we had it in uh had it in a tsv format you know",
    "start": "3600480",
    "end": "3608760"
  },
  {
    "text": "because our guys could read it into red shift but then you know you kind of have to develop with Amazon then Amazon",
    "start": "3608760",
    "end": "3615079"
  },
  {
    "text": "announced in red shift that they could read in Json whoa that was great uh and that allows you to point at you you",
    "start": "3615079",
    "end": "3622680"
  },
  {
    "text": "don't have to always look for the same data set you could say I only want these variables and so",
    "start": "3622680",
    "end": "3629559"
  },
  {
    "text": "Json helps the J scientists Downstream so that their red shift programs don't",
    "start": "3629559",
    "end": "3635880"
  },
  {
    "text": "break because it's always looking at it can grab a subset of the variables uh",
    "start": "3635880",
    "end": "3641799"
  },
  {
    "text": "and we've kind of stopped at Json because it seems to be working for us",
    "start": "3641799",
    "end": "3647000"
  },
  {
    "text": "and you have to think about the whole pipeline um one more I think we're out",
    "start": "3647480",
    "end": "3654559"
  },
  {
    "text": "of time but maybe we can take just one more question yeah go",
    "start": "3654559",
    "end": "3658760"
  },
  {
    "text": "ahead y uh Cloud watch uh we have actually my",
    "start": "3662000",
    "end": "3669559"
  },
  {
    "text": "uh soft SD uh and actually my CIS admin well we we actually installed",
    "start": "3669559",
    "end": "3677760"
  },
  {
    "text": "little uh we have a little uh template that we look at every day on a on a huddle that looks at actually the end",
    "start": "3677760",
    "end": "3684599"
  },
  {
    "text": "points the the actual through throughput data and monitors what's what's in elastic search and there's little",
    "start": "3684599",
    "end": "3691799"
  },
  {
    "text": "warnings that go off if the elastic search values start to change after a",
    "start": "3691799",
    "end": "3697079"
  },
  {
    "text": "certain amount and then we kind of back into the stream and try to figure out what happened um but um you know just",
    "start": "3697079",
    "end": "3705440"
  },
  {
    "text": "monitoring the end of the stream if you have a data Pipeline and monitoring the end of the pipeline has been very",
    "start": "3705440",
    "end": "3711240"
  },
  {
    "text": "effective at helping us you know identify when something's off or broken",
    "start": "3711240",
    "end": "3717000"
  },
  {
    "text": "and then we we use cloud watch and other tools to try to figure out kind of go through the pipeline",
    "start": "3717000",
    "end": "3725039"
  },
  {
    "text": "um good all right well thanks for joining us thank you",
    "start": "3725039",
    "end": "3732480"
  }
]
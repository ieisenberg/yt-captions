[
  {
    "start": "0",
    "end": "78000"
  },
  {
    "text": "alright it looks like we're ready to go so I want to tell you a little story about three years ago I was the Expedia",
    "start": "60",
    "end": "8090"
  },
  {
    "text": "global consumer payments bi team and I",
    "start": "8090",
    "end": "13799"
  },
  {
    "text": "was working my way through relational highly normalized relational data people",
    "start": "13799",
    "end": "20760"
  },
  {
    "text": "come to me and say hey I need you to do this such-and-such and I'd spent weeks or days and cobble together some kind of",
    "start": "20760",
    "end": "29189"
  },
  {
    "text": "a report for them and I quickly became the bottleneck well I wasn't really the",
    "start": "29189",
    "end": "35160"
  },
  {
    "text": "bottleneck the fact that I didn't have a data Mart was the bottleneck and so roll forward now approximately three years",
    "start": "35160",
    "end": "41399"
  },
  {
    "text": "and we have AWS completely in the cloud",
    "start": "41399",
    "end": "46610"
  },
  {
    "text": "data Mart solution with a tableau front-end and we have a high level of",
    "start": "46610",
    "end": "51690"
  },
  {
    "text": "confidence in that data that we can give it to our users we can go ahead and let",
    "start": "51690",
    "end": "57300"
  },
  {
    "text": "them explore the data on their own and I'm no longer the bottleneck I actually spend a lot of my time doing analysis so",
    "start": "57300",
    "end": "65010"
  },
  {
    "text": "my name is tad Newman I'm a senior business analyst with Expedia global",
    "start": "65010",
    "end": "70650"
  },
  {
    "text": "consumer payments also with Expedia",
    "start": "70650",
    "end": "76500"
  },
  {
    "text": "payments so today we're going to tell you a little bit about who we are and",
    "start": "76500",
    "end": "81600"
  },
  {
    "start": "78000",
    "end": "106000"
  },
  {
    "text": "why we built this data Mart we're going to tell you in some detail and it's",
    "start": "81600",
    "end": "86880"
  },
  {
    "text": "actually going to tell you in some detail about the platform that we created and then I'll talk a little bit",
    "start": "86880",
    "end": "92850"
  },
  {
    "text": "about the product which may surprise you what the actual product that we delivered is and then also why our",
    "start": "92850",
    "end": "99390"
  },
  {
    "text": "product allowed us to expose our data for self-service analytics so I don't",
    "start": "99390",
    "end": "108689"
  },
  {
    "start": "106000",
    "end": "305000"
  },
  {
    "text": "know how many of you saw mark Rochas from this morning but he's talked much more eloquently than I will about Expedia and what that we're a global",
    "start": "108689",
    "end": "115320"
  },
  {
    "text": "leader in the online travel he's told a little of my thunder actually but Expedia does business in over 200",
    "start": "115320",
    "end": "122219"
  },
  {
    "text": "countries almost three billion dollars of revenue and millions and millions of",
    "start": "122219",
    "end": "129270"
  },
  {
    "text": "transactions just in q3 of 2017",
    "start": "129270",
    "end": "134599"
  },
  {
    "text": "the reason that the Expedia global consumer payments group is is around is",
    "start": "135530",
    "end": "141319"
  },
  {
    "text": "because we need to optimize payments so if you as a qualified customer come to",
    "start": "141319",
    "end": "147829"
  },
  {
    "text": "our site and want to buy travel we want to make that simple we want to make sure that that payment transaction goes",
    "start": "147829",
    "end": "154640"
  },
  {
    "text": "through successfully and also processing",
    "start": "154640",
    "end": "160670"
  },
  {
    "text": "for any of those of you that are in any kind of detail or retail you understand that processing transactions is",
    "start": "160670",
    "end": "167180"
  },
  {
    "text": "incredibly expensive everybody wants a little bit of the pie the guy that the",
    "start": "167180",
    "end": "172250"
  },
  {
    "text": "gateways the acquiring banks the actual issuing banks all those people want a",
    "start": "172250",
    "end": "180019"
  },
  {
    "text": "little bit of money so we want to make sure that we understand who we're paying and how much we're paying to them and optimize the cost and finally as I",
    "start": "180019",
    "end": "189650"
  },
  {
    "text": "mentioned in my opening remarks the transaction systems are not necessarily built for reporting they're in fact not",
    "start": "189650",
    "end": "195470"
  },
  {
    "text": "at all built for reporting they don't even have a little bit of an inkling of being built for reporting they're built",
    "start": "195470",
    "end": "201109"
  },
  {
    "text": "for being read read to and written to quickly and so we needed to have a",
    "start": "201109",
    "end": "206120"
  },
  {
    "text": "system that was actually built for reporting so three of the things the",
    "start": "206120",
    "end": "214190"
  },
  {
    "text": "strategic topics that we want to talk about today is think about guiding principles this is one of the one of the",
    "start": "214190",
    "end": "220190"
  },
  {
    "text": "things that we did early on when we started building a data Mart and it really helped us to keep our focus our",
    "start": "220190",
    "end": "227680"
  },
  {
    "text": "architecture architectural focus right where we wanted to wanted it to be at",
    "start": "227680",
    "end": "233329"
  },
  {
    "text": "all times we always referred back to the guiding principles and it will tell you a bit more about those later but also",
    "start": "233329",
    "end": "240730"
  },
  {
    "text": "with our guiding principles that allowed us to provide enduring value over time",
    "start": "240730",
    "end": "249010"
  },
  {
    "text": "also we it took us a little bit of time to understand the impermanence to",
    "start": "249010",
    "end": "255139"
  },
  {
    "text": "embrace I guess the impermanence of the cloud and I've actually been to quite a few sessions so far this isn't something",
    "start": "255139",
    "end": "262400"
  },
  {
    "text": "new to anybody here but you know turn off the lights when you don't when you don't it's no more rack and stack and let it",
    "start": "262400",
    "end": "268410"
  },
  {
    "text": "run all the time and then also our end product your end product should be usable and familiar we went to great",
    "start": "268410",
    "end": "274860"
  },
  {
    "text": "lengths actually we kind of replaced sequel server analysis services cube and",
    "start": "274860",
    "end": "280230"
  },
  {
    "text": "Excel pivot tables and we moved completely to the cloud and tableau",
    "start": "280230",
    "end": "285480"
  },
  {
    "text": "totally different totally different software and hardware and paradigm and we went to great lengths to try and make",
    "start": "285480",
    "end": "293070"
  },
  {
    "text": "something that the users could open and see and immediately recognize and say oh",
    "start": "293070",
    "end": "298410"
  },
  {
    "text": "I see this data I understand this data I can move forward wait wait just a minute",
    "start": "298410",
    "end": "309180"
  },
  {
    "start": "305000",
    "end": "590000"
  },
  {
    "text": "and so I got to introduce Anna this is Anna Turk and so again about I don't",
    "start": "309180",
    "end": "314970"
  },
  {
    "text": "know is about a year and a half ago I guess we released our first version of our data Mart and we had data in",
    "start": "314970",
    "end": "322470"
  },
  {
    "text": "redshift and I was sitting and watching this spinny thing and I was so much I was watching the spinny thing that I",
    "start": "322470",
    "end": "328530"
  },
  {
    "text": "actually wrote a song about this being ahead like five verses in it right and I'm don't I'm not gonna sing it for you",
    "start": "328530",
    "end": "335370"
  },
  {
    "text": "don't worry but and then we hired Anna and she already kind of knew what she was doing and she came in and she said",
    "start": "335370",
    "end": "341960"
  },
  {
    "text": "I've got a I've got to do something with the key thing and something else with",
    "start": "341960",
    "end": "348000"
  },
  {
    "text": "the sort thing and all of a sudden everything started working really fast so Anna not only came to us knowing what",
    "start": "348000",
    "end": "355710"
  },
  {
    "text": "she was doing but she's really awesome at what she does Thank You Todd so our",
    "start": "355710",
    "end": "362400"
  },
  {
    "text": "guiding principles these were guiding principles were established before the project began before any development was",
    "start": "362400",
    "end": "369750"
  },
  {
    "text": "started and it was guidelines that the team could refer back to as the project progressed and it provided a framework",
    "start": "369750",
    "end": "376139"
  },
  {
    "text": "for making those key decisions and ensuring that the architecture that was being built was on track so the first",
    "start": "376139",
    "end": "383520"
  },
  {
    "text": "thing we knew we needed was that transaction level data and not aggregated data and this is really",
    "start": "383520",
    "end": "388530"
  },
  {
    "text": "important because when you go to build future KPIs you need that atomic level",
    "start": "388530",
    "end": "393930"
  },
  {
    "text": "data it's also important for deep investigation down to those individual transactions and you",
    "start": "393930",
    "end": "402260"
  },
  {
    "text": "know Expedia's roadmap communication included the cloud so we wanted a cloud",
    "start": "402260",
    "end": "407720"
  },
  {
    "text": "ready technology so the team was designing and evaluating solutions that",
    "start": "407720",
    "end": "413030"
  },
  {
    "text": "can run on Prem and then be moved to the cloud and they actually exceeded this expectation by delivering a full",
    "start": "413030",
    "end": "419000"
  },
  {
    "text": "cloud-based solution and in part this was successful because they used AWS to",
    "start": "419000",
    "end": "424640"
  },
  {
    "text": "test all these new technologies and then standard loosely coupled interfaces so",
    "start": "424640",
    "end": "429890"
  },
  {
    "text": "I'll be talking about this a lot throughout the presentation and if you've gone to any of the other BI",
    "start": "429890",
    "end": "435680"
  },
  {
    "text": "architectures you will hear this D couple you know D couple your components and this is really important you don't",
    "start": "435680",
    "end": "442400"
  },
  {
    "text": "want tightly integrated components as you bring on new data sources or you",
    "start": "442400",
    "end": "447680"
  },
  {
    "text": "change your technology you want to be able to do that without having to rewrite other components and then",
    "start": "447680",
    "end": "454820"
  },
  {
    "text": "scaling horizontally we want to take advantage of AWS is ability to dynamically scale and have distributed",
    "start": "454820",
    "end": "461780"
  },
  {
    "text": "processing so with Big Data as your data volumes grow as you bring in new data",
    "start": "461780",
    "end": "467030"
  },
  {
    "text": "sources you want to be able to handle that without having to change your platform and then self-service analytics",
    "start": "467030",
    "end": "472360"
  },
  {
    "text": "it was really important that our users had you know access usability to the",
    "start": "472360",
    "end": "479300"
  },
  {
    "text": "data you know quick access and tableau online really enabled our users to you",
    "start": "479300",
    "end": "485870"
  },
  {
    "text": "know look at the data for hidden patterns irregularities and do a lot of that gain awareness of the data",
    "start": "485870",
    "end": "491300"
  },
  {
    "text": "themselves without direct assistance as you heard Ted's opening comments he's an",
    "start": "491300",
    "end": "497390"
  },
  {
    "text": "expert in our payment process I mean he's in that transactional system so it was really important that tad and and",
    "start": "497390",
    "end": "504080"
  },
  {
    "text": "the team could be free to do those deep analytics analytic tasks and not you",
    "start": "504080",
    "end": "510620"
  },
  {
    "text": "know be writing reports and answering kind of questions that users could discover on their own my job's way more",
    "start": "510620",
    "end": "517580"
  },
  {
    "text": "fun now now I'm gonna hand it back to Ted to describe the product ok so let me",
    "start": "517580",
    "end": "524180"
  },
  {
    "text": "give you a high-level overview of the product this is where I think it's cut you may be a little bit surprised I'm",
    "start": "524180",
    "end": "530870"
  },
  {
    "text": "not going to show you a bunch of cool tableau reports that we've written although we've written a lot of cool tableau reports well what I'm going to show you is the",
    "start": "530870",
    "end": "538140"
  },
  {
    "text": "actual value that we added as a bi team so we engineered fact tables and I'll",
    "start": "538140",
    "end": "544380"
  },
  {
    "text": "tell you about this a little bit more later but our tables we didn't just take the atomic level data we do have atomic",
    "start": "544380",
    "end": "551130"
  },
  {
    "text": "level data but then we also engineered fact tables that made sense in the in business terms we then also managed",
    "start": "551130",
    "end": "558570"
  },
  {
    "text": "metrics so we know that all of our users will be using certain KPIs and we wanted",
    "start": "558570",
    "end": "565050"
  },
  {
    "text": "to make sure make sure that those KPIs were calculated the same way every time and then finally we put we used our",
    "start": "565050",
    "end": "572190"
  },
  {
    "text": "managed or engineered fact tables and our managed metrics and put them into managed data sources and we did this all",
    "start": "572190",
    "end": "578610"
  },
  {
    "text": "in tableau online so we have complete control over being able to publish our",
    "start": "578610",
    "end": "583829"
  },
  {
    "text": "data sources and so forth and to whom we grant permissions then we also have of",
    "start": "583829",
    "end": "592920"
  },
  {
    "start": "590000",
    "end": "670000"
  },
  {
    "text": "course reporting what what business intelligence wouldn't would ever be",
    "start": "592920",
    "end": "597959"
  },
  {
    "text": "complete without reporting we have your standard parameters reports that everybody knows about we've also built",
    "start": "597959",
    "end": "604440"
  },
  {
    "text": "pivot builders and I mentioned earlier that the the Excel spreadsheets and",
    "start": "604440",
    "end": "609540"
  },
  {
    "text": "pivot tables were what was used before so we created a paradigm in which our",
    "start": "609540",
    "end": "615750"
  },
  {
    "text": "users could we had our dimensions and measures in an actual report that was",
    "start": "615750",
    "end": "620850"
  },
  {
    "text": "kind of an editable report that they could actually create and design different types of data sets and they",
    "start": "620850",
    "end": "627390"
  },
  {
    "text": "can do that with both a report it's just kind of a tabular report or they can do that with a chart builder and then",
    "start": "627390",
    "end": "634829"
  },
  {
    "text": "finally because we have engineered our fact tables manage our metrics and and",
    "start": "634829",
    "end": "640860"
  },
  {
    "text": "managed our data sources we have a really high level of confidence in our",
    "start": "640860",
    "end": "646110"
  },
  {
    "text": "complete data set that we can go ahead and open that up to to our users and give them start from scratch editable",
    "start": "646110",
    "end": "652440"
  },
  {
    "text": "templates in tableau online so without all of those kind of safeguards we might",
    "start": "652440",
    "end": "658440"
  },
  {
    "text": "be a little you know you can open this up but don't do this and when you gotta be careful about that we don't",
    "start": "658440",
    "end": "663660"
  },
  {
    "text": "have any of those we don't have any of those types of things",
    "start": "663660",
    "end": "670430"
  },
  {
    "text": "so with that Ann is going to tell you all about the architecture and how we",
    "start": "670430",
    "end": "676500"
  },
  {
    "text": "got this wonderful data from where it was to where it is now so I joined the",
    "start": "676500",
    "end": "683160"
  },
  {
    "text": "team shortly before the production release and one of the things I was excited to see was the implementation of",
    "start": "683160",
    "end": "688860"
  },
  {
    "text": "a data Lake and the use of s3 is the data store and again if you've gone to some of the other sessions you should",
    "start": "688860",
    "end": "695130"
  },
  {
    "text": "see some kind of a similar pattern emerging in our architecture and we",
    "start": "695130",
    "end": "701370"
  },
  {
    "text": "really break it down into one item we talked about the architecture we talked about four components we talked about",
    "start": "701370",
    "end": "707490"
  },
  {
    "text": "collection where we either generate or collect the JSON data files and upload",
    "start": "707490",
    "end": "713130"
  },
  {
    "text": "those to a central s3 location called the landing zone from the landing zone",
    "start": "713130",
    "end": "718410"
  },
  {
    "text": "our transformation and data store component then processes of the data through loading the data leg to then",
    "start": "718410",
    "end": "725760"
  },
  {
    "text": "loading the data Mart and all of this is done on using hive on Hadoop with an EMR",
    "start": "725760",
    "end": "731480"
  },
  {
    "text": "this orchestration is done using AWS data pipelines and we execute bash shell",
    "start": "731480",
    "end": "738210"
  },
  {
    "text": "scripts and high QL to actually process the data and once we've loaded the data",
    "start": "738210",
    "end": "744020"
  },
  {
    "text": "our information delivery component is redshift so then we load that data into",
    "start": "744020",
    "end": "750390"
  },
  {
    "text": "redshift where tableau online then accesses it so before I go into a little",
    "start": "750390",
    "end": "757950"
  },
  {
    "start": "756000",
    "end": "834000"
  },
  {
    "text": "more detail about the components I want to talk about our build strategy what we did was identified the high risk",
    "start": "757950",
    "end": "764760"
  },
  {
    "text": "components first number one was information delivery so we really wanted",
    "start": "764760",
    "end": "770250"
  },
  {
    "text": "to make sure that we could deliver the data fast and reliably so this was the",
    "start": "770250",
    "end": "775410"
  },
  {
    "text": "first thing we prototype so we actually used AWS to prototype redshift and various tools then we identified the",
    "start": "775410",
    "end": "783450"
  },
  {
    "text": "second risk as the transformation and data store so looking at the cloud ready",
    "start": "783450",
    "end": "788460"
  },
  {
    "text": "technology we needed to evaluate all these different options and make sure that we could find one that",
    "start": "788460",
    "end": "794830"
  },
  {
    "text": "was sick scalable fast and again reliable so it was a lot of prototyping",
    "start": "794830",
    "end": "800950"
  },
  {
    "text": "done on both of these components the other thing was to again make sure that they were loosely coupled to each other",
    "start": "800950",
    "end": "807730"
  },
  {
    "text": "so we could do independent development and do as much as development in",
    "start": "807730",
    "end": "813040"
  },
  {
    "text": "parallel as possible and then justifying that complexity I'm gonna talk about",
    "start": "813040",
    "end": "818890"
  },
  {
    "text": "that a little bit later but the overall architecture looks a little bit complex but we wanted to make sure that each",
    "start": "818890",
    "end": "825280"
  },
  {
    "text": "component was as simple and robust as possible so let's talk about collection",
    "start": "825280",
    "end": "833640"
  },
  {
    "text": "so our initial data source was an on-prem sequel server and so what we did",
    "start": "833640",
    "end": "839620"
  },
  {
    "start": "834000",
    "end": "1002000"
  },
  {
    "text": "was we generated JSON data files and then move those up to a landing zone and",
    "start": "839620",
    "end": "845500"
  },
  {
    "text": "s3 and I don't want to pick on tad but I feel like I might be getting picked on",
    "start": "845500",
    "end": "852330"
  },
  {
    "text": "Ted did have some concerns that this was over engineered you know why are we why",
    "start": "852330",
    "end": "858100"
  },
  {
    "text": "are we extracting JSON data files and from a perfectly good database and it's",
    "start": "858100",
    "end": "863440"
  },
  {
    "text": "a good question and the reason we did this is again we didn't want to have our ETL connected directly to that source",
    "start": "863440",
    "end": "869320"
  },
  {
    "text": "system because what happens is that when you change that source system from a",
    "start": "869320",
    "end": "875350"
  },
  {
    "text": "sequel to an actual external expedia team that's now giving you and by the",
    "start": "875350",
    "end": "880390"
  },
  {
    "text": "way this is exactly what's happening right now so I believe it seemed crazy",
    "start": "880390",
    "end": "887110"
  },
  {
    "text": "to me to take a perfectly good database and make all this JSON gibberish out of",
    "start": "887110",
    "end": "893830"
  },
  {
    "text": "it but that's what we did and now we're",
    "start": "893830",
    "end": "898990"
  },
  {
    "text": "getting data directly from the system that's crew that doesn't write it to the database anymore guess what it gives us",
    "start": "898990",
    "end": "905170"
  },
  {
    "text": "anybody JSON exactly it was brilliant so",
    "start": "905170",
    "end": "910750"
  },
  {
    "text": "I'm I'm a believer at this point thanks Anna go ahead JSON JSON is great you",
    "start": "910750",
    "end": "918130"
  },
  {
    "text": "know it's it's lightweight it's self describing it's cool it's a great way to share data and physical files you know",
    "start": "918130",
    "end": "924190"
  },
  {
    "text": "allows you to replay that data and and share it with other systems as need be and that the collection system that",
    "start": "924190",
    "end": "929920"
  },
  {
    "text": "we built you know we can go ahead and deploy additional collection send sentinels over to another you know",
    "start": "929920",
    "end": "936070"
  },
  {
    "text": "sequel server some other server to generate those files so this is where we",
    "start": "936070",
    "end": "941700"
  },
  {
    "text": "benefited from that loosely coupled interface so what were some of the lessons learned in optimizations even",
    "start": "941700",
    "end": "949450"
  },
  {
    "text": "though you are decoupled from your ingestion it's important to look ahead to your transformation so we're using",
    "start": "949450",
    "end": "955060"
  },
  {
    "text": "Hadoop and what we found was Hadoop does not like a lot of small files so we",
    "start": "955060",
    "end": "960310"
  },
  {
    "text": "ended up changing collection to create larger less frequent files and then we",
    "start": "960310",
    "end": "965709"
  },
  {
    "text": "also found that we needed to do more distributed processing and intraday",
    "start": "965709",
    "end": "970899"
  },
  {
    "text": "processing to ensure that we actually you know generated all the daily data",
    "start": "970899",
    "end": "976660"
  },
  {
    "text": "and time for our nightly processing and now that we are ingesting external",
    "start": "976660",
    "end": "983610"
  },
  {
    "text": "externally provided data we've introduced a preprocessor so we have",
    "start": "983610",
    "end": "989560"
  },
  {
    "text": "insulated our ETL from malformed Jason or bad data we actually look at that",
    "start": "989560",
    "end": "994630"
  },
  {
    "text": "data and looked at look at that data and reject a bad data before it gets in to",
    "start": "994630",
    "end": "1000240"
  },
  {
    "text": "the system so as we collect the data we now need to transform it and store it",
    "start": "1000240",
    "end": "1006480"
  },
  {
    "start": "1006000",
    "end": "1180000"
  },
  {
    "text": "and all this is done using hive and on Hadoop so we have a hive meta store and",
    "start": "1006480",
    "end": "1013950"
  },
  {
    "text": "a my sequel RDS and we have the other external tables so so the data actually",
    "start": "1013950",
    "end": "1019410"
  },
  {
    "text": "resides on s3 so what this means is we persist the schema and we persist the",
    "start": "1019410",
    "end": "1025110"
  },
  {
    "text": "data but our EMR we spin up when we go to do our nightly batch processing and",
    "start": "1025110",
    "end": "1030808"
  },
  {
    "text": "then we terminate it when we're done so we don't have a long-running cluster so this is where we're sort of embracing",
    "start": "1030809",
    "end": "1036540"
  },
  {
    "text": "that impermanence of not of not keeping something running constantly when we're not using it one of the things we",
    "start": "1036540",
    "end": "1044490"
  },
  {
    "text": "haven't talked about is how quickly the team actually delivered the solution it was a small team and they were building",
    "start": "1044490",
    "end": "1050040"
  },
  {
    "text": "a new data Mart and the we were up and running a production in eight months and",
    "start": "1050040",
    "end": "1055410"
  },
  {
    "text": "a lot of that was due to the decision to use hive and hive QL because",
    "start": "1055410",
    "end": "1060750"
  },
  {
    "text": "you know sequel is a pretty widely used skillset and our team had a very good",
    "start": "1060750",
    "end": "1066970"
  },
  {
    "text": "deep understanding of sequel so this allowed them to focus on learning new technologies learning the cloud while",
    "start": "1066970",
    "end": "1074410"
  },
  {
    "text": "not having to learn a new language and then write everything in MapReduce jobs so this really enabled us to quickly get",
    "start": "1074410",
    "end": "1082600"
  },
  {
    "text": "the solution up and running there are a lot of lessons learned and optimizations",
    "start": "1082600",
    "end": "1088780"
  },
  {
    "text": "when we're talking about hive on Hadoop one of the things that we actually ran",
    "start": "1088780",
    "end": "1094630"
  },
  {
    "text": "into was the hive QL was very it's not",
    "start": "1094630",
    "end": "1100480"
  },
  {
    "text": "sequel so you couldn't just pick up your sequel code and run it on hive so there was there were some changes in some",
    "start": "1100480",
    "end": "1106660"
  },
  {
    "text": "learnings there we also learned to be careful with those AWS default settings",
    "start": "1106660",
    "end": "1112480"
  },
  {
    "text": "on your Hadoop cluster there's been a couple of times where we were successful in changing those configurations and",
    "start": "1112480",
    "end": "1118840"
  },
  {
    "text": "improving the performance of our processing but there was an instance where we set some memory settings and",
    "start": "1118840",
    "end": "1124480"
  },
  {
    "text": "what happened was we wanted to take advantage of that scaling out but those",
    "start": "1124480",
    "end": "1130090"
  },
  {
    "text": "settings then kind of bottleneck to us and so we ended up you know taking those",
    "start": "1130090",
    "end": "1135340"
  },
  {
    "text": "out and changing that so that when we scaled it out it would actually perform better so it's just weird a word of",
    "start": "1135340",
    "end": "1142990"
  },
  {
    "text": "warning be careful when you're messing with those configurations the other thing is those big files so as you're",
    "start": "1142990",
    "end": "1151179"
  },
  {
    "text": "inserting into your hive tables you're gonna create a lot of smaller files and as you process over a long time your",
    "start": "1151179",
    "end": "1159940"
  },
  {
    "text": "process will slow down so we had a nightly run of three and a half hours",
    "start": "1159940",
    "end": "1165340"
  },
  {
    "text": "and eventually we were slowing down to 12 hours and a couple strategies for",
    "start": "1165340",
    "end": "1170500"
  },
  {
    "text": "that is either to insert overwrite your partitions or have a maintenance that comes and reconsolidate those files into",
    "start": "1170500",
    "end": "1176950"
  },
  {
    "text": "one big file so all of this orchestration as I mentioned was done",
    "start": "1176950",
    "end": "1182890"
  },
  {
    "text": "using data pipelines with the shell scripts and executing pipe QL and we",
    "start": "1182890",
    "end": "1189040"
  },
  {
    "start": "1188000",
    "end": "1292000"
  },
  {
    "text": "picked pipeline so it was kind of a natural choice because it's a AWS service that's",
    "start": "1189040",
    "end": "1194970"
  },
  {
    "text": "meant to work with other services and when we looked at it was very similar to",
    "start": "1194970",
    "end": "1200180"
  },
  {
    "text": "SSIS sequel integration services and that's another skill set that the team",
    "start": "1200180",
    "end": "1205950"
  },
  {
    "text": "had one of the things that we quickly realized those we had to customize it we",
    "start": "1205950",
    "end": "1212310"
  },
  {
    "text": "ended up making we have a master pipeline and we ended up spinning off a lot of child pipelines so we could",
    "start": "1212310",
    "end": "1219660"
  },
  {
    "text": "process more things in parallel as well as have managed manageable chunks of code so it's one thing we had to kind of",
    "start": "1219660",
    "end": "1227280"
  },
  {
    "text": "customize quite a bit the other thing we're using is a dynamo DB so dynamo DB",
    "start": "1227280",
    "end": "1234390"
  },
  {
    "text": "is a no sequel solution and we use it for tracking the processing of our json",
    "start": "1234390",
    "end": "1240540"
  },
  {
    "text": "data files and ensuring that each step of our ETL is followed and this works",
    "start": "1240540",
    "end": "1246210"
  },
  {
    "text": "really well because there's a high of storage handler so we can connect directly to it and run our hive ql and",
    "start": "1246210",
    "end": "1253530"
  },
  {
    "text": "query the dynamo tables to make sure we're running the right right files at the right step one of the drawbacks",
    "start": "1253530",
    "end": "1259800"
  },
  {
    "text": "though is you know as the as the table gets larger you know it's a no sequel so",
    "start": "1259800",
    "end": "1264960"
  },
  {
    "text": "you have a key in a store key you can't add a lot of indexes so one strategy",
    "start": "1264960",
    "end": "1269970"
  },
  {
    "text": "that we've employed is is to archive off the data and when we start our nightly",
    "start": "1269970",
    "end": "1276120"
  },
  {
    "text": "batch processing we actually increase the dynamo capacity and then when we're done we decrease it so what we've done",
    "start": "1276120",
    "end": "1282090"
  },
  {
    "text": "is improved performance and added some cost benefits and then we get to",
    "start": "1282090",
    "end": "1290340"
  },
  {
    "text": "information delivery so our data Mart is on us actually on s3 using hive and our",
    "start": "1290340",
    "end": "1300750"
  },
  {
    "start": "1292000",
    "end": "1401000"
  },
  {
    "text": "that Dan Mars and pushed to redshift we found that the on-demand and analytical",
    "start": "1300750",
    "end": "1307200"
  },
  {
    "text": "queries against hive using MapReduce we're on MapReduce at this time it was just too slow unless we",
    "start": "1307200",
    "end": "1314520"
  },
  {
    "text": "created a really large cluster it also meant that we had to have a cluster up and running the whole time",
    "start": "1314520",
    "end": "1320410"
  },
  {
    "text": "so the choice was made to use red shift and right shift also has all those you",
    "start": "1320410",
    "end": "1325550"
  },
  {
    "text": "know handy drivers and it's easy to connect all sorts of reporting tools to it and then as far as the loosely",
    "start": "1325550",
    "end": "1333020"
  },
  {
    "text": "coupled interfaces we implemented view so all of our tables are abstract adduce",
    "start": "1333020",
    "end": "1338390"
  },
  {
    "text": "amuse and what this allows us to do is when we do a release and we rebuild a table we can do that and then verify the",
    "start": "1338390",
    "end": "1345710"
  },
  {
    "text": "data as is correct and then simply repoint the view to the new table so there's essentially no downtime for our",
    "start": "1345710",
    "end": "1353180"
  },
  {
    "text": "users the other thing that we've been able to do is you know scale redshift so we on a Saturday took about seven hours",
    "start": "1353180",
    "end": "1361280"
  },
  {
    "text": "we doubled the size of our cluster we got the cluster the whole time was",
    "start": "1361280",
    "end": "1366350"
  },
  {
    "text": "read-only so reports were still running and it was completed before the nightly",
    "start": "1366350",
    "end": "1372470"
  },
  {
    "text": "batch started so we doubled the size of the cluster which have dark queries with",
    "start": "1372470",
    "end": "1378860"
  },
  {
    "text": "its again essentially no downtime the one one thing that we're still",
    "start": "1378860",
    "end": "1384020"
  },
  {
    "text": "struggling with is a replacement for those OLAP cubes so this is one of those areas where we we've built some tables",
    "start": "1384020",
    "end": "1391300"
  },
  {
    "text": "to try to kind of fill that gap but it is one area that we're still kind of",
    "start": "1391300",
    "end": "1397430"
  },
  {
    "text": "struggling with so now I've described",
    "start": "1397430",
    "end": "1403460"
  },
  {
    "start": "1401000",
    "end": "1500000"
  },
  {
    "text": "the the platform you might be thinking okay well why aren't you using redshift",
    "start": "1403460",
    "end": "1410480"
  },
  {
    "text": "for your transformation data store as well as your information delivery and that's a good question that's where",
    "start": "1410480",
    "end": "1416870"
  },
  {
    "text": "where we come in and have to kind of justify that complexity and the reason being is we didn't want ETL and your",
    "start": "1416870",
    "end": "1424190"
  },
  {
    "text": "analytics and reporting competing for resources we're also a global company so we're not necessarily guaranteed a safe",
    "start": "1424190",
    "end": "1431450"
  },
  {
    "text": "ETL window and then you would also be bottlenecking your data access so now",
    "start": "1431450",
    "end": "1436490"
  },
  {
    "text": "everyone has to access the data through redshift by putting it on s3 we can",
    "start": "1436490",
    "end": "1442730"
  },
  {
    "text": "access it through now Amazon fina we could spin up like a spark cluster we could even access it through redshift",
    "start": "1442730",
    "end": "1449390"
  },
  {
    "text": "spectrum and as more and more service architectures or service services become",
    "start": "1449390",
    "end": "1456840"
  },
  {
    "text": "available you know it's we've set ourselves up so we can really get to that data and all sorts of new and",
    "start": "1456840",
    "end": "1462360"
  },
  {
    "text": "interesting ways now the component interfaces those loosely coupled interfaces and",
    "start": "1462360",
    "end": "1468120"
  },
  {
    "text": "impermanence we talked about you know changing out technology we talked about",
    "start": "1468120",
    "end": "1473160"
  },
  {
    "text": "again impermanence you know not having service maybe using server lists may be",
    "start": "1473160",
    "end": "1479299"
  },
  {
    "text": "changing things out as technologies change so what we could do is we could take our my sequel high meta store and",
    "start": "1479299",
    "end": "1486720"
  },
  {
    "text": "start using that fancy new data catalog or we could take out data pipelines and",
    "start": "1486720",
    "end": "1491880"
  },
  {
    "text": "use Apache airflow and without having to rewrite all these other pieces of code",
    "start": "1491880",
    "end": "1499370"
  },
  {
    "start": "1500000",
    "end": "1589000"
  },
  {
    "text": "so we also I also talked about the prototyping of that information delivery",
    "start": "1500960",
    "end": "1506309"
  },
  {
    "text": "that high risk component so one of the things we we did when we got to well we",
    "start": "1506309",
    "end": "1513150"
  },
  {
    "text": "did a lot of prototyping but when we did load the reduction level data as Ted mentioned there were some performance",
    "start": "1513150",
    "end": "1519150"
  },
  {
    "text": "issues and some of that was because we didn't load appropriate test data volume",
    "start": "1519150",
    "end": "1525000"
  },
  {
    "text": "so when you're going to prototype something like this and you're going to use transactional data load",
    "start": "1525000",
    "end": "1531780"
  },
  {
    "text": "transactional data like don't load out aggregated data and try to load it in volumes that you think that you'll be",
    "start": "1531780",
    "end": "1538500"
  },
  {
    "text": "seeing in a year or two years however much history you're planning on having the other thing was to look at the bulk",
    "start": "1538500",
    "end": "1545910"
  },
  {
    "text": "of the queries that you're gonna be running against those tables and build your tables accordingly you know when",
    "start": "1545910",
    "end": "1552600"
  },
  {
    "text": "you talk about redshift or any sort of distributed systems you really have to figure out how your data should be",
    "start": "1552600",
    "end": "1559110"
  },
  {
    "text": "distributed or else you're not going to be utilizing that parallel processing and the other thing we the goal was to",
    "start": "1559110",
    "end": "1567780"
  },
  {
    "text": "not have aggregated tables and to query the underlying fact tables and what we",
    "start": "1567780",
    "end": "1574320"
  },
  {
    "text": "found is that the performance you know from a user's perspective just did not",
    "start": "1574320",
    "end": "1579600"
  },
  {
    "text": "meet our expectations so we did go ahead and aggregate of tables to solve solve for",
    "start": "1579600",
    "end": "1585450"
  },
  {
    "text": "that problem and with that I think",
    "start": "1585450",
    "end": "1590730"
  },
  {
    "start": "1589000",
    "end": "1661000"
  },
  {
    "text": "Todd's gonna talk about self-service all right Thank You Anna that was great so Anna and her group are actually working",
    "start": "1590730",
    "end": "1596400"
  },
  {
    "text": "on a on automotive car architecture and",
    "start": "1596400",
    "end": "1602190"
  },
  {
    "text": "so imagine that a loosely coupled autumn our car maybe the maybe the wheels are tightly coupled but the rest of the car",
    "start": "1602190",
    "end": "1608370"
  },
  {
    "text": "and you can just take out that big v8 engine that's gas guzzling and throw in a new Tesla engine so that's that's what",
    "start": "1608370",
    "end": "1615360"
  },
  {
    "text": "I look forward to that in 2018 do that",
    "start": "1615360",
    "end": "1622230"
  },
  {
    "text": "okay so I'm going to talk a little bit now about the how we chose the the",
    "start": "1622230",
    "end": "1629370"
  },
  {
    "text": "products that we chose for the user interface and how we use the cloud and",
    "start": "1629370",
    "end": "1635670"
  },
  {
    "text": "the impermanence of the cloud to evaluate products and I'm going to kind of compare and contrast this with",
    "start": "1635670",
    "end": "1643250"
  },
  {
    "text": "current with you know on-premises solutions or on-premise testing of the",
    "start": "1643250",
    "end": "1649080"
  },
  {
    "text": "same same type of thing and then also how we maintain familiar concepts and",
    "start": "1649080",
    "end": "1655620"
  },
  {
    "text": "exactly a little bit more about that and our self-service methodology so start",
    "start": "1655620",
    "end": "1662400"
  },
  {
    "start": "1661000",
    "end": "1732000"
  },
  {
    "text": "out with evaluation our best practices for evaluation so if you can imagine you",
    "start": "1662400",
    "end": "1668640"
  },
  {
    "text": "know back in the day again me three years ago and I decide ok I want to try a new user interface product so I have",
    "start": "1668640",
    "end": "1675540"
  },
  {
    "text": "to order Hardware I have to load it on my desktop and then I have DLL can contention and all these different",
    "start": "1675540",
    "end": "1680640"
  },
  {
    "text": "things or I finally order hardware I get it racked I get it stacked I get it",
    "start": "1680640",
    "end": "1685680"
  },
  {
    "text": "loaded it's six months later I finally get to try my software out in the cloud",
    "start": "1685680",
    "end": "1690810"
  },
  {
    "text": "I was able to requisition an ec2 instance load the software I wanted to",
    "start": "1690810",
    "end": "1698130"
  },
  {
    "text": "test on it and I actually did load each of these different software packages",
    "start": "1698130",
    "end": "1705650"
  },
  {
    "text": "then I evaluated those packages against business requirements and then simply",
    "start": "1705650",
    "end": "1711870"
  },
  {
    "text": "drop the ec2 instance no foul and did it again so this is one of those",
    "start": "1711870",
    "end": "1720570"
  },
  {
    "text": "things that in the cloud happened so fast and so quickly and and so easily",
    "start": "1720570",
    "end": "1727320"
  },
  {
    "text": "compared to the paradigm of a few years ago so as far as familiar concepts go",
    "start": "1727320",
    "end": "1736049"
  },
  {
    "start": "1732000",
    "end": "1820000"
  },
  {
    "text": "you can see here on the left-hand side let's see they gate they told me there was a laser point oh yeah",
    "start": "1736049",
    "end": "1741590"
  },
  {
    "text": "on the left-hand side that's our legacy cube the actual sequel server analysis",
    "start": "1741590",
    "end": "1747509"
  },
  {
    "text": "service services cube and the right-hand side is the tableau data source that we created so you can see that that we have",
    "start": "1747509",
    "end": "1756269"
  },
  {
    "text": "other than the measures and dimensions being flip-flopped they're very similar the user can open up the tableau data",
    "start": "1756269",
    "end": "1763440"
  },
  {
    "text": "source that's used the cube the legacy cube in the past and they'll say oh I",
    "start": "1763440",
    "end": "1769139"
  },
  {
    "text": "get this you know they're they'll be able to figure out that the measures are on the bottom they can probably figure",
    "start": "1769139",
    "end": "1775379"
  },
  {
    "text": "that stuff out so the way we did this is is we used numbering just like we had in the cube",
    "start": "1775379",
    "end": "1782690"
  },
  {
    "text": "so everything is sorted the same so people start you know they go in and look look for things kind of in",
    "start": "1782690",
    "end": "1788279"
  },
  {
    "text": "sequential order so we use numbering in our folders and then we use folders now",
    "start": "1788279",
    "end": "1793470"
  },
  {
    "text": "if you're not familiar with being able to use folders in a data source in tableau it's it's a great feature that",
    "start": "1793470",
    "end": "1799940"
  },
  {
    "text": "we found very handy here so we were able to you can actually expand these folders",
    "start": "1799940",
    "end": "1805019"
  },
  {
    "text": "and then you have your actual dimensions and there or you can even expand them and have a hierarchy within a folder so",
    "start": "1805019",
    "end": "1810659"
  },
  {
    "text": "this allowed us to basically create something that our users were very familiar with they could open up the",
    "start": "1810659",
    "end": "1816179"
  },
  {
    "text": "first time I get it I understand where the data is the other thing that I",
    "start": "1816179",
    "end": "1822239"
  },
  {
    "start": "1820000",
    "end": "1903000"
  },
  {
    "text": "mentioned earlier is calculated measures so we spent a fair amount of time thinking about what our KPI is what are",
    "start": "1822239",
    "end": "1828779"
  },
  {
    "text": "the things that we know all of our users are going to go in and and want to",
    "start": "1828779",
    "end": "1835349"
  },
  {
    "text": "report on every day and then we built those and we built them in a couple of",
    "start": "1835349",
    "end": "1841019"
  },
  {
    "text": "different ways we engineered the fact tables as I mentioned before and I'll give you an example of that actually",
    "start": "1841019",
    "end": "1848099"
  },
  {
    "text": "I'll tell you about it now I think there might be a slide later but so in in payments there are a number of different",
    "start": "1848099",
    "end": "1853740"
  },
  {
    "text": "operations when when you go to make a payment that we have to verify your card and then we to make sure it's really a",
    "start": "1853740",
    "end": "1860130"
  },
  {
    "text": "card and then we have to authorize make sure you have enough money and then we have to capture them uh there's all these different operations that happen",
    "start": "1860130",
    "end": "1865650"
  },
  {
    "text": "and what we did is we took all of those operations and consolidated them into a single record and that record now has",
    "start": "1865650",
    "end": "1872970"
  },
  {
    "text": "all the great attribution that we have whether it's a Visa MasterCard what country it came from and so forth",
    "start": "1872970",
    "end": "1878730"
  },
  {
    "text": "but it's all one record and we can determine easily through all those operations if it was a successful or",
    "start": "1878730",
    "end": "1885750"
  },
  {
    "text": "failed transaction we can also then tie it back to the actual fees that were",
    "start": "1885750",
    "end": "1892230"
  },
  {
    "text": "charged for that transaction and so forth but this allows us to have business this this is the business value",
    "start": "1892230",
    "end": "1898440"
  },
  {
    "text": "we created within the data the other",
    "start": "1898440",
    "end": "1904169"
  },
  {
    "start": "1903000",
    "end": "1937000"
  },
  {
    "text": "thing that we did as far as keeping familiar concepts in tableau online is",
    "start": "1904169",
    "end": "1909630"
  },
  {
    "text": "we created projects we used projects in tableau online to sort of simulate",
    "start": "1909630",
    "end": "1915260"
  },
  {
    "text": "folders on your desktop so our users prior used Excel they would save their",
    "start": "1915260",
    "end": "1922200"
  },
  {
    "text": "their pivot table their pivot table or whatever they had created to their desktop or they would share it with",
    "start": "1922200",
    "end": "1928260"
  },
  {
    "text": "other people we needed to maintain that same functionality and we did it with",
    "start": "1928260",
    "end": "1933480"
  },
  {
    "text": "with projects in tableau online and then",
    "start": "1933480",
    "end": "1939539"
  },
  {
    "start": "1937000",
    "end": "1954000"
  },
  {
    "text": "our self-service analytics so I bit before we have parameters reports or",
    "start": "1939539",
    "end": "1945299"
  },
  {
    "text": "your basic basic reports these are great everybody knows this there's nothing to",
    "start": "1945299",
    "end": "1951260"
  },
  {
    "text": "ground chattering about this pivot builders this is this is kinda this is I",
    "start": "1951260",
    "end": "1958559"
  },
  {
    "start": "1954000",
    "end": "2025000"
  },
  {
    "text": "think this is kind of a neat thing that we did so you can see up here we have",
    "start": "1958559",
    "end": "1963720"
  },
  {
    "text": "rows row categories and then we have measures here so the users can actually",
    "start": "1963720",
    "end": "1969539"
  },
  {
    "text": "select we did this all with parameters in tableau reports so the users can",
    "start": "1969539",
    "end": "1976650"
  },
  {
    "text": "actually select which measures they want or row categories I'm sorry row",
    "start": "1976650",
    "end": "1981990"
  },
  {
    "text": "categories would the dimensions and then the which measures they want so they can choose up to four dimensions and three measures",
    "start": "1981990",
    "end": "1989590"
  },
  {
    "text": "and then they've got a whole lot of different filtering and sorting and so forth that they can do on the right hand side this is this type of report is for",
    "start": "1989590",
    "end": "1998440"
  },
  {
    "text": "our users that are quite ready to author a report from scratch yet but they need",
    "start": "1998440",
    "end": "2004440"
  },
  {
    "text": "something that we haven't yet written a report for a parameterised report so they can basically go in here and say",
    "start": "2004440",
    "end": "2010260"
  },
  {
    "text": "okay I need to know what the you know with the gross booking value in the",
    "start": "2010260",
    "end": "2017970"
  },
  {
    "text": "United Kingdom in July something like that and and we don't have a specific",
    "start": "2017970",
    "end": "2023040"
  },
  {
    "text": "report that would that would address that and then finally because we've",
    "start": "2023040",
    "end": "2029540"
  },
  {
    "start": "2025000",
    "end": "2088000"
  },
  {
    "text": "we've engineered our facts manage our metrics and manage our data sources we",
    "start": "2029540",
    "end": "2034920"
  },
  {
    "text": "can allow our users full editable templates and this is actually tableau online I don't know if is anybody in",
    "start": "2034920",
    "end": "2042690"
  },
  {
    "text": "here using tableau online - - so not too",
    "start": "2042690",
    "end": "2049440"
  },
  {
    "text": "many people tableau online is pretty cool it's it tableau basically takes all of the administration and and they do it",
    "start": "2049440",
    "end": "2056940"
  },
  {
    "text": "so it's it's like tableau server in the cloud but tableau does all the server",
    "start": "2056940",
    "end": "2063440"
  },
  {
    "text": "administration they do all the patches they put on the new the new software and so forth and and we use it so this is",
    "start": "2063440",
    "end": "2072450"
  },
  {
    "text": "actually the web authoring view so you can actually use this you can you can",
    "start": "2072450",
    "end": "2077908"
  },
  {
    "text": "drag and drop just like you can in tableau desktop it's very close to the same functionality as there is in",
    "start": "2077909",
    "end": "2084240"
  },
  {
    "text": "tableau desktop all right so let me tell",
    "start": "2084240",
    "end": "2089700"
  },
  {
    "start": "2088000",
    "end": "2100000"
  },
  {
    "text": "you a little bit about tableau best practices and some of the lessons we've",
    "start": "2089700",
    "end": "2095100"
  },
  {
    "text": "learned and some of the optimizations that we've come up with with tableau so",
    "start": "2095100",
    "end": "2101550"
  },
  {
    "start": "2100000",
    "end": "2156000"
  },
  {
    "text": "Anna mentioned a little bit about abstracting tables with views and when so so we we have these fact tables and",
    "start": "2101550",
    "end": "2110240"
  },
  {
    "text": "sometimes the developers they put names that are",
    "start": "2110240",
    "end": "2115650"
  },
  {
    "text": "technical technical in them and they mean something well they don't mean what",
    "start": "2115650",
    "end": "2123210"
  },
  {
    "text": "we like them to mean or maybe they mean something but they yeah so so we put business names on so we do this all with",
    "start": "2123210",
    "end": "2129420"
  },
  {
    "text": "views and we actually abstract everything with views we don't ever look",
    "start": "2129420",
    "end": "2134820"
  },
  {
    "text": "at a table in data source in tableau so we have even if our dimensions are just",
    "start": "2134820",
    "end": "2141690"
  },
  {
    "text": "you know select star from dimension table our fact tables we will rename",
    "start": "2141690",
    "end": "2147240"
  },
  {
    "text": "things we'll do some aggregations and so forth in those so definitely abstract",
    "start": "2147240",
    "end": "2153810"
  },
  {
    "text": "all tables with views naming so we I I",
    "start": "2153810",
    "end": "2160310"
  },
  {
    "text": "guess I made a mistake early on with with naming and naming conventions or",
    "start": "2160310",
    "end": "2167040"
  },
  {
    "text": "sometimes kind of hotly contested and people can have I've heard people have just really a lot of discussion about",
    "start": "2167040",
    "end": "2174510"
  },
  {
    "text": "them but I'm just gonna say if your generic descriptive and readable and",
    "start": "2174510",
    "end": "2179760"
  },
  {
    "text": "when I say generic so so this I'm gonna tell you about a little mistake I made I",
    "start": "2179760",
    "end": "2186170"
  },
  {
    "text": "thought it would be cool to put the version number in our data source",
    "start": "2186170",
    "end": "2191780"
  },
  {
    "start": "2189000",
    "end": "2220000"
  },
  {
    "text": "because then when when we brought out a new version everybody would know hey",
    "start": "2191780",
    "end": "2197040"
  },
  {
    "text": "we've got a new version the only problem is with data sources in tableau is that they live forever as far as I can tell",
    "start": "2197040",
    "end": "2203490"
  },
  {
    "text": "they live as long as this one has and so we're on version 144 144 now but our",
    "start": "2203490",
    "end": "2211350"
  },
  {
    "text": "data sources still say 1.2.3 so don't put your don't put the the version",
    "start": "2211350",
    "end": "2216720"
  },
  {
    "text": "number in your data source did you want",
    "start": "2216720",
    "end": "2221820"
  },
  {
    "start": "2220000",
    "end": "2382000"
  },
  {
    "text": "me to say anything else about naming convention no that's okay okay some of the lessons we've learned",
    "start": "2221820",
    "end": "2227430"
  },
  {
    "text": "and and you know by the gray in my beard you can tell that I've been around a little bit and if I don't tell you about",
    "start": "2227430",
    "end": "2234000"
  },
  {
    "text": "the things that we did that didn't work so well then then you might do them as",
    "start": "2234000",
    "end": "2239430"
  },
  {
    "text": "well so don't try to extract 500 million rows of data into a tableau extract it's",
    "start": "2239430",
    "end": "2246630"
  },
  {
    "text": "not going to work you extracts are great they were really fast but your data has to be really highly aggregated in our",
    "start": "2246630",
    "end": "2253590"
  },
  {
    "text": "case we found that unless we have our data aggregated at a monthly level it may be different for you depending on",
    "start": "2253590",
    "end": "2260100"
  },
  {
    "text": "how many trans actual transactions you have also consider performance always we",
    "start": "2260100",
    "end": "2265860"
  },
  {
    "text": "have we have you know demanding users anybody else demanding users and they",
    "start": "2265860",
    "end": "2273210"
  },
  {
    "text": "come up with some really great ideas hey we've got this report that's a weekly report and we always show it as of last",
    "start": "2273210",
    "end": "2280560"
  },
  {
    "text": "week so we're showing full weeks we don't want to show a partial week this week and they say you know that's great but we really want to see how things are",
    "start": "2280560",
    "end": "2286950"
  },
  {
    "text": "trending this week so we well we can do that we're clever we're tableau clever and so we put a",
    "start": "2286950",
    "end": "2295290"
  },
  {
    "text": "little check box on there that they can look at the current week well the problem is that little check box has to",
    "start": "2295290",
    "end": "2300960"
  },
  {
    "text": "go out to the server and figure out what the date is and what's the date range and how's the date compared to this you",
    "start": "2300960",
    "end": "2306900"
  },
  {
    "text": "know is it this week is it is it last week and and so it ended up running that date math a lot of times on the server",
    "start": "2306900",
    "end": "2315840"
  },
  {
    "text": "we found that then we could just put a regular date filter on there and tell users if you want to look at last week",
    "start": "2315840",
    "end": "2322470"
  },
  {
    "text": "then slide the date thing over if you want to look at this week slide the date thing over it ran way faster so always",
    "start": "2322470",
    "end": "2328710"
  },
  {
    "text": "consider that you can be clever and you can be very you know you can you can do",
    "start": "2328710",
    "end": "2336000"
  },
  {
    "text": "a lot of things but sometimes they will affect your performance edit xml to",
    "start": "2336000",
    "end": "2341910"
  },
  {
    "text": "change to change the environment so we had a kind of an issue with moving from",
    "start": "2341910",
    "end": "2349290"
  },
  {
    "text": "environment to environment with tableau data sources so we have a QA environment",
    "start": "2349290",
    "end": "2359070"
  },
  {
    "text": "a pre-production environment production environment just like everybody and so with a tableau data source you point to",
    "start": "2359070",
    "end": "2366510"
  },
  {
    "text": "that environment and then you really not an easy way to go in and just change",
    "start": "2366510",
    "end": "2371750"
  },
  {
    "text": "that where that's looking where even if the schemas are the same you can't change that without kind of rebuilding",
    "start": "2371750",
    "end": "2378600"
  },
  {
    "text": "the data source so we found this kind of clever way where you can actually go and edit edit the XML and I don't know",
    "start": "2378600",
    "end": "2387360"
  },
  {
    "start": "2382000",
    "end": "2434000"
  },
  {
    "text": "if there's any tableau people in here that they might not really want you to edit the test this is unsupported",
    "start": "2387360",
    "end": "2392370"
  },
  {
    "text": "completely unsupported all those caveats and everything but it's really very easy if you right-click on on the data source",
    "start": "2392370",
    "end": "2399210"
  },
  {
    "text": "file and open it in in a text editor this is actually notepad plus plus you",
    "start": "2399210",
    "end": "2405090"
  },
  {
    "text": "can just search for where it says schema equals here I says prod B I just changed",
    "start": "2405090",
    "end": "2410100"
  },
  {
    "text": "that to prod for example if I want to go from prod B to prod and then I do a",
    "start": "2410100",
    "end": "2415680"
  },
  {
    "text": "search and replace for everywhere where there's my old schema in brackets and I replace it with my new schema in",
    "start": "2415680",
    "end": "2421650"
  },
  {
    "text": "brackets save that and close it and when",
    "start": "2421650",
    "end": "2427530"
  },
  {
    "text": "you open your data source up it will automatically be looking at your new at your new environment all right",
    "start": "2427530",
    "end": "2437900"
  },
  {
    "start": "2434000",
    "end": "2491000"
  },
  {
    "text": "tableau optimization so again like Anna said we originally that the original",
    "start": "2437900",
    "end": "2445200"
  },
  {
    "text": "thought was hey if we can just keep the atomic level data the the lowest level",
    "start": "2445200",
    "end": "2450960"
  },
  {
    "text": "of detail and because registry is supposed to be super fast we can just",
    "start": "2450960",
    "end": "2456420"
  },
  {
    "text": "just you know we don't that way we don't have any maintenance in the overhead of",
    "start": "2456420",
    "end": "2461580"
  },
  {
    "text": "having to aggregate data or in different ways and different things so that was",
    "start": "2461580",
    "end": "2466920"
  },
  {
    "text": "the original thought but then the reality was we've got too much we've got to aggregate it it's at some level so we",
    "start": "2466920",
    "end": "2474990"
  },
  {
    "text": "went ahead and did that when you when you aggregate data of course look at it",
    "start": "2474990",
    "end": "2480300"
  },
  {
    "text": "carefully make sure that you're only including those fields in your",
    "start": "2480300",
    "end": "2485550"
  },
  {
    "text": "aggregations that need to be in the aggregation so that you don't blow it out further than you need this is",
    "start": "2485550",
    "end": "2493620"
  },
  {
    "start": "2491000",
    "end": "2540000"
  },
  {
    "text": "something that I learned and maybe everybody knows it but assume",
    "start": "2493620",
    "end": "2498660"
  },
  {
    "text": "referential integrity when you're creating a data source in tableau so in the tableau data source screen if you",
    "start": "2498660",
    "end": "2505740"
  },
  {
    "text": "drop and click on the the data and then assume referential integrity I think it",
    "start": "2505740",
    "end": "2510750"
  },
  {
    "text": "may be there by default but if it's not it should be you should or you should select it",
    "start": "2510750",
    "end": "2516539"
  },
  {
    "text": "this will increase Anna can really say exactly what it does yeah so your your",
    "start": "2516539",
    "end": "2523199"
  },
  {
    "text": "ETL should ensure your referential integrity and by checking this box tableau is now not scanning all of the",
    "start": "2523199",
    "end": "2530969"
  },
  {
    "text": "tables in your data source it's now just looking at the ones you're actually querying so it's a pretty important",
    "start": "2530969",
    "end": "2536549"
  },
  {
    "text": "setting that was another one of those great things and I didn't when she first came in again consider performance when",
    "start": "2536549",
    "end": "2543719"
  },
  {
    "start": "2540000",
    "end": "2603000"
  },
  {
    "text": "writing reports I kind of already spoke to that datasource optimization so here",
    "start": "2543719",
    "end": "2548969"
  },
  {
    "text": "are some some ideas some things that you can take away with you create",
    "start": "2548969",
    "end": "2554009"
  },
  {
    "text": "calculations in your data source prior pardon me prior to publishing any",
    "start": "2554009",
    "end": "2559799"
  },
  {
    "text": "calculations you want to do create hierarchies in your data source hide any",
    "start": "2559799",
    "end": "2565410"
  },
  {
    "text": "fields this is this is important primarily if you're making extracts so hide anything that's empty are not used",
    "start": "2565410",
    "end": "2573569"
  },
  {
    "text": "by anyone to improve the the extract generation performance this is basically the same thing that I talked about with",
    "start": "2573569",
    "end": "2580199"
  },
  {
    "text": "aggregations set default properties your number formats comments and so forth and",
    "start": "2580199",
    "end": "2589039"
  },
  {
    "text": "then any kind of data types and geographic roles you also want to make",
    "start": "2589039",
    "end": "2594809"
  },
  {
    "text": "sure that this is all done prior to publishing your data source",
    "start": "2594809",
    "end": "2599929"
  },
  {
    "start": "2603000",
    "end": "2667000"
  },
  {
    "text": "all right so wow we finished right on time so payments are incredibly important to",
    "start": "2604599",
    "end": "2614239"
  },
  {
    "text": "Expedia you know we didn't I don't know if you heard mark this morning he said what was that quote that Mark Twain and",
    "start": "2614239",
    "end": "2621130"
  },
  {
    "text": "and anyway payments are important to",
    "start": "2621130",
    "end": "2626689"
  },
  {
    "text": "Expedia and in order to be able to watch out for our effective payments and our",
    "start": "2626689",
    "end": "2634609"
  },
  {
    "text": "efficient payments we needed to build this data Mart and now that we have it we've been able to increase our",
    "start": "2634609",
    "end": "2641599"
  },
  {
    "text": "efficiency and and decrease the cost significantly and from a technology",
    "start": "2641599",
    "end": "2647509"
  },
  {
    "text": "standpoint you know our nightly processing runs about three three and a half hours and we could because we're on",
    "start": "2647509",
    "end": "2654650"
  },
  {
    "text": "the cloud we can scale up make that faster we can change your technology fairly easily so we're really in a good",
    "start": "2654650",
    "end": "2660769"
  },
  {
    "text": "space for being able to support any sort of future requirements so just a couple",
    "start": "2660769",
    "end": "2669650"
  },
  {
    "start": "2667000",
    "end": "2743000"
  },
  {
    "text": "takeaways think about those guiding principles this this is another thing that you'll probably hear at other",
    "start": "2669650",
    "end": "2676279"
  },
  {
    "text": "sessions is architectural tenants you know establishing these guidelines it's",
    "start": "2676279",
    "end": "2681859"
  },
  {
    "text": "really important when you are doing a project and also it's important to look",
    "start": "2681859",
    "end": "2687349"
  },
  {
    "text": "back on as you just continue to develop and add new features and so if you don't",
    "start": "2687349",
    "end": "2693349"
  },
  {
    "text": "have them go ahead and establish them we have some you can take with you embrace",
    "start": "2693349",
    "end": "2698539"
  },
  {
    "text": "the impairments of the cloud you know there's a lot of you there's a lot of differences out there you know if you",
    "start": "2698539",
    "end": "2704479"
  },
  {
    "text": "don't need it turn it off look into obviously serverless is a big thing and",
    "start": "2704479",
    "end": "2710019"
  },
  {
    "text": "as far as development it doesn't have to happen in sequence you know everything's",
    "start": "2710019",
    "end": "2715309"
  },
  {
    "text": "more agile and we kind of started at the end and worked on a little bit of stuff in the middle and you know completed a",
    "start": "2715309",
    "end": "2722619"
  },
  {
    "text": "whole project very successfully by by doing that and as Ted showed you know",
    "start": "2722619",
    "end": "2729199"
  },
  {
    "text": "you're building all these new things but make sure your end product is usable and it's familiar because you want people to",
    "start": "2729199",
    "end": "2736069"
  },
  {
    "text": "use it and that's a really important important part great thank you all for attending",
    "start": "2736069",
    "end": "2745750"
  },
  {
    "start": "2743000",
    "end": "2910000"
  },
  {
    "text": "today does anybody have any questions",
    "start": "2745750",
    "end": "2750000"
  },
  {
    "text": "yep there's a microphone here if you were eight I really want to talk about",
    "start": "2752340",
    "end": "2758500"
  },
  {
    "text": "the naming guidelines I didn't see anything about consistency up there we're building a data lake and one of",
    "start": "2758500",
    "end": "2766240"
  },
  {
    "text": "the challenges we see sometimes is with like calculations that folks have used",
    "start": "2766240",
    "end": "2771640"
  },
  {
    "text": "for reporting and I saw you talked about having like those those metrics existing",
    "start": "2771640",
    "end": "2778750"
  },
  {
    "text": "saw both in the semantic layer and then as well as the data layer that was",
    "start": "2778750",
    "end": "2783760"
  },
  {
    "text": "curious like what your thoughts were on how you decide where the appropriate place is for those calculations yeah so",
    "start": "2783760",
    "end": "2793410"
  },
  {
    "text": "so I don't think we've actually done a lot of calculations in the data layer most of what we did there is engineered",
    "start": "2793410",
    "end": "2800920"
  },
  {
    "text": "fact tape is engineered or facts so we didn't actually do calculations we did sort of consolidation in the data layer",
    "start": "2800920",
    "end": "2807520"
  },
  {
    "text": "and then we tried to put the the calculations that we knew that were",
    "start": "2807520",
    "end": "2813070"
  },
  {
    "text": "really the business calculations is close to the business as we could and we did those actually in the data source",
    "start": "2813070",
    "end": "2819370"
  },
  {
    "text": "well the the next step closer would have been at in the actual report but since",
    "start": "2819370",
    "end": "2824500"
  },
  {
    "text": "we wanted them to be available to all users to use we did them in the data source okay cool and also curious some",
    "start": "2824500",
    "end": "2831550"
  },
  {
    "text": "like what what execution engine you were using on on hive like like MapReduce Ted",
    "start": "2831550",
    "end": "2837370"
  },
  {
    "text": "yes we're using MapReduce we're moving over more things using spark",
    "start": "2837370",
    "end": "2843190"
  },
  {
    "text": "so using dag which you've seen a lot of performance gains using using that",
    "start": "2843190",
    "end": "2848700"
  },
  {
    "text": "because you can also hook spark up to your hive and use spark sequel okay and",
    "start": "2848700",
    "end": "2854650"
  },
  {
    "text": "and then with data pipeline you were talking about the future swapping that out for something like a patchy error flow I was I was wondering why they",
    "start": "2854650",
    "end": "2860980"
  },
  {
    "text": "weren't thinking about like another like Amazon service I well I put that out",
    "start": "2860980",
    "end": "2867190"
  },
  {
    "text": "there instead of glue cuz I already had a data catalog up there but yeah there's a lot of choices and I've heard think we",
    "start": "2867190",
    "end": "2873190"
  },
  {
    "text": "both kind of like those pinwheels yeah pinwheels were really pretty so but I've heard a lot of good things about Apache",
    "start": "2873190",
    "end": "2879010"
  },
  {
    "text": "airflow and but you know blue ETL is also a good option yep and then with",
    "start": "2879010",
    "end": "2886390"
  },
  {
    "text": "that batch meta data look like you have in dynamo DB do you have like the ability to like rollback batches you've",
    "start": "2886390",
    "end": "2892539"
  },
  {
    "text": "processed that is a it's not automatically it's code one of the",
    "start": "2892539",
    "end": "2899380"
  },
  {
    "text": "things the hive storage handler doesn't do is it doesn't delete so you have to go through the CLI or through the",
    "start": "2899380",
    "end": "2906369"
  },
  {
    "text": "interface great thank you anybody else is a little hard to see up",
    "start": "2906369",
    "end": "2912069"
  },
  {
    "start": "2910000",
    "end": "2966000"
  },
  {
    "text": "here yet yes sir yeah step up to the mic thank you does any of your does any of your transaction",
    "start": "2912069",
    "end": "2918190"
  },
  {
    "text": "data have mutable properties and if so how do you handle it with like a file based system like I have in s3 does any",
    "start": "2918190",
    "end": "2925510"
  },
  {
    "text": "of it have beautiful beautiful so are any of your transactions beautiful do they change the state so that you have",
    "start": "2925510",
    "end": "2930910"
  },
  {
    "text": "to update some information and if so how do you deal with that in a file based data like well we stitch the data back",
    "start": "2930910",
    "end": "2937569"
  },
  {
    "text": "together right so as we ingest the data so the transaction changes then you have multiple copies of that transaction that",
    "start": "2937569",
    "end": "2944319"
  },
  {
    "text": "you then load and in your ETL you decide what you're gonna allow to be updated",
    "start": "2944319",
    "end": "2949809"
  },
  {
    "text": "and what you're what you don't update so your initial like that's really loud your initial extract is append only JSON",
    "start": "2949809",
    "end": "2958240"
  },
  {
    "text": "so when the transaction changes you get a new JSON row for that same transaction",
    "start": "2958240",
    "end": "2964230"
  },
  {
    "start": "2966000",
    "end": "3007000"
  },
  {
    "text": "you guys consider using the AWS TMS data migration service to remove the MS",
    "start": "2966240",
    "end": "2973630"
  },
  {
    "text": "sequel server to the our sequel server to the rich shaped bar yes oh you mean",
    "start": "2973630",
    "end": "2979569"
  },
  {
    "text": "the are the data that we're collecting from the on-prem sequel yes yes so",
    "start": "2979569",
    "end": "2984880"
  },
  {
    "text": "that's not our database actually we're we're extracting data you know much like a lot of data you know bi organizations",
    "start": "2984880",
    "end": "2991420"
  },
  {
    "text": "we don't own the so data and that that team is moving to the cloud and this is where we're we're",
    "start": "2991420",
    "end": "2997930"
  },
  {
    "text": "getting that they're actually producing those json data files for us from a stream did you try querying json files",
    "start": "2997930",
    "end": "3010470"
  },
  {
    "start": "3007000",
    "end": "3033000"
  },
  {
    "text": "directly from s3 by using athena yeah no",
    "start": "3010470",
    "end": "3016500"
  },
  {
    "text": "actually no not the json we've actually done it with our hive files actually you",
    "start": "3016500",
    "end": "3024360"
  },
  {
    "text": "know I have I've used the JSON sterday to query the actual JSON files from",
    "start": "3024360",
    "end": "3030270"
  },
  {
    "text": "Athena is it like a big complexity",
    "start": "3030270",
    "end": "3036240"
  },
  {
    "start": "3033000",
    "end": "3070000"
  },
  {
    "text": "that's the reason did you choose EMR I'm sorry silicon is the complexity of",
    "start": "3036240",
    "end": "3041670"
  },
  {
    "text": "JSON files was the reason for choosing a mod no I don't I don't think so I mean",
    "start": "3041670",
    "end": "3048510"
  },
  {
    "text": "there's there's a lot of support for JSON there's a lot of third-party tools and libraries that you can you can add",
    "start": "3048510",
    "end": "3055980"
  },
  {
    "text": "to your cluster there's a built on and built in JSON 30 with hive as well it's",
    "start": "3055980",
    "end": "3064530"
  },
  {
    "text": "a little tricky to load nested JSON into redshift but it works pretty well with some of the other tools there was",
    "start": "3064530",
    "end": "3071760"
  },
  {
    "start": "3070000",
    "end": "3172000"
  },
  {
    "text": "another question over here too so it's again about JSON are couple of things do",
    "start": "3071760",
    "end": "3076860"
  },
  {
    "text": "you how many different JSON structures do you deal with on a normal basis and do you have any contract with the data",
    "start": "3076860",
    "end": "3083130"
  },
  {
    "text": "provider team to get only certain structures or you just deal with those as you get differences or changes in the",
    "start": "3083130",
    "end": "3089520"
  },
  {
    "text": "structures form everywhere in Azure I can tell you that's a really good question yeah we have established data",
    "start": "3089520",
    "end": "3095610"
  },
  {
    "text": "contracts so we have a couple different file formats that we expect and we you",
    "start": "3095610",
    "end": "3101370"
  },
  {
    "text": "know that's really important is to work with your data providers and establish a contract with the data Lake you can you",
    "start": "3101370",
    "end": "3108240"
  },
  {
    "text": "know just kind of consume these JSON blobs or whatever anyone sends you but if you want to really you know have a",
    "start": "3108240",
    "end": "3115110"
  },
  {
    "text": "solid ETL process you need to establish those contracts Thanks so we use a similar architecture",
    "start": "3115110",
    "end": "3122520"
  },
  {
    "text": "like what is shown the only difference is redshift rate from redshift we have",
    "start": "3122520",
    "end": "3129210"
  },
  {
    "text": "our own deployed tableau rather than tableau online because we worried about the performance connection oh yeah right",
    "start": "3129210",
    "end": "3135750"
  },
  {
    "text": "so how you resolve that because if you have the rear the data sitting in redshift and the connecting from tableau",
    "start": "3135750",
    "end": "3143040"
  },
  {
    "text": "online there is a bandwidth is you're going to play in brain I think the decision was to make our redshift in the",
    "start": "3143040",
    "end": "3150180"
  },
  {
    "text": "same region as tableau online which helped with the data delay and as far as",
    "start": "3150180",
    "end": "3156300"
  },
  {
    "text": "I know we haven't really had any performance yes I don't think there's any agency between actually the tableau",
    "start": "3156300",
    "end": "3162660"
  },
  {
    "text": "online is running on AWS yeah so you we're in the same region yeah so",
    "start": "3162660",
    "end": "3167910"
  },
  {
    "text": "we don't go across region okay thank you sure hi you mentioned using hive on",
    "start": "3167910",
    "end": "3176190"
  },
  {
    "start": "3172000",
    "end": "3238000"
  },
  {
    "text": "spark have you look into hive on tests to improve query performance would",
    "start": "3176190",
    "end": "3182550"
  },
  {
    "text": "everybody hear that yeah we did look on at hive on tez and we had some we ran",
    "start": "3182550",
    "end": "3190680"
  },
  {
    "text": "into a couple issues with a lot of our reprocessing we clear out our s3 data",
    "start": "3190680",
    "end": "3197550"
  },
  {
    "text": "partitions and with the dag it was a little trickier to repair those tables",
    "start": "3197550",
    "end": "3205530"
  },
  {
    "text": "to make sure that the partitions were showing up correctly so I think that we're probably moving more towards spark",
    "start": "3205530",
    "end": "3211740"
  },
  {
    "text": "than event as in the future you",
    "start": "3211740",
    "end": "3218040"
  },
  {
    "text": "mentioned like having storing the atomic data are they just stay on this tree or the",
    "start": "3218040",
    "end": "3223250"
  },
  {
    "text": "know them interested and also generate the data we only load the data Mart into",
    "start": "3223250",
    "end": "3228859"
  },
  {
    "text": "redshift so the all of the landing zone data stays in in s3 then you can when",
    "start": "3228859",
    "end": "3239780"
  },
  {
    "start": "3238000",
    "end": "3263000"
  },
  {
    "text": "you load it to redshift are you flattening it or you're loading it as a JSON structure and then doing something later when you query we're actually",
    "start": "3239780",
    "end": "3246770"
  },
  {
    "text": "loading it so they're at that point their hive tables and they're in Avro format actually and so which is actually",
    "start": "3246770",
    "end": "3254390"
  },
  {
    "text": "pretty handy for loading into redshift it supports Avro so it's a really easy copy into redshift using what phoenix",
    "start": "3254390",
    "end": "3268820"
  },
  {
    "text": "phoenix um I don't know if that was evaluated I'm not sure about that",
    "start": "3268820",
    "end": "3276010"
  },
  {
    "text": "security for a batch oh you know we have a V PC we have I am rolls our user",
    "start": "3279099",
    "end": "3286369"
  },
  {
    "text": "accounts are connected to the Federated IDs is that oh I was wondering it you",
    "start": "3286369",
    "end": "3302210"
  },
  {
    "start": "3296000",
    "end": "3416000"
  },
  {
    "text": "know felt like the new technologies coming from like you know the sequel server reporting services world I was",
    "start": "3302210",
    "end": "3307820"
  },
  {
    "text": "wondering if he if you like took like an iterative approach like initially trying",
    "start": "3307820",
    "end": "3313160"
  },
  {
    "text": "to like maybe like swap out like like redshift and just like trying to use that as a data source for sequel server",
    "start": "3313160",
    "end": "3319280"
  },
  {
    "text": "reporting services rather than like doing like that and tableau yeah and not",
    "start": "3319280",
    "end": "3325040"
  },
  {
    "text": "so not so much I mean we didn't go through we didn't go through development",
    "start": "3325040",
    "end": "3332089"
  },
  {
    "text": "the same way that the data goes through the system you know like Anna Anna alluded to we we",
    "start": "3332089",
    "end": "3337460"
  },
  {
    "text": "actually said okay what kind of what's the overarching architecture that we're gonna look at now we're the high risk",
    "start": "3337460",
    "end": "3343130"
  },
  {
    "text": "places and that the biggest one was redshift was the biggest unknown sort of so we did load data into redshift",
    "start": "3343130",
    "end": "3349730"
  },
  {
    "text": "directly just we exported CSV files and imported them into",
    "start": "3349730",
    "end": "3354940"
  },
  {
    "text": "shift just for prototyping yeah and then we knew but we knew that eventually we",
    "start": "3354940",
    "end": "3360670"
  },
  {
    "text": "were going to need to extract the data from sequel server into JSON and go the",
    "start": "3360670",
    "end": "3365740"
  },
  {
    "text": "end route but but we didn't think we didn't really ever think about because",
    "start": "3365740",
    "end": "3371619"
  },
  {
    "text": "we want to have loosely coupled interfaces all the way around this also wasn't a migration it's a new day",
    "start": "3371619",
    "end": "3377349"
  },
  {
    "text": "tomorrow yeah right so cool we weren't migrating got it and then I saw an s3 you had like",
    "start": "3377349",
    "end": "3383950"
  },
  {
    "text": "like ODS yeah data lag yes yes a redshift excuse like how do",
    "start": "3383950",
    "end": "3389770"
  },
  {
    "text": "you decide what users have access to what engineers only yeah right nobody",
    "start": "3389770",
    "end": "3398260"
  },
  {
    "text": "has access to anything right now not a whole lot of people are interested in looking at that s3 data you know",
    "start": "3398260",
    "end": "3405700"
  },
  {
    "text": "analysts we used Athena a couple times to get them I think direct access to some things on",
    "start": "3405700",
    "end": "3411609"
  },
  {
    "text": "s3 but right now it's it's all the access is really funnel through redshift yeah but that will likely change in the",
    "start": "3411609",
    "end": "3419470"
  },
  {
    "start": "3416000",
    "end": "3445000"
  },
  {
    "text": "future and then we have people that just need data extracts and so forth or not extracts but they just need you know hey",
    "start": "3419470",
    "end": "3426010"
  },
  {
    "text": "we need I want to know how many transactions there were in the world every quarter and we're not going to",
    "start": "3426010",
    "end": "3433359"
  },
  {
    "text": "create a report and give them a tableau license for that for example so we'll give them permissions to the to the ODS",
    "start": "3433359",
    "end": "3441069"
  },
  {
    "text": "or something like that eventually but we haven't worked that out completely if you were building this",
    "start": "3441069",
    "end": "3446800"
  },
  {
    "start": "3445000",
    "end": "3535000"
  },
  {
    "text": "pipeline from scratch an organization without an existing skill set what's the",
    "start": "3446800",
    "end": "3452410"
  },
  {
    "text": "title and the skills of the first person you would hire to get this thing started",
    "start": "3452410",
    "end": "3460140"
  },
  {
    "text": "Anna are you happy with your current employment yeah I think that you need",
    "start": "3460870",
    "end": "3469850"
  },
  {
    "text": "you need a database engineer or a database developer you need or you need somebody I mean anyone with database",
    "start": "3469850",
    "end": "3475490"
  },
  {
    "text": "skills I think this is a is a key key skill set yeah I think a lot of a lot of",
    "start": "3475490",
    "end": "3481640"
  },
  {
    "text": "the technology that we used was chosen because of our existing skill set as",
    "start": "3481640",
    "end": "3487130"
  },
  {
    "text": "well so where you can you can do do everything with hive and it looks like",
    "start": "3487130",
    "end": "3493460"
  },
  {
    "text": "sequel kind of you can also do that with with MapReduce jobs in Java so it kind",
    "start": "3493460",
    "end": "3499790"
  },
  {
    "text": "of depends on what what you want to do so if you if you are starting from scratch with nobody and you need to hire",
    "start": "3499790",
    "end": "3506270"
  },
  {
    "text": "somebody is that what you're saying correct yeah I start with lower level implementation people or higher level",
    "start": "3506270",
    "end": "3511820"
  },
  {
    "text": "visionaries I think higher level visionaries get those guiding principles",
    "start": "3511820",
    "end": "3519190"
  },
  {
    "text": "get the guiding principles down and then then that will be clear then now you'll know okay these these are the",
    "start": "3519190",
    "end": "3525200"
  },
  {
    "text": "technologies these are the principles what technologies are going to support these principles now what people are",
    "start": "3525200",
    "end": "3530840"
  },
  {
    "text": "going to support those technologies Thanks you probably notice that creating",
    "start": "3530840",
    "end": "3538040"
  },
  {
    "text": "dashboards in tableau requires you to stitch together multiple fact tables oftentimes because well I'm sorry multiple what fact tables yeah okay well",
    "start": "3538040",
    "end": "3551210"
  },
  {
    "text": "I was gonna ask like how you represent if you had to combine multiple fact tables like for example you have you",
    "start": "3551210",
    "end": "3556910"
  },
  {
    "text": "know like five or six different metrics that all exist in five or six different fact tables or maybe three fact tables",
    "start": "3556910",
    "end": "3562310"
  },
  {
    "text": "how you brought those back tables together inside tab yes so actually that's a great question and and and I",
    "start": "3562310",
    "end": "3569300"
  },
  {
    "text": "think I understand and that's that's where that's the value we brought we",
    "start": "3569300",
    "end": "3575960"
  },
  {
    "text": "don't have back tables where we don't have situations where you need to pull",
    "start": "3575960",
    "end": "3582200"
  },
  {
    "text": "data from multiple multiple fact tables I'll give you an example we have we have merchant fee data where we have to pay",
    "start": "3582200",
    "end": "3588500"
  },
  {
    "text": "all these people all this money to do the transactions we actually stitched that together with",
    "start": "3588500",
    "end": "3593930"
  },
  {
    "text": "the payment transaction with the actual transaction that came in so we say okay visa is gonna charge us a buck to do",
    "start": "3593930",
    "end": "3600259"
  },
  {
    "text": "this hundred dollar transaction we're gonna stitch it all together and make a fact table so we don't have we do that",
    "start": "3600259",
    "end": "3607460"
  },
  {
    "text": "in the we do that in the in the ETL so we don't have to do it in tableau",
    "start": "3607460",
    "end": "3613309"
  },
  {
    "text": "because it's it's way too big we couldn't we couldn't do that and so now we have just that one fact table that",
    "start": "3613309",
    "end": "3618650"
  },
  {
    "text": "has all the payment that transaction attribution to it what kind of card it",
    "start": "3618650",
    "end": "3623960"
  },
  {
    "text": "was you know what point-of-sale came through is all that kind of stuff and it also has all the fee attribution so so",
    "start": "3623960",
    "end": "3631309"
  },
  {
    "text": "that's kind of the value that we added on creating the data Mart that makes",
    "start": "3631309",
    "end": "3636859"
  },
  {
    "text": "sense are you incrementally loading rich the redshift data Mart every every day or do you do a whole flushing felt oh no",
    "start": "3636859",
    "end": "3643609"
  },
  {
    "text": "we we call it Killam fill but no we we do load it incrementally every morning",
    "start": "3643609",
    "end": "3649880"
  },
  {
    "text": "thanks you know what we're all out of time if you if you have another question I don't know if there's a there's",
    "start": "3649880",
    "end": "3656839"
  },
  {
    "text": "probably another session coming in here so we'll be yeah we'll be in the hallway like my question",
    "start": "3656839",
    "end": "3665230"
  }
]
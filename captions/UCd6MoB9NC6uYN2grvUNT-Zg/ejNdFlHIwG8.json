[
  {
    "text": "[Music]",
    "start": "650",
    "end": "8550"
  },
  {
    "text": "[Applause] [Music]",
    "start": "8550",
    "end": "14850"
  },
  {
    "text": "awesome thanks for having us here today super excited to talk about this topic",
    "start": "15139",
    "end": "22230"
  },
  {
    "text": "something very near and dear to my heart as well as Hubert's so we'll dive right in we're gonna be covering a lot of stuff",
    "start": "22230",
    "end": "28680"
  },
  {
    "text": "but we're hoping that this reaches a wide audience so there should hopefully be something here for everybody",
    "start": "28680",
    "end": "35460"
  },
  {
    "text": "we're gonna go briefly over what branches so it puts into perspective the infrastructure that we've built out",
    "start": "35460",
    "end": "41629"
  },
  {
    "text": "we're gonna do a brief introduction to containerization and then we're gonna",
    "start": "41629",
    "end": "46710"
  },
  {
    "text": "move into applications of kubernetes we're gonna go through a couple examples if you've never heard of kubernetes",
    "start": "46710",
    "end": "52410"
  },
  {
    "text": "before that's perfectly fine you'll walk away from this talk hopefully as an expert and we're also going to talk",
    "start": "52410",
    "end": "59100"
  },
  {
    "text": "about something that I'm very passionate about which is cost management on AWS I think there's a lot of small startups",
    "start": "59100",
    "end": "64830"
  },
  {
    "text": "here that are just starting to get on to the platform but we're gonna look at what it could actually be managing you",
    "start": "64830",
    "end": "71610"
  },
  {
    "text": "know a multi-million dollar AWS budget and then again at the end we'll talk about QA so this talk is intended for a",
    "start": "71610",
    "end": "81840"
  },
  {
    "text": "wide audience as I mentioned if you're a founder or maybe a budding founder or CTO you'll take away some lessons and",
    "start": "81840",
    "end": "89790"
  },
  {
    "text": "strategies about cost management about scaling infrastructure and some of the decisions you can make there if you're",
    "start": "89790",
    "end": "96119"
  },
  {
    "text": "just a hacker a developer an engineer and you want to learn about some cool technology you will learn about",
    "start": "96119",
    "end": "101150"
  },
  {
    "text": "applications of docker applications of kubernetes as well as various AWS",
    "start": "101150",
    "end": "106950"
  },
  {
    "text": "features such as aSG's and then lastly if you are here because of the really",
    "start": "106950",
    "end": "112439"
  },
  {
    "text": "awesome pork tacos and you're just kind of chilling out here hopefully you get exposed to some interesting new technology in terms and have fun in this",
    "start": "112439",
    "end": "119909"
  },
  {
    "text": "talk so really briefly onion Chan I'm",
    "start": "119909",
    "end": "125189"
  },
  {
    "text": "the director of engineering at branch I'm with my colleague Hubert Chen he's the manager on the infrastructure and",
    "start": "125189",
    "end": "131099"
  },
  {
    "text": "operations team and we've both been with branch for about four four ish",
    "start": "131099",
    "end": "136950"
  },
  {
    "text": "years the company itself is only five years old so we've got the opportunity to see all sorts of interesting rapid",
    "start": "136950",
    "end": "143220"
  },
  {
    "text": "hyperscale that you know our startup has had the great fortune to go through so",
    "start": "143220",
    "end": "148680"
  },
  {
    "text": "let's actually quickly talk about branch if you've never heard about branch before where a startup our head offices",
    "start": "148680",
    "end": "155790"
  },
  {
    "text": "in Redwood City as I mentioned were about five years old so founded in 2014 we're a mobile deep-linking",
    "start": "155790",
    "end": "162450"
  },
  {
    "text": "analytics and attribution company we've about two hundred and fifty employees about seventy engineers we have about",
    "start": "162450",
    "end": "170209"
  },
  {
    "text": "45,000 customers and apps using our core product and we have about twelve offices",
    "start": "170209",
    "end": "176220"
  },
  {
    "text": "around the world I'm not gonna go into too many details about how branch works",
    "start": "176220",
    "end": "181620"
  },
  {
    "text": "but if you are in the app business if you have a mobile app if you're a marketer if you're in the growth",
    "start": "181620",
    "end": "186989"
  },
  {
    "text": "business and you've never heard of branch you should you can learn more about it later on you can talk to us afterwards but we help customers grow",
    "start": "186989",
    "end": "194670"
  },
  {
    "text": "their user base we help them with their analytics the reporting and as I mentioned they're deep linking and just",
    "start": "194670",
    "end": "201000"
  },
  {
    "text": "the you know a smattering of some of the logos we work with some of the biggest companies in the world including Amazon",
    "start": "201000",
    "end": "206310"
  },
  {
    "text": "to provide them their analytics and reporting and again this is all setting the context for some of the scale that",
    "start": "206310",
    "end": "212130"
  },
  {
    "text": "we have to manage and deal with so speaking of scale let's talk about some",
    "start": "212130",
    "end": "218760"
  },
  {
    "text": "of the the numbers that you know we've had to overcome and some of the scaling challenges that we've engineered with or",
    "start": "218760",
    "end": "226650"
  },
  {
    "text": "around over the last few years today our core platform sees about 12",
    "start": "226650",
    "end": "232049"
  },
  {
    "text": "billion transactions per day any given time we can burst up to about a quarter",
    "start": "232049",
    "end": "237510"
  },
  {
    "text": "of a million messages per second within our infrastructure we have over a",
    "start": "237510",
    "end": "242549"
  },
  {
    "text": "hundred micro services running in our production environment we started very",
    "start": "242549",
    "end": "247889"
  },
  {
    "text": "typically with a giant monolithic JavaScript application but we actually decompose that into a micro services",
    "start": "247889",
    "end": "254040"
  },
  {
    "text": "back in 2015 we've been operating kubernetes in production for over four",
    "start": "254040",
    "end": "259229"
  },
  {
    "text": "years now and we have about 70 as I mentioned software engineers that on a",
    "start": "259229",
    "end": "264570"
  },
  {
    "text": "day to day basis are deploying tons of changes so it is a pretty",
    "start": "264570",
    "end": "269940"
  },
  {
    "text": "substantial management and governance challenge so the two different",
    "start": "269940",
    "end": "275160"
  },
  {
    "text": "challenges that I'm actually going to speak to today and we hope that you get some answers to by the end of this talk so one is the challenge around general",
    "start": "275160",
    "end": "283020"
  },
  {
    "text": "compute I talked about you know 70 engineers is not actually that many compared to some of the other bigger",
    "start": "283020",
    "end": "288389"
  },
  {
    "text": "companies in the bay area but we wanted to provide a flexible repeatable compute",
    "start": "288389",
    "end": "293490"
  },
  {
    "text": "platform for our growing edge team are growing scaling needs and the needs of",
    "start": "293490",
    "end": "298650"
  },
  {
    "text": "our developers so some of the challenges that come up on a day-to-day are things",
    "start": "298650",
    "end": "304470"
  },
  {
    "text": "like you know we support several different languages within our production infrastructure Java Python",
    "start": "304470",
    "end": "310970"
  },
  {
    "text": "JavaScript and the developers want to deploy their services and scalable means as fast as possible and part of our job",
    "start": "310970",
    "end": "318599"
  },
  {
    "text": "as infrastructure engineers is to provide them the platform so that they can do that we also don't have a very",
    "start": "318599",
    "end": "325560"
  },
  {
    "text": "big infra so we can't have a DevOps or an SRE paired with every developer and each",
    "start": "325560",
    "end": "332699"
  },
  {
    "text": "developer might themselves own five to ten services or more so you're talking about hundreds of services running in",
    "start": "332699",
    "end": "338580"
  },
  {
    "text": "production all needed to keep this platform online so we'll talk about the challenges and how to overcome these",
    "start": "338580",
    "end": "345180"
  },
  {
    "text": "compute colleges the next is costs so none of this is going to be free as your",
    "start": "345180",
    "end": "353639"
  },
  {
    "text": "infrastructure grows and scales so do the costs and forecasting the costs can",
    "start": "353639",
    "end": "358770"
  },
  {
    "text": "be quite challenging predicting these costs forecasts are generally going to be moving slower than rapidly iterating",
    "start": "358770",
    "end": "366090"
  },
  {
    "text": "development team and there are a lot of different products that Amazon offers",
    "start": "366090",
    "end": "372750"
  },
  {
    "text": "that make cost modeling and purchases more flexible but they're non trivial to",
    "start": "372750",
    "end": "378150"
  },
  {
    "text": "implement very well so I'll provide some tips on how you can do that as well so",
    "start": "378150",
    "end": "384300"
  },
  {
    "text": "the underlying principle behind a lot of this talk today is this core concept of",
    "start": "384300",
    "end": "390960"
  },
  {
    "text": "taking an application runtime and having it run on an instance somewhere so the",
    "start": "390960",
    "end": "397710"
  },
  {
    "text": "very canonical basic example is a developer writes a simple hello world app and on Amazon you could provision an",
    "start": "397710",
    "end": "406120"
  },
  {
    "text": "ec2 instance and then deploy your workload to that instance and then now your applications running and",
    "start": "406120",
    "end": "412000"
  },
  {
    "text": "everything's great and I wish it was that simple as we scaled but the reality is we have as I mentioned hundreds of",
    "start": "412000",
    "end": "419620"
  },
  {
    "text": "developers deploying hundreds of services each service has hundreds of replicas running and those hundreds and",
    "start": "419620",
    "end": "426940"
  },
  {
    "text": "hundreds of runtimes are also themselves running on hundreds of instances so this",
    "start": "426940",
    "end": "431949"
  },
  {
    "text": "dependency graph and that simple runtime to compute concept gets very complex very quickly",
    "start": "431949",
    "end": "439710"
  },
  {
    "text": "in kubernetes and some of the other technology that we're going to talk about today are some of the ways that",
    "start": "439710",
    "end": "445599"
  },
  {
    "text": "we've managed to overcome these challenges and the core objectives that",
    "start": "445599",
    "end": "451270"
  },
  {
    "text": "we have as an infrastructure offering is we don't want our developers thinking",
    "start": "451270",
    "end": "456370"
  },
  {
    "text": "about what instances or what machines their code is running on they just want to take their code deploy it and then",
    "start": "456370",
    "end": "462880"
  },
  {
    "text": "move on to the next feature or the next set of tasks that they're on we also don't really want to be thinking about",
    "start": "462880",
    "end": "469720"
  },
  {
    "text": "the very very specific details of perfectly provisioning each specific",
    "start": "469720",
    "end": "476770"
  },
  {
    "text": "deployment I might know that this JavaScript app only needs two cores and then as that scales I can scale it up to",
    "start": "476770",
    "end": "483280"
  },
  {
    "text": "three cores but the task of budgeting that purchasing the OP the instances can",
    "start": "483280",
    "end": "488889"
  },
  {
    "text": "be pretty cumbersome over time so we really just don't want to think about it and again we'll dive into that and at a",
    "start": "488889",
    "end": "497710"
  },
  {
    "text": "very high level this is the end stack that we work with and we're gonna walk",
    "start": "497710",
    "end": "505840"
  },
  {
    "text": "through each component of this infrastructure I'll describe it at a high level but my colleague Hubert will",
    "start": "505840",
    "end": "510849"
  },
  {
    "text": "actually dive into it and this is really what we're trying to achieve at the very top we have our application workloads",
    "start": "510849",
    "end": "516459"
  },
  {
    "text": "these are programs these are software systems that our developers are building we deploy them in docker containers on",
    "start": "516459",
    "end": "524078"
  },
  {
    "text": "top of kubernetes we use a blend of the various purchase options that Amazon",
    "start": "524079",
    "end": "530020"
  },
  {
    "text": "towards us when we deploy these onto ec2 instances and it it's a nice and",
    "start": "530020",
    "end": "536050"
  },
  {
    "text": "convenient diagram here but there's a lot of nuance and a lot of detail here but again the end objective is to solve",
    "start": "536050",
    "end": "542800"
  },
  {
    "text": "those two original goals one how do we solve scalable compute and two how do we",
    "start": "542800",
    "end": "548290"
  },
  {
    "text": "do that in a way that's being very mindful of costs so let's dive into some of the technical details here okay thank",
    "start": "548290",
    "end": "558580"
  },
  {
    "text": "you thank you so let's talk about a container is a ssin and orchestration so",
    "start": "558580",
    "end": "564580"
  },
  {
    "text": "containerization came about relatively about like ten years ago ish really been",
    "start": "564580",
    "end": "570430"
  },
  {
    "text": "popularized by docker and for a long time it's been used in very high skill very large workloads and as a variety of",
    "start": "570430",
    "end": "580180"
  },
  {
    "text": "developers have realized the power of docker and up and containerization it's",
    "start": "580180",
    "end": "585730"
  },
  {
    "text": "really grown pretty dramatically actually let me let me pull how many of yous containers how many use yes all",
    "start": "585730",
    "end": "594460"
  },
  {
    "text": "right sorry eight ec2 kubernetes okay good so",
    "start": "594460",
    "end": "603310"
  },
  {
    "text": "this will some of this will be review before the people who have used coop earnings but they're all go into some advanced topics but particularly in",
    "start": "603310",
    "end": "609910"
  },
  {
    "text": "scheduling containers at a basic layer they provide isolation between processes",
    "start": "609910",
    "end": "615670"
  },
  {
    "text": "on a Linux house typically so that means when you run two processes you can be",
    "start": "615670",
    "end": "621340"
  },
  {
    "text": "pretty much guaranteed two containers on on a Linux house you can be pretty much guaranteed they won't interfere with each other which is really really huge",
    "start": "621340",
    "end": "627250"
  },
  {
    "text": "from the standpoint of making sure that your applications are don't collide or cause any problems and that means you",
    "start": "627250",
    "end": "633490"
  },
  {
    "text": "can run them much more reliably and much more scalable containerization particularly shares unlike",
    "start": "633490",
    "end": "640390"
  },
  {
    "text": "virtualization technology which essentially you're running your own kernel containerization shares a kernel",
    "start": "640390",
    "end": "646840"
  },
  {
    "text": "with potentially other containers there's a the two big advantages of that is they that means the startup time is",
    "start": "646840",
    "end": "653200"
  },
  {
    "text": "faster because you don't have to spin up a new kernel for each instance or container you're running and the memory",
    "start": "653200",
    "end": "658720"
  },
  {
    "text": "footprint is much lower because you're not again running the same kernel the the downside is you're",
    "start": "658720",
    "end": "663880"
  },
  {
    "text": "in terms of what you can do within the kernel and you don't have a full feature like you can't run both a Mac container",
    "start": "663880",
    "end": "670600"
  },
  {
    "text": "and a Linux container on the same machine that doesn't really work that",
    "start": "670600",
    "end": "675790"
  },
  {
    "text": "way but the advantages are very significant for large-scale environments because the",
    "start": "675790",
    "end": "680920"
  },
  {
    "text": "memory efficiency in the startup time are really really powerful for especially if you're scaling big things",
    "start": "680920",
    "end": "688530"
  },
  {
    "text": "the efficiency allows you to really really pack nodes and instances very",
    "start": "688530",
    "end": "694090"
  },
  {
    "text": "tightly and put in a lot of instances so we have many many nodes which run",
    "start": "694090",
    "end": "700290"
  },
  {
    "text": "20-plus containers and they're not huge nodes but like 16 cores you could run 20",
    "start": "700290",
    "end": "706510"
  },
  {
    "text": "containers on easily and in a traditional like on-prem world you would also without containerization or",
    "start": "706510",
    "end": "712420"
  },
  {
    "text": "virtualization you you essentially buy a whole host for any kind of workload and that was very expensive and the",
    "start": "712420",
    "end": "718660"
  },
  {
    "text": "utilization was not very good because you were provision so much provisioning over-provisioning so much the other",
    "start": "718660",
    "end": "727090"
  },
  {
    "text": "benefit of containerization is the consistent and immutable images that you build to do it so I spent a lot of time",
    "start": "727090",
    "end": "733990"
  },
  {
    "text": "in the on-prem world trying to figure out oh why is this one server different maybe I deleted a file that I needed and",
    "start": "733990",
    "end": "739330"
  },
  {
    "text": "then I have to redeploy and reimage and that kind of problem really goes away when you're taking containers to their",
    "start": "739330",
    "end": "745570"
  },
  {
    "text": "full power because you just say ok I'm going to deploy this one container everywhere and it's always the same you",
    "start": "745570",
    "end": "750670"
  },
  {
    "text": "never worry about this sort of a snowflake problem where one server just starts to look different they building",
    "start": "750670",
    "end": "756610"
  },
  {
    "text": "the consistent images is really really great for large-scale production",
    "start": "756610",
    "end": "762130"
  },
  {
    "text": "environments and finally what docker really brought to the table was a great",
    "start": "762130",
    "end": "767170"
  },
  {
    "text": "toolset around building anything so instead of building up 20 different Linux the hosts of Red Hat and boone -",
    "start": "767170",
    "end": "774100"
  },
  {
    "text": "and not being sure if they're the same the the tool set around docker allows you to say ok all of these 20 images are all the same",
    "start": "774100",
    "end": "780910"
  },
  {
    "text": "and we all have perfect consistency and I can deploy it on on my desktop I can deploy it in my production environment I",
    "start": "780910",
    "end": "786580"
  },
  {
    "text": "can do employee in staging and they always like I spent a lot of time in earlier iterations of my life debugging",
    "start": "786580",
    "end": "793330"
  },
  {
    "text": "developer laptops and that's just such a nightmare I'm never gonna do that again so among those",
    "start": "793330",
    "end": "799180"
  },
  {
    "text": "things are the consistency is really really powerful for test environments so",
    "start": "799180",
    "end": "805330"
  },
  {
    "text": "what does cover daddy's bring to the table on top of that so now that I've explained docker a little bit",
    "start": "805330",
    "end": "810430"
  },
  {
    "text": "communities is essentially Anna Korca striation layer on top of Korea at ease it allows you to manage large numbers of",
    "start": "810430",
    "end": "816610"
  },
  {
    "text": "docker containers so it's not too difficult to manage three to five hosts of docker containers you just deploy two",
    "start": "816610",
    "end": "822990"
  },
  {
    "text": "if all the hosts and then you say okay point my web server to this host and",
    "start": "822990",
    "end": "828550"
  },
  {
    "text": "this container and point my database to this container but kubernetes provides a lot of tools around managing large-scale",
    "start": "828550",
    "end": "835510"
  },
  {
    "text": "workloads so if you want to speed up a hundred replicas that becomes a big",
    "start": "835510",
    "end": "840730"
  },
  {
    "text": "challenge particularly in scheduling so where do I have the resources to run",
    "start": "840730",
    "end": "846010"
  },
  {
    "text": "these containers and service discovery service discovery is actually quite a tricky challenge like if I tear down a",
    "start": "846010",
    "end": "852850"
  },
  {
    "text": "container and I move it from one host to another how do I get how do I fix the references there that are talking to",
    "start": "852850",
    "end": "858250"
  },
  {
    "text": "that old container such that they're not talking to the new running container so that's actually one of the greatest",
    "start": "858250",
    "end": "863470"
  },
  {
    "text": "strengths of kubernetes and feel like they've done a very good job of making",
    "start": "863470",
    "end": "868830"
  },
  {
    "text": "satisfying dynamic workloads such that when things move that you aw you automatically get pointing to the new",
    "start": "868830",
    "end": "875710"
  },
  {
    "text": "correct versions as I mentioned highly dynamic environments are really where kubernetes is very strong it's",
    "start": "875710",
    "end": "882360"
  },
  {
    "text": "particularly useful with small micro services it's not so great with large",
    "start": "882360",
    "end": "888220"
  },
  {
    "text": "like database or compute bound workloads and other types of things where you",
    "start": "888220",
    "end": "894250"
  },
  {
    "text": "really want for instance very specific types of requirements like you you need to occupy every single core on a CPU or",
    "start": "894250",
    "end": "902500"
  },
  {
    "text": "you need to run a high availability database and you need to talk to storage those kinds of workloads are not as",
    "start": "902500",
    "end": "909190"
  },
  {
    "text": "great for kubernetes Kooper days was really designed for small micro service workloads in dynamic environments and",
    "start": "909190",
    "end": "916060"
  },
  {
    "text": "finally a manages deployments as you say okay I want to deploy to 20 different",
    "start": "916060",
    "end": "921400"
  },
  {
    "text": "machines I wanted to deploy 100 managing that so that",
    "start": "921400",
    "end": "927930"
  },
  {
    "text": "rolls out smoothly it doesn't crash it doesn't it restarts automatically if",
    "start": "927930",
    "end": "933880"
  },
  {
    "text": "your container crashes kubernetes takes care and restarts it and can manage it",
    "start": "933880",
    "end": "939459"
  },
  {
    "text": "for you if it if it crashes permanently can reschedule it to a different node",
    "start": "939459",
    "end": "944610"
  },
  {
    "text": "most of you are familiar with ec2 s almost everybody uses it we're all in the 80s loft so I'm sure you're familiar",
    "start": "944639",
    "end": "951940"
  },
  {
    "text": "with Elastic Compute cloud it provides in as far as we could tell nearly",
    "start": "951940",
    "end": "957970"
  },
  {
    "text": "infinite scalability in terms of types of instances number of instances costs",
    "start": "957970",
    "end": "964060"
  },
  {
    "text": "and a lot of features that you don't have to worry about like is the network solid like a device this network is",
    "start": "964060",
    "end": "969910"
  },
  {
    "text": "incredibly saw like a lot of these things that that's why we're in the cloud we don't most companies are moving",
    "start": "969910",
    "end": "975970"
  },
  {
    "text": "to from on-prem environments to cloud environments and a device is probably the best choice as much as we would like",
    "start": "975970",
    "end": "983199"
  },
  {
    "text": "to to try other on prime instances to save money but eight of us is still like",
    "start": "983199",
    "end": "989860"
  },
  {
    "text": "gives us the best best flexibility in terms of choice of instances and look",
    "start": "989860",
    "end": "995769"
  },
  {
    "text": "global locations and various other cloud",
    "start": "995769",
    "end": "1001699"
  },
  {
    "text": "integrations like their cloud front their elby's all of those features sets put together a pretty strong offering so",
    "start": "1001699",
    "end": "1009980"
  },
  {
    "text": "applications so when you provision a kubernetes cluster you can kind of do it",
    "start": "1009980",
    "end": "1016949"
  },
  {
    "text": "in two different ways first you can think of it just like a",
    "start": "1016949",
    "end": "1022199"
  },
  {
    "text": "traditional on-premise environment where you have whatever twenty instances pretty nodes and you just install the",
    "start": "1022199",
    "end": "1028110"
  },
  {
    "text": "kubernetes binaries on it and you just run them that's that works and you can definitely there's lots of tools to do",
    "start": "1028110",
    "end": "1034350"
  },
  {
    "text": "that and if you have a very static environment it works but you don't you don't get the benefits of really using",
    "start": "1034350",
    "end": "1039959"
  },
  {
    "text": "the cloud if you just sort of if your permission in an instance yourself and then you're installing kubernetes binaries on top of it and then you",
    "start": "1039959",
    "end": "1046110"
  },
  {
    "text": "haven't you join the cluster that's okay but it doesn't provide take advantage of",
    "start": "1046110",
    "end": "1052080"
  },
  {
    "text": "the full advantages of the the cloud things like auto scan and that's what I'm here to talk about primarily the the",
    "start": "1052080",
    "end": "1060299"
  },
  {
    "text": "auto scaling feature is one do a cloud native install are pretty strong and I'll go over some of those",
    "start": "1060299",
    "end": "1065340"
  },
  {
    "text": "it'll do things like okay yeah kubernetes node joins a cluster and then",
    "start": "1065340",
    "end": "1070740"
  },
  {
    "text": "new workloads get scheduled onto that node and then that node automatically the those workloads automatically join",
    "start": "1070740",
    "end": "1077250"
  },
  {
    "text": "load balancers and then it can take care of all of that for you and so doing a true cloud native install is is definitely a high highly recommended and",
    "start": "1077250",
    "end": "1084679"
  },
  {
    "text": "one of the points that I wanted to dive into a little bit more especially for",
    "start": "1084679",
    "end": "1089909"
  },
  {
    "text": "those that aren't too familiar with kubernetes is again this idea of providing a generalized compute platform",
    "start": "1089909",
    "end": "1096899"
  },
  {
    "text": "so in this really really high level diagram at the very bottom we have an example of provisioning three ec2 nodes",
    "start": "1096899",
    "end": "1103980"
  },
  {
    "text": "we have an m4 for excel which has 16 cores and then let's say we throw in two",
    "start": "1103980",
    "end": "1110760"
  },
  {
    "text": "more m4 xl's which each have four cores when we're talking specifically about",
    "start": "1110760",
    "end": "1116520"
  },
  {
    "text": "ec2 we're interacting with three unique instances and when we set up kubernetes",
    "start": "1116520",
    "end": "1121590"
  },
  {
    "text": "running on these three nodes the kubernetes cluster exposes this effectively as 24 cores and for the",
    "start": "1121590",
    "end": "1128159"
  },
  {
    "text": "developer that's deploying their system into this cluster they don't know and they don't need to care about how many",
    "start": "1128159",
    "end": "1133679"
  },
  {
    "text": "instances are under the hood so obviously 24 cores is great in our production environment we're talking",
    "start": "1133679",
    "end": "1139320"
  },
  {
    "text": "about tens of thousands of course but again we're starting to see that abstraction and separation of the",
    "start": "1139320",
    "end": "1144570"
  },
  {
    "text": "developer's concerns of I need some course and the infer team's concerns about how many ec2 instances is is",
    "start": "1144570",
    "end": "1150990"
  },
  {
    "text": "actually running on so the scheduler tool and workloads on two instances the",
    "start": "1150990",
    "end": "1159510"
  },
  {
    "text": "one of the very core components of kubernetes it's a scheduler and how it takes care of workloads so you can see",
    "start": "1159510",
    "end": "1165299"
  },
  {
    "text": "in this diagram the the 16 core m4 for excels on the to four core and for",
    "start": "1165299",
    "end": "1171899"
  },
  {
    "text": "excels so if you look at different types of workloads could have an ideal fit on",
    "start": "1171899",
    "end": "1178730"
  },
  {
    "text": "various different instances like in the worst case and I've seen this happen in",
    "start": "1178730",
    "end": "1183870"
  },
  {
    "text": "like on-prem environments you have a you have a an instance with say 16 gigs of",
    "start": "1183870",
    "end": "1190500"
  },
  {
    "text": "memory and then you have an application which uses nine gigs of memory so you've now tuck yourself into terrible position",
    "start": "1190500",
    "end": "1196100"
  },
  {
    "text": "because you're wasting seven gigs of memory on every single instance you do this like once it's fine you do this a",
    "start": "1196100",
    "end": "1201320"
  },
  {
    "text": "hundred times it just gets wasteful so being unable to schedule and finding the places that you can fit your workload is",
    "start": "1201320",
    "end": "1208789"
  },
  {
    "text": "really really important and is the way he maximizes the compute and memory",
    "start": "1208789",
    "end": "1213830"
  },
  {
    "text": "efficiency the scheduler also has a vast",
    "start": "1213830",
    "end": "1219200"
  },
  {
    "text": "array of more complex resource constraints among them are things like",
    "start": "1219200",
    "end": "1225559"
  },
  {
    "text": "so CPU and memory are very basic that everybody understands them you say ok I need six gigs of memory I need three two",
    "start": "1225559",
    "end": "1231440"
  },
  {
    "text": "cores those are easy but the scheduler also has a lot more features around",
    "start": "1231440",
    "end": "1236720"
  },
  {
    "text": "things like affinity for instance you said okay I have a workload that runs on this node but I don't want it to run on",
    "start": "1236720",
    "end": "1243350"
  },
  {
    "text": "this I only wanted to run once here because it's like a database and I'm replicating it to somewhere else",
    "start": "1243350",
    "end": "1248450"
  },
  {
    "text": "so the the scheduler provides features to community's users that say things",
    "start": "1248450",
    "end": "1253520"
  },
  {
    "text": "like ante affinity don't schedule these together because that's gonna compromise my availability if I lose one so there",
    "start": "1253520",
    "end": "1259730"
  },
  {
    "text": "are a lot of different other kinds of ways and sometimes you you want to collocate them you say okay this I need",
    "start": "1259730",
    "end": "1265789"
  },
  {
    "text": "super high performance between these two applications so while Colo think co-locate them and with the schedules",
    "start": "1265789",
    "end": "1271610"
  },
  {
    "text": "affinity feature and then persistent volumes are very tricky to manage",
    "start": "1271610",
    "end": "1276740"
  },
  {
    "text": "whether you're using EBS or some kind of external storage the scheduler can",
    "start": "1276740",
    "end": "1282260"
  },
  {
    "text": "understand that okay I have an EBS volume I need to mount it to another instance if if my instance dies I can",
    "start": "1282260",
    "end": "1289190"
  },
  {
    "text": "reschedule my pod and then I pull the storage back onto that same instance that's a that's a really really powerful",
    "start": "1289190",
    "end": "1294799"
  },
  {
    "text": "ability and it's it's not easy to do and finally you can request specific types",
    "start": "1294799",
    "end": "1300799"
  },
  {
    "text": "of hardware like I could say ok my pod needs GPUs and you know now that that",
    "start": "1300799",
    "end": "1306289"
  },
  {
    "text": "that's not a thing you just always get with an instance you have to like provision of special instance but the",
    "start": "1306289",
    "end": "1312409"
  },
  {
    "text": "the combination of the kubernetes scheduler and the auto scalars will allow you to do that as you say ok I",
    "start": "1312409",
    "end": "1317539"
  },
  {
    "text": "need 100 GPUs for this workload and if you put these pieces all together in the",
    "start": "1317539",
    "end": "1323120"
  },
  {
    "text": "kubernetes in a Russell environment you can get that and you could say ok these workloads I'm gonna spin them up",
    "start": "1323120",
    "end": "1330230"
  },
  {
    "text": "for 20 minutes and then I'll tear them down when it's done those are those kinds of things are really going to help",
    "start": "1330230",
    "end": "1335450"
  },
  {
    "text": "you manage costs especially if you can use spot instances as well as a combination with on-demand reserves this",
    "start": "1335450",
    "end": "1344210"
  },
  {
    "text": "is a one thing I kind of like to show one of the things I'm proud about in how we use kubernetes is the efficiency",
    "start": "1344210",
    "end": "1350600"
  },
  {
    "text": "we've gained out of locating all the workloads on a few very large dense",
    "start": "1350600",
    "end": "1356450"
  },
  {
    "text": "nodes so in when you start out just provision and since you just say okay",
    "start": "1356450",
    "end": "1361580"
  },
  {
    "text": "give me a fork or 16 for Excel and then you say okay my java process let's put",
    "start": "1361580",
    "end": "1367460"
  },
  {
    "text": "it on there it's going to take two gigs two cores and eight gigs in memory but now you've wasted a half of that but",
    "start": "1367460",
    "end": "1373340"
  },
  {
    "text": "once you start to take the power of the containers and ease the scheduling on top of it and kubernetes manages all the",
    "start": "1373340",
    "end": "1379399"
  },
  {
    "text": "scheduling then you can really pack those things tight so you could say okay now I'll cut two of these to court a gig",
    "start": "1379399",
    "end": "1387940"
  },
  {
    "text": "processes onto the same four core 16 and utilize it perfectly but and then you",
    "start": "1387940",
    "end": "1394399"
  },
  {
    "text": "can also do reservations to say okay I may not use it all the time and then but",
    "start": "1394399",
    "end": "1399740"
  },
  {
    "text": "I'm gonna burst up so I don't want you to schedule too much on those things so",
    "start": "1399740",
    "end": "1404899"
  },
  {
    "text": "one of the things I'm proud about is how much we've improved the efficiency because it's not uncommon for typical",
    "start": "1404899",
    "end": "1410389"
  },
  {
    "text": "enterprise workloads to have just 10% if the CPU utilization or less especially",
    "start": "1410389",
    "end": "1415519"
  },
  {
    "text": "like a database where you can't reap revision it it's got a very low utilization rate and during normal and",
    "start": "1415519",
    "end": "1420889"
  },
  {
    "text": "you've just provisions for these massive spikes so you you run it at five percent utilization all the time and then like",
    "start": "1420889",
    "end": "1426679"
  },
  {
    "text": "once a night during your hourly batch jobs it goes at 80% so improving the",
    "start": "1426679",
    "end": "1432139"
  },
  {
    "text": "efficiency is one of those things I'm really proud of that kubernetes has done so if you look at those numbers like they're there this is actually low",
    "start": "1432139",
    "end": "1438649"
  },
  {
    "text": "traffic when we were hovering at 20 to 50% utilization during peak traffic we'll go to 60 80 percent plus so let me",
    "start": "1438649",
    "end": "1448700"
  },
  {
    "text": "talk about the actual scaley auto scaling features of how kubernetes works the very simplest one is the horizontal",
    "start": "1448700",
    "end": "1455059"
  },
  {
    "text": "part on a scaler has anybody used this anyway okay good um so the horizontal pot",
    "start": "1455059",
    "end": "1462290"
  },
  {
    "text": "autoscaler is relatively simple and straightforward as it starts so it",
    "start": "1462290",
    "end": "1467720"
  },
  {
    "text": "measures the CPU utilization of your processes your pods in Korea Andy's world or replicas and then when the CPU",
    "start": "1467720",
    "end": "1475130"
  },
  {
    "text": "dilution goes high then it can spin up more replicas it's a simple linear calculation where it says okay I have a",
    "start": "1475130",
    "end": "1482090"
  },
  {
    "text": "target of say 50% utilization and after that my workload starts to fail or gets",
    "start": "1482090",
    "end": "1488320"
  },
  {
    "text": "performs poorly so if I say okay I want to use 50% of my CPU then when it gets",
    "start": "1488320",
    "end": "1494480"
  },
  {
    "text": "to a hundred percent it would scale to two and then attempt to split that workload and that's relatively",
    "start": "1494480",
    "end": "1500270"
  },
  {
    "text": "straightforward he just does a CPU calculation and every few minutes it can scale up or scale down and just add and",
    "start": "1500270",
    "end": "1506330"
  },
  {
    "text": "subtract new replicas so if you yeah so",
    "start": "1506330",
    "end": "1512300"
  },
  {
    "text": "the workloads when the workloads exceed a target threshold then it can scale up or when it falls below then it can scale",
    "start": "1512300",
    "end": "1520250"
  },
  {
    "text": "down B you can also specify a minimum for instance if you have a large burst",
    "start": "1520250",
    "end": "1525560"
  },
  {
    "text": "workload that it it's not instant it takes a couple minutes typically and you don't want to have to provision every",
    "start": "1525560",
    "end": "1532580"
  },
  {
    "text": "single minute anyways because that the scale up and scale down for most applications is a little tricky so most",
    "start": "1532580",
    "end": "1538730"
  },
  {
    "text": "of the time it takes two to five minutes to to scale up or down to make a change but if this is an example of what we do",
    "start": "1538730",
    "end": "1547760"
  },
  {
    "text": "in production so we this event capping service has 30 replicas of a relatively",
    "start": "1547760",
    "end": "1552830"
  },
  {
    "text": "simple java service but we run a lot of copies of it and it's target CPU utilization is 75% so when it hits if",
    "start": "1552830",
    "end": "1558830"
  },
  {
    "text": "there's 30 replicas and they're all hitting 75% then it'll or when they",
    "start": "1558830",
    "end": "1565040"
  },
  {
    "text": "start to go over 75% CPU utilization it'll start to scale up but it's capped at 50 replicas so it could go to 100 150",
    "start": "1565040",
    "end": "1572480"
  },
  {
    "text": "once it hits that replica cap um actually back up there's also features",
    "start": "1572480",
    "end": "1578780"
  },
  {
    "text": "that allow you to define its CPU is the most straightforward and easiest metric",
    "start": "1578780",
    "end": "1584690"
  },
  {
    "text": "for which you can scale on but that you can also use custom metrics in later versions of kubernetes and say ok I",
    "start": "1584690",
    "end": "1589970"
  },
  {
    "text": "don't really care CPU is not about hoc which in almost every is anyway so most applications are either memory bound or",
    "start": "1589970",
    "end": "1595940"
  },
  {
    "text": "network or i/o bound so you could say okay the the i/o on my machine is too high I've defined this custom metric it",
    "start": "1595940",
    "end": "1602990"
  },
  {
    "text": "takes a little work to plug these in but not a lot work a lot of work and it says okay now when in my i/o is utilization",
    "start": "1602990",
    "end": "1609530"
  },
  {
    "text": "is 50% then I scale up or something like that so it's all it's pretty flexible for from if you want to start to define",
    "start": "1609530",
    "end": "1616070"
  },
  {
    "text": "custom metrics but it'll allow you to get there okay the cluster autoscaler so",
    "start": "1616070",
    "end": "1623360"
  },
  {
    "text": "the cluster autoscaler the horizontal autoscaler is straightforward and the simplest thing to do and is what",
    "start": "1623360",
    "end": "1629210"
  },
  {
    "text": "everybody starts out with the cluster autoscaler is more complex so the the pod autoscaler assumes that you already",
    "start": "1629210",
    "end": "1636140"
  },
  {
    "text": "have the nodes that you need so if you're if you've already maxed out your whole cluster it can't do anything it",
    "start": "1636140",
    "end": "1641480"
  },
  {
    "text": "won't schedule it doesn't know where to put things the cluster autoscaler alleviates this problem by saying okay I",
    "start": "1641480",
    "end": "1647660"
  },
  {
    "text": "can grab more nodes or instances if this works both in AWS and GCP and also azure",
    "start": "1647660",
    "end": "1655010"
  },
  {
    "text": "and I think even digitalocean may support this but it's really powerful so",
    "start": "1655010",
    "end": "1660020"
  },
  {
    "text": "now you can actually take full advantage of the cloud like horizontal pod autoscaler something we'd use even an",
    "start": "1660020",
    "end": "1665660"
  },
  {
    "text": "on-prem or local environment but to actually get the utilization that you",
    "start": "1665660",
    "end": "1671240"
  },
  {
    "text": "want out of the cloud and be able to scale up instantly to unlimited size workload you could use the cluster",
    "start": "1671240",
    "end": "1676580"
  },
  {
    "text": "autoscaler to add nodes to your cluster so the cluster autoscaler presumes that",
    "start": "1676580",
    "end": "1682460"
  },
  {
    "text": "you you have sort of this cloud environment and your nose just can start up and join the cluster so that's why I really encourage people to set up sort",
    "start": "1682460",
    "end": "1688940"
  },
  {
    "text": "of cloud native environments of kubernetes and once once you have these auto scaling groups set up and that your",
    "start": "1688940",
    "end": "1695210"
  },
  {
    "text": "your nodes can just join your cluster properly then whenever you you have",
    "start": "1695210",
    "end": "1700370"
  },
  {
    "text": "scheduling problems and the cluster autoscaler can detect that your pods are just stuck pending because they can't be",
    "start": "1700370",
    "end": "1706460"
  },
  {
    "text": "scheduled because there's not enough resources it'll go through and it'll detect that and they'll figure out which",
    "start": "1706460",
    "end": "1711799"
  },
  {
    "text": "nodes it needs to add to your cluster in order to get the nodes that you're that",
    "start": "1711799",
    "end": "1718100"
  },
  {
    "text": "are waiting to schedule schedule now obviously this takes a minute or two as it detects a division instances and",
    "start": "1718100",
    "end": "1724130"
  },
  {
    "text": "figures out which one it needs and then it spins them up which can take 30 to 30 seconds to a couple minutes",
    "start": "1724130",
    "end": "1729960"
  },
  {
    "text": "depending on the type of instances and your startup process but it's really really powerful and it allows you to at",
    "start": "1729960",
    "end": "1736919"
  },
  {
    "text": "the cost layer you don't pay for pods or workloads you pay for instances so this",
    "start": "1736919",
    "end": "1741960"
  },
  {
    "text": "is how you actually control their cost in conjunction with pod or escalator or other our scaling types of technology so",
    "start": "1741960",
    "end": "1749760"
  },
  {
    "text": "it also it's actually very interesting because it runs its own its own copy of",
    "start": "1749760",
    "end": "1755850"
  },
  {
    "text": "this scheduler so if you say okay I only need I only want GPU instances for my workload then it knows it understands",
    "start": "1755850",
    "end": "1763320"
  },
  {
    "text": "that and says okay I'm not gonna spin up these regular m4s because they don't have GPUs I'm only gonna if you have a",
    "start": "1763320",
    "end": "1769440"
  },
  {
    "text": "auto scaling group that has GPUs enabled then it would spin up to those specific types of workloads so it's very powerful",
    "start": "1769440",
    "end": "1776490"
  },
  {
    "text": "so that means you can run mixed workloads you can do all kinds of things so it also understands multiple",
    "start": "1776490",
    "end": "1782580"
  },
  {
    "text": "different types of auto scaling groups so if you said okay I would I have this",
    "start": "1782580",
    "end": "1788279"
  },
  {
    "text": "GPU cluster gpo auto scaling group and I also have a regular workload but I don't",
    "start": "1788279",
    "end": "1794700"
  },
  {
    "text": "it can choose between them for those situations where you need GPIOs but maybe it would choose the regular four",
    "start": "1794700",
    "end": "1800960"
  },
  {
    "text": "for your normal workloads and this is generally all configurable yeah I'd say on a daily basis I described our",
    "start": "1800960",
    "end": "1808890"
  },
  {
    "text": "day-to-day traffic of let's say a quarter million messages or events coming in per second due to the nature",
    "start": "1808890",
    "end": "1815429"
  },
  {
    "text": "of our product we have a very predictable sine wave of traffic where this troughs and Peaks depending on the",
    "start": "1815429",
    "end": "1820890"
  },
  {
    "text": "activity on the internet and as such we can track the metrics of our kubernetes",
    "start": "1820890",
    "end": "1827100"
  },
  {
    "text": "cluster growing and shrinking automatically every single day and this",
    "start": "1827100",
    "end": "1832230"
  },
  {
    "text": "is without the input from anybody on the infrastructure team hopefully but it's",
    "start": "1832230",
    "end": "1837779"
  },
  {
    "text": "just growing and shrinking accordingly which is great from a cost management perspective similarly and that's in the",
    "start": "1837779",
    "end": "1844350"
  },
  {
    "text": "context of the cluster autoscaler going back to the pod autoscaler we might have",
    "start": "1844350",
    "end": "1849360"
  },
  {
    "text": "a certain system or a certain endpoint that has a sudden burst of traffic well the pod a scalar will automatically",
    "start": "1849360",
    "end": "1855960"
  },
  {
    "text": "detect that spike and then scale itself out even if we don't need to scale out the entire cluster and a lot of this stuff",
    "start": "1855960",
    "end": "1862230"
  },
  {
    "text": "is happening automatically under our feet it's happening at 2:00 in the morning when hopefully we're sleeping or",
    "start": "1862230",
    "end": "1867600"
  },
  {
    "text": "it's happening at noon when there's a big burst of traffic and again these are some of the underlying benefits that",
    "start": "1867600",
    "end": "1872790"
  },
  {
    "text": "we're getting by using these tools finally and this is a relatively new",
    "start": "1872790",
    "end": "1879060"
  },
  {
    "text": "feature is the vertical pod autoscaler so the vertical pod autoscaler is actually a has a different theory",
    "start": "1879060",
    "end": "1885540"
  },
  {
    "text": "it measures what your pods or workloads are doing and then it scales an",
    "start": "1885540",
    "end": "1890730"
  },
  {
    "text": "individual pod to the right size after it measures it for a while so you you run it for a week and it says ok you",
    "start": "1890730",
    "end": "1896880"
  },
  {
    "text": "you've allocated 2 gigs of memory and one core but you're only using a half the core and one Giga memory so I'm",
    "start": "1896880",
    "end": "1903930"
  },
  {
    "text": "gonna resize your pod such that it can only take advantage of that ORS work that those sets of resources and then",
    "start": "1903930",
    "end": "1910200"
  },
  {
    "text": "you can tighten up your but your bin packing or your resource utilization it's not as freak nut as commonly used",
    "start": "1910200",
    "end": "1918120"
  },
  {
    "text": "but it is a new feature and I expect we'll be taking advantage of it soon and and many many large workloads would",
    "start": "1918120",
    "end": "1924720"
  },
  {
    "text": "benefit from this then it takes the worry of you of how to like we don't",
    "start": "1924720",
    "end": "1930390"
  },
  {
    "text": "want to measure every we don't want to make human decisions about every single workload and how much memory it needs",
    "start": "1930390",
    "end": "1935400"
  },
  {
    "text": "and how much CPU and needs but this will help take that the decision-making out",
    "start": "1935400",
    "end": "1940830"
  },
  {
    "text": "of our hands and just sort of do it I'll grow the magazine um what do we do at",
    "start": "1940830",
    "end": "1946680"
  },
  {
    "text": "branch so at branch we have a half a dozen cluster is running medium to plus-size",
    "start": "1946680",
    "end": "1952830"
  },
  {
    "text": "cards there are companies that run thousand node clusters I don't recommend it it can be quite challenging the we",
    "start": "1952830",
    "end": "1962040"
  },
  {
    "text": "our clusters are I would call the medium size 20 to 150 nodes we use plus size",
    "start": "1962040",
    "end": "1968310"
  },
  {
    "text": "instances like I would say we don't it's for most of the scheduling features it's",
    "start": "1968310",
    "end": "1975780"
  },
  {
    "text": "probably better to use larger instances that allow you to pack them tighter if you use smaller instances you'll get",
    "start": "1975780",
    "end": "1981570"
  },
  {
    "text": "into the problem that I mentioned about where you have a 16 gig machine and you'll try and run a 9 gig were closed and not",
    "start": "1981570",
    "end": "1987100"
  },
  {
    "text": "it also works better if you have smaller workloads so instead of running five",
    "start": "1987100",
    "end": "1992299"
  },
  {
    "text": "large four gig engine X pods you you run 21 Giga engine X pods or something like",
    "start": "1992299",
    "end": "1999110"
  },
  {
    "text": "that so smaller workloads tend to pack better and they're more efficient but sometimes that your application doesn't",
    "start": "1999110",
    "end": "2005860"
  },
  {
    "text": "work that way but that's a that's a consideration so we run sixteen sixteen",
    "start": "2005860",
    "end": "2010870"
  },
  {
    "text": "core to 128 core type of machines and we have hundreds of these the network",
    "start": "2010870",
    "end": "2019149"
  },
  {
    "text": "technology we use we actually are trying to variety of different ones the simplest one is the cube net one so that",
    "start": "2019149",
    "end": "2025240"
  },
  {
    "text": "essentially leaves all routing decisions to AWS that's straightforward and has",
    "start": "2025240",
    "end": "2032259"
  },
  {
    "text": "been quite reliable for us there's a limit to the size of a cluster you can build with that though but we've also",
    "start": "2032259",
    "end": "2037720"
  },
  {
    "text": "tested weave and cube router and we're gonna test the ATSC VPC CNI for our",
    "start": "2037720",
    "end": "2044409"
  },
  {
    "text": "costs we use it we try and use a variety of different methodologies and ian's will go into these a little bit more but",
    "start": "2044409",
    "end": "2050500"
  },
  {
    "text": "part of it is balancing the availability of on demands which they will never take",
    "start": "2050500",
    "end": "2056470"
  },
  {
    "text": "away versus spot instances which you can lose at any time and it is a danger that we have encountered where the ativ s",
    "start": "2056470",
    "end": "2063280"
  },
  {
    "text": "will decide ok these spot instances are ephemeral and you lose 30 at a time we",
    "start": "2063280",
    "end": "2068618"
  },
  {
    "text": "lost we've lost I don't know more than half of a cluster at this due to eat it was taking away spot instances so those are",
    "start": "2068619",
    "end": "2077290"
  },
  {
    "text": "but the cost savings are huge right there 1/4 of the cost of the dawn' demanding sis's so we we try and mix a",
    "start": "2077290",
    "end": "2085030"
  },
  {
    "text": "balance for our baseline workloads we have somewhere between 50 to 80 percent sort of on-demand Ince's and then we use",
    "start": "2085030",
    "end": "2091839"
  },
  {
    "text": "spot instances to fill reserve capacity so another thing we do is we kind of mix",
    "start": "2091839",
    "end": "2099010"
  },
  {
    "text": "we're trying to provision we have different SLA s for different clusters so we have a high SLA cluster where you",
    "start": "2099010",
    "end": "2106030"
  },
  {
    "text": "don't you really don't want to lose your workload you never want it to get lost on put on a spot ences and then we have",
    "start": "2106030",
    "end": "2111790"
  },
  {
    "text": "our other workloads where ok you can burst to 600 cores if you want you we",
    "start": "2111790",
    "end": "2117069"
  },
  {
    "text": "have large SPARC job and so large enlarge batch workloads that will just say we have full auto scaling and say okay",
    "start": "2117069",
    "end": "2122710"
  },
  {
    "text": "you can run the biggest job that you can possibly imagine but there's a reasonable chance you might get",
    "start": "2122710",
    "end": "2127900"
  },
  {
    "text": "interrupted whether it's due to spot or cluster or something else like that so those those and but because we're using",
    "start": "2127900",
    "end": "2134080"
  },
  {
    "text": "spots in those those clusters are much cheaper to run than the on-demand sort of high service level agreement type of",
    "start": "2134080",
    "end": "2139720"
  },
  {
    "text": "workloads and the two lean is done with circle CI which is our deployment tool",
    "start": "2139720",
    "end": "2145360"
  },
  {
    "text": "of choice and flux which is a get ops tool where we where it says okay let's check all our deployments and all our",
    "start": "2145360",
    "end": "2151870"
  },
  {
    "text": "configuration our kubernetes configuration into get and then flux just automatically applies on that like",
    "start": "2151870",
    "end": "2158020"
  },
  {
    "text": "is good really good visibility to developers operators and everyone to say okay this is that this change went out",
    "start": "2158020",
    "end": "2163660"
  },
  {
    "text": "this into the cluster at this time it caused these issues or didn't or we're not fine",
    "start": "2163660",
    "end": "2168880"
  },
  {
    "text": "so deploying so one of the key things I would say about trying to run kubernetes in a production or large-scale",
    "start": "2168880",
    "end": "2174730"
  },
  {
    "text": "environment is kubernetes is actually pretty straightforward once you sort of get into the flow and sort of understand",
    "start": "2174730",
    "end": "2181150"
  },
  {
    "text": "the primitives and the objects but building your workloads to actually deploy and have the CI process the",
    "start": "2181150",
    "end": "2187960"
  },
  {
    "text": "circle the continuous integration and continuous deployment process it's actually quite hard we spent probably as",
    "start": "2187960",
    "end": "2193600"
  },
  {
    "text": "much time or more time on continuous integration and continuous deployment as",
    "start": "2193600",
    "end": "2198640"
  },
  {
    "text": "we did on as we do on kubernetes management so a CI CD becomes quite",
    "start": "2198640",
    "end": "2205210"
  },
  {
    "text": "tricky because you have to support multiple platforms whether the node.js compilation environment is different",
    "start": "2205210",
    "end": "2210610"
  },
  {
    "text": "than the Java and maven and you have to it's a per platform we try make them",
    "start": "2210610",
    "end": "2216190"
  },
  {
    "text": "generic within a platform of course we also easy drop wizard we use and genetics we but there's always almost",
    "start": "2216190",
    "end": "2224410"
  },
  {
    "text": "always some custom work going into deployment and continuous integration to get the whole thing to build but once",
    "start": "2224410",
    "end": "2230830"
  },
  {
    "text": "you get the whole thing built then the deployment is not super tricky gear Ops",
    "start": "2230830",
    "end": "2236050"
  },
  {
    "text": "is sort of this new methodology that everybody's taking on where you even",
    "start": "2236050",
    "end": "2241150"
  },
  {
    "text": "configuration and code changes are not just code changes but configuration and management tooling changes are all",
    "start": "2241150",
    "end": "2246640"
  },
  {
    "text": "checked in to get and deploy it automatically so the only interface or the only way you ever make changes",
    "start": "2246640",
    "end": "2251710"
  },
  {
    "text": "should be through get or your source configuration so source code to manage me tool and",
    "start": "2251710",
    "end": "2257289"
  },
  {
    "text": "that means you can always roll back you can some things don't roll back like if you delete instances that's not",
    "start": "2257289",
    "end": "2262630"
  },
  {
    "text": "something you could roll back but you can always track changes as well and and make sure that because they all went",
    "start": "2262630",
    "end": "2268809"
  },
  {
    "text": "through the same pipeline of deploy infrastructure a deployment infrastructure as code then you always",
    "start": "2268809",
    "end": "2275079"
  },
  {
    "text": "know what happened and the other thing is it building a pipeline that this type",
    "start": "2275079",
    "end": "2280780"
  },
  {
    "text": "makes it so that you can unify and cert to codify things so now I don't have",
    "start": "2280780",
    "end": "2287890"
  },
  {
    "text": "five different interfaces to make changes to our monitoring system I change it once and get and now I can",
    "start": "2287890",
    "end": "2293920"
  },
  {
    "text": "automate that change in front of that so I can build a tooling pipeline in front of that too so all it has to do is push",
    "start": "2293920",
    "end": "2299829"
  },
  {
    "text": "to get to get my monitoring changes in that's not kubernetes specific that's just general good practice okay",
    "start": "2299829",
    "end": "2306990"
  },
  {
    "text": "so what are some of the tips that I would say to people starting out with kubernetes or building new",
    "start": "2306990",
    "end": "2313030"
  },
  {
    "text": "infrastructure with kubernetes first and this is just good practice kubernetes",
    "start": "2313030",
    "end": "2318160"
  },
  {
    "text": "are not is build stateless whenever possible stateless applications will give you a",
    "start": "2318160",
    "end": "2324609"
  },
  {
    "text": "much better scalability they'll give you much better reliability and I'm making deployment and management a lot easier",
    "start": "2324609",
    "end": "2332609"
  },
  {
    "text": "don't kubernetes moves very quickly in",
    "start": "2332609",
    "end": "2337660"
  },
  {
    "text": "terms of community and one of the one of my regrets is I didn't build a way to",
    "start": "2337660",
    "end": "2343240"
  },
  {
    "text": "upgrade kubernetes clusters very easily so now I'm kind of stuck with some old clusters like I have difficulty managing",
    "start": "2343240",
    "end": "2350349"
  },
  {
    "text": "but I want all these new features with 111 112 113 114 so come to the community",
    "start": "2350349",
    "end": "2357279"
  },
  {
    "text": "adds tons of features very very quickly so have a process by which you can upgrade your cluster to get all the",
    "start": "2357279",
    "end": "2363339"
  },
  {
    "text": "latest features because nobody ever builds for three year long version of kubernetes it's probably a mistake to",
    "start": "2363339",
    "end": "2370960"
  },
  {
    "text": "start building your most critical workloads into career days this is obviously just safe and sound practices",
    "start": "2370960",
    "end": "2377529"
  },
  {
    "text": "but people try and be aggressive about putting databases into communities I wouldn't do that",
    "start": "2377529",
    "end": "2383470"
  },
  {
    "text": "there are okay so I guess when when somebody asked me should I put my database into kubernetes I say well how",
    "start": "2383470",
    "end": "2390369"
  },
  {
    "text": "many 9s do you need if you need two nines of availability if you're 99 percent yeah it's probably fine if you",
    "start": "2390369",
    "end": "2395680"
  },
  {
    "text": "need four nines you should rethink what you're doing like if you need a if you only want to survive five minutes of",
    "start": "2395680",
    "end": "2401470"
  },
  {
    "text": "downtime of year then I would not put it in Cooper days yeah I could see a future in two or three years where that's possible but like it's not it's not that",
    "start": "2401470",
    "end": "2410819"
  },
  {
    "text": "risky it's not worth risking your business for and finally specifically",
    "start": "2410819",
    "end": "2416890"
  },
  {
    "text": "databases databases yes yeah databases also have very specific aiyyo aiyyo requirements find Network requirements",
    "start": "2416890",
    "end": "2422589"
  },
  {
    "text": "and all these things and you don't really want to co-locate your databases with all the other things that can make it noisy or problematic and finally",
    "start": "2422589",
    "end": "2429430"
  },
  {
    "text": "bigger nodes for cost efficiency but satisfy your availability requirements",
    "start": "2429430",
    "end": "2435550"
  },
  {
    "text": "first I typically say run five nodes in a kubernetes cluster then we then you have a core in system like a Kafka or a",
    "start": "2435550",
    "end": "2442810"
  },
  {
    "text": "zookeeper where you need three nodes available as you grow you'll you'll",
    "start": "2442810",
    "end": "2448300"
  },
  {
    "text": "expand the clusters and you can up size you for efficiency you should use bigger nodes but make sure you have anything",
    "start": "2448300",
    "end": "2454599"
  },
  {
    "text": "available you need first because sometimes eight like if you ask for two m4x cells they could actually be located",
    "start": "2454599",
    "end": "2461319"
  },
  {
    "text": "on the same machine so that's one of those dangers about availability and understanding where you can where you",
    "start": "2461319",
    "end": "2467349"
  },
  {
    "text": "should cut corners but so what are some of the easy things and hard things about",
    "start": "2467349",
    "end": "2472990"
  },
  {
    "text": "running carbonizing like in in a cloud native environment it's pretty easy to",
    "start": "2472990",
    "end": "2478119"
  },
  {
    "text": "change your instance times don't get tied to say oh I have these m floors and I like them or almost all the cloud",
    "start": "2478119",
    "end": "2486040"
  },
  {
    "text": "native environments you can swap you could swap out your instance types if you if you run out or decide that that",
    "start": "2486040",
    "end": "2491680"
  },
  {
    "text": "instance type is either too slow or it doesn't work for your application well those are relatively easy to change most",
    "start": "2491680",
    "end": "2497920"
  },
  {
    "text": "of the deployment and management tools allow you to to swap out different types of instances you might need to build a",
    "start": "2497920",
    "end": "2503170"
  },
  {
    "text": "new a my but it's not that bad and as I mentioned deploying applications onto kubernetes but the",
    "start": "2503170",
    "end": "2508900"
  },
  {
    "text": "most powerful thing about career days is from top to bottom it has very good api's whether you want to just send it",
    "start": "2508900",
    "end": "2515079"
  },
  {
    "text": "in a llamo text file and deploy or you want to build a Python or build a go client that that talks to the API",
    "start": "2515079",
    "end": "2522080"
  },
  {
    "text": "server and really fully orchestrates your system but all of the API is very good and they have a full path to",
    "start": "2522080",
    "end": "2529820"
  },
  {
    "text": "upgrade ability and manageability and finally I want to think of that I think was very successful for us was getting",
    "start": "2529820",
    "end": "2536030"
  },
  {
    "text": "our developers to understand the kubernetes environment and why and how workloads work and I think it's been a very big productivity and it's a skill",
    "start": "2536030",
    "end": "2542540"
  },
  {
    "text": "that they that understanding reliability and scalability it was good for them now the things that are hard for them it's",
    "start": "2542540",
    "end": "2549350"
  },
  {
    "text": "hard in the communities world is certain types of things like changing yours your network invert your network type that's",
    "start": "2549350",
    "end": "2557090"
  },
  {
    "text": "a dishes you should make very carefully we luckily chose the right one with our first production environment the",
    "start": "2557090",
    "end": "2562550"
  },
  {
    "text": "kubernetes the the ATS native routing but I've had to destroy clusters because",
    "start": "2562550",
    "end": "2568640"
  },
  {
    "text": "we decided the network the type we use which was weave or cube router it wasn't as as solid as the as our cube net",
    "start": "2568640",
    "end": "2577730"
  },
  {
    "text": "cluster and I mentioned talking about building scalable CI CD pipelines but",
    "start": "2577730",
    "end": "2584540"
  },
  {
    "text": "those are applications specific but you'll want to get the whole flow but it'll pay off when what you have the",
    "start": "2584540",
    "end": "2590780"
  },
  {
    "text": "reliability and through the your deployment pipeline the one one of the",
    "start": "2590780",
    "end": "2598670"
  },
  {
    "text": "challenges we had was trying to do the full auto scaling like we have I mentioned we lost 80% of a cluster with",
    "start": "2598670",
    "end": "2605540"
  },
  {
    "text": "auto scaling in spots if you're going to do that kind of workload that's fine I think it should be able to support it",
    "start": "2605540",
    "end": "2612440"
  },
  {
    "text": "but do it test it we've had problems with this the network scaling and that's",
    "start": "2612440",
    "end": "2618110"
  },
  {
    "text": "one of the biggest challenges if you add a hundred nodes to a cluster within three minutes and then tailor them it all down and you can do that 50 times",
    "start": "2618110",
    "end": "2623840"
  },
  {
    "text": "then your neck where it goes pretty solid the the cluster addition and subtraction is very stressful on the",
    "start": "2623840",
    "end": "2629270"
  },
  {
    "text": "network interfaces but the network technology and but tested because you",
    "start": "2629270",
    "end": "2634430"
  },
  {
    "text": "will potentially run into problems and I mentioned don't run a database in it I think it as long as you set your",
    "start": "2634430",
    "end": "2641540"
  },
  {
    "text": "expectations properly you can run a database but don't go crazy and log management it's just one of those things",
    "start": "2641540",
    "end": "2647120"
  },
  {
    "text": "we have I think that's a little bit more of a brain specific thing we just have a lot of logs alright sorry",
    "start": "2647120",
    "end": "2654439"
  },
  {
    "text": "finally this is my last slide and then we'll hand it back Ian sorry I'm running a little slow how would I compare eks to",
    "start": "2654439",
    "end": "2662449"
  },
  {
    "text": "various other kubernetes deployment methodologies eks is a fully managed kubernetes environment which is very",
    "start": "2662449",
    "end": "2668329"
  },
  {
    "text": "nice from the whole fully managed standpoint so they do a lot of things for you they take care of the control",
    "start": "2668329",
    "end": "2674119"
  },
  {
    "text": "plane they take care of the masters they take care of the xee those are all good its I would likely I'm most concerned",
    "start": "2674119",
    "end": "2681349"
  },
  {
    "text": "about the network so because that take that is affect your whole cluster",
    "start": "2681349",
    "end": "2687799"
  },
  {
    "text": "stability like individual nodes they're stateless I don't care I tear them down all the time but if your network gets",
    "start": "2687799",
    "end": "2692809"
  },
  {
    "text": "unstable then it's very very challenging so I like it for the 80s CNI V PC and I",
    "start": "2692809",
    "end": "2698389"
  },
  {
    "text": "like it for the manage control plane but conversely it's still relatively new you",
    "start": "2698389",
    "end": "2704059"
  },
  {
    "text": "don't get a lot of the the new the newer features because they don't run the very latest versions of kubernetes and you",
    "start": "2704059",
    "end": "2710719"
  },
  {
    "text": "don't get you don't get a lot of choices around certain types of things like the",
    "start": "2710719",
    "end": "2715879"
  },
  {
    "text": "network which is good from the standpoint as long as they're taking care for you you'll you don't have to worry about it",
    "start": "2715879",
    "end": "2722779"
  },
  {
    "text": "so I'm we haven't actually deployed production chaos clusters but I'm I'm thinking in the next iteration that we",
    "start": "2722779",
    "end": "2729289"
  },
  {
    "text": "will because we started relatively early before eks became a thing but now I think it's it's almost solid enough that",
    "start": "2729289",
    "end": "2734419"
  },
  {
    "text": "will be joining was that great awesome so hubert talked a lot about how to",
    "start": "2734419",
    "end": "2741409"
  },
  {
    "text": "leverage kubernetes how to set it up some of the flexibility I'm going to kind of go to the other side of the",
    "start": "2741409",
    "end": "2746689"
  },
  {
    "text": "equation I'm the guy that has to pay the bill at the end of the day so I'm going to talk about what that looks like for my side some of the strategies that",
    "start": "2746689",
    "end": "2752569"
  },
  {
    "text": "we've taken and some of the long conversations that I've had with Hubert when designing and architecting these",
    "start": "2752569",
    "end": "2757789"
  },
  {
    "text": "clusters so the first thing that I'll mention it independent of kubernetes is",
    "start": "2757789",
    "end": "2762889"
  },
  {
    "text": "just the ec2 pricing model hubert alluded to it earlier on but the tip the",
    "start": "2762889",
    "end": "2768439"
  },
  {
    "text": "typical model is the on demand where you're paying I think it's billed by the second but let's just for this example use the per",
    "start": "2768439",
    "end": "2775129"
  },
  {
    "text": "hour price I picked a very standard m4x large instance we probably have several",
    "start": "2775129",
    "end": "2780769"
  },
  {
    "text": "hundred of them running in our infrastructure that's simple unit has four V CPUs 16 gigs of memory",
    "start": "2780769",
    "end": "2787400"
  },
  {
    "text": "and pricing according to u.s. West one I pulled these numbers down today per hour",
    "start": "2787400",
    "end": "2793500"
  },
  {
    "text": "you're looking at about 23 cents per hour which is pretty good our eyes are",
    "start": "2793500",
    "end": "2798900"
  },
  {
    "text": "reserved instance is a methodology that we use where you can pre-purchase the",
    "start": "2798900",
    "end": "2803970"
  },
  {
    "text": "instance for one year or a three-year term and if you do that for one year the",
    "start": "2803970",
    "end": "2809550"
  },
  {
    "text": "price drops down to about fifteen cents an hour and if you purchase it for three years so you're committing to use that",
    "start": "2809550",
    "end": "2814830"
  },
  {
    "text": "instance for three years the price for will drop down to about ten cents and then the last methodology for purchasing",
    "start": "2814830",
    "end": "2821340"
  },
  {
    "text": "instances is spot instances if you're not familiar with that I know hubert mentioned it several times Amazon",
    "start": "2821340",
    "end": "2827550"
  },
  {
    "text": "provides a effectively elastic marketplace of spot instances that are",
    "start": "2827550",
    "end": "2832680"
  },
  {
    "text": "available to you but they don't have the same guarantees of availability in that you may get preempted and warned that",
    "start": "2832680",
    "end": "2838500"
  },
  {
    "text": "the node will disappear in a minute get off of the node and then they take it back",
    "start": "2838500",
    "end": "2843690"
  },
  {
    "text": "but those spots come with the upside of price we've gotten it down all the way",
    "start": "2843690",
    "end": "2848850"
  },
  {
    "text": "to six cents per hour so you can see a huge price differential between these different purchase options so if we look",
    "start": "2848850",
    "end": "2857340"
  },
  {
    "text": "at our and this is actually I pulled this from our last board board meeting so these are like legit slides - I think",
    "start": "2857340",
    "end": "2863430"
  },
  {
    "text": "I took away some of the prices you can see that we're spending a huge amount on ec2 and when I so some of the other",
    "start": "2863430",
    "end": "2871830"
  },
  {
    "text": "services here our CDN usage we use s3 quite a lot and then there's a bunch of other AWS services that we use but",
    "start": "2871830",
    "end": "2878700"
  },
  {
    "text": "whenever I talk about cost modeling and cost strategies I always like asking folks to look at what their biggest",
    "start": "2878700",
    "end": "2885240"
  },
  {
    "text": "costs are and for us it's very clear that ec2 and just pure compute is where",
    "start": "2885240",
    "end": "2891000"
  },
  {
    "text": "we're spending most of the money so this is where we should be spending most of our time optimizing our costs if you're",
    "start": "2891000",
    "end": "2898860"
  },
  {
    "text": "responsible for managing a large AWS bill like me this is probably a pretty familiar UI if not this is Amazon's cost",
    "start": "2898860",
    "end": "2906780"
  },
  {
    "text": "Explorer tool I blurred out like the y-axis in terms of how much we're spending maybe we'll talk about that",
    "start": "2906780",
    "end": "2913470"
  },
  {
    "text": "privately after this talk but I think I left yeah if I think that if you have it reduced it",
    "start": "2913470",
    "end": "2920460"
  },
  {
    "text": "down to cost per millions I yeah I hope that none of you have to deal with that",
    "start": "2920460",
    "end": "2925590"
  },
  {
    "text": "but it's a very interesting challenge and you know come talk to me later on and we can talk about our strategies here but this is a view that I've set up",
    "start": "2925590",
    "end": "2932640"
  },
  {
    "text": "and I found to be extremely effective in the very top left you can see well you",
    "start": "2932640",
    "end": "2938040"
  },
  {
    "text": "probably can't see it but I've been able to do a group buy the purchase option and then the three different color codes",
    "start": "2938040",
    "end": "2944820"
  },
  {
    "text": "here our purchase option by spot purchase option buy on demand and",
    "start": "2944820",
    "end": "2950160"
  },
  {
    "text": "purchase option by our eyes there's actually a fourth color for unused our eyes but we have 100% utilization so",
    "start": "2950160",
    "end": "2956520"
  },
  {
    "text": "this is the way that I make sure that our pricing as well as our purchase options is being well managed and along",
    "start": "2956520",
    "end": "2963570"
  },
  {
    "text": "the right side again if you're a nerd that spends a lot of time in a cost Explorer like me some of the other tips",
    "start": "2963570",
    "end": "2970560"
  },
  {
    "text": "that I'd have is when you enable a filter on ec2 and also you filter the",
    "start": "2970560",
    "end": "2975870"
  },
  {
    "text": "usage type by running usage you'll also get that secondary graph at the bottom which shows the compute hours per month",
    "start": "2975870",
    "end": "2984560"
  },
  {
    "text": "juxtaposed to the costs and you'll you'll be able to download this",
    "start": "2984560",
    "end": "2990270"
  },
  {
    "text": "information important to spreadsheets and do whatever kind of analysis that you want but I use these views to both",
    "start": "2990270",
    "end": "2995460"
  },
  {
    "text": "look at what our costs look like month over month but also look at the distribution of the usage in terms of",
    "start": "2995460",
    "end": "3001100"
  },
  {
    "text": "CPU cycles to get a good sense of what's going on lastly the very bottom error I",
    "start": "3001100",
    "end": "3007610"
  },
  {
    "text": "pointed to is a feature that the cost Explorer team so kudos to them added in recent months where you can also show",
    "start": "3007610",
    "end": "3013940"
  },
  {
    "text": "the amortized blended costs so if you are doing one-year reservations or three-year reservations the amortized",
    "start": "3013940",
    "end": "3020150"
  },
  {
    "text": "cost of one twenty-fourth or 112 for 136 will automatically get blended into these so that you can actually have",
    "start": "3020150",
    "end": "3026000"
  },
  {
    "text": "month-over-month accounting diving in a little bit more and sharing kind of",
    "start": "3026000",
    "end": "3032210"
  },
  {
    "text": "what's going on behind the scenes of our infrastructure the graph on the left is how we visualize all of our ec2 usage we",
    "start": "3032210",
    "end": "3040880"
  },
  {
    "text": "leverage the tagging system on ec2 so I can create these split charts to see what kind of workloads are we actually",
    "start": "3040880",
    "end": "3046730"
  },
  {
    "text": "spending money on I really like seeing the the blue so both mezzos and kubernetes we're using",
    "start": "3046730",
    "end": "3053180"
  },
  {
    "text": "heavily mezzos we're using for some of our data loads which could be another talk at a different time and then we see",
    "start": "3053180",
    "end": "3060080"
  },
  {
    "text": "that huge chunk designated to kubernetes and on the left side of that chart we have other infrastructure as hubert",
    "start": "3060080",
    "end": "3065599"
  },
  {
    "text": "mentioned we've elected to keep out of our kubernetes cluster like our high availability key value database HDFS",
    "start": "3065599",
    "end": "3072020"
  },
  {
    "text": "some of our analytic systems Kafka and some other core infrastructure on the",
    "start": "3072020",
    "end": "3077990"
  },
  {
    "text": "right is a chart that I derived by exporting the previous slides information where I'm able to visualize",
    "start": "3077990",
    "end": "3083540"
  },
  {
    "text": "point in time what's the distribution of our workloads so this was plotting the",
    "start": "3083540",
    "end": "3088700"
  },
  {
    "text": "actual CPU cycles by how they were purchased and this is a chart that I always like to keep my eye on in that I",
    "start": "3088700",
    "end": "3094430"
  },
  {
    "text": "want to make sure that we have a good chunk of our eyes or reserved instances because a lot of our kubernetes clusters",
    "start": "3094430",
    "end": "3100040"
  },
  {
    "text": "we know are always going to be at least let's say 100 to 200 nodes we have a pretty good chunk of spot instances",
    "start": "3100040",
    "end": "3105950"
  },
  {
    "text": "which again Huber described we can do that automatic scalability so if at 1:00",
    "start": "3105950",
    "end": "3111020"
  },
  {
    "text": "in the morning I needed to provision 10 more machines we'll pull them from the spot market we'll be paying what like",
    "start": "3111020",
    "end": "3117140"
  },
  {
    "text": "six seven cents an hour and then they'll get added to the cluster and then when we don't need them anymore we can scale",
    "start": "3117140",
    "end": "3122450"
  },
  {
    "text": "them down and then we also have some amount of on-demand I wouldn't recommend doing a hundred",
    "start": "3122450",
    "end": "3128119"
  },
  {
    "text": "percent our eyes because again sometimes your workloads will go up and down and in fact as I alluded to earlier on a day",
    "start": "3128119",
    "end": "3134390"
  },
  {
    "text": "over day basis our workloads and our clusters grow and shrink automatically depending on the traffic to our platform",
    "start": "3134390",
    "end": "3140210"
  },
  {
    "text": "so I think one of the really great",
    "start": "3140210",
    "end": "3145940"
  },
  {
    "text": "concepts that we are able to leverage because of kubernetes is this idea of a",
    "start": "3145940",
    "end": "3153020"
  },
  {
    "text": "general compute platform so for the developers they just see this platform that says let's say 1200 cores but under",
    "start": "3153020",
    "end": "3160910"
  },
  {
    "text": "the hood it's actually a heterogeneous compute pool and that we have nodes of",
    "start": "3160910",
    "end": "3166099"
  },
  {
    "text": "various different sizes of various different instance classes we have M floors we have C floors we have C fives",
    "start": "3166099",
    "end": "3171950"
  },
  {
    "text": "and we have a bunch of other instances this is really great from a provisioning perspective this gives you a path to",
    "start": "3171950",
    "end": "3178099"
  },
  {
    "text": "upgrading family instance types so let's say that I did one-year reservation of M fours and then",
    "start": "3178099",
    "end": "3184430"
  },
  {
    "text": "Amazon announces that they have these really amazing m5 I don't have to think oh my gosh how am I going to move all my",
    "start": "3184430",
    "end": "3190279"
  },
  {
    "text": "workloads from one to the other we just throw them all into the kubernetes cluster and then the developers don't even know that's happening underneath",
    "start": "3190279",
    "end": "3195920"
  },
  {
    "text": "there they're their feet this has been also really helpful because we are using",
    "start": "3195920",
    "end": "3201140"
  },
  {
    "text": "spot instances you know the spot instance market is kind of like this game system where maybe we can't find",
    "start": "3201140",
    "end": "3207739"
  },
  {
    "text": "any m4s in the spot market but we can find a ton of m5s or a ton of C fives we",
    "start": "3207739",
    "end": "3212960"
  },
  {
    "text": "can add those to the cluster and we get the nodes that we need at a really great price great so we're coming up on just",
    "start": "3212960",
    "end": "3220519"
  },
  {
    "text": "two minutes left I wanted to summarize a couple things and go over some of the",
    "start": "3220519",
    "end": "3226369"
  },
  {
    "text": "key challenges that we talked about at the beginning so the first challenge that we described we wanted to to have a",
    "start": "3226369",
    "end": "3232460"
  },
  {
    "text": "solution to was how do we solve this general compute problem how do we decouple the developer's needs from",
    "start": "3232460",
    "end": "3239539"
  },
  {
    "text": "infrastructure and operations needs and we achieve this with docker with kubernetes and our auto scaling and then",
    "start": "3239539",
    "end": "3246349"
  },
  {
    "text": "how do we manage our costs in this environment I just described how we leverage a blend of on demands spots as",
    "start": "3246349",
    "end": "3254569"
  },
  {
    "text": "well as reserved instances so going back to that first high-level architecture",
    "start": "3254569",
    "end": "3260630"
  },
  {
    "text": "that I showed what we've been able to achieve at branch and this is how we've",
    "start": "3260630",
    "end": "3265640"
  },
  {
    "text": "really scaled both in terms of the scale of the infrastructure but as well as the scale of the costs at the very top the",
    "start": "3265640",
    "end": "3272299"
  },
  {
    "text": "developer's concerns are all being met because they can deploy a variety of different workloads and applications",
    "start": "3272299",
    "end": "3278059"
  },
  {
    "text": "into production we have JavaScript developers Python developers Java developers each one of those",
    "start": "3278059",
    "end": "3283369"
  },
  {
    "text": "applications might require a small or a very large footprint we have a very various different kubernetes production",
    "start": "3283369",
    "end": "3290329"
  },
  {
    "text": "clusters that offer these cores so that they can satisfy the developer's needs and on a day to day basis when our",
    "start": "3290329",
    "end": "3296029"
  },
  {
    "text": "developers say hey I thought I needed 300 cores I actually need 350 they don't",
    "start": "3296029",
    "end": "3301519"
  },
  {
    "text": "even really need to interact or ask the infrastructure team from a capacity planning and capacity management",
    "start": "3301519",
    "end": "3307130"
  },
  {
    "text": "perspective this is all within their control and then again we've separated",
    "start": "3307130",
    "end": "3312259"
  },
  {
    "text": "that core compute platform from the capacity and kind of price modeling",
    "start": "3312259",
    "end": "3318140"
  },
  {
    "text": "perspective so at the very bottom you know I spend a lot of team working and modeling with our finance team and",
    "start": "3318140",
    "end": "3323690"
  },
  {
    "text": "they're very aware of on demands they're very aware of our eyes but they have no idea what ten core",
    "start": "3323690",
    "end": "3330020"
  },
  {
    "text": "nodejs application is going to cost and they don't really care and realistically they shouldn't so we've created these",
    "start": "3330020",
    "end": "3336110"
  },
  {
    "text": "kind of three layers of abstraction which allows each functional group within the organization to be successful",
    "start": "3336110",
    "end": "3342680"
  },
  {
    "text": "and optimized within that particular domain great so that concludes the talk",
    "start": "3342680",
    "end": "3349220"
  },
  {
    "text": "I think we're gonna go to questions in this this app and then we'll take some",
    "start": "3349220",
    "end": "3355190"
  },
  {
    "text": "questions from the floor afterwards but before you do that though just wanted to thank you all for your undivided attention and it was a great pleasure to",
    "start": "3355190",
    "end": "3361730"
  },
  {
    "text": "be here Cheers",
    "start": "3361730",
    "end": "3364630"
  },
  {
    "text": "okay so the question was do periodically rebalance pods to restore a somewhat",
    "start": "3367360",
    "end": "3373460"
  },
  {
    "text": "even distribution of them across the worker nodes if you do how do you do it",
    "start": "3373460",
    "end": "3379960"
  },
  {
    "text": "we don't actually have to do that generally there is a project called the D scheduler or the which tries to do",
    "start": "3379960",
    "end": "3386930"
  },
  {
    "text": "that but the reality is when you have a hundred nodes there's probably the balance is probably not going to get",
    "start": "3386930",
    "end": "3392930"
  },
  {
    "text": "much better or worse when you do if you try and rebalance it so not that much",
    "start": "3392930",
    "end": "3398830"
  },
  {
    "text": "cool oh you don't want to do it by popularity I mean great cool second",
    "start": "3398830",
    "end": "3409130"
  },
  {
    "text": "question was are you running your own kubernetes on ec2 we're using ECS or dks",
    "start": "3409130",
    "end": "3414520"
  },
  {
    "text": "we run our own kubernetes on ec2 or looking at any caste we'll probably do some of those and I think Hubert",
    "start": "3414520",
    "end": "3421790"
  },
  {
    "text": "mentioned it earlier on we were running kubernetes and production about four years ago before eks was a thing I know",
    "start": "3421790",
    "end": "3430430"
  },
  {
    "text": "ECS wasn't offering that we looked at but we've been very happy with our",
    "start": "3430430",
    "end": "3435820"
  },
  {
    "text": "management of kubernetes right now and one of the other things that kubernetes",
    "start": "3435820",
    "end": "3441650"
  },
  {
    "text": "gives us it's sort of clouded Gnostic capabilities so for flexibility now we could deploy communities into GCP of",
    "start": "3441650",
    "end": "3448340"
  },
  {
    "text": "call they have probably stronger career night he's offering than AWS and also if we",
    "start": "3448340",
    "end": "3454780"
  },
  {
    "text": "were ever to go into Azure or some of the other smaller platforms we could kubernetes gives us an open platform to",
    "start": "3454780",
    "end": "3460840"
  },
  {
    "text": "be able to do that so there that was one of the strong considerations when we chose kubernetes over ACS next question",
    "start": "3460840",
    "end": "3469810"
  },
  {
    "text": "is which programming languages did you use for developing micro services so at branch are two primary first class",
    "start": "3469810",
    "end": "3476350"
  },
  {
    "text": "languages are JavaScript and Java the original branch core application was a",
    "start": "3476350",
    "end": "3483640"
  },
  {
    "text": "gigantic node.js application and then we started carving it out into JavaScript micro services then we started building",
    "start": "3483640",
    "end": "3491130"
  },
  {
    "text": "restful Java services we also have some",
    "start": "3491130",
    "end": "3496270"
  },
  {
    "text": "piping services in production we have quite a lot of Lua and production as well but again using docker and",
    "start": "3496270",
    "end": "3503950"
  },
  {
    "text": "deploying the kubernetes for the most part operations is agnostic to what",
    "start": "3503950",
    "end": "3509440"
  },
  {
    "text": "languages our developers are writing them in next question is do you use vine",
    "start": "3509440",
    "end": "3515710"
  },
  {
    "text": "Linux for your containers we don't generally build Alpine Linux containers we like third parties tended to do that",
    "start": "3515710",
    "end": "3522030"
  },
  {
    "text": "it's ready now pine is something that an optimized workload might do Fergus",
    "start": "3522030",
    "end": "3527320"
  },
  {
    "text": "extremely small memory or CPU footprint that hasn't been a primary concern for",
    "start": "3527320",
    "end": "3533560"
  },
  {
    "text": "us we tend to like developer tools so we haven't optimized for it and I could see us doing it in the future for",
    "start": "3533560",
    "end": "3539050"
  },
  {
    "text": "security but right now we have so next question if ec2 is such a large part of",
    "start": "3539050",
    "end": "3546520"
  },
  {
    "text": "your AWS bill what are you doing for databases running them locally on ec2",
    "start": "3546520",
    "end": "3552430"
  },
  {
    "text": "instances so yeah easy easy to is a pretty big chunk of our bill we do use",
    "start": "3552430",
    "end": "3558000"
  },
  {
    "text": "Amazon's RDS for things like Postgres when I showed that split of our overall",
    "start": "3558000",
    "end": "3564300"
  },
  {
    "text": "bill about I think let's say 70% of it was ec2 and then when we dove into",
    "start": "3564300",
    "end": "3571440"
  },
  {
    "text": "where's that easy to spend going half of it was to orchestration frameworks like",
    "start": "3571440",
    "end": "3576700"
  },
  {
    "text": "mezzos and kubernetes and then the other half was designated to things like druid",
    "start": "3576700",
    "end": "3581920"
  },
  {
    "text": "which are calmer and analytics database Kafka which we're using comprehensively throughout our infrastructure and then",
    "start": "3581920",
    "end": "3588410"
  },
  {
    "text": "we have a combination of aerospike which is a extremely high performance key",
    "start": "3588410",
    "end": "3594440"
  },
  {
    "text": "value database as well as dynamodb and we actually were here about two months ago and we did a talk about our usage of",
    "start": "3594440",
    "end": "3601700"
  },
  {
    "text": "dynamo DB so you can check out that talk as well the next question is interested",
    "start": "3601700",
    "end": "3607490"
  },
  {
    "text": "interested to learn during your talk if you're using AWS at mesh and if not what",
    "start": "3607490",
    "end": "3613369"
  },
  {
    "text": "are you doing for service mesh to link micro services we're not using it at mesh it's brand new so we haven't yet",
    "start": "3613369",
    "end": "3619700"
  },
  {
    "text": "tested it service mesh is one of those things that's very high on my list of things to do I have tested is to you it",
    "start": "3619700",
    "end": "3626720"
  },
  {
    "text": "was more than a year ago and it was a little rough so I didn't feel like putting it into production but I think now it's it's made enough progress the",
    "start": "3626720",
    "end": "3633530"
  },
  {
    "text": "other the other consideration is I'm looking for a solution which runs not just in kubernetes because we have a",
    "start": "3633530",
    "end": "3639470"
  },
  {
    "text": "large non-korean IT infrastructure as well so something a little bit more generic it's do is great now for within",
    "start": "3639470",
    "end": "3646010"
  },
  {
    "text": "a cluster but we need something that provides both multi cluster and non community support so that's one of those investigative areas likely we'll choose",
    "start": "3646010",
    "end": "3652940"
  },
  {
    "text": "something like console or at mesh is is it a consideration or we could also use",
    "start": "3652940",
    "end": "3658609"
  },
  {
    "text": "envoy directly next question is do you have dr for eks across multiple regions",
    "start": "3658609",
    "end": "3664550"
  },
  {
    "text": "if yes how do you achieve that so as huber mentioned we're not directly",
    "start": "3664550",
    "end": "3670040"
  },
  {
    "text": "using eks right now we deploy in manager on kubernetes clusters we don't deploy",
    "start": "3670040",
    "end": "3676460"
  },
  {
    "text": "those clusters to span multiple regions that would potentially introduce you",
    "start": "3676460",
    "end": "3681770"
  },
  {
    "text": "know quite a lot of potential latency and network transfer concerns although we do have a dr kubernetes cluster",
    "start": "3681770",
    "end": "3687530"
  },
  {
    "text": "running in our failover region and us East one but currently we have all of",
    "start": "3687530",
    "end": "3692570"
  },
  {
    "text": "our primary production clusters running within our primary us les one region I'm",
    "start": "3692570",
    "end": "3698390"
  },
  {
    "text": "actually not too familiar with setting up PKS across multiple regions but that would be an interesting experiment to",
    "start": "3698390",
    "end": "3704869"
  },
  {
    "text": "hack on what tools do you use for monitoring kubernetes itself primarily",
    "start": "3704869",
    "end": "3710900"
  },
  {
    "text": "everybody everybody in the communities world uses Prometheus and we've adopted that it took us a while to get it stable but",
    "start": "3710900",
    "end": "3716910"
  },
  {
    "text": "it's actually very very scalable in a highly dynamic environments it provides a lot of features around service",
    "start": "3716910",
    "end": "3722369"
  },
  {
    "text": "discovery that are really hard to make to replicate in other environments so I strongly encourage everybody to look at",
    "start": "3722369",
    "end": "3728520"
  },
  {
    "text": "the architecture Prometheus's it's pretty good cool this question I think came up",
    "start": "3728520",
    "end": "3736020"
  },
  {
    "text": "earlier too but if you run your own kubernetes rather than eks why why not use AWS eks service so huber mentioned",
    "start": "3736020",
    "end": "3744240"
  },
  {
    "text": "earlier it is something that we are going to investigate and evaluate it did not exist when we started using",
    "start": "3744240",
    "end": "3749670"
  },
  {
    "text": "kubernetes we were actually I think this was like three years ago when our office was down in Palo Alto we worked pretty",
    "start": "3749670",
    "end": "3755880"
  },
  {
    "text": "closely with Google and the folks that were developing kubernetes at the time and they were excited that we were deploying this to production and I think",
    "start": "3755880",
    "end": "3763500"
  },
  {
    "text": "with the developments that have been made with AWS as eks this is definitely",
    "start": "3763500",
    "end": "3769109"
  },
  {
    "text": "something that we're going to explore do you have any experience with AWS cops",
    "start": "3769109",
    "end": "3774630"
  },
  {
    "text": "can you elaborate the choice between eks versus cops so as we mentioned eks",
    "start": "3774630",
    "end": "3782940"
  },
  {
    "text": "wasn't the thing when we started it was cops that was all and we still deploy with cops cops is good it has better",
    "start": "3782940",
    "end": "3789690"
  },
  {
    "text": "flexibility better control if you want that if you want to not worry about it",
    "start": "3789690",
    "end": "3795000"
  },
  {
    "text": "you can't is probably better if you want more managed ich then you cast gives you",
    "start": "3795000",
    "end": "3801690"
  },
  {
    "text": "better you don't have to worry about as much but if you need certain features like if you don't want to run the very",
    "start": "3801690",
    "end": "3807990"
  },
  {
    "text": "latest version of kubernetes or actually cops doesn't provide the very latest either but if you want to run like",
    "start": "3807990",
    "end": "3813600"
  },
  {
    "text": "custom code inside the control plane or want to provide other types of CNI",
    "start": "3813600",
    "end": "3820500"
  },
  {
    "text": "network interfaces then copses is probably the primary choice I use a nativist next question is do you use the",
    "start": "3820500",
    "end": "3828420"
  },
  {
    "text": "upstream or and/or custom DNS for servers not resolvable by kubernetes own DNS so kubernetes runs its own internal",
    "start": "3828420",
    "end": "3837359"
  },
  {
    "text": "DNS and then it forwards to the external yes which by default in Anna's on is the",
    "start": "3837359",
    "end": "3842910"
  },
  {
    "text": "Amazon DNS and that's the standard and we use that so we don't all the hosts",
    "start": "3842910",
    "end": "3848100"
  },
  {
    "text": "inside he's just resolved they try to rise it resolve within the cluster and then when they don't they were try to resolve",
    "start": "3848100",
    "end": "3853320"
  },
  {
    "text": "through and that's fine so on costs the next question is did you",
    "start": "3853320",
    "end": "3858420"
  },
  {
    "text": "calculate your man our costs salary and benefits to run kubernetes versus using",
    "start": "3858420",
    "end": "3863520"
  },
  {
    "text": "a managed kubernetes service a lot of eks questions yes I have done these models before it is certainly going to",
    "start": "3863520",
    "end": "3870599"
  },
  {
    "text": "factor into our decision to consider eks one of the challenges is I don't believe",
    "start": "3870599",
    "end": "3877829"
  },
  {
    "text": "eks is available in every region yet but that will definitely factor in I mean if it's not available in the region that we",
    "start": "3877829",
    "end": "3883560"
  },
  {
    "text": "need it that would be a blocker but absolutely now that a lot of these managed services like eks and managed",
    "start": "3883560",
    "end": "3890160"
  },
  {
    "text": "kafka for instance have come up it's certainly one of the considerations that",
    "start": "3890160",
    "end": "3895349"
  },
  {
    "text": "comes comes onto the table now mind you the eks service isn't necessarily going",
    "start": "3895349",
    "end": "3901710"
  },
  {
    "text": "to be at the same price point as a hyper optimized kubernetes cluster running on spot instances so there are some",
    "start": "3901710",
    "end": "3908369"
  },
  {
    "text": "trade-offs there that have to go into that calculus as well next question is",
    "start": "3908369",
    "end": "3915300"
  },
  {
    "text": "what is your ratio of developers to DevOps so we have a relatively small and",
    "start": "3915300",
    "end": "3922800"
  },
  {
    "text": "lean infrastructure and operations team it's effectively our DevOps team so with",
    "start": "3922800",
    "end": "3929250"
  },
  {
    "text": "about 75 engineers we have seven seven so it's about ten to one right now and I",
    "start": "3929250",
    "end": "3936810"
  },
  {
    "text": "would definitely believe that the functionality and some of the",
    "start": "3936810",
    "end": "3942089"
  },
  {
    "text": "capabilities that we've been afforded with things like kubernetes has helped us keep that ratio it's also worth",
    "start": "3942089",
    "end": "3948869"
  },
  {
    "text": "mentioning and repeating what hubert mentioned the developers are all like super pumped and jived about using",
    "start": "3948869",
    "end": "3955290"
  },
  {
    "text": "kubernetes they're managing a lot of their own services they're taking care of a lot of their own services they're",
    "start": "3955290",
    "end": "3960599"
  },
  {
    "text": "provisioning and scaling their own services which makes our lives a lot easier but that's like a huge benefit to",
    "start": "3960599",
    "end": "3967170"
  },
  {
    "text": "let's say in a different world or in a different environment it would be very unlikely that somebody that's managing",
    "start": "3967170",
    "end": "3972810"
  },
  {
    "text": "let's say a 50 core node app to necessarily provision their capacity and scale it out by themselves",
    "start": "3972810",
    "end": "3981050"
  },
  {
    "text": "does spark next question is the spark jobs or do spark jobs run well on",
    "start": "3981050",
    "end": "3986790"
  },
  {
    "text": "kubernetes so we do run spark in kubernetes it's moderately it's pretty successful from the standpoint of just",
    "start": "3986790",
    "end": "3994440"
  },
  {
    "text": "straight compute on top of instances the areas where I would caution about it was",
    "start": "3994440",
    "end": "4000500"
  },
  {
    "text": "so if you have spark jobs that talk directly to storage like you you",
    "start": "4000500",
    "end": "4005780"
  },
  {
    "text": "typically run spark on your yard on top of HDFS like that's a little bit dicey I",
    "start": "4005780",
    "end": "4012260"
  },
  {
    "text": "probably wouldn't do that our spark jobs are typically reading from like an s3 or something on external storage so if you",
    "start": "4012260",
    "end": "4020210"
  },
  {
    "text": "need to if you need high-performance to co-locate your your compute on top of your storage like they do in many spark",
    "start": "4020210",
    "end": "4026210"
  },
  {
    "text": "environments it might not be appropriate there is new native kubernetes support that does that we don't run that we were",
    "start": "4026210",
    "end": "4032870"
  },
  {
    "text": "essentially run spark stand-alone clusters inside kubernetes which works fine with the caveat that I just and I",
    "start": "4032870",
    "end": "4038810"
  },
  {
    "text": "think we have time for like two or three more questions before they kick us off the stage so if we don't get to your question will lurk I think we're gonna",
    "start": "4038810",
    "end": "4044630"
  },
  {
    "text": "hang around for a bit we we'd be happy to answer them but I'll dive into this I keep getting flashed like a sign back there like okay",
    "start": "4044630",
    "end": "4052820"
  },
  {
    "text": "next question is how are you hosting your images we have our own docker repo that we host on an ec2 ec2 instances and",
    "start": "4052820",
    "end": "4060140"
  },
  {
    "text": "it works fine it's just a docker registry running inside docker not inside kubernetes I'm we have too many",
    "start": "4060140",
    "end": "4066260"
  },
  {
    "text": "clusters so I don't really want to run karinna the docker registry inside the kubernetes but if some people doing I've",
    "start": "4066260",
    "end": "4073040"
  },
  {
    "text": "heard success stories with it I don't do ml jobs using tensor flow or run well on",
    "start": "4073040",
    "end": "4080390"
  },
  {
    "text": "kubernetes yeah we're like this this is",
    "start": "4080390",
    "end": "4088160"
  },
  {
    "text": "the startup talk where we don't say machine learning and we don't do any crazy AI or blockchain you know it's just crazy scalable infrastructure sorry",
    "start": "4088160",
    "end": "4094880"
  },
  {
    "text": "guys okay you talk more about network issues you've seen and how your",
    "start": "4094880",
    "end": "4100400"
  },
  {
    "text": "networking is set up VPC for all cluster or per cluster etc we so we use we",
    "start": "4100400",
    "end": "4109130"
  },
  {
    "text": "started out using the default configuration was a new DPC per cluster but then the network",
    "start": "4109130",
    "end": "4116609"
  },
  {
    "text": "transfer costs are pretty daunting actually so we're considering moving with some of our network back into our",
    "start": "4116609",
    "end": "4122190"
  },
  {
    "text": "default our standard V PC so it's one of those costs we actually do care a little",
    "start": "4122190",
    "end": "4127920"
  },
  {
    "text": "bit about because we're doing some so many analytics types of workloads pulling from Kafka all those things add",
    "start": "4127920",
    "end": "4133140"
  },
  {
    "text": "up not just to compute which is doesn't matter what networking is but the",
    "start": "4133140",
    "end": "4138390"
  },
  {
    "text": "network transfer cost does add up so we've been migrating some of our workloads back into our our primary VP",
    "start": "4138390",
    "end": "4146278"
  },
  {
    "text": "C's do you use any specific tools when it comes to infrastructure as code like",
    "start": "4146279",
    "end": "4152338"
  },
  {
    "text": "terraformer home we haven't used how much we've looked at it we may in the future use it a lot of the",
    "start": "4152339",
    "end": "4159270"
  },
  {
    "text": "infrastructure we've built is four years old and I would like to get rid of it but at the time we built it we didn't",
    "start": "4159270",
    "end": "4164488"
  },
  {
    "text": "have the the toy really wasn't there so a lot of its handcrafted and you could use an update so terraform is another",
    "start": "4164489",
    "end": "4171859"
  },
  {
    "text": "similarly that there was not really terraform support but nowadays if you were to build a cops cluster or ability",
    "start": "4171859",
    "end": "4177179"
  },
  {
    "text": "aks cluster or build a network you could terraform all of that but at the time we started they those tool sets around",
    "start": "4177179",
    "end": "4184409"
  },
  {
    "text": "kubernetes infrastructure burner metal and I'm going to keep going until they kick us off but if you have to get out",
    "start": "4184409",
    "end": "4190528"
  },
  {
    "text": "here just by all means just leave so how do you handle spot instances being ripped from your arms so we should be",
    "start": "4190529",
    "end": "4197790"
  },
  {
    "text": "like a whole talk yeah so the primary thing is to make your app stateless so",
    "start": "4197790",
    "end": "4204350"
  },
  {
    "text": "spawn instance dies just spins up somewhere else the secondary things are you can force",
    "start": "4204350",
    "end": "4211350"
  },
  {
    "text": "scheduling on to on-demand instances so there's primitives around that so on demands won't get taken away you never",
    "start": "4211350",
    "end": "4216900"
  },
  {
    "text": "have to worry for critical workloads in high SLA type of environment clusters will do that we have we will either put",
    "start": "4216900",
    "end": "4224219"
  },
  {
    "text": "you in a high SLA cluster which we use all on demands and say you'll never get rescheduled unless your application does",
    "start": "4224219",
    "end": "4229500"
  },
  {
    "text": "it or for other types of workloads like if it's a spark job we're relying on you",
    "start": "4229500",
    "end": "4235440"
  },
  {
    "text": "to build a resilient application such that you lose a spot it is generally unaffected and",
    "start": "4235440",
    "end": "4242010"
  },
  {
    "text": "we're officially getting the time so once again thank you all so much for attending our talk it was a pleasure and",
    "start": "4242010",
    "end": "4247770"
  },
  {
    "text": "we'll hang out [Applause] [Music]",
    "start": "4247770",
    "end": "4262199"
  }
]
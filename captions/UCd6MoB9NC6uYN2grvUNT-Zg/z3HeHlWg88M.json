[
  {
    "start": "0",
    "end": "17000"
  },
  {
    "text": "[Music]",
    "start": "430",
    "end": "4430"
  },
  {
    "text": "hi i'm jane from amazon web services",
    "start": "6170",
    "end": "8960"
  },
  {
    "text": "today i'm going to walk you through how",
    "start": "8960",
    "end": "11160"
  },
  {
    "text": "to use AWS glue to create an ETL job to",
    "start": "11160",
    "end": "14519"
  },
  {
    "text": "transform data from one format to",
    "start": "14519",
    "end": "16139"
  },
  {
    "text": "another AWS glue is a fully managed ETL",
    "start": "16139",
    "end": "20070"
  },
  {
    "start": "17000",
    "end": "102000"
  },
  {
    "text": "extract transform and load service that",
    "start": "20070",
    "end": "23430"
  },
  {
    "text": "makes it simple and cost-effective to",
    "start": "23430",
    "end": "25320"
  },
  {
    "text": "categorize your data clean it and rich",
    "start": "25320",
    "end": "27630"
  },
  {
    "text": "it and move it reliably between various",
    "start": "27630",
    "end": "29670"
  },
  {
    "text": "data stores it infers the schema of your",
    "start": "29670",
    "end": "32910"
  },
  {
    "text": "semi structured and structured data glue",
    "start": "32910",
    "end": "36180"
  },
  {
    "text": "will help you understand your data",
    "start": "36180",
    "end": "37530"
  },
  {
    "text": "suggest transformations and generate ETL",
    "start": "37530",
    "end": "40500"
  },
  {
    "text": "code and Python so that you spend less",
    "start": "40500",
    "end": "42660"
  },
  {
    "text": "time hand coding you can modify this",
    "start": "42660",
    "end": "45420"
  },
  {
    "text": "code using your favorite IDE or notebook",
    "start": "45420",
    "end": "48170"
  },
  {
    "text": "once your ETL job is ready you can",
    "start": "48170",
    "end": "50969"
  },
  {
    "text": "schedule it using glues flexible",
    "start": "50969",
    "end": "52800"
  },
  {
    "text": "scheduler with dependency resolution job",
    "start": "52800",
    "end": "55230"
  },
  {
    "text": "monitoring and alerting glue runs your",
    "start": "55230",
    "end": "58140"
  },
  {
    "text": "jobs on a Cerberus SPARC platform",
    "start": "58140",
    "end": "60239"
  },
  {
    "text": "automatically provisioning the resources",
    "start": "60239",
    "end": "62219"
  },
  {
    "text": "you need behind the scenes you pay only",
    "start": "62219",
    "end": "64350"
  },
  {
    "text": "for the resources you consume while your",
    "start": "64350",
    "end": "66060"
  },
  {
    "text": "jobs are running now let's look at an",
    "start": "66060",
    "end": "68040"
  },
  {
    "text": "example assume that I'm a data scientist",
    "start": "68040",
    "end": "70530"
  },
  {
    "text": "for an airline and I want to analyze",
    "start": "70530",
    "end": "72299"
  },
  {
    "text": "flight data to determine the popularity",
    "start": "72299",
    "end": "74100"
  },
  {
    "text": "of various airports in our video on how",
    "start": "74100",
    "end": "76470"
  },
  {
    "text": "to get started with glue data catalog I",
    "start": "76470",
    "end": "78390"
  },
  {
    "text": "explain how glue automatically infers",
    "start": "78390",
    "end": "80549"
  },
  {
    "text": "the data format schema and partitions of",
    "start": "80549",
    "end": "82799"
  },
  {
    "text": "this flight data and creates a",
    "start": "82799",
    "end": "84330"
  },
  {
    "text": "corresponding table flights CSV in the",
    "start": "84330",
    "end": "87360"
  },
  {
    "text": "glue data catalog you can find a link to",
    "start": "87360",
    "end": "90119"
  },
  {
    "text": "that video in the description section",
    "start": "90119",
    "end": "91380"
  },
  {
    "text": "below in this video I'm going to focus",
    "start": "91380",
    "end": "94860"
  },
  {
    "text": "on how glue suggests transformations and",
    "start": "94860",
    "end": "97320"
  },
  {
    "text": "generates ETL code to convert flight",
    "start": "97320",
    "end": "99360"
  },
  {
    "text": "data from CSV to park' format let's get",
    "start": "99360",
    "end": "102930"
  },
  {
    "start": "102000",
    "end": "382000"
  },
  {
    "text": "started by logging into the AWS",
    "start": "102930",
    "end": "104820"
  },
  {
    "text": "management console and navigate to Glu",
    "start": "104820",
    "end": "107390"
  },
  {
    "text": "first I'm going to create a job I'll",
    "start": "107390",
    "end": "110460"
  },
  {
    "text": "name it flights conversion I'll pick the",
    "start": "110460",
    "end": "113700"
  },
  {
    "text": "glue iam role for the job this role",
    "start": "113700",
    "end": "116340"
  },
  {
    "text": "provides the job with permissions to",
    "start": "116340",
    "end": "118020"
  },
  {
    "text": "access the data stores it reads from and",
    "start": "118020",
    "end": "120119"
  },
  {
    "text": "writes to glue can automatically",
    "start": "120119",
    "end": "122640"
  },
  {
    "text": "generate an ETL script based on the",
    "start": "122640",
    "end": "124680"
  },
  {
    "text": "source and target I select for this job",
    "start": "124680",
    "end": "127129"
  },
  {
    "text": "this script is entirely customizable",
    "start": "127129",
    "end": "129800"
  },
  {
    "text": "when I create an ETL job I can ask",
    "start": "129800",
    "end": "133290"
  },
  {
    "text": "to propose a script to get started which",
    "start": "133290",
    "end": "135540"
  },
  {
    "text": "is the default option however I also",
    "start": "135540",
    "end": "138390"
  },
  {
    "text": "have the option to use an existing PI",
    "start": "138390",
    "end": "140280"
  },
  {
    "text": "spark script or start creating one from",
    "start": "140280",
    "end": "142769"
  },
  {
    "text": "scratch I'm going to pick the Amazon s3",
    "start": "142769",
    "end": "145379"
  },
  {
    "text": "path where the script will be stored and",
    "start": "145379",
    "end": "147569"
  },
  {
    "text": "a temporary directory where intermediate",
    "start": "147569",
    "end": "150000"
  },
  {
    "text": "results are written next let's pick the",
    "start": "150000",
    "end": "153269"
  },
  {
    "text": "data source",
    "start": "153269",
    "end": "153900"
  },
  {
    "text": "the flight's csv table and now the data",
    "start": "153900",
    "end": "158370"
  },
  {
    "text": "target i can either ask glue to create a",
    "start": "158370",
    "end": "161400"
  },
  {
    "text": "new table by selecting a target location",
    "start": "161400",
    "end": "163260"
  },
  {
    "text": "for example an s3 RDS or redshift",
    "start": "163260",
    "end": "166530"
  },
  {
    "text": "destination or select a target table",
    "start": "166530",
    "end": "169530"
  },
  {
    "text": "that already exists in the glue data",
    "start": "169530",
    "end": "171090"
  },
  {
    "text": "catalog I'm going to select an s3 target",
    "start": "171090",
    "end": "174420"
  },
  {
    "text": "location and the format for the results",
    "start": "174420",
    "end": "177000"
  },
  {
    "text": "Parkay I'll specify the s3 path where I",
    "start": "177000",
    "end": "180720"
  },
  {
    "text": "want the results to be created next I",
    "start": "180720",
    "end": "183870"
  },
  {
    "text": "can specify column mappings from source",
    "start": "183870",
    "end": "185819"
  },
  {
    "text": "to target the default mapping is a",
    "start": "185819",
    "end": "188400"
  },
  {
    "text": "simple copy in this case as my target",
    "start": "188400",
    "end": "190650"
  },
  {
    "text": "location doesn't exist yet I can choose",
    "start": "190650",
    "end": "192690"
  },
  {
    "text": "to modify my target schema I'm going to",
    "start": "192690",
    "end": "195359"
  },
  {
    "text": "drop three columns from the target table",
    "start": "195359",
    "end": "197160"
  },
  {
    "text": "that correspond to airport gate return",
    "start": "197160",
    "end": "199049"
  },
  {
    "text": "information data that does not concern",
    "start": "199049",
    "end": "201269"
  },
  {
    "text": "my analysis now let's review the job",
    "start": "201269",
    "end": "204090"
  },
  {
    "text": "parameters and create the ETL job the",
    "start": "204090",
    "end": "207569"
  },
  {
    "text": "job has been created and here I can see",
    "start": "207569",
    "end": "209790"
  },
  {
    "text": "the proposed script and a corresponding",
    "start": "209790",
    "end": "212280"
  },
  {
    "text": "diagram to help visualize the script the",
    "start": "212280",
    "end": "215250"
  },
  {
    "text": "source will be transformed to the target",
    "start": "215250",
    "end": "216989"
  },
  {
    "text": "with the help of two transforms apply",
    "start": "216989",
    "end": "219120"
  },
  {
    "text": "mapping and drop null fields apply",
    "start": "219120",
    "end": "222299"
  },
  {
    "text": "mapping transform will apply the source",
    "start": "222299",
    "end": "224190"
  },
  {
    "text": "to target column mapping I had earlier",
    "start": "224190",
    "end": "226319"
  },
  {
    "text": "specified now let's run the job I can",
    "start": "226319",
    "end": "230340"
  },
  {
    "text": "optionally pass runtime parameters to",
    "start": "230340",
    "end": "232560"
  },
  {
    "text": "this job and that's it there are no",
    "start": "232560",
    "end": "235680"
  },
  {
    "text": "resources to configure or manage glue",
    "start": "235680",
    "end": "238139"
  },
  {
    "text": "automatically provisions the resources",
    "start": "238139",
    "end": "240090"
  },
  {
    "text": "required to run this job the job is now",
    "start": "240090",
    "end": "242730"
  },
  {
    "text": "running and I can see log entries as the",
    "start": "242730",
    "end": "244859"
  },
  {
    "text": "job runs here while this job runs let me",
    "start": "244859",
    "end": "248400"
  },
  {
    "text": "show you some features of the script",
    "start": "248400",
    "end": "249959"
  },
  {
    "text": "editor I can see the schema of tables on",
    "start": "249959",
    "end": "252900"
  },
  {
    "text": "the schema tab after the job completes",
    "start": "252900",
    "end": "255930"
  },
  {
    "text": "running I can see statistics on rows",
    "start": "255930",
    "end": "258389"
  },
  {
    "text": "read and written at each node of the",
    "start": "258389",
    "end": "260549"
  },
  {
    "text": "diagram over here as you can see this is",
    "start": "260549",
    "end": "263940"
  },
  {
    "text": "a PI SPARC script that is entirely",
    "start": "263940",
    "end": "266250"
  },
  {
    "text": "editable",
    "start": "266250",
    "end": "267090"
  },
  {
    "text": "I can add and customize new transforms",
    "start": "267090",
    "end": "270389"
  },
  {
    "text": "sources targets or other logic to add a",
    "start": "270389",
    "end": "273690"
  },
  {
    "text": "new transform source or target all I",
    "start": "273690",
    "end": "275850"
  },
  {
    "text": "need to do is place my cursor in the",
    "start": "275850",
    "end": "278280"
  },
  {
    "text": "code where I want to insert the",
    "start": "278280",
    "end": "280080"
  },
  {
    "text": "corresponding script template and click",
    "start": "280080",
    "end": "282660"
  },
  {
    "text": "on the template I'm interested in for",
    "start": "282660",
    "end": "285419"
  },
  {
    "text": "example if I want to rename the fields",
    "start": "285419",
    "end": "287880"
  },
  {
    "text": "in the target table",
    "start": "287880",
    "end": "288990"
  },
  {
    "text": "I can place my cursor in the right",
    "start": "288990",
    "end": "290820"
  },
  {
    "text": "location on the script and click on the",
    "start": "290820",
    "end": "292889"
  },
  {
    "text": "corresponding transform template option",
    "start": "292889",
    "end": "294930"
  },
  {
    "text": "as you can see I clicked on the rename",
    "start": "294930",
    "end": "297930"
  },
  {
    "text": "field transform and the corresponding",
    "start": "297930",
    "end": "300180"
  },
  {
    "text": "code snippet was inserted in the code",
    "start": "300180",
    "end": "302570"
  },
  {
    "text": "now I need to customize the parameters",
    "start": "302570",
    "end": "305160"
  },
  {
    "text": "of the snippet I'm going to rename one",
    "start": "305160",
    "end": "307919"
  },
  {
    "text": "of the target columns from year to year",
    "start": "307919",
    "end": "310260"
  },
  {
    "text": "new I've also modified the input",
    "start": "310260",
    "end": "313740"
  },
  {
    "text": "parameters of the target s3 location to",
    "start": "313740",
    "end": "316500"
  },
  {
    "text": "consume the output of the rename field",
    "start": "316500",
    "end": "318240"
  },
  {
    "text": "transform I filled in the parameters for",
    "start": "318240",
    "end": "321630"
  },
  {
    "text": "the annotations in the template and I",
    "start": "321630",
    "end": "323430"
  },
  {
    "text": "can regenerate the diagram I can also",
    "start": "323430",
    "end": "326430"
  },
  {
    "text": "add my own PI smart code and import",
    "start": "326430",
    "end": "328680"
  },
  {
    "text": "custom libraries into the script if I",
    "start": "328680",
    "end": "331350"
  },
  {
    "text": "want a more interactive environment to",
    "start": "331350",
    "end": "332910"
  },
  {
    "text": "edit these scripts I can simply connect",
    "start": "332910",
    "end": "334770"
  },
  {
    "text": "a spark notebook or an IDE to glues",
    "start": "334770",
    "end": "337320"
  },
  {
    "text": "development endpoint you can refer to",
    "start": "337320",
    "end": "339539"
  },
  {
    "text": "our documentation for more information",
    "start": "339539",
    "end": "341250"
  },
  {
    "text": "on this for each job I can see a history",
    "start": "341250",
    "end": "344550"
  },
  {
    "text": "of all the job runs let's check on our",
    "start": "344550",
    "end": "347250"
  },
  {
    "text": "job it looks like it's done now let's go",
    "start": "347250",
    "end": "350789"
  },
  {
    "text": "see the results in s3 as you can see the",
    "start": "350789",
    "end": "354150"
  },
  {
    "text": "output files are written in the park'",
    "start": "354150",
    "end": "355919"
  },
  {
    "text": "format and can be readily queried from",
    "start": "355919",
    "end": "357900"
  },
  {
    "text": "Amazon Athena or Amazon redshift",
    "start": "357900",
    "end": "359820"
  },
  {
    "text": "Spectrum now that I've created and run",
    "start": "359820",
    "end": "362729"
  },
  {
    "text": "this job once I can attach triggers to",
    "start": "362729",
    "end": "364919"
  },
  {
    "text": "it to run it on a schedule on completion",
    "start": "364919",
    "end": "367169"
  },
  {
    "text": "of other jobs or invoke it on demand",
    "start": "367169",
    "end": "369539"
  },
  {
    "text": "from a lambda function in this video",
    "start": "369539",
    "end": "372030"
  },
  {
    "text": "we've seen how glue makes it easy to",
    "start": "372030",
    "end": "373889"
  },
  {
    "text": "generate and run your ETL jobs thanks",
    "start": "373889",
    "end": "376349"
  },
  {
    "text": "for watching",
    "start": "376349",
    "end": "377020"
  },
  {
    "text": "[Music]",
    "start": "377020",
    "end": "378449"
  },
  {
    "text": "you",
    "start": "378449",
    "end": "380509"
  },
  {
    "text": "[Music]",
    "start": "380540",
    "end": "384249"
  }
]
[
  {
    "start": "0",
    "end": "63000"
  },
  {
    "text": "uh my name is SAA dupati I've been with the AWS for the past s and a half years",
    "start": "640",
    "end": "5960"
  },
  {
    "text": "uh for the first two and a half years or so I helped build a couple of services uh Amazon Dynamo DB which is a",
    "start": "5960",
    "end": "11639"
  },
  {
    "text": "nosql database service and uh later on Amazon RDS which is a relational database service for the past 5 years uh",
    "start": "11639",
    "end": "18480"
  },
  {
    "text": "plus I've been working with customers around the world including amazon.com uh to architect their Big",
    "start": "18480",
    "end": "24039"
  },
  {
    "text": "Data Solutions on AWS um I lead our U Big Data Solutions architecture team I'm a practicing architect as as well so I'm",
    "start": "24039",
    "end": "30800"
  },
  {
    "text": "delighted to be here uh my objective is to share some of the you know truths that I have lived uh in terms of design",
    "start": "30800",
    "end": "37960"
  },
  {
    "text": "principles uh that I have stood the test of time for me at AWS um and so um um",
    "start": "37960",
    "end": "44559"
  },
  {
    "text": "this is a repeat session so um I worked hard uh to incorporate some of the services that we announced as well into",
    "start": "44559",
    "end": "50440"
  },
  {
    "text": "the slides I haven't quite got everything in the slides uh but uh but I you know I factored in uh glue AWS glue",
    "start": "50440",
    "end": "58120"
  },
  {
    "text": "and Amazon Athena into it we'll see how it Compares with other stuff uh so let's get started so in terms of what to",
    "start": "58120",
    "end": "64760"
  },
  {
    "start": "63000",
    "end": "144000"
  },
  {
    "text": "expect from the session so I'm going to go through some of the Big Data challenges customers are having um and",
    "start": "64760",
    "end": "70479"
  },
  {
    "text": "I'll go through the architectural principles the five architectural principles that has stood the test of time for me uh that's Pro probably the",
    "start": "70479",
    "end": "77040"
  },
  {
    "text": "most important slide in this entire talk and that's the center of my presentation and everything else is there to support",
    "start": "77040",
    "end": "82920"
  },
  {
    "text": "that and then we'll use those principles to sort of simplify the big data processing pipeline if you will I'll",
    "start": "82920",
    "end": "89560"
  },
  {
    "text": "break big data processing into multiple stages collect store process and consume",
    "start": "89560",
    "end": "96119"
  },
  {
    "text": "and then in each stage we'll explore what technologies to use how and more importantly why um as a builder of some",
    "start": "96119",
    "end": "103439"
  },
  {
    "text": "of the services um you know I have been intimately aware of you know what we what considerations that go into",
    "start": "103439",
    "end": "108960"
  },
  {
    "text": "building some of these Services I'm going to expose the question why typically in life if you answer the why question the rest of that is details you",
    "start": "108960",
    "end": "115640"
  },
  {
    "text": "know it kind of falls into place correctly so I'm going to touch on some of that and and um you know I'm going to",
    "start": "115640",
    "end": "121119"
  },
  {
    "text": "derive a reference architecture it's going to be pretty colorful you may or may not like the color but we'll see um",
    "start": "121119",
    "end": "126200"
  },
  {
    "text": "but then I'll also paint some of the design patterns like you know real-time processing batch interactive analytics",
    "start": "126200",
    "end": "133000"
  },
  {
    "text": "and we'll also touch on this data Lake uh data Lake seems to be the answer no matter what the question is for customers we'll figure out what that is",
    "start": "133000",
    "end": "139959"
  },
  {
    "text": "um we'll try to figure out nobody knows what this this is that's the truth um so",
    "start": "139959",
    "end": "145080"
  },
  {
    "text": "um one thing that we I'm not going to cover in this presentation is really there's no code I believe you should get",
    "start": "145080",
    "end": "151000"
  },
  {
    "text": "the architecture right before writing code uh also I have a lot of slides uh",
    "start": "151000",
    "end": "156120"
  },
  {
    "text": "I'm going to run right into you know the top of the hour so I'm going to stand outside and S take some questions I'm",
    "start": "156120",
    "end": "161840"
  },
  {
    "text": "also give you some my email as well c r amazon.com so if you have any questions that I cannot answer here you'd rather",
    "start": "161840",
    "end": "167760"
  },
  {
    "text": "answer me privately please uh drop me a note and with that uh the volume",
    "start": "167760",
    "end": "172920"
  },
  {
    "text": "velocity and variety of big data is ever increasing from an architect perspective what this means to me is probably about",
    "start": "172920",
    "end": "179000"
  },
  {
    "text": "5 years ago people people came to us and said oh you know I need to do 200,000 requests per second can you help me",
    "start": "179000",
    "end": "185440"
  },
  {
    "text": "build you know inter an architecture that'll actually do these kinds of requests that was you know thankfully",
    "start": "185440",
    "end": "191760"
  },
  {
    "text": "Dynamo DV was there so we could actually scale that and put that in there but nowadays that number is around 4 million",
    "start": "191760",
    "end": "197440"
  },
  {
    "text": "requests per second you know this could be big companies or startups that have become wildly successful that come to us",
    "start": "197440",
    "end": "204080"
  },
  {
    "text": "and say can you please help me build a system that can handle 4 million requests per second that's a lot of requ",
    "start": "204080",
    "end": "210040"
  },
  {
    "text": "per second and then in terms of other data types it could be files for example",
    "start": "210040",
    "end": "215879"
  },
  {
    "text": "some of the large customers are sending in 150 terabytes of data per day again 150 terabytes of data per day typically",
    "start": "215879",
    "end": "223159"
  },
  {
    "text": "this this lands in S3 for example and also the other front uh iot devices and",
    "start": "223159",
    "end": "228920"
  },
  {
    "text": "platforms are starting to send about you know 500 to 600 billion events per day",
    "start": "228920",
    "end": "235680"
  },
  {
    "text": "and U if you look at these numbers look pretty big but actually your numbers may not be as big but if you look at these",
    "start": "235680",
    "end": "242239"
  },
  {
    "text": "even these big numbers how many people are building the systems how long it takes to build these systems it turns",
    "start": "242239",
    "end": "248799"
  },
  {
    "text": "out one or two developers built this system in a in a few weeks uh now how do",
    "start": "248799",
    "end": "253840"
  },
  {
    "text": "you how do you build these massive systems uh scalable systems in two weeks is something that will touch into it you",
    "start": "253840",
    "end": "259759"
  },
  {
    "text": "need to get your architecture correct you need to use the right Services Etc so that's sort of the picture that that",
    "start": "259759",
    "end": "265000"
  },
  {
    "text": "I I sort of live through every week uh these days so I just wanted to paint that picture uh for you and in terms of",
    "start": "265000",
    "end": "271759"
  },
  {
    "start": "270000",
    "end": "439000"
  },
  {
    "text": "the big data processing as a as an evolution batch processing is moving",
    "start": "271759",
    "end": "278639"
  },
  {
    "text": "into stream processing and we also most customers are evolving their systems",
    "start": "278639",
    "end": "283800"
  },
  {
    "text": "from batch processing to stream processing what this means is for example if you have a fraud deduction",
    "start": "283800",
    "end": "289400"
  },
  {
    "text": "system rather than saying well this fraud happened this is the report of all the fraud that happened today uh it'll",
    "start": "289400",
    "end": "295560"
  },
  {
    "text": "be probably more useful to say well this looks like a fraudulent transaction I'm going to sort of treat this separately",
    "start": "295560",
    "end": "301800"
  },
  {
    "text": "on the other hand this other customer coming into the site for the first time seems like a pretty reasonable customer",
    "start": "301800",
    "end": "306919"
  },
  {
    "text": "I'm not going to you know take them through all this pain you know to buy my product I'm going to give them a fast path right so how do you make such",
    "start": "306919",
    "end": "313800"
  },
  {
    "text": "decisions so you need to basically tie in machine learning into your pipeline to be able to do this both your patch",
    "start": "313800",
    "end": "319600"
  },
  {
    "text": "processing pipeline in a way as well as real-time processing pipeline in a way how do you think about architectures to",
    "start": "319600",
    "end": "324720"
  },
  {
    "text": "incorporate machine learning into your pipeline there another aspect that I will try to address so in terms of the",
    "start": "324720",
    "end": "330520"
  },
  {
    "text": "cloud services Evolution over the past 7 and a half years for me when I started at AWS yes we did have S3 we did have",
    "start": "330520",
    "end": "336280"
  },
  {
    "text": "sqs uh and but we had virtual machines ec2 instances was what we had primarily a",
    "start": "336280",
    "end": "343360"
  },
  {
    "text": "lot of the customers were starting to use ec2 you know over the course of time we've already built services such as RDS",
    "start": "343360",
    "end": "349160"
  },
  {
    "text": "rather than for example getting an ec2 instance getting EBS volumes RDS is a relational database service you know",
    "start": "349160",
    "end": "354759"
  },
  {
    "text": "when you push the button you know specify your requirements it gives you a database server running it could be",
    "start": "354759",
    "end": "360240"
  },
  {
    "text": "various engines um for example my SQL or post cross Etc and then rather than",
    "start": "360240",
    "end": "365919"
  },
  {
    "text": "actually you getting these instances stitching them together running a raid across various EBS volumes we do that",
    "start": "365919",
    "end": "371759"
  },
  {
    "text": "for you you know hence the word manage services um and then uh when I started",
    "start": "371759",
    "end": "376880"
  },
  {
    "text": "on the Dynamo DB team I wrote the first version of the spec in fact you know what we wanted to do is to provide a a",
    "start": "376880",
    "end": "383160"
  },
  {
    "text": "simple API that will say create a table for me here is the key and uh just the",
    "start": "383160",
    "end": "388360"
  },
  {
    "text": "key don't have to describe that attributes and then by the way give me um U 100,000 rights per second and a",
    "start": "388360",
    "end": "394400"
  },
  {
    "text": "million reads per second and that's it you know under the covers we had go ahead and provision everything for you",
    "start": "394400",
    "end": "400520"
  },
  {
    "text": "when the table is ready it says creating table and then in a few moments the table is ready and you start actually doing puts and gets into the table that",
    "start": "400520",
    "end": "407240"
  },
  {
    "text": "I think of that as sort of even serverless you know people think just try to think Lambda serverless to me you",
    "start": "407240",
    "end": "413759"
  },
  {
    "text": "know Dynamo DB you know Kinesis in a way sqs is also serverless you're not worrying about the box you know what",
    "start": "413759",
    "end": "420440"
  },
  {
    "text": "size of box you need to get You're simply trying to specify you know what data types go in or your requirements",
    "start": "420440",
    "end": "427680"
  },
  {
    "text": "and we do the rest for you so actually building these serverless architectures into your you know NN pipelines is going",
    "start": "427680",
    "end": "434240"
  },
  {
    "text": "to be fairly important now how do you do that and um we'll touch on some of that",
    "start": "434240",
    "end": "439759"
  },
  {
    "start": "439000",
    "end": "526000"
  },
  {
    "text": "so luckily there's a plur of tools on the left side there's the open source ecosystem churning all kinds of amazing",
    "start": "439759",
    "end": "446720"
  },
  {
    "text": "tools if you ever been to a start out Theo conference uh spark is the answer",
    "start": "446720",
    "end": "452360"
  },
  {
    "text": "no matter what the question is so looks there's a lot of laughter in the room so that should be right so and apparently",
    "start": "452360",
    "end": "458800"
  },
  {
    "text": "this little squirrel at the very end you don't know what that the pink squirrel uh anybody know what that",
    "start": "458800",
    "end": "464599"
  },
  {
    "text": "is Apache flank right it's going to challenge you know the the the dominance",
    "start": "464599",
    "end": "470400"
  },
  {
    "text": "of spark if you will um so as an architect that leaves me in a little bit of a quandry you know now do I need to",
    "start": "470400",
    "end": "477360"
  },
  {
    "text": "should I use park or should I bet on um you know the little squirrel there um",
    "start": "477360",
    "end": "482599"
  },
  {
    "text": "flank so I think Building Systems in a way that obsolesence is going to happen",
    "start": "482599",
    "end": "488800"
  },
  {
    "text": "and how do you factor that system for obsolesence is a is a key thing as well there on the right side obviously you",
    "start": "488800",
    "end": "494000"
  },
  {
    "text": "have AWS Services you know starting from S3 through sqs onto onto Lambda and uh",
    "start": "494000",
    "end": "500759"
  },
  {
    "text": "today Athena uh so how do you basically Factor this in you probably didn't know yesterday or two days ago that aena was",
    "start": "500759",
    "end": "507000"
  },
  {
    "text": "going to be announced now how do you factor in aena to your pipeline if you build your pipeline properly you should be able to Simply plug in just as I did",
    "start": "507000",
    "end": "513560"
  },
  {
    "text": "in my slides which I'll show you in a little bit right so um so I think how do you how do you build systems for future",
    "start": "513560",
    "end": "519919"
  },
  {
    "text": "technologies that will be in play 6 months or 18 months from now is is a key aspect that you need to think about as",
    "start": "519919",
    "end": "525920"
  },
  {
    "text": "well now in essence uh what customers are asking us uh is is there a reference",
    "start": "525920",
    "end": "531320"
  },
  {
    "start": "526000",
    "end": "544000"
  },
  {
    "text": "architecture you know what are some of the design patterns you know what technology should I use and um you know",
    "start": "531320",
    "end": "537839"
  },
  {
    "text": "how and why right so I think we're going we're going to address the why and then see how with other pieces fall into play",
    "start": "537839",
    "end": "544560"
  },
  {
    "start": "544000",
    "end": "658000"
  },
  {
    "text": "so um I talked about architectural principles these five that I'll discuss now has stood the test of time for me at",
    "start": "544560",
    "end": "551959"
  },
  {
    "text": "AWS the first is you should be Building decoupled Systems and I think I want to",
    "start": "551959",
    "end": "557959"
  },
  {
    "text": "use the Practical analogy a car uh I'm I'm a mechanical engineer by training in my first life U then a computer science",
    "start": "557959",
    "end": "564760"
  },
  {
    "text": "person the second life a car is a beautifully decoupled system so you have the engine uh the gasoline engine let's",
    "start": "564760",
    "end": "572079"
  },
  {
    "text": "take for example um that's running at a specific speed gasoline engines tend to run well at a constant speed they don't",
    "start": "572079",
    "end": "578720"
  },
  {
    "text": "like ups and downs whereas in real light real life you know your road has ups and downs and you know various speeds you",
    "start": "578720",
    "end": "585399"
  },
  {
    "text": "can't take the corner at the same speed as you've been driving you know in a straight line so there's this beautiful thing called a gearbox with a clutch if",
    "start": "585399",
    "end": "591920"
  },
  {
    "text": "you're familiar with a clutch maybe some people hav't driven manual are not familiar with the clutch um so um this",
    "start": "591920",
    "end": "598079"
  },
  {
    "text": "thing nicely decouples both tiers the engine as well as the wheels in a way in a processing scenario",
    "start": "598079",
    "end": "605480"
  },
  {
    "text": "what happens is you have two processing layers and the storage really acts as this gearbox or a clutch that nicely",
    "start": "605480",
    "end": "611000"
  },
  {
    "text": "decouples both of those as long as you you lay out your architecture in a way this is nicely decoupled the downstream",
    "start": "611000",
    "end": "617720"
  },
  {
    "text": "system can pump data at any rate that it wants and the Upstream system can pick up the data at any rate that it wants",
    "start": "617720",
    "end": "623640"
  },
  {
    "text": "and and the middle tier actually the storage tier nicely decompose this so this way actually nothing blows up you",
    "start": "623640",
    "end": "629640"
  },
  {
    "text": "know everything works at its own speed you're shaping and dicing the data in its own speed so I think using the right technology and the right decoupling",
    "start": "629640",
    "end": "636320"
  },
  {
    "text": "really helps uh towards the end I'm going to lay out three decoupled architectural patterns you know one is I",
    "start": "636320",
    "end": "641680"
  },
  {
    "text": "call as a datab bus the second one um I is Pub sub which has been pretty prevalent you know with the Advent of",
    "start": "641680",
    "end": "648000"
  },
  {
    "text": "you know Kinesis and Kafka and then the third one is what I'm calling is materialized views so those are the",
    "start": "648000",
    "end": "653880"
  },
  {
    "text": "mechanisms that will allow you to decouple these systems and um second",
    "start": "653880",
    "end": "659440"
  },
  {
    "start": "658000",
    "end": "747000"
  },
  {
    "text": "thing um using the right tool for the job one size does not fit all using the",
    "start": "659440",
    "end": "664519"
  },
  {
    "text": "right tool for the job is Paramount at AWS when we build services at AWS we typically tend build them to do a few",
    "start": "664519",
    "end": "671600"
  },
  {
    "text": "functions extremely well and we price them for that as well so what happens is",
    "start": "671600",
    "end": "676680"
  },
  {
    "text": "if you tend to use in some cases you could use two services for the same function and in many cases one service",
    "start": "676680",
    "end": "683000"
  },
  {
    "text": "is going to be costing you much more than the other so guess what which is the right service to pick the most",
    "start": "683000",
    "end": "688480"
  },
  {
    "text": "expensive service right no the Le the Lesser expensive service we'll go through an example",
    "start": "688480",
    "end": "694440"
  },
  {
    "text": "there's going a quiz uh at the very end so you got to stay awake a little bit so I hope you got some coffee I did before",
    "start": "694440",
    "end": "700639"
  },
  {
    "text": "I came here um so I think we're going to look at how do you one of the key things to finding the right tool is also",
    "start": "700639",
    "end": "706800"
  },
  {
    "text": "understanding your access patterns and U also your your your latency your throughput requirements Etc so you need",
    "start": "706800",
    "end": "713279"
  },
  {
    "text": "to understand what your application requirements are and sort of map that to the various Services what I'm going to",
    "start": "713279",
    "end": "718639"
  },
  {
    "text": "do in the the course of the presentation is layout for various Services what are the defining attributes that I found",
    "start": "718639",
    "end": "724320"
  },
  {
    "text": "pretty helpful when helping customers so it's going to be a pretty dense slide I'm not going to go through everything",
    "start": "724320",
    "end": "730160"
  },
  {
    "text": "but I'm going to lay out some of the key aspects so these slides will be available at the end of the presentation probably in two days or a week uh both",
    "start": "730160",
    "end": "736839"
  },
  {
    "text": "slides share as well as YouTube hopefully so then so you should be able to find the content there as well so you",
    "start": "736839",
    "end": "742920"
  },
  {
    "text": "can relax and take some notes or just listen and um third um leveraging a",
    "start": "742920",
    "end": "749480"
  },
  {
    "start": "747000",
    "end": "818000"
  },
  {
    "text": "manag Services is key you know rather than actually Building Systems there are customers who tell us you know I know",
    "start": "749480",
    "end": "755920"
  },
  {
    "text": "how to run you know a specific database very well whether it be Cassandra or  I'm picking two examples but I've",
    "start": "755920",
    "end": "762639"
  },
  {
    "text": "done that for a long time um in a way can you please take this away from me I want to use the manage services instead",
    "start": "762639",
    "end": "768760"
  },
  {
    "text": "and then they try to use Dynamo instead right not that they don't know how to do this they do this well at scale but it",
    "start": "768760",
    "end": "774279"
  },
  {
    "text": "comes to a point where they have limited resources and they want to focus those resources for building tools and",
    "start": "774279",
    "end": "780040"
  },
  {
    "text": "technologies that are very relevant for customers they don't actually spend time actually installing software upgrading",
    "start": "780040",
    "end": "786079"
  },
  {
    "text": "software maintaining software Etc even though they know how to do this fairly well and AWS using AWS manag Services is",
    "start": "786079",
    "end": "793680"
  },
  {
    "text": "the key to the agility that I talked about how does one or two developers you know how do people build such massive",
    "start": "793680",
    "end": "799440"
  },
  {
    "text": "systems in a short time clearly using manage services you know pushes a lot of the heavy lifting to AWS so you can",
    "start": "799440",
    "end": "805279"
  },
  {
    "text": "focus on your application uh scenarios and then it it basically gives you low",
    "start": "805279",
    "end": "811199"
  },
  {
    "text": "admin or no admin in many cases and also along with the various abilities availability you know reliability",
    "start": "811199",
    "end": "817839"
  },
  {
    "text": "Etc so the the fourth pattern um that is",
    "start": "817839",
    "end": "823279"
  },
  {
    "start": "818000",
    "end": "987000"
  },
  {
    "text": "our principle that's super important is using log Centric design patterns maybe",
    "start": "823279",
    "end": "830240"
  },
  {
    "text": "a better way of saying that is don't delete anything and um especially the logs um",
    "start": "830240",
    "end": "837560"
  },
  {
    "text": "you know transaction log if you're a database person transaction logs have been around for a long time the typically the way people back up",
    "start": "837560",
    "end": "843480"
  },
  {
    "text": "databases is that they take a snapshot of the database or they back up transaction logs the logs are basically",
    "start": "843480",
    "end": "849560"
  },
  {
    "text": "what are the changes that happened in a specific data table for example Etc you can always recover the state of the",
    "start": "849560",
    "end": "855720"
  },
  {
    "text": "database by actually applying the logs forward it's almost like your checking account or the savings account you don't",
    "start": "855720",
    "end": "861040"
  },
  {
    "text": "need to know what the balance is let's assume your database died uh what do you know how do you know what your balance is s if you had all those you know",
    "start": "861040",
    "end": "868040"
  },
  {
    "text": "change you know all all the money you deposited and withdrew you can clearly reconstruct the straight similarly when",
    "start": "868040",
    "end": "874519"
  },
  {
    "text": "you have all these logs you can actually have various views of these logs painted you know for example if there's a stream",
    "start": "874519",
    "end": "880320"
  },
  {
    "text": "of data coming in you may want to do actually a search on top of that or you",
    "start": "880320",
    "end": "885680"
  },
  {
    "text": "may want to actually put that in some other some other you know a search engine or a relational database or no",
    "start": "885680",
    "end": "892240"
  },
  {
    "text": "SQL database or various views or a graph view um having the log and then creating",
    "start": "892240",
    "end": "898079"
  },
  {
    "text": "various materialized views allows you to actually have a single source of Truth yet actually render this or view this in",
    "start": "898079",
    "end": "905639"
  },
  {
    "text": "various formats that's par amount uh again that has stood the test of time for me at AWS so the idea of immutable",
    "start": "905639",
    "end": "912480"
  },
  {
    "text": "logs and materialized views is super important last but not the least um be",
    "start": "912480",
    "end": "919120"
  },
  {
    "text": "cost conscious uh Big Data should not be equals to Big cost uh typically something is wrong in many of my design",
    "start": "919120",
    "end": "926000"
  },
  {
    "text": "reviews which typically last about an hour I park at 20 minute or a 30 minute time and say let's just figure out how",
    "start": "926000",
    "end": "932720"
  },
  {
    "text": "much what is the cost of the solution usually one or two things come out of that either the customer says all thumbs",
    "start": "932720",
    "end": "938639"
  },
  {
    "text": "up my God this is 50 bucks you know I love this right or something like that or in other cases they say oh this",
    "start": "938639",
    "end": "945079"
  },
  {
    "text": "breaks the bank what's going on here the problem is either I haven't used the right system or um right service or in",
    "start": "945079",
    "end": "954079"
  },
  {
    "text": "some cases people tend to imagine things they want to be vly successful that's all good but you know if you if if",
    "start": "954079",
    "end": "960319"
  },
  {
    "text": "you're building a system 200 times more than what you really want sometimes first of all you can't afford to build a",
    "start": "960319",
    "end": "965600"
  },
  {
    "text": "system second if you build a system probably building for the wrong requirements both are essentially wrong",
    "start": "965600",
    "end": "971199"
  },
  {
    "text": "so being able to actually think about costs when you design plays an important role in picking the right tool for the",
    "start": "971199",
    "end": "977920"
  },
  {
    "text": "job so uh this is I guess the most important Slide the rest of them are details we'll go through it a little bit",
    "start": "977920",
    "end": "983800"
  },
  {
    "text": "faster I spent a bit of time here just to focus on this one and uh now let's simplify",
    "start": "983800",
    "end": "990440"
  },
  {
    "start": "987000",
    "end": "1132000"
  },
  {
    "text": "y with those principles let's simplify big data processing the more and more",
    "start": "990440",
    "end": "995839"
  },
  {
    "text": "Big Data Systems I help build more and more they look like this big pipeline uh with the data going in from one side and",
    "start": "995839",
    "end": "1001639"
  },
  {
    "text": "answers coming out from the other side and typically there's multiple stages you know typical stages are collect",
    "start": "1001639",
    "end": "1007240"
  },
  {
    "text": "store process um or analyze I'm going to interchangeably call that and consume",
    "start": "1007240",
    "end": "1013639"
  },
  {
    "text": "and uh what also happens is the store process store process repeats itself multiple times to shape the data in a",
    "start": "1013639",
    "end": "1020480"
  },
  {
    "text": "form that's amable for Downstream access so if you want the answers in a few milliseconds obviously you need to have",
    "start": "1020480",
    "end": "1026000"
  },
  {
    "text": "a nosql database or something that's already pre-indexed that renders that pretty fast you can go back into your",
    "start": "1026000",
    "end": "1032319"
  },
  {
    "text": "data Lake and start assembling all the stuff together because your time window has passed if I need to serve an ad in 100 milliseconds you just have probably",
    "start": "1032319",
    "end": "1039280"
  },
  {
    "text": "about three or four milliseconds on the database here to actually tell you you know whether I should actually serve",
    "start": "1039280",
    "end": "1044360"
  },
  {
    "text": "this ad or not so if you so I think it's pretty important to basically shape the data a form that you will access it and",
    "start": "1044360",
    "end": "1051960"
  },
  {
    "text": "then what goes in there really is determined by like I said uh time to answer or latency and your throughput",
    "start": "1051960",
    "end": "1058360"
  },
  {
    "text": "which comprises of the number of requests and the payload size and um and also cost so this you know depending",
    "start": "1058360",
    "end": "1065440"
  },
  {
    "text": "upon your domain problem you know the length or the number of things that goes in there is basically has a few",
    "start": "1065440",
    "end": "1071559"
  },
  {
    "text": "constraints typically those are the three three top constraints so now let's look at the type of data that we're",
    "start": "1071559",
    "end": "1077159"
  },
  {
    "text": "dealing with typically you're either dealing with with transactions those could be you know in memory these days in memory databases are getting more",
    "start": "1077159",
    "end": "1083679"
  },
  {
    "text": "popular uh it could be your classic nosql databases or in memory databases and files you know files could be in the",
    "start": "1083679",
    "end": "1089919"
  },
  {
    "text": "form of search documents that your log stash senss it to your um to to elastic",
    "start": "1089919",
    "end": "1095600"
  },
  {
    "text": "search server or it could be log files you know for example you know either cloud trail logs or Cloud watch logs or",
    "start": "1095600",
    "end": "1103159"
  },
  {
    "text": "you know Flume Apache Flume or a log for J all these system sub system are",
    "start": "1103159",
    "end": "1109039"
  },
  {
    "text": "creating logs and those logs typically end up in a in a log in a log storage",
    "start": "1109039",
    "end": "1114240"
  },
  {
    "text": "and then either it used to be hdfs It's Quickly becoming S3 for all thews use",
    "start": "1114240",
    "end": "1119520"
  },
  {
    "text": "cases we'll delve into the details and then also messaging and more importantly more recently streams um are the two",
    "start": "1119520",
    "end": "1127200"
  },
  {
    "text": "different data types are that are getting fairly popular and um so uh",
    "start": "1127200",
    "end": "1133000"
  },
  {
    "start": "1132000",
    "end": "1143000"
  },
  {
    "text": "before we get into kind of picking the right store for this often times when I think about solving a data problem think",
    "start": "1133000",
    "end": "1139080"
  },
  {
    "text": "about the temperature of the data you know what is the temperature of the data I'm dealing with if I'm dealing with hot data you know imagine data in memory uh",
    "start": "1139080",
    "end": "1146880"
  },
  {
    "start": "1143000",
    "end": "1206000"
  },
  {
    "text": "your various caches and um our data on ssds uh which is synonymous to warm data",
    "start": "1146880",
    "end": "1153679"
  },
  {
    "text": "or cold data when you're dealing with actually hot data you're dealing with typically small payload moving really",
    "start": "1153679",
    "end": "1158840"
  },
  {
    "text": "really fast you want very low latency in the order of milliseconds or microsc as you move towards the right you know then",
    "start": "1158840",
    "end": "1165200"
  },
  {
    "text": "the time becomes you know milliseconds to seconds and seconds to hours and then",
    "start": "1165200",
    "end": "1170400"
  },
  {
    "text": "also the cost per gigabyte of storage actually tends to go up from you know goes down from left to right in other",
    "start": "1170400",
    "end": "1176600"
  },
  {
    "text": "words if you're putting it in memory it's a lot more expensive than potentially putting it in in Amazon Glacier which is 4/10 after the price",
    "start": "1176600",
    "end": "1183559"
  },
  {
    "text": "reduction which is 410 of a penny per gigabyte per month uh dramatically different cost cost points it could be",
    "start": "1183559",
    "end": "1189799"
  },
  {
    "text": "you know two digigit dollars for the memory if you're putting this in memory versus you know few few cents or",
    "start": "1189799",
    "end": "1194840"
  },
  {
    "text": "fractions of cents per gigabyte per month so having this no of what is the temperature of the data I'm dealing with",
    "start": "1194840",
    "end": "1201120"
  },
  {
    "text": "it typically you know helps me think better or more clearly which I'll explain how uh now we looked at the",
    "start": "1201120",
    "end": "1207600"
  },
  {
    "start": "1206000",
    "end": "1439000"
  },
  {
    "text": "various data types and typically you know records um both in memory as well as on disk records go in either caches",
    "start": "1207600",
    "end": "1215000"
  },
  {
    "text": "are SQL and nosql and then search documents go into search stores and",
    "start": "1215000",
    "end": "1220360"
  },
  {
    "text": "files go into file stores and then the messages typically went into message cues and more importantly the streaming",
    "start": "1220360",
    "end": "1226840"
  },
  {
    "text": "data now that is coming from various various platforms iot platforms and devices typically goes into some kind of",
    "start": "1226840",
    "end": "1233480"
  },
  {
    "text": "a streaming data store now let's look at what are the message and stream data stores now we're going to slice and dice",
    "start": "1233480",
    "end": "1239360"
  },
  {
    "text": "each layer and compare and contrast you know various pieces in each one of those like for example uh Amazon sqs is a",
    "start": "1239360",
    "end": "1246640"
  },
  {
    "text": "fully managed service um for for putting you know your queueing data for putting your message cues I mean these messages",
    "start": "1246640",
    "end": "1253240"
  },
  {
    "text": "could be something that you transfer between multiple applications or this could be a buffering stage for downam",
    "start": "1253240",
    "end": "1258600"
  },
  {
    "text": "stream consumption we'll we'll contrast that with with the stream storage in a moment and then Apache kovka has been",
    "start": "1258600",
    "end": "1265480"
  },
  {
    "text": "super popular uh for for putting streaming data for example Netflix uses",
    "start": "1265480",
    "end": "1270679"
  },
  {
    "text": "you know Kafka large kka clusters that they actually stitch on top of ec2 instances for managing all their events",
    "start": "1270679",
    "end": "1277640"
  },
  {
    "text": "events in the within the company and then um it works fairly well uh the equalent fully managed service is Amazon",
    "start": "1277640",
    "end": "1285919"
  },
  {
    "text": "Kinesis streams you know it's a fully managed kinesis Stream So in the case of a you know Kafka you need to basically",
    "start": "1285919",
    "end": "1291600"
  },
  {
    "text": "install the software get ec2 machines get the right discs install all the software and manage the cluster yourself",
    "start": "1291600",
    "end": "1297120"
  },
  {
    "text": "whereas in the case of Kinesis you will simply say create me a Kinesis stream um",
    "start": "1297120",
    "end": "1302360"
  },
  {
    "text": "and then you know I need this much amount of throughput you know Single Shard within the stream there's multiple shards each Shard is 1 Megabyte per",
    "start": "1302360",
    "end": "1309159"
  },
  {
    "text": "second ingest and 2 megabytes per second erress and then you would simply basically provision the right stream and",
    "start": "1309159",
    "end": "1315279"
  },
  {
    "text": "you can scale that up and down um automatically if you'd like uh by writing your own little application on top of that you know for",
    "start": "1315279",
    "end": "1321799"
  },
  {
    "text": "doing that that's amaz on Kinesis service streams we also introduced uh Amazon Kinesis fir hose you know for",
    "start": "1321799",
    "end": "1328559"
  },
  {
    "text": "example when we introduced Amazon Kinesis uh the top thing the customers did were they actually stuck all the",
    "start": "1328559",
    "end": "1334240"
  },
  {
    "text": "data in Amazon Kinesis and eventually took it to S3 we figured we'll build that for them you know then Amazon",
    "start": "1334240",
    "end": "1339360"
  },
  {
    "text": "Kinesis firehost was born firehost simply if you write to a firehouse uh you don't even have to specify the",
    "start": "1339360",
    "end": "1345200"
  },
  {
    "text": "number of shots Etc you you write to the Firehouse you create a firehouse and you right to the firehose and then it",
    "start": "1345200",
    "end": "1350880"
  },
  {
    "text": "automatically bucke bucke ties your data it also compresses your data you can compress the data with your own keys or",
    "start": "1350880",
    "end": "1358000"
  },
  {
    "text": "or KMS uh Key Management Service managed keys and it automatically SS them you",
    "start": "1358000",
    "end": "1363240"
  },
  {
    "text": "know in an S3 end point that you like uh a lot of customers love that because then they can run things like Athena to",
    "start": "1363240",
    "end": "1370240"
  },
  {
    "text": "run queries on top of that all of a sudden all your streaming data magically is available for querying with Thea",
    "start": "1370240",
    "end": "1376640"
  },
  {
    "text": "that's an amazing scenario that this thing you know allows you to do and uh",
    "start": "1376640",
    "end": "1381919"
  },
  {
    "text": "that's an example of the fire hose um also I'm on Dynamo DB streams I think wner touched in this talk this morning",
    "start": "1381919",
    "end": "1388240"
  },
  {
    "text": "many people don't consider a few a few years ago I think about a couple of years ago we introduced uh Dynamo DB",
    "start": "1388240",
    "end": "1393799"
  },
  {
    "text": "streams uh think of that as a transaction log of all the changes that happen if you create a table if you",
    "start": "1393799",
    "end": "1399120"
  },
  {
    "text": "start putting data and updating data into it you can also specify in my update stream give me only the changes",
    "start": "1399120",
    "end": "1405679"
  },
  {
    "text": "that happen if you change you know your key for specific customer Joe you you",
    "start": "1405679",
    "end": "1410880"
  },
  {
    "text": "you switch to floos from A to B you know you can you can get the prior image a",
    "start": "1410880",
    "end": "1415919"
  },
  {
    "text": "and then the after image b as well so it allows you to build very rich class of applications such as you can index all",
    "start": "1415919",
    "end": "1421360"
  },
  {
    "text": "your data that you put in Dynamo DB by actually having a Lambda function take that and put that in elastic search for",
    "start": "1421360",
    "end": "1428240"
  },
  {
    "text": "example so that's a beautiful way of nicely decoupling this and then having your search index on top of your nol",
    "start": "1428240",
    "end": "1435880"
  },
  {
    "text": "database for example and um so why stream storage it allows you to",
    "start": "1435880",
    "end": "1442440"
  },
  {
    "start": "1439000",
    "end": "1765000"
  },
  {
    "text": "it gives you like three main things in terms of decoupling a decoupling it decouples producers from consumers it",
    "start": "1442440",
    "end": "1448559"
  },
  {
    "text": "also by providing a persistent buffer essentially if you have producers one 2 three Etc uh those could be devices",
    "start": "1448559",
    "end": "1456080"
  },
  {
    "text": "rather than holding this hot potato of data that that got generated usually these little devices don't have much memory or or capability it'll be nice to",
    "start": "1456080",
    "end": "1463559"
  },
  {
    "text": "hand this off to some other layer that'll be nicely persistent that happens to be you know you can put that in you know stream storage such as",
    "start": "1463559",
    "end": "1470159"
  },
  {
    "text": "Dynamo DB stream or Kinesis stream or Kafka topic and um and one of the other",
    "start": "1470159",
    "end": "1477039"
  },
  {
    "text": "defining Factor you know defining attributes of a stream storage mechanism is preserve client it preserves client",
    "start": "1477039",
    "end": "1483080"
  },
  {
    "text": "ordering in other words the producer sends packets 1 two three and four in that order it ensures that a consuming",
    "start": "1483080",
    "end": "1490080"
  },
  {
    "text": "layer consumes this data in the same order it was produced for example a lot of times in amazon.com we do what",
    "start": "1490080",
    "end": "1497000"
  },
  {
    "text": "happens you know when people abandon the cart you know clickstream analytic system captures all the stuff that happens in amazon.com when when Amazon",
    "start": "1497000",
    "end": "1505600"
  },
  {
    "text": "teams are actually analyzing why are so many people abandoning the cart at this specific point maybe there's something",
    "start": "1505600",
    "end": "1510760"
  },
  {
    "text": "wrong with the website or maybe we're not presenting the right options so what is the sequence of actions that a",
    "start": "1510760",
    "end": "1516360"
  },
  {
    "text": "customer took as they walk through the site you know this one if you actually put the data in Kinesis or CFA that",
    "start": "1516360",
    "end": "1522720"
  },
  {
    "text": "preserves that client ordering your Downstream applications can do that there's also another function called streaming",
    "start": "1522720",
    "end": "1529039"
  },
  {
    "text": "um before I get there there's a parallel consumption Paradigm that you there a pubs up Paradigm this this this",
    "start": "1529039",
    "end": "1534440"
  },
  {
    "text": "subsystems introduced which means the same data if you have two teams in the case of amazon.com for example we may",
    "start": "1534440",
    "end": "1540120"
  },
  {
    "text": "have a fraud deduction team you know looking for if there's any fraud happening on that site but also we do a",
    "start": "1540120",
    "end": "1546080"
  },
  {
    "text": "lot of AB testing the AB testing team has changed the website and is presenting a different views to different customers they're actually",
    "start": "1546080",
    "end": "1552360"
  },
  {
    "text": "always running some tests on their side they want to know how the clickstream progresses right both the teams want to",
    "start": "1552360",
    "end": "1558039"
  },
  {
    "text": "look at the same clickstream data if you actually rather than you asking the first team to build the pipeline for you",
    "start": "1558039",
    "end": "1563919"
  },
  {
    "text": "and you consume that these two teams can parly consume the data so these subsystems allow you to actually allow",
    "start": "1563919",
    "end": "1570960"
  },
  {
    "text": "you for parallel consumption so the same stream is available for two or three or n number of teams as long as you",
    "start": "1570960",
    "end": "1576760"
  },
  {
    "text": "provision enough throughput um that's available now this is a huge deal for",
    "start": "1576760",
    "end": "1582279"
  },
  {
    "text": "speeding up things within your teams if you have four teams accessing the same data they can all build their products",
    "start": "1582279",
    "end": "1587440"
  },
  {
    "text": "and release at their own timeline rather than depending upon the first team uh to do it for them um and then that's an",
    "start": "1587440",
    "end": "1594240"
  },
  {
    "text": "indirect benefit just want to highlight as well and then last but not the least uh what I what we call streaming map",
    "start": "1594240",
    "end": "1600840"
  },
  {
    "text": "ruce you know for example map ruce if if the producer the red producer uh",
    "start": "1600840",
    "end": "1605880"
  },
  {
    "text": "designates all the packets that it sends as red then the idea of doing a map",
    "start": "1605880",
    "end": "1611000"
  },
  {
    "text": "produce is really finding out give me the the top end what are the what is the",
    "start": "1611000",
    "end": "1616159"
  },
  {
    "text": "top um value let's say this is a temperature measuring device what is the top temperature that you have seen or",
    "start": "1616159",
    "end": "1621960"
  },
  {
    "text": "what is the maximum temperature you have seen that is essentially map Reduce by just specifying key equals red the",
    "start": "1621960",
    "end": "1628039"
  },
  {
    "text": "mapping functions automatically happens within the stream storage in other words the red packet is ensured to go to a",
    "start": "1628039",
    "end": "1636279"
  },
  {
    "text": "specific partition and the downstream client framework also like KCl clent",
    "start": "1636279",
    "end": "1641840"
  },
  {
    "text": "Kinesis client Library also allows you to tie a single thread to that one uh",
    "start": "1641840",
    "end": "1646880"
  },
  {
    "text": "stream in that case that allows you to do computation such as men Max average so that automatically you know is",
    "start": "1646880",
    "end": "1653840"
  },
  {
    "text": "enabled if you if you specify the key one one downside of specifying the key is you're constrained by the maximum",
    "start": "1653840",
    "end": "1660240"
  },
  {
    "text": "throughput of a single portion or A Shard uh so in the case of Kinesis it'll be 1 Megabyte per second if you ever",
    "start": "1660240",
    "end": "1666159"
  },
  {
    "text": "ever think that the producer one is going to send more than 1 Megabyte of second then you can't actually use the streaming map ruce so it's not for",
    "start": "1666159",
    "end": "1673279"
  },
  {
    "text": "everyone but for some cases the streaming map produce functionality can be fairly very well used and uh now what",
    "start": "1673279",
    "end": "1679480"
  },
  {
    "text": "about sqs this is a top question that comes you know um as as an architect for",
    "start": "1679480",
    "end": "1686279"
  },
  {
    "text": "me sqs also decouples producers and consumers provides a persistent buffers",
    "start": "1686279",
    "end": "1691440"
  },
  {
    "text": "allows you to collect multiple streams uh but it doesn't give you client ordering it doesn't give you streaming",
    "start": "1691440",
    "end": "1697919"
  },
  {
    "text": "map produce functionality and there's no parallel consumption possible even though that are parallel clients that can consume the data if one client reads",
    "start": "1697919",
    "end": "1705200"
  },
  {
    "text": "the data that's not available for the other client to process you cannot have actually two teams consuming the same input as soon as the first team consumes",
    "start": "1705200",
    "end": "1712120"
  },
  {
    "text": "that it's not available for the second second second team now as I drew the slide I had to change this slide a",
    "start": "1712120",
    "end": "1718360"
  },
  {
    "text": "little bit now we also introduced a couple of weeks ago fifo Q's right when the fif Q's now preserve client ordering",
    "start": "1718360",
    "end": "1725960"
  },
  {
    "text": "now what's the difference between uh so I think the the second picture there preserves client ordering in fact it",
    "start": "1725960",
    "end": "1731360"
  },
  {
    "text": "does even ding if you will uh for a moment we'll we'll compare and contrast that with the other cues in the next",
    "start": "1731360",
    "end": "1737440"
  },
  {
    "text": "slide um the one uh well every exception um has a special case right I said no",
    "start": "1737440",
    "end": "1744320"
  },
  {
    "text": "parallel consumption you can also enable parallel consumption by actually putting your data in SNS creating a topic and",
    "start": "1744320",
    "end": "1751039"
  },
  {
    "text": "then have multiple cues subscribed to that so you can Bas pretty much derive the same thing that I said before you",
    "start": "1751039",
    "end": "1756440"
  },
  {
    "text": "can have you know the data the same data being sent to multiple cues by SNS some customers use that pattern that works",
    "start": "1756440",
    "end": "1762919"
  },
  {
    "text": "fairly well and um now here's the thick slide you know with a lot of details",
    "start": "1762919",
    "end": "1768320"
  },
  {
    "start": "1765000",
    "end": "1995000"
  },
  {
    "text": "which stream storage subsystem am I supposed to use um customers tell us",
    "start": "1768320",
    "end": "1773480"
  },
  {
    "text": "don't please don't give me a menu pick one for me I'm sick and tired of seeing these comparisons right now we'll get to",
    "start": "1773480",
    "end": "1781480"
  },
  {
    "text": "that in a moment as a designer first I want to show you the menu uh and all the parameters that are pretty much relevant",
    "start": "1781480",
    "end": "1787320"
  },
  {
    "text": "we'll go through the parameters you'll find that interesting is it a managed service or not is there a guaranteed",
    "start": "1787320",
    "end": "1792720"
  },
  {
    "text": "ordering or not you know is it delivered once or is there dding possible suppose",
    "start": "1792720",
    "end": "1798159"
  },
  {
    "text": "if you're building a Billing System we don't want to double bill you if you stuck your data in Kinesis and you didn't factor in for D duping once in a",
    "start": "1798159",
    "end": "1805200"
  },
  {
    "text": "while you know the client may actually send you you you read the same data",
    "start": "1805200",
    "end": "1810919"
  },
  {
    "text": "twice in other words if you if you Faithfully build your customer some customer is not going to be happy because they got double build so you",
    "start": "1810919",
    "end": "1817440"
  },
  {
    "text": "need to somehow factor in D duping into this certain Services allow you to do that you know if you if you stick your",
    "start": "1817440",
    "end": "1822760"
  },
  {
    "text": "data into Kinesis Dynamo DB streams for example and you can actually designate",
    "start": "1822760",
    "end": "1828039"
  },
  {
    "text": "if there's a key that you can ddop on you can come up with a semantic like the first Rider wins so the last Rider win",
    "start": "1828039",
    "end": "1833760"
  },
  {
    "text": "so the first if you in the first Rider win scenario you're basically saying I already wrote to this don't write the second second packet and you can avoid",
    "start": "1833760",
    "end": "1840559"
  },
  {
    "text": "that right um so and also the other piece is also availability if you're if you're running Kinesis or if you're",
    "start": "1840559",
    "end": "1846519"
  },
  {
    "text": "running Kafka for example um you need to factor this in in a way such that the Kafka is installed on multiple data",
    "start": "1846519",
    "end": "1852360"
  },
  {
    "text": "centers and availability zones but all the manag services we do that automatically for you in the C case of",
    "start": "1852360",
    "end": "1858000"
  },
  {
    "text": "kofka is configurable if you need multi- dat Center availability you need to configure that and um so um just to kind",
    "start": "1858000",
    "end": "1866360"
  },
  {
    "text": "of give you a set menu if you have stream processing if first in first out is really available if it's important",
    "start": "1866360",
    "end": "1873159"
  },
  {
    "text": "for you um the best place to start would be Amazon Kinesis streams um it it turns",
    "start": "1873159",
    "end": "1879399"
  },
  {
    "text": "out to be the lowest cost option you know the best way to test this out is for example in the pricing examples for",
    "start": "1879399",
    "end": "1884799"
  },
  {
    "text": "every service we give you this little pricing example of the one in many any scenarios you can take actually the same pricing example and run through various",
    "start": "1884799",
    "end": "1891240"
  },
  {
    "text": "services and cost out how much that's going to cost when I actually took the pricing example for kinis like 100",
    "start": "1891240",
    "end": "1896720"
  },
  {
    "text": "requests per second 35k payload and then ran it across all the services Kinesis bill was $52 or something like that",
    "start": "1896720",
    "end": "1904120"
  },
  {
    "text": "whereas if I did the same thing in sqs before the price reduction it was around $300 plus dollar or so if I actually did",
    "start": "1904120",
    "end": "1911639"
  },
  {
    "text": "this in dynamodb streams and skipped all the data all the you know 10 terabytes of data will get collected if you write",
    "start": "1911639",
    "end": "1918000"
  },
  {
    "text": "the rate of you know 10 100 requests per second you know but 24 hours a day you know 35k per thing is 10 terabyt of data",
    "start": "1918000",
    "end": "1926000"
  },
  {
    "text": "itself will cost you on just a storage alone $2,500 so unless if you use Dynamo",
    "start": "1926000",
    "end": "1931159"
  },
  {
    "text": "DB for dding what that tells me is I need to if if all the dding functionality is what I'm using for",
    "start": "1931159",
    "end": "1936679"
  },
  {
    "text": "Dynamo and then the stream functionality I I should quickly purchase that in S3 and then delete all the old data then",
    "start": "1936679",
    "end": "1942320"
  },
  {
    "text": "you will not spend that $2,500 in Dynamo so essentially the the summary is if you're simply doing streaming data I",
    "start": "1942320",
    "end": "1948799"
  },
  {
    "text": "would say Tau with Kinesis streams likely you will not go wrong unless you know something doesn't work there you",
    "start": "1948799",
    "end": "1954760"
  },
  {
    "text": "have other options there as well similarly sqs uh for example has 14 days",
    "start": "1954760",
    "end": "1960200"
  },
  {
    "text": "of uh data retention in some cases people don't they you need just a buffering solution uh they don't want to",
    "start": "1960200",
    "end": "1965679"
  },
  {
    "text": "provision anything or manage any provisioning uh sqs Works fairly well as a nicely decoupling mechanism for",
    "start": "1965679",
    "end": "1971159"
  },
  {
    "text": "messaging or streaming data as well so I'll leave that um for your you know further reference U the new kin say fif",
    "start": "1971159",
    "end": "1978519"
  },
  {
    "text": "qes have a limitation of 30 300 transactions per second uh per que um",
    "start": "1978519",
    "end": "1984240"
  },
  {
    "text": "that's a that's a hard limit we're working on actually make that making that bigger is what the team tells me so but nevertheless those are the things",
    "start": "1984240",
    "end": "1990480"
  },
  {
    "text": "that you need to be aware of I thought I will just basically you know leave this for your future reference now what about",
    "start": "1990480",
    "end": "1996399"
  },
  {
    "start": "1995000",
    "end": "2106000"
  },
  {
    "text": "file storage um if you're talking about you know the best place to put your data for",
    "start": "1996399",
    "end": "2001480"
  },
  {
    "text": "files is Amazon S3 uh S3 is quickly becoming the hdfs for big data on on AWS",
    "start": "2001480",
    "end": "2008960"
  },
  {
    "text": "because it is natively supported by all the data you know Big Data Frameworks such as parai Presto Etc and then um you",
    "start": "2008960",
    "end": "2017159"
  },
  {
    "text": "know Impala did not have the support they've actually put in the support as well for S3 I believe and then the beautiful aspect of S3 is that it allows",
    "start": "2017159",
    "end": "2024399"
  },
  {
    "text": "you to decouple compute from Storage so other words you need to you don't have to run this Hadoop cluster keeping the",
    "start": "2024399",
    "end": "2030159"
  },
  {
    "text": "storage you can turn off your Hadoop cluster if you're not doing any processing your data still lives in S3",
    "start": "2030159",
    "end": "2036600"
  },
  {
    "text": "with 119s durability and um and four NES availability and you can also compress",
    "start": "2036600",
    "end": "2043480"
  },
  {
    "text": "the data and you can use your own key for encrypting the data or you can or you can let us manage the keys for you",
    "start": "2043480",
    "end": "2050200"
  },
  {
    "text": "and uh it also has tiering options you can have S3 infrequent access if you basically set a policy it will",
    "start": "2050200",
    "end": "2056878"
  },
  {
    "text": "automatically move the data between the tiers we also announce some features to actually guide you as to how you should",
    "start": "2056879",
    "end": "2062560"
  },
  {
    "text": "be you know moving this data rapidly into infrequent access or Glacier Etc so",
    "start": "2062560",
    "end": "2069000"
  },
  {
    "text": "um suffice to say um there needs to be a good reason not to put data in S3 um",
    "start": "2069000",
    "end": "2075679"
  },
  {
    "text": "starting with S3 is almost always the right answer for your file data on AWS and it also allows you to use spot",
    "start": "2075679",
    "end": "2084200"
  },
  {
    "text": "instances so since you don't have to have this cluster running if you if we pull off the spot instance from you because the spot spot Market went up you",
    "start": "2084200",
    "end": "2091800"
  },
  {
    "text": "can simply request for a more instance and keep continuing processing or you can come back and process that later",
    "start": "2091800",
    "end": "2096919"
  },
  {
    "text": "when the spot price actually dips down again so nicely decoupled the key point is S3 allows you to decouple storage",
    "start": "2096919",
    "end": "2103240"
  },
  {
    "text": "from compute and um sometimes you need a little more speed you know hdfs is",
    "start": "2103240",
    "end": "2109079"
  },
  {
    "start": "2106000",
    "end": "2181000"
  },
  {
    "text": "slight faster than S3 on a on a you know if you don't actually parallelize it for",
    "start": "2109079",
    "end": "2114520"
  },
  {
    "text": "example um so many cases customers still use hdfs as sort of intermediate store",
    "start": "2114520",
    "end": "2120480"
  },
  {
    "text": "between multiple processing stages and then you know you do all the processing and then eventually store the data in S3",
    "start": "2120480",
    "end": "2127400"
  },
  {
    "text": "and then shut down the cluster if you don't need it and then as I said before you can also set a policy uh in S3",
    "start": "2127400",
    "end": "2134079"
  },
  {
    "text": "saying you know let's assume you you know you you all the less frequently used data for 6 months you don't tend to",
    "start": "2134079",
    "end": "2139240"
  },
  {
    "text": "use your data set that often then you can set a policy saying all these prefixes go ahead and move them to S3",
    "start": "2139240",
    "end": "2145680"
  },
  {
    "text": "infrequent Axis or you can move them to glaciate infrequent axis with the price reduction S3 is about 2.3 cents per",
    "start": "2145680",
    "end": "2152520"
  },
  {
    "text": "gigabyte per month uh S3 infrequent access I believe is 1.5 cents per GB per month and and then also the S3 uh the",
    "start": "2152520",
    "end": "2160160"
  },
  {
    "text": "glacier is um I think 410 per penny per gigabyte per month right so you get",
    "start": "2160160",
    "end": "2166920"
  },
  {
    "text": "immense I said don't delete anything now it's you need to aggressively Implement your policies to move you your data",
    "start": "2166920",
    "end": "2173599"
  },
  {
    "text": "between multiple tiers so that you know you're paying the right cost you know for the W for the gold which is the data",
    "start": "2173599",
    "end": "2179480"
  },
  {
    "text": "that you have and then what about inmemory databases uh let me go back a",
    "start": "2179480",
    "end": "2184920"
  },
  {
    "start": "2181000",
    "end": "2267000"
  },
  {
    "text": "little bit what about inmemory databases and uh database the classic database and search um in terms of the this is the",
    "start": "2184920",
    "end": "2192720"
  },
  {
    "text": "anti pattern in other words don't do this um so I love sus armi knives those are beautiful and nice gifts and uh that",
    "start": "2192720",
    "end": "2201560"
  },
  {
    "text": "picture I'm passionate about I got this from the Amazon site and that thing cost about $800 um a few years ago I don't",
    "start": "2201560",
    "end": "2208040"
  },
  {
    "text": "know if we sell them anymore it was called the big sus armi knife um if you have a big screw uh one way of actually",
    "start": "2208040",
    "end": "2215400"
  },
  {
    "text": "dealing with that is to buy a screwdriver and the other way is to actually get a big SS army knife the",
    "start": "2215400",
    "end": "2221079"
  },
  {
    "text": "difference is a screwdriver May cost you about $10 or whatever it is um but then this one is $800 when I L looked at it",
    "start": "2221079",
    "end": "2227599"
  },
  {
    "text": "so the point is relational databases have been around for 30 plus years they still work very well they have a very",
    "start": "2227599",
    "end": "2232880"
  },
  {
    "text": "valuable function um but uh there's not a it's not a good reason to use",
    "start": "2232880",
    "end": "2238280"
  },
  {
    "text": "relational databases for everything you know the most of the ad serving scenarios people serve ads at a mill you know million requests per second if you",
    "start": "2238280",
    "end": "2244920"
  },
  {
    "text": "need to use a relational database first you don't probably have a relational database I don't know about anything that will serve a million requests per second number two if in Dynamo DB you",
    "start": "2244920",
    "end": "2252319"
  },
  {
    "text": "can just say give me a million requests per second and then 100,000 rights per second and pay for exactly what you use",
    "start": "2252319",
    "end": "2257920"
  },
  {
    "text": "and that's not possible this you need to scale for one dimension and you need to get all these other things for free that you'll never use uh but still pay for it",
    "start": "2257920",
    "end": "2264800"
  },
  {
    "text": "right so not a good idea instead um you know thinking of your data tier as",
    "start": "2264800",
    "end": "2270680"
  },
  {
    "text": "comprising of multiple things such as IM memory no SQL SQL and search uh is a",
    "start": "2270680",
    "end": "2276160"
  },
  {
    "text": "pretty important pretty important Paradigm now even it's easy to say this but now where do you put your data",
    "start": "2276160",
    "end": "2282720"
  },
  {
    "text": "really um and um that's why we have all these four services for example elastic",
    "start": "2282720",
    "end": "2288920"
  },
  {
    "text": "cach is a fully managed service for running either redis or mcash we also recently introduced redis clusters you",
    "start": "2288920",
    "end": "2294720"
  },
  {
    "text": "know super important ask from a lot of our customers um worth taking a look at",
    "start": "2294720",
    "end": "2299800"
  },
  {
    "text": "it again as I mentioned Dynamo DB is a fully managed nosql database service RDS is a relational database service which",
    "start": "2299800",
    "end": "2305480"
  },
  {
    "text": "is fully managed we have various engines um postc crust MySQL SQL Server Oracle uh marad DB Etc",
    "start": "2305480",
    "end": "2315720"
  },
  {
    "text": "and we also have Amazon RDS for Aurora you know which is we've completely redesigned the storage subsystem as well",
    "start": "2315720",
    "end": "2322680"
  },
  {
    "text": "as the logging subsystem to scale out uh their database till it has a MySQL interface we also recently introduced uh",
    "start": "2322680",
    "end": "2329440"
  },
  {
    "text": "RDS Aurora for postc cross uh Sora is a 64 you know the maximum size is 64",
    "start": "2329440",
    "end": "2334839"
  },
  {
    "text": "terabytes if you had 16 read replicas you you can do in the order of about you know more than a million reads per",
    "start": "2334839",
    "end": "2340960"
  },
  {
    "text": "second and then almost about 100,000 wrs per second in in in using a relational system um RDS uh family of services and",
    "start": "2340960",
    "end": "2350079"
  },
  {
    "text": "then Amazon elastic search service is a fully managed service for running your elastic search elastic search is super",
    "start": "2350079",
    "end": "2355200"
  },
  {
    "text": "popular a lot of our customers love that the fact that we manage the Clusters uh on their behalf and uh now which data",
    "start": "2355200",
    "end": "2362560"
  },
  {
    "start": "2361000",
    "end": "2420000"
  },
  {
    "text": "store should I use well it depends upon you know your data structure access pth pattern you know your data",
    "start": "2362560",
    "end": "2368599"
  },
  {
    "text": "characteristics hot warm or cold and the cost um you know this access pattern modeling I've done a lot of Dynamo DB",
    "start": "2368599",
    "end": "2374960"
  },
  {
    "text": "design reviews the essence of the review is really finding out what the y u the",
    "start": "2374960",
    "end": "2380480"
  },
  {
    "text": "question goes like this can you please tell me you know what what are the final queries you're going to run with this",
    "start": "2380480",
    "end": "2386200"
  },
  {
    "text": "database then you start designing your data structures your key patterns for the end end access that is required when",
    "start": "2386200",
    "end": "2392520"
  },
  {
    "text": "somebody comes to you know use a no SQL database they either they need speed and",
    "start": "2392520",
    "end": "2397599"
  },
  {
    "text": "scale which is usually the you know pair amount for them that's why they're using no SQL um anyway and then starting with",
    "start": "2397599",
    "end": "2406079"
  },
  {
    "text": "the end in mind makes a lot of sense so what I've learned you know doing this data business for 25 plus years is that",
    "start": "2406079",
    "end": "2411680"
  },
  {
    "text": "storing the data in the most efficient form it is accessed is usually the right answer for many scenarios the fancy name",
    "start": "2411680",
    "end": "2417440"
  },
  {
    "text": "for that is materialized use um so now what structure if you have put get value",
    "start": "2417440",
    "end": "2423359"
  },
  {
    "start": "2420000",
    "end": "2490000"
  },
  {
    "text": "if you have simply doing puts and gets using either a no SQL or in memory database us usually the right answer if",
    "start": "2423359",
    "end": "2428720"
  },
  {
    "text": "you have a simple query pattern like one to many you know parent child relationships or many to many and then",
    "start": "2428720",
    "end": "2434560"
  },
  {
    "text": "usually a no SQL Works fairly well um if you have you know complex quides and",
    "start": "2434560",
    "end": "2440960"
  },
  {
    "text": "transactions and Joints um obviously the good old relational database works extremely well and um and then if you",
    "start": "2440960",
    "end": "2449480"
  },
  {
    "text": "have fating if you go to amazon.com on the left side we give you you know when you search for something we facet that",
    "start": "2449480",
    "end": "2455280"
  },
  {
    "text": "by you know is this Prime enabled is this by seller a b or c all that fating",
    "start": "2455280",
    "end": "2460520"
  },
  {
    "text": "is very well done by you know search search engines they are op super optimized for doing fating and searching",
    "start": "2460520",
    "end": "2466720"
  },
  {
    "text": "there's no point in running SQL queries to do fating and searching the best thing to do is to actually use a search engine to do fating because fating is a",
    "start": "2466720",
    "end": "2473880"
  },
  {
    "text": "first class data type the indexes are primed for doing fating and similarly if",
    "start": "2473880",
    "end": "2479160"
  },
  {
    "text": "you have a you know fixed schema using SQL or no SQL makes sense schema free which is Json um no SQL or search works",
    "start": "2479160",
    "end": "2486599"
  },
  {
    "text": "fairly well and key value memory or no SQL Works Fair well um when somebody reviewed this slide they said this is",
    "start": "2486599",
    "end": "2492760"
  },
  {
    "start": "2490000",
    "end": "2647000"
  },
  {
    "text": "the ugliest slide that they have done this is like telling your baby's ugly you know I thought really very hard to",
    "start": "2492760",
    "end": "2499240"
  },
  {
    "text": "make this slide and um and so well being a little bit upset I still you know it's",
    "start": "2499240",
    "end": "2505560"
  },
  {
    "text": "my baby so I want to keep the slide right so the idea here is that I I was trying to convey my idea of like a",
    "start": "2505560",
    "end": "2511680"
  },
  {
    "text": "multi-dimensional thing you know the structure of the data is high and low on the left side I have an AIS you know low",
    "start": "2511680",
    "end": "2518480"
  },
  {
    "text": "data structure and S3 it's a simple key value it's a low data structure if you go down it's a higher structure you know",
    "start": "2518480",
    "end": "2523920"
  },
  {
    "text": "you put complex structures in like search engines on the bottom you have you have all the parameters that I used",
    "start": "2523920",
    "end": "2529760"
  },
  {
    "text": "for hot and warm you know request rate cost per gigabyte latency data volume you know the way I think about imagine",
    "start": "2529760",
    "end": "2535880"
  },
  {
    "text": "all the services having been a builder as well we tend to build a spectrum of services right starting from in memory",
    "start": "2535880",
    "end": "2543040"
  },
  {
    "text": "no SQL surge S3 Etc there's a bit of an overlap between the services in some cases when you're",
    "start": "2543040",
    "end": "2549079"
  },
  {
    "text": "building a system you could do this in either a SQL or a search in other places as well so as a designer that gives me",
    "start": "2549079",
    "end": "2556000"
  },
  {
    "text": "an idea of when I'm talking to customers I'm Al always factoring in where is this workload belong is this a hot data set",
    "start": "2556000",
    "end": "2561520"
  },
  {
    "text": "is this structured or non-structured so I'm basically going into this two-dimensional or end dimensional space",
    "start": "2561520",
    "end": "2566680"
  },
  {
    "text": "and sort of you know that's how I was able to paint my brain you maybe it's ugly inside but so now what I've done this is that",
    "start": "2566680",
    "end": "2574040"
  },
  {
    "text": "actually painted that same hot cold I used spefic Services here and I've actually given those various attributes",
    "start": "2574040",
    "end": "2581559"
  },
  {
    "text": "you know latency typical data set storage size request rate Etc I'm not going to go through you know all of this",
    "start": "2581559",
    "end": "2587440"
  },
  {
    "text": "for the sake of time um but I'm going to leave this here the basic idea is if you want to basically have a millisecond CL",
    "start": "2587440",
    "end": "2594559"
  },
  {
    "text": "level access you know uh 1 millisecond or less typically elastic search would be a good place to start whereas if you",
    "start": "2594559",
    "end": "2600760"
  },
  {
    "text": "know if you look at the durability wise you know for example somebody asked me the other day in one of the design one",
    "start": "2600760",
    "end": "2606040"
  },
  {
    "text": "of the ebcs here um briefing review is like I'm I'm really getting confused should I put my data in in elastic search or Dynamo DB I",
    "start": "2606040",
    "end": "2614720"
  },
  {
    "text": "told them if durability is super important for you and this is this is the crown gel of your company I would",
    "start": "2614720",
    "end": "2620680"
  },
  {
    "text": "pick a store that is bulletproof in terms of durability for me that's Dynamo DB and then you should simply maybe have",
    "start": "2620680",
    "end": "2626800"
  },
  {
    "text": "a view or do your caching using your elastic cache but you should actually stick your data into Dynamo DB um and so",
    "start": "2626800",
    "end": "2635640"
  },
  {
    "text": "because if you look at this graph it's says durability would be low to moderate in the case of elastic search durability is very high that is the right answer",
    "start": "2635640",
    "end": "2642280"
  },
  {
    "text": "for this for this for this scenario this is an example um I want to move on to the next slide uh now this is the this",
    "start": "2642280",
    "end": "2648640"
  },
  {
    "start": "2647000",
    "end": "2694000"
  },
  {
    "text": "is where the quiz comes in right so this is a question that some customer sent me the person is trying to decide between",
    "start": "2648640",
    "end": "2654599"
  },
  {
    "text": "Amazon S3 and Dynamo DB um you know is they're scoping for the new project um",
    "start": "2654599",
    "end": "2660040"
  },
  {
    "text": "you know in terms of this is if you if you boil this down it turns out they're doing 300 rights per second 2K payload",
    "start": "2660040",
    "end": "2666400"
  },
  {
    "text": "1.5 terabytes of data they will store per month and then the number of objects stored is 777 million which data store",
    "start": "2666400",
    "end": "2672839"
  },
  {
    "text": "should you use uh how many think it's S3 a few hands here 1 2 3 4 S3 anybody a",
    "start": "2672839",
    "end": "2680359"
  },
  {
    "text": "few hands over there um I mean the sad news is that one one of one of this is",
    "start": "2680359",
    "end": "2686160"
  },
  {
    "text": "the winner for now still S three how many say Dynamo DB a few more hands um anytime that",
    "start": "2686160",
    "end": "2694800"
  },
  {
    "start": "2694000",
    "end": "2803000"
  },
  {
    "text": "there's a tie there's this beautiful thing called called a simple monthly calculator um it's not perfect it's not",
    "start": "2694800",
    "end": "2701000"
  },
  {
    "text": "perfect some cases I had to run my own Python program to actually you know find out the cost uh but but it's a it's a",
    "start": "2701000",
    "end": "2707520"
  },
  {
    "text": "good start if you plug in those numbers it basically tells me $644 is the Dynamo",
    "start": "2707520",
    "end": "2713000"
  },
  {
    "text": "DB cost whereas an S3 is going to be 3,932 uh people who said S3",
    "start": "2713000",
    "end": "2719960"
  },
  {
    "text": "unfortunately you lost this one right uh it turns out that they were thinking right they were thinking storage um it",
    "start": "2719960",
    "end": "2727000"
  },
  {
    "text": "only cost $44 for storage if you use S3 but turns out that the put prices is",
    "start": "2727000",
    "end": "2732520"
  },
  {
    "text": "$3,888 when I actually showed this slide to the S3 product manager the person was",
    "start": "2732520",
    "end": "2738119"
  },
  {
    "text": "pretty unhappy that I'm going to present this to 500 plus people and tell them don't use S3 so I do did have to put a",
    "start": "2738119",
    "end": "2744680"
  },
  {
    "text": "compensating scenario so so I changed the game so I basically even though the",
    "start": "2744680",
    "end": "2750160"
  },
  {
    "text": "customer requirement was first I came up with another requirement saying that the size of the payload is 32k it turns out",
    "start": "2750160",
    "end": "2756119"
  },
  {
    "text": "S3 is the winner in that scenario you know because you know Dynamo DB is very",
    "start": "2756119",
    "end": "2761440"
  },
  {
    "text": "good for smaller data sets moving really really fast but when the payload becomes very large DB can handle it too 35k it",
    "start": "2761440",
    "end": "2768440"
  },
  {
    "text": "can go until 400k but what happens is the price increases because you know um",
    "start": "2768440",
    "end": "2773880"
  },
  {
    "text": "it's so that in in this case clearly what our pricing tells you is you know",
    "start": "2773880",
    "end": "2779240"
  },
  {
    "text": "go ahead and pick Dynamo S3 when the payload is fairly high and Dynamo DB when when the payload is small low and",
    "start": "2779240",
    "end": "2786480"
  },
  {
    "text": "usually that that is the right answer if you if you if you're going through all the details I'm going to leave it leave it for thinking this is just a small",
    "start": "2786480",
    "end": "2792400"
  },
  {
    "text": "example it's a real example and but you know the same example applies in many",
    "start": "2792400",
    "end": "2797920"
  },
  {
    "text": "many scenarios that you will go through especially if there's a conflict of using potentially two services so quickly going through",
    "start": "2797920",
    "end": "2804359"
  },
  {
    "start": "2803000",
    "end": "2937000"
  },
  {
    "text": "process and analyze um you know you're dealing with either batch processing and interact in the case of batch processing",
    "start": "2804359",
    "end": "2809760"
  },
  {
    "text": "using map produce high or pig is the right answer in the case of interactive analytics uh Amazon red shift Amazon",
    "start": "2809760",
    "end": "2816240"
  },
  {
    "text": "Athena belong there in the case of interactive analytics and then or you can run Amazon elastic map ruce uh with",
    "start": "2816240",
    "end": "2822240"
  },
  {
    "text": "either Presto or spark and um um in the case of messaging you know writing an",
    "start": "2822240",
    "end": "2828520"
  },
  {
    "text": "sqs app either in ter terms of elastic beant elastic beanock could be a container for actually running your app",
    "start": "2828520",
    "end": "2835160"
  },
  {
    "text": "processing messages that usually works out fairly well uh in the case of stream processing you have a lot of options you",
    "start": "2835160",
    "end": "2841000"
  },
  {
    "text": "know starting with Kinesis analytics is a fairly new service that we launched um and then it's serverless and so on",
    "start": "2841000",
    "end": "2847359"
  },
  {
    "text": "uh or you could use you know uh spark streaming or you could use AWS Lambda",
    "start": "2847359",
    "end": "2852440"
  },
  {
    "text": "stom and Kinesis client Library based apps in the case of machine learning spark ml is super popular uh in",
    "start": "2852440",
    "end": "2859880"
  },
  {
    "text": "conjunction with spark ml you can also use Amazon ml we're also releasing a slew of services um you know machine",
    "start": "2859880",
    "end": "2867160"
  },
  {
    "text": "learning managed Services as well as well as um you know other services as well so we'll see how to tie that into",
    "start": "2867160",
    "end": "2873520"
  },
  {
    "text": "the pipeline so this is again a chart of Wist stream and the messaging store that you should use and um again here I have",
    "start": "2873520",
    "end": "2880559"
  },
  {
    "text": "given you multiple Dimensions here so if you look at you know if you want server less there's two choices Amazon Kinesis",
    "start": "2880559",
    "end": "2886359"
  },
  {
    "text": "analytics or AWS Lambda and then if you look at um so basically based on the",
    "start": "2886359",
    "end": "2892119"
  },
  {
    "text": "kind of processing that you that you want to do uh you can pick the right answer so I would say you know if you're",
    "start": "2892119",
    "end": "2898880"
  },
  {
    "text": "doing you know general purpose stream processing that needs to infinitely scale U you know clearly KCl and you've",
    "start": "2898880",
    "end": "2905839"
  },
  {
    "text": "using IF if it's Kinesis you're using using Kinesis client library application or spark streaming would work very very",
    "start": "2905839",
    "end": "2912359"
  },
  {
    "text": "well if you're using spark streaming you should be aware that that runs in a single a if you're running this on top",
    "start": "2912359",
    "end": "2917720"
  },
  {
    "text": "of EMR so if you need multi-az or multi data center availability you need to be able to run another cluster when one",
    "start": "2917720",
    "end": "2925160"
  },
  {
    "text": "data center goes down and you need to have both clusters processing that and persist that data in a common store to",
    "start": "2925160",
    "end": "2930480"
  },
  {
    "text": "be able to do that so I think those are all the parameters that were super helpful I'm not going to go through each and every detail but this is for your",
    "start": "2930480",
    "end": "2936079"
  },
  {
    "text": "reference uh similarly what analysis tool should I use we launched Amazon Athena uh Amazon",
    "start": "2936079",
    "end": "2942200"
  },
  {
    "start": "2937000",
    "end": "3019000"
  },
  {
    "text": "ethena is a fantastic tool for using ad hoc and interactive queries basically",
    "start": "2942200",
    "end": "2948000"
  },
  {
    "text": "you put your data in S3 you could use any of those data formats it could be CSV it could be tsv could be Json park",
    "start": "2948000",
    "end": "2955000"
  },
  {
    "text": "or orc Park and orc or columnar formats or it could be even an Apache web log so",
    "start": "2955000",
    "end": "2960280"
  },
  {
    "text": "you can use the right Sur when you create an external table you'll say create external table with the specific",
    "start": "2960280",
    "end": "2965839"
  },
  {
    "text": "survey you know serializer D serializer and then off you go running queries you know we keep that metadata definition in",
    "start": "2965839",
    "end": "2972280"
  },
  {
    "text": "Thea catalog and you can you can run queries um and then materialize results",
    "start": "2972280",
    "end": "2978000"
  },
  {
    "text": "uh if you have a classic data warehouse workload Amazon red shift is the best place to put that data and then if you",
    "start": "2978000",
    "end": "2983720"
  },
  {
    "text": "have general purpose workload with a lot of iterations that you want to build in machine learning uh you want to also",
    "start": "2983720",
    "end": "2989599"
  },
  {
    "text": "combine Real Time with machine learning you know spark Works fairly well and um",
    "start": "2989599",
    "end": "2995280"
  },
  {
    "text": "you know for example um um Netflix uses a 60 paby data workhouse that they have",
    "start": "2995280",
    "end": "3001559"
  },
  {
    "text": "that they built on top of presto and EMR right you know fantastic tool again for",
    "start": "3001559",
    "end": "3006839"
  },
  {
    "text": "for uh for for processing for running interactive queries so sort of that's sort of how I think about this is all",
    "start": "3006839",
    "end": "3012880"
  },
  {
    "text": "the these are all the specific attributes that were quite helpful in making decisions for me so I've documented this for your future",
    "start": "3012880",
    "end": "3018680"
  },
  {
    "text": "reference and uh now what about ETL right uh obviously you saw the glue announcement uh in combination with glue",
    "start": "3018680",
    "end": "3026400"
  },
  {
    "start": "3019000",
    "end": "3048000"
  },
  {
    "text": "uh we have amazing Partners in that space you know starting with alter X you know Udi Informatica these are all",
    "start": "3026400",
    "end": "3032760"
  },
  {
    "text": "various names that you know lot of ETL amazing ETL vendors that we have in",
    "start": "3032760",
    "end": "3038040"
  },
  {
    "text": "addition we also launched the AWS glue which will also you know be super",
    "start": "3038040",
    "end": "3043240"
  },
  {
    "text": "helpful for for ETL I'm not going to go into the details of this I'm going to leave it at that for now and move on on",
    "start": "3043240",
    "end": "3048720"
  },
  {
    "start": "3048000",
    "end": "3122000"
  },
  {
    "text": "the consumes on the consume tier now we we talked about storage and processing uh we're going to go through consumption",
    "start": "3048720",
    "end": "3054559"
  },
  {
    "text": "quickly and then the two classes of users or perhaps more the main classes or business users are going to go",
    "start": "3054559",
    "end": "3060720"
  },
  {
    "text": "through some kind of a UI you know it could be Tableau or it could be quick site uh that wner showed this morning or",
    "start": "3060720",
    "end": "3067119"
  },
  {
    "text": "it could be looker or micro strategy Etc actually slicing and dicing the data that you put in your data tier such as",
    "start": "3067119",
    "end": "3074040"
  },
  {
    "text": "you know RDS or on bread shift being able to materialize and answer and most",
    "start": "3074040",
    "end": "3079680"
  },
  {
    "text": "recently notebooks are getting fairly popular we have a number of articles in the AWS Big Data blog this is a",
    "start": "3079680",
    "end": "3085200"
  },
  {
    "text": "fantastic place for your reference we keep you know launching multiple blogs per week um and then we have a number of",
    "start": "3085200",
    "end": "3091480"
  },
  {
    "text": "blogs as to how do you run notebooks on top of elastic you know EMR for example",
    "start": "3091480",
    "end": "3096640"
  },
  {
    "text": "notebooks are getting fairly popular as well especially Jupiter and Zeppelin and our studio for data scientists is key",
    "start": "3096640",
    "end": "3103880"
  },
  {
    "text": "you know there are there are few talks actually in the Big Data track where people have gone through exactly how I",
    "start": "3103880",
    "end": "3109319"
  },
  {
    "text": "think it was fenra had one talk on this one probably Netflix might have touched on this aspect as well so there's",
    "start": "3109319",
    "end": "3115280"
  },
  {
    "text": "amazing talks on how do you enable these two classes of users in the Big Data track I'm going to leave that for as a",
    "start": "3115280",
    "end": "3120880"
  },
  {
    "text": "homework for you now putting it all together that's the fancy colorful picture reference architecture that I",
    "start": "3120880",
    "end": "3126880"
  },
  {
    "start": "3122000",
    "end": "3128000"
  },
  {
    "text": "came came with I'm going to show you a more fancy picture at the end you got to hold on to this okay so design patterns",
    "start": "3126880",
    "end": "3133799"
  },
  {
    "start": "3128000",
    "end": "3240000"
  },
  {
    "text": "the three Primitives I told you about you know one is the decoupled data pass it it should look like something like this tour process tour process should",
    "start": "3133799",
    "end": "3140119"
  },
  {
    "text": "repeat itself that's the first way of decoupling and um the second way is",
    "start": "3140119",
    "end": "3146040"
  },
  {
    "text": "using the PPS of Paradigm you know Kinesis put data and Kinesis have multiple consumers consuming that in",
    "start": "3146040",
    "end": "3151359"
  },
  {
    "text": "this case I've shown Amazon Kinesis connector Library as well as Lambda and Spark processing the same input parall",
    "start": "3151359",
    "end": "3157280"
  },
  {
    "text": "deriving various outputs that's the second way of decoupling those and the materialized views if you have a",
    "start": "3157280",
    "end": "3162680"
  },
  {
    "text": "framework that can access from multiple data stores in this case spark is materializing anwers that you put you",
    "start": "3162680",
    "end": "3169119"
  },
  {
    "text": "know data that you an answer from the data that you put in S3 and Dynamo DB and Kinesis and rendering a picture so",
    "start": "3169119",
    "end": "3175280"
  },
  {
    "text": "the idea of materialization and decoupling that from Storage makes a lot of sense in my mind so this is again",
    "start": "3175280",
    "end": "3183119"
  },
  {
    "text": "yeah beautiful or ugly depending upon how you see this um so what I'm trying to paint here is on the x-axis I have",
    "start": "3183119",
    "end": "3189280"
  },
  {
    "text": "various storage Services you know hot to warm to cold and then the y axis I have",
    "start": "3189280",
    "end": "3194920"
  },
  {
    "text": "various processing applications the combination of a hot store and a fast processing technology lends itself to",
    "start": "3194920",
    "end": "3202000"
  },
  {
    "text": "real-time processing and a combination of a warm store and a fast process processing technology lend itself to",
    "start": "3202000",
    "end": "3208720"
  },
  {
    "text": "interactive interactive query or analytics and the combination of um you know maybe hot or warm store uh cold",
    "start": "3208720",
    "end": "3216480"
  },
  {
    "text": "store with the batch processing which is slower processing stack allows you to do batch processing now we're going to",
    "start": "3216480",
    "end": "3223200"
  },
  {
    "text": "spend the next seven minutes actually going through like three different architecture types I'm going to draw it to the end but I'll take questions at",
    "start": "3223200",
    "end": "3228839"
  },
  {
    "text": "the end after and um so that's sort of a mental this is a mental map that I have",
    "start": "3228839",
    "end": "3233880"
  },
  {
    "text": "it's been quite helpful for a number of customers I mean that's a how I think about these various types of analytics",
    "start": "3233880",
    "end": "3239359"
  },
  {
    "text": "and um so um here is a classic stack for real-time analytics you're streaming data goes into Amazon Kinesis I'm going",
    "start": "3239359",
    "end": "3246160"
  },
  {
    "start": "3240000",
    "end": "3359000"
  },
  {
    "text": "to use only manage services here uh for obvious reasons and you can actually do instream ETL using Kinesis analytics on",
    "start": "3246160",
    "end": "3254319"
  },
  {
    "text": "that so basically you can run your SQL queries and just say you know from the incoming data stream go ahead and only",
    "start": "3254319",
    "end": "3260920"
  },
  {
    "text": "filter these one out or generate others other output based on that and you can stick that into another Kinesis stream",
    "start": "3260920",
    "end": "3267319"
  },
  {
    "text": "or a Kinesis fire hose right in this case I'm I'm doing real-time analytics I'm stick it back I'm going to stick this back into another Kinesis Stream So",
    "start": "3267319",
    "end": "3274520"
  },
  {
    "text": "once you have this in Kinesis stream again you can use all those applications that we went through now we did a comparison of the of that as well so",
    "start": "3274520",
    "end": "3280480"
  },
  {
    "text": "this is not a big menu in your case you're going to probably pick one of those right or perhaps two of those right either you could do a KCl or AWS",
    "start": "3280480",
    "end": "3288160"
  },
  {
    "text": "Lambda or spark running on top of elastic map reduced to actually process the data and you're going to store your",
    "start": "3288160",
    "end": "3294359"
  },
  {
    "text": "application state in in some kind of a you know storage subsystem it could be SQL or no SQL it could be cache such as",
    "start": "3294359",
    "end": "3302000"
  },
  {
    "text": "reddis or it could be elastic search and you're going to render a kpi uh using some kind of a drawing tool it could be",
    "start": "3302000",
    "end": "3308599"
  },
  {
    "text": "you know platform or you know some some D3 some some graphic you know grafting library and also you can also in some",
    "start": "3308599",
    "end": "3314920"
  },
  {
    "text": "cases people do fan out in other words they have you know an application all it does is simply take the data that comes",
    "start": "3314920",
    "end": "3321640"
  },
  {
    "text": "into Kinesis and puts that in another Kinesis Stream So if there have 20 teams processing that you have you need more",
    "start": "3321640",
    "end": "3327440"
  },
  {
    "text": "read throughput therefore you need to Fan out so you can actually fan it out using that Paradigm the most important",
    "start": "3327440",
    "end": "3333200"
  },
  {
    "text": "thing here is the log the arrow that's going to the log I always tell my customers write one simple application",
    "start": "3333200",
    "end": "3340400"
  },
  {
    "text": "that processes the data doesn't change anything and sticks there in S3 keep it as simple as you can and don't touch",
    "start": "3340400",
    "end": "3348079"
  },
  {
    "text": "it because data is gold is best to keep a copy of the data untouched in",
    "start": "3348079",
    "end": "3353319"
  },
  {
    "text": "someplace that you can always go back to if something something falls through super important and um in the case of",
    "start": "3353319",
    "end": "3360400"
  },
  {
    "start": "3359000",
    "end": "3439000"
  },
  {
    "text": "interactive analytics same kind of an idea your streaming data goes into Kinesis firose and then the firehost can",
    "start": "3360400",
    "end": "3366880"
  },
  {
    "text": "automatically transport the data to Red shift or S3 um and then what I've not shown here is elastic search um and you",
    "start": "3366880",
    "end": "3375400"
  },
  {
    "text": "can also if you're doing real-time predictions for example you can also the Paradigm of tying machine learning into",
    "start": "3375400",
    "end": "3381359"
  },
  {
    "text": "your thing is uh for being machine learning experts there's two aspects to it either you are the person building",
    "start": "3381359",
    "end": "3387359"
  },
  {
    "text": "the models or you're a user if you're a user it's like driving the car you don't need to find out you don't need to know how the car engine is assembled together",
    "start": "3387359",
    "end": "3394319"
  },
  {
    "text": "as long as you know how to drive a car what I presented here is if you have interactive analytics there are many",
    "start": "3394319",
    "end": "3399799"
  },
  {
    "text": "services that will that we have announced now and will come up with hopefully going forward that all you need to do is to send the user and ask",
    "start": "3399799",
    "end": "3407400"
  },
  {
    "text": "the question is this fraud or not fraud you'll get an answer back saying yes or no and that's all you need to know for",
    "start": "3407400",
    "end": "3412960"
  },
  {
    "text": "actually materializing the result now how do you generate the model how do you you tune this that's a separate separate thing so when I when I draw a line here",
    "start": "3412960",
    "end": "3419760"
  },
  {
    "text": "realtime predictions that's what I mean that the stack is passing the data and asking a question yes or no similarly",
    "start": "3419760",
    "end": "3425640"
  },
  {
    "text": "batch you can give a batch of users and say can you please classify them into fraudulent or nonf fraudulent users in your batch processing and this system",
    "start": "3425640",
    "end": "3432000"
  },
  {
    "text": "will come back and say well here's the location of all the thing that I did after after a little while then you can tie that into your Downstream system",
    "start": "3432000",
    "end": "3438280"
  },
  {
    "text": "right now for the famous thing data leak well I put a question mark there in",
    "start": "3438280",
    "end": "3443960"
  },
  {
    "start": "3439000",
    "end": "3535000"
  },
  {
    "text": "my first slide and somebody said remove the question mark and I removed that but nevertheless uh we're all trying to figure out what is the how do you do log",
    "start": "3443960",
    "end": "3451240"
  },
  {
    "text": "Centric processing how do you do the single um you know version of the truth the best thing is to basically have a",
    "start": "3451240",
    "end": "3458640"
  },
  {
    "text": "stream of data coming in having the original stream in S3 and then materializing the view and serving the",
    "start": "3458640",
    "end": "3465400"
  },
  {
    "text": "view to Downstream application is the main Paradigm there right and using all the principles that we we learned of",
    "start": "3465400",
    "end": "3471359"
  },
  {
    "text": "nicely decoupling systems along the way like wner pointed out there's always going to be silos of data you know but",
    "start": "3471359",
    "end": "3478000"
  },
  {
    "text": "having um a truth a single point of Truth in S3 in the most unprocessed",
    "start": "3478000",
    "end": "3483039"
  },
  {
    "text": "format and that is going to be the gold for your organization as long as you have that and it's very hard to just use",
    "start": "3483039",
    "end": "3489960"
  },
  {
    "text": "that to materialize every single answer in many cases you have to M you you have to have materialize this answer ahead of",
    "start": "3489960",
    "end": "3495039"
  },
  {
    "text": "time when you're when you're serving Downstream requests fairly fast you know what I've done here is simply combined",
    "start": "3495039",
    "end": "3501440"
  },
  {
    "text": "the interactive and a batch and then the real-time analytics and have nicely decoupled this with with with the",
    "start": "3501440",
    "end": "3507319"
  },
  {
    "text": "storage subsystem there to serve the answers in the case for Downstream applications so that's the essence in me",
    "start": "3507319",
    "end": "3513000"
  },
  {
    "text": "for me of a of a data Lake and um so um you know essentially transactions files",
    "start": "3513000",
    "end": "3520480"
  },
  {
    "text": "streams goes into your Lake and then you persist an original copy of that in S3 and then you transform that into various",
    "start": "3520480",
    "end": "3527240"
  },
  {
    "text": "Downstream using various drream application to render the views and downstream applications that you want to",
    "start": "3527240",
    "end": "3533359"
  },
  {
    "text": "serve I want to leave that that uh to summarize you know you should be Building decoupled Systems and um a",
    "start": "3533359",
    "end": "3541520"
  },
  {
    "start": "3535000",
    "end": "3599000"
  },
  {
    "text": "nicely decoupled pipeline is fairly important that lends you scale that lends you the ability to replace various",
    "start": "3541520",
    "end": "3547440"
  },
  {
    "text": "subsystem As you move along if you don't like your processing application today we announced atina if you're doing for",
    "start": "3547440",
    "end": "3553160"
  },
  {
    "text": "example all you're doing is running simple queries using Presto or something else then you can simply use atina",
    "start": "3553160",
    "end": "3559119"
  },
  {
    "text": "instead of that the basic assumption is as long as your data is in S3 you're good to go so if you nicely decouple",
    "start": "3559119",
    "end": "3564880"
  },
  {
    "text": "your system in S3 it should be tomorrow you should start using you know actually testing with this new service that we",
    "start": "3564880",
    "end": "3570839"
  },
  {
    "text": "launched and um using the right tool for the job is per amount we went through",
    "start": "3570839",
    "end": "3575920"
  },
  {
    "text": "you know I showed you various examples of various attributes that you need to compare and contrast to pick the right",
    "start": "3575920",
    "end": "3581400"
  },
  {
    "text": "tool in many cases it's not a menu quickly you'll narrow down to one or two Services then you can always break the",
    "start": "3581400",
    "end": "3586520"
  },
  {
    "text": "tie with that or go with one and um AWS manage services is key that gives you",
    "start": "3586520",
    "end": "3592000"
  },
  {
    "text": "the speed or agility and uh so you don't have to deal with you know managing the system Etc and um using log Centric design",
    "start": "3592000",
    "end": "3599960"
  },
  {
    "text": "patterns you know don't delete anything keep a copy of the logs uh because you",
    "start": "3599960",
    "end": "3605559"
  },
  {
    "text": "you never know what questions or what what machine learning models you may be building in the future and data as wner",
    "start": "3605559",
    "end": "3612000"
  },
  {
    "text": "pointed out this morning is the biggest differentiator because every other company is going to be using the same you know applications and services your",
    "start": "3612000",
    "end": "3618960"
  },
  {
    "text": "data is the gold and then keeping that safe as Paramount and keeping that in low cost services such as S3 And",
    "start": "3618960",
    "end": "3625079"
  },
  {
    "text": "archiving that to GL year is super important and be costc conscious with that I'm going to give you the most",
    "start": "3625079",
    "end": "3631079"
  },
  {
    "text": "colorful picture um that I've drawn so far uh you may hate or like this but",
    "start": "3631079",
    "end": "3637680"
  },
  {
    "text": "what I also did is put some legal blocks if you basically plug in the legal block I'm going to take Kinesis fire hose it",
    "start": "3637680",
    "end": "3643599"
  },
  {
    "text": "has this color um is should I should I call this pink or should I call this Violet I'm going",
    "start": "3643599",
    "end": "3650640"
  },
  {
    "text": "to call this Violet um that's going in it has a it has a v in there if you actually match that the the processing",
    "start": "3650640",
    "end": "3656280"
  },
  {
    "text": "layer that can access that is red shift right if you put in Kinesis you can actually you can see another layer that",
    "start": "3656280",
    "end": "3662200"
  },
  {
    "text": "actually Lego blocks into that uh Amazon red shift does that also kineses",
    "start": "3662200",
    "end": "3667640"
  },
  {
    "text": "analytics can process that so I tried to draw all kinds of lines uh connecting",
    "start": "3667640",
    "end": "3672680"
  },
  {
    "text": "them soon I couldn't read my slide so I went to a graphic designer and said can you please somehow you know tell me how",
    "start": "3672680",
    "end": "3679559"
  },
  {
    "text": "to abstract that and she came up with this Paradigm of these Lego blocks thing it's act pretty well so I'm pretty proud",
    "start": "3679559",
    "end": "3684960"
  },
  {
    "text": "of the Lego blocks with that I thank you for your time and I hope that was helpful and um really really appreciate",
    "start": "3684960",
    "end": "3692400"
  },
  {
    "text": "coming to the talk",
    "start": "3692400",
    "end": "3695920"
  }
]
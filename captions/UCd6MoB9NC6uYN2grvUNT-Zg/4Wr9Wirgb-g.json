[
  {
    "text": "good morning welcome and thanks for making it to my talk",
    "start": "4560",
    "end": "10719"
  },
  {
    "text": "the last day um so my name is sharma podilla i'm a software engineer at netflix",
    "start": "10719",
    "end": "17039"
  },
  {
    "text": "working on resource allocation and scheduling using apache mesos on amazon ec2",
    "start": "17039",
    "end": "25119"
  },
  {
    "text": "before netflix i also spent quite a bit of time doing resource allocation and scheduling work in a more data center environment at sun",
    "start": "25119",
    "end": "31679"
  },
  {
    "text": "and oracle regardless of data center or cloud apache mesos can be very useful for",
    "start": "31679",
    "end": "38800"
  },
  {
    "text": "deploying your applications by doing appropriate resource allocation scheduling so that's what we're going to",
    "start": "38800",
    "end": "44960"
  },
  {
    "text": "talk about we start a little bit with some context on why we're doing",
    "start": "44960",
    "end": "50719"
  },
  {
    "text": "this most of your familiar with how netflix",
    "start": "50719",
    "end": "56000"
  },
  {
    "text": "traffic can can be quite a bit in terms of scale at peak the us download traffic",
    "start": "56000",
    "end": "64000"
  },
  {
    "text": "more than 34 percent of it is netflix traffic in the us",
    "start": "64000",
    "end": "69920"
  },
  {
    "text": "and all of this traffic is enabled by a microservices architecture",
    "start": "69920",
    "end": "75439"
  },
  {
    "text": "that users come to and uh it gives the discovery of the movies and",
    "start": "75439",
    "end": "81360"
  },
  {
    "text": "playback and at this scale a lot of things can and will fail what we want to do",
    "start": "81360",
    "end": "89759"
  },
  {
    "text": "one of the things we want to do is detect signals like anomaly detection service health etc",
    "start": "89759",
    "end": "96000"
  },
  {
    "text": "and we not only want to detect big signals like how is the overall service health",
    "start": "96000",
    "end": "102880"
  },
  {
    "text": "or error percentage in any aspect but also want to do at smaller permutations",
    "start": "102880",
    "end": "111040"
  },
  {
    "text": "there's a lot of permutations also want to detect small signals that are important as well",
    "start": "111040",
    "end": "116320"
  },
  {
    "text": "in addition to the big signals we want to do it quickly and we want to do it cheap the infrastructure to detect signals and",
    "start": "116320",
    "end": "123119"
  },
  {
    "text": "alert us should be smaller than the infrastructure needed to run the services themselves",
    "start": "123119",
    "end": "129280"
  },
  {
    "text": "and we want to do it at scale so in order to do this as part of the",
    "start": "129280",
    "end": "136560"
  },
  {
    "text": "netflix edge engineering we are developing tools to detect and visualize the",
    "start": "136560",
    "end": "143520"
  },
  {
    "text": "service health for operational insights and in order to do that we're building",
    "start": "143520",
    "end": "149520"
  },
  {
    "text": "an event processing system that can let us run queries faceted queries on live",
    "start": "149520",
    "end": "156640"
  },
  {
    "text": "event streams and for that we're building um an apache",
    "start": "156640",
    "end": "163280"
  },
  {
    "text": "mesos framework to do optimal resource assignment for",
    "start": "163280",
    "end": "168560"
  },
  {
    "text": "the stream processing workload so an example of the visualization",
    "start": "168560",
    "end": "175680"
  },
  {
    "text": "we may have is for example this u.s map that shows us the service health in the u.s west and",
    "start": "175680",
    "end": "183360"
  },
  {
    "text": "east regions as an example so it provides an overall summary with some interesting charts at the bottom",
    "start": "183360",
    "end": "188879"
  },
  {
    "text": "right but then users also want to dig into a specific aspect of",
    "start": "188879",
    "end": "194000"
  },
  {
    "text": "it for example this shows a route summary on on various aspects of the",
    "start": "194000",
    "end": "201519"
  },
  {
    "text": "edge tier of the microservices architecture and users want to look at the summary of",
    "start": "201519",
    "end": "206720"
  },
  {
    "text": "all the routes look at the rps the latency percentiles etc",
    "start": "206720",
    "end": "212400"
  },
  {
    "text": "but users may also want to users as in netflix engineering who are trying to monitor the various aspects of the",
    "start": "212400",
    "end": "219040"
  },
  {
    "text": "service they also want to look at more specific aspects for example",
    "start": "219040",
    "end": "224080"
  },
  {
    "text": "how is the service doing for a specific ui maybe ps3 or xbox users on these devices",
    "start": "224080",
    "end": "231040"
  },
  {
    "text": "in a specific region or maybe also for a specific movie or",
    "start": "231040",
    "end": "237280"
  },
  {
    "text": "specific tv show and then they would submit a faceted query for",
    "start": "237280",
    "end": "243200"
  },
  {
    "text": "these and then they can start live streaming the service health and other anomaly detection for that",
    "start": "243200",
    "end": "250080"
  },
  {
    "text": "specific facets so today i'm going to talk about mantis",
    "start": "250080",
    "end": "257440"
  },
  {
    "text": "which is the stream processing infrastructure we're building i'm going to answer a couple of",
    "start": "257440",
    "end": "263440"
  },
  {
    "text": "questions that are very common when you start using apache mesos on an elastic cloud well why use",
    "start": "263440",
    "end": "270400"
  },
  {
    "text": "it to begin with we already have asgs that are pretty elastic maybe they can do the resource",
    "start": "270400",
    "end": "276080"
  },
  {
    "text": "allocation based on some cloud watch metrics and then for people familiar with apache",
    "start": "276080",
    "end": "281520"
  },
  {
    "text": "mesos there are already frameworks available and then the question is",
    "start": "281520",
    "end": "286880"
  },
  {
    "text": "do you need to develop another one or can you use a one that's existing we'll look at that and then some",
    "start": "286880",
    "end": "292479"
  },
  {
    "text": "specific challenges in the cloud and i'm going to basically spend more",
    "start": "292479",
    "end": "297759"
  },
  {
    "text": "time on the framework design apache mesos framework design and the",
    "start": "297759",
    "end": "303600"
  },
  {
    "text": "scheduling problem itself just a quick show of hands how many here already use apache mesas",
    "start": "303600",
    "end": "310080"
  },
  {
    "text": "either for test or production right there yeah okay there are some and",
    "start": "310080",
    "end": "316160"
  },
  {
    "text": "anyone here who is writing or intending to write in a framework for their workload okay",
    "start": "316160",
    "end": "324240"
  },
  {
    "text": "great all right so we'll definitely look at that and we'll talk about fenzo which is",
    "start": "324240",
    "end": "329280"
  },
  {
    "text": "our generic task scheduler that can be used by any framework and i'll show you some sample usages",
    "start": "329280",
    "end": "336400"
  },
  {
    "text": "so mantis is an even processing infrastructure um there are",
    "start": "337039",
    "end": "344000"
  },
  {
    "text": "other event processing systems already available in open source uh quite good ones when we looked at",
    "start": "344000",
    "end": "350840"
  },
  {
    "text": "those and looked at our specific use cases we felt that in the use cases being",
    "start": "350840",
    "end": "357919"
  },
  {
    "text": "anomaly detection operational insights to improve our customer experience",
    "start": "357919",
    "end": "362960"
  },
  {
    "text": "we felt that we needed to build a system that specifically addresses these",
    "start": "362960",
    "end": "369120"
  },
  {
    "text": "and what i mean is we needed it to be cloud native be auto scaling with the traffic that we",
    "start": "369120",
    "end": "375440"
  },
  {
    "text": "get based on the time of the day day of the week the traffic does vary quite a bit",
    "start": "375440",
    "end": "382638"
  },
  {
    "text": "and we wanted to do optimized scheduling of the resources for achieving what we",
    "start": "383440",
    "end": "390319"
  },
  {
    "text": "call stream locality i will talk about that and",
    "start": "390319",
    "end": "396080"
  },
  {
    "text": "also we felt that although some jobs require message delivery guarantees",
    "start": "396080",
    "end": "402720"
  },
  {
    "text": "such as exactly once delivery there are some jobs in operational insights that can trade",
    "start": "402720",
    "end": "409599"
  },
  {
    "text": "off these guarantees for increased speed and scale so for example if",
    "start": "409599",
    "end": "415280"
  },
  {
    "text": "there is a job that is doing percentile calculation it can handle a slight loss in",
    "start": "415280",
    "end": "421680"
  },
  {
    "text": "the data if it can scale much bigger and be much faster but some jobs do",
    "start": "421680",
    "end": "428960"
  },
  {
    "text": "require guaranteed delivery and there's both kind so we feel that the jobs can be allowed to specify what kind of",
    "start": "428960",
    "end": "435919"
  },
  {
    "text": "slas they need and the jobs themselves need to auto-scale",
    "start": "435919",
    "end": "440960"
  },
  {
    "text": "so if the traffic surges there's more data to evaluate",
    "start": "440960",
    "end": "446240"
  },
  {
    "text": "and therefore the job themselves need to scale up horizontally so all of these needs basically led us",
    "start": "446240",
    "end": "452960"
  },
  {
    "text": "to building a new system another interesting case for us is that",
    "start": "452960",
    "end": "458319"
  },
  {
    "text": "unlike other stream processing systems where a lot of times people are putting",
    "start": "458319",
    "end": "463919"
  },
  {
    "text": "the data into a queuing system such as kafka or others",
    "start": "463919",
    "end": "469039"
  },
  {
    "text": "we sometimes have so much data from the operational aspects that it's not",
    "start": "469039",
    "end": "475280"
  },
  {
    "text": "practical to put all of that into a queuing system instead what we do is when the jobs",
    "start": "475280",
    "end": "481599"
  },
  {
    "text": "are started when a stream processing job is started it sends a subscription all the way up to the actual service",
    "start": "481599",
    "end": "488160"
  },
  {
    "text": "instances that are running with a query and there could be multiple jobs each with different query",
    "start": "488160",
    "end": "494879"
  },
  {
    "text": "these all get subscriptions all the way up and then the actual app server starts streaming",
    "start": "494879",
    "end": "501599"
  },
  {
    "text": "the data that match that query so this makes it a bi-directional",
    "start": "501599",
    "end": "507360"
  },
  {
    "text": "a flow of information first with a subscription with a query and then the actual data streaming back",
    "start": "507360",
    "end": "514479"
  },
  {
    "text": "so just to get a big picture before we get into the details mantis is the even processing system",
    "start": "515519",
    "end": "521839"
  },
  {
    "text": "that uses fenzo which we'll talk about to do scheduling on top of apache mesas",
    "start": "521839",
    "end": "529839"
  },
  {
    "text": "and we have one or more asgs auto scaling groups that provide all of",
    "start": "529839",
    "end": "536160"
  },
  {
    "text": "the resources on which we're going to run them so in mantis a job is made up of",
    "start": "536160",
    "end": "544240"
  },
  {
    "text": "a source which is where the data is coming from one or more computation stages and then",
    "start": "544240",
    "end": "550240"
  },
  {
    "text": "eventually a sink where all the data is aggregated and made available to the users of that job",
    "start": "550240",
    "end": "557600"
  },
  {
    "text": "and each stage may have one or more workers it can horizontally scale and those are the workers that are tasks",
    "start": "557600",
    "end": "565920"
  },
  {
    "text": "that we're trying to schedule using mesos so a quick overview of what mesos",
    "start": "565920",
    "end": "571839"
  },
  {
    "text": "is there have been um",
    "start": "571839",
    "end": "577600"
  },
  {
    "text": "resource scheduling and allocation systems available so one thing that mesos does very",
    "start": "577600",
    "end": "582880"
  },
  {
    "text": "interestingly is that it separates our two related but different concepts of",
    "start": "582880",
    "end": "587920"
  },
  {
    "text": "resource allocation and scheduling so if you have a lot of",
    "start": "587920",
    "end": "593279"
  },
  {
    "text": "resources and then you have different use cases say a batch oriented workload",
    "start": "593279",
    "end": "598480"
  },
  {
    "text": "a service style jobs workload and an interactive workload you can allocate the resources among",
    "start": "598480",
    "end": "604720"
  },
  {
    "text": "them using a single mesos cluster and then let mesos give more and less",
    "start": "604720",
    "end": "610160"
  },
  {
    "text": "resources to each of those applications so it can help you do that instead of",
    "start": "610160",
    "end": "616320"
  },
  {
    "text": "completing segregating and bifurcating the resources",
    "start": "616320",
    "end": "622240"
  },
  {
    "text": "it also helps you develop distributed distributed applications easily where you can be given resources",
    "start": "622399",
    "end": "629360"
  },
  {
    "text": "as needed and then you can release them when you're done using them it makes it easier to develop such",
    "start": "629360",
    "end": "634880"
  },
  {
    "text": "applications and it simplifies basically running multiple types of applications in the",
    "start": "634880",
    "end": "641279"
  },
  {
    "text": "same cluster looking at the apache mesos architecture",
    "start": "641279",
    "end": "647120"
  },
  {
    "text": "there is a master that coordinates all of the resource allocation and then all of the resources",
    "start": "647120",
    "end": "652560"
  },
  {
    "text": "themselves are running in apache mesos slave process",
    "start": "652560",
    "end": "659040"
  },
  {
    "text": "and those uh advertise to the master what resources are available how many cpus memory uh the ports",
    "start": "659279",
    "end": "666320"
  },
  {
    "text": "available for networking disk etc and then there are applications written",
    "start": "666320",
    "end": "671600"
  },
  {
    "text": "on top of mesa's which are also called frameworks and",
    "start": "671600",
    "end": "676959"
  },
  {
    "text": "frameworks can register themselves into mesos to mesos master to get the resources",
    "start": "676959",
    "end": "683680"
  },
  {
    "text": "that they can use for launching tasks and a slave for example can run uh tasks",
    "start": "683680",
    "end": "688959"
  },
  {
    "text": "of one framework or multiple frameworks so there's definitely code tendency there and mesos uses the concept of containers",
    "start": "688959",
    "end": "697920"
  },
  {
    "text": "it could be docker container or it could be even a simple basic",
    "start": "697920",
    "end": "703600"
  },
  {
    "text": "linux c groups based container so that's how basically the architecture",
    "start": "703600",
    "end": "710240"
  },
  {
    "text": "looks so why use mesas on top of an elastic cloud",
    "start": "710240",
    "end": "715360"
  },
  {
    "text": "for us there are two reasons one is resource granularity tasks can have",
    "start": "715360",
    "end": "723519"
  },
  {
    "text": "various requirements single core multiple cores small memory large memory and some may",
    "start": "723519",
    "end": "730000"
  },
  {
    "text": "require better network throughput memory bandwidth etc there are",
    "start": "730000",
    "end": "735200"
  },
  {
    "text": "lots of instance types in ec2 however by the time sometimes you pick an instance type",
    "start": "735200",
    "end": "741120"
  },
  {
    "text": "that's say good for network throughput you automatically get more cores than you may need",
    "start": "741120",
    "end": "747040"
  },
  {
    "text": "you may need just one core and then you may have other tasks that are not as network intensive but need more course",
    "start": "747040",
    "end": "752240"
  },
  {
    "text": "and memory maybe and then you can actually bin pack them together so that's one good reason",
    "start": "752240",
    "end": "757519"
  },
  {
    "text": "one would want to use mesos on top of an elastic cloud and another reason for us is startup",
    "start": "757519",
    "end": "764000"
  },
  {
    "text": "latency getting a new instance could take a minute a few minutes",
    "start": "764000",
    "end": "770320"
  },
  {
    "text": "however starting a new task it could literally be in a few milliseconds so that's another good reason so now we",
    "start": "770320",
    "end": "777680"
  },
  {
    "text": "have a good reason to use mesas why develop a framework there are frameworks available in the",
    "start": "777680",
    "end": "783519"
  },
  {
    "text": "open source that people can straightaway use for running their applications using",
    "start": "783519",
    "end": "788959"
  },
  {
    "text": "mesos but there could be some reasons where you may want to develop your own",
    "start": "788959",
    "end": "796399"
  },
  {
    "text": "mesos did make it very easy to develop a new framework however what we feel is that if you",
    "start": "796720",
    "end": "802800"
  },
  {
    "text": "develop a framework that needs to scale be fault tolerant highly performant it does require",
    "start": "802800",
    "end": "808240"
  },
  {
    "text": "a long-term effort so that's the difference and scheduling itself can be a hard problem so we feel that there should be",
    "start": "808240",
    "end": "815519"
  },
  {
    "text": "a long-term reason to develop your own framework otherwise it's easier to use an existing open source framework",
    "start": "815519",
    "end": "821680"
  },
  {
    "text": "and maybe put in a request for enhancement or well write a little bit of card do pull",
    "start": "821680",
    "end": "827839"
  },
  {
    "text": "requests that's easier than trying to write the entire new framework so we had some reasons",
    "start": "827839",
    "end": "834160"
  },
  {
    "text": "uh that that were not addressed by previous frameworks and and then we developed our own",
    "start": "834160",
    "end": "840240"
  },
  {
    "text": "framework i'm going to talk about that um so generally in a cloud well most of",
    "start": "840240",
    "end": "846399"
  },
  {
    "text": "you are familiar with this um well the slave instances can be ephemeral",
    "start": "846399",
    "end": "851440"
  },
  {
    "text": "they're here they may be gone then you don't come you don't get the slain same slaves back so you need to be fault",
    "start": "851440",
    "end": "857920"
  },
  {
    "text": "tolerant as far as handling your tasks that we're running there high",
    "start": "857920",
    "end": "863360"
  },
  {
    "text": "availability is important we're going to talk about how that can be achieved",
    "start": "863360",
    "end": "868560"
  },
  {
    "text": "autoscaling the slave cluster this is definitely specific to a cloud um if you're running",
    "start": "868560",
    "end": "874720"
  },
  {
    "text": "it in an aztec cloud you don't want to allocate say a thousand resources thousand instances to your cluster and say that's",
    "start": "874720",
    "end": "880720"
  },
  {
    "text": "it that's for peak utilization but then you want to be auto scaling the cluster",
    "start": "880720",
    "end": "886560"
  },
  {
    "text": "and auto scaling is not a feature of the current frameworks available out there so that's",
    "start": "886560",
    "end": "891680"
  },
  {
    "text": "one good reason for us to develop this and scheduling itself has other challenges that we're going to talk",
    "start": "891680",
    "end": "897760"
  },
  {
    "text": "about so why is auto scaling a challenge why do i talk about auto scaling",
    "start": "897760",
    "end": "903920"
  },
  {
    "text": "when well there's already auto scaling groups here so unlike request response based processing",
    "start": "903920",
    "end": "910720"
  },
  {
    "text": "if you're running longer running tasks in using mesos or maybe their batch",
    "start": "910720",
    "end": "917279"
  },
  {
    "text": "workload or service style then you can't really just terminate some instances based on say",
    "start": "917279",
    "end": "925279"
  },
  {
    "text": "average system load because that would just terminate those tasks as well",
    "start": "925279",
    "end": "930560"
  },
  {
    "text": "you can only terminate instances that are running no tasks if you're doing request response then",
    "start": "930560",
    "end": "936720"
  },
  {
    "text": "it's easier you have an elb in front of it and then any failed request maybe can be",
    "start": "936720",
    "end": "942959"
  },
  {
    "text": "retried somewhere else but it's not the same for long-running tasks so suppose we had four instances",
    "start": "942959",
    "end": "949440"
  },
  {
    "text": "in our cluster just as a simple example and then we ended up with uh scheduling such that there are two",
    "start": "949440",
    "end": "957519"
  },
  {
    "text": "tasks on each of them and two idle cpus on each of them so we are using about 50",
    "start": "957519",
    "end": "963600"
  },
  {
    "text": "of the resources but none of the instances can be terminated whereas if i had a place them",
    "start": "963600",
    "end": "971199"
  },
  {
    "text": "differently such as this where i still use 50 utilization",
    "start": "971199",
    "end": "976959"
  },
  {
    "text": "but then i can now actually terminate two instances so this is a basic example of why auto",
    "start": "976959",
    "end": "983759"
  },
  {
    "text": "scaling is important to consider in scheduling using mesas and there could be other reasons",
    "start": "983759",
    "end": "989120"
  },
  {
    "text": "for example some tasks run long sometimes run short and if you end up with",
    "start": "989120",
    "end": "995839"
  },
  {
    "text": "a machine where there's two jobs that are long running and two are short running when the shortening jobs are done you",
    "start": "995839",
    "end": "1002000"
  },
  {
    "text": "still can scale down your cluster because they're still being used by those long running sas and then if you were to",
    "start": "1002000",
    "end": "1008320"
  },
  {
    "text": "separate out such that you schedule all the long-running ones in some place and all tasks that have approximately",
    "start": "1008320",
    "end": "1015360"
  },
  {
    "text": "the same completion time into other machines then you can scale down much quicker so scaling down",
    "start": "1015360",
    "end": "1021279"
  },
  {
    "text": "is harder than scaling up for this kind and the other challenge is the stream",
    "start": "1021279",
    "end": "1026798"
  },
  {
    "text": "locality so suppose i have a data stream coming in and i have three tasks running um",
    "start": "1026799",
    "end": "1033760"
  },
  {
    "text": "on three different machines so i now have three network connections streaming the same data instead if i had",
    "start": "1033760",
    "end": "1040558"
  },
  {
    "text": "placed those three jobs on the same machine i have one network connection that is",
    "start": "1040559",
    "end": "1045678"
  },
  {
    "text": "getting used for the same amount of data so therefore reduce network bandwidth and",
    "start": "1045679",
    "end": "1050720"
  },
  {
    "text": "therefore we ability to scale up much larger and there are other interesting stream processing challenges",
    "start": "1050720",
    "end": "1056320"
  },
  {
    "text": "so if i have a stream processing topology of one job which has three",
    "start": "1056320",
    "end": "1062160"
  },
  {
    "text": "stages and suppose the third stage is",
    "start": "1062160",
    "end": "1067600"
  },
  {
    "text": "having trouble uh it's slowing down its computation and then what we can do is detect",
    "start": "1067600",
    "end": "1075280"
  },
  {
    "text": "the slowdown which is also called as the back pressure and horizontally scale that stage so automatically the whole",
    "start": "1075280",
    "end": "1081120"
  },
  {
    "text": "job is flowing smoothly again so let's move on to the",
    "start": "1081120",
    "end": "1086400"
  },
  {
    "text": "framework design itself mesos framework design if you were to",
    "start": "1086400",
    "end": "1092000"
  },
  {
    "text": "develop your own framework there's a few things you should consider one is the availability and fortunately there's zookeeper",
    "start": "1092000",
    "end": "1098080"
  },
  {
    "text": "what we use is multiple instances of our framework are running using the leader election recipe from",
    "start": "1098080",
    "end": "1104160"
  },
  {
    "text": "the zookeeper service so that takes care of that another question to answer is a resource",
    "start": "1104160",
    "end": "1110640"
  },
  {
    "text": "granularity using mesos you can do a course grain scheduling like a resource allocation or",
    "start": "1110640",
    "end": "1116559"
  },
  {
    "text": "a fine grain in course grain you would get some amount of resources and then launch multiple tasks into the",
    "start": "1116559",
    "end": "1124480"
  },
  {
    "text": "same executor this is especially useful if the tasks are very short running",
    "start": "1124480",
    "end": "1130640"
  },
  {
    "text": "whereas in a fine grain you would deploy one executor per task and this also",
    "start": "1130640",
    "end": "1136480"
  },
  {
    "text": "gives you a clean separation for resource isolation and that's the model we use task state",
    "start": "1136480",
    "end": "1142559"
  },
  {
    "text": "persistence is important when you're developing a framework and then mesos provides a way to",
    "start": "1142559",
    "end": "1148799"
  },
  {
    "text": "reconcile tasks because your framework may have one idea of what tasks are running and then mesos",
    "start": "1148799",
    "end": "1155440"
  },
  {
    "text": "master has a similar picture of what's running and if your framework were to restart",
    "start": "1155440",
    "end": "1161840"
  },
  {
    "text": "you can use the reconcile feature to make sure that you haven't lost any task state updates while you were down",
    "start": "1161840",
    "end": "1169760"
  },
  {
    "text": "there's a checkpointing feature that mesos also provides where a slave daemon restart can connect to",
    "start": "1169760",
    "end": "1177360"
  },
  {
    "text": "the tasks that are already running you you would almost always use this feature",
    "start": "1177360",
    "end": "1182799"
  },
  {
    "text": "unless you're testing i can't think of a reason why you were not mesos works with what's called resource",
    "start": "1182799",
    "end": "1189679"
  },
  {
    "text": "offers so when there is a resource available it gives a resource offer to the framework saying",
    "start": "1189679",
    "end": "1196080"
  },
  {
    "text": "you can use this many cpus or memory from this machine and frameworks then launch tasks using",
    "start": "1196080",
    "end": "1202559"
  },
  {
    "text": "that offer it's generally a good practice for frameworks to",
    "start": "1202559",
    "end": "1207919"
  },
  {
    "text": "release the resource offers that are not being used so another framework that's sharing the cluster can use them",
    "start": "1207919",
    "end": "1214320"
  },
  {
    "text": "so those are the considerations if you are developing your own framework",
    "start": "1214320",
    "end": "1219360"
  },
  {
    "text": "so let's get into the scheduling a couple of i mean high level objectives are that we want to",
    "start": "1219360",
    "end": "1226240"
  },
  {
    "text": "schedule very quickly uh because scheduling can be a computer intensive problem and then we",
    "start": "1226240",
    "end": "1232000"
  },
  {
    "text": "have a heterogeneous mix of tasks resources of different sizes shapes",
    "start": "1232000",
    "end": "1237919"
  },
  {
    "text": "and then well we want to have some service level objectives for the scheduling itself auto scaling",
    "start": "1237919",
    "end": "1246000"
  },
  {
    "text": "task locality affinity that people can define between their tasks and specifically in ec2 we want to do",
    "start": "1246000",
    "end": "1254000"
  },
  {
    "text": "availability zone balancing for tasks and then also we want to have plugins",
    "start": "1254000",
    "end": "1260559"
  },
  {
    "text": "because not all optimizations can be well designed to begin with but as",
    "start": "1260559",
    "end": "1267360"
  },
  {
    "text": "you as you progress and find new ways to optimize tasks you should be able to put in plugins for optimizations",
    "start": "1267360",
    "end": "1273600"
  },
  {
    "text": "so we've created a fenzo which is a generic task scheduler that provides these features",
    "start": "1273600",
    "end": "1279840"
  },
  {
    "text": "or a scaling heterogeneous mix and also visibility into why tasks are not running one of the",
    "start": "1279840",
    "end": "1286320"
  },
  {
    "text": "challenges in operations is somebody submits a job it's not running right now well why is",
    "start": "1286320",
    "end": "1291360"
  },
  {
    "text": "it not running and it can provide answers like hey there's no resource left to run your",
    "start": "1291360",
    "end": "1297120"
  },
  {
    "text": "task or there are plenty of resources but you're asking for a resource that's not available maybe you're asking for too many cpus",
    "start": "1297120",
    "end": "1303280"
  },
  {
    "text": "and there's no such instance type in your cluster to to satisfy that requirement so and then",
    "start": "1303280",
    "end": "1310880"
  },
  {
    "text": "it provides a way to put in your own plugins for constraints and fitness",
    "start": "1310880",
    "end": "1316880"
  },
  {
    "text": "so there's a few things i'm going to talk about fenzo um these are the things and then let's",
    "start": "1317280",
    "end": "1323679"
  },
  {
    "text": "go into them fenzo itself can be used by any mesos framework",
    "start": "1323679",
    "end": "1329679"
  },
  {
    "text": "all frameworks eventually get resource offers from mesos master and they get task requests",
    "start": "1329679",
    "end": "1335679"
  },
  {
    "text": "from the users you just feed those two things into",
    "start": "1335679",
    "end": "1341440"
  },
  {
    "text": "fenzo and then it gives you a resource assignment based on the optimizations that you want to do",
    "start": "1341440",
    "end": "1347360"
  },
  {
    "text": "so when we look at the scheduling problem itself we like to think of it as in these two aspects how urgent the task",
    "start": "1347360",
    "end": "1355280"
  },
  {
    "text": "is that needs to be assigned some resources and how well does that task fit on a",
    "start": "1355280",
    "end": "1362559"
  },
  {
    "text": "given resource or a given instance and if the fitness is near perfect or if it is",
    "start": "1362559",
    "end": "1369120"
  },
  {
    "text": "very urgent go ahead assign that or we wait for another instance to see if we can find a",
    "start": "1369120",
    "end": "1375600"
  },
  {
    "text": "better fit that's the general strategy and scheduling itself it can be a hard problem",
    "start": "1375600",
    "end": "1382159"
  },
  {
    "text": "but in real life well if you've got a situation where any task can fit on any instance then",
    "start": "1382159",
    "end": "1389520"
  },
  {
    "text": "it's it's very tempting to use a first fed model and that could be really fast",
    "start": "1389520",
    "end": "1395919"
  },
  {
    "text": "however you might not be able to do optimizations because you're just using the first resource that's available and",
    "start": "1395919",
    "end": "1402000"
  },
  {
    "text": "if you start looking at optimization as the perfect fit based on task locality or any other optimizations you",
    "start": "1402000",
    "end": "1408720"
  },
  {
    "text": "have then it can get computationally very expensive even if you're not reassigning any tasks that are already",
    "start": "1408720",
    "end": "1415039"
  },
  {
    "text": "running it's still pretty expensive so what we would like to do is stay as close",
    "start": "1415039",
    "end": "1420320"
  },
  {
    "text": "as possible to the first fit assignment in terms of speed but achieve as much as possible the",
    "start": "1420320",
    "end": "1425600"
  },
  {
    "text": "optimizations so how do you do that i mean there's no big algorithm it's actually very simple all we do is",
    "start": "1425600",
    "end": "1433279"
  },
  {
    "text": "for each task we evaluate its fitness on all the instances that are available",
    "start": "1433279",
    "end": "1440400"
  },
  {
    "text": "but then we only do it until we find a good enough fitness",
    "start": "1440400",
    "end": "1446880"
  },
  {
    "text": "so all although this loop is very simple the the real work is in these two things one is",
    "start": "1446880",
    "end": "1453039"
  },
  {
    "text": "how do you define a good enough fitness and the other is how do you define fitness what is fitness fitness is",
    "start": "1453039",
    "end": "1460000"
  },
  {
    "text": "usually defined from zero to one zero being totally unfit one being perfect fit",
    "start": "1460000",
    "end": "1466159"
  },
  {
    "text": "and somewhere in between means well it fits to some degree and then there are constraints um well",
    "start": "1466159",
    "end": "1473120"
  },
  {
    "text": "let's talk about constraints there could be two kinds of constraints",
    "start": "1473120",
    "end": "1478240"
  },
  {
    "text": "heart constraints soft constraints heart constraints must be satisfied",
    "start": "1478240",
    "end": "1484559"
  },
  {
    "text": "they affect the resource selection so for example you have tasks that say i would like to run only",
    "start": "1484559",
    "end": "1491760"
  },
  {
    "text": "on m1 extra large type instance or another instance so that's a hard",
    "start": "1491760",
    "end": "1497520"
  },
  {
    "text": "constraint if you put that the task will only run on those type of instances or you may have a job",
    "start": "1497520",
    "end": "1503840"
  },
  {
    "text": "that says there's three availability zones i have three tasks and i would like to make sure each task",
    "start": "1503840",
    "end": "1510240"
  },
  {
    "text": "runs on only one availability zone that's a hard constraint and it has to be met before the job can",
    "start": "1510240",
    "end": "1515520"
  },
  {
    "text": "be assigned resources and then there's soft constraints which are well same as the hard constraints",
    "start": "1515520",
    "end": "1522000"
  },
  {
    "text": "except if you find a resource that meets the constraint go ahead assign it otherwise",
    "start": "1522000",
    "end": "1528480"
  },
  {
    "text": "give me the best possible i would rather not wait for the perfect fit that's the soft",
    "start": "1528480",
    "end": "1533600"
  },
  {
    "text": "constraint and then this can be used similarly i would rather run on m1 instance type but if",
    "start": "1533600",
    "end": "1542240"
  },
  {
    "text": "it's not available then just put me on the next one that's available that's a soft constraint and fenzo comes",
    "start": "1542240",
    "end": "1548720"
  },
  {
    "text": "built with a few constraints and fitness calculators so bin packing for example if you want to achieve",
    "start": "1548720",
    "end": "1554400"
  },
  {
    "text": "cpu unpacking or maybe sometimes memory bin packing is more important that's already available then there are",
    "start": "1554400",
    "end": "1560960"
  },
  {
    "text": "a few other constraints available so we can put in a constraint based on a host",
    "start": "1560960",
    "end": "1566640"
  },
  {
    "text": "attribute so for example one of the host attributes could be availability zone each instance",
    "start": "1566640",
    "end": "1572000"
  },
  {
    "text": "that's available has an attribute on it saying which availability zone it is and then i could specify a constraint",
    "start": "1572000",
    "end": "1578480"
  },
  {
    "text": "saying i want to only run on this availability zone for example",
    "start": "1578480",
    "end": "1583679"
  },
  {
    "text": "or you can use that and the instance name itself if you for some reason want to only run",
    "start": "1583679",
    "end": "1589120"
  },
  {
    "text": "on a specific instance and there's also a unique host attribute",
    "start": "1589120",
    "end": "1597039"
  },
  {
    "text": "constraint where you're not looking for a specific name for the host attribute a zone name for",
    "start": "1597039",
    "end": "1603600"
  },
  {
    "text": "example but you're saying i have three tasks and i want to make sure they each land on a unique",
    "start": "1603600",
    "end": "1610720"
  },
  {
    "text": "value for the zone attribute and similarly if you want to run 10 tasks each of them you want to make",
    "start": "1610720",
    "end": "1618000"
  },
  {
    "text": "sure is on a different host same thing you put in a unique host attribute and it readily gives you that",
    "start": "1618000",
    "end": "1623520"
  },
  {
    "text": "another one is exclusive sometimes you want to run a task on an instance and have no other task running there",
    "start": "1623520",
    "end": "1630799"
  },
  {
    "text": "and then there's the other one called balancing host attribute constraint which balances all of your workload if",
    "start": "1630799",
    "end": "1637440"
  },
  {
    "text": "there's a large jobs say you have 100 tasks on them you want to balance them across availability zones",
    "start": "1637440",
    "end": "1642960"
  },
  {
    "text": "then you would use this and each of these constraints can be specified as hard or soft so if you're hard constrained",
    "start": "1642960",
    "end": "1650480"
  },
  {
    "text": "the job would actually be pending until you're finding a resource that satisfies it soft constraint will get it",
    "start": "1650480",
    "end": "1657919"
  },
  {
    "text": "launched quickly and trying to make it fit as much as possible based on your constraint",
    "start": "1657919",
    "end": "1663760"
  },
  {
    "text": "so let's look at how bin packing fitness calculator works it's actually",
    "start": "1663760",
    "end": "1669120"
  },
  {
    "text": "very simple it can be defined as the ratio of used cpus to the total cpus if i was",
    "start": "1669120",
    "end": "1677039"
  },
  {
    "text": "doing cpu bin packing and then suppose we have five hosts um host one having no other tasks",
    "start": "1677039",
    "end": "1684960"
  },
  {
    "text": "running on it right now host five having all cpus already taken for other tasks",
    "start": "1684960",
    "end": "1690559"
  },
  {
    "text": "then using this equation the fitness comes up as 0.25 all the way to 1.0 for",
    "start": "1690559",
    "end": "1698000"
  },
  {
    "text": "host 4 and then it's 0 for host 5 because it can't fit all the cps are taken and so based on this if i were to do",
    "start": "1698000",
    "end": "1704720"
  },
  {
    "text": "that simple algorithm that i showed before i would pick host four because it's the perfect",
    "start": "1704720",
    "end": "1710559"
  },
  {
    "text": "fit um so that's how bin packing would work",
    "start": "1710559",
    "end": "1715760"
  },
  {
    "text": "so well does bin packing really help so here's an experiment that we did",
    "start": "1715760",
    "end": "1722320"
  },
  {
    "text": "so suppose you had a cluster with 3 000 instances and while we did a an experiment with",
    "start": "1722320",
    "end": "1729760"
  },
  {
    "text": "testing fenzo which means i can actually have the scheduling be tested without",
    "start": "1729760",
    "end": "1735360"
  },
  {
    "text": "requiring all the 3000 instances so this shows how the scheduling algorithm would work in that case",
    "start": "1735360",
    "end": "1741919"
  },
  {
    "text": "so let's say there's 3 000 instances each having eight cpus and then i have three",
    "start": "1741919",
    "end": "1748000"
  },
  {
    "text": "different task sizes one cpu three cpu and six cpu and if you were to place them not in an",
    "start": "1748000",
    "end": "1755279"
  },
  {
    "text": "optimal way you can see they will not fit perfectly on an 8 cpu machine right there's 3 and 6 cpus",
    "start": "1755279",
    "end": "1760880"
  },
  {
    "text": "and then what we do is iteratively we start filling up the cluster in each iteration we launch a few tasks",
    "start": "1760880",
    "end": "1767039"
  },
  {
    "text": "as in as if new jobs are coming in on a periodic basis we ran about 50",
    "start": "1767039",
    "end": "1772159"
  },
  {
    "text": "iterations so how does that look so the left side chart shows you when no bin packing is used",
    "start": "1772159",
    "end": "1779919"
  },
  {
    "text": "then some instances are fully used as in all 8 cpus are used some instances",
    "start": "1779919",
    "end": "1786159"
  },
  {
    "text": "are partially used non-zero cpus but not fully used and",
    "start": "1786159",
    "end": "1791760"
  },
  {
    "text": "then there are some instances that are empty because while we only run 50 iterations there's still space in the cluster",
    "start": "1791760",
    "end": "1797919"
  },
  {
    "text": "when we use bin packing the number of instances that were partially used was very close to zero",
    "start": "1797919",
    "end": "1805919"
  },
  {
    "text": "now what this means is that first of all there's more number of instances that are empty",
    "start": "1805919",
    "end": "1812399"
  },
  {
    "text": "so i can achieve scale down quickly and use fewer instances and",
    "start": "1812399",
    "end": "1819840"
  },
  {
    "text": "um so this is one way to do cpu bin packing and similarly there was another experiment we did",
    "start": "1819840",
    "end": "1825360"
  },
  {
    "text": "with the task run times so we have task run times um in two categories short and run for",
    "start": "1825360",
    "end": "1830880"
  },
  {
    "text": "this experiment a short and long running in this experiment and then when we used",
    "start": "1830880",
    "end": "1836080"
  },
  {
    "text": "bin packing we saw that almost all instances had similar run time tasks versus not so",
    "start": "1836080",
    "end": "1844320"
  },
  {
    "text": "what this means is that when the short running tasks are done those instances will be freed up and i can easily scale down",
    "start": "1844320",
    "end": "1852158"
  },
  {
    "text": "stream locality which i talked about can again be defined very easily in fenzo",
    "start": "1855360",
    "end": "1861440"
  },
  {
    "text": "we define it as the percentage of tasks on that house that are already connected",
    "start": "1861440",
    "end": "1867039"
  },
  {
    "text": "to the same stream and using that which gives me a zero to one watts per yeah zero to one value i can",
    "start": "1867039",
    "end": "1873919"
  },
  {
    "text": "easily achieve stream locality and sometimes you wanna do more than one thing fitness calculators",
    "start": "1873919",
    "end": "1879600"
  },
  {
    "text": "can be composed together stream locality is important to me bin packing is important to me",
    "start": "1879600",
    "end": "1884880"
  },
  {
    "text": "so i can just combine them together and say one is more important than the other and maybe give more",
    "start": "1884880",
    "end": "1890640"
  },
  {
    "text": "weight to stream locality and less weight to cpu bin packing so you can achieve",
    "start": "1890640",
    "end": "1896799"
  },
  {
    "text": "different slas using a composition of fitness calculators",
    "start": "1896799",
    "end": "1902080"
  },
  {
    "text": "so the other part is auto scaling so fenzo looks at the resources available what",
    "start": "1902080",
    "end": "1908880"
  },
  {
    "text": "tasks have been assigned and then can give you callbacks for scaling up and down",
    "start": "1908880",
    "end": "1915760"
  },
  {
    "text": "it does that on in two ways one is rules based uh this is similar to",
    "start": "1915760",
    "end": "1922799"
  },
  {
    "text": "how you set up uh rules for an asg where you have a min and a max so in in fenzo you can set up",
    "start": "1922799",
    "end": "1930559"
  },
  {
    "text": "a minimum idle that you always want to keep just in case there's new workload coming in you don't want to",
    "start": "1930559",
    "end": "1936640"
  },
  {
    "text": "wait to spin up new instances you want to have some buffer there and then a max if the number of idle",
    "start": "1936640",
    "end": "1942559"
  },
  {
    "text": "resources falls below the min then it gives you a callback to scale up and if it goes above",
    "start": "1942559",
    "end": "1948080"
  },
  {
    "text": "max it gives you a call back not just to scale down but with a list of instances that can be",
    "start": "1948080",
    "end": "1954159"
  },
  {
    "text": "terminated because they're idle so as with any scale up and scale down",
    "start": "1954159",
    "end": "1960960"
  },
  {
    "text": "you need to have a cool down period to do it right one challenge there is that if there's a",
    "start": "1960960",
    "end": "1966880"
  },
  {
    "text": "sudden surge in incoming requests and usually scale up happens by some",
    "start": "1966880",
    "end": "1974320"
  },
  {
    "text": "number so suppose you're scaling up by 10 instances but the amount of workload that's pending",
    "start": "1974320",
    "end": "1979919"
  },
  {
    "text": "requires 15 stances you don't want to wait for the cooldown and then scale up again",
    "start": "1979919",
    "end": "1985840"
  },
  {
    "text": "so fenzo also does resource shortfall analysis and then can scale up aggressively for",
    "start": "1985840",
    "end": "1992080"
  },
  {
    "text": "pending workload even if it's in a cool down period so like i said fenzo can give you",
    "start": "1992080",
    "end": "1998640"
  },
  {
    "text": "callbacks you can have multiple asds so for example you can have one ast that is more ideal for running large",
    "start": "1998640",
    "end": "2005919"
  },
  {
    "text": "memory workloads another ast that's for network throughput oriented or another asg for",
    "start": "2005919",
    "end": "2012640"
  },
  {
    "text": "cpu intensive workloads and for each of them you can define different auto scale rules in fenzo",
    "start": "2012640",
    "end": "2020159"
  },
  {
    "text": "in auto scaling itself while there's three numbers to control",
    "start": "2020559",
    "end": "2026559"
  },
  {
    "text": "in an asc the min max and desirable the number that fenzo gives you is ideal",
    "start": "2026559",
    "end": "2034159"
  },
  {
    "text": "to be set on the desirable number max i would use the max number to",
    "start": "2034159",
    "end": "2041120"
  },
  {
    "text": "limit the scale up for any reason maybe you never want to have more than",
    "start": "2041120",
    "end": "2047120"
  },
  {
    "text": "some number of instances in your cluster budget reason or whatever other reason and then min is controlled by",
    "start": "2047120",
    "end": "2055839"
  },
  {
    "text": "a more macro level scale up adjustments so at netflix we have scryer which is a",
    "start": "2055839",
    "end": "2062960"
  },
  {
    "text": "predictive auto scaling engine and what it does is it analyzes historical",
    "start": "2062960",
    "end": "2070000"
  },
  {
    "text": "usage of a cluster of an asg and says hey during this hour of the day",
    "start": "2070000",
    "end": "2075280"
  },
  {
    "text": "this is what has been traditionally used and then it predicts for the next hour based on similar times previous days day",
    "start": "2075280",
    "end": "2082960"
  },
  {
    "text": "of the week etc so that is a better candidate for setting them",
    "start": "2082960",
    "end": "2088079"
  },
  {
    "text": "in and then what fenzo does is it auto scales up and down based on the current demand between the",
    "start": "2088079",
    "end": "2095358"
  },
  {
    "text": "min and max so that's the strategy so a quick look at how",
    "start": "2095359",
    "end": "2101599"
  },
  {
    "text": "fenzo scheduler itself can be used so in java for example this is how you would",
    "start": "2101599",
    "end": "2107280"
  },
  {
    "text": "create a scheduler where you just specify very simple",
    "start": "2107280",
    "end": "2112960"
  },
  {
    "text": "things like i was telling you about mesos offer should be released if not being used you just tell it how long you want to",
    "start": "2112960",
    "end": "2119440"
  },
  {
    "text": "wait before you release an idle resource offer and then it just does that for you",
    "start": "2119440",
    "end": "2125440"
  },
  {
    "text": "and once you create that you can also say i want to use a fitness calculator that's already built in it's the bin packing fitness calculator",
    "start": "2125440",
    "end": "2133359"
  },
  {
    "text": "and then i can also say hey i'm just looking for a fitness",
    "start": "2133359",
    "end": "2140800"
  },
  {
    "text": "to be just 0.5 or greater i don't need a perfect fit or you can vary that and once you do this you now have a task",
    "start": "2140880",
    "end": "2147280"
  },
  {
    "text": "scheduler that you can feed your tasks into and all of the mesos offers and then",
    "start": "2147280",
    "end": "2153440"
  },
  {
    "text": "it'll do the assignment for you so to summarize um",
    "start": "2153440",
    "end": "2159839"
  },
  {
    "text": "we looked at why mesos could be a good candidate in elastic cloud for resource",
    "start": "2159839",
    "end": "2167119"
  },
  {
    "text": "granularity and task data latency reasons and fenzo lets you",
    "start": "2167119",
    "end": "2173920"
  },
  {
    "text": "schedule resources to tasks um and achieve customized optimizations",
    "start": "2173920",
    "end": "2180880"
  },
  {
    "text": "and and i showed you how we're building a stream processing system that uses fenzo to do",
    "start": "2180880",
    "end": "2187200"
  },
  {
    "text": "stream processing for live events to build the data visualization",
    "start": "2187200",
    "end": "2193280"
  },
  {
    "text": "so i think we have a few minutes we can take questions if there are yes",
    "start": "2193280",
    "end": "2201839"
  },
  {
    "text": "right so um yeah the the new ecs um container service that was",
    "start": "2224800",
    "end": "2231440"
  },
  {
    "text": "announced um was that um similar or was there any work done in",
    "start": "2231440",
    "end": "2238079"
  },
  {
    "text": "collaboration are these separated first that's the question these are separate efforts i learned about it when you learned about it as",
    "start": "2238079",
    "end": "2243680"
  },
  {
    "text": "well but i think there are some similarities obviously but as was mentioned apache mesos can",
    "start": "2243680",
    "end": "2251119"
  },
  {
    "text": "still be used in conjunction with ecs to do more sophisticated scheduling",
    "start": "2251119",
    "end": "2256480"
  },
  {
    "text": "and the container service would still work with mesas so what i'm talking about is more about resource allocation and",
    "start": "2256480",
    "end": "2261839"
  },
  {
    "text": "scheduling container service helps you launch the contain containers",
    "start": "2261839",
    "end": "2268480"
  },
  {
    "text": "that you have using docker so that's more of the focus and we can do more sophisticated",
    "start": "2268480",
    "end": "2273839"
  },
  {
    "text": "scheduling using this so i think they would work together they're not one instead of the other yeah",
    "start": "2273839",
    "end": "2280800"
  },
  {
    "text": "right correct yes bin packing is",
    "start": "2282839",
    "end": "2289839"
  },
  {
    "text": "what they showed as well and bin packing could be done in various ways sometimes it is cpu based sometimes it's",
    "start": "2289839",
    "end": "2295680"
  },
  {
    "text": "task locality based and you can define different optimizations based on your application",
    "start": "2295680",
    "end": "2301920"
  },
  {
    "text": "yes",
    "start": "2302079",
    "end": "2304240"
  },
  {
    "text": "the question is are we open sourcing fenzo and mantis um right now they are not open source but",
    "start": "2310640",
    "end": "2316800"
  },
  {
    "text": "in the future they might be should be thanks yes",
    "start": "2316800",
    "end": "2327839"
  },
  {
    "text": "i'm sorry i couldn't hear you",
    "start": "2332000",
    "end": "2341839"
  },
  {
    "text": "correct so uh the question is when you scale down uh do you have control on what instances you kill",
    "start": "2346320",
    "end": "2351599"
  },
  {
    "text": "um so well i'm writing code in java the java interface to the asg actually",
    "start": "2351599",
    "end": "2357839"
  },
  {
    "text": "does have a way to say terminate this instance and scale down the asg by count of one",
    "start": "2357839",
    "end": "2365280"
  },
  {
    "text": "by terminating this so that is the one you want to use you don't want to just say",
    "start": "2365280",
    "end": "2370480"
  },
  {
    "text": "set the desirable lower in that case it would terminate any instance based on different criteria",
    "start": "2370480",
    "end": "2376400"
  },
  {
    "text": "so yeah there is a way to do that yes",
    "start": "2376400",
    "end": "2383838"
  },
  {
    "text": "i'm sorry does pencil have",
    "start": "2389440",
    "end": "2393200"
  },
  {
    "text": "right so fenzo is written as a generic scheduler um it doesn't necessarily know the availability zone names",
    "start": "2394880",
    "end": "2401760"
  },
  {
    "text": "but it has a built-in constraint that you can say balance it according to",
    "start": "2401760",
    "end": "2408000"
  },
  {
    "text": "this host attribute and one of the host attributes is the availability zone name so yes",
    "start": "2408000",
    "end": "2425838"
  },
  {
    "text": "so um i understand the question right so why does the constraints",
    "start": "2428000",
    "end": "2433838"
  },
  {
    "text": "and why does fenzo need to be in the",
    "start": "2436839",
    "end": "2442000"
  },
  {
    "text": "framework can it be inserted into mesos itself",
    "start": "2442000",
    "end": "2446640"
  },
  {
    "text": "ah okay so um can fenzo be inserted into mesos itself i think that's a good",
    "start": "2447200",
    "end": "2453599"
  },
  {
    "text": "question mesos itself provides resource",
    "start": "2453599",
    "end": "2459440"
  },
  {
    "text": "allocation it explicitly does not do scheduling there's a good reason for it for it to",
    "start": "2459440",
    "end": "2465119"
  },
  {
    "text": "be really fast in resource allocation so it separates out these two it expects frameworks to do the actual",
    "start": "2465119",
    "end": "2471520"
  },
  {
    "text": "scheduling and fenzo is built for scheduling but what can happen",
    "start": "2471520",
    "end": "2476560"
  },
  {
    "text": "is fenzo can be used by any framework whether it's marathon i think you mentioned marathon",
    "start": "2476560",
    "end": "2481599"
  },
  {
    "text": "or other frameworks and we're using mantis in fact at netflix we have another framework that's also using",
    "start": "2481599",
    "end": "2487200"
  },
  {
    "text": "fenzo any of them can be used you can use fenzo to make all of this possible right now it's",
    "start": "2487200",
    "end": "2494800"
  },
  {
    "text": "not open source but in the future that is a possibility",
    "start": "2494800",
    "end": "2499520"
  },
  {
    "text": "yes i'm sorry i can't hear you",
    "start": "2506839",
    "end": "2513760"
  },
  {
    "text": "uh-huh",
    "start": "2520839",
    "end": "2523839"
  },
  {
    "text": "i'm sorry i can't hear all of it you you are asking about scale up and scale down",
    "start": "2527440",
    "end": "2537838"
  },
  {
    "text": "ah who is responsible to start and stop the machines okay so fenzo provides um the the framework for doing the auto",
    "start": "2538960",
    "end": "2546800"
  },
  {
    "text": "scaling it gives you a call back to say you need to scale up",
    "start": "2546800",
    "end": "2552560"
  },
  {
    "text": "that scale up ideally should basically trigger an action into the asg",
    "start": "2553280",
    "end": "2559520"
  },
  {
    "text": "to scale up to set the desired number so that part is not in fenzo because that is more logistics of scaling up and",
    "start": "2559520",
    "end": "2566720"
  },
  {
    "text": "down using the asg which requires your credentials and things like that so that's not part of fenzo fenzo",
    "start": "2566720",
    "end": "2571920"
  },
  {
    "text": "provides the genetic way of telling you to scale up and scale down",
    "start": "2571920",
    "end": "2579839"
  },
  {
    "text": "um so if you had different club if you have different asgs or",
    "start": "2591200",
    "end": "2596880"
  },
  {
    "text": "different clusters",
    "start": "2596880",
    "end": "2599759"
  },
  {
    "text": "okay",
    "start": "2604839",
    "end": "2607839"
  },
  {
    "text": "okay",
    "start": "2610079",
    "end": "2612319"
  },
  {
    "text": "right so um i think okay so i think i",
    "start": "2618839",
    "end": "2624560"
  },
  {
    "text": "understood the question so if you have 10 machines and if fenzo says shut down these five",
    "start": "2624560",
    "end": "2630240"
  },
  {
    "text": "machines or scale down by five machines will it specifically shut down only those five or any five in",
    "start": "2630240",
    "end": "2636800"
  },
  {
    "text": "the ten machines the other will it affect other tests so",
    "start": "2636800",
    "end": "2641920"
  },
  {
    "text": "what fenzo does is gives you a list of the five machines to terminate which are idle so when you terminate those the other",
    "start": "2641920",
    "end": "2648560"
  },
  {
    "text": "machines will not be affected the other task will not be affected so when you scale down you don't want to scale down by telling the asg",
    "start": "2648560",
    "end": "2655599"
  },
  {
    "text": "to reduce the desired number you want to scale down by terminating those specific instances",
    "start": "2655599",
    "end": "2661839"
  },
  {
    "text": "so then it should be fine",
    "start": "2661839",
    "end": "2665359"
  },
  {
    "text": "correct correct so when you terminate that instance you're also setting the desired number to go",
    "start": "2670880",
    "end": "2676960"
  },
  {
    "text": "down by one for each of them so that automatically does that",
    "start": "2676960",
    "end": "2682318"
  },
  {
    "text": "that is an interface into the um the asg api",
    "start": "2682560",
    "end": "2688800"
  },
  {
    "text": "that amazon has and then that like i said requires credentials and all that that is specific to your application and",
    "start": "2688800",
    "end": "2696319"
  },
  {
    "text": "that is not part of fenzo fenzo only provides the basic infrastructure to do it not the logistics of actual scaling up",
    "start": "2696319",
    "end": "2702480"
  },
  {
    "text": "and down of asd itself",
    "start": "2702480",
    "end": "2705838"
  },
  {
    "text": "right right yeah i think i understand what you're trying to say uh we are running out of time but i will be",
    "start": "2716160",
    "end": "2721839"
  },
  {
    "text": "available so maybe we can take our conversation after this outside",
    "start": "2721839",
    "end": "2727119"
  },
  {
    "text": "okay thank you all for your time",
    "start": "2727119",
    "end": "2733359"
  },
  {
    "text": "you",
    "start": "2733359",
    "end": "2735440"
  }
]
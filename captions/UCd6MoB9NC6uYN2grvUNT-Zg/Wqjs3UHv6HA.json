[
  {
    "text": "hi everyone welcome to today's webinar democratizing the ETL process how ebooks",
    "start": "810",
    "end": "6910"
  },
  {
    "text": "increased ETL literacy by 150% with battalion and AWS my name is Ryan Peterson I'm from it I guess and of your",
    "start": "6910",
    "end": "14140"
  },
  {
    "text": "speaker and moderator for today's webinar I'm joined today by Edie Thompson the CTO from Italian at the",
    "start": "14140",
    "end": "20140"
  },
  {
    "text": "Metreon ocean a data engineer at a books we all know that's become a data leader",
    "start": "20140",
    "end": "25439"
  },
  {
    "text": "we're finding that organizations are scaling as a result of getting the right insights and information from their data",
    "start": "25439",
    "end": "32340"
  },
  {
    "text": "organization to become data-driven are often outperforming their competitors and we see that throughout every",
    "start": "32340",
    "end": "38920"
  },
  {
    "text": "industry globally to become a differentiator though you have to really look at data outside of what you",
    "start": "38920",
    "end": "45010"
  },
  {
    "text": "contextually would not use to see the use of find data was just in structured format sitting in databases and that's",
    "start": "45010",
    "end": "51519"
  },
  {
    "text": "about the only thing we would look at but today's new type of analytics looks at everything from real-time information",
    "start": "51519",
    "end": "57670"
  },
  {
    "text": "like streams image recognition and puts predictive analysis on top of information so for example if you wanted",
    "start": "57670",
    "end": "65170"
  },
  {
    "text": "to look at how many sales you will be doing and not just how many sales you've had you may need to add some prediction",
    "start": "65170",
    "end": "71020"
  },
  {
    "text": "to that methodology to figure out what's happening and potentially add in other information about out side effects such",
    "start": "71020",
    "end": "77860"
  },
  {
    "text": "as weather and things of that that could impact your sales but the old way of",
    "start": "77860",
    "end": "82899"
  },
  {
    "text": "thinking about this was that you would take a whole bunch of different data silos and you put them into a data",
    "start": "82899",
    "end": "88869"
  },
  {
    "text": "warehouse and then you would bring bi out of that and and we saw those were initially in the terabytes up to",
    "start": "88869",
    "end": "95920"
  },
  {
    "text": "petabyte scale we didn't usually see any kind of relational data sources getting much larger than that",
    "start": "95920",
    "end": "102170"
  },
  {
    "text": "but in the next generation we found that you needed to have both the data warehouse and a data Lake sometimes",
    "start": "102170",
    "end": "108830"
  },
  {
    "text": "using just a data like or sometimes just a data warehouse but we really required the process at ETL to get that data into",
    "start": "108830",
    "end": "114649"
  },
  {
    "text": "the right formats so that you can get all of the access to the information you want to use the scale of these new",
    "start": "114649",
    "end": "121490"
  },
  {
    "text": "environments we've seen go up into the exabytes of scale it may be because the organization is really focusing on large",
    "start": "121490",
    "end": "128600"
  },
  {
    "text": "content whether it's images or video maybe because you're accessing a log",
    "start": "128600",
    "end": "133730"
  },
  {
    "text": "analytics data and bringing that in from various different sources but a lot of information means that you have larger",
    "start": "133730",
    "end": "140090"
  },
  {
    "text": "amounts to look through it means that if you do it right you can get a lot more data insights from your information at a",
    "start": "140090",
    "end": "148250"
  },
  {
    "text": "TBS we have a pretty consistent story around data like on TBS it starts with",
    "start": "148250",
    "end": "154130"
  },
  {
    "text": "s3 at its core and it allows you to store everything you'd ever want to",
    "start": "154130",
    "end": "159500"
  },
  {
    "text": "store with as much scales you can think of now inside of outside of that we have various processing engines and things of",
    "start": "159500",
    "end": "165890"
  },
  {
    "text": "that but the the partner applications that come around that data they can surround it now allow you to do various",
    "start": "165890",
    "end": "171950"
  },
  {
    "text": "things you couldn't previously do so we'll discuss a little bit more with metallian on how they can get",
    "start": "171950",
    "end": "178190"
  },
  {
    "text": "information in and out of the data like we want to make sure that we handle all of these privacy regulations and other",
    "start": "178190",
    "end": "186370"
  },
  {
    "text": "PCI and other regulations for you to the point at which it goes to the hypervisor",
    "start": "186370",
    "end": "191900"
  },
  {
    "text": "and above that we look to the organization's to handle the rest but we try to make sure that those compliance",
    "start": "191900",
    "end": "197450"
  },
  {
    "text": "regulatory regimes that any of your industries may require are all taken care of we talked a little bitty s3",
    "start": "197450",
    "end": "204079"
  },
  {
    "text": "holds trillions of objects regularly peaks at millions of requests per second it says very very very large data store",
    "start": "204079",
    "end": "210590"
  },
  {
    "text": "add the ability to scale infinitely I infest rate as what makes it really",
    "start": "210590",
    "end": "216920"
  },
  {
    "text": "valuable and three on top of that comes with 11 9 -",
    "start": "216920",
    "end": "222590"
  },
  {
    "text": "durability geographic redundancy and autumn Agri automated replication means you can run s3 across multiple different regions in",
    "start": "222590",
    "end": "230450"
  },
  {
    "text": "the globe and have single repositories they can hold all the information for organization we're really humbled to see",
    "start": "230450",
    "end": "238790"
  },
  {
    "text": "all of these different organizations that have utilized our data Lake processes and relied on AWS to take care",
    "start": "238790",
    "end": "245840"
  },
  {
    "text": "of this information for them on top of that we've we've got a great new",
    "start": "245840",
    "end": "251090"
  },
  {
    "text": "customer that wants to talk about what they've been doing with us and McCallion and so I want to introduce Dimitri a",
    "start": "251090",
    "end": "257150"
  },
  {
    "text": "notion to come and talk about what they're doing with a books hello everyone my name is Dmitry and I'm they",
    "start": "257150",
    "end": "263330"
  },
  {
    "text": "didn't be a engineer at a books and today I am going to cover our story how",
    "start": "263330",
    "end": "268490"
  },
  {
    "text": "we migrate to the cloud and how we choosing ETL tool for us and why we pick",
    "start": "268490",
    "end": "274190"
  },
  {
    "text": "up my Chilean and what we can do with my talents before we going forward I would",
    "start": "274190",
    "end": "280790"
  },
  {
    "text": "like to cover a brief about a books and eBooks it's online marketplace for books",
    "start": "280790",
    "end": "285980"
  },
  {
    "text": "art and collectibles on top of the slide you can see different product segments that you can find on our website and we",
    "start": "285980",
    "end": "292730"
  },
  {
    "text": "have more than 350 million listings and we have used books we have maps we have",
    "start": "292730",
    "end": "298130"
  },
  {
    "text": "arts for example you can find the first signed copy of Harry Potter or any other",
    "start": "298130",
    "end": "303860"
  },
  {
    "text": "unique books that really good for collections or investment and we have",
    "start": "303860",
    "end": "310640"
  },
  {
    "text": "two offices one of the in Victoria BC Canada and another in Dusseldorf and on",
    "start": "310640",
    "end": "315740"
  },
  {
    "text": "the picture you can see the beautiful downtown of Victoria and I personally really enjoying this city and the",
    "start": "315740",
    "end": "321980"
  },
  {
    "text": "weather here and the main point about a books and business and tells their house",
    "start": "321980",
    "end": "327710"
  },
  {
    "text": "that we have quite small team just free person that manage the data warehouse",
    "start": "327710",
    "end": "333470"
  },
  {
    "text": "business intelligence and ETL solution but that's why during the consideration",
    "start": "333470",
    "end": "340340"
  },
  {
    "text": "like what is the future business and health it will have eight eight books we were looking for the tool that can",
    "start": "340340",
    "end": "346970"
  },
  {
    "text": "simplify our life as a core team and how we can actually involve more",
    "start": "346970",
    "end": "352969"
  },
  {
    "text": "business users and this slide you can see quite common architecture and I",
    "start": "352969",
    "end": "361249"
  },
  {
    "text": "think most of organization has the same architecture and this architecture was before we moving to the cloud owing to a",
    "start": "361249",
    "end": "368209"
  },
  {
    "text": "SS and it's quite similar we have different relation databases as a source",
    "start": "368209",
    "end": "373699"
  },
  {
    "text": "we using script loading our data warehouse and finally we have multiple",
    "start": "373699",
    "end": "381039"
  },
  {
    "text": "solution for reporting such as Crystal Reports of course the excel spreadsheet",
    "start": "381039",
    "end": "386629"
  },
  {
    "text": "was the most popular and endi sequel and also we collect some files from external",
    "start": "386629",
    "end": "391759"
  },
  {
    "text": "entities and it was long time while working in this pace and everyone was",
    "start": "391759",
    "end": "399919"
  },
  {
    "text": "good but of course the BI literal house tomb was the kind of the bottleneck and",
    "start": "399919",
    "end": "405699"
  },
  {
    "text": "sometimes we have issue with the growing data or some some challenges with ETL",
    "start": "405699",
    "end": "410719"
  },
  {
    "text": "and but like how we can troubleshoot it'll how we can improve this I will",
    "start": "410719",
    "end": "416119"
  },
  {
    "text": "talk about this later and ok let's move to the story how we actually decide to",
    "start": "416119",
    "end": "424159"
  },
  {
    "text": "moving to the to the cloud we realize that the current infrastructure not",
    "start": "424159",
    "end": "429589"
  },
  {
    "text": "scalable enough its it's not good it's not cover of business requirements and",
    "start": "429589",
    "end": "435349"
  },
  {
    "text": "since we are working for the business and we would like to add maximum value to the business we understood that we",
    "start": "435349",
    "end": "442579"
  },
  {
    "text": "should move to the new architecture we should design your Heat actually we should need to bring new tools on place",
    "start": "442579",
    "end": "449629"
  },
  {
    "text": "and one of the key think was what ETL",
    "start": "449629",
    "end": "455269"
  },
  {
    "text": "tools we should use because we already adopted tabloids behind tool and we",
    "start": "455269",
    "end": "460849"
  },
  {
    "text": "decide module El Bulli a balloons and redshift but we didn't",
    "start": "460849",
    "end": "466339"
  },
  {
    "text": "know what is about ETL tool which one pick up because our team have different",
    "start": "466339",
    "end": "472549"
  },
  {
    "text": "experience with ETL tools we work if some legacy enterprise tools we work with open source we work with the script",
    "start": "472549",
    "end": "479469"
  },
  {
    "text": "what approach is what's the best we didn't know and as a result we define",
    "start": "479469",
    "end": "485389"
  },
  {
    "text": "multiple critic and then we define use keys and just",
    "start": "485389",
    "end": "490420"
  },
  {
    "text": "brought different tools and started to do comparison of those tools and among",
    "start": "490420",
    "end": "497180"
  },
  {
    "text": "kayo criterias was for sure we want native red ship drivers because most of",
    "start": "497180",
    "end": "502670"
  },
  {
    "text": "the ETL tools year ago they provided posthumous JDBC driver that should serve",
    "start": "502670",
    "end": "509690"
  },
  {
    "text": "your driver for red shift of course we would like to cover use",
    "start": "509690",
    "end": "515150"
  },
  {
    "text": "cases then we can capture data changes from relational database because majority follow our sources is",
    "start": "515150",
    "end": "521450"
  },
  {
    "text": "relational database that's why we want the clear path how we can capture all",
    "start": "521450",
    "end": "527510"
  },
  {
    "text": "changes and since we are team was a kind bottleneck for our company we would like",
    "start": "527510",
    "end": "533810"
  },
  {
    "text": "really simplify the use of ETL because there are legacy principle which is",
    "start": "533810",
    "end": "539330"
  },
  {
    "text": "script it was reliable it was good but it was really blank box for end-users",
    "start": "539330",
    "end": "544400"
  },
  {
    "text": "even for ourselves sometimes when you don't look to the script long time and",
    "start": "544400",
    "end": "551510"
  },
  {
    "text": "then you've got the issue you need to uncover this script with thousands of lines of code and you need to start",
    "start": "551510",
    "end": "558290"
  },
  {
    "text": "going through the code to find the spot where was the issue happen and all",
    "start": "558290",
    "end": "563900"
  },
  {
    "text": "logging that was available it's basically the login that you said and if it's not enough detail then it's",
    "start": "563900",
    "end": "571610"
  },
  {
    "text": "difficult to spot their issue that's why we really want the tool was friendly and",
    "start": "571610",
    "end": "576740"
  },
  {
    "text": "of course we we need some best practices like Russian control monitoring and the",
    "start": "576740",
    "end": "583400"
  },
  {
    "text": "price should be cost efficient for the cloud and we did compare multiple tools",
    "start": "583400",
    "end": "589880"
  },
  {
    "text": "and we among them was mighty lien and we were a bit skeptical then personally I",
    "start": "589880",
    "end": "596930"
  },
  {
    "text": "was a bit scheduling and first time I heard about material how how it is good with the cloud and especially friendship",
    "start": "596930",
    "end": "603320"
  },
  {
    "text": "because previously I tried different detail tools and I found that they kind like bottleneck because they try to",
    "start": "603320",
    "end": "609800"
  },
  {
    "text": "process all data from it frou-frou themself even if I just would like to",
    "start": "609800",
    "end": "615710"
  },
  {
    "text": "upload file to history by kids they still account like trying to read the file and then Lord and or that they didn't have native",
    "start": "615710",
    "end": "624769"
  },
  {
    "text": "integration of friendship and the maximum what I could do it just place the sequel coat inside of the ETL tool",
    "start": "624769",
    "end": "633680"
  },
  {
    "text": "company and any kind like to to make to use the ETL tool is a is a scheduler and",
    "start": "633680",
    "end": "641230"
  },
  {
    "text": "we decided to pick up my Chilean and here's the why because most of all",
    "start": "641230",
    "end": "646399"
  },
  {
    "text": "infrastructure based on eight players and metallian was built for redshift and",
    "start": "646399",
    "end": "651730"
  },
  {
    "text": "both built for a SS and it's good because basically material is running on",
    "start": "651730",
    "end": "657980"
  },
  {
    "text": "top of ec2 instance they live in our virtual private cloud cloud where we have redshift other instances and we we",
    "start": "657980",
    "end": "666560"
  },
  {
    "text": "can use different a SS features and we can really expand the default",
    "start": "666560",
    "end": "674690"
  },
  {
    "text": "capabilities of material just because it's built on native AWS and it's dramatically increase our speed of it'll",
    "start": "674690",
    "end": "681680"
  },
  {
    "text": "work and even our first project like proof-of-concept and we decided okay",
    "start": "681680",
    "end": "687079"
  },
  {
    "text": "let's do the marketing beta source bring into the date warehouse and build some fact tables dimension tables and",
    "start": "687079",
    "end": "694149"
  },
  {
    "text": "set this daily load job we finish this task quite fast and we learn material",
    "start": "694149",
    "end": "701779"
  },
  {
    "text": "quite quite fast and the support of Matilda was ever some like basically we asked the question and next day we get",
    "start": "701779",
    "end": "708980"
  },
  {
    "text": "detailed answer with how to do this what approach you can take and all this help us to move really fast and as a result",
    "start": "708980",
    "end": "717050"
  },
  {
    "text": "that speed of development it's increased them are dramatically dimension and my",
    "start": "717050",
    "end": "722779"
  },
  {
    "text": "Chilean is good because it's already supported lots of predefined data sources for example previously if we",
    "start": "722779",
    "end": "730070"
  },
  {
    "text": "need to grab any data from a using API or whatever we need to code but right",
    "start": "730070",
    "end": "736399"
  },
  {
    "text": "now the material provides you we've already predefined data source or some if you want to grab data from Facebook",
    "start": "736399",
    "end": "741620"
  },
  {
    "text": "or AdWords you all what you need you can just use this companions provide your",
    "start": "741620",
    "end": "747380"
  },
  {
    "text": "credentials and then here you go you start consuming your data load into read ship and the final point",
    "start": "747380",
    "end": "754080"
  },
  {
    "text": "of use for the technical and business users it's okay for difficult users we can accept different label of the of",
    "start": "754080",
    "end": "762590"
  },
  {
    "text": "using it could be scripted with coding it's okay for us but since we would like",
    "start": "762590",
    "end": "768000"
  },
  {
    "text": "to involve the users and and because we clear understood that if you want to",
    "start": "768000",
    "end": "774390"
  },
  {
    "text": "move faster and we if a books want to drive more inside we need to involve the",
    "start": "774390",
    "end": "779610"
  },
  {
    "text": "business teams in developing complete warehouse and to work with the data and",
    "start": "779610",
    "end": "785330"
  },
  {
    "text": "also if they have any questions they can self-service going to ETL tool and use",
    "start": "785330",
    "end": "790770"
  },
  {
    "text": "the data line H option basically to track down the metric or troubleshoot if",
    "start": "790770",
    "end": "796920"
  },
  {
    "text": "something wrong they can go into detail tool and Luke using visual interface that can look what's the problem and I",
    "start": "796920",
    "end": "803190"
  },
  {
    "text": "would like to tell one story about our marketing team we had marketing analyst",
    "start": "803190",
    "end": "808740"
  },
  {
    "text": "who never work if he killed previously he has some knowledge of sequence and",
    "start": "808740",
    "end": "814800"
  },
  {
    "text": "also be a tool but never work with ETA and he learn metallian quite fast using",
    "start": "814800",
    "end": "820200"
  },
  {
    "text": "the available tutorials and using our help and as the first project that he built he basically they built the",
    "start": "820200",
    "end": "827250"
  },
  {
    "text": "complete detailed job of integrating with Adwords and getting data from Edwards and for example we never had",
    "start": "827250",
    "end": "835110"
  },
  {
    "text": "Edwards data in our network house previously because this is was a such big project with the scripting to write",
    "start": "835110",
    "end": "841200"
  },
  {
    "text": "the code to get in using Google API and getting the data but with my Dylan our",
    "start": "841200",
    "end": "848480"
  },
  {
    "text": "business user with some advanced skills and the sequel was was able to figure",
    "start": "848480",
    "end": "853530"
  },
  {
    "text": "out how to use my Chilean to set up the job and low daily into redshift AdWords",
    "start": "853530",
    "end": "859530"
  },
  {
    "text": "data just driving more in size and and we continue to expand this since how",
    "start": "859530",
    "end": "865650"
  },
  {
    "text": "business team starting to look in two different data sources some of them look into the JIRA in other loops Salesforce",
    "start": "865650",
    "end": "872600"
  },
  {
    "text": "Facebook YouTube all those data source where we are getting and the good news that our team later hasn't been a team",
    "start": "872600",
    "end": "879990"
  },
  {
    "text": "they not really involved this anymore and we can focus on more core features",
    "start": "879990",
    "end": "885240"
  },
  {
    "text": "and this is how and architecture we still have this the same relational databases but also we",
    "start": "885240",
    "end": "894350"
  },
  {
    "text": "get no sequel database for our listing inventory because we need something",
    "start": "894350",
    "end": "900020"
  },
  {
    "text": "scalable and fast and we start using DynamoDB we we have external appears we",
    "start": "900020",
    "end": "905630"
  },
  {
    "text": "have SFTP and we have different apps and most of the apps martyrium cover with built in sources and also that we've",
    "start": "905630",
    "end": "913280"
  },
  {
    "text": "ever released they released something new and especially they really listened the customers because personally for a",
    "start": "913280",
    "end": "920390"
  },
  {
    "text": "books we talked exactly what we want to cover our use cases and we found those",
    "start": "920390",
    "end": "926390"
  },
  {
    "text": "features in the new releases of material and we all we manage all our data",
    "start": "926390",
    "end": "932180"
  },
  {
    "text": "warehouse in a SS were so proud private cloud where we have tableau we have",
    "start": "932180",
    "end": "939280"
  },
  {
    "text": "redshift we have email and we have s3 buckets that serve us as a data Lake and",
    "start": "939280",
    "end": "947200"
  },
  {
    "text": "the good news here about metallian what we enjoying this material is a not",
    "start": "947200",
    "end": "953420"
  },
  {
    "text": "really powerful instance it's quite small ec2 instance that orchestrate the whole your data warehouse and basically",
    "start": "953420",
    "end": "960650"
  },
  {
    "text": "for the material it doesn't matter how big your data set because it this is a constraint constraint a tool that get",
    "start": "960650",
    "end": "967400"
  },
  {
    "text": "data from the source load or relative but not actually touching today this is",
    "start": "967400",
    "end": "973250"
  },
  {
    "text": "true ELT approach then you first extracted data then load data into the",
    "start": "973250",
    "end": "978860"
  },
  {
    "text": "target and starting transformation this and using metallian we can extract data",
    "start": "978860",
    "end": "984650"
  },
  {
    "text": "from the all our sources even no sequel databases load into s3 bucket and then",
    "start": "984650",
    "end": "991490"
  },
  {
    "text": "redshift then using my Chilean you not sink everything what going under good",
    "start": "991490",
    "end": "997190"
  },
  {
    "text": "because with your default way working through fred shift you need first put date into s3 bucket and then using copy",
    "start": "997190",
    "end": "1003910"
  },
  {
    "text": "command to put it in red you think my dealing just specify your source and target like source this is",
    "start": "1003910",
    "end": "1011200"
  },
  {
    "text": "dynamodb table target redshift table in my chilean will do the rest for you provide you clear identification and",
    "start": "1011200",
    "end": "1018460"
  },
  {
    "text": "clear login click you can see step by step what going on exactly and I would like to",
    "start": "1018460",
    "end": "1024308"
  },
  {
    "text": "talk a bit about our end user experience because as I mentioned we really focus",
    "start": "1024309",
    "end": "1029319"
  },
  {
    "text": "to aiding failure for the business and before we start our project we conduct",
    "start": "1029319",
    "end": "1036010"
  },
  {
    "text": "the BI survey and this is a really good way to get feedback from the customers",
    "start": "1036010",
    "end": "1043178"
  },
  {
    "text": "or end-users in our cases the business user we would like to hear their voice",
    "start": "1043179",
    "end": "1048459"
  },
  {
    "text": "and know exactly what the pain points for them and it was some some of them",
    "start": "1048459",
    "end": "1054460"
  },
  {
    "text": "was really obvious some of them knew for us but most of them related to",
    "start": "1054460",
    "end": "1060780"
  },
  {
    "text": "complexity of our data warehouse solution our tail looked like black box",
    "start": "1060780",
    "end": "1066700"
  },
  {
    "text": "a lack of notification lack of the communication and it was tough for them and the problem that we as a behind a",
    "start": "1066700",
    "end": "1074500"
  },
  {
    "text": "treehouse team we didn't have enough time to address all those issues because we we just spent most of our time for",
    "start": "1074500",
    "end": "1082570"
  },
  {
    "text": "development because we couldn't we couldn't use any help from business usually because the technical bar was",
    "start": "1082570",
    "end": "1089169"
  },
  {
    "text": "really hard for them and using their",
    "start": "1089169",
    "end": "1094299"
  },
  {
    "text": "mighty lien we addressed lots of those things and improving please and",
    "start": "1094299",
    "end": "1099510"
  },
  {
    "text": "involving business users gave us lots of free time to doing the core integrations",
    "start": "1099510",
    "end": "1107260"
  },
  {
    "text": "or design the data models or working with friendships to to sizing kit and",
    "start": "1107260",
    "end": "1114630"
  },
  {
    "text": "ensure that we have good performance and I would like to cover one case with my",
    "start": "1114630",
    "end": "1120250"
  },
  {
    "text": "Chilean ETL and monitoring and verification by default you can use a SS",
    "start": "1120250",
    "end": "1126909"
  },
  {
    "text": "s and s topics just getting emails and we found that our user started to be",
    "start": "1126909",
    "end": "1131980"
  },
  {
    "text": "annoying getting too many emails that's why we start using Amazon chime this is",
    "start": "1131980",
    "end": "1137860"
  },
  {
    "text": "the same as a slack or any other messengers they can create the chat groups and using mighty lien and chime",
    "start": "1137860",
    "end": "1146440"
  },
  {
    "text": "web hooks basically we just trigger if something wrong or something good we",
    "start": "1146440",
    "end": "1151809"
  },
  {
    "text": "create custom notification that sent you to the chat group for example here I have an example where the file is loaded",
    "start": "1151809",
    "end": "1160259"
  },
  {
    "text": "and the business users that they get message in the messenger that everything",
    "start": "1160259",
    "end": "1165480"
  },
  {
    "text": "good and in the same way you can create different specification if something bad",
    "start": "1165480",
    "end": "1170909"
  },
  {
    "text": "and we had the plenty of them special design for technical teams for the",
    "start": "1170909",
    "end": "1176549"
  },
  {
    "text": "business teams for business demands and also the business person who responsible",
    "start": "1176549",
    "end": "1183139"
  },
  {
    "text": "for the BI work teams we call them bi champions they are now responsible to",
    "start": "1183139",
    "end": "1189419"
  },
  {
    "text": "set all notifications for their teams another thing with McQuillen it's",
    "start": "1189419",
    "end": "1196700"
  },
  {
    "text": "monitoring because if if the previous solution we had a lack of monitoring and",
    "start": "1196700",
    "end": "1201860"
  },
  {
    "text": "all the users god they got email your",
    "start": "1201860",
    "end": "1207600"
  },
  {
    "text": "ETL process is done and lots of the text there but now using material logs we",
    "start": "1207600",
    "end": "1214320"
  },
  {
    "text": "could visualize everything what's happened in my Chilean and this is example of the Gantt chart that we",
    "start": "1214320",
    "end": "1220139"
  },
  {
    "text": "visualized in tableau and users can sell serve them they example the morning",
    "start": "1220139",
    "end": "1225240"
  },
  {
    "text": "start the users came if they didn't get any message in the chat groups about",
    "start": "1225240",
    "end": "1231330"
  },
  {
    "text": "CTLs crashed that they still can go to this dashboard and look how their particular Hill was working if they",
    "start": "1231330",
    "end": "1237809"
  },
  {
    "text": "interesting can give different data source they can filter these and see did",
    "start": "1237809",
    "end": "1245970"
  },
  {
    "text": "they get all files did they get all data and issues how long could take and also we using list to see how our Excel works",
    "start": "1245970",
    "end": "1253649"
  },
  {
    "text": "they overtake this is example of the",
    "start": "1253649",
    "end": "1258710"
  },
  {
    "text": "common detail job and format iliyan that",
    "start": "1258710",
    "end": "1263759"
  },
  {
    "text": "we said for most of our process this is top level overview of this job basically",
    "start": "1263759",
    "end": "1269730"
  },
  {
    "text": "you start your job then you load raw data you getting data from the service",
    "start": "1269730",
    "end": "1275789"
  },
  {
    "text": "law to the staging or data lake and then you you have the step of check-in data",
    "start": "1275789",
    "end": "1282809"
  },
  {
    "text": "quality because sometimes you can you can load not all data or you can get",
    "start": "1282809",
    "end": "1288000"
  },
  {
    "text": "some issues that's why this step is chicken check data quality right now we using Python basically to run different user",
    "start": "1288000",
    "end": "1296450"
  },
  {
    "text": "usual tests and accepting tests to see the data to compare the number of rows",
    "start": "1296450",
    "end": "1301739"
  },
  {
    "text": "and different other metric just to understand that is it good or bad also we using SQS and this is a table a",
    "start": "1301739",
    "end": "1311789"
  },
  {
    "text": "skewer for trigger some other process for example this particular jobs will",
    "start": "1311789",
    "end": "1318509"
  },
  {
    "text": "load data for the marketing or for the sales and then I finish it can trigger something different it can trigger the",
    "start": "1318509",
    "end": "1326099"
  },
  {
    "text": "different job or trigger report whatever just whatever you want and metallian can",
    "start": "1326099",
    "end": "1331229"
  },
  {
    "text": "easy integrate different projects in different entities together and using sqs you can trigger those elements and",
    "start": "1331229",
    "end": "1338839"
  },
  {
    "text": "also here we data then they pass the data check if everything good we go",
    "start": "1338839",
    "end": "1345269"
  },
  {
    "text": "forward to load our fact tables and dimension tables and material provides rich capabilities of transformation",
    "start": "1345269",
    "end": "1352440"
  },
  {
    "text": "components for example now case we we we need to support dimensional modeling it",
    "start": "1352440",
    "end": "1357989"
  },
  {
    "text": "means we need to be built fact table we need to build dimension tables and metallian provide you special components",
    "start": "1357989",
    "end": "1365219"
  },
  {
    "text": "that allow you to design your dimensional table and it supports slowly",
    "start": "1365219",
    "end": "1371820"
  },
  {
    "text": "change dimension options that's why it's exactly what we need for our use case if if something front where users get and",
    "start": "1371820",
    "end": "1379169"
  },
  {
    "text": "detail to team will get the chyme notification that it's bad and also if",
    "start": "1379169",
    "end": "1384989"
  },
  {
    "text": "you will get the message with the error and everything good the moving forward to integrated file bi tool because",
    "start": "1384989",
    "end": "1393209"
  },
  {
    "text": "previously our bi tool live there its own life and detail lift over life for",
    "start": "1393209",
    "end": "1399479"
  },
  {
    "text": "example your reports scheduled 9 a.m. and use the pause that each end will",
    "start": "1399479",
    "end": "1405929"
  },
  {
    "text": "finish at 8:00 a.m. it's enough time to run all the reporters but sometimes detail could delay it",
    "start": "1405929",
    "end": "1411989"
  },
  {
    "text": "ETL could could failed but you're bi staff will go anyway because you just",
    "start": "1411989",
    "end": "1417419"
  },
  {
    "text": "get out to 9 a.m. that's why using in particular example we were using tableau and we",
    "start": "1417419",
    "end": "1424290"
  },
  {
    "text": "using tap CMD and we deploy comment lines and face of tableau on top of my",
    "start": "1424290",
    "end": "1430350"
  },
  {
    "text": "Chilean ec2 instance and now my Chilean can easily trigger different reports and",
    "start": "1430350",
    "end": "1436400"
  },
  {
    "text": "data sources and refresh date it means the end users will get their reports",
    "start": "1436400",
    "end": "1442650"
  },
  {
    "text": "only if ETL is done successfully and it pass all data checks as a result again",
    "start": "1442650",
    "end": "1448410"
  },
  {
    "text": "we improve end-user experience but by providing them only high quality content",
    "start": "1448410",
    "end": "1453480"
  },
  {
    "text": "a right and time and material definitely a support helped us to increase our",
    "start": "1453480",
    "end": "1459600"
  },
  {
    "text": "service level agreement for the end users and we collected bags if the users",
    "start": "1459600",
    "end": "1465360"
  },
  {
    "text": "and they they really happy about this and they enjoy working with material because it's user friendly everyone who",
    "start": "1465360",
    "end": "1471960"
  },
  {
    "text": "interests it can easily log in and see data lineage and they can get",
    "start": "1471960",
    "end": "1477690"
  },
  {
    "text": "documentation from my Chilean because it's generated automatically they can always go to confluence and see",
    "start": "1477690",
    "end": "1485010"
  },
  {
    "text": "information about particular job and everything good yes and some of lessons",
    "start": "1485010",
    "end": "1491310"
  },
  {
    "text": "lessons that we learn then we go into the cloud you need to choose the right",
    "start": "1491310",
    "end": "1498450"
  },
  {
    "text": "immigration strategy in our case because you you can use the strategy like lift",
    "start": "1498450",
    "end": "1504390"
  },
  {
    "text": "and shift or you can start going by pieces and and we prefer going by pieces",
    "start": "1504390",
    "end": "1510510"
  },
  {
    "text": "that's why we we just moving the marketing then we move the sales then we move to inventory and it's important to",
    "start": "1510510",
    "end": "1517590"
  },
  {
    "text": "change your mindset because some things that work for you with your legacy later",
    "start": "1517590",
    "end": "1523290"
  },
  {
    "text": "a house and if you've dated Center in house and you have servers and the database and all and in other in an",
    "start": "1523290",
    "end": "1532020"
  },
  {
    "text": "another server has the heal tool the things works differently in the cloud and you should take this into",
    "start": "1532020",
    "end": "1538440"
  },
  {
    "text": "consideration but it definitely will increase the speed of development and reduce the cost and do not scare up on",
    "start": "1538440",
    "end": "1547680"
  },
  {
    "text": "the blog black box here I mean with the migration it gives us opportunity to",
    "start": "1547680",
    "end": "1553980"
  },
  {
    "text": "review of our ETL process because each in process keeps their business logics and we had two choices",
    "start": "1553980",
    "end": "1560740"
  },
  {
    "text": "okay we can just move logic as this or we can actually extract this logic and",
    "start": "1560740",
    "end": "1566340"
  },
  {
    "text": "see what was wrong and provide some something to improve this for example",
    "start": "1566340",
    "end": "1573840"
  },
  {
    "text": "one of our use case if attribution model we had really complicated attribution",
    "start": "1573840",
    "end": "1579280"
  },
  {
    "text": "model they coded in the script in the legacy data warehouse and we had",
    "start": "1579280",
    "end": "1584610"
  },
  {
    "text": "opportunity to move as this and save lot lots of the time but we decide okay if",
    "start": "1584610",
    "end": "1590290"
  },
  {
    "text": "it's not sufficient for the business user let's try to reopen this and completely rewrite of metallian and as a",
    "start": "1590290",
    "end": "1596770"
  },
  {
    "text": "result we we really improve this and we found even some issues in our production",
    "start": "1596770",
    "end": "1602200"
  },
  {
    "text": "attribution model that's why it's always good to work close with the business users and review a business logic and I",
    "start": "1602200",
    "end": "1611470"
  },
  {
    "text": "think I'm done with my story of a books and my password to the earth Johnson",
    "start": "1611470",
    "end": "1617880"
  },
  {
    "text": "Dmitry thank you very much for that great to hear story there of a books using material so hi everybody I'm Tom",
    "start": "1617880",
    "end": "1626440"
  },
  {
    "text": "said I'm CTO metallian and I very briefly just take a step back from the",
    "start": "1626440",
    "end": "1633190"
  },
  {
    "text": "great detailed explanation that Dimitri's provided there and just talk about the product and material in",
    "start": "1633190",
    "end": "1639640"
  },
  {
    "text": "general and then we've got about five ten minutes left so hopefully I'll give you a quick demo of the product so we",
    "start": "1639640",
    "end": "1645490"
  },
  {
    "text": "can see we can see what's going on here so hopefully if I've got control these",
    "start": "1645490",
    "end": "1650830"
  },
  {
    "text": "slides yeah good so battalion as dimitris kind of",
    "start": "1650830",
    "end": "1656800"
  },
  {
    "text": "explained a couple of times there until Ian takes a slightly different approach to most ETL tools and we are a ELT first",
    "start": "1656800",
    "end": "1663370"
  },
  {
    "text": "tool and we're built for the cloud and for the data warehouse and this diagram",
    "start": "1663370",
    "end": "1668860"
  },
  {
    "text": "here is really designed to demonstrate that in an ETL scenario when you're",
    "start": "1668860",
    "end": "1674290"
  },
  {
    "text": "putting together source data and staging it and then transforming it",
    "start": "1674290",
    "end": "1679930"
  },
  {
    "text": "the difference with ELT are particularly ELT on on on a cloud base data warehouse",
    "start": "1679930",
    "end": "1687130"
  },
  {
    "text": "they're redshift is that doing the L on the T on the data warehouse you get all kinds of great",
    "start": "1687130",
    "end": "1693999"
  },
  {
    "text": "advantages you get advantages of scale you get all the performance and the",
    "start": "1693999",
    "end": "1699909"
  },
  {
    "text": "parallelization of a really capable underlying platform like redshift and",
    "start": "1699909",
    "end": "1705700"
  },
  {
    "text": "then by doing that in a cloud native way and really sort of doubling down and",
    "start": "1705700",
    "end": "1710739"
  },
  {
    "text": "building into the holy AWS ecosystem that allows us to build a product which is making use of all of the fantastic",
    "start": "1710739",
    "end": "1718860"
  },
  {
    "text": "pieces of platform infrastructure that AWS provides but allowing the user to",
    "start": "1718860",
    "end": "1726399"
  },
  {
    "text": "really easily build them together into an ETL pipeline solution and overall",
    "start": "1726399",
    "end": "1732970"
  },
  {
    "text": "what does that give you inside am Italian it gives you speed to meet you talked about the speed of development",
    "start": "1732970",
    "end": "1738730"
  },
  {
    "text": "but also the speed of the ETL processing itself speed ETL processing itself we",
    "start": "1738730",
    "end": "1745239"
  },
  {
    "text": "don't take too much credit for that that's really redshift doing the hard work of the actual data processing but",
    "start": "1745239",
    "end": "1751299"
  },
  {
    "text": "the speed of actually building those ETL processes that's that's thanks to both",
    "start": "1751299",
    "end": "1757419"
  },
  {
    "text": "the underlying platform and matil ian's just ease-of-use and simplicity the",
    "start": "1757419",
    "end": "1764080"
  },
  {
    "text": "simplicity is really you know we designed the tool initially to be usable",
    "start": "1764080",
    "end": "1769809"
  },
  {
    "text": "by any ETL developer who is coming from a familiar sort legacy ETL platform when",
    "start": "1769809",
    "end": "1776080"
  },
  {
    "text": "when we're working when we're working with those existing others what we tend",
    "start": "1776080",
    "end": "1781690"
  },
  {
    "text": "to find is because of the pushdown approach and because of the type validation that a database like redshift",
    "start": "1781690",
    "end": "1787059"
  },
  {
    "text": "provides also it's a far less error-prone process by doing it in an",
    "start": "1787059",
    "end": "1794289"
  },
  {
    "text": "ETL manner and hopefully you'll see that a little bit in a second and then finally there's the scalability of the",
    "start": "1794289",
    "end": "1799809"
  },
  {
    "text": "platform so everything that's built on AWS all the platforms are serviced",
    "start": "1799809",
    "end": "1806499"
  },
  {
    "text": "pieces hundreds of now services that make up AWS of which million users a",
    "start": "1806499",
    "end": "1812109"
  },
  {
    "text": "fair number are built from the ground up to be scalable so naturally by by",
    "start": "1812109",
    "end": "1819009"
  },
  {
    "text": "turning those pieces into into a an ETL approach which takes into account",
    "start": "1819009",
    "end": "1824799"
  },
  {
    "text": "the data ingestion the actual processing of the data and then thinks about where",
    "start": "1824799",
    "end": "1830590"
  },
  {
    "text": "it's where it's going to go next and all the peripheral things that go around that you do get a fantastic scalability",
    "start": "1830590",
    "end": "1837280"
  },
  {
    "text": "and again dmitri test had a little testimony in there to the fact that he runs a very small instance most of them",
    "start": "1837280",
    "end": "1845350"
  },
  {
    "text": "are tooling customers run the chilean itself on a very small instance like a medium or like an m3 m5 large or",
    "start": "1845350",
    "end": "1853090"
  },
  {
    "text": "extra-large instance probably the biggest that you'd run but the underlying platform like redshift does",
    "start": "1853090",
    "end": "1860500"
  },
  {
    "text": "the majority that heavy lifting okay so to engage brazilian we are exclusive to",
    "start": "1860500",
    "end": "1869650"
  },
  {
    "text": "the AWS marketplace so you buy in Mytilene as an AWS marketplace and it",
    "start": "1869650",
    "end": "1875559"
  },
  {
    "text": "launches as an ami into your AWS infrastructure it's not a SAS service",
    "start": "1875559",
    "end": "1880990"
  },
  {
    "text": "you have full control over it you have root access to the ami that runs and and",
    "start": "1880990",
    "end": "1887409"
  },
  {
    "text": "you have full control over the security where the data is going where it's coming in where it's going out but it",
    "start": "1887409",
    "end": "1893409"
  },
  {
    "text": "still only takes five minutes to stand up in your environment because of the way the marketplace makes it really easy to deploy software we've got a 14-day",
    "start": "1893409",
    "end": "1900700"
  },
  {
    "text": "free trial and pricing starts from $1 37 an hour we also got a big support and s",
    "start": "1900700",
    "end": "1907330"
  },
  {
    "text": "a team or a really designed to help on board and hopefully some of the things that Dimitri mentioned there are talking",
    "start": "1907330",
    "end": "1913120"
  },
  {
    "text": "about sa team helping him through getting up and running in the ETL",
    "start": "1913120",
    "end": "1918490"
  },
  {
    "text": "processes so let's switch over to a let's switch over to a quick demo if I",
    "start": "1918490",
    "end": "1924309"
  },
  {
    "text": "may and I'm just gonna briefly show you the product ok so hopefully at this",
    "start": "1924309",
    "end": "1930039"
  },
  {
    "text": "point you can see my screen this is the material ETL tool itself and first thing",
    "start": "1930039",
    "end": "1936039"
  },
  {
    "text": "you want to notice of course you're in a web browser McLean is a is a browser-based tool primarily and all of",
    "start": "1936039",
    "end": "1943450"
  },
  {
    "text": "the ETL building work will look we will be done in the browser and anybody that's familiar with an ETL tool will be",
    "start": "1943450",
    "end": "1951190"
  },
  {
    "text": "fairly familiar with the sort of component based approach",
    "start": "1951190",
    "end": "1956429"
  },
  {
    "text": "that we see here where we build outflows that represent our data pipeline in this",
    "start": "1956429",
    "end": "1963160"
  },
  {
    "text": "particular example I'm looking at a transformation job in Italian so this is taking data that's already in red shift",
    "start": "1963160",
    "end": "1970500"
  },
  {
    "text": "and transforming that data and typically customers are building data lakes",
    "start": "1970500",
    "end": "1976090"
  },
  {
    "text": "they're building data warehouses they're taking complex messy source data",
    "start": "1976090",
    "end": "1983190"
  },
  {
    "text": "possibly from disparate systems particularly in inter matrix case we saw we saw a four or five different",
    "start": "1983190",
    "end": "1989950"
  },
  {
    "text": "disparate systems all being brought together and they're generally they're denormalizing data they're simplifying",
    "start": "1989950",
    "end": "1996039"
  },
  {
    "text": "datasets and they're getting to a simple understandable analytic outputs that are suitable and ready to be used in a data",
    "start": "1996039",
    "end": "2002850"
  },
  {
    "text": "analysis tool you know of which there are many available tableau look quick",
    "start": "2002850",
    "end": "2011400"
  },
  {
    "text": "site a whole load of whole long list and then what makes metallian different is",
    "start": "2011400",
    "end": "2016440"
  },
  {
    "text": "that all of the steps that are going on here in this process are pushed down to",
    "start": "2016440",
    "end": "2022350"
  },
  {
    "text": "the underlying redshift database so to give you an example of what that looks like we have a starting point here and",
    "start": "2022350",
    "end": "2028830"
  },
  {
    "text": "this is a flight table use of flight data set here and we're still working with a reasonable data sets and working",
    "start": "2028830",
    "end": "2035490"
  },
  {
    "text": "with 123 million 123 million rows of data here and then the next step along",
    "start": "2035490",
    "end": "2042750"
  },
  {
    "text": "here is filter components the ability jobs are part of components or components for reading data in",
    "start": "2042750",
    "end": "2048929"
  },
  {
    "text": "components for joining data together and a whole load of components for transforming data before finally writing",
    "start": "2048929",
    "end": "2055200"
  },
  {
    "text": "it out if we go to this second step in the process where we've got some data",
    "start": "2055200",
    "end": "2061590"
  },
  {
    "text": "filtered out so now I'm working with 28 million rows of data and each of these",
    "start": "2061590",
    "end": "2068220"
  },
  {
    "text": "components has a set of properties that really guide you through the setup so at this point we get to a we are joined",
    "start": "2068220",
    "end": "2077878"
  },
  {
    "text": "where we joined on another data set this is a small data set here where I'm just joining on some plain information",
    "start": "2077879",
    "end": "2084710"
  },
  {
    "text": "massive data sets and plain information on to my main flights data set",
    "start": "2084710",
    "end": "2090210"
  },
  {
    "text": "by the time I get to here I'm ready to set up a join just to give you a feel",
    "start": "2090210",
    "end": "2095398"
  },
  {
    "text": "for what it's like to set up a component inside am italian just gonna remove that join and re-add it to give you a feel",
    "start": "2095399",
    "end": "2102510"
  },
  {
    "text": "for it you'll notice all the components that are downstream now I've gone red that's the validation that's been pushed",
    "start": "2102510",
    "end": "2109200"
  },
  {
    "text": "down to the underlying redshift server because redshift is validating every",
    "start": "2109200",
    "end": "2114630"
  },
  {
    "text": "step in this ETL process that then makes it really easy so all really reliable to",
    "start": "2114630",
    "end": "2122790"
  },
  {
    "text": "the point where when you get everything validated you know your ETL process is going to run end to end so I'm gonna",
    "start": "2122790",
    "end": "2130080"
  },
  {
    "text": "read out this join and I'm gonna bring in my dataset for my flights and my data set for my planes so I've set up a join",
    "start": "2130080",
    "end": "2137280"
  },
  {
    "text": "all components in the Trillium work this same way and in that they you have a series of properties which have guided",
    "start": "2137280",
    "end": "2142290"
  },
  {
    "text": "so everything guides you through setting up this is what it makes this is what makes and democratizes the ETL process",
    "start": "2142290",
    "end": "2148650"
  },
  {
    "text": "makes it easy for not just ETL developers but a whole range of data savvy users right across your",
    "start": "2148650",
    "end": "2156420"
  },
  {
    "text": "organization so we start with flights that took off I say I'm gonna call that",
    "start": "2156420",
    "end": "2161849"
  },
  {
    "text": "my flights and then I'm gonna take and I'm gonna join that with in this case",
    "start": "2161849",
    "end": "2168599"
  },
  {
    "text": "just one table here which is my planes and that's going to be an inner join",
    "start": "2168599",
    "end": "2174300"
  },
  {
    "text": "gonna join those two data centers together we go and set up a joint expression this window looks kind of a",
    "start": "2174300",
    "end": "2180480"
  },
  {
    "text": "little bit more complicated but basically gives you everything that you need including all of your redshift functions and guide you through actually",
    "start": "2180480",
    "end": "2188099"
  },
  {
    "text": "creating the join between these two tables in this example it's nice simple I'm gonna take my flight tale number and",
    "start": "2188099",
    "end": "2195450"
  },
  {
    "text": "I'm gonna join that on to my plane's tail number this will validate as I type so if I",
    "start": "2195450",
    "end": "2201390"
  },
  {
    "text": "mistyped anything there I'd get a validation error then if I ok that finally I just need to choose my output",
    "start": "2201390",
    "end": "2207660"
  },
  {
    "text": "from my join at that point that joint pushes down to redshift and validates",
    "start": "2207660",
    "end": "2212849"
  },
  {
    "text": "and now I can just tie everything together so my downstream components",
    "start": "2212849",
    "end": "2218810"
  },
  {
    "text": "well we'll take all of my we'll take we'll take all of my previous",
    "start": "2218810",
    "end": "2224509"
  },
  {
    "text": "join so she's gonna set up that joint that I should fix all that there we go soft I've fixed my job and",
    "start": "2224509",
    "end": "2233210"
  },
  {
    "text": "then ultimately what this does at the end is it creates a sequel statement",
    "start": "2233210",
    "end": "2239990"
  },
  {
    "text": "which will be pushed down on to redshift and manages all of that sequel so you've",
    "start": "2239990",
    "end": "2246200"
  },
  {
    "text": "got visual representation of your jobs other things that you get on the on the",
    "start": "2246200",
    "end": "2253839"
  },
  {
    "text": "on the on the orchestra or the transformation side of the tool",
    "start": "2253839",
    "end": "2259539"
  },
  {
    "text": "obviously you saw the ability to sample the data at each and every stage in the process that's really powerful for users",
    "start": "2259539",
    "end": "2266690"
  },
  {
    "text": "when building ETLs because they know what they've done and what they've done works when they're done right so if I",
    "start": "2266690",
    "end": "2271999"
  },
  {
    "text": "sample my data on my join I can scroll over to the right hand side and I can see yes I've successfully joined the",
    "start": "2271999",
    "end": "2278960"
  },
  {
    "text": "plane information to the fly information so I know I've done that step correctly I can move on to the next step and",
    "start": "2278960",
    "end": "2285200"
  },
  {
    "text": "that's really powerful while building these these things up for more enterprise users we've got the ability to understand the data lineage which",
    "start": "2285200",
    "end": "2291769"
  },
  {
    "text": "again that Dimitri mentioned a couple of times and we can also go away and see exactly what redshift is gonna do when",
    "start": "2291769",
    "end": "2298099"
  },
  {
    "text": "it's executing these these data these data transformations everything that you",
    "start": "2298099",
    "end": "2304910"
  },
  {
    "text": "see here can be parameterized so we can build these jobs with variables to make them entirely reusable and we get some",
    "start": "2304910",
    "end": "2311900"
  },
  {
    "text": "customers doing some extremely sophisticated ETL work that makes you reusable components out of pieces of ETL",
    "start": "2311900",
    "end": "2319239"
  },
  {
    "text": "very very powerful particularly in organizations where lots of similar ETL projects going on at the same time after",
    "start": "2319239",
    "end": "2327109"
  },
  {
    "text": "the orchestration that's all on data that was already in redshift I flip over to the transformation I flip over to the",
    "start": "2327109",
    "end": "2335630"
  },
  {
    "text": "orchestration side of metallian this is kind of what knits everything together",
    "start": "2335630",
    "end": "2340640"
  },
  {
    "text": "so this is the overall data pipeline from start to finish you can kind of think of this as a script and I've got a",
    "start": "2340640",
    "end": "2347900"
  },
  {
    "text": "little example here where we have a stock component we create some tables of",
    "start": "2347900",
    "end": "2354319"
  },
  {
    "text": "these four squares here away with creating some tables and then we do various data loads and this is really",
    "start": "2354319",
    "end": "2362010"
  },
  {
    "text": "just it is designed to show you the different data loads that are available so we've got some data coming from our",
    "start": "2362010",
    "end": "2368460"
  },
  {
    "text": "RDS database in AWS we've got some data coming from a REST API using a generic",
    "start": "2368460",
    "end": "2374820"
  },
  {
    "text": "REST API component we've got some data coming from a good old spreadsheet and",
    "start": "2374820",
    "end": "2380520"
  },
  {
    "text": "then we've got some data that we load directly from s3 right at the start of the of the webinar Ryan talked a little",
    "start": "2380520",
    "end": "2387600"
  },
  {
    "text": "bit about data lakes one of obviously the great new relatively new features of",
    "start": "2387600",
    "end": "2393800"
  },
  {
    "text": "redshift is red shift spectrum which allows us to load data directly from an",
    "start": "2393800",
    "end": "2399720"
  },
  {
    "text": "s3 data like from a data catalog in there that's baked intimately and so you",
    "start": "2399720",
    "end": "2405450"
  },
  {
    "text": "can use those data catalogues in transformations and orchestration straight off the bat and there's really",
    "start": "2405450",
    "end": "2411570"
  },
  {
    "text": "no difference to where you're loading your data from all of these components support loading data directly into the",
    "start": "2411570",
    "end": "2418140"
  },
  {
    "text": "data Lake rather than moving it into redshift itself in this example so we create the tables we load the data we",
    "start": "2418140",
    "end": "2424560"
  },
  {
    "text": "bring it all together and then we go and execute a flight transformation and then",
    "start": "2424560",
    "end": "2429720"
  },
  {
    "text": "we have a series of different sort of integrations into AWS or things like",
    "start": "2429720",
    "end": "2435930"
  },
  {
    "text": "cloud watch SNS and SQS to say what happens downstream to send out",
    "start": "2435930",
    "end": "2441450"
  },
  {
    "text": "notifications alerts and do monitoring and there's quite a lot of sophistication about what you can do",
    "start": "2441450",
    "end": "2446910"
  },
  {
    "text": "with those components and finally if you want to take your data to the next step you can push that data back into s3 so",
    "start": "2446910",
    "end": "2452820"
  },
  {
    "text": "if you want to push it back into your data lake or if you want to move it into",
    "start": "2452820",
    "end": "2458790"
  },
  {
    "text": "a relational database PostgreSQL arora and you can use that RDS both output",
    "start": "2458790",
    "end": "2465480"
  },
  {
    "text": "component so that's the overall orchestration we have a scheduler built",
    "start": "2465480",
    "end": "2471420"
  },
  {
    "text": "into the tool or so you can just schedule this to run as often as you",
    "start": "2471420",
    "end": "2476460"
  },
  {
    "text": "like or you can have it triggered from lambda events from data arriving from",
    "start": "2476460",
    "end": "2482730"
  },
  {
    "text": "Kinesis in a stream all manner of different ways that you can sort of integrate metallian into a larger data",
    "start": "2482730",
    "end": "2489630"
  },
  {
    "text": "pipeline we are using other tools inside of AWS",
    "start": "2489630",
    "end": "2494670"
  },
  {
    "text": "and around that obviously there's lots more to show you I'll just finish by showing you some of",
    "start": "2494670",
    "end": "2500699"
  },
  {
    "text": "the data loading components we have about 60 of these dimitri mentioned that",
    "start": "2500699",
    "end": "2506009"
  },
  {
    "text": "we are kind of every new release every eight weeks we pushing new features we aim to deliver around about five new",
    "start": "2506009",
    "end": "2512999"
  },
  {
    "text": "dating data loading components every time we do that but I won't go through",
    "start": "2512999",
    "end": "2518009"
  },
  {
    "text": "them all but you have hopefully recognized quite a lot of these popular ones like NetSuite and Salesforce Google",
    "start": "2518009",
    "end": "2525959"
  },
  {
    "text": "Adwords and analytics keep pulling in marketing data and then some really sophisticated generic ones like the API",
    "start": "2525959",
    "end": "2531930"
  },
  {
    "text": "query which will connect any rest or XML based API the builds to get data out of",
    "start": "2531930",
    "end": "2538199"
  },
  {
    "text": "RDS s3 and then pulling things in from",
    "start": "2538199",
    "end": "2543239"
  },
  {
    "text": "FTP HTTP hives spark excetra like that so just about anywhere where you've got your data metallian should be able to",
    "start": "2543239",
    "end": "2550650"
  },
  {
    "text": "get that get that into redshift and start transforming it in one place okay",
    "start": "2550650",
    "end": "2559559"
  },
  {
    "text": "so I think at that point it's probably time to to open up for questions I think",
    "start": "2559559",
    "end": "2566039"
  },
  {
    "text": "we've got 15 minutes left so I'll hand back to to Ryan just to finish off",
    "start": "2566039",
    "end": "2571099"
  },
  {
    "text": "things I have to say both what you talked about when Dimitri talked about was a lot of very interesting",
    "start": "2571099",
    "end": "2577349"
  },
  {
    "text": "eye-opening things for me I especially loved Dimitri's integration with web hooks and the chyme",
    "start": "2577349",
    "end": "2583289"
  },
  {
    "text": "I think that's a fantastic way to update the customers and the environment I",
    "start": "2583289",
    "end": "2588599"
  },
  {
    "text": "think I may have start doing that myself there's a lot of great questions in here",
    "start": "2588599",
    "end": "2594420"
  },
  {
    "text": "this is a good time for you to add more if you have questions for any of the presenters and I'll go ahead and get",
    "start": "2594420",
    "end": "2600809"
  },
  {
    "text": "moving on them pretty quickly because there's a good good 15 first question",
    "start": "2600809",
    "end": "2606509"
  },
  {
    "text": "and could ask the question does metallian offer api's",
    "start": "2606509",
    "end": "2612380"
  },
  {
    "text": "so the full product is covered via my API so that includes basically",
    "start": "2612560",
    "end": "2618260"
  },
  {
    "text": "everything you saw in a little demo there creating jobs creating schedules",
    "start": "2618260",
    "end": "2623710"
  },
  {
    "text": "importing and exporting data a lot of people using the API to sort of transfer",
    "start": "2623710",
    "end": "2629810"
  },
  {
    "text": "between environments so go from dev to test alive or to push data all the data",
    "start": "2629810",
    "end": "2636140"
  },
  {
    "text": "behind the scenes in material is export to the last JSON files so there's no sort of special format everything's easy",
    "start": "2636140",
    "end": "2642440"
  },
  {
    "text": "easy to read and understand with better knowledge of the model yeah thoughtful",
    "start": "2642440",
    "end": "2647990"
  },
  {
    "text": "API coverage is a genre I've just pasted a link to the API documentation in the",
    "start": "2647990",
    "end": "2655100"
  },
  {
    "text": "question panel so if you maybe wants to click on that they can that's correct",
    "start": "2655100",
    "end": "2660820"
  },
  {
    "text": "next question I think is more for Dmitry so there's there's a two or three questions actually in here that kind of",
    "start": "2660820",
    "end": "2666170"
  },
  {
    "text": "talk about competitors people are asking you know how does until you compare with X and without naming any names because I",
    "start": "2666170",
    "end": "2672890"
  },
  {
    "text": "don't think we we should do that here what was the what was some of decision points for you for choosing metallian",
    "start": "2672890",
    "end": "2679940"
  },
  {
    "text": "over maybe other other products in the market yeah I don't know I don't exactly",
    "start": "2679940",
    "end": "2686390"
  },
  {
    "text": "blame any other vendors they go to that because every engineer judge in",
    "start": "2686390",
    "end": "2692000"
  },
  {
    "text": "different way but personally I found that I can't blame the whole market of",
    "start": "2692000",
    "end": "2697430"
  },
  {
    "text": "ETL tools in two different categories and I call it one of them built by",
    "start": "2697430",
    "end": "2702760"
  },
  {
    "text": "software development engineers but for software development engineers and other",
    "start": "2702760",
    "end": "2709510"
  },
  {
    "text": "that built by kinda like ETL folks for",
    "start": "2709510",
    "end": "2714680"
  },
  {
    "text": "retail folks and I belong to the group with ETL data warehouse and bi folks and",
    "start": "2714680",
    "end": "2721130"
  },
  {
    "text": "I used to work if with the legacy ETL tools but on the market for like decades",
    "start": "2721130",
    "end": "2727130"
  },
  {
    "text": "like informatica sa peepin Tasha and I'm comfortable work with them and it's",
    "start": "2727130",
    "end": "2734210"
  },
  {
    "text": "clear for me and enmity Liam belongs to those toes as well it's clear for me the",
    "start": "2734210",
    "end": "2740120"
  },
  {
    "text": "first day then I start with McKinnon it's it's clearer and I like I feel in",
    "start": "2740120",
    "end": "2746330"
  },
  {
    "text": "just okay I shouldn't do this and these because it's basically covering my my",
    "start": "2746330",
    "end": "2751790"
  },
  {
    "text": "previous experience but it's it was designed for the cloud which is infrared ship that's why feel the benefits but in",
    "start": "2751790",
    "end": "2758720"
  },
  {
    "text": "case if we will look any other tools especially currently on the market lots of cloud tools and I found that",
    "start": "2758720",
    "end": "2767600"
  },
  {
    "text": "some of them built by talented engineers and but the one drawback personally for",
    "start": "2767600",
    "end": "2776360"
  },
  {
    "text": "me they require encoding for example if I need anything out of the box if I need to bring data from even like sometimes I",
    "start": "2776360",
    "end": "2784070"
  },
  {
    "text": "then I relate them and I need to bring data from a safety pin where is no",
    "start": "2784070",
    "end": "2789560"
  },
  {
    "text": "connection to SFTP like in any other PTL",
    "start": "2789560",
    "end": "2795230"
  },
  {
    "text": "tool then I can just specify the hostname the port credentials it means I",
    "start": "2795230",
    "end": "2800300"
  },
  {
    "text": "need to write a code to bring SFTP if I want to do any transformations it's",
    "start": "2800300",
    "end": "2807710"
  },
  {
    "text": "again required to writing the code and again I don't know I didn't want to build the solution that will good will",
    "start": "2807710",
    "end": "2816440"
  },
  {
    "text": "work for surf the purpose of data warehouse and it's again will be kind of",
    "start": "2816440",
    "end": "2822410"
  },
  {
    "text": "like box for the business user because my goal was to to have the business and",
    "start": "2822410",
    "end": "2828110"
  },
  {
    "text": "user friendly tool that can do work really well and that's one we pick up until a good intro so thank you for that",
    "start": "2828110",
    "end": "2835580"
  },
  {
    "text": "I think I Kevin here asked a good question that I'm actually not clear on",
    "start": "2835580",
    "end": "2841220"
  },
  {
    "text": "the answer for so how did you access the login information form Italians that you",
    "start": "2841220",
    "end": "2847190"
  },
  {
    "text": "could report out on the status of your jobs yes we have two ways of doing this one",
    "start": "2847190",
    "end": "2854690"
  },
  {
    "text": "of them this is default logon than around the job because inside of nomads metallian it has MongoDB but also you",
    "start": "2854690",
    "end": "2862460"
  },
  {
    "text": "can use a relational database using RDS and its store all the data everything",
    "start": "2862460",
    "end": "2868250"
  },
  {
    "text": "what you see in that task history on the in the Frances running array all this",
    "start": "2868250",
    "end": "2873860"
  },
  {
    "text": "data is storing and you can use it material API just grab these data dump into the table and visualize this but",
    "start": "2873860",
    "end": "2880850"
  },
  {
    "text": "because we didn't know this we restart in different way each I'll let show you that each of the companion is can",
    "start": "2880850",
    "end": "2888020"
  },
  {
    "text": "parametrize and you can specify the parameters and it has default parameters like start date end date component name",
    "start": "2888020",
    "end": "2896540"
  },
  {
    "text": "the text message if it's error or success duration number of rows and what",
    "start": "2896540",
    "end": "2903080"
  },
  {
    "text": "we are doing for every hour job we basically write we take this information",
    "start": "2903080",
    "end": "2908810"
  },
  {
    "text": "from the companion for example out the table and we just insert into the detail table and the example that will show it",
    "start": "2908810",
    "end": "2916850"
  },
  {
    "text": "just visualization of this detail table that we built ourself using material",
    "start": "2916850",
    "end": "2923600"
  },
  {
    "text": "companions and just writing every company and finish the job and it ensures the one row into the",
    "start": "2923600",
    "end": "2930530"
  },
  {
    "text": "table if the timestamp start and duration et cetera and this is kind of our pattern that we just copy for rest",
    "start": "2930530",
    "end": "2939020"
  },
  {
    "text": "of the jobs I think the good idea the",
    "start": "2939020",
    "end": "2944200"
  },
  {
    "text": "interesting to report out on your pipeline which is a good good news um on",
    "start": "2944200",
    "end": "2949480"
  },
  {
    "text": "I think this one's for add I battalion can run in an HJ configuration if it's",
    "start": "2949480",
    "end": "2956300"
  },
  {
    "text": "if so how does it handle fail overs yeah that's right so yeah we can run in",
    "start": "2956300",
    "end": "2964200"
  },
  {
    "text": "a in an a chain configuration the the bits of the product that are HJ the what",
    "start": "2964200",
    "end": "2972150"
  },
  {
    "text": "the H a setup is you set up a couple of instances across as many as you want but",
    "start": "2972150",
    "end": "2979740"
  },
  {
    "text": "most people are running two instances across to availability zones that's backed up by a post press cluster across",
    "start": "2979740",
    "end": "2987660"
  },
  {
    "text": "to about the same usually percent to availability zones with with the usual",
    "start": "2987660",
    "end": "2993420"
  },
  {
    "text": "sort of active passive configuration on the postcode cluster itself redshift the",
    "start": "2993420",
    "end": "3000310"
  },
  {
    "text": "matil in front and maintained state and the cluster sorry the scheduler is",
    "start": "3000310",
    "end": "3006950"
  },
  {
    "text": "clustered so anything that's going through the scheduler I anything that",
    "start": "3006950",
    "end": "3012470"
  },
  {
    "text": "scheduled will be active active failover so basically if either one of the the",
    "start": "3012470",
    "end": "3018950"
  },
  {
    "text": "knows fails the ETL processors will continue to run if pro se ETL processes",
    "start": "3018950",
    "end": "3025880"
  },
  {
    "text": "that are in flight at the moment will fail but then will be rerun by the",
    "start": "3025880",
    "end": "3032810"
  },
  {
    "text": "scheduler on the other node in future",
    "start": "3032810",
    "end": "3037940"
  },
  {
    "text": "will have the ability to allow those processes to pick up from a music that",
    "start": "3037940",
    "end": "3044510"
  },
  {
    "text": "user designated sort of waypoint rather than having to start over from scratch",
    "start": "3044510",
    "end": "3051140"
  },
  {
    "text": "but that's not in there right now that's coming soon I think so and so I'm David",
    "start": "3051140",
    "end": "3058730"
  },
  {
    "text": "like to know if spark and or flank are in your connectivity with",
    "start": "3058730",
    "end": "3065510"
  },
  {
    "text": "so yes the spark yes",
    "start": "3065510",
    "end": "3072040"
  },
  {
    "text": "link I'm not familiar with so yes sparks actually not in there right now",
    "start": "3072040",
    "end": "3078320"
  },
  {
    "text": "spark is we expect to release that in our next release on the 25th of this",
    "start": "3078320",
    "end": "3084830"
  },
  {
    "text": "month I believe so I'm saying it's in because I've seen it in but it's not actually shipped yet in like a setup",
    "start": "3084830",
    "end": "3092690"
  },
  {
    "text": "question yeah now honestly not favorite I'm not familiar with the second one",
    "start": "3092690",
    "end": "3100000"
  },
  {
    "text": "yeah I think link is just a little bit less used so I'm I'm assuming customers need to do it would probably be MLS",
    "start": "3100000",
    "end": "3106660"
  },
  {
    "text": "let's the business a question how about code maintenance if I wanted to find out",
    "start": "3106660",
    "end": "3112040"
  },
  {
    "text": "for example how many mapping a table is using as a source",
    "start": "3112040",
    "end": "3117700"
  },
  {
    "text": "yeah that's a great question so that's a feature of our lineage so our lineage",
    "start": "3119060",
    "end": "3127770"
  },
  {
    "text": "works in both directions so it's back was lineage and forwards lineage so with backwards lineage you'll be looking at a",
    "start": "3127770",
    "end": "3133380"
  },
  {
    "text": "particular output table and working out how particular column got populated and",
    "start": "3133380",
    "end": "3138720"
  },
  {
    "text": "you know what calculations and how many source tables are involved and all that sort of thing with forward lineage you",
    "start": "3138720",
    "end": "3147180"
  },
  {
    "text": "can work out given you know this source table go and tell me all the places that",
    "start": "3147180",
    "end": "3153000"
  },
  {
    "text": "it's used downstream I think you have the word versioning in the question as",
    "start": "3153000",
    "end": "3158730"
  },
  {
    "text": "well so there is a versioning system built into matil Ian and we have git integration coming early next year for",
    "start": "3158730",
    "end": "3167520"
  },
  {
    "text": "Andrew Shen ask the question what about some customized transformation steps",
    "start": "3167520",
    "end": "3173700"
  },
  {
    "text": "could we for example use our Python and loop that intimate ileum",
    "start": "3173700",
    "end": "3180230"
  },
  {
    "text": "yes you can so we provide the ability to",
    "start": "3180260",
    "end": "3186130"
  },
  {
    "text": "kick out into Python in an orchestration but also you can write Python",
    "start": "3186130",
    "end": "3192730"
  },
  {
    "text": "user-defined functions and call those inside of a transformation and then you",
    "start": "3192730",
    "end": "3198410"
  },
  {
    "text": "can wrap all of that up in concept in material called a shared job which",
    "start": "3198410",
    "end": "3204320"
  },
  {
    "text": "essentially takes a piece of ETL livre and does something doesn't matter what",
    "start": "3204320",
    "end": "3209510"
  },
  {
    "text": "it is and it takes any parameters that you've set and turns that into its own",
    "start": "3209510",
    "end": "3216770"
  },
  {
    "text": "component essentially with its own you know can even have its own icon so a",
    "start": "3216770",
    "end": "3223250"
  },
  {
    "text": "good example of that is if your traditional data warehousing you tend to write build a date dimension every",
    "start": "3223250",
    "end": "3229579"
  },
  {
    "text": "project project has a date dimension every project does it differently but you could build a date dimension job",
    "start": "3229579",
    "end": "3236150"
  },
  {
    "text": "which had some centered some parameters like when it started when it finished what columns who were involved and went",
    "start": "3236150",
    "end": "3242599"
  },
  {
    "text": "away and build the date dimension so you'd get consistent they dimensions across all your data warehouse assets",
    "start": "3242599",
    "end": "3248660"
  },
  {
    "text": "that's that's that's the best example I can cover for the top of my hat I'm the decimal question we we currently",
    "start": "3248660",
    "end": "3256940"
  },
  {
    "text": "maintain a lot of documentation for users to track how an attribute warehouse table is loaded there any way",
    "start": "3256940",
    "end": "3263420"
  },
  {
    "text": "the Mattila in' simplifies that it does definitely so it does sound like",
    "start": "3263420",
    "end": "3268880"
  },
  {
    "text": "recessive question yes so matil ian has built in documentation so you can",
    "start": "3268880",
    "end": "3275750"
  },
  {
    "text": "document your entire ETL process from end to end and you might have noticed in",
    "start": "3275750",
    "end": "3280910"
  },
  {
    "text": "my demo that a lot of the a lot of the kind of pages has had little yellow",
    "start": "3280910",
    "end": "3289069"
  },
  {
    "text": "notes on them and you can you can actually join those yellow yellow notes",
    "start": "3289069",
    "end": "3295430"
  },
  {
    "text": "with particular components and then that will come through in the automatically generated documentation as these",
    "start": "3295430",
    "end": "3302930"
  },
  {
    "text": "components do this specific thing the auto documentation has all components",
    "start": "3302930",
    "end": "3308180"
  },
  {
    "text": "all of the properties that are set on them all of the descriptions and notes that you put into the jobs",
    "start": "3308180",
    "end": "3314180"
  },
  {
    "text": "so really you can get it you can you can if you if you're the sort of person that",
    "start": "3314180",
    "end": "3319730"
  },
  {
    "text": "likes to build out ETL processes I will put lots of notes and little identifies",
    "start": "3319730",
    "end": "3326210"
  },
  {
    "text": "to aid understanding as you go your documentation job is done for you at that point it will just get generated by",
    "start": "3326210",
    "end": "3332450"
  },
  {
    "text": "the tool sounds like you make easy I think we've done this a couple minutes",
    "start": "3332450",
    "end": "3338270"
  },
  {
    "text": "left so we'll we'll take one last question here are there any opportunities to fine-tune the query",
    "start": "3338270",
    "end": "3346100"
  },
  {
    "text": "generated by metallian I mean and how would you know if it's the most optimized way of doing it yeah it's a",
    "start": "3346100",
    "end": "3352910"
  },
  {
    "text": "great question so it's not usually necessary to fine-tune that the sequel",
    "start": "3352910",
    "end": "3360050"
  },
  {
    "text": "that little Ian generated I've never known a customer need to do that they do",
    "start": "3360050",
    "end": "3366710"
  },
  {
    "text": "however find that they want to fine-tune the way that redshift is storing the",
    "start": "3366710",
    "end": "3373910"
  },
  {
    "text": "data how we provide a full set of tools to a help you understand and B do that",
    "start": "3373910",
    "end": "3379970"
  },
  {
    "text": "so I'm talking about things like sort of distribution keys the way that the data",
    "start": "3379970",
    "end": "3385520"
  },
  {
    "text": "is stored understanding that the plan of the query that's going to be processed",
    "start": "3385520",
    "end": "3391130"
  },
  {
    "text": "and working back through that I've never never needed to kind of rewrite sequel",
    "start": "3391130",
    "end": "3399410"
  },
  {
    "text": "in a different way in order to get the redshift query optimizer to do something",
    "start": "3399410",
    "end": "3405530"
  },
  {
    "text": "nice I I've always found it it's kind of more sophisticated than that but also I",
    "start": "3405530",
    "end": "3411800"
  },
  {
    "text": "think because the ETL components that we've built will kind of generate the",
    "start": "3411800",
    "end": "3417440"
  },
  {
    "text": "sequel to the best practices anyway and and we tweak that from time to time when",
    "start": "3417440",
    "end": "3422750"
  },
  {
    "text": "best practices change and that's or transparent to the tool as a final thing",
    "start": "3422750",
    "end": "3428150"
  },
  {
    "text": "if all else fails you can write a sequel step as a transformation so you can have",
    "start": "3428150",
    "end": "3434750"
  },
  {
    "text": "you know start a whole sequel step that you just write manually and then the",
    "start": "3434750",
    "end": "3440030"
  },
  {
    "text": "output so that's kind of a nice fallback if you if you really want to write the",
    "start": "3440030",
    "end": "3445760"
  },
  {
    "text": "sequel yourself you can but not I cannot like rivers well not know thank",
    "start": "3445760",
    "end": "3451440"
  },
  {
    "text": "you very much for thank the presenters Edie and Dimitri I also want to thank",
    "start": "3451440",
    "end": "3456900"
  },
  {
    "text": "all the attendees for taking time out of your day with us I look forward to see you next time I think's again for attending don't",
    "start": "3456900",
    "end": "3463290"
  },
  {
    "text": "hesitate to reach out take care bye-bye",
    "start": "3463290",
    "end": "3466760"
  }
]
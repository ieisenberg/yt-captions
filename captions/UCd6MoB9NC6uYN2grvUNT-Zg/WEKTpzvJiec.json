[
  {
    "start": "0",
    "end": "57000"
  },
  {
    "text": "hello and welcome to best practices",
    "start": "1240",
    "end": "4080"
  },
  {
    "text": "building generative AI applications on",
    "start": "4080",
    "end": "7360"
  },
  {
    "text": "AWS my name is Dan stair I am an",
    "start": "7360",
    "end": "10280"
  },
  {
    "text": "analytic specialist Solutions architect",
    "start": "10280",
    "end": "12559"
  },
  {
    "text": "and this video series was built in",
    "start": "12559",
    "end": "14759"
  },
  {
    "text": "collaboration with my co-workers Hara",
    "start": "14759",
    "end": "17240"
  },
  {
    "text": "tatap parthy and Felix huthmacher our",
    "start": "17240",
    "end": "20240"
  },
  {
    "text": "objective is to provide a One-Stop shop",
    "start": "20240",
    "end": "22680"
  },
  {
    "text": "for you to learn the essentials of",
    "start": "22680",
    "end": "24519"
  },
  {
    "text": "building a generative AI application on",
    "start": "24519",
    "end": "28000"
  },
  {
    "text": "AWS in our role we assist many customers",
    "start": "28000",
    "end": "31320"
  },
  {
    "text": "of different sizes in realizing their",
    "start": "31320",
    "end": "33559"
  },
  {
    "text": "vision for generative AI",
    "start": "33559",
    "end": "36000"
  },
  {
    "text": "applications since the technology is so",
    "start": "36000",
    "end": "38520"
  },
  {
    "text": "new we have seen that many customers",
    "start": "38520",
    "end": "40920"
  },
  {
    "text": "lack the proper level of understanding",
    "start": "40920",
    "end": "43200"
  },
  {
    "text": "needed to build a generative AI",
    "start": "43200",
    "end": "46000"
  },
  {
    "text": "application this video Series starts at",
    "start": "46000",
    "end": "48600"
  },
  {
    "text": "an early stage of learning how to choose",
    "start": "48600",
    "end": "50719"
  },
  {
    "text": "a model and takes you all the way",
    "start": "50719",
    "end": "52559"
  },
  {
    "text": "through deploying and monitoring a large",
    "start": "52559",
    "end": "55079"
  },
  {
    "text": "language model in",
    "start": "55079",
    "end": "57840"
  },
  {
    "start": "57000",
    "end": "99000"
  },
  {
    "text": "production this is the first video in a",
    "start": "57840",
    "end": "60440"
  },
  {
    "text": "four video series in this video we will",
    "start": "60440",
    "end": "64040"
  },
  {
    "text": "provide an overview of model selection",
    "start": "64040",
    "end": "66600"
  },
  {
    "text": "and how to choose the right large",
    "start": "66600",
    "end": "68280"
  },
  {
    "text": "language model for your use case in",
    "start": "68280",
    "end": "71320"
  },
  {
    "text": "video two we will show a demo of model",
    "start": "71320",
    "end": "74439"
  },
  {
    "text": "selection in video three we will show",
    "start": "74439",
    "end": "77479"
  },
  {
    "text": "how to improve the performance of your",
    "start": "77479",
    "end": "79479"
  },
  {
    "text": "large language model once it has been",
    "start": "79479",
    "end": "82320"
  },
  {
    "text": "chosen and finally in video 4 we will",
    "start": "82320",
    "end": "85479"
  },
  {
    "text": "review best practices for large language",
    "start": "85479",
    "end": "87479"
  },
  {
    "text": "model operations and how to deploy and",
    "start": "87479",
    "end": "90079"
  },
  {
    "text": "monitor your large language model in",
    "start": "90079",
    "end": "93280"
  },
  {
    "text": "production but to start what is a large",
    "start": "93280",
    "end": "96520"
  },
  {
    "text": "language",
    "start": "96520",
    "end": "98960"
  },
  {
    "start": "99000",
    "end": "179000"
  },
  {
    "text": "Model A large language model can be",
    "start": "99119",
    "end": "102360"
  },
  {
    "text": "defined as a pre-trained deep learning",
    "start": "102360",
    "end": "104680"
  },
  {
    "text": "model which can generate humanlike text",
    "start": "104680",
    "end": "107719"
  },
  {
    "text": "responses large language models take",
    "start": "107719",
    "end": "110360"
  },
  {
    "text": "input text called a prompt and predict",
    "start": "110360",
    "end": "113680"
  },
  {
    "text": "the next word or token in the",
    "start": "113680",
    "end": "117799"
  },
  {
    "text": "sequence for example",
    "start": "117799",
    "end": "120439"
  },
  {
    "text": "in this example we have the input tokens",
    "start": "120439",
    "end": "123280"
  },
  {
    "text": "the students opened there and the large",
    "start": "123280",
    "end": "127159"
  },
  {
    "text": "language model is considering one of",
    "start": "127159",
    "end": "129959"
  },
  {
    "text": "several next tokens it believes that",
    "start": "129959",
    "end": "132800"
  },
  {
    "text": "there is a 99.6% chance that the correct",
    "start": "132800",
    "end": "135920"
  },
  {
    "text": "next token is books and there is an",
    "start": "135920",
    "end": "138239"
  },
  {
    "text": "88.2% chance that the correct next token",
    "start": "138239",
    "end": "142000"
  },
  {
    "text": "is",
    "start": "142000",
    "end": "144440"
  },
  {
    "text": "laptops once it is chosen the correct",
    "start": "144440",
    "end": "147640"
  },
  {
    "text": "next token of books it may continue to",
    "start": "147640",
    "end": "150120"
  },
  {
    "text": "iterate on the sequence so now the input",
    "start": "150120",
    "end": "153239"
  },
  {
    "text": "text is the student open their books and",
    "start": "153239",
    "end": "155760"
  },
  {
    "text": "it may choose the next token in the",
    "start": "155760",
    "end": "157800"
  },
  {
    "text": "sequence to make the sentence the",
    "start": "157800",
    "end": "159959"
  },
  {
    "text": "students opened their books",
    "start": "159959",
    "end": "162959"
  },
  {
    "text": "quickly it will continue to iterate in",
    "start": "162959",
    "end": "165280"
  },
  {
    "text": "order to generate more output until it",
    "start": "165280",
    "end": "167760"
  },
  {
    "text": "is",
    "start": "167760",
    "end": "169959"
  },
  {
    "text": "done but how can you get started on your",
    "start": "170720",
    "end": "173879"
  },
  {
    "text": "journey with large language models and",
    "start": "173879",
    "end": "176560"
  },
  {
    "text": "what does a typical large language model",
    "start": "176560",
    "end": "178879"
  },
  {
    "text": "Journey look",
    "start": "178879",
    "end": "180959"
  },
  {
    "start": "179000",
    "end": "271000"
  },
  {
    "text": "like we recommend that you start by",
    "start": "180959",
    "end": "183560"
  },
  {
    "text": "defining your use case so what would a",
    "start": "183560",
    "end": "185920"
  },
  {
    "text": "good end result look like then narrow",
    "start": "185920",
    "end": "189640"
  },
  {
    "text": "down the set of models to evaluate based",
    "start": "189640",
    "end": "192599"
  },
  {
    "text": "on the set of criteria for example the",
    "start": "192599",
    "end": "195879"
  },
  {
    "text": "size of the model the end user license",
    "start": "195879",
    "end": "198360"
  },
  {
    "text": "agreement of the model or Andor the",
    "start": "198360",
    "end": "201640"
  },
  {
    "text": "purpose that the model was built",
    "start": "201640",
    "end": "203920"
  },
  {
    "text": "for once you have narrowed down the set",
    "start": "203920",
    "end": "206360"
  },
  {
    "text": "of models you are considering we",
    "start": "206360",
    "end": "208840"
  },
  {
    "text": "recommend that you employ one or more",
    "start": "208840",
    "end": "211599"
  },
  {
    "text": "techniques to improve model performance",
    "start": "211599",
    "end": "214799"
  },
  {
    "text": "including prompt engineering retrieval",
    "start": "214799",
    "end": "217840"
  },
  {
    "text": "augmented generation and or",
    "start": "217840",
    "end": "220760"
  },
  {
    "text": "reinforcement learning with",
    "start": "220760",
    "end": "224879"
  },
  {
    "text": "feedback then you will need to move on",
    "start": "224879",
    "end": "227680"
  },
  {
    "text": "to evaluate the results of your model",
    "start": "227680",
    "end": "230720"
  },
  {
    "text": "once you have improved the performance",
    "start": "230720",
    "end": "232120"
  },
  {
    "text": "on the model in the next video we will",
    "start": "232120",
    "end": "235319"
  },
  {
    "text": "cover recommended ways which are",
    "start": "235319",
    "end": "237760"
  },
  {
    "text": "quantitative automated and repeatable to",
    "start": "237760",
    "end": "240560"
  },
  {
    "text": "help you evaluate your large language",
    "start": "240560",
    "end": "242760"
  },
  {
    "text": "models",
    "start": "242760",
    "end": "244000"
  },
  {
    "text": "performance you may need to iterate on",
    "start": "244000",
    "end": "246400"
  },
  {
    "text": "these performance improvements steps",
    "start": "246400",
    "end": "248079"
  },
  {
    "text": "depending on how your evaluation metrics",
    "start": "248079",
    "end": "250480"
  },
  {
    "text": "compare to your",
    "start": "250480",
    "end": "252000"
  },
  {
    "text": "Target and finally once you've selected",
    "start": "252000",
    "end": "254640"
  },
  {
    "text": "and optimized a large language model for",
    "start": "254640",
    "end": "256880"
  },
  {
    "text": "your use case we will show you how to",
    "start": "256880",
    "end": "258880"
  },
  {
    "text": "deploy and model your llm in",
    "start": "258880",
    "end": "263880"
  },
  {
    "text": "production so to get started on this",
    "start": "263880",
    "end": "266280"
  },
  {
    "text": "journey what are some of the building",
    "start": "266280",
    "end": "268759"
  },
  {
    "text": "blocks that you will",
    "start": "268759",
    "end": "271440"
  },
  {
    "start": "271000",
    "end": "361000"
  },
  {
    "text": "need one useful tool is embedding",
    "start": "271440",
    "end": "274880"
  },
  {
    "text": "vectors large language models store text",
    "start": "274880",
    "end": "277639"
  },
  {
    "text": "Data as numbers in order to store large",
    "start": "277639",
    "end": "280600"
  },
  {
    "text": "amounts of information or quickly search",
    "start": "280600",
    "end": "283320"
  },
  {
    "text": "for related",
    "start": "283320",
    "end": "285160"
  },
  {
    "text": "information you will need to",
    "start": "285160",
    "end": "287880"
  },
  {
    "text": "convert text into vectors in this",
    "start": "287880",
    "end": "291160"
  },
  {
    "text": "example the text the sky is blue is",
    "start": "291160",
    "end": "293680"
  },
  {
    "text": "converted into a vector which is",
    "start": "293680",
    "end": "295759"
  },
  {
    "text": "basically a set of",
    "start": "295759",
    "end": "298360"
  },
  {
    "text": "numbers one once you have generated your",
    "start": "298360",
    "end": "301080"
  },
  {
    "text": "vectors you will need to store them in a",
    "start": "301080",
    "end": "303840"
  },
  {
    "text": "vector",
    "start": "303840",
    "end": "304960"
  },
  {
    "text": "database and finally once you have",
    "start": "304960",
    "end": "307280"
  },
  {
    "text": "provided your model with the data it",
    "start": "307280",
    "end": "309520"
  },
  {
    "text": "needs you will need to consider several",
    "start": "309520",
    "end": "311800"
  },
  {
    "text": "patterns commonly used to improve",
    "start": "311800",
    "end": "315520"
  },
  {
    "text": "performance these include prompt",
    "start": "315520",
    "end": "317759"
  },
  {
    "text": "engineering or using different prompts",
    "start": "317759",
    "end": "319919"
  },
  {
    "text": "to optimize responses the model gives",
    "start": "319919",
    "end": "322400"
  },
  {
    "text": "retrieval augmented generation in which",
    "start": "322400",
    "end": "325039"
  },
  {
    "text": "you augment the model's knowledge with a",
    "start": "325039",
    "end": "326919"
  },
  {
    "text": "vector",
    "start": "326919",
    "end": "327800"
  },
  {
    "text": "database or you may choose used to find",
    "start": "327800",
    "end": "330039"
  },
  {
    "text": "tunar model which involves providing the",
    "start": "330039",
    "end": "332759"
  },
  {
    "text": "model with additional training data so",
    "start": "332759",
    "end": "334600"
  },
  {
    "text": "that it learns about your use case",
    "start": "334600",
    "end": "337880"
  },
  {
    "text": "specifically or you may choose to train",
    "start": "337880",
    "end": "340360"
  },
  {
    "text": "a large language model from scratch",
    "start": "340360",
    "end": "342400"
  },
  {
    "text": "which is the most expensive in terms of",
    "start": "342400",
    "end": "344360"
  },
  {
    "text": "time and compute cost but can make sense",
    "start": "344360",
    "end": "347360"
  },
  {
    "text": "for highly specialized use",
    "start": "347360",
    "end": "350759"
  },
  {
    "text": "cases now that we have covered some",
    "start": "350759",
    "end": "352840"
  },
  {
    "text": "building blocks we will cover at a high",
    "start": "352840",
    "end": "355080"
  },
  {
    "text": "level the recommended steps to select",
    "start": "355080",
    "end": "357319"
  },
  {
    "text": "the right model for your use case",
    "start": "357319",
    "end": "361479"
  },
  {
    "start": "361000",
    "end": "448000"
  },
  {
    "text": "Cas large language models do have some",
    "start": "362639",
    "end": "365800"
  },
  {
    "text": "overlap but many large language models",
    "start": "365800",
    "end": "368440"
  },
  {
    "text": "are purpose-built to be good at tasks",
    "start": "368440",
    "end": "371400"
  },
  {
    "text": "such as summarization language",
    "start": "371400",
    "end": "374000"
  },
  {
    "text": "translation image creation Etc so be",
    "start": "374000",
    "end": "378120"
  },
  {
    "text": "sure to work backwards from your use",
    "start": "378120",
    "end": "379880"
  },
  {
    "text": "case to filter for the appropriate large",
    "start": "379880",
    "end": "382440"
  },
  {
    "text": "language",
    "start": "382440",
    "end": "384880"
  },
  {
    "text": "models keep in mind that there are a",
    "start": "385240",
    "end": "387280"
  },
  {
    "text": "number of model leaderboards out there",
    "start": "387280",
    "end": "390479"
  },
  {
    "text": "including Stanford Helm hugging faces",
    "start": "390479",
    "end": "392880"
  },
  {
    "text": "open large language model leaderboard",
    "start": "392880",
    "end": "395360"
  },
  {
    "text": "and hugging faces chatbot leaderboard",
    "start": "395360",
    "end": "398599"
  },
  {
    "text": "but remember that these public",
    "start": "398599",
    "end": "400520"
  },
  {
    "text": "benchmarks are not necessarily suitable",
    "start": "400520",
    "end": "403560"
  },
  {
    "text": "for your data and your use",
    "start": "403560",
    "end": "406880"
  },
  {
    "text": "case finally keep in mind that larger",
    "start": "406880",
    "end": "410919"
  },
  {
    "text": "large language models are not always",
    "start": "410919",
    "end": "413880"
  },
  {
    "text": "better large language model larger llms",
    "start": "413880",
    "end": "417160"
  },
  {
    "text": "May cost more they may May incur higher",
    "start": "417160",
    "end": "421479"
  },
  {
    "text": "latency and the chinchilla scaling laws",
    "start": "421479",
    "end": "424960"
  },
  {
    "text": "suggest that there's an optimal ratio of",
    "start": "424960",
    "end": "427800"
  },
  {
    "text": "training data to model size so some use",
    "start": "427800",
    "end": "431400"
  },
  {
    "text": "cases may actually be limited by the",
    "start": "431400",
    "end": "433520"
  },
  {
    "text": "amount of training data available in",
    "start": "433520",
    "end": "435919"
  },
  {
    "text": "which case choosing a larger model will",
    "start": "435919",
    "end": "438560"
  },
  {
    "text": "not deliver proportionately better",
    "start": "438560",
    "end": "442360"
  },
  {
    "text": "results there are several more tools",
    "start": "442360",
    "end": "444720"
  },
  {
    "text": "available which are important to look at",
    "start": "444720",
    "end": "447039"
  },
  {
    "text": "When selecting your model",
    "start": "447039",
    "end": "449919"
  },
  {
    "start": "448000",
    "end": "497000"
  },
  {
    "text": "many popular model hubs provide model",
    "start": "449919",
    "end": "452560"
  },
  {
    "text": "cards and these model cards often",
    "start": "452560",
    "end": "455039"
  },
  {
    "text": "specify which use cases fit best with",
    "start": "455039",
    "end": "458039"
  },
  {
    "text": "the model for example translation",
    "start": "458039",
    "end": "460440"
  },
  {
    "text": "summarization or image",
    "start": "460440",
    "end": "462759"
  },
  {
    "text": "generation the input data type and input",
    "start": "462759",
    "end": "465759"
  },
  {
    "text": "data volume for the model the model size",
    "start": "465759",
    "end": "468960"
  },
  {
    "text": "and number of",
    "start": "468960",
    "end": "470759"
  },
  {
    "text": "parameters and the enduser license",
    "start": "470759",
    "end": "474960"
  },
  {
    "text": "agreement again we recommend that you",
    "start": "474960",
    "end": "478680"
  },
  {
    "text": "evaluate the model with your data for",
    "start": "478680",
    "end": "481039"
  },
  {
    "text": "your use",
    "start": "481039",
    "end": "482479"
  },
  {
    "text": "cases and finally arrive at the best",
    "start": "482479",
    "end": "485400"
  },
  {
    "text": "model for your use",
    "start": "485400",
    "end": "488000"
  },
  {
    "text": "case so once you've decided on a use",
    "start": "488000",
    "end": "490599"
  },
  {
    "text": "case and chosen a model you will need to",
    "start": "490599",
    "end": "492720"
  },
  {
    "text": "get started using purpose-built",
    "start": "492720",
    "end": "496440"
  },
  {
    "text": "tooling AWS offers a rich ecosystem of",
    "start": "496440",
    "end": "499720"
  },
  {
    "start": "497000",
    "end": "606000"
  },
  {
    "text": "services to help customers build and",
    "start": "499720",
    "end": "502120"
  },
  {
    "text": "deploy large language",
    "start": "502120",
    "end": "504280"
  },
  {
    "text": "models one such service is sagemaker",
    "start": "504280",
    "end": "507759"
  },
  {
    "text": "jump start which is for customers who",
    "start": "507759",
    "end": "510120"
  },
  {
    "text": "want to deploy a large language model",
    "start": "510120",
    "end": "512120"
  },
  {
    "text": "onto dedicated",
    "start": "512120",
    "end": "514039"
  },
  {
    "text": "Hardware it offers a one-click",
    "start": "514039",
    "end": "516080"
  },
  {
    "text": "deployment for a variety of large",
    "start": "516080",
    "end": "517760"
  },
  {
    "text": "language models and these models are",
    "start": "517760",
    "end": "520599"
  },
  {
    "text": "deployed on pre-tested instance types",
    "start": "520599",
    "end": "524200"
  },
  {
    "text": "some models can be fine tuned and",
    "start": "524200",
    "end": "527000"
  },
  {
    "text": "because this is accessed via sagemaker",
    "start": "527000",
    "end": "529279"
  },
  {
    "text": "Studio you can also use the full",
    "start": "529279",
    "end": "532120"
  },
  {
    "text": "sagemaker ecosystem which includes a",
    "start": "532120",
    "end": "534800"
  },
  {
    "text": "feature store GitHub integration and",
    "start": "534800",
    "end": "537360"
  },
  {
    "text": "sagemaker Pipelines",
    "start": "537360",
    "end": "540680"
  },
  {
    "text": "another popular tool is Amazon Bedrock",
    "start": "540680",
    "end": "544040"
  },
  {
    "text": "Bedrock provides best-in-class",
    "start": "544040",
    "end": "545959"
  },
  {
    "text": "Foundation models with fully managed",
    "start": "545959",
    "end": "549079"
  },
  {
    "text": "serverless inference and a simple API",
    "start": "549079",
    "end": "551760"
  },
  {
    "text": "that is easy to build generative AI",
    "start": "551760",
    "end": "554279"
  },
  {
    "text": "applications",
    "start": "554279",
    "end": "556360"
  },
  {
    "text": "with in addition to a user interface",
    "start": "556360",
    "end": "560120"
  },
  {
    "text": "both bedrock and sagemaker jump offer",
    "start": "560120",
    "end": "563320"
  },
  {
    "text": "playgrounds so through the AWS",
    "start": "563320",
    "end": "565720"
  },
  {
    "text": "Management console you can play with a",
    "start": "565720",
    "end": "567480"
  },
  {
    "text": "model without having to actually deploy",
    "start": "567480",
    "end": "570519"
  },
  {
    "text": "it first and they can both be reached",
    "start": "570519",
    "end": "573920"
  },
  {
    "text": "via apis so Amazon Bedrock offers an API",
    "start": "573920",
    "end": "576920"
  },
  {
    "text": "and sa sagemaker inference endpoints",
    "start": "576920",
    "end": "579880"
  },
  {
    "text": "also offer API based",
    "start": "579880",
    "end": "583320"
  },
  {
    "text": "inference and you can access Bedrock",
    "start": "583320",
    "end": "585959"
  },
  {
    "text": "using the",
    "start": "585959",
    "end": "587760"
  },
  {
    "text": "awsd in a programming language of your",
    "start": "587760",
    "end": "590240"
  },
  {
    "text": "choice for example python JavaScript",
    "start": "590240",
    "end": "595040"
  },
  {
    "text": "Etc so once you have chosen the right",
    "start": "595040",
    "end": "597640"
  },
  {
    "text": "service to run your large l language",
    "start": "597640",
    "end": "599440"
  },
  {
    "text": "models on AWS you will need to choose",
    "start": "599440",
    "end": "603120"
  },
  {
    "text": "you may need to choose a vector",
    "start": "603120",
    "end": "606720"
  },
  {
    "start": "606000",
    "end": "670000"
  },
  {
    "text": "store the top list consists of AWS",
    "start": "607920",
    "end": "611320"
  },
  {
    "text": "manage ve Vector stores Amazon open",
    "start": "611320",
    "end": "614560"
  },
  {
    "text": "search is a popular data store for low",
    "start": "614560",
    "end": "617399"
  },
  {
    "text": "latency access to large data",
    "start": "617399",
    "end": "619640"
  },
  {
    "text": "sets it comes in both serverless and",
    "start": "619640",
    "end": "622640"
  },
  {
    "text": "provision flavors and supports a",
    "start": "622640",
    "end": "624959"
  },
  {
    "text": "purpose-built vector engine for Amazon",
    "start": "624959",
    "end": "627240"
  },
  {
    "text": "open Church serverless which is in",
    "start": "627240",
    "end": "629839"
  },
  {
    "text": "public preview as of",
    "start": "629839",
    "end": "632440"
  },
  {
    "text": "today Amazon Kendra is optimized for",
    "start": "632440",
    "end": "635720"
  },
  {
    "text": "search and provides a rich connector",
    "start": "635720",
    "end": "637600"
  },
  {
    "text": "ecosystem and also simplifies the",
    "start": "637600",
    "end": "640560"
  },
  {
    "text": "process of creating embeddings for your",
    "start": "640560",
    "end": "642639"
  },
  {
    "text": "vector",
    "start": "642639",
    "end": "644000"
  },
  {
    "text": "store and the PG Vector plugin for",
    "start": "644000",
    "end": "647440"
  },
  {
    "text": "Aurora postgress and RDS postgress are",
    "start": "647440",
    "end": "651200"
  },
  {
    "text": "popular options for customers who are",
    "start": "651200",
    "end": "653920"
  },
  {
    "text": "heavy users of",
    "start": "653920",
    "end": "656959"
  },
  {
    "text": "postgress there are also several",
    "start": "656959",
    "end": "659279"
  },
  {
    "text": "thirdparty tooling options including",
    "start": "659279",
    "end": "662000"
  },
  {
    "text": "pine cone and redis these integrate with",
    "start": "662000",
    "end": "664880"
  },
  {
    "text": "Amazon Bedrock via an integration",
    "start": "664880",
    "end": "667160"
  },
  {
    "text": "feature called Bedrock",
    "start": "667160",
    "end": "670519"
  },
  {
    "start": "670000",
    "end": "701000"
  },
  {
    "text": "agents in summary in this video we",
    "start": "670680",
    "end": "674040"
  },
  {
    "text": "discussed how to start your journey with",
    "start": "674040",
    "end": "676399"
  },
  {
    "text": "large language models by picking a use",
    "start": "676399",
    "end": "678639"
  },
  {
    "text": "case using popular available tools to",
    "start": "678639",
    "end": "682079"
  },
  {
    "text": "choose large language models and gave an",
    "start": "682079",
    "end": "685440"
  },
  {
    "text": "overview of the tools available on AWS",
    "start": "685440",
    "end": "688600"
  },
  {
    "text": "to help",
    "start": "688600",
    "end": "689880"
  },
  {
    "text": "on this",
    "start": "689880",
    "end": "691279"
  },
  {
    "text": "journey now I will hand it over to Felix",
    "start": "691279",
    "end": "694279"
  },
  {
    "text": "for our next",
    "start": "694279",
    "end": "697560"
  },
  {
    "text": "video",
    "start": "700800",
    "end": "703800"
  }
]
[
  {
    "text": "good afternoon I'm Corey and I'm here with tomash and today we're gonna be",
    "start": "30",
    "end": "5400"
  },
  {
    "text": "talking to you about ml flow a platform for the complete machine learning lifecycle ml flow is an open source",
    "start": "5400",
    "end": "12000"
  },
  {
    "text": "project that initially got its start at data bricks and it's developing a large community following to start off let me",
    "start": "12000",
    "end": "19800"
  },
  {
    "text": "provide an outline of the topics that tomash and i are going to cover over the course of the next hour first I'll talk",
    "start": "19800",
    "end": "26099"
  },
  {
    "text": "about the challenges associated with machine learning model development then I'll address how ml float tackles each",
    "start": "26099",
    "end": "33059"
  },
  {
    "text": "of these challenges tomash and I will also provide an overview of the three main components of ml flow tracking",
    "start": "33059",
    "end": "40340"
  },
  {
    "text": "projects and models and then finally tomash will tell you all how you can get",
    "start": "40340",
    "end": "45360"
  },
  {
    "text": "started with ml flow and contribute to the project so let's dive right into those challenges there's a lot of you",
    "start": "45360",
    "end": "52320"
  },
  {
    "text": "are probably painfully aware developing machine learning applications is difficult and complex and to expand on",
    "start": "52320",
    "end": "59160"
  },
  {
    "text": "that a bit let's take a look at the typical machine learning lifecycle it all starts with the collection of raw",
    "start": "59160",
    "end": "64739"
  },
  {
    "text": "data once data is available it is then cleaned and feature eyes and this clean",
    "start": "64739",
    "end": "70530"
  },
  {
    "text": "data is used to train a model finally this model is deployed to a variety of",
    "start": "70530",
    "end": "76200"
  },
  {
    "text": "production contexts whether that be a web application or a batch streaming",
    "start": "76200",
    "end": "81330"
  },
  {
    "text": "environment for example oftentimes these production applications receive new data",
    "start": "81330",
    "end": "86640"
  },
  {
    "text": "which can then be fed back into the first stage of the next iteration of the lifecycle and it repeats so at the",
    "start": "86640",
    "end": "94560"
  },
  {
    "text": "surface this may sound pretty simple you get a four stage process for developing machine learning models and applications",
    "start": "94560",
    "end": "101280"
  },
  {
    "text": "but there are several layers of additional complexity that make this a very difficult life cycle to implement",
    "start": "101280",
    "end": "108210"
  },
  {
    "text": "effectively especially for large organizations that need to operate at scale so let's take a look at that first",
    "start": "108210",
    "end": "114360"
  },
  {
    "text": "challenge that we may encounter if we were to sit down and attempt to implement a solution for each stage of",
    "start": "114360",
    "end": "121530"
  },
  {
    "text": "the lifecycle the first thing we find is that we have a large number of available frameworks that can be implemented in",
    "start": "121530",
    "end": "128670"
  },
  {
    "text": "order to do raw data collection preparation training or deploy but there really isn't a unified",
    "start": "128670",
    "end": "134629"
  },
  {
    "text": "framework that allows us to do all of these things at each stage and what that means for an application developer is",
    "start": "134629",
    "end": "140810"
  },
  {
    "text": "you're often trying to figure out how to stitch together your Kafka datastore with a spark ETL pipeline and it's",
    "start": "140810",
    "end": "147680"
  },
  {
    "text": "becomes a very difficult task especially when you consider the fact that machine learning practitioners in the training",
    "start": "147680",
    "end": "153950"
  },
  {
    "text": "phase are often encouraged and incentivized to experiment with a bunch of different machine learning frameworks",
    "start": "153950",
    "end": "158989"
  },
  {
    "text": "this means that data scientists may be attempting to train models and tensorflow for deep learning alongside",
    "start": "158989",
    "end": "165439"
  },
  {
    "text": "more traditional models like regression techniques in scikit-learn and these two",
    "start": "165439",
    "end": "171230"
  },
  {
    "text": "frameworks are just a couple of hundreds of popular machine learning libraries the data scientists depend on every day",
    "start": "171230",
    "end": "177980"
  },
  {
    "text": "in order to produce quality output finally at deployment time models",
    "start": "177980",
    "end": "183349"
  },
  {
    "text": "trained in this variety of formats need to be deployable to this variety of production contexts that means that it",
    "start": "183349",
    "end": "189470"
  },
  {
    "text": "should be just as easy for me to deploy a tensor flow graph for real-time serving using a product like Amazon Sage",
    "start": "189470",
    "end": "196129"
  },
  {
    "text": "maker as it is to deploy a scikit-learn model for a batch streaming context for",
    "start": "196129",
    "end": "202220"
  },
  {
    "text": "example inside of a spark job so assuming that as an organization you can stitch together all of these different",
    "start": "202220",
    "end": "208819"
  },
  {
    "text": "frameworks and make this happen your work is not done we also observe that hyper parameter tuning is an extremely",
    "start": "208819",
    "end": "215540"
  },
  {
    "text": "important concept in machine learning C models are configurable and they're highly sensitive to certain numeric",
    "start": "215540",
    "end": "222560"
  },
  {
    "text": "parameters that dramatically affect their performance for example selecting",
    "start": "222560",
    "end": "228379"
  },
  {
    "text": "the incorrect set of parameters can produce an output that's no better than guesswork but selecting the optimal set",
    "start": "228379",
    "end": "234440"
  },
  {
    "text": "of hyper parameters can produce a model that revolutionizes a business use case and so it's absolutely imperative that",
    "start": "234440",
    "end": "240799"
  },
  {
    "text": "when developing a machine learning platform data scientists are capable of adequately exploring this parameter",
    "start": "240799",
    "end": "247400"
  },
  {
    "text": "space and tuning their models so that they work exactly the way they want them to and finally",
    "start": "247400",
    "end": "254930"
  },
  {
    "text": "assuming this all happens at scale the last major hurdle is model exchange and governance see it's not enough to just",
    "start": "254930",
    "end": "261229"
  },
  {
    "text": "train a machine learning model once in isolation for every model that comes out of in production an organization should",
    "start": "261229",
    "end": "268490"
  },
  {
    "text": "have a complete understanding of exactly how that model is trained and that includes the source code that trained",
    "start": "268490",
    "end": "275389"
  },
  {
    "text": "remodel the version of that code who trained it and a bunch of other important metadata and this information",
    "start": "275389",
    "end": "281720"
  },
  {
    "text": "doesn't just have to stick around for a week potentially for businesses that are operating in more privacy sensitive or",
    "start": "281720",
    "end": "287860"
  },
  {
    "text": "scrutinized conditions and using machine learning this lineage needs to be kept for every model that's trained",
    "start": "287860",
    "end": "293389"
  },
  {
    "text": "potentially for years and clearly this is a lot more of a challenge than we",
    "start": "293389",
    "end": "298580"
  },
  {
    "text": "initially estimated so now that we've fleshed out these layers of the machine",
    "start": "298580",
    "end": "304340"
  },
  {
    "text": "learning lifecycle implementation it's pretty obvious that this isn't just a simple four stage process that can be",
    "start": "304340",
    "end": "310160"
  },
  {
    "text": "implemented by one or even potentially tens or hundreds of engineers it's a quite challenging problem and this is",
    "start": "310160",
    "end": "317450"
  },
  {
    "text": "reflected when we talked to certain customers before building ml flow and we asked them about their challenges a",
    "start": "317450",
    "end": "323090"
  },
  {
    "text": "chief scientist in an ad tech firm said I build hundreds of models every day to",
    "start": "323090",
    "end": "328280"
  },
  {
    "text": "lift revenue when I use any library that may include ml Lib PI torch R and more but there's no easy way to see what data",
    "start": "328280",
    "end": "335390"
  },
  {
    "text": "went into a model from a week ago tune it and rebuild it and we're just talking about a week not even a longer time",
    "start": "335390",
    "end": "341360"
  },
  {
    "text": "horizon additionally another consumer electronics firm says that their company",
    "start": "341360",
    "end": "347270"
  },
  {
    "text": "has a hundred teams using machine learning worldwide and yet they can't share their work across those teams when",
    "start": "347270",
    "end": "353180"
  },
  {
    "text": "a new team tries to run some code it often doesn't even produce the same result and so this is that reproducibility problem of model",
    "start": "353180",
    "end": "359570"
  },
  {
    "text": "exchange and governance that organizations are encountering on a regular basis which leads me to the",
    "start": "359570",
    "end": "366050"
  },
  {
    "text": "motivation for ml flow we derive a lot of inspiration from three organizations",
    "start": "366050",
    "end": "371539"
  },
  {
    "text": "that have actually had a lot of success in this arena Facebook with their FB Lerner platform uber with Michelangelo",
    "start": "371539",
    "end": "377570"
  },
  {
    "text": "and Google with tf-x if you're using one of these systems you get the standardized and machine learning life",
    "start": "377570",
    "end": "383870"
  },
  {
    "text": "cycle from ingest to preparation training and deployments and this all",
    "start": "383870",
    "end": "389090"
  },
  {
    "text": "happens right out of the box the problem is that unless you're fortunate enough to work within one of these",
    "start": "389090",
    "end": "394490"
  },
  {
    "text": "organizations these platforms are tied to a specific companies in structure and they're not open source",
    "start": "394490",
    "end": "399820"
  },
  {
    "text": "additionally they often provide first-class support for certain machine learning frameworks for example tf-x is",
    "start": "399820",
    "end": "406790"
  },
  {
    "text": "awesome for tensorflow but if you're an art developer you're probably not going to be able to leverage all of the benefits of that platform and so this",
    "start": "406790",
    "end": "414680"
  },
  {
    "text": "leads us to the motivating question can we provide a complete solution for the machine we don't like learning lifecycle",
    "start": "414680",
    "end": "420560"
  },
  {
    "text": "in the same fashion as these three major organizations but in an open source fashion and can we support the wide",
    "start": "420560",
    "end": "427250"
  },
  {
    "text": "variety of machine learning frameworks that data scientists depend on every day",
    "start": "427250",
    "end": "432880"
  },
  {
    "text": "introducing mo flow we're an open source machine learning platform we work with any machine learning library in language",
    "start": "432880",
    "end": "439490"
  },
  {
    "text": "and it's designed to be the run the same way anywhere meaning if I train a model on an external third-party cloud service",
    "start": "439490",
    "end": "447050"
  },
  {
    "text": "and I want to rerun it on my local machine that should work in a reproducible fashion the same way every",
    "start": "447050",
    "end": "453080"
  },
  {
    "text": "time additionally mo flow is designed to be useful for a single data scientist",
    "start": "453080",
    "end": "458540"
  },
  {
    "text": "operating in isolation just as much as it's designed to be used by thousands of data scientists and machine learning",
    "start": "458540",
    "end": "464720"
  },
  {
    "text": "practitioners across a large organization and with that let's take a",
    "start": "464720",
    "end": "470030"
  },
  {
    "text": "look at the three major components of mo flow I'll start off by talking about mo flow tracking this is a centralized",
    "start": "470030",
    "end": "476960"
  },
  {
    "text": "repository that collects all of the critical information about machine learning training sessions that occur",
    "start": "476960",
    "end": "483290"
  },
  {
    "text": "within a data science group then Tomas will talk about mo flow projects this is",
    "start": "483290",
    "end": "489140"
  },
  {
    "text": "a reproducible format for machine learning tasks ensuring that they can be executed on any platform and reproduced",
    "start": "489140",
    "end": "495560"
  },
  {
    "text": "at any time and finally Tomas will talk about mo flow models a generic model",
    "start": "495560",
    "end": "501200"
  },
  {
    "text": "format that allows any model produced with ml flow to be deployed across a variety of production environments for",
    "start": "501200",
    "end": "507680"
  },
  {
    "text": "real time scoring streaming and batch processing let's dive right into the key",
    "start": "507680",
    "end": "513469"
  },
  {
    "text": "concepts in tracking as I stated before the primary goal of ml flow tracking is",
    "start": "513470",
    "end": "518690"
  },
  {
    "text": "to provide all of the critical information about each machine learning training session that occurs and this",
    "start": "518690",
    "end": "526130"
  },
  {
    "text": "means that we're interested in the following attributes the tracking server keeps track of those",
    "start": "526130",
    "end": "531270"
  },
  {
    "text": "importance parameters that so dramatically affect model performance and it also stores the metrics that",
    "start": "531270",
    "end": "537750"
  },
  {
    "text": "provide a window into the effectiveness and accuracy of a machine learning model",
    "start": "537750",
    "end": "543650"
  },
  {
    "text": "additionally and arguably most important for reproducibility the ML flow tracking",
    "start": "543650",
    "end": "548850"
  },
  {
    "text": "components can store the models themselves this means that if I train a deep neural network in tensorflow",
    "start": "548850",
    "end": "554400"
  },
  {
    "text": "I can take that graph and persist it on the cloud so that it can be read back by a variety of other users who may be",
    "start": "554400",
    "end": "561150"
  },
  {
    "text": "interested in running that model additionally for lineage the tracking service allows for the storage of source",
    "start": "561150",
    "end": "568500"
  },
  {
    "text": "code as well as the version of that code and that can be as specific as the git commit associated with a project that",
    "start": "568500",
    "end": "575610"
  },
  {
    "text": "produced a machine learning model and then for anything that isn't explicitly supported as a first-class entity in the",
    "start": "575610",
    "end": "582330"
  },
  {
    "text": "centralized tracking ecosystem in ml flow we provide an API for specifying arbitrary tags and notes associated with",
    "start": "582330",
    "end": "590490"
  },
  {
    "text": "a ml training session meaning for example a data scientist working on a",
    "start": "590490",
    "end": "595500"
  },
  {
    "text": "content recommendation model can specify some information about the business use case for example that that model was",
    "start": "595500",
    "end": "601620"
  },
  {
    "text": "produced for now that we understand the concepts let's see how Emma flow tracking integrates within the existing",
    "start": "601620",
    "end": "608220"
  },
  {
    "text": "training ecosystem when we look at the workflows that many data scientists use",
    "start": "608220",
    "end": "613350"
  },
  {
    "text": "in training machine learning models we found that they prefer to perform their data scientists data science tasks in",
    "start": "613350",
    "end": "619740"
  },
  {
    "text": "different places some may prefer to use distributed hosted notebook environments",
    "start": "619740",
    "end": "625020"
  },
  {
    "text": "like data breaks others are much more comfortable doing machine learning on their local machines and a third group",
    "start": "625020",
    "end": "630720"
  },
  {
    "text": "prefers executing machine learning jobs remotely using large scalable cloud services in all of these cases ml flow",
    "start": "630720",
    "end": "638790"
  },
  {
    "text": "provides a tracking API that's available both in Python as well as in a restful",
    "start": "638790",
    "end": "644520"
  },
  {
    "text": "formats that can log all of this critical information about source code and artifacts and parameters to a",
    "start": "644520",
    "end": "650610"
  },
  {
    "text": "centralized location and therefore it doesn't matter where the model is being trained all of this information is",
    "start": "650610",
    "end": "657210"
  },
  {
    "text": "collected accurately every time once the data has been aggregated the ml flow",
    "start": "657210",
    "end": "662550"
  },
  {
    "text": "tracking server also provides an P I as well as a user interface for",
    "start": "662550",
    "end": "667589"
  },
  {
    "text": "exploring information about all of these trained machine learning models and training sessions this is a",
    "start": "667589",
    "end": "673320"
  },
  {
    "text": "sophisticated user interface that allows users to compare the accuracy of a model",
    "start": "673320",
    "end": "678570"
  },
  {
    "text": "to various parameters that it was configured with as well as sort based on evaluation metrics to find the optimal",
    "start": "678570",
    "end": "685620"
  },
  {
    "text": "model for their use case more quickly let's take a look at the API that users",
    "start": "685620",
    "end": "691500"
  },
  {
    "text": "can integrate into their existing machine learning training code to log all of this important information it's",
    "start": "691500",
    "end": "697410"
  },
  {
    "text": "very simple and it's very thin the first step is to create a new machine learning",
    "start": "697410",
    "end": "702420"
  },
  {
    "text": "training session using the ml flow start run directive for reference we call",
    "start": "702420",
    "end": "707430"
  },
  {
    "text": "machine learning training sessions run in ml flow the next step is to log those",
    "start": "707430",
    "end": "712769"
  },
  {
    "text": "very sensitive and critical parameters about the model using the ml flow log per am directive after that it's very",
    "start": "712769",
    "end": "720570"
  },
  {
    "text": "simple the user just pastes in their existing training code this could be a routine to train a tensor flow model it",
    "start": "720570",
    "end": "727230"
  },
  {
    "text": "could be code written for scikit-learn estimation or in a variety of other frameworks as long as it produces some",
    "start": "727230",
    "end": "732959"
  },
  {
    "text": "model it's compatible after that the user evaluates the model against some validation or some test data and this",
    "start": "732959",
    "end": "740820"
  },
  {
    "text": "produces metrics that provide insight into how well the model performs they can log these metrics to the tracking",
    "start": "740820",
    "end": "746130"
  },
  {
    "text": "component using the ml flow log metric directive and if there's any more sophisticated data for example if we",
    "start": "746130",
    "end": "753089"
  },
  {
    "text": "want to know exactly which data was used to train that model that can be logged as an artifact using the ml flow log",
    "start": "753089",
    "end": "759450"
  },
  {
    "text": "artifact directive and then finally the model itself is persisted using a",
    "start": "759450",
    "end": "764880"
  },
  {
    "text": "variety of convenience routines for saving models and different frameworks as the ml flow compatible formats in",
    "start": "764880",
    "end": "771750"
  },
  {
    "text": "this case we show an example call that saves a tensor flow graph in ml flow model format so now that we've seen",
    "start": "771750",
    "end": "779459"
  },
  {
    "text": "exactly how this API can be integrated into existing training code we're gonna walk through a demo and do it live the",
    "start": "779459",
    "end": "787709"
  },
  {
    "text": "goal of this demo is to leverage an existing public data set of Airbnb listings data and attempt to train a",
    "start": "787709",
    "end": "795690"
  },
  {
    "text": "regression model that predicts the price the given every be listing based on other attributes so the first step is to",
    "start": "795690",
    "end": "807930"
  },
  {
    "text": "check out our existing training code that doesn't have any of the ml flow hooks embedded everybody see that okay",
    "start": "807930",
    "end": "819350"
  },
  {
    "text": "awesome",
    "start": "819350",
    "end": "822350"
  },
  {
    "text": "so let's walk through the structure our existing training code at first we",
    "start": "826210",
    "end": "832029"
  },
  {
    "text": "define a couple of hyper parameters those sensitive values that are going to affect model performance then we load",
    "start": "832029",
    "end": "838720"
  },
  {
    "text": "model data both for training time as well as testing to produce validation",
    "start": "838720",
    "end": "843730"
  },
  {
    "text": "metrics next we leverage the scikit-learn model framework to train a model using",
    "start": "843730",
    "end": "851020"
  },
  {
    "text": "elastic net regression in order to fit our data and estimate prices based on",
    "start": "851020",
    "end": "857230"
  },
  {
    "text": "Airbnb listing attributes then we perform a simple evaluation routine",
    "start": "857230",
    "end": "862990"
  },
  {
    "text": "passing in our test data and retrieving some metrics about the performance of the model and we also print a standard",
    "start": "862990",
    "end": "868720"
  },
  {
    "text": "out just to make sure that something happened what we're gonna do now is embed the calls that would be necessary",
    "start": "868720",
    "end": "874360"
  },
  {
    "text": "to track every single run of this script using ml flow the first thing we're",
    "start": "874360",
    "end": "880839"
  },
  {
    "text": "going to do is create a new ml flow run using the mo flow start run directive",
    "start": "880839",
    "end": "887700"
  },
  {
    "text": "and we'll move the remainder of our code into the context generated by the start",
    "start": "887700",
    "end": "894010"
  },
  {
    "text": "run directive then after our hyper parameters have been specified we'll log",
    "start": "894010",
    "end": "900850"
  },
  {
    "text": "them using the log parameter method",
    "start": "900850",
    "end": "904800"
  },
  {
    "text": "after that the model is trained and our metrics are evaluated we can log those",
    "start": "905940",
    "end": "912610"
  },
  {
    "text": "as well additionally in this example we created",
    "start": "912610",
    "end": "918820"
  },
  {
    "text": "a more sophisticated performance plot that allows us to determine how this model is performing and pricing listings",
    "start": "918820",
    "end": "924850"
  },
  {
    "text": "will log that as an artifact as well and",
    "start": "924850",
    "end": "931870"
  },
  {
    "text": "finally and most importantly will log the model itself and that's it",
    "start": "931870",
    "end": "939100"
  },
  {
    "text": "all we had to do was paste in several small changes to our existing training code and we have complete compatibility",
    "start": "939100",
    "end": "945760"
  },
  {
    "text": "with the ml flow tracking ecosystem so let's go ahead and run the script and see how it works",
    "start": "945760",
    "end": "952439"
  },
  {
    "text": "and while this is running we'll go ahead and start the ml flow UI this will allow",
    "start": "963000",
    "end": "968129"
  },
  {
    "text": "us to visualize information about the training session that's currently running",
    "start": "968129",
    "end": "973370"
  },
  {
    "text": "awesome so what we see is that we just trained our scikit-learn estimator and we got some metrics such as mean",
    "start": "978089",
    "end": "984660"
  },
  {
    "text": "absolute error and an hour to value so now let's hop over to our UI now that",
    "start": "984660",
    "end": "996029"
  },
  {
    "text": "might be a little tough",
    "start": "996029",
    "end": "998959"
  },
  {
    "text": "just gonna start this up again real quick",
    "start": "1003820",
    "end": "1007470"
  },
  {
    "text": "I'll give it another couple seconds that's promising",
    "start": "1022050",
    "end": "1029600"
  },
  {
    "text": "anyway maybe we can move on to the next section of the demo and we'll see all the runs as they were initially produced",
    "start": "1043740",
    "end": "1049549"
  },
  {
    "text": "actually this looks like this finally came through for us awesome everybody",
    "start": "1049549",
    "end": "1060419"
  },
  {
    "text": "see this Polly cool so we trained our model then we have a new ml flow run you'll see that those same metrics that",
    "start": "1060419",
    "end": "1067350"
  },
  {
    "text": "were produced are available and visible to the user additionally the parameters that we",
    "start": "1067350",
    "end": "1072990"
  },
  {
    "text": "trained with in this case we just defaulted to alpha values and an l1 ratio these are the parameters for our",
    "start": "1072990",
    "end": "1078210"
  },
  {
    "text": "model of zero and then we have information about the user that train the model in this case this came off my",
    "start": "1078210",
    "end": "1083789"
  },
  {
    "text": "local machine and we have the actual version of a git repository that this code exists in so this information helps",
    "start": "1083789",
    "end": "1090929"
  },
  {
    "text": "us preserve the lineage of the training session if we take a closer look we also",
    "start": "1090929",
    "end": "1097620"
  },
  {
    "text": "have those artifacts that detailed performance plot which can then be visualized and this has already been",
    "start": "1097620",
    "end": "1103140"
  },
  {
    "text": "saved as an artifact that is available we also have the training data that we explicitly logged and we have the model",
    "start": "1103140",
    "end": "1110039"
  },
  {
    "text": "itself in ml flow format there's an ml model file that contains all of the",
    "start": "1110039",
    "end": "1115380"
  },
  {
    "text": "necessary information for reproducing this model on a different machine we include the version of Python it was",
    "start": "1115380",
    "end": "1120390"
  },
  {
    "text": "trained in we include the version of scikit-learn as well as the serialized scikit-learn",
    "start": "1120390",
    "end": "1125700"
  },
  {
    "text": "model artifacts and all of this information is expressed as a Conda environment so that users who are",
    "start": "1125700",
    "end": "1131760"
  },
  {
    "text": "familiar with the Conda workflow can activate it and immediately clone and reload the model",
    "start": "1131760",
    "end": "1138620"
  },
  {
    "text": "the next step is to perform a little bit of hyper parameter search and see how the ml flow UI can help us select the",
    "start": "1143179",
    "end": "1149539"
  },
  {
    "text": "model with the optimal parameters for a given use case let's take a look at a simple script that was written in order",
    "start": "1149539",
    "end": "1156649"
  },
  {
    "text": "to perform sort of a basic hyper parameter iteration over our two parameters we have the Alpha and the l1",
    "start": "1156649",
    "end": "1163969"
  },
  {
    "text": "values ranging over a small subset of potential options and for each of these values we're gonna run our training",
    "start": "1163969",
    "end": "1169849"
  },
  {
    "text": "script and then we're gonna see how we can compare the runs against each other to achieve a more optimal decision about",
    "start": "1169849",
    "end": "1175879"
  },
  {
    "text": "which model does the best job of predicting listing prices so let's go ahead and run this and essentially all",
    "start": "1175879",
    "end": "1184369"
  },
  {
    "text": "we're doing is just rerunning the same script for various parameter values so you'll see that for each selection of",
    "start": "1184369",
    "end": "1191419"
  },
  {
    "text": "parameters we're getting different metrics results and all of these are being persisted in real time to the UI",
    "start": "1191419",
    "end": "1196669"
  },
  {
    "text": "and what we're gonna do after this is actually visualize how the parameters affect the metrics outputs and and",
    "start": "1196669",
    "end": "1204379"
  },
  {
    "text": "hopefully that visualization will be somewhat illuminating so while this is",
    "start": "1204379",
    "end": "1210320"
  },
  {
    "text": "running if I were to refresh the UI I should see that we're getting a lot more",
    "start": "1210320",
    "end": "1215629"
  },
  {
    "text": "information about the different machine learning training sessions that have been initialized so here we have a lot",
    "start": "1215629",
    "end": "1224239"
  },
  {
    "text": "more information and if we take an eagle's eye sort of bird's eye view with",
    "start": "1224239",
    "end": "1230389"
  },
  {
    "text": "this we can see that there's this correlation between the r-squared value and the mean absolute error what we find",
    "start": "1230389",
    "end": "1238580"
  },
  {
    "text": "is that for smaller values of R squared it seems like we get more error so maybe we should use the ml flow search",
    "start": "1238580",
    "end": "1243979"
  },
  {
    "text": "functionality in the UI to filter our results and ignore some of those with the lower r-squared values and we can do",
    "start": "1243979",
    "end": "1250219"
  },
  {
    "text": "that by typing in a very simple sequel excerpt query we will restrict the R",
    "start": "1250219",
    "end": "1256309"
  },
  {
    "text": "squared value to being greater than 0.26 and if we do that and we take a look at",
    "start": "1256309",
    "end": "1263299"
  },
  {
    "text": "the filtered runs we see that all of them match that predicate then we can select our remaining information and",
    "start": "1263299",
    "end": "1270249"
  },
  {
    "text": "perform a comparison between the different training sessions we can plot for example how the l1 parameter",
    "start": "1270249",
    "end": "1277430"
  },
  {
    "text": "relates to mean absolutely there in this case this isn't a super illuminating context it looks like regardless of",
    "start": "1277430",
    "end": "1283220"
  },
  {
    "text": "parameter value you're sort of seeing the same error but you could imagine that for models that are highly",
    "start": "1283220",
    "end": "1288530"
  },
  {
    "text": "sensitive to certain parameters for performance this kind of visualization technique is extremely useful in",
    "start": "1288530",
    "end": "1294140"
  },
  {
    "text": "determining at a quick glance which set of parameters is optimal and that",
    "start": "1294140",
    "end": "1302810"
  },
  {
    "text": "concludes my portion of the ML flow tracking demo but rather there's a couple other concepts that I would like",
    "start": "1302810",
    "end": "1309200"
  },
  {
    "text": "to talk about addressing how the MFL tracking component could be integrated within your existing infrastructure so",
    "start": "1309200",
    "end": "1317060"
  },
  {
    "text": "ml flow divides its tracking components into a couple of different concepts that",
    "start": "1317060",
    "end": "1322250"
  },
  {
    "text": "are abstracted the first is an entity store this is a file store that persists all of the metrics parameters tags and",
    "start": "1322250",
    "end": "1330320"
  },
  {
    "text": "notes associated with a machine learning training session basically anything that's light weights and isn't a large",
    "start": "1330320",
    "end": "1335870"
  },
  {
    "text": "blob for example an artifact and users can leverage existing implementations of",
    "start": "1335870",
    "end": "1341750"
  },
  {
    "text": "a file store that's available on their local host as well as a restful based",
    "start": "1341750",
    "end": "1347660"
  },
  {
    "text": "server that can be integrated into existing infrastructure we're also working on a database back-end possibly",
    "start": "1347660",
    "end": "1353030"
  },
  {
    "text": "looking at using sequel Lite or some other more heavyweight database implementation to fully optimize this",
    "start": "1353030",
    "end": "1359930"
  },
  {
    "text": "entity store the other components is an artifact repository which allows users to store their existing machine learning",
    "start": "1359930",
    "end": "1366860"
  },
  {
    "text": "models as as blob data that can then be reloaded so this would store all of the tensor flow graphs scikit-learn",
    "start": "1366860",
    "end": "1373130"
  },
  {
    "text": "estimators are functions for example that are saved as Emma flow training",
    "start": "1373130",
    "end": "1378620"
  },
  {
    "text": "sessions and this is available in a variety of different formats and we define a relatively abstract and easy to",
    "start": "1378620",
    "end": "1385430"
  },
  {
    "text": "implements API for integrating additional blob stores into ml flow for the purpose of acting as artifact",
    "start": "1385430",
    "end": "1391910"
  },
  {
    "text": "repositories we provide support out of the box for an s3 back store we also provide support for platforms like",
    "start": "1391910",
    "end": "1398660"
  },
  {
    "text": "Google Cloud Storage as well as the dbfs artifact repository on data breaks so",
    "start": "1398660",
    "end": "1404000"
  },
  {
    "text": "chances are if there's a major blob store that you want to use to persist model artifacts ml flow is compatible",
    "start": "1404000",
    "end": "1409730"
  },
  {
    "text": "with it now I'm going to hand it over to Tomas who's going to run through the deep dive",
    "start": "1409730",
    "end": "1415360"
  },
  {
    "text": "of the m/l flow projects and m/l flow models components Thank You Cory okay",
    "start": "1415360",
    "end": "1439600"
  },
  {
    "text": "I'm so again I'm gonna continue where we left off and I'm gonna talk a little bit more about the other two components of",
    "start": "1439600",
    "end": "1446230"
  },
  {
    "text": "Mo flow which is Emma for projects and Emma for models and Emma flow projects",
    "start": "1446230",
    "end": "1452440"
  },
  {
    "text": "is a packaging format for reproducible runs on any platform and Emma flow models is a general format that supports",
    "start": "1452440",
    "end": "1459580"
  },
  {
    "text": "diverse deployment tools but what you can you can think of both of these is kind of like a wrapper around training",
    "start": "1459580",
    "end": "1466330"
  },
  {
    "text": "which allows you to run the same training code in you know any environment and then the wrapper around",
    "start": "1466330",
    "end": "1472780"
  },
  {
    "text": "scoring which allows you to deploy your models into any environment right so",
    "start": "1472780",
    "end": "1481060"
  },
  {
    "text": "here's the outline for the two parts of the talk I'm gonna talk a bit about motivation for above and then give a",
    "start": "1481060",
    "end": "1488530"
  },
  {
    "text": "quick overview follow up with an example and a short demo in any day and I'll wrap it up ok um so what's the",
    "start": "1488530",
    "end": "1497050"
  },
  {
    "text": "motivation for Emma for projects why do we think that you know this is important",
    "start": "1497050",
    "end": "1502740"
  },
  {
    "text": "so you know modern machine and modern machine learning environment you have",
    "start": "1502740",
    "end": "1508510"
  },
  {
    "text": "like many many different tools so you have fighter gym exhibition and tons of",
    "start": "1508510",
    "end": "1513760"
  },
  {
    "text": "flow and scikit-learn and our and spark and the list goes on and unlike in many",
    "start": "1513760",
    "end": "1520540"
  },
  {
    "text": "other disciplines you often actually need to use several of those tools in the same project because you know",
    "start": "1520540",
    "end": "1527230"
  },
  {
    "text": "different tools produce different results and different problems and sometimes you might need to try a couple",
    "start": "1527230",
    "end": "1533200"
  },
  {
    "text": "of them to get the best results for your your problem on top of that there is often situations where you know we have",
    "start": "1533200",
    "end": "1539980"
  },
  {
    "text": "diverse set of data scientists on your team they might be familiar with different tools so it comes up quite",
    "start": "1539980",
    "end": "1546020"
  },
  {
    "text": "often that that people combine multiple tools under project and then to mix",
    "start": "1546020",
    "end": "1551150"
  },
  {
    "text": "things first you have diverse set of environments where you might want to run your code right so you have you know your local",
    "start": "1551150",
    "end": "1557720"
  },
  {
    "text": "machine like Mac or Linux or whatever and then you have all these production environments based on docker or data",
    "start": "1557720",
    "end": "1565460"
  },
  {
    "text": "breaks or kubernetes and you know the the result is that it is quite difficult",
    "start": "1565460",
    "end": "1571850"
  },
  {
    "text": "to productionize machine learning code because it often happens that you know your code has dependencies you didn't",
    "start": "1571850",
    "end": "1578570"
  },
  {
    "text": "cover different version of the library leads to different results and yeah",
    "start": "1578570",
    "end": "1584990"
  },
  {
    "text": "people struggle physically reproducing their results in different environments",
    "start": "1584990",
    "end": "1590260"
  },
  {
    "text": "so division of ml flow to tackle this problem is to have this ml for project",
    "start": "1590260",
    "end": "1597500"
  },
  {
    "text": "which encapsulates basically everything that is needed to run the project so then capsulize the code in capture is",
    "start": "1597500",
    "end": "1604580"
  },
  {
    "text": "the configuration and encapsulates the data and then on top of that we provide api's which allow for you know either",
    "start": "1604580",
    "end": "1611720"
  },
  {
    "text": "local execution again in different environments or for remote execution in",
    "start": "1611720",
    "end": "1618320"
  },
  {
    "text": "production or maybe on a bigger machine on ec2 right so here's a little bit more",
    "start": "1618320",
    "end": "1625820"
  },
  {
    "text": "detail about what ml 4 projects are about so it is a packaging format for producible ml runs the kind of key",
    "start": "1625820",
    "end": "1633620"
  },
  {
    "text": "design principle of Emma flow is that it should be easy to get started so you",
    "start": "1633620",
    "end": "1639650"
  },
  {
    "text": "know we try to make like as few obstacles you know for you to",
    "start": "1639650",
    "end": "1645200"
  },
  {
    "text": "incorporate this into your existing tools as possible so actually any code directory or github repository will work",
    "start": "1645200",
    "end": "1652100"
  },
  {
    "text": "as a number for project but you'll get most benefit if you include this ml project file which tells ml flow kind of",
    "start": "1652100",
    "end": "1660890"
  },
  {
    "text": "what's inside what are the dependencies what command to run and it allows you to abstract from how that particular",
    "start": "1660890",
    "end": "1668360"
  },
  {
    "text": "project is implemented now the dependencies can be defined by either",
    "start": "1668360",
    "end": "1674210"
  },
  {
    "text": "Conda environment or our dependencies file in the future also darker and the idea",
    "start": "1674210",
    "end": "1683600"
  },
  {
    "text": "is that you know with the dependencies part being part of the project you get a",
    "start": "1683600",
    "end": "1689170"
  },
  {
    "text": "reproducible tear in any environment and then as I mentioned before on top of all",
    "start": "1689170",
    "end": "1696380"
  },
  {
    "text": "this we have we have this api's which allows you to run it in you know in",
    "start": "1696380",
    "end": "1701720"
  },
  {
    "text": "different environments in different way so we have a CLI which where you can execute projects from become online we",
    "start": "1701720",
    "end": "1708110"
  },
  {
    "text": "have clients for Python are in Java and which allow you to execute the projects directly from you know from the source",
    "start": "1708110",
    "end": "1715430"
  },
  {
    "text": "code now here is an example how ml flow project looks like so you can see that",
    "start": "1715430",
    "end": "1722450"
  },
  {
    "text": "it's basically a directory structure of code and then some extra stuff and the extra stuff is you know let's start with",
    "start": "1722450",
    "end": "1728660"
  },
  {
    "text": "the ML project file so it is a file which contains configuration of your machine learning project in this case you can see that it specifies condo",
    "start": "1728660",
    "end": "1735530"
  },
  {
    "text": "environment which has the dependencies and then it has a list of entry points",
    "start": "1735530",
    "end": "1741410"
  },
  {
    "text": "in this case there is only one entry point called main but every entry point is essentially a comment you can execute it it can be to train your code or you",
    "start": "1741410",
    "end": "1748610"
  },
  {
    "text": "know different versions of training your code and the entry point has a list of",
    "start": "1748610",
    "end": "1753680"
  },
  {
    "text": "parameters and then it specifies a comment to run so this actually is pretty powerful because you know",
    "start": "1753680",
    "end": "1760700"
  },
  {
    "text": "different people use different you know formats and the command line and different languages are invoked",
    "start": "1760700",
    "end": "1767480"
  },
  {
    "text": "differently so this kind of allows you to abstract of whatever is inside you have just like one unified interface so",
    "start": "1767480",
    "end": "1772790"
  },
  {
    "text": "you can execute whatever the ML project is and now here's an example how you can",
    "start": "1772790",
    "end": "1778850"
  },
  {
    "text": "run it so let's say if this project was sitting on gate I can execute it directly from gate in which case I'm",
    "start": "1778850",
    "end": "1785990"
  },
  {
    "text": "offload a lot to get hash and you get exact version of the code that ran and I",
    "start": "1785990",
    "end": "1791090"
  },
  {
    "text": "can run the same from Python okay um so now I'm gonna show to show a quick demo",
    "start": "1791090",
    "end": "1797450"
  },
  {
    "text": "of how ml projects work in practice so let's I'm gonna continue in chorus",
    "start": "1797450",
    "end": "1804140"
  },
  {
    "text": "example of the you know predicting prices of Airbnb listings",
    "start": "1804140",
    "end": "1810530"
  },
  {
    "text": "but in my case I'm gonna have like these two data scientists who produce you know",
    "start": "1810530",
    "end": "1815810"
  },
  {
    "text": "who who provided code in two different languages and we will see how we can",
    "start": "1815810",
    "end": "1821050"
  },
  {
    "text": "inspect and run their code and change parameters and improve on their results",
    "start": "1821050",
    "end": "1827500"
  },
  {
    "text": "okay so here's my here's my muffled tracking server I actually already when",
    "start": "1827500",
    "end": "1833390"
  },
  {
    "text": "when run myself but I would like to focus on the light later two items so we",
    "start": "1833390",
    "end": "1842240"
  },
  {
    "text": "have Aaron who ran this project called spark summit by exhibit project and if I",
    "start": "1842240",
    "end": "1849590"
  },
  {
    "text": "click on it it takes me to the github repository it is because he ran the project directly from good and I can see",
    "start": "1849590",
    "end": "1855710"
  },
  {
    "text": "that there's a bunch of files and you know there's some Python source code yeah and but it's kind of difficult to",
    "start": "1855710",
    "end": "1863180"
  },
  {
    "text": "see what exactly is going on and then you know because he ran it with ml flow",
    "start": "1863180",
    "end": "1868370"
  },
  {
    "text": "we have the list of parameters he used and we have the results he recorded as",
    "start": "1868370",
    "end": "1873880"
  },
  {
    "text": "rmse and validations at rmse and then we have Amy who provided the code in our",
    "start": "1873880",
    "end": "1880130"
  },
  {
    "text": "actual a any know similar thing we can go to to the github and see her source",
    "start": "1880130",
    "end": "1887450"
  },
  {
    "text": "code and she also provided you know",
    "start": "1887450",
    "end": "1893300"
  },
  {
    "text": "animation validation are missing her code seems to be doing a little bit better but you know first of all let's",
    "start": "1893300",
    "end": "1898640"
  },
  {
    "text": "let's see if we can reproduce their results right like if you can run it ourselves and you know so one option I",
    "start": "1898640",
    "end": "1907400"
  },
  {
    "text": "have to run the code is from the command line so let's execute Amy's ghost",
    "start": "1907400",
    "end": "1915560"
  },
  {
    "text": "Amy's code first let's say in this case I might not know anything about our I",
    "start": "1915560",
    "end": "1921170"
  },
  {
    "text": "might not know what sort of you know library she used within the our I can just simply execute ml for Ron and the",
    "start": "1921170",
    "end": "1927620"
  },
  {
    "text": "github repository and yeah we're training and we should",
    "start": "1927620",
    "end": "1936110"
  },
  {
    "text": "see the results in shortly",
    "start": "1936110",
    "end": "1939580"
  },
  {
    "text": "right so we have a have a new item and",
    "start": "1941200",
    "end": "1947750"
  },
  {
    "text": "you know we can see that we we get same results as its before and now for",
    "start": "1947750",
    "end": "1956210"
  },
  {
    "text": "running the Python I can run I can run the project in the same way but maybe let's try something more interesting",
    "start": "1956210",
    "end": "1961790"
  },
  {
    "text": "let's see that I'm Amy who's an our user doesn't know maybe much about Python but",
    "start": "1961790",
    "end": "1968060"
  },
  {
    "text": "she knows something about XE post and you know great and push the trees and maybe she noticed that the parameters",
    "start": "1968060",
    "end": "1973430"
  },
  {
    "text": "area news don't look quite right so she can actually execute errands project directly from are without you know again",
    "start": "1973430",
    "end": "1980600"
  },
  {
    "text": "knowing anything about it so she she can go just call ml for Ron and give me the",
    "start": "1980600",
    "end": "1986420"
  },
  {
    "text": "URI pointing to the same it have repository and then she can get parameter list where she says like her",
    "start": "1986420",
    "end": "1993220"
  },
  {
    "text": "you know hyper parameters right and we can execute the code from our steel as",
    "start": "1993220",
    "end": "2000070"
  },
  {
    "text": "she's used to and [Music]",
    "start": "2000070",
    "end": "2004630"
  },
  {
    "text": "seems like I'm missing seems like for some reason I lost my condo environment",
    "start": "2015860",
    "end": "2022130"
  },
  {
    "text": "but in principle this is how she could",
    "start": "2022130",
    "end": "2027920"
  },
  {
    "text": "run if she didn't mess up her condo environments before there should be a",
    "start": "2027920",
    "end": "2035690"
  },
  {
    "text": "you know simple fix but I'm gonna have to continue with my presentation I might I might get back to it later okay um so",
    "start": "2035690",
    "end": "2045680"
  },
  {
    "text": "now let's let's follow up to the ml for models yeah first the motivation why do",
    "start": "2045680",
    "end": "2053149"
  },
  {
    "text": "we think that mo for models is important part of you know machine learning workflow or you know tool for managing",
    "start": "2053150",
    "end": "2061490"
  },
  {
    "text": "machine learning workflow so it's really similar motivation to to the projects you know we start with the same diverse",
    "start": "2061490",
    "end": "2068840"
  },
  {
    "text": "set of tools as you know we had for training and these are tools can produce some form of a machine learning model",
    "start": "2068840",
    "end": "2074990"
  },
  {
    "text": "which you know sooner or later we would like to put it into production right and",
    "start": "2074990",
    "end": "2080419"
  },
  {
    "text": "then for production it's actually even worse in this case because we have many many different modes of production even",
    "start": "2080420",
    "end": "2086960"
  },
  {
    "text": "right so we have you know real-time scoring as a REST API endpoint which can",
    "start": "2086960",
    "end": "2093080"
  },
  {
    "text": "be deployed you know somewhere in docker or maybe on Sage maker and then we can also be interested in scoring big data",
    "start": "2093080",
    "end": "2099800"
  },
  {
    "text": "and badge let's say on spark right and you know so that the list of potential",
    "start": "2099800",
    "end": "2106600"
  },
  {
    "text": "you know deployment endpoints is even bigger here and with with the list of",
    "start": "2106600",
    "end": "2112040"
  },
  {
    "text": "tools what we get is like this you know unmanageable end-to-end mapping where",
    "start": "2112040",
    "end": "2118220"
  },
  {
    "text": "given basically every tool would have to provide ways to score on every potential endpoint and it's clearly not manageable",
    "start": "2118220",
    "end": "2125870"
  },
  {
    "text": "so the vision of my flow in this case is to have this unified ml4 model format",
    "start": "2125870",
    "end": "2134930"
  },
  {
    "text": "where you know all the tools can represent their models as the ammo for",
    "start": "2134930",
    "end": "2140450"
  },
  {
    "text": "model and then all the endpoints and then provide tools to deploy Emma for models",
    "start": "2140450",
    "end": "2146090"
  },
  {
    "text": "into them and the idea is that this is like a kind of abstraction barrier and",
    "start": "2146090",
    "end": "2152090"
  },
  {
    "text": "neither sides have to know details of the other one right so um let's take a",
    "start": "2152090",
    "end": "2157970"
  },
  {
    "text": "closer look on what Emma phone models look like so it is a packaging format for ml4 models the format is similar to",
    "start": "2157970",
    "end": "2167440"
  },
  {
    "text": "you know to to the project it's a directory structure with some you",
    "start": "2167440",
    "end": "2173540"
  },
  {
    "text": "know model specific data and some code and it contains this ml model file which includes configuration for a model",
    "start": "2173540",
    "end": "2181360"
  },
  {
    "text": "similarly to project we define dependencies by using the same tools so",
    "start": "2181360",
    "end": "2186560"
  },
  {
    "text": "Conda and our dependencies and in the future docker and similarity projects we",
    "start": "2186560",
    "end": "2192140"
  },
  {
    "text": "include api's to deploy deploy to models",
    "start": "2192140",
    "end": "2197330"
  },
  {
    "text": "right then we have again api's from for CLI python are in Java now here is an",
    "start": "2197330",
    "end": "2204890"
  },
  {
    "text": "example of how M oh I'm a model look like it looks like so in this particular",
    "start": "2204890",
    "end": "2211220"
  },
  {
    "text": "case we have a directory structure with some you know model specific data in this case it's a tensor flow model and",
    "start": "2211220",
    "end": "2217670"
  },
  {
    "text": "then we have this Emma model file with configuration and you can see that the configuration includes Devon ID so we",
    "start": "2217670",
    "end": "2224030"
  },
  {
    "text": "can always point we can always trace the model back to the run it generated it we know when it was created",
    "start": "2224030",
    "end": "2230570"
  },
  {
    "text": "it's important and then there's this list of flavors which I'm going to talk a little bit later in more detail but",
    "start": "2230570",
    "end": "2237980"
  },
  {
    "text": "flavors is basically different representations of the model for different purposes in this case we have turns the flow and then we have Python",
    "start": "2237980",
    "end": "2244340"
  },
  {
    "text": "function and you know tensorflow is useful for all the tools that know",
    "start": "2244340",
    "end": "2251090"
  },
  {
    "text": "how to deal with those are for models and Python function is useful basically to anybody who wants to deploy the model",
    "start": "2251090",
    "end": "2257750"
  },
  {
    "text": "without knowing what the model really is just knowing that it's a it's a Python executable and now here's how you would",
    "start": "2257750",
    "end": "2266990"
  },
  {
    "text": "log such a model so you could use Emma for tensorflow log model and then Emma for takes care of it",
    "start": "2266990",
    "end": "2273100"
  },
  {
    "text": "yeah so let me talk a little bit more about the flavors of Emma for models all",
    "start": "2273100",
    "end": "2278120"
  },
  {
    "text": "right so any model can lock multiple flavors and the purpose of this is that we basically",
    "start": "2278120",
    "end": "2287020"
  },
  {
    "text": "cover all the possible use cases you know you might have if when applying",
    "start": "2287020",
    "end": "2293470"
  },
  {
    "text": "when applying the model so for instance the model we looked at earlier someone might want to pull it back to tensorflow",
    "start": "2293470",
    "end": "2299410"
  },
  {
    "text": "extent the graph you know tweak it and score it someone else might just want to score it before knowing anything about",
    "start": "2299410",
    "end": "2306880"
  },
  {
    "text": "it in some cases for example for spark models that can be exported as in the",
    "start": "2306880",
    "end": "2313390"
  },
  {
    "text": "Emily format which provides more efficient online scoring right or spark",
    "start": "2313390",
    "end": "2318940"
  },
  {
    "text": "format which provides better support for batch coding and spark so the to the",
    "start": "2318940",
    "end": "2325570"
  },
  {
    "text": "flavors is like really a tool to give us flexibility to represent any models in",
    "start": "2325570",
    "end": "2331930"
  },
  {
    "text": "several different ways now let me talk",
    "start": "2331930",
    "end": "2337870"
  },
  {
    "text": "about the Python which is the generic Python model so the idea of a Python is",
    "start": "2337870",
    "end": "2343930"
  },
  {
    "text": "that it's a very generic model which can really represent any potential model",
    "start": "2343930",
    "end": "2349420"
  },
  {
    "text": "representable in Python whatsoever and it is a search it is defined as a",
    "start": "2349420",
    "end": "2354910"
  },
  {
    "text": "directory structure if you know these",
    "start": "2354910",
    "end": "2360220"
  },
  {
    "text": "components some of which are optional the only mandatory part is that it",
    "start": "2360220",
    "end": "2365380"
  },
  {
    "text": "includes a link to the loader which can load this model and the loader is Python",
    "start": "2365380",
    "end": "2372250"
  },
  {
    "text": "package which must be visible during the loading time right but in addition you",
    "start": "2372250",
    "end": "2378160"
  },
  {
    "text": "can specify any code dependencies where the code will be just packaged with the motor with the model itself any",
    "start": "2378160",
    "end": "2384190"
  },
  {
    "text": "potential data dependencies and in an environment with you know Python",
    "start": "2384190",
    "end": "2392050"
  },
  {
    "text": "packages that you require to run and",
    "start": "2392050",
    "end": "2399390"
  },
  {
    "text": "because the Python model makes or that the Python model makes very few",
    "start": "2399390",
    "end": "2405580"
  },
  {
    "text": "assumptions about what it has to provide",
    "start": "2405580",
    "end": "2410850"
  },
  {
    "text": "basically any any model can be represented as a Python model and an MF law provides",
    "start": "2411000",
    "end": "2418630"
  },
  {
    "text": "functionalities to work with this model for instance any Python function model can be deployed as a REST API server it",
    "start": "2418630",
    "end": "2426860"
  },
  {
    "text": "can be deployed to Sage Maker it can be deployed to spark in the spark UDF basically by including this Python",
    "start": "2426860",
    "end": "2434300"
  },
  {
    "text": "function flavor in your model you get all these things for free so it's great for ability ok so",
    "start": "2434300",
    "end": "2446720"
  },
  {
    "text": "now we're gonna go back to the demo and I'm gonna show how you know in the first first part we've generated some model in",
    "start": "2446720",
    "end": "2452930"
  },
  {
    "text": "different languages now we'll see how we can how we can score them so first we",
    "start": "2452930",
    "end": "2460760"
  },
  {
    "text": "can I kind of didn't really look into into the details of the round and in the",
    "start": "2460760",
    "end": "2467060"
  },
  {
    "text": "first part of the demo so maybe let's take a look on what sort of models we have so we have the model generated in our and we can see that you know it is",
    "start": "2467060",
    "end": "2476000"
  },
  {
    "text": "the familiar I'm a model file and we have flavors here Chara's because it's a Karass model and then python function",
    "start": "2476000",
    "end": "2483670"
  },
  {
    "text": "and then and then there is some like model specific file in this case h5 5",
    "start": "2484240",
    "end": "2491450"
  },
  {
    "text": "with configuration and then here we have cond environment which includes dependencies in this case ml flow and",
    "start": "2491450",
    "end": "2498470"
  },
  {
    "text": "chaos 2.2 or greater so let's take a",
    "start": "2498470",
    "end": "2505580"
  },
  {
    "text": "look how how we can put these models into production",
    "start": "2505580",
    "end": "2511540"
  },
  {
    "text": "right um so so we have these models and they are sitting and under under tracking so right so I can refer to them",
    "start": "2514620",
    "end": "2521680"
  },
  {
    "text": "by the run ID and their artifact path and they they all provided Python",
    "start": "2521680",
    "end": "2530500"
  },
  {
    "text": "function as one of their flavors so I can have use it to predict it without really knowing much about the models so",
    "start": "2530500",
    "end": "2543640"
  },
  {
    "text": "by using Emma for Python predict I can score basically any any model sitting on",
    "start": "2543640",
    "end": "2550720"
  },
  {
    "text": "which provides Python function on rich data so let's just go run of these yeah",
    "start": "2550720",
    "end": "2563410"
  },
  {
    "text": "and you can see the Emma flow in this case quietly activates the Conda environment runs the model with you know all the",
    "start": "2563410",
    "end": "2569800"
  },
  {
    "text": "dependencies and then just returns meter results similarly",
    "start": "2569800",
    "end": "2576089"
  },
  {
    "text": "I can set up the model as a REST API endpoint and again all I need to provide",
    "start": "2581250",
    "end": "2589020"
  },
  {
    "text": "this run ID and artifact I don't need to worry about what sort of model it is and",
    "start": "2589020",
    "end": "2598920"
  },
  {
    "text": "then I can create let's say by a curl and I get the same results",
    "start": "2598920",
    "end": "2605060"
  },
  {
    "text": "now the for maybe more interesting",
    "start": "2605060",
    "end": "2612060"
  },
  {
    "text": "example how I can use this model in diverse environment so maybe I have like",
    "start": "2612060",
    "end": "2617490"
  },
  {
    "text": "this big data set sitting on spark and I want to make sure that the model behaves it's expected on big data as well so I",
    "start": "2617490",
    "end": "2626190"
  },
  {
    "text": "can actually easily pull it into spark turn it into spark EDF and then scoring",
    "start": "2626190",
    "end": "2631410"
  },
  {
    "text": "on big data so here I just read read the data from",
    "start": "2631410",
    "end": "2638910"
  },
  {
    "text": "park' format here's the example of the of the data if you know Peter Center",
    "start": "2638910",
    "end": "2645000"
  },
  {
    "text": "columns and I said a mouthful tracking URI to the tutor server I used in this",
    "start": "2645000",
    "end": "2652890"
  },
  {
    "text": "case called data breaks and yeah this is",
    "start": "2652890",
    "end": "2658319"
  },
  {
    "text": "this is where I pull the model into spar basically again all I need to know is the artifact name that I called simply",
    "start": "2658319",
    "end": "2665520"
  },
  {
    "text": "model and the run ID we generated the model and I get my spark IDF and",
    "start": "2665520",
    "end": "2671810"
  },
  {
    "text": "applying spark PDF is simple as I'm sure many of you know I just got in data",
    "start": "2671810",
    "end": "2678569"
  },
  {
    "text": "frame and I have my results and model",
    "start": "2678569",
    "end": "2684540"
  },
  {
    "text": "seem to be behaving same on Big Data",
    "start": "2684540",
    "end": "2689690"
  },
  {
    "text": "okay um so that concludes the demo part of the models now we don't really have",
    "start": "2693940",
    "end": "2702470"
  },
  {
    "text": "too much time left in this talk but there is also more advanced parts of ML flouted you can",
    "start": "2702470",
    "end": "2708560"
  },
  {
    "text": "check on our website and you know work with we have a way for examples that you",
    "start": "2708560",
    "end": "2718310"
  },
  {
    "text": "can you can try for more advanced use right so this was like a machine learning basics but in reality you",
    "start": "2718310",
    "end": "2725240"
  },
  {
    "text": "probably want to do more so one example of such advanced use case is hyper parametric tuning which is critical part",
    "start": "2725240",
    "end": "2733070"
  },
  {
    "text": "of machine learning workflow it kind of reduces the variance of you know if your",
    "start": "2733070",
    "end": "2739100"
  },
  {
    "text": "machine learning process and it gives you out to mention rather than you know",
    "start": "2739100",
    "end": "2745580"
  },
  {
    "text": "manual tuning and uncertain results right and then if you check our our",
    "start": "2745580",
    "end": "2750920"
  },
  {
    "text": "examples there is an example how you can do hyperparameters before more flow here is a basically conceptual picture and",
    "start": "2750920",
    "end": "2757670"
  },
  {
    "text": "you can see that even such a thing as hyper parameter tuning can benefit from",
    "start": "2757670",
    "end": "2763430"
  },
  {
    "text": "Emma flow and several fronts so one one",
    "start": "2763430",
    "end": "2768860"
  },
  {
    "text": "big benefit we get from ammo flow here is that we can basically have this hyper",
    "start": "2768860",
    "end": "2774650"
  },
  {
    "text": "parameter tuning project which can then execute any other MMO full project again like Icarus language boundaries you know",
    "start": "2774650",
    "end": "2782600"
  },
  {
    "text": "different notations for command line parameters basically you can take any",
    "start": "2782600",
    "end": "2788210"
  },
  {
    "text": "particular project and to native if you hyper parameter with your favorite hyper",
    "start": "2788210",
    "end": "2795470"
  },
  {
    "text": "perimeter algorithm now everything is logged before mail flow tracking so you can you know inspect the results and",
    "start": "2795470",
    "end": "2802160"
  },
  {
    "text": "have history of those for later use and",
    "start": "2802160",
    "end": "2807860"
  },
  {
    "text": "we can lock Emma for models and deploy them later to production another example of advanced use of Emma flow is a",
    "start": "2807860",
    "end": "2814370"
  },
  {
    "text": "multi-step workflow again this comes very common in real use cases where maybe you have like a big data which can",
    "start": "2814370",
    "end": "2820580"
  },
  {
    "text": "mean they need to be pre-processed you know eventually generating train",
    "start": "2820580",
    "end": "2826830"
  },
  {
    "text": "they said which you might want to apply on different machine with this for instance if you want to turn if you want",
    "start": "2826830",
    "end": "2833700"
  },
  {
    "text": "to train this is flow model you might want to train on GPU machines but ETL is",
    "start": "2833700",
    "end": "2841440"
  },
  {
    "text": "better to be done on like a standard cluster so you can use these multi-step or close to to combine basically",
    "start": "2841440",
    "end": "2852270"
  },
  {
    "text": "different projects together chain them and get your results now to get started",
    "start": "2852270",
    "end": "2859230"
  },
  {
    "text": "with ml flow we are on pip and on cran so for you know Python dinar it's really",
    "start": "2859230",
    "end": "2868050"
  },
  {
    "text": "easy to the kids that you just type pip install ml flow and you can start using it you can find dogs and examples on M",
    "start": "2868050",
    "end": "2875040"
  },
  {
    "text": "afloat at arc all sonar github and we have a slack channel where you can ask",
    "start": "2875040",
    "end": "2881550"
  },
  {
    "text": "questions and answer now the ongoing",
    "start": "2881550",
    "end": "2887960"
  },
  {
    "text": "roadmaps I'm a flow is still relatively new project it's under intense",
    "start": "2887960",
    "end": "2892980"
  },
  {
    "text": "development there is plenty of new features and functionalities which are",
    "start": "2892980",
    "end": "2898890"
  },
  {
    "text": "coming also based on demand from our users so you know please check it out and be active on there on all the",
    "start": "2898890",
    "end": "2906120"
  },
  {
    "text": "channels and you know if you have stuff that you think is missing and would really benefit you we'll be happy to add",
    "start": "2906120",
    "end": "2912870"
  },
  {
    "text": "it ok so to conclude you know that to",
    "start": "2912870",
    "end": "2921090"
  },
  {
    "text": "like I'm a flow can greatly simplified machine learning life cycle it can allow you to abstract from you know details of",
    "start": "2921090",
    "end": "2928380"
  },
  {
    "text": "individual machine learning project and make sure that you can keep track of",
    "start": "2928380",
    "end": "2934500"
  },
  {
    "text": "your results be able to reproduce your code and deploy it to production thank",
    "start": "2934500",
    "end": "2942540"
  },
  {
    "text": "you [Applause]",
    "start": "2942540",
    "end": "2947150"
  }
]
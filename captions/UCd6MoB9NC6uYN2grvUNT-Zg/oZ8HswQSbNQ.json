[
  {
    "start": "0",
    "end": "30000"
  },
  {
    "text": "good morning and welcome to security 403 we're gonna dive deep in cloud trail",
    "start": "30",
    "end": "6629"
  },
  {
    "text": "logs today process them with Apache spark if you're looking to slice and dice cloud trail logs you're in the",
    "start": "6629",
    "end": "12300"
  },
  {
    "text": "right place my name is will Cruz I'm a security engineer on the ADA base Identity and Access Management team I'm",
    "start": "12300",
    "end": "19470"
  },
  {
    "text": "gonna show you some of the tools that we've used to be able to go back over historical cloud trail logs other log",
    "start": "19470",
    "end": "25859"
  },
  {
    "text": "sources as well as process those events as they arrive I promise I won't read",
    "start": "25859",
    "end": "31679"
  },
  {
    "start": "30000",
    "end": "30000"
  },
  {
    "text": "too many slides today but I want to be clear about what to expect from this session so we're gonna learn how to",
    "start": "31679",
    "end": "36690"
  },
  {
    "text": "audit database activity across multiple database accounts for compliance and security needs we're gonna learn how to",
    "start": "36690",
    "end": "42840"
  },
  {
    "text": "process that data as it arrives in your Amazon s3 buckets build profiles of",
    "start": "42840",
    "end": "49370"
  },
  {
    "text": "historical activity in your account for users origins maybe a specific country",
    "start": "49370",
    "end": "55379"
  },
  {
    "text": "of source IP address and then send alerts when there are deviations from those profiles or an interesting event",
    "start": "55379",
    "end": "62309"
  },
  {
    "text": "occurs and this is all gonna be based on Apache spark which is a cutting-edge Big",
    "start": "62309",
    "end": "68549"
  },
  {
    "text": "Data Platform I want to understand a little bit about you and what you're bringing to the session so who here has",
    "start": "68549",
    "end": "74880"
  },
  {
    "text": "used Apache spark before all right a couple people and but used spark streaming who's used some sort of big",
    "start": "74880",
    "end": "82500"
  },
  {
    "text": "data technology okay all right that's awesome I won't have to go too far back there cloud trail who's using cloud",
    "start": "82500",
    "end": "90060"
  },
  {
    "text": "trail who has it turned on in all regions all right thank you for your honesty",
    "start": "90060",
    "end": "95220"
  },
  {
    "text": "there's some homework which is go home turn it on in all regions you'll thank me later I told you this session came",
    "start": "95220",
    "end": "100470"
  },
  {
    "text": "with homework right all right and since it's a 400 level session I want to be clear on kind of the technical",
    "start": "100470",
    "end": "106470"
  },
  {
    "start": "102000",
    "end": "102000"
  },
  {
    "text": "background that we expect on the low end I'm gonna be presenting to you some code that is actually available in github",
    "start": "106470",
    "end": "113210"
  },
  {
    "text": "today that you can without even understanding it cut and paste it into",
    "start": "113210",
    "end": "118579"
  },
  {
    "text": "the spark interface and start querying your cloud trail logs but on the high end I'm going to be presenting to you",
    "start": "118579",
    "end": "124799"
  },
  {
    "text": "code that you can build on top of and you may look at this and say hey I could",
    "start": "124799",
    "end": "131009"
  },
  {
    "text": "do some of this with lambda I could do some of this with cloud watch well yeah you can this session is gonna give you a",
    "start": "131009",
    "end": "136900"
  },
  {
    "text": "starting point so you can control your own monitoring and security assurance",
    "start": "136900",
    "end": "142599"
  },
  {
    "text": "destiny for example there's a cloud trail provides an API lookup",
    "start": "142599",
    "end": "147840"
  },
  {
    "text": "functionality so you can go back a certain amount of time but if you want to run expressive sequel queries over",
    "start": "147840",
    "end": "154720"
  },
  {
    "text": "that data and combine it with other log sources this is a what we're going to be presenting today is a great platform for",
    "start": "154720",
    "end": "161860"
  },
  {
    "text": "that I'm gonna take questions here and outside afterwards so I just want to do",
    "start": "161860",
    "end": "168040"
  },
  {
    "text": "a quick reminder of the cloud trail schema in case anyone is not familiar",
    "start": "168040",
    "end": "174010"
  },
  {
    "text": "with it so go go demo go alright so this",
    "start": "174010",
    "end": "180250"
  },
  {
    "text": "is a sample cloud trail log this is the cloud trail excuse me a cloud trail event this is the cloud travel event",
    "start": "180250",
    "end": "186040"
  },
  {
    "text": "reference and in case you're not familiar with it pay attention to things like user identity principal ID access",
    "start": "186040",
    "end": "192250"
  },
  {
    "text": "key you'll see these showing up later when you make a particular request to a particular API the the service shows up",
    "start": "192250",
    "end": "200230"
  },
  {
    "text": "as the event name the excuse me the service shows up is the event source the event name is the API that you've called",
    "start": "200230",
    "end": "206889"
  },
  {
    "text": "here's the source IP address will be slicing and dicing that a bit today so I want to make sure we have that background and since I want to show you",
    "start": "206889",
    "end": "215109"
  },
  {
    "text": "is it I'd be like a cooking show I'm gonna show you the end result before we you know but before we actually go into",
    "start": "215109",
    "end": "221139"
  },
  {
    "text": "the how so this is just a standard sequel client this is squirrel SQL and I",
    "start": "221139",
    "end": "226959"
  },
  {
    "text": "apologize there's a for the small font this is a little harder to make the to increase the font size on but we have",
    "start": "226959",
    "end": "234340"
  },
  {
    "text": "our cloud trail logs exposed we've we've we've pulled them into Apache spark and",
    "start": "234340",
    "end": "239680"
  },
  {
    "text": "we have them exposed through a cloud trail table where we're able to put a wear condition on the event time and",
    "start": "239680",
    "end": "246790"
  },
  {
    "text": "let's say we're we're looking up the principal IDs and the event source and the event name and so this is well",
    "start": "246790",
    "end": "253090"
  },
  {
    "text": "actually the results are below but I got to show you that this actually works and so you run that query and what's",
    "start": "253090",
    "end": "258579"
  },
  {
    "text": "actually happening is that that is that is a JDBC connection",
    "start": "258579",
    "end": "265630"
  },
  {
    "text": "SSH tunneled to my you mark lustre and you can actually see here's a job that is active right now",
    "start": "265630",
    "end": "272289"
  },
  {
    "text": "this is the yarn interface that is that is this select query we can watch its",
    "start": "272289",
    "end": "278650"
  },
  {
    "text": "progress by refreshing this page we can sweat when the progress doesn't go as",
    "start": "278650",
    "end": "285970"
  },
  {
    "text": "fast as its supposed to oh demo is okay I'm not gonna belabor",
    "start": "285970",
    "end": "293620"
  },
  {
    "text": "the point there's also a spark sequel interface you can SSH into the cluster",
    "start": "293620",
    "end": "299639"
  },
  {
    "text": "type spark - SQL although I recommend some parameters to increase the number",
    "start": "299639",
    "end": "304960"
  },
  {
    "text": "of executors we'll talk about what those are in a minute and so let's say you",
    "start": "304960",
    "end": "310210"
  },
  {
    "text": "wanted to look through your cloud trail logs and you wanted to say who's calling",
    "start": "310210",
    "end": "316900"
  },
  {
    "text": "the Identity and Access Management Service the who here is the user identity dot AR n and what api's are",
    "start": "316900",
    "end": "325719"
  },
  {
    "text": "they calling and I'm gonna make it distinct and then I want to order it by event name so the use case for this is",
    "start": "325719",
    "end": "332229"
  },
  {
    "text": "you want to go figure out whose active in your account who's calling I am you know keep an eye on what's happening so",
    "start": "332229",
    "end": "338199"
  },
  {
    "text": "when you run this what you're actually seeing here stages this is the processing stages you can see that was",
    "start": "338199",
    "end": "343900"
  },
  {
    "text": "pretty fast I'll give you a little hint that when you run the query the first time spark actually has to go and fetch",
    "start": "343900",
    "end": "349840"
  },
  {
    "text": "that data from s3 so it takes a little bit longer but it's cached in memory which makes it real fast for this next",
    "start": "349840",
    "end": "355539"
  },
  {
    "text": "query in subsequent queries which is very helpful so now I've got a list of all the who's are doing what in the I am",
    "start": "355539",
    "end": "363729"
  },
  {
    "text": "service in my account and let's look here hmm the root a root user is",
    "start": "363729",
    "end": "369969"
  },
  {
    "text": "creating an access key and if you've been to any of the I M talks this weekend I've said you know minimize your",
    "start": "369969",
    "end": "375340"
  },
  {
    "text": "amount of root usage and why are we creating new access keys so now I'm going to run a similar query but I'm",
    "start": "375340",
    "end": "382330"
  },
  {
    "text": "going to add I want the event time now I want to know who made the request I'm",
    "start": "382330",
    "end": "390310"
  },
  {
    "text": "giving you the last one sorry and so I want to know who did it I want the event time and I want to I want to focus in on",
    "start": "390310",
    "end": "397839"
  },
  {
    "text": "user err ends where the where it's the root account and so we've got a wild card here",
    "start": "397839",
    "end": "404080"
  },
  {
    "text": "because I actually have multiple accounts worth of data loaded up here and so when I run this this is going to",
    "start": "404080",
    "end": "410650"
  },
  {
    "text": "allow me to Zone in on the specific specific times that route was creating",
    "start": "410650",
    "end": "418030"
  },
  {
    "text": "access keys and then if I want to actually get cloud trail has a response",
    "start": "418030",
    "end": "425740"
  },
  {
    "text": "elements in the cloud trail log so now if I include those maybe I can get a little bit more of a clue about what's",
    "start": "425740",
    "end": "430810"
  },
  {
    "text": "happening here so we run this and we get a response that includes here's the",
    "start": "430810",
    "end": "437289"
  },
  {
    "text": "access key that was created createdate although arguably we had that already",
    "start": "437289",
    "end": "443139"
  },
  {
    "text": "and here's the username so somebody using the root account created an access",
    "start": "443139",
    "end": "448690"
  },
  {
    "text": "key for the I M user work attempt and so this is a this is a simple illustration of being able to go into your cloud",
    "start": "448690",
    "end": "455440"
  },
  {
    "text": "trail logs run sequel queries against them and you can run them against any part of the the cloud trail logs let's",
    "start": "455440",
    "end": "462400"
  },
  {
    "text": "see if our other query finished no it's still running Oh bummer you'll just have",
    "start": "462400",
    "end": "470199"
  },
  {
    "text": "to trust me it works so let's actually switch back to presentation so it showed you the cloud",
    "start": "470199",
    "end": "477550"
  },
  {
    "text": "trail schema I showed you that demo so now you've seen you've seen the end result you've seen that we can run these sequel queries over local temporary",
    "start": "477550",
    "end": "484750"
  },
  {
    "text": "tables and hive tables we'll talk more about that in a minute how do we do this so the cloud trail logs are stored in s3",
    "start": "484750",
    "end": "490960"
  },
  {
    "text": "they're delivered they're delivered often within 15",
    "start": "490960",
    "end": "496000"
  },
  {
    "text": "minutes of the event occurring and we have a spark application running in",
    "start": "496000",
    "end": "501699"
  },
  {
    "text": "Amazon EMR that is that can go out and find those cloud trail logs and present",
    "start": "501699",
    "end": "507940"
  },
  {
    "text": "them for your security or compliance user and so let's actually discuss the",
    "start": "507940",
    "end": "513849"
  },
  {
    "start": "512000",
    "end": "512000"
  },
  {
    "text": "specific recipe the application that I'm showing you today and that we've",
    "start": "513849",
    "end": "519339"
  },
  {
    "text": "open-sourced and is on github it discovers your cloud trail logs by calling cloud trail calling described",
    "start": "519339",
    "end": "525160"
  },
  {
    "text": "trails and and that way it you don't have to say oh wait where did I put my cloud trail logs you can get just get",
    "start": "525160",
    "end": "531310"
  },
  {
    "text": "cloud travel tell you which is very helpful alternatively you could put your cloud trail logs from lots of different",
    "start": "531310",
    "end": "536800"
  },
  {
    "text": "accounts in one bucket or a small number of buckets even a large number of buckets it'll work we're then going to",
    "start": "536800",
    "end": "542259"
  },
  {
    "text": "create a list of those cloud trails in s3 objects we're gonna load the data",
    "start": "542259",
    "end": "547389"
  },
  {
    "text": "from each s3 object into a resilient distributed data set which is a spark",
    "start": "547389",
    "end": "553000"
  },
  {
    "text": "concept and we'll discuss it more in a minute and we're gonna the data that actually gets loaded in from a specific",
    "start": "553000",
    "end": "559319"
  },
  {
    "text": "s3 object is an array of json events spark needs the individual json events",
    "start": "559319",
    "end": "565720"
  },
  {
    "text": "so we need to massage those a little bit into the right format and then we're gonna load that into a data frame I'll",
    "start": "565720",
    "end": "571600"
  },
  {
    "text": "explain that in a minute and then register that data frame as a table for querying if any of that doesn't make",
    "start": "571600",
    "end": "576970"
  },
  {
    "text": "sense we're gonna dive into more detail but first I want to introduce spark since some folks are not as familiar",
    "start": "576970",
    "end": "582519"
  },
  {
    "start": "578000",
    "end": "578000"
  },
  {
    "text": "with it it's a big data processing framework it supports a number of different languages which is awesome",
    "start": "582519",
    "end": "587769"
  },
  {
    "text": "I initially was a little scared of Scala it's great right it is so refreshing",
    "start": "587769",
    "end": "592870"
  },
  {
    "text": "because I'm a Java guy so I recommend it different cluster management options and",
    "start": "592870",
    "end": "598449"
  },
  {
    "text": "then what's really great about SPARC is that if you like your existing Hadoop ecosystem component you can keep it you",
    "start": "598449",
    "end": "605350"
  },
  {
    "text": "can use HDFS and so lots of different storage options why did we why did we",
    "start": "605350",
    "end": "611380"
  },
  {
    "text": "pick spark well spark is fast well how fast you say compared to the dupe it's a",
    "start": "611380",
    "end": "616810"
  },
  {
    "text": "hundred times faster when you're storing the data in memory it's 10 times faster when you're storing the data in disk and",
    "start": "616810",
    "end": "623620"
  },
  {
    "text": "the reason is that Hadoop is not so good with multi pass computations each step",
    "start": "623620",
    "end": "630069"
  },
  {
    "text": "in generally each step in a data processing workflow needs to complete write that data out before the next one can begin spark can pipeline all of that",
    "start": "630069",
    "end": "637120"
  },
  {
    "text": "keep the data data local and so what we often see in the spark applications that we write is that is is that spark is",
    "start": "637120",
    "end": "645490"
  },
  {
    "text": "waiting until the last possible moment until you actually want it to do something and it's loading the data it's",
    "start": "645490",
    "end": "651550"
  },
  {
    "text": "processing it on that exact executor and writing it out from there you're not having to shuffle it around spark won",
    "start": "651550",
    "end": "657459"
  },
  {
    "text": "the 2014 Daytona Gray sort hundred terabyte benchmark in the previous year",
    "start": "657459",
    "end": "663370"
  },
  {
    "text": "2013 it took 72 minutes for a 2100 node",
    "start": "663370",
    "end": "668680"
  },
  {
    "text": "Hadoop cluster to sort those 100 terabytes the next year 2014 spark did it in 23 minutes",
    "start": "668680",
    "end": "675190"
  },
  {
    "text": "they used 206 ec2 nodes so they did it three times faster with 10 fewer machines I will say those ec2 machines",
    "start": "675190",
    "end": "682120"
  },
  {
    "text": "were pretty beefy but I digress and so we like spark because it not only",
    "start": "682120",
    "end": "691000"
  },
  {
    "text": "supports batch processing with stream processing we'll see that today it has integrated support for sequel the",
    "start": "691000",
    "end": "696399"
  },
  {
    "text": "machine learning graph data processing and even in our interface SPARC are just",
    "start": "696399",
    "end": "702250"
  },
  {
    "text": "had a big release and there's a number of high-level operations that you as a coder don't have to go out and and and",
    "start": "702250",
    "end": "709330"
  },
  {
    "text": "re-implement they're there for you it's it's very it's a great platform and as I",
    "start": "709330",
    "end": "716830"
  },
  {
    "text": "mentioned earlier it's compatible with a lot of your hip ecosystem so mention rdd's resilient distributed datasets",
    "start": "716830",
    "end": "722980"
  },
  {
    "start": "719000",
    "end": "719000"
  },
  {
    "text": "this is the this is the core data set in SPARC almost everything is an RDD its",
    "start": "722980",
    "end": "728920"
  },
  {
    "text": "resilient for two reasons number one is data in the RTD is replicated to different notes but it's actually the",
    "start": "728920",
    "end": "735760"
  },
  {
    "text": "primary reason is resilient is that spark when you take one RTD and you transform it to another and you",
    "start": "735760",
    "end": "742540"
  },
  {
    "text": "transform it to another it keeps a directed acyclic graph a dag of those transformations and if a block is lost",
    "start": "742540",
    "end": "749230"
  },
  {
    "text": "say in that third RTD it can go back and say oh I know how to take the data and the second RDD and transform it into the",
    "start": "749230",
    "end": "755500"
  },
  {
    "text": "third one which is awesome it's distributed because that RTD gets sliced up and apportioned out to the clusters",
    "start": "755500",
    "end": "761500"
  },
  {
    "text": "the nodes in the cluster and it's a it's a data SATA data set it's a first-class object which you can map you can Co",
    "start": "761500",
    "end": "768190"
  },
  {
    "text": "group you can count you can D dupe and so looking at our specific example here",
    "start": "768190",
    "end": "775300"
  },
  {
    "text": "let's see if my little clicker so we're starting out with the cloud trail",
    "start": "775300",
    "end": "781390"
  },
  {
    "text": "objects in s3 we call the spark parallelized command where we're actually taking the data in these log",
    "start": "781390",
    "end": "787839"
  },
  {
    "text": "files and we're creating an RDD in this first our DD is the string",
    "start": "787839",
    "end": "793360"
  },
  {
    "text": "representation of the data that's in s3 we haven't done any transformation yet so these are those Jason",
    "start": "793360",
    "end": "798889"
  },
  {
    "text": "raise and then we are going to flatmap that first RDD into a second RTD and end",
    "start": "798889",
    "end": "805699"
  },
  {
    "text": "up with an RDD of the individual json events of strings but we're not done yet",
    "start": "805699",
    "end": "811339"
  },
  {
    "text": "we're then going to take it's the same RTD there on the Left we're gonna take",
    "start": "811339",
    "end": "816379"
  },
  {
    "text": "that RTD and we're going to pass it to the sequel context a sequel context is",
    "start": "816379",
    "end": "822019"
  },
  {
    "text": "your interface to sparks SQL engine we're gonna pass it to the read JSON",
    "start": "822019",
    "end": "828109"
  },
  {
    "text": "interface and what it's going to do is it's going to it's going to read those objects it's going to figure out a",
    "start": "828109",
    "end": "833509"
  },
  {
    "text": "schema and it's going to create something that looks like a table that's something that looks like a table is a data frame this is sparks relational day",
    "start": "833509",
    "end": "840319"
  },
  {
    "text": "relational table abstraction and it can be queried just like it can be queried",
    "start": "840319",
    "end": "847069"
  },
  {
    "text": "with SQL you can register it either as a temporary table or register it as a hive table that hive table if you have a",
    "start": "847069",
    "end": "853970"
  },
  {
    "text": "medicine menaced or set up which the EMR for release has comes with a high of",
    "start": "853970",
    "end": "859279"
  },
  {
    "text": "meta store that will persist between runs of your application which is you know which is great because then you",
    "start": "859279",
    "end": "864829"
  },
  {
    "text": "have that data out there so looking at a spark cluster somewhat of a simplified",
    "start": "864829",
    "end": "870739"
  },
  {
    "start": "867000",
    "end": "867000"
  },
  {
    "text": "diagram so I can get it on to PowerPoint but you have a master node this is where your application runs and from your",
    "start": "870739",
    "end": "877489"
  },
  {
    "text": "perspective when you're writing this application is you're not worried about different nodes and and and what has to",
    "start": "877489",
    "end": "885829"
  },
  {
    "text": "happen on each node what spark is doing is saying oh hey you just did an operation on an RDD that data for that",
    "start": "885829",
    "end": "892309"
  },
  {
    "text": "RDD lives elsewhere on the cluster those operations let's take that let's serialize that Java or Scala code and",
    "start": "892309",
    "end": "900379"
  },
  {
    "text": "it's called a task and we'll send that task out to an executor there's at least one executor for every node in your",
    "start": "900379",
    "end": "906679"
  },
  {
    "text": "cluster you can have more than one they have to share nicely with the resources on on that node and it's a JVM that's",
    "start": "906679",
    "end": "914569"
  },
  {
    "text": "where that code is going to get deserialized executed and the results returned and also on each node is slices",
    "start": "914569",
    "end": "922339"
  },
  {
    "text": "or or partitions of those rdd's and so you generally want your code to be",
    "start": "922339",
    "end": "928399"
  },
  {
    "text": "executing near where the data that it's working on is so this is an overview of a spark",
    "start": "928399",
    "end": "934080"
  },
  {
    "text": "cluster I want to talk about a recommended cloud trail configuration you already heard that turn it on in all regions again you'll thank me later",
    "start": "934080",
    "end": "941400"
  },
  {
    "start": "935000",
    "end": "935000"
  },
  {
    "text": "you cloud trail will move data what you can use the same s3 bucket in different",
    "start": "941400",
    "end": "947040"
  },
  {
    "text": "regions so if you want to centralize all your cloud shell data in one region for easy query that's something that you can",
    "start": "947040",
    "end": "953520"
  },
  {
    "text": "do you can have if you have multiple accounts you can have the cloud trail logs for those separate accounts put in",
    "start": "953520",
    "end": "961410"
  },
  {
    "text": "one bucket and disallow deletes from your cloud trail bucket if you're looking to conserve space use the",
    "start": "961410",
    "end": "967140"
  },
  {
    "text": "lifecycle policy but nobody should need to go in and delete your security audit logs in the general case I would not be",
    "start": "967140",
    "end": "973680"
  },
  {
    "start": "973000",
    "end": "973000"
  },
  {
    "text": "a security engineer on the identity and access management team of it didn't talk about I am permissions so if you're just",
    "start": "973680",
    "end": "980130"
  },
  {
    "text": "getting started you want to you said oh hey I got a need to look through my cloud trail logs right now start an EMR",
    "start": "980130",
    "end": "985350"
  },
  {
    "text": "cluster with the default roles attached the cloud trail read only managed policy to the EMR easy to default instance role",
    "start": "985350",
    "end": "993890"
  },
  {
    "text": "later on if you want you can have you can take some lease privilege improvements by restricting that",
    "start": "993890",
    "end": "999360"
  },
  {
    "text": "clusters access to just the bucket and prefix where your cloud trail logs live and you can remove some of the other",
    "start": "999360",
    "end": "1006820"
  },
  {
    "text": "permissions that EMR has so let's actually look at the code that does the",
    "start": "1006820",
    "end": "1012320"
  },
  {
    "start": "1012000",
    "end": "1012000"
  },
  {
    "text": "heavy lifting here because I promised you we'd look at code so this is get cloud trail buckets and prefixes even",
    "start": "1012320",
    "end": "1019370"
  },
  {
    "text": "use my little pointer here what we're going to do is we're going to iterate over all of the AWS regions this is not",
    "start": "1019370",
    "end": "1026120"
  },
  {
    "text": "the region's that you're running in this is all of the Avis regions because we want to discover any place that you have Cloud trail logs and we are going to",
    "start": "1026120",
    "end": "1032630"
  },
  {
    "text": "find out where they are writing their cloud trail logs and put it in this trail set here and so mouse go so here's",
    "start": "1032630",
    "end": "1043189"
  },
  {
    "text": "where we're describing describing the trails are getting the trail list and we're gonna store it in that trail set",
    "start": "1043190",
    "end": "1049360"
  },
  {
    "text": "so if you if you run this in our classic regions expect an error when it hits gov",
    "start": "1049360",
    "end": "1054620"
  },
  {
    "text": "cloud when it hits the China region that's fine you can just ignore because there's no data there for you and then",
    "start": "1054620",
    "end": "1062150"
  },
  {
    "text": "we need to transform this cloud trail data so here's where we're actually pulling",
    "start": "1062150",
    "end": "1067490"
  },
  {
    "text": "in RAW cloud trail records they're just individual individual strings and then",
    "start": "1067490",
    "end": "1073760"
  },
  {
    "text": "you can see there in the middle we're going to use the jackson object mapper to go into that array pull out each",
    "start": "1073760",
    "end": "1081380"
  },
  {
    "text": "individual event from that array and we're gonna end up with a a and your",
    "start": "1081380",
    "end": "1089600"
  },
  {
    "text": "we're gonna end up with individual cloud trail events as JSON strings you can see",
    "start": "1089600",
    "end": "1094910"
  },
  {
    "text": "that persist calls a second from the bottom you might think that spark would when you when that was executed it would",
    "start": "1094910",
    "end": "1101930"
  },
  {
    "text": "go and read all your data and persist it in memory actually that's not going to happen and because spark is is lazy and",
    "start": "1101930",
    "end": "1107870"
  },
  {
    "text": "this is generally a good thing that persist operation operation isn't going to do anything until you read your data",
    "start": "1107870",
    "end": "1114170"
  },
  {
    "text": "the first time and after that that data will be stored in the clusters memory so you can query it a lot faster rather",
    "start": "1114170",
    "end": "1119960"
  },
  {
    "text": "than having to refetch it from s3 so now we need to register that cloud trail",
    "start": "1119960",
    "end": "1125600"
  },
  {
    "start": "1123000",
    "end": "1123000"
  },
  {
    "text": "data as a table so that we can query it so you can see on the second line there we're pulling in our raw Cloud Trail",
    "start": "1125600",
    "end": "1131870"
  },
  {
    "text": "logs the third line is the function that I just showed you which transform them into individual strings the fourth line",
    "start": "1131870",
    "end": "1139220"
  },
  {
    "text": "is where we feed it to the sequel context to the the JSON reader we are",
    "start": "1139220",
    "end": "1144650"
  },
  {
    "text": "going to again cache it to make sure that that data is readily available and we are going to register that data frame",
    "start": "1144650",
    "end": "1152810"
  },
  {
    "text": "as a temporary table in my examples it's it's a table name it's cloud trail and",
    "start": "1152810",
    "end": "1157840"
  },
  {
    "text": "we're going to return that data frame so what I showed you earlier was the the",
    "start": "1157840",
    "end": "1164750"
  },
  {
    "text": "spark SQL interface and the the JDBC interface and now we're going to look at",
    "start": "1164750",
    "end": "1171070"
  },
  {
    "text": "running those from the Scala prompt all",
    "start": "1171070",
    "end": "1176870"
  },
  {
    "text": "right this is one we looked at before so the code I'm the code that we are",
    "start": "1176870",
    "end": "1185270"
  },
  {
    "text": "releasing is in a github repo called timely security analytics off of a",
    "start": "1185270",
    "end": "1191570"
  },
  {
    "text": "Tobias labs and what's really nice about this is I've written this code so you can without even having to have",
    "start": "1191570",
    "end": "1197670"
  },
  {
    "text": "much knowledge of it you can take this code and drop it into the Scala prompt on your EMR cluster all the dependencies",
    "start": "1197670",
    "end": "1204870"
  },
  {
    "text": "it needs come with mr which is very helpful so so we're going to create a",
    "start": "1204870",
    "end": "1214260"
  },
  {
    "text": "data frame that we're going to call it cloud trail but that's a good name or whatever we want",
    "start": "1214260",
    "end": "1220460"
  },
  {
    "text": "so we're gonna call create table which is a function I showing you earlier we're going to pass the spark context which is how the spark context is the as",
    "start": "1225500",
    "end": "1233780"
  },
  {
    "text": "your codes interface to getting sparks to do distributed computing for you and we're going to pass a sequel context",
    "start": "1233780",
    "end": "1239990"
  },
  {
    "text": "which is again the interface that we use to register tables and what this is",
    "start": "1239990",
    "end": "1245960"
  },
  {
    "text": "going to do is this is now going to execute that code that goes out to all of the regions finds your cloud trail",
    "start": "1245960",
    "end": "1253010"
  },
  {
    "text": "logs those are those two errors I promise you one for gov cloud one for the China region I don't have any cloud",
    "start": "1253010",
    "end": "1258590"
  },
  {
    "text": "trail logs there and what we get in this",
    "start": "1258590",
    "end": "1264200"
  },
  {
    "text": "is our yarn interface and that query",
    "start": "1264200",
    "end": "1270320"
  },
  {
    "text": "from earlier is still running that's good that might be fun that might be fun when I try and dominate the the use of this",
    "start": "1270320",
    "end": "1277370"
  },
  {
    "text": "cluster in a couple minutes but we'll deal with it always something alright so we were in the spark shell so we can go",
    "start": "1277370",
    "end": "1284990"
  },
  {
    "text": "into the spark interface here and you can actually see here's that JSON",
    "start": "1284990",
    "end": "1290150"
  },
  {
    "text": "operation that was called from the console and let's see hey it worked awesome so now what you can do is you",
    "start": "1290150",
    "end": "1297650"
  },
  {
    "text": "can that cloud trail data frame you can say print schema and this will hopefully",
    "start": "1297650",
    "end": "1303740"
  },
  {
    "text": "look familiar from what we were looking at earlier so this is what I think is",
    "start": "1303740",
    "end": "1310549"
  },
  {
    "text": "just so cool about this so here's our event name our event source our event",
    "start": "1310549",
    "end": "1315980"
  },
  {
    "text": "time and what I think that is just so cool about this is no matter how your cloud trail log schema changes this",
    "start": "1315980",
    "end": "1324320"
  },
  {
    "text": "allows you to pull in pull in that data and spark is automatically going to figure out the schema and say hey",
    "start": "1324320",
    "end": "1330230"
  },
  {
    "text": "there's a field here that you can query and so let's actually what do we want to",
    "start": "1330230",
    "end": "1338270"
  },
  {
    "text": "do with this consult my notes all right so we've printed the schema and now",
    "start": "1338270",
    "end": "1343700"
  },
  {
    "text": "let's say we want to find so we saw that route was doing something earlier and we",
    "start": "1343700",
    "end": "1349100"
  },
  {
    "text": "know that we want to minimize route usage so let's actually run a query where we're saying you're saying select",
    "start": "1349100",
    "end": "1356690"
  },
  {
    "text": "distinct event source event name you identity a RN from our cloud trail logs where the accountant D equals the",
    "start": "1356690",
    "end": "1362840"
  },
  {
    "text": "principal ID which is a root user and you can see here that that is is getting",
    "start": "1362840",
    "end": "1369590"
  },
  {
    "text": "processed and if we go over to our here's actually that here's the SPARC",
    "start": "1369590",
    "end": "1378140"
  },
  {
    "text": "interface where you can see that that query just ran or it's trying to run Oh",
    "start": "1378140",
    "end": "1384070"
  },
  {
    "text": "odd probably because I was highlighting things who proved to you that that",
    "start": "1385340",
    "end": "1390740"
  },
  {
    "text": "worked what's cool is when you run this again again it's going to be streamlined",
    "start": "1390740",
    "end": "1396140"
  },
  {
    "text": "and so here's in these accounts and I was kind of intentionally not careful about using root usage you can see all",
    "start": "1396140",
    "end": "1403340"
  },
  {
    "text": "the different api's that are getting called with roots so if you wanted to drive down your root usage this is a",
    "start": "1403340",
    "end": "1408710"
  },
  {
    "text": "great tool for going and figuring out how it's being used and then you can go find out those individual use cases and",
    "start": "1408710",
    "end": "1416320"
  },
  {
    "text": "see what else we have here and let's look for let's figure out what IP",
    "start": "1416320",
    "end": "1421820"
  },
  {
    "text": "addresses are active so select distinct source IP address from cloud trail so",
    "start": "1421820",
    "end": "1428210"
  },
  {
    "text": "here's the list of IP addresses active in my account and I'm sure many of you will recognize what these are no way not",
    "start": "1428210",
    "end": "1433820"
  },
  {
    "text": "at all so you say hey ok well that's great but I really like to be able to do some sort of geoip look up on those IP",
    "start": "1433820",
    "end": "1441620"
  },
  {
    "text": "addresses and so some of the code that we are releasing today will allow you to",
    "start": "1441620",
    "end": "1447650"
  },
  {
    "text": "do exactly that so this code is going to register user-defined functions for",
    "start": "1447650",
    "end": "1455210"
  },
  {
    "text": "doing geoip lookups so we should be able to take our query by the way I should",
    "start": "1455210",
    "end": "1460670"
  },
  {
    "text": "have explained this earlier so we're saying sequel context SQL here's the SQL we want to run but if we",
    "start": "1460670",
    "end": "1467660"
  },
  {
    "text": "just say that sparks gonna go hey you haven't asked me to see any output yet so I'm not doing anything so we got to",
    "start": "1467660",
    "end": "1472880"
  },
  {
    "text": "call collect which will pull the data back to the driver and then for each element in the resulting array because",
    "start": "1472880",
    "end": "1480170"
  },
  {
    "text": "collect produces an array we're gonna print that output so now let's see",
    "start": "1480170",
    "end": "1485600"
  },
  {
    "text": "select distinct source IP address let's do country",
    "start": "1485600",
    "end": "1492730"
  },
  {
    "text": "if I didn't get any typos so this is gonna do is it's gonna do that same query and it's gonna go call those",
    "start": "1501390",
    "end": "1507330"
  },
  {
    "text": "user-defined functions to look up where in the world are those IP addresses and",
    "start": "1507330",
    "end": "1516720"
  },
  {
    "text": "I find this is very helpful because then you can see oh hey okay that that looks you know that looks normal that's a city",
    "start": "1516720",
    "end": "1522000"
  },
  {
    "text": "that I would expect oh hey that's from a different part of the world that we don't do any business there nobody was",
    "start": "1522000",
    "end": "1527100"
  },
  {
    "text": "traveling there you know that's concerning to me you'll have to believe",
    "start": "1527100",
    "end": "1536160"
  },
  {
    "text": "me that this worked just a couple minutes ago maybe let's see if we can",
    "start": "1536160",
    "end": "1548010"
  },
  {
    "text": "get spark to tell us what's going on so",
    "start": "1548010",
    "end": "1556740"
  },
  {
    "text": "what we see all we see in this interface is this is that collect job that's running there's 65 out of 266 are",
    "start": "1556740",
    "end": "1563760"
  },
  {
    "text": "complete and for whatever reason no more being completed I'm gonna quickly go",
    "start": "1563760",
    "end": "1572309"
  },
  {
    "text": "kill off that other spark job there that other so as if it's just sitting there",
    "start": "1572309",
    "end": "1581130"
  },
  {
    "text": "consuming cluster resources that's going to be a drag there it is reduce your",
    "start": "1581130",
    "end": "1597840"
  },
  {
    "text": "resource contention",
    "start": "1597840",
    "end": "1600710"
  },
  {
    "text": "you're gonna start over because I really want this to work because it's pretty",
    "start": "1607510",
    "end": "1613570"
  },
  {
    "text": "cool so you can actually see that was",
    "start": "1613570",
    "end": "1625630"
  },
  {
    "text": "the EMR cluster that we that we logged into and you just run the SPARC shell",
    "start": "1625630",
    "end": "1631080"
  },
  {
    "text": "the particular parameters that I'm passing to the SPARC shell arm increasing the number of executors to",
    "start": "1631080",
    "end": "1636909"
  },
  {
    "text": "two on each node because I want a little more processing capacity and I'm specifying forty executors so that spark",
    "start": "1636909",
    "end": "1645279"
  },
  {
    "text": "doesn't give me too few which sometimes happens let's start with our fancy code",
    "start": "1645279",
    "end": "1652110"
  },
  {
    "text": "I'm definitely using my cheat sheet cool",
    "start": "1655740",
    "end": "1663880"
  },
  {
    "text": "load up our tables and what's neat is",
    "start": "1663880",
    "end": "1670029"
  },
  {
    "text": "that you can combine lots of other data sources so one of the other data sources I'm not going to show today at least in",
    "start": "1670029",
    "end": "1675970"
  },
  {
    "text": "this demo is tour exit nodes so some of you may be saying oh I want all the",
    "start": "1675970",
    "end": "1682029"
  },
  {
    "text": "traffic to my aid abyss account to come from anonymizing proxies that sounds great you're part of an enterprise",
    "start": "1682029",
    "end": "1688139"
  },
  {
    "text": "someone's connecting to your a Davis account with poor I want to look into that I want to be a bit concerned and so",
    "start": "1688139",
    "end": "1698610"
  },
  {
    "text": "having that data available to you in an RDD that you can join against",
    "start": "1698610",
    "end": "1705179"
  },
  {
    "text": "and then will gave up on his demos entirely here we go when you can",
    "start": "1708539",
    "end": "1716830"
  },
  {
    "text": "actually see you in hey there we go so thank you for your patience I I don't",
    "start": "1716830",
    "end": "1726460"
  },
  {
    "text": "think you would have applauded giving me applause if it had just worked immediately so thank you thank you very",
    "start": "1726460",
    "end": "1732100"
  },
  {
    "text": "much well what's neat about this is now you can see hey where are these IP addresses you know Boardman Oregon in the United",
    "start": "1732100",
    "end": "1739179"
  },
  {
    "text": "States Dublin Ireland you'll see you'll note the presence of all eight of us",
    "start": "1739179",
    "end": "1744730"
  },
  {
    "text": "regions because I went through and turned on cloud trail in all my regions and that API call showed up in each of them the development for some of this",
    "start": "1744730",
    "end": "1752200"
  },
  {
    "text": "talk happened in Maine so you'll find a Maine in there somewhere so anyway you",
    "start": "1752200",
    "end": "1758350"
  },
  {
    "text": "can get some visibility into where those where those requests are coming from and",
    "start": "1758350",
    "end": "1764350"
  },
  {
    "text": "what I'm going to do now is kick off the streaming job that we're going to look",
    "start": "1764350",
    "end": "1770140"
  },
  {
    "text": "at in a little minute in a couple minutes so",
    "start": "1770140",
    "end": "1774269"
  },
  {
    "text": "so where are we in the talk we've looked at going back over historical cloud",
    "start": "1778470",
    "end": "1783539"
  },
  {
    "text": "trail data slice-and-dice it run expressive queries join with other data sources okay that's great but now what",
    "start": "1783539",
    "end": "1790289"
  },
  {
    "text": "if we want to process that cloud trail logs almost as soon as it's available in s3 how can we do that well we can use",
    "start": "1790289",
    "end": "1798259"
  },
  {
    "text": "spark streaming so what is spark streaming so I'm going to illustrate",
    "start": "1798259",
    "end": "1803659"
  },
  {
    "start": "1800000",
    "end": "1800000"
  },
  {
    "text": "what spark streaming is with the example of the application the second",
    "start": "1803659",
    "end": "1808710"
  },
  {
    "text": "application we're going to demo today which is you have a cloud trail SNS",
    "start": "1808710",
    "end": "1813750"
  },
  {
    "text": "topic so cloud trail is going to publish this topic saying hey I just dropped some new logs and your s3 bucket here's",
    "start": "1813750",
    "end": "1819299"
  },
  {
    "text": "the bucket here's the key I'm smoothing over a little detail here and that cloud trails gonna call an SNS topic I have an",
    "start": "1819299",
    "end": "1825480"
  },
  {
    "text": "SQ I have an sqs queue wired to that so I can have a bit of a buffer for when",
    "start": "1825480",
    "end": "1831240"
  },
  {
    "text": "this applications not running as I prepare for demos like this one but anyway anyways details there is a bit of",
    "start": "1831240",
    "end": "1838590"
  },
  {
    "text": "spark code called a receiver this is a very malleable interface but what this",
    "start": "1838590",
    "end": "1845190"
  },
  {
    "text": "does is you pull in data from Kinesis you pull and data from sqs you pull it",
    "start": "1845190",
    "end": "1850980"
  },
  {
    "text": "in from a TCP socket really whatever you want you can extend it and it's gonna",
    "start": "1850980",
    "end": "1856379"
  },
  {
    "text": "read data off the wire and in this case it's reading the the key and the the",
    "start": "1856379",
    "end": "1862529"
  },
  {
    "text": "object key and the bucket of the newly-arrived logs it's going to take that it's going to load up the",
    "start": "1862529",
    "end": "1867899"
  },
  {
    "text": "individual cloud trail events just like using the same transformation we saw in the previous previous code and then it's",
    "start": "1867899",
    "end": "1875070"
  },
  {
    "text": "going to take each individual cloud trail event and call the store operation and really what's going on under the",
    "start": "1875070",
    "end": "1880710"
  },
  {
    "text": "covers there is that that data is getting temporarily buffered into an RDD",
    "start": "1880710",
    "end": "1886320"
  },
  {
    "text": "a batch RTD so you can see in this example you have you have the receivers",
    "start": "1886320",
    "end": "1892350"
  },
  {
    "text": "storing to the enth batch in the the previous batch the N minus first batch is actually being processed right now",
    "start": "1892350",
    "end": "1899700"
  },
  {
    "text": "out on the individual executors so that n minus first batch represents new",
    "start": "1899700",
    "end": "1905159"
  },
  {
    "text": "activity that's shown up in your account we've been maintaining a previous profile of",
    "start": "1905159",
    "end": "1910780"
  },
  {
    "text": "that activity and in the the demo that we have today the profiles that we're keeping track of are what AR NS have we",
    "start": "1910780",
    "end": "1919360"
  },
  {
    "text": "seen active in the account so basically which users and roles have been active in the account as well as obviously the",
    "start": "1919360",
    "end": "1925060"
  },
  {
    "text": "root account we're keeping track of the city of origin of these requests doing",
    "start": "1925060",
    "end": "1931510"
  },
  {
    "text": "that source IP look up the country of origin as well and which access keys are",
    "start": "1931510",
    "end": "1937720"
  },
  {
    "text": "active because if you have an account that's at steady state and all and you've been running this streaming job",
    "start": "1937720",
    "end": "1943570"
  },
  {
    "text": "for a couple of weeks and all of a sudden access key comes active you might say hey maybe we should look into that",
    "start": "1943570",
    "end": "1949150"
  },
  {
    "text": "is that was I expecting somebody new to be active who hasn't been active in this account and you can extend this you can",
    "start": "1949150",
    "end": "1955180"
  },
  {
    "text": "you can build whatever profiles you want and so if that new activity does not match up with the previous profile we'll",
    "start": "1955180",
    "end": "1961930"
  },
  {
    "text": "send an alert back to SNS simple notification service and we will update",
    "start": "1961930",
    "end": "1967750"
  },
  {
    "text": "the profile so that we're not going to get duplicate entries so what sparks",
    "start": "1967750",
    "end": "1973090"
  },
  {
    "start": "1970000",
    "end": "1970000"
  },
  {
    "text": "gonna do spark operates on the concept sparks streaming operates in the concepts of micro batches it's going to",
    "start": "1973090",
    "end": "1978820"
  },
  {
    "text": "take the individual elements that are coming in and are gonna batch them up according not to a certain number of",
    "start": "1978820",
    "end": "1983890"
  },
  {
    "text": "elements but actually a certain amount of time that that data it's certain",
    "start": "1983890",
    "end": "1990580"
  },
  {
    "text": "amount of time and whatever data shows up and that time gets included in that micro batch it can be seconds it can be minutes whatever you need it to be in",
    "start": "1990580",
    "end": "1997030"
  },
  {
    "text": "order to process data the right unit of size and as quickly as you want so it's going to queue up these micro batches",
    "start": "1997030",
    "end": "2002280"
  },
  {
    "text": "you don't necessarily have to have the same number of events in every batch and then what you're gonna get each one of",
    "start": "2002280",
    "end": "2008310"
  },
  {
    "text": "these batches would be an RDD and that forms a discretized stream or a d-- stream this is the basic unit of work",
    "start": "2008310",
    "end": "2014730"
  },
  {
    "text": "for spark streaming application is that d-- stream and so our batch interval",
    "start": "2014730",
    "end": "2020640"
  },
  {
    "text": "here is three seconds and so you can see that as we go along so the recipe for",
    "start": "2020640",
    "end": "2025920"
  },
  {
    "text": "this spark streaming applications we're gonna have a cloud trail log receiver that's gonna learn about new logs from",
    "start": "2025920",
    "end": "2031860"
  },
  {
    "text": "SNS as they're delivered to s3 it's gonna take you to vent and store it and",
    "start": "2031860",
    "end": "2038940"
  },
  {
    "text": "then we're gonna analyze them in micro batches and we're gonna generate alarms on suspicious behavior",
    "start": "2038940",
    "end": "2044190"
  },
  {
    "text": "I actually have two different receivers in this code one receives new cloud trail logs that's one I've been",
    "start": "2044190",
    "end": "2049919"
  },
  {
    "text": "describing but I also have one called replay historical cloud trail log receiver so that you can start up this",
    "start": "2049919",
    "end": "2056368"
  },
  {
    "text": "application and have a and replay all the logs you've seen to date so you can",
    "start": "2056369",
    "end": "2061470"
  },
  {
    "text": "build up a nice profile rather than starting from scratch and trying to generate the behavior that you need in order to populate the profiles to a",
    "start": "2061470",
    "end": "2067710"
  },
  {
    "text": "steady-state so what are some scenarios that we want to know about as quickly as possible connections from unusual",
    "start": "2067710",
    "end": "2073319"
  },
  {
    "text": "geographies anonymizing proxies those dormant access keys and principles that I told you about earlier so let's look",
    "start": "2073319",
    "end": "2082260"
  },
  {
    "text": "at our streaming application",
    "start": "2082260",
    "end": "2086628"
  },
  {
    "text": "the streaming application is not nearly as exciting from from a command-line",
    "start": "2090340",
    "end": "2096580"
  },
  {
    "text": "perspective so sorry you're not going to get to look at black and white screens too much anymore but we will have in our",
    "start": "2096580",
    "end": "2104340"
  },
  {
    "text": "yarn interface now this is our good news",
    "start": "2104340",
    "end": "2114280"
  },
  {
    "text": "is I ran this earlier I already have a output that I can show you anyway yes so",
    "start": "2114280",
    "end": "2120280"
  },
  {
    "text": "what happened was is that since I had those two spark interfaces open that cloud troppo profiler wasn't able to run",
    "start": "2120280",
    "end": "2127000"
  },
  {
    "text": "yet so you'll actually get to see it starting which is kind of neat alright so what's this cloud trail profiler is",
    "start": "2127000",
    "end": "2134670"
  },
  {
    "text": "now running if we go into the streaming interface what you'll see here is not",
    "start": "2134670",
    "end": "2139900"
  },
  {
    "text": "much has happened we gotta wait at least 30 seconds for something interesting to happen but this is the streaming",
    "start": "2139900",
    "end": "2145480"
  },
  {
    "text": "interface that wasn't obviously available earlier because we weren't running a streaming job and what it's gonna be able to tell you is how quickly",
    "start": "2145480",
    "end": "2151390"
  },
  {
    "text": "data is arriving to your application as well as how quickly you're able to process it and how much data you're",
    "start": "2151390",
    "end": "2159160"
  },
  {
    "text": "processing the golden rule when it comes to spark streaming applications is you want to process data faster than it's",
    "start": "2159160",
    "end": "2165460"
  },
  {
    "text": "showing up otherwise you're gonna build up an internal backlog and so I strongly recommend if you're getting started with",
    "start": "2165460",
    "end": "2170530"
  },
  {
    "text": "spark streaming to throttle down the input rate using the receiver max rate",
    "start": "2170530",
    "end": "2175920"
  },
  {
    "text": "configuration option and this is gonna this is going to buy you some time to see how your application behaves I'm",
    "start": "2175920",
    "end": "2183040"
  },
  {
    "text": "sure some of you are really really good coders but if you're like me you don't write your most optimal code the first time around so don't you know you'll",
    "start": "2183040",
    "end": "2190150"
  },
  {
    "text": "it's it's really depressing like nothing's happening in my spark streaming applications so yeah because you just tried to eat the whole elephant",
    "start": "2190150",
    "end": "2196210"
  },
  {
    "text": "at once and so what you can see here now we have we've actually seen some input",
    "start": "2196210",
    "end": "2202240"
  },
  {
    "text": "we're getting to see the average rate of that input and here those two streams",
    "start": "2202240",
    "end": "2208840"
  },
  {
    "text": "one of these receivers I believe it's actually the the first receiver is the",
    "start": "2208840",
    "end": "2214030"
  },
  {
    "text": "replay existing cloud row logs receiver and the second one is going to be",
    "start": "2214030",
    "end": "2220000"
  },
  {
    "text": "pulling in new cloud trail logs now when you're doing building a spark streaming application you want to be",
    "start": "2220000",
    "end": "2226230"
  },
  {
    "text": "looking at the scheduling delay this is how long does it take when when the",
    "start": "2226230",
    "end": "2231240"
  },
  {
    "text": "receiver has stored and created a micro batch how long does it take for that micro batch to actually get processed",
    "start": "2231240",
    "end": "2238010"
  },
  {
    "text": "that scheduling delay should be pretty small less than a couple of seconds it's",
    "start": "2238010",
    "end": "2243090"
  },
  {
    "text": "fine if it blips up occasionally that scheduled delay is creeping up and up and up that means you're not able to",
    "start": "2243090",
    "end": "2248520"
  },
  {
    "text": "process data as quickly as it's arriving in your system and so you get to see the",
    "start": "2248520",
    "end": "2254250"
  },
  {
    "text": "the processing time here our average processing time is you know two seconds you get a nice little graph now let's",
    "start": "2254250",
    "end": "2260310"
  },
  {
    "text": "see if we were here we've actually completed some batches so far and so the",
    "start": "2260310",
    "end": "2265410"
  },
  {
    "text": "first batch we had 14 events and then we're gonna we're gonna roughly about 90 when the application first starts it's",
    "start": "2265410",
    "end": "2272400"
  },
  {
    "text": "going to be pulling in it's going to be pulling in the queued up cloud trail logs that have arrived and not yet been",
    "start": "2272400",
    "end": "2279990"
  },
  {
    "text": "processed since the last time I ran it and let's actually see some of the results here so if we go over to I'm",
    "start": "2279990",
    "end": "2286230"
  },
  {
    "text": "feeding these SNF I'm feeding the alerts to S&S and then SNS is publishing them to log Li and so",
    "start": "2286230",
    "end": "2294780"
  },
  {
    "text": "here's my log Li interface let's search for the last hour and hey we've seen",
    "start": "2294780",
    "end": "2300210"
  },
  {
    "text": "some events that have occurred and let's look at what these are",
    "start": "2300210",
    "end": "2305780"
  },
  {
    "text": "and so here's we've got a cloud trail profile mismatch for the city that the",
    "start": "2306500",
    "end": "2313440"
  },
  {
    "text": "source IP address corresponds to the country that corresponds to hey there's",
    "start": "2313440",
    "end": "2318510"
  },
  {
    "text": "an anonymizing proxy in use with my account that might be something that that I want to look into and so let's",
    "start": "2318510",
    "end": "2325290"
  },
  {
    "text": "actually pull up those",
    "start": "2325290",
    "end": "2328490"
  },
  {
    "text": "to make this a little more readable all right so when we're looking at here's",
    "start": "2332130",
    "end": "2337390"
  },
  {
    "text": "the here's an SNS notification for that anonymizing proxy in use and so the so",
    "start": "2337390",
    "end": "2349300"
  },
  {
    "text": "you can see your here's the message there's activity on your database resources that we've seen coming from this IP address which is a tor exit node",
    "start": "2349300",
    "end": "2356440"
  },
  {
    "text": "for those who are not familiar with tor tor publishes a list of its exit nodes",
    "start": "2356440",
    "end": "2362530"
  },
  {
    "text": "which are the where the traffic is moving through the anonymizing proxy network and actually leaves out on to",
    "start": "2362530",
    "end": "2368740"
  },
  {
    "text": "the broader Internet to its ultimate destination which in this case is AWS publishes that list of exit nodes and so",
    "start": "2368740",
    "end": "2375160"
  },
  {
    "text": "you can consume and that's what we're doing here so when we start the streaming application it goes downloads a copy of that exit node list and then",
    "start": "2375160",
    "end": "2382839"
  },
  {
    "text": "goes and looks up the source IP addresses that it sees one of the areas for improvement for this application is",
    "start": "2382839",
    "end": "2388720"
  },
  {
    "text": "to refresh that list occasionally because it changes periodically and so",
    "start": "2388720",
    "end": "2394270"
  },
  {
    "text": "let's look at the see if we've gotten some alerts about the country of origin",
    "start": "2394270",
    "end": "2401070"
  },
  {
    "text": "all right so we have some new activity which didn't fit the current profile we tell you what the current profile is the",
    "start": "2403560",
    "end": "2410589"
  },
  {
    "text": "current profile is the United States Japan Singapore unknown in Germany I can't look up all the IP addresses so you do have unknown",
    "start": "2410589",
    "end": "2416619"
  },
  {
    "text": "and so we've seen some activity from Australia that we did not expect when you first run this application and",
    "start": "2416619",
    "end": "2421869"
  },
  {
    "text": "you're replaying all your logs you start from an empty state and so these first couple you may want to ignore and then",
    "start": "2421869",
    "end": "2426970"
  },
  {
    "text": "as it's a steady state you're going to be able to you're gonna the alerts will be more meaningful and so let's look at",
    "start": "2426970",
    "end": "2435880"
  },
  {
    "text": "the city information come on Mowgli",
    "start": "2435880",
    "end": "2442220"
  },
  {
    "text": "I wait log Li interfaces awesome cool so",
    "start": "2442220",
    "end": "2448970"
  },
  {
    "text": "in this case we've done the the geoip look up in that IP IP address it was",
    "start": "2448970",
    "end": "2455180"
  },
  {
    "text": "coming from dublin and if you want to look at AR ends users in your account",
    "start": "2455180",
    "end": "2463930"
  },
  {
    "text": "turn off our patience is not one of my",
    "start": "2464109",
    "end": "2471290"
  },
  {
    "text": "virtues alright so now you can see here",
    "start": "2471290",
    "end": "2476330"
  },
  {
    "text": "we have a activity for this role that the role session name was Isengard",
    "start": "2476330",
    "end": "2483619"
  },
  {
    "text": "auditor role and it did not match the previous profile and you can see here",
    "start": "2483619",
    "end": "2490010"
  },
  {
    "text": "that we've actually been building up a profile of so here's the current",
    "start": "2490010",
    "end": "2495890"
  },
  {
    "text": "activity and then below here's the here's the full profile so you can see we're building up these profiles we're",
    "start": "2495890",
    "end": "2502040"
  },
  {
    "text": "comparing the data as we go along let's see if there's been any new data just",
    "start": "2502040",
    "end": "2507650"
  },
  {
    "text": "for kicks",
    "start": "2507650",
    "end": "2510609"
  },
  {
    "text": "all right cool so now we have a new alert streaming in so you'll get these periodically again it'll reach a reaches",
    "start": "2514060",
    "end": "2520930"
  },
  {
    "text": "steady state and I want to go back to",
    "start": "2520930",
    "end": "2529120"
  },
  {
    "text": "that spark in her face once more so you can actually see what we're looking at",
    "start": "2529120",
    "end": "2536440"
  },
  {
    "text": "here and so we've throttled this to three events per second which is why",
    "start": "2536440",
    "end": "2541930"
  },
  {
    "text": "you're seeing this magic number and you can see as we're replaying these logs it's storing them at roughly three",
    "start": "2541930",
    "end": "2549040"
  },
  {
    "text": "events per second we've got very little scheduling delay so we're happy we're happy with this and depending on the",
    "start": "2549040",
    "end": "2555460"
  },
  {
    "text": "size of your depending on the size of your account and the amount of activity one nice things about spark both with",
    "start": "2555460",
    "end": "2562180"
  },
  {
    "text": "the batch processing and the streaming is you can scale out to be as many or as few nodes as you want you can have more",
    "start": "2562180",
    "end": "2568450"
  },
  {
    "text": "memory intensive nodes you can have more compute intensive nodes whatever you need to do the type of processing so you",
    "start": "2568450",
    "end": "2575410"
  },
  {
    "text": "know what I'm showing you here is it's it's horizontally scalable and that's one of the things that we really like is",
    "start": "2575410",
    "end": "2580870"
  },
  {
    "text": "we're doing this type of analysis and processing",
    "start": "2580870",
    "end": "2585480"
  },
  {
    "text": "so let's actually look at the code Wow",
    "start": "2590510",
    "end": "2595840"
  },
  {
    "text": "let's actually look at the code that does this work so this is the Scala code that is going to create what's called",
    "start": "2598810",
    "end": "2605210"
  },
  {
    "start": "2599000",
    "end": "2599000"
  },
  {
    "text": "the streaming context which is then going to continually process information I apologize for the I test what we're",
    "start": "2605210",
    "end": "2613790"
  },
  {
    "text": "gonna do here on the on this this third line is we're going to create a new streaming context we're gonna specify",
    "start": "2613790",
    "end": "2620780"
  },
  {
    "text": "the batch interval which in this case is 30 seconds but it's config driven so that's what it's that config line there",
    "start": "2620780",
    "end": "2627920"
  },
  {
    "text": "and then we are going to what's called establish a checkpoint checkpoint path",
    "start": "2627920",
    "end": "2635180"
  },
  {
    "text": "so as the streaming application is running it's going to write out its state to this path so that if the",
    "start": "2635180",
    "end": "2642500"
  },
  {
    "text": "application crashes maybe the master node goes bad you can you can restart",
    "start": "2642500",
    "end": "2648200"
  },
  {
    "text": "the application and restore the existing state that's the motivation behind checkpointing and then we are going to",
    "start": "2648200",
    "end": "2657380"
  },
  {
    "text": "initialize all our profilers which is not meaningful except for the tour",
    "start": "2657380",
    "end": "2663320"
  },
  {
    "text": "profile which actually has to go out pull the exit node list and keep that in memory then we're going to see the d",
    "start": "2663320",
    "end": "2673220"
  },
  {
    "text": "stream this is where we're actually creating the D stream and this create D stream function it it it creates each of",
    "start": "2673220",
    "end": "2679100"
  },
  {
    "text": "the individual receivers passes the config so they know where to get their input and then unions the output to be a",
    "start": "2679100",
    "end": "2684590"
  },
  {
    "text": "single D stream that we can then we can then operate on and then we're gonna",
    "start": "2684590",
    "end": "2692150"
  },
  {
    "text": "create our initial state which is initially empty I guess if you wanted to if you had a certain amount of initial",
    "start": "2692150",
    "end": "2697910"
  },
  {
    "text": "State cash you could feed that in here and then we are gonna we're gonna",
    "start": "2697910",
    "end": "2703460"
  },
  {
    "text": "establish the specific processing of those cloud trail events as they as they",
    "start": "2703460",
    "end": "2709700"
  },
  {
    "text": "show up and we're gonna get this state D stream and then we're actually going to output this D stream so a little bit of",
    "start": "2709700",
    "end": "2716720"
  },
  {
    "text": "a spark spark streaming tip here is that you have to do something with that D",
    "start": "2716720",
    "end": "2722420"
  },
  {
    "text": "store if to write it out to s3 you have to pull the results of say your profilers",
    "start": "2722420",
    "end": "2728520"
  },
  {
    "text": "in their current States you have to do something otherwise spark application will say hey you haven't done anything interesting with this and it's not",
    "start": "2728520",
    "end": "2734070"
  },
  {
    "text": "enough to just omit an SNS event the thank you very much it's not enough to",
    "start": "2734070",
    "end": "2742110"
  },
  {
    "text": "omit just in an SNS event because spark doesn't know that that was an output of your application and so in our case this",
    "start": "2742110",
    "end": "2749070"
  },
  {
    "text": "outputs state status of profilers and profiles is going to put to the standard",
    "start": "2749070",
    "end": "2754770"
  },
  {
    "text": "out of the application hey I've been running these profiles I've built them up these profiles I've",
    "start": "2754770",
    "end": "2760440"
  },
  {
    "text": "built up these profiles I've sent this many alerts and so let's look at our how",
    "start": "2760440",
    "end": "2766560"
  },
  {
    "text": "we're going to compare to that old and new profile so what we're doing is we're",
    "start": "2766560",
    "end": "2771900"
  },
  {
    "text": "looking to see if the new activity is a subset so remember I said that there's a whole bunch of built-in high-level",
    "start": "2771900",
    "end": "2778170"
  },
  {
    "text": "operators so you don't have to go out and implement them yourself in spark so you can just say hey is this a subset of",
    "start": "2778170",
    "end": "2784980"
  },
  {
    "text": "this this other r2d this other set and so we're going to look and see if the",
    "start": "2784980",
    "end": "2791310"
  },
  {
    "text": "new activity is a subset of this the previous activity that's in our profile if it is fine great if it isn't we're",
    "start": "2791310",
    "end": "2798690"
  },
  {
    "text": "gonna send out an alert and we're going to update that profile and so here here",
    "start": "2798690",
    "end": "2806040"
  },
  {
    "text": "we are we've shown you the we've demoed this spark streaming application we've shown you the the output in log Li of",
    "start": "2806040",
    "end": "2813360"
  },
  {
    "text": "the SNS messages that it is emitting we've looked at the code that actually gets us here and so we're going to wrap",
    "start": "2813360",
    "end": "2820050"
  },
  {
    "start": "2820000",
    "end": "2820000"
  },
  {
    "text": "up so in terms of actually going and using these tools the first thing you need to do consummate security engineer",
    "start": "2820050",
    "end": "2827130"
  },
  {
    "text": "and recommending that you do a threat model you have to understand what what's important to you what are the what are",
    "start": "2827130",
    "end": "2832920"
  },
  {
    "text": "the what are the risks that you're worried about or if you have people traveling all over the globe getting an",
    "start": "2832920",
    "end": "2838410"
  },
  {
    "text": "alarm every time somebody goes to a new city may not be very meaningful to you but if you only do business in a certain",
    "start": "2838410",
    "end": "2843720"
  },
  {
    "text": "region and it is really important to you that you're keeping track of whether anybody's connecting from far-flung",
    "start": "2843720",
    "end": "2849780"
  },
  {
    "text": "places that may be an alert that is as interesting so build that her model figure out what's important you take",
    "start": "2849780",
    "end": "2855480"
  },
  {
    "text": "this application can figure it and customize it to your needs based on that threat model they used the",
    "start": "2855480",
    "end": "2861660"
  },
  {
    "text": "spark on EMR application I showed you for that ad hoc log analysis and then the streaming code to do regular",
    "start": "2861660",
    "end": "2868570"
  },
  {
    "text": "analysis and sends alerts I use these tools to keep my engineering teams honest you can see you know hey you've",
    "start": "2868570",
    "end": "2876190"
  },
  {
    "text": "been doing you know what hey why'd you why'd you call I am why'd you make that you know add something the other day they said oh I created this I am user in",
    "start": "2876190",
    "end": "2883600"
  },
  {
    "text": "in an account where they weren't supposed to be doing that and I said you know hey what were you doing I got this alert that you're creating an IM user",
    "start": "2883600",
    "end": "2890470"
  },
  {
    "text": "and he says i was just trying to get something to work I didn't understand I said okay well let me actually dig in on",
    "start": "2890470",
    "end": "2895660"
  },
  {
    "text": "the specific you know issue that you're having let's go delete that I am user and so we were able to jump on that pretty quickly you know and so obviously",
    "start": "2895660",
    "end": "2904360"
  },
  {
    "text": "that's that example of the non-compliant usage I want to see who's active in my account I actually had a very pleasant",
    "start": "2904360",
    "end": "2909520"
  },
  {
    "text": "surprise when I was using this on some of my internal accounts like hey look the AWS security team is actually using",
    "start": "2909520",
    "end": "2918100"
  },
  {
    "text": "their auditor role in my account to go and make sure that my security groups are configured properly that there have",
    "start": "2918100",
    "end": "2927760"
  },
  {
    "text": "a reasonable I am configuration and that was actually a pleasant surprise and if I hadn't had this and I hadn't been",
    "start": "2927760",
    "end": "2933760"
  },
  {
    "text": "going through I wouldn't have noticed I wouldn't have known that they were doing that so that was actually you know really nice to see another way that you",
    "start": "2933760",
    "end": "2940810"
  },
  {
    "text": "can use these tools is let's say you have a user they have maybe I am star let's pick on the I am service and you",
    "start": "2940810",
    "end": "2947560"
  },
  {
    "text": "want to restrict their access to just the I am permissions that they use but",
    "start": "2947560",
    "end": "2952720"
  },
  {
    "text": "you don't know which that you don't know which they use you ask them well you know I'm not really sure I just use the iron console since all I am activity API",
    "start": "2952720",
    "end": "2961450"
  },
  {
    "text": "activity ends up in the ends up in cloud trail you can actually go in and pull a",
    "start": "2961450",
    "end": "2968050"
  },
  {
    "text": "list of here's the API is that this user calls maybe even here's the resources that they're calling it on and then you",
    "start": "2968050",
    "end": "2974350"
  },
  {
    "text": "could use that to inform a lease privilege policy for that user so in",
    "start": "2974350",
    "end": "2979960"
  },
  {
    "text": "terms of whether it's your call to action go see who's active in your a dovish account and when what are they",
    "start": "2979960",
    "end": "2985210"
  },
  {
    "text": "doing might also be interesting to see who's active in your account and off right that would be I just thought of",
    "start": "2985210",
    "end": "2990780"
  },
  {
    "text": "that one run queries over your logs in the Ammar process the data as it streams",
    "start": "2990780",
    "end": "2995880"
  },
  {
    "text": "into your application you can use that QR code it's just it's it's it's not to anything special other than the you know",
    "start": "2995880",
    "end": "3002780"
  },
  {
    "text": "the github link there so you know go to that github repo pull out the code make",
    "start": "3002780",
    "end": "3008810"
  },
  {
    "text": "it your own do interesting things with it and that's it if anybody has any",
    "start": "3008810",
    "end": "3014210"
  },
  {
    "text": "questions you can ask them now or we can talk about a mountain long haul afterwards",
    "start": "3014210",
    "end": "3020320"
  }
]
[
  {
    "text": "hello hi everyone thank you for joining us today um I am Rob Parish the director of",
    "start": "1520",
    "end": "9200"
  },
  {
    "text": "product management at Treasure data um and we're excited to speak with you",
    "start": "9200",
    "end": "14559"
  },
  {
    "text": "about our latest open source project digdag a new solution for workflow",
    "start": "14559",
    "end": "20640"
  },
  {
    "text": "management um first before diving in um I'm going to briefly tell you a bit",
    "start": "20640",
    "end": "25880"
  },
  {
    "text": "about where s and I come from uh treasure data so treasure data is a serc company with",
    "start": "25880",
    "end": "33000"
  },
  {
    "text": "hundreds of customers worldwide we just launched a new category called live data",
    "start": "33000",
    "end": "38840"
  },
  {
    "text": "management our goal is to help you make all your customer data connected current",
    "start": "38840",
    "end": "45160"
  },
  {
    "text": "and easily accessible to the people and algorithms that drive your business with",
    "start": "45160",
    "end": "51160"
  },
  {
    "text": "it our platform provides a suite of technology and applications that help you to unify disperate data sources",
    "start": "51160",
    "end": "58079"
  },
  {
    "text": "perform Advanced Analytics and take action on those analytic insights",
    "start": "58079",
    "end": "63399"
  },
  {
    "text": "operationalizing them into your business uh we are a strong contributor",
    "start": "63399",
    "end": "69080"
  },
  {
    "text": "to the data and analytics open source Community uh the projects listed here in the middle are the ones that we either",
    "start": "69080",
    "end": "75280"
  },
  {
    "text": "created such as fluent D ulk and message pack or contribute to such as",
    "start": "75280",
    "end": "82520"
  },
  {
    "text": "Presto um and we work great with Amazon web services the majority of our customers run core aspects of their",
    "start": "82520",
    "end": "89439"
  },
  {
    "text": "business on on AWS and together we integrate seamlessly um with our analytic solution um for these",
    "start": "89439",
    "end": "97479"
  },
  {
    "text": "customers so on to our core topic for today I suspect many of you in the",
    "start": "97479",
    "end": "103880"
  },
  {
    "text": "audience are responsible for managing a modern analytics uh application or",
    "start": "103880",
    "end": "108960"
  },
  {
    "text": "looking to build one um applications ranging from marketing campaign optimizations personalizations churn",
    "start": "108960",
    "end": "116000"
  },
  {
    "text": "analysis churn detection um these are projects that will likely utilize key parts of the AWS ecosystem I'm shown",
    "start": "116000",
    "end": "123360"
  },
  {
    "text": "here from the S3 Object Store to redshift as your team's analytic data warehouse EMR for data preparation um or",
    "start": "123360",
    "end": "131360"
  },
  {
    "text": "machine learning and Spark and Aurora as your application's back end um and when",
    "start": "131360",
    "end": "136519"
  },
  {
    "text": "you begin to build uh you start with a series of scripts and SQL maybe you use",
    "start": "136519",
    "end": "142080"
  },
  {
    "text": "cron jobs to automate the processing and handle dependencies but pretty quickly even for small and mediumsized teams the",
    "start": "142080",
    "end": "149400"
  },
  {
    "text": "system quickly becomes very complex to manage um some issues that people see",
    "start": "149400",
    "end": "155519"
  },
  {
    "text": "cron scheduled scripts running in an unexpected order handling errors become complex as it's hard to determine where",
    "start": "155519",
    "end": "162720"
  },
  {
    "text": "you start where to start your analytic flows um logging happens across multiple different environments um and so making",
    "start": "162720",
    "end": "170239"
  },
  {
    "text": "debugging a big pain um and then collaboration becomes complex uh particularly when bringing on new team",
    "start": "170239",
    "end": "176480"
  },
  {
    "text": "members in large part because the overall flow and an association between tasks is",
    "start": "176480",
    "end": "182920"
  },
  {
    "text": "unclear um and of course that's why many people have started to use workflows um to manage as a core part of managing",
    "start": "182920",
    "end": "189959"
  },
  {
    "text": "their analytics processing system um in short uh for an introduction a workflow",
    "start": "189959",
    "end": "195599"
  },
  {
    "text": "is a way to define a separate processing recipe from the underlying details those",
    "start": "195599",
    "end": "200840"
  },
  {
    "text": "details include the code the environment the data um and in do in doing so it",
    "start": "200840",
    "end": "205879"
  },
  {
    "text": "provides a high level of abstraction of the overall process being completed as",
    "start": "205879",
    "end": "211640"
  },
  {
    "text": "well as a record of what environment that process was completed within um in the hypothetical example you see here",
    "start": "211640",
    "end": "218920"
  },
  {
    "text": "this workflow is orchestrating a chain of dependencies um across four different systems from left to right um it's",
    "start": "218920",
    "end": "226080"
  },
  {
    "text": "important to note that the processing is not happening in the workflow engine it's only orchestrating the processing",
    "start": "226080",
    "end": "231599"
  },
  {
    "text": "and data flows that occur elsewhere uh a common workflow may",
    "start": "231599",
    "end": "236799"
  },
  {
    "text": "involve these steps first you have to ingest data such as application logs or add Impressions uh you enrich and clean",
    "start": "236799",
    "end": "244480"
  },
  {
    "text": "that data uh removing bot access uh adding Geo information to IP addresses",
    "start": "244480",
    "end": "250519"
  },
  {
    "text": "uh then you likely produce a model based on that data some analytic Insight um",
    "start": "250519",
    "end": "256479"
  },
  {
    "text": "which could be the results of an AB test segmentation analysis um or otherwise um",
    "start": "256479",
    "end": "262360"
  },
  {
    "text": "and then finally you want to load those insights back into your production systems so that you can utilize those",
    "start": "262360",
    "end": "267800"
  },
  {
    "text": "insights for your product or system um for a more specific example",
    "start": "267800",
    "end": "273759"
  },
  {
    "text": "let's say you wanted to utilize data from your web logs a production database and marketing campaign data uh bring it",
    "start": "273759",
    "end": "281000"
  },
  {
    "text": "together in S3 clean and process it through EMR uh prepare data sets in red shift",
    "start": "281000",
    "end": "288320"
  },
  {
    "text": "that then your data science teams will use to run analysis build models that",
    "start": "288320",
    "end": "293400"
  },
  {
    "text": "may result in recommendations ready to be accessed for your customers of what um items in the shopping cart or items",
    "start": "293400",
    "end": "300600"
  },
  {
    "text": "they used to have in the shopping cart that you want to recommend or other products they may want to buy uh this can be quite a complex process to manage",
    "start": "300600",
    "end": "308360"
  },
  {
    "text": "um and you want to update it regularly so the recommendation is as fresh as",
    "start": "308360",
    "end": "313800"
  },
  {
    "text": "possible um to ad to manage exactly this type of flow uh we created the open",
    "start": "313800",
    "end": "319639"
  },
  {
    "text": "source project digdag um digdag is a workflow engine designed for Simplicity",
    "start": "319639",
    "end": "325199"
  },
  {
    "text": "extensibility um and multi-platform support it's language agnostic so",
    "start": "325199",
    "end": "330400"
  },
  {
    "text": "application developers data scientists data Engineers with different tools",
    "start": "330400",
    "end": "335560"
  },
  {
    "text": "chains and needs can use a single unified workflow engine and it's very",
    "start": "335560",
    "end": "340880"
  },
  {
    "text": "easy to get started you download your B the binary and you can get started immediately on your local machine um but",
    "start": "340880",
    "end": "347680"
  },
  {
    "text": "setting up server mode and running workflows in the cloud is quite easy as",
    "start": "347680",
    "end": "352960"
  },
  {
    "text": "well um one treasure Data customer uh that is using digdag for the workflow",
    "start": "352960",
    "end": "358240"
  },
  {
    "text": "management is packlink um packlink is an online platform providing coste effective package delivery Solutions in",
    "start": "358240",
    "end": "365280"
  },
  {
    "text": "Europe and internationally they've turned to digdag to help them manage their analytics processing flow shown",
    "start": "365280",
    "end": "371800"
  },
  {
    "text": "below um every part of the diagram that's represented in yellow so the bulk ETL the cleanup um analytic steps",
    "start": "371800",
    "end": "380400"
  },
  {
    "text": "deployment of those insights are managed by packlink using digdag um hosted by treasure data um and you can see that",
    "start": "380400",
    "end": "387759"
  },
  {
    "text": "based on the systems that the workflow um operates against um they are focused in large part on delivering value to",
    "start": "387759",
    "end": "394440"
  },
  {
    "text": "their sales and marketing teams uh for personalized marketing campaigns and optimizing sales",
    "start": "394440",
    "end": "400440"
  },
  {
    "text": "performance um Pierre uh pack Link's head of business intelligence uh put it",
    "start": "400440",
    "end": "405759"
  },
  {
    "text": "this way um using digdag I now feel confident in my ability to manage complex analytic flows from ETL",
    "start": "405759",
    "end": "413080"
  },
  {
    "text": "processes to transferring data to analytic steps for running attribution of Cort analysis to deploying those",
    "start": "413080",
    "end": "419199"
  },
  {
    "text": "insight back into the cloud systems my my company uses to run our business it's",
    "start": "419199",
    "end": "424599"
  },
  {
    "text": "enabled us to get out of refreshes of those insights more timely for our analytic consumers sales marketing and",
    "start": "424599",
    "end": "431039"
  },
  {
    "text": "the Executive Suite I now feel confident each night our analysis will be completed as",
    "start": "431039",
    "end": "436720"
  },
  {
    "text": "expected uh so with that it's now my pleasure to introduce Sada um to go into",
    "start": "436720",
    "end": "441960"
  },
  {
    "text": "more details about digdag and how to use it okay thank you um thank you for coming here and",
    "start": "441960",
    "end": "449639"
  },
  {
    "text": "thank you for being interested in this system dig my name is Sada Sashi one of the co-founders of this",
    "start": "449639",
    "end": "457160"
  },
  {
    "text": "company to data um I'm working for this company to build the uh cloud-based data",
    "start": "457160",
    "end": "462879"
  },
  {
    "text": "housing solution as a service and ETF Frameworks around it and also the connectivity to uh the data sources",
    "start": "462879",
    "end": "469840"
  },
  {
    "text": "around it I'm also a open source hacker actually I built these tools as a Open",
    "start": "469840",
    "end": "476879"
  },
  {
    "text": "Source Products uh you may already know about them uh message pack is a binary",
    "start": "476879",
    "end": "483319"
  },
  {
    "text": "based data object solarization system so it's like Json but it's binary based so",
    "start": "483319",
    "end": "488800"
  },
  {
    "text": "faster and more compact um it's used in like uh mobile applications or some major mobile um",
    "start": "488800",
    "end": "495560"
  },
  {
    "text": "messaging applications so you PS are using it currently and fendy is a data",
    "start": "495560",
    "end": "502400"
  },
  {
    "text": "collection system which is used in like sensors and also the cloud platforms",
    "start": "502400",
    "end": "507440"
  },
  {
    "text": "actually this is a part of Google's Cloud platform one so you are also prob probably using",
    "start": "507440",
    "end": "512719"
  },
  {
    "text": "it so um I think current question is that why we created bdag even though",
    "start": "512719",
    "end": "520320"
  },
  {
    "text": "they are open source tools and also similar uh commercial tools as well a short answer is that uh they did",
    "start": "520320",
    "end": "527920"
  },
  {
    "text": "not mat with our requirements uh specifically um there",
    "start": "527920",
    "end": "533640"
  },
  {
    "text": "are three problems actually one is that uh whenever we create a workflow and change it the",
    "start": "533640",
    "end": "541560"
  },
  {
    "text": "result of the uh result of the workflow will change of course however uh because",
    "start": "541560",
    "end": "546800"
  },
  {
    "text": "there there were no change logs of the workflow uh we could not track why that",
    "start": "546800",
    "end": "553120"
  },
  {
    "text": "happened so one problem was that uh one day a daily report",
    "start": "553120",
    "end": "558720"
  },
  {
    "text": "changed a value spiked it was good be but because it shows beta value but we",
    "start": "558720",
    "end": "565480"
  },
  {
    "text": "couldn't find why it happened actually the problem was a bag",
    "start": "565480",
    "end": "570640"
  },
  {
    "text": "in the workflow that may happen because the workflow become very complicated but because of lack of the change logs we",
    "start": "570640",
    "end": "577000"
  },
  {
    "text": "could not find that very quickly so it was a pain for the workflow",
    "start": "577000",
    "end": "582880"
  },
  {
    "text": "management another problem is that uh the the workflow itself depends on a",
    "start": "582880",
    "end": "589120"
  },
  {
    "text": "server's environment a lot so one day a um machine learning script wanted to use",
    "start": "589120",
    "end": "596640"
  },
  {
    "text": "some libraries like python pandas npy that's good so yeah we installed the system uh we",
    "start": "596640",
    "end": "602720"
  },
  {
    "text": "installed the packages on the server and the workflow worked on that b and we needed to upgrade the system",
    "start": "602720",
    "end": "611200"
  },
  {
    "text": "but of course they depends on the particular versions of the libraries and depends on some other components",
    "start": "611200",
    "end": "617600"
  },
  {
    "text": "installed in the server so it was T tough to upgrade the system plus",
    "start": "617600",
    "end": "623079"
  },
  {
    "text": "whenever you want to run the workflow on your machine or actually my machine uh I",
    "start": "623079",
    "end": "628160"
  },
  {
    "text": "needed to prepare everything on my machine it's tough and which means that uh only one person or several persons",
    "start": "628160",
    "end": "634760"
  },
  {
    "text": "can can join the development of workflow so it it uh it prevents us to from",
    "start": "634760",
    "end": "642440"
  },
  {
    "text": "having more collaboration between the data analy data engineers and marketing",
    "start": "642440",
    "end": "649000"
  },
  {
    "text": "actually and the other problem is that uh the scripts get uh getting harder and",
    "start": "649000",
    "end": "655000"
  },
  {
    "text": "harder to understand um so one example that uh",
    "start": "655000",
    "end": "660240"
  },
  {
    "text": "actually one uh our customers and also us we we are using some other workflows",
    "start": "660240",
    "end": "666079"
  },
  {
    "text": "actually and they were written in uh enter Pon sprs",
    "start": "666079",
    "end": "671279"
  },
  {
    "text": "and the as we add more steps or tasks there it became harder to",
    "start": "671279",
    "end": "678079"
  },
  {
    "text": "understand and there are many many tasks actually hundreds of tasks depending on",
    "start": "678079",
    "end": "683480"
  },
  {
    "text": "each other so uh without having like modulability or actually simpler",
    "start": "683480",
    "end": "689839"
  },
  {
    "text": "interface to understand that it became harder and harder to",
    "start": "689839",
    "end": "695200"
  },
  {
    "text": "understand but we want to encourage more like collaboration between the engineers",
    "start": "695200",
    "end": "700639"
  },
  {
    "text": "data engineers and also data analyst so that was they were the problems we",
    "start": "700639",
    "end": "706639"
  },
  {
    "text": "have so dig solves using these three concepts one is having parameterized",
    "start": "706639",
    "end": "714040"
  },
  {
    "text": "modules so in ddag a task will use a Operator Operator is a um step to run",
    "start": "714040",
    "end": "722160"
  },
  {
    "text": "something particular a single job like running a ver query or creating email",
    "start": "722160",
    "end": "728040"
  },
  {
    "text": "cluster or running Python scripts or running sh scripts so that is a module",
    "start": "728040",
    "end": "733880"
  },
  {
    "text": "and uh so one job one module does one thing and that you can customize the",
    "start": "733880",
    "end": "740279"
  },
  {
    "text": "behavior of that job by using parameters so it's a generalized",
    "start": "740279",
    "end": "745800"
  },
  {
    "text": "operator next step is that we group those operators into uh nested task",
    "start": "745800",
    "end": "752839"
  },
  {
    "text": "group so task group can um group the modularized uh modularized steps into",
    "start": "752839",
    "end": "759560"
  },
  {
    "text": "larger module so for example uh one step will run a red shift quy and then uh copy the",
    "start": "759560",
    "end": "767079"
  },
  {
    "text": "data unload the data into F3 then run EMR jobs so we can think that the three",
    "start": "767079",
    "end": "773839"
  },
  {
    "text": "steps as a a single module to do uh some machine learning on each",
    "start": "773839",
    "end": "780399"
  },
  {
    "text": "then next step is to uh load the results",
    "start": "780399",
    "end": "785720"
  },
  {
    "text": "back to our system production system we can think that is another step so there are two nested groups using this way we",
    "start": "785720",
    "end": "793160"
  },
  {
    "text": "can uh easily understand the workflows even though you are the not the",
    "start": "793160",
    "end": "798480"
  },
  {
    "text": "developer of the workflow itself we can read the code and because there's a commit log it's also easy to track the",
    "start": "798480",
    "end": "805120"
  },
  {
    "text": "changes and next thing is actually important for the the production",
    "start": "805120",
    "end": "810720"
  },
  {
    "text": "workflows uh for each steps uh we will produce some intermediate data and um",
    "start": "810720",
    "end": "817160"
  },
  {
    "text": "dig makes it possible to validate the results for each steps so this step should produce at at least 10 rows for",
    "start": "817160",
    "end": "824920"
  },
  {
    "text": "for example if that is less than 10 10 rows something is wrong so the work for aborts automatically so with the with",
    "start": "824920",
    "end": "832680"
  },
  {
    "text": "the with that building up we can get results and we can think that the",
    "start": "832680",
    "end": "838480"
  },
  {
    "text": "results is always correct so we can build trusts thrusts",
    "start": "838480",
    "end": "843920"
  },
  {
    "text": "on the results every time when there's a results it's thrusted it was important for us to",
    "start": "843920",
    "end": "849720"
  },
  {
    "text": "build to think about next actions based on the data so here's a example of the actual",
    "start": "849720",
    "end": "857240"
  },
  {
    "text": "workflow definition so as you can see uh DD uses yo format to define a",
    "start": "857240",
    "end": "863240"
  },
  {
    "text": "workflow a task uh a name starting with a plus sign is a task for example here",
    "start": "863240",
    "end": "870639"
  },
  {
    "text": "uh there are two tasks task one runs a operator called TD TD means actually to",
    "start": "870639",
    "end": "877199"
  },
  {
    "text": "data this runs a query SQL query on T data then once it's done runs next",
    "start": "877199",
    "end": "884079"
  },
  {
    "text": "query so um this is powerful for developers",
    "start": "884079",
    "end": "889720"
  },
  {
    "text": "because you can use git and Al any other tools you already know it's also",
    "start": "889720",
    "end": "895240"
  },
  {
    "text": "possible to generate this format automatically so it's powerful at the same time this is uh",
    "start": "895240",
    "end": "901560"
  },
  {
    "text": "straightforward enough for non Tech guys actually because uh you can uh you can",
    "start": "901560",
    "end": "908240"
  },
  {
    "text": "choose one operator to run job and then specify some uh parameters that's it to run a single task so our story is that",
    "start": "908240",
    "end": "915560"
  },
  {
    "text": "uh our marketing Rel our marketing manager actually try dig that and learned it a day on a single day then",
    "start": "915560",
    "end": "922160"
  },
  {
    "text": "created a demo it's a good story so uh let's see more about the",
    "start": "922160",
    "end": "930079"
  },
  {
    "text": "internals so first operators operators is important because one operator does",
    "start": "930079",
    "end": "935399"
  },
  {
    "text": "one one single job so there are operators like this R shift operator runs a r shift query EMR operator runs a",
    "start": "935399",
    "end": "944040"
  },
  {
    "text": "EMR jobs A3 weight is a interesting operator",
    "start": "944040",
    "end": "949240"
  },
  {
    "text": "to build a production pipelines it it weights until a file is available on F3",
    "start": "949240",
    "end": "956800"
  },
  {
    "text": "so for example you have a data collection system it will put the file every day then walk for wants to run",
    "start": "956800",
    "end": "964600"
  },
  {
    "text": "when the data is there so A3 weight using A3 weight operator as like the",
    "start": "964600",
    "end": "970800"
  },
  {
    "text": "right example shows it waits until the file is there then next step is to run the",
    "start": "970800",
    "end": "977639"
  },
  {
    "text": "actual analytics and some other uh postale operators and T operators and mailing",
    "start": "977639",
    "end": "983800"
  },
  {
    "text": "operators actually there are more uh such as like bqu operator Google Cloud platform operator so because data is on",
    "start": "983800",
    "end": "991720"
  },
  {
    "text": "any class or any data sources uh extensibility of the operator is important so what bigu does is that um",
    "start": "991720",
    "end": "1000160"
  },
  {
    "text": "we use uh plugin SDK so that you can write plugins and you can release the",
    "start": "1000160",
    "end": "1006880"
  },
  {
    "text": "plugins as a open source projects then you can install those plugins into DD to extend the",
    "start": "1006880",
    "end": "1013399"
  },
  {
    "text": "functionality of dig so one example is to have a slack operator open source",
    "start": "1013399",
    "end": "1019399"
  },
  {
    "text": "Community developed it so operators are good for typical",
    "start": "1019399",
    "end": "1026319"
  },
  {
    "text": "operations but of course um at many times you need to do custom",
    "start": "1026319",
    "end": "1031600"
  },
  {
    "text": "work so data also supports scripting operators like sh script operator python operator but downside is that uh",
    "start": "1031600",
    "end": "1038720"
  },
  {
    "text": "scripting operator easily depends on the server's environment it depends on some specific library or specific command on",
    "start": "1038720",
    "end": "1045038"
  },
  {
    "text": "the server uh which is not good to support so dig has native integration to",
    "start": "1045039",
    "end": "1052039"
  },
  {
    "text": "Docker this means that um with this configuration image UB to",
    "start": "1052039",
    "end": "1058440"
  },
  {
    "text": "16.04 this downloads the UB uh o image to run the task and task runs in the",
    "start": "1058440",
    "end": "1064440"
  },
  {
    "text": "docker cont so the command always runs within the same environment so that things will be",
    "start": "1064440",
    "end": "1071320"
  },
  {
    "text": "always republe and loop and parameters so for example this paror TD for each paror",
    "start": "1071320",
    "end": "1078240"
  },
  {
    "text": "runs a select statement on T dat then gets the results and for each results",
    "start": "1078240",
    "end": "1084600"
  },
  {
    "text": "Bros Loops the subdesk so in this example it gets a active user list using",
    "start": "1084600",
    "end": "1091000"
  },
  {
    "text": "a SQL and then for each row sends a email for uh using the email",
    "start": "1091000",
    "end": "1098039"
  },
  {
    "text": "priority and paral execution So within group you can set a option called",
    "start": "1098039",
    "end": "1103280"
  },
  {
    "text": "underscore parel if that is true sub tasks in the group will run in parel",
    "start": "1103280",
    "end": "1110159"
  },
  {
    "text": "so grouping is very essential concept of D so before having grouping everything",
    "start": "1110159",
    "end": "1115799"
  },
  {
    "text": "is flat like that and uh there are many arrows many dependencies each other it's",
    "start": "1115799",
    "end": "1121360"
  },
  {
    "text": "hard to understand what's happening there unless you understand all arrows",
    "start": "1121360",
    "end": "1126400"
  },
  {
    "text": "but with big that that would be group like this so first you ingest en data",
    "start": "1126400",
    "end": "1132840"
  },
  {
    "text": "and data modeling and within data modeling you have learning task and buket analytics uh uh task that within",
    "start": "1132840",
    "end": "1140600"
  },
  {
    "text": "uh learning task you will run machine learning steps in parall so that is uh easy for understanding and makes it",
    "start": "1140600",
    "end": "1148159"
  },
  {
    "text": "possible to collaborate between data engineers and analysts so",
    "start": "1148159",
    "end": "1153559"
  },
  {
    "text": "again uh D brings those best practices of software development to the uh",
    "start": "1153559",
    "end": "1159679"
  },
  {
    "text": "workflow uh workflow workflow application development so let's see the actual demo",
    "start": "1159679",
    "end": "1166600"
  },
  {
    "text": "how it is working in in production so in this example in this",
    "start": "1166600",
    "end": "1172600"
  },
  {
    "text": "demo I will show you about this uh workflow so uh first step is to load",
    "start": "1172600",
    "end": "1180000"
  },
  {
    "text": "data from Facebook ad and Amazon Aurora and a for like uh Facebook ad is for",
    "start": "1180000",
    "end": "1187520"
  },
  {
    "text": "like impression logs so someone clicked this ad and this user click this ad so",
    "start": "1187520",
    "end": "1192760"
  },
  {
    "text": "this side is clicked by like click for three times and this is for 10 times like that Amazon includes like user data",
    "start": "1192760",
    "end": "1200080"
  },
  {
    "text": "user attribute data and the patch includes some uh access logs then collect everything into",
    "start": "1200080",
    "end": "1206799"
  },
  {
    "text": "amazon3 as a table format using to data actually so I run some cies using to",
    "start": "1206799",
    "end": "1213440"
  },
  {
    "text": "data so that uh we can analyze data on F3 then put them into EMR to do some",
    "start": "1213440",
    "end": "1220840"
  },
  {
    "text": "spark application to run some spark applications then do machine learning and put the results back to uh rad shift",
    "start": "1220840",
    "end": "1228320"
  },
  {
    "text": "then application uses that data to provide recommendation and location based",
    "start": "1228320",
    "end": "1234520"
  },
  {
    "text": "suggestion okay let's do",
    "start": "1234520",
    "end": "1238280"
  },
  {
    "text": "that so here uh this file is the workflow definition",
    "start": "1241039",
    "end": "1247919"
  },
  {
    "text": "file demo. dig and here I run docment dig D dig D",
    "start": "1247919",
    "end": "1254559"
  },
  {
    "text": "run demo. dig so here started the",
    "start": "1254559",
    "end": "1261720"
  },
  {
    "text": "workflow so this takes a bit time for for for a while so this definition first",
    "start": "1261720",
    "end": "1268559"
  },
  {
    "text": "runs this task called setup this calls a table on amazon3 then next step is to ingest data",
    "start": "1268559",
    "end": "1277000"
  },
  {
    "text": "from S3 for the access logs from Apache Facebook add impression logs and the",
    "start": "1277000",
    "end": "1283960"
  },
  {
    "text": "user information from Aurora using my SQL",
    "start": "1283960",
    "end": "1289240"
  },
  {
    "text": "then this injection is using a three weight operator to wait until this file",
    "start": "1289240",
    "end": "1295760"
  },
  {
    "text": "is ready this file includes parameter like this so that this workor can run every",
    "start": "1295760",
    "end": "1303960"
  },
  {
    "text": "day then next step is to use TD load operator to load data to uh our uh th",
    "start": "1303960",
    "end": "1310240"
  },
  {
    "text": "data uh a three based data house then next step is to run some",
    "start": "1310240",
    "end": "1317400"
  },
  {
    "text": "queres to to in the data like joining or clining",
    "start": "1317400",
    "end": "1323000"
  },
  {
    "text": "up in this example uh we use three queries IP location to user item to",
    "start": "1323000",
    "end": "1329400"
  },
  {
    "text": "click count this says uh one this item is clicked for three times or five times",
    "start": "1329400",
    "end": "1335080"
  },
  {
    "text": "from the logs using Group by query so for example this",
    "start": "1335080",
    "end": "1342159"
  },
  {
    "text": "queries item to item count this is like that",
    "start": "1342159",
    "end": "1349320"
  },
  {
    "text": "so this workflow definition file and this query definition file are packaged together into one project then here",
    "start": "1349320",
    "end": "1357919"
  },
  {
    "text": "uh item to item yes this C is",
    "start": "1357919",
    "end": "1364039"
  },
  {
    "text": "running and those three tasks run in par as you",
    "start": "1366400",
    "end": "1371640"
  },
  {
    "text": "can see they are running in par here after that uh",
    "start": "1371640",
    "end": "1379279"
  },
  {
    "text": "so here data is prepared on F3 next step is to run a EMR operator",
    "start": "1379279",
    "end": "1386720"
  },
  {
    "text": "here so in this demo I use I'm I'm using a existing cluster so here is a prepared",
    "start": "1386720",
    "end": "1393279"
  },
  {
    "text": "cluster in advance and then this uh digdag is submitting those two steps",
    "start": "1393279",
    "end": "1398760"
  },
  {
    "text": "into the cluster one step is to create uh recommendation data and the other is",
    "start": "1398760",
    "end": "1404440"
  },
  {
    "text": "location based actually IP based uh recommendation data",
    "start": "1404440",
    "end": "1410440"
  },
  {
    "text": "if you use like this this operator creates a new cluster and runs the steps",
    "start": "1411880",
    "end": "1417520"
  },
  {
    "text": "and then shut shut down the uh cluster at the end but in this example I used existent",
    "start": "1417520",
    "end": "1423360"
  },
  {
    "text": "cluster at the end uh we run those copy command on red",
    "start": "1423360",
    "end": "1429799"
  },
  {
    "text": "shift so this means that uh data is preped on F3 using AMR using spark then",
    "start": "1429799",
    "end": "1437200"
  },
  {
    "text": "put the results using using copy command on red shift so that applications can use it so let's see uh this will take a",
    "start": "1437200",
    "end": "1445000"
  },
  {
    "text": "bit",
    "start": "1445000",
    "end": "1447200"
  },
  {
    "text": "more something I should say here um maybe you can speak to the date",
    "start": "1457279",
    "end": "1463320"
  },
  {
    "text": "parameterization that you're using in your workflow data parameterization like like",
    "start": "1463320",
    "end": "1469120"
  },
  {
    "text": "like session here yeah so in dig there are several buil-in",
    "start": "1469120",
    "end": "1476240"
  },
  {
    "text": "parameters session date is one parameter this is the time when the workf runs",
    "start": "1476240",
    "end": "1482840"
  },
  {
    "text": "when you schedule the query a schedule the workflow it automatically increments to the next day",
    "start": "1482840",
    "end": "1490919"
  },
  {
    "text": "and you can also Define some parameters as well so this export is defining some",
    "start": "1490919",
    "end": "1497000"
  },
  {
    "text": "parameters so in this case I Define TD database parameter so that it points",
    "start": "1497000",
    "end": "1504440"
  },
  {
    "text": "this database so this parameter is actually used in this TV",
    "start": "1504440",
    "end": "1509919"
  },
  {
    "text": "operator so in this case this TV operator uses a database called dig demo",
    "start": "1509919",
    "end": "1515520"
  },
  {
    "text": "today so for each for for uh for each run it creates a temporary database and",
    "start": "1515520",
    "end": "1521039"
  },
  {
    "text": "runs uh some queries within the database and creates tables on that database so",
    "start": "1521039",
    "end": "1526640"
  },
  {
    "text": "every day it creates a fresh datab",
    "start": "1526640",
    "end": "1530320"
  },
  {
    "text": "so oh yes finished great so at the end actually it runs uh red shift oper here",
    "start": "1539720",
    "end": "1546480"
  },
  {
    "text": "to copy the data to Red shift so let's see the results so is this connected",
    "start": "1546480",
    "end": "1554320"
  },
  {
    "text": "yes um so first I want to see",
    "start": "1554320",
    "end": "1560240"
  },
  {
    "text": "uh this recommendation table uh yes",
    "start": "1560520",
    "end": "1566919"
  },
  {
    "text": "here so someone bought item 281",
    "start": "1566919",
    "end": "1572480"
  },
  {
    "text": "uh who uh people who bought this item",
    "start": "1572480",
    "end": "1577960"
  },
  {
    "text": "also bought those items so by by running this quy you can build that",
    "start": "1577960",
    "end": "1584320"
  },
  {
    "text": "recommendation so data is there using this work for engine",
    "start": "1584320",
    "end": "1589360"
  },
  {
    "text": "and another thing is that location data so someone is accessing from this IP uh",
    "start": "1589360",
    "end": "1597360"
  },
  {
    "text": "19 96.4 point something something then uh previously people coming from this IP",
    "start": "1597360",
    "end": "1606919"
  },
  {
    "text": "uh this this this region bought that item so we can build that kind of",
    "start": "1606919",
    "end": "1612399"
  },
  {
    "text": "suggestion using this workflow so now you can think understand how to build",
    "start": "1612399",
    "end": "1617600"
  },
  {
    "text": "the recommend engine using this workfront let's see another demo so I",
    "start": "1617600",
    "end": "1626200"
  },
  {
    "text": "see that there's a native integration to",
    "start": "1626200",
    "end": "1630240"
  },
  {
    "text": "Docker",
    "start": "1631760",
    "end": "1634760"
  },
  {
    "text": "um so in this workflow uh I'm using two two tasks RB uh first is n r and second",
    "start": "1637080",
    "end": "1645120"
  },
  {
    "text": "is from DOA and this operator is running a ruby method defined here this is showing a",
    "start": "1645120",
    "end": "1652200"
  },
  {
    "text": "version of the Ruby so first Ruby is not does not have option to use Docker so",
    "start": "1652200",
    "end": "1657720"
  },
  {
    "text": "this uses the native this this this machines Ruby on the other hand next step is using",
    "start": "1657720",
    "end": "1663840"
  },
  {
    "text": "Docker actually on this machine I think this has uh Ruby 2.3 so this first step",
    "start": "1663840",
    "end": "1669399"
  },
  {
    "text": "should show 2.3 and the Second Step will show two. 3.3 so dig that run here",
    "start": "1669399",
    "end": "1678960"
  },
  {
    "text": "here we go like this so let's say if you have some uh machine learning uh",
    "start": "1681279",
    "end": "1687960"
  },
  {
    "text": "operation image you can you can install like spark or pandas npy we don't",
    "start": "1687960",
    "end": "1694640"
  },
  {
    "text": "installing that on your machine you can just specify the image of the docker and that's it",
    "start": "1694640",
    "end": "1701799"
  },
  {
    "text": "yes let's see thanks s um so",
    "start": "1711600",
    "end": "1718960"
  },
  {
    "text": "yes so thanks Auto for the demo um one of the pieces that uh he didn't speak about in the demo is actually so with",
    "start": "1719080",
    "end": "1726000"
  },
  {
    "text": "this when you start up the server mode and you deploy you can with a simple",
    "start": "1726000",
    "end": "1731640"
  },
  {
    "text": "command digdag push you can deploy that entire project to the server and once on",
    "start": "1731640",
    "end": "1736880"
  },
  {
    "text": "the server there's a web so that you can go on and see the status of your workflows that you've deployed",
    "start": "1736880",
    "end": "1742279"
  },
  {
    "text": "past sessions rerun sessions see metadata about the operation of those workflows find logs associated with that",
    "start": "1742279",
    "end": "1749320"
  },
  {
    "text": "so that's a key element as well that we aren't going over today but um is available and discussed in the",
    "start": "1749320",
    "end": "1755600"
  },
  {
    "text": "documentation as well um and so we created digdag to support our customers and our business we host it for our",
    "start": "1755600",
    "end": "1762200"
  },
  {
    "text": "customers so they can start creating and managing workflows uh without devops and to reduce the overall time to get",
    "start": "1762200",
    "end": "1768480"
  },
  {
    "text": "started um we have numerous customers already using it for scheduling processing flows across AWS running data",
    "start": "1768480",
    "end": "1775600"
  },
  {
    "text": "loads into and outof treasure data and organizing generally organizing their analytic processing flows um uh as such",
    "start": "1775600",
    "end": "1784360"
  },
  {
    "text": "if uh you uh want to become an open source uh user of digdag um you can",
    "start": "1784360",
    "end": "1789440"
  },
  {
    "text": "trust that we'll be continuously putting the lessons that we learn um when using it with our customers um back into the",
    "start": "1789440",
    "end": "1796039"
  },
  {
    "text": "open source project um we've we've already put Lessons Learned From maintaining a 24/7 uptime system and",
    "start": "1796039",
    "end": "1802840"
  },
  {
    "text": "having handled over 100 billion queries into our product over the last five years uh so thank you very much um I",
    "start": "1802840",
    "end": "1810480"
  },
  {
    "text": "hope you'll come by um to learn more about this project and get involved um if you want to become a user uh there's",
    "start": "1810480",
    "end": "1817000"
  },
  {
    "text": "a user email list that you can sign up for on digdag doio um and this is specific for digdag open source",
    "start": "1817000",
    "end": "1823600"
  },
  {
    "text": "Community conversations um also please feel free to stop by treasure data Booth",
    "start": "1823600",
    "end": "1829000"
  },
  {
    "text": "1818 um you can ask us questions about digdag uh we're hosting a party tonight at to nightclub um and would love to see",
    "start": "1829000",
    "end": "1835919"
  },
  {
    "text": "you there uh co-hosting it with Chio and logs. um well we will stay up here for a",
    "start": "1835919",
    "end": "1841640"
  },
  {
    "text": "little bit to answer questions um if you have any you're welcome to go to the microphone um as well thank you very",
    "start": "1841640",
    "end": "1847559"
  },
  {
    "text": "much",
    "start": "1847559",
    "end": "1850559"
  }
]
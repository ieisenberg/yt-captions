[
  {
    "start": "0",
    "end": "0"
  },
  {
    "text": "uh this is a technical introduction to Amazon EMR um my name is abishek s I'm a",
    "start": "599",
    "end": "5600"
  },
  {
    "text": "senior product manager on the Amazon EMR team um so what would you get out of",
    "start": "5600",
    "end": "11320"
  },
  {
    "text": "this session so I wanted to lay that out how many of you have used or heard about Amazon AMR just show",
    "start": "11320",
    "end": "16760"
  },
  {
    "text": "fans wow you're scaring me all of you know a lot about that so this is u in an",
    "start": "16760",
    "end": "23320"
  },
  {
    "text": "intro session on EMR we'll talk about some of the basic tenets of why we build",
    "start": "23320",
    "end": "28359"
  },
  {
    "text": "the service and how we build the service uh what are the benefits that it uh it provides we'll take you to some of the",
    "start": "28359",
    "end": "34040"
  },
  {
    "text": "features set we'll also talk about a real life experience of moving a two",
    "start": "34040",
    "end": "39320"
  },
  {
    "text": "petabyte Hado cluster from on premise uh to the AWS cloud and how that ended up",
    "start": "39320",
    "end": "45079"
  },
  {
    "text": "actually saving cost and doing more work so what it's not it's not a",
    "start": "45079",
    "end": "50199"
  },
  {
    "text": "technical introduction to any of the large scale data processing Frameworks that you be using it's not a",
    "start": "50199",
    "end": "55399"
  },
  {
    "text": "introduction to Hadoop it's not an introduction to spark or Presto uh there",
    "start": "55399",
    "end": "60440"
  },
  {
    "text": "are other sessions that talk about that there's a deep dive section later in the day that talks about that all right so",
    "start": "60440",
    "end": "66000"
  },
  {
    "text": "let's get started so Amazon Yar is essentially a managed platform that means we manage provisioning of a Hadoop",
    "start": "66000",
    "end": "72200"
  },
  {
    "text": "cluster on to on top of AWS so it's just not Hadoop we also have graduated to",
    "start": "72200",
    "end": "77439"
  },
  {
    "text": "running multiple different data processing Frameworks like spark and prestor so with latest release you can",
    "start": "77439",
    "end": "83600"
  },
  {
    "text": "get the latest version of presto on Amazon EMR as well Plus on Apaches Park we are at version 1.5",
    "start": "83600",
    "end": "90400"
  },
  {
    "text": "so it makes provisioning easy you can launch a cluster in a matter of minutes we basically vend the open source",
    "start": "90400",
    "end": "96479"
  },
  {
    "text": "distribution right so whatever you see in the open source AO 3 we have exactly the same bits on Amazon EMR we also",
    "start": "96479",
    "end": "103479"
  },
  {
    "text": "support the map R distribution so you have a choice whether you want to run open source or map hour we allow and",
    "start": "103479",
    "end": "110320"
  },
  {
    "text": "help you Leverage The elasticity of a cloud and as we go forward I'll show you how we talk about some of the basic",
    "start": "110320",
    "end": "117759"
  },
  {
    "text": "security features that are baked into the setup when you provision clusters firewalls get set up and security",
    "start": "117759",
    "end": "123840"
  },
  {
    "text": "principles get set up roles and accesses get defined automatically we also like just like any other Amazon service you",
    "start": "123840",
    "end": "130440"
  },
  {
    "text": "pay by the hour but you can also save on a cost by using something called a spot instances so we'll talk a little bit",
    "start": "130440",
    "end": "136319"
  },
  {
    "text": "about the concept of spot instances and how do you use Amazon uh EMR with spot instances so the the last point that",
    "start": "136319",
    "end": "143519"
  },
  {
    "text": "it's an it's an open source environment inside Amazon EMR um though it's a",
    "start": "143519",
    "end": "148760"
  },
  {
    "text": "managed platform we give give you complete flexibility to add on any bits that you want so we actually give you",
    "start": "148760",
    "end": "154760"
  },
  {
    "text": "root access which is quite unlike a managed environment we give you root access to modify anything that's on Amazon EMR and that allows you to do",
    "start": "154760",
    "end": "162120"
  },
  {
    "text": "interesting things with new uh Frameworks that are coming on top of EMR all right so what's the vision of",
    "start": "162120",
    "end": "169080"
  },
  {
    "text": "the service the vision of the service is essentially that we want to make it really easy secure and cost effective to",
    "start": "169080",
    "end": "174720"
  },
  {
    "text": "run this data processing Frameworks on AWS that's what we everyday think about when we think about what should we build",
    "start": "174720",
    "end": "180840"
  },
  {
    "text": "on amanar so what do I need to build a cluster essentially it's it's just three",
    "start": "180840",
    "end": "186360"
  },
  {
    "start": "182000",
    "end": "182000"
  },
  {
    "text": "steps three things three decisions that you need to make to build your cluster you need to choose your instances you",
    "start": "186360",
    "end": "191879"
  },
  {
    "text": "need to choose the software you want to use and you need to choose a method in which you want to access your cluster so",
    "start": "191879",
    "end": "197840"
  },
  {
    "text": "let's do that let's first look at a topology of an EMR cluster essentially there's something called as a master",
    "start": "197840",
    "end": "203560"
  },
  {
    "start": "198000",
    "end": "198000"
  },
  {
    "text": "node so for those of you who are familiar with yarn this is what the resource manager runs and then there are",
    "start": "203560",
    "end": "208720"
  },
  {
    "text": "a bunch of slave notes now the slave nodes are categorized into two kinds one of them is the core nodes and which runs",
    "start": "208720",
    "end": "216519"
  },
  {
    "text": "apart from the node manager they also run the data the data service that is hdfs and the others are called task",
    "start": "216519",
    "end": "222680"
  },
  {
    "text": "nodes these just run the node manager they don't have any hdfs on it also you can have multiple of these that means",
    "start": "222680",
    "end": "229200"
  },
  {
    "text": "you can mix and match different instance types you can mix and match instance types from different markets like the on",
    "start": "229200",
    "end": "235560"
  },
  {
    "text": "demand Market or from the reserve Market or from the spot market so you take all of this and that forms a basic EMR",
    "start": "235560",
    "end": "243400"
  },
  {
    "text": "cluster there are obviously different types of workloads that can be run on top of Hadoop it's become a very general",
    "start": "243400",
    "end": "249439"
  },
  {
    "start": "244000",
    "end": "244000"
  },
  {
    "text": "processing general purpose data processing application so for different to match the different styles you have",
    "start": "249439",
    "end": "255319"
  },
  {
    "text": "different types of instances that you can use so if you're doing something like badge processing the general family is good if you're doing machine learning",
    "start": "255319",
    "end": "261799"
  },
  {
    "text": "the CPU intensive family if you're doing large scale processing on spark or in Presto then the memory optimized and if",
    "start": "261799",
    "end": "268160"
  },
  {
    "text": "you have large hdfs requirements ments the dis iio intensive family is also good and this is not restrictions these",
    "start": "268160",
    "end": "274120"
  },
  {
    "text": "are just examples of how you can use one versus the other that because you might be running multiple different workloads",
    "start": "274120",
    "end": "279800"
  },
  {
    "text": "one team might be running a spark workload the other team might be using Hadoop to do batch processing they can",
    "start": "279800",
    "end": "284960"
  },
  {
    "text": "both use different types of instances on top of Amazon EMR all right so for those",
    "start": "284960",
    "end": "290400"
  },
  {
    "text": "of you who can see this is what the U console looks like essentially it's a very simple console it gives you a range",
    "start": "290400",
    "end": "295919"
  },
  {
    "text": "of choices of what kind of instances to pick it's very simple to do that pick instances now when you choose your",
    "start": "295919",
    "end": "301560"
  },
  {
    "start": "300000",
    "end": "300000"
  },
  {
    "text": "software you can choose bundles you can choose a bundle of let's say I want to run spark 1.5 with certain Hadoop",
    "start": "301560",
    "end": "307840"
  },
  {
    "text": "applications or I want the whole nine yards of all the applications together or you can also customize these",
    "start": "307840",
    "end": "316000"
  },
  {
    "start": "315000",
    "end": "315000"
  },
  {
    "text": "bundles so you can say I want to run EMR 4.1 with this particular software I can",
    "start": "316000",
    "end": "321639"
  },
  {
    "text": "add applications to it you can add other applications like ganglia Presto Zeppelin all of these different things",
    "start": "321639",
    "end": "327479"
  },
  {
    "text": "so you have both uh advantages you can take a bundle or you can customize this now all of this is based upon Apache",
    "start": "327479",
    "end": "334360"
  },
  {
    "text": "bigtop now for those of you who are who are not aware Apache bigtop is an open source project that describes how the",
    "start": "334360",
    "end": "339880"
  },
  {
    "text": "packaging of an open source uh ecosystem should be done especially for Hado so if",
    "start": "339880",
    "end": "345000"
  },
  {
    "text": "you're building your application on an open source tree you you're very sure that all of that would work on Amazon",
    "start": "345000",
    "end": "351000"
  },
  {
    "text": "EMR all right so you we run a wide variety of applications some of them are",
    "start": "351000",
    "end": "356280"
  },
  {
    "start": "352000",
    "end": "352000"
  },
  {
    "text": "bundled into the packaging some of them you can install on top of it right so things like hbas Presto spark Hugh",
    "start": "356280",
    "end": "363400"
  },
  {
    "text": "Zeppelin Impala actually all of them come bundled into the uh into the open source distribution but let's say I",
    "start": "363400",
    "end": "369319"
  },
  {
    "text": "wanted to run something new I wanted to run a cumulo or I wanted to run a Pache Flink you can use a bootstrap action",
    "start": "369319",
    "end": "376319"
  },
  {
    "text": "which is basically a way to add new bits to the cluster and you can load them up",
    "start": "376319",
    "end": "381800"
  },
  {
    "text": "people have also contributed to an open source git repository that allows you to take their bootstrap actions and use",
    "start": "381800",
    "end": "387319"
  },
  {
    "text": "them to add any more software on top top of Amazon EMR all right last but not the",
    "start": "387319",
    "end": "393039"
  },
  {
    "start": "391000",
    "end": "391000"
  },
  {
    "text": "least I choose a method so I can describe roles there are predefined roles roles and policies defined for how",
    "start": "393039",
    "end": "398360"
  },
  {
    "text": "what people are allowed to access and that's it you're are up and running in this case it's a it's a simple cluster",
    "start": "398360",
    "end": "406039"
  },
  {
    "start": "401000",
    "end": "401000"
  },
  {
    "text": "what you see in a cluster is a master node so we have the DNS already set up for you if you wanted to SSH into the",
    "start": "406039",
    "end": "411720"
  },
  {
    "text": "cluster or if you wanted to look at the name node resource manager uh web UI all",
    "start": "411720",
    "end": "417240"
  },
  {
    "text": "of these can be accessed through the to master node you have certain details that tell you about the configuration of",
    "start": "417240",
    "end": "423360"
  },
  {
    "text": "the cluster so this particular cluster runs um uh High one and pig 14 uh it",
    "start": "423360",
    "end": "429440"
  },
  {
    "text": "runs Amazon 2.6 or Hado 2.6 distribution you also have an understanding of what",
    "start": "429440",
    "end": "434720"
  },
  {
    "text": "Hardware you're running in this case it's a simple three note cluster is running in US US East you also have",
    "start": "434720",
    "end": "440400"
  },
  {
    "text": "certain basic security and access principles that are well that works security and access",
    "start": "440400",
    "end": "446280"
  },
  {
    "text": "principles that are there so there's a default role that is already set up you you would also see that there are default firewalls set up so the master",
    "start": "446280",
    "end": "452840"
  },
  {
    "text": "node has a firewall and all the slave nodes are encapsulated in a firewall what also happens is the slave nodes can",
    "start": "452840",
    "end": "459720"
  },
  {
    "text": "only talk to the master node via VIA a security group so it's all locked down for security right from the very",
    "start": "459720",
    "end": "466280"
  },
  {
    "text": "beginning but if you wanted to change that you can change that as well so that's it you got your cluster up and",
    "start": "466280",
    "end": "471520"
  },
  {
    "start": "470000",
    "end": "470000"
  },
  {
    "text": "running using the CLI it's even more uh easier it's a simple CLI or you can use your favorite SDK as well to configure",
    "start": "471520",
    "end": "478879"
  },
  {
    "text": "what it does is it gives you a way to programmatically do cluster provisioning",
    "start": "478879",
    "end": "484639"
  },
  {
    "start": "481000",
    "end": "481000"
  },
  {
    "text": "using the apis or the SDK that means I can build pipelines those pipelines can",
    "start": "484639",
    "end": "490280"
  },
  {
    "text": "look like hey when the data arrives spin up an EMR cluster process the data and then just uh terminate the",
    "start": "490280",
    "end": "497560"
  },
  {
    "text": "cluster we'll talk about these pipelines in a little while okay I have a cluster now all I need is some data to process",
    "start": "497560",
    "end": "505159"
  },
  {
    "text": "there are multiple different ways in which you can process data from AMR multiple different sources the first and",
    "start": "505159",
    "end": "510759"
  },
  {
    "start": "507000",
    "end": "507000"
  },
  {
    "text": "the most obvious one is htfs so when we set up an EMR cluster we actually use the local inst the local instance disc",
    "start": "510759",
    "end": "517919"
  },
  {
    "text": "and we set up htfs on those diss right but remember if you shut down the cluster the instances the data on the",
    "start": "517919",
    "end": "524399"
  },
  {
    "text": "instances goes away right because it's not EBS it's the local disk the second thing is we allow you to process data",
    "start": "524399",
    "end": "531360"
  },
  {
    "text": "directly from Amazon S3 through a component call as emrfs that comes directly integrated with Amazon EMR we",
    "start": "531360",
    "end": "538279"
  },
  {
    "text": "also allow you to process data from Dynamo DB or with Amazon Kinesis so there are a vast variety of systems that",
    "start": "538279",
    "end": "545720"
  },
  {
    "text": "are available to process data um most people understand how to process data from hdfs but I want to talk to you a",
    "start": "545720",
    "end": "552079"
  },
  {
    "text": "little bit about why we build the integration on with Amazon S3 through emrfs which generally stands for EMR",
    "start": "552079",
    "end": "558920"
  },
  {
    "text": "file system so when you look at the concept of a Hadoop cluster on premise the idea of compute and storage is very",
    "start": "558920",
    "end": "566880"
  },
  {
    "start": "560000",
    "end": "560000"
  },
  {
    "text": "tightly coupled that means as your store storage grows your compute also grows",
    "start": "566880",
    "end": "572040"
  },
  {
    "start": "572000",
    "end": "572000"
  },
  {
    "text": "accordingly that doesn't mean that you're processing all your data at all the time you might actually be just",
    "start": "572040",
    "end": "578959"
  },
  {
    "text": "storing a lot more data but you might just be processing a day worth of data or an hour worth of data or even",
    "start": "578959",
    "end": "586160"
  },
  {
    "text": "sometimes maybe at the end of the week a week worth of data so your Hadoop cluster keeps growing as much as",
    "start": "586160",
    "end": "592320"
  },
  {
    "text": "possible because of the way your data grows now what this leads to is the",
    "start": "592320",
    "end": "598040"
  },
  {
    "text": "compute requirements really where right that I might be processing a 1 hour worth of data that might just",
    "start": "598040",
    "end": "604079"
  },
  {
    "text": "require two CPUs or three CPUs right but I have 100 node Hado cluster because of",
    "start": "604079",
    "end": "609959"
  },
  {
    "text": "the storage that I'm accumulated on hdfs also I mean if you came it came to",
    "start": "609959",
    "end": "616560"
  },
  {
    "start": "614000",
    "end": "614000"
  },
  {
    "text": "a cloud computing conference this graph is pretty evident but it's it's a reality for a lot of analytics companies",
    "start": "616560",
    "end": "622120"
  },
  {
    "text": "right so if you think about this there is a weekly Peak because most people are looking at weekly aggregation of data",
    "start": "622120",
    "end": "628000"
  },
  {
    "text": "there is a steady state work workload where you're doing maybe the hourly or daily aggregation of data but there are",
    "start": "628000",
    "end": "633880"
  },
  {
    "text": "also times when you want to reprocess a lot of data and that might be the peak what people end up doing is they",
    "start": "633880",
    "end": "639360"
  },
  {
    "text": "provision their Hadoop clusters at somewhere on the provision capacity line but for most of the time when you're",
    "start": "639360",
    "end": "645200"
  },
  {
    "text": "just doing daily or weekly processing all of that is actually underutilized now what happens also is",
    "start": "645200",
    "end": "652760"
  },
  {
    "start": "651000",
    "end": "651000"
  },
  {
    "text": "you have a central Hadoop cluster so every Everybody every organization every",
    "start": "652760",
    "end": "658320"
  },
  {
    "text": "team within your setup or every developer within your setup is actually just using the same and running",
    "start": "658320",
    "end": "664480"
  },
  {
    "text": "different processing workloads on the same Hadoop cluster and that leads to a lot of resource contention for example",
    "start": "664480",
    "end": "670399"
  },
  {
    "text": "Hive jobs can be compute bound and Spark jobs might be Memory bound right and they're all thrashing against each other",
    "start": "670399",
    "end": "675920"
  },
  {
    "text": "trying to find space or trying to time share within the same Hado clusters and administrators tend to now go and do",
    "start": "675920",
    "end": "681279"
  },
  {
    "text": "things like Bild like cues so this is my Q for my production ready job and I need this to be higher priority than the",
    "start": "681279",
    "end": "687399"
  },
  {
    "text": "Devon test job right so that was something that we saw as a problem with a non- premis adup cluster also people",
    "start": "687399",
    "end": "694120"
  },
  {
    "start": "692000",
    "end": "692000"
  },
  {
    "text": "try to to replicate the setup so I'll give one cluster for spark one cluster for Hadoop and high which is doing batch",
    "start": "694120",
    "end": "700360"
  },
  {
    "text": "processing one cluster for ad hoc analysis one cluster for uh batch processing but then you tend to",
    "start": "700360",
    "end": "706800"
  },
  {
    "text": "duplicate your data and create silos right because now the data that is sitting in hdfs needs to be duplicated",
    "start": "706800",
    "end": "712920"
  },
  {
    "text": "across multiple different clusters so also hdfs adds 3x",
    "start": "712920",
    "end": "719240"
  },
  {
    "text": "replication as most of you know it has 3 its replication so if you have uh 30 terab of raw storage you're probably",
    "start": "719240",
    "end": "725360"
  },
  {
    "text": "just using 10 terab of hdfs stage and while you do that you're still only in a",
    "start": "725360",
    "end": "730399"
  },
  {
    "text": "single data center I can't tell you how many people have talked to within this conference who told me that they want to",
    "start": "730399",
    "end": "735560"
  },
  {
    "text": "do a backup of their hdfs because now it carries a lot of their pre-processed data sets their raw data sets right so",
    "start": "735560",
    "end": "741639"
  },
  {
    "text": "it's a real challenge when we look at all of these we thought we we thought really hard about how we're going to solve this",
    "start": "741639",
    "end": "747639"
  },
  {
    "text": "problem and the way we solve this problem is we want to decouple storage in compute right with storage what we",
    "start": "747639",
    "end": "754120"
  },
  {
    "start": "750000",
    "end": "750000"
  },
  {
    "text": "want is we want persistence we want durability we want low cost and we want High availability with compute we want",
    "start": "754120",
    "end": "760560"
  },
  {
    "text": "variety we want elasticity and we want fungibility and that's the reason we chose Amazon S3 as a data source that",
    "start": "760560",
    "end": "768199"
  },
  {
    "text": "which you can use to process your data so Amazon S3 as most of you uh know offers 11 nines of durability is uh is",
    "start": "768199",
    "end": "775639"
  },
  {
    "start": "771000",
    "end": "771000"
  },
  {
    "text": "by default distributed across multiple availability Zone it's extremely low cost starts at about 3 cents a Gaby",
    "start": "775639",
    "end": "781959"
  },
  {
    "text": "month in in Us East it's got life cycle policies so you can move all and old data from one uh one tier to another",
    "start": "781959",
    "end": "789480"
  },
  {
    "text": "it's got versioning enabled and it's and it's distributed by default right so when you think about that compared to",
    "start": "789480",
    "end": "795720"
  },
  {
    "text": "hdfs hdfs you're paying for three copies of data on on S3 you're not and that is",
    "start": "795720",
    "end": "802199"
  },
  {
    "text": "three copies of data in a single data center here it's distributed across multiple availability zones but you're",
    "start": "802199",
    "end": "808040"
  },
  {
    "text": "just paying for what you you actually store to us that was an immense Advantage right because it automatically",
    "start": "808040",
    "end": "814240"
  },
  {
    "text": "drops your storage cost by 1/3 now so to to interact with S3 we we actually built",
    "start": "814240",
    "end": "821440"
  },
  {
    "text": "a connector that is called emrfs that connector what it does it",
    "start": "821440",
    "end": "826760"
  },
  {
    "start": "825000",
    "end": "825000"
  },
  {
    "text": "allows you to process the data process Amazon S3 as a file system and directly run Hadoop jobs or spark jobs or Presto",
    "start": "826760",
    "end": "833720"
  },
  {
    "text": "jobs all directly on Amazon S3 it streams data directly to S3 and if",
    "start": "833720",
    "end": "839120"
  },
  {
    "text": "you're using the the map reduce format it uses hdfs for intermediate so it's not going back and forth from S3 it's",
    "start": "839120",
    "end": "846040"
  },
  {
    "text": "just taking the data from S3 streaming it into uh to process it and once for intermediates it uses hdfs it uses as I",
    "start": "846040",
    "end": "853519"
  },
  {
    "text": "said uses hdfs this is now this concept is not new I mean I see that there are",
    "start": "853519",
    "end": "858880"
  },
  {
    "text": "lots and lots of Open Source equivalent for for example spark has an open source S3 connector Presto has an open source",
    "start": "858880",
    "end": "865279"
  },
  {
    "text": "S3 connector so this this idea of decoupling and your storage and computer is not new but we we believe that the",
    "start": "865279",
    "end": "872040"
  },
  {
    "text": "emrfs uh file system has better read write performance and error handling because we've been working on it for the",
    "start": "872040",
    "end": "877360"
  },
  {
    "text": "last six years there's also things like S3 suffers from consistency so we have a",
    "start": "877360",
    "end": "882639"
  },
  {
    "text": "feature that allows you to do consistent that allows you to be consistent for read after wrs also emrfs allows you to",
    "start": "882639",
    "end": "890959"
  },
  {
    "text": "support encryption for a lot of our customers this is really important because what they can do is they can use",
    "start": "890959",
    "end": "896000"
  },
  {
    "text": "client side encryption that means they can encrypt the data sitting in S3 with the keys that are in either AWS KMS or",
    "start": "896000",
    "end": "903399"
  },
  {
    "text": "actually on their on premises HSM and EMR can directly use those keys to process the",
    "start": "903399",
    "end": "908759"
  },
  {
    "text": "data based of all of these we were um there's also things like Fast listing of",
    "start": "908759",
    "end": "914360"
  },
  {
    "text": "objects because S3 when you have a really large data set the listing can become really slow so we've made",
    "start": "914360",
    "end": "919480"
  },
  {
    "text": "improvements around fast listing of objects so how difficult it is if you actually wrote your program to use hdfs",
    "start": "919480",
    "end": "927160"
  },
  {
    "text": "to go to S3 so here's a very simple Declaration of an external table in Hive and I'm using uh the location to figure",
    "start": "927160",
    "end": "934240"
  },
  {
    "text": "out where the where uh the source data is for S3 all I need to change is from",
    "start": "934240",
    "end": "939399"
  },
  {
    "text": "hdfs to S3 pointed to the bucket where the actual data is it's that transparent",
    "start": "939399",
    "end": "944440"
  },
  {
    "text": "to move to uh from hdfs to S3 so what are the benefits of this the",
    "start": "944440",
    "end": "951000"
  },
  {
    "start": "948000",
    "end": "948000"
  },
  {
    "text": "first benefit is when you decouple your storage in compute now I can start processing the data and when the",
    "start": "951000",
    "end": "957040"
  },
  {
    "text": "processing is over I can actually switch off my cluster and I don't need to don't need to run my cluster all the time so",
    "start": "957040",
    "end": "963680"
  },
  {
    "text": "imagine a hive job that uh does daily aggregations uh and wakes up every 4",
    "start": "963680",
    "end": "969399"
  },
  {
    "text": "hours you actually don't need to have a cluster running all the time because your data actually persists on S3 you",
    "start": "969399",
    "end": "975120"
  },
  {
    "text": "can switch on the cluster it processes the data and when the step is done it can automatically shut it down now when",
    "start": "975120",
    "end": "981759"
  },
  {
    "text": "again the next fourth hour arrives you can still start that again and you can save enormous amount of cost just by",
    "start": "981759",
    "end": "987199"
  },
  {
    "text": "doing that remember the data is all there in S3 the data is persisting so is",
    "start": "987199",
    "end": "993279"
  },
  {
    "start": "992000",
    "end": "992000"
  },
  {
    "text": "it very difficult to Auto terminate my cluster no it's fairly simple you check on the auto terminate so it's a it's an",
    "start": "993279",
    "end": "999120"
  },
  {
    "text": "option on the console it's Al also an option on the API and the uh uh and the CLI you just say Auto terminate is on",
    "start": "999120",
    "end": "1006199"
  },
  {
    "text": "what that does is once the jobs that have been submitted to the cluster are over it will automatically shut down the",
    "start": "1006199",
    "end": "1012279"
  },
  {
    "text": "cluster there so now I can build intelligent pipelines I can build for example this is a really really",
    "start": "1012279",
    "end": "1019360"
  },
  {
    "start": "1018000",
    "end": "1018000"
  },
  {
    "text": "well uh documented pipeline that a lot of our customers use so data comes in in",
    "start": "1019360",
    "end": "1024959"
  },
  {
    "text": "some format there is an input data you use uh it let's say this is for example omniture logs you use Amazon EMR you use",
    "start": "1024959",
    "end": "1032520"
  },
  {
    "text": "Hadoop to process those logs to ETL those logs now you want to push them into another S3 bucket and you then load",
    "start": "1032520",
    "end": "1038520"
  },
  {
    "text": "the data into red shift for people to consume it using a normal SQL interface now what you can do with something like",
    "start": "1038520",
    "end": "1044319"
  },
  {
    "text": "Amazon data pipeline is create a complete pipeline of all of these activities and run it on a schedule",
    "start": "1044319",
    "end": "1050400"
  },
  {
    "text": "manner so a pipeline looks something like this on data pipeline right so the",
    "start": "1050400",
    "end": "1055559"
  },
  {
    "start": "1053000",
    "end": "1053000"
  },
  {
    "text": "service is called Amazon data pipeline so you can create really good views of your complete pipeline even if you don't",
    "start": "1055559",
    "end": "1062120"
  },
  {
    "text": "use Amazon data pipeline you can script these pipelines to start using something like Lambda",
    "start": "1062120",
    "end": "1068799"
  },
  {
    "text": "functions so what if I don't want to shut down my cluster what if my requirement is that I",
    "start": "1068799",
    "end": "1075480"
  },
  {
    "text": "want to process the data on an hourly basis so I don't want to switch it off switch it on switch it off switch it on",
    "start": "1075480",
    "end": "1081360"
  },
  {
    "text": "that's possible as well just do not check the auto Terminators yes so in that case your cluster will be running",
    "start": "1081360",
    "end": "1087880"
  },
  {
    "text": "as long as you want it to run right and then you can keep on submitting the Hadoop job also what you can do is you",
    "start": "1087880",
    "end": "1095039"
  },
  {
    "text": "can scale your clusters up and you can scale your clusters down right so that's how because your data is actually",
    "start": "1095039",
    "end": "1101919"
  },
  {
    "text": "persisting in S3 your compute layer can go up and compute layer can go down and thus allowing you to actually fall",
    "start": "1101919",
    "end": "1108799"
  },
  {
    "text": "follow the load that you're seeing on your uh um on your clusters right so resize is is uh is is driven by an API",
    "start": "1108799",
    "end": "1116520"
  },
  {
    "start": "1113000",
    "end": "1113000"
  },
  {
    "text": "it's a simple API command you say modify a certain instance group you give it a number and it goes and resize it also",
    "start": "1116520",
    "end": "1122440"
  },
  {
    "text": "resize down is possible and we have a lot of intelligence built into when we resize down we try and do it in a way",
    "start": "1122440",
    "end": "1128159"
  },
  {
    "text": "that it minimally impacts your job so I'll talk about that in a minute so scaling up and scaling down is very easy",
    "start": "1128159",
    "end": "1135080"
  },
  {
    "start": "1132000",
    "end": "1132000"
  },
  {
    "text": "uh on the console also you can do a quick resize uh you can issue a size on top of resize for example if you fat",
    "start": "1135080",
    "end": "1140960"
  },
  {
    "text": "fingered something so this this is another con great thing about Amazon EMR that it",
    "start": "1140960",
    "end": "1146799"
  },
  {
    "text": "integrates directly with spot instances how many of you know what spot instances are most of the room so spot spot is",
    "start": "1146799",
    "end": "1153720"
  },
  {
    "text": "excess capacity that Amazon has and you bid for that capacity when uh the the um",
    "start": "1153720",
    "end": "1158919"
  },
  {
    "text": "you pay the market price for that capacity but Amazon can also the instances can also be terminated if the",
    "start": "1158919",
    "end": "1164919"
  },
  {
    "text": "if the price that you actually bid actually goes above so how do you use that to be able to save cost with Amazon",
    "start": "1164919",
    "end": "1171600"
  },
  {
    "text": "EMR it Amazon EMR directly integrates with spot in let me show you how right so this is a spot bid U graph for I",
    "start": "1171600",
    "end": "1178640"
  },
  {
    "text": "think cc2 8 extra large in VPC in Us East yeah so this is the graph this is",
    "start": "1178640",
    "end": "1185120"
  },
  {
    "text": "the on demand price you might think of bidding somewhere around the bid price your bid price can be 50% 100% any uh",
    "start": "1185120",
    "end": "1192799"
  },
  {
    "text": "whatever you want the bit price to be here's the integration it's pretty simple so like you your instances now",
    "start": "1192799",
    "end": "1199640"
  },
  {
    "text": "you can call these instances to be spot instances and you can describe a bit price when you go onto the console it",
    "start": "1199640",
    "end": "1204760"
  },
  {
    "text": "also shows you what are the instances available in multiple availability zones and what are the prices current prices",
    "start": "1204760",
    "end": "1210360"
  },
  {
    "text": "are you can go to the spot API you can also look at the pricing history the spot team also released this this new",
    "start": "1210360",
    "end": "1216960"
  },
  {
    "start": "1215000",
    "end": "1215000"
  },
  {
    "text": "feature called The Spot bid advisor what it does is it looks at you specify how",
    "start": "1216960",
    "end": "1222280"
  },
  {
    "text": "much you want to bid do you want to bid 50% on demand 100% On Demand and based upon that it gives you a hint on whether",
    "start": "1222280",
    "end": "1228760"
  },
  {
    "text": "you will be interrupted or not based upon prior 30-day or 7-Day uh experiences based upon this you can",
    "start": "1228760",
    "end": "1235600"
  },
  {
    "text": "actually choose oh do I what do I bid uh uh do I bid something on this do I not",
    "start": "1235600",
    "end": "1240640"
  },
  {
    "text": "bid on this do I use a different instance type and there are multiple different instance types uh within",
    "start": "1240640",
    "end": "1245799"
  },
  {
    "text": "Amazon so you have a lot of choice right so how does um a spot integration uh with EMR works you can",
    "start": "1245799",
    "end": "1252720"
  },
  {
    "start": "1249000",
    "end": "1249000"
  },
  {
    "text": "provision spot instances directly from an EMR cluster you can also when the spot instance is actually taken away",
    "start": "1252720",
    "end": "1259159"
  },
  {
    "text": "because of interruption we will replace it with a new spot instance at the same price as in when it becomes",
    "start": "1259159",
    "end": "1265840"
  },
  {
    "text": "available what so what is the impact of interruption now the impact of interruption is interesting because",
    "start": "1265840",
    "end": "1270880"
  },
  {
    "text": "Hadoop actually is is self-healing that means if a node goes down Hadoop can",
    "start": "1270880",
    "end": "1276000"
  },
  {
    "text": "actually restart the jobs on a different Noe and that is really interesting and that's why that integration works so",
    "start": "1276000",
    "end": "1281880"
  },
  {
    "text": "well with EMR if you have a master node running on uh on um uh spot and that",
    "start": "1281880",
    "end": "1287080"
  },
  {
    "text": "spot instance goes away you can lose the entire cluster if you core node then you might lose the intermediate data that is",
    "start": "1287080",
    "end": "1293400"
  },
  {
    "text": "sitting on the cluster but if you have task nodes for most of the applications except like no SQL stores like hbes you",
    "start": "1293400",
    "end": "1301039"
  },
  {
    "text": "will be able to re the Hadoop the yarn component will be able to resite restart those jobs as the nodes become available",
    "start": "1301039",
    "end": "1308039"
  },
  {
    "text": "or on a different uh uh or on a different Noe altogether so here's the advantage let's",
    "start": "1308039",
    "end": "1314200"
  },
  {
    "text": "say I have a 10 node cluster and this runs for 14 hours right and let's for",
    "start": "1314200",
    "end": "1319279"
  },
  {
    "text": "sake of simple math imagine that this node cost me a doll um um an hour so to",
    "start": "1319279",
    "end": "1326120"
  },
  {
    "text": "process this data for 14 hours it'll cost me $140 right let's say for an",
    "start": "1326120",
    "end": "1331919"
  },
  {
    "text": "example I added 10 more notes on spot instances let's say now I have a 20 Noe",
    "start": "1331919",
    "end": "1337559"
  },
  {
    "start": "1333000",
    "end": "1333000"
  },
  {
    "text": "cluster instead of a 10 node cluster let's say for example that my job running time now goes down from 14 hours",
    "start": "1337559",
    "end": "1344080"
  },
  {
    "text": "to 7 hours because now I have doubled the number of nodes so let's look at the econom ICS of this remember the first 10",
    "start": "1344080",
    "end": "1350240"
  },
  {
    "text": "notes that I was running for 14 hours now they run for 7 hours so I have I pay the same amount $70 let's say the new",
    "start": "1350240",
    "end": "1356640"
  },
  {
    "text": "noes I got it at 50% discount you if you look at the spot bit advisor you would see that you get notes at something like",
    "start": "1356640",
    "end": "1362919"
  },
  {
    "text": "80 to 90% discount but that's Market driven let's say for we assume that we get it at 50% discount so here I have 10",
    "start": "1362919",
    "end": "1370039"
  },
  {
    "text": "more nodes running at uh uh running for 7 hours so if you look at the total cost",
    "start": "1370039",
    "end": "1375279"
  },
  {
    "text": "that's $ 105 uh dollar so what I've done is I've run for half the time and I have saved",
    "start": "1375279",
    "end": "1382360"
  },
  {
    "text": "25% of the cost so what people do is what is the worst SLA that you can",
    "start": "1382360",
    "end": "1388279"
  },
  {
    "text": "afford for the business that's what they run on demand and every time they scale out with spot",
    "start": "1388279",
    "end": "1395120"
  },
  {
    "text": "and if they get the spot instances at the price that they want you will always save money and you will always always",
    "start": "1395120",
    "end": "1401640"
  },
  {
    "text": "finish your jobs faster that's the advantage of spot instances so we see a lot of our customers where they the",
    "start": "1401640",
    "end": "1408559"
  },
  {
    "text": "steady state workload runs on on demand and all the scale up happens to spot you",
    "start": "1408559",
    "end": "1413720"
  },
  {
    "text": "will also see that some customers actually run a lot complete infrastructure on",
    "start": "1413720",
    "end": "1419360"
  },
  {
    "text": "spot so here is an example of um a customer for it's an attech company and",
    "start": "1419360",
    "end": "1425440"
  },
  {
    "start": "1420000",
    "end": "1420000"
  },
  {
    "text": "somewhere in q1 of 2012 the discovered house spon senses worked and look at the usage goway today they run as uh as long",
    "start": "1425440",
    "end": "1433279"
  },
  {
    "text": "as500 to 2,000 clusters and about 6,000 jobs per day this is an open data this is from from Bloom reach uh engineering",
    "start": "1433279",
    "end": "1439919"
  },
  {
    "text": "website and the way they do it is they also have some orchestration built around it for example they do something",
    "start": "1439919",
    "end": "1445240"
  },
  {
    "text": "like this where they actually look at different instances and they look at what is the cheapest price they can get",
    "start": "1445240",
    "end": "1450960"
  },
  {
    "text": "on an instance and based upon that data they fire a cluster on that instance right so they now because the data",
    "start": "1450960",
    "end": "1457159"
  },
  {
    "text": "persist in in S3 they use compute as a fungible resource right whatever the",
    "start": "1457159",
    "end": "1462880"
  },
  {
    "text": "cheapest that is possible uh the code is is online it's called briefly uh you can look it up on uh on GitHub but it's very",
    "start": "1462880",
    "end": "1469360"
  },
  {
    "text": "it's really interesting but the thing that they had to do to really get to that level was to make sure that their",
    "start": "1469360",
    "end": "1475840"
  },
  {
    "text": "Hadoop clusters instance choices are Diversified right that means it works on",
    "start": "1475840",
    "end": "1481000"
  },
  {
    "text": "a long range of instances you can use it on M1 to C1 to c3s to C c2s the more",
    "start": "1481000",
    "end": "1487360"
  },
  {
    "text": "Diversified these are that means the more you can take advantage of the lower pricing spot gives you that's why 6,000",
    "start": "1487360",
    "end": "1493960"
  },
  {
    "text": "jobs a day or 2,000 to 3,000 clusters is possible on with really really low",
    "start": "1493960",
    "end": "1500720"
  },
  {
    "text": "cost let's talk about so we talked about scale up and being able to say save cost let's talk about scale down so what",
    "start": "1500720",
    "end": "1507320"
  },
  {
    "text": "happens when you scale down what happens when you scale down is we actually look at what's running on a cluster and we",
    "start": "1507320",
    "end": "1513200"
  },
  {
    "text": "wait for those jobs to finish before we take those nodes out so we allow you to specify a timeout if the timeout is",
    "start": "1513200",
    "end": "1520760"
  },
  {
    "text": "breached then we will get you to the capacity that you want but before the timeout we will not interrupt a running",
    "start": "1520760",
    "end": "1527000"
  },
  {
    "text": "job that might be running on a cluster so you can actually issue a issue a re uh resize to shrink a cluster and it'll",
    "start": "1527000",
    "end": "1534159"
  },
  {
    "text": "automatically gracefully shrink the cluster without actually running uh without actually impacting jobs so what",
    "start": "1534159",
    "end": "1540600"
  },
  {
    "text": "do we do for when there is uh hdfs so when there is hdfs we automatically make",
    "start": "1540600",
    "end": "1546399"
  },
  {
    "start": "1542000",
    "end": "1542000"
  },
  {
    "text": "sure that the decommissioning of hdfs which basically includes taking the data that is there in that hdfs node and",
    "start": "1546399",
    "end": "1552919"
  },
  {
    "text": "actually storing it somewhere else that happens to maintain the replication factor of the of the cluster right and",
    "start": "1552919",
    "end": "1559760"
  },
  {
    "text": "remember this htfs if you're using S3 this htfs is only being used for your intermediate data which is important but",
    "start": "1559760",
    "end": "1566760"
  },
  {
    "text": "if it completely fails you can rerun the job because your Source data is still lying on S3 so but this is very",
    "start": "1566760",
    "end": "1572559"
  },
  {
    "text": "conservative also that it does not uh uh go down on hdfs in terms of the size if",
    "start": "1572559",
    "end": "1579159"
  },
  {
    "text": "the replication factor is not met if there's a lot of iio going on or it might uh or if there is a chance of any",
    "start": "1579159",
    "end": "1585200"
  },
  {
    "text": "corruption so it be so it kind of helps you and secures you around removing nodes and not knowing what",
    "start": "1585200",
    "end": "1591360"
  },
  {
    "text": "what's happening on the hdfs so by using this by using an ability to scale up using spot and scale",
    "start": "1591360",
    "end": "1597840"
  },
  {
    "start": "1593000",
    "end": "1593000"
  },
  {
    "text": "down you can your load can go up something like this it follow it variable it follows the variable load",
    "start": "1597840",
    "end": "1604279"
  },
  {
    "text": "patterns that we see uh in a lot of organizations right what are the other",
    "start": "1604279",
    "end": "1609880"
  },
  {
    "start": "1608000",
    "end": "1608000"
  },
  {
    "text": "advantages of this the other advantages of this is that you don't need to have your entire doop stack running on one",
    "start": "1609880",
    "end": "1615960"
  },
  {
    "text": "particular cluster you can logically set separate concerns and from so you can have one Central S3 bucket and you can",
    "start": "1615960",
    "end": "1623200"
  },
  {
    "text": "have multiple people running jobs that are in completely different Stacks they can be running spark they can be",
    "start": "1623200",
    "end": "1629240"
  },
  {
    "text": "different teams they can be Dev team or test team some of them might be running hiber pig or you might have an important",
    "start": "1629240",
    "end": "1635080"
  },
  {
    "text": "customer that might you might be running the job on this is your production job that can be a separate cluster so you",
    "start": "1635080",
    "end": "1640679"
  },
  {
    "text": "know that one cluster is not thrashing against the other cluster also This Disaster Recovery",
    "start": "1640679",
    "end": "1646840"
  },
  {
    "start": "1645000",
    "end": "1645000"
  },
  {
    "text": "built in because s three is uh uh is uh distributed by default if you actually",
    "start": "1646840",
    "end": "1652919"
  },
  {
    "text": "end up losing a cluster or a complete availability Zone goes down all you need to do is point your script towards a",
    "start": "1652919",
    "end": "1659120"
  },
  {
    "text": "different availability Zone in fact if you did not specify an availability Zone your script would automatically select",
    "start": "1659120",
    "end": "1664480"
  },
  {
    "text": "the availability Zone and launch a cluster there and there is no change the data is still present there you can",
    "start": "1664480",
    "end": "1669640"
  },
  {
    "text": "still launch your clusters right so there is no price that you pay for creating a Dr a BCP Dr for your haduk",
    "start": "1669640",
    "end": "1677159"
  },
  {
    "text": "clusters so is there is there proof point for this are a lot of people actually running this yes you will see a lot of",
    "start": "1677159",
    "end": "1683880"
  },
  {
    "start": "1678000",
    "end": "1678000"
  },
  {
    "text": "people U talking about this so this is this is an excerpt that I took from uh the AWS Big Data blog which I'll highly",
    "start": "1683880",
    "end": "1690679"
  },
  {
    "text": "encourage you to check it's a technical blog that gets run out of the AWS team um this is written by Nate Nate who is a",
    "start": "1690679",
    "end": "1697679"
  },
  {
    "text": "principal architect of NASDAQ NASDAQ puts a lot of their data on S3 and uses",
    "start": "1697679",
    "end": "1702720"
  },
  {
    "text": "Presto on top of it to to analyze for ad hoc analysis in fact uh I think Nate",
    "start": "1702720",
    "end": "1708240"
  },
  {
    "text": "talk is just after my talk at at 3:30 but they he said that there are no hot spots because every object in S3 S3",
    "start": "1708240",
    "end": "1715760"
  },
  {
    "text": "being a distributed Object Store is exactly accessible as any other object S3 is infinite scalability it almost",
    "start": "1715760",
    "end": "1722760"
  },
  {
    "text": "gives you it gives you 119 of durability automatic Clause data center replication straightforward multi- region",
    "start": "1722760",
    "end": "1729240"
  },
  {
    "text": "replication life cycle policies and this has been proven by people like NASDAQ and Netflix and a lot of our customers",
    "start": "1729240",
    "end": "1736240"
  },
  {
    "text": "in fact if you see customers around you who have been using AMR you should ask them if they're using S3 or",
    "start": "1736240",
    "end": "1741279"
  },
  {
    "text": "not so let's quickly recap what we talked about we talked about rapid",
    "start": "1741279",
    "end": "1746320"
  },
  {
    "start": "1744000",
    "end": "1744000"
  },
  {
    "text": "provisioning of clusters we talked about that you can run multiple different stacks on Amazon EMR you can run hadoo",
    "start": "1746320",
    "end": "1752919"
  },
  {
    "text": "one and two you can run spark Presto and other applications as well you can we",
    "start": "1752919",
    "end": "1758000"
  },
  {
    "text": "base it on Open Source packaging so whatever you see is actually very similar to what's in the open source",
    "start": "1758000",
    "end": "1763200"
  },
  {
    "text": "tree but the core point if you want to take something back from this talk is the ability to decoupled storage and",
    "start": "1763200",
    "end": "1769080"
  },
  {
    "text": "compute we also allow you to resize clusters and manage manage demand also I",
    "start": "1769080",
    "end": "1774559"
  },
  {
    "text": "talked to you about how do you save cost by using spot instances so this is all Theory so here's I wanted to introduce",
    "start": "1774559",
    "end": "1782159"
  },
  {
    "text": "gorov Agarwal who's a senior software engineer at AOL G is going to talk about how they use these principles to move a",
    "start": "1782159",
    "end": "1788760"
  },
  {
    "text": "two petabyte Hadoop cluster from on premise to the AWS cloud and live to tell tell the tale got up thanks aate",
    "start": "1788760",
    "end": "1797760"
  },
  {
    "start": "1801000",
    "end": "1801000"
  },
  {
    "text": "so let's look at the architecture diagram we had last year it's pretty simple we had Source systems within a",
    "start": "1801640",
    "end": "1807559"
  },
  {
    "text": "data center our source is omniture logs uh which provides our clickstream data so",
    "start": "1807559",
    "end": "1814000"
  },
  {
    "text": "Source system pushed data to the Hadoop cluster and after the ETL operations were done the data was pushed to the",
    "start": "1814000",
    "end": "1819960"
  },
  {
    "text": "database all our users for adog queries or front-end reporting we're directly hitting the database instead of hitting",
    "start": "1819960",
    "end": "1827039"
  },
  {
    "text": "the cluster so the Le of the cluster expired early this year and we had to",
    "start": "1827039",
    "end": "1832640"
  },
  {
    "text": "explore options like Q3 last year either to extend the Lee or maybe explore Cloud",
    "start": "1832640",
    "end": "1839919"
  },
  {
    "text": "options we we had to consider a few data points in mind while uh deciding the migration process so the cluster size",
    "start": "1839919",
    "end": "1846679"
  },
  {
    "start": "1841000",
    "end": "1841000"
  },
  {
    "text": "was 2 petabytes compute wise we processed around 2 to three terabytes data per day there were 100 nodes so",
    "start": "1846679",
    "end": "1854159"
  },
  {
    "text": "like do we really need 100 nodes shall we ask ask for more number of nodes or",
    "start": "1854159",
    "end": "1860120"
  },
  {
    "text": "is there is do we need less number of nodes data ret retention was 13 to 24",
    "start": "1860120",
    "end": "1866080"
  },
  {
    "text": "months for different summaries and sometimes business were Keen to keep raw data even for like 36 months so the",
    "start": "1866080",
    "end": "1874440"
  },
  {
    "text": "first and obvious choice was to extend the lease but we had a multi-year experience with Hadoop cluster and we",
    "start": "1874440",
    "end": "1880519"
  },
  {
    "text": "knew it has its own challenges the first one is fixed cost so you enter into a commitment where you",
    "start": "1880519",
    "end": "1886679"
  },
  {
    "start": "1883000",
    "end": "1883000"
  },
  {
    "text": "are paying X number of dollars for a lot like uh multiple years storage and",
    "start": "1886679",
    "end": "1893279"
  },
  {
    "text": "compute were tightly coupled so even if you had to increase the retention of data for 36 months it would have come up",
    "start": "1893279",
    "end": "1899919"
  },
  {
    "text": "with the additional compute which we might not need the cluster was always running so",
    "start": "1899919",
    "end": "1906600"
  },
  {
    "text": "some everyone has issues so sometime if there are Source issues there is no data to process the cluster was running which",
    "start": "1906600",
    "end": "1912720"
  },
  {
    "text": "is not very resource and cost efficient we needed a model where we could try things on our own like for",
    "start": "1912720",
    "end": "1919279"
  },
  {
    "text": "example I don't want to use Hive I want to use spark I want to use Presto and sometimes it takes a lot of time in the",
    "start": "1919279",
    "end": "1926399"
  },
  {
    "text": "organizations to get those things done so we needed a model where we could try and test things on our own so a self Ser",
    "start": "1926399",
    "end": "1933159"
  },
  {
    "text": "model was needed the Hadoop cluster was not scalable so what I mean is there were",
    "start": "1933159",
    "end": "1939519"
  },
  {
    "text": "always 100 nodes so even for tiny data sets there were 100 notes and even for the larger volume there were always 100",
    "start": "1939519",
    "end": "1946600"
  },
  {
    "text": "notes so it was not scaling according to the data volume of the input size during production outages there",
    "start": "1946600",
    "end": "1953960"
  },
  {
    "text": "were no Alternatives and the whole reporting used to go down so for that much window basically users could not do",
    "start": "1953960",
    "end": "1961240"
  },
  {
    "text": "anything production upgrades like for example if there is a grade of High version it used to create a lot of uh",
    "start": "1961240",
    "end": "1969240"
  },
  {
    "text": "Dev and QA work because they had to ensure the new upgrade does not break anything so a lot of smoke testing was",
    "start": "1969240",
    "end": "1976000"
  },
  {
    "text": "done to ensure the upgrade go smooth then if you",
    "start": "1976000",
    "end": "1981840"
  },
  {
    "text": "combine all these things ultimately it used to result in slow deployment cycles",
    "start": "1981840",
    "end": "1986960"
  },
  {
    "text": "and it's mainly not because the code or the soft skills we did not have it's mainly because the infrastructure was",
    "start": "1986960",
    "end": "1993039"
  },
  {
    "text": "serving as a barrier so if we get a major project or major requirement we had to worry about compute we had to",
    "start": "1993039",
    "end": "1999360"
  },
  {
    "text": "worry about storage so uh that really slowed us down in some cases so we went",
    "start": "1999360",
    "end": "2006960"
  },
  {
    "text": "for the next option okay let's try Cloud went for a big data training tried few things and came up with the rough",
    "start": "2006960",
    "end": "2013519"
  },
  {
    "text": "architecture that Source system can directly put data to S3 an EMR cluster",
    "start": "2013519",
    "end": "2020000"
  },
  {
    "text": "can read data from S3 write data to back to S3 since we since the Lee of the",
    "start": "2020000",
    "end": "2027200"
  },
  {
    "text": "database we had the lease was still active so we went with the hybrid model",
    "start": "2027200",
    "end": "2032320"
  },
  {
    "text": "so we pull data from S3 on a machine load it to the database and the",
    "start": "2032320",
    "end": "2038039"
  },
  {
    "text": "historical data gets archived or deleted so try to have a static image of the diagram because we'll go into the",
    "start": "2038039",
    "end": "2044840"
  },
  {
    "text": "complexity of the same in next few slides so the training which we went we",
    "start": "2044840",
    "end": "2052200"
  },
  {
    "start": "2049000",
    "end": "2049000"
  },
  {
    "text": "spent our initial time on the web console so we got familiar with AWS services like how to upload data to S3",
    "start": "2052200",
    "end": "2060320"
  },
  {
    "text": "how to create an EMR how to run steps on EMR and I I would highly recommend to",
    "start": "2060320",
    "end": "2065398"
  },
  {
    "text": "try and test multiple things like for example try multiple applications multiple instance types and come up with",
    "start": "2065399",
    "end": "2071440"
  },
  {
    "text": "a design that suits you well and create the architecture diagram which needs the business purpose once you are",
    "start": "2071440",
    "end": "2078118"
  },
  {
    "text": "comfortable with this web console definitely try out CLI because for actual de Q workor CLI will make things",
    "start": "2078119",
    "end": "2085878"
  },
  {
    "text": "really fast so once we made a call that we are",
    "start": "2085879",
    "end": "2092280"
  },
  {
    "text": "not going to extend the lease and we'll move to the AWS one of the key task was to move the existing data we had our",
    "start": "2092280",
    "end": "2099880"
  },
  {
    "text": "cluster was 80 to 90% utilized so we had to move terabytes of data and we started",
    "start": "2099880",
    "end": "2106000"
  },
  {
    "text": "few with few naming conventions so what we did we created separate bucket for",
    "start": "2106000",
    "end": "2111160"
  },
  {
    "start": "2108000",
    "end": "2108000"
  },
  {
    "text": "each environment like for example Dev QA production we have a few analysts in the",
    "start": "2111160",
    "end": "2117200"
  },
  {
    "text": "team so we created a separate bucket for them as well within each environment we created separate bucket for projects",
    "start": "2117200",
    "end": "2124000"
  },
  {
    "text": "like for example code for actual queries and Scripts log to store the EMR logs",
    "start": "2124000",
    "end": "2130920"
  },
  {
    "text": "data to store the actual data uh control bucket to indicate that the processing",
    "start": "2130920",
    "end": "2136160"
  },
  {
    "text": "is done and since we had the hybrid model we created a bucket to indicate that the data can be now pulled over for",
    "start": "2136160",
    "end": "2143520"
  },
  {
    "text": "the database load we the data we had in house was Snappy compressed we converted",
    "start": "2143520",
    "end": "2150720"
  },
  {
    "text": "it to jzip one of the key reason we converted it to J because it supports multiple",
    "start": "2150720",
    "end": "2156880"
  },
  {
    "text": "platforms so like you can use red shift directly on top of gzip data and it also supported the database we",
    "start": "2156880",
    "end": "2163400"
  },
  {
    "text": "have it offered us best compression since we use S3 as a storage you",
    "start": "2163400",
    "end": "2168599"
  },
  {
    "text": "definitely don't want uncompressed data so by converting it to gzip it resulted",
    "start": "2168599",
    "end": "2174800"
  },
  {
    "text": "in like 76% Less storage which will directly save cost for you so to give an",
    "start": "2174800",
    "end": "2181280"
  },
  {
    "text": "example if you have one petabyte of data to store it snappy versus gzip gzip will",
    "start": "2181280",
    "end": "2186920"
  },
  {
    "text": "Le you 7 $1,000 per year so now we had the data on S3 now",
    "start": "2186920",
    "end": "2192920"
  },
  {
    "text": "the next question was what should our EMR look like so the first question do we need a",
    "start": "2192920",
    "end": "2199359"
  },
  {
    "start": "2195000",
    "end": "2195000"
  },
  {
    "text": "cluster up and running or can our clusters go away since the cluster was Hado cluster was mainly used for ETL",
    "start": "2199359",
    "end": "2206000"
  },
  {
    "text": "purpose we did not need a a persistent cluster all the time so we went with the",
    "start": "2206000",
    "end": "2212200"
  },
  {
    "text": "transient model and transient model has its own Advantage because the cluster is not up",
    "start": "2212200",
    "end": "2219000"
  },
  {
    "text": "all the time you have minimum maintenance to do and also you are paying only for what you use so if there",
    "start": "2219000",
    "end": "2224839"
  },
  {
    "text": "is no data basically you don't have any infrastructure and you're not paying for that between S3 and",
    "start": "2224839",
    "end": "2234880"
  },
  {
    "text": "sorry between S3 and local sdfs we use both of them so S3 works well when for",
    "start": "2239480",
    "end": "2247599"
  },
  {
    "text": "the normal EMR clusters but if we have data which is read again and again like",
    "start": "2247599",
    "end": "2253040"
  },
  {
    "text": "where we have iterative queries we realize that the performance of local hdfs is",
    "start": "2253040",
    "end": "2259560"
  },
  {
    "text": "better since we have variety of workloads like we have hourly jobs daily jobs weekly jobs we did not need 100",
    "start": "2259560",
    "end": "2267240"
  },
  {
    "text": "clusters for each kind of the data volume so we went with a model where",
    "start": "2267240",
    "end": "2272599"
  },
  {
    "text": "each cluster can have data nodes according to the input size between on demand reserved and spot to",
    "start": "2272599",
    "end": "2279839"
  },
  {
    "text": "be really cost effective which chose spot the only risk with the spot is that your clusters might be taken away but as",
    "start": "2279839",
    "end": "2287160"
  },
  {
    "text": "abishek mentioned there are a lot of things that you can put in place and if you if you follow smart Bing strategy",
    "start": "2287160",
    "end": "2293920"
  },
  {
    "text": "you can handle that as well between core and task nodes we ensure that we assign enough number of",
    "start": "2293920",
    "end": "2301280"
  },
  {
    "text": "nodes so that processing finish within an hour so it really did not matter to us whether we choose score our task and",
    "start": "2301280",
    "end": "2309040"
  },
  {
    "text": "we went with the core nodes because it has additional advantage of uh local hdfs so let's look at the architecture",
    "start": "2309040",
    "end": "2316119"
  },
  {
    "text": "diagram again so this is the state where we don't have anything to process there is",
    "start": "2316119",
    "end": "2322240"
  },
  {
    "start": "2317000",
    "end": "2317000"
  },
  {
    "text": "persistent S3 for storage as data is available from The Source system an EMR",
    "start": "2322240",
    "end": "2327480"
  },
  {
    "text": "cluster comes up the ETL operations are done data is written back to S3 and the",
    "start": "2327480",
    "end": "2332599"
  },
  {
    "text": "cluster goes away now if you have multiple files or uh you have multiple",
    "start": "2332599",
    "end": "2338640"
  },
  {
    "text": "files of different volume multiple clusters are provisioned each cluster will have number of nodes as per the",
    "start": "2338640",
    "end": "2345520"
  },
  {
    "text": "input data after the etail operations are done all the Clusters will go away",
    "start": "2345520",
    "end": "2350800"
  },
  {
    "text": "so it's a true on demand design which has transient clusters making use of spot instances to be really cost",
    "start": "2350800",
    "end": "2357680"
  },
  {
    "text": "effective and if you also notice one more thing here the operations are Loosely coupled so suppose if the loads",
    "start": "2357680",
    "end": "2364319"
  },
  {
    "text": "are running slow on our database side or there is a maintenance the Emi clusters are not waiting for the load process the",
    "start": "2364319",
    "end": "2372000"
  },
  {
    "text": "Emi cluster clusters are still creating summaries and once the database issue is",
    "start": "2372000",
    "end": "2377319"
  },
  {
    "text": "resolved the loads can catch up quickly so that's the architecture diagram we have followed now to to automate the",
    "start": "2377319",
    "end": "2385680"
  },
  {
    "start": "2384000",
    "end": "2384000"
  },
  {
    "text": "whole flow we had to create few utilities on our side so for scheduling",
    "start": "2385680",
    "end": "2391359"
  },
  {
    "start": "2391000",
    "end": "2391000"
  },
  {
    "text": "the jobs we use in our Schuler because we still have active license for that we",
    "start": "2391359",
    "end": "2397160"
  },
  {
    "text": "we we created few common utilities like how to provision the EMR we had to create a utility to pull data from S3",
    "start": "2397160",
    "end": "2404560"
  },
  {
    "text": "for or database load there are few business Dimensions so to push data to",
    "start": "2404560",
    "end": "2411400"
  },
  {
    "text": "S3 to submit the jobs to the schuer because the normal EMR CLI commands are",
    "start": "2411400",
    "end": "2417480"
  },
  {
    "text": "not were not understood by our Schuler we modified our database utility because we changed the compression to",
    "start": "2417480",
    "end": "2424760"
  },
  {
    "text": "gzip so all the options that abish show showed you initially we broke them down into separate joons because if if you",
    "start": "2424760",
    "end": "2432480"
  },
  {
    "text": "want different applications or different steps for each application different ec2",
    "start": "2432480",
    "end": "2437560"
  },
  {
    "text": "attributes you can modify either of those without impacting the other one Improvement we are working on it is to",
    "start": "2437560",
    "end": "2445040"
  },
  {
    "text": "make it event driven design so instead of making use of schedular as soon as a file is put to S3 and EMR cluster can",
    "start": "2445040",
    "end": "2452240"
  },
  {
    "text": "come up come up or as soon as the processing of EMR is done the data can",
    "start": "2452240",
    "end": "2457440"
  },
  {
    "text": "extracted for the database load so Lambda and sqs are the services we are",
    "start": "2457440",
    "end": "2464280"
  },
  {
    "text": "trying this is a sample code so all the highlighted ones are the different",
    "start": "2465599",
    "end": "2470839"
  },
  {
    "text": "configuration files which we use as Jon for identify like instance group E2",
    "start": "2470839",
    "end": "2476880"
  },
  {
    "text": "attributes what steps to run and what bootstrap action should be",
    "start": "2476880",
    "end": "2482480"
  },
  {
    "text": "there now to since we automated the flow we had hundreds of clusters so roughly",
    "start": "2482480",
    "end": "2488720"
  },
  {
    "text": "we have 8 or 900 8 to 900 clusters each day and to monitor this we really needed",
    "start": "2488720",
    "end": "2495280"
  },
  {
    "start": "2495000",
    "end": "2495000"
  },
  {
    "text": "something custom so one of my teammate developed a code in nodejs called watch",
    "start": "2495280",
    "end": "2501800"
  },
  {
    "text": "doog so what it does it does things like identifying duplicate clusters based on the unique naming convention we follow",
    "start": "2501800",
    "end": "2509400"
  },
  {
    "text": "it also notifies when there is a filled cluster like for example one of your step has filled or your master has been",
    "start": "2509400",
    "end": "2516040"
  },
  {
    "text": "taken away we ensure that our clusters finish within an hour so if there are",
    "start": "2516040",
    "end": "2521760"
  },
  {
    "text": "clusters which are crossing 1 hour limit notifications are sent and since we make use of spot sometimes the provisioning",
    "start": "2521760",
    "end": "2529079"
  },
  {
    "text": "might take time so long provisional clusters are also notified you can also make use of a Few",
    "start": "2529079",
    "end": "2536440"
  },
  {
    "text": "cloudwatch alarms to ensure that you are within your monthly budget and you don't want your S3 buckets to grow huge like",
    "start": "2536440",
    "end": "2542920"
  },
  {
    "text": "for example you don't want terabytes of data in your D QA bucket you can create alarms for those as well for the",
    "start": "2542920",
    "end": "2549680"
  },
  {
    "text": "notifications we make use of SNS email and uh you can also choose different",
    "start": "2549680",
    "end": "2556599"
  },
  {
    "text": "endpoints like for example SMS or you can redirect to a web service but we make use of email mostly now during",
    "start": "2556599",
    "end": "2564359"
  },
  {
    "text": "challenges I mentioned to you about production outages and scalability so",
    "start": "2564359",
    "end": "2569960"
  },
  {
    "start": "2569000",
    "end": "2569000"
  },
  {
    "text": "those are the key reasons that you need to be lastic I'll show you few different graphs from the for the code we had",
    "start": "2569960",
    "end": "2577800"
  },
  {
    "text": "across multiple days one one back so this is the graph from 5th September",
    "start": "2577800",
    "end": "2583640"
  },
  {
    "text": "where we had no issues there were early jobs early in the morning there is a spike because that's expected we have a",
    "start": "2583640",
    "end": "2590319"
  },
  {
    "text": "daily job running two weeks back we had issues around 6:00 a.m. so there were no",
    "start": "2590319",
    "end": "2595640"
  },
  {
    "text": "cluster running for multiple hours and once the issues were resolved there is a spike in the demand because now the",
    "start": "2595640",
    "end": "2602119"
  },
  {
    "text": "backlog is catching up or you can have a day like 1st of June where we needed",
    "start": "2602119",
    "end": "2607800"
  },
  {
    "text": "around thousands of E2 instances within like within uh 3 4 hours so to handle",
    "start": "2607800",
    "end": "2614400"
  },
  {
    "text": "situations like this you need a design where infrastructure can come up as as",
    "start": "2614400",
    "end": "2620520"
  },
  {
    "text": "needed and that's the principle behind the uh Cloud so if if you're making use",
    "start": "2620520",
    "end": "2626280"
  },
  {
    "text": "of spot which is an open market where the resources not are not guaranteed",
    "start": "2626280",
    "end": "2632079"
  },
  {
    "text": "it's very important that you diversify your strategy so instead of putting everything in the same region try to",
    "start": "2632079",
    "end": "2639119"
  },
  {
    "text": "scale horizontally so what we did we put a hard limit of 3,000 ec2 for a",
    "start": "2639119",
    "end": "2645280"
  },
  {
    "text": "particular instance type in a region and if we reach that limit we switch to next",
    "start": "2645280",
    "end": "2650680"
  },
  {
    "text": "region since AWS has multiple regions we could have like we had thousands of V2s",
    "start": "2650680",
    "end": "2656599"
  },
  {
    "text": "across multiple regions but in case you don't get enough capacity because of your defined limit you can even switch",
    "start": "2656599",
    "end": "2664119"
  },
  {
    "text": "the instance type so that's how we ensured that whatever demand we had we",
    "start": "2664119",
    "end": "2670440"
  },
  {
    "text": "can meet it by making our infrastructure elastic and if you're making your",
    "start": "2670440",
    "end": "2676160"
  },
  {
    "text": "infrastructure in multiple regions it's very important that you control your cost as well",
    "start": "2676160",
    "end": "2683040"
  },
  {
    "start": "2678000",
    "end": "2678000"
  },
  {
    "text": "so try to identify the cheapest AZ because price of a particular instance",
    "start": "2683040",
    "end": "2688079"
  },
  {
    "text": "type can vary a lot between different AZ so choose cheapest ay so that you can",
    "start": "2688079",
    "end": "2693280"
  },
  {
    "text": "control the cost and by being elastic you designed for the failure as well so",
    "start": "2693280",
    "end": "2698800"
  },
  {
    "text": "you have created Alternatives if one of the services of AWS has some issues issues now you can switch to next region",
    "start": "2698800",
    "end": "2706440"
  },
  {
    "text": "and being Global you we also ensured that if there is a disaster or uh if",
    "start": "2706440",
    "end": "2713559"
  },
  {
    "text": "something goes wrong or business continues let me talk about few optimization tips so if try to partition",
    "start": "2713559",
    "end": "2721800"
  },
  {
    "start": "2718000",
    "end": "2718000"
  },
  {
    "text": "your data on S3 so that you can read only what you need make use of uh",
    "start": "2721800",
    "end": "2727000"
  },
  {
    "text": "versioning a life cycle to ensure that you have multiple versions of like code or to Archive the data you can set life",
    "start": "2727000",
    "end": "2735119"
  },
  {
    "text": "cycle policies assign the number of nodes based on the data volume and also try to",
    "start": "2735119",
    "end": "2741960"
  },
  {
    "text": "ensure that you make the complete use of the hour because if you use partial hour",
    "start": "2741960",
    "end": "2747319"
  },
  {
    "text": "you'll be still charged for the full hour you can tune few runtime parameters for Hadoop like for example memory you",
    "start": "2747319",
    "end": "2755280"
  },
  {
    "text": "can compress the map and reduce output you if you have multiple files and you don't want too many mappers you can",
    "start": "2755280",
    "end": "2761599"
  },
  {
    "text": "combine the input files for security if you're making use of transient clusters uh you don't even",
    "start": "2761599",
    "end": "2768960"
  },
  {
    "text": "need key pair for because no one needs to SSH to the transient cluster so you",
    "start": "2768960",
    "end": "2774240"
  },
  {
    "text": "can have keyless clusters and transient or persistent try to make use of EMR",
    "start": "2774240",
    "end": "2780839"
  },
  {
    "text": "roles so that people don't have access to production buckets or they don't Rite to the production buckets accidentally",
    "start": "2780839",
    "end": "2788000"
  },
  {
    "start": "2788000",
    "end": "2788000"
  },
  {
    "text": "gently so we spoke about the challenges we had last year and this is where we are now now we are paying for what we",
    "start": "2788000",
    "end": "2795040"
  },
  {
    "text": "use by using transient clusters we have decoupled our storage and compute we",
    "start": "2795040",
    "end": "2800599"
  },
  {
    "text": "have on demand design we have a self-service model where we can try things on our own our infrastructure is",
    "start": "2800599",
    "end": "2806839"
  },
  {
    "text": "elastic scalable and it's available globally because we have used multi-",
    "start": "2806839",
    "end": "2812079"
  },
  {
    "text": "region deployment and all these things have resulted in quick and easy deployments because we are not worrying",
    "start": "2812079",
    "end": "2817480"
  },
  {
    "text": "about the infrastructure anymore few features that would have been helpful to us is like for example reading uh having",
    "start": "2817480",
    "end": "2825400"
  },
  {
    "text": "external tables on top of S3 for red shift I know they launched the Lambda",
    "start": "2825400",
    "end": "2830640"
  },
  {
    "text": "for python today so this slide is kind old already old so with so much benefits and",
    "start": "2830640",
    "end": "2838520"
  },
  {
    "start": "2835000",
    "end": "2835000"
  },
  {
    "text": "improved efficiency we have managed to keep our costs low so our monthly AWS building is",
    "start": "2838520",
    "end": "2845280"
  },
  {
    "text": "almost 25% of what we used to pay before so if you have approved budget you can",
    "start": "2845280",
    "end": "2851920"
  },
  {
    "text": "reach out to the business and put three times more workload and that's that's",
    "start": "2851920",
    "end": "2857800"
  },
  {
    "text": "how we pay them and the best thing is we have the budget approved and the rest of the 34th is going to me to keep me",
    "start": "2857800",
    "end": "2866520"
  },
  {
    "text": "motivated so let me talk about the restatement",
    "start": "2866599",
    "end": "2872839"
  },
  {
    "text": "so on 1st of June business asked us to restate data going back 6 months for",
    "start": "2877200",
    "end": "2883200"
  },
  {
    "text": "that particular use case we needed around 24,000 dc2 instances using",
    "start": "2883200",
    "end": "2888680"
  },
  {
    "text": "multiple multiple region deployment we spread our requirement across 10 A's",
    "start": "2888680",
    "end": "2895480"
  },
  {
    "text": "across three regions of us and they were roughly 550 clusters running so for a",
    "start": "2895480",
    "end": "2901079"
  },
  {
    "text": "request like this initially when like business used to ask us we would be like",
    "start": "2901079",
    "end": "2908200"
  },
  {
    "text": "uh wait wait wait uh do we have enough compute we have enough storage or there used to be a lot of discussion and",
    "start": "2908200",
    "end": "2915160"
  },
  {
    "text": "ultimately it used to take us like weeks and months to do it in house but using",
    "start": "2915160",
    "end": "2920400"
  },
  {
    "text": "AWS we finished that within hours that was 60 times faster so it it it's really",
    "start": "2920400",
    "end": "2927200"
  },
  {
    "text": "the first time that we put our design to the test and it worked out really well where we provided things to the business",
    "start": "2927200",
    "end": "2934520"
  },
  {
    "text": "cheaply and very like quickly because business did not have options",
    "start": "2934520",
    "end": "2939799"
  },
  {
    "text": "before they they had to wait weeks and months and in that time sometimes even",
    "start": "2939799",
    "end": "2945079"
  },
  {
    "text": "the requirement had changed and the initial data was not even provided so that's the key win that happened to us",
    "start": "2945079",
    "end": "2952240"
  },
  {
    "text": "because of moving to the cloud there are few practic and",
    "start": "2952240",
    "end": "2957440"
  },
  {
    "start": "2955000",
    "end": "2955000"
  },
  {
    "text": "suggestions that I would like to mention from the experience I have so tag everything tag all your resources I know",
    "start": "2957440",
    "end": "2964359"
  },
  {
    "text": "it's going to be compulsory using uh you can make it compulsory by using rules that they launched yesterday uh if you",
    "start": "2964359",
    "end": "2971040"
  },
  {
    "text": "want to be cost effective definitely try spot instances they are 80 to 90%",
    "start": "2971040",
    "end": "2976960"
  },
  {
    "text": "discounted and the only risk you have is they might be taken away but don't worry",
    "start": "2976960",
    "end": "2982240"
  },
  {
    "text": "they never go away uh infrastructure as a code try to um make utilities and try",
    "start": "2982240",
    "end": "2989760"
  },
  {
    "text": "to make use of sdks so that you can provision infrastructure make heavy use of rules",
    "start": "2989760",
    "end": "2996280"
  },
  {
    "text": "and polic IES obviously for the security purpose if you have transient clusters don't put key key on them for security",
    "start": "2996280",
    "end": "3003920"
  },
  {
    "text": "try to scale horizontally so instead of have bumping up the resources in the same uh",
    "start": "3003920",
    "end": "3009880"
  },
  {
    "text": "cluster uh try to break down your task so that you can scale horizontally have",
    "start": "3009880",
    "end": "3015480"
  },
  {
    "text": "applications which are Loosely coupled don't don't keep applications dependent on each other there are few other things",
    "start": "3015480",
    "end": "3023200"
  },
  {
    "text": "uh like enable cloud trail use SNS for notif ifications try to use multiactor",
    "start": "3023200",
    "end": "3029599"
  },
  {
    "text": "authentication uh enable debugging and uh if if it applies to you definitely",
    "start": "3029599",
    "end": "3036599"
  },
  {
    "text": "try out the hybrid model I think that's it thank you uh we",
    "start": "3036599",
    "end": "3042599"
  },
  {
    "text": "have time for a few questions",
    "start": "3042599",
    "end": "3046599"
  }
]
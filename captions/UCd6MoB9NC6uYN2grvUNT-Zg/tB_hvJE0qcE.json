[
  {
    "start": "0",
    "end": "20000"
  },
  {
    "text": "- [Narrator] In this video,\nyou'll learn how to join data",
    "start": "630",
    "end": "2450"
  },
  {
    "text": "from AWS Data Exchange with\nyour data in Amazon Redshift.",
    "start": "2450",
    "end": "6270"
  },
  {
    "text": "Using the methods shown, you\ncan export third party data",
    "start": "6270",
    "end": "8720"
  },
  {
    "text": "from AWS Data Exchange",
    "start": "8720",
    "end": "10220"
  },
  {
    "text": "directly to Amazon Simple Storage Service",
    "start": "10220",
    "end": "12220"
  },
  {
    "text": "or Amazon S3, create an\nexternal schema for this data,",
    "start": "12220",
    "end": "15750"
  },
  {
    "text": "and run queries on this data\nfrom your Redshift cluster.",
    "start": "15750",
    "end": "18550"
  },
  {
    "start": "20000",
    "end": "142000"
  },
  {
    "text": "Before proceeding with the demo,",
    "start": "20480",
    "end": "21810"
  },
  {
    "text": "let's cover some prerequisites.",
    "start": "21810",
    "end": "23760"
  },
  {
    "text": "We'll be using Redshift\nSpectrum to join data",
    "start": "23760",
    "end": "25900"
  },
  {
    "text": "we export to Amazon S3 with\ndata in a Redshift cluster.",
    "start": "25900",
    "end": "29439"
  },
  {
    "text": "Therefore, we need a Redshift cluster.",
    "start": "29440",
    "end": "31340"
  },
  {
    "text": "Let's navigate to an\nAmazon Redshift cluster",
    "start": "32200",
    "end": "34190"
  },
  {
    "text": "we have already set up for this example.",
    "start": "34190",
    "end": "36730"
  },
  {
    "text": "We'll be using redshift-cluster-2.",
    "start": "36730",
    "end": "38603"
  },
  {
    "text": "We have also already\ncreated an AWS Identity",
    "start": "39990",
    "end": "42540"
  },
  {
    "text": "and Access Management, or IAM role,",
    "start": "42540",
    "end": "44630"
  },
  {
    "text": "and attached it to this cluster.",
    "start": "44630",
    "end": "46440"
  },
  {
    "text": "Let's find the role in the properties tab.",
    "start": "46440",
    "end": "48539"
  },
  {
    "text": "Here's the role. Let's drill down.",
    "start": "51870",
    "end": "53613"
  },
  {
    "text": "The role permissions provide\nfull access to Amazon S3",
    "start": "55050",
    "end": "58190"
  },
  {
    "text": "where we need to export\nthe third party data",
    "start": "58190",
    "end": "60050"
  },
  {
    "text": "from our Amazon Data Exchange Subscription",
    "start": "60050",
    "end": "62290"
  },
  {
    "text": "and to Amazon Redshift and\nthe AWS Glue Data Catalog.",
    "start": "62290",
    "end": "65493"
  },
  {
    "text": "Next, let's navigate to AWS Data Exchange",
    "start": "66970",
    "end": "69620"
  },
  {
    "text": "to see the third party subscription\nand data we'll be using.",
    "start": "69620",
    "end": "72690"
  },
  {
    "text": "For this demo, we'll be using\na data set with Amazon S3",
    "start": "72690",
    "end": "75620"
  },
  {
    "text": "as the delivery method.",
    "start": "75620",
    "end": "76770"
  },
  {
    "text": "Here is the entitled data\nfrom our subscription.",
    "start": "78900",
    "end": "80990"
  },
  {
    "text": "Let's expand it.",
    "start": "80990",
    "end": "81833"
  },
  {
    "text": "We have multiple revisions.",
    "start": "84200",
    "end": "85810"
  },
  {
    "text": "For this video, we'll be\nusing the July seven revision.",
    "start": "85810",
    "end": "88713"
  },
  {
    "text": "We need to export this data\ninto our Amazon S3 bucket.",
    "start": "90530",
    "end": "93450"
  },
  {
    "text": "We will manually export it.",
    "start": "93450",
    "end": "95280"
  },
  {
    "text": "You can also use the\nautomatic data export feature",
    "start": "95280",
    "end": "97640"
  },
  {
    "text": "to automatically receive data",
    "start": "97640",
    "end": "99010"
  },
  {
    "text": "from future revisions directly\ninto your Amazon S3 bucket.",
    "start": "99010",
    "end": "102023"
  },
  {
    "text": "Let's specify our Amazon S3 bucket",
    "start": "104090",
    "end": "106000"
  },
  {
    "text": "and the folder that we want\nthe data to be exported to.",
    "start": "106000",
    "end": "108633"
  },
  {
    "text": "Let's keep the default options selected",
    "start": "116360",
    "end": "118190"
  },
  {
    "text": "and export the data.",
    "start": "118190",
    "end": "119283"
  },
  {
    "text": "Now that the job has completed",
    "start": "124960",
    "end": "126220"
  },
  {
    "text": "and the revision has been exported to S3,",
    "start": "126220",
    "end": "128390"
  },
  {
    "text": "we'll go to Amazon S3 to see the data.",
    "start": "128390",
    "end": "130433"
  },
  {
    "text": "Let's find the bucket and folder\nthat we specified earlier.",
    "start": "134280",
    "end": "137230"
  },
  {
    "start": "142000",
    "end": "239000"
  },
  {
    "text": "We have exported the data successfully.",
    "start": "142670",
    "end": "145000"
  },
  {
    "text": "Now we must catalog the data\nin AWS Glue Data Catalog.",
    "start": "145000",
    "end": "148630"
  },
  {
    "text": "Once we've done that,",
    "start": "148630",
    "end": "149670"
  },
  {
    "text": "we will be able to\ncreate an external schema",
    "start": "149670",
    "end": "151530"
  },
  {
    "text": "and query the data\nusing Redshift Spectrum.",
    "start": "151530",
    "end": "153693"
  },
  {
    "text": "For our purposes, we'll create a table",
    "start": "156410",
    "end": "157980"
  },
  {
    "text": "in the Glue Data Catalog\nusing a glue crawler.",
    "start": "157980",
    "end": "161030"
  },
  {
    "text": "Glue crawlers can scan data\nin all kinds of repositories,",
    "start": "161030",
    "end": "163470"
  },
  {
    "text": "classify it, extract\nschema information from it,",
    "start": "163470",
    "end": "166560"
  },
  {
    "text": "and store the metadata automatically",
    "start": "166560",
    "end": "168340"
  },
  {
    "text": "in the AWS Glue Data Catalog.",
    "start": "168340",
    "end": "170443"
  },
  {
    "text": "Let's create a new crawler.",
    "start": "172530",
    "end": "173880"
  },
  {
    "text": "Let's specify a name for the crawler.",
    "start": "174920",
    "end": "176770"
  },
  {
    "text": "Let's retain the default\nsource type settings.",
    "start": "180680",
    "end": "182980"
  },
  {
    "text": "Here, we'll provide the Amazon S3 path",
    "start": "186210",
    "end": "188160"
  },
  {
    "text": "where the data we exported is stored.",
    "start": "188160",
    "end": "190010"
  },
  {
    "text": "For this demo, we will\nuse just one data source.",
    "start": "199847",
    "end": "202483"
  },
  {
    "text": "Next, we'll choose an IAM role.",
    "start": "204580",
    "end": "206640"
  },
  {
    "text": "This IAM role will grant\nthe AWS Glue Service",
    "start": "206640",
    "end": "209310"
  },
  {
    "text": "access to the files in Amazon S3.",
    "start": "209310",
    "end": "211523"
  },
  {
    "text": "We'll retain the default\nfrequency setting.",
    "start": "215320",
    "end": "217470"
  },
  {
    "text": "We can optionally create a new database",
    "start": "219057",
    "end": "220850"
  },
  {
    "text": "as part of this process.",
    "start": "220850",
    "end": "222480"
  },
  {
    "text": "For our purposes,",
    "start": "222480",
    "end": "223340"
  },
  {
    "text": "we'll use a database that\nhas already been created.",
    "start": "223340",
    "end": "225890"
  },
  {
    "text": "Let's review our options and\nfinish setting up the crawler.",
    "start": "227650",
    "end": "230592"
  },
  {
    "text": "Next, we'll run the crawler.",
    "start": "232970",
    "end": "234393"
  },
  {
    "start": "239000",
    "end": "369000"
  },
  {
    "text": "The crawler has finished running.",
    "start": "239710",
    "end": "241360"
  },
  {
    "text": "Notice that one table was\nadded to the database.",
    "start": "241360",
    "end": "243830"
  },
  {
    "text": "Let's take a quick look at it.",
    "start": "243830",
    "end": "245330"
  },
  {
    "text": "Let's drill down.",
    "start": "247070",
    "end": "248083"
  },
  {
    "text": "The table points to the Amazon S3 location",
    "start": "250220",
    "end": "252370"
  },
  {
    "text": "where the file we exported",
    "start": "252370",
    "end": "253500"
  },
  {
    "text": "from AWS Data Exchange is located.",
    "start": "253500",
    "end": "256019"
  },
  {
    "text": "Next, we'll connect to our\nAmazon Redshift cluster.",
    "start": "256020",
    "end": "258569"
  },
  {
    "text": "We'll use version two of the query editor.",
    "start": "260450",
    "end": "262563"
  },
  {
    "text": "Let's connect to our database.",
    "start": "264610",
    "end": "266110"
  },
  {
    "text": "We'll edit the connection",
    "start": "269230",
    "end": "270160"
  },
  {
    "text": "using the default username and database.",
    "start": "270160",
    "end": "272253"
  },
  {
    "text": "Our Redshift cluster has an\nempty database called dev.",
    "start": "274070",
    "end": "277170"
  },
  {
    "text": "It's empty at the moment,\nbut we can add data to it.",
    "start": "277170",
    "end": "279770"
  },
  {
    "text": "Let's paste in a command that\nwill create an external schema",
    "start": "281930",
    "end": "284380"
  },
  {
    "text": "to connect to our data\nin the Amazon S3 bucket.",
    "start": "284380",
    "end": "286813"
  },
  {
    "text": "Let's run this command.",
    "start": "289340",
    "end": "290490"
  },
  {
    "text": "If we refresh the Redshift clusters,",
    "start": "291930",
    "end": "293690"
  },
  {
    "text": "we should be able to see our data.",
    "start": "293690",
    "end": "295390"
  },
  {
    "text": "Here's the data that we created",
    "start": "301060",
    "end": "302389"
  },
  {
    "text": "when we ran the glue crawler.",
    "start": "302390",
    "end": "304100"
  },
  {
    "text": "Now we can run another command",
    "start": "304100",
    "end": "305460"
  },
  {
    "text": "on this table and see its results.",
    "start": "305460",
    "end": "307160"
  },
  {
    "text": "Here are the results of\nthe query we just ran.",
    "start": "310600",
    "end": "312910"
  },
  {
    "text": "As you can see, by using\nan external schema,",
    "start": "312910",
    "end": "315320"
  },
  {
    "text": "you are able to directly query your data",
    "start": "315320",
    "end": "317100"
  },
  {
    "text": "in Amazon S3 via Redshift Spectrum.",
    "start": "317100",
    "end": "319473"
  },
  {
    "text": "Now, let's see how Redshift\nSpectrum can be used",
    "start": "320750",
    "end": "322840"
  },
  {
    "text": "to join your data in Amazon\nS3 with your data in Redshift.",
    "start": "322840",
    "end": "326360"
  },
  {
    "text": "Let's create a table\nin our Redshift cluster",
    "start": "326360",
    "end": "328189"
  },
  {
    "text": "to demonstrate this.",
    "start": "328190",
    "end": "329223"
  },
  {
    "text": "Here's the table we just created.",
    "start": "333320",
    "end": "335010"
  },
  {
    "text": "Next, we'll insert some\ndata into this table.",
    "start": "335010",
    "end": "337260"
  },
  {
    "text": "Here's the data.",
    "start": "340500",
    "end": "341880"
  },
  {
    "text": "We can also run a query to get account",
    "start": "341880",
    "end": "343560"
  },
  {
    "text": "of the records we just created.",
    "start": "343560",
    "end": "345110"
  },
  {
    "text": "Next, let's run a query that\nwill join the company data",
    "start": "347910",
    "end": "350440"
  },
  {
    "text": "with the data table that\nexists in Amazon S3.",
    "start": "350440",
    "end": "352943"
  },
  {
    "text": "As you can see, we were\nable to join the data",
    "start": "355140",
    "end": "357060"
  },
  {
    "text": "in Amazon S3 with data\nin Redshift successfully.",
    "start": "357060",
    "end": "360490"
  },
  {
    "text": "You can also load data from Amazon S3",
    "start": "360490",
    "end": "362610"
  },
  {
    "text": "into your Redshift cluster\nusing a copy command",
    "start": "362610",
    "end": "364990"
  },
  {
    "text": "and natively join the two sets of data.",
    "start": "364990",
    "end": "366940"
  },
  {
    "start": "369000",
    "end": "383000"
  },
  {
    "text": "You've just seen how you\ncan join third party data",
    "start": "370260",
    "end": "372320"
  },
  {
    "text": "from AWS Data Exchange with\nyour data in Amazon Redshift.",
    "start": "372320",
    "end": "375743"
  },
  {
    "text": "You can learn more about this topic",
    "start": "376730",
    "end": "378030"
  },
  {
    "text": "in the description and\nlinks for this video.",
    "start": "378030",
    "end": "379920"
  },
  {
    "text": "Thanks for watching.",
    "start": "379920",
    "end": "380753"
  },
  {
    "text": "Now it's your turn to try.",
    "start": "380753",
    "end": "382050"
  }
]
[
  {
    "text": "thanks for coming out and participating in our talk today my name is Tom Jones",
    "start": "0",
    "end": "5330"
  },
  {
    "text": "actually my nickname is Elvis Tom Jones and Elvis both seems appropriate for",
    "start": "5330",
    "end": "11160"
  },
  {
    "text": "being on stage in Las Vegas so I hope everybody's having a good time today",
    "start": "11160",
    "end": "16350"
  },
  {
    "text": "we're gonna dive into some deep learning here and I'm gonna have Diego come out",
    "start": "16350",
    "end": "23490"
  },
  {
    "text": "and talk about his company algorithm-- yeah and the things that they're doing to make deep learning accessible to",
    "start": "23490",
    "end": "29550"
  },
  {
    "text": "everyone but first I want to provide a little bit of context so we've seen this",
    "start": "29550",
    "end": "38149"
  },
  {
    "text": "in some of the announcements today but highlighting the pace of innovation at AWS right we can see that the trend line",
    "start": "38149",
    "end": "45899"
  },
  {
    "text": "here obviously this is going to need to be updated after all the announcements we've had this week but AWS has a",
    "start": "45899",
    "end": "54629"
  },
  {
    "text": "furious pace of innovation and so if we start looking at trends we see this pace",
    "start": "54629",
    "end": "60329"
  },
  {
    "text": "of innovation trend and then we've seen other types of trends as well so we're",
    "start": "60329",
    "end": "67170"
  },
  {
    "text": "seeing a rapid adoption of things like micro services using serverless",
    "start": "67170",
    "end": "72330"
  },
  {
    "text": "architectures with services like AWS lamda API gateway using containers right",
    "start": "72330",
    "end": "80610"
  },
  {
    "text": "all of these provide pay-as-you-go scalability another trend that we're",
    "start": "80610",
    "end": "88290"
  },
  {
    "text": "seeing is a huge amount of interest in uptake in machine learning to drive",
    "start": "88290",
    "end": "94770"
  },
  {
    "text": "things like predictive analysis and things like generative design and the",
    "start": "94770",
    "end": "101189"
  },
  {
    "text": "equations really really simple you can build a smart application by leveraging",
    "start": "101189",
    "end": "106770"
  },
  {
    "text": "your existing data and machine learning and we're gonna see how algorithm it can help with them tying in with these",
    "start": "106770",
    "end": "116369"
  },
  {
    "text": "trends in this pace of innovation AWS recently launched the p2 instance family",
    "start": "116369",
    "end": "122280"
  },
  {
    "text": "it offers up to 16 Nvidia K 80 GPUs in a",
    "start": "122280",
    "end": "128310"
  },
  {
    "text": "single instance that's 8k 80 cards physical cards in a single instance giving you up",
    "start": "128310",
    "end": "134870"
  },
  {
    "text": "to 70 teraflops of single point floating-point precision performance or",
    "start": "134870",
    "end": "141610"
  },
  {
    "text": "more than 23 teraflops of double-precision floating-point",
    "start": "141610",
    "end": "147050"
  },
  {
    "text": "performance and it was designed for workloads like deep learning",
    "start": "147050",
    "end": "152950"
  },
  {
    "text": "computational fluid dynamics seismic analysis molecular modeling genomics and",
    "start": "152950",
    "end": "159410"
  },
  {
    "text": "more and this is what the family looks like we've got three different instances",
    "start": "159410",
    "end": "165050"
  },
  {
    "text": "here starting with a single GPU in the p2 extra-large moving up to our middle",
    "start": "165050",
    "end": "173210"
  },
  {
    "text": "instance here the the p2 8xl with 8 GPUs and 10 gigabytes of bandwidth in a",
    "start": "173210",
    "end": "181550"
  },
  {
    "text": "placement group and then our biggest instance our biggest instance if I could",
    "start": "181550",
    "end": "187130"
  },
  {
    "text": "talk is the p2 16 Excel all right with those 16 GPUs seven hundred and thirty",
    "start": "187130",
    "end": "193490"
  },
  {
    "text": "two gigabytes of memory and 20 gigabytes of bandwidth so massive massive",
    "start": "193490",
    "end": "198740"
  },
  {
    "text": "performance so in summary we've got a",
    "start": "198740",
    "end": "206120"
  },
  {
    "text": "pace of innovation here we've got new hardware right and this is a fantastic",
    "start": "206120",
    "end": "212540"
  },
  {
    "text": "vehicle to accelerate machine learning workloads and with that I'd like to",
    "start": "212540",
    "end": "218300"
  },
  {
    "text": "invite Diego to the podium and we're gonna find out what they've been up to at algorithm eeeh and the exciting",
    "start": "218300",
    "end": "223520"
  },
  {
    "text": "things that they're doing using AWS services and the p2 instance family yeah",
    "start": "223520",
    "end": "229160"
  },
  {
    "text": "thank you very much hello everyone let's see here yeah so I'm Diego Oppenheimer I'm the CEO and",
    "start": "229160",
    "end": "235580"
  },
  {
    "text": "founder of a company called algorithmic up in Seattle my background has always been in data and advanced analytics I've",
    "start": "235580",
    "end": "242840"
  },
  {
    "text": "been a prokta belapur I've worked on things like PowerPivot RBI excel get that trading start up before that",
    "start": "242840",
    "end": "249220"
  },
  {
    "text": "algorithm run introduce us to ourselves a little bit what we do and then kind of move into how we've actually deployed",
    "start": "249220",
    "end": "254690"
  },
  {
    "text": "deep learning so our mission is the companies to make state-of-the-art algorithms accessible and discoverable",
    "start": "254690",
    "end": "259790"
  },
  {
    "text": "by everyone and this is a simple mission in the sense that we think that no matter what technology what",
    "start": "259790",
    "end": "265130"
  },
  {
    "text": "programming language or where you are you should have access to the state-of-the-art algorithms that exists out there and this is everything from",
    "start": "265130",
    "end": "270530"
  },
  {
    "text": "machine learning models to image processing algorithms to deep learning models so what does the marketplace for",
    "start": "270530",
    "end": "276560"
  },
  {
    "text": "algorithms means so we turn algorithms into scaleable micro-services by taking",
    "start": "276560",
    "end": "282020"
  },
  {
    "text": "advantage of the latest technologies and containerization as well as API management and deep monitoring",
    "start": "282020",
    "end": "288530"
  },
  {
    "text": "researchers from universities independent developers National Labs they grab their work that were they",
    "start": "288530",
    "end": "294830"
  },
  {
    "text": "would usually either just host statically on github they push it into our system we turn it automatically into",
    "start": "294830",
    "end": "300380"
  },
  {
    "text": "an API containerized micro-service deploy it now it's available for any developer on earth to call through a",
    "start": "300380",
    "end": "305780"
  },
  {
    "text": "simple REST API really really easy to do so once we already have it there now any",
    "start": "305780",
    "end": "312050"
  },
  {
    "text": "developer calling that in their applications its metered by the second in terms of compute and so you're only",
    "start": "312050",
    "end": "317150"
  },
  {
    "text": "using the resources that you need talking about that kind of like Saturn determines how server lists as well as",
    "start": "317150",
    "end": "322610"
  },
  {
    "text": "you know just-in-time computing so we also provide an automatic taxonomy on how to grab all these algorithmic micro",
    "start": "322610",
    "end": "329210"
  },
  {
    "text": "services and organize them search them we make it really easy to find what you're doing by the different use cases",
    "start": "329210",
    "end": "334640"
  },
  {
    "text": "etc and of course if the algorithm developer or person creating these services wants to we give an ability to",
    "start": "334640",
    "end": "341090"
  },
  {
    "text": "monetize it so they can charge on a pair API call and we act like an app store in terms of 70/30 split with them 72 them",
    "start": "341090",
    "end": "348410"
  },
  {
    "text": "by the way so what do I mean by you know algorithm so we have over 2,600 of these",
    "start": "348410",
    "end": "356000"
  },
  {
    "text": "available today that any developer can call and it starts with things in the natural language processing world like",
    "start": "356000",
    "end": "361520"
  },
  {
    "text": "you know summarize errs and census standards and profanity detection we move into audio and video splitting",
    "start": "361520",
    "end": "368150"
  },
  {
    "text": "speech recognition file conversions and then go into kind of deep learning tasks like we're going to show you a couple of",
    "start": "368150",
    "end": "373550"
  },
  {
    "text": "demos everything from style transfer to image classification to audio classification in all of these all 2,600",
    "start": "373550",
    "end": "380570"
  },
  {
    "text": "are always live and available for anybody to call and when we talk about it you know these as my preserves we",
    "start": "380570",
    "end": "386210"
  },
  {
    "text": "mean it like any of these can actually be deployed at any moment as soon as you decide to invoke it as a developer so we",
    "start": "386210",
    "end": "393770"
  },
  {
    "text": "think of ourselves as kind of like building out the machine intelligence stack with the components that today so most of you have data stores",
    "start": "393770",
    "end": "400999"
  },
  {
    "text": "that you already work with a lot of them already in Amazon and then on top of that they're actually providing with his",
    "start": "400999",
    "end": "406039"
  },
  {
    "text": "amazing scalable CPU and GPU compute algorithm utilize on top of that taking",
    "start": "406039",
    "end": "411409"
  },
  {
    "text": "advantage of those data stores as well as that scalable CPU and GPU compute to provide these algorithmic micro services",
    "start": "411409",
    "end": "416689"
  },
  {
    "text": "so then you can come in and actually do the interesting part which is build smart applications and whatever language you want and whatever language your",
    "start": "416689",
    "end": "423319"
  },
  {
    "text": "stack is in so what do we mean by scale and why do we need this scalable GPU",
    "start": "423319",
    "end": "429110"
  },
  {
    "text": "compute so our system is a multi-tenancy system we have over 32,000 individual",
    "start": "429110",
    "end": "434869"
  },
  {
    "text": "developers calling algorithms at any given time we provide you know we get to",
    "start": "434869",
    "end": "440839"
  },
  {
    "text": "go through AWS we get access to this massive amount of hardware that allows us to scale and provide that experience",
    "start": "440839",
    "end": "446179"
  },
  {
    "text": "to all their azan CPUs as well as GPUs and this also means that our traffic is",
    "start": "446179",
    "end": "451729"
  },
  {
    "text": "extremely spiky at sometimes we get massive amount of need for compute at other times it's not so much and so we",
    "start": "451729",
    "end": "458059"
  },
  {
    "text": "need up for our own economics need to be able to do that scaling up and down in real time so to give a general idea",
    "start": "458059",
    "end": "465079"
  },
  {
    "text": "around the scale and container so as of a couple of weeks ago when I measured we generate and destroy about 150,000",
    "start": "465079",
    "end": "471979"
  },
  {
    "text": "containers a day and this is all done automatically by our system so what does",
    "start": "471979",
    "end": "478219"
  },
  {
    "text": "it mean by hosting deep learning so this is actually presents this is something that we got into about 6 months ago we",
    "start": "478219",
    "end": "484729"
  },
  {
    "text": "launched our support for a lot of deep learning frameworks and there's a lot of complexity around hardware and software",
    "start": "484729",
    "end": "490909"
  },
  {
    "text": "dependencies which is what I'm going to be talking about mostly today we had to learn how to say to our developers say",
    "start": "490909",
    "end": "497719"
  },
  {
    "text": "well you're already developing in some framework so we grabbed the most popular deep learning frameworks and make them",
    "start": "497719",
    "end": "503209"
  },
  {
    "text": "work in our system we had to deal with spiky traffic on GPUs it wasn't just like we couldn't just rent a whole bunch",
    "start": "503209",
    "end": "509719"
  },
  {
    "text": "of GPUs and let them sit there if they're not gonna be unused that would be cost prohibitive we had to deal with multi-tenancy on GPUs and this is",
    "start": "509719",
    "end": "516469"
  },
  {
    "text": "something that not a lot of people think about but we've been developing CPUs in a multi-tenancy world for about 30 years",
    "start": "516469",
    "end": "522258"
  },
  {
    "text": "like these things are figured out at this point like how to do multi-tenancy on on CPUs GPUs that is not the case",
    "start": "522259",
    "end": "528829"
  },
  {
    "text": "sharing GPUs and multi-tenancy Zack extremely hard to do especially when you're trying to use containerization",
    "start": "528829",
    "end": "534940"
  },
  {
    "text": "and load them side-by-side and then how do we you know how we had to approach building an extensible dynamic",
    "start": "534940",
    "end": "540250"
  },
  {
    "text": "architecture to support deep learning so really quickly I'm going to do a very",
    "start": "540250",
    "end": "545710"
  },
  {
    "text": "very brief introduction to like deep learning and some of the frameworks but just by a show of hands here how many",
    "start": "545710",
    "end": "550960"
  },
  {
    "text": "people have interacted with a deep learning framework okay how many people",
    "start": "550960",
    "end": "557320"
  },
  {
    "text": "have gone beyond the tutorial 101 on a deep learning framework a little bit",
    "start": "557320",
    "end": "563830"
  },
  {
    "text": "less how many people here have actually put in a deep learning system into live",
    "start": "563830",
    "end": "569110"
  },
  {
    "text": "production four five okay decent amount but very very few people so and this is",
    "start": "569110",
    "end": "576370"
  },
  {
    "text": "it like this is the truth here is that a lot of people are wanting to work with deep learning a lot of people are very very interested in it but the actual",
    "start": "576370",
    "end": "582070"
  },
  {
    "text": "amount of people and that means the amount of documentation and research and that about putting these things into",
    "start": "582070",
    "end": "588940"
  },
  {
    "text": "production is actually not quite there yet so at the super basic level deep learning is actually used as artificial",
    "start": "588940",
    "end": "594640"
  },
  {
    "text": "neurons to mimic how the brain you represents data high dimensional data so",
    "start": "594640",
    "end": "600550"
  },
  {
    "text": "it actually excels in tasks where there's like a very basic unique unit of",
    "start": "600550",
    "end": "606270"
  },
  {
    "text": "basic unit like a single pixel or frequency or word that has very little meaning out as itself but as you go",
    "start": "606270",
    "end": "611830"
  },
  {
    "text": "through the different layers that p.m. to come to and on your story so where we've seen deep learning being used a",
    "start": "611830",
    "end": "618670"
  },
  {
    "text": "lot is actually in unstructured data and recently we've had about this explosion",
    "start": "618670",
    "end": "624820"
  },
  {
    "text": "on unstructured data just your phones are probably the largest producers of unstructured data you can see out there",
    "start": "624820",
    "end": "630940"
  },
  {
    "text": "in terms of videos pictures audio speech and then you get to websites and log files in social media and we have to be",
    "start": "630940",
    "end": "637660"
  },
  {
    "text": "able to interpret this data and this is where deep learning is a technique because of how good it is with unstructured data can actually be",
    "start": "637660",
    "end": "644200"
  },
  {
    "text": "applied to so the production use cases we see today so you might have seen the",
    "start": "644200",
    "end": "649570"
  },
  {
    "text": "announcement yesterday around Amazon recognition you know Google has their own there's a company I'll clarify it",
    "start": "649570",
    "end": "655480"
  },
  {
    "text": "has theirs you know Microsoft has their own so image classification object",
    "start": "655480",
    "end": "660610"
  },
  {
    "text": "detection face recognition only being used already by a lot of different software developers natural",
    "start": "660610",
    "end": "665959"
  },
  {
    "text": "language you know so peach detects chatbots QA systems machine translation these are",
    "start": "665959",
    "end": "671119"
  },
  {
    "text": "the other production systems that we've actually seen optimization anomaly detection and finally recommender",
    "start": "671119",
    "end": "676399"
  },
  {
    "text": "systems that are being used on structure there so this is where we're really seeing live production systems today in",
    "start": "676399",
    "end": "683360"
  },
  {
    "text": "the world of deep learning so why now anybody who's been reading any news has",
    "start": "683360",
    "end": "689389"
  },
  {
    "text": "probably just seen deep learning actually this is a challenge for when you go to TechCrunch and open the page",
    "start": "689389",
    "end": "695449"
  },
  {
    "text": "and then just do ctrl F and type in deep learning and I bet money I'll buy your beer if you don't see at least one",
    "start": "695449",
    "end": "701119"
  },
  {
    "text": "result and there's a reason why this has become really really popular recently is that there's kind of been like three",
    "start": "701119",
    "end": "707239"
  },
  {
    "text": "moving forces that have gotten to the world where like why this has become important one is that so the research",
    "start": "707239",
    "end": "713089"
  },
  {
    "text": "actually comes from the 80s in which you know the first kind of neural nets were deployed but they",
    "start": "713089",
    "end": "718939"
  },
  {
    "text": "required an immense amount of data that was hard to get to they require an immense amount of compute that was",
    "start": "718939",
    "end": "724129"
  },
  {
    "text": "extremely expensive and you know the hardware wasn't just quite there yet in the there's been advances in research",
    "start": "724129",
    "end": "730850"
  },
  {
    "text": "from young laocoon who works in our facebook hints in in been geo over the last couple years that have made these",
    "start": "730850",
    "end": "737149"
  },
  {
    "text": "networks faster and more efficient there's been advances in hardware the use of GPUs for actually doing the",
    "start": "737149",
    "end": "743480"
  },
  {
    "text": "calculations allows us for these you know the deep learning why it's deep is we can go deeper into the levels that",
    "start": "743480",
    "end": "748669"
  },
  {
    "text": "know that so that we can which produce higher results and that requires an a massive amount of computation and GPUs",
    "start": "748669",
    "end": "755569"
  },
  {
    "text": "are really really good at this and then the final one is that the amount of data is finally there we've been spending",
    "start": "755569",
    "end": "762439"
  },
  {
    "text": "millions of dollars on storing every single log file every single image everything we could for the last 10",
    "start": "762439",
    "end": "768110"
  },
  {
    "text": "years now we actually have data sets so we can start applying these deep learning techniques between the",
    "start": "768110",
    "end": "773239"
  },
  {
    "text": "availability of a massive amount of compute like things like AWS and is where that give you that expansive bility the hardware that is their use of",
    "start": "773239",
    "end": "779929"
  },
  {
    "text": "GPUs and the fact that we have data now deep learning is starting to show really shine in this world of unstructured data",
    "start": "779929",
    "end": "785629"
  },
  {
    "text": "and you can see on the on the graph here which is the accuracy image net is kind",
    "start": "785629",
    "end": "791749"
  },
  {
    "text": "of the the gold standard for measuring accuracy and image recognition and this is what's been used for a while",
    "start": "791749",
    "end": "797300"
  },
  {
    "text": "and you can see us as soon as 2011 when you know deep learning it was starting to use on top of GPUs the accuracy just",
    "start": "797300",
    "end": "804320"
  },
  {
    "text": "completely left everything else back all the other methodologies for doing normal computer vision and this is why it's",
    "start": "804320",
    "end": "810620"
  },
  {
    "text": "exciting and everybody wants to talk about it right now so hardware so GPUs today and videos",
    "start": "810620",
    "end": "817790"
  },
  {
    "text": "dominating they made a big bet and I'll talk a little bit more about like white bet they made there and why that's",
    "start": "817790",
    "end": "823250"
  },
  {
    "text": "important but they've actually really been dominating the deep learning space the first GPU for neuro Nets I was on an",
    "start": "823250",
    "end": "828740"
  },
  {
    "text": "NVIDIA GTX 280 the Nvidia chips and tend to outperform on the types of operations",
    "start": "828740",
    "end": "835340"
  },
  {
    "text": "that are required for deep learning over AMD and the most important part the key here is that every single framework",
    "start": "835340",
    "end": "842150"
  },
  {
    "text": "supports CUDA which is the primitives inside that Nvidia is made available for using with their chips and that is",
    "start": "842150",
    "end": "847700"
  },
  {
    "text": "actually the thing that's been driving the most people over to Nvidia so today",
    "start": "847700",
    "end": "853490"
  },
  {
    "text": "we're starting to see the GPU is like the main deep learning like chipset but",
    "start": "853490",
    "end": "858830"
  },
  {
    "text": "we're starting to see specialization very similar to how we saw in the world of Bitcoin where people started mining",
    "start": "858830",
    "end": "864830"
  },
  {
    "text": "on CPUs then moved to GPUs because it was faster and then we got specialized hide word in the sense of Asics we're",
    "start": "864830",
    "end": "870560"
  },
  {
    "text": "starting to see the exact same trend in the deep learning world where we're signing to see FPGAs recently announced",
    "start": "870560",
    "end": "875750"
  },
  {
    "text": "as of yesterday the eff ones Microsoft has their own version and then we're seeing Asics Google's to be used IBM's",
    "start": "875750",
    "end": "881420"
  },
  {
    "text": "to North the nirvana engine and graphic cores IP use and these are chips where you're essentially getting rid of",
    "start": "881420",
    "end": "886880"
  },
  {
    "text": "everything that's not necessary so you can just do the calculations required for doing deep learning going into deep",
    "start": "886880",
    "end": "894020"
  },
  {
    "text": "learning dependencies this is what the deep learning stack looks like so you start out the driver at the chipset level which is the GPU then you have the",
    "start": "894020",
    "end": "900710"
  },
  {
    "text": "Nvidia driver on top of that the CUDA which is the first set of primitives that could an N which is actually",
    "start": "900710",
    "end": "906410"
  },
  {
    "text": "providing you the primitives for like the actual neural nets and then you actually have the deep learning frameworks which I'm going to talk a little bit about more and then recently",
    "start": "906410",
    "end": "913220"
  },
  {
    "text": "we've started seeing these meta deep learning more frameworks which I call like deep learning making accessible for",
    "start": "913220",
    "end": "920150"
  },
  {
    "text": "mortals like myself you know in in we call that Chara's which actually will give you like really really nice Python",
    "start": "920150",
    "end": "926510"
  },
  {
    "text": "interfaces to be able to interact with them so deep learning frameworks there's a",
    "start": "926510",
    "end": "931910"
  },
  {
    "text": "ton I can't review them all I'm gonna do a really really quick pass through them so we can get to the interesting part which is the architecture so the five",
    "start": "931910",
    "end": "938480"
  },
  {
    "text": "ones that we support today are on our platform our cafe tensorflow Theano MX",
    "start": "938480",
    "end": "943520"
  },
  {
    "text": "net and torch we're actually adding a couple more like CNT K and and and as",
    "start": "943520",
    "end": "949160"
  },
  {
    "text": "some other networks become more popular we actually add them to our platform as well but I'll do a quick review of them",
    "start": "949160",
    "end": "955250"
  },
  {
    "text": "so Theano was created by University of Montreal it's really kind of pioneered",
    "start": "955250",
    "end": "960470"
  },
  {
    "text": "the symbolic graph for programming a network very very mature networks been a frameworks been using for a long time it",
    "start": "960470",
    "end": "966590"
  },
  {
    "text": "has good supports for many types of different networks pros for it uses Python and numpy it has a declarative",
    "start": "966590",
    "end": "973850"
  },
  {
    "text": "computational graph it has good support for recursive neural nets and it has these wrapper frameworks like Kara's",
    "start": "973850",
    "end": "980450"
  },
  {
    "text": "lasagna and blocks which I'd allow you to kind of do like it makes it more accessible and easier to use the api's",
    "start": "980450",
    "end": "986480"
  },
  {
    "text": "with better error messaging etc BSP licensed the cons is that it took a low-level framework the error message",
    "start": "986480",
    "end": "992270"
  },
  {
    "text": "it's almost impossible to debug errors are really really unhelpful and this is",
    "start": "992270",
    "end": "998480"
  },
  {
    "text": "something that you'll see in a couple of the different frameworks large models can have really really long compile",
    "start": "998480",
    "end": "1003880"
  },
  {
    "text": "times and there's weak support for pre-trained models which means that you can't just go find an already existing",
    "start": "1003880",
    "end": "1009010"
  },
  {
    "text": "it's hard to find existing pre-trained models that you can have as a starting point so torch so this is actually a",
    "start": "1009010",
    "end": "1015880"
  },
  {
    "text": "collaborative research there's actually what deepmind used before they got acquired by Google so they're now moved",
    "start": "1015880",
    "end": "1021220"
  },
  {
    "text": "over to tensorflow it was actually they were the kind of pioneering and actually using torch as well it's a general scientific computing",
    "start": "1021220",
    "end": "1029290"
  },
  {
    "text": "framework that loses Lua and that kind of produces some of the problems you",
    "start": "1029290",
    "end": "1034390"
  },
  {
    "text": "have to know Lua so torch is more flexible than tensorflow and Theano it's that it's imperative while the",
    "start": "1034390",
    "end": "1040510"
  },
  {
    "text": "tensorflow and Theon are actually declarative it makes some operations much easier to do the prone the pros as",
    "start": "1040510",
    "end": "1047290"
  },
  {
    "text": "I said a very flexible multi-dimensional array engine multiple backends like CUDA at OpenMP as well OpenCL",
    "start": "1047290",
    "end": "1053980"
  },
  {
    "text": "there's lots of pre-trained models available and I'm actually show a couple of the ones that we've used the cons is",
    "start": "1053980",
    "end": "1058990"
  },
  {
    "text": "that it's Lua and there's not that many cool ooha developers out there it's not good for recurrent Nets and",
    "start": "1058990",
    "end": "1064039"
  },
  {
    "text": "there's actually a complete lack of commercial support because it's been on mostly an academic project for a really long time cafe so this was created at",
    "start": "1064039",
    "end": "1071929"
  },
  {
    "text": "the Berkeley vision and Learning Center they're kind of the pioneers of computer vision and that's no surprise that cafe",
    "start": "1071929",
    "end": "1080510"
  },
  {
    "text": "is kind of the gold standard for doing image recognition tasks probably the most common used framework today it's",
    "start": "1080510",
    "end": "1087830"
  },
  {
    "text": "optimized for feed-forward networks convolutional nets and image processing it has a simple at Python API good",
    "start": "1087830",
    "end": "1094940"
  },
  {
    "text": "license the cons are that when you actually are adding new GPU layers you have two new C++ Plus CUDA programming",
    "start": "1094940",
    "end": "1100639"
  },
  {
    "text": "which can be difficult at times limited support for recurrent neural nets and",
    "start": "1100639",
    "end": "1106190"
  },
  {
    "text": "then when it become when you're using really really large networks it becomes like a really cumbersome framework to work with tensorflow so this was created",
    "start": "1106190",
    "end": "1114860"
  },
  {
    "text": "by Google it's written with a Python API over a C++ C and C++ engine generates a",
    "start": "1114860",
    "end": "1120860"
  },
  {
    "text": "computational graph and performs automatic differentiation the pros that it uses Python and on PI again this is",
    "start": "1120860",
    "end": "1126950"
  },
  {
    "text": "really common like for a good network you want to use PI you know a little Python and um PI lots of interest from",
    "start": "1126950",
    "end": "1133010"
  },
  {
    "text": "the community so Google's done an amazing marketing effort and getting tensorflow out there and having a lot of",
    "start": "1133010",
    "end": "1138440"
  },
  {
    "text": "people talk about it as you know something to go so that's you know that gives us if you're gonna go into deep",
    "start": "1138440",
    "end": "1145190"
  },
  {
    "text": "learning it's like a pretty safe bet that there's a lot of community being built around this although there's not that much support for you just yet it's",
    "start": "1145190",
    "end": "1150950"
  },
  {
    "text": "highly parallel and designed to use various backends it can be on software-only mode it can be on CPU mode",
    "start": "1150950",
    "end": "1156230"
  },
  {
    "text": "it can be a GPU mode and can also be on ASIC mode which is not surprising giving the announcements that Google bit recently has an apache license it's a",
    "start": "1156230",
    "end": "1163610"
  },
  {
    "text": "lot slower than the other networks frameworks it has more features but you",
    "start": "1163610",
    "end": "1170389"
  },
  {
    "text": "know and more abstractions than torch and there's not many pre-trained models and this is a kind of common thread here",
    "start": "1170389",
    "end": "1176690"
  },
  {
    "text": "that like the availability of pre chain models is how most deep learning practitioners are gonna get up and started with these things so that's",
    "start": "1176690",
    "end": "1182389"
  },
  {
    "text": "becomes really important so finally when you're going to do training you know the",
    "start": "1182389",
    "end": "1190070"
  },
  {
    "text": "you don't start from scratch designing a known that unless you are in a research institution or",
    "start": "1190070",
    "end": "1195800"
  },
  {
    "text": "and academic like you usually what you'll do is you'll grab a pre trained neural net of some sort that has a",
    "start": "1195800",
    "end": "1201620"
  },
  {
    "text": "similar task to what you're trying to achieve and start there as kind of like as your starting point and so you can",
    "start": "1201620",
    "end": "1208640"
  },
  {
    "text": "get a lot of these like vgg google net alex net squeeze net cafe model zoo is a fantastic place to go get pre trained",
    "start": "1208640",
    "end": "1215570"
  },
  {
    "text": "models and that's where you can kind of say well if i see that you know i see a",
    "start": "1215570",
    "end": "1221390"
  },
  {
    "text": "model and cafe models ooh that's really good on training on recognizing you know animals of some sort maybe i can grab",
    "start": "1221390",
    "end": "1228650"
  },
  {
    "text": "that same network and start replicating with a new data set into recognizing insects so like if you're gonna be doing",
    "start": "1228650",
    "end": "1234890"
  },
  {
    "text": "like similar classification attacks and images and stuff like that like you can pretty much start from you know some of",
    "start": "1234890",
    "end": "1241340"
  },
  {
    "text": "these pre-existing ones so big difference here and and it'll become a",
    "start": "1241340",
    "end": "1246350"
  },
  {
    "text": "lot clearer as i go into the architecture which is there's two very distinct phases in the deep learning",
    "start": "1246350",
    "end": "1251570"
  },
  {
    "text": "world one which is called training and the other one which is actually running it or called inference and they are",
    "start": "1251570",
    "end": "1257210"
  },
  {
    "text": "completely different tasks with very very different approaches on how you actually scale and do them I'm mostly",
    "start": "1257210",
    "end": "1263120"
  },
  {
    "text": "going to concentrate on running an inference so what this means is once I've already trained the model either",
    "start": "1263120",
    "end": "1268250"
  },
  {
    "text": "I've done it in parallel or not you know once that is set like how am I going to",
    "start": "1268250",
    "end": "1273650"
  },
  {
    "text": "actually make it available to applications to call into that model and make it internet scale there's a ton of research as well as frameworks and",
    "start": "1273650",
    "end": "1281930"
  },
  {
    "text": "companies concentrating on the training part so we're gonna talk about running these models at scale so hosting deep",
    "start": "1281930",
    "end": "1290630"
  },
  {
    "text": "learning models available as an API represents a unique set of challenges that are rarely if ever really addressed",
    "start": "1290630",
    "end": "1298850"
  },
  {
    "text": "in tutorials and as I said like most people have gotten to the end of tutorial 101 on tensorflow so one in are",
    "start": "1298850",
    "end": "1305000"
  },
  {
    "text": "like okay well how do i hook up my mobile application to this because it's not gonna run off your laptop and or how",
    "start": "1305000",
    "end": "1310070"
  },
  {
    "text": "i going to hook up my web application so why would you want machine learning in the cloud so for us it's kind of obvious",
    "start": "1310070",
    "end": "1316870"
  },
  {
    "text": "you don't you want to react to live user data you don't want to manage your own servers you don't want to have to have",
    "start": "1316870",
    "end": "1323510"
  },
  {
    "text": "enough servers to sustain your max load at any given time because you can so you can you save money by",
    "start": "1323510",
    "end": "1328790"
  },
  {
    "text": "using these cloud services and then on mobile in particular like although there's a really interesting research",
    "start": "1328790",
    "end": "1334190"
  },
  {
    "text": "coming out of Facebook around cafe on mobile there's a really limited computing power on top of your phone not",
    "start": "1334190",
    "end": "1340790"
  },
  {
    "text": "to mention what it's going to do to your battery to be able to run these neural nets on it so you want to use the Internet as kind of like the way and",
    "start": "1340790",
    "end": "1347360"
  },
  {
    "text": "services to be able to scale those so I'm going to talk about a single use case here so we actually launched this a",
    "start": "1347360",
    "end": "1355040"
  },
  {
    "text": "couple of months ago and I'm just real quick a demo of it as soon as this comes alive and the idea here was that so",
    "start": "1355040",
    "end": "1369010"
  },
  {
    "text": "colorizer was research that came from berkeley it's an actually a cafe model and it's a neural net that was trained",
    "start": "1369010",
    "end": "1374840"
  },
  {
    "text": "at the lab there to colorize black-and-white pictures using a neural net and to actually being able to turn",
    "start": "1374840",
    "end": "1380780"
  },
  {
    "text": "them into color pictures and so what this is actually happening behind the scenes here is we grab the original",
    "start": "1380780",
    "end": "1386720"
  },
  {
    "text": "image which is a black and white image and the neural net is essentially guessing based on the pre train data set",
    "start": "1386720",
    "end": "1392270"
  },
  {
    "text": "what the colors might look like on this image and as you can see this is a completely artificial repainted picture",
    "start": "1392270",
    "end": "1397850"
  },
  {
    "text": "but it's getting it pretty accurate and this is kind of where like you know that magic starts coming to be so now there's",
    "start": "1397850",
    "end": "1404510"
  },
  {
    "text": "a neural net that can actually process black-and-white pictures and turn them into color and so why is this",
    "start": "1404510",
    "end": "1410090"
  },
  {
    "text": "interesting is that we actually you know grabbed the model was put on algorithm",
    "start": "1410090",
    "end": "1415820"
  },
  {
    "text": "yeah by the researchers we created this website and we put it out there for people to use it and so now every API is",
    "start": "1415820",
    "end": "1423170"
  },
  {
    "text": "actually hitting and we're using them and we're colorizing it and what happened 48 hours after we created this",
    "start": "1423170",
    "end": "1429770"
  },
  {
    "text": "demo is that it landed on the front page of Reddit and so as you know the front",
    "start": "1429770",
    "end": "1436280"
  },
  {
    "text": "page of Reddit has a bit of traffic and that was a real test of how does you",
    "start": "1436280",
    "end": "1442640"
  },
  {
    "text": "know how do you actually scale a real live system that is using inference or you know you're actually running those",
    "start": "1442640",
    "end": "1448700"
  },
  {
    "text": "this model at scale so that millions of users can actually hit it all at once",
    "start": "1448700",
    "end": "1453740"
  },
  {
    "text": "and you're gonna actually provide that performance so here back today so this is what actually our",
    "start": "1453740",
    "end": "1461290"
  },
  {
    "text": "Pete graph look like when we were actually doing that over the next couple of hours and days that when we got to",
    "start": "1461290",
    "end": "1468400"
  },
  {
    "text": "the front page of Reddit so at one given time I think you know within the first 48 hours over 1.8 and a half million",
    "start": "1468400",
    "end": "1475480"
  },
  {
    "text": "images had been colorized there was a reddit that had you know four thousand different posts on it about you know",
    "start": "1475480",
    "end": "1482410"
  },
  {
    "text": "these images and the most important part from our perspective was we were down for 0.0 minutes during this process and",
    "start": "1482410",
    "end": "1490900"
  },
  {
    "text": "the reason we could do that is because of the Elastic Compute that we had under our platforms that allowed us to scale",
    "start": "1490900",
    "end": "1496420"
  },
  {
    "text": "as the traffic was coming in and then scaled down as the traffic started tapering off so if you look at the chart",
    "start": "1496420",
    "end": "1503050"
  },
  {
    "text": "here if we had actually done capacity planning we would have overpaid by about seventy five percent of what we needed",
    "start": "1503050",
    "end": "1509950"
  },
  {
    "text": "in terms of the actual performance there and so now we with what using the lots",
    "start": "1509950",
    "end": "1516280"
  },
  {
    "text": "to compute we were actually allowed to scale down or scale up a peak and then scale down our system so that only those",
    "start": "1516280",
    "end": "1523360"
  },
  {
    "text": "pieces you know we paid for what we cared about using so the important part",
    "start": "1523360",
    "end": "1530260"
  },
  {
    "text": "here is that a service-oriented architecture is exactly what you want to do if you're going to start deploying",
    "start": "1530260",
    "end": "1535330"
  },
  {
    "text": "deep learning in the cloud and a big reason of it is because that deep learning is extremely computationally intense and so if you started for",
    "start": "1535330",
    "end": "1543070"
  },
  {
    "text": "example having your API servers or your front end servers also trying to process",
    "start": "1543070",
    "end": "1548410"
  },
  {
    "text": "the neural net on the GPU or even on the CPU are you gonna realize it's gonna completely choke out the resources of",
    "start": "1548410",
    "end": "1554980"
  },
  {
    "text": "the rest of your system so deploying the actual computation piece has its own kind of like worker fleet is a way so",
    "start": "1554980",
    "end": "1562930"
  },
  {
    "text": "that the rest of the system can stay up and snappy and then all you need to do is keep on adding pieces to that worker",
    "start": "1562930",
    "end": "1568630"
  },
  {
    "text": "fleet so in our world you know we grab one of these you know algorithms or models we containerize them and then we",
    "start": "1568630",
    "end": "1575380"
  },
  {
    "text": "pack them into these GPU workers and as efficiently as we can and so and then",
    "start": "1575380",
    "end": "1580810"
  },
  {
    "text": "manage the memory in between them so that they don't kind of like run into each other and so that allows us to actually just scale the worker fleet as",
    "start": "1580810",
    "end": "1587140"
  },
  {
    "text": "we get these like huge peaks of traffic so how it looks on AWS we have you know",
    "start": "1587140",
    "end": "1595150"
  },
  {
    "text": "obviously the clients and all the different languages that you would go call you have the load balancers which",
    "start": "1595150",
    "end": "1601630"
  },
  {
    "text": "are you know which we are using a lb our API servers which are mostly using M fours they and then we have two fleets a",
    "start": "1601630",
    "end": "1609880"
  },
  {
    "text": "CPU worker fleet where we do a combination of M for s and X ones and",
    "start": "1609880",
    "end": "1615010"
  },
  {
    "text": "then our GPU fleet which is purely on P to s today which have given us kind of",
    "start": "1615010",
    "end": "1620050"
  },
  {
    "text": "that advantage of being able to scale these out Y P to s well the first one",
    "start": "1620050",
    "end": "1625960"
  },
  {
    "text": "they have a lot more memory so and you care a lot about that because when you're loading on your own net it's all",
    "start": "1625960",
    "end": "1631600"
  },
  {
    "text": "getting loaded in memory and you know the more memory the better it's the fact like you want more memory and it's the",
    "start": "1631600",
    "end": "1637840"
  },
  {
    "text": "memory per GPU that matters because memory sharing between GPUs is early oh",
    "start": "1637840",
    "end": "1643720"
  },
  {
    "text": "that's let's leave it there so modern CUDA supports the other one so there's",
    "start": "1643720",
    "end": "1648910"
  },
  {
    "text": "more CUDA cores to run in parallel there's new messages which means useful things for debugging and in particular",
    "start": "1648910",
    "end": "1654850"
  },
  {
    "text": "we actually had a problem with the old CUDA 3.0 that's what was in the g 2s where you couldn't do memory management",
    "start": "1654850",
    "end": "1662020"
  },
  {
    "text": "and you couldn't share memory which meant that if we had a multi-tenancy environment we could only have one session loaded per GPU at any given time",
    "start": "1662020",
    "end": "1669100"
  },
  {
    "text": "the whole thing falls apart there because you know if we had a peak like that then I don't know what the capacity was in those regions but unless you mean",
    "start": "1669100",
    "end": "1675640"
  },
  {
    "text": "we would be getting a call from AWS being like you don't get any more and then the price per flop actually works",
    "start": "1675640",
    "end": "1681130"
  },
  {
    "text": "out really well so customer showcase from our perspective so see us disco is",
    "start": "1681130",
    "end": "1687490"
  },
  {
    "text": "a company down in Texas they offer this fantastic technology of doing ediscovery",
    "start": "1687490",
    "end": "1693580"
  },
  {
    "text": "you know for legal firms using like advanced NLP and you know what they",
    "start": "1693580",
    "end": "1699940"
  },
  {
    "text": "wanted to do is be able like you know customer comes in they say they're about to go into a lawsuit they have to go into a discovery they've just been",
    "start": "1699940",
    "end": "1706090"
  },
  {
    "text": "dumped with 1015 million documents they need to process those as quickly as possible and give an interface to the lawyers so they can actually go and find",
    "start": "1706090",
    "end": "1712930"
  },
  {
    "text": "what's relevant and then they're using NLP techniques including word for to vac and a couple nets to try to kind of like",
    "start": "1712930",
    "end": "1719890"
  },
  {
    "text": "find other things that look like this in those massive amount of documents something that used to be done with like 300",
    "start": "1719890",
    "end": "1726200"
  },
  {
    "text": "paralegals so they you know this is what they do they use a combination of",
    "start": "1726200",
    "end": "1732090"
  },
  {
    "text": "different neural nets so they came to us because one they wanted the scalability of being able to have that peak traffic",
    "start": "1732090",
    "end": "1738000"
  },
  {
    "text": "once those lawsuits come in or once there's customers come online it's a massive amount of compute all at once",
    "start": "1738000",
    "end": "1743129"
  },
  {
    "text": "that they want to quickly get under their you know under for them and then be able to like deprecated like really quickly they want the flexibility to",
    "start": "1743129",
    "end": "1749879"
  },
  {
    "text": "have peaks at certain hours which is usually when lawyers are working and",
    "start": "1749879",
    "end": "1755940"
  },
  {
    "text": "then they want to be able to reduce those compute as I showed like you know they could actually do the capacity planning but they would under playing",
    "start": "1755940",
    "end": "1761820"
  },
  {
    "text": "for a lot of cycles on the GPUs that they didn't want to have to take care of so the final long which is what we do on",
    "start": "1761820",
    "end": "1767850"
  },
  {
    "text": "our platform which allows the chaining of all these micro services and algorithms are piping them in to each other and so when they had four or five",
    "start": "1767850",
    "end": "1774090"
  },
  {
    "text": "different neural nets that they're different using as well as other NLP algorithms it made sense to have everything as independent microservices",
    "start": "1774090",
    "end": "1780360"
  },
  {
    "text": "that could be chained together for the different tasks and so that's kind of how they you know they came to us to",
    "start": "1780360",
    "end": "1785460"
  },
  {
    "text": "help you know do that scaling and put it on so now I'm going to talk about kind",
    "start": "1785460",
    "end": "1793860"
  },
  {
    "text": "of the challenges of you know working",
    "start": "1793860",
    "end": "1799320"
  },
  {
    "text": "with ec2 and sometimes where it helps so this is the things that we actually hate when working with you know different",
    "start": "1799320",
    "end": "1805860"
  },
  {
    "text": "deep learning frameworks that was you know and kind of this is my this is what",
    "start": "1805860",
    "end": "1812129"
  },
  {
    "text": "we did so you don't have to hopefully so challenge number one so new hardware so",
    "start": "1812129",
    "end": "1818370"
  },
  {
    "text": "when we started looking into deep learning there wasn't much option so you have a",
    "start": "1818370",
    "end": "1824580"
  },
  {
    "text": "couple of smart providers like Nimba kale penguin that we're providing different you know GPUs available to you",
    "start": "1824580",
    "end": "1831509"
  },
  {
    "text": "you could go build your own GPU racks you know which is again I'm pretty expensive SoftLayer had some Tesla 80",
    "start": "1831509",
    "end": "1839159"
  },
  {
    "text": "cards and em 60s as of now google just announced preview of their cards Azure",
    "start": "1839159",
    "end": "1846059"
  },
  {
    "text": "just announced their n series and then AWS is probably one of the first ones that had really and elasticity around",
    "start": "1846059",
    "end": "1852720"
  },
  {
    "text": "GPU compute but they had old in the beginning and now they have the",
    "start": "1852720",
    "end": "1857789"
  },
  {
    "text": "p2 instances and this is really important because kuda will be what you",
    "start": "1857789",
    "end": "1863669"
  },
  {
    "text": "like live and die about when you're actually doing the scaling here if you don't have the latest version of kuda",
    "start": "1863669",
    "end": "1869159"
  },
  {
    "text": "like you start running into a whole lot of problems and I'll kind of talk about why that is so language bindings so you",
    "start": "1869159",
    "end": "1881190"
  },
  {
    "text": "all are developers here you probably have an existing stock in some programming language that you're already",
    "start": "1881190",
    "end": "1887609"
  },
  {
    "text": "working how does it talk to your deep learning framework well I hope that stack is either Python or Lua",
    "start": "1887609",
    "end": "1894059"
  },
  {
    "text": "because otherwise you're pretty out of luck and so the solution here is actually services being able to abstract",
    "start": "1894059",
    "end": "1902009"
  },
  {
    "text": "any of the work that you're doing with a deep learning framework over an API will allow it to plug in to your real-world",
    "start": "1902009",
    "end": "1909149"
  },
  {
    "text": "services and applications that they can actually be work with versus having to be limited to either Python or Lua so if",
    "start": "1909149",
    "end": "1917970"
  },
  {
    "text": "those here that actually have done deep learning in any way exit code minus 99",
    "start": "1917970",
    "end": "1925889"
  },
  {
    "text": "and you guess I know you hit it so this means GPU out of memory ok and when GPU",
    "start": "1925889",
    "end": "1933869"
  },
  {
    "text": "out of memory it is not graceful the whole thing crashes and so we just don't",
    "start": "1933869",
    "end": "1940919"
  },
  {
    "text": "have like the you know the the the actual but we haven't seen the research",
    "start": "1940919",
    "end": "1948509"
  },
  {
    "text": "yet and like there's just it's not mature enough of platforms so that like the memory management is there so like you have to be very very very very",
    "start": "1948509",
    "end": "1955519"
  },
  {
    "text": "careful with no pointer exceptions and actually running out of memory because your entire process can actually just",
    "start": "1955519",
    "end": "1961590"
  },
  {
    "text": "eat it as you go so the pot you know the inverse of that is that actually the",
    "start": "1961590",
    "end": "1966690"
  },
  {
    "text": "models are getting larger so the chances of running out of memory are also a lot bigger as well so now you have the state",
    "start": "1966690",
    "end": "1973440"
  },
  {
    "text": "of the art networks that I can easily be multi-gigabyte they're producing a ridiculously large you know they're",
    "start": "1973440",
    "end": "1979590"
  },
  {
    "text": "really really good accuracy but they need to be loaded they need to be scaled and they need them",
    "start": "1979590",
    "end": "1984670"
  },
  {
    "text": "crash other people's applications because if you take out a GPU and you're actually a multi-tenancy environment",
    "start": "1984670",
    "end": "1989800"
  },
  {
    "text": "you're gonna get a lot of angry angry people on your task so the solution here is more Hardware smaller models so let's",
    "start": "1989800",
    "end": "1998680"
  },
  {
    "text": "talk about models so in general the",
    "start": "1998680",
    "end": "2005310"
  },
  {
    "text": "larger the model the more accuracy we're seeing or inverse of that belief the",
    "start": "2005310",
    "end": "2011550"
  },
  {
    "text": "less error the number usually behind the model is the number of layers that that",
    "start": "2011550",
    "end": "2017760"
  },
  {
    "text": "neural net has as you can see the larger the number the larger the size of the of",
    "start": "2017760",
    "end": "2022950"
  },
  {
    "text": "the model and so the state of the art right now you're seeing like error rates of about 4.8% but kind of the",
    "start": "2022950",
    "end": "2031680"
  },
  {
    "text": "interesting thing that's been happening recently is this squeezing it and squeezing it is a lot of research into",
    "start": "2031680",
    "end": "2037530"
  },
  {
    "text": "actually making really really small models for neural nets that have a small size so they can actually be put on",
    "start": "2037530",
    "end": "2043140"
  },
  {
    "text": "mobile phones or in any case be putting on GPUs without killing all the memory but you can see that the accuracy is not",
    "start": "2043140",
    "end": "2049169"
  },
  {
    "text": "the state-of-the-art accuracy it's pretty good but it's not the state-of-the-art accuracy so we're kind of getting there but again if you don't",
    "start": "2049169",
    "end": "2055200"
  },
  {
    "text": "want something that has a really really high accuracy like you're gonna actually have to commit to having much larger",
    "start": "2055200",
    "end": "2060330"
  },
  {
    "text": "models so the hypothesis behind squeezing it which we've been using a lot of recently is that you know today",
    "start": "2060330",
    "end": "2067500"
  },
  {
    "text": "we're just using because they're available in off-the-shelf and I just told you to twenty minutes ago that you should go grab one off the shelf we're",
    "start": "2067500",
    "end": "2073919"
  },
  {
    "text": "usually much larger networks than you really have to and they're more much more complicated than they really need to be and so this a lot of the research",
    "start": "2073919",
    "end": "2081300"
  },
  {
    "text": "behind squeezing that is trying to get to the Alex net level of accuracy which again is not the state of the art in terms of accuracy but it has 50 times",
    "start": "2081300",
    "end": "2089010"
  },
  {
    "text": "less parameters and it's under half a megabyte on memory of model size so it's",
    "start": "2089010",
    "end": "2094860"
  },
  {
    "text": "again not quite state of the arts but much much closer and easier to host there's another side of the house that's",
    "start": "2094860",
    "end": "2101640"
  },
  {
    "text": "actually doing research and pruning the size of networks so if you think about these neural nets is like this kind of",
    "start": "2101640",
    "end": "2107280"
  },
  {
    "text": "like tree structure you know and you actually start pruning and cutting off so the research really is start pruning",
    "start": "2107280",
    "end": "2113490"
  },
  {
    "text": "that the network look at the accuracy see if there's no like actually loss of accuracy and if there",
    "start": "2113490",
    "end": "2118680"
  },
  {
    "text": "then you got rid of some stuff that was unnecessary and you're good to go but this as you can see is like really",
    "start": "2118680",
    "end": "2123840"
  },
  {
    "text": "coming out of papers that were only published last year so han mal and dolly actually did you know this really",
    "start": "2123840",
    "end": "2129990"
  },
  {
    "text": "interesting paper around reduce the storage requirement for neural nets by 35 X - 49 X but this is academic at this",
    "start": "2129990",
    "end": "2136980"
  },
  {
    "text": "point where that's actually going challenge number for GPU sharing so I",
    "start": "2136980",
    "end": "2144660"
  },
  {
    "text": "kind of alluded to this at the beginning of the talk we have just not like we just haven't been sharing GPUs for 30",
    "start": "2144660",
    "end": "2151830"
  },
  {
    "text": "years like we have been sharing CPUs it's not as well-known multi context",
    "start": "2151830",
    "end": "2157830"
  },
  {
    "text": "management memory overflows unrestricted pointer logic are just really really dangerous in these applications because",
    "start": "2157830",
    "end": "2163980"
  },
  {
    "text": "you'll take down the entire GPU when you're the entire application when when",
    "start": "2163980",
    "end": "2169620"
  },
  {
    "text": "you're doing this and there's a limited amount of video memory so I think right now the largest card you can get a",
    "start": "2169620",
    "end": "2177060"
  },
  {
    "text": "memory per GPU is 12 gigabytes I might be wrapping I'm pretty sure at least commercially available 12 gigabytes is",
    "start": "2177060",
    "end": "2184200"
  },
  {
    "text": "as much memory you're getting into you know very rare but if you look at how much RAM your machine has you're",
    "start": "2184200",
    "end": "2189630"
  },
  {
    "text": "realizing that like you know we've you know and big like serving like like servers we've surpassed this by a lot so",
    "start": "2189630",
    "end": "2195240"
  },
  {
    "text": "there's just a limited amount of video memory today on these cards and then developers need a way to share GPU",
    "start": "2195240",
    "end": "2201960"
  },
  {
    "text": "resources safely from potentially malicious applications that can actually go take out an entire server by just",
    "start": "2201960",
    "end": "2207090"
  },
  {
    "text": "doing a nullpointerexception on them so GPU sharing is hard and fairly complex",
    "start": "2207090",
    "end": "2215460"
  },
  {
    "text": "though we have we think solved it like pretty well and you know we now the",
    "start": "2215460",
    "end": "2222060"
  },
  {
    "text": "second that is like well how do we do this over micro services so now it's GPU sharing and let's add the complexity of",
    "start": "2222060",
    "end": "2228090"
  },
  {
    "text": "containers onto that and so from our perspective docker is the kind of this new standard and deploying applications",
    "start": "2228090",
    "end": "2234980"
  },
  {
    "text": "but adds an additional layer to challenge GPU computing that said I absolutely think this is the future like",
    "start": "2234980",
    "end": "2241590"
  },
  {
    "text": "the way to deploy machine learning and deep learning applications and productions is to dr. eyes them is to",
    "start": "2241590",
    "end": "2246780"
  },
  {
    "text": "turn them into micro services because this is like there's so many advantages to but it comes with like some serious",
    "start": "2246780",
    "end": "2253020"
  },
  {
    "text": "problems especially since there's not that many people are doing it the first one is the Nvidia drivers on the chip on",
    "start": "2253020",
    "end": "2260780"
  },
  {
    "text": "the on the outside have to match exactly the Nvidia drivers on the inside of the",
    "start": "2260780",
    "end": "2266310"
  },
  {
    "text": "containers and so this is great if you have homogeneous hardware and you know exactly where your containers are getting deployed but if you're actually",
    "start": "2266310",
    "end": "2272250"
  },
  {
    "text": "going to potentially any machine that has you know docker that you can go deploy on how do you actually match the",
    "start": "2272250",
    "end": "2278780"
  },
  {
    "text": "the the drivers on the inside and the outside becomes particularly cumbersome the second one exact same story for CUDA",
    "start": "2278780",
    "end": "2285810"
  },
  {
    "text": "the drivers on the inside of the container have to be exactly the ones on the outside and that also becomes a",
    "start": "2285810",
    "end": "2293190"
  },
  {
    "text": "problem so some algorithms especially in our world like require X windows and has to",
    "start": "2293190",
    "end": "2300390"
  },
  {
    "text": "be started on the outside of the container and then mounted on the inside of the container and that's a whole lot of fun to kind of figure out how to do",
    "start": "2300390",
    "end": "2307109"
  },
  {
    "text": "and then but you know we're getting to a better world here so the first thing is like Nvidia docker so Nvidia published",
    "start": "2307109",
    "end": "2314280"
  },
  {
    "text": "their docker container which is kind of like they expect it to be this like the gold standard for using docker eyes deep",
    "start": "2314280",
    "end": "2321210"
  },
  {
    "text": "learning where they manage it we have found that it still has a lot of gaps in",
    "start": "2321210",
    "end": "2326250"
  },
  {
    "text": "terms of the drivers and and really being robust but it's definitely a really good step in the right direction",
    "start": "2326250",
    "end": "2333140"
  },
  {
    "text": "finally AWS just released their deep learning ami so you should be able to",
    "start": "2333140",
    "end": "2338700"
  },
  {
    "text": "click on that and just deploy it directly onto you know an instance inside AWS on this is a huge step in the",
    "start": "2338700",
    "end": "2345359"
  },
  {
    "text": "right direction mostly because the folks at AWS you know beat their heads against the wall to get all the drivers working",
    "start": "2345359",
    "end": "2350880"
  },
  {
    "text": "for you and no you don't have to and that's a good thing so this is we're getting to this world well this is this is becoming more mature and it's became",
    "start": "2350880",
    "end": "2357660"
  },
  {
    "text": "easier and this is definitely the path forward but there's still going to be gaps when doing it",
    "start": "2357660",
    "end": "2365720"
  },
  {
    "text": "so overall lessons learned deep learning in the cloud very much still in its",
    "start": "2365960",
    "end": "2372359"
  },
  {
    "text": "infancy as you can see not too many people are doing it in production and actually getting internet scale out of",
    "start": "2372359",
    "end": "2377369"
  },
  {
    "text": "deep learning workloads is really reserved for a few for a few people but it's getting more and more popular",
    "start": "2377369",
    "end": "2382770"
  },
  {
    "text": "Hosting deep learning models is the next logical step after training the model but the difficulty of actually deploying",
    "start": "2382770",
    "end": "2390460"
  },
  {
    "text": "them and putting them behind a web service or hosting on the Internet is actually completely underappreciated and",
    "start": "2390460",
    "end": "2395710"
  },
  {
    "text": "it's a different skill set very similar to how you know you if you're thinking about you know the training of deep",
    "start": "2395710",
    "end": "2402100"
  },
  {
    "text": "neural nets is very much a machine learning data scientists like kind of roll they actually scaling is very much",
    "start": "2402100",
    "end": "2408490"
  },
  {
    "text": "a DevOps operation and those two skill sets are completely different and so it's illogical to think that it's gonna",
    "start": "2408490",
    "end": "2415120"
  },
  {
    "text": "be the same folks who are gonna be doing that but we have to come up with a way of saying hey there's a hole now you",
    "start": "2415120",
    "end": "2421330"
  },
  {
    "text": "know industry that's gonna be moving to hosting these deep learning models and like I skillset that's needing the tooling frameworks are making things a",
    "start": "2421330",
    "end": "2427990"
  },
  {
    "text": "lot easier but there's a lot of opportunity for improvement so the big picture here before I go into a couple",
    "start": "2427990",
    "end": "2434530"
  },
  {
    "text": "of demos is the challenges involved with creating deep learning is only half the problem and there's a lot of challenges",
    "start": "2434530",
    "end": "2440020"
  },
  {
    "text": "and actually doing the training the second one is actually doing the deployment that skill set you know is something that's definitely going to be",
    "start": "2440020",
    "end": "2445900"
  },
  {
    "text": "needed and actually being able to run these at scales is extremely important so talking about running a skill again",
    "start": "2445900",
    "end": "2451690"
  },
  {
    "text": "I'm gonna show a couple of demos here hopefully the live demoing is a gonna be",
    "start": "2451690",
    "end": "2457030"
  },
  {
    "text": "on my side so two days ago we launched",
    "start": "2457030",
    "end": "2470680"
  },
  {
    "text": "something called deep style so this is area of research that's really really interesting called style transfer and",
    "start": "2470680",
    "end": "2477250"
  },
  {
    "text": "it's teaching a neural net to be able to apply the the style of one image to",
    "start": "2477250",
    "end": "2483820"
  },
  {
    "text": "another so think of it as we're actually teaching computers how to represent the style of a van Gogh or the style of a",
    "start": "2483820",
    "end": "2490360"
  },
  {
    "text": "Monet and apply it to another image and so there's a couple fun apps like prism on that I think that you can download on",
    "start": "2490360",
    "end": "2496060"
  },
  {
    "text": "your phone and I've applies that Google announced some research around this Facebook announced that they were doing",
    "start": "2496060",
    "end": "2501640"
  },
  {
    "text": "live video around this and the reason why this is interesting is because well first of all it's kind of creating this",
    "start": "2501640",
    "end": "2507430"
  },
  {
    "text": "human aspect of being able to translate style and create these really beautiful pictures to two images but also it's",
    "start": "2507430",
    "end": "2513910"
  },
  {
    "text": "like an extremely computationally intense and so we launched deep style it's kind",
    "start": "2513910",
    "end": "2519260"
  },
  {
    "text": "of like a little demo to showcase how you can do it so I'm gonna go pick an image we're gonna apply a style you can",
    "start": "2519260",
    "end": "2525410"
  },
  {
    "text": "see like the original image was right there this is one of the styles that's",
    "start": "2525410",
    "end": "2530450"
  },
  {
    "text": "being applied these are full resolution images so this was actually requiring a lot of computation behind the scenes to",
    "start": "2530450",
    "end": "2536450"
  },
  {
    "text": "do and you can see the different styles that get applied to it or they make the pictures look fascinating and so we",
    "start": "2536450",
    "end": "2544789"
  },
  {
    "text": "actually launched this as a demo the API is there we created 38 different filters that any developer can actually go build",
    "start": "2544789",
    "end": "2550670"
  },
  {
    "text": "we also open sourced and ami on AWS that you can go train your own filters and",
    "start": "2550670",
    "end": "2556520"
  },
  {
    "text": "then host that model on algorithmic so if you go to our blog blogger that Olga mediacom there's all the instructions on",
    "start": "2556520",
    "end": "2561650"
  },
  {
    "text": "how to do it it's all open source and that you can do so this is all great and",
    "start": "2561650",
    "end": "2566779"
  },
  {
    "text": "images are fantastic but how about video so this is actually done live on our",
    "start": "2566779",
    "end": "2572299"
  },
  {
    "text": "plan out in live now this is already pre rendered but there's actually a 4k drone video of the city of the Seattle being",
    "start": "2572299",
    "end": "2579799"
  },
  {
    "text": "applied on style transfer and if you try to actually render this video on your",
    "start": "2579799",
    "end": "2585020"
  },
  {
    "text": "laptop it probably will take a week maybe two if your actual GPU doesn't",
    "start": "2585020",
    "end": "2590990"
  },
  {
    "text": "burn down and and so one of the reasons why services becomes really interesting here and one of the things that I love",
    "start": "2590990",
    "end": "2597680"
  },
  {
    "text": "about this is that the you can actually that's it that one right you can",
    "start": "2597680",
    "end": "2606500"
  },
  {
    "text": "actually like pause it and it looks like a painting at any given time and they look beautiful but the thing that we did",
    "start": "2606500",
    "end": "2611779"
  },
  {
    "text": "when shooting is microservices we actually fed the video into our platform we actually farmed out every single",
    "start": "2611779",
    "end": "2618140"
  },
  {
    "text": "frame in parallel not every simple you know we farmed out the frames and pail applied strength for solid transfer to",
    "start": "2618140",
    "end": "2623569"
  },
  {
    "text": "the individual frames and then put them back together and because it's a microservices platform it allows sort of doing that",
    "start": "2623569",
    "end": "2628579"
  },
  {
    "text": "really easily versus having to do this all like you know impel and serially so",
    "start": "2628579",
    "end": "2634549"
  },
  {
    "text": "finally let's see hopefully this is the the test here I have a live server list",
    "start": "2634549",
    "end": "2641779"
  },
  {
    "text": "application here that's actually taking a picture every second of you",
    "start": "2641779",
    "end": "2647000"
  },
  {
    "text": "so hopefully don't even gradually get everybody in card here and actually doing the",
    "start": "2647000",
    "end": "2652680"
  },
  {
    "text": "uploading and doing the style transfer so let's see if it's there yeah so now",
    "start": "2652680",
    "end": "2659430"
  },
  {
    "text": "it's gonna start taking pictures and hopefully come on demo gods there you go",
    "start": "2659430",
    "end": "2668750"
  },
  {
    "text": "so this is actually actually so what's happening here is there's no back end here other than our API so the pictures",
    "start": "2668750",
    "end": "2675900"
  },
  {
    "text": "being taken by my phone it's being sent to the API and it's been dropped in an s3 bucket and that website all it's",
    "start": "2675900",
    "end": "2681810"
  },
  {
    "text": "doing is auto refresh on an s3 bucket that's it that's the entire thing and we're doing style transfer completely",
    "start": "2681810",
    "end": "2687930"
  },
  {
    "text": "live and you can build that with our API in about 20 minutes if you want to check",
    "start": "2687930",
    "end": "2694200"
  },
  {
    "text": "it out and that's all I got for you guys today hopefully you enjoyed learning a little bit more about scaling deep",
    "start": "2694200",
    "end": "2700020"
  },
  {
    "text": "learning today",
    "start": "2700020",
    "end": "2702500"
  },
  {
    "text": "yeah awesome if you guys want to try out algorithm yet there's a code here that",
    "start": "2708060",
    "end": "2714250"
  },
  {
    "text": "you can use reinvent 16 at algorithmic calm Thank You Diego for coming and",
    "start": "2714250",
    "end": "2720790"
  },
  {
    "text": "telling us all about what you guys have been doing it's super cool I hope everybody gets a chance to go out there",
    "start": "2720790",
    "end": "2725859"
  },
  {
    "text": "and play with that and thank you all for coming please remember to fill out the",
    "start": "2725859",
    "end": "2731470"
  },
  {
    "text": "survey on your mobile app thank you everybody appreciate it",
    "start": "2731470",
    "end": "2737970"
  }
]
[
  {
    "start": "0",
    "end": "30000"
  },
  {
    "text": "sorry for that guys we can get started now so yeah welcome again this is Emma",
    "start": "1340",
    "end": "7080"
  },
  {
    "text": "here I'm one of I'm a cloud infrastructure architect with a w's",
    "start": "7080",
    "end": "12120"
  },
  {
    "text": "professional services I also have Rohit with me who's a senior IOT architect",
    "start": "12120",
    "end": "17820"
  },
  {
    "text": "again with eight of these professional services and today we are here to present you know topic on building",
    "start": "17820",
    "end": "24689"
  },
  {
    "text": "dashboards using security server less security analytics so today we're gonna",
    "start": "24689",
    "end": "32430"
  },
  {
    "start": "30000",
    "end": "103000"
  },
  {
    "text": "be going over a number of things what do I expect from today's session we will",
    "start": "32430",
    "end": "37860"
  },
  {
    "text": "kick it off quickly but going over you know overview of some of these services",
    "start": "37860",
    "end": "43610"
  },
  {
    "text": "starting with AWS graph and row it will be going over the server less analytic",
    "start": "43610",
    "end": "49800"
  },
  {
    "text": "services and then we will dive deep on the solution architecture which is about",
    "start": "49800",
    "end": "56180"
  },
  {
    "text": "you know getting how do you easily get insights using a server less solution",
    "start": "56180",
    "end": "61469"
  },
  {
    "text": "from AWS graph logs and build simple and easy dashboards you also have a demo so",
    "start": "61469",
    "end": "69420"
  },
  {
    "text": "unlikely you know really complex and complex data warehouses or analytic",
    "start": "69420",
    "end": "75299"
  },
  {
    "text": "solutions and this one it's gonna in couple of minutes you'll use these services and in by click by clicks and",
    "start": "75299",
    "end": "83729"
  },
  {
    "text": "you'll have working - number of dashboards ready so we'll end the",
    "start": "83729",
    "end": "90659"
  },
  {
    "text": "session with you know also going over some of the m/l based additional architectures that revolve around the",
    "start": "90659",
    "end": "97770"
  },
  {
    "text": "same topic yeah let's jump right into the services now",
    "start": "97770",
    "end": "105220"
  },
  {
    "start": "103000",
    "end": "172000"
  },
  {
    "text": "yeah web application for our wall what is what is graph primarily valve is used",
    "start": "105220",
    "end": "112030"
  },
  {
    "text": "to you know really inspect layers of an HTTP traffic so graph can be used to",
    "start": "112030",
    "end": "120820"
  },
  {
    "text": "protect any sort of applications that are you know either three-tier typical applications that are",
    "start": "120820",
    "end": "128080"
  },
  {
    "text": "fronted with an application load balancer or it could be your server less apps that's using Amazon API gateway or",
    "start": "128080",
    "end": "135730"
  },
  {
    "text": "it could also be a CDN like Amazon CloudFront so it's okay as you go",
    "start": "135730",
    "end": "142570"
  },
  {
    "text": "service and it's you know really designed to be DevOps friendly since I",
    "start": "142570",
    "end": "147820"
  },
  {
    "text": "mention about DevOps friendly I'd also want to call out if there are folks here who missed this afternoon session that",
    "start": "147820",
    "end": "155110"
  },
  {
    "text": "was on using graph and firewall manager and if your teams are you know really working on implementing graph solutions",
    "start": "155110",
    "end": "161650"
  },
  {
    "text": "try to attend the repeat session that's happening tomorrow it's around 11:45",
    "start": "161650",
    "end": "166690"
  },
  {
    "text": "a.m. in the morning in I think level 2 room 2 or 3 yeah so what are the what",
    "start": "166690",
    "end": "176500"
  },
  {
    "start": "172000",
    "end": "271000"
  },
  {
    "text": "are the real advantages of rough they're mainly three main purposes of wife the",
    "start": "176500",
    "end": "181570"
  },
  {
    "text": "first one being you know really block the malicious traffic that you get and when we say malicious traffic we inspect",
    "start": "181570",
    "end": "189280"
  },
  {
    "text": "every web request and the payload of every web request and if anything is malicious we block that for you it's",
    "start": "189280",
    "end": "195640"
  },
  {
    "text": "it's happening with rules that you create like sequel injection rules or",
    "start": "195640",
    "end": "200980"
  },
  {
    "text": "cross-site can't cross site scripting conditions these conditions the web",
    "start": "200980",
    "end": "206680"
  },
  {
    "text": "requests are evaluated against these conditions and you basically blacklist",
    "start": "206680",
    "end": "213100"
  },
  {
    "text": "these IPS and block them from accessing your applications also yeah I'm talking",
    "start": "213100",
    "end": "219820"
  },
  {
    "text": "about marketplace manage rules I've worked with a lot of customers where you know the security teams are really small",
    "start": "219820",
    "end": "227560"
  },
  {
    "text": "teams and they are always oval with a number of things right around security",
    "start": "227560",
    "end": "233470"
  },
  {
    "text": "so such teams can definitely make use of marketplace manage rules which are",
    "start": "233470",
    "end": "238930"
  },
  {
    "text": "again designed to be pairs if pay as you go and you could really switch ON switch",
    "start": "238930",
    "end": "244930"
  },
  {
    "text": "them on when you wanted these are like we've worked with some of the security",
    "start": "244930",
    "end": "250269"
  },
  {
    "text": "expert security partners to come up with these managed rules they they actually",
    "start": "250269",
    "end": "255609"
  },
  {
    "text": "create up to 200 rules and these these rules are updated on a daily basis so",
    "start": "255609",
    "end": "262360"
  },
  {
    "text": "you're protected always so that's one thing you want and if if you get them and you want to switch back it's always",
    "start": "262360",
    "end": "268090"
  },
  {
    "text": "a click of a button to unsubscribe that and get back the second main thing is",
    "start": "268090",
    "end": "273789"
  },
  {
    "start": "271000",
    "end": "358000"
  },
  {
    "text": "about traffic filtering when we say traffic filtering this is not about malicious traffic that we are talking",
    "start": "273789",
    "end": "281110"
  },
  {
    "text": "about this is more about say you want to restrict your traffic to a specific",
    "start": "281110",
    "end": "286120"
  },
  {
    "text": "country say your business is working out of China and you want to restrict traffic from China you could use geo IP",
    "start": "286120",
    "end": "292240"
  },
  {
    "text": "based filters to really restrict your data right that you can really get",
    "start": "292240",
    "end": "298030"
  },
  {
    "text": "creative with your filters by using regex and string match conditions and",
    "start": "298030",
    "end": "304889"
  },
  {
    "text": "you know use all sorts of HD HTTP header attributes to really filter your traffic",
    "start": "304889",
    "end": "311680"
  },
  {
    "text": "there again and yeah a lot of our customers love to use rate based rules",
    "start": "311680",
    "end": "319030"
  },
  {
    "text": "which is about you know protecting yourself from DDoS attacks like HTTP",
    "start": "319030",
    "end": "324250"
  },
  {
    "text": "flood attacks yeah and the third last one is about monitoring every rule that",
    "start": "324250",
    "end": "333070"
  },
  {
    "text": "you create in graph you you can create metrics out of them and you can have you",
    "start": "333070",
    "end": "338620"
  },
  {
    "text": "know cloud watch alerts and alarms to really understand how what sort of",
    "start": "338620",
    "end": "343659"
  },
  {
    "text": "traffic you're getting what's getting blocked what's getting allowed and also you have you know the sample logs in the",
    "start": "343659",
    "end": "350889"
  },
  {
    "text": "full logs we will get more detail into more details on AWS full logs in the",
    "start": "350889",
    "end": "356560"
  },
  {
    "text": "coming section of slides key features of graph again just to quickly go over",
    "start": "356560",
    "end": "364139"
  },
  {
    "start": "358000",
    "end": "404000"
  },
  {
    "text": "customization on automation we always believe the best way to",
    "start": "364139",
    "end": "369270"
  },
  {
    "text": "make security even secure as automate and you have cloud formation support for",
    "start": "369270",
    "end": "374520"
  },
  {
    "text": "raff and firewall manager you can and you have you know some of these solutions like AWS five security",
    "start": "374520",
    "end": "381660"
  },
  {
    "text": "automation there's a readi CloudFormation template that you could go try out right tonight or you also",
    "start": "381660",
    "end": "388860"
  },
  {
    "text": "have another one that called Oh top 10 over ASPs Rohit will be diving a little",
    "start": "388860",
    "end": "394110"
  },
  {
    "text": "more deep on the Amazon guard duty scenario later and as one of his slides but that's again another customization",
    "start": "394110",
    "end": "401820"
  },
  {
    "text": "and automation piece of it fast and one",
    "start": "401820",
    "end": "407940"
  },
  {
    "start": "404000",
    "end": "447000"
  },
  {
    "text": "thing that we really distinguish ourselves from other you know traditional graph products is we have",
    "start": "407940",
    "end": "415620"
  },
  {
    "text": "around 176 edge locations across the globe and any changes that you make to",
    "start": "415620",
    "end": "422190"
  },
  {
    "text": "these graphs to your graph rules they are propagated and pushed well under a minute in most cases it's less than 30",
    "start": "422190",
    "end": "429569"
  },
  {
    "text": "seconds I know that there are a lot of other web products that take many hours",
    "start": "429569",
    "end": "435210"
  },
  {
    "text": "to even sometimes days so we know that when it comes to instance response this",
    "start": "435210",
    "end": "442320"
  },
  {
    "text": "is what matters and that was one of our primary goals when we were working on this product and the last part is",
    "start": "442320",
    "end": "449699"
  },
  {
    "start": "447000",
    "end": "470000"
  },
  {
    "text": "scalability and high volume performance like any other ALW service this was",
    "start": "449699",
    "end": "454770"
  },
  {
    "text": "designed to really perform at scale and for huge volume this is essentially",
    "start": "454770",
    "end": "461219"
  },
  {
    "text": "achieved by you know the around a millisecond time that we take and really",
    "start": "461219",
    "end": "467130"
  },
  {
    "text": "inspecting every web request yeah talking about AWS full AWI full logging",
    "start": "467130",
    "end": "476759"
  },
  {
    "start": "470000",
    "end": "503000"
  },
  {
    "text": "this is you know a fully accessible log stream that is made available through",
    "start": "476759",
    "end": "482780"
  },
  {
    "text": "Amazon Kinesis data firehose this is stored in the JSON format you have the",
    "start": "482780",
    "end": "489659"
  },
  {
    "text": "every request inspected by a De Beers flash and you have a lot of HTTP",
    "start": "489659",
    "end": "495180"
  },
  {
    "text": "attributes as well like how you can see you have read based rules and lot of others that's getting captured in your",
    "start": "495180",
    "end": "502220"
  },
  {
    "text": "laughs flocks if you look at the screen you'll be seeing that there are fields",
    "start": "502220",
    "end": "508250"
  },
  {
    "text": "that could really be very insightful for security teams like feels like you know",
    "start": "508250",
    "end": "513680"
  },
  {
    "text": "client IP or client IP or even hose so",
    "start": "513680",
    "end": "520909"
  },
  {
    "text": "this sort of gives you an idea as to who's accessing what in your systems and",
    "start": "520910",
    "end": "526630"
  },
  {
    "text": "make sure you you really know who's accessing your systems that fields like",
    "start": "526630",
    "end": "532280"
  },
  {
    "text": "user agent help you you're not really identify and block your bad box request",
    "start": "532280",
    "end": "537320"
  },
  {
    "text": "yeah yeah I'll call my friend Rohit to",
    "start": "537320",
    "end": "543200"
  },
  {
    "start": "539000",
    "end": "563000"
  },
  {
    "text": "you know continue on the server less analytics services all right thank you so so I'm gonna be talking about a",
    "start": "543200",
    "end": "551390"
  },
  {
    "text": "paradigm called serverless analytics so this covers a few services within AWS",
    "start": "551390",
    "end": "557030"
  },
  {
    "text": "mostly in the big data space so I this will probably be a quick introduction to those big data services so let's talk a",
    "start": "557030",
    "end": "564770"
  },
  {
    "start": "563000",
    "end": "673000"
  },
  {
    "text": "little brief lis about what the serverless operation model is so what does it mean exactly",
    "start": "564770",
    "end": "569900"
  },
  {
    "text": "so serverless means you abstract away the undifferentiated heavy lifting of",
    "start": "569900",
    "end": "574910"
  },
  {
    "text": "server operations so this is an important distinct this is important distinction for our customers because it",
    "start": "574910",
    "end": "580550"
  },
  {
    "text": "frees them up to actually focus on their business value rather than focusing on you know managing infrastructure",
    "start": "580550",
    "end": "587300"
  },
  {
    "text": "patching you know upgrading servers and things like that okay so the the the",
    "start": "587300",
    "end": "593780"
  },
  {
    "text": "real advantages that AWS has is has an operational advantage in providing these capabilities as services to customers so",
    "start": "593780",
    "end": "600560"
  },
  {
    "text": "they can use them out of the box so the first one is you know there's no infrastructure to provision or manage",
    "start": "600560",
    "end": "605990"
  },
  {
    "text": "there's no service to patch there's no you know there's no there's no maintenance or system and registration",
    "start": "605990",
    "end": "611600"
  },
  {
    "text": "required for these services the second point oops sorry okay the second point here is",
    "start": "611600",
    "end": "619520"
  },
  {
    "text": "that it automatically scales with usage on demand what that means is as your traffic grows for example these services",
    "start": "619520",
    "end": "626600"
  },
  {
    "text": "scale automatically like take lambda for example if you've used the AWS lambda if you hit it with more requests",
    "start": "626600",
    "end": "631910"
  },
  {
    "text": "concurrently lambda scales automatically it'll provision more containers are in provision more",
    "start": "631910",
    "end": "637040"
  },
  {
    "text": "instances of lambda for you you never pay for idle resources what that means",
    "start": "637040",
    "end": "642050"
  },
  {
    "text": "is with serverless you don't pay for services to just keep to be running you",
    "start": "642050",
    "end": "647060"
  },
  {
    "text": "pay for services only when they are used so that's called a sort of pay by value model you only pay for the value that",
    "start": "647060",
    "end": "652400"
  },
  {
    "text": "you consume when the service is actually working for you okay and the final point",
    "start": "652400",
    "end": "657620"
  },
  {
    "text": "is its availability fault tolerance and security features are already built in you don't need to think about it",
    "start": "657620",
    "end": "663830"
  },
  {
    "text": "additionally beyond what you already get out of the box with I am and basic security around aw services okay so",
    "start": "663830",
    "end": "670490"
  },
  {
    "text": "that's that's what we wanted to cover with serverless so in the AWS end",
    "start": "670490",
    "end": "675830"
  },
  {
    "text": "database analytics stack there are a number of services that you see over here not all of them are server less",
    "start": "675830",
    "end": "681110"
  },
  {
    "text": "services but the ones that we want to actually highlight are sort of circled over there and those are the services we",
    "start": "681110",
    "end": "687050"
  },
  {
    "text": "are going to be covering in in you know in brief in this in this presentation so",
    "start": "687050",
    "end": "692380"
  },
  {
    "text": "starting from the bottom we have a data movement service called Kinesis data firehose that allows you to sort of",
    "start": "692380",
    "end": "699050"
  },
  {
    "text": "reliably capture data from external data sources as well as internal data sources and move them to another AWS data source",
    "start": "699050",
    "end": "705860"
  },
  {
    "text": "mostly things like glacier elasticsearch or Splunk as well as redshift then we",
    "start": "705860",
    "end": "712310"
  },
  {
    "text": "have s3 as well as glaciers that's our data storage system so a large scale object files file storage system we have",
    "start": "712310",
    "end": "719390"
  },
  {
    "text": "AWS glue which is an ETL and data catalog system we have Athena which is a",
    "start": "719390",
    "end": "724490"
  },
  {
    "text": "managed query engine on top of s3 so we'll cover that as well and then finally we have creating a dashboard for",
    "start": "724490",
    "end": "731600"
  },
  {
    "text": "our end users in quick side okay so",
    "start": "731600",
    "end": "736730"
  },
  {
    "start": "735000",
    "end": "828000"
  },
  {
    "text": "let's go deeply a little bit deeper into Kinesis data firehose so it allows you to capture streaming data from a number",
    "start": "736730",
    "end": "743540"
  },
  {
    "text": "of data sources so Kinesis data firehose as a put api which allows you to send",
    "start": "743540",
    "end": "749390"
  },
  {
    "text": "data from applications from mobile apps from IOT devices etc directly into",
    "start": "749390",
    "end": "754850"
  },
  {
    "text": "firehose and so that allows you to bring your data into AWS once the data is in AWS you can forward the data from",
    "start": "754850",
    "end": "760370"
  },
  {
    "text": "firehose into s3 redshift Amazon elasticsearch or Splunk it's fully",
    "start": "760370",
    "end": "766820"
  },
  {
    "text": "managed to pay-as-you-go you only pay for the volume of data that you ingest if you don't use the service you",
    "start": "766820",
    "end": "772310"
  },
  {
    "text": "don't pay for the service there's no need to manage resources there's no scaling required there's no there's no",
    "start": "772310",
    "end": "777680"
  },
  {
    "text": "service to provision there there is a built-in data transformation piece that",
    "start": "777680",
    "end": "784580"
  },
  {
    "text": "happens along with your stream so for example let's take an example of a date field that's coming in this is a very common problem logs are coming in and",
    "start": "784580",
    "end": "791750"
  },
  {
    "text": "then the data is in a certain format maybe it's your slash month / day and you need it to be mdy for example you",
    "start": "791750",
    "end": "798500"
  },
  {
    "text": "can write a lambda function and you can you can sort of invoke it directly in firehose so that every record that comes",
    "start": "798500",
    "end": "804290"
  },
  {
    "text": "in on firehose is transformed with that lambda function okay so that's that's that's a great feature to use and it",
    "start": "804290",
    "end": "812240"
  },
  {
    "text": "optionally also supports encryption for data so if you if you need if your data is sensitive and it needs to be",
    "start": "812240",
    "end": "817310"
  },
  {
    "text": "encrypted at rest in s 3 firehose supports that as well so you can pass a kms key ID to firehose and it'll",
    "start": "817310",
    "end": "824180"
  },
  {
    "text": "actually encrypt the data address ok",
    "start": "824180",
    "end": "829210"
  },
  {
    "start": "828000",
    "end": "956000"
  },
  {
    "text": "Athena is the queries interactive query service that runs on top of s3 so it's",
    "start": "829270",
    "end": "834950"
  },
  {
    "text": "very easy to analyze this data and you use an C sequel to analyze this data the",
    "start": "834950",
    "end": "840890"
  },
  {
    "text": "this works on a principle of decoupling storage and compute and this is this is a concept that we've seen very often now",
    "start": "840890",
    "end": "847160"
  },
  {
    "text": "with our other service called Amazon EMR which essentially has the compute",
    "start": "847160",
    "end": "852470"
  },
  {
    "text": "service in EMR and the storage service in s3 so each of them can scale independently the same concept applies",
    "start": "852470",
    "end": "858560"
  },
  {
    "text": "here as well your your storage scales independently with s3 and your compute scales with with Athena its server less",
    "start": "858560",
    "end": "866420"
  },
  {
    "text": "because there's no instructure no service to manage no cluster setup ok you pay port query and you only pay for",
    "start": "866420",
    "end": "873320"
  },
  {
    "text": "the data that you scan so that is a very interesting paradigm which means that if you if you are scanning a lot of data",
    "start": "873320",
    "end": "879350"
  },
  {
    "text": "you're paying more if you're scanning you know smaller and more data you pay you pay you know the you know",
    "start": "879350",
    "end": "884600"
  },
  {
    "text": "subsequently quality concurrent amount of for that data so the cost at the",
    "start": "884600",
    "end": "890150"
  },
  {
    "text": "moment is five dollars per terabyte and you can actually lower your cost by compressing your data and actually",
    "start": "890150",
    "end": "896270"
  },
  {
    "text": "improving your performance as well by by partitioning the data as well okay",
    "start": "896270",
    "end": "902029"
  },
  {
    "text": "security is built-in so it supports I am authentication which means that you can use policy based authentication policy",
    "start": "902029",
    "end": "909110"
  },
  {
    "text": "based mechanisms use you for your I am users as well as roles as well as federated access for your your your",
    "start": "909110",
    "end": "917000"
  },
  {
    "text": "identity providers its standards compliant so like I mentioned it",
    "start": "917000",
    "end": "922220"
  },
  {
    "text": "supports ansi sequel directly into a into athena what what i also want to",
    "start": "922220",
    "end": "927560"
  },
  {
    "text": "mention is it supports a JDBC and ODBC interface so you can use your existing BI tools directly with with Athena so",
    "start": "927560",
    "end": "934430"
  },
  {
    "text": "what the what the image there shows a user querying Athena directly with a sequel query Athena uses a data catalog",
    "start": "934430",
    "end": "941540"
  },
  {
    "text": "which has the metadata above these tables that are in s3 and the and the metadata tells it the schema the file",
    "start": "941540",
    "end": "948800"
  },
  {
    "text": "format the compression and things like that and then finally when it's ready to create the data it goes out to s3 queries the data and gives you the",
    "start": "948800",
    "end": "955190"
  },
  {
    "text": "results back ok so this is a screenshot from our demo that we're going to be",
    "start": "955190",
    "end": "961850"
  },
  {
    "start": "956000",
    "end": "983000"
  },
  {
    "text": "showing soon this is this is Athena if you haven't seen this before it allows you to query to write a query called",
    "start": "961850",
    "end": "969350"
  },
  {
    "text": "query directly in the web browser run the query get the results directly there it's it has a history to see all the",
    "start": "969350",
    "end": "976640"
  },
  {
    "text": "saved queries are the saved or the previous results that you you've ran ok",
    "start": "976640",
    "end": "983199"
  },
  {
    "start": "983000",
    "end": "1087000"
  },
  {
    "text": "alright so moving on to AWS glue so goo is a flexible cost-effective automation",
    "start": "983199",
    "end": "989750"
  },
  {
    "text": "tool so it's actually composed of three portions so the first portion is the data catalog the data catalog allows you",
    "start": "989750",
    "end": "996199"
  },
  {
    "text": "to discover and extract schema from from your data sources in this case s3 but it",
    "start": "996199",
    "end": "1002079"
  },
  {
    "text": "can also connect to other data sources such as redshift RDS and even including",
    "start": "1002079",
    "end": "1007180"
  },
  {
    "text": "on-premise data sources ok so once it discovers this it creates metadata within its it's the era catalog and that",
    "start": "1007180",
    "end": "1013600"
  },
  {
    "text": "that can be used by other AWS services including Athena EMR and redshift",
    "start": "1013600",
    "end": "1020740"
  },
  {
    "text": "spectrum ok so once that era's is available to query",
    "start": "1020740",
    "end": "1027180"
  },
  {
    "text": "you can create one of these services the the second feature is that it is a ETL",
    "start": "1027180",
    "end": "1033329"
  },
  {
    "text": "job authoring tool as well which means that you can write code within a within glue to to run jobs which can transform",
    "start": "1033330",
    "end": "1041670"
  },
  {
    "text": "your data in into you know whatever your your business business needs are so for example in this case you can use auto",
    "start": "1041670",
    "end": "1048240"
  },
  {
    "text": "generated code within glue to do some some transformations which are built-in and you can customize that code as well",
    "start": "1048240",
    "end": "1053850"
  },
  {
    "text": "so you it supports Python and Scala essentially a managed spark spark framework and the third part is and it",
    "start": "1053850",
    "end": "1062340"
  },
  {
    "text": "schedules and runs your ETL jobs so it can create these complex workflows which we just launched a feature last week to",
    "start": "1062340",
    "end": "1068850"
  },
  {
    "text": "create these dependencies between triggers and jobs and workflows again",
    "start": "1068850",
    "end": "1075620"
  },
  {
    "text": "it's service flexible and it's built on open standards which means that this meta store is actually hive compatible",
    "start": "1075620",
    "end": "1082020"
  },
  {
    "text": "if you've used highs before you can use this as a drop-in replacement for that hive meta store okay and the the last",
    "start": "1082020",
    "end": "1091110"
  },
  {
    "start": "1087000",
    "end": "1160000"
  },
  {
    "text": "service that we're going to be using is Amazon quick side so it's a fully managed again Service Cloud bi solution",
    "start": "1091110",
    "end": "1097370"
  },
  {
    "text": "you can build visualizations you can share these visualizations with your end-users you can perform ad hoc",
    "start": "1097370",
    "end": "1103170"
  },
  {
    "text": "analysis and filtering directly in the dashboard so let's let's walk over some",
    "start": "1103170",
    "end": "1108900"
  },
  {
    "text": "of the key benefits so there's no server licensing costs you don't deploy it on ec2 instances or servers there's no",
    "start": "1108900",
    "end": "1114750"
  },
  {
    "text": "infrastructure costs you can you can connect your data wherever it is which means that you can connect to any AWS",
    "start": "1114750",
    "end": "1121170"
  },
  {
    "text": "data source that is supported like RDS redshift athina s3 and you can also",
    "start": "1121170",
    "end": "1126600"
  },
  {
    "text": "connect to on Prem data sources it's designed to scale whether you have you know a few users or thousands of users",
    "start": "1126600",
    "end": "1133230"
  },
  {
    "text": "it designed the scale for that for that purpose it's the the one I want to call",
    "start": "1133230",
    "end": "1138750"
  },
  {
    "text": "out is the ml insights portion the ml insights allows is is a quick side sort",
    "start": "1138750",
    "end": "1144060"
  },
  {
    "text": "of automatic feature in quick side which derives machine learning forecasting and analysis and actually generates user",
    "start": "1144060",
    "end": "1151490"
  },
  {
    "text": "narratives directly in the dashboard so you might see these interesting statistics pop out from quick side with",
    "start": "1151490",
    "end": "1157740"
  },
  {
    "text": "are you doing anything okay so this is a dashboard that we're going to be",
    "start": "1157740",
    "end": "1162840"
  },
  {
    "start": "1160000",
    "end": "1175000"
  },
  {
    "text": "actually showing you as part of the demo today so these are using graph logs so it'll split out for example records by",
    "start": "1162840",
    "end": "1170309"
  },
  {
    "text": "country the action count of Records whether it is blocked or allowed things like that okay so finally this is sort",
    "start": "1170309",
    "end": "1178530"
  },
  {
    "start": "1175000",
    "end": "1215000"
  },
  {
    "text": "of how these big data services will flow together and the reason why I want to show this this chart is this is a",
    "start": "1178530",
    "end": "1185040"
  },
  {
    "text": "generalized Big Data pipeline that is applicable to many use cases and many batch and analytics use cases not just",
    "start": "1185040",
    "end": "1191250"
  },
  {
    "text": "you know the one we're talking about today so you can use this for for pretty much any kind of bi analytics that you",
    "start": "1191250",
    "end": "1197580"
  },
  {
    "text": "do so you have a data in s3 you have a glue crawler that creates tables of your data in the data catalog and then you",
    "start": "1197580",
    "end": "1204360"
  },
  {
    "text": "have a tena that uses those tables in the data catalog to expose a tables and",
    "start": "1204360",
    "end": "1209910"
  },
  {
    "text": "then query those tables and then finally you have quick side which is querying Athena okay so I'm gonna hand it over to",
    "start": "1209910",
    "end": "1217740"
  },
  {
    "start": "1215000",
    "end": "1250000"
  },
  {
    "text": "mesh to talk about the solution with it obvious well thanks Ryan yeah you guys",
    "start": "1217740",
    "end": "1223530"
  },
  {
    "text": "might be wondering like why are we talking about all these data analytic",
    "start": "1223530",
    "end": "1228809"
  },
  {
    "text": "services believe me when we do the demo you realize that it is really not very",
    "start": "1228809",
    "end": "1234630"
  },
  {
    "text": "difficult to create these create this solution and by just doing couple of",
    "start": "1234630",
    "end": "1240480"
  },
  {
    "text": "clicks and once you've set it up it's one time that you setup and you will be able to just create your dashboards by",
    "start": "1240480",
    "end": "1247500"
  },
  {
    "text": "just doing certain drag and drops so to quickly go over the complete solution",
    "start": "1247500",
    "end": "1252660"
  },
  {
    "start": "1250000",
    "end": "1387000"
  },
  {
    "text": "Before we jump into the demo it's a double use graph that where you enable",
    "start": "1252660",
    "end": "1259710"
  },
  {
    "text": "VAW slash logs and once you enable AWS five logs which will be evaluating and",
    "start": "1259710",
    "end": "1266550"
  },
  {
    "text": "showing up all the details of the AWS who have fields that I was showing earlier you will stream the Y flocks",
    "start": "1266550",
    "end": "1272880"
  },
  {
    "text": "using Amazon Kinesis fire whole data firehose and the streaming is directly streamed to Amazon s3 bucket and it",
    "start": "1272880",
    "end": "1281190"
  },
  {
    "text": "streams it like how Rohit was explaining in in a partitioned manner and then you",
    "start": "1281190",
    "end": "1287910"
  },
  {
    "text": "can run your rate of this blue crawler job which scans your AWS graph logs and creates",
    "start": "1287910",
    "end": "1296370"
  },
  {
    "text": "your data cataloguing and then it'll also create your Athena table which you could use you not to hit your s3 bucket",
    "start": "1296370",
    "end": "1305010"
  },
  {
    "text": "directly that has your graph logs and really get and if you if you have sequel in expertise within your team you could",
    "start": "1305010",
    "end": "1312030"
  },
  {
    "text": "really get very creative and your sequel query that you'll hit your s3 bucket and directly analyze a lot of things with",
    "start": "1312030",
    "end": "1318780"
  },
  {
    "text": "the logs and then finally you'll have quick site where you can create",
    "start": "1318780",
    "end": "1324630"
  },
  {
    "text": "dashboards to hit Athena and yeah and",
    "start": "1324630",
    "end": "1330060"
  },
  {
    "text": "and you I'll also be showing about another thing called spiced engine within quick site where it literally can",
    "start": "1330060",
    "end": "1336540"
  },
  {
    "text": "also pull in the data periodically and store it within quick site so that you're not hitting Athena for every",
    "start": "1336540",
    "end": "1343740"
  },
  {
    "text": "query that you for every dashboard that you create an quick side yeah also on",
    "start": "1343740",
    "end": "1349680"
  },
  {
    "text": "this side that you're seeing on on this part of the screen where within graph",
    "start": "1349680",
    "end": "1355260"
  },
  {
    "text": "you could create security alerts through metrics that's created based on",
    "start": "1355260",
    "end": "1360570"
  },
  {
    "text": "different graph rules that you'll create but a Tobias graph so let's jump into",
    "start": "1360570",
    "end": "1366480"
  },
  {
    "text": "the demo right now",
    "start": "1366480",
    "end": "1369230"
  },
  {
    "start": "1387000",
    "end": "1507000"
  },
  {
    "text": "okay so right now on the screen you guys are seeing the firehose screen so the",
    "start": "1387990",
    "end": "1395910"
  },
  {
    "text": "firehose stream is you would really go through like six to seven clicks and",
    "start": "1395910",
    "end": "1401370"
  },
  {
    "text": "setting up this firehose stream that I've already set up for the sake of the demo I'll quickly go over these fields",
    "start": "1401370",
    "end": "1407250"
  },
  {
    "text": "you will put in a you will put in a name for the firehose stream which starts with a derby as vlogs and then you you",
    "start": "1407250",
    "end": "1416610"
  },
  {
    "text": "it creates a name role for you to grant access for the firehose to stream this",
    "start": "1416610",
    "end": "1422400"
  },
  {
    "text": "data to s3 source you set it to direct port or other sources yeah here is here",
    "start": "1422400",
    "end": "1431250"
  },
  {
    "text": "some other important things like you can in this for the sake of the demo we've",
    "start": "1431250",
    "end": "1436410"
  },
  {
    "text": "disabled the transformation but like how raw it was explaining you guys can use",
    "start": "1436410",
    "end": "1441690"
  },
  {
    "text": "transformation if you have lambda expertise within your team to really transform the data there you can convert",
    "start": "1441690",
    "end": "1449910"
  },
  {
    "text": "the data format from JSON to parque or row RC format for better or more",
    "start": "1449910",
    "end": "1456120"
  },
  {
    "text": "efficient performance and yeah if you're doing any transformations you can it's",
    "start": "1456120",
    "end": "1462420"
  },
  {
    "text": "always a good idea to backup your data and s3 the original log files and at",
    "start": "1462420",
    "end": "1469050"
  },
  {
    "text": "last you want to make sure when you set your Amazon s3 destination to s3 bucket",
    "start": "1469050",
    "end": "1474120"
  },
  {
    "text": "you can set your prefix so here you can set the prefix to certain values that",
    "start": "1474120",
    "end": "1479850"
  },
  {
    "text": "will help you to partition your data so that you your performance is better and",
    "start": "1479850",
    "end": "1486630"
  },
  {
    "text": "you always want to make sure you enable compression and enable encryption for",
    "start": "1486630",
    "end": "1492090"
  },
  {
    "text": "better performance and lower cost and also more security I mean make it more",
    "start": "1492090",
    "end": "1498780"
  },
  {
    "text": "secure enable cloud watch log error error logging for you know any",
    "start": "1498780",
    "end": "1504390"
  },
  {
    "text": "troubleshooting purposes so once you've set up the so when I showed the Genesis",
    "start": "1504390",
    "end": "1514290"
  },
  {
    "start": "1507000",
    "end": "1531000"
  },
  {
    "text": "Pharaohs set up for enabling graph logging there are two parts to it this",
    "start": "1514290",
    "end": "1520110"
  },
  {
    "text": "was the first one the second part is about creating enabling graph logs so",
    "start": "1520110",
    "end": "1526920"
  },
  {
    "text": "let me go over to graph here",
    "start": "1526920",
    "end": "1530870"
  },
  {
    "start": "1531000",
    "end": "1582000"
  },
  {
    "text": "so if I pick one of these rules that you see you you see something called web",
    "start": "1535440",
    "end": "1542410"
  },
  {
    "text": "ackles here web a CL is construct within a Tobias graph which is nothing but a",
    "start": "1542410",
    "end": "1548800"
  },
  {
    "text": "container of a WAF rules this just holds a set of rules and again these rules are",
    "start": "1548800",
    "end": "1555460"
  },
  {
    "text": "the ones that hold conditions and filters like you know they're a sequel",
    "start": "1555460",
    "end": "1560890"
  },
  {
    "text": "injection conditions and cross-site scripting conditions so these are the",
    "start": "1560890",
    "end": "1566220"
  },
  {
    "text": "these are the conditions these are the rules against which your web requests are being evaluated and your logging is",
    "start": "1566220",
    "end": "1573220"
  },
  {
    "text": "happening and the to enable logging for a specific rule go over to logging click",
    "start": "1573220",
    "end": "1582250"
  },
  {
    "start": "1582000",
    "end": "1630000"
  },
  {
    "text": "on enable logging here is where you choose the fire host stream that you",
    "start": "1582250",
    "end": "1587440"
  },
  {
    "text": "would have created this is the one that I just showed the one that I had already created for the sake of demo so yeah",
    "start": "1587440",
    "end": "1595690"
  },
  {
    "text": "here is another interesting piece so if if you really do not want to be logging all the fields in your database graph",
    "start": "1595690",
    "end": "1602590"
  },
  {
    "text": "logs and say there are some fields that your team is just not interested in you can redact those fields and cut the",
    "start": "1602590",
    "end": "1609400"
  },
  {
    "text": "clutter that by just adding those fields here so that that's not really captured in your wife locks it wouldn't even go",
    "start": "1609400",
    "end": "1616240"
  },
  {
    "text": "to your s3 bucket then and yeah you can just hit create there to create since",
    "start": "1616240",
    "end": "1622180"
  },
  {
    "text": "I've already created one I'm gonna be going over to the s3 bucket to show the",
    "start": "1622180",
    "end": "1628300"
  },
  {
    "text": "logs so this is one of the this is the",
    "start": "1628300",
    "end": "1633460"
  },
  {
    "start": "1630000",
    "end": "1660000"
  },
  {
    "text": "bucket that where I'm already streaming you know graph logs in my account for",
    "start": "1633460",
    "end": "1639220"
  },
  {
    "text": "the last couple of months and and it's in the format of year month date and",
    "start": "1639220",
    "end": "1648130"
  },
  {
    "text": "then you have hours so if you go to one of those over the third hour there you're seeing an AWS log which is a JSON",
    "start": "1648130",
    "end": "1656080"
  },
  {
    "text": "file that's generated there so let's go to glue here so in a double use glue",
    "start": "1656080",
    "end": "1664180"
  },
  {
    "start": "1660000",
    "end": "1695000"
  },
  {
    "text": "group chloric crawler is the of that you would run which you would",
    "start": "1664180",
    "end": "1669200"
  },
  {
    "text": "execute it generally these jobs take around a few minutes to run and this is",
    "start": "1669200",
    "end": "1674900"
  },
  {
    "text": "what creates your table this is the Athena table that my crawler job has",
    "start": "1674900",
    "end": "1680360"
  },
  {
    "text": "created and if you go to this table you will see that it's defined it's given",
    "start": "1680360",
    "end": "1686090"
  },
  {
    "text": "your table name the database it's also you know showing the schema of the files",
    "start": "1686090",
    "end": "1692150"
  },
  {
    "text": "that it's captured and since this is the",
    "start": "1692150",
    "end": "1697280"
  },
  {
    "start": "1695000",
    "end": "1710000"
  },
  {
    "text": "table that's already created let's go to Athena and look at the table so",
    "start": "1697280",
    "end": "1703550"
  },
  {
    "text": "reinforces this database and this is the table here so if you see here you will",
    "start": "1703550",
    "end": "1710870"
  },
  {
    "start": "1710000",
    "end": "1867000"
  },
  {
    "text": "see that the the table that's created",
    "start": "1710870",
    "end": "1717050"
  },
  {
    "text": "has a number of records that it will display but it will also show some of",
    "start": "1717050",
    "end": "1723200"
  },
  {
    "text": "the these fields that are in in your nested format okay looks like there's a",
    "start": "1723200",
    "end": "1732620"
  },
  {
    "text": "connectivity problem let me just reconnect and read on the query there",
    "start": "1732620",
    "end": "1740080"
  },
  {
    "text": "okay let me just open up another window for Athena and rerun that some of the",
    "start": "1747020",
    "end": "1756440"
  },
  {
    "text": "steel connections always create a problem",
    "start": "1756440",
    "end": "1761050"
  },
  {
    "text": "okay yeah that's what I was trying to look for the time that's running so here",
    "start": "1767400",
    "end": "1772680"
  },
  {
    "text": "is the query that you show and I mean if you see the records here Jason the JSON",
    "start": "1772680",
    "end": "1778350"
  },
  {
    "text": "file has certain nested nested structures where you will see these",
    "start": "1778350",
    "end": "1784730"
  },
  {
    "text": "you'll see a number of Records and within each record you'll have these nested loops of different HTTP header",
    "start": "1784730",
    "end": "1790800"
  },
  {
    "text": "values that you see here and I've created this I mean we've created this sequel that",
    "start": "1790800",
    "end": "1797940"
  },
  {
    "text": "will really help us do a join - more",
    "start": "1797940",
    "end": "1804060"
  },
  {
    "text": "like unflattering the number of Records so that you really see all the records like how you would see it in a sequel",
    "start": "1804060",
    "end": "1811290"
  },
  {
    "text": "database and it will show up you know all the extracted fields right when the",
    "start": "1811290",
    "end": "1817020"
  },
  {
    "text": "queries performed and this is the exact query that we will also be using in",
    "start": "1817020",
    "end": "1823310"
  },
  {
    "text": "quick side when we create the dashboards",
    "start": "1823310",
    "end": "1828290"
  },
  {
    "text": "okay for some reason",
    "start": "1831559",
    "end": "1835789"
  },
  {
    "text": "okay yeah some reason when I kick it off here the state connections are not",
    "start": "1842950",
    "end": "1849010"
  },
  {
    "text": "kicking off but yeah you'll see the query here that's ran and what I wanted",
    "start": "1849010",
    "end": "1854440"
  },
  {
    "text": "to show here is the HTTP header fields that are extracted from these sequels are now showing up as different columns",
    "start": "1854440",
    "end": "1860890"
  },
  {
    "text": "you know that you can't really extract and use in your charts so now I'll go to",
    "start": "1860890",
    "end": "1868020"
  },
  {
    "start": "1867000",
    "end": "1904000"
  },
  {
    "text": "quick side so to show it to you from the start",
    "start": "1868020",
    "end": "1873190"
  },
  {
    "text": "so if I have to create a new quick side I will say new analysis I'll say new",
    "start": "1873190",
    "end": "1879280"
  },
  {
    "text": "data set here and since our data source so quick side supports a number of data",
    "start": "1879280",
    "end": "1884920"
  },
  {
    "text": "source like a Roy Roy it was mentioning so in our case since it's Athena I'm gonna choose Athena here I'll type in a",
    "start": "1884920",
    "end": "1893920"
  },
  {
    "text": "name and call it demo so here I'll use a",
    "start": "1893920",
    "end": "1900490"
  },
  {
    "text": "custom sequel since we have a custom sequel that we want to use here and you can hit edit preview to really go run",
    "start": "1900490",
    "end": "1908080"
  },
  {
    "start": "1904000",
    "end": "1916000"
  },
  {
    "text": "your query and you know create the dashboard for the demo purpose again",
    "start": "1908080",
    "end": "1914200"
  },
  {
    "text": "right there when you had created this is the dashboard that would have got created so this is one dashboard where I",
    "start": "1914200",
    "end": "1921700"
  },
  {
    "start": "1916000",
    "end": "1985000"
  },
  {
    "text": "just dragged the country to this dashboard and you saw these various countries so I mean the data of graph",
    "start": "1921700",
    "end": "1927910"
  },
  {
    "text": "log across various countries displaying here I'll add couple of more charts to",
    "start": "1927910",
    "end": "1933520"
  },
  {
    "text": "just show how easy it is to you know create multiple dashboard and get more insights",
    "start": "1933520",
    "end": "1940890"
  },
  {
    "text": "so say here I would run I would want to see buy action you would look at all",
    "start": "1943460",
    "end": "1949440"
  },
  {
    "text": "these different block requests and action allowed requests and here say I",
    "start": "1949440",
    "end": "1954900"
  },
  {
    "text": "would want to look at by country I'll add the country as well here and I want",
    "start": "1954900",
    "end": "1960180"
  },
  {
    "text": "to see it right within what's allowed and what's blocked by country and here",
    "start": "1960180",
    "end": "1965340"
  },
  {
    "text": "you will see blog you have around thousand requests blogged in France and around 100 are in US so you you can",
    "start": "1965340",
    "end": "1972900"
  },
  {
    "text": "really get creative with the different visual types that you have here I'll add",
    "start": "1972900",
    "end": "1980640"
  },
  {
    "text": "a couple of more of such graphs to highlight few other features so let's",
    "start": "1980640",
    "end": "1991590"
  },
  {
    "start": "1991000",
    "end": "2083000"
  },
  {
    "text": "let's go with timestamp now so since I've had it's timestamp it's just gone",
    "start": "1991590",
    "end": "1998340"
  },
  {
    "text": "through all your raft logs across different you know years in 2018 and",
    "start": "1998340",
    "end": "2004400"
  },
  {
    "text": "2019 showing different spikes now here I want to see as to you know I really want",
    "start": "2004400",
    "end": "2012410"
  },
  {
    "text": "to magnify for a month like say for January data of this year I could just",
    "start": "2012410",
    "end": "2018050"
  },
  {
    "text": "create a filter and it's as simple as choosing timestamp again and adding",
    "start": "2018050",
    "end": "2025280"
  },
  {
    "text": "range from say January first to end of",
    "start": "2025280",
    "end": "2033680"
  },
  {
    "text": "January and hit apply it's going to",
    "start": "2033680",
    "end": "2041180"
  },
  {
    "text": "magnify and show that and during this time stamp I could really go and see",
    "start": "2041180",
    "end": "2047680"
  },
  {
    "text": "what all are blocked so I could really add another one and you will see there's",
    "start": "2048130",
    "end": "2053780"
  },
  {
    "text": "really very less that's blog most of it is allowed and yeah I just saw one that was blocked there and you could even",
    "start": "2053780",
    "end": "2060830"
  },
  {
    "text": "further you know go across for a week's time and play around here yeah and one",
    "start": "2060830",
    "end": "2066679"
  },
  {
    "text": "other thing is you could really apply this filter to all visuals if you want",
    "start": "2066680",
    "end": "2071720"
  },
  {
    "text": "and say you could put it across all the visuals by just hitting all these reels here and it",
    "start": "2071720",
    "end": "2078339"
  },
  {
    "text": "will go across and do it all now with this maybe I'll add one other visual for",
    "start": "2078339",
    "end": "2084339"
  },
  {
    "start": "2083000",
    "end": "2173000"
  },
  {
    "text": "you and let's play around with one of the HTTP headers let's go with HTTP",
    "start": "2084339",
    "end": "2092679"
  },
  {
    "text": "method so I want to know what sort of reads and writes are happening and I",
    "start": "2092679",
    "end": "2098770"
  },
  {
    "text": "really want to know of these what all are blogged and allowed so so what I'm",
    "start": "2098770",
    "end": "2107200"
  },
  {
    "text": "trying to show here is to give you an idea as to how simple it is or how creative you can get in you know really",
    "start": "2107200",
    "end": "2113560"
  },
  {
    "text": "analyzing your data here and here one other thing that it gives us now see you",
    "start": "2113560",
    "end": "2119530"
  },
  {
    "text": "want to you've created some dashboards and you want to share it across steams you want to give it your business team",
    "start": "2119530",
    "end": "2125530"
  },
  {
    "text": "or your leadership team you could really capture this as a snapshot and play this",
    "start": "2125530",
    "end": "2132609"
  },
  {
    "text": "is a story that's gonna display you know at that moment the snapshot for you and",
    "start": "2132609",
    "end": "2139119"
  },
  {
    "text": "if you want to share it right within across within AWS it's again as simple",
    "start": "2139119",
    "end": "2145030"
  },
  {
    "text": "as hitting share and publishing and sharing that URL or just share the",
    "start": "2145030",
    "end": "2151540"
  },
  {
    "text": "analysis and put in the AWS username by email id here and share this dashboard",
    "start": "2151540",
    "end": "2157270"
  },
  {
    "text": "across to your you know your team so",
    "start": "2157270",
    "end": "2163210"
  },
  {
    "text": "this is about yeah this that's where the demo ends and we will have couple of",
    "start": "2163210",
    "end": "2169990"
  },
  {
    "text": "more slides that we will go over",
    "start": "2169990",
    "end": "2173819"
  },
  {
    "start": "2173000",
    "end": "2554000"
  },
  {
    "text": "yeah I'll hand it over to Rohit to add you know talk more about few additional",
    "start": "2176329",
    "end": "2182430"
  },
  {
    "text": "ml patterns okay so we showed how we used back and created a dashboard with",
    "start": "2182430",
    "end": "2188160"
  },
  {
    "text": "some server assembly tools let's talk about some more use cases for graph logs okay so and these used machine learning",
    "start": "2188160",
    "end": "2195569"
  },
  {
    "text": "in some form or the other the first one is a managed service called guard duty",
    "start": "2195569",
    "end": "2202410"
  },
  {
    "text": "it's a service that continuously monitors your for malicious activity unauthorized access by analyzing VPC",
    "start": "2202410",
    "end": "2209550"
  },
  {
    "text": "flow logs cloud trail logs and route 53 DNS logs so it's it's a machine it uses",
    "start": "2209550",
    "end": "2217560"
  },
  {
    "text": "machine learning to identify these records and it's a fully managed service and what it does it actually generates cloud watch event or which we call",
    "start": "2217560",
    "end": "2224460"
  },
  {
    "text": "findings in this in this chart once those findings are generated we can take some action on those findings so you can",
    "start": "2224460",
    "end": "2230190"
  },
  {
    "text": "have a lambda subscribe to those cloud watch events and it can parse those events what that really does is it can",
    "start": "2230190",
    "end": "2237030"
  },
  {
    "text": "make you it can really let you take a decision on whether you consider that event to be useful or not and if you do",
    "start": "2237030",
    "end": "2244260"
  },
  {
    "text": "find it useful for example to block that specific host you can store that in a dynamodb table and then you can use that",
    "start": "2244260",
    "end": "2250500"
  },
  {
    "text": "for sort of checking the state for to see whether it's already been blocked or not if it's not been blocked for example",
    "start": "2250500",
    "end": "2256500"
  },
  {
    "text": "you can go ahead and update your graph log directly from your lambda function using the SDK or the API from from lamda",
    "start": "2256500",
    "end": "2263460"
  },
  {
    "text": "what that means is the where the rule will be updated and hopefully eventually that closed loop will will happen so",
    "start": "2263460",
    "end": "2270359"
  },
  {
    "text": "that guard duty will not find those events any any more so that sort of improves your overall security by",
    "start": "2270359",
    "end": "2276630"
  },
  {
    "text": "blocking those events so this is really a managed way of doing it and it's sort of a very hands-off way except for the",
    "start": "2276630",
    "end": "2283470"
  },
  {
    "text": "lambda function that you have to write if you want to read more about it please look at check out the blog post that we",
    "start": "2283470",
    "end": "2288930"
  },
  {
    "text": "have over there it's a great blog post allows you to deploy the solution in your own account the second solution",
    "start": "2288930",
    "end": "2295530"
  },
  {
    "text": "that we want to talk about is for for those who want to do a more hands-on approach and who want to say build their",
    "start": "2295530",
    "end": "2301650"
  },
  {
    "text": "own machine learning model so we are introducing a service in this chart called AWS Amazon sage maker so sage may",
    "start": "2301650",
    "end": "2309450"
  },
  {
    "text": "say is a fully managed machine learning service on on AWS and what that lets you",
    "start": "2309450",
    "end": "2315130"
  },
  {
    "text": "do is it lets you build train and deploy models on machine learning models on on",
    "start": "2315130",
    "end": "2320680"
  },
  {
    "text": "AWS so you can choose from either a variety of built-in algorithms and",
    "start": "2320680",
    "end": "2326320"
  },
  {
    "text": "models or you can choose to train your own so in this case we have listed three",
    "start": "2326320",
    "end": "2331390"
  },
  {
    "text": "algorithms on the right there which are suitable for sort of log analysis for anomaly detection random cut forests IP",
    "start": "2331390",
    "end": "2338770"
  },
  {
    "text": "insights are both unsupervised models that can be used for this kind of thing DPR is a forecasting supervised model",
    "start": "2338770",
    "end": "2346660"
  },
  {
    "text": "which can be used for anomaly detection for sort of trend lines and time series analysis excuse me if you want to read",
    "start": "2346660",
    "end": "2354310"
  },
  {
    "text": "more about for example IP insights as a blog post there as well which allows you to use IP insights with sage maker and",
    "start": "2354310",
    "end": "2361119"
  },
  {
    "text": "do some training on it but anyway coming back to the to the solution here we have",
    "start": "2361119",
    "end": "2366340"
  },
  {
    "text": "logs coming in from a variety of data sources so let's say we have VPC flow logs we have logs you think of it that",
    "start": "2366340",
    "end": "2372520"
  },
  {
    "text": "you can have additional logs as well which are may be meaningful to your business those go into firehose you of",
    "start": "2372520",
    "end": "2379030"
  },
  {
    "text": "course have a separate stream so in firehose for these for these and they will actually write the data out to s3",
    "start": "2379030",
    "end": "2385540"
  },
  {
    "text": "once the day rise in s3 you will periodically run a sage make a training job against the data in s3 let's say you",
    "start": "2385540",
    "end": "2391900"
  },
  {
    "text": "run it on a week's worth of data you'll get a week's worth of logs in s3 you will run a sage maker training on that that's kind of an offline process that",
    "start": "2391900",
    "end": "2398830"
  },
  {
    "text": "happens from the rest of the pipeline but when that happens sage maker creates a model artifact of the trained model that you've developed",
    "start": "2398830",
    "end": "2406150"
  },
  {
    "text": "when that is when you've created a trained model you can deploy that trained model to Sage make an inference",
    "start": "2406150",
    "end": "2412000"
  },
  {
    "text": "endpoint and what that means is it creates an HTTP endpoint which you can use by passing it events and it'll give",
    "start": "2412000",
    "end": "2419109"
  },
  {
    "text": "you a score back so that's that's one way in which sage maker allows you to do sort of inference and it'll give you a",
    "start": "2419109",
    "end": "2425619"
  },
  {
    "text": "normally score or the score really depends on how on the accuracy of how you've trained the model and the data set that you've used to train it but you",
    "start": "2425619",
    "end": "2432400"
  },
  {
    "text": "get the idea so going back to how it works so let's say a wife log comes in it goes through fire hose it goes to s3",
    "start": "2432400",
    "end": "2438820"
  },
  {
    "text": "it lands in s3 that gets an event notification to lambda when that gets an event on lambda a lambda can parse the event",
    "start": "2438820",
    "end": "2445390"
  },
  {
    "text": "and then it can use each record in that vlog event to send a message to Sage to",
    "start": "2445390",
    "end": "2450910"
  },
  {
    "text": "say the sage make an inference endpoint and ask it to give it a score a result for that for that you know for that for",
    "start": "2450910",
    "end": "2457000"
  },
  {
    "text": "that record now based on what score you get from from Sage Maker you can then make a decision on whether you need to",
    "start": "2457000",
    "end": "2462370"
  },
  {
    "text": "update the way flog rules or not so the idea is that really over time this",
    "start": "2462370",
    "end": "2467980"
  },
  {
    "text": "becomes a closed loop model where your raft log rules improve as your as your as your model improves as your training",
    "start": "2467980",
    "end": "2474970"
  },
  {
    "text": "data improves and then you start blocking more and more events that are malicious for example the the other",
    "start": "2474970",
    "end": "2482230"
  },
  {
    "text": "thing I want to point out is your once this is built really your security teams",
    "start": "2482230",
    "end": "2487270"
  },
  {
    "text": "can take this model and productionize it with really not a lot more you know and",
    "start": "2487270",
    "end": "2492580"
  },
  {
    "text": "not not too much of change besides sort of retraining which can also be done in an automated way you can additionally",
    "start": "2492580",
    "end": "2499240"
  },
  {
    "text": "also augment the data that's in s3 so let's say you have you have data that is very specific to your environment you",
    "start": "2499240",
    "end": "2505450"
  },
  {
    "text": "are you know maybe it's a private network completely that you only want to block a certain range of ips and within",
    "start": "2505450",
    "end": "2511030"
  },
  {
    "text": "that range you may have malicious IP so you can do all that augmentation directly on the training data set so it",
    "start": "2511030",
    "end": "2516880"
  },
  {
    "text": "really depends on how you train it so yep so please check out the blog post as well that's what we had so these are",
    "start": "2516880",
    "end": "2524500"
  },
  {
    "text": "some references this is a webinar that was given on this very topic on YouTube",
    "start": "2524500",
    "end": "2530110"
  },
  {
    "text": "in the past so you can look at that as well as a blog post which is which is - which talks about what we've we are",
    "start": "2530110",
    "end": "2536110"
  },
  {
    "text": "presenting here today so I think with that we conclude thank you very much",
    "start": "2536110",
    "end": "2541180"
  },
  {
    "text": "everyone for joining us today and please you know give us any feedback and",
    "start": "2541180",
    "end": "2546640"
  },
  {
    "text": "complete the session survey in the mobile app thank you very much in Kok",
    "start": "2546640",
    "end": "2553109"
  }
]
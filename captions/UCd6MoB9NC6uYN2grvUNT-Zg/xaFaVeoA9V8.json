[
  {
    "text": "alright hello and welcome my name is Bob Wilkinson I'm the general manager for Amazon CloudWatch such an exciting time",
    "start": "140",
    "end": "7770"
  },
  {
    "text": "to be here at reinvent with all of you customers and partners in the audience we're here today to talk about cloud",
    "start": "7770",
    "end": "13380"
  },
  {
    "text": "watch logs and Lambeth two services were pretty excited about so this is a quick audience poll the level set here how",
    "start": "13380",
    "end": "18480"
  },
  {
    "text": "many of your cloud watch logs users today alright love all those hands I'd",
    "start": "18480",
    "end": "24180"
  },
  {
    "text": "say definitely we're half now what about lambda how many of yous lambda in some context all right almost",
    "start": "24180",
    "end": "29820"
  },
  {
    "text": "as many now here's the key question how many of you have done both how many of you have known a lambda function with",
    "start": "29820",
    "end": "35489"
  },
  {
    "text": "your logs in some way all right pretty small so it looks like you might be in the right place I hope we have some some",
    "start": "35489",
    "end": "41190"
  },
  {
    "text": "really interesting things for you and of course these are gonna be focused on monitoring and how we are gonna give you some new tools to do more with",
    "start": "41190",
    "end": "47430"
  },
  {
    "text": "monitoring and tailor these monitoring use cases for your needs so what we'll do first is I'd like to",
    "start": "47430",
    "end": "52469"
  },
  {
    "text": "spend just a few minutes talking about industry trends and monitoring I think these are important because it really informs us you know Hawaii we have to",
    "start": "52469",
    "end": "59309"
  },
  {
    "text": "think about monitoring why it's important and what we're doing about it is cloud watch next we'll just briefly",
    "start": "59309",
    "end": "64530"
  },
  {
    "text": "talk about what is cloud watching cloud wash logs a little bit intro to lambda as well just to level set for the more",
    "start": "64530",
    "end": "69840"
  },
  {
    "text": "important part of the talk and then I'll be joined by my colleague Robert wah he's gonna walk us through three specific use cases that will show you so",
    "start": "69840",
    "end": "77490"
  },
  {
    "text": "the first scenario will be about centralizing logs so this will be a way to take logs or log data that maybe an",
    "start": "77490",
    "end": "83400"
  },
  {
    "text": "s3 and centralize it in cloud which logs so that you can do that use the features of cloud watch logs the second scenario",
    "start": "83400",
    "end": "89700"
  },
  {
    "text": "is a way to enrich alarms so it's a way to take the basic alarm notification out",
    "start": "89700",
    "end": "95460"
  },
  {
    "text": "of Klawock alarms enrich that with other information that makes it more actionable gives your users and",
    "start": "95460",
    "end": "100590"
  },
  {
    "text": "operators more context when they get that alarm and then last we'll show you how to build an on-demand scalable",
    "start": "100590",
    "end": "106500"
  },
  {
    "text": "elasticsearch cluster so this is a use case where you may want to do a specific data analysis not keep that cluster",
    "start": "106500",
    "end": "111659"
  },
  {
    "text": "running all the time not bear the management burden of that but just you have a particular window of data you'd like to get to elasticsearch and do some",
    "start": "111659",
    "end": "117780"
  },
  {
    "text": "deeper analysis all right so I'm gonna start with a meme if you bear with me",
    "start": "117780",
    "end": "122869"
  },
  {
    "text": "know if you ever haven't even seen that this is flying dog I think it's my colleagues told me this is the the most",
    "start": "122869",
    "end": "128610"
  },
  {
    "text": "popular meme of 2016 I don't know if that's true or not but I think this applies in a lot of context and I would sit",
    "start": "128610",
    "end": "133860"
  },
  {
    "text": "it to you that this dog has a monitoring problem does he not I mean how many times have we been in this situation we",
    "start": "133860",
    "end": "139860"
  },
  {
    "text": "think everything's okay but actually it's not so let's walk through a little scenario you know this is actually is a",
    "start": "139860",
    "end": "146610"
  },
  {
    "text": "true story I've changed some names to protect the innocent all right so so you own important app seems like",
    "start": "146610",
    "end": "154560"
  },
  {
    "text": "everything's okay right the you didn't know anything was going on customer rights a ticket says important app is",
    "start": "154560",
    "end": "159959"
  },
  {
    "text": "down melissa's news so john the uncle developer is paged he starts to engage none of your alarms fired here you",
    "start": "159959",
    "end": "166080"
  },
  {
    "text": "didn't know what was going on what i've tried to do on each step of our scenario here is capture the kind of the",
    "start": "166080",
    "end": "171570"
  },
  {
    "text": "predominant emotions going through and i would suggest here you've heard of blissful ignorance right it's fine we didn't even know anything was going on",
    "start": "171570",
    "end": "176610"
  },
  {
    "text": "turns out something is going on all right so john the operator starts to engage",
    "start": "176610",
    "end": "181850"
  },
  {
    "text": "starts to look at dashboard remember he didn't have an alarm so he's not directly pointed to a run book he's sort of looking at the dashboards trying to",
    "start": "181850",
    "end": "187890"
  },
  {
    "text": "discern what's going on he does see some sort of impact he sees some some intermittent availability impact on the",
    "start": "187890",
    "end": "192989"
  },
  {
    "text": "dashboard he's not sure really how many customers might be affected or really where to begin troubleshooting I think",
    "start": "192989",
    "end": "199200"
  },
  {
    "text": "he makes a good call here he asked late so manager on-call so here I think we're gonna say two confusion right John",
    "start": "199200",
    "end": "205380"
  },
  {
    "text": "really doesn't know what's going on made a good step to escalate to his manager all right more tickets are pouring in",
    "start": "205380",
    "end": "212250"
  },
  {
    "text": "here so this is does appear to be a pretty real incident more things are happening our escalation manager Jane has joined",
    "start": "212250",
    "end": "218670"
  },
  {
    "text": "the event she starts to help to starts to try to assess the situation impact low and behold their CTO is also noticed",
    "start": "218670",
    "end": "225239"
  },
  {
    "text": "this through through watching something else he said Jane what's going on with important app now I don't know about you",
    "start": "225239",
    "end": "230580"
  },
  {
    "text": "but I've been in situations like this and I started to feel stress here right the thing you own is down customers are",
    "start": "230580",
    "end": "237690"
  },
  {
    "text": "having problems you're not living up to your expectations this gets quite stressful alright so now",
    "start": "237690",
    "end": "244530"
  },
  {
    "text": "John and Jane of course they're on the hook here they recall there was some recent issue where they saw some",
    "start": "244530",
    "end": "249930"
  },
  {
    "text": "customers that were issuing expensive operations they say well maybe that's what's going on here maybe there's a customer that's changed their behavior",
    "start": "249930",
    "end": "255570"
  },
  {
    "text": "John starts to log dive unfortunately this wasn't a Halal that they had put in Clow its logs or some other source for",
    "start": "255570",
    "end": "261989"
  },
  {
    "text": "the centralized so he's on the host he's running greps trying to figure something out they identify me",
    "start": "261989",
    "end": "267900"
  },
  {
    "text": "be a customer that might be doing something John sees some expensive queries in the logs so they run through",
    "start": "267900",
    "end": "273360"
  },
  {
    "text": "the process here Jane cuts a ticket to that team saying hey you know please stop whatever you're doing John's gonna go ahead and prepare a",
    "start": "273360",
    "end": "278820"
  },
  {
    "text": "change to blacklist this customer now they don't know it yet but actually this is false hope right we don't really know",
    "start": "278820",
    "end": "284160"
  },
  {
    "text": "if this was what's going on turns out it was not so the other team engages said they hadn't done anything there was no",
    "start": "284160",
    "end": "290130"
  },
  {
    "text": "deployment they didn't change anything that that application was always doing those queries and then John and Jane",
    "start": "290130",
    "end": "295770"
  },
  {
    "text": "confirm the same thing when after they deploy this black list the event still continues they're still seeing this intermittent available it impacts",
    "start": "295770",
    "end": "301580"
  },
  {
    "text": "they're kind of out of ideas here and John says you know what we have a standby let's just failover it can't",
    "start": "301580",
    "end": "307590"
  },
  {
    "text": "hurt right now all right here I would suggest we're probably at this stage of desperation now in this case",
    "start": "307590",
    "end": "314460"
  },
  {
    "text": "there's a happy and to hear it actually that actually does work so the failover worked in Port Napa recovers yay life is",
    "start": "314460",
    "end": "319530"
  },
  {
    "text": "good John and Jane pursue through a pretty good root cause process turns out",
    "start": "319530",
    "end": "324810"
  },
  {
    "text": "a few weeks ago they'd use the new JDBC version there was different semantics for unclosing connections in that",
    "start": "324810",
    "end": "330180"
  },
  {
    "text": "version introduced a memory leak led to Java heap exhaustion GC pauses was",
    "start": "330180",
    "end": "335520"
  },
  {
    "text": "causing these availability impacts so they fixed the leak they add the alarms a memory usage of course that probably",
    "start": "335520",
    "end": "341430"
  },
  {
    "text": "should have been there they've tuned the service alarms right we were missing this it was an intermittent impacts where service alarms didn't take you",
    "start": "341430",
    "end": "347820"
  },
  {
    "text": "know didn't tell us something was going on there like it should have we've reached maybe a state of enlightenment here but I say can't we do",
    "start": "347820",
    "end": "354300"
  },
  {
    "text": "can we do better than this right is this really the the state of monitoring and where it should be today and I don't",
    "start": "354300",
    "end": "359849"
  },
  {
    "text": "think so and I'll call it a few things here I think there's probably more but often we have missing alarms and a lot",
    "start": "359849",
    "end": "365310"
  },
  {
    "text": "of times we have those alarms they're not as actual as they could be now if you remember that's going to be one of our demos the second demo will be how do",
    "start": "365310",
    "end": "370860"
  },
  {
    "text": "we take our alarms and make them more actionable using lambda in this case second case often we don't have the",
    "start": "370860",
    "end": "376889"
  },
  {
    "text": "right logs maybe also not the right metrics in this case but we also don't have the right logs and interacting with",
    "start": "376889",
    "end": "383159"
  },
  {
    "text": "them can be tedious and so we're one of the another one of the demo scenarios will be about how to take information that may reside somewhere else and put",
    "start": "383159",
    "end": "389699"
  },
  {
    "text": "it in a place such as cloud which logs where you can use it to interact with it in real-time and then finally our",
    "start": "389699",
    "end": "396389"
  },
  {
    "text": "dashboards aren't always telling us enough information about customer impacts or the behavior changes that they're making",
    "start": "396389",
    "end": "401430"
  },
  {
    "text": "so you remember in this scenario we sort of started out we weren't sure that we knew there was something going on we didn't know how many customers were",
    "start": "401430",
    "end": "406919"
  },
  {
    "text": "being impacted and we can just we can do better here too now we won't cover this in the demo today but hopefully we'll",
    "start": "406919",
    "end": "413039"
  },
  {
    "text": "maybe can come back and tell you about that sometime soon so I think hopefully",
    "start": "413039",
    "end": "418199"
  },
  {
    "text": "we've seen through this obviously monitoring is super important right if we had the right monitoring place hopefully we could have seen this case",
    "start": "418199",
    "end": "423960"
  },
  {
    "text": "before it ever started before it ever impacted customers but also we start to see why this is really hard so let's look take one step back and",
    "start": "423960",
    "end": "431639"
  },
  {
    "text": "talk about these more macro trends in the industry that's making monitoring really hard right now one is that complexity is increasing",
    "start": "431639",
    "end": "438020"
  },
  {
    "text": "right our applications are built off micro services so lots of components lots of micro services we heard a lot",
    "start": "438020",
    "end": "444030"
  },
  {
    "text": "about that in the keynote today applications are written in different languages and frameworks they're increasingly running on transient",
    "start": "444030",
    "end": "449970"
  },
  {
    "text": "resources like containers and serverless compute which we're going to talk about today there's specialization of the persistence tier it's not just apps",
    "start": "449970",
    "end": "456449"
  },
  {
    "text": "built on relational databases anymore right we know this that there's no sequel databases and sequel databases and in-memory databases and every other",
    "start": "456449",
    "end": "463229"
  },
  {
    "text": "every database Under the Sun applications are more dynamic right we",
    "start": "463229",
    "end": "468720"
  },
  {
    "text": "also saw this in the keynote as well today but we're testing and building and deploying small changes so we're rapidly",
    "start": "468720",
    "end": "474780"
  },
  {
    "text": "changing our application and as the scale and design of all these things change changing so are the infrastructure needs to go along with it",
    "start": "474780",
    "end": "480770"
  },
  {
    "text": "applications are global and with that comes customer behavior that's increasingly unpredictable and then we",
    "start": "480770",
    "end": "486870"
  },
  {
    "text": "know that this the role of automation is increasing right we need to automate more and more of our processes but this",
    "start": "486870",
    "end": "492060"
  },
  {
    "text": "means this is also magnifying all those changes so our monitoring has to keep up next maybe speaking to why monitor is so",
    "start": "492060",
    "end": "500340"
  },
  {
    "text": "important but there's more and more business impact London I will write the role of applications in business outcomes such as revenue costs and SLA",
    "start": "500340",
    "end": "507440"
  },
  {
    "text": "we know that businesses everywhere or having to evolve themselves to maintain and gain competitive advantage and",
    "start": "507440",
    "end": "513709"
  },
  {
    "text": "undeniably we all have increased the ex-patient expectations from our customers for the applications and",
    "start": "513709",
    "end": "519150"
  },
  {
    "text": "services that we're building and the last trend I think is that monitoring is no longer a standalone thing because of",
    "start": "519150",
    "end": "525570"
  },
  {
    "text": "all these other trends you know we used to roll up a server and put some software on it maybe we create a static dashboard and then just watch that",
    "start": "525570",
    "end": "531900"
  },
  {
    "text": "dashboard once a week and life was good but it's not like that anymore we know that right we're provisioning resources",
    "start": "531900",
    "end": "537180"
  },
  {
    "text": "containers and instances and using lamb Don these things are being provisioned in real time we have to you know",
    "start": "537180",
    "end": "542250"
  },
  {
    "text": "configure them in real time and monitor them in real time so there are all these trends that are making monitoring",
    "start": "542250",
    "end": "547320"
  },
  {
    "text": "increasingly important but also increasingly hard so as cloud watch what",
    "start": "547320",
    "end": "552450"
  },
  {
    "text": "are we doing about this so cloud watch today it's a portfolio of tools covering metrics alarms logs events dashboards",
    "start": "552450",
    "end": "559170"
  },
  {
    "text": "there'll be more over time but how we think about this it's really these four these four areas I'd like to talk about",
    "start": "559170",
    "end": "565050"
  },
  {
    "text": "which is to help you see then react diagnose ultimately to resolve whatever",
    "start": "565050",
    "end": "570300"
  },
  {
    "text": "problems may be impacting your applications and services so first to see so what we're doing today car watch",
    "start": "570300",
    "end": "577500"
  },
  {
    "text": "a day gives you metrics logs events from a all your AWS resources that's we're using and well we'll have a constant",
    "start": "577500",
    "end": "583620"
  },
  {
    "text": "list of these you know the growing list of these over time will probably bore more now of course in each case as well",
    "start": "583620",
    "end": "588660"
  },
  {
    "text": "these metrics logs and events you can do your own you can do your own custom from the api's that we provide now what",
    "start": "588660",
    "end": "595470"
  },
  {
    "text": "you'll see from us over the near term in this area will be easier tools to collect and publish metrics and logs so",
    "start": "595470",
    "end": "601650"
  },
  {
    "text": "increasing amount of agents and SDKs that we provide to make it easier to get the admit ryx so that you need from your",
    "start": "601650",
    "end": "606959"
  },
  {
    "text": "applications and services so next with all that data that you're seeing have to be able to react to that and do that in",
    "start": "606959",
    "end": "612779"
  },
  {
    "text": "in increasingly intelligent way so today of course you can define an alarm which is a ability to look at a metric you",
    "start": "612779",
    "end": "619830"
  },
  {
    "text": "define a threshold that crosses the threshold and you can trigger some action similarly you can write an event rule so you can say when I see this",
    "start": "619830",
    "end": "625680"
  },
  {
    "text": "event I'd like to take this particular action off in a lambda function in this area we'll be providing more and smarter",
    "start": "625680",
    "end": "633060"
  },
  {
    "text": "ways to act on these things so think of it you know more advanced trigger criteria for alarms we're looking at how",
    "start": "633060",
    "end": "639300"
  },
  {
    "text": "to do a prediction based alarm so we can alarm on prediction bands and things well these are all things you'll see from us over the relatively near term",
    "start": "639300",
    "end": "645450"
  },
  {
    "text": "roadmap that we're doing now when we look to diagnose right after you've reacted so you just know something is",
    "start": "645450",
    "end": "651240"
  },
  {
    "text": "going on but now I have to figure out what's going on and ideally you know hopefully this becomes automated as well but so here you have tools like cloud",
    "start": "651240",
    "end": "657870"
  },
  {
    "text": "dashboards that allowing you to inspect navigate zoom across your data something",
    "start": "657870",
    "end": "662940"
  },
  {
    "text": "we did recently was the announcement of metrics to log so since we launched the log service there was all",
    "start": "662940",
    "end": "668700"
  },
  {
    "text": "the ability to generate metrics from those log streams we now gave you a tool to jump from a metric graph or a",
    "start": "668700",
    "end": "674370"
  },
  {
    "text": "dashboard into the particular logs that generated that metric so it's really common troubleshooting pattern that we",
    "start": "674370",
    "end": "680340"
  },
  {
    "text": "see is when you see a point on a dashboard you'd like to investigate well what would the logs actually telling me to get those more details of what's",
    "start": "680340",
    "end": "686400"
  },
  {
    "text": "going on there at last as I said hopefully all of this really is about resolving problems faster and with less",
    "start": "686400",
    "end": "692370"
  },
  {
    "text": "effort and increasingly we see that over time where we need to head as a community is we have to make this",
    "start": "692370",
    "end": "699180"
  },
  {
    "text": "automate it right so in many cases what will help to be eventually is that we can detect these problems before they're",
    "start": "699180",
    "end": "705060"
  },
  {
    "text": "ever impacting customers and do something about it take those actions so you know today we give you tools such as",
    "start": "705060",
    "end": "710280"
  },
  {
    "text": "again clutch actions we'll show you ways to do it with lambda she'll be able to do that but increasingly looking at this",
    "start": "710280",
    "end": "718080"
  },
  {
    "text": "too need to be automated alright so just briefly if you've been paying attention",
    "start": "718080",
    "end": "723480"
  },
  {
    "text": "we have done quite a few announcements so I'll run through them quickly we announce the metrics price drop we think",
    "start": "723480",
    "end": "728760"
  },
  {
    "text": "you need more metrics and we hope that a new price helps you to to do that as I",
    "start": "728760",
    "end": "733950"
  },
  {
    "text": "said we'll do more metrics logs and event sources I haven't listed them all there's always going to be a long list of these coming out I mentioned the",
    "start": "733950",
    "end": "740730"
  },
  {
    "text": "metrics the logs navigation so this is sort of graphically shown where you're looking at a metric graph and a bill to",
    "start": "740730",
    "end": "746100"
  },
  {
    "text": "draw drill to the logs we upgraded our metric retention from two weeks out to 15 months this was done automatically it",
    "start": "746100",
    "end": "753510"
  },
  {
    "text": "will gradually grow to 15 months over time we didn't want to wait 15 months to launch it just all that history was there Werner mentioned this this morning",
    "start": "753510",
    "end": "761310"
  },
  {
    "text": "but we support arbitrary metric percentiles so this is the ability to look at something like ELB request",
    "start": "761310",
    "end": "767310"
  },
  {
    "text": "latency and see the difference between your p50 or your average and your p90 or p99 or whatever value makes sense you'll",
    "start": "767310",
    "end": "773490"
  },
  {
    "text": "often see a graph like us on the upper right where that that p50 maybe a relatively flat line but you're seeing",
    "start": "773490",
    "end": "779190"
  },
  {
    "text": "something interesting at the higher percentile values at p99 we find that that's a really important tool and it's one of the important tools",
    "start": "779190",
    "end": "784950"
  },
  {
    "text": "we use to manage our services internally the Amazon in the to help with that C",
    "start": "784950",
    "end": "790650"
  },
  {
    "text": "aspect we released an open source plugin for collecti that helps you publish on",
    "start": "790650",
    "end": "795900"
  },
  {
    "text": "host metrics about your processes your instances and whatnot into cloud watch we've had a number of improvements and",
    "start": "795900",
    "end": "802620"
  },
  {
    "text": "boards over the year so we had new widgets a dark theme y-axis limits and now families had a chance to clear out",
    "start": "802620",
    "end": "808380"
  },
  {
    "text": "the new widgets we lost about a month ago and a little bit early in the year we revamped our logs consoles we had a",
    "start": "808380",
    "end": "814020"
  },
  {
    "text": "lot of feedback from you that our logs console needed to be more usable so we we revamped out and cut a lot of good feedback on that I hope that's helped",
    "start": "814020",
    "end": "820170"
  },
  {
    "text": "you to interact with your logs in real time now I spend a lot of time talking about cloud watch but really it's",
    "start": "820170",
    "end": "826380"
  },
  {
    "text": "important to know here this is not just about what's inside cloud watch you know we've said monitoring is hard it's really hard and energy you know every",
    "start": "826380",
    "end": "833580"
  },
  {
    "text": "Enterprise team situation is gonna have unique needs and so you know any",
    "start": "833580",
    "end": "838590"
  },
  {
    "text": "discussion of cloud watch is really not complete without discussion or a partner ecosystem it's really important we've",
    "start": "838590",
    "end": "843630"
  },
  {
    "text": "got partners in the APM space and the login analytics space and the operational dashboarding space and these",
    "start": "843630",
    "end": "849120"
  },
  {
    "text": "are all helping you to do you know helping you to meet these unique needs that you have because it's never just going to be what some inside cloud watch",
    "start": "849120",
    "end": "854880"
  },
  {
    "text": "and then yep may be equally as importantly and so we give you the tools and flexibility to do great cloud watch",
    "start": "854880",
    "end": "860340"
  },
  {
    "text": "with other a2b of services and of course we're gonna see that here shortly with Robert it's gonna walk us through some of this but there's a lot of powerful",
    "start": "860340",
    "end": "865890"
  },
  {
    "text": "ways to integrate these different things and really tailor the monitoring to your own needs in your own business needs in",
    "start": "865890",
    "end": "871350"
  },
  {
    "text": "your own application needs so I'm gonna dive just a bit deeper into the two",
    "start": "871350",
    "end": "876630"
  },
  {
    "text": "services we're talking today before I hand it over to Robert so first cloud which logs it's a managed log service it was built for arbitrary",
    "start": "876630",
    "end": "883590"
  },
  {
    "text": "scale availability durability and security what customers are doing today first is centralizing their logs so I've",
    "start": "883590",
    "end": "889800"
  },
  {
    "text": "shown ingress options over to the left we have a logs agent that you can install in any host any agent this",
    "start": "889800",
    "end": "895620"
  },
  {
    "text": "allows you to point it at a log file and and stream those logs in near-real-time we've done native integration with a",
    "start": "895620",
    "end": "901140"
  },
  {
    "text": "number of aw services again this will be growing over time some of the more popular ones today are Cloud trail VPC",
    "start": "901140",
    "end": "906540"
  },
  {
    "text": "flow logs lambda ECS logs was mentioned in the keynote this morning by having all those",
    "start": "906540",
    "end": "912240"
  },
  {
    "text": "logs centralized what you get is you get the ability to search those so you can you can run text searches in near real time and as I mentioned you can also",
    "start": "912240",
    "end": "918780"
  },
  {
    "text": "extract metrics from those which is a powerful feature because you can take a particular data element in the log and",
    "start": "918780",
    "end": "924140"
  },
  {
    "text": "have that emitted as a metric which is then something you can put on a graph set an alarm on or to take other action",
    "start": "924140",
    "end": "929820"
  },
  {
    "text": "on which we'll see her shortly of course once they're inside the service its retention policy is according to what",
    "start": "929820",
    "end": "935460"
  },
  {
    "text": "you you can all it's secured pretty soon we'll be launching kms support so that will you know on top of the encryption we already",
    "start": "935460",
    "end": "941999"
  },
  {
    "text": "do inside of logs you'll be able to use your own KMS keys to encrypt logs and then equally interesting is what you can",
    "start": "941999",
    "end": "947879"
  },
  {
    "text": "do on the egress side of logs so again you know we know that it's not just about What's in logs and what you can do",
    "start": "947879",
    "end": "954480"
  },
  {
    "text": "there now but we know that there's many tools that you're going to use and these egress options allow you to do that so we've integrated with a number of AWS",
    "start": "954480",
    "end": "960509"
  },
  {
    "text": "services including Kinesis where you can egress a filtered subset of your logs to",
    "start": "960509",
    "end": "966240"
  },
  {
    "text": "a Kinesis stream and then consume those in whatever way you'd see fit we have a built in integration with Amazon elastic",
    "start": "966240",
    "end": "972660"
  },
  {
    "text": "search so from the console you can walk through a setup step of pointing again a filter instead of your logs at an",
    "start": "972660",
    "end": "979019"
  },
  {
    "text": "elastic search cluster you can associate a Lando function to your log repr log stream such that you can take a",
    "start": "979019",
    "end": "984360"
  },
  {
    "text": "particular action on a log of this coming through and then we also have an s3 capability to exports so it's this is",
    "start": "984360",
    "end": "990240"
  },
  {
    "text": "a batch export where you can take a particular time range of data export it to an s3 bucket up Robert actually use",
    "start": "990240",
    "end": "996149"
  },
  {
    "text": "this one of his demo scenarios now lambda just briefly hopefully you know",
    "start": "996149",
    "end": "1001970"
  },
  {
    "text": "this as well but it's a server list compute write we use this this buzzword but it really means that you can run",
    "start": "1001970",
    "end": "1007189"
  },
  {
    "text": "code without having to worry about the tedium of managing servers a lot werner did a great job this morning and",
    "start": "1007189",
    "end": "1012949"
  },
  {
    "text": "characterizing some of that so it's you write the code it only runs when you need it to you're only paying for when",
    "start": "1012949",
    "end": "1018230"
  },
  {
    "text": "it's running so at this point I am gonna turn it over to Robert and he's gonna start to walk us through our three",
    "start": "1018230",
    "end": "1023990"
  },
  {
    "text": "scenarios thank you Bob hi I'm Robert hua a service owner for",
    "start": "1023990",
    "end": "1029569"
  },
  {
    "text": "cloud watch logs we wanted to present you three demonstrations as Bob",
    "start": "1029569",
    "end": "1034909"
  },
  {
    "text": "introduced don't worry about copying down the code we're gonna have a link at",
    "start": "1034909",
    "end": "1040188"
  },
  {
    "text": "the end it's a link to the github repository for these examples so you can customize them for your own purposes so",
    "start": "1040189",
    "end": "1046579"
  },
  {
    "text": "first we're gonna look at how to centralize logs the essentially the",
    "start": "1046579",
    "end": "1052669"
  },
  {
    "text": "problem here is that you've got your logs scattered all over the place you've got containers you've got instances you've got stuff being delivered in s3",
    "start": "1052669",
    "end": "1059059"
  },
  {
    "text": "and if you think that having a centralized log repository with consistent api's and access controls and",
    "start": "1059059",
    "end": "1065389"
  },
  {
    "text": "retention policies is important you need to figure out some way to federate all that data one place so and once it's in that one",
    "start": "1065389",
    "end": "1073160"
  },
  {
    "text": "place in club which allows your able to search and filter extract metrics and these sort of things today Claude watch",
    "start": "1073160",
    "end": "1078679"
  },
  {
    "text": "offers an agent for instance logs and for a lot of services at eighty of us and more and more over time those those",
    "start": "1078679",
    "end": "1085250"
  },
  {
    "text": "can directly integrate with cloud watch logs but there are sub products and services that still deliver logs s3 so",
    "start": "1085250",
    "end": "1090799"
  },
  {
    "text": "how do you get those into your central repository essentially what we're gonna do here is we're going to do a",
    "start": "1090799",
    "end": "1096080"
  },
  {
    "text": "demonstration using ELB which you can configure to send your access logs to s3 we're going to set up a object create",
    "start": "1096080",
    "end": "1104360"
  },
  {
    "text": "event notification to lambda which is going to trigger a lambda function read the elbe log from s3 and then publish it",
    "start": "1104360",
    "end": "1111380"
  },
  {
    "text": "to cloud watch logs so in this demonstration we're going to set up a little sample stack we set up three",
    "start": "1111380",
    "end": "1117679"
  },
  {
    "text": "Apache servers one crazy as yours you should always do we're going to set up a",
    "start": "1117679",
    "end": "1124070"
  },
  {
    "text": "you'll be fronting those those three Apache servers we had those three Apache",
    "start": "1124070",
    "end": "1129350"
  },
  {
    "text": "servers to our OB and we go in and we configure s3 delivery of the access log",
    "start": "1129350",
    "end": "1136760"
  },
  {
    "text": "to our s3 bucket now that we have that going as objects are being created you",
    "start": "1136760",
    "end": "1144830"
  },
  {
    "text": "have the option to set up a lambda function to trigger on the s3 object creation our lambda function is going to",
    "start": "1144830",
    "end": "1152380"
  },
  {
    "text": "invoke when an object's create an s3 so he'll be delivering logs into s3",
    "start": "1152380",
    "end": "1158360"
  },
  {
    "text": "creating objects land function invokes wakes up it gets the s3 object out",
    "start": "1158360",
    "end": "1164110"
  },
  {
    "text": "decompresses it breaks it up into pieces and then calls the AWS SDK put log",
    "start": "1164110",
    "end": "1170750"
  },
  {
    "text": "events API for cloud watch logs you can use this in any of your applications we have a number of customers that use this",
    "start": "1170750",
    "end": "1177110"
  },
  {
    "text": "API to to do file less logging to log",
    "start": "1177110",
    "end": "1182360"
  },
  {
    "text": "straight to the cloud watch songs directly but in this case we're going to use it to pull in these s3 objects the",
    "start": "1182360",
    "end": "1188660"
  },
  {
    "text": "EOB has been delivering and putting them to iCloud watch logs this is an interesting point where you can do some",
    "start": "1188660",
    "end": "1194570"
  },
  {
    "text": "transformation maybe get some metadata from other services and that's also going to add it to your logs to annotate",
    "start": "1194570",
    "end": "1201960"
  },
  {
    "text": "as part of that so now that we've got all this set up we go in to test it out we you know do some accesses hitting the",
    "start": "1201960",
    "end": "1209730"
  },
  {
    "text": "default page and we start seeing the EOB logs delivering to s3 and as you see",
    "start": "1209730",
    "end": "1217289"
  },
  {
    "text": "there's just a collection of compressed files you know you're not really able to",
    "start": "1217289",
    "end": "1222960"
  },
  {
    "text": "search them or do anything else with that however because they're limited functions invoking the background as these things are being created the data",
    "start": "1222960",
    "end": "1230789"
  },
  {
    "text": "is flowing in in near-real-time into your cloud watch logs console and now you can see the timeline series the",
    "start": "1230789",
    "end": "1237990"
  },
  {
    "text": "data organized in a way that a little easier to deal with in a collection of compressed files we're able to for",
    "start": "1237990",
    "end": "1246480"
  },
  {
    "text": "instance search the data in this case we're searching for get requests for the last day and we're also able to extract",
    "start": "1246480",
    "end": "1253860"
  },
  {
    "text": "metrics of the data especially when your access logs land you posted the metrics service so in this case let's say we're",
    "start": "1253860",
    "end": "1261240"
  },
  {
    "text": "gonna look for a request that had latency is greater than one millisecond and we want to keep it count of how many",
    "start": "1261240",
    "end": "1268640"
  },
  {
    "text": "requests are breaching or expected SLA is we define our ELB latency filter and",
    "start": "1268640",
    "end": "1275970"
  },
  {
    "text": "this is a counting metric we assign it a default value of one as you see below here if you've configured your metric",
    "start": "1275970",
    "end": "1284429"
  },
  {
    "text": "filter you can also choose a bunch of other things for instance you can pull out status codes or received bytes sent",
    "start": "1284429",
    "end": "1290580"
  },
  {
    "text": "and emit those into a metric now once the as the as the log data is landing",
    "start": "1290580",
    "end": "1297240"
  },
  {
    "text": "into the s3 bucket being triggered triggering a de lambda function which is putting a cloud watch logs cloud which",
    "start": "1297240",
    "end": "1303450"
  },
  {
    "text": "logs is extracting a metric out of that for these high latency requests and we can see our high latency requests here",
    "start": "1303450",
    "end": "1310200"
  },
  {
    "text": "in this graph with the changes that Bob mentioned on metrics logs you'd be able",
    "start": "1310200",
    "end": "1316230"
  },
  {
    "text": "to narrow in on a spike in your latency and then ask it to take you straight to",
    "start": "1316230",
    "end": "1323220"
  },
  {
    "text": "those log entries and only show you the log entries that are above your latency threshold so in this using this this",
    "start": "1323220",
    "end": "1332279"
  },
  {
    "text": "demonstration you're able to now centralize any of your logs that are being delivered in s3 alongside",
    "start": "1332279",
    "end": "1338130"
  },
  {
    "text": "your instance logs using our agent or logs delivered from Amazon services you're able to search and extract from",
    "start": "1338130",
    "end": "1344700"
  },
  {
    "text": "these from these logs in near-real-time in our second demonstration we're gonna",
    "start": "1344700",
    "end": "1350850"
  },
  {
    "text": "look at customizing alarms today when you receive an alarm you may not have",
    "start": "1350850",
    "end": "1357180"
  },
  {
    "text": "all the information that you need from your business attach the alarm we include information that we think is helpful to you as a customer but it's",
    "start": "1357180",
    "end": "1364830"
  },
  {
    "text": "very general purpose you know we don't know your specific needs so it may not",
    "start": "1364830",
    "end": "1370200"
  },
  {
    "text": "be an actual enough if you have special information you'd like to put in there because ultimately when you get paged",
    "start": "1370200",
    "end": "1377460"
  },
  {
    "text": "let's say you're you know you're out to dinner and you get a page and it's really not the best time to dive in at a",
    "start": "1377460",
    "end": "1383760"
  },
  {
    "text": "laptop it's really helpful to be able to look at your page and see the context of",
    "start": "1383760",
    "end": "1388860"
  },
  {
    "text": "what was going on and you know you can make a decision whether it needs immediate attention or you can defer it or it's possibly something that you need",
    "start": "1388860",
    "end": "1395460"
  },
  {
    "text": "to escalate and rotate to another service operator team and you can do",
    "start": "1395460",
    "end": "1402570"
  },
  {
    "text": "that action if you can get it right there on the initial alert you may still want to add your run books and other",
    "start": "1402570",
    "end": "1409350"
  },
  {
    "text": "metadata and information to your alarms so that your operators can know very quickly where to get started and what's",
    "start": "1409350",
    "end": "1416250"
  },
  {
    "text": "expected given this type of alarm so this one what we're gonna do is we're going to generate error logs which we're",
    "start": "1416250",
    "end": "1424470"
  },
  {
    "text": "sending to cloud watch logs and then trigger an alarm off of that which will be published with SNS topic that SNS",
    "start": "1424470",
    "end": "1431760"
  },
  {
    "text": "topic will trigger an event notification in lambda and we'll have a lambda function that's going to pull the",
    "start": "1431760",
    "end": "1437070"
  },
  {
    "text": "information out of the alarm go back search the log service for the SLA",
    "start": "1437070",
    "end": "1442920"
  },
  {
    "text": "breach that was emitted from the from the log service and invoke SES with",
    "start": "1442920",
    "end": "1450210"
  },
  {
    "text": "those logs to for it on to the operator to tell them you know rich text format",
    "start": "1450210",
    "end": "1455790"
  },
  {
    "text": "with your runbook and everything else attached to it what to do so similar to",
    "start": "1455790",
    "end": "1462990"
  },
  {
    "text": "the prior thing we're going to set up a little dummy application in this case we're going to set up a Tomcat we've got",
    "start": "1462990",
    "end": "1468720"
  },
  {
    "text": "our which logs agent installed on it so it's forwarding over the HTTP request in the real time well you see here the time",
    "start": "1468720",
    "end": "1476460"
  },
  {
    "text": "line of data as it flows through we go ahead and we set up another metric extraction as we as we did before in",
    "start": "1476460",
    "end": "1482880"
  },
  {
    "text": "this case we want to look for unauthorized access attempts so we want to see if somebody's trying to penetrate our service so we look for a status code",
    "start": "1482880",
    "end": "1491520"
  },
  {
    "text": "for o1 in those logs again this is a counting metric so we choose the metric",
    "start": "1491520",
    "end": "1496710"
  },
  {
    "text": "value of one and we give it a name unauthorized access filter now we're gonna go in we're going to create an",
    "start": "1496710",
    "end": "1501870"
  },
  {
    "text": "alarm based on that this alarm as we see it's after in one consecutive point if",
    "start": "1501870",
    "end": "1509760"
  },
  {
    "text": "we see more than five unauthorized access attempts we're gonna trigger an alarm notification to our on call we now",
    "start": "1509760",
    "end": "1517650"
  },
  {
    "text": "attach a lambda function to the SNS topic that the alarm notifications going",
    "start": "1517650",
    "end": "1523470"
  },
  {
    "text": "to and we've created an example lambda",
    "start": "1523470",
    "end": "1528810"
  },
  {
    "text": "function which is again available in our github repository that will show at the end of the deck here and what's what",
    "start": "1528810",
    "end": "1534480"
  },
  {
    "text": "this is doing is it's taking the alarm notification from the SNS message it's pulling out the the metric name the",
    "start": "1534480",
    "end": "1541350"
  },
  {
    "text": "network namespace as well as other information such as the the time of the",
    "start": "1541350",
    "end": "1546540"
  },
  {
    "text": "alarm using that information we're able",
    "start": "1546540",
    "end": "1551820"
  },
  {
    "text": "to call actually sorry in the previous site we're able to call the public API",
    "start": "1551820",
    "end": "1558060"
  },
  {
    "text": "describe metric filters through the AWS SDK which takes in a metric name and",
    "start": "1558060",
    "end": "1566250"
  },
  {
    "text": "gives you back the log groups and the metric filter definitions attached to it now one of the interesting things about",
    "start": "1566250",
    "end": "1572730"
  },
  {
    "text": "how we've implemented metrics to logs and how logs works is that our Search API our search syntax for searching logs",
    "start": "1572730",
    "end": "1580350"
  },
  {
    "text": "has exactly the same syntax as the syntax used for extracting metrics from",
    "start": "1580350",
    "end": "1585510"
  },
  {
    "text": "logs so that means you can take that same metric filter definition and apply",
    "start": "1585510",
    "end": "1590550"
  },
  {
    "text": "it to our filter log events API you remember remember in the prior slide we",
    "start": "1590550",
    "end": "1596340"
  },
  {
    "text": "described the metric filters we got the log group out we got a the filter pattern out and from the alarm we know",
    "start": "1596340",
    "end": "1602370"
  },
  {
    "text": "the time Stan that are relevant like when the alarms stop and window alarms start and when",
    "start": "1602370",
    "end": "1608429"
  },
  {
    "text": "did it stop so we're able to call filter log events with these parameters with the log group that we want to search",
    "start": "1608429",
    "end": "1614280"
  },
  {
    "text": "with the filter expression that identifies the log entries and the time",
    "start": "1614280",
    "end": "1619590"
  },
  {
    "text": "range of the alarm and we get out a sample of log data which we then",
    "start": "1619590",
    "end": "1624750"
  },
  {
    "text": "generate an email out of by merging in our template for on-call support with",
    "start": "1624750",
    "end": "1631020"
  },
  {
    "text": "both the instance information and the log messages from that particular alarm period along with let's say runbook",
    "start": "1631020",
    "end": "1638640"
  },
  {
    "text": "information the account region other metadata you you know you could if you have the instance as the stream the",
    "start": "1638640",
    "end": "1644760"
  },
  {
    "text": "inference you could go out and call ec to metadata calls and annotate it so the",
    "start": "1644760",
    "end": "1650460"
  },
  {
    "text": "security thing so maybe you want to put in the security group information and other pieces of data test it out we go",
    "start": "1650460",
    "end": "1658470"
  },
  {
    "text": "and we generate a bunch of 4'o ones and we get our alarm this is the normal",
    "start": "1658470",
    "end": "1664140"
  },
  {
    "text": "alarm that you get today from CloudWatch alarms it's got essentially all the information you need in it but it's not",
    "start": "1664140",
    "end": "1670080"
  },
  {
    "text": "necessarily in the format that your on call needs in order to resolve a problem quickly your on call however receives a",
    "start": "1670080",
    "end": "1678570"
  },
  {
    "text": "message that tells them clearly what the alarm was what the runbook for resolving",
    "start": "1678570",
    "end": "1684270"
  },
  {
    "text": "this sort of situation is the account region other metadata the time of the alarm and then it gives them a sample of",
    "start": "1684270",
    "end": "1691770"
  },
  {
    "text": "each of the events that contributed to the alarm being triggered so with this",
    "start": "1691770",
    "end": "1698160"
  },
  {
    "text": "sort of pattern you can customize your alarms to add specific details better issues and customize your alerting to",
    "start": "1698160",
    "end": "1704850"
  },
  {
    "text": "your specific for your specific business we see a spike in metrics you can also",
    "start": "1704850",
    "end": "1710850"
  },
  {
    "text": "get the logs that were generated when triggering the alarm and the Elana function can be extended to add whatever",
    "start": "1710850",
    "end": "1716880"
  },
  {
    "text": "information you'd like now we're on to our third demonstration here in this",
    "start": "1716880",
    "end": "1723570"
  },
  {
    "text": "demonstration we're going to build an on-demand scalable elasticsearch cluster",
    "start": "1723570",
    "end": "1730070"
  },
  {
    "text": "we announced last year our ability to integrate seamlessly with the Amazon elastic search service",
    "start": "1730490",
    "end": "1736920"
  },
  {
    "text": "the way that that works today is that data is flowing and in real time and if you if you want to do log analysis so",
    "start": "1736920",
    "end": "1743310"
  },
  {
    "text": "the elasticsearch service using the data to look from clench logs it needs to always be running in accumulating that",
    "start": "1743310",
    "end": "1750420"
  },
  {
    "text": "data in real time but sometimes we don't to leave that cluster running all the time that musically we have to we have some you just another thing to manage to",
    "start": "1750420",
    "end": "1757740"
  },
  {
    "text": "scale to watch and make sure it's operating correctly plus you're paying",
    "start": "1757740",
    "end": "1762990"
  },
  {
    "text": "for it all the time and if you're not looking at these logs at all times it's not a very good use of of your budget",
    "start": "1762990",
    "end": "1768980"
  },
  {
    "text": "and sometimes our logs are not critical logs at all times sometimes they're you know if mass",
    "start": "1768980",
    "end": "1775740"
  },
  {
    "text": "amounts of firewall logs or you know system message logs and these may be relatively low value to have an indexed",
    "start": "1775740",
    "end": "1782700"
  },
  {
    "text": "product at all time play with the cloud watched logs pricing model it's affordable to collect them all but now",
    "start": "1782700",
    "end": "1789600"
  },
  {
    "text": "you if you want to do some sort of deep dive analysis on it you need to be able",
    "start": "1789600",
    "end": "1795450"
  },
  {
    "text": "to take that historical data from any point in time export it into an elastic search cluster and we're going to show",
    "start": "1795450",
    "end": "1801360"
  },
  {
    "text": "you here is a way to do that on demand so what we do here is we collect cloud",
    "start": "1801360",
    "end": "1807420"
  },
  {
    "text": "watch logs data over a period of time then we're going to go through and we're gonna use the export to s3 functionality",
    "start": "1807420",
    "end": "1813810"
  },
  {
    "text": "in cloud which allows borrowing the pattern that we use in the first demonstration we're going to trigger on",
    "start": "1813810",
    "end": "1820380"
  },
  {
    "text": "the object create event notifications to lambda then our lambda functions going",
    "start": "1820380",
    "end": "1825390"
  },
  {
    "text": "to transform the data restructure it maybe add in some it meta information",
    "start": "1825390",
    "end": "1830690"
  },
  {
    "text": "from other services similar to what we saw in the prior examples but you can",
    "start": "1830690",
    "end": "1837600"
  },
  {
    "text": "also break up the log into it into more detailed pieces for indexing and elastic",
    "start": "1837600",
    "end": "1843510"
  },
  {
    "text": "search through this and then we're going to forward those logs to the elastic search et bien point so we first go and",
    "start": "1843510",
    "end": "1851790"
  },
  {
    "text": "we're gonna configure the VPC flow logs for people that aren't familiar with this this is the ability to capture",
    "start": "1851790",
    "end": "1856860"
  },
  {
    "text": "essentially a span port audit summary for your VPC it gives you information on",
    "start": "1856860",
    "end": "1863460"
  },
  {
    "text": "source and destination IP s ports the amount of data transferred whether a CL is accepted or rejected",
    "start": "1863460",
    "end": "1869970"
  },
  {
    "text": "a common pattern is you know making sure that your accept and reject criterias",
    "start": "1869970",
    "end": "1875790"
  },
  {
    "text": "for your VPC access is what you actually believe it to be so you well you the way",
    "start": "1875790",
    "end": "1881700"
  },
  {
    "text": "you enable these logs did you go into the V PC console you choose your V PC and you ask and there's a there's a flow",
    "start": "1881700",
    "end": "1888840"
  },
  {
    "text": "logs tab where you configure whether you want to get the accept reject or all the",
    "start": "1888840",
    "end": "1894900"
  },
  {
    "text": "events and set up the roll for delivery to Klutch logs and which destination log",
    "start": "1894900",
    "end": "1901110"
  },
  {
    "text": "group those logs will go to once we've got that configured in our V PC flow",
    "start": "1901110",
    "end": "1908250"
  },
  {
    "text": "logs Law Group we start seeing log streams of information one per eni and",
    "start": "1908250",
    "end": "1914540"
  },
  {
    "text": "an event level in this case this is all the events McCann choose between ax",
    "start": "1914540",
    "end": "1921690"
  },
  {
    "text": "accept or reject or all and so we see here we've got all the accept and the rejects in here as well the log data it",
    "start": "1921690",
    "end": "1930180"
  },
  {
    "text": "it's a little dense and hard to consume as a human being it's got timestamps Ian's eyes IP",
    "start": "1930180",
    "end": "1937680"
  },
  {
    "text": "addresses port numbers and all sorts of stuff in there so we're gonna go ahead",
    "start": "1937680",
    "end": "1942690"
  },
  {
    "text": "and set this up into our last search cluster so we go into the elastic search console and we created an elastic search",
    "start": "1942690",
    "end": "1950490"
  },
  {
    "text": "domain we set it up with a number of nodes that we need and the instance",
    "start": "1950490",
    "end": "1956040"
  },
  {
    "text": "types and those sort of things click create and it goes off and starts creating or elastic search cluster for",
    "start": "1956040",
    "end": "1961380"
  },
  {
    "text": "us in the meantime we go in and we set up our lambda function as we saw in the",
    "start": "1961380",
    "end": "1968160"
  },
  {
    "text": "first demonstration - on s3 object.create to trigger a lambda function and in our lambda function",
    "start": "1968160",
    "end": "1975120"
  },
  {
    "text": "we're gonna go ahead and get the s3 object just as we did in the first demonstration decompress it start",
    "start": "1975120",
    "end": "1981240"
  },
  {
    "text": "parsing out the data then we transform that into JSON this is this is how you",
    "start": "1981240",
    "end": "1988110"
  },
  {
    "text": "ingest into the elastic search service and you can do whatever customizations you'd like to do here you can annotate",
    "start": "1988110",
    "end": "1994050"
  },
  {
    "text": "it with with meta information about the log itself and you can query instances a",
    "start": "1994050",
    "end": "1999870"
  },
  {
    "text": "popular thing in this this sort of model to query the VPC metadata to get a CLS",
    "start": "1999870",
    "end": "2006870"
  },
  {
    "text": "and and security group information to",
    "start": "2006870",
    "end": "2013679"
  },
  {
    "text": "attach into the view PC logs to help you with your audits and then we're going to",
    "start": "2013679",
    "end": "2018750"
  },
  {
    "text": "format this data and put it into the bulk ingestion API for elasticsearch has",
    "start": "2018750",
    "end": "2026039"
  },
  {
    "text": "a HTTP restful endpoint we're gonna take advantage that to ingest now we've got",
    "start": "2026039",
    "end": "2033450"
  },
  {
    "text": "our lambda functions set up we've got B PC flow log data flowing into the service and we're going to trigger an",
    "start": "2033450",
    "end": "2039870"
  },
  {
    "text": "export to our s3 bucket that everything's attached to we go to the logs console we just like log group we",
    "start": "2039870",
    "end": "2046289"
  },
  {
    "text": "go to the actions and we choose export data s3 in here you're able to choose the time range that you want to extract",
    "start": "2046289",
    "end": "2053069"
  },
  {
    "text": "from that log group and you can deliver it to your own bucket in your account or a common popular thing is to export into",
    "start": "2053069",
    "end": "2060210"
  },
  {
    "text": "a centralized bucket across your accounts and regions so you can get a cross regional view and cross account",
    "start": "2060210",
    "end": "2067290"
  },
  {
    "text": "view of your operations and if so if you do that you'll choose the other account",
    "start": "2067290",
    "end": "2072839"
  },
  {
    "text": "option here once we trigger that the log service diligently goes out there and",
    "start": "2072839",
    "end": "2079349"
  },
  {
    "text": "starts reassembling all of your data into into objects that it dumps into",
    "start": "2079349",
    "end": "2084839"
  },
  {
    "text": "your s3 bucket the prefixes and there will be by log stream and so in this case for VPC data it's by en I inside of",
    "start": "2084839",
    "end": "2093419"
  },
  {
    "text": "this you'll find sort of similar to easy with the EOB logs you'll see a bunch of",
    "start": "2093419",
    "end": "2098520"
  },
  {
    "text": "compressed objects that stream in as the launch service prepares them as is",
    "start": "2098520",
    "end": "2105630"
  },
  {
    "text": "streaming in its we remember we're invoking the object create notification and lambda the lambda functions",
    "start": "2105630",
    "end": "2111960"
  },
  {
    "text": "decompressing the data reformatting it and posting it into the elastic search cluster we can start seeing it flow in",
    "start": "2111960",
    "end": "2118470"
  },
  {
    "text": "in Cabana and once you've got everything loaded into your elastic search cluster",
    "start": "2118470",
    "end": "2123569"
  },
  {
    "text": "you can go in and start doing different sorts of analyses you can look at like the bytes accepted rejected and that",
    "start": "2123569",
    "end": "2128790"
  },
  {
    "text": "sort of so to help you see what the surface area of the incident looked like the suppose that we had you",
    "start": "2128790",
    "end": "2135390"
  },
  {
    "text": "in a network breach three months ago that we just realized and we want to find out what the what the possible",
    "start": "2135390",
    "end": "2142320"
  },
  {
    "text": "blast radius is we know which IP an instance was compromised and we want to see were they reaching out to two other",
    "start": "2142320",
    "end": "2149190"
  },
  {
    "text": "things during that time that they would typically would not so that so for doing",
    "start": "2149190",
    "end": "2154320"
  },
  {
    "text": "that sort of stuff we can do more interesting things like top talkers and pairs and these sort of things so key",
    "start": "2154320",
    "end": "2163260"
  },
  {
    "text": "takeaways on this one it's a it's it's also an extremely useful to build us and",
    "start": "2163260",
    "end": "2169470"
  },
  {
    "text": "historical data to indexed analysis product within a particular time frame",
    "start": "2169470",
    "end": "2174830"
  },
  {
    "text": "you don't necessarily want to be able to have something running at all times in order to access off and sometimes our",
    "start": "2174830",
    "end": "2180420"
  },
  {
    "text": "data in a next product can't fit all within the working set for the instance",
    "start": "2180420",
    "end": "2186540"
  },
  {
    "text": "or the cluster and so you need to be rotating data out but what do you do when you need to do a deep dive root",
    "start": "2186540",
    "end": "2192660"
  },
  {
    "text": "cause analysis or what do you do if the if the data is normally - it doesn't",
    "start": "2192660",
    "end": "2199140"
  },
  {
    "text": "have enough value to sit into index product at all times so this reduces your costs and it reduces your burden of",
    "start": "2199140",
    "end": "2205470"
  },
  {
    "text": "scaling on these elasticsearch clusters if you you know if you're building them in real time and it reduces your",
    "start": "2205470",
    "end": "2211740"
  },
  {
    "text": "operations time overall troubleshooting gets easier - because you're able to narrow the data down to this specific",
    "start": "2211740",
    "end": "2218250"
  },
  {
    "text": "window in what you need and you have then only their limited and relevant data for the incident response that",
    "start": "2218250",
    "end": "2224730"
  },
  {
    "text": "you're trying to do an analysis on and with that I'm gonna pass it back to Bob for the recap",
    "start": "2224730",
    "end": "2231410"
  },
  {
    "text": "all right thanks Robert so I hope that these scenarios you know whether you can",
    "start": "2231410",
    "end": "2236850"
  },
  {
    "text": "use them directly or not I hope that it's spurred some creative juices on what's possible with flowers logs and",
    "start": "2236850",
    "end": "2243000"
  },
  {
    "text": "lambda you know as we said honoré is more important than ever I think we probably have an innate sense of that",
    "start": "2243000",
    "end": "2249060"
  },
  {
    "text": "but it's still too hard and so we need tools like this and techniques like this - to work through some of these things",
    "start": "2249060",
    "end": "2254790"
  },
  {
    "text": "now of course yours cloud watch if I have to simplify the you know a simple statement of the mission of cloud watch",
    "start": "2254790",
    "end": "2260730"
  },
  {
    "text": "I would say we were trying to make monitoring easier and we're we're gonna roll out features and new services as",
    "start": "2260730",
    "end": "2266190"
  },
  {
    "text": "fast as we can to do that but ultimately it is going to be about the broader ecosystem what you're doing with other AWS services with other partners",
    "start": "2266190",
    "end": "2273900"
  },
  {
    "text": "no I should have probably warned everybody we're gonna have some time for questions so please be thinking about",
    "start": "2273900",
    "end": "2280359"
  },
  {
    "text": "questions just before we get there we have some links here so there's some documentation links as Robert mentioned",
    "start": "2280359",
    "end": "2285969"
  },
  {
    "text": "all of the code that we show at all the lambda functions are in our github AWS",
    "start": "2285969",
    "end": "2291369"
  },
  {
    "text": "labs now they're live now so please go check those out and see if there's anything of there that's abuse to you",
    "start": "2291369",
    "end": "2297089"
  },
  {
    "text": "and of course evaluations are quite important we value your feedback and we use that to get better and better each",
    "start": "2297089",
    "end": "2303309"
  },
  {
    "text": "year as we do these things so please complete those evaluations so at this point I would like to open the floor for",
    "start": "2303309",
    "end": "2309099"
  },
  {
    "text": "a few questions if there are questions out there",
    "start": "2309099",
    "end": "2312900"
  }
]
[
  {
    "start": "0",
    "end": "34000"
  },
  {
    "text": "hi my name is Lorenzo nicora and I am streaming solution architect at AWS and",
    "start": "780",
    "end": "7379"
  },
  {
    "text": "I would like to introduce you to some of the fundamental concepts of stream processing",
    "start": "7379",
    "end": "13740"
  },
  {
    "text": "in this video we will see what is streaming and why we need to process",
    "start": "13740",
    "end": "18779"
  },
  {
    "text": "data in streaming how to do it and how to implement business logic that is based on the when",
    "start": "18779",
    "end": "25260"
  },
  {
    "text": "or what are called time semantics and in the journey I will keep comparing",
    "start": "25260",
    "end": "30599"
  },
  {
    "text": "streaming with more traditional approaches but let's start from the definition what",
    "start": "30599",
    "end": "37680"
  },
  {
    "start": "34000",
    "end": "153000"
  },
  {
    "text": "is streaming in the context of data streaming the",
    "start": "37680",
    "end": "43920"
  },
  {
    "text": "terms usually refer to two separate meanings the first is to describe the nature of",
    "start": "43920",
    "end": "50280"
  },
  {
    "text": "the data what we process and the second to describe the processing mode how we",
    "start": "50280",
    "end": "56760"
  },
  {
    "text": "process it when referring to the nature of the data",
    "start": "56760",
    "end": "62160"
  },
  {
    "text": "streaming implies unbounded data sets virtually infinite stream of data that",
    "start": "62160",
    "end": "68040"
  },
  {
    "text": "we can only observe partially in contrast a bounded data set like a",
    "start": "68040",
    "end": "74640"
  },
  {
    "text": "table or a relation can be big but is finite and we can observe it completely",
    "start": "74640",
    "end": "82159"
  },
  {
    "text": "when referring to the processing mode streaming implies processing data continuously data points are processed",
    "start": "84299",
    "end": "91799"
  },
  {
    "text": "as they arrive in contrast again when we process data",
    "start": "91799",
    "end": "96900"
  },
  {
    "text": "as batches or periodically we process a big but finite by called Data one at a",
    "start": "96900",
    "end": "103619"
  },
  {
    "text": "time and in a finite time processing is often scheduled but not",
    "start": "103619",
    "end": "109200"
  },
  {
    "text": "necessarily a bounded data set a table often",
    "start": "109200",
    "end": "115560"
  },
  {
    "text": "represents a snapshot of the state of the system at a given point in time",
    "start": "115560",
    "end": "120840"
  },
  {
    "text": "the content of the table may change over time of course but at the given time we can know it completely",
    "start": "120840",
    "end": "129200"
  },
  {
    "text": "conversely an unbounded data set or stream is a sequence of discrete",
    "start": "129599",
    "end": "134819"
  },
  {
    "text": "messages or events stock transactions in this example",
    "start": "134819",
    "end": "140160"
  },
  {
    "text": "each event is independent for the others and each event usually has a timestamp",
    "start": "140160",
    "end": "145260"
  },
  {
    "text": "representing when the business fact has happened the transaction execution time in this",
    "start": "145260",
    "end": "151680"
  },
  {
    "text": "case but why should we process data continuously in streaming",
    "start": "151680",
    "end": "159920"
  },
  {
    "text": "one of the reasons is to to process data continuously is to reduce the latency of",
    "start": "160920",
    "end": "166019"
  },
  {
    "text": "the result and with latency in this case we refer to the delay between when the",
    "start": "166019",
    "end": "172980"
  },
  {
    "text": "actual event has happened or when we ingest it in our system to the moment we",
    "start": "172980",
    "end": "179940"
  },
  {
    "text": "can provide the result of our calculation or our analysis so we can act on the basis of that",
    "start": "179940",
    "end": "188300"
  },
  {
    "text": "and the point is the value of the data and the value of the Insight diminishes over time",
    "start": "189000",
    "end": "195599"
  },
  {
    "text": "and we are talking about business value but it can also be direct monetary value and this value can also become negative",
    "start": "195599",
    "end": "202860"
  },
  {
    "text": "a loss as you can easily imagine in the case of fraud detection",
    "start": "202860",
    "end": "209120"
  },
  {
    "text": "but let's see a couple of example use case that I will use during this",
    "start": "210000",
    "end": "215159"
  },
  {
    "text": "presentation the first is iot telemetry imagine we have a fleet of industrial Motors across",
    "start": "215159",
    "end": "222000"
  },
  {
    "text": "multiple plants to work safely Motors must run within an",
    "start": "222000",
    "end": "227099"
  },
  {
    "text": "operational envelopes that can be defined in terms of speed and temperature occasionally Motors can overheat or",
    "start": "227099",
    "end": "234659"
  },
  {
    "text": "speed too fast or too slow getting damaged so we have installed a network of",
    "start": "234659",
    "end": "241680"
  },
  {
    "text": "sensors on the motors and sensor continuously sample speed and temperature and send them over mobile",
    "start": "241680",
    "end": "248819"
  },
  {
    "text": "network to a central control system our goal is to minimize the risk of",
    "start": "248819",
    "end": "254159"
  },
  {
    "text": "failure and to reduce the maintenance cost",
    "start": "254159",
    "end": "258799"
  },
  {
    "text": "a completely different use case is a trading platform offering intraday trading to professional Traders each",
    "start": "259500",
    "end": "266880"
  },
  {
    "text": "Trader's buys and sell stocks many times a day sometimes many times every every",
    "start": "266880",
    "end": "273720"
  },
  {
    "text": "hour or every few minutes one problem for Traders is to monitor their exposure to certain stocks or",
    "start": "273720",
    "end": "281400"
  },
  {
    "text": "asset classes or markets and they also want to monitor the profit and loss of their strategy",
    "start": "281400",
    "end": "287460"
  },
  {
    "text": "as a trading platform provider we want to build a customer facing analytic platform to allow our customers the",
    "start": "287460",
    "end": "294720"
  },
  {
    "text": "traders to Monitor and improve their strategy",
    "start": "294720",
    "end": "299120"
  },
  {
    "text": "from a latest report of view let's see what happened when we process data in batches or periodically",
    "start": "300600",
    "end": "307620"
  },
  {
    "text": "well the event is generated at time one and this is at the moment the",
    "start": "307620",
    "end": "312780"
  },
  {
    "text": "measurement is made by the sensor or the stock trade is executed",
    "start": "312780",
    "end": "318660"
  },
  {
    "text": "and we ingest our system in just the event at time to so when our control",
    "start": "318660",
    "end": "325259"
  },
  {
    "text": "system or analytical platform receive the data point and because we process",
    "start": "325259",
    "end": "330840"
  },
  {
    "text": "data in batches the batch will only start at time 3. the batch will take some time to run and",
    "start": "330840",
    "end": "338400"
  },
  {
    "text": "we will eventually emit the result set at time 4.",
    "start": "338400",
    "end": "343500"
  },
  {
    "text": "ignoring for the moment the time between when the event is generated and it is",
    "start": "343500",
    "end": "348780"
  },
  {
    "text": "ingested so between Time 1 and time two because this is not under our control we",
    "start": "348780",
    "end": "355440"
  },
  {
    "text": "can say that the delay of the result from ingestion to the result being available so time 2 to Time 4 mainly",
    "start": "355440",
    "end": "363300"
  },
  {
    "text": "depends on the period of that batch and the time it takes to process the batch",
    "start": "363300",
    "end": "368520"
  },
  {
    "text": "we can improve the latter throwing more resources to the processing",
    "start": "368520",
    "end": "373620"
  },
  {
    "text": "and we can definitely shorten the period of the batching but this is a heavy cost to latency trade-off and we may end up",
    "start": "373620",
    "end": "381660"
  },
  {
    "text": "with batches that start immediately one after the other practically doing streaming with the tool that probably is",
    "start": "381660",
    "end": "388199"
  },
  {
    "text": "not designed for it it's interesting to observe that latency is variable in this case it depends",
    "start": "388199",
    "end": "395400"
  },
  {
    "text": "heavily on when the specific data point is ingested at the beginning or closer",
    "start": "395400",
    "end": "401280"
  },
  {
    "text": "to the end of the batch so it varies between a minimum that is",
    "start": "401280",
    "end": "406500"
  },
  {
    "text": "the time it takes to process the entire data set in a batch five minutes in this example to the sum",
    "start": "406500",
    "end": "414180"
  },
  {
    "text": "of the processing time plus the duration of the batch so 65 minutes for a hour",
    "start": "414180",
    "end": "420960"
  },
  {
    "text": "batch when processing data continuously things",
    "start": "420960",
    "end": "426419"
  },
  {
    "text": "are slightly different we still have a time between the event is generated and",
    "start": "426419",
    "end": "432419"
  },
  {
    "text": "and event being ingested what time 1 to time two and this is probably the same",
    "start": "432419",
    "end": "437880"
  },
  {
    "text": "as the in the previous case but now processing starts almost immediately",
    "start": "437880",
    "end": "443280"
  },
  {
    "text": "and in this case latency depends only on the time it takes to process the data",
    "start": "443280",
    "end": "449039"
  },
  {
    "text": "and in this case our constraints and trade-offs are slightly different well similarly to badging processing",
    "start": "449039",
    "end": "455819"
  },
  {
    "text": "time may also depend on the available resources but this is often not the most",
    "start": "455819",
    "end": "461460"
  },
  {
    "text": "important factor the delay also and mainly depends on the type of logic we",
    "start": "461460",
    "end": "467520"
  },
  {
    "text": "are applying particularly aggregation they are often based on time windows let's give a simple example so if we",
    "start": "467520",
    "end": "474960"
  },
  {
    "text": "want to calculate the average or some value every minute we need to accumulate",
    "start": "474960",
    "end": "480900"
  },
  {
    "text": "one minute of data before emitting the result so our results will always be",
    "start": "480900",
    "end": "486660"
  },
  {
    "text": "delayed of at least one minute",
    "start": "486660",
    "end": "491240"
  },
  {
    "text": "let's get back to our use cases and see the Practical effect of processing data",
    "start": "492300",
    "end": "498000"
  },
  {
    "text": "in batches or in streaming and please note that neither of these use cases is",
    "start": "498000",
    "end": "503580"
  },
  {
    "text": "considered low latency or strictly real time so for motor Telemetry if we process",
    "start": "503580",
    "end": "510720"
  },
  {
    "text": "data every hour this gives us the possibility of identifying the potentially damaged",
    "start": "510720",
    "end": "516599"
  },
  {
    "text": "Motors and then schedule maintenance to prevent a complete failure but if we process data continuously we",
    "start": "516599",
    "end": "523979"
  },
  {
    "text": "can act as soon as we identify a motor that risk and then send a signal to stop",
    "start": "523979",
    "end": "529320"
  },
  {
    "text": "the motor and prevent any damage for our trading platform if we provide",
    "start": "529320",
    "end": "535500"
  },
  {
    "text": "our customer with an analysis every hour this is probably better than most of our",
    "start": "535500",
    "end": "541560"
  },
  {
    "text": "competitors are already doing this will allow traders to analyze their strategy",
    "start": "541560",
    "end": "546779"
  },
  {
    "text": "and the risk but only post facto only with things has already happened in an hour probably most of the position of",
    "start": "546779",
    "end": "553560"
  },
  {
    "text": "the already reopened or closed they can learn for the future of course",
    "start": "553560",
    "end": "559140"
  },
  {
    "text": "but if the we process data continuously we can send an update of the result on",
    "start": "559140",
    "end": "565140"
  },
  {
    "text": "every trade or every few seconds and this will allow traders to act preemptively and just in their position",
    "start": "565140",
    "end": "571320"
  },
  {
    "text": "and the strategy on the flight",
    "start": "571320",
    "end": "575060"
  },
  {
    "text": "but this is not just about latency in fact the real word generates data",
    "start": "577320",
    "end": "582959"
  },
  {
    "text": "continuously not in batches this is an unbounded flow of data and",
    "start": "582959",
    "end": "588360"
  },
  {
    "text": "this doesn't happen at fixed time so our Motors continue spinning and our sensor",
    "start": "588360",
    "end": "593580"
  },
  {
    "text": "continues sampling the data and every single Trader will probably buy and sell",
    "start": "593580",
    "end": "599279"
  },
  {
    "text": "stocks multiple times in an hour when we receive data periodically as it",
    "start": "599279",
    "end": "604980"
  },
  {
    "text": "often happens these usually do due to a limitation of some of the Upstream",
    "start": "604980",
    "end": "610140"
  },
  {
    "text": "systems we have rather than the actual nature of our business being betchy",
    "start": "610140",
    "end": "617779"
  },
  {
    "start": "617000",
    "end": "696000"
  },
  {
    "text": "the word generate data continuously and we often process them as batches how do",
    "start": "619320",
    "end": "625380"
  },
  {
    "text": "we do it well what we usually do is we'll split",
    "start": "625380",
    "end": "631500"
  },
  {
    "text": "data in an arbitrary fixed size windows and we process each window of data one",
    "start": "631500",
    "end": "637320"
  },
  {
    "text": "at a time periodically when the windows end the size of the windows is usually",
    "start": "637320",
    "end": "642480"
  },
  {
    "text": "determined by the period of the batch so if we process data on every hour we are",
    "start": "642480",
    "end": "648600"
  },
  {
    "text": "processing one hour worth of data at each round we process the entire window",
    "start": "648600",
    "end": "653940"
  },
  {
    "text": "of data and for each patch we produce a result that is often aggregated in a",
    "start": "653940",
    "end": "660360"
  },
  {
    "text": "data store when we process the same unbounded stream of data but in streaming mode",
    "start": "660360",
    "end": "667560"
  },
  {
    "text": "continuously we can actually do something very similar simple way of doing it is to split the",
    "start": "667560",
    "end": "674040"
  },
  {
    "text": "infinite stream of data into finite windows at fixed time at the end of each",
    "start": "674040",
    "end": "679140"
  },
  {
    "text": "window we generate results that is a stream itself but this is just one of the",
    "start": "679140",
    "end": "685079"
  },
  {
    "text": "possibilities we have possibly the simplest in stream processing this is called processing time windows we will",
    "start": "685079",
    "end": "691860"
  },
  {
    "text": "get back to this in a minute or two",
    "start": "691860",
    "end": "695660"
  },
  {
    "start": "696000",
    "end": "777000"
  },
  {
    "text": "let's see in more details the difference between processing bounded and unbounded",
    "start": "698640",
    "end": "703860"
  },
  {
    "text": "data sets with the table a boundary data set we can process the entire data set at once",
    "start": "703860",
    "end": "711300"
  },
  {
    "text": "as you can query for example goes through the entire input set and produce",
    "start": "711300",
    "end": "716760"
  },
  {
    "text": "a single data set this is also true for bigger data let's",
    "start": "716760",
    "end": "723540"
  },
  {
    "text": "say if we're using a big data framework like mapreduce or any distributed query",
    "start": "723540",
    "end": "728880"
  },
  {
    "text": "engine what we are doing is parallelizing the processing splitting across nodes but we are still processing",
    "start": "728880",
    "end": "735540"
  },
  {
    "text": "a finite data sets in a single and finite run",
    "start": "735540",
    "end": "740959"
  },
  {
    "text": "with streaming the process is completely different remember our stream of data is",
    "start": "742320",
    "end": "748260"
  },
  {
    "text": "infinite we can never see all the data we can visualize the process a simple",
    "start": "748260",
    "end": "755820"
  },
  {
    "text": "filtering query in this case imagine the query is moving through the stream and",
    "start": "755820",
    "end": "761760"
  },
  {
    "text": "the query processes data at the moment they become visible the now of our system and the query",
    "start": "761760",
    "end": "768600"
  },
  {
    "text": "emits the result the filter rate stream in this example as it Scrolls through",
    "start": "768600",
    "end": "774420"
  },
  {
    "text": "the input but let's start with the simplest case",
    "start": "774420",
    "end": "780839"
  },
  {
    "start": "777000",
    "end": "1085000"
  },
  {
    "text": "of stream processing logic time agnostic logic it means logic that doesn't",
    "start": "780839",
    "end": "786060"
  },
  {
    "text": "include time as a factor the simplest example of time agnostic",
    "start": "786060",
    "end": "794339"
  },
  {
    "text": "logic is filtering based on some property of the event so let's imagine our",
    "start": "794339",
    "end": "800720"
  },
  {
    "text": "sensor measurement and we want to keep only the temperature measurement",
    "start": "800720",
    "end": "807000"
  },
  {
    "text": "note that filtering is stateless it means that we can process one event at a",
    "start": "807000",
    "end": "812279"
  },
  {
    "text": "time without any knowledge of the event that came before or that we can we will will come after it",
    "start": "812279",
    "end": "820639"
  },
  {
    "text": "more complex logic can also be time agnostic inner Joy is an example imagine",
    "start": "822360",
    "end": "828480"
  },
  {
    "text": "we have two streamers data and each event in one stream matches exactly with",
    "start": "828480",
    "end": "833579"
  },
  {
    "text": "one event in the other Steam an example of this can be an e-commerce platform where payments are collected",
    "start": "833579",
    "end": "841560"
  },
  {
    "text": "asynchronously and we produce these three more orders and payments Downstream we want to enrich the orders",
    "start": "841560",
    "end": "849240"
  },
  {
    "text": "with some information about the payments and this is a simple inner join by order",
    "start": "849240",
    "end": "854399"
  },
  {
    "text": "ID in SQL terms and it will be the same in streaming terms but remember this is",
    "start": "854399",
    "end": "860399"
  },
  {
    "text": "streaming we process data continuously we don't have a table and we want to process data as soon as",
    "start": "860399",
    "end": "867060"
  },
  {
    "text": "they arrive but the problem is the two corresponding event will reach the",
    "start": "867060",
    "end": "872339"
  },
  {
    "text": "component doing the inner join at different times so what we need to do is buffering each",
    "start": "872339",
    "end": "878639"
  },
  {
    "text": "event until the corresponding event on the other side is received this kind of process is called stateful",
    "start": "878639",
    "end": "886019"
  },
  {
    "text": "it means that our system need to remember some state in this case just",
    "start": "886019",
    "end": "891959"
  },
  {
    "text": "the event that comes first to be able to calculate the result the enriched event in this example but let's",
    "start": "891959",
    "end": "900180"
  },
  {
    "text": "see how it works with a simple animation",
    "start": "900180",
    "end": "904940"
  },
  {
    "text": "so the first order which is our node doing the zone and we buffer it or we",
    "start": "905399",
    "end": "912060"
  },
  {
    "text": "keep it in state in the streaming jargon",
    "start": "912060",
    "end": "917160"
  },
  {
    "text": "later we received the second order and we keep it in state as well",
    "start": "917160",
    "end": "923040"
  },
  {
    "text": "at some point we received the payment of the second order",
    "start": "923040",
    "end": "928139"
  },
  {
    "text": "we can match it emit the result and discard the match",
    "start": "928139",
    "end": "933899"
  },
  {
    "text": "order from the state later on we receive a third order and a",
    "start": "933899",
    "end": "940320"
  },
  {
    "text": "payment related to the first order we can match it emit the result and",
    "start": "940320",
    "end": "946380"
  },
  {
    "text": "discard again the newly matched order from the state",
    "start": "946380",
    "end": "952260"
  },
  {
    "text": "then we receive a new payment and this time it doesn't match any of the orders",
    "start": "952260",
    "end": "958260"
  },
  {
    "text": "we have received yet well this is not the problem we just keep it in state",
    "start": "958260",
    "end": "964320"
  },
  {
    "text": "we receive another payment we can match and discard until we eventually receive the fourth",
    "start": "964320",
    "end": "972240"
  },
  {
    "text": "order matching the payment we received first so we can match it and discard so",
    "start": "972240",
    "end": "978300"
  },
  {
    "text": "at this point our state is temporary empty until we receive the next order of",
    "start": "978300",
    "end": "984480"
  },
  {
    "text": "payment with a slightly different representation",
    "start": "984480",
    "end": "989880"
  },
  {
    "text": "we can imagine the join process scrolling through the two input strings",
    "start": "989880",
    "end": "995040"
  },
  {
    "text": "the stream of orders and payment temporarily buffering the events that on",
    "start": "995040",
    "end": "1000199"
  },
  {
    "text": "the side that comes first until the corresponding event on the other side is received",
    "start": "1000199",
    "end": "1005899"
  },
  {
    "text": "and this process lays behind a stream of output the order enriched with payment",
    "start": "1005899",
    "end": "1011240"
  },
  {
    "text": "information note that this process is time agnostic",
    "start": "1011240",
    "end": "1016279"
  },
  {
    "text": "I will set because the time the order was placed the time the payment was collected all the time we are doing the",
    "start": "1016279",
    "end": "1022820"
  },
  {
    "text": "join do not matter but differently from filtering this",
    "start": "1022820",
    "end": "1027918"
  },
  {
    "text": "process is stateful because we need to buffer the elements for some time",
    "start": "1027919",
    "end": "1034000"
  },
  {
    "text": "in reality we actually need to have some form of garbage collection that is probably based on time but this is not",
    "start": "1035720",
    "end": "1042260"
  },
  {
    "text": "related to the logic so what if the corresponding element on",
    "start": "1042260",
    "end": "1047780"
  },
  {
    "text": "one side never arrives for any reason for a failure and we need to be prepared",
    "start": "1047780",
    "end": "1052880"
  },
  {
    "text": "for failure we cannot allow our state to grow unbounded otherwise we may",
    "start": "1052880",
    "end": "1058520"
  },
  {
    "text": "eventually run out of memory or this space and a garbage collector is often based",
    "start": "1058520",
    "end": "1064640"
  },
  {
    "text": "on a simple timeout so in a matched element will be dropped after some time",
    "start": "1064640",
    "end": "1069919"
  },
  {
    "text": "that may be long but it's finite and expired event do not need to be lost do",
    "start": "1069919",
    "end": "1076340"
  },
  {
    "text": "not need to be ditched they can be sent to a special output to rise an alarm or",
    "start": "1076340",
    "end": "1081860"
  },
  {
    "text": "for some special handling",
    "start": "1081860",
    "end": "1085179"
  },
  {
    "start": "1085000",
    "end": "1325000"
  },
  {
    "text": "but more complex logic often has time as a factor but the concept of time doesn't",
    "start": "1087380",
    "end": "1093500"
  },
  {
    "text": "have a single definition let's see what are the different time semantics or time domain we can use",
    "start": "1093500",
    "end": "1101860"
  },
  {
    "text": "let's revisit something we have seen but from a different perspective from the",
    "start": "1102380",
    "end": "1107900"
  },
  {
    "text": "perspective of a single event as we have seen the event usually",
    "start": "1107900",
    "end": "1113000"
  },
  {
    "text": "happens externally from our system we call it the time when the event",
    "start": "1113000",
    "end": "1118760"
  },
  {
    "text": "actually happens event Time Time 1 on this diagram this is often written in the event",
    "start": "1118760",
    "end": "1125600"
  },
  {
    "text": "Itself by The Source system then data takes some time to reach our",
    "start": "1125600",
    "end": "1131360"
  },
  {
    "text": "system from The Source this can be millisecond can be second can be more depending on our system and sometimes it",
    "start": "1131360",
    "end": "1138440"
  },
  {
    "text": "can vary over time especially for heavily distributed system the instant our system received the",
    "start": "1138440",
    "end": "1144919"
  },
  {
    "text": "event is called ingestion time time 2 in this diagram and finally we process the data",
    "start": "1144919",
    "end": "1152240"
  },
  {
    "text": "processing can happen briefly after the ingestion but let's consider it a different point in time the instant we",
    "start": "1152240",
    "end": "1159200"
  },
  {
    "text": "handle the processing of the event is called processing time time 3 in this",
    "start": "1159200",
    "end": "1164360"
  },
  {
    "text": "diagram the most relevant time we we use are usually event time and processing",
    "start": "1164360",
    "end": "1170900"
  },
  {
    "text": "time and we can talk about event time semantics or event time domain and",
    "start": "1170900",
    "end": "1177380"
  },
  {
    "text": "processing time semantics and processing time domain",
    "start": "1177380",
    "end": "1182320"
  },
  {
    "text": "this chart represents a relation between event time and processing time",
    "start": "1183860",
    "end": "1189679"
  },
  {
    "text": "in an ideal word represented by the dashed white line where information",
    "start": "1189679",
    "end": "1195620"
  },
  {
    "text": "propagate instantaneously processing time will would always be identical to",
    "start": "1195620",
    "end": "1200840"
  },
  {
    "text": "event time unfortunately in the real world represented by the orange line so system",
    "start": "1200840",
    "end": "1207860"
  },
  {
    "text": "are distance at the minimum we are limited by the speed of light but usually data propagates slower than that",
    "start": "1207860",
    "end": "1214100"
  },
  {
    "text": "and propagation time May varies over time due to congestion of the network",
    "start": "1214100",
    "end": "1219320"
  },
  {
    "text": "failure system being disconnected Etc so the one important observation is",
    "start": "1219320",
    "end": "1226460"
  },
  {
    "text": "processing time is always different and later of course of event time and this",
    "start": "1226460",
    "end": "1231799"
  },
  {
    "text": "difference between the two varies over time and usually there is no simple",
    "start": "1231799",
    "end": "1237200"
  },
  {
    "text": "correlation between the two there are many use cases where we are",
    "start": "1237200",
    "end": "1244760"
  },
  {
    "text": "actually interested in when the event has happened so for example when we are talking about financial transaction why",
    "start": "1244760",
    "end": "1251419"
  },
  {
    "text": "interested when the X when the transaction was executed rather than when we received the corresponding data",
    "start": "1251419",
    "end": "1258559"
  },
  {
    "text": "and this is not just Finance so for example if we need to correlate events",
    "start": "1258559",
    "end": "1263600"
  },
  {
    "text": "coming from different devices especially if the data are delivered over mobile network that can be temporarily",
    "start": "1263600",
    "end": "1270320"
  },
  {
    "text": "disconnected we probably need to use event time for the correlation",
    "start": "1270320",
    "end": "1275360"
  },
  {
    "text": "but we saw in real world there is no fixed correlation between processing",
    "start": "1275360",
    "end": "1280640"
  },
  {
    "text": "time and event time it means that we can't use processing time as a proxy for",
    "start": "1280640",
    "end": "1286700"
  },
  {
    "text": "event time and we cannot use processing time as a way of representing in any way",
    "start": "1286700",
    "end": "1293179"
  },
  {
    "text": "event time safely the implication is for these use cases our processing system our framework must",
    "start": "1293179",
    "end": "1301640"
  },
  {
    "text": "support event Science semantics what does it mean it means that we can",
    "start": "1301640",
    "end": "1307460"
  },
  {
    "text": "Implement logic based on when the event has happened based on the time that is written in the event Itself by The",
    "start": "1307460",
    "end": "1314659"
  },
  {
    "text": "Source the transaction execution time for example rather than the current system time when we are doing the",
    "start": "1314659",
    "end": "1321679"
  },
  {
    "text": "processing now we understand the difference between",
    "start": "1321679",
    "end": "1327799"
  },
  {
    "text": "processing time and event time let's see some example of logic that do depend on",
    "start": "1327799",
    "end": "1333919"
  },
  {
    "text": "time a typical example of known time agnostic",
    "start": "1333919",
    "end": "1340880"
  },
  {
    "text": "logic is window Wing by time means slicing data in time-based Windows so",
    "start": "1340880",
    "end": "1346640"
  },
  {
    "text": "for example to calculate the average of a measurement over 5 minutes",
    "start": "1346640",
    "end": "1351740"
  },
  {
    "text": "the simplest case we have already mentioned is processing time windowing so windows in processing time domain so",
    "start": "1351740",
    "end": "1359299"
  },
  {
    "text": "windows are based on the current time of the system or wall clock time as is sometime called",
    "start": "1359299",
    "end": "1365659"
  },
  {
    "text": "imagine you set up a timer when you open the window when the timer expires you close the window you calculate the",
    "start": "1365659",
    "end": "1371960"
  },
  {
    "text": "result and you open the next window and restart the timer processing time logic is useful every",
    "start": "1371960",
    "end": "1379520"
  },
  {
    "text": "time you need to do some calculation some analysis based on when the event is",
    "start": "1379520",
    "end": "1384799"
  },
  {
    "text": "observed not when it actually happened an example of this can be a media",
    "start": "1384799",
    "end": "1391220"
  },
  {
    "text": "Broadcasting Service and they want to scale their infrastructure dynamically based on the number of viewers and they",
    "start": "1391220",
    "end": "1398480"
  },
  {
    "text": "decided that a good metric for that is scaling based on the number of viewers",
    "start": "1398480",
    "end": "1403640"
  },
  {
    "text": "of the last 10 minutes video devices are regularly emitting",
    "start": "1403640",
    "end": "1408919"
  },
  {
    "text": "signals when the user is watching we do not care about the delay of propagation",
    "start": "1408919",
    "end": "1414380"
  },
  {
    "text": "of this signal also because probably the video stream is affected by the same lag too",
    "start": "1414380",
    "end": "1420559"
  },
  {
    "text": "we need to decide whether to scale our infrastructure based on the number of devices there have been connected in the",
    "start": "1420559",
    "end": "1428179"
  },
  {
    "text": "last 10 minutes and connected means we have received the signal or we observed it in the last 10",
    "start": "1428179",
    "end": "1435320"
  },
  {
    "text": "minutes so this is clearly processing time logic",
    "start": "1435320",
    "end": "1440860"
  },
  {
    "text": "we have already seen how processing time Windows Works in a streaming engine",
    "start": "1441740",
    "end": "1447980"
  },
  {
    "text": "similarly to Inner join we need to buffer data it means that this process",
    "start": "1447980",
    "end": "1453260"
  },
  {
    "text": "is stateful but differently from inner join in this case we buffer events exactly for the",
    "start": "1453260",
    "end": "1460520"
  },
  {
    "text": "duration of the window in our example because we need to calculate the average of viewers over 10 minutes we accumulate",
    "start": "1460520",
    "end": "1467179"
  },
  {
    "text": "data for 10 minutes we calculate the average we emit the result we ditch the",
    "start": "1467179",
    "end": "1473360"
  },
  {
    "text": "the events and we start a new window also note that there is no problem of",
    "start": "1473360",
    "end": "1480919"
  },
  {
    "text": "completeness when do we have the result of the four window it's simple when our timer",
    "start": "1480919",
    "end": "1487039"
  },
  {
    "text": "expires when our current time passes the end of a 10 minute window any signal",
    "start": "1487039",
    "end": "1493159"
  },
  {
    "text": "coming later of this limit will just belong to the next window there is no",
    "start": "1493159",
    "end": "1498320"
  },
  {
    "text": "risk of an event coming in late but windowing also makes a lot of sense",
    "start": "1498320",
    "end": "1505460"
  },
  {
    "text": "or invent time actually we often aggregate data based on when the event",
    "start": "1505460",
    "end": "1511280"
  },
  {
    "text": "has happened not when we observe it but here a new problem arises we saw that",
    "start": "1511280",
    "end": "1517400"
  },
  {
    "text": "processing time is not a good proxy for event time but our Windows must be based",
    "start": "1517400",
    "end": "1522919"
  },
  {
    "text": "on event time so what is written in the event themselves rather than the wall clock time the hour timer",
    "start": "1522919",
    "end": "1530720"
  },
  {
    "text": "problem is we don't know exactly the delay between when the event happened and when we process it but also often",
    "start": "1530720",
    "end": "1537740"
  },
  {
    "text": "events have the bad habit of arriving out of order in respect of event time especially if they're coming from",
    "start": "1537740",
    "end": "1544220"
  },
  {
    "text": "different sources we also so we need to buffer events to give them time to arrive and have the",
    "start": "1544220",
    "end": "1551539"
  },
  {
    "text": "ability to reorder them but how long",
    "start": "1551539",
    "end": "1556419"
  },
  {
    "text": "so how do we solve the problem of out of order events and completeness when working in event time domain",
    "start": "1557360",
    "end": "1565480"
  },
  {
    "text": "how do we decide when all events belong into a specific Windows have actually arrived",
    "start": "1566120",
    "end": "1572000"
  },
  {
    "text": "and we need to wait for them before calculating the result also remember windows are based on event",
    "start": "1572000",
    "end": "1578059"
  },
  {
    "text": "time too and events May arrive out of order so what times time can we use to",
    "start": "1578059",
    "end": "1583279"
  },
  {
    "text": "decide when to open I close the window and also how long should we wait before",
    "start": "1583279",
    "end": "1588679"
  },
  {
    "text": "closing the window to allow some out of order particularly late events to get get in",
    "start": "1588679",
    "end": "1595880"
  },
  {
    "text": "the reality is there is no simple answer one possible approach to this problem is",
    "start": "1595880",
    "end": "1603919"
  },
  {
    "text": "using watermarks approach used by the data flow model and by Apache Flink an open source",
    "start": "1603919",
    "end": "1610039"
  },
  {
    "text": "implementation of this model each Watermark refers to a time in event time domain of course",
    "start": "1610039",
    "end": "1617179"
  },
  {
    "text": "a watermark is literally a simple message saying this is the watermark for time t",
    "start": "1617179",
    "end": "1623480"
  },
  {
    "text": "and these messages are injected in the data flow with the other events",
    "start": "1623480",
    "end": "1628760"
  },
  {
    "text": "any event time logic so for example deciding when to open or close a window",
    "start": "1628760",
    "end": "1633980"
  },
  {
    "text": "is based on the watermarks not the time steps that are written in the event themselves",
    "start": "1633980",
    "end": "1639980"
  },
  {
    "text": "and each Watermark represents a logical barrier saying after this Watermark",
    "start": "1639980",
    "end": "1645380"
  },
  {
    "text": "there is no event with event time older than me so for example when you receive the",
    "start": "1645380",
    "end": "1653120"
  },
  {
    "text": "watermark with the time that is greater than the window and time you can close the window",
    "start": "1653120",
    "end": "1659740"
  },
  {
    "text": "watermarks are also provides a clear semantic for the time Horizon of the",
    "start": "1659740",
    "end": "1665360"
  },
  {
    "text": "output our result so when a watermark reaches the end of the flow we know that no data there were",
    "start": "1665360",
    "end": "1672679"
  },
  {
    "text": "more recent than the watermark has been included in the result",
    "start": "1672679",
    "end": "1678220"
  },
  {
    "text": "if we have a perfect knowledge of our input data we can Implement perfect watermarks it means that no late events",
    "start": "1680120",
    "end": "1687200"
  },
  {
    "text": "can happen no event older than the watermark time will happen after the watermark",
    "start": "1687200",
    "end": "1694240"
  },
  {
    "text": "in the real world we seldom have a perfect knowledge of our inputs and data",
    "start": "1694340",
    "end": "1699679"
  },
  {
    "text": "can be delayed due to unexpected congestion failures disconnected devices",
    "start": "1699679",
    "end": "1704779"
  },
  {
    "text": "all conditions they are external to our system and we cannot control",
    "start": "1704779",
    "end": "1710600"
  },
  {
    "text": "in this case we need to use a heuristic Watermark and approximate watermark",
    "start": "1710600",
    "end": "1716600"
  },
  {
    "text": "one way of implementing a heuristic Watermark is to take the most recent event time we observed so far and then",
    "start": "1716600",
    "end": "1724159"
  },
  {
    "text": "we add some marginal error for example an expected maximum lateness",
    "start": "1724159",
    "end": "1730760"
  },
  {
    "text": "this will become our Watermark time so and we can inject Watermark messages in",
    "start": "1730760",
    "end": "1736820"
  },
  {
    "text": "the flow periodically these watermarks will not be perfect but",
    "start": "1736820",
    "end": "1742700"
  },
  {
    "text": "also they are a compromise between latency and completeness if we give a shorter margin for late events to come",
    "start": "1742700",
    "end": "1749419"
  },
  {
    "text": "in we reduce the latency of the output but if we give a longer margin we reduce",
    "start": "1749419",
    "end": "1755299"
  },
  {
    "text": "the chances of messages coming late but we are increasing the latency of the",
    "start": "1755299",
    "end": "1761480"
  },
  {
    "text": "output when a watermark is heuristic it means",
    "start": "1761480",
    "end": "1767419"
  },
  {
    "text": "that it can happen that events that are older than the watermark actually arrived after the watermark itself you",
    "start": "1767419",
    "end": "1774679"
  },
  {
    "text": "can see for example in the picture the event with time 18 has actually arrived after the watermark at time 20.",
    "start": "1774679",
    "end": "1782899"
  },
  {
    "text": "and these are called late events and you must handle them explicitly",
    "start": "1782899",
    "end": "1788779"
  },
  {
    "text": "the good news is that almost every modern stream processing framework allows you to handle late events",
    "start": "1788779",
    "end": "1795740"
  },
  {
    "text": "explicitly as first class citizen of the programming model and you usually have three options the",
    "start": "1795740",
    "end": "1802940"
  },
  {
    "text": "simplest is discarding late events this is good when all data are no longer relevant this Bay is probably good if",
    "start": "1802940",
    "end": "1809779"
  },
  {
    "text": "you are handling measurement for example this is definitely not good if you are handling Financial transactions",
    "start": "1809779",
    "end": "1816500"
  },
  {
    "text": "another review would be updating the result and emitting an update of the result itself so our destination can",
    "start": "1816500",
    "end": "1824059"
  },
  {
    "text": "handle it and update its own internal state this will require some additional",
    "start": "1824059",
    "end": "1830059"
  },
  {
    "text": "buffering and also the destination system must be ready to accept this kind of late updates",
    "start": "1830059",
    "end": "1837440"
  },
  {
    "text": "a third option will be sending late events as they are to a secondary output for some special external handling this",
    "start": "1837440",
    "end": "1845659"
  },
  {
    "text": "can be simply Rising an alarm or some manual handling which option to use and",
    "start": "1845659",
    "end": "1852260"
  },
  {
    "text": "the actual implementation completely depends on the business use case",
    "start": "1852260",
    "end": "1857980"
  },
  {
    "text": "and please note that these problems of completeness and late events are totally",
    "start": "1858559",
    "end": "1863840"
  },
  {
    "text": "not unique to stream processing even though we tend to forget them when we are building a batch implementation",
    "start": "1863840",
    "end": "1871159"
  },
  {
    "text": "let's see an example we have a daily batch that must process",
    "start": "1871159",
    "end": "1876200"
  },
  {
    "text": "all transactions that have weapon during the day so this is event time processing",
    "start": "1876200",
    "end": "1882080"
  },
  {
    "text": "the batch runs at fixed time as a chrome job for example and this is processing",
    "start": "1882080",
    "end": "1887480"
  },
  {
    "text": "time we are practically implementing event time logic and using a processing time",
    "start": "1887480",
    "end": "1892580"
  },
  {
    "text": "windows and you can probably start seeing what is the problem here",
    "start": "1892580",
    "end": "1897860"
  },
  {
    "text": "we need to wait for all transaction of the day to be ingested before starting",
    "start": "1897860",
    "end": "1903500"
  },
  {
    "text": "the process so we decide that we run the batch later the midnight let's say an",
    "start": "1903500",
    "end": "1909320"
  },
  {
    "text": "hour note that this is very similar to establishing a heuristic watermark with Max lateness of one hour",
    "start": "1909320",
    "end": "1916340"
  },
  {
    "text": "but in this case we are kind of mixing event time and processing time domains",
    "start": "1916340",
    "end": "1921740"
  },
  {
    "text": "most of the time we are lucky and all transaction are actually ingested before 1am",
    "start": "1921740",
    "end": "1927799"
  },
  {
    "text": "but once we are not so lucky maybe due to a temporary failure of one of the",
    "start": "1927799",
    "end": "1933740"
  },
  {
    "text": "Upstream systems sending us transaction something we do not really control so some transaction actually arrived after",
    "start": "1933740",
    "end": "1940640"
  },
  {
    "text": "1am and so what we do first thing we need to be able to detect these late",
    "start": "1940640",
    "end": "1946220"
  },
  {
    "text": "events and it means that we need to be aware it can happen and our implementation should detect them",
    "start": "1946220",
    "end": "1952760"
  },
  {
    "text": "explicitly then we need to include them in our calculation a naive",
    "start": "1952760",
    "end": "1957799"
  },
  {
    "text": "implementation may be just stopping batch and relaunching it including the recently arrived events but this will",
    "start": "1957799",
    "end": "1965480"
  },
  {
    "text": "delay the entire results possibly for very long and possibly generating a lot",
    "start": "1965480",
    "end": "1970880"
  },
  {
    "text": "of duplicates depending on the implementation of course sometimes we need to implement something",
    "start": "1970880",
    "end": "1977059"
  },
  {
    "text": "smart obviously but this will add complexity also because the tools we are using doesn't really support this so we",
    "start": "1977059",
    "end": "1984080"
  },
  {
    "text": "need to invent something to handle this kind of special case with streaming these are not spatial",
    "start": "1984080",
    "end": "1990799"
  },
  {
    "text": "case at all we can explicitly Define heuristic watermark with the max lateness one hour",
    "start": "1990799",
    "end": "1997700"
  },
  {
    "text": "for example and our framework will detect late events for us the only thing we need to do is then",
    "start": "1997700",
    "end": "2004299"
  },
  {
    "text": "decide what to do with these late events so for example being transaction we can discuss them we can decide whether we",
    "start": "2004299",
    "end": "2011620"
  },
  {
    "text": "can emit updated results or just send them to a separate output for an",
    "start": "2011620",
    "end": "2016720"
  },
  {
    "text": "external handling",
    "start": "2016720",
    "end": "2019620"
  },
  {
    "start": "2021000",
    "end": "2356000"
  },
  {
    "text": "but let's conclude with some few more examples of windowing",
    "start": "2024340",
    "end": "2030340"
  },
  {
    "text": "there are some interesting use cases that require Dynamic windowing based on event time",
    "start": "2030340",
    "end": "2035980"
  },
  {
    "text": "a typical example is Click stream analysis so imagine we have a website",
    "start": "2035980",
    "end": "2041019"
  },
  {
    "text": "and we want to measure the duration of each user session and the number of",
    "start": "2041019",
    "end": "2046480"
  },
  {
    "text": "pages that each user visits during the session a user session is defined as a sequence",
    "start": "2046480",
    "end": "2052839"
  },
  {
    "text": "of the interactions or Click by a single user with posts that are shorter than a",
    "start": "2052839",
    "end": "2058540"
  },
  {
    "text": "given timeout say 5 minutes so these are called defined as session",
    "start": "2058540",
    "end": "2064720"
  },
  {
    "text": "windows with session timeouts of 5 minutes consider that session must be based on",
    "start": "2064720",
    "end": "2071800"
  },
  {
    "text": "the time the interaction has happened so this is clearly event time processing",
    "start": "2071800",
    "end": "2077080"
  },
  {
    "text": "and so we are talking here about session windows in event time domain",
    "start": "2077080",
    "end": "2083500"
  },
  {
    "text": "imagine we have no strict latency business requirement here so we are processing the website logs and we can",
    "start": "2083500",
    "end": "2090520"
  },
  {
    "text": "process the logs the logs file once they are closed and rotated and there is no",
    "start": "2090520",
    "end": "2095980"
  },
  {
    "text": "need for you using stream processing just for the sake of latency here",
    "start": "2095980",
    "end": "2102099"
  },
  {
    "text": "so we decide to process logs as batches on every hour for example we run a batch",
    "start": "2102099",
    "end": "2108880"
  },
  {
    "text": "processing the logs that were rotated in the previous hour but we can also trigger the process when each file is",
    "start": "2108880",
    "end": "2116680"
  },
  {
    "text": "rotated this will not make any difference to be honest the problem is batching works very well",
    "start": "2116680",
    "end": "2122440"
  },
  {
    "text": "with fixed windows but when windows are Dynamic and especially when windows can",
    "start": "2122440",
    "end": "2128079"
  },
  {
    "text": "span across batches this is much more complicated and in this case each user",
    "start": "2128079",
    "end": "2133540"
  },
  {
    "text": "has independent sessions and you cannot decide whether a session is finished or not until you wait for the future and",
    "start": "2133540",
    "end": "2141220"
  },
  {
    "text": "you do not receive any more clicks so this is not ideal and will introduce",
    "start": "2141220",
    "end": "2147220"
  },
  {
    "text": "a lot of complexity and the reason is each batch cannot process the its own",
    "start": "2147220",
    "end": "2153339"
  },
  {
    "text": "Windover data as a final data set it also has to know what has happened before and what will happen after it",
    "start": "2153339",
    "end": "2162960"
  },
  {
    "text": "with a stream processing engine we can probably ingest the files as soon as",
    "start": "2163599",
    "end": "2168760"
  },
  {
    "text": "they are rotated and from this point on they become a stream of Click events",
    "start": "2168760",
    "end": "2175119"
  },
  {
    "text": "so our framework can create session windows on the flight a new windows is",
    "start": "2175119",
    "end": "2180700"
  },
  {
    "text": "open when a new interaction from a user is detected and is closed when no interaction happen after the timeout we",
    "start": "2180700",
    "end": "2187780"
  },
  {
    "text": "Define most of stream processing framework like Apache Flink provides session windows",
    "start": "2187780",
    "end": "2193660"
  },
  {
    "text": "out of the box you just need to define the identifier of the user so identify what is unique user the session timeout",
    "start": "2193660",
    "end": "2201579"
  },
  {
    "text": "and then implement the logic to process the click that belong to the session the framework will take care of",
    "start": "2201579",
    "end": "2208540"
  },
  {
    "text": "detecting the beginning at the end of the window and just just calling your implementation every time a window",
    "start": "2208540",
    "end": "2214599"
  },
  {
    "text": "closes getting back to fixed windows what we",
    "start": "2214599",
    "end": "2221619"
  },
  {
    "text": "have seen so far are actually called tumbling Windows this is because windows",
    "start": "2221619",
    "end": "2227320"
  },
  {
    "text": "are kind of tumbling forward when they finished and the next Windows always starts",
    "start": "2227320",
    "end": "2233500"
  },
  {
    "text": "immediately after the previous windows this type of Windows is quite easy to",
    "start": "2233500",
    "end": "2239560"
  },
  {
    "text": "implement with batching too as long as the windows coincide or are completely",
    "start": "2239560",
    "end": "2244660"
  },
  {
    "text": "contained in one batch but there is another commonly used type",
    "start": "2244660",
    "end": "2251980"
  },
  {
    "text": "of fixed window they are called sliding windows because they're called sliding because",
    "start": "2251980",
    "end": "2258040"
  },
  {
    "text": "each consecutive window actually slides forward of a fixed amount of time called",
    "start": "2258040",
    "end": "2263680"
  },
  {
    "text": "Windows light and the slide is often shorter than the",
    "start": "2263680",
    "end": "2268839"
  },
  {
    "text": "window side so actually windows will overlap and events May belong to multiple windows at the same time",
    "start": "2268839",
    "end": "2276280"
  },
  {
    "text": "in this animation the windows light is exactly half the windows side but this is just an example it can be anything",
    "start": "2276280",
    "end": "2282400"
  },
  {
    "text": "actually is often much shorter than the window size",
    "start": "2282400",
    "end": "2288000"
  },
  {
    "text": "so but how can we use this kind of window these are actually very useful",
    "start": "2288000",
    "end": "2293740"
  },
  {
    "text": "and an example of use of sliding Windows is anomaly detection imagine you have imagine your stream of",
    "start": "2293740",
    "end": "2301780"
  },
  {
    "text": "sensor data from the motors for example situation where some of the operating",
    "start": "2301780",
    "end": "2307119"
  },
  {
    "text": "parameters vary very quickly are considered dangerous so what you can do is calculating the",
    "start": "2307119",
    "end": "2313240"
  },
  {
    "text": "standard deviation of of a temperature or of the speed of the motor over a",
    "start": "2313240",
    "end": "2321339"
  },
  {
    "text": "sliding window or say five minutes when the standard deviation crosses a",
    "start": "2321339",
    "end": "2327339"
  },
  {
    "text": "certain threshold this can be considered an anomaly so you can trigger an alarm and send the message and shut down the",
    "start": "2327339",
    "end": "2334480"
  },
  {
    "text": "motor with batching sliding wisdom will inevitably cross the boundary of the",
    "start": "2334480",
    "end": "2339579"
  },
  {
    "text": "batch and as we saw this will increase the complexity because in this case we need to carry over data across batches",
    "start": "2339579",
    "end": "2347500"
  },
  {
    "text": "while in swinging framework sliding windows will be directly supported by the programming in abstraction",
    "start": "2347500",
    "end": "2355920"
  },
  {
    "start": "2356000",
    "end": "2451000"
  },
  {
    "text": "and we reach the end of our journey let's recap what we have seen so far",
    "start": "2357460",
    "end": "2364319"
  },
  {
    "text": "we have seen that when we talk about streaming we actually refer to two different meaning the nature of the data",
    "start": "2365260",
    "end": "2372099"
  },
  {
    "text": "is unbounded data sets and the processing mode as processing data continuously",
    "start": "2372099",
    "end": "2378220"
  },
  {
    "text": "we saw the impact on latency of process data periodically as opposed to continuously and we saw the difference",
    "start": "2378220",
    "end": "2385119"
  },
  {
    "text": "between processing in batches or in stream an unbounded stream of data that",
    "start": "2385119",
    "end": "2390339"
  },
  {
    "text": "comes in from the external systems we saw why some processes require State and",
    "start": "2390339",
    "end": "2397540"
  },
  {
    "text": "the difference between implementing event time semantics and processing time semantics we also show how to solve the",
    "start": "2397540",
    "end": "2404500"
  },
  {
    "text": "problem of out of order and completeness when working in event time domain using",
    "start": "2404500",
    "end": "2410260"
  },
  {
    "text": "a watermark problems that do exist also when we Implement a batch",
    "start": "2410260",
    "end": "2416740"
  },
  {
    "text": "and finally we saw various example of windowing but in processing time and event time and we saw how sometimes it",
    "start": "2416740",
    "end": "2424660"
  },
  {
    "text": "can be easier to implement some type of windowing in with the streaming framework because it supports them out",
    "start": "2424660",
    "end": "2431440"
  },
  {
    "text": "of the box so thank you I hope you find this useful",
    "start": "2431440",
    "end": "2438339"
  },
  {
    "text": "if you have any question don't hesitate to reach out and goodbye",
    "start": "2438339",
    "end": "2444420"
  }
]
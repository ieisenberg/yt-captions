[
  {
    "start": "0",
    "end": "20000"
  },
  {
    "text": "all right hi my name is Oleg a Dave I",
    "start": "170",
    "end": "5430"
  },
  {
    "text": "will work with a drill and I'm going to talk today about our experiences in building data pipelines using containers",
    "start": "5430",
    "end": "11759"
  },
  {
    "text": "and spot instances i guess the container parts brought so many people here anyway",
    "start": "11759",
    "end": "20300"
  },
  {
    "start": "20000",
    "end": "20000"
  },
  {
    "text": "so it's mostly about the lessons will learn from building a new product on a",
    "start": "20300",
    "end": "25769"
  },
  {
    "text": "pretty short timeline with just a few people and it's i would call data heavy",
    "start": "25769",
    "end": "31560"
  },
  {
    "text": "or its big data problem for us and how we'll manage to leverage AWS and docker",
    "start": "31560",
    "end": "38210"
  },
  {
    "text": "to make it as simple as possible and really very little maintenance and can",
    "start": "38210",
    "end": "46680"
  },
  {
    "text": "manage do this on a budget so a little bit about the product we were building it's called arrow prospecting it's",
    "start": "46680",
    "end": "54059"
  },
  {
    "text": "basically customer acquisition product so advertisers we're advertising company as other tithers obtain data they have",
    "start": "54059",
    "end": "62370"
  },
  {
    "text": "some anonymized user profiles and they can leverage that to build audiences to",
    "start": "62370",
    "end": "69150"
  },
  {
    "text": "discover new customers for their product and you think about this this is kind of holy grail of advertising let's say you",
    "start": "69150",
    "end": "76830"
  },
  {
    "text": "selling shoes and your profit margins ten dollars so you'd be totally happy to",
    "start": "76830",
    "end": "82680"
  },
  {
    "text": "give nine dollars out of ten to company like a draw if you manage to bring new customers to you and you still make a",
    "start": "82680",
    "end": "89700"
  },
  {
    "text": "healthy profit this is messy basically money-making machine so we said many my",
    "start": "89700",
    "end": "95549"
  },
  {
    "text": "money making machines that's pretty good business if you manage to pull this off and it's pretty data-heavy problem we",
    "start": "95549",
    "end": "104040"
  },
  {
    "text": "have finals of terabytes of data balloons of cookies kind of mais",
    "start": "104040",
    "end": "110070"
  },
  {
    "text": "profiles and we're building about 28,000 machine learning models per day to make",
    "start": "110070",
    "end": "116969"
  },
  {
    "text": "this work so requirements we had for this system is of course it has to be",
    "start": "116969",
    "end": "123990"
  },
  {
    "start": "120000",
    "end": "120000"
  },
  {
    "text": "robust that means that it shouldn't require too much attention it should be",
    "start": "123990",
    "end": "129270"
  },
  {
    "text": "as simple as possible even though there is really nice sophisticated much your products like distributed databases",
    "start": "129270",
    "end": "136800"
  },
  {
    "text": "like I don't know Cassandra they still need someone to keep an eye on them so",
    "start": "136800",
    "end": "142200"
  },
  {
    "text": "we want it to be at bare bones as possible without sacrificing performance",
    "start": "142200",
    "end": "147299"
  },
  {
    "text": "and given old tools to our data scientists the machine learning engineers to build this machine learning",
    "start": "147299",
    "end": "154799"
  },
  {
    "text": "models have to be language agnostic we not big fans of getting agent Holden to",
    "start": "154799",
    "end": "162840"
  },
  {
    "text": "some specific ecosystem I have nothing bad to say about Java but we didn't want",
    "start": "162840",
    "end": "168690"
  },
  {
    "text": "to get stuck with just jealous tech or Python stack for a lot worse and have multiple people from different",
    "start": "168690",
    "end": "175530"
  },
  {
    "text": "backgrounds on our team like machine learning engineers data scientists we",
    "start": "175530",
    "end": "180720"
  },
  {
    "text": "want them to you the tools they are comfortable with so like Python julia we",
    "start": "180720",
    "end": "186090"
  },
  {
    "text": "use c4 performance critical parts when it's just crunching numbers there is",
    "start": "186090",
    "end": "191250"
  },
  {
    "text": "still a pretty simple tool but works well for last 40 years and we have bits",
    "start": "191250",
    "end": "198780"
  },
  {
    "text": "of Julie and I think we have some bits of hospital now so really didn't want to get stuck on some specific ecosystem it",
    "start": "198780",
    "end": "208829"
  },
  {
    "text": "has to be easy to debug this is kind of trivial point but you want people to be able to examine their jobs and see",
    "start": "208829",
    "end": "215069"
  },
  {
    "text": "what's going on why they fare when they fail to be able to easily pull off logs",
    "start": "215069",
    "end": "221069"
  },
  {
    "text": "from their chance of type of code they write and should be easy to deploy new",
    "start": "221069",
    "end": "227099"
  },
  {
    "text": "jobs not for engineers just for data scientist so they don't have to learn",
    "start": "227099",
    "end": "232889"
  },
  {
    "text": "too much about deployment and things like that so first thing is you want to",
    "start": "232889",
    "end": "239849"
  },
  {
    "text": "run those chunks of code there's written in different languages click ours we get",
    "start": "239849",
    "end": "246090"
  },
  {
    "text": "bad with their library management situations so we wanted to get to keep",
    "start": "246090",
    "end": "252599"
  },
  {
    "text": "it contained so obvious answer this year it seems docker nice to primarily sells",
    "start": "252599",
    "end": "261599"
  },
  {
    "text": "deployment problem for us so we don't really use any kind of resource management",
    "start": "261599",
    "end": "266650"
  },
  {
    "text": "multi-tenancy capabilities and docker like you know creating 10 boxes and like",
    "start": "266650",
    "end": "272050"
  },
  {
    "text": "limited limited number of memory job using we just want to like build this",
    "start": "272050",
    "end": "278770"
  },
  {
    "text": "big hairy tired tar ball and just keep everything there and make it more or",
    "start": "278770",
    "end": "284560"
  },
  {
    "text": "less reproducible so for us dr. kind of soul this library problem it's kind of sweeping the problem under the rug",
    "start": "284560",
    "end": "290380"
  },
  {
    "text": "because you build this crazy tar balls that you kind of accumulate you don't",
    "start": "290380",
    "end": "296139"
  },
  {
    "text": "know what it what's inside but good thing you can still get an image and get it running pretty reproducibly and you",
    "start": "296139",
    "end": "305889"
  },
  {
    "text": "really don't want I mean you can been working like your software product and",
    "start": "305889",
    "end": "311110"
  },
  {
    "text": "you have just software engineers you kind of can make them follow some strict",
    "start": "311110",
    "end": "317139"
  },
  {
    "text": "guidelines building packages and setting fine-grained requirements and versions",
    "start": "317139",
    "end": "323770"
  },
  {
    "text": "things like that but it's still hard if you have data scientists not but I have",
    "start": "323770",
    "end": "330099"
  },
  {
    "text": "nothing bad to say about them but I didn't they make good salaries and I",
    "start": "330099",
    "end": "337639"
  },
  {
    "text": "don't want those people to waste their time of on deployment and like fiddling with variants and like very own",
    "start": "337639",
    "end": "344210"
  },
  {
    "text": "conflicts and stuff like that so best solution we have right now is just to build this blob and just ship it into a",
    "start": "344210",
    "end": "352580"
  },
  {
    "text": "data pipeline dr. skip which is a big advantage because it actually seriously",
    "start": "352580",
    "end": "358520"
  },
  {
    "text": "can attract more engineers because engenders want to work on new exciting stuff so when it's a docker lots of",
    "start": "358520",
    "end": "364550"
  },
  {
    "text": "people show up and has great great tooling because this is not new",
    "start": "364550",
    "end": "370790"
  },
  {
    "text": "technology containers were there for one time probably tens of years but what's",
    "start": "370790",
    "end": "377030"
  },
  {
    "text": "good about docker that they have really good tooling around it it's easy to use and it has a lot of momentum right now",
    "start": "377030",
    "end": "384610"
  },
  {
    "text": "so this is example of docker file to build a blob I guess most of you are",
    "start": "384610",
    "end": "390080"
  },
  {
    "text": "familiar with dr. and i'm going to focus on that but you just described your steps to build this container just bake",
    "start": "390080",
    "end": "399110"
  },
  {
    "text": "it basically like a my something or any virtual machine image the lenses that is",
    "start": "399110",
    "end": "404930"
  },
  {
    "text": "much more lightweight and like startup times a much smaller so next problem you",
    "start": "404930",
    "end": "411410"
  },
  {
    "start": "411000",
    "end": "411000"
  },
  {
    "text": "have is running containers so you can easily run docker containers from your laptop or wherever you can start",
    "start": "411410",
    "end": "417530"
  },
  {
    "text": "initiative instance but when you're starting to do this at scale I have hundreds of containers running you want",
    "start": "417530",
    "end": "424190"
  },
  {
    "text": "to have some kind of orchestration framework you don't want to manually provision all those instances and there",
    "start": "424190",
    "end": "430789"
  },
  {
    "text": "is a bunch of solutions for this there is swarm which is a docker own too I",
    "start": "430789",
    "end": "437360"
  },
  {
    "text": "think which is still under development i think there's whole meses ecosystem",
    "start": "437360",
    "end": "442960"
  },
  {
    "text": "there's ecs which is we have rehi high hopes for but when we started this acs",
    "start": "442960",
    "end": "449630"
  },
  {
    "text": "was still in beta so you didn't go for it and you can build a custom scheduler",
    "start": "449630",
    "end": "456139"
  },
  {
    "text": "q I think there's like hundreds of Q Q's",
    "start": "456139",
    "end": "461539"
  },
  {
    "text": "right now there's like RabbitMQ like tons of them and of course we decided to build our",
    "start": "461539",
    "end": "467920"
  },
  {
    "text": "and the kind of big point about swarm",
    "start": "467920",
    "end": "473000"
  },
  {
    "text": "and mesosphere is that their primary use case is running services so want to have",
    "start": "473000",
    "end": "478550"
  },
  {
    "text": "a fleet of containers running a web app or something like that and not many of",
    "start": "478550",
    "end": "483650"
  },
  {
    "text": "them at least not not much focus is spent on building this for the case of",
    "start": "483650",
    "end": "488690"
  },
  {
    "text": "bed jobs when you have containers running for like minutes maybe a few hours tops so yeah we built our own view",
    "start": "488690",
    "end": "497450"
  },
  {
    "start": "496000",
    "end": "496000"
  },
  {
    "text": "service which we may open source but it's pretty simple it's called Quentin so it's kind of a middleman between",
    "start": "497450",
    "end": "504200"
  },
  {
    "text": "cloud watch and photo scallion groups that run docker containers it's a simple q service you submit your jobs like I",
    "start": "504200",
    "end": "511790"
  },
  {
    "text": "want to run this container somewhere sometime there is no Street real-time",
    "start": "511790",
    "end": "517070"
  },
  {
    "text": "guarantees because all by jobs and we kind of not too sensitive about delays",
    "start": "517070",
    "end": "522219"
  },
  {
    "text": "so what it does is basically keep the sku send the queue size to cloud watch",
    "start": "522220",
    "end": "529390"
  },
  {
    "text": "the cloud which can scale auto scaling groups depending on demand and that's a",
    "start": "529390",
    "end": "535790"
  },
  {
    "text": "little bit different from normal i guess use case for auto scaling groups because when you're running a service and you",
    "start": "535790",
    "end": "542330"
  },
  {
    "text": "just want to have some kind of room to spare you don't want all your instances to run it maximum memory and maximum cpu",
    "start": "542330",
    "end": "549740"
  },
  {
    "text": "but with bad jobs that the opposite you want to save money I don't want two instances sit there idle so we want to",
    "start": "549740",
    "end": "556940"
  },
  {
    "text": "aggressively scale up and down depending on workload and keep them all busy and if we have to keep a backlog or a queue",
    "start": "556940",
    "end": "564290"
  },
  {
    "text": "we find that so yeah there are the queue and medical the coalition's really bare",
    "start": "564290",
    "end": "571190"
  },
  {
    "text": "bones not highly available system yeah",
    "start": "571190",
    "end": "576350"
  },
  {
    "text": "and has some few good features which are kind of helpful when debugging it so it",
    "start": "576350",
    "end": "582650"
  },
  {
    "text": "captures standard output you can there are lots of services to do that and we",
    "start": "582650",
    "end": "588770"
  },
  {
    "text": "kind of encourage people who create those jobs to actually feed their Lots",
    "start": "588770",
    "end": "593780"
  },
  {
    "text": "somewhere else if lots are really that important but it's still when you just want to play the system it's nice to",
    "start": "593780",
    "end": "599840"
  },
  {
    "text": "have some kind of bill capabilities to do that now it has UI which is also really bare bones but",
    "start": "599840",
    "end": "606730"
  },
  {
    "text": "looks like this so just jump to you but you can cancel jobs and examine their",
    "start": "606730",
    "end": "614180"
  },
  {
    "text": "status and look like it standard out on a cluster size really available to for",
    "start": "614180",
    "end": "619940"
  },
  {
    "text": "people who are using this that's how our normal workload looks like this is the",
    "start": "619940",
    "end": "627140"
  },
  {
    "text": "number of instances in Auto scan groups we're using largest instances just most",
    "start": "627140",
    "end": "633020"
  },
  {
    "text": "of the jobs are picky want a lot of memory so we use her 38 x largest and as",
    "start": "633020",
    "end": "639680"
  },
  {
    "text": "you can see here with several times a day we scale from 0 the more than 100",
    "start": "639680",
    "end": "645370"
  },
  {
    "text": "instances it's something like 30 terabytes of ram total in the cluster",
    "start": "645370",
    "end": "652510"
  },
  {
    "text": "kind of get him be there and a few lessons we learn from doing this is that",
    "start": "652510",
    "end": "660140"
  },
  {
    "start": "656000",
    "end": "656000"
  },
  {
    "text": "as I said you want to scale based and job back what size we try to do this based on water utilization CPU doesn't",
    "start": "660140",
    "end": "668510"
  },
  {
    "text": "work well just really if you have 10 jobs in eq you want to start 10 or maybe five instances you kind of have to be it",
    "start": "668510",
    "end": "677060"
  },
  {
    "text": "smart there because in pc to you still pay for an hour so if you just start an",
    "start": "677060",
    "end": "682579"
  },
  {
    "text": "instance run a ten minute job and just kill it and then next job comes in you kind of lose mine have multiple",
    "start": "682579",
    "end": "690589"
  },
  {
    "text": "instances because different jobs require different instants eyes and integrate",
    "start": "690589",
    "end": "695990"
  },
  {
    "text": "with photoscan groups it kind of starts to look like spot fleet sort of so we",
    "start": "695990",
    "end": "701360"
  },
  {
    "text": "kind of have hopes for that as well but still there are some features missing so",
    "start": "701360",
    "end": "706790"
  },
  {
    "text": "for now is still using other scan groups and just multiple queues for different",
    "start": "706790",
    "end": "712370"
  },
  {
    "text": "workloads we use wasting a lot of balancing just for health checks so",
    "start": "712370",
    "end": "718550"
  },
  {
    "text": "there is nothing no load balancing going on whatsoever is just basically to",
    "start": "718550",
    "end": "723680"
  },
  {
    "text": "health checks I like really basic they just tell you if instance is dead or not as if you want something to kind of",
    "start": "723680",
    "end": "731360"
  },
  {
    "text": "being here instance in like maybe fetch URL just too if you have a demon there there's",
    "start": "731360",
    "end": "736469"
  },
  {
    "text": "checking for overall health that's what we use elastic load balancers for it but I think this becomes unnecessary with",
    "start": "736469",
    "end": "743039"
  },
  {
    "text": "well which alerts and we use lifestyle cycle hoops to kind of work around the",
    "start": "743039",
    "end": "749189"
  },
  {
    "text": "problem when you trying to scale your plaster down let's say you had a hundred jobs running and then one you want to",
    "start": "749189",
    "end": "756779"
  },
  {
    "text": "bring it to 10 because there's only 10 left but with that auto scaling groups by default let's Kelly doesn't know what",
    "start": "756779",
    "end": "763019"
  },
  {
    "text": "instances are actually using so just kills random ones you kind of get in a loop when they fail and then they try",
    "start": "763019",
    "end": "768949"
  },
  {
    "text": "there is a way to do this with lifecycle hooks you cannot send a heartbeat to add",
    "start": "768949",
    "end": "774689"
  },
  {
    "text": "a scale and like to keep those particular instances alive when scaling down things we found out we don't really",
    "start": "774689",
    "end": "782759"
  },
  {
    "text": "need is data we're scheduling and high availability so it's from data we're scheduling we just keep everything in s3",
    "start": "782759",
    "end": "789649"
  },
  {
    "text": "you can get pretty good bandwidth downloading from a series of all the jobs just one date down usually on the",
    "start": "789649",
    "end": "797039"
  },
  {
    "text": "femoral drives process it and put it back in and we used to have some",
    "start": "797039",
    "end": "804839"
  },
  {
    "text": "features in the scheduler that allowed us to kind of demise that like many jobs",
    "start": "804839",
    "end": "811079"
  },
  {
    "text": "share same data sets so if the job that just finished used some files and next",
    "start": "811079",
    "end": "817199"
  },
  {
    "text": "job can want them to we try to schedule next job on the same note so it doesn't",
    "start": "817199",
    "end": "823439"
  },
  {
    "text": "have to download data but it's kind of hard to tune and really get pretty good",
    "start": "823439",
    "end": "829109"
  },
  {
    "text": "performance out of has three so it kind of bad in this and so high availability",
    "start": "829109",
    "end": "835259"
  },
  {
    "text": "again if you use as three so kind of all the heavy lifting is done for you it's",
    "start": "835259",
    "end": "840389"
  },
  {
    "text": "already distributed reliable system so if you just push your day 2 s 3 and 0 from s3 your scheduler don't have to be",
    "start": "840389",
    "end": "848159"
  },
  {
    "text": "highly available and easy to got much better over next few years I don't",
    "start": "848159",
    "end": "854609"
  },
  {
    "text": "remember any instances just going down randomly for a long time now so this",
    "start": "854609",
    "end": "860189"
  },
  {
    "text": "thing just runs in a single server there's not that much workload just to keep it cute and some rest api to submit",
    "start": "860189",
    "end": "865619"
  },
  {
    "text": "jobs so we didn't go for high ability one thing it would be nice to",
    "start": "865619",
    "end": "871510"
  },
  {
    "text": "have which is not exactly provided by law which right now is kind of job profiling so when you have bad jobs it's",
    "start": "871510",
    "end": "878320"
  },
  {
    "text": "a little bit different from having a service trying continuously so you can see like spew going up at 12pm or",
    "start": "878320",
    "end": "885730"
  },
  {
    "text": "something like that by jobs you just have lots of copies same code crunching",
    "start": "885730",
    "end": "891010"
  },
  {
    "text": "data different times of day and what you really want to do is kind of see profiles in like relative time scales I",
    "start": "891010",
    "end": "898240"
  },
  {
    "text": "want to see this job around thousand times over the last few days and it's kind of starts take longer or starts to",
    "start": "898240",
    "end": "904570"
  },
  {
    "text": "use more CPU or hits a braking system paging so we have our own tools around",
    "start": "904570",
    "end": "913900"
  },
  {
    "text": "this but be nice if someone actually provided this as a service that would be also cheap next thing you want to look",
    "start": "913900",
    "end": "923440"
  },
  {
    "text": "at is job dependencies so when you have all these containers running thousands",
    "start": "923440",
    "end": "928840"
  },
  {
    "text": "of them you still want have some kind of flare on top that would help you to kind",
    "start": "928840",
    "end": "935680"
  },
  {
    "text": "of coordinate the judge because for in our case for example you just pretty much standard data pipeline you pull",
    "start": "935680",
    "end": "941110"
  },
  {
    "text": "logs from somewhere we can press them we kind of get rid of the data we don't",
    "start": "941110",
    "end": "946630"
  },
  {
    "text": "need downstream to reduce working step size and you need some tool to",
    "start": "946630",
    "end": "955120"
  },
  {
    "start": "955000",
    "end": "955000"
  },
  {
    "text": "coordinate this and this is really like 50 year old problem so since like invention of computers that was a big",
    "start": "955120",
    "end": "962380"
  },
  {
    "text": "use case this is 50 years ago IBM released as 360 batch processing",
    "start": "962380",
    "end": "969910"
  },
  {
    "text": "operating system so you back then it didn't even have any like interactive",
    "start": "969910",
    "end": "974980"
  },
  {
    "text": "pronto wherever you just submitted your jobs their schedules and fifty years ago they had a special languages to describe",
    "start": "974980",
    "end": "982330"
  },
  {
    "text": "those jobs dependencies do all the scheduling so it's it's as old as",
    "start": "982330",
    "end": "987520"
  },
  {
    "text": "computing basically anyone before that I think NASA had a system called part two",
    "start": "987520",
    "end": "993700"
  },
  {
    "text": "also kind of job scheduling and that when for example topological sort sorting algorithms were invented and it",
    "start": "993700",
    "end": "1000810"
  },
  {
    "text": "was used to managed a manual labor so they had to",
    "start": "1000810",
    "end": "1006259"
  },
  {
    "text": "build a spaceship Oh actually Navy also you just built actual ships so kind of",
    "start": "1006259",
    "end": "1011600"
  },
  {
    "text": "want to coordinate all the teams building different parts of it and assembly so 50 years from there today in",
    "start": "1011600",
    "end": "1019730"
  },
  {
    "text": "this season we have multiple tools to do this so there is crowns built by air B&B",
    "start": "1019730",
    "end": "1026620"
  },
  {
    "text": "there is air flow built also by air B&B apparently they were happiest grunts",
    "start": "1026620",
    "end": "1032569"
  },
  {
    "text": "some reason there is all the continuous integration tools like Jenkins our bill",
    "start": "1032569",
    "end": "1038120"
  },
  {
    "text": "but which is kind of different based in a sense but also it's this is system",
    "start": "1038120",
    "end": "1044298"
  },
  {
    "text": "that schedules some chance of code to run regularly so they're actually pretty",
    "start": "1044299",
    "end": "1050480"
  },
  {
    "text": "stable and at some point I think we use bill but release and I think part of the",
    "start": "1050480",
    "end": "1055820"
  },
  {
    "text": "ad roll still use Jenkins because it's pretty easy to set up and the GUI and",
    "start": "1055820",
    "end": "1061010"
  },
  {
    "text": "everything and there's thing called Luigi from Spotify which we ended up using and a little bit about it later",
    "start": "1061010",
    "end": "1069039"
  },
  {
    "text": "but first I wanted to point out one kind of common pattern in those tools so many",
    "start": "1069039",
    "end": "1077149"
  },
  {
    "start": "1076000",
    "end": "1076000"
  },
  {
    "text": "of them come from a kind of chron like approach so you have a country file it",
    "start": "1077149",
    "end": "1082970"
  },
  {
    "text": "says I want to run this at 12pm daily it's kind of intuitive and easy when you",
    "start": "1082970",
    "end": "1088190"
  },
  {
    "text": "have a single job and then you start to have dependencies and it's also probable",
    "start": "1088190",
    "end": "1094039"
  },
  {
    "text": "problem have you can have job see so like today you run job a gypsy for today's log files tomorrow run it for",
    "start": "1094039",
    "end": "1101659"
  },
  {
    "text": "next batch for yesterday's lots Ricky Z can have multiple dependences even",
    "start": "1101659",
    "end": "1107149"
  },
  {
    "text": "though this is kind of harder when you start from like Ron like system video",
    "start": "1107149",
    "end": "1112880"
  },
  {
    "text": "problem starts when you have job jobs failing and that happens and they get delayed and then run over this midnight",
    "start": "1112880",
    "end": "1119450"
  },
  {
    "text": "boundary and now it's not completely clear if you want to run this on today's",
    "start": "1119450",
    "end": "1125450"
  },
  {
    "text": "data yesterday's it's kind of theirs it's not a hard problem obviously you",
    "start": "1125450",
    "end": "1130760"
  },
  {
    "text": "can figure this out but kind of complicates all the pipeline and before who used",
    "start": "1130760",
    "end": "1135980"
  },
  {
    "text": "kind of a harder time figuring out what's going on what went wrong what has to be restarted and yeah you can have",
    "start": "1135980",
    "end": "1144260"
  },
  {
    "text": "all kinds of failures there so our solution is to just forget about time",
    "start": "1144260",
    "end": "1150650"
  },
  {
    "start": "1147000",
    "end": "1147000"
  },
  {
    "text": "for now you just kind of have this directed I cyclic graph of jobs and",
    "start": "1150650",
    "end": "1155870"
  },
  {
    "text": "dependencies and instead of building cron like system you basically have make",
    "start": "1155870",
    "end": "1161960"
  },
  {
    "text": "as in built to so you just want to define inputs and outputs for every job",
    "start": "1161960",
    "end": "1167510"
  },
  {
    "text": "and basically in terms of files in our case and files and s3 and just tell it a",
    "start": "1167510",
    "end": "1174169"
  },
  {
    "text": "through the piece of code I want to run to produce results from inputs and it",
    "start": "1174169",
    "end": "1180950"
  },
  {
    "text": "makes things really easy you don't have to care about time and date anymore you",
    "start": "1180950",
    "end": "1186410"
  },
  {
    "text": "just consider it another parameter and just a trigger on file resistance so",
    "start": "1186410",
    "end": "1192260"
  },
  {
    "text": "there is no shared some kind of state in memory that system has to keep and it's",
    "start": "1192260",
    "end": "1198410"
  },
  {
    "text": "hard to get insights into it if it's just some kind of magic objects in",
    "start": "1198410",
    "end": "1203960"
  },
  {
    "text": "memory and it has some notion of job completeness you don't have to do this if you just do a make file like approach",
    "start": "1203960",
    "end": "1211370"
  },
  {
    "text": "you just rely on file existence somewhere so like s3 or maybe database a",
    "start": "1211370",
    "end": "1217429"
  },
  {
    "text": "row so stuff like that and it's easy to inspect you can just see the file is missing then job is failed or you can",
    "start": "1217429",
    "end": "1225290"
  },
  {
    "text": "just start jobs just by removing files and they just pick up the next next run",
    "start": "1225290",
    "end": "1231530"
  },
  {
    "text": "just sees that file is missing it will just restart parts of your pipeline it works really nicely for us so the two we",
    "start": "1231530",
    "end": "1238520"
  },
  {
    "text": "use is called Luigi some github open sourced by Spotify it's pretty much exactly Mike files except they don't",
    "start": "1238520",
    "end": "1246350"
  },
  {
    "text": "have this 30 year old craft it's written Python really small code base which is",
    "start": "1246350",
    "end": "1252200"
  },
  {
    "text": "great it's not not too sophisticated it's really to hack it's really easy to hack it so yeah it has a bunch of",
    "start": "1252200",
    "end": "1262220"
  },
  {
    "text": "libraries to work with s3 and Hadoop inputs and outputs called targets",
    "start": "1262220",
    "end": "1268660"
  },
  {
    "text": "start of the box and you can write your own extension in Python rickielee and",
    "start": "1268660",
    "end": "1277160"
  },
  {
    "text": "health UI which is kind of liking part but it still has it just great they",
    "start": "1277160",
    "end": "1282950"
  },
  {
    "text": "still can look at things and people who write those jobs here and not necessarily have a lot of background and",
    "start": "1282950",
    "end": "1289790"
  },
  {
    "text": "software they can still designing what's going on there so it's exactly the",
    "start": "1289790",
    "end": "1295160"
  },
  {
    "text": "direct cyclic graph like this I think we have like thousands of notes in our jobs",
    "start": "1295160",
    "end": "1302080"
  },
  {
    "text": "running daily a good thing about it maybe a post make files it that you can",
    "start": "1302080",
    "end": "1310370"
  },
  {
    "text": "create new jobs from other jobs so you can just let's say we can have a job that first Luke's a blog files then",
    "start": "1310370",
    "end": "1317690"
  },
  {
    "text": "charge them by size to make them faster to make things parallel and it can",
    "start": "1317690",
    "end": "1322790"
  },
  {
    "text": "create thousands of kind of child jobs and Luigi just execute this figures out",
    "start": "1322790",
    "end": "1328730"
  },
  {
    "text": "what order they should run in and takes care of all the dependencies but yeah",
    "start": "1328730",
    "end": "1333950"
  },
  {
    "text": "it's really simple this is how blue EG job description looks like so similar to",
    "start": "1333950",
    "end": "1340100"
  },
  {
    "text": "make files you have you define class and have inputs like requires method if I",
    "start": "1340100",
    "end": "1347150"
  },
  {
    "text": "outputs which is as three file on this case and we use it with our job queue",
    "start": "1347150",
    "end": "1353870"
  },
  {
    "text": "Quentin so no actual processing happens on we decide it just used for carnations",
    "start": "1353870",
    "end": "1359090"
  },
  {
    "text": "it just submits jobs as docker containers to the skewing synchronously waits for them and few lessons to learn",
    "start": "1359090",
    "end": "1368330"
  },
  {
    "text": "from this so yeah as I said it's not a hard problem lots of people thousands of",
    "start": "1368330",
    "end": "1375500"
  },
  {
    "text": "engineers sold it and but there is still need to solve it for two thousand first",
    "start": "1375500",
    "end": "1381559"
  },
  {
    "text": "time each year apparently good thing when jobs depend on data and time based",
    "start": "1381559",
    "end": "1388910"
  },
  {
    "text": "scheduling is not hard but complicates things unnecessarily and ideally want to",
    "start": "1388910",
    "end": "1397400"
  },
  {
    "text": "have important jobs so you can run them easily so you just run same job twice and if you have same",
    "start": "1397400",
    "end": "1403950"
  },
  {
    "text": "inputs you get the same output it's not strictly always the case because sometimes you have to pull data from",
    "start": "1403950",
    "end": "1410940"
  },
  {
    "text": "external sources things like that but you kind of should try to kind of strive",
    "start": "1410940",
    "end": "1417030"
  },
  {
    "text": "for it and you should be able to run job Whisenant you just all right existing",
    "start": "1417030",
    "end": "1424110"
  },
  {
    "text": "data another thing that helps is so we use success files Hadoop like an s3 to",
    "start": "1424110",
    "end": "1430380"
  },
  {
    "text": "kind of the indicator for job success of",
    "start": "1430380",
    "end": "1436980"
  },
  {
    "text": "failure they want to have some kind of easy way to figure out if job failed or not just as a whole there should be no",
    "start": "1436980",
    "end": "1443400"
  },
  {
    "text": "state when it's British partially succeeded and also kind of good thing to",
    "start": "1443400",
    "end": "1450810"
  },
  {
    "text": "do is use s3 as a kind of right only file system object stores don't we don't",
    "start": "1450810",
    "end": "1458070"
  },
  {
    "text": "override the same files over an hour or days we just create new set of files with each job run usually a like at",
    "start": "1458070",
    "end": "1465240"
  },
  {
    "text": "least for the same day you keep adding data make things really easy to debug so",
    "start": "1465240",
    "end": "1470970"
  },
  {
    "text": "you can always check file for days there so it's like the bare bones but you can just examine state of data pipeline",
    "start": "1470970",
    "end": "1477840"
  },
  {
    "text": "using AWS COI or something like that and it's pretty available and as I said",
    "start": "1477840",
    "end": "1483900"
  },
  {
    "text": "useful to have dynamic dependency graphs when you can create new jobs from existing jobs dynamically next part",
    "start": "1483900",
    "end": "1492780"
  },
  {
    "text": "about saving money because when you have lots of our three at its largest and sorry they tend to cause a lot and some",
    "start": "1492780",
    "end": "1503280"
  },
  {
    "text": "use cases you really cannot afford little because your margin will kind of be too small because of the value",
    "start": "1503280",
    "end": "1509460"
  },
  {
    "text": "produce with those jobs so we went for spot instances which is probably obvious",
    "start": "1509460",
    "end": "1515070"
  },
  {
    "text": "answer on AWS probably save maybe like eighty percent by using spot instances",
    "start": "1515070",
    "end": "1522960"
  },
  {
    "text": "everywhere problem is of course that this is a spare capacity at Amazon",
    "start": "1522960",
    "end": "1528600"
  },
  {
    "text": "datacenters and a little bility varies sometimes some sound becomes in and buys all the indices and kind of",
    "start": "1528600",
    "end": "1535410"
  },
  {
    "text": "your job start struggle and all the things I said about s3 and keeping it",
    "start": "1535410",
    "end": "1541140"
  },
  {
    "text": "simple and jobs to be runnable it really helps when you have those spot instances that can be taken away from you at any",
    "start": "1541140",
    "end": "1548730"
  },
  {
    "start": "1543000",
    "end": "1543000"
  },
  {
    "text": "time so this is how normal price graph for spot looks like I think it's our",
    "start": "1548730",
    "end": "1554880"
  },
  {
    "text": "three x-large it's normally say what money I think the normal price is about",
    "start": "1554880",
    "end": "1561230"
  },
  {
    "text": "two-thirty and most of the time in this period of time you would pay in much",
    "start": "1561230",
    "end": "1567930"
  },
  {
    "text": "later than that but you do have those spikes and if you familiar with how",
    "start": "1567930",
    "end": "1573030"
  },
  {
    "text": "sparring stance is pricing works you kind of set a floor like your bid you",
    "start": "1573030",
    "end": "1578850"
  },
  {
    "text": "say I'm ready to pay no more than two dollars for an hour loose instance type and in reality you pay this market price",
    "start": "1578850",
    "end": "1586740"
  },
  {
    "text": "is determined by amazon by some magic not really transparent but I guess it's",
    "start": "1586740",
    "end": "1592470"
  },
  {
    "text": "correlated with availability and at some point if price market price goes above",
    "start": "1592470",
    "end": "1597780"
  },
  {
    "text": "your bid they just take away your instances and your jobs fail so if you",
    "start": "1597780",
    "end": "1605130"
  },
  {
    "text": "have this transactional logs in s3 and you have all the data checkpoint at s3 periodically makes pretty easy to use",
    "start": "1605130",
    "end": "1613050"
  },
  {
    "text": "sparring senses worst thing things happen on spot market sometimes this is",
    "start": "1613050",
    "end": "1619110"
  },
  {
    "text": "a week in May when someone got into Amazon data center in Oregon someone big",
    "start": "1619110",
    "end": "1624990"
  },
  {
    "text": "probably paid them a lot of money but they also took away all these are 38 x lawyers from the market for a few days",
    "start": "1624990",
    "end": "1631530"
  },
  {
    "text": "it was bit bad time for us but still you",
    "start": "1631530",
    "end": "1637470"
  },
  {
    "text": "can work around this because there's many markets for each instance diets for",
    "start": "1637470",
    "end": "1642780"
  },
  {
    "text": "each availability zone there is a separate pool for instances and if your",
    "start": "1642780",
    "end": "1648240"
  },
  {
    "text": "jobs are not super tied to specific instance type you can often switch to",
    "start": "1648240",
    "end": "1654060"
  },
  {
    "text": "different instance type so in this case we I think we will part of the jobs we switch them to g28 x-large which is GPU",
    "start": "1654060",
    "end": "1660570"
  },
  {
    "text": "instance we don't use the view at all it was just cheaper it was doing cheaper than like normal m3 something for the",
    "start": "1660570",
    "end": "1668220"
  },
  {
    "text": "same amount of memory you so kind of have to have some kind of insurance against that and things you do",
    "start": "1668220",
    "end": "1676169"
  },
  {
    "text": "is use multiple instance types just pretty easy next thing is to have",
    "start": "1676169",
    "end": "1682470"
  },
  {
    "text": "multiple regions which is a little bit harder if you have all your data in s3 if you use different regions you have to",
    "start": "1682470",
    "end": "1689249"
  },
  {
    "text": "pay for bandwidth which can get expensive but ideally what we do is we",
    "start": "1689249",
    "end": "1697769"
  },
  {
    "text": "compress all the data like first step downloads loves and store them in a really compact form it helps a lot with",
    "start": "1697769",
    "end": "1704309"
  },
  {
    "text": "performance first of all but if you have a smaller data set you can probably replicate it to a different region and",
    "start": "1704309",
    "end": "1710700"
  },
  {
    "text": "have your jobs run there if market price changes and a good thing is to have a",
    "start": "1710700",
    "end": "1719159"
  },
  {
    "text": "pool of under management sis which I think we do too small extent of course",
    "start": "1719159",
    "end": "1727559"
  },
  {
    "text": "there's still a bit of a que Wed there if there is nothing spot market then",
    "start": "1727559",
    "end": "1733950"
  },
  {
    "text": "there is no spare capacity it means that you won't go too far on demand unless",
    "start": "1733950",
    "end": "1739320"
  },
  {
    "text": "you reserve them in advance I would support it in our opinion save lots of",
    "start": "1739320",
    "end": "1746820"
  },
  {
    "text": "money doing that and you don't have to hesitate to and use like smaller",
    "start": "1746820",
    "end": "1753119"
  },
  {
    "text": "instance types we just go for us are three it takes largest the final 50 gigs of RAM makes life so much easier when",
    "start": "1753119",
    "end": "1760499"
  },
  {
    "text": "you don't have a thousand of small reasons but if you have just a handful of big ones just way way better",
    "start": "1760499",
    "end": "1767009"
  },
  {
    "text": "performance and way better to write any kind of machine learning jobs we can you don't have to care that much about",
    "start": "1767009",
    "end": "1773330"
  },
  {
    "text": "distributing them and doing some kind of complex communication between your workers and now putting it all together",
    "start": "1773330",
    "end": "1782909"
  },
  {
    "text": "so the bottom layers docker so you can just practice all your pieces of your",
    "start": "1782909",
    "end": "1789419"
  },
  {
    "start": "1783000",
    "end": "1783000"
  },
  {
    "text": "code dr. containers nicely and not care about deployment too much for resource",
    "start": "1789419",
    "end": "1796859"
  },
  {
    "text": "management measuring how the auto scaling groups who is Quentin which is Q service but may open source it",
    "start": "1796859",
    "end": "1803130"
  },
  {
    "text": "you can probably build it easily yourself probably you could use SQ s and lambda and i think even amazon has a",
    "start": "1803130",
    "end": "1809730"
  },
  {
    "text": "blog post and something like that the only thing is the liking is having some kind of you I and tools to inspect this",
    "start": "1809730",
    "end": "1815940"
  },
  {
    "text": "Q in process on jobs are running and for dependency management views Luigi you",
    "start": "1815940",
    "end": "1822600"
  },
  {
    "text": "could go for like air flow which is a pretty good tool it has nice UI built by",
    "start": "1822600",
    "end": "1828470"
  },
  {
    "text": "Airbnb the only problem with it I see that this time management think they",
    "start": "1828470",
    "end": "1834510"
  },
  {
    "text": "kind of built in all the time based capabilities and they think it's kind of introduces too many concepts makes it a",
    "start": "1834510",
    "end": "1842070"
  },
  {
    "text": "little bit more complicated than it should be few things that we found out that yes we don't use any kind of",
    "start": "1842070",
    "end": "1848910"
  },
  {
    "start": "1845000",
    "end": "1845000"
  },
  {
    "text": "special storage distributed file system for this like no Cassandra nothing just",
    "start": "1848910",
    "end": "1854400"
  },
  {
    "text": "filed an s3 works perfectly reliable we can pull four gig for gigabits from a",
    "start": "1854400",
    "end": "1862110"
  },
  {
    "text": "single instance I think from a three if you use a largest instance size that has a 10 gigabit connection so don't have to",
    "start": "1862110",
    "end": "1870900"
  },
  {
    "text": "care about state like zookeeper going down any kind of war on let's already",
    "start": "1870900",
    "end": "1876810"
  },
  {
    "text": "taken care of by s3 so I keeping job",
    "start": "1876810",
    "end": "1881970"
  },
  {
    "text": "small needs two hours really helps but I think it's true for any batch processing",
    "start": "1881970",
    "end": "1887880"
  },
  {
    "text": "system you just want to be able to restart jobs and they fail if spare instance goes away things like that",
    "start": "1887880",
    "end": "1894450"
  },
  {
    "text": "happen you just want to be able to restart it and don't lose too much time and money that's three on ec2 so they",
    "start": "1894450",
    "end": "1905370"
  },
  {
    "text": "said yeah starting data efficiently it's a really big deal and you if you think about it all the big data problems it's",
    "start": "1905370",
    "end": "1912840"
  },
  {
    "text": "I mean it's been a long time since term big data was invented and since then we",
    "start": "1912840",
    "end": "1919890"
  },
  {
    "text": "got much better in terms of memory size and network and unless you're doing",
    "start": "1919890",
    "end": "1926730"
  },
  {
    "text": "something like an a large hadron collider or maybe a photo recognition",
    "start": "1926730",
    "end": "1932940"
  },
  {
    "text": "when you have lots of data which is actually from comes from kind of rays of physical sensors and that may be",
    "start": "1932940",
    "end": "1939419"
  },
  {
    "text": "big data problem when it's your data just some kind of user-generated basically a no clicks button presses",
    "start": "1939419",
    "end": "1947299"
  },
  {
    "text": "just stop that people do behind the computer and I'll write blog posts you",
    "start": "1947299",
    "end": "1954120"
  },
  {
    "text": "just take me put in a room in the computer and make me produce as much",
    "start": "1954120",
    "end": "1959850"
  },
  {
    "text": "entropy as I can do I won't go far and it will be maybe I kilobytes megabytes",
    "start": "1959850",
    "end": "1966389"
  },
  {
    "text": "of data and there's just six billion people out there so you can compare this well and gigabytes maybe terabytes range",
    "start": "1966389",
    "end": "1973580"
  },
  {
    "text": "and as I said when you have your data set reasonably small maybe not fitting",
    "start": "1973580",
    "end": "1982500"
  },
  {
    "text": "in memory but maybe terabytes tens of terabytes using bigger instances helps a",
    "start": "1982500",
    "end": "1988169"
  },
  {
    "text": "lot because you'll save on all the communication and coordination of those jobs you can just memory map all the",
    "start": "1988169",
    "end": "1993870"
  },
  {
    "text": "data and it just works just back it up with some daily numbers people love",
    "start": "1993870",
    "end": "1999960"
  },
  {
    "start": "1997000",
    "end": "1997000"
  },
  {
    "text": "numbers so we run hundreds of biggest part instances daily yeah probably",
    "start": "1999960",
    "end": "2005000"
  },
  {
    "text": "sounds like about right because we like start them for a few hours crunches the",
    "start": "2005000",
    "end": "2010700"
  },
  {
    "text": "data for a few hours and we kill them yeah they said 30 terabytes friend in",
    "start": "2010700",
    "end": "2016370"
  },
  {
    "text": "this cluster total at peak hundreds of containers running mean it's two hours",
    "start": "2016370",
    "end": "2021919"
  },
  {
    "text": "hundreds of billions logo is analyzed daily and we use lots of technologists",
    "start": "2021919",
    "end": "2028850"
  },
  {
    "text": "we don't have to hesitate and like not tied to any Java or Python or go",
    "start": "2028850",
    "end": "2034129"
  },
  {
    "text": "ecosystem we just used for our lots of C airline Haskell who use D some people",
    "start": "2034129",
    "end": "2040909"
  },
  {
    "text": "heard of it have some kind of testing these cells for some analytical jobs so",
    "start": "2040909",
    "end": "2048679"
  },
  {
    "text": "that pretty much all I have they this is last session anyway everyone's happy",
    "start": "2048679",
    "end": "2054679"
  },
  {
    "text": "thank you",
    "start": "2054679",
    "end": "2057310"
  }
]
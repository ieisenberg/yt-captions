[
  {
    "start": "0",
    "end": "16000"
  },
  {
    "text": "greetings welcome my name is Ryan Niche",
    "start": "60",
    "end": "2820"
  },
  {
    "text": "I am a principal Solutions architect",
    "start": "2820",
    "end": "4680"
  },
  {
    "text": "with Amazon web services joining me here",
    "start": "4680",
    "end": "7799"
  },
  {
    "text": "today is Charlotte who is one of the red",
    "start": "7799",
    "end": "11519"
  },
  {
    "text": "hat managed openshift black belt team",
    "start": "11519",
    "end": "14639"
  },
  {
    "text": "member Charlotte say hello hi everyone",
    "start": "14639",
    "end": "16980"
  },
  {
    "start": "16000",
    "end": "91000"
  },
  {
    "text": "my name is Charlotte",
    "start": "16980",
    "end": "19080"
  },
  {
    "text": "and I'm a managed officer Blackboard as",
    "start": "19080",
    "end": "21359"
  },
  {
    "text": "Ryan's",
    "start": "21359",
    "end": "22680"
  },
  {
    "text": "right so what we have here Charlotte is",
    "start": "22680",
    "end": "25380"
  },
  {
    "text": "a",
    "start": "25380",
    "end": "26840"
  },
  {
    "text": "architecture diagram of the red hat",
    "start": "26840",
    "end": "29400"
  },
  {
    "text": "openshift service on AWS or Rosa and",
    "start": "29400",
    "end": "34559"
  },
  {
    "text": "this is a very generic architecture for",
    "start": "34559",
    "end": "37860"
  },
  {
    "text": "a public facing cluster so we've got",
    "start": "37860",
    "end": "41280"
  },
  {
    "text": "these entry points where developers",
    "start": "41280",
    "end": "44340"
  },
  {
    "text": "customer administrators or red XS sorry",
    "start": "44340",
    "end": "47219"
  },
  {
    "text": "or are coming in over the Internet",
    "start": "47219",
    "end": "49620"
  },
  {
    "text": "through a collection of AWS load",
    "start": "49620",
    "end": "52020"
  },
  {
    "text": "balancers and we can see that here on",
    "start": "52020",
    "end": "54840"
  },
  {
    "text": "the top of the diagram I want to quickly",
    "start": "54840",
    "end": "56879"
  },
  {
    "text": "talk to you about what are some of the",
    "start": "56879",
    "end": "59039"
  },
  {
    "text": "resilience factors of open shift in",
    "start": "59039",
    "end": "62100"
  },
  {
    "text": "itself and how those complement",
    "start": "62100",
    "end": "64920"
  },
  {
    "text": "resilience on AWS one of the things that",
    "start": "64920",
    "end": "68520"
  },
  {
    "text": "you've got in this architecture is",
    "start": "68520",
    "end": "70140"
  },
  {
    "text": "openshift has a control plane made up of",
    "start": "70140",
    "end": "73200"
  },
  {
    "text": "Master nodes and there are three of",
    "start": "73200",
    "end": "75900"
  },
  {
    "text": "those",
    "start": "75900",
    "end": "77600"
  },
  {
    "text": "why three why is it always this magical",
    "start": "77600",
    "end": "81420"
  },
  {
    "text": "number of three and and what happens if",
    "start": "81420",
    "end": "84540"
  },
  {
    "text": "one of those control plane nodes has to",
    "start": "84540",
    "end": "87119"
  },
  {
    "text": "fail whether there is something wrong",
    "start": "87119",
    "end": "89220"
  },
  {
    "text": "from a software or a hardware",
    "start": "89220",
    "end": "90479"
  },
  {
    "text": "perspective",
    "start": "90479",
    "end": "91860"
  },
  {
    "start": "91000",
    "end": "136000"
  },
  {
    "text": "thank you Ryan for that question as you",
    "start": "91860",
    "end": "94860"
  },
  {
    "text": "said we the the basic like the default",
    "start": "94860",
    "end": "98520"
  },
  {
    "text": "deployment always comes with",
    "start": "98520",
    "end": "101040"
  },
  {
    "text": "three control plane because that's the",
    "start": "101040",
    "end": "104939"
  },
  {
    "text": "brain like this is what controls your",
    "start": "104939",
    "end": "107159"
  },
  {
    "text": "cluster and you want to make sure that",
    "start": "107159",
    "end": "109380"
  },
  {
    "text": "is always available because if one fails",
    "start": "109380",
    "end": "112020"
  },
  {
    "text": "then you have to to carry over the job",
    "start": "112020",
    "end": "114840"
  },
  {
    "text": "of the one that fell so so it is it's a",
    "start": "114840",
    "end": "118079"
  },
  {
    "text": "continuity element is there also a",
    "start": "118079",
    "end": "120540"
  },
  {
    "text": "quorum decision-making process uh that",
    "start": "120540",
    "end": "123720"
  },
  {
    "text": "that's sort of aiding uh being aided by",
    "start": "123720",
    "end": "126420"
  },
  {
    "text": "there being three so if one fails there",
    "start": "126420",
    "end": "128700"
  },
  {
    "text": "is no sort of situation of there being a",
    "start": "128700",
    "end": "131280"
  },
  {
    "text": "split brain that failover is facilitated",
    "start": "131280",
    "end": "133739"
  },
  {
    "text": "correctly",
    "start": "133739",
    "end": "136220"
  },
  {
    "start": "136000",
    "end": "206000"
  },
  {
    "text": "um",
    "start": "136800",
    "end": "137520"
  },
  {
    "text": "yeah it's more about",
    "start": "137520",
    "end": "139920"
  },
  {
    "text": "um just making sure that",
    "start": "139920",
    "end": "142860"
  },
  {
    "text": "at least there is a minimum of two if",
    "start": "142860",
    "end": "145920"
  },
  {
    "text": "one does fail why the cluster is able to",
    "start": "145920",
    "end": "148739"
  },
  {
    "text": "spin up",
    "start": "148739",
    "end": "149879"
  },
  {
    "text": "or why um a SRE team is able to detect",
    "start": "149879",
    "end": "153060"
  },
  {
    "text": "that that's a failure in one of the",
    "start": "153060",
    "end": "155400"
  },
  {
    "text": "Clusters like one of the control plane",
    "start": "155400",
    "end": "158220"
  },
  {
    "text": "and be able to spin up a third and so",
    "start": "158220",
    "end": "161220"
  },
  {
    "text": "those two can still be able to handle",
    "start": "161220",
    "end": "163260"
  },
  {
    "text": "all the API calls that come into the",
    "start": "163260",
    "end": "165959"
  },
  {
    "text": "cluster and be able to",
    "start": "165959",
    "end": "168060"
  },
  {
    "text": "um like do whatever needs to be done and",
    "start": "168060",
    "end": "170879"
  },
  {
    "text": "the fact that there's two remaining you",
    "start": "170879",
    "end": "172500"
  },
  {
    "text": "don't see a performance degradation you",
    "start": "172500",
    "end": "174599"
  },
  {
    "text": "don't see any impact to the customer uh",
    "start": "174599",
    "end": "177660"
  },
  {
    "text": "in a in a traditional open shift or a",
    "start": "177660",
    "end": "179819"
  },
  {
    "text": "self-managed openshift so if we look at",
    "start": "179819",
    "end": "181800"
  },
  {
    "text": "ocp or the openshift container platform",
    "start": "181800",
    "end": "184440"
  },
  {
    "text": "the customer would be managing all of",
    "start": "184440",
    "end": "186900"
  },
  {
    "text": "this so the customer would detect this",
    "start": "186900",
    "end": "188940"
  },
  {
    "text": "they would be responsible for correcting",
    "start": "188940",
    "end": "191940"
  },
  {
    "text": "that failed node even though openshift",
    "start": "191940",
    "end": "193739"
  },
  {
    "text": "still is continuing to work you'd still",
    "start": "193739",
    "end": "196739"
  },
  {
    "text": "need to fix the failure with managed",
    "start": "196739",
    "end": "199739"
  },
  {
    "text": "openshift that's not necessarily the",
    "start": "199739",
    "end": "201959"
  },
  {
    "text": "case with the row so the customer",
    "start": "201959",
    "end": "203760"
  },
  {
    "text": "doesn't need to worry about this that's",
    "start": "203760",
    "end": "205860"
  },
  {
    "text": "right because behind the scenes SRE like",
    "start": "205860",
    "end": "209640"
  },
  {
    "start": "206000",
    "end": "243000"
  },
  {
    "text": "proactively monitoring your clusters and",
    "start": "209640",
    "end": "212340"
  },
  {
    "text": "once this fails you won't even notice",
    "start": "212340",
    "end": "214620"
  },
  {
    "text": "that there was a failure in one of your",
    "start": "214620",
    "end": "216780"
  },
  {
    "text": "control planes because the team like you",
    "start": "216780",
    "end": "220860"
  },
  {
    "text": "the SRE team that manages the Clusters",
    "start": "220860",
    "end": "223080"
  },
  {
    "text": "will spin up another one for you okay so",
    "start": "223080",
    "end": "225780"
  },
  {
    "text": "this is more a case of I'm not being",
    "start": "225780",
    "end": "227640"
  },
  {
    "text": "paged in the middle of the night I'm not",
    "start": "227640",
    "end": "229560"
  },
  {
    "text": "needing to react to tickets I'm coming",
    "start": "229560",
    "end": "231659"
  },
  {
    "text": "back to work and getting an email that",
    "start": "231659",
    "end": "233459"
  },
  {
    "text": "states there was this event these are",
    "start": "233459",
    "end": "235799"
  },
  {
    "text": "the actions we've taken and have a",
    "start": "235799",
    "end": "238379"
  },
  {
    "text": "pleasant existence that's correct and",
    "start": "238379",
    "end": "240720"
  },
  {
    "text": "that's exactly what I as a business",
    "start": "240720",
    "end": "242700"
  },
  {
    "text": "owner hope for I want to shift to the uh",
    "start": "242700",
    "end": "244920"
  },
  {
    "start": "243000",
    "end": "283000"
  },
  {
    "text": "the infrastructure layer and more most",
    "start": "244920",
    "end": "247440"
  },
  {
    "text": "importantly this router this this router",
    "start": "247440",
    "end": "249900"
  },
  {
    "text": "layer that we have over here",
    "start": "249900",
    "end": "252420"
  },
  {
    "text": "uh this is facilitating",
    "start": "252420",
    "end": "256220"
  },
  {
    "text": "how my customers get to the actual",
    "start": "256220",
    "end": "259919"
  },
  {
    "text": "application workloads so my customers",
    "start": "259919",
    "end": "263160"
  },
  {
    "text": "are coming in through a collection of",
    "start": "263160",
    "end": "265020"
  },
  {
    "text": "load balancers they get to the router",
    "start": "265020",
    "end": "266940"
  },
  {
    "text": "layer and that router layer routes",
    "start": "266940",
    "end": "269340"
  },
  {
    "text": "traffic to my worker nodes where my pods",
    "start": "269340",
    "end": "271919"
  },
  {
    "text": "or my applications will be running what",
    "start": "271919",
    "end": "274440"
  },
  {
    "text": "happens if a router fails so let's for",
    "start": "274440",
    "end": "276600"
  },
  {
    "text": "example blow up this one uh how does",
    "start": "276600",
    "end": "279840"
  },
  {
    "text": "that function from an openshift",
    "start": "279840",
    "end": "281639"
  },
  {
    "text": "resilience perspective",
    "start": "281639",
    "end": "284280"
  },
  {
    "start": "283000",
    "end": "369000"
  },
  {
    "text": "um so when a router fails and that's why",
    "start": "284280",
    "end": "286919"
  },
  {
    "text": "we have like the two infra notes to act",
    "start": "286919",
    "end": "289620"
  },
  {
    "text": "to account for the high resiliency such",
    "start": "289620",
    "end": "291960"
  },
  {
    "text": "that if one router fails traffic is",
    "start": "291960",
    "end": "294720"
  },
  {
    "text": "automatically routed to the other and",
    "start": "294720",
    "end": "297540"
  },
  {
    "text": "that also gives a SRE time to spin up",
    "start": "297540",
    "end": "300479"
  },
  {
    "text": "another because this is still managed",
    "start": "300479",
    "end": "302460"
  },
  {
    "text": "for you so you really don't get to know",
    "start": "302460",
    "end": "305220"
  },
  {
    "text": "that it was a failure and then",
    "start": "305220",
    "end": "307979"
  },
  {
    "text": "um that's the second infra that gets",
    "start": "307979",
    "end": "310620"
  },
  {
    "text": "spun up for you and takes over so",
    "start": "310620",
    "end": "313919"
  },
  {
    "text": "usually when one fails everything gets",
    "start": "313919",
    "end": "317460"
  },
  {
    "text": "routed to the other one that's still up",
    "start": "317460",
    "end": "319259"
  },
  {
    "text": "and running and then you really don't",
    "start": "319259",
    "end": "321600"
  },
  {
    "text": "get to feel the impact of that and",
    "start": "321600",
    "end": "324139"
  },
  {
    "text": "configuration wise the registry the",
    "start": "324139",
    "end": "327360"
  },
  {
    "text": "route and the monitoring layers there",
    "start": "327360",
    "end": "328979"
  },
  {
    "text": "are actually a lot simpler than the xcd",
    "start": "328979",
    "end": "331620"
  },
  {
    "text": "or the actual controllers so these are",
    "start": "331620",
    "end": "334740"
  },
  {
    "text": "even easier and faster to replace should",
    "start": "334740",
    "end": "337979"
  },
  {
    "text": "something fail uh I would argue that",
    "start": "337979",
    "end": "340740"
  },
  {
    "text": "infrastructure teams could probably",
    "start": "340740",
    "end": "342060"
  },
  {
    "text": "replace these within in a few minutes",
    "start": "342060",
    "end": "344639"
  },
  {
    "text": "with the automation that they have at",
    "start": "344639",
    "end": "346680"
  },
  {
    "text": "their hands if we take this architecture",
    "start": "346680",
    "end": "349740"
  },
  {
    "text": "and we take what open shift is bringing",
    "start": "349740",
    "end": "352259"
  },
  {
    "text": "and we combine that with AWS am I",
    "start": "352259",
    "end": "355620"
  },
  {
    "text": "correct in saying we would take AWS as",
    "start": "355620",
    "end": "358500"
  },
  {
    "text": "multi-az constructs and spread these",
    "start": "358500",
    "end": "361680"
  },
  {
    "text": "across multiple availability zones so",
    "start": "361680",
    "end": "364080"
  },
  {
    "text": "put one control play node one",
    "start": "364080",
    "end": "366300"
  },
  {
    "text": "infrastructure node into each AZ as such",
    "start": "366300",
    "end": "369240"
  },
  {
    "start": "369000",
    "end": "494000"
  },
  {
    "text": "you are absolutely correct so this",
    "start": "369240",
    "end": "372660"
  },
  {
    "text": "deployment that we have here is just the",
    "start": "372660",
    "end": "374940"
  },
  {
    "text": "default as we said at the beginning for",
    "start": "374940",
    "end": "376680"
  },
  {
    "text": "anyone that wants to get started but for",
    "start": "376680",
    "end": "379320"
  },
  {
    "text": "your production we highly recommend that",
    "start": "379320",
    "end": "381900"
  },
  {
    "text": "you make use of the multi easy",
    "start": "381900",
    "end": "383900"
  },
  {
    "text": "deployment which helps you like helps",
    "start": "383900",
    "end": "387780"
  },
  {
    "text": "you spread out your resources in three",
    "start": "387780",
    "end": "389759"
  },
  {
    "text": "different availability zones which",
    "start": "389759",
    "end": "392280"
  },
  {
    "text": "accounts for high availability High",
    "start": "392280",
    "end": "394380"
  },
  {
    "text": "resiliency for tolerant such that if one",
    "start": "394380",
    "end": "396840"
  },
  {
    "text": "is is down you still have the other two",
    "start": "396840",
    "end": "398880"
  },
  {
    "text": "Aces",
    "start": "398880",
    "end": "400020"
  },
  {
    "text": "up and running and you don't really",
    "start": "400020",
    "end": "402120"
  },
  {
    "text": "notice any effect and as she said you",
    "start": "402120",
    "end": "405720"
  },
  {
    "text": "have one control plane per easy one in",
    "start": "405720",
    "end": "409199"
  },
  {
    "text": "front of per easy and one Walker note",
    "start": "409199",
    "end": "411660"
  },
  {
    "text": "per visit which is like the minimum okay",
    "start": "411660",
    "end": "414000"
  },
  {
    "text": "and and these availability zones they",
    "start": "414000",
    "end": "416940"
  },
  {
    "text": "are the closest construct that AWS has",
    "start": "416940",
    "end": "420000"
  },
  {
    "text": "to a physical data center they're not",
    "start": "420000",
    "end": "422520"
  },
  {
    "text": "actually data data centers there are",
    "start": "422520",
    "end": "424979"
  },
  {
    "text": "collections of physical buildings but",
    "start": "424979",
    "end": "427380"
  },
  {
    "text": "they're the closest construct we have to",
    "start": "427380",
    "end": "429900"
  },
  {
    "text": "a physical data center so what you're",
    "start": "429900",
    "end": "432479"
  },
  {
    "text": "actually saying is you're taking that",
    "start": "432479",
    "end": "434340"
  },
  {
    "text": "openshift cluster and you're making sure",
    "start": "434340",
    "end": "436979"
  },
  {
    "text": "that there are control infrastructure",
    "start": "436979",
    "end": "439620"
  },
  {
    "text": "and working out spread evenly across",
    "start": "439620",
    "end": "441539"
  },
  {
    "text": "separate physical data centers so if I",
    "start": "441539",
    "end": "445139"
  },
  {
    "text": "compare this to an on-premises",
    "start": "445139",
    "end": "446819"
  },
  {
    "text": "environment it's like me having three",
    "start": "446819",
    "end": "450240"
  },
  {
    "text": "distinct data centers protecting against",
    "start": "450240",
    "end": "452819"
  },
  {
    "text": "failure and really we've got the open",
    "start": "452819",
    "end": "455039"
  },
  {
    "text": "shift availability constructs",
    "start": "455039",
    "end": "457099"
  },
  {
    "text": "complemented by the AWS availability",
    "start": "457099",
    "end": "459720"
  },
  {
    "text": "constructs quickly shifting to the",
    "start": "459720",
    "end": "461880"
  },
  {
    "text": "actual worker nodes or the compute",
    "start": "461880",
    "end": "464300"
  },
  {
    "text": "locations this is where the applications",
    "start": "464300",
    "end": "467039"
  },
  {
    "text": "are running",
    "start": "467039",
    "end": "468300"
  },
  {
    "text": "these are a little bit more disposable",
    "start": "468300",
    "end": "471060"
  },
  {
    "text": "um if if one of these had to fail my",
    "start": "471060",
    "end": "474360"
  },
  {
    "text": "expectation would be that kubernetes",
    "start": "474360",
    "end": "476460"
  },
  {
    "text": "would detect that and try and move the",
    "start": "476460",
    "end": "479039"
  },
  {
    "text": "workloads around uh openshift also has",
    "start": "479039",
    "end": "482580"
  },
  {
    "text": "the ability to deal with that not just",
    "start": "482580",
    "end": "484380"
  },
  {
    "text": "from a kubernetes workload perspective",
    "start": "484380",
    "end": "486960"
  },
  {
    "text": "but also from an infrastructure",
    "start": "486960",
    "end": "488759"
  },
  {
    "text": "perspective we've got an auto scaling",
    "start": "488759",
    "end": "491280"
  },
  {
    "text": "mechanism built into openshift how does",
    "start": "491280",
    "end": "493919"
  },
  {
    "text": "that work",
    "start": "493919",
    "end": "496340"
  },
  {
    "start": "494000",
    "end": "645000"
  },
  {
    "text": "um so um with the auto scaling when you",
    "start": "496380",
    "end": "499680"
  },
  {
    "text": "do deploy your cluster you have the",
    "start": "499680",
    "end": "501360"
  },
  {
    "text": "option of uh enabling Auto scaling and",
    "start": "501360",
    "end": "505379"
  },
  {
    "text": "you you use that a minimum number of",
    "start": "505379",
    "end": "507599"
  },
  {
    "text": "worker nodes that you want which would",
    "start": "507599",
    "end": "509460"
  },
  {
    "text": "be like two at least two for a single",
    "start": "509460",
    "end": "512099"
  },
  {
    "text": "easy deployment and you can have more",
    "start": "512099",
    "end": "514740"
  },
  {
    "text": "than two for multi-azing deployment and",
    "start": "514740",
    "end": "517680"
  },
  {
    "text": "then based on what your limits are for",
    "start": "517680",
    "end": "519779"
  },
  {
    "text": "your auto scaling",
    "start": "519779",
    "end": "521760"
  },
  {
    "text": "um when your workload begins to increase",
    "start": "521760",
    "end": "525060"
  },
  {
    "text": "open Chef or Rosa will be able to detect",
    "start": "525060",
    "end": "528060"
  },
  {
    "text": "that you are getting more pots being",
    "start": "528060",
    "end": "531180"
  },
  {
    "text": "spawned up and then it's going to",
    "start": "531180",
    "end": "533040"
  },
  {
    "text": "automatically scale up",
    "start": "533040",
    "end": "535560"
  },
  {
    "text": "um your Walker notes and it could be",
    "start": "535560",
    "end": "538019"
  },
  {
    "text": "based on CPU or whatever metrics you set",
    "start": "538019",
    "end": "540360"
  },
  {
    "text": "for your scaling and it will scale that",
    "start": "540360",
    "end": "542339"
  },
  {
    "text": "up to you the desired amount that you",
    "start": "542339",
    "end": "544680"
  },
  {
    "text": "want up to the max",
    "start": "544680",
    "end": "546120"
  },
  {
    "text": "and once the workload begins to decrease",
    "start": "546120",
    "end": "548959"
  },
  {
    "text": "it would also sense that and scale down",
    "start": "548959",
    "end": "551720"
  },
  {
    "text": "automatically to your minimum so we have",
    "start": "551720",
    "end": "555240"
  },
  {
    "text": "two things that are working in",
    "start": "555240",
    "end": "556860"
  },
  {
    "text": "combination here we have the",
    "start": "556860",
    "end": "559920"
  },
  {
    "text": "um",
    "start": "559920",
    "end": "560820"
  },
  {
    "text": "kubernetes",
    "start": "560820",
    "end": "562920"
  },
  {
    "text": "pod",
    "start": "562920",
    "end": "565920"
  },
  {
    "text": "scalar which is managing the workloads",
    "start": "567660",
    "end": "570420"
  },
  {
    "text": "on the nodes and moving them around",
    "start": "570420",
    "end": "572339"
  },
  {
    "text": "creating additional pods and that is",
    "start": "572339",
    "end": "575399"
  },
  {
    "text": "working in combination with I believe it",
    "start": "575399",
    "end": "578880"
  },
  {
    "text": "is the machine sets",
    "start": "578880",
    "end": "582500"
  },
  {
    "text": "and these machine sets are doing two",
    "start": "584880",
    "end": "587160"
  },
  {
    "text": "things they're scaling the computer when",
    "start": "587160",
    "end": "589680"
  },
  {
    "text": "we need more compute when there's more",
    "start": "589680",
    "end": "591779"
  },
  {
    "text": "resources required but they're also",
    "start": "591779",
    "end": "594540"
  },
  {
    "text": "facilitating a recovery or resilience",
    "start": "594540",
    "end": "597959"
  },
  {
    "text": "model that if we lose a node it will",
    "start": "597959",
    "end": "600540"
  },
  {
    "text": "launch a new compute node or a new a AWS",
    "start": "600540",
    "end": "605339"
  },
  {
    "text": "ec2 instance and once that new instance",
    "start": "605339",
    "end": "608100"
  },
  {
    "text": "comes online then the Pod Auto scaler",
    "start": "608100",
    "end": "610860"
  },
  {
    "text": "will then shift workloads to that",
    "start": "610860",
    "end": "613800"
  },
  {
    "text": "balancing out the workload so again",
    "start": "613800",
    "end": "615779"
  },
  {
    "text": "we've got that resilience mechanism of",
    "start": "615779",
    "end": "618600"
  },
  {
    "text": "openshift from a application or a pod",
    "start": "618600",
    "end": "621300"
  },
  {
    "text": "perspective combined with the",
    "start": "621300",
    "end": "623220"
  },
  {
    "text": "infrastructure side coming through from",
    "start": "623220",
    "end": "624779"
  },
  {
    "text": "that machine set and this is all in a",
    "start": "624779",
    "end": "627420"
  },
  {
    "text": "single region taking advantage of",
    "start": "627420",
    "end": "629399"
  },
  {
    "text": "openshift and multiple availability",
    "start": "629399",
    "end": "631920"
  },
  {
    "text": "zones and scaling constructs",
    "start": "631920",
    "end": "634740"
  },
  {
    "text": "uh Charlotte thank you for joining me as",
    "start": "634740",
    "end": "637560"
  },
  {
    "text": "always a fantastic pleasure to work with",
    "start": "637560",
    "end": "639480"
  },
  {
    "text": "you and thank you for joining us here",
    "start": "639480",
    "end": "644300"
  }
]
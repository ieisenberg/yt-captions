[
  {
    "start": "0",
    "end": "85000"
  },
  {
    "text": "[Music]",
    "start": "700",
    "end": "9080"
  },
  {
    "text": "so today I want to talk to you about simplifying Big Data with Amazon web",
    "start": "9080",
    "end": "14840"
  },
  {
    "text": "services big data is when your data set becomes so large that you have to start",
    "start": "15160",
    "end": "21119"
  },
  {
    "text": "innovating on how to collect store analyze and share your",
    "start": "21119",
    "end": "26480"
  },
  {
    "text": "data so there's really three V's of Big Data challenges there's volume velocity and",
    "start": "26480",
    "end": "34280"
  },
  {
    "text": "variety by velocity I mean that you know how frequently the new data arrives to you and what's the latency of that",
    "start": "34280",
    "end": "41760"
  },
  {
    "text": "variety means is that you know you have data that comes in various different formats data comes uh in structured uh",
    "start": "41760",
    "end": "48719"
  },
  {
    "text": "ways like schemas and then there's unstructured data sets like um log files",
    "start": "48719",
    "end": "54520"
  },
  {
    "text": "or images or binary data and so the more variety of data sets you have the larger",
    "start": "54520",
    "end": "60559"
  },
  {
    "text": "the problem in collecting storing analyzing and sharing it and that's what you have in in Big",
    "start": "60559",
    "end": "67720"
  },
  {
    "text": "Data so why big data is so important the collection and Analysis of large amounts",
    "start": "67720",
    "end": "73240"
  },
  {
    "text": "of data can really create a competitive Advantage for the Enterprise and that's why a lot of Enterprises nowadays are",
    "start": "73240",
    "end": "79320"
  },
  {
    "text": "trying to analyze and collect the data you know the uh the data sets that they have and really typically the more data",
    "start": "79320",
    "end": "86960"
  },
  {
    "start": "85000",
    "end": "233000"
  },
  {
    "text": "you collect the more value that you can d dve from it so let's take a few",
    "start": "86960",
    "end": "92479"
  },
  {
    "text": "examples the more misspelled words you collect from your customers the better spell check application that you can",
    "start": "92479",
    "end": "99200"
  },
  {
    "text": "create and Yelp is using Amazon web services to regularly process customer generated data to improve spell check on",
    "start": "99200",
    "end": "105920"
  },
  {
    "text": "their website the more searches you collect uh",
    "start": "105920",
    "end": "112000"
  },
  {
    "text": "from the customers the better recommendations you can provide for customers Yelp is using Amazon web",
    "start": "112000",
    "end": "117799"
  },
  {
    "text": "services to deliver features such as hotel or restaurant recommendations uh review",
    "start": "117799",
    "end": "124560"
  },
  {
    "text": "highlights and search hints so all of those features in that website are",
    "start": "124560",
    "end": "129679"
  },
  {
    "text": "driven by the customer data the customer interaction",
    "start": "129679",
    "end": "135720"
  },
  {
    "text": "data the more data you can collect about your customers the better advertising models",
    "start": "136360",
    "end": "142319"
  },
  {
    "text": "you can create by incorporating sales data and clickstream data over a long",
    "start": "142319",
    "end": "148920"
  },
  {
    "text": "period of time Razer fish helped Best Buy improve return on N spend by",
    "start": "148920",
    "end": "154720"
  },
  {
    "text": "500% as you can see Best Buy has a large number of visitors 3.5 billion records",
    "start": "154720",
    "end": "161599"
  },
  {
    "text": "71 million unique cookies and 1.7 million targeted ads per day and so you",
    "start": "161599",
    "end": "166959"
  },
  {
    "text": "know in in a naive instrumentation you can see that if a user recently purchased a sports movie and is",
    "start": "166959",
    "end": "172280"
  },
  {
    "text": "searching for a video game you can offer them you know U you know a video game from Xbox and so analyzing Fair large",
    "start": "172280",
    "end": "179840"
  },
  {
    "text": "volumes of that interaction data you can really improve the advertising",
    "start": "179840",
    "end": "186080"
  },
  {
    "text": "models Etsy is the largest handmade Goods marketplace with last year's revenues of",
    "start": "186280",
    "end": "192720"
  },
  {
    "text": "about 600 million um they track customer interactions to figure out what people like and offer them relevant products So",
    "start": "192720",
    "end": "201560"
  },
  {
    "text": "based on the data that they collect they can figure out your taste in fact you can see on this uh on",
    "start": "201560",
    "end": "208000"
  },
  {
    "text": "this insert here items matching your taste so you know they really uh dive deep into into understanding uh how you",
    "start": "208000",
    "end": "214400"
  },
  {
    "text": "um how you interact with their website now Big Data grows very quickly",
    "start": "214400",
    "end": "219599"
  },
  {
    "text": "igc estimates that compound annual growth of big data between 2008 and 2012",
    "start": "219599",
    "end": "226920"
  },
  {
    "text": "is about 62% and this rate is accelerating so it's really is a big",
    "start": "226920",
    "end": "232480"
  },
  {
    "text": "deal so how do you collect store analyze and share data using Amazon web services",
    "start": "232480",
    "end": "240079"
  },
  {
    "start": "233000",
    "end": "355000"
  },
  {
    "text": "let's talk about the collection part First Data comes from a lot of different",
    "start": "240079",
    "end": "245920"
  },
  {
    "text": "places right so you have on premus or Cloud application servers that generate the data you have databases that",
    "start": "245920",
    "end": "252159"
  },
  {
    "text": "continuously generate the data whether it's a transactional data or user data there's third parties now that provide",
    "start": "252159",
    "end": "257759"
  },
  {
    "text": "data sets right so you have Twitter data feeds you have Facebook social graphs you have a lot of data you can buy with",
    "start": "257759",
    "end": "263680"
  },
  {
    "text": "the demographic data so you can incorporate all those sources together Amazon has a few few",
    "start": "263680",
    "end": "269919"
  },
  {
    "text": "technologies that we've shipped in recent years to help you move continuously or periodically the data to",
    "start": "269919",
    "end": "276600"
  },
  {
    "text": "the cloud so we have features such as uh S3 Import and Export where you can literally ship your media to us using",
    "start": "276600",
    "end": "283039"
  },
  {
    "text": "FedEx FedEx sometimes have more bandwidth than uh than a regular connection um you have S3 Gateway which",
    "start": "283039",
    "end": "291080"
  },
  {
    "text": "is appliance that you can install in your data center and then you can do um",
    "start": "291080",
    "end": "296320"
  },
  {
    "text": "on the background you can do things like offsite backup disaster recovery and data mirroring from that Gateway so the",
    "start": "296320",
    "end": "302400"
  },
  {
    "text": "Gateway you know you write the data to the Gateway and then the Gateway does a replication onto the cloud there is the direct connect uh",
    "start": "302400",
    "end": "309639"
  },
  {
    "text": "feature that allows you to physically connect to Amazon public Cloud so you can have low cost high bandwidth",
    "start": "309639",
    "end": "317759"
  },
  {
    "text": "connectivity and um last but not least you can actually generate a lot of data",
    "start": "317759",
    "end": "322880"
  },
  {
    "text": "on the cloud Itself by running application servers on lc2 by using RDS",
    "start": "322880",
    "end": "329199"
  },
  {
    "text": "d Etc in addition there's plenty of Open Source technologies that allow you to",
    "start": "329199",
    "end": "335720"
  },
  {
    "text": "stream data to Amazon so these are just a few examples of Apache based projects",
    "start": "335720",
    "end": "341560"
  },
  {
    "text": "that you can use to continuously stream data from your application servers into the cloud into Sor Solutions something",
    "start": "341560",
    "end": "348080"
  },
  {
    "text": "like into star solution like S3 or directly into Amazon elastic mapus",
    "start": "348080",
    "end": "354120"
  },
  {
    "text": "hdfs so once you collect that data where do you store it let's look at that space a little bit and how Amazon helps there",
    "start": "354680",
    "end": "362479"
  },
  {
    "start": "355000",
    "end": "465000"
  },
  {
    "text": "so where is your data the diversity of data storage solution is Solutions is only going to increase and there's a",
    "start": "362479",
    "end": "368639"
  },
  {
    "text": "good reason for that currently you know we have Dynamo DB we have S3 RDS you have on premise Solutions there's third",
    "start": "368639",
    "end": "376039"
  },
  {
    "text": "party data sets there's log and application servers so why do you need all that diversity of data the of the",
    "start": "376039",
    "end": "383120"
  },
  {
    "text": "data story Solutions if you look at sort of from this perspective From perspective of data structure the data",
    "start": "383120",
    "end": "389960"
  },
  {
    "text": "size and the access pattern you will need to pick the right solution for your",
    "start": "389960",
    "end": "395800"
  },
  {
    "text": "application for example S3 is ideal for large unstructured objects such as files",
    "start": "395800",
    "end": "402400"
  },
  {
    "text": "pictures binary data Etc and then Dynamo DB is ideal for",
    "start": "402400",
    "end": "408479"
  },
  {
    "text": "small objects that you have to read or write at a high speed so for instance",
    "start": "408479",
    "end": "413680"
  },
  {
    "text": "dyam DB is a great for um great solution for powering your uh mobile or web",
    "start": "413680",
    "end": "418879"
  },
  {
    "text": "applications RDS is great for structured schema in stand in SQL access but um the size of",
    "start": "418879",
    "end": "427080"
  },
  {
    "text": "data is typically limit to a single server of course it's possible to build",
    "start": "427080",
    "end": "432479"
  },
  {
    "text": "um across to build essentially shards and split data across multiple RDS instances but this requires substantial",
    "start": "432479",
    "end": "439080"
  },
  {
    "text": "development in Ops work that's why it is much more advantageous for instance to move if you need to have very large",
    "start": "439080",
    "end": "445039"
  },
  {
    "text": "tables you need you know ideally you do that in Dynamo DB but if you want to have sort of a a rigid SQL structure and",
    "start": "445039",
    "end": "453560"
  },
  {
    "text": "a simple SQL interface RDS is a great solution and so there are a variety of",
    "start": "453560",
    "end": "459039"
  },
  {
    "text": "ways you can store your data in the cloud based on the particular need of the",
    "start": "459039",
    "end": "464199"
  },
  {
    "text": "application so analyzing data first of all analyzing data you know there's a lot of mainan",
    "start": "464639",
    "end": "471199"
  },
  {
    "start": "465000",
    "end": "645000"
  },
  {
    "text": "tasks that don't really uh associate with with actual analysis you have to organize the data you have to clean it",
    "start": "471199",
    "end": "478199"
  },
  {
    "text": "I'm sure you've seen a lot of s you know the the record's been misspelled or address has been misspelled or IBM spelled in 15 different ways um you have",
    "start": "478199",
    "end": "485879"
  },
  {
    "text": "you can enrich data where you uh for example can translate IP addresses in",
    "start": "485879",
    "end": "491159"
  },
  {
    "text": "your log files uh you know augment that data with the zip codes that associated",
    "start": "491159",
    "end": "496599"
  },
  {
    "text": "with those IP addresses and then you can get a rich demographic information based on the zip codes and so you can learn",
    "start": "496599",
    "end": "502520"
  },
  {
    "text": "more about your customer base so let's talk about sort of a",
    "start": "502520",
    "end": "507840"
  },
  {
    "text": "concrete example so we see a lot of customers with the data spread across fairly diverse formats and sources",
    "start": "507840",
    "end": "513919"
  },
  {
    "text": "imagine that you're an Enterprise with a customer sign up information in a jdbc",
    "start": "513919",
    "end": "519159"
  },
  {
    "text": "table uh it could be RDS or ec2 or even on premise database and you have a",
    "start": "519159",
    "end": "524440"
  },
  {
    "text": "purchase history in Dynamo DB if you want to improve your customer targeting",
    "start": "524440",
    "end": "530240"
  },
  {
    "text": "um you ought to be thinking on how you can merge those two data sets for analysis right and then you can start uh",
    "start": "530240",
    "end": "536959"
  },
  {
    "text": "to predict what a user might be interested in and better Target your website content now of course you want",
    "start": "536959",
    "end": "542880"
  },
  {
    "text": "to go to store that targeted information somewhere so you can quickly access it U",
    "start": "542880",
    "end": "548000"
  },
  {
    "text": "while you're generating that customer content so that might be RDS table but there's no really uh reason to stop",
    "start": "548000",
    "end": "553959"
  },
  {
    "text": "there though right you've got access to wealth of other data maybe you have clickstream data in S3 that you'll be",
    "start": "553959",
    "end": "560320"
  },
  {
    "text": "that you'll be able to um see some what what other what your customers are looking at um or maybe you have uh",
    "start": "560320",
    "end": "566680"
  },
  {
    "text": "access to some social uh networking data maybe you have a Twitter feed uh where you can incorporate the sentiment",
    "start": "566680",
    "end": "573000"
  },
  {
    "text": "analysis about your products or about your content and Incorporated that into the targeting",
    "start": "573000",
    "end": "578480"
  },
  {
    "text": "models so all of these things are going to help you better tailor your target take tailor and Target your",
    "start": "578480",
    "end": "585640"
  },
  {
    "text": "content it's tempting to say that you should be you should just migrate all your data in a single data store but in",
    "start": "585640",
    "end": "591880"
  },
  {
    "text": "practice it's not really an option uh so not only the availability of third party data sets not is not there but also you",
    "start": "591880",
    "end": "598880"
  },
  {
    "text": "know as I mentioned earlier uh different applications have very different uh requirements as far as throughput is",
    "start": "598880",
    "end": "604800"
  },
  {
    "text": "concerned latency durability and Cost needs and so um as soon as you start dealing with the",
    "start": "604800",
    "end": "613320"
  },
  {
    "text": "data produced by multiple you know multiple uh data stores like this uh you have to address the uh formats the",
    "start": "613320",
    "end": "620320"
  },
  {
    "text": "different heterogeneous formats as well and after you've built all those",
    "start": "620320",
    "end": "625600"
  },
  {
    "text": "great targeting models you actually want to analyze that data first further for patterns and and and various other",
    "start": "625600",
    "end": "632720"
  },
  {
    "text": "intelligent information and uh maybe generate weekly daily or monthly reports so let's talk about this orange",
    "start": "632720",
    "end": "640880"
  },
  {
    "text": "icon in the middle of the screen that is Amazon elastic map",
    "start": "640880",
    "end": "646639"
  },
  {
    "start": "645000",
    "end": "763000"
  },
  {
    "text": "produce U that's the K based infrastructure service that lets you build and deploy applications into the",
    "start": "646639",
    "end": "654639"
  },
  {
    "text": "cloud Amazon elastic map produce reduces complexity in and cost of kup management",
    "start": "654720",
    "end": "660959"
  },
  {
    "text": "we manage the clusters for you so you don't have to invest in system administrative resources and um in",
    "start": "660959",
    "end": "668760"
  },
  {
    "text": "infrastructure so you can just completely offload that process to us it integrates seamlessly with Amazon web",
    "start": "668760",
    "end": "674920"
  },
  {
    "text": "services such as S3 and Dynamo DB and it leverages unmatched operational",
    "start": "674920",
    "end": "680880"
  },
  {
    "text": "experience that we have on AWS there's a lot of use cases that you can apply this technology to but some of",
    "start": "680880",
    "end": "687800"
  },
  {
    "text": "the more popular ones are digital advertising web analytics log processing digital warehousing and there's a huge",
    "start": "687800",
    "end": "695279"
  },
  {
    "text": "diverse list of industries that are you and in companies that are using our technology today media advertising is",
    "start": "695279",
    "end": "702240"
  },
  {
    "text": "really popular with targeting as I me uh targeting advertising as I mentioned earlier security is a really popular",
    "start": "702240",
    "end": "708040"
  },
  {
    "text": "field where um elastic map use is used in antivirus uh building antivirus",
    "start": "708040",
    "end": "713639"
  },
  {
    "text": "models so that um you can quickly react on new viruses fraud detection both in",
    "start": "713639",
    "end": "719440"
  },
  {
    "text": "retail world as well as in credit card processing image recognition is is really popular field you know in the",
    "start": "719440",
    "end": "725560"
  },
  {
    "text": "cameras you know when you can actually compare images U uh of certain people",
    "start": "725560",
    "end": "730680"
  },
  {
    "text": "social and uh network uh social networking and gaming is a really popular field where games you know is a",
    "start": "730680",
    "end": "736480"
  },
  {
    "text": "really large analytical uh space so there's a tremendous amount of customers",
    "start": "736480",
    "end": "741920"
  },
  {
    "text": "that we have and uh We've operated well over a million of Hado clusters just last year and we've been in business for",
    "start": "741920",
    "end": "748880"
  },
  {
    "text": "three years now so we have a really you know a phenomenal operational experience and what we do with that operational",
    "start": "748880",
    "end": "754440"
  },
  {
    "text": "experience is that we build features and we integrate them into our Amazon web services fabric so you don't have to",
    "start": "754440",
    "end": "759959"
  },
  {
    "text": "worry about administrative aspects of that Forest to wave report named Amazon",
    "start": "759959",
    "end": "765279"
  },
  {
    "start": "763000",
    "end": "950000"
  },
  {
    "text": "EMR the number one Enterprise Hadoop solution because of its integration with various data stores its ecosystem of",
    "start": "765279",
    "end": "771839"
  },
  {
    "text": "vendors and the number of customers that we support so let's talk a little bit about our integration with the with the rest",
    "start": "771839",
    "end": "778360"
  },
  {
    "text": "of Amazon Fab so on Amazon EMR and Amazon S3",
    "start": "778360",
    "end": "783639"
  },
  {
    "text": "integration you can use S3 as a Hado file system so you can store all your",
    "start": "783639",
    "end": "789000"
  },
  {
    "text": "data in S3 with 11 9's durability and then we have a really high and improved",
    "start": "789000",
    "end": "794120"
  },
  {
    "text": "IO performance to move the data between computer of of elastic map produ and the",
    "start": "794120",
    "end": "799199"
  },
  {
    "text": "storage in S3 so you can use S3 just as a file system for hu and so that really",
    "start": "799199",
    "end": "804839"
  },
  {
    "text": "removes the necessity of um Disaster Recovery because S3 has um uh has 119 durability job contention",
    "start": "804839",
    "end": "813920"
  },
  {
    "text": "and per application cluster customization so what you can do is essentially you can launch multiple clusters on top of S3 content and you",
    "start": "813920",
    "end": "821399"
  },
  {
    "text": "tailor those clusters to the problems that you're trying to solve and not trying to match one single cluster to to",
    "start": "821399",
    "end": "828160"
  },
  {
    "text": "all of the problems Amazon EMR and Dynamo DB integration gives you an integration at",
    "start": "828160",
    "end": "834800"
  },
  {
    "text": "a SQL layer so you can have we have this package called Hive it's enabled s enables a SQL like data query and so you",
    "start": "834800",
    "end": "842240"
  },
  {
    "text": "can have uh distributed data queries and data movement between uh EMR and S3 uh",
    "start": "842240",
    "end": "847880"
  },
  {
    "text": "between Dynam DB and S3 you can have filter push down to Dynam DB and we have a back uh built-in throughput and",
    "start": "847880",
    "end": "855000"
  },
  {
    "text": "throttling and so let me actually explain that with a couple of examples so imagine suppose you have a files in",
    "start": "855000",
    "end": "861360"
  },
  {
    "text": "S3 and you want to load this files into Dynamo DB you can start by creating a Dynamo DB table and then you can spit up",
    "start": "861360",
    "end": "868720"
  },
  {
    "text": "a lot L elastic maped use cluster and you can then use EMR to draw the data",
    "start": "868720",
    "end": "874959"
  },
  {
    "text": "from S3 taking advantage of EMR massive parallelism and then write this data to Dynamo DB and after running your",
    "start": "874959",
    "end": "882480"
  },
  {
    "text": "application for a while you might want to Archive some of the Dynamo DB data back into S3 and you can use that same",
    "start": "882480",
    "end": "890120"
  },
  {
    "text": "mechanism in reverse and so you can extract data from Dynamo DB and",
    "start": "890120",
    "end": "895279"
  },
  {
    "text": "efficiently write it back to S3 so why you want why you want want to do that let me actually actually that's a simple",
    "start": "895279",
    "end": "901519"
  },
  {
    "text": "um code snippet of how you how you can do that it's a really simple mechanism you can just Define a table in Dynamo DB",
    "start": "901519",
    "end": "908320"
  },
  {
    "text": "Define a table in S3 and then just use this code in through elastic maper to do the uh the push and you can achieve you",
    "start": "908320",
    "end": "915120"
  },
  {
    "text": "know 100 thousand of Rights per second using that",
    "start": "915120",
    "end": "919240"
  },
  {
    "text": "mechanism so there's various use cases for that for example you can archive uh tables from Dynamo DB into S3 you can",
    "start": "920199",
    "end": "927320"
  },
  {
    "text": "load data from S3 to Dynam would be and you can run complex queries with support for things like group by join and having",
    "start": "927320",
    "end": "934000"
  },
  {
    "text": "all form elastic mappers elastic mappers really becomes a query engine on top of your Dynamo DB data and you can have",
    "start": "934000",
    "end": "941160"
  },
  {
    "text": "complex join situations where you want to join maybe a table in S3 with a table",
    "start": "941160",
    "end": "946440"
  },
  {
    "text": "in Dynamo DB you can do that with EMR and of course once you start running",
    "start": "946440",
    "end": "952880"
  },
  {
    "start": "950000",
    "end": "1040000"
  },
  {
    "text": "the Clusters elastic map cluster you want to see how it's doing you want to see you know uh",
    "start": "952880",
    "end": "959839"
  },
  {
    "text": "how your cluster is performing and for that elastic map produce provides 23 different metrics about your cluster",
    "start": "959839",
    "end": "966360"
  },
  {
    "text": "through Amazon cloudwatch so you see free metrics on job progress cluster health and resource contention so for",
    "start": "966360",
    "end": "973959"
  },
  {
    "text": "example you can see how many map tasks are running how many reduced tasks are running how much space is left in hdfs",
    "start": "973959",
    "end": "979720"
  },
  {
    "text": "and things like that and then you can set up alarms that can tell you when",
    "start": "979720",
    "end": "986440"
  },
  {
    "text": "things are going you know poorly so for example if the cluster is Idle if the cluster is not doing anything for an",
    "start": "986440",
    "end": "992079"
  },
  {
    "text": "hour you might want to receive a message saying hey shut down that cluster so we can you know help you contain the costs",
    "start": "992079",
    "end": "998319"
  },
  {
    "text": "if your hgfs is 80% full you can set up an alarm hey you know grow your cluster and we have apis by the way to expand",
    "start": "998319",
    "end": "1003560"
  },
  {
    "text": "the cluster and then um you can do uh things like you know does the cluster",
    "start": "1003560",
    "end": "1008880"
  },
  {
    "text": "runs efficiently does it does it sort of chew through uh the work fast enough and",
    "start": "1008880",
    "end": "1014399"
  },
  {
    "text": "so you can set all those alarms and of course you can have web debugging uh a aable for you as well so you can see uh",
    "start": "1014399",
    "end": "1020920"
  },
  {
    "text": "problem problems with with the application and there's a lot of third party tools such as kere analyst where",
    "start": "1020920",
    "end": "1027918"
  },
  {
    "text": "you can um run uh your jobs and debug them right through the uh cons through",
    "start": "1027919",
    "end": "1033520"
  },
  {
    "text": "the console on their desktop so that is how you collect store and analyze data",
    "start": "1033520",
    "end": "1039199"
  },
  {
    "text": "now what about sharing when you when you share your data you visualize it you explore it and",
    "start": "1039199",
    "end": "1044600"
  },
  {
    "start": "1040000",
    "end": "1090000"
  },
  {
    "text": "you decide um based on you make decisions based on the data so let's",
    "start": "1044600",
    "end": "1049679"
  },
  {
    "text": "look at a couple of examples here in this example you can see uh where one of our customers",
    "start": "1049679",
    "end": "1055679"
  },
  {
    "text": "forsquare has built this visualization of customer signups from November of 2008 to June 2011 and this visualization",
    "start": "1055679",
    "end": "1064240"
  },
  {
    "text": "helps understand global Service adoption over time you can create very similar visualizations easily with packages such",
    "start": "1064240",
    "end": "1071559"
  },
  {
    "text": "as gplot or our graphical package and both the support on top of elastic maper",
    "start": "1071559",
    "end": "1077720"
  },
  {
    "text": "use uh um you can see that visualization like this can help really bring LinkedIn",
    "start": "1077720",
    "end": "1083880"
  },
  {
    "text": "data to life and uh make make make sort of understand your your networks",
    "start": "1083880",
    "end": "1090400"
  },
  {
    "text": "better and EMR integrates with tools like micro strategy and business intelligence platform so you can build",
    "start": "1090400",
    "end": "1096760"
  },
  {
    "text": "visualization such as this one directly from elastic map prod use so I hope this V this presentation",
    "start": "1096760",
    "end": "1104640"
  },
  {
    "text": "help you understand how you collect store analyze and share data using Amazon web services and now I'd like to",
    "start": "1104640",
    "end": "1111039"
  },
  {
    "text": "introduce you to um one of our customers Jeff Sternberg of capital IQ who is going to present some of their big data",
    "start": "1111039",
    "end": "1117480"
  },
  {
    "text": "use cases thank you thanks Peter so I'm Jeff Sternberg and I'm from SNP uh",
    "start": "1117480",
    "end": "1124480"
  },
  {
    "text": "Capital IQ uh we are a financial information uh publisher and uh analytics platform uh",
    "start": "1124480",
    "end": "1132679"
  },
  {
    "text": "we serve uh uh Wall Street types um so I'm going to be talking about Big Data",
    "start": "1132679",
    "end": "1137760"
  },
  {
    "text": "Wall Street Style so I'm going to start a little bit with a boring Financial chart um just a very",
    "start": "1137760",
    "end": "1145280"
  },
  {
    "text": "typical uh trend line over time goes up and to the right um it gets a little uh",
    "start": "1145280",
    "end": "1151080"
  },
  {
    "text": "more interesting or less boring with labels um so what we're actually looking at here is the cumulative transaction",
    "start": "1151080",
    "end": "1158320"
  },
  {
    "text": "value uh of investment in the information technology sector uh over the last 10 years and um you can note",
    "start": "1158320",
    "end": "1166559"
  },
  {
    "text": "actually there's a little flattening out in the in the uh downturn time of 2008 2009 related to the recession um but",
    "start": "1166559",
    "end": "1174799"
  },
  {
    "text": "this is a a pretty big number uh $ 2.37 trillion dollar invested in Information",
    "start": "1174799",
    "end": "1180280"
  },
  {
    "text": "Technology over the last 10 years so you know I was I I also wanted to mention that I was able to do this",
    "start": "1180280",
    "end": "1185919"
  },
  {
    "text": "analysis using S&P Capital iq's uh TR transaction screening tools of course so",
    "start": "1185919",
    "end": "1191520"
  },
  {
    "text": "Shameless plug there um so next I wanted to think about uh big data and and this",
    "start": "1191520",
    "end": "1196720"
  },
  {
    "text": "is obviously a pretty hot topic the these days and and kind of fits in well with the theme of today um so how much",
    "start": "1196720",
    "end": "1202440"
  },
  {
    "text": "investment is is happening in Big Data so uh we'll drill into that and and this",
    "start": "1202440",
    "end": "1207679"
  },
  {
    "text": "is a similar chart as um as before so this is narrowing the time range down to",
    "start": "1207679",
    "end": "1213120"
  },
  {
    "text": "just the last three years and and this is still cumulative transaction value for the it sector um so this represents",
    "start": "1213120",
    "end": "1219559"
  },
  {
    "text": "nearly 800 billion over the last three years and I narrow the time range to three years so that I could do this",
    "start": "1219559",
    "end": "1225080"
  },
  {
    "text": "chart um which shows us the uh investment in specifically in Big Data",
    "start": "1225080",
    "end": "1230880"
  },
  {
    "text": "uh companies so I did this by limiting um uh the results of my screen or the",
    "start": "1230880",
    "end": "1236000"
  },
  {
    "text": "scope the scope of my screen to companies to transactions where the target company uh contained keywords in",
    "start": "1236000",
    "end": "1242159"
  },
  {
    "text": "their business description uh for things like data optimization modeling analytics Hadoop Map ruce cloud storage",
    "start": "1242159",
    "end": "1250799"
  },
  {
    "text": "Etc um so and you can see actually there's a little bump at the end which is which is Facebook which I think we'd",
    "start": "1250799",
    "end": "1256520"
  },
  {
    "text": "all agree is a a big data company um so uh so using this um this this",
    "start": "1256520",
    "end": "1263520"
  },
  {
    "text": "manipulation or this data uh and and rolling it into the quadratic equation we can actually compute the yearly",
    "start": "1263520",
    "end": "1270039"
  },
  {
    "text": "growth rates growth rates of these two uh valuation trend lines um and uh to do",
    "start": "1270039",
    "end": "1276240"
  },
  {
    "text": "that we find that the information technology investment is growing at a yearly rate of about 23% and the uh",
    "start": "1276240",
    "end": "1284559"
  },
  {
    "text": "investment in Big Data uh during the corresponding time range is growing at rate of",
    "start": "1284559",
    "end": "1290159"
  },
  {
    "text": "78% um so using this this uh this little extra formula here we were able to solve",
    "start": "1290159",
    "end": "1296360"
  },
  {
    "text": "for y which is the number of years it will take for Big Data investment to take to overtake it in general um and",
    "start": "1296360",
    "end": "1302919"
  },
  {
    "text": "that's going to be nine and 9.7 years so um you know by the by the end of the decade I think uh big data will",
    "start": "1302919",
    "end": "1309240"
  },
  {
    "text": "completely dominate uh information technology so that's my prediction here today and here's a little uh curve to",
    "start": "1309240",
    "end": "1316120"
  },
  {
    "text": "just you know just to make that pretty um so and and and with that I think we can",
    "start": "1316120",
    "end": "1322320"
  },
  {
    "start": "1320000",
    "end": "1350000"
  },
  {
    "text": "answer the question big money yes big data is big money so and I wanted to talk a little",
    "start": "1322320",
    "end": "1328840"
  },
  {
    "text": "bit about um how how we at S&P Capital IQ are using elastic map produce in particular and we're doing it with a",
    "start": "1328840",
    "end": "1335720"
  },
  {
    "text": "recommendation engine although we're not technically allowed to say recommend because we're uh we're a financial",
    "start": "1335720",
    "end": "1340880"
  },
  {
    "text": "platform and and we're supposed to be unbiased and uh we're not really allowed to give uh actual Buy sell hold",
    "start": "1340880",
    "end": "1346000"
  },
  {
    "text": "recommendations because we're just public data so we're we're calling it suggesting data um so what we want out of our",
    "start": "1346000",
    "end": "1352600"
  },
  {
    "text": "platform is is a platform that learns from user Behavior right and some of the examples Peter mentioned um and I'm sure",
    "start": "1352600",
    "end": "1358760"
  },
  {
    "text": "everybody here uh is can can get into this you know you want a web experience",
    "start": "1358760",
    "end": "1364159"
  },
  {
    "text": "where um it's kind of tailored over time to to you as the user um and we're no different even though that you know our",
    "start": "1364159",
    "end": "1370559"
  },
  {
    "text": "our end users are are Wall Street Wall Street investors um and in our particular case what we want to do is we",
    "start": "1370559",
    "end": "1376640"
  },
  {
    "text": "want to suggest company profiles that the user might be interested in viewing based on their previous click history in",
    "start": "1376640",
    "end": "1383200"
  },
  {
    "text": "our platform right um so at over time investors are looking at company profiles in capital IQ and they're",
    "start": "1383200",
    "end": "1388679"
  },
  {
    "text": "they're saying you know uh they're basically informing us what's going on with with the way they think based on",
    "start": "1388679",
    "end": "1395120"
  },
  {
    "text": "that usage um and unlike uh say an Amazon or Netflix or something that can",
    "start": "1395120",
    "end": "1402080"
  },
  {
    "text": "um use collaborative filtering uh we can't do that because um our users are",
    "start": "1402080",
    "end": "1407679"
  },
  {
    "text": "uh you know people who work at investment Banks um or manage Investments and you know they really",
    "start": "1407679",
    "end": "1413400"
  },
  {
    "text": "don't want their uh activity to to sort of inform um someone else's activity",
    "start": "1413400",
    "end": "1418840"
  },
  {
    "text": "right or or you know we don't want any any bleed through so we we can actually provide investment advice and and and",
    "start": "1418840",
    "end": "1424640"
  },
  {
    "text": "are the clients wind up being or our clients wind up being super secret about their deals um so but our advantage is",
    "start": "1424640",
    "end": "1432400"
  },
  {
    "text": "that we have lots of great data um that we that we sell on our platform that we collect uh store and and and and sell um",
    "start": "1432400",
    "end": "1439799"
  },
  {
    "text": "and one of the key data sets um is is called key developments which is a news product and and we curate news and and",
    "start": "1439799",
    "end": "1446760"
  },
  {
    "text": "figure out what are the most important events um so that our clients can get smart on a company very",
    "start": "1446760",
    "end": "1452559"
  },
  {
    "text": "quickly um we do searches to catch interesting um articles in press press releases and we have a a global research",
    "start": "1452559",
    "end": "1460279"
  },
  {
    "text": "team that ensures that the entities are linked correctly that that the news articles key developments are are tagged",
    "start": "1460279",
    "end": "1466480"
  },
  {
    "text": "correctly to the right companies um and that the uh the events are typed correctly with different",
    "start": "1466480",
    "end": "1473240"
  },
  {
    "text": "categories um and so here's just a an an example of some of this data just to get",
    "start": "1473320",
    "end": "1478760"
  },
  {
    "text": "a feel for it this is um a dump of of Facebook's um recent key developments",
    "start": "1478760",
    "end": "1484559"
  },
  {
    "text": "and you can see things like m&a transactions lawsuits um client announcements",
    "start": "1484559",
    "end": "1491120"
  },
  {
    "start": "1491000",
    "end": "1622000"
  },
  {
    "text": "Etc so with our key developments data set what we wanted to do was was get um",
    "start": "1491240",
    "end": "1497120"
  },
  {
    "text": "the the interesting um events that occur in the news you know the news is sort of full of sort of regular news and then",
    "start": "1497120",
    "end": "1502919"
  },
  {
    "text": "there's every once in a while there's interesting news and we're defining interesting news based on um popularity",
    "start": "1502919",
    "end": "1508919"
  },
  {
    "text": "and frequency so things that are uh very popular when they occur and don't occur",
    "start": "1508919",
    "end": "1514520"
  },
  {
    "text": "very frequently are more interesting so that's um you know an example of that in in the Wall Street world is something",
    "start": "1514520",
    "end": "1520799"
  },
  {
    "text": "like a dividend dividend increase right so if a company has had a a the same dividend um year over year or quarter",
    "start": "1520799",
    "end": "1527600"
  },
  {
    "text": "over a quarter and then suddenly they increase it because they're they want to return more profits to shareholders uh",
    "start": "1527600",
    "end": "1533320"
  },
  {
    "text": "you know that's that's an anomaly or an interesting event and and that's going to be recommended higher um we also",
    "start": "1533320",
    "end": "1538799"
  },
  {
    "text": "Build A A A system that we call user selectivity so I mentioned that you know",
    "start": "1538799",
    "end": "1543880"
  },
  {
    "text": "we're we're tracking uh or we're we're learning from user behavior in our in our platform and what we want to do is",
    "start": "1543880",
    "end": "1550880"
  },
  {
    "text": "say you know uh based on your usage are do you show a preference for a particular sector um do you like",
    "start": "1550880",
    "end": "1556440"
  },
  {
    "text": "information technology companies or utilities or energy companies um do you focus on a particular region of the",
    "start": "1556440",
    "end": "1562480"
  },
  {
    "text": "world or are you kind of broad um and then you know do you do you care more about private companies or public",
    "start": "1562480",
    "end": "1568080"
  },
  {
    "text": "companies because of the type of Investments that you can do um so we create patterns uh for each",
    "start": "1568080",
    "end": "1574480"
  },
  {
    "text": "user um and the way we do it is is we score these suggestions um and and we do",
    "start": "1574480",
    "end": "1580440"
  },
  {
    "text": "this in Hadoop and And Hive with elastic map produce um we got to be careful to remember to uh remove items that the",
    "start": "1580440",
    "end": "1587000"
  },
  {
    "text": "user's already seen and um we presented in a widget on on our dashboard um and",
    "start": "1587000",
    "end": "1592679"
  },
  {
    "text": "then obviously to tune the algorithm we want to measure how frequently um users click through that and so that we can",
    "start": "1592679",
    "end": "1598440"
  },
  {
    "text": "iterate the cycle and make improvements and so this is just a very um uh high level overview of what uh the",
    "start": "1598440",
    "end": "1606039"
  },
  {
    "text": "what it looks like in our platform so this is the my homepage when I log into the platform um and the uh the feature",
    "start": "1606039",
    "end": "1612760"
  },
  {
    "text": "that we're talking about here is the companies who may be interested in widget so this is recommended some um",
    "start": "1612760",
    "end": "1618240"
  },
  {
    "text": "some companies to me based on my previous activity and uh just a couple of quick",
    "start": "1618240",
    "end": "1625120"
  },
  {
    "start": "1622000",
    "end": "1731000"
  },
  {
    "text": "uh tips on how we did it or how the implementation is um so what we do is we",
    "start": "1625120",
    "end": "1630919"
  },
  {
    "text": "actually have a a very large um set of data that's stored inhouse in uh in in",
    "start": "1630919",
    "end": "1637159"
  },
  {
    "text": "traditional relational database uh structure and um we export that data um",
    "start": "1637159",
    "end": "1642679"
  },
  {
    "text": "including the the clicks and the key developments um into uh an S3 um bucket",
    "start": "1642679",
    "end": "1648399"
  },
  {
    "text": "and then um compute with elastic map ruce the selectivity components the uh",
    "start": "1648399",
    "end": "1654799"
  },
  {
    "text": "key development uh event typing uh recency and a few other things and we join those things up together compute a",
    "start": "1654799",
    "end": "1661880"
  },
  {
    "text": "score and and produce a data output set that we then Store back on S3 and then load back into our SQL database and our",
    "start": "1661880",
    "end": "1669360"
  },
  {
    "text": "web pages you know query the data from the SQL database that way um and then if you want to get into a little bit more",
    "start": "1669360",
    "end": "1675679"
  },
  {
    "text": "of the detail um some of the tools that we're using us uh we're using Microsoft SQL Server BCP utility which is a bull",
    "start": "1675679",
    "end": "1682880"
  },
  {
    "text": "copy utility um and and we bu copy data out um and we're using an S3 a Windows",
    "start": "1682880",
    "end": "1688919"
  },
  {
    "text": "s3. exe commandline application to push data to uh the S3 bucket and then we",
    "start": "1688919",
    "end": "1695039"
  },
  {
    "text": "launch a uh a 16 node cluster right now um with uh hupen hiive um via a ruby",
    "start": "1695039",
    "end": "1701200"
  },
  {
    "text": "script we we decided to use Ruby because uh a lot of the uh the Amazon apis are",
    "start": "1701200",
    "end": "1706640"
  },
  {
    "text": "have nice uh command line interface wrappers in in Ruby um so we kind of control the cluster through this Ruby",
    "start": "1706640",
    "end": "1712600"
  },
  {
    "text": "script and uh the we actually wind up pushing the hive data and or the hive scripts and the data Computing and then",
    "start": "1712600",
    "end": "1719600"
  },
  {
    "text": "kind of hanging out waiting for the for the job to complete and then when it's done we we pull it back with that same",
    "start": "1719600",
    "end": "1724960"
  },
  {
    "text": "S3 application and uh and BCP it back into our",
    "start": "1724960",
    "end": "1730159"
  },
  {
    "text": "database so that's uh that's actually the end of my of my bit so I think we're going to uh move on to questions um um",
    "start": "1730480",
    "end": "1738760"
  },
  {
    "start": "1731000",
    "end": "1778000"
  },
  {
    "text": "Peter and I will come up here and uh and if you guys have any questions thanks for thanks for",
    "start": "1738760",
    "end": "1743840"
  },
  {
    "text": "coming all right thanks very much Jeff and uh do",
    "start": "1743840",
    "end": "1750840"
  },
  {
    "text": "you guys have any questions about Big Data please out there we have a",
    "start": "1750840",
    "end": "1756200"
  },
  {
    "text": "microphone right here if",
    "start": "1756200",
    "end": "1759600"
  },
  {
    "text": "uh can you guys hear me we can hear you yeah excellent question for I'm curious",
    "start": "1761360",
    "end": "1770039"
  },
  {
    "start": "1778000",
    "end": "1830000"
  },
  {
    "text": "right okay cool so um repeat the question repeating the question yeah so the question is how frequently does this",
    "start": "1779200",
    "end": "1785720"
  },
  {
    "text": "calculation uh that I described work for the recommendation system um and and how",
    "start": "1785720",
    "end": "1791559"
  },
  {
    "text": "quickly do we update data um so right now I think uh our cluster our job runs in about eight hours um and so we run",
    "start": "1791559",
    "end": "1798760"
  },
  {
    "text": "that twice a day um and you know we're thinking of uh you know various ways to tune it and maybe run it a little bit",
    "start": "1798760",
    "end": "1805919"
  },
  {
    "text": "more frequently but um many of the events that happen in our platform and",
    "start": "1805919",
    "end": "1810960"
  },
  {
    "text": "our key developments um are kind of look back over a week or two weeks or a month and and so we think that's a pretty good",
    "start": "1810960",
    "end": "1817600"
  },
  {
    "text": "latency for the use case great I think good was",
    "start": "1817600",
    "end": "1824760"
  },
  {
    "text": "waiting does like you have long running EMR job like do you have a long running",
    "start": "1825000",
    "end": "1832120"
  },
  {
    "start": "1830000",
    "end": "1898000"
  },
  {
    "text": "uh cluster or is it like do you restart them um at you know whenever you need to run the job and the second related",
    "start": "1832120",
    "end": "1839279"
  },
  {
    "text": "question is do you do real-time analytics I mean Hado is not meant for this but how do you do your realtime analytics and you know um end user uh",
    "start": "1839279",
    "end": "1847399"
  },
  {
    "text": "quick response time queries sure um so yeah the first part of the question is",
    "start": "1847399",
    "end": "1852679"
  },
  {
    "text": "we do we do spin up a new cluster every time we want to do compute because we're only need it for a few hours and then we",
    "start": "1852679",
    "end": "1858480"
  },
  {
    "text": "shut it down um so actually EMR is really good at that and and you know it that really fits our use case um and",
    "start": "1858480",
    "end": "1864840"
  },
  {
    "text": "then for sort of realtime stuff uh we have a whole bunch of other stuff going on uh we don't really use Hadoop at this",
    "start": "1864840",
    "end": "1871480"
  },
  {
    "text": "point for uh for that sort of use cases but um you know our front-end website has a bunch of realtime um capabilities",
    "start": "1871480",
    "end": "1878679"
  },
  {
    "text": "in including you know stock quotes and and uh various sorts of financial analytics uh and and so those use other",
    "start": "1878679",
    "end": "1885639"
  },
  {
    "text": "other toolkits um you mentioned that you use a 16 node",
    "start": "1885639",
    "end": "1890960"
  },
  {
    "text": "cluster how did you guys come up with that number and have you experimented with other like volumes of of of the",
    "start": "1890960",
    "end": "1897760"
  },
  {
    "text": "size of the cluster yeah definitely that's a really good question um we we basically started kind of small I think",
    "start": "1897760",
    "end": "1903720"
  },
  {
    "start": "1898000",
    "end": "1967000"
  },
  {
    "text": "two or three nodes and then we just started iteratively you know testing larger sizes and and um you know it we",
    "start": "1903720",
    "end": "1909880"
  },
  {
    "text": "found that it's a trade-off between instance types and the number of instances that you have and then you",
    "start": "1909880",
    "end": "1915320"
  },
  {
    "text": "know frankly how paral parallelizable is your query or is your is your hive code",
    "start": "1915320",
    "end": "1920799"
  },
  {
    "text": "um Hive sometimes has steps that it will you know want to use a single a single",
    "start": "1920799",
    "end": "1926480"
  },
  {
    "text": "map task or a single reduce task and you have to kind of tweak it a little bit to to make it partition um or to take",
    "start": "1926480",
    "end": "1932919"
  },
  {
    "text": "advantage of the right number of of instances but um it's mostly a process of experimentation which again is pretty",
    "start": "1932919",
    "end": "1939600"
  },
  {
    "text": "easy because you can you know you can have you can try different parameters you can run tests and uh it's pretty easy to get",
    "start": "1939600",
    "end": "1946399"
  },
  {
    "text": "going hey thank thanks for doing all this uh uh at really superficially uh how",
    "start": "1946399",
    "end": "1954200"
  },
  {
    "text": "would you do a join query uh between uh",
    "start": "1954200",
    "end": "1960279"
  },
  {
    "text": "uh Dynamo and uh and and SQL and my and",
    "start": "1960279",
    "end": "1967240"
  },
  {
    "start": "1967000",
    "end": "2052000"
  },
  {
    "text": "RDS right so how does that work so both Dynamo and um RDS we have connectors in",
    "start": "1967240",
    "end": "1975039"
  },
  {
    "text": "elastic mapper use and so you you do it essentially through Hive so um in Hive",
    "start": "1975039",
    "end": "1981840"
  },
  {
    "text": "you can specify a table in Dynamo you can say select stuff from a table in Dynamo and you can join it to a table in",
    "start": "1981840",
    "end": "1989639"
  },
  {
    "text": "RDS The Joint itself is going to happen on an EMR cluster so but you filter push",
    "start": "1989639",
    "end": "1996840"
  },
  {
    "text": "down the Dynamo DB so you retrieve the relevant data from Dynamo you retrieve the relevant data from RDS and then you",
    "start": "1996840",
    "end": "2003080"
  },
  {
    "text": "do SQL join inside map ruce uh on elastic mapu",
    "start": "2003080",
    "end": "2008720"
  },
  {
    "text": "sorry so it happens inside map produce it does happen inside map produce right there there's no data data import that",
    "start": "2008720",
    "end": "2014519"
  },
  {
    "text": "goes into first the SQL side and the joint happens natively as part of the",
    "start": "2014519",
    "end": "2019679"
  },
  {
    "text": "SQL engine no The Joint part happens as a part of map U uh engine in EMR",
    "start": "2019679",
    "end": "2025919"
  },
  {
    "text": "yeah I really enjoyed your boring graphs they were boring um so I'm wondering if",
    "start": "2025919",
    "end": "2031799"
  },
  {
    "text": "either of you might speak for a second about realtime visualization experience",
    "start": "2031799",
    "end": "2037399"
  },
  {
    "text": "or tools that you uh have found uh valuable or approaches you found",
    "start": "2037399",
    "end": "2043639"
  },
  {
    "text": "valuable for converting uh you know Big Data into uh",
    "start": "2043639",
    "end": "2048878"
  },
  {
    "text": "particularly into real-time visualization thank you yeah so um",
    "start": "2048879",
    "end": "2054800"
  },
  {
    "start": "2052000",
    "end": "2129000"
  },
  {
    "text": "generally elastic map producer um uh Hadoop is a batch processing uh batch",
    "start": "2054800",
    "end": "2061000"
  },
  {
    "text": "processing uh technology now the batch sizes can be actually quite small we have customers that have batch size of 5",
    "start": "2061000",
    "end": "2067440"
  },
  {
    "text": "minutes every time they process every five minutes um and there's several plotting",
    "start": "2067440",
    "end": "2074240"
  },
  {
    "text": "technologies that people apply in and integrate directly with elastic mappers and I mentioned our package so our",
    "start": "2074240",
    "end": "2080079"
  },
  {
    "text": "graphing as well as gplot those are the two really most commonly used uh Technologies where you can plot you know",
    "start": "2080079",
    "end": "2086000"
  },
  {
    "text": "the visualization that was created by for square I me showed in the presentation you know you can create those kinds of presentations um based on",
    "start": "2086000",
    "end": "2093679"
  },
  {
    "text": "this uh batch processing and and uh can continuously sort of upload the data points into those visualizations so your",
    "start": "2093679",
    "end": "2100079"
  },
  {
    "text": "visualization would would refresh so to speak every five minutes it's not every five minutes or every 10 minutes",
    "start": "2100079",
    "end": "2105880"
  },
  {
    "text": "whatever the frequency is it's not really real time uh but it is sort of a you know a near real time uh type",
    "start": "2105880",
    "end": "2113880"
  },
  {
    "text": "experience what is the uh language the M produ job is programmed and the what is",
    "start": "2116280",
    "end": "2122960"
  },
  {
    "text": "the like simple um like my Produce job how many",
    "start": "2122960",
    "end": "2128040"
  },
  {
    "text": "lines of code it will take you so traditional Hado uses uh Java to program",
    "start": "2128040",
    "end": "2135839"
  },
  {
    "start": "2129000",
    "end": "2217000"
  },
  {
    "text": "map and reduce but there are multiple layers or multiple applications have been written on top of map reduce to",
    "start": "2135839",
    "end": "2141320"
  },
  {
    "text": "enable other languages and so um there's python that you can write jobs in you",
    "start": "2141320",
    "end": "2147240"
  },
  {
    "text": "can write jobs in Ruby you can you know you can write jobs in SQL like language which is Hive there's this um Pig",
    "start": "2147240",
    "end": "2155040"
  },
  {
    "text": "language U that's the name of that the langage",
    "start": "2155040",
    "end": "2159640"
  },
  {
    "start": "2217000",
    "end": "2361000"
  },
  {
    "text": "sense um so it's it's interesting you know uh if you uh you if you don't have",
    "start": "2218000",
    "end": "2226000"
  },
  {
    "text": "a essentially the big data problem starts when you can't fit necessarily a data on a single machine that's when you",
    "start": "2226000",
    "end": "2232160"
  },
  {
    "text": "have sort of distributed data problem um but but you don't have to wait to use",
    "start": "2232160",
    "end": "2238040"
  },
  {
    "text": "Hado to process data sets you can set up Hado jobs to process your data however",
    "start": "2238040",
    "end": "2243720"
  },
  {
    "text": "small it is and then you essentially solve your scaling Pro your SC in data problem forever the more data you have",
    "start": "2243720",
    "end": "2250680"
  },
  {
    "text": "if you implement in such a mentality the more data you have the you know just just add more more nodes and your",
    "start": "2250680",
    "end": "2256920"
  },
  {
    "text": "problem is solved so um I would encourage people to think through their",
    "start": "2256920",
    "end": "2263839"
  },
  {
    "text": "problems at a scalable hadu way and introduce you knowu process into your",
    "start": "2263839",
    "end": "2269520"
  },
  {
    "text": "data processing no matter how large your data sets so a couple of things would happen number one is you'll see you you",
    "start": "2269520",
    "end": "2275319"
  },
  {
    "text": "want to move more and more data sets to process you you'll be able to integrate because it's so easy and number two the",
    "start": "2275319",
    "end": "2280640"
  },
  {
    "text": "more volume of data you have uh the easier it is going to be to scale in the future so um there is really no",
    "start": "2280640",
    "end": "2287680"
  },
  {
    "text": "threshold I mean there's a physical threshold over one machine but but there's really no threshold of when you",
    "start": "2287680",
    "end": "2292720"
  },
  {
    "text": "should use kup technology you can start with a data of couple hundred Megs or or or even",
    "start": "2292720",
    "end": "2299280"
  },
  {
    "text": "smaller do you want to add anything to that um yeah I mean we we basically made",
    "start": "2299280",
    "end": "2304800"
  },
  {
    "text": "the the choice to go to EMR over sort of",
    "start": "2304800",
    "end": "2309520"
  },
  {
    "text": "[Music]",
    "start": "2338850",
    "end": "2341969"
  },
  {
    "text": "you can very easily kill your RDS instance with a relatively small cluster Hado cluster just because it can't it's",
    "start": "2368200",
    "end": "2374560"
  },
  {
    "text": "so efficient of pulling data and so um you have to be a little careful is how",
    "start": "2374560",
    "end": "2379760"
  },
  {
    "text": "you size your cluster to to not to not do that um so the couple of techniques",
    "start": "2379760",
    "end": "2385560"
  },
  {
    "text": "one is you can actually you know you can pull directly from RDS instance that you have for production the other one is you can just create SQL dumps in S3 and then",
    "start": "2385560",
    "end": "2392319"
  },
  {
    "text": "you load them from S3 into uh into hadu and a lot of people that have oper op",
    "start": "2392319",
    "end": "2397599"
  },
  {
    "text": "AAL requirement High operational requirement in RDS instance follow that follow that mechanism instead of direct",
    "start": "2397599",
    "end": "2403839"
  },
  {
    "text": "pull just because had is so powerful and pulling",
    "start": "2403839",
    "end": "2407720"
  },
  {
    "text": "it I I'd like to know if you had some um client or idea of people using uh map",
    "start": "2409319",
    "end": "2415560"
  },
  {
    "text": "produc for image processing resizing detection whatever absolutely we have uh",
    "start": "2415560",
    "end": "2422440"
  },
  {
    "start": "2420000",
    "end": "2527000"
  },
  {
    "text": "in fact we have several uh case studies on the website you can go and check it out image resizing is very powerful uh",
    "start": "2422440",
    "end": "2428839"
  },
  {
    "text": "and and bread and butter use case for EMR but there are a lot of interesting Innovative things that people are doing there's a company in career in Korea",
    "start": "2428839",
    "end": "2436440"
  },
  {
    "text": "that uses image recognition using elastic map produce to",
    "start": "2436440",
    "end": "2442040"
  },
  {
    "text": "sort of do like a really nice stocking application you just upload an image and it surfaces that image on Facebook and",
    "start": "2442040",
    "end": "2447160"
  },
  {
    "text": "everywhere else and just finds all the sources of images that contain that picture that photo there's a lot of",
    "start": "2447160",
    "end": "2452800"
  },
  {
    "text": "other image processing that is going on some company we have companies that do um interesting um copyright searches so",
    "start": "2452800",
    "end": "2459920"
  },
  {
    "text": "you know if your image has been used inappropriately on the internet they can actually using image recognition software figure out which sites are",
    "start": "2459920",
    "end": "2467000"
  },
  {
    "text": "using that image in appropriately so there's a lot of use cases of image processing on the on the EMR okay but how we can uh customize the map produce",
    "start": "2467000",
    "end": "2474880"
  },
  {
    "text": "for example to use open CV or image magic or those libraries you can do you can do exactly that with elastic map",
    "start": "2474880",
    "end": "2480800"
  },
  {
    "text": "produce using this feature called streaming where Hado streams the data",
    "start": "2480800",
    "end": "2486560"
  },
  {
    "text": "into your applic on each note and then gets the results back so kup is a really sort of paration and scheduling",
    "start": "2486560",
    "end": "2492520"
  },
  {
    "text": "framework in this case using uh you know that uses the libraries you already have you don't have to recompile any of the",
    "start": "2492520",
    "end": "2498040"
  },
  {
    "text": "libraries to use it with had you just feed you pipe the data into hadu cluster thank",
    "start": "2498040",
    "end": "2505960"
  },
  {
    "text": "you please I heard basically like a job and",
    "start": "2506240",
    "end": "2513160"
  },
  {
    "text": "you mentioned something about streaming the way that I would",
    "start": "2513160",
    "end": "2518240"
  },
  {
    "text": "it that way be that actually a query and I'm going to get some kind of response",
    "start": "2518240",
    "end": "2524000"
  },
  {
    "text": "in a fashion is that possible with yes it is possible so the question",
    "start": "2524000",
    "end": "2529400"
  },
  {
    "start": "2527000",
    "end": "2633000"
  },
  {
    "text": "is can I send a query in the real time get a result back um it is possible many customers are using elastic maer as a",
    "start": "2529400",
    "end": "2535880"
  },
  {
    "text": "sort of a data warehouse with Hive so you actually have a hive client in fact",
    "start": "2535880",
    "end": "2541000"
  },
  {
    "text": "you know I've mentioned kosere has one uh such client you actually install a desktop application where you can use",
    "start": "2541000",
    "end": "2546880"
  },
  {
    "text": "free one want like a uh SQL squirrel or any other you know uh jdbc compliant um",
    "start": "2546880",
    "end": "2553160"
  },
  {
    "text": "uh clients and you can run Hive on top of EMR and so you can just type in",
    "start": "2553160",
    "end": "2558680"
  },
  {
    "text": "select star whatever and it goes and executes on EMR and R retrieves the results back now um how fast it really",
    "start": "2558680",
    "end": "2566520"
  },
  {
    "text": "how fast it really depends on what kind of queries you're doing so if you're doing Full Table scan um type of queries",
    "start": "2566520",
    "end": "2573359"
  },
  {
    "text": "Hadoop is extremely efficient it's you know could be faster than your traditional databases if you're doing",
    "start": "2573359",
    "end": "2580359"
  },
  {
    "text": "some select select queries where you know you benefit from an index uh Hadoop",
    "start": "2580359",
    "end": "2585920"
  },
  {
    "text": "will be slower because Hadoop doesn't have the Strategic data placement Etc but people do people do run these large",
    "start": "2585920",
    "end": "2592119"
  },
  {
    "text": "data warehouses on had on on using exactly the mechanisms that you just asked",
    "start": "2592119",
    "end": "2598839"
  },
  {
    "text": "iess it would go faster so if you increase the kup does have a linear scale almost linear scale there's some",
    "start": "2598839",
    "end": "2605839"
  },
  {
    "text": "um caveats to that but yeah if you add more notes you will run faster so um we",
    "start": "2605839",
    "end": "2611880"
  },
  {
    "text": "have several examples in fact we have a tutorial on our website about how do you use Amazon elastic maper as a data",
    "start": "2611880",
    "end": "2618119"
  },
  {
    "text": "warehouse it goes exactly into those details I how would you compare using",
    "start": "2618119",
    "end": "2624680"
  },
  {
    "text": "Ado over using an architecture with message heing and workers with data",
    "start": "2624680",
    "end": "2630920"
  },
  {
    "text": "coming uh uh progressively yeah so how do you compare Hado with other uh",
    "start": "2630920",
    "end": "2636160"
  },
  {
    "start": "2633000",
    "end": "2714000"
  },
  {
    "text": "scheduling Technologies like message queuing and whatnot um so Hadoop is a great framework that has um um that has",
    "start": "2636160",
    "end": "2644680"
  },
  {
    "text": "scheduling that has fault tolerance and it has distributed file system so um",
    "start": "2644680",
    "end": "2650000"
  },
  {
    "text": "there's been tremendous amount of investment in hiup infrastructure so while there are others available you",
    "start": "2650000",
    "end": "2656480"
  },
  {
    "text": "know there's another Frameworks like that maybe Condor is another example uh Hado is just had such a big wave of",
    "start": "2656480",
    "end": "2662520"
  },
  {
    "text": "innovation in it that the question is you know why would you use something else and it's open source as well so um",
    "start": "2662520",
    "end": "2668960"
  },
  {
    "text": "you know there's M mqs and whatnot so maybe there's uh some targeted applications uh in biospace for example",
    "start": "2668960",
    "end": "2675440"
  },
  {
    "text": "that you might use some Alternatives but for general purpose scheduling distributed file system and fault",
    "start": "2675440",
    "end": "2681200"
  },
  {
    "text": "tolerant application development is a really native Choice uh is Ado able to",
    "start": "2681200",
    "end": "2686359"
  },
  {
    "text": "get data that that is BU progressively with a message cre with a queueing",
    "start": "2686359",
    "end": "2692359"
  },
  {
    "text": "system you just queue data and workers work on it but with aoop is it only one",
    "start": "2692359",
    "end": "2697680"
  },
  {
    "text": "shot or or you can tell aop to watch from time to time the data yeah you can",
    "start": "2697680",
    "end": "2702839"
  },
  {
    "text": "you can have you can watch you know you can run continuous job that we just look at the file system and continuously react and change in the file system",
    "start": "2702839",
    "end": "2709160"
  },
  {
    "text": "absolutely okay thanks y something on Friday so just wanted to",
    "start": "2709160",
    "end": "2715800"
  },
  {
    "start": "2714000",
    "end": "2762000"
  },
  {
    "text": "mention that we have big data event the full one day event on next Friday in",
    "start": "2715800",
    "end": "2721319"
  },
  {
    "text": "Boston where we're going to go um the whole day talking about big data and uh",
    "start": "2721319",
    "end": "2727079"
  },
  {
    "text": "we're going to have a Hands-On session where our solution Architects and developers will help will be there to",
    "start": "2727079",
    "end": "2732640"
  },
  {
    "text": "help and answer any of the details questions about about the technology so please uh check out our website for uh",
    "start": "2732640",
    "end": "2739280"
  },
  {
    "text": "the Big Data event in Boston on April the",
    "start": "2739280",
    "end": "2744160"
  },
  {
    "text": "27th all right any other questions no thank you very much for",
    "start": "2745200",
    "end": "2751559"
  },
  {
    "text": "coming thank [Applause] you",
    "start": "2751559",
    "end": "2759040"
  }
]
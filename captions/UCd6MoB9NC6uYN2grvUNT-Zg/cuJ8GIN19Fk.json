[
  {
    "text": "hello and thank you for attending today's webinar we're going to begin the presentation and approximately one",
    "start": "9059",
    "end": "14309"
  },
  {
    "text": "minute from now",
    "start": "14309",
    "end": "16910"
  },
  {
    "text": "all right hello and welcome to Citrix moves data to Amazon redshift fast with",
    "start": "66390",
    "end": "71940"
  },
  {
    "text": "Mattila and ETL my name is Ryan Peterson I'm a partner Solutions Architect for Amazon Web Services I'm going to be your",
    "start": "71940",
    "end": "78390"
  },
  {
    "text": "host and moderator for today's presentation when you join today's webinar you selected to join by either",
    "start": "78390",
    "end": "84150"
  },
  {
    "text": "phone call or your computer audio if for any reason you would like to change your audio selection you can do so by",
    "start": "84150",
    "end": "90420"
  },
  {
    "text": "accessing your audio pane in the control panel from the control panel also have the opportunity to submit questions to",
    "start": "90420",
    "end": "96090"
  },
  {
    "text": "today's presenters by typing your questions into the questions panel we'll collect the questions and address as",
    "start": "96090",
    "end": "101880"
  },
  {
    "text": "many as we can during the Q&A section at the end of today's presentation at the end of today's event is a brief survey",
    "start": "101880",
    "end": "107970"
  },
  {
    "text": "please stay connected until the end of the broadcast and submit your feedback as your opinions count and matter toward",
    "start": "107970",
    "end": "113399"
  },
  {
    "text": "future presentations lastly the PowerPoint presentation will be available through SlideShare along",
    "start": "113399",
    "end": "118590"
  },
  {
    "text": "with the recording of the webinar on YouTube being an email you will be sent two to three days after the conclusion",
    "start": "118590",
    "end": "123750"
  },
  {
    "text": "of the event so please keep an eye out for that and follow up with any email sent to the address you've provided",
    "start": "123750",
    "end": "130390"
  },
  {
    "text": "you in addition to learning about Amazon Web",
    "start": "130390",
    "end": "137489"
  },
  {
    "text": "Services we're also going to hear from Sean Edmondson the senior director of engineering at Citrix",
    "start": "137489",
    "end": "142530"
  },
  {
    "text": "from Xie jammed the lead database engineer for Citrix and from Ed Thompson the CTO from Juliet today we're going to",
    "start": "142530",
    "end": "152670"
  },
  {
    "text": "learn about how to move data to Amazon redshift with speed and accuracy how to make inform to business critical",
    "start": "152670",
    "end": "158099"
  },
  {
    "text": "decisions by analyzing data with Amazon redshift out of speed time the value for your analytics initiatives using the",
    "start": "158099",
    "end": "164430"
  },
  {
    "text": "chileans pushdown ELT architecture I'm please remember to post your questions in the chat box throughout the event and",
    "start": "164430",
    "end": "170639"
  },
  {
    "text": "we'll get to those questions at the end let's begin with Amazon Web Services so",
    "start": "170639",
    "end": "178620"
  },
  {
    "text": "with Amazon redshift traditional analytics looked like this",
    "start": "178620",
    "end": "183800"
  },
  {
    "text": "you would you would take various source systems where there was old 50 or RPC",
    "start": "183800",
    "end": "189050"
  },
  {
    "text": "RMS and line of business applications and you'd push them to it data warehouse ultimately receive out business intelligence I was on premise it was",
    "start": "189050",
    "end": "196640"
  },
  {
    "text": "dealing with relational data and you had terabytes petabytes scale it was usually a very large capex investments and and",
    "start": "196640",
    "end": "204980"
  },
  {
    "text": "we believe what's happened now is we would change the model of how you can go and do that so for one you can spin it",
    "start": "204980",
    "end": "211460"
  },
  {
    "text": "up really rapidly and much easier with redshift you can get a simple click",
    "start": "211460",
    "end": "218120"
  },
  {
    "text": "button start and get working on your warehouse within minutes the the time lag that it used to be to get to a point",
    "start": "218120",
    "end": "224000"
  },
  {
    "text": "where you had a data warehouse in the first place is all gone as cost-effective would no up can cost you just simply pay-as-you-go it's like",
    "start": "224000",
    "end": "230840"
  },
  {
    "text": "the card and keep building or your data warehouse it's extremely scalable we talked about the elastic scalability you",
    "start": "230840",
    "end": "238490"
  },
  {
    "text": "can also scale to various regions globally so the ability to go out as far as you need to go and without having to",
    "start": "238490",
    "end": "245960"
  },
  {
    "text": "retain all the personnel to maintain and manage the physical infrastructure related we give you a better faster and",
    "start": "245960",
    "end": "253460"
  },
  {
    "text": "more cost-effective way of handling your video warehouse I would say we're very",
    "start": "253460",
    "end": "259790"
  },
  {
    "text": "integrated there's a lot of different connectivity we have throughout Amazon and throughout other organizations",
    "start": "259790",
    "end": "265850"
  },
  {
    "text": "Tooley how you learn about some of that today and of course to a very secure audited every step of the place and we",
    "start": "265850",
    "end": "274250"
  },
  {
    "text": "have quite a lot of compliancy features covering things I keep a compliancy and more",
    "start": "274250",
    "end": "281680"
  },
  {
    "text": "one of the more interesting things that we do is we talk about the data like all of the data that you have can be pushed",
    "start": "281989",
    "end": "288379"
  },
  {
    "text": "up through files into s3 and using something called Amazon spectral Reggio spectrum you can actually query that",
    "start": "288379",
    "end": "294739"
  },
  {
    "text": "data from the file directly in redshift there's that that is one feature that really enhances the capabilities of the",
    "start": "294739",
    "end": "301909"
  },
  {
    "text": "platform and with support for Part A or C Avro and other so very interesting",
    "start": "301909",
    "end": "308149"
  },
  {
    "text": "opportunities when it comes to ingesting file contents into your ATW",
    "start": "308149",
    "end": "315279"
  },
  {
    "text": "with that said a lot of different organizations or utilizing redshift you can see some of them on the screen there",
    "start": "315700",
    "end": "321820"
  },
  {
    "text": "we see more and more or picking up redshift every single day and in some of",
    "start": "321820",
    "end": "327640"
  },
  {
    "text": "those organizations we'll talk about today and specifically I love to talk about Citrix and how Citrix has made the",
    "start": "327640",
    "end": "334090"
  },
  {
    "text": "decision to use redshift for ShareFile so with that said I'm going to hand it",
    "start": "334090",
    "end": "340160"
  },
  {
    "text": "over to Shaun Edmondson and she a gem Shaun you want to go ahead and talk about your file thanks Aaron hi everyone this is Shaun",
    "start": "340160",
    "end": "347840"
  },
  {
    "text": "Edmondson I lead back-end engineering for citrix sharefile covering our cloud services platform storage and data bases",
    "start": "347840",
    "end": "355030"
  },
  {
    "text": "and we have a strong DevOps culture and share file in both Chia and I work really closely with our cloud ops team",
    "start": "355030",
    "end": "361190"
  },
  {
    "text": "as well yeah everyone this is sheer jam",
    "start": "361190",
    "end": "368660"
  },
  {
    "text": "lead database engineer here at Citrix I bring technical expertise and leadership",
    "start": "368660",
    "end": "373880"
  },
  {
    "text": "to the database team thanks she is a",
    "start": "373880",
    "end": "379720"
  },
  {
    "text": "dancing there we go so from a business",
    "start": "379720",
    "end": "386360"
  },
  {
    "text": "point of view share file is a rapidly growing Citrix product for content collaboration and file sharing for",
    "start": "386360",
    "end": "393229"
  },
  {
    "text": "enterprises as well as small business share file emphasizes a security user experience and choice for example we can",
    "start": "393229",
    "end": "400880"
  },
  {
    "text": "securely provide collaboration access across on-premise file servers applications such as SharePoint and of",
    "start": "400880",
    "end": "407840"
  },
  {
    "text": "course our own cloud storage now from a technical point of view share file is essentially a rather large SAS web",
    "start": "407840",
    "end": "415190"
  },
  {
    "text": "application we have roughly four and a half million users in over 80 thousand",
    "start": "415190",
    "end": "420380"
  },
  {
    "text": "paid accounts with billions of managed files using over 19 petabytes of cloud",
    "start": "420380",
    "end": "425930"
  },
  {
    "text": "storage last I checked we run over 2 million monthly instance hours across many easy to and Azure regions which is",
    "start": "425930",
    "end": "433400"
  },
  {
    "text": "the equivalent of about 3,000 full time running instances and we have a well automated DevOps deployment I'm really",
    "start": "433400",
    "end": "440389"
  },
  {
    "text": "proud that we hit three and a half 9s or 99.95% uptime in 2017 despite the",
    "start": "440389",
    "end": "447349"
  },
  {
    "text": "February outage in a certain cloud storage service that we we depend on now",
    "start": "447349",
    "end": "453199"
  },
  {
    "text": "let's dig down into our analytics problem oops there we go a couple years",
    "start": "453199",
    "end": "460280"
  },
  {
    "text": "ago we changed the ShareFile platform to use a high capacity internal message bus for end user events this hits over 500",
    "start": "460280",
    "end": "468469"
  },
  {
    "text": "events per second at peak times and it delivers a ton of about user and programmatic activity the",
    "start": "468469",
    "end": "474840"
  },
  {
    "text": "bus serves many purposes such as event-driven workflows async customer integrations via ShareFile web hooks and",
    "start": "474840",
    "end": "480720"
  },
  {
    "text": "most recently the citrix analytics service itself which is a slick product that delivers unique analytics for",
    "start": "480720",
    "end": "487530"
  },
  {
    "text": "security and other domains to our customers and of course the event stream is a rich source of information for our",
    "start": "487530",
    "end": "493530"
  },
  {
    "text": "internal analytics which is what we're talking about today Brian can you give me the desktop real quick so I'm going",
    "start": "493530",
    "end": "502710"
  },
  {
    "text": "to show an internal live dashboard to give you a sense of our event volume",
    "start": "502710",
    "end": "509750"
  },
  {
    "text": "let's see this coming up okay so anytime a user performs a core ShareFile",
    "start": "509750",
    "end": "515789"
  },
  {
    "text": "operation anywhere on earth such as logging in you see a dot on this map",
    "start": "515789",
    "end": "521130"
  },
  {
    "text": "within one second of the actual event so stash board is throwing away all the",
    "start": "521130",
    "end": "527460"
  },
  {
    "text": "event detail except the IP geolocation but every actual event has a ton of",
    "start": "527460",
    "end": "533940"
  },
  {
    "text": "properties which makes them a goldmine for analytics so this is a real-time stream it's at the core of the ShareFile",
    "start": "533940",
    "end": "540810"
  },
  {
    "text": "platform and the question is you know how do we do analytics on this thing so",
    "start": "540810",
    "end": "547200"
  },
  {
    "text": "getting back to the slides see there we",
    "start": "547200",
    "end": "554760"
  },
  {
    "text": "go all right so what's our problem oops too far again sorry we wanted to",
    "start": "554760",
    "end": "561690"
  },
  {
    "text": "deliver high value dashboards and reports on things like active use and customer lifecycle and geographic",
    "start": "561690",
    "end": "567690"
  },
  {
    "text": "behavior patterns and we wanted to base that data on the entire uh Nagre gated event stream running queries over",
    "start": "567690",
    "end": "574230"
  },
  {
    "text": "billions of events so essentially we don't just slurp all those events into a giant database and do fast interesting",
    "start": "574230",
    "end": "580920"
  },
  {
    "text": "queries on it we want to really wanted to have our cake and eat it too and we also needed a very lean solution",
    "start": "580920",
    "end": "587490"
  },
  {
    "text": "suitable for our sequel devs and our application does now we didn't you know we couldn't justify going out and",
    "start": "587490",
    "end": "592920"
  },
  {
    "text": "building a team of data scientists and a MapReduce cluster just to do this internal analytics so that is the",
    "start": "592920",
    "end": "598980"
  },
  {
    "text": "problem we're at how do we how do we do analytics on billions of events without a massive investment and that's where a",
    "start": "598980",
    "end": "604770"
  },
  {
    "text": "red shift in the came in so at this point I'd like to hand it off to Xie who's our senior technologist who personally built much",
    "start": "604770",
    "end": "611850"
  },
  {
    "text": "of what we're about to talk about",
    "start": "611850",
    "end": "615019"
  },
  {
    "text": "hello again thanks Sean so in this part of the webinar I would",
    "start": "618510",
    "end": "624519"
  },
  {
    "text": "like to delve deeper into how Citrix has correlated data across multiple data sources to drive deeper insights into",
    "start": "624519",
    "end": "632589"
  },
  {
    "text": "our data and build a stronger analytics platform the eventing system that Shawn",
    "start": "632589",
    "end": "639100"
  },
  {
    "text": "just demoed and talked about has been pumping data into our redshift databases and some of our tables over there have",
    "start": "639100",
    "end": "647529"
  },
  {
    "text": "upwards of a billion records for instance one of the main tables we have is the file stable and the files table",
    "start": "647529",
    "end": "655959"
  },
  {
    "text": "has data coming from events around file operations and this would be copy move",
    "start": "655959",
    "end": "662160"
  },
  {
    "text": "deletes shares uploads downloads and another example would be the sessions",
    "start": "662160",
    "end": "668740"
  },
  {
    "text": "table and this is information around user logins log as the IP that the",
    "start": "668740",
    "end": "674529"
  },
  {
    "text": "session came from all of that good information and the data that we have",
    "start": "674529",
    "end": "680230"
  },
  {
    "text": "from the system has been great we've been able to drive a lot of analytics metrics and the metrics are both",
    "start": "680230",
    "end": "687550"
  },
  {
    "text": "real-time because be able to talk about a point in time that a particular event",
    "start": "687550",
    "end": "693279"
  },
  {
    "text": "is happening and we are also able to look at it over a period of time however",
    "start": "693279",
    "end": "699190"
  },
  {
    "text": "as we started presenting these reports to our end users we started being asked",
    "start": "699190",
    "end": "706329"
  },
  {
    "text": "questions that clearly needed an extra dimension of data for instance well we",
    "start": "706329",
    "end": "711910"
  },
  {
    "text": "could tell how often a user had logged in over the past quarter and what times we didn't have the data to tell what the",
    "start": "711910",
    "end": "719019"
  },
  {
    "text": "first name or the last name or where the user had logged in from be could not put",
    "start": "719019",
    "end": "725290"
  },
  {
    "text": "that data together now we do have the data it's just outside of redshift it's",
    "start": "725290",
    "end": "730779"
  },
  {
    "text": "not relational database systems in our sales databases in our reporting databases and we had to find a way to",
    "start": "730779",
    "end": "738130"
  },
  {
    "text": "bring this all in to redshift correlate them and then build analytics off of multiple data sources",
    "start": "738130",
    "end": "746670"
  },
  {
    "text": "so how do we go about doing this as part",
    "start": "749140",
    "end": "754640"
  },
  {
    "text": "of iteration one we decided to build a workflow to get the data in using exercise now the database systems that I",
    "start": "754640",
    "end": "761510"
  },
  {
    "text": "just talked about rely heavily on sequel technologies so exercise was the national choice for us we had deep",
    "start": "761510",
    "end": "768470"
  },
  {
    "text": "technical knowledge there and we knew we could use the database team and myself for the most part to build this together",
    "start": "768470",
    "end": "774680"
  },
  {
    "text": "so the package that we first built aggregated data from our database system",
    "start": "774680",
    "end": "780740"
  },
  {
    "text": "a database system is a multi-tenant horizontally charted system which now",
    "start": "780740",
    "end": "787520"
  },
  {
    "text": "has I want to say about thirty five databases so we had to aggregate the data from all of these databases",
    "start": "787520",
    "end": "793750"
  },
  {
    "text": "transform the data write it out into CSV files and then we built in our the",
    "start": "793750",
    "end": "798860"
  },
  {
    "text": "process that would move the CSV files into s3 buckets and then eventually the",
    "start": "798860",
    "end": "804350"
  },
  {
    "text": "copy command from redshift to upload them in as you can tell this is a fairly",
    "start": "804350",
    "end": "809870"
  },
  {
    "text": "cumbersome process multiple moving case pieces which means higher maintenance",
    "start": "809870",
    "end": "815060"
  },
  {
    "text": "costs also the fact that we needed our",
    "start": "815060",
    "end": "820370"
  },
  {
    "text": "team to build this out now the database team is heavily involved in other tasks as well so this increased our load and",
    "start": "820370",
    "end": "828070"
  },
  {
    "text": "we knew that this wasn't necessarily scalable especially as each workflow",
    "start": "828070",
    "end": "833180"
  },
  {
    "text": "took upwards of off of a few days even up to a week to build which meant that",
    "start": "833180",
    "end": "838700"
  },
  {
    "text": "every time and an analyst asked for a table to be brought in that was a week",
    "start": "838700",
    "end": "844550"
  },
  {
    "text": "of dedicated database engineer time lastly the workflows ran on our ETL",
    "start": "844550",
    "end": "850310"
  },
  {
    "text": "servers which increased load on our sequel server systems so we knew we had",
    "start": "850310",
    "end": "856220"
  },
  {
    "text": "to find a better way to build our workflows",
    "start": "856220",
    "end": "860410"
  },
  {
    "text": "so has we researched into products that are available we came upon",
    "start": "861900",
    "end": "867140"
  },
  {
    "text": "metallian metallian was easy to procure from the AWS marketplace and we had deployed and running in a couple of",
    "start": "867140",
    "end": "873440"
  },
  {
    "text": "hours the next step was to build a proofs concept to determine if methylene",
    "start": "873440",
    "end": "878570"
  },
  {
    "text": "was the right solution for us now metallian has out-of-the-box support to",
    "start": "878570",
    "end": "884030"
  },
  {
    "text": "move data into redshift it provides four components that we are able to easily",
    "start": "884030",
    "end": "890060"
  },
  {
    "text": "configure in fact we found that using just one component out there we could",
    "start": "890060",
    "end": "896210"
  },
  {
    "text": "set our source database string our connection string there set the",
    "start": "896210",
    "end": "902060"
  },
  {
    "text": "destination table that we wanted the data into put together a really quick script and this was a transformation",
    "start": "902060",
    "end": "908300"
  },
  {
    "text": "script and we had data loading into redshift so essentially a proof-of-concept itself took took a few",
    "start": "908300",
    "end": "915230"
  },
  {
    "text": "hours I want to say no more than a day to build out so we knew we were on the right path here I also found that as I",
    "start": "915230",
    "end": "922730"
  },
  {
    "text": "configured the components that they were very intuitive it's a visual and to interface and well it's great to be able",
    "start": "922730",
    "end": "929480"
  },
  {
    "text": "to have sequel skills to write out the scripts a non sequel user would be just as comfortable with metal Ian to put",
    "start": "929480",
    "end": "935600"
  },
  {
    "text": "together in fact we now have our marketing team and sales team using",
    "start": "935600",
    "end": "941210"
  },
  {
    "text": "messaging as well Andy very recently built out integrations are with Marketo",
    "start": "941210",
    "end": "948130"
  },
  {
    "text": "so all in all metal ian has been a great success for us methylenes also a ELT",
    "start": "948130",
    "end": "954650"
  },
  {
    "text": "tool which means all the transformations run on redshift which implies that our",
    "start": "954650",
    "end": "959870"
  },
  {
    "text": "ETL servers no longer have to do the transformations on them troubleshooting",
    "start": "959870",
    "end": "966800"
  },
  {
    "text": "is easy the visual interface really helps us to zero in on issues pretty quickly and we have started leveraging",
    "start": "966800",
    "end": "974180"
  },
  {
    "text": "metal Ian to build out our custom reports we've been able to write out the",
    "start": "974180",
    "end": "979820"
  },
  {
    "text": "workflows to the point where once we generate the report we are able to upload it into a share file our folder",
    "start": "979820",
    "end": "987560"
  },
  {
    "text": "for the user and this user is then able to securely access that report we",
    "start": "987560",
    "end": "993379"
  },
  {
    "text": "possible doubt sqs messages for error loading and logging as well so the",
    "start": "993379",
    "end": "1001869"
  },
  {
    "text": "results speak for themselves but metallian we've been able to load millions of rows of data into redshift",
    "start": "1001869",
    "end": "1008109"
  },
  {
    "text": "in minutes it's greatly increased our efficiency and agility and we're now",
    "start": "1008109",
    "end": "1013179"
  },
  {
    "text": "able to gather call it collate and analyze user data faster than ever before",
    "start": "1013179",
    "end": "1018399"
  },
  {
    "text": "and at a much granular level I'd like to I'd like to quickly talk to a couple",
    "start": "1018399",
    "end": "1025798"
  },
  {
    "text": "reports that we have here the first one here is the account active use I thought",
    "start": "1025799",
    "end": "1031480"
  },
  {
    "text": "we had the eventing system and our data coming in from our other data sources we",
    "start": "1031480",
    "end": "1037029"
  },
  {
    "text": "really defined active views to be when a user logged in logged out and ever done",
    "start": "1037029",
    "end": "1042548"
  },
  {
    "text": "but we've not since been able to widen that definition to talk about not just",
    "start": "1042549",
    "end": "1049450"
  },
  {
    "text": "when a user logged in or log out but how they intentionally used our system on",
    "start": "1049450",
    "end": "1055029"
  },
  {
    "text": "the upper left corner here you see data that's very relational and that came in",
    "start": "1055029",
    "end": "1061779"
  },
  {
    "text": "straight from our relational source and the rest of the slides have data coming",
    "start": "1061779",
    "end": "1067059"
  },
  {
    "text": "in from multiple sources",
    "start": "1067059",
    "end": "1070620"
  },
  {
    "text": "the next slide here is partner usage and again on the upper left corner relational data on the right you can see",
    "start": "1072090",
    "end": "1079230"
  },
  {
    "text": "that it's been it's correlated data its partners by industry so the events are coming from my event system and the rest",
    "start": "1079230",
    "end": "1086520"
  },
  {
    "text": "of the data is coming from our relational and and some sales data as well they're the graphs below are are",
    "start": "1086520",
    "end": "1096179"
  },
  {
    "text": "all eventing data this is one of my favorite slides this",
    "start": "1096179",
    "end": "1104280"
  },
  {
    "text": "particular dashboard was built as a request from our product management team",
    "start": "1104280",
    "end": "1110460"
  },
  {
    "text": "a product management team was looking into visible visibility to see how a",
    "start": "1110460",
    "end": "1117060"
  },
  {
    "text": "feature that was just released performed essentially they wanted to know how the feature was being adopted and how it was",
    "start": "1117060",
    "end": "1123510"
  },
  {
    "text": "used by users and by having our eventing system bringing data in as well as our",
    "start": "1123510",
    "end": "1129390"
  },
  {
    "text": "relational system talking about the names of the tools and all of that information we're able to show here how",
    "start": "1129390",
    "end": "1135410"
  },
  {
    "text": "users have been logging into our system the different color codes talked about",
    "start": "1135410",
    "end": "1140460"
  },
  {
    "text": "the tools they use to access our system this has been great because we've been able to make our features more robust",
    "start": "1140460",
    "end": "1148320"
  },
  {
    "text": "our based on user demand and we've also been able to look at features that could potentially be deprecated because",
    "start": "1148320",
    "end": "1154200"
  },
  {
    "text": "they're not used as much as part of it being used",
    "start": "1154200",
    "end": "1159470"
  },
  {
    "text": "the last slide I have here is really numbers data transform to date we're",
    "start": "1160520",
    "end": "1166970"
  },
  {
    "text": "looking at 1.2 billion data moved is 20 million and honestly this increases on a",
    "start": "1166970",
    "end": "1172850"
  },
  {
    "text": "daily basis as we bring in more workflows our future plans involve are",
    "start": "1172850",
    "end": "1178490"
  },
  {
    "text": "moving all reporting to redshift and this would be all of our application reporting that we now have running on",
    "start": "1178490",
    "end": "1183500"
  },
  {
    "text": "our application to integrated it with redshift and then presented",
    "start": "1183500",
    "end": "1189520"
  },
  {
    "text": "and with that I would like to hand it over to Ed Thompson CTO of mitoan",
    "start": "1189520",
    "end": "1197580"
  },
  {
    "text": "very much so everybody yes I'm just going to give you a brief interruption",
    "start": "1199690",
    "end": "1206000"
  },
  {
    "text": "and then we'll dive into a quick demo just to give give everyone a little bit",
    "start": "1206000",
    "end": "1211700"
  },
  {
    "text": "feel for material she has given a great introduction to the product and the",
    "start": "1211700",
    "end": "1217640"
  },
  {
    "text": "success that Citrix had with it so I'm going to kind of expand on that with the",
    "start": "1217640",
    "end": "1224960"
  },
  {
    "text": "key sort of differentiators form experience forma Tilian is primarily an",
    "start": "1224960",
    "end": "1233270"
  },
  {
    "text": "ELT tool and all that essentially means is we push down all the transformation",
    "start": "1233270",
    "end": "1241070"
  },
  {
    "text": "work we do on to the underlying redshift server red ship all ships spectrum is",
    "start": "1241070",
    "end": "1250520"
  },
  {
    "text": "doing the underlying transformation work which means you get all the advantages of the scalability and compact price",
    "start": "1250520",
    "end": "1258470"
  },
  {
    "text": "competitiveness of that platform or to",
    "start": "1258470",
    "end": "1263600"
  },
  {
    "text": "perform the kinds of transformations that you would build in any ezl tool a lot of ETL tools now recognize this and",
    "start": "1263600",
    "end": "1271580"
  },
  {
    "text": "all have ELT features but mozillian is always built from the ground up as an",
    "start": "1271580",
    "end": "1277820"
  },
  {
    "text": "ELT tool primarily what that means is it's built specifically for the",
    "start": "1277820",
    "end": "1285800"
  },
  {
    "text": "underlying platform so the - liam's not generalists - built to allow you to do",
    "start": "1285800",
    "end": "1291500"
  },
  {
    "text": "ETL on any database it's built specifically for redshift and redshift",
    "start": "1291500",
    "end": "1296660"
  },
  {
    "text": "spectrum and that means that we always follow the redshift best practice it's",
    "start": "1296660",
    "end": "1302330"
  },
  {
    "text": "not up to the users to do that the ELT approved you gives you fantastic speed",
    "start": "1302330",
    "end": "1307750"
  },
  {
    "text": "because you're leveraging the earth the underlying source power of that cloud based based warehouse it also allows us",
    "start": "1307750",
    "end": "1315380"
  },
  {
    "text": "to build greater simplicity into the tool ultimately the tool is built around",
    "start": "1315380",
    "end": "1322610"
  },
  {
    "text": "SQL so anyone that's sort of familiar with SQL is going to get on great with",
    "start": "1322610",
    "end": "1330230"
  },
  {
    "text": "the tool but also if you're if you a relative SQL novice metallian will do",
    "start": "1330230",
    "end": "1336929"
  },
  {
    "text": "a lot of the heavy lifting for you similarly when it comes to getting data into your redshift data warehouse we",
    "start": "1336929",
    "end": "1344730"
  },
  {
    "text": "have taken great strides in making that whole process as easy as possible and",
    "start": "1344730",
    "end": "1351320"
  },
  {
    "text": "finally the scalability of course scalability is inherent in the scalability of red shift register",
    "start": "1351320",
    "end": "1357750"
  },
  {
    "text": "extremely scalable platform and you know anybody wanting to build a small Basel",
    "start": "1357750",
    "end": "1364049"
  },
  {
    "text": "warehouse right rooms and multiple terabytes multiple petabytes read data",
    "start": "1364049",
    "end": "1369090"
  },
  {
    "text": "they can scale a redshift platform appropriately and also grow their redshift has as their data volume grows",
    "start": "1369090",
    "end": "1377429"
  },
  {
    "text": "and that's exactly what situated a",
    "start": "1377429",
    "end": "1381620"
  },
  {
    "text": "metallian engine the sheer mentioned is available on the AWS marketplace with a",
    "start": "1382940",
    "end": "1390840"
  },
  {
    "text": "highest rated product on the AWS marketplace it delivers into your own AWS account as",
    "start": "1390840",
    "end": "1396840"
  },
  {
    "text": "an ami so we're not a pure static product or anything like that and the",
    "start": "1396840",
    "end": "1402510"
  },
  {
    "text": "long thing about that is it means that customers are always in control of where their data is getting always lives",
    "start": "1402510",
    "end": "1408750"
  },
  {
    "text": "inside their own Amazon infrastructure we're not producing any data on customers behalf it's not not supposed",
    "start": "1408750",
    "end": "1416340"
  },
  {
    "text": "to 90 percent of our customers say that refers to a friend's and I've just got",
    "start": "1416340",
    "end": "1423299"
  },
  {
    "text": "one customer quote on there if you want to see more great customer quotes take a",
    "start": "1423299",
    "end": "1428549"
  },
  {
    "text": "look at the reviews on iOS marketplace page cuz of the way WS marketplace works",
    "start": "1428549",
    "end": "1435210"
  },
  {
    "text": "you can essentially be up and running and starting to build ETL processes in",
    "start": "1435210",
    "end": "1440490"
  },
  {
    "text": "five minutes let's jump over to a demo very quickly and I'll just going to show",
    "start": "1440490",
    "end": "1445590"
  },
  {
    "text": "you the tool give your feel for the capabilities screen share Garen here",
    "start": "1445590",
    "end": "1453650"
  },
  {
    "text": "okay excellent so you should be seeing my screen now saw some little criminal",
    "start": "1455090",
    "end": "1460110"
  },
  {
    "text": "shelter bit but not and will that we'll take a quick look at the detailing down",
    "start": "1460110",
    "end": "1466830"
  },
  {
    "text": "knocking out Harriet enlisted limited in ETL tool itself actually the browser-based easy outsource first of",
    "start": "1466830",
    "end": "1473460"
  },
  {
    "text": "all nothing to download and so on to your local desktop machines anything",
    "start": "1473460",
    "end": "1478950"
  },
  {
    "text": "like that if you've got a team or small team of ETL developers data scientists",
    "start": "1478950",
    "end": "1485990"
  },
  {
    "text": "as she said people working in it with data and marketing they can just point",
    "start": "1485990",
    "end": "1492899"
  },
  {
    "text": "their web browser to an ETL instance and immediately be inside those ETL projects",
    "start": "1492899",
    "end": "1498450"
  },
  {
    "text": "getting get it so this on the screen",
    "start": "1498450",
    "end": "1504510"
  },
  {
    "text": "here is an example of a data transformation inside mix of the ETL and this is kind of the bread and butter of",
    "start": "1504510",
    "end": "1510809"
  },
  {
    "text": "the two Lissa's war customers spend most of their time working with building that",
    "start": "1510809",
    "end": "1518070"
  },
  {
    "text": "data transformation logic usually pulling together multiple based sources to create a single analytic ready data",
    "start": "1518070",
    "end": "1525750"
  },
  {
    "text": "set so here we have three data inputs so for those are inputs the orange squares",
    "start": "1525750",
    "end": "1533159"
  },
  {
    "text": "and then there's data output which is my analytic data output if I'm right click",
    "start": "1533159",
    "end": "1539429"
  },
  {
    "text": "and validate this job now what we'll see is you'll see that the borders on those",
    "start": "1539429",
    "end": "1544559"
  },
  {
    "text": "tiles going from grey to green that's the push down validation of where we",
    "start": "1544559",
    "end": "1552360"
  },
  {
    "text": "push down the validation on to the underlying that ship server this has lots of advantages when you're building",
    "start": "1552360",
    "end": "1558899"
  },
  {
    "text": "ETL processes and it's one of the things that makes the tool very easy to use",
    "start": "1558899",
    "end": "1564630"
  },
  {
    "text": "because you can see your mistakes as you go along because the validation that",
    "start": "1564630",
    "end": "1569760"
  },
  {
    "text": "comes back from redshift is very stripped which means that you encounter",
    "start": "1569760",
    "end": "1575039"
  },
  {
    "text": "problems straight away rather than you know building out big complex flow and",
    "start": "1575039",
    "end": "1580440"
  },
  {
    "text": "then spending you know minutes hours days debugging that flow and the other",
    "start": "1580440",
    "end": "1587220"
  },
  {
    "text": "thing that you can do in any LTS all like matil IAM is you can see what's going on at each and every stage of",
    "start": "1587220",
    "end": "1593460"
  },
  {
    "text": "musial process so I've got I have starting data's they're called flight",
    "start": "1593460",
    "end": "1598700"
  },
  {
    "text": "and that that's 123 million rows of data when we",
    "start": "1598700",
    "end": "1604110"
  },
  {
    "text": "sample that we can see it looks like this I then move on to the next step in",
    "start": "1604110",
    "end": "1609960"
  },
  {
    "text": "the process this is a filter this is just filtering down a flight of dataset",
    "start": "1609960",
    "end": "1614990"
  },
  {
    "text": "and we filter that down to 28 million rows and we can see we've got data from",
    "start": "1614990",
    "end": "1621770"
  },
  {
    "text": "the Year 2005 onwards once a year and",
    "start": "1621770",
    "end": "1627150"
  },
  {
    "text": "then then we apply some more filters and then here we've set up my flights data",
    "start": "1627150",
    "end": "1633600"
  },
  {
    "text": "and I want to embellish that with a another dataset which could have come from somewhere else not are they",
    "start": "1633600",
    "end": "1638730"
  },
  {
    "text": "describe how these data that got into the product second this is our planes data you can see it's not kind of plain",
    "start": "1638730",
    "end": "1646530"
  },
  {
    "text": "information like the manufacturer and the model and the air engine side and things like that we then bring those two",
    "start": "1646530",
    "end": "1653220"
  },
  {
    "text": "datasets together in to join this joins configured here you know bringing in the",
    "start": "1653220",
    "end": "1659940"
  },
  {
    "text": "main table joining it onto the flame table then we set up a joint expression in this and if you just an example this",
    "start": "1659940",
    "end": "1669990"
  },
  {
    "text": "is an SQL join expression but of course what we've done here is built an editor to make it really easy to see the bill",
    "start": "1669990",
    "end": "1676770"
  },
  {
    "text": "that joins as you can see I've got all of the fields that are available to",
    "start": "1676770",
    "end": "1682500"
  },
  {
    "text": "build the join and all of the functions that are available in redshift Kailas specifically to redshift to set",
    "start": "1682500",
    "end": "1688620"
  },
  {
    "text": "up that joy and then if I then go and sample that data at that point see how",
    "start": "1688620",
    "end": "1697049"
  },
  {
    "text": "many rows I'm working we're still working with 23 million versus data if we actually looked at the data itself",
    "start": "1697049",
    "end": "1703160"
  },
  {
    "text": "scrolling the right-hand side we can see that I've successfully joined those tail",
    "start": "1703160",
    "end": "1708630"
  },
  {
    "text": "number the manufacturing model etc on to my original dataset so as an ETL developer I know",
    "start": "1708630",
    "end": "1715770"
  },
  {
    "text": "immediately that my join has has connected at work and I can move on to",
    "start": "1715770",
    "end": "1723570"
  },
  {
    "text": "the next step in my ETL process all of the components in material are just set",
    "start": "1723570",
    "end": "1729720"
  },
  {
    "text": "up with this kind of property driven approach so you just configure the components as you get and in the end this will",
    "start": "1729720",
    "end": "1737560"
  },
  {
    "text": "process hundred twenty three million rows of data embellishing and joining all these three these three data tables",
    "start": "1737560",
    "end": "1745750"
  },
  {
    "text": "and then performing some calculations here we we join on a we work out the",
    "start": "1745750",
    "end": "1754120"
  },
  {
    "text": "delay ratio and then we use that staff flag to say if it's a long delay or",
    "start": "1754120",
    "end": "1760690"
  },
  {
    "text": "shorter we end up we end up with an output data set that is ready for",
    "start": "1760690",
    "end": "1767860"
  },
  {
    "text": "analysis so you can point your favorite data analysis tool be it something like",
    "start": "1767860",
    "end": "1773650"
  },
  {
    "text": "a quick site or looker or Pavlov's at this the output dataset in redshift and",
    "start": "1773650",
    "end": "1781030"
  },
  {
    "text": "start doing analytics straight away so that's the transformation 30 million",
    "start": "1781030",
    "end": "1786160"
  },
  {
    "text": "this is a very simple example these transformations can get much much more complicated than this much much more",
    "start": "1786160",
    "end": "1791860"
  },
  {
    "text": "sophisticated and but I'll also like to",
    "start": "1791860",
    "end": "1797770"
  },
  {
    "text": "show you is the orchestration side so that's really the overall ETL process",
    "start": "1797770",
    "end": "1804250"
  },
  {
    "text": "from start to finish including how we get the data interruptions in the first place and then what we can do around",
    "start": "1804250",
    "end": "1811960"
  },
  {
    "text": "that data processing that we've set up in the transformation so let's take a quick look at that so this is a",
    "start": "1811960",
    "end": "1819160"
  },
  {
    "text": "transformation job in Brasilia this kind of shows the whole eld process quite",
    "start": "1819160",
    "end": "1825850"
  },
  {
    "text": "nicely because here we have a starting point and this can kind of be read like a visual script so you can see the",
    "start": "1825850",
    "end": "1832780"
  },
  {
    "text": "process going along at the starting point we split out it's for parallel",
    "start": "1832780",
    "end": "1839110"
  },
  {
    "text": "flows for things happening at once here and we create for separate tables for",
    "start": "1839110",
    "end": "1845680"
  },
  {
    "text": "tables being created there and then we load some data this is deliberately kind",
    "start": "1845680",
    "end": "1850870"
  },
  {
    "text": "of showing off some of the different ways that data is loaded so first of all we have data being loaded from RDS which",
    "start": "1850870",
    "end": "1857950"
  },
  {
    "text": "is the Amazon relational database service but you can run up my SQL",
    "start": "1857950",
    "end": "1864490"
  },
  {
    "text": "Postgres or a sequel server database on we we have first-class connector",
    "start": "1864490",
    "end": "1871490"
  },
  {
    "text": "which will make it really easy just to pull data in and interrogate your AWS account pull back most of the connection",
    "start": "1871490",
    "end": "1877820"
  },
  {
    "text": "details by itself just asking for user a password or not you go here we pull some",
    "start": "1877820",
    "end": "1884150"
  },
  {
    "text": "data from a REST API julian has a REST API connected or connected just about any REST API so give my internal REST",
    "start": "1884150",
    "end": "1893630"
  },
  {
    "text": "API Zoar external systems that we don't already support by RS API it's really",
    "start": "1893630",
    "end": "1899030"
  },
  {
    "text": "easy to pull that data in pulling something from a spreadsheet because everybody has some spreadsheets in their",
    "start": "1899030",
    "end": "1904820"
  },
  {
    "text": "organization whether they like them or not in this case it's a Google sheet and then this is some data files that are in",
    "start": "1904820",
    "end": "1911390"
  },
  {
    "text": "s3 so a lot of organizations will have data you know already in s3 or landing",
    "start": "1911390",
    "end": "1917420"
  },
  {
    "text": "in s3 - another process so if we want to make it really easy to ingest data we've",
    "start": "1917420",
    "end": "1923690"
  },
  {
    "text": "got quite a lot of tools to make that easy as possible once we've got data loaded in we bring all that together",
    "start": "1923690",
    "end": "1931280"
  },
  {
    "text": "here all those four parallel flows are brought together in this and component and then we run our transformations so",
    "start": "1931280",
    "end": "1937880"
  },
  {
    "text": "that's kind of the create the tables load the data and then build all those transformations that we just saw with",
    "start": "1937880",
    "end": "1943610"
  },
  {
    "text": "the airport day - the plane data lines data and then after that we can move on",
    "start": "1943610",
    "end": "1950630"
  },
  {
    "text": "to some other stages in the process but a lot of the time we'll want to send out notifications I think she mentioned that",
    "start": "1950630",
    "end": "1956720"
  },
  {
    "text": "she was sending some notifications out by our SQL that's a really popular wedges to drop a message on to an SQL",
    "start": "1956720",
    "end": "1962570"
  },
  {
    "text": "user maybe initiates a mother / external process we can send out SMS messages",
    "start": "1962570",
    "end": "1968750"
  },
  {
    "text": "email notifications or any other messaging system are we going to print",
    "start": "1968750",
    "end": "1973940"
  },
  {
    "text": "directly to cloud watch so you can push them to watch card watch messages",
    "start": "1973940",
    "end": "1980680"
  },
  {
    "text": "alerting so you can see exactly how your ETL processes are running try watch and",
    "start": "1980680",
    "end": "1986030"
  },
  {
    "text": "then finally if you want to then take the data that's been processed in mozillian on somewhere else we can push",
    "start": "1986030",
    "end": "1995030"
  },
  {
    "text": "that data back into RDS for example with an RBS both output or we push that dated back out s3",
    "start": "1995030",
    "end": "2000950"
  },
  {
    "text": "that then might be picked up by some other system maybe you wanna do sir I feed this an AI model or do some data",
    "start": "2000950",
    "end": "2009080"
  },
  {
    "text": "ingestion from machine learning system whatever you need good quality prepped",
    "start": "2009080",
    "end": "2014240"
  },
  {
    "text": "analytic analytic ready data for the tool you can do that big thing inside we",
    "start": "2014240",
    "end": "2021679"
  },
  {
    "text": "have lots and lots of components and something always follow this sort of component driven approach which is",
    "start": "2021679",
    "end": "2027860"
  },
  {
    "text": "common for ETL tools but the big important connectors for the",
    "start": "2027860",
    "end": "2034549"
  },
  {
    "text": "orchestration silence or of course the data loading components so I'm just",
    "start": "2034549",
    "end": "2040490"
  },
  {
    "text": "going to open these real quick as you zoom in on them a little bit hopefully you'll see some some names of some",
    "start": "2040490",
    "end": "2047870"
  },
  {
    "text": "systems that you recognize but we have you know all sorts of CRM and marketing",
    "start": "2047870",
    "end": "2054770"
  },
  {
    "text": "systems Mixpanel NetSuite Marketo Salesforce obviously very popular",
    "start": "2054770",
    "end": "2060638"
  },
  {
    "text": "on-premise databases like Couchbase Cassandra we've got integrations",
    "start": "2060639",
    "end": "2067099"
  },
  {
    "text": "social networks various ERP systems spreadsheets a whole load of internet",
    "start": "2067099",
    "end": "2073158"
  },
  {
    "text": "circl things like elasticsearch gen so very popular YouTube as well and then",
    "start": "2073159",
    "end": "2079550"
  },
  {
    "text": "various financial system PayPal where stripe etc and then I'll have kind of",
    "start": "2079550",
    "end": "2086990"
  },
  {
    "text": "more generic ones like the database query would call any on-premise",
    "start": "2086990",
    "end": "2093970"
  },
  {
    "text": "relational database you can go you can",
    "start": "2093970",
    "end": "2099140"
  },
  {
    "text": "pull in with the database query components you've got things like sequel",
    "start": "2099140",
    "end": "2104900"
  },
  {
    "text": "server db2 MySQL Oracle etc so by",
    "start": "2104900",
    "end": "2112599"
  },
  {
    "text": "combining orchestrations and transformations you can you can you can",
    "start": "2112599",
    "end": "2119660"
  },
  {
    "text": "build out full fully featured fully functional ETL processes from end to end",
    "start": "2119660",
    "end": "2126040"
  },
  {
    "text": "literal you know populate data warehousing whatever whatever data transformation or data migration tasks",
    "start": "2126040",
    "end": "2133190"
  },
  {
    "text": "you want it before on top of friendship pushing down all that underlying processing on to shift instance and then",
    "start": "2133190",
    "end": "2143569"
  },
  {
    "text": "the final sort of things that are in the tool are really important we have things like version control built in obviously",
    "start": "2143569",
    "end": "2150890"
  },
  {
    "text": "there's a scheduler built into the tool and API for starting jobs then we've got",
    "start": "2150890",
    "end": "2157730"
  },
  {
    "text": "sort of full user and permission management whole loads of sort of a lot of the nice",
    "start": "2157730",
    "end": "2163310"
  },
  {
    "text": "features that you want to build around your ETL tool particularly in an enterprise organization a lot of",
    "start": "2163310",
    "end": "2169790"
  },
  {
    "text": "different people different level access centralized control and administration of ETL detailed processes and the ETL",
    "start": "2169790",
    "end": "2178819"
  },
  {
    "text": "pipelines I also be able to version control them across multiple instances and have dev",
    "start": "2178819",
    "end": "2185060"
  },
  {
    "text": "test arise it's like that so the whole load more which we can perhaps go into a",
    "start": "2185060",
    "end": "2190670"
  },
  {
    "text": "little bit more detail at a later date but hopefully that gives you a little bit of a flavor of maternity CL and I",
    "start": "2190670",
    "end": "2198950"
  },
  {
    "text": "think at that point we'll go back to the slides of Asura",
    "start": "2198950",
    "end": "2204339"
  },
  {
    "text": "probably so sort of information about metallian you can read ship sorry you",
    "start": "2211839",
    "end": "2217190"
  },
  {
    "text": "can find here I think I probably meant to be handing back to that AWS this would let somebody else take over Edie",
    "start": "2217190",
    "end": "2227000"
  },
  {
    "text": "Shawn she had really really great information fantastic presentation I",
    "start": "2227000",
    "end": "2232220"
  },
  {
    "text": "thought it was really really great I have to say we've got a great group of",
    "start": "2232220",
    "end": "2237740"
  },
  {
    "text": "participants this day and quite a lot of great questions so I'd love to get to",
    "start": "2237740",
    "end": "2242750"
  },
  {
    "text": "those right away so hopefully you guys are all off mute let's see if we can't",
    "start": "2242750",
    "end": "2248569"
  },
  {
    "text": "get through as many as we can before we run out of time Citrix first what message bus did you",
    "start": "2248569",
    "end": "2255200"
  },
  {
    "text": "use in implementation it's it's rabbitmq managed with their own hops automation",
    "start": "2255200",
    "end": "2265150"
  },
  {
    "text": "using sqs as well but for this particular kind of bus rabbit works",
    "start": "2265210",
    "end": "2270770"
  },
  {
    "text": "really well and then I think we answered this question already but the question",
    "start": "2270770",
    "end": "2276470"
  },
  {
    "text": "was in what ways can you connect to an Oracle on-prem database and I believe",
    "start": "2276470",
    "end": "2281810"
  },
  {
    "text": "that was through the ODBC JDBC connector",
    "start": "2281810",
    "end": "2286690"
  },
  {
    "text": "that sounds like a question for me yes until Ian uses a JDBC connection to",
    "start": "2287800",
    "end": "2295520"
  },
  {
    "text": "connect to Oracle and when Mattila ninjetta beta into redshift it follows kind of",
    "start": "2295520",
    "end": "2304280"
  },
  {
    "text": "the best practice route for doing that so it will actually load that data into",
    "start": "2304280",
    "end": "2311140"
  },
  {
    "text": "into s3 and then it will do one of two things in kind of normal mode if you",
    "start": "2311140",
    "end": "2318109"
  },
  {
    "text": "like it we issue the copy command to load that data into redshift and that",
    "start": "2318109",
    "end": "2323810"
  },
  {
    "text": "whole process is is very very fast both these the loading to s3 and the",
    "start": "2323810",
    "end": "2330380"
  },
  {
    "text": "data ingestion you do also have the option if you're if you want to take",
    "start": "2330380",
    "end": "2335599"
  },
  {
    "text": "advantage of redshift spectrum be using what we call external most which is just a switch on the",
    "start": "2335599",
    "end": "2341819"
  },
  {
    "text": "component and that will actually leave the date sets in s3 but create an",
    "start": "2341819",
    "end": "2347099"
  },
  {
    "text": "external table definition in redshift so that you can query that data directly on",
    "start": "2347099",
    "end": "2352109"
  },
  {
    "text": "s3 without ingesting it without using your disk space inside your red chip",
    "start": "2352109",
    "end": "2358890"
  },
  {
    "text": "cluster if you want to excellent the",
    "start": "2358890",
    "end": "2364529"
  },
  {
    "text": "next question the gamers were cedric's could you give us any examples of the",
    "start": "2364529",
    "end": "2369719"
  },
  {
    "text": "types of transformations you've built using this LT process I can take that",
    "start": "2369719",
    "end": "2376709"
  },
  {
    "text": "idea so the transformations are of two kinds",
    "start": "2376709",
    "end": "2384749"
  },
  {
    "text": "that we've been building so far the first set of transformations involves moving data from our data sources into",
    "start": "2384749",
    "end": "2391920"
  },
  {
    "text": "redshift tables and and once it's in redshift we have further cleansed it if need be",
    "start": "2391920",
    "end": "2400140"
  },
  {
    "text": "mostly there hasn't been much of a need for that but the transformation has certainly happened over there and then",
    "start": "2400140",
    "end": "2406319"
  },
  {
    "text": "we aggregate the data with eventing data usually it's some kind of roll-up",
    "start": "2406319",
    "end": "2412589"
  },
  {
    "text": "summary kind of thing that we build and apply the data coming in from our oil TP",
    "start": "2412589",
    "end": "2418890"
  },
  {
    "text": "data resource is almost like a relational dimension to our fact event",
    "start": "2418890",
    "end": "2424769"
  },
  {
    "text": "tables and use that to populate final tables we then have tableau sitting on",
    "start": "2424769",
    "end": "2431940"
  },
  {
    "text": "top of this to visualize the data into the reports that we want to put out how",
    "start": "2431940",
    "end": "2441089"
  },
  {
    "text": "are you handling up certs into redshift using Italian at this time we have not",
    "start": "2441089",
    "end": "2451130"
  },
  {
    "text": "done ups as yet most of our data has been either direct insert or delete and",
    "start": "2451130",
    "end": "2459839"
  },
  {
    "text": "replace okay I'll just expand on that a little bit but if I may so matil Ian as",
    "start": "2459839",
    "end": "2469229"
  },
  {
    "text": "a tool gives you we have a database update component that you can",
    "start": "2469229",
    "end": "2475350"
  },
  {
    "text": "use at the end of transformation that has two modes that has a a update mode",
    "start": "2475350",
    "end": "2483150"
  },
  {
    "text": "which does a DML bulk updates or you can",
    "start": "2483150",
    "end": "2489030"
  },
  {
    "text": "run it in delete insert mode which will within a transactions delete matching",
    "start": "2489030",
    "end": "2495180"
  },
  {
    "text": "rows and then reinsert those rows for updates so usually the latter of those",
    "start": "2495180",
    "end": "2503220"
  },
  {
    "text": "two is the most performant but it really depends on exactly what you want to do",
    "start": "2503220",
    "end": "2509670"
  },
  {
    "text": "or what you expect if you're doing with the data that makes a lot of sense",
    "start": "2509670",
    "end": "2517640"
  },
  {
    "text": "question view Ed's dollar are the transformations from Italian bats",
    "start": "2517850",
    "end": "2523110"
  },
  {
    "text": "microbats real-time what we're kind of options do you have so insulin is is a batch focused tool",
    "start": "2523110",
    "end": "2531260"
  },
  {
    "text": "but it's very much designed to work in a in a micro batch way as well as a kind",
    "start": "2531260",
    "end": "2539940"
  },
  {
    "text": "of a macro batch that's such a thing so what I mean by that a lot of customers",
    "start": "2539940",
    "end": "2546540"
  },
  {
    "text": "will work on micro batches and data either on a kind of a kind' basis so you",
    "start": "2546540",
    "end": "2554070"
  },
  {
    "text": "know every few seconds or a couple of minutes or more often on kind of a data",
    "start": "2554070",
    "end": "2561960"
  },
  {
    "text": "landing basis so every time I add data set lands in s3 that will one of the way",
    "start": "2561960",
    "end": "2569310"
  },
  {
    "text": "that I didn't mention that you can initiate an ETL process in mozillian is via sqf message so you can set up",
    "start": "2569310",
    "end": "2575520"
  },
  {
    "text": "material and couple of clicks and listen on s USQ and wait for a specific formatting message and then it will pick",
    "start": "2575520",
    "end": "2583080"
  },
  {
    "text": "up a process with some parameters at that point that's the way to set up a micro batch and you can do that every",
    "start": "2583080",
    "end": "2590250"
  },
  {
    "text": "time a file lands on s3 it can fire an sqs message and initiate mozillian to",
    "start": "2590250",
    "end": "2597290"
  },
  {
    "text": "just process that file that's a very efficient way of doing of doing micro",
    "start": "2597290",
    "end": "2602970"
  },
  {
    "text": "batching immaturely yeah that's a current there's a few questions in this space",
    "start": "2602970",
    "end": "2609220"
  },
  {
    "text": "all I'll kind of generalize them the question is is matil iam ec2 instances",
    "start": "2609220",
    "end": "2614950"
  },
  {
    "text": "being used for all of the joins all the functions or are you able to push any of the workloads down to places like",
    "start": "2614950",
    "end": "2621760"
  },
  {
    "text": "spectrum or or redshift the direct processing yeah great question so it's",
    "start": "2621760",
    "end": "2629170"
  },
  {
    "text": "all being pushed down so you know our mantra and Mazzilli knows we're lazy and",
    "start": "2629170",
    "end": "2635410"
  },
  {
    "text": "we don't want to do work that's not a reflection on earth that's a reflection on the tool it wants to push down the",
    "start": "2635410",
    "end": "2641650"
  },
  {
    "text": "work that it does on to the underlying platforms that Amazon provides that",
    "start": "2641650",
    "end": "2647560"
  },
  {
    "text": "Amazon's providing these fantastic scalable platforms and it's not just red shift but red shift very much sits at",
    "start": "2647560",
    "end": "2653560"
  },
  {
    "text": "the core of the products its spectrum its sqf its cloud logically destory it's",
    "start": "2653560",
    "end": "2662130"
  },
  {
    "text": "in the future we'll be looking very heavily social things like containers lambda functions all of these are very",
    "start": "2662130",
    "end": "2669610"
  },
  {
    "text": "reliable as scale very well for the user so we will use those so wherever",
    "start": "2669610",
    "end": "2676360"
  },
  {
    "text": "possible we don't do any work on the material instance in a normal customer",
    "start": "2676360",
    "end": "2682600"
  },
  {
    "text": "scenario the Mitylene instance should be basically idle it's just acting as an",
    "start": "2682600",
    "end": "2687610"
  },
  {
    "text": "Orchestrator and a coordinator of the best-of-breed AWS services",
    "start": "2687610",
    "end": "2694770"
  },
  {
    "text": "right right questions Aiki talk about HIPAA compliance and and how metallian",
    "start": "2695170",
    "end": "2701050"
  },
  {
    "text": "can help deal with pH I and PII data especially given the recent GDR announcements",
    "start": "2701050",
    "end": "2707430"
  },
  {
    "text": "yeah that's great question two so HIPAA compliance is is a work in progress for",
    "start": "2707430",
    "end": "2713650"
  },
  {
    "text": "us because we're not a fast service that puts us in a in a in a strong position",
    "start": "2713650",
    "end": "2721390"
  },
  {
    "text": "because the product is kind of almost a piece of software that's delivered into",
    "start": "2721390",
    "end": "2727540"
  },
  {
    "text": "your Amazon V PC and is controlled by you however right now the product isn't",
    "start": "2727540",
    "end": "2735940"
  },
  {
    "text": "HIPAA compliant in its own right yet we're working on that",
    "start": "2735940",
    "end": "2741810"
  },
  {
    "text": "kind of question zoomy has an IBM AIX wants to know if they can connect to the",
    "start": "2745609",
    "end": "2753000"
  },
  {
    "text": "Oracle databases in IBM AIX and migrate data in videos what's the was the best",
    "start": "2753000",
    "end": "2758960"
  },
  {
    "text": "process to use for bringing that data in or near real-time as possible yes so for",
    "start": "2758960",
    "end": "2768020"
  },
  {
    "text": "Oracle on AIX my understanding is and then you know there may be some caveats",
    "start": "2768020",
    "end": "2773520"
  },
  {
    "text": "I'm not on AIX expert so my understanding is you'll be able to access that data via JDBC and the best",
    "start": "2773520",
    "end": "2785579"
  },
  {
    "text": "way to deal with that right now and it kind of a would be in a couple micro batch scenario if you've got things like",
    "start": "2785579",
    "end": "2792390"
  },
  {
    "text": "reliable updated dates on the major tables that you want to pull in the",
    "start": "2792390",
    "end": "2797520"
  },
  {
    "text": "Tilian will be releasing over the course of the summer a CDC version of the",
    "start": "2797520",
    "end": "2806579"
  },
  {
    "text": "product that will work with Oracle on all platforms that will essentially turn",
    "start": "2806579",
    "end": "2814250"
  },
  {
    "text": "those data would will turn the data changes into streams that will then",
    "start": "2814250",
    "end": "2821310"
  },
  {
    "text": "micro batching process as as streaming data but yeah right now you can just",
    "start": "2821310",
    "end": "2829859"
  },
  {
    "text": "query that Oracle data directly to pull into batch processes in between",
    "start": "2829859",
    "end": "2836240"
  },
  {
    "text": "all right perfect there's a question about CDC from source databases so it",
    "start": "2838900",
    "end": "2844059"
  },
  {
    "text": "sounds like that's coming soon question",
    "start": "2844059",
    "end": "2849760"
  },
  {
    "text": "questionnaires s3 always the staging layer for any workflow built from a Chilean",
    "start": "2849760",
    "end": "2855359"
  },
  {
    "text": "let's go just the question yes it is I'm",
    "start": "2856759",
    "end": "2861779"
  },
  {
    "text": "just guessing from a read between the lines I'm interested in the original question",
    "start": "2861779",
    "end": "2867839"
  },
  {
    "text": "but yes it is we always stage that data by RS 3 don't",
    "start": "2867839",
    "end": "2873029"
  },
  {
    "text": "forget that and that the school first class support in this result that David",
    "start": "2873029",
    "end": "2878699"
  },
  {
    "text": "can of course be encrypted using the kms encryption system in AWS if you're worried about the sort of sensitivity of",
    "start": "2878699",
    "end": "2885269"
  },
  {
    "text": "the data what we don't ever do is kind of do like DML inserts interruptions",
    "start": "2885269",
    "end": "2890999"
  },
  {
    "text": "kind of not not always designed to do really so yeah we always work to just match said the bowler question that is",
    "start": "2890999",
    "end": "2899400"
  },
  {
    "text": "is is how you handle spacing or planning for storage space on s3 for those",
    "start": "2899400",
    "end": "2906209"
  },
  {
    "text": "workflows so with us to really you know an s3",
    "start": "2906209",
    "end": "2914650"
  },
  {
    "text": "bucket is as far as I'm aware effectively can it and it infinite there",
    "start": "2914650",
    "end": "2920530"
  },
  {
    "text": "are some good sort of best practices and rules around how you insert data into s3",
    "start": "2920530",
    "end": "2927220"
  },
  {
    "text": "and how you kind of structure that storage particularly if you want to use spectrum and you want to use",
    "start": "2927220",
    "end": "2932290"
  },
  {
    "text": "partitioning in spectrum that's a great way of you know if you've got sort of",
    "start": "2932290",
    "end": "2938860"
  },
  {
    "text": "daily hourly data sets you can structure them like a month with I give dates",
    "start": "2938860",
    "end": "2944500"
  },
  {
    "text": "based directory structure and then partition the data like that and that can make some very efficient uses of",
    "start": "2944500",
    "end": "2951940"
  },
  {
    "text": "rush of spectrum but yeah in terms of quantity there's rules of best practices",
    "start": "2951940",
    "end": "2959770"
  },
  {
    "text": "around in the best way to split data up according to the size of your veggie pluster for the maximum ingestion speed",
    "start": "2959770",
    "end": "2967090"
  },
  {
    "text": "specifically with large data set that's really important in terms of kind of worrying about the size of those data",
    "start": "2967090",
    "end": "2974230"
  },
  {
    "text": "sets as far more where our customers don't really the",
    "start": "2974230",
    "end": "2980780"
  },
  {
    "text": "about some migrating elt jobs from dev to test the Pradhan barman's and cannot",
    "start": "2980780",
    "end": "2986600"
  },
  {
    "text": "be scheduled using a third-party scheduling tool yes it can",
    "start": "2986600",
    "end": "2992900"
  },
  {
    "text": "so assuming had a an API which covers",
    "start": "2992900",
    "end": "2998090"
  },
  {
    "text": "the full product and we've got some some basic screens which customers can take",
    "start": "2998090",
    "end": "3004540"
  },
  {
    "text": "one kind of run where then they tend to sort of done adjust them to their own",
    "start": "3004540",
    "end": "3010540"
  },
  {
    "text": "ends really but or you can just do it yourself but you can you can pull either",
    "start": "3010540",
    "end": "3017710"
  },
  {
    "text": "whole projects or individual jobs I'll check them into a central source control",
    "start": "3017710",
    "end": "3023920"
  },
  {
    "text": "management systems then if you've got a build system you can you can use that to push into us you know pre prod that",
    "start": "3023920",
    "end": "3031500"
  },
  {
    "text": "lifetime and however you want to do it but yeah all of that very much possible",
    "start": "3031500",
    "end": "3036690"
  },
  {
    "text": "all of the assets that material creates valuable PDF registers just something",
    "start": "3036690",
    "end": "3043720"
  },
  {
    "text": "documents that crazy to roll it great answers think that probably is great",
    "start": "3043720",
    "end": "3049570"
  },
  {
    "text": "these are great questions a great answer is AB is there any any transformation plug-in available for converting XML",
    "start": "3049570",
    "end": "3055570"
  },
  {
    "text": "messages to a flat structure yeah there is so the fuel caveat to it",
    "start": "3055570",
    "end": "3063160"
  },
  {
    "text": "so the best way to do that currently is with our API query component which is",
    "start": "3063160",
    "end": "3068920"
  },
  {
    "text": "designed to work with structured just Psalm and XML documents and those will",
    "start": "3068920",
    "end": "3076120"
  },
  {
    "text": "you know work up to varying levels of nesting in order to pull at extracts the",
    "start": "3076120",
    "end": "3083560"
  },
  {
    "text": "right kinds of features that you want out of that we'll be doing more we'll be",
    "start": "3083560",
    "end": "3092140"
  },
  {
    "text": "doing more around that because we'd like to take advantage of some of the",
    "start": "3092140",
    "end": "3098680"
  },
  {
    "text": "features of the glue platform in AWS to do some pre-processing of that kind of",
    "start": "3098680",
    "end": "3106270"
  },
  {
    "text": "structured data and one of the things that glue can do is relational eyes semi",
    "start": "3106270",
    "end": "3112330"
  },
  {
    "text": "structured data like JSON or XML into essentially a series of relational",
    "start": "3112330",
    "end": "3118150"
  },
  {
    "text": "tables that you can work with in a really easily that to align the Chilean",
    "start": "3118150",
    "end": "3124020"
  },
  {
    "text": "grid questions I think I'll take this one the last one because it's a good good one to end on what's the cost",
    "start": "3124020",
    "end": "3131470"
  },
  {
    "text": "structure how do you kind of get started using the Chilean yes a million is we",
    "start": "3131470",
    "end": "3138340"
  },
  {
    "text": "privileged took the kind of the Amazon model of cloud economics so mozillian",
    "start": "3138340",
    "end": "3143370"
  },
  {
    "text": "you paid for by the Alice just like AWS so some recent - I should stay and now",
    "start": "3143370",
    "end": "3153340"
  },
  {
    "text": "isn't it but yeah Amazon Basilian starts a $1 37 an hour but kind of that",
    "start": "3153340",
    "end": "3161200"
  },
  {
    "text": "throughout sort of what we describe as a medium instance type and yeah you pay",
    "start": "3161200",
    "end": "3168160"
  },
  {
    "text": "for the hour while the instance is running which means if you're developing ETL you need it running you're running",
    "start": "3168160",
    "end": "3174130"
  },
  {
    "text": "ETL Canadian running but you can turn it off the rest of the time so we have plenty of customers who don't run the",
    "start": "3174130",
    "end": "3181840"
  },
  {
    "text": "Tilian 24/7 if they have you know overnight batch jobs and things like that that's a perfectly reasonable use",
    "start": "3181840",
    "end": "3188290"
  },
  {
    "text": "case so yeah thanks ed so I want to I want to thank",
    "start": "3188290",
    "end": "3195550"
  },
  {
    "text": "one more time Shan Xie an ad for all the greats information that's right on the call I thank you everyone for attending",
    "start": "3195550",
    "end": "3202180"
  },
  {
    "text": "today's webinar we know you have other things that you're doing so taking time out of your day to join us is fantastic",
    "start": "3202180",
    "end": "3207490"
  },
  {
    "text": "please remember to stay connected and complete a brief survey at the end of this webinar look forward to supporting",
    "start": "3207490",
    "end": "3213550"
  },
  {
    "text": "you and your current and future endeavors thanks again and have a wonderful day - thanks Ryan thanks",
    "start": "3213550",
    "end": "3220210"
  },
  {
    "text": "everyone",
    "start": "3220210",
    "end": "3222420"
  }
]
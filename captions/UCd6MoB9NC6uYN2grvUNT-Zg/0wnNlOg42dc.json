[
  {
    "start": "0",
    "end": "37000"
  },
  {
    "text": "Hello and welcome to another episode of 'This is My Architecture'.\nI am Sonika, and today I have Abhinav from Spyne.ai.",
    "start": "6940",
    "end": "13447"
  },
  {
    "text": "- Hello Abhinav. Thank you for joining us.\n- Hi. Thanks for having me.",
    "start": "13447",
    "end": "17150"
  },
  {
    "text": "Abhinav, can you tell us a bit about Spyne.ai?",
    "start": "17150",
    "end": "20020"
  },
  {
    "text": "Yeah, so at Spyne, we are solving global internet cataloging\nwith computer vision at its core.",
    "start": "20020",
    "end": "25726"
  },
  {
    "text": "So we are using AI to help businesses shoot, edit, and publish\ntheir catalogs on marketplaces on scale at a fraction of cost and time.",
    "start": "25726",
    "end": "36403"
  },
  {
    "text": "Image processing, right?\nSo I assume these are like many images.",
    "start": "36403",
    "end": "39439"
  },
  {
    "text": "Can you talk about what scale are you dealing with?",
    "start": "39439",
    "end": "41475"
  },
  {
    "text": "Yeah, so we process around 100K images every day.",
    "start": "41475",
    "end": "45178"
  },
  {
    "text": "Okay and who are your users?\nWhat category do they belong?",
    "start": "45179",
    "end": "48582"
  },
  {
    "text": "So our product is used by 80+ enterprises globally\nin food, automobile, fashion, and retail industries.",
    "start": "48582",
    "end": "55689"
  },
  {
    "text": "Okay and let's say this one user uploads the images,\nhow does this platform help?",
    "start": "56156",
    "end": "61260"
  },
  {
    "start": "57000",
    "end": "91000"
  },
  {
    "text": "So users can upload images from a lot of sources\nlike SDK, APIs, our application, as well as web.",
    "start": "61662",
    "end": "69970"
  },
  {
    "text": "Once we get the images they are passed on\nto our gateway, that's where the images come from,",
    "start": "69970",
    "end": "77177"
  },
  {
    "text": "and appropriately pass it to the Application Load Balancer\nwhere we decide, on the basis of the category of the image",
    "start": "77177",
    "end": "84685"
  },
  {
    "text": "and how exactly it is to be processed,\non which ECS cluster would this image go through.",
    "start": "84685",
    "end": "90423"
  },
  {
    "text": "Okay, can you tell a tell us a bit more on the ECS cluster\nbecause you spoke about multiple categories, right?",
    "start": "91058",
    "end": "97297"
  },
  {
    "text": "Yeah, so every image comes with a lot of processing parameters\nand metadata and how exactly will the image be processed.",
    "start": "97297",
    "end": "107840"
  },
  {
    "text": "Okay? So once it gets to ECS we save the parameters and metadata\nto our RDS as well and our RDS actually powers our dashboard",
    "start": "107841",
    "end": "117951"
  },
  {
    "text": "where users can go view their catalogs\nas well as download them.",
    "start": "117951",
    "end": "122322"
  },
  {
    "start": "123000",
    "end": "137000"
  },
  {
    "text": "Okay, so once the category is done,\nwhat do you do next?",
    "start": "123190",
    "end": "128028"
  },
  {
    "text": "Okay, once we have all the info about the image - \nhow exactly it will be processed..",
    "start": "128529",
    "end": "133166"
  },
  {
    "text": "We push those images to their appropriate queues.",
    "start": "133166",
    "end": "136503"
  },
  {
    "text": "Okay, and once the category is decided,\nthe image moves to the appropriate queue, how do you process those images?",
    "start": "136503",
    "end": "142843"
  },
  {
    "start": "137000",
    "end": "161000"
  },
  {
    "text": "Okay, now we know what sort of model\nthat image would go through",
    "start": "142843",
    "end": "148081"
  },
  {
    "text": "and what sort of CPU middleware\nwould that image go through to have that sort of output.",
    "start": "148081",
    "end": "153286"
  },
  {
    "text": "So, then from SQS that image\nis consumed by the appropriate AI service.",
    "start": "153287",
    "end": "160661"
  },
  {
    "text": "- Okay, which means the processing layer?\n- Exactly.",
    "start": "160661",
    "end": "163864"
  },
  {
    "start": "161000",
    "end": "195000"
  },
  {
    "text": "So these instances...\nwhat are you exactly doing at this processing layer?",
    "start": "163864",
    "end": "168602"
  },
  {
    "text": "So we have divided the processing pipeline\ninto three major categories.",
    "start": "168602",
    "end": "172372"
  },
  {
    "text": "It's 'Pre',",
    "start": "172706",
    "end": "174174"
  },
  {
    "text": "'Infer',",
    "start": "175475",
    "end": "177277"
  },
  {
    "text": "and 'Post'.",
    "start": "177778",
    "end": "179446"
  },
  {
    "text": "In 'pre', we do stuff like resizing, color correction.\nIn 'post', we create images from the output that we get from the base,",
    "start": "179446",
    "end": "189923"
  },
  {
    "text": "and in 'infer', we read the images to their appropriate GPU models.",
    "start": "189923",
    "end": "194795"
  },
  {
    "text": "Okay, so I assume that these are different work types, right?\nSo how do you decide what EC2 instance you will use?",
    "start": "194795",
    "end": "201401"
  },
  {
    "start": "195000",
    "end": "217000"
  },
  {
    "text": "Yeah, so for 'pre' and 'post', we let the image go through CPU instances\nbecause those are CPU-intensive workloads.",
    "start": "201401",
    "end": "209877"
  },
  {
    "text": "For 'inference', that image goes through GPU workloads, and for GPU,\nwe use G5 Instances that are like A10 GPUs.",
    "start": "209877",
    "end": "216383"
  },
  {
    "text": "Okay, and you spoke about 'inference', right?\nSo I assume these are like AI models.",
    "start": "216383",
    "end": "220787"
  },
  {
    "start": "217000",
    "end": "254000"
  },
  {
    "text": "- Exactly.\n- So how are you training these AI models?",
    "start": "220787",
    "end": "224224"
  },
  {
    "text": "So we have this training pipeline.",
    "start": "224224",
    "end": "226093"
  },
  {
    "text": "First, we upload the input data to S3 - the input training data.",
    "start": "226793",
    "end": "232966"
  },
  {
    "text": "Once we have the input training data we trigger SageMaker.\nOnce we trigger the SageMaker, it gets the input data from S3.",
    "start": "232966",
    "end": "239406"
  },
  {
    "text": "It gets it and starts the training.",
    "start": "241542",
    "end": "243777"
  },
  {
    "text": "We check the losses and accuracy of how the training is going\nand once the training completes, it uploads the weights to S3.",
    "start": "243777",
    "end": "254120"
  },
  {
    "start": "254000",
    "end": "281000"
  },
  {
    "text": "Okay. So once the weights are there innthe S3,\nhow do you update the processing layer?",
    "start": "254688",
    "end": "259226"
  },
  {
    "text": "Once we have the weights on S3, we have a basic benchmarking\nprocess through which the weights go through",
    "start": "259626",
    "end": "268635"
  },
  {
    "text": "and once it passes our benchmarks and accuracy,\nwe trigger the SageMaker, it triggers the Lambda.",
    "start": "268635",
    "end": "273540"
  },
  {
    "text": "Okay. From there the Lambda synchronizes\nthe weights from S3 to the processing services.",
    "start": "273941",
    "end": "279713"
  },
  {
    "text": "Okay, and what are you doing to make this, because you are doing\nimage processing, so, I assume that training data is a lot.",
    "start": "280848",
    "end": "288121"
  },
  {
    "start": "281000",
    "end": "327000"
  },
  {
    "text": "So, once you have so much of training data,\nwhat exactly are you doing in SageMaker to optimize it?",
    "start": "288789",
    "end": "293227"
  },
  {
    "text": "In SageMaker, we are leveraging Spot Instances.",
    "start": "293227",
    "end": "296496"
  },
  {
    "text": "With Spot Instances, we have been able\nto reduce our cost to one-third of it",
    "start": "296496",
    "end": "301201"
  },
  {
    "text": "just by using Spot Instances,",
    "start": "301869",
    "end": "303436"
  },
  {
    "text": "and not just the cost point of it, with SageMaker, we have been able\nto distribute the resources and manage them efficiently and effectively within our team.",
    "start": "303437",
    "end": "313580"
  },
  {
    "text": "Oh, that's great. Thank you so much, Abhinav\nfor sharing this architecture with us.",
    "start": "313580",
    "end": "317985"
  },
  {
    "text": "Thank you for watching, 'This is My Architecture'.",
    "start": "318886",
    "end": "320921"
  }
]
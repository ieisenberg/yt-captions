[
  {
    "start": "0",
    "end": "84000"
  },
  {
    "text": "hello everyone welcome my name is Shrikant monkey and i am a software",
    "start": "30",
    "end": "6509"
  },
  {
    "text": "development manager here at Amazon Marketplace me and my team built a",
    "start": "6509",
    "end": "12480"
  },
  {
    "text": "document management service we built it for our initial use cases and we built",
    "start": "12480",
    "end": "19109"
  },
  {
    "text": "it quite small so at that point of time we built it with Oracle as its database",
    "start": "19109",
    "end": "24510"
  },
  {
    "text": "and we were using Oracle in the active and passive mode as soon as the service",
    "start": "24510",
    "end": "30240"
  },
  {
    "text": "was launched we saw a phenomenal adoption we were seeing 500x growth",
    "start": "30240",
    "end": "36000"
  },
  {
    "text": "year-on-year basis and within the first 18 months we realized that we would have",
    "start": "36000",
    "end": "41730"
  },
  {
    "text": "to change our primary data store and hence we decided to move from Oracle to",
    "start": "41730",
    "end": "47329"
  },
  {
    "text": "dynamodb at the same time the number of new use cases that had been unbothered",
    "start": "47329",
    "end": "54090"
  },
  {
    "text": "onto the platform where our business critical nature it was dead when we",
    "start": "54090",
    "end": "59340"
  },
  {
    "text": "realized that we would have to do the migration right without any downtime",
    "start": "59340",
    "end": "66020"
  },
  {
    "text": "this talk is going to summarize all the learnings that we got from doing this",
    "start": "66020",
    "end": "71549"
  },
  {
    "text": "migration it is going to be right from beginning all the way to the end and",
    "start": "71549",
    "end": "77570"
  },
  {
    "text": "this is meant for anybody else who is trying to do this migration in future",
    "start": "77570",
    "end": "84110"
  },
  {
    "start": "84000",
    "end": "84000"
  },
  {
    "text": "just to get a little bit of understanding of the audience here how many of you are just using relational",
    "start": "85130",
    "end": "91320"
  },
  {
    "text": "databases here and who are using a mix",
    "start": "91320",
    "end": "98729"
  },
  {
    "text": "of both a lot more right and how many of",
    "start": "98729",
    "end": "104399"
  },
  {
    "text": "you are considering migration in the next short time right might be the next one or two years okay large number great",
    "start": "104399",
    "end": "112729"
  },
  {
    "text": "this talk is really going to help you to think about every aspect of what you",
    "start": "112729",
    "end": "118110"
  },
  {
    "text": "might have to undergo face think plan for doing this migration",
    "start": "118110",
    "end": "123920"
  },
  {
    "text": "with this material you would have clearly understanding of what it will",
    "start": "127660",
    "end": "132680"
  },
  {
    "text": "take how you could go about doing it and what are the things you might have to consider again I just put a caveat that",
    "start": "132680",
    "end": "141380"
  },
  {
    "text": "this is going to be a template this is how we did it but you will have to tweak it a little bit for your own needs and this is not a",
    "start": "141380",
    "end": "151430"
  },
  {
    "text": "talk on Oracle or DynamoDB I expect a fair amount of knowledge of both of",
    "start": "151430",
    "end": "156590"
  },
  {
    "text": "these products so I will not be going into any details of them second it is",
    "start": "156590",
    "end": "161990"
  },
  {
    "text": "I'm not taking any sides we basically think both technologies and products",
    "start": "161990",
    "end": "167570"
  },
  {
    "text": "have their own sweet spot and finally I will talk about a little bit of how we",
    "start": "167570",
    "end": "172670"
  },
  {
    "text": "went about our schema but it is not a primer on how to do non relational",
    "start": "172670",
    "end": "177920"
  },
  {
    "text": "schema design either fit so this is what we are going to follow so this I'm going",
    "start": "177920",
    "end": "185989"
  },
  {
    "text": "to give you a brief overview of the application so that it sets your context second we will talk about the different",
    "start": "185989",
    "end": "192470"
  },
  {
    "text": "different steps that we took for preparation and those might be things that you might have to consider then you are thinking about your own migration we",
    "start": "192470",
    "end": "200239"
  },
  {
    "text": "talked about how we went about transforming our schema the different different migration strategies that we",
    "start": "200239",
    "end": "206330"
  },
  {
    "text": "considered and their pros and cons and the ones which we went with we will talk",
    "start": "206330",
    "end": "211700"
  },
  {
    "text": "about how we refactor our api's we will talk of the actual data migration itself",
    "start": "211700",
    "end": "216890"
  },
  {
    "text": "let me give you a little bit of the results okay so application overview",
    "start": "216890",
    "end": "225100"
  },
  {
    "start": "224000",
    "end": "224000"
  },
  {
    "text": "as is a document management application so we receive documents we manage the",
    "start": "225930",
    "end": "231599"
  },
  {
    "text": "documents and metadata and we give the documents to whoever deserves them or",
    "start": "231599",
    "end": "237269"
  },
  {
    "text": "who has got authorization for them there are three services the document ingestion service is responsible for",
    "start": "237269",
    "end": "244139"
  },
  {
    "text": "receiving the documents the document manager service manages the metadata the",
    "start": "244139",
    "end": "250170"
  },
  {
    "text": "attributes the permissions the configurations the distribution service is responsible for distributing the",
    "start": "250170",
    "end": "257669"
  },
  {
    "text": "documents to the clients the documents are themselves maintained in s3 they are",
    "start": "257669",
    "end": "263130"
  },
  {
    "text": "encrypted and kept and all of the document metadata the permissions ACLs",
    "start": "263130",
    "end": "268650"
  },
  {
    "text": "are managed in the Oracle database and this is our primary database and this",
    "start": "268650",
    "end": "274289"
  },
  {
    "text": "was the database that we were trying to migrate so this is what we hope for",
    "start": "274289",
    "end": "279860"
  },
  {
    "text": "you just have DynamoDB and we are good",
    "start": "279860",
    "end": "285560"
  },
  {
    "text": "so let's kind of look at the reasons why we had to migrate first availability as",
    "start": "285560",
    "end": "291349"
  },
  {
    "text": "mentioned we had Oracle in the active and standby mode when we initially",
    "start": "291349",
    "end": "297750"
  },
  {
    "text": "started off our application and we had to flip the database from time to time to apply security patches and just the",
    "start": "297750",
    "end": "305310"
  },
  {
    "text": "amount of downtime that was required to flip the database was not meeting the needs of the business critical use cases",
    "start": "305310",
    "end": "311699"
  },
  {
    "text": "that had been on ported say the business use case has needed five nines of availability at least because we were",
    "start": "311699",
    "end": "318840"
  },
  {
    "text": "even supporting the Amazon Treaty of pipeline so that was less than ten",
    "start": "318840",
    "end": "324000"
  },
  {
    "text": "minutes of downtime and zero plant on time we couldn't meet it with what we were trying to do with a current",
    "start": "324000",
    "end": "330240"
  },
  {
    "text": "straight scalability we were seeing find Road x growth Iranian and since the",
    "start": "330240",
    "end": "337020"
  },
  {
    "text": "start of the service we expected to cross like a ten billion in the first four years so it was something just",
    "start": "337020",
    "end": "344430"
  },
  {
    "text": "phenomenal we were not planning for it when we started off as I where thought of it differently",
    "start": "344430",
    "end": "351320"
  },
  {
    "text": "operations as new use cases came on and more data was added we always needed the",
    "start": "352380",
    "end": "358630"
  },
  {
    "text": "DBA to tweak the partitions manage the indices so that we could get a really good consistent throughput from our",
    "start": "358630",
    "end": "364600"
  },
  {
    "text": "database but we really liked the fact that DynamoDB would allow us to scale",
    "start": "364600",
    "end": "370900"
  },
  {
    "text": "and our reads and writes quite easily so that was a very attractive feature",
    "start": "370900",
    "end": "377220"
  },
  {
    "text": "finally cost we looked at running Oracle in the active active mode and it looked",
    "start": "377220",
    "end": "382600"
  },
  {
    "text": "at using dynamo D and it was quite clear from our analysis that dynamodb was",
    "start": "382600",
    "end": "387910"
  },
  {
    "text": "going to be a little bit more cheaper or less expensive so those are the reasons why we migrated so what are the steps",
    "start": "387910",
    "end": "397960"
  },
  {
    "text": "that we took as a preparation for the migration first me and my team we're the",
    "start": "397960",
    "end": "405910"
  },
  {
    "start": "402000",
    "end": "402000"
  },
  {
    "text": "people who built and the application but over appeared of one to 18 months we had",
    "start": "405910",
    "end": "413020"
  },
  {
    "text": "made a lot of changes to the Mike to the data we had foreign key constraints that",
    "start": "413020",
    "end": "418270"
  },
  {
    "text": "were different there was changes in null handling there were difference in how we managed",
    "start": "418270",
    "end": "424240"
  },
  {
    "text": "some columns some of them changed from the data types strings to ends to",
    "start": "424240",
    "end": "429460"
  },
  {
    "text": "boolean we had to deal with entities and every variation of the entity in all of",
    "start": "429460",
    "end": "435880"
  },
  {
    "text": "its forms in the existing database and that was a challenge because even though",
    "start": "435880",
    "end": "441010"
  },
  {
    "text": "we built the application we were not sure that we knew every variant of every entity in our own database and that is a",
    "start": "441010",
    "end": "447910"
  },
  {
    "text": "challenge you've got to face to the way we try to just think about it was let us",
    "start": "447910",
    "end": "455560"
  },
  {
    "text": "sample data or entities every 15 days and create a test bed and see that we",
    "start": "455560",
    "end": "463060"
  },
  {
    "text": "could migrate at least these entities so that was the basic starting point for any migration we created approximately 5",
    "start": "463060",
    "end": "469930"
  },
  {
    "text": "to 6 million entities with all of its different variants and by sampling data",
    "start": "469930",
    "end": "476199"
  },
  {
    "text": "all the way from start of the service to today and use that as the basis for starting off",
    "start": "476199",
    "end": "483539"
  },
  {
    "text": "second when we are trying to migrate off a particular database like Oracle we are",
    "start": "483800",
    "end": "491130"
  },
  {
    "text": "not just talking of moving away the data usually we have a lot of information in",
    "start": "491130",
    "end": "497940"
  },
  {
    "text": "the stored procedures in the jobs in the scheduled jobs that document transformations all of these processes",
    "start": "497940",
    "end": "504600"
  },
  {
    "text": "need to be migrated to one of the things that we did was to move all of these",
    "start": "504600",
    "end": "512090"
  },
  {
    "text": "things into api's we moved all of the business logic out of Oracle into the",
    "start": "512090",
    "end": "518669"
  },
  {
    "text": "application logic and all database interaction was limited to the most",
    "start": "518669",
    "end": "525120"
  },
  {
    "text": "basic operations read write update or delete and that is how we prepare",
    "start": "525120",
    "end": "531810"
  },
  {
    "text": "ourselves to do this migration because we had moved out all of the business",
    "start": "531810",
    "end": "537000"
  },
  {
    "text": "information out of the database just to",
    "start": "537000",
    "end": "542580"
  },
  {
    "start": "540000",
    "end": "540000"
  },
  {
    "text": "give you an example here is an example of one of our api's this API is talking",
    "start": "542580",
    "end": "549990"
  },
  {
    "text": "to three different databases therefore and this API is updating tables we would",
    "start": "549990",
    "end": "556470"
  },
  {
    "text": "know what amount of data being written to each of these tables how much data was being returned in what order so this",
    "start": "556470",
    "end": "563910"
  },
  {
    "text": "helped way to know this is what the process that I'm trying to migrate from",
    "start": "563910",
    "end": "569250"
  },
  {
    "text": "Oracle to dynamodb so we had this for every API that we had so that we know",
    "start": "569250",
    "end": "576720"
  },
  {
    "text": "that at the end of it each of these processes would have a store in DynamoDB",
    "start": "576720",
    "end": "584660"
  },
  {
    "text": "traffic any application sees variation of",
    "start": "585830",
    "end": "591710"
  },
  {
    "text": "traffic patterns my beta varies by time of day sometimes by pieter of the year",
    "start": "591710",
    "end": "598100"
  },
  {
    "text": "and we really need to kind of think of the application that would be able to",
    "start": "598100",
    "end": "605270"
  },
  {
    "text": "manage the traffic over a period of time because data migration takes months or longer depending on tough data so we",
    "start": "605270",
    "end": "613460"
  },
  {
    "text": "analyze the traffic for the last three months and we figure out which of those traffic patterns where put the most",
    "start": "613460",
    "end": "620540"
  },
  {
    "text": "stress on our own database and on the application so these are the different",
    "start": "620540",
    "end": "630020"
  },
  {
    "text": "sessions or these are the different patterns of traffic that had been",
    "start": "630020",
    "end": "636170"
  },
  {
    "text": "supported on our application and we looked at this distribution and we figure out which distribution would have",
    "start": "636170",
    "end": "643130"
  },
  {
    "text": "the most impact on our application we chose exactly those patterns which would",
    "start": "643130",
    "end": "649160"
  },
  {
    "text": "apply the most stress as the basis for migration so when we were going to do",
    "start": "649160",
    "end": "654530"
  },
  {
    "text": "stress test we would figure out the pattern which was going to apply the most stress to that we added our",
    "start": "654530",
    "end": "660320"
  },
  {
    "text": "migration traffic and that was the minimum threshold that the application had to reach for it to be able to",
    "start": "660320",
    "end": "667760"
  },
  {
    "text": "successfully migrated we went further",
    "start": "667760",
    "end": "673630"
  },
  {
    "text": "way from the sessions each of those sessions could call multiple api's and",
    "start": "673630",
    "end": "679450"
  },
  {
    "text": "we bought it down to each API level what would be the pattern of api's we would",
    "start": "679450",
    "end": "684560"
  },
  {
    "text": "be calling at any point of time and this is what we stress did it for so we had",
    "start": "684560",
    "end": "691040"
  },
  {
    "text": "the complete information of what we were going to stress our application down so that we knew that we would be able to",
    "start": "691040",
    "end": "697430"
  },
  {
    "text": "successfully migrated finally we froze",
    "start": "697430",
    "end": "703370"
  },
  {
    "text": "the schema for the duration of the migration we knew that we couldn't kind of have a dynamically changing schema",
    "start": "703370",
    "end": "710270"
  },
  {
    "text": "what we did was we planned all of the features requests that was going to require a feature change all upfront we",
    "start": "710270",
    "end": "717620"
  },
  {
    "text": "completed them we froze the schema and we told our clients that we would not be able to on board any new",
    "start": "717620",
    "end": "724579"
  },
  {
    "text": "request that required a schema change till the end of the migration and",
    "start": "724579",
    "end": "730540"
  },
  {
    "text": "finally we communicated to the clients so they were in sync with what we were doing and why we couldn't make any",
    "start": "730540",
    "end": "737089"
  },
  {
    "text": "changes to the schema so those were the preparation steps now moving on to the",
    "start": "737089",
    "end": "744379"
  },
  {
    "text": "schema design in through Amazonian",
    "start": "744379",
    "end": "751429"
  },
  {
    "start": "746000",
    "end": "746000"
  },
  {
    "text": "fashion whenever there is a complicated problem we first come up with tenets and",
    "start": "751429",
    "end": "756619"
  },
  {
    "text": "these are guiding principles which we use for any complex project so these we",
    "start": "756619",
    "end": "764300"
  },
  {
    "text": "always use them this is what we want to achieve and this is why we then make the",
    "start": "764300",
    "end": "769879"
  },
  {
    "text": "design and we validate that the design is meeting the tenets if the design matches the tenets then we know that we",
    "start": "769879",
    "end": "775999"
  },
  {
    "text": "are complete else we iterate again and again until we know that all the tenets are met so it's a iterative process we",
    "start": "775999",
    "end": "783679"
  },
  {
    "text": "did not get the schema in the first shot we went through several several iterations before we got to where we",
    "start": "783679",
    "end": "789110"
  },
  {
    "text": "wanted it to be but these are the tenets that helped us you might have to design your own tenets if that is how we'd go",
    "start": "789110",
    "end": "795649"
  },
  {
    "text": "about designing optimize for scalability yes we were migrating very clearly for",
    "start": "795649",
    "end": "802089"
  },
  {
    "text": "speed and scalability because that is why now we needed to we were going to",
    "start": "802089",
    "end": "811189"
  },
  {
    "text": "design it so that every operation would be as fast as possible would be able to update as less data as possible and we",
    "start": "811189",
    "end": "818569"
  },
  {
    "text": "were not going to consider using third normal forms as we did when we designed Oracle each the design of the api's",
    "start": "818569",
    "end": "826699"
  },
  {
    "text": "would design the database schema and not how we wanted to store it clearly second",
    "start": "826699",
    "end": "834579"
  },
  {
    "text": "we chose eventual consistency only because when we use consistent reads all",
    "start": "834579",
    "end": "841399"
  },
  {
    "text": "reads in dynamodb goes solely to the master which itself becomes a bottleneck and we do not want to have that so",
    "start": "841399",
    "end": "849319"
  },
  {
    "text": "anytime a client wanted to do a read after write pattern they would have to redo and ask the",
    "start": "849319",
    "end": "854860"
  },
  {
    "text": "very again if the data was not there but we did not support it in the application so it important we were i distributed",
    "start": "854860",
    "end": "862210"
  },
  {
    "text": "system and we expect failures in a distributed system so we had to make",
    "start": "862210",
    "end": "868840"
  },
  {
    "text": "sure that an application even if it failed would you able to recover gracefully from that immutability we",
    "start": "868840",
    "end": "878290"
  },
  {
    "text": "were going to use the insert only pattern that is anytime we updated any entity we would not update the entity",
    "start": "878290",
    "end": "885460"
  },
  {
    "text": "itself we would insert a new row and update a pointer to the latest and we",
    "start": "885460",
    "end": "891820"
  },
  {
    "text": "were doing this for audit we needed to maintain every historical change made to every entity single table writes this is",
    "start": "891820",
    "end": "901330"
  },
  {
    "text": "again for performance we were hoping that any api would be able to just write to one table or just read from one table",
    "start": "901330",
    "end": "908020"
  },
  {
    "text": "that was our goal we knew it was aspirational but anytime we knew that we",
    "start": "908020",
    "end": "913510"
  },
  {
    "text": "had write to multiple tables we ensure that the first write would have the data",
    "start": "913510",
    "end": "919000"
  },
  {
    "text": "to use so that it had although the super set of data that would be updated any",
    "start": "919000",
    "end": "924400"
  },
  {
    "text": "subsequent tables the reason for it is that we could do read repair even though",
    "start": "924400",
    "end": "929440"
  },
  {
    "text": "the next operations fail and I will talk a little bit more of this later on in the talk just to give you a little bit",
    "start": "929440",
    "end": "939070"
  },
  {
    "start": "936000",
    "end": "936000"
  },
  {
    "text": "of hint of our schema the document class let's say it represents it's a passport",
    "start": "939070",
    "end": "945700"
  },
  {
    "text": "so all passports would be a document class called passports my own personal passport would be the document I might",
    "start": "945700",
    "end": "954130"
  },
  {
    "text": "have to update my passport ID say after 10 years after it expires and I've got a",
    "start": "954130",
    "end": "959710"
  },
  {
    "text": "second copy or a second version that would be in my versions I might maintain",
    "start": "959710",
    "end": "965020"
  },
  {
    "text": "my passport either as a PDF file jpg PNG and that would be the locators the",
    "start": "965020",
    "end": "971170"
  },
  {
    "text": "locators told me what is the different files actually stored for it and metadata so",
    "start": "971170",
    "end": "976990"
  },
  {
    "text": "this is a key value pair so for every file type we could store like oh this is",
    "start": "976990",
    "end": "982540"
  },
  {
    "text": "the size this is the type this is the resolution all of those would go into the locator metadata",
    "start": "982540",
    "end": "988110"
  },
  {
    "text": "at the same time the document version metadata could have for my passport place of issue date of expiry described",
    "start": "988110",
    "end": "995490"
  },
  {
    "text": "so this was again a key value so this would show the approximate wavy stored",
    "start": "995490",
    "end": "1002030"
  },
  {
    "text": "metadata are before and this is the",
    "start": "1002030",
    "end": "1008770"
  },
  {
    "start": "1005000",
    "end": "1005000"
  },
  {
    "text": "white table that we came up with let me go through it piece by piece first so here we have the locator and",
    "start": "1008770",
    "end": "1017540"
  },
  {
    "text": "metadata being stored and we see the locator IDs always a UUID and you'll",
    "start": "1017540",
    "end": "1022580"
  },
  {
    "text": "notice that in this table there are uu IDs everywhere because we did not want any hotspots second the version metadata",
    "start": "1022580",
    "end": "1032390"
  },
  {
    "text": "so all the key value became a JSON blob and we stored it the document version",
    "start": "1032390",
    "end": "1039350"
  },
  {
    "text": "itself that became our partition key that is the UUID and we had five indices",
    "start": "1039350",
    "end": "1045230"
  },
  {
    "text": "in order to and those became our five columns in the documents table and then",
    "start": "1045230",
    "end": "1052730"
  },
  {
    "text": "the document at the document class came DC so that's how all of this data became",
    "start": "1052730",
    "end": "1059150"
  },
  {
    "text": "into one wide table but we also had",
    "start": "1059150",
    "end": "1066680"
  },
  {
    "text": "specific tables to support the different different operations and all the information stored at the documents",
    "start": "1066680",
    "end": "1073040"
  },
  {
    "text": "table was redundantly stored in the user attributes and the document attributes table but these were built specifically",
    "start": "1073040",
    "end": "1080300"
  },
  {
    "text": "for supporting different different operations and I will talk about these operations a little bit later first we",
    "start": "1080300",
    "end": "1090350"
  },
  {
    "text": "use a user attributes table to search and that is why we see the GS is on it",
    "start": "1090350",
    "end": "1096410"
  },
  {
    "text": "it doesn't mean that we all of them have to have five GS is but doesn't maximum 5 GS is as the dynamodb limitation and we",
    "start": "1096410",
    "end": "1103880"
  },
  {
    "text": "use the same document UUID document version UUID as the partition key we",
    "start": "1103880",
    "end": "1111640"
  },
  {
    "text": "this had user metadata so for example if i was trying to store the status of my",
    "start": "1111640",
    "end": "1118690"
  },
  {
    "text": "document so if it hasn't been reviewed by somebody on those are the things that would go into",
    "start": "1118690",
    "end": "1123860"
  },
  {
    "text": "the user metadata at the same time my password might be valid for 10 years",
    "start": "1123860",
    "end": "1131809"
  },
  {
    "text": "after that is expired and those would go into the document lifetime data and we would have completely different api's to",
    "start": "1131809",
    "end": "1137960"
  },
  {
    "text": "support each of these operations so it is never the one operation that is trying to get both the data depending",
    "start": "1137960",
    "end": "1144770"
  },
  {
    "text": "what you are trying to do you would either go against the user data or the lifetime data this is how we handle the",
    "start": "1144770",
    "end": "1155149"
  },
  {
    "text": "multiple rights so whenever a client writes to the API we write to the documents table we get a",
    "start": "1155149",
    "end": "1162799"
  },
  {
    "text": "document version ID and once we have the document version ID we write to the user attributes and the document attributes",
    "start": "1162799",
    "end": "1169399"
  },
  {
    "text": "table in parallel to just to save time it's only when all of them are successful that we return back to the",
    "start": "1169399",
    "end": "1175909"
  },
  {
    "text": "client now anytime there are writing to",
    "start": "1175909",
    "end": "1180980"
  },
  {
    "text": "multiple tables there is a chance for failures and it is expected so yes we",
    "start": "1180980",
    "end": "1187370"
  },
  {
    "text": "totally handled such kind of failures and this is how we handle those failures",
    "start": "1187370",
    "end": "1192610"
  },
  {
    "start": "1192000",
    "end": "1192000"
  },
  {
    "text": "anytime we read a data we first check their act might it in my user attributes",
    "start": "1192610",
    "end": "1199580"
  },
  {
    "text": "table if it is not there I go back to my original table which is the documents table get the data from there put it",
    "start": "1199580",
    "end": "1207080"
  },
  {
    "text": "into the user attributes table and return it so by doing read repair even",
    "start": "1207080",
    "end": "1212210"
  },
  {
    "text": "if there are failures in updating your multiple tables we are able to rectify the problem and we use read repair in",
    "start": "1212210",
    "end": "1219559"
  },
  {
    "text": "several several places very common pattern we use everywhere now let's talk",
    "start": "1219559",
    "end": "1226669"
  },
  {
    "text": "about the second aspect of the problem which was they were following an insert only pattern let me kind of show it with",
    "start": "1226669",
    "end": "1234380"
  },
  {
    "text": "a better example here is a table which is got the UUID s if you notice are all",
    "start": "1234380",
    "end": "1241220"
  },
  {
    "text": "the same so that would be my document version itself so it could be my passport there are two copies but your",
    "start": "1241220",
    "end": "1247640"
  },
  {
    "text": "your ID version one is the first entry of it and that's why the previous version is not then UUID two is the data",
    "start": "1247640",
    "end": "1255020"
  },
  {
    "text": "version and the head row is a special row the header always points to the latest",
    "start": "1255020",
    "end": "1260600"
  },
  {
    "text": "version of the record and it is only this record that is updated there are no",
    "start": "1260600",
    "end": "1266510"
  },
  {
    "text": "other records in anywhere in the database that get changed so let's see",
    "start": "1266510",
    "end": "1271760"
  },
  {
    "text": "how when you insert happens into this table well now I insert version 3 its",
    "start": "1271760",
    "end": "1277309"
  },
  {
    "text": "previous version is v2 at the same time the head is not yet updated so if you",
    "start": "1277309",
    "end": "1283160"
  },
  {
    "text": "search at this time version 2 is still the latest and finally you update the head to v3 at this point of time version",
    "start": "1283160",
    "end": "1290690"
  },
  {
    "text": "3 is what you would recognize is the latest version but this is how we follow the insert only pattern so every version",
    "start": "1290690",
    "end": "1298610"
  },
  {
    "text": "of every change to every entity is maintained okay so let's review we",
    "start": "1298610",
    "end": "1308840"
  },
  {
    "text": "talked about our tenets we then talked about how we kind of came up with a wide schema we talked about how we write to",
    "start": "1308840",
    "end": "1316460"
  },
  {
    "text": "multiple tables how we read how we used read repair to rectify problems because",
    "start": "1316460",
    "end": "1322010"
  },
  {
    "text": "there is no acid support and non-relational databases and then we talked about our insert only pattern and",
    "start": "1322010",
    "end": "1328640"
  },
  {
    "text": "we also talked about how we optimize performance by having specific tables",
    "start": "1328640",
    "end": "1333760"
  },
  {
    "text": "specific to user operations so let's",
    "start": "1333760",
    "end": "1338809"
  },
  {
    "text": "move into the next section which talks about the different migration strategies just to give you a little bit of",
    "start": "1338809",
    "end": "1344870"
  },
  {
    "start": "1342000",
    "end": "1342000"
  },
  {
    "text": "introduction to what I define by phases data was originally only in Oracle and",
    "start": "1344870",
    "end": "1350660"
  },
  {
    "text": "that's phase 1 that is the existing behavior and we wanted to finally have all the data go into dynamodb that's the",
    "start": "1350660",
    "end": "1356270"
  },
  {
    "text": "final phase and the phase 2 and phase 3 are how we get there first we move the",
    "start": "1356270",
    "end": "1362090"
  },
  {
    "text": "application so that we start writing to both Oracle and dynamodb so that all new",
    "start": "1362090",
    "end": "1367549"
  },
  {
    "text": "data goes into both and at that point of time Oracle is considered the master so in case there is any variance we cannot",
    "start": "1367549",
    "end": "1373790"
  },
  {
    "text": "go against the data from the master then we do the back full of the data from Oracle into danwoah dB and once dynamodb",
    "start": "1373790",
    "end": "1381080"
  },
  {
    "text": "is caught up we then switch we maintain this to make sure that there are no mistakes no errors and finally when",
    "start": "1381080",
    "end": "1387590"
  },
  {
    "text": "you're convinced that everything is good that's how we're going to take off so these are the phrases and we move",
    "start": "1387590",
    "end": "1393090"
  },
  {
    "text": "between phases through configuration so it is not through deployments because we",
    "start": "1393090",
    "end": "1398970"
  },
  {
    "text": "take approximately one or two days to do our deployments in four realms and that would be too time-consuming in case we",
    "start": "1398970",
    "end": "1405660"
  },
  {
    "text": "have to do our roll backs so when we started off migration all the four",
    "start": "1405660",
    "end": "1411210"
  },
  {
    "text": "phases of data in the code had how to handle all four phases at that point of",
    "start": "1411210",
    "end": "1416280"
  },
  {
    "text": "time and we were just migrated by using configuration so I'm also kind of",
    "start": "1416280",
    "end": "1423210"
  },
  {
    "start": "1421000",
    "end": "1421000"
  },
  {
    "text": "talking now about a few ways to evaluate how we are going to evaluate the",
    "start": "1423210",
    "end": "1428280"
  },
  {
    "text": "different different migration strategies so that's how application consistency all client applications should see the",
    "start": "1428280",
    "end": "1435750"
  },
  {
    "text": "same uniform behavior across the migration independent of phase and that is expected that's application",
    "start": "1435750",
    "end": "1442290"
  },
  {
    "text": "consistency second correctness at the end of it with the expectation for the",
    "start": "1442290",
    "end": "1447600"
  },
  {
    "text": "data it both stores is that they are the same completeness we need to know that",
    "start": "1447600",
    "end": "1453960"
  },
  {
    "text": "every entity in Oracle has been migrated to DynamoDB and we need to actually",
    "start": "1453960",
    "end": "1459420"
  },
  {
    "text": "verify that it is all migrated and finally even though we plan for the best",
    "start": "1459420",
    "end": "1465270"
  },
  {
    "text": "we have to design for the worst say we should assume that we would not be able",
    "start": "1465270",
    "end": "1471030"
  },
  {
    "text": "to do things completely in the first run go back to a last known good fix the problem and continue so any migration",
    "start": "1471030",
    "end": "1478680"
  },
  {
    "text": "strategy should be able to be restarted successfully first one workflow a client",
    "start": "1478680",
    "end": "1488790"
  },
  {
    "text": "writes to the workflow engine the workflow engine puts it in the queue then we have workers and then the",
    "start": "1488790",
    "end": "1494280"
  },
  {
    "text": "workers take the responsibility of writing to the two databases and then we",
    "start": "1494280",
    "end": "1502320"
  },
  {
    "text": "read from both of them to make sure that the data being written to both of them is the same and once we confirm that",
    "start": "1502320",
    "end": "1507870"
  },
  {
    "text": "both the data and the entities are the same we say the successful so this is our work flow model so let's see why we",
    "start": "1507870",
    "end": "1515100"
  },
  {
    "start": "1515000",
    "end": "1515000"
  },
  {
    "text": "did not use it first data was written to the workflow and the",
    "start": "1515100",
    "end": "1522059"
  },
  {
    "text": "clients have got a success so if the workflow engine is backlogged or it's",
    "start": "1522059",
    "end": "1527520"
  },
  {
    "text": "stuck you would never be able to get the data from the stores because neither of the stores either Oracle or DynamoDB do",
    "start": "1527520",
    "end": "1534570"
  },
  {
    "text": "not have the data second if there are multiple updates going on simultaneously",
    "start": "1534570",
    "end": "1541220"
  },
  {
    "text": "the workflow engines do not ensure the same order so it is a possibility that",
    "start": "1541220",
    "end": "1547280"
  },
  {
    "text": "Ritu happens later than read three or update two happens after update three so",
    "start": "1547280",
    "end": "1553260"
  },
  {
    "text": "the data finally might be wrong finally",
    "start": "1553260",
    "end": "1559260"
  },
  {
    "text": "if we are always reading from both stores to make sure that we have written",
    "start": "1559260",
    "end": "1564690"
  },
  {
    "text": "data carefully and correctly but if you are verifying for version one or update one update to our update we might have",
    "start": "1564690",
    "end": "1571980"
  },
  {
    "text": "started so you might be comparing data in Oracle but version one with update two or update three now this could lead",
    "start": "1571980",
    "end": "1579419"
  },
  {
    "text": "to false positives or false negatives which is unacceptable we actually ran this and the amount of data errors we",
    "start": "1579419",
    "end": "1586350"
  },
  {
    "text": "were getting there unacceptable for our application and that is why we did not use this method so just to give you an",
    "start": "1586350",
    "end": "1593820"
  },
  {
    "text": "example of how we are using these criteria the complexity is low app",
    "start": "1593820",
    "end": "1599460"
  },
  {
    "text": "consistency is not meeting because the final state if then update to happens earlier than update three it would not",
    "start": "1599460",
    "end": "1605460"
  },
  {
    "text": "be correct correctness is the same completeness we could always ensure because once we know that workflow is",
    "start": "1605460",
    "end": "1611309"
  },
  {
    "text": "completed all of the rows it is complete potential data loss is mainly because",
    "start": "1611309",
    "end": "1616679"
  },
  {
    "text": "again due to correctness restartable we can always restart the workflow and latency so this is how we kind of use",
    "start": "1616679",
    "end": "1623070"
  },
  {
    "text": "these evaluation criteria so I could go fast in the next iterations so first",
    "start": "1623070",
    "end": "1633000"
  },
  {
    "text": "what are the problems with the single master model means with the workflow model was we were writing to a separate",
    "start": "1633000",
    "end": "1639600"
  },
  {
    "text": "entity and not writing to the actual databases so first now in the single master model",
    "start": "1639600",
    "end": "1646230"
  },
  {
    "text": "we use the client to write directly to the database itself and if there are",
    "start": "1646230",
    "end": "1652050"
  },
  {
    "text": "multiple updates happening at the same time we use conditional puts to make sure that only one of them happens at",
    "start": "1652050",
    "end": "1657750"
  },
  {
    "text": "the time so we address both of the problems for the workflow model so let's",
    "start": "1657750",
    "end": "1664230"
  },
  {
    "text": "see how this thing works so whenever an update comes to the service now the",
    "start": "1664230",
    "end": "1670080"
  },
  {
    "text": "service would and the entity shows that this record is right now in Oracle so",
    "start": "1670080",
    "end": "1675540"
  },
  {
    "text": "the update goes to where the entity is so it goes first time to Oracle now if",
    "start": "1675540",
    "end": "1682590"
  },
  {
    "text": "the data was migrated over the next time an update to the entity happens it would",
    "start": "1682590",
    "end": "1687810"
  },
  {
    "text": "go to dynamodb so this is how the simple single master model worked the main",
    "start": "1687810",
    "end": "1693270"
  },
  {
    "start": "1690000",
    "end": "1690000"
  },
  {
    "text": "problem we found was there was no means to verify that the data written to DynamoDB was correct or not because",
    "start": "1693270",
    "end": "1699570"
  },
  {
    "text": "there was no baseline unless we were able to compare it to something which we know was good there's a potential that",
    "start": "1699570",
    "end": "1706230"
  },
  {
    "text": "what we have written would not be correct and that is why we have ended this model to tracking model so to",
    "start": "1706230",
    "end": "1720560"
  },
  {
    "text": "improve on the model we said we needed a baseline so we started writing to both the stores so both Oracle and DynamoDB",
    "start": "1720560",
    "end": "1727530"
  },
  {
    "text": "and since we are writing to two stores we added flags to the entities in both",
    "start": "1727530",
    "end": "1734760"
  },
  {
    "text": "sides one who is master and is the robing back field to the other day or",
    "start": "1734760",
    "end": "1741990"
  },
  {
    "text": "store or not so we had flags both in Oracle and flags and dynamodb and the",
    "start": "1741990",
    "end": "1748440"
  },
  {
    "text": "reason we had flags in both sides is because in case there was a rollback we might need to move data from danwoah DB",
    "start": "1748440",
    "end": "1755520"
  },
  {
    "text": "back to Oracle so that is why we have flags in both sides and just to kind of",
    "start": "1755520",
    "end": "1760770"
  },
  {
    "text": "give you a high-level view of the client rights to the master master flag is set and the for that row then secondary data",
    "start": "1760770",
    "end": "1768600"
  },
  {
    "text": "gets updated then once it is written to the secretary we will write the back field and then only then is client so",
    "start": "1768600",
    "end": "1774750"
  },
  {
    "text": "let's done Feli but is this model is a",
    "start": "1774750",
    "end": "1781070"
  },
  {
    "text": "very simplistic approach to what the problems are in this we have spent days with this model",
    "start": "1781070",
    "end": "1788789"
  },
  {
    "text": "trying to deal with all of the edge cases and it is quite difficult to make",
    "start": "1788789",
    "end": "1796619"
  },
  {
    "text": "sure that we have handled all of the edge cases because every time we consider educators we need to think",
    "start": "1796619",
    "end": "1802289"
  },
  {
    "text": "about we might have to roll forward roll back because of errors there might be potential loss of data so even though",
    "start": "1802289",
    "end": "1809309"
  },
  {
    "text": "this model was great we could not convince ourselves that there would be",
    "start": "1809309",
    "end": "1814320"
  },
  {
    "text": "no loss of data and there was a reason for it one we found that when we we have to put",
    "start": "1814320",
    "end": "1823950"
  },
  {
    "start": "1818000",
    "end": "1818000"
  },
  {
    "text": "an index on the GSI just to know that has this row being migrated or not and",
    "start": "1823950",
    "end": "1829789"
  },
  {
    "text": "when we put this GSI on the row we found that that became the bottleneck because",
    "start": "1829789",
    "end": "1836309"
  },
  {
    "text": "this was a low cardinality because had only two values so for the volumes of data that we were managing and the rate",
    "start": "1836309",
    "end": "1842820"
  },
  {
    "text": "that we needed to get to by just having this GSI we just did not get the rates we needed second we were already using",
    "start": "1842820",
    "end": "1852239"
  },
  {
    "text": "all of the five GS is because we had five index metadata in oracle so we",
    "start": "1852239",
    "end": "1857429"
  },
  {
    "text": "couldn't add a sixth GSI to the same table and we are forced to use a",
    "start": "1857429",
    "end": "1862649"
  },
  {
    "text": "secondary table for that and any which is table which is a secondary there is a",
    "start": "1862649",
    "end": "1867839"
  },
  {
    "text": "chance that it might not get updated because we are not guarding asset properties and that is the reason why",
    "start": "1867839",
    "end": "1874889"
  },
  {
    "text": "even with our best intentions and efforts we could not get this work this",
    "start": "1874889",
    "end": "1879929"
  },
  {
    "text": "mechanism to work for us successfully and we can talk about this later if you",
    "start": "1879929",
    "end": "1885419"
  },
  {
    "text": "wanted more details but I'm going to kind of move on at this point of time",
    "start": "1885419",
    "end": "1890628"
  },
  {
    "text": "so the implemented model so what were the improvements to this model first the",
    "start": "1898650",
    "end": "1908140"
  },
  {
    "text": "limitation was that we could not have GSIS on the flags in dynamodb so first we",
    "start": "1908140",
    "end": "1914890"
  },
  {
    "text": "moved all of the flags for is it master from the data into the code",
    "start": "1914890",
    "end": "1923460"
  },
  {
    "text": "so the code knew if it was working in phase 2 that Oracle was going to be",
    "start": "1923460",
    "end": "1930160"
  },
  {
    "text": "master and if it was in phase 3 dynamodb was going to be master so that's how we eliminated one flag the second flag was",
    "start": "1930160",
    "end": "1939310"
  },
  {
    "text": "is it master and this was related to in case we needed to roll back from danwoah",
    "start": "1939310",
    "end": "1945580"
  },
  {
    "text": "DB back to Oracle so how did we minimize the chance for rollback",
    "start": "1945580",
    "end": "1951700"
  },
  {
    "text": "we took a penalty in terms of validating each row so whenever you wrote a row to",
    "start": "1951700",
    "end": "1958750"
  },
  {
    "text": "any data store we read it back we compared it with the base which was",
    "start": "1958750",
    "end": "1964990"
  },
  {
    "text": "Oracle or DynamoDB and only when the comparison said that both entities in both the data stores work consisted we",
    "start": "1964990",
    "end": "1972220"
  },
  {
    "text": "then returned the success to the client so by adding a performance penalty to our application we minimize the need to",
    "start": "1972220",
    "end": "1979240"
  },
  {
    "text": "roll back from phase 3 to phase 2 so the",
    "start": "1979240",
    "end": "1986650"
  },
  {
    "text": "only portion that we needed to really migrate was in historical data which was an Oracle",
    "start": "1986650",
    "end": "1991900"
  },
  {
    "text": "before the migration share for doing this migration we just needed one flag",
    "start": "1991900",
    "end": "1997600"
  },
  {
    "text": "in Oracle is this entity being back filled or not and that is what we did so",
    "start": "1997600",
    "end": "2003660"
  },
  {
    "text": "we just added a single entity in the Oracle side for checking if the migration of that entity was done or not",
    "start": "2003660",
    "end": "2010490"
  },
  {
    "text": "so let's look at it further right I also would like to call out there is a small",
    "start": "2010490",
    "end": "2016230"
  },
  {
    "text": "chance of inconsistent data let me explain whenever you are writing to two data stores there is a potential that",
    "start": "2016230",
    "end": "2023040"
  },
  {
    "text": "you might not be able to write to the other just because of distributor systems and failures and we would not",
    "start": "2023040",
    "end": "2030970"
  },
  {
    "text": "return a success to the client but there's a chance that this row got orphaned in the master and we were okay",
    "start": "2030970",
    "end": "2037480"
  },
  {
    "text": "with this because this row would get purged through the lifetime retention",
    "start": "2037480",
    "end": "2043660"
  },
  {
    "text": "policies might be a little bit later but that would be just a row which would be a redundant row in our store and we were",
    "start": "2043660",
    "end": "2049658"
  },
  {
    "text": "okay with this redundant data being there there was also possibility that",
    "start": "2049659",
    "end": "2056169"
  },
  {
    "text": "this redundant row would be discovered by a search which asked for give me all",
    "start": "2056169",
    "end": "2061570"
  },
  {
    "text": "the rows for a particular service or entity and we were okay with this",
    "start": "2061570",
    "end": "2068940"
  },
  {
    "text": "redundant row being discovered too because anytime they try to do anything with it they would recover that this was",
    "start": "2068940",
    "end": "2074950"
  },
  {
    "text": "not a useful role because they would not have a corresponding correlation both of these things were acceptable so let's",
    "start": "2074950",
    "end": "2084128"
  },
  {
    "start": "2083000",
    "end": "2083000"
  },
  {
    "text": "see how we did the right in phase one we were just writing to Oracle in Phase two",
    "start": "2084129",
    "end": "2089590"
  },
  {
    "text": "Oracle being master we first row to Oracle and then we mark that is done",
    "start": "2089590",
    "end": "2094720"
  },
  {
    "text": "over backwards to know then we wrote to dynamodb and once we have written to that we mark that oh this was being",
    "start": "2094720",
    "end": "2101140"
  },
  {
    "text": "battled we compare the two entities across the two data stores and only when",
    "start": "2101140",
    "end": "2106450"
  },
  {
    "text": "they say they are consistent is a good so that's how we did it in phase 2 and",
    "start": "2106450",
    "end": "2111850"
  },
  {
    "text": "phase 2 this is where we do the Battle of all of the data this is just a marker for that phase 3 we follow a very",
    "start": "2111850",
    "end": "2118090"
  },
  {
    "text": "similar pattern it just that now since dynamodb is the master we first write two DynamoDB but essentially the same",
    "start": "2118090",
    "end": "2124570"
  },
  {
    "text": "pattern and finally in phase 4 we just write into DynamoDB and a very similar",
    "start": "2124570",
    "end": "2132400"
  },
  {
    "text": "model is used for read we read only in Oracle again when we are doing a read",
    "start": "2132400",
    "end": "2139900"
  },
  {
    "text": "before Street Oracle in phase 2 and if the data has not been backfilled we",
    "start": "2139900",
    "end": "2146440"
  },
  {
    "text": "write two DynamoDB is it backfilled and midweek so and then we compare the two",
    "start": "2146440",
    "end": "2153670"
  },
  {
    "text": "entities and then return back so in case it was not backfilled",
    "start": "2153670",
    "end": "2159829"
  },
  {
    "text": "originally we do this read repaired pattern again to fix it",
    "start": "2159829",
    "end": "2165789"
  },
  {
    "text": "similarly in phase three we do the same pattern in the opposite direction with danwoah DB being the master finally in",
    "start": "2167109",
    "end": "2175339"
  },
  {
    "text": "phase four we just reading from dynamo DB so that's how we did our read and writes now again",
    "start": "2175339",
    "end": "2182390"
  },
  {
    "text": "this is a simplistic model I would not kind of shown you all the edge cases the error handling the exception and",
    "start": "2182390",
    "end": "2187640"
  },
  {
    "text": "handling but this is the basic pattern again to evaluate the complexity is high",
    "start": "2187640",
    "end": "2196310"
  },
  {
    "text": "but everything else was good latency is the place where we paid the penalty for",
    "start": "2196310",
    "end": "2202630"
  },
  {
    "text": "we have higher latency 's due to multiple region writes which we are",
    "start": "2202630",
    "end": "2208069"
  },
  {
    "text": "doing so though that was the penalty we paid but apart from that everything was",
    "start": "2208069",
    "end": "2213170"
  },
  {
    "text": "what we were hoping for and that is why we went with this pattern so we looked",
    "start": "2213170",
    "end": "2221540"
  },
  {
    "text": "at the different patterns we looked at some of the commonly used ones the workflow the single master the to flag",
    "start": "2221540",
    "end": "2226970"
  },
  {
    "text": "and then finally the mod version of the single master with the two flag models that we implemented and we gave you the",
    "start": "2226970",
    "end": "2233510"
  },
  {
    "text": "reasons of how we went evaluating these strategies we actually wrote and worked",
    "start": "2233510",
    "end": "2239180"
  },
  {
    "text": "with each model to see if it was working or not before we moved on to the next one let's move to the next section now",
    "start": "2239180",
    "end": "2246079"
  },
  {
    "text": "the API refactoring we use the adapter pattern to work across all the phases so",
    "start": "2246079",
    "end": "2254540"
  },
  {
    "start": "2248000",
    "end": "2248000"
  },
  {
    "text": "when the code was put in it had information of how to work in phase 1 phase 2 phase 3 phase 4 and whereby a",
    "start": "2254540",
    "end": "2262609"
  },
  {
    "text": "mere change in configuration it could instantly move in the behavior from how",
    "start": "2262609",
    "end": "2267920"
  },
  {
    "text": "it would do from phase one or phase two so we could do our roll forward or roll back quite immediately and we had our",
    "start": "2267920",
    "end": "2275270"
  },
  {
    "text": "basically persistence model being defined by the oracle dao or by the dan Mahtob you do so very",
    "start": "2275270",
    "end": "2282589"
  },
  {
    "text": "easily adapter pattern that we use and that is how all of our API as well to do the migration",
    "start": "2282589",
    "end": "2291039"
  },
  {
    "text": "now let's actually talk about some of the things of data migration itself so",
    "start": "2292050",
    "end": "2299560"
  },
  {
    "text": "before we did a data migration we looked at several things before we start at all so before we started out being sure had",
    "start": "2299560",
    "end": "2307630"
  },
  {
    "text": "we done the data migration successfully on sample data or not and to do this we",
    "start": "2307630",
    "end": "2313780"
  },
  {
    "start": "2312000",
    "end": "2312000"
  },
  {
    "text": "had actually built a data migration to now this was a tool which we built custom for ourselves but this tool",
    "start": "2313780",
    "end": "2321450"
  },
  {
    "text": "ramped up or down the traffic of migration traffic you know in the",
    "start": "2321450",
    "end": "2327790"
  },
  {
    "text": "exactly opposite direction of the production traffic now the reason for this is if we did the migration of data",
    "start": "2327790",
    "end": "2333850"
  },
  {
    "text": "only in the off peak ours it was going to add several months to our own",
    "start": "2333850",
    "end": "2339310"
  },
  {
    "text": "migration time frame so it was a really big saving and investment this tool",
    "start": "2339310",
    "end": "2344470"
  },
  {
    "text": "really paid off second we had tested out",
    "start": "2344470",
    "end": "2351430"
  },
  {
    "text": "the rollback scenarios in case of failures so we not only tested out the",
    "start": "2351430",
    "end": "2358630"
  },
  {
    "start": "2355000",
    "end": "2355000"
  },
  {
    "text": "happy path which was going from phase one phase two doing the battle phase 3 and phase 4 which was the ideal one but",
    "start": "2358630",
    "end": "2364690"
  },
  {
    "text": "we assume we could fail in phase two and we would had rolled back we actually tested it out similarly in Phase three",
    "start": "2364690",
    "end": "2371170"
  },
  {
    "text": "we could have failures rolled back and go so we actually went to this thing",
    "start": "2371170",
    "end": "2376510"
  },
  {
    "text": "twice to make sure that we could successfully do a rollback go to a last known good move forward from there and",
    "start": "2376510",
    "end": "2383850"
  },
  {
    "text": "not have any loss of data check there",
    "start": "2383850",
    "end": "2390520"
  },
  {
    "text": "was no loss of data and we use 5 million rows third we run stress test in every",
    "start": "2390520",
    "end": "2397960"
  },
  {
    "text": "phase I think this is very key that we have ran stress testing in each phase the read and write patterns in every",
    "start": "2397960",
    "end": "2405070"
  },
  {
    "text": "phase are different and you need to make sure that you are able to handle the",
    "start": "2405070",
    "end": "2412150"
  },
  {
    "text": "peak loads of data from production traffic and your migration traffic in each phases to do that we had built a",
    "start": "2412150",
    "end": "2420760"
  },
  {
    "text": "specific to stress test to at the beginning as a part of preparation we had collected the",
    "start": "2420760",
    "end": "2427020"
  },
  {
    "text": "different sessions that were the most impactful and that's exactly what we used we chose the most those sessions",
    "start": "2427020",
    "end": "2437160"
  },
  {
    "text": "which had the most impact on the database and application at the migration traffic and use that to stress",
    "start": "2437160",
    "end": "2442890"
  },
  {
    "text": "test in each phase so at the end of each phase we knew that we could handle the expected max production volume in the",
    "start": "2442890",
    "end": "2450390"
  },
  {
    "text": "worst traffic and we had whatever migration traffic that we were planning",
    "start": "2450390",
    "end": "2455490"
  },
  {
    "text": "on adding on to the application third",
    "start": "2455490",
    "end": "2462859"
  },
  {
    "text": "the read and write throughputs had to be really adjusted for danwoah DB and this",
    "start": "2462859",
    "end": "2469589"
  },
  {
    "text": "is what we did I know it's a really busy slide but let me walk you through it",
    "start": "2469589",
    "end": "2475319"
  },
  {
    "start": "2472000",
    "end": "2472000"
  },
  {
    "text": "here is a API the create document and we were expecting TPS or 400 we are writing",
    "start": "2475319",
    "end": "2483710"
  },
  {
    "text": "approximately 8k and that's why based upon the read units for dynamo DB being",
    "start": "2483710",
    "end": "2489180"
  },
  {
    "text": "one KB it's eight times that and we were writing in this operation only one time",
    "start": "2489180",
    "end": "2495180"
  },
  {
    "text": "to the table and that is why for this operation we got a the right units of",
    "start": "2495180",
    "end": "2501960"
  },
  {
    "text": "3200 then since we were only writing",
    "start": "2501960",
    "end": "2507000"
  },
  {
    "text": "once to the GSI it became 404 the same operation however writing the user",
    "start": "2507000",
    "end": "2513569"
  },
  {
    "text": "attributes table we talked of the different size and operation multipliers",
    "start": "2513569",
    "end": "2518609"
  },
  {
    "text": "and that's how we got the different different values for each three so this is a theoretical calculation of what we",
    "start": "2518609",
    "end": "2524460"
  },
  {
    "text": "were expecting for each API and we had all of the api's and this is what the",
    "start": "2524460",
    "end": "2531750"
  },
  {
    "text": "peak values were expected so we had at the end the total of exactly what each",
    "start": "2531750",
    "end": "2537270"
  },
  {
    "text": "read and write units should be except for each of the tables so when we",
    "start": "2537270",
    "end": "2542369"
  },
  {
    "text": "actually ran our data migration tool we would confirm that they expected GSI",
    "start": "2542369",
    "end": "2549599"
  },
  {
    "start": "2546000",
    "end": "2546000"
  },
  {
    "text": "settings and the actual theoretical values matched so that we knew that we",
    "start": "2549599",
    "end": "2555480"
  },
  {
    "text": "would not get through as a part of migration at any point of time we made mistakes in this process",
    "start": "2555480",
    "end": "2561900"
  },
  {
    "text": "and this exercise really helped us we did discover a few places that we are",
    "start": "2561900",
    "end": "2568319"
  },
  {
    "text": "underestimated of what the reed units and right units needed to be and we were able to corrected based upon this we now",
    "start": "2568319",
    "end": "2580470"
  },
  {
    "text": "knew the different different values for the latencies in each phase and we",
    "start": "2580470",
    "end": "2585750"
  },
  {
    "text": "updated our operational and alarms dashboards so that we would knew if we were behaving in the expected manner or",
    "start": "2585750",
    "end": "2593460"
  },
  {
    "text": "not and finally we informed the same things to our clients because we had SLA",
    "start": "2593460",
    "end": "2598829"
  },
  {
    "text": "guarantees with our clients so that they were in sync with what were the new updated SLA is for the time timeline",
    "start": "2598829",
    "end": "2609470"
  },
  {
    "text": "from start to end we took approximately nine months and the schema was frozen for six months so",
    "start": "2609470",
    "end": "2616470"
  },
  {
    "text": "that is just a rough guideline this can change again we planned we had four",
    "start": "2616470",
    "end": "2625740"
  },
  {
    "text": "realms and we were migrating data in four different realms we had planned all of the migration to take place in the",
    "start": "2625740",
    "end": "2631380"
  },
  {
    "text": "month but it took twice as long just because production traffic was high and we couldn't get the migration traffic to",
    "start": "2631380",
    "end": "2638970"
  },
  {
    "text": "reach the levels we wanted it to third",
    "start": "2638970",
    "end": "2644900"
  },
  {
    "text": "code we had to build and code for each phase of the migration at this time and",
    "start": "2644900",
    "end": "2652470"
  },
  {
    "text": "that increase our size of our code 3x and just to verify that the code was",
    "start": "2652470",
    "end": "2659400"
  },
  {
    "text": "behaving correctly in each phase took us quite a bit of time we took three weeks just to verify that migration code was",
    "start": "2659400",
    "end": "2666240"
  },
  {
    "text": "correct and finally when we've completed data",
    "start": "2666240",
    "end": "2674319"
  },
  {
    "text": "migration and we were in Phase three we kept it for two weeks running in that",
    "start": "2674319",
    "end": "2680799"
  },
  {
    "text": "phase just before we kind of removed Oracle completely just to be a sanity check for our side so now let's kind of",
    "start": "2680799",
    "end": "2691210"
  },
  {
    "text": "talk about the results we were able to",
    "start": "2691210",
    "end": "2696250"
  },
  {
    "text": "complete the migration and happy path no resets or no roll backs we were really",
    "start": "2696250",
    "end": "2701259"
  },
  {
    "text": "thankful for it there was no loss of data or errors and we migrated hundred",
    "start": "2701259",
    "end": "2707920"
  },
  {
    "text": "million entities very successfully let's",
    "start": "2707920",
    "end": "2712930"
  },
  {
    "start": "2711000",
    "end": "2711000"
  },
  {
    "text": "evaluate the reasons to migrate and where we are today since the migration we have had 100%",
    "start": "2712930",
    "end": "2718119"
  },
  {
    "text": "availability so the first reason to migrate we have successfully managed very successfully second we have got 10x",
    "start": "2718119",
    "end": "2728019"
  },
  {
    "text": "more data and we are seeing there's ample Headroom so we can keep on scaling",
    "start": "2728019",
    "end": "2733960"
  },
  {
    "text": "with DynamoDB and finally we do not have a DBA so I think we have bought down our",
    "start": "2733960",
    "end": "2741220"
  },
  {
    "text": "costs both from operations and from the ownership point suggestions",
    "start": "2741220",
    "end": "2751109"
  },
  {
    "start": "2748000",
    "end": "2748000"
  },
  {
    "text": "we ran the first time migration from the primary and it became a bottleneck we",
    "start": "2751150",
    "end": "2758469"
  },
  {
    "text": "then moved to the sec different server and did the migration was far better because much better performance again",
    "start": "2758469",
    "end": "2766660"
  },
  {
    "text": "avoid GSI and low cardinality this was a really a bad problem and that is the",
    "start": "2766660",
    "end": "2772059"
  },
  {
    "text": "same reason why we couldn't kind of use the two flag model to really be careful of this one if you need to you might",
    "start": "2772059",
    "end": "2780339"
  },
  {
    "text": "want to move your search to your cloud search or less research and this was",
    "start": "2780339",
    "end": "2786309"
  },
  {
    "text": "under thing which you learn the hard way when you scale for migration do not over",
    "start": "2786309",
    "end": "2791859"
  },
  {
    "text": "scale because when you actually bring down the throughputs DynamoDB does not",
    "start": "2791859",
    "end": "2798249"
  },
  {
    "text": "collapse the partitions say if you might have very low throughput on the partitions afterwards and that can lead",
    "start": "2798249",
    "end": "2804700"
  },
  {
    "text": "to hot spots in the partitions even though you have sufficient read and write true puts at the table level so do",
    "start": "2804700",
    "end": "2812440"
  },
  {
    "text": "not over scale just for migration well",
    "start": "2812440",
    "end": "2818369"
  },
  {
    "text": "that is what I had we can take Q&A I've got me I got parts of my code team here",
    "start": "2818369",
    "end": "2825630"
  },
  {
    "text": "who did the migration so we can all take answers if you have any otherwise thank",
    "start": "2825630",
    "end": "2831999"
  },
  {
    "text": "you",
    "start": "2831999",
    "end": "2834150"
  }
]
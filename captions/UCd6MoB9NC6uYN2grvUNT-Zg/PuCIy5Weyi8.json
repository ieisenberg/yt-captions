[
  {
    "start": "0",
    "end": "23000"
  },
  {
    "text": "hi everyone my name is juhi Patel and I'm a dynamodb specialist Solutions architect here at AWS in this video I'll",
    "start": "539",
    "end": "7560"
  },
  {
    "text": "be covering the performance efficiency pillar of the dynamodb well architected lens so let's get started the",
    "start": "7560",
    "end": "14099"
  },
  {
    "text": "performance efficiency pillar focuses on using Computing resources efficiently to meet the current requirements and to",
    "start": "14099",
    "end": "20160"
  },
  {
    "text": "maintain that efficiency as requirements change one of the key considerations for this",
    "start": "20160",
    "end": "25800"
  },
  {
    "start": "23000",
    "end": "23000"
  },
  {
    "text": "pillar is to evaluate if the workload at hand is oltp or not as you may know dynamodb is a key value store so it",
    "start": "25800",
    "end": "32940"
  },
  {
    "text": "cannot natively support analytical queries or aggregations as required by olap workloads",
    "start": "32940",
    "end": "38520"
  },
  {
    "text": "also dynamodb is optimized for compute unlike relational databases that are optimized for storage so we work",
    "start": "38520",
    "end": "45300"
  },
  {
    "text": "backwards from our access patterns to pre-built items in the format that they need to be retrieved in it is important",
    "start": "45300",
    "end": "51420"
  },
  {
    "text": "to know most of our access patterns before we jump into modeling so that we can choose appropriate partition Keys",
    "start": "51420",
    "end": "57260"
  },
  {
    "text": "dynamodb scales horizontally so it is important to choose partition keys that enable horizontal scaling if partition",
    "start": "57260",
    "end": "64140"
  },
  {
    "text": "keys are a low cardinality attribute for example they can cause scaling bottlenecks we also recommend design",
    "start": "64140",
    "end": "70200"
  },
  {
    "text": "best practices to avoid such bottlenecks and avoid throttling of requests as a result",
    "start": "70200",
    "end": "75240"
  },
  {
    "text": "next it is very important to identify suitable throughput mode for performance efficiency some workloads are more spiky",
    "start": "75240",
    "end": "82080"
  },
  {
    "text": "and random while there are others that are more predictable and they change gradually based on such characteristics",
    "start": "82080",
    "end": "87720"
  },
  {
    "text": "we decide which throughput Mode best serves our traffic another important design consideration",
    "start": "87720",
    "end": "93000"
  },
  {
    "text": "is client-side SDK tuning this is primarily for latency optimization load",
    "start": "93000",
    "end": "98460"
  },
  {
    "text": "testing largely helps identify any room for SDK tuning lastly if the workload",
    "start": "98460",
    "end": "103740"
  },
  {
    "text": "uses caching we must use a suitable caching strategy if dynamodp accelerator or Dax is the caching service in use we",
    "start": "103740",
    "end": "111000"
  },
  {
    "text": "recommend monitoring and right sizing Dax clusters as per the workload at hand let's jump into the details of these",
    "start": "111000",
    "end": "117299"
  },
  {
    "text": "considerations now we'll start with the basic dynamodb concepts dynamodb is a",
    "start": "117299",
    "end": "122579"
  },
  {
    "text": "serverless nosql database service so you work with tables instead of instances or clusters table is a collection of items",
    "start": "122579",
    "end": "130020"
  },
  {
    "text": "and items can be thought of as analogous to rows in relational databases dynamodb",
    "start": "130020",
    "end": "135480"
  },
  {
    "text": "being a key values data store a key uniquely identifies each item in your table",
    "start": "135480",
    "end": "141900"
  },
  {
    "text": "the key can either be a simple primary key in terms of the partition key or it",
    "start": "141900",
    "end": "147840"
  },
  {
    "text": "can be a composite primary key in terms of the partition key and sort key partition key determines the physical",
    "start": "147840",
    "end": "153720"
  },
  {
    "text": "location of your data it is mandatory and it should be a high cardinality attribute to ensure even distribution of",
    "start": "153720",
    "end": "159840"
  },
  {
    "text": "your data optionally you can specify a sort key as well in this case your",
    "start": "159840",
    "end": "165000"
  },
  {
    "text": "primary key is composite which means the combination of partition key and sort key uniquely identifies your items sort",
    "start": "165000",
    "end": "171480"
  },
  {
    "text": "keys are used to model one-to-many relationships which means one partition key value can be associated with",
    "start": "171480",
    "end": "177300"
  },
  {
    "text": "multiple sort key values and sort Keys enable you to perform range queries such as greater than less",
    "start": "177300",
    "end": "183300"
  },
  {
    "text": "than begins with and so on let's look at Global secondary indexes",
    "start": "183300",
    "end": "189000"
  },
  {
    "text": "or gsis now",
    "start": "189000",
    "end": "192019"
  },
  {
    "text": "is there a copy of your table organized in a different manner you can choose any arbitrary key schema for your GSI",
    "start": "194280",
    "end": "200540"
  },
  {
    "text": "dynamodb is responsible for populating items on your gsis asynchronously so you",
    "start": "200540",
    "end": "206280"
  },
  {
    "text": "cannot write directly to your gsis items from the table are propagated to the GSI only if GSI key attributes are present",
    "start": "206280",
    "end": "213599"
  },
  {
    "text": "on the items in the table gsis are maintained as Separate dynamodb Tables you should configure enough right",
    "start": "213599",
    "end": "220140"
  },
  {
    "text": "capacity on your gsis so that they cope up with the right activity on your table and you should also make sure that the",
    "start": "220140",
    "end": "227040"
  },
  {
    "text": "GSI partition key is high cardinality so that gsis don't end up being a scaling bottleneck",
    "start": "227040",
    "end": "233159"
  },
  {
    "text": "you don't want something like an order status to be your GSI partition key for example because the partition key is",
    "start": "233159",
    "end": "238680"
  },
  {
    "text": "used to figure out where your data is going to be stored and if you are inserting 10 000 orders per second with",
    "start": "238680",
    "end": "243900"
  },
  {
    "text": "a status new that's all going to end up in one dynamodb partition if the order",
    "start": "243900",
    "end": "249360"
  },
  {
    "text": "status is your partition key you can have up to 20 GSS on your table and their capacities are independent of the",
    "start": "249360",
    "end": "255720"
  },
  {
    "text": "page table let's understand what capacity units are now when we say one wcu or one write",
    "start": "255720",
    "end": "262019"
  },
  {
    "start": "257000",
    "end": "257000"
  },
  {
    "text": "capacity unit it stands for one right per second of an item up to 1 KB in size",
    "start": "262019",
    "end": "267540"
  },
  {
    "text": "for reads you have two consistency options a strongly consistent read is one read per second for an item up to 4",
    "start": "267540",
    "end": "274020"
  },
  {
    "text": "KB in size using one RCU or one read capacity unit and eventually consistent",
    "start": "274020",
    "end": "279600"
  },
  {
    "text": "read is one read per second for an item up to 8 KB in size or it can be defined",
    "start": "279600",
    "end": "284759"
  },
  {
    "text": "as 2 reads per second of items up to 4 KB in size using one RCU now dynamodb",
    "start": "284759",
    "end": "291120"
  },
  {
    "text": "being nosql it scales horizontally and the unit for scaling is called a partition a table is divided into",
    "start": "291120",
    "end": "297479"
  },
  {
    "text": "multiple partitions depending on the storage read and write capacity each partition can handle up to 3000 read",
    "start": "297479",
    "end": "304080"
  },
  {
    "text": "capacity units 1000 ride capacity units and 10 GB of data",
    "start": "304080",
    "end": "310620"
  },
  {
    "text": "let's look at the partition key and item storage in play now suppose you have a table storing data",
    "start": "310620",
    "end": "317040"
  },
  {
    "text": "about orders on the right hand side you can see that the key space is divided into corresponding subsections or",
    "start": "317040",
    "end": "323220"
  },
  {
    "text": "partitions order ID is the partition key here the partition key value is hashed to determine the physical location of",
    "start": "323220",
    "end": "329759"
  },
  {
    "text": "the item in the key space so hash of 1 comes out to be 7B here 7B Falls between",
    "start": "329759",
    "end": "335759"
  },
  {
    "text": "5 5 and AA so this item sits in Partition B similarly hash of 2 comes out to be 48",
    "start": "335759",
    "end": "342600"
  },
  {
    "text": "which is between 0 0 and 5 5 which corresponds to partition a and lastly",
    "start": "342600",
    "end": "347940"
  },
  {
    "text": "hash of 3 comes out to be CD so it ends up in Partition C you can see that the",
    "start": "347940",
    "end": "353220"
  },
  {
    "text": "hashing algorithm randomly distributes data to different partitions despite having incremental values in the",
    "start": "353220",
    "end": "358560"
  },
  {
    "text": "partition key the hashing algorithm is not configurable it is a part of the manage service by default and it ensures",
    "start": "358560",
    "end": "365100"
  },
  {
    "text": "height entropy for highly Cardinal partition key values even if they are incremental",
    "start": "365100",
    "end": "371220"
  },
  {
    "start": "371000",
    "end": "371000"
  },
  {
    "text": "let's look at this interesting feature called adaptive capacity suppose you have one partition in your table",
    "start": "371220",
    "end": "376860"
  },
  {
    "text": "initially and you're driving disproportionately high amount of traffic for two items Foo and Bar in",
    "start": "376860",
    "end": "383100"
  },
  {
    "text": "this case adaptive capacity proactively monitors such situations and tries to isolate",
    "start": "383100",
    "end": "388380"
  },
  {
    "text": "higher traffic items onto their own partitions so you can see that Foo and bar have their own partitions now",
    "start": "388380",
    "end": "395340"
  },
  {
    "text": "say you continue driving high traffic to Foo dynamodb redistributes this traffic",
    "start": "395340",
    "end": "400500"
  },
  {
    "text": "again and you have all these different partitions that are equally sized and balanced in terms of traffic now as a",
    "start": "400500",
    "end": "407880"
  },
  {
    "text": "developer you didn't have to change a single thing no code changes no data changes dynamodb literally adjusts to",
    "start": "407880",
    "end": "414240"
  },
  {
    "text": "fit your usage patterns this can ultimately result in a single key on a single partition which shifts the limits",
    "start": "414240",
    "end": "420960"
  },
  {
    "text": "from 3000 rcos and thousand wsus per partition to 3000 rcos and thousand wsus",
    "start": "420960",
    "end": "427800"
  },
  {
    "text": "per key per item this Auto partition functionality will not be performed in",
    "start": "427800",
    "end": "432960"
  },
  {
    "text": "some cases where it won't help for example in cases where there is higher write throughput with the same partition",
    "start": "432960",
    "end": "438600"
  },
  {
    "text": "key and monolithically incrementing sort key like current timestamp the heat will just move over the partition and",
    "start": "438600",
    "end": "445380"
  },
  {
    "text": "splitting the partitions will not help also the split isn't immediate and requires higher traffic over periods of",
    "start": "445380",
    "end": "451860"
  },
  {
    "text": "time in the meantime throttling may occur that's why our data modeling should not be dependent on these Auto",
    "start": "451860",
    "end": "457680"
  },
  {
    "text": "splits one other case where this split does not work is when tables have a local",
    "start": "457680",
    "end": "462960"
  },
  {
    "text": "secondary index let's explore the data modeling aspect now",
    "start": "462960",
    "end": "468360"
  },
  {
    "start": "468000",
    "end": "468000"
  },
  {
    "text": "dynamodb is suitable for oltp and key value workloads it does not support aggregations or joints to facilitate",
    "start": "468360",
    "end": "475199"
  },
  {
    "text": "olap workloads we first understand the use case the various entities involved in the use case and their relationships",
    "start": "475199",
    "end": "482039"
  },
  {
    "text": "with each other we then identify and document various access patterns that our table is",
    "start": "482039",
    "end": "487440"
  },
  {
    "text": "expected to serve we follow and access patterns first approach to data modeling we pre-build",
    "start": "487440",
    "end": "493560"
  },
  {
    "text": "aggregated items as our application would need to read them nosql is optimized for compute so we do not",
    "start": "493560",
    "end": "499680"
  },
  {
    "text": "normalize the data and then perform joints on it instead we build the data model according to the access pattern",
    "start": "499680",
    "end": "505379"
  },
  {
    "text": "and store related data together we try to keep the number of tables to minimum we start with one table and determine",
    "start": "505379",
    "end": "511560"
  },
  {
    "text": "the partition key and sort key for that table then we check if secondary indexes are needed to support the remaining",
    "start": "511560",
    "end": "517200"
  },
  {
    "text": "access patterns we then document how each identified access pattern is handled by our design",
    "start": "517200",
    "end": "523020"
  },
  {
    "text": "it is important to validate the design iterate through it and test the design to see if it satisfies all the access",
    "start": "523020",
    "end": "529320"
  },
  {
    "text": "patterns as they change over time it is very important to choose the right",
    "start": "529320",
    "end": "535980"
  },
  {
    "start": "533000",
    "end": "533000"
  },
  {
    "text": "partition key for your table it should be a high cardinality attribute to ensure even distribution of data across",
    "start": "535980",
    "end": "542220"
  },
  {
    "text": "the key space this helps avoid throttling of requests due to hotkeys and hot partitions it",
    "start": "542220",
    "end": "548100"
  },
  {
    "text": "also helps us build targeted queries to enable horizontal scaling",
    "start": "548100",
    "end": "553320"
  },
  {
    "text": "since dynamodb is serverless we talk about workloads in terms of read and write requests as opposed to instances",
    "start": "553320",
    "end": "560100"
  },
  {
    "text": "or servers dynamodb has two capacity modes the",
    "start": "560100",
    "end": "565380"
  },
  {
    "start": "562000",
    "end": "562000"
  },
  {
    "text": "first one is called the provision mode where you allocate capacity to your table you have an option of using Auto scaling",
    "start": "565380",
    "end": "572339"
  },
  {
    "text": "where you specify the minimum and maximum expected traffic on your table the capacity is adjusted as per",
    "start": "572339",
    "end": "578459"
  },
  {
    "text": "consumption and you can also configure a Target utilization threshold to determine if scaling is needed",
    "start": "578459",
    "end": "584760"
  },
  {
    "text": "the second one is called the on-demand mode it is a paper request mode so no capacity allocation is required dynamodb",
    "start": "584760",
    "end": "592320"
  },
  {
    "text": "automatically scales to handle increasing traffic now a valid question is what is the suitable mode for your workload",
    "start": "592320",
    "end": "600620"
  },
  {
    "text": "the provision mode is suitable for traffic that changes steadily and where there are no sudden bursts of traffic it",
    "start": "601019",
    "end": "607440"
  },
  {
    "text": "works well for predictable workloads or events with known traffic you would typically opt for on-demand",
    "start": "607440",
    "end": "614040"
  },
  {
    "text": "mode when you have new unprecedented workloads it also works well for frequently idle workloads",
    "start": "614040",
    "end": "621120"
  },
  {
    "start": "620000",
    "end": "620000"
  },
  {
    "text": "this is an example of the provision mode with auto scaling the blue line is the provision capacity and the orange line",
    "start": "621120",
    "end": "627600"
  },
  {
    "text": "is the consumed capacity reads and write scale independently of each other you",
    "start": "627600",
    "end": "632760"
  },
  {
    "text": "can see that a Headroom is maintained between the provision capacity and the consume capacity this Headroom is based",
    "start": "632760",
    "end": "638760"
  },
  {
    "text": "on the configured Target utilization Auto scaling monitors your capacity for a couple of minutes and decides whether",
    "start": "638760",
    "end": "645180"
  },
  {
    "text": "scaling is needed it is a reactive mechanism and that's why it is suitable for gradually changing traffic",
    "start": "645180",
    "end": "652560"
  },
  {
    "start": "652000",
    "end": "652000"
  },
  {
    "text": "this is a typical use case for the on-demand mode the spikes are random and unpredictable and the workload seems to",
    "start": "652560",
    "end": "658920"
  },
  {
    "text": "be frequently idle the spikes here are very Steep and short-lived this does not allow enough time for auto scaling to",
    "start": "658920",
    "end": "665459"
  },
  {
    "text": "react so this is better handle using the on-demand mode dynamodb horizontally scales by adding",
    "start": "665459",
    "end": "672959"
  },
  {
    "text": "partitions on the fly as your traffic changes or your data storage increases however there are use cases where you",
    "start": "672959",
    "end": "679380"
  },
  {
    "text": "know beforehand that there is going to be high amount of traffic on your table in such cases you can pre-warm or",
    "start": "679380",
    "end": "685380"
  },
  {
    "text": "pre-scale your table by creating it in the provision mode with large WSU and RCU values dynamodb does not scale down",
    "start": "685380",
    "end": "692880"
  },
  {
    "text": "your partitions currently so you can either reduce the capacity or update the table to use on demand mode once it is",
    "start": "692880",
    "end": "699540"
  },
  {
    "text": "created let's look at identifying the causes of throttling and managing them the first",
    "start": "699540",
    "end": "706440"
  },
  {
    "start": "706000",
    "end": "706000"
  },
  {
    "text": "scenario that we'll talk about is throttling despite having enough provision capacity and this can happen",
    "start": "706440",
    "end": "711899"
  },
  {
    "text": "because the cloudwatch metric granularity for dynamodb is one minute but the dynamodb rate limits are applied",
    "start": "711899",
    "end": "717839"
  },
  {
    "text": "per second the second level data points are summed up and averaged over 60 seconds as cloudwatch metric data points",
    "start": "717839",
    "end": "724620"
  },
  {
    "text": "this could be misunderstood as the consumption being less than the provision capacity if the workload is",
    "start": "724620",
    "end": "730560"
  },
  {
    "text": "queued in time which means there is a high workload only for a few seconds in a minute this could lead to throttling",
    "start": "730560",
    "end": "736260"
  },
  {
    "text": "but the cloud watch metrics can indicate that the consumption has been less than the provision capacity for example if",
    "start": "736260",
    "end": "743579"
  },
  {
    "text": "you provision 60ws use for your table and you perform 3600 rights in one minute however you",
    "start": "743579",
    "end": "750839"
  },
  {
    "text": "are driving all those 3600 requests in one second with no request for the rest of the minute this might result in",
    "start": "750839",
    "end": "757260"
  },
  {
    "text": "throttling because for that second you are expected to be within the provision capacity of 60ws use",
    "start": "757260",
    "end": "763800"
  },
  {
    "text": "the next scenario is throttling despite using Auto scaling we've been discussing that the auto scaling is a reactive",
    "start": "763800",
    "end": "770100"
  },
  {
    "text": "mechanism it follows a Target tracking policy which means it monitors capacity consumption and triggers the scale up",
    "start": "770100",
    "end": "776399"
  },
  {
    "text": "after two consecutive data points from the consumed capacity metrics Auto scaling is a reactive Behavior",
    "start": "776399",
    "end": "783000"
  },
  {
    "text": "suitable for smoothly changing traffic as we said earlier sudden bursts of traffic or spikes of traffic can still",
    "start": "783000",
    "end": "789300"
  },
  {
    "text": "lead to throttling if Auto scaling does not get enough time to react to resolve this issue you can add Jitter an",
    "start": "789300",
    "end": "795779"
  },
  {
    "text": "exponential back off to your API calls you can also change your target utilization threshold the default is 70",
    "start": "795779",
    "end": "802820"
  },
  {
    "text": "but changing it to a smaller value like 50 or 40 percent can make Auto scaling",
    "start": "802820",
    "end": "808380"
  },
  {
    "text": "more aggressive and reactive to smaller changes in traffic another question is about on-demand",
    "start": "808380",
    "end": "813899"
  },
  {
    "text": "tables can on-demand tables throttle the answer is yes for newly created on-demand tables you can immediately",
    "start": "813899",
    "end": "820079"
  },
  {
    "text": "drive up to 4000 write request units and 12 000 read request units for an",
    "start": "820079",
    "end": "825660"
  },
  {
    "text": "existing table that you switch to the on-demand capacity the previous Peak is half the maximum provision throughput",
    "start": "825660",
    "end": "831720"
  },
  {
    "text": "for the table or the settings for a newly created table whichever is higher",
    "start": "831720",
    "end": "836760"
  },
  {
    "text": "if your traffic is more than double the previous Peak within 30 minutes you might experience throttling even for",
    "start": "836760",
    "end": "843060"
  },
  {
    "text": "on-demand tables it's best practice to spread your traffic growth over at least 30 minutes before exceeding double your",
    "start": "843060",
    "end": "849120"
  },
  {
    "text": "previous Peak you can use the consumed read capacity units and consume ride capacity units in",
    "start": "849120",
    "end": "855120"
  },
  {
    "text": "Amazon cloudwatch to monitor traffic to this table you can also pre-scale your tables as per expected peak of requests",
    "start": "855120",
    "end": "862680"
  },
  {
    "text": "the final throttling scenario that we'll talk about is hot partitions this can happen in the provision mode and the",
    "start": "862680",
    "end": "869399"
  },
  {
    "text": "on-demand mode as well if the traffic exceeds the per partition limits of 3000 rcos and thousand wsus your requests can",
    "start": "869399",
    "end": "876959"
  },
  {
    "text": "be throttled this can also happen due to hotkeys and data to resolve this you",
    "start": "876959",
    "end": "882120"
  },
  {
    "text": "should randomize requests such that request to hotkeys are distributed over time if you face re-throttling due to",
    "start": "882120",
    "end": "888240"
  },
  {
    "text": "hotkeys a caching solution such as Dax can help alleviate the issue if you have hotkeys while writing you can",
    "start": "888240",
    "end": "894420"
  },
  {
    "text": "artificially Shard your keys by adding suffixes artificial sharding helps represent a single key as multiple items",
    "start": "894420",
    "end": "901399"
  },
  {
    "text": "Distributing traffic over multiple items rather than a single key helps avoid scaling bottlenecks and helps avoid",
    "start": "901399",
    "end": "907860"
  },
  {
    "text": "hotkeys using cloudwatch contributor insights you can monitor key level capacity",
    "start": "907860",
    "end": "913440"
  },
  {
    "text": "consumption and identify the most accessed or most throttle Keys it can be",
    "start": "913440",
    "end": "918600"
  },
  {
    "text": "enabled with one click or one API call and you can customize the granularity the time window you can also enable them",
    "start": "918600",
    "end": "925380"
  },
  {
    "text": "separately for the tables and gsis wherever you want to monitor for hotkeys let's see how we can optimize dynamodb",
    "start": "925380",
    "end": "932579"
  },
  {
    "text": "latency now it is important to perform load testing using realistic scenarios and data benchmarks should confirm with",
    "start": "932579",
    "end": "939660"
  },
  {
    "start": "934000",
    "end": "934000"
  },
  {
    "text": "your application slas and resources must be pre-owned to handle the load test load tests allow you to establish",
    "start": "939660",
    "end": "946139"
  },
  {
    "text": "benchmarks with respect to kpis such as average latency and throughput you can also identify the most optimal SDK",
    "start": "946139",
    "end": "952920"
  },
  {
    "text": "settings for your use case using load tests it is important to understand that end",
    "start": "952920",
    "end": "958860"
  },
  {
    "start": "956000",
    "end": "956000"
  },
  {
    "text": "to end latency includes Network latency and client latency as well to understand the server-side latency Trend you can",
    "start": "958860",
    "end": "965459"
  },
  {
    "text": "monitor and set alarms on the successful request latency metric this metric does not account for Network or client",
    "start": "965459",
    "end": "972000"
  },
  {
    "text": "latency owing to how distributed systems like dynamodb work the maximum statistics for this metric might have",
    "start": "972000",
    "end": "979260"
  },
  {
    "text": "random spikes so the best practice is to check for consistent average Trends in this metric we have additional services",
    "start": "979260",
    "end": "985800"
  },
  {
    "text": "and features such as AWS X-ray and AWS SDK metric logging that can help identify the source of increased latency",
    "start": "985800",
    "end": "993540"
  },
  {
    "text": "let's walk through some best practices that can help reduce latency firstly you can tune SDK parameters such as the",
    "start": "993540",
    "end": "1000259"
  },
  {
    "start": "994000",
    "end": "994000"
  },
  {
    "text": "request timeout this enables latent requests to time out and fail much faster this causes the client to abandon",
    "start": "1000259",
    "end": "1006560"
  },
  {
    "text": "High latency requests after the specified period and then send a second request that usually completes faster",
    "start": "1006560",
    "end": "1012440"
  },
  {
    "text": "than the first you have request timeout and client execution timeout parameters for Java there are similar such",
    "start": "1012440",
    "end": "1018980"
  },
  {
    "text": "client-side SDK settings in different sdks the next step is to reduce the",
    "start": "1018980",
    "end": "1024079"
  },
  {
    "text": "distance between the client and the dynamodb endpoint if you have globally dispersed users consider using Global",
    "start": "1024079",
    "end": "1030500"
  },
  {
    "text": "tables with global tables you can specify the AWS regions where you want the table to be available this can",
    "start": "1030500",
    "end": "1037040"
  },
  {
    "text": "significantly reduce latency for your users along with resolving re-throttling issues caching can also help optimize",
    "start": "1037040",
    "end": "1043880"
  },
  {
    "text": "latency if your traffic is read heavy consider using a caching service such as Dax or dynamodb accelerator Dax is a",
    "start": "1043880",
    "end": "1051500"
  },
  {
    "text": "fully managed highly available in memory cache for dynamodb and it delivers up to 10x performance Improvement which means",
    "start": "1051500",
    "end": "1058580"
  },
  {
    "text": "the latency goes down from milliseconds to microseconds and Dax serves even millions of requests per second",
    "start": "1058580",
    "end": "1065360"
  },
  {
    "text": "another technique to optimize latency is to send dummy traffic or reuse connections when your tables are idle",
    "start": "1065360",
    "end": "1071720"
  },
  {
    "text": "consider having the client send dummy traffic to your tables also consider using client connections or use",
    "start": "1071720",
    "end": "1077840"
  },
  {
    "text": "connection pooling these techniques help avoid the extra cost and time associated with TLS handshakes and authentication",
    "start": "1077840",
    "end": "1084620"
  },
  {
    "text": "they also keep the internal caches warm for dynamodb so that the latency is kept low lastly if your application does not",
    "start": "1084620",
    "end": "1091880"
  },
  {
    "text": "require strongly consistent reads consider using eventually consistent reads eventually consistent reads are",
    "start": "1091880",
    "end": "1097940"
  },
  {
    "text": "cheaper and are less likely to experience High latency by Design some operations in dynamodb are more",
    "start": "1097940",
    "end": "1104960"
  },
  {
    "start": "1102000",
    "end": "1102000"
  },
  {
    "text": "efficient than the others with batch operations like batch write item and batch cat item the number of network",
    "start": "1104960",
    "end": "1110539"
  },
  {
    "text": "round trips are quite less compared to individual operations the application needs to handle less serialization and",
    "start": "1110539",
    "end": "1116720"
  },
  {
    "text": "deserialization of traffic as a result the CPU usage goes down and each",
    "start": "1116720",
    "end": "1122059"
  },
  {
    "text": "application server can handle higher throughput so less number of application servers",
    "start": "1122059",
    "end": "1127100"
  },
  {
    "text": "can ultimately do the same amount of work scans on large tables can be expensive",
    "start": "1127100",
    "end": "1132320"
  },
  {
    "text": "and time consuming it is important to design your schema such that you are able to Target a particular partition",
    "start": "1132320",
    "end": "1137900"
  },
  {
    "text": "key using the query operation a scan runs through all the items in the table and that's why we prefer query",
    "start": "1137900",
    "end": "1144320"
  },
  {
    "text": "over scan for needle and hasta kind of use cases where a handful of items out of millions are relevant you can use",
    "start": "1144320",
    "end": "1151160"
  },
  {
    "text": "past gsis rather than scan and filter sparse gsis are typically useful in",
    "start": "1151160",
    "end": "1156380"
  },
  {
    "text": "cases where you need escalations or top three ranks on leaderboards for example finally if you have small number of",
    "start": "1156380",
    "end": "1163100"
  },
  {
    "text": "access patterns where you scan your tables or gsis use parallel scans for a",
    "start": "1163100",
    "end": "1168320"
  },
  {
    "text": "faster way of reading all items rather than sequential scans consider the key space range from 0 0 to",
    "start": "1168320",
    "end": "1175580"
  },
  {
    "start": "1172000",
    "end": "1172000"
  },
  {
    "text": "FF and all the items existing in the tables key space need to be read using a scan operation a Serial scan would go",
    "start": "1175580",
    "end": "1182840"
  },
  {
    "text": "from 0 0 to FF and would be time consuming with parallel scan you can divide the key space in multiple",
    "start": "1182840",
    "end": "1188840"
  },
  {
    "text": "segments and divide your application into multiple workers or threads each worker in an application can Target",
    "start": "1188840",
    "end": "1195740"
  },
  {
    "text": "one segment start reading from the start of the segment to the last address of",
    "start": "1195740",
    "end": "1200960"
  },
  {
    "text": "the segment these workers read parallely and this results in a speedier and performance scan",
    "start": "1200960",
    "end": "1206900"
  },
  {
    "text": "the total number of segments in the parallel scan can be configured by you depending on the number of available",
    "start": "1206900",
    "end": "1212059"
  },
  {
    "text": "workers in your application most workloads are satisfied by the typical single digit millisecond average",
    "start": "1212059",
    "end": "1218720"
  },
  {
    "text": "latency provided by dynamodb however there can be some use cases where there are repeated set of reads or hotkeys or",
    "start": "1218720",
    "end": "1226220"
  },
  {
    "text": "the microsecond latency requirement in such cases it might be beneficial to use caching",
    "start": "1226220",
    "end": "1232280"
  },
  {
    "start": "1232000",
    "end": "1232000"
  },
  {
    "text": "there can be different ways of using a cache side caches are general purpose caches that are decoupled from the",
    "start": "1232280",
    "end": "1238640"
  },
  {
    "text": "underlying data store the application first tries to read from the cache if there is a cache missed the application",
    "start": "1238640",
    "end": "1244220"
  },
  {
    "text": "tries to fetch the data from the underlying data store to ensure that the data is present for the subsequent read",
    "start": "1244220",
    "end": "1249799"
  },
  {
    "text": "it is written to the cache after the cache Miss it is important to note that this design is associated with penalties",
    "start": "1249799",
    "end": "1256520"
  },
  {
    "text": "because the cache does not sit in line with the underlying database so it can result in multiple round trips and",
    "start": "1256520",
    "end": "1262220"
  },
  {
    "text": "additional connection handling the second caching strategy is called the read through cache Dax is a typical",
    "start": "1262220",
    "end": "1268340"
  },
  {
    "text": "read-through crash a read through cash sits in line with the database and fetches item from the underlying data",
    "start": "1268340",
    "end": "1274100"
  },
  {
    "text": "store when there is a cache Miss the items are then returned directly from the cache for a cache the technique",
    "start": "1274100",
    "end": "1280340"
  },
  {
    "text": "of populating the cache only when data is requested is referred to as lazy loading similar to a read through cache",
    "start": "1280340",
    "end": "1287179"
  },
  {
    "text": "right through cache also sits in line with the database and updates the cache as data is written to the underlying",
    "start": "1287179",
    "end": "1293000"
  },
  {
    "text": "data store Dax is a right through cache as well as soon as right to the underlying data store is successful the",
    "start": "1293000",
    "end": "1299360"
  },
  {
    "text": "new data is populated in the cache for any subsequent reads if the write is unsuccessful the exception is returned",
    "start": "1299360",
    "end": "1305900"
  },
  {
    "text": "to the application without writing the new data to the cache this makes sure that your underlying data store and cash",
    "start": "1305900",
    "end": "1311840"
  },
  {
    "text": "are in sync with right through caches you don't have the additional overhead of writing or",
    "start": "1311840",
    "end": "1317659"
  },
  {
    "text": "testing cash population or invalidation logic rights have a slightly higher",
    "start": "1317659",
    "end": "1322760"
  },
  {
    "text": "latency with right through caches because of the additional hop but it makes sure that the data is consistent",
    "start": "1322760",
    "end": "1328460"
  },
  {
    "text": "between the underlying data store and the cache the last strategy is to use a right back",
    "start": "1328460",
    "end": "1333980"
  },
  {
    "text": "or right behind cash here the data is written to the cache directly and there is a background process which populates",
    "start": "1333980",
    "end": "1340580"
  },
  {
    "text": "the underlying data store with the data written in the cache the main drawback of right back caches is the risk of data",
    "start": "1340580",
    "end": "1347299"
  },
  {
    "text": "loss due to rights being asynchronous we've been talking about Dax for a while now dynamodb accelerator or Dax can be",
    "start": "1347299",
    "end": "1354799"
  },
  {
    "start": "1349000",
    "end": "1349000"
  },
  {
    "text": "used as a read through or write through cache as we talked earlier it is fully API compatible with dynamodb because of",
    "start": "1354799",
    "end": "1361640"
  },
  {
    "text": "which it seamlessly intercepts the API calls that an application would normally make to dynamodb this makes sure that",
    "start": "1361640",
    "end": "1367700"
  },
  {
    "text": "the reads and writes are both reflected from the cache the benefits of using Dax include latency in microsecond",
    "start": "1367700",
    "end": "1374299"
  },
  {
    "text": "throughputs of millions of requests per second alleviation of hotkey issues and",
    "start": "1374299",
    "end": "1380419"
  },
  {
    "text": "potential cost savings by reducing the provision read capacity on dynamodb last",
    "start": "1380419",
    "end": "1385580"
  },
  {
    "text": "but not the least managed cash population and invalidation logic come as a part of the service with Dax it",
    "start": "1385580",
    "end": "1392299"
  },
  {
    "text": "doesn't matter what redistribution is the first request will be sent to the dynamodb table but every subsequent",
    "start": "1392299",
    "end": "1399020"
  },
  {
    "text": "request is fulfilled from memory tax clusters decide on your VPC and you",
    "start": "1399020",
    "end": "1404539"
  },
  {
    "start": "1401000",
    "end": "1401000"
  },
  {
    "text": "can configure the instance class and number of instances in your Dax cluster some portion of the memory in each",
    "start": "1404539",
    "end": "1410299"
  },
  {
    "text": "cluster node is used as the item cache and the item cache serves get item and badge get item requests some portion of",
    "start": "1410299",
    "end": "1417440"
  },
  {
    "text": "the memory is used as the query cache to Cache responses from query and scan operations the tax client in your",
    "start": "1417440",
    "end": "1423620"
  },
  {
    "text": "application issues a get item request to your Dax cluster Dax tries to read the item from the item cache if the item is",
    "start": "1423620",
    "end": "1430760"
  },
  {
    "text": "found tax returns is back to the client if there is a cache Miss which means the item is not in the cache Dax performs an",
    "start": "1430760",
    "end": "1437659"
  },
  {
    "text": "eventually consistent get item against the underlying dynamodb table the item returned by dynamodb is then cached in",
    "start": "1437659",
    "end": "1444440"
  },
  {
    "text": "the item cache and returned to the application if there are multiple nodes in the cluster the item is replicated to",
    "start": "1444440",
    "end": "1450620"
  },
  {
    "text": "all the other nodes in the cluster let's look at the flow of a write",
    "start": "1450620",
    "end": "1455780"
  },
  {
    "start": "1454000",
    "end": "1454000"
  },
  {
    "text": "request with tax say a user Alice sends a request to update an item in the product catalog table tax forwards this",
    "start": "1455780",
    "end": "1463340"
  },
  {
    "text": "request to dynamodb and the update succeeds tax then writes the item to the item cache and returns a successful",
    "start": "1463340",
    "end": "1470120"
  },
  {
    "text": "response to Alice from that point on until the item is ultimately evicted from the cache any user who reads the",
    "start": "1470120",
    "end": "1476840"
  },
  {
    "text": "item from Dax sees Alice's update a short time later another user Bob updates the same product catalog item",
    "start": "1476840",
    "end": "1483860"
  },
  {
    "text": "that Alice wrote earlier but Bob updates the item directly in dynamodb in this",
    "start": "1483860",
    "end": "1489260"
  },
  {
    "text": "case Dax does not automatically refresh its item cache in response to updates so Dax uses don't see Bob's update now",
    "start": "1489260",
    "end": "1496940"
  },
  {
    "text": "Alice reads the same item from Dax again the item is not evicted from the cash yet so Dax returns it to Alice without",
    "start": "1496940",
    "end": "1503539"
  },
  {
    "text": "accessing the dynamodb table now let's look at the right around",
    "start": "1503539",
    "end": "1509419"
  },
  {
    "text": "strategy in this example say a user Charlie wants to retrieve all of his scores so he sends a query to Dax",
    "start": "1509419",
    "end": "1515780"
  },
  {
    "text": "assuming that this query has not been issued before that's forwards the query to dynamodb for processing it stores the",
    "start": "1515780",
    "end": "1522679"
  },
  {
    "text": "results in the Dax query cache and then Returns the items to Charlie the results that remains available in query cache",
    "start": "1522679",
    "end": "1529100"
  },
  {
    "text": "unless it is evicted now suppose Charlie plays the meteor Blaster games and achieves a high score Charlie sends an",
    "start": "1529100",
    "end": "1535880"
  },
  {
    "text": "update item request to dynamodb modifying an item in the game score table because the request was sent to",
    "start": "1535880",
    "end": "1542179"
  },
  {
    "text": "dynamodb directly the item cache is not updated even if Charlie sends the update item",
    "start": "1542179",
    "end": "1548299"
  },
  {
    "text": "request via Dax the item cache gets updated but the query cache does not if",
    "start": "1548299",
    "end": "1553520"
  },
  {
    "text": "Charlie decides to rerun his earlier query to retrieve all of his game scores chati does not see the high score from",
    "start": "1553520",
    "end": "1559400"
  },
  {
    "text": "the meter Blaster games this is because the query cache and the item cash work independently from each other and do not",
    "start": "1559400",
    "end": "1566000"
  },
  {
    "text": "affect each other tax behavior is different for strongly consistent reads and transactional reads",
    "start": "1566000",
    "end": "1571820"
  },
  {
    "text": "Dax passes these requests directly to dynamodb after receiving a response from dynamodb the results are directly",
    "start": "1571820",
    "end": "1578960"
  },
  {
    "text": "returned to the client without caching them basically because Dax is not tightly coupled with dynamodb it does",
    "start": "1578960",
    "end": "1584960"
  },
  {
    "text": "not serve transactional or strongly consistent reads there are configurable TTL settings",
    "start": "1584960",
    "end": "1590600"
  },
  {
    "start": "1588000",
    "end": "1588000"
  },
  {
    "text": "available for the item cache and the query cache to control eviction the value for TTL for both the caches is 5",
    "start": "1590600",
    "end": "1597440"
  },
  {
    "text": "minutes by default there are a couple of special cases as well if you specify the item cache detail as 0 the data will be",
    "start": "1597440",
    "end": "1604279"
  },
  {
    "text": "persisted in the cache unless a write-through operation changes it or till the cash item is evicted by lru lru",
    "start": "1604279",
    "end": "1611000"
  },
  {
    "text": "stands for least recently used and this technique is used to evict items when there is no memory to store new entries",
    "start": "1611000",
    "end": "1616820"
  },
  {
    "text": "in the cache on the contrary if you specify the query cache detail as 0 the",
    "start": "1616820",
    "end": "1621860"
  },
  {
    "text": "query responses will not be cached at all this configuration for TTL might be typically used if you are planning to",
    "start": "1621860",
    "end": "1628220"
  },
  {
    "text": "use the item cache only sizing your Dax cluster appropriately is very important for it to be performant",
    "start": "1628220",
    "end": "1634580"
  },
  {
    "start": "1630000",
    "end": "1630000"
  },
  {
    "text": "you first make predictions about the volume of traffic that your application will send to Dax the nature of your",
    "start": "1634580",
    "end": "1640340"
  },
  {
    "text": "traffic and the expected cash hit rate Dax clusters cannot be scaled vertically so it is important to consider growth in",
    "start": "1640340",
    "end": "1647419"
  },
  {
    "text": "data volume and write traffic while sizing the cluster as a Next Step you create a cluster and send traffic to it",
    "start": "1647419",
    "end": "1653779"
  },
  {
    "text": "mirroring your estimates from the previous steps there can be multiple iterations of this step till you find a",
    "start": "1653779",
    "end": "1659299"
  },
  {
    "text": "suitable cluster configuration note that you can add more nodes and remove nodes on the fly as your traffic changes but",
    "start": "1659299",
    "end": "1666140"
  },
  {
    "text": "you cannot change the instance class or scale your Dax cluster vertically finally while your application is using",
    "start": "1666140",
    "end": "1673039"
  },
  {
    "text": "Dax in production you should monitor the cluster continuously to validate that it is still scaled correctly as your",
    "start": "1673039",
    "end": "1679580"
  },
  {
    "text": "workload changes more details about monitoring are discussed in the operational excellence pillar",
    "start": "1679580",
    "end": "1686799"
  },
  {
    "text": "to wrap up these are the typical questions that will help us figure out if there's further room to optimize",
    "start": "1686840",
    "end": "1691940"
  },
  {
    "text": "performance the first question to ask would be about your access patterns to reiterate we are focusing on compute",
    "start": "1691940",
    "end": "1698480"
  },
  {
    "text": "knowing access patterns beforehand helps us design the model such that you can fetch required data with minimum number",
    "start": "1698480",
    "end": "1704659"
  },
  {
    "text": "of lookups having information about the nature of your traffic helps you decide the suitable throughput mode",
    "start": "1704659",
    "end": "1710720"
  },
  {
    "text": "it also helps you decide whether any pre-scaling is required or if caching should be used the next question about",
    "start": "1710720",
    "end": "1716900"
  },
  {
    "text": "data access can indicate whether you can substitute scans with corresponding queries and whether there's room to use",
    "start": "1716900",
    "end": "1723559"
  },
  {
    "text": "batch operations instead of individual requests and if you should deploy a multivision setup or a single region",
    "start": "1723559",
    "end": "1729260"
  },
  {
    "text": "setup dynamodp has a feature called Global tables which enables multi-region active active setups this feature will",
    "start": "1729260",
    "end": "1735860"
  },
  {
    "text": "be discussed in detail in the reliability pillar latency is an important aspect of performance we",
    "start": "1735860",
    "end": "1741500"
  },
  {
    "text": "talked about considering the effect of client-side and network latency along with server-side latency we also",
    "start": "1741500",
    "end": "1747320"
  },
  {
    "text": "discussed the various latency optimization techniques such as reusing connections using Global tables using",
    "start": "1747320",
    "end": "1752840"
  },
  {
    "text": "caching and so on we discussed the various scenarios in which throttling can occur and how we",
    "start": "1752840",
    "end": "1758539"
  },
  {
    "text": "can manage and resolve thoroughly the next point is about scan ideally we should only scan sparse gsis and design",
    "start": "1758539",
    "end": "1765140"
  },
  {
    "text": "for targeted queries but in those small number of inevitable scan operations it",
    "start": "1765140",
    "end": "1770179"
  },
  {
    "text": "is a good idea to use parallel scans for better performance finally we had a section about when to use caching and",
    "start": "1770179",
    "end": "1776539"
  },
  {
    "text": "what are the different caching strategies if you are using Dax as a read through or write through cache it is important",
    "start": "1776539",
    "end": "1783440"
  },
  {
    "text": "to right size your cluster and choose the correct configuration for TTL and instance class it is also important to",
    "start": "1783440",
    "end": "1789799"
  },
  {
    "text": "consider that Dax cannot be scaled up vertically so you should factor in data set size growth and the increase in ride",
    "start": "1789799",
    "end": "1795980"
  },
  {
    "text": "traffic for your diets cluster you can monitor different Cloud watch metrics for your Dax cluster to understand if",
    "start": "1795980",
    "end": "1802460"
  },
  {
    "text": "more nodes need to be added to your cluster or if your cluster is over provisioned you also have other metrics",
    "start": "1802460",
    "end": "1808039"
  },
  {
    "text": "for cache eviction cache hits cache misses the CPU utilization and so on the",
    "start": "1808039",
    "end": "1813799"
  },
  {
    "text": "operational excellence pillar will talk about the important Dax metrics in more detail",
    "start": "1813799",
    "end": "1819380"
  },
  {
    "text": "with that we are at the end of this video please watch out for more videos covering the other pillars thank you",
    "start": "1819380",
    "end": "1826600"
  }
]
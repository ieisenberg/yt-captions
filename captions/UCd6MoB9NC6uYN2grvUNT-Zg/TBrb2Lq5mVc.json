[
  {
    "start": "0",
    "end": "20000"
  },
  {
    "text": "hi my name is Leonardo Moro and I build",
    "start": "560",
    "end": "2760"
  },
  {
    "text": "cold stuff in aw us using products in aw",
    "start": "2760",
    "end": "5080"
  },
  {
    "text": "us Marketplace thank you for joining me",
    "start": "5080",
    "end": "7759"
  },
  {
    "text": "I'm going to be talking about industry",
    "start": "7759",
    "end": "9080"
  },
  {
    "text": "Trends challenges and how you can solve",
    "start": "9080",
    "end": "10599"
  },
  {
    "text": "them today I want to talk about",
    "start": "10599",
    "end": "12519"
  },
  {
    "text": "generative AI large language models and",
    "start": "12519",
    "end": "15559"
  },
  {
    "text": "rag which means retrieval adantage",
    "start": "15559",
    "end": "17240"
  },
  {
    "text": "Generation all done in the cloud Because",
    "start": "17240",
    "end": "20199"
  },
  {
    "start": "20000",
    "end": "76000"
  },
  {
    "text": "unless you've been living under a rock",
    "start": "20199",
    "end": "21519"
  },
  {
    "text": "I'm sure you're all well aware of the",
    "start": "21519",
    "end": "22760"
  },
  {
    "text": "geni Cates it's easy to understand right",
    "start": "22760",
    "end": "25439"
  },
  {
    "text": "the feeds that are coming up from a",
    "start": "25439",
    "end": "27359"
  },
  {
    "text": "large language and multimodel models and",
    "start": "27359",
    "end": "29800"
  },
  {
    "text": "and the features that are being built",
    "start": "29800",
    "end": "31759"
  },
  {
    "text": "with them and around them are just all",
    "start": "31759",
    "end": "33760"
  },
  {
    "text": "inspiring they're really revolutionary",
    "start": "33760",
    "end": "35719"
  },
  {
    "text": "they're changing how we see the world",
    "start": "35719",
    "end": "38399"
  },
  {
    "text": "and because of that everybody out there",
    "start": "38399",
    "end": "40039"
  },
  {
    "text": "is looking to jump in on this Buzz which",
    "start": "40039",
    "end": "42559"
  },
  {
    "text": "means many many organizations uh have",
    "start": "42559",
    "end": "45160"
  },
  {
    "text": "built prototypes they've built Pilots",
    "start": "45160",
    "end": "47199"
  },
  {
    "text": "they've played around with Concepts as",
    "start": "47199",
    "end": "49000"
  },
  {
    "text": "to how they can both optimize their",
    "start": "49000",
    "end": "50440"
  },
  {
    "text": "internal",
    "start": "50440",
    "end": "51399"
  },
  {
    "text": "operations using J or Pro provide",
    "start": "51399",
    "end": "54280"
  },
  {
    "text": "revolutionary new features new",
    "start": "54280",
    "end": "55920"
  },
  {
    "text": "capabilities to users to external users",
    "start": "55920",
    "end": "58719"
  },
  {
    "text": "and a lot of these Concepts are being uh",
    "start": "58719",
    "end": "60879"
  },
  {
    "text": "piloted rely on rag retal man generation",
    "start": "60879",
    "end": "65760"
  },
  {
    "text": "and rag is a very efficient and fast way",
    "start": "65760",
    "end": "68119"
  },
  {
    "text": "to enrich the context the knowledge that",
    "start": "68119",
    "end": "70799"
  },
  {
    "text": "an llm has access to the data that it",
    "start": "70799",
    "end": "72840"
  },
  {
    "text": "has access to in order to generate a",
    "start": "72840",
    "end": "74159"
  },
  {
    "text": "response right to generate content and",
    "start": "74159",
    "end": "76640"
  },
  {
    "start": "76000",
    "end": "136000"
  },
  {
    "text": "allows you to do that without the",
    "start": "76640",
    "end": "78840"
  },
  {
    "text": "complexity and the usually very timec",
    "start": "78840",
    "end": "80799"
  },
  {
    "text": "consuming process of the alternatives",
    "start": "80799",
    "end": "83040"
  },
  {
    "text": "for example F tuning which can be very",
    "start": "83040",
    "end": "85479"
  },
  {
    "text": "much a trial and error process and and",
    "start": "85479",
    "end": "87600"
  },
  {
    "text": "you got to figure it out over time or",
    "start": "87600",
    "end": "90040"
  },
  {
    "text": "training which means you need data sets",
    "start": "90040",
    "end": "92200"
  },
  {
    "text": "that are properly prepared uh you need",
    "start": "92200",
    "end": "94280"
  },
  {
    "text": "to use you need a lot of compute",
    "start": "94280",
    "end": "95799"
  },
  {
    "text": "capacity to train those models and",
    "start": "95799",
    "end": "98159"
  },
  {
    "text": "that's fine because for the most part",
    "start": "98159",
    "end": "99439"
  },
  {
    "text": "all those new features that are coming",
    "start": "99439",
    "end": "100720"
  },
  {
    "text": "out that are using rag as its underlying",
    "start": "100720",
    "end": "103320"
  },
  {
    "text": "implementation are really being lost by",
    "start": "103320",
    "end": "105520"
  },
  {
    "text": "users and they they've been really",
    "start": "105520",
    "end": "107399"
  },
  {
    "text": "effective and and and value driving so",
    "start": "107399",
    "end": "110280"
  },
  {
    "text": "users are really digging into this",
    "start": "110280",
    "end": "111719"
  },
  {
    "text": "different prototypes and pilots and the",
    "start": "111719",
    "end": "114119"
  },
  {
    "text": "different concepts that are coming out",
    "start": "114119",
    "end": "115680"
  },
  {
    "text": "but what that means for the builders",
    "start": "115680",
    "end": "117039"
  },
  {
    "text": "like myself and the teams that are",
    "start": "117039",
    "end": "118119"
  },
  {
    "text": "operating those pilots and prototypes is",
    "start": "118119",
    "end": "119920"
  },
  {
    "text": "is that now they're basically sitting in",
    "start": "119920",
    "end": "121479"
  },
  {
    "text": "front of the challenge of scaling those",
    "start": "121479",
    "end": "123960"
  },
  {
    "text": "new services that they built which were",
    "start": "123960",
    "end": "126479"
  },
  {
    "text": "originally Pilots to the demands of a",
    "start": "126479",
    "end": "129560"
  },
  {
    "text": "full production scale environment and",
    "start": "129560",
    "end": "132200"
  },
  {
    "text": "that's what I want to talk about uh",
    "start": "132200",
    "end": "135360"
  },
  {
    "text": "today because there's also the need to",
    "start": "135360",
    "end": "138200"
  },
  {
    "start": "136000",
    "end": "183000"
  },
  {
    "text": "find out how to accelerate the",
    "start": "138200",
    "end": "139800"
  },
  {
    "text": "development and reduce the operational",
    "start": "139800",
    "end": "142080"
  },
  {
    "text": "complexity of supporting all the",
    "start": "142080",
    "end": "144040"
  },
  {
    "text": "infrastructure that is required for uh",
    "start": "144040",
    "end": "146200"
  },
  {
    "text": "the services to actually run in a",
    "start": "146200",
    "end": "147599"
  },
  {
    "text": "production environment so some of the",
    "start": "147599",
    "end": "149519"
  },
  {
    "text": "challenges is R uh well rag hinges on",
    "start": "149519",
    "end": "153000"
  },
  {
    "text": "Vector data and Vector search okay and",
    "start": "153000",
    "end": "155480"
  },
  {
    "text": "that means that you're actually storing",
    "start": "155480",
    "end": "157200"
  },
  {
    "text": "numerical representations of your data",
    "start": "157200",
    "end": "159640"
  },
  {
    "text": "and you're using that data to run",
    "start": "159640",
    "end": "161080"
  },
  {
    "text": "similarity searches right you're looking",
    "start": "161080",
    "end": "162840"
  },
  {
    "text": "to find data that looks like that can be",
    "start": "162840",
    "end": "165879"
  },
  {
    "text": "related to the content that your large",
    "start": "165879",
    "end": "167959"
  },
  {
    "text": "language model is using to generate its",
    "start": "167959",
    "end": "170720"
  },
  {
    "text": "response and you're going to need to do",
    "start": "170720",
    "end": "172640"
  },
  {
    "text": "this over an everg growing data set",
    "start": "172640",
    "end": "175120"
  },
  {
    "text": "because the more data that you add to",
    "start": "175120",
    "end": "177000"
  },
  {
    "text": "the context of the rag the better the",
    "start": "177000",
    "end": "179319"
  },
  {
    "text": "response that that you're bringing your",
    "start": "179319",
    "end": "180560"
  },
  {
    "text": "llm or you're being able to produce for",
    "start": "180560",
    "end": "182519"
  },
  {
    "text": "your llm and this all needs to happen",
    "start": "182519",
    "end": "185799"
  },
  {
    "start": "183000",
    "end": "241000"
  },
  {
    "text": "while keeping user interactive friendly",
    "start": "185799",
    "end": "187959"
  },
  {
    "text": "response time because your users are",
    "start": "187959",
    "end": "191080"
  },
  {
    "text": "already used to a certain level of",
    "start": "191080",
    "end": "193280"
  },
  {
    "text": "service from what you're giving them",
    "start": "193280",
    "end": "194959"
  },
  {
    "text": "what you're servicing to them right uh",
    "start": "194959",
    "end": "198239"
  },
  {
    "text": "they already run queries whenever they",
    "start": "198239",
    "end": "200400"
  },
  {
    "text": "use your service whether it's to",
    "start": "200400",
    "end": "201840"
  },
  {
    "text": "document storage to optic storage",
    "start": "201840",
    "end": "203560"
  },
  {
    "text": "relational databases and you're building",
    "start": "203560",
    "end": "206080"
  },
  {
    "text": "something that is also going to be user",
    "start": "206080",
    "end": "207400"
  },
  {
    "text": "interactive the user is going to make a",
    "start": "207400",
    "end": "209280"
  },
  {
    "text": "request and you're going to be waiting",
    "start": "209280",
    "end": "210439"
  },
  {
    "text": "there for a response so you need to make",
    "start": "210439",
    "end": "212480"
  },
  {
    "text": "sure that the response times that your",
    "start": "212480",
    "end": "214560"
  },
  {
    "text": "vector search and your vector data",
    "start": "214560",
    "end": "216040"
  },
  {
    "text": "repositories are providing are are",
    "start": "216040",
    "end": "218200"
  },
  {
    "text": "within that userfriendly reasonable",
    "start": "218200",
    "end": "219959"
  },
  {
    "text": "expected time frame and you'll also need",
    "start": "219959",
    "end": "222360"
  },
  {
    "text": "to understand how sary search is",
    "start": "222360",
    "end": "224280"
  },
  {
    "text": "actually getting to the data that the LM",
    "start": "224280",
    "end": "226400"
  },
  {
    "text": "is using to produce a response and this",
    "start": "226400",
    "end": "229040"
  },
  {
    "text": "is critical because you really need to",
    "start": "229040",
    "end": "231239"
  },
  {
    "text": "optimize those responses the value is",
    "start": "231239",
    "end": "234280"
  },
  {
    "text": "going to be driven by the content and",
    "start": "234280",
    "end": "238040"
  },
  {
    "text": "what the user can extract from the",
    "start": "238040",
    "end": "239920"
  },
  {
    "text": "capabilities that you're not bringing",
    "start": "239920",
    "end": "241040"
  },
  {
    "start": "241000",
    "end": "361000"
  },
  {
    "text": "into production and we all know that",
    "start": "241040",
    "end": "243000"
  },
  {
    "text": "users are Relentless and and they're in",
    "start": "243000",
    "end": "244519"
  },
  {
    "text": "Need for new stuff all the time and that",
    "start": "244519",
    "end": "246720"
  },
  {
    "text": "means that the very same builders that",
    "start": "246720",
    "end": "248720"
  },
  {
    "text": "are not trying to support and get these",
    "start": "248720",
    "end": "250519"
  },
  {
    "text": "Pilots into production well they also",
    "start": "250519",
    "end": "252560"
  },
  {
    "text": "have to support the ongoing development",
    "start": "252560",
    "end": "254519"
  },
  {
    "text": "of more feature requests they are going",
    "start": "254519",
    "end": "256280"
  },
  {
    "text": "to be started getting bug reports Etc",
    "start": "256280",
    "end": "258600"
  },
  {
    "text": "right um and that needs more development",
    "start": "258600",
    "end": "261160"
  },
  {
    "text": "work that needs to be continuously",
    "start": "261160",
    "end": "262840"
  },
  {
    "text": "pushed to production and that has to",
    "start": "262840",
    "end": "264479"
  },
  {
    "text": "happen safely quickly so I want to talk",
    "start": "264479",
    "end": "267680"
  },
  {
    "text": "about two different technologies that",
    "start": "267680",
    "end": "269440"
  },
  {
    "text": "are coming into play here that I think",
    "start": "269440",
    "end": "271199"
  },
  {
    "text": "are really really solving for this",
    "start": "271199",
    "end": "273000"
  },
  {
    "text": "different challenges one is Amazon",
    "start": "273000",
    "end": "275360"
  },
  {
    "text": "bedrock and the other is spine col Pine",
    "start": "275360",
    "end": "277720"
  },
  {
    "text": "called the vector dat together they work",
    "start": "277720",
    "end": "279960"
  },
  {
    "text": "in Perfect Harmony because Bedrock",
    "start": "279960",
    "end": "281960"
  },
  {
    "text": "eliminates a gigantic percentage of the",
    "start": "281960",
    "end": "284120"
  },
  {
    "text": "effort in getting llm based applications",
    "start": "284120",
    "end": "285840"
  },
  {
    "text": "deployed and running with production",
    "start": "285840",
    "end": "287880"
  },
  {
    "text": "Readiness and pine cone basically does",
    "start": "287880",
    "end": "290000"
  },
  {
    "text": "the same thing for the vector storage",
    "start": "290000",
    "end": "292440"
  },
  {
    "text": "and Vector search side of the house now",
    "start": "292440",
    "end": "294840"
  },
  {
    "text": "if you put all that together and you use",
    "start": "294840",
    "end": "296759"
  },
  {
    "text": "features like agents for bedlock that 's",
    "start": "296759",
    "end": "299800"
  },
  {
    "text": "an article where you found this video",
    "start": "299800",
    "end": "301759"
  },
  {
    "text": "that's going to talk to to you a little",
    "start": "301759",
    "end": "303320"
  },
  {
    "text": "bit more about that um you can very",
    "start": "303320",
    "end": "305880"
  },
  {
    "text": "tightly integrate say pine cone with",
    "start": "305880",
    "end": "308039"
  },
  {
    "text": "your data from S3 and you're",
    "start": "308039",
    "end": "310199"
  },
  {
    "text": "dramatically reducing the effort and",
    "start": "310199",
    "end": "311600"
  },
  {
    "text": "keeping the representations of your data",
    "start": "311600",
    "end": "313080"
  },
  {
    "text": "and vectors up to date because of course",
    "start": "313080",
    "end": "314720"
  },
  {
    "text": "as your data evolves you need to make",
    "start": "314720",
    "end": "316759"
  },
  {
    "text": "sure that the vector representations of",
    "start": "316759",
    "end": "318479"
  },
  {
    "text": "that data are up to date so that the",
    "start": "318479",
    "end": "321080"
  },
  {
    "text": "responses that your llm is producing are",
    "start": "321080",
    "end": "322919"
  },
  {
    "text": "meaningful and with pine code you can",
    "start": "322919",
    "end": "325199"
  },
  {
    "text": "actually easily observe and monitor how",
    "start": "325199",
    "end": "327840"
  },
  {
    "text": "this data is stored how this data is",
    "start": "327840",
    "end": "329360"
  },
  {
    "text": "squared and how this data is used so I",
    "start": "329360",
    "end": "331560"
  },
  {
    "text": "really encourage you to give it a try uh",
    "start": "331560",
    "end": "333479"
  },
  {
    "text": "for pinee you can get it off AWS",
    "start": "333479",
    "end": "335160"
  },
  {
    "text": "Marketplace by clicking on the link in",
    "start": "335160",
    "end": "336479"
  },
  {
    "text": "the article where you found this video",
    "start": "336479",
    "end": "338520"
  },
  {
    "text": "and there's also the article where we",
    "start": "338520",
    "end": "340319"
  },
  {
    "text": "talk about more details as to how this",
    "start": "340319",
    "end": "341919"
  },
  {
    "text": "different servic is tied together and",
    "start": "341919",
    "end": "343639"
  },
  {
    "text": "we're going to be releasing a Hands-On",
    "start": "343639",
    "end": "345080"
  },
  {
    "text": "lab soon where you actually get to build",
    "start": "345080",
    "end": "347639"
  },
  {
    "text": "this thing with me in aw so be on the",
    "start": "347639",
    "end": "350680"
  },
  {
    "text": "lookout for it and use it as as come as",
    "start": "350680",
    "end": "352400"
  },
  {
    "text": "it comes out going to be really cool um",
    "start": "352400",
    "end": "355039"
  },
  {
    "text": "so hope to see you all very soon and",
    "start": "355039",
    "end": "356840"
  },
  {
    "text": "thank you so much",
    "start": "356840",
    "end": "359410"
  },
  {
    "text": "[Music]",
    "start": "359410",
    "end": "363799"
  }
]
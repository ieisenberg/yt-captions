[
  {
    "start": "0",
    "end": "20000"
  },
  {
    "text": "In this video, you’ll see how to build an Apache \nSpark ETL job using Amazon CodeWhisperer.",
    "start": "0",
    "end": "6168"
  },
  {
    "text": "With CodeWhisperer, you can generate \nETL code in Python, create and submit",
    "start": "6752",
    "end": "11763"
  },
  {
    "text": "infrastructure resources using the AWS CLI, \nand verify the results in Amazon Athena.",
    "start": "11763",
    "end": "18491"
  },
  {
    "start": "20000",
    "end": "85000"
  },
  {
    "text": "For this demonstration, we’ll work in the \nAmazon EMR Serverless environment.",
    "start": "20580",
    "end": "25555"
  },
  {
    "text": "To get started, let’s launch EMR Studio.",
    "start": "26265",
    "end": "29428"
  },
  {
    "text": "We’ll name the application we’re \ncreating CodeWhisperer because",
    "start": "32297",
    "end": "35026"
  },
  {
    "text": "that’s the tool we’re going to use.",
    "start": "35026",
    "end": "36851"
  },
  {
    "text": "We’ll keep the Type set to Spark \nand retain the default settings.",
    "start": "37728",
    "end": "40847"
  },
  {
    "text": "Let’s create the application.",
    "start": "41794",
    "end": "43218"
  },
  {
    "text": "Now that we have an EMR Serverless \napplication, we need a Spark job to run.",
    "start": "46032",
    "end": "49996"
  },
  {
    "text": "Let’s open the application.",
    "start": "50121",
    "end": "51486"
  },
  {
    "text": "We can click Submit job to \nsee what we have to prepare.",
    "start": "51959",
    "end": "54531"
  },
  {
    "text": "We’ll need to provide a runtime role, an \nAmazon S3 location, and a script here.",
    "start": "55563",
    "end": "60405"
  },
  {
    "text": "We’ll also want to adjust \nthe application log settings.",
    "start": "62355",
    "end": "65170"
  },
  {
    "text": "Let’s view our Amazon S3 buckets.",
    "start": "67413",
    "end": "69659"
  },
  {
    "text": "For our purposes, we’ve already created \na log folder for the EMR service log.",
    "start": "70077",
    "end": "74578"
  },
  {
    "text": "This folder is empty now.",
    "start": "74842",
    "end": "76221"
  },
  {
    "text": "Later, we’ll upload the input data \nand a Spark script into this bucket.",
    "start": "76917",
    "end": "80707"
  },
  {
    "text": "Let’s view the input data we are going to use.",
    "start": "81529",
    "end": "84110"
  },
  {
    "start": "85000",
    "end": "205000"
  },
  {
    "text": "We’re going to use this sample taxi data.",
    "start": "86157",
    "end": "88332"
  },
  {
    "text": "Currently, some of the column \nnames are in uppercase.",
    "start": "88680",
    "end": "91253"
  },
  {
    "text": "Our Spark application will change \nthe column names to lowercase",
    "start": "91545",
    "end": "94847"
  },
  {
    "text": "and also calculate the total \nnumber of columns in this CSV file.",
    "start": "94847",
    "end": "98714"
  },
  {
    "text": "Let’s use CodeWhisperer to create a Python file.",
    "start": "99271",
    "end": "101910"
  },
  {
    "text": "We’ll write a comment to tell CodeWhisperer \nto use PySpark to count the total number",
    "start": "104041",
    "end": "108084"
  },
  {
    "text": "of records in the CSV file.",
    "start": "108084",
    "end": "110217"
  },
  {
    "text": "We can trigger CodeWhisperer \nsuggestions manually by using the",
    "start": "111066",
    "end": "114216"
  },
  {
    "text": "Option + C key combination on a Mac, or\n ALT + C key combination on Windows.",
    "start": "114216",
    "end": "119384"
  },
  {
    "text": "To accept a suggestion, \nwe can press our Tab key.",
    "start": "120205",
    "end": "122828"
  },
  {
    "text": "Let’s tell CodeWhisperer to create\na method to read the CSV file from",
    "start": "126281",
    "end": "129981"
  },
  {
    "text": "Amazon S3 and put it in the Spark data frame.",
    "start": "129981",
    "end": "133376"
  },
  {
    "text": "We'll accept the code suggested by CodeWhisperer.",
    "start": "134198",
    "end": "136625"
  },
  {
    "text": "Next, we’ll tell CodeWhisperer to create a \nmethod to store the data frame as a CSV file.",
    "start": "138464",
    "end": "143847"
  },
  {
    "text": "Next, we’ll tell CodeWhisperer to create a method to \ncount the total number of records in the data frame.",
    "start": "144613",
    "end": "150000"
  },
  {
    "text": "We’ll also tell CodeWhisperer to create a \nmethod to print out the schema of the data frame.",
    "start": "150711",
    "end": "155482"
  },
  {
    "text": "Next, we’ll ask CodeWhisperer to create a \nmethod to convert the field name to lowercase.",
    "start": "156136",
    "end": "160866"
  },
  {
    "text": "Now that we have all the methods we need, let’s \ntell CodeWhisperer to put them together in order.",
    "start": "163317",
    "end": "168088"
  },
  {
    "text": "Let’s quickly edit the Python main method.",
    "start": "174697",
    "end": "176841"
  },
  {
    "text": "Let’s also put our own bucket \nand key information here.",
    "start": "179765",
    "end": "182409"
  },
  {
    "text": "Now let’s go back to our Amazon S3 bucket \nand upload our Python script and sample data.",
    "start": "183941",
    "end": "188502"
  },
  {
    "text": "The upload succeeded.",
    "start": "202537",
    "end": "203746"
  },
  {
    "start": "205000",
    "end": "272000"
  },
  {
    "text": "The script and data have \nbeen added to the bucket.",
    "start": "206002",
    "end": "208485"
  },
  {
    "text": "Now let’s go back to the Spark \njob we're going to submit.",
    "start": "209154",
    "end": "211741"
  },
  {
    "text": "For the runtime role, let’s create a new IAM role.",
    "start": "212479",
    "end": "215449"
  },
  {
    "text": "We’ll limit the permission for the EMR \nServerless runtime role to our S3 bucket.",
    "start": "217203",
    "end": "221755"
  },
  {
    "text": "Next, we’ll point to the script \nlocation in our Amazon S3 bucket.",
    "start": "227255",
    "end": "230839"
  },
  {
    "text": "Finally, we’ll choose to upload our ETL logs\n to the log folder in our Amazon S3 bucket.",
    "start": "242633",
    "end": "248180"
  },
  {
    "text": "Let’s submit the job.",
    "start": "257131",
    "end": "258468"
  },
  {
    "text": "The job succeeded.",
    "start": "265639",
    "end": "266738"
  },
  {
    "text": "Let’s view the driver log files.",
    "start": "266933",
    "end": "268827"
  },
  {
    "text": "We’ll click the standard output.",
    "start": "269481",
    "end": "271013"
  },
  {
    "start": "272000",
    "end": "323000"
  },
  {
    "text": "This output shows the total number of records in the \ninput CSV as well as the schema of our data frame.",
    "start": "272892",
    "end": "279000"
  },
  {
    "text": "Now let’s return to the S3 bucket.",
    "start": "279794",
    "end": "282000"
  },
  {
    "text": "We have a new folder called “output.”",
    "start": "284284",
    "end": "286110"
  },
  {
    "text": "Let’s see what’s in it.",
    "start": "286305",
    "end": "287311"
  },
  {
    "text": "Let’s open this CSV file.",
    "start": "290305",
    "end": "292207"
  },
  {
    "text": "Observe that all the column \nnames are now in lowercase.",
    "start": "303165",
    "end": "306000"
  },
  {
    "text": "You’ve just seen how to build an Apache\n Spark ETL job using Amazon CodeWhisperer.",
    "start": "308882",
    "end": "313706"
  },
  {
    "text": "You can learn more about this topic in \nthe description and links for this video.",
    "start": "314653",
    "end": "318324"
  },
  {
    "text": "Thanks for watching. Now it’s your turn to try.",
    "start": "319200",
    "end": "321900"
  }
]
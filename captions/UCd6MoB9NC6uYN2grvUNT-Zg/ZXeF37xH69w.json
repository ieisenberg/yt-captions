[
  {
    "text": "- iFood is the largest\nfood tech in Latin America.",
    "start": "160",
    "end": "3300"
  },
  {
    "text": "Right now, our approach to generative AI",
    "start": "3300",
    "end": "5490"
  },
  {
    "text": "is to be the company",
    "start": "5490",
    "end": "7019"
  },
  {
    "text": "that's most innovative in Latin America.",
    "start": "7020",
    "end": "9600"
  },
  {
    "text": "We built the Garcon on AWS,\nwhich is our virtual waiter.",
    "start": "9600",
    "end": "14250"
  },
  {
    "text": "Together with the\ngenerative AI team from AWS,",
    "start": "14250",
    "end": "17130"
  },
  {
    "text": "we developed that agent\nend-to-end using Linkchain,",
    "start": "17130",
    "end": "20340"
  },
  {
    "text": "Bedrock, and some open-source models.",
    "start": "20340",
    "end": "22650"
  },
  {
    "text": "So there was, on Traffic Cloud,",
    "start": "22650",
    "end": "25020"
  },
  {
    "text": "there was the Titan, we used\nembeddings for our regs,",
    "start": "25020",
    "end": "30020"
  },
  {
    "text": "and using symmetric search,",
    "start": "31200",
    "end": "33360"
  },
  {
    "text": "and we also use SageMaker",
    "start": "33360",
    "end": "35238"
  },
  {
    "text": "to keep track of our experimentation.",
    "start": "35238",
    "end": "37320"
  },
  {
    "text": "Garcon has two main features.",
    "start": "37320",
    "end": "38940"
  },
  {
    "text": "The first one is the catalog,",
    "start": "38940",
    "end": "40770"
  },
  {
    "text": "where you ask it directly for a night",
    "start": "40770",
    "end": "42750"
  },
  {
    "text": "and it'll give it to back for you.",
    "start": "42750",
    "end": "44400"
  },
  {
    "text": "So I want a specific burger\nwith specific changes.",
    "start": "44400",
    "end": "48660"
  },
  {
    "text": "And the other one is, I\nwant something like that,",
    "start": "48660",
    "end": "51090"
  },
  {
    "text": "or I want to something for a hot day.",
    "start": "51090",
    "end": "53400"
  },
  {
    "text": "And then Garcon is able to\nunderstand your request,",
    "start": "53400",
    "end": "56070"
  },
  {
    "text": "and based on what we\nhave available on iFood,",
    "start": "56070",
    "end": "58829"
  },
  {
    "text": "recommend what's better for you.",
    "start": "58830",
    "end": "60510"
  },
  {
    "text": "We are focusing on efficiency.",
    "start": "60510",
    "end": "62640"
  },
  {
    "text": "We are seeing a lot of cost reduction.",
    "start": "62640",
    "end": "65665"
  },
  {
    "text": "We are getting some very\ninteresting results.",
    "start": "65665",
    "end": "69240"
  },
  {
    "text": "There are a lot of advantages.",
    "start": "69240",
    "end": "70950"
  },
  {
    "text": "So I think data security is a great one",
    "start": "70950",
    "end": "75420"
  },
  {
    "text": "because our data is always inside of DPC,",
    "start": "75420",
    "end": "78720"
  },
  {
    "text": "and it's never on the open internet.",
    "start": "78720",
    "end": "81210"
  },
  {
    "text": "It's a great issue for us, data security.",
    "start": "81210",
    "end": "83850"
  },
  {
    "text": "We have a lot of models running right now.",
    "start": "83850",
    "end": "86220"
  },
  {
    "text": "So for us, it's a no brainer.",
    "start": "86220",
    "end": "88620"
  },
  {
    "text": "We, you just simply use the\nAPI, and it's very easy for us,",
    "start": "88620",
    "end": "92400"
  },
  {
    "text": "and we have the facility\nof getting the machines",
    "start": "92400",
    "end": "97320"
  },
  {
    "text": "that we want to run, the\nfine tuning, for example,",
    "start": "97320",
    "end": "100200"
  },
  {
    "text": "the regs are great because\nyou can talk to a chatbot,",
    "start": "100200",
    "end": "104070"
  },
  {
    "text": "and can basically answer\nevery question that you have",
    "start": "104070",
    "end": "107790"
  },
  {
    "text": "that is inside the knowledge base.",
    "start": "107790",
    "end": "109770"
  },
  {
    "text": "So if you have a lot of\narticles that want to read,",
    "start": "109770",
    "end": "112590"
  },
  {
    "text": "or some document that want to summarize,",
    "start": "112590",
    "end": "115229"
  },
  {
    "text": "and things like that, you\ncan use it to summarize.",
    "start": "115230",
    "end": "117330"
  },
  {
    "text": "It's very fast.",
    "start": "117330",
    "end": "118710"
  },
  {
    "text": "So it decrease a lot the time\nyou have to learn new things,",
    "start": "118710",
    "end": "122790"
  },
  {
    "text": "to understand new things.",
    "start": "122790",
    "end": "123938"
  },
  {
    "text": "And the same can be used\nto basically everything",
    "start": "123938",
    "end": "127110"
  },
  {
    "text": "that you want to extract information from.",
    "start": "127110",
    "end": "129000"
  },
  {
    "text": "We can do basically every single step",
    "start": "129000",
    "end": "132120"
  },
  {
    "text": "using traditional machine learning,",
    "start": "132120",
    "end": "134129"
  },
  {
    "text": "but it'll take months to be good enough",
    "start": "134130",
    "end": "136890"
  },
  {
    "text": "to build to production.",
    "start": "136890",
    "end": "138090"
  },
  {
    "text": "Using generative AI,\nit'll be a lot faster.",
    "start": "138090",
    "end": "140730"
  },
  {
    "text": "And also there's a cost efficiency.",
    "start": "140730",
    "end": "142562"
  },
  {
    "text": "Sometimes people think that\ngenerative AI is very costly,",
    "start": "142563",
    "end": "146460"
  },
  {
    "text": "it's very expensive, but if\nyou can use it correctly,",
    "start": "146460",
    "end": "149632"
  },
  {
    "text": "like some fine tuning for example,",
    "start": "149632",
    "end": "151770"
  },
  {
    "text": "that we do use in Bedrock,",
    "start": "151770",
    "end": "153990"
  },
  {
    "text": "it gets cheaper than\nusing traditional models.",
    "start": "153990",
    "end": "157140"
  },
  {
    "text": "And lastly, when we are\ntalking to a chatbot,",
    "start": "157140",
    "end": "160590"
  },
  {
    "text": "we don't want it to be robotic.",
    "start": "160590",
    "end": "162269"
  },
  {
    "text": "Usually when you talk to the chatbot,",
    "start": "162270",
    "end": "164070"
  },
  {
    "text": "we are trained to send\nkeywords and not talk,",
    "start": "164070",
    "end": "167297"
  },
  {
    "text": "because you know that's our\nrobots go on the other side.",
    "start": "167297",
    "end": "171270"
  },
  {
    "text": "Using generative AI,",
    "start": "171270",
    "end": "172110"
  },
  {
    "text": "you can break that\nexperience and improve it.",
    "start": "172110",
    "end": "175110"
  },
  {
    "text": "So the user may think he's\ntalking to an actual human,",
    "start": "175110",
    "end": "180090"
  },
  {
    "text": "or it will be a better conversation.",
    "start": "180090",
    "end": "181980"
  },
  {
    "text": "And on the user experience,",
    "start": "181980",
    "end": "183224"
  },
  {
    "text": "we starting to go production more heavily.",
    "start": "183224",
    "end": "186450"
  },
  {
    "text": "So we increase the base of users",
    "start": "186450",
    "end": "189000"
  },
  {
    "text": "that are seeing our products,",
    "start": "189000",
    "end": "190590"
  },
  {
    "text": "and we are pretty\noptimistic of the results,",
    "start": "190590",
    "end": "194519"
  },
  {
    "text": "and we think that we\ngoing to change the way",
    "start": "194520",
    "end": "196410"
  },
  {
    "text": "the user will interact with us.",
    "start": "196410",
    "end": "198441"
  },
  {
    "text": "(upbeat music)",
    "start": "198441",
    "end": "201023"
  }
]
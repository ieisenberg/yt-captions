[
  {
    "start": "0",
    "end": "30000"
  },
  {
    "text": "Basics thank you for coming Friday afternoon um uh my name is Jim nisbit",
    "start": "1320",
    "end": "7040"
  },
  {
    "text": "I'm the vice president of engineering and CTO at lley um my associate here is",
    "start": "7040",
    "end": "12599"
  },
  {
    "text": "Philip otou who's the lead architect of our infrastructure team and we're going to talk to you today about uh our use of",
    "start": "12599",
    "end": "19600"
  },
  {
    "text": "a number of Open Source Technologies as well as our use of U Amazon Technologies to build our our log ingestion",
    "start": "19600",
    "end": "28320"
  },
  {
    "text": "infrastructure let me just spend a couple moments and talk to you about what logi does um we're a log management",
    "start": "28320",
    "end": "35079"
  },
  {
    "start": "30000",
    "end": "30000"
  },
  {
    "text": "as a service company where we will uh where customers uh send us log events in",
    "start": "35079",
    "end": "41879"
  },
  {
    "text": "real time and we provide the infrastructure to index those and a web application that lets you search and",
    "start": "41879",
    "end": "47920"
  },
  {
    "text": "gain insights from that we're a distributed architecture built from the beginning using AWS our initial",
    "start": "47920",
    "end": "54039"
  },
  {
    "text": "Production Services were offered in 2010 our first generation services and just a",
    "start": "54039",
    "end": "60079"
  },
  {
    "text": "couple of months ago we introduced our second generation of loggly with a with a brand new event in ingestion",
    "start": "60079",
    "end": "66479"
  },
  {
    "text": "infrastructure um we have thousands of customers um a lot of them are in the cloud customers and we can just cover a",
    "start": "66479",
    "end": "73600"
  },
  {
    "text": "little bit of those details coming up just looking at the agenda of the presentation I thought what I would",
    "start": "73600",
    "end": "79200"
  },
  {
    "text": "start off by doing is talking a little bit about logging the lessons we learned in our first generation infrastructure",
    "start": "79200",
    "end": "86280"
  },
  {
    "text": "how we leverage AWS services and then also so uh our use of kofka storm and",
    "start": "86280",
    "end": "92479"
  },
  {
    "text": "elastic search um we also thought we would add what worked well for us and a",
    "start": "92479",
    "end": "97759"
  },
  {
    "text": "couple of slides on what didn't which is will be helpful for those of you uh embracing these",
    "start": "97759",
    "end": "104560"
  },
  {
    "text": "Technologies let me start off with the basics because I think almost everyone starts this way um where logs are just",
    "start": "104560",
    "end": "112799"
  },
  {
    "text": "these primary usually text files sometimes binary but usually text files that your applications are just",
    "start": "112799",
    "end": "117960"
  },
  {
    "text": "appending to not really super sophisticated in terms of a structure but every application produces log files",
    "start": "117960",
    "end": "124759"
  },
  {
    "text": "your operating system produces a collection of log files and what happens is as each each instance you deploy has",
    "start": "124759",
    "end": "132239"
  },
  {
    "text": "those collections of log files as you install more middleware you have more log files as you replicate for",
    "start": "132239",
    "end": "138040"
  },
  {
    "text": "scalability and have more instances you have more different copies of those files and so log management often starts",
    "start": "138040",
    "end": "146480"
  },
  {
    "text": "without being named as such just doing the simple things using log rotate um",
    "start": "146480",
    "end": "151879"
  },
  {
    "text": "kind of things where a file gets to its maximum size you'll start a new file compressing the old files eventually",
    "start": "151879",
    "end": "157560"
  },
  {
    "text": "deleting those files um and what you'll find stop me if those of you have",
    "start": "157560",
    "end": "162959"
  },
  {
    "text": "already done this before is the information is there but it's awkward to find and so you'll write special purpose programs to go try and hunting down the",
    "start": "162959",
    "end": "170159"
  },
  {
    "text": "information um and the other thing that happens over time using these ad hoc",
    "start": "170159",
    "end": "175360"
  },
  {
    "text": "mechanisms is you really just H develop weird kind of retention policies some",
    "start": "175360",
    "end": "180440"
  },
  {
    "text": "logs are retained essentially too long other logs are retained not long enough",
    "start": "180440",
    "end": "185599"
  },
  {
    "text": "because you once ran out of space on a partition that those logs were in and stuff so that's the way a lot of people",
    "start": "185599",
    "end": "192280"
  },
  {
    "text": "are introduced to log management um and in this highly technical slide um I've",
    "start": "192280",
    "end": "199000"
  },
  {
    "text": "shown the amount of log data and the amount of self-inflicted pain and the way I'm looking at self-inflicted pain",
    "start": "199000",
    "end": "205280"
  },
  {
    "text": "is um the amount of time you're spending juggling the resources that you that you",
    "start": "205280",
    "end": "211599"
  },
  {
    "text": "need and providing accessibility to log management as your volume grows you're",
    "start": "211599",
    "end": "216640"
  },
  {
    "text": "going to start looking and saying gee our logs are a little bit bloated sometimes you're running",
    "start": "216640",
    "end": "221680"
  },
  {
    "text": "services at debug level sometimes you you have uh multiple collections of information but we still need that",
    "start": "221680",
    "end": "227519"
  },
  {
    "text": "information occasionally for operational reasons so you're going to let it grow as long as your business grows I'll walk",
    "start": "227519",
    "end": "233480"
  },
  {
    "text": "over here just so I can talk to both sides um so um you know as your volume",
    "start": "233480",
    "end": "241120"
  },
  {
    "text": "continues to grow oftentimes people will look and say we need to do something about this we need to manage the growth",
    "start": "241120",
    "end": "246720"
  },
  {
    "text": "we need to figure we need to classify the logs we need to do do all this but again if your business is growing you're",
    "start": "246720",
    "end": "252360"
  },
  {
    "text": "not going to constrain it by how well you're managing your logs the volume will continue to grow and my claim is",
    "start": "252360",
    "end": "258359"
  },
  {
    "text": "eventually you're going to get to the point where you just want to make this someone else's problem the volume will continue to grow and you want to either",
    "start": "258359",
    "end": "265680"
  },
  {
    "text": "buy software or make use of a service that manages this complexity for",
    "start": "265680",
    "end": "271639"
  },
  {
    "start": "271000",
    "end": "271000"
  },
  {
    "text": "you best practices in log management I just wrote up a couple of things I think are really important first in um looking",
    "start": "271639",
    "end": "279680"
  },
  {
    "text": "at modern operating systems they all support the ability to stream events in real time you know to an aggregation",
    "start": "279680",
    "end": "286240"
  },
  {
    "text": "server or aggregation service of some kind and I think you can take advantage of the existing log infrastructure don't",
    "start": "286240",
    "end": "292600"
  },
  {
    "text": "think you need a proprietary um uh infrastructure to get those logs to to a central location um uh things um Ser",
    "start": "292600",
    "end": "301800"
  },
  {
    "text": "Unix services such as syslog NG and our syslog support the ability to monitor files or you can uh send UDP messages to",
    "start": "301800",
    "end": "309479"
  },
  {
    "text": "those Services um so that the they're written to the standard",
    "start": "309479",
    "end": "314840"
  },
  {
    "text": "files hello you can use the existing infrastructure uh to get your uh to to",
    "start": "314840",
    "end": "321680"
  },
  {
    "text": "transmit your logs um and in doing so um you have the ability to transmit them to",
    "start": "321680",
    "end": "327240"
  },
  {
    "text": "multiple places and you're basically um you know all set to go the second best",
    "start": "327240",
    "end": "332560"
  },
  {
    "text": "practice seems seems pretty clear is you want to store these thing these messages externally um if the system that uh is",
    "start": "332560",
    "end": "340759"
  },
  {
    "text": "generating those log messages is uh is down or exhibiting some sort of problem",
    "start": "340759",
    "end": "345840"
  },
  {
    "text": "you don't want to have to be able you want to be forced to log into that system if it's even possible to recover",
    "start": "345840",
    "end": "351560"
  },
  {
    "text": "information about what it was doing um the third one is think of log messages",
    "start": "351560",
    "end": "357280"
  },
  {
    "text": "as being consumed by two different classes of entities um and this is really",
    "start": "357280",
    "end": "363000"
  },
  {
    "text": "important and those of you that are developers I I think will really save a lot of time the first class of entity is",
    "start": "363000",
    "end": "369360"
  },
  {
    "text": "people you're writing messages for yourself initially for devops later for for uh troubleshooting and tech support",
    "start": "369360",
    "end": "376440"
  },
  {
    "text": "and so it makes sense you're writing a message to be digested by a human being but the second class which is",
    "start": "376440",
    "end": "381520"
  },
  {
    "text": "increasingly coming about is it enters the category of semi-structured data so",
    "start": "381520",
    "end": "387880"
  },
  {
    "text": "the second class of consumer is our machines our programs that are parsing and analyzing those log messages so in",
    "start": "387880",
    "end": "395479"
  },
  {
    "text": "terms of a best practice if what you're trying to write out is a highly structured piece of",
    "start": "395479",
    "end": "400680"
  },
  {
    "text": "information use Json just serialize it as a Json message it's easy for machines",
    "start": "400680",
    "end": "405759"
  },
  {
    "text": "to read um it's it's reasonably easy for a person to read in a you know a compressed format um and that will be um",
    "start": "405759",
    "end": "414720"
  },
  {
    "text": "a very sort of solid way of getting that information through the log infrastructure to to its final",
    "start": "414720",
    "end": "420720"
  },
  {
    "text": "destination the other mechanism that you can use is use some sort of keyword equal value uh you know pair if you're",
    "start": "420720",
    "end": "427720"
  },
  {
    "text": "writing out information perhaps append it to the end of a log message instead of writing an englishy message or",
    "start": "427720",
    "end": "434199"
  },
  {
    "text": "instead of autoscaling uh the increments are really trying to favor the human being think of",
    "start": "434199",
    "end": "439319"
  },
  {
    "text": "the two consumers how do you make a brain dead simple format that will that that will uh achieve those",
    "start": "439319",
    "end": "446479"
  },
  {
    "text": "results so I thought I'd put something from the trenches now admit it it I know",
    "start": "446479",
    "end": "451639"
  },
  {
    "text": "it's Friday afternoon but how often have you seen this kind of thing from an operational standpoint step one if you",
    "start": "451639",
    "end": "458319"
  },
  {
    "text": "run out of dis space delete those damn log files um step two is oh um maybe we",
    "start": "458319",
    "end": "465560"
  },
  {
    "text": "should look at those log files to figure out what the hell just happened you know um so um I you know my strong case here",
    "start": "465560",
    "end": "472720"
  },
  {
    "text": "is don't make this an either or you know you don't don't don't say I'm either going to manage my application or I'm",
    "start": "472720",
    "end": "478199"
  },
  {
    "text": "going to manage my logs um um you know create a use a logging",
    "start": "478199",
    "end": "484639"
  },
  {
    "text": "infrastructure that is independent of your applications because when you need it most um you know is is when the",
    "start": "484639",
    "end": "491560"
  },
  {
    "text": "applications are misbehaving somehow or you need to go back and look at Trends um I wish I could say that that was just",
    "start": "491560",
    "end": "497639"
  },
  {
    "text": "a madeup example by the way I actually remember the person who wrote it",
    "start": "497639",
    "end": "504159"
  },
  {
    "start": "504000",
    "end": "504000"
  },
  {
    "text": "um so we all have logs we know what they are um uh",
    "start": "504159",
    "end": "509960"
  },
  {
    "text": "but I you know I just took one example um that we posted on our website not so long ago if you have a Java application",
    "start": "509960",
    "end": "516919"
  },
  {
    "text": "and you've turned on um writing out debugging information about garbage collection you'll have a ton of these",
    "start": "516919",
    "end": "522518"
  },
  {
    "text": "messages that says you know you know how long did a full GC take how long did a minor GC take and you can look at all",
    "start": "522519",
    "end": "528920"
  },
  {
    "text": "these messages and you can send these messages to a log management system and",
    "start": "528920",
    "end": "533959"
  },
  {
    "text": "I think any of the systems that that you look at will have the basic ability to search those those those logs um so you",
    "start": "533959",
    "end": "541160"
  },
  {
    "text": "if you know what you're looking for you can search and find out let me look at all the Java GC messages or let me look",
    "start": "541160",
    "end": "546600"
  },
  {
    "text": "at all the full GCS um and I think that's good um but increasingly as we're watching orders of magnitude increases",
    "start": "546600",
    "end": "554040"
  },
  {
    "text": "in volume you realize I don't want to look at the individual messages I can't find the exceptions myself I want to",
    "start": "554040",
    "end": "560720"
  },
  {
    "text": "grab the data and just look at Trends and so this is just a a simple example of grabbing the GC time and saying how",
    "start": "560720",
    "end": "568000"
  },
  {
    "text": "long did a a GC cycle take uh minor and major what was the size of the Heap this",
    "start": "568000",
    "end": "573160"
  },
  {
    "text": "is simple practical analytics based on your log data as a source of information",
    "start": "573160",
    "end": "579240"
  },
  {
    "text": "you just very quickly want to find out what's going on and then once you do find out what's going on you said when",
    "start": "579240",
    "end": "584959"
  },
  {
    "text": "was that going on and then you can drill into additional messages after that logi offers this as a you know as a",
    "start": "584959",
    "end": "592600"
  },
  {
    "text": "service and I thought the next thing I could talk to you about was what our generation one service looked like you",
    "start": "592600",
    "end": "598399"
  },
  {
    "text": "know um and and uh how we went about solving the problem when we first introduced this",
    "start": "598399",
    "end": "603600"
  },
  {
    "text": "service so we knew we wanted to do realtime indexing of logs um uh we we um",
    "start": "603600",
    "end": "613040"
  },
  {
    "text": "have thousands of customers uh ranging in volumes of 10 events per second to",
    "start": "613040",
    "end": "618800"
  },
  {
    "text": "100,000 events per second so widely differing volume one thing we came to recognize is",
    "start": "618800",
    "end": "626880"
  },
  {
    "text": "that the logging volume that our system see follows um the peak activities during",
    "start": "626880",
    "end": "633920"
  },
  {
    "text": "the work day during weekends and holiday seasons and stuff and it kind of makes sense if you think about it because um",
    "start": "633920",
    "end": "641079"
  },
  {
    "text": "when your if your system writes out a certain number of messages for for every event process or for every customer",
    "start": "641079",
    "end": "647760"
  },
  {
    "text": "acquisition or for every purchase as as those systems are busier they write out more log messages so we end up uh being",
    "start": "647760",
    "end": "655920"
  },
  {
    "text": "able to do certain predictive analysis in terms of allocating indexing resources just knowing that you'll",
    "start": "655920",
    "end": "662079"
  },
  {
    "text": "follow a a a daily cycle um um the thing that may not be as obvious is that logs",
    "start": "662079",
    "end": "670720"
  },
  {
    "text": "unlike your your customer facing systems also have periods of very high activity during internal maintenance periods if",
    "start": "670720",
    "end": "677839"
  },
  {
    "text": "you're running some collection of internal processes they could be very chatty to the logs and we'll see Peak",
    "start": "677839",
    "end": "683639"
  },
  {
    "text": "activity periods that don't just last for minutes they last for hours so that was the challenge in ter terms of",
    "start": "683639",
    "end": "689600"
  },
  {
    "text": "building a logging service um as I mentioned at the beginning we deployed",
    "start": "689600",
    "end": "695720"
  },
  {
    "text": "uh you know initially on Amazon uh using not VPC instances they weren't available then we used dc2 instances uh I think",
    "start": "695720",
    "end": "703320"
  },
  {
    "text": "perhaps our experience was similar to others in that we wanted the Persistence of EBS but there was a high degree of",
    "start": "703320",
    "end": "708839"
  },
  {
    "text": "Vari variability prior to provision doops so we ended up using ephemeral",
    "start": "708839",
    "end": "714000"
  },
  {
    "text": "storage instance storage uh and we ended up replicating the indexes across nodes",
    "start": "714000",
    "end": "719120"
  },
  {
    "text": "uh um uh we knew we wanted to use Lucine for the power of that search engine but",
    "start": "719120",
    "end": "724399"
  },
  {
    "text": "Lucine is a Java Library it's not it's it's not a clustered uh uh search engine",
    "start": "724399",
    "end": "729600"
  },
  {
    "text": "so we ended up using solar uh uh something called solar Cloud um and we",
    "start": "729600",
    "end": "735199"
  },
  {
    "text": "use that as the mechanism to support our cluster of indexes because we have",
    "start": "735199",
    "end": "740760"
  },
  {
    "text": "thousands of customers because a lot of those customers are low volume customers um in addition to these very high volume",
    "start": "740760",
    "end": "747639"
  },
  {
    "text": "customers we ended up heavily modifying that code base to be able to support many more shards than than your typical",
    "start": "747639",
    "end": "754240"
  },
  {
    "text": "solar Cloud installation and we use zeromq as a terrifically fast um non-persistent message",
    "start": "754240",
    "end": "761279"
  },
  {
    "text": "Cube so Lessons Learned in the first generation um was our event ingestion",
    "start": "761279",
    "end": "768720"
  },
  {
    "start": "764000",
    "end": "764000"
  },
  {
    "text": "taking events from the customers was too tightly coupled to the backend indexing",
    "start": "768720",
    "end": "774920"
  },
  {
    "text": "um so if we experienced a temporary resource problem on solar Cloud where we",
    "start": "774920",
    "end": "780440"
  },
  {
    "text": "had to reconfigure the system we would have to go back and manually schedule the re-indexing of previous customer",
    "start": "780440",
    "end": "787240"
  },
  {
    "text": "data so our event ingestion pipeline um could support a brief period of time uh",
    "start": "787240",
    "end": "795000"
  },
  {
    "text": "you know uh 5 minutes worth of um the backend system not being available but not longer time than that and that was a",
    "start": "795000",
    "end": "801760"
  },
  {
    "text": "lesson learned the other Lesson Learned was that our particular customer base",
    "start": "801760",
    "end": "809199"
  },
  {
    "text": "comparing our low volume customers to our high volume customers there's four orders of magnitude difference between",
    "start": "809199",
    "end": "815279"
  },
  {
    "text": "those customers so we needed very um uh in our first generation system it was",
    "start": "815279",
    "end": "821800"
  },
  {
    "text": "hard for us to efficiently manage the low volume customers it was also at",
    "start": "821800",
    "end": "827000"
  },
  {
    "text": "times hard for us to effectively manage very high volume customers so we wanted",
    "start": "827000",
    "end": "832759"
  },
  {
    "text": "different strategies for how we managed the indexes for when we chose to break the indexes into pieces is called chards",
    "start": "832759",
    "end": "840519"
  },
  {
    "text": "um uh and um what we found is that our low volume customers and our high volume",
    "start": "840519",
    "end": "846480"
  },
  {
    "text": "customers were sometimes the same customer they would be very low volume until all of a sudden they turned on",
    "start": "846480",
    "end": "851759"
  },
  {
    "text": "different systems or they were backlogged and they shipped us logs and they would be a very high volume customer so all of that was flexibility",
    "start": "851759",
    "end": "858480"
  },
  {
    "text": "that we learned during our you know you know our first generation so big data infrastructure",
    "start": "858480",
    "end": "865079"
  },
  {
    "start": "865000",
    "end": "865000"
  },
  {
    "text": "Solutions I couldn't think of anything else other than Jeopardy here you know um we realized that we weren't alone",
    "start": "865079",
    "end": "871639"
  },
  {
    "text": "because when we started looking at the second generation system we realized we have a massive incoming event stream",
    "start": "871639",
    "end": "877959"
  },
  {
    "text": "coming from many customers we're fundamentally multi-tenant we don't build separate stove typ stove piped um",
    "start": "877959",
    "end": "885680"
  },
  {
    "text": "systems they all share their common resources uh we needed a scalable framework for the analysis and analytics",
    "start": "885680",
    "end": "892040"
  },
  {
    "text": "we do on Logs with NE realtime indexing with time series data and fundamentally",
    "start": "892040",
    "end": "897680"
  },
  {
    "text": "we realized we were looking at a lot lot of common Big Data infrastructure Solutions what I thought I'd do is just",
    "start": "897680",
    "end": "903399"
  },
  {
    "text": "cover a real quickly kfka storm and elastic search just uh in term for those",
    "start": "903399",
    "end": "909160"
  },
  {
    "text": "of you who who aren't familiar with it and then Philip will get into the details of how we use it in our Gen 2",
    "start": "909160",
    "end": "915399"
  },
  {
    "text": "system so Apache Kafka for those of you who don't know is a high performance",
    "start": "915399",
    "end": "921639"
  },
  {
    "start": "918000",
    "end": "918000"
  },
  {
    "text": "persistent message queue um it's notable in that the um producer doesn't track",
    "start": "921639",
    "end": "929000"
  },
  {
    "text": "who is consuming the information it's up to the consumers to track where they are as a result you end up keeping the last",
    "start": "929000",
    "end": "936000"
  },
  {
    "text": "24 hours let's say 24 hours or a large period of time uh worth of data longer",
    "start": "936000",
    "end": "941440"
  },
  {
    "text": "than any it would take any consumers to consume and what it gives us is it's a",
    "start": "941440",
    "end": "947000"
  },
  {
    "text": "specially optimized persistent message queue that doesn't degrade when the amount of messages in the system is",
    "start": "947000",
    "end": "953720"
  },
  {
    "text": "large in fact there is no degradation because all messages go go to disk um",
    "start": "953720",
    "end": "959160"
  },
  {
    "text": "and uh you know secondarily we get the benefit of a system optimized for for",
    "start": "959160",
    "end": "964800"
  },
  {
    "text": "real-time event processing um looking just at the um oh I should",
    "start": "964800",
    "end": "972040"
  },
  {
    "text": "mention LinkedIn developed Kafka and open source it now it is now an Apache project but looking at some of the um uh",
    "start": "972040",
    "end": "979519"
  },
  {
    "start": "979000",
    "end": "979000"
  },
  {
    "text": "performance characteristics and we also measured these this comes from the paper on kofka um they're they're really",
    "start": "979519",
    "end": "986240"
  },
  {
    "text": "exciting uh using this kind of technique what this shows us is that on a single",
    "start": "986240",
    "end": "991360"
  },
  {
    "text": "machine modestly configured system by today standards um a single kofka",
    "start": "991360",
    "end": "996519"
  },
  {
    "text": "producer can produce can emit messages at 400,000 messages a second and sustain",
    "start": "996519",
    "end": "1002120"
  },
  {
    "text": "that kind of speed about 400,000 uh what it says then is the consumer that does have to keep track of where they are can",
    "start": "1002120",
    "end": "1008959"
  },
  {
    "text": "consume at 200,000 messages per second and these kind of numbers allow us to scale obviously they support horizontal",
    "start": "1008959",
    "end": "1015839"
  },
  {
    "text": "scalability and scale to the kind of numbers that we we have to deal with so we're very pleased with the performance",
    "start": "1015839",
    "end": "1021279"
  },
  {
    "text": "of kofka second of all let me talk to you a little bit about the storm framework um",
    "start": "1021279",
    "end": "1026880"
  },
  {
    "text": "for again uh developed by Twitter open sourced uh uh in 2001 is now an Apache",
    "start": "1026880",
    "end": "1033120"
  },
  {
    "text": "incubator project what storm is is it's a complex event processing framework um",
    "start": "1033120",
    "end": "1039600"
  },
  {
    "text": "it lets you write the pro the the processing um uh information that you",
    "start": "1039600",
    "end": "1045600"
  },
  {
    "text": "want write the the code that you want as how you want to deal with events and have the framework take uh um uh",
    "start": "1045600",
    "end": "1053080"
  },
  {
    "text": "guarantee a single delivery of you know of each of the events and guarantee that you can take nodes in and out of the",
    "start": "1053080",
    "end": "1059080"
  },
  {
    "text": "system um storm has its own terminology and again just so for to be helpful as",
    "start": "1059080",
    "end": "1065360"
  },
  {
    "text": "you look at how we use it let me just cover a a simple logical view of of what",
    "start": "1065360",
    "end": "1070640"
  },
  {
    "text": "a storm cluster lets you do um you can define a topology which basically says",
    "start": "1070640",
    "end": "1077760"
  },
  {
    "text": "um uh and again using the storm terminology I have a spout that knows",
    "start": "1077760",
    "end": "1083200"
  },
  {
    "text": "how to read information and emit a stream of tupal in our case it's log events and then I have I can connect",
    "start": "1083200",
    "end": "1089280"
  },
  {
    "text": "that to a bolt um that does some processing and has the option of emitting one or more streams itself so",
    "start": "1089280",
    "end": "1095520"
  },
  {
    "text": "you can break up the processing um it's okay to uh group uh to tell the the",
    "start": "1095520",
    "end": "1101039"
  },
  {
    "text": "cluster to group the uh two bolts together so there isn't a network hop between that processing but uh you get",
    "start": "1101039",
    "end": "1108000"
  },
  {
    "text": "uh the notion of a topology deployed on a storm cluster um looking at more a",
    "start": "1108000",
    "end": "1114039"
  },
  {
    "text": "resource view of storm um storm consists of a master um schedule or monitor which",
    "start": "1114039",
    "end": "1121960"
  },
  {
    "text": "simply has to be uh which simply keeps track of where the worker nodes are on",
    "start": "1121960",
    "end": "1127120"
  },
  {
    "text": "in in the storm cluster uh the master is called Nimbus um and it keeps track in",
    "start": "1127120",
    "end": "1132200"
  },
  {
    "text": "Zookeeper of where uh the information is and then there are worker nodes that are added to the to the cluster that",
    "start": "1132200",
    "end": "1138880"
  },
  {
    "text": "semantic for the bolts you know are that you will get each event at least once in",
    "start": "1138880",
    "end": "1145080"
  },
  {
    "text": "the event that you shut down in node or uh or start it you may get it more than once storm supports a transactional",
    "start": "1145080",
    "end": "1151559"
  },
  {
    "text": "topology that you can guarantee in only once um uh semantic we don't use that because our transactions are item potent",
    "start": "1151559",
    "end": "1158400"
  },
  {
    "text": "we can replay them and so we can take advantage of a slightly higher performance mechanism in storm um but",
    "start": "1158400",
    "end": "1164720"
  },
  {
    "text": "the the really neat part for us is as we're processing event if we get behind",
    "start": "1164720",
    "end": "1170120"
  },
  {
    "text": "we add worker notes as we're as we're dealing with stuff if it's clear that we're we've you know uh we're over",
    "start": "1170120",
    "end": "1176440"
  },
  {
    "text": "provisioned we can shut those down so it's a wonderful marriage between the kind of um uh infrastructure and",
    "start": "1176440",
    "end": "1181960"
  },
  {
    "text": "framework that you that you're provided and what you can do you know in the cloud with",
    "start": "1181960",
    "end": "1188039"
  },
  {
    "text": "AWS the third component I want to talk about is elastic search despite its name",
    "start": "1188039",
    "end": "1193679"
  },
  {
    "text": "elastic search is not actually an Amazon service um it's a separate open source project",
    "start": "1193679",
    "end": "1199520"
  },
  {
    "text": "um uh um that it now has a commercial company elastic search.com uh that will",
    "start": "1199520",
    "end": "1205640"
  },
  {
    "text": "offer support for it and what elastic search is is it's a distributed clustered high performance search engine",
    "start": "1205640",
    "end": "1213320"
  },
  {
    "text": "um it is the framework around the Lucine library that lets us a access that",
    "start": "1213320",
    "end": "1218720"
  },
  {
    "text": "information um um it uh for those of you who are familiar with different search",
    "start": "1218720",
    "end": "1223760"
  },
  {
    "text": "Technologies it would be similar to the role that solar played in in our first generation what we really liked about",
    "start": "1223760",
    "end": "1230320"
  },
  {
    "text": "elastic search is that it was designed for the kind of real-time events or",
    "start": "1230320",
    "end": "1235440"
  },
  {
    "start": "1235000",
    "end": "1235000"
  },
  {
    "text": "certainly makes it very easy for us to manage with uh real-time events we can do things like add additional nodes",
    "start": "1235440",
    "end": "1242080"
  },
  {
    "text": "delete nodes uh dynamically uh the nodes have storage on them the storage is where you store the indexes um we can",
    "start": "1242080",
    "end": "1250120"
  },
  {
    "text": "assign attributes to indexes and nodes so that as usage changes we can over the",
    "start": "1250120",
    "end": "1255600"
  },
  {
    "text": "long term migrate uh indexes and and the shards that are underneath them to",
    "start": "1255600",
    "end": "1261240"
  },
  {
    "text": "different nodes it all the things that a frame that we would hope for in a",
    "start": "1261240",
    "end": "1266400"
  },
  {
    "text": "framework in that it will manage replicas and um uh and it will um manage",
    "start": "1266400",
    "end": "1272640"
  },
  {
    "text": "uh the overall cluster State uh in addition to that there's a high performance bulk insertion mechanism",
    "start": "1272640",
    "end": "1279000"
  },
  {
    "text": "which we use um we actually heavily uh uh pre-process the input",
    "start": "1279000",
    "end": "1286400"
  },
  {
    "text": "stream for maximum efficiency um you know uh in terms of uh bulk",
    "start": "1286400",
    "end": "1291480"
  },
  {
    "text": "insertions into the elastic search index so next we're going to talk about",
    "start": "1291480",
    "end": "1297919"
  },
  {
    "text": "our second generation I can think of no one better to talk about it than Philip otou our lead architect who built the",
    "start": "1297919",
    "end": "1303360"
  },
  {
    "start": "1299000",
    "end": "1299000"
  },
  {
    "text": "second generation or his team built it",
    "start": "1303360",
    "end": "1308840"
  },
  {
    "text": "hello no oh there we go okay great thanks a lot Jim um as Jim said my name is Philip I'm the lead developer on the",
    "start": "1309640",
    "end": "1316200"
  },
  {
    "text": "infrastructure team I have to give my colleagues credit it wasn't just wasn't just I who built this as a bunch of us",
    "start": "1316200",
    "end": "1321840"
  },
  {
    "text": "have been working on for the last year um I'm very proud of what we built very excited and and I just hope to be generous today to give you some",
    "start": "1321840",
    "end": "1328880"
  },
  {
    "text": "details um I want to talk about there's kind of three sections to this talk this part of the presentation first of all I",
    "start": "1328880",
    "end": "1334559"
  },
  {
    "text": "want to show you a logical view how we hooked all these components together give you an idea where our software hooked into it as well the second thing",
    "start": "1334559",
    "end": "1341400"
  },
  {
    "text": "I'll do is I'll give some specific technical details on the resources and infrastructure we used in",
    "start": "1341400",
    "end": "1346559"
  },
  {
    "text": "AWS to actually build this system in reality hopefully to help you people out there to understand what we had to do",
    "start": "1346559",
    "end": "1352919"
  },
  {
    "text": "and what resources we used there's a lot of other resources in AWS we use as well that aren't explicitly shown here and",
    "start": "1352919",
    "end": "1359039"
  },
  {
    "text": "the third thing I'll talk about briefly is some details Jim alluded to earlier on about what didn't work for us there",
    "start": "1359039",
    "end": "1364760"
  },
  {
    "text": "are some technologies that I'm sure work for people out there really really well they didn't quite meld with our system",
    "start": "1364760",
    "end": "1370640"
  },
  {
    "text": "especially as we tried to solve the problem once Fred books has that famous saying about plan to throw one away",
    "start": "1370640",
    "end": "1377159"
  },
  {
    "text": "because you always will we definitely went through some of that and we learned some some things about different technologies that we try to",
    "start": "1377159",
    "end": "1383880"
  },
  {
    "text": "use so when I joined logi a year and a half ago this was the challenge that charity or CEO gave me he said we want a",
    "start": "1383880",
    "end": "1391080"
  },
  {
    "text": "system that can a always accept log data obvious but why is that's important it's important because as Jim said a lot of",
    "start": "1391080",
    "end": "1396960"
  },
  {
    "text": "our customers are busiest when they're when they're busy or when there's something going on in their system and we wanted to make sure that we had an",
    "start": "1396960",
    "end": "1403600"
  },
  {
    "text": "ingestion pipeline that would always take the data off them we never wanted to make the incident worse by back",
    "start": "1403600",
    "end": "1408919"
  },
  {
    "text": "pressure or anything like this we really wanted to make sure we accepted the log data uh the next one was never drop the",
    "start": "1408919",
    "end": "1415400"
  },
  {
    "text": "log data again obvious to some people but as a developer I really appreciate",
    "start": "1415400",
    "end": "1420840"
  },
  {
    "text": "that all it takes is one log message to completely change your mental model of",
    "start": "1420840",
    "end": "1426039"
  },
  {
    "text": "how your system is working or an operations person can just miss one message so never dropping a log message",
    "start": "1426039",
    "end": "1431080"
  },
  {
    "text": "was very important and third and actually just to that point our customers had told us that in the event they would rather have",
    "start": "1431080",
    "end": "1437720"
  },
  {
    "text": "increased lay latency than losing data so if we could say to you well we can always be caught up to your data stream",
    "start": "1437720",
    "end": "1443880"
  },
  {
    "text": "but some might messages may not be there they said no we would rather you be a few minutes behind and make sure that",
    "start": "1443880",
    "end": "1449320"
  },
  {
    "text": "the data is always there and I'm sure your customers feel the same way as well and the third one was true elasticity we",
    "start": "1449320",
    "end": "1455039"
  },
  {
    "text": "wanted to make sure that the system that we built really would scale given the cap the opportunities we have for",
    "start": "1455039",
    "end": "1460440"
  },
  {
    "text": "scaling when we run in the cloud so it was important that the components we design did scale both horizontally and",
    "start": "1460440",
    "end": "1465840"
  },
  {
    "text": "vertically so just to re to reiterate some of the",
    "start": "1465840",
    "end": "1470960"
  },
  {
    "text": "stuff that Jim had mentioned this made some of the technology that we pick work really well for us Apache Kafka is",
    "start": "1470960",
    "end": "1476720"
  },
  {
    "text": "extremely high performance pubs up persistent queue the fact that the consumers track their location in the queue makes it makes it perform very",
    "start": "1476720",
    "end": "1482919"
  },
  {
    "text": "well and the fact that you can run as many cfer Brokers as you're prepared to pay for and get increasing performance",
    "start": "1482919",
    "end": "1488840"
  },
  {
    "text": "works really well in AWS and in the cloud we run multiple Brokers per region we run across regions run across zones",
    "start": "1488840",
    "end": "1495240"
  },
  {
    "text": "and the availability Zone oparation has been really good and has helped us a lot so that's the great thing about Kafka",
    "start": "1495240",
    "end": "1500440"
  },
  {
    "text": "really scales in a horizontal manner storm again you can throw as much",
    "start": "1500440",
    "end": "1505720"
  },
  {
    "text": "resources as you're prepared to provision and pay money for it gives you extra extra processing power as you add more nodes it's a little bit more",
    "start": "1505720",
    "end": "1512480"
  },
  {
    "text": "difficult to tune than than CFA but the horizontal scalability is there the nice thing about our storm framework and I'll",
    "start": "1512480",
    "end": "1518480"
  },
  {
    "text": "get into it graphically in a moment is that it's the first part of our system that pulls so we're able to engineer",
    "start": "1518480",
    "end": "1523840"
  },
  {
    "text": "storm for an average workload which is much easier to engineer than trying to engineer for a peak workload cuz you",
    "start": "1523840",
    "end": "1530240"
  },
  {
    "text": "know what is your Peak Lo workload going to ever be so storm is the first part of our system that pulls from Kafka",
    "start": "1530240",
    "end": "1535600"
  },
  {
    "text": "allowing us to be sure as long as we have enough resources over the long run we'll keep up with the incoming data",
    "start": "1535600",
    "end": "1541279"
  },
  {
    "text": "stream and it is elastic you can provision many worker nodes we provision them across availability zones so that",
    "start": "1541279",
    "end": "1547600"
  },
  {
    "text": "if we lose we don't lose it if Amazon loses the availability Zone we can still keep processing data and it's actually",
    "start": "1547600",
    "end": "1553480"
  },
  {
    "text": "quite well and we've tested this pulling nodes actually works quite well so storm also works well for",
    "start": "1553480",
    "end": "1559919"
  },
  {
    "text": "us so what I'd like to do is to to show you how our system is scaled together",
    "start": "1559919",
    "end": "1565240"
  },
  {
    "text": "I'm actually going to tell the story and show it graphically of what happens when your log message arrives at loggly to give you an idea of how the components",
    "start": "1565240",
    "end": "1571760"
  },
  {
    "text": "hook together and what happens to your data so we all know what log data looks like it's a stream of never ending",
    "start": "1571760",
    "end": "1578559"
  },
  {
    "text": "events most importantly it's time stamped so you can tell which event happened before one of the other and this we call it the loggly fire hose in",
    "start": "1578559",
    "end": "1585279"
  },
  {
    "text": "honor of what Twitter calls their fire hose this data is constantly coming at us whether we want it or",
    "start": "1585279",
    "end": "1590360"
  },
  {
    "text": "not our particular system can over 100,000 events a second is happens all the time we support three different",
    "start": "1590360",
    "end": "1596760"
  },
  {
    "text": "types of protocols streaming over TCP RFC 54124 or 3164 or over UDP and we",
    "start": "1596760",
    "end": "1603840"
  },
  {
    "text": "also support hdtp so people can post their logs to us if they wish over hdtp we prefer TCP it's reliable it works",
    "start": "1603840",
    "end": "1611320"
  },
  {
    "text": "quite well people can send UDP but then I can promise you we can't drop it because I can promise you we got it so",
    "start": "1611320",
    "end": "1616600"
  },
  {
    "text": "TCP is by far our most common common way of people sending data to us and it's what thisis log works really well so",
    "start": "1616600",
    "end": "1622399"
  },
  {
    "text": "your event comes in and the first thing it hits is these custom collectors that we built and these are custom high",
    "start": "1622399",
    "end": "1628240"
  },
  {
    "text": "performance processes we wrote in C++ we run them across a multiple availability zones and all these these guys have to",
    "start": "1628240",
    "end": "1635679"
  },
  {
    "text": "do is pull bits off the wire and perform some validation on them the validation on them is to make sure that they're",
    "start": "1635679",
    "end": "1640840"
  },
  {
    "text": "compliant with the RFC we're very standards are important to us they help us as Engineers talk to one another and",
    "start": "1640840",
    "end": "1646600"
  },
  {
    "text": "they help people understand what what we're building and what we're providing so they pull data off the wire make sure they look like log messages and send it",
    "start": "1646600",
    "end": "1653520"
  },
  {
    "text": "on to our next stage which is a cross connect to our first the cues in our Kafka cluster and this is where Kafka",
    "start": "1653520",
    "end": "1660600"
  },
  {
    "text": "kicks in so collectors do nothing with this they're all about Ram the idea is aess message goes into the collector and",
    "start": "1660600",
    "end": "1665640"
  },
  {
    "text": "it's there for a few NCS and it's out the other side straight into a Kafka cluster where",
    "start": "1665640",
    "end": "1670720"
  },
  {
    "text": "Kafka persisted to dis immediately and this has worked really well for us we run multiple Kafka Brokers the numbers",
    "start": "1670720",
    "end": "1676480"
  },
  {
    "text": "aren't important because they scale up down as we need more performance and as we use AWS but this CF broker cluster",
    "start": "1676480",
    "end": "1684360"
  },
  {
    "text": "runs in mult across multiple availability zones it sits on top of provision DBS volumes I talk a little bit more that in a little bit later and",
    "start": "1684360",
    "end": "1690600"
  },
  {
    "text": "we run multiple partitions and this is the very first part that your data comes in and hits us and the nice thing about",
    "start": "1690600",
    "end": "1697039"
  },
  {
    "text": "this is it looks simple but it took us quite a while to really come up with this in a robust implementation of",
    "start": "1697039",
    "end": "1702320"
  },
  {
    "text": "design but just this alone allows us to address the first two points that was",
    "start": "1702320",
    "end": "1707640"
  },
  {
    "text": "the design go that Charlie gave me always accept the data because the collectors really move and make sure",
    "start": "1707640",
    "end": "1713640"
  },
  {
    "text": "it's safe and I can promise you that once an event gets from here and onto the dis here it's safe now EBS is",
    "start": "1713640",
    "end": "1720159"
  },
  {
    "text": "persistent you have to monitor it but generally its quality is very very high and this will this means that the first",
    "start": "1720159",
    "end": "1725200"
  },
  {
    "text": "two parts of our design goal have been met after this this is where we move",
    "start": "1725200",
    "end": "1731159"
  },
  {
    "text": "into the pole side of our our infrastructure and this is where storm comes in and storm pulls from Kafka this",
    "start": "1731159",
    "end": "1737080"
  },
  {
    "text": "is a model that other people definitely using it's one we followed as well and I'm going to get into this a little bit more about what's actually going on",
    "start": "1737080",
    "end": "1743039"
  },
  {
    "text": "inside the storm framework but this is the this is what we call the first stage of our ingestion Pipeline and it's",
    "start": "1743039",
    "end": "1748200"
  },
  {
    "text": "worked out really well and then from Storm I'll be deling into this a little bit more we go into",
    "start": "1748200",
    "end": "1753880"
  },
  {
    "text": "more CF cues but this is the main design principle on which our ingestion pipeline is built and just as a little Sidetrack the",
    "start": "1753880",
    "end": "1761200"
  },
  {
    "text": "collectors which I'm very proud of actually because we did a nice job they're C++ they're multi-threaded we",
    "start": "1761200",
    "end": "1766399"
  },
  {
    "text": "built them on the Boost asio framework which which is a joy to code against I recommend it if anybody's looking to build high performance network software",
    "start": "1766399",
    "end": "1773120"
  },
  {
    "text": "and early on in our performance testing to go back to the point that we always want to accept customers data we don't want to let them",
    "start": "1773120",
    "end": "1779159"
  },
  {
    "text": "down each collector we rate it as each collector alone even though we run multiple ones for redundancy could",
    "start": "1779159",
    "end": "1785000"
  },
  {
    "text": "easily handle 250,000 events a second when running on an M2 2x large instance which is plenty of memory collectors are",
    "start": "1785000",
    "end": "1791640"
  },
  {
    "text": "all about CPU and RAM and once you give it to them the Amazon framework and the software rot was able to scale so that",
    "start": "1791640",
    "end": "1797240"
  },
  {
    "text": "really addressed our first point and we're very happy with that and of course cfco could keep up with this no problem",
    "start": "1797240",
    "end": "1802320"
  },
  {
    "text": "at all it could take data from the collectors at this rate so it work very very well so now let me dive a little bit",
    "start": "1802320",
    "end": "1809200"
  },
  {
    "text": "into what we actually do with the events in the storm framework so now your data has gone through the collectors it's safely sitting on dis but of course it's",
    "start": "1809200",
    "end": "1815600"
  },
  {
    "text": "actually in the buffer cache that Kafka uses so it's it's easy to read from Kafka in high performant manner but it's",
    "start": "1815600",
    "end": "1821399"
  },
  {
    "text": "it's safe so what do we what is the first thing we do with the events from your CFA Q we go into our",
    "start": "1821399",
    "end": "1828559"
  },
  {
    "text": "storm topology we run me many topologies but this is our main one and we go into what's known as a cfus spout Jim alluded",
    "start": "1828559",
    "end": "1834880"
  },
  {
    "text": "to this concept earlier on we use the open source cfus bout that's available with storm but we've modified it quite a",
    "start": "1834880",
    "end": "1839919"
  },
  {
    "text": "bit for our own purposes we run multiple instances of the sofware objects I'm showing up here again because Amazon",
    "start": "1839919",
    "end": "1846120"
  },
  {
    "text": "scales horizontally and this software intrinsically scales horizontally so numbers aren't important because they",
    "start": "1846120",
    "end": "1851399"
  },
  {
    "text": "change all the time but we certainly run more than one instance of each of these we do multiple other things in our",
    "start": "1851399",
    "end": "1857039"
  },
  {
    "text": "stream we do classific ation we do summary statistics a lot of important stuff that goes on here the summary",
    "start": "1857039",
    "end": "1862080"
  },
  {
    "text": "statistics are mostly for our own monitoring if you're new to building these distributed systems as I was over",
    "start": "1862080",
    "end": "1867440"
  },
  {
    "text": "a couple years ago you'll find out you will monitoring is really important if you don't know that now you're going to",
    "start": "1867440",
    "end": "1872840"
  },
  {
    "text": "find it out so monitoring is very important and our classification is all about identifying the data that's that's coming into US who's it coming from what",
    "start": "1872840",
    "end": "1879360"
  },
  {
    "text": "kind of type is it what should we do with it next and all this is happening in real time another very important",
    "start": "1879360",
    "end": "1884919"
  },
  {
    "text": "component that we do inside our storm event processing is rate monitoring rate monitoring is very important it's related to statistics but rate",
    "start": "1884919",
    "end": "1891440"
  },
  {
    "text": "monitoring is like the valves on an engine it's telling our pipeline what's going on what resources we're going to",
    "start": "1891440",
    "end": "1897559"
  },
  {
    "text": "have to permission in the indexers downstream which I haven't even got to you at so rate monitoring who's sending us at what rate again is very important",
    "start": "1897559",
    "end": "1904200"
  },
  {
    "text": "so that's what rate monitoring is all about in our storm framework and finally we get to the stage where we run a lot of our secret",
    "start": "1904200",
    "end": "1911200"
  },
  {
    "text": "sauce a lot of time we spend in this area and now note I haven't got to the indexers at all yet but a lot of this is",
    "start": "1911200",
    "end": "1917240"
  },
  {
    "text": "about parsing more statistic analysis Aggregates we run on the log data looking for Trends it's all very",
    "start": "1917240",
    "end": "1923639"
  },
  {
    "text": "important what happens in these stages of our storm pipeline the storm pipeline also allows us to bifurcate the streams",
    "start": "1923639",
    "end": "1929720"
  },
  {
    "text": "so for example one of the features that our customers really like is the ability to take their data and send it into S3",
    "start": "1929720",
    "end": "1936720"
  },
  {
    "text": "in parallel with us sending it into our indexers and this explains a little bit how LLY thinks about your data because",
    "start": "1936720",
    "end": "1943279"
  },
  {
    "text": "it's your data at the end of the day and logi does not want to be a culd theack for your data we don't want to we want",
    "start": "1943279",
    "end": "1948519"
  },
  {
    "text": "people to send data to us and then they never see it again apart from through our interface so we offer our customers the option to stream the data in",
    "start": "1948519",
    "end": "1954919"
  },
  {
    "text": "parallel to the rest three buckets because we can never we're never going to think of all the processing that",
    "start": "1954919",
    "end": "1960080"
  },
  {
    "text": "every customer is ever going to want to do on their data so it's important that we make it available to stream out to their individual S3 buckets if we like",
    "start": "1960080",
    "end": "1967080"
  },
  {
    "text": "if they like and we've had this feature in place for quite a while and what's interesting about this is this is just an example other destination sources are",
    "start": "1967080",
    "end": "1975320"
  },
  {
    "text": "are applicable to for example we're very excited about what Amazon and announced yesterday about their Kinesis product",
    "start": "1975320",
    "end": "1980559"
  },
  {
    "text": "there's no reason why Kinesis couldn't simply be another destination of data here perhaps you have some other event processing going on that said Kinesis",
    "start": "1980559",
    "end": "1987559"
  },
  {
    "text": "could also be a source here what's important to us is that the data goes through our Pipeline and we can run the",
    "start": "1987559",
    "end": "1992840"
  },
  {
    "text": "analytics and indexing on that we want so this is the storm Pipeline and from the storm pipeline we go to more CF qes",
    "start": "1992840",
    "end": "2000000"
  },
  {
    "text": "so let's just take a check where we are before we get to the indexers which is where the real heart and soul of our system is Storm provides our Complex",
    "start": "2000000",
    "end": "2006399"
  },
  {
    "text": "events processing where we run much of our secret sauce Kafka contains the data",
    "start": "2006399",
    "end": "2011600"
  },
  {
    "text": "in various stages of processing and what's nice about it it's sitting on EBS so we snapshot those volumes every day",
    "start": "2011600",
    "end": "2017080"
  },
  {
    "text": "to EBS as our fallback for Dr for Disaster Recovery other purposes that we",
    "start": "2017080",
    "end": "2022799"
  },
  {
    "text": "need it's important that we're able to never lose the data it's important with the customer sent us so we snapshot the",
    "start": "2022799",
    "end": "2029639"
  },
  {
    "text": "last day of Kafka events S3 now this is where we start getting to",
    "start": "2029639",
    "end": "2035240"
  },
  {
    "text": "the real heart and soul of our system and how things are are linked together so from CFA we have a more AWS",
    "start": "2035240",
    "end": "2044360"
  },
  {
    "text": "processes more processes after that we run up an AWS now elastic search is obviously very important to us it's and",
    "start": "2044360",
    "end": "2049720"
  },
  {
    "text": "I'll get into it a little bit in a few minutes about how we use it but elastic search you have to do a lot",
    "start": "2049720",
    "end": "2056079"
  },
  {
    "text": "of things to the data if you really wanted to index at a high rate if you don't the CPU usage will go through the",
    "start": "2056079",
    "end": "2061878"
  },
  {
    "text": "roof the ram will go through the roof its own internal state will get quite convoluted and quite hard to manage",
    "start": "2061879",
    "end": "2068679"
  },
  {
    "text": "unless you're very careful about the amount of data that you're pumping into it at the rates and volumes we're talking about here in my experience we",
    "start": "2068679",
    "end": "2076158"
  },
  {
    "text": "met some people in in particularly in San Francisco who were're based we're very interested in elastic search community and people consider a four",
    "start": "2076159",
    "end": "2082760"
  },
  {
    "text": "five six seven not elastic search cluster large I'm not going to give numbers because it scales up and down depending",
    "start": "2082760",
    "end": "2088440"
  },
  {
    "text": "but we have much larger elastic search clusters in that and once you start pushing elastic search Beyond certain nod certain size it works very well but",
    "start": "2088440",
    "end": "2095720"
  },
  {
    "text": "you just have to be more careful and that's why a lot of pre-processing is done on the streams it's also do this to make it easier to index and easier to",
    "start": "2095720",
    "end": "2102240"
  },
  {
    "text": "the data easier to find so up in Amazon we run special dedicated proprietary",
    "start": "2102240",
    "end": "2107280"
  },
  {
    "text": "what we call es Riders we run multiple multiple of these processes in parallel on the AWS infrastructure and they are",
    "start": "2107280",
    "end": "2114040"
  },
  {
    "text": "constantly pulling from the CFA qes again everything is a pull system which makes it very stable if data is coming",
    "start": "2114040",
    "end": "2120640"
  },
  {
    "text": "in temporarily faster than we can pull it it simply backs up in Kafka we don't drop it our previous version which used",
    "start": "2120640",
    "end": "2127000"
  },
  {
    "text": "zmq was memory based so the cues can only get so big before you start getting in trouble the nice thing about cfk is",
    "start": "2127000",
    "end": "2133000"
  },
  {
    "text": "it gives you the performance of memory but the Persistence of dis so our Es riters are pulling constantly pulling",
    "start": "2133000",
    "end": "2139400"
  },
  {
    "text": "data from our CFA qes and sending it into our multi-tier elastic search cluster and I can dig into a little bit",
    "start": "2139400",
    "end": "2145079"
  },
  {
    "text": "of that in a few minutes but this is the life cycle of your data as it has flowed through our system in through the",
    "start": "2145079",
    "end": "2151200"
  },
  {
    "text": "collectors in through Kafka in through storm and in through es and we're very proud of the fact that when the system",
    "start": "2151200",
    "end": "2156839"
  },
  {
    "text": "is working nicely which it is almost all the time less than 10 seconds will have",
    "start": "2156839",
    "end": "2163319"
  },
  {
    "text": "passed from when we received the event to when it's available in the search box in our web app and so we are quite proud",
    "start": "2163319",
    "end": "2169280"
  },
  {
    "text": "of that and as a developer I I want to really make our system operations of different needs but I really want to make our system almost like a Serial",
    "start": "2169280",
    "end": "2175440"
  },
  {
    "text": "port in the sky we all know you can plug a Serial port on your system and I really want to make ours like that so you're talking less than 10 seconds",
    "start": "2175440",
    "end": "2181400"
  },
  {
    "text": "between the whole thing and actually most of that latency is due to CFA because of its periodic flushing to dis",
    "start": "2181400",
    "end": "2187720"
  },
  {
    "text": "you can make that short period shorter but then you pay for it in performance so most of the it's not Network it's",
    "start": "2187720",
    "end": "2193520"
  },
  {
    "text": "just the cyclical flushes that to dis that a lot of the systems we use are doing and so we've made that pretty",
    "start": "2193520",
    "end": "2201040"
  },
  {
    "text": "small now one thing I'd like to point out that Kafka also allows us to do and it's an interesting design principle I think a lot of people can think about",
    "start": "2201040",
    "end": "2206839"
  },
  {
    "text": "when they're building high performance pipelines is especially when you're open to the outside world is I have a friend",
    "start": "2206839",
    "end": "2212119"
  },
  {
    "text": "who works for an ISP in California in Southern California and he told me that he",
    "start": "2212119",
    "end": "2218319"
  },
  {
    "text": "can when you connect to the outside world it's chaos you don't know what data is going to be sent your way and it's our customers have a lot of varied",
    "start": "2218319",
    "end": "2224119"
  },
  {
    "text": "data and we don't have to tell them the schema or the format it has to be beforehand they just send us whatever they want and it's always possible that",
    "start": "2224119",
    "end": "2230599"
  },
  {
    "text": "some bit on the wire that we've seen even though they can follow if they follow certain standards it's it's their",
    "start": "2230599",
    "end": "2236920"
  },
  {
    "text": "data and we have to do our best to help them index it make it available for search is there's always possibly",
    "start": "2236920",
    "end": "2243040"
  },
  {
    "text": "something in their data that that elastic search doesn't like for whatever reason elastic search is a complex system so instead of hammering es and",
    "start": "2243040",
    "end": "2251520"
  },
  {
    "text": "trying to say please Index this data the moment es S I can't Index this data right now we don't drop it because we",
    "start": "2251520",
    "end": "2257119"
  },
  {
    "text": "don't want to lose your data it's very important so we write it to another area of capf called our deferred storage and",
    "start": "2257119",
    "end": "2262280"
  },
  {
    "text": "this allows us to take events out of the pipeline that are currently causing elastic search trouble and leave them",
    "start": "2262280",
    "end": "2267400"
  },
  {
    "text": "there for processing later and then what we can do what we do do is every day twice to day we have a system that wakes",
    "start": "2267400",
    "end": "2272680"
  },
  {
    "text": "up checks the referred storage sees what's in there and can reindex it into El search again perhaps we have to tweak",
    "start": "2272680",
    "end": "2279440"
  },
  {
    "text": "the system slightly but that's generally not the case and this goes back to addressing the two or three design three",
    "start": "2279440",
    "end": "2284640"
  },
  {
    "text": "design principles I spoke about the start is our customers have told us that they would rather have latency than lose",
    "start": "2284640",
    "end": "2291359"
  },
  {
    "text": "data and this allows us to make sure that their data will always be indexed and available for search now I should",
    "start": "2291359",
    "end": "2296599"
  },
  {
    "text": "add sorry I should add that this is a rare scenario but it is important about making our systems correct and we call",
    "start": "2296599",
    "end": "2302480"
  },
  {
    "text": "it our deferred storage there's no Q per se coming off it it's just where data can reside until",
    "start": "2302480",
    "end": "2309720"
  },
  {
    "text": "the other programs can get in and reindex that data so there's actually a lot going on",
    "start": "2309720",
    "end": "2316319"
  },
  {
    "text": "in our system that isn't shown here because it's proprietary it's it's it's pretty important to us and it's supplementary to the pipeline but it is",
    "start": "2316319",
    "end": "2322839"
  },
  {
    "text": "important you get an idea of what this is for example index management is a huge thing that goes on in elastic",
    "start": "2322839",
    "end": "2329119"
  },
  {
    "text": "search elastic search is not intrinsically a multi-tenant system how you create indexes in it and manage",
    "start": "2329119",
    "end": "2335119"
  },
  {
    "text": "those indexes how you make it a multitenant system that's a big part of what loggly does uh we do a lot of",
    "start": "2335119",
    "end": "2340880"
  },
  {
    "text": "pre-processing on the data before it goes in to make sure that it's efficiently indexed by es search query if any of you guys have ever worked with",
    "start": "2340880",
    "end": "2346920"
  },
  {
    "text": "a search engine on the search side there's a ton of stuff you have to do so that the queries you make to your search engine work and remember the point of",
    "start": "2346920",
    "end": "2353920"
  },
  {
    "text": "indexing is to search so indexes we a lot of our index management is that happens in real time as the pipeline is",
    "start": "2353920",
    "end": "2359640"
  },
  {
    "text": "going through is indexes are separated by customer they represent slices of time if you're a customer and you're",
    "start": "2359640",
    "end": "2364800"
  },
  {
    "text": "sending more data to us you'll have more indexes covering a shorter time if you're sending us a small amount of data",
    "start": "2364800",
    "end": "2370440"
  },
  {
    "text": "you'll have one larger indexes covering a longer amount of time our elastic search cluster is also multi-tiered we",
    "start": "2370440",
    "end": "2377160"
  },
  {
    "text": "throw more re resources at the park that's doing much of the heavy lifting if you think about it logs are spread",
    "start": "2377160",
    "end": "2382960"
  },
  {
    "text": "across space and time in terms of their size and space and their time and when they were generated just because you",
    "start": "2382960",
    "end": "2388359"
  },
  {
    "text": "generate a log message today doesn't mean that you're going to send it us today perhaps you'll send it to us in a week but most log messages are in real",
    "start": "2388359",
    "end": "2394880"
  },
  {
    "text": "time so we can in we throw most of our indexing resources at at messages that are near real time it also a lot of the",
    "start": "2394880",
    "end": "2403119"
  },
  {
    "text": "software we wrot allows us to make efficient use of the AWS resources and that's what a lot of stuff isn't shown",
    "start": "2403119",
    "end": "2408880"
  },
  {
    "text": "here but that's because it's outside the main pipeline which is what we're talking about today another big Advantage we found",
    "start": "2408880",
    "end": "2415400"
  },
  {
    "text": "with Kafka and uh and our general Pipeline and I think this is something else that people may like to learn about is how we do staging now all companies",
    "start": "2415400",
    "end": "2423000"
  },
  {
    "text": "they know what they're doing have a staging idea before you roll software on into production you put it into staging",
    "start": "2423000",
    "end": "2428119"
  },
  {
    "text": "cross your fingers if you don't and it's a dress rehearsal for your operations team to see is there any gotches any",
    "start": "2428119",
    "end": "2433599"
  },
  {
    "text": "schema changes anything that just is mind have CAU them but you want your staging system to be a true reflection",
    "start": "2433599",
    "end": "2440680"
  },
  {
    "text": "of your production system you want the same data you go through it it's not much Point sending test data I've been burned more than once by sending test",
    "start": "2440680",
    "end": "2446839"
  },
  {
    "text": "data through our system everything looks lovely and then you send real data and it acts completely differently yet at",
    "start": "2446839",
    "end": "2452319"
  },
  {
    "text": "the same time you don't want to build a staging system as large as your production system because you don't have to their entire operations team so we",
    "start": "2452319",
    "end": "2459800"
  },
  {
    "text": "managed to use a feature of Kafka that made running a staging system very very nice and to go back to it this is the",
    "start": "2459800",
    "end": "2466160"
  },
  {
    "text": "ingest the first stage of the ingestion system that I spoke about we got the collectors Kafka Brokers",
    "start": "2466160",
    "end": "2471640"
  },
  {
    "text": "storm because of the way Kafka works it's the data is written randomly across",
    "start": "2471640",
    "end": "2476880"
  },
  {
    "text": "these entire partitions so say for example you have 10 partitions in Kafka and you're just streaming data into CFA",
    "start": "2476880",
    "end": "2483000"
  },
  {
    "text": "in its default mode any one of those partitions has precisely a on10th s sample of your data so this is really",
    "start": "2483000",
    "end": "2489280"
  },
  {
    "text": "nice if you think about it you want a small but representative sample of your incoming traffic it could be a",
    "start": "2489280",
    "end": "2494680"
  },
  {
    "text": "clickstream it could be log data it could be perhaps photos that somebody are posting but you get a really nice",
    "start": "2494680",
    "end": "2500160"
  },
  {
    "text": "sample so we've used that to mirror we don't want to stream to mirror a",
    "start": "2500160",
    "end": "2505720"
  },
  {
    "text": "fraction of our production stream and send it into a scal down version of our staging system and this is really really",
    "start": "2505720",
    "end": "2512240"
  },
  {
    "text": "nice and it's worked out really well for us so we get to reuse a lot of our infrastructure but still get a represent resentative sample of data going into",
    "start": "2512240",
    "end": "2518839"
  },
  {
    "text": "what is our most complex part of our pipeline which is storm and elastic search onwards so just to summarize that",
    "start": "2518839",
    "end": "2525520"
  },
  {
    "text": "because the Kafka broker doesn't care the Kafka cluster doesn't care how many consumers there are you can add as many",
    "start": "2525520",
    "end": "2530800"
  },
  {
    "text": "consumers as you want and Kafka doesn't care the performance doesn't drop and this allows us to",
    "start": "2530800",
    "end": "2535960"
  },
  {
    "text": "run uh this staging architecture it's a highly effective",
    "start": "2535960",
    "end": "2541440"
  },
  {
    "start": "2540000",
    "end": "2540000"
  },
  {
    "text": "pre-production system and anybody who's using cfar or similar technology the AWS Kinesis system would you to do the same",
    "start": "2541440",
    "end": "2547920"
  },
  {
    "text": "I was at the presentation yesterday it's something to think about it's really really nice so let me get into the meat of some",
    "start": "2547920",
    "end": "2554040"
  },
  {
    "text": "of the technical details that might be helpful to you guys out there to say how we actually deploy the system in AWS",
    "start": "2554040",
    "end": "2559720"
  },
  {
    "text": "what instance types did we use what I Ops did we use to give you an idea of what's you you've got in mind if you",
    "start": "2559720",
    "end": "2564920"
  },
  {
    "text": "want to start building systems like this our colle now the numbers don't",
    "start": "2564920",
    "end": "2570079"
  },
  {
    "text": "matter I mean they do matter to us but the number of instances changes because of the way our system works and the way",
    "start": "2570079",
    "end": "2576440"
  },
  {
    "text": "we use aw the point is what types do we use for our collectors we use c1x large",
    "start": "2576440",
    "end": "2581640"
  },
  {
    "start": "2577000",
    "end": "2577000"
  },
  {
    "text": "instances collectors are all about dis and network IO they don't care about uh dis so CPU is a big deal network is a",
    "start": "2581640",
    "end": "2588720"
  },
  {
    "text": "big deal and uh RAM was a big deal so we found that the c1x large instances were a good price point between and",
    "start": "2588720",
    "end": "2594280"
  },
  {
    "text": "performance for our what are basically high performance Network ingestion software appliances now Kafka is very",
    "start": "2594280",
    "end": "2601480"
  },
  {
    "text": "different Kafka is all about giving it plenty of ram so that the Linux operating system can use it to buffer the disc cache so we run our Kafka",
    "start": "2601480",
    "end": "2608520"
  },
  {
    "text": "clusters Brokers on M2 2x large machines I think they have 34 gbt of ram 3 gigs",
    "start": "2608520",
    "end": "2614119"
  },
  {
    "text": "is given to the jvm and the rest is just left to Linux to buffer the disc cash so memory optimized instances CPUs these",
    "start": "2614119",
    "end": "2621440"
  },
  {
    "text": "are by no means uh slow in machines but they're they have a different bias towards RAM and CPU versus the",
    "start": "2621440",
    "end": "2627920"
  },
  {
    "text": "collectors and then very important as you can imagine because CFA persisted dis iio was very important and we put oh",
    "start": "2627920",
    "end": "2634839"
  },
  {
    "text": "excuse me we put a going forward there we put a 4K provisioned iops EBS volumes",
    "start": "2634839",
    "end": "2641119"
  },
  {
    "text": "underneath CFA why do we do this EBS is persistent you have to monitor it but it",
    "start": "2641119",
    "end": "2646240"
  },
  {
    "text": "is persistent but the provisioned iops volumes gives you consistent performance which is really important when it comes",
    "start": "2646240",
    "end": "2652280"
  },
  {
    "text": "to test so I can say today that the Kafka cluster we have can can write",
    "start": "2652280",
    "end": "2657960"
  },
  {
    "text": "250,000 messages to dis per second tomorrow it'll be able to write 250,000 messages to disc per second and at",
    "start": "2657960",
    "end": "2664200"
  },
  {
    "text": "Sunday at 4: a.m. when somebody bursts to us they can write 400,000 messages events per second to dis provision iops",
    "start": "2664200",
    "end": "2670520"
  },
  {
    "text": "gives you that because in Amazon it's a multi-tenant system you've got noisy neighbors if you use uh unpro un",
    "start": "2670520",
    "end": "2676599"
  },
  {
    "text": "unprovisioned iops EBS volumes your your um performance can be great one day and",
    "start": "2676599",
    "end": "2681760"
  },
  {
    "text": "poor the next day and I guarantee you you'll be doing your performance testing the day that it's really really good and walk away feeling",
    "start": "2681760",
    "end": "2687440"
  },
  {
    "text": "great um so the 4K provision Diop ensures consistent IO no noisy neighbors",
    "start": "2687440",
    "end": "2694359"
  },
  {
    "text": "and it is persistent of course so as long as you monitor it you can be sure sure that your data is safe bu 4K 4K as",
    "start": "2694359",
    "end": "2700160"
  },
  {
    "text": "fast as you can buy at Amazon right now we did this is a very important part of our system it's where our customer data",
    "start": "2700160",
    "end": "2705960"
  },
  {
    "text": "lives we needed High IO performance storm actually this is pretty standard if anybody's familiar",
    "start": "2705960",
    "end": "2713280"
  },
  {
    "start": "2711000",
    "end": "2711000"
  },
  {
    "text": "with the storm starter project this is the specs that they say you should run a storm cluster in the difference is how",
    "start": "2713280",
    "end": "2718559"
  },
  {
    "text": "many instances of each you run again we run the c1x large storm is all about compute RAM and network it's not writing",
    "start": "2718559",
    "end": "2725359"
  },
  {
    "text": "anything to dis apart from the log files but it doesn't do that because the log files go to our another one of our systems right uh so we run our storm",
    "start": "2725359",
    "end": "2732839"
  },
  {
    "text": "worker nodes our storm supervisor nodes on c1x large our operations seem appreciate this because it's the same instance type as which we run the",
    "start": "2732839",
    "end": "2739280"
  },
  {
    "text": "collectors the configuration and management components which is stor excuse me storm Nimbus and our zookeeper",
    "start": "2739280",
    "end": "2744440"
  },
  {
    "text": "cluster we don't need huge machines for these we run them at m1x large again 64-bit machines general purpose",
    "start": "2744440",
    "end": "2751319"
  },
  {
    "text": "configuration and management not a huge amount going on here but they work quite well for us spread across multiple",
    "start": "2751319",
    "end": "2758119"
  },
  {
    "text": "availability zones which is very important this is where we spend our",
    "start": "2758119",
    "end": "2764520"
  },
  {
    "start": "2762000",
    "end": "2762000"
  },
  {
    "text": "money as Charlie our CEO knows quite well this is our multi-tiered elastic search cluster uh we have done a lot of",
    "start": "2764520",
    "end": "2770800"
  },
  {
    "text": "work in our pre- indexing pipeline to ensure that when es has work to do it",
    "start": "2770800",
    "end": "2777520"
  },
  {
    "text": "has the least amount of work to do possible with the result that our indexing performance is and all the",
    "start": "2777520",
    "end": "2783839"
  },
  {
    "text": "testing performance and measurement we done is only limited by IO it's not CPU bound if you don't do a lot of the",
    "start": "2783839",
    "end": "2789000"
  },
  {
    "text": "pre-processing that we do before you'll find that the CPUs get busy quite quickly but we still need some fairly",
    "start": "2789000",
    "end": "2795440"
  },
  {
    "text": "beefy machines here we use a cluster compute 8ex large machines um for 4K",
    "start": "2795440",
    "end": "2801440"
  },
  {
    "text": "provision iops EBS volumes and we get great performance from these",
    "start": "2801440",
    "end": "2808119"
  },
  {
    "text": "machines we put 4K iops volumes underneath it um really good performance and then in",
    "start": "2808119",
    "end": "2813920"
  },
  {
    "text": "our second tier in tier two we have uh 4K provision diaps well slightly smaller slightly smaller instances because this",
    "start": "2813920",
    "end": "2820200"
  },
  {
    "text": "is where not as much of the heavy lifting lifting goes on but this works really really well for us and we've got great",
    "start": "2820200",
    "end": "2826280"
  },
  {
    "text": "um great performance here for for our indexing the next slide here so I'd like",
    "start": "2826280",
    "end": "2833400"
  },
  {
    "text": "to finish with a couple of few fall STS that we worked through uh in our in our pipeline to give you a couple of ideas",
    "start": "2833400",
    "end": "2839680"
  },
  {
    "text": "call technologies that um work well for many people but didn't",
    "start": "2839680",
    "end": "2844960"
  },
  {
    "text": "work as well for us as we hoped and we used a different different designs so the first thing we tried to",
    "start": "2844960",
    "end": "2850800"
  },
  {
    "text": "do is we tried to we we tried to put an elb in front of our collectors and we knew that we'd have to run multiple",
    "start": "2850800",
    "end": "2856200"
  },
  {
    "start": "2852000",
    "end": "2852000"
  },
  {
    "text": "collectors even though one of them would be enough to take much of our load for a long time so we had we knew we'd have to",
    "start": "2856200",
    "end": "2862160"
  },
  {
    "text": "run at least three and we tried to put a put an elb in front of our collectors but it didn't work very well even though",
    "start": "2862160",
    "end": "2868240"
  },
  {
    "text": "it works very well for our web apps why doesn't it work elastic load balancers don't allow forwarding on Port",
    "start": "2868240",
    "end": "2875319"
  },
  {
    "text": "514 which is where we send a lot of our which is the standard CIS log Port according to the RFC so they",
    "start": "2875319",
    "end": "2882079"
  },
  {
    "text": "don't wouldn't use that also elastic L balancers don't use don't support forwarding over UDP another blocker",
    "start": "2882079",
    "end": "2888520"
  },
  {
    "text": "since we wanted to put it since some customers do prefer to send messages over UDP and also we actually found that",
    "start": "2888520",
    "end": "2894040"
  },
  {
    "text": "the elastic low balancer simply didn't reach the performance characteristics that we needed uh we tried to send plenty of",
    "start": "2894040",
    "end": "2900520"
  },
  {
    "text": "data through them and sometimes they would just not really keep up with the amount of traffic that we wanted to send through so quickly we found out that an",
    "start": "2900520",
    "end": "2906920"
  },
  {
    "text": "B isn't really built to be balancing high performance streaming software based Network appliances it's great for",
    "start": "2906920",
    "end": "2913800"
  },
  {
    "text": "our uh web app front ends but it's it's not really suitable for when you want to balance traffic into these Network",
    "start": "2913800",
    "end": "2919280"
  },
  {
    "text": "appliances software Network appliances that we put together what we did like and Jim actually worked in this he's a",
    "start": "2919280",
    "end": "2924960"
  },
  {
    "text": "big fan of this is we used Amazon 53 DNS um what's nice about this is when you resolve to one of our collectors you",
    "start": "2924960",
    "end": "2931040"
  },
  {
    "start": "2925000",
    "end": "2925000"
  },
  {
    "text": "actually get the IP address of The Collector itself so your data gets to go right into the high performance software",
    "start": "2931040",
    "end": "2936280"
  },
  {
    "text": "that we spend so much time working on and as gym Li says it's not a bump in the wire in other words your traffic",
    "start": "2936280",
    "end": "2941760"
  },
  {
    "text": "gets to a socket that's on the collectors and it works really well we take advantage of the a AWS health check so that if a collector goes wonky or an",
    "start": "2941760",
    "end": "2948240"
  },
  {
    "text": "A an AWS a drops out um it's transparent to our customers and this has actually",
    "start": "2948240",
    "end": "2954359"
  },
  {
    "text": "saved us on at least one occasion since we went live three months ago Amazon had",
    "start": "2954359",
    "end": "2959680"
  },
  {
    "text": "an a outage but none of our customers noticed because the Route 53 DNS made it transparent to our customers and it",
    "start": "2959680",
    "end": "2967119"
  },
  {
    "text": "helps because it works across multiple regions in azs so we can deploy collectors as geographically widespread",
    "start": "2967119",
    "end": "2972160"
  },
  {
    "text": "as we like so there's another thing I wanted to talk about just to give you AE give",
    "start": "2972160",
    "end": "2978559"
  },
  {
    "text": "you an idea of another idea we had early on in our design for use that we didn't have going with and it was Cassandra I'm",
    "start": "2978559",
    "end": "2983960"
  },
  {
    "text": "sure that many of you are familiar with Cassandra here and it's a highly scalable key Value Store really good right performance um it works very well",
    "start": "2983960",
    "end": "2992280"
  },
  {
    "text": "for a lot of the the target applications that it's used for and we've met with the we met with the data sax guys it",
    "start": "2992280",
    "end": "2998079"
  },
  {
    "text": "works really well and what we tried to do with cassander was we knew we'd have to have a queue and we knew we'd have to",
    "start": "2998079",
    "end": "3003400"
  },
  {
    "text": "have an authorative data stores where we would store your data your events and we at the time thought wouldn't it be great",
    "start": "3003400",
    "end": "3009520"
  },
  {
    "text": "if we could use the same technology to do both it may be obvious to some of you but key value stores for us are not we",
    "start": "3009520",
    "end": "3016799"
  },
  {
    "text": "did not find them to be a good match to try and build a queue so we struggled with this for a little while and it just",
    "start": "3016799",
    "end": "3022799"
  },
  {
    "text": "turned out not to be the right thing to do it was better to use a proper queuing system um while we were trying to do this we we",
    "start": "3022799",
    "end": "3030000"
  },
  {
    "text": "we came up with lots of wide row schemas trying to work out how we could both",
    "start": "3030000",
    "end": "3035160"
  },
  {
    "text": "track the order and which events were received but when they came out of order make sure that we still had the order",
    "start": "3035160",
    "end": "3040960"
  },
  {
    "text": "when we sent them into the indexers Because if you think about it there's one other thing about log messages that's very important you don't want you",
    "start": "3040960",
    "end": "3046960"
  },
  {
    "text": "always want to accept them you always want to drop them or you always want not drop them you don't want to drop them",
    "start": "3046960",
    "end": "3052440"
  },
  {
    "text": "you always want to keep them around but you also want to present them to you the end user in in the order for which they",
    "start": "3052440",
    "end": "3057680"
  },
  {
    "text": "were received if you as a developer have two messages in two different loops and one Loop happens before the other but we",
    "start": "3057680",
    "end": "3063480"
  },
  {
    "text": "present the log messages in the ref first order and you believe us you might think wow my software is not working the",
    "start": "3063480",
    "end": "3068720"
  },
  {
    "text": "way I want or the machine went down after the disc filled up as opposed to the dis filling up when the machine went",
    "start": "3068720",
    "end": "3074680"
  },
  {
    "text": "down so it was very difficult for us to get Cassandra to resolve this issue of how do we make sure that we remember the",
    "start": "3074680",
    "end": "3080880"
  },
  {
    "text": "order of events and to cut a long story short it it um key value stores are not",
    "start": "3080880",
    "end": "3086760"
  },
  {
    "text": "cues they're great as authoritative sources but they're not good cues and as our design went on elastic search",
    "start": "3086760",
    "end": "3093160"
  },
  {
    "text": "intrinsics elastic searches intrinsic support for key value store was actually good enough that we now use elastic",
    "start": "3093160",
    "end": "3099240"
  },
  {
    "text": "searches both the indexes and the authoritative data stores so actually our need for Cassandra and other key",
    "start": "3099240",
    "end": "3104599"
  },
  {
    "text": "value stores has actually has kind of gone away and we don't really need them as much as we used to with the result that Cassandra is not in our pipeline",
    "start": "3104599",
    "end": "3110960"
  },
  {
    "text": "today the other thing is while Cassandra is very reliable it's got replicas Quorum reads Quorum writes I could write",
    "start": "3110960",
    "end": "3117359"
  },
  {
    "text": "100,000 events to it very easily after a couple of days playing with it it's still a complex system it's going to",
    "start": "3117359",
    "end": "3122520"
  },
  {
    "text": "have outages it's going to have failures and in the event that we had a system whereby collectors were streaming into CFA or streaming into Cassandra what",
    "start": "3122520",
    "end": "3129640"
  },
  {
    "text": "would they do if Cassandra was down which is going to happen and we realized well they're going to have to buffer to dis but if collectors are going to",
    "start": "3129640",
    "end": "3136160"
  },
  {
    "text": "buffer to dis maybe we should just have them Rite into Kafka and let Kafka buffer to dis and CFA is so much simpler",
    "start": "3136160",
    "end": "3142359"
  },
  {
    "text": "in many ways if it's simpler it's more liable to stay up and that's what we have found so this is the reason why we",
    "start": "3142359",
    "end": "3147720"
  },
  {
    "text": "didn't put a we left our most complex components elastic search and the like much deeper in the pipeline after we",
    "start": "3147720",
    "end": "3154400"
  },
  {
    "text": "were sure that our events were safely persisted to disk",
    "start": "3154400",
    "end": "3160520"
  },
  {
    "text": "so to to finish up I'll just give you a summary of what we found as big winds um",
    "start": "3160520",
    "end": "3166400"
  },
  {
    "text": "multi- region multi-az has really worked for us Amazon Hammer this point or AWS Hammer this point home a lot but it",
    "start": "3166400",
    "end": "3172440"
  },
  {
    "text": "really does work deployer services in multiple regions multiple zones run your",
    "start": "3172440",
    "end": "3177480"
  },
  {
    "text": "processes on smaller instances if it means that you end up with nine as opposed to three because you want",
    "start": "3177480",
    "end": "3184200"
  },
  {
    "text": "smaller in my experience many smaller pieces are better than large monolithic",
    "start": "3184200",
    "end": "3189920"
  },
  {
    "text": "pieces large monolithic pieces are for pre-2000 smaller autoscaling pieces are",
    "start": "3189920",
    "end": "3196280"
  },
  {
    "text": "what works well with the cloud because you can deploy it in multiple availability zones provision diaps it's",
    "start": "3196280",
    "end": "3202079"
  },
  {
    "text": "done what it said on the tin gives us consistent performance allows us to scale allows us to test Jim has been a",
    "start": "3202079",
    "end": "3208720"
  },
  {
    "text": "big fan of AWS Route 53 worked very well for us never let us down and being able to you know the being able to apply that",
    "start": "3208720",
    "end": "3215160"
  },
  {
    "text": "elasticity to uh increase storm and decrease storm resources has helped a lot too so that's been really nice so um",
    "start": "3215160",
    "end": "3223079"
  },
  {
    "text": "and leveraging open source infrastructure of course using the technology I talked about has been really good and allowed us to concentrate on building the search and",
    "start": "3223079",
    "end": "3228839"
  },
  {
    "text": "analytics that that we're really interested in building um so let me finish by saying the at the end of the",
    "start": "3228839",
    "end": "3235000"
  },
  {
    "text": "day the reason we build these pipes I mean it's fun as an engineer to move bits from place to place but the reason",
    "start": "3235000",
    "end": "3241480"
  },
  {
    "text": "I get excited is because all the computers that we're working with are constantly talking right they're just constantly saying stuff they never shut",
    "start": "3241480",
    "end": "3247559"
  },
  {
    "text": "up they're constantly saying stuff to us and we as human beings can never listen to it all and it goes back to Jim's",
    "start": "3247559",
    "end": "3253920"
  },
  {
    "text": "point that I think if you were to take one thing away from this talk it would be forget about people listening to your",
    "start": "3253920",
    "end": "3259880"
  },
  {
    "text": "computers think about computers listening to your computers because that changes the diagnostic information that",
    "start": "3259880",
    "end": "3265400"
  },
  {
    "text": "your computers will spit out and so you're able to ask the one set of computers what are these other set of",
    "start": "3265400",
    "end": "3270839"
  },
  {
    "text": "computers doing and there's a lot of magic that has to happen there but of course there's no magic right it has to be built but the point of all this is to",
    "start": "3270839",
    "end": "3277839"
  },
  {
    "text": "build applications and build systems that will allow you to um produce applications yes this is",
    "start": "3277839",
    "end": "3285240"
  },
  {
    "text": "ours but allows you to produce applications that give and bring joy to your customers and and they can really",
    "start": "3285240",
    "end": "3290440"
  },
  {
    "text": "enjoy using it so that's it and gimini will be around for questions if anybody has at moment",
    "start": "3290440",
    "end": "3296920"
  },
  {
    "text": "out of time we have four minutes I think for questions if anybody has any questions but otherwise we would be around so thank you very much",
    "start": "3296920",
    "end": "3305040"
  }
]
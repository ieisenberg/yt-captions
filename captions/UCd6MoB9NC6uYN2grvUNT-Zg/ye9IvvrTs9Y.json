[
  {
    "text": "Hello, I'm Subhash Talluri,",
    "start": "3870",
    "end": "5279"
  },
  {
    "text": "and what we have is a solution",
    "start": "5280",
    "end": "6750"
  },
  {
    "text": "with COX Communications looking at",
    "start": "6750",
    "end": "9000"
  },
  {
    "text": "Intelligent Service Health\nusing Generative AI.",
    "start": "9000",
    "end": "11493"
  },
  {
    "text": "We built a forensic tool to\nhelp network operations center",
    "start": "14160",
    "end": "17580"
  },
  {
    "text": "and field technicians to\nreduce meantime to detect,",
    "start": "17580",
    "end": "20670"
  },
  {
    "text": "diagnose, and remediate network issues.",
    "start": "20670",
    "end": "23490"
  },
  {
    "text": "Today it takes about\neight hours altogether.",
    "start": "23490",
    "end": "26430"
  },
  {
    "text": "We reduced that to a matter of seconds.",
    "start": "26430",
    "end": "28863"
  },
  {
    "text": "We have done that in a two-step process.",
    "start": "32490",
    "end": "34770"
  },
  {
    "text": "One is we build a service help platform",
    "start": "34770",
    "end": "37530"
  },
  {
    "text": "and the platform taps into\nevery operational platform",
    "start": "37530",
    "end": "42530"
  },
  {
    "text": "of COX Communications,",
    "start": "42630",
    "end": "44250"
  },
  {
    "text": "looking at data coming from\nrouters, switches, and modems,",
    "start": "44250",
    "end": "48030"
  },
  {
    "text": "and it's streamed into AWS Data Lake.",
    "start": "48030",
    "end": "51120"
  },
  {
    "text": "The service cell platform",
    "start": "51120",
    "end": "52260"
  },
  {
    "text": "is powered by a custom built angular UI,",
    "start": "52260",
    "end": "54692"
  },
  {
    "text": "which is looking at,",
    "start": "56490",
    "end": "57693"
  },
  {
    "text": "you know, we have a network filter",
    "start": "58800",
    "end": "61200"
  },
  {
    "text": "through which we look at the headend site",
    "start": "61200",
    "end": "63930"
  },
  {
    "text": "all the way to the node level.",
    "start": "63930",
    "end": "65550"
  },
  {
    "text": "And at the node level,",
    "start": "65550",
    "end": "66960"
  },
  {
    "text": "we are showing all the homes\nthat are connected to the node,",
    "start": "66960",
    "end": "70799"
  },
  {
    "text": "looking at service experience,\ncustomer interactions,",
    "start": "70800",
    "end": "73470"
  },
  {
    "text": "offline modem activity,",
    "start": "73470",
    "end": "75270"
  },
  {
    "text": "and on top of the service health,",
    "start": "75270",
    "end": "77159"
  },
  {
    "text": "which gives a real time\nstate of the network,",
    "start": "77160",
    "end": "80370"
  },
  {
    "text": "we have built a conversational UI,",
    "start": "80370",
    "end": "82710"
  },
  {
    "text": "which is powered by Generative AI.",
    "start": "82710",
    "end": "85680"
  },
  {
    "text": "Imagine we have a network\ntechnicians who needs to perform",
    "start": "85680",
    "end": "89280"
  },
  {
    "text": "or diagnose an active event or\ntroubleshoot a network issue.",
    "start": "89280",
    "end": "93330"
  },
  {
    "text": "At that point,",
    "start": "93330",
    "end": "94380"
  },
  {
    "text": "he would come into this\nservice cell platform,",
    "start": "94380",
    "end": "97770"
  },
  {
    "text": "use the conversational UI",
    "start": "97770",
    "end": "99479"
  },
  {
    "text": "to ask and answer freeform text",
    "start": "99480",
    "end": "101670"
  },
  {
    "text": "about historic work that was\ndone on the network element.",
    "start": "101670",
    "end": "106320"
  },
  {
    "text": "So at this point, the NOC engineer",
    "start": "106320",
    "end": "108840"
  },
  {
    "text": "or a technician asking that question",
    "start": "108840",
    "end": "111149"
  },
  {
    "text": "to the analytics dashboard,",
    "start": "111150",
    "end": "113220"
  },
  {
    "text": "the solution or the response",
    "start": "113220",
    "end": "115770"
  },
  {
    "text": "that is orchestrated by AWS Lambda,",
    "start": "115770",
    "end": "119460"
  },
  {
    "text": "the language model\nunderstands the semantics",
    "start": "119460",
    "end": "121740"
  },
  {
    "text": "of the user question, interprets that,",
    "start": "121740",
    "end": "125100"
  },
  {
    "text": "and taps into the right data source.",
    "start": "125100",
    "end": "127740"
  },
  {
    "text": "The orchestration, which\nis done by AWS Lambda.",
    "start": "127740",
    "end": "130112"
  },
  {
    "text": "What you see here is a concise summary.",
    "start": "131220",
    "end": "133653"
  },
  {
    "text": "When we retrieve the context\nfrom the original data source,",
    "start": "134490",
    "end": "137460"
  },
  {
    "text": "it goes into Amazon Bedrock\nand Tropic Cloud Model two.",
    "start": "137460",
    "end": "141810"
  },
  {
    "text": "We are summarizing about\n50,000 tokens of text",
    "start": "141810",
    "end": "144989"
  },
  {
    "text": "into less than 200 tokens\nin a chronological manner,",
    "start": "144990",
    "end": "149310"
  },
  {
    "text": "which concise, which is\nmeaningful, and factually accurate.",
    "start": "149310",
    "end": "153810"
  },
  {
    "text": "Behind the scenes, we have done\nextensive prompt engineering",
    "start": "153810",
    "end": "156540"
  },
  {
    "text": "that systematically filters out noise",
    "start": "156540",
    "end": "159989"
  },
  {
    "text": "such as automatic tickets\nthat were open and closed,",
    "start": "159990",
    "end": "163500"
  },
  {
    "text": "which is something that a technician",
    "start": "163500",
    "end": "164790"
  },
  {
    "text": "does not need to know.",
    "start": "164790",
    "end": "166079"
  },
  {
    "text": "And then further along\nwe have enabled Q and A.",
    "start": "166080",
    "end": "169830"
  },
  {
    "text": "So what now happens",
    "start": "169830",
    "end": "171750"
  },
  {
    "text": "is a technician can ask further questions.",
    "start": "171750",
    "end": "175080"
  },
  {
    "text": "For example, list all the\ntickets that were raised.",
    "start": "175080",
    "end": "177690"
  },
  {
    "text": "So at that point we are\nlisting all the tickets.",
    "start": "177690",
    "end": "179850"
  },
  {
    "text": "This enables a drill down,",
    "start": "179850",
    "end": "181773"
  },
  {
    "text": "a drill down fashion of\ndiagnosing an active event",
    "start": "182975",
    "end": "186630"
  },
  {
    "text": "by taking the network ticket",
    "start": "186630",
    "end": "188490"
  },
  {
    "text": "and understanding the\nspecifics of that ticket.",
    "start": "188490",
    "end": "191700"
  },
  {
    "text": "So going forward, we have also used",
    "start": "191700",
    "end": "193530"
  },
  {
    "text": "a multi RAG design pattern",
    "start": "193530",
    "end": "195780"
  },
  {
    "text": "where a traditional RAG\nwould tap into one source.",
    "start": "195780",
    "end": "199650"
  },
  {
    "text": "In this case, we are\nlooking at multiple sources,",
    "start": "199650",
    "end": "202290"
  },
  {
    "text": "taking that information into\ncontext of a language model,",
    "start": "202290",
    "end": "206069"
  },
  {
    "text": "understanding the\nsemantics of the question.",
    "start": "206070",
    "end": "208440"
  },
  {
    "text": "So what you see here is the\nsummary of telemetry events.",
    "start": "208440",
    "end": "211560"
  },
  {
    "text": "At that point, we go\ninto network telemetry,",
    "start": "211560",
    "end": "214440"
  },
  {
    "text": "retrieve that context.",
    "start": "214440",
    "end": "216420"
  },
  {
    "text": "Further along what we have,\nwhat we show is we have,",
    "start": "216420",
    "end": "220380"
  },
  {
    "text": "you know, if,",
    "start": "220380",
    "end": "221250"
  },
  {
    "text": "let's assume that the\ntechnician has identified",
    "start": "221250",
    "end": "224020"
  },
  {
    "text": "if an amplifier to be an issue.",
    "start": "224880",
    "end": "227760"
  },
  {
    "text": "So at that point a free\nform question could be",
    "start": "227760",
    "end": "230700"
  },
  {
    "text": "that are any of the reported outages",
    "start": "230700",
    "end": "233489"
  },
  {
    "text": "that are related to an amplifier fault?",
    "start": "233490",
    "end": "236100"
  },
  {
    "text": "So we now, we are now trying to correlate",
    "start": "236100",
    "end": "238410"
  },
  {
    "text": "between remedy journal entries\nand network telemetry events,",
    "start": "238410",
    "end": "243410"
  },
  {
    "text": "and we have a response\nfrom the Gen AI system",
    "start": "243720",
    "end": "246780"
  },
  {
    "text": "that's trying to identify if\nthere are any correlations,",
    "start": "246780",
    "end": "249630"
  },
  {
    "text": "and further along a technician can ask",
    "start": "249630",
    "end": "252060"
  },
  {
    "text": "for troubleshooting steps, for example,",
    "start": "252060",
    "end": "254040"
  },
  {
    "text": "of an amplifier fault.",
    "start": "254040",
    "end": "255540"
  },
  {
    "text": "In that case, we bring\nthat troubleshooting guides",
    "start": "255540",
    "end": "258959"
  },
  {
    "text": "and the information from the\ntroubleshooting information",
    "start": "258960",
    "end": "261030"
  },
  {
    "text": "into context to answer that question.",
    "start": "261030",
    "end": "263700"
  },
  {
    "text": "So effectively what we have done is,",
    "start": "263700",
    "end": "266940"
  },
  {
    "text": "for the customer benefit,",
    "start": "266940",
    "end": "268020"
  },
  {
    "text": "we have effectively reduced\nthe diagnostic interval",
    "start": "268020",
    "end": "270330"
  },
  {
    "text": "from hours to minutes.",
    "start": "270330",
    "end": "272849"
  },
  {
    "text": "Today, COX technicians take up to a day,",
    "start": "272850",
    "end": "276240"
  },
  {
    "text": "about eight hours to pull information",
    "start": "276240",
    "end": "278550"
  },
  {
    "text": "from multiple data sources",
    "start": "278550",
    "end": "280560"
  },
  {
    "text": "and diagnose and remediate active events.",
    "start": "280560",
    "end": "284370"
  },
  {
    "text": "We reduce that to a matter of seconds.",
    "start": "284370",
    "end": "286800"
  },
  {
    "text": "We have a scalable low latency design.",
    "start": "286800",
    "end": "289409"
  },
  {
    "text": "The backend architecture that we have has,",
    "start": "289410",
    "end": "292170"
  },
  {
    "text": "we have differentiated between\nRAG runtime and pipeline.",
    "start": "292170",
    "end": "295440"
  },
  {
    "text": "That means any of the historic summaries",
    "start": "295440",
    "end": "297425"
  },
  {
    "text": "can be pre-populated,\nstored in a vector database",
    "start": "297425",
    "end": "301169"
  },
  {
    "text": "such as Amazon Open Search.",
    "start": "301170",
    "end": "303210"
  },
  {
    "text": "And then at runtime to a user question,",
    "start": "303210",
    "end": "306960"
  },
  {
    "text": "the response is only exporting\nthrough the vector space",
    "start": "306960",
    "end": "311250"
  },
  {
    "text": "and effectively we have\nreduced the latency",
    "start": "311250",
    "end": "313380"
  },
  {
    "text": "to less than 10 seconds.",
    "start": "313380",
    "end": "315570"
  },
  {
    "text": "So thank you for watching this demo.",
    "start": "315570",
    "end": "317850"
  },
  {
    "text": "I hope you have great takeaways from this",
    "start": "317850",
    "end": "320910"
  },
  {
    "text": "and we hope to implement this",
    "start": "320910",
    "end": "323400"
  },
  {
    "text": "with many of your customers and partners.",
    "start": "323400",
    "end": "326817"
  }
]
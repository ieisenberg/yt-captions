[
  {
    "text": "hello everyone this is sunny i'm a",
    "start": "1120",
    "end": "2879"
  },
  {
    "text": "specialist customer solutions manager in",
    "start": "2879",
    "end": "4799"
  },
  {
    "text": "data analytics",
    "start": "4799",
    "end": "6480"
  },
  {
    "text": "today we're going to talk about amazon",
    "start": "6480",
    "end": "8480"
  },
  {
    "text": "redshift built-in feature called",
    "start": "8480",
    "end": "10240"
  },
  {
    "text": "spectrum",
    "start": "10240",
    "end": "10960"
  },
  {
    "text": "that enables users to query data",
    "start": "10960",
    "end": "12799"
  },
  {
    "text": "directly in their data lake without",
    "start": "12799",
    "end": "14320"
  },
  {
    "text": "having to load their data or duplicating",
    "start": "14320",
    "end": "16240"
  },
  {
    "text": "their infrastructure",
    "start": "16240",
    "end": "18640"
  },
  {
    "text": "we've seen a proliferation of data and",
    "start": "18640",
    "end": "20960"
  },
  {
    "text": "the data sources",
    "start": "20960",
    "end": "22800"
  },
  {
    "text": "with iot devices smart devices and",
    "start": "22800",
    "end": "24960"
  },
  {
    "text": "social media essentially adding to the",
    "start": "24960",
    "end": "27039"
  },
  {
    "text": "streaming data",
    "start": "27039",
    "end": "28960"
  },
  {
    "text": "couple that with you know on-prem or",
    "start": "28960",
    "end": "31359"
  },
  {
    "text": "cloud oltp",
    "start": "31359",
    "end": "32558"
  },
  {
    "text": "transactional databases you've got flag",
    "start": "32559",
    "end": "34719"
  },
  {
    "text": "files coming in in different formats",
    "start": "34719",
    "end": "36559"
  },
  {
    "text": "logs and so on",
    "start": "36559",
    "end": "38160"
  },
  {
    "text": "and then you see more and more often uh",
    "start": "38160",
    "end": "40879"
  },
  {
    "text": "in modern architecture data lakes are",
    "start": "40879",
    "end": "42879"
  },
  {
    "text": "smack in the middle of",
    "start": "42879",
    "end": "44000"
  },
  {
    "text": "it all with structured unstructured data",
    "start": "44000",
    "end": "46079"
  },
  {
    "text": "or raw and curated data",
    "start": "46079",
    "end": "48079"
  },
  {
    "text": "and that's why it's very important to",
    "start": "48079",
    "end": "50480"
  },
  {
    "text": "start",
    "start": "50480",
    "end": "51680"
  },
  {
    "text": "querying data that's sitting in the data",
    "start": "51680",
    "end": "53680"
  },
  {
    "text": "lakes",
    "start": "53680",
    "end": "55840"
  },
  {
    "text": "in order to understand how spectrum",
    "start": "55840",
    "end": "58320"
  },
  {
    "text": "helps us integrate the data lake",
    "start": "58320",
    "end": "60160"
  },
  {
    "text": "into the data warehouse we must first",
    "start": "60160",
    "end": "62160"
  },
  {
    "text": "understand the overall redshift",
    "start": "62160",
    "end": "64320"
  },
  {
    "text": "architecture",
    "start": "64320",
    "end": "66080"
  },
  {
    "text": "typically users interact with the leader",
    "start": "66080",
    "end": "68159"
  },
  {
    "text": "node using",
    "start": "68159",
    "end": "69119"
  },
  {
    "text": "sql queries the leader node uses",
    "start": "69119",
    "end": "72320"
  },
  {
    "text": "machine learning to optimize and",
    "start": "72320",
    "end": "74080"
  },
  {
    "text": "distribute the workload between the",
    "start": "74080",
    "end": "77040"
  },
  {
    "text": "compute nodes and the slices",
    "start": "77040",
    "end": "79119"
  },
  {
    "text": "within those nodes which are like",
    "start": "79119",
    "end": "82000"
  },
  {
    "text": "virtual compute nodes",
    "start": "82000",
    "end": "84320"
  },
  {
    "text": "giving it a lot of parallel processing",
    "start": "84320",
    "end": "86560"
  },
  {
    "text": "capabilities",
    "start": "86560",
    "end": "88080"
  },
  {
    "text": "and amazon s3 storage is used to load",
    "start": "88080",
    "end": "90960"
  },
  {
    "text": "unload",
    "start": "90960",
    "end": "91600"
  },
  {
    "text": "backup restore data warehouse data",
    "start": "91600",
    "end": "94880"
  },
  {
    "text": "and then retrieve spectrum is basically",
    "start": "94880",
    "end": "97280"
  },
  {
    "text": "additional managed nodes available to",
    "start": "97280",
    "end": "99280"
  },
  {
    "text": "you whether",
    "start": "99280",
    "end": "100000"
  },
  {
    "text": "you use them or not they're included as",
    "start": "100000",
    "end": "101840"
  },
  {
    "text": "part of your retro cluster when you",
    "start": "101840",
    "end": "103520"
  },
  {
    "text": "first spin that up",
    "start": "103520",
    "end": "105200"
  },
  {
    "text": "and these nodes are used to interact",
    "start": "105200",
    "end": "107840"
  },
  {
    "text": "with",
    "start": "107840",
    "end": "108240"
  },
  {
    "text": "one or many amazon s3 data lakes",
    "start": "108240",
    "end": "110880"
  },
  {
    "text": "creating what we like to call the",
    "start": "110880",
    "end": "112560"
  },
  {
    "text": "data lake house a lean massively",
    "start": "112560",
    "end": "114799"
  },
  {
    "text": "parallel",
    "start": "114799",
    "end": "116000"
  },
  {
    "text": "shared nothing data warehouse capable of",
    "start": "116000",
    "end": "118399"
  },
  {
    "text": "querying",
    "start": "118399",
    "end": "119119"
  },
  {
    "text": "the data lake let's see this in action",
    "start": "119119",
    "end": "121840"
  },
  {
    "text": "in a demonstration",
    "start": "121840",
    "end": "124718"
  },
  {
    "text": "for the purpose of this demo i've set up",
    "start": "127439",
    "end": "129840"
  },
  {
    "text": "a data lake with a",
    "start": "129840",
    "end": "132239"
  },
  {
    "text": "table called parquet that's partitioned",
    "start": "132239",
    "end": "135040"
  },
  {
    "text": "by product category in",
    "start": "135040",
    "end": "136720"
  },
  {
    "text": "parquet file formats that we will use",
    "start": "136720",
    "end": "140480"
  },
  {
    "text": "redshift is nc sql compliant and",
    "start": "140480",
    "end": "143040"
  },
  {
    "text": "therefore needs to be aware of the",
    "start": "143040",
    "end": "144640"
  },
  {
    "text": "schema in order to process queries",
    "start": "144640",
    "end": "146480"
  },
  {
    "text": "against the data lake",
    "start": "146480",
    "end": "148160"
  },
  {
    "text": "in order to accomplish this task i've",
    "start": "148160",
    "end": "150080"
  },
  {
    "text": "already created and run a glue crawler",
    "start": "150080",
    "end": "152080"
  },
  {
    "text": "which is captured that there are 160",
    "start": "152080",
    "end": "154239"
  },
  {
    "text": "million records in my table and",
    "start": "154239",
    "end": "155680"
  },
  {
    "text": "discovered the column names",
    "start": "155680",
    "end": "157280"
  },
  {
    "text": "their types and even identified the",
    "start": "157280",
    "end": "159360"
  },
  {
    "text": "columns",
    "start": "159360",
    "end": "160720"
  },
  {
    "text": "are being used for partitioning",
    "start": "160720",
    "end": "164239"
  },
  {
    "text": "switching over to my sql client that",
    "start": "168319",
    "end": "170879"
  },
  {
    "text": "i've already connected to my retrieve",
    "start": "170879",
    "end": "173040"
  },
  {
    "text": "cluster",
    "start": "173040",
    "end": "174000"
  },
  {
    "text": "i'm going to use this simple query to",
    "start": "174000",
    "end": "176319"
  },
  {
    "text": "pull in the external schema from the",
    "start": "176319",
    "end": "178080"
  },
  {
    "text": "glue crawler table and database",
    "start": "178080",
    "end": "180800"
  },
  {
    "text": "let's also run a query to see that we",
    "start": "180800",
    "end": "182959"
  },
  {
    "text": "are able to see",
    "start": "182959",
    "end": "184239"
  },
  {
    "text": "all 160 million records that we saw in",
    "start": "184239",
    "end": "186560"
  },
  {
    "text": "the data lake",
    "start": "186560",
    "end": "187440"
  },
  {
    "text": "let's query the data lake and do some",
    "start": "187440",
    "end": "189840"
  },
  {
    "text": "analytics on that data",
    "start": "189840",
    "end": "191360"
  },
  {
    "text": "this query will create a view for us",
    "start": "191360",
    "end": "193920"
  },
  {
    "text": "that contains the product",
    "start": "193920",
    "end": "195200"
  },
  {
    "text": "aggregate review ratings and average",
    "start": "195200",
    "end": "198239"
  },
  {
    "text": "review star rating let's use that view",
    "start": "198239",
    "end": "202400"
  },
  {
    "text": "to see what products are popular in the",
    "start": "202400",
    "end": "205040"
  },
  {
    "text": "home and grocery categories",
    "start": "205040",
    "end": "207599"
  },
  {
    "text": "the san francisco bay one cup seems to",
    "start": "207599",
    "end": "209920"
  },
  {
    "text": "be pretty popular",
    "start": "209920",
    "end": "211040"
  },
  {
    "text": "so maybe let's learn more about that",
    "start": "211040",
    "end": "214319"
  },
  {
    "text": "so far we've done some basic querying",
    "start": "214319",
    "end": "216879"
  },
  {
    "text": "but let's",
    "start": "216879",
    "end": "217519"
  },
  {
    "text": "use that horsepower of the redshift",
    "start": "217519",
    "end": "219519"
  },
  {
    "text": "processing and do some analytics on the",
    "start": "219519",
    "end": "221440"
  },
  {
    "text": "data lake",
    "start": "221440",
    "end": "222799"
  },
  {
    "text": "this query is going to give us",
    "start": "222799",
    "end": "226080"
  },
  {
    "text": "the 30 and 90 day average rolling",
    "start": "226080",
    "end": "228879"
  },
  {
    "text": "average review rating for the san",
    "start": "228879",
    "end": "230560"
  },
  {
    "text": "francisco bay one cup",
    "start": "230560",
    "end": "232000"
  },
  {
    "text": "and show us how this products been",
    "start": "232000",
    "end": "233439"
  },
  {
    "text": "trending",
    "start": "233439",
    "end": "235920"
  },
  {
    "text": "let's combine the warm data lake product",
    "start": "236720",
    "end": "239760"
  },
  {
    "text": "data",
    "start": "239760",
    "end": "240720"
  },
  {
    "text": "with the customer demographic data",
    "start": "240720",
    "end": "244159"
  },
  {
    "text": "from the data warehouse that is more",
    "start": "244159",
    "end": "245840"
  },
  {
    "text": "frequently accessed or utilized which is",
    "start": "245840",
    "end": "248000"
  },
  {
    "text": "also why it's referred to as hot data",
    "start": "248000",
    "end": "252000"
  },
  {
    "text": "this query takes the customer",
    "start": "252000",
    "end": "253760"
  },
  {
    "text": "demographic information from the data",
    "start": "253760",
    "end": "255599"
  },
  {
    "text": "warehouse and combines it with the",
    "start": "255599",
    "end": "257199"
  },
  {
    "text": "product data that we saw earlier from",
    "start": "257199",
    "end": "259040"
  },
  {
    "text": "the data lake",
    "start": "259040",
    "end": "260239"
  },
  {
    "text": "and it creates a table that also",
    "start": "260239",
    "end": "262160"
  },
  {
    "text": "includes the 30 and 90 day",
    "start": "262160",
    "end": "264400"
  },
  {
    "text": "rolling rating average analysis",
    "start": "264400",
    "end": "267600"
  },
  {
    "text": "let's say we speak to some data",
    "start": "267600",
    "end": "269120"
  },
  {
    "text": "scientists we work with and they find",
    "start": "269120",
    "end": "270560"
  },
  {
    "text": "this data really interesting and ask us",
    "start": "270560",
    "end": "272560"
  },
  {
    "text": "to",
    "start": "272560",
    "end": "272880"
  },
  {
    "text": "copy it over to their data lake so their",
    "start": "272880",
    "end": "275120"
  },
  {
    "text": "data link looks pretty empty right now",
    "start": "275120",
    "end": "277040"
  },
  {
    "text": "we're going to use this unload query to",
    "start": "277040",
    "end": "280320"
  },
  {
    "text": "essentially copy that table",
    "start": "280320",
    "end": "282560"
  },
  {
    "text": "in parque format partition by product",
    "start": "282560",
    "end": "285680"
  },
  {
    "text": "category over to their data lake",
    "start": "285680",
    "end": "288320"
  },
  {
    "text": "i'm running the unload command but",
    "start": "288320",
    "end": "291680"
  },
  {
    "text": "you can also run a simple sql",
    "start": "291680",
    "end": "295040"
  },
  {
    "text": "query to write or update the data in an",
    "start": "295040",
    "end": "298320"
  },
  {
    "text": "external table",
    "start": "298320",
    "end": "300720"
  },
  {
    "text": "we hit refresh on the data lake and we",
    "start": "300720",
    "end": "302880"
  },
  {
    "text": "can see that the table has been created",
    "start": "302880",
    "end": "304960"
  },
  {
    "text": "in parque format partitioned by the",
    "start": "304960",
    "end": "306880"
  },
  {
    "text": "product category ready for the data",
    "start": "306880",
    "end": "308720"
  },
  {
    "text": "scientists to run machine",
    "start": "308720",
    "end": "310000"
  },
  {
    "text": "learning and other jobs on this data in",
    "start": "310000",
    "end": "311680"
  },
  {
    "text": "a completely different data lake",
    "start": "311680",
    "end": "314400"
  },
  {
    "text": "this is how you run a lean data",
    "start": "314400",
    "end": "316560"
  },
  {
    "text": "warehouse with the ability to combine",
    "start": "316560",
    "end": "318560"
  },
  {
    "text": "with",
    "start": "318560",
    "end": "318960"
  },
  {
    "text": "exabyte scale data lakes using amazon",
    "start": "318960",
    "end": "322160"
  },
  {
    "text": "redshift spectrum i hope you learned",
    "start": "322160",
    "end": "324479"
  },
  {
    "text": "something today",
    "start": "324479",
    "end": "325440"
  },
  {
    "text": "i highly recommend spinning up a",
    "start": "325440",
    "end": "327280"
  },
  {
    "text": "redshift cluster and playing around with",
    "start": "327280",
    "end": "329360"
  },
  {
    "text": "it to learn about",
    "start": "329360",
    "end": "330400"
  },
  {
    "text": "spectrum re3 aqua and the many features",
    "start": "330400",
    "end": "334240"
  },
  {
    "text": "and capabilities of amazon redshift",
    "start": "334240",
    "end": "337440"
  },
  {
    "text": "and thank you for your time",
    "start": "337440",
    "end": "343759"
  }
]
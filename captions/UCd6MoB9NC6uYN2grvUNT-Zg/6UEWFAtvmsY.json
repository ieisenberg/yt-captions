[
  {
    "start": "0",
    "end": "27000"
  },
  {
    "text": "my name is Tony Gibbs I work with AWS I'm a data warehousing solution architect and we're going to be doing",
    "start": "399",
    "end": "6879"
  },
  {
    "text": "red shift best practices today going to have a couple co-presenters come up uh",
    "start": "6879",
    "end": "13320"
  },
  {
    "text": "Todd from finra will be coming up and talking about some use cases and we'll also have Jessica from CMS will also be",
    "start": "13320",
    "end": "20240"
  },
  {
    "text": "coming up and sharing some use cases as well uh so it's pretty jamack session with lots of",
    "start": "20240",
    "end": "26640"
  },
  {
    "text": "content um just before I get started in the overview I always like to kind of get a feel for how many of you are using",
    "start": "26640",
    "end": "33879"
  },
  {
    "start": "27000",
    "end": "27000"
  },
  {
    "text": "red shift today um if you are using red shift just get a show of hands here okay",
    "start": "33879",
    "end": "39600"
  },
  {
    "text": "so a reasonable number how about uh are any of you evaluating red shift as a potential you know migrating okay wow",
    "start": "39600",
    "end": "47640"
  },
  {
    "text": "okay that's quite a few um I don't have a lot of info on the data migration side",
    "start": "47640",
    "end": "52800"
  },
  {
    "text": "of things in this one but um you know talk if you want you know come talk to me after and we can talk about some of",
    "start": "52800",
    "end": "58559"
  },
  {
    "text": "that stuff so we're going to get started with just kind of the history and the development we'll move into the",
    "start": "58559",
    "end": "64680"
  },
  {
    "text": "architecture and then the real kind of meat of it will be in the concepts and the storage Deep dive uh and then we",
    "start": "64680",
    "end": "71320"
  },
  {
    "text": "that's after that we'll move on to the use cases uh from both thra and CMS and",
    "start": "71320",
    "end": "76439"
  },
  {
    "text": "then after that I'll go into just the road map and that sort of thing and anytime we have left Q&A I'll stick",
    "start": "76439",
    "end": "82759"
  },
  {
    "text": "around after if you have further questions as well uh for as long as you guys",
    "start": "82759",
    "end": "88640"
  },
  {
    "text": "want",
    "start": "88920",
    "end": "91920"
  },
  {
    "text": "so really red shift kind of starts out um with postgress I mean if you've ever",
    "start": "98360",
    "end": "104399"
  },
  {
    "text": "used red shift uh it looks and feels a lot like postgress um when you connect to it for",
    "start": "104399",
    "end": "110840"
  },
  {
    "text": "the first time you might even notice a connection string that reports back that it is actually",
    "start": "110840",
    "end": "116920"
  },
  {
    "text": "postgress we obviously rebuilt a huge portion of it the storage engine is",
    "start": "116920",
    "end": "122360"
  },
  {
    "text": "entirely different it's a colmer storage engine we revamped it so it's massively parallel uh this means that it can scale",
    "start": "122360",
    "end": "129759"
  },
  {
    "text": "horizontally uh up to 128 nodes uh We've added a ton of olap functionality to Red",
    "start": "129759",
    "end": "136000"
  },
  {
    "text": "shift these are window functions approximate count distincts uh functions like that then what we did was is we",
    "start": "136000",
    "end": "143640"
  },
  {
    "text": "also took it and we wrapped it in the AWS ecosystem so this is You Know Rich",
    "start": "143640",
    "end": "151599"
  },
  {
    "text": "backups um you know it interacts with a ton of other services or uses them in",
    "start": "151599",
    "end": "156840"
  },
  {
    "text": "how it's built and it's kind of the combination of all of these things that make red shift what it",
    "start": "156840",
    "end": "165000"
  },
  {
    "text": "is we launched red shift um Valentine's Day uh February",
    "start": "165000",
    "end": "170560"
  },
  {
    "text": "2013 uh so it's been out for a little over four years now and since that time",
    "start": "170560",
    "end": "176360"
  },
  {
    "text": "we've innovated like crazy we've been releasing patches on on a regular Cadence we usually release a patch every",
    "start": "176360",
    "end": "183159"
  },
  {
    "text": "two weeks is where we add new features you don't have to do anything it's maintenance free you just kind of wake",
    "start": "183159",
    "end": "189519"
  },
  {
    "text": "up and you know the next day and you have new features that we've added new enhancements performance enhancements",
    "start": "189519",
    "end": "195000"
  },
  {
    "text": "and those sorts of things near the end of this presentation I'll go through some of the recent ones that we've added",
    "start": "195000",
    "end": "200959"
  },
  {
    "text": "um but there you know there's quite a few of them the cluster",
    "start": "200959",
    "end": "206120"
  },
  {
    "text": "architecture in red shift uh the the bit that you're kind of you work with is",
    "start": "206120",
    "end": "211560"
  },
  {
    "start": "207000",
    "end": "207000"
  },
  {
    "text": "what we call the leader node that's at the top here of uh the slide right up there that's what you connect to using",
    "start": "211560",
    "end": "219080"
  },
  {
    "text": "your drivers uh you can use jdbc odbc because it's based on postgress",
    "start": "219080",
    "end": "226159"
  },
  {
    "text": "originally you can also connect technically with any postgress driver so it's lib PQ compatible so you can also",
    "start": "226159",
    "end": "233040"
  },
  {
    "text": "connect with that the important bit behind the leader node is the compute nodes as I mentioned",
    "start": "233040",
    "end": "240000"
  },
  {
    "text": "you can have up to 128 of these uh smallest number of cluster you can have you can technically have a single node",
    "start": "240000",
    "end": "245799"
  },
  {
    "text": "cluster but the smallest multide cluster is obviously two compute nodes red shift",
    "start": "245799",
    "end": "251159"
  },
  {
    "text": "is a share nothing architecture what that means is we try to use all of the computing power across",
    "start": "251159",
    "end": "258280"
  },
  {
    "text": "all of the nodes to execute your query as s quick as possible if you throw a",
    "start": "258280",
    "end": "264240"
  },
  {
    "text": "large enough query at Red shift you can technically saturate all of the hardware you can use up all the the CPUs and all",
    "start": "264240",
    "end": "270800"
  },
  {
    "text": "the discs and the network bandwidth and everything if it's a big enough query and that's by Design and that's how",
    "start": "270800",
    "end": "276000"
  },
  {
    "text": "we're able to execute query so quickly is by running everything in",
    "start": "276000",
    "end": "283039"
  },
  {
    "text": "parallel the next is is these compute nodes they also you know they talk to other services primarily S3 is one of",
    "start": "283039",
    "end": "290199"
  },
  {
    "text": "the main Services uh we ingest data usually from S3 you can unload data to",
    "start": "290199",
    "end": "295560"
  },
  {
    "text": "S3 I mentioned backups we're continuously backing up your cluster to",
    "start": "295560",
    "end": "300840"
  },
  {
    "text": "S3 uh so all of this kind of happens in the background all in parallel uh and",
    "start": "300840",
    "end": "306039"
  },
  {
    "text": "that's really kind of the important Takeaway on this slide is that everything really does happen in",
    "start": "306039",
    "end": "312240"
  },
  {
    "text": "parallel we'll talk a little bit more about the components of these bits here we're going to talk about the leader",
    "start": "313880",
    "end": "319680"
  },
  {
    "text": "node here first and what it does so the leader node obviously parses the query",
    "start": "319680",
    "end": "326240"
  },
  {
    "text": "it rewrites the query this is a step where we strip out some syntactic sugar out of SQL rewrite SQL and such we",
    "start": "326240",
    "end": "333479"
  },
  {
    "text": "obviously have a planner and we optimize and all that kind of stuff what we then do is is we generate on your query we we",
    "start": "333479",
    "end": "340360"
  },
  {
    "text": "generate C++ code so there's a whole bunch of C++ uh binaries that are",
    "start": "340360",
    "end": "345600"
  },
  {
    "text": "compiled and we send those down to all the compute notes that that work is also done by the",
    "start": "345600",
    "end": "350880"
  },
  {
    "text": "leader node the postgress catalog tables uh they also exist on the leader node so",
    "start": "350880",
    "end": "356520"
  },
  {
    "text": "if you're familiar with postgress and you're used to you know like the PG catalog that is also there we've also",
    "start": "356520",
    "end": "362960"
  },
  {
    "text": "add made a superet of that so there's a lot of you know catalog tables we've also added to Red shift as",
    "start": "362960",
    "end": "371120"
  },
  {
    "text": "well the compute nodes as I already mentioned you know there's the back back",
    "start": "371120",
    "end": "376360"
  },
  {
    "text": "up and restore stuff that they are responsible for because they're talking directly to S3 they're also the ones",
    "start": "376360",
    "end": "381720"
  },
  {
    "text": "that execute the actual queries uh when you send down query we're going to go",
    "start": "381720",
    "end": "387680"
  },
  {
    "text": "further into this bit here that's highlighted uh in the presentation here so I'll talk about that",
    "start": "387680",
    "end": "395599"
  },
  {
    "text": "later so let's kind of build up some Concepts and terminology",
    "start": "395599",
    "end": "401639"
  },
  {
    "text": "here first red shift is designed to reduce IO um the first way that we do",
    "start": "401639",
    "end": "407599"
  },
  {
    "text": "that is is the colmer architecture so on the left here there's kind of these yellow blocks here or boxes but they're",
    "start": "407599",
    "end": "415280"
  },
  {
    "text": "meant to represent what we call blocks they're one meeg chunks of data technically uh and the idea here is is that we store",
    "start": "415280",
    "end": "422840"
  },
  {
    "text": "data column by column in red shift this is different than a traditional database",
    "start": "422840",
    "end": "428039"
  },
  {
    "text": "uh say like I'll just postgress for example where the data is stored row by Row the reason we do this is because if",
    "start": "428039",
    "end": "435800"
  },
  {
    "text": "you typically in an analytics database or data warehouse you're only going to be accessing a subset of the columns in",
    "start": "435800",
    "end": "444360"
  },
  {
    "text": "a case this particular case if you were only wanting to scan data off of the date time column we only need to read",
    "start": "444360",
    "end": "451240"
  },
  {
    "text": "that data off disk so that's one of the ways that red shift is designed to reduce",
    "start": "451240",
    "end": "457560"
  },
  {
    "text": "IO the next is data compression uh because we store the data",
    "start": "457560",
    "end": "465000"
  },
  {
    "text": "column by column and red shift uh it means that the data it's all the same data type so it's really easy to",
    "start": "465000",
    "end": "471440"
  },
  {
    "text": "compress we can compress each column independently with different encoding types if you look up here where I'm",
    "start": "471440",
    "end": "477919"
  },
  {
    "text": "highlighting or just pointing uh that's the modifications to the SQL there um to",
    "start": "477919",
    "end": "483520"
  },
  {
    "text": "encode different columns with different encoding",
    "start": "483520",
    "end": "488240"
  },
  {
    "text": "types the next is something that we call zone maps um what they're basically are",
    "start": "489800",
    "end": "496159"
  },
  {
    "text": "is they're an inmemory data structure that stores the Min and the max values",
    "start": "496159",
    "end": "501240"
  },
  {
    "text": "for each of these blocks and we store that data in memory this allows us to check that data",
    "start": "501240",
    "end": "509120"
  },
  {
    "text": "structure and effectively prune out uh data when you're doing say a predicate",
    "start": "509120",
    "end": "514399"
  },
  {
    "text": "as an example of that imagine we have just these four blocks here up on the screen",
    "start": "514399",
    "end": "521240"
  },
  {
    "text": "uh this is date time data in this particular case uh you know we start those Min and Max values represent our",
    "start": "521240",
    "end": "528000"
  },
  {
    "text": "zone maps if you came along with a SQL query",
    "start": "528000",
    "end": "533560"
  },
  {
    "text": "that looks something like this uh and you're just kind of you know looking for that date what we can do is we can check",
    "start": "533560",
    "end": "539560"
  },
  {
    "text": "the inmemory zone maps and we know which blocks we need to read off disk this",
    "start": "539560",
    "end": "544880"
  },
  {
    "text": "further eliminates IO this leads to what if we sorted this",
    "start": "544880",
    "end": "549920"
  },
  {
    "text": "data which you can do in Red shift so best practice sorting time stamps if you came along and you sorted",
    "start": "549920",
    "end": "557160"
  },
  {
    "text": "this data you ran this same query in this particular example we can further",
    "start": "557160",
    "end": "562399"
  },
  {
    "text": "reduce IO so this illustrates how sorting data in red shift uh can help",
    "start": "562399",
    "end": "568240"
  },
  {
    "text": "reduce IO and obviously greatly improve performance some of the the design",
    "start": "568240",
    "end": "576440"
  },
  {
    "start": "573000",
    "end": "573000"
  },
  {
    "text": "considerations for picking a sort key are mainly around your query patterns",
    "start": "576440",
    "end": "581959"
  },
  {
    "text": "your business requirements and if you know your data your data",
    "start": "581959",
    "end": "587279"
  },
  {
    "text": "profile a lot of times because a lot of data in a data warehouse is time series",
    "start": "587279",
    "end": "592760"
  },
  {
    "text": "data it usually makes sense to base your sort key around your timestamp whatever",
    "start": "592760",
    "end": "597920"
  },
  {
    "text": "that is but the main goal is really to reduce IO",
    "start": "597920",
    "end": "603399"
  },
  {
    "text": "um there's a few other cases which I'm not going to go into to at all really but there are like merge joints and",
    "start": "603399",
    "end": "609839"
  },
  {
    "text": "optimizations for things like that where you may use sort keys but the 95% case",
    "start": "609839",
    "end": "615480"
  },
  {
    "text": "is pretty much to sort to reduce io on your",
    "start": "615480",
    "end": "621079"
  },
  {
    "start": "621000",
    "end": "621000"
  },
  {
    "text": "timestamp so this slices is a very important Concept in red shift actually",
    "start": "621600",
    "end": "627399"
  },
  {
    "text": "it's one of the most important uh it's how we achieve parallelism within a node",
    "start": "627399",
    "end": "632600"
  },
  {
    "text": "on the cluster so what we've done is is we've taken each compute node and we've",
    "start": "632600",
    "end": "638040"
  },
  {
    "text": "divied it up into what we call slices and they're really just a collection of processes that are on each node and we",
    "start": "638040",
    "end": "646800"
  },
  {
    "text": "used to have it pinned to the number of CPUs that's no longer the case but you can really think of them as virtual",
    "start": "646800",
    "end": "652920"
  },
  {
    "text": "compute nodes uh depending on the Node type there'll be 216 or 32 of these",
    "start": "652920",
    "end": "658839"
  },
  {
    "text": "virtual compute nodes within each compute node uh we store the data per",
    "start": "658839",
    "end": "664680"
  },
  {
    "text": "slice so if say you had like a two node cluster and there was two uh two slices",
    "start": "664680",
    "end": "671120"
  },
  {
    "text": "that would mean that you would have a total of four slices in your cluster and we would store the data within each of",
    "start": "671120",
    "end": "677480"
  },
  {
    "text": "those I'll get a little bit deeper into how that works and illustrate that uh in a few",
    "start": "677480",
    "end": "683000"
  },
  {
    "text": "slides or in like two so that really leads into how do we",
    "start": "683000",
    "end": "689360"
  },
  {
    "text": "distribute data on these slices we have three different methods for that the first is is what we call distribute by",
    "start": "689360",
    "end": "697000"
  },
  {
    "text": "key what we're effectively doing in this case is we're taking one of the columns or you're defining a column that we're",
    "start": "697000",
    "end": "702920"
  },
  {
    "text": "going to distribute on and we hash that value that's in that column and we run",
    "start": "702920",
    "end": "709360"
  },
  {
    "text": "like a modulo operator on it and then that figures out you know what slice the data will land on the next is",
    "start": "709360",
    "end": "716399"
  },
  {
    "text": "distribution style even which essentially just means that we'll just round robin the data through the cluster",
    "start": "716399",
    "end": "721839"
  },
  {
    "text": "we'll make it even and that's just kind of like that's the default it's if",
    "start": "721839",
    "end": "727000"
  },
  {
    "text": "you're not sure what to do it's actually the safest distribution style to go with the last one is distribution style all",
    "start": "727000",
    "end": "734320"
  },
  {
    "text": "this is primarily for Dimension tables so this would be you have small tables",
    "start": "734320",
    "end": "739680"
  },
  {
    "text": "you join against them frequently and you want to make joins really fast that's what this distribution style is for go",
    "start": "739680",
    "end": "746760"
  },
  {
    "text": "into this and illustrate this so that you know some animations to explain it so up here",
    "start": "746760",
    "end": "753639"
  },
  {
    "start": "747000",
    "end": "747000"
  },
  {
    "text": "though you can see the modifications to standard table ddl the disc style here",
    "start": "753639",
    "end": "759279"
  },
  {
    "text": "and that's where you specify what distribution style you want to",
    "start": "759279",
    "end": "764120"
  },
  {
    "start": "765000",
    "end": "765000"
  },
  {
    "text": "use up here on the right I got some I have some fictitious data it's really simple just four",
    "start": "765680",
    "end": "771639"
  },
  {
    "text": "rows we're going to first start out with distribution style even it's the simplest one what's going to happen here",
    "start": "771639",
    "end": "777920"
  },
  {
    "text": "is the data is just going to evenly get spread across the cluster pretty simple",
    "start": "777920",
    "end": "783320"
  },
  {
    "text": "four rows four slices so we have a compute node here a compute node here",
    "start": "783320",
    "end": "789680"
  },
  {
    "text": "each compute node has two slices so the data just evenly went across those",
    "start": "789680",
    "end": "795959"
  },
  {
    "text": "slices the next is is an example if we took the location uh this SFO JFK here",
    "start": "795959",
    "end": "803160"
  },
  {
    "start": "796000",
    "end": "796000"
  },
  {
    "text": "to be our distribution style so it says distribution style location up here what",
    "start": "803160",
    "end": "808560"
  },
  {
    "text": "we're going to do do is we're going to distribute by that and what's going to happen is the data is going to land",
    "start": "808560",
    "end": "814399"
  },
  {
    "text": "something like this this is an example of a poor",
    "start": "814399",
    "end": "819680"
  },
  {
    "text": "distribution what's happened right here is we have data that's this data only",
    "start": "819680",
    "end": "824839"
  },
  {
    "text": "exists on one of the compute nodes so what this means is if you execute a query only half of your cluster is being",
    "start": "824839",
    "end": "831959"
  },
  {
    "text": "used and the other half just sits there idle doing nothing it'll get the query it'll run it but there's no data for it",
    "start": "831959",
    "end": "838079"
  },
  {
    "text": "to return it doesn't have any data so what if we picked the ID in this",
    "start": "838079",
    "end": "846519"
  },
  {
    "text": "case to be the distribution so this is the primary key value it looks like here",
    "start": "846519",
    "end": "851680"
  },
  {
    "text": "if we did this the data might distribute something that looks like this and we get nice even distribution of data",
    "start": "851680",
    "end": "859199"
  },
  {
    "text": "that's exactly what we want to have happen so the data is nice spread nicely across the cluster the last example is distribution",
    "start": "859199",
    "end": "866839"
  },
  {
    "start": "865000",
    "end": "865000"
  },
  {
    "text": "style all so what we do here because we want to have a complete copy of the data",
    "start": "866839",
    "end": "872839"
  },
  {
    "text": "on each cluster we write all of the data on the First Slice on each",
    "start": "872839",
    "end": "880279"
  },
  {
    "start": "881000",
    "end": "881000"
  },
  {
    "text": "node so when you want to use distribution",
    "start": "882639",
    "end": "887759"
  },
  {
    "text": "Style by key the most important thing is that it creates an even distribution if",
    "start": "887759",
    "end": "892920"
  },
  {
    "text": "it doesn't create an even distribution you don't want to use uh that that column as a key",
    "start": "892920",
    "end": "899720"
  },
  {
    "text": "what why would you use key or the main reason for that it's because you want to optimize for joints that's typically",
    "start": "899720",
    "end": "907000"
  },
  {
    "text": "what you're trying to do so what this means is if you have two tables and you want to do a join between them and you",
    "start": "907000",
    "end": "914360"
  },
  {
    "text": "want to optimize for that if you collocate on the same key the data will be joined on the same slice in the",
    "start": "914360",
    "end": "921000"
  },
  {
    "text": "cluster and that means red shift can do the join very quickly the next case if is distribution",
    "start": "921000",
    "end": "928639"
  },
  {
    "text": "Style all this is really good for small tables if say you have a whole bunch of little tables they have basically under",
    "start": "928639",
    "end": "934240"
  },
  {
    "text": "3 million rows or less distribution style all is what we recommend uh this will also result in really fast joints",
    "start": "934240",
    "end": "942319"
  },
  {
    "text": "um and the last choice if you don't if none of the above apply that's where distribution style even comes",
    "start": "942319",
    "end": "949480"
  },
  {
    "text": "in so we'll go into the storage system here so one thing and I don't think we",
    "start": "949480",
    "end": "955920"
  },
  {
    "start": "952000",
    "end": "952000"
  },
  {
    "text": "really advertise this at all actually it's not even in our document this top Point uh but it is important to kind of",
    "start": "955920",
    "end": "962040"
  },
  {
    "text": "be aware of uh especially if you're coming doing a data migration for something on premise is that we actually",
    "start": "962040",
    "end": "967839"
  },
  {
    "text": "have two and a half to three times more storage on our nodes than we actually advertise so what this means is that the",
    "start": "967839",
    "end": "976480"
  },
  {
    "text": "amount that we're advertising is the amount of space you have as user data uh",
    "start": "976480",
    "end": "982759"
  },
  {
    "text": "the reason we do that is is red shift always makes a complete mirror of the data within the cluster so we're always",
    "start": "982759",
    "end": "990440"
  },
  {
    "text": "kind of have two copies of the data live in the cluster and the reason we do that is data safety right so if a for some",
    "start": "990440",
    "end": "996880"
  },
  {
    "text": "reason a node disappeared we still have another copy of the data to recover from we have an",
    "start": "996880",
    "end": "1003399"
  },
  {
    "text": "automatic workflow that replaces that node and the data gets mirrored back over to the new",
    "start": "1003399",
    "end": "1009920"
  },
  {
    "text": "node the other bit obviously that why it's two and a half to three times so that means we need 2x data for that the",
    "start": "1010279",
    "end": "1016720"
  },
  {
    "text": "rest of the data is you know there's an operating system uh there we need scratch space things like that uh that's",
    "start": "1016720",
    "end": "1023079"
  },
  {
    "text": "what the other bit is for that is actually this information actually is exposed in one of the system tables we",
    "start": "1023079",
    "end": "1029038"
  },
  {
    "text": "do call it local data and remote data is what we call it and there's two",
    "start": "1029039",
    "end": "1034160"
  },
  {
    "text": "partitions that you'll see in this one system",
    "start": "1034160",
    "end": "1038720"
  },
  {
    "start": "1039000",
    "end": "1039000"
  },
  {
    "text": "table we talked a little bit about the blocks I mentioned you know we have these one meeg blocks they're immutable",
    "start": "1039600",
    "end": "1047360"
  },
  {
    "text": "in red shift what that means is is that we never edit an existing block we always are writing a new block to the",
    "start": "1047360",
    "end": "1053280"
  },
  {
    "text": "system there's a couple reasons for that one is is that red shift uses mvcc so",
    "start": "1053280",
    "end": "1058880"
  },
  {
    "text": "multiversion concurrency control that's why it can be asset and you know transactions work and you can do deletes",
    "start": "1058880",
    "end": "1064760"
  },
  {
    "text": "and if you have a transaction running you continue to see that data um so the",
    "start": "1064760",
    "end": "1071440"
  },
  {
    "text": "blocks are individually encoded which I mentioned already uh we actually have 12",
    "start": "1071440",
    "end": "1076640"
  },
  {
    "text": "encodings now uh we recently released one called Z standard um and yeah and",
    "start": "1076640",
    "end": "1082080"
  },
  {
    "text": "then we have the zone maps that store the inmemory",
    "start": "1082080",
    "end": "1086640"
  },
  {
    "start": "1087000",
    "end": "1087000"
  },
  {
    "text": "data the next is is these blocks build up what we call the blockchain so the",
    "start": "1089559",
    "end": "1096600"
  },
  {
    "text": "blockchain is is really just a linked list of our blocks and we have two of",
    "start": "1096600",
    "end": "1102080"
  },
  {
    "text": "these on the cluster I talked a little bit about sorting uh what we end up having is is there's two sections to",
    "start": "1102080",
    "end": "1109440"
  },
  {
    "text": "one is the sorted region and one is the unsorted region so there always kind of be two blockchains per",
    "start": "1109440",
    "end": "1116480"
  },
  {
    "start": "1121000",
    "end": "1121000"
  },
  {
    "text": "column the next bit is uh red shift what the one main takeaway from these blocks",
    "start": "1122760",
    "end": "1130159"
  },
  {
    "text": "is is that red shift is really kind of designed around batch processing so what that means is uh say if you do an update",
    "start": "1130159",
    "end": "1138159"
  },
  {
    "text": "in red sh shift what happens is is we have to mark a block is deleted and then we have to",
    "start": "1138159",
    "end": "1144880"
  },
  {
    "text": "rewrite or not the block the block will be marked as deleted so there'll be marked rows that are marked deleted then",
    "start": "1144880",
    "end": "1151200"
  },
  {
    "text": "we have to take that block and we have to rewrite it to the end of the blockchain and that's to deal with this",
    "start": "1151200",
    "end": "1157600"
  },
  {
    "text": "multiversion concurrency control and the next bit is that we also",
    "start": "1157600",
    "end": "1164080"
  },
  {
    "text": "have because of that uh deletes are also marked as just deleted as well and",
    "start": "1164080",
    "end": "1171080"
  },
  {
    "text": "because of that we also have to have vacuums and such clean up the data uh so",
    "start": "1171080",
    "end": "1177360"
  },
  {
    "text": "we do have I'll get into kind of the next bit which is vacuum delete only which is going to be like Auto vacuum uh",
    "start": "1177360",
    "end": "1183320"
  },
  {
    "text": "but as of right now you do need to run vacuum to clean up these you know",
    "start": "1183320",
    "end": "1188360"
  },
  {
    "text": "basically ghost rows in a way the important Takeaway on this slide",
    "start": "1188360",
    "end": "1193480"
  },
  {
    "text": "is really that because red shift is designed around batch processing that means that",
    "start": "1193480",
    "end": "1199919"
  },
  {
    "text": "to do a batch load we can basically load about 100,000 rows worth of data in",
    "start": "1199919",
    "end": "1206120"
  },
  {
    "text": "about the same time as we can write you know one row basically and that's because these blocks are so large",
    "start": "1206120",
    "end": "1212200"
  },
  {
    "text": "they're one mag blocks red shift is designed for dealing with you know",
    "start": "1212200",
    "end": "1217440"
  },
  {
    "text": "millions or billions of rows actually billions even trillions of rows I've seen uh and that's because red shift is",
    "start": "1217440",
    "end": "1223240"
  },
  {
    "text": "a petabyte scale data warehouse you know it can scale all the way up to two pedabytes and that's it's designed for",
    "start": "1223240",
    "end": "1229840"
  },
  {
    "text": "big data we I didn't really talk too much",
    "start": "1229840",
    "end": "1236280"
  },
  {
    "start": "1233000",
    "end": "1233000"
  },
  {
    "text": "about compression other than mention that we do compress the data in red shift uh we do our best to figure out",
    "start": "1236280",
    "end": "1244200"
  },
  {
    "text": "the compression for you the first time you load data into a table we will automatically attempt to figure out that",
    "start": "1244200",
    "end": "1251000"
  },
  {
    "text": "compression we also have a utility built-in red shift that we call analyze compression this utility you can just",
    "start": "1251000",
    "end": "1258000"
  },
  {
    "text": "run it any time is just type in analyze space compression in the name of a table and red shift will analyze that data in",
    "start": "1258000",
    "end": "1264600"
  },
  {
    "text": "your table and figure out the best compression in the table uh we",
    "start": "1264600",
    "end": "1270120"
  },
  {
    "text": "technically brute force it uh we basically compress a sample of the data with every compression algorithm we have",
    "start": "1270120",
    "end": "1276960"
  },
  {
    "text": "and then we spit out the best one the one that gives you the least amount of data uh the new compression algorithm",
    "start": "1276960",
    "end": "1284799"
  },
  {
    "text": "which I'll talk about in the road map bit new features is z standard you'll find nowadays you'll almost always get",
    "start": "1284799",
    "end": "1291919"
  },
  {
    "text": "that recommendation for most of your columns uh it does an incredibly good job of compressing",
    "start": "1291919",
    "end": "1298279"
  },
  {
    "text": "data if performance in red shift isn't what you expect it to be usually it's",
    "start": "1298279",
    "end": "1304760"
  },
  {
    "text": "distance sort keys that are messed up uh they can have orders of magnitude",
    "start": "1304760",
    "end": "1310760"
  },
  {
    "text": "difference in performance uh so usually if I'm working with a customer it's the first thing I'll go to look at is is the",
    "start": "1310760",
    "end": "1317320"
  },
  {
    "text": "distribution key resulting in an even spread of data that's the first thing the next is uh checking your sort keys",
    "start": "1317320",
    "end": "1325320"
  },
  {
    "text": "and making sure that your tables are vacuumed in other words the data is actually sorted and uh making sure the",
    "start": "1325320",
    "end": "1331480"
  },
  {
    "text": "sort key is on something that you're actually filtering on uh usually it's a time stamp because usually end up having",
    "start": "1331480",
    "end": "1337120"
  },
  {
    "text": "a wear Clause where you're going to be selecting where two dates or between something so those are kind of the main",
    "start": "1337120",
    "end": "1344400"
  },
  {
    "text": "things to really kind of check is the distribution and the sort keys",
    "start": "1344400",
    "end": "1349440"
  },
  {
    "text": "I'm going to hand it off uh now to Todd",
    "start": "1349440",
    "end": "1354759"
  },
  {
    "text": "so clicker sensitive this is forward right one's forward right one's",
    "start": "1355600",
    "end": "1363440"
  },
  {
    "text": "forward clicker 101 all right hi my name is Todd griffi",
    "start": "1366640",
    "end": "1372679"
  },
  {
    "text": "I'm a principal at finra um aside from specifically what the slides talk about",
    "start": "1372679",
    "end": "1378640"
  },
  {
    "text": "here I'm really going to cover three different topics I'm going to give you just a real quick overview of the",
    "start": "1378640",
    "end": "1383720"
  },
  {
    "text": "problem that we're solving specifically um and then two different issues that we ran into um while we were",
    "start": "1383720",
    "end": "1390440"
  },
  {
    "text": "building out our capabilities which may or may not be helpful for you based on your use cases but if there's helpful to",
    "start": "1390440",
    "end": "1397480"
  },
  {
    "text": "a handful of you then it was probably worth talking about so go ahead and just go to the next that's good so our use",
    "start": "1397480",
    "end": "1404000"
  },
  {
    "start": "1402000",
    "end": "1402000"
  },
  {
    "text": "case um our data lake so if you've gone to any present ations where there's fin",
    "start": "1404000",
    "end": "1410000"
  },
  {
    "text": "people presenting we love to talk about how much data we have uh we basically have in our data Lake around 30 plus",
    "start": "1410000",
    "end": "1416279"
  },
  {
    "text": "trillion rows of data um that data is looked at from a surveillance",
    "start": "1416279",
    "end": "1421480"
  },
  {
    "text": "perspective it's looking for trade reporting compliance it's looking for nefarious activities and there's",
    "start": "1421480",
    "end": "1426600"
  },
  {
    "text": "kickouts that happen from that so whenever there's a kickout we have data analysts that need to essentially",
    "start": "1426600",
    "end": "1432240"
  },
  {
    "text": "recreate the market around that kickout they need to look at that data and then decide whether um what actions we're",
    "start": "1432240",
    "end": "1438840"
  },
  {
    "text": "going to take on it and in recreating the market if it's a thinly traded stock and it's a small firm it might be a",
    "start": "1438840",
    "end": "1445200"
  },
  {
    "text": "couple of rows if it's a highly traded stock and it's a large firm it could be",
    "start": "1445200",
    "end": "1450480"
  },
  {
    "text": "a couple billion rows so for us a data Mar really just means a recreation of",
    "start": "1450480",
    "end": "1456640"
  },
  {
    "text": "the market and we have a table for each request that a user makes so they make a",
    "start": "1456640",
    "end": "1462400"
  },
  {
    "text": "request from the data Lake we stage the data and that that data lake is S3 uh we",
    "start": "1462400",
    "end": "1467679"
  },
  {
    "text": "use em artic quari it it stages the data in LZ it's loaded into red shift and",
    "start": "1467679",
    "end": "1473120"
  },
  {
    "text": "then our analysts look at it the atypical case if our users in a",
    "start": "1473120",
    "end": "1479320"
  },
  {
    "text": "perfect world um they would just be using Excel on top of a billion rows of data and that's what they want that's",
    "start": "1479320",
    "end": "1485679"
  },
  {
    "text": "not exactly what we can give them but uh that's that's their Ideal World so what",
    "start": "1485679",
    "end": "1490760"
  },
  {
    "text": "it does mean is we we return data um they do need the capability to see",
    "start": "1490760",
    "end": "1496080"
  },
  {
    "text": "summaries at a column level so if I'm looking at something called Buy sell code I can see that 60% of them were",
    "start": "1496080",
    "end": "1501799"
  },
  {
    "text": "buys and 40% of them that's a really good use case for red shift because it's a single column that we're looking at",
    "start": "1501799",
    "end": "1508600"
  },
  {
    "text": "and we can summarize that based on filters that we have quickly what they also want to see though is every single",
    "start": "1508600",
    "end": "1514760"
  },
  {
    "text": "column and a request that they made and that can be up to 900 columns and column or databases red shift included are less",
    "start": "1514760",
    "end": "1521679"
  },
  {
    "text": "good at showing multiple multiple Columns of data um and so I'm going to",
    "start": "1521679",
    "end": "1526880"
  },
  {
    "text": "talk about that just in a minute and then the other other part is based on our base of users which is hundreds of",
    "start": "1526880",
    "end": "1533320"
  },
  {
    "text": "users and thousands of requests per day we were running into concern concurrency challenges so I'll talk about that a",
    "start": "1533320",
    "end": "1539039"
  },
  {
    "text": "little bit too all right so addressing wide data um in this case we have different",
    "start": "1539039",
    "end": "1547600"
  },
  {
    "text": "record types that we can bring up a record type is something like firm orders which is just what it sounds like it's the orders that a firm makes we",
    "start": "1547600",
    "end": "1554520"
  },
  {
    "text": "have trades that occur on an exchange and our analyst look at those together to",
    "start": "1554520",
    "end": "1561360"
  },
  {
    "text": "recreate the market um that data just between those two record types is about",
    "start": "1561360",
    "end": "1566399"
  },
  {
    "text": "400 Columns of data once we start retrieving more than 50 Columns of data",
    "start": "1566399",
    "end": "1572520"
  },
  {
    "text": "uh the performance comes really bad and that's because of the correlation that needs to happen between the many rows of data and the many columns of data so",
    "start": "1572520",
    "end": "1579679"
  },
  {
    "text": "what we did is we created this Big Field text and we literally take all the fields we concatenate them with a",
    "start": "1579679",
    "end": "1586399"
  },
  {
    "text": "non-printable character uh control B and we shove them into one big field so we",
    "start": "1586399",
    "end": "1594039"
  },
  {
    "text": "still have the discrete Fields like field one field two we have those so that you can filter on them you can sort",
    "start": "1594039",
    "end": "1600919"
  },
  {
    "text": "on them and then we have when we need to actually return the database and show it into grid um we pull The Big Field back",
    "start": "1600919",
    "end": "1608960"
  },
  {
    "text": "it's parsed on the server and then sent back to the browser so if you run into a scenario",
    "start": "1608960",
    "end": "1615760"
  },
  {
    "text": "where you do need uh multiple Columns of data it's just one technique that you",
    "start": "1615760",
    "end": "1621240"
  },
  {
    "text": "can use to potentially do it and because the data is coming back just as a single",
    "start": "1621240",
    "end": "1626559"
  },
  {
    "text": "column it works out well next",
    "start": "1626559",
    "end": "1633200"
  },
  {
    "start": "1633000",
    "end": "1633000"
  },
  {
    "text": "slide all right scaling red shift trial and error um 90% of our requests are",
    "start": "1633200",
    "end": "1639360"
  },
  {
    "text": "less than a million rows and about 2% of our requests are more than 100 million rows and a little bit different um",
    "start": "1639360",
    "end": "1647120"
  },
  {
    "text": "problems that we have one of the things that we were seeing is copies and selects running together were um hurting",
    "start": "1647120",
    "end": "1654919"
  },
  {
    "text": "each other and more specifically you could select something one point in time and it might take a second return and",
    "start": "1654919",
    "end": "1660799"
  },
  {
    "text": "then the next time you um you executed it it could take 20 seconds to return and it really just was the other",
    "start": "1660799",
    "end": "1666600"
  },
  {
    "text": "activity that was going on around it um so we played some different things we used workload management to segment off",
    "start": "1666600",
    "end": "1674000"
  },
  {
    "text": "and we said um the copies got about 25% of the system resources and we said that",
    "start": "1674000",
    "end": "1680240"
  },
  {
    "text": "select got the other 75% and that helped um but it still did",
    "start": "1680240",
    "end": "1685720"
  },
  {
    "text": "not address the issue the red shift team introduced something called Q hopping um",
    "start": "1685720",
    "end": "1691279"
  },
  {
    "text": "we played with that you can ask questions about it later we did not end up using that and then we tried different instant types and",
    "start": "1691279",
    "end": "1699200"
  },
  {
    "text": "configurations so we did play around uh one of the recommendations that came from the red shift team and it's some of",
    "start": "1699200",
    "end": "1705240"
  },
  {
    "text": "the stuff that Tony talked about as far as the writing that happens across the nodes um is blocks of four node clusters",
    "start": "1705240",
    "end": "1712640"
  },
  {
    "text": "give you the best performance and availability um so we were basically trying four nodes on DS2 XLS uh we",
    "start": "1712640",
    "end": "1720559"
  },
  {
    "text": "actually this is this is one of the things in the cloud the old way of thinking is you have a single database",
    "start": "1720559",
    "end": "1726480"
  },
  {
    "text": "um that's running essentially on one cluster and you're just trying to build out the capabilities of that cluster and",
    "start": "1726480",
    "end": "1732519"
  },
  {
    "text": "we The Hope was as we grew the nodes it would be a linear progression of how much faster would get but that's not",
    "start": "1732519",
    "end": "1739360"
  },
  {
    "text": "exactly how it worked out so I'll talk about it but essentially we ended up going from a Ford node ds28 XL to an 8",
    "start": "1739360",
    "end": "1746200"
  },
  {
    "text": "node um still didn't address all of our concurrency challenges so next",
    "start": "1746200",
    "end": "1751559"
  },
  {
    "start": "1751000",
    "end": "1751000"
  },
  {
    "text": "slide so what we did um we ended up introducing multiple red shift",
    "start": "1751559",
    "end": "1757960"
  },
  {
    "text": "clusters so these ones down at the bottom we essentially had small clusters",
    "start": "1757960",
    "end": "1763279"
  },
  {
    "text": "and we had large clusters our small clusters were Ford node DS2 XLS and our",
    "start": "1763279",
    "end": "1769399"
  },
  {
    "text": "large clusters were 24 node DS2 XLS we use tagging that's the picture over there in the bottom right uh to",
    "start": "1769399",
    "end": "1776440"
  },
  {
    "text": "essentially indicate the size of our cluster and the status of the cluster so if one filled up we could take it",
    "start": "1776440",
    "end": "1782399"
  },
  {
    "text": "essentially offline meaning we could read from it but we wouldn't write to it anymore and we self-discovered these",
    "start": "1782399",
    "end": "1790240"
  },
  {
    "text": "clusters so you could just stand up a cluster once the tags were added the software um was smart enough to figure",
    "start": "1790240",
    "end": "1795640"
  },
  {
    "text": "out that there was new you know new cluster out there to use use so we're currently running 12 small clusters and",
    "start": "1795640",
    "end": "1802640"
  },
  {
    "text": "two larger clusters um and you know this this is a somewhat constantly evolving",
    "start": "1802640",
    "end": "1809279"
  },
  {
    "text": "architecture because we'll be using probably different Technologies um we're actually looking",
    "start": "1809279",
    "end": "1814360"
  },
  {
    "text": "at using Presto for the smalls or Spectrum which Tony is going to talk to for the Smalls and and",
    "start": "1814360",
    "end": "1820720"
  },
  {
    "text": "we'll get into that so the next one so how did we do it um while we were trying",
    "start": "1820720",
    "end": "1826600"
  },
  {
    "text": "to build out our environment we had software changes that we need to make so the problem with introducing more than",
    "start": "1826600",
    "end": "1832919"
  },
  {
    "text": "one red shift clusters if you created a table before it was always in one",
    "start": "1832919",
    "end": "1838159"
  },
  {
    "text": "cluster and so you only needed one set of connection pools to get there now we",
    "start": "1838159",
    "end": "1843559"
  },
  {
    "text": "had 12 of them and so how does the software know or I should say where how does the query know which cluster to go",
    "start": "1843559",
    "end": "1850679"
  },
  {
    "text": "find it in and so we had been talking to Amazon we were actually looking at building something sort of a broker in",
    "start": "1850679",
    "end": "1857480"
  },
  {
    "text": "our own BBC driver uh but around that time um this thing called PG bouncer um",
    "start": "1857480",
    "end": "1864559"
  },
  {
    "text": "RR came out and what it did is allowed us to have essentially a connection pool",
    "start": "1864559",
    "end": "1871720"
  },
  {
    "text": "and you could put a thin parser in front of it so as long as we named our clusters a way that we could recognize",
    "start": "1871720",
    "end": "1878559"
  },
  {
    "text": "them and it literally was rs1 rs2 RS3 um it pulls the query it allows you",
    "start": "1878559",
    "end": "1885320"
  },
  {
    "text": "to do a rewrite of the query so we would just have a generic um part in the query that we would put in the location how",
    "start": "1885320",
    "end": "1892480"
  },
  {
    "text": "should I say this we would write in our tracking table which cluster it was in",
    "start": "1892480",
    "end": "1898519"
  },
  {
    "text": "this the broker would do a rewrite of it to actually use the correct connection",
    "start": "1898519",
    "end": "1904480"
  },
  {
    "text": "to the correct correct database so again what this allowed us to do is Without Really changing our code because we also",
    "start": "1904480",
    "end": "1911080"
  },
  {
    "text": "have a bi tool that we used and we can't change that code at all it allowed us to have the same capabilities that we had",
    "start": "1911080",
    "end": "1917639"
  },
  {
    "text": "before for but essentially if we were running into issues with around um a",
    "start": "1917639",
    "end": "1922840"
  },
  {
    "text": "couple dozen users in the system while big copies were going on we could go to",
    "start": "1922840",
    "end": "1928360"
  },
  {
    "text": "now essentially 15 times the amount of concurrency that we had before so that's all that I have um next",
    "start": "1928360",
    "end": "1935960"
  },
  {
    "text": "up is Jess Khan from CMS okay great thank you I don't have",
    "start": "1935960",
    "end": "1943440"
  },
  {
    "text": "any slides I don't have any slides it's even better I have slide allergies so",
    "start": "1943440",
    "end": "1949279"
  },
  {
    "text": "this works for me um okay so I'm going to give you a little bit of a segue",
    "start": "1949279",
    "end": "1954919"
  },
  {
    "text": "because um I am a self admitted um it and data convert as opposed to native",
    "start": "1954919",
    "end": "1961600"
  },
  {
    "text": "born like these guys clearly are um but I got there as fast as I could so here's",
    "start": "1961600",
    "end": "1966880"
  },
  {
    "text": "what I'll tell you um I'm in charge of data and it for Medicaid um at CMS the",
    "start": "1966880",
    "end": "1973159"
  },
  {
    "text": "centers for Medicaid and Medicare services so federal government um and we",
    "start": "1973159",
    "end": "1978960"
  },
  {
    "text": "have a program Medicaid is administered by States and so it's a partnership and so they have to give us their data we",
    "start": "1978960",
    "end": "1985399"
  },
  {
    "text": "don't have a direct line to it um and so we're not the primary data source so part of the reason that we like red",
    "start": "1985399",
    "end": "1992360"
  },
  {
    "text": "shift is because it's really good for loading what my Engineers call I don't like this term but I'm going to say it anyway dirty data I prefer to say that",
    "start": "1992360",
    "end": "2000720"
  },
  {
    "text": "it's not pristine data it is what it is and other than the edits that we run to understand that we don't change it we're",
    "start": "2000720",
    "end": "2006639"
  },
  {
    "text": "very very serious about being a steward of the data as is and so red shift allows us um to load to load that data",
    "start": "2006639",
    "end": "2014720"
  },
  {
    "text": "um as it is um and it allows us to use",
    "start": "2014720",
    "end": "2020399"
  },
  {
    "text": "um what we call these um analytic dashboards so that in real time we can",
    "start": "2020399",
    "end": "2026159"
  },
  {
    "text": "um show our users what's happening in each state as the data loads um month after month um we like the diversity of",
    "start": "2026159",
    "end": "2033919"
  },
  {
    "text": "products everything has to be fed ramp approved for us and all those extra steps and so we like the integration we",
    "start": "2033919",
    "end": "2040440"
  },
  {
    "text": "have um micro strategy and SAS running now we will add others so that way we",
    "start": "2040440",
    "end": "2046360"
  },
  {
    "text": "can have everything from the very wonky data scientist who wants to run their own queries all the way to somebody who",
    "start": "2046360",
    "end": "2052480"
  },
  {
    "text": "really you shouldn't even mention data or analysis around them or they get the chills you should just say sit down I want to show you something cool and it's",
    "start": "2052480",
    "end": "2058960"
  },
  {
    "text": "Facebook easy it's a dashboard and it's all intuitive I have to service that range of data users and so um in",
    "start": "2058960",
    "end": "2067000"
  },
  {
    "text": "combination all of these things really made it the best for us um and we really have um appreciated the Ingenuity um",
    "start": "2067000",
    "end": "2075720"
  },
  {
    "text": "that we've gotten in the support from the Amazon team and the red shift team and figuring out and problem solving as",
    "start": "2075720",
    "end": "2080878"
  },
  {
    "text": "we go because this is the first time um as I mentioned earlier this morning that we have ever put this large of a data",
    "start": "2080879",
    "end": "2087280"
  },
  {
    "text": "set and a personal health information data set in the cloud at our agency and it was meant for performance not storage",
    "start": "2087280",
    "end": "2093480"
  },
  {
    "text": "so these kinds of integration and growth and support for um dirty data has been",
    "start": "2093480",
    "end": "2099119"
  },
  {
    "text": "really critical to what we're trying to do such so that we're putting other kinds of data into that same Cloud so",
    "start": "2099119",
    "end": "2106280"
  },
  {
    "text": "that we can start to layer things together and to make that more real for you U Medicaid right now the states have",
    "start": "2106280",
    "end": "2112400"
  },
  {
    "text": "a lot of flexibility um they can operate policy slightly different so one state might",
    "start": "2112400",
    "end": "2117599"
  },
  {
    "text": "consider a pregnant woman two people on an application another state might consider that one person for example and",
    "start": "2117599",
    "end": "2124200"
  },
  {
    "text": "so um what's important for us is to understand when States Implement different policies how does utilization",
    "start": "2124200",
    "end": "2130560"
  },
  {
    "text": "look so we get all these uh waivers from states to be able to do their policies",
    "start": "2130560",
    "end": "2136040"
  },
  {
    "text": "differently than the other state and then we get all this claims data and encounter data and eligibility data and",
    "start": "2136040",
    "end": "2141320"
  },
  {
    "text": "we need to be able to marry the two so that you can say okay when the state covers this service or people are",
    "start": "2141320",
    "end": "2146800"
  },
  {
    "text": "allowed to access this service in this way what does utilization look like well those are two very different kinds of",
    "start": "2146800",
    "end": "2152280"
  },
  {
    "text": "data and that come in into two very different ways it's a mix of structured and unstructured um and so we this again",
    "start": "2152280",
    "end": "2159319"
  },
  {
    "text": "allows us to put those things together and bounce it off the data on how much money we give to states to pay for these",
    "start": "2159319",
    "end": "2165040"
  },
  {
    "text": "things um and other things like Pharmacy and and other data points that come in to give you the true total cost of what",
    "start": "2165040",
    "end": "2172079"
  },
  {
    "text": "we're providing for this care so again that flexibility was really important to us to have such an operational data set",
    "start": "2172079",
    "end": "2179079"
  },
  {
    "text": "certainly um not an esoteric exercise so I'm going to turn it back to Tony who",
    "start": "2179079",
    "end": "2184760"
  },
  {
    "text": "will go back to the it wonky stuff thank you am I on okay thank you very",
    "start": "2184760",
    "end": "2192079"
  },
  {
    "text": "much both of you really good works just you have to be",
    "start": "2192079",
    "end": "2197359"
  },
  {
    "text": "close uh so I'm going to talk a little bit about uh some of the new features we've recently released in red shift and",
    "start": "2197359",
    "end": "2203040"
  },
  {
    "text": "then go into a little bit of uh the road map that I can on some upcoming features",
    "start": "2203040",
    "end": "2208079"
  },
  {
    "text": "as well uh so if you haven't heard we",
    "start": "2208079",
    "end": "2213560"
  },
  {
    "text": "released uh Amazon red shift Spectrum uh in April",
    "start": "2213560",
    "end": "2219200"
  },
  {
    "text": "what red shift spectrum is is it's the ability to query data on S3 directly",
    "start": "2219200",
    "end": "2226280"
  },
  {
    "text": "from redshift using a another scalable",
    "start": "2226280",
    "end": "2231319"
  },
  {
    "text": "cluster that is thousands of nodes red shift Spectrum was designed to",
    "start": "2231319",
    "end": "2237240"
  },
  {
    "text": "be exabyte scale uh one of the you know primary use cases was internally at",
    "start": "2237240",
    "end": "2243880"
  },
  {
    "text": "amazon.com we have a huge retail data warehouse from all the orders that are",
    "start": "2243880",
    "end": "2249480"
  },
  {
    "text": "placed at Amazon so exabyte scale was something we needed we also had a",
    "start": "2249480",
    "end": "2254560"
  },
  {
    "text": "handful of other customers that were really kind of pushing the limits of what red shift uh can store uh the",
    "start": "2254560",
    "end": "2261720"
  },
  {
    "text": "largest cluster we have is about six pedabytes of data and red shift and",
    "start": "2261720",
    "end": "2267599"
  },
  {
    "text": "customer needs more so Spectrum was kind of meant to that you can kind of go to that next",
    "start": "2267599",
    "end": "2273480"
  },
  {
    "text": "level so it is elastic highly available you pay with an on demand per query",
    "start": "2273480",
    "end": "2280640"
  },
  {
    "text": "basis we it's the same price as Athena if any of you familiar with that service",
    "start": "2280640",
    "end": "2285800"
  },
  {
    "text": "so it's $5 uh per terabyte scanned off of S3 and you can technically Point",
    "start": "2285800",
    "end": "2292400"
  },
  {
    "text": "multiple red shift clusters to the exact same data in S3 so if you have you know",
    "start": "2292400",
    "end": "2297440"
  },
  {
    "text": "a data Lake filled with data in S3 and you have multiple red shift clusters like finra has they can query the exact",
    "start": "2297440",
    "end": "2304880"
  },
  {
    "text": "same data uh from any of those clusters ERS one other interesting use case is is",
    "start": "2304880",
    "end": "2312079"
  },
  {
    "text": "kind of the no ETL case uh was working with a game company recently and there",
    "start": "2312079",
    "end": "2318359"
  },
  {
    "text": "was basically event data from a video game and they could just land the data",
    "start": "2318359",
    "end": "2323599"
  },
  {
    "text": "in S3 there was no ETL they needed to do on it because it's just event data rolling in and they could just",
    "start": "2323599",
    "end": "2330680"
  },
  {
    "text": "immediately begin quering it right off S3 so super convenient if you have that kind of workload where it's just a pend",
    "start": "2330680",
    "end": "2336680"
  },
  {
    "text": "only and just start querying it instantly the other beautiful thing",
    "start": "2336680",
    "end": "2341800"
  },
  {
    "text": "about red shift Spectrum it's the exact same sequel that you use in red shift so",
    "start": "2341800",
    "end": "2348200"
  },
  {
    "text": "it's the full set of SQL uh there's no different end points no switching end",
    "start": "2348200",
    "end": "2354079"
  },
  {
    "text": "points you just connect to the same red shift cluster and now you can query external",
    "start": "2354079",
    "end": "2360079"
  },
  {
    "start": "2362000",
    "end": "2362000"
  },
  {
    "text": "tables so it's kind of made a bit of a paradigm shift in a way traditionally on",
    "start": "2362400",
    "end": "2369280"
  },
  {
    "text": "the left there we you know you'd kind of be picking and choosing what data you",
    "start": "2369280",
    "end": "2374400"
  },
  {
    "text": "want to put into your data warehouse uh usually for a lot of people that's like",
    "start": "2374400",
    "end": "2379720"
  },
  {
    "text": "maybe the last year or last three years or whatever time period that they uh",
    "start": "2379720",
    "end": "2384800"
  },
  {
    "text": "kind of deem as the most valuable or that they can afford with red shift Spectrum you can have all of your data",
    "start": "2384800",
    "end": "2391359"
  },
  {
    "text": "sitting in S3 which is very cheap H and you can query It On Demand so if you",
    "start": "2391359",
    "end": "2396680"
  },
  {
    "text": "have these ports that maybe you only run once a quarter once a year uh you just pay on the ond demand price and you can",
    "start": "2396680",
    "end": "2404560"
  },
  {
    "text": "now query all of your data thank",
    "start": "2404560",
    "end": "2409880"
  },
  {
    "start": "2409000",
    "end": "2409000"
  },
  {
    "text": "you so as I mentioned it is fully ancel it's the same SQL uh it's has full",
    "start": "2409880",
    "end": "2416240"
  },
  {
    "text": "support for joins and all of that you can even join data between your red shift cluster and S3 so you those joins",
    "start": "2416240",
    "end": "2424599"
  },
  {
    "text": "will work red shift's query Optimizer is really smart it'll figure out which T which way to pull data uh whether it's",
    "start": "2424599",
    "end": "2431880"
  },
  {
    "text": "to pull data out of your red shift cluster and down into the Spectrum layer or the other way around but red shift",
    "start": "2431880",
    "end": "2437760"
  },
  {
    "text": "will figure out uh what what the best way to do that is you can even do like all the windowing functions and all of",
    "start": "2437760",
    "end": "2444160"
  },
  {
    "text": "that good stuff uh and it works so the architecture of this I",
    "start": "2444160",
    "end": "2452040"
  },
  {
    "text": "mentioned there's another compute layer uh if you remember from the architecture before the top bit there is you know",
    "start": "2452040",
    "end": "2458880"
  },
  {
    "text": "your standard endpoint connected to the leader node with your red shift compute nodes behind it um what'll end up happening is is",
    "start": "2458880",
    "end": "2466599"
  },
  {
    "text": "when you send a query there's kind of an example of a query going against an S3",
    "start": "2466599",
    "end": "2472079"
  },
  {
    "text": "table there red shift's query Optimizer has been designed to look at that query",
    "start": "2472079",
    "end": "2478920"
  },
  {
    "text": "it will figure out how many nodes to provision and it will those compute nodes will then ask the Spectrum layer",
    "start": "2478920",
    "end": "2485720"
  },
  {
    "text": "to execute that query basically what we're going to do is we're going to send that query down to a certain number of",
    "start": "2485720",
    "end": "2491760"
  },
  {
    "text": "compute nodes based on what the optimizer figures is the best and fastest way to get you the results those",
    "start": "2491760",
    "end": "2498400"
  },
  {
    "text": "Spectrum nodes will then pull the data off of S3 uh and do the query and send",
    "start": "2498400",
    "end": "2505280"
  },
  {
    "text": "up the results red shift Spectrum uh is also",
    "start": "2505280",
    "end": "2511079"
  },
  {
    "start": "2508000",
    "end": "2508000"
  },
  {
    "text": "secure uh all of the same audit logging that's in red shift applies uh you can",
    "start": "2511079",
    "end": "2516560"
  },
  {
    "text": "still do all all the end to-end encryption uh it still you know runs in your ver VPC uh and you know it's Hippa",
    "start": "2516560",
    "end": "2524280"
  },
  {
    "text": "compliant and sock and these fed ramp and all of these other uh the certificates you know we've we've",
    "start": "2524280",
    "end": "2531920"
  },
  {
    "text": "made sure that it's uh you know compliant with that so if you have those workloads red shift Spectrum does have",
    "start": "2531920",
    "end": "2538680"
  },
  {
    "text": "that today these are some of the customers that helped us uh get red shift Spectrum",
    "start": "2538680",
    "end": "2545839"
  },
  {
    "text": "out um and TT do uh was the one customer I mentioned with the six pedabytes uh in",
    "start": "2545839",
    "end": "2552000"
  },
  {
    "text": "their cluster um but so they were a huge part in helping us get red red shift",
    "start": "2552000",
    "end": "2557520"
  },
  {
    "text": "Spectrum out uh as well as you know red fin and Yelp and others uh as amazon.com",
    "start": "2557520",
    "end": "2563720"
  },
  {
    "text": "who's not up there was also a big help as",
    "start": "2563720",
    "end": "2568240"
  },
  {
    "start": "2568000",
    "end": "2568000"
  },
  {
    "text": "well so moving into a few of the other recently released features uh qmr was",
    "start": "2568760",
    "end": "2575599"
  },
  {
    "text": "also released in April uh it's basic query monitoring rules is what it is basically it allows you in",
    "start": "2575599",
    "end": "2582559"
  },
  {
    "text": "our workload management system to set up rules that watch the system and they'll look for things like you could set it up",
    "start": "2582559",
    "end": "2588760"
  },
  {
    "text": "to watch for maybe you know uh query that returns billions of rows maybe",
    "start": "2588760",
    "end": "2594280"
  },
  {
    "text": "someone wrote a really bad query it's a cartisian product or something awful and it's going to return a whole bunch of",
    "start": "2594280",
    "end": "2600000"
  },
  {
    "text": "rows you can set up rules to detect those queries and proactively kill",
    "start": "2600000",
    "end": "2605680"
  },
  {
    "text": "them the next that I mentioned a couple times in the presentation with the compression is in February actually end",
    "start": "2605680",
    "end": "2613280"
  },
  {
    "text": "of January we released uh zst standard compression for our columns this is a compression",
    "start": "2613280",
    "end": "2619240"
  },
  {
    "text": "algorithm actually came out of Facebook uh that they open sourced and it's an",
    "start": "2619240",
    "end": "2625200"
  },
  {
    "text": "incredible compression algorithm that we're using now in red shift and we're getting very good results with",
    "start": "2625200",
    "end": "2631599"
  },
  {
    "text": "it we added uh this was a very frequently Asked uh line item which was",
    "start": "2631599",
    "end": "2637160"
  },
  {
    "text": "time stamp with time zone uh so red shift can now do time stamps with a time zone uh and then a couple others multi",
    "start": "2637160",
    "end": "2644440"
  },
  {
    "text": "bite object names connection limits uh for users uh sometimes you want to",
    "start": "2644440",
    "end": "2650680"
  },
  {
    "text": "restrict the number of users uh or connections a single user will open to a red shift cluster um so you're only",
    "start": "2650680",
    "end": "2657680"
  },
  {
    "text": "allowed 500 so it's a lot but sometimes users create a lot of",
    "start": "2657680",
    "end": "2664160"
  },
  {
    "text": "connections we've also last last year was a big year for performance for us we",
    "start": "2664960",
    "end": "2670680"
  },
  {
    "text": "worked very heavily to increase the performance of red shift uh there were in a lot of cases a lot of queries are",
    "start": "2670680",
    "end": "2677400"
  },
  {
    "text": "run actually about 5x faster than they did uh over a year ago uh so that was a",
    "start": "2677400",
    "end": "2682839"
  },
  {
    "text": "huge theme for us last year uh vacuum performance was something we also worked",
    "start": "2682839",
    "end": "2688000"
  },
  {
    "text": "very heavily on especially vacuum deletes uh so we can prune out those deleted rows now very quickly uh",
    "start": "2688000",
    "end": "2694800"
  },
  {
    "text": "snapshot restore um a year ago August we doubled the performance of",
    "start": "2694800",
    "end": "2700760"
  },
  {
    "text": "that in certain cases the next feature uh we really work to uh extend the",
    "start": "2700760",
    "end": "2707800"
  },
  {
    "text": "sorted region it's called so it's basically if you're loading sorted data you don't actually need to sort it anymore if you're using a single sort",
    "start": "2707800",
    "end": "2714200"
  },
  {
    "text": "key so that was kind of you know one of the features we've been working on the",
    "start": "2714200",
    "end": "2720040"
  },
  {
    "text": "schema conversion tool so for those of you out there that are looking at migrations uh I totally recommend",
    "start": "2720040",
    "end": "2725559"
  },
  {
    "text": "checking out this tool it's not technically part of red shift it's a standalone tool you can download Windows",
    "start": "2725559",
    "end": "2731880"
  },
  {
    "text": "Mac and what you can do is you can point it to to a source system and to Red",
    "start": "2731880",
    "end": "2738000"
  },
  {
    "text": "shift and we'll convert the schema for you as best as we can uh it'll give you out a report on how much it converted",
    "start": "2738000",
    "end": "2744680"
  },
  {
    "text": "and it can also do a onetime data migration as well uh so that's you know if you're moving from another system I",
    "start": "2744680",
    "end": "2750760"
  },
  {
    "text": "highly recommend checking that out coming soon I am am Authentication",
    "start": "2750760",
    "end": "2757079"
  },
  {
    "start": "2754000",
    "end": "2754000"
  },
  {
    "text": "this will be out well we're working on it but it's it is really coming soon uh",
    "start": "2757079",
    "end": "2762800"
  },
  {
    "text": "we announced this technically at reinvent uh but it's basically you'll be able to map a user inside your red shift",
    "start": "2762800",
    "end": "2769800"
  },
  {
    "text": "cluster to an IM user and essentially do single sign on with your IM",
    "start": "2769800",
    "end": "2776040"
  },
  {
    "text": "credentials couple other uh things that we're also coming out with one is this",
    "start": "2776319",
    "end": "2781880"
  },
  {
    "text": "one I I'm super excited for this top one it's automatic vacuum so we will have",
    "start": "2781880",
    "end": "2787000"
  },
  {
    "text": "Auto vacuum uh we're working on auto vacuum delete only first so that one",
    "start": "2787000",
    "end": "2792559"
  },
  {
    "text": "will be coming out soon and then after that we will work on the vacu autov vacuum sort the",
    "start": "2792559",
    "end": "2799800"
  },
  {
    "text": "next is a short query bias which I perked up uh when Todd was talking about queries getting stuck behind other",
    "start": "2799800",
    "end": "2806880"
  },
  {
    "text": "longer running queries this is is where we're going to be adding a feature to Red shift to prioritize your short",
    "start": "2806880",
    "end": "2812880"
  },
  {
    "text": "running queries so red shift if you have good statistics we can detect if a quer is going to be short or not and what",
    "start": "2812880",
    "end": "2819800"
  },
  {
    "text": "that'll mean is is we can we'll prioritize it so it gets done the idea",
    "start": "2819800",
    "end": "2824880"
  },
  {
    "text": "is is to keep those one two 3 second queries running fast um and if we slow",
    "start": "2824880",
    "end": "2831280"
  },
  {
    "text": "down some of the longer running queries that you know maybe take 10 minutes or something and they now take 12 it's",
    "start": "2831280",
    "end": "2836520"
  },
  {
    "text": "probably not a big deal so that's the idea behind this",
    "start": "2836520",
    "end": "2841880"
  },
  {
    "text": "feature uh and that's about all I have and I think if we're going to up for the",
    "start": "2842200",
    "end": "2847520"
  },
  {
    "text": "last 2 minutes here for Q&A um for all three of",
    "start": "2847520",
    "end": "2853359"
  },
  {
    "text": "[Applause] us so if you were to use um uh red ship",
    "start": "2853490",
    "end": "2863240"
  },
  {
    "text": "Spectrum how do you do the cluster sizing um so the cluster sizing and red",
    "start": "2863240",
    "end": "2870400"
  },
  {
    "text": "shift spectrum is is we actually have a large elastic cluster that will size up",
    "start": "2870400",
    "end": "2875520"
  },
  {
    "text": "and down behind the scenes um your red shift cluster is going to end up based on the query it will pull a",
    "start": "2875520",
    "end": "2882760"
  },
  {
    "text": "certain number of nodes from that large elastic cluster and execute on that and it's going to depend on things like the",
    "start": "2882760",
    "end": "2889079"
  },
  {
    "text": "number of files you have in S3 and such uh because if you only have a single file in S3 to pull from we can only",
    "start": "2889079",
    "end": "2895920"
  },
  {
    "text": "really pull that file one at a time so it's you're only going to get one node so it's going to depend on things like that but it's a",
    "start": "2895920",
    "end": "2902359"
  },
  {
    "text": "smart think of it like a query Optimizer that is provisioning the amount of nodes",
    "start": "2902359",
    "end": "2908160"
  },
  {
    "text": "on the fly so truly taking advantage of the",
    "start": "2908160",
    "end": "2913400"
  },
  {
    "text": "cloud um question is for Bob um so you uh experimented a lot with clustering on",
    "start": "2913400",
    "end": "2920000"
  },
  {
    "text": "red shift and to really scale up to your needs so how how was the performance",
    "start": "2920000",
    "end": "2925760"
  },
  {
    "text": "change after all these changes that you had made like from a small small clusters to large cluster and so what we",
    "start": "2925760",
    "end": "2933280"
  },
  {
    "text": "were looking for was consistency so we want if if something took 2 seconds the",
    "start": "2933280",
    "end": "2938960"
  },
  {
    "text": "first time we wanted it to always take 2 seconds for the same type of thing so it wasn't so much making two seconds",
    "start": "2938960",
    "end": "2945440"
  },
  {
    "text": "running 1 second it was more consistent experience um so by scaling it out and",
    "start": "2945440",
    "end": "2952359"
  },
  {
    "text": "Spectrum actually is going to take care of some of the things that we did using PG bouncer because it all scale behind",
    "start": "2952359",
    "end": "2958480"
  },
  {
    "text": "the scenes uh it just wasn't available yet so but we were able to achieve based",
    "start": "2958480",
    "end": "2964720"
  },
  {
    "text": "on concurrency of users and requests that we have occasionally we still will have a really big request come in we get",
    "start": "2964720",
    "end": "2972400"
  },
  {
    "text": "occasionally it'll be like we we max out at 2.4 billion rows and it's one an",
    "start": "2972400",
    "end": "2977960"
  },
  {
    "text": "analyze is happening after the fact sometimes we still can get stuck on a given cluster and for the most part",
    "start": "2977960",
    "end": "2984559"
  },
  {
    "text": "those are the biggest requests and we basically have said you know if you've got a big data Mark you might still",
    "start": "2984559",
    "end": "2991240"
  },
  {
    "text": "experience but as far as the small data marks it's been very consistent uh unfortunately last",
    "start": "2991240",
    "end": "3000000"
  },
  {
    "text": "question no more what's the for",
    "start": "3002440",
    "end": "3009400"
  },
  {
    "text": "usum um I think the main thing would be if you already have a red shift cluster",
    "start": "3010359",
    "end": "3015960"
  },
  {
    "text": "for example and you don't want to switch end points which makes sense uh the",
    "start": "3015960",
    "end": "3021160"
  },
  {
    "text": "other would be the SQL in red shift is the same dialect to what you'd already be using",
    "start": "3021160",
    "end": "3027720"
  },
  {
    "text": "obviously with Athena it's a different dialect of SQL so those would be the main things uh you would use Athena",
    "start": "3027720",
    "end": "3034720"
  },
  {
    "text": "obviously if you didn't use red shift because to spin up a red shift cluster just to get query On Demand on S3 uh",
    "start": "3034720",
    "end": "3042079"
  },
  {
    "text": "wouldn't you know make sense I I have one slight different Nuance to that if",
    "start": "3042079",
    "end": "3048359"
  },
  {
    "text": "one of the things that happens with Presto on Athena is the further you get so if you do have something that you",
    "start": "3048359",
    "end": "3053760"
  },
  {
    "text": "need to page through data when you present it back to users the further you get down the longer it takes so red",
    "start": "3053760",
    "end": "3060359"
  },
  {
    "text": "shift stays consistent regardless of how far down the page but Presto on Athena and our experience actually takes a",
    "start": "3060359",
    "end": "3066640"
  },
  {
    "text": "little bit longer the further down you go thank thank you I'll be around if any people have",
    "start": "3066640",
    "end": "3073640"
  },
  {
    "text": "any other questions",
    "start": "3073640",
    "end": "3078839"
  }
]
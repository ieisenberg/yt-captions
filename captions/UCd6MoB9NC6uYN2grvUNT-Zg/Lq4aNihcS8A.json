[
  {
    "start": "0",
    "end": "219000"
  },
  {
    "text": "hello everyone my name is Maria and I'm the CTO at tinder so we're all here",
    "start": "260",
    "end": "8670"
  },
  {
    "text": "today curious about data migration am i right",
    "start": "8670",
    "end": "13830"
  },
  {
    "text": "and before we dive deep into the best practices the lessons learned the",
    "start": "13830",
    "end": "21510"
  },
  {
    "text": "nightmares I want to start this talk by",
    "start": "21510",
    "end": "26779"
  },
  {
    "text": "sharing the story of how it all got started the question why did we need to",
    "start": "26779",
    "end": "35309"
  },
  {
    "text": "do such a massive data migration so for",
    "start": "35309",
    "end": "41610"
  },
  {
    "text": "a combination of reasons let's just call it legacy that we had a hybrid",
    "start": "41610",
    "end": "47070"
  },
  {
    "text": "environment a lot of our services are running on AWS but we have a very core",
    "start": "47070",
    "end": "55559"
  },
  {
    "text": "piece of the entire runtime process hosting one of our largest data set and",
    "start": "55559",
    "end": "63090"
  },
  {
    "text": "very mission-critical separate at a data center and you know after a few months",
    "start": "63090",
    "end": "73590"
  },
  {
    "text": "of investigating understanding the architecture and the benefits and cost",
    "start": "73590",
    "end": "79710"
  },
  {
    "text": "that I decided that it was necessary to migrate the data off this data center",
    "start": "79710",
    "end": "86460"
  },
  {
    "text": "onto AWS and this is a decision it wasn't made lightly and as a CTO of the",
    "start": "86460",
    "end": "94020"
  },
  {
    "text": "company I had to present to the board and so there's the kind of the board room story so we went up to the board I",
    "start": "94020",
    "end": "101850"
  },
  {
    "text": "put together this presentation and in summary it was three words downtime",
    "start": "101850",
    "end": "107869"
  },
  {
    "text": "performance and cost the previous setup in this situation that we were suffering",
    "start": "107869",
    "end": "116240"
  },
  {
    "text": "outages here and there and it really wasn't something we felt like we could",
    "start": "116240",
    "end": "122329"
  },
  {
    "text": "mitigate through engineering excellence and in terms of performance as you can",
    "start": "122329",
    "end": "130530"
  },
  {
    "text": "imagine just data transferring across the Y is just pure physics but when you have",
    "start": "130530",
    "end": "135990"
  },
  {
    "text": "data coming in and out and you run time and it's pegging long latency and",
    "start": "135990",
    "end": "142020"
  },
  {
    "text": "hampering our user experience in the third part it's cost because you are",
    "start": "142020",
    "end": "148290"
  },
  {
    "text": "paying for all the data transfer and additional maintenance and support at",
    "start": "148290",
    "end": "153660"
  },
  {
    "text": "this this data center that's hosting that user data so that led to this",
    "start": "153660",
    "end": "158820"
  },
  {
    "text": "decision and so if anyone here is planning or consider a thinking about",
    "start": "158820",
    "end": "165540"
  },
  {
    "text": "that I think the first question we need to have a very clear answer is its why",
    "start": "165540",
    "end": "171660"
  },
  {
    "text": "why do we need to do that and after we've committed of yes this is the right",
    "start": "171660",
    "end": "178110"
  },
  {
    "text": "thing to do let's do it it wasn't easy frankly I was a little",
    "start": "178110",
    "end": "184050"
  },
  {
    "text": "scared because of course I asked the board ok we're gonna do migration and",
    "start": "184050",
    "end": "190890"
  },
  {
    "text": "this is in the critical path of our runtime services tonight go dark for a",
    "start": "190890",
    "end": "198090"
  },
  {
    "text": "bit right I actually already knew the answer is no but I thought I would ask anyways and then basically the",
    "start": "198090",
    "end": "206010"
  },
  {
    "text": "requirement is yes you can migrate all day long but I want zero downtime right",
    "start": "206010",
    "end": "211470"
  },
  {
    "text": "and that makes right all the challenges surface so just in case you don't know I",
    "start": "211470",
    "end": "223170"
  },
  {
    "start": "219000",
    "end": "278000"
  },
  {
    "text": "want to do a quick intro off gender so who here has heard of tinder",
    "start": "223170",
    "end": "229010"
  },
  {
    "text": "yes everyone yeah so so what is tinder",
    "start": "229010",
    "end": "234110"
  },
  {
    "text": "tinder is a platform to connect people all over the world to make a new",
    "start": "234110",
    "end": "240030"
  },
  {
    "text": "connection right so we all use Facebook Instagram and so forth right so those",
    "start": "240030",
    "end": "245070"
  },
  {
    "text": "social networks are important because a keeps us connected with you know friends",
    "start": "245070",
    "end": "252540"
  },
  {
    "text": "cousins right people you want to elementary school that that's your that's your network of social",
    "start": "252540",
    "end": "259019"
  },
  {
    "text": "connections and that's great so I know when my cousin had for lunch yesterday but how about the people you don't",
    "start": "259019",
    "end": "267750"
  },
  {
    "text": "yet no right how about a new connection and have a conversation you would not",
    "start": "267750",
    "end": "273390"
  },
  {
    "text": "have had otherwise and this is what tinder is for and so if you've known",
    "start": "273390",
    "end": "280620"
  },
  {
    "start": "278000",
    "end": "361000"
  },
  {
    "text": "tinder you probably are familiar with a swipe laughs and swipe right and it",
    "start": "280620",
    "end": "286080"
  },
  {
    "text": "looks like such a simple app right it's just this just this little app you can",
    "start": "286080",
    "end": "292410"
  },
  {
    "text": "you see photos and you swipe and how hard could that be so the tinder product design I use this",
    "start": "292410",
    "end": "300810"
  },
  {
    "text": "term iceberg product meaning the user interface is very minimalist and very",
    "start": "300810",
    "end": "309630"
  },
  {
    "text": "intuitive for anyone to use and that was the intention and also a constraint we",
    "start": "309630",
    "end": "316470"
  },
  {
    "text": "hide all of the complexity beneath the surface and if you look at our scale and",
    "start": "316470",
    "end": "322710"
  },
  {
    "text": "scale it makes all the difference that we're processing 1.6 billion swipes a",
    "start": "322710",
    "end": "329790"
  },
  {
    "text": "day our users all over the world so we processed over 300 million personalized",
    "start": "329790",
    "end": "336620"
  },
  {
    "text": "geospatial queries in terms of when you open the app actually there's a very",
    "start": "336620",
    "end": "343650"
  },
  {
    "text": "complex data retrieval and computation and ranking in the last step is serving",
    "start": "343650",
    "end": "349320"
  },
  {
    "text": "and rendering we're also a very global company we're in a hundred and ninety countries and",
    "start": "349320",
    "end": "355680"
  },
  {
    "text": "the products are in more than 40 languages yep so now compounding massive",
    "start": "355680",
    "end": "364710"
  },
  {
    "start": "361000",
    "end": "479000"
  },
  {
    "text": "amount of data right global footprint and we want to migrate all these data",
    "start": "364710",
    "end": "371580"
  },
  {
    "text": "from you know some data centers I'm wearing east coast on to the cloud in this case AWS this is all great but",
    "start": "371580",
    "end": "381210"
  },
  {
    "text": "who's gonna do the work so again a little story of the first time at my",
    "start": "381210",
    "end": "387210"
  },
  {
    "text": "twins joonyoung at this coffee shop career cafe in West Hollywood and a",
    "start": "387210",
    "end": "392790"
  },
  {
    "text": "little background of Jun Yan that he wanted the Seoul National University",
    "start": "392790",
    "end": "397990"
  },
  {
    "text": "South Korea and the ones you see at new and then went to UIC and got his PhD in",
    "start": "397990",
    "end": "403540"
  },
  {
    "text": "computer science doing machine learning and robotics database systems and when I saw his resume what I see is someone",
    "start": "403540",
    "end": "411610"
  },
  {
    "text": "who's not afraid of a challenge more so he's probably energized by my challenges",
    "start": "411610",
    "end": "419230"
  },
  {
    "text": "so when I first met I was the extending offer and it was very honest I said you know I promise you you won't be bored",
    "start": "419230",
    "end": "426060"
  },
  {
    "text": "and I think it's it's and he wasn't scared and he said you know I'm ready to",
    "start": "426060",
    "end": "432250"
  },
  {
    "text": "do this long story short it took us months to get to a complete migration",
    "start": "432250",
    "end": "437860"
  },
  {
    "text": "order 100% on the new system and going back to the original concern downtime",
    "start": "437860",
    "end": "444420"
  },
  {
    "text": "performance and cost that we benefit it in all three and address all the issues",
    "start": "444420",
    "end": "449790"
  },
  {
    "text": "so next I'll have joonyoung walk you through this this journey that we had",
    "start": "449790",
    "end": "456160"
  },
  {
    "text": "gone through a massive migration with zero downtime thank you thank you again",
    "start": "456160",
    "end": "468160"
  },
  {
    "text": "Maria for nice instructions I'm very happy to be here today to have an opportunity to share out in the really",
    "start": "468160",
    "end": "474760"
  },
  {
    "text": "handle massive data migration with zero downtime as Maya already gave on context",
    "start": "474760",
    "end": "481060"
  },
  {
    "start": "479000",
    "end": "790000"
  },
  {
    "text": "or story and a higher level the building efficient and reliable backend service is really tough and one of the core",
    "start": "481060",
    "end": "488470"
  },
  {
    "text": "challenges coming out from that is choosing the right data stores so these",
    "start": "488470",
    "end": "493570"
  },
  {
    "text": "days it comes more and more complex you have more choices coming out in the market and you now have to understand",
    "start": "493570",
    "end": "500500"
  },
  {
    "text": "what's the characteristic of the retail stores and what's the benefit you can actually get maximally from it and also",
    "start": "500500",
    "end": "508300"
  },
  {
    "text": "you need to look at your data and then see what it could fit like let's say one datastore is a perfectly good but if",
    "start": "508300",
    "end": "514719"
  },
  {
    "text": "there is not working on my data set that's basically usually right so obviously we have to understand what's",
    "start": "514720",
    "end": "522460"
  },
  {
    "text": "the requirement coming out naturally from the data set and choosing the right there are stores based on your",
    "start": "522460",
    "end": "528430"
  },
  {
    "text": "requirement is critical but even further the requirement around",
    "start": "528430",
    "end": "534010"
  },
  {
    "text": "the data store and then data is it can be changed over time so for instance your data scale might be",
    "start": "534010",
    "end": "539589"
  },
  {
    "text": "change it if you just keep extending your services going to different global markets your data scale can be significant",
    "start": "539589",
    "end": "545589"
  },
  {
    "text": "increase at the same time data access patterns on your data set can be changed which is often not control over from",
    "start": "545589",
    "end": "553120"
  },
  {
    "text": "your side at all so which is really really tough problem this is where the massive data migration is actually comes",
    "start": "553120",
    "end": "559720"
  },
  {
    "text": "into play and then you really have to consider we have to do the massive migrations between different data stores",
    "start": "559720",
    "end": "566680"
  },
  {
    "text": "or sometimes you need to optimize it our model or access pattern and then schema",
    "start": "566680",
    "end": "572079"
  },
  {
    "text": "and so forth and then that's a great opportunity to reconnect you take that but at the same time it's really tough",
    "start": "572079",
    "end": "579279"
  },
  {
    "text": "as again the Maya mentioned that the handling that the data migration is naturally really tough why is that so",
    "start": "579279",
    "end": "587110"
  },
  {
    "text": "before getting into the details let me actually pop to the one-click picture for that so if you look at this this is",
    "start": "587110",
    "end": "593440"
  },
  {
    "text": "a very simple picture one pilot is trying to fix a problem in the airplane by they actually are operating it in the",
    "start": "593440",
    "end": "599470"
  },
  {
    "text": "air that means this is really were capturing where we are in the real world",
    "start": "599470",
    "end": "604720"
  },
  {
    "text": "we cannot really simply stop operating our services which is really degrading the user experiences then what can we do",
    "start": "604720",
    "end": "611950"
  },
  {
    "text": "we want to do this massive migration over time while keeping the service up",
    "start": "611950",
    "end": "616990"
  },
  {
    "text": "up to date and then up so that's where these are all those challenges are coming in or undeserved massive data",
    "start": "616990",
    "end": "623740"
  },
  {
    "text": "migration in this situation then why do we care about the massive migration",
    "start": "623740",
    "end": "629589"
  },
  {
    "text": "again like why do we need this data migration over time what we want to achieve from that so I just like surely",
    "start": "629589",
    "end": "637899"
  },
  {
    "text": "the one acronym that's called prices I just really like it you can imagine this",
    "start": "637899",
    "end": "644649"
  },
  {
    "text": "is somewhat abstractly way capturing the migration is not coming in free it's",
    "start": "644649",
    "end": "650170"
  },
  {
    "text": "really pricey but if you successfully handle that at the end it comes back",
    "start": "650170",
    "end": "655300"
  },
  {
    "text": "with really highly word for you getting into a little more details this price",
    "start": "655300",
    "end": "660880"
  },
  {
    "text": "actually mean certain terms including performance will ability impact cost efficiency and then",
    "start": "660880",
    "end": "668440"
  },
  {
    "text": "scalability I think it's time in this chart is self-explanatory itself but let",
    "start": "668440",
    "end": "674200"
  },
  {
    "text": "me just explain very briefly for its time for instance performance we really want to decrease the latency what would",
    "start": "674200",
    "end": "680620"
  },
  {
    "text": "be the right there suppose we want to use where to move reliability I want you increase data availability",
    "start": "680620",
    "end": "687040"
  },
  {
    "text": "over time and then really reduce leader downtime from this service what would be a good choice for that once you choose",
    "start": "687040",
    "end": "694690"
  },
  {
    "text": "the right data stores probably you have a lot more flexibility and then freedom to build extra features on top in a much",
    "start": "694690",
    "end": "701829"
  },
  {
    "text": "much faster speed then you will actually give back to much better user impact in",
    "start": "701829",
    "end": "707709"
  },
  {
    "text": "real world and at the same time by optimizing data model in their exit",
    "start": "707709",
    "end": "713170"
  },
  {
    "text": "pattern you will see significant cost reduction by handling this migration over time and that is really critical",
    "start": "713170",
    "end": "721180"
  },
  {
    "text": "because we can actually make the our financial teams over time very happy",
    "start": "721180",
    "end": "726660"
  },
  {
    "text": "when I actually say the efficiency in this chart it's not simply the service efficiency only you can imagine we have",
    "start": "726660",
    "end": "734260"
  },
  {
    "text": "we are engineers we actually need to build something we award and you will see you need to choose the right data",
    "start": "734260",
    "end": "740649"
  },
  {
    "text": "model and there are stores really building services on top testing debugging releasing those features in",
    "start": "740649",
    "end": "746620"
  },
  {
    "text": "the real world you have to often recycle and repeat this many many times and simply choosing the right data stored",
    "start": "746620",
    "end": "753010"
  },
  {
    "text": "and then data model will reduce these efforts a lot less in the scalability",
    "start": "753010",
    "end": "759699"
  },
  {
    "text": "obviously I want to choose the right data stores that is by nature supported horizontal scalability regardless of the",
    "start": "759699",
    "end": "766360"
  },
  {
    "text": "data scale I want to store so so this is",
    "start": "766360",
    "end": "771519"
  },
  {
    "text": "kind of did a goal we actually all want to achieve from the data migration and then what do we do so this is what we",
    "start": "771519",
    "end": "779260"
  },
  {
    "text": "did obviously we chose the dynamodb as a best match for us and we love each other",
    "start": "779260",
    "end": "786940"
  },
  {
    "text": "and then rest of the session I will actually focus on why the dynamodb was a",
    "start": "786940",
    "end": "793930"
  },
  {
    "start": "790000",
    "end": "907000"
  },
  {
    "text": "good fit for us based on our characteristic property and at the same time discover a little",
    "start": "793930",
    "end": "799430"
  },
  {
    "text": "more details about the potato my girlfriend what we built to handle this migration in a very seamless way and",
    "start": "799430",
    "end": "805070"
  },
  {
    "text": "then sharing couple of learning them best practices and then wrap up to a session I believe like most of the",
    "start": "805070",
    "end": "813290"
  },
  {
    "text": "audience in this session is already familiar to the DynamoDB and the related features I will not will repeat too much but I just point a couple points why",
    "start": "813290",
    "end": "820130"
  },
  {
    "text": "there is really attractive to us for instance documentation really claims",
    "start": "820130",
    "end": "825320"
  },
  {
    "text": "that shows the consistent or latest performances really well are usually",
    "start": "825320",
    "end": "831110"
  },
  {
    "text": "very skeptical to believe this documentation lets us by itself so we really test you out and then see how it",
    "start": "831110",
    "end": "836839"
  },
  {
    "text": "works and it was really consistent so I showed the result at the end a little more details another big point for us is",
    "start": "836839",
    "end": "845000"
  },
  {
    "text": "it really supposedly the seamless scalability based on the project repeat",
    "start": "845000",
    "end": "850250"
  },
  {
    "text": "concept with auto scaling with really low administration cost so they actually",
    "start": "850250",
    "end": "855650"
  },
  {
    "text": "helped us to achieve the the development efficiency that I mentioned a little earlier slide just like simply choosing",
    "start": "855650",
    "end": "862220"
  },
  {
    "text": "the dynamodb and one Asian point is low cost we can actually optimize a lot and",
    "start": "862220",
    "end": "868070"
  },
  {
    "text": "play with that with a private throughput you delaying auto scaling reserve capacity and so forth and you can actually optimize cost over time as well",
    "start": "868070",
    "end": "876400"
  },
  {
    "text": "another features on top of Dino DB is obviously we are using more and more streams and triggers on top these Dino",
    "start": "876400",
    "end": "883100"
  },
  {
    "text": "streams comes into the play to actually sync up all the data change in your main critical table and then pushed out the",
    "start": "883100",
    "end": "888980"
  },
  {
    "text": "data into different places automatically and then triggers also if you using lambda functions that actually for free",
    "start": "888980",
    "end": "895880"
  },
  {
    "text": "you can just push out those events happening through the streams and then",
    "start": "895880",
    "end": "901040"
  },
  {
    "text": "you only need to pay where you actually using the lambda function on me so based",
    "start": "901040",
    "end": "908060"
  },
  {
    "start": "907000",
    "end": "958000"
  },
  {
    "text": "on the background I will actually get into a little more details about the data migration framework we actually built and then execute from this side",
    "start": "908060",
    "end": "916040"
  },
  {
    "text": "I'm mainly focusing on like visualizing how we actually build with what flow and",
    "start": "916040",
    "end": "922250"
  },
  {
    "text": "what of the key point and then challenge we actually met and then I will skip to much technical detail in throughout this",
    "start": "922250",
    "end": "928520"
  },
  {
    "text": "session but I'm happy to our friend if you want to get more so",
    "start": "928520",
    "end": "933890"
  },
  {
    "text": "let's say you have your own existing services its app usually running on ec2 the Gateway services anything else and",
    "start": "933890",
    "end": "940870"
  },
  {
    "text": "it actually has your own search data stores it can be you can be dynamo",
    "start": "940870",
    "end": "946220"
  },
  {
    "text": "it can be less cash and so forth anything and you actually serve your entire party on top now I figured okay I",
    "start": "946220",
    "end": "953900"
  },
  {
    "text": "want to move some of the data to dynamo what should i do first obviously you need to set up the dynamic table first",
    "start": "953900",
    "end": "959980"
  },
  {
    "start": "958000",
    "end": "1006000"
  },
  {
    "text": "so you can actually using cloud formation or any other gear a difference here i console you can just create it",
    "start": "959980",
    "end": "965960"
  },
  {
    "text": "and then you can actually start writing to both source and target table whenever",
    "start": "965960",
    "end": "972470"
  },
  {
    "text": "I say for operations in this session that actually means the shadow operations which should be non-blocking",
    "start": "972470",
    "end": "979700"
  },
  {
    "text": "in prod but at the same time we have to really handle this reliable error",
    "start": "979700",
    "end": "985250"
  },
  {
    "text": "handling on those chatter operation so once you turn it on the fork right what",
    "start": "985250",
    "end": "990470"
  },
  {
    "text": "that means is from that point we actually start from the empty data store but you now catch all the incoming",
    "start": "990470",
    "end": "997100"
  },
  {
    "text": "updates in both source and target table and whenever you see the failure still",
    "start": "997100",
    "end": "1002830"
  },
  {
    "text": "you need to handle somehow how can we handle that so we actually using the dynamo DB as our cue I mean you can",
    "start": "1002830",
    "end": "1009700"
  },
  {
    "start": "1006000",
    "end": "1083000"
  },
  {
    "text": "choose different stories like as sq or kinases and so forth and then storing",
    "start": "1009700",
    "end": "1016180"
  },
  {
    "text": "those things and then catching up but what you can do is pushing those failed",
    "start": "1016180",
    "end": "1021610"
  },
  {
    "text": "cases with ID and time stem and so forth turning on the streams and then you can actually enable the data sync flow now",
    "start": "1021610",
    "end": "1028600"
  },
  {
    "text": "you can actually maintain your own Walker said you still have more freedom you can just improve it as a lambda you",
    "start": "1028600",
    "end": "1034990"
  },
  {
    "text": "can just using the KC Walker's running on ec2 obviously you want to utilize but instances to save cost a lot more so the",
    "start": "1034990",
    "end": "1043930"
  },
  {
    "text": "good things for here is the core business logic regardless of how you actually build the Walker is shareable",
    "start": "1043930",
    "end": "1051670"
  },
  {
    "text": "so you want to build in April a form you can't remove their logic into the different form to simply running them",
    "start": "1051670",
    "end": "1058120"
  },
  {
    "text": "based on your requirement change then you will see that now okay now I have",
    "start": "1058120",
    "end": "1063820"
  },
  {
    "text": "a lot more reliable failure handling cases so I can I can believe now more between source and target tables are in",
    "start": "1063820",
    "end": "1071290"
  },
  {
    "text": "a in a sink at least for the incoming requests but still the missing point is",
    "start": "1071290",
    "end": "1077290"
  },
  {
    "text": "here how we handle the legacy data that has not been touched by the product travel yet so we actually have to offer",
    "start": "1077290",
    "end": "1084940"
  },
  {
    "start": "1083000",
    "end": "1355000"
  },
  {
    "text": "end data migration this is more like a one-time stuff if there is ideal but you can just run multiple times as you want",
    "start": "1084940",
    "end": "1090940"
  },
  {
    "text": "but this offering magazine essentially what they do is scanning through entire",
    "start": "1090940",
    "end": "1096460"
  },
  {
    "text": "search table or data applying the data transformation in a batch way pushing",
    "start": "1096460",
    "end": "1102250"
  },
  {
    "text": "out to your target table so again the one of the key things here is from the",
    "start": "1102250",
    "end": "1108580"
  },
  {
    "text": "Opera migration you might see the failure to we cannot ignore them how can we link them then you can just reusing",
    "start": "1108580",
    "end": "1114910"
  },
  {
    "text": "existing features and then simply just sending those failure case to the queue then you can imagine now you don't",
    "start": "1114910",
    "end": "1121210"
  },
  {
    "text": "really have to worry about any of the failed cases all of those failed case like store in the queue will be",
    "start": "1121210",
    "end": "1126820"
  },
  {
    "text": "automatically caught up and then eventually you will see their updates in the target table so one more key a key",
    "start": "1126820",
    "end": "1134620"
  },
  {
    "text": "point I really want to emphasize here is often you might need to move your data not only within the same BTC in AWS you",
    "start": "1134620",
    "end": "1142360"
  },
  {
    "text": "might need to move your data center to your V PC or some other outside vendor to then we can probably set up the data",
    "start": "1142360",
    "end": "1148900"
  },
  {
    "text": "connect to speed up and then reduce the latency and then make more reliable for a taster now we can see that now like",
    "start": "1148900",
    "end": "1158320"
  },
  {
    "text": "after the running the software migration all of those data including offering Las Vegas data and then incoming data are in",
    "start": "1158320",
    "end": "1165310"
  },
  {
    "text": "sync how do we validate them in the beginning we thought maybe offering",
    "start": "1165310",
    "end": "1172030"
  },
  {
    "text": "validation might be good enough what that means is we just like going to entire search table and then fetch into",
    "start": "1172030",
    "end": "1179110"
  },
  {
    "text": "the target table from the target stores new stores and they really compare then the check what is the ratio of being",
    "start": "1179110",
    "end": "1185590"
  },
  {
    "text": "consensus and so forth this is great in terms of static way you actually go through entire data",
    "start": "1185590",
    "end": "1191650"
  },
  {
    "text": "regardless of whether there is access or not just like checking order data and then see how it works",
    "start": "1191650",
    "end": "1197389"
  },
  {
    "text": "but we actually realized one problems in doing these migrations what happened",
    "start": "1197389",
    "end": "1203869"
  },
  {
    "text": "here is we actually had a small bug in for Christ's logic it actually keep interesting noise on the real data and",
    "start": "1203869",
    "end": "1210950"
  },
  {
    "text": "it was we built a lot later not a later time so if you just rely on this",
    "start": "1210950",
    "end": "1216259"
  },
  {
    "text": "offering validation at one time with a snapshot version you might not be rebuild for that so okay what is the",
    "start": "1216259",
    "end": "1224839"
  },
  {
    "text": "good way to actually resolve that then so we introduced either old line validation on top same way we're",
    "start": "1224839",
    "end": "1231589"
  },
  {
    "text": "actually turning on the for creed that means still this is shredder operation just reading additionally from the",
    "start": "1231589",
    "end": "1236929"
  },
  {
    "text": "target table based on the prod traffic we really compared the data and then making sure the server data from the",
    "start": "1236929",
    "end": "1243829"
  },
  {
    "text": "target table is ready to go so this is",
    "start": "1243829",
    "end": "1248929"
  },
  {
    "text": "really good in terms of catching the dynamic changes that is currently happening the real data in specific",
    "start": "1248929",
    "end": "1255320"
  },
  {
    "text": "target table and you will see this both combinational offline and online",
    "start": "1255320",
    "end": "1260329"
  },
  {
    "text": "validation is really capturing all those aspects of static and dynamic validation",
    "start": "1260329",
    "end": "1265429"
  },
  {
    "text": "purposes one caveat here is focus for",
    "start": "1265429",
    "end": "1270469"
  },
  {
    "text": "cooperation is great but it's not free again you have to maintain that additional logic and they really have to",
    "start": "1270469",
    "end": "1276409"
  },
  {
    "text": "run them that requires additional resource consumption so what we usually do is we controlling this traffic with",
    "start": "1276409",
    "end": "1284329"
  },
  {
    "text": "acidic roster days supporting from the OP scheme contained either gradually how",
    "start": "1284329",
    "end": "1289519"
  },
  {
    "text": "much traffic you want to sending and then fetching the data so we gradually turning on the fork read while carefully",
    "start": "1289519",
    "end": "1295969"
  },
  {
    "text": "monitoring the stats in apps so that we don't really interrupt any of the product or a tion ongoing and also at",
    "start": "1295969",
    "end": "1301549"
  },
  {
    "text": "the same time we actually handle this olá invalidation in a more selective way like why do you need to value the",
    "start": "1301549",
    "end": "1307820"
  },
  {
    "text": "wonder-percent if we just believe this is a good and we can probably turn it on 10% validation rate only and the sec see",
    "start": "1307820",
    "end": "1313519"
  },
  {
    "text": "how it goes another key thing is it during the validation is you really have to define",
    "start": "1313519",
    "end": "1320089"
  },
  {
    "text": "your success metrics very very definite way they are usually have to be",
    "start": "1320089",
    "end": "1326239"
  },
  {
    "text": "measurable and then quantifiable exempt of the validation success match we'll be related sequences how how fast",
    "start": "1326239",
    "end": "1334039"
  },
  {
    "text": "you should be or what about the error rate you might see what about cost reduction do I want to expect to see",
    "start": "1334039",
    "end": "1340159"
  },
  {
    "text": "something like that so once you actually match up with your own success metrics",
    "start": "1340159",
    "end": "1346639"
  },
  {
    "text": "once you feel good okay I'm ready to go then you actually enter the final stage we actually cut the core of a code so we",
    "start": "1346639",
    "end": "1355730"
  },
  {
    "text": "handle this code of traffic with a lot more careful but in the same way so",
    "start": "1355730",
    "end": "1361309"
  },
  {
    "text": "we're actually gradually sending new traffic's let's say I'm percent of traffic to the target table now you can",
    "start": "1361309",
    "end": "1368419"
  },
  {
    "text": "imagine all those data served would imprison traffic from the target table",
    "start": "1368419",
    "end": "1375429"
  },
  {
    "text": "this is great once you have a great extent of the validation in the previous",
    "start": "1375429",
    "end": "1380659"
  },
  {
    "text": "steps you might be okay with that so we really just extremely turn it on the",
    "start": "1380659",
    "end": "1385850"
  },
  {
    "text": "card over and then see how he goes over time and it actually we realized he was",
    "start": "1385850",
    "end": "1391399"
  },
  {
    "text": "not that good enough the reason being is sometimes the issue again is not",
    "start": "1391399",
    "end": "1397639"
  },
  {
    "text": "immediately popped up we extensively validated for certain time but later we found one of the edge",
    "start": "1397639",
    "end": "1406250"
  },
  {
    "text": "cases that is actually happening right after Carrabba and he was not going to be billed for weeks then what should we",
    "start": "1406250",
    "end": "1412580"
  },
  {
    "text": "do and it actually happened to us too in two weeks for instance one of the other",
    "start": "1412580",
    "end": "1417919"
  },
  {
    "text": "purchased team actually asked us hey this data looks a little weird what's going on and we start investigating oh",
    "start": "1417919",
    "end": "1424159"
  },
  {
    "text": "god there was some some logic errors and it was really hard to find because there",
    "start": "1424159",
    "end": "1429919"
  },
  {
    "text": "was a really educators but we cannot really even know them so we're just thinking about okay maybe we have to be",
    "start": "1429919",
    "end": "1436539"
  },
  {
    "text": "coming up with some more low back plans for that so that's where we actually setting up this the reusing basically",
    "start": "1436539",
    "end": "1443990"
  },
  {
    "text": "did a cue and then still turning on the fork right even under the collarbone mode so that you can imagine these two",
    "start": "1443990",
    "end": "1451159"
  },
  {
    "text": "data stores are completely in sync between source and targets over time and then great thing is you can actually",
    "start": "1451159",
    "end": "1458360"
  },
  {
    "text": "reuse all of those existing resources as they are you don't have to rebuild anything",
    "start": "1458360",
    "end": "1464210"
  },
  {
    "text": "anything you need to change is just change the data transformation and then source an end target point and creating",
    "start": "1464210",
    "end": "1472880"
  },
  {
    "text": "here is once you have all this ready then you can actually roll back and proceeding cut over based on your",
    "start": "1472880",
    "end": "1479560"
  },
  {
    "text": "confidence and progress level and then you can really control like okay how quickly I want to go and eventually once",
    "start": "1479560",
    "end": "1487280"
  },
  {
    "text": "you feel all the validation is success from the record over even we can actually cutting over 100% and declare",
    "start": "1487280",
    "end": "1493730"
  },
  {
    "text": "the victory and then you are now ready to tear down the resources so this is",
    "start": "1493730",
    "end": "1500420"
  },
  {
    "text": "again capturing the overall migration frame we handle that you know higher level level visual level so there are",
    "start": "1500420",
    "end": "1508700"
  },
  {
    "text": "much more the detailed challenges and then the implementation details you can actually share that again feel free to",
    "start": "1508700",
    "end": "1515360"
  },
  {
    "text": "talk to me if you are interested to hear more so that'll be great to share that",
    "start": "1515360",
    "end": "1521200"
  },
  {
    "start": "1522000",
    "end": "1862000"
  },
  {
    "text": "based on that the migration framework so so far we discussed about the other challenges what we are seeing from this",
    "start": "1522160",
    "end": "1529160"
  },
  {
    "text": "data migration why there is important why there is hard what we want to achieve how did we achieve what did we",
    "start": "1529160",
    "end": "1536630"
  },
  {
    "text": "learn from it before getting into the key learning points I will actually share clicks that's what we achieved by",
    "start": "1536630",
    "end": "1544760"
  },
  {
    "text": "the way for the clarification this is only covering the the Hmong go to dynamo migration case so this is not including",
    "start": "1544760",
    "end": "1551570"
  },
  {
    "text": "all the other migration we are currently handling so we moved the the total data",
    "start": "1551570",
    "end": "1556760"
  },
  {
    "text": "size more than 25 billion actually close to 30 terabytes the data from mango to",
    "start": "1556760",
    "end": "1562700"
  },
  {
    "text": "dynamo and essentially we actually achieved a cost reduction more than by",
    "start": "1562700",
    "end": "1568010"
  },
  {
    "text": "sixty percent that means simply moving your data more if optimizing data model",
    "start": "1568010",
    "end": "1573620"
  },
  {
    "text": "little bit on top massaging them you only paying less than 40 percent of cost compared to the previous situation this",
    "start": "1573620",
    "end": "1580070"
  },
  {
    "text": "is great so you can also utilizing the auto scaling and reserve capacity again",
    "start": "1580070",
    "end": "1585890"
  },
  {
    "text": "the resource capacity is more like a reserved instance concept is just like pay upfront fee for minimum usage level",
    "start": "1585890",
    "end": "1592070"
  },
  {
    "text": "you actually define and just like paying with a significant reduce the cost for project report",
    "start": "1592070",
    "end": "1597860"
  },
  {
    "text": "so you can essentially utilizing these to conceive in a combination way and achieve a lot higher cost reduction more",
    "start": "1597860",
    "end": "1605950"
  },
  {
    "text": "in terms of orphans gain really we actually studied the read and then write it's really very consistent in terms of",
    "start": "1605950",
    "end": "1614000"
  },
  {
    "text": "the porphyrin scale and then single it is in milliseconds for most of our case one caveat here is Dinamo is great when",
    "start": "1614000",
    "end": "1623450"
  },
  {
    "text": "you scale the data while keeping the data size consistent or concise what",
    "start": "1623450",
    "end": "1629120"
  },
  {
    "text": "that means is it really matters more item size that you're actually maintaining not really the data scale",
    "start": "1629120",
    "end": "1635090"
  },
  {
    "text": "you need to store you will see the same consistent level of the performance when",
    "start": "1635090",
    "end": "1640309"
  },
  {
    "text": "you have 100 items versus 3 3 billions of data but if your item size is 1 K",
    "start": "1640309",
    "end": "1647570"
  },
  {
    "text": "versus 400 K there is a limit of dynamodb that will be impacting your performances but obviously it's",
    "start": "1647570",
    "end": "1652730"
  },
  {
    "text": "inevitable you will see the same thing in all the different data stores so just keep in mind that's a great thing is you",
    "start": "1652730",
    "end": "1658820"
  },
  {
    "text": "actually need to keep for learning part",
    "start": "1658820",
    "end": "1665029"
  },
  {
    "text": "I would probably break down into three sessions before studying the migration what we want to new are no organ as I",
    "start": "1665029",
    "end": "1673399"
  },
  {
    "text": "mentioned that the first thing you really need to understand what's the situation what's the limitation you're actually seeing in the source type data",
    "start": "1673399",
    "end": "1679399"
  },
  {
    "text": "stores you want to migrate and then what's the the potential Target stores",
    "start": "1679399",
    "end": "1685880"
  },
  {
    "text": "you want to use what's the difference in this case so for instance in our case we",
    "start": "1685880",
    "end": "1691039"
  },
  {
    "text": "actually look into the monger and dynamo specifically see how it works it sounds",
    "start": "1691039",
    "end": "1696139"
  },
  {
    "text": "very similar at the higher level but indeed when you actually dig into more you will see many different assumption",
    "start": "1696139",
    "end": "1702769"
  },
  {
    "text": "differences it's very impressive there is sometimes a very problematic so as an",
    "start": "1702769",
    "end": "1709279"
  },
  {
    "text": "example for instance when you actually build the app services all of the API is accessing the exactly same way regards",
    "start": "1709279",
    "end": "1716750"
  },
  {
    "text": "the data stores and it turned out the way to actually handle updates and partial update delete and create is very",
    "start": "1716750",
    "end": "1724159"
  },
  {
    "text": "different between one way and dynamo any study coding issue although we keep the same data model",
    "start": "1724159",
    "end": "1730640"
  },
  {
    "text": "so that's just one simple example but you will see there are many different underlying differences you need to",
    "start": "1730640",
    "end": "1735710"
  },
  {
    "text": "understand first what you need to be prepared to change in your absolute here and obviously again this data migration",
    "start": "1735710",
    "end": "1744650"
  },
  {
    "text": "is a great opportunity to optimize data model and then schema particularly in dynamo one of the key things you need to",
    "start": "1744650",
    "end": "1751790"
  },
  {
    "text": "consider is the key design so hash plus range key that is a primary key",
    "start": "1751790",
    "end": "1757520"
  },
  {
    "text": "virtually maintained or partisan clearance or key what would be the best",
    "start": "1757520",
    "end": "1762559"
  },
  {
    "text": "way to distribute your data in a more even way well really good design for",
    "start": "1762559",
    "end": "1769250"
  },
  {
    "text": "collaborative conducts you want to maintain what computer what all of the data you want to project to the global",
    "start": "1769250",
    "end": "1776179"
  },
  {
    "text": "second index table from the main table really depending on just one decision for that you will determine your entire",
    "start": "1776179",
    "end": "1782809"
  },
  {
    "text": "cost and performance of all as a design program GSI in general we just protect",
    "start": "1782809",
    "end": "1788900"
  },
  {
    "text": "the entire field into the GSI table what happening is whenever you write",
    "start": "1788900",
    "end": "1794150"
  },
  {
    "text": "something in your main table all of those change will be propagated to the GSI unnecessarily although you don't",
    "start": "1794150",
    "end": "1799669"
  },
  {
    "text": "need that data then it's actually multiply n times of the cost for the",
    "start": "1799669",
    "end": "1804710"
  },
  {
    "text": "writing depending on the number of GS are you actually maintaining another",
    "start": "1804710",
    "end": "1810620"
  },
  {
    "text": "thing is the dynamo really supported us the schema is that's great and if you",
    "start": "1810620",
    "end": "1816890"
  },
  {
    "text": "can't restore different types of data over time we all will have to change too much but at the same time if you don't",
    "start": "1816890",
    "end": "1822679"
  },
  {
    "text": "really carefully design the schema enforcement from your server side you might lose the ability to track down the",
    "start": "1822679",
    "end": "1829070"
  },
  {
    "text": "quality of the data over time so this is something you also have to keep in mind okay what is a good design of the data",
    "start": "1829070",
    "end": "1836150"
  },
  {
    "text": "model and specifically design match up trying to match up with your data access",
    "start": "1836150",
    "end": "1841429"
  },
  {
    "text": "patterns for coming from real traffic and lastly again we really need to",
    "start": "1841429",
    "end": "1848030"
  },
  {
    "text": "carefully define success metrics in more quantified way and that will be the key",
    "start": "1848030",
    "end": "1853970"
  },
  {
    "text": "to evaluate your overall migration efforts and then decide whether you are",
    "start": "1853970",
    "end": "1859730"
  },
  {
    "text": "good to go once you are ready again then Bey defined success metrics we really want",
    "start": "1859730",
    "end": "1867500"
  },
  {
    "text": "to evaluate the entire migration in a very careful way and in our case it",
    "start": "1867500",
    "end": "1873140"
  },
  {
    "text": "turned out this two-way extended data validation including online and offline works really well and then key here is",
    "start": "1873140",
    "end": "1881270"
  },
  {
    "text": "you have to make a framework that is allowing you to validate over time multiple times whenever you need another",
    "start": "1881270",
    "end": "1888590"
  },
  {
    "text": "thing is whenever you do the validation you have to be prepared to collect all",
    "start": "1888590",
    "end": "1894169"
  },
  {
    "text": "the metrics coming from that so we actually helps get a lot of help from ops team to actually set up level",
    "start": "1894169",
    "end": "1900679"
  },
  {
    "text": "metrics tracking in the logging system all those values are coming in and this",
    "start": "1900679",
    "end": "1906590"
  },
  {
    "text": "validation I can actually confidently believe okay we are ready in terms of the objective value actually seeing from",
    "start": "1906590",
    "end": "1913340"
  },
  {
    "text": "the traffic another thing is the failure",
    "start": "1913340",
    "end": "1918650"
  },
  {
    "text": "can happen anytime point during the migration procedure you really have to",
    "start": "1918650",
    "end": "1923990"
  },
  {
    "text": "plan for failures and design the system to overcome or mitigate those impacts",
    "start": "1923990",
    "end": "1932230"
  },
  {
    "text": "again the one of the example that I mentioned earlier is in the corner bar we didn't really consider about the sync",
    "start": "1932320",
    "end": "1937970"
  },
  {
    "text": "between source and target table because we believe we are now ready to cut over just to switch the traffic over time to",
    "start": "1937970",
    "end": "1944510"
  },
  {
    "text": "the target table you'll be good sometimes we have a in a hurry sometimes",
    "start": "1944510",
    "end": "1950690"
  },
  {
    "text": "or overconfidence we don't really want to do that so we really come up with the",
    "start": "1950690",
    "end": "1956630"
  },
  {
    "text": "systematic way to mitigate those failures as long as we have we are prepared you should be okay so you don't",
    "start": "1956630",
    "end": "1962570"
  },
  {
    "text": "really have to worry about the failures then you can actually going back and porce a little bit just controlling your",
    "start": "1962570",
    "end": "1967820"
  },
  {
    "text": "schedule and pace a little bit and then you can still achieve the same goal once",
    "start": "1967820",
    "end": "1974510"
  },
  {
    "start": "1973000",
    "end": "2113000"
  },
  {
    "text": "you are done with the migration reach to the 100% cover is not done yet what is the follow-up you really need to set up",
    "start": "1974510",
    "end": "1981049"
  },
  {
    "text": "the data backup correctly fortunately the in AWS we were able to use AWS",
    "start": "1981049",
    "end": "1986270"
  },
  {
    "text": "Amazon data pipeline to set up the export import to s3 using EMR from the",
    "start": "1986270",
    "end": "1992390"
  },
  {
    "text": "dynamo Bay Inn based on some like given frequency but now you have",
    "start": "1992390",
    "end": "1997910"
  },
  {
    "text": "to use many of the backup service Lee from dynamo - which is great so you don't really worry about the backup",
    "start": "1997910",
    "end": "2004240"
  },
  {
    "text": "anymore and as long as you actually push stuff to dynamo you have all the backups whenever you need based on your",
    "start": "2004240",
    "end": "2011080"
  },
  {
    "text": "frequency and requirement at the same time you can actually turn on the streams whenever you want to pushed out",
    "start": "2011080",
    "end": "2016660"
  },
  {
    "text": "those changes and synchronize update in two different air stores another big",
    "start": "2016660",
    "end": "2023620"
  },
  {
    "text": "shout to Dogs team is they actually start to actually apply CloudFormation I am in throughout this migration",
    "start": "2023620",
    "end": "2030850"
  },
  {
    "text": "procedure we actually like prefer a click away in in general engineers it's",
    "start": "2030850",
    "end": "2036040"
  },
  {
    "text": "like I want to create the table in using CRI and then console why do we need to care about the cloud formation but it's",
    "start": "2036040",
    "end": "2042310"
  },
  {
    "text": "not true once you start the cloud formation you actually have a lot more ability to control your history of the",
    "start": "2042310",
    "end": "2050409"
  },
  {
    "text": "changes of the dynamic table conjuring the problem through P in a more systematic way and then you can actually",
    "start": "2050410",
    "end": "2055629"
  },
  {
    "text": "build whenever you need that in the exactly same way based on DSL another",
    "start": "2055630",
    "end": "2061419"
  },
  {
    "text": "thing is you can actually utilize I am for controlling the accessibility this",
    "start": "2061419",
    "end": "2066639"
  },
  {
    "text": "is great because not only just like controlling you're making entire apps more secured but at the same time use",
    "start": "2066640",
    "end": "2073870"
  },
  {
    "text": "preset which services can talk to which table then based on the information you",
    "start": "2073870",
    "end": "2079270"
  },
  {
    "text": "can understand TEDx pattern a lot better way let's say I only had to have the",
    "start": "2079270",
    "end": "2084550"
  },
  {
    "text": "except Iran service a and B and C talking to Table one then when I actually underlies table",
    "start": "2084550",
    "end": "2090909"
  },
  {
    "text": "one data access pattern I only need to talk about service a and PN C that's it you only need to understand the QP s",
    "start": "2090910",
    "end": "2097630"
  },
  {
    "text": "coming from those third services I don't really have to worry about some other cases because they will reject it lastly",
    "start": "2097630",
    "end": "2105820"
  },
  {
    "text": "don't forget to tear down resources once you're done so this is great for releasing your cost there are more",
    "start": "2105820",
    "end": "2114550"
  },
  {
    "start": "2113000",
    "end": "2279000"
  },
  {
    "text": "learning points but we just like summarized it for the sake of time but again we'll be happy to share more over",
    "start": "2114550",
    "end": "2120250"
  },
  {
    "text": "time as we time allows I also want to cover some of the best practices we",
    "start": "2120250",
    "end": "2126790"
  },
  {
    "text": "actually observed from the DynamoDB there are many different best practices but I would just like focus on one thing",
    "start": "2126790",
    "end": "2134079"
  },
  {
    "text": "how do you want to maintain or many's dynamic triplets over time this is",
    "start": "2134079",
    "end": "2139849"
  },
  {
    "text": "really hard problem we often just using the word scaling that's great for predictable data",
    "start": "2139849",
    "end": "2147940"
  },
  {
    "text": "attributable tract parents case but sometimes you cannot really control your",
    "start": "2147940",
    "end": "2153859"
  },
  {
    "text": "data access pattern from real world or real user cases and even for us we",
    "start": "2153859",
    "end": "2160069"
  },
  {
    "text": "actually see a lot of spiky pattern of traffic coming in or completely unpredictable access panel might happen",
    "start": "2160069",
    "end": "2165680"
  },
  {
    "text": "at some point and in that case autoscale is not good enough because usually that",
    "start": "2165680",
    "end": "2171170"
  },
  {
    "text": "is happening in reactive manner they try to catch up after the fact if you see",
    "start": "2171170",
    "end": "2177529"
  },
  {
    "text": "the changes very gradually over time the sort of scaling works really good you don't really have to worry about too",
    "start": "2177529",
    "end": "2183200"
  },
  {
    "text": "much but imagine your traffic pattern changes to sharp and then too abrupt",
    "start": "2183200",
    "end": "2189740"
  },
  {
    "text": "then this little screen never catching up those changes then you will continually see the problems from harsh",
    "start": "2189740",
    "end": "2195470"
  },
  {
    "text": "art and then total requests one way to solve that is really set high problem",
    "start": "2195470",
    "end": "2201140"
  },
  {
    "text": "throughput I don't care then it will cost a lot so it's not",
    "start": "2201140",
    "end": "2206150"
  },
  {
    "text": "really ideal case so this hotshot issue is one of the critical points caused by",
    "start": "2206150",
    "end": "2212569"
  },
  {
    "text": "auto scaling or access pattern at the same time that the key design you actually premium as I mentioned earlier",
    "start": "2212569",
    "end": "2220789"
  },
  {
    "text": "the key design means a primary key design of the hash key and range key combination is the key thing is how to",
    "start": "2220789",
    "end": "2227420"
  },
  {
    "text": "control distribution of the data across the physical partitions in dynamodb but",
    "start": "2227420",
    "end": "2234400"
  },
  {
    "text": "ideally speaking or practically speaking it's not possible to measure perfectly it based on the data access pattern you",
    "start": "2234400",
    "end": "2240980"
  },
  {
    "text": "might not even see yet I mean you might be able to come up with or imagine based on predictions looking at the history",
    "start": "2240980",
    "end": "2248240"
  },
  {
    "text": "data maybe this might be happening in terms of traffic patterns I might be able to distribute the data in that",
    "start": "2248240",
    "end": "2253519"
  },
  {
    "text": "sense or what happened that is changing again it's not the easy to change the key setup so obviously we will see the",
    "start": "2253519",
    "end": "2261349"
  },
  {
    "text": "harsher issue inevitable way that actually means you actually start",
    "start": "2261349",
    "end": "2266490"
  },
  {
    "text": "seeing the truth to request that actually degrade your performance a lot and eventually you will start seeing the",
    "start": "2266490",
    "end": "2271559"
  },
  {
    "text": "errors and that is actually coming from both read and write and this is",
    "start": "2271559",
    "end": "2277230"
  },
  {
    "text": "something we actually suggest for read case let's say your service is suddenly",
    "start": "2277230",
    "end": "2282329"
  },
  {
    "start": "2279000",
    "end": "2328000"
  },
  {
    "text": "just like we're sending the request to that I know I really hey give me the all the data I need them right now and that",
    "start": "2282329",
    "end": "2289020"
  },
  {
    "text": "actually cause the harsher issue then you can actually maintain additional cash layer in between you can be",
    "start": "2289020",
    "end": "2295289"
  },
  {
    "text": "anything this is just example it can be Dax it can be a less cash you can be combination of them and this sketch",
    "start": "2295289",
    "end": "2303030"
  },
  {
    "text": "layer choice is really depending on your requirement and imagine once you have",
    "start": "2303030",
    "end": "2309030"
  },
  {
    "text": "this additional cash layer most of the the hot data you will most frequently access there's already cashed then there",
    "start": "2309030",
    "end": "2316920"
  },
  {
    "text": "is actually covered by cash most of the cases and you only need to send down the cash miss traffic to the dynamodb and",
    "start": "2316920",
    "end": "2323480"
  },
  {
    "text": "you only need to stay really low problem throughput on it let me break down the",
    "start": "2323480",
    "end": "2329789"
  },
  {
    "start": "2328000",
    "end": "2629000"
  },
  {
    "text": "some of these cases how we actually tries them war let's say I really want",
    "start": "2329789",
    "end": "2334950"
  },
  {
    "text": "to get fastest speed for weed but I'm okay maintaining my cash logic in you",
    "start": "2334950",
    "end": "2340470"
  },
  {
    "text": "know side then less cash will be the best way you can imagine I start to less",
    "start": "2340470",
    "end": "2346319"
  },
  {
    "text": "cash from your service side you actually whenever you receive the real crash send them crashed Alaskans first once you",
    "start": "2346319",
    "end": "2353609"
  },
  {
    "text": "cash it in just return it if not now we are sending back to the DynamoDB that's",
    "start": "2353609",
    "end": "2358680"
  },
  {
    "text": "for back search once you're faster data you back view in the return it",
    "start": "2358680",
    "end": "2364130"
  },
  {
    "text": "one thing we observed that in practice is less cash is really showing very very",
    "start": "2364130",
    "end": "2370470"
  },
  {
    "text": "good performances regardless of their size for example in most of cases in our",
    "start": "2370470",
    "end": "2375809"
  },
  {
    "text": "data P even ninety latency was around among one Billy seconds it's great the",
    "start": "2375809",
    "end": "2381660"
  },
  {
    "text": "very consistent but obviously the downside here is you have to maintain",
    "start": "2381660",
    "end": "2387510"
  },
  {
    "text": "your own cash handling logic in your service side which is bugging so what we",
    "start": "2387510",
    "end": "2392819"
  },
  {
    "text": "want to do if I want don't want to do that so another use case is coming in this way",
    "start": "2392819",
    "end": "2398190"
  },
  {
    "text": "I still want to speed up the read compared to the dynamic speed but I don't really want to maintain a",
    "start": "2398190",
    "end": "2403830"
  },
  {
    "text": "additional logic then that should be the best case for that one thing in GA",
    "start": "2403830",
    "end": "2411420"
  },
  {
    "text": "version of Dex is really you don't have to change anything you just need to setup the Dex cluster and set the the",
    "start": "2411420",
    "end": "2419310"
  },
  {
    "text": "configurations of endpoint of Dex in your dynamo SDK just accessing in the",
    "start": "2419310",
    "end": "2424440"
  },
  {
    "text": "exactly same way so literally for us we just adding one line and every the other",
    "start": "2424440",
    "end": "2429810"
  },
  {
    "text": "logic is working perfectly as it is so all of them is a very transparent now you can imagine is how the works is",
    "start": "2429810",
    "end": "2436740"
  },
  {
    "text": "internally it's very similar way is actually your central request but implicitly sending to the backs first if",
    "start": "2436740",
    "end": "2442500"
  },
  {
    "text": "there is cache it immediately turn them if not that now we exit sending down to",
    "start": "2442500",
    "end": "2447510"
  },
  {
    "text": "the DynamoDB fallback and like factory and then returning but there is all over all the procedures actually",
    "start": "2447510",
    "end": "2454260"
  },
  {
    "text": "automatically handle by Dex so from your point you don't really need to maintain any of the additional logic",
    "start": "2454260",
    "end": "2460530"
  },
  {
    "text": "which is great but at the same time you can actually achieve the better speed",
    "start": "2460530",
    "end": "2466700"
  },
  {
    "text": "one thing I also want to mention here is elapsed cache index is not exclusive",
    "start": "2467060",
    "end": "2473180"
  },
  {
    "text": "it's really like choice obviously either like how you want how much you want to",
    "start": "2473180",
    "end": "2478500"
  },
  {
    "text": "boost your speed and usage pattern is a quite different",
    "start": "2478500",
    "end": "2483620"
  },
  {
    "text": "also another comparative point between less cache index is price model usually",
    "start": "2483620",
    "end": "2489450"
  },
  {
    "text": "the texts instance is a more expensive compared to large cache for the same size but you don't really need to",
    "start": "2489450",
    "end": "2496680"
  },
  {
    "text": "maintain a specific asset index they just following the same model of the other three availability on the",
    "start": "2496680",
    "end": "2502230"
  },
  {
    "text": "distribution like that only be so you only need to create the size of the",
    "start": "2502230",
    "end": "2507930"
  },
  {
    "text": "instances based on the primary data you actually only need to store then they will handle the duplicates for free as",
    "start": "2507930",
    "end": "2514640"
  },
  {
    "text": "opposed to less cash you have to really maintain Express the orderly percoset if you want to so in general we see huge",
    "start": "2514640",
    "end": "2523470"
  },
  {
    "text": "cost reductions by using the bags as a Priscilla's cache well obviously the down sorry is less",
    "start": "2523470",
    "end": "2529590"
  },
  {
    "text": "cases faster index so again just keep their mind and then see what is the best requirement and",
    "start": "2529590",
    "end": "2536110"
  },
  {
    "text": "then you just case it for you and that's how you actually go",
    "start": "2536110",
    "end": "2541470"
  },
  {
    "text": "what about I want to get either the read in a fascist way but I also want to",
    "start": "2541620",
    "end": "2547860"
  },
  {
    "text": "speed up the backfield as well this is like one simple case I just demonstrated but you can find many more different",
    "start": "2547860",
    "end": "2554800"
  },
  {
    "text": "combinations you can actually hit this cache now you only you also need to",
    "start": "2554800",
    "end": "2561190"
  },
  {
    "text": "maintain your position your left side but in this case even for the cache miss",
    "start": "2561190",
    "end": "2566320"
  },
  {
    "text": "case you can even split up then really depending on what it cache hit rate in",
    "start": "2566320",
    "end": "2572050"
  },
  {
    "text": "your system let's say 50% of cashy rate now the rest of the 50 percent cache miss case was really slow previously but",
    "start": "2572050",
    "end": "2578980"
  },
  {
    "text": "now he was automatically boosted by decks so again as a recap you actually",
    "start": "2578980",
    "end": "2584320"
  },
  {
    "text": "hit a less cash from your business logic returning if the cache hit if the cache miss now you're actually talking to",
    "start": "2584320",
    "end": "2590140"
  },
  {
    "text": "dynamodb through the decks end point then you actually have a two layers of",
    "start": "2590140",
    "end": "2595330"
  },
  {
    "text": "data cache then eventually what you really see in the Dynamo is really nothing then you only need to set really",
    "start": "2595330",
    "end": "2604420"
  },
  {
    "text": "really small problem troopers that's how you can also save the cost again this is",
    "start": "2604420",
    "end": "2610480"
  },
  {
    "text": "kind of demonstrated use cases we just want to share but you can imagine how different basically how you have to",
    "start": "2610480",
    "end": "2617380"
  },
  {
    "text": "define this configuration will be less the clusters or systems you can achieve a lot different the goals and then the",
    "start": "2617380",
    "end": "2625870"
  },
  {
    "text": "divorce for car coming from that so so far we actually talk about a real",
    "start": "2625870",
    "end": "2631150"
  },
  {
    "start": "2629000",
    "end": "2830000"
  },
  {
    "text": "hotshot what about great hash art in typical this is more critical problems because",
    "start": "2631150",
    "end": "2637900"
  },
  {
    "text": "although you set the eventual consistency setup in your dynamo table the right cost is 20 times more",
    "start": "2637900",
    "end": "2643810"
  },
  {
    "text": "expensive than we so like usually although you set that really really high for them to put on",
    "start": "2643810",
    "end": "2649750"
  },
  {
    "text": "read it's not dominating compared to the right cost so let's say app service is",
    "start": "2649750",
    "end": "2657790"
  },
  {
    "text": "accessed are sending the massive rights for whatever reason it can be bought you can be spam it can be completely unexpected data trend tax",
    "start": "2657790",
    "end": "2664420"
  },
  {
    "text": "parents study hammering out the Dino DBE what should I do again you can actually set really high protein throughput to overcome but",
    "start": "2664420",
    "end": "2671349"
  },
  {
    "text": "that's really costly and ineffective so this isn't one way you can actually handle that as soon as you just start",
    "start": "2671349",
    "end": "2679150"
  },
  {
    "text": "receiving those massive requests in the right side you can sending those requests and redirect into the queue and",
    "start": "2679150",
    "end": "2685089"
  },
  {
    "text": "you can actually maintain your own Walker set it can be again in case a worker it can be just regular worker",
    "start": "2685089",
    "end": "2690190"
  },
  {
    "text": "consuming the message from SQL queue it can be lambda function it's really your",
    "start": "2690190",
    "end": "2695500"
  },
  {
    "text": "choice but keep in mind if you want to maintain your own work on ec2 please",
    "start": "2695500",
    "end": "2700510"
  },
  {
    "text": "consider using spot instances that's the best practice you actually can save cost more but obviously that means your",
    "start": "2700510",
    "end": "2707380"
  },
  {
    "text": "operation should be I didn't put it in whenever you repeat them you should be able to recover them as it is and the Q",
    "start": "2707380",
    "end": "2715510"
  },
  {
    "text": "side I just showed that as ICS but you can just choose dynamo DB it can be kinases it's really up to you one",
    "start": "2715510",
    "end": "2723849"
  },
  {
    "text": "important thing here is then why not just like using this everywhere it's not",
    "start": "2723849",
    "end": "2730470"
  },
  {
    "text": "because usually this is a synchronous operation is slower than synchronizers in terms of data sync so if you really",
    "start": "2730470",
    "end": "2737619"
  },
  {
    "text": "need real-time consistent relatively speaking then you want to handle in a",
    "start": "2737619",
    "end": "2743589"
  },
  {
    "text": "synchronous way so you really what you what we usually do in practice is your",
    "start": "2743589",
    "end": "2748869"
  },
  {
    "text": "identified the track patterns what's requirement in terms of the speed of the consistency required and then",
    "start": "2748869",
    "end": "2755829"
  },
  {
    "text": "identifies three paths and only allowing is the rate limiting concepts for that",
    "start": "2755829",
    "end": "2761500"
  },
  {
    "text": "particular path rest of cases you can actually apply the same synchronous rights and dynamo we'll be happy with",
    "start": "2761500",
    "end": "2768400"
  },
  {
    "text": "that even with all scary so one message I really want to deliver",
    "start": "2768400",
    "end": "2774519"
  },
  {
    "text": "throughout this simple example is there are many different best practices around",
    "start": "2774519",
    "end": "2779549"
  },
  {
    "text": "but you really need to understand what that actually means on your data set and in your service once you understand",
    "start": "2779549",
    "end": "2787240"
  },
  {
    "text": "fully okay based on this access pattern that this particular path maybe twenty",
    "start": "2787240",
    "end": "2792609"
  },
  {
    "text": "percent of path should we go to this rate limiting eighty percent of the writing is totally fine that gives me on average maybe 80% of problem",
    "start": "2792609",
    "end": "2801560"
  },
  {
    "text": "trooper consumptions or chip that's great same thing happening for the read so in",
    "start": "2801560",
    "end": "2810080"
  },
  {
    "text": "summary we just want to say whenever you you see the hot char this is really hard",
    "start": "2810080",
    "end": "2815750"
  },
  {
    "text": "to avoid you just need to come up with a systematic way to avoid them and",
    "start": "2815750",
    "end": "2820960"
  },
  {
    "text": "obviously if you can come up with the perfect key design that's absolutely great but again it's really tough so",
    "start": "2820960",
    "end": "2831290"
  },
  {
    "start": "2830000",
    "end": "2924000"
  },
  {
    "text": "that's pretty much it that I actually want to share today what I will be",
    "start": "2831290",
    "end": "2836300"
  },
  {
    "text": "covered that you're a higher level today is why massive migration is required what actually means what are the goal of",
    "start": "2836300",
    "end": "2843590"
  },
  {
    "text": "did the property we want to achieve throughout that procedure how we actually achieve that in a modular way and this is what we actually achieved",
    "start": "2843590",
    "end": "2851840"
  },
  {
    "text": "and this is one of the indicator that we actually got that higher level again",
    "start": "2851840",
    "end": "2859070"
  },
  {
    "text": "this is this example like what actually means in real world there are many different indicator we actually need to analyze that but if you step back and",
    "start": "2859070",
    "end": "2866060"
  },
  {
    "text": "then looking at this not just X simply just step you will see the users are",
    "start": "2866060",
    "end": "2871490"
  },
  {
    "text": "getting happy once you actually improve your performance is on the line we didn't change anything what suddenly",
    "start": "2871490",
    "end": "2877460"
  },
  {
    "text": "Abby's getting faster and then responsive then all the rates on the app is immediately fractured that's great to",
    "start": "2877460",
    "end": "2885200"
  },
  {
    "text": "see and at the same time we're in the tinder team we have a lot more freedom",
    "start": "2885200",
    "end": "2890930"
  },
  {
    "text": "to build the features really quickly in a reliable way on top of provide the backend service in",
    "start": "2890930",
    "end": "2897500"
  },
  {
    "text": "their stores then you will actually give back to the users hey this is a great feature we actually built it it was a",
    "start": "2897500",
    "end": "2903350"
  },
  {
    "text": "really reliable way that actually give make more impact on user side it comes back to us so you can understand this",
    "start": "2903350",
    "end": "2910250"
  },
  {
    "text": "ecosystem cycle that's something we actually want to achieve and you will see at at the end of the migration you",
    "start": "2910250",
    "end": "2918350"
  },
  {
    "text": "cannot achieve this the same thing in in different way or your own defined way so",
    "start": "2918350",
    "end": "2926120"
  },
  {
    "start": "2924000",
    "end": "3059000"
  },
  {
    "text": "this is just a one pictures that we actually took from one of the board trips in LA as part of the colleagues the great",
    "start": "2926120",
    "end": "2932960"
  },
  {
    "text": "colleagues be actually working together in off steam - you guys are having too much fun yeah yeah we drink too much the",
    "start": "2932960",
    "end": "2940880"
  },
  {
    "text": "free check out the website as well if you're interesting and I think I'm happy to open up the Q&A I do want to just say",
    "start": "2940880",
    "end": "2948800"
  },
  {
    "text": "one last thing that I think it was a dramatized story that I said oh let's",
    "start": "2948800",
    "end": "2954170"
  },
  {
    "text": "hire joonyoung to do all of this obviously it wasn't himself as a whole boatload of people right there so it's a",
    "start": "2954170",
    "end": "2960140"
  },
  {
    "text": "great team many of them are here today I really want to thank my team they're just so awesome and and it was amazing",
    "start": "2960140",
    "end": "2967490"
  },
  {
    "text": "and last thing is the learnings we share today we actually learned it in the hard way for example we started with one-way",
    "start": "2967490",
    "end": "2974840"
  },
  {
    "text": "data validation of course the data in the original store in the new store were all good and we later learned and the yes the",
    "start": "2974840",
    "end": "2982220"
  },
  {
    "text": "original data is in the new table and some so I think we turned we need to do",
    "start": "2982220",
    "end": "2987860"
  },
  {
    "text": "two-way validation we actually just you know went back to square one and restarted the whole process don't feel",
    "start": "2987860",
    "end": "2994610"
  },
  {
    "text": "bad about it and taste they paint you will need to take a couple try but kind of with conviction with Gela gence",
    "start": "2994610",
    "end": "3000400"
  },
  {
    "text": "with attention to detail you walk out there there's a light at the end of the tunnel",
    "start": "3000400",
    "end": "3006190"
  },
  {
    "text": "so we're opening up for questions and thank you so much for your patience and sitting through the presentation there",
    "start": "3006190",
    "end": "3012700"
  },
  {
    "text": "are two microphones in the hallway so please come back I'll come up form a queue and ask your questions",
    "start": "3012700",
    "end": "3021630"
  },
  {
    "text": "go ahead hey so my question is with the complex queries that you have when you",
    "start": "3029440",
    "end": "3037280"
  },
  {
    "text": "do a MongoDB collection query - DynamoDB table query one to one I mean those",
    "start": "3037280",
    "end": "3045050"
  },
  {
    "text": "queries like require a lot of indices on DynamoDB tables to be matching like one",
    "start": "3045050",
    "end": "3050210"
  },
  {
    "text": "to one yeah so how do you go about designing those like because the more indexes you are it's slower and it costs you more in",
    "start": "3050210",
    "end": "3056570"
  },
  {
    "text": "then oh that's a good question so the one caveat here is dynamo has a",
    "start": "3056570",
    "end": "3063080"
  },
  {
    "start": "3059000",
    "end": "3127000"
  },
  {
    "text": "lot more limitation in terms of index extensibility so in you can actually maintain",
    "start": "3063080",
    "end": "3069320"
  },
  {
    "text": "whatever number of indexes but that's also bad because in duplicity you get the penalty and then user doesn't really",
    "start": "3069320",
    "end": "3076940"
  },
  {
    "text": "recognize that often so keep adding the indexes and getting slower and slower once they print the more data it's",
    "start": "3076940",
    "end": "3083030"
  },
  {
    "text": "getting worse as opposed dynamo they explicitly limit them so what we need to",
    "start": "3083030",
    "end": "3088850"
  },
  {
    "text": "do is analyzing what index set we really need to keep them analyzing do we need",
    "start": "3088850",
    "end": "3094460"
  },
  {
    "text": "to maintain either RSI or GSI migrate them if some of them can be dropped that's great",
    "start": "3094460",
    "end": "3099650"
  },
  {
    "text": "if we still need to support some of the specific join like indexes then you have",
    "start": "3099650",
    "end": "3105230"
  },
  {
    "text": "to flatten the data again across different tables and axis differently when I say validation regards to how you",
    "start": "3105230",
    "end": "3111890"
  },
  {
    "text": "actually physically designed like disparate data you have to or gate again in the final form and then compare so it",
    "start": "3111890",
    "end": "3119600"
  },
  {
    "text": "really like depending on how you actually handle this business logic does it answer your question okay",
    "start": "3119600",
    "end": "3126190"
  },
  {
    "start": "3127000",
    "end": "3325000"
  },
  {
    "text": "joined maria for the thanks for the very impressive session and I work for a",
    "start": "3129410",
    "end": "3134570"
  },
  {
    "text": "semantics for a use of protection we are actually experiencing something very similar but we just started for the data",
    "start": "3134570",
    "end": "3141140"
  },
  {
    "text": "migration from you know relatively traditional store RDS into something",
    "start": "3141140",
    "end": "3148040"
  },
  {
    "text": "like no sicko out there I'm just curious in your migration I would imagine it would take several",
    "start": "3148040",
    "end": "3154100"
  },
  {
    "text": "months right the whole process do you have a need to maintain the data",
    "start": "3154100",
    "end": "3159470"
  },
  {
    "text": "consistency amount those two data stores and what is how you strategically achieve that the",
    "start": "3159470",
    "end": "3165380"
  },
  {
    "text": "answer is absolutely right because we do have a very high requirement that for",
    "start": "3165380",
    "end": "3170900"
  },
  {
    "text": "data consistency it is our users data and we need to keep it you know 100% consistent and that's why we build this",
    "start": "3170900",
    "end": "3177500"
  },
  {
    "text": "two-way data validation and then a gradual cut over and so when is 100% we",
    "start": "3177500",
    "end": "3183500"
  },
  {
    "text": "are all happy and we make we made the cut or if we if you don't mind I'll follow up from there",
    "start": "3183500",
    "end": "3188870"
  },
  {
    "text": "I think those two data data sets that then in pandemic nature so every second",
    "start": "3188870",
    "end": "3194540"
  },
  {
    "text": "because they have like billions of transactions every day so every second day will be different you know I know",
    "start": "3194540",
    "end": "3200630"
  },
  {
    "text": "actually there's also other things out there the the whole thing it's a heterogeneous data store I don't",
    "start": "3200630",
    "end": "3206360"
  },
  {
    "text": "know there's a transaction there out there so what do you factually after you know three weeks please do you have the",
    "start": "3206360",
    "end": "3214190"
  },
  {
    "text": "confidence do you think yes we do online validation it was an offline validation that all my malady she means every read",
    "start": "3214190",
    "end": "3222020"
  },
  {
    "text": "and write comes in and we query both store store regional and the new and and",
    "start": "3222020",
    "end": "3227630"
  },
  {
    "text": "we have a system that says score it's 100% it's green and triage shares that's",
    "start": "3227630",
    "end": "3233410"
  },
  {
    "text": "service is fully instrumented so we do have the confidence the online once you",
    "start": "3233410",
    "end": "3239540"
  },
  {
    "text": "hit actually the real trance d2 traffic where in one time what if actually you",
    "start": "3239540",
    "end": "3244670"
  },
  {
    "text": "will have your another M percentage of them they are not actually touched for",
    "start": "3244670",
    "end": "3249740"
  },
  {
    "text": "six months so how do you know they're in sync so that's the cover by offering validation that's why we need both so if",
    "start": "3249740",
    "end": "3256910"
  },
  {
    "text": "you for the offline ones do you iterate through every every data every day that is it so you have a way to either waited",
    "start": "3256910",
    "end": "3263570"
  },
  {
    "text": "and without any action so this is exactly that's more like off Ranger we really invested in the validation",
    "start": "3263570",
    "end": "3270560"
  },
  {
    "text": "service we're basically building your service just to do this and of course after you invested in this and now we",
    "start": "3270560",
    "end": "3276860"
  },
  {
    "text": "feel free to wear free different migration or we can migrate with confidence with you and it's very",
    "start": "3276860",
    "end": "3283250"
  },
  {
    "text": "agnostic to the you know either it's from to dynamo or whatever from you know one destination to another",
    "start": "3283250",
    "end": "3290500"
  },
  {
    "text": "that that you can do that I wouldn't imagine actually there's also detail where did offline validation out there",
    "start": "3290500",
    "end": "3296230"
  },
  {
    "text": "at the very moment you know there's a life of traffic eating one outfit actually they're different at a moment",
    "start": "3296230",
    "end": "3301450"
  },
  {
    "text": "so you will see okay you know actually I have one data here and I don't have this exactly dated there but maybe you're",
    "start": "3301450",
    "end": "3308110"
  },
  {
    "text": "after five seconds you go back and look at them they're now the same yeah the eventual consistency you deal with all",
    "start": "3308110",
    "end": "3314950"
  },
  {
    "text": "those things okay sure but for us it's not five seconds I mean that's too long yeah that's only within milliseconds it",
    "start": "3314950",
    "end": "3321550"
  },
  {
    "text": "will be consistent repeat multiple times for the values and not only one time it's like making sure we actually see",
    "start": "3321550",
    "end": "3328810"
  },
  {
    "start": "3325000",
    "end": "3600000"
  },
  {
    "text": "the the criteria of satisfied consistently then that's where you can actually say that on every side you can",
    "start": "3328810",
    "end": "3334990"
  },
  {
    "text": "actually good to go thank you so much thank you so when you were doing the the",
    "start": "3334990",
    "end": "3341560"
  },
  {
    "text": "cut over to to actually start driving like production traffic for both read and write on dynamo what kind of metrics",
    "start": "3341560",
    "end": "3346930"
  },
  {
    "text": "were you looking at to determine that it was actually working properly so there",
    "start": "3346930",
    "end": "3352840"
  },
  {
    "text": "are many different metrics we actually could measure that we for instance whenever you maintain one table or one",
    "start": "3352840",
    "end": "3358780"
  },
  {
    "text": "service like literally speaking we have more than twenty thirty metrics we",
    "start": "3358780",
    "end": "3364630"
  },
  {
    "text": "actually maintain and this is maintained in one dashboard that I should be real-time wage just show all the differences example Danny's was a p50",
    "start": "3364630",
    "end": "3372580"
  },
  {
    "text": "latency or a p90 latency what is a p99 latency what is the percentage of the",
    "start": "3372580",
    "end": "3378550"
  },
  {
    "text": "data validate as opposed to matched versus not match why not is match it is",
    "start": "3378550",
    "end": "3383620"
  },
  {
    "text": "it like missing or different we actually like measuring all the different reason as well as a label and then counting or",
    "start": "3383620",
    "end": "3390850"
  },
  {
    "text": "measuring the metrics separately it actually tells you what's going on really in the real world aside in the in",
    "start": "3390850",
    "end": "3396970"
  },
  {
    "text": "the data side and also we keep checking the cost as well that's the kind of side one though but that's very important",
    "start": "3396970",
    "end": "3403330"
  },
  {
    "text": "thing as well when you actually build a new table of course so that's this example but it's really depend on us of",
    "start": "3403330",
    "end": "3409180"
  },
  {
    "text": "the symmetric exams I mean just a quick follow-up you mentioned you spend a lot of time obvious on this data validation",
    "start": "3409180",
    "end": "3414370"
  },
  {
    "text": "thing what kind of scenarios did you encounter where validation failed valuation Perryman",
    "start": "3414370",
    "end": "3421640"
  },
  {
    "text": "yeah like what drove those so some of the example is we have like if you",
    "start": "3421640",
    "end": "3429170"
  },
  {
    "text": "really it's really case-by-case but if you rely on the data extreme for instance from the queue into caching of",
    "start": "3429170",
    "end": "3436069"
  },
  {
    "text": "the failure cases he only has a 24-hour data retention period for whatever",
    "start": "3436069",
    "end": "3441079"
  },
  {
    "text": "reason your Walker kept failing then you immediately lose that permanent way",
    "start": "3441079",
    "end": "3446480"
  },
  {
    "text": "after 24 hours that's one thing you can actually start seeing there in constancy so sometimes we realize that this",
    "start": "3446480",
    "end": "3454640"
  },
  {
    "text": "automatic catching up doesn't really work for certain types of data because we have to do manual intervention for",
    "start": "3454640",
    "end": "3460970"
  },
  {
    "text": "that case we can be legacy data you can very noisy so for whatever things there",
    "start": "3460970",
    "end": "3466369"
  },
  {
    "text": "is to continuously failing we actually lock them out like just all the IDS and then see what's different it could be",
    "start": "3466369",
    "end": "3473599"
  },
  {
    "text": "caused by an unanticipated data issues race accommodation what's another one we",
    "start": "3473599",
    "end": "3479000"
  },
  {
    "text": "ran into a couple of those or even a heist and put scenario your renter ease conditions and also data loss for",
    "start": "3479000",
    "end": "3485000"
  },
  {
    "text": "various reasons that you have data loss thank you thank you I have a question so",
    "start": "3485000",
    "end": "3491720"
  },
  {
    "text": "I'm personally I'm not that familiar with dynamodb and the design but I'm interesting seeing that the schema for",
    "start": "3491720",
    "end": "3499790"
  },
  {
    "text": "the cue that you use as a cue is a different from the target schema or is a",
    "start": "3499790",
    "end": "3505760"
  },
  {
    "text": "based on source schema is a post transform 54 transformation so in general I highly recommend you",
    "start": "3505760",
    "end": "3513680"
  },
  {
    "text": "only maintain ID and timestamp in the queue for the failure cases sometimes",
    "start": "3513680",
    "end": "3518900"
  },
  {
    "text": "it's very efficient if you just extort the snapshot you're actually trying to write or update pre in the queue as it",
    "start": "3518900",
    "end": "3525560"
  },
  {
    "text": "is catching up that's great in terms of partial update perspectives but in terms",
    "start": "3525560",
    "end": "3531859"
  },
  {
    "text": "of cost again it's not different from the dynamo model the question you're",
    "start": "3531859",
    "end": "3537290"
  },
  {
    "text": "asking you what data schema we should store the elements in the queue was it the pre transformation or post",
    "start": "3537290",
    "end": "3543650"
  },
  {
    "text": "transformation or maybe change set like that yeah delete or insert it's like is",
    "start": "3543650",
    "end": "3548660"
  },
  {
    "text": "its own schema or is conforming to a target I think I think they're they're both",
    "start": "3548660",
    "end": "3554360"
  },
  {
    "text": "approaches are valid it depends on if you have low confidence your if you have",
    "start": "3554360",
    "end": "3559910"
  },
  {
    "text": "very complex transformation service and you think the transformation service would be causing issues either in",
    "start": "3559910",
    "end": "3565820"
  },
  {
    "text": "delighting or throwing exceptions you might want to store it in the pre",
    "start": "3565820",
    "end": "3571160"
  },
  {
    "text": "transformation so you can retry to retransform if it's a very simple transformation right you're very",
    "start": "3571160",
    "end": "3577580"
  },
  {
    "text": "confident that's high high success rate then you store it in the post transformation we store in post",
    "start": "3577580",
    "end": "3582770"
  },
  {
    "text": "transformations yeah thanks all right one last question",
    "start": "3582770",
    "end": "3589010"
  },
  {
    "text": "yeah with respect to the caching use cases on the DAX use case did you or are",
    "start": "3589010",
    "end": "3597650"
  },
  {
    "text": "you able to selectively cache different tables like I can imagine some tables",
    "start": "3597650",
    "end": "3603110"
  },
  {
    "text": "you don't want to cache so it's really again when you actually set the decks",
    "start": "3603110",
    "end": "3609350"
  },
  {
    "text": "there are many different ways to actually utilize them one way you can do is maintain that separately per table",
    "start": "3609350",
    "end": "3615640"
  },
  {
    "text": "another way is you can actually share one decks cluster across multiple tables only when there's enabled is when you",
    "start": "3615640",
    "end": "3623480"
  },
  {
    "text": "set the endpoint and then sending that traffic to the target table through that there is only time when injuries did",
    "start": "3623480",
    "end": "3630550"
  },
  {
    "text": "utilizing the decks for instance let's say I have a table a and B I only want",
    "start": "3630550",
    "end": "3635750"
  },
  {
    "text": "to utilize stacks on the a but not B then when you actually access the the",
    "start": "3635750",
    "end": "3641570"
  },
  {
    "text": "the dynamo data in a you can only select a be set to endpoint abducts",
    "start": "3641570",
    "end": "3646750"
  },
  {
    "text": "dynamic way and then B you don't set them then you actually straight you go to dynamic table and then getting back",
    "start": "3646750",
    "end": "3652070"
  },
  {
    "text": "okay and as I opposed to a Sai you actually implicitly going to the X because you actually set the endpoint",
    "start": "3652070",
    "end": "3657230"
  },
  {
    "text": "and that's how you should control the traffic thank you guys thank you so much",
    "start": "3657230",
    "end": "3665000"
  },
  {
    "text": "[Applause]",
    "start": "3665000",
    "end": "3669650"
  }
]
[
  {
    "start": "0",
    "end": "45000"
  },
  {
    "text": "good afternoon everybody can you hear me at the back give me a away if you can hear me at the back excellent hi guys uh",
    "start": "240",
    "end": "6440"
  },
  {
    "text": "so good afternoon my name is Matt Woods I'm the principal data scientist at Amazon web services which basically",
    "start": "6440",
    "end": "11559"
  },
  {
    "text": "means that I get to talk to smart people such as yourselves about how to make uh the right choices in terms of delivering",
    "start": "11559",
    "end": "18600"
  },
  {
    "text": "uh value from the data your applications are generating and in terms of delivering high performance applications",
    "start": "18600",
    "end": "23840"
  },
  {
    "text": "on top of the Amazon web services platform um so uh I get to spend a lot of time with customers uh discussing how",
    "start": "23840",
    "end": "30599"
  },
  {
    "text": "best to use uh the Amazon web services platform for building all types of applications uh from high performance",
    "start": "30599",
    "end": "37879"
  },
  {
    "text": "scientific and Technical Computing applications all the way through to uh more traditional web applications and",
    "start": "37879",
    "end": "43520"
  },
  {
    "text": "that's what I'm going to focus in on today so let's just talk a little bit about performance as it relates to web",
    "start": "43520",
    "end": "49920"
  },
  {
    "start": "45000",
    "end": "237000"
  },
  {
    "text": "applications um so it's kind of instinctive to developers to understand",
    "start": "49920",
    "end": "55160"
  },
  {
    "text": "that performance has a positive effect on your uh on your customer experience and this is not new information so this",
    "start": "55160",
    "end": "61920"
  },
  {
    "text": "is a study a graph from a study that was published all the way back in 1981 where people start to to look at how the",
    "start": "61920",
    "end": "68119"
  },
  {
    "text": "latency of a system affected customer satisfaction and you can see there's a pretty obvious uh negative correlation",
    "start": "68119",
    "end": "74479"
  },
  {
    "text": "there that the longer the computer return uh took to respond and interestingly this response time is",
    "start": "74479",
    "end": "80680"
  },
  {
    "text": "measured in seconds whereas we now tend to measure things in milliseconds which shows just how far we've come uh but",
    "start": "80680",
    "end": "85840"
  },
  {
    "text": "there's a negative correlation between the time that took the computer took to respond and the satisfaction or the",
    "start": "85840",
    "end": "91840"
  },
  {
    "text": "happiness that customers experienced when they working with that system and that is very much carried through into",
    "start": "91840",
    "end": "97040"
  },
  {
    "text": "today's uh internet scale world uh this is a um a results of the uh satisfa or",
    "start": "97040",
    "end": "104159"
  },
  {
    "text": "the number of daily searches for customers uh that had artificially introduced latency into their search",
    "start": "104159",
    "end": "110680"
  },
  {
    "text": "results uh so you can see when you start to introduce 50 millisecs doesn't really make much of a difference but when",
    "start": "110680",
    "end": "116280"
  },
  {
    "text": "you're getting up to the 400 millisecond Mark so adding less than half a second in terms of the search results uh people",
    "start": "116280",
    "end": "122600"
  },
  {
    "text": "will use your application less people will search Less in terms of the number of searches that they're doing and you",
    "start": "122600",
    "end": "128000"
  },
  {
    "text": "can even go to a more frying grained uh uh measurement than that you can look at not just the queries per visitor but how",
    "start": "128000",
    "end": "134239"
  },
  {
    "text": "people refine their queries so do subsequent searches you can look at the number the amount of Revenue per visitor",
    "start": "134239",
    "end": "140560"
  },
  {
    "text": "uh the number of clicks that they make inside your application and the satisfaction that they have relating to that application so all of these are",
    "start": "140560",
    "end": "146800"
  },
  {
    "text": "negatively correlated you can see this trending downwards uh to what's that nearly 4 and a half% decrease in",
    "start": "146800",
    "end": "153480"
  },
  {
    "text": "customer satisfaction uh when you're introducing two seconds of latency into your application so anything that we can",
    "start": "153480",
    "end": "159159"
  },
  {
    "text": "do to improve the performance of our application uh results in higher spent",
    "start": "159159",
    "end": "164440"
  },
  {
    "text": "or rather reduction in the uh cost of uh the latency introduced looking at this",
    "start": "164440",
    "end": "170239"
  },
  {
    "text": "the other way Firefox did some interesting um work looking at the",
    "start": "170239",
    "end": "175400"
  },
  {
    "text": "reduction in their page load time and relating that to the conversion rate which for five Fox and Mozilla is a",
    "start": "175400",
    "end": "181040"
  },
  {
    "text": "download of the Firefox browser so they looked at a uh a simple web page this is",
    "start": "181040",
    "end": "186080"
  },
  {
    "text": "their download page which had become very heavy and they removed a bunch of crof and they took some uh took some of",
    "start": "186080",
    "end": "191200"
  },
  {
    "text": "the approaches that we're going to talk about today and they reduced the page load Time by 2.2 seconds and the result",
    "start": "191200",
    "end": "196959"
  },
  {
    "text": "was 15.4% increase in the number of browsers that were downloaded so again reducing",
    "start": "196959",
    "end": "203080"
  },
  {
    "text": "latency an increase in the desired outcome of your application even for something as simple as a web page and",
    "start": "203080",
    "end": "209879"
  },
  {
    "text": "Wilson a well-known venture capitalist um says that when he goes through and makes a list of the top 10 things that",
    "start": "209879",
    "end": "216840"
  },
  {
    "text": "his portfolio companies need to focus on speed is number one it is more than just a feature it is the foundation it's the",
    "start": "216840",
    "end": "224360"
  },
  {
    "text": "uh barrier it's the the the starting price of delivering a high performance application and building a scalable",
    "start": "224360",
    "end": "230680"
  },
  {
    "text": "sophisticated business further down the line so he says that uh speed is more than a feature and I tend to agree with",
    "start": "230680",
    "end": "237120"
  },
  {
    "start": "237000",
    "end": "571000"
  },
  {
    "text": "him so with that in mind let's talk about a web requ EST uh so um when we",
    "start": "237120",
    "end": "242239"
  },
  {
    "text": "think about a web request a web request is a relatively complex it's got a collection of assets and those assets are loaded from a remote server into a",
    "start": "242239",
    "end": "249200"
  },
  {
    "text": "local client typically a web browser and what I have here is a uh anonymized uh",
    "start": "249200",
    "end": "254640"
  },
  {
    "text": "to protect the guilty uh set of assets over there on the left hand side and we're going to take a look at the uh the",
    "start": "254640",
    "end": "260320"
  },
  {
    "text": "response time of those assets as we hit return on our browser and this is pretty much what it looks like so you can see",
    "start": "260320",
    "end": "266520"
  },
  {
    "text": "here the the Top Line there is the request for the home page you can see a certain amount of time for the initial",
    "start": "266520",
    "end": "272400"
  },
  {
    "text": "connection this is the TCP handshake going through the web server there's a certain amount of time for SSL negotiation sorting out all the",
    "start": "272400",
    "end": "278639"
  },
  {
    "text": "certificates for a secure connection then you have a pause this green barrier in that first line uh which is the time",
    "start": "278639",
    "end": "284440"
  },
  {
    "text": "to the first bite this is the server and the client Sitting Waiting for each other to talk to each other with real content and then after that we have the",
    "start": "284440",
    "end": "291080"
  },
  {
    "text": "blue barrier which is the content download so this is the HTML and then we have all of the other assets that come",
    "start": "291080",
    "end": "297000"
  },
  {
    "text": "in after that with separate requests so this is the stylesheet the JavaScript the images and all the rest of it and",
    "start": "297000",
    "end": "302919"
  },
  {
    "text": "what you can see is that this kind of breaks down into two halves over here on the left hand side uh we have basically",
    "start": "302919",
    "end": "310000"
  },
  {
    "text": "the server being responsible for this latency for this performance of the application this is the connection this",
    "start": "310000",
    "end": "316479"
  },
  {
    "text": "is the latency of that connection the handshake information and then delivering that first bite back to the",
    "start": "316479",
    "end": "322039"
  },
  {
    "text": "browser as quickly as possible over on the right hand side all of this is uh on",
    "start": "322039",
    "end": "327400"
  },
  {
    "text": "the uh the behalf of the client so this is is the browser this is the browser taking that information in and the",
    "start": "327400",
    "end": "332759"
  },
  {
    "text": "browser will help you out wherever possible to make your application appear more responsive so this is the very much",
    "start": "332759",
    "end": "338759"
  },
  {
    "text": "the reason that when you uh when you click a link in a web page the browser doesn't remove the page you're currently",
    "start": "338759",
    "end": "343880"
  },
  {
    "text": "looking at whilst it loads the next one because if it did that you'd be staring at a white page and it actually decreases the satisfaction of the",
    "start": "343880",
    "end": "349880"
  },
  {
    "text": "customer with the browser so the browser leaves that page up so things feel more responsive so it'll do everything it can",
    "start": "349880",
    "end": "355199"
  },
  {
    "text": "to help you out but there's still a large amount of work on the client side to building the page p and delivering",
    "start": "355199",
    "end": "360280"
  },
  {
    "text": "the assets and rendering it and all the rest of it which is to say um for the majority of my talk I'm going to",
    "start": "360280",
    "end": "365880"
  },
  {
    "text": "concentrate on the remote side of the application this is an area where your infrastructure can have an impact but",
    "start": "365880",
    "end": "371840"
  },
  {
    "text": "you shouldn't forget that there's a significant amount of work in fact the majority of the work is spent over on",
    "start": "371840",
    "end": "377599"
  },
  {
    "text": "the right hand side which is to say don't listen to me just focus on your front end uh uh",
    "start": "377599",
    "end": "383880"
  },
  {
    "text": "optimization and the reason for this is that when you look at the top 10 sites on the web you can see that the",
    "start": "383880",
    "end": "390360"
  },
  {
    "text": "the the the responsibility of the response in terms of time is 24% in average on the back end and 76% on the",
    "start": "390360",
    "end": "398000"
  },
  {
    "text": "front end so optimizing the back end is a good start uh but you shouldn't ignore",
    "start": "398000",
    "end": "403680"
  },
  {
    "text": "the fact that you've got some more work to do on the front end so whil I'm going to focus on the back end because that's really where your infrastructure and the",
    "start": "403680",
    "end": "410160"
  },
  {
    "text": "services that you use on AWS can really drive down that 24% um they'll I'll",
    "start": "410160",
    "end": "415479"
  },
  {
    "text": "touch on some uh some hints and tips for optimizing on the front end as well and uh just to show the sort of complexity",
    "start": "415479",
    "end": "422160"
  },
  {
    "text": "these things can get to uh this is the uh waterfall graph the asset load graph uh for the front page of amazon.com and",
    "start": "422160",
    "end": "429319"
  },
  {
    "text": "you can see that uh it's relatively complicated um but that thin sliver on the left hand side that is the backend",
    "start": "429319",
    "end": "436360"
  },
  {
    "text": "component of the uh responding application that's the backend component of amazon.com and when you can crunch",
    "start": "436360",
    "end": "442759"
  },
  {
    "text": "that component all the way down to that very very tiny Slither it makes a much much more uh satisfied engagement with",
    "start": "442759",
    "end": "449080"
  },
  {
    "text": "your customer customers and as your companies grow so let's talk a little bit about a web request so web requests",
    "start": "449080",
    "end": "456360"
  },
  {
    "text": "come in from your users all the way up there on the top that represents your Global uh collection of users it comes",
    "start": "456360",
    "end": "462560"
  },
  {
    "text": "in over the Internet it comes from the browser when they hit return over the Internet into uh your application uh it",
    "start": "462560",
    "end": "468879"
  },
  {
    "text": "typically goes through a web server uh this can be something like Apache or IIs the web server roots your request",
    "start": "468879",
    "end": "474479"
  },
  {
    "text": "through some application logic uh this can be uh some PHP code this can be uh some uh Java stack could be rails",
    "start": "474479",
    "end": "481240"
  },
  {
    "text": "anything like that application processes up all that logic and it typically has to go back to the database make some",
    "start": "481240",
    "end": "486639"
  },
  {
    "text": "queries and the database will process those queries go back to disk when necessary to restore the data package",
    "start": "486639",
    "end": "493039"
  },
  {
    "text": "that up in a response it'll go back into the application Logic the application logic will extract the information it",
    "start": "493039",
    "end": "498199"
  },
  {
    "text": "needs from that database query it'll repackage itself start to build up the HTML template from all the fragments on",
    "start": "498199",
    "end": "503479"
  },
  {
    "text": "the rest of it deliver that back to the web server which will uh issue an HTTP response uh back to your client which is",
    "start": "503479",
    "end": "510080"
  },
  {
    "text": "to say that there are about seven areas within your application where latency can start to build up and what I thought",
    "start": "510080",
    "end": "516120"
  },
  {
    "text": "I'd do is just run through these seven areas uh and try and zoom in on what we can do to reduce uh the areas of latency",
    "start": "516120",
    "end": "523599"
  },
  {
    "text": "reduce the latency from each of these steps within the application so we should start at the",
    "start": "523599",
    "end": "529640"
  },
  {
    "text": "start so whilst I said all the way over on the left hand side here that this is all on the back end it's not strictly",
    "start": "529640",
    "end": "536560"
  },
  {
    "text": "true um about half of it in this examples case I did choose this example",
    "start": "536560",
    "end": "541880"
  },
  {
    "text": "um specifically for this reason but about half of it is due to latency in the network so before the TCP",
    "start": "541880",
    "end": "548000"
  },
  {
    "text": "interaction and the handshake protocol starts to take effect there's this large gap all the way over on the left hand",
    "start": "548000",
    "end": "553160"
  },
  {
    "text": "side where nothing is happening and this is internet induced latency and you can see that's what 30 40 sorry 25 30% of",
    "start": "553160",
    "end": "561480"
  },
  {
    "text": "the entire request is made up of that latency and there's a lot you can do uh to reduce this latency uh entirely and",
    "start": "561480",
    "end": "567839"
  },
  {
    "text": "TR and remove it entirely from your app application so it turns out that this",
    "start": "567839",
    "end": "574160"
  },
  {
    "start": "571000",
    "end": "937000"
  },
  {
    "text": "part of the problem of measuring this latency uh is that it is not predictable so it is not predictable for all of your",
    "start": "574160",
    "end": "580480"
  },
  {
    "text": "users around the world and you can't start to make a dent into the latency of your application until you are measuring",
    "start": "580480",
    "end": "588200"
  },
  {
    "text": "uh the latency in your application so you should pretty much measure all of the things but that is very difficult",
    "start": "588200",
    "end": "593360"
  },
  {
    "text": "when that latency is uh unpredictable or inconsistent and so inconsistency plus",
    "start": "593360",
    "end": "598880"
  },
  {
    "text": "latency is basically the the worst case example and this is particularly personified in this front in this",
    "start": "598880",
    "end": "605839"
  },
  {
    "text": "backend internet latency because you may have customers in New York City that are talking to the US East uh data centers",
    "start": "605839",
    "end": "613760"
  },
  {
    "text": "um but you might also have customers elsewhere around the world so the London guys will have to go all the way across",
    "start": "613760",
    "end": "619680"
  },
  {
    "text": "the internet over to Virginia in Us East to be able to get that data and then go all the way back and that's a variable",
    "start": "619680",
    "end": "625480"
  },
  {
    "text": "latency that will differ from your customers in uh Virginia for example or New York City which are very closely physically located or more importantly",
    "start": "625480",
    "end": "632839"
  },
  {
    "text": "Network located with your with your regions so there's also uh you have could have customers over in Sydney",
    "start": "632839",
    "end": "637959"
  },
  {
    "text": "which have it even worse they have to go all the way through the internet usually through Singapore and then back over to the US get to New York City so you have",
    "start": "637959",
    "end": "644680"
  },
  {
    "text": "a very variable ttfb time to First Bite based on the geographic location of your customers so this variability plus the",
    "start": "644680",
    "end": "651800"
  },
  {
    "text": "latency is something we definitely want to reduce and remove because it makes it very very difficult to measure and",
    "start": "651800",
    "end": "657760"
  },
  {
    "text": "eradicate so one way to approach this is to reduce the internet induced latency",
    "start": "657760",
    "end": "663000"
  },
  {
    "text": "by using a Content delivery network uh so uh we just happen to have one of these uh called Amazon cloudfront uh it",
    "start": "663000",
    "end": "669320"
  },
  {
    "text": "shares all of the same characteristics with the rest of our services in that it's available on demand you only pay",
    "start": "669320",
    "end": "674880"
  },
  {
    "text": "for what you use and it's designed to deliver much lower latency on a geographic basis uh with predictable",
    "start": "674880",
    "end": "681360"
  },
  {
    "text": "consistent latency for your application uh consumers in addition to that it'll deliver faster downloads so the way that",
    "start": "681360",
    "end": "688079"
  },
  {
    "text": "it does this is basically by providing an edge cache network uh so uh let's say",
    "start": "688079",
    "end": "693560"
  },
  {
    "text": "that we are a customer over in uh in Perth and we have data stored in our Dublin data centers um what cloudfront",
    "start": "693560",
    "end": "700800"
  },
  {
    "text": "will do is it will basically take that request for the first time that data is requested it'll go off and fetch the",
    "start": "700800",
    "end": "706440"
  },
  {
    "text": "data from Dublin it'll then move it back and cach it locally in our Sydney data",
    "start": "706440",
    "end": "712079"
  },
  {
    "text": "centers after that first request any subsequent requests from that customer or any other customer uh will be",
    "start": "712079",
    "end": "718079"
  },
  {
    "text": "retrieved from The Edge Lo location in Sydney so that means you're getting much lower latency because every customer",
    "start": "718079",
    "end": "723120"
  },
  {
    "text": "doesn't have to keep going back to Dublin and getting potentially the same information so this is perfect if you",
    "start": "723120",
    "end": "728320"
  },
  {
    "text": "have assets which don't change so JavaScript files CSS files anything like that that doesn't change you just want",
    "start": "728320",
    "end": "734600"
  },
  {
    "text": "to be able to store that in a local Edge cache you're going to get much lower latency and consistent latency for your",
    "start": "734600",
    "end": "740480"
  },
  {
    "text": "customers around there so that's the first thing so that's a sort of typical common use case for content deler",
    "start": "740480",
    "end": "746920"
  },
  {
    "text": "content delivery networks but with cloudfront you can actually deliver both static and dynamic content so you can",
    "start": "746920",
    "end": "753120"
  },
  {
    "text": "cache Dynamic pages in cloudfront like search results so rather than having to go back all the way through the request",
    "start": "753120",
    "end": "758560"
  },
  {
    "text": "Loop all the way through the web server the application tier the database all the way back up to deliver it over a inconsistent connection uh to back to",
    "start": "758560",
    "end": "765839"
  },
  {
    "text": "the browser you can store the results of that database query in the terms of an HTTP HTTP request in the cloudfront edge",
    "start": "765839",
    "end": "773160"
  },
  {
    "text": "Network so you can use Query stings query strings or uh cookies as C keys so",
    "start": "773160",
    "end": "780399"
  },
  {
    "text": "these will be what the cloudfront network uses to look up your cache within a local Edge Network so you can",
    "start": "780399",
    "end": "786560"
  },
  {
    "text": "use those query stings and the cookies to deliver Dynamic content into to your application so this isn't just for",
    "start": "786560",
    "end": "792279"
  },
  {
    "text": "static content irrespective of whether it's static or dynamic uh cloudfront has a ton of network and path optimizations",
    "start": "792279",
    "end": "798959"
  },
  {
    "text": "built into it to accelerate even unique content so even for Unique content that's only going to be delivered once",
    "start": "798959",
    "end": "804279"
  },
  {
    "text": "there's still an advantage to putting cloudfront in front of your entire request in addition to this Dynamic and",
    "start": "804279",
    "end": "809720"
  },
  {
    "text": "static content so content delivery is a really A A first order um service that",
    "start": "809720",
    "end": "816240"
  },
  {
    "text": "you should consider using to reduce the latency improve the satisfaction of your web applications it's very very easy to",
    "start": "816240",
    "end": "821720"
  },
  {
    "text": "hook up it works with uh S3 objects but also with any custom origin server uh so",
    "start": "821720",
    "end": "827079"
  },
  {
    "text": "you can just put it in front of uh either your ec2 instances your on- premises uh data or your data inside",
    "start": "827079",
    "end": "833839"
  },
  {
    "text": "S3 so going down the stack uh We've reduced as much as possible the latency introduc with a network by putting a",
    "start": "833839",
    "end": "840480"
  },
  {
    "text": "Content delivery Network in front of it let's take a look and zoom in on the web server and our application um so what",
    "start": "840480",
    "end": "847360"
  },
  {
    "text": "typically happens uh as you might request is a request comes in it goes through your web server uh httpd from",
    "start": "847360",
    "end": "852800"
  },
  {
    "text": "Apache or IAS or whatever it happens to be your web server packages that up and then talks to your application server um",
    "start": "852800",
    "end": "859560"
  },
  {
    "text": "the trouble is that that can be uh relatively high performance uh it can deliver that very very quickly when it's",
    "start": "859560",
    "end": "865880"
  },
  {
    "text": "only getting a small number of requests because web servers are particularly well equipped to deal with um high",
    "start": "865880",
    "end": "872480"
  },
  {
    "text": "levels of concurrency so when you have a high level of traffic that's when you start building up a queue inside the web",
    "start": "872480",
    "end": "878759"
  },
  {
    "text": "server so requests start queuing up inside the web server and they don't get processed by your application tier they just queue up now you have a concurrency",
    "start": "878759",
    "end": "885759"
  },
  {
    "text": "problem where each of those requests is going to wait until the web server can process it now that may be only uh you",
    "start": "885759",
    "end": "892279"
  },
  {
    "text": "know less than a millisecond for a low traffic site but as you start to build up more more and more and more more customers this concurrency problem can",
    "start": "892279",
    "end": "898720"
  },
  {
    "text": "become pretty significant and the wait times can start to impact the satisfaction of your web application now you can run web servers",
    "start": "898720",
    "end": "906079"
  },
  {
    "text": "with multiple processes and that's fantastic and you should do that uh but it does impact how your application",
    "start": "906079",
    "end": "911240"
  },
  {
    "text": "works if you've got multiple threads of your web server working then you not just need to start to think about how thread safe your application tier is and",
    "start": "911240",
    "end": "918440"
  },
  {
    "text": "what happens to the application State as these concurrent application requests are being handled how do you handle that",
    "start": "918440",
    "end": "923519"
  },
  {
    "text": "state within an application server so multiple processing points is is very",
    "start": "923519",
    "end": "929160"
  },
  {
    "text": "very useful it will give you additional scale on a single uh box or single instance uh but you do have to start",
    "start": "929160",
    "end": "934440"
  },
  {
    "text": "thinking about how that will be handled inside your application a slightly different approach um would be to start to",
    "start": "934440",
    "end": "941319"
  },
  {
    "start": "937000",
    "end": "1040000"
  },
  {
    "text": "actually decouple your application and your uh your unit of scale so rather",
    "start": "941319",
    "end": "947440"
  },
  {
    "text": "than having everything bounded up into a single instance where you've got low latency access to the database and all",
    "start": "947440",
    "end": "952639"
  },
  {
    "text": "the rest of it it actually makes more sense to in terms of building for concurrency to figure out what your unit",
    "start": "952639",
    "end": "958040"
  },
  {
    "text": "of scale is going to be and then horizontally scale that unit to provide uh additional capacity and reduce the",
    "start": "958040",
    "end": "965040"
  },
  {
    "text": "concurrency load reduce that concurrency induced latency and in the case of a web application that unit of scale is",
    "start": "965040",
    "end": "970959"
  },
  {
    "text": "typically the web server and an application server that is stateless and decoupled from the rest of the",
    "start": "970959",
    "end": "976040"
  },
  {
    "text": "application tier what I mean by decoupled is that each of these units shouldn't know too much about the rest",
    "start": "976040",
    "end": "982680"
  },
  {
    "text": "of the application architecture you should be able to add as many of these into your application as possible to add",
    "start": "982680",
    "end": "988319"
  },
  {
    "text": "additional uh uh uh capacity and reduce add additional concurrency into your tier and once you've done that and",
    "start": "988319",
    "end": "995360"
  },
  {
    "text": "you've removed and dropped out the state back into the database where it belongs it doesn't matter if these things start",
    "start": "995360",
    "end": "1001519"
  },
  {
    "text": "up and disappear as and when you need to add or remove capacity the unit of scale becomes U very easy to add and remove to",
    "start": "1001519",
    "end": "1009240"
  },
  {
    "text": "reduce the concurrency based latency and you can stick these things behind a load balancer what that then means is that as",
    "start": "1009240",
    "end": "1015759"
  },
  {
    "text": "your uh queries start to come in and you get more than your single web server can handle and you're starting to see increased latency in your application",
    "start": "1015759",
    "end": "1022079"
  },
  {
    "text": "because of the concurrency your low balancer will actually root those queries all at the same time to as many",
    "start": "1022079",
    "end": "1027240"
  },
  {
    "text": "of these different users as as many of these different units of scale as possible so your web server then is",
    "start": "1027240",
    "end": "1032438"
  },
  {
    "text": "dealing with a much less a much lower velocity collection of web requests you're going to get lower levels of",
    "start": "1032439",
    "end": "1037678"
  },
  {
    "text": "concurrency lower levels of latency so my biggest piece of advice",
    "start": "1037679",
    "end": "1043000"
  },
  {
    "start": "1040000",
    "end": "1142000"
  },
  {
    "text": "for this is to decouple your service tiers this is actually much much uh easier to develop against as well",
    "start": "1043000",
    "end": "1048919"
  },
  {
    "text": "because you start to be able to separate the concerns within your web application you might have multiple services for example under the hood and you can then",
    "start": "1048919",
    "end": "1056160"
  },
  {
    "text": "once you've separated them out into units of scale you can then scale those independently of one another so it",
    "start": "1056160",
    "end": "1061520"
  },
  {
    "text": "become much easier to separate your concerns much easier to develop against much easier to collaborate against to",
    "start": "1061520",
    "end": "1066919"
  },
  {
    "text": "across multiple uh developers and much easier to manage when you put them into production and it also drives higher",
    "start": "1066919",
    "end": "1072280"
  },
  {
    "text": "availability because these things are now fault tolerant uh so these instances can be removed if they fail or come up",
    "start": "1072280",
    "end": "1078919"
  },
  {
    "text": "when you need additional capacity and uh the application will just keep on trucking so building for horizontal",
    "start": "1078919",
    "end": "1086159"
  },
  {
    "text": "scale basically allows you to decrease your request contention and reduce Your Capacity planning headaches so rather",
    "start": "1086159",
    "end": "1091799"
  },
  {
    "text": "than having to be sure that you're choosing the Run single instance type and hor and vertically scaling that",
    "start": "1091799",
    "end": "1097000"
  },
  {
    "text": "instance type by adding more memory or more CPU or whatever um this allows you to build for horizontal scale which",
    "start": "1097000",
    "end": "1103240"
  },
  {
    "text": "allows you to much more dynamically respond to the changing uh capacity environment of your application but it",
    "start": "1103240",
    "end": "1109480"
  },
  {
    "text": "does require a stateless application architecture so moving state from the application tier into a decoupled",
    "start": "1109480",
    "end": "1116360"
  },
  {
    "text": "environment usually a database that is responsible for handling State and pushing that down means that if these",
    "start": "1116360",
    "end": "1122000"
  },
  {
    "text": "instances need to have additional or you need to add additional instances of these units of scale you can just go",
    "start": "1122000",
    "end": "1127240"
  },
  {
    "text": "ahead and do so likewise if something fails or you're scaling down uh then you don't lose the state of your application",
    "start": "1127240",
    "end": "1132520"
  },
  {
    "text": "just because you lose uh uh capacity so it does require that stateless application architecture but the",
    "start": "1132520",
    "end": "1138240"
  },
  {
    "text": "benefits and in terms of availability and performance are are vast it also allows you to do small",
    "start": "1138240",
    "end": "1144840"
  },
  {
    "start": "1142000",
    "end": "1229000"
  },
  {
    "text": "things Loosely coupled uh so this is kind of the uh the Unix philosophy basically of allow of having one thing",
    "start": "1144840",
    "end": "1150440"
  },
  {
    "text": "and allowing that one thing to do it well it's very much the approach that we follow at Amazon internally at Amazon",
    "start": "1150440",
    "end": "1155840"
  },
  {
    "text": "we're a very service oriented uh company where each team basically owns the development of the service and the",
    "start": "1155840",
    "end": "1162159"
  },
  {
    "text": "operations of that service moving forward it allows each of these teams to be a lot more agile and focus in on the",
    "start": "1162159",
    "end": "1167640"
  },
  {
    "text": "one thing that it does well and you can see that in the services that we expose like Amazon ec2 and S3 and elastic Block",
    "start": "1167640",
    "end": "1173799"
  },
  {
    "text": "store these are specifically designed to do one thing and do it well and you get to piece them together much like you",
    "start": "1173799",
    "end": "1179000"
  },
  {
    "text": "would on the command line in Unix where you can just pipe between them uh with the building blocks that are Exposed on the Amazon platform you can piece those",
    "start": "1179000",
    "end": "1185760"
  },
  {
    "text": "together in a way that makes sense for you um small piece of recommendation if you're a ruby developer of which I am",
    "start": "1185760",
    "end": "1192600"
  },
  {
    "text": "you should take a look at unicorn and rainbows uh unicorn and Rainbows are custom designed for this approach of",
    "start": "1192600",
    "end": "1199000"
  },
  {
    "text": "using the sort of Unix philosophy uh they're rack compatible so if you have a ruby web application take a look at",
    "start": "1199000",
    "end": "1204720"
  },
  {
    "text": "unicorn rainbows is light unicorn um in that it but that it allows for longer polling processes but these are well",
    "start": "1204720",
    "end": "1211360"
  },
  {
    "text": "worth a look a little tip there if you're working with rack applications and you should also try and be asynchronous by default and what I mean",
    "start": "1211360",
    "end": "1218360"
  },
  {
    "text": "by that is respond in an asynchronous way to requests that doesn't mean in a high latency way but where possible use",
    "start": "1218360",
    "end": "1225200"
  },
  {
    "text": "cues to decouple these things and uh move State into those",
    "start": "1225200",
    "end": "1230360"
  },
  {
    "start": "1229000",
    "end": "1308000"
  },
  {
    "text": "so this allows you to basically reduce the response time of your application because you're able to handle concurrence uh concurrency um however as",
    "start": "1230360",
    "end": "1238280"
  },
  {
    "text": "your application and your uh users are using your application or not using it depending on either the time of day or",
    "start": "1238280",
    "end": "1244240"
  },
  {
    "text": "say you're supporting a television program and you're anticipating to get a lot of customers very early on for that",
    "start": "1244240",
    "end": "1249880"
  },
  {
    "text": "one hour that TV program is on and then they'll go away again um you do need to think about the response time of your",
    "start": "1249880",
    "end": "1255960"
  },
  {
    "text": "units of scale so how quickly those response uh those units of scale can come online become instantiated and then",
    "start": "1255960",
    "end": "1262400"
  },
  {
    "text": "start responding to requests and you can limit the impact on performance through more rapid or low time uh to providing",
    "start": "1262400",
    "end": "1269559"
  },
  {
    "text": "additional capacity so there's a couple of tips for that uh what we're basically talking about is the time that it takes",
    "start": "1269559",
    "end": "1274960"
  },
  {
    "text": "for the low balancer to notice that you have a significant capacity constraint",
    "start": "1274960",
    "end": "1280000"
  },
  {
    "text": "uh instantiate those additional instances on ec2 wait for those to warm up and for the OS to boot and the",
    "start": "1280000",
    "end": "1286080"
  },
  {
    "text": "application to start up so they can start require receiving requests the low balancer the",
    "start": "1286080",
    "end": "1291320"
  },
  {
    "text": "elastic low balancer will actually start to Ping those applications with a health check and once the applications pass that health",
    "start": "1291320",
    "end": "1297360"
  },
  {
    "text": "check only then will it start to root request to them so the time for all of that OS booting and the instance",
    "start": "1297360",
    "end": "1303159"
  },
  {
    "text": "instantiation and all the rest of it can limit your response uh if it's too slow",
    "start": "1303159",
    "end": "1308440"
  },
  {
    "start": "1308000",
    "end": "1375000"
  },
  {
    "text": "so how do we speed it up well the first piece of advice is to use faster booting EBS backed instances these are the",
    "start": "1308440",
    "end": "1314679"
  },
  {
    "text": "default uh but older uh um uh armies Amazon machine images uh uh do sometimes",
    "start": "1314679",
    "end": "1321559"
  },
  {
    "text": "get stored in S3 that was the way we originally did it and then we move to EBS backed instances and it takes longer",
    "start": "1321559",
    "end": "1326960"
  },
  {
    "text": "for S3 images or images stored in S3 to be copied from S3 onto ec2 and then",
    "start": "1326960",
    "end": "1332679"
  },
  {
    "text": "instantiated with EBS back instances they're right there on EBS we simply need to start up the EBS volume attach",
    "start": "1332679",
    "end": "1339279"
  },
  {
    "text": "it to the instance and away we go in addition to that uh Linux is faster to boot than Windows uh we can provision a",
    "start": "1339279",
    "end": "1345240"
  },
  {
    "text": "Linux server in about 15 seconds um but Windows takes a little bit longer because we have to shuttle security",
    "start": "1345240",
    "end": "1350960"
  },
  {
    "text": "certificates around now this is unlikely to determine uh the choice of the",
    "start": "1350960",
    "end": "1356080"
  },
  {
    "text": "platform that you're building against uh but it is a consideration when you're working with it so EBS backed instances",
    "start": "1356080",
    "end": "1362159"
  },
  {
    "text": "will boot faster than S3 backed instances and if you have an option uh you should use those where possible um",
    "start": "1362159",
    "end": "1367480"
  },
  {
    "text": "EBS pack instances also tend to be smaller in size than S3 instances so the the instantiation time of the data is",
    "start": "1367480",
    "end": "1374200"
  },
  {
    "text": "also less we often see customers um pre making their EBS backed uh Amazon",
    "start": "1374200",
    "end": "1381320"
  },
  {
    "start": "1375000",
    "end": "1471000"
  },
  {
    "text": "machine images as well so this is what Netflix do um at the end of each code deployment on the Netflix platform uh it",
    "start": "1381320",
    "end": "1387919"
  },
  {
    "text": "goes through the usual uh integration tests and unit tests and all the rest of it and the end of that deployment",
    "start": "1387919",
    "end": "1393559"
  },
  {
    "text": "pipeline is a fresh Amazon machine image and that Ami becomes the unit of",
    "start": "1393559",
    "end": "1398679"
  },
  {
    "text": "deployment there is no bootstrapping on that instance or anything like that it is specially prepared at check-in time",
    "start": "1398679",
    "end": "1404840"
  },
  {
    "text": "to be deployed quickly uh so the Ami becomes the unit of deployment and this works well if you need to be",
    "start": "1404840",
    "end": "1411200"
  },
  {
    "text": "able to scale quickly and scale where the Delta is very very large where you're bringing up hundreds of instances",
    "start": "1411200",
    "end": "1416559"
  },
  {
    "text": "and taking down hundreds of instances at a time where the time to bring those up uh would be significant so booting a new",
    "start": "1416559",
    "end": "1422600"
  },
  {
    "text": "Ami uh which is completely packag to boot quickly is a lot more uh uh is a",
    "start": "1422600",
    "end": "1428080"
  },
  {
    "text": "lot more responsive than having an application which needs to bootstrap itself so another approach which is very",
    "start": "1428080",
    "end": "1433320"
  },
  {
    "text": "common with using things like opsw works or Amazon cloud formation all these sort of things is is that you basically take",
    "start": "1433320",
    "end": "1439600"
  },
  {
    "text": "a vanilla machine image maybe Amazon Linux or Ubuntu or something like that",
    "start": "1439600",
    "end": "1445400"
  },
  {
    "text": "and then as it comes up you install all the dependencies you pull your application down from Version Control then you start it up and then you",
    "start": "1445400",
    "end": "1451679"
  },
  {
    "text": "register it with a low balancer building everything into a pre-packaged Army is a lot quicker than taking that but you do",
    "start": "1451679",
    "end": "1457480"
  },
  {
    "text": "lose some flexibility and you have to put more Machinery in place early on to be able to do that so finding your comfort level between the two entirely",
    "start": "1457480",
    "end": "1464320"
  },
  {
    "text": "bootstrapped an entirely cold start but prepackaged um will is an important",
    "start": "1464320",
    "end": "1471279"
  },
  {
    "start": "1471000",
    "end": "1559000"
  },
  {
    "text": "consideration you can also automate the response with autoscaling uh so one of",
    "start": "1471279",
    "end": "1477240"
  },
  {
    "text": "the biggest uh latency uh components of adding and removing capacity if you're not automated is that somebody has to be",
    "start": "1477240",
    "end": "1483399"
  },
  {
    "text": "actively checking the stats to see when you need to add and remove capacity and that latency can be pretty high at 3:00",
    "start": "1483399",
    "end": "1488960"
  },
  {
    "text": "in the morning when everyone's in bed and nobody wants to be on page of Duty as to to add and remove capacity at the",
    "start": "1488960",
    "end": "1494720"
  },
  {
    "text": "sort of speed that you need to to respond to changing capacity requests um so we provide a service to help you",
    "start": "1494720",
    "end": "1500480"
  },
  {
    "text": "automate this it's called autoscaling Uh we're not particularly inventive with our service names uh and this basically",
    "start": "1500480",
    "end": "1506240"
  },
  {
    "text": "allows you to set the operational thresholds of your application so you can look at the amount of uh Network",
    "start": "1506240",
    "end": "1512000"
  },
  {
    "text": "latency you can look look at the amount of network utilization for your current uh group of uh units of scale and then",
    "start": "1512000",
    "end": "1518960"
  },
  {
    "text": "as you start to move outside those oper operational thresholds let's say you start to use too much the total",
    "start": "1518960",
    "end": "1524559"
  },
  {
    "text": "available memory on your cluster Falls beneath the the level where your application will start to swap that's",
    "start": "1524559",
    "end": "1530399"
  },
  {
    "text": "the point at which autoscaling will respond and add additional capacity on your behalf but it won't just go crazy",
    "start": "1530399",
    "end": "1535960"
  },
  {
    "text": "and add like 10 million instances and you end up getting charged a million dollars at the end of the month um you",
    "start": "1535960",
    "end": "1541200"
  },
  {
    "text": "can set the limits of what is added either by the total number of instances or by the percentage change so you might",
    "start": "1541200",
    "end": "1547640"
  },
  {
    "text": "say between you know 80 and 90% Network utilization add another 40% to my",
    "start": "1547640",
    "end": "1552720"
  },
  {
    "text": "network capacity so this is obviously much faster than a manual response especially early in the morning when",
    "start": "1552720",
    "end": "1558360"
  },
  {
    "text": "everyone's in bed using opsw Works uh you can also do time based responses uh so you can set",
    "start": "1558360",
    "end": "1564919"
  },
  {
    "start": "1559000",
    "end": "1611000"
  },
  {
    "text": "not just operational levels of when to scale up and scale down but you can set operational times so you can say well my",
    "start": "1564919",
    "end": "1571440"
  },
  {
    "text": "business application is primarily used uh when it is uh between 9: and 5:00 p.m. and outside those times I want to",
    "start": "1571440",
    "end": "1578120"
  },
  {
    "text": "scale down to a Bare Bones unit or do some offline batch processing so with OP opsw this makes this super easy you can",
    "start": "1578120",
    "end": "1584760"
  },
  {
    "text": "also do a follow the sun response to your application so you can add remove capacity to the various regions where",
    "start": "1584760",
    "end": "1590520"
  },
  {
    "text": "people are working with your application and then scale back when those guys stop working with it whether at whatever time",
    "start": "1590520",
    "end": "1596279"
  },
  {
    "text": "frame uh that becomes important so time based and follow the sun responses uh can help pre-warm your application so in",
    "start": "1596279",
    "end": "1603240"
  },
  {
    "text": "the half an hour before your application is you know is going to become popular you can start adding additional capacity at that point to the point where you are",
    "start": "1603240",
    "end": "1609880"
  },
  {
    "text": "comfortable with the concurrency level and you can also do preemptive scaling of some of the AWS Services as well so",
    "start": "1609880",
    "end": "1616320"
  },
  {
    "start": "1611000",
    "end": "1642000"
  },
  {
    "text": "for example the elastic low balancer uh it's not exposed to you but under the hood that's a large distributed system",
    "start": "1616320",
    "end": "1622240"
  },
  {
    "text": "uh and if you know you're going to you you anticipate you're going to get a large amount of traffic uh you should get in touch with your um premium",
    "start": "1622240",
    "end": "1628760"
  },
  {
    "text": "support guys and say look I know this is going to happen uh we're having going to have an event um let's say this a music",
    "start": "1628760",
    "end": "1635080"
  },
  {
    "text": "festival we know we're going to have a significant amount of live streaming uh then please prescale uh the elastic low",
    "start": "1635080",
    "end": "1641000"
  },
  {
    "text": "balancer on our behalf the other approach is to use uh reserved capacity so whilst we try",
    "start": "1641000",
    "end": "1648320"
  },
  {
    "start": "1642000",
    "end": "1722000"
  },
  {
    "text": "really really hard to ensure that we have capacity available as and when you need it our data centers are not uh",
    "start": "1648320",
    "end": "1654600"
  },
  {
    "text": "infinitely sized unfortunately so there can be sometimes when you receive an insufficient capacity error uh this is",
    "start": "1654600",
    "end": "1661399"
  },
  {
    "text": "very very very uncommon uh but it can happen and if you want to remove the risk of that happening when you're",
    "start": "1661399",
    "end": "1666559"
  },
  {
    "text": "experiencing a a large scale event when you need to add significant amounts of scale the best approach for that is to",
    "start": "1666559",
    "end": "1672519"
  },
  {
    "text": "reserve the capacity you're going to need at a baseline using reserved instances these allow you to make a",
    "start": "1672519",
    "end": "1678559"
  },
  {
    "text": "small upfront payment which will Reserve that capacity for you as and when you need it it's guaranteed to be available",
    "start": "1678559",
    "end": "1684960"
  },
  {
    "text": "and be there that means that when you start to reach the limits of your capacity and you want to add more it's always guaranteed to be there for you in",
    "start": "1684960",
    "end": "1692039"
  },
  {
    "text": "addition to that it also because it allows us to plan uh our operations more efficiently if we know what you're going",
    "start": "1692039",
    "end": "1697080"
  },
  {
    "text": "to need a year or three years down the line we actually pass those savings back on to you in the form of a lower hourly",
    "start": "1697080",
    "end": "1703279"
  },
  {
    "text": "rate so it actually works out to be a lot more cost effective to reserve the capacity as well plus you get that guaranteed",
    "start": "1703279",
    "end": "1709640"
  },
  {
    "text": "availability so that's the importance of horizontal scale so you see we've moved from a monolithic vertically scaled",
    "start": "1709640",
    "end": "1715480"
  },
  {
    "text": "application into something which is a a lot more responsive to our changing capacity environment within our",
    "start": "1715480",
    "end": "1722600"
  },
  {
    "start": "1722000",
    "end": "1795000"
  },
  {
    "text": "application so let's take a look down and just take a look at the importance of choosing the right instance type so",
    "start": "1722600",
    "end": "1730440"
  },
  {
    "text": "um as you probably know ec2 has a wide range uh of different instance types that are available to you this is a",
    "start": "1730440",
    "end": "1736840"
  },
  {
    "text": "collection of um mixtures of resources so some instances have more memory some",
    "start": "1736840",
    "end": "1742440"
  },
  {
    "text": "instances have more CPU available some have more or faster dis so you get a full spectrum of price performance",
    "start": "1742440",
    "end": "1748720"
  },
  {
    "text": "options and you guys get to choose what the right level is for your application so choosing the right instance type is",
    "start": "1748720",
    "end": "1755240"
  },
  {
    "text": "incredibly application specific your application May behave in a particular way or have a particular idiosyncrasy uh",
    "start": "1755240",
    "end": "1762080"
  },
  {
    "text": "which makes a particular uh instance type a good fit or a bad fit so my advice is to Benchmark your application",
    "start": "1762080",
    "end": "1768799"
  },
  {
    "text": "against a broader set of instances as possible to see what responses you can expect and one way to look at that is to",
    "start": "1768799",
    "end": "1774519"
  },
  {
    "text": "look at our cloudwatch metric service which will take a look at uh uh Network utilization and CPU and memory and all",
    "start": "1774519",
    "end": "1780480"
  },
  {
    "text": "the rest of it so monitoring that change is relatively easy and lightweight uh it's also important uh that if you can",
    "start": "1780480",
    "end": "1786480"
  },
  {
    "text": "to select a 64-bit architecture as the platform because that gives you much more freedom as you want to move between",
    "start": "1786480",
    "end": "1792320"
  },
  {
    "text": "instance types and change and evaluate instance types the other piece of advice",
    "start": "1792320",
    "end": "1797399"
  },
  {
    "start": "1795000",
    "end": "1835000"
  },
  {
    "text": "is to Rel relate those benchmarks not just to CPU utilization but to relate",
    "start": "1797399",
    "end": "1802960"
  },
  {
    "text": "those as closely as possible to business metrics so this is one of the components of uh the sort of 21st century",
    "start": "1802960",
    "end": "1809320"
  },
  {
    "text": "architectures the next generation of architectures that cloud computing and programmable utility platforms allow you",
    "start": "1809320",
    "end": "1815480"
  },
  {
    "text": "you can start to relate not just the number of instances that you have back to the amount of CPU you're using but",
    "start": "1815480",
    "end": "1821440"
  },
  {
    "text": "also relate it back to the number of uh uh customers that you can serve or the number of images that you can process",
    "start": "1821440",
    "end": "1828080"
  },
  {
    "text": "all these sort of things and so you can take a look at um the price per",
    "start": "1828080",
    "end": "1833559"
  },
  {
    "text": "operation for your architecture and one approach to this is something called the canary and the coal mine so if you",
    "start": "1833559",
    "end": "1840880"
  },
  {
    "start": "1835000",
    "end": "1859000"
  },
  {
    "text": "standardize on 64-bit Amis you can deploy across the instance types as I say but it also allows you to evaluate",
    "start": "1840880",
    "end": "1847120"
  },
  {
    "text": "new instance types with real traffic so this is a demo that I ran at the uh keyote of uh reinvent which is our user",
    "start": "1847120",
    "end": "1855120"
  },
  {
    "text": "uh and partner conference in Las Vegas anyone here at reinvent okay good um so you might have seen this",
    "start": "1855120",
    "end": "1861240"
  },
  {
    "text": "before but this is the basic approach um so this is a an application uh which is",
    "start": "1861240",
    "end": "1866639"
  },
  {
    "text": "running and processing images and what we have here is a pretty static infrastructure uh this is this is",
    "start": "1866639",
    "end": "1873080"
  },
  {
    "text": "actually a live application that we ran it was running on top of Dynamo DB and we were throwing requests at it and we",
    "start": "1873080",
    "end": "1878120"
  },
  {
    "text": "were monitoring the cost of processing a thousand images you can imagine this might be an image sharing site and you",
    "start": "1878120",
    "end": "1884880"
  },
  {
    "text": "can this is a pretty static uh um level this is actually updating in real time",
    "start": "1884880",
    "end": "1890320"
  },
  {
    "text": "uh and then what we did was we said well let's see what the effect of adding a new type of instance is so we moved from",
    "start": "1890320",
    "end": "1896760"
  },
  {
    "text": "an M1 grade instance to a Next Generation M3 grade instance what we did was we deployed the same machine image",
    "start": "1896760",
    "end": "1903480"
  },
  {
    "text": "to the M3 instance and we just added it to the low balancer and immediately you could see the effect of the cost of",
    "start": "1903480",
    "end": "1910080"
  },
  {
    "text": "processing these M3 instances were more efficient at processing the images so the cost of delivering a th processed",
    "start": "1910080",
    "end": "1916919"
  },
  {
    "text": "images started fall that was just with one instance that we added into the low balancer of the production traffic and",
    "start": "1916919",
    "end": "1922799"
  },
  {
    "text": "because that was successful what we went ahead and did was we added another five of those instances into the infrastructure and remove the other five",
    "start": "1922799",
    "end": "1929799"
  },
  {
    "text": "instances that were running on the old version so you shouldn't become too attached to the servers that are running",
    "start": "1929799",
    "end": "1934919"
  },
  {
    "text": "your application you should consider them effectively fungible resources these are resources that you can just swap out uh we're moving from an area",
    "start": "1934919",
    "end": "1942159"
  },
  {
    "text": "where we can uh where it's nice to be able to sit and hug our servers but they don't hug you back so don't become to",
    "start": "1942159",
    "end": "1948159"
  },
  {
    "text": "attach to these guys just add and remove them as necessary and you can actually have a significant impact just by",
    "start": "1948159",
    "end": "1953480"
  },
  {
    "text": "swapping out the instance type on the cost of your operations so the instance selection is",
    "start": "1953480",
    "end": "1958720"
  },
  {
    "text": "important Benchmark and Benchmark against business metrics the fourth area is really uh the interface with the data",
    "start": "1958720",
    "end": "1965399"
  },
  {
    "start": "1961000",
    "end": "2000000"
  },
  {
    "text": "store uh so it is always going to be faster to access that data store if you",
    "start": "1965399",
    "end": "1970960"
  },
  {
    "text": "don't have to go back to disk uh going to disk will always be slower than just looking something up in in memory and",
    "start": "1970960",
    "end": "1977559"
  },
  {
    "text": "it's also got an increased concurrency if you can look things up in memory because on premise on instance memory is",
    "start": "1977559",
    "end": "1984679"
  },
  {
    "text": "much much faster so working with inmemory data is a lot faster than having to go back to disk Plus in most",
    "start": "1984679",
    "end": "1990919"
  },
  {
    "text": "cases you'll get increased concurrency because memory can handle uh random access in a much more efficient way if you don't have to move the platter heads",
    "start": "1990919",
    "end": "1998080"
  },
  {
    "text": "uh across the the read heads across the platters on your disk so one approach to this is",
    "start": "1998080",
    "end": "2003240"
  },
  {
    "start": "2000000",
    "end": "2039000"
  },
  {
    "text": "obviously caching uh so you this is the the process of storing query results in",
    "start": "2003240",
    "end": "2009000"
  },
  {
    "text": "memory rather than having to go through the database layer to get back to the disk but the rights still go back to dis",
    "start": "2009000",
    "end": "2014639"
  },
  {
    "text": "so we're just talking about reads here which happen frequently um we have a service for this as well which can help you set it up it's called Uh",
    "start": "2014639",
    "end": "2021240"
  },
  {
    "text": "imaginatively Amazon elasticache and this basically allows you to deploy operate and scale in memory caches so",
    "start": "2021240",
    "end": "2027720"
  },
  {
    "text": "this is mem cach D compliant so if any of your om layers already have a a a a",
    "start": "2027720",
    "end": "2032960"
  },
  {
    "text": "mcache uh component then you can just point spin up an elastic cache cluster and point your layer at elastic cache so",
    "start": "2032960",
    "end": "2040639"
  },
  {
    "start": "2039000",
    "end": "2074000"
  },
  {
    "text": "caches are great not just for reducing uh the uh opportunity to go back to disk",
    "start": "2040639",
    "end": "2045679"
  },
  {
    "text": "but also for storing transient data and it really should just be transient so for example web server state would be a",
    "start": "2045679",
    "end": "2051440"
  },
  {
    "text": "good fit here high score tables anything like that uh and any timec consuming uh",
    "start": "2051440",
    "end": "2056560"
  },
  {
    "text": "reporting style analytics that you want to put together and uh particularly many to many query results where you might",
    "start": "2056560",
    "end": "2061599"
  },
  {
    "text": "have to go across large number of or do complex relational queries you can just throw all of those results of those",
    "start": "2061599",
    "end": "2067839"
  },
  {
    "text": "timec consuming queries into the cache and then go back to the cache memory to recover it rather than having to rerun",
    "start": "2067839",
    "end": "2072960"
  },
  {
    "text": "the queries every time you want to do it so in terms of best practices of deploying and operating a cache uh you",
    "start": "2072960",
    "end": "2078960"
  },
  {
    "start": "2074000",
    "end": "2169000"
  },
  {
    "text": "should very much build your application and assume cold cache latency this is data which is not cached uh when you're",
    "start": "2078960",
    "end": "2085440"
  },
  {
    "text": "building out your application architecture so caching is an improvement to your application latency",
    "start": "2085440",
    "end": "2091079"
  },
  {
    "text": "based on a cold lat based on a cold Baseline for your application uh you also need to think carefully about uh",
    "start": "2091079",
    "end": "2097920"
  },
  {
    "text": "the appropriate time to live of the data inside your cach this is how long the data is stored there and it's oftenly",
    "start": "2097920",
    "end": "2103800"
  },
  {
    "text": "said that there are two uh significant problems in computer science first is uh naming things second is cash",
    "start": "2103800",
    "end": "2110520"
  },
  {
    "text": "invalidation and the third is off by one errors and that very much is representative here so choosing the",
    "start": "2110520",
    "end": "2116560"
  },
  {
    "text": "right time to live of your of your caching and doing the right level of invalidation is challenging but it can give you significant performance gains",
    "start": "2116560",
    "end": "2123520"
  },
  {
    "text": "um it's also beneficial to batch requests rather than making single request against the cach again it's just",
    "start": "2123520",
    "end": "2128839"
  },
  {
    "text": "more efficient to do those random accesses in memory uh but you should always architect for cash failure and",
    "start": "2128839",
    "end": "2134240"
  },
  {
    "text": "this goes back to assuming a c cache latency uh there will be requests which go back to disk you're not removing that",
    "start": "2134240",
    "end": "2140200"
  },
  {
    "text": "entirely the first time a request is made and you should build the internal SLA of the latency inside your",
    "start": "2140200",
    "end": "2145839"
  },
  {
    "text": "application assuming that you're going to have to go back to disk or assuming that the cach has failed so doing a cach",
    "start": "2145839",
    "end": "2151400"
  },
  {
    "text": "miss and going back to disk is an important component of your architecture it's always going to happen for a proportion of your users and optimizing",
    "start": "2151400",
    "end": "2158319"
  },
  {
    "text": "away from that means that those proportion of those users are going to have a worse experience than everyone else so removing that assuming cold",
    "start": "2158319",
    "end": "2164640"
  },
  {
    "text": "cache and assuming application cache failure which elastic cache helps you operate around is important so that's",
    "start": "2164640",
    "end": "2170960"
  },
  {
    "start": "2169000",
    "end": "2198000"
  },
  {
    "text": "caching very e easy to add into your application for reads um but eventually some of those queries as I say are going",
    "start": "2170960",
    "end": "2177359"
  },
  {
    "text": "to be a cach miss and they're going to have to go back to the database so what can we do here to help how do we first",
    "start": "2177359",
    "end": "2183640"
  },
  {
    "text": "accelerate reads for our application well the first way is that we get to choose between uh vertical scaling",
    "start": "2183640",
    "end": "2189440"
  },
  {
    "text": "that's having a single database instance and scaling that to add additional levels of concurrency or query",
    "start": "2189440",
    "end": "2195400"
  },
  {
    "text": "complexity versus adding horizontal scale so for horizontal scale um we just",
    "start": "2195400",
    "end": "2201359"
  },
  {
    "start": "2198000",
    "end": "2298000"
  },
  {
    "text": "add additional database resources just as we did with the unit of scale in our web tier and this is perfect if you want",
    "start": "2201359",
    "end": "2207000"
  },
  {
    "text": "to scale out read heavy applications uh so what you can do with the Amazon uh relational database service RDS is add",
    "start": "2207000",
    "end": "2214640"
  },
  {
    "text": "additional read replicas to your database so you can have your master database and then spin up up to five",
    "start": "2214640",
    "end": "2220800"
  },
  {
    "text": "additional uh read replicas which are purely based and purely there for read heavy applications so you can remove you",
    "start": "2220800",
    "end": "2227400"
  },
  {
    "text": "can move all of your reads going to the all of your reads and your rights going to your master database and start to",
    "start": "2227400",
    "end": "2232920"
  },
  {
    "text": "filter off those reads into the read replicas your right still go to the master and so obviously you've got",
    "start": "2232920",
    "end": "2238680"
  },
  {
    "text": "additional capacity there to handle a higher number of uh requests um there's asynchronous mirroring of data between",
    "start": "2238680",
    "end": "2245800"
  },
  {
    "text": "uh the master and the read replicas so you do have to architect for that but the uh the latency or the delay of that",
    "start": "2245800",
    "end": "2252920"
  },
  {
    "text": "mirroring is available as a cloudwatch metric so you can keep an eye on the the the replication lag between the data you",
    "start": "2252920",
    "end": "2260000"
  },
  {
    "text": "can also start to charge your data and this is good for both reads and writes so this is very useful if you have data",
    "start": "2260000",
    "end": "2265520"
  },
  {
    "text": "which easily uh comp compartmentalizes uh either by geography or customer name or something like that rather than",
    "start": "2265520",
    "end": "2271720"
  },
  {
    "text": "having 100% of your traffic go to a single database instance you can basically spin up uh five different",
    "start": "2271720",
    "end": "2277040"
  },
  {
    "text": "databases instances and put 20% of your customers on each of those database instances so this is very useful you",
    "start": "2277040",
    "end": "2282839"
  },
  {
    "text": "could have all of your customers in Tokyo running on one database instance you can have all of your customers in uh",
    "start": "2282839",
    "end": "2288079"
  },
  {
    "text": "in the west coast running on another database instance and you can obviously Shard to be more more segmented and add",
    "start": "2288079",
    "end": "2294800"
  },
  {
    "text": "additional capacity that way so that's a useful pattern for horizontal scale like I said you can also add",
    "start": "2294800",
    "end": "2300359"
  },
  {
    "start": "2298000",
    "end": "2334000"
  },
  {
    "text": "vertical scale into the equiv into the equation so you can add and remove individual resources to your database by",
    "start": "2300359",
    "end": "2306520"
  },
  {
    "text": "adding additional CP you additional memory to the instances and that'll do more allow the database engine to do",
    "start": "2306520",
    "end": "2312200"
  },
  {
    "text": "more heavy lifting for you in terms of caching those uh inside the the database memory as well and you can add more CPU",
    "start": "2312200",
    "end": "2318720"
  },
  {
    "text": "for uh resource intensive queries for reporting and all those sort of things actually read replicas are a very good",
    "start": "2318720",
    "end": "2324119"
  },
  {
    "text": "fit for that as well you can spin up a read replica and fire your reports uh to your read replica rather than having to",
    "start": "2324119",
    "end": "2329920"
  },
  {
    "text": "go to the production database which may still be uh being accessed by customers but at some point you may want",
    "start": "2329920",
    "end": "2336319"
  },
  {
    "start": "2334000",
    "end": "2377000"
  },
  {
    "text": "to scale the uh the input output operations of your database um and the",
    "start": "2336319",
    "end": "2341920"
  },
  {
    "text": "best way to do this on AWS is to provision the throughput that your application is going to need what I mean",
    "start": "2341920",
    "end": "2348200"
  },
  {
    "text": "by that is that based on your application requirements you can actually provision consistent",
    "start": "2348200",
    "end": "2353839"
  },
  {
    "text": "predictable performance back to the disk um based on what your application needs",
    "start": "2353839",
    "end": "2359079"
  },
  {
    "text": "so this IO uh is reserved uh so it'll be predictable and consistent it's also designed to be available and elastic so",
    "start": "2359079",
    "end": "2366240"
  },
  {
    "text": "you can add and remove IO as and when you need to and this mechanism of provisioning the throughput",
    "start": "2366240",
    "end": "2372240"
  },
  {
    "text": "the io throughput of your application is available for EBS RDS and Dynam",
    "start": "2372240",
    "end": "2377839"
  },
  {
    "start": "2377000",
    "end": "2409000"
  },
  {
    "text": "DB so provision throughput is designed to be consistent so you'll get consistent predictable performance of",
    "start": "2377839",
    "end": "2384520"
  },
  {
    "text": "your IO and this is important with relational databases such as RDS with Oracle and MySQL and uh SQL Server it's",
    "start": "2384520",
    "end": "2392359"
  },
  {
    "text": "very important for nosql style data stores like Dynamo DB and whether you're running relational databases or nosql",
    "start": "2392359",
    "end": "2398520"
  },
  {
    "text": "databases like Cassandra or on ec2 um you often use the elastic Block store",
    "start": "2398520",
    "end": "2404119"
  },
  {
    "text": "under the hood to store your persistent data and their consistent performance back to EBS is very very important so",
    "start": "2404119",
    "end": "2410640"
  },
  {
    "start": "2409000",
    "end": "2459000"
  },
  {
    "text": "with the relational database service you can provision pretty high levels of IO for your database so we actually support",
    "start": "2410640",
    "end": "2417240"
  },
  {
    "text": "up to 30,000 iops on RDS um now the database engines beneath that can",
    "start": "2417240",
    "end": "2422880"
  },
  {
    "text": "actually handle a lower level of IO so you can expect to get about 12 a half ,000 iops on MySQL with provision",
    "start": "2422880",
    "end": "2430319"
  },
  {
    "text": "throughput about 25,000 iops on Oracle that's because U mysql's page size is",
    "start": "2430319",
    "end": "2435640"
  },
  {
    "text": "double that of oracles uh so you get half the performance and about 10,000 iops on Microsoft SQL server but we",
    "start": "2435640",
    "end": "2441839"
  },
  {
    "text": "still recommend that if you you need this level of throughput uh you should provision up to the maximum level of",
    "start": "2441839",
    "end": "2447520"
  },
  {
    "text": "30,000 iops because you get reduced latency access you'll get reduced contention to that RDS you'll see some",
    "start": "2447520",
    "end": "2452960"
  },
  {
    "text": "performance gains uh with uh with uh with 30,000 with higher than theoretical maximum",
    "start": "2452960",
    "end": "2459599"
  },
  {
    "start": "2459000",
    "end": "2541000"
  },
  {
    "text": "levels and you also get to select and run on provisioned throughput with instance types so there are certain",
    "start": "2459599",
    "end": "2466240"
  },
  {
    "text": "instance types inside the RDS catalog which are optimized to work with this provision throughput model and the way",
    "start": "2466240",
    "end": "2472040"
  },
  {
    "text": "that it works is that they basically have dedicated network access back to the network attached storage of the",
    "start": "2472040",
    "end": "2477680"
  },
  {
    "text": "persistent data store so on an M1 large you should expect to get about 500 megabits per second and on M1 extra",
    "start": "2477680",
    "end": "2484400"
  },
  {
    "text": "large M2 extra large and M2 quadruple extra large you can expect to get about a th000 megabits per second throughput",
    "start": "2484400",
    "end": "2490480"
  },
  {
    "text": "dedicated to your storage so understanding this architecturing your application and taking advantage of",
    "start": "2490480",
    "end": "2495720"
  },
  {
    "text": "provisioned throughput with RDS is a key indicator for enabling lower latency",
    "start": "2495720",
    "end": "2501880"
  },
  {
    "text": "access and more importantly enabling that consistency that we talked about uh earli on provision throughput is also",
    "start": "2501880",
    "end": "2508760"
  },
  {
    "text": "available with Dynam DB um so you can expect consistent performance with with Dynamo DB will maintain that consistent",
    "start": "2508760",
    "end": "2516160"
  },
  {
    "text": "performance for you uh irrespective of the amount of data stored within dynamodb uh you can expect single",
    "start": "2516160",
    "end": "2521839"
  },
  {
    "text": "digigit millisecond latencies irrespective of the amount of data that's in Dynamo DB and we do that by",
    "start": "2521839",
    "end": "2527440"
  },
  {
    "text": "having ssds under the hood uh so all of your data on Dynamo DB is actually stored on an SSD eventually and we",
    "start": "2527440",
    "end": "2533680"
  },
  {
    "text": "manage those ssds and the capacity under the hood to give you consistent performance you just tell dynb how many",
    "start": "2533680",
    "end": "2540040"
  },
  {
    "text": "iops you need the important thing there is to build for a uniform workload uh",
    "start": "2540040",
    "end": "2545720"
  },
  {
    "start": "2541000",
    "end": "2549000"
  },
  {
    "text": "which is basically a plug for my talk at 430 on dynb so that's the read capacity that",
    "start": "2545720",
    "end": "2551760"
  },
  {
    "start": "2549000",
    "end": "2625000"
  },
  {
    "text": "you can scale on your application and you can see here that we've again moved from this monolithic approach to starting to separate out our concerns",
    "start": "2551760",
    "end": "2557839"
  },
  {
    "text": "and building in the throughput and the latency concerns that each individual component needs to deliver that high",
    "start": "2557839",
    "end": "2563800"
  },
  {
    "text": "performance system so that's read capacity we should also take a look at just how you optimize for read and write",
    "start": "2563800",
    "end": "2570520"
  },
  {
    "text": "capacity or for persistent data on EBS so if you're not familiar with uh the",
    "start": "2570520",
    "end": "2576200"
  },
  {
    "text": "elastic block storm it allows you to spin up network attached persistent storage and that data is snapshotted to",
    "start": "2576200",
    "end": "2581960"
  },
  {
    "text": "S3 for high durability availability and you can snapshot it and replicate it across regions to make it available to",
    "start": "2581960",
    "end": "2588559"
  },
  {
    "text": "other databases um the standard classic EBS volumes are built for moderate or B",
    "start": "2588559",
    "end": "2595400"
  },
  {
    "text": "or bursty workloads so you can anticipate about a 100 iops on a standard EBS instance burst to hundreds",
    "start": "2595400",
    "end": "2601920"
  },
  {
    "text": "of iops for short amounts of time this by the way is another reason that using EBS backed armies is important because",
    "start": "2601920",
    "end": "2608800"
  },
  {
    "text": "that uh that IO burst is available when you start to up that instance so with an EBS backed Army you'll see EBS start to",
    "start": "2608800",
    "end": "2616160"
  },
  {
    "text": "provide additional capacity for a short amount of time as your army is copied and spun up so this is really good for",
    "start": "2616160",
    "end": "2621960"
  },
  {
    "text": "your boot volumes of your applications and speeding up the availability of those but there's a second flavor of EBS",
    "start": "2621960",
    "end": "2628079"
  },
  {
    "start": "2625000",
    "end": "2660000"
  },
  {
    "text": "available which is a with a provisioned high throughput uh uh IO intensive workloads so here you can expect around",
    "start": "2628079",
    "end": "2635160"
  },
  {
    "text": "2,000 iops per volume and you can stripe your data across those multiple volumes",
    "start": "2635160",
    "end": "2640640"
  },
  {
    "text": "for even higher levels of throughput and uh provision iops with EBS is designed with consistency in mind so you can",
    "start": "2640640",
    "end": "2647520"
  },
  {
    "text": "expect it to deliver 10% of the performance within sorry 10% of the performance 99.9% of the time so this is",
    "start": "2647520",
    "end": "2654680"
  },
  {
    "text": "a consistent application uh persistent level of IO that you can build your application",
    "start": "2654680",
    "end": "2659880"
  },
  {
    "text": "against again we have EBS optimized instances which have dedicated network access so M1 large M2 double extra large",
    "start": "2659880",
    "end": "2666800"
  },
  {
    "start": "2660000",
    "end": "2690000"
  },
  {
    "text": "m 3 extra large 500 megabit M1 extra large M2 quadruple extra large M3 double",
    "start": "2666800",
    "end": "2672079"
  },
  {
    "text": "extra large C1 extra large we really need to change our instance names so they're easier for me to say uh a th",
    "start": "2672079",
    "end": "2678760"
  },
  {
    "text": "megabits per second if you're running on these EBS optimized instances so again consistent Network predictable Network",
    "start": "2678760",
    "end": "2684880"
  },
  {
    "text": "perform performance predictable latency and lower latency for high iio",
    "start": "2684880",
    "end": "2690240"
  },
  {
    "start": "2690000",
    "end": "2725000"
  },
  {
    "text": "applications there are some instance types uh such as these ones so the cg1",
    "start": "2690240",
    "end": "2695280"
  },
  {
    "text": "our GPU instances and our performance instances like cluster compute which has",
    "start": "2695280",
    "end": "2700920"
  },
  {
    "text": "Intel Zeon E5 processors High storage and high memory instances um which are",
    "start": "2700920",
    "end": "2707359"
  },
  {
    "text": "not necessarily they're not specifically EBS optimized but they already run on a high performance 10 GB Network so you'll",
    "start": "2707359",
    "end": "2714040"
  },
  {
    "text": "still see some advantages of EBS optimization and higher throughput back to the disk uh in using these instance",
    "start": "2714040",
    "end": "2720480"
  },
  {
    "text": "types even though they're not specifically designated as EBS optimized we also have specifically",
    "start": "2720480",
    "end": "2727559"
  },
  {
    "start": "2725000",
    "end": "2767000"
  },
  {
    "text": "designated High IO instances so these are designed for high throughput database workloads so if you're running",
    "start": "2727559",
    "end": "2733760"
  },
  {
    "text": "Cassandra this is absolutely the the perfect data instance type for you so these are equipped with uh dual one tbte",
    "start": "2733760",
    "end": "2740440"
  },
  {
    "text": "ssds and here you can expect about two uh gigabytes per second for reads and about 1.1 gabt uh per second for wres so",
    "start": "2740440",
    "end": "2748760"
  },
  {
    "text": "these are designed with very high IO uh requirements in mind and building a cluster of these uh gives you extremely",
    "start": "2748760",
    "end": "2755720"
  },
  {
    "text": "large amounts of performance there's no reason your Cassandra cluster couldn't deal with millions of requests per second built on these higho instances",
    "start": "2755720",
    "end": "2762240"
  },
  {
    "text": "you're reducing the concurrency and reducing the seat times of the database using those",
    "start": "2762240",
    "end": "2767720"
  },
  {
    "start": "2767000",
    "end": "2790000"
  },
  {
    "text": "ssds on these instance types if you're using par virtualization uh you can expect around 120,000 iops uh using 4K",
    "start": "2767720",
    "end": "2775800"
  },
  {
    "text": "random reads and at 4K random rights you can expect to be at between 10 and 880,000 iops so again build your",
    "start": "2775800",
    "end": "2782680"
  },
  {
    "text": "application with this in mind that you can get extremely high levels of Random reads using par virtualization and ssds",
    "start": "2782680",
    "end": "2790200"
  },
  {
    "text": "if you're running Hardware virtualized instances which includes Windows uh and some of the other instance types um",
    "start": "2790200",
    "end": "2796280"
  },
  {
    "text": "although hardware virtualization gives you uh A A reduced abstraction away from",
    "start": "2796280",
    "end": "2801319"
  },
  {
    "text": "the CPU that comes at the cost of an increased abstraction from the storage subsystem of the instances so you expect",
    "start": "2801319",
    "end": "2807280"
  },
  {
    "text": "slightly lower performance with these applications 990,000 iops for reads and 9 to 75,000 iops for wrs so you should",
    "start": "2807280",
    "end": "2815480"
  },
  {
    "text": "build again that into your application for um High sequential IO we have a high",
    "start": "2815480",
    "end": "2822920"
  },
  {
    "start": "2817000",
    "end": "2864000"
  },
  {
    "text": "storage instance available for you um this is specifically built with data warehousing Tools in mind so these come",
    "start": "2822920",
    "end": "2828880"
  },
  {
    "text": "built for very large numbers of concurrent parallel queries and for that reason we have 24 2 terab drives on the",
    "start": "2828880",
    "end": "2836240"
  },
  {
    "text": "back end of these so you can uh scale out your application scale out your query access across 24 spindles and that",
    "start": "2836240",
    "end": "2842520"
  },
  {
    "text": "gives you much higher levels of paralyzation and because of that you can get 2.4 gabes second of 2 megabyte uh",
    "start": "2842520",
    "end": "2849160"
  },
  {
    "text": "sequential reads and 2.6 for sequential wrs so this is a very very high performance system for the right type of",
    "start": "2849160",
    "end": "2855079"
  },
  {
    "text": "workload and this is what Amazon redshift our database warehousing uh service uses on the back end we make it",
    "start": "2855079",
    "end": "2860960"
  },
  {
    "text": "available on ec2 to anyone who wants to use it for anything else as well so that's the Block store we talked",
    "start": "2860960",
    "end": "2866839"
  },
  {
    "start": "2864000",
    "end": "2948000"
  },
  {
    "text": "about the rec capacity we talked about right capacity we talked about using ssds and highly parallel data warehousing type workloads um but coming",
    "start": "2866839",
    "end": "2875079"
  },
  {
    "text": "back to our original uh request you can see that about half is on the back end which is what we've been talking about",
    "start": "2875079",
    "end": "2880240"
  },
  {
    "text": "and the other half is on the front end and so there's a huge amount of optimization left there to do uh now I",
    "start": "2880240",
    "end": "2885920"
  },
  {
    "text": "am by no means a front-end optimization expert and so I can recommend uh these two books uh high performance websites",
    "start": "2885920",
    "end": "2892480"
  },
  {
    "text": "and even faster websites available now on Amazon uh so you can look these up",
    "start": "2892480",
    "end": "2897520"
  },
  {
    "text": "available in Kindle uh editions download them read them on the plane home uh really really uh excellent books um",
    "start": "2897520",
    "end": "2903520"
  },
  {
    "text": "extracting out from that uh there's about 14 rules tools for faster loading websites um so things like making fewer",
    "start": "2903520",
    "end": "2911200"
  },
  {
    "text": "HTTP requests these are things which make sense using a Content delivery network is in there and this is advice",
    "start": "2911200",
    "end": "2916359"
  },
  {
    "text": "from Steve Sounders the author of those two books so some of these are entirely server based things like gzipping your",
    "start": "2916359",
    "end": "2922839"
  },
  {
    "text": "components so they take up less over the wire minifying your JavaScript that's a front- end optimization but there are a",
    "start": "2922839",
    "end": "2928599"
  },
  {
    "text": "number on here like delivering through a Content uh delivery Network removing duplic duplicate scripts uh avoiding",
    "start": "2928599",
    "end": "2935119"
  },
  {
    "text": "redirects which you can handle on infrastructure level so all of this available at St sanders.com uh take a",
    "start": "2935119",
    "end": "2940520"
  },
  {
    "text": "look at it and this is basically what he writes about in his book but he's really a Pioneer in enabling front-end",
    "start": "2940520",
    "end": "2946400"
  },
  {
    "text": "optimization highly recommend you check it out and so with that we talked about pretty much everything um but there is",
    "start": "2946400",
    "end": "2952359"
  },
  {
    "start": "2948000",
    "end": "3056000"
  },
  {
    "text": "just one more thing that I wanted to touch on we talked about the full web request within a particular region um",
    "start": "2952359",
    "end": "2957920"
  },
  {
    "text": "but again that web request sits inside a particular region and even with the content delivery Network on the front",
    "start": "2957920",
    "end": "2963079"
  },
  {
    "text": "end you might want to scale across multiple regions now this is is very useful again for reducing the latency of",
    "start": "2963079",
    "end": "2968920"
  },
  {
    "text": "your application back to your customers and you can do this pretty easily uh so we support now Army multiple region copy",
    "start": "2968920",
    "end": "2976160"
  },
  {
    "text": "so you can just choose the uh the army that you want to copy across so again if you're using EBS backed armies as your",
    "start": "2976160",
    "end": "2982040"
  },
  {
    "text": "deployment of scale moving those across multiple regions gives you the availability of spinning up the exact",
    "start": "2982040",
    "end": "2987079"
  },
  {
    "text": "same application across those uh across those regions so you can spin up the exact same application with sharded data",
    "start": "2987079",
    "end": "2993799"
  },
  {
    "text": "across these individual uh individual regions we do the same multi- region copy with uh EBS snapshots as well so if",
    "start": "2993799",
    "end": "3000880"
  },
  {
    "text": "you have a database backup or you have foundational uh data persistent data you want to make available you can take that",
    "start": "3000880",
    "end": "3006799"
  },
  {
    "text": "snapshot and do a multi- region copy across all the regions that you want to run it uh we have nine regions available",
    "start": "3006799",
    "end": "3012200"
  },
  {
    "text": "including govcloud and then you can hook all of those up to Route 53 our DNS service now Route 53 has latency based",
    "start": "3012200",
    "end": "3019839"
  },
  {
    "text": "routing so it will root your requests to the lowest latency region so you don't have to worry about that as well so",
    "start": "3019839",
    "end": "3025880"
  },
  {
    "text": "there's some advantage in using not only cloudfront for Content delivery but",
    "start": "3025880",
    "end": "3031000"
  },
  {
    "text": "using the sister service which uses the same end points and the same points of presence Route 53 to distribute out your",
    "start": "3031000",
    "end": "3037480"
  },
  {
    "text": "lcy uh base requests across multiple regions that's very easy to do now that we've added multi- region uh deployment",
    "start": "3037480",
    "end": "3044200"
  },
  {
    "text": "options through Ami and snapshot copy and with that I'd like to thank you very much for your attention thanks",
    "start": "3044200",
    "end": "3052040"
  },
  {
    "text": "[Applause]",
    "start": "3053660",
    "end": "3057039"
  }
]
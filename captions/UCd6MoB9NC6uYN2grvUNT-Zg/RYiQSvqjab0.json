[
  {
    "start": "0",
    "end": "80000"
  },
  {
    "text": "hi everyone welcome i'm Suresh I'm a product manager for Amazon Aurora and",
    "start": "230",
    "end": "6740"
  },
  {
    "text": "for those of you who are not familiar with the service Aurora is a fully",
    "start": "6740",
    "end": "12059"
  },
  {
    "text": "managed my sequel and Postgres compatible database that offers the performance and availability of a",
    "start": "12059",
    "end": "18510"
  },
  {
    "text": "high-end commercial system along with the cost and simplicity of open-source it's my real pleasure today to introduce",
    "start": "18510",
    "end": "25439"
  },
  {
    "text": "Jean Yahoo and Reuben Lee from Airbnb Airbnb is a longtime user of arias my",
    "start": "25439",
    "end": "31920"
  },
  {
    "text": "sequel which they have used to power most of their production workloads and as the business has killed they were",
    "start": "31920",
    "end": "38520"
  },
  {
    "text": "looking for something that was even more performant even more available and they've chosen Aurora as a work with the",
    "start": "38520",
    "end": "46379"
  },
  {
    "text": "team through this migration process one of the things that really stood out to me is the world-class infrastructure",
    "start": "46379",
    "end": "52770"
  },
  {
    "text": "that they've put in place to test and migrate web-scale workloads so without",
    "start": "52770",
    "end": "57930"
  },
  {
    "text": "further ado gen Yahoo to describe the journey to Aurora enrobing from Airbnb s",
    "start": "57930",
    "end": "73320"
  },
  {
    "text": "infrastructure team today we are going to give a talk how we migrate our",
    "start": "73320",
    "end": "78540"
  },
  {
    "text": "databases to our Ola the general the agenda of the talk is part of following",
    "start": "78540",
    "end": "84210"
  },
  {
    "start": "80000",
    "end": "123000"
  },
  {
    "text": "first we are going to briefly introduce Airbnb architecture we will go over our databases setups in depth and we will",
    "start": "84210",
    "end": "91860"
  },
  {
    "text": "illustrate the challenges we have seen in a past few years both from the nature traffic girls and increasing the number",
    "start": "91860",
    "end": "98549"
  },
  {
    "text": "of engineer these challenges become the motivation for us to test and adopt",
    "start": "98549",
    "end": "104549"
  },
  {
    "text": "better databases technologies we will explain how do we test and benchmark or",
    "start": "104549",
    "end": "111390"
  },
  {
    "text": "Ola to make sure that it will meet our production needs in the Indian we will",
    "start": "111390",
    "end": "116610"
  },
  {
    "text": "introduce our migration approaches to migrate to or Ola with minimal site on time let's start for those of you who",
    "start": "116610",
    "end": "125219"
  },
  {
    "text": "are not familiar with the album be l BN b is the online marketplace for hospitality services enabling people to",
    "start": "125219",
    "end": "133530"
  },
  {
    "text": "lease or rent short term short term lunging including vacation rentals apartment rentals and so on",
    "start": "133530",
    "end": "140100"
  },
  {
    "text": "it has over 3 million listings distributed in 6565 southern cities in",
    "start": "140100",
    "end": "145980"
  },
  {
    "text": "191 countries that's firstly plus first briefly look",
    "start": "145980",
    "end": "152220"
  },
  {
    "start": "148000",
    "end": "255000"
  },
  {
    "text": "at Albion B's architecture few years ago L B&B starts with a very simple",
    "start": "152220",
    "end": "157410"
  },
  {
    "text": "architecture to earlier architecture the requests hit our load balancer and gets",
    "start": "157410",
    "end": "164190"
  },
  {
    "text": "forwarded to our webserver we choose to run Ruby which was Ruby on Rails as our",
    "start": "164190",
    "end": "169560"
  },
  {
    "text": "web framework and our most critical data storing in Mexico we partition the",
    "start": "169560",
    "end": "175650"
  },
  {
    "text": "databases by portal features for instances or LBB messages are storing my",
    "start": "175650",
    "end": "181290"
  },
  {
    "text": "Seco databases named NASA DB all listing availability informations are storing",
    "start": "181290",
    "end": "186540"
  },
  {
    "text": "databases called calendar D be the most critical data such as reservations are",
    "start": "186540",
    "end": "191850"
  },
  {
    "text": "starting our main databases we call our master we're all my Seco entirely on",
    "start": "191850",
    "end": "198299"
  },
  {
    "text": "Amazon RDS in order to support more reap ups we start to run multiple audience",
    "start": "198299",
    "end": "205650"
  },
  {
    "text": "replicas typical cluster will consist of one master and up to 10 weary replicas",
    "start": "205650",
    "end": "211760"
  },
  {
    "text": "few years ago we decided to move away from this monolithic",
    "start": "211760",
    "end": "217140"
  },
  {
    "text": "routine rose architecture to a more service-oriented architecture services like search and risk has already been",
    "start": "217140",
    "end": "224670"
  },
  {
    "text": "running on a standalone Java services and there are ongoing migration to pull the rest services like pricing and",
    "start": "224670",
    "end": "231420"
  },
  {
    "text": "payments into a separate services we use open source software extensively for",
    "start": "231420",
    "end": "238109"
  },
  {
    "text": "inverse kind of stacks for instance we using nginx in our load balancer we're using",
    "start": "238109",
    "end": "243359"
  },
  {
    "text": "zookeeper to power order service discovery we're using elk to store and Cori production logs in addition to",
    "start": "243359",
    "end": "250380"
  },
  {
    "text": "mexico we use radius and memcache to store more data so what is the business",
    "start": "250380",
    "end": "258450"
  },
  {
    "start": "255000",
    "end": "370000"
  },
  {
    "text": "requirement on daily basis I'd so for typical page on Airbnb for instance the",
    "start": "258450",
    "end": "264389"
  },
  {
    "text": "listing detail pages it takes the web sure will query databases from 30 to 50",
    "start": "264389",
    "end": "270720"
  },
  {
    "text": "times and every single quarry would take on average one to two milliseconds and p95 latency would take about ten",
    "start": "270720",
    "end": "278159"
  },
  {
    "text": "milliseconds so any small regressions",
    "start": "278159",
    "end": "284129"
  },
  {
    "text": "and issues on databases side can be very easily observed from a web view from our",
    "start": "284129",
    "end": "289710"
  },
  {
    "text": "databases cluster point of view the biggest clusters we get take over a hundred thousand QPS so here's a summary",
    "start": "289710",
    "end": "299280"
  },
  {
    "text": "of our databases deployment mostly using Mexico we have very few Postgres and",
    "start": "299280",
    "end": "305490"
  },
  {
    "text": "oracle these post question oracle are used by vendors offer a third-party",
    "start": "305490",
    "end": "312210"
  },
  {
    "text": "software who has very strong dependencies to these databases we were running Mexico on easy to initially it",
    "start": "312210",
    "end": "320669"
  },
  {
    "text": "was a challenge back in 2011 it was a challenge for us to implement the proper",
    "start": "320669",
    "end": "326159"
  },
  {
    "text": "automations to run my sequel on ec2 for instance automatic failover backup",
    "start": "326159",
    "end": "332219"
  },
  {
    "text": "restore and patr back in 2011 we made a decision to migrate all my secure",
    "start": "332219",
    "end": "338729"
  },
  {
    "text": "databases to our Seco RDS Mexico and we are a hundred percent running on RDS Mexico since then up until right now we",
    "start": "338729",
    "end": "346949"
  },
  {
    "text": "have hundreds of audience clusters deployed we also using telephone to",
    "start": "346949",
    "end": "352620"
  },
  {
    "text": "manage all the databases the benefits of using terraform is that all the changes",
    "start": "352620",
    "end": "357690"
  },
  {
    "text": "to our databases cluster is version control and peer reviewed let's go over",
    "start": "357690",
    "end": "365430"
  },
  {
    "text": "some of the challenges we have experienced on databases there in the past few years the first challenge was",
    "start": "365430",
    "end": "372900"
  },
  {
    "start": "370000",
    "end": "430000"
  },
  {
    "text": "to support Airbnb is fast business growth this graph shows how weekly traffic",
    "start": "372900",
    "end": "378240"
  },
  {
    "text": "count and response time changes in the past two years the red bar represents the aggregated",
    "start": "378240",
    "end": "385440"
  },
  {
    "text": "weekly traffic counts and the red line represented average responsible time response time observed on web layer you",
    "start": "385440",
    "end": "394229"
  },
  {
    "text": "can see very clearly that the traffic to Airbnb grows very quickly why the user experiences do not does not",
    "start": "394229",
    "end": "400529"
  },
  {
    "text": "degree in the past few years so on the",
    "start": "400529",
    "end": "406529"
  },
  {
    "text": "backend we have the numerous optimizations such as caching reducing",
    "start": "406529",
    "end": "412919"
  },
  {
    "text": "unnecessary databases query to support a business growth however given all the",
    "start": "412919",
    "end": "418789"
  },
  {
    "text": "optimization implemented it becomes harder and harder for us to achieve the same the over year",
    "start": "418789",
    "end": "424050"
  },
  {
    "text": "therefore we are actively looking for new databases technologies to help us callous act the second challenge is",
    "start": "424050",
    "end": "432509"
  },
  {
    "start": "430000",
    "end": "463000"
  },
  {
    "text": "introduced by SOAs Ovation initiative with the transition to SOA more",
    "start": "432509",
    "end": "438270"
  },
  {
    "text": "engineers are building services now we have hundreds of services and hundreds of databases classrooms running",
    "start": "438270",
    "end": "444599"
  },
  {
    "text": "production the increasing number of databases cluster make it really hard for us to provision modify monitor and",
    "start": "444599",
    "end": "452459"
  },
  {
    "text": "opera databases in next few slides I'm going to explain how jitter impacts our",
    "start": "452459",
    "end": "458789"
  },
  {
    "text": "site availability and how the increasing number of classroom make the problem worse",
    "start": "458789",
    "end": "464719"
  },
  {
    "start": "463000",
    "end": "518000"
  },
  {
    "text": "another issues we are seeing is fast data growth this graph shows the",
    "start": "465080",
    "end": "470580"
  },
  {
    "text": "freespace percentage changes on one of our critical payments databases you can",
    "start": "470580",
    "end": "475830"
  },
  {
    "text": "see clearly that the client is inserting a lot of data and in the past a few months we have increasing the EBS volume",
    "start": "475830",
    "end": "483149"
  },
  {
    "text": "on the underlying audience on the audience in census three times and it is provision at the maximum capacity right",
    "start": "483149",
    "end": "489180"
  },
  {
    "text": "now according to our estimation it's going to run out of disk in about five",
    "start": "489180",
    "end": "495569"
  },
  {
    "text": "months if nothing is being done on application side one way to solve this is beautifully de Mexico on application",
    "start": "495569",
    "end": "502649"
  },
  {
    "text": "layer the idea is that try to distribute data to more than one audience instances however is pretty challenging for us to",
    "start": "502649",
    "end": "510389"
  },
  {
    "text": "finish in this within five months giving all the capacity of dependencies on databases in LB amis infrastructure",
    "start": "510389",
    "end": "516810"
  },
  {
    "text": "ecosystems over the past few years we have observed a few challenges while",
    "start": "516810",
    "end": "524250"
  },
  {
    "start": "518000",
    "end": "611000"
  },
  {
    "text": "running at web scale the first challenge is that it talks more than a day first",
    "start": "524250",
    "end": "530639"
  },
  {
    "text": "to create a rear up for some of a bigger databases caster",
    "start": "530639",
    "end": "535580"
  },
  {
    "text": "for instance this is especially inconvenient when we want to expand our",
    "start": "538550",
    "end": "544740"
  },
  {
    "text": "rear applica during a spike over user traffic for instance during the Super Bowl as fine a similar issue that it",
    "start": "544740",
    "end": "552120"
  },
  {
    "text": "took about a similar amount of time to restore a daily basis for some of the big clusters restoring and databases is",
    "start": "552120",
    "end": "558750"
  },
  {
    "text": "a fairly regular process for us for instance we use databases backup and",
    "start": "558750",
    "end": "564270"
  },
  {
    "text": "restore to move data from our databases to the data warehouses in addition to that we will store databases to run",
    "start": "564270",
    "end": "570690"
  },
  {
    "text": "experiment to tune and benchmark my psycho configuration changes the additional 16 hours of delay is",
    "start": "570690",
    "end": "577560"
  },
  {
    "text": "acceptable for some of these use cases another issue we observed is what we saw",
    "start": "577560",
    "end": "584790"
  },
  {
    "text": "in databases is often needed to warm up the instances applications often see",
    "start": "584790",
    "end": "590370"
  },
  {
    "text": "significantly more latency after the instance is initially created therefore",
    "start": "590370",
    "end": "595860"
  },
  {
    "text": "we have built customized script to warm up the instances by scanning every single row on databases this entire",
    "start": "595860",
    "end": "603360"
  },
  {
    "text": "process takes several hours and is quite inconvenient for us the last challenge",
    "start": "603360",
    "end": "609000"
  },
  {
    "text": "we see is frequent chatter this graph",
    "start": "609000",
    "end": "614490"
  },
  {
    "start": "611000",
    "end": "660000"
  },
  {
    "text": "shows effect of jitter when happens we see constant readwrite latency increase",
    "start": "614490",
    "end": "620760"
  },
  {
    "text": "on the audience instances other results my sequence rats running increase on the",
    "start": "620760",
    "end": "626970"
  },
  {
    "text": "RDS side the in front application point of view the rear i/o latency two databases were increase and maybe as the",
    "start": "626970",
    "end": "636390"
  },
  {
    "text": "application will start to see time out and the users will see five hundred pages for instance level it might",
    "start": "636390",
    "end": "642540"
  },
  {
    "text": "appears only a few times in a year randomly the less of jitters vary from a couple of minutes to a couple hours",
    "start": "642540",
    "end": "649410"
  },
  {
    "text": "depending on the underlying events on the Amazon side which we do not have a lot of visibility into this is a further",
    "start": "649410",
    "end": "656790"
  },
  {
    "text": "scenario where we have very little controls our site from a single instance",
    "start": "656790",
    "end": "661980"
  },
  {
    "start": "660000",
    "end": "709000"
  },
  {
    "text": "point of view a minus T a might not seem to be have a big deal if there's only a few",
    "start": "661980",
    "end": "667710"
  },
  {
    "text": "chitters happens in Europe however if you look at it the aggregated level is quite concerning this is a graph shows",
    "start": "667710",
    "end": "675420"
  },
  {
    "text": "the effect of jitters on a small portions of our production databases each line represents a databases with a",
    "start": "675420",
    "end": "683850"
  },
  {
    "text": "different color you can see clearly that in this four hours of pure time jitter is constantly happening in order to",
    "start": "683850",
    "end": "691140"
  },
  {
    "text": "alleviate this we have implemented a few four back strategies in our databases client and proxy for instance our client",
    "start": "691140",
    "end": "698790"
  },
  {
    "text": "would automatically retry the query if the query comes out on a daily basis replicas with jitter however if the",
    "start": "698790",
    "end": "706290"
  },
  {
    "text": "issue happens our master there's very little we can do according to our",
    "start": "706290",
    "end": "711300"
  },
  {
    "start": "709000",
    "end": "740000"
  },
  {
    "text": "estimations about 10% of lbm bees downtown can be attributed latency",
    "start": "711300",
    "end": "717120"
  },
  {
    "text": "jitters the current lb means availability matrix is somewhere around three to four nines 10% is a small",
    "start": "717120",
    "end": "724050"
  },
  {
    "text": "number but we still wants to optimize in here this problem this problem is the",
    "start": "724050",
    "end": "730380"
  },
  {
    "text": "the general problem is is enlarged by our our critical business flow depends",
    "start": "730380",
    "end": "736380"
  },
  {
    "text": "on more databases which is the problem when we're running our web scale because",
    "start": "736380",
    "end": "742800"
  },
  {
    "start": "740000",
    "end": "823000"
  },
  {
    "text": "of all these challenges we start to consider alternative by the time we do a valuation there are two alternative to",
    "start": "742800",
    "end": "749850"
  },
  {
    "text": "us one is easy to Mexico the second is or Rolla the benefits of",
    "start": "749850",
    "end": "755010"
  },
  {
    "text": "running easy to Mexico is that we get access to the underlying local SSD directly which is more performant also",
    "start": "755010",
    "end": "763080"
  },
  {
    "text": "we have more control and visibility in his system we could have SSH to the instances and there's an instance level",
    "start": "763080",
    "end": "769410"
  },
  {
    "text": "profiling the downside is that we need to staff a DBA team and starting working",
    "start": "769410",
    "end": "774839"
  },
  {
    "text": "on a lot of the automation pieces where audience Mexico already provides such as databases backup restore point point",
    "start": "774839",
    "end": "781589"
  },
  {
    "text": "time restore and query replicas and also due to the limitations on a single",
    "start": "781589",
    "end": "787140"
  },
  {
    "text": "dependency on single ec2 instance we need to handle the sharding in the database of sharding in a very near term",
    "start": "787140",
    "end": "793080"
  },
  {
    "text": "on the roll aside the benefit or roller solves a lot of the problems",
    "start": "793080",
    "end": "798720"
  },
  {
    "text": "we see in the past no jurors can scale up to 64 terabytes in term of the",
    "start": "798720",
    "end": "804120"
  },
  {
    "text": "operation it is very similar as audience Mexico which we already get used to and also we are really excited about some of",
    "start": "804120",
    "end": "812310"
  },
  {
    "text": "the features or roller features which is not available in a standard Mexico built",
    "start": "812310",
    "end": "817340"
  },
  {
    "text": "given all of this we decided to evaluating rola first you want to",
    "start": "817340",
    "end": "824880"
  },
  {
    "start": "823000",
    "end": "982000"
  },
  {
    "text": "evaluate in Rolla we build up evaluation metrics which can be categorized into",
    "start": "824880",
    "end": "830220"
  },
  {
    "text": "four different buckets performance compatibility failure scenario and operation overhead in performance we",
    "start": "830220",
    "end": "839310"
  },
  {
    "text": "were first evaluating latency meaning that given a same production workload or Ola needs to be on power of faster",
    "start": "839310",
    "end": "846450"
  },
  {
    "text": "compared with audience Mexico we also evaluating in support the definitions of throughput",
    "start": "846450",
    "end": "852480"
  },
  {
    "text": "given a latency threshold how much mock-ups can a ruler take in terms of",
    "start": "852480",
    "end": "858420"
  },
  {
    "text": "read and writes in a compatibility assertions want to making sure that from",
    "start": "858420",
    "end": "863490"
  },
  {
    "text": "our client Ruby and Java client point of view or Ola is no different than a normal Mexico instances we also studied",
    "start": "863490",
    "end": "871250"
  },
  {
    "text": "isolation transaction isolation in the hope that all existing databases transaction will have the same semantics",
    "start": "871250",
    "end": "877920"
  },
  {
    "text": "as before we also tested it durability setting meaning that during a massive",
    "start": "877920",
    "end": "883350"
  },
  {
    "text": "fail over over la do not lose more data compared with audience mexico we also",
    "start": "883350",
    "end": "889350"
  },
  {
    "text": "have a lot of truly imbued around Mexico for instance we use Mexico pinlock to do",
    "start": "889350",
    "end": "896640"
  },
  {
    "text": "change capture system to send Mexico Bing log into the rest of album B's",
    "start": "896640",
    "end": "901680"
  },
  {
    "text": "infrastructure in addition to that we have script monitor script to pull in",
    "start": "901680",
    "end": "907770"
  },
  {
    "text": "ODB stats and sending these monitoring metrics into our monitoring systems in",
    "start": "907770",
    "end": "913620"
  },
  {
    "text": "addition to that we use extensively my dumper my loader to do logical databases",
    "start": "913620",
    "end": "919080"
  },
  {
    "text": "backup we hope all of these tools will still work in addition to that we",
    "start": "919080",
    "end": "924810"
  },
  {
    "text": "studied a lot of failure scenarios which we often commonly see in audience Mexico take master fear over for example we",
    "start": "924810",
    "end": "932160"
  },
  {
    "text": "want to calculate how long does it take for both or rola and arias Mexico perform masterful over",
    "start": "932160",
    "end": "937879"
  },
  {
    "text": "in the last section or personal overhead we study the most common operations we",
    "start": "937879",
    "end": "944819"
  },
  {
    "text": "do for instance quick cluster create replicas and doing point in time recover in hope that on the operational side or",
    "start": "944819",
    "end": "952740"
  },
  {
    "text": "Allah would perform much better now I'm going to hand over to Robin to cover the",
    "start": "952740",
    "end": "957870"
  },
  {
    "text": "rest of the sections hello everyone my",
    "start": "957870",
    "end": "968459"
  },
  {
    "text": "name is Ruby Lee I'm a software engineer working on the aura migration so I'm gonna talk about",
    "start": "968459",
    "end": "974519"
  },
  {
    "text": "some of the technical details on how we evaluate and migrate or so so what we",
    "start": "974519",
    "end": "984000"
  },
  {
    "start": "982000",
    "end": "1017000"
  },
  {
    "text": "care most about is the perfect or as performance for performance testing we use a tool called EB replay DB replay is",
    "start": "984000",
    "end": "991170"
  },
  {
    "text": "an in-house developed load testing framework it's a tool to test against production workload without actually",
    "start": "991170",
    "end": "997079"
  },
  {
    "text": "putting your DB into production so we can use T be repaid who straight has the database with 1x to 10x workload in the",
    "start": "997079",
    "end": "1005509"
  },
  {
    "text": "past it helped us to do a database Headroom projection and right now we are we are also using it to verify new",
    "start": "1005509",
    "end": "1013069"
  },
  {
    "text": "infrastructure projects like the or run migration so this is the high-level overview of",
    "start": "1013069",
    "end": "1019699"
  },
  {
    "start": "1017000",
    "end": "1080000"
  },
  {
    "text": "the DB replay so in production we have running applications and encouraged for",
    "start": "1019699",
    "end": "1025069"
  },
  {
    "text": "the production databases at the same time they are also logging the exact the",
    "start": "1025069",
    "end": "1030168"
  },
  {
    "text": "actual cycle queries they made to a deep database to the Kafka queue we have a daily job to restore the instances from",
    "start": "1030169",
    "end": "1037428"
  },
  {
    "text": "production databases backups and those instances will be used to test against TB replay a 2-star a DB",
    "start": "1037429",
    "end": "1045260"
  },
  {
    "text": "replay test we go to the DB repair controller web application and create a",
    "start": "1045260",
    "end": "1051110"
  },
  {
    "text": "test job the test job will spawn multiple TB play workers depending on how many times or production work law we",
    "start": "1051110",
    "end": "1057799"
  },
  {
    "text": "want to replay and the workers will consume event from the Kafka queue and get a Seco carries all of it",
    "start": "1057799",
    "end": "1064340"
  },
  {
    "text": "and then send the queries to typically instances we want to test",
    "start": "1064340",
    "end": "1070390"
  },
  {
    "text": "while the job is running we can monitor the performance using car wash and",
    "start": "1070390",
    "end": "1075530"
  },
  {
    "text": "bicycle metrics from our database or dashboard this is the UI of the group",
    "start": "1075530",
    "end": "1082820"
  },
  {
    "start": "1080000",
    "end": "1120000"
  },
  {
    "text": "Hsu to give an idea of how it looks like first of all you can specify the source database workload you want to overplay",
    "start": "1082820",
    "end": "1089240"
  },
  {
    "text": "and then the target database host name you want to replay the workload on and",
    "start": "1089240",
    "end": "1094480"
  },
  {
    "text": "then you can provide a starting incremental and ending load multiplier",
    "start": "1094480",
    "end": "1099500"
  },
  {
    "text": "for example we can just put starting low 1x starting no s1 incremental load 0.01",
    "start": "1099500",
    "end": "1107840"
  },
  {
    "text": "per minutes and ending low 4 and then you put the duration of the test and",
    "start": "1107840",
    "end": "1113030"
  },
  {
    "text": "finally you can say replay the queries start from the given timestamp we test",
    "start": "1113030",
    "end": "1121460"
  },
  {
    "start": "1120000",
    "end": "1180000"
  },
  {
    "text": "the one of our write heavy workload using DP replay and here is how we compare Mexico or a side-by-side the",
    "start": "1121460",
    "end": "1130400"
  },
  {
    "text": "blue line represents Aurora and the purple line represents bicycle five-seven we ran four times of",
    "start": "1130400",
    "end": "1136370"
  },
  {
    "text": "production workload which which is around three thirty thousand QBs and the",
    "start": "1136370",
    "end": "1141620"
  },
  {
    "text": "yellow dashed line was the current production were low which is near 8000 GPS both Aurora and Mexico were running",
    "start": "1141620",
    "end": "1149840"
  },
  {
    "text": "on our three a like a X large instances and mastico instance has the max RI off",
    "start": "1149840",
    "end": "1155390"
  },
  {
    "text": "settings we are sending we are sending a same QPS to both instances if you look",
    "start": "1155390",
    "end": "1160400"
  },
  {
    "text": "at the total QPS graph on upper left the",
    "start": "1160400",
    "end": "1165650"
  },
  {
    "text": "two lines actually overlaps which means they are getting the same amount of traffic however on the right hand side",
    "start": "1165650",
    "end": "1171340"
  },
  {
    "text": "you can see that Ora performed much better in terms of clients are we right latency here's the",
    "start": "1171340",
    "end": "1181610"
  },
  {
    "start": "1180000",
    "end": "1221000"
  },
  {
    "text": "performance metrics summer week off from the right heavy load tests we saw Ora has two times of real hair room and four",
    "start": "1181610",
    "end": "1189110"
  },
  {
    "text": "times of right Headroom compared to audience Mexico the Headroom the term",
    "start": "1189110",
    "end": "1194450"
  },
  {
    "text": "Headroom here means that the maximum throughput we can achieve while keeping the latency",
    "start": "1194450",
    "end": "1199830"
  },
  {
    "text": "in our our SLA under the same throughput or us right latency is 75 percent lower",
    "start": "1199830",
    "end": "1206940"
  },
  {
    "text": "than my sickle priests know that is this number these numbers are only for",
    "start": "1206940",
    "end": "1213179"
  },
  {
    "text": "specific world oh we are testing you may see different results for your specific workload and we also did a lot of non",
    "start": "1213179",
    "end": "1223799"
  },
  {
    "start": "1221000",
    "end": "1337000"
  },
  {
    "text": "performance testings and here's the test summary we verify that my aura is fully",
    "start": "1223799",
    "end": "1229289"
  },
  {
    "text": "compatible with Ruby to clients and JDBC and it has the same transaction isolation behavior as my sickle in a",
    "start": "1229289",
    "end": "1237090"
  },
  {
    "text": "crash event all are does not lose any beam lock and also provides comparable",
    "start": "1237090",
    "end": "1242519"
  },
  {
    "text": "cloud watch and my second matrix as RDS my sickle aura is fully compatible with",
    "start": "1242519",
    "end": "1248970"
  },
  {
    "text": "some of some of the common toolings who are using such as my secure pin lock my temper and antara fall during the",
    "start": "1248970",
    "end": "1256889"
  },
  {
    "text": "evaluation we didn't observe any network blips and for one of our largest",
    "start": "1256889",
    "end": "1263159"
  },
  {
    "text": "database cluster the time to do a masterful over went down from 2 minutes to 20 seconds in a time to create a real",
    "start": "1263159",
    "end": "1271110"
  },
  {
    "text": "replicas went down from one day to 5 minutes and a time to do a point in time we restore went down from 10 hours to",
    "start": "1271110",
    "end": "1278340"
  },
  {
    "text": "one hour another nice property about app idea or a speed here is that it has the",
    "start": "1278340",
    "end": "1285029"
  },
  {
    "text": "restore instances the restore engine switch maximum performance immediately",
    "start": "1285029",
    "end": "1290130"
  },
  {
    "text": "and we don't need to we don't know to a warm-up like the like the EBS before we",
    "start": "1290130",
    "end": "1300269"
  },
  {
    "text": "started a full-scale migration we want to por hora in production with relatively low risk and we decide to use",
    "start": "1300269",
    "end": "1307110"
  },
  {
    "text": "or we replicas to serve we traffic we went or are we replicas on our",
    "start": "1307110",
    "end": "1315000"
  },
  {
    "text": "biggest database clusters for a month just to test its stability in the real production environment we observe note",
    "start": "1315000",
    "end": "1322049"
  },
  {
    "text": "with her during the or our evaluation this is a big win for us because that means by switch with Laura we can",
    "start": "1322049",
    "end": "1328770"
  },
  {
    "text": "eliminate 10% of our total downtime now let's let me talk about actual",
    "start": "1328770",
    "end": "1336309"
  },
  {
    "text": "migration so we have some high-level requirements for the migration first of all migration should minimize",
    "start": "1336309",
    "end": "1344190"
  },
  {
    "start": "1337000",
    "end": "1395000"
  },
  {
    "text": "disruptions on end users and our product teams a few months ago we finished a",
    "start": "1344190",
    "end": "1350559"
  },
  {
    "text": "project who migrated RDS instances into VPC we used to take down the whole site",
    "start": "1350559",
    "end": "1355990"
  },
  {
    "text": "for 20 minutes of maintenance and then favorite dozens of clusters at the same time this is a highly risky error-prone",
    "start": "1355990",
    "end": "1363370"
  },
  {
    "text": "stressful operation and was not a great experience for everyone involved at this",
    "start": "1363370",
    "end": "1369100"
  },
  {
    "text": "time for our migration one we want to do something better secondly the migration should be",
    "start": "1369100",
    "end": "1374920"
  },
  {
    "text": "scalable enough to handle 100 plus clusters the micro issues have a",
    "start": "1374920",
    "end": "1380620"
  },
  {
    "text": "well-defined process and should be automated in most parts similarly because there are so many work to do",
    "start": "1380620",
    "end": "1387090"
  },
  {
    "text": "finally the migration should be reversible we want to have a way to fall back to RDS bicycle if anything goes",
    "start": "1387090",
    "end": "1393280"
  },
  {
    "text": "wrong let me share with you our migration timeline we started the hora",
    "start": "1393280",
    "end": "1400179"
  },
  {
    "start": "1395000",
    "end": "1446000"
  },
  {
    "text": "evaluation on July 2017 and then in September we finish the evaluation and",
    "start": "1400179",
    "end": "1406929"
  },
  {
    "text": "we started to run over we replicas in production in October we migrated the",
    "start": "1406929",
    "end": "1412780"
  },
  {
    "text": "field most important masters - Aurora - to test the failover process while still",
    "start": "1412780",
    "end": "1419830"
  },
  {
    "text": "keeping the audience magical fleet at this time we can still the river we can still revert the migration if necessary",
    "start": "1419830",
    "end": "1425860"
  },
  {
    "text": "in December we are gonna fail over all the masters while keeping the audience",
    "start": "1425860",
    "end": "1431080"
  },
  {
    "text": "medical fleet we're gonna fulfill 4 months and if anything if everything",
    "start": "1431080",
    "end": "1438220"
  },
  {
    "text": "goes well we will gradually start deleting the RDS Mexico instances since",
    "start": "1438220",
    "end": "1448570"
  },
  {
    "start": "1446000",
    "end": "1512000"
  },
  {
    "text": "we have one to pass classes through migrate we need a scalable way to manage those audience instances Airbnb we use",
    "start": "1448570",
    "end": "1455950"
  },
  {
    "text": "terraform to manage RDS resource recode the right hand side is the code that describes one of our biggest aura",
    "start": "1455950",
    "end": "1463000"
  },
  {
    "text": "clusters the cold describes the cluster with one",
    "start": "1463000",
    "end": "1468260"
  },
  {
    "text": "master and six replicas and some of the parameter group settings when we commit",
    "start": "1468260",
    "end": "1473630"
  },
  {
    "text": "a code we have a Jenkins job to run terraform and automatically create update and delete the resources based on",
    "start": "1473630",
    "end": "1480170"
  },
  {
    "text": "your change by committing this code terraform will automatically create one",
    "start": "1480170",
    "end": "1486350"
  },
  {
    "text": "or our cluster one master instance six replicas one DB prime the group and one",
    "start": "1486350",
    "end": "1491840"
  },
  {
    "text": "DB plus a parameter called automatically for you he saves us from creating a lot",
    "start": "1491840",
    "end": "1497990"
  },
  {
    "text": "of patterns on AWS console since all the changes are made through code you can",
    "start": "1497990",
    "end": "1506000"
  },
  {
    "text": "actually track the complete history of the changes in the version control system now after all the all our classes",
    "start": "1506000",
    "end": "1514760"
  },
  {
    "start": "1512000",
    "end": "1541000"
  },
  {
    "text": "are created the are using terraform the next thing to do is to Tom data we use a",
    "start": "1514760",
    "end": "1520160"
  },
  {
    "text": "tool called my dumper which is a faster paralyzed magical dump the reason why we do this is because we have many magical",
    "start": "1520160",
    "end": "1526640"
  },
  {
    "text": "five seven clusters creating aura replicas through a table console API was",
    "start": "1526640",
    "end": "1531770"
  },
  {
    "text": "not supported yet after the beta tom is finished we said we setup applications",
    "start": "1531770",
    "end": "1537680"
  },
  {
    "text": "from earliest magical tour the next",
    "start": "1537680",
    "end": "1542960"
  },
  {
    "start": "1541000",
    "end": "1588000"
  },
  {
    "text": "stage is to ship sleigh traffic from audience Mexico to Ora this is such a low-risk way to get",
    "start": "1542960",
    "end": "1550760"
  },
  {
    "text": "experience of running or raw in production which angel application to",
    "start": "1550760",
    "end": "1556310"
  },
  {
    "text": "risk to send sleigh traffic to send Slade traffic away from Mexico replicas",
    "start": "1556310",
    "end": "1564110"
  },
  {
    "text": "or replicas while still sending the message traffic to my cycle masters the",
    "start": "1564110",
    "end": "1569390"
  },
  {
    "text": "aura master is sync with magical master we've been lot replication if there is an issue we can just revert the change",
    "start": "1569390",
    "end": "1576080"
  },
  {
    "text": "with our effort in data integrity we run this setting for our biggest DB clusters",
    "start": "1576080",
    "end": "1581240"
  },
  {
    "text": "for a month now the tricky part is how do we migrate a master right traffic with minimum downtime we came up with a",
    "start": "1581240",
    "end": "1590000"
  },
  {
    "start": "1588000",
    "end": "1644000"
  },
  {
    "text": "pretty nice solution with the help of DB proxy the main benefit of DB proxy is to",
    "start": "1590000",
    "end": "1596380"
  },
  {
    "text": "decoupled applications from the underlying database infrastructure we",
    "start": "1596380",
    "end": "1601810"
  },
  {
    "text": "are using a fork of the open-source Mac scale DB proxy including several in-house develop features like the",
    "start": "1601810",
    "end": "1608650"
  },
  {
    "text": "configurable connection pooling request rattling and back pressure blacklist",
    "start": "1608650",
    "end": "1614560"
  },
  {
    "text": "query introjection and most importantly fast connection refresh I want to",
    "start": "1614560",
    "end": "1619660"
  },
  {
    "text": "highlight fast connection refresh here because it helped us a lot to in reducing downtime during the master",
    "start": "1619660",
    "end": "1625210"
  },
  {
    "text": "migration I will talk about this in a little bit we deploy DB proceeding in",
    "start": "1625210",
    "end": "1632170"
  },
  {
    "text": "ec2 instances and pull it in the middle of the applications and databases it's the stylus service so that we can",
    "start": "1632170",
    "end": "1639190"
  },
  {
    "text": "scour horizontally with capacity increase now let's take a dig deeper",
    "start": "1639190",
    "end": "1646420"
  },
  {
    "text": "look at how the proxy was set up to realize fast connection refresh the DB proxy was configured with two connection",
    "start": "1646420",
    "end": "1653170"
  },
  {
    "text": "pools which creates persistent connection to my Sakura respectively however only one of that connection pool",
    "start": "1653170",
    "end": "1660580"
  },
  {
    "text": "is active at any given time the proxy determines which probes connection for is active party telling the current",
    "start": "1660580",
    "end": "1667240"
  },
  {
    "text": "replication topology it will only activate the pool for the master of the replication topology the current",
    "start": "1667240",
    "end": "1674620"
  },
  {
    "text": "connections are connected to D deep are connected to a DB proxy and there is a router that routes the client queries to",
    "start": "1674620",
    "end": "1681760"
  },
  {
    "text": "the current active connection pool when the replication topology changes the DB",
    "start": "1681760",
    "end": "1689380"
  },
  {
    "text": "proxy quickly detects the change and almost instantaneously Ralph's queries for the alternative progressive",
    "start": "1689380",
    "end": "1695560"
  },
  {
    "text": "connection pool the client doesn't know anything about it like it's always talking to the same database because the",
    "start": "1695560",
    "end": "1701920"
  },
  {
    "text": "client connection don't close it takes only 10 seconds to ship all the courage",
    "start": "1701920",
    "end": "1708250"
  },
  {
    "text": "to the alternative connect connection pool the process is extremely fast because the persistent connection were",
    "start": "1708250",
    "end": "1714790"
  },
  {
    "text": "already created and there is no extra overhead of creating new connections from the clients lon now let's zoom out",
    "start": "1714790",
    "end": "1723370"
  },
  {
    "start": "1721000",
    "end": "1848000"
  },
  {
    "text": "a little bit and see how we apply the epoxy in the master migration we drop DB policy in the middle of application",
    "start": "1723370",
    "end": "1729010"
  },
  {
    "text": "databases we configure the proxy to manage to pack ends the or Massacre master and/or a",
    "start": "1729010",
    "end": "1735429"
  },
  {
    "text": "master the worst thing happened during a migration is losing data we need to make",
    "start": "1735429",
    "end": "1740979"
  },
  {
    "text": "sure that any given time we are making rise to either my cycle or aura but not",
    "start": "1740979",
    "end": "1746739"
  },
  {
    "text": "both the aura team provided us a special store procedure called set re only which",
    "start": "1746739",
    "end": "1753429"
  },
  {
    "text": "effectively rejects all the rights first we write lock the my secure master by",
    "start": "1753429",
    "end": "1760329"
  },
  {
    "text": "setting really two one this will prevent all the rights from the applications but",
    "start": "1760329",
    "end": "1767409"
  },
  {
    "text": "reads will still be fine the applications will start seeing my errors from from this point since there",
    "start": "1767409",
    "end": "1776379"
  },
  {
    "text": "is no rightful my cycle master after with every only two one we wait for Laura to catch her replication and then",
    "start": "1776379",
    "end": "1784029"
  },
  {
    "text": "we reverse the replication promoter or a master a prologue promote ora as master",
    "start": "1784029",
    "end": "1789459"
  },
  {
    "text": "and Mexico as or our slave the DB proxy quickly detects the replication topology",
    "start": "1789459",
    "end": "1795129"
  },
  {
    "text": "has changed and then started around massive traffic to Ora the whole process can be finished under 10 seconds and",
    "start": "1795129",
    "end": "1802649"
  },
  {
    "text": "then the application was stopped seeing why errors we keep my cycle master right",
    "start": "1802649",
    "end": "1808599"
  },
  {
    "text": "locked to prevent unexpected rice going through my the master migration only",
    "start": "1808599",
    "end": "1819129"
  },
  {
    "text": "creates less than one minutes of the write down time and there were no we don't come at all",
    "start": "1819129",
    "end": "1824950"
  },
  {
    "text": "my sicko is still sync with or after the migration we're gonna keep this setting",
    "start": "1824950",
    "end": "1830169"
  },
  {
    "text": "for for a month so if any issue comes off we can revert the migration without",
    "start": "1830169",
    "end": "1835239"
  },
  {
    "text": "losing any data once we verify that there is no more errors from the application side we'll repeat this for",
    "start": "1835239",
    "end": "1842229"
  },
  {
    "text": "repeat this process for every other clusters so far we have migrated 25% of",
    "start": "1842229",
    "end": "1851409"
  },
  {
    "start": "1848000",
    "end": "1886000"
  },
  {
    "text": "our our database clusters which represents 70% of our total database",
    "start": "1851409",
    "end": "1857589"
  },
  {
    "text": "traffic our strategy here is to migrate the biggest and most important",
    "start": "1857589",
    "end": "1863430"
  },
  {
    "text": "clusters to deliver the most impact and also address the immediate penguin from",
    "start": "1863430",
    "end": "1869290"
  },
  {
    "text": "our team there are long hair of Angela's clusters we are either there are either",
    "start": "1869290",
    "end": "1875440"
  },
  {
    "text": "internal usages or honest or not Serena core business logic and we will migrate",
    "start": "1875440",
    "end": "1880870"
  },
  {
    "text": "them gradually in the next few months now in Christian future work here's a",
    "start": "1880870",
    "end": "1889000"
  },
  {
    "start": "1886000",
    "end": "1911000"
  },
  {
    "text": "quick recap of all the measurable benefits of adopting Aurora we gain a",
    "start": "1889000",
    "end": "1895150"
  },
  {
    "text": "significant amount of wicked and white hair rooms we eliminate all the jitters we we have a small and stable",
    "start": "1895150",
    "end": "1903010"
  },
  {
    "text": "replication lag and we save a lot of time in some of the common database",
    "start": "1903010",
    "end": "1908140"
  },
  {
    "text": "operations we just started to use or aura for having really leverage some of",
    "start": "1908140",
    "end": "1915910"
  },
  {
    "text": "the cool features in aura yet sometimes we need to run some expensive one-off",
    "start": "1915910",
    "end": "1921910"
  },
  {
    "text": "queries or other crazy things against the real-time data with auras chrome",
    "start": "1921910",
    "end": "1926920"
  },
  {
    "text": "feature we can't quickly spin up a chrome instance within five minutes and then they did after use currently we",
    "start": "1926920",
    "end": "1935170"
  },
  {
    "text": "have some online schema changes that can take hours or days to finish the first",
    "start": "1935170",
    "end": "1940990"
  },
  {
    "text": "DDL we can I believe it can definitely help a lot in some other cases will have",
    "start": "1940990",
    "end": "1949390"
  },
  {
    "text": "a requirement to pack up data into s3 for disaster recovery or are suppose in",
    "start": "1949390",
    "end": "1955450"
  },
  {
    "text": "loading data directly into s3 so it will be more convenient than a Mexico dump so",
    "start": "1955450",
    "end": "1963640"
  },
  {
    "start": "1963000",
    "end": "2020000"
  },
  {
    "text": "that's the talk thank you for joining us",
    "start": "1963640",
    "end": "1969120"
  },
  {
    "text": "[Applause]",
    "start": "1969580",
    "end": "1973169"
  },
  {
    "text": "so hopefully that gave you a good sense of how Airbnb was able to scale they workloads with Aurora and eliminate some",
    "start": "1975010",
    "end": "1982760"
  },
  {
    "text": "of the problems that they were seen earlier really getting web scale performance web scale availability and",
    "start": "1982760",
    "end": "1988040"
  },
  {
    "text": "also a ton of operational benefit in terms of just all the things that you'd have to do as a DBA and not just that",
    "start": "1988040",
    "end": "1995390"
  },
  {
    "text": "but also how they were very methodical about thinking how do you actually evaluate one of your database targets",
    "start": "1995390",
    "end": "2001600"
  },
  {
    "text": "and once you made a choice how do you make sure that you can migrate with as little or no disruption to your web",
    "start": "2001600",
    "end": "2007480"
  },
  {
    "text": "scale workloads so we're gonna stick around we have a few minutes left still so please if you have any questions find",
    "start": "2007480",
    "end": "2014740"
  },
  {
    "text": "us jigna Reuben and I will be here and thank you again to genera bunk for",
    "start": "2014740",
    "end": "2020660"
  },
  {
    "text": "[Applause]",
    "start": "2020660",
    "end": "2022819"
  }
]
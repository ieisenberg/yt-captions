[
  {
    "text": "[Music]",
    "start": "440",
    "end": "2760"
  },
  {
    "text": "hey everyone my name is Nathan Peck and",
    "start": "6750",
    "end": "9430"
  },
  {
    "text": "I'm a developer advocate for ec2",
    "start": "9430",
    "end": "11139"
  },
  {
    "text": "container service in the last couple",
    "start": "11139",
    "end": "13330"
  },
  {
    "text": "segments we took an initial look at the",
    "start": "13330",
    "end": "15190"
  },
  {
    "text": "core concepts of ECS and then covered",
    "start": "15190",
    "end": "17710"
  },
  {
    "text": "how to get network traffic to your",
    "start": "17710",
    "end": "19180"
  },
  {
    "text": "containers using an application load",
    "start": "19180",
    "end": "20980"
  },
  {
    "text": "balancer which is automatically managed",
    "start": "20980",
    "end": "22810"
  },
  {
    "text": "by UCS once you have your containers",
    "start": "22810",
    "end": "24550"
  },
  {
    "text": "running on ECS an HTTP request flowing",
    "start": "24550",
    "end": "26829"
  },
  {
    "text": "into your containers the next step is",
    "start": "26829",
    "end": "28180"
  },
  {
    "text": "scaling most services will see variable",
    "start": "28180",
    "end": "30640"
  },
  {
    "text": "request volume throughout the day and",
    "start": "30640",
    "end": "32320"
  },
  {
    "text": "week fortunately ECS has auto scaling",
    "start": "32320",
    "end": "35020"
  },
  {
    "text": "features built in that are designed to",
    "start": "35020",
    "end": "36850"
  },
  {
    "text": "help your ECS managed services react to",
    "start": "36850",
    "end": "39160"
  },
  {
    "text": "variable conditions in this panel you",
    "start": "39160",
    "end": "41019"
  },
  {
    "text": "can see the ECS has been capturing",
    "start": "41019",
    "end": "42910"
  },
  {
    "text": "statistics such as CPU utilization and",
    "start": "42910",
    "end": "45519"
  },
  {
    "text": "memory load for my service these stats",
    "start": "45519",
    "end": "48730"
  },
  {
    "text": "are all being piped into cloud watch and",
    "start": "48730",
    "end": "50879"
  },
  {
    "text": "here you can see that I've created based",
    "start": "50879",
    "end": "54370"
  },
  {
    "text": "on these stats and these alarms are tied",
    "start": "54370",
    "end": "56440"
  },
  {
    "text": "to scaling actions",
    "start": "56440",
    "end": "57579"
  },
  {
    "text": "so when CPU utilization for the service",
    "start": "57579",
    "end": "60579"
  },
  {
    "text": "is greater than 70% ECS will",
    "start": "60579",
    "end": "63070"
  },
  {
    "text": "automatically launch another task but if",
    "start": "63070",
    "end": "65530"
  },
  {
    "text": "the CPU usage dips below 20% then it",
    "start": "65530",
    "end": "68740"
  },
  {
    "text": "will start removing tasks from the",
    "start": "68740",
    "end": "70150"
  },
  {
    "text": "service to free up capacity on the",
    "start": "70150",
    "end": "71710"
  },
  {
    "text": "cluster to be used for other purposes",
    "start": "71710",
    "end": "72970"
  },
  {
    "text": "let's see what this auto scaling looks",
    "start": "72970",
    "end": "74950"
  },
  {
    "text": "like when the service is under load in",
    "start": "74950",
    "end": "76479"
  },
  {
    "text": "this dashboard I created you can see an",
    "start": "76479",
    "end": "78490"
  },
  {
    "text": "overview of all the stats for all of the",
    "start": "78490",
    "end": "80439"
  },
  {
    "text": "services in the cluster in one place you",
    "start": "80439",
    "end": "82869"
  },
  {
    "text": "can see from this request count graph at",
    "start": "82869",
    "end": "84520"
  },
  {
    "text": "the top that I'm currently running a",
    "start": "84520",
    "end": "85750"
  },
  {
    "text": "load test that ramps up every 30 minutes",
    "start": "85750",
    "end": "87939"
  },
  {
    "text": "to approximately 60,000 requests per",
    "start": "87939",
    "end": "90700"
  },
  {
    "text": "minute but this total request volume is",
    "start": "90700",
    "end": "92710"
  },
  {
    "text": "being distributed across a number of",
    "start": "92710",
    "end": "94119"
  },
  {
    "text": "different services so this pink service",
    "start": "94119",
    "end": "97030"
  },
  {
    "text": "is doing roughly 6,000 requests per",
    "start": "97030",
    "end": "99789"
  },
  {
    "text": "minute whereas the purple service is",
    "start": "99789",
    "end": "101619"
  },
  {
    "text": "doing 13,000 requests per minute and",
    "start": "101619",
    "end": "103719"
  },
  {
    "text": "some of these services are doing more",
    "start": "103719",
    "end": "105670"
  },
  {
    "text": "CPU intensive jobs for example the auth",
    "start": "105670",
    "end": "108909"
  },
  {
    "text": "service has to do ten round bcrypt",
    "start": "108909",
    "end": "111340"
  },
  {
    "text": "hashing of password plain ticks in order",
    "start": "111340",
    "end": "113350"
  },
  {
    "text": "to validate login attempts that's a very",
    "start": "113350",
    "end": "115299"
  },
  {
    "text": "CPU intensive task each service is going",
    "start": "115299",
    "end": "117820"
  },
  {
    "text": "to have a different level of CPU demand",
    "start": "117820",
    "end": "119799"
  },
  {
    "text": "that grows a different rate as the load",
    "start": "119799",
    "end": "121840"
  },
  {
    "text": "test progresses so each service also has",
    "start": "121840",
    "end": "125079"
  },
  {
    "text": "its own auto scaling policies that are",
    "start": "125079",
    "end": "126909"
  },
  {
    "text": "operating independently and that's what",
    "start": "126909",
    "end": "128860"
  },
  {
    "text": "you can see from this graph of CPU",
    "start": "128860",
    "end": "130270"
  },
  {
    "text": "utilization per service the graph looks",
    "start": "130270",
    "end": "132310"
  },
  {
    "text": "somewhat sawtooth each time the CPU for",
    "start": "132310",
    "end": "135220"
  },
  {
    "text": "a particular service crosses the",
    "start": "135220",
    "end": "136660"
  },
  {
    "text": "threshold it drops back down again as",
    "start": "136660",
    "end": "138880"
  },
  {
    "text": "ECS launches work into",
    "start": "138880",
    "end": "140350"
  },
  {
    "text": "to distribute the load across if the",
    "start": "140350",
    "end": "142780"
  },
  {
    "text": "requests volume drops back down it will",
    "start": "142780",
    "end": "144700"
  },
  {
    "text": "cause the CPU usage metric to drop as",
    "start": "144700",
    "end": "146860"
  },
  {
    "text": "well and ECS will respond by scaling",
    "start": "146860",
    "end": "149470"
  },
  {
    "text": "back the number of containers this auto",
    "start": "149470",
    "end": "151900"
  },
  {
    "text": "scaling integrates seamlessly with the",
    "start": "151900",
    "end": "153490"
  },
  {
    "text": "application load balancer to avoid",
    "start": "153490",
    "end": "155050"
  },
  {
    "text": "dropped requests when ECS is scaling",
    "start": "155050",
    "end": "157600"
  },
  {
    "text": "your service down it transitions one or",
    "start": "157600",
    "end": "159400"
  },
  {
    "text": "more containers into a draining state so",
    "start": "159400",
    "end": "161530"
  },
  {
    "text": "that the load balancer have stops on a",
    "start": "161530",
    "end": "162760"
  },
  {
    "text": "new request to that container once the",
    "start": "162760",
    "end": "164560"
  },
  {
    "text": "container has finished handling all",
    "start": "164560",
    "end": "166000"
  },
  {
    "text": "in-flight connections UCS stops the",
    "start": "166000",
    "end": "168310"
  },
  {
    "text": "container in summary UCS has auto",
    "start": "168310",
    "end": "170560"
  },
  {
    "text": "scaling abilities that give you another",
    "start": "170560",
    "end": "172180"
  },
  {
    "text": "level of auto scaling beyond just the",
    "start": "172180",
    "end": "174250"
  },
  {
    "text": "number of instances you run UCS auto",
    "start": "174250",
    "end": "176860"
  },
  {
    "text": "scaling is ideal for use with reserved",
    "start": "176860",
    "end": "178720"
  },
  {
    "text": "instances to get the most value out of",
    "start": "178720",
    "end": "181180"
  },
  {
    "text": "your reserved instances you want to run",
    "start": "181180",
    "end": "183100"
  },
  {
    "text": "them at all times but you also want to",
    "start": "183100",
    "end": "184930"
  },
  {
    "text": "get the best utilization out of them by",
    "start": "184930",
    "end": "187150"
  },
  {
    "text": "scaling services up and down UCS can",
    "start": "187150",
    "end": "189400"
  },
  {
    "text": "ensure that your reserved instances are",
    "start": "189400",
    "end": "191020"
  },
  {
    "text": "being well utilized throughout the day",
    "start": "191020",
    "end": "192580"
  },
  {
    "text": "by different workloads perhaps web",
    "start": "192580",
    "end": "194890"
  },
  {
    "text": "traffic during the day and background",
    "start": "194890",
    "end": "196780"
  },
  {
    "text": "batch processing at night and best of",
    "start": "196780",
    "end": "199120"
  },
  {
    "text": "all UCS automates everything so that",
    "start": "199120",
    "end": "201370"
  },
  {
    "text": "it's hands-off no developer intervention",
    "start": "201370",
    "end": "203230"
  },
  {
    "text": "required thanks for watching",
    "start": "203230",
    "end": "206970"
  },
  {
    "text": "you",
    "start": "210830",
    "end": "212890"
  }
]
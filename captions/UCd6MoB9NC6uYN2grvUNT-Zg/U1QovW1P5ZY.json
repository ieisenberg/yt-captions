[
  {
    "text": "hello and welcome to TiVo how to scale new products with a data Lake on AWS and cue-ball my name is Paul Sears I'm a",
    "start": "30",
    "end": "7140"
  },
  {
    "text": "partner solution architect for Amazon Web Services and I will be your host and moderator for today's presentation when",
    "start": "7140",
    "end": "14250"
  },
  {
    "text": "you join today's webinar you selected to join by either phone call or your computer audio if for any reason you",
    "start": "14250",
    "end": "20520"
  },
  {
    "text": "would like to change your audio selection you can do so by accessing the your audio pan pane in the control panel",
    "start": "20520",
    "end": "27449"
  },
  {
    "text": "from this control panel you will also have the opportunity to submit questions to today's presenters by typing your",
    "start": "27449",
    "end": "34440"
  },
  {
    "text": "questions into the questions panel we will collect the questions and address as many as we can during the Q&A session",
    "start": "34440",
    "end": "40890"
  },
  {
    "text": "at the end of today's presentation also at the end of today's event is a brief survey please stay connected until the end of",
    "start": "40890",
    "end": "48180"
  },
  {
    "text": "the broadcast and submit your feedback as your opinions count lastly the PowerPoint presentation will",
    "start": "48180",
    "end": "54300"
  },
  {
    "text": "be available through SlideShare along with the recording of the webinar on YouTube sent via an email that will be",
    "start": "54300",
    "end": "61530"
  },
  {
    "text": "sent two to three days after the conclusion of the event so keep an eye out for the follow-up email sent to the",
    "start": "61530",
    "end": "68909"
  },
  {
    "text": "address you provided I will be your host and moderator for today's webinar in addition to learning about AWS we also",
    "start": "68909",
    "end": "76290"
  },
  {
    "text": "hear from harsh Jetley Solutions Architect with cue ball and Ashish Murray senior manager data analytics at",
    "start": "76290",
    "end": "83729"
  },
  {
    "text": "TiVo today we're going to present a",
    "start": "83729",
    "end": "89790"
  },
  {
    "text": "brief overview of AWS and AWS data Lake solutions harsh will provide an overview of cueball solutions and Ashish will",
    "start": "89790",
    "end": "97290"
  },
  {
    "text": "share challenges that tebow faced and how AWS and cubile gave them a path to",
    "start": "97290",
    "end": "102450"
  },
  {
    "text": "success and finally time permitting we will have Q&A at the end of this webinar",
    "start": "102450",
    "end": "108618"
  },
  {
    "text": "today you will learn how to dramatically reduce management complexities of big",
    "start": "109490",
    "end": "114659"
  },
  {
    "text": "data analytics operations in AWS you will learn best practices for optimizing",
    "start": "114659",
    "end": "119759"
  },
  {
    "text": "data Lakes for self-service analytics and enable teams to production-wise data science and accelerate data pipelines",
    "start": "119759",
    "end": "126049"
  },
  {
    "text": "you will also learn about using presto and q-ball's auto-scaling management and",
    "start": "126049",
    "end": "131430"
  },
  {
    "text": "spot instance bidding to reduce complexity cost and deployment time of big data",
    "start": "131430",
    "end": "136530"
  },
  {
    "text": "projects and remember please post your questions in the chat box throughout the presentation as we will review questions",
    "start": "136530",
    "end": "143220"
  },
  {
    "text": "at the end of today's event so let's talk about data lakes and AWS and how",
    "start": "143220",
    "end": "150480"
  },
  {
    "text": "they drive business value traditionally analytics data was stored",
    "start": "150480",
    "end": "156629"
  },
  {
    "text": "in a large data warehouse or a large relational database system however these systems are expensive to implement and",
    "start": "156629",
    "end": "162659"
  },
  {
    "text": "maintain and face significant challenges with scaling so what is another option",
    "start": "162659",
    "end": "169519"
  },
  {
    "text": "another option is to build a data Lake where you can store all your data in a",
    "start": "170510",
    "end": "175590"
  },
  {
    "text": "single large repository in this repository becomes your source of truth for all your data and analytics by",
    "start": "175590",
    "end": "182340"
  },
  {
    "text": "having all your data in one place you can discover insights that you may have missed when data is stored in different",
    "start": "182340",
    "end": "188430"
  },
  {
    "text": "systems so implementing data Lake is a",
    "start": "188430",
    "end": "193590"
  },
  {
    "text": "start of a journey to becoming a data-driven business you define your",
    "start": "193590",
    "end": "198780"
  },
  {
    "text": "business outcomes working backwards to modernize to your modern data architecture along the journey you can",
    "start": "198780",
    "end": "205079"
  },
  {
    "text": "experiment and explore in new ways while only paying for what you actually consume and this enables agility",
    "start": "205079",
    "end": "212400"
  },
  {
    "text": "allowing you to quickly adapt to new data sources and deployment of your infrastructure in minutes instead of",
    "start": "212400",
    "end": "218519"
  },
  {
    "text": "months when you implement a data Lake as part of a modern data architecture you",
    "start": "218519",
    "end": "225690"
  },
  {
    "text": "gain a number of beneficial business outcomes such as consolidation of your data into a single source of truth this",
    "start": "225690",
    "end": "232260"
  },
  {
    "text": "allows you to innovate for new revenues or leverage by leveraging relationships of data that you wouldn't otherwise be",
    "start": "232260",
    "end": "238560"
  },
  {
    "text": "able to use another outcome could be real-time engagement with an interactive and better customer experience and",
    "start": "238560",
    "end": "244829"
  },
  {
    "text": "building your analytics pipeline around your data lake facilitates automation across the organization now that you",
    "start": "244829",
    "end": "252810"
  },
  {
    "text": "have decided on implementing a data Lake what do you want do with the data data",
    "start": "252810",
    "end": "257820"
  },
  {
    "text": "lakes can be designed in there is ways but you need to understand your business case first and then work backwards",
    "start": "257820",
    "end": "263190"
  },
  {
    "text": "through the Analects pipeline that you implement as a modern data architect",
    "start": "263190",
    "end": "269330"
  },
  {
    "text": "the analytics pipeline allows you to experiment in scale as needed this data",
    "start": "272000",
    "end": "277290"
  },
  {
    "text": "becomes this data lake becomes a source that lets you derive your answers and insights regardless of the kind of data",
    "start": "277290",
    "end": "283830"
  },
  {
    "text": "that you want to use such as monitoring data or ERP transactions Amazon s3 is",
    "start": "283830",
    "end": "292530"
  },
  {
    "text": "ideal to use as a data lake and as the core of a modern data architecture Amazon s3 is extremely durable with 11-9",
    "start": "292530",
    "end": "299820"
  },
  {
    "text": "to durability this is very important when you have hundreds of terabytes or petabytes or more of data s3 is also",
    "start": "299820",
    "end": "306240"
  },
  {
    "text": "designed to be highly available with up to 99.9% of availability so you can",
    "start": "306240",
    "end": "311370"
  },
  {
    "text": "always access your data in terms of scale s3 is practically scaleless and you can store as much as you need and",
    "start": "311370",
    "end": "317550"
  },
  {
    "text": "more importantly you only pay for the amount of storage you are actually consuming as mentioning mentioned",
    "start": "317550",
    "end": "325980"
  },
  {
    "text": "previously traditional data warehouses and relational database systems are often limited by scale one of the",
    "start": "325980",
    "end": "331500"
  },
  {
    "text": "primary advantages of using a data Lake is that storage and computer no longer coupled together this allows you to",
    "start": "331500",
    "end": "337500"
  },
  {
    "text": "scale your compute needs as appropriate for your analytics workflows and you will learn more about this shortly a",
    "start": "337500",
    "end": "345199"
  },
  {
    "text": "data Lake is a central component of a modern data architecture on AWS this",
    "start": "345440",
    "end": "352320"
  },
  {
    "text": "provides a single repository that all your relation and non relation data can reside in Dana Lake is the source that",
    "start": "352320",
    "end": "358950"
  },
  {
    "text": "we consume by many highly interrupted inoperable services such as ETL processes or services to query your data",
    "start": "358950",
    "end": "366000"
  },
  {
    "text": "and tools that let you visualize your data and new ways to gain unique insight to drive your business forward",
    "start": "366000",
    "end": "372290"
  },
  {
    "text": "so now harsh from Cuba will talk about Cuba and Big Data activation for data",
    "start": "372290",
    "end": "377550"
  },
  {
    "text": "driven companies Thank You Baal",
    "start": "377550",
    "end": "383960"
  },
  {
    "text": "you",
    "start": "386390",
    "end": "388450"
  },
  {
    "text": "hi good morning I am hard shaky from cue ball I'm a Solutions Architect here and",
    "start": "392150",
    "end": "397430"
  },
  {
    "text": "today I'm going to talk to you about how cue ball can be used to derive insights and value from the data that resides",
    "start": "397430",
    "end": "403250"
  },
  {
    "text": "within your data leak as you see data teams are getting out over on today so",
    "start": "403250",
    "end": "409370"
  },
  {
    "text": "the needs with with the data that resides in your data like as that increases the number of users the types",
    "start": "409370",
    "end": "415220"
  },
  {
    "text": "of teams that want to interact with this data also increase it becomes really tough to Manly provision or manually",
    "start": "415220",
    "end": "422060"
  },
  {
    "text": "provision to get to that scale and along with that you have exploding data you",
    "start": "422060",
    "end": "427850"
  },
  {
    "text": "have workloads that keep on increasing and different kinds of data types that you're working with and this results in",
    "start": "427850",
    "end": "434090"
  },
  {
    "text": "missed SLA is and some people don't even get access to the data that they require",
    "start": "434090",
    "end": "440440"
  },
  {
    "text": "what sorry what this the consequence of",
    "start": "446880",
    "end": "454720"
  },
  {
    "text": "this is the activation gap so what we see is the needs of the users have increased and the use case have",
    "start": "454720",
    "end": "461319"
  },
  {
    "text": "increased but the IT budgets in the Big Data skills remain stagnant of flat so",
    "start": "461319",
    "end": "466810"
  },
  {
    "text": "what we need at this time is a way to to become a data-driven organization we",
    "start": "466810",
    "end": "472030"
  },
  {
    "text": "have to close the activation gap and have a new approach of how we can tackle the needs of the data and of the teams",
    "start": "472030",
    "end": "479169"
  },
  {
    "text": "that require access to these data sets big data can be successful with modern",
    "start": "479169",
    "end": "486220"
  },
  {
    "text": "datalink architectures so what are the things that you would primarily require you would you should be able to scale",
    "start": "486220",
    "end": "492250"
  },
  {
    "text": "based on use cases and as the use cases increase and the users that want to access the data increase they should not",
    "start": "492250",
    "end": "498850"
  },
  {
    "text": "be blocked on scale and you should and like Paul mentioned with with the by",
    "start": "498850",
    "end": "506470"
  },
  {
    "text": "using a data layer what you are able to do is you're able to decouple compute and storage so what that helps you do is",
    "start": "506470",
    "end": "512710"
  },
  {
    "text": "teams can quickly prototype and come up with new solutions and you also need a way that you could use a platform where",
    "start": "512710",
    "end": "521560"
  },
  {
    "text": "you can collaborate and different users and teams can work together and come up with more innovative solutions and what",
    "start": "521560",
    "end": "531460"
  },
  {
    "text": "we've seen is in 2017 about 58% of the",
    "start": "531460",
    "end": "536620"
  },
  {
    "text": "Big Data projects were in the cloud but right now we're seeing about 73% of",
    "start": "536620",
    "end": "541720"
  },
  {
    "text": "these Big Data projects are coming are running in the cloud their world their workloads are running in the cloud and",
    "start": "541720",
    "end": "548830"
  },
  {
    "text": "this is a typical d-league operation that we see so below is what you see is",
    "start": "548830",
    "end": "554110"
  },
  {
    "text": "the deal it storage where you could have different formats of data residing in your deedily and there would be",
    "start": "554110",
    "end": "559270"
  },
  {
    "text": "different use cases and different people who want to access these data sets so it could be analyst it could be data",
    "start": "559270",
    "end": "564900"
  },
  {
    "text": "products data teams your data scientists and then they would perform different",
    "start": "564900",
    "end": "569920"
  },
  {
    "text": "operations so your analyst teams would use TI tools to access this data and the format's of these data sets would be",
    "start": "569920",
    "end": "575530"
  },
  {
    "text": "different your data science teams could also be using different formats and they would use different tools to access",
    "start": "575530",
    "end": "580660"
  },
  {
    "text": "these data sets for example a data science team could be using spark for running machine learning algorithms that",
    "start": "580660",
    "end": "587200"
  },
  {
    "text": "could do some transformations that decide on the data sets that assign material lake and you could have",
    "start": "587200",
    "end": "593230"
  },
  {
    "text": "analysts or you could have other teams that are using Crestor to run ad hoc or interactive queries with the D reside",
    "start": "593230",
    "end": "599980"
  },
  {
    "text": "resides so all the data is available to all the teams across the organization and different personas can access it as",
    "start": "599980",
    "end": "606610"
  },
  {
    "text": "they want without having to worry about provisioning without having to worry about ask for different leaders data",
    "start": "606610",
    "end": "613150"
  },
  {
    "text": "sets this brings me to our first poll",
    "start": "613150",
    "end": "618170"
  },
  {
    "text": "question so the question is what is the status of your big data initiative in",
    "start": "618170",
    "end": "623510"
  },
  {
    "text": "your organization right now is it deployed but needs to it's deployed but",
    "start": "623510",
    "end": "629900"
  },
  {
    "text": "need to reduce cost of complexity of infrastructure be expanding deployments",
    "start": "629900",
    "end": "635720"
  },
  {
    "text": "adding more data users or workloads see initial use cases are deployed but need",
    "start": "635720",
    "end": "641600"
  },
  {
    "text": "to expand D have not deployed big data batteries but are doing research on how",
    "start": "641600",
    "end": "647930"
  },
  {
    "text": "to do it he no intention to deploy big tera in the next 12 months",
    "start": "647930",
    "end": "655169"
  },
  {
    "text": "so we'll give you a quick few seconds to answer the poll questions",
    "start": "655169",
    "end": "661918"
  },
  {
    "text": "you",
    "start": "662760",
    "end": "664820"
  },
  {
    "text": "thank you for submitting the poll questions so this is these are the results that we see so the maximum are",
    "start": "682780",
    "end": "689600"
  },
  {
    "text": "expanding the 25% of the people are expanding the deployments adding more data users and workloads",
    "start": "689600",
    "end": "695240"
  },
  {
    "text": "there are about 42 people who haven't deployed big data yet and 12% of the",
    "start": "695240",
    "end": "700760"
  },
  {
    "text": "people have initial use cases that they're trying to expand and learn more about",
    "start": "700760",
    "end": "706930"
  },
  {
    "text": "Brian can you stop this thank you",
    "start": "710089",
    "end": "714769"
  },
  {
    "text": "so what we see is for any organization that wants to become theater driven has",
    "start": "716360",
    "end": "722430"
  },
  {
    "text": "to have a big data activation strategy and one thing we see is right now they they have situations where the data",
    "start": "722430",
    "end": "728550"
  },
  {
    "text": "resides in silos it's not available to different teams there are different replicas of data that decide and if some",
    "start": "728550",
    "end": "734459"
  },
  {
    "text": "team has already done work on some data sets it's not available for other teams to reuse so to become a truly good truly",
    "start": "734459",
    "end": "742320"
  },
  {
    "text": "actor to have to become a truly data-driven organization and have a big data activation strategy you need to",
    "start": "742320",
    "end": "748649"
  },
  {
    "text": "have a way to be that all the data is shared and governed and there is data access to every or NOC across the",
    "start": "748649",
    "end": "754949"
  },
  {
    "text": "organization and what we also see is right now 10% of the data is active it",
    "start": "754949",
    "end": "760709"
  },
  {
    "text": "might reside in the data warehouses there will be different leader sets that unstructured and are still not being",
    "start": "760709",
    "end": "765959"
  },
  {
    "text": "used by organizations so truly activated Comfort company would have about 90",
    "start": "765959",
    "end": "771570"
  },
  {
    "text": "percent of the data data sets that could be active and could be usable by different teams and another thing we see",
    "start": "771570",
    "end": "779310"
  },
  {
    "text": "is in the traditional way about for every 10 users you would have one admin",
    "start": "779310",
    "end": "784880"
  },
  {
    "text": "admin person so that's the ratio that we see across organizations but if you want to scale and have a dealer a data-driven",
    "start": "784880",
    "end": "791970"
  },
  {
    "text": "approach you would have to be in a situation where you have one one ops or",
    "start": "791970",
    "end": "798720"
  },
  {
    "text": "want one admin person for every 200 users to run whatever use cases you want and we've seen these ratios increase",
    "start": "798720",
    "end": "805320"
  },
  {
    "text": "also so you could have one to about 200 400 users and to be in a position where",
    "start": "805320",
    "end": "813149"
  },
  {
    "text": "you can have a self-service infrastructure you can use all your collaborative tools and everyone can",
    "start": "813149",
    "end": "818310"
  },
  {
    "text": "access the data sets and use all the tools across the organization and the focus should primarily be on the",
    "start": "818310",
    "end": "825210"
  },
  {
    "text": "business impact and the use cases that people are trying to solve rather than having to worry about infrastructure and",
    "start": "825210",
    "end": "830280"
  },
  {
    "text": "the scale of infrastructure",
    "start": "830280",
    "end": "833450"
  },
  {
    "text": "so this is cue balls big data activation stack so what you see at the bottom is",
    "start": "836750",
    "end": "841759"
  },
  {
    "text": "the cloud data Lake in this case it would be s3 and you have the cube or big",
    "start": "841759",
    "end": "847459"
  },
  {
    "text": "data activation platform which primarily shows you all the engines that you could run within this so it could be high",
    "start": "847459",
    "end": "853490"
  },
  {
    "text": "spark presto Hadoop and then you have different users who would be able to",
    "start": "853490",
    "end": "858800"
  },
  {
    "text": "interact with the data set aside in your day delay so you could have data scientists who are running the machine",
    "start": "858800",
    "end": "864290"
  },
  {
    "text": "learning algorithms you could have analysts who are running reports doing visualizations creating",
    "start": "864290",
    "end": "870019"
  },
  {
    "text": "dashboards or you could have data engineers who are actually preparing the data they perform the ETL activities",
    "start": "870019",
    "end": "876860"
  },
  {
    "text": "they're doing data ingestion and doing other activities on the data sets and what people also provides is which I'm",
    "start": "876860",
    "end": "882769"
  },
  {
    "text": "going to show you soon is how we order some of the features we provide us how we do workload away or the scaling how",
    "start": "882769",
    "end": "888050"
  },
  {
    "text": "we built in spot buying right into the engines and how we provide all the other",
    "start": "888050",
    "end": "893209"
  },
  {
    "text": "features so this is a deeper look on how we",
    "start": "893209",
    "end": "898320"
  },
  {
    "text": "perform auto-scaling in cueball so this is a two-hour window the cluster starts off with about many nodes there are n",
    "start": "898320",
    "end": "904709"
  },
  {
    "text": "number of workloads that are going on and suddenly we see an increase in the workloads and there what we are able to",
    "start": "904709",
    "end": "910920"
  },
  {
    "text": "do is we are able to scale up to a 70 in this for this example we've been able to",
    "start": "910920",
    "end": "916079"
  },
  {
    "text": "scale up to a 72 node cluster and have a good ratio of spot and on-demand nodes and as we see the workload is reducing",
    "start": "916079",
    "end": "923190"
  },
  {
    "text": "and workloads completing we are able to go down and have go down to go back down",
    "start": "923190",
    "end": "928980"
  },
  {
    "text": "to about 10 nodes or 20 nodes and eventually as we see the workload increased we are able to scale up and scale down so what we are able this is",
    "start": "928980",
    "end": "936029"
  },
  {
    "text": "something that we built into the cue ball platform an AV engine that's that we use and this is what we have seen",
    "start": "936029",
    "end": "943709"
  },
  {
    "text": "across our customers and how do you spot instances so for example for Apache",
    "start": "943709",
    "end": "949410"
  },
  {
    "text": "Hadoop we see Apache Hadoop in HI we see about a 60 1.5% of the cluster",
    "start": "949410",
    "end": "954510"
  },
  {
    "text": "composition is made of spot instances for press those about 29 percent and we",
    "start": "954510",
    "end": "960630"
  },
  {
    "text": "see that it has increased quite a bit from 2017 and one of the stats that we",
    "start": "960630",
    "end": "966000"
  },
  {
    "text": "have seen is 54% of all easy to compute as have you spot instances resulting in",
    "start": "966000",
    "end": "972240"
  },
  {
    "text": "an estimated - 30 million in savings in ec2 cost",
    "start": "972240",
    "end": "978620"
  },
  {
    "text": "and this is how we see our customers using cue balls of both load aware order",
    "start": "978620",
    "end": "985100"
  },
  {
    "text": "scaling and all the other features we have so one thing is cluster life cycle savings so what we do is we are able to",
    "start": "985100",
    "end": "991430"
  },
  {
    "text": "automatically terminate the clusters when they no workflows that are running and we've saved customers about her and",
    "start": "991430",
    "end": "996950"
  },
  {
    "text": "fifty million dollars on that and we have workload aware order scaling where we are able to scale up and scale down",
    "start": "996950",
    "end": "1002560"
  },
  {
    "text": "clusters and we build the spot shop or into into our into our engine so what",
    "start": "1002560",
    "end": "1010000"
  },
  {
    "text": "that primarily does is being able to go to the spot market look for instance types and see which instance types are",
    "start": "1010000",
    "end": "1015670"
  },
  {
    "text": "cheaper at that time and build the cluster out with those instance types so",
    "start": "1015670",
    "end": "1021880"
  },
  {
    "text": "this brings us through the second poll question how do you deploy Big Data",
    "start": "1021880",
    "end": "1027069"
  },
  {
    "text": "today hey on-prem managing Big Data software and hardware to colocation third-party",
    "start": "1027070",
    "end": "1034720"
  },
  {
    "text": "managers on Prem Big Data three in the cloud you manage big data and cloud",
    "start": "1034720",
    "end": "1040449"
  },
  {
    "text": "infrastructure D cloud SAS multi tenant",
    "start": "1040450",
    "end": "1045550"
  },
  {
    "text": "big data service from cloud provider e SAS provider multi-tenant big data",
    "start": "1045550",
    "end": "1051280"
  },
  {
    "text": "service from third party and the results are in so we see 46 of the 46 percent of",
    "start": "1051280",
    "end": "1058240"
  },
  {
    "text": "the people are in the cloud you manage a big data and cloud infrastructure 36 percent of the people use big data",
    "start": "1058240",
    "end": "1065700"
  },
  {
    "text": "softwares on manage a big data on Prem and they are about 7% who are actually",
    "start": "1065700",
    "end": "1072160"
  },
  {
    "text": "using cloud SAS multi-tenant big data services and from cloud providers that's",
    "start": "1072160",
    "end": "1078580"
  },
  {
    "text": "an interesting stat so the next thing that we want to show you",
    "start": "1078580",
    "end": "1084620"
  },
  {
    "text": "you you you",
    "start": "1084620",
    "end": "1090700"
  },
  {
    "text": "when can we go to the site space and",
    "start": "1091059",
    "end": "1096859"
  },
  {
    "text": "this is what we see across our customers is the adoption of open source engines",
    "start": "1096859",
    "end": "1102409"
  },
  {
    "text": "so we've seen a growth of about one sixty two percent in open source engines",
    "start": "1102409",
    "end": "1108049"
  },
  {
    "text": "used globally and a growth of about four twenty percent in presto over the last",
    "start": "1108049",
    "end": "1114379"
  },
  {
    "text": "year and the usage of spark is also increased tonight to to 98% so what we",
    "start": "1114379",
    "end": "1121669"
  },
  {
    "text": "also see is the number of queries that run using presto or about twenty four times more than spark and about six",
    "start": "1121669",
    "end": "1130129"
  },
  {
    "text": "times more than Hadoop and hive in but only integers that we support",
    "start": "1130129",
    "end": "1138549"
  },
  {
    "text": "or swapping the we see the first slide from people so good afternoon everyone",
    "start": "1142000",
    "end": "1148930"
  },
  {
    "text": "my name is Ashish and I work with the big data analytics group in TiVo in",
    "start": "1148930",
    "end": "1154570"
  },
  {
    "text": "Boston so for last year so we have been working extensively on a big data driven",
    "start": "1154570",
    "end": "1161820"
  },
  {
    "text": "reporting platform so today I'm going to share some of our experiences and",
    "start": "1161820",
    "end": "1166840"
  },
  {
    "text": "lessons learned on how we build a scalable reporting framework solution using AWS cueball and presto",
    "start": "1166840",
    "end": "1176490"
  },
  {
    "text": "before we start I wanted to give you a brief context about the team analytics group so we are based in Boston and we",
    "start": "1176490",
    "end": "1184810"
  },
  {
    "text": "primarily deal with TV viewership data on a daily basis we receive data from",
    "start": "1184810",
    "end": "1189820"
  },
  {
    "text": "about 10 to 12 million households we also receive demographic and",
    "start": "1189820",
    "end": "1196360"
  },
  {
    "text": "location-based consumer data from various winters which which pertains to demographic patterns purchasing",
    "start": "1196360",
    "end": "1203200"
  },
  {
    "text": "behaviors so this essentially tells us about the households that are watching the television and then finally we get",
    "start": "1203200",
    "end": "1210660"
  },
  {
    "text": "on a weekly basis we get a ad listing of all the hot spots that ad on any",
    "start": "1210660",
    "end": "1216160"
  },
  {
    "text": "national or local channel in in United States so these are these three the",
    "start": "1216160",
    "end": "1222820"
  },
  {
    "text": "viewership the demographic attributes and xboxone each of them on itself is a",
    "start": "1222820",
    "end": "1230130"
  },
  {
    "text": "huge data set so these three big data sets are churned through a TiVo",
    "start": "1230130",
    "end": "1236320"
  },
  {
    "text": "analytics platform and they're made available to the three framework which",
    "start": "1236320",
    "end": "1241420"
  },
  {
    "text": "is called target targeted or instill early or tad so let me",
    "start": "1241420",
    "end": "1249300"
  },
  {
    "text": "spend some time on what does this platform does so this platform is used",
    "start": "1249600",
    "end": "1256000"
  },
  {
    "text": "by her clients to build their custom target for research so somebody like I",
    "start": "1256000",
    "end": "1262420"
  },
  {
    "text": "can go in and they can build they can define the attributes that they want to",
    "start": "1262420",
    "end": "1268000"
  },
  {
    "text": "target and then they build it a custom audience and then they can put the",
    "start": "1268000",
    "end": "1273100"
  },
  {
    "text": "research based on the custom clothier audience users can also view various",
    "start": "1273100",
    "end": "1279190"
  },
  {
    "text": "type of TV ratings on various programs they can discern the viewership pattern",
    "start": "1279190",
    "end": "1285880"
  },
  {
    "text": "based on different dimensions and that we provide on the deponents framework this the emissions can be like network",
    "start": "1285880",
    "end": "1293740"
  },
  {
    "text": "of grand or depart and finally they can measure the efficiency of their ad campaigns based on the target that they",
    "start": "1293740",
    "end": "1301900"
  },
  {
    "text": "updated so this platform as I said is called a",
    "start": "1301900",
    "end": "1308360"
  },
  {
    "text": "targeted audience delivery and this this is used by the TV TV networks ad",
    "start": "1308360",
    "end": "1315200"
  },
  {
    "text": "agencies and advertisers and it provides them in with an understanding of what and when they target audience segments",
    "start": "1315200",
    "end": "1322340"
  },
  {
    "text": "of washing on the television and this information is very valuable because a",
    "start": "1322340",
    "end": "1328610"
  },
  {
    "text": "this is a niche area in terms of targeting and B it allows them to tailor",
    "start": "1328610",
    "end": "1337250"
  },
  {
    "text": "and optimize TV ad campaigns which results in a huge saving for them as TV",
    "start": "1337250",
    "end": "1343760"
  },
  {
    "text": "as TV ads are extremely expensive so I",
    "start": "1343760",
    "end": "1348950"
  },
  {
    "text": "also want to touch upon some of the asks for this platform for the requirements",
    "start": "1348950",
    "end": "1355360"
  },
  {
    "text": "so the first thing is we provide a lot of filters and aggregation options so",
    "start": "1355360",
    "end": "1363400"
  },
  {
    "text": "which means we cannot pre aggregate the data so most of our aggregation is done",
    "start": "1363400",
    "end": "1369890"
  },
  {
    "text": "on the live data on the disaggregated data set so which becomes which makes",
    "start": "1369890",
    "end": "1375800"
  },
  {
    "text": "our query engine to be very challenging and very complex secondly we need the",
    "start": "1375800",
    "end": "1384350"
  },
  {
    "text": "results really fast because the user is obviously waiting for further repose to",
    "start": "1384350",
    "end": "1391070"
  },
  {
    "text": "finish and and third and final we don't want to pay too much money for the",
    "start": "1391070",
    "end": "1396980"
  },
  {
    "text": "operational cost for managing this solution so this is sort of a Holy Trinity of software development we want",
    "start": "1396980",
    "end": "1404390"
  },
  {
    "text": "to basically do everything from the disaggregated data we want extremely",
    "start": "1404390",
    "end": "1409910"
  },
  {
    "text": "high performance and we don't want to pay too much so with those modest goals we decided",
    "start": "1409910",
    "end": "1418040"
  },
  {
    "text": "that we will use custom a couple with",
    "start": "1418040",
    "end": "1423710"
  },
  {
    "text": "the cueball service on AWS instructure can you go to the next slide please",
    "start": "1423710",
    "end": "1432250"
  },
  {
    "text": "why pesto so as you were looking for a",
    "start": "1434920",
    "end": "1441370"
  },
  {
    "text": "query engine for a solution we wanted something that is scalable and that that obviously is cost-effective for us so",
    "start": "1441370",
    "end": "1449050"
  },
  {
    "text": "plus it has a bunch of advantages well the first one is a ver storage computer",
    "start": "1449050",
    "end": "1454660"
  },
  {
    "text": "submission we are storing our data on s3 and at the espadrille protocol in work",
    "start": "1454660",
    "end": "1461890"
  },
  {
    "text": "we point our pesto query engine to the s3 and run our queries secondly a pesto",
    "start": "1461890",
    "end": "1468610"
  },
  {
    "text": "is extremely scalable we can easily add and remove worker nodes third and this",
    "start": "1468610",
    "end": "1475150"
  },
  {
    "text": "is very was very important for us we have our data living in multiple data",
    "start": "1475150",
    "end": "1481930"
  },
  {
    "text": "sources we have hives we have red shape",
    "start": "1481930",
    "end": "1487660"
  },
  {
    "text": "we have my sequel and you have flat files so presto can essentially query",
    "start": "1487660",
    "end": "1494830"
  },
  {
    "text": "different data sources in one single query and then serve the results to the",
    "start": "1494830",
    "end": "1502240"
  },
  {
    "text": "users so this means we don't have to move the data into one place before the reports are run so this was very",
    "start": "1502240",
    "end": "1508510"
  },
  {
    "text": "valuable for us and then fourth is we",
    "start": "1508510",
    "end": "1514180"
  },
  {
    "text": "wanted obviously good performance for our analytical queries and plus still extremely reform without testing Prester",
    "start": "1514180",
    "end": "1521020"
  },
  {
    "text": "is extremely performant in a scanning large amount of data and then finally we",
    "start": "1521020",
    "end": "1528400"
  },
  {
    "text": "wanted something which is managed so services like you'll have",
    "start": "1528400",
    "end": "1535020"
  },
  {
    "text": "out-of-the-box custom managed service so",
    "start": "1535020",
    "end": "1541660"
  },
  {
    "text": "the next slide shows you gives you an example of how a sample query runs on it",
    "start": "1541660",
    "end": "1548140"
  },
  {
    "text": "on a pesto cluster so this query essentially is going after two tables the first table of the viewership which",
    "start": "1548140",
    "end": "1554920"
  },
  {
    "text": "is which is a huge fact able lives in hi and the second table lives in my sequel",
    "start": "1554920",
    "end": "1561910"
  },
  {
    "text": "but the query is essentially joining them as if they're on one single database so",
    "start": "1561910",
    "end": "1568720"
  },
  {
    "text": "so this obviously means that we don't have to move our data into one place and",
    "start": "1568720",
    "end": "1574860"
  },
  {
    "text": "pesto has native connectors to each of",
    "start": "1574860",
    "end": "1580090"
  },
  {
    "text": "the two to many underlying data sources so through the connectors the data is streamed and Google worker nodes and a",
    "start": "1580090",
    "end": "1587830"
  },
  {
    "text": "coordinator essentially works as a named node in the Hadoop parlance it looks at",
    "start": "1587830",
    "end": "1596350"
  },
  {
    "text": "the query and then the query patterns so",
    "start": "1596350",
    "end": "1603850"
  },
  {
    "text": "as part of this presentation we will review a couple of use cases and I will",
    "start": "1603850",
    "end": "1609610"
  },
  {
    "text": "share the lessons learnt as part of those use cases so the first lesson that",
    "start": "1609610",
    "end": "1615220"
  },
  {
    "text": "I wanted to share with you is when constructing a pesto cluster what instance type should be used so before I",
    "start": "1615220",
    "end": "1624909"
  },
  {
    "text": "jump into the buffet of AWS instances I want to spend some time on tests of",
    "start": "1624909",
    "end": "1632740"
  },
  {
    "text": "memory and other attributes so plus two has three memory pools the system memory",
    "start": "1632740",
    "end": "1639970"
  },
  {
    "text": "pool is is by default a fine as 40% of the total memory then we have two memory",
    "start": "1639970",
    "end": "1647409"
  },
  {
    "text": "pools which are available for the general users the first one is the general memory pool where all the",
    "start": "1647409",
    "end": "1653500"
  },
  {
    "text": "queries by default go and the third is the reserved memory pool which is as the",
    "start": "1653500",
    "end": "1659140"
  },
  {
    "text": "name suggests is reserved for the highest query which cannot be fit into the general memory pool that goes into",
    "start": "1659140",
    "end": "1665110"
  },
  {
    "text": "the resulting report now what does that mean how do we how do we set these",
    "start": "1665110",
    "end": "1670120"
  },
  {
    "text": "parameters so there are different considerations on how do we set these",
    "start": "1670120",
    "end": "1676270"
  },
  {
    "text": "things and what sort of instance types should be used so what happens if a",
    "start": "1676270",
    "end": "1686440"
  },
  {
    "text": "query if the queries are using different memory they have different asks from the",
    "start": "1686440",
    "end": "1694150"
  },
  {
    "text": "cluster so what we found was it is better to have multiple clusters for",
    "start": "1694150",
    "end": "1700720"
  },
  {
    "text": "different workload so if you have a small interactive queries they should",
    "start": "1700720",
    "end": "1705800"
  },
  {
    "text": "go on its own cursor or versus if you have huge ETL queries or huge your",
    "start": "1705800",
    "end": "1712430"
  },
  {
    "text": "opponent queries which has a big memory requirement they should go on on its own cluster it is easier to optimize a",
    "start": "1712430",
    "end": "1719600"
  },
  {
    "text": "cluster based on a consistent workload rather than trying to sell everything so",
    "start": "1719600",
    "end": "1726430"
  },
  {
    "text": "secondly or what should we use should be use of few big clusters or large amount",
    "start": "1727390",
    "end": "1737600"
  },
  {
    "text": "of small clusters sorry what's actually heals a few big instance types or small",
    "start": "1737600",
    "end": "1745130"
  },
  {
    "text": "amount of small smaller largest stage so based on our and empirical testing we",
    "start": "1745130",
    "end": "1752840"
  },
  {
    "text": "found small amount of large distance instance types were better than than the",
    "start": "1752840",
    "end": "1758780"
  },
  {
    "text": "other way round so so for example should be used for nodes of r4 16x or should we",
    "start": "1758780",
    "end": "1766430"
  },
  {
    "text": "use 16 nodes of R 4 for X so the the",
    "start": "1766430",
    "end": "1773000"
  },
  {
    "text": "smaller size was preferable in our in our testing obviously this can differ",
    "start": "1773000",
    "end": "1778070"
  },
  {
    "text": "for other people and then should we use computer optimized Oakland instances or",
    "start": "1778070",
    "end": "1786170"
  },
  {
    "text": "should we use memory optimized instances and that obviously depends on need",
    "start": "1786170",
    "end": "1793179"
  },
  {
    "text": "can we go to the next one so as I said",
    "start": "1796420",
    "end": "1801460"
  },
  {
    "text": "AWS have a huge amount of instance types to choose from and sometimes it can be",
    "start": "1801460",
    "end": "1808000"
  },
  {
    "text": "confusing so this slide gives you a",
    "start": "1808000",
    "end": "1813510"
  },
  {
    "text": "non-integer of how these tense instances are defined in a de lewis so the first",
    "start": "1813510",
    "end": "1819070"
  },
  {
    "text": "letter tells you the type of instance whether it is memory optimized which is",
    "start": "1819070",
    "end": "1826000"
  },
  {
    "text": "our compute optimized UC or general purpose which is T and there are others also second letter tells you the",
    "start": "1826000",
    "end": "1833080"
  },
  {
    "text": "generation how old or new the instance type is and then after the dot we have a",
    "start": "1833080",
    "end": "1839910"
  },
  {
    "text": "multiplier which tells you how much CPU and storage multiplication does this",
    "start": "1839910",
    "end": "1847660"
  },
  {
    "text": "instance provides so can you go to the",
    "start": "1847660",
    "end": "1853630"
  },
  {
    "text": "next slide so there are literally",
    "start": "1853630",
    "end": "1859090"
  },
  {
    "text": "hundreds of instances to choose from I didn't care it can get very confusing at least for us we were struggling with it",
    "start": "1859090",
    "end": "1865710"
  },
  {
    "text": "so daughter Bill Simmons who's the CTO",
    "start": "1865710",
    "end": "1871360"
  },
  {
    "text": "of data Zoo which is a local a tech company in Boston has done this analysis",
    "start": "1871360",
    "end": "1878700"
  },
  {
    "text": "essentially is called a efficient frontier or Pareto front analysis so he",
    "start": "1878700",
    "end": "1885970"
  },
  {
    "text": "took two metrics so on the y-axis he",
    "start": "1885970",
    "end": "1891220"
  },
  {
    "text": "plotted the compute efficiencies computer vision we measured in elastic compute unit per dollar and on the",
    "start": "1891220",
    "end": "1897880"
  },
  {
    "text": "x-axis he plotted the memory efficiency as measured in the gigabytes of memory",
    "start": "1897880",
    "end": "1903130"
  },
  {
    "text": "per dollar per hour so essentially he normalized all the instances in in these",
    "start": "1903130",
    "end": "1908890"
  },
  {
    "text": "two units and then he plotted the units of so he plotted the instances along",
    "start": "1908890",
    "end": "1916840"
  },
  {
    "text": "this x and y y axis and quickly we found that the the instances which are at the",
    "start": "1916840",
    "end": "1928059"
  },
  {
    "text": "forefront or the most efficient instances and and should be I should be used the upper right-hand",
    "start": "1928059",
    "end": "1935209"
  },
  {
    "text": "corner is the Utopia point which is the most efficient combination of compute and memory which obviously doesn't exist",
    "start": "1935209",
    "end": "1942349"
  },
  {
    "text": "as you speak one caveat that I want to point out is",
    "start": "1942349",
    "end": "1948909"
  },
  {
    "text": "this analysis is assuming the on demand pricing now if you consider spot pricing",
    "start": "1948909",
    "end": "1956149"
  },
  {
    "text": "which is obviously comes with a huge discount this numbers might change so",
    "start": "1956149",
    "end": "1962209"
  },
  {
    "text": "that does a caveat Oh",
    "start": "1962209",
    "end": "1967270"
  },
  {
    "text": "as I said the new instances are most efficient so that our decision was made",
    "start": "1967270",
    "end": "1974770"
  },
  {
    "text": "easier by just considering those instances which are at the front of this",
    "start": "1974770",
    "end": "1980160"
  },
  {
    "text": "plot so the bottom two are instance types which are the R 4 and C and so R 4",
    "start": "1980160",
    "end": "1990280"
  },
  {
    "text": "and X 1 are optimized for memory",
    "start": "1990280",
    "end": "1995490"
  },
  {
    "text": "customized from memory so if your work load is highly memory intensive then I",
    "start": "1995490",
    "end": "2002100"
  },
  {
    "text": "would suggest that you should use either R 4 or X 1 and if your workload is",
    "start": "2002100",
    "end": "2012020"
  },
  {
    "text": "compute-intensive then you should go for c5 or M so in our case we our workload",
    "start": "2012020",
    "end": "2021120"
  },
  {
    "text": "is memory intensive but we still wanted some good power to do some sort of fire",
    "start": "2021120",
    "end": "2026760"
  },
  {
    "text": "and Attucks queries so we went for our 4",
    "start": "2026760",
    "end": "2031850"
  },
  {
    "text": "and then and then based on our testing we found our 460 next large was the sort",
    "start": "2031850",
    "end": "2038400"
  },
  {
    "text": "of the best way to file our workload all",
    "start": "2038400",
    "end": "2044190"
  },
  {
    "text": "right so the next lesson learnt that I want to share was how do we scale so now",
    "start": "2044190",
    "end": "2049648"
  },
  {
    "text": "that we have chosen the instance types how many instances should we build in a",
    "start": "2049649",
    "end": "2056520"
  },
  {
    "text": "cluster so this slide I want to give you",
    "start": "2056520",
    "end": "2063450"
  },
  {
    "text": "a sample an average pesto query which goes against a a small cluster cluster",
    "start": "2063450",
    "end": "2070590"
  },
  {
    "text": "which has one coordinate event and couple of worker nodes so this conservative average query and this goes",
    "start": "2070590",
    "end": "2076860"
  },
  {
    "text": "to an average cluster cluster and it's completed nablus times so this is so far",
    "start": "2076860",
    "end": "2082320"
  },
  {
    "text": "a baseline now what happens if in a",
    "start": "2082320",
    "end": "2088290"
  },
  {
    "text": "reporting platform you get 10 concurrent users who are running 10 concurrent",
    "start": "2088290",
    "end": "2094020"
  },
  {
    "text": "queries now your average cluster is not going to be able to service those 10",
    "start": "2094020",
    "end": "2099150"
  },
  {
    "text": "queries in the same time as it was able to service one query so the queries will",
    "start": "2099150",
    "end": "2104760"
  },
  {
    "text": "slow down as they are waiting for memory CP or other resources so what do we do",
    "start": "2104760",
    "end": "2111210"
  },
  {
    "text": "so we are using a q-ball service which is which provides auto scanning it",
    "start": "2111210",
    "end": "2117780"
  },
  {
    "text": "senses the demands are based on the number of processes in the queue and it",
    "start": "2117780",
    "end": "2125640"
  },
  {
    "text": "automatically increases the worker nodes based on the limit that we can configure",
    "start": "2125640",
    "end": "2131580"
  },
  {
    "text": "in our cluster definition so it will auto scale up to the limit that we are",
    "start": "2131580",
    "end": "2136890"
  },
  {
    "text": "provided in the cluster now this 10 queries will are being",
    "start": "2136890",
    "end": "2143280"
  },
  {
    "text": "serviced by four or more nodes and then then they are now running at a good clip",
    "start": "2143280",
    "end": "2149240"
  },
  {
    "text": "so so so far so good so now what happens if the demand again dips now we are back",
    "start": "2149240",
    "end": "2156870"
  },
  {
    "text": "to one user one query so now your for node cluster is overkill because one",
    "start": "2156870",
    "end": "2163080"
  },
  {
    "text": "query can obviously be serviced by two nodes so the cube or service again does",
    "start": "2163080",
    "end": "2170040"
  },
  {
    "text": "it down scaling based on the demand it will take take down to work indoors and",
    "start": "2170040",
    "end": "2175470"
  },
  {
    "text": "and one your one query is now back to your regular cluster so we so that we",
    "start": "2175470",
    "end": "2181380"
  },
  {
    "text": "don't have to obviously pay for the extra nodes in the cluster so now what",
    "start": "2181380",
    "end": "2188820"
  },
  {
    "text": "happens if you have sort of an average query you have a huge query which is",
    "start": "2188820",
    "end": "2196860"
  },
  {
    "text": "let's say scanning six months of data and is in liquid lot of memory so the",
    "start": "2196860",
    "end": "2205020"
  },
  {
    "text": "piece of the cube of service again senses that there is a huge demand on",
    "start": "2205020",
    "end": "2210300"
  },
  {
    "text": "the worker that works as a pack day at hundred percent CPU and memory so it will Auto scale and it will add again it",
    "start": "2210300",
    "end": "2217170"
  },
  {
    "text": "will add more worker nodes based on their limit but the problem is the the up scaling",
    "start": "2217170",
    "end": "2226140"
  },
  {
    "text": "will work only for the new queries though the gray that is already is running will not see the benefits",
    "start": "2226140",
    "end": "2234570"
  },
  {
    "text": "in terms of the new workers down have been added so so the net result will be",
    "start": "2234570",
    "end": "2240810"
  },
  {
    "text": "the query even though you have upscaled very still using two worker nodes and and whatever additions work and oh she",
    "start": "2240810",
    "end": "2247230"
  },
  {
    "text": "added of sitting idle so the lesson here is that if you have multiple or",
    "start": "2247230",
    "end": "2256080"
  },
  {
    "text": "concurrent queries then auto-scaling works beautifully if you have a different workload query then",
    "start": "2256080",
    "end": "2263480"
  },
  {
    "text": "auto-scaling is not an option it's not a good option may be using a different",
    "start": "2263480",
    "end": "2268860"
  },
  {
    "text": "cluster sending that query to a different cluster is a better option so",
    "start": "2268860",
    "end": "2274290"
  },
  {
    "text": "that's how we sort of figured out Auto scale or a scaling part and we ended up",
    "start": "2274290",
    "end": "2279300"
  },
  {
    "text": "having three or four clusters for our",
    "start": "2279300",
    "end": "2284790"
  },
  {
    "text": "workload one for ETL one for interactive queries one for huge queries and and one",
    "start": "2284790",
    "end": "2293070"
  },
  {
    "text": "cluster was always on for all the miscellaneous work that coming coming from the users so I want to summarize",
    "start": "2293070",
    "end": "2302190"
  },
  {
    "text": "the results and the lessons learned that we discussed so far so number one is",
    "start": "2302190",
    "end": "2308610"
  },
  {
    "text": "elastic scaling so that was main the filtration we don't want to pay for the",
    "start": "2308610",
    "end": "2314970"
  },
  {
    "text": "inverter if you are using it so using cubile service we are spinning the notes",
    "start": "2314970",
    "end": "2320670"
  },
  {
    "text": "up and down and we are obviously then paying for the service as we use this is",
    "start": "2320670",
    "end": "2327450"
  },
  {
    "text": "a huge this is a huge deal for us secondly we are using a specialized",
    "start": "2327450",
    "end": "2332520"
  },
  {
    "text": "cluster we're not using one of feist at all we are following old adage of horses",
    "start": "2332520",
    "end": "2340290"
  },
  {
    "text": "for courses so every work logged have",
    "start": "2340290",
    "end": "2345480"
  },
  {
    "text": "its own cluster which is optimized and configure configure for that workload",
    "start": "2345480",
    "end": "2351330"
  },
  {
    "text": "and then finally we have a storage and computer separation we don't want to be",
    "start": "2351330",
    "end": "2357540"
  },
  {
    "text": "tied up in a closed system or an appliance we are where the system is",
    "start": "2357540",
    "end": "2363930"
  },
  {
    "text": "always up 24/7 so you know we wanted to have a open a storage solution like and which",
    "start": "2363930",
    "end": "2372310"
  },
  {
    "text": "was for provided by ADA Lewis s3 so the benefit of this is now I can I can",
    "start": "2372310",
    "end": "2378280"
  },
  {
    "text": "obviously I'm using tester but I can also point my spark I can point a spectrum I can point hi then there are a",
    "start": "2378280",
    "end": "2386920"
  },
  {
    "text": "number of solutions available in the market where I I can use to point to the",
    "start": "2386920",
    "end": "2392650"
  },
  {
    "text": "same data without actually copying the data to different different places so",
    "start": "2392650",
    "end": "2398050"
  },
  {
    "text": "this increases our scalability and the data will will be alright so this slide",
    "start": "2398050",
    "end": "2406240"
  },
  {
    "text": "gives you some of the links on on AWS and cable in case you're interested in",
    "start": "2406240",
    "end": "2413589"
  },
  {
    "text": "trying the solution and I think we are",
    "start": "2413589",
    "end": "2418690"
  },
  {
    "text": "at the end of the presentation from people so I think we can open the",
    "start": "2418690",
    "end": "2427829"
  },
  {
    "text": "meeting for Q&A hi yes I think you are and thank you",
    "start": "2427829",
    "end": "2434260"
  },
  {
    "text": "harsh as well we are just reminded before we get started in queue at Q & A we the the",
    "start": "2434260",
    "end": "2440339"
  },
  {
    "text": "presentation as well as recording a webinar will be emailed out to you links",
    "start": "2440339",
    "end": "2446380"
  },
  {
    "text": "to those the content will be emailed email up to you in a couple days so please look for a follow-up email about",
    "start": "2446380",
    "end": "2454240"
  },
  {
    "text": "this and that will get you access to the slides available on SlideShare as well as the webinar on YouTube we have a few",
    "start": "2454240",
    "end": "2461470"
  },
  {
    "text": "questions that have been submitted there's there's one I want to go ahead and answer for the general audience and",
    "start": "2461470",
    "end": "2468609"
  },
  {
    "text": "that was we had a lot of discussions around Browns what was spot instances and question was um what are spot",
    "start": "2468609",
    "end": "2475000"
  },
  {
    "text": "instances and so spot instances are spare ec2 capacity and it's offered at a",
    "start": "2475000",
    "end": "2483220"
  },
  {
    "text": "significant lower price than the standard on-demand pricing so if you were to launch an ec2 instance that",
    "start": "2483220",
    "end": "2491770"
  },
  {
    "text": "would be normally launched under a call on demand pricing which is the standard pricing as there as a spare capacity may",
    "start": "2491770",
    "end": "2500980"
  },
  {
    "text": "be available instance type and quantity there are times where those are made available to",
    "start": "2500980",
    "end": "2508720"
  },
  {
    "text": "call spot market and they're offered at a much lower price the caveat is that",
    "start": "2508720",
    "end": "2514320"
  },
  {
    "text": "these instances can be reclaimed back and be can and be assigned to as demand",
    "start": "2514320",
    "end": "2522160"
  },
  {
    "text": "needs and so Spotnitz is not guaranteed to be persistent for any period of time",
    "start": "2522160",
    "end": "2529390"
  },
  {
    "text": "you will have a two-minute warning when that instance will be terminated to give you opportunity if your whatever you're",
    "start": "2529390",
    "end": "2536290"
  },
  {
    "text": "doing when your instance to be cleaned up and saved if you need to and such but that is the advantage is that you get a",
    "start": "2536290",
    "end": "2542320"
  },
  {
    "text": "significant less expensive cost for the using instances but at the same time you",
    "start": "2542320",
    "end": "2549400"
  },
  {
    "text": "have a risk of possibly losing availability of those instances if they need to be reclaimed you can learn more",
    "start": "2549400",
    "end": "2555070"
  },
  {
    "text": "about this at AWS to amazon.com / ec2 slash spot",
    "start": "2555070",
    "end": "2562030"
  },
  {
    "text": "okay so we're having a few questions for q-ball and for TiVo so first for Cuba",
    "start": "2562030",
    "end": "2569080"
  },
  {
    "text": "one question that came up came in was what kind of engines do people use for",
    "start": "2569080",
    "end": "2574390"
  },
  {
    "text": "different use cases and and can you provide some examples of those of those",
    "start": "2574390",
    "end": "2581530"
  },
  {
    "text": "use cases engine type in these cases sure it would be fun yeah oh sure thanks",
    "start": "2581530",
    "end": "2587650"
  },
  {
    "text": "thanks that's an interesting question so over the years we've seen at the adoption of multiple engines being used",
    "start": "2587650",
    "end": "2593320"
  },
  {
    "text": "across organizations increase quite a bit so we see like the slides pointed out we see people using a lot of presto",
    "start": "2593320",
    "end": "2599800"
  },
  {
    "text": "there is a lot of spark and hi and a Hadoop in the mix so if you talk much specific use cases what patterns we see",
    "start": "2599800",
    "end": "2606970"
  },
  {
    "text": "with customers is that for interactive workloads or interactive queries we see a lot of customers use presto like she",
    "start": "2606970",
    "end": "2614920"
  },
  {
    "text": "should also shown that they use press so for some of most quite a few of their interactive queries and some interesting",
    "start": "2614920",
    "end": "2621310"
  },
  {
    "text": "use cases that we see with spark is machine burning workloads ETL workloads so if people want to do some data",
    "start": "2621310",
    "end": "2627250"
  },
  {
    "text": "wrangling wanna test and train their algorithms they do that using the spark ml live of MLF packages within cueball",
    "start": "2627250",
    "end": "2635380"
  },
  {
    "text": "and people it it depends so use cases would be it could be ETL workloads ETL boatloads could be - oops Park",
    "start": "2635380",
    "end": "2642120"
  },
  {
    "text": "interactive queries are you seen a lot of adoption on presto and for for",
    "start": "2642120",
    "end": "2649690"
  },
  {
    "text": "machine learning we've seen a lot of people go to spark in this case great",
    "start": "2649690",
    "end": "2656200"
  },
  {
    "text": "okay thank you um actually I have a number of questions around using a spark",
    "start": "2656200",
    "end": "2661630"
  },
  {
    "text": "and hive inquiries and such so one question came in around how do you send queries to different cluster clusters in",
    "start": "2661630",
    "end": "2668530"
  },
  {
    "text": "cube all right so there are various ways so one is the cueball user interface so you could we have a work integrated",
    "start": "2668530",
    "end": "2675130"
  },
  {
    "text": "workbench so using that workbench you could choose what query you want to compose and which",
    "start": "2675130",
    "end": "2680890"
  },
  {
    "text": "cluster you want to run it against that's one way the other way would be we have a REST API that is exposed so you",
    "start": "2680890",
    "end": "2686980"
  },
  {
    "text": "could use our REST API and submit the query to a particular cluster the interesting thing over here is that the clusters can be down when you submit the",
    "start": "2686980",
    "end": "2693280"
  },
  {
    "text": "query and as soon as the query or workload is submitted it automatically starts the cluster runs the workload and",
    "start": "2693280",
    "end": "2698950"
  },
  {
    "text": "eventually terminates the cluster also so and we've seen customers who use other bi interfaces so you could use",
    "start": "2698950",
    "end": "2706090"
  },
  {
    "text": "look a tableau or any other a bi interface and connect to q-ball - so with a JDBC drivers so we have JDBC ODBC",
    "start": "2706090",
    "end": "2713620"
  },
  {
    "text": "drivers so those are few options of these people in connect to Cuba and eventually run workloads on clusters ok",
    "start": "2713620",
    "end": "2721930"
  },
  {
    "text": "um we'll stay on the Cuba theme right now some more questions coming around this so another one is do you have any",
    "start": "2721930",
    "end": "2730870"
  },
  {
    "text": "do you have to do anything for any tuning of memory on master nodes as opposed to worker nodes and if so do you",
    "start": "2730870",
    "end": "2737890"
  },
  {
    "text": "need to have instant types that work better as masters right that's a good",
    "start": "2737890",
    "end": "2743800"
  },
  {
    "text": "question so we have recommendations so what we've done internally is we've been able to look at instance types and be a",
    "start": "2743800",
    "end": "2749800"
  },
  {
    "text": "VP have recommended settings that we have for instance types and we've also built or for especially for SPARC we",
    "start": "2749800",
    "end": "2755800"
  },
  {
    "text": "built this tool called spot lands so primarily it tells you how the workloads are running and if you need to tune",
    "start": "2755800",
    "end": "2760810"
  },
  {
    "text": "something and again a lot of statistics are available and most of the we have",
    "start": "2760810",
    "end": "2766390"
  },
  {
    "text": "recommendations for certain exercise for presto and what is society useless part so those are tuned and for master and",
    "start": "2766390",
    "end": "2773260"
  },
  {
    "text": "worker there feeling differently - yes great ok I'll actually ask a question",
    "start": "2773260",
    "end": "2779109"
  },
  {
    "text": "now for a sheet for tebow so so what is",
    "start": "2779109",
    "end": "2784930"
  },
  {
    "text": "what is so we appreciate you sharing the team of stories so what is next for TiVo",
    "start": "2784930",
    "end": "2790080"
  },
  {
    "text": "will you be incorporating same machine learning into the product yeah I thanks",
    "start": "2790080",
    "end": "2796990"
  },
  {
    "text": "Paul yes that's a good question so another road map we have a use case",
    "start": "2796990",
    "end": "2803290"
  },
  {
    "text": "for or TV viewership predictive analytics basically that involves forecasting the viewership patterns for",
    "start": "2803290",
    "end": "2810160"
  },
  {
    "text": "the next quarter and for different target and audience segments this is",
    "start": "2810160",
    "end": "2816119"
  },
  {
    "text": "extremely useful further for our clients for advertisers because the ad buys that",
    "start": "2816119",
    "end": "2823750"
  },
  {
    "text": "happens it happens a quarter or two before the actual TV is TV broadcast so",
    "start": "2823750",
    "end": "2830380"
  },
  {
    "text": "those are friends are very important and advertisers want to see the VA ship patterns for the next caller so so we",
    "start": "2830380",
    "end": "2836980"
  },
  {
    "text": "are running some proof-of-concept some experimentation with the machine learning algorithms to do exactly that",
    "start": "2836980",
    "end": "2844180"
  },
  {
    "text": "so I would say stay tuned for more information okay and actually I'm gonna",
    "start": "2844180",
    "end": "2849550"
  },
  {
    "text": "I'm gonna go and follow up this question with cue ball so um maybe you talk about how Cuba can use for machine learning",
    "start": "2849550",
    "end": "2857579"
  },
  {
    "text": "right thanks a lot of ways you can interface with Cuba for machine learning one is we have Zeppelin notebooks built",
    "start": "2858330",
    "end": "2864670"
  },
  {
    "text": "into cue ball so what would primarily happen is you could install the packages that you want or your machine learn",
    "start": "2864670",
    "end": "2870880"
  },
  {
    "text": "pocket is on the cluster as the cluster comes up those packages are available and then you could use a notebook interface to do your data wrangling do",
    "start": "2870880",
    "end": "2878230"
  },
  {
    "text": "your testing and validation of M training testing and validation of your models and this could be done for different models so if you want to build",
    "start": "2878230",
    "end": "2884410"
  },
  {
    "text": "a model of your own you could do that too or if you want to use existing model that using people great so far along",
    "start": "2884410",
    "end": "2893680"
  },
  {
    "text": "with some more cubic questions is similar interest in the product on Cuba can you write sequel Python skaila",
    "start": "2893680",
    "end": "2899650"
  },
  {
    "text": "etc yes so like I mentioned we have the work bench so the work bench primarily gives",
    "start": "2899650",
    "end": "2905430"
  },
  {
    "text": "you a way to execute a query so you could have a presser query and if you",
    "start": "2905430",
    "end": "2910470"
  },
  {
    "text": "use spark you could have your pythons or Scala and you could also submit chars or",
    "start": "2910470",
    "end": "2915690"
  },
  {
    "text": "you could write a spark SQL in this case so you could submit any of those queries using our workbench or or the REST API",
    "start": "2915690",
    "end": "2924829"
  },
  {
    "text": "great okay um that makes a lot of sense so how about let's look at maybe some",
    "start": "2925040",
    "end": "2930200"
  },
  {
    "text": "dashboarding um how do you build dashboard and cue-ball does it have something like Tim Pablo the coccyx you",
    "start": "2930200",
    "end": "2936330"
  },
  {
    "text": "but what do you how do you do how do you get that type of data visualizations available so the few ways so one is we",
    "start": "2936330",
    "end": "2942300"
  },
  {
    "text": "have the notebook interface so the notebook can be converted into dashboards so for example we have visualizations that are centered in the",
    "start": "2942300",
    "end": "2948180"
  },
  {
    "text": "notebooks and that you can have - poster refreshed on a cycle so you could have a dashboard that is refreshed every one",
    "start": "2948180",
    "end": "2954990"
  },
  {
    "text": "hour and that - what could be used so visualization in this case could be using matplotlib lochley or any other",
    "start": "2954990",
    "end": "2960810"
  },
  {
    "text": "visualization tool that you want to use the other aspect is how do we interface with the BI tools so we have JDBC and",
    "start": "2960810",
    "end": "2968430"
  },
  {
    "text": "woody PC connectors so you could use those to interface with any of the p.i tools like tableau or looker okay um so",
    "start": "2968430",
    "end": "2977730"
  },
  {
    "text": "that's actually interesting how you can interface with hello looker and such so let's let's take it back to to TiVo and",
    "start": "2977730",
    "end": "2986540"
  },
  {
    "text": "maybe you can discuss some of what you learn you learn your lessons learned some of the best practices that you",
    "start": "2986540",
    "end": "2992670"
  },
  {
    "text": "discovered when maybe moving sequel code from data warehouse to inter press toe",
    "start": "2992670",
    "end": "2997859"
  },
  {
    "text": "did you have any challenges you faced when doing that or some practices you may have may have derived from most",
    "start": "2997859",
    "end": "3005119"
  },
  {
    "text": "lessons learned yeah absolutely so every database every system is",
    "start": "3005119",
    "end": "3011450"
  },
  {
    "text": "different so there are obviously some nuances and a pistol I would say is a",
    "start": "3011450",
    "end": "3017540"
  },
  {
    "text": "code engine and it's it's maturing but it's not as mature as some of the other",
    "start": "3017540",
    "end": "3023960"
  },
  {
    "text": "ones that being said there are some the ones inside near door console so number",
    "start": "3023960",
    "end": "3029570"
  },
  {
    "text": "one is when you're doing multi table join",
    "start": "3029570",
    "end": "3034610"
  },
  {
    "text": "the biggest table should be the first table in the joint and this is because the default joint setting is broadcast",
    "start": "3034610",
    "end": "3042230"
  },
  {
    "text": "so as to tries to broadcast the right-hand table so if you have left",
    "start": "3042230",
    "end": "3048740"
  },
  {
    "text": "table as the biggest table then that John was a lot better",
    "start": "3048740",
    "end": "3054050"
  },
  {
    "text": "secondly Preston is the column - engine so you should only select those columns",
    "start": "3054050",
    "end": "3062480"
  },
  {
    "text": "that you need because otherwise you're doing an associate data scans third we",
    "start": "3062480",
    "end": "3067850"
  },
  {
    "text": "found that sometimes the row number function is slow so we had to do some work around using rank or something",
    "start": "3067850",
    "end": "3073580"
  },
  {
    "text": "similar and fourth if you are trying to access from a partitions partitioned",
    "start": "3073580",
    "end": "3080180"
  },
  {
    "text": "table then the body polishing column in",
    "start": "3080180",
    "end": "3086180"
  },
  {
    "text": "the query which is used for the polishing pruning should have the explicit values now if you try to deduce",
    "start": "3086180",
    "end": "3092990"
  },
  {
    "text": "that value using a sub-query or something else plus two dozen the pistol optimizer doesn't know the values of",
    "start": "3092990",
    "end": "3100280"
  },
  {
    "text": "front then it will try to do a full table scan so it obviously is hugely expensive so explicit values partition",
    "start": "3100280",
    "end": "3108590"
  },
  {
    "text": "key are very important and then finally I would say when you are doing a group",
    "start": "3108590",
    "end": "3114920"
  },
  {
    "text": "by the columns in the high cardinality should come first when you run a query",
    "start": "3114920",
    "end": "3121340"
  },
  {
    "text": "and that we have found has big performance gains okay great so I've",
    "start": "3121340",
    "end": "3130970"
  },
  {
    "text": "gone through most of the questions that have been submitted here and I think we're about out of time for this webinar",
    "start": "3130970",
    "end": "3138830"
  },
  {
    "text": "I do want to go ahead and wear emphasized everybody to please stay",
    "start": "3138830",
    "end": "3145010"
  },
  {
    "text": "connected to the webinar went in to complete a brief survey about the",
    "start": "3145010",
    "end": "3150350"
  },
  {
    "text": "conclusion you know at the conclusion and we do look forward to supporting you incurring future projects we do",
    "start": "3150350",
    "end": "3156080"
  },
  {
    "text": "apologize for the technical difficulties we were we're having what the presentation itself and as another",
    "start": "3156080",
    "end": "3161450"
  },
  {
    "text": "reminder the links to the the deck will be available for SlideShare as well",
    "start": "3161450",
    "end": "3168059"
  },
  {
    "text": "as the recording of the webinar on YouTube and they will be distributed to you via a follow-up email that you'll",
    "start": "3168059",
    "end": "3174119"
  },
  {
    "text": "receive two to three days later I so again please remain connected and and",
    "start": "3174119",
    "end": "3180089"
  },
  {
    "text": "complete the brief survey the end of this webinar or your feedback is very important to us thank you",
    "start": "3180089",
    "end": "3187849"
  },
  {
    "text": "you",
    "start": "3194299",
    "end": "3196359"
  }
]
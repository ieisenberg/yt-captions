[
  {
    "text": "okay so let's go ahead and get started as with many capabilities of AWS there's",
    "start": "0",
    "end": "5940"
  },
  {
    "text": "choices that you can make when you decide to move a workload into AWS and one of those choices is you know what's",
    "start": "5940",
    "end": "12030"
  },
  {
    "text": "the level of abstraction that I want the services that I consume from AWS you can do things and deploy software and",
    "start": "12030",
    "end": "18330"
  },
  {
    "text": "products on ec2 and full operating systems get full control and customizability of those we also have a",
    "start": "18330",
    "end": "24930"
  },
  {
    "text": "class of services that for this discussion today we call managed services and these are services where",
    "start": "24930",
    "end": "30720"
  },
  {
    "text": "servers are still there there's still a concern they're still exposed to you in",
    "start": "30720",
    "end": "37110"
  },
  {
    "text": "some capability in order for you to operate with that service for example you might size that service scale it out",
    "start": "37110",
    "end": "43860"
  },
  {
    "text": "scale it in and with these managed classes of services you typically do that you know with servers in mind and",
    "start": "43860",
    "end": "50219"
  },
  {
    "text": "then there's a class of services that we're calling serverless services and that's where this this notion of servers",
    "start": "50219",
    "end": "56940"
  },
  {
    "text": "and containers is completely removed from the the consumption of those services and the interaction with those",
    "start": "56940",
    "end": "63270"
  },
  {
    "text": "services you never have to be concerned with them to scale in or scale out as an example so the name server lists to us",
    "start": "63270",
    "end": "71549"
  },
  {
    "text": "at AWS means no servers or containers to manage both of those environments",
    "start": "71549",
    "end": "76560"
  },
  {
    "text": "although great for a lot of workloads and use cases have nuances right there's",
    "start": "76560",
    "end": "81750"
  },
  {
    "text": "things specific to servers into containers that you always have to manage and you don't have to worry about",
    "start": "81750",
    "end": "87330"
  },
  {
    "text": "those things in the server list world server lists also means high availability all of the services we're",
    "start": "87330",
    "end": "93780"
  },
  {
    "text": "going to be talking about today in our patterns span the entire AWS region their regional services so they",
    "start": "93780",
    "end": "99509"
  },
  {
    "text": "automatically take advantage of all the availability zones inside each of those regions for high availability serverless",
    "start": "99509",
    "end": "106140"
  },
  {
    "text": "applications also inherently scale and that is maybe the most important of these because it's really hard to",
    "start": "106140",
    "end": "113250"
  },
  {
    "text": "implement horizontal scale when you're working with servers very difficult to do so serb lists as your requests or",
    "start": "113250",
    "end": "120600"
  },
  {
    "text": "events increase coming in to your application server lists will handle the scale for you on the backend as the",
    "start": "120600",
    "end": "126719"
  },
  {
    "text": "requests die back down service will automatically scale that back down and if you don't have any requests coming in",
    "start": "126719",
    "end": "132690"
  },
  {
    "text": "then that means your back end is completely idle you never pay for anything with serverless",
    "start": "132690",
    "end": "137940"
  },
  {
    "text": "in those situations so those are really important tenants that you can apply to all of these patterns we're gonna be",
    "start": "137940",
    "end": "143610"
  },
  {
    "text": "talking about today now well you need to talk about lambda functions a little bit",
    "start": "143610",
    "end": "148920"
  },
  {
    "text": "I want to first explain the execution lifecycle of a lambda function there's",
    "start": "148920",
    "end": "154260"
  },
  {
    "text": "two types of indications cold and warm cold start and warm start a cold start",
    "start": "154260",
    "end": "159269"
  },
  {
    "text": "is the first time you invoke a lambda function it's going to download the code that you've uploaded into the service",
    "start": "159269",
    "end": "165090"
  },
  {
    "text": "create a container for those start the runtime copy all of your packet everything you've packaged up into that",
    "start": "165090",
    "end": "171180"
  },
  {
    "text": "container basically get it ready to run and start executing some initialization code a warm start means that it just",
    "start": "171180",
    "end": "177510"
  },
  {
    "text": "invokes at the entry point the handler function that you define when you create the the lambda function so a cold start",
    "start": "177510",
    "end": "185519"
  },
  {
    "text": "will happen the first time subsequent implications will just be a warm start but eventually lambda may take that",
    "start": "185519",
    "end": "191880"
  },
  {
    "text": "container back and reclaim that those resources for other customers and other workloads and if that happens the next",
    "start": "191880",
    "end": "197940"
  },
  {
    "text": "time you invite your lambda function you go through that cold start process again so it becomes really important to talk about the cold starting to talk about",
    "start": "197940",
    "end": "204239"
  },
  {
    "text": "you know how you can improve that and make it as fast as possible so that's",
    "start": "204239",
    "end": "211260"
  },
  {
    "text": "where we have the the tuning knob for lambda which is the memory tuning knob whenever you configure a lambda function you have one dial to dial up or dial",
    "start": "211260",
    "end": "218069"
  },
  {
    "text": "down and that's memory but what a lot of people don't realize is that dial also affects CPU and network bandwidth so if",
    "start": "218069",
    "end": "225299"
  },
  {
    "text": "you need more memory great you dial that knob but also if you need more CPU if it's a compute intensive code or",
    "start": "225299",
    "end": "231930"
  },
  {
    "text": "application that's running inside the lambda functions or if you need more networking bandwidth maybe you're interacting with s3 to download your",
    "start": "231930",
    "end": "238530"
  },
  {
    "text": "code is an example or back-end systems you know the networking there as well will increase as you increase your",
    "start": "238530",
    "end": "245639"
  },
  {
    "text": "memory down and this is important because a lot of times we see customers save money by turning that dial up if",
    "start": "245639",
    "end": "252660"
  },
  {
    "text": "your lambda function you know don't just start with the smallest 128 Meg's and say well it's going to be the least expensive that's my primary driver you",
    "start": "252660",
    "end": "259470"
  },
  {
    "text": "know sometimes turning that up alleviates bottlenecks and makes your entire lambda function execute quicker",
    "start": "259470",
    "end": "264479"
  },
  {
    "text": "we see that happen quite a bit to help you size your lambda functions appropriately check out a project like",
    "start": "264479",
    "end": "270790"
  },
  {
    "text": "this this one was actually created by one of our colleagues in Italy on github for you to use uses eight of us step",
    "start": "270790",
    "end": "276190"
  },
  {
    "text": "functions you can specify many different sizes of that memory knob and see what the results are how long they take to",
    "start": "276190",
    "end": "281530"
  },
  {
    "text": "execute and find the most optimal size and calculate your costs some other best practices around lambda specifically the",
    "start": "281530",
    "end": "288550"
  },
  {
    "text": "smaller your package size that you upload the faster it's going to be number one right you can use",
    "start": "288550",
    "end": "293680"
  },
  {
    "text": "technologies like minify we're applicable if you're writing your lambda functions in Java or.net those SDKs from",
    "start": "293680",
    "end": "300160"
  },
  {
    "text": "AWS are modular so you can just include the pieces of those SDKs or the modules that you need with your lambda function",
    "start": "300160",
    "end": "307150"
  },
  {
    "text": "and that's really nice specifically around Java and concern around Java cold-start x there's a few also there's",
    "start": "307150",
    "end": "314680"
  },
  {
    "text": "a few best practices there as well first of all how you package the the lambda function when you upload it to the",
    "start": "314680",
    "end": "320800"
  },
  {
    "text": "service can impact the cold start times in the performance there's two ways to",
    "start": "320800",
    "end": "326470"
  },
  {
    "text": "do it with job and one is you can have a single jar file with all your classes but that can result in a lot of individual class files inside of a",
    "start": "326470",
    "end": "333250"
  },
  {
    "text": "single jar which can be inefficient to work with a better approach is to take your dependency jars put them in a Lib",
    "start": "333250",
    "end": "338830"
  },
  {
    "text": "directory as an example and then zip it up and upload it to the lambda service also some older Java frameworks like",
    "start": "338830",
    "end": "345940"
  },
  {
    "text": "spring and spring boots they do a lot of dependency injection at runtime by",
    "start": "345940",
    "end": "351850"
  },
  {
    "text": "default and that's just not friendly for lambda environments you know it increases your cold start time so we're",
    "start": "351850",
    "end": "358810"
  },
  {
    "text": "possible try to favor simpler smaller more agile frameworks that do the same",
    "start": "358810",
    "end": "364750"
  },
  {
    "text": "thing for you like dagger 2 in this case and if you're doing any Java data",
    "start": "364750",
    "end": "370150"
  },
  {
    "text": "binding like maybe converting a plain old Java object into JSON you know leverage some of the smaller and simpler",
    "start": "370150",
    "end": "376090"
  },
  {
    "text": "frameworks for that as well like jackson junior lambda also have support for environment variables these allow you to",
    "start": "376090",
    "end": "382390"
  },
  {
    "text": "change configurations for your lambda function it allows you to change a configuration which affects how your",
    "start": "382390",
    "end": "388720"
  },
  {
    "text": "code runs right so you can change these variables these are configuration parameters then your code executes",
    "start": "388720",
    "end": "394270"
  },
  {
    "text": "differently because it references those those variables you can also store secrets inside",
    "start": "394270",
    "end": "399370"
  },
  {
    "text": "environment variables in lambda and that's really useful for low latency application needs you can also store",
    "start": "399370",
    "end": "406419"
  },
  {
    "text": "secrets in AWS and a Tobias Secrets manager and that's an absolutely great place to store your secrets it's outside",
    "start": "406419",
    "end": "412479"
  },
  {
    "text": "of lambda so a lot of different services will be able to leverage those secrets but if you need the lowest latency access to secrets maybe to downstream",
    "start": "412479",
    "end": "419530"
  },
  {
    "text": "databases or something like that these environment variables now you're also",
    "start": "419530",
    "end": "424660"
  },
  {
    "text": "going to need some tooling around your lambda functions you're going to need to handle or be able to promote your code",
    "start": "424660",
    "end": "431199"
  },
  {
    "text": "and deploy new versions safely you're going to need to be able to enable developer scenarios for local testing",
    "start": "431199",
    "end": "436780"
  },
  {
    "text": "and promotions into AWS developers still work locally and encode locally on a",
    "start": "436780",
    "end": "442510"
  },
  {
    "text": "laptop so you have to enable that and probably most importantly you need to be able to define your serverless",
    "start": "442510",
    "end": "448810"
  },
  {
    "text": "applications as a single version of entity that you can deliver through your delivery and development pipelines and",
    "start": "448810",
    "end": "455410"
  },
  {
    "text": "that's where the serverless application model or sam comes into play this is two",
    "start": "455410",
    "end": "461050"
  },
  {
    "text": "things it's a template specification so you can define all your server list components in a much abbreviated way in",
    "start": "461050",
    "end": "467020"
  },
  {
    "text": "the events that trigger all your lambda functions and it's also a CLI that lets you do the local testing and debug and",
    "start": "467020",
    "end": "473500"
  },
  {
    "text": "then promotions into AWS it also has support for things like global configurations so you know you don't",
    "start": "473500",
    "end": "479530"
  },
  {
    "text": "have to define every attribute of every lambda function for every lambda function you know you can define them globally you know what's my run time you",
    "start": "479530",
    "end": "486550"
  },
  {
    "text": "know what's any attribute associated what are my environment vera's whatever the case may be and do that globally",
    "start": "486550",
    "end": "492520"
  },
  {
    "text": "with your API your lambda functions so that all the other resources can use those and the team's been hard at work",
    "start": "492520",
    "end": "497889"
  },
  {
    "text": "adding new features we support API gateway authorizers now which we'll talk about in an upcoming slide single line",
    "start": "497889",
    "end": "504010"
  },
  {
    "text": "course configuration you know where was that a few years ago really easy to do with with serverless application model",
    "start": "504010",
    "end": "509800"
  },
  {
    "text": "and manage policies much like ims had managed policies for I am to give you",
    "start": "509800",
    "end": "515400"
  },
  {
    "text": "really easy ways to set up restrictive access for your lambda functions you can define that now and in Sam as well",
    "start": "515400",
    "end": "521760"
  },
  {
    "text": "probably the easiest way for developers to take advantage of Sam is through cloud 9 this is our browser-based IDE",
    "start": "521760",
    "end": "529089"
  },
  {
    "text": "and it's a poll supports multiple users working the same project at the same time so",
    "start": "529089",
    "end": "534570"
  },
  {
    "text": "it's a collaborative IDE you can author your Sam templates from here and validate them",
    "start": "534570",
    "end": "539970"
  },
  {
    "text": "you can upload your code into a git repository and begin deploying that for",
    "start": "539970",
    "end": "546030"
  },
  {
    "text": "your delivery pipeline now in the AWS world we have a code repository that's",
    "start": "546030",
    "end": "551580"
  },
  {
    "text": "private called code commit and we also have a suite of code services here that will take your code through a pipeline",
    "start": "551580",
    "end": "557310"
  },
  {
    "text": "perform the build steps integrate any third-party testing that you need and ultimately deploy that right you can",
    "start": "557310",
    "end": "563490"
  },
  {
    "text": "leverage cloud formation which Sam does as well as code deploy to do your deployments and you know you can you're",
    "start": "563490",
    "end": "570360"
  },
  {
    "text": "free to go into those individual consoles and string all of that together but it's actually a lot easier now with code star so code star is a console that",
    "start": "570360",
    "end": "578130"
  },
  {
    "text": "you can go into that's a wrapper around all of these deployment and development pipeline services and you can go in and",
    "start": "578130",
    "end": "586110"
  },
  {
    "text": "create a new project say hey when we create a service web app is an example choose your runtime and it will actually",
    "start": "586110",
    "end": "592650"
  },
  {
    "text": "create all of the things in these services that it needs string them all together according to our best practices it'll even spin up a cloud9 IDE for you",
    "start": "592650",
    "end": "599550"
  },
  {
    "text": "ready to go with a Sam template that you can use to start getting to get started so really really nice and easy way to",
    "start": "599550",
    "end": "606510"
  },
  {
    "text": "get going with some of this stuff lambda also supports traffic shifting or safe",
    "start": "606510",
    "end": "612510"
  },
  {
    "text": "deployments through the serverless application model so in your Sam templates you can specify this auto",
    "start": "612510",
    "end": "618480"
  },
  {
    "text": "publish alias line and when you upload a new code to an existing lambda function",
    "start": "618480",
    "end": "623670"
  },
  {
    "text": "it will detect that and it will allow you to specify a traffic shifting policy you've got nine of those listed here",
    "start": "623670",
    "end": "630450"
  },
  {
    "text": "this is actually handled by code deploy under the covers so you can do canary deployments you can say I just want 10%",
    "start": "630450",
    "end": "636420"
  },
  {
    "text": "of my traffic to go to that new version and I want to associate up to ten cloud watch alarms with that if any of those",
    "start": "636420",
    "end": "642300"
  },
  {
    "text": "alarms fire I'm gonna revert back to the old version there's also linear deployments where you can go up by ten percent every so",
    "start": "642300",
    "end": "648990"
  },
  {
    "text": "every so often according to every time interval that you see there and if you need more flexibility with this",
    "start": "648990",
    "end": "654900"
  },
  {
    "text": "deployment then we have a blog post out there that really uses step functions to do very similar things it just gives you",
    "start": "654900",
    "end": "661170"
  },
  {
    "text": "more customized ability instead of those nine predefined deployment you do whatever you want to here okay so",
    "start": "661170",
    "end": "666790"
  },
  {
    "text": "this is a good blog that has some a template to get you started okay so",
    "start": "666790",
    "end": "671860"
  },
  {
    "text": "that's a little bit about the background right that's what is serverless lambda function some optimization for those and",
    "start": "671860",
    "end": "677110"
  },
  {
    "text": "some tooling around those lambda functions now we're going to start with the first pattern which is our web application pattern this is what the web",
    "start": "677110",
    "end": "684910"
  },
  {
    "text": "application pattern looks like at the top you have static content stored in an s3 bucket that's front ended with a",
    "start": "684910",
    "end": "691329"
  },
  {
    "text": "cloud front distribution and then dynamic requests funneled down along the bottom to API gateway that provides a",
    "start": "691329",
    "end": "697209"
  },
  {
    "text": "rest endpoint for your api's and typically the most common pattern is to",
    "start": "697209",
    "end": "703240"
  },
  {
    "text": "have a lambda function behind those rest endpoints which in turn can contact some downstream service in this case dynamodb",
    "start": "703240",
    "end": "710709"
  },
  {
    "text": "but it could be other back-end services as well like Aurora service DynamoDB",
    "start": "710709",
    "end": "716500"
  },
  {
    "text": "released a lot of great features in 2018 it's been a busy year for them backup & restore point in time recovery to go",
    "start": "716500",
    "end": "723100"
  },
  {
    "text": "back in case errors occurred so you can recover from those errors and also adaptive capacity hasn't really been",
    "start": "723100",
    "end": "730449"
  },
  {
    "text": "touted very much but it used to be with dynamo DB you get hot partitions and you could consume all the bandwidth of one",
    "start": "730449",
    "end": "736540"
  },
  {
    "text": "partition very easily but now dynamodb will borrow throughput and bandwidth from some of the other",
    "start": "736540",
    "end": "741790"
  },
  {
    "text": "unused partitions so that the hot partition can continue to execute and",
    "start": "741790",
    "end": "747310"
  },
  {
    "text": "then you have Cognito for sign up and sign-in capabilities and for Federation so if you're in a corporate environment",
    "start": "747310",
    "end": "753279"
  },
  {
    "text": "if you have Active Directory Federation services or some other identity provider you can build these applications",
    "start": "753279",
    "end": "759069"
  },
  {
    "text": "according to this pattern and you can Fedder eight with your existing identity providers customink",
    "start": "759069",
    "end": "766209"
  },
  {
    "text": "uses this exact pattern and you guys familiar with custom Inc out there it's a really cool site you can go upload",
    "start": "766209",
    "end": "771639"
  },
  {
    "text": "clipart they make t-shirts and apparel for family events I'm sure you've seen the family reunion t-shirts that people",
    "start": "771639",
    "end": "778540"
  },
  {
    "text": "wear sometimes you know great use case for custom ink but they actually went from a legacy environment based on ec2",
    "start": "778540",
    "end": "785440"
  },
  {
    "text": "they had problems with scaling they had problems during high peak usage and specifically their most problematic area",
    "start": "785440",
    "end": "792670"
  },
  {
    "text": "of their website was the clipart upload manipulation portion so they moved that",
    "start": "792670",
    "end": "797800"
  },
  {
    "text": "over to service with API gateway and lambda and they've been able to realize up to 90% savings and a much more reliable",
    "start": "797800",
    "end": "805930"
  },
  {
    "text": "environment okay now back to this pattern I want to drill into API gateway",
    "start": "805930",
    "end": "813460"
  },
  {
    "text": "a little bit because there's a lot of choices around API gateway specifically with this pattern there are three types",
    "start": "813460",
    "end": "819610"
  },
  {
    "text": "of API gateway API is that you can create in AWS the first one and the one",
    "start": "819610",
    "end": "825040"
  },
  {
    "text": "that's been around the longest is an edge optimized API and that just means the API actually",
    "start": "825040",
    "end": "830770"
  },
  {
    "text": "exists at our cloud front locations and the API gateway team creates a",
    "start": "830770",
    "end": "836410"
  },
  {
    "text": "CloudFront distribution for any API you spin up of this type but that distribution is not exposed to you at",
    "start": "836410",
    "end": "843070"
  },
  {
    "text": "all you can't enable caching on that you can't take advantage of many of the cloud cloud front features so",
    "start": "843070",
    "end": "850410"
  },
  {
    "text": "fortunately you don't pay for it but it's it's there but you you're unable to take advantage of it so you might have a",
    "start": "850410",
    "end": "856330"
  },
  {
    "text": "need to put a cloud front distribution in front of your API in this pattern sharing your cloud front distribution",
    "start": "856330",
    "end": "863260"
  },
  {
    "text": "for both the s3 content and your API now this introduces some some patterns",
    "start": "863260",
    "end": "869950"
  },
  {
    "text": "we used to recommend this for wife you know if you wanted to put AWS wife in front of your API you could do that at a",
    "start": "869950",
    "end": "875500"
  },
  {
    "text": "cloud front layer but it also introduces now lambda add edge into the picture lambda add edge or lambda functions that",
    "start": "875500",
    "end": "883060"
  },
  {
    "text": "run at our edge locations and you can do some really creative things with this a",
    "start": "883060",
    "end": "888220"
  },
  {
    "text": "lot of use cases for example you can actually create and customize content and experiences for your users without",
    "start": "888220",
    "end": "894700"
  },
  {
    "text": "ever changing your back-end you can do all of that stuff at the edge because these lambda edge functions can now make",
    "start": "894700",
    "end": "900340"
  },
  {
    "text": "Network calls into other AWS services you can also do things like URL",
    "start": "900340",
    "end": "905500"
  },
  {
    "text": "rewriting pretty URLs to help with search engine optimization you can validate authorization tokens when they",
    "start": "905500",
    "end": "911950"
  },
  {
    "text": "come in at the edge a lot of great scenarios to take advantage of with lambda edge and we have blueprints for",
    "start": "911950",
    "end": "917920"
  },
  {
    "text": "most of these so when you go into the lambda console and you create a function you'll see at the top you can search",
    "start": "917920",
    "end": "922960"
  },
  {
    "text": "through blueprints starting points for your lambda functions and if you just search through cloud front the word",
    "start": "922960",
    "end": "928480"
  },
  {
    "text": "cloud front you'll see all of these blueprints and you can start from them for all of these different use cases there's also a",
    "start": "928480",
    "end": "936200"
  },
  {
    "text": "several this application repository I'll just quickly mention that's at that same location when you create a lambda",
    "start": "936200",
    "end": "941750"
  },
  {
    "text": "function and these are entire serverless applications that you can start from that people share based on Sam templates",
    "start": "941750",
    "end": "948320"
  },
  {
    "text": "so check that out as well I think that's very useful the second type of API gateway API is a regional API and we",
    "start": "948320",
    "end": "955460"
  },
  {
    "text": "came out with this after edge optimized api's to help with regional failover",
    "start": "955460",
    "end": "961040"
  },
  {
    "text": "disaster recovery scenarios so you build out your serverless environment according to the pattern we talked about in one region now you can do that in a",
    "start": "961040",
    "end": "968300"
  },
  {
    "text": "second region and you can share the same TLS certificate so you can put both of",
    "start": "968300",
    "end": "973370"
  },
  {
    "text": "those behind the same host name that's may be managed and routed through route 53 as you see in this example so route",
    "start": "973370",
    "end": "980660"
  },
  {
    "text": "53 could do 0-100 weightings you know send all your traffic to one region and then in the case of a failover you know",
    "start": "980660",
    "end": "986750"
  },
  {
    "text": "send your traffic to another region or you could have both of them active at the same time and you can use DynamoDB",
    "start": "986750",
    "end": "992240"
  },
  {
    "text": "global tables in the backend to move your rights keep your rights in sync between your DynamoDB tables in both of",
    "start": "992240",
    "end": "999020"
  },
  {
    "text": "those regions you can still put cloud front distributions in front of each of",
    "start": "999020",
    "end": "1004030"
  },
  {
    "text": "these regional api so that's still a valid pattern in this particular case I'm still leveraging route 53 to do the",
    "start": "1004030",
    "end": "1011260"
  },
  {
    "text": "routing between those two now cloud front endpoints ok but you can move to a",
    "start": "1011260",
    "end": "1017860"
  },
  {
    "text": "single cloud front distribution as well with lambda at edge and move the logic of routing to lambda at edge so you can",
    "start": "1017860",
    "end": "1024730"
  },
  {
    "text": "maybe take the country the origin location of that incoming request and use that to route to the specific",
    "start": "1024730",
    "end": "1031390"
  },
  {
    "text": "endpoint that you'd like or other logic so the nice thing is you have the flexibility with lambda edge to do that",
    "start": "1031390",
    "end": "1036689"
  },
  {
    "text": "and then the third type of API type with API gateway is a private API and this",
    "start": "1036690",
    "end": "1043060"
  },
  {
    "text": "just means it's inside the VPC it's not exposed at all to the public network or the public side of our data centers",
    "start": "1043060",
    "end": "1049290"
  },
  {
    "text": "systems and in instances in inside your VPC can contact that API directly and",
    "start": "1049290",
    "end": "1055540"
  },
  {
    "text": "we've also enabled scenarios through a double yes Direct Connect for private api's as well so if you have direct",
    "start": "1055540",
    "end": "1061000"
  },
  {
    "text": "connect today at an on-premises location you can use that to get to that private API endpoint",
    "start": "1061000",
    "end": "1066010"
  },
  {
    "text": "as well okay let's talk about security of serverless web applications many of",
    "start": "1066010",
    "end": "1073570"
  },
  {
    "text": "you I'm sure familiar with traditional web applications that are tiered according to a web layer and a logic",
    "start": "1073570",
    "end": "1078730"
  },
  {
    "text": "layer in the data layer and you have firewalls between those tiers that's traditionally how you handled security",
    "start": "1078730",
    "end": "1084279"
  },
  {
    "text": "it's different with serverless there's different security features every one of the services we're talking about has",
    "start": "1084279",
    "end": "1089860"
  },
  {
    "text": "their own security features that you can implement they give you multiple layers of protection s3 has bucket policies",
    "start": "1089860",
    "end": "1096640"
  },
  {
    "text": "these are resource policies that control who can access that bucket you could whitelist blacklist IPS or VP sees for",
    "start": "1096640",
    "end": "1103419"
  },
  {
    "text": "example clout front has origin access identity to prevent anybody except cloud",
    "start": "1103419",
    "end": "1109270"
  },
  {
    "text": "front from getting to that s3 bucket and has the ability to leverage signed cookies and signed URLs for requests",
    "start": "1109270",
    "end": "1116049"
  },
  {
    "text": "coming in and it provides DDoS protection which probably by itself is enough region reason to put a cloud",
    "start": "1116049",
    "end": "1122289"
  },
  {
    "text": "front distribution in front of your application down at the bottom on the API gateway side there's authorizers for",
    "start": "1122289",
    "end": "1128500"
  },
  {
    "text": "every single method an api that your clients may call so at a method level you can make sure that people are",
    "start": "1128500",
    "end": "1134590"
  },
  {
    "text": "authorized and we'll talk about some of the strategies to do that there's also this notion now of resource policies at",
    "start": "1134590",
    "end": "1141340"
  },
  {
    "text": "the API gateway and lambda service level this is new resource policies is something AWS has done for quite a while",
    "start": "1141340",
    "end": "1147850"
  },
  {
    "text": "we've had bucket policies on s3 for many years and SQS has had resource policies for many years and many other services",
    "start": "1147850",
    "end": "1154270"
  },
  {
    "text": "and just in 2018 we announced the support for lambda and api gateway so now you can specify principles other",
    "start": "1154270",
    "end": "1162580"
  },
  {
    "text": "than identities to get access to those resources for example other VP C's or",
    "start": "1162580",
    "end": "1168370"
  },
  {
    "text": "other AWS accounts or IP addresses something other than identities and this enables cross account scenarios between",
    "start": "1168370",
    "end": "1175480"
  },
  {
    "text": "lambda and API gateways for example I can author functions in a central",
    "start": "1175480",
    "end": "1180730"
  },
  {
    "text": "location my lambda functions can be in a central AWS account and then I can have many api's across many teams and API",
    "start": "1180730",
    "end": "1188169"
  },
  {
    "text": "gateway api's that leverage those lambda functions in the other account I can also centralize my authorizers your",
    "start": "1188169",
    "end": "1194890"
  },
  {
    "text": "security team can build out the logic inside the authorizers and then all of the API scattered across all your AWS API gateway accounts can",
    "start": "1194890",
    "end": "1202120"
  },
  {
    "text": "leverage that and then dynamodb also has a few new security features this year encryption at rest a big round of",
    "start": "1202120",
    "end": "1209590"
  },
  {
    "text": "applause for that one and private V PC endpoints now let's talk a little bit",
    "start": "1209590",
    "end": "1215410"
  },
  {
    "text": "about kognito and how it can be leveraged to promote Federation and",
    "start": "1215410",
    "end": "1220570"
  },
  {
    "text": "sign-in and authorization for your server list web application so there's",
    "start": "1220570",
    "end": "1226210"
  },
  {
    "text": "two sides to Cognito there's Cognito identity pools and Cognito user pools the main job of Cognito identity pools",
    "start": "1226210",
    "end": "1233200"
  },
  {
    "text": "is to honor an authentication token from a down an upstream identity provider and",
    "start": "1233200",
    "end": "1239260"
  },
  {
    "text": "convert that or exchange that for IAM credentials so you can see in this",
    "start": "1239260",
    "end": "1244390"
  },
  {
    "text": "diagram I've got scenario a at the top and green and be in the middle and yellow those are both authorized API gateway",
    "start": "1244390",
    "end": "1253210"
  },
  {
    "text": "methods with iam authorization okay so I'm allowing people to call these api's",
    "start": "1253210",
    "end": "1258330"
  },
  {
    "text": "through iam authorization so in in scenario a maybe I'm authenticating to Facebook I get a token from Facebook or",
    "start": "1258330",
    "end": "1265690"
  },
  {
    "text": "some other identity provider I get a token from that provider I exchange that for I am credentials and as long as my",
    "start": "1265690",
    "end": "1271299"
  },
  {
    "text": "credentials have the privileges I'll be able to execute the method or the resource inside of the API gateway API",
    "start": "1271299",
    "end": "1277290"
  },
  {
    "text": "scenario B is the same way it sits instead of using some identity provider",
    "start": "1277290",
    "end": "1282640"
  },
  {
    "text": "out there that Cognito identity pool supports its using kognito user pools kognito user pools also provides a token",
    "start": "1282640",
    "end": "1288669"
  },
  {
    "text": "I exchange that token for I am credentials and I get authorized for that resource but that particular",
    "start": "1288669",
    "end": "1294010"
  },
  {
    "text": "scenario scenario B here is really useful for leveraging group memberships as well inside of Cognito user pools you",
    "start": "1294010",
    "end": "1299470"
  },
  {
    "text": "can say things like if you're a member of this group then I get access to this API and then the third white handle",
    "start": "1299470",
    "end": "1305860"
  },
  {
    "text": "authorization with Cognito is just directly validating the web tokens that Cognito user pools provides so in this",
    "start": "1305860",
    "end": "1313299"
  },
  {
    "text": "case we're not using iam authorization we're using a specific Cognito user pools authorizer we take the token",
    "start": "1313299",
    "end": "1319270"
  },
  {
    "text": "directly from Cognito user pools and API gateway validates that for us so that's",
    "start": "1319270",
    "end": "1325000"
  },
  {
    "text": "probably the lowest latency way to perform all three now if you want to go beyond that for",
    "start": "1325000",
    "end": "1330240"
  },
  {
    "text": "authorization you can actually create your own custom authorizers and they're called lambda authorizers there's two",
    "start": "1330240",
    "end": "1336150"
  },
  {
    "text": "types the token puts a some sort of identity token in the header the",
    "start": "1336150",
    "end": "1341370"
  },
  {
    "text": "authorization header the request and validates that and then you can add your own custom logic there and then there's",
    "start": "1341370",
    "end": "1346980"
  },
  {
    "text": "a request authorization type which can use any of the headers or query strings paths or stage variables and you can",
    "start": "1346980",
    "end": "1354120"
  },
  {
    "text": "create your own logic to authorize and that's really great for scenarios where you may want to have different authorization schemes for different",
    "start": "1354120",
    "end": "1360750"
  },
  {
    "text": "stages of your web application maybe in dev test authorized one way but in production authorize a different way a",
    "start": "1360750",
    "end": "1369140"
  },
  {
    "text": "lot of customers are looking at alternatives to REST API s when it comes",
    "start": "1369230",
    "end": "1374910"
  },
  {
    "text": "to creating really highly dynamic and responsive web and mobile applications and that's where graph QL comes and",
    "start": "1374910",
    "end": "1381390"
  },
  {
    "text": "deployed so this is also a part of serverless web applications now at AWS I",
    "start": "1381390",
    "end": "1386910"
  },
  {
    "text": "want to cover graph QL a little bit and then I'll talk about how we implement that at AWS let's imagine you had an API",
    "start": "1386910",
    "end": "1395190"
  },
  {
    "text": "that was for blog posts thousands of blog posts and I wanted to create an application that listed all of those",
    "start": "1395190",
    "end": "1401790"
  },
  {
    "text": "blog posts so I could choose one and get more details about it so with the REST API I might make a call to my endpoint",
    "start": "1401790",
    "end": "1409080"
  },
  {
    "text": "and say hey give me all the blog posts as a client I really just take whatever the back-end gives me it's going to give",
    "start": "1409080",
    "end": "1415440"
  },
  {
    "text": "me a list of those blog posts but it might give me a lot of details about those blog posts that I just don't need all I need is the title okay graph QL",
    "start": "1415440",
    "end": "1422490"
  },
  {
    "text": "enables that scenario it enables clients to specify just the information that",
    "start": "1422490",
    "end": "1427770"
  },
  {
    "text": "they want so I can actually make a request and say just give me the title even though the backend is set up to",
    "start": "1427770",
    "end": "1433290"
  },
  {
    "text": "provide a JSON document with a lot of different attributes related to the blog post and then I click on a blog post and",
    "start": "1433290",
    "end": "1440550"
  },
  {
    "text": "I want to be able to view details about that like maybe the author people comments the readers have left about",
    "start": "1440550",
    "end": "1445650"
  },
  {
    "text": "that blog post in the rest world that might involve multiple round trips to backends to endpoints I might go in and",
    "start": "1445650",
    "end": "1453210"
  },
  {
    "text": "get the comments in point and get all the comments and then I go get the biographies about the authors and their names and those are multiple",
    "start": "1453210",
    "end": "1459490"
  },
  {
    "text": "trips to my rest endpoint but with graph QL I have one endpoint for all my back-end data sources so I",
    "start": "1459490",
    "end": "1465640"
  },
  {
    "text": "make one call and request that information you get it back so ultimately you're left with a lot of network efficiencies by using graph QL",
    "start": "1465640",
    "end": "1472570"
  },
  {
    "text": "Facebook created this they open sourced it in 2015 and they create it because of",
    "start": "1472570",
    "end": "1477880"
  },
  {
    "text": "the responsiveness they needed in their applications and it's really gaining a lot of popularity it also supports offline modes and it",
    "start": "1477880",
    "end": "1484360"
  },
  {
    "text": "supports multiple transports not just HTTP but also MQTT over WebSockets and",
    "start": "1484360",
    "end": "1489730"
  },
  {
    "text": "that's great for subscribing to data you can subscribe to imposed in my scenario",
    "start": "1489730",
    "end": "1497470"
  },
  {
    "text": "my application would immediately reflect that change as soon as it gets added",
    "start": "1497470",
    "end": "1503340"
  },
  {
    "text": "now we implement graph QL at AWS with app Sync ok so check out AWS app sync it provides",
    "start": "1503340",
    "end": "1509380"
  },
  {
    "text": "several different resolvers for back-end data sources DynamoDB tables legacy applications",
    "start": "1509380",
    "end": "1514809"
  },
  {
    "text": "it supports Federation with Cognito there's even an HTTP resolver which you can use to wrap REST API so if you want",
    "start": "1514809",
    "end": "1521350"
  },
  {
    "text": "to do that ok so that's it for the web application pattern let's talk about some stream processing and some patterns",
    "start": "1521350",
    "end": "1528850"
  },
  {
    "text": "related to that for this section we're going to focus primarily on the Kinesis family of services there are four",
    "start": "1528850",
    "end": "1535000"
  },
  {
    "text": "services today with Kinesis may change later this week I don't know but for now there's four the first is video streams",
    "start": "1535000",
    "end": "1541660"
  },
  {
    "text": "we're not going to spend too much time on that but that's allowing you to put videos and time and coded data like",
    "start": "1541660",
    "end": "1546820"
  },
  {
    "text": "audio radar or lidar data in a stream and then you can create computer vision",
    "start": "1546820",
    "end": "1551980"
  },
  {
    "text": "or machine learning applications from that time series data my trip will talk about recognition video Amazon",
    "start": "1551980",
    "end": "1558370"
  },
  {
    "text": "recognition video and how that can work with Kinesis video streams to do facial recognition of video streams we're going",
    "start": "1558370",
    "end": "1565450"
  },
  {
    "text": "to focus primarily on data streams data firehose and data analytics now the",
    "start": "1565450",
    "end": "1571150"
  },
  {
    "text": "easiest way I think to ingest data into AWS and deliver it to a location is with",
    "start": "1571150",
    "end": "1577120"
  },
  {
    "text": "Kinesis data firehose so I want to start there in this scenario you have record",
    "start": "1577120",
    "end": "1582340"
  },
  {
    "text": "producers and clients on the left side of this diagram and they're writing to the stream it usually a very fast ingest",
    "start": "1582340",
    "end": "1589840"
  },
  {
    "text": "rate the Kinesis agent is great here as well because if you have log files or text files that are",
    "start": "1589840",
    "end": "1595180"
  },
  {
    "text": "constantly being updated you can use the Kinesis agent just afford that information to a stream so it's really easy to implement first of all in the",
    "start": "1595180",
    "end": "1602440"
  },
  {
    "text": "bottom right hand corner you see source record backup that's a check box that you can enable to automatically preserve",
    "start": "1602440",
    "end": "1608410"
  },
  {
    "text": "all your original records as they enter the stream so that's a really easy thing to do to get backups of everything",
    "start": "1608410",
    "end": "1614050"
  },
  {
    "text": "before they're processed you can leverage a lambda function in this pattern to handle some lightweight transformations and enrichments in this",
    "start": "1614050",
    "end": "1620830"
  },
  {
    "text": "case at the top maybe looking up some values and dynamodb and adding that to your data before it gets processed and",
    "start": "1620830",
    "end": "1626140"
  },
  {
    "text": "the really important thing about firehose is that it can deliver to these known destinations that you see on the",
    "start": "1626140",
    "end": "1631780"
  },
  {
    "text": "right s3 elasticsearch redshift you don't have to write the code to take the data off",
    "start": "1631780",
    "end": "1637120"
  },
  {
    "text": "the stream and put it in the destination now you can also enable this scenario",
    "start": "1637120",
    "end": "1642250"
  },
  {
    "text": "with HTTP clients so instead of having some of those clients we talked about in the previous slide you just have browsers out there maybe and they're",
    "start": "1642250",
    "end": "1648820"
  },
  {
    "text": "sending HTTP posts and puts they can send that to a cloud print distribution with lambda edge and lambda edge can",
    "start": "1648820",
    "end": "1654490"
  },
  {
    "text": "then handle the task of placing that information onto the Kinesis stream so it can be delivered that's great for",
    "start": "1654490",
    "end": "1660610"
  },
  {
    "text": "clickstream analytics some best practices around Kinesis data firehose",
    "start": "1660610",
    "end": "1665770"
  },
  {
    "text": "first of all you have two envelopes to determine when data is delivered to those destinations it doesn't happen in",
    "start": "1665770",
    "end": "1672700"
  },
  {
    "text": "real time it happens when one of these envelopes fills up so I can specify a buffer size the amount of data and then",
    "start": "1672700",
    "end": "1679270"
  },
  {
    "text": "buffer in over interval the amount of time and as soon as one of those envelopes fills up its going to deliver",
    "start": "1679270",
    "end": "1684490"
  },
  {
    "text": "to that destination that I've specified okay so the lower you have those envelopes",
    "start": "1684490",
    "end": "1690310"
  },
  {
    "text": "the more often it's going to deliver right but the higher those envelopes are the more efficient it's going to be the",
    "start": "1690310",
    "end": "1696460"
  },
  {
    "text": "fewer calls it's going to make to your lambda function for enrichment or s3 puts that are going to be involved so",
    "start": "1696460",
    "end": "1702460"
  },
  {
    "text": "there's some trade-offs there Canisius firehose can also compress your data before it delivers that to the",
    "start": "1702460",
    "end": "1707920"
  },
  {
    "text": "destination so that's useful you might as well take advantage of that where possible now if you need near real-time",
    "start": "1707920",
    "end": "1713760"
  },
  {
    "text": "processing of stream data then we recommend Kinesis data streams and lambda as a consumer of the data on that",
    "start": "1713760",
    "end": "1720910"
  },
  {
    "text": "data stream Kinesis data streams is scaled by shard each shard has one megabyte of ingest",
    "start": "1720910",
    "end": "1726570"
  },
  {
    "text": "and two megabytes of of egress bandwidth okay and you can assign a lambda",
    "start": "1726570",
    "end": "1732570"
  },
  {
    "text": "function one lambda function to process the data on each shard and only one now",
    "start": "1732570",
    "end": "1738809"
  },
  {
    "text": "you can't actually I'll take it about you can't have multiple lambda functions process shard but there they be totally separate applications totally separate",
    "start": "1738809",
    "end": "1745289"
  },
  {
    "text": "iterators for different purposes with different logic but one lambda function per application per shard",
    "start": "1745289",
    "end": "1751159"
  },
  {
    "text": "what happens is the lambda service reads the date off those Kinesis streams for you takes all the data off and then",
    "start": "1751159",
    "end": "1757380"
  },
  {
    "text": "hands it to your lambda function in batches so you need to make sure that the batch size is configured correctly",
    "start": "1757380",
    "end": "1763019"
  },
  {
    "text": "in this case it's small enough where that lambda function can process it efficiently in return to get more data",
    "start": "1763019",
    "end": "1770190"
  },
  {
    "text": "off of that but it's it's also big enough to prevent your data stream from backing up right you're getting enough",
    "start": "1770190",
    "end": "1776789"
  },
  {
    "text": "data off so it's not growing faster than your lambda function can process if that becomes an issue then we suggest maybe",
    "start": "1776789",
    "end": "1783389"
  },
  {
    "text": "looking at the fan-out pattern so in this pattern I'm changing the role of the lambda function from the processor",
    "start": "1783389",
    "end": "1790409"
  },
  {
    "text": "of the data on that stream to just a dispatcher that lambda function is reading off the shard and what it's",
    "start": "1790409",
    "end": "1796200"
  },
  {
    "text": "doing is it's invoking parallel lambda functions to actually do the processing and it can do that asynchronously come",
    "start": "1796200",
    "end": "1802860"
  },
  {
    "text": "back and get more data off the stream and invoke more lambda functions to process that data right",
    "start": "1802860",
    "end": "1807929"
  },
  {
    "text": "you lose ordering when you do this okay so that's one caveat to be aware of but",
    "start": "1807929",
    "end": "1813509"
  },
  {
    "text": "it will improve your latency so if latency is more important than ordering this is a great pattern to follow and",
    "start": "1813509",
    "end": "1820139"
  },
  {
    "text": "then the last component of Kinesis I want to talk about is Kinesis data analytics this gives you real time",
    "start": "1820139",
    "end": "1825570"
  },
  {
    "text": "insight into the data on your stream as its flowing in it gives you a sequel",
    "start": "1825570",
    "end": "1830759"
  },
  {
    "text": "interface to query that data and you can actually create outputs from these sequel queries and use the outputs to",
    "start": "1830759",
    "end": "1837990"
  },
  {
    "text": "deliver to other streams or lambda functions like you see here a lambda function maybe that's looking for high",
    "start": "1837990",
    "end": "1844919"
  },
  {
    "text": "valued metrics for whatever is on your stream could be delivered to SNS for a",
    "start": "1844919",
    "end": "1850350"
  },
  {
    "text": "notification as an example and you can also tear these sequel queries together so the output of one could be the input",
    "start": "1850350",
    "end": "1856590"
  },
  {
    "text": "of the other Kinesis data analytics also has a lot of built functions really advanced functions that",
    "start": "1856590",
    "end": "1862650"
  },
  {
    "text": "can help you get more insight into this data for example anomaly detection with random cut forest functions or the top",
    "start": "1862650",
    "end": "1869760"
  },
  {
    "text": "occurrences of a certain metric or maybe hotspots in your data so really advanced functions very easy to take advantage of",
    "start": "1869760",
    "end": "1876330"
  },
  {
    "text": "out of the box here's an example of a sequel statement that's that we used with Kinesis data analytics so this is a",
    "start": "1876330",
    "end": "1883559"
  },
  {
    "text": "real sequel statement in blue here you have kind of some of your boilerplate sequel your select statement in pink if",
    "start": "1883559",
    "end": "1891179"
  },
  {
    "text": "that's clear as you can see here I'm using connexxus data analytics step",
    "start": "1891179",
    "end": "1896850"
  },
  {
    "text": "function not to be confused with AWS as step function to group my readings according to a time window so I'm doing",
    "start": "1896850",
    "end": "1903870"
  },
  {
    "text": "some some time windowing analysis here and aggregations so I'm grouping them by 10-minute windows and then I'm doing",
    "start": "1903870",
    "end": "1910290"
  },
  {
    "text": "sums or counts or averages or whatever it is you want to do on that data and and that's in in purple in the middle",
    "start": "1910290",
    "end": "1916610"
  },
  {
    "text": "one of the customers that leverages these Kinesis data services is a ton of",
    "start": "1916610",
    "end": "1921960"
  },
  {
    "text": "moe a ton of Moe's in the connected car business and they're really responsible and have taken a view point of creating",
    "start": "1921960",
    "end": "1928950"
  },
  {
    "text": "an exchange of connected car data that's safe and anonymized they get data sources from multiple car manufacturers",
    "start": "1928950",
    "end": "1935880"
  },
  {
    "text": "and and other companies and they anonymize that and allow people to make applications from this data this is",
    "start": "1935880",
    "end": "1941910"
  },
  {
    "text": "location information about cars traffic patterns parking locations I mean there's a lot of different use cases in",
    "start": "1941910",
    "end": "1947970"
  },
  {
    "text": "this space but they use Kinesis data streams firehose as well as analytics to",
    "start": "1947970",
    "end": "1954090"
  },
  {
    "text": "enable these types of scenarios a lot of volume as well 200 million events per",
    "start": "1954090",
    "end": "1959490"
  },
  {
    "text": "day up to 500 thousand million events per second at peak and then lastly I",
    "start": "1959490",
    "end": "1965370"
  },
  {
    "text": "just want to leave you with a slide that might help you choose the correct messaging platforms for your",
    "start": "1965370",
    "end": "1971670"
  },
  {
    "text": "applications we've been very focused on Kinesis in this section obviously but",
    "start": "1971670",
    "end": "1976740"
  },
  {
    "text": "there are other choices even in the service realm they have various attributes message ordering for example",
    "start": "1976740",
    "end": "1983870"
  },
  {
    "text": "with Kinesis data streams happens within a shard you also might have cat caught",
    "start": "1983870",
    "end": "1989220"
  },
  {
    "text": "last week we made an announcement with HTTP to support between lambda and kin data streams it's not something I talked",
    "start": "1989220",
    "end": "1996370"
  },
  {
    "text": "about in the previous slide but now you can able push scenarios into your lambda functions from the data on your Kinesis",
    "start": "1996370",
    "end": "2002400"
  },
  {
    "text": "data streams with this new feature it'll keep a connection open for up to five minutes and as new data arrives on",
    "start": "2002400",
    "end": "2008190"
  },
  {
    "text": "your stream that will be pushed versus the lambda service having you pull data and hand it back to your functions and",
    "start": "2008190",
    "end": "2013590"
  },
  {
    "text": "batches okay so that concludes my section on web application patterns and",
    "start": "2013590",
    "end": "2019890"
  },
  {
    "text": "streaming patterns I'm now gonna turn it over to Maitreya to talk about data like pattern thank you thank you drew so I'll",
    "start": "2019890",
    "end": "2033390"
  },
  {
    "text": "take you through the remaining two patterns I'll start with first talking about how you can collect store organize",
    "start": "2033390",
    "end": "2039900"
  },
  {
    "text": "as well as analyze all your organization's data in the data Lake pattern and I'll conclude with how you",
    "start": "2039900",
    "end": "2046140"
  },
  {
    "text": "can bring the power of machine learning to your applications to make them smarter to be able to serve your",
    "start": "2046140",
    "end": "2052770"
  },
  {
    "text": "customers better so let's start first with the data Lake the holiday season is just about upon us so we just had back",
    "start": "2052770",
    "end": "2059940"
  },
  {
    "text": "Friday and we had Cyber Monday yesterday so I thought it would be appropriate to look at a ecommerce example and build",
    "start": "2059940",
    "end": "2066060"
  },
  {
    "text": "that through our use case so if you are running an e-commerce site and you're responsible for analytics you know that",
    "start": "2066060",
    "end": "2071970"
  },
  {
    "text": "you'll be getting data from a variety of different sources that could be clique streams on your website that could be",
    "start": "2071970",
    "end": "2078690"
  },
  {
    "text": "data from your supply chain your inventory management that could also be reviews and social media posts by your",
    "start": "2078690",
    "end": "2085290"
  },
  {
    "text": "customers who are describing their experiences on your website that could be pretty unstructured so all that data",
    "start": "2085290",
    "end": "2091860"
  },
  {
    "text": "is valuable to your organization and it's important for you to be able to collect that and store it as",
    "start": "2091860",
    "end": "2098150"
  },
  {
    "text": "inexpensively as possible so that you can use tools and techniques to analyze that so you can improve your",
    "start": "2098150",
    "end": "2104730"
  },
  {
    "text": "operations business insights to make your efficiencies better and serve your customers ultimately better so as you",
    "start": "2104730",
    "end": "2111840"
  },
  {
    "text": "think about that one of the key attributes is to make sure that your compute is independent and decoupled",
    "start": "2111840",
    "end": "2118020"
  },
  {
    "text": "from your storage so you can scale those independently and pay for those as well",
    "start": "2118020",
    "end": "2123090"
  },
  {
    "text": "independently you also want to make sure that you store all your data in raw and unprocessed form in an open",
    "start": "2123090",
    "end": "2130529"
  },
  {
    "text": "format and that's important because of two reasons one is though you might have an idea of the questions you might want",
    "start": "2130529",
    "end": "2136740"
  },
  {
    "text": "to ask of that data today you don't know what you might need to ask of that data tomorrow you might have completely",
    "start": "2136740",
    "end": "2141990"
  },
  {
    "text": "different questions and having the raw data makes it possible for you to answer that likewise you might know what tools",
    "start": "2141990",
    "end": "2149640"
  },
  {
    "text": "you want to use today but they might be tools that come out in the future that you might want to deploy and use with",
    "start": "2149640",
    "end": "2155670"
  },
  {
    "text": "the same data so you want to keep that data in an open format so that you can use techniques like schema on read where",
    "start": "2155670",
    "end": "2162299"
  },
  {
    "text": "you don't define the schema when you write the data but you define it on the fly when you read it with the new tools",
    "start": "2162299",
    "end": "2167579"
  },
  {
    "text": "that come along so that in a sense are some attributes of a data Lake so how do",
    "start": "2167579",
    "end": "2173279"
  },
  {
    "text": "we implement a data Lake in the serverless world it really starts first with s3 as the core for some really good",
    "start": "2173279",
    "end": "2180599"
  },
  {
    "text": "reasons that we shall go into in a minute and we layer services around that for different functionality so we start",
    "start": "2180599",
    "end": "2187289"
  },
  {
    "text": "first with ingest and Dru talked about how you can use streaming services from the Kinesis family to stream your data",
    "start": "2187289",
    "end": "2193859"
  },
  {
    "text": "into your data Lake but what if you have a fleet of sensors devices IOT systems",
    "start": "2193859",
    "end": "2200670"
  },
  {
    "text": "that are sensing data and sending you measurements you can use AWS IOT to effectively collect that data and ingest",
    "start": "2200670",
    "end": "2207239"
  },
  {
    "text": "that into your data leak what if you have a different scenario you have systems that send you data using legacy",
    "start": "2207239",
    "end": "2212670"
  },
  {
    "text": "protocols like SFTP so I'm happy to announce that we had a service announced just on Monday which is called AWS",
    "start": "2212670",
    "end": "2219869"
  },
  {
    "text": "transfer for SFTP this is a fully managed service that lets you set up an SFTP endpoint point that to an s3 bucket",
    "start": "2219869",
    "end": "2227519"
  },
  {
    "text": "as you're back in and collect your data using SFTP from your legacy apps you can",
    "start": "2227519",
    "end": "2232980"
  },
  {
    "text": "use SSH keys for authentication or you can also connect up to your existing identity stores like ID Active Directory",
    "start": "2232980",
    "end": "2239880"
  },
  {
    "text": "for authenticating our users so great ways for you to get your data into s3",
    "start": "2239880",
    "end": "2244940"
  },
  {
    "text": "efficiently and quickly once you have your data in the data Lake it's important to let your users be able to",
    "start": "2244940",
    "end": "2251369"
  },
  {
    "text": "find it and to also be able to identify elements of interest to them and so",
    "start": "2251369",
    "end": "2256650"
  },
  {
    "text": "that's search and catalog we shall see patterns for that soon and you also want to give",
    "start": "2256650",
    "end": "2261850"
  },
  {
    "text": "your users a variety of choices in terms of the tools they want to use to analyze and process that we look at a couple of",
    "start": "2261850",
    "end": "2267550"
  },
  {
    "text": "examples here and also not to forget to mention there are lots of server based choices which work really well with s3",
    "start": "2267550",
    "end": "2273910"
  },
  {
    "text": "as a data link as well such as EMR we talked about how the data is really",
    "start": "2273910",
    "end": "2279820"
  },
  {
    "text": "valuable to your organization so it's important to be able to protect that data so there are lot of security features that you might want to take",
    "start": "2279820",
    "end": "2286000"
  },
  {
    "text": "advantage of the first problem you want to solve is to make sure that your users that are allowed to see the data are",
    "start": "2286000",
    "end": "2292270"
  },
  {
    "text": "actually have a business need to do so so you want to have permissions and controls and you can do that using",
    "start": "2292270",
    "end": "2297640"
  },
  {
    "text": "identity based policies in I am or you can use that do that based on resource",
    "start": "2297640",
    "end": "2303190"
  },
  {
    "text": "based policies using s3 buckets and s3 bucket policies and ACLs so take",
    "start": "2303190",
    "end": "2308320"
  },
  {
    "text": "advantage of that to define policies like financial data can only be accessed by the Finance Group or the Finance role",
    "start": "2308320",
    "end": "2315180"
  },
  {
    "text": "once you have your data in the data like you might be required to encrypt that at rest and the easiest way to do that is",
    "start": "2315180",
    "end": "2320980"
  },
  {
    "text": "to use encryption server-side with keys stored in kms you get a complete list of",
    "start": "2320980",
    "end": "2326380"
  },
  {
    "text": "audit of who accessed the data and when they used the end decrypt operations to",
    "start": "2326380",
    "end": "2331930"
  },
  {
    "text": "see that data it's also important to enable what's called data event logging which is s3 feature which now generates",
    "start": "2331930",
    "end": "2339790"
  },
  {
    "text": "cloud trail events so that you can audit all the accesses of data and your data leak and use that to identify if your",
    "start": "2339790",
    "end": "2347620"
  },
  {
    "text": "controls that you set up are working as expected almost by definition a data",
    "start": "2347620",
    "end": "2352660"
  },
  {
    "text": "leak is going to have different types of data so you might want to answer questions like does that data have",
    "start": "2352660",
    "end": "2357970"
  },
  {
    "text": "personally identifying from identifiable information does it have credit card numbers that it does it have social",
    "start": "2357970",
    "end": "2364330"
  },
  {
    "text": "security numbers do I know what's in my data leak so to help you answer that question you might want to consider",
    "start": "2364330",
    "end": "2370420"
  },
  {
    "text": "enabling it Amazon may see which is a service that crawls your data leak and",
    "start": "2370420",
    "end": "2375690"
  },
  {
    "text": "identifies indicators of this type of sensitive information and it highlights that to you in a dashboard so you can",
    "start": "2375690",
    "end": "2382270"
  },
  {
    "text": "see which elements of data have sensitive information of which types and you can take now actions to protect that",
    "start": "2382270",
    "end": "2389080"
  },
  {
    "text": "appropriately you might want to perhaps delete some of that to comply with your laws or encrypt that with different",
    "start": "2389080",
    "end": "2394390"
  },
  {
    "text": "techniques Macie also models user behavior so it learns what is normal for your",
    "start": "2394390",
    "end": "2399989"
  },
  {
    "text": "organization what are your users normally do and when it notices suspicious behavior so a user downloads",
    "start": "2399989",
    "end": "2405839"
  },
  {
    "text": "an entire corpus of data whereas in normal practice they download very small parts of that every day that might be an",
    "start": "2405839",
    "end": "2413039"
  },
  {
    "text": "indicator of a rogue user or a program that's trying to exfiltrate data you can be alerted of that and again you can",
    "start": "2413039",
    "end": "2419339"
  },
  {
    "text": "take actions to prevent that data loss now that you have your results from your",
    "start": "2419339",
    "end": "2425159"
  },
  {
    "text": "data like after your analysis you might want to now share that with your end users and you can do that using the web",
    "start": "2425159",
    "end": "2431429"
  },
  {
    "text": "or micro services patterns API gateway kognito that Dru talked about in pattern one so now let's answer the question why",
    "start": "2431429",
    "end": "2440279"
  },
  {
    "text": "is s3 a great foundation for a data Lake it really starts with that first principle which is decoupling storage",
    "start": "2440279",
    "end": "2446640"
  },
  {
    "text": "from compute you don't have to run a computer cluster just in order to store data compare that with if you were",
    "start": "2446640",
    "end": "2452909"
  },
  {
    "text": "storing your data in a Hadoop cluster on HDFS you do need a cluster running 24/7",
    "start": "2452909",
    "end": "2458009"
  },
  {
    "text": "whether you analyze that or not just for the storage so with s3 you just pay for storage and you can use multiple",
    "start": "2458009",
    "end": "2464969"
  },
  {
    "text": "analytics techniques as we shall see to analyze that data those two are not couple you can pay for that",
    "start": "2464969",
    "end": "2470279"
  },
  {
    "text": "independently and scale them indefinitely coming to scale s3 can scale virtually unlimited in terms of",
    "start": "2470279",
    "end": "2476969"
  },
  {
    "text": "the number of objects the volume precise as well as bandwidth as you throw as",
    "start": "2476969",
    "end": "2482789"
  },
  {
    "text": "much parallel readers a test at s3 and it'll scale according to that some",
    "start": "2482789",
    "end": "2489150"
  },
  {
    "text": "interesting features that are also perhaps less known is s3 select for example so this is a feature that lets",
    "start": "2489150",
    "end": "2495779"
  },
  {
    "text": "you push down your sequel query down to the s3 layer and say don't give me the",
    "start": "2495779",
    "end": "2501089"
  },
  {
    "text": "entire object as 3 just give me the rows and columns that match the sequel query that I just gave you great way for you",
    "start": "2501089",
    "end": "2507269"
  },
  {
    "text": "to reduce the amount of data that you read from your data leak and to make it very optimal in terms of how you get",
    "start": "2507269",
    "end": "2512909"
  },
  {
    "text": "your data back you can also protect your data in lake much better using two features here",
    "start": "2512909",
    "end": "2518400"
  },
  {
    "text": "the first is object tagging you can add tags to your objects and you can use those tags in policies again going back",
    "start": "2518400",
    "end": "2525419"
  },
  {
    "text": "to the finance example you can have objects which are tagged with owner was financed and you can have I am",
    "start": "2525419",
    "end": "2531250"
  },
  {
    "text": "policies that say that groups of users belonging to the finance role can access",
    "start": "2531250",
    "end": "2536920"
  },
  {
    "text": "data which is tagged with owner equals financed and no one else so it's a great way for you to organize and manage",
    "start": "2536920",
    "end": "2542140"
  },
  {
    "text": "accesses to your data another great feature that we announced about two weeks ago let you further",
    "start": "2542140",
    "end": "2547540"
  },
  {
    "text": "protect your resources in the data lake it's called block public access this is an account level set of properties that",
    "start": "2547540",
    "end": "2554410"
  },
  {
    "text": "will allow you to override bucket policies and object ACLs so even if",
    "start": "2554410",
    "end": "2560470"
  },
  {
    "text": "someone made a mistake at the bucket level or the object level and made an object public block public access will",
    "start": "2560470",
    "end": "2566530"
  },
  {
    "text": "override that and ensure that your objects are always private and your data leak stays protected so it avoids",
    "start": "2566530",
    "end": "2572800"
  },
  {
    "text": "mistakes happening so now we have your data in your data Lake you want to allow",
    "start": "2572800",
    "end": "2578980"
  },
  {
    "text": "your data analysts and users of that data to quickly find the data elements and data sets of interest to them you",
    "start": "2578980",
    "end": "2586720"
  },
  {
    "text": "want to allow them for example we've collected data about purchases products reviews perhaps inventory those are",
    "start": "2586720",
    "end": "2594550"
  },
  {
    "text": "different data sets and you want to let your users find those data sets using keywords like that as well as look up",
    "start": "2594550",
    "end": "2600970"
  },
  {
    "text": "information like I want inventory from a particular month in 2018 rather than",
    "start": "2600970",
    "end": "2606190"
  },
  {
    "text": "going to s3 and listing large lists of objects and trying to find those elements of interest you want to index",
    "start": "2606190",
    "end": "2611920"
  },
  {
    "text": "that and let them query a more optimized system so that is where you want to put your data into elastic search for free",
    "start": "2611920",
    "end": "2619480"
  },
  {
    "text": "text or keyword based searches and dynamodb for index based lookups and you",
    "start": "2619480",
    "end": "2624880"
  },
  {
    "text": "can do that using the pattern here objects arrived in s3 those can trigger a lambda function the function pulls out",
    "start": "2624880",
    "end": "2631480"
  },
  {
    "text": "metadata and writes that into DynamoDB or updates a search index and elastic search this is a well established",
    "start": "2631480",
    "end": "2637900"
  },
  {
    "text": "pattern and it actually is part of the data Lake solution the link below this",
    "start": "2637900",
    "end": "2642940"
  },
  {
    "text": "is a QuickStart that you can deploy into your account and get this type of pattern and much more deployed in a few",
    "start": "2642940",
    "end": "2648580"
  },
  {
    "text": "minutes now you have your data in your data Lake you want to let your users",
    "start": "2648580",
    "end": "2654130"
  },
  {
    "text": "actually be able to query that in order in order to do that you need a metadata index or a metadata catalog which",
    "start": "2654130",
    "end": "2659950"
  },
  {
    "text": "contains information about data formats are the files JSON yes V or Parque what are the column",
    "start": "2659950",
    "end": "2666730"
  },
  {
    "text": "types and what are the column data types right are they strings are the integers things like that and that is effectively",
    "start": "2666730",
    "end": "2673420"
  },
  {
    "text": "stored in a service called glue which has a feature called a glue catalog and a glue catalog is",
    "start": "2673420",
    "end": "2679210"
  },
  {
    "text": "hive meta store compatible so you can use a variety of tools to query that but",
    "start": "2679210",
    "end": "2684700"
  },
  {
    "text": "in order to populate that catalog you might want to use crawlers which are features of glue which you deploy and",
    "start": "2684700",
    "end": "2691420"
  },
  {
    "text": "unleash on your data Lake the crawlers will look at the data files that are in a data Lake identify the file types CSV",
    "start": "2691420",
    "end": "2698500"
  },
  {
    "text": "JSON or park' it will extract field information from those files essentially",
    "start": "2698500",
    "end": "2703960"
  },
  {
    "text": "the columns and the data types and populate that into your glue catalog if your file data changes in the future you",
    "start": "2703960",
    "end": "2711069"
  },
  {
    "text": "can rerun your crawlers and the crawlers will update update your catalog based on the new data once you have your data in",
    "start": "2711069",
    "end": "2717309"
  },
  {
    "text": "the catalog you can deploy tools like Athena which is a server less query service or Amazon redshift spectrum",
    "start": "2717309",
    "end": "2724809"
  },
  {
    "text": "which is a feature of redshift to query the data from the group glue metadata catalog and get you the results EMR",
    "start": "2724809",
    "end": "2732190"
  },
  {
    "text": "which is a server based service also supports the same catalog so you can query the data using multiple different methods another feature to call out is",
    "start": "2732190",
    "end": "2739839"
  },
  {
    "text": "that the data catalog has resource level policies which means that you can",
    "start": "2739839",
    "end": "2745359"
  },
  {
    "text": "control access to individual tables in the glue catalog again deciding that the",
    "start": "2745359",
    "end": "2750430"
  },
  {
    "text": "finance team went query tables related to finance data but no one else for",
    "start": "2750430",
    "end": "2755619"
  },
  {
    "text": "example we talked about analysis and how you want to essentially give your users",
    "start": "2755619",
    "end": "2762250"
  },
  {
    "text": "the widest array of choices so we have s3 select quick site which is a visualization service as well as Athena",
    "start": "2762250",
    "end": "2769270"
  },
  {
    "text": "and lambda we shall see in a minute but I also want to call out machine learning you might want to enable your users to",
    "start": "2769270",
    "end": "2774910"
  },
  {
    "text": "do predictive analytics and sage maker is a great way to do that it lets your users build train based on the data in",
    "start": "2774910",
    "end": "2782470"
  },
  {
    "text": "your data Lake as well as host machine learning models and those models can also be exported and deployed into ec2",
    "start": "2782470",
    "end": "2789520"
  },
  {
    "text": "instances as you wish oftentimes you want to do something that's called typically called extract transform load",
    "start": "2789520",
    "end": "2796450"
  },
  {
    "text": "so you have the today tonic you need to transform it in different ways and load it into a destination system like redshift you can",
    "start": "2796450",
    "end": "2804099"
  },
  {
    "text": "do that very easily with another feature of glue called the glue ETL glue can provide you and auto generate spark code",
    "start": "2804099",
    "end": "2811059"
  },
  {
    "text": "for you that you can customize and then once you have that code you can submit that to glue and you can use the glues",
    "start": "2811059",
    "end": "2817240"
  },
  {
    "text": "job execution framework to run that at scale on glues clusters completely server less and perform that",
    "start": "2817240",
    "end": "2823599"
  },
  {
    "text": "transformation and load that data into your destination system what if your",
    "start": "2823599",
    "end": "2829420"
  },
  {
    "text": "users don't want to actually run a cluster but they want to answer quick questions they want something that is exploratory or ad-hoc analysis they just",
    "start": "2829420",
    "end": "2836980"
  },
  {
    "text": "want to run X equal query and get the results quickly without the overhead of having to run a cluster 24/7 or wait for",
    "start": "2836980",
    "end": "2843010"
  },
  {
    "text": "that cluster to spin up a great fit for that use cases Athena it's a server less query service it starts by you just",
    "start": "2843010",
    "end": "2849970"
  },
  {
    "text": "writing a sequel in the Presto dialect submitting that to Athena and Athena",
    "start": "2849970",
    "end": "2855280"
  },
  {
    "text": "will run that query on a cluster of servers behind the scenes and get the results back to you in s3 it can be",
    "start": "2855280",
    "end": "2861819"
  },
  {
    "text": "really fast as you can see here a very simple example that crawled through about 160 gigs of data it Athena did so",
    "start": "2861819",
    "end": "2869770"
  },
  {
    "text": "at the rate of about 4 gigabytes per second I am also want to highlight the cost Athena charges you based on the amount",
    "start": "2869770",
    "end": "2876309"
  },
  {
    "text": "of data scanned and this query just cost 85 cents and if this is all the query",
    "start": "2876309",
    "end": "2881410"
  },
  {
    "text": "you ever run this is all you ever paid right you don't have to pay for a cluster running 24/7 just to answer this",
    "start": "2881410",
    "end": "2887680"
  },
  {
    "text": "particular ad hoc query a few best practices with Athena since Athena",
    "start": "2887680",
    "end": "2894160"
  },
  {
    "text": "charges you based on the amount of data scanned if you reduce that you reduce your cost as well as you get your",
    "start": "2894160",
    "end": "2899530"
  },
  {
    "text": "results faster so three techniques here the first is partitioning create a",
    "start": "2899530",
    "end": "2904540"
  },
  {
    "text": "naming convention something like this which lets you scope down your query based on date and month in year and so",
    "start": "2904540",
    "end": "2911349"
  },
  {
    "text": "that Athena will skip all the other files and other folders effectively in s3 that don't contain data matching your",
    "start": "2911349",
    "end": "2917170"
  },
  {
    "text": "query it's always a good idea to use columnar formats for two reasons columnar formats many of them support",
    "start": "2917170",
    "end": "2923950"
  },
  {
    "text": "compression which reduces the amount of data and Athena can use the columnar data to pull out only those column",
    "start": "2923950",
    "end": "2929710"
  },
  {
    "text": "blocks that you query knee if you have very wide columns you don't need to pull the data for all of them",
    "start": "2929710",
    "end": "2935230"
  },
  {
    "text": "and the third thing that that Athena can do is look at blog statistics which have information about max min on those",
    "start": "2935230",
    "end": "2941980"
  },
  {
    "text": "columns and it will skip those column blocks which don't have data matching your query criteria compression we",
    "start": "2941980",
    "end": "2948910"
  },
  {
    "text": "talked about but if you are compressing individual files use a splittable compression so that Athena can still",
    "start": "2948910",
    "end": "2954730"
  },
  {
    "text": "paralyze those queries across a cluster what if your processing needs are",
    "start": "2954730",
    "end": "2961300"
  },
  {
    "text": "slightly different you can't represent that easily in sequel it's custom logic or compute intensive work now you can",
    "start": "2961300",
    "end": "2968170"
  },
  {
    "text": "deploy that processing logic of course on ec2 server based or you can even use the service called AWS batch to",
    "start": "2968170",
    "end": "2974170"
  },
  {
    "text": "orchestrate that in terms of containers across the fleet of container servers but what if you want to take advantage",
    "start": "2974170",
    "end": "2980680"
  },
  {
    "text": "of the massively parallel computer available to you through lambda you have lots of parallel functions that you can",
    "start": "2980680",
    "end": "2986140"
  },
  {
    "text": "run and you can take advantage of that using a pattern like this here essentially this is a server less",
    "start": "2986140",
    "end": "2991870"
  },
  {
    "text": "MapReduce pattern it starts first with a splitter function which picks up work",
    "start": "2991870",
    "end": "2996970"
  },
  {
    "text": "from s3 besides the batches and the batches sizes and it invokes a bunch of",
    "start": "2996970",
    "end": "3002490"
  },
  {
    "text": "parallel lambda function invocations up to 1,000 parallel functions with the default limit and of course that limit",
    "start": "3002490",
    "end": "3009090"
  },
  {
    "text": "can be increased once those functions crunched through the data and they can now be invoked for up to 15 minutes so",
    "start": "3009090",
    "end": "3016050"
  },
  {
    "text": "that's a lot of compute time that you have those functions can write their intermediate results into dynamodb which",
    "start": "3016050",
    "end": "3021780"
  },
  {
    "text": "are picked up by a reducer function and final results go into s3 so you can get a lot of compute out of this an example",
    "start": "3021780",
    "end": "3028830"
  },
  {
    "text": "of a customer that uses this pattern is Fannie Mae they need to do a lot of financial modeling which turns out to be",
    "start": "3028830",
    "end": "3034830"
  },
  {
    "text": "a really compute intensive process mathematically compute intensive Monte Carlo simulations essentially and they",
    "start": "3034830",
    "end": "3041160"
  },
  {
    "text": "take advantage of this pattern to run that at scale and they found that moving from a server based approach to a server",
    "start": "3041160",
    "end": "3047310"
  },
  {
    "text": "less approach made their process four times faster and they can do a lot of these processing in the time that it",
    "start": "3047310",
    "end": "3053790"
  },
  {
    "text": "used to take the server based approach to do if you have Python code which is",
    "start": "3053790",
    "end": "3059100"
  },
  {
    "text": "doing that numerical compute you might want to take advantage of pyrin which is a framework or a project",
    "start": "3059100",
    "end": "3064920"
  },
  {
    "text": "helps you distribute that massively parallel across lambda functions so it takes care of packaging your Python code",
    "start": "3064920",
    "end": "3071640"
  },
  {
    "text": "as well as the inputs related to that and pushes that in parallel to the function invocation in lambda in",
    "start": "3071640",
    "end": "3078420"
  },
  {
    "text": "parallel so they benchmark saying that they could actually get ten teraflops of compute power from lambda just with the",
    "start": "3078420",
    "end": "3085800"
  },
  {
    "text": "default thousand concurrent function limit so that's a lot of compute power in your hands for data intensive apps",
    "start": "3085800",
    "end": "3091920"
  },
  {
    "text": "they also benchmark that they could transfer data in at 60 gigabytes per second using the same thousand",
    "start": "3091920",
    "end": "3098250"
  },
  {
    "text": "concurrent lambda function invocation so that's very fast as well as a lot of compute so that's it for data Lake now",
    "start": "3098250",
    "end": "3105600"
  },
  {
    "text": "let's see how you can make your app smarter as a developer using the power of machine learning so AWS has many",
    "start": "3105600",
    "end": "3111390"
  },
  {
    "text": "services that fit into the machine learning space and it really is different services targeted at different",
    "start": "3111390",
    "end": "3118050"
  },
  {
    "text": "levels of users if you are a data scientist you might be comfortable and you need the power of working at the",
    "start": "3118050",
    "end": "3123780"
  },
  {
    "text": "framework level so you can customize all the attributes for the framework and work with it at the framework level like",
    "start": "3123780",
    "end": "3129780"
  },
  {
    "text": "using techniques like tensorflow or cafe and AWS provides optimized ec2 instances",
    "start": "3129780",
    "end": "3135870"
  },
  {
    "text": "for those frameworks to run on in the middle tier you have services like sage maker which will help you with",
    "start": "3135870",
    "end": "3142080"
  },
  {
    "text": "predefined models as well as custom models and give you a framework for you to build as well as test and build and",
    "start": "3142080",
    "end": "3149310"
  },
  {
    "text": "learn and deploy and host those models on the sage maker service itself the top",
    "start": "3149310",
    "end": "3154680"
  },
  {
    "text": "layer is our focus for this talk which is API driven services these are targeted towards developers who don't",
    "start": "3154680",
    "end": "3160830"
  },
  {
    "text": "have a lot of machine learning expertise but again want to take advantage of models that AWS builds and provides that",
    "start": "3160830",
    "end": "3167220"
  },
  {
    "text": "power in your own hands we have services that deal with vision such as recognition image recognition video you",
    "start": "3167220",
    "end": "3174210"
  },
  {
    "text": "have services that deal with language processing such as Pali which is text-to-speech transcribe which is",
    "start": "3174210",
    "end": "3180900"
  },
  {
    "text": "speech to text and translate as the name suggests can convert between languages and comprehend which can make sense of",
    "start": "3180900",
    "end": "3187770"
  },
  {
    "text": "natural language identify sentiments key words phrases and topics as well as",
    "start": "3187770",
    "end": "3193740"
  },
  {
    "text": "chatbots which will give you the same kind of conversational experience as you might have experienced with the",
    "start": "3193740",
    "end": "3199060"
  },
  {
    "text": "echo Amazon elixir family of devices let's start first with an image",
    "start": "3199060",
    "end": "3205210"
  },
  {
    "text": "processing example imagine you have a website you allow users to submit images you share that with your friends and",
    "start": "3205210",
    "end": "3211570"
  },
  {
    "text": "family you might want to search for those images based on keywords and content inside those images so the",
    "start": "3211570",
    "end": "3218170"
  },
  {
    "text": "process starts with a user uploading that it ends up in s3 and now we trigger",
    "start": "3218170",
    "end": "3223300"
  },
  {
    "text": "a lambda function which starts off a step function workflow this orchestrates",
    "start": "3223300",
    "end": "3228940"
  },
  {
    "text": "multiple api's such as recognition to call to label the images based on",
    "start": "3228940",
    "end": "3234550"
  },
  {
    "text": "content inside the images to detect moderation labels is the content mature content should we have it published at",
    "start": "3234550",
    "end": "3241360"
  },
  {
    "text": "all and things like text so the end result of all of that is that we have that metadata or information written to",
    "start": "3241360",
    "end": "3248770"
  },
  {
    "text": "DynamoDB as well as elasticsearch so when your users come in and say give me all the images with bicycles in them",
    "start": "3248770",
    "end": "3254920"
  },
  {
    "text": "they can get that results back really quickly what if you are required now to",
    "start": "3254920",
    "end": "3260050"
  },
  {
    "text": "extend that to allow your users to upload audio as well as video so now you have other requirements coming in you",
    "start": "3260050",
    "end": "3266710"
  },
  {
    "text": "can extend that same application to add video and audio capabilities so you have the same properties but once you have",
    "start": "3266710",
    "end": "3273670"
  },
  {
    "text": "the images and the audio and video you might want to translate that or transcribe that into different formats",
    "start": "3273670",
    "end": "3279100"
  },
  {
    "text": "so you can use the service which is part of the elemental media convert family to transcribe the video into different",
    "start": "3279100",
    "end": "3284950"
  },
  {
    "text": "formats you can use recognition video now to analyze that video to extract",
    "start": "3284950",
    "end": "3289960"
  },
  {
    "text": "faces labels as well as objects and store that into elastic search and you",
    "start": "3289960",
    "end": "3295510"
  },
  {
    "text": "can transcribe the audio part of those videos to get the text and you can use",
    "start": "3295510",
    "end": "3300670"
  },
  {
    "text": "comprehend on that to identify sentiment and keywords so now you have a really good search index that your users can",
    "start": "3300670",
    "end": "3307660"
  },
  {
    "text": "search to find media of interest so I can put in a search criteria saying give me all the reinvent videos and the",
    "start": "3307660",
    "end": "3313690"
  },
  {
    "text": "results will come back based on the transcripts of the videos themselves and",
    "start": "3313690",
    "end": "3318930"
  },
  {
    "text": "this is actually part of our media analysis solution again a QuickStart that you can deploy in a few minutes",
    "start": "3318930",
    "end": "3324010"
  },
  {
    "text": "into your account the next two patterns really have connect at their core so Amazon Connect is a fully",
    "start": "3324010",
    "end": "3330720"
  },
  {
    "text": "managed survey less call center solution in the cloud it lets you create interactive call center applications",
    "start": "3330720",
    "end": "3336660"
  },
  {
    "text": "that do things like IVR and call routing as well as analytical features as we",
    "start": "3336660",
    "end": "3341970"
  },
  {
    "text": "shall see in a minute so imagine that your users are calling a call center and they are frustrated because they are",
    "start": "3341970",
    "end": "3347430"
  },
  {
    "text": "waiting in queues because they have common tasks such as rescheduling appointments and they are waiting to",
    "start": "3347430",
    "end": "3352500"
  },
  {
    "text": "speak to a human agent you can speed that all up by creating a chat bot for those common use cases the customer",
    "start": "3352500",
    "end": "3358800"
  },
  {
    "text": "calls a call center Amazon connects direct them to Alex chat bot which starts conversing with the user to see",
    "start": "3358800",
    "end": "3365849"
  },
  {
    "text": "that what is their next scheduled appointment time what are the available times once they agree upon an intent",
    "start": "3365849",
    "end": "3372060"
  },
  {
    "text": "which is the new time Lex will call a lambda function to fulfill the intent which could involve writing to DynamoDB",
    "start": "3372060",
    "end": "3378810"
  },
  {
    "text": "table and delivering an SMS notification confirming the appointment now your",
    "start": "3378810",
    "end": "3383940"
  },
  {
    "text": "users get served really fast and your agents can focus on the actual important customer experience tasks rather than",
    "start": "3383940",
    "end": "3390570"
  },
  {
    "text": "the common tasks such as rescheduling appointments we can take call center analytics further we can use the",
    "start": "3390570",
    "end": "3397080"
  },
  {
    "text": "information provided by connect to improve our service much further so connect provides two streams the first",
    "start": "3397080",
    "end": "3403589"
  },
  {
    "text": "are called contract trace records which is information about the call duration the call time the agent that picked it",
    "start": "3403589",
    "end": "3410460"
  },
  {
    "text": "up all that information is streamed we are Kinesis streams as well as firehose into s3 connect can also provide call",
    "start": "3410460",
    "end": "3418170"
  },
  {
    "text": "recordings the audio parts and we can stream that and send that over through transcribe",
    "start": "3418170",
    "end": "3423750"
  },
  {
    "text": "to get the transcripts in s3 we can send those transcripts through comprehend to find sentiments and topics so now you",
    "start": "3423750",
    "end": "3431130"
  },
  {
    "text": "can see that we've added all that call center data to a data Lake and we can use familiar tools like Athena and quick",
    "start": "3431130",
    "end": "3436800"
  },
  {
    "text": "site to analyze that to provide insights to improve the service to our customers so in summary I'd like to leave you with",
    "start": "3436800",
    "end": "3444180"
  },
  {
    "text": "a quote from one of organs he said this when we launched lambda back in 2015 he",
    "start": "3444180",
    "end": "3449280"
  },
  {
    "text": "said no server is easier to manage than no server and that remains true today with all the server less services that",
    "start": "3449280",
    "end": "3454530"
  },
  {
    "text": "we've seen you don't pay for idle and you actually scale as you grow and you also pay as you grow we've seen how",
    "start": "3454530",
    "end": "3462300"
  },
  {
    "text": "those patterns can apply to web apps we've seen those applied to streaming as well as building a data lake as well as",
    "start": "3462300",
    "end": "3469349"
  },
  {
    "text": "using machine learning algorithms to make your app smarter we hope that you can use these patterns in your",
    "start": "3469349",
    "end": "3474540"
  },
  {
    "text": "organization's when you go home and we'd like to actually hear from you what you will build with serverless",
    "start": "3474540",
    "end": "3479630"
  },
  {
    "text": "thank you [Applause]",
    "start": "3479630",
    "end": "3484359"
  }
]
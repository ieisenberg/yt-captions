[
  {
    "text": "- Hi, my name's Emily Webber.",
    "start": "170",
    "end": "1969"
  },
  {
    "text": "I'm a Machine Learning Specialist",
    "start": "1970",
    "end": "3270"
  },
  {
    "text": "Solutions Architect at\nAmazon Web Services,",
    "start": "3270",
    "end": "5370"
  },
  {
    "text": "and today we're gonna learn\nabout Hugging Face on SageMaker.",
    "start": "5370",
    "end": "8650"
  },
  {
    "text": "This is your deep dive.",
    "start": "8650",
    "end": "10223"
  },
  {
    "text": "So we have three videos for you",
    "start": "14350",
    "end": "16850"
  },
  {
    "text": "to really understand\nHugging Face on SageMaker.",
    "start": "16850",
    "end": "19010"
  },
  {
    "text": "This first one is your introduction,",
    "start": "19010",
    "end": "21080"
  },
  {
    "text": "the second one is a deep dive on training,",
    "start": "21080",
    "end": "23300"
  },
  {
    "text": "and the third one is\na deep dive on deploy.",
    "start": "23300",
    "end": "25689"
  },
  {
    "text": "So let's first look at the introduction.",
    "start": "25690",
    "end": "28000"
  },
  {
    "text": "And so before we wanna\ntalk about Hugging Face,",
    "start": "28000",
    "end": "30619"
  },
  {
    "text": "we actually wanna understand\nthe concept of a transformer.",
    "start": "30620",
    "end": "34610"
  },
  {
    "text": "And no, I am not talking about cars",
    "start": "34610",
    "end": "37640"
  },
  {
    "text": "that turn into robots\nthat save the human race.",
    "start": "37640",
    "end": "40260"
  },
  {
    "text": "I am actually talking about\na new type of NLP model.",
    "start": "40260",
    "end": "44289"
  },
  {
    "text": "So if you have been following",
    "start": "44290",
    "end": "46680"
  },
  {
    "text": "the machine learning general press",
    "start": "46680",
    "end": "48270"
  },
  {
    "text": "for the last four or\nfive years since 2017,",
    "start": "48270",
    "end": "51070"
  },
  {
    "text": "you will be familiar with this concept.",
    "start": "51070",
    "end": "53150"
  },
  {
    "text": "If not, welcome to the\nworld of transformers.",
    "start": "53150",
    "end": "56440"
  },
  {
    "text": "So transformers have been\ndemonstrating state of the art",
    "start": "56440",
    "end": "59480"
  },
  {
    "text": "and near human-level performance.",
    "start": "59480",
    "end": "61550"
  },
  {
    "text": "In some cases, actually,",
    "start": "61550",
    "end": "62780"
  },
  {
    "text": "it's exceeding human-level performance",
    "start": "62780",
    "end": "65780"
  },
  {
    "text": "in natural language processing use cases",
    "start": "65780",
    "end": "68420"
  },
  {
    "text": "across tax classification,\ntoken classification,",
    "start": "68420",
    "end": "72070"
  },
  {
    "text": "text generation, question answering,",
    "start": "72070",
    "end": "74350"
  },
  {
    "text": "and those translate into\nany type of NLP use case.",
    "start": "74350",
    "end": "77580"
  },
  {
    "text": "So if you are using\nsearch at your company,",
    "start": "77580",
    "end": "80640"
  },
  {
    "text": "if you're doing question\nanswering, if you have chatbots,",
    "start": "80640",
    "end": "84130"
  },
  {
    "text": "if you are working with documentation,",
    "start": "84130",
    "end": "86159"
  },
  {
    "text": "if you deal with text in some capacity,",
    "start": "86160",
    "end": "88690"
  },
  {
    "text": "odds are you can improve\nyour business efficiency",
    "start": "88690",
    "end": "91320"
  },
  {
    "text": "using transformers.",
    "start": "91320",
    "end": "93400"
  },
  {
    "text": "Now, transformers are great",
    "start": "93400",
    "end": "94720"
  },
  {
    "text": "for both large, unsupervised datasets",
    "start": "94720",
    "end": "98280"
  },
  {
    "text": "and for smaller domain-specific datasets.",
    "start": "98280",
    "end": "100750"
  },
  {
    "text": "They use this concept of pre-training",
    "start": "100750",
    "end": "103230"
  },
  {
    "text": "to gain intelligence on\nreally, really large datasets.",
    "start": "103230",
    "end": "106440"
  },
  {
    "text": "So all of Wikipedia,",
    "start": "106440",
    "end": "107940"
  },
  {
    "text": "all of Common Crawl, many\ndifferent booked datasets,",
    "start": "107940",
    "end": "111130"
  },
  {
    "text": "you can use those pre-trained models",
    "start": "111130",
    "end": "113820"
  },
  {
    "text": "and then finetune them on your data,",
    "start": "113820",
    "end": "116230"
  },
  {
    "text": "so on a much smaller dataset",
    "start": "116230",
    "end": "118100"
  },
  {
    "text": "and on something that's more\nspecific to your business",
    "start": "118100",
    "end": "120330"
  },
  {
    "text": "and to your customers.",
    "start": "120330",
    "end": "121790"
  },
  {
    "text": "Transformers themselves\nare highly scalable",
    "start": "121790",
    "end": "124350"
  },
  {
    "text": "and parallelizable,",
    "start": "124350",
    "end": "125560"
  },
  {
    "text": "so they take advantage of all the GPUs,",
    "start": "125560",
    "end": "127970"
  },
  {
    "text": "all the nodes in your cluster in a way",
    "start": "127970",
    "end": "130000"
  },
  {
    "text": "that recurrent neural networks",
    "start": "130000",
    "end": "131230"
  },
  {
    "text": "and other sequence-based approaches",
    "start": "131230",
    "end": "132730"
  },
  {
    "text": "really haven't been able to.",
    "start": "132730",
    "end": "134680"
  },
  {
    "text": "They understand both\nthe word and its context",
    "start": "134680",
    "end": "137180"
  },
  {
    "text": "using this concept called self-attention,",
    "start": "137180",
    "end": "139670"
  },
  {
    "text": "I'm not gonna go into detail here,",
    "start": "139670",
    "end": "142260"
  },
  {
    "text": "but definitely read more\nabout it if you're interested,",
    "start": "142260",
    "end": "145140"
  },
  {
    "text": "both bidirectional, so\nforwards and backwards,",
    "start": "145140",
    "end": "147760"
  },
  {
    "text": "in addition to just strictly\nleft to right for generating.",
    "start": "147760",
    "end": "151080"
  },
  {
    "text": "And generally speaking,",
    "start": "151080",
    "end": "152580"
  },
  {
    "text": "again, transformers can raise\nthe level of intelligence",
    "start": "152580",
    "end": "156150"
  },
  {
    "text": "on almost all of your NLP models.",
    "start": "156150",
    "end": "158159"
  },
  {
    "text": "So for any NLP model that\nyou use for customer support,",
    "start": "158160",
    "end": "162300"
  },
  {
    "text": "for, again, document search,\nfor document retrieval,",
    "start": "162300",
    "end": "166490"
  },
  {
    "text": "odds are you can use a\nbase transformer model",
    "start": "166490",
    "end": "170310"
  },
  {
    "text": "to just raise the level of intelligence.",
    "start": "170310",
    "end": "172310"
  },
  {
    "text": "And first off, there's actually a book.",
    "start": "173981",
    "end": "176850"
  },
  {
    "text": "So the Hugging Face team just\npublished a book on this.",
    "start": "176850",
    "end": "181850"
  },
  {
    "text": "So it came out in\nFebruary or March of 2022.",
    "start": "182120",
    "end": "185773"
  },
  {
    "text": "I have been absolutely eating this up.",
    "start": "186630",
    "end": "189390"
  },
  {
    "text": "It's been my candy for\nthe last couple weeks.",
    "start": "189390",
    "end": "192530"
  },
  {
    "text": "And so we're gonna be\nlooking at some of the topics",
    "start": "192530",
    "end": "195110"
  },
  {
    "text": "that they mentioned here today.",
    "start": "195110",
    "end": "197060"
  },
  {
    "text": "So if you're asking yourself,",
    "start": "197060",
    "end": "198560"
  },
  {
    "text": "well, Emily, what is Hugging Face?",
    "start": "198560",
    "end": "200250"
  },
  {
    "text": "What exactly is going on?",
    "start": "200250",
    "end": "202473"
  },
  {
    "text": "So the net-net here is that\nNLP is really exciting, right?",
    "start": "202473",
    "end": "207010"
  },
  {
    "text": "In the last few years,",
    "start": "207010",
    "end": "208540"
  },
  {
    "text": "we've seen state of the art\nperformance in computer vision,",
    "start": "208540",
    "end": "211099"
  },
  {
    "text": "with object detection,\nwith image classification,",
    "start": "211100",
    "end": "213370"
  },
  {
    "text": "ResNet, and in the 2017/ 2018 timeframe,",
    "start": "213370",
    "end": "218370"
  },
  {
    "text": "we saw that start to switch,",
    "start": "218640",
    "end": "220080"
  },
  {
    "text": "where many of the insights that we learned",
    "start": "220080",
    "end": "222730"
  },
  {
    "text": "in computer vision were applied",
    "start": "222730",
    "end": "224010"
  },
  {
    "text": "to natural language\nprocessing, but in particular,",
    "start": "224010",
    "end": "226890"
  },
  {
    "text": "there's this new model\ncalled the transformer.",
    "start": "226890",
    "end": "229120"
  },
  {
    "text": "And so Hugging Face is an SDK",
    "start": "229120",
    "end": "232519"
  },
  {
    "text": "and a suite of tens of thousands",
    "start": "232520",
    "end": "235300"
  },
  {
    "text": "of pre-trained NLP models,\ntokenizers, datasets,",
    "start": "235300",
    "end": "238300"
  },
  {
    "text": "example notebooks, and scripts",
    "start": "238300",
    "end": "240100"
  },
  {
    "text": "that wrap state of the art NLP models",
    "start": "240100",
    "end": "242880"
  },
  {
    "text": "and make them really easy to use.",
    "start": "242880",
    "end": "244620"
  },
  {
    "text": "So in just a few lines of code,",
    "start": "244620",
    "end": "246590"
  },
  {
    "text": "we're gonna get absolute\nstate of the art performance",
    "start": "246590",
    "end": "248849"
  },
  {
    "text": "across text classification,",
    "start": "248850",
    "end": "250290"
  },
  {
    "text": "across named entity recognition,",
    "start": "250290",
    "end": "252390"
  },
  {
    "text": "question answering, text generation,",
    "start": "252390",
    "end": "254700"
  },
  {
    "text": "translation, training from scratch,",
    "start": "254700",
    "end": "256910"
  },
  {
    "text": "finetuning, all sorts of things.",
    "start": "256910",
    "end": "259370"
  },
  {
    "text": "Hugging Face also\nproduces code generation,",
    "start": "259370",
    "end": "262630"
  },
  {
    "text": "so you can go onto their site,",
    "start": "262630",
    "end": "264000"
  },
  {
    "text": "and we're gonna look at this,",
    "start": "264000",
    "end": "265250"
  },
  {
    "text": "and pick the model that\nyou're interested in,",
    "start": "265250",
    "end": "268480"
  },
  {
    "text": "determine the downstream\ntask that you want for it,",
    "start": "268480",
    "end": "271810"
  },
  {
    "text": "whether it's, again, text classification,",
    "start": "271810",
    "end": "274030"
  },
  {
    "text": "named entity recognition, et cetera,",
    "start": "274030",
    "end": "276023"
  },
  {
    "text": "and then you can actually\ngenerate the config for that.",
    "start": "276907",
    "end": "278720"
  },
  {
    "text": "We're gonna generate\nthe code configuration",
    "start": "278720",
    "end": "281650"
  },
  {
    "text": "to just run that on SageMaker.",
    "start": "281650",
    "end": "283790"
  },
  {
    "text": "And also, Hugging Face has an\nawesome open source community.",
    "start": "283790",
    "end": "287480"
  },
  {
    "text": "I mean, I follow their GitHub repository.",
    "start": "287480",
    "end": "289760"
  },
  {
    "text": "It is incredibly active.",
    "start": "289760",
    "end": "291780"
  },
  {
    "text": "You're gonna see many,\nmany pushes every day.",
    "start": "291780",
    "end": "294310"
  },
  {
    "text": "They have really, really just robust",
    "start": "294310",
    "end": "296760"
  },
  {
    "text": "open source community support.",
    "start": "296760",
    "end": "298440"
  },
  {
    "text": "And so today we're gonna learn",
    "start": "298440",
    "end": "300230"
  },
  {
    "text": "how to use Hugging Face on SageMaker.",
    "start": "300230",
    "end": "302927"
  },
  {
    "text": "So now that we know what Hugging Face is",
    "start": "303790",
    "end": "306330"
  },
  {
    "text": "at a very high level,",
    "start": "306330",
    "end": "307550"
  },
  {
    "text": "what can we do with\nHugging Face on SageMaker?",
    "start": "307550",
    "end": "311284"
  },
  {
    "text": "And the answer, my\nfriends, is a lot. (laughs)",
    "start": "311285",
    "end": "313770"
  },
  {
    "text": "We have a huge amount of\nfeatures that are purpose-built",
    "start": "313770",
    "end": "317250"
  },
  {
    "text": "for Hugging Face on SageMaker.",
    "start": "317250",
    "end": "319920"
  },
  {
    "text": "So at the core, you're gonna see two",
    "start": "319920",
    "end": "321920"
  },
  {
    "text": "what we call Deep Learning Containers.",
    "start": "321920",
    "end": "323970"
  },
  {
    "text": "So they're Hugging Face\nDeep Learning Containers,",
    "start": "323970",
    "end": "326250"
  },
  {
    "text": "both for training and for inferencing,",
    "start": "326250",
    "end": "328960"
  },
  {
    "text": "but then we're gonna wrap on top of that",
    "start": "328960",
    "end": "331449"
  },
  {
    "text": "many different features across the stack.",
    "start": "331450",
    "end": "333800"
  },
  {
    "text": "So we can really look at\nthem in three different ways.",
    "start": "333800",
    "end": "336129"
  },
  {
    "text": "We have features for training,",
    "start": "336130",
    "end": "338130"
  },
  {
    "text": "features for deployment,",
    "start": "338130",
    "end": "339780"
  },
  {
    "text": "and then features for operationalize.",
    "start": "339780",
    "end": "341840"
  },
  {
    "text": "And so in the training side of the house,",
    "start": "341840",
    "end": "344270"
  },
  {
    "text": "you're gonna see finetuning,",
    "start": "344270",
    "end": "345919"
  },
  {
    "text": "so the ability to\nfinetune those NLP models.",
    "start": "345920",
    "end": "348720"
  },
  {
    "text": "Again, the Deep Learning Containers,",
    "start": "348720",
    "end": "350360"
  },
  {
    "text": "we can tune them using automatic\nmodel tuning and sign tune.",
    "start": "350360",
    "end": "353759"
  },
  {
    "text": "We can compile them with the\nSageMaker Training Compiler.",
    "start": "353760",
    "end": "357180"
  },
  {
    "text": "We can distribute them\nacross multiple GPUs,",
    "start": "357180",
    "end": "360380"
  },
  {
    "text": "multiple accelerators, multiple nodes,",
    "start": "360380",
    "end": "362400"
  },
  {
    "text": "and then we can also\ntrain those from scratch.",
    "start": "362400",
    "end": "365150"
  },
  {
    "text": "And the deployment, we can deploy",
    "start": "365150",
    "end": "368300"
  },
  {
    "text": "those tens of thousands\nof pre-trained models",
    "start": "368300",
    "end": "371409"
  },
  {
    "text": "directly from the Hugging Face Hub,",
    "start": "371410",
    "end": "373300"
  },
  {
    "text": "so that's gonna be one line of code",
    "start": "373300",
    "end": "375409"
  },
  {
    "text": "where we're gonna again\npoint to the models",
    "start": "375410",
    "end": "378750"
  },
  {
    "text": "that are pre-trained in\nthe Hugging Face Hub,",
    "start": "378750",
    "end": "380620"
  },
  {
    "text": "and then we're just gonna\ndeploy those onto SageMaker.",
    "start": "380620",
    "end": "383430"
  },
  {
    "text": "We can also deploy finetuned\nmodels from the Hub",
    "start": "383430",
    "end": "386520"
  },
  {
    "text": "from S3 onto SageMaker,",
    "start": "386520",
    "end": "388900"
  },
  {
    "text": "again both with PyTorch and TensorFlow.",
    "start": "388900",
    "end": "391160"
  },
  {
    "text": "And then we get all the same features",
    "start": "391160",
    "end": "393030"
  },
  {
    "text": "for deploying on SageMaker\nthat we do with Hugging Face.",
    "start": "393030",
    "end": "395610"
  },
  {
    "text": "So auto-scaling, support\nfor serverless endpoints,",
    "start": "395610",
    "end": "398840"
  },
  {
    "text": "asynchronous endpoints,\nmulti-model endpoints,",
    "start": "398840",
    "end": "401910"
  },
  {
    "text": "Inferentia, and Neo.",
    "start": "401910",
    "end": "404570"
  },
  {
    "text": "On the operationalize\nside, you're gonna look",
    "start": "404570",
    "end": "407290"
  },
  {
    "text": "at SageMaker pipelines,",
    "start": "407290",
    "end": "409340"
  },
  {
    "text": "really any third party MLOp\nstack that you wanna use",
    "start": "409340",
    "end": "412580"
  },
  {
    "text": "fully compatible with Hugging Face.",
    "start": "412580",
    "end": "415030"
  },
  {
    "text": "We also have a new Inference Recommender,",
    "start": "415030",
    "end": "416950"
  },
  {
    "text": "so you can use Inference Recommender",
    "start": "416950",
    "end": "420150"
  },
  {
    "text": "to find the best instance type,",
    "start": "420150",
    "end": "421970"
  },
  {
    "text": "and then configure that instance for you.",
    "start": "421970",
    "end": "424550"
  },
  {
    "text": "We can also detect and monitor for bias",
    "start": "424550",
    "end": "427949"
  },
  {
    "text": "in text classification models\nwith SageMaker Clarify.",
    "start": "427950",
    "end": "431223"
  },
  {
    "text": "So how do we pick the\nright Hugging Face model?",
    "start": "432750",
    "end": "435490"
  },
  {
    "text": "This is a very common question.",
    "start": "435490",
    "end": "437849"
  },
  {
    "text": "The first piece of advice that I would say",
    "start": "437850",
    "end": "441430"
  },
  {
    "text": "is try and add value to your organization",
    "start": "441430",
    "end": "445110"
  },
  {
    "text": "as a step one, right?",
    "start": "445110",
    "end": "446360"
  },
  {
    "text": "Figure out what areas",
    "start": "446360",
    "end": "448080"
  },
  {
    "text": "are your organization most interested in?",
    "start": "448080",
    "end": "449979"
  },
  {
    "text": "What datasets do you have?",
    "start": "449980",
    "end": "451610"
  },
  {
    "text": "What problems are most relevant to you?",
    "start": "451610",
    "end": "454229"
  },
  {
    "text": "And then try and backtrack that",
    "start": "454230",
    "end": "455900"
  },
  {
    "text": "into a type of use case\nthat Hugging Face supports,",
    "start": "455900",
    "end": "459759"
  },
  {
    "text": "whether that's, again, question answering,",
    "start": "459760",
    "end": "461370"
  },
  {
    "text": "summarization, token classification,",
    "start": "461370",
    "end": "464080"
  },
  {
    "text": "text generation, all sorts of things.",
    "start": "464080",
    "end": "466919"
  },
  {
    "text": "We wanna ask ourselves, is my\ndataset primarily in English,",
    "start": "466920",
    "end": "471680"
  },
  {
    "text": "or do I need a multilingual model?",
    "start": "471680",
    "end": "474820"
  },
  {
    "text": "Do I need a model that has support",
    "start": "474820",
    "end": "476320"
  },
  {
    "text": "for multiple different languages?",
    "start": "476320",
    "end": "477970"
  },
  {
    "text": "Also, how specific is my dataset,",
    "start": "477970",
    "end": "481700"
  },
  {
    "text": "and especially how different\nis it from a pre-trained model?",
    "start": "481700",
    "end": "485130"
  },
  {
    "text": "All of these tens of thousands of models",
    "start": "485130",
    "end": "487000"
  },
  {
    "text": "that we're looking at have been optimized",
    "start": "487000",
    "end": "489710"
  },
  {
    "text": "for research dataset,",
    "start": "489710",
    "end": "491009"
  },
  {
    "text": "whether that is SST-2 or SQuAD",
    "start": "491010",
    "end": "493800"
  },
  {
    "text": "or Common Crawl or Books.",
    "start": "493800",
    "end": "497000"
  },
  {
    "text": "And so essentially we want to consider,",
    "start": "497000",
    "end": "500400"
  },
  {
    "text": "we wanna ask ourselves, again,",
    "start": "500400",
    "end": "501590"
  },
  {
    "text": "how different is that\ndataset from my dataset?",
    "start": "501590",
    "end": "506060"
  },
  {
    "text": "And then will the research\ndataset performance",
    "start": "506060",
    "end": "509500"
  },
  {
    "text": "meet my needs?",
    "start": "509500",
    "end": "510333"
  },
  {
    "text": "So you'll find that each of these models",
    "start": "510333",
    "end": "512740"
  },
  {
    "text": "has a benchmark performance",
    "start": "512740",
    "end": "514159"
  },
  {
    "text": "for how well it performed\non that specific dataset.",
    "start": "514160",
    "end": "517110"
  },
  {
    "text": "And so we wanna ask ourselves\nwhat would be the impact",
    "start": "517110",
    "end": "520130"
  },
  {
    "text": "of that level of accuracy, of perplexity,",
    "start": "520130",
    "end": "522840"
  },
  {
    "text": "of BLEU score within my use case?",
    "start": "522840",
    "end": "527330"
  },
  {
    "text": "And then go forth and experiment.",
    "start": "527330",
    "end": "530240"
  },
  {
    "text": "There are again so many different models",
    "start": "530240",
    "end": "532450"
  },
  {
    "text": "and so many different methods.",
    "start": "532450",
    "end": "533980"
  },
  {
    "text": "What I really like to do is time backs.",
    "start": "533980",
    "end": "535970"
  },
  {
    "text": "So I like to spend one week, two weeks",
    "start": "535970",
    "end": "539410"
  },
  {
    "text": "exploring one of these models,",
    "start": "539410",
    "end": "540920"
  },
  {
    "text": "exploring one of these\ncandidate use cases,",
    "start": "540920",
    "end": "543222"
  },
  {
    "text": "and then rinse and repeat.",
    "start": "544330",
    "end": "545780"
  },
  {
    "text": "And then only after you've\nfound a model or a use case",
    "start": "545780",
    "end": "550120"
  },
  {
    "text": "that's really performing well,",
    "start": "550120",
    "end": "551990"
  },
  {
    "text": "after that point it's\nappropriate to start scaling,",
    "start": "551990",
    "end": "554750"
  },
  {
    "text": "and we'll learn all about\nthat in just a little bit.",
    "start": "554750",
    "end": "558110"
  },
  {
    "text": "And so with that, let's\ntake a look at the demo.",
    "start": "558110",
    "end": "560592"
  },
  {
    "text": "All right, so here we are.",
    "start": "563920",
    "end": "565950"
  },
  {
    "text": "So you see we're sitting\nin SageMaker Studio,",
    "start": "565950",
    "end": "569080"
  },
  {
    "text": "and I'm in us-east-1,",
    "start": "569080",
    "end": "571070"
  },
  {
    "text": "and in particular, I have a notebook,",
    "start": "571070",
    "end": "573760"
  },
  {
    "text": "and this notebook uses\nthe DistilBERT model.",
    "start": "573760",
    "end": "577270"
  },
  {
    "text": "The DistilBERT model is\ncommon for classification,",
    "start": "577270",
    "end": "580440"
  },
  {
    "text": "and so we're going to\nbuild a binary classifier",
    "start": "580440",
    "end": "584520"
  },
  {
    "text": "using this DistilBERT model,",
    "start": "584520",
    "end": "586740"
  },
  {
    "text": "and we're gonna use it",
    "start": "586740",
    "end": "587573"
  },
  {
    "text": "across three different\nphases of SageMaker.",
    "start": "587573",
    "end": "589550"
  },
  {
    "text": "So this first phase is installing",
    "start": "589550",
    "end": "592490"
  },
  {
    "text": "and using that model locally,",
    "start": "592490",
    "end": "595100"
  },
  {
    "text": "where we're actually\nbuilding a very small scale",
    "start": "595100",
    "end": "598660"
  },
  {
    "text": "but still performant\ntext classifier locally,",
    "start": "598660",
    "end": "602079"
  },
  {
    "text": "and so we're doing that on Studio.",
    "start": "602080",
    "end": "604430"
  },
  {
    "text": "The second phase is where\nwe run a training job,",
    "start": "604430",
    "end": "607839"
  },
  {
    "text": "where we're going to take a new dataset",
    "start": "607840",
    "end": "610060"
  },
  {
    "text": "and we're gonna finetune this\nmodel on that new dataset",
    "start": "610060",
    "end": "613760"
  },
  {
    "text": "using the SageMaker training API.",
    "start": "613760",
    "end": "616240"
  },
  {
    "text": "So we're gonna have new EC2 instances",
    "start": "616240",
    "end": "618160"
  },
  {
    "text": "within machine learning coming online.",
    "start": "618160",
    "end": "620220"
  },
  {
    "text": "We're gonna copy our data\nout to those instances",
    "start": "620220",
    "end": "622529"
  },
  {
    "text": "and run a job.",
    "start": "622530",
    "end": "623590"
  },
  {
    "text": "And then in the third stage,",
    "start": "623590",
    "end": "625100"
  },
  {
    "text": "we're gonna take our finetuned model",
    "start": "625100",
    "end": "627300"
  },
  {
    "text": "and we're gonna deploy that onto SageMaker",
    "start": "627300",
    "end": "629180"
  },
  {
    "text": "for realtime hosting.",
    "start": "629180",
    "end": "630460"
  },
  {
    "text": "So let's get started.",
    "start": "630460",
    "end": "633370"
  },
  {
    "text": "All right, so you'll see\nin this first cell here,",
    "start": "633370",
    "end": "636490"
  },
  {
    "text": "we're just installing some local script.",
    "start": "636490",
    "end": "639750"
  },
  {
    "text": "So that's that SageMaker Python SDK,",
    "start": "639750",
    "end": "642670"
  },
  {
    "text": "and then transformers.",
    "start": "642670",
    "end": "644519"
  },
  {
    "text": "And so remember,",
    "start": "644520",
    "end": "645353"
  },
  {
    "text": "transformers is the\nflagship Hugging Face SDK.",
    "start": "645353",
    "end": "649990"
  },
  {
    "text": "They have, again, a really\nrobust GitHub repository",
    "start": "649990",
    "end": "653610"
  },
  {
    "text": "and open source context and support.",
    "start": "653610",
    "end": "656200"
  },
  {
    "text": "And then the datasets\nlibrary is another SDK",
    "start": "656200",
    "end": "660020"
  },
  {
    "text": "that's built by Hugging Face,",
    "start": "660020",
    "end": "661870"
  },
  {
    "text": "and it gives you access\nto a lot of datasets",
    "start": "661870",
    "end": "665060"
  },
  {
    "text": "that are relevant for Hugging Face.",
    "start": "665060",
    "end": "667310"
  },
  {
    "text": "So let's install both of those.",
    "start": "667310",
    "end": "669143"
  },
  {
    "text": "And then, in our next step here,",
    "start": "670410",
    "end": "673639"
  },
  {
    "text": "we're gonna build what's\ncalled a pipeline.",
    "start": "673640",
    "end": "675680"
  },
  {
    "text": "So the transformers SDK",
    "start": "675680",
    "end": "677720"
  },
  {
    "text": "has this pipeline object as a construct,",
    "start": "677720",
    "end": "680490"
  },
  {
    "text": "and it's really nice because it wraps",
    "start": "680490",
    "end": "682450"
  },
  {
    "text": "all the different stages of\nthis classification process,",
    "start": "682450",
    "end": "686123"
  },
  {
    "text": "from loading the model to\nperforming tokenization,",
    "start": "687570",
    "end": "690800"
  },
  {
    "text": "to actually again getting\nthat pre-trained model,",
    "start": "690800",
    "end": "695490"
  },
  {
    "text": "tokenizing the incoming text,",
    "start": "695490",
    "end": "697330"
  },
  {
    "text": "running that through\nthe pre-trained model,",
    "start": "697330",
    "end": "699570"
  },
  {
    "text": "generating the text, and\nthen loading that back.",
    "start": "699570",
    "end": "702590"
  },
  {
    "text": "And so that's why this pipeline construct",
    "start": "702590",
    "end": "705320"
  },
  {
    "text": "is really valuable.",
    "start": "705320",
    "end": "706153"
  },
  {
    "text": "So here we're just gonna\npass in one phrase,",
    "start": "706153",
    "end": "709580"
  },
  {
    "text": "which is sentiment-analysis.",
    "start": "709580",
    "end": "711610"
  },
  {
    "text": "And so this classifier that we're building",
    "start": "711610",
    "end": "715160"
  },
  {
    "text": "is gonna give us a binary classification",
    "start": "715160",
    "end": "717560"
  },
  {
    "text": "on the sentiment of the\ntext that's passed in here.",
    "start": "717560",
    "end": "720450"
  },
  {
    "text": "And so when we call this classifier",
    "start": "720450",
    "end": "723650"
  },
  {
    "text": "on this new piece of text,",
    "start": "723650",
    "end": "726560"
  },
  {
    "text": "it's gonna come back with a score, right?",
    "start": "726560",
    "end": "728130"
  },
  {
    "text": "And so in this case, it comes\nback with a positive score.",
    "start": "728130",
    "end": "731500"
  },
  {
    "text": "So that comes directly through,\nagain, this pipeline object.",
    "start": "731500",
    "end": "736150"
  },
  {
    "text": "So now in the second step,",
    "start": "736150",
    "end": "738470"
  },
  {
    "text": "we're gonna deconstruct\nthis a little bit further.",
    "start": "738470",
    "end": "740899"
  },
  {
    "text": "We're gonna point to not just\na generic type of problem,",
    "start": "740900",
    "end": "745810"
  },
  {
    "text": "which was the sentiment classification,",
    "start": "745810",
    "end": "748920"
  },
  {
    "text": "but we're gonna point to a specific model.",
    "start": "748920",
    "end": "750560"
  },
  {
    "text": "So this model is again one",
    "start": "750560",
    "end": "753020"
  },
  {
    "text": "of the more than 30,000 transformers",
    "start": "753020",
    "end": "757340"
  },
  {
    "text": "that are pre-trained on\nthe Hugging Face Hub,",
    "start": "757340",
    "end": "760120"
  },
  {
    "text": "as it's called.",
    "start": "760120",
    "end": "761010"
  },
  {
    "text": "And so I'm pointing to\nthe maker of that model,",
    "start": "761010",
    "end": "764360"
  },
  {
    "text": "which is nlptown,",
    "start": "764360",
    "end": "765880"
  },
  {
    "text": "and then the model itself.",
    "start": "765880",
    "end": "767880"
  },
  {
    "text": "So we've got a bert-base-multilingual,",
    "start": "767880",
    "end": "770320"
  },
  {
    "text": "so support for multiple languages,",
    "start": "770320",
    "end": "772850"
  },
  {
    "text": "uncased, and then sentiment.",
    "start": "772850",
    "end": "774943"
  },
  {
    "text": "And we're gonna use\nthis first object here,",
    "start": "775830",
    "end": "778356"
  },
  {
    "text": "AutoModelforSequenceClassification.from_pretrained.",
    "start": "778356",
    "end": "783210"
  },
  {
    "text": "So we're gonna load in\nthe name of this model.",
    "start": "783210",
    "end": "786300"
  },
  {
    "text": "Now, it's nice because if\nyou have your own model,",
    "start": "786300",
    "end": "789769"
  },
  {
    "text": "you can pass that here, as well.",
    "start": "789770",
    "end": "791800"
  },
  {
    "text": "We'll just say from_pretrained,",
    "start": "791800",
    "end": "793350"
  },
  {
    "text": "and then it'll actually just pass in",
    "start": "794569",
    "end": "795569"
  },
  {
    "text": "the local path of that model.",
    "start": "795570",
    "end": "798060"
  },
  {
    "text": "And so, yeah, so that's\ngonna get loaded in here,",
    "start": "798060",
    "end": "800850"
  },
  {
    "text": "and so that's our model.",
    "start": "800850",
    "end": "802100"
  },
  {
    "text": "The next step is our tokenizer.",
    "start": "802100",
    "end": "804180"
  },
  {
    "text": "So if you've worked with NLP,",
    "start": "804180",
    "end": "806690"
  },
  {
    "text": "you know that really the\nheart of transforming text",
    "start": "806690",
    "end": "810780"
  },
  {
    "text": "into something that a computer can read",
    "start": "810780",
    "end": "814710"
  },
  {
    "text": "is really about tokenization,",
    "start": "814710",
    "end": "816280"
  },
  {
    "text": "is where we're again taking the strings,",
    "start": "816280",
    "end": "818893"
  },
  {
    "text": "which is the raw text,",
    "start": "819850",
    "end": "821009"
  },
  {
    "text": "and then breaking that string up in a way",
    "start": "821010",
    "end": "822680"
  },
  {
    "text": "that's appropriate for the model.",
    "start": "822680",
    "end": "825020"
  },
  {
    "text": "Now, the beauty of the Hugging Face SDK",
    "start": "825020",
    "end": "828170"
  },
  {
    "text": "is that they have\ntokenizers for each model.",
    "start": "828170",
    "end": "832269"
  },
  {
    "text": "So whether you're looking\nat GPT-2 or RoBERTa",
    "start": "832270",
    "end": "835700"
  },
  {
    "text": "or DistilBERT",
    "start": "835700",
    "end": "836920"
  },
  {
    "text": "or BigBird or DeBERTa",
    "start": "839135",
    "end": "840610"
  },
  {
    "text": "or any of those models,",
    "start": "840610",
    "end": "843240"
  },
  {
    "text": "they actually have tokenizers\nthat are loaded for these,",
    "start": "843240",
    "end": "846279"
  },
  {
    "text": "and those are all just\navailable on the Hub.",
    "start": "846280",
    "end": "848120"
  },
  {
    "text": "So here, I'm gonna pass in\nthe name again of my model",
    "start": "848120",
    "end": "851970"
  },
  {
    "text": "and I'm gonna get a tokenizer.",
    "start": "851970",
    "end": "853470"
  },
  {
    "text": "And now I'm gonna use that\nsame pipeline construct,",
    "start": "854330",
    "end": "858380"
  },
  {
    "text": "except now I'm passing in a specific model",
    "start": "858380",
    "end": "861750"
  },
  {
    "text": "and a specific tokenizer,",
    "start": "861750",
    "end": "863540"
  },
  {
    "text": "so I'm just being a little\nbit more fine-grained there.",
    "start": "863540",
    "end": "867300"
  },
  {
    "text": "And then I'm gonna run\nthe classifier again,",
    "start": "867300",
    "end": "870610"
  },
  {
    "text": "especially the large scale\ndistributor training,",
    "start": "870610",
    "end": "872440"
  },
  {
    "text": "which is definitely fun.",
    "start": "872440",
    "end": "874540"
  },
  {
    "text": "And so we're gonna run\nthat classifier here",
    "start": "874540",
    "end": "877360"
  },
  {
    "text": "and we get the same score.",
    "start": "877360",
    "end": "879260"
  },
  {
    "text": "Now we're gonna take\nthis one step further.",
    "start": "879260",
    "end": "882200"
  },
  {
    "text": "We're gonna finetune this model.",
    "start": "882200",
    "end": "884600"
  },
  {
    "text": "Now, finetuning is incredibly valuable,",
    "start": "884600",
    "end": "887759"
  },
  {
    "text": "number one, because you need less data.",
    "start": "887760",
    "end": "890420"
  },
  {
    "text": "Finetuning means you're\npointing to a pre-trained model,",
    "start": "890420",
    "end": "894500"
  },
  {
    "text": "and it could be a really large model.",
    "start": "894500",
    "end": "896380"
  },
  {
    "text": "It could be GPT-2, it could\nbe GPT-3, it could be BigBird,",
    "start": "896380",
    "end": "901380"
  },
  {
    "text": "it could be really any of the\nstate of the art NLP models.",
    "start": "901500",
    "end": "905380"
  },
  {
    "text": "And we're gonna piggyback\noff of that model",
    "start": "905380",
    "end": "908177"
  },
  {
    "text": "and that team's work, and then\nadd a few more layers onto it",
    "start": "908177",
    "end": "912130"
  },
  {
    "text": "or more specifically set",
    "start": "912130",
    "end": "914250"
  },
  {
    "text": "some of the last layers to trainable,",
    "start": "914250",
    "end": "916880"
  },
  {
    "text": "but we're using again the\nHugging Face framework for it,",
    "start": "916880",
    "end": "920540"
  },
  {
    "text": "and they abstract away a lot\nof that lower level work.",
    "start": "920540",
    "end": "923399"
  },
  {
    "text": "But we're gonna bring our own data",
    "start": "923400",
    "end": "925510"
  },
  {
    "text": "and we're gonna make that model",
    "start": "925510",
    "end": "926900"
  },
  {
    "text": "more specific to our dataset,",
    "start": "926900",
    "end": "928450"
  },
  {
    "text": "so that's really what this next step is.",
    "start": "928450",
    "end": "930630"
  },
  {
    "text": "So we're importing",
    "start": "930630",
    "end": "931463"
  },
  {
    "text": "that sagemake.huggingface\nframework right here,",
    "start": "931463",
    "end": "935120"
  },
  {
    "text": "and then this is just setting",
    "start": "935120",
    "end": "936450"
  },
  {
    "text": "our normal SageMaker credentials, right?",
    "start": "936450",
    "end": "938410"
  },
  {
    "text": "So we've got our session,\nour bucket, our role.",
    "start": "938410",
    "end": "941959"
  },
  {
    "text": "Life is good.",
    "start": "941960",
    "end": "943480"
  },
  {
    "text": "We're gonna load in that tokenizer.",
    "start": "943480",
    "end": "946050"
  },
  {
    "text": "So this case, the DistilBERT Base Uncased.",
    "start": "946050",
    "end": "948600"
  },
  {
    "text": "So similar to the previous one,",
    "start": "948600",
    "end": "949899"
  },
  {
    "text": "just not strictly multilingual, sst,",
    "start": "949900",
    "end": "953390"
  },
  {
    "text": "and then we're gonna load the dataset,",
    "start": "953390",
    "end": "955830"
  },
  {
    "text": "which happens here.",
    "start": "955830",
    "end": "957650"
  },
  {
    "text": "But in this case, actually for the demo,",
    "start": "957650",
    "end": "959870"
  },
  {
    "text": "we're gonna be pointing to a data",
    "start": "959870",
    "end": "961540"
  },
  {
    "text": "that's already been hosted in S3.",
    "start": "961540",
    "end": "963420"
  },
  {
    "text": "So we've got some SageMaker sample files",
    "start": "963420",
    "end": "966089"
  },
  {
    "text": "sitting in a readable S3 bucket,",
    "start": "966090",
    "end": "968500"
  },
  {
    "text": "and so we're gonna load those here",
    "start": "968500",
    "end": "970990"
  },
  {
    "text": "and then make sure that\nwe have them accessible.",
    "start": "970990",
    "end": "975170"
  },
  {
    "text": "And then we're gonna drop those",
    "start": "975170",
    "end": "976450"
  },
  {
    "text": "into our S3 bucket in short order.",
    "start": "976450",
    "end": "978943"
  },
  {
    "text": "All right, so we've got\nthe tokenizer downloaded,",
    "start": "980440",
    "end": "982500"
  },
  {
    "text": "and then the train and test\nsets, so we're all set.",
    "start": "982500",
    "end": "985050"
  },
  {
    "text": "There we go, and then\nwe'll upload those to S3.",
    "start": "986030",
    "end": "988513"
  },
  {
    "text": "Now we're gonna run a SageMaker job.",
    "start": "989750",
    "end": "993150"
  },
  {
    "text": "So remember, that SageMaker training job,",
    "start": "993150",
    "end": "995540"
  },
  {
    "text": "using the Hugging Face\nDeep Learning Containers.",
    "start": "995540",
    "end": "998680"
  },
  {
    "text": "So remember, we have prebuilt\nHugging Face containers",
    "start": "998680",
    "end": "1002940"
  },
  {
    "text": "in the SageMaker family,",
    "start": "1002940",
    "end": "1004223"
  },
  {
    "text": "both for training and for hosting",
    "start": "1005120",
    "end": "1006970"
  },
  {
    "text": "and for all the rest of the capabilities",
    "start": "1006970",
    "end": "1009246"
  },
  {
    "text": "that we were just looking at.",
    "start": "1009246",
    "end": "1010180"
  },
  {
    "text": "So we're gonna initialize, again,",
    "start": "1010180",
    "end": "1011930"
  },
  {
    "text": "that Hugging Face construct right here,",
    "start": "1011930",
    "end": "1014360"
  },
  {
    "text": "and then we'll define the hyperparameters",
    "start": "1014360",
    "end": "1016240"
  },
  {
    "text": "that we want for this job.",
    "start": "1016240",
    "end": "1017860"
  },
  {
    "text": "When you are just starting with a model,",
    "start": "1017860",
    "end": "1021209"
  },
  {
    "text": "it is strongly recommended to\nset epochs to a small number,",
    "start": "1021210",
    "end": "1025640"
  },
  {
    "text": "because epochs is essentially a full pass",
    "start": "1025640",
    "end": "1028470"
  },
  {
    "text": "through your dataset.",
    "start": "1028470",
    "end": "1029880"
  },
  {
    "text": "And so if you set epochs to a high number,",
    "start": "1029880",
    "end": "1032699"
  },
  {
    "text": "it just means your job is gonna\nbe training for a long time,",
    "start": "1032700",
    "end": "1036049"
  },
  {
    "text": "and unless you have a\nmodel that's ready to go,",
    "start": "1036050",
    "end": "1039180"
  },
  {
    "text": "you may not want that.",
    "start": "1039180",
    "end": "1040209"
  },
  {
    "text": "So it's better to start\nwith a smaller epoch number.",
    "start": "1040210",
    "end": "1044250"
  },
  {
    "text": "We're also gonna pass in\nsomething called train_batch_size.",
    "start": "1044250",
    "end": "1047740"
  },
  {
    "text": "So that's literally the number\nof records in your dataset",
    "start": "1047740",
    "end": "1051400"
  },
  {
    "text": "the script is gonna be picking up",
    "start": "1051400",
    "end": "1053270"
  },
  {
    "text": "to pass through your network per batch.",
    "start": "1053270",
    "end": "1056060"
  },
  {
    "text": "So train_batch_size 32,\nand then our model name.",
    "start": "1056060",
    "end": "1060023"
  },
  {
    "text": "So here's our estimator.",
    "start": "1062150",
    "end": "1063260"
  },
  {
    "text": "So we have that Hugging Face construct,",
    "start": "1063260",
    "end": "1065630"
  },
  {
    "text": "and the entry point is\na local Python script.",
    "start": "1065630",
    "end": "1068900"
  },
  {
    "text": "Now, that local Python script,",
    "start": "1068900",
    "end": "1070950"
  },
  {
    "text": "happy to tell you, is optional.",
    "start": "1070950",
    "end": "1073419"
  },
  {
    "text": "So in the training deep dive video,",
    "start": "1073420",
    "end": "1075660"
  },
  {
    "text": "we're gonna look at more specifically",
    "start": "1075660",
    "end": "1077410"
  },
  {
    "text": "passing in a GitHub config\nso you can actually just run",
    "start": "1077410",
    "end": "1081870"
  },
  {
    "text": "the Hugging Face code\nthat's sitting on GitHub,",
    "start": "1081870",
    "end": "1085440"
  },
  {
    "text": "you can run that directly\nfrom your SageMaker estimator.",
    "start": "1085440",
    "end": "1088850"
  },
  {
    "text": "But here we've got a local train.py.",
    "start": "1088850",
    "end": "1091179"
  },
  {
    "text": "And let's see if we can open that up here.",
    "start": "1091180",
    "end": "1093670"
  },
  {
    "text": "So that's out here in my scripts folder,",
    "start": "1093670",
    "end": "1098030"
  },
  {
    "text": "and there we go, train.py.",
    "start": "1098030",
    "end": "1099350"
  },
  {
    "text": "So let's look at this briefly.",
    "start": "1099350",
    "end": "1100850"
  },
  {
    "text": "So remember, from transformers,",
    "start": "1101880",
    "end": "1103560"
  },
  {
    "text": "that's that Hugging Face SDK,\nwe're gonna import from there.",
    "start": "1103560",
    "end": "1107670"
  },
  {
    "text": "And these should all look pretty familiar.",
    "start": "1107670",
    "end": "1109040"
  },
  {
    "text": "So that AutoModel trainer API",
    "start": "1109040",
    "end": "1111880"
  },
  {
    "text": "is the Hugging Face based trainer API.",
    "start": "1111880",
    "end": "1113870"
  },
  {
    "text": "Super useful TrainingArguments\nin that tokenizer.",
    "start": "1113870",
    "end": "1118240"
  },
  {
    "text": "And so if name equals main,",
    "start": "1118240",
    "end": "1119900"
  },
  {
    "text": "remember that's how we start\nour scripts generally speaking,",
    "start": "1119900",
    "end": "1124390"
  },
  {
    "text": "but especially we do\nthem a lot in SageMaker.",
    "start": "1124390",
    "end": "1126660"
  },
  {
    "text": "And then we'll start with\nquite a few argparsers.",
    "start": "1126660",
    "end": "1129600"
  },
  {
    "text": "So we're gonna add in the epochs,",
    "start": "1129600",
    "end": "1131830"
  },
  {
    "text": "train_batch_size, et cetera.",
    "start": "1131830",
    "end": "1133492"
  },
  {
    "text": "Load in our datasets from disk.",
    "start": "1134360",
    "end": "1136860"
  },
  {
    "text": "Turn on the logger.",
    "start": "1136860",
    "end": "1138429"
  },
  {
    "text": "And then what do you know?",
    "start": "1138430",
    "end": "1140340"
  },
  {
    "text": "It's exactly the same\nscripts we saw from earlier.",
    "start": "1140340",
    "end": "1142880"
  },
  {
    "text": "Remember, so\nAutoModelForSequenceClassification,",
    "start": "1142880",
    "end": "1145360"
  },
  {
    "text": "and then that AutoTokenizer.",
    "start": "1145360",
    "end": "1147490"
  },
  {
    "text": "The difference is that now\nwe're passing it into a script",
    "start": "1147490",
    "end": "1150570"
  },
  {
    "text": "and then we're gonna run it",
    "start": "1150570",
    "end": "1151809"
  },
  {
    "text": "on the SageMaker training backend.",
    "start": "1151810",
    "end": "1154220"
  },
  {
    "text": "So we're defining our training arguments.",
    "start": "1154220",
    "end": "1156200"
  },
  {
    "text": "We're gonna pass that into the trainer",
    "start": "1156200",
    "end": "1158549"
  },
  {
    "text": "called trainer.fit, trainer.train.",
    "start": "1158550",
    "end": "1161800"
  },
  {
    "text": "Then we'll run an eval,",
    "start": "1161800",
    "end": "1163450"
  },
  {
    "text": "and then save the model out to S3.",
    "start": "1163450",
    "end": "1165429"
  },
  {
    "text": "So that's our training file,",
    "start": "1165430",
    "end": "1168083"
  },
  {
    "text": "and let's look at that in action.",
    "start": "1168920",
    "end": "1171340"
  },
  {
    "text": "So we're gonna say estimator.fit, right?",
    "start": "1171340",
    "end": "1173630"
  },
  {
    "text": "And we're gonna point to our\ntraining and test datasets",
    "start": "1173630",
    "end": "1177010"
  },
  {
    "text": "which are landed in S3.",
    "start": "1177010",
    "end": "1178333"
  },
  {
    "text": "And so this happens\nexactly as you'd think.",
    "start": "1179223",
    "end": "1183610"
  },
  {
    "text": "We have a p3.2xl,",
    "start": "1183610",
    "end": "1185500"
  },
  {
    "text": "so that's gonna be one NVIDIA V100",
    "start": "1185500",
    "end": "1189350"
  },
  {
    "text": "that's coming online in the\nSageMaker training instance.",
    "start": "1189350",
    "end": "1192480"
  },
  {
    "text": "And so we're printing\nout the hyperparameters",
    "start": "1192480",
    "end": "1194880"
  },
  {
    "text": "and the inputs and outputs,",
    "start": "1196320",
    "end": "1198950"
  },
  {
    "text": "environment variables,",
    "start": "1198950",
    "end": "1200919"
  },
  {
    "text": "and then the play by play.",
    "start": "1200920",
    "end": "1204120"
  },
  {
    "text": "So just loading in the model itself here,",
    "start": "1204120",
    "end": "1206580"
  },
  {
    "text": "counting the parameters,",
    "start": "1206580",
    "end": "1208222"
  },
  {
    "text": "and then all sorts of downloading,",
    "start": "1209100",
    "end": "1211673"
  },
  {
    "text": "and then lots of tokens.",
    "start": "1212540",
    "end": "1214450"
  },
  {
    "text": "And so I'm just gonna close this here,",
    "start": "1214450",
    "end": "1216090"
  },
  {
    "text": "'cause that's a bit of an eyesore,",
    "start": "1216090",
    "end": "1217480"
  },
  {
    "text": "but the net-net is we trained our model,",
    "start": "1217480",
    "end": "1219429"
  },
  {
    "text": "the model trains.",
    "start": "1219430",
    "end": "1221030"
  },
  {
    "text": "And then once it's trained,",
    "start": "1221030",
    "end": "1223370"
  },
  {
    "text": "we're gonna do another complex maneuver,",
    "start": "1223370",
    "end": "1226483"
  },
  {
    "text": "I say with tongue in cheek.",
    "start": "1227457",
    "end": "1229160"
  },
  {
    "text": "This is not a complex maneuver.",
    "start": "1229160",
    "end": "1231130"
  },
  {
    "text": "We're gonna say estimator.fit,",
    "start": "1231130",
    "end": "1233010"
  },
  {
    "text": "and again, just using that estimator",
    "start": "1233010",
    "end": "1236880"
  },
  {
    "text": "that we did in order to run the job,",
    "start": "1236880",
    "end": "1238640"
  },
  {
    "text": "we're gonna use the same estimator here",
    "start": "1238640",
    "end": "1240880"
  },
  {
    "text": "and say .deploy.",
    "start": "1240880",
    "end": "1243910"
  },
  {
    "text": "So we're gonna deploy that endpoint.",
    "start": "1243910",
    "end": "1245740"
  },
  {
    "text": "In this case, we're\ndeploying onto one m5.xlarge,",
    "start": "1245740",
    "end": "1249087"
  },
  {
    "text": "so one extra large general\npurpose compute instance.",
    "start": "1250460",
    "end": "1255460"
  },
  {
    "text": "And then, so that's our predictor,",
    "start": "1256490",
    "end": "1258679"
  },
  {
    "text": "and we'll pass in our inputs\nand then we'll get the score.",
    "start": "1258680",
    "end": "1262883"
  },
  {
    "text": "So in this demo, we\nfinetuned a BERT model.",
    "start": "1264474",
    "end": "1267670"
  },
  {
    "text": "We trained it on SageMaker\nand we hosted it on SageMaker.",
    "start": "1267670",
    "end": "1271862"
  },
  {
    "text": "And we're gonna just briefly take a look",
    "start": "1271862",
    "end": "1273570"
  },
  {
    "text": "at some of those objects in the console,",
    "start": "1273570",
    "end": "1275610"
  },
  {
    "text": "if that's your preference.",
    "start": "1275610",
    "end": "1278481"
  },
  {
    "text": "So again, here I'm in the\nSageMaker AWS console.",
    "start": "1278482",
    "end": "1281220"
  },
  {
    "text": "This is the dark mode you'll see,",
    "start": "1281220",
    "end": "1284220"
  },
  {
    "text": "and essentially I'm gonna\nlook at this training job.",
    "start": "1284220",
    "end": "1288090"
  },
  {
    "text": "And you'll see I've got my p3.2xl.",
    "start": "1288090",
    "end": "1291140"
  },
  {
    "text": "This was one machine I was running on.",
    "start": "1291140",
    "end": "1293790"
  },
  {
    "text": "My dataset is loaded in S3 here",
    "start": "1293790",
    "end": "1296520"
  },
  {
    "text": "and my test dataset is also loaded there.",
    "start": "1297360",
    "end": "1300590"
  },
  {
    "text": "And I'll be able to\nlook at some very brief,",
    "start": "1300590",
    "end": "1304220"
  },
  {
    "text": "remember, this was one epoch,",
    "start": "1304220",
    "end": "1306460"
  },
  {
    "text": "so definitely a short period.",
    "start": "1306460",
    "end": "1309080"
  },
  {
    "text": "And then my model artifact\nwas hosted again in S3.",
    "start": "1309080",
    "end": "1314080"
  },
  {
    "text": "So after the job completed,",
    "start": "1314480",
    "end": "1316559"
  },
  {
    "text": "I was able to look at\nthe model output in S3,",
    "start": "1316560",
    "end": "1320040"
  },
  {
    "text": "and then when we deployed\nit to the endpoint,",
    "start": "1320040",
    "end": "1323270"
  },
  {
    "text": "again, we actually created\nthis new SageMaker instance",
    "start": "1323270",
    "end": "1327770"
  },
  {
    "text": "in the backend, which is\nhosting that pre-trained model.",
    "start": "1327770",
    "end": "1331660"
  },
  {
    "text": "And so here's my endpoints.",
    "start": "1331660",
    "end": "1333900"
  },
  {
    "text": "I have monitoring enabled on my endpoints",
    "start": "1333900",
    "end": "1336030"
  },
  {
    "text": "so I can look at the utilization",
    "start": "1336030",
    "end": "1338880"
  },
  {
    "text": "across a couple different settings there.",
    "start": "1338880",
    "end": "1341070"
  },
  {
    "text": "I can specify the traffic",
    "start": "1341070",
    "end": "1343840"
  },
  {
    "text": "and I can double click on the\nmodel that's hosted there,",
    "start": "1343840",
    "end": "1347730"
  },
  {
    "text": "which is this model\nspecifically using this image",
    "start": "1347730",
    "end": "1351020"
  },
  {
    "text": "pointing to my model data in S3.",
    "start": "1352020",
    "end": "1353843"
  },
  {
    "text": "And that's what I got.",
    "start": "1356080",
    "end": "1357970"
  },
  {
    "text": "So I hope you enjoyed the demo.",
    "start": "1357970",
    "end": "1360270"
  },
  {
    "text": "And so now we'll close it\nout with some pro tips.",
    "start": "1360270",
    "end": "1363820"
  },
  {
    "text": "So number one, if you're\nunsure which model to use",
    "start": "1363820",
    "end": "1368820"
  },
  {
    "text": "and how to utilize that model,",
    "start": "1369420",
    "end": "1371640"
  },
  {
    "text": "I would say try and have a\npreference for finetuning.",
    "start": "1371640",
    "end": "1374990"
  },
  {
    "text": "Actually, when you finetune a model,",
    "start": "1374990",
    "end": "1377040"
  },
  {
    "text": "you really have a chance",
    "start": "1377040",
    "end": "1378160"
  },
  {
    "text": "to just make it more\nspecific to your data.",
    "start": "1378160",
    "end": "1380970"
  },
  {
    "text": "That model is gonna know\nmore about your data,",
    "start": "1380970",
    "end": "1383020"
  },
  {
    "text": "it's gonna be more in the style\nof the text that you prefer,",
    "start": "1383020",
    "end": "1386320"
  },
  {
    "text": "it's gonna be more\nsuited to your use cases,",
    "start": "1386320",
    "end": "1389679"
  },
  {
    "text": "so I would say try and have a preference",
    "start": "1389680",
    "end": "1391350"
  },
  {
    "text": "for finetuning your model.",
    "start": "1391350",
    "end": "1393549"
  },
  {
    "text": "Another preference you should try and have",
    "start": "1393550",
    "end": "1396170"
  },
  {
    "text": "is just use the Hugging Face scripts.",
    "start": "1396170",
    "end": "1397990"
  },
  {
    "text": "Like, they have, again, a\nhuge amount of examples.",
    "start": "1397990",
    "end": "1401790"
  },
  {
    "text": "They have code samples available,",
    "start": "1401790",
    "end": "1403230"
  },
  {
    "text": "they have notebooks available,",
    "start": "1403230",
    "end": "1404510"
  },
  {
    "text": "they have lots of scripts.",
    "start": "1404510",
    "end": "1405950"
  },
  {
    "text": "Their scripts are lovely.",
    "start": "1405950",
    "end": "1407299"
  },
  {
    "text": "They're updated regularly.",
    "start": "1407300",
    "end": "1409570"
  },
  {
    "text": "They work excellently.",
    "start": "1409570",
    "end": "1411470"
  },
  {
    "text": "Really try and use those directly.",
    "start": "1411470",
    "end": "1413419"
  },
  {
    "text": "And in the training video coming up,",
    "start": "1413420",
    "end": "1416090"
  },
  {
    "text": "we're gonna double click\non that specifically",
    "start": "1416090",
    "end": "1418070"
  },
  {
    "text": "and just really unpack what's going on.",
    "start": "1418070",
    "end": "1420019"
  },
  {
    "text": "And then the last pro tip I would have",
    "start": "1421051",
    "end": "1422130"
  },
  {
    "text": "is just plan for bias, actually.",
    "start": "1422130",
    "end": "1425070"
  },
  {
    "text": "NLP models, very well documented,",
    "start": "1425070",
    "end": "1428063"
  },
  {
    "text": "they inherit the bias that\nsits in their datasets.",
    "start": "1429030",
    "end": "1432400"
  },
  {
    "text": "So it's common to see bias around",
    "start": "1432400",
    "end": "1434480"
  },
  {
    "text": "especially social characteristics",
    "start": "1434480",
    "end": "1436030"
  },
  {
    "text": "with different individuals,",
    "start": "1436030",
    "end": "1437710"
  },
  {
    "text": "ways of describing those\nindividuals, models,",
    "start": "1437710",
    "end": "1440320"
  },
  {
    "text": "will put them into different profiles.",
    "start": "1440320",
    "end": "1443669"
  },
  {
    "text": "And so when you are designing your model,",
    "start": "1443670",
    "end": "1446860"
  },
  {
    "text": "anticipate some level of bias.",
    "start": "1446860",
    "end": "1448760"
  },
  {
    "text": "And again SageMaker Clarify",
    "start": "1448760",
    "end": "1451130"
  },
  {
    "text": "has some bias detection capabilities,",
    "start": "1451130",
    "end": "1454250"
  },
  {
    "text": "especially for text classification,",
    "start": "1454250",
    "end": "1456290"
  },
  {
    "text": "and then you can also monitor those models",
    "start": "1456290",
    "end": "1459310"
  },
  {
    "text": "for bias as well using SageMaker.",
    "start": "1459310",
    "end": "1462280"
  },
  {
    "text": "And with that, thank you very much.",
    "start": "1462280",
    "end": "1465310"
  },
  {
    "text": "So there's also a 30-day\nfree trial for O'Reilly.",
    "start": "1465310",
    "end": "1469070"
  },
  {
    "text": "So that tiny or URL, you can\ngo ahead and click on that",
    "start": "1469070",
    "end": "1473169"
  },
  {
    "text": "if you prefer, and\nthat'll give you 30 days",
    "start": "1473170",
    "end": "1476310"
  },
  {
    "text": "of reading O'Reilly\nbooks, and then you too",
    "start": "1476310",
    "end": "1479760"
  },
  {
    "text": "can get your very own O'Reilly\ncopy and join me in reading.",
    "start": "1479760",
    "end": "1483970"
  },
  {
    "text": "So, thanks.",
    "start": "1483970",
    "end": "1485033"
  }
]
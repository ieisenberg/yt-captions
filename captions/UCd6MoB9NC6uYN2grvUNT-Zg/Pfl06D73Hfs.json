[
  {
    "text": "my name is John handler I'm a Solutions Architect with AWS I work with our search services specifically",
    "start": "539",
    "end": "6690"
  },
  {
    "text": "elasticsearch and cloud search and today we are going to talk about elastic search service up I got to do my button",
    "start": "6690",
    "end": "17270"
  },
  {
    "text": "okay that's me John handler so out of curiosity who is",
    "start": "17270",
    "end": "25619"
  },
  {
    "text": "currently using elastic search very large a number of people that's great so",
    "start": "25619",
    "end": "33090"
  },
  {
    "text": "a lot of you are going to know some of this background material pretty intimately you know as we look at it we",
    "start": "33090",
    "end": "39629"
  },
  {
    "text": "are generating tons and tons of data and we're generating more data all the time back when I was a baby hacker we had",
    "start": "39629",
    "end": "46320"
  },
  {
    "text": "like 10 megabyte discs and boy we were happy and you know everybody remembers that 640 KB thing so and in fact you",
    "start": "46320",
    "end": "54899"
  },
  {
    "text": "know we see a lot of different places where this is coming specifically we see",
    "start": "54899",
    "end": "60690"
  },
  {
    "text": "a lot of movement down in the organization so a lot of developers are",
    "start": "60690",
    "end": "66619"
  },
  {
    "text": "generating data from their applications they're generating log data from their infrastructure and they're directly",
    "start": "66619",
    "end": "72720"
  },
  {
    "text": "interacting with that data they want to monitor they want to figure out what's going on with it we also have tons of IOT devices out",
    "start": "72720",
    "end": "79439"
  },
  {
    "text": "there everything from temperature sensors to smart buildings to taxis all of that stuff and finally we have",
    "start": "79439",
    "end": "85890"
  },
  {
    "text": "cloud-based architectures where if you're putting an architecture and cloud building application in the cloud",
    "start": "85890",
    "end": "92070"
  },
  {
    "text": "you'll be generating log data from all of that you'll be generating cloud trail logs you're be generating ec2 logs your",
    "start": "92070",
    "end": "98220"
  },
  {
    "text": "application logs all of that is going to be coming so and really you know the",
    "start": "98220",
    "end": "105840"
  },
  {
    "text": "emphasis there is on the ability to dig in and really get a real-time feel for",
    "start": "105840",
    "end": "110939"
  },
  {
    "text": "what's going on with your application or your hardware based on what's the log data that you have and elasticsearch",
    "start": "110939",
    "end": "118530"
  },
  {
    "text": "came out in 2009 and it's very easy to deploy it's very easy to get your data",
    "start": "118530",
    "end": "124979"
  },
  {
    "text": "into it it's an open-source piece of software and it's compelling there's a really fast time to",
    "start": "124979",
    "end": "130530"
  },
  {
    "text": "you it's very easy to deploy it send a bunch of data in and you're visualizing",
    "start": "130530",
    "end": "136200"
  },
  {
    "text": "it very quickly and all of that has pushed elasticsearch to the top of the",
    "start": "136200",
    "end": "142230"
  },
  {
    "text": "open-source projects this is from TechCrunch elasticsearch number seven on the list of open-source products in",
    "start": "142230",
    "end": "148709"
  },
  {
    "text": "terms of popularity now the wrinkle with it is you know with elasticsearch it is",
    "start": "148709",
    "end": "156390"
  },
  {
    "text": "very easy to get started but as your data size grows and as your deployment",
    "start": "156390",
    "end": "161430"
  },
  {
    "text": "grows it becomes more difficult to manage so two years ago we came out with Amazon elastic search service that makes",
    "start": "161430",
    "end": "168120"
  },
  {
    "text": "it easy to deploy in scale elastic search in the AWS cloud we have",
    "start": "168120",
    "end": "176310"
  },
  {
    "text": "a number of things that we provide first of all we provide an open-source compatible version of elastic search so",
    "start": "176310",
    "end": "182730"
  },
  {
    "text": "if you're already using elastic search and you're using itself managed you can bring that into the service easily we do",
    "start": "182730",
    "end": "190170"
  },
  {
    "text": "the management and overhead and undifferentiated heavy lifting work to",
    "start": "190170",
    "end": "195590"
  },
  {
    "text": "manage that cluster for you and you can use the same open source tools and api's",
    "start": "195590",
    "end": "200640"
  },
  {
    "text": "that you're already using second of all we make it easy to use so with Amazon elastic search service you",
    "start": "200640",
    "end": "207840"
  },
  {
    "text": "use the console SDKs CLI what-have-you to deploy an elastic search cluster we",
    "start": "207840",
    "end": "214500"
  },
  {
    "text": "do the work of bringing all that in making cluster out of it configuring it and bring it to you over an endpoint",
    "start": "214500",
    "end": "219959"
  },
  {
    "text": "that you can use the elastic search REST API we make it easy to scale with",
    "start": "219959",
    "end": "225299"
  },
  {
    "text": "elastic search service you can change the funder the underlying pieces of your",
    "start": "225299",
    "end": "231090"
  },
  {
    "text": "infrastructure so if you'd like to go from an m3 to x-large to an r3 8x large",
    "start": "231090",
    "end": "237000"
  },
  {
    "text": "just a few commands and we will redeploy a new cluster for you and we'll do all",
    "start": "237000",
    "end": "244109"
  },
  {
    "text": "of that work seamlessly so you continue to use your cluster it's all behind load balancing we have a number of different",
    "start": "244109",
    "end": "250200"
  },
  {
    "text": "security options so you can use I am and VPC together or separately to secure",
    "start": "250200",
    "end": "257820"
  },
  {
    "text": "access to your cluster and make sure that only the right people get to view the information that you want them to view we have a high",
    "start": "257820",
    "end": "264780"
  },
  {
    "text": "availability feature this is called multi a Z we simply split your cluster",
    "start": "264780",
    "end": "270270"
  },
  {
    "text": "into two zones you have a hundred percent data redundancy in each of those zones makes your cluster more resilient",
    "start": "270270",
    "end": "277319"
  },
  {
    "text": "and finally we have a lot of integrations with other AWS services on the inside you can send data from cloud",
    "start": "277319",
    "end": "284370"
  },
  {
    "text": "watch logs directly to elastic search service you can use Kinesis firehose to send data to elastic search service you",
    "start": "284370",
    "end": "291090"
  },
  {
    "text": "can send it from IOT and on the cluster creation side cloud formation does",
    "start": "291090",
    "end": "296729"
  },
  {
    "text": "support elastic search service as well we see a number of different uses of",
    "start": "296729",
    "end": "302970"
  },
  {
    "text": "elastic search service so in particular the main use case that we have is for",
    "start": "302970",
    "end": "308370"
  },
  {
    "text": "application and infrastructure monitoring so most of our customers are",
    "start": "308370",
    "end": "313409"
  },
  {
    "text": "sending logs into elastic search those logs are Apache web logs their sis logs what have you and they're using Cabana",
    "start": "313409",
    "end": "321180"
  },
  {
    "text": "to visualize what's going on with their application or with their hardware to make make sure things are up and running",
    "start": "321180",
    "end": "327020"
  },
  {
    "text": "we also see a number of siem use cases things like denial of service fraud",
    "start": "327020",
    "end": "334620"
  },
  {
    "text": "detection people are using their logs sending them in and then being able to",
    "start": "334620",
    "end": "339840"
  },
  {
    "text": "pull out that kind of information in the IOT space of course IOT data goes in",
    "start": "339840",
    "end": "345090"
  },
  {
    "text": "there you have nice graphs and charts you can see what's going on and then finally at a business level we do see a",
    "start": "345090",
    "end": "351930"
  },
  {
    "text": "lot of data flowing in from logs that allows business users to figure out how the software is being used what people",
    "start": "351930",
    "end": "358770"
  },
  {
    "text": "are buying what people are doing with the software and how to improve it I'll",
    "start": "358770",
    "end": "364380"
  },
  {
    "text": "just mention a couple of case studies for you so the first one these is Expedia Expedia had tons and tons of",
    "start": "364380",
    "end": "372180"
  },
  {
    "text": "logs and again driven very bottom-up by individual developer groups that were",
    "start": "372180",
    "end": "377340"
  },
  {
    "text": "deploying elasticsearch with their applications so that they could do development work and monitoring of that",
    "start": "377340",
    "end": "383909"
  },
  {
    "text": "application you know as a corporate model we do see a lot that when we have",
    "start": "383909",
    "end": "389130"
  },
  {
    "text": "these very scattered use cases there's a drive to bring them into a more sense realized architectures so that people",
    "start": "389130",
    "end": "396110"
  },
  {
    "text": "are more successful with being able to monitor their their software so they",
    "start": "396110",
    "end": "401900"
  },
  {
    "text": "have come onto the service they are streaming a number of different log types and they have a centralized",
    "start": "401900",
    "end": "408260"
  },
  {
    "text": "logging service with Kabana that allows their developers to to deploy that and use it another interesting use case this",
    "start": "408260",
    "end": "416810"
  },
  {
    "text": "is a more of a business data kind of use case so Financial Times is an online media amongst other media companies and",
    "start": "416810",
    "end": "424550"
  },
  {
    "text": "they are sending their applicate their web traffic logs to elasticsearch they",
    "start": "424550",
    "end": "431960"
  },
  {
    "text": "have an internal tool which they call Lantern and Lantern allows their journalist number one to go look and see",
    "start": "431960",
    "end": "438650"
  },
  {
    "text": "what is the world doing with their articles how what's the interaction like how long are people dwelling it's really",
    "start": "438650",
    "end": "445550"
  },
  {
    "text": "it's a nice thing for the journalist they get the immediate feedback of knowing that people like their content on top of that the editorial board is",
    "start": "445550",
    "end": "452360"
  },
  {
    "text": "able to use these use this information in this analysis to figure out how to target content and what to bring out we",
    "start": "452360",
    "end": "462350"
  },
  {
    "text": "have a number of customers who are using elastic search service these range in",
    "start": "462350",
    "end": "467450"
  },
  {
    "text": "scale from very small to very large the thing that is interesting about this",
    "start": "467450",
    "end": "472610"
  },
  {
    "text": "slide is we have so many different segments that are all using elastic search service primarily they're using",
    "start": "472610",
    "end": "479300"
  },
  {
    "text": "it again for this kind of real-time monitoring where they're able to see what's going on with their hardware and",
    "start": "479300",
    "end": "485030"
  },
  {
    "text": "software so there's not a particular segment directed usage of elastic search",
    "start": "485030",
    "end": "491210"
  },
  {
    "text": "it's across the board log monitoring we have a number of different topics that",
    "start": "491210",
    "end": "496639"
  },
  {
    "text": "we'll cover today some foundational stuff we'll talk about ingest security",
    "start": "496639",
    "end": "502370"
  },
  {
    "text": "durability monitoring and also a little bit of analysis so hello I love this",
    "start": "502370",
    "end": "510139"
  },
  {
    "text": "slide so who has something that generates logs okay right everybody yeah and you know when the pager goes off and",
    "start": "510139",
    "end": "517459"
  },
  {
    "text": "it's 3:00 in the morning and the servers are melting and your boss says you need",
    "start": "517459",
    "end": "523130"
  },
  {
    "text": "to get in there and figure it out right and then you have this this is an Apache web blog in fact it's from NASA but it's an",
    "start": "523130",
    "end": "530269"
  },
  {
    "text": "open-source weblog let's say I have you know a terabyte of that right what's the",
    "start": "530269",
    "end": "535370"
  },
  {
    "text": "first thing I want to do I want to reach for my search tools so I can find the thing that's that's broken right",
    "start": "535370",
    "end": "541100"
  },
  {
    "text": "this is human readable but it's not useful in this format right and beyond",
    "start": "541100",
    "end": "546350"
  },
  {
    "text": "that what I'd like to do is I'd like to have a nice interface that lets me visualize in some way that's meaningful",
    "start": "546350",
    "end": "553720"
  },
  {
    "text": "what is going on under the covers so I",
    "start": "553720",
    "end": "558769"
  },
  {
    "text": "have a little demo this is actually from a lab that we're gonna be running Thursday what we've done is we created a",
    "start": "558769",
    "end": "566149"
  },
  {
    "text": "little sample application that allows you to search through a movie database of 5,000 movies the search is actually",
    "start": "566149",
    "end": "574190"
  },
  {
    "text": "powered by elastic search as well so elastic search is good for text search as well on the individual application",
    "start": "574190",
    "end": "581839"
  },
  {
    "text": "nodes we have a technology called file beat which is sending the Apache web log lines through Redis which is buffering",
    "start": "581839",
    "end": "589339"
  },
  {
    "text": "into elastic search we're then able to use Cabana to visualize what's going on",
    "start": "589339",
    "end": "595270"
  },
  {
    "text": "with the cluster with the application so",
    "start": "595270",
    "end": "601870"
  },
  {
    "text": "and all of this is is happening in a V PC so I actually have an SSH tunnel I'm",
    "start": "608860",
    "end": "616030"
  },
  {
    "text": "running from my laptop which is talking to my VPS which is talking to the elasticsearch cluster in my V PC that",
    "start": "616030",
    "end": "622150"
  },
  {
    "text": "lets me use Chrome here to connect to",
    "start": "622150",
    "end": "627880"
  },
  {
    "text": "the cluster alright let me just make it a little bit bigger okay so it's this is",
    "start": "627880",
    "end": "637990"
  },
  {
    "text": "the application right so it's a very simple application you know I can simply type something like Gwyneth Paltrow say",
    "start": "637990",
    "end": "647010"
  },
  {
    "text": "and I'll see some movies by winneth Paltrow I don't see Iron Man here which",
    "start": "647010",
    "end": "652570"
  },
  {
    "text": "is my favorite movie so let's go ahead and search for Iron Man and we can get",
    "start": "652570",
    "end": "658870"
  },
  {
    "text": "titles like that so this is totally obvious this is the stand-in like I'm just running some kind of search",
    "start": "658870",
    "end": "665710"
  },
  {
    "text": "application so it's also happening again we have data that's coming from my web",
    "start": "665710",
    "end": "671920"
  },
  {
    "text": "log lines and this coming into Cabana now this is the Cabana UI and you can",
    "start": "671920",
    "end": "678460"
  },
  {
    "text": "see here I have a graph at the top which is showing all of the traffic to my website I have also here some example",
    "start": "678460",
    "end": "686470"
  },
  {
    "text": "love lines that are coming in right so I can look at one of these can you guys",
    "start": "686470",
    "end": "695320"
  },
  {
    "text": "see that yeah pretty much let me see if I can make it bigger you'll see here",
    "start": "695320",
    "end": "704170"
  },
  {
    "text": "these are all the pieces of the message itself right so here is the Apache web",
    "start": "704170",
    "end": "709420"
  },
  {
    "text": "message that's that's what's coming out of my log line data that goes into elasticsearch gets structured into jason",
    "start": "709420",
    "end": "715480"
  },
  {
    "text": "and split into individual fields those fields are searchable they're also visualizable right so some",
    "start": "715480",
    "end": "721810"
  },
  {
    "text": "of this some of the things that I have in here that are broken out here's the straight-up request here's the response",
    "start": "721810",
    "end": "727360"
  },
  {
    "text": "code etc etc I can also build visualizations so I have a number of",
    "start": "727360",
    "end": "733930"
  },
  {
    "text": "different visualizations that I can build including charts and graphs and",
    "start": "733930",
    "end": "739310"
  },
  {
    "text": "line graphs and pie graphs all of these things so I can do something pretty simple I can simply go in and we have to",
    "start": "739310",
    "end": "749120"
  },
  {
    "text": "have to think of this like an OLAP cube okay so I have fields in there and I'm",
    "start": "749120",
    "end": "754760"
  },
  {
    "text": "able to create buckets based on ranges of values in those fields and I'm able",
    "start": "754760",
    "end": "759770"
  },
  {
    "text": "to subdivide those buckets to create visualizations so for this particular visualization let's say I want to know",
    "start": "759770",
    "end": "765800"
  },
  {
    "text": "how much data am i pushing out of my web server right over time so the first",
    "start": "765800",
    "end": "771710"
  },
  {
    "text": "thing I need is on the x-axis I need to have a graph which is the time if I set",
    "start": "771710",
    "end": "778850"
  },
  {
    "text": "that one up you can see here this is actually just a graph of all my requests you can see the couple there where I",
    "start": "778850",
    "end": "784520"
  },
  {
    "text": "sent four movies right but what I actually want is the sum of my traffic",
    "start": "784520",
    "end": "791780"
  },
  {
    "text": "out these are the kinds of aggregations is the kind of functions I can compute for the y-axis I have things like the",
    "start": "791780",
    "end": "797990"
  },
  {
    "text": "sum in the medium and the min and the max and the average all of those things I can compute and put on the y-axis but",
    "start": "797990",
    "end": "803450"
  },
  {
    "text": "I'm gonna pick some and I'm gonna go ahead and pick the byte field so this is",
    "start": "803450",
    "end": "811880"
  },
  {
    "text": "a sum of bytes I can also save that and I can build a dashboard out of it",
    "start": "811880",
    "end": "817280"
  },
  {
    "text": "the dashboard is really where things become interesting and useful so this",
    "start": "817280",
    "end": "822320"
  },
  {
    "text": "dashboard has a number of things on it including a total number of requests here's my traffic graph here's an",
    "start": "822320",
    "end": "829280"
  },
  {
    "text": "average of the bytes out for my server IPS and requests this is a breakdown of source IP and what is the actual request",
    "start": "829280",
    "end": "837260"
  },
  {
    "text": "that it made I have agents this is the agent field in the web log line I even",
    "start": "837260",
    "end": "843800"
  },
  {
    "text": "can have a keyword cloud we can see my my keywords there so I'm gonna take this",
    "start": "843800",
    "end": "849950"
  },
  {
    "text": "one quick step further I have J meter setup J meter is using is hitting the",
    "start": "849950",
    "end": "857030"
  },
  {
    "text": "application with URLs and it's doing searches in the application for one to",
    "start": "857030",
    "end": "863330"
  },
  {
    "text": "five words so what I do that so now I",
    "start": "863330",
    "end": "868430"
  },
  {
    "text": "have 25 threads running and I'm also here going to enable my auto refresh so with",
    "start": "868430",
    "end": "875930"
  },
  {
    "text": "with cabana I can set an auto refresh so that my my graph updates and you can see",
    "start": "875930",
    "end": "883850"
  },
  {
    "text": "you know my traffic is starting to come in so this is the the kind of the power",
    "start": "883850",
    "end": "889190"
  },
  {
    "text": "of caba√±as to be able quickly i'm this dashboard took me maybe 20 minutes to set up and yet i have tons of useful",
    "start": "889190",
    "end": "896630"
  },
  {
    "text": "information that's updating in real time as traffic is coming to my website so",
    "start": "896630",
    "end": "906220"
  },
  {
    "text": "let's talk a little bit about how we set that up and what goes what are the",
    "start": "908260",
    "end": "913490"
  },
  {
    "text": "pieces how do I put them together so in particular when I use Amazon Elastic",
    "start": "913490",
    "end": "919370"
  },
  {
    "text": "search service I deploy what we call a domain a domain wraps a number of",
    "start": "919370",
    "end": "924589"
  },
  {
    "text": "different pieces of hardware the software and all of the portions of elasticsearch that you use in particular",
    "start": "924589",
    "end": "931370"
  },
  {
    "text": "we have a number of different instances so we have data instances and master instances we have load balancing in",
    "start": "931370",
    "end": "938180"
  },
  {
    "text": "front of the cluster that's sending the traffic across all that we have I am that you use for security to control",
    "start": "938180",
    "end": "945170"
  },
  {
    "text": "access to the different pieces of the cluster and we send logs to cloud trail",
    "start": "945170",
    "end": "950240"
  },
  {
    "text": "and cloud watch logs when you use elastic search you when you use any",
    "start": "950240",
    "end": "958430"
  },
  {
    "text": "search engine really a document is a core entity of the search engine a search document is what you send into a",
    "start": "958430",
    "end": "964490"
  },
  {
    "text": "search engine it's what you get back from a search engine for a query ok so the document is the core entity and as I",
    "start": "964490",
    "end": "971360"
  },
  {
    "text": "said a document is structured Jason ok so if we take that Apache web log line",
    "start": "971360",
    "end": "977089"
  },
  {
    "text": "at the top then we break it down into Jason that looks like what's on the left",
    "start": "977089",
    "end": "982250"
  },
  {
    "text": "and that gives us the document that we're sending to elasticsearch the documents contain fields and a field is",
    "start": "982250",
    "end": "989390"
  },
  {
    "text": "a name value pair so in this case we have a field for the verb which is get we have the bytes we have the request we",
    "start": "989390",
    "end": "995930"
  },
  {
    "text": "have the response etc we break it all down like that within elastic search fields can nest and there are tons of",
    "start": "995930",
    "end": "1004029"
  },
  {
    "text": "different value types and you can have single or multiple value fields for weblog lines it's",
    "start": "1004029",
    "end": "1011590"
  },
  {
    "text": "always flat like that so when you send documents to elasticsearch you send them as Jason just like that an elastic",
    "start": "1011590",
    "end": "1019690"
  },
  {
    "text": "search stores those documents in an index index is a high level structure",
    "start": "1019690",
    "end": "1024910"
  },
  {
    "text": "that contains documents right we're not talking here about indexing the values",
    "start": "1024910",
    "end": "1030610"
  },
  {
    "text": "yet so in this case you the documents go into an index that index is logically",
    "start": "1030610",
    "end": "1037540"
  },
  {
    "text": "composed of a number of shards each shard is a subset of all of the",
    "start": "1037540",
    "end": "1042640"
  },
  {
    "text": "documents in the index so in this case we have five primary shards and each of",
    "start": "1042640",
    "end": "1047800"
  },
  {
    "text": "those shards contains one-fifth of the documents in the index not overlapping",
    "start": "1047800",
    "end": "1052920"
  },
  {
    "text": "okay we can also set a dynamically set",
    "start": "1052920",
    "end": "1059080"
  },
  {
    "text": "of replicas so the first set of replicas we want for redundancy so that we have",
    "start": "1059080",
    "end": "1065410"
  },
  {
    "text": "data in two places within the cluster and we can add additional ones for",
    "start": "1065410",
    "end": "1070810"
  },
  {
    "text": "additional capacity the shards themselves elasticsearch distributes",
    "start": "1070810",
    "end": "1077500"
  },
  {
    "text": "onto nodes in a cluster right so we have some instances in this case we have",
    "start": "1077500",
    "end": "1083620"
  },
  {
    "text": "three instances we have our primaries and our replicas are distributed onto the instances in the cluster with the",
    "start": "1083620",
    "end": "1090460"
  },
  {
    "text": "important feature that primary and replicas always go on to different instances okay so if I lose a single",
    "start": "1090460",
    "end": "1097930"
  },
  {
    "text": "node and I have replicas I have a copy somewhere and then elasticsearch can",
    "start": "1097930",
    "end": "1103150"
  },
  {
    "text": "recreate that primary replicas and then",
    "start": "1103150",
    "end": "1108190"
  },
  {
    "text": "finally each shard itself is actually an instance of a process which is running something called Apache Lucene Apache",
    "start": "1108190",
    "end": "1116350"
  },
  {
    "text": "Lucene is a Java library that reads and writes search indexes so when we look at",
    "start": "1116350",
    "end": "1123910"
  },
  {
    "text": "it the shard itself is the main components the the main piece of scale",
    "start": "1123910",
    "end": "1129370"
  },
  {
    "text": "right elasticsearch is distributing all this stuff to parallel eyes across a",
    "start": "1129370",
    "end": "1135310"
  },
  {
    "text": "number of instances the shards themselves are what do the actual work",
    "start": "1135310",
    "end": "1140880"
  },
  {
    "text": "okay so that's our foundation so let's talk about how to get data into elasticsearch when we think about",
    "start": "1141250",
    "end": "1149120"
  },
  {
    "text": "ingestion there are a number of different parts of ingestion number different pieces that you can think about first of all you have a data",
    "start": "1149120",
    "end": "1155780"
  },
  {
    "text": "source somewhere that's going to be your web server that's going to be your s3",
    "start": "1155780",
    "end": "1161750"
  },
  {
    "text": "bucket it's gonna be your Dynamo table it's going to be what-have-you somehow you have to take the data from",
    "start": "1161750",
    "end": "1168440"
  },
  {
    "text": "that source and collect it there are a number of different technologies or pieces that can do this as well for",
    "start": "1168440",
    "end": "1174590"
  },
  {
    "text": "servers we have filed well beets which is an open source product that pulls or",
    "start": "1174590",
    "end": "1181310"
  },
  {
    "text": "tails your log lines we also have logs - we have the Kinesis agent the cloud",
    "start": "1181310",
    "end": "1188540"
  },
  {
    "text": "watch agent all of these can sit on your server tail your logs in a lightweight fashion and push them off to somewhere",
    "start": "1188540",
    "end": "1198340"
  },
  {
    "text": "after the logs are collected then they do need to be transformed as we said they started out as strings they need to",
    "start": "1198340",
    "end": "1204140"
  },
  {
    "text": "be Jason so something has to transform that then depending on scale but usually",
    "start": "1204140",
    "end": "1211310"
  },
  {
    "text": "you also want to have a buffer in place that's going to hold those log lines create batches out of them and deliver",
    "start": "1211310",
    "end": "1217610"
  },
  {
    "text": "those batches to elasticsearch and finally there's the delivery piece so we'll talk about you know a number of",
    "start": "1217610",
    "end": "1224210"
  },
  {
    "text": "different architectures but in the back of your head think about the jobs that they're doing and you can slot many",
    "start": "1224210",
    "end": "1231380"
  },
  {
    "text": "different things into each of those pieces to accomplish the task right so",
    "start": "1231380",
    "end": "1236720"
  },
  {
    "text": "some of the more AWS centric architectures involve number one the",
    "start": "1236720",
    "end": "1242990"
  },
  {
    "text": "data producers and then Kinesis firehose and cloud watch logs performing the",
    "start": "1242990",
    "end": "1248870"
  },
  {
    "text": "buffering and transform IOT you can also do that buffering and transform logstash",
    "start": "1248870",
    "end": "1255290"
  },
  {
    "text": "is again a an open source option for sending that data through it also does",
    "start": "1255290",
    "end": "1261080"
  },
  {
    "text": "buffering and transform that data is arriving at the elastic search service",
    "start": "1261080",
    "end": "1266810"
  },
  {
    "text": "cluster and then the access to that to that data from the front end via Cabana that's one set of options",
    "start": "1266810",
    "end": "1275120"
  },
  {
    "text": "there another set of options that serve different use cases select the first one",
    "start": "1275120",
    "end": "1281270"
  },
  {
    "text": "where we have files perhaps their enterprise files perhaps they're even files of logs that are landing in s3 as",
    "start": "1281270",
    "end": "1288740"
  },
  {
    "text": "your data Lake you then have lambda that can trigger on those object creation",
    "start": "1288740",
    "end": "1294140"
  },
  {
    "text": "events to read those files parse them transform them and send them off somewhere usually this one you'll need a",
    "start": "1294140",
    "end": "1300680"
  },
  {
    "text": "buffering solution in here from DynamoDB we have dynamo streams",
    "start": "1300680",
    "end": "1307130"
  },
  {
    "text": "again you can trigger lambda off your dynamo stream to push data to elasticsearch as it changes in your",
    "start": "1307130",
    "end": "1312260"
  },
  {
    "text": "table and then finally we have Kinesis streams where you can have the Kinesis",
    "start": "1312260",
    "end": "1318020"
  },
  {
    "text": "client on your data producer pushing to a Kinesis stream lambda can trigger off of that do a transform send it somewhere",
    "start": "1318020",
    "end": "1325460"
  },
  {
    "text": "else to do a transform buffer etc I like",
    "start": "1325460",
    "end": "1331040"
  },
  {
    "text": "to mention Kinesis firehose because I Kinesis firehose has some really great characteristics for elasticsearch",
    "start": "1331040",
    "end": "1337340"
  },
  {
    "text": "traffic number one it is server lists its scales almost infinitely and it",
    "start": "1337340",
    "end": "1346100"
  },
  {
    "text": "affords you the opportunity to do the transform in line so with Kinesis firehose you can trigger",
    "start": "1346100",
    "end": "1352010"
  },
  {
    "text": "a lambda for all of the events as they're coming through that fire hose you can transform those records return",
    "start": "1352010",
    "end": "1357800"
  },
  {
    "text": "them to fire hose fire hose will deliver them so that nicely takes care of transformation in buffering fire hose",
    "start": "1357800",
    "end": "1364040"
  },
  {
    "text": "also deals with with errors so if documents are not delivered to elasticsearch fire hose will put them in",
    "start": "1364040",
    "end": "1370250"
  },
  {
    "text": "an s3 bucket for you you can come back so essentially you have a dead letter Q built in you can adjust fire hose buffer",
    "start": "1370250",
    "end": "1377300"
  },
  {
    "text": "sizing so fire hose does the buffering and you can adjust and then finally you",
    "start": "1377300",
    "end": "1382850"
  },
  {
    "text": "can also deliver all of the source records to s3 so if you need to have a backup of that data as it's coming",
    "start": "1382850",
    "end": "1389300"
  },
  {
    "text": "through you can easily have fire hose send it off to s3 so fire is a great",
    "start": "1389300",
    "end": "1394640"
  },
  {
    "text": "option just in general for getting data into elasticsearch service",
    "start": "1394640",
    "end": "1400240"
  },
  {
    "text": "all right let's talk about sizing so I -",
    "start": "1400240",
    "end": "1406130"
  },
  {
    "text": "many many customers and I would say everybody struggles with scaling elasticsearch it's kind of one of the",
    "start": "1406130",
    "end": "1411680"
  },
  {
    "text": "fundamental challenges of it and when you come to the service you're often you're confronted with ok I need to",
    "start": "1411680",
    "end": "1417860"
  },
  {
    "text": "figure out my deployment and how many instances do I need how many shards do I need how do I get this thing deployed",
    "start": "1417860",
    "end": "1424010"
  },
  {
    "text": "right and my one piece of advice and it's simplistic but it's kind of true is",
    "start": "1424010",
    "end": "1430910"
  },
  {
    "text": "to pick use storage as your yardstick when you're trying to figure out how to",
    "start": "1430910",
    "end": "1436070"
  },
  {
    "text": "initially size your cluster after that you're gonna have to monitor and check and make sure and adjust but to get",
    "start": "1436070",
    "end": "1442460"
  },
  {
    "text": "started size is the thing to work on so if I",
    "start": "1442460",
    "end": "1448370"
  },
  {
    "text": "think about how many instances do I need and I think about that in the context of storage I have to know ok well given",
    "start": "1448370",
    "end": "1455270"
  },
  {
    "text": "some amount of data how much storage do I need right and it turns out that when",
    "start": "1455270",
    "end": "1460520"
  },
  {
    "text": "you send data into elasticsearch it inflates a little bit in the index but not a lot it's about 1.1 to 1 so for all",
    "start": "1460520",
    "end": "1469250"
  },
  {
    "text": "intents and purposes and because you're taking the first simple pass you can just say 1 to 1 if you're going to",
    "start": "1469250",
    "end": "1475460"
  },
  {
    "text": "deploy a replica remember the scene is storage so you need to double the storage you need and then you can size",
    "start": "1475460",
    "end": "1482660"
  },
  {
    "text": "your instance count based on how many how much storage you're putting per",
    "start": "1482660",
    "end": "1488750"
  },
  {
    "text": "instance and just divide so if I have a 2 terabyte corpus and I'm deploying",
    "start": "1488750",
    "end": "1495830"
  },
  {
    "text": "one-and-a-half terabytes of storage per node I need four notes because I have",
    "start": "1495830",
    "end": "1501830"
  },
  {
    "text": "two terabytes of corpus let's call that two terabytes of index I have a replica",
    "start": "1501830",
    "end": "1507290"
  },
  {
    "text": "so I have four terabytes of storage that I need and then I have one-and-a-half",
    "start": "1507290",
    "end": "1512900"
  },
  {
    "text": "terabytes of storage per instance so given overhead and squinting at it four times one point five terabytes six",
    "start": "1512900",
    "end": "1519620"
  },
  {
    "text": "terabytes sounds like a good size",
    "start": "1519620",
    "end": "1523360"
  },
  {
    "text": "come on thank you",
    "start": "1528710",
    "end": "1533820"
  },
  {
    "text": "similarly for shards so the best practice for shards is that each shard",
    "start": "1533820",
    "end": "1539460"
  },
  {
    "text": "should be no larger than 50 gigabytes right so you can divide your total index",
    "start": "1539460",
    "end": "1545550"
  },
  {
    "text": "size by about 40 gigabytes to have a first cut at how much how many shards",
    "start": "1545550",
    "end": "1551730"
  },
  {
    "text": "you need 40 40 gigabytes because you want to leave a little overhead right and if I have again a 2 terabyte corpus",
    "start": "1551730",
    "end": "1560850"
  },
  {
    "text": "I'll need 50 shards because I have two thousand gigabytes I want 40 gigabytes per shard I need 50 shards couple other",
    "start": "1560850",
    "end": "1569370"
  },
  {
    "text": "points you kind of want to keep your shards in line with your number of CPUs so we're going out of the storage realm",
    "start": "1569370",
    "end": "1575670"
  },
  {
    "text": "here but this is a first approximation you may have to adjust if you have too many shards you may have to add",
    "start": "1575670",
    "end": "1581940"
  },
  {
    "text": "instances and always use a replica at least one for any production work look because that replica again gives you",
    "start": "1581940",
    "end": "1588780"
  },
  {
    "text": "data redundancy you want to lose your data we support a number of different",
    "start": "1588780",
    "end": "1594870"
  },
  {
    "text": "instances in the service and it can be a little bit confusing which instance do I want to pick given my workload number",
    "start": "1594870",
    "end": "1601830"
  },
  {
    "text": "one we have the T 2's the T 2's are okay for Devon test and my slide is lying",
    "start": "1601830",
    "end": "1608430"
  },
  {
    "text": "there not okay for dead of dedicated masters the T 2's are fine instances but I wouldn't put them in a production",
    "start": "1608430",
    "end": "1614730"
  },
  {
    "text": "setting not with elasticsearch with the M class of instances we have equal read",
    "start": "1614730",
    "end": "1620700"
  },
  {
    "text": "and write capacities those are a good general-purpose place to start that's our default instance type is M for large",
    "start": "1620700",
    "end": "1627620"
  },
  {
    "text": "that's an excellent place to start with the our class instances we have additional RAM and you can get out to",
    "start": "1627620",
    "end": "1635490"
  },
  {
    "text": "really large Ram sizes now in fact elasticsearch is a java application and",
    "start": "1635490",
    "end": "1641760"
  },
  {
    "text": "a java application has a heap and probably no you don't ever want to run",
    "start": "1641760",
    "end": "1646800"
  },
  {
    "text": "the heap larger than 32 gigabytes so a B say to yourself well okay I have a 244 gigabyte r38 X large what's the point of",
    "start": "1646800",
    "end": "1654720"
  },
  {
    "text": "running elasticsearch on that instance well if we think back loose Lucy",
    "start": "1654720",
    "end": "1660650"
  },
  {
    "text": "is a storage based solution so it's M mapping all of the index data into",
    "start": "1660650",
    "end": "1666710"
  },
  {
    "text": "memory if I have two hundred and ten additional gigabytes what the operating",
    "start": "1666710",
    "end": "1672320"
  },
  {
    "text": "system will cache all of that data so the are instances really can give me a big speed boost because all of my",
    "start": "1672320",
    "end": "1678440"
  },
  {
    "text": "indexes get cached into RAM and essentially I'm running rampant so the r-class are good for heavier",
    "start": "1678440",
    "end": "1684680"
  },
  {
    "text": "workloads or we're clothes that require more RAM the C class we use that for a",
    "start": "1684680",
    "end": "1691580"
  },
  {
    "text": "high concurrency because the you know additional CPUs gives you the ability to handle more requests concurrently and",
    "start": "1691580",
    "end": "1698630"
  },
  {
    "text": "the AI class has the largest ephemeral storage for any instance so the AI class",
    "start": "1698630",
    "end": "1704030"
  },
  {
    "text": "is good if you have a very large use case and you need that additional storage that's a quick sidebar on",
    "start": "1704030",
    "end": "1710930"
  },
  {
    "text": "storage we support both EBS and instant storage ephemeral storage and the",
    "start": "1710930",
    "end": "1717290"
  },
  {
    "text": "question is you know what's the difference there is EBS the right storage choice we find in most",
    "start": "1717290",
    "end": "1723140"
  },
  {
    "text": "situations that EBS is perfectly acceptable especially for these real time logging kind of use cases",
    "start": "1723140",
    "end": "1729980"
  },
  {
    "text": "EBS works great for those use cases you do find it's via 10-15 percent slower",
    "start": "1729980",
    "end": "1735530"
  },
  {
    "text": "than ephemeral storage but again for this use case it is perfectly acceptable",
    "start": "1735530",
    "end": "1741880"
  },
  {
    "text": "and gets you bigger storage on smaller instances so as we said we started with",
    "start": "1741880",
    "end": "1749510"
  },
  {
    "text": "sizing but then we have to make some adjustments based on what is the workload this is this is a thesis is",
    "start": "1749510",
    "end": "1758840"
  },
  {
    "text": "worth of information and there's no way to cover it all but I'm going to try and point out a couple of things that will",
    "start": "1758840",
    "end": "1765110"
  },
  {
    "text": "help out as you test and monitor and try and figure out so we have two kind of",
    "start": "1765110",
    "end": "1770660"
  },
  {
    "text": "classes of use cases we have a write heavy class of use case this is the log analytics use case and we have a read",
    "start": "1770660",
    "end": "1776900"
  },
  {
    "text": "heavy use case which is just the full text search like my movies application and you want to scale those a little bit",
    "start": "1776900",
    "end": "1783170"
  },
  {
    "text": "differently so number one in both cases you have to pay attention to concurrency",
    "start": "1783170",
    "end": "1788570"
  },
  {
    "text": "as you're sending traffic through you're engaging those shards that means they have to run on a CPU",
    "start": "1788570",
    "end": "1794419"
  },
  {
    "text": "somewhere if I send a thousand requests in a second and I have two CPUs it's not going to be",
    "start": "1794419",
    "end": "1800960"
  },
  {
    "text": "successful I just don't have the capacity there so I have to make sure that I have enough CPUs to handle the",
    "start": "1800960",
    "end": "1807109"
  },
  {
    "text": "concurrent readers and writers that I want and then there's a setting on the",
    "start": "1807109",
    "end": "1812779"
  },
  {
    "text": "right side called index dot refresh interval this is a really great setting it's a good knob that gives you up to 75",
    "start": "1812779",
    "end": "1820429"
  },
  {
    "text": "or so percent more capacity what this controls is how often does elasticsearch",
    "start": "1820429",
    "end": "1826460"
  },
  {
    "text": "or leucine actually flush data to disk the data is not searchable until it's",
    "start": "1826460",
    "end": "1831769"
  },
  {
    "text": "flushed it accumulates in RAM and then it gets flushed to disk the default here",
    "start": "1831769",
    "end": "1836840"
  },
  {
    "text": "is 1:1 every second now that's fine if I increase that though I increase I",
    "start": "1836840",
    "end": "1842840"
  },
  {
    "text": "decrease the writes to disk and I decrease the amount of work that elasticsearch has to do with those",
    "start": "1842840",
    "end": "1848210"
  },
  {
    "text": "pieces of index right so in this case if I go to 30 seconds I get 50 to 75",
    "start": "1848210",
    "end": "1853730"
  },
  {
    "text": "percent more capacity in the same instances the downside is that puts a",
    "start": "1853730",
    "end": "1859759"
  },
  {
    "text": "delay of 30 seconds before I can actually read that data for right use",
    "start": "1859759",
    "end": "1866330"
  },
  {
    "text": "cases you increase you scale horizontally by adding primary shards",
    "start": "1866330",
    "end": "1871789"
  },
  {
    "text": "and instances to hold those shards okay so the more primary shards you have the more you're distributing your rights",
    "start": "1871789",
    "end": "1878299"
  },
  {
    "text": "across those instances for read use cases you want to increase your replicas",
    "start": "1878299",
    "end": "1883999"
  },
  {
    "text": "not your primaries you increase your replicas and add instances your replicas give you additional read capacity",
    "start": "1883999",
    "end": "1890379"
  },
  {
    "text": "monitor monitor monitor always monitor that's the only way to figure out how to",
    "start": "1890379",
    "end": "1896210"
  },
  {
    "text": "right-size your cluster there are a number of different things that we provide through cloud watch also",
    "start": "1896210",
    "end": "1901609"
  },
  {
    "text": "elasticsearch api's for monitoring are open so that you can read what's going on in the cluster down at the file",
    "start": "1901609",
    "end": "1908239"
  },
  {
    "text": "system at the operating system level CPUs all that stuff is open you have to look at that to figure out what's going",
    "start": "1908239",
    "end": "1914690"
  },
  {
    "text": "on when you look at how your shards are",
    "start": "1914690",
    "end": "1919710"
  },
  {
    "text": "distributed across your cluster there is a sort of sweet spot that looks like the number of shards per node is roughly",
    "start": "1919710",
    "end": "1925650"
  },
  {
    "text": "equivalent to the number of CPUs it's not precise but that seems to be where",
    "start": "1925650",
    "end": "1930840"
  },
  {
    "text": "the sweet spot is so if you think I have 50 shards and I'm gonna run on four CPUs",
    "start": "1930840",
    "end": "1936060"
  },
  {
    "text": "probably ten instances is what you want there sorry yes",
    "start": "1936060",
    "end": "1943380"
  },
  {
    "text": "and then beware because elasticsearch actually distributes the shards based on",
    "start": "1943380",
    "end": "1948630"
  },
  {
    "text": "shard count not shard sizing so you can get into situations where you have lots",
    "start": "1948630",
    "end": "1954030"
  },
  {
    "text": "of little shards and then a few big shards and then that causes log jams in your cluster okay let's talk a little",
    "start": "1954030",
    "end": "1963840"
  },
  {
    "text": "bit about security so we have two different options with an elastic search",
    "start": "1963840",
    "end": "1969090"
  },
  {
    "text": "service for where the endpoint sits so your endpoint can be a public access",
    "start": "1969090",
    "end": "1974160"
  },
  {
    "text": "endpoint that means it's a public DNS entry to a public endpoint where your",
    "start": "1974160",
    "end": "1979350"
  },
  {
    "text": "traffic goes if you choose that option then you're going to use iam policies to",
    "start": "1979350",
    "end": "1984450"
  },
  {
    "text": "secure your cluster the second option is it can be in your V PC so it will be a",
    "start": "1984450",
    "end": "1990120"
  },
  {
    "text": "private endpoint within your V PC again resolved through DNS but to a local address within your V PC in that case",
    "start": "1990120",
    "end": "1998010"
  },
  {
    "text": "you can use security groups and inbound and outbound rules to control access to the cluster so this is if you're in the",
    "start": "1998010",
    "end": "2008750"
  },
  {
    "text": "public access scenario you use I am to control access to that cluster so here's",
    "start": "2008750",
    "end": "2015800"
  },
  {
    "text": "a skeleton I am policy with a number of different pieces to it first is the",
    "start": "2015800",
    "end": "2021620"
  },
  {
    "text": "effect so you can allow things and you can deny things there is a principle which can be an AWS user account ID role",
    "start": "2021620",
    "end": "2031610"
  },
  {
    "text": "so this identifies a principle with an AWS if you specify a principle you have to use signe for signing to sign the",
    "start": "2031610",
    "end": "2038090"
  },
  {
    "text": "request that's how we do the authentication and access control there is an action the actions include the",
    "start": "2038090",
    "end": "2044870"
  },
  {
    "text": "HTTP verbs as well as the service commands so you can",
    "start": "2044870",
    "end": "2050480"
  },
  {
    "text": "if I and the HTTP verbs matter because elasticsearch implements arrest protocol",
    "start": "2050480",
    "end": "2055760"
  },
  {
    "text": "correctly so get is an actual read from the cluster delete you use to delete",
    "start": "2055760",
    "end": "2061128"
  },
  {
    "text": "indexes and like that so this gives you some granularity in terms of the elasticsearch API which commands you're",
    "start": "2061129",
    "end": "2068060"
  },
  {
    "text": "allowing or denying for a particular user as well the service actions you know you want to have administrators you",
    "start": "2068060",
    "end": "2074750"
  },
  {
    "text": "want to have various actors and you can you can who can do administrative or",
    "start": "2074750",
    "end": "2080300"
  },
  {
    "text": "other service level things the resource that you specify is your AR n for your",
    "start": "2080300",
    "end": "2086419"
  },
  {
    "text": "domain you can have full domain access control or you can have access control down to an index level so user Sally can",
    "start": "2086419",
    "end": "2094398"
  },
  {
    "text": "read from index my big logs index or what have you and then finally you can",
    "start": "2094399",
    "end": "2101359"
  },
  {
    "text": "specify an IP address or sitter block for the the policy this will restrict",
    "start": "2101359",
    "end": "2107420"
  },
  {
    "text": "access to a particular set of IP addresses so we now support",
    "start": "2107420",
    "end": "2114160"
  },
  {
    "text": "elasticsearch in VPN vbc and this is supported through en eyes within your",
    "start": "2114160",
    "end": "2121400"
  },
  {
    "text": "sorry elastic network interfaces within your VPC it the traffic itself is",
    "start": "2121400",
    "end": "2128440"
  },
  {
    "text": "private so it goes between your VPC and the elastic search cluster and does not",
    "start": "2128440",
    "end": "2134240"
  },
  {
    "text": "go to the public Internet at all you can use both I am policies and security",
    "start": "2134240",
    "end": "2140210"
  },
  {
    "text": "groups to secure this traffic between your application and the cluster itself",
    "start": "2140210",
    "end": "2146710"
  },
  {
    "text": "so just a quick architecture for how you might do that in this case we have some",
    "start": "2146710",
    "end": "2154810"
  },
  {
    "text": "producer nodes those are sending data via logstash to a load balanced a load balancer that",
    "start": "2154810",
    "end": "2162200"
  },
  {
    "text": "is an auto scale group of logstash instances that are taking that traffic and indexing it to elasticsearch via",
    "start": "2162200",
    "end": "2170330"
  },
  {
    "text": "those en eyes and then again we stand up a bastion host that lets me at SSH in or",
    "start": "2170330",
    "end": "2177320"
  },
  {
    "text": "tunnel in or in some other way proxies the cluster so that I can access it through Cubana",
    "start": "2177320",
    "end": "2184180"
  },
  {
    "text": "so we have our data in there we've got it in our V PC we have our security setup so how can we make this solution a",
    "start": "2185500",
    "end": "2193280"
  },
  {
    "text": "little bit more durable so number one we have a feature we called edit well",
    "start": "2193280",
    "end": "2200030"
  },
  {
    "text": "elasticsearch has a feature it's called dedicated masters so let me explain a little bit about this every cluster",
    "start": "2200030",
    "end": "2205700"
  },
  {
    "text": "every elasticsearch cluster has a master note that master node keeps track of the",
    "start": "2205700",
    "end": "2211670"
  },
  {
    "text": "cluster state and the cluster state includes things like what are the different instances where are the shards",
    "start": "2211670",
    "end": "2217190"
  },
  {
    "text": "what are the the schemas for each of the indexes and that master node is",
    "start": "2217190",
    "end": "2222230"
  },
  {
    "text": "responsible for distributing that information across the cluster you could kind of think like zookeeper note so if",
    "start": "2222230",
    "end": "2228079"
  },
  {
    "text": "I have a cluster with no dedicated masters one of those cluster instances will be elected as the master and its",
    "start": "2228079",
    "end": "2235700"
  },
  {
    "text": "job will be to do the master function and to do the data function like write data and respond to queries the problem",
    "start": "2235700",
    "end": "2242900"
  },
  {
    "text": "is if I have a lot of traffic my master node can become overloaded and when that happens my cluster goes away and that's",
    "start": "2242900",
    "end": "2250010"
  },
  {
    "text": "a bad thing right so putting the master function and the data function on the",
    "start": "2250010",
    "end": "2255529"
  },
  {
    "text": "same instance can is not the greatest idea certainly not for production so what you actually want to do is you want",
    "start": "2255529",
    "end": "2262069"
  },
  {
    "text": "to say okay let's get some master nodes and that's all they're gonna do they're just going to do the master function and we can do",
    "start": "2262069",
    "end": "2270230"
  },
  {
    "text": "that with the service then the master itself is elected from the dedicated",
    "start": "2270230",
    "end": "2275750"
  },
  {
    "text": "master instances and those nodes are just doing the master thing they're just",
    "start": "2275750",
    "end": "2281029"
  },
  {
    "text": "keeping track of State so number one they can be a lot smaller than the data nodes but they're very important for",
    "start": "2281029",
    "end": "2288500"
  },
  {
    "text": "stability now you want to have three dedicated master nodes why do you want",
    "start": "2288500",
    "end": "2295039"
  },
  {
    "text": "to have three so the master itself again is elected based on the majority of",
    "start": "2295039",
    "end": "2300760"
  },
  {
    "text": "voting notes if you have an even number and you have a network split and you",
    "start": "2300760",
    "end": "2306230"
  },
  {
    "text": "have say two in this one and two in that one each of them can decide oh I'm a cluster and then you have your data",
    "start": "2306230",
    "end": "2312200"
  },
  {
    "text": "going in two different places and everything falls apart it's bad so even this bad so you want to have an odd number of",
    "start": "2312200",
    "end": "2318920"
  },
  {
    "text": "masters and actually one is not really sufficient right so the first even if the first odd number bigger than 1 is 3",
    "start": "2318920",
    "end": "2325940"
  },
  {
    "text": "so 3 is the right number of dedicated masters sometimes for really big clusters you might want to have 5 but",
    "start": "2325940",
    "end": "2332990"
  },
  {
    "text": "generally speaking 3 is the right number your instance size as I said is going to",
    "start": "2332990",
    "end": "2338749"
  },
  {
    "text": "be smaller probably than your data notes right so here's our recommendations for",
    "start": "2338749",
    "end": "2344569"
  },
  {
    "text": "masternodes based on how many data nodes are in the cluster if you have fewer than 10 m3",
    "start": "2344569",
    "end": "2351200"
  },
  {
    "text": "medium if you have 50 to 100 c4 2x large and you can see it sort of scales up",
    "start": "2351200",
    "end": "2358329"
  },
  {
    "text": "always use the odd number of masters more than 3 and they can be smaller than data nodes so unawareness is another",
    "start": "2358329",
    "end": "2365539"
  },
  {
    "text": "durability feature and this will essentially take your cluster and split",
    "start": "2365539",
    "end": "2372289"
  },
  {
    "text": "it into two different availability zones right so in this case we evenly divide the instances and then we make sure that",
    "start": "2372289",
    "end": "2379099"
  },
  {
    "text": "primary and replica shards end up in different availability zones should a full zone go out you again retain 100%",
    "start": "2379099",
    "end": "2386960"
  },
  {
    "text": "of the data in the second one and elasticsearch can then recover from that",
    "start": "2386960",
    "end": "2392739"
  },
  {
    "text": "this we also recommend for all production workloads all right let's",
    "start": "2392739",
    "end": "2399769"
  },
  {
    "text": "talk about monitoring monitoring is really important number one we publish a number of cloud",
    "start": "2399769",
    "end": "2407299"
  },
  {
    "text": "watch alarms and these alarms are there for you to make sure that your cluster",
    "start": "2407299",
    "end": "2413299"
  },
  {
    "text": "is running ok so just to talk a little bit about some of them cluster status",
    "start": "2413299",
    "end": "2419390"
  },
  {
    "text": "red means that your cluster has gotten into a red state a red state occurs when",
    "start": "2419390",
    "end": "2424970"
  },
  {
    "text": "some data has been lost so that's an important one to understand and pick a",
    "start": "2424970",
    "end": "2431029"
  },
  {
    "text": "threshold of one if it ever happens you want to know that some data is gone also",
    "start": "2431029",
    "end": "2437259"
  },
  {
    "text": "when you fill your cluster too much then we start sending back a right block",
    "start": "2437259",
    "end": "2443349"
  },
  {
    "text": "error so if your cluster has become overly full or we can't deploy shard",
    "start": "2443349",
    "end": "2449930"
  },
  {
    "text": "somewhere you want to know that so one the threshold is one just one period you",
    "start": "2449930",
    "end": "2455280"
  },
  {
    "text": "want to go and look at that with the we also publish the CPU utilization metric",
    "start": "2455280",
    "end": "2460800"
  },
  {
    "text": "I find it's it's okay to run elasticsearch up to about 80% above 80%",
    "start": "2460800",
    "end": "2466320"
  },
  {
    "text": "you start to break down a little bit you don't have enough extra CPU for all of",
    "start": "2466320",
    "end": "2471359"
  },
  {
    "text": "the administrative tasks that have to happen so you want to keep the average CPU below 80% if it goes above for three",
    "start": "2471359",
    "end": "2478349"
  },
  {
    "text": "periods that's a time you want to alarm and say oh maybe I need to think about my scale here in the JVM memory pressure",
    "start": "2478349",
    "end": "2486500"
  },
  {
    "text": "the JVM memory pressure measures the essentially the effectiveness of garbage",
    "start": "2486500",
    "end": "2491580"
  },
  {
    "text": "collection so normally you'll see that number bounced between 50 and 75 percent",
    "start": "2491580",
    "end": "2497060"
  },
  {
    "text": "if it breaches 75 percent you're on the way to trouble so 80 percent is a",
    "start": "2497060",
    "end": "2503070"
  },
  {
    "text": "sensible line to set there and alarm on that and start thinking about remedies",
    "start": "2503070",
    "end": "2508650"
  },
  {
    "text": "in terms of adding more instances or larger instances free storage space pretty obvious if you run out of storage",
    "start": "2508650",
    "end": "2514260"
  },
  {
    "text": "space you're in trouble so but the recommendation here is that you take 25 percent of the available",
    "start": "2514260",
    "end": "2520770"
  },
  {
    "text": "space and if you drop below that it's time to start doing something and then finally we take automated snapshots if",
    "start": "2520770",
    "end": "2527369"
  },
  {
    "text": "one of those fails you probably want to know that in addition we've released a",
    "start": "2527369",
    "end": "2534390"
  },
  {
    "text": "feature where you can publish elastic searches slow logs to cloud watch logs",
    "start": "2534390",
    "end": "2540230"
  },
  {
    "text": "so what are the slow logs so slow logs are logs that contain requests the",
    "start": "2540230",
    "end": "2547470"
  },
  {
    "text": "elastic search cluster that take longer than a particular threshold as you can see here we have a number of different",
    "start": "2547470",
    "end": "2552930"
  },
  {
    "text": "thresholds that we can set we have the warn and info debug and trace and we can",
    "start": "2552930",
    "end": "2559560"
  },
  {
    "text": "set them at different millisecond values so I want to know if you know I want to",
    "start": "2559560",
    "end": "2564750"
  },
  {
    "text": "log all of the queries that ran for longer than a second I can enable this they go to cloud watch I can then look",
    "start": "2564750",
    "end": "2570869"
  },
  {
    "text": "at them in cloud watch send it back to elastic search what happy",
    "start": "2570869",
    "end": "2576049"
  },
  {
    "text": "and finally let's talk a little bit about how elasticsearch analyzes your",
    "start": "2577280",
    "end": "2582950"
  },
  {
    "text": "data so if you think back to sort of the construction of the index and how the",
    "start": "2582950",
    "end": "2590090"
  },
  {
    "text": "data comes in we have a number of fields within that data in this case let's say",
    "start": "2590090",
    "end": "2596000"
  },
  {
    "text": "we have a host field for our patchy web logs and I want to know for this particular host what are the verbs that",
    "start": "2596000",
    "end": "2603200"
  },
  {
    "text": "that host sent to me so how does elastic search process that so the first thing the lastic search goes and looks in the",
    "start": "2603200",
    "end": "2609860"
  },
  {
    "text": "host index now we're talking about actually indexing data not the global structure there's actually an index per",
    "start": "2609860",
    "end": "2616370"
  },
  {
    "text": "field elastic search looks up the host that I requested that points to a list",
    "start": "2616370",
    "end": "2623030"
  },
  {
    "text": "of all of the documents that contain that value for the host field so those",
    "start": "2623030",
    "end": "2628340"
  },
  {
    "text": "are all of the documents in this example that contain that that that host sent it",
    "start": "2628340",
    "end": "2633890"
  },
  {
    "text": "then looks up the data on the verb field for all of those requests and it",
    "start": "2633890",
    "end": "2639680"
  },
  {
    "text": "constructs buckets based on what's in the data it then computes a count in the",
    "start": "2639680",
    "end": "2645200"
  },
  {
    "text": "simplest case to generate a histogram of the requests from that particular host",
    "start": "2645200",
    "end": "2651580"
  },
  {
    "text": "that is the basis for how elastic search does all of the work that goes into the",
    "start": "2651580",
    "end": "2657590"
  },
  {
    "text": "Kabana visualizations every cabana visualization ends up as one of these kinds of queries so within elastic",
    "start": "2657590",
    "end": "2665810"
  },
  {
    "text": "search you know that's this is called an aggregation an aggregation again is a",
    "start": "2665810",
    "end": "2671240"
  },
  {
    "text": "collection of buckets and some metrics that I compute on those buckets so in this case I have a bucket for time",
    "start": "2671240",
    "end": "2677210"
  },
  {
    "text": "that's going on the x-axis and I have a metric of count and what that gives me",
    "start": "2677210",
    "end": "2682550"
  },
  {
    "text": "is is I bucket all of my data into 30-second slices and I count how many",
    "start": "2682550",
    "end": "2687800"
  },
  {
    "text": "things are in that bucket I get this graph which is requests over time but we",
    "start": "2687800",
    "end": "2695300"
  },
  {
    "text": "can do much more complicated things this particular example is for the Apache web logs of July 1995 and in this case what",
    "start": "2695300",
    "end": "2703910"
  },
  {
    "text": "we're seeing is the traffic that that was requested for STS 70",
    "start": "2703910",
    "end": "2708930"
  },
  {
    "text": "STS 71 for those of you who don't remember July of 1995 including me STS",
    "start": "2708930",
    "end": "2715470"
  },
  {
    "text": "70 was a space-shuttle as was 71 and it turns out that STS 71",
    "start": "2715470",
    "end": "2721470"
  },
  {
    "text": "flew and landed on the 6th and STS 70 launched on the 13th and why did 70",
    "start": "2721470",
    "end": "2728880"
  },
  {
    "text": "launched after 71 woodpeckers got into the fuel tanks honestly so you know this",
    "start": "2728880",
    "end": "2736589"
  },
  {
    "text": "is if i if i graph out my web logs for that time for your jelly of 95 i can see",
    "start": "2736589",
    "end": "2743250"
  },
  {
    "text": "the peak and interest for STS 71 happened in the beginning of the month and actually peaked on the 6th when it",
    "start": "2743250",
    "end": "2749309"
  },
  {
    "text": "landed and I can see the peak of interest that happened for STS 71 the 13th when it launched so I can I can",
    "start": "2749309",
    "end": "2756329"
  },
  {
    "text": "build complicated things like this with different buckets and different ways of slicing my data and viewing it within",
    "start": "2756329",
    "end": "2762990"
  },
  {
    "text": "Kabana so that's that's what I got",
    "start": "2762990",
    "end": "2768770"
  },
  {
    "text": "elasticsearch service allows you to run elastic search in the AWS cloud we take",
    "start": "2768770",
    "end": "2774030"
  },
  {
    "text": "care of all of the undifferentiated heavy lifting making it easy to deploy scale and jeff's secure monitor and",
    "start": "2774030",
    "end": "2780660"
  },
  {
    "text": "analyzing so send us some log data today thank you",
    "start": "2780660",
    "end": "2786310"
  },
  {
    "text": "[Applause] [Music]",
    "start": "2786310",
    "end": "2792099"
  }
]
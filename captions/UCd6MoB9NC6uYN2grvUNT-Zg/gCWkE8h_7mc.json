[
  {
    "text": "hi there do you work a lot with",
    "start": "1920",
    "end": "5120"
  },
  {
    "text": "streaming your time series events from",
    "start": "5120",
    "end": "7680"
  },
  {
    "text": "your Kafka",
    "start": "7680",
    "end": "9000"
  },
  {
    "text": "clusters and you really love using",
    "start": "9000",
    "end": "11840"
  },
  {
    "text": "Amazon time stream for live analytics",
    "start": "11840",
    "end": "14799"
  },
  {
    "text": "where you can ingest more than tens of",
    "start": "14799",
    "end": "17520"
  },
  {
    "text": "gigabytes of time series data per minute",
    "start": "17520",
    "end": "20320"
  },
  {
    "text": "and run SQL queries on terabytes of time",
    "start": "20320",
    "end": "23840"
  },
  {
    "text": "series data per second",
    "start": "23840",
    "end": "26400"
  },
  {
    "text": "well in this video I'm going to show you",
    "start": "26400",
    "end": "28720"
  },
  {
    "text": "the ways in which you can stream your",
    "start": "28720",
    "end": "31119"
  },
  {
    "text": "time series data from your Kafka",
    "start": "31119",
    "end": "33680"
  },
  {
    "text": "clusters to Amazon time stream tables",
    "start": "33680",
    "end": "36239"
  },
  {
    "text": "where you want to further",
    "start": "36239",
    "end": "38360"
  },
  {
    "text": "analyze my name is Kyle Vikandas Swami",
    "start": "38360",
    "end": "41200"
  },
  {
    "text": "i'm a principal solutions architect at",
    "start": "41200",
    "end": "43360"
  },
  {
    "text": "AWS and let's dive in",
    "start": "43360",
    "end": "47680"
  },
  {
    "text": "before we get into the demo let me show",
    "start": "47680",
    "end": "49840"
  },
  {
    "text": "you an end toend data journey that",
    "start": "49840",
    "end": "52840"
  },
  {
    "text": "includes starting from ingesting time",
    "start": "52840",
    "end": "55840"
  },
  {
    "text": "series data to storing them onto time",
    "start": "55840",
    "end": "58559"
  },
  {
    "text": "stream tables where it gets further",
    "start": "58559",
    "end": "60239"
  },
  {
    "text": "analyzed for consumption by people or by",
    "start": "60239",
    "end": "63359"
  },
  {
    "text": "other downstream applications or devices",
    "start": "63359",
    "end": "66799"
  },
  {
    "text": "the data flow starts with a number of",
    "start": "66799",
    "end": "68960"
  },
  {
    "text": "streaming sources that includes data",
    "start": "68960",
    "end": "71119"
  },
  {
    "text": "sources like sensors social media IoT",
    "start": "71119",
    "end": "74479"
  },
  {
    "text": "devices log files generated from your",
    "start": "74479",
    "end": "77040"
  },
  {
    "text": "web or mobile applications that gets",
    "start": "77040",
    "end": "80159"
  },
  {
    "text": "ingested through various AWS services",
    "start": "80159",
    "end": "82799"
  },
  {
    "text": "like Amazon MSK Kinesis and more now",
    "start": "82799",
    "end": "86880"
  },
  {
    "text": "that the data is ingested how do you get",
    "start": "86880",
    "end": "89520"
  },
  {
    "text": "your data to the targeted storage that",
    "start": "89520",
    "end": "91600"
  },
  {
    "text": "is Amazon timestream tables",
    "start": "91600",
    "end": "94400"
  },
  {
    "text": "there comes the integration layer and",
    "start": "94400",
    "end": "96880"
  },
  {
    "text": "there are multiple options available you",
    "start": "96880",
    "end": "99439"
  },
  {
    "text": "can leverage built-in integrations with",
    "start": "99439",
    "end": "101920"
  },
  {
    "text": "AWS IoT core for IoT sensor data or you",
    "start": "101920",
    "end": "106720"
  },
  {
    "text": "may author your lambda functions that",
    "start": "106720",
    "end": "108640"
  },
  {
    "text": "opens up multiple integrations possible",
    "start": "108640",
    "end": "111680"
  },
  {
    "text": "or you can leverage the built-in",
    "start": "111680",
    "end": "113840"
  },
  {
    "text": "connectors like time streams Kafka sync",
    "start": "113840",
    "end": "115840"
  },
  {
    "text": "connector or flink connector and more",
    "start": "115840",
    "end": "119280"
  },
  {
    "text": "now that we got the data stream to time",
    "start": "119280",
    "end": "121920"
  },
  {
    "text": "stream the next step is to analyze and",
    "start": "121920",
    "end": "124799"
  },
  {
    "text": "consume the data in the format that your",
    "start": "124799",
    "end": "127439"
  },
  {
    "text": "data consumers need there are many ways",
    "start": "127439",
    "end": "130959"
  },
  {
    "text": "and it depends on your use cases you can",
    "start": "130959",
    "end": "134319"
  },
  {
    "text": "visualize the data using Amazon",
    "start": "134319",
    "end": "136400"
  },
  {
    "text": "Quicksite and build dashboards or you",
    "start": "136400",
    "end": "139599"
  },
  {
    "text": "may want to export to S3 in their",
    "start": "139599",
    "end": "142480"
  },
  {
    "text": "original form and do further analysis",
    "start": "142480",
    "end": "146400"
  },
  {
    "text": "using these options you can stream your",
    "start": "146400",
    "end": "148879"
  },
  {
    "text": "time series data in and around time",
    "start": "148879",
    "end": "151360"
  },
  {
    "text": "stream",
    "start": "151360",
    "end": "152599"
  },
  {
    "text": "tables and let us zoom in on streaming",
    "start": "152599",
    "end": "155920"
  },
  {
    "text": "data from your Kafka clusters to time",
    "start": "155920",
    "end": "158640"
  },
  {
    "text": "stream for live analytics using Kuffka",
    "start": "158640",
    "end": "161680"
  },
  {
    "text": "connect",
    "start": "161680",
    "end": "164000"
  },
  {
    "text": "framework so when the time stream sync",
    "start": "164200",
    "end": "166720"
  },
  {
    "text": "connector is deployed in msk connect it",
    "start": "166720",
    "end": "169280"
  },
  {
    "text": "loads the target table schema",
    "start": "169280",
    "end": "171519"
  },
  {
    "text": "definitions from an S3 bucket the",
    "start": "171519",
    "end": "174160"
  },
  {
    "text": "connector uses this definition to",
    "start": "174160",
    "end": "175840"
  },
  {
    "text": "validate the incoming messages from the",
    "start": "175840",
    "end": "177840"
  },
  {
    "text": "Kuffka topic before inserting them as",
    "start": "177840",
    "end": "180879"
  },
  {
    "text": "records to the table it is of the same",
    "start": "180879",
    "end": "183760"
  },
  {
    "text": "format that we support in time stream",
    "start": "183760",
    "end": "185599"
  },
  {
    "text": "batch load feature and this is how it",
    "start": "185599",
    "end": "188640"
  },
  {
    "text": "looks like the schema definition for",
    "start": "188640",
    "end": "191920"
  },
  {
    "text": "mapping Kuffka messages to a record in",
    "start": "191920",
    "end": "195599"
  },
  {
    "text": "time stream table right at a high level",
    "start": "195599",
    "end": "197920"
  },
  {
    "text": "each record contains an array of",
    "start": "197920",
    "end": "200400"
  },
  {
    "text": "dimensions and measures in addition to",
    "start": "200400",
    "end": "203360"
  },
  {
    "text": "the time stamp of when it was collected",
    "start": "203360",
    "end": "206239"
  },
  {
    "text": "and the time stamp unit which represents",
    "start": "206239",
    "end": "209120"
  },
  {
    "text": "the uh granularity of the time stamp",
    "start": "209120",
    "end": "213200"
  },
  {
    "text": "dimensions represent the metadata",
    "start": "213200",
    "end": "215360"
  },
  {
    "text": "attributes of a time stream time series",
    "start": "215360",
    "end": "217920"
  },
  {
    "text": "data point such as user ID or product",
    "start": "217920",
    "end": "221400"
  },
  {
    "text": "code and measure represents the actual",
    "start": "221400",
    "end": "224560"
  },
  {
    "text": "value being measured such as quantity of",
    "start": "224560",
    "end": "227840"
  },
  {
    "text": "the purchased item IP address of the",
    "start": "227840",
    "end": "230400"
  },
  {
    "text": "user and",
    "start": "230400",
    "end": "233159"
  },
  {
    "text": "more and the connector is configured to",
    "start": "233159",
    "end": "236640"
  },
  {
    "text": "pull from a msk topic and write to a",
    "start": "236640",
    "end": "239840"
  },
  {
    "text": "timestream table so uh this is how it",
    "start": "239840",
    "end": "243360"
  },
  {
    "text": "goes the data flow starts with an EC2",
    "start": "243360",
    "end": "246480"
  },
  {
    "text": "instance a Kafka producer instant that",
    "start": "246480",
    "end": "249680"
  },
  {
    "text": "writes records to a Kafka topic as data",
    "start": "249680",
    "end": "253360"
  },
  {
    "text": "arrives the connector writes the data to",
    "start": "253360",
    "end": "257359"
  },
  {
    "text": "the time stream",
    "start": "257359",
    "end": "259799"
  },
  {
    "text": "table if you would like to follow along",
    "start": "259799",
    "end": "262560"
  },
  {
    "text": "as I demonstrate check out the article",
    "start": "262560",
    "end": "265120"
  },
  {
    "text": "shared here with that I'll show you how",
    "start": "265120",
    "end": "268400"
  },
  {
    "text": "you can use the connectors when you",
    "start": "268400",
    "end": "270560"
  },
  {
    "text": "navigate to the AWS blog real-time",
    "start": "270560",
    "end": "272720"
  },
  {
    "text": "serverless data injection you will find",
    "start": "272720",
    "end": "275199"
  },
  {
    "text": "a cloud formation template that you can",
    "start": "275199",
    "end": "278320"
  },
  {
    "text": "use to provision the resources using",
    "start": "278320",
    "end": "281199"
  },
  {
    "text": "cloud form",
    "start": "281199",
    "end": "282759"
  },
  {
    "text": "console and it has all the step-by-step",
    "start": "282759",
    "end": "286080"
  },
  {
    "text": "instructions starting from setting up",
    "start": "286080",
    "end": "288240"
  },
  {
    "text": "the producer instance to publishing the",
    "start": "288240",
    "end": "290160"
  },
  {
    "text": "messages using a JMeter script that we",
    "start": "290160",
    "end": "294080"
  },
  {
    "text": "have provided as part of this blog",
    "start": "294080",
    "end": "298080"
  },
  {
    "text": "we are in the AWS console let's go to",
    "start": "298080",
    "end": "300400"
  },
  {
    "text": "the Amazon timestream",
    "start": "300400",
    "end": "303400"
  },
  {
    "text": "console and the region here is Ohio US",
    "start": "303400",
    "end": "306960"
  },
  {
    "text": "East 2 and under management tools you",
    "start": "306960",
    "end": "310479"
  },
  {
    "text": "find query",
    "start": "310479",
    "end": "313320"
  },
  {
    "text": "editor and we have two tables in Kafka",
    "start": "313320",
    "end": "316720"
  },
  {
    "text": "stream",
    "start": "316720",
    "end": "317560"
  },
  {
    "text": "database so the first one is the click",
    "start": "317560",
    "end": "320320"
  },
  {
    "text": "stream table let's validate if it has",
    "start": "320320",
    "end": "322880"
  },
  {
    "text": "any",
    "start": "322880",
    "end": "323960"
  },
  {
    "text": "messages both are empty tables so you'll",
    "start": "323960",
    "end": "327440"
  },
  {
    "text": "find zero records in there and similar",
    "start": "327440",
    "end": "330320"
  },
  {
    "text": "is the case with purchase",
    "start": "330320",
    "end": "333320"
  },
  {
    "text": "history count star from Kafka",
    "start": "333320",
    "end": "337199"
  },
  {
    "text": "stream.purchase",
    "start": "337199",
    "end": "339720"
  },
  {
    "text": "history",
    "start": "339720",
    "end": "342680"
  },
  {
    "text": "yes now let me take you to",
    "start": "342680",
    "end": "346600"
  },
  {
    "text": "the",
    "start": "346600",
    "end": "348680"
  },
  {
    "text": "msk let's click on this msk console",
    "start": "348680",
    "end": "354039"
  },
  {
    "text": "we have a cluster up and",
    "start": "354639",
    "end": "357479"
  },
  {
    "text": "running when you click on",
    "start": "357479",
    "end": "361199"
  },
  {
    "text": "that you have the client information",
    "start": "361639",
    "end": "365199"
  },
  {
    "text": "under client information you find the",
    "start": "365199",
    "end": "367360"
  },
  {
    "text": "bootstrap server URLs and the port it is",
    "start": "367360",
    "end": "369759"
  },
  {
    "text": "listening",
    "start": "369759",
    "end": "371000"
  },
  {
    "text": "to and under msk connect you have worker",
    "start": "371000",
    "end": "375639"
  },
  {
    "text": "configuration the custom worker",
    "start": "375639",
    "end": "377520"
  },
  {
    "text": "configuration where we specify the",
    "start": "377520",
    "end": "379199"
  },
  {
    "text": "converters key and value converters",
    "start": "379199",
    "end": "383560"
  },
  {
    "text": "and we have custom",
    "start": "384319",
    "end": "387160"
  },
  {
    "text": "plugins so the custom plug-in references",
    "start": "387160",
    "end": "390479"
  },
  {
    "text": "to the jar file that is in S3",
    "start": "390479",
    "end": "394360"
  },
  {
    "text": "bucket and we have connectors",
    "start": "394360",
    "end": "398440"
  },
  {
    "text": "here purchase history connector is",
    "start": "398440",
    "end": "400880"
  },
  {
    "text": "already up and",
    "start": "400880",
    "end": "403759"
  },
  {
    "text": "running and let's check the",
    "start": "403800",
    "end": "408240"
  },
  {
    "text": "uh messages right so we have two topics",
    "start": "408240",
    "end": "410479"
  },
  {
    "text": "clickstream and purchase history and",
    "start": "410479",
    "end": "412319"
  },
  {
    "text": "they do not have any messages at this",
    "start": "412319",
    "end": "415800"
  },
  {
    "text": "moment now we'll create a",
    "start": "415800",
    "end": "420478"
  },
  {
    "text": "connector let's use the custom",
    "start": "421319",
    "end": "425160"
  },
  {
    "text": "plug-in click on next let's provide a",
    "start": "425160",
    "end": "428919"
  },
  {
    "text": "name",
    "start": "428919",
    "end": "431560"
  },
  {
    "text": "connector click",
    "start": "431560",
    "end": "434520"
  },
  {
    "text": "stream the description is optional",
    "start": "434520",
    "end": "438319"
  },
  {
    "text": "so we have option here we can choose msk",
    "start": "438319",
    "end": "440880"
  },
  {
    "text": "cluster or a self-managed Apache Kafka",
    "start": "440880",
    "end": "443280"
  },
  {
    "text": "cluster we have this msk cluster that's",
    "start": "443280",
    "end": "445759"
  },
  {
    "text": "going to be selected",
    "start": "445759",
    "end": "448440"
  },
  {
    "text": "now the connector",
    "start": "448440",
    "end": "450919"
  },
  {
    "text": "configuration I have the configuration",
    "start": "450919",
    "end": "453199"
  },
  {
    "text": "here let me",
    "start": "453199",
    "end": "455800"
  },
  {
    "text": "copy paste it here so we have the",
    "start": "455800",
    "end": "458880"
  },
  {
    "text": "connector class",
    "start": "458880",
    "end": "460599"
  },
  {
    "text": "specified the target database Kafka",
    "start": "460599",
    "end": "463759"
  },
  {
    "text": "stream the region the plugins",
    "start": "463759",
    "end": "467880"
  },
  {
    "text": "bucket the source",
    "start": "467880",
    "end": "470680"
  },
  {
    "text": "topic injection URL and the target table",
    "start": "470680",
    "end": "476120"
  },
  {
    "text": "name let's keep the rest",
    "start": "476120",
    "end": "479919"
  },
  {
    "text": "uh capacity and all default and select",
    "start": "479919",
    "end": "482960"
  },
  {
    "text": "the recommended Kafka connect version",
    "start": "482960",
    "end": "486080"
  },
  {
    "text": "and let's use the custom worker",
    "start": "486080",
    "end": "488199"
  },
  {
    "text": "configuration the one that we have",
    "start": "488199",
    "end": "490520"
  },
  {
    "text": "created and the access permission that",
    "start": "490520",
    "end": "493280"
  },
  {
    "text": "has access to both read from the topic",
    "start": "493280",
    "end": "496000"
  },
  {
    "text": "and write to the timestream table the",
    "start": "496000",
    "end": "497919"
  },
  {
    "text": "security we keep it default and we",
    "start": "497919",
    "end": "501199"
  },
  {
    "text": "deliver to the cloudatch logs in case we",
    "start": "501199",
    "end": "503440"
  },
  {
    "text": "want to",
    "start": "503440",
    "end": "505840"
  },
  {
    "text": "troubleshoot click on next",
    "start": "505960",
    "end": "510080"
  },
  {
    "text": "let's review the information",
    "start": "510080",
    "end": "513680"
  },
  {
    "text": "once connector",
    "start": "515080",
    "end": "518279"
  },
  {
    "text": "configuration access control logs yes",
    "start": "518279",
    "end": "521360"
  },
  {
    "text": "create the",
    "start": "521360",
    "end": "523760"
  },
  {
    "text": "connector the connector creation takes",
    "start": "525880",
    "end": "528560"
  },
  {
    "text": "some time so meanwhile what we do we",
    "start": "528560",
    "end": "532640"
  },
  {
    "text": "will use the connector that I have",
    "start": "532640",
    "end": "534880"
  },
  {
    "text": "already",
    "start": "534880",
    "end": "537360"
  },
  {
    "text": "provisioned which is the purchase",
    "start": "538040",
    "end": "540000"
  },
  {
    "text": "history",
    "start": "540000",
    "end": "541240"
  },
  {
    "text": "connector so if you see the informations",
    "start": "541240",
    "end": "544080"
  },
  {
    "text": "are uh you know similar except the",
    "start": "544080",
    "end": "546959"
  },
  {
    "text": "source topic and the target table name",
    "start": "546959",
    "end": "548880"
  },
  {
    "text": "that is purchase history",
    "start": "548880",
    "end": "552040"
  },
  {
    "text": "here the rest of the details are",
    "start": "552040",
    "end": "556399"
  },
  {
    "text": "similar now let's go to the uh producer",
    "start": "558120",
    "end": "561959"
  },
  {
    "text": "instance which is an EC2",
    "start": "561959",
    "end": "566000"
  },
  {
    "text": "instance that has all the configurations",
    "start": "567959",
    "end": "570640"
  },
  {
    "text": "including the JMTER",
    "start": "570640",
    "end": "573920"
  },
  {
    "text": "script let's connect to the instance",
    "start": "575399",
    "end": "577600"
  },
  {
    "text": "using session",
    "start": "577600",
    "end": "580319"
  },
  {
    "text": "manager so we are in the session manager",
    "start": "582920",
    "end": "585279"
  },
  {
    "text": "console",
    "start": "585279",
    "end": "587920"
  },
  {
    "text": "so do",
    "start": "587920",
    "end": "589399"
  },
  {
    "text": "u easy to user-",
    "start": "589399",
    "end": "594080"
  },
  {
    "text": "high so the script expects two",
    "start": "594279",
    "end": "597040"
  },
  {
    "text": "parameters the bootstrap server and the",
    "start": "597040",
    "end": "599279"
  },
  {
    "text": "topic the source",
    "start": "599279",
    "end": "602160"
  },
  {
    "text": "topic let's go to the script location",
    "start": "603720",
    "end": "606480"
  },
  {
    "text": "and execute it so the topic here is the",
    "start": "606480",
    "end": "610240"
  },
  {
    "text": "purchase history and the bootstrap",
    "start": "610240",
    "end": "611920"
  },
  {
    "text": "server information that we received from",
    "start": "611920",
    "end": "613760"
  },
  {
    "text": "the client information of the msk",
    "start": "613760",
    "end": "616000"
  },
  {
    "text": "cluster the script execution takes some",
    "start": "616000",
    "end": "617920"
  },
  {
    "text": "time meanwhile we will check if the",
    "start": "617920",
    "end": "620160"
  },
  {
    "text": "messages are flowing in the purchase",
    "start": "620160",
    "end": "622399"
  },
  {
    "text": "history topic has uh five messages so",
    "start": "622399",
    "end": "625120"
  },
  {
    "text": "far",
    "start": "625120",
    "end": "626920"
  },
  {
    "text": "published and we also check in the time",
    "start": "626920",
    "end": "629760"
  },
  {
    "text": "stream table how many records are coming",
    "start": "629760",
    "end": "632000"
  },
  {
    "text": "up in the purchase history",
    "start": "632000",
    "end": "634680"
  },
  {
    "text": "table so earlier it was zero now if you",
    "start": "634680",
    "end": "637839"
  },
  {
    "text": "see is 179 records have been ingested to",
    "start": "637839",
    "end": "641040"
  },
  {
    "text": "time stream",
    "start": "641040",
    "end": "642279"
  },
  {
    "text": "table we'll give some time is tidying up",
    "start": "642279",
    "end": "645440"
  },
  {
    "text": "we see",
    "start": "645440",
    "end": "646760"
  },
  {
    "text": "3702 messages",
    "start": "646760",
    "end": "649800"
  },
  {
    "text": "published we'll check the Kuffka topic",
    "start": "649800",
    "end": "652320"
  },
  {
    "text": "it is",
    "start": "652320",
    "end": "653560"
  },
  {
    "text": "3702 and all the records are valid so we",
    "start": "653560",
    "end": "657120"
  },
  {
    "text": "should be able to see them in the",
    "start": "657120",
    "end": "658959"
  },
  {
    "text": "purchase history table as",
    "start": "658959",
    "end": "662560"
  },
  {
    "text": "well yes we see the all the records are",
    "start": "662600",
    "end": "666720"
  },
  {
    "text": "uh",
    "start": "666720",
    "end": "667800"
  },
  {
    "text": "ingested now we'll look at the message",
    "start": "667800",
    "end": "670240"
  },
  {
    "text": "structure right the count is validated",
    "start": "670240",
    "end": "672720"
  },
  {
    "text": "if you look at the message structure you",
    "start": "672720",
    "end": "675040"
  },
  {
    "text": "see channel IP address session ID user",
    "start": "675040",
    "end": "678760"
  },
  {
    "text": "group and we'll validate if this",
    "start": "678760",
    "end": "681839"
  },
  {
    "text": "information is present in our purchase",
    "start": "681839",
    "end": "683680"
  },
  {
    "text": "history table as",
    "start": "683680",
    "end": "685480"
  },
  {
    "text": "well xar and",
    "start": "685480",
    "end": "688839"
  },
  {
    "text": "let's limit the response",
    "start": "688839",
    "end": "693040"
  },
  {
    "text": "here okay so here you see product user",
    "start": "695399",
    "end": "700120"
  },
  {
    "text": "ID time user group product ID okay all",
    "start": "700120",
    "end": "703279"
  },
  {
    "text": "the information that we have seen in the",
    "start": "703279",
    "end": "705519"
  },
  {
    "text": "Kuffka",
    "start": "705519",
    "end": "706600"
  },
  {
    "text": "messages this marks the end of the",
    "start": "706600",
    "end": "710519"
  },
  {
    "text": "demonstration i have shown you how you",
    "start": "710519",
    "end": "713040"
  },
  {
    "text": "can stream your time series events from",
    "start": "713040",
    "end": "715519"
  },
  {
    "text": "your Kuffka clusters to Amazon time",
    "start": "715519",
    "end": "717760"
  },
  {
    "text": "stream tables using the time stream sync",
    "start": "717760",
    "end": "720560"
  },
  {
    "text": "connector that we have opensourced i",
    "start": "720560",
    "end": "723360"
  },
  {
    "text": "hope you have enjoyed this video thanks",
    "start": "723360",
    "end": "725760"
  },
  {
    "text": "for watching and have fun experimenting",
    "start": "725760",
    "end": "727760"
  },
  {
    "text": "the solution provided bye",
    "start": "727760",
    "end": "732519"
  }
]
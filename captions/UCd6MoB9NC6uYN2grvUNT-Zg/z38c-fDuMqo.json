[
  {
    "start": "0",
    "end": "229000"
  },
  {
    "text": "everybody welcome thank you all so much for coming I cannot believe how many of you are actually in this room right now",
    "start": "30",
    "end": "5190"
  },
  {
    "text": "so my name is Brett Nash I'm a senior software engineer at Amazon game studios and I mostly run around the AWS",
    "start": "5190",
    "end": "11670"
  },
  {
    "text": "ecosystem all day so I work on back-end systems like crash reporting and building deployment and analytics and",
    "start": "11670",
    "end": "16730"
  },
  {
    "text": "today I'm here to talk to you about the system we built to ingest store and analyze gameplay data before we get",
    "start": "16730",
    "end": "22590"
  },
  {
    "text": "rolling I feel like I owe you a bit of an explanation so I um I knew I wanted to do this talk a few months ago and I",
    "start": "22590",
    "end": "28920"
  },
  {
    "text": "started and you know August I had to come up with the title so I could submit it and I didn't exactly know what the",
    "start": "28920",
    "end": "34829"
  },
  {
    "text": "talk was gonna be so I sort of came up with the longest most vague title I could come up with I would kind of cover every eventuality of what this talk",
    "start": "34829",
    "end": "41340"
  },
  {
    "text": "might turn into and as we've gotten closer and closer to reinvent I've gotten increasingly self-conscious about",
    "start": "41340",
    "end": "46559"
  },
  {
    "text": "it just in terms of the sheer length of it and I started having this moment where I I kind of went is this do I have",
    "start": "46559",
    "end": "53219"
  },
  {
    "text": "the longest session title at reinvent like probably not like let's not be crazy but you know it's like top 10",
    "start": "53219",
    "end": "58890"
  },
  {
    "text": "maybe you like top 25 probably right and so you know finally like a week or two ago the program and programmer and me",
    "start": "58890",
    "end": "66030"
  },
  {
    "text": "got the better of me so I sat down one night I popped up in a Python interpreter and I started writing a whole bunch of code to scrape the",
    "start": "66030",
    "end": "71850"
  },
  {
    "text": "reinvent session website for to get like all the session catalogs for all or titles for all the breakout sessions and you know normally like as a programmer",
    "start": "71850",
    "end": "78810"
  },
  {
    "text": "that moment when you find yourself like scraping data out of HTML that's usually my cue like I've steered off the road",
    "start": "78810",
    "end": "83880"
  },
  {
    "text": "somewhere like something that's gone horribly wrong but you know that's the fun thing about data right you don't control this horses sometimes you got to",
    "start": "83880",
    "end": "89220"
  },
  {
    "text": "go to where it is to get it so anyway I write the script I pull all the session titles I filter out the duplicates and I",
    "start": "89220",
    "end": "94920"
  },
  {
    "text": "rank them all from one to end by just sheer length in number of characters and I was actually pretty surprised about",
    "start": "94920",
    "end": "100500"
  },
  {
    "text": "the result maybe you guys aren't having gone to some talks now but some good news I don't have the longest session",
    "start": "100500",
    "end": "105600"
  },
  {
    "text": "title interestingly I'm not in the top ten I'm not in the top 25 I'm not even the top 100 so I've kind of gone to the",
    "start": "105600",
    "end": "112799"
  },
  {
    "text": "other side now almost like indignant about it like if I have the fortune of coming back next year like I'm swinging for the fences but the eye I think it's",
    "start": "112799",
    "end": "120600"
  },
  {
    "text": "funny it ended up mapping onto analytics in an interesting way which is that this is why we gather data right this is why",
    "start": "120600",
    "end": "125969"
  },
  {
    "text": "we run experiments because your gut tells you one thing but your guts often",
    "start": "125969",
    "end": "131069"
  },
  {
    "text": "wrong and the data tell us a completely different story and so I think this maps on the games really well to you know for a long time",
    "start": "131069",
    "end": "136470"
  },
  {
    "text": "in this industry we had cartridges we had disks we had consoles and houses with no connectivity but we're not there anymore right like everything people",
    "start": "136470",
    "end": "142650"
  },
  {
    "text": "play games on it's connected you know games as a service is the thing that's here to stay you know you don't have to",
    "start": "142650",
    "end": "148050"
  },
  {
    "text": "trust your gut anymore you can actually you know gather data and see what your players are really doing and so back to",
    "start": "148050",
    "end": "154680"
  },
  {
    "text": "my lung but apparently not abnormally long session title what I wanted to cover today was a brief overview of",
    "start": "154680",
    "end": "160830"
  },
  {
    "text": "stuff here so we're going to talk just briefly about analytics why they matter talk a little bit about this idea of",
    "start": "160830",
    "end": "166050"
  },
  {
    "text": "flexibility and why I think it's really important we're going to spend most of the time deep diving into the architecture and the backend on AWS and",
    "start": "166050",
    "end": "172590"
  },
  {
    "text": "we're going to talk about how they had to change over time as sort of requirements changed and evolved and hopefully I'll give you guys some",
    "start": "172590",
    "end": "178170"
  },
  {
    "text": "takeaways that will be useful to take home and use your day-to-day so let's jump in so to start you know you've all",
    "start": "178170",
    "end": "186960"
  },
  {
    "text": "self-selected into a talk about game analytics so I don't feel like I need to pitch you too much on why they matter",
    "start": "186960",
    "end": "192080"
  },
  {
    "text": "but so we're all on kind of a common understanding here you know the basic idea is you want to measure what your",
    "start": "192080",
    "end": "197790"
  },
  {
    "text": "players are doing in your game understand how that affects your player experience your game design your game balance and ultimately use that",
    "start": "197790",
    "end": "204660"
  },
  {
    "text": "information to improve your game and some reasons you might want to do that are to increase engagement you know keep",
    "start": "204660",
    "end": "210060"
  },
  {
    "text": "your players happy increase retention keep them coming back you know increase monetization and ultimately drive",
    "start": "210060",
    "end": "216060"
  },
  {
    "text": "revenue and the key here is we're being data-driven about it right we don't have to guess what our players are doing we",
    "start": "216060",
    "end": "221130"
  },
  {
    "text": "can know and you know I've done this a few times over now and the thing that I've found that works the best is you",
    "start": "221130",
    "end": "227310"
  },
  {
    "text": "sort of treat this like the scientific method and what I mean by that is you start with questions so you start with",
    "start": "227310",
    "end": "232980"
  },
  {
    "start": "229000",
    "end": "229000"
  },
  {
    "text": "you know what character do people choose the most what level or player is dying on the most you start with a question",
    "start": "232980",
    "end": "238050"
  },
  {
    "text": "form your hypothesis and then you instrument the data right then you figure out what you actually want to collect and you know you analyze it you",
    "start": "238050",
    "end": "244800"
  },
  {
    "text": "draw your conclusions and inevitably you're going to form more questions but I think the anti-pattern is the opposite right and what you see a lot of people",
    "start": "244800",
    "end": "251100"
  },
  {
    "text": "do is they start just instrumental like we need analytics now let's just instrument all the data let's just gather everything and that's fine but",
    "start": "251100",
    "end": "257790"
  },
  {
    "text": "what happens at the end of the day is you now end up with this big pile of data and then you start looking at it going like what questions can I ask",
    "start": "257790",
    "end": "264270"
  },
  {
    "text": "about this I can answer this one no let's ignore it sort of constrict what questions you can ask by what data you've collected and so",
    "start": "264270",
    "end": "270870"
  },
  {
    "text": "I would encourage you to do the opposite and start with the questions so I want to run through a brief example that is",
    "start": "270870",
    "end": "276030"
  },
  {
    "text": "going to kind of follow us through the presentation today so hopefully keep this in the back of your mind as we go I want to talk about level design so this",
    "start": "276030",
    "end": "282750"
  },
  {
    "start": "280000",
    "end": "280000"
  },
  {
    "text": "is an image of a level in a game I work on we don't really need to go into specifics but the basic idea is there's two teams before they start on another",
    "start": "282750",
    "end": "289680"
  },
  {
    "text": "side there's an objective that spawns in the middle we call the relic and the teams are trying to get that and deliver it to the enemy's base and you know when",
    "start": "289680",
    "end": "297750"
  },
  {
    "text": "we design these levels we want to encourage specific player behavior so you'll notice there's not a lot of protection around the outsides of the",
    "start": "297750",
    "end": "303630"
  },
  {
    "text": "level so there are these dangerous platforming paths that are sort of high-risk high-reward there's this wide-open area in the center where we're",
    "start": "303630",
    "end": "309900"
  },
  {
    "text": "attempting to funnel combat or the middle of the arena and so we want to validate those assumptions right and we",
    "start": "309900",
    "end": "315000"
  },
  {
    "text": "want to answer the question where a player is dying the most in this level where are the most player deaths occurring that's that's sort of the",
    "start": "315000",
    "end": "321090"
  },
  {
    "text": "thing that'll visualize this for us and so to do that we can create something called a heat map and I'm sure many many",
    "start": "321090",
    "end": "327300"
  },
  {
    "text": "of you who have seen heat maps before basic idea is you find where things are happening in your level you plot them geographically and you overlay it on to",
    "start": "327300",
    "end": "333630"
  },
  {
    "text": "a level image so we're gonna walk through really quickly what a heat map for this in player deaths might look like so to start you apologize profusely",
    "start": "333630",
    "end": "340680"
  },
  {
    "text": "to your art team because you're going to take a beautiful image like this and turn it into something like this so",
    "start": "340680",
    "end": "346320"
  },
  {
    "start": "345000",
    "end": "345000"
  },
  {
    "text": "we're going to take a top-down 2d screenshot of our level remove all the visual noise we don't care how pretty it",
    "start": "346320",
    "end": "351930"
  },
  {
    "text": "is just the shape and we're going to start with that as a baseline and then we're going to find a gradient so we're gonna say okay the places fewer player",
    "start": "351930",
    "end": "359340"
  },
  {
    "text": "deaths are happening are going to be cooler colors like black and red the place where more are happening or your warm colors like white and yellow so you",
    "start": "359340",
    "end": "365789"
  },
  {
    "text": "run your queries you've been up all your data and you spit out something like this so it looks pretty awesome it can",
    "start": "365789",
    "end": "372270"
  },
  {
    "text": "be a little difficult to interpret if you're not intimately familiar with the level so let's kind of look at them side-by-side so the first thing we said",
    "start": "372270",
    "end": "379590"
  },
  {
    "text": "is well there's all this high-risk platforming is that actually happening and I saw this graphic person got really worried I was like oh no my data is off",
    "start": "379590",
    "end": "385380"
  },
  {
    "text": "the side of the image everything's broken and it turns out no that's actually totally correct because that's all the people jumping off the map or",
    "start": "385380",
    "end": "391530"
  },
  {
    "text": "getting pushed off the map depending and so that's a good thing that validates the assumption and then we also",
    "start": "391530",
    "end": "397139"
  },
  {
    "text": "mentioned we're trying to funnel combat toward the middle and we have this nice warm red stripe right down the middle of the level that mean it's okay wants the",
    "start": "397139",
    "end": "403140"
  },
  {
    "text": "player death there that must be almost the combats happening cool that tracks as well but you can also pick out some",
    "start": "403140",
    "end": "408810"
  },
  {
    "text": "things you maybe didn't expect right so these areas apparently are really dangerous it's not people falling off",
    "start": "408810",
    "end": "413970"
  },
  {
    "text": "the edge it's just a lot of fighting happens to happen at the bottom of those stairways so that's interesting that might be worth looking into more and",
    "start": "413970",
    "end": "420380"
  },
  {
    "text": "then you can also look at the absence of data so I happen to know that in our game we spawn buffs at the top of these",
    "start": "420380",
    "end": "426840"
  },
  {
    "text": "ziggurats on the other side they increase player health increase player damage we'd expect people to be contending over those pretty heavily and",
    "start": "426840",
    "end": "432810"
  },
  {
    "text": "they're not it seems and so that's another thing we kind of want to look into and follow up maybe so what I want",
    "start": "432810",
    "end": "439530"
  },
  {
    "text": "to do is sort of just keep this example in the back your mind as we build out our architecture these heat maps are gonna be the thing we're gonna try to",
    "start": "439530",
    "end": "445050"
  },
  {
    "text": "get the end end everything we're miss drawing data into the game all the way through running it through the entire system to spit these back out cool so",
    "start": "445050",
    "end": "452520"
  },
  {
    "text": "that's the analytics part from there I want to give you a little bit of background and this is going to be brief",
    "start": "452520",
    "end": "459030"
  },
  {
    "start": "453000",
    "end": "453000"
  },
  {
    "text": "I promise you don't need like the full history of what's going on but the thing to consider is that I started working on analytics for games back in like 2015",
    "start": "459030",
    "end": "465060"
  },
  {
    "text": "and as we all know I mean like things have changed since I got to reinvent right like the pace of Technology in",
    "start": "465060",
    "end": "470520"
  },
  {
    "text": "division at AWS and in analytics is just off the charts like their shiny new toy is coming out every day and so keep that",
    "start": "470520",
    "end": "476760"
  },
  {
    "text": "in the back of your mind when I when I present bits of this you know we want to build in such a way we can take advantage of that stuff later so we had",
    "start": "476760",
    "end": "485190"
  },
  {
    "text": "a bunch of teams back in 2015 we were prototyping all kinds of games we're working on the which you now know is the",
    "start": "485190",
    "end": "490410"
  },
  {
    "text": "Amazon lumberyard game engine it was not announced back then and I was under shared services team right so I sort of",
    "start": "490410",
    "end": "496530"
  },
  {
    "text": "work on tech that all of our games need like analytics so I was running my own prototype and that's me and the lovely",
    "start": "496530",
    "end": "501630"
  },
  {
    "text": "red shirt off to the side and you know we were talking in the game designers and we said well hey wouldn't wouldn't",
    "start": "501630",
    "end": "506880"
  },
  {
    "text": "it be cool you guys are far enough along can can we help validate some of your design assumptions and that's where this",
    "start": "506880",
    "end": "512310"
  },
  {
    "text": "idea of why keep maps as our first major use case came from and you know the",
    "start": "512310",
    "end": "517500"
  },
  {
    "text": "first interesting thing here I think is that this was very early in development it's a lot of people think analytics they think all production right like",
    "start": "517500",
    "end": "523380"
  },
  {
    "text": "that's the last-minute thing like I needed to know my da you and my ma you and my ARPU and all these acronyms right to drive my business why would I why",
    "start": "523380",
    "end": "530280"
  },
  {
    "text": "would I do this in development it turns out especially from design standpoint you know validating level design character design whatever",
    "start": "530280",
    "end": "536230"
  },
  {
    "text": "and lytx can be really useful really early on in the process I'll also point out since this was a one-man effort for",
    "start": "536230",
    "end": "543699"
  },
  {
    "text": "at least six to eight months you'll notice I biased toward managed services right things with like minimal operational overhead if I got to keep",
    "start": "543699",
    "end": "549459"
  },
  {
    "text": "this whole thing standing up I wanted to be as easy to manage as possible and then finally I mean I I could have built",
    "start": "549459",
    "end": "555670"
  },
  {
    "text": "a system to do nothing but spit out heat maps but we all know that's not realistic right well knew they were eventually going to be other things",
    "start": "555670",
    "end": "561160"
  },
  {
    "text": "other things we wanted to do with analytics other games that came online like it made sense to design in some",
    "start": "561160",
    "end": "566649"
  },
  {
    "text": "level of flexibility since I knew it was gonna change later so that's the second major topic I want to sort of have be",
    "start": "566649",
    "end": "572620"
  },
  {
    "start": "571000",
    "end": "571000"
  },
  {
    "text": "the background for this today is that designing systems you know you know when they're gonna change so I'm doing this",
    "start": "572620",
    "end": "578709"
  },
  {
    "text": "thing my high school English teacher told me never to do which is take a dictionary definition and throw it up on the slide or start a paper with it but",
    "start": "578709",
    "end": "584800"
  },
  {
    "text": "here we are so the definition I found that I really liked was characterized by already capability to adapt to new different or",
    "start": "584800",
    "end": "590800"
  },
  {
    "text": "changing requirements and I assume for every developer in the room like especially that last bit about changing requirements that probably rings pretty",
    "start": "590800",
    "end": "597339"
  },
  {
    "text": "true and there's a lot of reasons I think this matters and thinking about this so first of all maybe you just",
    "start": "597339",
    "end": "604060"
  },
  {
    "text": "don't know what you're building up front like I knew we needed heat maps I didn't exactly know the rest of the stuff we needed it was a little ambiguous but you",
    "start": "604060",
    "end": "609819"
  },
  {
    "text": "know if you know all your requirements upfront how often have you worked on a project and start to end their requirements never changed like there's",
    "start": "609819",
    "end": "615639"
  },
  {
    "text": "a good chance stuff is going to shift over time and then furthermore when you factor in the the pace of innovation at",
    "start": "615639",
    "end": "620980"
  },
  {
    "text": "AWS and you know all the new analytics technology coming online like there's gonna be new stuff you want to take",
    "start": "620980",
    "end": "626199"
  },
  {
    "text": "advantage of and finally there's this thing I call the awesome prototype conundrum and it's in quotes because I",
    "start": "626199",
    "end": "631240"
  },
  {
    "text": "totally made it up but the basic idea is every good prototype I've built like I've built tons of junk to don't don't",
    "start": "631240",
    "end": "638050"
  },
  {
    "text": "worry about that but every good prototype I've built that's actually gotten people excited it ultimately",
    "start": "638050",
    "end": "643209"
  },
  {
    "text": "wormed its way into production like I always said I was going to redesign it I always said I was gonna rebuild it never happened always what wound up finding its way",
    "start": "643209",
    "end": "649899"
  },
  {
    "text": "into production and so if you can design this flexibility and up front when you build this stuff you can save yourself a",
    "start": "649899",
    "end": "655509"
  },
  {
    "text": "lot of headaches down the road cool so from there let's dive in a little bit to the actual architecture",
    "start": "655509",
    "end": "661660"
  },
  {
    "text": "which is going to be the meat of the presentation and what I want to emphasize is that what I'm going to show you today is one of many possible",
    "start": "661660",
    "end": "667899"
  },
  {
    "text": "architectures that like there's I I don't claim there's a panacea for analytics right there's not one solution to rule them all forged in",
    "start": "667899",
    "end": "674500"
  },
  {
    "text": "the fires of AWS there's this breadth of functionality available and the beauty of it is that you can take the pieces",
    "start": "674500",
    "end": "680920"
  },
  {
    "text": "that work for you and fit your requirements and fit them together you know this ability to flex the architecture to fit your needs I think",
    "start": "680920",
    "end": "686380"
  },
  {
    "text": "is a really fun thing so here's kind of the high-level flow we're going to cover and we're going to dig into each of",
    "start": "686380",
    "end": "692170"
  },
  {
    "text": "these sections so we're first gonna talk about how we produce this data what it looks like where it comes from how we",
    "start": "692170",
    "end": "697270"
  },
  {
    "text": "ingest it into our back-end how we store it and process it and ultimately how we analyze it to create stuff like heat maps so let's start with data production",
    "start": "697270",
    "end": "707790"
  },
  {
    "text": "so I made this comment up front and the session title I called it event based analytics and what what does that mean",
    "start": "707790",
    "end": "713830"
  },
  {
    "start": "708000",
    "end": "708000"
  },
  {
    "text": "so for me events are things that are unique and they happen at a point in time so it could be a thing like a",
    "start": "713830",
    "end": "719500"
  },
  {
    "text": "player collected an item a player died a player got to kill a player won a match they can also be non gameplay things to",
    "start": "719500",
    "end": "725740"
  },
  {
    "text": "write like a player started your game client the players game client crashed a player framerate measurement these are",
    "start": "725740",
    "end": "730930"
  },
  {
    "text": "all events as well and I think this should be self describing and what I mean by that is player death is kind of",
    "start": "730930",
    "end": "737260"
  },
  {
    "text": "useful but player death you know killed by player X on player Y in this level",
    "start": "737260",
    "end": "742390"
  },
  {
    "text": "during this game mode at this X Y position as you add metadata it becomes increasingly meaningful on its own and",
    "start": "742390",
    "end": "748510"
  },
  {
    "text": "that can be a really handy thing later when you're doing analysis and I also think it's fine for events to be",
    "start": "748510",
    "end": "753760"
  },
  {
    "text": "redundant so some people disagree on this but I think the basic idea is if",
    "start": "753760",
    "end": "758800"
  },
  {
    "text": "it's going to make you you have this trade-off to make right so you can either send more events up front you",
    "start": "758800",
    "end": "764290"
  },
  {
    "text": "know spend a little more in bandwidth spend a little more in storage and make your analysis easier at the end or you",
    "start": "764290",
    "end": "769300"
  },
  {
    "text": "can try to send the minimal amount upfront save those costs but have some more headaches when you go to analyze so for example one thing we do in our game",
    "start": "769300",
    "end": "775930"
  },
  {
    "text": "is we don't just send a player kill event we send a player kill event on behalf of the player who got the kill",
    "start": "775930",
    "end": "781480"
  },
  {
    "text": "and two player death event on behalf of the player who ended up getting killed and you know at the end of the day like",
    "start": "781480",
    "end": "787330"
  },
  {
    "text": "you could have figured out the second one from the first one but when I go to write the sequel or go to do the analysis later having both separate",
    "start": "787330",
    "end": "793630"
  },
  {
    "text": "events make certain types of queries much easier if you're doing kill death assist ratios or that sort of thing right and that brings us to sort of the",
    "start": "793630",
    "end": "801280"
  },
  {
    "text": "first major inflection point the architecture which is what data format are gonna use so yes I know like",
    "start": "801280",
    "end": "807100"
  },
  {
    "start": "802000",
    "end": "802000"
  },
  {
    "text": "we all look at this and go yes JSON whatever next slide like that's fine and 95% of the time you'd be right like",
    "start": "807100",
    "end": "812860"
  },
  {
    "text": "that's that's not a bad default to choose but so for me my background before I got into video games I worked",
    "start": "812860",
    "end": "818710"
  },
  {
    "text": "in spacecraft telemetry at the NASA Jet Propulsion lab so I spent a good five or six years sending and receiving stuff",
    "start": "818710",
    "end": "823900"
  },
  {
    "text": "from things running on Mars or orbiting Mars so I have a very solid appreciation for when a good binary pack data",
    "start": "823900",
    "end": "829420"
  },
  {
    "text": "structure is the right thing to use so I'm not saying that should be the case here but it's something to consider based on your environment and secondly",
    "start": "829420",
    "end": "836140"
  },
  {
    "text": "what about downstream support so one of the reasons we ended up going with JSON for this architecture was that a lot of",
    "start": "836140",
    "end": "843160"
  },
  {
    "text": "the AWS tools and services just provide native support for it there were going to be a bunch of things we would just get for free by virtue of choosing JSON",
    "start": "843160",
    "end": "849130"
  },
  {
    "text": "so you don't want to choose your data format in a bubble you want some of of consideration as to what you're going to",
    "start": "849130",
    "end": "854440"
  },
  {
    "text": "use to process it later and then finally this presentation is all about change so let's think about extensibility right",
    "start": "854440",
    "end": "859960"
  },
  {
    "text": "inevitably whatever you have at your data format for v1 it's not going to be that way forever you're gonna change it",
    "start": "859960",
    "end": "865420"
  },
  {
    "text": "eventually you're gonna add stuff your remove stuff you know some of these formats like the tree based ones like XML JSON they lend themselves a little",
    "start": "865420",
    "end": "871570"
  },
  {
    "text": "better to adding and removing stuff not breaking all of your existing parsing so things to consider so from there let's",
    "start": "871570",
    "end": "877810"
  },
  {
    "text": "jump into what actually a sample event we might send looks like so this is sort of a minimal event we might use to",
    "start": "877810",
    "end": "883030"
  },
  {
    "text": "generate that heat map that we showed earlier so I don't expect you to digest the whole thing let's let's walk through",
    "start": "883030",
    "end": "888430"
  },
  {
    "text": "it real quick so first we have an event section so there's an event version right version all our API is like if",
    "start": "888430",
    "end": "895180"
  },
  {
    "text": "this ever changes later this field was going to save our bacon secondly every event we send every single one has a",
    "start": "895180",
    "end": "900730"
  },
  {
    "text": "unique identifier for that event and that's going to become really handy later when we talk about deduplication there's gonna be an event timestamp I've",
    "start": "900730",
    "end": "907630"
  },
  {
    "text": "got it in UNIX epoch milliseconds but essentially the time at which the event happened and then what was the event the type of player death in this case",
    "start": "907630",
    "end": "913470"
  },
  {
    "text": "there's some high-level stuff you care about too you probably want to know what game it came from probably want to know what version of the game and have some",
    "start": "913470",
    "end": "920230"
  },
  {
    "text": "sort of identifier on behalf of the player who generated this event or caused it happen and then finally if",
    "start": "920230",
    "end": "925840"
  },
  {
    "text": "we're gonna do this heat map thing we probably need to know what level the event happened in and what the XY coordinate in that level was so that's",
    "start": "925840",
    "end": "933160"
  },
  {
    "text": "kind of the breakdown of what the events we might send look like then being at least this one ends up being about 300 bytes so not not too onerous",
    "start": "933160",
    "end": "941230"
  },
  {
    "text": "and we had at one point we got what I call metadata bloat I think we got up to like 50 or 55 attributes that might be a",
    "start": "941230",
    "end": "947800"
  },
  {
    "text": "little much scale it back but somewhere in between is totally fine - all right so let's talk about the high-level look",
    "start": "947800",
    "end": "953649"
  },
  {
    "text": "of this this is like the 10,000 foot view of what we're going to be doing so we've got our analytic system on the top we'll get there later we have I want to",
    "start": "953649",
    "end": "961120"
  },
  {
    "text": "use as an example a sort of a session based multi player game so a game that players get together play against each other join and then leave so for our",
    "start": "961120",
    "end": "967959"
  },
  {
    "text": "game clients we're going to have customers running games on their PCs all around the world and for our game",
    "start": "967959",
    "end": "973120"
  },
  {
    "text": "servers we're going to be running those in a service like Amazon game lyft if you're not familiar that's the service for deploying operating and scaling",
    "start": "973120",
    "end": "979770"
  },
  {
    "text": "multiplayer session based game servers in the AWS cloud so a lot of our prototypes used game lifts and what's",
    "start": "979770",
    "end": "985779"
  },
  {
    "text": "interesting when you look at clients for servers in the scenario they behave pretty differently and send pretty different stuff so let's talk about",
    "start": "985779",
    "end": "992770"
  },
  {
    "text": "servers first so if you're doing the multiplayer thing odds are that you're probably server authoritative or you're",
    "start": "992770",
    "end": "998890"
  },
  {
    "start": "993000",
    "end": "993000"
  },
  {
    "text": "trying to be to keep players from cheating as much as possible so most of your gameplay data is probably going to come from your server side and then",
    "start": "998890",
    "end": "1005040"
  },
  {
    "text": "things like simulation rate or CPU usage memory usage on the server that's obviously got to come from the server as well and servers are fun because we",
    "start": "1005040",
    "end": "1012540"
  },
  {
    "text": "consider them mostly trusted and what I mean by trusted is that they run in a restricted environment we mostly have",
    "start": "1012540",
    "end": "1018570"
  },
  {
    "text": "full control of it and we don't expect them to be intentionally malicious now let's be clear trusted is not the same",
    "start": "1018570",
    "end": "1025890"
  },
  {
    "text": "as will not do bad things these are separate concepts so if you're anything like us you will inevitably send",
    "start": "1025890",
    "end": "1031290"
  },
  {
    "text": "yourself data that is horribly malformed you will instrument an event and accidentally trigger it every simulation",
    "start": "1031290",
    "end": "1036540"
  },
  {
    "text": "frame and just flood your backends like these things are all still possibilities you need to consider but it's at least a",
    "start": "1036540",
    "end": "1041579"
  },
  {
    "text": "trusted environment that you can control and fix clients are a little bit different so first of all clients in our",
    "start": "1041579",
    "end": "1047370"
  },
  {
    "start": "1045000",
    "end": "1045000"
  },
  {
    "text": "case at least they probably send maybe 5% of the overall data most of it comes from the server but they send some",
    "start": "1047370",
    "end": "1052740"
  },
  {
    "text": "important stuff so they're the source of a lot of engagement data so you know when did people play how long did they play their source of performance data",
    "start": "1052740",
    "end": "1060059"
  },
  {
    "text": "you know what's your client frame rate you know our players having trouble rendering the game properly and any",
    "start": "1060059",
    "end": "1065160"
  },
  {
    "text": "local gameplay you have like if you have an offline tutorial mode that sort of thing that's probably all going to come from your client and clients I think as we all know I",
    "start": "1065160",
    "end": "1072149"
  },
  {
    "text": "probably don't need to tell this to a room full of people who build architectures but we don't trust clients clients will do bad things and that",
    "start": "1072149",
    "end": "1078210"
  },
  {
    "text": "falls into a couple categories so there are certainly clients who will reverse engineer your protocol pull your keys",
    "start": "1078210",
    "end": "1084720"
  },
  {
    "text": "out of memory and just try to send you junk absolutely happens those are the minority of people would you actually or",
    "start": "1084720",
    "end": "1090659"
  },
  {
    "text": "at least what we actually saw a lot more of is that you have people who are well-meaning players they love your game they want to play your game they just",
    "start": "1090659",
    "end": "1096869"
  },
  {
    "text": "set their system clock to two weeks ago for no apparent reason and so you'll get all this data that is from a good player",
    "start": "1096869",
    "end": "1102210"
  },
  {
    "text": "but it has some weird issues with it along the way and so what a lot of people will do is they'll put in a proxy",
    "start": "1102210",
    "end": "1107669"
  },
  {
    "text": "in between you know kind of rate limit and buffers stuff from clients before they let it into the backend so consider",
    "start": "1107669",
    "end": "1113759"
  },
  {
    "text": "what you want to do about that I'm not going to draw a proxy here just to keep the diagram somewhat clean but keep it in the back of your head and with that",
    "start": "1113759",
    "end": "1120539"
  },
  {
    "text": "good news we are one quarter of the way done building this thing we have our",
    "start": "1120539",
    "end": "1125580"
  },
  {
    "text": "clients our servers sending telemetry now we need to talk about how we're actually going to ingest it into our back-end so let's talk about Anna Justin",
    "start": "1125580",
    "end": "1133739"
  },
  {
    "text": "so there's really I think one major thing that's important when you're picking how you're going to ingest your data into your back-end and that is",
    "start": "1133739",
    "end": "1140279"
  },
  {
    "text": "making sure your clients and servers know as little about it as possible right decouple them from what's going on as much as possible and I know what",
    "start": "1140279",
    "end": "1147029"
  },
  {
    "text": "you're gonna say you're gonna have this moment because I totally have this moment where like well if my client sent",
    "start": "1147029",
    "end": "1152429"
  },
  {
    "text": "the data on this exact CSV format it would map directly onto my database columns my code to load it would be like",
    "start": "1152429",
    "end": "1158039"
  },
  {
    "text": "ten lines it would be amazing and it is amazing right up until it needs to change and then you have this strong",
    "start": "1158039",
    "end": "1163710"
  },
  {
    "text": "coupling between your front-end and your back-end or your producers and your consumers and then you're in trouble because teasing that out and making that",
    "start": "1163710",
    "end": "1169980"
  },
  {
    "text": "change is a lot harder you end up with concurrent deployments and all sorts of horrible things so for us the service",
    "start": "1169980",
    "end": "1175080"
  },
  {
    "text": "that made the most sense here was Amazon Kinesis streams so if you're not familiar at Canisius is a fully managed service for collecting and processing",
    "start": "1175080",
    "end": "1180919"
  },
  {
    "text": "word streams of data records in real time it's got some added benefits that I really like so it's got by default 24",
    "start": "1180919",
    "end": "1187259"
  },
  {
    "text": "hours of retention you can configure that up to a week so that's really handy for disaster recovery scenarios you know",
    "start": "1187259",
    "end": "1193139"
  },
  {
    "text": "having that that backup buffer of data it's also got this ecosystem of tools like the Kinesis producer library and",
    "start": "1193139",
    "end": "1198570"
  },
  {
    "text": "the Kinesis client library we'll get into those later they make it a pleasure to work with but really let's get let's get back to the",
    "start": "1198570",
    "end": "1205040"
  },
  {
    "text": "main point here which is that cleansing servers they don't care whose processing this data it could be some on-premise application you wrote it could be some",
    "start": "1205040",
    "end": "1212510"
  },
  {
    "text": "awesome giant Apache spark cluster running an Amazon Elastic MapReduce it could be some ridiculous service that",
    "start": "1212510",
    "end": "1218360"
  },
  {
    "text": "prints every event out on a piece of paper folds into a paper airplane and throws it out the window the point is they don't care they don't need to know",
    "start": "1218360",
    "end": "1224900"
  },
  {
    "text": "nothing that's going on the back end needs to be known to the clients and more importantly all three of those things could be happening because",
    "start": "1224900",
    "end": "1230540"
  },
  {
    "text": "Kinesis has this ability to take one event in and multiplex it out to multiple places and so that's talking",
    "start": "1230540",
    "end": "1236570"
  },
  {
    "text": "about you know how producers don't need to care about consumers it goes the other way too so those consumer pipelines they don't",
    "start": "1236570",
    "end": "1243830"
  },
  {
    "text": "need to know if all the events are coming from a single application on a single computer or the same application",
    "start": "1243830",
    "end": "1248900"
  },
  {
    "text": "on many computers or many different applications on a whole different set of computers like your game clients and game servers and some weird Python",
    "start": "1248900",
    "end": "1255140"
  },
  {
    "text": "scripts scraping a website somewhere does not matter as the more you can decouple these two sides of the equation",
    "start": "1255140",
    "end": "1261170"
  },
  {
    "text": "the better off you'll be because you'll be able to chop and change things later without impacting both sides at the same",
    "start": "1261170",
    "end": "1267050"
  },
  {
    "text": "time cool so we're back good news so I'd",
    "start": "1267050",
    "end": "1273440"
  },
  {
    "text": "be lying to you if I said this was the actual halfway point of the presentation Boas pretend like it is and we can get all peppy about it so from there we get",
    "start": "1273440",
    "end": "1280370"
  },
  {
    "text": "into the hard stuff so we started talking about how are we gonna store and process this data so when we talk data",
    "start": "1280370",
    "end": "1285380"
  },
  {
    "text": "storage it comes down to requirements like what you'll find probably because we did is that you don't actually have",
    "start": "1285380",
    "end": "1292520"
  },
  {
    "text": "the same requirements you don't even have one set of requirements you're gonna want to use your data and store your data in different ways and so for",
    "start": "1292520",
    "end": "1298190"
  },
  {
    "text": "us we kind of amid sense and you've probably seen this elsewhere to break data down by temperature and so what I mean by that is we're gonna start with",
    "start": "1298190",
    "end": "1304370"
  },
  {
    "text": "what I call cold data and the idea of cold data is we're gonna grab everything that comes into the system like every",
    "start": "1304370",
    "end": "1310250"
  },
  {
    "text": "single event we're just going to store it we're going to store it potentially on the order of years and the trade-off there is that we're cool if the access",
    "start": "1310250",
    "end": "1316580"
  },
  {
    "text": "times slow like of it once it's in there if it takes a little while to get it back out that's fine and the turnaround",
    "start": "1316580",
    "end": "1322070"
  },
  {
    "text": "time from the time it gets into the system till the time we get it back out don't really care as long as it gets there eventually we're good it can be semi structured so",
    "start": "1322070",
    "end": "1329390"
  },
  {
    "text": "if it wants to stay in its original JSON format that's fine and don't care if there are duplicates will talk more about duplicates later but for this",
    "start": "1329390",
    "end": "1335600"
  },
  {
    "text": "particular storage doesn't make a big difference and so for us the service that made the most sense",
    "start": "1335600",
    "end": "1340970"
  },
  {
    "text": "for this I'm sure you already guessed this already was Amazon s3 which is a simple storage service offers a highly",
    "start": "1340970",
    "end": "1347900"
  },
  {
    "text": "scalable reliable in milolii and C data storage what I really like about s3 is it has some extra features that are",
    "start": "1347900",
    "end": "1352940"
  },
  {
    "text": "really neat so it's got these life cycle rules where you can say hey if the data's been in s3 for this amount of",
    "start": "1352940",
    "end": "1357980"
  },
  {
    "text": "time let's expire it to some cheaper storage like infrequent access or Amazon glacier and you know in general like if you're",
    "start": "1357980",
    "end": "1364880"
  },
  {
    "text": "gonna put your data one place in AWS like s3 is a great place to do it because it just has all these",
    "start": "1364880",
    "end": "1369980"
  },
  {
    "text": "integrations with all these other systems right it's a gateway to Amazon machine learning now Amazon Elastic MapReduce and all these other services",
    "start": "1369980",
    "end": "1375280"
  },
  {
    "text": "so getting your data into it opens up a lot of possibilities for what you can do with it so let's go back to architecture",
    "start": "1375280",
    "end": "1382549"
  },
  {
    "start": "1382000",
    "end": "1382000"
  },
  {
    "text": "so this looks nice and simple so far so we essentially have our konista stream we're pulling events out this s3 app guy",
    "start": "1382549",
    "end": "1389570"
  },
  {
    "text": "is processing them and he's writing them in batches test three and we have our s3 application running on Adobe elastic",
    "start": "1389570",
    "end": "1396230"
  },
  {
    "text": "Beanstalk so if you're not familiar easy to use service for deploying and scaling apps and services eliminates a lot of",
    "start": "1396230",
    "end": "1401600"
  },
  {
    "text": "the operational overhead but still gives you kind of some low-level ability to tinker with stuff and for me I find",
    "start": "1401600",
    "end": "1407240"
  },
  {
    "text": "Beanstalk turns into my Swiss Army knife like whenever I needed some level of compute flexibility in my architecture",
    "start": "1407240",
    "end": "1412520"
  },
  {
    "text": "like Beanstalk often has the functionality I need and there's an extra layer to this which is that we're",
    "start": "1412520",
    "end": "1418400"
  },
  {
    "text": "not just running Beanstalk apps we're running Beanstalk apps using the Kinesis client library so I mentioned this thing",
    "start": "1418400",
    "end": "1424100"
  },
  {
    "text": "earlier it's a library that's out there for helping you process records from makinia stream it's got some really cool",
    "start": "1424100",
    "end": "1429230"
  },
  {
    "text": "features so the KCl if you have multiple instances of workers running it'll load bounce the reading of your stream across",
    "start": "1429230",
    "end": "1434690"
  },
  {
    "text": "all those which is nice one goes away the others will pick up the slack it also gives you the ability to checkpoint",
    "start": "1434690",
    "end": "1439760"
  },
  {
    "text": "so you can process a batch of data write a checkpoint and then if you crash or go away and come back you can pick up where",
    "start": "1439760",
    "end": "1445340"
  },
  {
    "text": "you left off with that checkpoint so that stuff ends up being really handy and data processing in this particular scenario cool so from there I wanted to",
    "start": "1445340",
    "end": "1452990"
  },
  {
    "text": "do kind of one more dive so we're gonna jump into that s3 app and see what that guy's actually doing so we're gonna play",
    "start": "1452990",
    "end": "1458000"
  },
  {
    "text": "a game of follow the flow chart real quick so this guy is pulling batches of events from this Kinesis stream and he's",
    "start": "1458000",
    "end": "1464630"
  },
  {
    "text": "gonna run him through a couple processes so first of all he's gonna validate the events and to me validation is about",
    "start": "1464630",
    "end": "1470929"
  },
  {
    "text": "protecting your back-end from your data producers so you're going to make sure all the required attributes are there",
    "start": "1470929",
    "end": "1475999"
  },
  {
    "text": "you're gonna make sure they're all well formatted and anything that's not you're going to drop it on the floor and in",
    "start": "1475999",
    "end": "1481279"
  },
  {
    "text": "reality we don't actually drop it on the floor but you don't want it to continue in the pipeline so in our particular case what we found useful was to take an",
    "start": "1481279",
    "end": "1487309"
  },
  {
    "text": "event that failed validation plus the reason why it failed and that's a key part and write those together to an s3",
    "start": "1487309",
    "end": "1493820"
  },
  {
    "text": "bucket we call it the arrow bucket you can think of it as a dead letter to you there's a bunch of different ways you could do this but ultimately we hold on",
    "start": "1493820",
    "end": "1499610"
  },
  {
    "text": "to it to come back and look later so from there once you validate you can optionally choose to do what I call",
    "start": "1499610",
    "end": "1504919"
  },
  {
    "text": "sanitization and the idea of sanitization is that well what if I had this event it has 20 fields right all",
    "start": "1504919",
    "end": "1512570"
  },
  {
    "text": "good stuff and one of those fields is bad maybe it's 10 characters too long maybe I came out to not a number should",
    "start": "1512570",
    "end": "1518960"
  },
  {
    "text": "I ditch that entire event just because that one field was bad right maybe if it's a string I should just truncate it",
    "start": "1518960",
    "end": "1524600"
  },
  {
    "text": "to the proper length if it's a double I should just zero it out you can sort of choose right because maybe those other",
    "start": "1524600",
    "end": "1529999"
  },
  {
    "text": "19 fields are still giving you a lot of useful information whereas if you drop the entire event you'd get none of it so",
    "start": "1529999",
    "end": "1535429"
  },
  {
    "text": "it's a consideration you can make you can be super strict about your validation or you can find some balance between the two and then finally you can",
    "start": "1535429",
    "end": "1541460"
  },
  {
    "text": "enrich the data and so what I mean by enriched is at any information you have now that you didn't have when the event",
    "start": "1541460",
    "end": "1547100"
  },
  {
    "text": "was generated so a really common example is to take a server-side timestamp and append it to your events and that way",
    "start": "1547100",
    "end": "1552830"
  },
  {
    "text": "you now have a nice reliable timestamp on the server-side to offset all those people with their clock set to two weeks ago and that could be a really handy",
    "start": "1552830",
    "end": "1559490"
  },
  {
    "text": "thing especially when you're sorting data and your data store and things like that cool so the last step then is we",
    "start": "1559490",
    "end": "1566629"
  },
  {
    "text": "all the events that pass these steps we sort of buffer them all up in this in memory buffer and we try to hit what I",
    "start": "1566629",
    "end": "1572809"
  },
  {
    "text": "would call a reasonable size and reasonable size is totally going to vary from project to project and architecture",
    "start": "1572809",
    "end": "1577909"
  },
  {
    "text": "to architecture for us knows 100 megabytes based on efficiency of storage costs efficiency of loading into data",
    "start": "1577909",
    "end": "1583190"
  },
  {
    "text": "stores down the road that was what we targeted and so we would sort of do this check every time every time we added",
    "start": "1583190",
    "end": "1589009"
  },
  {
    "text": "events we'd say hey is that buffer full have we hit that hundred megabyte threshold yet and if not we would say",
    "start": "1589009",
    "end": "1594619"
  },
  {
    "text": "how long has it been since we published anything we also did timeout right because early on like we had some pretty",
    "start": "1594619",
    "end": "1599659"
  },
  {
    "text": "low data volumes and development you know we weren't spamming the system with all kinds of stuff we have like 50 people",
    "start": "1599659",
    "end": "1604669"
  },
  {
    "text": "and all in the studio right and so you generally want a secondary condition that says if it's been a long time since I published stuff",
    "start": "1604669",
    "end": "1610279"
  },
  {
    "text": "I should probably publish it anyway and so if one of those two conditions is true we'll take all the data batch it up",
    "start": "1610279",
    "end": "1616070"
  },
  {
    "text": "into a single JSON file gzip it and push it up to s3 and that's the end of our called data processing so",
    "start": "1616070",
    "end": "1622100"
  },
  {
    "text": "that's how information gets into the system and in DES 3 all right so this is my cue to take a water break this is",
    "start": "1622100",
    "end": "1630499"
  },
  {
    "text": "Thor Grimm he's known as the giant slayer here's this hammer that can help him control the elemental forces of",
    "start": "1630499",
    "end": "1636230"
  },
  {
    "text": "winter he's also a programmer on the side say I want to guess what his favorite a double yes service might be",
    "start": "1636230",
    "end": "1642519"
  },
  {
    "text": "yes this joke is as bad as you think it's going to be yeah I hear Amazon",
    "start": "1642519",
    "end": "1647960"
  },
  {
    "text": "glacier that is an excellent answer I would have also accepted AWS snowball thank you sorry the groans from the",
    "start": "1647960",
    "end": "1653960"
  },
  {
    "text": "audience let me know you guys are still awake all right cool so unfortunately much the programs dissapointment cold",
    "start": "1653960",
    "end": "1660200"
  },
  {
    "text": "data is not the only data we care about turns out there's another category we care about too that I call warm data and",
    "start": "1660200",
    "end": "1665389"
  },
  {
    "text": "the idea of warm data is that newer is more relevant so we don't need everything forever about the last six",
    "start": "1665389",
    "end": "1671269"
  },
  {
    "text": "months is good but the trade-off is we want it faster so it needs to be fast to get into the system and the turnaround",
    "start": "1671269",
    "end": "1677929"
  },
  {
    "text": "time from when it gets into when we get it back out needs to be less than an hour and beyond that we want structured",
    "start": "1677929",
    "end": "1684379"
  },
  {
    "text": "data so no more of these JSON blobs we want strongly type stuff we can run queries against easily and furthermore",
    "start": "1684379",
    "end": "1690470"
  },
  {
    "text": "we want no duplicates so I keep punting on that we'll get to in a minute but filtering out duplicates is going to be a big part of this and for us the",
    "start": "1690470",
    "end": "1697549"
  },
  {
    "text": "service that made the most sense was Amazon redshift so if you're not familiar that's Amazon's petabyte scale data warehouse in the cloud also has the",
    "start": "1697549",
    "end": "1704149"
  },
  {
    "text": "nice feature of being fully sequel compatible so you know familiar to developers and analysts and all of the",
    "start": "1704149",
    "end": "1709700"
  },
  {
    "text": "tools that we know and love to use against databases so we're back to our architecture so we've got data flowing",
    "start": "1709700",
    "end": "1716450"
  },
  {
    "start": "1714000",
    "end": "1714000"
  },
  {
    "text": "index 3 and now we know we want to get it into redshift as well with some processing along the way and you know at",
    "start": "1716450",
    "end": "1722869"
  },
  {
    "text": "this point like all of your minds were probably racing if you say WS there's like 28,000 ways you could do this right there it all sort of depends on your",
    "start": "1722869",
    "end": "1728960"
  },
  {
    "text": "requirements and what makes sense for you so for us what actually made the most sense was every time we published",
    "start": "1728960",
    "end": "1734149"
  },
  {
    "text": "one of these files these batches test three we would take the pointer to that file the bucket name in the key name and we'd",
    "start": "1734149",
    "end": "1740360"
  },
  {
    "text": "pass it down to another Kinesis stream so we know we now have the secondary stream I'll call it the file stream so the first stream is events the second",
    "start": "1740360",
    "end": "1746840"
  },
  {
    "text": "stream is file pointers and from there stop me if you've heard this we have an elastic beanstalk app that's going to",
    "start": "1746840",
    "end": "1752900"
  },
  {
    "text": "read events from this stream it's going to buffer them up in memory and when it has what it deems enough it's going to",
    "start": "1752900",
    "end": "1760040"
  },
  {
    "text": "push it to redshift and the way we happen to do that redshift has this really cool command called copy if you've never used it before it can copy",
    "start": "1760040",
    "end": "1766370"
  },
  {
    "text": "data straight out of other Amazon sources such as s3 so we talked about s3 earlier or being really handy for",
    "start": "1766370",
    "end": "1771410"
  },
  {
    "text": "integrating with other stuff redshift is one of those things that integrates well with and so you can look at this you",
    "start": "1771410",
    "end": "1776600"
  },
  {
    "text": "could say well like why weren't using s3 bucket upload notifications right you could trigger a lambda function and do",
    "start": "1776600",
    "end": "1782330"
  },
  {
    "text": "stuff that way that's all totally valid for me what ended up being the big deal here right we go back to sort of the",
    "start": "1782330",
    "end": "1787340"
  },
  {
    "text": "one-man project thing at the time there's a nice amount of symmetry in this architecture so we have two Kinesis",
    "start": "1787340",
    "end": "1793340"
  },
  {
    "text": "streams two AWS lesbians all caps trading from them buffering stuff up in memory and publishing to a data sink and",
    "start": "1793340",
    "end": "1800120"
  },
  {
    "text": "that parallelism ended up meaning they got to share about 80 to 90% of their codebase they had the exact same",
    "start": "1800120",
    "end": "1805670"
  },
  {
    "text": "deployment process exact same build process right so it made sort of the commonality amongst all the tools and",
    "start": "1805670",
    "end": "1811640"
  },
  {
    "text": "all the development much easier for us so there's something to be said for sort of having self similarity in your",
    "start": "1811640",
    "end": "1817550"
  },
  {
    "text": "architecture okay so finally we're going to talk about that thing I keep punting on which is I want to talk about",
    "start": "1817550",
    "end": "1823400"
  },
  {
    "start": "1823000",
    "end": "1823000"
  },
  {
    "text": "duplicate records and so the idea of duplicates is that well first of all I",
    "start": "1823400",
    "end": "1830180"
  },
  {
    "text": "guess the way I think we all get why they matter but you know you don't want duplicate data in your system if you're making critical business decisions for",
    "start": "1830180",
    "end": "1836150"
  },
  {
    "text": "making critical game design decisions or if I log in and we send an event when I log in and you actually get ten of those",
    "start": "1836150",
    "end": "1841670"
  },
  {
    "text": "instead of one you can imagine that you know extrapolated across players how that's gonna skew your data pretty badly so I think we all agree duplicates are",
    "start": "1841670",
    "end": "1848630"
  },
  {
    "text": "bad thing and so you're probably thinking like okay why would you ever send duplicate stuff into the system I get it there's a few ways that can",
    "start": "1848630",
    "end": "1854960"
  },
  {
    "text": "happen so some of this is straight out of the enzyme Kinesis documentation so if you want to kind of read up more on",
    "start": "1854960",
    "end": "1861140"
  },
  {
    "text": "this I'll recommend you check that out but the first major source to duplicates is what I call producer retries and the",
    "start": "1861140",
    "end": "1866600"
  },
  {
    "text": "idea of a producer we try as we've got somebody like our game client he sends an event to the backend Kinesis gets it",
    "start": "1866600",
    "end": "1872210"
  },
  {
    "text": "sensing an acknowledgment and the acknowledgement gets lost and our game client goes oh that didn't get there",
    "start": "1872210",
    "end": "1877700"
  },
  {
    "text": "actually send another one and now we have two of that event in the system and so you know these tend to be pretty low",
    "start": "1877700",
    "end": "1883730"
  },
  {
    "text": "in volume in my experience but they're pretty regular like you know networks are flaky what can you do it happens periodically the more insidious version",
    "start": "1883730",
    "end": "1891410"
  },
  {
    "text": "of this is sort of the other end of the problem this what I call consumer retries so these are much more rare but potentially much more impactful and the",
    "start": "1891410",
    "end": "1898250"
  },
  {
    "text": "idea is that let's look at that s3 app so he's pulling these batches of events from s3 or sorry from Kinesis processing",
    "start": "1898250",
    "end": "1904760"
  },
  {
    "text": "them writing in them to s3 and then he's going to use the KCl to checkpoint and store his progress so what happens if he",
    "start": "1904760",
    "end": "1911120"
  },
  {
    "text": "pulls data processes uploads and dives before you checkpoints right what if he runs out of memory we have some horrible",
    "start": "1911120",
    "end": "1917120"
  },
  {
    "text": "crash whatever you can't checkpoint well he'll go down somebody will come up in this place and they'll pick up at the last checkpoint and they'll grab that",
    "start": "1917120",
    "end": "1923540"
  },
  {
    "text": "same Batchelor records they'll process that same batch records they'll reapplied that entire same batch of records so now that entire batch of",
    "start": "1923540",
    "end": "1930110"
  },
  {
    "text": "records we had initially we got an entire duplicate set so that's you could see there's probably a rare scenario but",
    "start": "1930110",
    "end": "1936290"
  },
  {
    "text": "definitely a lot more BIGBANG impactful when it happens and then the funnel bit is why I called the human factor and",
    "start": "1936290",
    "end": "1941860"
  },
  {
    "text": "this is maybe you got somebody poking around the database who has a little bit more privileges than they should and",
    "start": "1941860",
    "end": "1948050"
  },
  {
    "text": "accidentally deletes the table messes up some data maybe has a system outage for some period of time and data wasn't",
    "start": "1948050",
    "end": "1954440"
  },
  {
    "text": "flowing all the way through the system to the end there's a lot of scenarios we're being able to pump data back into the system becomes really important and",
    "start": "1954440",
    "end": "1960890"
  },
  {
    "text": "if you can make it so you can do that in an idempotent fashion where you can write the same event a hundred times to",
    "start": "1960890",
    "end": "1966320"
  },
  {
    "text": "redshift but only have one unique instance of it actually show up in the end datastore that becomes a really big",
    "start": "1966320",
    "end": "1971420"
  },
  {
    "text": "deal and it is say it saved me on a number of occasions it's been a really handy thing and so I think the",
    "start": "1971420",
    "end": "1976970"
  },
  {
    "text": "duplication is important enough that I want to kind of walk through like how the deduplication stuff works so this is",
    "start": "1976970",
    "end": "1982670"
  },
  {
    "start": "1979000",
    "end": "1979000"
  },
  {
    "text": "the redshift version of our follow the flow chart diagram from earlier so what we're gonna do is we're going to star in the upper left we've got this redshift",
    "start": "1982670",
    "end": "1989720"
  },
  {
    "text": "application he's reading these batches of pointers from the Kinesis stream and once he deems he's got enough to make it",
    "start": "1989720",
    "end": "1996260"
  },
  {
    "text": "as sufficient load into redshift he's going to write a manifest file so he's gonna take all the file pointers all the",
    "start": "1996260",
    "end": "2001540"
  },
  {
    "text": "files he wants to load and he's going to push those up in the single manifest and that's our cool thing so they're",
    "start": "2001540",
    "end": "2006940"
  },
  {
    "text": "redshift concept if you've never seen one before it looks something like this it's literally a set of s3u our eyes or",
    "start": "2006940",
    "end": "2012250"
  },
  {
    "text": "pointers combined with a mandatory flag that says whether or not this load should fail if that file is not there so",
    "start": "2012250",
    "end": "2018160"
  },
  {
    "text": "our case everything's mandatory all the time but manifests do some other cool stuff so they let you do stuff from",
    "start": "2018160",
    "end": "2024760"
  },
  {
    "text": "across s3 buckets so you can load from multiple buckets at once and they help you enforce strong consistency so that",
    "start": "2024760",
    "end": "2030460"
  },
  {
    "text": "can be a really handy thing as well if your systems moving really quickly I didn't mention up front but a lot of this sections going to sound like a",
    "start": "2030460",
    "end": "2036429"
  },
  {
    "text": "laundry list of the redshift best practices if you're ever going to work with redshift highly recommend you look up there best practices Docs it is a",
    "start": "2036429",
    "end": "2042669"
  },
  {
    "text": "super useful thing so from there we got this manifest file and s3 now we need",
    "start": "2042669",
    "end": "2048368"
  },
  {
    "text": "somewhere to put all this data so what we're going to do is we're going to create a temporary staging table and a redshift and for now we're not going",
    "start": "2048369",
    "end": "2054760"
  },
  {
    "text": "worry about duplicates we just want to get the data into redshift and then we'll deal with it so we're going to create this empty temporary staging",
    "start": "2054760",
    "end": "2059830"
  },
  {
    "text": "table looks a lot like our main event table and then we're gonna use that copy command that we mentioned previously to get all the data out of the redshift app",
    "start": "2059830",
    "end": "2066100"
  },
  {
    "text": "and into that table and if you're nursing the copy command before it looks",
    "start": "2066100",
    "end": "2071320"
  },
  {
    "text": "something like this we're not gonna walk through the entire thing but you essentially tell redshift a lot about your data so here's where to get the",
    "start": "2071320",
    "end": "2076780"
  },
  {
    "text": "manifest file it's gzipped I use epoch milliseconds you know use this I am roll to load it",
    "start": "2076780",
    "end": "2082148"
  },
  {
    "text": "so we have time limited credentials but there's one line in here I want to point out so this line might be the most important line on this entire diagram",
    "start": "2082149",
    "end": "2087970"
  },
  {
    "text": "and the reason I say that is it has to do with how we're loading the data so the first part tells read code for a",
    "start": "2087970",
    "end": "2093220"
  },
  {
    "text": "loading JSON not super exciting that's fine the second part is the important bit which is that we're using adjacent path file and so if you're not familiar",
    "start": "2093220",
    "end": "2099940"
  },
  {
    "text": "with how this works in redshift Jason path lets you map the fields from your input JSON on to database columns",
    "start": "2099940",
    "end": "2105790"
  },
  {
    "text": "but more importantly it lets you pick and choose the fields you care about you don't have to take all of them and more",
    "start": "2105790",
    "end": "2111580"
  },
  {
    "text": "importantly you can reorder them as well so your column order in your database doesn't have to match the order of attributes and your events and so what",
    "start": "2111580",
    "end": "2117880"
  },
  {
    "text": "we've essentially done is use this file to completely decoupler data storage format from a redshift schema and that",
    "start": "2117880",
    "end": "2124210"
  },
  {
    "text": "ends up being a big deal it's been a good 10 minutes since I hopped on flexibilities so let's bring it back to that again right any point you candy",
    "start": "2124210",
    "end": "2129400"
  },
  {
    "text": "couple things your life will get easier in the end so we've got all these events in this staging table now duplicates",
    "start": "2129400",
    "end": "2136000"
  },
  {
    "text": "warts-and-all and we want to get rid of those so we're going to the secondary staging table are called the dee doop table and the idea here is",
    "start": "2136000",
    "end": "2143080"
  },
  {
    "text": "that we're going to use a little sequel magic so we're going to take everything in that staging table and the left join it against our existing set of events in",
    "start": "2143080",
    "end": "2149890"
  },
  {
    "text": "this main event table and put only the new unique ones into this secondary staging table this dee doop table and",
    "start": "2149890",
    "end": "2155710"
  },
  {
    "text": "the way we do that looks something like this so this is paired down a bit but if we look at that inner select clause",
    "start": "2155710",
    "end": "2160720"
  },
  {
    "text": "there select query there's a couple things to point out so the first is we're doing a select distinct that's",
    "start": "2160720",
    "end": "2166150"
  },
  {
    "text": "important because a lot of times especially with producer retries duplicates end up really close to each other in memory and so you want to do we",
    "start": "2166150",
    "end": "2173710"
  },
  {
    "text": "do the distinct because if they're on that staging table together they're not going to be in the main table but there are still duplicates we got to get rid",
    "start": "2173710",
    "end": "2178840"
  },
  {
    "text": "of them the second bit is we're gonna do a left join and we're going to leverage that unique event ID we defined earlier",
    "start": "2178840",
    "end": "2184240"
  },
  {
    "text": "so we're gonna say hey all the event ideas that aren't already in the main table those are the ones that go into",
    "start": "2184240",
    "end": "2189310"
  },
  {
    "text": "the D dupe table if they're already there norm we don't need them and so as a result we end up with nice clean no",
    "start": "2189310",
    "end": "2194920"
  },
  {
    "text": "duplicate data in the ste doop table and we can sort of do a simple merge up from there dump it all into our main event",
    "start": "2194920",
    "end": "2200020"
  },
  {
    "text": "table and we're good and at the end we have one other nice thing which is we can just access our temp tables so this",
    "start": "2200020",
    "end": "2205869"
  },
  {
    "text": "is the beauty of temp tables right they're unique to your connection they're lightweight you make them you throw it into them you drop them when",
    "start": "2205869",
    "end": "2211840"
  },
  {
    "text": "you're done right no worrying about deleting and vacuuming and creating garbage and all that stuff right there",
    "start": "2211840",
    "end": "2217060"
  },
  {
    "text": "resources we don't need anymore hence the name temp get rid of it life's good all right water brick number",
    "start": "2217060",
    "end": "2223990"
  },
  {
    "text": "two for me you guys are already forming in your heads what a horrible joke I'm going to try to tell so this is Killian",
    "start": "2223990",
    "end": "2231730"
  },
  {
    "text": "he's the Grand Inquisitor he's into dark magic world domination quest for immortality that sort of thing anyone I",
    "start": "2231730",
    "end": "2238869"
  },
  {
    "text": "take a guess what his favorite day Tobias services something somebody was",
    "start": "2238869",
    "end": "2243910"
  },
  {
    "text": "shot out fire hose Alton yeah thank you I appreciate the groans alternately it's",
    "start": "2243910",
    "end": "2249340"
  },
  {
    "text": "actually a mess on light sale he's writing a wordpress blog don't judge me new poll floating book by its cover all right so we're back to our",
    "start": "2249340",
    "end": "2255730"
  },
  {
    "start": "2254000",
    "end": "2254000"
  },
  {
    "text": "architecture now so good news we're on the homestretch we got all our cool data and us three we got a worm did and redshift let's talk about how we're",
    "start": "2255730",
    "end": "2261880"
  },
  {
    "text": "actually gonna analyze it so for our team analysis looks something like this so we have this set of custom tools that",
    "start": "2261880",
    "end": "2268869"
  },
  {
    "start": "2265000",
    "end": "2265000"
  },
  {
    "text": "we built that stuff like our heat map generator and you know people could run those get out themselves self-service we have",
    "start": "2268869",
    "end": "2275830"
  },
  {
    "text": "a team of analysts who you know most of the complex queries and business stuff sort of funnels through them and they do",
    "start": "2275830",
    "end": "2281380"
  },
  {
    "text": "a lot of the heavy lifting against redshift that's not entirely true like we have developers and product managers",
    "start": "2281380",
    "end": "2287260"
  },
  {
    "text": "I put myself in this bucket that I would call sequel dangerous which is that if you point us at a table and give us equal access we'll eventually figure out",
    "start": "2287260",
    "end": "2293470"
  },
  {
    "text": "how to get what we need it's not gonna be the most efficient thing but you know there's something to be said for self-service and then finally we use",
    "start": "2293470",
    "end": "2299920"
  },
  {
    "text": "tableau a lot from naaw s marketplace and tableau has been really handy for having these persistent visualizations and workbooks that people can just go",
    "start": "2299920",
    "end": "2306400"
  },
  {
    "text": "check out at any point in time cool so now I want to bring it all back together so we started off with these heat maps",
    "start": "2306400",
    "end": "2312690"
  },
  {
    "text": "we hopefully at least agree that they're a useful thing this was about to the",
    "start": "2312690",
    "end": "2317770"
  },
  {
    "text": "point in the architecture where I finally had all the data and I had to generate one of these things I went oh no I have no idea how to do this like",
    "start": "2317770",
    "end": "2324010"
  },
  {
    "text": "there's got to be something to do this already right and and it turns out the data science community like many other",
    "start": "2324010",
    "end": "2329560"
  },
  {
    "text": "problems have mostly trivialized this problem for us so this is the majority of a Python script to generate that heat",
    "start": "2329560",
    "end": "2334960"
  },
  {
    "start": "2333000",
    "end": "2333000"
  },
  {
    "text": "map this is probably 80% of it I was pleasantly surprised it ended up being this short so let's kind of walk through",
    "start": "2334960",
    "end": "2341170"
  },
  {
    "text": "real quick what it's doing so first thing if you're pulling stuff out of a database you obviously need a database connection so I'm using this is Python 2",
    "start": "2341170",
    "end": "2348220"
  },
  {
    "text": "7 I'm using this library called a PG 8,000 which is a post cross-compatible library why I really like it is pure",
    "start": "2348220",
    "end": "2354820"
  },
  {
    "text": "Python which means it runs anywhere easy to lambda whatever no real issues there and ok let's all agree yes I heard coded",
    "start": "2354820",
    "end": "2362230"
  },
  {
    "text": "credentials on the slide we collectively agree that is a horrible idea and should only be done when you're trying to fit things on a PowerPoint slide we've",
    "start": "2362230",
    "end": "2368830"
  },
  {
    "text": "established it so what I would point out is that redshift has this really cool API I don't remember exactly when it",
    "start": "2368830",
    "end": "2374140"
  },
  {
    "text": "came online but it's called get clustered credentials and so you can use your i.m credentials to actually get it",
    "start": "2374140",
    "end": "2379150"
  },
  {
    "text": "to spit out a temporary time-limited database username and password so if you're actually going to build something like this I recommend looking into",
    "start": "2379150",
    "end": "2384940"
  },
  {
    "text": "something like that instead so database connection made next up we're going to actually pull that data",
    "start": "2384940",
    "end": "2390040"
  },
  {
    "text": "and aggregate it so we're gonna leverage one a redshift superpowers here which is being able to crunch large amounts of data aggregation and so if you look at",
    "start": "2390040",
    "end": "2397300"
  },
  {
    "text": "the where clause we're gonna say alright we're interested in this particular map and player death events and if you'll",
    "start": "2397300",
    "end": "2402760"
  },
  {
    "text": "get the Select what we're going to do is we're essentially going to take all the XY coordinates for them so the round numbers and count up how many deaths",
    "start": "2402760",
    "end": "2408789"
  },
  {
    "text": "happened there so what we're doing is we're cutting the entire sort of level under these one meter by one meter cells and bidding up how many player deaths",
    "start": "2408789",
    "end": "2415510"
  },
  {
    "text": "happened there from there this is the part I get to hand wave at so if if",
    "start": "2415510",
    "end": "2422530"
  },
  {
    "text": "you're pulling this data at a redshift right these XY coordinates are in world space in your level world space doesn't",
    "start": "2422530",
    "end": "2428770"
  },
  {
    "text": "map super easily on to image pixel space of the screenshot right so there's going to be sort of some hand wavy conversion",
    "start": "2428770",
    "end": "2434470"
  },
  {
    "text": "you have to do here if you guys are already doing this game development thing I'm gonna guess you have people on your team who are probably pretty good",
    "start": "2434470",
    "end": "2439510"
  },
  {
    "text": "at coordinate transformations so if you're like me you'll screw this up a number of times you'll get it upside down sideways backwards but you'll get",
    "start": "2439510",
    "end": "2445510"
  },
  {
    "text": "it eventually and then finally we get to this bit which I think is the magic part so I've been playing a lot Lilly with",
    "start": "2445510",
    "end": "2451000"
  },
  {
    "text": "the pandas data science library for Python which I love if you've never used it but these essentially two lions",
    "start": "2451000",
    "end": "2456970"
  },
  {
    "text": "generate that entire hex plot so we're going to create a data frame which is one a pen pen those native data",
    "start": "2456970",
    "end": "2462190"
  },
  {
    "text": "structures out of those combinations of x coordinate y coordinate death count and then we're gonna call this hex pin",
    "start": "2462190",
    "end": "2468760"
  },
  {
    "text": "function that is going to somewhat magically generate that entire overlay for us so we're going to make it semi-transparent we're going to tell it",
    "start": "2468760",
    "end": "2474849"
  },
  {
    "text": "how big we want the hex is to be and ultimately that's gonna generate that whole plot for us complete with the color gradient and then finally the last",
    "start": "2474849",
    "end": "2482319"
  },
  {
    "text": "little bit is we take our level screenshot we zero order zero to slip it behind that overlay and we save it to a",
    "start": "2482319",
    "end": "2488319"
  },
  {
    "text": "file or display to the screen and that's it and I can't tell you how pleasantly surprised I was that this ended up being how much code it took I'd also like to",
    "start": "2488319",
    "end": "2495099"
  },
  {
    "text": "point out that we have now officially walked through a slide of code so I think I've earned my 400 level talk so",
    "start": "2495099",
    "end": "2500349"
  },
  {
    "text": "yay for us all achievement unlocked and all that good stuff all right so good",
    "start": "2500349",
    "end": "2506349"
  },
  {
    "text": "news we have now officially finished our four stage architecture and if you're looking at your watch you're probably wondering why I'm done so soon and then",
    "start": "2506349",
    "end": "2513309"
  },
  {
    "text": "you're realizing unfortunately it is because I'm not so got called data we",
    "start": "2513309",
    "end": "2518529"
  },
  {
    "text": "got warm data got heat maps we're done what else could there possibly be and this was actually true for like three",
    "start": "2518529",
    "end": "2525430"
  },
  {
    "text": "months maybe maybe four months if I was lucky but inevitably things change requirements change the game change the",
    "start": "2525430",
    "end": "2531819"
  },
  {
    "text": "game pivoted right and so what ended up happening is we went from development mode into more production mode so we had",
    "start": "2531819",
    "end": "2538869"
  },
  {
    "text": "game servers up and running 24/7 we were running they test people were playing the game constantly we had more data volume and",
    "start": "2538869",
    "end": "2544000"
  },
  {
    "text": "what arose was the need for a third type of data and that was what I call a hot data and so the idea of hot data is most",
    "start": "2544000",
    "end": "2551830"
  },
  {
    "text": "recent is most relevant so we care about the last week and nothing else this is the kind of stuff that lives on operational dashboards and weekly",
    "start": "2551830",
    "end": "2557890"
  },
  {
    "text": "business reports that sort of thing so access to it we wanted to be superfast the turnaround time from when it gets",
    "start": "2557890",
    "end": "2563560"
  },
  {
    "text": "into the system till we can get it back out that's got to be five minutes or less and on top of that we still wanted",
    "start": "2563560",
    "end": "2568900"
  },
  {
    "text": "to be structured and we still want no duplicates and so for us the service that made the most sense to do this",
    "start": "2568900",
    "end": "2574210"
  },
  {
    "text": "ended up being elasticsearch service or Amazon elasticsearch service if not familiar Lassard service is service for",
    "start": "2574210",
    "end": "2579430"
  },
  {
    "text": "deploying operating and scaling elasticsearch clusters in the cloud if you're not familiar with elasticsearch that could feel like a whole other set",
    "start": "2579430",
    "end": "2585609"
  },
  {
    "text": "of presentations I'm sure it's a really neat thing it does cool stuff the time series data it's also got some really",
    "start": "2585609",
    "end": "2591040"
  },
  {
    "text": "handy built-in plugins so if anybody here is used Cabana before right you can pretty quickly throw together some",
    "start": "2591040",
    "end": "2596260"
  },
  {
    "text": "really neat operational dashboards just by virtue of getting data in there so I've made a lot of claims up to this",
    "start": "2596260",
    "end": "2602170"
  },
  {
    "start": "2602000",
    "end": "2602000"
  },
  {
    "text": "point about hey design flexibility in your architecture you can add new stuff later so this is kind of where the rubber hits the road so we had this",
    "start": "2602170",
    "end": "2609070"
  },
  {
    "text": "whole architecture built and we're using it for a few months and then we wanted to add elasticsearch to the equation and",
    "start": "2609070",
    "end": "2614310"
  },
  {
    "text": "so we kind of went back to the architecture and thought about where would fit in and it turns out it drops",
    "start": "2614310",
    "end": "2620349"
  },
  {
    "text": "right in pretty easily so we already had these apps that knew how to read from a stream process events bulk put them out",
    "start": "2620349",
    "end": "2626200"
  },
  {
    "text": "to some other data sink so we use that same framework that same source code base and developed an elasticsearch",
    "start": "2626200",
    "end": "2631660"
  },
  {
    "text": "version of it we hooked it directly up to the Kinesis stream so it could pull its own events not worry about s3 and red shift and I think the beautiful part",
    "start": "2631660",
    "end": "2638800"
  },
  {
    "text": "about this diagram to me is that those game plans and game servers they didn't know this happened right those cold data",
    "start": "2638800",
    "end": "2644080"
  },
  {
    "text": "and warm data pipelines they didn't know this happened right we were just able to drop this into the system and not have to tell or change anything else along",
    "start": "2644080",
    "end": "2650920"
  },
  {
    "text": "the way and you know I'll use elasticsearch is the example but we've used this to evaluate third-party tools",
    "start": "2650920",
    "end": "2656109"
  },
  {
    "text": "on the fly with production data we've used this to forward data and other teams who are interested in some of it",
    "start": "2656109",
    "end": "2661330"
  },
  {
    "text": "and to be clear you don't have to deal with every single event like that elasticsearch app he's fine to say like hey I don't care about combat in that",
    "start": "2661330",
    "end": "2667869"
  },
  {
    "text": "combat events I'm gonna drop all those right like what are you going to do with every sword swing in the game in real time probably nothing super exciting",
    "start": "2667869",
    "end": "2674560"
  },
  {
    "text": "so you know every pipeline doesn't have to process every event they'll receive it but they're free to selectively choose what they want to process cool so",
    "start": "2674560",
    "end": "2681970"
  },
  {
    "text": "that handles sort of adding new data consumers let's see if the same argument holds for data producers because",
    "start": "2681970",
    "end": "2687340"
  },
  {
    "text": "inevitably our game clients and game servers they weren't going to be the only source of data we cared about so before I worked on analytics architect",
    "start": "2687340",
    "end": "2694720"
  },
  {
    "start": "2694000",
    "end": "2694000"
  },
  {
    "text": "crash reporting so we have this whole back-end system built on AWS in a",
    "start": "2694720",
    "end": "2700300"
  },
  {
    "text": "separate account off doing its own thing and you know would accept crashes and dumps from players or do server-side stacktrace generation most importantly",
    "start": "2700300",
    "end": "2707410"
  },
  {
    "text": "we built it before we built the analytics system and so as we were building it this other developer and I",
    "start": "2707410",
    "end": "2713100"
  },
  {
    "text": "we sort of had this inkling right you get that tickling as you're building something where you know that like it'll",
    "start": "2713100",
    "end": "2718660"
  },
  {
    "text": "have a bigger purpose eventually or something else is going to care about it and so we came up with this idea we call extension points which is really fancy",
    "start": "2718660",
    "end": "2725350"
  },
  {
    "text": "way of saying we made that's a nice topic so if you're not familiar Amazon SMS is this managed service for letting",
    "start": "2725350",
    "end": "2730660"
  },
  {
    "text": "you do a highly scalable pub/sub operations and so what we did is we decided okay every time a crash happens",
    "start": "2730660",
    "end": "2736450"
  },
  {
    "text": "we're gonna take that crash and we're going to push it to this SMS topic and it was easy to implement low-cost thing",
    "start": "2736450",
    "end": "2743470"
  },
  {
    "text": "to do and at the time we did it there was nothing listening right I think I hooked up an email address for a while just to make sure it worked but like",
    "start": "2743470",
    "end": "2749410"
  },
  {
    "text": "there's nothing listening to that topic but eventually the time came when analytics came into the picture and we",
    "start": "2749410",
    "end": "2755890"
  },
  {
    "text": "had this moment where we have our entire analytics architecture and our entire crash reporting architecture and we",
    "start": "2755890",
    "end": "2760930"
  },
  {
    "text": "wanted to get those crash and crash details into the analytics system and by virtue of having designed both these",
    "start": "2760930",
    "end": "2766810"
  },
  {
    "text": "systems in such a way that we sort of had these extension points this flexibility baked in it ended up being",
    "start": "2766810",
    "end": "2771850"
  },
  {
    "text": "pretty trivial all right spend a couple hours wrote a lambda function it triggered off the SMS topic translated the data into the",
    "start": "2771850",
    "end": "2778240"
  },
  {
    "text": "analytics format and pushed it into the event stream and again the really nice thing was that those game clients game",
    "start": "2778240",
    "end": "2784660"
  },
  {
    "text": "servers they didn't know somebody else was publishing events all of the pipeline's processing that data they",
    "start": "2784660",
    "end": "2789970"
  },
  {
    "text": "didn't have to know either this was just able to drop in and start publishing data without really affecting anything else so that ended up being a really",
    "start": "2789970",
    "end": "2796150"
  },
  {
    "text": "cool thing and then finally I've made these sort of grant claims about you know all this new tech that was",
    "start": "2796150",
    "end": "2802090"
  },
  {
    "start": "2798000",
    "end": "2798000"
  },
  {
    "text": "available so this is by no means an exhaustive list but since I started building this these are some of the things that came online in aw",
    "start": "2802090",
    "end": "2808000"
  },
  {
    "text": "right there's Kinesis analytics for running sequel across your Kinesis streams there's rich of spectrum for",
    "start": "2808000",
    "end": "2813280"
  },
  {
    "text": "querying data across redshift and s3 there's quick site for doing business analytics in the cloud there's Athena for doing pay-as-you-go queries against",
    "start": "2813280",
    "end": "2819670"
  },
  {
    "text": "data and s3 there's a lot of cool stuff that happens in AWS and a lot of it happens after you start building and so",
    "start": "2819670",
    "end": "2825730"
  },
  {
    "text": "the question becomes okay we're back to our architecture we want to evaluate these new toys and play with them were we able to and it turns out",
    "start": "2825730",
    "end": "2833320"
  },
  {
    "text": "like everything else they sort of dropped right in and okay I you're forgiven for the reaction you're having",
    "start": "2833320",
    "end": "2838930"
  },
  {
    "text": "right now which is that you did nothing here like AWS did this and it just worked and you got lucky and that's that's mostly true like a lot of this is",
    "start": "2838930",
    "end": "2845859"
  },
  {
    "text": "credit AWS for integrating well but I think the important note here is that it matters where you put your data right we",
    "start": "2845859",
    "end": "2852730"
  },
  {
    "text": "didn't sequester our data off on a file system somewhere it's not in some service that only one process knows how to get to right we bought into the",
    "start": "2852730",
    "end": "2859240"
  },
  {
    "text": "ecosystem we use Canisius s3 redshift and by virtue of putting our data there into these these data stores that have",
    "start": "2859240",
    "end": "2865660"
  },
  {
    "text": "fan-out right can go to multiple places we're able to take advantage of these things as they came online so I think",
    "start": "2865660",
    "end": "2872440"
  },
  {
    "start": "2872000",
    "end": "2872000"
  },
  {
    "text": "the takeaway here is that when you do this right it almost looks like magic and the more systems you build this way",
    "start": "2872440",
    "end": "2878200"
  },
  {
    "text": "and design in this flexibility you get this sort of multiplicative value as they can start to interoperate with each other so I had this moment when I was",
    "start": "2878200",
    "end": "2887349"
  },
  {
    "text": "concluding this presentation as I was writing out what did did that just get lucky like was this all just a total",
    "start": "2887349",
    "end": "2892390"
  },
  {
    "text": "coincidence and like you know the last 15 minutes has been a farce and I don't think that's true I think there are some",
    "start": "2892390",
    "end": "2898210"
  },
  {
    "text": "very subtle things here that happened that made this possible so let's talk peer functionality so from a pure",
    "start": "2898210",
    "end": "2904780"
  },
  {
    "text": "functionality standpoint those Kinesis streams they don't need to be there right like those clients and servers they could publish straight to that s3",
    "start": "2904780",
    "end": "2911200"
  },
  {
    "text": "app will get throw a load balancer in front of it scale it out that would work that has 3 app you could publish",
    "start": "2911200",
    "end": "2916330"
  },
  {
    "text": "straight to the redshift app right another one bounce or scale it out that would work too so from a pure functional",
    "start": "2916330",
    "end": "2921880"
  },
  {
    "text": "standpoint those aren't necessary and yeah they add a little bit of overhead but ultimately you it more than pays",
    "start": "2921880",
    "end": "2927760"
  },
  {
    "text": "itself back in terms of a the durability and disaster recovery but be this decoupling all right this ability to add",
    "start": "2927760",
    "end": "2933339"
  },
  {
    "text": "new producers and consumers on the fly without changing things and then secondarily you know I harp on that a",
    "start": "2933339",
    "end": "2939040"
  },
  {
    "text": "second ago we'll say it again putting your data into data stores with fan-out is a big deal right being able to write data",
    "start": "2939040",
    "end": "2945340"
  },
  {
    "text": "somewhere that multiple things can pull that data back out ideally concurrently without affecting operations so if I had to distill this",
    "start": "2945340",
    "end": "2951850"
  },
  {
    "text": "down to a set of bullet points it would look something like this basically as you design these systems at least in my",
    "start": "2951850",
    "end": "2958450"
  },
  {
    "text": "experience just assume it's going to change right you will spend a little extra effort upfront you will have a couple more moving parts but in my",
    "start": "2958450",
    "end": "2965650"
  },
  {
    "text": "experience it has paid massive dividends down the road when I've thought about it to begin with secondly abstracting decouple wherever",
    "start": "2965650",
    "end": "2972190"
  },
  {
    "text": "possible think really hard about if this service is over here and is actually no this one exists do they need that direct",
    "start": "2972190",
    "end": "2978760"
  },
  {
    "text": "dependency or can you have some pub/sub in between like SMS can you do couple with Kinesis can you throw an api",
    "start": "2978760",
    "end": "2983980"
  },
  {
    "text": "gateway in the middle and abstract the two from each other all right think really hard about what direct dependencies you need to have and then I",
    "start": "2983980",
    "end": "2990720"
  },
  {
    "text": "won't go into a deeply into third time but biased toward fan-out put your data where other things can get it don't put it down to dead end somewhere right",
    "start": "2990720",
    "end": "2997420"
  },
  {
    "text": "always be thinking that they're going to be multiple things that want to get that data back out and then finally you have",
    "start": "2997420",
    "end": "3002670"
  },
  {
    "text": "fun like run experiments I don't mean experiments in a/b testing sense I mean experiments in terms of spin up new",
    "start": "3002670",
    "end": "3008250"
  },
  {
    "text": "stacks play with the new toys right rot them off your production stream or your dev stream you know you can this the",
    "start": "3008250",
    "end": "3013410"
  },
  {
    "text": "beauty of the cloud is you can have this agility to spin things up try them out if they don't work tear them back down right or if they do work great scale it",
    "start": "3013410",
    "end": "3020550"
  },
  {
    "text": "out and use it you know this sort of gives you the ability when you do it right to kind of play with all the new toys --is that come along so last bit",
    "start": "3020550",
    "end": "3028830"
  },
  {
    "text": "before I conclude I'm going to throw a link farm at you guys so bear with me for one second so I set up work for",
    "start": "3028830",
    "end": "3033900"
  },
  {
    "text": "Amazon Game Studios I don't wanna advertise too much but if you're interested in what we do what we're about follow that top link dado because",
    "start": "3033900",
    "end": "3040740"
  },
  {
    "text": "for gaming if you're going to be building gaming systems on AWS servers analytics whatever there's a lot of great resources on that page and then",
    "start": "3040740",
    "end": "3047370"
  },
  {
    "text": "the bottom two I really want to take a minute to tell you about so a lot of people on the various AWS teams have",
    "start": "3047370",
    "end": "3052830"
  },
  {
    "text": "worked really hard with me the past couple months and we're able to take this solution that we've presented today and put it up on this game analytics",
    "start": "3052830",
    "end": "3059790"
  },
  {
    "text": "pipeline solution page so there's an implementation guide you can go check out there's a CloudFormation template you can one click to play at your AWS",
    "start": "3059790",
    "end": "3066240"
  },
  {
    "text": "account and check it out and as a companion to that all the source codes up on github so that's the heat map generator a data generator and all the",
    "start": "3066240",
    "end": "3073260"
  },
  {
    "text": "backend code to sort of deal with this stuff so if you guys are interested in more feel free to catch me afterward I'm happy to follow up but hopefully that at",
    "start": "3073260",
    "end": "3079860"
  },
  {
    "text": "least gives you something to go play with right after this talk and with that I think that's all I had so thank you all so much for coming I'll go back to",
    "start": "3079860",
    "end": "3085770"
  },
  {
    "text": "the links in the sack",
    "start": "3085770",
    "end": "3088370"
  }
]
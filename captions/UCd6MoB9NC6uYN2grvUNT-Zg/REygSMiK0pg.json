[
  {
    "start": "0",
    "end": "36000"
  },
  {
    "text": "welcome everybody welcome to ark 404 metering the hybrid cloud my name is Dan",
    "start": "60",
    "end": "7170"
  },
  {
    "text": "Garrity and I'm here with my colleague Jack Chen we're from the AWS commerce platform tell you a little bit more",
    "start": "7170",
    "end": "14309"
  },
  {
    "text": "about that in a second we're going to talk to you about ways that you can use AWS tools and some of your own grit and",
    "start": "14309",
    "end": "25080"
  },
  {
    "text": "muscle to build build out systems that can help you meter from your on-prem and",
    "start": "25080",
    "end": "30689"
  },
  {
    "text": "other cloud providers into AWS I'm gonna",
    "start": "30689",
    "end": "36090"
  },
  {
    "start": "36000",
    "end": "36000"
  },
  {
    "text": "take we're gonna take questions at the end we'll just be down here in front so rather than doing the microphones and",
    "start": "36090",
    "end": "41460"
  },
  {
    "text": "all that will be available at the end so if you have questions if you could hold them until the end I'd appreciate it so",
    "start": "41460",
    "end": "47940"
  },
  {
    "text": "really excited to be here talking to you about this this is a kind of a perennial",
    "start": "47940",
    "end": "53250"
  },
  {
    "text": "customer ask and so we're excited to to share some of what we've learned I want",
    "start": "53250",
    "end": "59039"
  },
  {
    "text": "to make it clear that we are not talking about a public service that we have to offer but instead what we're going to do",
    "start": "59039",
    "end": "65518"
  },
  {
    "text": "is talk to you about the hard lessons that we've learned and talk to you about",
    "start": "65519",
    "end": "70560"
  },
  {
    "text": "the AWS tools that you can use to put together to accomplish what we accomplished in the metering pipeline so",
    "start": "70560",
    "end": "79130"
  },
  {
    "text": "I'll give you a little background what the problem is what we're trying to solve we can talk about some",
    "start": "79130",
    "end": "84869"
  },
  {
    "text": "alternatives for building this using commercially available tools then I'm",
    "start": "84869",
    "end": "91650"
  },
  {
    "text": "going to turn over to Jack he's going to tell you how you could build such a system and then we'll circle back and",
    "start": "91650",
    "end": "97229"
  },
  {
    "text": "talk about what the benefits of this would be now just before we get started",
    "start": "97229",
    "end": "103259"
  },
  {
    "text": "a little bit if I had to divide the world between finance people and engineers if I forced you to make a",
    "start": "103259",
    "end": "110369"
  },
  {
    "text": "decision because I know a lot of you are here because you cover both avenues how many would say you're principally",
    "start": "110369",
    "end": "115640"
  },
  {
    "text": "financially oriented okay and the rest I'm presuming are more",
    "start": "115640",
    "end": "122880"
  },
  {
    "text": "engineering oriented okay well we have a nice mix here so we're going to we're",
    "start": "122880",
    "end": "130229"
  },
  {
    "text": "going to explain this in ways that hopefully both sides can can understand",
    "start": "130229",
    "end": "136020"
  },
  {
    "start": "136000",
    "end": "136000"
  },
  {
    "text": "so the commerce platform first let me just say we're the people that are",
    "start": "136020",
    "end": "141250"
  },
  {
    "text": "responsible effectively for generating your bill Jack and I work at the very",
    "start": "141250",
    "end": "146740"
  },
  {
    "text": "front end of that process so we're the ones that do all the metering from the service teams from ec2 and s3 and RDS",
    "start": "146740",
    "end": "153220"
  },
  {
    "text": "they send their information on usage in to us we compile it rate it produce the",
    "start": "153220",
    "end": "158860"
  },
  {
    "text": "bills and things like that you see the bills and the data the usage data that",
    "start": "158860",
    "end": "165160"
  },
  {
    "text": "we provide in a variety of artifacts like for example the billing console the",
    "start": "165160",
    "end": "171220"
  },
  {
    "text": "cost Explorer AWS budgets and something",
    "start": "171220",
    "end": "176320"
  },
  {
    "text": "that's relatively new the cost and usage reports how many of you have ever been on the AWS console okay yes I am just",
    "start": "176320",
    "end": "184900"
  },
  {
    "text": "checking to see if everybody's away cuz most of you probably been there okay what about how many of you have created",
    "start": "184900",
    "end": "191410"
  },
  {
    "text": "a budget okay good and how many of you",
    "start": "191410",
    "end": "196840"
  },
  {
    "text": "have looked at a cost in usage report wow that's that's fantastic okay great",
    "start": "196840",
    "end": "204640"
  },
  {
    "text": "well I know that the the AWS bill is often the subject of a number of I guess",
    "start": "204640",
    "end": "213340"
  },
  {
    "text": "jokes it's been said that you need a PhD to understand your bill from AWS and the",
    "start": "213340",
    "end": "219700"
  },
  {
    "text": "only remaining question is a PhD and what discipline we're not exactly sure",
    "start": "219700",
    "end": "225180"
  },
  {
    "text": "it is it is challenging but part of the reason that it's challenging is because",
    "start": "225180",
    "end": "231430"
  },
  {
    "text": "our job is to liberate you from your fixed infrastructure from your data",
    "start": "231430",
    "end": "236500"
  },
  {
    "text": "centers and your other providers allow you to effectively make the move to the",
    "start": "236500",
    "end": "241989"
  },
  {
    "text": "cloud and things are different in the cloud and you need to have information detailed information about what's going",
    "start": "241989",
    "end": "249640"
  },
  {
    "text": "on with your infrastructure in the cloud and so that's why we provide this extremely rich data it can be a lot but",
    "start": "249640",
    "end": "260109"
  },
  {
    "text": "our customers every time we go and we say ok well we can simplify this cut this down by",
    "start": "260109",
    "end": "265150"
  },
  {
    "text": "order-of-magnitude will just eliminate this piece of detail that's not",
    "start": "265150",
    "end": "270790"
  },
  {
    "text": "something that our customers want they want to understand what's happening in their infrastructure and that's kind of",
    "start": "270790",
    "end": "277060"
  },
  {
    "text": "the basis of this talk we've realized that people really want to understand what's going on in their AWS",
    "start": "277060",
    "end": "283539"
  },
  {
    "text": "infrastructure we have some tools to say well let's get that same usage",
    "start": "283539",
    "end": "289870"
  },
  {
    "text": "infrastructure that same understanding for our on-prem and for our",
    "start": "289870",
    "end": "296169"
  },
  {
    "text": "infrastructure and other cloud providers so the cost Explorer is our graphical",
    "start": "296169",
    "end": "302650"
  },
  {
    "text": "visual user interface it allows you to understand what's going on",
    "start": "302650",
    "end": "307900"
  },
  {
    "text": "usage wides in your bill and cost both cost and usage it's meant for human consumption you go in there through the",
    "start": "307900",
    "end": "315669"
  },
  {
    "text": "website you're selecting filters and interacting with the information as a human we have various levels of reports",
    "start": "315669",
    "end": "323560"
  },
  {
    "text": "all the way down to the cost and usage report which many of you are familiar with which I'm very happy about this is",
    "start": "323560",
    "end": "331210"
  },
  {
    "text": "our most detailed data possible I think it's probably the most granular usage",
    "start": "331210",
    "end": "336370"
  },
  {
    "text": "data maybe on the planet I don't know it's down to an hourly level with resource IDs tells you which our eyes",
    "start": "336370",
    "end": "344020"
  },
  {
    "text": "are covering which instances it's very sophisticated that's meant for",
    "start": "344020",
    "end": "349539"
  },
  {
    "text": "programmatic consumption like we're not really expecting anybody to read that cost in usage report but that's the",
    "start": "349539",
    "end": "355389"
  },
  {
    "text": "range of services that we provide so human readable and the cost Explorer",
    "start": "355389",
    "end": "360430"
  },
  {
    "text": "machine readable at the cost and usage report the details matter we're providing a rich set of data because",
    "start": "360430",
    "end": "366940"
  },
  {
    "text": "customers really want that so we're going to talk today about how we can provide that kind of data for the",
    "start": "366940",
    "end": "373419"
  },
  {
    "text": "on-prem environment because really your respective of where you consume",
    "start": "373419",
    "end": "379210"
  },
  {
    "start": "374000",
    "end": "374000"
  },
  {
    "text": "resources whether it's on Prem or in a juror or AWS your shareholders need you",
    "start": "379210",
    "end": "385210"
  },
  {
    "text": "to account for them for those resources properly and in the data center days a",
    "start": "385210",
    "end": "392199"
  },
  {
    "text": "lot of that was about efficiency it was about asset utilization you know if you have a bunch of",
    "start": "392199",
    "end": "398539"
  },
  {
    "text": "expensive assets really what you really want to measure is how effectively are",
    "start": "398539",
    "end": "403759"
  },
  {
    "text": "you utilizing those assets you just don't want them to be idle so we used to measure things in the data center like",
    "start": "403759",
    "end": "410449"
  },
  {
    "text": "efficiency you know what is my average percent CPU utilization or what's my disk utilization of my storage",
    "start": "410449",
    "end": "417229"
  },
  {
    "text": "utilization what's my i/o bandwidth utilization I call that efficiency and one of the",
    "start": "417229",
    "end": "424999"
  },
  {
    "text": "first things that happens when you move from an on-prem into the cloud is that",
    "start": "424999",
    "end": "430039"
  },
  {
    "text": "concept gets turned a little bit sideways and I call it effectiveness so",
    "start": "430039",
    "end": "435169"
  },
  {
    "text": "what we really want to do is manage effectiveness versus efficiency and of",
    "start": "435169",
    "end": "440240"
  },
  {
    "text": "course I'm not at all saying that percent CPU utilization doesn't matter because of course it still does but",
    "start": "440240",
    "end": "445969"
  },
  {
    "text": "because of the benefits of the cloud because of the elasticity that you have and the fact that you're only paying for",
    "start": "445969",
    "end": "452959"
  },
  {
    "text": "what you use the efficiency is dominated",
    "start": "452959",
    "end": "458240"
  },
  {
    "text": "really by a measure that we call effectiveness so how can you manage the effectiveness of your implementation",
    "start": "458240",
    "end": "465490"
  },
  {
    "text": "wherever it wherever it lives the first thing you have to have is access to the",
    "start": "465490",
    "end": "470839"
  },
  {
    "text": "data you need the right people need to be able to effortlessly access the data they need to make decisions about their",
    "start": "470839",
    "end": "479509"
  },
  {
    "text": "use of technology we're just talking about this obviously a bunch of meetings with customers here at reinvent and this",
    "start": "479509",
    "end": "487459"
  },
  {
    "text": "concept of getting the usage data from these reports back to the person that spun up the instance so that person can",
    "start": "487459",
    "end": "494839"
  },
  {
    "text": "see what's happening is crucial so you have to get access to the information we",
    "start": "494839",
    "end": "500199"
  },
  {
    "text": "the information needs to be understandable now this is an area of where we as the commerce platform have",
    "start": "500199",
    "end": "507019"
  },
  {
    "text": "made some strides recently we have a long ways to go because the data is complex part of that is because our",
    "start": "507019",
    "end": "513979"
  },
  {
    "text": "services are complex we have a multitude of different offerings even if you just",
    "start": "513979",
    "end": "518990"
  },
  {
    "text": "look in the compute category for example you see - we've got our eyes we have convertibles and so forth those",
    "start": "518990",
    "end": "525970"
  },
  {
    "text": "offerings have to be expressed in the bill so we can make a crystal-clear representation of what's",
    "start": "525970",
    "end": "532459"
  },
  {
    "text": "in the bill and it still looks complicated because it is but you have to be able to understand it that's where",
    "start": "532459",
    "end": "539149"
  },
  {
    "text": "the data the quality of the data and the way it's organized comes into play once",
    "start": "539149",
    "end": "544490"
  },
  {
    "text": "you have access to the data and you can understand it then you need to put controls around it and when I talk about",
    "start": "544490",
    "end": "550519"
  },
  {
    "text": "control here I'm talking to the finance those people that raise their their hands talking about financial controls",
    "start": "550519",
    "end": "557329"
  },
  {
    "text": "you know the ability to audit to understand what the usage is it's like in the old days you could walk through",
    "start": "557329",
    "end": "563600"
  },
  {
    "text": "the data center and count asset tags well now you have to walk through a virtual data center accounting usage",
    "start": "563600",
    "end": "571010"
  },
  {
    "text": "tags there is really no no analog and so that control allows you to examine",
    "start": "571010",
    "end": "577430"
  },
  {
    "text": "inspect and audit your usage the next step is once you've got your controls in place and you you've got your data you",
    "start": "577430",
    "end": "584570"
  },
  {
    "text": "can understand it your controls are in place now you want to optimize your infrastructure and this is a place where",
    "start": "584570",
    "end": "589880"
  },
  {
    "text": "we have a lot of tools a trusted adviser we just recently in the cost Explorer just a week ago introduced our eye",
    "start": "589880",
    "end": "596980"
  },
  {
    "text": "recommendations so we'll go back over time look at analyze your usage and put",
    "start": "596980",
    "end": "602660"
  },
  {
    "text": "forth some recommendations so you can save money and the once you've optimized",
    "start": "602660",
    "end": "609079"
  },
  {
    "text": "your infrastructure then typically most companies most of you have to find a way",
    "start": "609079",
    "end": "614630"
  },
  {
    "text": "to allocate those costs back to their original cost centers there's",
    "start": "614630",
    "end": "620540"
  },
  {
    "text": "differences between the way that you accomplish those five things in the",
    "start": "620540",
    "end": "625550"
  },
  {
    "text": "cloud versus the way that you accomplish those five things in on-prem is slightly different there is in the traditional",
    "start": "625550",
    "end": "633019"
  },
  {
    "text": "infrastructure there are a number of players that help you allocate different pieces of hardware different pieces of",
    "start": "633019",
    "end": "638839"
  },
  {
    "text": "software personnel cost for example aptio many of you may use that in the",
    "start": "638839",
    "end": "645290"
  },
  {
    "text": "cloud or sorry in your own data center there's a lot of existing tools that",
    "start": "645290",
    "end": "653149"
  },
  {
    "text": "that play there in the fullness of time you know we believe that the vast",
    "start": "653149",
    "end": "658730"
  },
  {
    "text": "majority of companies are going to move most of their workloads into the cloud whether it's ours or another provide",
    "start": "658730",
    "end": "665370"
  },
  {
    "text": "and it is and and always will be a priority for us to make the you know",
    "start": "665370",
    "end": "671670"
  },
  {
    "text": "your to allow you to run on AWS as if it were a seamless extension of your own data center because I mean unless you're",
    "start": "671670",
    "end": "679080"
  },
  {
    "text": "all in AWS from the outset like born in the cloud let's face it pretty much",
    "start": "679080",
    "end": "684330"
  },
  {
    "text": "everyone is in some kind of a hybrid hybrid environment so I just want to",
    "start": "684330",
    "end": "689970"
  },
  {
    "text": "look at a couple of these key differences that drive differences in the way we measure what we're doing in",
    "start": "689970",
    "end": "697020"
  },
  {
    "text": "these different environments so first of all of course the cloud is pay-as-you-go so instead of having a bunch of fixed",
    "start": "697020",
    "end": "704430"
  },
  {
    "text": "infrastructure now you've got elasticity and your your payload is growing and",
    "start": "704430",
    "end": "709500"
  },
  {
    "text": "shrinking that's pretty much the opposite of well typically of a data center unless you're running your own",
    "start": "709500",
    "end": "714630"
  },
  {
    "text": "private cloud with VMware or something similar transactions are much more detailed they're billed at the hour the",
    "start": "714630",
    "end": "721410"
  },
  {
    "text": "second the call per million calls off it's much finer grained transactions",
    "start": "721410",
    "end": "727830"
  },
  {
    "text": "rather than once a quarter making a call or executing a purchase order and buying",
    "start": "727830",
    "end": "733170"
  },
  {
    "text": "a bunch of equipment for the for the data center and costs that are tied to",
    "start": "733170",
    "end": "738750"
  },
  {
    "text": "departments at the time of purchase now we are floating around and need to be",
    "start": "738750",
    "end": "743880"
  },
  {
    "text": "attributed back in the chargeback process so really what we're doing is",
    "start": "743880",
    "end": "748890"
  },
  {
    "text": "we're going from a capex world to an optics world we're going from asset tags to usage data we're going from machines",
    "start": "748890",
    "end": "757020"
  },
  {
    "text": "to looking at api's and we're going from recurring subscriptions to usage based",
    "start": "757020",
    "end": "763080"
  },
  {
    "text": "costing we're doing a lot of this for you in the AWS cloud once you get",
    "start": "763080",
    "end": "770370"
  },
  {
    "text": "accustomed to this and get familiar with it and comfortable with it it's a good way to measure your costs what we're",
    "start": "770370",
    "end": "776610"
  },
  {
    "text": "trying to do here is say hey how can we take that methodology usage based accounting and take it and move it to",
    "start": "776610",
    "end": "783180"
  },
  {
    "text": "two on-prem and that's what Jack's gonna tell you about as soon as I click through these next few few slides so",
    "start": "783180",
    "end": "789320"
  },
  {
    "text": "we've gone from counting assets to measuring usage and",
    "start": "789320",
    "end": "796130"
  },
  {
    "text": "in doing so we're creating some simple requirements and the question that we're asking is who's using how much of my",
    "start": "796130",
    "end": "802880"
  },
  {
    "text": "infrastructure and I guess I should have put on there and when and what we're",
    "start": "802880",
    "end": "808520"
  },
  {
    "text": "going to do is I'm just going to introduce this concept of a metering record which is just a simple small",
    "start": "808520",
    "end": "814960"
  },
  {
    "text": "compact piece of data packet of data that that contains essentially an",
    "start": "814960",
    "end": "821390"
  },
  {
    "text": "account ID a user ID an operation type and a value and this metering record is",
    "start": "821390",
    "end": "830029"
  },
  {
    "text": "what's going to get beamed around throughout this system that Jack's going to talk about we're gonna have a lot of",
    "start": "830029",
    "end": "836150"
  },
  {
    "text": "these metering records and they need to be secured they need to come in on an authenticated endpoint we need to make",
    "start": "836150",
    "end": "842900"
  },
  {
    "text": "sure that not only are you who you say you are but also that you have the right you have the authorization to execute",
    "start": "842900",
    "end": "850070"
  },
  {
    "text": "this this registering of this metering metered usage so security always our",
    "start": "850070",
    "end": "857740"
  },
  {
    "text": "number one priority and obviously that's going to be included in what Jack talks",
    "start": "857740",
    "end": "863089"
  },
  {
    "text": "about but the scale so I just want to point out some of the lessons that we've learned you can imagine we're sending",
    "start": "863089",
    "end": "869450"
  },
  {
    "text": "these metering records in and we grow by the cube of the number of customers AWS",
    "start": "869450",
    "end": "875210"
  },
  {
    "text": "has by the number of products AWS has by the number by the amount of usage AWS",
    "start": "875210",
    "end": "881330"
  },
  {
    "text": "has so we're dealing with tremendous scale and a lot of what he's talking about is going to talk to you about how",
    "start": "881330",
    "end": "888560"
  },
  {
    "text": "to deal with scale also aggregation because you're not going to want to look at every single millisecond you're gonna",
    "start": "888560",
    "end": "895310"
  },
  {
    "text": "want to be able to aggregate these and you're gonna want to do that on the edge so he's going to talk about that and then of course accuracy is extremely",
    "start": "895310",
    "end": "902839"
  },
  {
    "text": "important some of the things that we have to do in our systems in our design and our architecture is account for",
    "start": "902839",
    "end": "908529"
  },
  {
    "text": "exactly once delivery and as you know in a distributed system that's not always",
    "start": "908529",
    "end": "915080"
  },
  {
    "text": "easy you can get maybe at least once or most of the time but getting it exactly",
    "start": "915080",
    "end": "922730"
  },
  {
    "text": "once is a challenge so he'll talk about that",
    "start": "922730",
    "end": "928180"
  },
  {
    "text": "so applications are what businesses run so I recognized from an engineering",
    "start": "928430",
    "end": "936860"
  },
  {
    "text": "perspective or from a data center perspective we talked about instances",
    "start": "936860",
    "end": "942260"
  },
  {
    "text": "and and assets and discs and these kinds of things but really at the end of the day you want to measure your",
    "start": "942260",
    "end": "947840"
  },
  {
    "text": "applications and applications are made up of workloads and aslak business moves",
    "start": "947840",
    "end": "952970"
  },
  {
    "text": "into the cloud we typically see some some patterns where they move first with",
    "start": "952970",
    "end": "958640"
  },
  {
    "text": "the brand new application that has no dependencies but then as you start to move the rest of your applications you",
    "start": "958640",
    "end": "965690"
  },
  {
    "text": "kind of have to ask the question well which ones should we move first and how fast should we move these and that's",
    "start": "965690",
    "end": "971930"
  },
  {
    "text": "where I think this kind of analytical this kind of analysis will be applicable",
    "start": "971930",
    "end": "978880"
  },
  {
    "text": "helping you understand which applications are the ones to move first and you can build your cloud",
    "start": "978880",
    "end": "985370"
  },
  {
    "text": "infrastructure workload by workload yes",
    "start": "985370",
    "end": "994190"
  },
  {
    "text": "so Jim Collins he's a famous author that has been quoted by our esteemed leader",
    "start": "994190",
    "end": "1000970"
  },
  {
    "text": "Jeff Bezos many times because of the flywheel concept but he wrote a book",
    "start": "1000970",
    "end": "1006070"
  },
  {
    "text": "called built to last and it was lauded as a great business",
    "start": "1006070",
    "end": "1011170"
  },
  {
    "text": "book about how to build an enduring business but it really started with startups and it's like if you're born in",
    "start": "1011170",
    "end": "1017440"
  },
  {
    "text": "the cloud you can build an enduring infrastructure from the get-go it's much",
    "start": "1017440",
    "end": "1022630"
  },
  {
    "text": "harder to do that when you're born in a data center and you're moving in so that's our goal",
    "start": "1022630",
    "end": "1027699"
  },
  {
    "text": "help you figure out what to move first",
    "start": "1027700",
    "end": "1032010"
  },
  {
    "start": "1032000",
    "end": "1032000"
  },
  {
    "text": "the other thing that's important is to have an integrated view AWS we have a",
    "start": "1034390",
    "end": "1041808"
  },
  {
    "text": "bunch of tools that shows you what's going on within AWS you may have other tools on Prem you may",
    "start": "1041809",
    "end": "1048079"
  },
  {
    "text": "be trying to move those tools from the on-prem environment into AWS sometimes that's that's great and that works if",
    "start": "1048079",
    "end": "1054649"
  },
  {
    "text": "people have homegrown applications or they're running agents user agents these kinds of things those are a little bit",
    "start": "1054649",
    "end": "1059779"
  },
  {
    "text": "harder to move to the cloud but ultimately at the end of the day we're going to want to have an integrated view of this and so one of",
    "start": "1059779",
    "end": "1066289"
  },
  {
    "text": "the things that we'll we'll talk about at the end is how you can take the cost and usage report data put it into for",
    "start": "1066289",
    "end": "1073100"
  },
  {
    "text": "example a redshift cluster and then add your own on-prem data in a similar schema so that you can have an",
    "start": "1073100",
    "end": "1079010"
  },
  {
    "text": "integrated view so then these become the",
    "start": "1079010",
    "end": "1087679"
  },
  {
    "text": "final list of requirements we talked about security scale aggregation exactly once delivery should have mentioned that",
    "start": "1087679",
    "end": "1095480"
  },
  {
    "text": "all of this stuff is multi-tenant and this is because when you're moving enterprise applications they're going to",
    "start": "1095480",
    "end": "1102500"
  },
  {
    "text": "be multi tenant you're gonna have multiple users using the same API or multiple accounts using the same",
    "start": "1102500",
    "end": "1108159"
  },
  {
    "text": "database or multiple whatever it is they're all interleaved and so a lot of",
    "start": "1108159",
    "end": "1113659"
  },
  {
    "text": "what Jack is going to talk about is how to deem Ochs all of these multi tenant users so it's",
    "start": "1113659",
    "end": "1120980"
  },
  {
    "text": "got to be multi tenant and it has to be integrated so now that we've setup the",
    "start": "1120980",
    "end": "1127929"
  },
  {
    "text": "requirements I guess the question is how do how do we do something like this and so I'm gonna turn it over to Jack and",
    "start": "1127929",
    "end": "1133850"
  },
  {
    "text": "let him talk to you about putting it in place thank you Dan",
    "start": "1133850",
    "end": "1138940"
  },
  {
    "text": "in order to answer Dan's question about who is using what of how much of my IT",
    "start": "1138940",
    "end": "1144799"
  },
  {
    "text": "infrastructure we need to first understand the different types of things that we are measuring this really comes",
    "start": "1144799",
    "end": "1149870"
  },
  {
    "text": "down to three different things that you can reader there's the physical infrastructure which includes your",
    "start": "1149870",
    "end": "1154880"
  },
  {
    "text": "servers your databases your instances and containers as well as the",
    "start": "1154880",
    "end": "1159950"
  },
  {
    "text": "applications are deployed across this infrastructure as well and their utilization resource CPU",
    "start": "1159950",
    "end": "1166230"
  },
  {
    "text": "with and so on finally we get down to the level of services and api's which cracks the per user per request level of",
    "start": "1166230",
    "end": "1174419"
  },
  {
    "text": "access the usage level access of your applications and services your",
    "start": "1174419",
    "end": "1180090"
  },
  {
    "text": "architecture and the choice of technology that you use will vary dramatically based on what it is that you are measuring from a scaling",
    "start": "1180090",
    "end": "1187320"
  },
  {
    "text": "perspective your physical infrastructure can often run in the thousands or hundreds of thousands of servers and",
    "start": "1187320",
    "end": "1193110"
  },
  {
    "text": "instances that you measure and the applications that are deployed across that again on the order of hundreds of",
    "start": "1193110",
    "end": "1198720"
  },
  {
    "text": "thousands in aggregate this is a fairly large number but as Dan mentioned because this is something where you're",
    "start": "1198720",
    "end": "1204720"
  },
  {
    "text": "tracking the total assets of your inventory it's something that can be done over a longer period of time typically on days months or even over",
    "start": "1204720",
    "end": "1211710"
  },
  {
    "text": "quarters however when you make the change excuse me however when you make the change to usage based metering when you",
    "start": "1211710",
    "end": "1220890"
  },
  {
    "text": "make the change to usage based metering you hit a different inflection of scale that's much much larger you are now",
    "start": "1220890",
    "end": "1227580"
  },
  {
    "text": "looking at millions of requests possibly hundreds of millions of requests per second that's touching your applications",
    "start": "1227580",
    "end": "1233280"
  },
  {
    "text": "and between these different things do you also get different information again",
    "start": "1233280",
    "end": "1239130"
  },
  {
    "text": "with physical infrastructure with the assets of Cal and catalog of applications that you run you're really",
    "start": "1239130",
    "end": "1244470"
  },
  {
    "text": "looking at what it is that you have deployed you can understand better efficiencies five identifying those",
    "start": "1244470",
    "end": "1250559"
  },
  {
    "text": "servers or those instances that are underperforming and sort of Regis should be reallocating them to some of their",
    "start": "1250559",
    "end": "1256049"
  },
  {
    "text": "purpose with application based or usage based metering you're really looking at the effectiveness of your business this",
    "start": "1256049",
    "end": "1262470"
  },
  {
    "text": "is where you can figure out how to invest your infrastructure into places that are that need that have more users",
    "start": "1262470",
    "end": "1268350"
  },
  {
    "text": "or more activity and this is how you could really gain those kind of insights so with that in mind let's take a deeper",
    "start": "1268350",
    "end": "1274260"
  },
  {
    "start": "1272000",
    "end": "1272000"
  },
  {
    "text": "dive into building a system that actually supports usage based metering this is where really the scale comes in",
    "start": "1274260",
    "end": "1280919"
  },
  {
    "text": "and that's where the fun comes in there's a lot of different components that make up sort of a metering pipeline that you would have to build but I'm",
    "start": "1280919",
    "end": "1287490"
  },
  {
    "text": "going to focus on sort of three different areas around collection processing and auditing this is where really the most interesting and most",
    "start": "1287490",
    "end": "1293790"
  },
  {
    "text": "challenging problems occur at scale and we're gonna talk about some of the things that some of the solutions we have learned along the way to help",
    "start": "1293790",
    "end": "1299419"
  },
  {
    "text": "you deal with that first when you collect the usage data you really are focusing on getting the data off of the",
    "start": "1299419",
    "end": "1305809"
  },
  {
    "text": "different hosts and instances containers as quickly off of the edge as possible into a central place and this is where",
    "start": "1305809",
    "end": "1312350"
  },
  {
    "text": "you need to handle that scale to be able to deal with the firehose and data that's coming in you also want to make a",
    "start": "1312350",
    "end": "1318140"
  },
  {
    "text": "decision around building indexes to make it simpler to make a simpler down stream when you pour your processing so that",
    "start": "1318140",
    "end": "1324950"
  },
  {
    "text": "when you're processing your data in a multi-tenant system you only pull down the data that you need instead of pulling down the entire world and this",
    "start": "1324950",
    "end": "1331519"
  },
  {
    "text": "is also where we want to make some early decisions around exactly what's processing we're going to make sure that we have the right semantics in place so",
    "start": "1331519",
    "end": "1338090"
  },
  {
    "text": "that we can actually support exactly what's processing and auditing throughout our pipeline in the processing stage we're really talking",
    "start": "1338090",
    "end": "1343970"
  },
  {
    "text": "about aggregation in this particular conversation but you can imagine applying other kinds of transformations",
    "start": "1343970",
    "end": "1349220"
  },
  {
    "text": "in the positive pipeline and again we want to make sure that we are supporting a multi-tenant type of environment and",
    "start": "1349220",
    "end": "1354440"
  },
  {
    "text": "finally with auditing and verification we're really talking about tracking the accuracy the completeness and correctness of the data that's going",
    "start": "1354440",
    "end": "1360320"
  },
  {
    "text": "through your pipeline and we're going to talk a little bit more about the different ways in which you can do this just did better set expectations we're",
    "start": "1360320",
    "end": "1366679"
  },
  {
    "text": "going to spend the majority of our time in the in the collection area this is because from the lessons that we have",
    "start": "1366679",
    "end": "1373039"
  },
  {
    "text": "learned at AWS the what we find is that when you make decisions early in the",
    "start": "1373039",
    "end": "1378440"
  },
  {
    "text": "pipeline it's really again it simplifies the your workflow throughout the",
    "start": "1378440",
    "end": "1383960"
  },
  {
    "text": "entirety of your systems it makes it more makes it more resilient more flexible and it ultimately makes it more",
    "start": "1383960",
    "end": "1390350"
  },
  {
    "text": "scalable so that let's focus on collecting collecting usage data this is",
    "start": "1390350",
    "end": "1396409"
  },
  {
    "text": "a system view of the architecture that we have again we want to get ruin of focus on getting the data off of the",
    "start": "1396409",
    "end": "1402440"
  },
  {
    "text": "edge as quickly as possible so in this case we have a little bit you can use a year I'll be a low balancer we're in",
    "start": "1402440",
    "end": "1409100"
  },
  {
    "text": "toward The Bachelor of metering records are coming in and you can set it through the collection stage you're going through an authentication authorization",
    "start": "1409100",
    "end": "1414289"
  },
  {
    "text": "layer and you build a scalable a horizontally scale system to be able to collect this data this is also where we",
    "start": "1414289",
    "end": "1421730"
  },
  {
    "text": "want to perform some simple validation you might want to do some schema formatting validation before you offer the data into a persistent data store",
    "start": "1421730",
    "end": "1428120"
  },
  {
    "text": "here we take the data we put into s3 and for instance to it in dynamodb this is",
    "start": "1428120",
    "end": "1434960"
  },
  {
    "text": "also we can make an early decision architectural decision about trade-offs between streaming versus batch now",
    "start": "1434960",
    "end": "1440450"
  },
  {
    "text": "streaming makes it easier for your clients for your customers to put records directly into a streaming pipeline and pass it to the rest of the",
    "start": "1440450",
    "end": "1446419"
  },
  {
    "text": "system however from our experience streaming in order to guarantee exactly what is",
    "start": "1446419",
    "end": "1451610"
  },
  {
    "text": "processing streaming in the streaming platform so you had to build a lot more complicated tools to be able to support that and so",
    "start": "1451610",
    "end": "1458509"
  },
  {
    "text": "our objective here is to get the data off the edge as quickly as possible so using a batch based system it's actually",
    "start": "1458509",
    "end": "1463549"
  },
  {
    "text": "dead simple and allows you to scale out and support exactly what semantics are a lot simpler and that's the reason we",
    "start": "1463549",
    "end": "1469639"
  },
  {
    "text": "suggest to use that approach instead once you get the data into the pipeline we then pass it through an sqs cue to go",
    "start": "1469639",
    "end": "1477289"
  },
  {
    "text": "to a local aggregation stage now this is an optional stage and the reason why",
    "start": "1477289",
    "end": "1483590"
  },
  {
    "text": "it's optional is anytime you introduce another component or another system in a distributed environment you're adding more complexity more opportunities or",
    "start": "1483590",
    "end": "1490009"
  },
  {
    "text": "failures or opportunity for duplicate data that has to be retransmitted but what we have found is that there's",
    "start": "1490009",
    "end": "1495889"
  },
  {
    "text": "actually a lot of op with doing some simple local aggregation within a batch of metering records and the reason why",
    "start": "1495889",
    "end": "1503210"
  },
  {
    "text": "that is is when you get to API or service level metering you just need to see a lot of repetitive actions the same",
    "start": "1503210",
    "end": "1510499"
  },
  {
    "text": "user making the same call to the same product multiple times can give you great efficiencies when you reduce that",
    "start": "1510499",
    "end": "1516499"
  },
  {
    "text": "data often up to 10x and this and that's the reason why when I had this kind of",
    "start": "1516499",
    "end": "1521690"
  },
  {
    "text": "local aggregation station now with this benefit you may ask the question if you get this efficiency why not push it",
    "start": "1521690",
    "end": "1527749"
  },
  {
    "text": "further up the stack you can put it as close to the edge as possible from our",
    "start": "1527749",
    "end": "1533059"
  },
  {
    "text": "experience that's the trade-off of CPU that you have at the edge versus the bandwidth it's much better to just get",
    "start": "1533059",
    "end": "1539960"
  },
  {
    "text": "the data off because you really want to reserve that CPU to serve the applications for your users doing whatever that is really doing so pushing",
    "start": "1539960",
    "end": "1546440"
  },
  {
    "text": "that data further down is a better trade-off similarly in the collection",
    "start": "1546440",
    "end": "1551690"
  },
  {
    "text": "stage if you do aggregation within your batch at that stage you lose the",
    "start": "1551690",
    "end": "1557629"
  },
  {
    "text": "resolution once you have read over the information that detail is gone and what we find is that there are times",
    "start": "1557629",
    "end": "1563640"
  },
  {
    "text": "you want to go back and sort of really get to that detailed level view of information for auditing for sort of a",
    "start": "1563640",
    "end": "1569250"
  },
  {
    "text": "detailed check and it's better to get the data offloaded and then do your aggregation your further step finally",
    "start": "1569250",
    "end": "1575970"
  },
  {
    "text": "from the aggregation stage we then route our traffic to an indexing stage this is",
    "start": "1575970",
    "end": "1581700"
  },
  {
    "text": "where we start introducing more state into our system by introducing partitions in terms of how you build your index and this is where a lot of",
    "start": "1581700",
    "end": "1588270"
  },
  {
    "text": "the complexity really comes in and we're using Kinesis in this example to sort of act as a streaming MapReduce so my next",
    "start": "1588270",
    "end": "1595230"
  },
  {
    "text": "few slides I'm going to focus on sort of dealing with some of the complexity that comes in with this hit scale this is a",
    "start": "1595230",
    "end": "1601920"
  },
  {
    "text": "few examples of some of the metering records that you can generate in this case you can it's a pretty simple schema",
    "start": "1601920",
    "end": "1607380"
  },
  {
    "text": "there's a user ID an application an operation that's executed a time as well",
    "start": "1607380",
    "end": "1612840"
  },
  {
    "text": "as the value the number of things that were run and as you can see in a",
    "start": "1612840",
    "end": "1618360"
  },
  {
    "text": "multi-tenant system you have users that submit applications across different types of batches of Records and so in",
    "start": "1618360",
    "end": "1623880"
  },
  {
    "text": "order to build an index you can imagine that for every user forever in every batch it exists you have to create sort",
    "start": "1623880",
    "end": "1630240"
  },
  {
    "text": "of this product of product of records together and in this particular case the",
    "start": "1630240",
    "end": "1636300"
  },
  {
    "text": "cardinality of the bigger oh is an N times n type of operation where ends the number of users you have and M is the",
    "start": "1636300",
    "end": "1642870"
  },
  {
    "text": "number of batches that those user records exists and this becomes a big",
    "start": "1642870",
    "end": "1648720"
  },
  {
    "text": "challenge in using dynamodb as a person did as a persistent layer to store the",
    "start": "1648720",
    "end": "1655200"
  },
  {
    "text": "number of a ops and you have the handle to to deal with the to building this index and anytime you add a new",
    "start": "1655200",
    "end": "1661050"
  },
  {
    "text": "dimension say that you want to track the applications that are deployed across your batches this again introduces",
    "start": "1661050",
    "end": "1668370"
  },
  {
    "text": "another of n times n type of operation to store the number by ops do to try the number by ops and you need to be able to",
    "start": "1668370",
    "end": "1674070"
  },
  {
    "text": "store this index so in order to control this scale you really need to introduce",
    "start": "1674070",
    "end": "1679590"
  },
  {
    "text": "a sort of a MapReduce like function to be able to collect similar things together so in this case for our user",
    "start": "1679590",
    "end": "1685560"
  },
  {
    "text": "index you can imagine putting the different user data together in order to generate in order to generate a larger",
    "start": "1685560",
    "end": "1691890"
  },
  {
    "text": "list of batches before you write them into your database this effectively reduces your throughput",
    "start": "1691890",
    "end": "1698049"
  },
  {
    "text": "requirements from an O of n times M operation to an O and operation now it's not exactly like that because",
    "start": "1698049",
    "end": "1704770"
  },
  {
    "text": "depending on how large that list of Rights huh flowers that list of batches get you may incur multiple rights in to say",
    "start": "1704770",
    "end": "1711100"
  },
  {
    "text": "dynamodb but this is where sort of Kinesis comes in as a as a streaming app to really buffer and allow you to sort",
    "start": "1711100",
    "end": "1716740"
  },
  {
    "text": "dial up and down how frequently you write into your database you can imagine that the longer you buffering your input",
    "start": "1716740",
    "end": "1722740"
  },
  {
    "text": "the fewer rights and you have to do some",
    "start": "1722740",
    "end": "1727840"
  },
  {
    "text": "additional other benefits of using Canisius is a streaming app deduplication is handled locally again",
    "start": "1727840",
    "end": "1733630"
  },
  {
    "text": "in an exactly once system we really want to focus on making sure that retransmits that happening the pipeline either user",
    "start": "1733630",
    "end": "1740130"
  },
  {
    "text": "user generated or system generated or did you throughout in our system in this",
    "start": "1740130",
    "end": "1746049"
  },
  {
    "text": "case with a map with a streaming map you know that every batch for a particular index is going to the same place so that",
    "start": "1746049",
    "end": "1751929"
  },
  {
    "text": "you can handle D dupe locally in memory without sort of incurring a costly distributed systems or a costly global",
    "start": "1751929",
    "end": "1757510"
  },
  {
    "text": "data store please know that this is actually not something that comes for free with Kinesis so you do have to",
    "start": "1757510",
    "end": "1762789"
  },
  {
    "text": "build some tooling build some systems to support that but in who we find said essentially fairly straightforward to do",
    "start": "1762789",
    "end": "1768299"
  },
  {
    "text": "the map workloads in this case also reduce the blast radius of failures in your system so bad data or bad hosts",
    "start": "1768299",
    "end": "1775720"
  },
  {
    "text": "will only impact a few partitions where they get mapped into your system so that the rest of the data can flow through",
    "start": "1775720",
    "end": "1781929"
  },
  {
    "text": "without impacting everybody else and ultimately Kinesis provides streaming",
    "start": "1781929",
    "end": "1787169"
  },
  {
    "text": "checkpoint semantics that allows you to incrementally progress all the way so that depending how long your buffer you",
    "start": "1787169",
    "end": "1793000"
  },
  {
    "text": "can buffer your input for about ten minutes and then when you checkpoint if something fails all the way you only lose that ten minutes worth of",
    "start": "1793000",
    "end": "1799539"
  },
  {
    "text": "processing before you have to come back and introducing a MapReduce however does",
    "start": "1799539",
    "end": "1805570"
  },
  {
    "text": "it does add the possibility that you're gonna hit hotspots now you're now you're",
    "start": "1805570",
    "end": "1810880"
  },
  {
    "text": "entering constraints within your partition so for Canisius in Kinesis for example within a regular shard",
    "start": "1810880",
    "end": "1817779"
  },
  {
    "text": "we're talking about one thousand TPS with mo making byte per second and you can hit those pretty quickly for",
    "start": "1817779",
    "end": "1824350"
  },
  {
    "text": "enough indexes so now we want to think about how do we actually deal with manage of the hot partition here's a",
    "start": "1824350",
    "end": "1830169"
  },
  {
    "text": "really simple example imagine you'll have two partitions where all of the load is not evenly distributed well one",
    "start": "1830169",
    "end": "1835510"
  },
  {
    "text": "partition has some three times as much as another and you now have a very unbalanced load and so using Kinesis the",
    "start": "1835510",
    "end": "1843460"
  },
  {
    "start": "1841000",
    "end": "1841000"
  },
  {
    "text": "way that we sort of control this the hotspots is by adding a little bit of",
    "start": "1843460",
    "end": "1849010"
  },
  {
    "text": "entropy in terms of how to put the data into our system in this case Canisius uses a partition key before it puts",
    "start": "1849010",
    "end": "1854559"
  },
  {
    "text": "records into the stream you by adding a little bit entropy we are we can now sort of control the throughput and how",
    "start": "1854559",
    "end": "1860799"
  },
  {
    "text": "many partitions logical partitions we actually use within Kinesis this we",
    "start": "1860799",
    "end": "1866470"
  },
  {
    "text": "recommend using using some hash function over the field or fields that you are",
    "start": "1866470",
    "end": "1872470"
  },
  {
    "text": "actually using to build your index in this case we're using a user ID performing the hash over the user ID and",
    "start": "1872470",
    "end": "1877990"
  },
  {
    "text": "then mod it by some sub partition size sub partition size here it's just a logical partition and this is really how",
    "start": "1877990",
    "end": "1884289"
  },
  {
    "text": "you use what you use to sort of control the scale in your potting the industry right the more purchasable partitions",
    "start": "1884289",
    "end": "1890500"
  },
  {
    "text": "you want the more logical partitions the more even you want to spread out your load the higher than of the sub partition size number you want and",
    "start": "1890500",
    "end": "1897450"
  },
  {
    "text": "because we value exactly one semantics there's some other constraints that we want to add in when we define the sub",
    "start": "1897450",
    "end": "1903340"
  },
  {
    "text": "partition this entropy we want to make sure that the hash function that you're using is is determinists is",
    "start": "1903340",
    "end": "1908860"
  },
  {
    "text": "deterministic so that generates an idempotent result upon every every use and also that small partition size",
    "start": "1908860",
    "end": "1915159"
  },
  {
    "text": "itself is actually versioned in a time series kind of way this the reason why this is important is again you can have",
    "start": "1915159",
    "end": "1921820"
  },
  {
    "text": "retransmits in the pipeline so you wanna make sure that any sub any any retransmitted data is using the same",
    "start": "1921820",
    "end": "1927700"
  },
  {
    "text": "partition scheme that are used upon the previous run so that you're gonna get model yeah you don't get information",
    "start": "1927700",
    "end": "1933490"
  },
  {
    "text": "that crossed between different times this is a simple way to do this is just use the time stamp when you generate the",
    "start": "1933490",
    "end": "1940270"
  },
  {
    "text": "bash you can have a time stamp that's associated with a batch at the time of generation and then the time stamp is used with the sub partition size so that",
    "start": "1940270",
    "end": "1947590"
  },
  {
    "text": "when you see a batch come in from a previous time stamp you can find a correct version to use and then provide",
    "start": "1947590",
    "end": "1952809"
  },
  {
    "text": "that as an entropy so in a toy example with with the with",
    "start": "1952809",
    "end": "1958570"
  },
  {
    "text": "the introduction of a sub partition parameter we have better more uniform distribution of our load across the",
    "start": "1958570",
    "end": "1964359"
  },
  {
    "text": "partitions this is the component view of the systems that we can use to manage",
    "start": "1964359",
    "end": "1970359"
  },
  {
    "start": "1966000",
    "end": "1966000"
  },
  {
    "text": "hard partitions the producer when it's putting records into Kinesis gains different iOS statistics they can record",
    "start": "1970359",
    "end": "1977649"
  },
  {
    "text": "things like the throughput or the TPS district seen at each partition you can also record information from Canisius in",
    "start": "1977649",
    "end": "1984099"
  },
  {
    "text": "terms of throttles the hotspot manager and discern intern recent information from dynamo it's then able to make",
    "start": "1984099",
    "end": "1989979"
  },
  {
    "text": "decisions proactively and reactively based on the trends of growth as well as",
    "start": "1989979",
    "end": "1995019"
  },
  {
    "text": "the throttles that is seized from Kinesis in turn makes decisions and writes the partition information back into dynamo and then the producer reads",
    "start": "1995019",
    "end": "2002009"
  },
  {
    "text": "that information and uses that to push this push put records into the streaming",
    "start": "2002009",
    "end": "2007080"
  },
  {
    "text": "map you can also use api's that are",
    "start": "2007080",
    "end": "2014039"
  },
  {
    "text": "offered directly through kinases such as split shards and merge charts to sort of control how you grow the stream will be",
    "start": "2014039",
    "end": "2021629"
  },
  {
    "text": "found in practice though is using our own logical partition makes gives us more control because there's more",
    "start": "2021629",
    "end": "2027089"
  },
  {
    "text": "flexibility and to really do targeted changes into our stream by growing only",
    "start": "2027089",
    "end": "2032639"
  },
  {
    "text": "a subset of partitions so that we don't impact the rest of the other stream so",
    "start": "2032639",
    "end": "2038549"
  },
  {
    "text": "to quickly recap for the collection or usage data we're really focusing on how",
    "start": "2038549",
    "end": "2044190"
  },
  {
    "text": "to cut a horizontally scale and how to cheaply and quickly get data off of the edge and we want to focus on we talked",
    "start": "2044190",
    "end": "2050908"
  },
  {
    "text": "about building an index that's able to support making decisions later on in a processing station that you're only",
    "start": "2050909",
    "end": "2056520"
  },
  {
    "text": "selectively pulling down the data that you need when you process and then making some decisions again around exactly what semantics early on next we",
    "start": "2056520",
    "end": "2064408"
  },
  {
    "text": "want to talk about your processing stage and the things that you want to build to be able to support a multi-tenant kind of environment this is a system view of",
    "start": "2064409",
    "end": "2073049"
  },
  {
    "text": "the architecture that we use to aggregate and transform data in our pipeline in this case the controller is",
    "start": "2073049",
    "end": "2079138"
  },
  {
    "text": "where all of the different job requests are coming in the multi tenant kind of jobs where you're trying to track",
    "start": "2079139",
    "end": "2084589"
  },
  {
    "text": "processing by user or by application or by region or by time and this job's then tracked against a",
    "start": "2084589",
    "end": "2091740"
  },
  {
    "text": "workers a fleet of different EMR clusters in this particular design we actually recommend that you use multiple",
    "start": "2091740",
    "end": "2097590"
  },
  {
    "text": "Yammer clusters instead of a single large GM cluster that you're scaling up and down by adding more hosts or adding larger hosts",
    "start": "2097590",
    "end": "2104280"
  },
  {
    "text": "the reason again for some doing some like this is just about building the increase iliyan see where we find as",
    "start": "2104280",
    "end": "2109560"
  },
  {
    "text": "poison pills or bad data sometimes can't can take down an entire large cluster and take your processing pipeline to a",
    "start": "2109560",
    "end": "2116099"
  },
  {
    "text": "screeching halt and you really want to protect yourself against that and building support for multiple clusters",
    "start": "2116099",
    "end": "2121740"
  },
  {
    "text": "allow you to allow you to sort of isolate the blast radius for failures it also has additional benefits what we",
    "start": "2121740",
    "end": "2127950"
  },
  {
    "text": "find is that when you have this information you can experiment a lot quick more quickly you want to build",
    "start": "2127950",
    "end": "2134160"
  },
  {
    "text": "different indexes different ways that you want to add v8 or transform your data and with the multi sort of cluster setup you can isolate those experiments",
    "start": "2134160",
    "end": "2141060"
  },
  {
    "text": "in a small place using production data without having to sort of impact the rest of your rest of your services and",
    "start": "2141060",
    "end": "2147690"
  },
  {
    "text": "other users are using this application this is the component view of how the",
    "start": "2147690",
    "end": "2153330"
  },
  {
    "text": "cluster manager interacts with different systems in this case the controller and the cluster manager working tandem to be",
    "start": "2153330",
    "end": "2159359"
  },
  {
    "text": "able to handle auto scale the controller again takes requests for different types of jobs that are running it it submits",
    "start": "2159359",
    "end": "2166980"
  },
  {
    "text": "those requests and it looks into a datastore in this case dynamodb to find available clusters to lease and also in",
    "start": "2166980",
    "end": "2172440"
  },
  {
    "text": "queues others jobs and restores that information into dynamodb for those jobs that do have our map to a cluster a kick",
    "start": "2172440",
    "end": "2179250"
  },
  {
    "text": "toss to EMR directly and kicks off those jobs the cluster manager in turn pulls",
    "start": "2179250",
    "end": "2184680"
  },
  {
    "text": "that information from dynamo so that it can identify trends on how long the jobs",
    "start": "2184680",
    "end": "2189839"
  },
  {
    "text": "are running and how big is the backlog so that it can make decisions on whether or not to spend up new clusters or tear",
    "start": "2189839",
    "end": "2194970"
  },
  {
    "text": "them down the net result of this is that you've effectively turned your different EMR clusters into ephemeral",
    "start": "2194970",
    "end": "2202040"
  },
  {
    "text": "resources and you can spin up and tear down just like an ec2 instance from a",
    "start": "2202040",
    "end": "2208080"
  },
  {
    "start": "2207000",
    "end": "2207000"
  },
  {
    "text": "workflow perspective again because you want to support a multi-tenant kind of system with different types of jobs you",
    "start": "2208080",
    "end": "2213810"
  },
  {
    "text": "want to really isolate and treat the different types of jobs their inputs as well as their outputs in the",
    "start": "2213810",
    "end": "2220500"
  },
  {
    "text": "you want to and you want to store this information so that you can do this",
    "start": "2220500",
    "end": "2225520"
  },
  {
    "text": "processing in different stages and I'll talk a little bit more about store what that means once you've identified the",
    "start": "2225520",
    "end": "2230650"
  },
  {
    "text": "jobs the list of jobs and for particularly on vacation you then want to query the index that you built in the",
    "start": "2230650",
    "end": "2236290"
  },
  {
    "text": "in the collection stage to then identify all the input that you need for that particular job the once you have that",
    "start": "2236290",
    "end": "2244810"
  },
  {
    "text": "index once you have the batches identified you want to lock this information down so that you so that you",
    "start": "2244810",
    "end": "2249970"
  },
  {
    "text": "can go ahead and read so that if you had to read one and reprocess you have the same data set that that's used for a",
    "start": "2249970",
    "end": "2255940"
  },
  {
    "text": "previous job against it's coasting to item potency and goes into sort of deterministic and deduplication behavior",
    "start": "2255940",
    "end": "2261400"
  },
  {
    "text": "so you want in your system once the input is set gonna kick off near my job and perform the processing again whether",
    "start": "2261400",
    "end": "2268480"
  },
  {
    "text": "its aggregation or any other types of transfers you wanted to we can go ahead and run it through and and that",
    "start": "2268480",
    "end": "2274420"
  },
  {
    "text": "completes the the workflow the two benefits that I mentioned around sort of this item potency the reason why you",
    "start": "2274420",
    "end": "2280180"
  },
  {
    "text": "want unlock the different stages of input down is that with the lock dataset again you have guaranteed idempotency",
    "start": "2280180",
    "end": "2285820"
  },
  {
    "text": "with if the application fails somewhat time along the way it's on some pipe in the processing stage you can go back and",
    "start": "2285820",
    "end": "2292270"
  },
  {
    "text": "rerun it without fear of generating duplicate data and with that item potency guarantee your consumers that read this information because it's",
    "start": "2292270",
    "end": "2298990"
  },
  {
    "text": "deterministic the output they know exactly the output should be they can build better duplication reasoning",
    "start": "2298990",
    "end": "2304090"
  },
  {
    "text": "behind when they consume that information and another benefit of using sort of a fixed data set is that enjoys",
    "start": "2304090",
    "end": "2309250"
  },
  {
    "text": "predictability now with this information the cluster manager can actually do auto scaling by knowing that with this fixed",
    "start": "2309250",
    "end": "2315850"
  },
  {
    "text": "input this is how I would take to run this is my backlog of work this is how much throughput I how many clusters I",
    "start": "2315850",
    "end": "2320890"
  },
  {
    "text": "need to use to be able to actually make sure I go through the backlog to recap in the processing stage again we're",
    "start": "2320890",
    "end": "2327880"
  },
  {
    "text": "focusing on aggregation in a multi-tenant system and using a Bachelor than MapReduce framework like EMR again",
    "start": "2327880",
    "end": "2334150"
  },
  {
    "text": "using multiple Yammer clusters finally one finally we're gonna take a look at how you can build auditing into",
    "start": "2334150",
    "end": "2340180"
  },
  {
    "text": "your pipeline and auditing is a critical step to prove the accuracy in your",
    "start": "2340180",
    "end": "2346450"
  },
  {
    "text": "system in this case inside the Amidah and pipeline they're really two different things that you're on there's completeness and correctness",
    "start": "2346450",
    "end": "2352720"
  },
  {
    "text": "completeness answers the question did I process everything that I received and correctness to answer this question did",
    "start": "2352720",
    "end": "2358850"
  },
  {
    "text": "I process everything accurately for auditing for completeness is fairly",
    "start": "2358850",
    "end": "2364280"
  },
  {
    "text": "straightforward be in an eventually consistent system you basically have to wait for all the data to arrive after",
    "start": "2364280",
    "end": "2370640"
  },
  {
    "text": "some period of time before you kick out your completeness part and in this case you want to you want to measure for some",
    "start": "2370640",
    "end": "2376640"
  },
  {
    "text": "fixed time window say all of the metering data there was some a different a particular hour after some fixed time",
    "start": "2376640",
    "end": "2382370"
  },
  {
    "text": "interval say two hours after the time has happened to sort of track to your",
    "start": "2382370",
    "end": "2387500"
  },
  {
    "text": "input space to see these are all the patches that were submitted you can match that against the manifest so you generated when you process the data to",
    "start": "2387500",
    "end": "2393380"
  },
  {
    "text": "see how does this line up and there's anything that's missing then you have an error and you can fail the audit there",
    "start": "2393380",
    "end": "2398410"
  },
  {
    "text": "by comparison for correctness it's much more complicated at scale and this is",
    "start": "2398410",
    "end": "2404780"
  },
  {
    "text": "really where you know to do it efficiently we need to do we need to be able to fail fast so that you can react",
    "start": "2404780",
    "end": "2411260"
  },
  {
    "text": "quickly when they're not it fails and also be able do it in an incremental fashion and the way to do that is to add",
    "start": "2411260",
    "end": "2418190"
  },
  {
    "text": "in hashes in your audits so that you're not doing a line by a lion comparison and really relying on that I on the on",
    "start": "2418190",
    "end": "2426020"
  },
  {
    "text": "the item potency semantics within your pipelines so that you can do this in a incremental fashion and we're gonna",
    "start": "2426020",
    "end": "2431180"
  },
  {
    "text": "spend a little bit more time talking about how you can build this how you can build this auditing for correctness in this pipeline first for auditing we",
    "start": "2431180",
    "end": "2439640"
  },
  {
    "start": "2436000",
    "end": "2436000"
  },
  {
    "text": "talked about a little bit about a checksum this math this formula here really just something that you can rely",
    "start": "2439640",
    "end": "2444680"
  },
  {
    "text": "on to guarantee that when you perform some hash or some checksum on the raw",
    "start": "2444680",
    "end": "2450230"
  },
  {
    "text": "data that the same can be that you can get the same results on the aggregated side in a previous example for our usage",
    "start": "2450230",
    "end": "2456530"
  },
  {
    "text": "records for the three different usage records that we have when we apply a checksum we can gain information around",
    "start": "2456530",
    "end": "2462380"
  },
  {
    "text": "the hashes and the checksum for the individual records themselves as well as a hash for the overall batch and at this",
    "start": "2462380",
    "end": "2469490"
  },
  {
    "text": "point you can perform an incremental check to verify that the records check sums when they are added together matches the matches the batch as well",
    "start": "2469490",
    "end": "2477290"
  },
  {
    "text": "this proffer gives you the first operating you do performing incremental and sort of armed with that information",
    "start": "2477290",
    "end": "2482410"
  },
  {
    "text": "you can persist the checksums with the index as you're building index so for",
    "start": "2482410",
    "end": "2487900"
  },
  {
    "text": "our example from the floor for each of the user indexes you're generating for each of the input batches you have a",
    "start": "2487900",
    "end": "2494140"
  },
  {
    "text": "corresponding checksum that matches the batch and when you're in the compute stage in processing side you pass that",
    "start": "2494140",
    "end": "2500050"
  },
  {
    "text": "checksum along with the source information so that when you get the aggregated result you're really",
    "start": "2500050",
    "end": "2505240"
  },
  {
    "text": "comparing the source checksums with the aggregated checksum to make sure that they're correct and if they don't match",
    "start": "2505240",
    "end": "2510730"
  },
  {
    "text": "this is really a fail quickly for that job so that you can allow so that you can go and see what's going on well everything else continues to run and so",
    "start": "2510730",
    "end": "2520630"
  },
  {
    "start": "2518000",
    "end": "2518000"
  },
  {
    "text": "that kind of concludes the the different areas of the of building out a metering",
    "start": "2520630",
    "end": "2525849"
  },
  {
    "text": "pipeline and some key takeaways so I hope to leave you with here is that in the collection stage you really focus",
    "start": "2525849",
    "end": "2533200"
  },
  {
    "text": "are you really focused on getting the data getting the usage data off of the edge as quickly as possible and you want to build an index to be able to simplify",
    "start": "2533200",
    "end": "2540670"
  },
  {
    "text": "your processing downstream you're making some early decisions in this stage so that you can make the rest of your",
    "start": "2540670",
    "end": "2545799"
  },
  {
    "text": "pipeline more flexible more resilient in the processing stage it's important from our lessons to use to DMR clusters like",
    "start": "2545799",
    "end": "2553660"
  },
  {
    "text": "your ephemeral resources you want to be able to spin them up and tear them down on an unneeded basis this allows you to",
    "start": "2553660",
    "end": "2559180"
  },
  {
    "text": "gain some this allows you to really meet the multi-tenant requirements of their system and finally for auditing and",
    "start": "2559180",
    "end": "2565930"
  },
  {
    "text": "verification it's really about auditing quickly and building using checksums as well as you're using the relying on the",
    "start": "2565930",
    "end": "2571839"
  },
  {
    "text": "item potency guarantees in your pipeline to be able to do it in an incremental fashion and with that I'm going to turn",
    "start": "2571839",
    "end": "2578440"
  },
  {
    "text": "it back over to Dan great thanks jack so I think you can see it's complicated",
    "start": "2578440",
    "end": "2586390"
  },
  {
    "text": "work to meet these requirements of scale and security and multi-tenant and",
    "start": "2586390",
    "end": "2591970"
  },
  {
    "text": "exactly once delivery and accuracy is challenging it's hard work and I hope",
    "start": "2591970",
    "end": "2598359"
  },
  {
    "text": "that these lessons that we put here can be valuable to you as you build out",
    "start": "2598359",
    "end": "2603760"
  },
  {
    "text": "systems like this that are essentially financially oriented so they have to have this control audit exact",
    "start": "2603760",
    "end": "2610599"
  },
  {
    "text": "one's type of type of behavior I think if you were able to or did build this",
    "start": "2610599",
    "end": "2618130"
  },
  {
    "text": "system for yourselves and connected it to your on-prem environment and ended up essentially with all of this usage based",
    "start": "2618130",
    "end": "2625779"
  },
  {
    "text": "metering data organized by any of the keys that you passed in originally so",
    "start": "2625779",
    "end": "2630789"
  },
  {
    "text": "organized by application ID for example organized by user ID for example or",
    "start": "2630789",
    "end": "2637319"
  },
  {
    "text": "organized by resource type however you want to do it you now have this the same",
    "start": "2637319",
    "end": "2643589"
  },
  {
    "text": "usage level data on an hourly basis that you'd be able to get from running",
    "start": "2643589",
    "end": "2648819"
  },
  {
    "text": "resources in the AWS cloud so the idea now is what what do you get if you",
    "start": "2648819",
    "end": "2654460"
  },
  {
    "text": "combine those two data sources now you can compare your effectiveness on an",
    "start": "2654460",
    "end": "2660190"
  },
  {
    "text": "apples-to-apples basis you can see how applications are using resources in your own on Prem data center versus how",
    "start": "2660190",
    "end": "2666670"
  },
  {
    "text": "they're using them in the cloud and that way you can prioritize which workloads I",
    "start": "2666670",
    "end": "2672539"
  },
  {
    "text": "guess I should say if any because I know there are some out there that can do",
    "start": "2672539",
    "end": "2677769"
  },
  {
    "text": "things better in their own data center so prioritized workloads that are optimal for moving into the cloud that",
    "start": "2677769",
    "end": "2684700"
  },
  {
    "text": "would be the benefit of doing this I think again it would also give you the",
    "start": "2684700",
    "end": "2692680"
  },
  {
    "text": "ability to access data about your own on Prem operation or your operation that",
    "start": "2692680",
    "end": "2699700"
  },
  {
    "text": "you may have in a different cloud and join cloud or Microsoft cloud whatever the case may be it allows you to",
    "start": "2699700",
    "end": "2706900"
  },
  {
    "text": "understand what's happening on a per application or a per user basis allows",
    "start": "2706900",
    "end": "2713680"
  },
  {
    "text": "you to provide controls audits financial controls understanding what's going on",
    "start": "2713680",
    "end": "2720239"
  },
  {
    "text": "allows you to optimize your spend because now you can understand what",
    "start": "2720239",
    "end": "2725440"
  },
  {
    "text": "you're actually using who's using what where why and when and ultimately use",
    "start": "2725440",
    "end": "2732640"
  },
  {
    "text": "that data that you have to allocate costs back to the rightful owners within your own or",
    "start": "2732640",
    "end": "2738250"
  },
  {
    "text": "sation so with that thank you Jack and I",
    "start": "2738250",
    "end": "2743680"
  },
  {
    "text": "will be here for a few minutes after the talk if you have questions we'd be delighted to take them thank you",
    "start": "2743680",
    "end": "2749530"
  },
  {
    "text": "[Applause]",
    "start": "2749530",
    "end": "2753659"
  }
]
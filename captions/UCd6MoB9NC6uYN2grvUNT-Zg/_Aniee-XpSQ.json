[
  {
    "text": "welcome everybody thank you for joining our talk on dating a data science I'm David I'm lead on the data team at",
    "start": "30",
    "end": "6839"
  },
  {
    "text": "coffee meets bagel dating app Daniel is our machine learning engineer we're gonna be talking today a little bit",
    "start": "6839",
    "end": "12750"
  },
  {
    "text": "about how we use elastic hash as part of our recommendation pipeline to deliver high quality match recommendations to",
    "start": "12750",
    "end": "18810"
  },
  {
    "text": "our users I'm pretty be giving you guys brief intro on coffee meets bagel and on Redis and ElastiCache and I'll be",
    "start": "18810",
    "end": "24240"
  },
  {
    "text": "handing it off to Daniel for some of the more technical details bear with us with for the early parts I think the meat of the presentation is in the latter half",
    "start": "24240",
    "end": "30210"
  },
  {
    "text": "and for parts you probably most interested in that's really where the the good stuff is so yeah this is the",
    "start": "30210",
    "end": "39030"
  },
  {
    "text": "intro I'm gonna give you the introduction of what coffee makes bagels mission is all about how we are using data science at coffee meets bagel and",
    "start": "39030",
    "end": "45239"
  },
  {
    "text": "then finally some of the considerations for implementing these systems at scale so coffee meets bagel we are dating app",
    "start": "45239",
    "end": "52500"
  },
  {
    "text": "if you aren't familiar with us and our whole thing is we value quality over quantity so we don't have an infinite",
    "start": "52500",
    "end": "58469"
  },
  {
    "text": "feed of users that you can scroll through we only provide a fixed number of matches per day for male users that's",
    "start": "58469",
    "end": "63600"
  },
  {
    "text": "up to twenty one per day for female users it's up to six and as part of this constraint of only showing a limited",
    "start": "63600",
    "end": "69720"
  },
  {
    "text": "number of matches per day we are it's important for us to have a very high level of quality with the matches that",
    "start": "69720",
    "end": "75570"
  },
  {
    "text": "we provide for our users so our mission is really to create meaningful connections between people we're not just trying to optimize for likes for",
    "start": "75570",
    "end": "82049"
  },
  {
    "text": "users we really want people to meet chat and actually go out on dates and get in relationships today we have signed up",
    "start": "82049",
    "end": "88380"
  },
  {
    "text": "millions of users and we've made tens of millions of connections so data science",
    "start": "88380",
    "end": "93810"
  },
  {
    "text": "at coffee meets bagel as you might imagine the main problem we're trying to solve on the data team is the matching",
    "start": "93810",
    "end": "98820"
  },
  {
    "text": "algorithm so there's a couple different ways that we talked about this so we describe the system is both a",
    "start": "98820",
    "end": "105149"
  },
  {
    "text": "two-way matching algorithm there's one pipeline that we work on and then also a one-way recommendation system the way to",
    "start": "105149",
    "end": "110700"
  },
  {
    "text": "think about this is as you can imagine for a company like Amazon potentially Netflix for recommendation system you",
    "start": "110700",
    "end": "115740"
  },
  {
    "text": "have a set of users and you have an inventory of products and you're trying to recommend relevant products to those",
    "start": "115740",
    "end": "121049"
  },
  {
    "text": "users that's what we call a one-way recommendation system for a two-way system we actually are trying to connect",
    "start": "121049",
    "end": "126689"
  },
  {
    "text": "to people so we actually have to take into the account the Preferences of to individual people and this adds an additional level of complexity for",
    "start": "126689",
    "end": "132590"
  },
  {
    "text": "solving this problem so that's really been the brunt of what the team has been focused on but that",
    "start": "132590",
    "end": "138150"
  },
  {
    "text": "said the team works on other problems like pretend predicting user retention or churn measuring attractiveness of",
    "start": "138150",
    "end": "143730"
  },
  {
    "text": "users via facial features we've done some experiments using collaborative filtering on similar faces looking at",
    "start": "143730",
    "end": "149340"
  },
  {
    "text": "the history of users that you'd like to try and recommend people who would look similar to those you like and yeah in",
    "start": "149340",
    "end": "154890"
  },
  {
    "text": "the future we are still looking to solve some other problems right now we use some simple heuristics to try and",
    "start": "154890",
    "end": "160500"
  },
  {
    "text": "identify scammers using our app but we'd like to have some more sophisticated models to try and more identify abusive",
    "start": "160500",
    "end": "167160"
  },
  {
    "text": "users earlier on along those lines finding inappropriate content in our app now that we have both video and photo",
    "start": "167160",
    "end": "173580"
  },
  {
    "text": "it's really critical for us to be able to remove this content ASAP and so we'd like to help the human raters that we",
    "start": "173580",
    "end": "178950"
  },
  {
    "text": "already use to do this moderation to try and bring attention to particularly a content that's particularly likely to be",
    "start": "178950",
    "end": "185190"
  },
  {
    "text": "abusive or inappropriate and then finally we just want to do more with our media in the future you know we aren't",
    "start": "185190",
    "end": "190560"
  },
  {
    "text": "doing as much as we could be with with both photo content and now that we have video content we'd really like to extract some more information from that",
    "start": "190560",
    "end": "197250"
  },
  {
    "text": "media as input into our various models so in terms of technical challenges for",
    "start": "197250",
    "end": "203400"
  },
  {
    "text": "us as you might imagine and for a lot of businesses this really just comes down to scale so you know we have millions of",
    "start": "203400",
    "end": "208560"
  },
  {
    "text": "users but in our context since our users are effectively our products you can imagine we now have potentially billions",
    "start": "208560",
    "end": "214950"
  },
  {
    "text": "of potential matches for our our matches that we'd have to calculate without any logic backing about how we go about",
    "start": "214950",
    "end": "222239"
  },
  {
    "text": "providing recommendations for our users and so really what we'd like to be able to do is to be able to refresh all of",
    "start": "222239",
    "end": "228600"
  },
  {
    "text": "our recommendations on a daily basis to take into account all the most recent information that we have and that's high",
    "start": "228600",
    "end": "234540"
  },
  {
    "text": "throughput is really the goal of what we're trying to achieve with us and obviously reliability and low maintenance so just walking sort of",
    "start": "234540",
    "end": "241080"
  },
  {
    "text": "backwards through our funnel here you know today we've created roughly a hundred thousand people reporting that",
    "start": "241080",
    "end": "246780"
  },
  {
    "text": "there and having relationships and couples with 300 million messages exchanged and more than a billion",
    "start": "246780",
    "end": "252090"
  },
  {
    "text": "introductions that have been made through our app so I know a lot of you",
    "start": "252090",
    "end": "257489"
  },
  {
    "text": "probably are familiar with Redis or ElastiCache I'm just going to do a sort of quick primer for those who aren't as familiar with it so yeah Redis as you",
    "start": "257489",
    "end": "266190"
  },
  {
    "text": "may know is open sources in mmm a key value store by being in Mary the advantage is that it's very very fast",
    "start": "266190",
    "end": "272580"
  },
  {
    "text": "low latency but potentially a little bit expensive we can achieve high availability with it and now that Redis",
    "start": "272580",
    "end": "280110"
  },
  {
    "text": "has cluster capability we can do horizontal scaling there's also a number of primitive data types in Redis that we",
    "start": "280110",
    "end": "287759"
  },
  {
    "text": "are leveraging beyond just the key basic key value functionality getting into some of those that you may not have used",
    "start": "287759",
    "end": "294770"
  },
  {
    "text": "sorted sets are something that Daniel get into a little bit later in terms of how we're using in a couple different capacities but sorted sets are",
    "start": "294770",
    "end": "302789"
  },
  {
    "text": "effectively you can think of as a priority queue so we can add items to a set but we can also assign a priority to",
    "start": "302789",
    "end": "308490"
  },
  {
    "text": "it and then we can do queries in constant time to do for instance range queries or we can pull items from the",
    "start": "308490",
    "end": "314219"
  },
  {
    "text": "front of the queue all in constant time so the basic example here we're adding four items to a sorted set each with a",
    "start": "314219",
    "end": "319530"
  },
  {
    "text": "different priority between 0 and 2 and then we do a range query on the set to figure out which items are actually in",
    "start": "319530",
    "end": "325229"
  },
  {
    "text": "the queue in addition breast has just basic sets with basic sets you can add",
    "start": "325229",
    "end": "331110"
  },
  {
    "text": "any items and then you can do general set queries that you might like to do so in our context Center query which is a",
    "start": "331110",
    "end": "336810"
  },
  {
    "text": "set intersection between two set keys will return any overlapping items between the two sets finally in terms of",
    "start": "336810",
    "end": "344639"
  },
  {
    "text": "geospatial query we're using reticences geo sorted sets and this allows us to",
    "start": "344639",
    "end": "350190"
  },
  {
    "text": "add items to these sets at a given latitude and longitude once those items",
    "start": "350190",
    "end": "355590"
  },
  {
    "text": "and add it to a geo sorted set we can do radius queries on those sets in order to find all of the items in that set that",
    "start": "355590",
    "end": "361740"
  },
  {
    "text": "are within a given radius of the location input it as for ElastiCache",
    "start": "361740",
    "end": "368219"
  },
  {
    "text": "alaska is Amazon's a hosted version of either Redis or memcache and great thing",
    "start": "368219",
    "end": "374460"
  },
  {
    "text": "about less cache is it can hold a lot of information in memory it's really really easy to set up and in terms of",
    "start": "374460",
    "end": "381449"
  },
  {
    "text": "operational considerations automatically detecting and replacing failed knows is really convenient means not as much",
    "start": "381449",
    "end": "387229"
  },
  {
    "text": "hands-on work well for our DevOps team and then finally scaling it with no downtime is a great asset for us so this",
    "start": "387229",
    "end": "395909"
  },
  {
    "text": "point I'm gonna hand it off to Daniel he's going to get into some of the real good meat of the presentation about how we're currently leveraging lasso cash so",
    "start": "395909",
    "end": "401780"
  },
  {
    "text": "Thanks all right thank you very much David all right thank you all for being",
    "start": "401780",
    "end": "406950"
  },
  {
    "text": "here so now we're going to get into the nitty-gritty of of our challenges we're gonna look at how red is an elastic cash",
    "start": "406950",
    "end": "414050"
  },
  {
    "text": "helped us solve some of the really challenging problems that we have here which is which is you know giving high",
    "start": "414050",
    "end": "420330"
  },
  {
    "text": "quality matches at scale but before we do that let's let's start with the with",
    "start": "420330",
    "end": "425460"
  },
  {
    "text": "the basics okay so what is the CMB data team trying to achieve at a higher level",
    "start": "425460",
    "end": "431180"
  },
  {
    "text": "at a high level we're trying to give you the highest quality matches serve to our mobile clients as fast as possible why",
    "start": "431180",
    "end": "439110"
  },
  {
    "text": "is this well because it's it's computationally infeasible for us to calculate the best match for you on",
    "start": "439110",
    "end": "444630"
  },
  {
    "text": "demand we have business logic we have the score calculation components it's",
    "start": "444630",
    "end": "449940"
  },
  {
    "text": "basically very hard to do this immediately for the mobile clients so what do we have to do we have to",
    "start": "449940",
    "end": "455610"
  },
  {
    "text": "calculate these scores upfront right from a technical standpoint this looks",
    "start": "455610",
    "end": "461010"
  },
  {
    "text": "like every user having one or more Q's each Q has one or more recommendations",
    "start": "461010",
    "end": "467880"
  },
  {
    "text": "and these recommendations are sorted by score where a higher score is a better match right and just to set it just to",
    "start": "467880",
    "end": "476340"
  },
  {
    "text": "set the tone here in the audience I want to tell you where does the score come",
    "start": "476340",
    "end": "481500"
  },
  {
    "text": "from right so this call comes from two main components we had the feature vectors and we have the classifiers or",
    "start": "481500",
    "end": "488580"
  },
  {
    "text": "morals so the feature vectors just think of them as ident this this this vector",
    "start": "488580",
    "end": "495240"
  },
  {
    "text": "of numbers that identifies a user right and every user has one or more of these",
    "start": "495240",
    "end": "500730"
  },
  {
    "text": "each of these feature is is a specific characteristic of the user right",
    "start": "500730",
    "end": "506640"
  },
  {
    "text": "demographic features like for example the user being told but we also have behavioral features like the user being",
    "start": "506640",
    "end": "513750"
  },
  {
    "text": "popular that's based on on historical analysis right just think of a feature vector as being the DNA of a user and",
    "start": "513750",
    "end": "520789"
  },
  {
    "text": "then we have the classifiers and these classifiers are trained using a lot of historical data and they understand how",
    "start": "520790",
    "end": "528570"
  },
  {
    "text": "much every feature weighs in the in the in the context of a match the higher the",
    "start": "528570",
    "end": "535410"
  },
  {
    "text": "the higher the feature is in the classifier the the more important it is right so let's look at let's look at an",
    "start": "535410",
    "end": "542339"
  },
  {
    "text": "example here so here we have three features here is popular is tall and is engineer as you can see here is popular",
    "start": "542339",
    "end": "549839"
  },
  {
    "text": "as the most is the most important feature it's the most indicative feature in in the scope of a match right and I'm",
    "start": "549839",
    "end": "556470"
  },
  {
    "text": "sorry for all the engineers out here but is engineer doesn't really help sorry about that",
    "start": "556470",
    "end": "563060"
  },
  {
    "text": "well how do we perform a score well what we do is to calculate the score between",
    "start": "563060",
    "end": "568230"
  },
  {
    "text": "between the users we have to multiply each feature by its coefficient in the",
    "start": "568230",
    "end": "573750"
  },
  {
    "text": "classifier and then we sum everything up all together and that gives us one score here so in this case it's 0.5 all right",
    "start": "573750",
    "end": "582839"
  },
  {
    "text": "so now let's look at coffee meets bagel from a bird's eye view what is our data pipeline look like as",
    "start": "582839",
    "end": "589740"
  },
  {
    "text": "you can see there are two main components here we have the batch component and we have the real-time component the batch component is a set",
    "start": "589740",
    "end": "596879"
  },
  {
    "text": "of cron jobs that kicks off at 7:30 a.m. in the morning and it takes around 15 to 20 hours to run our feature extractor",
    "start": "596879",
    "end": "604350"
  },
  {
    "text": "processes extract data from our data warehouse which in this case is redshift we take that data we transform it and we",
    "start": "604350",
    "end": "611910"
  },
  {
    "text": "build features for our users this happens every day once we build those",
    "start": "611910",
    "end": "617130"
  },
  {
    "text": "features we store them into an offline storage for later use and then we have",
    "start": "617130",
    "end": "622800"
  },
  {
    "text": "the real-time component add the real-time component there is a there is one part which is really important",
    "start": "622800",
    "end": "629220"
  },
  {
    "text": "crucial to all this the heart is the recommender workers and these workers they take profile IDs of the of our",
    "start": "629220",
    "end": "635910"
  },
  {
    "text": "priority queue and for every profile ID they have one responsibility find and generate recommendations for that",
    "start": "635910",
    "end": "643290"
  },
  {
    "text": "profile ID and store them for later use all right so that's from now on what",
    "start": "643290",
    "end": "650399"
  },
  {
    "text": "we're going to do is we're going to look at some of the challenges here as you can see that a lot of ours in in this in",
    "start": "650399",
    "end": "656129"
  },
  {
    "text": "this presentation and each of these has something to do with Redis and elastic cash we're going to go through them one",
    "start": "656129",
    "end": "662129"
  },
  {
    "text": "by one and we're gonna we're going to outline the problem and the associated solution that we found let's",
    "start": "662129",
    "end": "668450"
  },
  {
    "text": "with the first one all right invalid matches so our users are very very picky",
    "start": "668450",
    "end": "674000"
  },
  {
    "text": "in the matches they want right they tell us their criteria their tell us their",
    "start": "674000",
    "end": "679430"
  },
  {
    "text": "location and most importantly they don't want to see users that they've already seen before if I am in San Francisco I",
    "start": "679430",
    "end": "687410"
  },
  {
    "text": "most probably want to date someone which is in San Francisco don't want to date someone from New York and if I've",
    "start": "687410",
    "end": "692930"
  },
  {
    "text": "already seen a user and passed passed on that user in the past I don't want to see that user again right and most",
    "start": "692930",
    "end": "699920"
  },
  {
    "text": "importantly we cannot afford to score matches that that we that are invalid",
    "start": "699920",
    "end": "706310"
  },
  {
    "text": "because we end up with with a quadratic problem here so we definitely need to filter down and narrow down the matches",
    "start": "706310",
    "end": "713030"
  },
  {
    "text": "that we want to score as much as possible let's start with the first component here how do we how do we fetch",
    "start": "713030",
    "end": "719750"
  },
  {
    "text": "the users how do we fetch the potential recommendations well the first step here",
    "start": "719750",
    "end": "725630"
  },
  {
    "text": "is finding users that are eligible for our location right how do we do this",
    "start": "725630",
    "end": "730760"
  },
  {
    "text": "well in Redis we have four geo sorted sets of active users one for each gender",
    "start": "730760",
    "end": "737330"
  },
  {
    "text": "and gender preference right so me male looking for female female looking for",
    "start": "737330",
    "end": "742940"
  },
  {
    "text": "male male looking for male and female looking for female right each of these",
    "start": "742940",
    "end": "748160"
  },
  {
    "text": "sets contains the active users when I need to search for for the my potential",
    "start": "748160",
    "end": "756080"
  },
  {
    "text": "matches all I do is I perform a Geo radius query which allows us to efficiently fetch candidates that MIT",
    "start": "756080",
    "end": "762320"
  },
  {
    "text": "that meet that criteria let me give you an example so I'm a straight male in San Francisco and Mike my max criteria I",
    "start": "762320",
    "end": "770480"
  },
  {
    "text": "want to date someone which is within 50 miles of my location so they perform a Geo radius query with the bucket",
    "start": "770480",
    "end": "777440"
  },
  {
    "text": "female towards male with a longitude or latitude of San Francisco and a distance",
    "start": "777440",
    "end": "782870"
  },
  {
    "text": "of 50 miles bear in mind just to recap I'm I'm a straight male so I'm looking for a",
    "start": "782870",
    "end": "789320"
  },
  {
    "text": "female towards male female looking for male and so I will pick in the bucket",
    "start": "789320",
    "end": "794480"
  },
  {
    "text": "which is female towards male just this step allows us to reduce the number of candidates from 1 million to 10",
    "start": "794480",
    "end": "802070"
  },
  {
    "text": "thousand this is pretty huge all right so then we get disaster candidates but",
    "start": "802070",
    "end": "809270"
  },
  {
    "text": "we still have another another challenge here we want to make sure that that that the recommendations that we serve to a",
    "start": "809270",
    "end": "815600"
  },
  {
    "text": "user are not recommendations that we've already served to our user in the past and so we need to find a space efficient",
    "start": "815600",
    "end": "822410"
  },
  {
    "text": "way to filter out those recommendations bloom filters are these probabilistic data structures that effectively check",
    "start": "822410",
    "end": "829910"
  },
  {
    "text": "set membership really really fast and very efficiently right at the cost of false positives though we don't get",
    "start": "829910",
    "end": "834980"
  },
  {
    "text": "anything for free here what do these look like under the hood under the hood they're a bit vector and each bloom",
    "start": "834980",
    "end": "842300"
  },
  {
    "text": "filter has one or more hash functions and these hash functions except a a hashable item and return a specific",
    "start": "842300",
    "end": "849500"
  },
  {
    "text": "index of the bit vector let me give you an example of of two common operations",
    "start": "849500",
    "end": "856310"
  },
  {
    "text": "that we want to do with our bit vectors add an item to the bit vector and check the membership check if an item is",
    "start": "856310",
    "end": "863480"
  },
  {
    "text": "already present in that bloom filter so to add an item let's say here we want to add ID 25 and we this bloom filter has",
    "start": "863480",
    "end": "871520"
  },
  {
    "text": "two hashing functions all right the first hashing function tells us to set the bit at index one the second hash",
    "start": "871520",
    "end": "880430"
  },
  {
    "text": "function tells us to set the bit at index four we calculate these upfront",
    "start": "880430",
    "end": "886010"
  },
  {
    "text": "and then we know exactly what bits to set and we set those bits to one remember a bloom filter starts with all",
    "start": "886010",
    "end": "891800"
  },
  {
    "text": "bits set to zero then we have our second ID here ID 57 do the same operation we",
    "start": "891800",
    "end": "897920"
  },
  {
    "text": "calculate that the outputs of the hashes which is index four and index seven and",
    "start": "897920",
    "end": "903890"
  },
  {
    "text": "we set those bits now we want to actually check membership when we want",
    "start": "903890",
    "end": "909500"
  },
  {
    "text": "to actually check if a specific bit if a specific user is inside the bit vector",
    "start": "909500",
    "end": "915470"
  },
  {
    "text": "then what we do is the same operation we calculate the hash functions and we",
    "start": "915470",
    "end": "920900"
  },
  {
    "text": "calculate the bits that we need to that we need to check and we just check that all those bits are set to one if any of",
    "start": "920900",
    "end": "928400"
  },
  {
    "text": "those bits are is not set to one then we know for sure that that item is not present in the bit vector",
    "start": "928400",
    "end": "935300"
  },
  {
    "text": "if all those bits are set to 1 then we know with a certain probability that the",
    "start": "935300",
    "end": "940790"
  },
  {
    "text": "item is present inside the bit factor and as I said here we have a risk of fall positive here as you can see both I",
    "start": "940790",
    "end": "948140"
  },
  {
    "text": "D 25 a 1957 have one hash function which sets the specific bit so that there is a",
    "start": "948140",
    "end": "955280"
  },
  {
    "text": "risk of false positives here when we when we check what are the pros and cons of this the process obviously space",
    "start": "955280",
    "end": "961340"
  },
  {
    "text": "efficiency right we know we allocate these bit vectors upfront so we know exactly how much we can account for it",
    "start": "961340",
    "end": "966980"
  },
  {
    "text": "for future scalability for future organic growth the concert is obviously",
    "start": "966980",
    "end": "972140"
  },
  {
    "text": "the probability of false positives but these are tunable through some parameters of the bloom filters when we",
    "start": "972140",
    "end": "978320"
  },
  {
    "text": "create them so how do these bloom filters how are they used in coffee",
    "start": "978320",
    "end": "983480"
  },
  {
    "text": "meets bagel well every user in coffee meets bagel has a bloom filter let's call this the exclusion bloom filter",
    "start": "983480",
    "end": "989110"
  },
  {
    "text": "every time a user sees a recommendation in our app that recommendation ID is added to the bloom filter and these",
    "start": "989110",
    "end": "996770"
  },
  {
    "text": "bloom filters live entirely inside of Redis luckily we have some Python code",
    "start": "996770",
    "end": "1003070"
  },
  {
    "text": "around it Python is the programming language of our infrastructure and we have some",
    "start": "1003070",
    "end": "1008350"
  },
  {
    "text": "Python code a wrapper around these bloom filters that is able to compute all the",
    "start": "1008350",
    "end": "1014320"
  },
  {
    "text": "hash functions up front and then just perform set bit operations on the on the",
    "start": "1014320",
    "end": "1022120"
  },
  {
    "text": "Redis key that we want to address right and just to put into context set bit is a specific is is a is a is a function",
    "start": "1022120",
    "end": "1029140"
  },
  {
    "text": "inside of Redis is the operation inside of Redis that allows us to set a specific bit of a red is key so every",
    "start": "1029140",
    "end": "1035770"
  },
  {
    "text": "time we have to add a user we calculate all the all the bits that we have to set in our hash function and then all we do",
    "start": "1035770",
    "end": "1041350"
  },
  {
    "text": "is we just put issue set bit operations and we can do that also in a pipeline to make it more efficient then when we need",
    "start": "1041350",
    "end": "1048550"
  },
  {
    "text": "to check membership well luckily we always do this in batch right every time we will have to check membership we",
    "start": "1048550",
    "end": "1054940"
  },
  {
    "text": "always have a lot of candidates that we need to that we need to check for so then what we do is we just read the",
    "start": "1054940",
    "end": "1061630"
  },
  {
    "text": "entire bloom filter in memory once and we perform all the checks in our Python",
    "start": "1061630",
    "end": "1067210"
  },
  {
    "text": "code so it's very very efficient from an i/o perspective just to show you this is",
    "start": "1067210",
    "end": "1072620"
  },
  {
    "text": "what our code looks like right so this is a Python function that accepts one",
    "start": "1072620",
    "end": "1078440"
  },
  {
    "text": "argument which is the candidate IDs just think of it as a collection of profile IDs that we want to check for membership",
    "start": "1078440",
    "end": "1084169"
  },
  {
    "text": "inside the bloom filter the output of this function returns a subset of those IDs that for sure are not inside the",
    "start": "1084169",
    "end": "1091010"
  },
  {
    "text": "bloom filter what I love to what I'd love to show you here is how simple this",
    "start": "1091010",
    "end": "1096500"
  },
  {
    "text": "this Python code is as you can see we iterate over the candidate IDs for every",
    "start": "1096500",
    "end": "1101870"
  },
  {
    "text": "candidate ID we just calculate the hash positions and we just check if that if that bit at a specific hash position is",
    "start": "1101870",
    "end": "1108679"
  },
  {
    "text": "set if any of those bits is not set we know for sure that we need to include that item inside the bloom filter and as",
    "start": "1108679",
    "end": "1115159"
  },
  {
    "text": "I said we're okay with false positives here now the great thing about this code",
    "start": "1115159",
    "end": "1121250"
  },
  {
    "text": "is that we only do one read from reddit that's huge because we don't have to",
    "start": "1121250",
    "end": "1126260"
  },
  {
    "text": "perform like complex like send intersections and stuff like that we read the entire bloom filter in memory",
    "start": "1126260",
    "end": "1131330"
  },
  {
    "text": "and we know exactly how much the space is in front all right so let's get to",
    "start": "1131330",
    "end": "1136580"
  },
  {
    "text": "another challenge here so before I was showing you our classifiers I will show you a linear classifier right and these",
    "start": "1136580",
    "end": "1143690"
  },
  {
    "text": "models are very very compact they're very compact to store a coffee meets",
    "start": "1143690",
    "end": "1148820"
  },
  {
    "text": "bagel though we also use very non compact classifiers like in this case we",
    "start": "1148820",
    "end": "1153919"
  },
  {
    "text": "use our ALS classifier which is which is used to perform collaborative filtering these classifiers not only are very very",
    "start": "1153919",
    "end": "1161840"
  },
  {
    "text": "huge to store in memory but also grow linearly based quadratically based on our user base right they're pretty big",
    "start": "1161840",
    "end": "1168140"
  },
  {
    "text": "and most importantly by serializing this",
    "start": "1168140",
    "end": "1173840"
  },
  {
    "text": "to to disk or to memory or whatever you want and reloading it inside our workers",
    "start": "1173840",
    "end": "1179120"
  },
  {
    "text": "is very very expensive operation right and we don't have to bring a lot of dependencies with us so is there any way",
    "start": "1179120",
    "end": "1186980"
  },
  {
    "text": "we can train these classifiers and then use a instead of having to like reload",
    "start": "1186980",
    "end": "1192500"
  },
  {
    "text": "them in memory just to use a predict function it's any way we can do this more efficiently well it turns out that",
    "start": "1192500",
    "end": "1199279"
  },
  {
    "text": "the a OS classifier is mainly composed once trained of two",
    "start": "1199279",
    "end": "1205419"
  },
  {
    "text": "matrices the U and the V matrix and it turns out that to compute one score between a user and their recommendation",
    "start": "1205419",
    "end": "1212799"
  },
  {
    "text": "all we need is two vectors one from one matrix and one from the other we take",
    "start": "1212799",
    "end": "1218140"
  },
  {
    "text": "those two matrices and we could perform a dot product and we get the score between those two users so what we do is",
    "start": "1218140",
    "end": "1223690"
  },
  {
    "text": "this we train we train the classifier in the traditional way but then what we do",
    "start": "1223690",
    "end": "1228760"
  },
  {
    "text": "is we decompose the classifier and we get both matrices the U and the V and we save every row we serialize every row",
    "start": "1228760",
    "end": "1235929"
  },
  {
    "text": "and we save it in Redis at a different key right so every row has a specific key then in our recommender workers when",
    "start": "1235929",
    "end": "1243610"
  },
  {
    "text": "we have to compute the scores between two users all we do is fetch those two vectors that we care about and perform",
    "start": "1243610",
    "end": "1249130"
  },
  {
    "text": "the dot product it's very very efficient and and you know if you think about it also from a memory perspective we don't",
    "start": "1249130",
    "end": "1255100"
  },
  {
    "text": "have to load an entire classifier a lot of rows that we'd never use we only use a subset of those rows and this was",
    "start": "1255100",
    "end": "1262450"
  },
  {
    "text": "really great and also if one day we don't want to use spark anymore we as long as this as long as the new",
    "start": "1262450",
    "end": "1268150"
  },
  {
    "text": "classifier supports this concept of matrix factorization is made out of these matrices that can be decomposed we",
    "start": "1268150",
    "end": "1274120"
  },
  {
    "text": "can perform the same operation all right so now we know how to fetch these",
    "start": "1274120",
    "end": "1280540"
  },
  {
    "text": "recommendations we know how to filter them down to remove ones that we've",
    "start": "1280540",
    "end": "1285640"
  },
  {
    "text": "already seen and we know how to calculate the scores but we still got a per system and if you think about it if",
    "start": "1285640",
    "end": "1291250"
  },
  {
    "text": "you consider our user bases being around let's say 1 million active users and for",
    "start": "1291250",
    "end": "1297220"
  },
  {
    "text": "every active user we want to have a backlog of at least a thousand recommendations to be served well then",
    "start": "1297220",
    "end": "1302650"
  },
  {
    "text": "we have 1 billion matches that we need to that we need to persist that's a huge number and most importantly we said we",
    "start": "1302650",
    "end": "1309790"
  },
  {
    "text": "want to refresh these recommendations organically in a regular fashion right and so the the data store that we use to",
    "start": "1309790",
    "end": "1318520"
  },
  {
    "text": "persist these recommendations need to need to address our our high update frequency and moderate delay deletion",
    "start": "1318520",
    "end": "1325480"
  },
  {
    "text": "but most importantly it's going to be update and creation right and then obviously when the clients ask for this",
    "start": "1325480",
    "end": "1331270"
  },
  {
    "text": "information we want to serve it as fast as possible so we want to make sure that there's low latency when the web's read this read this",
    "start": "1331270",
    "end": "1338050"
  },
  {
    "text": "information so what did we start with we started with Cassandra and the reason",
    "start": "1338050",
    "end": "1345760"
  },
  {
    "text": "we started with Cassandra is because we have a good in-house knowledge of how Cassandra works we've already using it and also there",
    "start": "1345760",
    "end": "1352780"
  },
  {
    "text": "were two main things which is you know it's made for high right volume and low latency on reads right so that was",
    "start": "1352780",
    "end": "1358810"
  },
  {
    "text": "really huge for us but we had we had two main issues with Cassandra the first",
    "start": "1358810",
    "end": "1364240"
  },
  {
    "text": "issue was the garbage collector our DevOps team was spending a lot of time chewing the garbage collector we tried",
    "start": "1364240",
    "end": "1371050"
  },
  {
    "text": "different garbage collectors on top of the JVM unfortunately we couldn't find anything that wasn't giving us partial",
    "start": "1371050",
    "end": "1378160"
  },
  {
    "text": "outages at times and then the second the second issue is as a consequence of that",
    "start": "1378160",
    "end": "1384780"
  },
  {
    "text": "as Cassandra Cassandra gives us this this this consistency this is like",
    "start": "1384780",
    "end": "1391120"
  },
  {
    "text": "eventual consistency right and we thought we could deal with that but unfortunately we found out that we can't especially when you just delete",
    "start": "1391120",
    "end": "1397060"
  },
  {
    "text": "their profiles we want to make sure that those those changes are addressed immediately so then we already had expertise with",
    "start": "1397060",
    "end": "1403960"
  },
  {
    "text": "Redis in the house we turn to Redis and what we ended up having is using sorted",
    "start": "1403960",
    "end": "1411580"
  },
  {
    "text": "sets to store our queues of recommendation what does this look like well we have one sorted set per model",
    "start": "1411580",
    "end": "1418420"
  },
  {
    "text": "per user right and each of these sorted sets stores the recommendation IDs",
    "start": "1418420",
    "end": "1424480"
  },
  {
    "text": "sorted by score right and this is here is an example of the syntax here to add",
    "start": "1424480",
    "end": "1431440"
  },
  {
    "text": "a recommendation as you can see it also the the curly braces here are used as a cluster syntax so this will also short",
    "start": "1431440",
    "end": "1438460"
  },
  {
    "text": "horizontally this was really great for us because it allowed us to use the",
    "start": "1438460",
    "end": "1444820"
  },
  {
    "text": "technology that we were already familiar with and and persist these recommendations in a fairly simple way",
    "start": "1444820",
    "end": "1450730"
  },
  {
    "text": "right and another thing I wanted to say about this is that the cost of of",
    "start": "1450730",
    "end": "1458020"
  },
  {
    "text": "actually holding this data in memory wasn't substantially more than our",
    "start": "1458020",
    "end": "1463990"
  },
  {
    "text": "Cassandra cluster with the added value that obviously this is all in memory so it does support our are you",
    "start": "1463990",
    "end": "1469900"
  },
  {
    "text": "patterns right low-latency read in high-throughput writes it does support that alright so let's go on to another",
    "start": "1469900",
    "end": "1476500"
  },
  {
    "text": "challenges which is set intersections between mutual friends so based on our",
    "start": "1476500",
    "end": "1482590"
  },
  {
    "text": "data we find out that mutual friends is a really important aspect to consider",
    "start": "1482590",
    "end": "1487840"
  },
  {
    "text": "when serving a match right users love to find recommendations so they have",
    "start": "1487840",
    "end": "1493750"
  },
  {
    "text": "something in common it's some level of proximity right and that's where mutual friends comes into play we want to make",
    "start": "1493750",
    "end": "1500830"
  },
  {
    "text": "sure that when we serve matches we consider the factor that users may have mutual friends between them and we want",
    "start": "1500830",
    "end": "1506800"
  },
  {
    "text": "to prioritize those matches right so what work what happens here when you when you signup to coffee meets bagel we",
    "start": "1506800",
    "end": "1513880"
  },
  {
    "text": "ask permission to download your Facebook friends list if you give us that permission then we're gonna download",
    "start": "1513880",
    "end": "1520230"
  },
  {
    "text": "that Facebook friend we're gonna add it to a set inside of Redis right now",
    "start": "1520230",
    "end": "1525730"
  },
  {
    "text": "there's a sad truth about mutual friends which is unfortunately only like three percent of the possible matches between",
    "start": "1525730",
    "end": "1534310"
  },
  {
    "text": "two users have mutual friends right it's very very low but you know everyone knows here on Facebook you have like",
    "start": "1534310",
    "end": "1540700"
  },
  {
    "text": "three thousand friends right every user has like three thousand friends so it's it's very very inefficient to have to",
    "start": "1540700",
    "end": "1546670"
  },
  {
    "text": "download on the on our on our on our processes on our worker process to download the entire sets of two users to",
    "start": "1546670",
    "end": "1553630"
  },
  {
    "text": "then perform an intersection right just think of the amount of i/o operations that you're doing the amount of i/o to",
    "start": "1553630",
    "end": "1560350"
  },
  {
    "text": "download these sets of like three thousand people each to then perform an intersection in your code right so it",
    "start": "1560350",
    "end": "1567880"
  },
  {
    "text": "turns out that Redis has a sinter operation and what's good about the center operation is that it accepts two",
    "start": "1567880",
    "end": "1575320"
  },
  {
    "text": "sets and it just returned the intersection between those two sets right so in this case we're intersecting",
    "start": "1575320",
    "end": "1581560"
  },
  {
    "text": "the set of user a and user B and we just get the output of the intersection there",
    "start": "1581560",
    "end": "1586780"
  },
  {
    "text": "are two great things about this approach the first great thing is the obviously the amount of i/o that comes back to us",
    "start": "1586780",
    "end": "1592600"
  },
  {
    "text": "is minimal right as I said only three percent of matches have some kind of mutual friends so we're we're reducing",
    "start": "1592600",
    "end": "1598390"
  },
  {
    "text": "the amount of IO to very minimal on the other side though a great thing",
    "start": "1598390",
    "end": "1603770"
  },
  {
    "text": "is that it also simplifies our application code a lot because we're just issuing an operation and delegating",
    "start": "1603770",
    "end": "1609950"
  },
  {
    "text": "to Redis to perform that operation as efficient as possible so this was really efficient for us all right and now let",
    "start": "1609950",
    "end": "1618500"
  },
  {
    "text": "me get to the the last use case here of our presentation which is our fault",
    "start": "1618500",
    "end": "1625610"
  },
  {
    "text": "tolerant priority queues using Redis so when they are building our own in-house",
    "start": "1625610",
    "end": "1630980"
  },
  {
    "text": "queue using sorted sets and hashes and we built it with specific goals in mind",
    "start": "1630980",
    "end": "1637070"
  },
  {
    "text": "what are these goals granular prioritization scheduling tasks in",
    "start": "1637070",
    "end": "1642290"
  },
  {
    "text": "advance fault tolerance and locking and I'm going to go through all of these and I'm going to give you an example of when",
    "start": "1642290",
    "end": "1649370"
  },
  {
    "text": "you may need them for example so when you're a prioritization so we were speaking before about our recommender",
    "start": "1649370",
    "end": "1656240"
  },
  {
    "text": "queues right and that our recommender workers will take IDs off the recommender queue to generate",
    "start": "1656240",
    "end": "1661820"
  },
  {
    "text": "recommendations well that queue always has a backlog intentionally because we",
    "start": "1661820",
    "end": "1668420"
  },
  {
    "text": "always want to make sure that we refresh everyone's recommendation on a regular basis but at the same time if a user",
    "start": "1668420",
    "end": "1675500"
  },
  {
    "text": "changes their location or changes their criteria we want to prioritize that user through the queue so we wanted in",
    "start": "1675500",
    "end": "1682640"
  },
  {
    "text": "queueing API that supports a additional priority and allows us to process one",
    "start": "1682640",
    "end": "1688640"
  },
  {
    "text": "item before another regardless of when it was inserted scheduled tasks well",
    "start": "1688640",
    "end": "1696410"
  },
  {
    "text": "many times are our team wants to send some push notifications out but these",
    "start": "1696410",
    "end": "1702680"
  },
  {
    "text": "post certifications maybe want to schedule them in advance right and this are in queueing API supports an",
    "start": "1702680",
    "end": "1709760"
  },
  {
    "text": "additional timestamp parameter this timestamp parameter allows us to in queue tasks in the future regardless of",
    "start": "1709760",
    "end": "1717260"
  },
  {
    "text": "when they were inserted so an example is if I in queue push notifications with a timestamp it's 9:00 a.m. by n cube",
    "start": "1717260",
    "end": "1723200"
  },
  {
    "text": "pushes with a timestamp of noon well those pushes will never be processed until noon comes our workers know that",
    "start": "1723200",
    "end": "1730010"
  },
  {
    "text": "they don't need to process any item any task with an Associated timestamp in the future and that will happen organically",
    "start": "1730010",
    "end": "1736340"
  },
  {
    "text": "with all the retry mechanisms and it's really great for us and finally fault-tolerance obviously",
    "start": "1736340",
    "end": "1742620"
  },
  {
    "text": "everyone wants for Florence right we want to make sure that regardless of when you of when you insert the item and",
    "start": "1742620",
    "end": "1749130"
  },
  {
    "text": "when the worker process is it you know things will fail eventually but we want to make sure that if things fail there",
    "start": "1749130",
    "end": "1756179"
  },
  {
    "text": "always will be another worker that in the future is able to process that that",
    "start": "1756179",
    "end": "1761280"
  },
  {
    "text": "task at a later stage and then finally we want to make sure that there never is",
    "start": "1761280",
    "end": "1768809"
  },
  {
    "text": "just a scenario in which two workers are working on the same item at the same time for example for consistency",
    "start": "1768809",
    "end": "1776910"
  },
  {
    "text": "mechanism for race condition potential race conditions that that may it may happen so many people ask us why not use",
    "start": "1776910",
    "end": "1785130"
  },
  {
    "text": "celery and we did start with celery obviously right we're a small company remember we're Ferdie were Ferdie people",
    "start": "1785130",
    "end": "1790470"
  },
  {
    "text": "pretty people and not all of us are engineers we started with celery but we",
    "start": "1790470",
    "end": "1796620"
  },
  {
    "text": "had two main issues with celery the first issue was if you use celery with a Redis back-end there's a huge amount of",
    "start": "1796620",
    "end": "1803250"
  },
  {
    "text": "i/o going on between your workers and between the retinas box I speak about",
    "start": "1803250",
    "end": "1809370"
  },
  {
    "text": "pub/sub operations and other kind of operations it's pretty huge and a year ago we had a small outage because of it",
    "start": "1809370",
    "end": "1815700"
  },
  {
    "text": "so that wasn't really that good another reason is because celery is is a",
    "start": "1815700",
    "end": "1821760"
  },
  {
    "text": "really big project and it's got all these bells and whistles but most of the time we just want to keep things really",
    "start": "1821760",
    "end": "1826950"
  },
  {
    "text": "simple and we just have these specific use cases that we want to we want to run out here too so for the sake of",
    "start": "1826950",
    "end": "1833460"
  },
  {
    "text": "simplicity we also decided to use these priority queues just to keep it simple",
    "start": "1833460",
    "end": "1838830"
  },
  {
    "text": "and by the way for tasks that need to go in first in first out or need to be",
    "start": "1838830",
    "end": "1843929"
  },
  {
    "text": "processed as fast as possible we also use sqs which has been really grateful for us we're able to were able to scale",
    "start": "1843929",
    "end": "1851760"
  },
  {
    "text": "really well with that and our application code is very simple so yeah our our synchronous processes are all or",
    "start": "1851760",
    "end": "1858240"
  },
  {
    "text": "our fault tolerant part queues or celery or sorry or ask us now what do these",
    "start": "1858240",
    "end": "1865590"
  },
  {
    "text": "priority queues look like under the hood well they're backed by free main day",
    "start": "1865590",
    "end": "1871470"
  },
  {
    "text": "the structures here the main queue the retry queue and the backlog the main",
    "start": "1871470",
    "end": "1878010"
  },
  {
    "text": "queue contains all the items that are waiting to be processed this is a sorted set of an item sorted by priority where",
    "start": "1878010",
    "end": "1886289"
  },
  {
    "text": "priority just think of it as an integer then we have to retry Q and this retry",
    "start": "1886289",
    "end": "1892080"
  },
  {
    "text": "queue contains all the items that are being processed now this is a sorted set",
    "start": "1892080",
    "end": "1897179"
  },
  {
    "text": "of an item with an Associated timestamp and bear in mind that we try Q is going",
    "start": "1897179",
    "end": "1903090"
  },
  {
    "text": "to be also very crucial for our fault tolerance if if any process that checks",
    "start": "1903090",
    "end": "1908820"
  },
  {
    "text": "out an item then fails the item will still be present in the retry queue for later use and then we also have a",
    "start": "1908820",
    "end": "1915690"
  },
  {
    "text": "backlog right and this backlog is used if we Trotter in queue an item which is already present in the main or retry",
    "start": "1915690",
    "end": "1922080"
  },
  {
    "text": "queue this item gets added in the backlog and this is just a a hash keyed by item ID and whose values is a",
    "start": "1922080",
    "end": "1929549"
  },
  {
    "text": "timestamp and these priority queues are",
    "start": "1929549",
    "end": "1934740"
  },
  {
    "text": "then backed by three main operations right and these operations run in Lua",
    "start": "1934740",
    "end": "1940130"
  },
  {
    "text": "right so Lua is the scripting language the Redis supports what's great about it",
    "start": "1940130",
    "end": "1946799"
  },
  {
    "text": "is that it's a very very simple language to understand and it also gives us",
    "start": "1946799",
    "end": "1951840"
  },
  {
    "text": "within the lifetime of a Lua script it gives us atomicity so that's something we really love we have free operations",
    "start": "1951840",
    "end": "1958799"
  },
  {
    "text": "here in queue check out and remove let's start with the first one so when you're in queue an item you the API accepts a",
    "start": "1958799",
    "end": "1967080"
  },
  {
    "text": "item with a specific priority the in curation first looks at the main queue",
    "start": "1967080",
    "end": "1972600"
  },
  {
    "text": "and if there is it already is an item in the main queue or the retry queue then",
    "start": "1972600",
    "end": "1978179"
  },
  {
    "text": "it's added to the backlog because it means that it's already been scheduled to process we don't want to process things at the same time then we have the",
    "start": "1978179",
    "end": "1985080"
  },
  {
    "text": "checkout operation the checkout operation is called by our workers when they want to when they want to take an",
    "start": "1985080",
    "end": "1990750"
  },
  {
    "text": "item to be processed right the checkout operation does two main things the first",
    "start": "1990750",
    "end": "1997020"
  },
  {
    "text": "thing is it tries to find where to fetch the item to checkout and the second thing is it adds it for late",
    "start": "1997020",
    "end": "2003710"
  },
  {
    "text": "rescheduling in the retry queue let's go into a little bit more details so when I check out light and the first",
    "start": "2003710",
    "end": "2010160"
  },
  {
    "text": "thing I look is in the retry queue remember the retry queue is a sorted set of items sorted by time step I checked",
    "start": "2010160",
    "end": "2018590"
  },
  {
    "text": "the first item at the top of the retry queue MA and I look at its associated timestamp if that timestamp is in the",
    "start": "2018590",
    "end": "2026690"
  },
  {
    "text": "past or in the present it's not in the future then I check out that item if",
    "start": "2026690",
    "end": "2032740"
  },
  {
    "text": "every time stamp in the retry queue is in the future or the retry queue is",
    "start": "2032740",
    "end": "2038270"
  },
  {
    "text": "empty I'll pick from the top of the main queue regardless of where I pick up my item I",
    "start": "2038270",
    "end": "2043820"
  },
  {
    "text": "always add a reference of that item at the back of the retry queue and this is",
    "start": "2043820",
    "end": "2049429"
  },
  {
    "text": "because of the fault tolerance and then finally when a worker has finished his processing an item we want to cool",
    "start": "2049430",
    "end": "2056210"
  },
  {
    "text": "remove and what remove does is it removes the item from the main and the retry queue and then it checks the",
    "start": "2056210",
    "end": "2061490"
  },
  {
    "text": "backlog if it finds an item in the backlog with the same key it'll take",
    "start": "2061490",
    "end": "2067100"
  },
  {
    "text": "that item from the backlog with this associated priority and move it back to the main queue right so this is I can",
    "start": "2067100",
    "end": "2073820"
  },
  {
    "text": "assign it being like a bit complicated and so what I want to do is I want to go through an example with you specifically",
    "start": "2073820",
    "end": "2080120"
  },
  {
    "text": "I want to go through the example of checking out and I apologize for the",
    "start": "2080120",
    "end": "2085250"
  },
  {
    "text": "people on the on my right because I just have to choose one screen so I'll just",
    "start": "2085250",
    "end": "2090889"
  },
  {
    "text": "choose this one sorry I don't hate you I hope everyone is able to see but I'll",
    "start": "2090890",
    "end": "2097520"
  },
  {
    "text": "trying to be as verbose as possible ok so here we have this this dotted line that separates the the current state of",
    "start": "2097520",
    "end": "2106660"
  },
  {
    "text": "our priority queue and the state after the the check out operation has has",
    "start": "2106660",
    "end": "2111860"
  },
  {
    "text": "completed right we're removing the backlog here just for simplicity right",
    "start": "2111860",
    "end": "2117310"
  },
  {
    "text": "so remember we're checking out an item the first thing we do is we check at on",
    "start": "2117310",
    "end": "2123470"
  },
  {
    "text": "the first item of the retry queue as you can see this item is F right and we check it's party which is now plus 5",
    "start": "2123470",
    "end": "2129980"
  },
  {
    "text": "just think us 5 is like 5 minutes in the future 5 hours some point in the future we see that the priority is in the",
    "start": "2129980",
    "end": "2136610"
  },
  {
    "text": "future so we we take the item from the mink here which in this case is B and before",
    "start": "2136610",
    "end": "2142220"
  },
  {
    "text": "returning B we add B at the back of the retry Q and we return B this is all",
    "start": "2142220",
    "end": "2149510"
  },
  {
    "text": "happens inside our dual code let's look at another example here same thing here",
    "start": "2149510",
    "end": "2154700"
  },
  {
    "text": "we're checking out an item we look at the retry Q and as you can see there's an item here which is F and that item",
    "start": "2154700",
    "end": "2161900"
  },
  {
    "text": "has a priority which is in the past here is its current timestamp - one minute",
    "start": "2161900",
    "end": "2168200"
  },
  {
    "text": "one hour whatever so we return F but before returning F we bump F in the",
    "start": "2168200",
    "end": "2175490"
  },
  {
    "text": "retry Q to the back of the queue and we return it so that if our worker fails at",
    "start": "2175490",
    "end": "2180740"
  },
  {
    "text": "some point F is going to be retried and this is the checkout script right it's",
    "start": "2180740",
    "end": "2190040"
  },
  {
    "text": "what I like about is that it's very very simple this is lua script it's a language",
    "start": "2190040",
    "end": "2195080"
  },
  {
    "text": "native to Redis and it's executed atomically which is really great because we make sure that between one operation",
    "start": "2195080",
    "end": "2203210"
  },
  {
    "text": "or another there is no race condition there is no other item trying to take take items off of that queue right this",
    "start": "2203210",
    "end": "2210710"
  },
  {
    "text": "is atomic and now you know hopefully hopefully you've understood some of our",
    "start": "2210710",
    "end": "2218960"
  },
  {
    "text": "challenges but it can be a bit confusing to see everything all together so hopefully now be able to tell you a little bit of a story around it right",
    "start": "2218960",
    "end": "2226390"
  },
  {
    "text": "everything starts with a feature extractor right this kicks off at 7:30",
    "start": "2226390",
    "end": "2231650"
  },
  {
    "text": "a.m. in the morning and the responsibility of the feature extractor is to take our data from our data",
    "start": "2231650",
    "end": "2237980"
  },
  {
    "text": "warehouse redshift transform that data and write those features out to Redis",
    "start": "2237980",
    "end": "2243050"
  },
  {
    "text": "right so extraction from redshift transformation within the process and",
    "start": "2243050",
    "end": "2249620"
  },
  {
    "text": "writing out those feature vectors to our store and then we have then we have our",
    "start": "2249620",
    "end": "2255860"
  },
  {
    "text": "workers right as we said the workers basically consume the items from the queue those profile ideas from that",
    "start": "2255860",
    "end": "2262220"
  },
  {
    "text": "queue in a in a priority basis so obviously gonna process items the higher priority first right for every mitem",
    "start": "2262220",
    "end": "2269450"
  },
  {
    "text": "they have to generate recommendations for that user that happened well the first thing we do",
    "start": "2269450",
    "end": "2274619"
  },
  {
    "text": "is for one item we perform a G or radius query we get the potential candidates of",
    "start": "2274619",
    "end": "2280650"
  },
  {
    "text": "the user within a geographical proximity right and this reduces the number of candidates from 1 million to 10,000",
    "start": "2280650",
    "end": "2287789"
  },
  {
    "text": "that's huge right then for those remaining candidates we pass them through the bloom filter we remove",
    "start": "2287789",
    "end": "2294150"
  },
  {
    "text": "candidates that the user has already seen ten thousand goes down to 8,000 and then for only those 8,000 users we fetch",
    "start": "2294150",
    "end": "2303690"
  },
  {
    "text": "the vectors of those users from our Redis datastore right and we know exactly which factors to fetch compute",
    "start": "2303690",
    "end": "2310859"
  },
  {
    "text": "the scores and save those scores inside the sorted set for later use in summary",
    "start": "2310859",
    "end": "2318809"
  },
  {
    "text": "we use Redis at every level and this is not only on the data team but pretty much everywhere we love Redis a lot and",
    "start": "2318809",
    "end": "2325140"
  },
  {
    "text": "one thing we love about it is the low operational cost it's really great for us to to be able to handle all this",
    "start": "2325140",
    "end": "2333660"
  },
  {
    "text": "operation hold all this information delegating our you know processing",
    "start": "2333660",
    "end": "2338729"
  },
  {
    "text": "constraints memory constraints to elastic cache and and it's obviously performing at scale right it's really",
    "start": "2338729",
    "end": "2345029"
  },
  {
    "text": "it's been really great for us you know we also use Redis in the traditional way of like caching key value store but it",
    "start": "2345029",
    "end": "2351029"
  },
  {
    "text": "also works with you know with these kind of like more advanced operations right and most importantly right I love the",
    "start": "2351029",
    "end": "2358170"
  },
  {
    "text": "fact that these primitive data structures can be used in a datastore because it really reduces the complexity",
    "start": "2358170",
    "end": "2364229"
  },
  {
    "text": "of our textile and it makes our code very simple because we rely on on the on",
    "start": "2364229",
    "end": "2370200"
  },
  {
    "text": "the the Redis is guarantee of atomicity and on the other side you know it always",
    "start": "2370200",
    "end": "2376380"
  },
  {
    "text": "ends up being the simplest solution in our case if this is something that is",
    "start": "2376380",
    "end": "2383400"
  },
  {
    "text": "interesting to you well we are hiring so you know feel free to come speak to via",
    "start": "2383400",
    "end": "2388499"
  },
  {
    "text": "David and we also hire remotely so if you're not in San Francisco you know",
    "start": "2388499",
    "end": "2394229"
  },
  {
    "text": "we'd love to have a chat with you regardless because yeah we have a lot of exciting things going on this is just a",
    "start": "2394229",
    "end": "2399749"
  },
  {
    "text": "subset of them and yes so this is the website but you know you could speak to me or David",
    "start": "2399749",
    "end": "2406400"
  },
  {
    "text": "yeah thank you very much I hope now we can open for Q&A and if anyone has to",
    "start": "2406400",
    "end": "2418140"
  },
  {
    "text": "ask any questions our two microphones here at the end that you can come up and ask questions if not we'll just have",
    "start": "2418140",
    "end": "2426600"
  },
  {
    "text": "beer all together all right thank you very much and I apologize if you already",
    "start": "2426600",
    "end": "2435960"
  },
  {
    "text": "addressed that I've missed it but with the Facebook thing I thought that was",
    "start": "2435960",
    "end": "2441240"
  },
  {
    "text": "really interesting did you do you did you say that you update that facebook",
    "start": "2441240",
    "end": "2446520"
  },
  {
    "text": "list regularly because people are always adding and removing friends and is that something you update yeah we cached the",
    "start": "2446520",
    "end": "2453000"
  },
  {
    "text": "friends we do an initial download of the friends list so we get anonymized IDs for our users friends and then after I",
    "start": "2453000",
    "end": "2459510"
  },
  {
    "text": "think it's a month we we just check again once it expires yeah we have some",
    "start": "2459510",
    "end": "2464670"
  },
  {
    "text": "cron jobs that run and do that for us",
    "start": "2464670",
    "end": "2468650"
  },
  {
    "text": "all right is there anything anything else that anyone is interested about elastic cash or as any generic questions",
    "start": "2470930",
    "end": "2477540"
  },
  {
    "text": "hopefully we'll be able to answer those I had a quick question how are you persisting the Redis data that append",
    "start": "2477540",
    "end": "2484950"
  },
  {
    "text": "only log or like if you know it goes down the Redis nodes go down how do you",
    "start": "2484950",
    "end": "2492330"
  },
  {
    "text": "persist that right how do you get it back we're backing up with BG SAV I think and then when nodes failover so we",
    "start": "2492330",
    "end": "2498750"
  },
  {
    "text": "have masters and slaves right so if a node fails it's gonna fail over to the slave and then get promoted and that's really easy with lesser cache it sort of",
    "start": "2498750",
    "end": "2505290"
  },
  {
    "text": "happens automatic done automatically by AWS or dejected yeah with less cache we don't even have",
    "start": "2505290",
    "end": "2511950"
  },
  {
    "text": "to worry about it yeah yeah unfortunately we had to turn off like",
    "start": "2511950",
    "end": "2518190"
  },
  {
    "text": "automatic saves because it was pretty much pausing our operations but by having a replicas there we're able to",
    "start": "2518190",
    "end": "2524250"
  },
  {
    "text": "guarantee that if anything happens to the master it'll failover automatically yeah and also cluster obviously has for",
    "start": "2524250",
    "end": "2530670"
  },
  {
    "text": "every node in the cluster for every partition in our cluster we also have associated slaves yeah",
    "start": "2530670",
    "end": "2538160"
  },
  {
    "text": "I'm not sure if you already address this but how do you filter out someone from",
    "start": "2540440",
    "end": "2546119"
  },
  {
    "text": "the recommendation that the person has already seen is that like a bit in the bloom filter or yeah so I mean that is",
    "start": "2546119",
    "end": "2553109"
  },
  {
    "text": "we actually is maintain the recommendations and more or less like near-real-time so anytime a user sees",
    "start": "2553109",
    "end": "2559890"
  },
  {
    "text": "you or you see a user we add the profile to a asynchronous one of our queue",
    "start": "2559890",
    "end": "2564930"
  },
  {
    "text": "actually our priority queues in an asynchronous worker picks it up and then we'll both add it to the bloom filter and actually remove that recommendation",
    "start": "2564930",
    "end": "2571229"
  },
  {
    "text": "from our system so it'll yeah basically by maintaining all the recognitions in your real time we can always sort of do",
    "start": "2571229",
    "end": "2576749"
  },
  {
    "text": "a query on demand and have some assurance that it meets all the criteria that we wanted me to be a criteria",
    "start": "2576749",
    "end": "2583079"
  },
  {
    "text": "location and all the other stuff that we discussed yeah I wanted to know if you",
    "start": "2583079",
    "end": "2592799"
  },
  {
    "text": "guys use Redis like modules and if you've come to you balance moving",
    "start": "2592799",
    "end": "2599430"
  },
  {
    "text": "functionality into Redis and then have a do everything yeah okay that could be",
    "start": "2599430",
    "end": "2605819"
  },
  {
    "text": "good or bad yeah that's a really good question I think Redis free introduced modules and",
    "start": "2605819",
    "end": "2611210"
  },
  {
    "text": "we there is actually a bloom filter module that we could use I so that I",
    "start": "2611210",
    "end": "2617160"
  },
  {
    "text": "think that so the first reason is obviously like if something is working for us there's no real reason to actually port that over to another",
    "start": "2617160",
    "end": "2623489"
  },
  {
    "text": "solution because you know as I said we're a very small team so time is very important for us and the current bloom",
    "start": "2623489",
    "end": "2629249"
  },
  {
    "text": "filter implementation we have is working relatively well so we want to keep that but there's also a second reason which",
    "start": "2629249",
    "end": "2634499"
  },
  {
    "text": "is the bloom filter inside the Redis modules from my understanding obviously there's all the hashing calculations in",
    "start": "2634499",
    "end": "2640529"
  },
  {
    "text": "the Redis code in the lower curve right or C code or whatever we want to what we",
    "start": "2640529",
    "end": "2645690"
  },
  {
    "text": "love about our current approach is that we calculate the bits that we have to set up front and then we batch the",
    "start": "2645690",
    "end": "2651539"
  },
  {
    "text": "separate operations and that's very efficient because we don't we wouldn't want any additional computation",
    "start": "2651539",
    "end": "2656880"
  },
  {
    "text": "happening on our datastore right we want to keep our datastore just simply for writing and so by moving that that logic",
    "start": "2656880",
    "end": "2664200"
  },
  {
    "text": "over to our application code we literally minimize the amount of operations happening on Redis right",
    "start": "2664200",
    "end": "2669420"
  },
  {
    "text": "remember Redis is atomic so it'll block until that operation finishes yeah anyone used it ask the",
    "start": "2669420",
    "end": "2681920"
  },
  {
    "text": "cashier sorry yeah I had a question settle your first parking the",
    "start": "2681920",
    "end": "2687260"
  },
  {
    "text": "architectural review diagram yeah basically back whereas the second part is screaming sorts of this part here",
    "start": "2687260",
    "end": "2693290"
  },
  {
    "text": "yeah said the feature extractor runs about 17 hours that's correct do you have like any future improvements",
    "start": "2693290",
    "end": "2701990"
  },
  {
    "text": "to make data streaming and like because you can only run run at once a day right that's what happens when you want to run",
    "start": "2701990",
    "end": "2707810"
  },
  {
    "text": "it multiple times a day or if it fails and you don't get to finish in that day yeah yeah so when I'm in my 17 hours is",
    "start": "2707810",
    "end": "2714920"
  },
  {
    "text": "every actual process itself takes around so when we generate recommendations",
    "start": "2714920",
    "end": "2720140"
  },
  {
    "text": "right we when we use our spark implementation right spark has this concept of user and product right so",
    "start": "2720140",
    "end": "2727070"
  },
  {
    "text": "it's always direct right so it's like generating rec when we generate recommendations we do that like males",
    "start": "2727070",
    "end": "2732410"
  },
  {
    "text": "towards females or females towards males right and we also do a partition by location so we have literally the number",
    "start": "2732410",
    "end": "2738800"
  },
  {
    "text": "of genders right so male and female times the number of match regions that we have every match region is just like a geographical area like Las Vegas San",
    "start": "2738800",
    "end": "2745970"
  },
  {
    "text": "Francisco the entire process takes 20 plus hours but if we want to rerun a",
    "start": "2745970",
    "end": "2751520"
  },
  {
    "text": "subset of those we don't have to rerun the 20 also delivers in partition subs yeah which you can rerun that's correct",
    "start": "2751520",
    "end": "2757730"
  },
  {
    "text": "so I just for simplicity I just said this process takes 20 hours but this process is a series of Jenkins jobs that",
    "start": "2757730",
    "end": "2763340"
  },
  {
    "text": "runs with a matrix configuration so it'll just run small small partitions at",
    "start": "2763340",
    "end": "2769760"
  },
  {
    "text": "the time and the great thing about this is that if one of these partitions fails it'll just retry that partition so yeah",
    "start": "2769760",
    "end": "2776420"
  },
  {
    "text": "this this this allows for our fault tolerant tolerant behavior second question I have you mentioned",
    "start": "2776420",
    "end": "2782060"
  },
  {
    "text": "that the data is originally in redshift right yes do you have any plans on using a double is glue too late",
    "start": "2782060",
    "end": "2788210"
  },
  {
    "text": "Oh unfortunately we have not considered that I to be honest I have never used",
    "start": "2788210",
    "end": "2794420"
  },
  {
    "text": "that the reason we we use we use redshift is simply because it's working",
    "start": "2794420",
    "end": "2799610"
  },
  {
    "text": "for us now and by the way I actually admitted for simplicity here one step that happens which is between",
    "start": "2799610",
    "end": "2806400"
  },
  {
    "text": "the user data and the feature extractor we do have a spark job that actually takes the data from our redshift cluster",
    "start": "2806400",
    "end": "2814320"
  },
  {
    "text": "so performs an unload operation from our redshift cluster to s free and then takes that data from is free and",
    "start": "2814320",
    "end": "2820760"
  },
  {
    "text": "partitions it in match regions and users and saves it in park' so it's a lot more",
    "start": "2820760",
    "end": "2826619"
  },
  {
    "text": "space efficient right I recommend ER our feature extractors don't speak directly to redshift but they only speak to that",
    "start": "2826619",
    "end": "2832530"
  },
  {
    "text": "partition thanks yeah hope answered your question yeah thank you all right I",
    "start": "2832530",
    "end": "2843990"
  },
  {
    "text": "think we're good here thank you very much thank you [Applause]",
    "start": "2843990",
    "end": "2852869"
  }
]
[
  {
    "text": "hi my name is Holly miss rubian and I'm the director of engineering for AWS",
    "start": "20",
    "end": "5790"
  },
  {
    "text": "lambda in a little bit I'll be joined my bark Bricker who's a senior principal",
    "start": "5790",
    "end": "10860"
  },
  {
    "text": "engineer and serverless mark and I work together at Amazon on lambda today we",
    "start": "10860",
    "end": "18060"
  },
  {
    "text": "plan to walk you through some of the key pieces of the lambda architecture and also some of the innovations that we've",
    "start": "18060",
    "end": "23580"
  },
  {
    "text": "been working on by the end of this talk you will have a conceptual understanding of the lambda architecture and",
    "start": "23580",
    "end": "29810"
  },
  {
    "text": "understand how your code moves through its systems when you call invoke first a",
    "start": "29810",
    "end": "38370"
  },
  {
    "text": "little bit about lambda so you'll understand the scale of what we're doing at just three years after general",
    "start": "38370",
    "end": "44910"
  },
  {
    "text": "availability AWS lambda already processes trillions of requests across",
    "start": "44910",
    "end": "50070"
  },
  {
    "text": "hundreds of thousands of active customers every month lambda is currently available in all 18 AWS",
    "start": "50070",
    "end": "57180"
  },
  {
    "text": "regions and as a foundational service we launch in every new region that AWS launches we have a number of customers",
    "start": "57180",
    "end": "66150"
  },
  {
    "text": "that are using lambda to build highly available scalable and secure services",
    "start": "66150",
    "end": "71570"
  },
  {
    "text": "including thomson reuters whose processing 4,000 requests per second for",
    "start": "71570",
    "end": "76710"
  },
  {
    "text": "its product insights analytics platform finra who performs half a trillion",
    "start": "76710",
    "end": "81869"
  },
  {
    "text": "validations of stock trades daily for fraud and anomaly detection and zillow",
    "start": "81869",
    "end": "87960"
  },
  {
    "text": "who uses lambda in Kinesis to track a subset of mobile metrics in real time",
    "start": "87960",
    "end": "93979"
  },
  {
    "text": "now let's turn to why so many customers are adopting lambda and it's because",
    "start": "93979",
    "end": "100439"
  },
  {
    "text": "running highly available large-scale systems is a lot of work first you need",
    "start": "100439",
    "end": "108659"
  },
  {
    "text": "to ensure that your system has load balancing at every layer of your architecture you do this so you have",
    "start": "108659",
    "end": "114149"
  },
  {
    "text": "redundancy on your architecture but you also so that you can handle more traffic than a single set server is able to",
    "start": "114149",
    "end": "120270"
  },
  {
    "text": "serve when you plan to build a new service you need to plan for and provision for these load balancing",
    "start": "120270",
    "end": "126090"
  },
  {
    "text": "layers between primary architectural components you also need to ensure you have these systems configured with",
    "start": "126090",
    "end": "132150"
  },
  {
    "text": "appropriate routing rules such that your load is distributed evenly second on the point of more than",
    "start": "132150",
    "end": "139230"
  },
  {
    "text": "a single server can serve you need to support scaling up so that if you have more traffic than your current service",
    "start": "139230",
    "end": "145110"
  },
  {
    "text": "layer can handle you can continue to serve that traffic but you also need to be able to scale back down after the",
    "start": "145110",
    "end": "151830"
  },
  {
    "text": "traffic Peaks so that you're not indefinitely over provisioned which of course is wasteful when you plan to",
    "start": "151830",
    "end": "158430"
  },
  {
    "text": "build a new service you also need to plan for and provision for these auto scaling layers to sit in front of your",
    "start": "158430",
    "end": "164250"
  },
  {
    "text": "fleet evaluate the capacity of the fleet and scale up with traffic volume and stress on your server pool and then back",
    "start": "164250",
    "end": "171000"
  },
  {
    "text": "down as peak traffic decreases third continuing on the point of system",
    "start": "171000",
    "end": "177390"
  },
  {
    "text": "failure you need to consider both when a host fails but what about a complete failure of a data center or availability",
    "start": "177390",
    "end": "184170"
  },
  {
    "text": "zone to this you need to instrument each of your services with health checks based on key service metrics and if the",
    "start": "184170",
    "end": "191790"
  },
  {
    "text": "service shows is unhealthy stop routing traffic to that host then",
    "start": "191790",
    "end": "197910"
  },
  {
    "text": "you need to repeat to ensure you do this for every single system and service component that you build as a developer",
    "start": "197910",
    "end": "206880"
  },
  {
    "text": "you're now spending a lot of your engineering hours on systems administration lambda takes care of all",
    "start": "206880",
    "end": "213390"
  },
  {
    "text": "that for you and more helping developers to focus on business logic and writing code and not administering systems today",
    "start": "213390",
    "end": "222690"
  },
  {
    "text": "we will show you how lamda transparently supports load balancing auto scaling and",
    "start": "222690",
    "end": "228840"
  },
  {
    "text": "handling failures while preserving security isolation and utilization so",
    "start": "228840",
    "end": "235769"
  },
  {
    "text": "let's start off with the lambda architecture the lambda architecture is",
    "start": "235769",
    "end": "240959"
  },
  {
    "text": "split into the control plane and the data plane the control plane is where",
    "start": "240959",
    "end": "246120"
  },
  {
    "text": "engineers and developers typically end up interacting with the lambda service",
    "start": "246120",
    "end": "251579"
  },
  {
    "text": "and on that part of the system we have a set of developer tools such as the lambda console the CM CLI your favorite",
    "start": "251579",
    "end": "258780"
  },
  {
    "text": "ID and tool chains you're probably familiar with this and underneath those tools we have a set",
    "start": "258780",
    "end": "265740"
  },
  {
    "text": "of control plane api's and these are for configuration and resource management so",
    "start": "265740",
    "end": "272699"
  },
  {
    "text": "when you go and you create a function upload a function you end up interoperating with these api's and the",
    "start": "272699",
    "end": "279780"
  },
  {
    "text": "resource management does the packaging up of your code and ends up putting that up into the lambda service and it's at",
    "start": "279780",
    "end": "285750"
  },
  {
    "text": "this point where the data plane really picks up and the data plane picks up and",
    "start": "285750",
    "end": "292289"
  },
  {
    "text": "what's going to first talk about asynchronous invoke and events and I'll pick up here and this is where we do",
    "start": "292289",
    "end": "299580"
  },
  {
    "text": "both asynchronous invokes which you're probably familiar with and also where we",
    "start": "299580",
    "end": "305130"
  },
  {
    "text": "interoperate with systems like dynamodb and Kinesis and SQS and we have a set of",
    "start": "305130",
    "end": "311669"
  },
  {
    "text": "systems here who work together Polar's state managers and Leasing service and they work together to",
    "start": "311669",
    "end": "318120"
  },
  {
    "text": "process those events and once those events are kind of processed through that system they're handed over to the",
    "start": "318120",
    "end": "325919"
  },
  {
    "text": "synchronous invoke area of the service and this is where we're going to spend a lot of our time today in the synchronous",
    "start": "325919",
    "end": "332909"
  },
  {
    "text": "invoke area of the system we have a front-end invoke the counting service",
    "start": "332909",
    "end": "337979"
  },
  {
    "text": "the worker manager the worker and the placement service and so let's walk",
    "start": "337979",
    "end": "344490"
  },
  {
    "text": "through those system components and talk about what they do so front-end invoke",
    "start": "344490",
    "end": "350699"
  },
  {
    "text": "it's responsible for orchestrating both synchronous and asynchronous invokes as we just talked about and as it's at the",
    "start": "350699",
    "end": "356729"
  },
  {
    "text": "very front of the service the first thing that it needs to do is authenticate callers so when you call",
    "start": "356729",
    "end": "361740"
  },
  {
    "text": "invoke you want to know that only valid callers are going to make it to your function and call invoke so the very",
    "start": "361740",
    "end": "367349"
  },
  {
    "text": "first thing the service does is it kate's the callers and then assuming that that's ok it will go and load the",
    "start": "367349",
    "end": "373650"
  },
  {
    "text": "function metadata that's things like the environment variables and the limits that you put in when you created the function through the control plane api's",
    "start": "373650",
    "end": "380400"
  },
  {
    "text": "and then it will go and confirm the concurrency with the counting service",
    "start": "380400",
    "end": "385440"
  },
  {
    "text": "and then what it will do assuming that we're not exceeding concurrency then",
    "start": "385440",
    "end": "392690"
  },
  {
    "text": "what what we'll do is we will go and at that customer function to a worker manager and we scale up our worker",
    "start": "392690",
    "end": "400469"
  },
  {
    "text": "managers based on the current running concurrency so as your function concurrency scales up the number of",
    "start": "400469",
    "end": "406770"
  },
  {
    "text": "worker managers also scales up along with that and thereby also your more",
    "start": "406770",
    "end": "412169"
  },
  {
    "text": "workers are being scaled up in this distributes load so the counting service",
    "start": "412169",
    "end": "417629"
  },
  {
    "text": "is responsible for providing a region-wide view of customer concurrency to help enforce those set concurrency",
    "start": "417629",
    "end": "424259"
  },
  {
    "text": "limits and what it does is it's always tracking the current concurrency of your",
    "start": "424259",
    "end": "429749"
  },
  {
    "text": "function executing on the service and if it's below the granted execution it will",
    "start": "429749",
    "end": "434879"
  },
  {
    "text": "automatically be granted execution and if it's hits the concurrency limit it",
    "start": "434879",
    "end": "441270"
  },
  {
    "text": "may or may not be throttled and the reason I say may or may not is because we want all customers to get their full",
    "start": "441270",
    "end": "447719"
  },
  {
    "text": "concurrency and if we started throttling as soon as you started to get to that limit then you would really never meet",
    "start": "447719",
    "end": "453210"
  },
  {
    "text": "your full concurrency so we have some intelligence there that helps us make sure that you get the full concurrency now this function this service has to be",
    "start": "453210",
    "end": "460770"
  },
  {
    "text": "fast and it has to be resilient and because of that it uses a quorum based protocol which you'll probably remember",
    "start": "460770",
    "end": "467490"
  },
  {
    "text": "from your distributed systems in computer science is a two thirds agreement type protocol and as it's",
    "start": "467490",
    "end": "474149"
  },
  {
    "text": "accessed on every single call it can't introduce latency and slow down performance and so it's designed for",
    "start": "474149",
    "end": "479999"
  },
  {
    "text": "high throughput in low latency of less than 1.5 milliseconds in addition this",
    "start": "479999",
    "end": "486029"
  },
  {
    "text": "is a critical component and so we make it resilient to failure and make it highly available by distributing it",
    "start": "486029",
    "end": "492689"
  },
  {
    "text": "across multiple availability zones so the worker manager is responsible for",
    "start": "492689",
    "end": "499169"
  },
  {
    "text": "tracking container idle and busy state and scheduling incoming and VOC requests to the available containers it handles",
    "start": "499169",
    "end": "507149"
  },
  {
    "text": "the workflow steps around function invocation including environment variable setup and compute metering it",
    "start": "507149",
    "end": "513719"
  },
  {
    "text": "will assume the customer supplied execution role so that the function code",
    "start": "513719",
    "end": "518789"
  },
  {
    "text": "executes with the correct privileges and when a container is not available it",
    "start": "518789",
    "end": "523828"
  },
  {
    "text": "will handle the scale-up path through the placement service and it will also spin-down sandboxes and workers when",
    "start": "523829",
    "end": "531120"
  },
  {
    "text": "they become idle because we don't want those running indefinitely if if they're not being used and one of the key things",
    "start": "531120",
    "end": "537720"
  },
  {
    "text": "that this survey service component does is it will optimize for running of code",
    "start": "537720",
    "end": "542940"
  },
  {
    "text": "on a warm sandbox and I'm going to explain to you quite a bit that through this talk about what a warm sandbox",
    "start": "542940",
    "end": "548550"
  },
  {
    "text": "means and what it looks like so you can stay tuned for that so the worker is a very important",
    "start": "548550",
    "end": "555630"
  },
  {
    "text": "component of the system architecture it's responsible for provisioning a",
    "start": "555630",
    "end": "560880"
  },
  {
    "text": "secure environment for customer code execution and how it does that it",
    "start": "560880",
    "end": "566580"
  },
  {
    "text": "creates and manages a collection of sand boxes it sets limits on sand boxes such",
    "start": "566580",
    "end": "571590"
  },
  {
    "text": "as the memory and CPU which is available for function execution it downloads customer code and mounts it for",
    "start": "571590",
    "end": "577530"
  },
  {
    "text": "execution and it also manages multiple language runtimes it will execute",
    "start": "577530",
    "end": "582780"
  },
  {
    "text": "customer code through initialization and invoke and it will manage the AWS owned",
    "start": "582780",
    "end": "587850"
  },
  {
    "text": "agents that are required for monitoring operational controls like cloud watch it's also responsible for notifying the",
    "start": "587850",
    "end": "595290"
  },
  {
    "text": "worker manager when a sandbox invoke completes and again this is going to tie back to talking about warm sandboxes and",
    "start": "595290",
    "end": "602990"
  },
  {
    "text": "mark is going to be talking a lot today about the internals of the worker so",
    "start": "602990",
    "end": "609960"
  },
  {
    "text": "last the placement service that's responsible for placing sand boxes on",
    "start": "609960",
    "end": "615210"
  },
  {
    "text": "workers to maximize packing density without impacting the customer experience or cold pack latency so",
    "start": "615210",
    "end": "621990"
  },
  {
    "text": "really it's the intelligence to help determine where we want to put a sandbox when we have a function ready for",
    "start": "621990",
    "end": "627960"
  },
  {
    "text": "execution and it monitors worker health and makes the decision as to win to mark a worker as unhealthy and again you're",
    "start": "627960",
    "end": "635850"
  },
  {
    "text": "gonna hear a lot from me about speed it's designed so that in deject no more than 100 milliseconds into the cold",
    "start": "635850",
    "end": "642720"
  },
  {
    "text": "start latency path again our systems need to be fast and mark will also be",
    "start": "642720",
    "end": "647940"
  },
  {
    "text": "speaking more on this later and how it affects utilization so now with the high",
    "start": "647940",
    "end": "654720"
  },
  {
    "text": "level understanding of the primary system components let's turn back to the load balancing and how lambda does this",
    "start": "654720",
    "end": "660460"
  },
  {
    "text": "behind the scenes lambda has several modes based on if a worker is already provisioned and then if a sandbox is",
    "start": "660460",
    "end": "667450"
  },
  {
    "text": "provisioned and we're going to start off with the scenario where we have an existing worker but we need a new",
    "start": "667450",
    "end": "674320"
  },
  {
    "text": "sandbox so I'm gonna walk you through that call flow so here we have a customer and they're calling and VOC and",
    "start": "674320",
    "end": "681010"
  },
  {
    "text": "that hits an application load balancer and the application load balancer routes",
    "start": "681010",
    "end": "686590"
  },
  {
    "text": "that call across a fleet a front-end invoke hosts now let's have you talked",
    "start": "686590",
    "end": "691690"
  },
  {
    "text": "about earlier the first thing that that front end and VOC is going to do is it's going to go and authenticate that that's",
    "start": "691690",
    "end": "698080"
  },
  {
    "text": "a valid caller and assuming that it is an important to note is that we do",
    "start": "698080",
    "end": "703330"
  },
  {
    "text": "caching throughout here of course for performance reasons so assuming that it is it's going to go retrieve the",
    "start": "703330",
    "end": "710140"
  },
  {
    "text": "function metadata and then it will go and check with the counting service the",
    "start": "710140",
    "end": "715720"
  },
  {
    "text": "current concurrency and verify that against the concurrency limit assuming we can continue on from that point the",
    "start": "715720",
    "end": "722950"
  },
  {
    "text": "front-end then goes to the worker manager to reserve a sandbox and the",
    "start": "722950",
    "end": "728710"
  },
  {
    "text": "worker manager says hey great I have a worker you can put a sandbox on it and so the worker manager will go and create",
    "start": "728710",
    "end": "736750"
  },
  {
    "text": "the sandbox download the code initialize the runtime and call the customer code",
    "start": "736750",
    "end": "742330"
  },
  {
    "text": "in it so your init function and then once that's done we say that we have a",
    "start": "742330",
    "end": "748300"
  },
  {
    "text": "warm sandbox the sandbox is all ready to go there's nothing more to do other than to call invoke and so the worker lets",
    "start": "748300",
    "end": "754690"
  },
  {
    "text": "the worker manager know and the worker manager lets the front-end know and now the front-end can call invoke and that",
    "start": "754690",
    "end": "763420"
  },
  {
    "text": "causes your code to be run on the sandbox and at the end of the code execution metrics are collected up and",
    "start": "763420",
    "end": "770050"
  },
  {
    "text": "then the worker lets the worker manager know that it is idle and that way the worker manager knows it again has a warm",
    "start": "770050",
    "end": "776920"
  },
  {
    "text": "sandbox so we just left off where we",
    "start": "776920",
    "end": "783280"
  },
  {
    "text": "have a warm sandbox I want to pick up on that scenario here where we have an existing worker and an existing sandbox",
    "start": "783280",
    "end": "790150"
  },
  {
    "text": "and so we're coming back in with another invoke the customer again hits the application",
    "start": "790150",
    "end": "795560"
  },
  {
    "text": "load balancer hits the front end we do authentication we go and we access the",
    "start": "795560",
    "end": "802459"
  },
  {
    "text": "function metadata and then we go and check the concurrency limits with the counting service the front end will then",
    "start": "802459",
    "end": "809720"
  },
  {
    "text": "proceed forward to reserve a sandbox with the worker manager and it's this time where the worker manager says great",
    "start": "809720",
    "end": "816230"
  },
  {
    "text": "I don't only have a worker I have as a warm sandbox there and it returns that",
    "start": "816230",
    "end": "821600"
  },
  {
    "text": "back to the front end and the front end can then call invoke which causes the code your code to run and then again",
    "start": "821600",
    "end": "829459"
  },
  {
    "text": "lets the worker manager know when it's done so that it again knows it has a warm sandbox and so I want to emphasize",
    "start": "829459",
    "end": "835699"
  },
  {
    "text": "here this is where we spend most of our time this is the call pattern where most",
    "start": "835699",
    "end": "840829"
  },
  {
    "text": "of our time is spent on the lambda service so load balancing is always",
    "start": "840829",
    "end": "847370"
  },
  {
    "text": "necessary but it really shines when looking at high TPS use cases of consistent traffic that needs high",
    "start": "847370",
    "end": "853430"
  },
  {
    "text": "availability and reliability for instance web and mobile applications as is the case for high-traffic startups",
    "start": "853430",
    "end": "860329"
  },
  {
    "text": "like bustle and next door to enterprises like Capital One and Comcast and I love",
    "start": "860329",
    "end": "868279"
  },
  {
    "text": "this quote from Edmunds around how quickly they were able to build a lambda based solution so in the above example",
    "start": "868279",
    "end": "880209"
  },
  {
    "text": "we covered where we have a worker that's already provisioned but what happens",
    "start": "880209",
    "end": "885439"
  },
  {
    "text": "when we scale up quickly and exceed the capacity of workers and we need to get a new worker the overall call pattern is",
    "start": "885439",
    "end": "892970"
  },
  {
    "text": "similar but we - what we have but there are additional systems involved so let's",
    "start": "892970",
    "end": "899720"
  },
  {
    "text": "pick up again I hope you like my pretty pictures here so we have the lambda",
    "start": "899720",
    "end": "906860"
  },
  {
    "text": "customer and there's a new function or we're scaling up really quickly in this scenario and we call invoke which again",
    "start": "906860",
    "end": "913699"
  },
  {
    "text": "hits the application load balancer and goes to the front end and at this point",
    "start": "913699",
    "end": "918860"
  },
  {
    "text": "you're very familiar with this scenario you can probably do it in your sleep we have the and that that authenticates retrieves",
    "start": "918860",
    "end": "927060"
  },
  {
    "text": "function metadata and then does the concurrency against the counting service and then proceeds forward to reserve a",
    "start": "927060",
    "end": "933510"
  },
  {
    "text": "sandbox with the worker manager but this time the worker manager says I don't have a work a worker and I don't have a",
    "start": "933510",
    "end": "939390"
  },
  {
    "text": "sandbox that I can place this function on and so what it does is it goes to claim a worker from the placement",
    "start": "939390",
    "end": "945690"
  },
  {
    "text": "service and the placement service does it's it's its valuation its intelligence",
    "start": "945690",
    "end": "950940"
  },
  {
    "text": "to say okay here's a good place for you to provision that sandbox or provision",
    "start": "950940",
    "end": "956220"
  },
  {
    "text": "the sandbox and so it gives that back to the worker manager and then we per pick up the worker manager is going to go and",
    "start": "956220",
    "end": "963950"
  },
  {
    "text": "create the sandbox download the code initialize the runtime and call in it on",
    "start": "963950",
    "end": "971430"
  },
  {
    "text": "your code and again we say here that we have a warm sandbox and so the worker",
    "start": "971430",
    "end": "978900"
  },
  {
    "text": "manager now now lets the front-end know and the front-end comes in and calls invoke your code runs and then it lets",
    "start": "978900",
    "end": "985920"
  },
  {
    "text": "the worker manager know again that it's done running and that way it knows it has a warm sandbox so a little bit more",
    "start": "985920",
    "end": "993660"
  },
  {
    "text": "about the placement service and it is responsible for ensuring sufficient worker capacity to continue to fulfill",
    "start": "993660",
    "end": "999540"
  },
  {
    "text": "worker manager requests for hosts when the placement service hands out a worker",
    "start": "999540",
    "end": "1004850"
  },
  {
    "text": "to the worker manager it provides that worker to the worker manager with a lease of between six and ten hours the",
    "start": "1004850",
    "end": "1011900"
  },
  {
    "text": "reason for the lease is to enable work or cycling however lease duration is also impacted",
    "start": "1011900",
    "end": "1018260"
  },
  {
    "text": "by function duration you can't have a function that runs longer than your lease when the worker gets close to its",
    "start": "1018260",
    "end": "1027170"
  },
  {
    "text": "lease expiry the worker manager must return the worker and when the placement service receives a worker with an",
    "start": "1027170",
    "end": "1033560"
  },
  {
    "text": "expiring lease it will reprovision that worker if the worker manager finds its",
    "start": "1033560",
    "end": "1040010"
  },
  {
    "text": "worker to be close to expiration it will stop reserving sandbox on the worker such that all of the sandbox has become",
    "start": "1040010",
    "end": "1046730"
  },
  {
    "text": "idle and it's at this point that all the sandbox has become idle that the worker",
    "start": "1046730",
    "end": "1051740"
  },
  {
    "text": "can be returned so auto-scaling is nearly always",
    "start": "1051740",
    "end": "1058750"
  },
  {
    "text": "necessary however when it is heavily used is for workloads where you need to rapidly provision see on boxes for a",
    "start": "1058750",
    "end": "1065320"
  },
  {
    "text": "limited time period and then return them when when completed like with Fannie Mae or pyrin who scale to between 20 and",
    "start": "1065320",
    "end": "1072220"
  },
  {
    "text": "50,000 concurrent executions over minutes failure is always a possibility",
    "start": "1072220",
    "end": "1079690"
  },
  {
    "text": "and lambda is designed to handle cases of failure whether it be post failure or",
    "start": "1079690",
    "end": "1085060"
  },
  {
    "text": "a complete availability zone failure lambdas built across multiple",
    "start": "1085060",
    "end": "1090730"
  },
  {
    "text": "availability zones and system components are striped across these availability zones with as we discussed prior load",
    "start": "1090730",
    "end": "1098200"
  },
  {
    "text": "balancing and redundancy across service layers in the lambda architecture in addition lambda monitors the health of",
    "start": "1098200",
    "end": "1105040"
  },
  {
    "text": "hosts and removes unhealthy hosts when a worker becomes unhealthy the worker",
    "start": "1105040",
    "end": "1112060"
  },
  {
    "text": "manager detects and stops provisioning sandboxes on this worker and when an",
    "start": "1112060",
    "end": "1117880"
  },
  {
    "text": "entire availability zone fails the system components continue to execute as shown although without routing traffic",
    "start": "1117880",
    "end": "1124630"
  },
  {
    "text": "through the failed availability zone now as discussed earlier mark will pick up",
    "start": "1124630",
    "end": "1131050"
  },
  {
    "text": "and go into the details on the worker",
    "start": "1131050",
    "end": "1134910"
  },
  {
    "text": "thank you [Applause]",
    "start": "1138930",
    "end": "1145300"
  },
  {
    "text": "so it's no secret that click forward here there we go",
    "start": "1145430",
    "end": "1151800"
  },
  {
    "text": "it's no secret that lambda functions multiple lambda functions ran on the same hardware and on the same host at",
    "start": "1151800",
    "end": "1160020"
  },
  {
    "text": "the same time and the reason we do that is you know it's just not cost-effective for us to buy data center servers with",
    "start": "1160020",
    "end": "1167670"
  },
  {
    "text": "128 megabytes of RAM so we run multiple functions on servers at the same time",
    "start": "1167670",
    "end": "1173940"
  },
  {
    "text": "and this leads to customers most just one of the most frequent questions we get is how do we isolate the different",
    "start": "1173940",
    "end": "1181140"
  },
  {
    "text": "functions that are running on a particular worker an isolation generally means two things to people one of those",
    "start": "1181140",
    "end": "1188400"
  },
  {
    "text": "things is security and the other is operational isolation and and by that I",
    "start": "1188400",
    "end": "1194190"
  },
  {
    "text": "mean you know how do you ensure that functions ran at a consistent performance all with consistent",
    "start": "1194190",
    "end": "1202410"
  },
  {
    "text": "performance when there are other functions on the same Hardware how do you prevent noise e neighbor impacts and",
    "start": "1202410",
    "end": "1208080"
  },
  {
    "text": "so on so do dive into that I'm going to talk a little bit about the software",
    "start": "1208080",
    "end": "1213420"
  },
  {
    "text": "stack that runs on these workers so Holly talked about the worker these are the hosts that that ran our that ran",
    "start": "1213420",
    "end": "1219630"
  },
  {
    "text": "your code and this is what the stack on a worker looks like at the top of the stack is is the most important part and",
    "start": "1219630",
    "end": "1226050"
  },
  {
    "text": "that is your code and this is the stuff that comes from your your function zip or it comes from the layers that you",
    "start": "1226050",
    "end": "1232530"
  },
  {
    "text": "heard Verna talked about this morning the next layer down is the lambda",
    "start": "1232530",
    "end": "1238950"
  },
  {
    "text": "runtime so this is the Java or or nodejs or Python that comes built into lambda",
    "start": "1238950",
    "end": "1246240"
  },
  {
    "text": "and then the sandbox and the contents of the sandbox is pretty it's a pretty",
    "start": "1246240",
    "end": "1251280"
  },
  {
    "text": "full-featured copy of Linux you can go poking around in the sandbox that lambda",
    "start": "1251280",
    "end": "1256590"
  },
  {
    "text": "functions run in you know looking user bin and user Lib there's quite a lot of stuff there and you know that stuff is",
    "start": "1256590",
    "end": "1263430"
  },
  {
    "text": "there because you know code expects those things to be there code that's built in on operating systems expects",
    "start": "1263430",
    "end": "1269430"
  },
  {
    "text": "that stuff to be there the next layer down is the guest OS and in our case the guest OS is Amazon",
    "start": "1269430",
    "end": "1275690"
  },
  {
    "text": "then we ran multiple guest OSS on a box sometimes many many hundreds or",
    "start": "1275690",
    "end": "1281160"
  },
  {
    "text": "thousands isolated from each other using virtualization using a hypervisor then",
    "start": "1281160",
    "end": "1287340"
  },
  {
    "text": "there's a host OS again Amazon Linux and this is the thing that that hypervisor runs on and the hardware itself so this",
    "start": "1287340",
    "end": "1295470"
  },
  {
    "text": "is what it looks like from an isolation perspective the first three layers to your code layer the runtime in the",
    "start": "1295470",
    "end": "1302070"
  },
  {
    "text": "sandbox are only ever used by one function and you all know if you use lambda that multiple invocations will",
    "start": "1302070",
    "end": "1311100"
  },
  {
    "text": "land in the same sandbox in serial so if you call the same function once and then",
    "start": "1311100",
    "end": "1316770"
  },
  {
    "text": "you call it again and then you call it again those will all go to the same sandbox in serial they won't overlap",
    "start": "1316770",
    "end": "1322020"
  },
  {
    "text": "concurrently and that's where we'll scale up but we never reuse a sandbox",
    "start": "1322020",
    "end": "1327420"
  },
  {
    "text": "across multiple functions then the guest operating systems are shared within an",
    "start": "1327420",
    "end": "1334620"
  },
  {
    "text": "account so multiple functions within one account will run on the same guest operating system either at the same time",
    "start": "1334620",
    "end": "1341160"
  },
  {
    "text": "or when we destroy the sandbox for one function and recreate one so those guest operating systems are shared across",
    "start": "1341160",
    "end": "1347340"
  },
  {
    "text": "functions but never shared across multiple AWS accounts and the the",
    "start": "1347340",
    "end": "1354030"
  },
  {
    "text": "boundary that we put up between accounts is virtualization and we think this is the minimum security bar for isolation",
    "start": "1354030",
    "end": "1361560"
  },
  {
    "text": "of functions between accounts and in a lot of ways also the minimum operational",
    "start": "1361560",
    "end": "1366630"
  },
  {
    "text": "bar so let's step through these layers a little bit and talk about how we achieve operational and security isolation",
    "start": "1366630",
    "end": "1374840"
  },
  {
    "text": "underneath the sandbox layer is the same technology that powers containers and the thing about Linux containers that",
    "start": "1374840",
    "end": "1381750"
  },
  {
    "text": "that you'll probably know is Linux containers don't really exist instead containers are kind of grouping of",
    "start": "1381750",
    "end": "1388440"
  },
  {
    "text": "different functionality that's built into the Linux kernel a kind of toolbox that you can build sand boxes and",
    "start": "1388440",
    "end": "1394590"
  },
  {
    "text": "containers out of and we use a number of the tools from those toolbox for our sandbox isolation",
    "start": "1394590",
    "end": "1402830"
  },
  {
    "text": "the first one of those tools is C groups or control groups and C groups are mechanism to say you know this this",
    "start": "1404290",
    "end": "1411190"
  },
  {
    "text": "process and obviously anything that Forks or any any threads that creates is",
    "start": "1411190",
    "end": "1416260"
  },
  {
    "text": "only allowed to use a certain amount of CPU a certain amount of memory a certain",
    "start": "1416260",
    "end": "1421840"
  },
  {
    "text": "amount of disk throughput a certain amount of memory throughput so this is the kind of operational isolation and",
    "start": "1421840",
    "end": "1427960"
  },
  {
    "text": "this is how for example we we enforce the the maximum function memory footprint using using control groups and",
    "start": "1427960",
    "end": "1436510"
  },
  {
    "text": "C groups are sticky actually all of these mechanisms are sticky so you know you add if at a process to a C group and",
    "start": "1436510",
    "end": "1442510"
  },
  {
    "text": "it can't get out of that it can't take itself out the next mechanism we use is",
    "start": "1442510",
    "end": "1448900"
  },
  {
    "text": "called namespaces so there a whole bunch of resources in the Linux kernel like process IDs and user IDs and group IDs",
    "start": "1448900",
    "end": "1455410"
  },
  {
    "text": "and namespaces are just what they say are there a namespace for those IDs so",
    "start": "1455410",
    "end": "1461640"
  },
  {
    "text": "if you go digging around inside the lambda sandbox you'll see that the process that your lambda function runs",
    "start": "1461640",
    "end": "1468310"
  },
  {
    "text": "as always runs as process ID pit number one and you know how can you have",
    "start": "1468310",
    "end": "1474310"
  },
  {
    "text": "multiple functions with the same pin number one well you don't it's actually just pit number one in its in its",
    "start": "1474310",
    "end": "1480730"
  },
  {
    "text": "process namespace and it's got a real pit that is is not one but within the",
    "start": "1480730",
    "end": "1486490"
  },
  {
    "text": "namespace which is where you are if you're looking at this stuff you see a namespace set of process IDs then this",
    "start": "1486490",
    "end": "1493720"
  },
  {
    "text": "sitcom or sitcom PPF this is a kind of firewall for the kernel so you know the",
    "start": "1493720",
    "end": "1499150"
  },
  {
    "text": "Linux kernel has a whole bunch of syscalls just exposes stuff the kernel can do like opening sockets and opening files",
    "start": "1499150",
    "end": "1505870"
  },
  {
    "text": "and so on and or reading and writing from files and and what sitcom its you",
    "start": "1505870",
    "end": "1512980"
  },
  {
    "text": "do is say this process can only call these sis calls or cannot call those sis calls or can call these sis calls but",
    "start": "1512980",
    "end": "1519010"
  },
  {
    "text": "with only these arguments or can call those is called but not with those arguments and we you say con PPF to cut",
    "start": "1519010",
    "end": "1524890"
  },
  {
    "text": "out bits of the kernel surface area and restricted to only the functionality that lambda functions actually need to",
    "start": "1524890",
    "end": "1531160"
  },
  {
    "text": "ran and this is one of the primary security controls next iptables EB tables routing in",
    "start": "1531160",
    "end": "1538960"
  },
  {
    "text": "various other things provide network isolation and to route bind mounts and loopback mounts provide the underlying",
    "start": "1538960",
    "end": "1545679"
  },
  {
    "text": "filesystem the next layer down in the in",
    "start": "1545679",
    "end": "1551950"
  },
  {
    "text": "the stack or in the isolation story is virtualization and device emulation and",
    "start": "1551950",
    "end": "1557200"
  },
  {
    "text": "this is this is using virtualization features built into into the hardware so",
    "start": "1557200",
    "end": "1563410"
  },
  {
    "text": "there's like VTX on Intel to make the hardware essentially just pretend to be multiple to be multiple CPUs instead of",
    "start": "1563410",
    "end": "1571090"
  },
  {
    "text": "one and this is all this all controlled by the hypervisor and virtual machine",
    "start": "1571090",
    "end": "1577330"
  },
  {
    "text": "monitor and I'll get into that a little bit later when I talk about firecracker so there are two ways that we build",
    "start": "1577330",
    "end": "1584799"
  },
  {
    "text": "lambda today the two ways that lambda workers come together one of those whoa step I have gone way ahead here somehow",
    "start": "1584799",
    "end": "1592980"
  },
  {
    "text": "hopefully I can skip that there we go a little bit of a spoiler there one of",
    "start": "1592980",
    "end": "1599620"
  },
  {
    "text": "those is on ec2 instances so on Monday night she would have repeated to Santa's say when we started lambda we started by",
    "start": "1599620",
    "end": "1608409"
  },
  {
    "text": "building every worker as a separate ec2 instance and we did it that way for",
    "start": "1608409",
    "end": "1616480"
  },
  {
    "text": "several reasons one was that's a great security boundary and the other is that was a fast way to build the system and",
    "start": "1616480",
    "end": "1622539"
  },
  {
    "text": "we still use this mode today we ran these lambda workers as normal ec2",
    "start": "1622539",
    "end": "1629470"
  },
  {
    "text": "instances exactly the same kinds of ec2 instances you could go off and launch today and we usually the instances on",
    "start": "1629470",
    "end": "1636610"
  },
  {
    "text": "the mat nitro platform the other kind of isolation that we've just started",
    "start": "1636610",
    "end": "1641860"
  },
  {
    "text": "talking about this week is based on our new firecracker vmm and on firecracker",
    "start": "1641860",
    "end": "1647950"
  },
  {
    "text": "instead of running you know one instance per you know per account we run one",
    "start": "1647950",
    "end": "1654340"
  },
  {
    "text": "bare-metal ec2 instance and again the same kinds of a metal ec2 instances that you can go off and buy and we use",
    "start": "1654340",
    "end": "1662500"
  },
  {
    "text": "firecracker to launch many many micro VMs hundreds of thousands of micro VMs",
    "start": "1662500",
    "end": "1668470"
  },
  {
    "text": "on top of that we're and these are more flexible or",
    "start": "1668470",
    "end": "1675610"
  },
  {
    "text": "more agile boundary than than instances all for us and has some really great",
    "start": "1675610",
    "end": "1681159"
  },
  {
    "text": "features and one of those really great features is simplifying the security model so instead of having the layer of",
    "start": "1681159",
    "end": "1688419"
  },
  {
    "text": "you know one function one account many accounts instead we've simplified this down to one function in a macro VM and",
    "start": "1688419",
    "end": "1695620"
  },
  {
    "text": "in multiple macro vm's across multiple accounts on a piece of hardware and this",
    "start": "1695620",
    "end": "1700960"
  },
  {
    "text": "is really good for us in a whole lot of ways which I'll talk about when I get to talking about utilization but it's also",
    "start": "1700960",
    "end": "1706480"
  },
  {
    "text": "nice for the lambda programming model because this is provides strong isolation even between functions when",
    "start": "1706480",
    "end": "1714820"
  },
  {
    "text": "we're running in this firecracker mode so I want to talk a little bit about one of the innovations are we put into a",
    "start": "1714820",
    "end": "1720879"
  },
  {
    "text": "firecracker which I you know helps raise the security bar so by way of",
    "start": "1720879",
    "end": "1726789"
  },
  {
    "text": "introduction there you know I said we're running hundreds with thousands of firecrackers on a host obviously these",
    "start": "1726789",
    "end": "1732580"
  },
  {
    "text": "boxes don't have hundreds or thousands of of network cards they don't have thousands of hard drives but each guest",
    "start": "1732580",
    "end": "1739539"
  },
  {
    "text": "VM each of those micro VMs sees a network card and sees a hard drive and",
    "start": "1739539",
    "end": "1746369"
  },
  {
    "text": "to user space cloud running in that micro VM those looked like hardware devices well how does this work",
    "start": "1746369",
    "end": "1753279"
  },
  {
    "text": "this works through the magic of virtualization and a little bit of cooperation between the guest OS kernel",
    "start": "1753279",
    "end": "1759190"
  },
  {
    "text": "and the hypervisor and 5na implementation of device emulation",
    "start": "1759190",
    "end": "1764519"
  },
  {
    "text": "inside firecracker so we use a protocol called vert ire and this is a this is a",
    "start": "1764519",
    "end": "1772570"
  },
  {
    "text": "way to pull a driver inside the guest kernel to implement a block device and",
    "start": "1772570",
    "end": "1777999"
  },
  {
    "text": "implement a network card in a way that is very efficient and it's very simple",
    "start": "1777999",
    "end": "1785559"
  },
  {
    "text": "and is very secure so the efficiency although the efficiency comes from the fact that one of the most important",
    "start": "1785559",
    "end": "1791980"
  },
  {
    "text": "things in virtualization performance is reducing the number of times that the guest OS has to you have to sort of",
    "start": "1791980",
    "end": "1797889"
  },
  {
    "text": "switch between the guest and the and the host operating system and so you can",
    "start": "1797889",
    "end": "1803260"
  },
  {
    "text": "imagine the simplest possible interface is a way for the the guest operating system to write a byte or or write you",
    "start": "1803260",
    "end": "1810130"
  },
  {
    "text": "know some some words into into the host and it would have to do this multiple times to send a network packet for",
    "start": "1810130",
    "end": "1816790"
  },
  {
    "text": "example with ver tired instead what it does is builds apps and data structures in memory and then it it rings the",
    "start": "1816790",
    "end": "1824470"
  },
  {
    "text": "doorbell on the on the hypervisor saying you know dingdong there's some work for you to do there's some packets here for",
    "start": "1824470",
    "end": "1830020"
  },
  {
    "text": "you to send the device simulation implementation picks that stuff up and",
    "start": "1830020",
    "end": "1835420"
  },
  {
    "text": "sends those to the real hardware so there's really kind of bread and butter virtualization stuff the innovation in",
    "start": "1835420",
    "end": "1842590"
  },
  {
    "text": "fire cracker is that this device simulation runs inside a very restricted",
    "start": "1842590",
    "end": "1847720"
  },
  {
    "text": "sandbox so this kind of a second layer sandbox it just sits around that device simulation code R with very few",
    "start": "1847720",
    "end": "1854830"
  },
  {
    "text": "privileges and what's nice about this is that we get to use all of those controls that I talked about earlier all of that",
    "start": "1854830",
    "end": "1860980"
  },
  {
    "text": "kind of sitcom PPF and so on to provide an additional layer of security around device emulation so we built firecracker",
    "start": "1860980",
    "end": "1868990"
  },
  {
    "text": "and rest and we paid a huge amount of attention to the security of that boundary and the quality of that device",
    "start": "1868990",
    "end": "1874930"
  },
  {
    "text": "emulation implementation but there is also one of the most complex pieces of code so having the second layer of",
    "start": "1874930",
    "end": "1881500"
  },
  {
    "text": "sandboxing around it provides a second layer of security control which we think is very important next utilization and",
    "start": "1881500",
    "end": "1893680"
  },
  {
    "text": "certainly this is about you know how do we keep those workers busy how do we keep our system our servers busy well",
    "start": "1893680",
    "end": "1901270"
  },
  {
    "text": "how do you measure utilization we think of utilization as the percentage of resources and and their resources mean",
    "start": "1901270",
    "end": "1907720"
  },
  {
    "text": "CPU and memory and so on doing useful work rather than being idle or being wasted and by doing useful work what",
    "start": "1907720",
    "end": "1915280"
  },
  {
    "text": "that means to me is ideally I want every CPU cycle on my worker to be running",
    "start": "1915280",
    "end": "1920920"
  },
  {
    "text": "your code I want every byte of RAM on my worker to be filled with your data and",
    "start": "1920920",
    "end": "1928440"
  },
  {
    "text": "this is good for us because it's very efficient and good for you because you get better cache locality and better",
    "start": "1928440",
    "end": "1935140"
  },
  {
    "text": "container reuse which is performance so the good news for you is that with lambda you only pay for useful",
    "start": "1935140",
    "end": "1942570"
  },
  {
    "text": "work so you don't have to worry about utilization utilization is entirely you",
    "start": "1942570",
    "end": "1948270"
  },
  {
    "text": "know my problem and Holly's problem this is something we're working on but there's some interesting topics here which I wanted to dig into and one of",
    "start": "1948270",
    "end": "1955980"
  },
  {
    "text": "the things that my team spends a huge amount of work does a huge amount of work on is this optimization of",
    "start": "1955980",
    "end": "1961830"
  },
  {
    "text": "utilization is the packing on to workers packing functions onto workers to keep those workers optimally busy so let's",
    "start": "1961830",
    "end": "1970500"
  },
  {
    "text": "talk about one topic there here are seven Sam boxes for a function just",
    "start": "1970500",
    "end": "1975900"
  },
  {
    "text": "arbitrarily chose the number seven and you know if you usual Holly's diagrams who scaled up this kind of seven",
    "start": "1975900",
    "end": "1982680"
  },
  {
    "text": "concurrency going on here we've scaled up to create seven Sam boxes the typical",
    "start": "1982680",
    "end": "1988020"
  },
  {
    "text": "kind of distributed systems approach if you had seven servers would be to load balance between them so you would take",
    "start": "1988020",
    "end": "1994650"
  },
  {
    "text": "some amount of load and you would try and spread it out across the fleet as kind of evenly as you can and you do",
    "start": "1994650",
    "end": "2000770"
  },
  {
    "text": "this for a couple of reasons and but the most the primary reason is that it's really hard to tell how busy computers",
    "start": "2000770",
    "end": "2006950"
  },
  {
    "text": "are um and that's because there's so many many bottlenecks there's the easy stuff like CPU and memory but there's",
    "start": "2006950",
    "end": "2013820"
  },
  {
    "text": "harder stuff like networks and even harder stuff like memory buses and caches and so on so it's very difficult",
    "start": "2013820",
    "end": "2019280"
  },
  {
    "text": "to boil down the busyness of a server to one number or even any reasonable number",
    "start": "2019280",
    "end": "2025010"
  },
  {
    "text": "of dimensions so what people do in practice is see a fairly conservative auto scaling goals make their fleet",
    "start": "2025010",
    "end": "2033410"
  },
  {
    "text": "bigger when they hit some kind of CPU utilization and use that as a kind of proxy for the real load and then load",
    "start": "2033410",
    "end": "2039650"
  },
  {
    "text": "balance across those servers it's a very time-honored pattern and a pretty great one we do something quite different in",
    "start": "2039650",
    "end": "2045770"
  },
  {
    "text": "lambda we intentionally concentrate the load on the smallest possible number of",
    "start": "2045770",
    "end": "2053120"
  },
  {
    "text": "busy Sam boxes and this is a good thing and it's good thing for your code because keeping a small number of",
    "start": "2053120",
    "end": "2060470"
  },
  {
    "text": "sandbox is very busy means that any caches you have or any precomputed staff or any connections you have open are",
    "start": "2060470",
    "end": "2066950"
  },
  {
    "text": "kept optimally busy and that's really great for temporal charity and cash locality and it's good",
    "start": "2066950",
    "end": "2073879"
  },
  {
    "text": "for us because it gives us a really good ability to auto scale so why can we get away with us well we can get away with",
    "start": "2073880",
    "end": "2079490"
  },
  {
    "text": "us because of the semantics of the lamda API there's only ever one invoke going",
    "start": "2079490",
    "end": "2085730"
  },
  {
    "text": "on in a sandbox so sandbox is kind of busy in a very binary way it's either",
    "start": "2085730",
    "end": "2091580"
  },
  {
    "text": "gotten invoked running on it or it hasn't gotten invoke running on it so just by counting the number of Sam boxes",
    "start": "2091580",
    "end": "2098060"
  },
  {
    "text": "that have an invoke running on them we can get a very clear picture of the load across the system and by pecking load on",
    "start": "2098060",
    "end": "2105740"
  },
  {
    "text": "to the smallest number of Sam boxes we can simply count the number of idle ones and scale them down or we can count the",
    "start": "2105740",
    "end": "2112100"
  },
  {
    "text": "number of busy ones and seeing that see that that's approaching the total and start scaling at so this is all work to",
    "start": "2112100",
    "end": "2119090"
  },
  {
    "text": "Ted placement service dads and it's worked that we can do because of the the",
    "start": "2119090",
    "end": "2124430"
  },
  {
    "text": "semantics of lambda it's another topic in utilization and that's the really",
    "start": "2124430",
    "end": "2129530"
  },
  {
    "text": "interesting one for me is how do you pick workloads to run on a worker so",
    "start": "2129530",
    "end": "2135200"
  },
  {
    "text": "this is a worker this is a server yes there are servers in service and you",
    "start": "2135200",
    "end": "2141620"
  },
  {
    "text": "know the obvious thing to do here and the thing it would you be forced to do if you were kind of building a lambda for yourself is ran multiple copies of",
    "start": "2141620",
    "end": "2149240"
  },
  {
    "text": "the same workload so you cut it up into multiple sandboxes and you run multiple copies of the same workload it turns out",
    "start": "2149240",
    "end": "2155840"
  },
  {
    "text": "that's a bad thing to do and that's a bad thing to do because multiple copies of the same workload will have very",
    "start": "2155840",
    "end": "2161210"
  },
  {
    "text": "correlated load and what that means is when one spikes up on CPU it's quite",
    "start": "2161210",
    "end": "2166730"
  },
  {
    "text": "likely another one will spike up on CPU at the same time because they're doing the same work or on memory usage or on",
    "start": "2166730",
    "end": "2173780"
  },
  {
    "text": "you know bus usage or a network usage or or whatever so these loads are very correlated and that really limits how",
    "start": "2173780",
    "end": "2180740"
  },
  {
    "text": "densely you can pack on hardware because your load is going to be very spiky so",
    "start": "2180740",
    "end": "2186110"
  },
  {
    "text": "what can you do about that how can you how can you flatten that out well you can take advantage of statistics and you",
    "start": "2186110",
    "end": "2192380"
  },
  {
    "text": "can take advantage of statistics and simply put as many uncorrelated workloads onto a server as you can so",
    "start": "2192380",
    "end": "2200720"
  },
  {
    "text": "have a diverse set of workloads instead of multiple cop the same workload and this makes the",
    "start": "2200720",
    "end": "2205750"
  },
  {
    "text": "workload way way better behaved it really brings down that those Peaks brings up the average and makes it",
    "start": "2205750",
    "end": "2212500"
  },
  {
    "text": "easier to predict scale so that might sound counterintuitive so let's see if",
    "start": "2212500",
    "end": "2217570"
  },
  {
    "text": "we can build an intuition for why that's true when I was in high school I really enjoyed playing Dungeons and Dragons and",
    "start": "2217570",
    "end": "2224670"
  },
  {
    "text": "one of the things you do with D&D is throw a 20-sided die and so here I said",
    "start": "2224670",
    "end": "2233950"
  },
  {
    "text": "on my desk one day I threw a 20-sided dice uh a hundred thousand times and I countered each of the twenty values how",
    "start": "2233950",
    "end": "2240850"
  },
  {
    "text": "often they came up and you can see that's pretty consistent I'm obviously quite good at rolling dice so you know",
    "start": "2240850",
    "end": "2248110"
  },
  {
    "text": "one night my friends and I wanted to play some D and E and and we lift our 20 sided dice at home but we have had some",
    "start": "2248110",
    "end": "2253180"
  },
  {
    "text": "10-sided dice so can we just take two two in sided dice and throw them and add the two numbers up and make that a 20",
    "start": "2253180",
    "end": "2260140"
  },
  {
    "text": "sided dice turns out you can't so this is what the distribution looks like for",
    "start": "2260140",
    "end": "2265540"
  },
  {
    "text": "the sum of two ten sided dice and why is this true well it's true for a very simple reason there's only one way to",
    "start": "2265540",
    "end": "2271780"
  },
  {
    "text": "make twenty that's a 10 and a 10 but there are lot of ways to make 12 you",
    "start": "2271780",
    "end": "2277690"
  },
  {
    "text": "know 10 + 2 9 + 3 8 + 4 7 + 5 and so on so it just becomes much more likely that",
    "start": "2277690",
    "end": "2285220"
  },
  {
    "text": "you're going to make that 9 and 10 and 11 12 13 then you're all going to need to make 20 and it turns out the more of",
    "start": "2285220",
    "end": "2294070"
  },
  {
    "text": "these dice you throw these uncorrelated dice you throw the better the distribution behaves and even throwing",
    "start": "2294070",
    "end": "2301480"
  },
  {
    "text": "10 dice you can see that I've really pushed down the extremes it's really unlikely that I'm gonna roll a hundred",
    "start": "2301480",
    "end": "2308530"
  },
  {
    "text": "it's really unlikely that I'm gonna roll 10 so I pushed down those extremes and I",
    "start": "2308530",
    "end": "2314860"
  },
  {
    "text": "move the chances of load on my server or or some of my dice into a narrow",
    "start": "2314860",
    "end": "2320670"
  },
  {
    "text": "predictable spike and the more workloads you put on a box and the more",
    "start": "2320670",
    "end": "2325720"
  },
  {
    "text": "uncorrelated workloads and that's very important you put on a box the better behaved they are in aggregate so this is",
    "start": "2325720",
    "end": "2332320"
  },
  {
    "text": "something that is very powerful for us at scale and the fact that aw ran so many different customer workloads",
    "start": "2332320",
    "end": "2339640"
  },
  {
    "text": "gives us the ability to find uncorrelated ones and put them onto hardware and this is something that",
    "start": "2339640",
    "end": "2345190"
  },
  {
    "text": "people can't do at lower scale or doesn't work well at lower scale and it's fairly unusual in computing to find",
    "start": "2345190",
    "end": "2351910"
  },
  {
    "text": "problems that get easier at scale so I kind of enjoyed this one it turns out we",
    "start": "2351910",
    "end": "2359230"
  },
  {
    "text": "can actually do better than that better than just chance by going and finding workloads that are anti-correlated you",
    "start": "2359230",
    "end": "2365980"
  },
  {
    "text": "know ones that spike down on CPU when another one spikes up and this is something that we've started doing in",
    "start": "2365980",
    "end": "2371380"
  },
  {
    "text": "our placement service going off and finding workloads that pack together really nicely and make that distribution",
    "start": "2371380",
    "end": "2378160"
  },
  {
    "text": "even tighter than it would be if it was just based on chance so moving on from",
    "start": "2378160",
    "end": "2384850"
  },
  {
    "text": "this topic I want you to talk about another investment that we're making over the course of 2019 are enabled by",
    "start": "2384850",
    "end": "2390790"
  },
  {
    "text": "our work on firecracker and that it's an investment in improving VPC cold-start",
    "start": "2390790",
    "end": "2396490"
  },
  {
    "text": "latency so let's talk about how VPC works in lambda what we do in lambda is",
    "start": "2396490",
    "end": "2401890"
  },
  {
    "text": "when you create a function in your V PC and you invoke it we go off and we",
    "start": "2401890",
    "end": "2407440"
  },
  {
    "text": "create an ec2 eni an elastic network interface just the kind that you would have an ec2 we attach that eni to the",
    "start": "2407440",
    "end": "2414280"
  },
  {
    "text": "worker and attaching in the NI to worker takes some amount of time because ec2",
    "start": "2414280",
    "end": "2419290"
  },
  {
    "text": "has to go back and do a huge amount of rejiggering of the network to get the right packets to go to the right places and every one of those en i's consumes",
    "start": "2419290",
    "end": "2427060"
  },
  {
    "text": "an IP address in your subnet so there's a great model in some ways one is that it's conceptually simple another is that",
    "start": "2427060",
    "end": "2434920"
  },
  {
    "text": "it supports the full VPC feature set so this way we started as an implementation but it does have this huge downside of",
    "start": "2434920",
    "end": "2441580"
  },
  {
    "text": "VPC cold-start latency which we've heard from a lot of customers is something you care about deeply so in 2019 we're",
    "start": "2441580",
    "end": "2450730"
  },
  {
    "text": "moving the way this works we're taking the DNI and we're moving that off the",
    "start": "2450730",
    "end": "2456820"
  },
  {
    "text": "worker and instead of doing network address translation are between or NAT",
    "start": "2456820",
    "end": "2462400"
  },
  {
    "text": "between the lambda function on the worker and the NI locally we're moving",
    "start": "2462400",
    "end": "2468130"
  },
  {
    "text": "that into a remote NAT and we're securely tunneling from the lambda function to the remote NAT so",
    "start": "2468130",
    "end": "2474940"
  },
  {
    "text": "what does this mean well in practice it means that we can use 1 e and I across many different workers we can",
    "start": "2474940",
    "end": "2481930"
  },
  {
    "text": "essentially multi-tenant those en eyes and this lets us you make music or get",
    "start": "2481930",
    "end": "2487420"
  },
  {
    "text": "away with many many fewer en eyes and the fact that we have many fewer en eyes",
    "start": "2487420",
    "end": "2492670"
  },
  {
    "text": "means that a lot of the time we can create them at the time that you create a function rather than at the time the",
    "start": "2492670",
    "end": "2498880"
  },
  {
    "text": "function scales app and what this means view is much more predictable VPC",
    "start": "2498880",
    "end": "2504550"
  },
  {
    "text": "latency so you'll see this coming in over the course of 2019 but also faster",
    "start": "2504550",
    "end": "2509860"
  },
  {
    "text": "scaling the ability to ramp up faster than you have before without running into limits around en eyes or around IP",
    "start": "2509860",
    "end": "2516910"
  },
  {
    "text": "addresses but there's another reason this is so important and that's it that's because it's just way easier to",
    "start": "2516910",
    "end": "2523660"
  },
  {
    "text": "use one of the edge cases in lambda VPC is that it's hard to predict how many IP",
    "start": "2523660",
    "end": "2530980"
  },
  {
    "text": "addresses a lambda function is going to need so you know as your lambda function",
    "start": "2530980",
    "end": "2536230"
  },
  {
    "text": "scales up every single worker is going to consume an IP address from from your subnet and that makes your network",
    "start": "2536230",
    "end": "2543160"
  },
  {
    "text": "management focuses life fairly complicated in this new model things are",
    "start": "2543160",
    "end": "2548200"
  },
  {
    "text": "much much simpler because for most workloads we're going to need exactly one IP from each subnet so that's gonna",
    "start": "2548200",
    "end": "2556570"
  },
  {
    "text": "make that management task way simpler than it was in the past I wanted to get back to firecracker as",
    "start": "2556570",
    "end": "2567070"
  },
  {
    "text": "we ramped up wrap up here a little bit and talk about why we've we've talked about it so much this week and why",
    "start": "2567070",
    "end": "2573220"
  },
  {
    "text": "you've heard so much about firecracker and that's because we're extremely excited about how it enables our",
    "start": "2573220",
    "end": "2579280"
  },
  {
    "text": "innovation firecracker gives us much lower startup time than other similar",
    "start": "2579280",
    "end": "2584860"
  },
  {
    "text": "virtualization solutions it gets gives us lower memory overhead very similar",
    "start": "2584860",
    "end": "2590350"
  },
  {
    "text": "performance but most importantly it gives us a huge amount of flexibility and this is giving my team the ability",
    "start": "2590350",
    "end": "2599020"
  },
  {
    "text": "to do all kinds of things like that VPC improve and that you're going to see show up in",
    "start": "2599020",
    "end": "2604509"
  },
  {
    "text": "lamda over time so for us firecracker",
    "start": "2604509",
    "end": "2610059"
  },
  {
    "text": "unlocks innovation but for you firecracker unlocks higher utilization and higher scale it unlocks the you know",
    "start": "2610059",
    "end": "2620019"
  },
  {
    "text": "increasing the ability for us to give you ramping up in you know for scale",
    "start": "2620019",
    "end": "2625239"
  },
  {
    "text": "ramp up and higher numbers of absolute or higher amounts of absolute scale so",
    "start": "2625239",
    "end": "2630249"
  },
  {
    "text": "we're very excited about firecracker and we're very excited about the stuff that's gonna let us do over the next few years so in conclusion you heard Holly",
    "start": "2630249",
    "end": "2639670"
  },
  {
    "text": "talked about how lambda goes together those front-end components the invoke",
    "start": "2639670",
    "end": "2645549"
  },
  {
    "text": "service and the counting service and placement and I talked about the worker and how we think about security",
    "start": "2645549",
    "end": "2651249"
  },
  {
    "text": "isolation and how we think about utilization and how we think about packing but the great thing about lambda",
    "start": "2651249",
    "end": "2658359"
  },
  {
    "text": "the thing I'm excited about in service is that you can leave this room and forget about all of this stuff it's just",
    "start": "2658359",
    "end": "2664479"
  },
  {
    "text": "been for your entertainment",
    "start": "2664479",
    "end": "2667769"
  },
  {
    "text": "so I hope you enjoyed hearing about it and then going off and building things that you don't need to need to look",
    "start": "2676000",
    "end": "2683119"
  },
  {
    "text": "under the covers and can just go off and build your business logic and deliver value to your businesses without without",
    "start": "2683119",
    "end": "2690109"
  },
  {
    "text": "needing to needing to understand a lot of this deep architecture stuff well thank you very much Holly's gonna join",
    "start": "2690109",
    "end": "2696320"
  },
  {
    "text": "me back on stage for for some questions I just flew through them in the deck again yeah thank you",
    "start": "2696320",
    "end": "2703650"
  },
  {
    "text": "[Applause]",
    "start": "2703650",
    "end": "2712700"
  },
  {
    "text": "any questions yeah so the question was",
    "start": "2712700",
    "end": "2727770"
  },
  {
    "text": "to slam the French in work with API gateway in the same way that's probably a great question for Holly the lambda",
    "start": "2727770",
    "end": "2734160"
  },
  {
    "text": "friends can work with API gateways it integrated with the API gateway actually",
    "start": "2734160",
    "end": "2740430"
  },
  {
    "text": "a very common use case is to call in to lambda functions and that invocation",
    "start": "2740430",
    "end": "2748859"
  },
  {
    "text": "works just like you you would have seen API gateway literally calls the lambda",
    "start": "2748859",
    "end": "2754230"
  },
  {
    "text": "invoke API you know just like you can call the lambda invoke API and there's",
    "start": "2754230",
    "end": "2759420"
  },
  {
    "text": "one thing that we kind of like architectural e and AWS is using our public api's because you know because if",
    "start": "2759420",
    "end": "2766740"
  },
  {
    "text": "we if we need an API or we need a control chances are you do too and using",
    "start": "2766740",
    "end": "2771810"
  },
  {
    "text": "our own API gets us you know a great understanding of you know what the needs",
    "start": "2771810",
    "end": "2776849"
  },
  {
    "text": "are of customers at scale using that same API yes so instead of using virtual",
    "start": "2776849",
    "end": "2786420"
  },
  {
    "text": "you know pcs on micro v ends why don't you run it under s containers you know",
    "start": "2786420",
    "end": "2794160"
  },
  {
    "text": "lambda functions on top of containers right or on top of a key s instead of ec2 hypothetical question sure why do we",
    "start": "2794160",
    "end": "2804810"
  },
  {
    "text": "run not run lambda functions as containers we believe that virtualization is the right security",
    "start": "2804810",
    "end": "2810210"
  },
  {
    "text": "boundary across accounts I can't go into exactly all of the details why we",
    "start": "2810210",
    "end": "2815339"
  },
  {
    "text": "believe that here but I'd be happy to talk later but we think that hardware",
    "start": "2815339",
    "end": "2822210"
  },
  {
    "text": "virtualization is is should be the minimum bar for code multi-tenancy",
    "start": "2822210",
    "end": "2827970"
  },
  {
    "text": "across multiple accounts so with the",
    "start": "2827970",
    "end": "2834390"
  },
  {
    "text": "changes to the eyes in the concurrency does that mean we're not gonna have to do that crazy concurrency formula",
    "start": "2834390",
    "end": "2841570"
  },
  {
    "text": "in deciding how many IPS we need for a subnet that the lambdas are attached to yeah we hope so",
    "start": "2841570",
    "end": "2848190"
  },
  {
    "text": "when over the course of 2019 ok we'll",
    "start": "2848190",
    "end": "2860740"
  },
  {
    "text": "we'll have more precise dates to share for being q1 yep so my question was",
    "start": "2860740",
    "end": "2869920"
  },
  {
    "text": "about the nat gateway so it says showed up in your diagram that it then that",
    "start": "2869920",
    "end": "2876760"
  },
  {
    "text": "instance will pop up inside of the V PC do we have to pay for the running costs",
    "start": "2876760",
    "end": "2881830"
  },
  {
    "text": "of that neck gateway cuz they can be quite expensive on a monthly basis no that's that's something that's built",
    "start": "2881830",
    "end": "2888190"
  },
  {
    "text": "into our architecture so this is completely under the covers and either then lower consumption of IP addresses",
    "start": "2888190",
    "end": "2894100"
  },
  {
    "text": "you're going to see no change in networking capabilities and no change in your belt and the last question I had on",
    "start": "2894100",
    "end": "2901510"
  },
  {
    "text": "that was currently if you want outbound traffic to go through a static IP address currently you have to go through",
    "start": "2901510",
    "end": "2907570"
  },
  {
    "text": "a private subnet routed through a NAT gateway into another public subnet is",
    "start": "2907570",
    "end": "2912610"
  },
  {
    "text": "there any way of actually simplifying that so that it's it the lambda instance",
    "start": "2912610",
    "end": "2918010"
  },
  {
    "text": "can run inside of the public subnet instead or yeah no not right now but",
    "start": "2918010",
    "end": "2925930"
  },
  {
    "text": "that is a that is a great feature request on something that we will we will take a look at thank you thank you",
    "start": "2925930",
    "end": "2932640"
  },
  {
    "text": "so I noticed that you had your virtualization directly over Hardware so",
    "start": "2932640",
    "end": "2938500"
  },
  {
    "text": "how do you deal with contention of resources is there actually dealing with the contention on the network card and",
    "start": "2938500",
    "end": "2944920"
  },
  {
    "text": "the hard on the hard disk I'd say it's a",
    "start": "2944920",
    "end": "2951340"
  },
  {
    "text": "very deep topic and a great question I probably the best thing I can do is is point you at some some reinvent talks",
    "start": "2951340",
    "end": "2958210"
  },
  {
    "text": "from last year there was one that Antony Liguori did and one that Matt Wilson did you can find them on YouTube or if you",
    "start": "2958210",
    "end": "2964960"
  },
  {
    "text": "find me afterwards I can I can find the links for you that explains in detail how the ec2 nitro' system does that ok",
    "start": "2964960",
    "end": "2971440"
  },
  {
    "text": "great thanks I am here I'm very curious about the workers",
    "start": "2971440",
    "end": "2978049"
  },
  {
    "text": "and I would like to know how do you keep track of what your workers are doing where they are at and where they've done",
    "start": "2978049",
    "end": "2985099"
  },
  {
    "text": "and what kind of technology and possible languages do you use okay let's let's",
    "start": "2985099",
    "end": "2993259"
  },
  {
    "text": "ahead take that one one at a time so how do we keep track of workers so we have",
    "start": "2993259",
    "end": "2999980"
  },
  {
    "text": "multiple systems that keep track of workers both in terms of as you saw the",
    "start": "2999980",
    "end": "3006359"
  },
  {
    "text": "the placement service as well as the",
    "start": "3006359",
    "end": "3011769"
  },
  {
    "text": "worker manager and it really depends on the current state and how we're using",
    "start": "3011769",
    "end": "3017259"
  },
  {
    "text": "that worker at that point in time can you explain to me a little bit about the",
    "start": "3017259",
    "end": "3023109"
  },
  {
    "text": "the languages and where you're going with that are you just are you are you asking about what different language",
    "start": "3023109",
    "end": "3029470"
  },
  {
    "text": "runtimes we support or no I'm I'm more interested in like the internals like",
    "start": "3029470",
    "end": "3034809"
  },
  {
    "text": "these workers you mentioned a state like where does that state live and how is it",
    "start": "3034809",
    "end": "3040029"
  },
  {
    "text": "run like continually inside inside of the worker so inside of the worker we",
    "start": "3040029",
    "end": "3046869"
  },
  {
    "text": "also keep track of all of the Sam boxes",
    "start": "3046869",
    "end": "3053049"
  },
  {
    "text": "that we create so there's data structures inside of our worker that helps to do that it's more of a",
    "start": "3053049",
    "end": "3063130"
  },
  {
    "text": "confirmation here so I thought you",
    "start": "3063130",
    "end": "3068499"
  },
  {
    "text": "mentioned that one of the pain area we have with Eni being consuming IP of a",
    "start": "3068499",
    "end": "3074710"
  },
  {
    "text": "subnet and without understanding the detail about it what we ended up with I",
    "start": "3074710",
    "end": "3080470"
  },
  {
    "text": "ended up doing when we created lamda which connects to V PC it goes to the",
    "start": "3080470",
    "end": "3085779"
  },
  {
    "text": "Direct Connect and goes into our data center for transition during transition phase I ended up connecting three",
    "start": "3085779",
    "end": "3092319"
  },
  {
    "text": "subnets so is from what I understood it makes sense just to have two subnet",
    "start": "3092319",
    "end": "3098640"
  },
  {
    "text": "connected basically to avoid because you",
    "start": "3098640",
    "end": "3103720"
  },
  {
    "text": "just need one for failover let's say you're still going to want to have",
    "start": "3103720",
    "end": "3109400"
  },
  {
    "text": "ideally i1 subnet / availability zone that the thing that you're talking to R",
    "start": "3109400",
    "end": "3115950"
  },
  {
    "text": "and Z so if your back-end runs across three availability zones you're going to want to need you're going to want three",
    "start": "3115950",
    "end": "3122520"
  },
  {
    "text": "subnets to you know to balance the load and to make that make it fault tolerance",
    "start": "3122520",
    "end": "3128610"
  },
  {
    "text": "better it runs across for ACS you're gonna want four subnets and for a couple",
    "start": "3128610",
    "end": "3135000"
  },
  {
    "text": "of reasons one of them is it gives us more placement flexibility and then we can make better decisions on your behalf",
    "start": "3135000",
    "end": "3140750"
  },
  {
    "text": "but it also means that you know if you don't have a sudden 8 in one of your AZ's we won't be sending load into that",
    "start": "3140750",
    "end": "3147900"
  },
  {
    "text": "AZ's you'll kind of end up with unbalanced load on your back-end so we think that you know this new VPC",
    "start": "3147900",
    "end": "3154500"
  },
  {
    "text": "approach is going to make things much easier to balance by reducing the number of IPs that you need but it's not going to",
    "start": "3154500",
    "end": "3161730"
  },
  {
    "text": "change those best practices about having you know essentially 178 parisi in front",
    "start": "3161730",
    "end": "3167730"
  },
  {
    "text": "of your backends I was just thinking till you guys have that feature available should I think of producing",
    "start": "3167730",
    "end": "3173880"
  },
  {
    "text": "one submit just to avoid but looks like from balancing point of view yeah from a",
    "start": "3173880",
    "end": "3181980"
  },
  {
    "text": "from a load balancing and and fault tolerance point of view it's better to have three subnets all right got two",
    "start": "3181980",
    "end": "3190740"
  },
  {
    "text": "questions first one is about cold start I've got customers who use an API gateway with laptop behind them and they",
    "start": "3190740",
    "end": "3197850"
  },
  {
    "text": "have some very strict SLS and they noticed that if there are cold start habits they don't meet their resumes so",
    "start": "3197850",
    "end": "3203940"
  },
  {
    "text": "they're using these really convoluted frameworks to make sure that they also always have a certain number of lambdas",
    "start": "3203940",
    "end": "3210030"
  },
  {
    "text": "provisions but it's just hard at the moment is there anything in the works that allows you just to specify how many",
    "start": "3210030",
    "end": "3216810"
  },
  {
    "text": "warm lab does you will want to have provisioned at any given time I'll take this one so we are very aware that for",
    "start": "3216810",
    "end": "3226470"
  },
  {
    "text": "certain use cases latency can be an issue and",
    "start": "3226470",
    "end": "3232120"
  },
  {
    "text": "one of the things that we are interested in hearing from customers and you have have just asked about it which is is",
    "start": "3232120",
    "end": "3239710"
  },
  {
    "text": "there a way of guarantee that something is warm and so it's it's great to hear",
    "start": "3239710",
    "end": "3245350"
  },
  {
    "text": "that that's something that interests you okay thanks and forgot my second one",
    "start": "3245350",
    "end": "3252580"
  },
  {
    "text": "I'll get back to you question regarding",
    "start": "3252580",
    "end": "3258130"
  },
  {
    "text": "they're more heterogeneous resource allocation potentially like maybe non",
    "start": "3258130",
    "end": "3263650"
  },
  {
    "text": "proportional allocation of resources or perhaps support for elastic GPUs is this",
    "start": "3263650",
    "end": "3272140"
  },
  {
    "text": "something that you're thinking of there is any technical implications or is it more of a business decision I would be",
    "start": "3272140",
    "end": "3282100"
  },
  {
    "text": "very interested to hear more about what you would like to see there in terms of controls so maybe we should we should",
    "start": "3282100",
    "end": "3288130"
  },
  {
    "text": "chat afterwards but I think as they kind",
    "start": "3288130",
    "end": "3293590"
  },
  {
    "text": "of met a point like one of our goals with with serverless is to keep things as simple as possible and that doesn't",
    "start": "3293590",
    "end": "3300880"
  },
  {
    "text": "mean that you know we want to compromise on stuff like that but we want to be",
    "start": "3300880",
    "end": "3308290"
  },
  {
    "text": "very thoughtful about the buttons and knobs and controls we add because the more buttons and knobs and controls and",
    "start": "3308290",
    "end": "3313840"
  },
  {
    "text": "things we add the more there is going to be for you and your team's to understand to use lambda effectively so we think we",
    "start": "3313840",
    "end": "3320680"
  },
  {
    "text": "can get to most use cases that need additional controls without building additional controls so that's what I'd",
    "start": "3320680",
    "end": "3326590"
  },
  {
    "text": "like to hear more about your use case and see if it fits into our thinking about how to solve these problems",
    "start": "3326590",
    "end": "3331690"
  },
  {
    "text": "without pushing that complexity on to you well I guess maybe we can take this",
    "start": "3331690",
    "end": "3337150"
  },
  {
    "text": "offline yeah hey so we have time for just maybe one or two more questions I",
    "start": "3337150",
    "end": "3342310"
  },
  {
    "text": "just want to let people know yeah if that's okay",
    "start": "3342310",
    "end": "3347410"
  },
  {
    "text": "is there anything in the roadmap in the future that you're going to decouple the amount of memory in the amount of CPU",
    "start": "3347410",
    "end": "3353470"
  },
  {
    "text": "resources that you've assigned to love the functions right now I'm again a slave problem we have to assign well",
    "start": "3353470",
    "end": "3360910"
  },
  {
    "text": "over a gigabyte of memory to love the function that only requires 42 mix in order to meet our SLA target",
    "start": "3360910",
    "end": "3367650"
  },
  {
    "text": "which is just a waste of tremendous amount of memory",
    "start": "3367650",
    "end": "3373068"
  },
  {
    "text": "I think the same answer as the previous one we think that we can get rid of that",
    "start": "3373109",
    "end": "3379829"
  },
  {
    "text": "waste on your behalf without adding the additional controls so I'd like to if you have a moment afterwards or we can",
    "start": "3379829",
    "end": "3386309"
  },
  {
    "text": "get in contact and hear about exactly what you'd like to see there in terms of in terms of control for example",
    "start": "3386309",
    "end": "3394079"
  },
  {
    "text": "actually yeah let's just share afterwards yeah I'm wondering uh just",
    "start": "3394079",
    "end": "3399630"
  },
  {
    "text": "what keeps you up at night about this system what keeps you up at night",
    "start": "3399630",
    "end": "3411150"
  },
  {
    "text": "what are you pretty scared of you know I",
    "start": "3411150",
    "end": "3417900"
  },
  {
    "text": "I was I was talking to mark backstage",
    "start": "3417900",
    "end": "3423029"
  },
  {
    "text": "before our talk and I'm actually very",
    "start": "3423029",
    "end": "3428160"
  },
  {
    "text": "excited about where we're at with the Surrealists technology and where we're",
    "start": "3428160",
    "end": "3434009"
  },
  {
    "text": "going to and you know back to the conversation on firecracker and the innovation that we can drive I I truly",
    "start": "3434009",
    "end": "3442650"
  },
  {
    "text": "believe that you know this is the future of computing and so you know I sleep",
    "start": "3442650",
    "end": "3449700"
  },
  {
    "text": "well at night [Laughter] do you have time for one more tip time",
    "start": "3449700",
    "end": "3456180"
  },
  {
    "text": "for one more mark oh yeah hi thanks I've done you know better",
    "start": "3456180",
    "end": "3462480"
  },
  {
    "text": "testing with running many simultaneous invocations of pretty simple functions",
    "start": "3462480",
    "end": "3468569"
  },
  {
    "text": "that do one remarkable things but I'll see sometimes well in the distribution",
    "start": "3468569",
    "end": "3473640"
  },
  {
    "text": "of run times of an instance let's see five verse a factor of five or six",
    "start": "3473640",
    "end": "3479539"
  },
  {
    "text": "easily in the minimum run time and the maximum run time I just like to",
    "start": "3479539",
    "end": "3485490"
  },
  {
    "text": "understand what I'm seeing I'm curious is that something that you would expect is that something like oh there's always",
    "start": "3485490",
    "end": "3491849"
  },
  {
    "text": "some number of instances that are on health and that's what it looks like just curious if you could comment on that we",
    "start": "3491849",
    "end": "3498380"
  },
  {
    "text": "certainly wouldn't expect high variance at steady-state so if you're running a constant load what we would expect to",
    "start": "3498380",
    "end": "3505249"
  },
  {
    "text": "see is you know very consistent performance you know obviously if your code is doing something that takes a",
    "start": "3505249",
    "end": "3511609"
  },
  {
    "text": "consistent amount of time so if you're seeing something other than that I'd be interested in getting in touch and we can we can dive into that at not",
    "start": "3511609",
    "end": "3519380"
  },
  {
    "text": "steady-state if you're ramping up or ramping down you get this this auto scaling behavior that Holly talked about where we're adding sand boxes or we're",
    "start": "3519380",
    "end": "3525769"
  },
  {
    "text": "removing sand boxes and for the vast majority of cases where you're seeing inconsistent latency it's during those",
    "start": "3525769",
    "end": "3531559"
  },
  {
    "text": "scaling times and that's something that we're working very hard on improving over the next year starting with you",
    "start": "3531559",
    "end": "3538670"
  },
  {
    "text": "know the VP seal agency but but working on all aspects of that problem well",
    "start": "3538670",
    "end": "3545179"
  },
  {
    "text": "thank you everyone thank you for coming and watching our talk [Applause]",
    "start": "3545179",
    "end": "3554219"
  }
]
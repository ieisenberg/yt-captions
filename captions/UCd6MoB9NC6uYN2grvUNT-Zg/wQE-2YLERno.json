[
  {
    "text": "hi everyone uh my name is Jeff kisy I'm",
    "start": "359",
    "end": "2520"
  },
  {
    "text": "the CEO and co-founder of engin ML and",
    "start": "2520",
    "end": "5440"
  },
  {
    "text": "engin ml what we want to do is we want",
    "start": "5440",
    "end": "7040"
  },
  {
    "text": "to help companies that are doing deep",
    "start": "7040",
    "end": "8760"
  },
  {
    "text": "learning scale beyond the 4 GPU training",
    "start": "8760",
    "end": "11160"
  },
  {
    "text": "that you're used to when you buy a box",
    "start": "11160",
    "end": "12519"
  },
  {
    "text": "and put it under your desk um uh before",
    "start": "12519",
    "end": "15759"
  },
  {
    "text": "starting engine ml I was a master",
    "start": "15759",
    "end": "17880"
  },
  {
    "text": "student at Stanford working in Andrew",
    "start": "17880",
    "end": "19400"
  },
  {
    "text": "in's lab doing deep learning research",
    "start": "19400",
    "end": "21320"
  },
  {
    "text": "for self-driving vehicles I co-founded",
    "start": "21320",
    "end": "23800"
  },
  {
    "text": "Drive AI I then joined Auto as a machine",
    "start": "23800",
    "end": "26400"
  },
  {
    "text": "learning engineer and then went to Uber",
    "start": "26400",
    "end": "28320"
  },
  {
    "text": "doing deep learning object detection and",
    "start": "28320",
    "end": "30359"
  },
  {
    "text": "3D recognition for things like Vehicles",
    "start": "30359",
    "end": "33000"
  },
  {
    "text": "bicyclists uh and Lane lines so I",
    "start": "33000",
    "end": "35840"
  },
  {
    "text": "believe that we are in a winter take all",
    "start": "35840",
    "end": "38040"
  },
  {
    "text": "uh race for progress with deep learning",
    "start": "38040",
    "end": "40559"
  },
  {
    "text": "uh for self-driving Vehicles there's a",
    "start": "40559",
    "end": "42640"
  },
  {
    "text": "bunch of analysts that have have said",
    "start": "42640",
    "end": "44160"
  },
  {
    "text": "that the first person that can deploy a",
    "start": "44160",
    "end": "46039"
  },
  {
    "text": "self-driving vehicle will be able to",
    "start": "46039",
    "end": "47680"
  },
  {
    "text": "capture a hundred billion dollar maybe a",
    "start": "47680",
    "end": "49520"
  },
  {
    "text": "trillion dollar market or multi-trillion",
    "start": "49520",
    "end": "51120"
  },
  {
    "text": "dollar market and being able to get the",
    "start": "51120",
    "end": "53760"
  },
  {
    "text": "first car on the road as fast as you can",
    "start": "53760",
    "end": "56399"
  },
  {
    "text": "is super super super important so this",
    "start": "56399",
    "end": "58719"
  },
  {
    "text": "is why you have so many companies is",
    "start": "58719",
    "end": "60120"
  },
  {
    "text": "trying to work towards this and this is",
    "start": "60120",
    "end": "61680"
  },
  {
    "text": "why I was so excited to work at at all",
    "start": "61680",
    "end": "63359"
  },
  {
    "text": "of these different self-driving",
    "start": "63359",
    "end": "64559"
  },
  {
    "text": "companies um I also believe that it's a",
    "start": "64560",
    "end": "66720"
  },
  {
    "text": "race to save the environment uh Google a",
    "start": "66720",
    "end": "69000"
  },
  {
    "text": "few years ago released a paper where",
    "start": "69000",
    "end": "70560"
  },
  {
    "text": "they were able to reduce their en energy",
    "start": "70560",
    "end": "72640"
  },
  {
    "text": "consumption in their data centers by",
    "start": "72640",
    "end": "74520"
  },
  {
    "text": "around 40% uh using research from their",
    "start": "74520",
    "end": "76960"
  },
  {
    "text": "deep mine laboratory uh in London and",
    "start": "76960",
    "end": "80119"
  },
  {
    "text": "you know if you reduce the the energy",
    "start": "80119",
    "end": "82040"
  },
  {
    "text": "usage in your house maybe you'll save",
    "start": "82040",
    "end": "83360"
  },
  {
    "text": "$100 but when you're at Google scale or",
    "start": "83360",
    "end": "86280"
  },
  {
    "text": "Amazon scale or Microsoft scale that's",
    "start": "86280",
    "end": "88640"
  },
  {
    "text": "very very important and amounts to",
    "start": "88640",
    "end": "90159"
  },
  {
    "text": "Millions tens hundreds of millions of",
    "start": "90159",
    "end": "91840"
  },
  {
    "text": "dollars a year and finally I believe",
    "start": "91840",
    "end": "94000"
  },
  {
    "text": "that deep learning will help us save",
    "start": "94000",
    "end": "95320"
  },
  {
    "text": "lives uh when I was at Stanford I was",
    "start": "95320",
    "end": "97200"
  },
  {
    "text": "working with a couple colleagues that",
    "start": "97200",
    "end": "98880"
  },
  {
    "text": "were doing deep learning detection of uh",
    "start": "98880",
    "end": "102119"
  },
  {
    "text": "skin cancer and during the uh the",
    "start": "102119",
    "end": "105040"
  },
  {
    "text": "process they were able to detect skin",
    "start": "105040",
    "end": "106680"
  },
  {
    "text": "cancer on patients using just a cell",
    "start": "106680",
    "end": "108520"
  },
  {
    "text": "phone camera better than board certified",
    "start": "108520",
    "end": "110600"
  },
  {
    "text": "dermatologists so you can imagine a",
    "start": "110600",
    "end": "112439"
  },
  {
    "text": "scenario where you deploy this out to",
    "start": "112439",
    "end": "114960"
  },
  {
    "text": "everybody in the world people that don't",
    "start": "114960",
    "end": "116240"
  },
  {
    "text": "have access to dermatologist uh readily",
    "start": "116240",
    "end": "118680"
  },
  {
    "text": "and they can easily detect skin cancer",
    "start": "118680",
    "end": "121119"
  },
  {
    "text": "way before they need to go see a doctor",
    "start": "121119",
    "end": "123360"
  },
  {
    "text": "and they can uh they can get the the",
    "start": "123360",
    "end": "125320"
  },
  {
    "text": "treatment that they need very early on",
    "start": "125320",
    "end": "127640"
  },
  {
    "text": "so uh getting to this point is very very",
    "start": "127640",
    "end": "130599"
  },
  {
    "text": "important and all of these problems can",
    "start": "130599",
    "end": "132360"
  },
  {
    "text": "be solved with with deep learning so I'm",
    "start": "132360",
    "end": "134239"
  },
  {
    "text": "going to go a little bit into the Weeds",
    "start": "134239",
    "end": "135640"
  },
  {
    "text": "now and talk about um where we're at",
    "start": "135640",
    "end": "138200"
  },
  {
    "text": "today and how things have changed over",
    "start": "138200",
    "end": "139760"
  },
  {
    "text": "the past few years with uh machine",
    "start": "139760",
    "end": "141720"
  },
  {
    "text": "learning so uh up here is the slide uh I",
    "start": "141720",
    "end": "145120"
  },
  {
    "text": "put together some of the most recent",
    "start": "145120",
    "end": "146720"
  },
  {
    "text": "examples where people have trained",
    "start": "146720",
    "end": "148440"
  },
  {
    "text": "what's called imet image Net's a data",
    "start": "148440",
    "end": "151160"
  },
  {
    "text": "set of 14 million examples uh there's a",
    "start": "151160",
    "end": "153760"
  },
  {
    "text": "thousand classes from uh horses to uh",
    "start": "153760",
    "end": "157480"
  },
  {
    "text": "different types of breeds of dogs and",
    "start": "157480",
    "end": "159840"
  },
  {
    "text": "right now we're at superhuman levels of",
    "start": "159840",
    "end": "161800"
  },
  {
    "text": "accuracy uh and generally what that",
    "start": "161800",
    "end": "163760"
  },
  {
    "text": "means is you're at about 75% accuracy",
    "start": "163760",
    "end": "166800"
  },
  {
    "text": "top one so uh the most recent examples",
    "start": "166800",
    "end": "169280"
  },
  {
    "text": "that you've seen come out of um of",
    "start": "169280",
    "end": "172200"
  },
  {
    "text": "places like Facebook and places like um",
    "start": "172200",
    "end": "175319"
  },
  {
    "text": "Google are like maybe top top five",
    "start": "175319",
    "end": "178360"
  },
  {
    "text": "accuracy of 3% error rate but most of",
    "start": "178360",
    "end": "180640"
  },
  {
    "text": "the time when we when we look to say",
    "start": "180640",
    "end": "182680"
  },
  {
    "text": "when this problem is solved it's 75%",
    "start": "182680",
    "end": "184840"
  },
  {
    "text": "accuracy top one so in the top left",
    "start": "184840",
    "end": "187000"
  },
  {
    "text": "corner you'll see issue uh a few papers",
    "start": "187000",
    "end": "189239"
  },
  {
    "text": "that you may have seen before uh there's",
    "start": "189239",
    "end": "191120"
  },
  {
    "text": "things like Inception there's things",
    "start": "191120",
    "end": "193159"
  },
  {
    "text": "like resnet and then this 5day one right",
    "start": "193159",
    "end": "196000"
  },
  {
    "text": "here is res next and so uh around this",
    "start": "196000",
    "end": "200159"
  },
  {
    "text": "time back between 2016 and 2017 most",
    "start": "200159",
    "end": "203519"
  },
  {
    "text": "people were training on a single machine",
    "start": "203519",
    "end": "205360"
  },
  {
    "text": "under their desk so for example uh uh",
    "start": "205360",
    "end": "208560"
  },
  {
    "text": "this 10day one is resnet it took 10 days",
    "start": "208560",
    "end": "211040"
  },
  {
    "text": "to train on 8 gpus Facebook was then",
    "start": "211040",
    "end": "213360"
  },
  {
    "text": "able to cut that time down by modifying",
    "start": "213360",
    "end": "216000"
  },
  {
    "text": "their model a bit but it still took them",
    "start": "216000",
    "end": "217760"
  },
  {
    "text": "10 sorry excuse me five days to train",
    "start": "217760",
    "end": "219799"
  },
  {
    "text": "their model and when you're in machine",
    "start": "219799",
    "end": "221680"
  },
  {
    "text": "learning you know how hard it is to know",
    "start": "221680",
    "end": "223720"
  },
  {
    "text": "if your model is going to do better uh",
    "start": "223720",
    "end": "225760"
  },
  {
    "text": "right when you kick it off so you're",
    "start": "225760",
    "end": "227040"
  },
  {
    "text": "basically starting a job you'll come",
    "start": "227040",
    "end": "228480"
  },
  {
    "text": "back a week later and try and figure out",
    "start": "228480",
    "end": "230280"
  },
  {
    "text": "if that model actually performed better",
    "start": "230280",
    "end": "232640"
  },
  {
    "text": "a few months later another group at",
    "start": "232640",
    "end": "233959"
  },
  {
    "text": "Facebook uh released a paper called",
    "start": "233959",
    "end": "235720"
  },
  {
    "text": "training imag net in under an hour and",
    "start": "235720",
    "end": "237680"
  },
  {
    "text": "what they were able to do is take that",
    "start": "237680",
    "end": "239079"
  },
  {
    "text": "8gpu workload and split it across 500",
    "start": "239079",
    "end": "242200"
  },
  {
    "text": "gpus 1,000 gpus and they were able to",
    "start": "242200",
    "end": "244599"
  },
  {
    "text": "shrink that time down to train that",
    "start": "244599",
    "end": "246200"
  },
  {
    "text": "model by 120x and so since then uh",
    "start": "246200",
    "end": "249760"
  },
  {
    "text": "people have been able to shrink that",
    "start": "249760",
    "end": "251000"
  },
  {
    "text": "down now most recently by uh uh by um I",
    "start": "251000",
    "end": "257239"
  },
  {
    "text": "forget who it was but uh down to three",
    "start": "257239",
    "end": "258919"
  },
  {
    "text": "and a half minutes uh Sony by three and",
    "start": "258919",
    "end": "260799"
  },
  {
    "text": "a half minutes and that was just at the",
    "start": "260799",
    "end": "262800"
  },
  {
    "text": "uh the end of last year so another thing",
    "start": "262800",
    "end": "265120"
  },
  {
    "text": "to note about this slide is every bullet",
    "start": "265120",
    "end": "267199"
  },
  {
    "text": "point on this comes from a Fortune 500",
    "start": "267199",
    "end": "269479"
  },
  {
    "text": "company and what we want to do atml is",
    "start": "269479",
    "end": "271600"
  },
  {
    "text": "make it so it's possible that so anybody",
    "start": "271600",
    "end": "273240"
  },
  {
    "text": "can be on this slide anybody can train",
    "start": "273240",
    "end": "274680"
  },
  {
    "text": "their model in less than a day uh this",
    "start": "274680",
    "end": "277160"
  },
  {
    "text": "is super important going back to my",
    "start": "277160",
    "end": "278720"
  },
  {
    "text": "previous slide when you want to get your",
    "start": "278720",
    "end": "280120"
  },
  {
    "text": "self-driving Vehicles out faster when",
    "start": "280120",
    "end": "281639"
  },
  {
    "text": "you want to reduce energy in your data",
    "start": "281639",
    "end": "283000"
  },
  {
    "text": "centers and when you want to uh detect",
    "start": "283000",
    "end": "285680"
  },
  {
    "text": "cancer and improve the world so let's",
    "start": "285680",
    "end": "288840"
  },
  {
    "text": "see so uh a lot of people have a hard",
    "start": "288840",
    "end": "291280"
  },
  {
    "text": "time quantifying what a 100x speed up",
    "start": "291280",
    "end": "293120"
  },
  {
    "text": "looks like if I say things go 10x faster",
    "start": "293120",
    "end": "295919"
  },
  {
    "text": "a lot of times you can get to the point",
    "start": "295919",
    "end": "297120"
  },
  {
    "text": "you be like oh 10x is I can understand",
    "start": "297120",
    "end": "298919"
  },
  {
    "text": "that but 12x is something that's very",
    "start": "298919",
    "end": "301360"
  },
  {
    "text": "very hard to Fathom so I put together a",
    "start": "301360",
    "end": "303240"
  },
  {
    "text": "quick video of what that looks like and",
    "start": "303240",
    "end": "304919"
  },
  {
    "text": "all of this was done using engine",
    "start": "304919",
    "end": "307120"
  },
  {
    "text": "ml so let's see if we can get this to go",
    "start": "307120",
    "end": "310600"
  },
  {
    "text": "um real quick uh this is a model called",
    "start": "310600",
    "end": "313160"
  },
  {
    "text": "avod it was at the top of the kitty",
    "start": "313160",
    "end": "315000"
  },
  {
    "text": "leaderboard for sometime um it uses lar",
    "start": "315000",
    "end": "317960"
  },
  {
    "text": "data and Camera data in order to detect",
    "start": "317960",
    "end": "320240"
  },
  {
    "text": "things like Vehicles pedestrians uh and",
    "start": "320240",
    "end": "322960"
  },
  {
    "text": "bicyclists in the road scene Kitty is a",
    "start": "322960",
    "end": "325600"
  },
  {
    "text": "data set that's composed of 1,800",
    "start": "325600",
    "end": "327400"
  },
  {
    "text": "examples of those different data sources",
    "start": "327400",
    "end": "330120"
  },
  {
    "text": "and the goal is to be able to detect",
    "start": "330120",
    "end": "331880"
  },
  {
    "text": "these things with a certain level of",
    "start": "331880",
    "end": "333479"
  },
  {
    "text": "accuracy uh uh after the experiment is",
    "start": "333479",
    "end": "336080"
  },
  {
    "text": "done training uh so uh on the left side",
    "start": "336080",
    "end": "339000"
  },
  {
    "text": "we have us training uh this model avod",
    "start": "339000",
    "end": "341639"
  },
  {
    "text": "on one GPU and on the right side it's",
    "start": "341639",
    "end": "343520"
  },
  {
    "text": "trained on engine ml using 128 gpus and",
    "start": "343520",
    "end": "346199"
  },
  {
    "text": "this is the 128x speed up that that",
    "start": "346199",
    "end": "348360"
  },
  {
    "text": "you'll",
    "start": "348360",
    "end": "349479"
  },
  {
    "text": "see cool so every time a line is printed",
    "start": "349479",
    "end": "352240"
  },
  {
    "text": "out this is it seeing 12 128 examples of",
    "start": "352240",
    "end": "355000"
  },
  {
    "text": "your data set uh on the right side we",
    "start": "355000",
    "end": "357240"
  },
  {
    "text": "just completed one iteration or an epic",
    "start": "357240",
    "end": "359120"
  },
  {
    "text": "or epoch depending on how you say that",
    "start": "359120",
    "end": "361600"
  },
  {
    "text": "word but generally you want to get",
    "start": "361600",
    "end": "363240"
  },
  {
    "text": "through UH 60 or so maybe 100 epics",
    "start": "363240",
    "end": "366360"
  },
  {
    "text": "through your data set especially on a",
    "start": "366360",
    "end": "367720"
  },
  {
    "text": "small data set like kitty you may want",
    "start": "367720",
    "end": "369360"
  },
  {
    "text": "to train for a lot longer um on the left",
    "start": "369360",
    "end": "372160"
  },
  {
    "text": "side we still haven't even done 128",
    "start": "372160",
    "end": "374280"
  },
  {
    "text": "examples yet uh and so we just got there",
    "start": "374280",
    "end": "377160"
  },
  {
    "text": "uh the right side will take you two and",
    "start": "377160",
    "end": "378759"
  },
  {
    "text": "a half hours to complete training and be",
    "start": "378759",
    "end": "380440"
  },
  {
    "text": "able to have your model up to that",
    "start": "380440",
    "end": "381840"
  },
  {
    "text": "accuracy that you would want and on the",
    "start": "381840",
    "end": "383360"
  },
  {
    "text": "left side it would take you 2 and 1 half",
    "start": "383360",
    "end": "384880"
  },
  {
    "text": "days so you can imagine starting this",
    "start": "384880",
    "end": "387120"
  },
  {
    "text": "experiment before lunch taking a long",
    "start": "387120",
    "end": "389080"
  },
  {
    "text": "lunch break getting a coffee and coming",
    "start": "389080",
    "end": "390960"
  },
  {
    "text": "back and having your model completely",
    "start": "390960",
    "end": "392360"
  },
  {
    "text": "trained so that you can iterate really",
    "start": "392360",
    "end": "394080"
  },
  {
    "text": "quickly and go onto your next experiment",
    "start": "394080",
    "end": "395800"
  },
  {
    "text": "that you want to try out the model on",
    "start": "395800",
    "end": "397560"
  },
  {
    "text": "the left it requires a weekend it",
    "start": "397560",
    "end": "399400"
  },
  {
    "text": "requires you to uh take some of your",
    "start": "399400",
    "end": "401560"
  },
  {
    "text": "resources maybe you have four gpus under",
    "start": "401560",
    "end": "403280"
  },
  {
    "text": "your desk and you uh you're Now using",
    "start": "403280",
    "end": "405199"
  },
  {
    "text": "one of those gpus for two and a half",
    "start": "405199",
    "end": "406960"
  },
  {
    "text": "days and so it's a it's a non-starter",
    "start": "406960",
    "end": "408759"
  },
  {
    "text": "for a lot of companies but this is the",
    "start": "408759",
    "end": "410400"
  },
  {
    "text": "world that people live in for most of",
    "start": "410400",
    "end": "411800"
  },
  {
    "text": "the time because getting to the point",
    "start": "411800",
    "end": "413560"
  },
  {
    "text": "where you can train on 128 gpus is",
    "start": "413560",
    "end": "418039"
  },
  {
    "text": "difficult cool So speaking of difficult",
    "start": "418039",
    "end": "420759"
  },
  {
    "text": "there's a bunch of people who I've",
    "start": "420759",
    "end": "422160"
  },
  {
    "text": "talked to that have really struggled",
    "start": "422160",
    "end": "423960"
  },
  {
    "text": "getting to the point where they can go",
    "start": "423960",
    "end": "425360"
  },
  {
    "text": "from one machine to end machines uh",
    "start": "425360",
    "end": "428520"
  },
  {
    "text": "often times one machine means four gpus",
    "start": "428520",
    "end": "431280"
  },
  {
    "text": "on Amazon you're able to train up to 16",
    "start": "431280",
    "end": "433440"
  },
  {
    "text": "gpus um but going to that 17th GPU or to",
    "start": "433440",
    "end": "436560"
  },
  {
    "text": "that fifth GPU is very very challenging",
    "start": "436560",
    "end": "438720"
  },
  {
    "text": "and requires a lot of work to do um so",
    "start": "438720",
    "end": "441080"
  },
  {
    "text": "I've talked to a bunch of my friends",
    "start": "441080",
    "end": "442319"
  },
  {
    "text": "most of the time they're happy uh they",
    "start": "442319",
    "end": "444080"
  },
  {
    "text": "do they do their 4 GPU training but it",
    "start": "444080",
    "end": "445960"
  },
  {
    "text": "still takes them about 5 days and I just",
    "start": "445960",
    "end": "447879"
  },
  {
    "text": "found a quote from the machine learning",
    "start": "447879",
    "end": "449199"
  },
  {
    "text": "suburb Reddit I'm interested in getting",
    "start": "449199",
    "end": "451080"
  },
  {
    "text": "multi- node multi-gpu into my workflow",
    "start": "451080",
    "end": "453240"
  },
  {
    "text": "but pytorch distributed data parallel is",
    "start": "453240",
    "end": "455199"
  },
  {
    "text": "bewildering and I'm sure some of you",
    "start": "455199",
    "end": "456800"
  },
  {
    "text": "that have been doing machine learning",
    "start": "456800",
    "end": "458440"
  },
  {
    "text": "have gotten to this point where you've",
    "start": "458440",
    "end": "459919"
  },
  {
    "text": "scaled up to four gpus but getting to",
    "start": "459919",
    "end": "461879"
  },
  {
    "text": "that fifth GPU is very very difficult so",
    "start": "461879",
    "end": "464639"
  },
  {
    "text": "I want to chat a little bit about this",
    "start": "464639",
    "end": "466120"
  },
  {
    "text": "the best practices in order to go from 4",
    "start": "466120",
    "end": "468039"
  },
  {
    "text": "gpus to 5 gpus up to 128 gpus um there's",
    "start": "468039",
    "end": "472599"
  },
  {
    "text": "really only one way to do that right now",
    "start": "472599",
    "end": "474599"
  },
  {
    "text": "with software and that's a nickel-based",
    "start": "474599",
    "end": "476400"
  },
  {
    "text": "ring or hierarchical all reduce and I'm",
    "start": "476400",
    "end": "478639"
  },
  {
    "text": "not going to go into the det details",
    "start": "478639",
    "end": "479800"
  },
  {
    "text": "about how all that works just know that",
    "start": "479800",
    "end": "481800"
  },
  {
    "text": "it's very efficient it scales out to",
    "start": "481800",
    "end": "483800"
  },
  {
    "text": "about 90% efficiency so when you're",
    "start": "483800",
    "end": "485879"
  },
  {
    "text": "training on 128 gpus you're going to get",
    "start": "485879",
    "end": "488599"
  },
  {
    "text": "around 110x scale up um there's some",
    "start": "488599",
    "end": "492599"
  },
  {
    "text": "other different techniques you can use",
    "start": "492599",
    "end": "493840"
  },
  {
    "text": "some people might have heard of",
    "start": "493840",
    "end": "494800"
  },
  {
    "text": "parameter servers uh those scale out to",
    "start": "494800",
    "end": "497000"
  },
  {
    "text": "somewhere around 60% and these are",
    "start": "497000",
    "end": "499120"
  },
  {
    "text": "things that are generally built into",
    "start": "499120",
    "end": "501120"
  },
  {
    "text": "Frameworks like pytorch or Frameworks",
    "start": "501120",
    "end": "502759"
  },
  {
    "text": "like tensorflow uh by default uh",
    "start": "502759",
    "end": "505080"
  },
  {
    "text": "nickel-based ring all redu was",
    "start": "505080",
    "end": "506560"
  },
  {
    "text": "popularized by Buu in 2017 um in",
    "start": "506560",
    "end": "509560"
  },
  {
    "text": "eventually was ported into a Frameworks",
    "start": "509560",
    "end": "512159"
  },
  {
    "text": "that you might have heard called horovod",
    "start": "512159",
    "end": "513518"
  },
  {
    "text": "which was released uh by Uber in late",
    "start": "513519",
    "end": "515959"
  },
  {
    "text": "2017 and uh the scale out of these",
    "start": "515959",
    "end": "518360"
  },
  {
    "text": "Frameworks is is super impressive and it",
    "start": "518360",
    "end": "520320"
  },
  {
    "text": "allows you to very easily scale things",
    "start": "520320",
    "end": "522120"
  },
  {
    "text": "out now the uh the infrastructure world",
    "start": "522120",
    "end": "525640"
  },
  {
    "text": "is not the same um whereas there's kind",
    "start": "525640",
    "end": "529200"
  },
  {
    "text": "of one best practice where you would you",
    "start": "529200",
    "end": "530839"
  },
  {
    "text": "would allow yourself to distribute your",
    "start": "530839",
    "end": "532120"
  },
  {
    "text": "model on one machine when you want to go",
    "start": "532120",
    "end": "533800"
  },
  {
    "text": "to multiple machines it becomes very",
    "start": "533800",
    "end": "535480"
  },
  {
    "text": "difficult and uh this slide just",
    "start": "535480",
    "end": "537560"
  },
  {
    "text": "captures some of the different",
    "start": "537560",
    "end": "538519"
  },
  {
    "text": "trade-offs you have to choose when",
    "start": "538519",
    "end": "540000"
  },
  {
    "text": "building out your distributed machine",
    "start": "540000",
    "end": "541560"
  },
  {
    "text": "learning uh pipeline so I'm want to",
    "start": "541560",
    "end": "544079"
  },
  {
    "text": "highlight one of them uh storing and",
    "start": "544079",
    "end": "546000"
  },
  {
    "text": "fetching data Amazon offers a couple",
    "start": "546000",
    "end": "548399"
  },
  {
    "text": "different types of services and ways for",
    "start": "548399",
    "end": "550200"
  },
  {
    "text": "you to save your data on on that machine",
    "start": "550200",
    "end": "552640"
  },
  {
    "text": "or uh in the cloud uh you can save your",
    "start": "552640",
    "end": "554640"
  },
  {
    "text": "things on EFS which is Amazon's",
    "start": "554640",
    "end": "556279"
  },
  {
    "text": "equivalent of an NFS like file store you",
    "start": "556279",
    "end": "558560"
  },
  {
    "text": "can save things on EBS which are block",
    "start": "558560",
    "end": "560279"
  },
  {
    "text": "stores ssds that get attached to",
    "start": "560279",
    "end": "561920"
  },
  {
    "text": "instances you can put things on FSX",
    "start": "561920",
    "end": "564200"
  },
  {
    "text": "which is Amazon's luster store uh you",
    "start": "564200",
    "end": "566720"
  },
  {
    "text": "can save things in S3 and probably most",
    "start": "566720",
    "end": "568560"
  },
  {
    "text": "of you have your data S3 already just as",
    "start": "568560",
    "end": "570440"
  },
  {
    "text": "a backup or you can roll your own htfs",
    "start": "570440",
    "end": "573320"
  },
  {
    "text": "type service and and uh and pull data in",
    "start": "573320",
    "end": "575519"
  },
  {
    "text": "from that now each of these have",
    "start": "575519",
    "end": "577000"
  },
  {
    "text": "different uh trade-offs that you have to",
    "start": "577000",
    "end": "578560"
  },
  {
    "text": "take into account when making a decision",
    "start": "578560",
    "end": "580440"
  },
  {
    "text": "when you want to do distributed deep",
    "start": "580440",
    "end": "582160"
  },
  {
    "text": "learning if you choose something like",
    "start": "582160",
    "end": "584120"
  },
  {
    "text": "EFS you have very low latency when",
    "start": "584120",
    "end": "586800"
  },
  {
    "text": "reading files but you struggle when uh",
    "start": "586800",
    "end": "589320"
  },
  {
    "text": "with throughput when you are on many",
    "start": "589320",
    "end": "591200"
  },
  {
    "text": "many machines so if you have 16 machines",
    "start": "591200",
    "end": "594000"
  },
  {
    "text": "uh eight gpus a piece you have 128 gpus",
    "start": "594000",
    "end": "596480"
  },
  {
    "text": "reading in that data then what can",
    "start": "596480",
    "end": "598440"
  },
  {
    "text": "happen is you can get neck by that",
    "start": "598440",
    "end": "600120"
  },
  {
    "text": "single that single pipe going to each of",
    "start": "600120",
    "end": "601839"
  },
  {
    "text": "those machines you can put your data on",
    "start": "601839",
    "end": "604079"
  },
  {
    "text": "an EBS uh store the problem with EBS is",
    "start": "604079",
    "end": "607000"
  },
  {
    "text": "that you have to copy that data to each",
    "start": "607000",
    "end": "608600"
  },
  {
    "text": "of those block storages before you can",
    "start": "608600",
    "end": "610480"
  },
  {
    "text": "start training so what that means again",
    "start": "610480",
    "end": "613200"
  },
  {
    "text": "16 instances uh you'll have to copy your",
    "start": "613200",
    "end": "615920"
  },
  {
    "text": "one terabyte data set to to 16 different",
    "start": "615920",
    "end": "618240"
  },
  {
    "text": "EBS volumes and attach those volumes",
    "start": "618240",
    "end": "620560"
  },
  {
    "text": "that can be super time consuming and",
    "start": "620560",
    "end": "622399"
  },
  {
    "text": "even though once it's on there you have",
    "start": "622399",
    "end": "623920"
  },
  {
    "text": "very low latency and very uh high",
    "start": "623920",
    "end": "626040"
  },
  {
    "text": "throughput so that that works uh in the",
    "start": "626040",
    "end": "628279"
  },
  {
    "text": "long run but has a very High uh upfront",
    "start": "628279",
    "end": "630760"
  },
  {
    "text": "cost you can store things in uh luster",
    "start": "630760",
    "end": "633320"
  },
  {
    "text": "or FSX which is by",
    "start": "633320",
    "end": "635200"
  },
  {
    "text": "Amazon uh the issues with luster is that",
    "start": "635200",
    "end": "638000"
  },
  {
    "text": "it's a transient data store you can't be",
    "start": "638000",
    "end": "639560"
  },
  {
    "text": "guaranteed that the data exists it also",
    "start": "639560",
    "end": "641600"
  },
  {
    "text": "struggles with uh with throughput",
    "start": "641600",
    "end": "643959"
  },
  {
    "text": "similar to EFS and it's also much more",
    "start": "643959",
    "end": "645720"
  },
  {
    "text": "expensive so if if cost is an issue you",
    "start": "645720",
    "end": "647760"
  },
  {
    "text": "may not want to do something like",
    "start": "647760",
    "end": "649560"
  },
  {
    "text": "FSX most people already have their data",
    "start": "649560",
    "end": "651680"
  },
  {
    "text": "stored in S3 the issue with S3 is that",
    "start": "651680",
    "end": "654360"
  },
  {
    "text": "you have very very high latency cost to",
    "start": "654360",
    "end": "657320"
  },
  {
    "text": "pay when you're fetching data so even",
    "start": "657320",
    "end": "659560"
  },
  {
    "text": "though you can get great throughput you",
    "start": "659560",
    "end": "661600"
  },
  {
    "text": "can uh if you if you've saved your stuff",
    "start": "661600",
    "end": "663519"
  },
  {
    "text": "in Big Block stores like TF records or",
    "start": "663519",
    "end": "666279"
  },
  {
    "text": "in uh some other large data storage",
    "start": "666279",
    "end": "668200"
  },
  {
    "text": "format uh you can get very high",
    "start": "668200",
    "end": "670200"
  },
  {
    "text": "throughput and the latency doesn't",
    "start": "670200",
    "end": "671639"
  },
  {
    "text": "matter as much but most of the time the",
    "start": "671639",
    "end": "673639"
  },
  {
    "text": "people that we work with have their data",
    "start": "673639",
    "end": "674880"
  },
  {
    "text": "stored in jpegs pgs csvs and so these",
    "start": "674880",
    "end": "677440"
  },
  {
    "text": "really small files they don't work with",
    "start": "677440",
    "end": "678839"
  },
  {
    "text": "storage uh storage uh block storage like",
    "start": "678839",
    "end": "681320"
  },
  {
    "text": "S3 and very similar htfs has uh similar",
    "start": "681320",
    "end": "684639"
  },
  {
    "text": "problems where uh small files don't work",
    "start": "684639",
    "end": "687040"
  },
  {
    "text": "very well and so when you think about",
    "start": "687040",
    "end": "688680"
  },
  {
    "text": "setting up your distributed deep",
    "start": "688680",
    "end": "689959"
  },
  {
    "text": "learning pipeline uh there's all that's",
    "start": "689959",
    "end": "692279"
  },
  {
    "text": "just one potential category of things",
    "start": "692279",
    "end": "693880"
  },
  {
    "text": "that you need to think about so there's",
    "start": "693880",
    "end": "695360"
  },
  {
    "text": "other things like do I want to run on",
    "start": "695360",
    "end": "696959"
  },
  {
    "text": "spot instances do I want to use uh",
    "start": "696959",
    "end": "699560"
  },
  {
    "text": "kubernetes do I want to use drer swarm",
    "start": "699560",
    "end": "701200"
  },
  {
    "text": "MOS and when you combine all of these",
    "start": "701200",
    "end": "703600"
  },
  {
    "text": "potential different ways of setting up",
    "start": "703600",
    "end": "705600"
  },
  {
    "text": "your infrastructure you end up with this",
    "start": "705600",
    "end": "707160"
  },
  {
    "text": "decision paralysis and it's very hard to",
    "start": "707160",
    "end": "709040"
  },
  {
    "text": "make progress moving",
    "start": "709040",
    "end": "710600"
  },
  {
    "text": "forward again tying this back to the",
    "start": "710600",
    "end": "712560"
  },
  {
    "text": "beginning the goal is to get it so that",
    "start": "712560",
    "end": "714120"
  },
  {
    "text": "you can train your models very quickly",
    "start": "714120",
    "end": "715399"
  },
  {
    "text": "and if all of this stuff is getting in",
    "start": "715399",
    "end": "716639"
  },
  {
    "text": "the way it's very hard to get back to",
    "start": "716639",
    "end": "718720"
  },
  {
    "text": "your original problem which is maybe uh",
    "start": "718720",
    "end": "720639"
  },
  {
    "text": "you want to solve self-driving vehicles",
    "start": "720639",
    "end": "722079"
  },
  {
    "text": "or you want to do cancer detection so",
    "start": "722079",
    "end": "724079"
  },
  {
    "text": "this Z to say this is very very hard to",
    "start": "724079",
    "end": "726200"
  },
  {
    "text": "get right and it takes a long time and",
    "start": "726200",
    "end": "727959"
  },
  {
    "text": "even if you build something out you may",
    "start": "727959",
    "end": "729399"
  },
  {
    "text": "not have built it correctly and so you",
    "start": "729399",
    "end": "731360"
  },
  {
    "text": "pay a a lot of upfront engineering time",
    "start": "731360",
    "end": "733320"
  },
  {
    "text": "to just try these things out so what did",
    "start": "733320",
    "end": "736079"
  },
  {
    "text": "we do at engin ml to make this possible",
    "start": "736079",
    "end": "738360"
  },
  {
    "text": "for people to get highly efficient",
    "start": "738360",
    "end": "740040"
  },
  {
    "text": "distributed training uh without having",
    "start": "740040",
    "end": "742079"
  },
  {
    "text": "to think too hard about how they want to",
    "start": "742079",
    "end": "743519"
  },
  {
    "text": "set up their distributed training",
    "start": "743519",
    "end": "744720"
  },
  {
    "text": "pipeline uh a few I won't highlight all",
    "start": "744720",
    "end": "747079"
  },
  {
    "text": "of these but uh I I'll talk through a",
    "start": "747079",
    "end": "748680"
  },
  {
    "text": "few of them",
    "start": "748680",
    "end": "749760"
  },
  {
    "text": "uh we run on top of eks and this allows",
    "start": "749760",
    "end": "752040"
  },
  {
    "text": "us to do cluster management manage a lot",
    "start": "752040",
    "end": "754199"
  },
  {
    "text": "of our services and I'll talk about a",
    "start": "754199",
    "end": "755560"
  },
  {
    "text": "few of those right now so uh the first",
    "start": "755560",
    "end": "757880"
  },
  {
    "text": "thing I like to highlight is our",
    "start": "757880",
    "end": "759079"
  },
  {
    "text": "in-memory data set cache so I mentioned",
    "start": "759079",
    "end": "761600"
  },
  {
    "text": "before S3 has super super high latency",
    "start": "761600",
    "end": "763720"
  },
  {
    "text": "when you want to read data from it the",
    "start": "763720",
    "end": "766560"
  },
  {
    "text": "uh the the issue with that is you uh",
    "start": "766560",
    "end": "768800"
  },
  {
    "text": "often pay a penalty every time you want",
    "start": "768800",
    "end": "770160"
  },
  {
    "text": "to read your data set and if you saw",
    "start": "770160",
    "end": "771760"
  },
  {
    "text": "that example I saw before or I mentioned",
    "start": "771760",
    "end": "773720"
  },
  {
    "text": "before you need to iterate through your",
    "start": "773720",
    "end": "775240"
  },
  {
    "text": "data set maybe 60 times or so in order",
    "start": "775240",
    "end": "777639"
  },
  {
    "text": "to get to the point where you can uh",
    "start": "777639",
    "end": "779720"
  },
  {
    "text": "have your model fully trained to",
    "start": "779720",
    "end": "780920"
  },
  {
    "text": "completion so on each of the machines we",
    "start": "780920",
    "end": "783079"
  },
  {
    "text": "set up an in-memory data cache that is a",
    "start": "783079",
    "end": "785199"
  },
  {
    "text": "readr cache so that every time after the",
    "start": "785199",
    "end": "787440"
  },
  {
    "text": "first read you're able to get native",
    "start": "787440",
    "end": "789440"
  },
  {
    "text": "speeds SSD inmemory speeds so that uh",
    "start": "789440",
    "end": "792240"
  },
  {
    "text": "you're able to train your models uh very",
    "start": "792240",
    "end": "794160"
  },
  {
    "text": "very quickly on those machines uh we're",
    "start": "794160",
    "end": "797160"
  },
  {
    "text": "also able to predictively prefetch that",
    "start": "797160",
    "end": "799000"
  },
  {
    "text": "data uh for example if you're training",
    "start": "799000",
    "end": "800880"
  },
  {
    "text": "on 128 gpus you don't need to have your",
    "start": "800880",
    "end": "803920"
  },
  {
    "text": "entire data set on each of those",
    "start": "803920",
    "end": "805320"
  },
  {
    "text": "machines you only need 128th of that",
    "start": "805320",
    "end": "807600"
  },
  {
    "text": "data set and so most of the time that",
    "start": "807600",
    "end": "809279"
  },
  {
    "text": "will fit inside an inmemory cach or on",
    "start": "809279",
    "end": "811120"
  },
  {
    "text": "disk which means that you can get those",
    "start": "811120",
    "end": "812920"
  },
  {
    "text": "massive speedups without paying the",
    "start": "812920",
    "end": "814560"
  },
  {
    "text": "latency cost of having your data on",
    "start": "814560",
    "end": "816560"
  },
  {
    "text": "S3 another thing I'd like to chat about",
    "start": "816560",
    "end": "818720"
  },
  {
    "text": "is spot autor restor so most of you know",
    "start": "818720",
    "end": "821320"
  },
  {
    "text": "what spot instances are uh they allow",
    "start": "821320",
    "end": "823440"
  },
  {
    "text": "you to pay 75% of the cost of an on-",
    "start": "823440",
    "end": "826519"
  },
  {
    "text": "demand instance for a k80 instance right",
    "start": "826519",
    "end": "828800"
  },
  {
    "text": "now it's 90 cents per GPU per hour on an",
    "start": "828800",
    "end": "831839"
  },
  {
    "text": "on demand instance and it's somewhere",
    "start": "831839",
    "end": "833360"
  },
  {
    "text": "around 20 25 cents on a spot instance",
    "start": "833360",
    "end": "835800"
  },
  {
    "text": "now the problem is when you run on 128",
    "start": "835800",
    "end": "838040"
  },
  {
    "text": "gpus and you're using something like",
    "start": "838040",
    "end": "840040"
  },
  {
    "text": "horovod if any of those machines get",
    "start": "840040",
    "end": "842360"
  },
  {
    "text": "preempted the entire ring shuts down you",
    "start": "842360",
    "end": "844360"
  },
  {
    "text": "have to start training over and if you",
    "start": "844360",
    "end": "846279"
  },
  {
    "text": "haven't set it up correctly uh you may",
    "start": "846279",
    "end": "848199"
  },
  {
    "text": "have lost the most recent checkpoint so",
    "start": "848199",
    "end": "850440"
  },
  {
    "text": "what we've built into engine ml is a way",
    "start": "850440",
    "end": "852320"
  },
  {
    "text": "to know when spot instances are about to",
    "start": "852320",
    "end": "854199"
  },
  {
    "text": "get shut down automatically checkpoint",
    "start": "854199",
    "end": "856040"
  },
  {
    "text": "the save or uh checkpoint the model and",
    "start": "856040",
    "end": "858560"
  },
  {
    "text": "then replace the spot instance that's",
    "start": "858560",
    "end": "860199"
  },
  {
    "text": "going to be preempted with an on demand",
    "start": "860199",
    "end": "862160"
  },
  {
    "text": "instance so that you can continue",
    "start": "862160",
    "end": "863440"
  },
  {
    "text": "training uh receiving the benefits of",
    "start": "863440",
    "end": "865480"
  },
  {
    "text": "running on on demand instances and the",
    "start": "865480",
    "end": "867320"
  },
  {
    "text": "user experience but also the cost",
    "start": "867320",
    "end": "869120"
  },
  {
    "text": "savings when running on spot uh finally",
    "start": "869120",
    "end": "872199"
  },
  {
    "text": "uh distributed debugging when you're on",
    "start": "872199",
    "end": "874519"
  },
  {
    "text": "a local machine under your desk you may",
    "start": "874519",
    "end": "876000"
  },
  {
    "text": "have four gpus a lot of Engineers will",
    "start": "876000",
    "end": "877680"
  },
  {
    "text": "open things like Nvidia SMI or htop and",
    "start": "877680",
    "end": "880880"
  },
  {
    "text": "they'll keep track of uh their",
    "start": "880880",
    "end": "882639"
  },
  {
    "text": "utilization metrics of their Network and",
    "start": "882639",
    "end": "884360"
  },
  {
    "text": "their CPU and their GPU but now imagine",
    "start": "884360",
    "end": "886920"
  },
  {
    "text": "trying to run each of those on 16",
    "start": "886920",
    "end": "888600"
  },
  {
    "text": "different machines all with eight gpus a",
    "start": "888600",
    "end": "890800"
  },
  {
    "text": "piece it's pretty unimaginable and it's",
    "start": "890800",
    "end": "892839"
  },
  {
    "text": "very hard to keep track of how efficient",
    "start": "892839",
    "end": "894360"
  },
  {
    "text": "these models are actually doing over",
    "start": "894360",
    "end": "895759"
  },
  {
    "text": "time so what we've built is a a",
    "start": "895759",
    "end": "898199"
  },
  {
    "text": "dashboard that runs",
    "start": "898199",
    "end": "899680"
  },
  {
    "text": "on top of influx DB and grafana that",
    "start": "899680",
    "end": "901959"
  },
  {
    "text": "allows you to see your metrics of your",
    "start": "901959",
    "end": "903399"
  },
  {
    "text": "training job over time now it's not only",
    "start": "903399",
    "end": "906000"
  },
  {
    "text": "important that you're able to see that",
    "start": "906000",
    "end": "907120"
  },
  {
    "text": "your your gpus are highly uh utilized",
    "start": "907120",
    "end": "909240"
  },
  {
    "text": "but also be able to correlate that to",
    "start": "909240",
    "end": "911320"
  },
  {
    "text": "the actual code that's running so most",
    "start": "911320",
    "end": "913040"
  },
  {
    "text": "of the time you'll launch htop and vsmi",
    "start": "913040",
    "end": "914920"
  },
  {
    "text": "and you'll see spikes in your GPU and",
    "start": "914920",
    "end": "916920"
  },
  {
    "text": "network utilization and CPU utilization",
    "start": "916920",
    "end": "919120"
  },
  {
    "text": "but you won't necessarily know if your",
    "start": "919120",
    "end": "921639"
  },
  {
    "text": "model is inefficient and at what points",
    "start": "921639",
    "end": "923519"
  },
  {
    "text": "is your model inefficient so often times",
    "start": "923519",
    "end": "926040"
  },
  {
    "text": "what we'll see is the CPU will Spike",
    "start": "926040",
    "end": "928240"
  },
  {
    "text": "then the GPU will Spike and then the",
    "start": "928240",
    "end": "929519"
  },
  {
    "text": "network will Spike and what that will",
    "start": "929519",
    "end": "931319"
  },
  {
    "text": "allow you to notice is that uh maybe",
    "start": "931319",
    "end": "933240"
  },
  {
    "text": "your input pipeline isn't set up",
    "start": "933240",
    "end": "934480"
  },
  {
    "text": "correctly and you should do better",
    "start": "934480",
    "end": "936000"
  },
  {
    "text": "pipelining so maybe uh you can fetch",
    "start": "936000",
    "end": "938759"
  },
  {
    "text": "data while you're pre-processing the",
    "start": "938759",
    "end": "940199"
  },
  {
    "text": "next batch and also while you're",
    "start": "940199",
    "end": "941880"
  },
  {
    "text": "training on a new batch um all of this",
    "start": "941880",
    "end": "944800"
  },
  {
    "text": "is to say uh you can train a lot faster",
    "start": "944800",
    "end": "947319"
  },
  {
    "text": "once you're able to know how inefficient",
    "start": "947319",
    "end": "949199"
  },
  {
    "text": "your code actually",
    "start": "949199",
    "end": "952000"
  },
  {
    "text": "is uh and then this one is is near and",
    "start": "952839",
    "end": "955440"
  },
  {
    "text": "dear to my heart I'm sure we've all been",
    "start": "955440",
    "end": "957120"
  },
  {
    "text": "in a situation where we've left instance",
    "start": "957120",
    "end": "959120"
  },
  {
    "text": "up over the weekend um one thing that I",
    "start": "959120",
    "end": "962279"
  },
  {
    "text": "always dreaded was uh forgetting to shut",
    "start": "962279",
    "end": "964880"
  },
  {
    "text": "those machines down and then going into",
    "start": "964880",
    "end": "966519"
  },
  {
    "text": "work on a Monday and having to explain",
    "start": "966519",
    "end": "967920"
  },
  {
    "text": "to my boss why I left 5,000 or $10,000",
    "start": "967920",
    "end": "971160"
  },
  {
    "text": "worth of instances running over the",
    "start": "971160",
    "end": "972680"
  },
  {
    "text": "weekend so with engine ml you can always",
    "start": "972680",
    "end": "974639"
  },
  {
    "text": "be certain that whenever a job crashes",
    "start": "974639",
    "end": "977560"
  },
  {
    "text": "or finishes or you cancel it those",
    "start": "977560",
    "end": "979800"
  },
  {
    "text": "machines will automatically be",
    "start": "979800",
    "end": "981360"
  },
  {
    "text": "deprovisioned and you won't have to have",
    "start": "981360",
    "end": "983079"
  },
  {
    "text": "these hard conversations with your boss",
    "start": "983079",
    "end": "986120"
  },
  {
    "text": "uh to explain why you spent $10,000 over",
    "start": "986120",
    "end": "988800"
  },
  {
    "text": "the weekend",
    "start": "988800",
    "end": "990920"
  },
  {
    "text": "cool so uh this is all to say that all",
    "start": "990920",
    "end": "995800"
  },
  {
    "text": "of these problems are very hard to get",
    "start": "995800",
    "end": "998079"
  },
  {
    "text": "right and they're not your goal as a",
    "start": "998079",
    "end": "1000920"
  },
  {
    "text": "company so if you're trying to solell",
    "start": "1000920",
    "end": "1002800"
  },
  {
    "text": "self-driving vehicles or if you're",
    "start": "1002800",
    "end": "1004360"
  },
  {
    "text": "trying to do cancer detection or maybe",
    "start": "1004360",
    "end": "1006399"
  },
  {
    "text": "if you're trying to uh save energy usage",
    "start": "1006399",
    "end": "1009199"
  },
  {
    "text": "at your data center you don't",
    "start": "1009199",
    "end": "1010959"
  },
  {
    "text": "necessarily want to have to worry about",
    "start": "1010959",
    "end": "1013680"
  },
  {
    "text": "uh did I leave a machine up over the",
    "start": "1013680",
    "end": "1015199"
  },
  {
    "text": "weekend or am I getting efficient",
    "start": "1015199",
    "end": "1016839"
  },
  {
    "text": "throughput with my data over s three and",
    "start": "1016839",
    "end": "1019600"
  },
  {
    "text": "so we built engine ml to solve these",
    "start": "1019600",
    "end": "1021440"
  },
  {
    "text": "problems for you we make it really easy",
    "start": "1021440",
    "end": "1023160"
  },
  {
    "text": "to interface uh it's just about five",
    "start": "1023160",
    "end": "1025038"
  },
  {
    "text": "lines of code change required uh we have",
    "start": "1025039",
    "end": "1027120"
  },
  {
    "text": "a very simple git interface so as an",
    "start": "1027120",
    "end": "1028839"
  },
  {
    "text": "engineer you don't need to know about",
    "start": "1028839",
    "end": "1030720"
  },
  {
    "text": "what instances types you're running on",
    "start": "1030720",
    "end": "1032678"
  },
  {
    "text": "where your data lives and you get all",
    "start": "1032679",
    "end": "1034438"
  },
  {
    "text": "the benefits of uh engine ml without",
    "start": "1034439",
    "end": "1037199"
  },
  {
    "text": "having to build these feature sets out",
    "start": "1037199",
    "end": "1038798"
  },
  {
    "text": "yourself so thank you very much open to",
    "start": "1038799",
    "end": "1041199"
  },
  {
    "text": "questions now and feel free to chat with",
    "start": "1041199",
    "end": "1042600"
  },
  {
    "text": "me",
    "start": "1042600",
    "end": "1044720"
  },
  {
    "text": "after all right so we'll go for some",
    "start": "1044760",
    "end": "1047120"
  },
  {
    "text": "questions",
    "start": "1047120",
    "end": "1050120"
  },
  {
    "text": "uh thank you for the talk most exciting",
    "start": "1050160",
    "end": "1053640"
  },
  {
    "text": "part is uh could you elaborate a little",
    "start": "1053640",
    "end": "1055919"
  },
  {
    "text": "bit how to optimize my application code",
    "start": "1055919",
    "end": "1058799"
  },
  {
    "text": "so I can do I do not have to be bothered",
    "start": "1058799",
    "end": "1062000"
  },
  {
    "text": "by the am old MD's law even though I",
    "start": "1062000",
    "end": "1064880"
  },
  {
    "text": "mean there are 128 gpus but I mean sorry",
    "start": "1064880",
    "end": "1068160"
  },
  {
    "text": "optimize your code for to get around",
    "start": "1068160",
    "end": "1070960"
  },
  {
    "text": "with Mall's law mol's law says you can",
    "start": "1070960",
    "end": "1074080"
  },
  {
    "text": "only paralyze so much and eventually the",
    "start": "1074080",
    "end": "1077679"
  },
  {
    "text": "theal Go pass will kill you yeah so um",
    "start": "1077679",
    "end": "1082559"
  },
  {
    "text": "so generally we see scale out to around",
    "start": "1082559",
    "end": "1085400"
  },
  {
    "text": "1,000 gpus anything beyond that you get",
    "start": "1085400",
    "end": "1088000"
  },
  {
    "text": "to the point where you are getting below",
    "start": "1088000",
    "end": "1089520"
  },
  {
    "text": "a 90% scale out so uh in practice if you",
    "start": "1089520",
    "end": "1093360"
  },
  {
    "text": "can train your model in about an hour uh",
    "start": "1093360",
    "end": "1095919"
  },
  {
    "text": "and that's if you're doing like 128 gpus",
    "start": "1095919",
    "end": "1098559"
  },
  {
    "text": "most of the time that's enough um",
    "start": "1098559",
    "end": "1101080"
  },
  {
    "text": "there's it's an open area of research in",
    "start": "1101080",
    "end": "1102880"
  },
  {
    "text": "order to how to make this work uh we",
    "start": "1102880",
    "end": "1104679"
  },
  {
    "text": "have Technologies like uh uh fp16",
    "start": "1104679",
    "end": "1108159"
  },
  {
    "text": "compression when sending data across the",
    "start": "1108159",
    "end": "1109919"
  },
  {
    "text": "nodes which allows you to reduce the",
    "start": "1109919",
    "end": "1111919"
  },
  {
    "text": "bandwidth required to do training",
    "start": "1111919",
    "end": "1113679"
  },
  {
    "text": "there's also techniques like deep",
    "start": "1113679",
    "end": "1115000"
  },
  {
    "text": "gradient compression where you can",
    "start": "1115000",
    "end": "1116240"
  },
  {
    "text": "ignore different uh different gradients",
    "start": "1116240",
    "end": "1118480"
  },
  {
    "text": "that may be lower than a certain",
    "start": "1118480",
    "end": "1119919"
  },
  {
    "text": "threshold so that you can train faster",
    "start": "1119919",
    "end": "1122200"
  },
  {
    "text": "uh and reduce the bandwidth as well um",
    "start": "1122200",
    "end": "1124200"
  },
  {
    "text": "but in general scale out to around a",
    "start": "1124200",
    "end": "1126280"
  },
  {
    "text": "th000 gpus uh you don't see performance",
    "start": "1126280",
    "end": "1129120"
  },
  {
    "text": "degradation or scale out uh below",
    "start": "1129120",
    "end": "1133080"
  },
  {
    "text": "90% do you see uh distributed learning",
    "start": "1136400",
    "end": "1140200"
  },
  {
    "text": "across Edge uh across Edge sites like on",
    "start": "1140200",
    "end": "1144320"
  },
  {
    "text": "premise of a customer where they may",
    "start": "1144320",
    "end": "1146000"
  },
  {
    "text": "have a large data centers and or large",
    "start": "1146000",
    "end": "1148679"
  },
  {
    "text": "um Stacks um racks of servers do you see",
    "start": "1148679",
    "end": "1152280"
  },
  {
    "text": "your engine ml running on each one of",
    "start": "1152280",
    "end": "1154559"
  },
  {
    "text": "these different sort of racks of servers",
    "start": "1154559",
    "end": "1157080"
  },
  {
    "text": "and doing distributed yeah so earning",
    "start": "1157080",
    "end": "1159280"
  },
  {
    "text": "right now we're focusing on cloud um we",
    "start": "1159280",
    "end": "1161799"
  },
  {
    "text": "do have the ability because we run",
    "start": "1161799",
    "end": "1163320"
  },
  {
    "text": "kubernetes it allows us to scale out to",
    "start": "1163320",
    "end": "1165080"
  },
  {
    "text": "on Prem uh we're a small company now",
    "start": "1165080",
    "end": "1166960"
  },
  {
    "text": "we're seven people and so we're mostly",
    "start": "1166960",
    "end": "1168440"
  },
  {
    "text": "Focus focusing on cloud providers um but",
    "start": "1168440",
    "end": "1170840"
  },
  {
    "text": "there's no reason that technology like",
    "start": "1170840",
    "end": "1172280"
  },
  {
    "text": "this canot be deployed on",
    "start": "1172280",
    "end": "1175280"
  },
  {
    "text": "Prem hey a few slides ago it looked like",
    "start": "1176520",
    "end": "1179360"
  },
  {
    "text": "it said gang",
    "start": "1179360",
    "end": "1181679"
  },
  {
    "text": "scheduling is that a custom scheduler",
    "start": "1181679",
    "end": "1184440"
  },
  {
    "text": "you all built internally and if so is",
    "start": "1184440",
    "end": "1188120"
  },
  {
    "text": "there a reason you didn't use the native",
    "start": "1188120",
    "end": "1189679"
  },
  {
    "text": "eks scheduler yeah thanks for the",
    "start": "1189679",
    "end": "1192440"
  },
  {
    "text": "question um the question is why didn't",
    "start": "1192440",
    "end": "1194960"
  },
  {
    "text": "we use the native",
    "start": "1194960",
    "end": "1196480"
  },
  {
    "text": "ekser um so by default when you're using",
    "start": "1196480",
    "end": "1200039"
  },
  {
    "text": "uh kubernetes uh you'll use what's",
    "start": "1200039",
    "end": "1201960"
  },
  {
    "text": "called asgs autoscaling groups to spin",
    "start": "1201960",
    "end": "1203840"
  },
  {
    "text": "up instances the problem with asgs is",
    "start": "1203840",
    "end": "1206480"
  },
  {
    "text": "that if you request 16 instances and",
    "start": "1206480",
    "end": "1209080"
  },
  {
    "text": "there's a capacity limit maybe you only",
    "start": "1209080",
    "end": "1210679"
  },
  {
    "text": "get 10 at that time you'll keep trying",
    "start": "1210679",
    "end": "1213039"
  },
  {
    "text": "again to scale those machines up but",
    "start": "1213039",
    "end": "1214559"
  },
  {
    "text": "you're paying for those 8 GPU or those 8",
    "start": "1214559",
    "end": "1216640"
  },
  {
    "text": "GPU instance types while the other",
    "start": "1216640",
    "end": "1218280"
  },
  {
    "text": "machines are spinning up and so a lot of",
    "start": "1218280",
    "end": "1220640"
  },
  {
    "text": "the people that we're working with would",
    "start": "1220640",
    "end": "1222440"
  },
  {
    "text": "have maybe an hour or so where they were",
    "start": "1222440",
    "end": "1224159"
  },
  {
    "text": "waiting for uh the next six gpus to spin",
    "start": "1224159",
    "end": "1226559"
  },
  {
    "text": "up six GPU instances to spin up and so",
    "start": "1226559",
    "end": "1228760"
  },
  {
    "text": "we built a custom scheduler that uses",
    "start": "1228760",
    "end": "1230720"
  },
  {
    "text": "what's called Gang scheduling and what",
    "start": "1230720",
    "end": "1232440"
  },
  {
    "text": "that means is if I don't have enough",
    "start": "1232440",
    "end": "1233960"
  },
  {
    "text": "instances at that time to uh stop and",
    "start": "1233960",
    "end": "1237240"
  },
  {
    "text": "alert the user and prompt them hey do",
    "start": "1237240",
    "end": "1238799"
  },
  {
    "text": "you want to continue using this or do",
    "start": "1238799",
    "end": "1240520"
  },
  {
    "text": "you want to try again in a little bit",
    "start": "1240520",
    "end": "1241880"
  },
  {
    "text": "when maybe there's enough capacity um so",
    "start": "1241880",
    "end": "1244360"
  },
  {
    "text": "the default eks scheduler does not have",
    "start": "1244360",
    "end": "1246080"
  },
  {
    "text": "that capability and so we ended up",
    "start": "1246080",
    "end": "1247280"
  },
  {
    "text": "building our",
    "start": "1247280",
    "end": "1248520"
  },
  {
    "text": "own I think I have one question over",
    "start": "1248520",
    "end": "1252559"
  },
  {
    "text": "here so um if if one want to use it so",
    "start": "1252559",
    "end": "1256080"
  },
  {
    "text": "it the application has to be distributed",
    "start": "1256080",
    "end": "1258120"
  },
  {
    "text": "or you are going to distribut for",
    "start": "1258120",
    "end": "1259120"
  },
  {
    "text": "example so do I have to have a a",
    "start": "1259120",
    "end": "1261600"
  },
  {
    "text": "distributed tensor flow to use this or a",
    "start": "1261600",
    "end": "1264280"
  },
  {
    "text": "regular tensor flow application will you",
    "start": "1264280",
    "end": "1265880"
  },
  {
    "text": "convert that to a distributed one yeah",
    "start": "1265880",
    "end": "1268080"
  },
  {
    "text": "so we have a uh a library that we've",
    "start": "1268080",
    "end": "1270720"
  },
  {
    "text": "built that uses nickel uh hierarchical",
    "start": "1270720",
    "end": "1273240"
  },
  {
    "text": "all ruce it's about five lines of code",
    "start": "1273240",
    "end": "1275240"
  },
  {
    "text": "change required when I was at uh uh",
    "start": "1275240",
    "end": "1278039"
  },
  {
    "text": "working at my my past companies we",
    "start": "1278039",
    "end": "1279840"
  },
  {
    "text": "always got into this situation where you",
    "start": "1279840",
    "end": "1282120"
  },
  {
    "text": "would have one code path for when you're",
    "start": "1282120",
    "end": "1283799"
  },
  {
    "text": "training distributed and one code path",
    "start": "1283799",
    "end": "1285480"
  },
  {
    "text": "where you're training locally and that",
    "start": "1285480",
    "end": "1287080"
  },
  {
    "text": "makes it really hard to debug when go",
    "start": "1287080",
    "end": "1288960"
  },
  {
    "text": "wrong uh so we built the engine ml",
    "start": "1288960",
    "end": "1290679"
  },
  {
    "text": "Library it uses best practices for",
    "start": "1290679",
    "end": "1292960"
  },
  {
    "text": "nickel hierarchical all ruce uh and ring",
    "start": "1292960",
    "end": "1295400"
  },
  {
    "text": "based all ruce but the benefit of using",
    "start": "1295400",
    "end": "1297960"
  },
  {
    "text": "the nml library is code will run exactly",
    "start": "1297960",
    "end": "1300679"
  },
  {
    "text": "as it would locally except now it's on",
    "start": "1300679",
    "end": "1302400"
  },
  {
    "text": "128 gpus in the cloud so one other",
    "start": "1302400",
    "end": "1305440"
  },
  {
    "text": "question is that um you since in AWS",
    "start": "1305440",
    "end": "1308400"
  },
  {
    "text": "most of the instances are one one gig",
    "start": "1308400",
    "end": "1310600"
  },
  {
    "text": "not U not 10 gig unless you have a",
    "start": "1310600",
    "end": "1312919"
  },
  {
    "text": "multi- GPU so you don't have um I think",
    "start": "1312919",
    "end": "1315960"
  },
  {
    "text": "you answered the question but I just",
    "start": "1315960",
    "end": "1317000"
  },
  {
    "text": "asking one more time so you don't have",
    "start": "1317000",
    "end": "1318640"
  },
  {
    "text": "any network latencies when you have U",
    "start": "1318640",
    "end": "1321000"
  },
  {
    "text": "such a big cluster since the network is",
    "start": "1321000",
    "end": "1323520"
  },
  {
    "text": "only one one gig right yeah so I I",
    "start": "1323520",
    "end": "1326080"
  },
  {
    "text": "mentioned a bit before there's ways to",
    "start": "1326080",
    "end": "1327520"
  },
  {
    "text": "compress the gradients that you're",
    "start": "1327520",
    "end": "1328799"
  },
  {
    "text": "sending so your gradients might be 300",
    "start": "1328799",
    "end": "1331240"
  },
  {
    "text": "megabytes that you need to send at every",
    "start": "1331240",
    "end": "1332720"
  },
  {
    "text": "step uh if you can cut your gradients",
    "start": "1332720",
    "end": "1335440"
  },
  {
    "text": "down to a 16bit floating Point",
    "start": "1335440",
    "end": "1337000"
  },
  {
    "text": "representation and then send those over",
    "start": "1337000",
    "end": "1338960"
  },
  {
    "text": "the network now you've cut your your",
    "start": "1338960",
    "end": "1340320"
  },
  {
    "text": "bandwidth in half uh which is really",
    "start": "1340320",
    "end": "1342760"
  },
  {
    "text": "quite nice um but generally we're",
    "start": "1342760",
    "end": "1345120"
  },
  {
    "text": "bottlenecked by data throughput not",
    "start": "1345120",
    "end": "1346760"
  },
  {
    "text": "necessarily gradient updates",
    "start": "1346760",
    "end": "1349640"
  },
  {
    "text": "Co would do one more question over here",
    "start": "1349640",
    "end": "1352320"
  },
  {
    "text": "if I'm just getting started with deep",
    "start": "1352320",
    "end": "1353799"
  },
  {
    "text": "learning and don't need 120 gpus in the",
    "start": "1353799",
    "end": "1356559"
  },
  {
    "text": "cloud is there a way that I could use",
    "start": "1356559",
    "end": "1358039"
  },
  {
    "text": "engine ml to get a taste of it um so",
    "start": "1358039",
    "end": "1361679"
  },
  {
    "text": "today we don't have a way that allows",
    "start": "1361679",
    "end": "1363360"
  },
  {
    "text": "you to scale from one GPU to four gpus",
    "start": "1363360",
    "end": "1365919"
  },
  {
    "text": "on a single box but we're working on a",
    "start": "1365919",
    "end": "1368200"
  },
  {
    "text": "system that would allow you to train and",
    "start": "1368200",
    "end": "1369919"
  },
  {
    "text": "help you scale up if you are still",
    "start": "1369919",
    "end": "1371279"
  },
  {
    "text": "struggling with going from one uh one",
    "start": "1371279",
    "end": "1373640"
  },
  {
    "text": "GPU to four gpus on on the same box um",
    "start": "1373640",
    "end": "1376840"
  },
  {
    "text": "and that's will be coming out in the",
    "start": "1376840",
    "end": "1378279"
  },
  {
    "text": "next next month or so um so if you are",
    "start": "1378279",
    "end": "1380039"
  },
  {
    "text": "interested in running engine ml locally",
    "start": "1380039",
    "end": "1381440"
  },
  {
    "text": "you'll still be able to get uh the",
    "start": "1381440",
    "end": "1383039"
  },
  {
    "text": "metrics dashboard and experiment",
    "start": "1383039",
    "end": "1384559"
  },
  {
    "text": "tracking and all the other services that",
    "start": "1384559",
    "end": "1386120"
  },
  {
    "text": "we provide",
    "start": "1386120",
    "end": "1389080"
  }
]
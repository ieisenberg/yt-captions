[
  {
    "start": "0",
    "end": "32000"
  },
  {
    "text": "big data services and the cubel service together I am rul Baha and I'm part of",
    "start": "199",
    "end": "5560"
  },
  {
    "text": "the Amazon web services team I work in the Amazon web services partner team as a solution architect along with me I",
    "start": "5560",
    "end": "12360"
  },
  {
    "text": "have dmesh Desai who is a technology evangelist with cubal and he's going to",
    "start": "12360",
    "end": "18320"
  },
  {
    "text": "talk about kubel's role in helping you manage your data or how kubel can",
    "start": "18320",
    "end": "23439"
  },
  {
    "text": "provide the services you need to manage your data at scale effectively with that let's get started",
    "start": "23439",
    "end": "31960"
  },
  {
    "start": "32000",
    "end": "32000"
  },
  {
    "text": "as we all of know that data is growing at an unprecedented space to give you some numbers today 1.7",
    "start": "32759",
    "end": "40840"
  },
  {
    "text": "megabyte of data might be generated by 2020 from every single human on the",
    "start": "40840",
    "end": "46600"
  },
  {
    "text": "planet Earth and just to give you idea of numbers today we have over 7 billion",
    "start": "46600",
    "end": "52480"
  },
  {
    "text": "of world population as of this year and by 2020 that will in the 2020 the",
    "start": "52480",
    "end": "59359"
  },
  {
    "text": "population could very well surpass 10 billions of human and that is a data set",
    "start": "59359",
    "end": "65040"
  },
  {
    "text": "which pushes the boundaries of what a traditional technology can do in terms of analysis but if you look on the other",
    "start": "65040",
    "end": "70799"
  },
  {
    "text": "side only a half per or 05% of the data is being analyzed",
    "start": "70799",
    "end": "76520"
  },
  {
    "text": "today Yet theop Market or the big data market is forecasted to grow at a",
    "start": "76520",
    "end": "82040"
  },
  {
    "text": "compounded annual growth rate of 58% and it is for Caster to surpass a dollar 1",
    "start": "82040",
    "end": "87640"
  },
  {
    "text": "billion Market by 2020 combined with all of these data it doesn't really mean that you have to",
    "start": "87640",
    "end": "94280"
  },
  {
    "start": "94000",
    "end": "94000"
  },
  {
    "text": "worry about how we want to solve the problem of the Big Data as demonstrated by the",
    "start": "94280",
    "end": "100399"
  },
  {
    "text": "customers such as fenra or Netflix or unil Kell yel mlbam and",
    "start": "100399",
    "end": "106439"
  },
  {
    "text": "semens what they have done they have taken the big data and turned it to their advantage by doing no wise things",
    "start": "106439",
    "end": "113119"
  },
  {
    "text": "by doing new things with the data sets for instance Netflix not only uses big data",
    "start": "113119",
    "end": "120159"
  },
  {
    "text": "to analyze what people are watching but they understand to how how their viewers engage what they can do how how they can",
    "start": "120159",
    "end": "126520"
  },
  {
    "text": "create new shows what kind of data sets they can cash so people get a better response when watching Netflix",
    "start": "126520",
    "end": "132599"
  },
  {
    "text": "streaming and to help you build some of these Mark Solutions we you should look",
    "start": "132599",
    "end": "139640"
  },
  {
    "start": "137000",
    "end": "137000"
  },
  {
    "text": "into using AWS for your big data workloads and why you should look into using AWS for your big data work loses",
    "start": "139640",
    "end": "146360"
  },
  {
    "text": "first you don't have to think about provisioning any infrastructure or capacity all of the services provided by",
    "start": "146360",
    "end": "152720"
  },
  {
    "text": "AWS are immediately available for you to use you can get started with a Hado cluster or a datab house cluster in a",
    "start": "152720",
    "end": "159640"
  },
  {
    "text": "very few in few minutes and you can terminate the cluster when you don't need them thereby saving the cost with",
    "start": "159640",
    "end": "166680"
  },
  {
    "text": "your big data workloads not only that AWS gives you",
    "start": "166680",
    "end": "172480"
  },
  {
    "text": "very Broad and deep capabilities in terms of compute network and infrastructure but going upper in the",
    "start": "172480",
    "end": "177920"
  },
  {
    "text": "stack it also provides you services for things like real-time streaming for Hado clusters for data warehousing and even",
    "start": "177920",
    "end": "184840"
  },
  {
    "text": "for bi workloads which you can utilize for your big data or for your database analytical workloads quite",
    "start": "184840",
    "end": "192599"
  },
  {
    "text": "easily on top of that you can even build a very trusted and secure platform by",
    "start": "192599",
    "end": "197680"
  },
  {
    "text": "leveraging the compliance such as pcss fed fisma ISO 270001 or even Hippa",
    "start": "197680",
    "end": "204760"
  },
  {
    "text": "compliance and you can encrypt your data both at rest and in trans that using the",
    "start": "204760",
    "end": "210480"
  },
  {
    "text": "features we provide when your data is stored in services such as S3 Dynamo or even a Amazon elastic blog store",
    "start": "210480",
    "end": "218000"
  },
  {
    "text": "volumes but all of these Services work at the scale doesn't matter whether you are a customer who are at Netflix scale",
    "start": "218000",
    "end": "224959"
  },
  {
    "text": "where they're storing petabytes of data or whether you're a small customer who's storing only a gigabytes of data each",
    "start": "224959",
    "end": "231920"
  },
  {
    "text": "with each of these situation or with AWS or with Cloud you don't really have to worry about changing your data",
    "start": "231920",
    "end": "237400"
  },
  {
    "text": "infrastructure as your data set grows you can take advantage of the cloud elasticity um or spot instances to learn",
    "start": "237400",
    "end": "244959"
  },
  {
    "text": "how to manage your workload better and in the most cost uh effective way and if",
    "start": "244959",
    "end": "251959"
  },
  {
    "text": "you look at the BR and deep capabilities of the AWS platform we provide you",
    "start": "251959",
    "end": "257239"
  },
  {
    "start": "253000",
    "end": "253000"
  },
  {
    "text": "Services which can help you collect store analyze and visualize the data",
    "start": "257239",
    "end": "262680"
  },
  {
    "text": "sets from collect and store we have import export service where you can ship your volumes we have snowball which is",
    "start": "262680",
    "end": "269759"
  },
  {
    "text": "is a new service announc from AWS Direct Connect where you can make uh",
    "start": "269759",
    "end": "275199"
  },
  {
    "text": "AWS part of AWS Cloud called virtual private Cloud extension of your own data center or we have virtual machines",
    "start": "275199",
    "end": "283360"
  },
  {
    "text": "Import and Export going to the storage size we have Amazon S3 which is a object",
    "start": "283360",
    "end": "289360"
  },
  {
    "text": "storage a Amazon Glacier which is a long-term archival storage Amazon red",
    "start": "289360",
    "end": "294440"
  },
  {
    "text": "Shi which is a dataware housing Amazon Dynamo DB which is a nosql database",
    "start": "294440",
    "end": "300320"
  },
  {
    "text": "and Amazon RDS with Amazon's own offering called Aurora which is a MySQL",
    "start": "300320",
    "end": "305400"
  },
  {
    "text": "compatible Cloud native database on the analysis side you have",
    "start": "305400",
    "end": "310440"
  },
  {
    "text": "things like Amazon EMR Amazon ec2 Amazon AWS Lambda and even Amazon kesis which",
    "start": "310440",
    "end": "316160"
  },
  {
    "text": "can help you collect data into real time for the visualized part we recently announced our service called quick",
    "start": "316160",
    "end": "323039"
  },
  {
    "text": "site and quicksite is being available under preview right now which you can quickly use to analyze and visualize uh",
    "start": "323039",
    "end": "330000"
  },
  {
    "text": "data sets in your Cloud now these were some of the",
    "start": "330000",
    "end": "336680"
  },
  {
    "text": "examples we mentioned in terms of what are the services you could use to handle with different aspects of a big data",
    "start": "336680",
    "end": "342360"
  },
  {
    "text": "workflow but what you could do with some of these services and your data sets on",
    "start": "342360",
    "end": "348680"
  },
  {
    "text": "AWS is truly immensely bigger than what we can think",
    "start": "348680",
    "end": "353759"
  },
  {
    "text": "but here to mention some examples such as that you could build",
    "start": "353759",
    "end": "359520"
  },
  {
    "text": "uh Big Data repository or the quential data Lake you could do clickstream analysis you could even do things like",
    "start": "359960",
    "end": "366400"
  },
  {
    "text": "ETL offload where you can take advantage of the cloud to give you the best capacity in case your on Prime",
    "start": "366400",
    "end": "372560"
  },
  {
    "text": "infrastructure is not able to cope up with the growing data sets with Amazon machine learning you can get started",
    "start": "372560",
    "end": "378919"
  },
  {
    "text": "doing something as advanced as machine learning in a very in few hours per se",
    "start": "378919",
    "end": "383960"
  },
  {
    "text": "or you can build an online ad serving platform using Dynamo DB or even you can build a bi application quickly using",
    "start": "383960",
    "end": "389800"
  },
  {
    "text": "Amazon quick site these are some of the examples of what you could do using the AWS Big Data platform and and your data",
    "start": "389800",
    "end": "396919"
  },
  {
    "text": "set together with that what I'm going to do is I'm going to invite my colleague dmesh here to talk about",
    "start": "396919",
    "end": "404400"
  },
  {
    "text": "how to migrate your big data to the cloud and take advant thanks rul for a great introduction um on what uh you",
    "start": "404400",
    "end": "412240"
  },
  {
    "text": "know Amazon provides as uh products as well as uh Services um hello everyone my",
    "start": "412240",
    "end": "418599"
  },
  {
    "text": "name is darash or Dash and I'm a technology evangelist with Cubo for",
    "start": "418599",
    "end": "424639"
  },
  {
    "text": "those listeners that are not familiar with Cubo or cual data service we're Big",
    "start": "424639",
    "end": "429720"
  },
  {
    "text": "Data as a service platform in the cloud founded by asish tuso and joy charma in",
    "start": "429720",
    "end": "436919"
  },
  {
    "text": "2007 um prior to finding Cub they were part of building and leading the",
    "start": "436919",
    "end": "442759"
  },
  {
    "text": "original Facebook data service team and during that time they also authored",
    "start": "442759",
    "end": "448759"
  },
  {
    "text": "several IND indry leading uh Big Data tools uh including uh Apache hiive",
    "start": "448759",
    "end": "455400"
  },
  {
    "text": "project in the next 30 minutes or so um we're going to cover several topics",
    "start": "455400",
    "end": "460520"
  },
  {
    "text": "ranging from Cub as a big data service uh and sell service platform it's Cloud",
    "start": "460520",
    "end": "466560"
  },
  {
    "text": "advantage in conjunction with u AWS as well as Big Data had migration service",
    "start": "466560",
    "end": "472560"
  },
  {
    "text": "that it provides followed by an uh in-depth look at uh a customer case study",
    "start": "472560",
    "end": "480440"
  },
  {
    "text": "so let's get started um we're going to quickly look at uh",
    "start": "480440",
    "end": "487879"
  },
  {
    "start": "486000",
    "end": "486000"
  },
  {
    "text": "some of the advantages uh so let's start reviewing by let's start by reviewing some of the advantages of migrating your",
    "start": "487879",
    "end": "493720"
  },
  {
    "text": "big data deployments in the cloud one of the big one um is being",
    "start": "493720",
    "end": "500639"
  },
  {
    "text": "able to separate cloud or being able to separate storage from compute um and",
    "start": "500639",
    "end": "506319"
  },
  {
    "text": "we'll talk about this uh in detail in just a little bit but basically it reduces the complexity",
    "start": "506319",
    "end": "511919"
  },
  {
    "text": "of managing multiple environments for example production development and AOG",
    "start": "511919",
    "end": "517719"
  },
  {
    "text": "analytics processes could run on the same data sources um without having to",
    "start": "517719",
    "end": "523479"
  },
  {
    "text": "either duplicate or replicate the data and then since initial provisioning",
    "start": "523479",
    "end": "528959"
  },
  {
    "text": "can occur in hours instead of you know weeks or days um the quick uh it it provides quick",
    "start": "528959",
    "end": "536760"
  },
  {
    "text": "time to value and since the Generations can be faster uh you can you can also",
    "start": "536760",
    "end": "542760"
  },
  {
    "text": "make changes on the Fly while clusters are actually up and running um and it's",
    "start": "542760",
    "end": "547839"
  },
  {
    "text": "all policy driven with minimal operations uh management",
    "start": "547839",
    "end": "553200"
  },
  {
    "text": "overhead and it's pretty obvious that you can you know take uh full advantage",
    "start": "553200",
    "end": "558920"
  },
  {
    "text": "of uh the elasticity of the cloud and qds has built-in Autos scaling at multiple levels uh including storage",
    "start": "558920",
    "end": "567839"
  },
  {
    "text": "compute uh and even at the spark job level uh so depending on your workloads",
    "start": "567839",
    "end": "573240"
  },
  {
    "text": "uh it automatically scales the uh the Clusters and the uh the other Advantage",
    "start": "573240",
    "end": "579360"
  },
  {
    "text": "is um overall cost uh the total cost of ownership is significantly lower and uh",
    "start": "579360",
    "end": "585480"
  },
  {
    "text": "couple of um tidbits there is U you can mix and match on demand spot and Reserve",
    "start": "585480",
    "end": "594800"
  },
  {
    "text": "instances and uh just a side note 84% of cuq in sated clusters leverage spot",
    "start": "594800",
    "end": "601760"
  },
  {
    "text": "instances and that results in up to 80% uh of savings for our customers compared",
    "start": "601760",
    "end": "608519"
  },
  {
    "text": "to ond demand pricing and the flexibility is also much higher because it's qds out of the box supports 40 plus",
    "start": "608519",
    "end": "617920"
  },
  {
    "text": "Amazon instances um and you can create test run and schedule queries using",
    "start": "617920",
    "end": "624760"
  },
  {
    "text": "multiple engines for example Hive Pig Presto uh red shift spark Etc and also",
    "start": "624760",
    "end": "632560"
  },
  {
    "text": "provides rest API for programmatic uh integration from your existing",
    "start": "632560",
    "end": "638639"
  },
  {
    "text": "applications as well as sdks for python Java R and",
    "start": "638639",
    "end": "643839"
  },
  {
    "text": "scholar and um last but not the least it has a OD obbc and JD jdbc connectors uh",
    "start": "643839",
    "end": "651920"
  },
  {
    "text": "to Red shift my SQL and no SQL databases such as uh mongodb",
    "start": "651920",
    "end": "659600"
  },
  {
    "start": "659000",
    "end": "659000"
  },
  {
    "text": "so as Rahul mentioned earlier uh many companies are using uh data as a differentiator and Pinterest is um",
    "start": "660639",
    "end": "668839"
  },
  {
    "text": "definitely one of them that uses the uh the value of data as core part of the customer",
    "start": "668839",
    "end": "674600"
  },
  {
    "text": "experience um so if you're a foodie for example uh descrip descriptive guides",
    "start": "674600",
    "end": "680519"
  },
  {
    "text": "will you know help you sift through all the yummy recipes and and foods and",
    "start": "680519",
    "end": "686040"
  },
  {
    "text": "Cuisines that you like and you know while you're tapping on your um you know pins that you like it'll",
    "start": "686040",
    "end": "692639"
  },
  {
    "text": "steer you your search in the direction uh to get to get more specific uh to",
    "start": "692639",
    "end": "698160"
  },
  {
    "text": "your sweet spot and Pinterest relies on qds or qall",
    "start": "698160",
    "end": "703440"
  },
  {
    "text": "running on Amazon for you know several different reasons um qds is Advanced",
    "start": "703440",
    "end": "709399"
  },
  {
    "text": "support for spot instances and also 100% spot inance clusters and relies heavily",
    "start": "709399",
    "end": "717079"
  },
  {
    "text": "on S3s Amazon S3's event ual consistency protection as well as you know qds is",
    "start": "717079",
    "end": "723600"
  },
  {
    "text": "graceful Auto scaling according to recent Cas study Pinterest uh is known to generate",
    "start": "723600",
    "end": "730880"
  },
  {
    "text": "over 20 billion log messages and processes nearly a pide of data with uh",
    "start": "730880",
    "end": "737480"
  },
  {
    "text": "Hado each day and uh in in if you put it in numbers as far as users it they have",
    "start": "737480",
    "end": "744680"
  },
  {
    "text": "over 100 regular mad produ users that are running over uh two 2,000 jobs each",
    "start": "744680",
    "end": "751199"
  },
  {
    "text": "day through Cubo so that's pretty up there um and",
    "start": "751199",
    "end": "757199"
  },
  {
    "start": "756000",
    "end": "756000"
  },
  {
    "text": "just to briefly touch on uh why Big Data deployments are difficult well they they",
    "start": "757199",
    "end": "764199"
  },
  {
    "text": "can be really rigid and uh there's also a chance of you being locked into a",
    "start": "764199",
    "end": "770120"
  },
  {
    "text": "certain Hardware uh specification or you know software licenses and so forth and",
    "start": "770120",
    "end": "776279"
  },
  {
    "text": "it's also um something that requires highly specialized teams um inhouse that",
    "start": "776279",
    "end": "782959"
  },
  {
    "text": "can handle or maintain um these kinds of deployments and they're you know out of",
    "start": "782959",
    "end": "789800"
  },
  {
    "text": "the box really uh difficult to build and operate just to give you a um a sense in",
    "start": "789800",
    "end": "796839"
  },
  {
    "text": "numbers it takes about 6 to 18 months to implement and out of those",
    "start": "796839",
    "end": "802240"
  },
  {
    "text": "implementations only 20% of Big Data initiatives are classified as successful",
    "start": "802240",
    "end": "808040"
  },
  {
    "text": "of those only 30 13% of um implementations achieve full scale",
    "start": "808040",
    "end": "814240"
  },
  {
    "text": "production and um according to the surveys or studies that um that have",
    "start": "814240",
    "end": "819800"
  },
  {
    "text": "been cited here um 50% uh 57% of uh companies s skills Gap as a",
    "start": "819800",
    "end": "828639"
  },
  {
    "text": "major obstacle so give it a second for these stats to s",
    "start": "828639",
    "end": "834320"
  },
  {
    "text": "in now the companies have a um an option here so you don't really have to go down",
    "start": "835000",
    "end": "840920"
  },
  {
    "text": "the path right um and let's look at how Cub simplifies big data deployments in",
    "start": "840920",
    "end": "846279"
  },
  {
    "text": "the cloud by leveraging Cloud's unlimited scaling and compute",
    "start": "846279",
    "end": "852320"
  },
  {
    "text": "capacity and in the in the next few uh slides uh short of an actual demo we're",
    "start": "852320",
    "end": "857680"
  },
  {
    "text": "going to review uh some aspects of Cu Ball's web interface and we'll see how",
    "start": "857680",
    "end": "864040"
  },
  {
    "text": "um they cater to different members of U of the data team including data analysts",
    "start": "864040",
    "end": "869519"
  },
  {
    "text": "data engineers and uh data admins so let's look at data analysts",
    "start": "869519",
    "end": "877920"
  },
  {
    "start": "875000",
    "end": "875000"
  },
  {
    "text": "first so what you're looking at here is a uh is a notebook part of the uh Cubs",
    "start": "878560",
    "end": "884880"
  },
  {
    "text": "web interface uh notebooks provide an interactive interface for uh data",
    "start": "884880",
    "end": "890079"
  },
  {
    "text": "exploration so here analysts can view run visualize the results of SQL Scola",
    "start": "890079",
    "end": "897279"
  },
  {
    "text": "python in a single collaborative environment they can also iterate",
    "start": "897279",
    "end": "902480"
  },
  {
    "text": "quickly and they can save queries so queries and results are persistent and",
    "start": "902480",
    "end": "909639"
  },
  {
    "text": "can be viewed even when the cluster is not up and running and they have the ability to",
    "start": "909639",
    "end": "915600"
  },
  {
    "text": "create multiple notebooks targeting different engines and different",
    "start": "915600",
    "end": "921440"
  },
  {
    "text": "clusters it also has a a way to integrate into GitHub for a Version",
    "start": "921440",
    "end": "927240"
  },
  {
    "text": "Control and tracking changes so if you have a large team that that kind of integration comes in really",
    "start": "927240",
    "end": "933839"
  },
  {
    "text": "handy and uh what notebooks allow uh them to do is build on on a a larger",
    "start": "933839",
    "end": "942800"
  },
  {
    "text": "application uh step by step so you have if you have a couple thousand steps",
    "start": "942800",
    "end": "948040"
  },
  {
    "text": "working toward a particular machine learning algorithm using spark uh you can you can Version Control the entire",
    "start": "948040",
    "end": "956720"
  },
  {
    "text": "application using the uh GitHub integration so that's that I think is pretty",
    "start": "956720",
    "end": "961880"
  },
  {
    "text": "neat they can also use a Smart query interface what it allows them to do is",
    "start": "961880",
    "end": "969399"
  },
  {
    "text": "visually build queries without having to know SQL or if they just don't like typing like a lot of people do um and it",
    "start": "969399",
    "end": "977440"
  },
  {
    "text": "can also be used to compose um queries with filters Auto by",
    "start": "977440",
    "end": "982959"
  },
  {
    "text": "Clauses and limit the number of rows that affects so it's a pretty handy uh",
    "start": "982959",
    "end": "988000"
  },
  {
    "text": "interface let's move on to uh data Engineers so",
    "start": "988000",
    "end": "993639"
  },
  {
    "start": "989000",
    "end": "989000"
  },
  {
    "text": "what you're looking at here is a scheduler interface part of the uh the qds or CUO um data",
    "start": "993639",
    "end": "1001639"
  },
  {
    "text": "service using the scheduler what in data Engineers can do is run complex uh",
    "start": "1001639",
    "end": "1007800"
  },
  {
    "text": "queries and commands at specific intervals without manual intervention",
    "start": "1007800",
    "end": "1012920"
  },
  {
    "text": "they can build out workflows and schedule jobs for automation it also supports",
    "start": "1012920",
    "end": "1019279"
  },
  {
    "text": "scheduling queries and commands targeting multiple engines so that would include um spark and what you see here",
    "start": "1019279",
    "end": "1026918"
  },
  {
    "text": "is a spark SQL they could do hiive Presto Pig um and it also lets them",
    "start": "1026919",
    "end": "1033798"
  },
  {
    "text": "Import and Export data external data source uh as part of the scheduled",
    "start": "1033799",
    "end": "1040360"
  },
  {
    "text": "workflow one of the advanced settings um that I'd like to point out is being able",
    "start": "1040360",
    "end": "1046839"
  },
  {
    "text": "to add dependencies so for example if you have a scheduled job that depends on",
    "start": "1046839",
    "end": "1054039"
  },
  {
    "text": "a particular hi partition you can you can set that here and uh another example",
    "start": "1054039",
    "end": "1060960"
  },
  {
    "text": "would be uh if you want a particular file to exist on S3 before a job runs so",
    "start": "1060960",
    "end": "1067280"
  },
  {
    "text": "there's a lot of these different things that you can set um within this interface when when you're scheduling",
    "start": "1067280",
    "end": "1074080"
  },
  {
    "text": "these jobs most moving on to the next um",
    "start": "1074080",
    "end": "1081039"
  },
  {
    "start": "1078000",
    "end": "1078000"
  },
  {
    "text": "interface analyze again data Engineers can use this to compose complex queries and",
    "start": "1081039",
    "end": "1088840"
  },
  {
    "text": "commands targeting different engines Hive haduk Pig prel and on the left you",
    "start": "1088840",
    "end": "1095039"
  },
  {
    "text": "can see a number of tabs so using the composed tab what you we're actually seeing right now is where you would",
    "start": "1095039",
    "end": "1102000"
  },
  {
    "text": "um run your all your complex queries and these composed queries can",
    "start": "1102000",
    "end": "1107600"
  },
  {
    "text": "be saved for future references and these save queries can be accessed via the",
    "start": "1107600",
    "end": "1113280"
  },
  {
    "text": "repo tab you see on the left using S3 tab they're able to look",
    "start": "1113280",
    "end": "1121280"
  },
  {
    "text": "at all their Amazon S3 buckets and see what what files and folders they have",
    "start": "1121280",
    "end": "1127559"
  },
  {
    "text": "created so that's also uh visible on the left uh next to tables and tables tab",
    "start": "1127559",
    "end": "1135240"
  },
  {
    "text": "allows them to examine um all the schemas and tables and hives that they",
    "start": "1135240",
    "end": "1140480"
  },
  {
    "text": "may have created and allows them to um look at the columns and and their data",
    "start": "1140480",
    "end": "1146039"
  },
  {
    "text": "types as as you can see in the screenshot the history tab is really um",
    "start": "1146039",
    "end": "1152400"
  },
  {
    "text": "really handy uh it it allows data Engineers to access pass",
    "start": "1152400",
    "end": "1159440"
  },
  {
    "text": "queries results and logs and any comments that that may have been added",
    "start": "1160159",
    "end": "1165640"
  },
  {
    "text": "during the collaboration phase between team members and important thing to note here is that all of this is persisted",
    "start": "1165640",
    "end": "1173280"
  },
  {
    "text": "and can be accessed even when the cluster is not up and running so you can go back and see what you did differently",
    "start": "1173280",
    "end": "1179840"
  },
  {
    "text": "um you know week ago month ago look at the results you can compare the results you can export the results right from",
    "start": "1179840",
    "end": "1186320"
  },
  {
    "text": "here so a lot of different things um that are possible through this interface and obviously you can also",
    "start": "1186320",
    "end": "1192679"
  },
  {
    "text": "Target different clusters depending on the queries and nature of the workload VI uh the uh the drop down that you see",
    "start": "1192679",
    "end": "1199880"
  },
  {
    "text": "on the top right uh it says default right now so pretty handy U um interface now",
    "start": "1199880",
    "end": "1207919"
  },
  {
    "start": "1203000",
    "end": "1203000"
  },
  {
    "text": "let's look at how data admins can use uh the unified interface um as part of",
    "start": "1207919",
    "end": "1214039"
  },
  {
    "text": "their um you know daily schedule so what you're looking at here is the control",
    "start": "1214039",
    "end": "1219799"
  },
  {
    "text": "panel um this this is you know where they would uh manage settings related to",
    "start": "1219799",
    "end": "1226080"
  },
  {
    "text": "clusters users roles sessions Etc and there are a few that I really want to",
    "start": "1226080",
    "end": "1232440"
  },
  {
    "text": "highlight um what you see here is the cluster settings page and um there's a",
    "start": "1232440",
    "end": "1238880"
  },
  {
    "text": "few attributes that are uh really important as far as the uh the the admins go uh one is cluster type so you",
    "start": "1238880",
    "end": "1247679"
  },
  {
    "text": "could you could you know pre-configure either Hadoop Hadoop 2 spark or pressor",
    "start": "1247679",
    "end": "1252720"
  },
  {
    "text": "cluster and the the next that I'd like to point out are and Max node counts you",
    "start": "1252720",
    "end": "1260320"
  },
  {
    "text": "can set the initial number of flave of nodes in the cluster You' like and then specify the maximum number",
    "start": "1260320",
    "end": "1266400"
  },
  {
    "text": "of Flav nodes and then you can specify the node types for each um qds out of",
    "start": "1266400",
    "end": "1273360"
  },
  {
    "text": "the box supports 40 plus instance types um and uh another really important",
    "start": "1273360",
    "end": "1280720"
  },
  {
    "text": "attribute here is uh disable automatic cluster termination uh cubble by default",
    "start": "1280720",
    "end": "1286960"
  },
  {
    "text": "terminates clusters when not used but that can be overridden by this",
    "start": "1286960",
    "end": "1292320"
  },
  {
    "text": "setting what this means is all you know U the cluster will clusters will uh will",
    "start": "1292320",
    "end": "1298559"
  },
  {
    "text": "not be shut down although the Clusters will still be downsized to the minimum",
    "start": "1298559",
    "end": "1303760"
  },
  {
    "text": "size when there's not um that much workload the other section I really want",
    "start": "1303760",
    "end": "1309799"
  },
  {
    "text": "to Target here really quick is the cluster composition which is really important uh when it comes to Autos",
    "start": "1309799",
    "end": "1315919"
  },
  {
    "text": "scaling TCL uh obviously depending on on the use cases and workloads but when Autos skting the cluster beyond the",
    "start": "1315919",
    "end": "1322600"
  },
  {
    "text": "minimum node count um you have the opportunity or you have the option to to select either on",
    "start": "1322600",
    "end": "1331039"
  },
  {
    "text": "demand or spot instances as part of your autoscaling uh uh",
    "start": "1331039",
    "end": "1336799"
  },
  {
    "text": "nodes so that's you know that's that's a good setting that uh comes in handy",
    "start": "1336799",
    "end": "1342120"
  },
  {
    "text": "as depending on obviously like I said the use cases uh the next one that I'd like to highlight is cub block placement",
    "start": "1342120",
    "end": "1350000"
  },
  {
    "text": "policy um to minimize the impact of losing a node if you use for example uh",
    "start": "1350000",
    "end": "1356720"
  },
  {
    "text": "all spot which are volatile instances cubol implements this policy which is in",
    "start": "1356720",
    "end": "1362159"
  },
  {
    "text": "effect by default and forces a copy of data to be stored on stable",
    "start": "1362159",
    "end": "1367799"
  },
  {
    "text": "nodes the next one is fall back to On Demand nodes if you said this if um so",
    "start": "1367799",
    "end": "1374360"
  },
  {
    "text": "saying this means that if B inis is are not um",
    "start": "1374360",
    "end": "1380120"
  },
  {
    "text": "available during the time based on the timeout uh specified uh the cuq ball will automatically fall back to On",
    "start": "1380120",
    "end": "1386640"
  },
  {
    "text": "Demand so it does not affect your um jobs or processes that you may have be uh may have running",
    "start": "1386640",
    "end": "1394720"
  },
  {
    "text": "currently and then the spot instance percentag is how many of those did you want um them to be spot versus uh either",
    "start": "1394720",
    "end": "1403440"
  },
  {
    "text": "stable or uh or on demand so moving on to the",
    "start": "1403440",
    "end": "1410440"
  },
  {
    "start": "1409000",
    "end": "1409000"
  },
  {
    "text": "uh to the next uh next screen here this is where admins can manage",
    "start": "1410440",
    "end": "1416720"
  },
  {
    "text": "roles users and groups I won't spend too much time on this because it's pretty standard implementation of um roles",
    "start": "1416720",
    "end": "1423360"
  },
  {
    "text": "users and groups uh based uh security um this is where they would set which users",
    "start": "1423360",
    "end": "1429880"
  },
  {
    "text": "can access what part of the uh what part of the qds and so forth and users uh",
    "start": "1429880",
    "end": "1435360"
  },
  {
    "text": "generally can join many accounts with a single profile but user can also have um but you can",
    "start": "1435360",
    "end": "1441760"
  },
  {
    "text": "but user can only have one default account at any given",
    "start": "1441760",
    "end": "1447360"
  },
  {
    "text": "[Music] point moving on to the uh the next interface that they would use uh uh kind",
    "start": "1448940",
    "end": "1455960"
  },
  {
    "text": "of important uh this is where they would monitor um cluster usage so what they can do from this",
    "start": "1455960",
    "end": "1465919"
  },
  {
    "text": "is look at different just different um settings and uh different ways to",
    "start": "1466039",
    "end": "1474039"
  },
  {
    "text": "generate reports for example how the cluster was formed and you know number of On Demand versus spot instances uh",
    "start": "1474039",
    "end": "1481919"
  },
  {
    "text": "start time end time cluster usage hours they they can also generate reports",
    "start": "1481919",
    "end": "1487440"
  },
  {
    "text": "based on given date range and the status tab uh exposes",
    "start": "1487440",
    "end": "1493799"
  },
  {
    "text": "latency related uh statistics command latency distribution",
    "start": "1493799",
    "end": "1499080"
  },
  {
    "text": "uh command statuses how many jobs in progress how many failed how many succeeded how many scheduled jobs uh are",
    "start": "1499080",
    "end": "1506960"
  },
  {
    "text": "in progress and so forth and another um kind of interesting um uh you know view",
    "start": "1506960",
    "end": "1514880"
  },
  {
    "text": "there is a leaderboard which lists total commands and scheduled jobs run by individual users so pretty handy for uh",
    "start": "1514880",
    "end": "1523080"
  },
  {
    "text": "admin to keep an eye on and this is the just a a view of a",
    "start": "1523080",
    "end": "1529799"
  },
  {
    "start": "1525000",
    "end": "1525000"
  },
  {
    "text": "graph for detailed cluster usage basically it's it's showing how the",
    "start": "1529799",
    "end": "1535000"
  },
  {
    "text": "system is autoscaled and uh chosen On Demand",
    "start": "1535000",
    "end": "1540399"
  },
  {
    "text": "versus uh spot inance um in this graph and this is all as a result of um of",
    "start": "1540399",
    "end": "1549880"
  },
  {
    "text": "autoscaling and there's also integration with u built-in integration with ganglia",
    "start": "1551559",
    "end": "1557039"
  },
  {
    "start": "1554000",
    "end": "1554000"
  },
  {
    "text": "for monitoring um clusters the admins can view performance of the cluster as a",
    "start": "1557039",
    "end": "1562440"
  },
  {
    "text": "whole as well as inspect the operation uh performance of individual node instances and they can also view Hado",
    "start": "1562440",
    "end": "1569480"
  },
  {
    "text": "metrics uh for each node instance and there are some other",
    "start": "1569480",
    "end": "1574520"
  },
  {
    "text": "interrogations that uh we don't have uh I'm not going to spend too much time on in this presentation uh but you can also",
    "start": "1574520",
    "end": "1582720"
  },
  {
    "text": "integrate with data dog and we have obbc drivers for um Tablo",
    "start": "1582720",
    "end": "1589919"
  },
  {
    "text": "so that was a uh very brief overview of cu's web interface and how it caters to",
    "start": "1590240",
    "end": "1596600"
  },
  {
    "text": "the members of uh uh your data teams now as I mentioned earlier Cub or qds uh",
    "start": "1596600",
    "end": "1605279"
  },
  {
    "text": "takes full advantage of the unlimited scalability of the cloud and it's",
    "start": "1605279",
    "end": "1610679"
  },
  {
    "text": "built-in Autos scaling feature automatically adds resources when Computing or storage demands uh",
    "start": "1610679",
    "end": "1619840"
  },
  {
    "text": "change and all along the way while keeping the uh number of cluster nodes",
    "start": "1619840",
    "end": "1625320"
  },
  {
    "text": "at the minimum needed to meet the processing needs of your",
    "start": "1625320",
    "end": "1630360"
  },
  {
    "text": "workloads uh just to give you an idea of uh our customer based uh customers scale",
    "start": "1630360",
    "end": "1635720"
  },
  {
    "text": "up to uh their clusters in average of 34 times its minimum size that they have uh",
    "start": "1635720",
    "end": "1643520"
  },
  {
    "text": "preconfigured and 47% of all Compu",
    "start": "1643520",
    "end": "1648720"
  },
  {
    "text": "hours are run with uh spot instances uh without user intervention just a tidbit",
    "start": "1648720",
    "end": "1655159"
  },
  {
    "text": "there so um basically I'm going to repeat a couple of",
    "start": "1655159",
    "end": "1660360"
  },
  {
    "start": "1656000",
    "end": "1656000"
  },
  {
    "text": "um things here so we get all caught up uh before we address the cloud advantage of using cuq ball on um AWS let's",
    "start": "1660360",
    "end": "1668480"
  },
  {
    "text": "briefly review some of the attributes of on premise cluster deployments um one of",
    "start": "1668480",
    "end": "1673840"
  },
  {
    "text": "the one of the biggest ones in my mind is uh that it forces comput and storage",
    "start": "1673840",
    "end": "1679320"
  },
  {
    "text": "uh to live together and which also means that it should scale together which",
    "start": "1679320",
    "end": "1685159"
  },
  {
    "text": "which I don't think is ideal and clusters must be provisioned for Peak capacity which can obviously be very",
    "start": "1685159",
    "end": "1691640"
  },
  {
    "text": "expensive and also leads to under utilize resources during off peak usage",
    "start": "1691640",
    "end": "1698960"
  },
  {
    "text": "hours and the Clusters must be persistently on otherwise the data is",
    "start": "1698960",
    "end": "1705480"
  },
  {
    "text": "not accessible on the other",
    "start": "1705480",
    "end": "1711200"
  },
  {
    "text": "hand because storage is cheap and persistent and compute can be",
    "start": "1711200",
    "end": "1718720"
  },
  {
    "start": "1714000",
    "end": "1714000"
  },
  {
    "text": "expensive using the cloud we are able to decouple storage from",
    "start": "1718720",
    "end": "1724080"
  },
  {
    "text": "compute the idea is to use persistent storage service like Amazon S3 and use",
    "start": "1724080",
    "end": "1730799"
  },
  {
    "text": "compute power on demand and selectively so by doing this storage we can sent",
    "start": "1730799",
    "end": "1738080"
  },
  {
    "text": "utze the storage and uh we can we can have computation uh as distributed and",
    "start": "1738080",
    "end": "1744799"
  },
  {
    "text": "On Demand resources can Scale elastically based on the workload for example",
    "start": "1744799",
    "end": "1750919"
  },
  {
    "text": "compute heavy versus uh storage heavy now what going to look at what",
    "start": "1750919",
    "end": "1758600"
  },
  {
    "start": "1758000",
    "end": "1758000"
  },
  {
    "text": "we're looking at here is a um well as I mentioned earlier Cub on",
    "start": "1758600",
    "end": "1763840"
  },
  {
    "text": "AWS takes advantage of the the uh the power of unlimited compute capacity in",
    "start": "1763840",
    "end": "1769039"
  },
  {
    "text": "the cloud using its built-in Autos scaling feature and what you're seeing here is a a production usage report that",
    "start": "1769039",
    "end": "1776840"
  },
  {
    "text": "we've pulled out um where the cluster started to Downs scale around 300 p.m.",
    "start": "1776840",
    "end": "1782840"
  },
  {
    "text": "and it scaled back up at 7 uh 700 p.m. when the bat job started to execute so",
    "start": "1782840",
    "end": "1789559"
  },
  {
    "text": "basically cuq dynamically M dynamically mat matches the uh size of the cluster",
    "start": "1789559",
    "end": "1795279"
  },
  {
    "text": "with the workload and auto automatically add as resources when competing or storage demands U",
    "start": "1795279",
    "end": "1802480"
  },
  {
    "text": "increase just a side note 80% of all clusters are turned off automatically by",
    "start": "1802480",
    "end": "1808039"
  },
  {
    "text": "Cubo versus manually by uh by a data admin um this is just tidbit from our",
    "start": "1808039",
    "end": "1813679"
  },
  {
    "text": "existing uh uh customer",
    "start": "1813679",
    "end": "1817559"
  },
  {
    "text": "base um in addition to unlimited compute capacity cubble on Amazon or AWS it",
    "start": "1818840",
    "end": "1826240"
  },
  {
    "text": "supports 40 plus uh instance types spanning Niche such as storage optimized memory",
    "start": "1826240",
    "end": "1833760"
  },
  {
    "text": "optimized and um computer optimize and it also easily integrates AWS reserved",
    "start": "1833760",
    "end": "1842320"
  },
  {
    "text": "instances all you have to do is Select and um easy in the cluster config page",
    "start": "1842320",
    "end": "1848440"
  },
  {
    "text": "and um as a side note uh we we've seen in our current customer base uh that",
    "start": "1848440",
    "end": "1855559"
  },
  {
    "text": "37 different instance types have been used by uh by our",
    "start": "1855559",
    "end": "1862398"
  },
  {
    "text": "customers so before we review so before we review uh Cubs on",
    "start": "1863639",
    "end": "1871600"
  },
  {
    "text": "premise to the cloud migration services in partnership with uh wandisco let's",
    "start": "1871600",
    "end": "1878039"
  },
  {
    "text": "quickly look at some Cloud migration use cases um that are pretty common these",
    "start": "1878039",
    "end": "1885399"
  },
  {
    "text": "days so the first one being",
    "start": "1885399",
    "end": "1889919"
  },
  {
    "start": "1886000",
    "end": "1886000"
  },
  {
    "text": "where you have a maxed out on Prem cluster that just cannot handle uh",
    "start": "1890880",
    "end": "1896799"
  },
  {
    "text": "workloads anymore and some of the requirements for these kinds of uh deployments could be that data must uh",
    "start": "1896799",
    "end": "1904320"
  },
  {
    "text": "must be sync only during migration process uh you must de commission workload uh from on-prem after migration",
    "start": "1904320",
    "end": "1912399"
  },
  {
    "text": "so you know all the um all the analytics jobs processes that are running against the uh",
    "start": "1912399",
    "end": "1919840"
  },
  {
    "text": "the either the migrated uh deployment versus on Prem um 20 24 by 7 data",
    "start": "1920679",
    "end": "1927639"
  },
  {
    "text": "replication and no production downtime so one of the ways you can handle that is",
    "start": "1927639",
    "end": "1935480"
  },
  {
    "text": "by by moving the data to the cloud and then moving the applications and data",
    "start": "1936880",
    "end": "1941919"
  },
  {
    "text": "pipelines to uh to qds",
    "start": "1941919",
    "end": "1946518"
  },
  {
    "text": "the Second Use case might be that the workload with spikes that can be processed on Prem a good example is",
    "start": "1948159",
    "end": "1953880"
  },
  {
    "text": "holidays yearly sales Etc and the requirements are um kind of similar in",
    "start": "1953880",
    "end": "1959240"
  },
  {
    "text": "that there shouldn't be any downtime um and you know 20 4x7 data application",
    "start": "1959240",
    "end": "1965600"
  },
  {
    "text": "with no data loss and uh an additional requirement here might be that uh the",
    "start": "1965600",
    "end": "1971440"
  },
  {
    "text": "the results that you see should be you know brought back to on Prem so that's why you know there",
    "start": "1971440",
    "end": "1978039"
  },
  {
    "text": "could be a requirement for B directional replication so the the solution in case in this case would be to sync on Prem",
    "start": "1978039",
    "end": "1984720"
  },
  {
    "text": "data with the cloud uh process workloads in qds in the cloud and then send",
    "start": "1984720",
    "end": "1990279"
  },
  {
    "text": "results back to uh to on Prem and then the third one is um where",
    "start": "1990279",
    "end": "1998679"
  },
  {
    "text": "you have a single shed cluster deployed for production and it's just not able to",
    "start": "1998679",
    "end": "2004039"
  },
  {
    "text": "handle uh new use cases uh because it's reaching limits and um requirements here",
    "start": "2004039",
    "end": "2010480"
  },
  {
    "text": "again you know there shouldn't be any downtime uh and then periodic replication with uh no data loss so in",
    "start": "2010480",
    "end": "2018000"
  },
  {
    "text": "terms of solution what uh what could be done is free to free up on Prim free up",
    "start": "2018000",
    "end": "2023799"
  },
  {
    "text": "on Prem resources for production workloads and for that you could move some subset of data to the cloud and",
    "start": "2023799",
    "end": "2030840"
  },
  {
    "text": "build applications and data ppins in qds that Target different clusters from",
    "start": "2030840",
    "end": "2035919"
  },
  {
    "text": "unified um from the ified",
    "start": "2035919",
    "end": "2040080"
  },
  {
    "text": "interface so these um these types of use cases uh to address them kudo's Hado",
    "start": "2042799",
    "end": "2049760"
  },
  {
    "start": "2043000",
    "end": "2043000"
  },
  {
    "text": "migration services offered in partnership with uh lisco it's basically",
    "start": "2049760",
    "end": "2054839"
  },
  {
    "text": "a software and service solution that allows companies to transparently migrate workloads uh to the cloud and",
    "start": "2054839",
    "end": "2061440"
  },
  {
    "text": "start using cubble uh immediately and you uh some of the",
    "start": "2061440",
    "end": "2068240"
  },
  {
    "text": "benefits are elasticity uh lower cost agility simplified management no",
    "start": "2068240",
    "end": "2073878"
  },
  {
    "text": "production impact U data consistency between on Prem and cloud and you can",
    "start": "2073879",
    "end": "2079280"
  },
  {
    "text": "also reuse your existing data pipelines ETL applications and so",
    "start": "2079280",
    "end": "2085440"
  },
  {
    "text": "forth you can uh definitely learn more about um this offering um on cub.com",
    "start": "2085440",
    "end": "2092560"
  },
  {
    "text": "uh moving on to our next section",
    "start": "2092560",
    "end": "2099680"
  },
  {
    "text": "um in the in this section we'll briefly review media mat's uh Journey to the",
    "start": "2099680",
    "end": "2106040"
  },
  {
    "text": "cloud uh basically qds on uh AWS for those listeners that are not",
    "start": "2106040",
    "end": "2112359"
  },
  {
    "text": "familiar with uh media maath it's the leading Global digital media buying platform based out of uh New York City",
    "start": "2112359",
    "end": "2119800"
  },
  {
    "text": "it develops and sells tools for digital marketing managers under their main",
    "start": "2119800",
    "end": "2125720"
  },
  {
    "text": "brand called terminal one it allows uh marketing managers to plan execute",
    "start": "2125720",
    "end": "2131800"
  },
  {
    "text": "optimize and analyze marketing programs and",
    "start": "2131800",
    "end": "2138839"
  },
  {
    "text": "um the uh Antics team and insights team at media maath is responsible for",
    "start": "2141240",
    "end": "2148920"
  },
  {
    "text": "delivering decision-making infrastructure and advisory services to their clients so basically the team um",
    "start": "2148920",
    "end": "2156680"
  },
  {
    "text": "helps clients answer complex business questions using analytics that produce",
    "start": "2156680",
    "end": "2162160"
  },
  {
    "text": "actionable insights and here are uh what you see on the on the slide are the",
    "start": "2162160",
    "end": "2167200"
  },
  {
    "text": "three uh top three of their use cases the first one is segment",
    "start": "2167200",
    "end": "2173200"
  },
  {
    "text": "audiences uh based on their behavior including um such topics as user pathway",
    "start": "2173200",
    "end": "2179160"
  },
  {
    "text": "and multi-dimensional uh recency analysis they need to segment different",
    "start": "2179160",
    "end": "2184760"
  },
  {
    "text": "audiences and uh they also need to build customer profiles across you know thousands of first party and third party",
    "start": "2184760",
    "end": "2192359"
  },
  {
    "text": "segments uh examples would be uh C CRM files uh demographics and so forth and",
    "start": "2192359",
    "end": "2199359"
  },
  {
    "text": "the third one is uh uh just simplifying the attribution insights uh which shows",
    "start": "2199359",
    "end": "2204960"
  },
  {
    "text": "the effects of you know upper funnel prospecting on Lower funnel um",
    "start": "2204960",
    "end": "2211040"
  },
  {
    "text": "remarketing um media strategies so to be honest my uh my knowledge uh",
    "start": "2211040",
    "end": "2218040"
  },
  {
    "text": "about this domain kind of ends here so I'd like to move on to to to the to the",
    "start": "2218040",
    "end": "2225040"
  },
  {
    "start": "2223000",
    "end": "2223000"
  },
  {
    "text": "next slide um their medium uh their Flagship product today terminal one",
    "start": "2225040",
    "end": "2230800"
  },
  {
    "text": "captures data that is generated when customers run digital marketing campaigns and the data amounts to a few",
    "start": "2230800",
    "end": "2238480"
  },
  {
    "text": "terabytes of structured and um semi-structured data in a day uh you",
    "start": "2238480",
    "end": "2245760"
  },
  {
    "text": "know a few terabytes that's a lot of data and it consists information of marketing plans campaigns Impressions",
    "start": "2245760",
    "end": "2253560"
  },
  {
    "text": "clicks con um conversions revenue and so forth and medium math was looking to",
    "start": "2253560",
    "end": "2259640"
  },
  {
    "text": "take um their existing capabilities uh to the next level to manage these new",
    "start": "2259640",
    "end": "2265560"
  },
  {
    "text": "Innovative U analytics um tasks so as you can see they have 180 billion",
    "start": "2265560",
    "end": "2271359"
  },
  {
    "text": "Impressions or opportunities a day uh their Peak uh query per second is uh",
    "start": "2271359",
    "end": "2277960"
  },
  {
    "text": "about 3 plus million and they process up to um three plus terabytes of data",
    "start": "2277960",
    "end": "2284480"
  },
  {
    "text": "compressed data that's a lot of",
    "start": "2284480",
    "end": "2289280"
  },
  {
    "text": "data here are some of the challenges that they were um that that they needed",
    "start": "2290920",
    "end": "2296760"
  },
  {
    "start": "2291000",
    "end": "2291000"
  },
  {
    "text": "to find a solution for um as processing the raw data to segment the audience",
    "start": "2296760",
    "end": "2303160"
  },
  {
    "text": "optimize campaigns compute Revenue um attribute and so",
    "start": "2303160",
    "end": "2309800"
  },
  {
    "text": "forth this is what they they were facing um transforming session log data to construct use sessions and click path",
    "start": "2309800",
    "end": "2317560"
  },
  {
    "text": "analysis uh it's a complex process they wanted a solution that their analysts could easily and uh easily use and get",
    "start": "2317560",
    "end": "2325839"
  },
  {
    "text": "started with quickly and uh do not have to worry about operational management of",
    "start": "2325839",
    "end": "2332520"
  },
  {
    "text": "such um you know such technical uh operations",
    "start": "2332520",
    "end": "2338359"
  },
  {
    "text": "they also wanted to make sure that they could reuse their um data",
    "start": "2338359",
    "end": "2343640"
  },
  {
    "text": "pipelines automating the execution of the data pipeline while honoring the uh",
    "start": "2343640",
    "end": "2348960"
  },
  {
    "text": "interdependencies between the pipeline activities and um these pipelines uh they're repeated",
    "start": "2348960",
    "end": "2356760"
  },
  {
    "text": "and they trans they run the same Transformations on daily basis uh week after week without you know much",
    "start": "2356760",
    "end": "2364119"
  },
  {
    "text": "intervention from uh their their team once it was set so they they kind of wanted to make sure that whatever",
    "start": "2364119",
    "end": "2370359"
  },
  {
    "text": "platform or solution um they could um they could reuse these",
    "start": "2370359",
    "end": "2376520"
  },
  {
    "text": "pipelines and obviously the U The Upfront investment and commitment is um",
    "start": "2376520",
    "end": "2382319"
  },
  {
    "text": "always um always a challenge and uh a factor when people uh when companies um",
    "start": "2382319",
    "end": "2389400"
  },
  {
    "text": "look for",
    "start": "2389400",
    "end": "2391880"
  },
  {
    "start": "2394000",
    "end": "2394000"
  },
  {
    "text": "Solutions so basically what this is what the were looking for according to their um senior director they needed something",
    "start": "2394680",
    "end": "2401520"
  },
  {
    "text": "that was reliable easy to learn set up used and put into production without the risk and ey expectations that comes with",
    "start": "2401520",
    "end": "2409160"
  },
  {
    "text": "committing millions of dollars in upfront investment and they decided to choose um qall um to summarize many",
    "start": "2409160",
    "end": "2417640"
  },
  {
    "text": "factors played a critical role in their Journey to the cloud um qds on uh AWS",
    "start": "2417640",
    "end": "2424119"
  },
  {
    "text": "one of them being a big data analytics solution within hours they were able to reuse a",
    "start": "2424119",
    "end": "2430319"
  },
  {
    "text": "number of useful business critical custom python libraries that they had",
    "start": "2430319",
    "end": "2435480"
  },
  {
    "text": "devolved matured and stabilized and then these libraries um",
    "start": "2435480",
    "end": "2441800"
  },
  {
    "text": "were able to they were able to import them and start using right away the",
    "start": "2441800",
    "end": "2446880"
  },
  {
    "text": "other one being unlimited Cloud capacity uh via Autos scaling um the Clusters",
    "start": "2446880",
    "end": "2452200"
  },
  {
    "text": "automatically GRE the number of compete nodes as they started to move uh and run",
    "start": "2452200",
    "end": "2457520"
  },
  {
    "text": "more queries and scale the cluster down as the numberers queries um number of queries went down so the the operational",
    "start": "2457520",
    "end": "2465040"
  },
  {
    "text": "efficiency was a was a plus as they didn't have to continually uh reach out to their Engineering Group and uh that",
    "start": "2465040",
    "end": "2472280"
  },
  {
    "text": "led them focus on complex tasks of managing their mission critical systems",
    "start": "2472280",
    "end": "2478200"
  },
  {
    "text": "and obviously the the existing data pipelines and so forth um so",
    "start": "2478200",
    "end": "2486520"
  },
  {
    "text": "this is where CU is being used at media maath it's being used at a lot of different uh um in a lot of different",
    "start": "2489440",
    "end": "2497440"
  },
  {
    "text": "ways by a lot of different teams data science they use spark uh analytics spark And Hive uh product team uses Hive",
    "start": "2497440",
    "end": "2505400"
  },
  {
    "text": "analyst use mod query and Engineering uses Spark um And Hive so uh in the",
    "start": "2505400",
    "end": "2512800"
  },
  {
    "text": "interest of time I also want to make sure we have enough time for Q&A so I'm going to move on to this and uh this",
    "start": "2512800",
    "end": "2519720"
  },
  {
    "text": "slide pretty much accurately uh describes itself so with that I'm going",
    "start": "2519720",
    "end": "2526000"
  },
  {
    "text": "to hand it over um to to R thank you dmes U that's a great talk and we",
    "start": "2526000",
    "end": "2531560"
  },
  {
    "text": "learned a lot about cubal and Big Data what you can do with big data using the cloud with that we'll open up for Q&A um",
    "start": "2531560",
    "end": "2540400"
  },
  {
    "text": "if you don't know you can type your Q&A question in the panel you must see as attendee you must see a panel to type",
    "start": "2540400",
    "end": "2546440"
  },
  {
    "text": "your question and answer and we will start taking reading out some of the questions as the time",
    "start": "2546440",
    "end": "2552760"
  },
  {
    "text": "permits all right the first question is while dmes talked about the idea of",
    "start": "2557520",
    "end": "2562760"
  },
  {
    "text": "being able to separate the compute from um storage the question is what are your",
    "start": "2562760",
    "end": "2568440"
  },
  {
    "text": "thoughts around performance of storing data on S3 versus uh hdfs which is the",
    "start": "2568440",
    "end": "2573680"
  },
  {
    "text": "storage file system storage with hadu um it's as some of the customers have",
    "start": "2573680",
    "end": "2580160"
  },
  {
    "text": "demonstrated for example like Netflix was storing our paryt of data onto S3",
    "start": "2580160",
    "end": "2585240"
  },
  {
    "text": "and that they have been able to scale the system much better that they would otherwise had to do on if they have went",
    "start": "2585240",
    "end": "2592000"
  },
  {
    "text": "with Hadoop as a storage and what helps with the storing data on S3 is that you",
    "start": "2592000",
    "end": "2597760"
  },
  {
    "text": "can infinite infinitely scale your computer instances rather than trying to",
    "start": "2597760",
    "end": "2603040"
  },
  {
    "text": "put all of your data onto a single node making that node vertically scale so the idea of horizontally scaling up your",
    "start": "2603040",
    "end": "2609119"
  },
  {
    "text": "workload actually helps uh with data sets in S3 because you can have not only one single cluster talking to S3 but you",
    "start": "2609119",
    "end": "2615319"
  },
  {
    "text": "can have multiple clusters talking to SC at the same time what are your thoughts raes on that yeah definitely um I think",
    "start": "2615319",
    "end": "2623640"
  },
  {
    "text": "if you compare SV to sdfs directly with a simple test sdfs will obviously be",
    "start": "2623640",
    "end": "2631559"
  },
  {
    "text": "faster but SV really U skills well linear linearly",
    "start": "2631559",
    "end": "2638720"
  },
  {
    "text": "with the throughput as the connections grow and um you know that's that's",
    "start": "2638720",
    "end": "2644680"
  },
  {
    "text": "pretty much how uh Big Data engines work the more data you need uh to read the more tasks uh that you can deploy uh to",
    "start": "2644680",
    "end": "2654760"
  },
  {
    "text": "for those kinds of jobs cool thank you the second question is do I have to have",
    "start": "2654760",
    "end": "2661200"
  },
  {
    "text": "my data in a particular format in Amazon S3 to be able to use with cubble",
    "start": "2661200",
    "end": "2667559"
  },
  {
    "text": "now the advantage of that is cu cubal or any Hado for that matter works by",
    "start": "2667559",
    "end": "2674160"
  },
  {
    "text": "connecting to S3 using something called Hado compatible file system which means that any format you can use with htfs",
    "start": "2674160",
    "end": "2680800"
  },
  {
    "text": "you can actually use with S3 but I would let dmes talk more about that yeah no we",
    "start": "2680800",
    "end": "2687520"
  },
  {
    "text": "uh Cub definitely supports all the standard H formats AO orc uh par and uh",
    "start": "2687520",
    "end": "2695280"
  },
  {
    "text": "we actually also support uh you know custom formats or propriety as long as",
    "start": "2695280",
    "end": "2700960"
  },
  {
    "text": "you have uh serers to uh to read the data cool thank you so it seems like you",
    "start": "2700960",
    "end": "2707000"
  },
  {
    "text": "can store your data set with any sort of format you want in Amazon S3 whether be it a text format whether be it a binary",
    "start": "2707000",
    "end": "2713720"
  },
  {
    "text": "format or whether it be it a colum format as being made popular with formats like park or or recently that's",
    "start": "2713720",
    "end": "2722319"
  },
  {
    "text": "correct the question is with regards to Auto downscaling and in qds would that",
    "start": "2722400",
    "end": "2728800"
  },
  {
    "text": "impact or would it have any impact on my active jobs uh no there's no real impact",
    "start": "2728800",
    "end": "2735480"
  },
  {
    "text": "because of uh Grace full shutdown uh by making sure that there aren't any active jobs running and also keeps track of the",
    "start": "2735480",
    "end": "2743160"
  },
  {
    "text": "hour boundary of uh Amazon so so the answer is uh answer is no okay the next",
    "start": "2743160",
    "end": "2751359"
  },
  {
    "text": "question it says do you support heterogeneous clusters yes uh in fact we do we support",
    "start": "2751359",
    "end": "2759200"
  },
  {
    "text": "uh heterogenous spark and H two clusters which means that the slave nodes",
    "start": "2759200",
    "end": "2764680"
  },
  {
    "text": "comprising um the cluster maybe of different instance types of uh on Amazon",
    "start": "2764680",
    "end": "2770880"
  },
  {
    "text": "and what what would be the advantage of doing such a scenario is that something you talked about in terms of a storage",
    "start": "2770880",
    "end": "2776040"
  },
  {
    "text": "heavy workload versus compute heavy workload exactly and then the other uh the other use case uh would be uh if you",
    "start": "2776040",
    "end": "2783040"
  },
  {
    "text": "really have a tight budget it's a basically TCL okay uh yeah so you can better control your cost in terms of",
    "start": "2783040",
    "end": "2789480"
  },
  {
    "text": "workload match exactly um this question says that we talked a",
    "start": "2789480",
    "end": "2796480"
  },
  {
    "text": "lot about ad hoc analytics with big data um the question is like what about",
    "start": "2796480",
    "end": "2802000"
  },
  {
    "text": "production pipelines is there a way to schedule jobs or invoke things more programmatically rather than just going",
    "start": "2802000",
    "end": "2807160"
  },
  {
    "text": "to your UI yes uh so you can definitely create simple workflows in qds using the",
    "start": "2807160",
    "end": "2813800"
  },
  {
    "text": "schedule interface that we talked about earlier uh and you can also use outside of the web",
    "start": "2813800",
    "end": "2820200"
  },
  {
    "text": "interface you can use apis rest apis as well as sdks in Java Python and R and",
    "start": "2820200",
    "end": "2828359"
  },
  {
    "text": "all the detail documentation can be found on our website and also note that uh we do support uh airflow so if you're",
    "start": "2828359",
    "end": "2836880"
  },
  {
    "text": "already using airflow you can create complex pipelines using that and have um",
    "start": "2836880",
    "end": "2842960"
  },
  {
    "text": "those uh integrated with the CU qds yeah and now I see a bunch of questions",
    "start": "2842960",
    "end": "2848480"
  },
  {
    "text": "around the voice loss and really sorry about that uh but we're not going to go back to that I think the next question",
    "start": "2848480",
    "end": "2855480"
  },
  {
    "text": "from a user is from attendee is definitely in the reflection of the something we talked about earlier which",
    "start": "2855480",
    "end": "2861040"
  },
  {
    "text": "is would you shed light on the trade-offs of decoupling storage and",
    "start": "2861040",
    "end": "2866440"
  },
  {
    "text": "comput as a result of this decoupling or data becoming non local does Network may",
    "start": "2866440",
    "end": "2872880"
  },
  {
    "text": "become the bottleneck um in some aspects of this May remain true",
    "start": "2872880",
    "end": "2879319"
  },
  {
    "text": "that as you decouple storage and compute there could be situations where Network may become a bottleneck but what the way",
    "start": "2879319",
    "end": "2886960"
  },
  {
    "text": "to the right way to think about that would be that instead of making Network a bottleneck you can actually scale out",
    "start": "2886960",
    "end": "2892800"
  },
  {
    "text": "horizontally so instead of having a 10 note cluster for example which gives you a limited side size of hdfs uh with S3",
    "start": "2892800",
    "end": "2900119"
  },
  {
    "text": "since it scales linearly you probably could have a 100 smaller nodes in which case your network will never become a",
    "start": "2900119",
    "end": "2906000"
  },
  {
    "text": "bottle data still will go over the network but you won't be able to um see the performance impact as such um for",
    "start": "2906000",
    "end": "2913440"
  },
  {
    "text": "people who are interested in this we definitely can probably put a link back to the Netflix study where they did a",
    "start": "2913440",
    "end": "2919440"
  },
  {
    "text": "good study on showing that how the idea of storing data set into S3 bit instead",
    "start": "2919440",
    "end": "2925240"
  },
  {
    "text": "of htfs is really does not lead to any more performance impact than maybe let's say three or 4% on average yeah what",
    "start": "2925240",
    "end": "2932319"
  },
  {
    "text": "what do you think yeah I totally agree it's definitely depend on um use cases",
    "start": "2932319",
    "end": "2937720"
  },
  {
    "text": "and U um I think um most use cases that we've come across uh the the benefits of",
    "start": "2937720",
    "end": "2944520"
  },
  {
    "text": "separating the two definitely outweighs uh the tradeoffs or the disadvantages of",
    "start": "2944520",
    "end": "2950160"
  },
  {
    "text": "separating the two okay the next question from attendee is that do we have a guide some quick start guide to",
    "start": "2950160",
    "end": "2956599"
  },
  {
    "text": "get handson with AWS and assuming this is most probably in terms of Big Data",
    "start": "2956599",
    "end": "2962000"
  },
  {
    "text": "yes if you go to aws.amazon.com bigdata or Big hyund Data you actually",
    "start": "2962000",
    "end": "2968480"
  },
  {
    "text": "will see a link there which will say getting started and the getting started will",
    "start": "2968480",
    "end": "2974359"
  },
  {
    "text": "guide will point you to everything needed now at the same time I just want to take a moment and ask you that you",
    "start": "2974359",
    "end": "2981440"
  },
  {
    "text": "must you will be able to see a online poll right now please do take a moment to answer the online poll your feedback",
    "start": "2981440",
    "end": "2987559"
  },
  {
    "text": "is very important for us uh entire AWS works on the premise of customer",
    "start": "2987559",
    "end": "2992839"
  },
  {
    "text": "Obsession and the more you can help us provide feedback and and the more we can cater to uh contents which can help you",
    "start": "2992839",
    "end": "2999400"
  },
  {
    "text": "with your workload on AWS effectively we will keep and again thank",
    "start": "2999400",
    "end": "3005200"
  },
  {
    "text": "you for taking time today to answer uh to attend the webinar we hope you that you got to learn something out of it uh",
    "start": "3005200",
    "end": "3011559"
  },
  {
    "text": "while you answering the polls we'll keep um probably answer another question or",
    "start": "3011559",
    "end": "3017559"
  },
  {
    "text": "two the other one says that is the webinar recorded online where to access it uh the people who attended the",
    "start": "3018520",
    "end": "3025640"
  },
  {
    "text": "webinar they would get a link probably within a week on how to access the webinar the content of the webinar and",
    "start": "3025640",
    "end": "3031760"
  },
  {
    "text": "the recorded audio for that uh the question is how does cubal",
    "start": "3031760",
    "end": "3037240"
  },
  {
    "text": "determine if something is going to be processed by a spot instance or I think the way to probably",
    "start": "3037240",
    "end": "3044280"
  },
  {
    "text": "read that is that is there a way cubel can automatically use spot instances or does a user has to tell cubel to use",
    "start": "3044280",
    "end": "3050960"
  },
  {
    "text": "spot instances um well all of these are um",
    "start": "3050960",
    "end": "3056680"
  },
  {
    "text": "settings are configurable through the web interface so you can choose to use spot instances as part of your",
    "start": "3056680",
    "end": "3063040"
  },
  {
    "text": "autoscaling um you know nodes uh if you will and you can definitely set it so",
    "start": "3063040",
    "end": "3070119"
  },
  {
    "text": "that if spot instances are not available you can fall back on demand or you can",
    "start": "3070119",
    "end": "3075799"
  },
  {
    "text": "also use stable spot instances but I think um the other the other part of",
    "start": "3075799",
    "end": "3082079"
  },
  {
    "text": "this question is if if if there's a way to know",
    "start": "3082079",
    "end": "3087440"
  },
  {
    "text": "which processes are being uh processed the vs spot instances and the answer the",
    "start": "3087440",
    "end": "3092720"
  },
  {
    "text": "short answer is yes the uh the admin uh web interface that I uh showed earlier",
    "start": "3092720",
    "end": "3099160"
  },
  {
    "text": "has a lot more details that I could uh present in a slide so there's detailed",
    "start": "3099160",
    "end": "3105160"
  },
  {
    "text": "uh reports that you can generate off of that you can see exactly what jobs are running on which instances and how much",
    "start": "3105160",
    "end": "3112440"
  },
  {
    "text": "um load are they processing and so forth okay cool thank you so another question which is says is any",
    "start": "3112440",
    "end": "3120240"
  },
  {
    "text": "archiving methods to move all unused data to less expensive storage uh if",
    "start": "3120240",
    "end": "3125319"
  },
  {
    "text": "you're storing with cubal you Prim are storing all of your data in Amazon S3 on AWS and in Amazon S3 we do provide",
    "start": "3125319",
    "end": "3131720"
  },
  {
    "text": "something called a policy life cycle policies to be specific using the life",
    "start": "3131720",
    "end": "3137040"
  },
  {
    "text": "cycle policies you can say that any data which has not been used for last amount of time or is older than let's say 90",
    "start": "3137040",
    "end": "3144559"
  },
  {
    "text": "days you could automatically base move it to Glacier and that will actually help you with archival so you could",
    "start": "3144559",
    "end": "3151799"
  },
  {
    "text": "definitely create a life cycle policies on your S3 buckets and objects which automatically move them uh to Amazon",
    "start": "3151799",
    "end": "3158440"
  },
  {
    "text": "Glacier for long-term storage or even in S3 we do provide",
    "start": "3158440",
    "end": "3163680"
  },
  {
    "text": "something called S3 infrequent access and that's that allows that's a",
    "start": "3163680",
    "end": "3169200"
  },
  {
    "text": "different tier of storage where you can say that move my data to S3 infrequent access um and you will be a char Char at",
    "start": "3169200",
    "end": "3177200"
  },
  {
    "text": "a little less amount than what S3 standard is being charged",
    "start": "3177200",
    "end": "3182359"
  },
  {
    "text": "for okay um the question is how does cubble control the type of instance to be used or do we even or do we control",
    "start": "3186240",
    "end": "3195200"
  },
  {
    "text": "it no it's totally dependent on um on the user or data admin uh depending on",
    "start": "3195200",
    "end": "3201040"
  },
  {
    "text": "the use case they would they would pick they would choose for a particular cluster to only use on demand or use a",
    "start": "3201040",
    "end": "3210359"
  },
  {
    "text": "heterogenous cluster in that you can mix and match spot and On Demand or you can",
    "start": "3210359",
    "end": "3217319"
  },
  {
    "text": "you can also have a 100% um spot inance clusters so it's it's really dependent",
    "start": "3217319",
    "end": "3223440"
  },
  {
    "text": "on on the on the user or the the organization data team that was the last",
    "start": "3223440",
    "end": "3229520"
  },
  {
    "text": "question we are hitting the hour now again all of the attendees thank you for attending the webinar today um if you",
    "start": "3229520",
    "end": "3235079"
  },
  {
    "text": "have a moment please do take time to the poll questions and we really appreciate your feedback here and again thank you",
    "start": "3235079",
    "end": "3240640"
  },
  {
    "text": "and we hope that you got to learn something today about cuble and AWS and how to use them with your big data",
    "start": "3240640",
    "end": "3246839"
  },
  {
    "text": "uploads thanks everyone",
    "start": "3246839",
    "end": "3251200"
  }
]
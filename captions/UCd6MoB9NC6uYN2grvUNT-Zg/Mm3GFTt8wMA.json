[
  {
    "text": "- Okay, so hello everyone.",
    "start": "4950",
    "end": "6720"
  },
  {
    "text": "My name is Prashant\nAgrawal and I am working",
    "start": "6720",
    "end": "8880"
  },
  {
    "text": "as an Analytics Specialist\nSolution Architect in AWS,",
    "start": "8880",
    "end": "12330"
  },
  {
    "text": "where I primarily focus on\nAmazon OpenSearch Service.",
    "start": "12330",
    "end": "15600"
  },
  {
    "text": "And today I will be talking\nabout managing time-series data",
    "start": "15600",
    "end": "18556"
  },
  {
    "text": "with data-streams using\nAmazon OpenSearch Service.",
    "start": "18556",
    "end": "22200"
  },
  {
    "text": "So, before getting into the data-streams,",
    "start": "22200",
    "end": "24810"
  },
  {
    "text": "let me explain about\nAmazon OpenSearch Service.",
    "start": "24810",
    "end": "27869"
  },
  {
    "text": "So, Amazon OpenSearch Service",
    "start": "27870",
    "end": "29400"
  },
  {
    "text": "is a fully managed\nservice that makes it easy",
    "start": "29400",
    "end": "31800"
  },
  {
    "text": "to deploy, operate and scale OpenSearch",
    "start": "31800",
    "end": "34649"
  },
  {
    "text": "along with legacy Elasticsearch\ncluster in AWS Cloud.",
    "start": "34650",
    "end": "38700"
  },
  {
    "text": "It also has tight integration\nwith other AWS services",
    "start": "38700",
    "end": "42240"
  },
  {
    "text": "such as Amazon Kinesis Data Firehose,",
    "start": "42240",
    "end": "44940"
  },
  {
    "text": "AWS Lambda, CloudWatch, and so on.",
    "start": "44940",
    "end": "47660"
  },
  {
    "text": "So let's take a quick detour",
    "start": "47660",
    "end": "50100"
  },
  {
    "text": "and talk about what is OpenSearch.",
    "start": "50100",
    "end": "52379"
  },
  {
    "text": "So OpenSearch is a community driven,",
    "start": "52380",
    "end": "54360"
  },
  {
    "text": "open source search and analytics suite",
    "start": "54360",
    "end": "56430"
  },
  {
    "text": "which is derived from Apache 2.0",
    "start": "56430",
    "end": "58530"
  },
  {
    "text": "licensed version of Elasticsearch 7.10.2",
    "start": "58530",
    "end": "61760"
  },
  {
    "text": "and Kibana 7.10.2 projects.",
    "start": "61760",
    "end": "64739"
  },
  {
    "text": "It consists of a search\nengine, which is OpenSearch",
    "start": "64740",
    "end": "67560"
  },
  {
    "text": "that provides you a way to\nperform search on your data.",
    "start": "67560",
    "end": "71100"
  },
  {
    "text": "As well as, we do analyze your logs",
    "start": "71100",
    "end": "73710"
  },
  {
    "text": "using visualization interface\ncalled OpenSearch Dashboards.",
    "start": "73710",
    "end": "77520"
  },
  {
    "text": "So using OpenSearch,",
    "start": "77520",
    "end": "78869"
  },
  {
    "text": "you can easily index the data of any type",
    "start": "78870",
    "end": "81240"
  },
  {
    "text": "such as logs, metrics and traces,",
    "start": "81240",
    "end": "84570"
  },
  {
    "text": "and then you can use\nvisualization interface",
    "start": "84570",
    "end": "86790"
  },
  {
    "text": "using the OpenSearch\nDashboard or even the API",
    "start": "86790",
    "end": "89820"
  },
  {
    "text": "to perform aggregation\non top of those data.",
    "start": "89820",
    "end": "92850"
  },
  {
    "text": "Next, we also have set up\nplugins that OpenSearch provides",
    "start": "92850",
    "end": "96119"
  },
  {
    "text": "which adds the comprehensive functionality",
    "start": "96120",
    "end": "98130"
  },
  {
    "text": "such as generating alerts on the log data",
    "start": "98130",
    "end": "100950"
  },
  {
    "text": "or look for anomalies using\nmachine learning algorithm",
    "start": "100950",
    "end": "104100"
  },
  {
    "text": "or maybe use the trace analytics",
    "start": "104100",
    "end": "106080"
  },
  {
    "text": "and the observability feature",
    "start": "106080",
    "end": "107520"
  },
  {
    "text": "to capture logs, metrics and traces,",
    "start": "107520",
    "end": "110310"
  },
  {
    "text": "and then make the code addition across",
    "start": "110310",
    "end": "112110"
  },
  {
    "text": "those logs, metrics and traces.",
    "start": "112110",
    "end": "114611"
  },
  {
    "text": "So let's jump on next and see\nwhy do we need data-stream.",
    "start": "114611",
    "end": "118593"
  },
  {
    "text": "So one of the common\nuse case with OpenSearch",
    "start": "119430",
    "end": "122390"
  },
  {
    "text": "is to index continuous\ngenerating time-series data",
    "start": "122390",
    "end": "125670"
  },
  {
    "text": "such as logs, metrics and traces.",
    "start": "125670",
    "end": "128550"
  },
  {
    "text": "Previously, automating index rollover",
    "start": "128550",
    "end": "130800"
  },
  {
    "text": "means you had to first\ncreate a write index,",
    "start": "130800",
    "end": "133500"
  },
  {
    "text": "configure a rollover alias",
    "start": "133500",
    "end": "135420"
  },
  {
    "text": "and verify that indexes are\nbeing rolled over as expected.",
    "start": "135420",
    "end": "139380"
  },
  {
    "text": "That makes your bootstrapping\nprocess for an index",
    "start": "139380",
    "end": "142320"
  },
  {
    "text": "to be more cumbersome than it needs to be.",
    "start": "142320",
    "end": "145080"
  },
  {
    "text": "So with the data-stream it is\noptimized for time-series data",
    "start": "145080",
    "end": "148560"
  },
  {
    "text": "that is primarily append only in nature",
    "start": "148560",
    "end": "150750"
  },
  {
    "text": "and simplifies all the initial\nsetup process for the data.",
    "start": "150750",
    "end": "154650"
  },
  {
    "text": "So let's see how the flow works",
    "start": "154650",
    "end": "156299"
  },
  {
    "text": "with and without data-stream.",
    "start": "156300",
    "end": "158310"
  },
  {
    "text": "So prior to data-stream,",
    "start": "158310",
    "end": "159810"
  },
  {
    "text": "this is how you user set up their indexes",
    "start": "159810",
    "end": "161970"
  },
  {
    "text": "for time-series data.",
    "start": "161970",
    "end": "163470"
  },
  {
    "text": "So they start with setting up an index",
    "start": "163470",
    "end": "165510"
  },
  {
    "text": "by specifying the index\nmapping and settings.",
    "start": "165510",
    "end": "168540"
  },
  {
    "text": "And, as their data grows,",
    "start": "168540",
    "end": "170700"
  },
  {
    "text": "they encounter the scaling\nissue with their logs and data.",
    "start": "170700",
    "end": "174239"
  },
  {
    "text": "And at that time they start thinking",
    "start": "174240",
    "end": "176040"
  },
  {
    "text": "about creating daily rotating indices",
    "start": "176040",
    "end": "178260"
  },
  {
    "text": "on the basis of dates",
    "start": "178260",
    "end": "179790"
  },
  {
    "text": "or maybe you use the Rollover API",
    "start": "179790",
    "end": "181680"
  },
  {
    "text": "to create an index for each date.",
    "start": "181680",
    "end": "183930"
  },
  {
    "text": "At this point, user has\ngot more than one indices",
    "start": "183930",
    "end": "186989"
  },
  {
    "text": "to run the search, so they\ncan either use the wildcard",
    "start": "186990",
    "end": "189853"
  },
  {
    "text": "to specify the index such as\nlogs hyphen nginx hyphen star",
    "start": "189853",
    "end": "194550"
  },
  {
    "text": "or maybe too, they can\nuse the create an alias",
    "start": "194550",
    "end": "198540"
  },
  {
    "text": "by creating the alias for\nthose time-series indices.",
    "start": "198540",
    "end": "202110"
  },
  {
    "text": "So here in the next one you can see,",
    "start": "202110",
    "end": "204450"
  },
  {
    "text": "they can define the index\nalias for all relevant index",
    "start": "204450",
    "end": "207750"
  },
  {
    "text": "to bring it under one umbrella.",
    "start": "207750",
    "end": "209910"
  },
  {
    "text": "And here, searches can be performed",
    "start": "209910",
    "end": "211980"
  },
  {
    "text": "across all the underlying\nindices on the alias.",
    "start": "211980",
    "end": "215040"
  },
  {
    "text": "But how about performing the write updates",
    "start": "215040",
    "end": "217829"
  },
  {
    "text": "and not indexing the data,",
    "start": "217830",
    "end": "219570"
  },
  {
    "text": "as in how do we determine that which index",
    "start": "219570",
    "end": "221880"
  },
  {
    "text": "would be getting the write request, right?",
    "start": "221880",
    "end": "224580"
  },
  {
    "text": "So in this case, they can solve it",
    "start": "224580",
    "end": "226950"
  },
  {
    "text": "by marking the latest\nindex as the write index",
    "start": "226950",
    "end": "230069"
  },
  {
    "text": "and this can be solved by\nbringing the common setting",
    "start": "230070",
    "end": "234150"
  },
  {
    "text": "such as the mapping index settings,",
    "start": "234150",
    "end": "236310"
  },
  {
    "text": "index patterns into an index template",
    "start": "236310",
    "end": "239310"
  },
  {
    "text": "which can be again\nconfigured on all new indices",
    "start": "239310",
    "end": "242520"
  },
  {
    "text": "getting created as a part\nof the rollover process.",
    "start": "242520",
    "end": "245580"
  },
  {
    "text": "So now, user needs to call the rollover",
    "start": "245580",
    "end": "248130"
  },
  {
    "text": "and calling it manually on daily basis",
    "start": "248130",
    "end": "250350"
  },
  {
    "text": "is not a practical solution",
    "start": "250350",
    "end": "251820"
  },
  {
    "text": "and they have to manage it by themselves.",
    "start": "251820",
    "end": "254220"
  },
  {
    "text": "So in that case,",
    "start": "254220",
    "end": "255510"
  },
  {
    "text": "they could use the Index\nState Management Policy",
    "start": "255510",
    "end": "258930"
  },
  {
    "text": "to define the index\npattern and rollover policy",
    "start": "258930",
    "end": "261539"
  },
  {
    "text": "to rollover the indices.",
    "start": "261540",
    "end": "263100"
  },
  {
    "text": "It could be done either on\nthe basis of time or the size.",
    "start": "263100",
    "end": "266910"
  },
  {
    "text": "With this legacy method,",
    "start": "266910",
    "end": "268320"
  },
  {
    "text": "user has to be aware of so many concept",
    "start": "268320",
    "end": "270930"
  },
  {
    "text": "to manage and maintain those indices",
    "start": "270930",
    "end": "273360"
  },
  {
    "text": "and they need to set up them explicitly.",
    "start": "273360",
    "end": "276060"
  },
  {
    "text": "So if you consolidate\nit, so we can see that,",
    "start": "276060",
    "end": "279393"
  },
  {
    "text": "what are the typical challenges",
    "start": "280350",
    "end": "281910"
  },
  {
    "text": "with the time-series indices.",
    "start": "281910",
    "end": "283497"
  },
  {
    "text": "So, OpenSearch has basic\nsupport of time-series data",
    "start": "283497",
    "end": "287070"
  },
  {
    "text": "where one can name indices\non the basis of timestamp",
    "start": "287070",
    "end": "290250"
  },
  {
    "text": "by prefixing it with some\nname and then suffix as time,",
    "start": "290250",
    "end": "293820"
  },
  {
    "text": "where you can have some indices",
    "start": "293820",
    "end": "295500"
  },
  {
    "text": "on the basis of day,\nweek, month, etcetera.",
    "start": "295500",
    "end": "298593"
  },
  {
    "text": "If everything is working fine",
    "start": "299490",
    "end": "300900"
  },
  {
    "text": "then why do we really need data-stream?",
    "start": "300900",
    "end": "303240"
  },
  {
    "text": "So managing your time-series indices,",
    "start": "303240",
    "end": "304530"
  },
  {
    "text": "you need to perform index rotation",
    "start": "304530",
    "end": "306990"
  },
  {
    "text": "then your log ingestion tools",
    "start": "306990",
    "end": "308400"
  },
  {
    "text": "such as Beats, logs test",
    "start": "308400",
    "end": "309780"
  },
  {
    "text": "can help you to rotate\nthose indices on dates.",
    "start": "309780",
    "end": "312360"
  },
  {
    "text": "But, what if you hit onto some event",
    "start": "312360",
    "end": "315389"
  },
  {
    "text": "such as Black Friday or Cyber Monday",
    "start": "315390",
    "end": "318120"
  },
  {
    "text": "where your data is significantly\nlarger than the usual.",
    "start": "318120",
    "end": "321120"
  },
  {
    "text": "So it creates the data's\ncube for those days",
    "start": "321120",
    "end": "323550"
  },
  {
    "text": "where you are getting a\nlarge amount of traffic.",
    "start": "323550",
    "end": "327720"
  },
  {
    "text": "So once index is rotated\nyou need to make sure",
    "start": "327720",
    "end": "330210"
  },
  {
    "text": "that the write index is pointed\nto the current date index",
    "start": "330210",
    "end": "333330"
  },
  {
    "text": "and then index alias is rollover as well.",
    "start": "333330",
    "end": "336060"
  },
  {
    "text": "So here alias is nothing\nbut a way to query",
    "start": "336060",
    "end": "338580"
  },
  {
    "text": "all the latest data which\npoints to the current",
    "start": "338580",
    "end": "340979"
  },
  {
    "text": "or latest underlying index\nfor the specific log.",
    "start": "340980",
    "end": "344790"
  },
  {
    "text": "This is why we have the data-stream",
    "start": "344790",
    "end": "347070"
  },
  {
    "text": "come into the existence.",
    "start": "347070",
    "end": "348720"
  },
  {
    "text": "So, let's see how data-stream works",
    "start": "348720",
    "end": "351660"
  },
  {
    "text": "at very high level and\nsolve some of these problems",
    "start": "351660",
    "end": "354450"
  },
  {
    "text": "being a first class citizen\nto store the time-series data.",
    "start": "354450",
    "end": "358020"
  },
  {
    "text": "So data-stream has one or more",
    "start": "358020",
    "end": "359819"
  },
  {
    "text": "auto generated backing indices",
    "start": "359820",
    "end": "361890"
  },
  {
    "text": "and prefixed by dot ds,\nthen the data-stream name",
    "start": "361890",
    "end": "365053"
  },
  {
    "text": "and the generation id.",
    "start": "365053",
    "end": "366547"
  },
  {
    "text": "So if you look here,",
    "start": "366547",
    "end": "368130"
  },
  {
    "text": "here the data-stream name\nis dot ds logs hyphen nginx.",
    "start": "368130",
    "end": "371910"
  },
  {
    "text": "Then the backing indices are like dot ds",
    "start": "371910",
    "end": "374130"
  },
  {
    "text": "hyphen logs hyphen nginx hyphen 000001",
    "start": "374130",
    "end": "378330"
  },
  {
    "text": "then 02 and 03 and so on.",
    "start": "378330",
    "end": "380733"
  },
  {
    "text": "Now coming back to the write operation,",
    "start": "381600",
    "end": "383850"
  },
  {
    "text": "so for any write operation,",
    "start": "383850",
    "end": "385560"
  },
  {
    "text": "you send the request to data-stream",
    "start": "385560",
    "end": "387690"
  },
  {
    "text": "then it will send it to the latest index.",
    "start": "387690",
    "end": "390000"
  },
  {
    "text": "Once an index is rolled,\nit will become read only",
    "start": "390000",
    "end": "392700"
  },
  {
    "text": "and you cannot add any new document",
    "start": "392700",
    "end": "394620"
  },
  {
    "text": "to the rotated index.",
    "start": "394620",
    "end": "396060"
  },
  {
    "text": "So typically in the log analytics scenario",
    "start": "396060",
    "end": "399030"
  },
  {
    "text": "there is rarely a modification.",
    "start": "399030",
    "end": "401040"
  },
  {
    "text": "And if needed, you can run update by query",
    "start": "401040",
    "end": "403640"
  },
  {
    "text": "or delete by query in the\nolder backing indices.",
    "start": "403640",
    "end": "406593"
  },
  {
    "text": "Now let's talk about the search",
    "start": "407640",
    "end": "409260"
  },
  {
    "text": "like how do we perform the read\nrequest from those indices.",
    "start": "409260",
    "end": "412650"
  },
  {
    "text": "While learning this search\nquery, data-stream routes",
    "start": "412650",
    "end": "415139"
  },
  {
    "text": "request to all the backing indices",
    "start": "415140",
    "end": "417330"
  },
  {
    "text": "and of course you can filter out the data",
    "start": "417330",
    "end": "419250"
  },
  {
    "text": "by timestamp to perform\nthe intelligent search",
    "start": "419250",
    "end": "422100"
  },
  {
    "text": "on those data sets.",
    "start": "422100",
    "end": "423420"
  },
  {
    "text": "You can also use the query\nsuch as the aggregation query",
    "start": "423420",
    "end": "427530"
  },
  {
    "text": "or maybe use the filters\nlike the Boolean filter,",
    "start": "427530",
    "end": "430230"
  },
  {
    "text": "merge clause, suit clause,\netcetera to filter out the data.",
    "start": "430230",
    "end": "434120"
  },
  {
    "text": "So this is how read and write\nworks with the data-stream.",
    "start": "434120",
    "end": "437790"
  },
  {
    "text": "So, let's talk about",
    "start": "437790",
    "end": "439710"
  },
  {
    "text": "some of the data-stream\ncaveats what we have.",
    "start": "439710",
    "end": "442350"
  },
  {
    "text": "So, because as I mentioned data-stream",
    "start": "442350",
    "end": "444480"
  },
  {
    "text": "is primarily designed\nfor the append only data.",
    "start": "444480",
    "end": "447240"
  },
  {
    "text": "So in order to create a data-stream,",
    "start": "447240",
    "end": "449190"
  },
  {
    "text": "you first need to create an index template",
    "start": "449190",
    "end": "451680"
  },
  {
    "text": "which configures a set of\nindices as a data-stream.",
    "start": "451680",
    "end": "454740"
  },
  {
    "text": "Then you need to ensure that each document",
    "start": "454740",
    "end": "456990"
  },
  {
    "text": "has a timestamp field",
    "start": "456990",
    "end": "458250"
  },
  {
    "text": "otherwise it will be added by default.",
    "start": "458250",
    "end": "460860"
  },
  {
    "text": "Then, recent data is more relevant",
    "start": "460860",
    "end": "463289"
  },
  {
    "text": "which makes it suitable for\neven the hot warm architecture",
    "start": "463290",
    "end": "466620"
  },
  {
    "text": "with respect to the\nAmazon OpenSearch service.",
    "start": "466620",
    "end": "469380"
  },
  {
    "text": "Then there are certain operations\nwhich you cannot perform",
    "start": "469380",
    "end": "472183"
  },
  {
    "text": "that will, that are termed\nas the blocked operation",
    "start": "472183",
    "end": "474960"
  },
  {
    "text": "like clone, delete, close, freeze.",
    "start": "474960",
    "end": "477870"
  },
  {
    "text": "So those kind of things\ncould not be performed",
    "start": "477870",
    "end": "480120"
  },
  {
    "text": "because these operation\ncould hinder the indexing",
    "start": "480120",
    "end": "483510"
  },
  {
    "text": "and that's why these are blocked.",
    "start": "483510",
    "end": "485373"
  },
  {
    "text": "Talking about the Ingestion API,",
    "start": "486450",
    "end": "488328"
  },
  {
    "text": "so you can run the simple API\nor you can do the bulk API,",
    "start": "488328",
    "end": "492390"
  },
  {
    "text": "but the only thing is if\nyou're running the bulk API",
    "start": "492390",
    "end": "494880"
  },
  {
    "text": "you now have to explicitly\nspecify the op type as create,",
    "start": "494880",
    "end": "498630"
  },
  {
    "text": "that is the pre requisite\nfor sending any bulk request",
    "start": "498630",
    "end": "501360"
  },
  {
    "text": "using the data-stream.",
    "start": "501360",
    "end": "503159"
  },
  {
    "text": "So let's jump into the\nworkings of data-stream",
    "start": "503160",
    "end": "505470"
  },
  {
    "text": "and see it in action with a short demo.",
    "start": "505470",
    "end": "508233"
  },
  {
    "text": "Okay, so let's see how\nit works in real world.",
    "start": "509130",
    "end": "512700"
  },
  {
    "text": "So, I have logged into\nthe OpenSearch Dashboard",
    "start": "512700",
    "end": "515940"
  },
  {
    "text": "and I'm going to create a data-stream",
    "start": "515940",
    "end": "518460"
  },
  {
    "text": "but as of now I do not\nhave any index template",
    "start": "518460",
    "end": "521820"
  },
  {
    "text": "and if you create a data-stream",
    "start": "521820",
    "end": "523110"
  },
  {
    "text": "without creating an index\ntemplate, it will error out.",
    "start": "523110",
    "end": "525839"
  },
  {
    "text": "So if you recall my\ndata-stream caveat slide",
    "start": "525840",
    "end": "528600"
  },
  {
    "text": "so in order to create it,",
    "start": "528600",
    "end": "530069"
  },
  {
    "text": "you need to create an index template",
    "start": "530070",
    "end": "531600"
  },
  {
    "text": "which configures a set of\nindices as a data-stream,",
    "start": "531600",
    "end": "534474"
  },
  {
    "text": "and data-stream object indicates\nthat it's a data-stream",
    "start": "534474",
    "end": "537780"
  },
  {
    "text": "and not the regular index template.",
    "start": "537780",
    "end": "539670"
  },
  {
    "text": "And then the index pattern matches",
    "start": "539670",
    "end": "541380"
  },
  {
    "text": "with the name of the\ndata-stream over here.",
    "start": "541380",
    "end": "544140"
  },
  {
    "text": "So in this case, if I'm going\nto create an data-stream,",
    "start": "544140",
    "end": "547819"
  },
  {
    "text": "it is giving me an error",
    "start": "547819",
    "end": "550350"
  },
  {
    "text": "like no matching index template found",
    "start": "550350",
    "end": "552029"
  },
  {
    "text": "for this particular data-stream,",
    "start": "552030",
    "end": "553320"
  },
  {
    "text": "so, now I'm going to\ncreate the index template",
    "start": "553320",
    "end": "555960"
  },
  {
    "text": "by specifying the index\npattern as logs hyphen nginx.",
    "start": "555960",
    "end": "559458"
  },
  {
    "text": "And then I have the\nnumber of shards as one",
    "start": "559458",
    "end": "561480"
  },
  {
    "text": "and number of replica as one.",
    "start": "561480",
    "end": "563100"
  },
  {
    "text": "Then I have the timestamp\nfield as @timestamp.",
    "start": "563100",
    "end": "566519"
  },
  {
    "text": "Now I have created an index template.",
    "start": "566520",
    "end": "569070"
  },
  {
    "text": "Let's verify",
    "start": "569070",
    "end": "570150"
  },
  {
    "text": "whether I have the current\nindex template or not.",
    "start": "570150",
    "end": "572580"
  },
  {
    "text": "So, on running the GET\nindex template logs nginx,",
    "start": "572580",
    "end": "576000"
  },
  {
    "text": "you can see the index template details",
    "start": "576000",
    "end": "578040"
  },
  {
    "text": "like the index patterns, name,",
    "start": "578040",
    "end": "579720"
  },
  {
    "text": "number of shards, replica\nof what we have configured.",
    "start": "579720",
    "end": "582452"
  },
  {
    "text": "So let's move on and then\ncreate the data-stream now.",
    "start": "583380",
    "end": "587010"
  },
  {
    "text": "So in this, basically when\nyou create the data-stream,",
    "start": "587010",
    "end": "592010"
  },
  {
    "text": "so you can use the data-stream\nAPI to explicitly create it",
    "start": "592260",
    "end": "596520"
  },
  {
    "text": "or even like data-stream will initialize",
    "start": "596520",
    "end": "599250"
  },
  {
    "text": "as soon as you send the\nfirst document to the index",
    "start": "599250",
    "end": "602250"
  },
  {
    "text": "which is matching the index pattern name.",
    "start": "602250",
    "end": "605190"
  },
  {
    "text": "So here I'm creating the\ndata-stream explicitly",
    "start": "605190",
    "end": "608430"
  },
  {
    "text": "by running this command and it\ngives me the acknowledge too",
    "start": "608430",
    "end": "611100"
  },
  {
    "text": "that means data-stream has been created.",
    "start": "611100",
    "end": "613680"
  },
  {
    "text": "You can verify the data-stream\nand associated index",
    "start": "613680",
    "end": "616710"
  },
  {
    "text": "by running the GET\ndata-stream logs hyphen nginx.",
    "start": "616710",
    "end": "620430"
  },
  {
    "text": "In this case, it returns me\nthe name of the data-stream,",
    "start": "620430",
    "end": "623307"
  },
  {
    "text": "the timestamp field and\nwhat is the backing indices",
    "start": "623307",
    "end": "626370"
  },
  {
    "text": "for this particular data-stream,",
    "start": "626370",
    "end": "628410"
  },
  {
    "text": "and then what is the\ngeneration, what is the status",
    "start": "628410",
    "end": "630959"
  },
  {
    "text": "and the template behind\nthis particular data-stream.",
    "start": "630960",
    "end": "634050"
  },
  {
    "text": "Now let's start into sending",
    "start": "634050",
    "end": "636330"
  },
  {
    "text": "or writing the data into the data-stream.",
    "start": "636330",
    "end": "639240"
  },
  {
    "text": "So here,",
    "start": "639240",
    "end": "640412"
  },
  {
    "text": "in order to ingest data into data-stream",
    "start": "641520",
    "end": "643320"
  },
  {
    "text": "you can use the regular indexing API,",
    "start": "643320",
    "end": "646080"
  },
  {
    "text": "for example over here,",
    "start": "646080",
    "end": "648540"
  },
  {
    "text": "I'm writing the POST logs hyphen nginx",
    "start": "648540",
    "end": "651480"
  },
  {
    "text": "which is my data-stream name,",
    "start": "651480",
    "end": "652949"
  },
  {
    "text": "then I have a body where I\nhave a couple of like message",
    "start": "652950",
    "end": "656130"
  },
  {
    "text": "and @timestamp.",
    "start": "656130",
    "end": "657990"
  },
  {
    "text": "So as I mentioned earlier",
    "start": "657990",
    "end": "659100"
  },
  {
    "text": "you need to have the timestamp field",
    "start": "659100",
    "end": "660446"
  },
  {
    "text": "otherwise it will give me an error.",
    "start": "660447",
    "end": "662520"
  },
  {
    "text": "So, after you run this particular command",
    "start": "662520",
    "end": "665970"
  },
  {
    "text": "your data is being indexed",
    "start": "665970",
    "end": "667620"
  },
  {
    "text": "and your document has been created",
    "start": "667620",
    "end": "669390"
  },
  {
    "text": "onto the data-stream\nwith the backing indices",
    "start": "669390",
    "end": "672180"
  },
  {
    "text": "as ds logs nginx 00001.",
    "start": "672180",
    "end": "675690"
  },
  {
    "text": "Apart from sending the individual request",
    "start": "675690",
    "end": "677910"
  },
  {
    "text": "you can also send the\nbulk API request as well",
    "start": "677910",
    "end": "681389"
  },
  {
    "text": "in order to ingest data\ninto the data-stream.",
    "start": "681390",
    "end": "683760"
  },
  {
    "text": "The only thing is you need\nto have the operation type",
    "start": "683760",
    "end": "686490"
  },
  {
    "text": "as create when you are\nsending any bulk request.",
    "start": "686490",
    "end": "689520"
  },
  {
    "text": "Now if I run this command,\nit inserts two document",
    "start": "689520",
    "end": "692880"
  },
  {
    "text": "where I have these two documents\ninto my bulk API as well,",
    "start": "692880",
    "end": "697140"
  },
  {
    "text": "one with the message 'login success'",
    "start": "697140",
    "end": "698940"
  },
  {
    "text": "and another one as the\nmessage 'login failed'.",
    "start": "698940",
    "end": "702630"
  },
  {
    "text": "Let's see how the search works",
    "start": "702630",
    "end": "706110"
  },
  {
    "text": "and how you can perform\nsearching the data-stream",
    "start": "706110",
    "end": "709860"
  },
  {
    "text": "and get all the documents\nfrom that stream.",
    "start": "709860",
    "end": "712500"
  },
  {
    "text": "So you can do a simple search request",
    "start": "712500",
    "end": "716100"
  },
  {
    "text": "like GET your data-stream name",
    "start": "716100",
    "end": "719190"
  },
  {
    "text": "followed by the underscore search API.",
    "start": "719190",
    "end": "721470"
  },
  {
    "text": "It will return you all the data",
    "start": "721470",
    "end": "723060"
  },
  {
    "text": "for that particular data-stream.",
    "start": "723060",
    "end": "725100"
  },
  {
    "text": "So I have inserted three documents on it",
    "start": "725100",
    "end": "727380"
  },
  {
    "text": "so you can see one is\nwith 'login attempt',",
    "start": "727380",
    "end": "729660"
  },
  {
    "text": "one is the 'login success',",
    "start": "729660",
    "end": "730889"
  },
  {
    "text": "and another one is the 'login failed'.",
    "start": "730890",
    "end": "732720"
  },
  {
    "text": "So this way you canceled the\ndata from the data-stream",
    "start": "732720",
    "end": "736920"
  },
  {
    "text": "and you can further use\nthe Query DSL as well",
    "start": "736920",
    "end": "739444"
  },
  {
    "text": "to run advance query such as\nthe bool query with filter",
    "start": "739444",
    "end": "742496"
  },
  {
    "text": "for running aggregations and\nwhat not using the data-stream.",
    "start": "742497",
    "end": "746310"
  },
  {
    "text": "Next talk about how you\ncan perform the rollover",
    "start": "746310",
    "end": "749160"
  },
  {
    "text": "onto the data-stream.",
    "start": "749160",
    "end": "750209"
  },
  {
    "text": "So you can use the ISM Policy",
    "start": "750210",
    "end": "752940"
  },
  {
    "text": "in order to define the rollover policy",
    "start": "752940",
    "end": "754710"
  },
  {
    "text": "on the basis of size or maybe\non the basis of the date-time.",
    "start": "754710",
    "end": "758280"
  },
  {
    "text": "Apart from that you can\nalso run the manual command",
    "start": "758280",
    "end": "760980"
  },
  {
    "text": "to rollover the data-stream",
    "start": "760980",
    "end": "762720"
  },
  {
    "text": "by running the command as POST API",
    "start": "762720",
    "end": "765420"
  },
  {
    "text": "with your data-stream name\nfollowed by underscore rollover.",
    "start": "765420",
    "end": "768930"
  },
  {
    "text": "Once you run this command,\nit will give you the details",
    "start": "768930",
    "end": "771570"
  },
  {
    "text": "about your old index and the new index.",
    "start": "771570",
    "end": "774090"
  },
  {
    "text": "So now your old index has\ngone into the read only mode,",
    "start": "774090",
    "end": "777000"
  },
  {
    "text": "you cannot perform any\nwrite operation on this,",
    "start": "777000",
    "end": "779460"
  },
  {
    "text": "and all of the data what\nyou are going to send,",
    "start": "779460",
    "end": "781590"
  },
  {
    "text": "it will be sent to the new index",
    "start": "781590",
    "end": "783150"
  },
  {
    "text": "which is the ds logs nginx 000002.",
    "start": "783150",
    "end": "785437"
  },
  {
    "text": "You can verify the\nrollover operation as well",
    "start": "787830",
    "end": "790530"
  },
  {
    "text": "by running the GET\ndata-stream logs hyphen nginx",
    "start": "790530",
    "end": "794460"
  },
  {
    "text": "and here we have the generation two",
    "start": "794460",
    "end": "796590"
  },
  {
    "text": "means it has been rolled over,",
    "start": "796590",
    "end": "798600"
  },
  {
    "text": "this the second generation\nof the data-stream.",
    "start": "798600",
    "end": "801779"
  },
  {
    "text": "And then it has the details\nof your timestamp field",
    "start": "801780",
    "end": "804780"
  },
  {
    "text": "and then all the indices.",
    "start": "804780",
    "end": "806313"
  },
  {
    "text": "Next, we can talk about",
    "start": "807210",
    "end": "810000"
  },
  {
    "text": "whether we can delete\nthe write index or not.",
    "start": "810000",
    "end": "812220"
  },
  {
    "text": "So, if you run the command\nto delete the write index",
    "start": "812220",
    "end": "815910"
  },
  {
    "text": "which is the 02 as of now,",
    "start": "815910",
    "end": "818190"
  },
  {
    "text": "it will error out because\nyou cannot perform",
    "start": "818190",
    "end": "820770"
  },
  {
    "text": "the delete operation on the write index.",
    "start": "820770",
    "end": "823620"
  },
  {
    "text": "So if you have to delete the write index",
    "start": "823620",
    "end": "826170"
  },
  {
    "text": "then you have to delete the index template",
    "start": "826170",
    "end": "828660"
  },
  {
    "text": "and then you have to\ndelete the data-stream.",
    "start": "828660",
    "end": "831149"
  },
  {
    "text": "So before showing you the delete command",
    "start": "831150",
    "end": "833580"
  },
  {
    "text": "let me quickly go to the\nindex management page",
    "start": "833580",
    "end": "837690"
  },
  {
    "text": "and there we can search for\nall the indices what we have.",
    "start": "837690",
    "end": "841920"
  },
  {
    "text": "So go to the indices tab,\nshow the data-stream indices",
    "start": "841920",
    "end": "845399"
  },
  {
    "text": "then you can select the data-stream.",
    "start": "845400",
    "end": "847500"
  },
  {
    "text": "So here I have two data, two\nindices on the data-stream",
    "start": "847500",
    "end": "850680"
  },
  {
    "text": "logs hyphen nginx 000001 and 02",
    "start": "850680",
    "end": "854820"
  },
  {
    "text": "and you can see I have\nthree documents on the 01",
    "start": "854820",
    "end": "857010"
  },
  {
    "text": "and there is no documents on 02",
    "start": "857010",
    "end": "858810"
  },
  {
    "text": "because we haven't run any Ingestion API",
    "start": "858810",
    "end": "861668"
  },
  {
    "text": "to ingest the data after the rollover.",
    "start": "861668",
    "end": "863453"
  },
  {
    "text": "Now let's move to the command again",
    "start": "864420",
    "end": "867240"
  },
  {
    "text": "and how you can perform the delete.",
    "start": "867240",
    "end": "870060"
  },
  {
    "text": "So now if you go and try\nto delete the data-stream",
    "start": "870060",
    "end": "873845"
  },
  {
    "text": "it will delete everything\nand if you go to,",
    "start": "873845",
    "end": "878553"
  },
  {
    "text": "fetch the data-stream over here",
    "start": "880650",
    "end": "883410"
  },
  {
    "text": "like perform any search,",
    "start": "883410",
    "end": "885089"
  },
  {
    "text": "so it will say like no index was found",
    "start": "885090",
    "end": "887400"
  },
  {
    "text": "because we have deleted the data-stream.",
    "start": "887400",
    "end": "889920"
  },
  {
    "text": "So once you delete the data-stream",
    "start": "889920",
    "end": "891810"
  },
  {
    "text": "it will delete all the indices\nor all the backing indices",
    "start": "891810",
    "end": "895230"
  },
  {
    "text": "as well the write indices from\nthat particular data-stream.",
    "start": "895230",
    "end": "898352"
  },
  {
    "text": "So this is all about a quick\ndemo about the data-stream",
    "start": "899340",
    "end": "902430"
  },
  {
    "text": "and let's get back onto the deck",
    "start": "902430",
    "end": "904440"
  },
  {
    "text": "and then we can talk\nabout what we discussed",
    "start": "904440",
    "end": "908430"
  },
  {
    "text": "as a part of the demo.",
    "start": "908430",
    "end": "909540"
  },
  {
    "text": "So I will show all the script\nover there in the form of deck",
    "start": "909540",
    "end": "912930"
  },
  {
    "text": "and followed by couple of documents",
    "start": "912930",
    "end": "916140"
  },
  {
    "text": "like how you can get\nstarted with the data-stream",
    "start": "916140",
    "end": "918900"
  },
  {
    "text": "and then what should be the next step",
    "start": "918900",
    "end": "921000"
  },
  {
    "text": "or the next action on that.",
    "start": "921000",
    "end": "922590"
  },
  {
    "text": "Thank you.",
    "start": "922590",
    "end": "923423"
  },
  {
    "text": "So in the demo we have seen",
    "start": "924360",
    "end": "926160"
  },
  {
    "text": "how you could create a data-stream,",
    "start": "926160",
    "end": "928199"
  },
  {
    "text": "without creating an index\ntemplate, it will error out.",
    "start": "928200",
    "end": "930690"
  },
  {
    "text": "So if you recall the data-stream caveats,",
    "start": "930690",
    "end": "932880"
  },
  {
    "text": "in order to create a data-stream",
    "start": "932880",
    "end": "934020"
  },
  {
    "text": "you first need to create an index template",
    "start": "934020",
    "end": "936300"
  },
  {
    "text": "and this shows like how you\ncan create the index template,",
    "start": "936300",
    "end": "938790"
  },
  {
    "text": "you can refer this script for\ncreating the index template.",
    "start": "938790",
    "end": "942029"
  },
  {
    "text": "Once we have created the index template,",
    "start": "942030",
    "end": "944820"
  },
  {
    "text": "you can verify those\nby running the GET API",
    "start": "944820",
    "end": "947760"
  },
  {
    "text": "to make sure your index\ntemplate is created.",
    "start": "947760",
    "end": "950640"
  },
  {
    "text": "Then after you have\ncreated an index template,",
    "start": "950640",
    "end": "952860"
  },
  {
    "text": "you can create a data-stream",
    "start": "952860",
    "end": "954570"
  },
  {
    "text": "where you can use the data-stream API",
    "start": "954570",
    "end": "956517"
  },
  {
    "text": "to explicitly create a data-stream.",
    "start": "956517",
    "end": "958380"
  },
  {
    "text": "If you're not creating it explicitly",
    "start": "958380",
    "end": "960510"
  },
  {
    "text": "then as soon as you\nsend the first document,",
    "start": "960510",
    "end": "962460"
  },
  {
    "text": "it will create the data-stream.",
    "start": "962460",
    "end": "964830"
  },
  {
    "text": "Talking about the ingestion,",
    "start": "964830",
    "end": "966360"
  },
  {
    "text": "you can send the individual\nrequest as this one",
    "start": "966360",
    "end": "969120"
  },
  {
    "text": "or you can refer the demo\nwhich I showed just now",
    "start": "969120",
    "end": "971910"
  },
  {
    "text": "where you can send the\nbulk request as well",
    "start": "971910",
    "end": "974279"
  },
  {
    "text": "with the op type as create.",
    "start": "974280",
    "end": "976590"
  },
  {
    "text": "Then last but not the least,",
    "start": "976590",
    "end": "977940"
  },
  {
    "text": "you can run the search request",
    "start": "977940",
    "end": "979830"
  },
  {
    "text": "using the GET data-stream\nname slash underscore search.",
    "start": "979830",
    "end": "983430"
  },
  {
    "text": "It will give you the top twenty documents",
    "start": "983430",
    "end": "985440"
  },
  {
    "text": "for that particular data-stream",
    "start": "985440",
    "end": "987480"
  },
  {
    "text": "and then you can further use the Query DSL",
    "start": "987480",
    "end": "989941"
  },
  {
    "text": "to run advanced queries",
    "start": "989941",
    "end": "991199"
  },
  {
    "text": "such as using the bool query with filters,",
    "start": "991200",
    "end": "993780"
  },
  {
    "text": "running aggregates and send what not.",
    "start": "993780",
    "end": "996240"
  },
  {
    "text": "Lastly we saw in the demo how\nyou can manage those indices",
    "start": "996240",
    "end": "999325"
  },
  {
    "text": "and data-stream from OpenSearch Dashboard,",
    "start": "999325",
    "end": "1001520"
  },
  {
    "text": "where you can go to the index management,",
    "start": "1001520",
    "end": "1003380"
  },
  {
    "text": "filter the data for the data-streams",
    "start": "1003380",
    "end": "1005840"
  },
  {
    "text": "and then it will list down\nall the backing indices",
    "start": "1005840",
    "end": "1008570"
  },
  {
    "text": "for a particular data-stream.",
    "start": "1008570",
    "end": "1010730"
  },
  {
    "text": "So that's what we covered as part of demo.",
    "start": "1010730",
    "end": "1013850"
  },
  {
    "text": "So coming back to the conclusion,",
    "start": "1013850",
    "end": "1016100"
  },
  {
    "text": "so in a nutshell, data-stream helps you",
    "start": "1016100",
    "end": "1018470"
  },
  {
    "text": "to intelligently manage\nthe time-series data",
    "start": "1018470",
    "end": "1021410"
  },
  {
    "text": "where developer or operation team",
    "start": "1021410",
    "end": "1023120"
  },
  {
    "text": "can perform focus on the development",
    "start": "1023120",
    "end": "1025100"
  },
  {
    "text": "and growing their business",
    "start": "1025100",
    "end": "1026630"
  },
  {
    "text": "rather than spending\ntime on management tasks",
    "start": "1026630",
    "end": "1029000"
  },
  {
    "text": "such as managing time-series indices,",
    "start": "1029000",
    "end": "1031189"
  },
  {
    "text": "performing the rollover and so on.",
    "start": "1031190",
    "end": "1033082"
  },
  {
    "text": "So this concludes a quick overview",
    "start": "1034610",
    "end": "1036380"
  },
  {
    "text": "of data-stream along with a demo.",
    "start": "1036380",
    "end": "1038360"
  },
  {
    "text": "If you would like to know\nmore about data-stream,",
    "start": "1038360",
    "end": "1040339"
  },
  {
    "text": "please check out our documentation",
    "start": "1040340",
    "end": "1042169"
  },
  {
    "text": "which you can get from the\nQR code that's on here.",
    "start": "1042170",
    "end": "1044990"
  },
  {
    "text": "So thank you for listening",
    "start": "1044990",
    "end": "1046459"
  },
  {
    "text": "and feel free to reach out to us",
    "start": "1046460",
    "end": "1047839"
  },
  {
    "text": "if you have any further questions.",
    "start": "1047840",
    "end": "1049520"
  },
  {
    "text": "Thank you.",
    "start": "1049520",
    "end": "1050353"
  }
]
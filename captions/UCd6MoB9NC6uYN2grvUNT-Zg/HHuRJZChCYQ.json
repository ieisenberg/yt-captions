[
  {
    "text": "hello again my name is Ryan and I'm a technical evangelist at Amazon web services and today's webinar is a master",
    "start": "240",
    "end": "6359"
  },
  {
    "text": "class on S3 so the idea behind these master classes is that it's a technical",
    "start": "6359",
    "end": "11639"
  },
  {
    "text": "Deep dive on a particular service um we're going to show you how things work and how to get started on",
    "start": "11639",
    "end": "18359"
  },
  {
    "text": "various aspects that you may not uh be familiar with just by browsing or coming",
    "start": "18359",
    "end": "23439"
  },
  {
    "text": "across a service for the first time the idea being in 45 minutes we can broaden your knowledge with a quick Deep dive so",
    "start": "23439",
    "end": "30199"
  },
  {
    "text": "today's subject is Amazon S3 and really the theme is that this is more than just",
    "start": "30199",
    "end": "35200"
  },
  {
    "text": "a simple storage Service as the name implies it is a sophisticated what we'd",
    "start": "35200",
    "end": "40520"
  },
  {
    "text": "call a 21st century distributed architecture behind the scenes it's a highly sophisticated application that",
    "start": "40520",
    "end": "47199"
  },
  {
    "text": "ensures that your data is held with 11 NES of durability and we'll go into how that works and how you can leverage that",
    "start": "47199",
    "end": "53239"
  },
  {
    "text": "throughout this webinar and it's a Bedrock architectural component for many applications once you start using S3 for",
    "start": "53239",
    "end": "59480"
  },
  {
    "text": "storage of all sorts of different Assets in your applications or your media applications you'll find that you never",
    "start": "59480",
    "end": "65320"
  },
  {
    "text": "want to go away from it so let's go down into some detail then on on S3 and the",
    "start": "65320",
    "end": "71119"
  },
  {
    "text": "first thing is that of course S3 is used by many many of our customers as a Bedrock application component as I said",
    "start": "71119",
    "end": "78200"
  },
  {
    "text": "one of the great examples is Spotify and I'm sure that in our personal lives and maybe where we're around our desks",
    "start": "78200",
    "end": "83600"
  },
  {
    "text": "working away with our headphones on we may stream music from Spotify now Spotify their assets are stored in S3",
    "start": "83600",
    "end": "91200"
  },
  {
    "text": "and their operations director really talks about the ability for Spotify to scale to remove the constraints on their",
    "start": "91200",
    "end": "98079"
  },
  {
    "text": "storage not have to do capacity planning on what they would call the most mature large scale storage platform available",
    "start": "98079",
    "end": "105159"
  },
  {
    "text": "today so there are other examples if you use dropbox Dropbox again is backed by",
    "start": "105159",
    "end": "110320"
  },
  {
    "text": "S3 and many many applications use S3 in different ways whether it be for delivering of media static content via",
    "start": "110320",
    "end": "117560"
  },
  {
    "text": "cloudfront whether it be simply for holding internal assets like code or bootstrapping scripts um they'll be",
    "start": "117560",
    "end": "123759"
  },
  {
    "text": "using S3 all over the place and we're going to go down then into some of the use cases and some of the technical",
    "start": "123759",
    "end": "129640"
  },
  {
    "text": "features that enable you to do great things with S3",
    "start": "129640",
    "end": "135080"
  },
  {
    "text": "today so the idea being really and if you look at what Spotify do is they put stuff in S3 and we store it with what we",
    "start": "135400",
    "end": "142040"
  },
  {
    "text": "call 11 nines of durability so durability being uh the probability of loss of data over a given time period so",
    "start": "142040",
    "end": "149360"
  },
  {
    "text": "that's significant um technical infrastructure behind the scenes to make that happen because we have a highly",
    "start": "149360",
    "end": "154879"
  },
  {
    "text": "scalable web access to your object so you can retrieve your objects at extremely high volumes and rates when",
    "start": "154879",
    "end": "161400"
  },
  {
    "text": "you put things into S3 and that we're storing those in multiple redundant copies in a region behind the",
    "start": "161400",
    "end": "168560"
  },
  {
    "text": "scenes but it's more than just a simple storage service so looking at um the",
    "start": "168560",
    "end": "175000"
  },
  {
    "text": "objects that we have in S3 today we just passed 1.3 trillion objects in storage",
    "start": "175000",
    "end": "180959"
  },
  {
    "text": "within the S3 platform and bear in mind that an object can be 1 by to 5 terabytes in size we're not talking",
    "start": "180959",
    "end": "187040"
  },
  {
    "text": "about small volumes here there are significant volumes of data and at Peak we're pushing 835,000 transactions per",
    "start": "187040",
    "end": "194440"
  },
  {
    "text": "second reading or writing data from S3 and if you think about how it works and as I explain in a moment multiple",
    "start": "194440",
    "end": "200720"
  },
  {
    "text": "redundant copies those transactions fan out behind the scenes because we're storing things multiple times creating",
    "start": "200720",
    "end": "207280"
  },
  {
    "text": "multiple copies of indexes behind the scenes to ensure that we achieve that 11 lines of",
    "start": "207280",
    "end": "212959"
  },
  {
    "text": "durability so what is S3 okay it's a web store not a file system and I think",
    "start": "212959",
    "end": "218640"
  },
  {
    "text": "that'll become apparent as we look through the technical detail as we go through this webinar it's highly scalable data storage you don't have any",
    "start": "218640",
    "end": "225519"
  },
  {
    "text": "constraints on what you can store you can store as much as you like it's fast it's web sess speeds it's economical you",
    "start": "225519",
    "end": "231640"
  },
  {
    "text": "only pay for what you use and it's highly available and durable in terms of the storage platform behind the scenes",
    "start": "231640",
    "end": "237360"
  },
  {
    "text": "and of course as everything we do is accessible VI the apis and we're going to look at some of those apis today in",
    "start": "237360",
    "end": "243000"
  },
  {
    "text": "this webinar but one of the things we need to drill down into really to understand how S3 Works behind the scenes is this thing",
    "start": "243000",
    "end": "249840"
  },
  {
    "text": "that it's a web store not a file system and it's a right once read many platform",
    "start": "249840",
    "end": "255239"
  },
  {
    "text": "so the idea being is that you can can of course there are plugins out there enable you to mount S3 as a file system",
    "start": "255239",
    "end": "260959"
  },
  {
    "text": "but it's not designed to work in that way it's not a block storage device it's an object storage device and it has an",
    "start": "260959",
    "end": "266800"
  },
  {
    "text": "eventually consistent data model behind the scenes so let's look at how it",
    "start": "266800",
    "end": "272000"
  },
  {
    "text": "works when you look at S3 S3 is made up of various components spread across a",
    "start": "272000",
    "end": "278720"
  },
  {
    "text": "region and the availability zones within an Amazon region so availability zones",
    "start": "278720",
    "end": "284160"
  },
  {
    "text": "being physically distinct data centers or collections of data centers so when we make a request to S3 we're going for",
    "start": "284160",
    "end": "291240"
  },
  {
    "text": "a lad balanced infrastructure hitting S3 web server fleets and ultimately putting",
    "start": "291240",
    "end": "297120"
  },
  {
    "text": "hitting some storage subsystem to read rights and data and the storage subsystem when we write to that will",
    "start": "297120",
    "end": "303759"
  },
  {
    "text": "then make multiple copies within availability Zone but also across a region into alternative availability",
    "start": "303759",
    "end": "310160"
  },
  {
    "text": "zones shown here is two but there can be more than two availability zones depending on what region you're looking",
    "start": "310160",
    "end": "315680"
  },
  {
    "text": "at once we've written data we then write an index and in a similar way we write",
    "start": "315680",
    "end": "320720"
  },
  {
    "text": "to an index within an availability Zone and we make multiple copies of that index and then we copy those indexes",
    "start": "320720",
    "end": "327160"
  },
  {
    "text": "across the region into other availability zones so it's by this multiple copies and",
    "start": "327160",
    "end": "332199"
  },
  {
    "text": "multiple redundant versions of the data that we achieve the high durability now the storage subsystem has constant check",
    "start": "332199",
    "end": "339039"
  },
  {
    "text": "summing of these copies to ensure that they're held with Integrity now when something fails and",
    "start": "339039",
    "end": "345960"
  },
  {
    "text": "that could be in the low balancing web server tier indexing or storage then we seamlessly root your requests to",
    "start": "345960",
    "end": "352520"
  },
  {
    "text": "available infrastructure and available copies of your index and your storage and likewise if we were to lose a whole",
    "start": "352520",
    "end": "359319"
  },
  {
    "text": "available a ability Zone again your requests are swapped to the copies in the availability Zone that's still",
    "start": "359319",
    "end": "364759"
  },
  {
    "text": "working so it's these mechanisms and this is of course a logical conceptual diagram that achieve 11 lines of",
    "start": "364759",
    "end": "371520"
  },
  {
    "text": "durability but because we're writing multiple copies then there is a consistency model behind the scenes that",
    "start": "371520",
    "end": "377400"
  },
  {
    "text": "you should be aware of so looking at the eventually consistent model um three things when we",
    "start": "377400",
    "end": "384759"
  },
  {
    "text": "write new objects we will synchronously store your data across multiple facilities before returning success so",
    "start": "384759",
    "end": "392360"
  },
  {
    "text": "when you're writing an object aresh you achieve what we call read after write consistency as a general rule wherever",
    "start": "392360",
    "end": "399120"
  },
  {
    "text": "you write S3 you'll get read after write consistency on new objects so you can be sure that when you've written an object",
    "start": "399120",
    "end": "404919"
  },
  {
    "text": "you then retrieve the object you'll get that object back now where we differ then is when we update and then perform",
    "start": "404919",
    "end": "411599"
  },
  {
    "text": "deletes against objects so an update you'll have an eventually consistent model and same with deletes so depending",
    "start": "411599",
    "end": "418720"
  },
  {
    "text": "on your operation if you're writing then you're reading you could report keys that don't exist Keys being objects um",
    "start": "418720",
    "end": "426400"
  },
  {
    "text": "you might retre return an old key for example um and deletes deletes then reads you could still get old data now",
    "start": "426400",
    "end": "433599"
  },
  {
    "text": "depending upon the size of the object you WR you might have a more or less lag within that now for most off operations",
    "start": "433599",
    "end": "440599"
  },
  {
    "text": "and and use cases this won't impact you but you should be aware that you have an eventually consistent model for updates",
    "start": "440599",
    "end": "446440"
  },
  {
    "text": "and deletes to objects with an S3 now talking about regions it is a regional service so you data will never",
    "start": "446440",
    "end": "453919"
  },
  {
    "text": "leave a region unless you choose to move it so our regions aren't connected we don't spread copies of data around",
    "start": "453919",
    "end": "460759"
  },
  {
    "text": "different regions around the world to achieve those 11 lines of durability they're all achieved um within uh an",
    "start": "460759",
    "end": "467919"
  },
  {
    "text": "availability Zone within a region now then diving down into the technical depth then when you store",
    "start": "467919",
    "end": "474520"
  },
  {
    "text": "something in S3 there are three storage classes and storage classes are a way that you control the way in which S3",
    "start": "474520",
    "end": "481000"
  },
  {
    "text": "holds your data on your behalf so the first of those storage classes is what we'd call standard and this is the",
    "start": "481000",
    "end": "487000"
  },
  {
    "text": "default so when you pop something into S3 it will be stored in a standard storage class mode where we achieve 11",
    "start": "487000",
    "end": "494599"
  },
  {
    "text": "lines of durability designed to sustain the concurrent loss of two of data in two",
    "start": "494599",
    "end": "500319"
  },
  {
    "text": "facilities okay so this is where we're making the maximum number of copies of your data and doing all the check",
    "start": "500319",
    "end": "505639"
  },
  {
    "text": "summing around that data to ensure Integrity of that data and that comes of a certain price that you can find on the",
    "start": "505639",
    "end": "511320"
  },
  {
    "text": "website but there is an alternative storage class called reduced redundancy storage or RRS and effectively what",
    "start": "511320",
    "end": "518360"
  },
  {
    "text": "we're doing is making less copies of your data and it's a lower number of nines and durability four nines of",
    "start": "518360",
    "end": "524680"
  },
  {
    "text": "durability and designed to sustain the loss of data in a single facility so you can see that we're",
    "start": "524680",
    "end": "531360"
  },
  {
    "text": "making less copies we have to do less work and as a result the reduced redundancy storage comes at a lower",
    "start": "531360",
    "end": "537040"
  },
  {
    "text": "price point now there is a a third storage class called glassier which is a new",
    "start": "537040",
    "end": "542399"
  },
  {
    "text": "storage class for rest Tre and we'll look into how we we use glassier storage behind the scenes later but this is",
    "start": "542399",
    "end": "547720"
  },
  {
    "text": "where we can put things into long-term Cold Storage so it uses a very lowcost",
    "start": "547720",
    "end": "553519"
  },
  {
    "text": "storage sub platform within S3 um but you can access these objects through the S3 apis the idea being is that you won't",
    "start": "553519",
    "end": "561640"
  },
  {
    "text": "retrieve these objects very often so you can put them into long storage at a very low price point and you'll only really",
    "start": "561640",
    "end": "567320"
  },
  {
    "text": "pay when you retrieve that data so some ways in which you might use the three storage uh classes is that You' have",
    "start": "567320",
    "end": "573959"
  },
  {
    "text": "objects that you want to have a high durability in standard mode so this might be a master copy of movie media",
    "start": "573959",
    "end": "580240"
  },
  {
    "text": "for example you then might move different encodings of that movie different formats into reduce redundancy",
    "start": "580240",
    "end": "586360"
  },
  {
    "text": "storage because ultimately if you lost one you could recreate it and you can afford to lose it therefore and then in",
    "start": "586360",
    "end": "592320"
  },
  {
    "text": "glassier you might then take a digital Archive of old movie or broadcasts that you very rarely want to access but you",
    "start": "592320",
    "end": "598079"
  },
  {
    "text": "want to preserve for the future in case you ever need to so three storage",
    "start": "598079",
    "end": "604600"
  },
  {
    "text": "classes next up in terms of understanding how S3 works is name spaces and name spaces around the the",
    "start": "604600",
    "end": "610760"
  },
  {
    "text": "names that you give to objects buckets that you store objects in and keys so the S3 namespace is globally",
    "start": "610760",
    "end": "619040"
  },
  {
    "text": "unique so the bucket if you like the folder or container of your objects plus the object name and this is also know as",
    "start": "619040",
    "end": "625720"
  },
  {
    "text": "a key in S3 has to be globally unique so the the first thing is when you create a bucket we'll make a check to see if that",
    "start": "625720",
    "end": "632760"
  },
  {
    "text": "bucket name is available now bucket names can be anything you like really and sometimes people would uh use uh",
    "start": "632760",
    "end": "639480"
  },
  {
    "text": "random generators to name their buckets or they'll m match their bucket names to",
    "start": "639480",
    "end": "644839"
  },
  {
    "text": "things like their domain names and we'll come on to to that mode of operation when we look at static website",
    "start": "644839",
    "end": "651120"
  },
  {
    "text": "serving so if you look at the name space Amazon S3 Global Nam space at the top and then we have buckets and then within",
    "start": "651120",
    "end": "657800"
  },
  {
    "text": "those buckets we have objects in green so if you think about you being mixed up with every other customer on the",
    "start": "657800",
    "end": "663680"
  },
  {
    "text": "platform you might have people using S3 on the left as a simple bucket to to share some documents with colleagues",
    "start": "663680",
    "end": "670240"
  },
  {
    "text": "they might have in there you know um some photos or some Word documents and on the right we've got subdomain uh as a",
    "start": "670240",
    "end": "677320"
  },
  {
    "text": "name as a bucket and at the bottom we've got uh yourdomain.com and inside of those we have objects now those objects",
    "start": "677320",
    "end": "684440"
  },
  {
    "text": "appear to have a folder structure but they're not that object and that name including the slash the path if you like",
    "start": "684440",
    "end": "691040"
  },
  {
    "text": "is just part of the object name so an object key is unique within a bucket an",
    "start": "691040",
    "end": "697519"
  },
  {
    "text": "object key can be 1024 bytes long when it's utfa encoded and it includes those",
    "start": "697519",
    "end": "703240"
  },
  {
    "text": "path prefixes that we saw previously so an object like this is a key so asset",
    "start": "703240",
    "end": "709519"
  },
  {
    "text": "sljs jQuery plugins js. JS for example that whole string is the object key and",
    "start": "709519",
    "end": "717000"
  },
  {
    "text": "prefixed by the bucket that will be unique",
    "start": "717000",
    "end": "721880"
  },
  {
    "text": "globally now based upon that if you look at these um object Keys um and a",
    "start": "723639",
    "end": "730680"
  },
  {
    "text": "fictitional example of a bucket where I've got my bucket on the left called my new game and my object keys on the right",
    "start": "730680",
    "end": "737600"
  },
  {
    "text": "um S3 will try to automatically partition data across nodes within the",
    "start": "737600",
    "end": "743240"
  },
  {
    "text": "subsystems to ensure that we get consistent performance for reads of your objects",
    "start": "743240",
    "end": "749519"
  },
  {
    "text": "and if you look at this example what I'm really showing here is this is incrementing game IDs so if this is a",
    "start": "749519",
    "end": "755199"
  },
  {
    "text": "Gaming website we've got uh some photos some resources and some text files for",
    "start": "755199",
    "end": "760680"
  },
  {
    "text": "each game that we're publishing for example on this website and the game IDs are incrementing each time and storing",
    "start": "760680",
    "end": "767000"
  },
  {
    "text": "all of those assets in a single bucket now behind the scenes S3 will essentially create a partition based",
    "start": "767000",
    "end": "773079"
  },
  {
    "text": "upon the first prefix of that object key so partition will be my new game2",
    "start": "773079",
    "end": "779360"
  },
  {
    "text": "now clearly all objects are then um lumped into one partition now if one of those games had particularly high volume",
    "start": "779360",
    "end": "786320"
  },
  {
    "text": "against it um you're not going to get consistent performance across all games",
    "start": "786320",
    "end": "791440"
  },
  {
    "text": "so one of the tips and tricks is that you can seed if you like that automatic partitioning you could reverse the game",
    "start": "791440",
    "end": "798279"
  },
  {
    "text": "ID in this case so by simply reversing that ID what we're doing is creating or",
    "start": "798279",
    "end": "804399"
  },
  {
    "text": "enabling S3 to automatically create partitions in this case sl7 sl8 SL n and",
    "start": "804399",
    "end": "809920"
  },
  {
    "text": "we're spreading the performance across partitions so one of the things you can do in terms of throughput optimization",
    "start": "809920",
    "end": "815320"
  },
  {
    "text": "is to think about your key naming convention so you're not uh coalescing them all on a single prefix okay and",
    "start": "815320",
    "end": "821240"
  },
  {
    "text": "there's various different things you can have a look on the the website give you guidance on some of different models that you can use to do this and to",
    "start": "821240",
    "end": "827440"
  },
  {
    "text": "enable you to search those indexes effectively next up on S3 once I've got",
    "start": "827440",
    "end": "833680"
  },
  {
    "text": "some data in it um I've understood the consistency model and I've optimized for performance m is encryption so S3",
    "start": "833680",
    "end": "841800"
  },
  {
    "text": "enables you to secure data at rest via a simple tick of a box within the console",
    "start": "841800",
    "end": "847199"
  },
  {
    "text": "and server side encryption um really is around then enabling you to take uh a",
    "start": "847199",
    "end": "852759"
  },
  {
    "text": "self-managed if you like approach to encrypting your data you don't have to worry about key management or",
    "start": "852759",
    "end": "858519"
  },
  {
    "text": "maintaining a key store the server side encryption in S3 is a256 it's a",
    "start": "858519",
    "end": "864120"
  },
  {
    "text": "symmetric um encryption algorithm and that we're storing the keys that we",
    "start": "864120",
    "end": "869399"
  },
  {
    "text": "encrypt with in S3 as well so the key store is durable and because we we go",
    "start": "869399",
    "end": "875040"
  },
  {
    "text": "for a method of encrypting the key and cycling Keys which I'll explain in a second it's secure it's three-way",
    "start": "875040",
    "end": "880440"
  },
  {
    "text": "simultaneous access is required to unencrypted data so it's very hard for for anyone and this is an ordered",
    "start": "880440",
    "end": "885680"
  },
  {
    "text": "process of an Amazon to get hold of your data once it's encrypted you simply need the object you'll need the object",
    "start": "885680",
    "end": "892040"
  },
  {
    "text": "encryption key and you need a master key to be able to do an encryption of this data and you said you can enable this",
    "start": "892040",
    "end": "897839"
  },
  {
    "text": "with a simple tick box in the console but also a simple put header in the request to push your data inter rest3",
    "start": "897839",
    "end": "904000"
  },
  {
    "text": "will enable uh server side encryption so how does it work so normally when you put an object into S3",
    "start": "904000",
    "end": "911560"
  },
  {
    "text": "your data is just deposited in a bucket but with server side encryption we will generate a per object key and we'll",
    "start": "911560",
    "end": "919440"
  },
  {
    "text": "encrypt your object as it's placed into S3 and then it will reside in your",
    "start": "919440",
    "end": "924680"
  },
  {
    "text": "bucket in encrypted form and we're generating a random key per object object and we store that object in a",
    "start": "924680",
    "end": "932920"
  },
  {
    "text": "bucket in S3 but we're encrypting that key with a master key that is maintained",
    "start": "932920",
    "end": "938880"
  },
  {
    "text": "by AWS and that master key is uh managed by us and rotated monthly so we'll",
    "start": "938880",
    "end": "945519"
  },
  {
    "text": "reencrypt and cycle those keys for encrypting your keys so you can see here you need your data you need the object",
    "start": "945519",
    "end": "952399"
  },
  {
    "text": "key and you need the master key to unencrypted data now we take care of all of that when you do a get and we'll pass",
    "start": "952399",
    "end": "958440"
  },
  {
    "text": "you back on encrypted data now of course this isn't encrypting data at flight and there's different ways in which you can",
    "start": "958440",
    "end": "964480"
  },
  {
    "text": "do that um but this is ensuring that once it's in the subsystem it's encrypted with that as 256 key with this",
    "start": "964480",
    "end": "971600"
  },
  {
    "text": "key management scheme so there we go in the console",
    "start": "971600",
    "end": "977120"
  },
  {
    "text": "when you upload a document you can an object you can simply tick the Box use server side encryption and indeed on",
    "start": "977120",
    "end": "983759"
  },
  {
    "text": "there you can also see the use of reduced redundancy storage to change the storage class",
    "start": "983759",
    "end": "990800"
  },
  {
    "text": "okay so getting data in Insurance encrypted and so on all good and and",
    "start": "991839",
    "end": "996959"
  },
  {
    "text": "well how do you control who can see what in S3 and who can do what in S3 so we",
    "start": "996959",
    "end": "1003399"
  },
  {
    "text": "provide you with a set of access controls that enable you to control who does what so S3 is secure by default so",
    "start": "1003399",
    "end": "1012880"
  },
  {
    "text": "by default only you can access the objects that you place within those buckets and you have to decide what to",
    "start": "1012880",
    "end": "1018279"
  },
  {
    "text": "share and how to share it and we give you some tools to do that in terms of",
    "start": "1018279",
    "end": "1023360"
  },
  {
    "text": "policies that you can apply to buckets Access Control lists and IM integration identity and access management",
    "start": "1023360",
    "end": "1029760"
  },
  {
    "text": "integration so let's have a look at those three things now the first which",
    "start": "1029760",
    "end": "1035120"
  },
  {
    "text": "is IM is the overarching if you like ro-based access controls within AWS and",
    "start": "1035120",
    "end": "1041280"
  },
  {
    "text": "this gives you fine grained control over who can do what around S3 so you might",
    "start": "1041280",
    "end": "1047438"
  },
  {
    "text": "administer S3 policies as part of a wider role-based access scheme and then",
    "start": "1047439",
    "end": "1053039"
  },
  {
    "text": "you can apply a policy an IM am policy to users or groups so shown below for",
    "start": "1053039",
    "end": "1059880"
  },
  {
    "text": "example have an action that enables somebody to put an object into S3 and the resource that people are allowed to",
    "start": "1059880",
    "end": "1065960"
  },
  {
    "text": "do if they're assigned to this group is my bucket and any object within my bucket so if you like that's top box is",
    "start": "1065960",
    "end": "1073520"
  },
  {
    "text": "the IM uh policy and then I can assign that policy to users so Bob and Jane",
    "start": "1073520",
    "end": "1079760"
  },
  {
    "text": "both have that policy assigned to them they will be enabled to put an object into my bucket and if I revoke that",
    "start": "1079760",
    "end": "1086200"
  },
  {
    "text": "policy from Jane or Jane leaves the company and I remove her account and of course um that policy is",
    "start": "1086200",
    "end": "1091720"
  },
  {
    "text": "removed now that is functionally equivalent to applying what we call a bucket policy so you can take a policy",
    "start": "1091720",
    "end": "1098240"
  },
  {
    "text": "and apply it at the Bucket Level and again this gives you fine grain control but what this does is essentially allows",
    "start": "1098240",
    "end": "1105240"
  },
  {
    "text": "you to do user restrictions without using Im so in this case we would have the same actions put object against my",
    "start": "1105240",
    "end": "1112520"
  },
  {
    "text": "bucket um and you've assigned that to a policy on the bucket but in this case",
    "start": "1112520",
    "end": "1117799"
  },
  {
    "text": "you'd have to explicitly allow Bob and Jane's AWS user IDs to be able to do such a thing so you can apply that at",
    "start": "1117799",
    "end": "1124960"
  },
  {
    "text": "that level lastly we have an access control list or ACLS and this is course",
    "start": "1124960",
    "end": "1130400"
  },
  {
    "text": "grained control because this enables you to apply a rule a bucket or indeed an",
    "start": "1130400",
    "end": "1135720"
  },
  {
    "text": "object level in S3 that would do action such as read or write okay or control",
    "start": "1135720",
    "end": "1142600"
  },
  {
    "text": "the access control policy read or write the ACL and you can allow everyone for example or you could allow authenticated",
    "start": "1142600",
    "end": "1150440"
  },
  {
    "text": "users which are other people with S3 accounts or you can apply specific AWS",
    "start": "1150440",
    "end": "1156600"
  },
  {
    "text": "colonal user IDs so you can allow Bob or Jane and you can assign that access control list to a bucket or my object",
    "start": "1156600",
    "end": "1163960"
  },
  {
    "text": "now most commonly it's the access control list you'll use if you're using something like uh S3 console in the um",
    "start": "1163960",
    "end": "1171760"
  },
  {
    "text": "um AWS console or you're using a third party FTP type tool that integrates with S3 and you upload an object and you",
    "start": "1171760",
    "end": "1178600"
  },
  {
    "text": "might want to share that with some people you might set the uh availability of that object to be read by everyone in",
    "start": "1178600",
    "end": "1185320"
  },
  {
    "text": "that case you're applying an access control list on just an object within a bucket but there's three things you need",
    "start": "1185320",
    "end": "1190679"
  },
  {
    "text": "to be aware of and how you might use them and we'll look at things like bucket policies as I go from some",
    "start": "1190679",
    "end": "1195760"
  },
  {
    "text": "examples uh in this webinar and here's a bucket policy so this is a bucket policy that effectively allows",
    "start": "1195760",
    "end": "1203960"
  },
  {
    "text": "accounts so there's some fictitious uh account IDs canonical count IDs that enables uh these people to access or do",
    "start": "1203960",
    "end": "1211840"
  },
  {
    "text": "something within my bucket the resource applied there and in case the action is there as a star so as a wild card they",
    "start": "1211840",
    "end": "1218159"
  },
  {
    "text": "can do anything in my bucket but I've added an IP address restriction to say",
    "start": "1218159",
    "end": "1223360"
  },
  {
    "text": "that they must come from this particular Network which is the corporate Network so this is effect Bob and Jane accessing",
    "start": "1223360",
    "end": "1230240"
  },
  {
    "text": "my bucket but only when they're in the office or on the VPN for example okay so you can apply that bucket policy and",
    "start": "1230240",
    "end": "1236559"
  },
  {
    "text": "then all objects within that bucket would um be restricted against those",
    "start": "1236559",
    "end": "1242559"
  },
  {
    "text": "rules so Transitions and life cycle management is another topic um so this",
    "start": "1243400",
    "end": "1248440"
  },
  {
    "text": "is about automating the management of objects within bucket so objects sprawl",
    "start": "1248440",
    "end": "1253559"
  },
  {
    "text": "can happen and you might be depositing for example logs into a bucket from various different applications servers",
    "start": "1253559",
    "end": "1259480"
  },
  {
    "text": "and you might have a desire that periodically you're cleaning up that bucket so that this isn't growing and",
    "start": "1259480",
    "end": "1264640"
  },
  {
    "text": "growing and growing beyond control and life cycle management within S3 lets you",
    "start": "1264640",
    "end": "1269799"
  },
  {
    "text": "do this so you can do object deletion so you can control when an object will be",
    "start": "1269799",
    "end": "1275840"
  },
  {
    "text": "automatically deleted from S3 and you can also control object archiving so you",
    "start": "1275840",
    "end": "1281720"
  },
  {
    "text": "can move objects into glassier or move it to the other storage class and out of S3 based upon some rules",
    "start": "1281720",
    "end": "1290039"
  },
  {
    "text": "so glacia is that long-term durable archive I mentioned before so effectively being used as a different",
    "start": "1290039",
    "end": "1295880"
  },
  {
    "text": "storage subsystem within S3 and glassier is designed for long-term Cold Storage",
    "start": "1295880",
    "end": "1301360"
  },
  {
    "text": "where data is is accessed infrequently so it's same durability as",
    "start": "1301360",
    "end": "1306880"
  },
  {
    "text": "S3 in terms of 119 designed for durability of the archives within glassier but it's designed as a right",
    "start": "1306880",
    "end": "1313640"
  },
  {
    "text": "once read never and because of that we can make it very cost effective for high",
    "start": "1313640",
    "end": "1319200"
  },
  {
    "text": "volume data storage within from 1 cent um per gigabyte per month now you only",
    "start": "1319200",
    "end": "1326120"
  },
  {
    "text": "pay really for accessing the data so there is a certain free amount of data",
    "start": "1326120",
    "end": "1331360"
  },
  {
    "text": "transfer that you get but when you go beyond that and you'll retrieving lots of data from archives you'll start",
    "start": "1331360",
    "end": "1336480"
  },
  {
    "text": "incurring the price because we have to go and retrieve that data and make it hot for you now we do that um in various",
    "start": "1336480",
    "end": "1342880"
  },
  {
    "text": "ways that you can do that via the glassier API but when it integrates to S3 it's a particularly elegant model",
    "start": "1342880",
    "end": "1349279"
  },
  {
    "text": "so I mentioned logs before and expiries let's have a look at transitions of life cycles that incorporate deletions and",
    "start": "1349279",
    "end": "1356159"
  },
  {
    "text": "glassier archive movings so I might have a series of application logs that are in a bucket and they're accessible from S3",
    "start": "1356159",
    "end": "1363320"
  },
  {
    "text": "and after some period of time 6 months say I want those objects to expire and I",
    "start": "1363320",
    "end": "1368919"
  },
  {
    "text": "want them to be deleted and we could a simple expiry rule on S3 buckets to enable you to do",
    "start": "1368919",
    "end": "1375720"
  },
  {
    "text": "that conversely we might have trans transactions we w't have an e-commerce site and we've got transaction audits",
    "start": "1375720",
    "end": "1381440"
  },
  {
    "text": "held in files within S3 now you want these accessible from S3 for that 6",
    "start": "1381440",
    "end": "1387320"
  },
  {
    "text": "months period but after 6 months you want to invoke a transition to glacia",
    "start": "1387320",
    "end": "1392799"
  },
  {
    "text": "and then glacia will um take on the storage of that data the storage class will flip with an S3 from standard to",
    "start": "1392799",
    "end": "1400360"
  },
  {
    "text": "glacia and after some unspecified period of time maybe years later that you wish",
    "start": "1400360",
    "end": "1405559"
  },
  {
    "text": "to retrieve that data and restore that object for Access and you make a request",
    "start": "1405559",
    "end": "1410720"
  },
  {
    "text": "then to restore the data and you you ask for how long that data uh would be made",
    "start": "1410720",
    "end": "1416559"
  },
  {
    "text": "available to you for you to access before it's removed from S3 because effectively what we're going to do is to",
    "start": "1416559",
    "end": "1422120"
  },
  {
    "text": "pull the data back from glassier and hold it in RRS reduce redundancy storage",
    "start": "1422120",
    "end": "1428320"
  },
  {
    "text": "for the time that you specify you want the object to be available for now it takes 3 to 5 hours for that restoration",
    "start": "1428320",
    "end": "1435080"
  },
  {
    "text": "process to happen which is standard glassier restoration time and then and then once it's there it's available in",
    "start": "1435080",
    "end": "1440120"
  },
  {
    "text": "S3 like a normal object until that period elapses so 3 to 5 Hour retrieval time",
    "start": "1440120",
    "end": "1448360"
  },
  {
    "text": "now we're assuming you won't access glassier storage class objects that often only when you really need to to",
    "start": "1448360",
    "end": "1455880"
  },
  {
    "text": "retrieve maybe what is a single copy of data um in your",
    "start": "1455880",
    "end": "1460919"
  },
  {
    "text": "environment and if you look at uh the console you can set a simple life cycle",
    "start": "1460919",
    "end": "1466080"
  },
  {
    "text": "rule on um a bucket so here I have a rule that is my 10-year archive policy",
    "start": "1466080",
    "end": "1472919"
  },
  {
    "text": "and it's applying to all objects in my bucket and it's going to work based upon the days from the creation date of this",
    "start": "1472919",
    "end": "1480080"
  },
  {
    "text": "these objects and I've got two transitions in there I've got a transition and an expiry rule so it's",
    "start": "1480080",
    "end": "1485720"
  },
  {
    "text": "going to transition to glassier 365 days or a year from the object's creation",
    "start": "1485720",
    "end": "1491440"
  },
  {
    "text": "date and then it's going to expire the objects 10 years from the creation date",
    "start": "1491440",
    "end": "1497039"
  },
  {
    "text": "so effectively I have my object in S3 for a year and then after which it will move to glassier storage class and if I",
    "start": "1497039",
    "end": "1504360"
  },
  {
    "text": "want it back it would take 3 to 5 hours but 10 years in the object's going to be deleted and it won't be available at",
    "start": "1504360",
    "end": "1511880"
  },
  {
    "text": "all another way of um doing that and this is a net um API example so here I",
    "start": "1511880",
    "end": "1518240"
  },
  {
    "text": "have the exactly the same life cycle rules being defined and I can see I'm defining a transition after one year so",
    "start": "1518240",
    "end": "1525120"
  },
  {
    "text": "setting my storage class to glassier after 365 days and I'm also setting an",
    "start": "1525120",
    "end": "1532120"
  },
  {
    "text": "expiration on my life cycle rules after 3,650 days so I can achieve all the same",
    "start": "1532120",
    "end": "1539000"
  },
  {
    "text": "things that I did simply in the console programmatically and you might want to consider how you manage the policies",
    "start": "1539000",
    "end": "1544679"
  },
  {
    "text": "around objects in S3 but also how you manage for example indexes that you might want to search outside of S3",
    "start": "1544679",
    "end": "1552200"
  },
  {
    "text": "because you might want to have queriable databases of all your objects and archives in pointing to your assets and",
    "start": "1552200",
    "end": "1559559"
  },
  {
    "text": "your keys within S3 that's a very common way of doing things having a relational data structure managing a metadata",
    "start": "1559559",
    "end": "1566720"
  },
  {
    "text": "around objects held in S3 now when you initiate a restore this",
    "start": "1566720",
    "end": "1572000"
  },
  {
    "text": "is the console view so you initiate restore and you're specifying the number of days that you want that to be",
    "start": "1572000",
    "end": "1577440"
  },
  {
    "text": "available for so here I have seven days the object will be pulled back popped into RS storage and made available for 7",
    "start": "1577440",
    "end": "1585200"
  },
  {
    "text": "days now another way of looking at this is using the rest API so um you'll find",
    "start": "1585200",
    "end": "1590320"
  },
  {
    "text": "that in our documentation we often talk about the the rest API or indeed the XML content that is going to get fired",
    "start": "1590320",
    "end": "1595799"
  },
  {
    "text": "across different soap interfaces behind the scenes and really to to note here is that this restore request here is just",
    "start": "1595799",
    "end": "1602559"
  },
  {
    "text": "specifying a number of days against an object and a bucket and if you want to look into how you sign uh rest API API",
    "start": "1602559",
    "end": "1610120"
  },
  {
    "text": "calls there's some great documentation online but it brings an interesting uh sort of Point here and illustrates quite",
    "start": "1610120",
    "end": "1616240"
  },
  {
    "text": "nicely what you'd achieve via the other rest dks as well is that there'll be various different response codes and the",
    "start": "1616240",
    "end": "1622799"
  },
  {
    "text": "rest API clearly is is HTTP type response codes so the responses you'll get from making this call is a 202",
    "start": "1622799",
    "end": "1629960"
  },
  {
    "text": "accepted so if this is an object that is in glassier storage and we haven't requested restoration before we'll get a",
    "start": "1629960",
    "end": "1636720"
  },
  {
    "text": "202 accepted and the process will kick off behind the scenes if I make another request against that object I'll get a",
    "start": "1636720",
    "end": "1643520"
  },
  {
    "text": "200 okay because the object is already being restored and what that will do is will simply or it's already restored I",
    "start": "1643520",
    "end": "1650320"
  },
  {
    "text": "should say and what this will do is it update the number of days that it will be made available in reduced redundancy",
    "start": "1650320",
    "end": "1656200"
  },
  {
    "text": "storage so it's effectively updating and keeping that that object hanging around in S3 for longer versus if the",
    "start": "1656200",
    "end": "1662720"
  },
  {
    "text": "restoration is in progress I get a 409 conflict back so I can using this for",
    "start": "1662720",
    "end": "1668559"
  },
  {
    "text": "example periodically check the progress of my restoration and the other sdks like python Ruby net Java wrap this up",
    "start": "1668559",
    "end": "1676279"
  },
  {
    "text": "in in different ways for you to handle in more elegant",
    "start": "1676279",
    "end": "1680600"
  },
  {
    "text": "fashion another great use case for S3 is serving websites straight from sray",
    "start": "1681960",
    "end": "1689519"
  },
  {
    "text": "buckets now it's a web service so so why not so why not serve up web content",
    "start": "1689519",
    "end": "1694600"
  },
  {
    "text": "directly from S3 it's highly scalable it's cost effective and there's some great tools for managing what gets put",
    "start": "1694600",
    "end": "1701440"
  },
  {
    "text": "in there um when and you can also deal with things like archiving data off using uh expiry policies if you got a",
    "start": "1701440",
    "end": "1708600"
  },
  {
    "text": "lot of user generated content for example being thrown up behind a Content management system for example that you",
    "start": "1708600",
    "end": "1714120"
  },
  {
    "text": "might want to back onto S3 so setting a static website hosting",
    "start": "1714120",
    "end": "1720760"
  },
  {
    "text": "with an S3 is really very simple so you would enable a bucket for website hosting and you would then enable the",
    "start": "1720760",
    "end": "1727919"
  },
  {
    "text": "default document to be served and an error document you can build a custom error document so the top left is",
    "start": "1727919",
    "end": "1733039"
  },
  {
    "text": "settings and default documents um but you can also do redirections so you",
    "start": "1733039",
    "end": "1738200"
  },
  {
    "text": "might name buckets and I'm going to show you example in a second of how we can create buckets that are named the same",
    "start": "1738200",
    "end": "1744679"
  },
  {
    "text": "as our domain names and how then marry that together with Route 53 to essentially serve something up",
    "start": "1744679",
    "end": "1752600"
  },
  {
    "text": "directly um when I set a website we then look at doing a bucket policy as well",
    "start": "1752600",
    "end": "1758159"
  },
  {
    "text": "because clearly when we're creating a bucket we want our and serving it as a static website we want the users and",
    "start": "1758159",
    "end": "1765000"
  },
  {
    "text": "authenticated users to be able to read the objects to return the HT Emil Pages or the the image assets or whatever",
    "start": "1765000",
    "end": "1770640"
  },
  {
    "text": "we're hosting so a bucket policy will enable us to do that and this is another example of bucket policy which is public",
    "start": "1770640",
    "end": "1776559"
  },
  {
    "text": "read get object you can see that name I've given it which is to allow anyone",
    "start": "1776559",
    "end": "1781720"
  },
  {
    "text": "principal AWS star to do an S3 get object against the resource my bucket in",
    "start": "1781720",
    "end": "1787760"
  },
  {
    "text": "this case example bucket so this is a policy you would apply so you'd flip the bucket to enable static website hosting",
    "start": "1787760",
    "end": "1795200"
  },
  {
    "text": "and then drop this bucket policy on top of the bucket and then we're ready to go to push some documents into",
    "start": "1795200",
    "end": "1802080"
  },
  {
    "text": "S3 now it brings in an interesting topic now around the um the normal addressing",
    "start": "1802080",
    "end": "1807799"
  },
  {
    "text": "versus website addressing of S3 buckets so S3 buckets um when they're served as",
    "start": "1807799",
    "end": "1813640"
  },
  {
    "text": "a website have a particular URL form shown at the top so if I have a bucket my bucket and I'm in the region EU West",
    "start": "1813640",
    "end": "1821640"
  },
  {
    "text": "the URL of my website by default will be my bucket. S3 website e1. Amazon AWS",
    "start": "1821640",
    "end": "1829000"
  },
  {
    "text": "now that's um versus normal addressing of buckets which can take two forms and",
    "start": "1829000",
    "end": "1834440"
  },
  {
    "text": "we can see down the bottom there that I either got my S3 region with a path style suffix with bucket object key or",
    "start": "1834440",
    "end": "1841799"
  },
  {
    "text": "I'd have if you like the subdomain type format with bucket name at the start and then my object key at the right there so",
    "start": "1841799",
    "end": "1850120"
  },
  {
    "text": "be aware that when you do website addressing you'll get the S3 website in the URL and it's that that you can use",
    "start": "1850120",
    "end": "1856679"
  },
  {
    "text": "then to manage d s so this is an example of Route 53",
    "start": "1856679",
    "end": "1863120"
  },
  {
    "text": "owning the record set for my domain AWS examples. info so I've got a domain from",
    "start": "1863120",
    "end": "1868880"
  },
  {
    "text": "a provider I've then created a record set in Route 53 and I've taken the root",
    "start": "1868880",
    "end": "1874039"
  },
  {
    "text": "53 name servers and updated my domain provider so that we're pointing AWS and",
    "start": "1874039",
    "end": "1880440"
  },
  {
    "text": "Route 53 is now in control of the record set for AWS examples. info a really quick and easy thing to do that's really",
    "start": "1880440",
    "end": "1887399"
  },
  {
    "text": "really good for bringing in control of your DNS entries into AWS because it enables you to do some quite clever",
    "start": "1887399",
    "end": "1892519"
  },
  {
    "text": "things now the first of those is to do this so if I've got a bucket on the bottom right there called AWS examples.",
    "start": "1892519",
    "end": "1899960"
  },
  {
    "text": "info so that's the name of my bucket that I've given it and that's the bucket that I'm going to use to pop in my index",
    "start": "1899960",
    "end": "1906320"
  },
  {
    "text": "HTML and my error HTML on the left I create a second",
    "start": "1906320",
    "end": "1911360"
  },
  {
    "text": "bucket which is dubdub dub. AWS examples.in info so exactly the same but",
    "start": "1911360",
    "end": "1917360"
  },
  {
    "text": "with the the dubdub prefix applied to it and that what I would do then is within",
    "start": "1917360",
    "end": "1923320"
  },
  {
    "text": "S3 on my dub dubdub bucket is I set a redirect so I set this to be a serving a",
    "start": "1923320",
    "end": "1929240"
  },
  {
    "text": "static website but I'm going to redirect all requests to my aw. examples. info so",
    "start": "1929240",
    "end": "1936000"
  },
  {
    "text": "depending on whether the I want it one way or the other I can flip this but this is going to mean that anyone that types in dubdub dub. AWS examples. info",
    "start": "1936000",
    "end": "1943360"
  },
  {
    "text": "will be returned AWS examples. info without the the root domain then",
    "start": "1943360",
    "end": "1948840"
  },
  {
    "text": "then in Route 53 I set up an a record and I use a special Alias record now in",
    "start": "1948840",
    "end": "1954200"
  },
  {
    "text": "the console when you do this you'll see S3 static website sources within Route 53 and you can simply choose the one to",
    "start": "1954200",
    "end": "1962120"
  },
  {
    "text": "apply and I choose AWS examples. info which is served as a static",
    "start": "1962120",
    "end": "1967320"
  },
  {
    "text": "website then on the flip side I put another rule I put a c name and I put a simple C name for um to redirect dubdub",
    "start": "1967320",
    "end": "1976320"
  },
  {
    "text": "duub requests into my dubdub dub bucket and we can see then we'll complete the cycle then when I hit either of those",
    "start": "1976320",
    "end": "1983440"
  },
  {
    "text": "domains I will then be return my static website another thing um that S3 does um",
    "start": "1983440",
    "end": "1991600"
  },
  {
    "text": "is object versioning so because we have unlimited storage in S3 it's possible",
    "start": "1991600",
    "end": "1997080"
  },
  {
    "text": "for us to keep all copies of an object that have ever been uploaded and we can preserve object histories Now by",
    "start": "1997080",
    "end": "2003880"
  },
  {
    "text": "selecting at the Bucket Level the object version is enabled we will preserve all",
    "start": "2003880",
    "end": "2010399"
  },
  {
    "text": "copies of objects so if you do an update to an object we will create a new version and keep the old and it's",
    "start": "2010399",
    "end": "2016679"
  },
  {
    "text": "persistent even if you delete the object we'll simply create a delete marker for the latest version of the object and you",
    "start": "2016679",
    "end": "2022760"
  },
  {
    "text": "can simply go back in time to have a look at the old object versions if you say wish and this is all handled",
    "start": "2022760",
    "end": "2028240"
  },
  {
    "text": "automatically it should be noted that once you enable it you can't turn it off so I'm going to introduce some apis",
    "start": "2028240",
    "end": "2036000"
  },
  {
    "text": "now and one of my favorite uh sdks for AWS is python um Botto so maintained by",
    "start": "2036000",
    "end": "2043600"
  },
  {
    "text": "us um you'll find the Botto libraries on many ec2 instances automatically installed so simple case of importing",
    "start": "2043600",
    "end": "2050240"
  },
  {
    "text": "the boso library and shown here in my code I'm connecting to S3 um and I'm",
    "start": "2050240",
    "end": "2056000"
  },
  {
    "text": "going to do a get bucket on my bucket and I'm going to list versions of objects in my bucket with that simple",
    "start": "2056000",
    "end": "2062118"
  },
  {
    "text": "recursion there for Loop and I returned then in this case I'm printing the version name and the version ID and I've",
    "start": "2062119",
    "end": "2068919"
  },
  {
    "text": "got my file. text and I got three versions and there's the version ID in text form returned for me and I can use",
    "start": "2068919",
    "end": "2075440"
  },
  {
    "text": "that version ID then to go and access things now it should be said that in the S3 console with versioning enabled",
    "start": "2075440",
    "end": "2081398"
  },
  {
    "text": "there's a simple switch and you can go and look at these versions yourself in the console but I wanted to illustrate",
    "start": "2081399",
    "end": "2086960"
  },
  {
    "text": "how easy it is to do this stuff via an API so if I then go in this case going",
    "start": "2086960",
    "end": "2093158"
  },
  {
    "text": "set my key in my Python language there to key equals bucket. getet key from my",
    "start": "2093159",
    "end": "2098160"
  },
  {
    "text": "file. textt and specify the version ID that I'm looking for and then I return",
    "start": "2098160",
    "end": "2103599"
  },
  {
    "text": "the contents of my file as a string because I've uploaded simple files to to illustrate the point the content of my",
    "start": "2103599",
    "end": "2110000"
  },
  {
    "text": "file is this is version one of my file and likewise I could go and get another version and in that case the different",
    "start": "2110000",
    "end": "2115680"
  },
  {
    "text": "version ID returns different content and I uploaded a a second version with this is version two of my",
    "start": "2115680",
    "end": "2122720"
  },
  {
    "text": "file now subsequently um just so you know that you can generate",
    "start": "2122720",
    "end": "2128359"
  },
  {
    "text": "URLs for accessing uh objects within S3 now you can generate um time bombed URLs",
    "start": "2128359",
    "end": "2135800"
  },
  {
    "text": "and in boso library it's very simple to do a key. generate and the time in seconds that you want something to be",
    "start": "2135800",
    "end": "2140960"
  },
  {
    "text": "available for so this is a 10-minute Time Bomb URL for an older version so you can do this for any version of a",
    "start": "2140960",
    "end": "2147079"
  },
  {
    "text": "file but if you've got older versions you might want to give up um part of your application is to access all the",
    "start": "2147079",
    "end": "2153040"
  },
  {
    "text": "versions of files maybe for document management you can pop up a a time bomb URL L pass it around in your application",
    "start": "2153040",
    "end": "2159480"
  },
  {
    "text": "or email it out and so on um now once a link has expired on",
    "start": "2159480",
    "end": "2167240"
  },
  {
    "text": "time bombed URLs you will be returned a message like this so the link has expired so this is accessing that time",
    "start": "2167240",
    "end": "2173119"
  },
  {
    "text": "bombed URL after the event and this is something that you can handle in a client application or that you can",
    "start": "2173119",
    "end": "2178680"
  },
  {
    "text": "simply pass out a URL to an object email it out and be sure that after the time",
    "start": "2178680",
    "end": "2183960"
  },
  {
    "text": "that you want the summer to access it will be gone so time B URLs there incorporated into that um example around",
    "start": "2183960",
    "end": "2191520"
  },
  {
    "text": "using the python apis now of course objects within S3",
    "start": "2191520",
    "end": "2196720"
  },
  {
    "text": "have metadata associated with them they have system generated metadata and some of that data is like the date that your",
    "start": "2196720",
    "end": "2203160"
  },
  {
    "text": "object was created the size and bites of the objects the check sums um there's Flags there so for example server side",
    "start": "2203160",
    "end": "2210480"
  },
  {
    "text": "encryption I talked about putting a simple put header you know this metadata is a header that is enabling uh ser side",
    "start": "2210480",
    "end": "2217800"
  },
  {
    "text": "encryption that will turn it on and off we can clearly see a version ID there so talking about the object versioning will",
    "start": "2217800",
    "end": "2223760"
  },
  {
    "text": "be returned and going with that as a delete marker so that if this is actually a deleted object then we can",
    "start": "2223760",
    "end": "2230319"
  },
  {
    "text": "see that based upon bucket versioning we we return the storage class but we can also do redirects as well for locations",
    "start": "2230319",
    "end": "2237720"
  },
  {
    "text": "so we might want to override the location of a particular object with an S3 when we're serving as a static",
    "start": "2237720",
    "end": "2244359"
  },
  {
    "text": "website and push it into a new object a new version of a file or a maintenance page or something like that but you can",
    "start": "2244359",
    "end": "2251119"
  },
  {
    "text": "also store your own metadata so you can pop up key value pairs into S3 and that will be returned",
    "start": "2251119",
    "end": "2258319"
  },
  {
    "text": "with requests whether you're managing requests for an SDK whether you're using a simple rest API and forming up those",
    "start": "2258319",
    "end": "2265079"
  },
  {
    "text": "HTTP headers and bodies you can get prefixed with xam Z meta your metadata",
    "start": "2265079",
    "end": "2271560"
  },
  {
    "text": "key in here so you can put anything you like and you can drive content around",
    "start": "2271560",
    "end": "2276680"
  },
  {
    "text": "the object or or processes around the object without having to expect the bytes in the object",
    "start": "2276680",
    "end": "2282560"
  },
  {
    "text": "itself so back to that python API example a simple key set metadata will",
    "start": "2282560",
    "end": "2288560"
  },
  {
    "text": "set um my tag to be equal to the string my metadata and then I can return that",
    "start": "2288560",
    "end": "2294640"
  },
  {
    "text": "key. get metadata my tag and there I'll be returned to string my",
    "start": "2294640",
    "end": "2300079"
  },
  {
    "text": "metadata next up is cloudfront so cloudfront is our Global",
    "start": "2300079",
    "end": "2305480"
  },
  {
    "text": "CDN and cloudfront integrates perfectly with S3 so you can deliver content in S3",
    "start": "2305480",
    "end": "2311000"
  },
  {
    "text": "buckets from Global Edge locations at a few clicks of a button now you can do download distributions and you can do",
    "start": "2311000",
    "end": "2317280"
  },
  {
    "text": "streaming distributions so for download we're talking about maybe static assets",
    "start": "2317280",
    "end": "2323240"
  },
  {
    "text": "like uh stylesheets JavaScript images uh and so on you'd have those in a download",
    "start": "2323240",
    "end": "2329760"
  },
  {
    "text": "distribution and we push those to Global Edge locations you can also set up a global um download distribution that",
    "start": "2329760",
    "end": "2336440"
  },
  {
    "text": "will have Origins that are ec2 instances mixed and match with S3 buckets so that's called Dynamic Edge location",
    "start": "2336440",
    "end": "2343000"
  },
  {
    "text": "serving so another topic for another day on these webinar series but a streaming",
    "start": "2343000",
    "end": "2348280"
  },
  {
    "text": "distribution enables you to serve media files like MP4 h264 encoded media um as",
    "start": "2348280",
    "end": "2354839"
  },
  {
    "text": "an rtmp stream directly from a bucket so effectively creating a flash media",
    "start": "2354839",
    "end": "2360160"
  },
  {
    "text": "server behind the scenes on top of S3 and giving you a simple endpoint that references an object in an S3 bucket and",
    "start": "2360160",
    "end": "2367880"
  },
  {
    "text": "streams it into your favorite player so download distribution is simple case of",
    "start": "2367880",
    "end": "2373720"
  },
  {
    "text": "creating in cloudfront and the console a download distribution and then various",
    "start": "2373720",
    "end": "2378839"
  },
  {
    "text": "things that you can set the most obvious and fundamental setting is at the top which is the origin domain name which",
    "start": "2378839",
    "end": "2385119"
  },
  {
    "text": "you would just set to be your S3 bucket and simply clicking in that box will give you a list of your available buckets that you can set as a download",
    "start": "2385119",
    "end": "2392599"
  },
  {
    "text": "distribution and then there's various other things that you can you can set on this so so access controls that you",
    "start": "2392599",
    "end": "2398960"
  },
  {
    "text": "might have on your S3 buckets can flow through to Edge locations so you can ensure that you got signed URLs going",
    "start": "2398960",
    "end": "2405359"
  },
  {
    "text": "out to Edge locations you can do forwarding of of cookies or parameter strings that are coming back to maybe",
    "start": "2405359",
    "end": "2412040"
  },
  {
    "text": "Dynamic servers as well and spread out your data across not only S3 but ec2 instances but you can also pop a c name",
    "start": "2412040",
    "end": "2419319"
  },
  {
    "text": "on top of this stuff so this will generate you a a unique URL for distribution but you can put your",
    "start": "2419319",
    "end": "2425520"
  },
  {
    "text": "mysite.com on top of this as well and make this a really clean and simple way of publishing assets from S3 directly",
    "start": "2425520",
    "end": "2431680"
  },
  {
    "text": "into existing websites streaming very similar so choosing streaming on top of a bucket",
    "start": "2431680",
    "end": "2438839"
  },
  {
    "text": "and again you would choose the S3 buckets and here I've got my bucket populated in there I could again pop a a",
    "start": "2438839",
    "end": "2444960"
  },
  {
    "text": "single C name on the top I can turn logging on and off and so on now looking at the streaming um or or looking at any",
    "start": "2444960",
    "end": "2452079"
  },
  {
    "text": "of those in fact your content will be served from a whole host of edge location shown as star",
    "start": "2452079",
    "end": "2458119"
  },
  {
    "text": "um after they've first been accessed so once they've been requested there will be a cach Miss at an edge location that",
    "start": "2458119",
    "end": "2464560"
  },
  {
    "text": "people are coming from and then they'll be uh served from your S3 bucket thereafter that data will be cached in",
    "start": "2464560",
    "end": "2471319"
  },
  {
    "text": "an edge location for subsequent viewing and looking at the streaming example",
    "start": "2471319",
    "end": "2476800"
  },
  {
    "text": "this is an HTML uh JavaScript snippet which uses the JW player which is a a",
    "start": "2476800",
    "end": "2483560"
  },
  {
    "text": "player that you can get on the internet and it's essentially set two sources now I've set a download Distribution on top",
    "start": "2483560",
    "end": "2490720"
  },
  {
    "text": "of a bucket where I'm serving my JavaScript from my JW player. JS so I've",
    "start": "2490720",
    "end": "2497079"
  },
  {
    "text": "have a bucket in my S3 account which has got assets that are static and that I",
    "start": "2497079",
    "end": "2502560"
  },
  {
    "text": "want to be served up from as fast as possible as closest to possible to end users and there I've got my download",
    "start": "2502560",
    "end": "2508640"
  },
  {
    "text": "distribution URL and then the object key within my S3 bucket and my object key is",
    "start": "2508640",
    "end": "2515160"
  },
  {
    "text": "JW playjw player. Js likewise my streaming distribution I",
    "start": "2515160",
    "end": "2520560"
  },
  {
    "text": "have another bucket with some media in it some movie files and here I've got the streaming distribution URL and then",
    "start": "2520560",
    "end": "2528359"
  },
  {
    "text": "my object name within the S3 bucket that that streaming distribution is pointing at Montag medium. MP4 and a little bit",
    "start": "2528359",
    "end": "2535800"
  },
  {
    "text": "of URL funing cfx slst to get the stuff to work as part of JW player so that",
    "start": "2535800",
    "end": "2541559"
  },
  {
    "text": "simple HTML snippet depending on where that is served from or the user is that is rendering that page in that browser",
    "start": "2541559",
    "end": "2548720"
  },
  {
    "text": "will then pull data from the pop the ledge location closest to them in our in my case it will be coming from",
    "start": "2548720",
    "end": "2555760"
  },
  {
    "text": "London so a really quick and easy way of creating streaming media into your website so give it a try it's really fun",
    "start": "2555760",
    "end": "2562559"
  },
  {
    "text": "and it's really satisfying okay so that's my uh deep",
    "start": "2562559",
    "end": "2567839"
  },
  {
    "text": "Dive Master Class on the topics now there are more topics to an S3 and we could talk about S3 for days because it",
    "start": "2567839",
    "end": "2574839"
  },
  {
    "text": "really is as Verna Vogal are see talks about it being the 10th wonder of the world but the idea really around it",
    "start": "2574839",
    "end": "2581480"
  },
  {
    "text": "let's summarize it is to stop doing this sort of stuff so stop thinking about capacity planning on storage because you don't have to of S3 stop worrying about",
    "start": "2581480",
    "end": "2589000"
  },
  {
    "text": "the management of storage devices worrying about backing up a backup that you might have on a storage system in",
    "start": "2589000",
    "end": "2595400"
  },
  {
    "text": "your office or your data center and worrying about fixing broken disc drives when they break because all of that",
    "start": "2595400",
    "end": "2600839"
  },
  {
    "text": "stuff is wrapped up in S3 and we do it for you and because you can stop worrying about those things you can",
    "start": "2600839",
    "end": "2606520"
  },
  {
    "text": "start doing some of these and these are some of the broad ranging use cases that use some of the features I've talked",
    "start": "2606520",
    "end": "2611880"
  },
  {
    "text": "about I clearly I've talked about sdks so you can incorporate S3 into your application back ends yourself or you",
    "start": "2611880",
    "end": "2619400"
  },
  {
    "text": "can download if you're using maybe a Content management system like WordPress you can download plugins which move",
    "start": "2619400",
    "end": "2625040"
  },
  {
    "text": "everything off the file system into S3 essentially as a place to store up user",
    "start": "2625040",
    "end": "2630440"
  },
  {
    "text": "generated content so that method is being used all over the place by different applications bootstrapping EC",
    "start": "2630440",
    "end": "2637119"
  },
  {
    "text": "two instances and when we look at the ec2 master class that's coming up in a few weeks we'll talk about extensively",
    "start": "2637119",
    "end": "2642240"
  },
  {
    "text": "about bootstrapping you can use S3 as a place to store your scripts that your ec2 instances when startup go and pull",
    "start": "2642240",
    "end": "2649440"
  },
  {
    "text": "these things and assets from S3 and set themselves up in a way that enables them to do something intelligent we have",
    "start": "2649440",
    "end": "2655359"
  },
  {
    "text": "storage Gateway and other third party tools that might enable you to take an Oracle database snapshot it",
    "start": "2655359",
    "end": "2660520"
  },
  {
    "text": "automatically in your data centers and push that up into S3 and then regenerate databases in the cloud so storage way a",
    "start": "2660520",
    "end": "2667480"
  },
  {
    "text": "great way of doing that and all backed on S3 you can store your application logs in S3 unlimited storage and then",
    "start": "2667480",
    "end": "2674160"
  },
  {
    "text": "you can start consuming those of elastic Mac produced to process vast volumes of data we've looked at store serving web",
    "start": "2674160",
    "end": "2681280"
  },
  {
    "text": "content and of course s is a great platform for doing document sharing with all the access control versioning you",
    "start": "2681280",
    "end": "2687640"
  },
  {
    "text": "can put around it and of course the popular Dropbox is indeed built upon S3",
    "start": "2687640",
    "end": "2693160"
  },
  {
    "text": "itself so hopefully you found some information in this webinar that you didn't know before and it's gone and",
    "start": "2693160",
    "end": "2699640"
  },
  {
    "text": "expanded your knowledge a little bit more and of course as always aws.amazon.com have a look around there",
    "start": "2699640",
    "end": "2706400"
  },
  {
    "text": "have a look at the future webinar series that we're doing sign up and and and get cracking and using the services",
    "start": "2706400",
    "end": "2714680"
  }
]
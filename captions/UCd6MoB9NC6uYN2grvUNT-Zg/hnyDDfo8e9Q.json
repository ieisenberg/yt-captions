[
  {
    "text": "- [Fraser] Hello, everyone.",
    "start": "300",
    "end": "1410"
  },
  {
    "text": "Thank you so much for joining this session",
    "start": "1410",
    "end": "3480"
  },
  {
    "text": "on how to build a RAG-based\ngenerative AI chatbot",
    "start": "3480",
    "end": "6510"
  },
  {
    "text": "in 20 minutes using Amazon\nBedrock Knowledge Bases.",
    "start": "6510",
    "end": "10170"
  },
  {
    "text": "I'm Fraser Sequiera, a startup\nsolutions architect at AWS,",
    "start": "10170",
    "end": "13113"
  },
  {
    "text": "so let's get started.",
    "start": "14520",
    "end": "15603"
  },
  {
    "text": "To equip a foundation model",
    "start": "17850",
    "end": "19290"
  },
  {
    "text": "with up-to-date proprietary information,",
    "start": "19290",
    "end": "21060"
  },
  {
    "text": "organizations turn to\nretrieval-augmented generation.",
    "start": "21060",
    "end": "24180"
  },
  {
    "text": "It's a technique that\ninvolves fetching data",
    "start": "24180",
    "end": "26070"
  },
  {
    "text": "from company data sources\nand enriching the prompt",
    "start": "26070",
    "end": "28470"
  },
  {
    "text": "with that data to deliver more relevant",
    "start": "28470",
    "end": "30420"
  },
  {
    "text": "and accurate responses.",
    "start": "30420",
    "end": "32550"
  },
  {
    "text": "Knowledge Bases for Amazon Bedrock",
    "start": "32550",
    "end": "34410"
  },
  {
    "text": "is a fully managed RAG\ncapability that allows you",
    "start": "34410",
    "end": "37050"
  },
  {
    "text": "to customize foundation model\nresponses with contextual",
    "start": "37050",
    "end": "39549"
  },
  {
    "text": "and relevant company data.",
    "start": "39549",
    "end": "41760"
  },
  {
    "text": "Knowledge Bases automates\nthe end-to-end RAG workflow,",
    "start": "41760",
    "end": "44699"
  },
  {
    "text": "including ingestion, retrieval,\nand prompt augmentation,",
    "start": "44700",
    "end": "47910"
  },
  {
    "text": "eliminating the need for\nyou to write custom code",
    "start": "47910",
    "end": "49980"
  },
  {
    "text": "to integrate data sources\nand manage queries.",
    "start": "49980",
    "end": "52710"
  },
  {
    "text": "Session context management is built in",
    "start": "52710",
    "end": "54750"
  },
  {
    "text": "so your app can support\nmulti-turn conversations.",
    "start": "54750",
    "end": "57870"
  },
  {
    "text": "All the information retrieved\nfrom Knowledge Bases comes",
    "start": "57870",
    "end": "60540"
  },
  {
    "text": "with source citations to\nimprove the transparency",
    "start": "60540",
    "end": "63001"
  },
  {
    "text": "and minimize hallucination.",
    "start": "63001",
    "end": "64773"
  },
  {
    "text": "Let's now head to the AWS console",
    "start": "66150",
    "end": "68010"
  },
  {
    "text": "to build our RAG application.",
    "start": "68010",
    "end": "69483"
  },
  {
    "text": "Here, within the AWS console,",
    "start": "71010",
    "end": "73180"
  },
  {
    "text": "we are on the Amazon Bedrock service page.",
    "start": "73180",
    "end": "76020"
  },
  {
    "text": "Amazon Bedrock offers a diverse\nrange of foundation models,",
    "start": "76020",
    "end": "79590"
  },
  {
    "text": "accessible via a single API",
    "start": "79590",
    "end": "81539"
  },
  {
    "text": "without you having to host them on GPUs.",
    "start": "81540",
    "end": "84060"
  },
  {
    "text": "With Bedrock, you just pay for the input",
    "start": "84060",
    "end": "85420"
  },
  {
    "text": "and output tokens consumed\nas part of your request.",
    "start": "85420",
    "end": "88443"
  },
  {
    "text": "You can click on model access",
    "start": "89610",
    "end": "91410"
  },
  {
    "text": "and go through the list\nof models available",
    "start": "91410",
    "end": "93330"
  },
  {
    "text": "on the Bedrock platform.",
    "start": "93330",
    "end": "95130"
  },
  {
    "text": "Once access has been\ngranted, you can then head",
    "start": "95130",
    "end": "98369"
  },
  {
    "text": "to the Bedrock playground\nmode and try out these models.",
    "start": "98370",
    "end": "102900"
  },
  {
    "text": "You can also compare\nvarious foundation models",
    "start": "102900",
    "end": "106410"
  },
  {
    "text": "on the Bedrock platform.",
    "start": "106410",
    "end": "108030"
  },
  {
    "text": "Let's start with an example.",
    "start": "108030",
    "end": "109443"
  },
  {
    "text": "Let's select Anthropic Claude 3 Sonnet,",
    "start": "112080",
    "end": "114750"
  },
  {
    "text": "and we could choose another model.",
    "start": "114750",
    "end": "116450"
  },
  {
    "text": "Let's go with Anthropic Claude 3 Haiku,",
    "start": "117750",
    "end": "121233"
  },
  {
    "text": "and let's try out a prompt.",
    "start": "124980",
    "end": "127653"
  },
  {
    "text": "Okay, so Haiku gave us a quick response,",
    "start": "135450",
    "end": "139170"
  },
  {
    "text": "and then Sonnet came back later.",
    "start": "139170",
    "end": "140670"
  },
  {
    "text": "Here, we can see details on\nthe input tokens consumed,",
    "start": "140670",
    "end": "144209"
  },
  {
    "text": "the output tokens, and the latency.",
    "start": "144210",
    "end": "147480"
  },
  {
    "text": "Similarly, we have the same\nmetrics for Haiku as well.",
    "start": "147480",
    "end": "150659"
  },
  {
    "text": "Now that we understand a bit\nabout the Bedrock platform,",
    "start": "150660",
    "end": "153180"
  },
  {
    "text": "let's build our RAG application",
    "start": "153180",
    "end": "154530"
  },
  {
    "text": "with Bedrock Knowledge Bases.",
    "start": "154530",
    "end": "155910"
  },
  {
    "text": "For that, you would need to\nclick here on Knowledge Bases.",
    "start": "155910",
    "end": "158810"
  },
  {
    "text": "Now, here, we have an option\nto chat with your document,",
    "start": "160230",
    "end": "162480"
  },
  {
    "text": "which you could explore on your own,",
    "start": "162480",
    "end": "164250"
  },
  {
    "text": "but our goal is to build a\nproduction-ready application",
    "start": "164250",
    "end": "166770"
  },
  {
    "text": "where we have millions of documents",
    "start": "166770",
    "end": "168120"
  },
  {
    "text": "that need to be searched and summarized,",
    "start": "168120",
    "end": "169709"
  },
  {
    "text": "so for that, let's click\non create knowledge base.",
    "start": "169710",
    "end": "172210"
  },
  {
    "text": "Now, let's build a tax advice bot,",
    "start": "174180",
    "end": "176073"
  },
  {
    "text": "so let's give our knowledge\nbase a name, tax advice.",
    "start": "177060",
    "end": "180063"
  },
  {
    "text": "Adding a description is optional,",
    "start": "181440",
    "end": "182880"
  },
  {
    "text": "but let's add a description here.",
    "start": "182880",
    "end": "184177"
  },
  {
    "text": "\"This KBase contains some tax data.\"",
    "start": "184177",
    "end": "187133"
  },
  {
    "text": "The next is IAM permissions.",
    "start": "192810",
    "end": "195090"
  },
  {
    "text": "You will need to create a service role",
    "start": "195090",
    "end": "196470"
  },
  {
    "text": "if you have not created one previously.",
    "start": "196470",
    "end": "198900"
  },
  {
    "text": "This is for Amazon\nBedrock to access services",
    "start": "198900",
    "end": "200640"
  },
  {
    "text": "and APIs on your behalf.",
    "start": "200641",
    "end": "202830"
  },
  {
    "text": "Now, we can select the default option",
    "start": "202830",
    "end": "205620"
  },
  {
    "text": "to create and use a new service role.",
    "start": "205620",
    "end": "207540"
  },
  {
    "text": "Next, we need to choose our data source.",
    "start": "207540",
    "end": "208950"
  },
  {
    "text": "Now, we have a wide\nvariety of data sources",
    "start": "208950",
    "end": "210540"
  },
  {
    "text": "that we can choose from,\nbut for this example,",
    "start": "210540",
    "end": "212415"
  },
  {
    "text": "let's stick to S3, so I have\nall of my tax-related data",
    "start": "212415",
    "end": "215819"
  },
  {
    "text": "in an Amazon S3 bucket.",
    "start": "215820",
    "end": "217083"
  },
  {
    "text": "You have options to tag and set up logging",
    "start": "218580",
    "end": "220470"
  },
  {
    "text": "for your knowledge base here.",
    "start": "220470",
    "end": "222750"
  },
  {
    "text": "Let's hit next. Here, we\nconfigure data sources.",
    "start": "222750",
    "end": "226050"
  },
  {
    "text": "We can attach up to five data sources",
    "start": "226050",
    "end": "227670"
  },
  {
    "text": "with a single knowledge base.",
    "start": "227670",
    "end": "229440"
  },
  {
    "text": "Here, I'll select my S3 bucket",
    "start": "229440",
    "end": "230760"
  },
  {
    "text": "that contains all the\ntax-related information.",
    "start": "230760",
    "end": "233060"
  },
  {
    "text": "Once we've done that, we then\nneed to configure a chunking",
    "start": "236070",
    "end": "238320"
  },
  {
    "text": "and parsing strategy.",
    "start": "238320",
    "end": "239700"
  },
  {
    "text": "We could just go with the defaults",
    "start": "239700",
    "end": "241080"
  },
  {
    "text": "or customize it as per our use case.",
    "start": "241080",
    "end": "243210"
  },
  {
    "text": "Bedrock offers a parsing strategy",
    "start": "243210",
    "end": "244950"
  },
  {
    "text": "to extract tabular data to keep it intact,",
    "start": "244950",
    "end": "247230"
  },
  {
    "text": "and you could select a\nfoundation model for doing so.",
    "start": "247230",
    "end": "249390"
  },
  {
    "text": "It also offers a chunking strategy.",
    "start": "249390",
    "end": "251130"
  },
  {
    "text": "Let's pick the fixed\nchunking strategy here,",
    "start": "251130",
    "end": "253860"
  },
  {
    "text": "and let's select max tokens as 500",
    "start": "253860",
    "end": "256536"
  },
  {
    "text": "and a chunk overlap percentage of 10.",
    "start": "256537",
    "end": "258693"
  },
  {
    "text": "This overlap maintains some context",
    "start": "261480",
    "end": "263151"
  },
  {
    "text": "and continuity between chunks.",
    "start": "263151",
    "end": "265860"
  },
  {
    "text": "You could further customize\nthe chunking behavior",
    "start": "265860",
    "end": "268202"
  },
  {
    "text": "and the document metadata\nprocessing in a Lambda function",
    "start": "268203",
    "end": "271783"
  },
  {
    "text": "and attach it here.",
    "start": "271783",
    "end": "274050"
  },
  {
    "text": "The next thing to do is to\nselect an embeddings model.",
    "start": "274050",
    "end": "276840"
  },
  {
    "text": "There are multiple options available here.",
    "start": "276840",
    "end": "278520"
  },
  {
    "text": "Let's go with the Embed\nEnglish V3 model by Cohere here",
    "start": "278520",
    "end": "281460"
  },
  {
    "text": "that offers 1024 dimensions.",
    "start": "281460",
    "end": "283443"
  },
  {
    "text": "Now, this model will create\nthe embeddings for our data,",
    "start": "286740",
    "end": "289620"
  },
  {
    "text": "which will then be chunked and\nstored in our vector database",
    "start": "289620",
    "end": "291900"
  },
  {
    "text": "as per our configuration.",
    "start": "291900",
    "end": "293163"
  },
  {
    "text": "So the next step is to\nselect a vector database",
    "start": "294630",
    "end": "297750"
  },
  {
    "text": "where we store these embeddings.",
    "start": "297750",
    "end": "299640"
  },
  {
    "text": "Vector databases store the\nnumerical representation",
    "start": "299640",
    "end": "302070"
  },
  {
    "text": "of our data, and this allows them",
    "start": "302070",
    "end": "303450"
  },
  {
    "text": "to perform similarity searches\non our stored documents.",
    "start": "303450",
    "end": "306780"
  },
  {
    "text": "Here, we will go with\na quick create option.",
    "start": "306780",
    "end": "309510"
  },
  {
    "text": "An Amazon OpenSearch\nServerless vector collection",
    "start": "309510",
    "end": "311391"
  },
  {
    "text": "is created on your behalf.",
    "start": "311391",
    "end": "313380"
  },
  {
    "text": "There are also other options\nthat you could explore.",
    "start": "313380",
    "end": "315893"
  },
  {
    "text": "We support third-party\nvector databases as well,",
    "start": "317130",
    "end": "320130"
  },
  {
    "text": "such as Pinecone, MongoDB,\nAtlas, Redis Enterprise Cloud.",
    "start": "320130",
    "end": "324303"
  },
  {
    "text": "Now, let's click next and\nreview our KBase configuration.",
    "start": "325920",
    "end": "329373"
  },
  {
    "text": "After you've validated the configuration,",
    "start": "338670",
    "end": "340230"
  },
  {
    "text": "you can click on create knowledge base.",
    "start": "340230",
    "end": "342300"
  },
  {
    "text": "Now, depending on which\nvector database you've chosen,",
    "start": "342300",
    "end": "343970"
  },
  {
    "text": "it would take anywhere\nbetween 30 to 15 minutes",
    "start": "343971",
    "end": "345990"
  },
  {
    "text": "to set up your knowledge base.",
    "start": "345990",
    "end": "347490"
  },
  {
    "text": "Here, I'll pause the video",
    "start": "347490",
    "end": "349259"
  },
  {
    "text": "and get back when my\nknowledge base is set up.",
    "start": "349260",
    "end": "351503"
  },
  {
    "text": "So here, we have knowledge base created.",
    "start": "354720",
    "end": "358350"
  },
  {
    "text": "It roughly took around 10 minutes",
    "start": "358350",
    "end": "359880"
  },
  {
    "text": "to create this knowledge base.",
    "start": "359880",
    "end": "361800"
  },
  {
    "text": "Now, let's look at what all\nBedrock has created for us.",
    "start": "361800",
    "end": "364919"
  },
  {
    "text": "So the first thing that we can look at",
    "start": "364920",
    "end": "366162"
  },
  {
    "text": "is the Amazon OpenSearch\nServerless vector database here,",
    "start": "366162",
    "end": "369663"
  },
  {
    "text": "so Bedrock has created",
    "start": "370770",
    "end": "372120"
  },
  {
    "text": "a serverless vector collection for us.",
    "start": "372120",
    "end": "374610"
  },
  {
    "text": "Let's review that.",
    "start": "374610",
    "end": "375723"
  },
  {
    "text": "Let's go to Amazon OpenSearch service,",
    "start": "376560",
    "end": "379623"
  },
  {
    "text": "and here, let's look at\nserverless collections.",
    "start": "385170",
    "end": "388473"
  },
  {
    "text": "Now, here, we have a\nBedrock knowledge base.",
    "start": "391050",
    "end": "394319"
  },
  {
    "text": "Let's click on this.",
    "start": "394320",
    "end": "396120"
  },
  {
    "text": "Actually, let's click on\nthe OpenSearch dashboard,",
    "start": "396120",
    "end": "399960"
  },
  {
    "text": "and let's see if we have some data here",
    "start": "399960",
    "end": "402660"
  },
  {
    "text": "in our vector database,",
    "start": "402660",
    "end": "404340"
  },
  {
    "text": "so let's just fire this default query",
    "start": "404340",
    "end": "406980"
  },
  {
    "text": "and see if it returns any results.",
    "start": "406980",
    "end": "409863"
  },
  {
    "text": "So right now, we do not have any data",
    "start": "412830",
    "end": "414758"
  },
  {
    "text": "in our vector database.",
    "start": "414759",
    "end": "416883"
  },
  {
    "text": "Now, let's go back to our knowledge base,",
    "start": "418350",
    "end": "420750"
  },
  {
    "text": "and let's click on the radio button next",
    "start": "420750",
    "end": "423570"
  },
  {
    "text": "to our S3 data source.",
    "start": "423570",
    "end": "425403"
  },
  {
    "text": "Let's click on sync.",
    "start": "429150",
    "end": "430503"
  },
  {
    "text": "Syncing should take anywhere\nfrom a couple of minutes",
    "start": "433230",
    "end": "436980"
  },
  {
    "text": "to a few hours, depending\non the number of documents",
    "start": "436980",
    "end": "440100"
  },
  {
    "text": "in your S3 bucket.",
    "start": "440100",
    "end": "441240"
  },
  {
    "text": "Here, we have roughly\nfive to six documents,",
    "start": "441240",
    "end": "444539"
  },
  {
    "text": "so syncing should be faster.",
    "start": "444540",
    "end": "446730"
  },
  {
    "text": "During the sync process,\nAmazon Bedrock Knowledge Base",
    "start": "446730",
    "end": "450270"
  },
  {
    "text": "is fetching the data from the S3 bucket.",
    "start": "450270",
    "end": "452940"
  },
  {
    "text": "It's then chunking the data",
    "start": "452940",
    "end": "453953"
  },
  {
    "text": "as per our defined chunking strategy",
    "start": "453953",
    "end": "456570"
  },
  {
    "text": "and then passing those\nchunks to our embedding model",
    "start": "456570",
    "end": "459150"
  },
  {
    "text": "that's generating embeddings for our data.",
    "start": "459150",
    "end": "462030"
  },
  {
    "text": "Once the embeddings are\ngenerated, it's then stored",
    "start": "462030",
    "end": "464285"
  },
  {
    "text": "in our Amazon OpenSearch\nServerless vector collection.",
    "start": "464285",
    "end": "467883"
  },
  {
    "text": "So syncing the S3 data\nwith the vector database",
    "start": "469620",
    "end": "471990"
  },
  {
    "text": "took around five minutes.",
    "start": "471990",
    "end": "473699"
  },
  {
    "text": "We can check the sync history",
    "start": "473700",
    "end": "474990"
  },
  {
    "text": "by clicking on the data source,",
    "start": "474990",
    "end": "477060"
  },
  {
    "text": "and it tells you that we had\nsix source files, one failed,",
    "start": "477060",
    "end": "480270"
  },
  {
    "text": "and five were added.",
    "start": "480270",
    "end": "481919"
  },
  {
    "text": "We can further investigate the fail reason",
    "start": "481920",
    "end": "483750"
  },
  {
    "text": "by clicking on view warnings.",
    "start": "483750",
    "end": "485220"
  },
  {
    "text": "We can retry the sync once\nwe've fixed the issue.",
    "start": "485220",
    "end": "488370"
  },
  {
    "text": "Now, let's quickly head\nto our vector database",
    "start": "488370",
    "end": "490440"
  },
  {
    "text": "and confirm that the data exists in there.",
    "start": "490440",
    "end": "493143"
  },
  {
    "text": "So here, let's click on\nour vector collection,",
    "start": "494010",
    "end": "495630"
  },
  {
    "text": "and let's go to indexes.",
    "start": "495630",
    "end": "497850"
  },
  {
    "text": "Here, we have roughly 38 MB of\ndata in our vector database,",
    "start": "497850",
    "end": "500940"
  },
  {
    "text": "and around 2,000 chunks indexed.",
    "start": "500940",
    "end": "503853"
  },
  {
    "text": "We can further check the configuration",
    "start": "504990",
    "end": "506418"
  },
  {
    "text": "of the index created by\nthe Bedrock Knowledge Base.",
    "start": "506419",
    "end": "509613"
  },
  {
    "text": "So here, we can click on the index",
    "start": "510540",
    "end": "514020"
  },
  {
    "text": "and look for additional configuration.",
    "start": "514020",
    "end": "515920"
  },
  {
    "text": "So here, we have more information.",
    "start": "516960",
    "end": "518729"
  },
  {
    "text": "It's using Faiss for\nnearest neighbor search,",
    "start": "518730",
    "end": "521131"
  },
  {
    "text": "it's using Euclidean distance type,",
    "start": "521132",
    "end": "523140"
  },
  {
    "text": "and the vector field has 1024 dimensions.",
    "start": "523140",
    "end": "525450"
  },
  {
    "text": "Similarly, we have some\nadditional metadata in here",
    "start": "525450",
    "end": "527908"
  },
  {
    "text": "along with their data type.",
    "start": "527908",
    "end": "529683"
  },
  {
    "text": "So it stores the source\nURI of the document,",
    "start": "530760",
    "end": "532890"
  },
  {
    "text": "the page number, a\nunique ID, and much more.",
    "start": "532890",
    "end": "535563"
  },
  {
    "text": "If you intend to deep dive,\nyou could verify the data",
    "start": "536940",
    "end": "540120"
  },
  {
    "text": "by going to OpenSearch dashboards",
    "start": "540120",
    "end": "542010"
  },
  {
    "text": "and firing the default query.",
    "start": "542010",
    "end": "543960"
  },
  {
    "text": "As you recall, previously, we\ndidn't have any data in here,",
    "start": "543960",
    "end": "547320"
  },
  {
    "text": "but now that we have ingested documents",
    "start": "547320",
    "end": "548910"
  },
  {
    "text": "through Bedrock Knowledge Base,",
    "start": "548910",
    "end": "549930"
  },
  {
    "text": "we can see our chunked\nand embedded data in here.",
    "start": "549930",
    "end": "552543"
  },
  {
    "text": "This is our vector field on\nwhich similarity searches",
    "start": "553500",
    "end": "556696"
  },
  {
    "text": "will be performed, and this\nis our passage, or chunk,",
    "start": "556696",
    "end": "561420"
  },
  {
    "text": "that's used for source\ncitations by the knowledge base.",
    "start": "561420",
    "end": "564209"
  },
  {
    "text": "Now that we see the data in here,",
    "start": "564210",
    "end": "565590"
  },
  {
    "text": "it's time to put our\nknowledge base to the test,",
    "start": "565590",
    "end": "567840"
  },
  {
    "text": "so let's head back to our knowledge base,",
    "start": "567840",
    "end": "569520"
  },
  {
    "text": "and let's select a foundation model.",
    "start": "569520",
    "end": "571320"
  },
  {
    "text": "In this case, let's go\nwith Claude 3 Haiku.",
    "start": "572756",
    "end": "575493"
  },
  {
    "text": "As you can see, it's\ngiving me relevant data.",
    "start": "591510",
    "end": "593370"
  },
  {
    "text": "It's also giving me source details,",
    "start": "593370",
    "end": "595290"
  },
  {
    "text": "which is very important for provenance,",
    "start": "595290",
    "end": "596910"
  },
  {
    "text": "which is important, especially\nin legal and finance domains.",
    "start": "596910",
    "end": "600420"
  },
  {
    "text": "So here, we have source details",
    "start": "600420",
    "end": "601740"
  },
  {
    "text": "and the metadata\nassociated with the chunk.",
    "start": "601740",
    "end": "604050"
  },
  {
    "text": "Here, we can also see from\nwhich document this chunk",
    "start": "604050",
    "end": "606358"
  },
  {
    "text": "or this data was summarized.",
    "start": "606358",
    "end": "608876"
  },
  {
    "text": "In order to build a chat bot\nusing Bedrock Knowledge Bases,",
    "start": "608877",
    "end": "612570"
  },
  {
    "text": "you would have to interact\nwith knowledge base APIs.",
    "start": "612570",
    "end": "616050"
  },
  {
    "text": "The two prominent APIs that\nyou would have to interact with",
    "start": "616050",
    "end": "619290"
  },
  {
    "text": "is the retrieve API and the\nretrieve and generate API.",
    "start": "619290",
    "end": "623040"
  },
  {
    "text": "The retrieve API is solely responsible",
    "start": "623040",
    "end": "625170"
  },
  {
    "text": "for fetching the documents,",
    "start": "625170",
    "end": "626399"
  },
  {
    "text": "fetching the data from\nyour vector database,",
    "start": "626400",
    "end": "628710"
  },
  {
    "text": "whereas the retrieve and\ngenerate API is responsible",
    "start": "628710",
    "end": "631350"
  },
  {
    "text": "for fetching the data\nfrom the vector database",
    "start": "631350",
    "end": "634334"
  },
  {
    "text": "as well as passing on that\ninformation to a foundation model",
    "start": "634335",
    "end": "636900"
  },
  {
    "text": "and generating the\nresponse from that model",
    "start": "636900",
    "end": "639990"
  },
  {
    "text": "and giving you the final output.",
    "start": "639990",
    "end": "641733"
  },
  {
    "text": "Hope you enjoyed tuning in.\nThat's all for today's video.",
    "start": "643830",
    "end": "647940"
  },
  {
    "text": "Thanks for watching.",
    "start": "647940",
    "end": "648993"
  }
]
[
  {
    "start": "0",
    "end": "120000"
  },
  {
    "text": "and this session is going to be focusing on Amazon sage maker and discuss the",
    "start": "0",
    "end": "5400"
  },
  {
    "text": "different opportunities and and and things that you can do with sage maker and cooperation with other AWS services",
    "start": "5400",
    "end": "13190"
  },
  {
    "text": "it assumes no knowledge or background on on data science itself and we'll just be",
    "start": "13190",
    "end": "21180"
  },
  {
    "text": "basically talking to how to build machine learning models whether you're a developer or data scientist so let's go",
    "start": "21180",
    "end": "28019"
  },
  {
    "text": "ahead and jump right in so looking first at what's happening in the industry and",
    "start": "28019",
    "end": "34290"
  },
  {
    "text": "obviously we see a large volume of discussion around AI and ml but specific",
    "start": "34290",
    "end": "40920"
  },
  {
    "text": "to a lot of use cases we do see the same kind of things coming up again and again we look at things like image recognition",
    "start": "40920",
    "end": "47550"
  },
  {
    "text": "so computer vision applied to image recognition to identify whether there's",
    "start": "47550",
    "end": "52559"
  },
  {
    "text": "a cat or a dog in a a photo as an example or to be able to detect how many cats do we see inside the photo using",
    "start": "52559",
    "end": "59550"
  },
  {
    "text": "single-shot detectors for object detection the speech recognition is very",
    "start": "59550",
    "end": "64768"
  },
  {
    "text": "popular and voice user interfaces are being developed things like Amazon Alexa as a example of that it's been largely",
    "start": "64769",
    "end": "73290"
  },
  {
    "text": "very popular consumer device and in the use of speech whether it be voiced text",
    "start": "73290",
    "end": "80460"
  },
  {
    "text": "or text voice is a really popular use case for machine learning and of course",
    "start": "80460",
    "end": "85590"
  },
  {
    "text": "anybody who is involved with any trading strategies where there's automated training and we know that that's a very",
    "start": "85590",
    "end": "91560"
  },
  {
    "text": "large-scale effort obviously those have to be driven by some form of algorithm",
    "start": "91560",
    "end": "96720"
  },
  {
    "text": "and machine learning is a very popular approach to achieving that and finally being able to do sentiment analysis and",
    "start": "96720",
    "end": "103649"
  },
  {
    "text": "do it in an automated fashion against whether it be your Twitter feed or your Facebook feed or or whatnot so this",
    "start": "103649",
    "end": "111210"
  },
  {
    "text": "obviously these are use cases that apply across many different industries and so these are things you can be thinking",
    "start": "111210",
    "end": "117240"
  },
  {
    "text": "about as we talk about specifically how we build machine learning now when we",
    "start": "117240",
    "end": "122579"
  },
  {
    "start": "120000",
    "end": "160000"
  },
  {
    "text": "look at Amazon itself amazon.com we've actually been involved with this for a very long time",
    "start": "122579",
    "end": "128700"
  },
  {
    "text": "we started back in 97 with a recommendation service for No education so that if your based on your",
    "start": "128700",
    "end": "136050"
  },
  {
    "text": "past purchase history that you'd be notified via email of a recommendation",
    "start": "136050",
    "end": "141690"
  },
  {
    "text": "for a book or something that nature and so that was probably largely manual at",
    "start": "141690",
    "end": "148349"
  },
  {
    "text": "the time but certainly there was a there is a element that was you know done the",
    "start": "148349",
    "end": "153750"
  },
  {
    "text": "spreadsheets and finally into real true machine learning and and so we've been doing this for a very long time and",
    "start": "153750",
    "end": "160489"
  },
  {
    "start": "160000",
    "end": "260000"
  },
  {
    "text": "since then we've grown our team to more than thousands of we have thousands of engineers that are focused specifically",
    "start": "160489",
    "end": "168390"
  },
  {
    "text": "on machine learning today and if we think about the categories or the areas that we focus that effort on we could",
    "start": "168390",
    "end": "175140"
  },
  {
    "text": "first look at fulfillment and logistics and that first element is when we think about our Amazon robotics formerly kevo",
    "start": "175140",
    "end": "182940"
  },
  {
    "text": "robotics it's about lifting up shelves and racks and bringing those to our",
    "start": "182940",
    "end": "188220"
  },
  {
    "text": "Pickers in our in our fulfillment or warehouse operations as well as",
    "start": "188220",
    "end": "193410"
  },
  {
    "text": "monitoring the supply chain and recommending best routing for product",
    "start": "193410",
    "end": "198709"
  },
  {
    "text": "search and discovery very common use case where you need to be able to find",
    "start": "198709",
    "end": "203760"
  },
  {
    "text": "among millions of items that's a very common use case on amazon.com you look",
    "start": "203760",
    "end": "209640"
  },
  {
    "text": "at things like taking existing products and and adding new features to them to extend those features those products",
    "start": "209640",
    "end": "216630"
  },
  {
    "text": "with these AI and m/l features and so you can think about if you have access",
    "start": "216630",
    "end": "222900"
  },
  {
    "text": "to Amazon Kindle there's an x-ray feature it's also available inside our",
    "start": "222900",
    "end": "228560"
  },
  {
    "text": "video which allows you to better drill in and understand the content also this",
    "start": "228560",
    "end": "234930"
  },
  {
    "text": "can lead to completely new products right so the idea is that your voice user interface the popular the Alexa",
    "start": "234930",
    "end": "241560"
  },
  {
    "text": "that was a completely new product a new service such as Amazon Go which we'll",
    "start": "241560",
    "end": "247739"
  },
  {
    "text": "talk about briefly and finally the idea is that we apply that machine learning back into AWS to try to help our",
    "start": "247739",
    "end": "254819"
  },
  {
    "text": "customers millions of customers to develop solutions of for their customers",
    "start": "254819",
    "end": "259850"
  },
  {
    "text": "so we look at amazon.com for a common website you see that that recommended",
    "start": "259850",
    "end": "266230"
  },
  {
    "start": "260000",
    "end": "282000"
  },
  {
    "text": "engine has evolved over the years and now you see things that are items related to things that you viewed or",
    "start": "266230",
    "end": "272080"
  },
  {
    "text": "similar items have been purchased by others many recommendations form the content that you experience when you're",
    "start": "272080",
    "end": "278050"
  },
  {
    "text": "on amazon.com if you look at the Alexa devices we've actually evolved that",
    "start": "278050",
    "end": "283870"
  },
  {
    "start": "282000",
    "end": "317000"
  },
  {
    "text": "device platform first we introduced that and as a household device that would",
    "start": "283870",
    "end": "289840"
  },
  {
    "text": "allow you to interact with it without a keyboard without a mouse and to be able",
    "start": "289840",
    "end": "294970"
  },
  {
    "text": "to do it in a natural way using Artemis speech recognition and natural language understanding so we've",
    "start": "294970",
    "end": "301540"
  },
  {
    "text": "even involved that product further by adding in video screens because the idea of being that sometimes the information",
    "start": "301540",
    "end": "308260"
  },
  {
    "text": "can be communicated back to you from that device in a visual form and that's actually sometimes more efficient so we",
    "start": "308260",
    "end": "316930"
  },
  {
    "text": "also have this retail new retail concept called Amazon go and this is the",
    "start": "316930",
    "end": "322420"
  },
  {
    "start": "317000",
    "end": "359000"
  },
  {
    "text": "experience of a cashier --less store experience or consumer experience so the",
    "start": "322420",
    "end": "328810"
  },
  {
    "text": "idea being that consumers can enter the store that they can they can pick up any objects that they wished the purchase",
    "start": "328810",
    "end": "335830"
  },
  {
    "text": "and they just walk out from the store and it uses things like computer vision",
    "start": "335830",
    "end": "340900"
  },
  {
    "text": "and sensor fusion RFID technology be able to identify what were the items",
    "start": "340900",
    "end": "346030"
  },
  {
    "text": "that were picked up by the consumers and then later charge them to their account so again removing essentially friction",
    "start": "346030",
    "end": "353380"
  },
  {
    "text": "from the experience of purchasing product in a convenience store setting so when we think about all the different",
    "start": "353380",
    "end": "361270"
  },
  {
    "text": "areas that we've touched on 20 years you can see there's a wealth of different areas demand forecasting obviously very",
    "start": "361270",
    "end": "367000"
  },
  {
    "text": "large part of our operations machine translation robotics and so we have a",
    "start": "367000",
    "end": "373360"
  },
  {
    "text": "very large story and a lot that we can share that leads us to a discussion",
    "start": "373360",
    "end": "379570"
  },
  {
    "text": "about eight of us and m/l at AWS and what our mission is and really it's all about democratizing AI and ml and we",
    "start": "379570",
    "end": "387820"
  },
  {
    "start": "381000",
    "end": "403000"
  },
  {
    "text": "want to put machine learning in the hands of every developer and data scientist so everything we talk about",
    "start": "387820",
    "end": "393940"
  },
  {
    "text": "today is really geared or focused towards enabling even developers to be",
    "start": "393940",
    "end": "399070"
  },
  {
    "text": "able to they machine learning today so when we think about the the wealth of different",
    "start": "399070",
    "end": "406029"
  },
  {
    "text": "customers of the broad range and deep range of use of AWS for machine learning",
    "start": "406029",
    "end": "412240"
  },
  {
    "text": "it's quite a bit and you can look and see you know as a premier customer example you can look and see Pinterest",
    "start": "412240",
    "end": "419139"
  },
  {
    "text": "which is as an alts visual search it does that on AWS in terms of building",
    "start": "419139",
    "end": "424659"
  },
  {
    "text": "the machine learning as well as hosting that you can also see that there's Capital One which is the largest credit",
    "start": "424659",
    "end": "430479"
  },
  {
    "text": "card issuer in the US so the idea being that when they want to build their vision their voice user interfaces and",
    "start": "430479",
    "end": "436839"
  },
  {
    "text": "they're different different products and fraud monitoring that's something that",
    "start": "436839",
    "end": "441999"
  },
  {
    "text": "the capital one chooses AWS for and FINRA which monitors more than fifty billion market transactions every day",
    "start": "441999",
    "end": "448990"
  },
  {
    "text": "that happen on NASDAQ and New York Stock Exchange and other exchanges and",
    "start": "448990",
    "end": "454019"
  },
  {
    "text": "detecting fraud or some collusion or activity that's that's being regulated",
    "start": "454019",
    "end": "459550"
  },
  {
    "text": "by the US government all that's happening on AWS and using machine",
    "start": "459550",
    "end": "464649"
  },
  {
    "text": "learning to do that it's being built by FINRA on AWS so looking at the overall",
    "start": "464649",
    "end": "473050"
  },
  {
    "text": "story of what does that comprise because you can think about this actually in three different layers you can think",
    "start": "473050",
    "end": "479289"
  },
  {
    "text": "about users who just simply want an API driven black box approach they owe it to",
    "start": "479289",
    "end": "485529"
  },
  {
    "text": "AI and machine learning so they can leverage some of these services at the very top layer called application",
    "start": "485529",
    "end": "492759"
  },
  {
    "text": "services here we have things like recognition which allow them to do computer vision and analyze do facial",
    "start": "492759",
    "end": "498939"
  },
  {
    "text": "sentiment analysis or to detect similarity between faces so these that's",
    "start": "498939",
    "end": "505990"
  },
  {
    "text": "feature of recognition if you look at transcribe the ability to take voice and turn it into text as well as translate",
    "start": "505990",
    "end": "513490"
  },
  {
    "text": "which goes between 24 different language pairs today we have Pali which allows",
    "start": "513490",
    "end": "519370"
  },
  {
    "text": "you to do natural sounding text-to-speech and is used by companies like duolingo who chose it over a number",
    "start": "519370",
    "end": "525939"
  },
  {
    "text": "of other competitors because they found it was the best performing and the most natural sounding voice they could find",
    "start": "525939",
    "end": "532880"
  },
  {
    "text": "and also you have comprehend which allows you to do better text analysis to",
    "start": "532880",
    "end": "538250"
  },
  {
    "text": "be able to understand what topics are being discussed or any sentiment within the text and Lex which is the same kind",
    "start": "538250",
    "end": "546410"
  },
  {
    "text": "of technology that drives our Alexa device platform and provides a natural",
    "start": "546410",
    "end": "552170"
  },
  {
    "text": "language understanding as well as a voice piece which allows you to build a",
    "start": "552170",
    "end": "559040"
  },
  {
    "text": "complete automated voices or interface solution i particularly if you want to",
    "start": "559040",
    "end": "564740"
  },
  {
    "text": "build a chatbot so those services are available where there is not a fit where",
    "start": "564740",
    "end": "570950"
  },
  {
    "text": "there's a need to go deeper that's where customers will start looking at the next layer down so one of",
    "start": "570950",
    "end": "577520"
  },
  {
    "text": "the first areas that one that we'll be discussing in depth is Amazon Sage maker",
    "start": "577520",
    "end": "583400"
  },
  {
    "text": "and it is a managed machine learning solution which allows you to do building",
    "start": "583400",
    "end": "588410"
  },
  {
    "text": "training and deploying your machine learning models and basically removes a",
    "start": "588410",
    "end": "593540"
  },
  {
    "text": "lot of the undifferentiated heavy lifting that for years a lot of data scientists have been left to do on their",
    "start": "593540",
    "end": "600620"
  },
  {
    "text": "own or develop solutions custom bespoke solutions but in this case sage maker",
    "start": "600620",
    "end": "606590"
  },
  {
    "text": "takes care of lot of that for you Amazon EMR which is a traditional product we've had it around for quite a",
    "start": "606590",
    "end": "612800"
  },
  {
    "text": "while and that's being used for Hadoop and spark workloads but specifically for machine learning you know customers who",
    "start": "612800",
    "end": "619580"
  },
  {
    "text": "are using spark they'll often be using spark and melsmel that live to leverage",
    "start": "619580",
    "end": "625040"
  },
  {
    "text": "that for doing machine learning for both training the models as well as doing inference as part of a batch process so",
    "start": "625040",
    "end": "631430"
  },
  {
    "text": "that's always available as well to our customers Amazon Mechanical Turk which",
    "start": "631430",
    "end": "637430"
  },
  {
    "text": "is a crowdsourcing platform which allows you to take you know a lot of the challenge of machine learning is",
    "start": "637430",
    "end": "643640"
  },
  {
    "text": "labeling data so it allows you to leverage the resources worldwide of",
    "start": "643640",
    "end": "648790"
  },
  {
    "text": "several million people to be able to bid out and receive back labelled data which",
    "start": "648790",
    "end": "656330"
  },
  {
    "text": "then helps to train better and better models and also we have finally theta of",
    "start": "656330",
    "end": "661640"
  },
  {
    "text": "SD plans which was just launched reinvent this past year and then it includes the capabilities to deploy small devices for",
    "start": "661640",
    "end": "669500"
  },
  {
    "text": "proof of concept and tend to disprove concept device but it allows you to test out ideas quickly around computer vision",
    "start": "669500",
    "end": "675620"
  },
  {
    "text": "so that you can deploy a model from something like sage maker and then detect detect faces or detect cat versus",
    "start": "675620",
    "end": "684110"
  },
  {
    "text": "dog or these other computer vision tasks and then finally when we look at the",
    "start": "684110",
    "end": "689180"
  },
  {
    "text": "lowest tier the lowest layer this is really where the heavy lifting occurs",
    "start": "689180",
    "end": "695150"
  },
  {
    "text": "and this is where customers who really wish to have complete access to the operating system to be able to do",
    "start": "695150",
    "end": "701390"
  },
  {
    "text": "everything and anything to achieve the exact requirements that they have can",
    "start": "701390",
    "end": "708020"
  },
  {
    "text": "leverage things like our deep learning ami and that deep learning ami has within it several different open source",
    "start": "708020",
    "end": "714680"
  },
  {
    "text": "frameworks as well as the drivers that are required for you to be able to leverage GPU processing from the Nvidia",
    "start": "714680",
    "end": "721760"
  },
  {
    "text": "the latest Nvidia processors so the idea is that out of the box you can spin up an instance an ec2 instance our virtual",
    "start": "721760",
    "end": "729650"
  },
  {
    "text": "server instances using the deep learning ami that's available from a marketplace they had no cost and use these open",
    "start": "729650",
    "end": "737930"
  },
  {
    "text": "source tools and be able to immediately gain some some value but do exactly what",
    "start": "737930",
    "end": "743660"
  },
  {
    "text": "you want to achieve without without any burden between you and the actual",
    "start": "743660",
    "end": "749230"
  },
  {
    "text": "low-level operating system and the and the hardware then rely hired work and of",
    "start": "749230",
    "end": "754700"
  },
  {
    "text": "course all this is within a framework of AWS services that surround that including things like Amazon s3 and",
    "start": "754700",
    "end": "761210"
  },
  {
    "text": "we'll talk briefly on that topic because it is a centerpiece to a lot of this because it involves object storage and",
    "start": "761210",
    "end": "768800"
  },
  {
    "text": "the ability to pull data in for training as well as storing that models that are",
    "start": "768800",
    "end": "774800"
  },
  {
    "text": "created from the training process so let's review the typical ml process we",
    "start": "774800",
    "end": "782930"
  },
  {
    "start": "775000",
    "end": "1207000"
  },
  {
    "text": "always start with a business problem we need to focus ourselves on what is the thing that needs to be achieved before",
    "start": "782930",
    "end": "789770"
  },
  {
    "text": "we even set about identifying data that's required and building models so you know we have the business problem we",
    "start": "789770",
    "end": "796550"
  },
  {
    "text": "frame that as an ml problem the ml problem framing is to be focused on identifying what are",
    "start": "796550",
    "end": "802310"
  },
  {
    "text": "the key success criterias that need to be addressed so what is the level of confidence that you need from your",
    "start": "802310",
    "end": "808730"
  },
  {
    "text": "predictions what are you trying to predict you know do you need a human and loop just defining that and better",
    "start": "808730",
    "end": "814970"
  },
  {
    "text": "before we even start out on your task so you can define success before you start so next you look at a lot of the heavy",
    "start": "814970",
    "end": "822950"
  },
  {
    "text": "lifting that happens within data collection integration it's about",
    "start": "822950",
    "end": "827990"
  },
  {
    "text": "identifying what data sources exist that are relevant to that that machine learning problem and being able to then",
    "start": "827990",
    "end": "834740"
  },
  {
    "text": "clean that data or identify issues of that data or missing data and determine how you want to deal with that so it's",
    "start": "834740",
    "end": "841730"
  },
  {
    "text": "all about the pre process before you get to the actual training of machine learning models and that's a majority of",
    "start": "841730",
    "end": "848600"
  },
  {
    "text": "the effort of data scientists today and then the next step is about ad hoc",
    "start": "848600",
    "end": "855020"
  },
  {
    "text": "analysis from visualization of that data to bill identify you know different correlations and patterns that data and",
    "start": "855020",
    "end": "861770"
  },
  {
    "text": "identify what is believed to be the relevant features from what what's been found but impossibly doing feature",
    "start": "861770",
    "end": "869360"
  },
  {
    "text": "augmentation feature or engineering around that and then that box of model training and parameter tuning becomes",
    "start": "869360",
    "end": "875870"
  },
  {
    "text": "your next heavy lifting and that's basically about running the models",
    "start": "875870",
    "end": "881450"
  },
  {
    "text": "sorry training the models fitting the models and identifying the success of",
    "start": "881450",
    "end": "886640"
  },
  {
    "text": "those models and then identifying the hyper parameters that that led to that",
    "start": "886640",
    "end": "891650"
  },
  {
    "text": "success the hyper parameters being the metadata that essentially tells how the training process will will be handled",
    "start": "891650",
    "end": "899120"
  },
  {
    "text": "and then finally you have a model evaluation step of course so this",
    "start": "899120",
    "end": "904220"
  },
  {
    "text": "becomes an iterative process you don't train once you often train multiple times you just keep going back and back",
    "start": "904220",
    "end": "909880"
  },
  {
    "text": "trying to find the best results and it's never a job that's completed so if we",
    "start": "909880",
    "end": "917240"
  },
  {
    "text": "look at the end of them we actually would have to identify with that model",
    "start": "917240",
    "end": "922760"
  },
  {
    "text": "evaluated did it succeed at achieving our business problem or meeting our",
    "start": "922760",
    "end": "928310"
  },
  {
    "text": "business problem and achieving that ml problem statement and if you say no then of course you're",
    "start": "928310",
    "end": "934790"
  },
  {
    "text": "augmenting data you have to go out and identify other additional data sources are there are the things that you need",
    "start": "934790",
    "end": "939889"
  },
  {
    "text": "to do to address this maybe there's completely missing data and you have to start from scratch to start looking at",
    "start": "939889",
    "end": "945769"
  },
  {
    "text": "what else needs to be collected but then you also could potentially say that you",
    "start": "945769",
    "end": "952130"
  },
  {
    "text": "need to do a bit deeper dive on the features themselves and there can be feature argumentation techniques could",
    "start": "952130",
    "end": "957980"
  },
  {
    "text": "be applied the data in order to synthesize or add additional features that can help to guide a better outcome",
    "start": "957980",
    "end": "967070"
  },
  {
    "text": "for your model evaluation and finally if your business goals are met then you can",
    "start": "967070",
    "end": "972380"
  },
  {
    "text": "move forward but your jobs not done and that's where you have to actually take the model that you've you've created and",
    "start": "972380",
    "end": "979250"
  },
  {
    "text": "you have to deliver it into production and that becomes a real challenge because now you're asked to basically",
    "start": "979250",
    "end": "985339"
  },
  {
    "text": "deploy and to do continuous deployment I'd do a kind of DevOps approach in",
    "start": "985339",
    "end": "990410"
  },
  {
    "text": "terms of how you're gonna slipstream that new model into production and then how do you monitor that endpoint how do",
    "start": "990410",
    "end": "996290"
  },
  {
    "text": "you scale at endpoint so this becomes a challenge because now you're throwing",
    "start": "996290",
    "end": "1001389"
  },
  {
    "text": "that model over the wall and somebody else is responsible for it but but someone on the data engineering team or",
    "start": "1001389",
    "end": "1007060"
  },
  {
    "text": "even the data scientist has to be responsible for doing that last mile of delivering the model into production so",
    "start": "1007060",
    "end": "1013779"
  },
  {
    "text": "and eventually of course you're capturing data and you're you're putting that back in and you're retraining based",
    "start": "1013779",
    "end": "1019870"
  },
  {
    "text": "on this additional data you're hoping you're going to get better and better results over time so if we break this",
    "start": "1019870",
    "end": "1025630"
  },
  {
    "text": "out as what is AWS do for you well with the first block we can't do a lot other",
    "start": "1025630",
    "end": "1032678"
  },
  {
    "text": "than to give you advice about what we've seen as I started the conversation with different ml use cases that we observe",
    "start": "1032679",
    "end": "1038640"
  },
  {
    "text": "and we do have a resource called ml solutions lab owl and I'll mention it towards the end again which can help you",
    "start": "1038640",
    "end": "1046449"
  },
  {
    "text": "a bit with that we also have Pro serve resources we can do discovery workshops but at the end of the day it's really",
    "start": "1046449",
    "end": "1052750"
  },
  {
    "text": "going to be about what you identify as your problem and what your domain knowledge tells you about that",
    "start": "1052750",
    "end": "1058330"
  },
  {
    "text": "particular issue so we can definitely assist but we don't have any services outright other than our our different",
    "start": "1058330",
    "end": "1064450"
  },
  {
    "text": "solutions of serve and m/l solutions lab but now when",
    "start": "1064450",
    "end": "1070080"
  },
  {
    "text": "we get to the data collection piece we actually can start to isolate and identify services that are available right now from AWS that can help you",
    "start": "1070080",
    "end": "1077550"
  },
  {
    "text": "solve these different challenges with data collection with data integration with transforming that data with being",
    "start": "1077550",
    "end": "1085170"
  },
  {
    "text": "able to scan that data as it sits latent inside something like this tree so let's go through from the top we have Amazon",
    "start": "1085170",
    "end": "1091590"
  },
  {
    "text": "s3 and that's its object storage and if you've used AWS before this is one of the most common services but for those",
    "start": "1091590",
    "end": "1098190"
  },
  {
    "text": "that haven't it's the idea that you have a durable storage that you can put objects into and it becomes a key value",
    "start": "1098190",
    "end": "1104970"
  },
  {
    "text": "store you can pull out that data or you can choose to compress it or secure it",
    "start": "1104970",
    "end": "1110280"
  },
  {
    "text": "or have it a part of a data lifecycle and be able to have that that data",
    "start": "1110280",
    "end": "1115740"
  },
  {
    "text": "basically move to a cold storage format so the idea is that it gives you a complete storage solution so s3 is a is",
    "start": "1115740",
    "end": "1123300"
  },
  {
    "text": "a basis for often for company's data lakes and so the idea is that you can",
    "start": "1123300",
    "end": "1128580"
  },
  {
    "text": "store all your data necessary and you can have it be a part of this overall machine learning process so that's part",
    "start": "1128580",
    "end": "1134070"
  },
  {
    "text": "of the data platform we have a new tool that just came out a new service called AWS glue which does manage to extract",
    "start": "1134070",
    "end": "1141150"
  },
  {
    "text": "transform load we have another call them Amazon Athena which is for doing ad-hoc",
    "start": "1141150",
    "end": "1147300"
  },
  {
    "text": "query against the data that's sitting at rest inside s3 we have Amazon EMR as I",
    "start": "1147300",
    "end": "1153030"
  },
  {
    "text": "mentioned that earlier and then Amazon redshift and Amazon redshift spectrum which offer you petabyte scale data",
    "start": "1153030",
    "end": "1159990"
  },
  {
    "text": "warehouse capability which is then accessible via Postgres or sequel style",
    "start": "1159990",
    "end": "1166640"
  },
  {
    "text": "post press compatible sequel style querying so there's a lot of different",
    "start": "1166640",
    "end": "1172470"
  },
  {
    "text": "solutions in there this is all about pre-processing the data and preparing it for use in your machine learning we are",
    "start": "1172470",
    "end": "1178890"
  },
  {
    "text": "not going to talk in depth about any news topics but I do believe that there's other topics that or there are",
    "start": "1178890",
    "end": "1184080"
  },
  {
    "text": "other sessions talking to these areas so ganesh has been covering on the data",
    "start": "1184080",
    "end": "1189600"
  },
  {
    "text": "lakeside that's a that's a definitely well worth tuning in for as well as Luke",
    "start": "1189600",
    "end": "1195360"
  },
  {
    "text": "covering the storage solution so please do attend or review those other webcasts that were",
    "start": "1195360",
    "end": "1200950"
  },
  {
    "text": "part of this and then after we have the data in a prepared format this is when",
    "start": "1200950",
    "end": "1207220"
  },
  {
    "start": "1207000",
    "end": "1538000"
  },
  {
    "text": "we can actually start to use sage maker this is where sage maker begins and so sage maker first starts as a managed",
    "start": "1207220",
    "end": "1214450"
  },
  {
    "text": "notebook environment so for those who are not data scientist who have never used data science tools there's a tool",
    "start": "1214450",
    "end": "1223270"
  },
  {
    "text": "will call Jupiter notebook and the Jupiter notebook is essentially an interactive repple it's read X cube",
    "start": "1223270",
    "end": "1230470"
  },
  {
    "text": "print and loop and that's the idea that you can execute commands in a managed",
    "start": "1230470",
    "end": "1235780"
  },
  {
    "text": "environment and that those commands are written in Python or a number of other languages depending on the the way that",
    "start": "1235780",
    "end": "1242440"
  },
  {
    "text": "you've configured Jupiter and what data scientists often do is they use these",
    "start": "1242440",
    "end": "1247450"
  },
  {
    "text": "tools used Jupiter notebooks as a method for sharing their data and their experiments with each other so it's",
    "start": "1247450",
    "end": "1254200"
  },
  {
    "text": "become kind of a best practice to use notebooks as a a form of communication that means that they include both",
    "start": "1254200",
    "end": "1261510"
  },
  {
    "text": "documentation as well as executable code and we'll take a look at what that looks like we'll actually look at the console",
    "start": "1261510",
    "end": "1267520"
  },
  {
    "text": "and we'll actually look at a Jupiter notebook that's the first offering from sage maker bear in mind that sage maker",
    "start": "1267520",
    "end": "1274810"
  },
  {
    "text": "is an ala carte service that means that while I'm going to mention a few different features of sage maker you",
    "start": "1274810",
    "end": "1281170"
  },
  {
    "text": "have the option of using or not using any of these features so for instance if you find that you don't want to use sage",
    "start": "1281170",
    "end": "1288940"
  },
  {
    "text": "maker firts manage notebooks that's completely up to you you can still take advantage of the training as well as the",
    "start": "1288940",
    "end": "1295090"
  },
  {
    "text": "deployment of the endpoints and that's what I'm going to be talking to at length so bear in mind as we talked",
    "start": "1295090",
    "end": "1301390"
  },
  {
    "text": "about this this is not you must use everything that we're talking about you actually can pick and choose what it is",
    "start": "1301390",
    "end": "1307750"
  },
  {
    "text": "you like about stage maker what fits your particular workflow because sage maker is not a workflow for machine",
    "start": "1307750",
    "end": "1315010"
  },
  {
    "text": "learning it is actually a pipeline set it's a set of tools that allow you to pipeline your particular workflow and so",
    "start": "1315010",
    "end": "1322780"
  },
  {
    "text": "it's always up to you whether you wish to adopt or not adopt pieces of sage maker so so the notebook environments",
    "start": "1322780",
    "end": "1330580"
  },
  {
    "text": "the manage notebook of iron are provided for you that's one of the key aspects of sage maker and the second",
    "start": "1330580",
    "end": "1336419"
  },
  {
    "text": "aspect is that you actually can spin up and run your training instances for",
    "start": "1336419",
    "end": "1341820"
  },
  {
    "text": "training them machine learning models that actually is all provided to you via sage maker as a one click or one line of",
    "start": "1341820",
    "end": "1348720"
  },
  {
    "text": "code that when you call the API and you call this API dot fit and doing fit",
    "start": "1348720",
    "end": "1355320"
  },
  {
    "text": "basically and structs it to spin up a number of servers as many servers as you wish and it will do the training the",
    "start": "1355320",
    "end": "1362820"
  },
  {
    "text": "machine learning training build the model and at the end of that training it will shut the server's back down again",
    "start": "1362820",
    "end": "1368730"
  },
  {
    "text": "those servers will it will be only executing or paint you will only pay per",
    "start": "1368730",
    "end": "1374760"
  },
  {
    "text": "second for that execution at a minimum of one minute and so the execution of those those the",
    "start": "1374760",
    "end": "1381659"
  },
  {
    "text": "server training is actually completely ephemeral and it's something that once you're finished those servers go away",
    "start": "1381659",
    "end": "1388110"
  },
  {
    "text": "actually it's managed cluster of servers those those instances of the the",
    "start": "1388110",
    "end": "1394409"
  },
  {
    "text": "containers that are running your source code will exit and they'll no longer be recharged so that means you can take",
    "start": "1394409",
    "end": "1401100"
  },
  {
    "text": "advantage of very powerful machine learning hardware using again Nvidia Volta as an example of the latest and",
    "start": "1401100",
    "end": "1408809"
  },
  {
    "text": "video processors you could use those processors and have extreme amount of processing power and not have to pay any",
    "start": "1408809",
    "end": "1416760"
  },
  {
    "text": "more than per second for the amount of time you actually use for training so",
    "start": "1416760",
    "end": "1421919"
  },
  {
    "text": "that those two pieces are very important and then the next aspect is you actually",
    "start": "1421919",
    "end": "1429029"
  },
  {
    "text": "have the last mile delivery where you can actually deploy a real-time endpoint",
    "start": "1429029",
    "end": "1435059"
  },
  {
    "text": "which is auto scalable which provides you with monitoring and debugging if you've used AWS before it uses cloud",
    "start": "1435059",
    "end": "1442320"
  },
  {
    "text": "watch from both the metrics and the logs to be able to monitor what is happening inside the instances that hosts the API",
    "start": "1442320",
    "end": "1449850"
  },
  {
    "text": "endpoint those API endpoints are accessible either privately within",
    "start": "1449850",
    "end": "1455130"
  },
  {
    "text": "neural and vbc your virtual private cloud or they can be publicly hosted and so you have this flexibility in terms of",
    "start": "1455130",
    "end": "1462990"
  },
  {
    "text": "how you want to deploy the API endpoint but you still again the benefits of managed the managed service of it managing all the",
    "start": "1462990",
    "end": "1470590"
  },
  {
    "text": "auto-scaling pieces for you managing the deployment of the model itself monitoring those endpoints as well as",
    "start": "1470590",
    "end": "1478000"
  },
  {
    "text": "allowing you to do a/b testing so that if you do develop a new model which happens all the time",
    "start": "1478000",
    "end": "1483520"
  },
  {
    "text": "as you develop better and better models you'll continue to push those into production and it gives you a seamless",
    "start": "1483520",
    "end": "1489280"
  },
  {
    "text": "way of introducing that via a/b testing so let's take em that's Amazon Sage",
    "start": "1489280",
    "end": "1497080"
  },
  {
    "text": "maker let's take Amazon Sage maker against the process that we've just talked about what we're doing is they're taking the same process that we've just",
    "start": "1497080",
    "end": "1503710"
  },
  {
    "text": "discussed related to machine learning and we've laid it out flat and so the very first two steps are covered by the",
    "start": "1503710",
    "end": "1511090"
  },
  {
    "text": "build process inside sage maker and so as mentioned it provides pre-built",
    "start": "1511090",
    "end": "1516640"
  },
  {
    "text": "notebooks where you can spin up a jupiter notebook and have access to all",
    "start": "1516640",
    "end": "1521740"
  },
  {
    "text": "of this compute power and from there execute training functions and your fitting as well as your deployment so",
    "start": "1521740",
    "end": "1529090"
  },
  {
    "text": "the next piece of it is that you have these built in high performance algorithms that are provided as",
    "start": "1529090",
    "end": "1535600"
  },
  {
    "text": "first-party algorithms within sage maker supported by AWS and so let's take a look at what what these approaches to",
    "start": "1535600",
    "end": "1542740"
  },
  {
    "start": "1538000",
    "end": "1743000"
  },
  {
    "text": "the training actually include so the sage maker built-in algorithms we have 14",
    "start": "1542740",
    "end": "1547870"
  },
  {
    "text": "sorry 13 different algorithms that you can you can see some of the most common",
    "start": "1547870",
    "end": "1553390"
  },
  {
    "text": "algorithms if you're familiar with data science you can recognize many of these names but I'll just run through them for those who haven't really had familiarity",
    "start": "1553390",
    "end": "1559690"
  },
  {
    "text": "we have k-means clustering which gives you the ability to specify a certain",
    "start": "1559690",
    "end": "1565120"
  },
  {
    "text": "number of centroids and be able to identify clusters of different different",
    "start": "1565120",
    "end": "1570220"
  },
  {
    "text": "pieces within your data so the idea is that if you have data set and you want to just on it in an unsupervised way",
    "start": "1570220",
    "end": "1576880"
  },
  {
    "text": "just see where things cluster you can use something like k-means a very common algorithm you can use a PCA or principal",
    "start": "1576880",
    "end": "1584080"
  },
  {
    "text": "component analysis they'll identify high dimensional data can be reduced in",
    "start": "1584080",
    "end": "1589180"
  },
  {
    "text": "dimensionality and still not lose information and by squeezing it",
    "start": "1589180",
    "end": "1594580"
  },
  {
    "text": "essentially you can create faster results or better results in or later downstream machine-learning",
    "start": "1594580",
    "end": "1600909"
  },
  {
    "text": "processing you have neural topic modeling we can analyze text factorization machines which allow you",
    "start": "1600909",
    "end": "1607029"
  },
  {
    "text": "to do matrix factorization that's a very common use case for that would be recommendation engines you have a linear",
    "start": "1607029",
    "end": "1614230"
  },
  {
    "text": "learner which allows you to do both linear regression as well as logistic regression XG boost which does gradient",
    "start": "1614230",
    "end": "1621669"
  },
  {
    "text": "boosting and it's very common open source package for solving machine learning both linear and logistic",
    "start": "1621669",
    "end": "1629500"
  },
  {
    "text": "regressions you have latent Dursley allocation which allows you to identify",
    "start": "1629500",
    "end": "1634770"
  },
  {
    "text": "spectral topics that may underline different different pieces of text you",
    "start": "1634770",
    "end": "1641260"
  },
  {
    "text": "have image classification as mentioned earlier the idea of detecting whether something is a cat or a dog or whatever",
    "start": "1641260",
    "end": "1647289"
  },
  {
    "text": "it is that you're trying to do it could be identifying logos but whatever your",
    "start": "1647289",
    "end": "1652690"
  },
  {
    "text": "business requirement is around image classification it can automate the classification of different images that",
    "start": "1652690",
    "end": "1659350"
  },
  {
    "text": "are provided to it sequence a sequence which is focused on machine translation",
    "start": "1659350",
    "end": "1665100"
  },
  {
    "text": "deep they are forecasting which is about identifying next the next predicted",
    "start": "1665100",
    "end": "1671200"
  },
  {
    "text": "steps in a time series based on several other time series so the idea is that when things move together you can",
    "start": "1671200",
    "end": "1678250"
  },
  {
    "text": "actually learn across time series and you can try to better predict what would be the next one or two or three hours or",
    "start": "1678250",
    "end": "1685059"
  },
  {
    "text": "days or weeks of production or demand that could be coming in blazing text",
    "start": "1685059",
    "end": "1691990"
  },
  {
    "text": "which allows you to embed words into numbers which is a another important bit for machine learning random cut forests",
    "start": "1691990",
    "end": "1700570"
  },
  {
    "text": "which allows you to an anomaly detection so the idea being that if you see something that's completely strange or",
    "start": "1700570",
    "end": "1706270"
  },
  {
    "text": "an outlier random cut forest is actually very good at identifying outliers inside of it data set and K nearest neighbor",
    "start": "1706270",
    "end": "1713559"
  },
  {
    "text": "which would identify similarities between items and so the idea is that it classifies items potentially as being",
    "start": "1713559",
    "end": "1721390"
  },
  {
    "text": "very similar and tagging things together potentially so you could identify these",
    "start": "1721390",
    "end": "1726460"
  },
  {
    "text": "are similar products or these are similar types of people and object detection which is this",
    "start": "1726460",
    "end": "1732290"
  },
  {
    "text": "shock detection which is provided that you can do a count of items or identify",
    "start": "1732290",
    "end": "1737420"
  },
  {
    "text": "individual items inside of an image so you can actually get better detail and even just an image classification so the",
    "start": "1737420",
    "end": "1746180"
  },
  {
    "start": "1743000",
    "end": "1795000"
  },
  {
    "text": "next choice is that if none of that works for you to use case and these are very common algorithms that were offered",
    "start": "1746180",
    "end": "1752140"
  },
  {
    "text": "but if those things don't work and if there's a need to go deeper then one option you have is to write your own",
    "start": "1752140",
    "end": "1759650"
  },
  {
    "text": "docker file and specify all of the necessary code and implement your own",
    "start": "1759650",
    "end": "1765700"
  },
  {
    "text": "algorithm and it can still be supported inside safe maker as long as you follow",
    "start": "1765700",
    "end": "1770780"
  },
  {
    "text": "specific conventions so it's it's about creating a docker file it's about creating source code and checking that",
    "start": "1770780",
    "end": "1778400"
  },
  {
    "text": "all into a docker repository and providing that access to Sage Maker so",
    "start": "1778400",
    "end": "1783770"
  },
  {
    "text": "that sage maker can execute your doctor container and fire your code and do the",
    "start": "1783770",
    "end": "1790190"
  },
  {
    "text": "training without you having to manage all the heavy lifting of doing all that so the next option is to use sage maker",
    "start": "1790190",
    "end": "1799790"
  },
  {
    "start": "1795000",
    "end": "1861000"
  },
  {
    "text": "frameworks and sage maker framework SDKs for deep learning networks you have",
    "start": "1799790",
    "end": "1805370"
  },
  {
    "text": "things like tensorflow an MX net and chain or and pipe torch SDKs so the idea is that this is a bit",
    "start": "1805370",
    "end": "1812510"
  },
  {
    "text": "higher level so between you may have noticed that in the previous previous",
    "start": "1812510",
    "end": "1817760"
  },
  {
    "text": "list of bring your own algorithms there was also a max net there was also tensor flow there's PI torch there's actually",
    "start": "1817760",
    "end": "1823970"
  },
  {
    "text": "chain or and that as well those things can all be done that's complete customizable in the previous but in the",
    "start": "1823970",
    "end": "1831530"
  },
  {
    "text": "case of the sage maker framework SDKs this simplifies it considerably so you",
    "start": "1831530",
    "end": "1836630"
  },
  {
    "text": "don't have to write your own docker file you just simply specify your tensorflow file or your MX net file and if you",
    "start": "1836630",
    "end": "1843710"
  },
  {
    "text": "follow a specific convention for how how the file will be called how sage maker",
    "start": "1843710",
    "end": "1850310"
  },
  {
    "text": "will call your file then you can actually execute your tensorflow code as",
    "start": "1850310",
    "end": "1856490"
  },
  {
    "text": "as regular tensorflow code just following specific conventions around training and deployment and",
    "start": "1856490",
    "end": "1864570"
  },
  {
    "start": "1861000",
    "end": "1886000"
  },
  {
    "text": "finally we have the ability to integrate with spar work so if you are running spark workloads today and you have",
    "start": "1864570",
    "end": "1870000"
  },
  {
    "text": "pipelines related spark you can actually integrate integrate sage maker into that",
    "start": "1870000",
    "end": "1876299"
  },
  {
    "text": "pipeline as a part of that overall ETL process so that you can actually gain",
    "start": "1876299",
    "end": "1882149"
  },
  {
    "text": "the benefits of your existing spark pipeline and the sage maker at the same time so the next aspect that we'll look",
    "start": "1882149",
    "end": "1892289"
  },
  {
    "start": "1886000",
    "end": "1924000"
  },
  {
    "text": "at is one-click training so as I mentioned earlier I said it's one click or actually it's one API call to the",
    "start": "1892289",
    "end": "1900269"
  },
  {
    "text": "sage maker interface that then would execute the training for a particular machine learning model it also has the",
    "start": "1900269",
    "end": "1908190"
  },
  {
    "text": "ability a feature of sage maker is hyper parameter tuning and I'm going to go into more detail by hyper or hard tuning",
    "start": "1908190",
    "end": "1914610"
  },
  {
    "text": "because it's a very important point and I think a very important part of the value proposition of using sage maker so",
    "start": "1914610",
    "end": "1921000"
  },
  {
    "text": "I'll come back to that in more detail as soon as we've covered off some of the other aspects and then finally you have",
    "start": "1921000",
    "end": "1927929"
  },
  {
    "start": "1924000",
    "end": "1973000"
  },
  {
    "text": "the deployment so you're deploying that model into production you have this fully managed hosting with auto scaling",
    "start": "1927929",
    "end": "1933419"
  },
  {
    "text": "this is using under the covers all the auto scaling mechanisms that are already currently available to you if you're",
    "start": "1933419",
    "end": "1940350"
  },
  {
    "text": "using AWS if you use ec2 instances it just simplifies the interface so the",
    "start": "1940350",
    "end": "1945960"
  },
  {
    "text": "idea is that you have completely maintained a service you specify the minimum number of instances the maximum",
    "start": "1945960",
    "end": "1951149"
  },
  {
    "text": "number instances and it will follow your instructions and it will spin up the exact instance types you've asked for",
    "start": "1951149",
    "end": "1957779"
  },
  {
    "text": "the number of instance types and it will host that model for you as well as give",
    "start": "1957779",
    "end": "1963090"
  },
  {
    "text": "you cod watch metrics and cloud watch logging around those instances so you can monitor and see what's happening",
    "start": "1963090",
    "end": "1968759"
  },
  {
    "text": "with them so if we think about we've looked at a lot of things so I want to",
    "start": "1968759",
    "end": "1975059"
  },
  {
    "start": "1973000",
    "end": "2213000"
  },
  {
    "text": "put this in the context and make you think about how would you actually use this right so when we think about the",
    "start": "1975059",
    "end": "1981120"
  },
  {
    "text": "first step the first step is preparing the data and that's where the stage mark sage maker notebooks the manage",
    "start": "1981120",
    "end": "1986279"
  },
  {
    "text": "notebooks you know would come to play to be able to analyze that raw raw data and",
    "start": "1986279",
    "end": "1991320"
  },
  {
    "text": "then maybe create prepared data sets that then you can do your initial training with now on the long-term",
    "start": "1991320",
    "end": "1998410"
  },
  {
    "text": "that's not the solution the solution is that once you've identified a proper preparation routine you would actually",
    "start": "1998410",
    "end": "2004410"
  },
  {
    "text": "go back and start doing your ETL and actually use tools like glue to do that on a managed regular basis but during",
    "start": "2004410",
    "end": "2012390"
  },
  {
    "text": "the exploration phases and during those those future engineering moments where you're trying to identify what actually",
    "start": "2012390",
    "end": "2018630"
  },
  {
    "text": "is relevant to your business case or your machine learning problem you actually are are going to be doing a lot",
    "start": "2018630",
    "end": "2024809"
  },
  {
    "text": "of iteration a lot of look at these maybe smaller subsets of data to do the",
    "start": "2024809",
    "end": "2030120"
  },
  {
    "text": "immediate training so in this diagram we're showing this raw data into the notebook consents and prepared data back",
    "start": "2030120",
    "end": "2037049"
  },
  {
    "text": "out to Amazon s3 and that certainly is applicable in any investigative portion",
    "start": "2037049",
    "end": "2043260"
  },
  {
    "text": "of your machine learning but once you've identified essentially a production state that you're going to always be",
    "start": "2043260",
    "end": "2049020"
  },
  {
    "text": "using the same features and you need this to be using millions of rows of data that it wasn't probably actually",
    "start": "2049020",
    "end": "2055590"
  },
  {
    "text": "better left to the data preparation stages that I mentioned earlier the tools that I mentioned earlier so I",
    "start": "2055590",
    "end": "2062100"
  },
  {
    "text": "don't want to confuse anyone with that but I do want to note that that's actually designating that this is more",
    "start": "2062100",
    "end": "2068280"
  },
  {
    "text": "for just ad hoc analysis and preparing that data for an initial test to see if the training is going to be successful",
    "start": "2068280",
    "end": "2075300"
  },
  {
    "text": "or not so once we've got the prepared data in place and we absolutely feed that training data into the managed",
    "start": "2075300",
    "end": "2083250"
  },
  {
    "text": "training portion of sage maker we also have the optimization of the tuning",
    "start": "2083250",
    "end": "2089790"
  },
  {
    "text": "portion which is an iterative process so the idea is that the training would not happen just once so looking at that",
    "start": "2089790",
    "end": "2096990"
  },
  {
    "text": "middle portion that HP oh-- with the little loop it's representing a hyper parameter optimization or the high",
    "start": "2096990",
    "end": "2103410"
  },
  {
    "text": "primero tuning that's going to occur as part of any machine learning workload often they decided to have to keep",
    "start": "2103410",
    "end": "2109470"
  },
  {
    "text": "tweaking and tweaking those meta values those those hyper parameters to obtain",
    "start": "2109470",
    "end": "2115109"
  },
  {
    "text": "the best possible results so once there's an outcome from that any",
    "start": "2115109",
    "end": "2120630"
  },
  {
    "text": "of those outcomes that anytime you've trained a model every single time its deploying that train model out back to S",
    "start": "2120630",
    "end": "2127680"
  },
  {
    "text": "3 and that s 3 location is up to you you determine that and once you've placed that train model",
    "start": "2127680",
    "end": "2133710"
  },
  {
    "text": "into s3 now the next logical step is you want to host that and that's where we talked about the end point so the sage",
    "start": "2133710",
    "end": "2139800"
  },
  {
    "text": "maker hosting comes into play and it becomes an API that's available now imagine your users out on the outside",
    "start": "2139800",
    "end": "2146580"
  },
  {
    "text": "are wanting to access that endpoint so often you actually want a pre pre",
    "start": "2146580",
    "end": "2151980"
  },
  {
    "text": "process or to actually make sure that they don't have direct access to the API you would actually want to abstract that",
    "start": "2151980",
    "end": "2158010"
  },
  {
    "text": "and place an API gateway interface as well as an AWS lambda function to call",
    "start": "2158010",
    "end": "2164070"
  },
  {
    "text": "the sage maker hosting endpoint on their behalf so it becomes the sage maker hosting piece is probably more of a part",
    "start": "2164070",
    "end": "2171869"
  },
  {
    "text": "of a micro service architecture that's being called as part of some larger process so the idea is that if it's",
    "start": "2171869",
    "end": "2178290"
  },
  {
    "text": "maybe a fraud check when the user is doing is checkout or maybe it's doing the recommendation based on the user's",
    "start": "2178290",
    "end": "2183540"
  },
  {
    "text": "current page often it would be abstracted in a way where you're actually first calling against an API",
    "start": "2183540",
    "end": "2189780"
  },
  {
    "text": "gateway based on user interactions and that those dues or interactions are driving a lambda function a lambda",
    "start": "2189780",
    "end": "2196109"
  },
  {
    "text": "function is just simply a small piece of code a literally a program a permanent",
    "start": "2196109",
    "end": "2201150"
  },
  {
    "text": "programmatic function that then is responsible for calling the sage maker hosting and endpoint and doing the",
    "start": "2201150",
    "end": "2208410"
  },
  {
    "text": "inference against that to maybe again recommend a list of books or detect if",
    "start": "2208410",
    "end": "2214470"
  },
  {
    "text": "there's some kind of fraudulent activity based on the user's use case so having",
    "start": "2214470",
    "end": "2220560"
  },
  {
    "text": "said all that a lot of different slides here I want to switch over and I want to show you what the console looks like and",
    "start": "2220560",
    "end": "2226410"
  },
  {
    "text": "I want to walk you through what sage maker looks like the notebook instance is the training and how that all works",
    "start": "2226410",
    "end": "2232380"
  },
  {
    "text": "so let's go ahead and jump over to that and this is actually the AWS console but",
    "start": "2232380",
    "end": "2237750"
  },
  {
    "start": "2234000",
    "end": "2536000"
  },
  {
    "text": "on the service page for Amazon sage maker and we see the overview we have",
    "start": "2237750",
    "end": "2243540"
  },
  {
    "text": "the notebooks the training and the inference aspects and they're also listed over here so the first thing we",
    "start": "2243540",
    "end": "2249570"
  },
  {
    "text": "would typically do is we would do a creation of a notebook instance so in this case I'm just going to give it a",
    "start": "2249570",
    "end": "2255420"
  },
  {
    "text": "name I can give it anything up to 63 characters anything it has to have hyphens and no spaces",
    "start": "2255420",
    "end": "2262400"
  },
  {
    "text": "and you can now specify an instance type these instance type four represent the",
    "start": "2262400",
    "end": "2268760"
  },
  {
    "text": "capacity in which that notebook instance will have in terms of this compute and it's its amount of memory so you can",
    "start": "2268760",
    "end": "2277069"
  },
  {
    "text": "choose very small or very large and these are actually all GPU accelerated",
    "start": "2277069",
    "end": "2283029"
  },
  {
    "text": "computing environments which allow you to do really fast training but because",
    "start": "2283029",
    "end": "2288440"
  },
  {
    "text": "the notebook is not intended for training itself the notebook is intended to just simply give you a control area",
    "start": "2288440",
    "end": "2295339"
  },
  {
    "text": "through which you'll actually call training against other instances so while you could certainly spin up at p3",
    "start": "2295339",
    "end": "2302170"
  },
  {
    "text": "16x large you will be paying for the most expensive notebook instance but not",
    "start": "2302170",
    "end": "2307309"
  },
  {
    "text": "necessarily using it in the way that it would be intended so I just want to caution you that probably you want to",
    "start": "2307309",
    "end": "2313789"
  },
  {
    "text": "look at something more reasonable because this notebook will then become that control panel through which you",
    "start": "2313789",
    "end": "2319789"
  },
  {
    "text": "will be executing your ad hoc query you'll be analyzing your data and then you'll be issuing commands against the",
    "start": "2319789",
    "end": "2326180"
  },
  {
    "text": "other components in Sage maker to do training and endpoint hosting so I'm",
    "start": "2326180",
    "end": "2332240"
  },
  {
    "text": "just gonna choose an m4 x-large instance there's a full list of information about what these actually mean but I'm gonna",
    "start": "2332240",
    "end": "2340789"
  },
  {
    "text": "I'm gonna lid that for now so we're gonna look at you have to have a role in",
    "start": "2340789",
    "end": "2346609"
  },
  {
    "text": "which you're going to actually execute commands inside your notebook so in other words I it will give you permission to things like those s3",
    "start": "2346609",
    "end": "2353809"
  },
  {
    "text": "buckets I mentioned earlier you can create a brand new role and you can specify the s3 buckets that that",
    "start": "2353809",
    "end": "2359599"
  },
  {
    "text": "notebook instance will have access to it has a number of different conventions",
    "start": "2359599",
    "end": "2364819"
  },
  {
    "text": "you can choose whether it's going to support anything with the name sage maker in it so that you don't have to",
    "start": "2364819",
    "end": "2370700"
  },
  {
    "text": "worry about creating multiple roles you can choose exactly how you want your securities to be or you could say I",
    "start": "2370700",
    "end": "2376760"
  },
  {
    "text": "wanted to have access any of my s3 buckets it's the least secure approach but it is an option and then if I select",
    "start": "2376760",
    "end": "2384529"
  },
  {
    "text": "I've already created this role so I'm going to go ahead and select that role VEC is our virtual private cloud and",
    "start": "2384529",
    "end": "2390950"
  },
  {
    "text": "it's essentially like a network that sits inside AWS you control that network",
    "start": "2390950",
    "end": "2396110"
  },
  {
    "text": "create those networks and from inside those networks you'll often have hosted",
    "start": "2396110",
    "end": "2401180"
  },
  {
    "text": "data it could be RDS data written traditional database service data it",
    "start": "2401180",
    "end": "2406340"
  },
  {
    "text": "could be redshift data I had mentioned earlier as the petabyte scale data warehouse so the idea is that if you",
    "start": "2406340",
    "end": "2413540"
  },
  {
    "text": "have resources inside the V PC you can you can assign this notebook to attach",
    "start": "2413540",
    "end": "2419000"
  },
  {
    "text": "itself to a BBC if you wish to restrict access to the Internet perhaps you have some compliance",
    "start": "2419000",
    "end": "2424870"
  },
  {
    "text": "requirements some regulatory reasons or or some other reasons why you decide that the notebook",
    "start": "2424870",
    "end": "2430610"
  },
  {
    "text": "instances should not have access to the Internet and it could be very useful for ensuring that if you have contractors",
    "start": "2430610",
    "end": "2437840"
  },
  {
    "text": "working for you that they do not have the ability to egress data conveniently from there no publicans so the idea is",
    "start": "2437840",
    "end": "2444980"
  },
  {
    "text": "that using these pieces you can help lock down and control the security of access to your data we're choosing not",
    "start": "2444980",
    "end": "2452420"
  },
  {
    "text": "to do V PC there's also the option of lifecycle configuration and inside this",
    "start": "2452420",
    "end": "2457910"
  },
  {
    "text": "it gives you the ability to actually assign a script that can either start every time the notebook starts or it'll",
    "start": "2457910",
    "end": "2463940"
  },
  {
    "text": "start the very first time the notebook is created so these are bash scripts you can give it any command you wish to tell",
    "start": "2463940",
    "end": "2470180"
  },
  {
    "text": "it how to launch and so for instance you may actually decide if you have a team",
    "start": "2470180",
    "end": "2475280"
  },
  {
    "text": "of developers the data scientist you may decide there's certain packages you want installed by default inside the notebook",
    "start": "2475280",
    "end": "2481100"
  },
  {
    "text": "instances you can assign that to a lifecycle configuration and then assign that lifecycle configuration to a new",
    "start": "2481100",
    "end": "2487580"
  },
  {
    "text": "notebook instance you have the ability to use our key management services to",
    "start": "2487580",
    "end": "2493970"
  },
  {
    "text": "encrypt the hard drives in which you'll be running those notebook instances so that's an option we're not going to",
    "start": "2493970",
    "end": "2500300"
  },
  {
    "text": "choose to do any encryption today and you can assign tags tags can be assigned",
    "start": "2500300",
    "end": "2505910"
  },
  {
    "text": "to notebook instances to training instances so when you spin up training it can actually be tagged this is",
    "start": "2505910",
    "end": "2512360"
  },
  {
    "text": "important because then you can actually track and see costs where things have been maybe there's cost centers that",
    "start": "2512360",
    "end": "2518090"
  },
  {
    "text": "have to be charged back to related to any machine learning so it's very very powerful mechanism and it's part of the",
    "start": "2518090",
    "end": "2525230"
  },
  {
    "text": "overall AWS in infrastructure or environment that you can sign tags to different things and be",
    "start": "2525230",
    "end": "2531469"
  },
  {
    "text": "able to track the activities based on that so I'm going to go ahead and hit create but we are not going to wait",
    "start": "2531469",
    "end": "2538819"
  },
  {
    "start": "2536000",
    "end": "3068000"
  },
  {
    "text": "until that finishes it's going to take a couple minutes but we don't have time to wait so we're just going to jump in and",
    "start": "2538819",
    "end": "2544489"
  },
  {
    "text": "look at one that's already up and running so this is a notebook instance",
    "start": "2544489",
    "end": "2549529"
  },
  {
    "text": "when I click open I'm basically launching a secure URL that is going",
    "start": "2549529",
    "end": "2555019"
  },
  {
    "text": "through HTTPS and allowing you access to that server that means that there's no ports being open to the Internet and",
    "start": "2555019",
    "end": "2561650"
  },
  {
    "text": "also it respects our I am permissions for accessing - that no - for notebook",
    "start": "2561650",
    "end": "2568039"
  },
  {
    "text": "so essentially it's ensuring that your securities are consistent and everything is validated in terms of activities in",
    "start": "2568039",
    "end": "2575420"
  },
  {
    "text": "attaching to this instance so when we come in here we see a number of different notebooks and I'll explain",
    "start": "2575420",
    "end": "2580999"
  },
  {
    "text": "kind of what the notebooks look like but we actually can see a tab up here called",
    "start": "2580999",
    "end": "2586699"
  },
  {
    "text": "sage make your examples so inside there we can see a number of different examples of what you can do a sage maker",
    "start": "2586699",
    "end": "2594170"
  },
  {
    "text": "it gives a number or different applied use cases for sage maker for machine",
    "start": "2594170",
    "end": "2599269"
  },
  {
    "text": "learning and using sage maker to achieve that it shows you what I talked about before with a high level framework SDKs",
    "start": "2599269",
    "end": "2607609"
  },
  {
    "text": "where you can see examples of how to run MX net or PI torch or tensorflow inside",
    "start": "2607609",
    "end": "2615289"
  },
  {
    "text": "the sage maker environment using that high level SDK it talks about those",
    "start": "2615289",
    "end": "2620509"
  },
  {
    "text": "built in algorithms that we had mentioned earlier which allows you to see some examples of how is that all",
    "start": "2620509",
    "end": "2627049"
  },
  {
    "text": "work so we're actually going to look at an example but before I do that I want to also point something out for those",
    "start": "2627049",
    "end": "2632930"
  },
  {
    "text": "people who know what Jupiter is and they're used to running Jupiter on notebooks the first question may be why",
    "start": "2632930",
    "end": "2638479"
  },
  {
    "text": "would I want to run it as a managed service well you know it certainly adds a lot of value to be able to just",
    "start": "2638479",
    "end": "2644959"
  },
  {
    "text": "quickly spin up or close down a Jupiter instance via API call the second aspect",
    "start": "2644959",
    "end": "2650839"
  },
  {
    "text": "is that if you're pulling data from AWS and using s3 for the benefits that it",
    "start": "2650839",
    "end": "2656150"
  },
  {
    "text": "provides and you have a data leak you want to use something that's in the cloud so that you're not pulling",
    "start": "2656150",
    "end": "2661829"
  },
  {
    "text": "out of AWS and having the restrictions of your local bandwidth to be able to access all that data so the idea is",
    "start": "2661829",
    "end": "2669420"
  },
  {
    "text": "getting that notebook instance as close as you can whether it's your own hosted easy to instance running notebook server",
    "start": "2669420",
    "end": "2675839"
  },
  {
    "text": "or whether you use Jupiter the idea is that that's your choice but it is definitely recommended best practice",
    "start": "2675839",
    "end": "2681869"
  },
  {
    "text": "that you'd be running that Jupiter notebook in the cloud oftentimes people will run things on a local machine or",
    "start": "2681869",
    "end": "2687839"
  },
  {
    "text": "they'll be running it in a different way but it's it's been seen as the best practice in terms of being able to run",
    "start": "2687839",
    "end": "2693329"
  },
  {
    "text": "that as close to the data as possible and if your concern is about any ability",
    "start": "2693329",
    "end": "2699509"
  },
  {
    "text": "to do changes to that instance beyond just a life cycle configuration I mentioned before you actually have full",
    "start": "2699509",
    "end": "2706049"
  },
  {
    "text": "shell access to that instance so there's nothing restricting you from actually we",
    "start": "2706049",
    "end": "2712739"
  },
  {
    "text": "can take a look and see what we can see",
    "start": "2712739",
    "end": "2718229"
  },
  {
    "text": "this is an Amazon Linux instance we can actually do a yum install because Amazon",
    "start": "2718229",
    "end": "2725729"
  },
  {
    "text": "Linux is a CentOS based operating system and you can just show here how powerful",
    "start": "2725729",
    "end": "2732119"
  },
  {
    "text": "it is is that I could actually install httpd I can install pretty much any package I wish so you're not restricted",
    "start": "2732119",
    "end": "2738479"
  },
  {
    "text": "at all you are a root user on that instance and you can actually shut it down you can kill it you can make it",
    "start": "2738479",
    "end": "2743910"
  },
  {
    "text": "very bad you can mess it up a lot but the idea is that it's not restricting",
    "start": "2743910",
    "end": "2749759"
  },
  {
    "text": "you from doing what's necessary as a data scientist or developer from achieving results so I want to be very",
    "start": "2749759",
    "end": "2756029"
  },
  {
    "text": "clear even though it's managed it is not protecting you from your own changes",
    "start": "2756029",
    "end": "2761670"
  },
  {
    "text": "that could cost we could possibly stop it or kill it but it gives you the power then to do exactly what you want to do",
    "start": "2761670",
    "end": "2768900"
  },
  {
    "text": "and what you want to achieve inside your notebook instance so going back to what we're doing inside the instance let's",
    "start": "2768900",
    "end": "2775229"
  },
  {
    "text": "let's take a look at that here's an example notebook and so as mentioned a",
    "start": "2775229",
    "end": "2780329"
  },
  {
    "text": "notebook consists often of text and code so this is all just texts and it can be",
    "start": "2780329",
    "end": "2786329"
  },
  {
    "text": "edited on the fly if necessary but this is this is Jupiter and Jupiter is something you can find out a lot about",
    "start": "2786329",
    "end": "2792390"
  },
  {
    "text": "there's a many resources on the Internet not about Jupiter it's probably outside",
    "start": "2792390",
    "end": "2797750"
  },
  {
    "text": "the scope to talk in too much detail about it but it did have some questions on the earlier webinar about it",
    "start": "2797750",
    "end": "2802940"
  },
  {
    "text": "I do recommend you go to G to search on YouTube about Jupiter there's a lot of",
    "start": "2802940",
    "end": "2808520"
  },
  {
    "text": "documentation about it's an open source software and it gives you this ability to execute Python code inside of a again",
    "start": "2808520",
    "end": "2816530"
  },
  {
    "text": "this this web-based repple environment so I'm going to show you this has already been processed so we can",
    "start": "2816530",
    "end": "2822920"
  },
  {
    "text": "actually see the at the code that was executed and then the outcome from that code execution and so we'll see",
    "start": "2822920",
    "end": "2829520"
  },
  {
    "text": "something very interesting here is that we're using again an s3 bucket we could control what those s3 buckets are",
    "start": "2829520",
    "end": "2836000"
  },
  {
    "text": "they're your buckets and you specify where the in the training and test data",
    "start": "2836000",
    "end": "2841100"
  },
  {
    "text": "is going to be located as well as the output model you have a number of",
    "start": "2841100",
    "end": "2846530"
  },
  {
    "text": "different steps that are happening but I'm gonna scan forward in the interest of time and just show you what happens",
    "start": "2846530",
    "end": "2852800"
  },
  {
    "text": "when I want to do actually train a training and this is using the k-means k-means algorithm for the estimator for",
    "start": "2852800",
    "end": "2861290"
  },
  {
    "text": "k-means to execute the training its first specifying a role in which it's",
    "start": "2861290",
    "end": "2866720"
  },
  {
    "text": "going to execute it's telling it the number of training instances in this case I've specified two instances will",
    "start": "2866720",
    "end": "2872240"
  },
  {
    "text": "be used for training and next it will specify that I'm specifying the type of instance the output location for that",
    "start": "2872240",
    "end": "2879830"
  },
  {
    "text": "the K which is referring to the number of clusters that I'm going to try to achieve the analysis with and then the",
    "start": "2879830",
    "end": "2887350"
  },
  {
    "text": "location for the embalm data and then I do a fit and this is what I mentioned",
    "start": "2887350",
    "end": "2892610"
  },
  {
    "text": "earlier there's one call you're doing a fit and this spins up the necessary servers to do training and if you look",
    "start": "2892610",
    "end": "2899360"
  },
  {
    "text": "down here you can see actually that there's two different servers working at the problem it's green and red if you're",
    "start": "2899360",
    "end": "2906860"
  },
  {
    "text": "able to see that and you can see that the actual log file is being written by",
    "start": "2906860",
    "end": "2912830"
  },
  {
    "text": "both of those instances there's log being written by both those instances so it becomes quite efficient at doing",
    "start": "2912830",
    "end": "2918860"
  },
  {
    "text": "multi distributed training using the support algorithms that support it so as",
    "start": "2918860",
    "end": "2924950"
  },
  {
    "text": "an example k-means supports it there's a number different algorithms that support it so you can do you can essentially achieve",
    "start": "2924950",
    "end": "2931369"
  },
  {
    "text": "results faster then the next step is I have to deploy that for production and I",
    "start": "2931369",
    "end": "2937789"
  },
  {
    "text": "had mentioned before that you can do dot deploy and again you can specify this the initial a number of instances you",
    "start": "2937789",
    "end": "2944269"
  },
  {
    "text": "could specify a maximum number instances and then you specify the size of the instances and so you actually get an end",
    "start": "2944269",
    "end": "2951019"
  },
  {
    "text": "point at the end which now you can send some data to that end point using the predictor or you can actually access it",
    "start": "2951019",
    "end": "2957529"
  },
  {
    "text": "as a restful interface and then get back a result so it's I'm not going to go",
    "start": "2957529",
    "end": "2962960"
  },
  {
    "text": "into detail about this example because all of these examples are actually available on github you can actually",
    "start": "2962960",
    "end": "2970609"
  },
  {
    "text": "find them at the links and I'll provide the links as part of the deck but inside there this all these different folders",
    "start": "2970609",
    "end": "2978019"
  },
  {
    "text": "relate to the actual thing that I saw earlier here these Amazon algorithms so",
    "start": "2978019",
    "end": "2987289"
  },
  {
    "text": "this is a list of Amazon based algorithms that are being updated constantly",
    "start": "2987289",
    "end": "2992539"
  },
  {
    "text": "and it's the same list that you find under the stage maker examples this is all the same code so if you choose to",
    "start": "2992539",
    "end": "2999950"
  },
  {
    "text": "just want to investigate and you want to go to github and you want to look at exactly how the notebooks look then you",
    "start": "2999950",
    "end": "3005109"
  },
  {
    "text": "can do that but the end of this was that it wrote the data to s3 wrote out the",
    "start": "3005109",
    "end": "3011499"
  },
  {
    "text": "model thestory after training and then that model was used from s3 to deploy",
    "start": "3011499",
    "end": "3016809"
  },
  {
    "text": "out to an end point and then everything was automated and all within Sage maker and again you could choose whether you",
    "start": "3016809",
    "end": "3022809"
  },
  {
    "text": "decide you don't want to do you don't want to do training on Sage maker for example and you just want to use the",
    "start": "3022809",
    "end": "3028690"
  },
  {
    "text": "deployment for the end point there's examples in here of how to do that so for advanced functionality there's",
    "start": "3028690",
    "end": "3035859"
  },
  {
    "text": "examples of bring your own model and the idea is that you don't have to train on sage maker you could actually bring your",
    "start": "3035859",
    "end": "3042309"
  },
  {
    "text": "own own existing model into Sage maker and have that hosted for you potentially and then there's also a lot of examples",
    "start": "3042309",
    "end": "3049839"
  },
  {
    "text": "around how to run those SDKs that I mentioned earlier so a lot of examples",
    "start": "3049839",
    "end": "3054970"
  },
  {
    "text": "around tensorflow using the high level sdk but even more complex examples so I",
    "start": "3054970",
    "end": "3060609"
  },
  {
    "text": "really recommend that you go and take a look at some that piece and I will now talk about we'll",
    "start": "3060609",
    "end": "3067910"
  },
  {
    "text": "talk about another portion which is the architecture so as mentioned there's actually containers that are being used",
    "start": "3067910",
    "end": "3075109"
  },
  {
    "start": "3068000",
    "end": "3303000"
  },
  {
    "text": "that you're writing either you're writing a docker file for or you're leveraging sage makers existing built-in",
    "start": "3075109",
    "end": "3081440"
  },
  {
    "text": "algorithms or the high level SDKs they all constitute a docker file that's been",
    "start": "3081440",
    "end": "3088640"
  },
  {
    "text": "checked into the elastic container registry so whether those are sage maker managed or whether they're managed by",
    "start": "3088640",
    "end": "3094010"
  },
  {
    "text": "you you can follow the convention you can create your own docker file which",
    "start": "3094010",
    "end": "3099650"
  },
  {
    "text": "then can be used and merged with your training data to be able to execute and",
    "start": "3099650",
    "end": "3105170"
  },
  {
    "text": "do a training of a model at the end of that training that model can actually pushed out to s3 the model then it can",
    "start": "3105170",
    "end": "3112309"
  },
  {
    "text": "be picked up again and you can choose to essentially create a second container for inference code or you could even",
    "start": "3112309",
    "end": "3118730"
  },
  {
    "text": "potentially use the same container again that's usually the convention and the inference code that dot deploy will",
    "start": "3118730",
    "end": "3125720"
  },
  {
    "text": "execute and it will pull in the container for the deployment and it will merge it with the model that's been",
    "start": "3125720",
    "end": "3131480"
  },
  {
    "text": "trained and then it becomes available as an endpoint again in this illustration we have the client directly access an",
    "start": "3131480",
    "end": "3137690"
  },
  {
    "text": "endpoint but you probably want to consider some kind of abstraction in the middle and the inference requests and",
    "start": "3137690",
    "end": "3143270"
  },
  {
    "text": "the inference response occurs as a restful interface or you can use SDK to access it the final thing is you record",
    "start": "3143270",
    "end": "3150289"
  },
  {
    "text": "the ground truth back to s3 that's not being handled by sage maker that's not part of sage maker and I just want to",
    "start": "3150289",
    "end": "3158240"
  },
  {
    "text": "get to this point I think this is the most important we mentioned something about hyper parameter tuning and so",
    "start": "3158240",
    "end": "3163520"
  },
  {
    "text": "hyper parameter tuning imagine these these sound boards where there's a sound engineer that's on top of you know all",
    "start": "3163520",
    "end": "3169670"
  },
  {
    "text": "these different knobs and that's really the challenge for most machine learning practitioners is to be able to identify",
    "start": "3169670",
    "end": "3175430"
  },
  {
    "text": "what knobs to turn to what levels during the process it can code us widely",
    "start": "3175430",
    "end": "3181880"
  },
  {
    "text": "different responses based on those knobs so imagine if you have all these knobs in front of you that represent hyper",
    "start": "3181880",
    "end": "3187730"
  },
  {
    "text": "parameters how are you going to do your machine learning training well you know this is just an example coming from the",
    "start": "3187730",
    "end": "3193700"
  },
  {
    "text": "sage maker screen of one particular or algorithm and all the different hyper-paranoid that you could",
    "start": "3193700",
    "end": "3198890"
  },
  {
    "text": "be dealing with so you're talking about a number of different little knobs that have to be dressed and now the first",
    "start": "3198890",
    "end": "3205040"
  },
  {
    "text": "option that costs that customers that machine learning practitioner so you can do is to do a full grid search that",
    "start": "3205040",
    "end": "3210980"
  },
  {
    "text": "means you have to search across every possibility that means it becomes common vitria Li like it becomes very",
    "start": "3210980",
    "end": "3217220"
  },
  {
    "text": "expensive compute wise to try to address but we would think of that as just like",
    "start": "3217220",
    "end": "3222830"
  },
  {
    "text": "with two different parameters it would be a loop inside of a loop but you're checking an exhaustive search of every",
    "start": "3222830",
    "end": "3229880"
  },
  {
    "text": "possible parameters at some point it's not possible and that's why actually it turns out that rather than doing a",
    "start": "3229880",
    "end": "3236540"
  },
  {
    "text": "strict grid search according to different documents of and published you",
    "start": "3236540",
    "end": "3241580"
  },
  {
    "text": "actually can find better results from doing a random search completely random search it actually performs better and",
    "start": "3241580",
    "end": "3248510"
  },
  {
    "text": "there's links to the survey or the research paper around that that you can",
    "start": "3248510",
    "end": "3253910"
  },
  {
    "text": "reset research and find so now let's say we did the same thing we're just trying to randomly guess and we just run",
    "start": "3253910",
    "end": "3259700"
  },
  {
    "text": "through a range of possibilities so that would be our code if we were writing this as code all right and so often data",
    "start": "3259700",
    "end": "3266780"
  },
  {
    "text": "scientists do have to write this zip code or they have to do something to manually address this problem of",
    "start": "3266780",
    "end": "3272150"
  },
  {
    "text": "searching that space so there's actually a third process that learns from the",
    "start": "3272150",
    "end": "3277970"
  },
  {
    "text": "past the idea is that each time and each step that you do your your training you actually can learn from your machine",
    "start": "3277970",
    "end": "3284300"
  },
  {
    "text": "learning parameters and try to make a better guess based on your previous experience your priority priors can help",
    "start": "3284300",
    "end": "3291230"
  },
  {
    "text": "educate you and make a better choice for the next set and so we have within Sage",
    "start": "3291230",
    "end": "3296900"
  },
  {
    "text": "maker we have an implementation a Bayesian optimization which allows you to address that and get better results",
    "start": "3296900",
    "end": "3304160"
  },
  {
    "start": "3303000",
    "end": "3565000"
  },
  {
    "text": "and optimize in a way that's automated so you're putting machine learning on top of machine learning so let's just",
    "start": "3304160",
    "end": "3310100"
  },
  {
    "text": "quickly look at that and we have over here hyper parameter optimization an",
    "start": "3310100",
    "end": "3318680"
  },
  {
    "text": "example and we're just using the sage maker library and that library again",
    "start": "3318680",
    "end": "3324320"
  },
  {
    "text": "while I'm showing you everything as part of our notebook instances just as accessible if you installed sage",
    "start": "3324320",
    "end": "3331290"
  },
  {
    "text": "maker library if you're a Python user you just do pip installed by sage maker there's actually documentation on all",
    "start": "3331290",
    "end": "3338670"
  },
  {
    "text": "this in terms of how to use the library itself this doesn't require you to run inside the notebook instance this is",
    "start": "3338670",
    "end": "3344490"
  },
  {
    "text": "just a convenience for us to be able to illustrate and communicate is between",
    "start": "3344490",
    "end": "3350160"
  },
  {
    "text": "people what is happening inside this notebook but there's a lot of different options and there's things that you can",
    "start": "3350160",
    "end": "3355470"
  },
  {
    "text": "do to automate in all of this because it's just Python code so you can see that there's actually a tuner object and",
    "start": "3355470",
    "end": "3362430"
  },
  {
    "text": "you're importing or tumor library inside the tuner library there's a different parameters that you might be",
    "start": "3362430",
    "end": "3368370"
  },
  {
    "text": "investigating so it has integer a categorical and a continuous parameter as well as a hyper parameter tuner",
    "start": "3368370",
    "end": "3374490"
  },
  {
    "text": "object and so what happens is you specify the let's move down here you",
    "start": "3374490",
    "end": "3382980"
  },
  {
    "text": "specify to tune and you can ignore this is just an estimator object we saw it earlier called k-means and the idea is",
    "start": "3382980",
    "end": "3389730"
  },
  {
    "text": "that it gives it all the information it needs about the training job itself but more interestingly for a hyper parameter",
    "start": "3389730",
    "end": "3396090"
  },
  {
    "text": "tuning job is we want to give it a range of values we want to test so here's three different high parameters they're",
    "start": "3396090",
    "end": "3402000"
  },
  {
    "text": "going to be tested and if you assign it then to a promising range of values it will investigate using Bayesian",
    "start": "3402000",
    "end": "3408450"
  },
  {
    "text": "optimization at each iteration it will try to investigate the best set of values within those ranges it also has",
    "start": "3408450",
    "end": "3415620"
  },
  {
    "text": "the ability to have multiple different outputs that are judged to determine whether we're getting closer or further",
    "start": "3415620",
    "end": "3421530"
  },
  {
    "text": "from a good result and this is for custom use you have the ability to customize this registry expert this",
    "start": "3421530",
    "end": "3429030"
  },
  {
    "text": "sorry this regular expression to be able to actually scan the logs and identify the outcomes and then finally we have we",
    "start": "3429030",
    "end": "3436950"
  },
  {
    "text": "have the number of jobs being run it's going to run nine jobs it's going to run three in parallel so it's gonna be three iterations of three jobs each time it's",
    "start": "3436950",
    "end": "3444960"
  },
  {
    "text": "going to be informing it each time it's going to set new parameters so I'm Nessen that's the end of it it actually is the",
    "start": "3444960",
    "end": "3451590"
  },
  {
    "text": "end of this if I'm jump over to the to an example of what this looks like once",
    "start": "3451590",
    "end": "3458010"
  },
  {
    "text": "you've run it you can see here we have M net job that ran this is the exact same",
    "start": "3458010",
    "end": "3464200"
  },
  {
    "text": "code but I ran it earlier and have a number of training jobs it had nine jobs",
    "start": "3464200",
    "end": "3469960"
  },
  {
    "text": "run as we discussed but each one had a different outcome all right so the only thing that changed was the hyper",
    "start": "3469960",
    "end": "3475869"
  },
  {
    "text": "parameters the training data it didn't change the test data didn't change everything was consistent but the only thing changed from one iteration to the",
    "start": "3475869",
    "end": "3482170"
  },
  {
    "text": "next was the hyper parameters that were used and if I go to the completed if I",
    "start": "3482170",
    "end": "3487960"
  },
  {
    "text": "go to sorry best training job I can actually see the exact values that were used that gave me the best performance",
    "start": "3487960",
    "end": "3495430"
  },
  {
    "text": "so for data scientist this is a this is a relief because it provides an",
    "start": "3495430",
    "end": "3500650"
  },
  {
    "text": "automated mechanism that will essentially take away a lot of the heavy lifting that comes from an iterative",
    "start": "3500650",
    "end": "3507010"
  },
  {
    "text": "task of trying different hyper parameters so this is uh this is a big part the final part that I want to share",
    "start": "3507010",
    "end": "3513490"
  },
  {
    "text": "is I mentioned about endpoints and API and hosting that as you run the training",
    "start": "3513490",
    "end": "3519430"
  },
  {
    "text": "jobs you only pay per second for the training job execution but when you run the endpoints you are paying on a 7 by",
    "start": "3519430",
    "end": "3527380"
  },
  {
    "text": "24 basis for that real-time inference so the choice is if you choose you do not",
    "start": "3527380",
    "end": "3532960"
  },
  {
    "text": "want to run that machine learning model on a regular you know minute-by-minute",
    "start": "3532960",
    "end": "3538090"
  },
  {
    "text": "basis and you want to instead use it in a traditional batch transform from mode",
    "start": "3538090",
    "end": "3543160"
  },
  {
    "text": "perhaps you're scoring credit on a nightly basis you can actually use batch transformation and it's the same model",
    "start": "3543160",
    "end": "3549640"
  },
  {
    "text": "which is you choose a type of instance and then you give it a a input data and",
    "start": "3549640",
    "end": "3554830"
  },
  {
    "text": "then it will actually run predictions against that and store the output as part of the batch transform job it'll",
    "start": "3554830",
    "end": "3560230"
  },
  {
    "text": "store the output to s3 determine by you so those pieces are all about the hyper",
    "start": "3560230",
    "end": "3567910"
  },
  {
    "start": "3565000",
    "end": "3599000"
  },
  {
    "text": "parameters there's the additional resources that are available the links that I talked about that I shared with",
    "start": "3567910",
    "end": "3573580"
  },
  {
    "text": "you in examples there's also a workshop to give you a more fully comprehensive idea of how to use sage maker here's the",
    "start": "3573580",
    "end": "3580200"
  },
  {
    "text": "documentation about the actual library is the the Python SDK that I mentioned",
    "start": "3580200",
    "end": "3586030"
  },
  {
    "text": "earlier and you saw the documents for and then the sage maker spark as well I",
    "start": "3586030",
    "end": "3592359"
  },
  {
    "text": "did want to call out Amazon learning solutions lab which again is about leveraging AWS expertise our data",
    "start": "3592359",
    "end": "3599630"
  },
  {
    "text": "scientist for your particular domain issue and you can engage with us and",
    "start": "3599630",
    "end": "3604820"
  },
  {
    "text": "identify a proof-of-concept with us we can help you brainstorm model and also teach your teams whether you have data",
    "start": "3604820",
    "end": "3611870"
  },
  {
    "text": "scientists who are experienced or not experienced we can help teach to our best practices and share with you those",
    "start": "3611870",
    "end": "3618350"
  },
  {
    "text": "as part of the ML solutions lab engagement so that will typically be a face-to-face hands-on with your data",
    "start": "3618350",
    "end": "3625340"
  },
  {
    "text": "scientists and our ml Solutions lab team in order to achieve results around your",
    "start": "3625340",
    "end": "3630590"
  },
  {
    "text": "proof of concept needs and we have a training offer so the idea is that if you are wishing to improve your",
    "start": "3630590",
    "end": "3636290"
  },
  {
    "text": "knowledge and sort of certify on AWS you certainly are encouraged to pursue",
    "start": "3636290",
    "end": "3642580"
  },
  {
    "text": "certification and big data as especially and you can find out more about that on AWS training site in order to obtain",
    "start": "3642580",
    "end": "3650080"
  },
  {
    "text": "free digital training around a number of these steps so QA a couple of things",
    "start": "3650080",
    "end": "3656480"
  },
  {
    "text": "that I've gotten questions on here is there are support yes ours are as",
    "start": "3656480",
    "end": "3661730"
  },
  {
    "text": "supported and we actually have a number of examples inside that examples directory I want to also mention that",
    "start": "3661730",
    "end": "3668150"
  },
  {
    "text": "our studio is supported you can use the reticulate package there's actually an entire blog post on this using our with",
    "start": "3668150",
    "end": "3676640"
  },
  {
    "text": "sage maker that's a that's just search on our sage maker on the machine",
    "start": "3676640",
    "end": "3681830"
  },
  {
    "text": "learning blog and it'll give you details of exactly it'll actually spin up in our studio instance you can use reticulate",
    "start": "3681830",
    "end": "3688700"
  },
  {
    "text": "and you can actually spin up the training not inside our but inside of the sage maker and then another question",
    "start": "3688700",
    "end": "3697190"
  },
  {
    "text": "I had was about how what's the is there any choice in terms of s3 is the source",
    "start": "3697190",
    "end": "3704180"
  },
  {
    "text": "for the data there is no choice if you're running sage maker and you're running the training instances the data",
    "start": "3704180",
    "end": "3710390"
  },
  {
    "text": "has to be placed into s3 and the output will always be s3 as well and then",
    "start": "3710390",
    "end": "3716180"
  },
  {
    "text": "finally the question was about lambda whether you if you want to do real-time inference with lambda you can do that",
    "start": "3716180",
    "end": "3722180"
  },
  {
    "text": "but the question will be about how large your models become as you're trying to do inference so this is something that",
    "start": "3722180",
    "end": "3728300"
  },
  {
    "text": "you have to be cautious and you have to look at what are the sizes of the lambda instances not the lammed instances but",
    "start": "3728300",
    "end": "3734720"
  },
  {
    "text": "lambda configuration that you choose so I know I've run over quite a bit I really do appreciate all of your",
    "start": "3734720",
    "end": "3741080"
  },
  {
    "text": "attention to this and I hope that you've gotten a lot out of it if you haven't",
    "start": "3741080",
    "end": "3746330"
  },
  {
    "text": "and if you have it either way we want to hear back from you and we really want to hear about what other things you want to",
    "start": "3746330",
    "end": "3751850"
  },
  {
    "text": "hear about specific to daily lakes specific to big data analytics and machine learning so please do share your",
    "start": "3751850",
    "end": "3758510"
  },
  {
    "text": "feedback and complete the surveys otherwise thank you so much for joining and my apologies for running over",
    "start": "3758510",
    "end": "3766990"
  },
  {
    "text": "you",
    "start": "3774920",
    "end": "3776980"
  }
]
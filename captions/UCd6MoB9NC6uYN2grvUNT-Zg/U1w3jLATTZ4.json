[
  {
    "start": "0",
    "end": "165000"
  },
  {
    "text": "good morning everybody thank you for coming in you have some really exciting",
    "start": "30",
    "end": "6029"
  },
  {
    "text": "stuff for you throughout this day so we're gonna be talking about streaming",
    "start": "6029",
    "end": "11550"
  },
  {
    "text": "data analytics in this first session we're gonna talk about multiple topics related to streaming and its importance",
    "start": "11550",
    "end": "19260"
  },
  {
    "text": "and how different it is from things that we are more used to like batch analytics and at the end we're gonna have a",
    "start": "19260",
    "end": "26240"
  },
  {
    "text": "workshop where we're gonna dive deeper into some of the building block building",
    "start": "26240",
    "end": "34079"
  },
  {
    "text": "blocks that we have at AWS that enable you to build streaming data and other x-pipe lines and applications and we",
    "start": "34079",
    "end": "41040"
  },
  {
    "text": "will see ourselves we will do it by hand we will build an application that",
    "start": "41040",
    "end": "47480"
  },
  {
    "text": "process ingests processes streaming data and gives you results based on on that",
    "start": "47480",
    "end": "56100"
  },
  {
    "text": "data so real quick before we start who",
    "start": "56100",
    "end": "61620"
  },
  {
    "text": "here has a streaming data pipeline of any kind that's currently in production",
    "start": "61620",
    "end": "69409"
  },
  {
    "text": "okay so we have a couple people ok great ok so first what is streaming data and",
    "start": "69409",
    "end": "80960"
  },
  {
    "text": "this is some thought that's coming up a",
    "start": "80960",
    "end": "86009"
  },
  {
    "text": "lot in conversations these days and the nature of streaming data and how",
    "start": "86009",
    "end": "93119"
  },
  {
    "text": "different it is from our usual batch processing pipelines and within in this",
    "start": "93119",
    "end": "100110"
  },
  {
    "text": "comparison we can see how streaming data",
    "start": "100110",
    "end": "105560"
  },
  {
    "text": "deals with smaller chunks of data that",
    "start": "105560",
    "end": "110759"
  },
  {
    "text": "that is coming at you at high speed it's coming at you all the time and compared",
    "start": "110759",
    "end": "117479"
  },
  {
    "text": "to batch processing which has been around for a long time where you get",
    "start": "117479",
    "end": "124189"
  },
  {
    "text": "larger batches of data or larger chunks of data at certain intervals maybe say",
    "start": "124189",
    "end": "130920"
  },
  {
    "text": "daily or weekly sometimes and then you go and you process that data and you analyze it and you get your",
    "start": "130920",
    "end": "137610"
  },
  {
    "text": "insights with streaming data that pace is much faster you're ingesting these",
    "start": "137610",
    "end": "145230"
  },
  {
    "text": "smaller chunks and instead of running a processing job nightly or weekly you are",
    "start": "145230",
    "end": "152520"
  },
  {
    "text": "constantly the processing the transformation and the analysis and",
    "start": "152520",
    "end": "157950"
  },
  {
    "text": "gaining insights from their data is happening all the time and some of the",
    "start": "157950",
    "end": "166770"
  },
  {
    "start": "165000",
    "end": "165000"
  },
  {
    "text": "use cases that streaming data enables are very very valuable to many different",
    "start": "166770",
    "end": "175800"
  },
  {
    "text": "organizations for example if you are trying to monitor your server",
    "start": "175800",
    "end": "182460"
  },
  {
    "text": "infrastructure or instances and trying to gain insight into what is going on on",
    "start": "182460",
    "end": "188880"
  },
  {
    "text": "this interest its infrastructure level if you are ingesting and processing your",
    "start": "188880",
    "end": "194940"
  },
  {
    "text": "logs that at a daily kind of interval you can gain some insights into what is",
    "start": "194940",
    "end": "203580"
  },
  {
    "text": "going on what are the kind of events that are happening on my infrastructure but when you switch to a different model",
    "start": "203580",
    "end": "210330"
  },
  {
    "text": "where you are ingesting and processing your logs in real time you kind of you",
    "start": "210330",
    "end": "218010"
  },
  {
    "text": "kind of transform into a dev a different kind of response model you can respond",
    "start": "218010",
    "end": "225270"
  },
  {
    "text": "in real-time or near real-time to events that are happening on your infrastructure if you have some errors",
    "start": "225270",
    "end": "232020"
  },
  {
    "text": "or problems that you are getting messages about from your website or your",
    "start": "232020",
    "end": "239310"
  },
  {
    "text": "app you can act much more proactively or what we will what will look to many of",
    "start": "239310",
    "end": "247500"
  },
  {
    "text": "your users or all of your user base like a proactive way because you can take",
    "start": "247500",
    "end": "255840"
  },
  {
    "text": "these make decisions based on their streaming data in real time or near real",
    "start": "255840",
    "end": "261780"
  },
  {
    "text": "time for example if you are getting this is a use case that happens a lot if",
    "start": "261780",
    "end": "270020"
  },
  {
    "text": "you are getting messages that you have user abandonment abandonment user",
    "start": "270020",
    "end": "275509"
  },
  {
    "text": "sessions are people are being abandoned and users are leaving your application at a rate that is much higher than usual",
    "start": "275509",
    "end": "282370"
  },
  {
    "text": "and you can start looking at this and you can prepare like your help desk and",
    "start": "282370",
    "end": "288860"
  },
  {
    "text": "your customer support agents to be ready with a message that they can address the",
    "start": "288860",
    "end": "294350"
  },
  {
    "text": "issue or at least look like they know what is going on and can respond with",
    "start": "294350",
    "end": "300350"
  },
  {
    "text": "much better messaging to your customers or to your users then if they don't know",
    "start": "300350",
    "end": "308080"
  },
  {
    "text": "so the use cases vary a lot you have things like real time spending alerts",
    "start": "309160",
    "end": "316580"
  },
  {
    "text": "and and and reporting clickstream analysis that you can get in in real time of how your users are interacting",
    "start": "316580",
    "end": "324020"
  },
  {
    "text": "with your content and with your website or your app getting these insights it is",
    "start": "324020",
    "end": "330949"
  },
  {
    "text": "very beneficial because then you can take real-time action based on it and",
    "start": "330949",
    "end": "338050"
  },
  {
    "text": "one of the very important use cases that",
    "start": "338050",
    "end": "345349"
  },
  {
    "text": "get enabled in this as well as fraud detection these text messages or alerts",
    "start": "345349",
    "end": "351590"
  },
  {
    "text": "that you get sometimes from your credit card company or your bank whenever you",
    "start": "351590",
    "end": "357020"
  },
  {
    "text": "use your card somewhere that you haven't used it before or if you are traveling somewhere that you have it that you",
    "start": "357020",
    "end": "362960"
  },
  {
    "text": "haven't traveled to before you use your card and you get a text message saying hey we got this transaction do you",
    "start": "362960",
    "end": "371120"
  },
  {
    "text": "approve it read on to prove it and this all without having that near real-time",
    "start": "371120",
    "end": "378220"
  },
  {
    "text": "capability this whole functionality will didn't have value and it wouldn't be",
    "start": "378220",
    "end": "383720"
  },
  {
    "text": "happening of course Internet of Things and smart",
    "start": "383720",
    "end": "389180"
  },
  {
    "text": "home devices are also very good use cases for streaming data these devices",
    "start": "389180",
    "end": "396099"
  },
  {
    "text": "create large and very large amounts of data",
    "start": "396099",
    "end": "401479"
  },
  {
    "text": "that are coming at you in very small packets they might be temperature",
    "start": "401479",
    "end": "406850"
  },
  {
    "text": "sensors thermostats wearable devices alarms whatever kind of device they are",
    "start": "406850",
    "end": "415460"
  },
  {
    "text": "you have a large installed base and you will be ingesting and processing data at",
    "start": "415460",
    "end": "422449"
  },
  {
    "text": "a very high rate",
    "start": "422449",
    "end": "425860"
  },
  {
    "text": "so why streaming data it is the value",
    "start": "428169",
    "end": "433729"
  },
  {
    "text": "that you get out of it and the value that you get out of the streaming data",
    "start": "433729",
    "end": "439039"
  },
  {
    "start": "437000",
    "end": "437000"
  },
  {
    "text": "will really depend on how quickly you can react when when you can react in",
    "start": "439039",
    "end": "446180"
  },
  {
    "text": "real or near real time you will get the most data out of out of it and as time",
    "start": "446180",
    "end": "453530"
  },
  {
    "text": "elapses the value of the data will start to dwindle down and and diminish however",
    "start": "453530",
    "end": "461900"
  },
  {
    "text": "you know there's there's always that question of what is wrong that what is where's the place of batch processing",
    "start": "461900",
    "end": "470030"
  },
  {
    "text": "along with streaming data and bets processing is not going anywhere and",
    "start": "470030",
    "end": "476560"
  },
  {
    "text": "stream streaming there always comes in to to add and to be complimentary to",
    "start": "476560",
    "end": "484639"
  },
  {
    "text": "batch processing pipelines and actually the streaming data that you are ingesting a lot of times we'll end up",
    "start": "484639",
    "end": "492740"
  },
  {
    "text": "getting aggregated and being transformed into a batch processing pipeline of some",
    "start": "492740",
    "end": "499340"
  },
  {
    "text": "kind or to a data persistent persistence layer of some kind that you will use",
    "start": "499340",
    "end": "505969"
  },
  {
    "text": "some bi or analytics tool to get some long-term insights from it so in",
    "start": "505969",
    "end": "513349"
  },
  {
    "text": "addition to what you're getting here's what is happening you know in the last 30 seconds for example across my",
    "start": "513349",
    "end": "520550"
  },
  {
    "text": "infrastructure across my by the user interactions with my application you",
    "start": "520550",
    "end": "527660"
  },
  {
    "text": "will take that data you will aggregate it you'll start looking at at a high level and see hardly daily weekly or monthly trends",
    "start": "527660",
    "end": "535780"
  },
  {
    "text": "that you have as well now where do",
    "start": "535780",
    "end": "545310"
  },
  {
    "text": "streaming data serve screaming data services on AWS",
    "start": "545310",
    "end": "550330"
  },
  {
    "text": "where are they where do they fit for the most part they will fit into the data",
    "start": "550330",
    "end": "556330"
  },
  {
    "start": "552000",
    "end": "552000"
  },
  {
    "text": "ingestion block that you see on the left hand side that's where the Kinesis",
    "start": "556330",
    "end": "563430"
  },
  {
    "text": "services fall within the AWS data",
    "start": "563430",
    "end": "569460"
  },
  {
    "text": "services ecosystem as one of the building blocks that enable you to build",
    "start": "569460",
    "end": "576040"
  },
  {
    "text": "your data Lake and start your analytics journey on AWS now we will start looking",
    "start": "576040",
    "end": "587260"
  },
  {
    "text": "at the individual services that we have in the Kinesis family of services",
    "start": "587260",
    "end": "597990"
  },
  {
    "start": "589000",
    "end": "589000"
  },
  {
    "text": "Kinesis video streams is the one of the younger siblings in in that family it",
    "start": "601980",
    "end": "610240"
  },
  {
    "text": "was introduced I think two years ago in reinvent and it enables you to ingest",
    "start": "610240",
    "end": "618390"
  },
  {
    "text": "and process video and audio data and",
    "start": "618390",
    "end": "624330"
  },
  {
    "text": "it's usually used in conjunction with surveillance systems and and/or cameras",
    "start": "624330",
    "end": "630250"
  },
  {
    "text": "that you can have to push video feeds",
    "start": "630250",
    "end": "635830"
  },
  {
    "text": "into the service and it is one of the things that we use in the Amazon Go",
    "start": "635830",
    "end": "641950"
  },
  {
    "text": "stores the grocery stores there are unmanned Kinesis data streams is the",
    "start": "641950",
    "end": "651640"
  },
  {
    "text": "oldest sibling in that family where the service started back I think in 2013 is",
    "start": "651640",
    "end": "658270"
  },
  {
    "text": "when it was introduced and Kinesis data streams enables you to capture and process and store data streams and it",
    "start": "658270",
    "end": "667330"
  },
  {
    "text": "enables you to build your own custom processing or custom consumer",
    "start": "667330",
    "end": "672970"
  },
  {
    "text": "applications build your own logic depending on how you want to process the",
    "start": "672970",
    "end": "679420"
  },
  {
    "text": "data that you are ingesting in real time or near real-time Canisius data firehose",
    "start": "679420",
    "end": "686200"
  },
  {
    "text": "is a more kind of more of a streamlined version of Kinesis data streams and it's",
    "start": "686200",
    "end": "693340"
  },
  {
    "text": "more targeted at moving data from your producers the sources that are creating",
    "start": "693340",
    "end": "700900"
  },
  {
    "text": "these the the data streaming records into a a data store in AWS and we have",
    "start": "700900",
    "end": "710800"
  },
  {
    "text": "options for multiple data stores but you can put their data into and that fits",
    "start": "710800",
    "end": "716440"
  },
  {
    "text": "many many use cases where you have already an analytics pipeline that's",
    "start": "716440",
    "end": "722710"
  },
  {
    "text": "already established and you do your or you do your processing in a different tool you don't need to create your own",
    "start": "722710",
    "end": "730420"
  },
  {
    "text": "consumer application or your own consumer logic you can use Kinesis data firehouse to move their",
    "start": "730420",
    "end": "738940"
  },
  {
    "text": "data into that pipeline Kinesis data",
    "start": "738940",
    "end": "746110"
  },
  {
    "text": "analytics is where you have that layer of intelligence that you can inject into",
    "start": "746110",
    "end": "753090"
  },
  {
    "text": "the data that you are processing you can start running sequel queries on the data",
    "start": "753090",
    "end": "760090"
  },
  {
    "text": "that you are streaming and these sequel queries will run continuously to do",
    "start": "760090",
    "end": "765190"
  },
  {
    "text": "things like aggregations to give you the insights that you need from the data now",
    "start": "765190",
    "end": "774670"
  },
  {
    "text": "lastly we have Amazon manage streams for Kafka which is a service that we have",
    "start": "774670",
    "end": "781950"
  },
  {
    "text": "announced in reinvent 2018 where we offer you managed Kafka",
    "start": "781950",
    "end": "789160"
  },
  {
    "text": "clusters and cough-cough courses is an open source project and it is something",
    "start": "789160",
    "end": "795040"
  },
  {
    "text": "that many of our customers asked us to offer because they already use it",
    "start": "795040",
    "end": "800880"
  },
  {
    "text": "especially in their data centers so we started offering this service it's",
    "start": "800880",
    "end": "807520"
  },
  {
    "text": "currently in in preview and to accommodate that use case where",
    "start": "807520",
    "end": "812980"
  },
  {
    "text": "customers already have Kafka in their infrastructure or in their data center",
    "start": "812980",
    "end": "818710"
  },
  {
    "text": "and they want to continue to use it in AWS",
    "start": "818710",
    "end": "823770"
  },
  {
    "start": "827000",
    "end": "827000"
  },
  {
    "text": "now let's take a quick look at a couple of typical use cases for Kafka or sorry",
    "start": "827370",
    "end": "835200"
  },
  {
    "text": "Kinesis services for streaming data one",
    "start": "835200",
    "end": "841140"
  },
  {
    "text": "here that we've touched upon quickly is IOT devices we have a large number of",
    "start": "841140",
    "end": "847020"
  },
  {
    "text": "IOT sensors that are generating readings or data at a very fast pace and it can",
    "start": "847020",
    "end": "853950"
  },
  {
    "text": "be sending these readings to the MD AWS IOT service and using the IOT rules",
    "start": "853950",
    "end": "861000"
  },
  {
    "text": "engine the IT services rule engine you can push these data records into a",
    "start": "861000",
    "end": "867570"
  },
  {
    "text": "Kinesis data stream and from there you can have a separate logic or a an",
    "start": "867570",
    "end": "875880"
  },
  {
    "text": "application that you build in Kinesis data analytics to do something like calculating average temperature every 10",
    "start": "875880",
    "end": "883890"
  },
  {
    "text": "seconds for example and pushing their data via lamda to a relational database",
    "start": "883890",
    "end": "890300"
  },
  {
    "text": "sitting on on my sequel for example",
    "start": "890300",
    "end": "895519"
  },
  {
    "text": "I'm sorry if you can raise your voice just a little bit",
    "start": "900980",
    "end": "905320"
  },
  {
    "text": "so so you're asking whether the the producers are configured to push data",
    "start": "911560",
    "end": "918459"
  },
  {
    "text": "into Kinesis data streams automatically this this is a very simple setting where",
    "start": "918459",
    "end": "924339"
  },
  {
    "text": "you just give the the service the name of your Kinesis data stream and it will",
    "start": "924339",
    "end": "929499"
  },
  {
    "text": "start pushing your data records into it yes I'm sorry I can't hear you",
    "start": "929499",
    "end": "944279"
  },
  {
    "text": "out there there there are so you're asking whether the how the Kinesis",
    "start": "951530",
    "end": "956890"
  },
  {
    "text": "Canisius service is being made available to you yes so we're gonna take a look",
    "start": "956890",
    "end": "963320"
  },
  {
    "text": "into that there are multiple ways that you can connect into Kinesis and start pushing europe your data records into it",
    "start": "963320",
    "end": "970130"
  },
  {
    "text": "and we will start we will look at those in just a few slides",
    "start": "970130",
    "end": "975010"
  },
  {
    "text": "you can you if you have Kafka already in your in your data center that's where we",
    "start": "988180",
    "end": "996250"
  },
  {
    "text": "are giving you Kafka as a managed service in AWS you can continue to use",
    "start": "996250",
    "end": "1002100"
  },
  {
    "text": "it if you want to run in a hybrid model or as you are starting to migrate maybe",
    "start": "1002100",
    "end": "1008430"
  },
  {
    "text": "some or all of your workloads to AWS I",
    "start": "1008430",
    "end": "1015140"
  },
  {
    "text": "don't I don't know exactly since the service is still in review so there is",
    "start": "1015140",
    "end": "1021930"
  },
  {
    "text": "still a lot of work being done on the service itself",
    "start": "1021930",
    "end": "1026870"
  },
  {
    "start": "1031000",
    "end": "1031000"
  },
  {
    "text": "another option or use case is analyzing",
    "start": "1032000",
    "end": "1037668"
  },
  {
    "text": "logs and ingesting logs in in near-real-time so as an example of that",
    "start": "1037669",
    "end": "1044360"
  },
  {
    "text": "we can have our cloud trail logs which are the audit audit logs that record all",
    "start": "1044360",
    "end": "1051830"
  },
  {
    "text": "the API actions that are taken against your AWS resources you can push these",
    "start": "1051830",
    "end": "1058280"
  },
  {
    "text": "cloud trail messages or events to a Kinesis data firehose through a cloud",
    "start": "1058280",
    "end": "1065510"
  },
  {
    "text": "watch event and then from there you can compute some operational metrics via a",
    "start": "1065510",
    "end": "1074150"
  },
  {
    "text": "Kinesis data analytics application that you build and after that use a at lambda",
    "start": "1074150",
    "end": "1082370"
  },
  {
    "text": "function to push some of these some of the limit the metrics data into",
    "start": "1082370",
    "end": "1089630"
  },
  {
    "text": "something like an Amazon DynamoDB table or if you have other options that",
    "start": "1089630",
    "end": "1095720"
  },
  {
    "text": "you can use you know if you want to use a relational database like my sequel something like that you can do that as",
    "start": "1095720",
    "end": "1101360"
  },
  {
    "text": "well and you can also what you can do what the Kinesis services enable you to",
    "start": "1101360",
    "end": "1107090"
  },
  {
    "text": "do is to push the data that you want into s3 buckets that can act as kind of",
    "start": "1107090",
    "end": "1116090"
  },
  {
    "text": "the source of truth for you before you start processing the data so these",
    "start": "1116090",
    "end": "1121100"
  },
  {
    "text": "records that you're getting from Cloud trail if you want to push them to an s3 bucket that will act as source of truth",
    "start": "1121100",
    "end": "1127400"
  },
  {
    "text": "that you can get go back to at some point later on you can do that you can",
    "start": "1127400",
    "end": "1133580"
  },
  {
    "text": "also push the process data push a copy of the processed data into a different",
    "start": "1133580",
    "end": "1138890"
  },
  {
    "text": "s3 bucket later on in in the pipeline",
    "start": "1138890",
    "end": "1143710"
  },
  {
    "text": "now we're gonna start looking at the different Kinesis services a little bit",
    "start": "1152770",
    "end": "1158950"
  },
  {
    "text": "more depth so Kinesis data streams again the oldest service in this portfolio",
    "start": "1158950",
    "end": "1167460"
  },
  {
    "start": "1160000",
    "end": "1160000"
  },
  {
    "text": "gives you a easy to manage and a very",
    "start": "1167460",
    "end": "1173830"
  },
  {
    "text": "cost efficient solution to ingest real-time streaming data the service is",
    "start": "1173830",
    "end": "1182550"
  },
  {
    "text": "secure it provides you with server-side encryption and provides for data",
    "start": "1182550",
    "end": "1189190"
  },
  {
    "text": "durability by replicating your data into three availability zones and for any",
    "start": "1189190",
    "end": "1197320"
  },
  {
    "text": "Kinesis data stream there are basically three components you have your producers",
    "start": "1197320",
    "end": "1202630"
  },
  {
    "text": "on one side these can be your servers your instances your iot devices your",
    "start": "1202630",
    "end": "1211330"
  },
  {
    "text": "mobile apps your mobile devices themselves these create the data records",
    "start": "1211330",
    "end": "1217990"
  },
  {
    "text": "the Kinesis stream the Kinesis data stream sits in the middle it ingests all",
    "start": "1217990",
    "end": "1223630"
  },
  {
    "text": "of these data records and you have your consumers sitting on the other side of",
    "start": "1223630",
    "end": "1229750"
  },
  {
    "text": "the stream and these consumers dip into the stream they get the records and they",
    "start": "1229750",
    "end": "1235059"
  },
  {
    "text": "process them and for each one each side for the producers and the consumers you",
    "start": "1235059",
    "end": "1242740"
  },
  {
    "text": "have many options and in terms of the tools that you can use to achieve that",
    "start": "1242740",
    "end": "1250480"
  },
  {
    "text": "functionality that we're going to be looking at so as an example for your",
    "start": "1250480",
    "end": "1258179"
  },
  {
    "text": "processing tools or for your consumers you can use your own custom code on ec2",
    "start": "1258179",
    "end": "1265890"
  },
  {
    "text": "to do the consumption of your data records you can use lambda functions",
    "start": "1265890",
    "end": "1273580"
  },
  {
    "text": "that will get invoked whenever data records are put into the stream and that",
    "start": "1273580",
    "end": "1278980"
  },
  {
    "text": "kind of will give you that completely serverless pipeline you don't need to",
    "start": "1278980",
    "end": "1286010"
  },
  {
    "text": "to worry about managing instances or servers and lambda will invoke multiple",
    "start": "1286010",
    "end": "1293480"
  },
  {
    "text": "or as many functions as needed to",
    "start": "1293480",
    "end": "1298809"
  },
  {
    "text": "process your records as the data volume or the volume of data records grows in",
    "start": "1298809",
    "end": "1304160"
  },
  {
    "text": "your data stream or you can push you can",
    "start": "1304160",
    "end": "1309950"
  },
  {
    "text": "do something like pushing your data via spark streaming on an EMR cluster if",
    "start": "1309950",
    "end": "1316669"
  },
  {
    "text": "there is your preferred way of processing the data and after that your outputs can be persisted into whatever",
    "start": "1316669",
    "end": "1323720"
  },
  {
    "text": "database or data store that you prefer and you can hook up all of your bi or",
    "start": "1323720",
    "end": "1331340"
  },
  {
    "text": "visualization tools to that data to get your final insights and one of the you",
    "start": "1331340",
    "end": "1341720"
  },
  {
    "start": "1338000",
    "end": "1338000"
  },
  {
    "text": "know the the great things about Kinesis services is that you can connect multiple Kinesis services together in",
    "start": "1341720",
    "end": "1350690"
  },
  {
    "text": "kind of a chain to achieve the functionality that you have so you can ingest data via Kinesis data streams and",
    "start": "1350690",
    "end": "1358669"
  },
  {
    "text": "then do your real-time processing in a Kinesis data analytics application and",
    "start": "1358669",
    "end": "1366140"
  },
  {
    "text": "then push all the results through a Kinesis data firehose to be persisted",
    "start": "1366140",
    "end": "1372380"
  },
  {
    "text": "into something like a redshift cluster or index it in classic search or push",
    "start": "1372380",
    "end": "1378530"
  },
  {
    "text": "push it to Splunk or an s3 bucket on the other hand you can push your your data",
    "start": "1378530",
    "end": "1385070"
  },
  {
    "text": "into a Kinesis data stream and then process it in something like an EMR",
    "start": "1385070",
    "end": "1390200"
  },
  {
    "text": "cluster via spark or use any of the options we just talked about if you have",
    "start": "1390200",
    "end": "1395480"
  },
  {
    "text": "your code running on ec2 or if you're using lambda for processing",
    "start": "1395480",
    "end": "1400840"
  },
  {
    "text": "now let's talk a little bit more about consumers and for I'm sorry for about",
    "start": "1402880",
    "end": "1409270"
  },
  {
    "text": "the producers the producers you have multiple options there the simplest one",
    "start": "1409270",
    "end": "1415000"
  },
  {
    "text": "to use is the AWS SDK and the Mobile SDK and these are your best option if you",
    "start": "1415000",
    "end": "1422170"
  },
  {
    "text": "have a low volume producer if you have a small device or or a mobile device that",
    "start": "1422170",
    "end": "1429580"
  },
  {
    "text": "is producing a low volume of Records the SDK is very simple to use to make your",
    "start": "1429580",
    "end": "1436540"
  },
  {
    "text": "put calls in to your Kinesis data stream",
    "start": "1436540",
    "end": "1441750"
  },
  {
    "text": "the Kinesis agent is a application that",
    "start": "1441750",
    "end": "1446920"
  },
  {
    "text": "you can install on your servers or your instances and it's very well suited for",
    "start": "1446920",
    "end": "1453040"
  },
  {
    "text": "use cases where you want to push logs to Kinesis it basically you install it you",
    "start": "1453040",
    "end": "1462010"
  },
  {
    "text": "configure it to monitor certain directories or log files and it will sit",
    "start": "1462010",
    "end": "1467590"
  },
  {
    "text": "there and whenever it detects any new updates or messages written to these logs it will collect them patch them up",
    "start": "1467590",
    "end": "1474040"
  },
  {
    "text": "and send them to either a Kinesis data streams or at least data stream for a",
    "start": "1474040",
    "end": "1480160"
  },
  {
    "text": "Kinesis data Firehouse so you have both options with the Kinesis agent",
    "start": "1480160",
    "end": "1486960"
  },
  {
    "text": "in your talking in the in the eye in the IOT example",
    "start": "1505880",
    "end": "1512950"
  },
  {
    "text": "yes",
    "start": "1519980",
    "end": "1522980"
  },
  {
    "text": "yes the question was whether this is the way something like the SDK is what you",
    "start": "1526170",
    "end": "1533100"
  },
  {
    "text": "use to interface as the interface between your producers if you have something like IOT sensors and the",
    "start": "1533100",
    "end": "1540450"
  },
  {
    "text": "service itself or the Kinesis data streams and and the answer is yes what",
    "start": "1540450",
    "end": "1548760"
  },
  {
    "text": "do what do you classify as low volume there there is there is no hard and fast",
    "start": "1548760",
    "end": "1554070"
  },
  {
    "text": "rule there is if you're talking about one device that is pushing its own",
    "start": "1554070",
    "end": "1562320"
  },
  {
    "text": "records then there is kind of you know something that you can think of as a low",
    "start": "1562320",
    "end": "1567390"
  },
  {
    "text": "volume but if you have something there is probably like aggregating records",
    "start": "1567390",
    "end": "1574440"
  },
  {
    "text": "from multiple devices or a large volume of devices and then pushing all these",
    "start": "1574440",
    "end": "1579780"
  },
  {
    "text": "records into the data stream then maybe that's you know a case where you need to",
    "start": "1579780",
    "end": "1585000"
  },
  {
    "text": "look at something like the kpl or that can produce our library that we'll talk about right now but again there is",
    "start": "1585000",
    "end": "1592290"
  },
  {
    "text": "always you know room for you to experiment and see which which option",
    "start": "1592290",
    "end": "1597420"
  },
  {
    "text": "works best for you because some your your decision or the best option for you",
    "start": "1597420",
    "end": "1604320"
  },
  {
    "text": "will depend on things like the feet the size of your individual records and the",
    "start": "1604320",
    "end": "1611430"
  },
  {
    "text": "rate at which you are sending records through the service as well",
    "start": "1611430",
    "end": "1616160"
  },
  {
    "start": "1618000",
    "end": "1618000"
  },
  {
    "text": "so the kpl or the Kinesis producer library is a library that we are making",
    "start": "1622810",
    "end": "1630550"
  },
  {
    "text": "available to you it's written in Java and you can use the kpl for your high",
    "start": "1630550",
    "end": "1638620"
  },
  {
    "text": "volume producers if you have something just like I said if you have an ec2",
    "start": "1638620",
    "end": "1645370"
  },
  {
    "text": "instance that aggregates records from a hundred or thousands of instances and",
    "start": "1645370",
    "end": "1651580"
  },
  {
    "text": "pushes all of these to a Kinesis data stream then the kpl is probably your",
    "start": "1651580",
    "end": "1657880"
  },
  {
    "text": "best option the kpl gives you capabilities like aggregation where it can aggregate",
    "start": "1657880",
    "end": "1665280"
  },
  {
    "text": "multiple data records from your application and put them into one",
    "start": "1665280",
    "end": "1672040"
  },
  {
    "text": "Kinesis data record and it can also do collection by collecting multiple",
    "start": "1672040",
    "end": "1678570"
  },
  {
    "text": "Kinesis data records and pushing them to the stream via a single HTTP request so",
    "start": "1678570",
    "end": "1686770"
  },
  {
    "text": "it gives you a lot of capabilities to increase the throughput of your data it also gives you things capabilities like",
    "start": "1686770",
    "end": "1694530"
  },
  {
    "text": "having cloud watch metrics so it emits cloud watch metrics data that will",
    "start": "1694530",
    "end": "1699940"
  },
  {
    "text": "enable you to have much better visibility into the to how your",
    "start": "1699940",
    "end": "1706270"
  },
  {
    "text": "producers are performing and it also has a built-in retry mechanism for any",
    "start": "1706270",
    "end": "1713020"
  },
  {
    "text": "failures for of your records that didn't make it it can retry and keep retrying",
    "start": "1713020",
    "end": "1719520"
  },
  {
    "text": "these records until they succeed",
    "start": "1719520",
    "end": "1724050"
  },
  {
    "text": "and on top of these three options that I talked about that we are provide from",
    "start": "1727520",
    "end": "1732900"
  },
  {
    "text": "AWS there are many third-party and and open source agents and and options that",
    "start": "1732900",
    "end": "1739740"
  },
  {
    "text": "are available for you to connect to data streams and push your data records into",
    "start": "1739740",
    "end": "1746670"
  },
  {
    "start": "1746000",
    "end": "1746000"
  },
  {
    "text": "them now on the other side of the stream for the consumers how you're going to be",
    "start": "1746670",
    "end": "1753990"
  },
  {
    "text": "processing and the the records that you are ingesting you have the AWS SDK it's",
    "start": "1753990",
    "end": "1762120"
  },
  {
    "text": "again available to you very simple and easy to use you have lambda you can run",
    "start": "1762120",
    "end": "1770520"
  },
  {
    "text": "your lambda functions in there again so you can complete that serverless picture",
    "start": "1770520",
    "end": "1776310"
  },
  {
    "text": "if that's what you are looking to achieve and you also have the Kinesis",
    "start": "1776310",
    "end": "1782370"
  },
  {
    "text": "client library which is another Java library that we are we have written with",
    "start": "1782370",
    "end": "1787950"
  },
  {
    "text": "multiple interfaces in in Ruby and Python and dotnet that you can use to as",
    "start": "1787950",
    "end": "1796170"
  },
  {
    "text": "kind of the to handle the load the low-level functionality of your consumer",
    "start": "1796170",
    "end": "1802020"
  },
  {
    "text": "application so if you have decided that you want to write your own consumer",
    "start": "1802020",
    "end": "1807210"
  },
  {
    "text": "application and run it on ec2 you only need to worry about writing your own",
    "start": "1807210",
    "end": "1812400"
  },
  {
    "text": "business logic what you want to do with the data the Kinesis client library we'll worry",
    "start": "1812400",
    "end": "1818850"
  },
  {
    "text": "about spinning up the threads and the workers that will dip into the stream",
    "start": "1818850",
    "end": "1824100"
  },
  {
    "text": "different shorts in in out of the stream and get the data out of it it will",
    "start": "1824100",
    "end": "1829500"
  },
  {
    "text": "handle the load balancing of these workers and threads across multiple ec2",
    "start": "1829500",
    "end": "1836040"
  },
  {
    "text": "instances especially if you have something like auto scaling and the number of ec2 instances in that auto",
    "start": "1836040",
    "end": "1843750"
  },
  {
    "text": "scaling group will continue to change up and down",
    "start": "1843750",
    "end": "1849710"
  },
  {
    "text": "but can you repeat that I'm sorry",
    "start": "1856340",
    "end": "1860630"
  },
  {
    "text": "so your question is whether the the data persists within the Kinesis stream if",
    "start": "1868970",
    "end": "1876260"
  },
  {
    "text": "you want to go back and reread it or replay it the the data in the stream will persist",
    "start": "1876260",
    "end": "1883610"
  },
  {
    "text": "up to a certain period there's a retention period that's by default 24",
    "start": "1883610",
    "end": "1888650"
  },
  {
    "text": "hours and you can extend that up to 7 days after that the data will will",
    "start": "1888650",
    "end": "1894560"
  },
  {
    "text": "expire but within that retention period you can go as many times as you want and",
    "start": "1894560",
    "end": "1901370"
  },
  {
    "text": "read the data from the stream there",
    "start": "1901370",
    "end": "1912140"
  },
  {
    "text": "there there is data durability by replicating the data to three",
    "start": "1912140",
    "end": "1917440"
  },
  {
    "text": "availability zones yes",
    "start": "1917440",
    "end": "1924700"
  },
  {
    "text": "so your your question is about whether there are certain patterns of which tool",
    "start": "1938770",
    "end": "1944480"
  },
  {
    "text": "to use on the on the producer and on the consumer side it really it really runs",
    "start": "1944480",
    "end": "1950750"
  },
  {
    "text": "the gamut there is there is a huge variety there and depending on on the on",
    "start": "1950750",
    "end": "1955970"
  },
  {
    "text": "the volume of data and how you want to to process it and and and consume it",
    "start": "1955970",
    "end": "1962320"
  },
  {
    "text": "people use your very variety of tools if",
    "start": "1962320",
    "end": "1968000"
  },
  {
    "text": "you have something like if if you are using something like the kpl as your",
    "start": "1968000",
    "end": "1973130"
  },
  {
    "text": "producer then you will probably be using the KCl on the other side because yeah",
    "start": "1973130",
    "end": "1980630"
  },
  {
    "text": "because that kasya or by default can handle the D aggregation of the records",
    "start": "1980630",
    "end": "1989150"
  },
  {
    "text": "if you are doing aggregation on the kpl for example so there are some synergies",
    "start": "1989150",
    "end": "1995300"
  },
  {
    "text": "between the two but there are you know customers who use the Deb kpl on one",
    "start": "1995300",
    "end": "2003580"
  },
  {
    "text": "side and they run lambda and lambda has a module that you can connect to it a",
    "start": "2003580",
    "end": "2009160"
  },
  {
    "text": "library that that hand can handle the D aggregation of records as well",
    "start": "2009160",
    "end": "2017220"
  },
  {
    "text": "okay so your question is if you are using the Kinesis data analytics to to",
    "start": "2030330",
    "end": "2036670"
  },
  {
    "text": "to process your data do you have the same option or the same array of options",
    "start": "2036670",
    "end": "2043570"
  },
  {
    "text": "to push the data to F after they get out of the data analytics know it's it's",
    "start": "2043570",
    "end": "2055148"
  },
  {
    "text": "it's agnostic to what is on D on the producer side how is the offset",
    "start": "2055149",
    "end": "2066158"
  },
  {
    "text": "management",
    "start": "2066159",
    "end": "2068849"
  },
  {
    "text": "mm-hm okay okay so the question is how's the",
    "start": "2076780",
    "end": "2085970"
  },
  {
    "text": "offset management handled and if there are data that you have processed and then something or some kind of failure",
    "start": "2085970",
    "end": "2092600"
  },
  {
    "text": "happens and you need to go and reread it there are markers within the stream that",
    "start": "2092600",
    "end": "2101000"
  },
  {
    "text": "are called short iterators that act as as these markers debt that you can",
    "start": "2101000",
    "end": "2107210"
  },
  {
    "text": "basically tell or use the short iterators to read from certain positions",
    "start": "2107210",
    "end": "2113930"
  },
  {
    "text": "in the stream some of them can be on the you can ask the service to take you to a certain",
    "start": "2113930",
    "end": "2123200"
  },
  {
    "text": "timestamp or to a certain record number or something like if you wanted to take",
    "start": "2123200",
    "end": "2129110"
  },
  {
    "text": "you to the latest record in the stream or the the very first record in the",
    "start": "2129110",
    "end": "2134300"
  },
  {
    "text": "stream so there are multiple markers that you go to to replay or reread your",
    "start": "2134300",
    "end": "2139370"
  },
  {
    "text": "data",
    "start": "2139370",
    "end": "2141790"
  },
  {
    "text": "the markers are are available that the question a second question was do I have",
    "start": "2145700",
    "end": "2151369"
  },
  {
    "text": "to use the KCl to get these markers or the short iterators and the answer is no you can get those if you're using the",
    "start": "2151369",
    "end": "2158299"
  },
  {
    "text": "SDK and issuing your get record are calls yes",
    "start": "2158299",
    "end": "2170290"
  },
  {
    "text": "you can there are there is Kinesis that the question was do we support multiple",
    "start": "2179210",
    "end": "2186130"
  },
  {
    "text": "connectors for on the consumer side or multiple consumers and you can connect",
    "start": "2186130",
    "end": "2194300"
  },
  {
    "text": "or in the Kinesis enhanced fan-out model",
    "start": "2194300",
    "end": "2199340"
  },
  {
    "text": "you can connect up to five five consumers to a shard in Kinesis",
    "start": "2199340",
    "end": "2210220"
  },
  {
    "text": "this is a very kind of high level look at some of the tools that are available",
    "start": "2219820",
    "end": "2225370"
  },
  {
    "text": "to you both on the producer side and on the consumer side I'm not going to go",
    "start": "2225370",
    "end": "2230920"
  },
  {
    "text": "through all of them one by one but just to give you a very quick idea about the",
    "start": "2230920",
    "end": "2238330"
  },
  {
    "text": "ecosystem and the variety of tools that are available to you if you want to",
    "start": "2238330",
    "end": "2243790"
  },
  {
    "text": "enter our interface with the Kinesis data streams now we want to talk a",
    "start": "2243790",
    "end": "2253570"
  },
  {
    "text": "little bit about capacity and scaling in Kinesis data streams so a Kinesis data",
    "start": "2253570",
    "end": "2261490"
  },
  {
    "text": "screen consists of one or more shards and a shard is a unit of capacity and it",
    "start": "2261490",
    "end": "2270760"
  },
  {
    "text": "is where you'll find that most of the limits in Kinesis data streams are",
    "start": "2270760",
    "end": "2275950"
  },
  {
    "text": "applied so one shard will give you a",
    "start": "2275950",
    "end": "2281380"
  },
  {
    "text": "write capacity of one megabyte per second or 1,000 records per second ever",
    "start": "2281380",
    "end": "2288430"
  },
  {
    "text": "you hit first and give you a read limit of two megabytes per second or five",
    "start": "2288430",
    "end": "2294550"
  },
  {
    "text": "transactions per second we will allow you to go and do a read transaction and",
    "start": "2294550",
    "end": "2303370"
  },
  {
    "text": "pull up to 10,000 records in in one transaction with an upper limit of 10",
    "start": "2303370",
    "end": "2311140"
  },
  {
    "text": "megabytes but we will throttle your your other calls for 5 seconds after that",
    "start": "2311140",
    "end": "2321569"
  },
  {
    "text": "you're asking whether the the if you go beyond this if we will be queued no it",
    "start": "2327450",
    "end": "2333460"
  },
  {
    "text": "will not be Q that will be throttled and you will need to our best option there",
    "start": "2333460",
    "end": "2338740"
  },
  {
    "text": "is to use a a back often and retry mechanism yeah so the data records in",
    "start": "2338740",
    "end": "2352900"
  },
  {
    "start": "2349000",
    "end": "2349000"
  },
  {
    "text": "Kinesis data streams these are the smallest data unit that you can put in a",
    "start": "2352900",
    "end": "2365010"
  },
  {
    "text": "Kinesis data stream partition keys is a",
    "start": "2365010",
    "end": "2372120"
  },
  {
    "text": "value that you need to provide in your put record or put records call when you",
    "start": "2372120",
    "end": "2379810"
  },
  {
    "text": "want to ingest data and the partition key value will tell or will help to get",
    "start": "2379810",
    "end": "2386410"
  },
  {
    "text": "the service put your record into a specific short in that stream if you",
    "start": "2386410",
    "end": "2393340"
  },
  {
    "text": "have multiple shorts",
    "start": "2393340",
    "end": "2396360"
  },
  {
    "text": "so your question about the the limit and what you do if you have a higher rate",
    "start": "2411890",
    "end": "2420410"
  },
  {
    "text": "you can you can add as many shorts to the stream as you like and each short",
    "start": "2420410",
    "end": "2426200"
  },
  {
    "text": "that you add will add another one megabyte or 1000 records",
    "start": "2426200",
    "end": "2432790"
  },
  {
    "text": "yeah that's per shirt yeah these limits are per shot yeah the the short is the capacity unit in data streams you're",
    "start": "2432790",
    "end": "2447830"
  },
  {
    "text": "you're asking if the capacity the capacity increases with what",
    "start": "2447830",
    "end": "2453220"
  },
  {
    "text": "you can you can add as as many shots as you want and you can add these shorts at at any point in time and it doesn't",
    "start": "2469230",
    "end": "2475470"
  },
  {
    "text": "interrupt the operation of the stream but I feel like you have some more detailed use case in mind and we can",
    "start": "2475470",
    "end": "2482670"
  },
  {
    "text": "certainly pick that up after after I'm done here and talk about it in in in a little bit more detail",
    "start": "2482670",
    "end": "2490430"
  },
  {
    "text": "so your question is if you have multiple shorts because you have you need more",
    "start": "2507040",
    "end": "2513880"
  },
  {
    "text": "capacity to to write more data than the one megabyte or or 1000 records",
    "start": "2513880",
    "end": "2521220"
  },
  {
    "text": "we will we will answer that question in just a couple slides okay so",
    "start": "2534700",
    "end": "2546900"
  },
  {
    "text": "your question is about compressing data records the the the payload that you put",
    "start": "2553620",
    "end": "2560340"
  },
  {
    "text": "into the Kinesis data stream is completely up to you we do not read it we do not manipulate it so if you want",
    "start": "2560340",
    "end": "2567960"
  },
  {
    "text": "to do compression on on your side of the data before you put it into the stream",
    "start": "2567960",
    "end": "2573840"
  },
  {
    "text": "that that's an available option but what that the kpl or the the Kinesis producer",
    "start": "2573840",
    "end": "2579600"
  },
  {
    "text": "library gives you the collection and aggregation functions to help you get",
    "start": "2579600",
    "end": "2587150"
  },
  {
    "text": "higher throughput through the stream through these two functionalities",
    "start": "2587150",
    "end": "2594140"
  },
  {
    "text": "so when when you are you're asking when you when you are consuming the data is it gonna be decompressed if you are if",
    "start": "2602520",
    "end": "2611220"
  },
  {
    "text": "you are if you are compressing the data on your side then you will need to have logic on the consumer side to decompress",
    "start": "2611220",
    "end": "2618869"
  },
  {
    "text": "that data but if you are using the kpl to do aggregation and collection and",
    "start": "2618869",
    "end": "2625080"
  },
  {
    "text": "then you are using something like the KCl on the consumer side the KCl can handle the the aggregation of records",
    "start": "2625080",
    "end": "2632160"
  },
  {
    "text": "for you okay put record and put records",
    "start": "2632160",
    "end": "2637680"
  },
  {
    "text": "are the two calls that you issue to put your record a single record or multiple",
    "start": "2637680",
    "end": "2643170"
  },
  {
    "text": "records into your data stream and get records is what you use on the consumer",
    "start": "2643170",
    "end": "2649140"
  },
  {
    "text": "side to have to dip into the stream get your records out of it and start",
    "start": "2649140",
    "end": "2655710"
  },
  {
    "text": "processing them the retention period I just talked about that is by default 24",
    "start": "2655710",
    "end": "2665130"
  },
  {
    "text": "hours this is a stream level value it is not pressured so you set it for the",
    "start": "2665130",
    "end": "2670950"
  },
  {
    "text": "whole stream the data will be retained for 24 hours by default and you can",
    "start": "2670950",
    "end": "2675990"
  },
  {
    "text": "extend that up to 7 days sequence",
    "start": "2675990",
    "end": "2681600"
  },
  {
    "text": "numbers are unique numbers that get assigned to your individual data records",
    "start": "2681600",
    "end": "2688200"
  },
  {
    "text": "in each short as you make your put calls you will get the sequence number for",
    "start": "2688200",
    "end": "2695490"
  },
  {
    "text": "your data records in the response of your request the short iterator is what",
    "start": "2695490",
    "end": "2702900"
  },
  {
    "text": "I just talked about as well there is these different markers within the short that you can go to to read data from a",
    "start": "2702900",
    "end": "2711390"
  },
  {
    "text": "certain position within the short and these can can very have multiple types",
    "start": "2711390",
    "end": "2717660"
  },
  {
    "text": "of short short iterators that you can use whether you want to go to a certain",
    "start": "2717660",
    "end": "2723119"
  },
  {
    "text": "time stamp or a certain sequence number or to the oldest or or latest record in",
    "start": "2723119",
    "end": "2729780"
  },
  {
    "text": "your short now if you have multiple shorts in your",
    "start": "2729780",
    "end": "2739060"
  },
  {
    "start": "2733000",
    "end": "2733000"
  },
  {
    "text": "stream it becomes really important for you to think about the partition key",
    "start": "2739060",
    "end": "2745330"
  },
  {
    "text": "strategy or the partition key values that you use when you put your records in and the Kinesis service will take the",
    "start": "2745330",
    "end": "2758140"
  },
  {
    "text": "partition key value that you provide in your put record or put records request and run that through a hash function and",
    "start": "2758140",
    "end": "2766990"
  },
  {
    "text": "use the result to map your data record into a certain short and it will write",
    "start": "2766990",
    "end": "2774910"
  },
  {
    "text": "that record to that specific short so as you start to increase the number of",
    "start": "2774910",
    "end": "2781330"
  },
  {
    "text": "shorts in your stream for most use cases",
    "start": "2781330",
    "end": "2786610"
  },
  {
    "text": "the majority of use cases you will want to have a randomized partition key value",
    "start": "2786610",
    "end": "2794260"
  },
  {
    "text": "and the more random you get the more of a uniform distribution of your rights",
    "start": "2794260",
    "end": "2801940"
  },
  {
    "text": "across all the shorts in the stream you're gonna have and this is what you",
    "start": "2801940",
    "end": "2807370"
  },
  {
    "text": "want to have versus hitting one or two shorts especially hard while some of the",
    "start": "2807370",
    "end": "2815320"
  },
  {
    "text": "other shorts are sitting underutilized because then you'll end up trying to",
    "start": "2815320",
    "end": "2820750"
  },
  {
    "text": "write or read sometimes from the short at a rate that is higher than its limit",
    "start": "2820750",
    "end": "2826480"
  },
  {
    "text": "and then you will start getting a throughput or a throughput exceeded",
    "start": "2826480",
    "end": "2833160"
  },
  {
    "text": "errors and your records will get throttled and you will need to have some retry mechanism to do to try and to",
    "start": "2833160",
    "end": "2841660"
  },
  {
    "text": "retry and these records after a certain period of time",
    "start": "2841660",
    "end": "2848400"
  },
  {
    "text": "the the partition key is is one of the three values that you need to provide",
    "start": "2852320",
    "end": "2859140"
  },
  {
    "text": "with your put record request so there's his question was where do you get the",
    "start": "2859140",
    "end": "2865710"
  },
  {
    "text": "partition key and when you do your put record input records request you need to",
    "start": "2865710",
    "end": "2872250"
  },
  {
    "text": "provide the data itself your payload the data that you want to write the partition key and the stream name yes",
    "start": "2872250",
    "end": "2882090"
  },
  {
    "text": "you you need yeah yeah you need to have logic that that generates that partition key value yes",
    "start": "2882090",
    "end": "2890240"
  },
  {
    "text": "the the partition key itself that that will need to come that value will need",
    "start": "2899619",
    "end": "2905809"
  },
  {
    "text": "to come from you yeah",
    "start": "2905809",
    "end": "2909849"
  },
  {
    "start": "2912000",
    "end": "2912000"
  },
  {
    "text": "so since we are talking about having multiple shorts in your stream and and",
    "start": "2913700",
    "end": "2921140"
  },
  {
    "text": "scaling mechanisms one of the important things for you to know is that adding",
    "start": "2921140",
    "end": "2928369"
  },
  {
    "text": "shorts to your stream is works a little bit differently it's not just adding",
    "start": "2928369",
    "end": "2935599"
  },
  {
    "text": "additional shorts it works by splitting and existing shorts in your stream and",
    "start": "2935599",
    "end": "2942170"
  },
  {
    "text": "if you are going to reduce the capacity of your stream you don't need as many",
    "start": "2942170",
    "end": "2947240"
  },
  {
    "text": "shorts because for example you know the the data rate the data flow rate that",
    "start": "2947240",
    "end": "2952430"
  },
  {
    "text": "you're dealing with has gone down a little bit it's cyclical or season or something like that and you want to",
    "start": "2952430",
    "end": "2958339"
  },
  {
    "text": "reduce it then you would be merging two adjacent shorts together and these",
    "start": "2958339",
    "end": "2966369"
  },
  {
    "text": "scaling operations are all non-disruptive your your stream will",
    "start": "2966369",
    "end": "2973520"
  },
  {
    "text": "continue to function it will continue to ingest data and it will continue to make your records available for processing",
    "start": "2973520",
    "end": "2980859"
  },
  {
    "text": "while these scaling operations are being executed so the split call here it's",
    "start": "2980859",
    "end": "2991040"
  },
  {
    "text": "called split short call and with this action you split one short into two",
    "start": "2991040",
    "end": "2997430"
  },
  {
    "text": "child shards what happens is as soon as that the two child shards are created",
    "start": "2997430",
    "end": "3004780"
  },
  {
    "text": "they will be ready to ingest new data records but your existing data records",
    "start": "3004780",
    "end": "3012819"
  },
  {
    "text": "that are in the parent shard will still be available to you that short part will",
    "start": "3012819",
    "end": "3017859"
  },
  {
    "text": "be put in a closed status but assure the data records in it will still be",
    "start": "3017859",
    "end": "3023440"
  },
  {
    "text": "available for you to consume and read them up to the streams retention period",
    "start": "3023440",
    "end": "3029770"
  },
  {
    "text": "that you have configured after that these records will be expired",
    "start": "3029770",
    "end": "3036210"
  },
  {
    "start": "3035000",
    "end": "3035000"
  },
  {
    "text": "pretty much the same thing happens when you do the merge which was the merge you",
    "start": "3036690",
    "end": "3041819"
  },
  {
    "text": "need to specify to shards that are adjacent or have a continuous range of",
    "start": "3041819",
    "end": "3049849"
  },
  {
    "text": "hash key values when these two shards are merged the new resulting shard will",
    "start": "3049849",
    "end": "3057539"
  },
  {
    "text": "be available to accept new data records and the two parent shards will be in a",
    "start": "3057539",
    "end": "3067020"
  },
  {
    "text": "closed status retaining their data records up to the streams retention period so after we talked about all of",
    "start": "3067020",
    "end": "3077339"
  },
  {
    "start": "3076000",
    "end": "3076000"
  },
  {
    "text": "that there is always the question of how many shards do I need and you can use",
    "start": "3077339",
    "end": "3083490"
  },
  {
    "text": "this simple formula and you can look at",
    "start": "3083490",
    "end": "3088559"
  },
  {
    "text": "basically the your incoming data rate the incoming records in the data rate",
    "start": "3088559",
    "end": "3096059"
  },
  {
    "text": "that you are ingesting data at and the outgoing data rate that you are",
    "start": "3096059",
    "end": "3101279"
  },
  {
    "text": "consuming data at and plug these numbers into this simple formula and it will",
    "start": "3101279",
    "end": "3108029"
  },
  {
    "text": "give you a number of charts that you can start with so recommended that you add",
    "start": "3108029",
    "end": "3114119"
  },
  {
    "text": "just a little bit of headroom to that number just to give yourself some breathing room in case you have",
    "start": "3114119",
    "end": "3120539"
  },
  {
    "text": "something like a consumer application that has failed and needs to get",
    "start": "3120539",
    "end": "3125670"
  },
  {
    "text": "restarted or you have a new version an updated version of of that consumer",
    "start": "3125670",
    "end": "3131730"
  },
  {
    "text": "application and you deploy it and now it needs to catch up so it starts consuming",
    "start": "3131730",
    "end": "3137819"
  },
  {
    "text": "records at a much higher rate than before",
    "start": "3137819",
    "end": "3145190"
  },
  {
    "text": "I'm sorry it's it's it's the maximum of the two values yes you yes because you",
    "start": "3155560",
    "end": "3165040"
  },
  {
    "text": "you your your your your data rate that",
    "start": "3165040",
    "end": "3171220"
  },
  {
    "text": "you are that you that the tool the total",
    "start": "3171220",
    "end": "3176760"
  },
  {
    "text": "rate of their flow in the stream is based on your write and read",
    "start": "3176760",
    "end": "3188369"
  },
  {
    "text": "okay yes there might be a typo there let's",
    "start": "3199990",
    "end": "3206020"
  },
  {
    "text": "talk about this after we're done and yeah okay now we'll move on to Kinesis",
    "start": "3206020",
    "end": "3213160"
  },
  {
    "start": "3213000",
    "end": "3213000"
  },
  {
    "text": "data firehose and like mentioned before data firehose is a more streamlined version of data streams and it is",
    "start": "3213160",
    "end": "3223380"
  },
  {
    "text": "targeted at use cases where you have streaming data that you want to push",
    "start": "3223380",
    "end": "3229510"
  },
  {
    "text": "into a certain data store with an AWS so",
    "start": "3229510",
    "end": "3235020"
  },
  {
    "text": "with data firehose you can forget about the consumer side where no you don't",
    "start": "3235020",
    "end": "3242980"
  },
  {
    "text": "need to worry about consumer applications the KCl you just want to",
    "start": "3242980",
    "end": "3249160"
  },
  {
    "text": "push your data records from your producers into s3 redshift elasticsearch",
    "start": "3249160",
    "end": "3256150"
  },
  {
    "text": "or Splunk that's basically where data firehose can help you",
    "start": "3256150",
    "end": "3262600"
  },
  {
    "start": "3262000",
    "end": "3262000"
  },
  {
    "text": "data firehose will buffer your data records up to it gives you a buffer size",
    "start": "3262600",
    "end": "3271420"
  },
  {
    "text": "that is configurable from one megabyte to 128 megabytes and a buffer interval",
    "start": "3271420",
    "end": "3277450"
  },
  {
    "text": "that runs from 60 to 900 seconds and whichever one is met first your data",
    "start": "3277450",
    "end": "3284440"
  },
  {
    "text": "records will be that are buffered will be written or delivered to the data",
    "start": "3284440",
    "end": "3289780"
  },
  {
    "text": "store that you've configured for house gives you also some flexibility with",
    "start": "3289780",
    "end": "3297760"
  },
  {
    "start": "3291000",
    "end": "3291000"
  },
  {
    "text": "lambda transformations of of your data if you want to do format conversions or",
    "start": "3297760",
    "end": "3305230"
  },
  {
    "text": "you want to do some cleanup of your data you can use all M the function to handle",
    "start": "3305230",
    "end": "3310690"
  },
  {
    "text": "that but you don't need to worry about shards or scaling or any of the other",
    "start": "3310690",
    "end": "3316359"
  },
  {
    "text": "things that you worried about with data streams it scales automatically for you",
    "start": "3316359",
    "end": "3323579"
  },
  {
    "text": "now moving on to Kinesis data analytics",
    "start": "3325350",
    "end": "3331110"
  },
  {
    "start": "3327000",
    "end": "3327000"
  },
  {
    "text": "can each data analytics works by breeding and processing and delivering your your streaming data using a data",
    "start": "3331260",
    "end": "3342280"
  },
  {
    "text": "application that you configure within the service and we have two options now",
    "start": "3342280",
    "end": "3348400"
  },
  {
    "text": "for Kinesis data analytics you can run sequel queries on the date on the data",
    "start": "3348400",
    "end": "3354010"
  },
  {
    "text": "and recently I think maybe two or three months ago we introduced Java so you can",
    "start": "3354010",
    "end": "3359440"
  },
  {
    "text": "run your java code against that streaming data as well so the idea is",
    "start": "3359440",
    "end": "3365860"
  },
  {
    "start": "3364000",
    "end": "3364000"
  },
  {
    "text": "that you connect to a streaming source and that streaming source can either be",
    "start": "3365860",
    "end": "3371830"
  },
  {
    "text": "a Kinesis data stream or a Kinesis data firehose that's where you're going to be getting your data from and then you have",
    "start": "3371830",
    "end": "3380050"
  },
  {
    "text": "sequel queries or java code that continuously runs against that data",
    "start": "3380050",
    "end": "3386950"
  },
  {
    "text": "and you have our results that are continuously deliver to you you can also",
    "start": "3386950",
    "end": "3395080"
  },
  {
    "start": "3391000",
    "end": "3391000"
  },
  {
    "text": "have lambda functions to do some transformation work or or data format",
    "start": "3395080",
    "end": "3403780"
  },
  {
    "text": "conversion for you on the data before it's pushed through to the data",
    "start": "3403780",
    "end": "3409330"
  },
  {
    "text": "analytics pipeline",
    "start": "3409330",
    "end": "3412320"
  },
  {
    "start": "3413000",
    "end": "3413000"
  },
  {
    "text": "and you can have you can configure the queries if you are using sequel you can",
    "start": "3415970",
    "end": "3423060"
  },
  {
    "text": "configure your queries that you want to have run against the data and we also",
    "start": "3423060",
    "end": "3429000"
  },
  {
    "text": "have multiple templates that are already available to you in the council that",
    "start": "3429000",
    "end": "3435150"
  },
  {
    "text": "give you you know regularly used or popular you know functionality such as",
    "start": "3435150",
    "end": "3443000"
  },
  {
    "text": "aggregation and anomaly detection and you can take those you know use them as",
    "start": "3443000",
    "end": "3448589"
  },
  {
    "text": "they are or start building upon them to you know be the kind of custom tailor",
    "start": "3448589",
    "end": "3454500"
  },
  {
    "text": "them to your use case so one of the very",
    "start": "3454500",
    "end": "3460550"
  },
  {
    "text": "important questions that using Kinesis data analytics or running you know",
    "start": "3460550",
    "end": "3466410"
  },
  {
    "text": "sequel queries for example against a stream of data is what are my boundaries",
    "start": "3466410",
    "end": "3471660"
  },
  {
    "text": "where when I run a sequel query which there exactly am i running that that",
    "start": "3471660",
    "end": "3479820"
  },
  {
    "text": "query over and for that we use something",
    "start": "3479820",
    "end": "3484920"
  },
  {
    "text": "called Windows and we have three types of Windows that are available to you in",
    "start": "3484920",
    "end": "3491970"
  },
  {
    "start": "3490000",
    "end": "3490000"
  },
  {
    "text": "Kinesis data analytics the first one is the template the tumbling window and the",
    "start": "3491970",
    "end": "3498810"
  },
  {
    "text": "tumbling window is a very simple window that runs for a certain runs that opens",
    "start": "3498810",
    "end": "3505589"
  },
  {
    "text": "for a certain number of seconds or whatever your time interval is and it",
    "start": "3505589",
    "end": "3511800"
  },
  {
    "text": "will give you an aggregation of all the events or records that came in",
    "start": "3511800",
    "end": "3517830"
  },
  {
    "text": "throughout that window so you will get one result and each record will be",
    "start": "3517830",
    "end": "3524580"
  },
  {
    "text": "represented only once in a tumbling window so if you want to do something",
    "start": "3524580",
    "end": "3531990"
  },
  {
    "text": "like calculating an average of you know the login failures every 60 seconds then",
    "start": "3531990",
    "end": "3542130"
  },
  {
    "text": "you can have a tumbling tumbling window calculate that for you",
    "start": "3542130",
    "end": "3548369"
  },
  {
    "text": "the second type of Windows is a sliding window and the sliding window can",
    "start": "3548369",
    "end": "3554530"
  },
  {
    "text": "calculate something like a rolling average it's it's a sliding window that",
    "start": "3554530",
    "end": "3560050"
  },
  {
    "text": "keeps it moves constantly with time and you can have if you have for example",
    "start": "3560050",
    "end": "3567270"
  },
  {
    "text": "four records that have fallen into that sliding window as you start to move that",
    "start": "3567270",
    "end": "3575589"
  },
  {
    "text": "window forward it will start to accumulate more records that will fall",
    "start": "3575589",
    "end": "3580780"
  },
  {
    "text": "into the window and some records will start to fall out of the window but you",
    "start": "3580780",
    "end": "3586660"
  },
  {
    "text": "also have the possibility of a record being represented multiple times within",
    "start": "3586660",
    "end": "3593950"
  },
  {
    "text": "that window and the last the highest",
    "start": "3593950",
    "end": "3599770"
  },
  {
    "text": "type is the staggered window and the staggered window is suitable for use",
    "start": "3599770",
    "end": "3606369"
  },
  {
    "text": "cases where you can have some inconsistencies within the data that you",
    "start": "3606369",
    "end": "3611440"
  },
  {
    "text": "are ingesting so for example if you if you are ingesting data from a system",
    "start": "3611440",
    "end": "3616599"
  },
  {
    "text": "where some events can come in late like if you have for example and like a",
    "start": "3616599",
    "end": "3624580"
  },
  {
    "text": "transient failure or an instance that hasn't reported it's it or hasn't sent",
    "start": "3624580",
    "end": "3630550"
  },
  {
    "text": "its log messages you know in for for maybe 90 seconds and then it sends a",
    "start": "3630550",
    "end": "3637420"
  },
  {
    "text": "record that's late there is logic in the in the stagger in the stagger",
    "start": "3637420",
    "end": "3643390"
  },
  {
    "text": "window that is utilized to capture that late if and and include it with the",
    "start": "3643390",
    "end": "3649990"
  },
  {
    "text": "events that it should have been include included in instead of or basically use",
    "start": "3649990",
    "end": "3660550"
  },
  {
    "text": "the time that the event was took place",
    "start": "3660550",
    "end": "3665910"
  },
  {
    "text": "rather than the time that the event was ingested into the the streaming pipeline",
    "start": "3665910",
    "end": "3675839"
  },
  {
    "text": "so with Kinesis data analytics you basically write your sequel query you",
    "start": "3677790",
    "end": "3686380"
  },
  {
    "text": "create a in-stream application and you",
    "start": "3686380",
    "end": "3692980"
  },
  {
    "text": "create a schema to handle the data that you are ingesting and one of the",
    "start": "3692980",
    "end": "3700120"
  },
  {
    "text": "advantages of data analytics here or Canisius data analytics is that it can automatically discover the schema for",
    "start": "3700120",
    "end": "3707530"
  },
  {
    "text": "you so as soon as you hook up your streaming source that Kinesis data stream or Kinesis fire hose into Kinesis",
    "start": "3707530",
    "end": "3714490"
  },
  {
    "text": "data analytics and you start it it can automatically discover the schema for",
    "start": "3714490",
    "end": "3719860"
  },
  {
    "text": "you and create that and create it and you can adjust it further if you like",
    "start": "3719860",
    "end": "3727710"
  },
  {
    "text": "and then you create your sequel queries you write your sequel queries that you",
    "start": "3727710",
    "end": "3733630"
  },
  {
    "text": "want to run against that data and we call it we call that a pump because it's constantly pushing new data into that",
    "start": "3733630",
    "end": "3742810"
  },
  {
    "text": "query or into the pipeline from the query against it deliver the results",
    "start": "3742810",
    "end": "3748770"
  },
  {
    "text": "then run the query against the new data",
    "start": "3748770",
    "end": "3754330"
  },
  {
    "text": "that it's ingested Kinesis data",
    "start": "3754330",
    "end": "3759430"
  },
  {
    "text": "analytics for a java is this new option that we have announced a few months ago",
    "start": "3759430",
    "end": "3767430"
  },
  {
    "text": "and we use we give you a set of open",
    "start": "3768570",
    "end": "3776080"
  },
  {
    "text": "source library that are based on Apache chief link and you can do your your",
    "start": "3776080",
    "end": "3781450"
  },
  {
    "text": "development of this code of the Java code locally and then you upload a jar",
    "start": "3781450",
    "end": "3786790"
  },
  {
    "text": "file and we run that for you and we start scaling the available resources to",
    "start": "3786790",
    "end": "3795010"
  },
  {
    "text": "process your code using the Kinesis processing units and each Kinesis",
    "start": "3795010",
    "end": "3803200"
  },
  {
    "text": "processing unit has one virtual CPU four gigs of memory and",
    "start": "3803200",
    "end": "3808730"
  },
  {
    "text": "access to 50 gigabytes of storage and you can either decide to let us",
    "start": "3808730",
    "end": "3814160"
  },
  {
    "text": "automatically handle the scaling of these KP use for you at Cape use with",
    "start": "3814160",
    "end": "3819950"
  },
  {
    "text": "the load of your application or you can turn off auto scaling if you don't want",
    "start": "3819950",
    "end": "3826400"
  },
  {
    "text": "to and you want to handle scaling manually for yourself",
    "start": "3826400",
    "end": "3831670"
  },
  {
    "text": "now many streaming for Kafka Amazon managed streaming for Kafka the service",
    "start": "3835430",
    "end": "3841500"
  },
  {
    "text": "that is currently in preview there are certain parallels and and similarities",
    "start": "3841500",
    "end": "3848880"
  },
  {
    "text": "between Kinesis and and Kafka some different terminology but you can see",
    "start": "3848880",
    "end": "3856109"
  },
  {
    "text": "here that partitions and shards are kind of more or less analogous and then you",
    "start": "3856109",
    "end": "3865650"
  },
  {
    "text": "also have the topics instead of streams in Kafka is the name used and Kafka uses",
    "start": "3865650",
    "end": "3876869"
  },
  {
    "text": "a more of a pop sub model versus Kinesis",
    "start": "3876869",
    "end": "3884099"
  },
  {
    "text": "where it uses the producers and consumers so why and or when you know",
    "start": "3884099",
    "end": "3893220"
  },
  {
    "text": "you should be using one or the other that's a decision that's that's up to",
    "start": "3893220",
    "end": "3898829"
  },
  {
    "text": "you each one gives you certain advantages with Kinesis you get the",
    "start": "3898829",
    "end": "3906119"
  },
  {
    "text": "typical AWS experience and the api's that you are used to and you get a lot",
    "start": "3906119",
    "end": "3912119"
  },
  {
    "text": "of built-in integration and integration with many AWS services and you have that",
    "start": "3912119",
    "end": "3919250"
  },
  {
    "text": "scaling that is based on the throughput how much throughput you want and then",
    "start": "3919250",
    "end": "3924630"
  },
  {
    "text": "you put in a number of street or a number of shorts that you want to scale",
    "start": "3924630",
    "end": "3930000"
  },
  {
    "text": "to and that all the provisioning is is done for you you don't need to worry about managing servers or clusters or",
    "start": "3930000",
    "end": "3936930"
  },
  {
    "text": "anything like that with Amazon msk it is you have the open source compatibility",
    "start": "3936930",
    "end": "3943259"
  },
  {
    "text": "if it is something that you were already using and familiar with then you'll be",
    "start": "3943259",
    "end": "3949200"
  },
  {
    "text": "right you know more at home it gives you maybe more broad performance and the if",
    "start": "3949200",
    "end": "3957240"
  },
  {
    "text": "you are used to provisioning clusters for that's the model that you want to work in then that's what you're gonna",
    "start": "3957240",
    "end": "3965519"
  },
  {
    "text": "get with msk okay and with this we got to the end of",
    "start": "3965519",
    "end": "3974670"
  },
  {
    "text": "the presentation now we're gonna go into the lab and in the lab we're gonna go to",
    "start": "3974670",
    "end": "3982620"
  },
  {
    "text": "the github page that you guys have in front of you here this is where you'll",
    "start": "3982620",
    "end": "3988080"
  },
  {
    "text": "find all the lab instructions and details there are also some files that you're",
    "start": "3988080",
    "end": "3994980"
  },
  {
    "text": "going to need to download you'll find instructions for those as well in the",
    "start": "3994980",
    "end": "4000260"
  },
  {
    "text": "lab instructions what we're gonna be doing basically is building this",
    "start": "4000260",
    "end": "4006310"
  },
  {
    "text": "streaming pipeline and ingesting data through it",
    "start": "4006310",
    "end": "4012080"
  },
  {
    "text": "running a Kinesis data analytics application on it to do anomaly",
    "start": "4012080",
    "end": "4019220"
  },
  {
    "text": "detection and then seeing the results of that and firing off alerts and",
    "start": "4019220",
    "end": "4026240"
  },
  {
    "text": "notifications whenever the anomaly is actually detected so when you start",
    "start": "4026240",
    "end": "4033680"
  },
  {
    "text": "looking at the the lab instructions you will see that we have a cloud formation",
    "start": "4033680",
    "end": "4039860"
  },
  {
    "text": "template that will automate a large part of this infrastructure for you it will",
    "start": "4039860",
    "end": "4046720"
  },
  {
    "text": "build the Kinesis data firehose and give you the code for the lamda and it will",
    "start": "4046720",
    "end": "4052820"
  },
  {
    "text": "provision the s3 buckets and the the SNS",
    "start": "4052820",
    "end": "4058540"
  },
  {
    "text": "topics it will ask you for some inputs for your email and phone number so it",
    "start": "4058540",
    "end": "4065930"
  },
  {
    "text": "can send you the emails and the SMS notifications what we are going to be",
    "start": "4065930",
    "end": "4072890"
  },
  {
    "text": "provisioning kind of manually are the two blocks in the green frames here",
    "start": "4072890",
    "end": "4079940"
  },
  {
    "text": "we're gonna be using the Kinesis data generator to create the data that we'll",
    "start": "4079940",
    "end": "4085550"
  },
  {
    "text": "be pushing to Kinesis and ingesting and we're gonna be creating the data",
    "start": "4085550",
    "end": "4092150"
  },
  {
    "text": "analytics application and putting in the see the sequel queries that will be",
    "start": "4092150",
    "end": "4097370"
  },
  {
    "text": "running against the data to do that anomaly detection so we're gonna be available for you here",
    "start": "4097370",
    "end": "4105210"
  },
  {
    "text": "please let us know if you have any questions at any point in time there's",
    "start": "4105210",
    "end": "4111060"
  },
  {
    "text": "gonna be you know more than one of us I'm certainly gonna be here so let us",
    "start": "4111060",
    "end": "4118380"
  },
  {
    "text": "know if you have any questions and thanks again for listening thanks for coming in",
    "start": "4118380",
    "end": "4123619"
  }
]
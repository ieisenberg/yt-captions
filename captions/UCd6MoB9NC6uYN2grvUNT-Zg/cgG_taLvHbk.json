[
  {
    "text": "In this video, you'll see how you can add dashboards, panels,\nalerts, and transformations in Amazon Managed Grafana.",
    "start": "80",
    "end": "5575"
  },
  {
    "text": "With this solution, you can visualize\nperformance metrics from multiple data sources,",
    "start": "6053",
    "end": "9981"
  },
  {
    "text": "transform and query operational data, and set alerts\nand notifications to proactively capture issues.",
    "start": "9981",
    "end": "15256"
  },
  {
    "text": "For the purposes of this demo, we have already \ncreated an Amazon Managed Grafana workspace.",
    "start": "16309",
    "end": "20523"
  },
  {
    "text": "Let’s look at our data sources.",
    "start": "20928",
    "end": "22224"
  },
  {
    "text": "Amazon CloudWatch and Amazon Managed Service for \nPrometheus (AMP) are configured as data sources.",
    "start": "26800",
    "end": "32000"
  },
  {
    "text": "The Grafana workspace is also configured with the \nAmazon Simple Notification Service (Amazon SNS).",
    "start": "33541",
    "end": "38549"
  },
  {
    "text": "The SNS collects any notifications in the region, \nand our AMP workspace collects the metrics.",
    "start": "40608",
    "end": "45285"
  },
  {
    "text": "Our AMP workspace, seen here, is set up to ingest and collect metrics\nfrom two Amazon Elastic Compute Cloud (Amazon EC2) instances.",
    "start": "47738",
    "end": "55151"
  },
  {
    "text": "Let's quickly review the configuration \nof our EC2 instances in AWS Cloud9.",
    "start": "56480",
    "end": "60868"
  },
  {
    "text": "The first instance is running the Prometheus service\nand a node exporter service to send metrics to the AMP workspace.",
    "start": "63210",
    "end": "68374"
  },
  {
    "text": "The code of the Prometheus service assigns it to scrape\nand remote-write the metrics to the AMP workspace.",
    "start": "72501",
    "end": "77215"
  },
  {
    "text": "Both EC2 instances mounted with Amazon \nElastic File System (Amazon EFS).",
    "start": "81274",
    "end": "85988"
  },
  {
    "text": "You can learn more about ingesting metrics from an EC2 instance\ninto AMP using the links in the description of this video.",
    "start": "87301",
    "end": "92597"
  },
  {
    "text": "Now let's clear the AWS Cloud9 commands \nand access our Grafana workspace.",
    "start": "93744",
    "end": "97734"
  },
  {
    "text": "Here you can see that Amazon CloudWatch\nand Amazon Managed Prometheus are already configured as data sources.",
    "start": "103162",
    "end": "107962"
  },
  {
    "text": "We can also see the Amazon SNS notification \nchannel we set up for our workspace.\n  ",
    "start": "112202",
    "end": "116042"
  },
  {
    "text": "Now we're ready to create a new dashboard.",
    "start": "116847",
    "end": "118624"
  },
  {
    "text": "Let’s create one that lets us monitor\nthe Amazon EFS metrics.",
    "start": "119018",
    "end": "122154"
  },
  {
    "text": "We’ll add two rows so we can distinguish \nthe Prometheus and CloudWatch metrics.",
    "start": "126421",
    "end": "130054"
  },
  {
    "text": "Let’s save and name the dashboard.",
    "start": "142677",
    "end": "144197"
  },
  {
    "text": "Now let's create a panel in the CloudWatch row.",
    "start": "150458",
    "end": "152538"
  },
  {
    "text": "For this one, we'll build a stat panel to represent\nthe total storage of the Amazon EFS files.",
    "start": "155296",
    "end": "159914"
  },
  {
    "text": "We'll specify the data source and region,\nthen configure the panel using a query expression.",
    "start": "161610",
    "end": "166001"
  },
  {
    "text": "We'll make some more adjustments to represent \nthe data to fit our needs and name the panel.",
    "start": "172911",
    "end": "176511"
  },
  {
    "text": "Let’s also provide a description.",
    "start": "182421",
    "end": "183766"
  },
  {
    "text": "Now we'll finish configuring the panel.",
    "start": "184826",
    "end": "186426"
  },
  {
    "text": "Let's change the unit to bytes per second.",
    "start": "197482",
    "end": "199465"
  },
  {
    "text": "We'll use this unit for all the dashboard panels.",
    "start": "199561",
    "end": "201733"
  },
  {
    "text": "Let's also delete the threshold value.",
    "start": "202320",
    "end": "204080"
  },
  {
    "text": "We'll save the panel\nand apply it to our dashboard.",
    "start": "206591",
    "end": "208723"
  },
  {
    "text": "Next, we’ll add a panel to the CloudWatch row\nthat calculates the total throughput.",
    "start": "213077",
    "end": "216709"
  },
  {
    "text": "We'll use a time series view for this panel.",
    "start": "219210",
    "end": "221050"
  },
  {
    "text": "As with our first panel, we'll select the data \nsource and region, write a query expression,  ",
    "start": "223541",
    "end": "227616"
  },
  {
    "text": "adjust the specifications,\nand configure the on the right.",
    "start": "227616",
    "end": "230597"
  },
  {
    "text": "For the purposes of this demonstration,\nwe'll skip ahead so we can quickly create an alert on this panel.",
    "start": "231194",
    "end": "235557"
  },
  {
    "text": "We can assign alerts when building panels \nto help us monitor and analyze our metrics.",
    "start": "238074",
    "end": "241782"
  },
  {
    "text": "Let's build an alert that activates if the \nAmazon EFS exceeds a threshold of 50 megabytes.",
    "start": "242303",
    "end": "246943"
  },
  {
    "text": "We’ll send alerts to the Amazon SNS \nnotification channel we created.",
    "start": "251946",
    "end": "255386"
  },
  {
    "text": "Let's save and apply the panel.",
    "start": "257669",
    "end": "258949"
  },
  {
    "text": "We also want to create a few panels \nin the Prometheus row.",
    "start": "264574",
    "end": "266934"
  },
  {
    "text": "First, however, let's define a few variables\nthat we can query in those panels.",
    "start": "267504",
    "end": "271050"
  },
  {
    "text": "Variables are displayed as dropdown \nlists at the top of the dashboard.  ",
    "start": "273525",
    "end": "276660"
  },
  {
    "text": "These dropdowns make it easy to change\nthe data being displayed in your dashboard.",
    "start": "277221",
    "end": "280649"
  },
  {
    "text": "We’ll begin by defining an instance variable \nthat queries the Prometheus workspace.",
    "start": "284890",
    "end": "288470"
  },
  {
    "text": "Select Update to save the variable.",
    "start": "299797",
    "end": "301477"
  },
  {
    "text": "Now let’s create a variable\nthat queries the EFS file system.",
    "start": "303909",
    "end": "306798"
  },
  {
    "text": "Let's update the variable \nand then save the dashboard.",
    "start": "319408",
    "end": "321703"
  },
  {
    "text": "Now we can add panels\nto the Prometheus row.",
    "start": "327450",
    "end": "329585"
  },
  {
    "text": "For the purposes of this demonstration, we're going to skip ahead\nand take a look at the query expression for this third panel.",
    "start": "330000",
    "end": "334997"
  },
  {
    "text": "With our Prometheus data source, this time-series panel we've built\ncalculates the throughput in bytes sent and received with our client.",
    "start": "337562",
    "end": "343633"
  },
  {
    "text": "Let's save and apply the panel.",
    "start": "344026",
    "end": "345386"
  },
  {
    "text": "Let’s add one more panel to calculate \nthe total read/write throughput endpoint.",
    "start": "349951",
    "end": "353470"
  },
  {
    "text": "We'll supply the query expression \nfor the total write throughput first.",
    "start": "358148",
    "end": "361319"
  },
  {
    "text": "Now we can copy the query and make some \nadjustments so it calculates the read throughput.",
    "start": "369000",
    "end": "372760"
  },
  {
    "text": "Next, we'll apply a transformation\nthat joins the two time series together.",
    "start": "374645",
    "end": "377947"
  },
  {
    "text": "This changes the panel visualization and helps us\nto infer more relevant information from our dashboard.",
    "start": "378415",
    "end": "383098"
  },
  {
    "text": "With our transform applied,\nlet's skip ahead to our completed panel.",
    "start": "384511",
    "end": "387551"
  },
  {
    "text": "Let's save and apply our panel.",
    "start": "390080",
    "end": "391490"
  },
  {
    "text": "With our panels built, we can load some data into the EC2 instances\nand watch how the metrics appear on our dashboard.",
    "start": "396575",
    "end": "402181"
  },
  {
    "text": "Let's return to the AWS Cloud9 \nterminal of our EC2 instance.",
    "start": "403093",
    "end": "406511"
  },
  {
    "text": "Using this command, we'll introduce the \nload test from two different EC2 instances.  ",
    "start": "408976",
    "end": "413014"
  },
  {
    "text": "On the first EC2 instance, we'll perform \nthe read test using the copy command.  ",
    "start": "413280",
    "end": "417274"
  },
  {
    "text": "On the second EC2 instance,\nwe'll perform the write test to the EFS.",
    "start": "417802",
    "end": "421691"
  },
  {
    "text": "Let's return to the dashboard \nin our Grafana workspace.",
    "start": "426325",
    "end": "428725"
  },
  {
    "text": "We can adjust the settings to have the \ndashboard auto-refresh every 10 seconds,  ",
    "start": "431231",
    "end": "434831"
  },
  {
    "text": "and then monitor the changes on our panels.",
    "start": "434831",
    "end": "436645"
  },
  {
    "text": "The load metrics are already showing up.",
    "start": "439477",
    "end": "441077"
  },
  {
    "text": "Let's watch for the alert to activate\non the EFS Total I/O Throughput panel.",
    "start": "441577",
    "end": "445274"
  },
  {
    "text": "As you can see, the alert on the EFS Total \nI/O Throughput panel has changed to yellow,  ",
    "start": "448378",
    "end": "452938"
  },
  {
    "text": "indicating that the data threshold \nis close to its 50-megabyte capacity.",
    "start": "452938",
    "end": "456388"
  },
  {
    "text": "Let's continue to monitor the dashboard as data loads into\nthe Prometheus and CloudWatch data sources from the EC2 instances.",
    "start": "458954",
    "end": "464794"
  },
  {
    "text": "As you can see from the red alert icon, total EFS \nthroughput just exceeded the 50-megabyte capacity.",
    "start": "466160",
    "end": "471269"
  },
  {
    "text": "We can see the type of workload running,\nread or write.",
    "start": "472741",
    "end": "475301"
  },
  {
    "text": "We can also see the traffic for each EC2 instance.",
    "start": "477493",
    "end": "479893"
  },
  {
    "text": "We can also filter the panels according to a \nparticular EC2 instance, using its IP address.",
    "start": "481754",
    "end": "486154"
  },
  {
    "text": "Let's change the view back to \ninclude both EC2 instances.",
    "start": "487221",
    "end": "490101"
  },
  {
    "text": "We can share this dashboard with others who have access\nto our Grafana workspace by copying and sending its link URL.",
    "start": "491914",
    "end": "497194"
  },
  {
    "text": "Or we can export the dashboard as a file\nand send it to external users.",
    "start": "499861",
    "end": "503301"
  },
  {
    "text": "You've just seen how you can add dashboards, panels, alerts,\nand transformations in Amazon Managed Grafana.",
    "start": "505263",
    "end": "510063"
  },
  {
    "text": "You can learn more about this topic in \nthe description and links for this video.",
    "start": "511218",
    "end": "514307"
  },
  {
    "text": "Thanks for watching.\nNow it’s your turn to try.",
    "start": "514634",
    "end": "516537"
  }
]
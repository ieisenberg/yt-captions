[
  {
    "start": "0",
    "end": "0"
  },
  {
    "text": "as promised we are now going to run a",
    "start": "680",
    "end": "2480"
  },
  {
    "text": "Hadoop job so at a high level running a",
    "start": "2480",
    "end": "5400"
  },
  {
    "text": "job has three",
    "start": "5400",
    "end": "7360"
  },
  {
    "text": "steps actually four if you include the",
    "start": "7360",
    "end": "10800"
  },
  {
    "text": "setup that we did in the previous",
    "start": "10800",
    "end": "12120"
  },
  {
    "text": "section so the first step here is we're",
    "start": "12120",
    "end": "15559"
  },
  {
    "text": "going to upload our Hadoop job jar and",
    "start": "15559",
    "end": "17760"
  },
  {
    "text": "whatever data we want to process to",
    "start": "17760",
    "end": "20279"
  },
  {
    "text": "S3 then we tell Amazon what we want to",
    "start": "20279",
    "end": "24560"
  },
  {
    "text": "do with our job which basically means",
    "start": "24560",
    "end": "26480"
  },
  {
    "text": "what kind of job we're running what data",
    "start": "26480",
    "end": "28920"
  },
  {
    "text": "we're processing for input where we want",
    "start": "28920",
    "end": "31480"
  },
  {
    "text": "the results to go what kind of logging",
    "start": "31480",
    "end": "33120"
  },
  {
    "text": "we want Etc and finally we run the job",
    "start": "33120",
    "end": "36520"
  },
  {
    "text": "we wait for it to finish we can monitor",
    "start": "36520",
    "end": "38399"
  },
  {
    "text": "it and we can look at the",
    "start": "38399",
    "end": "41440"
  },
  {
    "start": "41000",
    "end": "41000"
  },
  {
    "text": "results so the first step is setting up",
    "start": "41440",
    "end": "43680"
  },
  {
    "text": "that S3 bucket we created the bucket in",
    "start": "43680",
    "end": "45680"
  },
  {
    "text": "the previous section but now we need to",
    "start": "45680",
    "end": "48840"
  },
  {
    "text": "set up the four different subdirectories",
    "start": "48840",
    "end": "51680"
  },
  {
    "text": "that contain the elements of a job so",
    "start": "51680",
    "end": "53960"
  },
  {
    "text": "one of those elements is the Hadoop job",
    "start": "53960",
    "end": "55440"
  },
  {
    "text": "jar in this example that I'm going to be",
    "start": "55440",
    "end": "57559"
  },
  {
    "text": "doing we've got a bucket called aw",
    "start": "57559",
    "end": "60480"
  },
  {
    "text": "test KK in there is a job directory and",
    "start": "60480",
    "end": "63800"
  },
  {
    "text": "in that job directory we put the job jar",
    "start": "63800",
    "end": "66720"
  },
  {
    "text": "then we've got our input data we're",
    "start": "66720",
    "end": "68640"
  },
  {
    "text": "going to upload some data that our job",
    "start": "68640",
    "end": "70040"
  },
  {
    "text": "is going to",
    "start": "70040",
    "end": "71560"
  },
  {
    "text": "process we have the directory where we",
    "start": "71560",
    "end": "74159"
  },
  {
    "text": "want to put our results and we have the",
    "start": "74159",
    "end": "75799"
  },
  {
    "text": "directory where we where we're going to",
    "start": "75799",
    "end": "77159"
  },
  {
    "text": "tell Amazon that we wanted to put the",
    "start": "77159",
    "end": "79119"
  },
  {
    "text": "log files from the job and again we can",
    "start": "79119",
    "end": "81960"
  },
  {
    "text": "use the AWS console to create all these",
    "start": "81960",
    "end": "84759"
  },
  {
    "text": "directories inside the bucket and to",
    "start": "84759",
    "end": "86640"
  },
  {
    "text": "handle uploading files so let's go do",
    "start": "86640",
    "end": "88720"
  },
  {
    "text": "that",
    "start": "88720",
    "end": "90439"
  },
  {
    "text": "all right we're going to walk through",
    "start": "90439",
    "end": "91400"
  },
  {
    "text": "the steps required to get the data up",
    "start": "91400",
    "end": "93640"
  },
  {
    "text": "into S3 that we need to be able to run",
    "start": "93640",
    "end": "95520"
  },
  {
    "text": "our job so once again we start at the",
    "start": "95520",
    "end": "97560"
  },
  {
    "text": "top level of the ads console we're going",
    "start": "97560",
    "end": "100079"
  },
  {
    "text": "to click on S3 because we're going to be",
    "start": "100079",
    "end": "102560"
  },
  {
    "text": "pushing data up into an S3 bucket that",
    "start": "102560",
    "end": "104880"
  },
  {
    "text": "we previously created so over here we've",
    "start": "104880",
    "end": "107280"
  },
  {
    "text": "got this AWS test KK bucket now one of",
    "start": "107280",
    "end": "110399"
  },
  {
    "text": "the first things I typically do here is",
    "start": "110399",
    "end": "111880"
  },
  {
    "text": "I create some folders so inside this",
    "start": "111880",
    "end": "114479"
  },
  {
    "text": "bucket I have a folder that I'm going to",
    "start": "114479",
    "end": "116360"
  },
  {
    "text": "call",
    "start": "116360",
    "end": "117320"
  },
  {
    "text": "job and this is where I'm going to put",
    "start": "117320",
    "end": "119960"
  },
  {
    "text": "the job",
    "start": "119960",
    "end": "121039"
  },
  {
    "text": "jar I'm going to create another folder",
    "start": "121039",
    "end": "124159"
  },
  {
    "text": "and this one I'm going to call logs and",
    "start": "124159",
    "end": "125840"
  },
  {
    "text": "this is where I'm going to tell uh EMR",
    "start": "125840",
    "end": "128160"
  },
  {
    "text": "to put the job log files at the end of",
    "start": "128160",
    "end": "131080"
  },
  {
    "text": "the",
    "start": "131080",
    "end": "132040"
  },
  {
    "text": "job I'm also going to create a folder",
    "start": "132040",
    "end": "134200"
  },
  {
    "text": "here called Data where I'm going to",
    "start": "134200",
    "end": "136000"
  },
  {
    "text": "upload my input data and I'm going to",
    "start": "136000",
    "end": "139040"
  },
  {
    "text": "create another folder here called",
    "start": "139040",
    "end": "141400"
  },
  {
    "text": "results which is what I'm going to use",
    "start": "141400",
    "end": "142680"
  },
  {
    "text": "for the results of the job so I've got",
    "start": "142680",
    "end": "144519"
  },
  {
    "text": "these folders created so now I'm going",
    "start": "144519",
    "end": "147640"
  },
  {
    "text": "to drill into the job directory which is",
    "start": "147640",
    "end": "149959"
  },
  {
    "text": "empty and now I'm going to upload a job",
    "start": "149959",
    "end": "154800"
  },
  {
    "text": "jar so let us go find a job jar to",
    "start": "155400",
    "end": "160879"
  },
  {
    "text": "upload here it is and you can see it's",
    "start": "160879",
    "end": "162920"
  },
  {
    "text": "7.8 megabytes so uh it's going to take a",
    "start": "162920",
    "end": "166319"
  },
  {
    "text": "little",
    "start": "166319",
    "end": "168440"
  },
  {
    "text": "while we can watch it over",
    "start": "168440",
    "end": "172280"
  },
  {
    "text": "here oh it's going pretty fast all right",
    "start": "172720",
    "end": "176000"
  },
  {
    "text": "so while that is uploading I can",
    "start": "176000",
    "end": "178200"
  },
  {
    "text": "actually start other uploads but in this",
    "start": "178200",
    "end": "179680"
  },
  {
    "text": "case case it's going to finish fast",
    "start": "179680",
    "end": "181519"
  },
  {
    "text": "enough okay so now let's go back to here",
    "start": "181519",
    "end": "186000"
  },
  {
    "text": "and let us open up the data directory",
    "start": "186000",
    "end": "189720"
  },
  {
    "text": "and now I'd like to upload some input",
    "start": "189720",
    "end": "193560"
  },
  {
    "text": "data so here I've got some Wikipedia",
    "start": "193560",
    "end": "197319"
  },
  {
    "text": "data that I've previously prepared small",
    "start": "197319",
    "end": "199319"
  },
  {
    "text": "sample of it and this shouldn't take",
    "start": "199319",
    "end": "201799"
  },
  {
    "text": "very long because it's pretty",
    "start": "201799",
    "end": "203799"
  },
  {
    "text": "small all right so at this point I've",
    "start": "203799",
    "end": "206400"
  },
  {
    "text": "got both the job jar uploaded and the",
    "start": "206400",
    "end": "208920"
  },
  {
    "text": "input data uploaded",
    "start": "208920",
    "end": "210360"
  },
  {
    "start": "210000",
    "end": "210000"
  },
  {
    "text": "now the second step is to do what",
    "start": "210360",
    "end": "212640"
  },
  {
    "text": "elastic map produce calls creating the",
    "start": "212640",
    "end": "215280"
  },
  {
    "text": "job flow now this job flow has a whole",
    "start": "215280",
    "end": "218159"
  },
  {
    "text": "bunch of settings uh specifically you",
    "start": "218159",
    "end": "221200"
  },
  {
    "text": "have to give it a name you have to tell",
    "start": "221200",
    "end": "222439"
  },
  {
    "text": "it what kind of job it is you need to",
    "start": "222439",
    "end": "225120"
  },
  {
    "text": "specify the cluster what type of servers",
    "start": "225120",
    "end": "228159"
  },
  {
    "text": "how many you need to tell it what key",
    "start": "228159",
    "end": "230200"
  },
  {
    "text": "pair to use to run the job where to put",
    "start": "230200",
    "end": "231879"
  },
  {
    "text": "the log files few other things that you",
    "start": "231879",
    "end": "234040"
  },
  {
    "text": "typically don't need to care about uh so",
    "start": "234040",
    "end": "236319"
  },
  {
    "text": "we're going to go and we're going to set",
    "start": "236319",
    "end": "237519"
  },
  {
    "text": "up a job flow and now now I can go and",
    "start": "237519",
    "end": "240439"
  },
  {
    "text": "actually create the job flow using the",
    "start": "240439",
    "end": "243920"
  },
  {
    "text": "EMR interface so I'm going to click on",
    "start": "243920",
    "end": "246519"
  },
  {
    "text": "elastic map produce",
    "start": "246519",
    "end": "248799"
  },
  {
    "text": "here it's going to show me that I don't",
    "start": "248799",
    "end": "250680"
  },
  {
    "text": "have any job flows so I'm going to",
    "start": "250680",
    "end": "253200"
  },
  {
    "text": "create a new job",
    "start": "253200",
    "end": "255959"
  },
  {
    "text": "flow and I'll call",
    "start": "256840",
    "end": "259359"
  },
  {
    "text": "this Wikipedia",
    "start": "259359",
    "end": "262360"
  },
  {
    "text": "processing and I'm going to run my own",
    "start": "262360",
    "end": "264479"
  },
  {
    "text": "application versus there are some",
    "start": "264479",
    "end": "266080"
  },
  {
    "text": "samples that have been pre-created and",
    "start": "266080",
    "end": "268160"
  },
  {
    "text": "the job type here that I'm running",
    "start": "268160",
    "end": "270800"
  },
  {
    "text": "is going to be a custom",
    "start": "270800",
    "end": "274478"
  },
  {
    "text": "jar now it's going to ask me where this",
    "start": "275520",
    "end": "278000"
  },
  {
    "text": "jar is located and here I need to put in",
    "start": "278000",
    "end": "280479"
  },
  {
    "text": "the path starting with the bucket in S3",
    "start": "280479",
    "end": "282960"
  },
  {
    "text": "where the job is the job jar is located",
    "start": "282960",
    "end": "285840"
  },
  {
    "text": "so I know I put this into AWS test KK",
    "start": "285840",
    "end": "289600"
  },
  {
    "text": "slash job slash and it's called the",
    "start": "289600",
    "end": "294080"
  },
  {
    "text": "Wikipedia engrs D job. jar",
    "start": "295440",
    "end": "300520"
  },
  {
    "text": "now I have to specify the arguments and",
    "start": "300520",
    "end": "302320"
  },
  {
    "text": "these are the arguments that are",
    "start": "302320",
    "end": "303240"
  },
  {
    "text": "actually going to the main method of the",
    "start": "303240",
    "end": "307199"
  },
  {
    "text": "class that's been specified in my job",
    "start": "307199",
    "end": "308720"
  },
  {
    "text": "jars manifest so here I know I need to",
    "start": "308720",
    "end": "311479"
  },
  {
    "text": "specify the input file that I'm going to",
    "start": "311479",
    "end": "313600"
  },
  {
    "text": "be processing and note that here I'm",
    "start": "313600",
    "end": "316120"
  },
  {
    "text": "using real htfs paths so I'm specifying",
    "start": "316120",
    "end": "319639"
  },
  {
    "text": "s3n as the protocol because input file",
    "start": "319639",
    "end": "322880"
  },
  {
    "text": "is going to be coming from S3 and of",
    "start": "322880",
    "end": "325560"
  },
  {
    "text": "course it's coming out of the AWS test",
    "start": "325560",
    "end": "327720"
  },
  {
    "text": "KK bucket and",
    "start": "327720",
    "end": "330479"
  },
  {
    "text": "the location of the data subter and Ian",
    "start": "330479",
    "end": "336479"
  },
  {
    "text": "Wiki split.",
    "start": "336680",
    "end": "339240"
  },
  {
    "text": "XML I also have to tell my program where",
    "start": "339240",
    "end": "342360"
  },
  {
    "text": "the output's going so I'm going to say",
    "start": "342360",
    "end": "343800"
  },
  {
    "text": "minus output and this case again it",
    "start": "343800",
    "end": "346800"
  },
  {
    "text": "needs to go into S3 because otherwise",
    "start": "346800",
    "end": "349560"
  },
  {
    "text": "it's just going to disappear when the",
    "start": "349560",
    "end": "350840"
  },
  {
    "text": "cluster terminates so I'm going to again",
    "start": "350840",
    "end": "353960"
  },
  {
    "text": "put it into that",
    "start": "353960",
    "end": "356000"
  },
  {
    "text": "same AWS test KK bucket in the results",
    "start": "356000",
    "end": "361759"
  },
  {
    "text": "directory",
    "start": "361759",
    "end": "363960"
  },
  {
    "text": "and I also can specify an additional",
    "start": "363960",
    "end": "366599"
  },
  {
    "text": "parameter to my program that says I only",
    "start": "366599",
    "end": "367960"
  },
  {
    "text": "want to use one reduced task so wind up",
    "start": "367960",
    "end": "369720"
  },
  {
    "text": "with a single output file so I click the",
    "start": "369720",
    "end": "372639"
  },
  {
    "text": "continue button and now it's letting me",
    "start": "372639",
    "end": "375440"
  },
  {
    "text": "pick the type and the number of the",
    "start": "375440",
    "end": "377680"
  },
  {
    "text": "servers that are going into my cluster",
    "start": "377680",
    "end": "379680"
  },
  {
    "text": "so for my master I'm going to use an M1",
    "start": "379680",
    "end": "381520"
  },
  {
    "text": "small instance here for my slaves I'm",
    "start": "381520",
    "end": "384720"
  },
  {
    "text": "going to use two and one small instances",
    "start": "384720",
    "end": "387440"
  },
  {
    "text": "and I'm not going to use any task only",
    "start": "387440",
    "end": "389960"
  },
  {
    "text": "instances we'll talk about that in the",
    "start": "389960",
    "end": "391800"
  },
  {
    "text": "last module of the course where you can",
    "start": "391800",
    "end": "394160"
  },
  {
    "text": "use a tax task instance group and",
    "start": "394160",
    "end": "396479"
  },
  {
    "text": "request spot pricing for it uh and",
    "start": "396479",
    "end": "398319"
  },
  {
    "text": "there's good reasons for doing that but",
    "start": "398319",
    "end": "399720"
  },
  {
    "text": "we don't need to do that for this",
    "start": "399720",
    "end": "400840"
  },
  {
    "text": "particular",
    "start": "400840",
    "end": "403440"
  },
  {
    "text": "example and for keys I'm using that AWS",
    "start": "403440",
    "end": "406479"
  },
  {
    "text": "test key that I previously created for",
    "start": "406479",
    "end": "409199"
  },
  {
    "text": "the key pair I don't need to have a",
    "start": "409199",
    "end": "411800"
  },
  {
    "text": "virtual private Cloud um for the logs",
    "start": "411800",
    "end": "416800"
  },
  {
    "text": "that are being generated by the job I",
    "start": "416800",
    "end": "418960"
  },
  {
    "text": "want them to go into that AWS test KK",
    "start": "418960",
    "end": "421479"
  },
  {
    "text": "bucket in the lob logs",
    "start": "421479",
    "end": "423599"
  },
  {
    "text": "subdirectory I'm not doing any special",
    "start": "423599",
    "end": "426800"
  },
  {
    "text": "debugging logging if I did want to do",
    "start": "426800",
    "end": "428759"
  },
  {
    "text": "this I'd have to use Simple DB we'll",
    "start": "428759",
    "end": "431080"
  },
  {
    "text": "talk about that later and uh I don't",
    "start": "431080",
    "end": "433919"
  },
  {
    "text": "need to keep my cluster around once the",
    "start": "433919",
    "end": "436560"
  },
  {
    "text": "job finishes so keep alive is set to",
    "start": "436560",
    "end": "440720"
  },
  {
    "text": "no when I click continue it lets me um",
    "start": "441120",
    "end": "445000"
  },
  {
    "text": "decide whether I want to use anything",
    "start": "445000",
    "end": "446440"
  },
  {
    "text": "any bootstrap actions and we'll talk",
    "start": "446440",
    "end": "448080"
  },
  {
    "text": "about that again in the last module this",
    "start": "448080",
    "end": "450199"
  },
  {
    "text": "is a way to sort of alter the",
    "start": "450199",
    "end": "452360"
  },
  {
    "text": "configuration of my cluster or do",
    "start": "452360",
    "end": "453919"
  },
  {
    "text": "special setup of servers in my cluster",
    "start": "453919",
    "end": "455759"
  },
  {
    "text": "but I don't need any of that so I click",
    "start": "455759",
    "end": "458120"
  },
  {
    "text": "continue gives me one last chance to",
    "start": "458120",
    "end": "460440"
  },
  {
    "text": "check over all the",
    "start": "460440",
    "end": "461840"
  },
  {
    "text": "settings and then I can create the job",
    "start": "461840",
    "end": "464360"
  },
  {
    "text": "flow once the job FL has been created I",
    "start": "464360",
    "end": "467440"
  },
  {
    "text": "can go back over here and it'll show me",
    "start": "467440",
    "end": "469280"
  },
  {
    "text": "that I've got this job that's starting",
    "start": "469280",
    "end": "472000"
  },
  {
    "text": "up and at some point typically a couple",
    "start": "472000",
    "end": "475120"
  },
  {
    "text": "of minutes my cluster will be running",
    "start": "475120",
    "end": "476879"
  },
  {
    "text": "which means elastic map reduce has has",
    "start": "476879",
    "end": "479840"
  },
  {
    "text": "allocated the servers that I asked for",
    "start": "479840",
    "end": "482599"
  },
  {
    "text": "uh provisioned them with",
    "start": "482599",
    "end": "484800"
  },
  {
    "text": "Hadoop downloaded my job jar and started",
    "start": "484800",
    "end": "487520"
  },
  {
    "text": "up the job and so we're going to wait",
    "start": "487520",
    "end": "489319"
  },
  {
    "text": "until that happens and we're going to",
    "start": "489319",
    "end": "490720"
  },
  {
    "text": "take a look at the job as it's",
    "start": "490720",
    "end": "493759"
  },
  {
    "text": "running while your job is running you",
    "start": "493759",
    "end": "495759"
  },
  {
    "start": "495000",
    "end": "495000"
  },
  {
    "text": "can use the AWS console to monitor it to",
    "start": "495759",
    "end": "498720"
  },
  {
    "text": "find out what state it's in is it",
    "start": "498720",
    "end": "500360"
  },
  {
    "text": "starting up is it actually running the",
    "start": "500360",
    "end": "501720"
  },
  {
    "text": "job is it terminating is it done you can",
    "start": "501720",
    "end": "505360"
  },
  {
    "text": "also see how long it's been running and",
    "start": "505360",
    "end": "507039"
  },
  {
    "text": "you get an estimate of roughly how much",
    "start": "507039",
    "end": "509039"
  },
  {
    "text": "it's going to cost you and if need be",
    "start": "509039",
    "end": "511000"
  },
  {
    "text": "you can terminate the job so we've",
    "start": "511000",
    "end": "513039"
  },
  {
    "text": "started our job let's go take a look at",
    "start": "513039",
    "end": "515399"
  },
  {
    "text": "it okay now you see we're actually",
    "start": "515399",
    "end": "517560"
  },
  {
    "text": "running the job so the status has",
    "start": "517560",
    "end": "519320"
  },
  {
    "text": "changed to",
    "start": "519320",
    "end": "520599"
  },
  {
    "text": "running and here it shows that you have",
    "start": "520599",
    "end": "523640"
  },
  {
    "text": "this normalized instance hours what",
    "start": "523640",
    "end": "525959"
  },
  {
    "text": "that's saying is that as soon as this",
    "start": "525959",
    "end": "527680"
  },
  {
    "text": "cluster starts actually running I'm",
    "start": "527680",
    "end": "530360"
  },
  {
    "text": "being charged for three servers times up",
    "start": "530360",
    "end": "534240"
  },
  {
    "text": "to an hour and if I actually had a job",
    "start": "534240",
    "end": "537519"
  },
  {
    "text": "that ran longer than an hour then you'd",
    "start": "537519",
    "end": "539000"
  },
  {
    "text": "see this jumping up to six instance",
    "start": "539000",
    "end": "541160"
  },
  {
    "text": "hours this is one of the reasons why you",
    "start": "541160",
    "end": "543120"
  },
  {
    "text": "want to avoid having a job that fails",
    "start": "543120",
    "end": "544959"
  },
  {
    "text": "right away because you're still going to",
    "start": "544959",
    "end": "546360"
  },
  {
    "text": "pay for the number of servers times at",
    "start": "546360",
    "end": "549200"
  },
  {
    "text": "least 1 hour even if your job only runs",
    "start": "549200",
    "end": "551079"
  },
  {
    "text": "for 10",
    "start": "551079",
    "end": "552320"
  },
  {
    "text": "seconds now the actual run time for this",
    "start": "552320",
    "end": "554480"
  },
  {
    "text": "job isn't very long so I expect pretty",
    "start": "554480",
    "end": "556240"
  },
  {
    "text": "quickly that this job will succeed if I",
    "start": "556240",
    "end": "559079"
  },
  {
    "text": "go down here and look at the",
    "start": "559079",
    "end": "561920"
  },
  {
    "text": "steps what you'll see here is I've got",
    "start": "561920",
    "end": "564959"
  },
  {
    "text": "essentially one step in my flow which is",
    "start": "564959",
    "end": "568360"
  },
  {
    "text": "this single jar uh job that's running",
    "start": "568360",
    "end": "571399"
  },
  {
    "text": "with my parameters that I passed it down",
    "start": "571399",
    "end": "575160"
  },
  {
    "text": "here once the job finishes the status",
    "start": "576560",
    "end": "579160"
  },
  {
    "text": "will change to shutting down and at that",
    "start": "579160",
    "end": "582160"
  },
  {
    "text": "point the results of the Run are being",
    "start": "582160",
    "end": "586079"
  },
  {
    "text": "copied up to S3 which includes both the",
    "start": "586079",
    "end": "588120"
  },
  {
    "text": "results and also the um log files so you",
    "start": "588120",
    "end": "593360"
  },
  {
    "text": "can see the status just changed to",
    "start": "593360",
    "end": "594760"
  },
  {
    "text": "shutting",
    "start": "594760",
    "end": "595720"
  },
  {
    "text": "down my laps time and the laps time",
    "start": "595720",
    "end": "598640"
  },
  {
    "text": "actually doesn't start",
    "start": "598640",
    "end": "600040"
  },
  {
    "text": "until the cluster is actually up and",
    "start": "600040",
    "end": "602240"
  },
  {
    "text": "running the job so the total lapse time",
    "start": "602240",
    "end": "604640"
  },
  {
    "text": "for this job was only 4",
    "start": "604640",
    "end": "606399"
  },
  {
    "text": "minutes now the job is finished I can",
    "start": "606399",
    "end": "608680"
  },
  {
    "start": "607000",
    "end": "607000"
  },
  {
    "text": "actually go take a look at the",
    "start": "608680",
    "end": "610600"
  },
  {
    "text": "results when I set up my job I specified",
    "start": "610600",
    "end": "613920"
  },
  {
    "text": "my output directory and that was",
    "start": "613920",
    "end": "615360"
  },
  {
    "text": "actually a parameter to the job that I",
    "start": "615360",
    "end": "617680"
  },
  {
    "text": "was running so I told it we an S3 to put",
    "start": "617680",
    "end": "620399"
  },
  {
    "text": "it using the s3n protocol now because",
    "start": "620399",
    "end": "623399"
  },
  {
    "text": "the Hadoop cluster goes away at the end",
    "start": "623399",
    "end": "625800"
  },
  {
    "text": "of the job it means all the drives that",
    "start": "625800",
    "end": "628360"
  },
  {
    "text": "are used for HD FS they're ephemeral",
    "start": "628360",
    "end": "631320"
  },
  {
    "text": "which means they disappear so the only",
    "start": "631320",
    "end": "634399"
  },
  {
    "text": "way to persist data typically is that",
    "start": "634399",
    "end": "636800"
  },
  {
    "text": "you have to write it to S3 now you can",
    "start": "636800",
    "end": "639920"
  },
  {
    "text": "set up job flows where they are alive",
    "start": "639920",
    "end": "643639"
  },
  {
    "text": "that means they don't terminate at the",
    "start": "643639",
    "end": "644839"
  },
  {
    "text": "end of your job and that's a great way",
    "start": "644839",
    "end": "647000"
  },
  {
    "text": "to debug jobs when you're first getting",
    "start": "647000",
    "end": "649120"
  },
  {
    "text": "started with them and we'll talk about",
    "start": "649120",
    "end": "651279"
  },
  {
    "text": "uh that more later but a typical run has",
    "start": "651279",
    "end": "654760"
  },
  {
    "text": "everything going into S3 which means you",
    "start": "654760",
    "end": "656600"
  },
  {
    "text": "get both the results and and typically",
    "start": "656600",
    "end": "660200"
  },
  {
    "text": "that's because your program is using",
    "start": "660200",
    "end": "661680"
  },
  {
    "text": "some output path that you specify and",
    "start": "661680",
    "end": "664120"
  },
  {
    "text": "you tell it that you want to write it",
    "start": "664120",
    "end": "665600"
  },
  {
    "text": "into S3 and secondly elastic map reduce",
    "start": "665600",
    "end": "669120"
  },
  {
    "text": "is going to copy all of the log files up",
    "start": "669120",
    "end": "670880"
  },
  {
    "text": "to the location you specified in S3 and",
    "start": "670880",
    "end": "673279"
  },
  {
    "text": "in our case we used the bucket name aw-",
    "start": "673279",
    "end": "676880"
  },
  {
    "text": "test- kk/",
    "start": "676880",
    "end": "679279"
  },
  {
    "text": "logs so let's go look at the job results",
    "start": "679279",
    "end": "682480"
  },
  {
    "text": "now if I go over to",
    "start": "682480",
    "end": "685360"
  },
  {
    "text": "S3 and I take a look",
    "start": "687279",
    "end": "689839"
  },
  {
    "text": "in my AWS test KK",
    "start": "689839",
    "end": "694600"
  },
  {
    "text": "bucket you see I've got my four",
    "start": "695240",
    "end": "697440"
  },
  {
    "text": "directories there if I look in the",
    "start": "697440",
    "end": "699040"
  },
  {
    "text": "results",
    "start": "699040",
    "end": "701480"
  },
  {
    "text": "directory my job is created two",
    "start": "702880",
    "end": "705639"
  },
  {
    "text": "subdirectories inside there raw counts",
    "start": "705639",
    "end": "707360"
  },
  {
    "text": "and sorted counts sorted counts I know",
    "start": "707360",
    "end": "709519"
  },
  {
    "text": "is the final",
    "start": "709519",
    "end": "712200"
  },
  {
    "text": "output and here you see the typical",
    "start": "713079",
    "end": "715160"
  },
  {
    "text": "Hadoop success file and then also a part",
    "start": "715160",
    "end": "717120"
  },
  {
    "text": "file from the reducer so part-",
    "start": "717120",
    "end": "720680"
  },
  {
    "text": "r-50 and I can actually download this",
    "start": "720680",
    "end": "724519"
  },
  {
    "text": "file and I'll open it up with BB edit my",
    "start": "724519",
    "end": "728399"
  },
  {
    "text": "editor of",
    "start": "728399",
    "end": "729920"
  },
  {
    "text": "choice and that displays results that",
    "start": "729920",
    "end": "734279"
  },
  {
    "text": "look like this now what this job does is",
    "start": "734279",
    "end": "736079"
  },
  {
    "text": "it generates Byram Counts from text",
    "start": "736079",
    "end": "738120"
  },
  {
    "text": "found in Wikipedia stories so you can",
    "start": "738120",
    "end": "740680"
  },
  {
    "text": "see that the most common Byram was eace",
    "start": "740680",
    "end": "742959"
  },
  {
    "text": "and it occurred 4,25 times in that",
    "start": "742959",
    "end": "746199"
  },
  {
    "text": "snippet from Wikipedia that I uploaded",
    "start": "746199",
    "end": "748360"
  },
  {
    "text": "into the S3 uh data directory",
    "start": "748360",
    "end": "751639"
  },
  {
    "text": "subdirectory of my",
    "start": "751639",
    "end": "754800"
  },
  {
    "text": "bucket now if we go back up to the",
    "start": "754959",
    "end": "758199"
  },
  {
    "text": "Bucket",
    "start": "758199",
    "end": "760440"
  },
  {
    "text": "Level and I look in",
    "start": "760440",
    "end": "762639"
  },
  {
    "text": "logs what you'll see here is it's",
    "start": "762639",
    "end": "764720"
  },
  {
    "text": "created a j-h and then a job ID",
    "start": "764720",
    "end": "769079"
  },
  {
    "text": "directory so this has information about",
    "start": "769079",
    "end": "771560"
  },
  {
    "text": "the actual job if I open up this one",
    "start": "771560",
    "end": "774079"
  },
  {
    "text": "you'll see there's a bunch of",
    "start": "774079",
    "end": "775480"
  },
  {
    "text": "subdirectories most of this isn't that",
    "start": "775480",
    "end": "777399"
  },
  {
    "text": "interesting it's information being",
    "start": "777399",
    "end": "778680"
  },
  {
    "text": "logged by the Hadoop system itself but",
    "start": "778680",
    "end": "780600"
  },
  {
    "text": "if you look in steps I only had one step",
    "start": "780600",
    "end": "784120"
  },
  {
    "text": "so it's just a single subdirectory",
    "start": "784120",
    "end": "786000"
  },
  {
    "text": "called one if I look inside of that",
    "start": "786000",
    "end": "788959"
  },
  {
    "text": "you'll see I've got a number of files in",
    "start": "788959",
    "end": "790560"
  },
  {
    "text": "here the interesting one is standard out",
    "start": "790560",
    "end": "793279"
  },
  {
    "text": "this is where my login goes so if I",
    "start": "793279",
    "end": "795720"
  },
  {
    "text": "double click at this because it's a",
    "start": "795720",
    "end": "797120"
  },
  {
    "text": "regular text file uh I'll just get a",
    "start": "797120",
    "end": "799639"
  },
  {
    "text": "window popped up with the results with",
    "start": "799639",
    "end": "801639"
  },
  {
    "text": "the contents of this and this is what my",
    "start": "801639",
    "end": "804440"
  },
  {
    "text": "job was logging it was giving me",
    "start": "804440",
    "end": "806839"
  },
  {
    "text": "information about the job tracker and I",
    "start": "806839",
    "end": "808480"
  },
  {
    "text": "printed out some information about input",
    "start": "808480",
    "end": "810160"
  },
  {
    "text": "and output paths and the engram size I",
    "start": "810160",
    "end": "813160"
  },
  {
    "text": "was using",
    "start": "813160",
    "end": "815639"
  },
  {
    "text": "Etc so as you can see elastic map ruce",
    "start": "815800",
    "end": "819560"
  },
  {
    "text": "automatically uploaded this information",
    "start": "819560",
    "end": "822160"
  },
  {
    "text": "into the directory that I'd specified as",
    "start": "822160",
    "end": "824399"
  },
  {
    "text": "my logs directory when I was defining my",
    "start": "824399",
    "end": "826199"
  },
  {
    "text": "job and if in particular my job failed",
    "start": "826199",
    "end": "830000"
  },
  {
    "text": "then this is where I'd start looking for",
    "start": "830000",
    "end": "831800"
  },
  {
    "text": "Clues as to what went wrong and remember",
    "start": "831800",
    "end": "834399"
  },
  {
    "text": "that there's a a lag between when the",
    "start": "834399",
    "end": "836560"
  },
  {
    "text": "job finishes and this data gets uploaded",
    "start": "836560",
    "end": "838480"
  },
  {
    "text": "especially if your job's doing a lot of",
    "start": "838480",
    "end": "840639"
  },
  {
    "text": "logging then you can have potentially",
    "start": "840639",
    "end": "842959"
  },
  {
    "text": "many many gigabytes of log files and",
    "start": "842959",
    "end": "845279"
  },
  {
    "text": "those will take some time to upload so",
    "start": "845279",
    "end": "846800"
  },
  {
    "text": "if you have a large cluster generating",
    "start": "846800",
    "end": "848079"
  },
  {
    "text": "lots of logging output I typically wait",
    "start": "848079",
    "end": "850160"
  },
  {
    "text": "at least 5 minutes more like 10 minutes",
    "start": "850160",
    "end": "852160"
  },
  {
    "text": "after my job has finished before I start",
    "start": "852160",
    "end": "853959"
  },
  {
    "text": "looking for the logs from the job all",
    "start": "853959",
    "end": "856920"
  },
  {
    "text": "right to",
    "start": "856920",
    "end": "857839"
  },
  {
    "start": "857000",
    "end": "857000"
  },
  {
    "text": "summarize running jobs using elastic map",
    "start": "857839",
    "end": "861040"
  },
  {
    "text": "reduce is very simple you def the jobs",
    "start": "861040",
    "end": "863680"
  },
  {
    "text": "using databas console your input data",
    "start": "863680",
    "end": "866880"
  },
  {
    "text": "and your job jar get gets loaded from S3",
    "start": "866880",
    "end": "871680"
  },
  {
    "text": "the results of your job which include",
    "start": "871680",
    "end": "873279"
  },
  {
    "text": "the log files get pushed back up to S3",
    "start": "873279",
    "end": "875639"
  },
  {
    "text": "and you can use the AWS console to",
    "start": "875639",
    "end": "877199"
  },
  {
    "text": "monitor the status of your job now in",
    "start": "877199",
    "end": "880079"
  },
  {
    "text": "the next module we're going to go and",
    "start": "880079",
    "end": "881320"
  },
  {
    "text": "look at the different options you have",
    "start": "881320",
    "end": "883360"
  },
  {
    "text": "for servers that you can use to create",
    "start": "883360",
    "end": "885519"
  },
  {
    "text": "your Hadoop cluster",
    "start": "885519",
    "end": "889040"
  }
]
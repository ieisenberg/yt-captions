[
  {
    "start": "0",
    "end": "145000"
  },
  {
    "text": "hello and welcome to Amazon elastic cash deep dive my name is Michael abib I'm a",
    "start": "1079",
    "end": "6279"
  },
  {
    "text": "specialist Solutions architect here at AWS and I'm delighted to share the stage today with Brian Kaiser CTO of huddle",
    "start": "6279",
    "end": "13719"
  },
  {
    "text": "who will be presenting afterward now we have a lot of content that we're going to present today so uh please uh save",
    "start": "13719",
    "end": "19880"
  },
  {
    "text": "your questions to the end of the session and we'll we'll stick around and take those",
    "start": "19880",
    "end": "25400"
  },
  {
    "text": "questions all right so today we're going to be talking about the value of a key Value Store we're going to dive into",
    "start": "26800",
    "end": "33200"
  },
  {
    "text": "Amazon elasticache we're going to look at the various usage patterns that you could use Amazon elasticache with we'll",
    "start": "33200",
    "end": "39480"
  },
  {
    "text": "talk about how you can scale your data using redus cluster we'll look at Best Practices and at that point I'm going to",
    "start": "39480",
    "end": "45360"
  },
  {
    "text": "hand it over to Brian all right [Music]",
    "start": "45360",
    "end": "51199"
  },
  {
    "text": "so we are headed into a the midst of a massive shift toward real-time data and",
    "start": "51199",
    "end": "58399"
  },
  {
    "text": "if you think about the the need for you know realtime analytics the data",
    "start": "58399",
    "end": "64080"
  },
  {
    "text": "velocity the data volume um it really created an emerging trend for this fast",
    "start": "64080",
    "end": "71080"
  },
  {
    "text": "data so in our session today what we're going to do is we're going to talk about how Amazon elasticache can power those",
    "start": "71080",
    "end": "77880"
  },
  {
    "text": "various workloads outside of caching what is Amazon elasticache so",
    "start": "77880",
    "end": "83960"
  },
  {
    "text": "it's a managed service it supports the two most popular key Value Store engines which is R ASC",
    "start": "83960",
    "end": "90600"
  },
  {
    "text": "it's fully managed so what that means is you don't have to worry about anything besides your data and the size of your",
    "start": "90600",
    "end": "96720"
  },
  {
    "text": "cluster it is uh highly available reliable and it's managed and hardened by Amazon so we're going to talk about",
    "start": "96720",
    "end": "103360"
  },
  {
    "text": "what that exactly means in a later slide now if you were to think about",
    "start": "103360",
    "end": "109240"
  },
  {
    "text": "your data as a temperature gauge you would want that hot data to be readily available you would want it to support",
    "start": "109240",
    "end": "116039"
  },
  {
    "text": "extremely high request rates you'd want it to support extremely low latency see that's where Amazon elasticache fits you",
    "start": "116039",
    "end": "122680"
  },
  {
    "text": "might also have cold data you might also have warm data and for those data uh for those data needs you'll have data",
    "start": "122680",
    "end": "128679"
  },
  {
    "text": "different data uh data stores that can augment Your solution and so for your coal data you might want to put that in",
    "start": "128679",
    "end": "134280"
  },
  {
    "text": "Amazon Glacier which you can archive and do something else with it and the same thing is true for those other data",
    "start": "134280",
    "end": "140720"
  },
  {
    "text": "stores uh in between and it all depends on your use case so I mentioned there are two",
    "start": "140720",
    "end": "148160"
  },
  {
    "start": "145000",
    "end": "145000"
  },
  {
    "text": "popular uh key values stores that are supported with elasticache the first one being MCD so MCD has been available and",
    "start": "148160",
    "end": "155599"
  },
  {
    "text": "around since 2003 it's been the gold standard of caching for many years um if",
    "start": "155599",
    "end": "161120"
  },
  {
    "text": "you think about the capabilities of MCD it's really like a flat cache it supports a a data structure which is a",
    "start": "161120",
    "end": "167800"
  },
  {
    "text": "string you can support up to one megabyte in that value um it has no persistence so if you're adding shards",
    "start": "167800",
    "end": "175959"
  },
  {
    "text": "in a MCD cluster uh and you lose the data in a particular node you lost that",
    "start": "175959",
    "end": "181040"
  },
  {
    "text": "data and for a caching use case that's uh that's okay um and if it's not okay",
    "start": "181040",
    "end": "187280"
  },
  {
    "text": "this is kind of where reddis fits in and we'll talk about that other things with MCD it's very easy to scale you can add",
    "start": "187280",
    "end": "194159"
  },
  {
    "text": "nodes and your key space will kind of distribute across those nodes pretty easily and uh and it's insanely fast",
    "start": "194159",
    "end": "202159"
  },
  {
    "text": "right so I mean we're dealing with microc performance Reddit on the other hand I",
    "start": "202159",
    "end": "208480"
  },
  {
    "text": "like to think of is a super set to mecd why do I say that well it supports the",
    "start": "208480",
    "end": "213680"
  },
  {
    "text": "string data structure so you can have the string value except from a one",
    "start": "213680",
    "end": "219120"
  },
  {
    "text": "megabyte instead of having data up to one megabyte you can store up to 512 megabytes worth of data um there are",
    "start": "219120",
    "end": "225840"
  },
  {
    "text": "other data structures which we're going to dive into it has persistence so if you care about that data and you want to",
    "start": "225840",
    "end": "231959"
  },
  {
    "text": "have uh you know support RTO and rpos you can do that with redus we'll talk about the different options you have",
    "start": "231959",
    "end": "238480"
  },
  {
    "text": "it's highly available so you you can have a master and if that primary node fails you can have a read replica which",
    "start": "238480",
    "end": "244959"
  },
  {
    "text": "will be uh promoted to be the new uh new master it's very powerful there's over",
    "start": "244959",
    "end": "250840"
  },
  {
    "text": "200 commands in reddis you have Lis scripting which you can uh build some business logic and you can have that",
    "start": "250840",
    "end": "257199"
  },
  {
    "text": "logic execute in memory um and it's also simple and that's important to to",
    "start": "257199",
    "end": "262360"
  },
  {
    "text": "mention because syntactically it's very easy to use and we we'll see some examples later in this",
    "start": "262360",
    "end": "268600"
  },
  {
    "text": "presentation so when we talk about data structures I",
    "start": "268600",
    "end": "274639"
  },
  {
    "start": "272000",
    "end": "272000"
  },
  {
    "text": "like to start with the basic so the basic data structure is a string now in redus this is supported both in mecd and",
    "start": "274639",
    "end": "282080"
  },
  {
    "text": "redus in me in redus it's uh you know it supports up to 512 megabytes it's binary safe so what does that mean what it",
    "start": "282080",
    "end": "288840"
  },
  {
    "text": "means is you can essentially put any anything that fits into that space in that value that could be HTML code it",
    "start": "288840",
    "end": "296160"
  },
  {
    "text": "could be a Json object it could be a image a picture and there's also a cool",
    "start": "296160",
    "end": "301199"
  },
  {
    "text": "capability where if you have an integer representation in that string value uh",
    "start": "301199",
    "end": "306400"
  },
  {
    "text": "you can increment and decrement that value uh and use it as a counter where it gets interesting with",
    "start": "306400",
    "end": "312720"
  },
  {
    "start": "311000",
    "end": "311000"
  },
  {
    "text": "Reus is these additional data structures the first one we'll talk about is a set so if you remember uh if you came from a",
    "start": "312720",
    "end": "319720"
  },
  {
    "text": "Dev background a set is a collection that allows you to have unique values or elements within that collection so say",
    "start": "319720",
    "end": "327160"
  },
  {
    "text": "for example you have a customer you want to group maybe your customer IDs your key may be that uh customer um the",
    "start": "327160",
    "end": "335080"
  },
  {
    "text": "customer list and then every value that you have in that set might be a customer ID and this is great why because you",
    "start": "335080",
    "end": "342160"
  },
  {
    "text": "don't want to have duplicate customer IDs so this is managed for you in memory it's lightning fast it's microsc",
    "start": "342160",
    "end": "349360"
  },
  {
    "text": "performance and it's a great way to group your data",
    "start": "349360",
    "end": "354720"
  },
  {
    "text": "together now a sorted set is a set so it it it maintains those unique values",
    "start": "354759",
    "end": "361600"
  },
  {
    "start": "355000",
    "end": "355000"
  },
  {
    "text": "within the set but it also has an interesting parameter which is a score now a score allows you to sort the data",
    "start": "361600",
    "end": "368720"
  },
  {
    "text": "based on a particular value right so take for example you are building a game",
    "start": "368720",
    "end": "374199"
  },
  {
    "text": "and your key might be a leaderboard and then your users are the value and uh you",
    "start": "374199",
    "end": "381199"
  },
  {
    "text": "want to sort these users based on something right so in a game you're actually sorting them by the",
    "start": "381199",
    "end": "387319"
  },
  {
    "text": "score so again this has happened for you in an in-memory Performance Engine and",
    "start": "387319",
    "end": "393759"
  },
  {
    "text": "uh you pass in those values it'll maintain the uniqueness and it will sort it for you automatically and then you",
    "start": "393759",
    "end": "399440"
  },
  {
    "text": "can retrieve it in a number of ways one way that you can retrieve it is you know in a synchronous order and a reverse",
    "start": "399440",
    "end": "405960"
  },
  {
    "text": "order and you can pull in a range of information so again this is great for duping information for grouping",
    "start": "405960",
    "end": "412680"
  },
  {
    "text": "information and sorting information and we'll take a look at other use cases where you can use a sorted",
    "start": "412680",
    "end": "418400"
  },
  {
    "text": "set a list is a collection that allows you to capture the elements that are",
    "start": "418400",
    "end": "424479"
  },
  {
    "start": "419000",
    "end": "419000"
  },
  {
    "text": "inserted in that order so there is no particular order that this is maintained",
    "start": "424479",
    "end": "431080"
  },
  {
    "text": "uh and but it's great for pushing and popping elements either from the head or the tail of this list so a lot of common",
    "start": "431080",
    "end": "438960"
  },
  {
    "text": "patterns that are built using a list could be you know a a timeline and so you can have a timeline that might be",
    "start": "438960",
    "end": "445240"
  },
  {
    "text": "your key and all the elements that you put in that list could be an event based",
    "start": "445240",
    "end": "451000"
  },
  {
    "text": "on that timeline so this is a common pattern and a usage for a",
    "start": "451000",
    "end": "456080"
  },
  {
    "start": "456000",
    "end": "456000"
  },
  {
    "text": "list and in hashes they are my favorite so what a hash allows you to do is it's",
    "start": "456080",
    "end": "462000"
  },
  {
    "text": "the it's a it's a data structure that is suited for object rep rep representation",
    "start": "462000",
    "end": "467440"
  },
  {
    "text": "so take for example you have a customer record now that customer has attributes",
    "start": "467440",
    "end": "473080"
  },
  {
    "text": "that attribute could be you know the customer name could be a customer address so if you're using a hash the",
    "start": "473080",
    "end": "479319"
  },
  {
    "text": "the key may be your customer ID and then all the fields and values associated with that customer are the attributes",
    "start": "479319",
    "end": "486159"
  },
  {
    "text": "related to that customer now why is a cash why is a hash cool you can create a Json object and",
    "start": "486159",
    "end": "493360"
  },
  {
    "text": "you can store this in a string but what I like about hashes is that you can do operations on individual Fields so you",
    "start": "493360",
    "end": "500919"
  },
  {
    "text": "can set the data in a hash it's memory efficient in reddis and then I can query",
    "start": "500919",
    "end": "506159"
  },
  {
    "text": "individual elements so maybe within my customer key or my customer list or my",
    "start": "506159",
    "end": "511599"
  },
  {
    "text": "my individual customer I just want to know his address I can just query for that individual field so it's",
    "start": "511599",
    "end": "519080"
  },
  {
    "start": "519000",
    "end": "519000"
  },
  {
    "text": "great one of the questions that I get a lot from customers who are new to you know caching is which one should I use",
    "start": "519080",
    "end": "526240"
  },
  {
    "text": "mcash te or reddis and so one of the things I like to do is kind of think backwards um if you are just doing a",
    "start": "526240",
    "end": "533560"
  },
  {
    "text": "caching use case and uh I'd like to start with what you know what languages are you using you might be using a",
    "start": "533560",
    "end": "540480"
  },
  {
    "text": "language that um you know has you know sophisticated support for mecd maybe",
    "start": "540480",
    "end": "546120"
  },
  {
    "text": "it's baked into the framework and if you're just using caching maybe MEC te is good enough however if you are",
    "start": "546120",
    "end": "553640"
  },
  {
    "text": "needing to do caching but you think that there might be other use cases for your data I I'll tell you to use redus I",
    "start": "553640",
    "end": "560320"
  },
  {
    "text": "think redus in a lot of ways does what mecd can do but it but it can support additional use cases and we'll take a",
    "start": "560320",
    "end": "566600"
  },
  {
    "text": "look at those so some of the value propositions that",
    "start": "566600",
    "end": "574360"
  },
  {
    "text": "you get with elasticache I mentioned the first one it's fully managed what does that mean you just have to worry about",
    "start": "574360",
    "end": "580079"
  },
  {
    "text": "the data that you put in a cluster and the size of your actual cluster as far as patching as far as failovers all",
    "start": "580079",
    "end": "587120"
  },
  {
    "text": "those additional processes which we call heavy lifting it's kind of removed from your plate the other thing is that it's open",
    "start": "587120",
    "end": "594399"
  },
  {
    "text": "source compatible so if you're already if already have code written uh using Rus on E 2 you can easily Port that code",
    "start": "594399",
    "end": "601279"
  },
  {
    "text": "over to elasticache same is true for mecd so we support all the open source protocols there is no cross a uh data",
    "start": "601279",
    "end": "609839"
  },
  {
    "text": "transfer so this is uh sometimes overlooked so say for example you're running reddis on ec2 and you're in a",
    "start": "609839",
    "end": "616880"
  },
  {
    "text": "multi-az environment you may have you know uh your your nodes communicating",
    "start": "616880",
    "end": "622560"
  },
  {
    "text": "with each other and if you're doing that there is an additional charge so if you take a look at the actual charge for ec2",
    "start": "622560",
    "end": "629640"
  },
  {
    "text": "instance plus the data out you're in the same ballpark of using elasticache might",
    "start": "629640",
    "end": "635000"
  },
  {
    "text": "as well just use elasticache um and this is especially true when your node size or your cluster",
    "start": "635000",
    "end": "640519"
  },
  {
    "text": "size is large the other thing is that the enhanced redus engine comes with us and",
    "start": "640519",
    "end": "647880"
  },
  {
    "text": "so I'll talk about that in the next slide and this is really some of the lessons learned that we've heard from",
    "start": "647880",
    "end": "653079"
  },
  {
    "text": "our customers that we built into uh the service so the first one uh so the first",
    "start": "653079",
    "end": "659079"
  },
  {
    "start": "656000",
    "end": "656000"
  },
  {
    "text": "first feature is that we've heard from customers um that memory management can be challenging with reddish so one",
    "start": "659079",
    "end": "666279"
  },
  {
    "text": "example is say for example you're running redus and uh you have background processes like doing snapshots and",
    "start": "666279",
    "end": "672760"
  },
  {
    "text": "syncing especially with snapshots depending on how much rights you have occurring on the primary Reddit may take",
    "start": "672760",
    "end": "681000"
  },
  {
    "text": "up up to you know it may double your memory footprint on that instance and if you don't have enough memory for those",
    "start": "681000",
    "end": "686959"
  },
  {
    "text": "background processes they'll throw you into swap now you don't want to be in swap when you're an inmemory database",
    "start": "686959",
    "end": "692600"
  },
  {
    "text": "system so what we have is we have enhancements that detect that situation we'll look at how much memory you have",
    "start": "692600",
    "end": "698720"
  },
  {
    "text": "available on that on your instance and it will put you in a forkless backup",
    "start": "698720",
    "end": "704160"
  },
  {
    "text": "scenario the other one is a right throttling so if you have a lot of Rights hitting your primary we've heard",
    "start": "704160",
    "end": "709920"
  },
  {
    "text": "from customers that this could be challenging because your read replicas may fall out of sink and so we have",
    "start": "709920",
    "end": "715680"
  },
  {
    "text": "controls that will detect that scenario and it will th throttle some of those rights to make sure that your cluster is",
    "start": "715680",
    "end": "721600"
  },
  {
    "text": "in sync the last one that I'm going to talk about is a smoother failover process so",
    "start": "721600",
    "end": "727200"
  },
  {
    "text": "say for example you have a primary you have a replica actually you have a couple replicas and then your primary",
    "start": "727200",
    "end": "733760"
  },
  {
    "text": "fails one of your replicas will be elected to be the new primary but any other replica that you have the data",
    "start": "733760",
    "end": "740600"
  },
  {
    "text": "will be flushed and this is in this is if you're running it on E ec2 what we",
    "start": "740600",
    "end": "745680"
  },
  {
    "text": "have is we've kind of uh enhanced that process to make sure the whole failover process runs smoother so we don't flush",
    "start": "745680",
    "end": "752240"
  },
  {
    "text": "the data in the other replicas we just make sure that it's in sync with the newly elected uh the newly elected",
    "start": "752240",
    "end": "760440"
  },
  {
    "text": "primary let's talk about some usage patterns the most popular one is caching right so there's a couple reasons a",
    "start": "760440",
    "end": "767160"
  },
  {
    "text": "couple drivers that you want to do caching the first one is you want to alleviate some of the pressure to your",
    "start": "767160",
    "end": "773000"
  },
  {
    "text": "database now that pressure could be maybe you uh maybe can't your database can't scale it doesn't matter what your",
    "start": "773000",
    "end": "778480"
  },
  {
    "text": "database bases it could be Cassandra it could be Dynamo DB it could be it could be uh you know rdbms uh based",
    "start": "778480",
    "end": "785600"
  },
  {
    "text": "database it could be anything um the other reason the other driver is maybe the performance that",
    "start": "785600",
    "end": "791920"
  },
  {
    "text": "you're getting out of your database isn't good enough right you want to lower that latency in a few lines of code um you",
    "start": "791920",
    "end": "799399"
  },
  {
    "text": "can you can you can augment your architecture and add a caching layer right and so what that caching layer is",
    "start": "799399",
    "end": "805680"
  },
  {
    "text": "going to give you automatically it's going to give you a higher level of throughput up to 20 million reads per",
    "start": "805680",
    "end": "811880"
  },
  {
    "text": "second up to 4.5 million writes per second that's crazy the second one is",
    "start": "811880",
    "end": "817639"
  },
  {
    "text": "it's cost effective why do I say that because if you were trying to scale your database a lot of times the cost of",
    "start": "817639",
    "end": "823680"
  },
  {
    "text": "scaling your backend database which you'll never get the lower latency uh compared to a caching system the cost of",
    "start": "823680",
    "end": "830360"
  },
  {
    "text": "scaling your database is a lot higher than than adding a caching layer and then the third one is better",
    "start": "830360",
    "end": "837399"
  },
  {
    "text": "performance right you're getting micro second speed and in today's day and age you want to have that fast response",
    "start": "837399",
    "end": "843680"
  },
  {
    "text": "times to power your applications now if you're using Dynamo DB what's cool about this is that you",
    "start": "843680",
    "end": "850720"
  },
  {
    "text": "can have an automatic trigger which is automatically going to going to populate",
    "start": "850720",
    "end": "856320"
  },
  {
    "text": "the data in elastic hash so you can have a trigger based on an update that's hitting your Dynamo DB table that will",
    "start": "856320",
    "end": "863160"
  },
  {
    "text": "put that updated in a Dynamo DB stream where a Lambda function will be triggered off of that stream and",
    "start": "863160",
    "end": "868920"
  },
  {
    "text": "populate your data into elastic cache now outside of caching this is great for decorating your data because you might",
    "start": "868920",
    "end": "875399"
  },
  {
    "text": "not want to put that data in elasticache in the same way that it's stored into",
    "start": "875399",
    "end": "881320"
  },
  {
    "text": "Dynamo you might want to augment that data you might want to enhance or enrich that data and you can just code that",
    "start": "881320",
    "end": "886440"
  },
  {
    "text": "into your function now once you set this function it's just there it's just going to work for you this isn't this is a way",
    "start": "886440",
    "end": "892160"
  },
  {
    "text": "of a a right through pattern now I said earlier in a few lines of code you can you can can",
    "start": "892160",
    "end": "898959"
  },
  {
    "text": "augment your Solution by adding a cache let's see if I'm lying so from a right through if you see there's two lines",
    "start": "898959",
    "end": "904839"
  },
  {
    "text": "that are highlighted here essentially how a write through works is you you are",
    "start": "904839",
    "end": "910040"
  },
  {
    "text": "writing to your system of record to your database and and after you write to your database you immediately write that data",
    "start": "910040",
    "end": "916759"
  },
  {
    "text": "to your cache now what's great about a write through uh pattern is that you are",
    "start": "916759",
    "end": "923000"
  },
  {
    "text": "proactively filling your ca cache you're hydrating your cach with data that um is",
    "start": "923000",
    "end": "929120"
  },
  {
    "text": "that you think is usable now the con with doing this is that you are you have the potential of putting data into the",
    "start": "929120",
    "end": "934959"
  },
  {
    "text": "cache and using more memory than you then you probably need on the other hand there's another",
    "start": "934959",
    "end": "940160"
  },
  {
    "text": "common pattern that's lazy loading so the way lazy loading works is you check your cache to see if a value was there",
    "start": "940160",
    "end": "946720"
  },
  {
    "text": "if it is not there you retrieve it from your system of record your database and then you you set that data into your",
    "start": "946720",
    "end": "953839"
  },
  {
    "text": "cache now the value with that is that you are setting the data that that you know your application actually needs",
    "start": "953839",
    "end": "961199"
  },
  {
    "text": "right so the con is you have a higher chance of hitting getting a Miss which is you know the data is not in your",
    "start": "961199",
    "end": "967959"
  },
  {
    "text": "cache and uh you know that's that might not be best for your performance in practice people typically use both of",
    "start": "967959",
    "end": "974319"
  },
  {
    "text": "these patterns and they augment with uh a TTL an expire parameter based on the",
    "start": "974319",
    "end": "981399"
  },
  {
    "text": "data frequency the change of their data in their database so you have to understand how your data changes in your",
    "start": "981399",
    "end": "986880"
  },
  {
    "text": "system of record and then apply it to TL that corresponds to that",
    "start": "986880",
    "end": "992439"
  },
  {
    "text": "data okay so we're talking about caching another example I'll quickly go over session caching now when you're in a",
    "start": "992959",
    "end": "999759"
  },
  {
    "start": "994000",
    "end": "994000"
  },
  {
    "text": "distributed environment you have web applications um it's important to to uh",
    "start": "999759",
    "end": "1005759"
  },
  {
    "text": "you know abstract your sessions and put them in a distributed cache right so this is great especially if you have a",
    "start": "1005759",
    "end": "1011920"
  },
  {
    "text": "fleet of servers that can you know that can grow and shrink and based on your",
    "start": "1011920",
    "end": "1017040"
  },
  {
    "text": "usage so based on a lot of the Frameworks that you're using say for example this PHP",
    "start": "1017040",
    "end": "1022839"
  },
  {
    "text": "example I can augment my solution with just changing a couple configuration",
    "start": "1022839",
    "end": "1028600"
  },
  {
    "text": "changes and I don't have to create a session manager or do anything else I could just make these changes and now my",
    "start": "1028600",
    "end": "1034319"
  },
  {
    "text": "application is using in this example mcash T this is also true for redus and",
    "start": "1034319",
    "end": "1039798"
  },
  {
    "text": "it's also true for a variety of programming languages so this is just one example you could take a look at",
    "start": "1039799",
    "end": "1045678"
  },
  {
    "text": "that GitHub repo for how you can actually do this iot is an emerging kind of need that",
    "start": "1045679",
    "end": "1053160"
  },
  {
    "text": "we're seeing with customers so imagine you have a solution that you know you have devices and you're capturing say",
    "start": "1053160",
    "end": "1060120"
  },
  {
    "text": "sensor information um one of the ways that you could do this there's a variety of ways that you could do it but one of",
    "start": "1060120",
    "end": "1066000"
  },
  {
    "text": "the ways that you could do it is you can create an an AWS iot rule that rule will",
    "start": "1066000",
    "end": "1071400"
  },
  {
    "text": "trigger a Lambda function and then after that Lambda function is triggered you can have whatever sensor information",
    "start": "1071400",
    "end": "1078039"
  },
  {
    "text": "that's coming coming in you can have that basically persisted into your Amazon elasticache uh uh engine now why",
    "start": "1078039",
    "end": "1086200"
  },
  {
    "text": "is that good it's good because you're not paying for request rates you're not paying for throughput you are not paying",
    "start": "1086200",
    "end": "1092280"
  },
  {
    "text": "for anything from a from a cost effective perspective you're only paying for that instance type that you've",
    "start": "1092280",
    "end": "1097640"
  },
  {
    "text": "selected and you can support the 20 million reads and the 4.5 million rights",
    "start": "1097640",
    "end": "1103880"
  },
  {
    "text": "per second that's that's fast that's going to support all your device data now say for example you want to capture",
    "start": "1103880",
    "end": "1110919"
  },
  {
    "text": "that data in another repository maybe you want to have longer retention you can always augment Your solution and",
    "start": "1110919",
    "end": "1117080"
  },
  {
    "text": "dump that data in Dynamo DB you can also create a data Lake put that data in S3 and then you can do you know EMR jobs on",
    "start": "1117080",
    "end": "1123880"
  },
  {
    "text": "top of that data or you can archive that data into Amazon Glacier if we look at this particular",
    "start": "1123880",
    "end": "1130799"
  },
  {
    "text": "example for the iot rule you'll see that it's pretty simple this is a node.js example I actually have the code checked",
    "start": "1130799",
    "end": "1136840"
  },
  {
    "text": "into GitHub as well play around with that but the zad is essentially how you",
    "start": "1136840",
    "end": "1141880"
  },
  {
    "text": "add data to a sensor uh to a assorted set so the assorted set is called sensor data and the date is my score so we",
    "start": "1141880",
    "end": "1150240"
  },
  {
    "text": "talked earlier about what a score does in uh you know with redus with a sorted",
    "start": "1150240",
    "end": "1155760"
  },
  {
    "text": "set so what I want to do here is I want to capture time series data and it's important for me to have the actual time",
    "start": "1155760",
    "end": "1162919"
  },
  {
    "text": "or the the date of when that event actually occurred now when I query this data out of the sorted set I'm going to",
    "start": "1162919",
    "end": "1168600"
  },
  {
    "text": "do the reverse order so I know all the the values that happened in in you know",
    "start": "1168600",
    "end": "1173880"
  },
  {
    "text": "the most frequent data that I'm going to have that return back to me now the HM set is how you you persist",
    "start": "1173880",
    "end": "1182600"
  },
  {
    "text": "data into a hash and uh the first is my the first value is my key so the device",
    "start": "1182600",
    "end": "1188320"
  },
  {
    "text": "ID is my key and all those additional attributes and values are the fields and",
    "start": "1188320",
    "end": "1193400"
  },
  {
    "text": "values that I have Associated to my hash now I'm wrapping this into a multi command because I just want to ceue up",
    "start": "1193400",
    "end": "1199840"
  },
  {
    "text": "these commands and just execute that transaction with redit another popular use case is",
    "start": "1199840",
    "end": "1207039"
  },
  {
    "text": "streaming data so we have Amazon Kinesis streams and with Kinesis streams you can have a a AWS Lambda function trigger as",
    "start": "1207039",
    "end": "1215000"
  },
  {
    "text": "soon as records are in that stream and then as I mentioned earlier as that data is coming out of that stream you can",
    "start": "1215000",
    "end": "1221440"
  },
  {
    "text": "decorate that data you can do something with that data and then you can persist that data into Amazon elasticache and",
    "start": "1221440",
    "end": "1227360"
  },
  {
    "text": "you can always have any dc2 instance sitting on the the right hand side here that can query elastic hash maybe you",
    "start": "1227360",
    "end": "1233280"
  },
  {
    "text": "just want to see that moving data moving maybe you want to do something with that data you can always do that and the same",
    "start": "1233280",
    "end": "1238840"
  },
  {
    "text": "is true as I mentioned before you can always augment that solution and store that data in another system of",
    "start": "1238840",
    "end": "1245679"
  },
  {
    "text": "record streaming data enrichment is uh another interesting pattern that we",
    "start": "1245679",
    "end": "1250880"
  },
  {
    "start": "1246000",
    "end": "1246000"
  },
  {
    "text": "we're seeing customers use so imagine you have that data coming in the Stream now you may have various data sources",
    "start": "1250880",
    "end": "1257280"
  },
  {
    "text": "that are populated that stream with data that stream is a raw stream and it might",
    "start": "1257280",
    "end": "1262960"
  },
  {
    "text": "not be a cleanse Stream So you want to do something with that data before you start you know using it so what you can",
    "start": "1262960",
    "end": "1269240"
  },
  {
    "text": "do is you can collect that data from the stream have an AWS Lambda function trigger when records are in the Stream",
    "start": "1269240",
    "end": "1276240"
  },
  {
    "text": "persist that data into redus say you wanted to D dup dup data you can throw",
    "start": "1276240",
    "end": "1281320"
  },
  {
    "text": "that data in a set say you wanted to decorate that data you can take data that's already persisted into redus and",
    "start": "1281320",
    "end": "1287640"
  },
  {
    "text": "then BAS Bas on the records that are coming in you can you can uh you know decorate that data you can enrich that",
    "start": "1287640",
    "end": "1293120"
  },
  {
    "text": "data you can do a lot of things with that data and and once your your data is cleansed throw that data in a cleanse",
    "start": "1293120",
    "end": "1299440"
  },
  {
    "text": "stream and then and then you can run any type of operations on that stream you can even do SQL on that stream using",
    "start": "1299440",
    "end": "1305679"
  },
  {
    "text": "Kinesis uh analytics spark streaming with redus is",
    "start": "1305679",
    "end": "1312760"
  },
  {
    "start": "1309000",
    "end": "1309000"
  },
  {
    "text": "an interesting use case so you know typically when you are doing data analytics you are you know you have",
    "start": "1312760",
    "end": "1319200"
  },
  {
    "text": "maybe data coming in from kesa stream you have maybe a spark streaming job that's pulling data out of that stream",
    "start": "1319200",
    "end": "1326000"
  },
  {
    "text": "it's summarizing that data it's augmenting that data it's dumping that data into uh S3 then once it's an S3",
    "start": "1326000",
    "end": "1332760"
  },
  {
    "text": "your data Lake you could have maybe a red shift or another EMR job pick up that data and do something with it now",
    "start": "1332760",
    "end": "1338919"
  },
  {
    "text": "what's what's an interesting Trend here is that if you augment your spark job",
    "start": "1338919",
    "end": "1344200"
  },
  {
    "text": "with redus you will um by orders of magnitude speed up that performance why",
    "start": "1344200",
    "end": "1350600"
  },
  {
    "text": "because number one um pulling data out of an in-memory system is faster than",
    "start": "1350600",
    "end": "1355679"
  },
  {
    "text": "pulling data from a you know a file based system right or a SSD based system",
    "start": "1355679",
    "end": "1361279"
  },
  {
    "text": "the second reason is that if you think about the kind of code that you typically write in spark you're usually",
    "start": "1361279",
    "end": "1367320"
  },
  {
    "text": "you know uh sorting data you're aggregating data you are doing some sort",
    "start": "1367320",
    "end": "1372400"
  },
  {
    "text": "of function that a lot of these Advanced data structures and reddits can help reduce your code complexity so from both",
    "start": "1372400",
    "end": "1379200"
  },
  {
    "text": "angles um it's an interesting project to take a look at so rdus in a multi-az environment",
    "start": "1379200",
    "end": "1386279"
  },
  {
    "text": "let's take a look at that so the first thing that I'll call out is this is in a non-clustered environment so we'll talk",
    "start": "1386279",
    "end": "1391799"
  },
  {
    "text": "about clustered environments a little later in this presentation but typically what happens is um you have rights that",
    "start": "1391799",
    "end": "1398960"
  },
  {
    "text": "you want issued to your primary your primary is asynchronously communicating",
    "start": "1398960",
    "end": "1404720"
  },
  {
    "text": "to your read replicas now there's a an option to set for multi-az and when you do multi-az we",
    "start": "1404720",
    "end": "1411559"
  },
  {
    "text": "will put your read replicas in different uh azs and we will enable that failover",
    "start": "1411559",
    "end": "1417799"
  },
  {
    "text": "and when a failover happens um we'll basically take the DNS name from your",
    "start": "1417799",
    "end": "1423000"
  },
  {
    "text": "primary and we'll propagate that to uh to one of your read replicas now we'll select the read",
    "start": "1423000",
    "end": "1428960"
  },
  {
    "text": "replica that has the lowest replication lag in your cluster now one thing that we always recommend as well is that when",
    "start": "1428960",
    "end": "1436000"
  },
  {
    "text": "you do snapshots do them on a read replica so you don't interrupt or uh interrupt your your master or your",
    "start": "1436000",
    "end": "1443320"
  },
  {
    "text": "primary let's take a look at that let's visualize it so you have your applications they are talking to your",
    "start": "1443320",
    "end": "1449240"
  },
  {
    "text": "primary which has a border around it something happened to that primary DNS",
    "start": "1449240",
    "end": "1454360"
  },
  {
    "text": "replication will happen the read replica will be in the new primary and then we'll replace that replica and in this",
    "start": "1454360",
    "end": "1460679"
  },
  {
    "text": "particular uh example you'll see there's another data store in this case it's Dynamo DB is showing you that you can",
    "start": "1460679",
    "end": "1466640"
  },
  {
    "text": "your application can talk to to a variety of databases it doesn't really matter that but the databases themselves",
    "start": "1466640",
    "end": "1472080"
  },
  {
    "text": "don't talk to each other now one question that I get a lot",
    "start": "1472080",
    "end": "1477360"
  },
  {
    "start": "1474000",
    "end": "1474000"
  },
  {
    "text": "is how do I know what my read replicas are um especially in an environment where your read replicas can change well",
    "start": "1477360",
    "end": "1483679"
  },
  {
    "text": "we we provide an API that allows you to query your replication group and you can pass in a replication ID you can easily",
    "start": "1483679",
    "end": "1491240"
  },
  {
    "text": "get all the attributes Associated to your cluster and then once you have for",
    "start": "1491240",
    "end": "1496279"
  },
  {
    "text": "example your replicas you can use them right so you can issue reads against",
    "start": "1496279",
    "end": "1501600"
  },
  {
    "text": "your replica and take advantage of them so an example of how you could do that I checked into that GitHub",
    "start": "1501600",
    "end": "1507720"
  },
  {
    "text": "repo all right so what's new so two months ago roughly two months ago we",
    "start": "1507720",
    "end": "1512760"
  },
  {
    "text": "announced a new feature which is reddis cluster we support up to 3.5 terabytes",
    "start": "1512760",
    "end": "1518080"
  },
  {
    "text": "in redis we as I mentioned earlier up to 20 million reads per second up to 4.5",
    "start": "1518080",
    "end": "1525399"
  },
  {
    "text": "writes per second um all the enhancements that we talked about earlier are rolled into this version",
    "start": "1525399",
    "end": "1532360"
  },
  {
    "text": "it's up to four times faster than version 2.8 and that's because it's not based on DNS and we'll talk about how it",
    "start": "1532360",
    "end": "1539000"
  },
  {
    "text": "actually works cluster level backup you don't have to backup individual nodes and we support up to 15 shards within",
    "start": "1539000",
    "end": "1546200"
  },
  {
    "text": "your cluster the other thing that I'll mention is fully supported by a AWS cloud formation if you're familiar with",
    "start": "1546200",
    "end": "1552159"
  },
  {
    "text": "that it's a template engine that allows you to build build environments and it's supported in all our AWS",
    "start": "1552159",
    "end": "1559960"
  },
  {
    "text": "regions the other thing is that there's two additional uh data types that are supported with uh version 3.2 one is the",
    "start": "1559960",
    "end": "1567880"
  },
  {
    "start": "1560000",
    "end": "1560000"
  },
  {
    "text": "bitfield command and then the other one is geospatial I I love geospatial I think it's awesome it's an awesome way",
    "start": "1567880",
    "end": "1574120"
  },
  {
    "text": "to build data aware code or Geo aware code so say for example you have a",
    "start": "1574120",
    "end": "1580000"
  },
  {
    "text": "mobile application and in that mobile application you want to advertise particular points of interest to your",
    "start": "1580000",
    "end": "1586600"
  },
  {
    "text": "customers those points of interest could be anything right they could be restaurants they could be anything that you really",
    "start": "1586600",
    "end": "1591960"
  },
  {
    "text": "want to advertise well in that mobile application you can pass up the longitude latitude of that position of",
    "start": "1591960",
    "end": "1599279"
  },
  {
    "text": "that customer and uh based on go ads which are those points of interest that",
    "start": "1599279",
    "end": "1604440"
  },
  {
    "text": "you added in the cluster you can find all the uh the uh points of interest",
    "start": "1604440",
    "end": "1610640"
  },
  {
    "text": "within a particular radius right so I can say all right this customer is in this particular location let me find",
    "start": "1610640",
    "end": "1616960"
  },
  {
    "text": "everything in a you know a a mile away from this customer and then let me send those recommendations up to this mobile",
    "start": "1616960",
    "end": "1622799"
  },
  {
    "text": "app so we can see it now again as I mentioned redus is an in-memory system",
    "start": "1622799",
    "end": "1628159"
  },
  {
    "text": "we're dealing with microsc performance this is why this is awesome because realistically when you have an",
    "start": "1628159",
    "end": "1634279"
  },
  {
    "text": "application like that you want to be able to you know to Market those advertisements as quick as possible now",
    "start": "1634279",
    "end": "1641120"
  },
  {
    "text": "in addition to finding all the points of interest within a particular you know radius you can also do other things like",
    "start": "1641120",
    "end": "1647600"
  },
  {
    "text": "what's the distance between two points as well as other things scaling with r as cluster so how",
    "start": "1647600",
    "end": "1655080"
  },
  {
    "text": "do you tell the engine that you want to horizontally scale the first thing you do is you check cluster mode otherwise",
    "start": "1655080",
    "end": "1661120"
  },
  {
    "text": "if you don't check that we'll assume that you want that primary and then that read replica kind of vertically scale",
    "start": "1661120",
    "end": "1666960"
  },
  {
    "text": "architecture that we looked at earlier and before we kind of dive into",
    "start": "1666960",
    "end": "1672399"
  },
  {
    "start": "1669000",
    "end": "1669000"
  },
  {
    "text": "how sharding looks like let's talk a little bit about the client so essentially the way sh starting works is",
    "start": "1672399",
    "end": "1678760"
  },
  {
    "text": "you have 16,384 total hash slots now those hash",
    "start": "1678760",
    "end": "1684159"
  },
  {
    "text": "slots are distributed across your shards Now by default that distribution",
    "start": "1684159",
    "end": "1690080"
  },
  {
    "text": "is an equal distribution so if you if you create five shards those hash ranges",
    "start": "1690080",
    "end": "1695720"
  },
  {
    "text": "will dist be distribute be distributed across those uh those shards now your actual client",
    "start": "1695720",
    "end": "1703600"
  },
  {
    "text": "now client being the driver or the client code that you're using to connect nextor retus has a map of every Shard",
    "start": "1703600",
    "end": "1711640"
  },
  {
    "text": "that has those hash ranges as well as any read replicas for that individual",
    "start": "1711640",
    "end": "1718840"
  },
  {
    "text": "Shard now what's also great about a client is that um a lot of clients do uh",
    "start": "1718840",
    "end": "1725200"
  },
  {
    "text": "they load balance reads for you um the other thing that I'll mention about the client is that because all",
    "start": "1725200",
    "end": "1732320"
  },
  {
    "text": "that information is in a map within the client you don't need DNS propagation all those IP address es and all that",
    "start": "1732320",
    "end": "1738519"
  },
  {
    "text": "cluster information is built into the map uh and so the client itself knows where to Route the",
    "start": "1738519",
    "end": "1745080"
  },
  {
    "text": "traffic now this of course is much better than you know doing things like a a proxy or something else why because",
    "start": "1745080",
    "end": "1752600"
  },
  {
    "text": "that map is right there with your code and so you can eliminate you're talking",
    "start": "1752600",
    "end": "1757799"
  },
  {
    "text": "directly with the cluster and you can eliminate any other network hop between your code and actual the redus",
    "start": "1757799",
    "end": "1766080"
  },
  {
    "start": "1766000",
    "end": "1766000"
  },
  {
    "text": "engine all right let's visualize this so we the outside blue border is your",
    "start": "1766080",
    "end": "1771120"
  },
  {
    "text": "reddest cluster now that cluster again can be up to 15 shards and this example we have three",
    "start": "1771120",
    "end": "1777519"
  },
  {
    "text": "shards the the nodes that have the gray border those are your primary",
    "start": "1777519",
    "end": "1783240"
  },
  {
    "text": "shards now any other node that has the same range in this example is a read",
    "start": "1783240",
    "end": "1789760"
  },
  {
    "text": "replica so our first our first Shard has a slot",
    "start": "1789760",
    "end": "1795039"
  },
  {
    "text": "range of 0 to 5454 and then you can see which are the read replicas in this example they're in",
    "start": "1795039",
    "end": "1800919"
  },
  {
    "text": "different azs and I have two other shards with a",
    "start": "1800919",
    "end": "1806600"
  },
  {
    "text": "different hash range Associated to them now with elastic hash you can have up to",
    "start": "1806600",
    "end": "1811679"
  },
  {
    "text": "five read replicas for each Shard and as I mentioned U up to 15 total shards",
    "start": "1811679",
    "end": "1818399"
  },
  {
    "text": "every one of these nodes together are your total cluster size so in this",
    "start": "1818399",
    "end": "1823480"
  },
  {
    "text": "example we have nine how do you do that right so in the console the first thing that you do is",
    "start": "1823480",
    "end": "1830279"
  },
  {
    "start": "1826000",
    "end": "1826000"
  },
  {
    "text": "you give your cluster a name so this example my reddest cluster the second",
    "start": "1830279",
    "end": "1835919"
  },
  {
    "text": "thing you do you select the engine type 3.2.4 then you will start selecting a",
    "start": "1835919",
    "end": "1841799"
  },
  {
    "text": "node size this is the node size for your Shard so in that case 13.5 * 3 that's",
    "start": "1841799",
    "end": "1848320"
  },
  {
    "text": "the total memory space for my cluster and then I'm saying I want two",
    "start": "1848320",
    "end": "1854320"
  },
  {
    "text": "shards or two replicas for my shard so in total there are nine total",
    "start": "1854320",
    "end": "1860399"
  },
  {
    "text": "shards now I mentioned earlier by default we'll assume you want equal distribution so we have that total hash",
    "start": "1860399",
    "end": "1866639"
  },
  {
    "text": "slot range and uh we will divide that range across each individual Shard but",
    "start": "1866639",
    "end": "1872639"
  },
  {
    "text": "you may have a key or something that's a hot key say for example uh you know you're always reading from an individual",
    "start": "1872639",
    "end": "1878399"
  },
  {
    "text": "key so we'll give you the capability to change the slot and the key space you",
    "start": "1878399",
    "end": "1883679"
  },
  {
    "text": "know orientation of your of your cluster and it will also by default",
    "start": "1883679",
    "end": "1888799"
  },
  {
    "text": "spread your your nodes across azs unless you have a particular use case where you",
    "start": "1888799",
    "end": "1894120"
  },
  {
    "text": "want your your uh your your nodes in a particular a let look at failure",
    "start": "1894120",
    "end": "1900919"
  },
  {
    "start": "1899000",
    "end": "1899000"
  },
  {
    "text": "scenarios so assume that your primary",
    "start": "1900919",
    "end": "1906080"
  },
  {
    "text": "fails this is an easy scenario right so what we do is we uh will promote one of",
    "start": "1906880",
    "end": "1912720"
  },
  {
    "text": "your read replicas that be a new primary your previous uh you know your primary will be a RCA and we'll will'll repair",
    "start": "1912720",
    "end": "1920679"
  },
  {
    "text": "it your your client code um your client is aware of this and this typically",
    "start": "1920679",
    "end": "1926840"
  },
  {
    "text": "happens within 30 seconds as far as your reads There's No Interruption assuming",
    "start": "1926840",
    "end": "1932399"
  },
  {
    "text": "you have read replicas your application can continue reading from the cluster you might have some right interruption",
    "start": "1932399",
    "end": "1938799"
  },
  {
    "text": "in the process of making that new read replica the new primary but that's up to",
    "start": "1938799",
    "end": "1944200"
  },
  {
    "text": "30 seconds another example is when you have",
    "start": "1944200",
    "end": "1949679"
  },
  {
    "start": "1946000",
    "end": "1946000"
  },
  {
    "text": "two primaries fail within your cluster and in this example um or or two or more",
    "start": "1949679",
    "end": "1955320"
  },
  {
    "text": "primaries fail in your cluster this example we have three total shards so two primary shards are failing and why",
    "start": "1955320",
    "end": "1962279"
  },
  {
    "text": "this is challenging is that if you're running this on ec2 and we've heard customers tell us this if the majority of your primaries",
    "start": "1962279",
    "end": "1969679"
  },
  {
    "text": "fail it causes a problem and why does this cause a problem because you need a majority of primaries to be available to",
    "start": "1969679",
    "end": "1976799"
  },
  {
    "text": "a collect new primaries from read replicas we have controls around this so",
    "start": "1976799",
    "end": "1983480"
  },
  {
    "text": "essentially we'll see you know we'll look at your entire cluster health and",
    "start": "1983480",
    "end": "1988519"
  },
  {
    "text": "uh you know if you're in a scenario where you don't have the majority to elect new primaries we have controls",
    "start": "1988519",
    "end": "1994720"
  },
  {
    "text": "that can resolve that problem builts in the engine you don't have to do anything we will do this for",
    "start": "1994720",
    "end": "2001200"
  },
  {
    "start": "2001000",
    "end": "2001000"
  },
  {
    "text": "you how do you get from a non-clustered environment to a clustered environment",
    "start": "2001440",
    "end": "2007080"
  },
  {
    "text": "so it's pretty easy you essentially you take a uh a snapshot of your cluster and",
    "start": "2007080",
    "end": "2013559"
  },
  {
    "text": "then you restore that snapshot on each one of your individual shards in your cluster now the way cluster works",
    "start": "2013559",
    "end": "2020360"
  },
  {
    "text": "there's a particular hash range right that we mentioned earlier on each one of these shards so we'll discard any keys",
    "start": "2020360",
    "end": "2027200"
  },
  {
    "text": "that aren't applicable to that hash range now if you wanted to you know",
    "start": "2027200",
    "end": "2032519"
  },
  {
    "text": "migrate from a non-clustered to a non-clustered 3.2 version that's seamless right there's a couple clicks",
    "start": "2032519",
    "end": "2038880"
  },
  {
    "text": "and then that just that just works the other thing that I'll call out is that it's important to make sure that",
    "start": "2038880",
    "end": "2045159"
  },
  {
    "text": "your client supports Redd is cluster um and so you can just look up the client that you're using and just make sure it",
    "start": "2045159",
    "end": "2050839"
  },
  {
    "text": "supports r as 3 and up cloud formation is fully supported",
    "start": "2050839",
    "end": "2057240"
  },
  {
    "start": "2054000",
    "end": "2054000"
  },
  {
    "text": "out of the box so essentially building your cluster you know how many we replicas you want all that is supported",
    "start": "2057240",
    "end": "2064839"
  },
  {
    "text": "so you want to augment or automate your environments maybe build up an environment for test and Dev and you",
    "start": "2064839",
    "end": "2070398"
  },
  {
    "text": "know just terminate it you could do all that through cloud",
    "start": "2070399",
    "end": "2074639"
  },
  {
    "text": "formation okay so best practices kind of go through a few of these so we can leave time here uh in",
    "start": "2076480",
    "end": "2083440"
  },
  {
    "text": "the presentation um these are just a few uh That We snuck into the presentation",
    "start": "2083440",
    "end": "2088960"
  },
  {
    "text": "first one is avoid really short key names so I know a lot of people who are you know they try to be extremely memory",
    "start": "2088960",
    "end": "2095520"
  },
  {
    "text": "efficient they want to have like the smallest you know abbreviated key name possible um so what they'll do is",
    "start": "2095520",
    "end": "2101920"
  },
  {
    "text": "they'll pick a key name that doesn't make sense for an application developer right so pick something that has a you",
    "start": "2101920",
    "end": "2107079"
  },
  {
    "text": "know a logical schema name that's easy to code against um the second thing is you know",
    "start": "2107079",
    "end": "2113280"
  },
  {
    "text": "use hashes lists and sets when possible these are memory efficient collections",
    "start": "2113280",
    "end": "2119200"
  },
  {
    "text": "so one thing that you can easily do so if you think about it this way if you have maybe five keys and you had a you",
    "start": "2119200",
    "end": "2125079"
  },
  {
    "text": "know a hash that had five values in it the hash has a smaller memory footprint",
    "start": "2125079",
    "end": "2130599"
  },
  {
    "text": "than those five individual keys um and then the last thing is I see some people you know they have the a keys command",
    "start": "2130599",
    "end": "2137280"
  },
  {
    "text": "coded into their application don't do that right that is a you know that's a blocking command um instead use like",
    "start": "2137280",
    "end": "2144480"
  },
  {
    "text": "scans and uh you know just kind of iterate through that you know the uh results that you",
    "start": "2144480",
    "end": "2151079"
  },
  {
    "text": "get all right so a few things I talked about a lot of these things I just kind of mentioned a a few of them from a",
    "start": "2151079",
    "end": "2158079"
  },
  {
    "start": "2152000",
    "end": "2152000"
  },
  {
    "text": "reddest cluster standpoint have a odd number of shards now I talked about earlier that even in a in a situation",
    "start": "2158079",
    "end": "2164440"
  },
  {
    "text": "where the majority of your shards fail we will fix that scenario uh we have controls around that but it's still good",
    "start": "2164440",
    "end": "2170520"
  },
  {
    "text": "to have an odd number because it just speeds up the overall failure scenario the other thing is you know for",
    "start": "2170520",
    "end": "2177160"
  },
  {
    "text": "critical workloads you want to have a few read replicas you know Associated um",
    "start": "2177160",
    "end": "2182280"
  },
  {
    "text": "you know for swap usage you'd never want to see that you'd never want to be in swap swap memory so you always want to",
    "start": "2182280",
    "end": "2187920"
  },
  {
    "text": "see that at least zero to very low and uh uh let's see what else for Reserve",
    "start": "2187920",
    "end": "2193720"
  },
  {
    "text": "memory um I mention in if you're running this on ec2 that typically this can double your total memory footprint with",
    "start": "2193720",
    "end": "2200160"
  },
  {
    "text": "elasticache we'll just recommend you know 25 to 30% Reserve memory just to make sure you know there's there's",
    "start": "2200160",
    "end": "2206040"
  },
  {
    "text": "additional memory for those background operations and runers few things I'll call out here are",
    "start": "2206040",
    "end": "2213240"
  },
  {
    "start": "2212000",
    "end": "2212000"
  },
  {
    "text": "some uh Cloud watch metrics now every cloud watch metric you can have an alarm setup um the first one CPU you know",
    "start": "2213240",
    "end": "2220400"
  },
  {
    "text": "typically don't go past 90 remember red is is single threaded so you want to divide that by the number number of",
    "start": "2220400",
    "end": "2226040"
  },
  {
    "text": "cores that you have swap usage low again this is an inmemory system you never want to be in swap cash misses the hits",
    "start": "2226040",
    "end": "2233680"
  },
  {
    "text": "you want to have more hits right so if you're getting the value out of your cash you want to be you want to be",
    "start": "2233680",
    "end": "2239599"
  },
  {
    "text": "finding data in the cash evictions this is when you know redus uh you know mcash",
    "start": "2239599",
    "end": "2245760"
  },
  {
    "text": "D kind of kind of just jumps in and starts evicting keys because uh you're poor memory management um you never want",
    "start": "2245760",
    "end": "2252480"
  },
  {
    "text": "to really run into evictions unless this is unintentional maybe you're following a particular algorithm that uh you know",
    "start": "2252480",
    "end": "2258839"
  },
  {
    "text": "like the Russian doll caching algorithm where you want to do this uh I wouldn't recommend it um and uh there are",
    "start": "2258839",
    "end": "2266280"
  },
  {
    "text": "eviction policies that you can uh you know that you can look at um and I would",
    "start": "2266280",
    "end": "2271720"
  },
  {
    "text": "select one in the case you are in an eviction um select one that makes sense for your application",
    "start": "2271720",
    "end": "2277680"
  },
  {
    "text": "the other thing I'll mention is for an a a Max for the clients you can have up to",
    "start": "2277680",
    "end": "2282760"
  },
  {
    "text": "65,000 connections per node um but it's good to have parameters around timeout",
    "start": "2282760",
    "end": "2288800"
  },
  {
    "text": "and TCP keep alive to make sure you're killing dead connections or Idol connections just get rid of",
    "start": "2288800",
    "end": "2294760"
  },
  {
    "text": "those and uh that's pretty much all I'm going to cover for this session uh the other thing just to kind of recap Amazon",
    "start": "2294760",
    "end": "2301560"
  },
  {
    "start": "2297000",
    "end": "2297000"
  },
  {
    "text": "elasticache supports a variety of use cases we're not talking about just cash",
    "start": "2301560",
    "end": "2306839"
  },
  {
    "text": "although that's what the name kind of sounds like we're talking about a lot of use cases that support that fast data",
    "start": "2306839",
    "end": "2312160"
  },
  {
    "text": "and fast moving data second thing is as you saw with a few lines of code it's very easy to augment Your solution um",
    "start": "2312160",
    "end": "2319880"
  },
  {
    "text": "you know whether you're using mecd or redus doing Lazy loading right throughs very easy a lot of Frameworks already",
    "start": "2319880",
    "end": "2326240"
  },
  {
    "text": "support uh these caching Solutions so in some cases it's just uh configuration",
    "start": "2326240",
    "end": "2331720"
  },
  {
    "text": "changes and then lastly you can support you know terabytes worth of data with",
    "start": "2331720",
    "end": "2337079"
  },
  {
    "text": "millions of iops so to really power your architectures um it's an interesting uh",
    "start": "2337079",
    "end": "2343240"
  },
  {
    "text": "you know it's it's an interesting and also a high Roi to augment that solution",
    "start": "2343240",
    "end": "2348280"
  },
  {
    "text": "with putting uh elastic cach uh as part of that thank you guys that's all I have for this",
    "start": "2348280",
    "end": "2355720"
  },
  {
    "text": "presentation thanks man all right thanks Michael hey",
    "start": "2360960",
    "end": "2368720"
  },
  {
    "text": "everyone my name is Brian Kaiser I'm the CTO of huddle so today I'm going to talk",
    "start": "2368720",
    "end": "2373880"
  },
  {
    "text": "about what huddle is kind of how we got into basic caching uh our journey from",
    "start": "2373880",
    "end": "2379079"
  },
  {
    "text": "mcash D to redus and alasa cach and then some best practices we learned along the way so huddle is a sports platform that",
    "start": "2379079",
    "end": "2387440"
  },
  {
    "text": "really allows coaches analysts and athletes to win with video and analytics we were founded by myself and two",
    "start": "2387440",
    "end": "2393640"
  },
  {
    "text": "partners about 10 years ago really focusing on football at the professional level nowadays we work broadly across",
    "start": "2393640",
    "end": "2400400"
  },
  {
    "text": "Sports from soccer basketball football from kind of peeee and youth teams all the way up to the NBA NFL and English",
    "start": "2400400",
    "end": "2407160"
  },
  {
    "text": "Premier League in fact over 98% of American football teams use our product",
    "start": "2407160",
    "end": "2412599"
  },
  {
    "text": "and the entire English Premier League calls us a customer now so it's really is broadly applicable both domestically",
    "start": "2412599",
    "end": "2417800"
  },
  {
    "text": "and internationally this is just a cool example I think of some of the more",
    "start": "2417800",
    "end": "2423079"
  },
  {
    "text": "advanced analysis that we're seeing the English Premier League do around player tracking data they're really kind of Cutting Edge in the space of sports",
    "start": "2423079",
    "end": "2428760"
  },
  {
    "text": "analytics as you probably read about a lot online so some quick fun facts on our",
    "start": "2428760",
    "end": "2434480"
  },
  {
    "text": "platform we have over 100,000 130,000 teams internationally using the product",
    "start": "2434480",
    "end": "2439960"
  },
  {
    "text": "that equates to over 4 A5 million active users we actually store and serve over",
    "start": "2439960",
    "end": "2445640"
  },
  {
    "text": "two billion videos on S3 so needless to say we have a lot of video and S3 really likes our usage we actually ingested en",
    "start": "2445640",
    "end": "2453520"
  },
  {
    "text": "code over 35 hours of HD video per per minute during our primary Sports season get that encoded and sort of back out",
    "start": "2453520",
    "end": "2460800"
  },
  {
    "text": "and we're servicing over 15,000 API requests per second during that same timespan and every one of those API",
    "start": "2460800",
    "end": "2466560"
  },
  {
    "text": "requests is actually multiple cash hits as we'll kind of talk about so we've been on Amazon pretty",
    "start": "2466560",
    "end": "2472640"
  },
  {
    "text": "much since the start of huddle um and in fact if you look at the dates it's the start of Amazon is right about the time",
    "start": "2472640",
    "end": "2477880"
  },
  {
    "text": "that huddle actually started and it really made sense for us right we needed the ability to scale very quickly we",
    "start": "2477880",
    "end": "2482960"
  },
  {
    "text": "handle very seasonal traffic workloads which is a great fit for Amazon and we need the ability to deliver high",
    "start": "2482960",
    "end": "2488400"
  },
  {
    "text": "performance to teams no matter what region of the world they're in Amazon checked all those boxes for us we run a",
    "start": "2488400",
    "end": "2494400"
  },
  {
    "text": "fairly standard microservices architecture at huddle so we use an El as our primary entry point that's",
    "start": "2494400",
    "end": "2500560"
  },
  {
    "text": "actually spread out to our routing layer which is really engine Xboxes in each availability Zone that talk to Eureka",
    "start": "2500560",
    "end": "2507280"
  },
  {
    "text": "and Eureka is a service Discovery system written by Netflix it's a wonderful piece of Open Source software we use a",
    "start": "2507280",
    "end": "2513319"
  },
  {
    "text": "to see what services are online what servers are a available and what routes we need to do and then route down to the",
    "start": "2513319",
    "end": "2519480"
  },
  {
    "text": "appropriate Squad cluster and the microservice cluster in each applicable availability",
    "start": "2519480",
    "end": "2524640"
  },
  {
    "text": "zone now the entry point to that is of course our web tier pretty standard we run IAS for our primary web server and",
    "start": "2524640",
    "end": "2531160"
  },
  {
    "text": "it's just an autoscaling group across the 3 ACS each Squad is able to determine the supporting services to",
    "start": "2531160",
    "end": "2536920"
  },
  {
    "text": "meet their needs whether it's elasticache Dynamo DB sqs um whatever it",
    "start": "2536920",
    "end": "2542559"
  },
  {
    "text": "may be to actually service their needs each Squad is able to use those Amazon services and then mongodb is our primary data",
    "start": "2542559",
    "end": "2548559"
  },
  {
    "text": "store at the B at the bottom layer now we've had caching for a long",
    "start": "2548559",
    "end": "2553880"
  },
  {
    "text": "long time and we got started with couch base on top of MCD and honestly it was a",
    "start": "2553880",
    "end": "2559079"
  },
  {
    "text": "pretty logical fit for us hopefully it's obvious from this presentation what Michael's talked about",
    "start": "2559079",
    "end": "2564200"
  },
  {
    "text": "that caching is easy to implement and it's very high impact and we recognized that early on and honestly for us it's",
    "start": "2564200",
    "end": "2569400"
  },
  {
    "text": "not just about performance it's also about some of the things that are a little less obvious so we noticed that it helped us smooth out volatilities and",
    "start": "2569400",
    "end": "2576319"
  },
  {
    "text": "things like EBS latency that might Spike or network blips that happened in our internal infrastructure we also found it",
    "start": "2576319",
    "end": "2582200"
  },
  {
    "text": "as a very effective way for us as a smaller startup to scale cost effectively without having to increase our database usage",
    "start": "2582200",
    "end": "2589960"
  },
  {
    "text": "significantly we started making the transition to redus a couple years ago and it's it's been quite impactful for",
    "start": "2589960",
    "end": "2595599"
  },
  {
    "text": "us I like to think of it now as kind of the Swiss Army knif of Swiss army knife of our infrastructure not only can It",
    "start": "2595599",
    "end": "2601000"
  },
  {
    "text": "that very basic key value store but also has so many Advanced capabilities and data structures we use it for queuing",
    "start": "2601000",
    "end": "2607240"
  },
  {
    "text": "and pubsub in fact now we serve over 880,000 requests per second through our me through our reddis clusters and in",
    "start": "2607240",
    "end": "2614720"
  },
  {
    "text": "preparing for this presentation I did some calculations and found that our average latency is less than 1 millisecond which is pretty astounding",
    "start": "2614720",
    "end": "2622119"
  },
  {
    "text": "right it even surprised me that's one to two orders of magnitude quicker than what we found from our traditional",
    "start": "2622119",
    "end": "2628000"
  },
  {
    "text": "database fetches so now I'm going to walk through some kind of basic use cases of how we use reddis at huddle I'm going to start",
    "start": "2628000",
    "end": "2634880"
  },
  {
    "text": "with the most simple one which which is the lazy loaning basic data caching now we put this data caching at the lowest",
    "start": "2634880",
    "end": "2641319"
  },
  {
    "text": "level possible right in front of the database calls in the database functions and we do that to allow for very easy",
    "start": "2641319",
    "end": "2646640"
  },
  {
    "text": "cach invalidation we found that if our caching code was spread out broadly or up at the service layer inv validation",
    "start": "2646640",
    "end": "2652520"
  },
  {
    "text": "became very difficult so in our opinion we like to have it as low as possible for those inv",
    "start": "2652520",
    "end": "2657640"
  },
  {
    "text": "validation so here's a very basic get utility function that we wrote and this is in net code one of the things that I",
    "start": "2657640",
    "end": "2664200"
  },
  {
    "text": "think is somewhat unique is the first Chun where it says underscore rdis enable doval huddle has a system of",
    "start": "2664200",
    "end": "2670760"
  },
  {
    "text": "feature toggles where we can turn on and off different pieces of our system and architecture dynamically on a per",
    "start": "2670760",
    "end": "2677000"
  },
  {
    "text": "cluster basis so for example in redis if we need to do maintenance on a certain cluster if we're having any kind of",
    "start": "2677000",
    "end": "2682640"
  },
  {
    "text": "connectivity issues we can hit one toggle we actually use SNS for this propagation we can turn off redus access",
    "start": "2682640",
    "end": "2689160"
  },
  {
    "text": "across that entire cluster now we have some pieces in our system that are extremely high volume and just kind of",
    "start": "2689160",
    "end": "2695119"
  },
  {
    "text": "turning off Redd binarily would cause the Thundering hert effect potentially in a massive load on our database so in",
    "start": "2695119",
    "end": "2701319"
  },
  {
    "text": "those cases it's much more of a broad range toggle where it might be between zero and 100 we can ramp up and down our",
    "start": "2701319",
    "end": "2706839"
  },
  {
    "text": "usage of these features depending on the maintenance and the time of day things like that the next line you see in bold",
    "start": "2706839",
    "end": "2713160"
  },
  {
    "text": "there is just where we actually get a value from the database this is coming back as a bite array very very simple",
    "start": "2713160",
    "end": "2718359"
  },
  {
    "text": "and then we're deserializing it and the bottom line in this case we're using Proto buff so we're taking that bite array and we're desizing it into net",
    "start": "2718359",
    "end": "2725599"
  },
  {
    "text": "object again this is incredibly simple but I just want to show how simple this actually is and this is the code we use",
    "start": "2725599",
    "end": "2730720"
  },
  {
    "text": "for it on the flip side of it here's our put method so you can see again that toggle at the top that allows us to",
    "start": "2730720",
    "end": "2736079"
  },
  {
    "text": "control access to redus we actually seriz the object into a bite array and then we pop it into the database with a",
    "start": "2736079",
    "end": "2742319"
  },
  {
    "text": "TTL on it and huddle it really depends on what the frequency of access on our objects are it could be anywhere from 5",
    "start": "2742319",
    "end": "2748559"
  },
  {
    "text": "minutes to an hour on the low end up to 1 to 7 to 30 days for the amount of time that we put objects in the cache",
    "start": "2748559",
    "end": "2754880"
  },
  {
    "text": "for a slightly more complicated example is the utility function we wrote to kind of enforce this lazy loading pattern so",
    "start": "2754880",
    "end": "2761280"
  },
  {
    "text": "this is our get in put so again we have the toggle at the top we go to attempt to get that key out of cash if it's a",
    "start": "2761280",
    "end": "2767880"
  },
  {
    "text": "cash hit we go ahead and return that value right away if it's a Miss we're able to pass in an accessor function",
    "start": "2767880",
    "end": "2774400"
  },
  {
    "text": "which may be a DB access or maybe a call to another microservice and then we put that cash key in again this is ultra",
    "start": "2774400",
    "end": "2780559"
  },
  {
    "text": "simple right we write these functions to help enforce a good pattern and make sure we don't have any problems or bugs down the road",
    "start": "2780559",
    "end": "2786839"
  },
  {
    "start": "2786000",
    "end": "2786000"
  },
  {
    "text": "so what are some examples of ways that we use this the most common one for us is the O token so every call that comes",
    "start": "2786839",
    "end": "2792520"
  },
  {
    "text": "into huddle gets authenticated right that off token is in the cash we check it every single time so these Keys alone",
    "start": "2792520",
    "end": "2798040"
  },
  {
    "text": "are over 15,000 requests per second just for our off tokens the next big one is",
    "start": "2798040",
    "end": "2803359"
  },
  {
    "text": "user information this is a perfect example as Michael mentioned of where a hash is a wonderful fit in reddis we can",
    "start": "2803359",
    "end": "2809079"
  },
  {
    "text": "store the relevant information for a user like their Jersey their email address what teams they're a part of in",
    "start": "2809079",
    "end": "2815480"
  },
  {
    "text": "a simple hash function in redus and either get that whole object out which is actually the most common thing for us or individual pieces as we need it",
    "start": "2815480",
    "end": "2823160"
  },
  {
    "text": "likewise we store information on our teams this might be the sport that that we're part of the level whether it's a",
    "start": "2823160",
    "end": "2828280"
  },
  {
    "text": "high school Collegiate or pro team and a very simple hash function in reddis and it just makes a whole lot of sense so",
    "start": "2828280",
    "end": "2834480"
  },
  {
    "text": "let's move on to a little more advanced example um this is our news feed so you can think of the news feed kind of like",
    "start": "2834480",
    "end": "2840319"
  },
  {
    "text": "well a Facebook Newsfeed right this is essential source of information for our users and teams and a good example would",
    "start": "2840319",
    "end": "2846880"
  },
  {
    "text": "be a coach posts a new highlight reel or playlist or video for a team to watch and you can imagine it populating into",
    "start": "2846880",
    "end": "2853000"
  },
  {
    "text": "the news feed this is a function that makes incredibly heavy use of redus for us in fact it's such a heavy user of",
    "start": "2853000",
    "end": "2859119"
  },
  {
    "text": "redus that if redus has a problem or goes down for any reason we have to turn off this piece of functionality in our",
    "start": "2859119",
    "end": "2864400"
  },
  {
    "text": "system because it would quickly overload our database and I think it'll make sense in a second when I talk about the access",
    "start": "2864400",
    "end": "2869480"
  },
  {
    "text": "patterns so at the top of the page here we use a hash so we're storing things like the background image for the team",
    "start": "2869480",
    "end": "2875520"
  },
  {
    "text": "the the location of the team things like the view count for this page or for highlight reels and the number of",
    "start": "2875520",
    "end": "2881040"
  },
  {
    "text": "followers of this team and again this is a wonderful use of a hash often as example in this page load we're",
    "start": "2881040",
    "end": "2886319"
  },
  {
    "text": "retrieving that entire thing out we can automically increment things like view count and followers right it's a very",
    "start": "2886319",
    "end": "2892400"
  },
  {
    "text": "very simple but highly effective and highly efficient way of storing this data and kind of the bulk of the page",
    "start": "2892400",
    "end": "2898480"
  },
  {
    "text": "here is the actual feed itself and I think this is a somewhat novel approach that one of our developers came up with",
    "start": "2898480",
    "end": "2903720"
  },
  {
    "text": "for this essentially this is a single reddish list of feed IDs and a little",
    "start": "2903720",
    "end": "2909520"
  },
  {
    "text": "bit of metadata around them and what happens is let's say a coach in that previous example is publishing a video",
    "start": "2909520",
    "end": "2915520"
  },
  {
    "text": "we will go through every single user on that team and we will push that ID and information onto the redest list for",
    "start": "2915520",
    "end": "2922160"
  },
  {
    "text": "that User it's a very very quick operation and then we'll trim the list to make sure it's at a constant length",
    "start": "2922160",
    "end": "2927520"
  },
  {
    "text": "and so in our case we keep this list at right around 500 items now when the user is scrolling through this list we know",
    "start": "2927520",
    "end": "2933400"
  },
  {
    "text": "the offset so we can actually grab a range off that reddish list of the IDS and information and then we can hydrate",
    "start": "2933400",
    "end": "2940160"
  },
  {
    "text": "that with those items out of the cach in parallel with a multi-gate so I know that's a lot there but effectively what",
    "start": "2940160",
    "end": "2945480"
  },
  {
    "text": "that means is we're able to generate this news feed in literally a couple milliseconds on page load it's a very",
    "start": "2945480",
    "end": "2951119"
  },
  {
    "text": "very efficient operation for us for something that would be very complicated right and this is a wonderful example of",
    "start": "2951119",
    "end": "2956400"
  },
  {
    "text": "how we can use lists and coupled with a caching and a multi-g get so let's talk about another example",
    "start": "2956400",
    "end": "2962760"
  },
  {
    "start": "2961000",
    "end": "2961000"
  },
  {
    "text": "distributed caching this is kind of a dirty word often I I I don't encourage you to use distributed caching but when",
    "start": "2962760",
    "end": "2968520"
  },
  {
    "text": "you need it it's really nice to have a very reliable and consistent way to do it atomically and reddis provides that",
    "start": "2968520",
    "end": "2974559"
  },
  {
    "text": "so in this example we have a lot of coaches they're at their game and they're filming it with iPads fragments",
    "start": "2974559",
    "end": "2979960"
  },
  {
    "text": "of this video is Flowing directly to S3 so little Snippets of the game live while it's happening we're then making",
    "start": "2979960",
    "end": "2986240"
  },
  {
    "text": "calls into a queue which get put into a very massive worker Farm we have that does that video encoding we talked about",
    "start": "2986240",
    "end": "2991599"
  },
  {
    "text": "that 35 hours of video per minute right that's where these jobs come in we're grabbing those chunks of video we're",
    "start": "2991599",
    "end": "2997079"
  },
  {
    "text": "encoding them in multiple qualities we're sanitizing them we're getting ready for streaming the challenge comes",
    "start": "2997079",
    "end": "3002799"
  },
  {
    "text": "this is all happening parallel at a very broad scale so these jobs come back not only are we writing them to mongodb out",
    "start": "3002799",
    "end": "3008760"
  },
  {
    "text": "of this queue but we also have to use a distributed lock to make sure that we're coordinating delivery and finalization",
    "start": "3008760",
    "end": "3014440"
  },
  {
    "text": "of this video and it's a small piece and it's very very quick but it's incredibly important to get right so we know when",
    "start": "3014440",
    "end": "3019799"
  },
  {
    "text": "this video is ready for the user and that's what we actually use elasticache for and again this is a thing that elasticache does extreme extremely well",
    "start": "3019799",
    "end": "3026200"
  },
  {
    "text": "in our experience and if you have to do distributed locking I'd recommend you checking it out so we've got to answer the question",
    "start": "3026200",
    "end": "3033040"
  },
  {
    "text": "why do we use elastic cash versus just running Reddit ourselves and Michael gave some great examples of the benefits",
    "start": "3033040",
    "end": "3038440"
  },
  {
    "text": "and I can tell you from personal experience that we've seen that for us it's also an operational question and an operational answer so we are organized",
    "start": "3038440",
    "end": "3045680"
  },
  {
    "text": "as a company and a product team like Spotify we pretty blatantly ripped it off and I appreciate all the",
    "start": "3045680",
    "end": "3050920"
  },
  {
    "text": "documentation they've done on this in fact these are screenshots from a slide that they've posted online and what this",
    "start": "3050920",
    "end": "3056200"
  },
  {
    "text": "model is it's all about tribes and squads and pushing down decisionmaking and autonomy as low as possible and that",
    "start": "3056200",
    "end": "3062559"
  },
  {
    "text": "includes not just requirements Gathering and working as customers but also the operational side whether it being what",
    "start": "3062559",
    "end": "3067720"
  },
  {
    "text": "services you want to run how you want to run the servers monitoring scaling and all that so having a managed service",
    "start": "3067720",
    "end": "3073720"
  },
  {
    "text": "like a lastic cache is really critical to allow our squads to operate autonomy and it's a perfect fit each Squad can",
    "start": "3073720",
    "end": "3080920"
  },
  {
    "text": "determine how they want to integrate that into their cluster do they want to use red as cluster is it a single node",
    "start": "3080920",
    "end": "3086400"
  },
  {
    "text": "what size do they want it to be what eviction policy make sense for them and how do they want to manage their serialization and elasticache takes care",
    "start": "3086400",
    "end": "3093599"
  },
  {
    "text": "of all the operational complexity and it just works and they can focus on how they actually want to use that service on top of it it really just makes",
    "start": "3093599",
    "end": "3100960"
  },
  {
    "text": "sense so we had an analogy when we were prepping for this where someone said it's kind of like a slam dunk isn't it",
    "start": "3100960",
    "end": "3106440"
  },
  {
    "text": "that's a Cheesy Sports analogy but I I think it really resonates here so I'd be remiss if I didn't talk about reddis",
    "start": "3106440",
    "end": "3111680"
  },
  {
    "start": "3110000",
    "end": "3110000"
  },
  {
    "text": "cluster briefly um this is a really new addition it's been incredibly impactful for us I'll tell you that we don't need",
    "start": "3111680",
    "end": "3117280"
  },
  {
    "text": "to use it broadly it's kind of like a a hammer and often it's overkill for us but we do need it it's incredibly",
    "start": "3117280",
    "end": "3123040"
  },
  {
    "text": "important and it was the last piece of the puzzle for us to migrate all of our caching onto elastic cache I gave just a",
    "start": "3123040",
    "end": "3128599"
  },
  {
    "text": "screenshot up here of that feed that I talked about earlier that is running on reddish cluster in production today and",
    "start": "3128599",
    "end": "3133880"
  },
  {
    "text": "the performance on it is is really incredible this is one screenshot that I took just prepping for this presentation",
    "start": "3133880",
    "end": "3140000"
  },
  {
    "text": "so this is one Single Shard out of that feed cluster and you can see it's running right around 1.2% CPU and it's",
    "start": "3140000",
    "end": "3146480"
  },
  {
    "text": "doing 100,000 operations per minute I with that was per second sorry but that's per minute but on this Single",
    "start": "3146480",
    "end": "3152000"
  },
  {
    "text": "Shard at 1.2 CPU I mean that's that's really really incredible we're not even pushing this and we're operating in",
    "start": "3152000",
    "end": "3157640"
  },
  {
    "text": "Shard capacity all right so it's time for me to wrap up I want to talk about some best practices that we've learned over",
    "start": "3157640",
    "end": "3163640"
  },
  {
    "start": "3160000",
    "end": "3160000"
  },
  {
    "text": "the past couple years on elasticache first and foremost and I cannot stress this enough if you're in production use",
    "start": "3163640",
    "end": "3169599"
  },
  {
    "text": "a multi easy replica honestly you just have to at the end of the day you know you're running on an infrastructure",
    "start": "3169599",
    "end": "3175280"
  },
  {
    "text": "where nodes need maintenance nodes will fail there'll be network problems and in our experience running multi-az has been",
    "start": "3175280",
    "end": "3181799"
  },
  {
    "text": "a very very efficient way to provide uptime our fail is failover is often in the order magnitude of seconds I know",
    "start": "3181799",
    "end": "3188520"
  },
  {
    "text": "they talk about 30 seconds for us that's been a very high bar it's often much much quicker than that multiz is critical now obviously in you know Dev",
    "start": "3188520",
    "end": "3195200"
  },
  {
    "text": "and test we run single node right but production is always multiz Michael had a slide up there that",
    "start": "3195200",
    "end": "3201839"
  },
  {
    "text": "he went through kind of quickly talking about setting up alerting that's been critical for us and early on we didn't do a very good job with this and we paid",
    "start": "3201839",
    "end": "3208040"
  },
  {
    "text": "the price for it so some of the alerts that we found very valuable swap usage we've had some cases of where we didn't",
    "start": "3208040",
    "end": "3213799"
  },
  {
    "text": "manage our memory properly swap usage got out of hand and all of a sudden you see horrible performance this is a very",
    "start": "3213799",
    "end": "3219000"
  },
  {
    "text": "critical alert to set up CPU and evictions are the two others I'd recommend alerts on from our point of view so very",
    "start": "3219000",
    "end": "3225760"
  },
  {
    "text": "important I think it's worth taking the time to understand available eviction policies in reddis depending on your use",
    "start": "3225760",
    "end": "3232040"
  },
  {
    "text": "case different policies make sense for you there's six of them out there there's a really really good documentation online so I don't need to",
    "start": "3232040",
    "end": "3238240"
  },
  {
    "text": "waste your time talking about it but for example there's one called all keys lru and if you're just going to have a",
    "start": "3238240",
    "end": "3243640"
  },
  {
    "text": "cluster that only does caching it'll take care of the eviction for you based on lease requested automatically you",
    "start": "3243640",
    "end": "3249319"
  },
  {
    "text": "basically don't even need ttls it's a very easy way to phase in whereas we use volatile TTL for clusters that we have",
    "start": "3249319",
    "end": "3255839"
  },
  {
    "text": "mixed things like we have some distributed locks some caching some more persistent objects and if we use the",
    "start": "3255839",
    "end": "3261960"
  },
  {
    "text": "wrong one we might get the wrong objects evicted from memory or the wrong access patterns might be evicted it's very very",
    "start": "3261960",
    "end": "3267200"
  },
  {
    "text": "important to get that right my final one it's worth the time to learn and understand R's Advanced",
    "start": "3267200",
    "end": "3273960"
  },
  {
    "text": "data structures I talked a little bit about our news feed when we first got into caching we were just doing the basic object caching key value and that",
    "start": "3273960",
    "end": "3280799"
  },
  {
    "text": "is impactful and it makes a huge performance difference but what really happened in our company it was almost like a cultural shift to take the time",
    "start": "3280799",
    "end": "3287359"
  },
  {
    "text": "to learn to understand sorted sets hashes lists hyper hyper logs and how those could benefit our ability to",
    "start": "3287359",
    "end": "3293520"
  },
  {
    "text": "provide higher access to our data for our customers and things that just aren't possible in a traditional",
    "start": "3293520",
    "end": "3299079"
  },
  {
    "text": "database it really kind of opened our eyes to what we could do I also think it's important to understand the Big O",
    "start": "3299079",
    "end": "3304240"
  },
  {
    "text": "complexity of the operations on those data structures so when we were looking at designing the news feed we had to",
    "start": "3304240",
    "end": "3309359"
  },
  {
    "text": "decide did we want to use a sorted set based on date or did we want to use a more traditional list well we looked at",
    "start": "3309359",
    "end": "3315079"
  },
  {
    "text": "the Big O complexity of the operations we needed to run on that object don't understand what the performance implications are and again this is all",
    "start": "3315079",
    "end": "3321760"
  },
  {
    "text": "documented on the reddish site very very clearly there's wonderful examples on there I encourage you to check it out so",
    "start": "3321760",
    "end": "3327799"
  },
  {
    "text": "with that I really appreciate you talking to me today um I'm going to be available afterwards to answer questions",
    "start": "3327799",
    "end": "3333039"
  },
  {
    "text": "um I encourage you all to fill out the uh recommendation forms thank you and have a good one",
    "start": "3333039",
    "end": "3340720"
  }
]
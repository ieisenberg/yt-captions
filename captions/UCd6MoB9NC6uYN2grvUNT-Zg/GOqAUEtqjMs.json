[
  {
    "text": "- Hi, my name is Leonardo Murillo",
    "start": "360",
    "end": "1860"
  },
  {
    "text": "and I build cool stuff in AWS",
    "start": "1860",
    "end": "3510"
  },
  {
    "text": "using products in AWS Marketplace.",
    "start": "3510",
    "end": "5279"
  },
  {
    "text": "Thank you for joining me.",
    "start": "5280",
    "end": "6930"
  },
  {
    "text": "We're gonna be talking\nabout industry trends,",
    "start": "6930",
    "end": "8519"
  },
  {
    "text": "challenges, and how you can solve them.",
    "start": "8520",
    "end": "10830"
  },
  {
    "text": "Today I wanna talk about how to tap",
    "start": "10830",
    "end": "12420"
  },
  {
    "text": "into an existing\norganizational knowledge bases",
    "start": "12420",
    "end": "15060"
  },
  {
    "text": "without having to jump through data hoops,",
    "start": "15060",
    "end": "17400"
  },
  {
    "text": "like data pipelines or duplication of data",
    "start": "17400",
    "end": "20039"
  },
  {
    "text": "just to make it available\nto LLM-based solutions,",
    "start": "20040",
    "end": "23220"
  },
  {
    "text": "enriched through RAG.",
    "start": "23220",
    "end": "24602"
  },
  {
    "text": "You might have already\nheard me talk about LLMs,",
    "start": "25530",
    "end": "27930"
  },
  {
    "text": "large language models, and RAG,",
    "start": "27930",
    "end": "29700"
  },
  {
    "text": "Retrieval-Augmented Generation.",
    "start": "29700",
    "end": "31050"
  },
  {
    "text": "So let me just do a quick recap.",
    "start": "31050",
    "end": "32649"
  },
  {
    "text": "Large language models are trained",
    "start": "33870",
    "end": "35340"
  },
  {
    "text": "using huge datasets and\nhave quickly evolved",
    "start": "35340",
    "end": "38490"
  },
  {
    "text": "to provide sometimes unbelievable\nhuman-like capabilities.",
    "start": "38490",
    "end": "41700"
  },
  {
    "text": "The thing about foundational\nlarge language models",
    "start": "41700",
    "end": "44430"
  },
  {
    "text": "is that they don't know\nanything about the custom,",
    "start": "44430",
    "end": "46530"
  },
  {
    "text": "internal and private knowledge",
    "start": "46530",
    "end": "48180"
  },
  {
    "text": "that is stored across most organizations.",
    "start": "48180",
    "end": "50700"
  },
  {
    "text": "You're trained using publicly available",
    "start": "50700",
    "end": "52290"
  },
  {
    "text": "and open source data, which, of course,",
    "start": "52290",
    "end": "54030"
  },
  {
    "text": "and luckily, does not include\na lot of the knowledge",
    "start": "54030",
    "end": "57030"
  },
  {
    "text": "you hold and that makes your\norganization one of a kind.",
    "start": "57030",
    "end": "60270"
  },
  {
    "text": "Most of the times, this data,",
    "start": "60270",
    "end": "62310"
  },
  {
    "text": "your custom data, is stored and indexed",
    "start": "62310",
    "end": "65070"
  },
  {
    "text": "in a fit-for-purpose data repository,",
    "start": "65070",
    "end": "66990"
  },
  {
    "text": "a search engine, that provides users",
    "start": "66990",
    "end": "69270"
  },
  {
    "text": "with access to it using\njust plain English queries.",
    "start": "69270",
    "end": "72180"
  },
  {
    "text": "This very data is precisely\nthe type of context",
    "start": "72180",
    "end": "75108"
  },
  {
    "text": "that large language models need",
    "start": "75108",
    "end": "77280"
  },
  {
    "text": "in order to provide custom responses",
    "start": "77280",
    "end": "79409"
  },
  {
    "text": "specific to your organization\nand to your users.",
    "start": "79410",
    "end": "82800"
  },
  {
    "text": "Now, there are different\nways in which your data",
    "start": "82800",
    "end": "84480"
  },
  {
    "text": "can be made available to LLMs.",
    "start": "84480",
    "end": "87210"
  },
  {
    "text": "Most of them though, are\ncomplex, time-consuming",
    "start": "87210",
    "end": "89850"
  },
  {
    "text": "and therefore expensive,",
    "start": "89850",
    "end": "91350"
  },
  {
    "text": "which is why\nRetrieval-Augmented Generation",
    "start": "91350",
    "end": "93450"
  },
  {
    "text": "has turned into the go-to\napproach for a lot of folks",
    "start": "93450",
    "end": "96149"
  },
  {
    "text": "looking to provide custom\ncontext with little effort.",
    "start": "96150",
    "end": "98970"
  },
  {
    "text": "And it works fairly\nwell for most scenarios.",
    "start": "98970",
    "end": "101730"
  },
  {
    "text": "The thing about RAG is\nthat it queries for data",
    "start": "101730",
    "end": "104670"
  },
  {
    "text": "that is applicable, similar\nto the response generated",
    "start": "104670",
    "end": "108090"
  },
  {
    "text": "by the LLM.",
    "start": "108090",
    "end": "109200"
  },
  {
    "text": "And for that capability to work,",
    "start": "109200",
    "end": "110909"
  },
  {
    "text": "data must be made available somewhere",
    "start": "110910",
    "end": "113460"
  },
  {
    "text": "where this type of search can take place.",
    "start": "113460",
    "end": "115229"
  },
  {
    "text": "This usually means it must be vectorized",
    "start": "115230",
    "end": "117810"
  },
  {
    "text": "and put into some vector database.",
    "start": "117810",
    "end": "120090"
  },
  {
    "text": "Vectors are numerical\nrepresentations of data",
    "start": "120090",
    "end": "122850"
  },
  {
    "text": "that enable simulator searches",
    "start": "122850",
    "end": "124470"
  },
  {
    "text": "and other capabilities\naligned with what RAG",
    "start": "124470",
    "end": "127110"
  },
  {
    "text": "and most RAG frameworks actually need",
    "start": "127110",
    "end": "128940"
  },
  {
    "text": "to do their own thing, right,",
    "start": "128940",
    "end": "130590"
  },
  {
    "text": "and turning data into vectors\nusually requires pipelines",
    "start": "130590",
    "end": "134010"
  },
  {
    "text": "and storing that data in\na different repository,",
    "start": "134010",
    "end": "136860"
  },
  {
    "text": "away from the canonical source of truth",
    "start": "136860",
    "end": "139290"
  },
  {
    "text": "that was used to generate those vectors,",
    "start": "139290",
    "end": "141959"
  },
  {
    "text": "which means it requires updating\nthose vectors continuously",
    "start": "141960",
    "end": "145170"
  },
  {
    "text": "so you get the gist of it, right?",
    "start": "145170",
    "end": "146610"
  },
  {
    "text": "You see why it's complex.",
    "start": "146610",
    "end": "148470"
  },
  {
    "text": "What I recently learned though",
    "start": "148470",
    "end": "149910"
  },
  {
    "text": "is that if your knowledge\nlives in Elastic,",
    "start": "149910",
    "end": "152670"
  },
  {
    "text": "none of that is necessary.",
    "start": "152670",
    "end": "154380"
  },
  {
    "text": "Elastic has built in\nsimilarity search capabilities",
    "start": "154380",
    "end": "157290"
  },
  {
    "text": "that integrate directly",
    "start": "157290",
    "end": "158610"
  },
  {
    "text": "with pretty much every\nRAG framework I dug into,",
    "start": "158610",
    "end": "161520"
  },
  {
    "text": "which means you can directly\nuse your existing data",
    "start": "161520",
    "end": "164520"
  },
  {
    "text": "to provide context",
    "start": "164520",
    "end": "165600"
  },
  {
    "text": "to your RAG solution without\never having it leave Elastic.",
    "start": "165600",
    "end": "168870"
  },
  {
    "text": "I find that level of\nreduction in complexity",
    "start": "168870",
    "end": "171614"
  },
  {
    "text": "that this approach facilitates",
    "start": "171615",
    "end": "173460"
  },
  {
    "text": "and the fact that you get\na single source of truth",
    "start": "173460",
    "end": "175380"
  },
  {
    "text": "for all knowledge you're\npresenting to your users,",
    "start": "175380",
    "end": "177570"
  },
  {
    "text": "whether through say, a chatbot,",
    "start": "177570",
    "end": "178950"
  },
  {
    "text": "or using the builtin search\nfeature of your application,",
    "start": "178950",
    "end": "181560"
  },
  {
    "text": "nothing short of revolutionary.",
    "start": "181560",
    "end": "183540"
  },
  {
    "text": "Now, if you tie that together",
    "start": "183540",
    "end": "184739"
  },
  {
    "text": "with a fully-managed\nservice like Amazon Bedrock",
    "start": "184740",
    "end": "187380"
  },
  {
    "text": "to run your LLM in the cloud,",
    "start": "187380",
    "end": "189060"
  },
  {
    "text": "it's hard to think of a simpler way",
    "start": "189060",
    "end": "190860"
  },
  {
    "text": "to get your large language\nmodel-driven solution",
    "start": "190860",
    "end": "193260"
  },
  {
    "text": "enriched with context using RAG,",
    "start": "193260",
    "end": "195480"
  },
  {
    "text": "without having to worry about\nany of the moving pieces",
    "start": "195480",
    "end": "197670"
  },
  {
    "text": "that other stacks would\nhave you taken care of.",
    "start": "197670",
    "end": "200069"
  },
  {
    "text": "And the cool thing",
    "start": "200070",
    "end": "201810"
  },
  {
    "text": "is that you can get Elastic\nCloud off AWS Marketplace,",
    "start": "201810",
    "end": "205080"
  },
  {
    "text": "which will provide you\nwith a very streamlined way",
    "start": "205080",
    "end": "206910"
  },
  {
    "text": "to integrate the Elastic Managed Service",
    "start": "206910",
    "end": "208710"
  },
  {
    "text": "into your AWS account and\neven get a free trial.",
    "start": "208710",
    "end": "211860"
  },
  {
    "text": "So look for the technical article",
    "start": "211860",
    "end": "213180"
  },
  {
    "text": "that accompanies this\nvideo to get a close review",
    "start": "213180",
    "end": "215549"
  },
  {
    "text": "as to actually how you can build something",
    "start": "215550",
    "end": "217140"
  },
  {
    "text": "like this and be on the lookout for a lab",
    "start": "217140",
    "end": "219420"
  },
  {
    "text": "that we'll be releasing soon\nthat actually guides you",
    "start": "219420",
    "end": "221640"
  },
  {
    "text": "step-by-step in building\nthis very solution.",
    "start": "221640",
    "end": "224640"
  },
  {
    "text": "See you all soon.",
    "start": "224640",
    "end": "225815"
  },
  {
    "text": "(upbeat music)",
    "start": "225815",
    "end": "228398"
  }
]
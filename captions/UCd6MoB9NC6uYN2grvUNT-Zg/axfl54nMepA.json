[
  {
    "text": "[Music]",
    "start": "0",
    "end": "2800"
  },
  {
    "text": "we've collected data on over a thousand",
    "start": "2800",
    "end": "5520"
  },
  {
    "text": "tumor samples almost 200 million cells",
    "start": "5520",
    "end": "9120"
  },
  {
    "text": "worth of really carefully crafted",
    "start": "9120",
    "end": "11440"
  },
  {
    "text": "precise multimodal data to train AI",
    "start": "11440",
    "end": "14400"
  },
  {
    "text": "models on cancers are a lot more complex",
    "start": "14400",
    "end": "17359"
  },
  {
    "text": "than we can define as humans and really",
    "start": "17359",
    "end": "20160"
  },
  {
    "text": "this is a problem for machine learning",
    "start": "20160",
    "end": "22240"
  },
  {
    "text": "our vision at Noetic is to train",
    "start": "22240",
    "end": "24080"
  },
  {
    "text": "foundation models of cancer biology that",
    "start": "24080",
    "end": "26480"
  },
  {
    "text": "can help us to position the right drug",
    "start": "26480",
    "end": "29039"
  },
  {
    "text": "in the right patient in less than 2",
    "start": "29039",
    "end": "31599"
  },
  {
    "text": "years we've already generated close to a",
    "start": "31599",
    "end": "33440"
  },
  {
    "text": "pabyte of data arguably one of the",
    "start": "33440",
    "end": "35440"
  },
  {
    "text": "largest deepest human tumor biology data",
    "start": "35440",
    "end": "37760"
  },
  {
    "text": "sets of its kind to process all this",
    "start": "37760",
    "end": "41120"
  },
  {
    "text": "multimodal data requires a lot of",
    "start": "41120",
    "end": "43760"
  },
  {
    "text": "compute we've built this infrastructure",
    "start": "43760",
    "end": "45520"
  },
  {
    "text": "from day one on AWS and Nvidia GPUs in",
    "start": "45520",
    "end": "49680"
  },
  {
    "text": "the future we'll move to H200's and",
    "start": "49680",
    "end": "51920"
  },
  {
    "text": "hopefully double our training throughput",
    "start": "51920",
    "end": "54719"
  },
  {
    "text": "using Amazon SageMaker Hyper Pod and",
    "start": "54719",
    "end": "57360"
  },
  {
    "text": "access to technical experts at both AWS",
    "start": "57360",
    "end": "60079"
  },
  {
    "text": "and Nvidia we've been able to scale up",
    "start": "60079",
    "end": "62480"
  },
  {
    "text": "our training with a really quite small",
    "start": "62480",
    "end": "65720"
  },
  {
    "text": "team i'm a cancer survivor myself and I",
    "start": "65720",
    "end": "69600"
  },
  {
    "text": "was really fortunate to have a diagnosis",
    "start": "69600",
    "end": "72240"
  },
  {
    "text": "that was quite treatable but there are",
    "start": "72240",
    "end": "74320"
  },
  {
    "text": "so many patients who just don't have",
    "start": "74320",
    "end": "77280"
  },
  {
    "text": "great options the dream is new and more",
    "start": "77280",
    "end": "81119"
  },
  {
    "text": "efficacious therapies and being able to",
    "start": "81119",
    "end": "84080"
  },
  {
    "text": "know exactly which patients those will",
    "start": "84080",
    "end": "85840"
  },
  {
    "text": "work for we're in a point right now",
    "start": "85840",
    "end": "88000"
  },
  {
    "text": "where AI can make an impact on science",
    "start": "88000",
    "end": "90479"
  },
  {
    "text": "at scale at speed now we're envisioning",
    "start": "90479",
    "end": "93119"
  },
  {
    "text": "that next step the work we do today can",
    "start": "93119",
    "end": "95840"
  },
  {
    "text": "impact patients and help save lives",
    "start": "95840",
    "end": "99690"
  },
  {
    "text": "[Music]",
    "start": "99690",
    "end": "103780"
  }
]
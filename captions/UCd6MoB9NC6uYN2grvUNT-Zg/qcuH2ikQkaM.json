[
  {
    "start": "0",
    "end": "65000"
  },
  {
    "text": "hello everyone good morning and welcome yeah let's just uh since it's Friday",
    "start": "0",
    "end": "6270"
  },
  {
    "text": "morning after the replay party we'll start off with a fun question to make sure everyone's awake so we just went",
    "start": "6270",
    "end": "11460"
  },
  {
    "text": "through Black Friday a week ago in Cyber Monday so how many people here bought something from Amazon in the last week",
    "start": "11460",
    "end": "18800"
  },
  {
    "text": "well yeah that's actually most of the room um how about in the last year is that like everyone yeah that's everyone",
    "start": "18800",
    "end": "25619"
  },
  {
    "text": "okay and one more question so how many of you would be a little bit upset or a little",
    "start": "25619",
    "end": "30689"
  },
  {
    "text": "frustrated if what you bought didn't get delivered to you on time yeah me too",
    "start": "30689",
    "end": "36780"
  },
  {
    "text": "hi my name is Mike Thomas and this is Pierce Kalani and we work on one of the many systems at Amazon responsible for",
    "start": "36780",
    "end": "43379"
  },
  {
    "text": "ensuring that what you buy gets delivered we're really excited to be here to give you a small peek under the",
    "start": "43379",
    "end": "48899"
  },
  {
    "text": "hoods and we're gonna be sharing with you an architectural challenge that our particular team faced and we walking",
    "start": "48899",
    "end": "56190"
  },
  {
    "text": "through how we overcame that challenge you guessed it with the help of AWS and DynamoDB thanks for taking the time out",
    "start": "56190",
    "end": "63359"
  },
  {
    "text": "of the schedule to hear from us all right so just two I want to start off by",
    "start": "63359",
    "end": "68820"
  },
  {
    "start": "65000",
    "end": "148000"
  },
  {
    "text": "setting the expectations for the session so first we're gonna we're going to be opening up the hood of our system and",
    "start": "68820",
    "end": "75600"
  },
  {
    "text": "we're going to be talking about the specific design challenges that our team faced from moving our team system off of",
    "start": "75600",
    "end": "82950"
  },
  {
    "text": "Oracle and on to dynamodb we're gonna walk through how we solve those challenges and as we do so we will",
    "start": "82950",
    "end": "90600"
  },
  {
    "text": "highlight five techniques you may be able to apply to a system that you own shifting from a relational to a no",
    "start": "90600",
    "end": "97500"
  },
  {
    "text": "sequel database it's not always easy and so we expect the techniques will be particularly useful if you find yourself that you're",
    "start": "97500",
    "end": "104579"
  },
  {
    "text": "no sequel database of choice doesn't quite provide everything you might want right out of the box what this talk is",
    "start": "104579",
    "end": "111720"
  },
  {
    "text": "not this talk is not an introduction to Oracle it's not an introduction to dynamodb we're gonna assume quite a bit",
    "start": "111720",
    "end": "117210"
  },
  {
    "text": "of background knowledge on the ladder it's not an exhaustive of all the designs we could have gone with all the choices we could have make made we won't",
    "start": "117210",
    "end": "123960"
  },
  {
    "text": "have the time to do all that nuance justice and again it's actually not",
    "start": "123960",
    "end": "129539"
  },
  {
    "text": "going to be about how order processing it Amazon works we're gonna be looking at a little bit of a deeper layer in the tech",
    "start": "129539",
    "end": "135120"
  },
  {
    "text": "stack than that so if this isn't what you were expecting like you can feel free to leave no hard feelings I won't",
    "start": "135120",
    "end": "141239"
  },
  {
    "text": "take it personally you won't take it personally and don't worry you'll still get your stuff delivered on time all",
    "start": "141239",
    "end": "148799"
  },
  {
    "start": "148000",
    "end": "252000"
  },
  {
    "text": "right so let's get started here's the flow of the talk first I'm just going to introduce our system it's key functionality our requirements if you",
    "start": "148799",
    "end": "155099"
  },
  {
    "text": "will and then we're gonna dig in a little bit to our Oracle based architecture just to see kind of how it",
    "start": "155099",
    "end": "161040"
  },
  {
    "text": "started to break down for us next really the heart of the talk will will cover the design challenges faced when moving",
    "start": "161040",
    "end": "167430"
  },
  {
    "text": "the system from dynamo and how we overcame those and finally we'll summarize what results we saw once the",
    "start": "167430",
    "end": "173609"
  },
  {
    "text": "surrey architecture project was finally done with that in mind let me introduce",
    "start": "173609",
    "end": "178889"
  },
  {
    "text": "our system the system that ph and i work on is called herd herd is a distributed",
    "start": "178889",
    "end": "184500"
  },
  {
    "text": "workflow orchestration system used within amazon and you can think of us as a behind the scenes coordinator working",
    "start": "184500",
    "end": "190799"
  },
  {
    "text": "across amazon's service-oriented architecture engineering teams within amazon use us to stitch together",
    "start": "190799",
    "end": "197299"
  },
  {
    "text": "individual services step-by-step to form an end-to-end process that we call a",
    "start": "197299",
    "end": "202620"
  },
  {
    "text": "workflow so let's pretend for a minute that we're the order processing team at",
    "start": "202620",
    "end": "207959"
  },
  {
    "text": "Amazon and we're going to build a really overly simplified version of how order processing in amazon works so at a high",
    "start": "207959",
    "end": "214139"
  },
  {
    "text": "level you might think that hey the first thing that might happen after you place an order on the website is that we",
    "start": "214139",
    "end": "219299"
  },
  {
    "text": "should probably you know charge the customers credit card right to make sure that payment would be able to go through",
    "start": "219299",
    "end": "224699"
  },
  {
    "text": "and so we might plug in a payment service that knows how to do that and if that charge is approved you might then",
    "start": "224699",
    "end": "231299"
  },
  {
    "text": "imagine plugging in a fulfillment service that knows how to you know determine which fulfillment center the",
    "start": "231299",
    "end": "237079"
  },
  {
    "text": "customers order should ship from and to ultimately ship the order and on the contrary if that order was declined you",
    "start": "237079",
    "end": "244319"
  },
  {
    "text": "can imagine plugging in an email service that knows how to email you and say hey your credit card is expired can please",
    "start": "244319",
    "end": "250259"
  },
  {
    "text": "update it then once you've got your workflow defined and you tell us to run",
    "start": "250259",
    "end": "256019"
  },
  {
    "start": "252000",
    "end": "361000"
  },
  {
    "text": "an instance of one we are responsible for driving all those steps through to completion as we do so we're gonna",
    "start": "256019",
    "end": "262409"
  },
  {
    "text": "record everything that happens and guarantee that it won't get lost we can't have any orders left behind right",
    "start": "262409",
    "end": "270720"
  },
  {
    "text": "next we're gonna retry whenever there's a failure because as you all know in distributed systems stuff breaks right",
    "start": "270720",
    "end": "279270"
  },
  {
    "text": "lastly we're gonna help you monitor and debug errors that might be happening in your workflow both individually and an",
    "start": "279270",
    "end": "286180"
  },
  {
    "text": "aggregate because you won't be surprised to learn that Amazon has bugs too so in",
    "start": "286180",
    "end": "293379"
  },
  {
    "text": "short we make sure your workflow gets to where it needs to go and that it stays safe along the way hence the name herd",
    "start": "293379",
    "end": "301319"
  },
  {
    "text": "all right so that's the mental model of what herd does throughout the rest of the talk we're actually going to zero in",
    "start": "301319",
    "end": "307120"
  },
  {
    "text": "and focus on just one core piece of the system the piece of the system responsible for storing each workflow",
    "start": "307120",
    "end": "313240"
  },
  {
    "text": "instance as it runs so let's take a look at the data model that our storage",
    "start": "313240",
    "end": "318849"
  },
  {
    "text": "system will need to work with in herd we call a single running instance of a workflow a work item it has a string",
    "start": "318849",
    "end": "326050"
  },
  {
    "text": "identifier a string indicating the name of the workflow that's running like order processing a timestamp indicating",
    "start": "326050",
    "end": "332110"
  },
  {
    "text": "when the workflow should run next a string indicating the current step that the workflow is in and a history list",
    "start": "332110",
    "end": "339340"
  },
  {
    "text": "that records every event that occurs while the workflow is running so now what we're going to need is we're gonna",
    "start": "339340",
    "end": "345490"
  },
  {
    "text": "we're going to need a system that lets a store these work items and query them in",
    "start": "345490",
    "end": "350590"
  },
  {
    "text": "various ways we'll call the system our work item storage service and so now let's walk",
    "start": "350590",
    "end": "357250"
  },
  {
    "text": "through the key pieces of functionality that the system is going to need to be able to provide so first thing we're",
    "start": "357250",
    "end": "363520"
  },
  {
    "start": "361000",
    "end": "540000"
  },
  {
    "text": "gonna need is a history store we're gonna give a store a work item along with the history of events that occurred over time so taking our example from",
    "start": "363520",
    "end": "370870"
  },
  {
    "text": "before the first thing that would happen is we move into that charge state we'd we'd be then calling that payment",
    "start": "370870",
    "end": "376990"
  },
  {
    "text": "service to charge the customers credit card and say that charge was declined we'd record that as an event on the",
    "start": "376990",
    "end": "382659"
  },
  {
    "text": "history list there - and next we'll move on to the email service to email that the customer has that their payment has",
    "start": "382659",
    "end": "389770"
  },
  {
    "text": "failed and that gets recorded in as an event as well that's really all there is to it for the history server for the",
    "start": "389770",
    "end": "395409"
  },
  {
    "text": "history store our storage system needs a way to store this history as the events accumulate",
    "start": "395409",
    "end": "401310"
  },
  {
    "text": "over time and once it's stored we can't lose it right no order left behind next thing we need is actually a",
    "start": "401310",
    "end": "409860"
  },
  {
    "text": "scheduled q when failures happen workflows can get rescheduled for execution at a later time so let's say",
    "start": "409860",
    "end": "417389"
  },
  {
    "text": "we go to call that email service to notify the customer that their charge was declined and let's say that that",
    "start": "417389",
    "end": "422490"
  },
  {
    "text": "service is having a temporary outage stuff breaks right so we're gonna record",
    "start": "422490",
    "end": "427800"
  },
  {
    "text": "that call failure as an event maybe as an internal server error and then depending on how the workflow is",
    "start": "427800",
    "end": "433680"
  },
  {
    "text": "configured will push out the next scheduled execution time in this case let's retry after three minutes and you",
    "start": "433680",
    "end": "439919"
  },
  {
    "text": "can see the time advances they're the job of our storage system will be to",
    "start": "439919",
    "end": "445620"
  },
  {
    "text": "find the next work item scheduled to run for a given workflow type and it's oh",
    "start": "445620",
    "end": "452789"
  },
  {
    "text": "and by the way workflows can be scheduled to run it basically any point in the future like up from one second to",
    "start": "452789",
    "end": "458009"
  },
  {
    "text": "now two years in the future like thank pre-orders for the next Georgia RR",
    "start": "458009",
    "end": "463860"
  },
  {
    "text": "martin novel yeah that's actually how that works so the final piece of",
    "start": "463860",
    "end": "469889"
  },
  {
    "text": "functionality we need is the ability to group count and list work items according to their current step to see",
    "start": "469889",
    "end": "476370"
  },
  {
    "text": "why let's keep going with in our example we're in that email customer step and the email service is having a temporary",
    "start": "476370",
    "end": "482129"
  },
  {
    "text": "outage we want to be able to monitor for failures that happen in real time to catch backlogs that might be building up",
    "start": "482129",
    "end": "488219"
  },
  {
    "text": "in our workflows that means we want to be able to not just work it look at a single work item but across all work",
    "start": "488219",
    "end": "494580"
  },
  {
    "text": "items in aggregate and see how many of them are running in each step this is",
    "start": "494580",
    "end": "499889"
  },
  {
    "text": "really handy for on-call engineers at Amazon as you can imagine having cloud watch style metrics getting published on",
    "start": "499889",
    "end": "505529"
  },
  {
    "text": "this data and alarms firing in an on-call engineer getting paged whenever there's a problem so when that email service goes down",
    "start": "505529",
    "end": "512339"
  },
  {
    "text": "instead of there just being a few workflows in the email customer step it'll quickly balloon to maybe thousands",
    "start": "512339",
    "end": "517620"
  },
  {
    "text": "or more and an on-call engineer can be page to look into the issue that",
    "start": "517620",
    "end": "522719"
  },
  {
    "text": "engineer is going to be able to want to see what those thousands of work items are maybe sample a few of them look at",
    "start": "522719",
    "end": "528990"
  },
  {
    "text": "the exceptions that were happening see some stack traces and use that information to solve the problem and",
    "start": "528990",
    "end": "534899"
  },
  {
    "text": "that's why we need the ability to list all the work items that are in a given step - all right so actually that's what",
    "start": "534899",
    "end": "543029"
  },
  {
    "start": "540000",
    "end": "662000"
  },
  {
    "text": "all we need we need a work item storage service that can do these three things not too bad right and indeed we've",
    "start": "543029",
    "end": "549240"
  },
  {
    "text": "actually had one of those on the herd team for a while here it is this is our work item storage system it's a web",
    "start": "549240",
    "end": "555690"
  },
  {
    "text": "service and here's what it looked like back in 2009 back in 2009 we had just",
    "start": "555690",
    "end": "561839"
  },
  {
    "text": "three sharded Oracle databases each database was doing all three of those",
    "start": "561839",
    "end": "567120"
  },
  {
    "text": "key pieces of functionality for us you can imagine us having tables during the work item in the history queries to find",
    "start": "567120",
    "end": "574350"
  },
  {
    "text": "the next scheduled item to run group by queries or some materialized views to a greet and this was workflows out first",
    "start": "574350",
    "end": "580170"
  },
  {
    "text": "step and we had indexes defined and you know to make everything efficient some fairly standard stuff the gray boxes",
    "start": "580170",
    "end": "587130"
  },
  {
    "text": "here are all web services you'll notice there's one per database and this is",
    "start": "587130",
    "end": "592980"
  },
  {
    "text": "this exists because relational databases have limits on the number of connections and each can accept so really those are",
    "start": "592980",
    "end": "599010"
  },
  {
    "text": "just there to kind of pool all the Oracle connections together and the routing layer exists on top just about",
    "start": "599010",
    "end": "604649"
  },
  {
    "text": "requests requests appropriately and to aggregate the results simple enough",
    "start": "604649",
    "end": "609810"
  },
  {
    "text": "simples good but what created a problem for us was that our system was on",
    "start": "609810",
    "end": "615329"
  },
  {
    "text": "average doubling and traffic volume year-over-year thanks to increased adoption of heard by other teams within",
    "start": "615329",
    "end": "621839"
  },
  {
    "text": "Amazon and so the thing about doubling is it kind of sucks I mean don't get me",
    "start": "621839",
    "end": "628829"
  },
  {
    "text": "wrong it's a good problem to have but the thing is you build a system right and things work great at first and then",
    "start": "628829",
    "end": "634800"
  },
  {
    "text": "after a couple of years you'll go from three databases to a dozen in a couple of years after that you'll have multiple",
    "start": "634800",
    "end": "640320"
  },
  {
    "text": "dozens almost fifty and soon you'll be in the hundreds and so at this point in the story the systems at a scale where",
    "start": "640320",
    "end": "646709"
  },
  {
    "text": "we're running billions of workflows every single day we have hundreds of millions of them running at any given",
    "start": "646709",
    "end": "653310"
  },
  {
    "text": "point at a time and we're doing a hundred thousand steps every second so",
    "start": "653310",
    "end": "659190"
  },
  {
    "text": "where did the architecture start to break down well firstly if the effort RIT to scale",
    "start": "659190",
    "end": "666120"
  },
  {
    "start": "662000",
    "end": "777000"
  },
  {
    "text": "the system is what really started to become untenable so scaling this system up obviously meant provisioning new",
    "start": "666120",
    "end": "672630"
  },
  {
    "text": "Oracle database hardware but what that meant was things like creating Oracle database credentials creating table",
    "start": "672630",
    "end": "678270"
  },
  {
    "text": "schemas tuning Oracle database settings creating that new service to front them getting the connection strings and plugging them into our application",
    "start": "678270",
    "end": "684900"
  },
  {
    "text": "provisioning a load balancer to sit in front of that web service defining new alarms doing functional testing and",
    "start": "684900",
    "end": "690810"
  },
  {
    "text": "performance testing to make sure we didn't mess up any of that previous stuff oh and then we had to have a whole way to actually repartition our data",
    "start": "690810",
    "end": "697170"
  },
  {
    "text": "across the old shards and the new ones seamlessly without violating any system constraints for which we built a whole",
    "start": "697170",
    "end": "702840"
  },
  {
    "text": "system that I'm not gonna have time to talk about and then we had ongoing maintenance effort - that wasn't where",
    "start": "702840",
    "end": "708090"
  },
  {
    "text": "it ended right we had operating system patches we had to do Oracle database software patches and upgrades that",
    "start": "708090",
    "end": "713190"
  },
  {
    "text": "sometimes required 20 minutes of scheduled downtime scheduled downtime for processing orders at Amazon index",
    "start": "713190",
    "end": "720330"
  },
  {
    "text": "rebuild jobs that would run that need to make sure the indexes were efficient we'd have to fine-tune their schedule to",
    "start": "720330",
    "end": "725640"
  },
  {
    "text": "make sure that all then didn't happen at the same time so that we otherwise we'd have a big latency hit we'd have to debug problems like why is one database",
    "start": "725640",
    "end": "732240"
  },
  {
    "text": "slower than the others you know checking hardware metrics maybe there's a bad query plan maybe the",
    "start": "732240",
    "end": "737730"
  },
  {
    "text": "configuration is out of sync sometimes individual pieces of hardware would die due to a bad disk or an i/o controller I",
    "start": "737730",
    "end": "743940"
  },
  {
    "text": "can honestly say I've been paged in the middle of the night for an i/o control they're dying and sometimes the",
    "start": "743940",
    "end": "750960"
  },
  {
    "text": "automated fail overs would fail and we'd have to have a database administrator get paged in to determine which database",
    "start": "750960",
    "end": "756000"
  },
  {
    "text": "was primary and what should actually be the secondary in short you guys probably",
    "start": "756000",
    "end": "761100"
  },
  {
    "text": "are familiar with this if you're running Oracle setups these it required a lot of tender love and care for us and I don't",
    "start": "761100",
    "end": "767220"
  },
  {
    "text": "know about you I only care about individual IO controllers so much and so",
    "start": "767220",
    "end": "773280"
  },
  {
    "text": "we decided let's see if we can make this all of this someone else's problem dinah ODB's alright and now let's see how we",
    "start": "773280",
    "end": "781950"
  },
  {
    "start": "777000",
    "end": "900000"
  },
  {
    "text": "did that so let's go back to the three key pieces of functionality our system",
    "start": "781950",
    "end": "789060"
  },
  {
    "text": "needs to provide we need the history store we need a scheduled queue and group count and list we're gonna start",
    "start": "789060",
    "end": "794730"
  },
  {
    "text": "with the history store first so recall if the Oracle based architecture each individual database",
    "start": "794730",
    "end": "800190"
  },
  {
    "text": "did all three of those job for us and so now let's like take a look under the hoods of one of those and see how",
    "start": "800190",
    "end": "806100"
  },
  {
    "text": "that history store actually operated we actually had simply two tables on Oracle",
    "start": "806100",
    "end": "811950"
  },
  {
    "text": "a work item table which we'll call the header table going forward because it contains the work items basic metadata",
    "start": "811950",
    "end": "818700"
  },
  {
    "text": "like its ID in the workflow name and history table with a one-to-many relationship between the two sexually is",
    "start": "818700",
    "end": "825960"
  },
  {
    "text": "a fairly standard relational data database schema actually probably a lot simpler than a lot of the systems that you all own and on Oracle we were you",
    "start": "825960",
    "end": "835410"
  },
  {
    "text": "know able to rely on Oracle's transactions to ensure that everything was consistent and you know and that was",
    "start": "835410",
    "end": "842010"
  },
  {
    "text": "good but on the DynamoDB if we were to model the tables the same way we'd run",
    "start": "842010",
    "end": "847440"
  },
  {
    "text": "into a problem right as you know DynamoDB does not need a belief support transactions across tables whenever we",
    "start": "847440",
    "end": "854250"
  },
  {
    "text": "add a new history record we typically also have to update something in the main header table like the current step",
    "start": "854250",
    "end": "859860"
  },
  {
    "text": "and they have to stay in sync and this is a problem because we can't guarantee that both updates will succeed the",
    "start": "859860",
    "end": "865770"
  },
  {
    "text": "history update might happen but then the header might fail and we'd end up with this inconsistent state we're in the",
    "start": "865770",
    "end": "871200"
  },
  {
    "text": "charge step or are we in the ship step I don't know so our system really needs to provide a consistent view of the work item data to",
    "start": "871200",
    "end": "877620"
  },
  {
    "text": "its users and so this was the first big problem we encountered let's take a look at how we might solve it so the first",
    "start": "877620",
    "end": "885450"
  },
  {
    "text": "thing we realized one thing we could do is just store it all in one big table demo DB provides reads or writes",
    "start": "885450",
    "end": "891060"
  },
  {
    "text": "consistency for records within the same table so why don't we just store the history in right there no you know no",
    "start": "891060",
    "end": "897840"
  },
  {
    "text": "big deal right well for us actually the big deal was cost so if you recall the",
    "start": "897840",
    "end": "904620"
  },
  {
    "start": "900000",
    "end": "997000"
  },
  {
    "text": "DynamoDB costing model you provision your throughput in advance right and dynamo charges per kilobyte you read and",
    "start": "904620",
    "end": "911250"
  },
  {
    "text": "write what we just did by clubbing all that data into one record let's make it",
    "start": "911250",
    "end": "916830"
  },
  {
    "text": "so that we have to write a lot more data over time than ideally we should have - let me show you",
    "start": "916830",
    "end": "922680"
  },
  {
    "text": "so if recall that the work flow history a cruise as a work item executes so say",
    "start": "922680",
    "end": "928410"
  },
  {
    "text": "we have a series of updates into the workout and I'm each 2 kilobytes in size you can see that if we have three updates here in principle we",
    "start": "928410",
    "end": "935610"
  },
  {
    "text": "should really only have to write six kilobytes of data total but instead if",
    "start": "935610",
    "end": "941220"
  },
  {
    "text": "we used our one single BigTable strategy the first update would start out the same way we'd write that two kilobytes",
    "start": "941220",
    "end": "947370"
  },
  {
    "text": "but what would we do for the second one we'd read in the existing two right and",
    "start": "947370",
    "end": "952530"
  },
  {
    "text": "have our new to our additional two that's coming in with the new request and we'd have to write back four and if",
    "start": "952530",
    "end": "959970"
  },
  {
    "text": "I repeat this we'd read in four and then write that add onto and write back six",
    "start": "959970",
    "end": "965430"
  },
  {
    "text": "and so you can see what we actually got charged for twelve kilobytes of writes",
    "start": "965430",
    "end": "970530"
  },
  {
    "text": "instead of six and if we were to actually double our write costs in our",
    "start": "970530",
    "end": "975750"
  },
  {
    "text": "actual production system like the slide shows for a system our VAR scale that would be millions of more dollars per",
    "start": "975750",
    "end": "981930"
  },
  {
    "text": "year that I'd be paying to AWS now AWS is happy to have our business but as the",
    "start": "981930",
    "end": "987900"
  },
  {
    "text": "manager of the herd team that would really wreak havoc on my budget and I don't think her finance department would be too happy either",
    "start": "987900",
    "end": "993840"
  },
  {
    "text": "so we need to do better so really the challenge we set for ourselves was to",
    "start": "993840",
    "end": "999600"
  },
  {
    "start": "997000",
    "end": "1178000"
  },
  {
    "text": "minimize our rights we wanted to keep the size of the art frequently record written records really small",
    "start": "999600",
    "end": "1006200"
  },
  {
    "text": "ideally less than a kilobyte less than or equal to a kilobyte the minimal amount that dynamo will charge you for",
    "start": "1006200",
    "end": "1011450"
  },
  {
    "text": "on it right what that means in practice is we wanted to move all of the extra",
    "start": "1011450",
    "end": "1017450"
  },
  {
    "text": "data that didn't update very often out of that main table and only keep our keys and indexed attributes which",
    "start": "1017450",
    "end": "1024260"
  },
  {
    "text": "changed frequently so along those lines one thing we realized is that hey the",
    "start": "1024260",
    "end": "1029870"
  },
  {
    "text": "work item history is immutable events only ever get added so let's see if we",
    "start": "1029870",
    "end": "1035329"
  },
  {
    "text": "can use that fact to our advantage we'll try a variation of the two table idea",
    "start": "1035330",
    "end": "1041120"
  },
  {
    "text": "we'll have that one header record table for small index metadata and one history",
    "start": "1041120",
    "end": "1047270"
  },
  {
    "text": "table in which to log events as they occur now we don't have the transaction",
    "start": "1047270",
    "end": "1052550"
  },
  {
    "text": "support across tables right and so we can't rely on a Dino ndb's query API to",
    "start": "1052550",
    "end": "1057740"
  },
  {
    "text": "let us see what history records exist one might get written here before we",
    "start": "1057740",
    "end": "1062780"
  },
  {
    "text": "have a chance to update The Associated header record so instead of doing that instead of relying",
    "start": "1062780",
    "end": "1069460"
  },
  {
    "text": "on dynamodb to give us the true list of what header records exist let's maintain that list ourselves as a list of",
    "start": "1069460",
    "end": "1077020"
  },
  {
    "text": "pointers within the header record so here we write the header record and as part of it we write a little reference",
    "start": "1077020",
    "end": "1083560"
  },
  {
    "text": "to the key of that history record that we just wrote and now we know it exists and as another history record gets",
    "start": "1083560",
    "end": "1090370"
  },
  {
    "text": "updated but it gets written over time we add one here and then we update the header record and so when the caller",
    "start": "1090370",
    "end": "1096670"
  },
  {
    "text": "comes in to read this they always read that header record first that tells the caller which",
    "start": "1096670",
    "end": "1103390"
  },
  {
    "text": "history records exists and then they're able to read the whole data set and get a consistent view of the work item but",
    "start": "1103390",
    "end": "1110470"
  },
  {
    "text": "let's throw a failure in and see what happens so let's say I write a third history record and then that updates to",
    "start": "1110470",
    "end": "1116470"
  },
  {
    "text": "the header record there fails what happens well so the to the caller they",
    "start": "1116470",
    "end": "1122830"
  },
  {
    "text": "actually just see the same picture they saw before they see that older version of the history record pointing to those",
    "start": "1122830",
    "end": "1127870"
  },
  {
    "text": "two history records and so why they actually have a consistent view of the world still but looking under the covers",
    "start": "1127870",
    "end": "1133900"
  },
  {
    "text": "of the system we do see this one odd thing here we've got an extra history record that nothing's pointing to it's",
    "start": "1133900",
    "end": "1139510"
  },
  {
    "text": "kind of orphaned it's kind of cruft or garbage that's accumulated and so that's a little wasteful actually and so then",
    "start": "1139510",
    "end": "1146470"
  },
  {
    "text": "that is a problem but let's get back to that in a second let's just keep going with the algorithm forward if I write",
    "start": "1146470",
    "end": "1151750"
  },
  {
    "text": "another if I reach I that right and add that third record back again and I then update the header record and it succeeds",
    "start": "1151750",
    "end": "1157990"
  },
  {
    "text": "this time yes it all still works the caller can get a consistent view with",
    "start": "1157990",
    "end": "1163570"
  },
  {
    "text": "these three latest records and you'll notice we wrote except for that cruft",
    "start": "1163570",
    "end": "1168640"
  },
  {
    "text": "we wrote six kilobytes of data total not twelve so we actually achieved our",
    "start": "1168640",
    "end": "1174540"
  },
  {
    "text": "cost-saving goal as long as those failures aren't happening that often and so this introduces the first technique",
    "start": "1174540",
    "end": "1181270"
  },
  {
    "start": "1178000",
    "end": "1376000"
  },
  {
    "text": "we use that maybe you could use in a system you on we we separated out these",
    "start": "1181270",
    "end": "1186670"
  },
  {
    "text": "large immutable payloads from small mutable data in order to reduce our",
    "start": "1186670",
    "end": "1191920"
  },
  {
    "text": "costs all right so we've got that Croft problem though do we have any others we",
    "start": "1191920",
    "end": "1198830"
  },
  {
    "text": "can read all these records in parallel right so latency is a concern for our system but since we have that",
    "start": "1198830",
    "end": "1204260"
  },
  {
    "text": "parallelism it isn't a problem but what we do have is a scalability problem",
    "start": "1204260",
    "end": "1209390"
  },
  {
    "text": "here's why so some of our work at it let's get updated a lot more often than others say hundreds or thousands of",
    "start": "1209390",
    "end": "1216110"
  },
  {
    "text": "times more often and now loading thousands of history records in parallel wouldn't really scale or perform that",
    "start": "1216110",
    "end": "1222559"
  },
  {
    "text": "well the odds of one in a thousand calls failing is pretty high even for a really four 9s highly available service and so",
    "start": "1222559",
    "end": "1231500"
  },
  {
    "text": "we got to solve that somehow so just solve that let's try the following let's",
    "start": "1231500",
    "end": "1237260"
  },
  {
    "text": "limit the number that the maximum amount of parallel calls we'll ever make to do",
    "start": "1237260",
    "end": "1243440"
  },
  {
    "text": "that we'll set a limit on the number of references will hold the limit on the maximum number of history records in",
    "start": "1243440",
    "end": "1249710"
  },
  {
    "text": "this case let's try four so now when that new fifth record comes in what",
    "start": "1249710",
    "end": "1255230"
  },
  {
    "text": "we're gonna do instead is we're gonna take it and we're gonna bundle it up together with all the four existing",
    "start": "1255230",
    "end": "1261140"
  },
  {
    "text": "existing records we're gonna load those four I'm gonna write one big blob of",
    "start": "1261140",
    "end": "1266690"
  },
  {
    "text": "data that's ten kilobytes so now that's an expensive write and you might notice",
    "start": "1266690",
    "end": "1272780"
  },
  {
    "text": "and we are paying extra in that case so in in our real system we already tune that limit so that's that this somewhat",
    "start": "1272780",
    "end": "1278900"
  },
  {
    "text": "inefficient compaction operation only happens really rarely but and remember",
    "start": "1278900",
    "end": "1285890"
  },
  {
    "text": "the key thing here is that we did actually just limit the amount of parallelism and so we did get the",
    "start": "1285890",
    "end": "1291710"
  },
  {
    "text": "scalability we needed with this little bit of extra cost so that actually helps",
    "start": "1291710",
    "end": "1298100"
  },
  {
    "text": "us pretty well except for one other problem what if this problem what if",
    "start": "1298100",
    "end": "1303559"
  },
  {
    "text": "this algorithm keeps repeating and this record size grows bigger and bigger and bigger DynamoDB has limits on the maximum item",
    "start": "1303559",
    "end": "1309500"
  },
  {
    "text": "sizes it can hold right what if this becomes ten megabytes so what we do",
    "start": "1309500",
    "end": "1314659"
  },
  {
    "text": "there instead we actually just did something pretty simple if it's bigger than dynamodb is limit we just put it in",
    "start": "1314659",
    "end": "1321380"
  },
  {
    "text": "s/3 s/3 is another key value storage the storage service that eight of us",
    "start": "1321380",
    "end": "1327020"
  },
  {
    "text": "provides that you're probably for it's really good for storing large binary payloads so we just did that and",
    "start": "1327020",
    "end": "1334039"
  },
  {
    "text": "we kept a little pointer bit inside of the header record that said hey this one is an s3 so that when we go handle when",
    "start": "1334039",
    "end": "1340279"
  },
  {
    "text": "we go to load it we know where to look okay we still got this cruft though that",
    "start": "1340279",
    "end": "1346490"
  },
  {
    "text": "have been conveniently ignoring isn't that bad yes and I'm actually but I'm actually gonna cheat a little bit here",
    "start": "1346490",
    "end": "1352759"
  },
  {
    "text": "so when workflows finish in our system they're archived out and at that time we",
    "start": "1352759",
    "end": "1358940"
  },
  {
    "text": "have a chance to list or to query from DynamoDB and find all the stuff that was",
    "start": "1358940",
    "end": "1365029"
  },
  {
    "text": "there that might have gotten orphans that doesn't have a strongly referenced pointer associated with it and so we do",
    "start": "1365029",
    "end": "1371629"
  },
  {
    "text": "have a way to make sure that most of that craft gets deleted in the end and so this introduces the second key",
    "start": "1371629",
    "end": "1378590"
  },
  {
    "text": "technique that we used we're able to work around not having transactions by being a little bit efficient rarely",
    "start": "1378590",
    "end": "1385700"
  },
  {
    "text": "leaving that cruft behind but only for a small percentage of calls and as long as we had a way to monitor at to make sure",
    "start": "1385700",
    "end": "1391940"
  },
  {
    "text": "we did clean it up afterwards and I found this technique a little bit surprising at first right because as",
    "start": "1391940",
    "end": "1398090"
  },
  {
    "text": "engineers in our systems oftentimes we want things to be like perfect and it's for some definition of perfect right but",
    "start": "1398090",
    "end": "1405529"
  },
  {
    "text": "this was actually turned out to be a really practical good trade-off for us to make and so this is what our",
    "start": "1405529",
    "end": "1413779"
  },
  {
    "start": "1411000",
    "end": "1546000"
  },
  {
    "text": "architecture looks like now we've just got this work item storage service so far pointing to dynamodb we've got a",
    "start": "1413779",
    "end": "1419929"
  },
  {
    "text": "couple of tables in there and that covers how we did the history store and so now I'll turn it over to Pioche who",
    "start": "1419929",
    "end": "1427129"
  },
  {
    "text": "will get to talk about the hard stuff thanks Mike",
    "start": "1427129",
    "end": "1432970"
  },
  {
    "text": "good morning everyone once again my name is BIOS Kalani I am a software development engineer at Amazon and I",
    "start": "1432970",
    "end": "1439909"
  },
  {
    "text": "have got lots of things to cover today so let's get back to our slides so we just saw how we used dynamodb and s3 to store our work item",
    "start": "1439909",
    "end": "1447379"
  },
  {
    "text": "history now let's take a look at how we build a scheduled queue on top of dynamodb",
    "start": "1447379",
    "end": "1452419"
  },
  {
    "text": "so let's get familiar with the requirements and what made this problem really challenging for us so we process",
    "start": "1452419",
    "end": "1458929"
  },
  {
    "text": "billions of work items every day and at any given point of time we have hundreds of millions of them active and",
    "start": "1458929",
    "end": "1464850"
  },
  {
    "text": "we have a very large fleet of hosts we call it engine which is constantly pulling our work items tourist service",
    "start": "1464850",
    "end": "1471390"
  },
  {
    "text": "asking it a very simple question find me the next work item to process for a",
    "start": "1471390",
    "end": "1476610"
  },
  {
    "text": "given work flow and we have tens of thousands of threads who are dedicated for a given work flow who are all asking",
    "start": "1476610",
    "end": "1483990"
  },
  {
    "text": "this question in parallel at the time of our launch our biggest work flow had",
    "start": "1483990",
    "end": "1489600"
  },
  {
    "text": "about 60 million active items and so the challenging thing was to be able to find that one item which is ready to get",
    "start": "1489600",
    "end": "1496470"
  },
  {
    "text": "processed and we had to find that item within like couple of seconds of it scheduled time and that's because we",
    "start": "1496470",
    "end": "1503700"
  },
  {
    "text": "have some latency sensitive use cases which execute on our platform for example when you place a prime now order",
    "start": "1503700",
    "end": "1510420"
  },
  {
    "text": "on amazon.com we only have minutes from the time you place the order to the time",
    "start": "1510420",
    "end": "1516090"
  },
  {
    "text": "it has to be shipped out from our warehouse and multiple systems work together to make that happen",
    "start": "1516090",
    "end": "1521610"
  },
  {
    "text": "and so you want to make sure that all these systems the delay introduced by",
    "start": "1521610",
    "end": "1526620"
  },
  {
    "text": "these systems is as small as possible so that all of you can get your stuff on time and finally we execute tens of",
    "start": "1526620",
    "end": "1534660"
  },
  {
    "text": "thousands of work items every second so it's not just about finding that one item it's about finding tens of",
    "start": "1534660",
    "end": "1540750"
  },
  {
    "text": "thousands of those every second in parallel without stepping over each other all right so before we look into",
    "start": "1540750",
    "end": "1548460"
  },
  {
    "start": "1546000",
    "end": "1725000"
  },
  {
    "text": "the solution let's recap some of the key dynamodb concepts which I am going to use in this talk and get familiar with",
    "start": "1548460",
    "end": "1554580"
  },
  {
    "text": "the imagery which I am going to use to represent them so you're our dynamodb partitions these are the physical hosts",
    "start": "1554580",
    "end": "1561660"
  },
  {
    "text": "where they store the data which we provide they also call it a storage node each storage node has replicas and",
    "start": "1561660",
    "end": "1568620"
  },
  {
    "text": "different availability zones for redundancy for today's talk I am NOT going to show the replicas for simplicity this is the dynamodb load",
    "start": "1568620",
    "end": "1575910"
  },
  {
    "text": "balancer using which clients read and write data let's quickly run through some examples here so let's say if you",
    "start": "1575910",
    "end": "1582210"
  },
  {
    "text": "need to write a record that partition key a and sought key to Nana is going to hash or partition key and it's going to",
    "start": "1582210",
    "end": "1588930"
  },
  {
    "text": "map it to one of its storage node in the backend and since the only hash the partition key",
    "start": "1588930",
    "end": "1594810"
  },
  {
    "text": "every record which has the same partition key will always get mapped to the same storage node in the backend and",
    "start": "1594810",
    "end": "1600330"
  },
  {
    "text": "they'll all be stored in the order of its sort T so interests talk I'm going",
    "start": "1600330",
    "end": "1605670"
  },
  {
    "text": "to represent a particular partition keys space on a given storage node using this view vertical bar and every record in",
    "start": "1605670",
    "end": "1613380"
  },
  {
    "text": "this blue vertical bar will have the same partition key and they'll all be ordered by its sort key so for example",
    "start": "1613380",
    "end": "1619950"
  },
  {
    "text": "for example if you write another recorded partition key a and sought key one it's going to go right above it",
    "start": "1619950",
    "end": "1626550"
  },
  {
    "text": "another one if you write with sort key three it's going to go below it let's",
    "start": "1626550",
    "end": "1632130"
  },
  {
    "text": "write another one with partition key B this time that may happen to get mapped to a different storage node as we have",
    "start": "1632130",
    "end": "1637980"
  },
  {
    "text": "changed our partition key and let's say another one with partition key C well it can get mapped to a storage node which",
    "start": "1637980",
    "end": "1644610"
  },
  {
    "text": "already has records from a different partition key all right so that that understanding let's start building our",
    "start": "1644610",
    "end": "1651150"
  },
  {
    "text": "solution so so far we have introduced this work item header table the",
    "start": "1651150",
    "end": "1656430"
  },
  {
    "text": "partition key on this table is the identifier of the work item now for scheduled q functionality the query",
    "start": "1656430",
    "end": "1663390"
  },
  {
    "text": "which we need to support is to find the next item which is ready to get processed and an item is ready to get",
    "start": "1663390",
    "end": "1669840"
  },
  {
    "text": "processed when it's scheduled time is less than or equal to current time and so if you need to make that query on",
    "start": "1669840",
    "end": "1676740"
  },
  {
    "text": "this main header table it's going to be extremely inefficient as there are no indexes on the attribute workflow name",
    "start": "1676740",
    "end": "1683340"
  },
  {
    "text": "or on the attribute schedule at a time and so to be able to make this query efficient we are going to leverage",
    "start": "1683340",
    "end": "1689640"
  },
  {
    "text": "dynamodb is global secondary indexing support also commonly known as GSI so",
    "start": "1689640",
    "end": "1695760"
  },
  {
    "text": "we'll create a new GSI to name a timer we'll set our partition key on the attribute to a flow name and set the",
    "start": "1695760",
    "end": "1702630"
  },
  {
    "text": "sort key on the attribute schedule to time now we can use this index and efficiently query and find the next work",
    "start": "1702630",
    "end": "1710490"
  },
  {
    "text": "item for a given workflow which has the earliest scheduled time and then we can",
    "start": "1710490",
    "end": "1717540"
  },
  {
    "text": "easily check if it is ready to get processed or not so does that solve our problem here well",
    "start": "1717540",
    "end": "1724200"
  },
  {
    "text": "not really if you have one single partition key for a given workflow all work items which we",
    "start": "1724200",
    "end": "1732330"
  },
  {
    "text": "are going to process for this particular workflow they're all going to get funneled into this one single storage",
    "start": "1732330",
    "end": "1738180"
  },
  {
    "text": "node and eventually this storage node is going to end up throttling that's",
    "start": "1738180",
    "end": "1743610"
  },
  {
    "text": "because a single storage node can only support a certain amount of throughput",
    "start": "1743610",
    "end": "1748910"
  },
  {
    "text": "so what can we do to make it scale well the real problem is that we have one",
    "start": "1748910",
    "end": "1754770"
  },
  {
    "text": "single partition key for a given workflow so what if we shot this into n",
    "start": "1754770",
    "end": "1759900"
  },
  {
    "text": "different partition keys and one way to do that is simply by adding a suffix now",
    "start": "1759900",
    "end": "1765030"
  },
  {
    "text": "for every work item which we process for this particular workflow we can map it to one of the N partition key in the",
    "start": "1765030",
    "end": "1772050"
  },
  {
    "text": "backend behind the scenes so basically all work items which are getting processed for this particular workflow",
    "start": "1772050",
    "end": "1777450"
  },
  {
    "text": "can now be evenly distributed across these N partition keys will that make",
    "start": "1777450",
    "end": "1783300"
  },
  {
    "text": "our solution scalable well it really depends on the value of n in comparison",
    "start": "1783300",
    "end": "1789180"
  },
  {
    "text": "to a number of storage nodes which you have in DynamoDB let's quickly run through some examples here to understand",
    "start": "1789180",
    "end": "1794880"
  },
  {
    "start": "1793000",
    "end": "2006000"
  },
  {
    "text": "that let's say we have five partition keys for a given workflow and we have",
    "start": "1794880",
    "end": "1799890"
  },
  {
    "text": "five storage nodes in the backend well when dynamodb is going to map these partition keys to their storage nodes",
    "start": "1799890",
    "end": "1805650"
  },
  {
    "text": "there's a very good chance that one of the storage node may end up with two or even more partition key is mapped to it",
    "start": "1805650",
    "end": "1811880"
  },
  {
    "text": "well so in an ideal case we wanted that each storage node should only receive",
    "start": "1811880",
    "end": "1817260"
  },
  {
    "text": "20% of the traffic for this particular workflow as there are only five storage nodes but in this case this particular",
    "start": "1817260",
    "end": "1824460"
  },
  {
    "text": "storage node will receive 40% of the traffic which is quite a lot higher and it may end up throttling even though we",
    "start": "1824460",
    "end": "1832230"
  },
  {
    "text": "have another storage node which is not receiving any traffic at all for this workflow so what if you have hundreds of",
    "start": "1832230",
    "end": "1839730"
  },
  {
    "text": "partition keys and still five storage nodes well in that case the distribution will still not be hundred percent even",
    "start": "1839730",
    "end": "1846510"
  },
  {
    "text": "but it will be lot more uniform than before the storage node which ends up",
    "start": "1846510",
    "end": "1851550"
  },
  {
    "text": "receiving maximum number of partition keys may end up getting somewhere from twenty to twenty five point seven",
    "start": "1851550",
    "end": "1857130"
  },
  {
    "text": "percent of the traffic which is still a lot closer to twenty percent which we want to achieve",
    "start": "1857130",
    "end": "1862940"
  },
  {
    "text": "so as we increase the number of partition keys our distribution is going to become better and better and better",
    "start": "1862940",
    "end": "1869930"
  },
  {
    "text": "distribution means better scalability because now we can use the entire",
    "start": "1869930",
    "end": "1875070"
  },
  {
    "text": "capacity which is allocated to us and so that's our technique number three",
    "start": "1875070",
    "end": "1881490"
  },
  {
    "text": "avoid hot dynamodb partitions by manufacturing additional keys and get",
    "start": "1881490",
    "end": "1886500"
  },
  {
    "text": "better scalability all right so more keys means better distribution so does",
    "start": "1886500",
    "end": "1894210"
  },
  {
    "text": "that mean we can have 100,000 keys for a given workflow or even more well if you",
    "start": "1894210",
    "end": "1901050"
  },
  {
    "text": "have 100,000 keys for a workflow we need to query each one of them independently",
    "start": "1901050",
    "end": "1906540"
  },
  {
    "text": "to be able to find that next item which is ready to get processed and that's a",
    "start": "1906540",
    "end": "1912150"
  },
  {
    "text": "lot of work to do and it's going to be impossible to do all of that within the couple of seconds of SLA we need to",
    "start": "1912150",
    "end": "1918600"
  },
  {
    "text": "maintain so yes as we increase the number of partition keys our",
    "start": "1918600",
    "end": "1924120"
  },
  {
    "text": "distribution becomes better and better but discovering that next item is going",
    "start": "1924120",
    "end": "1929880"
  },
  {
    "text": "to become harder and harder and so clearly we needed to strike a balance",
    "start": "1929880",
    "end": "1935070"
  },
  {
    "text": "here so we decided to keep the number of partition keys for individual workflows",
    "start": "1935070",
    "end": "1940860"
  },
  {
    "text": "to be in thousands because given the number of storage nodes we needed at the",
    "start": "1940860",
    "end": "1945960"
  },
  {
    "text": "time of our launch having thousands of partition keys would have been showed that a load is roughly evenly distributed across each of those storage",
    "start": "1945960",
    "end": "1953340"
  },
  {
    "text": "nodes and we kept this value configurable in our system so that when",
    "start": "1953340",
    "end": "1959070"
  },
  {
    "text": "we scale up in future and add more storage nodes our distribution will still be roughly evenly distributed if",
    "start": "1959070",
    "end": "1966300"
  },
  {
    "text": "we can in proportionate to increase those partition keys all right so with",
    "start": "1966300",
    "end": "1972570"
  },
  {
    "text": "thousands of partition keys how do we still find that next item which is ready to get processed well we'll have to",
    "start": "1972570",
    "end": "1979350"
  },
  {
    "text": "query each one of them independently and that's still a lot of work to do moreover we need to be able to read",
    "start": "1979350",
    "end": "1987090"
  },
  {
    "text": "thousands of items in order to find that one item and we need to do that over and",
    "start": "1987090",
    "end": "1992730"
  },
  {
    "text": "over again on every poll request and that's to be extremely inefficient and costly",
    "start": "1992730",
    "end": "1999020"
  },
  {
    "text": "so there's a very common technique used in computer science to be able to deal with problems like this it's called cash",
    "start": "1999020",
    "end": "2007130"
  },
  {
    "start": "2006000",
    "end": "2453000"
  },
  {
    "text": "prefetching what it means is if you know that we are going to need some data in",
    "start": "2007130",
    "end": "2012350"
  },
  {
    "text": "future proactively prefetch that data from a memory which is slower to access",
    "start": "2012350",
    "end": "2018020"
  },
  {
    "text": "and put it in a memory which is faster to access well in our case our data is",
    "start": "2018020",
    "end": "2023120"
  },
  {
    "text": "in DynamoDB so what is faster to access than dynamodb run so what if we",
    "start": "2023120",
    "end": "2031280"
  },
  {
    "text": "proactively prefetch the topmost items from each of these thousands of partition keys and put it in the memory",
    "start": "2031280",
    "end": "2038480"
  },
  {
    "text": "of a host let's give that a try so this is the same image as before just a bit",
    "start": "2038480",
    "end": "2045110"
  },
  {
    "text": "zoomed in at the bottom was layer we have dynamo DB storage nodes each storage node has data for the view GSI",
    "start": "2045110",
    "end": "2052510"
  },
  {
    "text": "each storage node has multiple partition keys mapped to it each partition key has",
    "start": "2052510",
    "end": "2058760"
  },
  {
    "text": "multiple work items mapped to it and they are all so ordered by it scheduled",
    "start": "2058760",
    "end": "2064070"
  },
  {
    "text": "time so basically the item right at the top has the earliest scheduled time for thus that particular partition key now",
    "start": "2064070",
    "end": "2072290"
  },
  {
    "text": "let's put an host in front of it and we'll make this host proactively prefetch the topmost items from each of",
    "start": "2072290",
    "end": "2079669"
  },
  {
    "text": "the partition thousand partition keys and it's going to put it in its in-memory indexed cache data structure",
    "start": "2079670",
    "end": "2086899"
  },
  {
    "text": "which has support for finding the next item which has the earliest scheduled time now all we need to do whenever we",
    "start": "2086900",
    "end": "2094070"
  },
  {
    "text": "receive a poll request is to route that request to this host and it can answer the rest it can find",
    "start": "2094070",
    "end": "2100340"
  },
  {
    "text": "the next item within few milliseconds well that's great except one host will",
    "start": "2100340",
    "end": "2107480"
  },
  {
    "text": "not be able to scale for the poll throughput which we need to support for our largest workflow so what do we do",
    "start": "2107480",
    "end": "2114680"
  },
  {
    "text": "when one host doesn't scale we add more horse now we will be able to route our",
    "start": "2114680",
    "end": "2120350"
  },
  {
    "text": "poll throughput to any one of these hosts and so we will be able to scale for that but we still have two main",
    "start": "2120350",
    "end": "2126500"
  },
  {
    "text": "problems one each host needs to query for all the",
    "start": "2126500",
    "end": "2132560"
  },
  {
    "text": "thousands of partition keys and that's a lot of work to do specially in couple of seconds and so this solution doesn't",
    "start": "2132560",
    "end": "2140300"
  },
  {
    "text": "really scale as when we increase the number of partition keys in future this",
    "start": "2140300",
    "end": "2146870"
  },
  {
    "text": "won't be able to scale for that second records from each of these partition",
    "start": "2146870",
    "end": "2151940"
  },
  {
    "text": "keys unloaded into the memory of every host so basically every host is going to",
    "start": "2151940",
    "end": "2157610"
  },
  {
    "text": "return the same set of items on a poll request which will lead to contention",
    "start": "2157610",
    "end": "2162830"
  },
  {
    "text": "and it will kill our system's throughput so came up with a solution which solve",
    "start": "2162830",
    "end": "2168440"
  },
  {
    "text": "both of these problems what we did was we grouped certain partition keys together and leader elected a single",
    "start": "2168440",
    "end": "2176510"
  },
  {
    "text": "host which has exclusive access to those partition keys so basically in this",
    "start": "2176510",
    "end": "2182630"
  },
  {
    "text": "example partition keys order processing 1 2 & 3 we group them together later",
    "start": "2182630",
    "end": "2188990"
  },
  {
    "text": "elected host 1 to have exclusive access to them and so basically no other host except host 1 can own those similarly we",
    "start": "2188990",
    "end": "2196460"
  },
  {
    "text": "grouped another set of partition keys and leader elected goes to for that and continued that process until all",
    "start": "2196460",
    "end": "2202790"
  },
  {
    "text": "partition keys were uniquely assigned to an individual host now this solves both",
    "start": "2202790",
    "end": "2208490"
  },
  {
    "text": "of our previous problems each host only has to own a fixed set of partition keys",
    "start": "2208490",
    "end": "2214280"
  },
  {
    "text": "and it only needs to query for those set so it makes it scalable now because as we add more partition keys we can simply",
    "start": "2214280",
    "end": "2221330"
  },
  {
    "text": "add more hosts and make them own the new partition keys second records from each",
    "start": "2221330",
    "end": "2227330"
  },
  {
    "text": "of these partition keys are now loaded into the memory of a single host and so",
    "start": "2227330",
    "end": "2232790"
  },
  {
    "text": "each horse is going to return a unique set of records on every poll request thus avoiding any sort of contention",
    "start": "2232790",
    "end": "2239960"
  },
  {
    "text": "whatsoever all right there's one more last thing we need to take care of as",
    "start": "2239960",
    "end": "2245440"
  },
  {
    "text": "these host handout records as part of poll response we want to update the main",
    "start": "2245440",
    "end": "2254150"
  },
  {
    "text": "work item header table and set the scheduled time of these work items to current time plus X minutes and there",
    "start": "2254150",
    "end": "2261800"
  },
  {
    "text": "are two reasons why we want to do that one when we hand out records as part of",
    "start": "2261800",
    "end": "2267950"
  },
  {
    "text": "poor the response we want these items to move below in the index so that when we",
    "start": "2267950",
    "end": "2273470"
  },
  {
    "text": "query next time we see new set of items thus avoiding any sort of starvation",
    "start": "2273470",
    "end": "2281140"
  },
  {
    "text": "second let's say in case of a failure let's say the engine host we which",
    "start": "2281140",
    "end": "2287060"
  },
  {
    "text": "picked up this particular record crashed we don't want to forget about this item",
    "start": "2287060",
    "end": "2292510"
  },
  {
    "text": "remember we don't want to leave behind any orders we want this item to surface are back again in some time so that we",
    "start": "2292510",
    "end": "2300290"
  },
  {
    "text": "can retry processing it by handing it over to a different engine host and that is the reason why we don't delete an",
    "start": "2300290",
    "end": "2307730"
  },
  {
    "text": "item from the index we simply push them down now in a happy case before our X",
    "start": "2307730",
    "end": "2313250"
  },
  {
    "text": "minutes expire our engine host will be able to successfully process an item and it will update it will provide a new",
    "start": "2313250",
    "end": "2319700"
  },
  {
    "text": "scheduled time using which will update it in the GSI alright let's put it all",
    "start": "2319700",
    "end": "2325490"
  },
  {
    "text": "together at the bottommost layer we have the dynamo DB storage nodes each storage node has multiple application partition",
    "start": "2325490",
    "end": "2332210"
  },
  {
    "text": "keys mapped to them at the application layer we have this bunch of ec2 hosts and given that ec2 hosts are really",
    "start": "2332210",
    "end": "2339560"
  },
  {
    "text": "powerful these days at the time of our launch we needed about 10 hosts to support the throughput of our largest",
    "start": "2339560",
    "end": "2345500"
  },
  {
    "text": "workflow above it we added a timer router which had bunch of stateless ec2",
    "start": "2345500",
    "end": "2351830"
  },
  {
    "text": "hosts behind a load balancer and whenever it receives a pull request for a given workflow it simply routes that",
    "start": "2351830",
    "end": "2359120"
  },
  {
    "text": "request to one of the hosts randomly which owns the partition key for that particular workflow and given that we",
    "start": "2359120",
    "end": "2367880"
  },
  {
    "text": "had tens of thousands of threads who are constantly polling for a given workflow and only like 10 hosts which has worked",
    "start": "2367880",
    "end": "2374510"
  },
  {
    "text": "for a given workflow the simple strategy of randomly routing the requests worked really great we were able to hit every",
    "start": "2374510",
    "end": "2381500"
  },
  {
    "text": "host pretty frequently looking for work and if you can see now our solution is",
    "start": "2381500",
    "end": "2387470"
  },
  {
    "text": "scalable at every place horizontally scalable at every layer at the bottom most layer we have dynamo DB storage",
    "start": "2387470",
    "end": "2394460"
  },
  {
    "text": "nodes and they can scale by simply adding most notes then we can proportionately increase the number of partition keys",
    "start": "2394460",
    "end": "2401350"
  },
  {
    "text": "then we can proportionately also increase the number of application hosts and finally we can also proportionately",
    "start": "2401350",
    "end": "2407780"
  },
  {
    "text": "increase the number of polling threads so as to maintain the same SLA for finding the work so that's a solution",
    "start": "2407780",
    "end": "2416330"
  },
  {
    "text": "for the schedule queue functionality but if you have noticed as part of this coming up with the solution we have",
    "start": "2416330",
    "end": "2423980"
  },
  {
    "text": "introduced this concept of leader election and leader election is not easy to do although it's a well-known",
    "start": "2423980",
    "end": "2431180"
  },
  {
    "text": "computer science problem and so I'm not going to explain how we solve this problem for us because of the time",
    "start": "2431180",
    "end": "2437840"
  },
  {
    "text": "constraint in short we created an application called partition a signer which did leader election for us using",
    "start": "2437840",
    "end": "2445790"
  },
  {
    "text": "couple of tables on DynamoDB if you would like to learn more about this please feel free to reach out to me",
    "start": "2445790",
    "end": "2450950"
  },
  {
    "text": "after this presentation all right so putting it all together is technique number four today move heart",
    "start": "2450950",
    "end": "2457520"
  },
  {
    "text": "problems into memory where everything is easy well kind of we still have to do",
    "start": "2457520",
    "end": "2462890"
  },
  {
    "text": "leader election and that's not easy but consolidating tens of millions of Records into the memory of handful of",
    "start": "2462890",
    "end": "2469670"
  },
  {
    "text": "hosts allowed us to do some kind of complicated query across these tens of",
    "start": "2469670",
    "end": "2475400"
  },
  {
    "text": "millions of items well in this case specifically it allowed us to find that next item which is ready to get",
    "start": "2475400",
    "end": "2482030"
  },
  {
    "text": "processed within few milliseconds and so that sums up our technique number four",
    "start": "2482030",
    "end": "2488440"
  },
  {
    "start": "2489000",
    "end": "2760000"
  },
  {
    "text": "all right moving on there's one problem I have conveniently ignored so far GSI",
    "start": "2489220",
    "end": "2495380"
  },
  {
    "text": "propagation delay so how does it really affect our current design let's take a",
    "start": "2495380",
    "end": "2501440"
  },
  {
    "text": "look this is our architecture so far let me walk you through this quickly before",
    "start": "2501440",
    "end": "2507140"
  },
  {
    "text": "I explain the issue this is the work item storage service we have seen that before it writes to the main dynamodb",
    "start": "2507140",
    "end": "2513530"
  },
  {
    "text": "work Adam had a table these are the main tables on dynamodb work Adam had a table and when we write to that it's a",
    "start": "2513530",
    "end": "2519560"
  },
  {
    "text": "DynamoDB replicates our write to dine primer GSI on the bottom left we have timer hosts which participate in leader",
    "start": "2519560",
    "end": "2525920"
  },
  {
    "text": "election they know each of these hosts to know what partition key is there using our leader election system and",
    "start": "2525920",
    "end": "2533280"
  },
  {
    "text": "once they know that they periodically query the primer GSI and treat the topmost records from each of those",
    "start": "2533280",
    "end": "2539640"
  },
  {
    "text": "partition keys and load it in its mem in-memory cache and then finally this is the timer router again host here know",
    "start": "2539640",
    "end": "2546359"
  },
  {
    "text": "which timer host owns what partition keys using a leader election system and once it knows that it uses that",
    "start": "2546359",
    "end": "2552900"
  },
  {
    "text": "information to appropriately route request among these set of timer hosts",
    "start": "2552900",
    "end": "2558050"
  },
  {
    "text": "so let's take a look at our GSI propagation delay issue so when a new insert work item request comes in for a",
    "start": "2558050",
    "end": "2565589"
  },
  {
    "text": "work item which is ready to get processed immediately the first thing we do is we write that record to DynamoDB s",
    "start": "2565589",
    "end": "2571890"
  },
  {
    "text": "main work atom header table let's say that happened at time T one at some",
    "start": "2571890",
    "end": "2578609"
  },
  {
    "text": "point later dynamodb is going to replicate this to time at GSI let's say that happened at time T two and finally",
    "start": "2578609",
    "end": "2585119"
  },
  {
    "text": "at some point later one of the timer hosts will query this record and put it in its own memory cache let's say that",
    "start": "2585119",
    "end": "2590730"
  },
  {
    "text": "happened at time T three now what we really want is that the time between t1 and t3 to be under couple of seconds",
    "start": "2590730",
    "end": "2599059"
  },
  {
    "text": "because that's when the item is available for processing and in a happy case that's achievable because dynamodb",
    "start": "2599059",
    "end": "2606000"
  },
  {
    "text": "is replication to the GSI happens within sub seconds and we can make our timer",
    "start": "2606000",
    "end": "2611490"
  },
  {
    "text": "host query like really aggressively like once every second for every partition",
    "start": "2611490",
    "end": "2616559"
  },
  {
    "text": "key but dynamodb is documentation also cautions us saying that this delay can",
    "start": "2616559",
    "end": "2623520"
  },
  {
    "text": "be longer in case of an unlikely failure scenario and so as I mentioned before if",
    "start": "2623520",
    "end": "2630180"
  },
  {
    "text": "the delay is going to be more than few seconds it can negatively affect the latency sensitive workflows which",
    "start": "2630180",
    "end": "2636150"
  },
  {
    "text": "execute on our platform and so that wasn't acceptable to us so here's what",
    "start": "2636150",
    "end": "2642540"
  },
  {
    "text": "we did to solve this problem like before when a new insert work item request comes in we first write it into dynamo",
    "start": "2642540",
    "end": "2650220"
  },
  {
    "text": "dB now once this record has been written successfully there's one thing we know for sure that at some point in future",
    "start": "2650220",
    "end": "2657799"
  },
  {
    "text": "this record is going to get propagated to one of the timer hosts",
    "start": "2657799",
    "end": "2663430"
  },
  {
    "text": "so instead of waiting for all of that to happen we make it happen instantly by",
    "start": "2663430",
    "end": "2668980"
  },
  {
    "text": "simply forwarding that request to timer router which then forwards it to the",
    "start": "2668980",
    "end": "2674140"
  },
  {
    "text": "appropriate timer host and that host takes this record and Prime's up in",
    "start": "2674140",
    "end": "2679510"
  },
  {
    "text": "memory cache instantly so within few milliseconds now we have this record",
    "start": "2679510",
    "end": "2685180"
  },
  {
    "text": "available for processing yes it involves two Network hops and",
    "start": "2685180",
    "end": "2690760"
  },
  {
    "text": "that can fail transiently sometimes due to electrons in network failures but",
    "start": "2690760",
    "end": "2696369"
  },
  {
    "text": "with enough retries we get about 99.999 percent success rate for this call and",
    "start": "2696369",
    "end": "2701890"
  },
  {
    "text": "that's good enough for our use cases and the background replication and querying",
    "start": "2701890",
    "end": "2707020"
  },
  {
    "text": "is still happening",
    "start": "2707020",
    "end": "2709740"
  },
  {
    "text": "background querying is still happening and that helps us catch any record which actually failed to get propagated due to",
    "start": "2716609",
    "end": "2722920"
  },
  {
    "text": "transient Network failures it also helps a new host with just God leader elected",
    "start": "2722920",
    "end": "2728079"
  },
  {
    "text": "to be able to prime its cache by reading all the record from DynamoDB so this",
    "start": "2728079",
    "end": "2735130"
  },
  {
    "text": "background query is our mechanism to guarantee that every record which we wrote to dynamodb successfully will be",
    "start": "2735130",
    "end": "2742329"
  },
  {
    "text": "eventually available for processing and this best effort priming of cache technique ensures that 99.999% of those",
    "start": "2742329",
    "end": "2750730"
  },
  {
    "text": "records are actually available instantly for processing and so that's our technique number five today and this",
    "start": "2750730",
    "end": "2757869"
  },
  {
    "text": "seems like it's not working all right prime caches to minimize eventual consistency delays for the GSIS",
    "start": "2757869",
    "end": "2766589"
  },
  {
    "start": "2760000",
    "end": "2782000"
  },
  {
    "text": "here is architecture so far we have the new components as timer router timer",
    "start": "2766589",
    "end": "2771849"
  },
  {
    "text": "host and the timer GSI and right at the bottom we have partition a signer which",
    "start": "2771849",
    "end": "2777970"
  },
  {
    "text": "does leader election for us and that's how we built a scalable distributed",
    "start": "2777970",
    "end": "2784980"
  },
  {
    "start": "2782000",
    "end": "2808000"
  },
  {
    "text": "scheduled queue on top of dynamodb all right a lot of technical content and",
    "start": "2784980",
    "end": "2791260"
  },
  {
    "text": "there's still one more function I'd to cover to be honest FF I was sitting right there I will be exhausted by",
    "start": "2791260",
    "end": "2796730"
  },
  {
    "text": "No so I promise no more new techniques I'm going to show how we solved this",
    "start": "2796730",
    "end": "2802310"
  },
  {
    "text": "last key piece of functionality by using the techniques which we have already shown so ability to group count and list",
    "start": "2802310",
    "end": "2811090"
  },
  {
    "start": "2808000",
    "end": "2896000"
  },
  {
    "text": "let's recap the requirements for this so for every work item which executes on",
    "start": "2811090",
    "end": "2817910"
  },
  {
    "text": "our platform we show a view like this basically it shows the total number of",
    "start": "2817910",
    "end": "2823610"
  },
  {
    "text": "work items which are executing for that particular workflow broken down by the step in which it is in and this is",
    "start": "2823610",
    "end": "2831170"
  },
  {
    "text": "really useful for our clients for debugging and monitoring their workflows and so again the challenging thing here",
    "start": "2831170",
    "end": "2837890"
  },
  {
    "text": "was to be able to generate this view we had to aggregate across hundreds of millions of items and so this problem",
    "start": "2837890",
    "end": "2845450"
  },
  {
    "text": "started to sound very similar to a timer problem we need to loop through millions of millions of items and do some kind of",
    "start": "2845450",
    "end": "2852560"
  },
  {
    "text": "complicated query across all of them so we thought okay let's try to apply the same set of solution and techniques",
    "start": "2852560",
    "end": "2860150"
  },
  {
    "text": "which we applied to a timer problem and see if we can solve this problem as well",
    "start": "2860150",
    "end": "2865300"
  },
  {
    "text": "so like before we first created a GSI called it view and we set our partition",
    "start": "2865300",
    "end": "2872210"
  },
  {
    "text": "key on the attribute workflow name then the first technique which we applied to",
    "start": "2872210",
    "end": "2878180"
  },
  {
    "text": "a timer solution was to avoid hot DynamoDB partitions by manufacturing additional keys so he went back and",
    "start": "2878180",
    "end": "2885520"
  },
  {
    "text": "added a suffix to our partition key and now we are will be able to generate multiple partition keys for our",
    "start": "2885520",
    "end": "2891740"
  },
  {
    "text": "workflows and that will make our solution scalable on dynamodb then the",
    "start": "2891740",
    "end": "2896750"
  },
  {
    "start": "2896000",
    "end": "3041000"
  },
  {
    "text": "next technique which we applied to a timer solution was to move hard programs into memory and so this is the same",
    "start": "2896750",
    "end": "2903680"
  },
  {
    "text": "image as before we have the storage nodes which has this time this storage nodes have data for the view GSI and",
    "start": "2903680",
    "end": "2910510"
  },
  {
    "text": "similarly like before we have application host each one of them owns exclusive set of partition keys and each",
    "start": "2910510",
    "end": "2918380"
  },
  {
    "text": "host in this case queries for all the records which exists in the partition",
    "start": "2918380",
    "end": "2923720"
  },
  {
    "text": "keys which that host owns in one says do that all of these host put those data in",
    "start": "2923720",
    "end": "2929720"
  },
  {
    "text": "it's in indexed data structure and that data structure has support for group count",
    "start": "2929720",
    "end": "2935120"
  },
  {
    "text": "and list and now similar to a timer solution we add a router in front and",
    "start": "2935120",
    "end": "2942100"
  },
  {
    "text": "whenever it receives a request for aggregating across for a given workflow it calls out to every host in parallel",
    "start": "2942100",
    "end": "2949820"
  },
  {
    "text": "gets the locally aggregated results does a global aggregation locally and then",
    "start": "2949820",
    "end": "2955220"
  },
  {
    "text": "returns the response and that's how we supported the ability to group and count",
    "start": "2955220",
    "end": "2960320"
  },
  {
    "text": "and list works pretty much the same way except that the call is paginated because of course we can't return",
    "start": "2960320",
    "end": "2966620"
  },
  {
    "text": "hundreds or millions of items as part of a single API call ok so now since this",
    "start": "2966620",
    "end": "2972800"
  },
  {
    "text": "host has to read all the records from each of the partition keys it owns it",
    "start": "2972800",
    "end": "2978470"
  },
  {
    "text": "takes us about a couple of minutes to be able to generate the view we need and that's fine for our use cases for two",
    "start": "2978470",
    "end": "2985850"
  },
  {
    "text": "reasons one the use case for this is for debugging and monitoring and so a delay",
    "start": "2985850",
    "end": "2991880"
  },
  {
    "text": "of two minutes is in the end of the world and second the the main reason is that we use the same technique here",
    "start": "2991880",
    "end": "2999590"
  },
  {
    "text": "which we use for a timer solution which was to prime caches to minimize eventual consistency delays and so basically that",
    "start": "2999590",
    "end": "3007150"
  },
  {
    "text": "delay of two minutes occurred only initially when a new host got leader elected and it had to read all the data",
    "start": "3007150",
    "end": "3014470"
  },
  {
    "text": "from dynamodb once it did that the host was receiving almost all updates live",
    "start": "3014470",
    "end": "3020950"
  },
  {
    "text": "updates which we were making on dynamodb instantly well except for the ones which failed you to transient network failures",
    "start": "3020950",
    "end": "3027520"
  },
  {
    "text": "and so the host was able to provide almost 99.99% accurate results henceforth and yes the battle on",
    "start": "3027520",
    "end": "3034930"
  },
  {
    "text": "querying was again still going on to be able to catch any records which were missed due to network failures all right",
    "start": "3034930",
    "end": "3042250"
  },
  {
    "start": "3041000",
    "end": "3073000"
  },
  {
    "text": "so as the solution to this problem was exactly similar to our timer problem the",
    "start": "3042250",
    "end": "3048760"
  },
  {
    "text": "view architecture is a mirror image of a timer architecture we have the view routers the view host and a view GSI and",
    "start": "3048760",
    "end": "3056250"
  },
  {
    "text": "partition assign a dead leader election for this new set of view hosts as well",
    "start": "3056250",
    "end": "3061480"
  },
  {
    "text": "and this is the final architecture which we ended up on on a dynamodb based system and that's",
    "start": "3061480",
    "end": "3068210"
  },
  {
    "text": "how we build the key three key pieces of functionality on top of DynamoDB let's",
    "start": "3068210",
    "end": "3073700"
  },
  {
    "start": "3073000",
    "end": "3150000"
  },
  {
    "text": "quickly recap the five key techniques we have shown you guys today separate large payloads from small mutable data and as",
    "start": "3073700",
    "end": "3081560"
  },
  {
    "text": "Mike showed us before that helped us reduce our cost be a little inefficient",
    "start": "3081560",
    "end": "3087520"
  },
  {
    "text": "rarely and as long as we can monitor and ensure it's only rarely it works out",
    "start": "3087520",
    "end": "3092960"
  },
  {
    "text": "fine in our case it helped us optimize for scale avoid hot dynamodb partitions by",
    "start": "3092960",
    "end": "3100100"
  },
  {
    "text": "manufacturing additional keys and that helped us scale on top of DynamoDB move",
    "start": "3100100",
    "end": "3105890"
  },
  {
    "text": "hard problems into memory they're doing any kind of complicated queries easy right and finally prime caches to",
    "start": "3105890",
    "end": "3113600"
  },
  {
    "text": "minimize eventual consistency delays and particularly the last two techniques",
    "start": "3113600",
    "end": "3118790"
  },
  {
    "text": "four and five combined together was really powerful it allowed us to do some",
    "start": "3118790",
    "end": "3124580"
  },
  {
    "text": "kind of complicated query across hundreds of millions of items and still get pretty accurate results of those",
    "start": "3124580",
    "end": "3130520"
  },
  {
    "text": "queries within like few milliseconds all right that's it from me thank you",
    "start": "3130520",
    "end": "3135710"
  },
  {
    "text": "everyone for listening to me patiently I would hand over mic now back to my to",
    "start": "3135710",
    "end": "3140840"
  },
  {
    "text": "just share the results with us [Applause]",
    "start": "3140840",
    "end": "3148780"
  },
  {
    "text": "thanks P ish all right so let's let's close with a brief comparison of the two",
    "start": "3148780",
    "end": "3154730"
  },
  {
    "start": "3150000",
    "end": "3399000"
  },
  {
    "text": "architectures that we had Oracle our Oracle based architecture it was",
    "start": "3154730",
    "end": "3159740"
  },
  {
    "text": "actually awesome for us in some ways each interval database was able to perform all that complicated stuff for",
    "start": "3159740",
    "end": "3167150"
  },
  {
    "text": "us right within the database heck we built a schedule to queue on top of",
    "start": "3167150",
    "end": "3172190"
  },
  {
    "text": "Oracle and it worked I daresay at a smaller scale it actually worked well but the Oracle databases didn't scale",
    "start": "3172190",
    "end": "3179420"
  },
  {
    "text": "themselves they didn't hatch themselves the required manual efforts and tender",
    "start": "3179420",
    "end": "3185090"
  },
  {
    "text": "love and care on our end remember this slide from before compare that with the",
    "start": "3185090",
    "end": "3190730"
  },
  {
    "text": "new architecture yeah cool compare that",
    "start": "3190730",
    "end": "3201050"
  },
  {
    "text": "with the new DynamoDB based architecture in this setup timer and view services",
    "start": "3201050",
    "end": "3207470"
  },
  {
    "text": "view service are isolated systems these pieces of functionality can now scale",
    "start": "3207470",
    "end": "3213470"
  },
  {
    "text": "and fail independently which is a really nice proper to have in a system you",
    "start": "3213470",
    "end": "3218830"
  },
  {
    "text": "might notice though we still have partitions we even have some individual hosts that",
    "start": "3218830",
    "end": "3225800"
  },
  {
    "text": "we do care about right but the key difference now is that none of those",
    "start": "3225800",
    "end": "3230990"
  },
  {
    "text": "hosts are special none has any special configuration none has any durable data",
    "start": "3230990",
    "end": "3236930"
  },
  {
    "text": "on its disk if any dies we automatically replace them with another ec2 host within seconds and to scale up our",
    "start": "3236930",
    "end": "3244580"
  },
  {
    "text": "durable store we just ask Dino DB to scale that up and it does so what did we",
    "start": "3244580",
    "end": "3251270"
  },
  {
    "text": "see four results so one great thing we saw was that our workflow processing",
    "start": "3251270",
    "end": "3256580"
  },
  {
    "text": "delays actually dropped 10x with this new architecture at the 50th percentile from one second down to a hundred",
    "start": "3256580",
    "end": "3263150"
  },
  {
    "text": "milliseconds and that's in large part thanks to those two techniques that Pioche had there of querying data in",
    "start": "3263150",
    "end": "3268940"
  },
  {
    "text": "memory and priming the caches secondly our latency and availability improved",
    "start": "3268940",
    "end": "3274750"
  },
  {
    "text": "especially we didn't have to worry about database fail overs and those index rebuild jobs anymore",
    "start": "3274750",
    "end": "3280340"
  },
  {
    "text": "we can scale down now we don't have that durable state anymore and this is with",
    "start": "3280340",
    "end": "3285690"
  },
  {
    "text": "the Oracle databases this is something we wouldn't have ever even thought about doing honestly and this saves us money",
    "start": "3285690",
    "end": "3291510"
  },
  {
    "text": "which is great and we've got that architectural isolation we can scale and",
    "start": "3291510",
    "end": "3298550"
  },
  {
    "text": "those systems can fail independently now as awesome as all those results are they",
    "start": "3298550",
    "end": "3305340"
  },
  {
    "text": "were actually really just bonus results we would have done this project even if we didn't get any of these benefits our",
    "start": "3305340",
    "end": "3312330"
  },
  {
    "text": "main victory was that the ongoing effort to scale and maintain the system also dropped by 10x in in like twenty fifteen",
    "start": "3312330",
    "end": "3319770"
  },
  {
    "text": "or sixteen at the end of the life of this Oracle based system we were spending 60 developer weeks every year",
    "start": "3319770",
    "end": "3325710"
  },
  {
    "text": "scaling the system up and that chopped down to six and we did the math and we",
    "start": "3325710",
    "end": "3331860"
  },
  {
    "text": "actually would have needed over a thousand Oracle hosts to go through last Prime day this July and soon like my",
    "start": "3331860",
    "end": "3338910"
  },
  {
    "text": "team would have been doing nothing but just scaling the system up and instead",
    "start": "3338910",
    "end": "3344310"
  },
  {
    "text": "we can actually uh Nevaeh on behalf of our internal customers now and so this",
    "start": "3344310",
    "end": "3350580"
  },
  {
    "text": "is really what I would encourage you all to take a hard look at with your systems that you own how much time are you",
    "start": "3350580",
    "end": "3356610"
  },
  {
    "text": "spending just kind of keeping the lights on for us even though we did have to build on top of DynamoDB it did still",
    "start": "3356610",
    "end": "3364740"
  },
  {
    "text": "end up with a net reduction in our maintenance efforts that was it was so",
    "start": "3364740",
    "end": "3370470"
  },
  {
    "text": "worth it oh and by the way in case you can't tell going through all the algorithms and designing all this was",
    "start": "3370470",
    "end": "3376830"
  },
  {
    "text": "kind of a lot of fun for us too and so that's why and how we replaced hundreds",
    "start": "3376830",
    "end": "3382560"
  },
  {
    "text": "of databases with one big one thank you",
    "start": "3382560",
    "end": "3387560"
  },
  {
    "text": "for questions feel free to come on up we'll take them kind of offline thank you everyone",
    "start": "3393440",
    "end": "3399859"
  }
]
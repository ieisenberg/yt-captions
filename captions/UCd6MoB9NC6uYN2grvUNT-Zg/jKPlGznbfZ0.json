[
  {
    "start": "0",
    "end": "54000"
  },
  {
    "text": "all right well good afternoon Seifer noon we're going to talk about streaming",
    "start": "0",
    "end": "6420"
  },
  {
    "text": "data so my name is Alan Mukesh I am a Solutions Architect here at AWS",
    "start": "6420",
    "end": "12120"
  },
  {
    "text": "and I work primarily in our streaming data space which primarily is Kinesis I",
    "start": "12120",
    "end": "17640"
  },
  {
    "text": "work with a lot of customers who do other streaming data technologies as well such as kafka but for the purposes of today it's gonna be focused on on",
    "start": "17640",
    "end": "24449"
  },
  {
    "text": "Kinesis with me is gabriel como from Comcast and he is going to talk to you",
    "start": "24449",
    "end": "30420"
  },
  {
    "text": "all about how they have leveraged high-speed performance dating 4/4",
    "start": "30420",
    "end": "36000"
  },
  {
    "text": "performance data at Comcast and some of the learnings that they found in the in",
    "start": "36000",
    "end": "42090"
  },
  {
    "text": "the platform that he's created so I'm gonna jump in some of the details and then we'll invite Gabriel to come up",
    "start": "42090",
    "end": "47910"
  },
  {
    "text": "here in a few minutes to jump into the Comcast details so this is a quick view",
    "start": "47910",
    "end": "56760"
  },
  {
    "start": "54000",
    "end": "138000"
  },
  {
    "text": "of what we'll be talking about in the next 45 to 50 minutes we'll hopefully have some time at the end for Q&A so let",
    "start": "56760",
    "end": "63930"
  },
  {
    "text": "me get there there's a couple of mics feel free to get behind the mics and ask some questions of us but what we'll do",
    "start": "63930",
    "end": "71189"
  },
  {
    "text": "is a streaming data overview I want to make sure just we're all on the same page for what we're talking about with regards to streaming data we'll do a",
    "start": "71189",
    "end": "77850"
  },
  {
    "text": "very quick interactive demo we're gonna do that here at the beginning just to kind of highlight what it is that we're",
    "start": "77850",
    "end": "83040"
  },
  {
    "text": "talking about with streaming data then we'll do it a very quick introduced introduction to Amazon Kinesis and the",
    "start": "83040",
    "end": "90180"
  },
  {
    "text": "four services that make up the Kinesis set of services and then we'll start",
    "start": "90180",
    "end": "96270"
  },
  {
    "text": "talking about consuming from Kinesis streams because there's two different",
    "start": "96270",
    "end": "101909"
  },
  {
    "text": "ways you can do this and each them have their pros and cons so I want to make sure we jump into that and you",
    "start": "101909",
    "end": "107850"
  },
  {
    "text": "understand which model might be best for you and then Chris will come up I'm sorry Gabriel will come up and he'll",
    "start": "107850",
    "end": "114329"
  },
  {
    "text": "talk about Comcast and what they have done in the headwaters platform he's generally built a platform for streaming",
    "start": "114329",
    "end": "120240"
  },
  {
    "text": "data across all of Comcast and he will dive into the details of considerations",
    "start": "120240",
    "end": "125369"
  },
  {
    "text": "for scaling your data streams and then the impact that enhanced fan-out which is one of the two different consumer",
    "start": "125369",
    "end": "131220"
  },
  {
    "text": "choices that you get when you use Kinesis stream what impacts that had on their architecture all right let's talk about",
    "start": "131220",
    "end": "140680"
  },
  {
    "start": "138000",
    "end": "292000"
  },
  {
    "text": "the value of data and this is this is why we stream data but let's just quickly talk about the value of data and",
    "start": "140680",
    "end": "147250"
  },
  {
    "text": "how that data loses value quickly over time on this chart and this comes from a",
    "start": "147250",
    "end": "154050"
  },
  {
    "text": "paper produced by Forster the author's name is Mike gallery it's a good paper",
    "start": "154050",
    "end": "160750"
  },
  {
    "text": "called perishable insights where he talks about the insights into your data is perishable meaning over time it",
    "start": "160750",
    "end": "167980"
  },
  {
    "text": "decays or the value of what you can get out of that data diminishes over time so",
    "start": "167980",
    "end": "173440"
  },
  {
    "text": "in this chart we look at on the left side the things called time critical",
    "start": "173440",
    "end": "178660"
  },
  {
    "text": "decisions those blocks time critical decisions typically happen in real time",
    "start": "178660",
    "end": "185080"
  },
  {
    "text": "so you know milliseconds after the data was created or in seconds or minutes this is all going to be very dependent",
    "start": "185080",
    "end": "190630"
  },
  {
    "text": "on your application but in some cases seconds or minutes is fast enough for",
    "start": "190630",
    "end": "197500"
  },
  {
    "text": "your use case but can still be considered a time critical data piece traditional batch processes some of the",
    "start": "197500",
    "end": "206260"
  },
  {
    "text": "historical data that you might use there might have they generally lose value",
    "start": "206260",
    "end": "211750"
  },
  {
    "text": "over time but still have a lot of value just not valued that you can generally use to make a time critical decision a",
    "start": "211750",
    "end": "217150"
  },
  {
    "text": "very simple example and probably some of you have experienced this since you got to Las Vegas you swipe your card",
    "start": "217150",
    "end": "222670"
  },
  {
    "text": "somewhere and you get almost an immediate text message or notification from your credit card provider right",
    "start": "222670",
    "end": "228700"
  },
  {
    "text": "they've got some kind of real time analysis happening on all the transactions in their cards and they're",
    "start": "228700",
    "end": "235090"
  },
  {
    "text": "looking for fraudulent activity they might say oh suddenly you're in Las Vegas and your card has been swiped at",
    "start": "235090",
    "end": "240220"
  },
  {
    "text": "this ATM to get out a bunch of cash or you use it at this restaurant or whatever it might be and they've alerted",
    "start": "240220",
    "end": "245590"
  },
  {
    "text": "you and you can reply yes it's good or you know that wasn't me so that's like a real-time decision that they want to",
    "start": "245590",
    "end": "253150"
  },
  {
    "text": "know about because if it wasn't you obviously they want to take care of it if it was you then all is good but they",
    "start": "253150",
    "end": "260530"
  },
  {
    "text": "still do batch processes right they still send you an invoice at the end of the month and you still have to pay",
    "start": "260530",
    "end": "265599"
  },
  {
    "text": "whatever it was you charged on your car now they could have waited until the end of the month to say out of these hundred",
    "start": "265599",
    "end": "272240"
  },
  {
    "text": "transactions three of them look anomalous and you can then kind of go",
    "start": "272240",
    "end": "277850"
  },
  {
    "text": "through all the different transactions and decide which ones are good or bad but that's not good for them not good",
    "start": "277850",
    "end": "283250"
  },
  {
    "text": "for you so it's much more important for them to make that time critical decision on that data as soon as it gets created",
    "start": "283250",
    "end": "289610"
  },
  {
    "text": "so how is this happening through streaming those transactions get",
    "start": "289610",
    "end": "296480"
  },
  {
    "start": "292000",
    "end": "362000"
  },
  {
    "text": "streamed streaming means ingesting the data as soon as it's get soon as it gets",
    "start": "296480",
    "end": "302000"
  },
  {
    "text": "generated processing that data on the fly and then doing some kind of analysis",
    "start": "302000",
    "end": "307450"
  },
  {
    "text": "doing anomaly detection on it some kind of machine learning doing alerts or",
    "start": "307450",
    "end": "312500"
  },
  {
    "text": "actions as soon as you learn something from that data so this whole thing is what we're calling streaming data and",
    "start": "312500",
    "end": "318770"
  },
  {
    "text": "there's different technologies to enable this but the concept is streaming data who can remember the day where you would",
    "start": "318770",
    "end": "325640"
  },
  {
    "text": "probably put data into a database from your application and then you didn't do",
    "start": "325640",
    "end": "331430"
  },
  {
    "text": "any learnings from it until a batch process ran that night or a batch process ran at the end of the week to",
    "start": "331430",
    "end": "338600"
  },
  {
    "text": "move that data into some warehouse where you could then go run reports I'm pretty sure probably probably pretty much",
    "start": "338600",
    "end": "344600"
  },
  {
    "text": "everybody could put their hand up to say yeah you used to do that or you still do it because you know like I said there's",
    "start": "344600",
    "end": "349820"
  },
  {
    "text": "still plenty of use cases where that applies but to get those real-time",
    "start": "349820",
    "end": "355040"
  },
  {
    "text": "insights it's important to ingest that data as soon as it gets generated and then analyze it immediately so common",
    "start": "355040",
    "end": "364460"
  },
  {
    "start": "362000",
    "end": "431000"
  },
  {
    "text": "use cases of streaming these are just a few and I'm not going to talk about them all in detail but the two that we see",
    "start": "364460",
    "end": "370310"
  },
  {
    "text": "very very popular our log analytics feeding into data lakes and then I'll",
    "start": "370310",
    "end": "376490"
  },
  {
    "text": "say IOT analytics but I'm going to generalize IOT analytics it's not quite I or T devices like not doesn't",
    "start": "376490",
    "end": "383210"
  },
  {
    "text": "necessarily have to be temperature sensors or pressure sensors but I will call an IOT device just a connected",
    "start": "383210",
    "end": "389660"
  },
  {
    "text": "device like your phone a game that's running on your phone these are connected devices that are always",
    "start": "389660",
    "end": "395630"
  },
  {
    "text": "sending data so between those three on the right they",
    "start": "395630",
    "end": "400980"
  },
  {
    "text": "generate a ton of streaming real-time data that our customers are using to get real-time insights out of them and then",
    "start": "400980",
    "end": "408150"
  },
  {
    "text": "the industrial automation space we have plenty of customers in the factories who are using streaming data to get insights",
    "start": "408150",
    "end": "414360"
  },
  {
    "text": "into what's happening across their operations in near real-time imagine they want to know if one of their lines",
    "start": "414360",
    "end": "421410"
  },
  {
    "text": "is down or is taking longer to process some product than it typically does they want to know that right away you have to",
    "start": "421410",
    "end": "427560"
  },
  {
    "text": "go in and fix it so that's a good example there so how do we do this at",
    "start": "427560",
    "end": "433200"
  },
  {
    "start": "431000",
    "end": "754000"
  },
  {
    "text": "Amazon we have four different services for streaming data this is probably old news to do maybe quickshow hands who are",
    "start": "433200",
    "end": "438960"
  },
  {
    "text": "already using a Kinesis service in production today so it's about maybe a",
    "start": "438960",
    "end": "444840"
  },
  {
    "text": "third of the room but that's 3 or 2 1/2 of the room so very good so I'm not",
    "start": "444840",
    "end": "450510"
  },
  {
    "text": "going to get into then a ton of details about what these services do but I'm going to tell you some of the differences between and why you might",
    "start": "450510",
    "end": "456810"
  },
  {
    "text": "choose to use one over the other I'll start on the left Amazon Kinesis video streams this is a",
    "start": "456810",
    "end": "462990"
  },
  {
    "text": "relatively new service we've launched it at reinvent last year but it enables you to ingest and process binary encoded",
    "start": "462990",
    "end": "471770"
  },
  {
    "text": "time series data so that could be video audio lidar radar it's intended we call",
    "start": "471770",
    "end": "479850"
  },
  {
    "text": "the video because video is kind of the number one use case but there's other binary formats that can easily be ingested into video streams the other",
    "start": "479850",
    "end": "487410"
  },
  {
    "text": "three services and what we're going to focus on mostly today is our data set of services so these are the types of",
    "start": "487410",
    "end": "493380"
  },
  {
    "text": "services that are just receiving either unencoded or encoded data that's coming off of your systems could be log data it",
    "start": "493380",
    "end": "500640"
  },
  {
    "text": "could be application event data being sent into Kinesis so you can get some of",
    "start": "500640",
    "end": "506520"
  },
  {
    "text": "that real-time analysis that we just discussed so the three services on the right data streams data firehose and",
    "start": "506520",
    "end": "512700"
  },
  {
    "text": "data analytics can all work together to get you those insights Kinesis data",
    "start": "512700",
    "end": "518099"
  },
  {
    "text": "streams to compare and contrast it with firehose I get that question a lot Kinesis data streams I'll tell you the",
    "start": "518099",
    "end": "523800"
  },
  {
    "text": "biggest question that you can ask yourself to determine should I use streams or should I use firehose is this",
    "start": "523800",
    "end": "531060"
  },
  {
    "text": "Kinesis data streams what requires you to typically write custom code to get data",
    "start": "531060",
    "end": "537210"
  },
  {
    "text": "from the stream so you have a data producer that puts data into the stream it's going to sit there in a buffer by",
    "start": "537210",
    "end": "544440"
  },
  {
    "text": "default 24 hours you can extend it up to seven days and then your consumers one",
    "start": "544440",
    "end": "550320"
  },
  {
    "text": "or more are going to take the data off the stream and do something with it so in that context the stream is just a",
    "start": "550320",
    "end": "555810"
  },
  {
    "text": "buffer and you have to write the custom code to take the data off the stream and apply your business logic to it the",
    "start": "555810",
    "end": "562230"
  },
  {
    "text": "stream doesn't care if the data was used or not by your consumer once that window",
    "start": "562230",
    "end": "568200"
  },
  {
    "text": "expires of 24 hours which is the default the data's gone from the buffer so it's a little bit different than a queue like",
    "start": "568200",
    "end": "573750"
  },
  {
    "text": "with a queue if you're using something sqs you can pop a message off the queue and it's no longer going to be consumed",
    "start": "573750",
    "end": "580110"
  },
  {
    "text": "by any other queue consumers with a stream it's going to sit there until it expires now with case of streams you're also",
    "start": "580110",
    "end": "587610"
  },
  {
    "text": "writing your own code to take the data off of the stream and that contrasts a",
    "start": "587610",
    "end": "593910"
  },
  {
    "text": "little bit with firehose firehose yes the the front end how you get the data into the firehose is very similar it's",
    "start": "593910",
    "end": "600930"
  },
  {
    "text": "going to be an agent perhaps that's running on your localhost that's taking log files and streaming the logs into",
    "start": "600930",
    "end": "607830"
  },
  {
    "text": "the firehose or you're using the SDK to write messages directly into firehose",
    "start": "607830",
    "end": "613860"
  },
  {
    "text": "but the biggest difference is firehose has a managed consumer to take the data off of the streams and put it into one",
    "start": "613860",
    "end": "621360"
  },
  {
    "text": "of four different destinations you can put it into s3 put it into Splunk put it into redshift or put it into Amazon",
    "start": "621360",
    "end": "629520"
  },
  {
    "text": "Elastic search service so when you ask yourself I want to stream data I don't",
    "start": "629520",
    "end": "635100"
  },
  {
    "text": "really want to do much with it at least not yet I just want to put it into s3 so I have a durable store really relatively",
    "start": "635100",
    "end": "640950"
  },
  {
    "text": "inexpensive spot to put my streaming data firehose firehose by far and away is going to be the easiest way to do it",
    "start": "640950",
    "end": "646470"
  },
  {
    "text": "and it's probably should be the first consideration you make there's a lot more complexities there you can do things like data transformation with",
    "start": "646470",
    "end": "653160"
  },
  {
    "text": "firehose using lambda so there's a lot of more complexities that I'm kind of glossing over but you know if you're",
    "start": "653160",
    "end": "659430"
  },
  {
    "text": "asking yourself between streams and firehose and you ultimately say I really just want to stream the data and put it into elasticsearch so I can do log",
    "start": "659430",
    "end": "665880"
  },
  {
    "text": "analytics and elasticsearch and i don't really have to transform my data in the middle consider firehose the last service on your right",
    "start": "665880",
    "end": "674709"
  },
  {
    "text": "Kinesis data analytics this service gives you the capability to do real-time analysis on that data before it even",
    "start": "674709",
    "end": "681110"
  },
  {
    "text": "persists in any destination so it's basically an application that can listen",
    "start": "681110",
    "end": "687620"
  },
  {
    "text": "to the streaming data get some insights that you have to code you have to tell it what insights you want so we have two",
    "start": "687620",
    "end": "694160"
  },
  {
    "text": "versions now Kinesis data analytics one is sequel base so you can write some sequel code to do things like tell me",
    "start": "694160",
    "end": "701149"
  },
  {
    "text": "how many times the this event has occurred in the past two hours I'll give",
    "start": "701149",
    "end": "707630"
  },
  {
    "text": "an example we work with an e-commerce customer not not Amazon a different one and they use Kinesis data analytics to",
    "start": "707630",
    "end": "717350"
  },
  {
    "text": "find out what the top-selling products are in a 30 minute window on their website so they stream all the order",
    "start": "717350",
    "end": "723769"
  },
  {
    "text": "data through Kinesis streams they run Kinesis data analytics which inspects that streaming data and they run an",
    "start": "723769",
    "end": "730279"
  },
  {
    "text": "aggregation every 30 minutes and then they say that out to a dashboard so their business users can go in and look",
    "start": "730279",
    "end": "735980"
  },
  {
    "text": "at the most popular ordered products over those windows and then they can",
    "start": "735980",
    "end": "741199"
  },
  {
    "text": "make decisions about how they want to increase promotions on the website for other products that they want to perhaps get higher in the sales rank so that's",
    "start": "741199",
    "end": "749180"
  },
  {
    "text": "just a quick overview of those three services and we'll move now into a bit more detail after we do a very fast demo",
    "start": "749180",
    "end": "756170"
  },
  {
    "start": "754000",
    "end": "937000"
  },
  {
    "text": "to kind of put it all into perspective ok so I need you all this is an interactive demo I need your help I want",
    "start": "756170",
    "end": "762110"
  },
  {
    "text": "you to pull out your phones and go to that URL don't do it on your computer",
    "start": "762110",
    "end": "768800"
  },
  {
    "text": "you could it's just not going to be as valuable please use your phone",
    "start": "768800",
    "end": "773500"
  },
  {
    "text": "I'm leaving it up for one second give you guys a chance to pull it up what you should see is a quadrant or the number",
    "start": "778410",
    "end": "783730"
  },
  {
    "text": "of boxes or sorry quadrant with a ball you can move the ball around",
    "start": "783730",
    "end": "789330"
  },
  {
    "text": "and I have a window somewhere there we go okay so this is all happening in real",
    "start": "797190",
    "end": "806850"
  },
  {
    "text": "time this is a real demo I'd like everybody to try and move the ball into quadrant a move the ball into quadrant a",
    "start": "806850",
    "end": "813329"
  },
  {
    "text": "and then hold it there and we should see within three to four seconds this should all show up in a yeah very cool",
    "start": "813329",
    "end": "821519"
  },
  {
    "text": "we're also capturing some other numbers so about five most five hundred yeah over five hundred of you now have",
    "start": "821519",
    "end": "826649"
  },
  {
    "text": "participated that's unique on the top and then it's numbered the raw data about how many art in each quadrant I",
    "start": "826649",
    "end": "833399"
  },
  {
    "text": "said a but we have a couple of a couple of non conformists that's okay so that's",
    "start": "833399",
    "end": "841800"
  },
  {
    "text": "all go to C let's all move it to see hold it there should be three or four",
    "start": "841800",
    "end": "847470"
  },
  {
    "text": "seconds we should jump it there we go come on there we go okay so pretty cool",
    "start": "847470",
    "end": "854490"
  },
  {
    "text": "so this example just highlight in kind this could be anything right this could be your business KPIs this could be log",
    "start": "854490",
    "end": "859920"
  },
  {
    "text": "data this could be errors that are streaming from your application error logs but you can take that data use",
    "start": "859920",
    "end": "865139"
  },
  {
    "text": "Kinesis analytics use Kinesis to ingest it get very real insights out of it and put this on a dashboard for your",
    "start": "865139",
    "end": "870630"
  },
  {
    "text": "business users of course per one second might not be necessary for some of those",
    "start": "870630",
    "end": "875790"
  },
  {
    "text": "types of things I just mentioned but you could of course change the window to be every you know every every few minutes every hour this is just a good one to",
    "start": "875790",
    "end": "882630"
  },
  {
    "text": "show you for how fast we can do it last thing we're also capturing device data",
    "start": "882630",
    "end": "888050"
  },
  {
    "text": "so iOS to Android not uncommon slightly",
    "start": "888050",
    "end": "893550"
  },
  {
    "text": "higher in the iOS no Windows Phone users",
    "start": "893550",
    "end": "897620"
  },
  {
    "text": "there is a point funny point on that because I did this at a previous talk not here at read invent but it was at a",
    "start": "899480",
    "end": "905550"
  },
  {
    "text": "different session and it did show up there was a Windows Phone and I asked the person in the room to put up their",
    "start": "905550",
    "end": "911400"
  },
  {
    "text": "hand to volunteer but they did not",
    "start": "911400",
    "end": "918470"
  },
  {
    "text": "alright let's go back to here all right cool",
    "start": "920090",
    "end": "926300"
  },
  {
    "text": "alright I'll figure this out here there",
    "start": "931670",
    "end": "938340"
  },
  {
    "start": "937000",
    "end": "996000"
  },
  {
    "text": "we go okay this is the architecture of what you guys just did I don't have a whole lot of time to spend on this we",
    "start": "938340",
    "end": "943560"
  },
  {
    "text": "have to kind of jump through and get to the next section but the nice point about that whole demo is it was all swivel 'us so there's no ec2 instances",
    "start": "943560",
    "end": "951000"
  },
  {
    "text": "and mixed nothing to manage on the backend for servers there was all just Kinesis and lambda and DynamoDB and of",
    "start": "951000",
    "end": "956700"
  },
  {
    "text": "course some static content in s3 for the JavaScript and HTML so a very simple",
    "start": "956700",
    "end": "961920"
  },
  {
    "text": "application and the fact it can even be improved because since this demo was built there have been changes to the",
    "start": "961920",
    "end": "967980"
  },
  {
    "text": "Kinesis analytics product I don't know if I have a laser pointer that will",
    "start": "967980",
    "end": "973710"
  },
  {
    "text": "actually work anyway you can see here after the Kinesis analytics application and before the lambda function there's",
    "start": "973710",
    "end": "979500"
  },
  {
    "text": "this extra stream this Kinesis aggregate stream that can be removed now in fact there's a feature that's been released",
    "start": "979500",
    "end": "985320"
  },
  {
    "text": "that allows Kinesis analytics to invoke a lambda function with the results of its analysis so I could take that piece",
    "start": "985320",
    "end": "992430"
  },
  {
    "text": "out and it's even a simpler architecture but what we're really here to talk about",
    "start": "992430",
    "end": "998610"
  },
  {
    "start": "996000",
    "end": "1056000"
  },
  {
    "text": "today is high performance data streaming and how you can best do that on Kinesis",
    "start": "998610",
    "end": "1006610"
  },
  {
    "text": "particularly with Kinesis data streams before we do that we talked we want to talk a little bit about producers and",
    "start": "1006610",
    "end": "1011870"
  },
  {
    "text": "consumers because we're primarily going to discuss consumers today but I don't want to make sure we're all on the same page there's plenty of ways to produce",
    "start": "1011870",
    "end": "1018050"
  },
  {
    "text": "data to Kinesis plenty of ways to consume I am definitely not going to go through each of these the point I want",
    "start": "1018050",
    "end": "1025100"
  },
  {
    "text": "to make on the consumer side of it is the Kinesis client library and AWS",
    "start": "1025100",
    "end": "1031910"
  },
  {
    "text": "lambda those are the two that can most benefit from some of the features that we're about to discuss the other ones",
    "start": "1031910",
    "end": "1038780"
  },
  {
    "text": "that you see here what we're looking at here like Apache flank Apache storm",
    "start": "1038780",
    "end": "1045400"
  },
  {
    "text": "pachi spark they can also benefit from some of the new features but it will require the light the open source",
    "start": "1045400",
    "end": "1050510"
  },
  {
    "text": "libraries to use some of the new API is that we have created that I don't believe they have yet so talking about",
    "start": "1050510",
    "end": "1057920"
  },
  {
    "start": "1056000",
    "end": "1303000"
  },
  {
    "text": "consumers I have a clicker here I should use it standard consumers this is what the vast",
    "start": "1057920",
    "end": "1065669"
  },
  {
    "text": "majority of stream consumers on AWS are using right now and that's because it's been the only way to do it up until",
    "start": "1065669",
    "end": "1070890"
  },
  {
    "text": "about August so what is a standard consumer actually before I get a jump into that take a look at the the the",
    "start": "1070890",
    "end": "1077429"
  },
  {
    "text": "kind of a white rectangle in the middle that is the representation of a stream that is made up of shards if you're not",
    "start": "1077429",
    "end": "1083309"
  },
  {
    "text": "familiar with shards a shard is essentially a unit of scale in a stream it can accept 1 Meg per second or a",
    "start": "1083309",
    "end": "1089640"
  },
  {
    "text": "thousand records per second so when you do your analysis of a Kinesis stream and you have to determine how many shards",
    "start": "1089640",
    "end": "1095760"
  },
  {
    "text": "are sorry how much data you want to ingest into that stream that determines",
    "start": "1095760",
    "end": "1101730"
  },
  {
    "text": "how many shards you'll have to put into that stream so if your use case says that you're going to stream about 4,000",
    "start": "1101730",
    "end": "1109590"
  },
  {
    "text": "records per second you will need 4 shards in your stream so a shard is a",
    "start": "1109590",
    "end": "1114899"
  },
  {
    "text": "unit of scale and a stream a consumer application has multiple threads each",
    "start": "1114899",
    "end": "1122669"
  },
  {
    "text": "thread gets data from a shard via a get records call this is largely abstracted",
    "start": "1122669",
    "end": "1130049"
  },
  {
    "text": "from you if you're using one of our libraries called the KCl the Kinesis client library or if you're using lambda",
    "start": "1130049",
    "end": "1135720"
  },
  {
    "text": "to consume the get records operation is abstracted by those libraries or the service but it's important to understand",
    "start": "1135720",
    "end": "1142559"
  },
  {
    "text": "what's going on so that when we if you consider the the KCl 2.0 which is the",
    "start": "1142559",
    "end": "1148350"
  },
  {
    "text": "next version or the newest version of lambda so you can use enhanced fan out of Kinesis which gives you that lower",
    "start": "1148350",
    "end": "1155159"
  },
  {
    "text": "latency so this is what's going on ket records is made and data is returned",
    "start": "1155159",
    "end": "1162320"
  },
  {
    "text": "come on my clicker might be dead oh you",
    "start": "1163039",
    "end": "1170340"
  },
  {
    "text": "have to press it a whole bunch times",
    "start": "1170340",
    "end": "1173419"
  },
  {
    "text": "okay so the get record the get record operation can only be made five times",
    "start": "1176019",
    "end": "1182869"
  },
  {
    "text": "per second on a single shard that's a limitation in the service and it's not something that can be changed and data",
    "start": "1182869",
    "end": "1188929"
  },
  {
    "text": "can be returned at a rate of two megabytes per second per shard also that's a limit from the service not",
    "start": "1188929",
    "end": "1196009"
  },
  {
    "text": "something that can be changed so with that the fastest that your consumer can get data from the stream is every 200",
    "start": "1196009",
    "end": "1203299"
  },
  {
    "text": "milliseconds this is a polling operation that your consumer application has to implement or the KCl will do it for you",
    "start": "1203299",
    "end": "1208970"
  },
  {
    "text": "on your behalf but get records every 200 milliseconds because you have to stay below that five requests per second for",
    "start": "1208970",
    "end": "1216739"
  },
  {
    "text": "the get records call if you go beyond that if you lowered it to one every 100 millisecond of a polling window that's",
    "start": "1216739",
    "end": "1222799"
  },
  {
    "text": "ten times per and five of those would get throttled so the service that",
    "start": "1222799",
    "end": "1227929"
  },
  {
    "text": "Kinesis service would return an exception and your consumer would have to have to swallow that exception do a",
    "start": "1227929",
    "end": "1234080"
  },
  {
    "text": "little bit of a back off and retry so you know 200 milliseconds is not bad in many cases that's good enough for",
    "start": "1234080",
    "end": "1240379"
  },
  {
    "text": "real-time like I said earlier all depends on your you and your company's definition of real-time but it's not bad",
    "start": "1240379",
    "end": "1245559"
  },
  {
    "text": "but what if we do this what if you have five consuming applications all of which",
    "start": "1245559",
    "end": "1251840"
  },
  {
    "text": "have you know different business logic perhaps different teams in your organization that want to do something with the data now each of them can only",
    "start": "1251840",
    "end": "1260690"
  },
  {
    "text": "ask for can only get 400 kilobytes of data each because it's a two Meg per",
    "start": "1260690",
    "end": "1266330"
  },
  {
    "text": "second egress limitation on that shard and have five so that means they can only get 400 KB and they can only ask",
    "start": "1266330",
    "end": "1274940"
  },
  {
    "text": "for data once per second because with five of them they don't want to go",
    "start": "1274940",
    "end": "1281239"
  },
  {
    "text": "beyond the five requests per second so they can all only ask for data now once per second so now your latency is going",
    "start": "1281239",
    "end": "1287570"
  },
  {
    "text": "to go up from the previous use case with one consumer it could ask every 200 milliseconds these can now only pull",
    "start": "1287570",
    "end": "1293749"
  },
  {
    "text": "every single second so your latency for how quickly your consumer can respond to",
    "start": "1293749",
    "end": "1299239"
  },
  {
    "text": "data in the stream it goes up so now",
    "start": "1299239",
    "end": "1304730"
  },
  {
    "start": "1303000",
    "end": "1499000"
  },
  {
    "text": "with enhanced fan-out we've changed that model quite considerably this is a new feature like I said launched in August and we've introduced",
    "start": "1304730",
    "end": "1312979"
  },
  {
    "text": "some new API to take care of a lot of the issues that we just described so the",
    "start": "1312979",
    "end": "1318499"
  },
  {
    "text": "few new API is the first point to make it's the sub title on here as consumers",
    "start": "1318499",
    "end": "1324889"
  },
  {
    "text": "no longer pull messages are pushed to your consumers as they arrive so the",
    "start": "1324889",
    "end": "1330440"
  },
  {
    "text": "server will push them over a long-running HTTP to request that has",
    "start": "1330440",
    "end": "1336109"
  },
  {
    "text": "been made by the consumer over a subscribe to shard API call so the",
    "start": "1336109",
    "end": "1341119"
  },
  {
    "text": "consumer initiates subscribe to shard that will remain open for up to five minutes it uses HTTP 2 so how many",
    "start": "1341119",
    "end": "1349039"
  },
  {
    "text": "people here are familiar with WebSockets a lot of you that's great so this I mean this is not WebSockets but if you know",
    "start": "1349039",
    "end": "1356029"
  },
  {
    "text": "what WebSockets does this is very very similar it's just managed by the protocol itself it's not a layer on top",
    "start": "1356029",
    "end": "1362719"
  },
  {
    "text": "of HTTP 1 1 it's managed by the HTTP 2 protocol that allows the server in this",
    "start": "1362719",
    "end": "1370249"
  },
  {
    "text": "case the Kinesis service to send data out of order to the client without",
    "start": "1370249",
    "end": "1376429"
  },
  {
    "text": "having to be asked for each packet so",
    "start": "1376429",
    "end": "1381489"
  },
  {
    "text": "come on there we go so this it's hard to see there's a little curly brace in between the data producer and the stream",
    "start": "1381489",
    "end": "1387589"
  },
  {
    "text": "that's our piece of data that's coming in the shard will persist it and then it",
    "start": "1387589",
    "end": "1392989"
  },
  {
    "text": "will send it to the consumer application right away I'm gonna have to go back to",
    "start": "1392989",
    "end": "1398749"
  },
  {
    "text": "the keyboard and then it will keep doing it over and over and over again for as long as data is being sent to this to",
    "start": "1398749",
    "end": "1407029"
  },
  {
    "text": "the stream so that means your data is now your story your consumer is now",
    "start": "1407029",
    "end": "1412070"
  },
  {
    "text": "getting that data very very frequently on the order of 50 to 70 milliseconds active data was written was being",
    "start": "1412070",
    "end": "1418700"
  },
  {
    "text": "delivered to your consumer contrast that with the best case and the get records",
    "start": "1418700",
    "end": "1424369"
  },
  {
    "text": "operation was about 2 to 300 milliseconds we're now down to about 50",
    "start": "1424369",
    "end": "1430639"
  },
  {
    "text": "milliseconds latency that's much better that's only with one consumer using the",
    "start": "1430639",
    "end": "1436309"
  },
  {
    "text": "get Records model when you had those five consumers using the get Records model right you're talking about one",
    "start": "1436309",
    "end": "1441810"
  },
  {
    "text": "one request per second so much longer Layton sees the other big benefit is that each consumer gets its own",
    "start": "1441810",
    "end": "1450390"
  },
  {
    "text": "dedicated two megabytes per second of egress so each consumer has to say",
    "start": "1450390",
    "end": "1456180"
  },
  {
    "text": "register stream we create internally this pipe the fo pipe that gives us its",
    "start": "1456180",
    "end": "1461700"
  },
  {
    "text": "own dedicated throughput and so now when it comes back and calls subscribe to",
    "start": "1461700",
    "end": "1467160"
  },
  {
    "text": "shard we give it its own two Meg's per second egress limit just for that one",
    "start": "1467160",
    "end": "1473220"
  },
  {
    "text": "consumer and so it's no longer having to contend for that two Meg's per second",
    "start": "1473220",
    "end": "1479700"
  },
  {
    "text": "per shard limitation that previously existed with the old API I can now come in and add more and more consumers the",
    "start": "1479700",
    "end": "1487260"
  },
  {
    "text": "data will be pushed to the consumers and they can get the full throughput from",
    "start": "1487260",
    "end": "1492480"
  },
  {
    "text": "the stream to the consumer so no more contention for two Meg's per second no more contention for five reads per",
    "start": "1492480",
    "end": "1497520"
  },
  {
    "text": "second so it really enables you to add more and more consumers to a stream and",
    "start": "1497520",
    "end": "1504390"
  },
  {
    "start": "1499000",
    "end": "1597000"
  },
  {
    "text": "not have to worry about contending for resources where you did have to",
    "start": "1504390",
    "end": "1509720"
  },
  {
    "text": "definitely consider that in the older model we're doing get records so when",
    "start": "1509720",
    "end": "1515610"
  },
  {
    "text": "should you use standard consumers that was the first one that's calling get records if your total number of",
    "start": "1515610",
    "end": "1521340"
  },
  {
    "text": "consumers is low and your consumers aren't particularly latency sensitive then consider using the older model our",
    "start": "1521340",
    "end": "1530010"
  },
  {
    "text": "library the KCl we have two versions one point eight point X and 2.0 point x one",
    "start": "1530010",
    "end": "1538020"
  },
  {
    "text": "point eight is the older one we've upgraded to two I would recommend you",
    "start": "1538020",
    "end": "1543630"
  },
  {
    "text": "all use 2.0 because it supports both you just have to implement different interfaces for the consumption model",
    "start": "1543630",
    "end": "1550980"
  },
  {
    "text": "that you want to implement but if your consumers aren't latency sensitive and",
    "start": "1550980",
    "end": "1556110"
  },
  {
    "text": "you have a low number of consumers consider using the standard consumers and it's also going to be cheaper there",
    "start": "1556110",
    "end": "1561300"
  },
  {
    "text": "are cost dimensions with the enhanced fan-out feature so we will charge you for those pipes these efo pipes on the",
    "start": "1561300",
    "end": "1568830"
  },
  {
    "text": "previous slide and there's a per gigabyte data egress now in that model so it's cheaper to use the",
    "start": "1568830",
    "end": "1575800"
  },
  {
    "text": "old consumers which is why if you have very few consumers with low latency requirements use the old way when do use enhanced fan-out multiple",
    "start": "1575800",
    "end": "1583480"
  },
  {
    "text": "consumers let's say more than three and you have very low latency requirements",
    "start": "1583480",
    "end": "1588850"
  },
  {
    "text": "for that if you have low latency requirements less than 70 milliseconds then enhanced fan out is how you're",
    "start": "1588850",
    "end": "1594700"
  },
  {
    "text": "gonna get there and that does it for me",
    "start": "1594700",
    "end": "1600100"
  },
  {
    "start": "1597000",
    "end": "1723000"
  },
  {
    "text": "so I'm gonna hand it over to Gabriel now and he's going to take you through what they did at Comcast sorry my apologies",
    "start": "1600100",
    "end": "1608500"
  },
  {
    "text": "is my screen up here isn't different there we go thank you",
    "start": "1608500",
    "end": "1612990"
  },
  {
    "text": "all right so 100% of the Canisius users that I have worked with so far or either",
    "start": "1623260",
    "end": "1631059"
  },
  {
    "text": "overpaying for the kinases streams or facing technical difficulties because",
    "start": "1631059",
    "end": "1636380"
  },
  {
    "text": "there's trim is under scaled so how do you scale a kinases stream and how does",
    "start": "1636380",
    "end": "1641480"
  },
  {
    "text": "the new enhance fan-out consumer changes the pictures hi my name is Gabriel como",
    "start": "1641480",
    "end": "1646640"
  },
  {
    "text": "and I lead streaming data platform at Comcast I'm really excited to be here I hope you guys are enjoying the AWS",
    "start": "1646640",
    "end": "1653630"
  },
  {
    "text": "reinvent 2018 as much as I am and so I will split the rest of this",
    "start": "1653630",
    "end": "1660320"
  },
  {
    "text": "session into three parts first I'll give you some background and some context",
    "start": "1660320",
    "end": "1667309"
  },
  {
    "text": "about the streaming data platform that we've built at Comcast then we'll see five considerations to think about when",
    "start": "1667309",
    "end": "1674559"
  },
  {
    "text": "considering scaling in kinesis dream and finally we'll see how the consumer",
    "start": "1674559",
    "end": "1679760"
  },
  {
    "text": "fan-out the new feature changes this picture so before we start I've got a",
    "start": "1679760",
    "end": "1686120"
  },
  {
    "text": "good news and bad news the bad news is that I left a lot of math on the slides the good news is that I will not be",
    "start": "1686120",
    "end": "1693919"
  },
  {
    "text": "boring you through those instead I will focus on the principles and the logic to",
    "start": "1693919",
    "end": "1699650"
  },
  {
    "text": "arrive to those formulas and I left them so that if you want to dig further into this topic after the talk you have the",
    "start": "1699650",
    "end": "1706970"
  },
  {
    "text": "material to do so the second good news is that we actually implemented those",
    "start": "1706970",
    "end": "1712730"
  },
  {
    "text": "formulas into a calculator that were recently open sourced and I'll come back to that towards the end of the demo of",
    "start": "1712730",
    "end": "1720409"
  },
  {
    "text": "the session sorry all the time we came",
    "start": "1720409",
    "end": "1725870"
  },
  {
    "start": "1723000",
    "end": "1787000"
  },
  {
    "text": "to call the concept of managing the stream data essentially a streaming platform Jai Creve J Krebs wrote that in",
    "start": "1725870",
    "end": "1733549"
  },
  {
    "text": "a blog article in 2015 actually that first link that you see on the side and",
    "start": "1733549",
    "end": "1739720"
  },
  {
    "text": "Joe Krebs and his team are the one who built Apache Kafka while they were working I",
    "start": "1739720",
    "end": "1745310"
  },
  {
    "text": "at LinkedIn and I really like this quote because it marks to me a transition in",
    "start": "1745310",
    "end": "1752090"
  },
  {
    "text": "the industry were streaming really to goth it's it's to me a paradigm shift",
    "start": "1752090",
    "end": "1758480"
  },
  {
    "text": "because data is not a table in some database anymore",
    "start": "1758480",
    "end": "1763490"
  },
  {
    "text": "data set is alive and changing and it has a whole new dimension when you",
    "start": "1763490",
    "end": "1769460"
  },
  {
    "text": "consider streaming so I added two articles that are excellent nicing",
    "start": "1769460",
    "end": "1775850"
  },
  {
    "text": "fundamental for an engineer working on on streaming I would highly recommend",
    "start": "1775850",
    "end": "1782660"
  },
  {
    "text": "you to go through those if you haven't read them already so we called our",
    "start": "1782660",
    "end": "1788720"
  },
  {
    "start": "1787000",
    "end": "1964000"
  },
  {
    "text": "streaming data platform at Comcast headwaters and there are three objectives that we try to accomplish the",
    "start": "1788720",
    "end": "1799790"
  },
  {
    "text": "first one is that we want to decouple the data producer from its consumers so",
    "start": "1799790",
    "end": "1805430"
  },
  {
    "text": "the teams that writes the applications that interact with our platform or from",
    "start": "1805430",
    "end": "1810890"
  },
  {
    "text": "different divisions within Comcast but CB even from different companies and therefore it's important to sorry so",
    "start": "1810890",
    "end": "1818270"
  },
  {
    "text": "because they are from different divisions and companies they have different objectives and different",
    "start": "1818270",
    "end": "1823310"
  },
  {
    "text": "budgets so it's really important to us to have as as loose as a coupling as we",
    "start": "1823310",
    "end": "1829970"
  },
  {
    "text": "can between those various applications also the platform acts as a buffer in",
    "start": "1829970",
    "end": "1836900"
  },
  {
    "text": "case one of those application isn't available for some time it doesn't affect the other application or at least",
    "start": "1836900",
    "end": "1844610"
  },
  {
    "text": "as little as possible and also it formalizes the data exchanged between",
    "start": "1844610",
    "end": "1850580"
  },
  {
    "text": "those applications so not only from a technical point of view in terms of API",
    "start": "1850580",
    "end": "1855650"
  },
  {
    "text": "and data sterilization but also in terms of processes such as data governance and",
    "start": "1855650",
    "end": "1862310"
  },
  {
    "text": "data security the second group of objective is to assist the data team",
    "start": "1862310",
    "end": "1870110"
  },
  {
    "text": "which their streaming needs so we help them scale the kinases or the data stream",
    "start": "1870110",
    "end": "1876860"
  },
  {
    "text": "we help them manage the data retention and onboard consumers finally and really",
    "start": "1876860",
    "end": "1883850"
  },
  {
    "text": "importantly we want to foster real-time data exchange within the company that's really important to me because I believe",
    "start": "1883850",
    "end": "1889910"
  },
  {
    "text": "that data is one of the most valuable asset that a modern company can have so we want to lower the bar of entry as",
    "start": "1889910",
    "end": "1897680"
  },
  {
    "text": "much as possible so that teams can share the data that they have so to that end",
    "start": "1897680",
    "end": "1903170"
  },
  {
    "text": "we manage the metadata about the stream to answer questions such as who when how",
    "start": "1903170",
    "end": "1909800"
  },
  {
    "text": "and also the the data set whether",
    "start": "1909800",
    "end": "1915200"
  },
  {
    "text": "structured or unstructured or associated with a schema and that schema evolves over time so we manage that so that the",
    "start": "1915200",
    "end": "1923390"
  },
  {
    "text": "consumer team can make sense of the bytes that flows through our platform",
    "start": "1923390",
    "end": "1928690"
  },
  {
    "text": "finally we implemented what I call a fair cost model in which the teams that",
    "start": "1928690",
    "end": "1933890"
  },
  {
    "text": "benefit from the data are the one that financed the infrastructure to power",
    "start": "1933890",
    "end": "1942320"
  },
  {
    "text": "those those data exchange in proportion to what they use I don't have time to",
    "start": "1942320",
    "end": "1947630"
  },
  {
    "text": "dig further into this but this is a fascinating topic actually to give you an idea of the scale of our platform we",
    "start": "1947630",
    "end": "1954770"
  },
  {
    "text": "have hundreds of data streams and combine to generate millions of of events per second or gigabytes per",
    "start": "1954770",
    "end": "1961880"
  },
  {
    "text": "second so this is a high-level overview of the architecture of headwaters it's",
    "start": "1961880",
    "end": "1969290"
  },
  {
    "start": "1964000",
    "end": "2055000"
  },
  {
    "text": "composed of three main groups of component the first one on the upper left is the CICU pipeline created a that",
    "start": "1969290",
    "end": "1976460"
  },
  {
    "text": "uses the AWS services that you typically use to build a cloud native application it creates the headwaters control plane",
    "start": "1976460",
    "end": "1985310"
  },
  {
    "text": "which is essentially based on that pattern with API gateway Linda and",
    "start": "1985310",
    "end": "1990800"
  },
  {
    "text": "dynamodb we use other services where it makes sense such as SSM or is our SES and also for",
    "start": "1990800",
    "end": "1998000"
  },
  {
    "text": "troubleshooting and monitoring we use GLAAD trail cloud watch and x-ray now this control plan is",
    "start": "1998000",
    "end": "2004330"
  },
  {
    "text": "the the one that creates the datastream so obviously the data streams are mostly focused around kinases but also we",
    "start": "2004330",
    "end": "2012610"
  },
  {
    "text": "create an SNS topic that we associate with each one of the data stream so that the stakeholders of the stream have a",
    "start": "2012610",
    "end": "2020010"
  },
  {
    "text": "communication channel to communicate about that particular stream so the",
    "start": "2020010",
    "end": "2027340"
  },
  {
    "text": "stakeholders of the stream are us the platform the data producer and the data",
    "start": "2027340",
    "end": "2032410"
  },
  {
    "text": "consumers so for example if we detect that there's no data in coming into the particular stream we may raise an alert",
    "start": "2032410",
    "end": "2039040"
  },
  {
    "text": "on that topic or if the data producer is going is planning to perform some",
    "start": "2039040",
    "end": "2044710"
  },
  {
    "text": "maintenance on the the producing application that may impact the availability of the data in a that team",
    "start": "2044710",
    "end": "2052330"
  },
  {
    "text": "may use that topic to communicate that so in order to understand better how our",
    "start": "2052330",
    "end": "2059050"
  },
  {
    "start": "2055000",
    "end": "2112000"
  },
  {
    "text": "platform works this is a flow diagram of how a data producer is going to create a",
    "start": "2059050",
    "end": "2064659"
  },
  {
    "text": "stream so first the data producer requests the creation of the stream to",
    "start": "2064660",
    "end": "2070840"
  },
  {
    "text": "Arlanda function we add way the nanda function is going to create the appropriate resources the kinases stream",
    "start": "2070840",
    "end": "2077290"
  },
  {
    "text": "and the SNS topic and also is going to register the user to that SNS topic then",
    "start": "2077290",
    "end": "2083409"
  },
  {
    "text": "it's going to use I am to grant the appropriate permission to the user and",
    "start": "2083410",
    "end": "2089010"
  },
  {
    "text": "finally we will send a welcome email with further instructions on how to proceed at this point the data producer",
    "start": "2089010",
    "end": "2095620"
  },
  {
    "text": "can write data to the kinases stream can monitor the streams using cat watch metrics and communicate with the other",
    "start": "2095620",
    "end": "2101500"
  },
  {
    "text": "stakeholders so now let's see five considerations",
    "start": "2101500",
    "end": "2108640"
  },
  {
    "text": "that I think you should keep in mind when scaling a kinases stream number one the data producer limit so and I just",
    "start": "2108640",
    "end": "2117820"
  },
  {
    "start": "2112000",
    "end": "2206000"
  },
  {
    "text": "went through that do you remember what those two limits there are two limits hard limits that",
    "start": "2117820",
    "end": "2123160"
  },
  {
    "text": "you cannot change about the data producer do you remember what those are",
    "start": "2123160",
    "end": "2128170"
  },
  {
    "text": "the two limits yeah so the one megabyte",
    "start": "2128170",
    "end": "2134560"
  },
  {
    "text": "per second per shard and 1,000 put requests per second Shawn so let's see how this translates",
    "start": "2134560",
    "end": "2140020"
  },
  {
    "text": "into a real-life scenario a real-life use case Comcast users can watch TV live",
    "start": "2140020",
    "end": "2147820"
  },
  {
    "text": "TV or on-demand movies through the Internet that's video over IP and there's a",
    "start": "2147820",
    "end": "2153250"
  },
  {
    "text": "number of devices that they use to do that whether mobile devices such as iOS",
    "start": "2153250",
    "end": "2159220"
  },
  {
    "text": "Android desktop application or IP set-top boxes all those devices reports",
    "start": "2159220",
    "end": "2165700"
  },
  {
    "text": "analytics data back to our platform in a single stream and this is one of the",
    "start": "2165700",
    "end": "2171010"
  },
  {
    "text": "most valuable streams that we have within Comcast there are literally a dozen different teams that are consuming",
    "start": "2171010",
    "end": "2177580"
  },
  {
    "text": "from this data set and the range from business intelligence group wanted to report usage of the of the service to",
    "start": "2177580",
    "end": "2185740"
  },
  {
    "text": "operations team who needs to monitor specific part of the system to data scientists to data engineer who may",
    "start": "2185740",
    "end": "2193060"
  },
  {
    "text": "process the data as it streamed through so they may filter unread or session",
    "start": "2193060",
    "end": "2199390"
  },
  {
    "text": "eyes the data and they usually send the data back onto our platform so this is",
    "start": "2199390",
    "end": "2207790"
  },
  {
    "start": "2206000",
    "end": "2276000"
  },
  {
    "text": "what the actual usage of the stream looks like you see the bandwidth or throughput over four days so as you may",
    "start": "2207790",
    "end": "2215380"
  },
  {
    "text": "expect you have the the usage going up and down as people our users watch more",
    "start": "2215380",
    "end": "2222880"
  },
  {
    "text": "TV throughout the day the users increase and it Peaks around dinnertime and a little bit after that and then falls",
    "start": "2222880",
    "end": "2229330"
  },
  {
    "text": "back down when users go to sleep so with a little bit of history you can easily",
    "start": "2229330",
    "end": "2234730"
  },
  {
    "text": "compute the average and the maximum vent weighs what I would like to draw your attention to or those many ways search",
    "start": "2234730",
    "end": "2241990"
  },
  {
    "text": "that you see and those happens because we have hundreds of cells and millions",
    "start": "2241990",
    "end": "2248050"
  },
  {
    "text": "of devices reporting analytics datum and they may react to a particular event and",
    "start": "2248050",
    "end": "2255280"
  },
  {
    "text": "generate a surge of traffic like that for example an es alert would trigger",
    "start": "2255280",
    "end": "2261790"
  },
  {
    "text": "such an event or if you have popular shows say the the game of in the",
    "start": "2261790",
    "end": "2269300"
  },
  {
    "text": "latest episode of Game of Thrones or the Superbowl might have search of traffic",
    "start": "2269300",
    "end": "2275660"
  },
  {
    "text": "like this so when you think about the 1 megabyte per second per short limit you",
    "start": "2275660",
    "end": "2281930"
  },
  {
    "start": "2276000",
    "end": "2462000"
  },
  {
    "text": "have a choice here what Ben was are you going to use and this drives to what I",
    "start": "2281930",
    "end": "2288080"
  },
  {
    "text": "call this back pressure scale where you have to use at the minimum the average",
    "start": "2288080",
    "end": "2293780"
  },
  {
    "text": "pathways and you can use all the way to the maximum and ways if you use the maximum ven ways you'll see it's going",
    "start": "2293780",
    "end": "2300470"
  },
  {
    "text": "to be a little more expensive because you have more shards but if you used average bent ways you'll have more",
    "start": "2300470",
    "end": "2307100"
  },
  {
    "text": "latency in your data now dealing with back pressure is actually pretty difficult and expensive so you have to",
    "start": "2307100",
    "end": "2314990"
  },
  {
    "text": "consider the whole picture when you're looking at the cost and so I would strongly advise you to look at the",
    "start": "2314990",
    "end": "2321230"
  },
  {
    "text": "maximum bandwidth for the period of time that you're dealing with if you whether you whatever Ben was you",
    "start": "2321230",
    "end": "2330260"
  },
  {
    "text": "use you need to deal with back pressure because you can always have a new usage",
    "start": "2330260",
    "end": "2336320"
  },
  {
    "text": "that goes over your historical maximum so you have to deal with that if you don't guess what happens you get",
    "start": "2336320",
    "end": "2344330"
  },
  {
    "text": "exceptions right and you're most likely to lose data so this drives us to the first slide",
    "start": "2344330",
    "end": "2351860"
  },
  {
    "text": "with the formulas because you have those two limitations you have two formulas when you look at those two together you",
    "start": "2351860",
    "end": "2358040"
  },
  {
    "text": "see that if your messages on average are smaller than when one kilobyte then the",
    "start": "2358040",
    "end": "2365480"
  },
  {
    "text": "throughput limitation is what's going to drive the number of shots so what you do",
    "start": "2365480",
    "end": "2371450"
  },
  {
    "text": "in that case is it's very well documented in the Kinesis documentation you do record aggregation essentially",
    "start": "2371450",
    "end": "2379070"
  },
  {
    "text": "what you do is you batch records together before sending them to two kinases and kpl does that for you",
    "start": "2379070",
    "end": "2386300"
  },
  {
    "text": "automatically so that will drive you down to the first",
    "start": "2386300",
    "end": "2392480"
  },
  {
    "text": "formula where the the Ben ways is the limiting factor and is driving the number of shards so",
    "start": "2392480",
    "end": "2398250"
  },
  {
    "text": "what you do in that case to lower the number of shots that you see online is to compress the data so the providential",
    "start": "2398250",
    "end": "2404940"
  },
  {
    "text": "part about this particular slide is that as I was writing this very slide a few weeks ago I was contacted by a team",
    "start": "2404940",
    "end": "2411420"
  },
  {
    "text": "within Comcast who had a problem they were seeing exceptions on their stream",
    "start": "2411420",
    "end": "2417270"
  },
  {
    "text": "and they keep scaling up and scaling up their stream until they reach 700 shots and they were concerned about the price",
    "start": "2417270",
    "end": "2424650"
  },
  {
    "text": "of running that stream so I looked at their stream and sure enough they were generating a lot of small messages so I",
    "start": "2424650",
    "end": "2432990"
  },
  {
    "text": "gave them the two advices the two pieces of advice that I just gave you aggregate the record compress the data and they",
    "start": "2432990",
    "end": "2441060"
  },
  {
    "text": "were able to drive down the the need for the number of shards from 700 to 80 and",
    "start": "2441060",
    "end": "2446280"
  },
  {
    "text": "more importantly the cost of running their stream they saved about two",
    "start": "2446280",
    "end": "2451320"
  },
  {
    "text": "hundred thousand dollars per year so I hope that those advice this advice is",
    "start": "2451320",
    "end": "2457020"
  },
  {
    "text": "gonna be as beneficial to you as a West for them now consideration number two",
    "start": "2457020",
    "end": "2466520"
  },
  {
    "start": "2462000",
    "end": "2604000"
  },
  {
    "text": "limit on the consumer side so again anin talked about that do you guys remember",
    "start": "2466520",
    "end": "2471750"
  },
  {
    "text": "what those are the two limits right so",
    "start": "2471750",
    "end": "2479900"
  },
  {
    "text": "the first one is that the consumers as a whole as a group are going to share two",
    "start": "2479900",
    "end": "2487950"
  },
  {
    "text": "megabytes per second per Shawn and similarly to the producer this gives us this formula now the second limit is",
    "start": "2487950",
    "end": "2495690"
  },
  {
    "text": "that the consumers again as a group may not consume may not request more than",
    "start": "2495690",
    "end": "2500970"
  },
  {
    "text": "five get requests per second and so this is problematic because you cannot solve",
    "start": "2500970",
    "end": "2507120"
  },
  {
    "text": "that particular limit by increasing the number of shots that's because it's it's",
    "start": "2507120",
    "end": "2514920"
  },
  {
    "text": "related to the frequency at which you queried those charts no matter how many they are so you have two groups of",
    "start": "2514920",
    "end": "2522300"
  },
  {
    "text": "solutions to this problem the first one on one side is to try to solve this problem on the",
    "start": "2522300",
    "end": "2528150"
  },
  {
    "text": "an application side so if you control all the consumers if you can dynamically",
    "start": "2528150",
    "end": "2535890"
  },
  {
    "text": "adjust the frequency at which you request district the get record for the",
    "start": "2535890",
    "end": "2540960"
  },
  {
    "text": "string and if your consumers are aware of the other consumers in the group then",
    "start": "2540960",
    "end": "2547680"
  },
  {
    "text": "you can solve that problem so as you can see this is pretty challenging to do and also this is naive anyway because you",
    "start": "2547680",
    "end": "2555720"
  },
  {
    "text": "can still have a consumer that would be a rogue consumer that hugs all those",
    "start": "2555720",
    "end": "2561450"
  },
  {
    "text": "requests per second and basically performs a denial of service attack on your stream so the other categories of",
    "start": "2561450",
    "end": "2568980"
  },
  {
    "text": "solution is to have a different architecture on the server side so one",
    "start": "2568980",
    "end": "2575640"
  },
  {
    "text": "of the ways you solve that is to create a copy stream a slave string you do that by using lambda or kenosis analytics and",
    "start": "2575640",
    "end": "2584130"
  },
  {
    "text": "you spread the consumers across those two strings the downside of the solution",
    "start": "2584130",
    "end": "2589710"
  },
  {
    "text": "is that the reliability of the slave stream is lower than the master stream",
    "start": "2589710",
    "end": "2595349"
  },
  {
    "text": "so you can think about other architectures that you can create in order to solve that problem",
    "start": "2595349",
    "end": "2603500"
  },
  {
    "start": "2604000",
    "end": "2805000"
  },
  {
    "text": "now consideration number three is to look at how Canisius actually works on",
    "start": "2604099",
    "end": "2609990"
  },
  {
    "text": "to scale with stream up and down so let me illustrate that with an example",
    "start": "2609990",
    "end": "2616400"
  },
  {
    "text": "imagine that you have a stream that has three shorts and a data retention of wente Kinesis has only two operations",
    "start": "2616400",
    "end": "2624750"
  },
  {
    "text": "that he can do it can either split a stream into two or merge two stream to",
    "start": "2624750",
    "end": "2632220"
  },
  {
    "text": "short sorry into one so I imagine that",
    "start": "2632220",
    "end": "2637230"
  },
  {
    "text": "on day three you split shot one into short three and four short one at this",
    "start": "2637230",
    "end": "2643140"
  },
  {
    "text": "point is going to be closed so you won't you will not be charged for that",
    "start": "2643140",
    "end": "2648150"
  },
  {
    "text": "particular shot however however the data",
    "start": "2648150",
    "end": "2653910"
  },
  {
    "text": "that it had been receiving up until that point or still stored onto that shard",
    "start": "2653910",
    "end": "2659069"
  },
  {
    "text": "and they're going to be stored for the duration of the retention period",
    "start": "2659069",
    "end": "2664600"
  },
  {
    "text": "right so on only 24 hours after you you",
    "start": "2664600",
    "end": "2670450"
  },
  {
    "text": "do that split operation the stream is going to actually remove short one and",
    "start": "2670450",
    "end": "2677710"
  },
  {
    "text": "you're gonna end up with four short string so let's talk about something a",
    "start": "2677710",
    "end": "2683680"
  },
  {
    "text": "little different here how does kinases know what shard to",
    "start": "2683680",
    "end": "2689560"
  },
  {
    "text": "write the data to you guys know it uses",
    "start": "2689560",
    "end": "2696730"
  },
  {
    "text": "the key right so when you send a piece of data to kinases it you send the data",
    "start": "2696730",
    "end": "2703990"
  },
  {
    "text": "associated with a key and based on that key it will it will determine which",
    "start": "2703990",
    "end": "2709600"
  },
  {
    "text": "shard the data is going to so there are two types of keys either your key is",
    "start": "2709600",
    "end": "2715390"
  },
  {
    "text": "perfectly balancing the the data amongst all the shards or it's not if it's not",
    "start": "2715390",
    "end": "2721600"
  },
  {
    "text": "what's going to happen is that some of the shards is going to receive more data than the others and this is going to",
    "start": "2721600",
    "end": "2727690"
  },
  {
    "text": "create hot shot's in that case you want to split those particular shard the goal",
    "start": "2727690",
    "end": "2733720"
  },
  {
    "text": "being that the each shard received the same amount of data as much as possible so this is a little difficult to manage",
    "start": "2733720",
    "end": "2742150"
  },
  {
    "text": "actually and unless you have a good reason to do that I would recommend you to use a key that spreads the data",
    "start": "2742150",
    "end": "2748300"
  },
  {
    "text": "evenly across the shards and if that's the case what you want to do is use that",
    "start": "2748300",
    "end": "2753430"
  },
  {
    "text": "update short count operation that Kinesis provides and it's a convenience",
    "start": "2753430",
    "end": "2758620"
  },
  {
    "text": "method that basically uses those split merge operations that I mentioned in",
    "start": "2758620",
    "end": "2764650"
  },
  {
    "text": "order to create the number of shot the appropriate number of shots and maintain an equal portion of the key space for",
    "start": "2764650",
    "end": "2771760"
  },
  {
    "text": "each one of those shots and so if you observe kinases scaling from 3 shards to",
    "start": "2771760",
    "end": "2778300"
  },
  {
    "text": "5 shards you see that it goes through a bunch of steps actually following this pattern of split split merge split split",
    "start": "2778300",
    "end": "2785410"
  },
  {
    "text": "merge until it creates the shards that are needed so",
    "start": "2785410",
    "end": "2792320"
  },
  {
    "text": "as you can see it creates a number of temporary chard and because those",
    "start": "2792320",
    "end": "2797640"
  },
  {
    "text": "operation are synchronous you see that it may take some time especially if you",
    "start": "2797640",
    "end": "2802950"
  },
  {
    "text": "have a lot more shorts than this so now let's see consideration number for the consumption speed so it's",
    "start": "2802950",
    "end": "2809940"
  },
  {
    "start": "2805000",
    "end": "2898000"
  },
  {
    "text": "unfortunate but in my experience it happens from time to time that the consumer comes to you and says I cannot",
    "start": "2809940",
    "end": "2817710"
  },
  {
    "text": "process the data fast enough you need to scale up the data stream so obviously the and that's because they",
    "start": "2817710",
    "end": "2825390"
  },
  {
    "text": "have data processing on their side that is taking a lot longer than and so",
    "start": "2825390",
    "end": "2832320"
  },
  {
    "text": "creating a bottleneck so the appropriate solution to this problem is to reorder TechEd the consumer so that you",
    "start": "2832320",
    "end": "2839460"
  },
  {
    "text": "basically take that bottleneck into a second layer that can scale independently from the layer that is",
    "start": "2839460",
    "end": "2846660"
  },
  {
    "text": "consuming from Kinesis so in the example that i havent decide each so you have a",
    "start": "2846660",
    "end": "2852540"
  },
  {
    "text": "three short stream each shard is receiving a thousand message per second but consumer number two can only consume",
    "start": "2852540",
    "end": "2858990"
  },
  {
    "text": "500 shots 500 message per second and so because the stream has three shots the",
    "start": "2858990",
    "end": "2865320"
  },
  {
    "text": "consumer is bounded by having three consumer processes so again the solution",
    "start": "2865320",
    "end": "2872190"
  },
  {
    "text": "here is to really tag consumer to but the thing is that this takes time and so",
    "start": "2872190",
    "end": "2879330"
  },
  {
    "text": "in the meantime you may have to scale the stream to comply with the request of",
    "start": "2879330",
    "end": "2884760"
  },
  {
    "text": "that particular consumer but the good thing is that you can put a price tag on",
    "start": "2884760",
    "end": "2890130"
  },
  {
    "text": "how much discussed and then you can charge this particular consumer as an incentive to do the work and so this",
    "start": "2890130",
    "end": "2899430"
  },
  {
    "start": "2898000",
    "end": "3057000"
  },
  {
    "text": "drives you to this formula that basically you have to compute for every consumers look at how many shorts each",
    "start": "2899430",
    "end": "2904800"
  },
  {
    "text": "one of them need so now the fifth and last consideration is what I call the",
    "start": "2904800",
    "end": "2911430"
  },
  {
    "text": "acceptable data latency and there are different cases where this can happen",
    "start": "2911430",
    "end": "2917790"
  },
  {
    "text": "the one that I that I illustrate here on this diagram are the surge",
    "start": "2917790",
    "end": "2923530"
  },
  {
    "text": "many ways that I showed you at the beginning of the of the presentation the",
    "start": "2923530",
    "end": "2928690"
  },
  {
    "text": "red line is the producer producing data and the blue line is the consumer",
    "start": "2928690",
    "end": "2934690"
  },
  {
    "text": "consuming the data and because of this particular scenarios with those numbers",
    "start": "2934690",
    "end": "2939880"
  },
  {
    "text": "here the consumers are bounded by a",
    "start": "2939880",
    "end": "2945360"
  },
  {
    "text": "consumption throughput that is lower than what the producer can will produce",
    "start": "2945360",
    "end": "2950680"
  },
  {
    "text": "and therefore the data the consumer is going to is going to start lagging the",
    "start": "2950680",
    "end": "2956170"
  },
  {
    "text": "data is going to have more and more delay more and more latency so the",
    "start": "2956170",
    "end": "2963820"
  },
  {
    "text": "difference between the end of the surge and when the consumer catches up is going to be the maximum latency that the",
    "start": "2963820",
    "end": "2970990"
  },
  {
    "text": "data is going to have that the consumer is going to see and the point I'm trying to make here is that you can compute the",
    "start": "2970990",
    "end": "2978760"
  },
  {
    "text": "number of shots that you need if the consumer have an SLA if the consumer",
    "start": "2978760",
    "end": "2984040"
  },
  {
    "text": "have specific requirements on how much that data a latency can be at the",
    "start": "2984040",
    "end": "2989110"
  },
  {
    "text": "maximum so in this slide I named some variables and that leads us to this",
    "start": "2989110",
    "end": "2995890"
  },
  {
    "text": "particular formula and that loose complicated it's really not that you can",
    "start": "2995890",
    "end": "3002010"
  },
  {
    "text": "use to plug the numbers to see how many shots you need to comply with",
    "start": "3002010",
    "end": "3007110"
  },
  {
    "text": "requirements such as this there are two other contexts where there are similar",
    "start": "3007110",
    "end": "3014190"
  },
  {
    "text": "to that if a consumer if a consumer is unavailable for some time and suddenly",
    "start": "3014190",
    "end": "3022200"
  },
  {
    "text": "comes back up it will need time it will accumulate some lags and it will need time to catch up with the real time",
    "start": "3022200",
    "end": "3029220"
  },
  {
    "text": "stream and again you can compute how long this is going to take based on various input variables and most",
    "start": "3029220",
    "end": "3036090"
  },
  {
    "text": "importantly the number of shots the other cases where this happens that's similar to this is if a consumer is",
    "start": "3036090",
    "end": "3043350"
  },
  {
    "text": "trying to reprocess pass the data and again you can compute the rate at which that consumer is going to consume data",
    "start": "3043350",
    "end": "3050670"
  },
  {
    "text": "so for example it may need 10 it's to process an hour of data so with",
    "start": "3050670",
    "end": "3058799"
  },
  {
    "start": "3057000",
    "end": "3155000"
  },
  {
    "text": "that let's see what the new enhanced valid consumer changes these pictures",
    "start": "3058799",
    "end": "3064339"
  },
  {
    "text": "so as an unmentioned and explain a fan at consumer have basically a dedicated",
    "start": "3064339",
    "end": "3071549"
  },
  {
    "text": "two megabytes per second per shark and essentially what that does is that it isolates this consumer from the other",
    "start": "3071549",
    "end": "3078839"
  },
  {
    "text": "consumers so what this does not change is the fact that Kinesis chillin forces",
    "start": "3078839",
    "end": "3086339"
  },
  {
    "text": "limits on the data producer that kinases still works the way it does by splitting",
    "start": "3086339",
    "end": "3091920"
  },
  {
    "text": "and merging shards together and it doesn't change the consumption speed because the bottleneck is not in terms",
    "start": "3091920",
    "end": "3101160"
  },
  {
    "text": "of the consumer reading the data from Kinesis but it's a little bit further down the stream with what this does",
    "start": "3101160",
    "end": "3108569"
  },
  {
    "text": "change however is obviously the fact that the detect consumption limits are",
    "start": "3108569",
    "end": "3114839"
  },
  {
    "text": "affected so the fan up consumers have seen no limits because they can consume",
    "start": "3114839",
    "end": "3120779"
  },
  {
    "text": "twice as fast as the producer can produce and it changes also the other consumers the regular consumers because",
    "start": "3120779",
    "end": "3128609"
  },
  {
    "text": "now they have a smaller pool of consumers that they have to share that two megabytes per second bandwidth with",
    "start": "3128609",
    "end": "3136489"
  },
  {
    "text": "similarily it changes the maximum acceptable latency and for the same reason again",
    "start": "3136489",
    "end": "3143910"
  },
  {
    "text": "the fan at consumers will see no lag and the regular consumer have a small pool of consumers to share the two megabytes",
    "start": "3143910",
    "end": "3151679"
  },
  {
    "text": "per second with so this is the",
    "start": "3151679",
    "end": "3159769"
  },
  {
    "start": "3155000",
    "end": "3208000"
  },
  {
    "text": "calculator that we implemented it is open source I would encourage you to go",
    "start": "3159769",
    "end": "3165119"
  },
  {
    "text": "check it out basically what it is is it's a web form in which you input the numbers that",
    "start": "3165119",
    "end": "3171539"
  },
  {
    "text": "describe your Akina stream and things such as the average message size the",
    "start": "3171539",
    "end": "3178410"
  },
  {
    "text": "average food the maximum throughput etc and it's going to recommend the optimal number of shots that your stream should",
    "start": "3178410",
    "end": "3185579"
  },
  {
    "text": "have it also is going to give you a cuss estimate for how much the stream is",
    "start": "3185579",
    "end": "3191700"
  },
  {
    "text": "going to cost you and also it supports the new enhanced valid consumer and it",
    "start": "3191700",
    "end": "3197340"
  },
  {
    "text": "will also provide you an estimate for how much running a specific and hence",
    "start": "3197340",
    "end": "3203760"
  },
  {
    "text": "valid consumer will cast in this particular context so in conclusion I",
    "start": "3203760",
    "end": "3211950"
  },
  {
    "start": "3208000",
    "end": "3600000"
  },
  {
    "text": "hope that this presentation has given you a framework to think through how to",
    "start": "3211950",
    "end": "3217830"
  },
  {
    "text": "scale Akina stream again the considerations to keep in mind or the producer limit the consumer limits the",
    "start": "3217830",
    "end": "3225660"
  },
  {
    "text": "way Kinesis scales a data stream the consumption spin and the maximum",
    "start": "3225660",
    "end": "3232440"
  },
  {
    "text": "acceptable latency with that I thank you",
    "start": "3232440",
    "end": "3238470"
  },
  {
    "text": "for attending this talk and if you have any questions for either Anna or I would",
    "start": "3238470",
    "end": "3244560"
  },
  {
    "text": "be pleased to answer them thank you [Applause]",
    "start": "3244560",
    "end": "3255190"
  },
  {
    "text": "yeah there's a microphone if you don't mind step into the microphone hello so in one of the previous sessions I was",
    "start": "3255190",
    "end": "3262100"
  },
  {
    "text": "told that a shard should ideally be matching with one V CPU to make it",
    "start": "3262100",
    "end": "3268610"
  },
  {
    "text": "efficient is that what you noticed also could you repeat that I'm sorry",
    "start": "3268610",
    "end": "3274610"
  },
  {
    "text": "so shard when we are like building up - are the number of shards so ideally one",
    "start": "3274610",
    "end": "3281090"
  },
  {
    "text": "shard should match to one C V CPU if you're concerned all heard that with the",
    "start": "3281090",
    "end": "3287330"
  },
  {
    "text": "KCl if you're building a consuming applications using the KCl then",
    "start": "3287330",
    "end": "3292660"
  },
  {
    "text": "essentially a thread will be lease will be obtained a shard lease so it makes",
    "start": "3292660",
    "end": "3299660"
  },
  {
    "text": "the most sense for optimization of CPUs and shards so that makes a lot of sense",
    "start": "3299660",
    "end": "3305300"
  },
  {
    "text": "it's not required but that would be the optimal way to do that so you may also",
    "start": "3305300",
    "end": "3310310"
  },
  {
    "text": "consider having multiple hosts process the same stream so if you have a very",
    "start": "3310310",
    "end": "3315800"
  },
  {
    "text": "large team for example with let's just say four hundred shards and you try to",
    "start": "3315800",
    "end": "3320960"
  },
  {
    "text": "consume that with one single host you're not going to get a box with a 400 V CPU so you'll have to spread that across",
    "start": "3320960",
    "end": "3326480"
  },
  {
    "text": "multiple multiple hosts multiple ec2 instances but the KCl will manage the",
    "start": "3326480",
    "end": "3332840"
  },
  {
    "text": "distribution across the different hosts",
    "start": "3332840",
    "end": "3336520"
  },
  {
    "text": "related to the topic of the spreading over multiple hosts with the enhanced fan-out is the to make per second",
    "start": "3338990",
    "end": "3345440"
  },
  {
    "text": "limited to unique consumer or is it spread across the application that is load balancing across those hosts it is",
    "start": "3345440",
    "end": "3352130"
  },
  {
    "text": "specific for the shard so typically the the the conceal consumer record",
    "start": "3352130",
    "end": "3360080"
  },
  {
    "text": "processor so similar to that question where there is a thread that is leased to a given shard its specific to that to",
    "start": "3360080",
    "end": "3367190"
  },
  {
    "text": "that individual that individual record processor for that singular consumer",
    "start": "3367190",
    "end": "3372890"
  },
  {
    "text": "application so another consumer application that might come online would get it's another record processor and it",
    "start": "3372890",
    "end": "3378770"
  },
  {
    "text": "would get its own 2 Meg's per second egress but off of a different shard now on the same chart on the same showcases",
    "start": "3378770",
    "end": "3384650"
  },
  {
    "text": "every time out then every time a consuming application registers every",
    "start": "3384650",
    "end": "3390680"
  },
  {
    "text": "shard in the stream gets another 2 Meg's per second specifically for that",
    "start": "3390680",
    "end": "3395810"
  },
  {
    "text": "application even when you're using a shared application group in the load balancing method rather than the multiple unique consumers method well",
    "start": "3395810",
    "end": "3402710"
  },
  {
    "text": "every time at application every time the consumer application calls the register",
    "start": "3402710",
    "end": "3408550"
  },
  {
    "text": "stream consumer API which it has to do ok every consuming app consumer application has to make that API call",
    "start": "3408550",
    "end": "3414859"
  },
  {
    "text": "because we give it an AR n we give it a unique ID once that's done we create we",
    "start": "3414859",
    "end": "3420290"
  },
  {
    "text": "provision resources in the stream that gives that particular consuming application 2 Meg's per second specific",
    "start": "3420290",
    "end": "3427820"
  },
  {
    "text": "to it which is independent of any of the older consumers who might also be calling the get records if you have",
    "start": "3427820",
    "end": "3433760"
  },
  {
    "text": "older consumers who are calling the get records operation they're still going to be limited to the 2 Meg's per second",
    "start": "3433760",
    "end": "3439430"
  },
  {
    "text": "across all consumers who are calling get records so only that 2 Meg's pipe if you",
    "start": "3439430",
    "end": "3444740"
  },
  {
    "text": "want to call it that is dedicated to your new efo and hands fan-out consumer",
    "start": "3444740",
    "end": "3450260"
  },
  {
    "text": "ok and for the enhanced fan-out where is the data persisted I know in their in",
    "start": "3450260",
    "end": "3456410"
  },
  {
    "text": "the regular consumers the KCl uses dynamo to persist the position per Shire per unique consumer application that",
    "start": "3456410",
    "end": "3462800"
  },
  {
    "text": "hasn't changed that's that's still promoting dynamo just looks slightly different yeah the checkpointing implementation is is exactly the same",
    "start": "3462800",
    "end": "3470560"
  },
  {
    "text": "yep oh yeah I we use the kpl and get a",
    "start": "3470560",
    "end": "3475960"
  },
  {
    "text": "lot of performance improvements for the record compaction as it puts it onto the",
    "start": "3475960",
    "end": "3481090"
  },
  {
    "text": "queue if we go serverless with lambda is the kpl still gonna work that way",
    "start": "3481090",
    "end": "3486150"
  },
  {
    "text": "there is a there is a library that you can use in your lambda function that",
    "start": "3486150",
    "end": "3492550"
  },
  {
    "text": "will essentially D aggregate the records that were aggregated by the kpl right",
    "start": "3492550",
    "end": "3499840"
  },
  {
    "text": "but that's on the consumer side I'm concerned about the producer side well",
    "start": "3499840",
    "end": "3505570"
  },
  {
    "text": "you tell lambda for producer I'm sorry I misunderstood same thing the library can I also aggregate the the messages",
    "start": "3505570",
    "end": "3512800"
  },
  {
    "text": "together before sending them yeah okay now you don't get it's the what it will do is create the same aggregation",
    "start": "3512800",
    "end": "3518260"
  },
  {
    "text": "structure but it's still a little different than running the kpl locally on a host because the KPI locally on a",
    "start": "3518260",
    "end": "3523720"
  },
  {
    "text": "host does a lot of buffering because it's running a separate process in the",
    "start": "3523720",
    "end": "3529240"
  },
  {
    "text": "background like a c++ based process yeah which has a local buffer has a lot of",
    "start": "3529240",
    "end": "3534730"
  },
  {
    "text": "the back off and retry capability already built in this library will allow",
    "start": "3534730",
    "end": "3539950"
  },
  {
    "text": "you to use lambda to create the same structure but you lose some of the benefits that you might get from running",
    "start": "3539950",
    "end": "3546040"
  },
  {
    "text": "like a long-running process that the kpl provides if you're running it natively okay thank you okay",
    "start": "3546040",
    "end": "3552690"
  },
  {
    "text": "for for the efo case and the limits that you guys were talking about those",
    "start": "3552690",
    "end": "3558880"
  },
  {
    "text": "numbers apply whether you're using the kpl and having aggregated messages or not right so it's like a thousand per",
    "start": "3558880",
    "end": "3565570"
  },
  {
    "text": "second that's a thousand aggregated or individual messages if I wasn't using the kpl yeah the thousand records per",
    "start": "3565570",
    "end": "3571270"
  },
  {
    "text": "second when you do aggregation with the kpl from the Kinesis streams per sec perspective it just sees even if you",
    "start": "3571270",
    "end": "3577480"
  },
  {
    "text": "aggregate you know a hundred of your records into a single Kinesis record",
    "start": "3577480",
    "end": "3585150"
  },
  {
    "text": "that appears as a single record in Kinesis and you could send a thousand of those over the wire before you'd be",
    "start": "3585150",
    "end": "3591880"
  },
  {
    "text": "throttled by the Kinesis front end so Kinesis itself the service does not know",
    "start": "3591880",
    "end": "3597370"
  },
  {
    "text": "that there's any aggregation going on this is just the buffer the only things that know about this aggregation are the",
    "start": "3597370",
    "end": "3603310"
  },
  {
    "text": "producer and the consumer except from the Kinesis streams perspective it's just a record just happens to be made up of aggregated and",
    "start": "3603310",
    "end": "3610359"
  },
  {
    "text": "smaller records right okay and then from the KCl side I know that there's a way you can set like max records fetched eat",
    "start": "3610359",
    "end": "3617019"
  },
  {
    "text": "with each get that's again referring to like Kinesis messages yes which would be aggregated which may be",
    "start": "3617019",
    "end": "3623349"
  },
  {
    "text": "made up of hundreds of your actual user records that the producer created right which depends on the load of course",
    "start": "3623349",
    "end": "3629829"
  },
  {
    "text": "because it because the kpl doesn't have like a fixed aggregation factor right it's just sort of I think it's like five",
    "start": "3629829",
    "end": "3636160"
  },
  {
    "text": "megabytes or every so often it will just ship them right so yeah the KPM well you had it's not going to a grenade on the",
    "start": "3636160",
    "end": "3643359"
  },
  {
    "text": "maximum amount of records that can go into a single put which is a megabyte so there is a limit in what it does know",
    "start": "3643359",
    "end": "3650170"
  },
  {
    "text": "where to stop aggregating and you do have some properties in the kpl that say i only want to aggregate 200 records max",
    "start": "3650170",
    "end": "3657489"
  },
  {
    "text": "even though that's well below that one Meg you can you can still make that property setting okay I'm sorry",
    "start": "3657489",
    "end": "3665369"
  },
  {
    "text": "one Meg compressed its if we don't care",
    "start": "3665369",
    "end": "3670599"
  },
  {
    "text": "so it's one Meg of binary data so if that's two Meg's of your own data that you've compressed using gzip down to one",
    "start": "3670599",
    "end": "3676450"
  },
  {
    "text": "Meg before you send it that's fine by us as long as your consumer knows how to unzip it yep so AWS me launched a",
    "start": "3676450",
    "end": "3686380"
  },
  {
    "text": "managed Kafka service today that's that compared to Kinesis when might you want to use one I was waiting",
    "start": "3686380",
    "end": "3691839"
  },
  {
    "text": "for that question so I hope you guys heard that so yeah today we announced",
    "start": "3691839",
    "end": "3698160"
  },
  {
    "text": "Amazon managed streaming for Kafka so Kinesis is not it's it's owned and built",
    "start": "3698160",
    "end": "3705009"
  },
  {
    "text": "by the same team that built Kinesis the Kinesis will continue to evolve",
    "start": "3705009",
    "end": "3711880"
  },
  {
    "text": "independently the the reason we built that new service one of the main reasons was we have a lot of customers who are",
    "start": "3711880",
    "end": "3718359"
  },
  {
    "text": "using Kafka today in the data center or E or even an AC ec2 and we've worked",
    "start": "3718359",
    "end": "3725440"
  },
  {
    "text": "with them to consider moving to Kinesis but they're like we just have too much invested from a development standpoint a",
    "start": "3725440",
    "end": "3733059"
  },
  {
    "text": "lot of code a lot of operations that we just know what we're doing and we would love for you to manage some of",
    "start": "3733059",
    "end": "3738930"
  },
  {
    "text": "that for us but we're just not interested in a migration at this point because we're using some features that you don't support log compaction is a",
    "start": "3738930",
    "end": "3745440"
  },
  {
    "text": "good example you can do in Kafka you can't in the Kinesis so in order to get those customers kind of a nice managed",
    "start": "3745440",
    "end": "3753150"
  },
  {
    "text": "solution for their environment that was the genesis for managed Kafka yeah this",
    "start": "3753150",
    "end": "3758880"
  },
  {
    "text": "is great what I would add to that is that kefka and Canisius are really two different ecosystems you have different",
    "start": "3758880",
    "end": "3764610"
  },
  {
    "text": "tools and indeed teams have a lot of work that they that they put into their",
    "start": "3764610",
    "end": "3771900"
  },
  {
    "text": "application in order to get to where they are so you know it's good to have those two options I think this is great",
    "start": "3771900",
    "end": "3778830"
  },
  {
    "text": "and we just run out of time as we are getting hooked from the stage so thank",
    "start": "3778830",
    "end": "3784170"
  },
  {
    "text": "you all very much",
    "start": "3784170",
    "end": "3786650"
  }
]
[
  {
    "start": "0",
    "end": "25000"
  },
  {
    "text": "my name is Rick Houlihan I am a principal TPM a technical product manager I work on the database services",
    "start": "6670",
    "end": "13090"
  },
  {
    "text": "team I am actually working on the next generation of dynamodb but we're here today talk to you a little bit about",
    "start": "13090",
    "end": "18730"
  },
  {
    "text": "what we have as far as dynamodb today it's a managed no SQL service offering from Amazon and we'll",
    "start": "18730",
    "end": "25179"
  },
  {
    "start": "25000",
    "end": "25000"
  },
  {
    "text": "talk a little bit about what that means so the first part of the presentation today we'll go through a little bit of a",
    "start": "25179",
    "end": "30279"
  },
  {
    "text": "history of data processing I like to do this with groups that I talk to because it level sets why we're even looking at",
    "start": "30279",
    "end": "36760"
  },
  {
    "text": "no SQL it actually talks a little bit about the history of data processing and and really the fact that we're facing",
    "start": "36760",
    "end": "42340"
  },
  {
    "text": "the same problem today that we faced repeatedly in the past history tends to repeat itself and we'll talk a little bit about why I will get into DynamoDB",
    "start": "42340",
    "end": "49300"
  },
  {
    "text": "internals the table structure API data types indexing structures and whatnot you know scaling and de tomate data",
    "start": "49300",
    "end": "55929"
  },
  {
    "text": "modelling mechanics I will get into design patterns and best practices and I'll leave you with a little bit of",
    "start": "55929",
    "end": "60940"
  },
  {
    "text": "discussion around what we're starting to market as serverless applications or event-driven application development",
    "start": "60940",
    "end": "66520"
  },
  {
    "text": "using dynamodb streams and and dynamodb is a backplane service what is a",
    "start": "66520",
    "end": "72250"
  },
  {
    "start": "72000",
    "end": "72000"
  },
  {
    "text": "database a place to stick stuff okay and that's how most developers start right",
    "start": "72250",
    "end": "78070"
  },
  {
    "text": "we build applications there's a database hey cool I can push things there persist my data I can you know I can relaunch my",
    "start": "78070",
    "end": "83890"
  },
  {
    "text": "app later on it can retrieve the data and I can work with it and we just kind of started using it like a dumping ground right well unfortunately that's",
    "start": "83890",
    "end": "90280"
  },
  {
    "text": "how the data but that's how your application will scale right it will dictate how your application will scale over time so understanding how to use",
    "start": "90280",
    "end": "96820"
  },
  {
    "text": "the database how to use the technology that you're using efficiently is going to drive whether or not you're going to",
    "start": "96820",
    "end": "102909"
  },
  {
    "text": "have to rebuild your entire stack down the road when a million users show up if we look out through the history of",
    "start": "102909",
    "end": "108250"
  },
  {
    "start": "107000",
    "end": "107000"
  },
  {
    "text": "database technology what we see is a repeating situation it peaks and valleys in data what I call data pressure data",
    "start": "108250",
    "end": "115719"
  },
  {
    "text": "pressure is the ability of a system to process the amount of data is being asked to process at a reasonable cost or",
    "start": "115719",
    "end": "121479"
  },
  {
    "text": "at a reasonable timeframe okay so over time we've seen this happen repeatedly throughout history you can call this a",
    "start": "121479",
    "end": "127119"
  },
  {
    "text": "series of high-water marks what happens at these high-water marks these are technology triggers right this where we invent new things write new stuff to do",
    "start": "127119",
    "end": "133810"
  },
  {
    "text": "the work that we are asking our systems to do the first system we had the first database we had was the one between our",
    "start": "133810",
    "end": "138970"
  },
  {
    "text": "year and it was an excellent database right highly available very low latency I have a single single user system questionable",
    "start": "138970",
    "end": "145600"
  },
  {
    "text": "durability zero fault tolerance right you know there's no no backup no but no restore right we didn't like that so we",
    "start": "145600",
    "end": "151720"
  },
  {
    "text": "figured out that you know in order for us to persist the data that we were storing we need to write things down right so we started developing a system",
    "start": "151720",
    "end": "158140"
  },
  {
    "text": "of ledger accounting ledger accounting was really a database right structured data written on written down in tabular",
    "start": "158140",
    "end": "163660"
  },
  {
    "text": "form that drove business and and and infrastructure for millennia right and",
    "start": "163660",
    "end": "169870"
  },
  {
    "text": "really when did that stop that stopped in the 1880 u.s. census timeframe right when Herman Hollerith",
    "start": "169870",
    "end": "175630"
  },
  {
    "text": "was tasked with processing the data of the US Census in 1880 and found it took eight years of the ten-year interval to",
    "start": "175630",
    "end": "182800"
  },
  {
    "text": "process the amount of data they collected in 1880 he realized I need a better system when 1890 rolls around I'm",
    "start": "182800",
    "end": "188650"
  },
  {
    "text": "not gonna be able to get this done in time so he invented the machine readable punch card and you know history of",
    "start": "188650",
    "end": "195250"
  },
  {
    "text": "modern data processing was born so what we're starting to see is a trend right his business starts to you know as we",
    "start": "195250",
    "end": "200680"
  },
  {
    "text": "invent new technologies business starts to adopt those technologies they find new use cases new applications new ways",
    "start": "200680",
    "end": "206290"
  },
  {
    "text": "of using more and more data and the data processing pressure the data pressure on our processing infrastructure increases",
    "start": "206290",
    "end": "212530"
  },
  {
    "text": "so what came next data drums tape serial",
    "start": "212530",
    "end": "217990"
  },
  {
    "text": "tape right the way we access data started to become depending upon the way we did we stored it right if I wanted to",
    "start": "217990",
    "end": "223870"
  },
  {
    "text": "access a file that was on stored on tape I had to read all the way through the tape to a certain point and be able to get that data right not a very efficient",
    "start": "223870",
    "end": "230140"
  },
  {
    "text": "way to store data we developed the random access file system distributed block storage right and data sprawl",
    "start": "230140",
    "end": "235420"
  },
  {
    "text": "began in the modern data center and what drove the innovation of the next innovation was really the cost of that",
    "start": "235420",
    "end": "242170"
  },
  {
    "text": "distributed data store right they you know the file system the sprawl of file systems developed drove the innovation",
    "start": "242170",
    "end": "248140"
  },
  {
    "text": "which was what we now commonly refer to as the relational database system right it was driven it was delivered to or",
    "start": "248140",
    "end": "255040"
  },
  {
    "text": "built to reduce the footprint of data on disk disk was the most expensive",
    "start": "255040",
    "end": "260130"
  },
  {
    "text": "resource in the data center in the 60s right in the 70s and maybe even arguably the 80s right you could still say that",
    "start": "260130",
    "end": "266770"
  },
  {
    "text": "disk storage was really the most costly investment the data center operators had to make on daily basis right provision",
    "start": "266770",
    "end": "272850"
  },
  {
    "text": "of stories and the enterprise never stops so what did we do today you know",
    "start": "272850",
    "end": "278040"
  },
  {
    "text": "when we look at the cost of infrastructure today now it's the cost of the CPU is where we have to spend the",
    "start": "278040",
    "end": "283350"
  },
  {
    "text": "most money storage is cheap right I can put data up on s3 you know i can store",
    "start": "283350",
    "end": "288840"
  },
  {
    "text": "massive amounts of data three cents a gigabyte you know cloud storage is available from multiple vendors I don't",
    "start": "288840",
    "end": "294810"
  },
  {
    "text": "necessarily have to worry about the size of the data anymore what I need to worry about is the cost of processing the data",
    "start": "294810",
    "end": "300120"
  },
  {
    "text": "the cost of CPU right back in the 60s the CPU is a fixed asset it was something I bought it was part of the",
    "start": "300120",
    "end": "305940"
  },
  {
    "text": "system if it wasn't processing data it was spinning today I actually pay for those CPU cycles right so why would I",
    "start": "305940",
    "end": "313590"
  },
  {
    "text": "use the technology was built to solve problem in the past to solve the problems that I'm facing today so we",
    "start": "313590",
    "end": "318780"
  },
  {
    "text": "want to look at something new we want to look at distributed database technologies like no SQL what does this really mean as you know developers and",
    "start": "318780",
    "end": "325710"
  },
  {
    "text": "his business owners it's about data it's about that we talked about data pressure the data pressure this picture has never",
    "start": "325710",
    "end": "332190"
  },
  {
    "text": "been different for the last 150 years it's been the same right 90% of the data",
    "start": "332190",
    "end": "337260"
  },
  {
    "text": "stored today is it was generated in the last two years you can google this it's out there IDC Forrester is knowledge the I",
    "start": "337260",
    "end": "343560"
  },
  {
    "text": "acknowledge this number IBM did some research on this as well it's very well accepted fact so what does that really",
    "start": "343560",
    "end": "349650"
  },
  {
    "text": "mean that means that one terabyte of data in 2010 is equal to six point five petabytes of data today all right 6,500",
    "start": "349650",
    "end": "357240"
  },
  {
    "text": "times more data today and I see this all the time as an essay I would deal with customers and five six years ago they",
    "start": "357240",
    "end": "363450"
  },
  {
    "text": "were talking to me about their multi terabyte databases and they're saying you know hey maybe we'll be in the",
    "start": "363450",
    "end": "368940"
  },
  {
    "text": "hundred terabyte or 200 terabyte range within four or five years and these same customers right same people I'm talking",
    "start": "368940",
    "end": "375660"
  },
  {
    "text": "to today are now talking to me about how am I going to deal with these petabytes of data that are we have you know",
    "start": "375660",
    "end": "380730"
  },
  {
    "text": "floating around okay so it is not a problem that is going away it is not a problem that is going to change in the",
    "start": "380730",
    "end": "387180"
  },
  {
    "text": "future and there's a linear correlation between this data pressure right that we see these peaks and valleys there's a",
    "start": "387180",
    "end": "392640"
  },
  {
    "text": "linear correlation between that and the technical innovations that we see in the data processing field we're all probably",
    "start": "392640",
    "end": "398250"
  },
  {
    "start": "398000",
    "end": "398000"
  },
  {
    "text": "familiar with this bottom chart that's the you know the the technology adoption curve we all say right there's a you",
    "start": "398250",
    "end": "404610"
  },
  {
    "text": "know the beginning we have many options we have all these little ideas and some of them are good and some of them are bad and eventually you know the early",
    "start": "404610",
    "end": "410640"
  },
  {
    "text": "adopters figure out which ones those are right smart companies coming in the early majority and they say hey you guys",
    "start": "410640",
    "end": "415920"
  },
  {
    "text": "all figured out the problems right we're gonna start deploying this stuff to solve these problems and then you know",
    "start": "415920",
    "end": "421560"
  },
  {
    "text": "the late majority and so on but what happens what's interesting what happens with companies that eventually run to these new technologies early is they",
    "start": "421560",
    "end": "428580"
  },
  {
    "text": "have this enormous hype curve right hey look so and so you know it's no SQL technology it's a distrait distributed",
    "start": "428580",
    "end": "434730"
  },
  {
    "text": "database it's gonna solve all of our big data problems just deploy MongoDB just deploy Cassandra right it'll fix",
    "start": "434730",
    "end": "439890"
  },
  {
    "text": "everything and they run in there and they go out and they start to deploy the technologies and they build applications on it and they find out that you know",
    "start": "439890",
    "end": "445680"
  },
  {
    "text": "this stuff doesn't work none of it works right oh I've got use cases that don't apply right my my app is not good for",
    "start": "445680",
    "end": "452690"
  },
  {
    "text": "NoSQL and I've heard that so many times right it's not even funny but the",
    "start": "452690",
    "end": "457800"
  },
  {
    "text": "reality is that every app is fine for no SQL it's about using the tool the way it was meant to be used if you're trying to",
    "start": "457800",
    "end": "463590"
  },
  {
    "text": "design a relational schema and you push it into a no SQL platform you're gonna have a very bad experience right so you",
    "start": "463590",
    "end": "470070"
  },
  {
    "text": "have to learn how to use the technology if you're gonna have a good experience and this is one of the things I talk to people is avoid that peak of inflated",
    "start": "470070",
    "end": "476330"
  },
  {
    "text": "expectation learn how to use this new technology talk to people who have had success how did they use it figure out",
    "start": "476330",
    "end": "482910"
  },
  {
    "text": "how these things are supposed to work and you'll have a better experience right you'll be on that slope of enlightenment right away and so that's a",
    "start": "482910",
    "end": "489510"
  },
  {
    "text": "lot of what I deal with with companies is teaching them how to forget what they used to know and how to use you know the",
    "start": "489510",
    "end": "495090"
  },
  {
    "text": "new platforms why would I use no SQL technology we've had this great thing called SQL for many many years it solved",
    "start": "495090",
    "end": "501690"
  },
  {
    "text": "all of our problems you know what's the what's the big deal well sql's fantastic technology you know for ad-hoc queries",
    "start": "501690",
    "end": "508740"
  },
  {
    "text": "if I don't understand the access pattern if my users are coming in and they're asking me questions and it could be you",
    "start": "508740",
    "end": "514409"
  },
  {
    "text": "know bi analytics maybe and you know somebody sitting in the back office and gonna ask different questions today than",
    "start": "514410",
    "end": "519510"
  },
  {
    "text": "they did yesterday well it's probably not a good technology use no SQL is not a good technology to use SQL is a very",
    "start": "519510",
    "end": "524580"
  },
  {
    "text": "flexible technology that way I can ask many questions of the data I can perform ad hoc queries and aggregations and you",
    "start": "524580",
    "end": "531000"
  },
  {
    "text": "know the problems with SQL is it scales vertically right meaning I have to get a bigger box if I want to run a bigger day",
    "start": "531000",
    "end": "537360"
  },
  {
    "text": "well sooner or later I can't get a bigger box so we have we have a fundamental problem here was not built",
    "start": "537360",
    "end": "543240"
  },
  {
    "text": "to be able to run in a partitioned easily run as a partition data store so",
    "start": "543240",
    "end": "549330"
  },
  {
    "text": "really it's good for OLAP good for those online analytics processing workloads data warehousing things like this this",
    "start": "549330",
    "end": "554670"
  },
  {
    "text": "is a fantastic application for SQL technology I know sq on the other hand its denormalized it's what I call",
    "start": "554670",
    "end": "561240"
  },
  {
    "text": "hierarchical views of your data right pre joined pre aggregated views but",
    "start": "561240",
    "end": "567180"
  },
  {
    "text": "you'd say instantiated views OLTP this is the place this is the sweet spot for no SQL why because no SQL schema is",
    "start": "567180",
    "end": "573480"
  },
  {
    "text": "designed to support the access pattern specifically support the access pattern right I don't join no SQL databases I",
    "start": "573480",
    "end": "581190"
  },
  {
    "text": "read the view that's out of the newest QL database it's pre joined for all intents and purposes and we'll talk a",
    "start": "581190",
    "end": "586980"
  },
  {
    "text": "little bit about what that means but you know suffice to say we spend a lot less time hopping around the disk pulling",
    "start": "586980",
    "end": "592290"
  },
  {
    "text": "data out of various tables assembling views because I'm basically doing big select statements out of my no SQL",
    "start": "592290",
    "end": "597810"
  },
  {
    "text": "tables all the time I'm never taking records merging them joining them the aggregations are stored on disk the way",
    "start": "597810",
    "end": "603360"
  },
  {
    "text": "the application needs them and it is all about aggregations for OLTP applications if you think about it I'm always looking",
    "start": "603360",
    "end": "609750"
  },
  {
    "text": "at you know orders by users invoices by orders payments on invoices right there's always a dimension in which I'm",
    "start": "609750",
    "end": "615750"
  },
  {
    "text": "looking at records aggregated into a particular you know dimension when I'm looking at LTP data and it's consistent",
    "start": "615750",
    "end": "623610"
  },
  {
    "text": "right every time the transaction runs through the system guess what it does it uses the data the same way every time I",
    "start": "623610",
    "end": "630210"
  },
  {
    "text": "can count on it it's not going to change when the guy clicks the buy button I'm going to I'm going to execute a",
    "start": "630210",
    "end": "635930"
  },
  {
    "text": "transaction against what the contents of his shopping cart it's going to be the same way every time so we can actually",
    "start": "635930",
    "end": "641970"
  },
  {
    "text": "optimize the data structure to support that SQL is agnostic to the access pattern it is means it's optimized for",
    "start": "641970",
    "end": "649410"
  },
  {
    "text": "none right if I open where is at where no SQL is specifically designed to",
    "start": "649410",
    "end": "654870"
  },
  {
    "text": "support the access pattern it is optimized for that access pattern all right is not it is not agnostic to the",
    "start": "654870",
    "end": "660570"
  },
  {
    "text": "access pattern this is what's important basically every type of application we build is going to look at data in some",
    "start": "660570",
    "end": "665580"
  },
  {
    "text": "sort of applicant some sort of aggregation this is SQL this is a relational structure we're very familiar with this represents all the common types of",
    "start": "665580",
    "end": "673050"
  },
  {
    "text": "relationships you see you in a you know our DBMS there's a product catalog a",
    "start": "673050",
    "end": "678320"
  },
  {
    "text": "products table products table has a one-to-one relationship between books albums and videos in itself there's one",
    "start": "678320",
    "end": "686220"
  },
  {
    "text": "of many between albums and tracks the tracks and albums got many tracks and there's a many demanding between videos",
    "start": "686220",
    "end": "691410"
  },
  {
    "text": "and actors actors can be in many videos and videos can be in many actors and videos can have many actors so if you",
    "start": "691410",
    "end": "698280"
  },
  {
    "text": "think about what happens when I want to see okay let give me all the products that are videos and this particular you",
    "start": "698280",
    "end": "703860"
  },
  {
    "text": "know data structure okay let me select from products inner join videos on",
    "start": "703860",
    "end": "709590"
  },
  {
    "text": "product ID you know oh let's inner join actor video on the on the video ID and",
    "start": "709590",
    "end": "715410"
  },
  {
    "text": "then join through that table to get to the you know the actual actors for my video think what the CPU is doing to be",
    "start": "715410",
    "end": "722310"
  },
  {
    "text": "able to assemble that view right it's going and finding the victim products it goes and maps those product IDs to the",
    "start": "722310",
    "end": "727980"
  },
  {
    "text": "videos it puts these rows together then it goes through another table and another table this is the cost of SQL",
    "start": "727980",
    "end": "733530"
  },
  {
    "text": "this is why SQL will not scale it just cannot scale because again it's agnostic",
    "start": "733530",
    "end": "739200"
  },
  {
    "text": "to the access patterns which means to produce the results said it has to do a lot of work alright so let's take a look",
    "start": "739200",
    "end": "744720"
  },
  {
    "text": "at what that looks like in know SQL right let me get all my products you",
    "start": "744720",
    "end": "749940"
  },
  {
    "text": "know let alone just all my videos I can get all my videos easy enough but I could just select all my products just simply by selecting star from the",
    "start": "749940",
    "end": "756330"
  },
  {
    "text": "products table right a select star is always gonna be a faster query than a select star inner join this inner join",
    "start": "756330",
    "end": "762330"
  },
  {
    "text": "that inner join this always this is why no SQL performance will blaze over SQL",
    "start": "762330",
    "end": "767640"
  },
  {
    "text": "at scale through OLTP applications it's amazing that performance difference between a well-designed no SQL schema",
    "start": "767640",
    "end": "774810"
  },
  {
    "text": "and a relational schema for most complex relational database schemas one of the",
    "start": "774810",
    "end": "780090"
  },
  {
    "text": "probably understated and most valuable features of dynamo is the fact that it's a fully managed no SQL database platform",
    "start": "780090",
    "end": "786570"
  },
  {
    "text": "I talked to customers all the time who are starting out with you know MongoDB",
    "start": "786570",
    "end": "792300"
  },
  {
    "text": "or Cassandra you name it and a dozens of little projects no it's great the developers can get running and I love",
    "start": "792300",
    "end": "798090"
  },
  {
    "text": "these databases don't get me wrong I was at MongoDB over two years fantastic database okay the problem with",
    "start": "798090",
    "end": "803550"
  },
  {
    "text": "these things is when you scale it's not when you get started it's when these business units and these apps and these services start to actually become",
    "start": "803550",
    "end": "809639"
  },
  {
    "text": "successful you start to scale and you start to see the operational burden of managing a hundred two hundred a",
    "start": "809639",
    "end": "816240"
  },
  {
    "text": "thousand fifteen hundred instances of your database when you used to manage five right this is this is a huge cost",
    "start": "816240",
    "end": "825240"
  },
  {
    "text": "right the customers have to pay to actually scale these applications so looking at a fully managed service that",
    "start": "825240",
    "end": "830369"
  },
  {
    "text": "provides an OS ql database is pretty pretty attractive most of the customers I talked to you our customers who are",
    "start": "830369",
    "end": "835439"
  },
  {
    "text": "looking to come off of their you know large scale either and these could be",
    "start": "835439",
    "end": "840480"
  },
  {
    "text": "you know on Prem in their own data center so they could be an ec2 I work with customers who are I think yes I buy",
    "start": "840480",
    "end": "846329"
  },
  {
    "text": "a mega mentioned customer names cuz I'm not sure who I'm cleared to talk about but I do I work with customers who have made large-scale migrations from on Prem",
    "start": "846329",
    "end": "853619"
  },
  {
    "text": "MongoDB into ec2 or they're still running MongoDB they're running an ec2 but even then the cost is still killing",
    "start": "853619",
    "end": "859860"
  },
  {
    "text": "them so they come to me they say how can I move all this stuff into dynamo DB right and so I mean I do a lot of these",
    "start": "859860",
    "end": "866009"
  },
  {
    "text": "types of migrations there are two flavors I guess you'd say primary flavors have no SQL these days of document in key value store dynamodb",
    "start": "866009",
    "end": "873300"
  },
  {
    "start": "867000",
    "end": "867000"
  },
  {
    "text": "does its best to support both at its heart at its core it's a key value store we do support document attributes right",
    "start": "873300",
    "end": "880379"
  },
  {
    "text": "so as part of that the value of the key value can actually be a JSON document I'll talk a little bit about how we",
    "start": "880379",
    "end": "885959"
  },
  {
    "text": "access that data you know again where the biggest value points we have fast and consistent at any scale so design",
    "start": "885959",
    "end": "893490"
  },
  {
    "text": "goal for the system was a single-digit millisecond latency at any scale and we",
    "start": "893490",
    "end": "899459"
  },
  {
    "text": "have customers that are doing millions of transactions per second billions of transactions per day and seeing exactly",
    "start": "899459",
    "end": "905249"
  },
  {
    "text": "that very consistent sub 10 millisecond actually low single-digit millisecond in the case of guys like AdRoll these guys",
    "start": "905249",
    "end": "912689"
  },
  {
    "text": "are doing over a million requests per second at peak and they're 99.5% i",
    "start": "912689",
    "end": "917970"
  },
  {
    "text": "latency is is less than 3 milliseconds so amazing scale fine grained access",
    "start": "917970",
    "end": "923549"
  },
  {
    "text": "control document level attribute level access control fully integrated with AWS I am so",
    "start": "923549",
    "end": "930089"
  },
  {
    "text": "you know and I am is also intern integrated with LDAP Kerberos other Enterprise auth management so you can",
    "start": "930089",
    "end": "935819"
  },
  {
    "text": "tie into your Active Directory and actually authorize use use Active Directory roles and permissions to",
    "start": "935819",
    "end": "942470"
  },
  {
    "text": "associate to your iam users which will then grant access and permissions to DynamoDB data and a backplane service",
    "start": "942470",
    "end": "949470"
  },
  {
    "text": "again fully managed something that you don't need to worry about which means that it's always there it's always on",
    "start": "949470",
    "end": "955920"
  },
  {
    "text": "you know how do I deploy dynamodb you log into the console you create a table you tell me how much capacity you want",
    "start": "955920",
    "end": "962129"
  },
  {
    "text": "on the table and then and and and that's it no deploy and instance update",
    "start": "962129",
    "end": "967139"
  },
  {
    "text": "software no install software configure things you know that it's just just a",
    "start": "967139",
    "end": "972240"
  },
  {
    "text": "very simple process so as a table look like tables pretty simple table has items this is just similar to very you",
    "start": "972240",
    "end": "977850"
  },
  {
    "text": "know many know SQL platforms no different items can have attributes attributes don't need to be consistent",
    "start": "977850",
    "end": "983579"
  },
  {
    "text": "across items you can have any number of attributes in an item in DynamoDB there is one mandatory attribute it's called",
    "start": "983579",
    "end": "990149"
  },
  {
    "text": "the partition key alright the partition key uniquely identifies the item it said",
    "start": "990149",
    "end": "995579"
  },
  {
    "text": "add any attribute but you specify you say I want the user ID to be my partition key and then every item that",
    "start": "995579",
    "end": "1001759"
  },
  {
    "text": "you insert into that table must have a user ID attribute that's the only mandatory attribute there's another attribute that you can push that was",
    "start": "1001759",
    "end": "1008569"
  },
  {
    "text": "called a sort key the sort key is really a way of creating a composite key now",
    "start": "1008569",
    "end": "1014449"
  },
  {
    "text": "when I add a sort key instead of the the partition key uniquely identifying uniquely identifying the item the",
    "start": "1014449",
    "end": "1020600"
  },
  {
    "text": "combination of the two uniquely identifies the item why would I use a sort key because sort keys support range",
    "start": "1020600",
    "end": "1026538"
  },
  {
    "text": "queries all right range queries our complex query operators things like equals greater than less than begins",
    "start": "1026539",
    "end": "1033350"
  },
  {
    "text": "with contains range keys support the ability to execute queries and filtered",
    "start": "1033350",
    "end": "1039260"
  },
  {
    "text": "we get extremely selective and filtered result sets in a sorted order based on the key value all right so we'll explain",
    "start": "1039260",
    "end": "1046010"
  },
  {
    "text": "a little bit why about why is this important but try to remember it if you want to get you know items between a",
    "start": "1046010",
    "end": "1051380"
  },
  {
    "text": "certain date you know orders that happen for this customer between a certain date these are types of queries that you",
    "start": "1051380",
    "end": "1056390"
  },
  {
    "text": "would execute against a sort key operator so the partition key as we said uniquely identifies the item we'll take",
    "start": "1056390",
    "end": "1062360"
  },
  {
    "start": "1059000",
    "end": "1059000"
  },
  {
    "text": "that partition key we'll take the tribute that you specify in this case we're gonna say that the hash key is the",
    "start": "1062360",
    "end": "1067399"
  },
  {
    "text": "ID attribute every item has an ID attribute we'll apply a hash algorithm to generate a uniquely random value out",
    "start": "1067399",
    "end": "1074149"
  },
  {
    "text": "of that value and we will then realign these items and lay them out across what we call a key space when when the table",
    "start": "1074149",
    "end": "1081679"
  },
  {
    "text": "has a single server or tuesday's very small table and it runs on a single server the entire key space is served by",
    "start": "1081679",
    "end": "1087409"
  },
  {
    "text": "a single storage node if the table grows or increases in capacity then we would",
    "start": "1087409",
    "end": "1094220"
  },
  {
    "text": "start to split that key space and this is how no SQL databases work right all no SQL databases work this way they take",
    "start": "1094220",
    "end": "1100669"
  },
  {
    "text": "some attribute some value out of the document and they will apply either a hash algorithm or they'll use the",
    "start": "1100669",
    "end": "1106370"
  },
  {
    "text": "straight value and they will that will sort those records across a key space and then as you scale the system they'll",
    "start": "1106370",
    "end": "1112760"
  },
  {
    "text": "just chunk the key space and start handing it off to different nodes in the cluster right so this is what gives the no SQL database the ability to scale",
    "start": "1112760",
    "end": "1119779"
  },
  {
    "text": "horizontally this how it looks like when you have the partition the sort key you know table right when I've specified a",
    "start": "1119779",
    "end": "1124970"
  },
  {
    "start": "1121000",
    "end": "1121000"
  },
  {
    "text": "sort key now what happens is all of the items with the same partition key will get co-located on the same storage node",
    "start": "1124970",
    "end": "1131690"
  },
  {
    "text": "so I actually get laid out on disk sorted by the sort key value why is this important because when we go to get the",
    "start": "1131690",
    "end": "1137809"
  },
  {
    "text": "records and you say give me all the orders for this customer between this date I'm just gonna go do one big sequential read on the disk sadistic so",
    "start": "1137809",
    "end": "1144980"
  },
  {
    "text": "we got two things going for us we got a big select statement those are always fast we love select statements no joints and then we got a large sequential read",
    "start": "1144980",
    "end": "1151850"
  },
  {
    "text": "this is one of the reasons why dynamodb is going to give you single-digit millisecond latency low single-digit",
    "start": "1151850",
    "end": "1157070"
  },
  {
    "text": "millisecond latency all the time because when we go query the datastore we're doing it very selectively and",
    "start": "1157070",
    "end": "1163039"
  },
  {
    "text": "we're and we're doing it very efficiently partitions by default or 3-way replicated when you write two dynamodb we're gonna write across three",
    "start": "1163039",
    "end": "1169190"
  },
  {
    "start": "1166000",
    "end": "1166000"
  },
  {
    "text": "partitions so those three partitions are in three AZ's even in regions that only have one or two AZ's which we do have a",
    "start": "1169190",
    "end": "1175519"
  },
  {
    "text": "few of those there's still three AZ's for DynamoDB it's what we call backplane service so you may not as a customer see",
    "start": "1175519",
    "end": "1181730"
  },
  {
    "text": "three ACS it doesn't mean they aren't there a region doesn't actually stand up without it because we can't stand up dynamodb without it so anyways you",
    "start": "1181730",
    "end": "1188630"
  },
  {
    "text": "should write two DynamoDB we're going to write to two of those servers it'll replicate to the third when the two servers that we write to come back",
    "start": "1188630",
    "end": "1195200"
  },
  {
    "text": "and confirm the right spin you're gonna get acknowledgment that the Wrights been committed okay when we read",
    "start": "1195200",
    "end": "1200280"
  },
  {
    "text": "we will read from two servers and we will give you the most current version that comes back that's what makes dynamodb a consistent read after write",
    "start": "1200280",
    "end": "1206700"
  },
  {
    "text": "database just like MongoDB MongoDB is also consistent read after write database it's no master master type of",
    "start": "1206700",
    "end": "1213000"
  },
  {
    "text": "functionality here now you can choose to turn on I guess you'd say eventually",
    "start": "1213000",
    "end": "1218430"
  },
  {
    "text": "consistent reads and when you do that what happens is we actually just read from any one node randomly and get",
    "start": "1218430",
    "end": "1223470"
  },
  {
    "text": "whatever data it has why would you do that because it will cut your read cost in half right",
    "start": "1223470",
    "end": "1228930"
  },
  {
    "text": "we're only reading from you know a normal read I read from two nodes on EC read I read from one node so I only",
    "start": "1228930",
    "end": "1234360"
  },
  {
    "text": "charge you half the read capacities as a very cheap way most workloads will support eventually consistent reads and",
    "start": "1234360",
    "end": "1240690"
  },
  {
    "text": "we're talking about milliseconds not minutes right most most workloads are just fine with that and it's a very very easy way to",
    "start": "1240690",
    "end": "1247830"
  },
  {
    "text": "optimize your cost on dynamo DB just turn on eventually consistent reads you double you read capacity indexes in",
    "start": "1247830",
    "end": "1253470"
  },
  {
    "start": "1253000",
    "end": "1253000"
  },
  {
    "text": "dynamo DB a rather interesting we have two flavors we have the local what we call local secondary index and we have a",
    "start": "1253470",
    "end": "1258540"
  },
  {
    "text": "global secondary index we'll talk about the local first the local is in essence it's a way to give us an alternate sort",
    "start": "1258540",
    "end": "1264330"
  },
  {
    "text": "key attribute we mentioned sort keys we have the range key and the sort key I can execute you know complex built or",
    "start": "1264330",
    "end": "1270690"
  },
  {
    "text": "queries against the sort key well oftentimes I need to execute those types of queries against more than just the",
    "start": "1270690",
    "end": "1276240"
  },
  {
    "text": "sort attribute I need to execute those types of queries against other attributes in the item we can do that in",
    "start": "1276240",
    "end": "1282000"
  },
  {
    "text": "two ways I can create a local secondary index to do that that gives me a nice selective highly selective way of doing",
    "start": "1282000",
    "end": "1287850"
  },
  {
    "text": "it because I can filter on the sort key attribute I can get that down to the hey I need this block of items I'll do a sequential read against it right or I",
    "start": "1287850",
    "end": "1294660"
  },
  {
    "text": "can do it using a filtering filter condition filter conditions a little different it'll read all the records on the bucket and then filter out the ones",
    "start": "1294660",
    "end": "1300870"
  },
  {
    "text": "that don't match so filters are more expensive the indexes are more efficient on the read side but like all database",
    "start": "1300870",
    "end": "1307500"
  },
  {
    "text": "indexes on the right side I got to write the data twice right when I could do when I create an index so again so I",
    "start": "1307500",
    "end": "1313890"
  },
  {
    "text": "create an alternate sort key and I can with dynamodb indexes you can project additional attributes into the index",
    "start": "1313890",
    "end": "1320760"
  },
  {
    "text": "right so I will sort on this secondary attribute and I will let you say and also by the way append these other",
    "start": "1320760",
    "end": "1326910"
  },
  {
    "text": "attributes because when I query the index I'm gonna want to read these other attributes to write you know that that's",
    "start": "1326910",
    "end": "1332640"
  },
  {
    "text": "the in your in your app that's the access pattern if I'm looking for data on that dimension I'm also looking for",
    "start": "1332640",
    "end": "1338520"
  },
  {
    "text": "these other attributes as well project those I treats into the index so I don't have to read the index and then go back",
    "start": "1338520",
    "end": "1343530"
  },
  {
    "text": "to the table and read the items global secondary indexes are a little different they allow us to specify a completely",
    "start": "1343530",
    "end": "1350669"
  },
  {
    "start": "1346000",
    "end": "1346000"
  },
  {
    "text": "different partition and sort key okay so think of this as a totally different aggregation so my primary table maybe",
    "start": "1350669",
    "end": "1357270"
  },
  {
    "text": "I'm aggravated you know parts by assembly right but then I also need to",
    "start": "1357270",
    "end": "1362940"
  },
  {
    "text": "see parts by manufacturer parts by you know you know by lot number or whatever",
    "start": "1362940",
    "end": "1369120"
  },
  {
    "text": "right I can create a GSI or global secondary index and I can have a totally different partition key on those items",
    "start": "1369120",
    "end": "1375419"
  },
  {
    "text": "as they're inserting the primary table they might be falling into aggregations that are by assembly and then when I go",
    "start": "1375419",
    "end": "1380880"
  },
  {
    "text": "and run the GSI the GSI is gonna spin that on it's completely different dimension and create a totally different",
    "start": "1380880",
    "end": "1386549"
  },
  {
    "text": "aggregation and now I have in essence what amounts to a different one to many relationship pre built into this GSI",
    "start": "1386549",
    "end": "1392159"
  },
  {
    "text": "than I do on the table alright and we'll talk about a little bit about how those",
    "start": "1392159",
    "end": "1397230"
  },
  {
    "start": "1396000",
    "end": "1396000"
  },
  {
    "text": "play GSI updates are eventually consistent right so you're gonna upgrade",
    "start": "1397230",
    "end": "1403260"
  },
  {
    "text": "update the table you're gonna get acknowledged back to the client that you've been updated the index is going to get it in the second or two well not",
    "start": "1403260",
    "end": "1408960"
  },
  {
    "text": "a second or two usually less than a second but they're not going to necessarily happen in line with the updates that's how that works",
    "start": "1408960",
    "end": "1414600"
  },
  {
    "text": "the response is asynchronous to the update of the GSI LSI's are consistent",
    "start": "1414600",
    "end": "1421409"
  },
  {
    "text": "okay so that's a good big difference in the differ the reason why is because GSI is maintained a totally different",
    "start": "1421409",
    "end": "1427140"
  },
  {
    "text": "ordered aggregation LSI generally maintain the same aggregation by the same dimension because it's just a",
    "start": "1427140",
    "end": "1432780"
  },
  {
    "text": "different sort key so I can co-locate the LSI on the same partition as the GSI makes it a lot easier for me to",
    "start": "1432780",
    "end": "1439230"
  },
  {
    "text": "synchronize the updates across the to in the GSI the partition sets are gonna be totally different than the main table in",
    "start": "1439230",
    "end": "1445590"
  },
  {
    "text": "essence the key space is totally different so in if you update the the primary table it's now a distributed",
    "start": "1445590",
    "end": "1451890"
  },
  {
    "text": "computing problem to synchronize the update to the GSI we basically punted on that said too hard we're just going to",
    "start": "1451890",
    "end": "1458399"
  },
  {
    "text": "create and eventually consistent GSI so when do you use LS or GS is you know if eventual consistency is okay",
    "start": "1458399",
    "end": "1464889"
  },
  {
    "text": "for your scenario I always recommend the GSI because it's more flexible GSA's can always be created and and",
    "start": "1464889",
    "end": "1471070"
  },
  {
    "text": "deleted anytime LSI's can only be created when the table is created and they can never be deleted so this is",
    "start": "1471070",
    "end": "1478179"
  },
  {
    "text": "something to remember when you're starting to set these things up a little bit more flexibility when you use the GSI there's also a 10 gigabyte limit to",
    "start": "1478179",
    "end": "1484570"
  },
  {
    "text": "the LSI if you're gonna create a LSI on a table it limits the partition size to",
    "start": "1484570",
    "end": "1490419"
  },
  {
    "text": "10 gigabytes and that's because they need to co-locate we talked a little bit about partitioning and how important",
    "start": "1490419",
    "end": "1495519"
  },
  {
    "text": "that is and it really comes down to how we scale DynamoDB scales in two dimensions throughput in size provision",
    "start": "1495519",
    "end": "1501789"
  },
  {
    "text": "any amount of throughput to a table that's up to you you come into the console you say I want 10,000 WCU's wcu",
    "start": "1501789",
    "end": "1507879"
  },
  {
    "text": "is the right capacity unit we'll talk a little bit about what that means in a second you know then of course size is",
    "start": "1507879",
    "end": "1513219"
  },
  {
    "text": "you can add any number of items to the table the maximum item size today is 400 kilobytes and of course we have this",
    "start": "1513219",
    "end": "1519219"
  },
  {
    "text": "little limit with the LS is where the size of a partition or the number of range keys per partition is limited to",
    "start": "1519219",
    "end": "1525580"
  },
  {
    "text": "10 gigabytes but in essence you can you know for all practical purposes we can put any number of items on the table and",
    "start": "1525580",
    "end": "1532059"
  },
  {
    "text": "have tables of any size there is no limit throughput is provision at the table level right capacity units are",
    "start": "1532059",
    "end": "1537489"
  },
  {
    "text": "measured is one kilobyte per second read capacity units are measured at 4 kilobytes per second are see use by",
    "start": "1537489",
    "end": "1543789"
  },
  {
    "text": "default measure those strictly consistent reads as we talked about you can turn those off and cut your cost in",
    "start": "1543789",
    "end": "1549129"
  },
  {
    "text": "half and they're adjusted completely independently so you can set any number of recap acity and write capacity I can",
    "start": "1549129",
    "end": "1554169"
  },
  {
    "text": "consume 100 percent of my read capacity it's not going to affect the availability of the right capacity and",
    "start": "1554169",
    "end": "1559539"
  },
  {
    "text": "vice versa as far as partitioning goes here's how it works as far as what it looks like on the table at a given point",
    "start": "1559539",
    "end": "1565059"
  },
  {
    "start": "1561000",
    "end": "1561000"
  },
  {
    "text": "your capacity number divided by take your total RCU divided by 3000 take a",
    "start": "1565059",
    "end": "1570219"
  },
  {
    "text": "total wcu divided by 1,000 add those two numbers together and round up that's how many partitions that I would need to",
    "start": "1570219",
    "end": "1576129"
  },
  {
    "text": "support my table by the capacity that you have set so if I provision a table",
    "start": "1576129",
    "end": "1581259"
  },
  {
    "text": "with 9,000 hours to use it needs three partitions right by size it's really",
    "start": "1581259",
    "end": "1586960"
  },
  {
    "text": "easy it's just the size of the table divided by 10 gigabytes that's how many partitions you'll get we'll take the",
    "start": "1586960",
    "end": "1591969"
  },
  {
    "text": "larger of those two numbers and we can't give you a fractional so if we look at some real number there this is how that would work out",
    "start": "1591969",
    "end": "1598330"
  },
  {
    "text": "for a table of eight gigabytes $5,000 to use 500 WCU's by capacity I need 2.17",
    "start": "1598330",
    "end": "1605530"
  },
  {
    "text": "by sighs I need 0.8 I'm going to take the max of those two numbers with 2.17",
    "start": "1605530",
    "end": "1610600"
  },
  {
    "text": "round up you're going to get three partitions on your table so okay that's interesting why is that important",
    "start": "1610600",
    "end": "1616320"
  },
  {
    "text": "important because of this in order to do the capacity provisioning for your table",
    "start": "1616320",
    "end": "1622030"
  },
  {
    "start": "1617000",
    "end": "1617000"
  },
  {
    "text": "we are going to evenly distribute the RC use and WCS across three partitions what",
    "start": "1622030",
    "end": "1627520"
  },
  {
    "text": "does that really mean it means on a per partition basis your throughput is 166",
    "start": "1627520",
    "end": "1632970"
  },
  {
    "text": "WCU's in 1666 RC used per partition if I",
    "start": "1632970",
    "end": "1638260"
  },
  {
    "text": "start to hit any particular partition key harder than that I might actually get throttled even though the table has",
    "start": "1638260",
    "end": "1644500"
  },
  {
    "text": "5000 RC use right if I'm reading it faster if I'm reading a particular key faster than 1666 RC use I might end up",
    "start": "1644500",
    "end": "1652660"
  },
  {
    "text": "getting throttled because the individual partition it's on doesn't have the throughput to support it now there is",
    "start": "1652660",
    "end": "1657880"
  },
  {
    "text": "burst capacity built in the system we don't want to just create a hard wall where people fall over you get five",
    "start": "1657880",
    "end": "1663730"
  },
  {
    "text": "minutes of unused capacity it sits in a burst bucket that's available for you on a per partition basis right across all",
    "start": "1663730",
    "end": "1669669"
  },
  {
    "text": "your partitions I bet except it's a best guess it's a best-effort right that you'll get that so don't count on burst",
    "start": "1669669",
    "end": "1676120"
  },
  {
    "text": "it'll be there for you most of the time but if other people have provision tables and the provision capacity is",
    "start": "1676120",
    "end": "1681760"
  },
  {
    "text": "being consumed and there's no Headroom on the stories node then you're gonna get throttled what cause is throttling",
    "start": "1681760",
    "end": "1687190"
  },
  {
    "start": "1687000",
    "end": "1687000"
  },
  {
    "text": "we'd kind of just went through it if that sustained throughput goes beyond the provision throughput on a per",
    "start": "1687190",
    "end": "1692590"
  },
  {
    "text": "partition basis and these can be caused access patterns are caused by non-uniform workloads what we call hot",
    "start": "1692590",
    "end": "1698320"
  },
  {
    "text": "keys right hot partitions and you know high velocity reads high velocity rights to with single partition key value those",
    "start": "1698320",
    "end": "1705940"
  },
  {
    "text": "can be what we call hot keys large aggregations large bursts of traffic mixing hot data with cold data if you",
    "start": "1705940",
    "end": "1712090"
  },
  {
    "text": "think about a lot of operational analytics right we bring in the data and we're only interested in that data for",
    "start": "1712090",
    "end": "1717190"
  },
  {
    "text": "some period of time it might be 24 hours or a week or a month after that the data gets old it gets stale nobody looks at",
    "start": "1717190",
    "end": "1723010"
  },
  {
    "text": "it if I sit there and keep on filling that table up the table is gonna get bigger and bigger and bigger and bigger it's just gonna split split split split",
    "start": "1723010",
    "end": "1728919"
  },
  {
    "text": "and time I split i'm rate-limiting i'm rate-limiting i'm rate-limiting so you know if you got a bunch of data that you",
    "start": "1728919",
    "end": "1735059"
  },
  {
    "text": "don't care about then don't leave it in the dynamodb table if you do and we'll talk about design pattern for that let's",
    "start": "1735059",
    "end": "1741450"
  },
  {
    "text": "create a staggered set of aging tables right so we age the data out right this data is only good for 30 days every 30",
    "start": "1741450",
    "end": "1748200"
  },
  {
    "text": "days I create a new table and start writing new data to it things like this right I manage the table based on how",
    "start": "1748200",
    "end": "1754380"
  },
  {
    "text": "you're accessing the data this is what throttling looks like this is what we call bad no SQL and it's the same in",
    "start": "1754380",
    "end": "1760140"
  },
  {
    "start": "1756000",
    "end": "1756000"
  },
  {
    "text": "DynamoDB MongoDB Cassandra you name it we all have our anti patterns that will",
    "start": "1760140",
    "end": "1765390"
  },
  {
    "text": "create this effect I pull these for customers quite frequently this is looking at the partition set of the table on the y-axis and the access",
    "start": "1765390",
    "end": "1772380"
  },
  {
    "text": "pattern over time and what you can see is this guy's got one little storage node up there that's blazing hot because",
    "start": "1772380",
    "end": "1778649"
  },
  {
    "text": "don't know why maybe there's a large aggregation that we're importing and e-tailing a whole pile of data in and",
    "start": "1778649",
    "end": "1784740"
  },
  {
    "text": "millions of records are coming in in one big batch load and we're trying to shove it all into one partition you know maybe",
    "start": "1784740",
    "end": "1791909"
  },
  {
    "text": "it's a high velocity counter somebody's trying to maintain counters on a DynamoDB item maybe not the best place",
    "start": "1791909",
    "end": "1797490"
  },
  {
    "text": "to do that I've had customers try to maintain that kind of transient IVA Lassa tea counter in a dynamo DB item this is going to create a hotkey maybe",
    "start": "1797490",
    "end": "1804330"
  },
  {
    "text": "we should use something like elastic cash or an a player cash for that you know especially if it's transient data",
    "start": "1804330",
    "end": "1810960"
  },
  {
    "text": "data that's gonna repopulate it can be easily rebuilt and don't don't need to store that in the database these types",
    "start": "1810960",
    "end": "1816600"
  },
  {
    "text": "of things those cause those access patterns so to get the most out of dynamo really what it comes down to is",
    "start": "1816600",
    "end": "1822000"
  },
  {
    "text": "creating tables where the hash key element has a large high cardinality set",
    "start": "1822000",
    "end": "1828539"
  },
  {
    "text": "right true/false does not make a good hash key that means that everything's gonna be in 1 or 2 right you know these",
    "start": "1828539",
    "end": "1835529"
  },
  {
    "text": "types of things are not good so avoid those binary hash keys uu IDs uu IDs make excellent hash keys unfortunately",
    "start": "1835529",
    "end": "1841320"
  },
  {
    "text": "for most applications that's fairly useless the the you know the key thing is to understand what kind of",
    "start": "1841320",
    "end": "1847169"
  },
  {
    "text": "aggregations I'm trying to maintain on the table how thick how big how deep are these things you know if I've got",
    "start": "1847169",
    "end": "1852539"
  },
  {
    "text": "aggregations that require millions and millions of items then let's talk about design patterns that allow us to spread",
    "start": "1852539",
    "end": "1857789"
  },
  {
    "text": "those things out across multiple hash key values instead of just one you know and then the other thing I want",
    "start": "1857789",
    "end": "1863380"
  },
  {
    "text": "is I want those hash key elements to be accessed or requested fairly uniformly",
    "start": "1863380",
    "end": "1868600"
  },
  {
    "text": "and as randomly as possible and that's great the first one we can handle that space I can always design a schema that",
    "start": "1868600",
    "end": "1874300"
  },
  {
    "text": "will distribute the access pattern we can always do this the the time times another one time is you know hey the",
    "start": "1874300",
    "end": "1880720"
  },
  {
    "text": "Thundering Herd shows up tomorrow because I had the most successful you know promo ever in the history of my company and nothing can help you with",
    "start": "1880720",
    "end": "1887500"
  },
  {
    "text": "that right so we actually have to build the ability of the application to react to that in an elastic way into our",
    "start": "1887500",
    "end": "1893620"
  },
  {
    "text": "architecture and we can talk about some of those design patterns if we accomplish those things this is what it looks like",
    "start": "1893620",
    "end": "1899110"
  },
  {
    "text": "much better picture right we've got you know it actually looks a little bit more colorful than this because we would see",
    "start": "1899110",
    "end": "1905500"
  },
  {
    "text": "a more you know spread access pattern across the space but you get the idea we",
    "start": "1905500",
    "end": "1910660"
  },
  {
    "text": "don't want a lot of key pressure on any given partition we want that pressure to be more evenly distributed across the",
    "start": "1910660",
    "end": "1916090"
  },
  {
    "text": "cluster let's talk a little bit about data modelling we talked about those one-to-one one-to-many many-to-many relationships very common structures in",
    "start": "1916090",
    "end": "1922720"
  },
  {
    "start": "1917000",
    "end": "1917000"
  },
  {
    "text": "relational databases is how we maintain those in dynamo DB you know the use case here would be you know getting pulled",
    "start": "1922720",
    "end": "1929230"
  },
  {
    "text": "over by the Highway Patrol you know I need to give my license they got to get my social security number my contact",
    "start": "1929230",
    "end": "1936010"
  },
  {
    "text": "info they don't necessarily be my social security number but when I go to the DMV and get my license they want my social security number and all that birth",
    "start": "1936010",
    "end": "1941740"
  },
  {
    "text": "certificate and all that stuff right it's a one on one thing right you have one when you know social security number",
    "start": "1941740",
    "end": "1947260"
  },
  {
    "text": "one license so maybe when I get my license at the DMV I have a users table it's partitioned on social security it's",
    "start": "1947260",
    "end": "1953710"
  },
  {
    "text": "got all my email attributes this is really bad PII we're not worried about that I'm sure they don't use Social",
    "start": "1953710",
    "end": "1958930"
  },
  {
    "text": "Security number at DMV next day I'm not so sure I get pulled",
    "start": "1958930",
    "end": "1964390"
  },
  {
    "text": "over by the Highway Patrol Highway Patrol systems all hooked up to a different table it's actually a GSI on the user's table and it's partitioned on",
    "start": "1964390",
    "end": "1971080"
  },
  {
    "text": "the license and and just gives me those attributes right so this is a partition only table that we just flipped the keys",
    "start": "1971080",
    "end": "1977290"
  },
  {
    "text": "around right so that gives me that one-to-one relationship I can make those access those lookups on the two",
    "start": "1977290",
    "end": "1982840"
  },
  {
    "text": "different access patterns using that base table and the GSI this way next one we'll talk about is the one-to-many",
    "start": "1982840",
    "end": "1988780"
  },
  {
    "text": "relationship this is very basically built into the table structure using a partition sort key",
    "start": "1988780",
    "end": "1995110"
  },
  {
    "text": "particular you know common example here IOT type of scenario given a device you",
    "start": "1995110",
    "end": "2000269"
  },
  {
    "text": "know find all the readings that were taken between these particular time stamps okay so I use a table structure",
    "start": "2000269",
    "end": "2005669"
  },
  {
    "text": "that has a partition key of the device ID and an assorted an every time I take",
    "start": "2005669",
    "end": "2011700"
  },
  {
    "text": "a reading off the device it comes into the DynamoDB table with a different timestamp it's got the same device ID I",
    "start": "2011700",
    "end": "2016860"
  },
  {
    "text": "can lay those records out nice and you know in the linear fashion on disk I execute the query that says give it",
    "start": "2016860",
    "end": "2022440"
  },
  {
    "text": "between these two timestamps very easy to find the records are associated with that device between those timestamps",
    "start": "2022440",
    "end": "2028019"
  },
  {
    "text": "many many relationships this is using a you know partition sort key and then",
    "start": "2028019",
    "end": "2034559"
  },
  {
    "start": "2029000",
    "end": "2029000"
  },
  {
    "text": "flipping them around so a particularly use case here would be for a user video game online gaming for a user find all",
    "start": "2034559",
    "end": "2041370"
  },
  {
    "text": "the games that they play and for a game find all the users that play it so I have a user games table partitioned on",
    "start": "2041370",
    "end": "2047610"
  },
  {
    "text": "the user ID and sorted on the game ID Bob plays a bunch of games he's got a bunch of items in his hash key when I go",
    "start": "2047610",
    "end": "2054839"
  },
  {
    "text": "into on the on the game users table I'm just gonna flip those around I'm just gonna say thou my partition key is the game ID and my store key is the is the",
    "start": "2054839",
    "end": "2061858"
  },
  {
    "text": "user ID so now I can query the game ID and get all the list of users that are played there playing that game and on",
    "start": "2061859",
    "end": "2068280"
  },
  {
    "text": "the on the if I want to see what you what games a particular user plays it's very easy to query the users table so",
    "start": "2068280",
    "end": "2073618"
  },
  {
    "text": "you can see imagine all the workflows and access patterns that this supports right you know an online gaming user",
    "start": "2073619",
    "end": "2079440"
  },
  {
    "text": "show up they want a game match right by you know what kind of games do you play how good are you what's your skill level",
    "start": "2079440",
    "end": "2085070"
  },
  {
    "text": "what not you know these are the types of tables that those types of companies end up creating quite frequently the next",
    "start": "2085070",
    "end": "2091710"
  },
  {
    "text": "one will talk about hierarchical data hierarchical data is is really about how a little teepee apps use the data right",
    "start": "2091710",
    "end": "2097290"
  },
  {
    "start": "2092000",
    "end": "2092000"
  },
  {
    "text": "we talked about you know the these relational structures that we know and back in the day you know when we build",
    "start": "2097290",
    "end": "2102540"
  },
  {
    "text": "relational database it was pretty easy I get to say what kind of what data do you need I just identify the elements that the",
    "start": "2102540",
    "end": "2108060"
  },
  {
    "text": "relationships and the database normalize everything put it in third normal form you know and and then I then I just",
    "start": "2108060",
    "end": "2113790"
  },
  {
    "text": "tweaked the queries to support what the application developers required now it's not quite so easy in no SQL I need to",
    "start": "2113790",
    "end": "2119430"
  },
  {
    "text": "understand exactly what the developers need how they what the access pattern is so that I can build this structure for",
    "start": "2119430",
    "end": "2124830"
  },
  {
    "text": "it but the reality is I what I'm doing is I'm building these higher structures using entity driven workflows",
    "start": "2124830",
    "end": "2130950"
  },
  {
    "text": "right a user an invoice a payment right you know the data gets spread out across these tables and it requires complex",
    "start": "2130950",
    "end": "2137609"
  },
  {
    "text": "queries in SQL to assemble all this and we don't want that so how do I represent those structures in in dynamodb so let's",
    "start": "2137609",
    "end": "2143970"
  },
  {
    "text": "take a look at that relational structure it was distributed out across multiple tables there's a couple ways that we can maintain hierarchical structures in",
    "start": "2143970",
    "end": "2150779"
  },
  {
    "text": "DynamoDB in this particular example what we've done is we've created multiple items and we've created hierarchies",
    "start": "2150779",
    "end": "2157079"
  },
  {
    "text": "under each product ID so I've heard for a book there's only one item books where",
    "start": "2157079",
    "end": "2163319"
  },
  {
    "text": "you could remember is a one-to-one relationship so I can build the one item for the book it has all the properties",
    "start": "2163319",
    "end": "2168779"
  },
  {
    "text": "of the book now for albums I have multiple tracks per album so I would have a product ID and then an album ID",
    "start": "2168779",
    "end": "2175049"
  },
  {
    "text": "and then maybe you know album concatenated with track ID you know so",
    "start": "2175049",
    "end": "2180450"
  },
  {
    "text": "on and so forth and then I would be able to build the hierarchy of albums and tracks and the same with movies and",
    "start": "2180450",
    "end": "2185609"
  },
  {
    "text": "actors right so what I what I what have I really done here I've taken all those tables I've collapsed them into one and",
    "start": "2185609",
    "end": "2191160"
  },
  {
    "text": "if I want to get a particular Product ID I say select from this table where Product ID equals two in boom here comes a hierarchical data structure that",
    "start": "2191160",
    "end": "2197400"
  },
  {
    "text": "represents that product right okay I want to get all the tracks you know for I preferred for you know album to give",
    "start": "2197400",
    "end": "2205170"
  },
  {
    "text": "me all the you know elements that start with an album ID and then a track indicator or something like that right I",
    "start": "2205170",
    "end": "2210630"
  },
  {
    "text": "mean there's lots of ways to play with this type of data think about you can create higher you know create and you know documents of any size can be",
    "start": "2210630",
    "end": "2217079"
  },
  {
    "text": "supported using these types of item higher hierarchies I can index any attribute one of the limitations of",
    "start": "2217079",
    "end": "2223170"
  },
  {
    "text": "dynamodb today is if I use JSON attributes that Canada index the attributes the actual properties of the",
    "start": "2223170",
    "end": "2228539"
  },
  {
    "text": "JSON object are not indexable in hierarchies that are maintained this way I can actually index every attribute so",
    "start": "2228539",
    "end": "2235049"
  },
  {
    "text": "those are the kind of reasons that I would use that there's another way to maintain those hierarchies is probably you could say a little simpler would be",
    "start": "2235049",
    "end": "2241500"
  },
  {
    "text": "to actually use JSON attributes it's the same data structure now that's being you",
    "start": "2241500",
    "end": "2246509"
  },
  {
    "text": "know maintained on the on the table as JSON attributes and what I might do in this particular case I'll project",
    "start": "2246509",
    "end": "2252180"
  },
  {
    "text": "attributes to the route that I want to index on right so I actually pull",
    "start": "2252180",
    "end": "2257279"
  },
  {
    "text": "attributes out of the JSON document put those in his top-level first-class elements of the item it's",
    "start": "2257279",
    "end": "2262329"
  },
  {
    "text": "so I can create indexes on those attributes now why would I choose one oh the over the other in this particular",
    "start": "2262329",
    "end": "2268059"
  },
  {
    "text": "case I might say the items are small so there's a write penalty if I do it like",
    "start": "2268059",
    "end": "2273549"
  },
  {
    "text": "this right each one of these items cost me 1k 1k 1k so it actually cost me 4 RC",
    "start": "2273549",
    "end": "2278859"
  },
  {
    "text": "use or WCU's to to write this item now when I read the item it's okay because it will aggregate the read but on the",
    "start": "2278859",
    "end": "2285670"
  },
  {
    "text": "right I pay a penalty so if I'm writing and I've write heavy workload and I have really small JSON attributes I might or",
    "start": "2285670",
    "end": "2291339"
  },
  {
    "text": "JSON documents I might choose to go this route because I can actually aggregate the right cost and just write it into",
    "start": "2291339",
    "end": "2297099"
  },
  {
    "text": "one attribute and then maybe there's a little bit of duplicate duplicitous I project those attributes up into the",
    "start": "2297099",
    "end": "2302439"
  },
  {
    "text": "top-level item to index on but you know that's okay I mean it gives me the ability to support the access pattern",
    "start": "2302439",
    "end": "2307719"
  },
  {
    "text": "it's OK about one of the things about no SQL you need to understand data duplication is ok it's ok to have a",
    "start": "2307719",
    "end": "2313059"
  },
  {
    "text": "little bit of you know maybe I put that guy's name in the database a thousand times right because I don't really care",
    "start": "2313059",
    "end": "2319299"
  },
  {
    "text": "about the cost of storage I care about the cost of the CPU you know in the back of the day of normalized data is",
    "start": "2319299",
    "end": "2324849"
  },
  {
    "text": "beautiful right everything only appears once and we don't do we don't duplicate the data anywhere but you pay for you",
    "start": "2324849",
    "end": "2330249"
  },
  {
    "text": "pay for the cost you pay for the you know the CPU that's required to you know pull that data in and out of the",
    "start": "2330249",
    "end": "2335349"
  },
  {
    "start": "2335000",
    "end": "2335000"
  },
  {
    "text": "database so getting into scenarios and best practices I won't talk to all of these I don't think we have enough time but I will talk to you a couple the ones",
    "start": "2335349",
    "end": "2341499"
  },
  {
    "text": "that I feel are the most important the idea here is we're talking about query filters versus composite key indexes so in this particular example I've got an",
    "start": "2341499",
    "end": "2347769"
  },
  {
    "start": "2346000",
    "end": "2346000"
  },
  {
    "text": "online gaming scenario where my partition key is a game ID and game at game items have status and so what I'm",
    "start": "2347769",
    "end": "2354549"
  },
  {
    "text": "looking for is I want to actually write a query where I want to select star from the game table where my opponent is Bob",
    "start": "2354549",
    "end": "2360429"
  },
  {
    "start": "2357000",
    "end": "2357000"
  },
  {
    "text": "and the status is pending and I also want it ordered by the date right so we",
    "start": "2360429",
    "end": "2366249"
  },
  {
    "text": "know that we can you know select the from the partition key by you know the opponents Bob he's our partition key",
    "start": "2366249",
    "end": "2371739"
  },
  {
    "text": "great no problem you know we know we can sort on the order and that's great but what do we deal with this you know status that's a sec that's a third",
    "start": "2371739",
    "end": "2378309"
  },
  {
    "text": "condition how do we query on those three conditions right so you know the way we do that in dynamodb is we write a filter",
    "start": "2378309",
    "end": "2384429"
  },
  {
    "start": "2380000",
    "end": "2380000"
  },
  {
    "text": "condition okay so you can in essence select star from game where the opponent",
    "start": "2384429",
    "end": "2389650"
  },
  {
    "text": "equals Bob all right no problem you get all the records where deny opponent equals Bob I'm go order by date",
    "start": "2389650",
    "end": "2395859"
  },
  {
    "text": "I got my range key there and I can pull back those three items and I'm going to apply the filter condition to those three items and return only and what the",
    "start": "2395859",
    "end": "2401829"
  },
  {
    "text": "only the ones that match it so I'll in essence read more data then I'm gonna return to you that's good for a query",
    "start": "2401829",
    "end": "2408099"
  },
  {
    "text": "that's maybe not so selective right or you know that's it's not as selective as you need to be right but it also costs",
    "start": "2408099",
    "end": "2416109"
  },
  {
    "text": "because you're paying the extra RCU of reading the items that you're not returning you're lowering the cost across the wire a little bit less",
    "start": "2416109",
    "end": "2421930"
  },
  {
    "text": "bandwidth but you're still paying the RCU penalty what I call is that's like needle in a haystack here's a bunch of hay filter it out right now look we",
    "start": "2421930",
    "end": "2429130"
  },
  {
    "start": "2425000",
    "end": "2425000"
  },
  {
    "text": "found the items we need and that can that's fine if you're not necessarily reading a ton of items and returning a few I mean if I'm reading like a hundred",
    "start": "2429130",
    "end": "2436089"
  },
  {
    "text": "items I'm returning ninety then they that filter condition is not so painful if I'm reading a hundred items and I'm",
    "start": "2436089",
    "end": "2441549"
  },
  {
    "text": "returning to then maybe I'd rather have a more selective index right so how do we build more selective indexes again",
    "start": "2441549",
    "end": "2448329"
  },
  {
    "start": "2446000",
    "end": "2446000"
  },
  {
    "text": "you can use that query filter to return they turn return less on the wire you're still paying that read cost but the way",
    "start": "2448329",
    "end": "2453670"
  },
  {
    "start": "2453000",
    "end": "2453000"
  },
  {
    "text": "to build a selective index is use what we call composite keys all right in composite key scenario what I'm going to do is concatenate the the status and the",
    "start": "2453670",
    "end": "2460960"
  },
  {
    "text": "date and I create a new composite key value called status date okay and what does this do if we look at the table",
    "start": "2460960",
    "end": "2467380"
  },
  {
    "text": "structure now you can see we are actually creating a nested sort right I've sorted that table now not only by",
    "start": "2467380",
    "end": "2473890"
  },
  {
    "text": "status but by date I can get all the in progress games sorted by date you know",
    "start": "2473890",
    "end": "2479589"
  },
  {
    "text": "give me all the in progress games for Carol that are you know they give me all the games for Carol they'd start with in",
    "start": "2479589",
    "end": "2485589"
  },
  {
    "text": "progress boom I have a sorted list of her date of her stat you know in progress games by date so we write this",
    "start": "2485589",
    "end": "2492400"
  },
  {
    "text": "query now with the composite key I say hey give me they give me the games where the opponent equals Bob and it begins",
    "start": "2492400",
    "end": "2498999"
  },
  {
    "text": "with pending now I have a much more selective result set right I filtered out off the off the range query and I",
    "start": "2498999",
    "end": "2505690"
  },
  {
    "text": "don't have to read those items off the disk to return him back to the user and so this is more or less hey let's get",
    "start": "2505690",
    "end": "2511660"
  },
  {
    "text": "the hey let's sort it all and let's find that that's there's the needle DynamoDB index is by default are always sparse",
    "start": "2511660",
    "end": "2517269"
  },
  {
    "start": "2516000",
    "end": "2516000"
  },
  {
    "text": "you don't enable them but they just are if you index an attribute and the attribute and insert an item on the",
    "start": "2517269",
    "end": "2523239"
  },
  {
    "text": "table it doesn't include that attribute it just won't show up in the index that's a good way to create these types",
    "start": "2523239",
    "end": "2528410"
  },
  {
    "text": "of sorted so highly selective indexes for in this particular case we do or like Awards games might have billions of",
    "start": "2528410",
    "end": "2533810"
  },
  {
    "text": "users or millions of users but they're not going to have millions of people winning them you know the top awards",
    "start": "2533810",
    "end": "2538940"
  },
  {
    "text": "right the top ten the top twenty oh so if I put attributes on specific users indicating the awards they've won",
    "start": "2538940",
    "end": "2544850"
  },
  {
    "text": "I can now provision a users table with a very high write capacity or read",
    "start": "2544850",
    "end": "2550190"
  },
  {
    "text": "capacity and an awards GSI with a very very low read/write capacity because I know it's totally sparse for every",
    "start": "2550190",
    "end": "2556640"
  },
  {
    "text": "million items I end up here in insert here I'm gonna get a hundred in the other table right so you can actually kind of run the math in your head and",
    "start": "2556640",
    "end": "2562970"
  },
  {
    "text": "understand that the rate of insert in the in the index is gonna be much lower than the table and you can adjust",
    "start": "2562970",
    "end": "2568460"
  },
  {
    "text": "capacity that way so not always do indexes need to have the same write capacity as the parent table replace",
    "start": "2568460",
    "end": "2574520"
  },
  {
    "text": "filters with indexes compat innate attributes create those composite keys you know take advantage of sparse",
    "start": "2574520",
    "end": "2580700"
  },
  {
    "start": "2575000",
    "end": "2575000"
  },
  {
    "text": "indexes these are all the strategies that you use when you want to optimize the result set or create a selective and",
    "start": "2580700",
    "end": "2587600"
  },
  {
    "text": "index as possible so the other one that we want to talk to you is a real time voting scenario and it's actually really",
    "start": "2587600",
    "end": "2593570"
  },
  {
    "text": "about right heavy items and hot keys hot keys are the things the number one thing that I deal with the most with customers",
    "start": "2593570",
    "end": "2599660"
  },
  {
    "text": "you know they just they create some aggregation they don't understand it's very very thick aggregation or there or",
    "start": "2599660",
    "end": "2606170"
  },
  {
    "text": "it's a very hot access pattern and they don't understand with what they're doing is nailing that workload to a single",
    "start": "2606170",
    "end": "2612080"
  },
  {
    "text": "storage node and so you know typical scenario that starts this is a voting scenario right you got millions of",
    "start": "2612080",
    "end": "2617990"
  },
  {
    "start": "2614000",
    "end": "2614000"
  },
  {
    "text": "people coming in to vote for things and really only one or two things are popular right so if I'm starting to",
    "start": "2617990",
    "end": "2623480"
  },
  {
    "text": "aggregate all the votes per for by candidate what ends up happening is they all start coming in on a single partition because a single candidate ID",
    "start": "2623480",
    "end": "2629930"
  },
  {
    "text": "and you know it because creates problems in the datastore creates these hot keys and every no SQL database suffers from",
    "start": "2629930",
    "end": "2636770"
  },
  {
    "text": "this disease so how do we stop that from happening well the ID the basic idea here is you create more candidates right",
    "start": "2636770",
    "end": "2642050"
  },
  {
    "start": "2638000",
    "end": "2638000"
  },
  {
    "text": "instead of having just candidate a and candidate B I'm gonna have candidate a with a series of random values in a",
    "start": "2642050",
    "end": "2650000"
  },
  {
    "text": "known range right say candidate a 0 to 100 and then every time I get an insert",
    "start": "2650000",
    "end": "2655010"
  },
  {
    "text": "I'm going to just tack a random value between 0 and 100 whatever zero and ten in this example I",
    "start": "2655010",
    "end": "2660160"
  },
  {
    "text": "think on to the end of that candidate ID and now in essence I've created more",
    "start": "2660160",
    "end": "2665320"
  },
  {
    "text": "buckets I can spread the votes across multiple buckets when I go read the aggregation I scatter gather all the",
    "start": "2665320",
    "end": "2671950"
  },
  {
    "start": "2669000",
    "end": "2669000"
  },
  {
    "text": "results you know why does this work it works because DynamoDB scales linearly across threads and actually single",
    "start": "2671950",
    "end": "2677530"
  },
  {
    "text": "thread performance and DynamoDB he's not great you'll find that if you try to get you know increase the throughput by you",
    "start": "2677530",
    "end": "2683530"
  },
  {
    "text": "know running you know a higher powered processor you're not going to be able to do that i mean it's a it's a web api",
    "start": "2683530",
    "end": "2689200"
  },
  {
    "text": "right that's got to make us it's got to make a connection across the public Internet but what it does do is scales",
    "start": "2689200",
    "end": "2695590"
  },
  {
    "text": "linearly across threads so I can spin up any number of threads I'll never break DynamoDB the way people get millions of",
    "start": "2695590",
    "end": "2701320"
  },
  {
    "text": "connections per millions requests per second now dynamo is by running thousands of threads right not thousands",
    "start": "2701320",
    "end": "2707920"
  },
  {
    "text": "necessarily hundreds but the idea is you know don't-don't-don't you know a single single thread your workflow so you run",
    "start": "2707920",
    "end": "2714280"
  },
  {
    "text": "the scatter gather process to go ahead and produce the aggregate result set and that in essence it now allows you to",
    "start": "2714280",
    "end": "2719950"
  },
  {
    "text": "distribute the the the aggregation across multiple buckets I have many many",
    "start": "2719950",
    "end": "2725050"
  },
  {
    "text": "customers that deal with this one of my customers is a they track prescription pill bottles every prescription pill",
    "start": "2725050",
    "end": "2730750"
  },
  {
    "text": "bottle has a unique serial number and they need to do things like track by you know a time period or aggregate by",
    "start": "2730750",
    "end": "2737110"
  },
  {
    "text": "manufacturer or a lot number and literally billions and billions of items they're shoving onto their tables and they're spreading them out across you",
    "start": "2737110",
    "end": "2743500"
  },
  {
    "text": "know a thousand buckets on their larger manufacturers so a very common access pattern to deal with or design pattern",
    "start": "2743500",
    "end": "2750370"
  },
  {
    "text": "to deal with that high velocity aggregations yeah we talk a lot about what we call these days Cerberus",
    "start": "2750370",
    "end": "2755500"
  },
  {
    "start": "2754000",
    "end": "2754000"
  },
  {
    "text": "architecture it's the ability to use these back playing services like dynamo DB and this chart actually shows you you",
    "start": "2755500",
    "end": "2762070"
  },
  {
    "text": "know DynamoDB as well as a variety of other AWS services I have many many customers now they're building you know",
    "start": "2762070",
    "end": "2768340"
  },
  {
    "text": "full scale applications using nothing but these backplane services and these",
    "start": "2768340",
    "end": "2774310"
  },
  {
    "start": "2774000",
    "end": "2774000"
  },
  {
    "text": "types of applications look like this so this is one that we actually wrote for an internal app we have a PMO for the",
    "start": "2774310",
    "end": "2781780"
  },
  {
    "text": "essays the global SAT but at AWS and one of the requests came in was the ability to collect what we call anytime feedback",
    "start": "2781780",
    "end": "2789220"
  },
  {
    "text": "you know from customers right now internally we have the to give any member of AWS or Amazon can",
    "start": "2789220",
    "end": "2795640"
  },
  {
    "text": "give anybody else any time feedback and we like that system and we wanted our customers to have the ability access",
    "start": "2795640",
    "end": "2801340"
  },
  {
    "text": "that system but in order to do that we would have had to expose internal API is that were just not built for public",
    "start": "2801340",
    "end": "2807220"
  },
  {
    "text": "access so we actually built an application when we came back from the development team to build the app to do",
    "start": "2807220",
    "end": "2813250"
  },
  {
    "text": "it they kay said something like 17 I develop er weeks 12 p.m. weeks you know to be able to put an RDS backed",
    "start": "2813250",
    "end": "2819550"
  },
  {
    "text": "application service out there and we looked at it this was the last reinvent for last right after we announced lambda",
    "start": "2819550",
    "end": "2826119"
  },
  {
    "text": "and we looked at and said you know this looks like something we should be able do at lambda so we put a nice little form processing application together for",
    "start": "2826119",
    "end": "2832420"
  },
  {
    "text": "lambda do exactly this users basically get a male form",
    "start": "2832420",
    "end": "2837490"
  },
  {
    "text": "you know requesting you know feedback on the essay engagement they they pull that",
    "start": "2837490",
    "end": "2842619"
  },
  {
    "text": "form down from a secure s3 bucket that's configured to operate as a web server right and then that form when they hit",
    "start": "2842619",
    "end": "2849130"
  },
  {
    "text": "post makes an AJAX called the API gateway API gateway logs the request parses the form data using a lambda",
    "start": "2849130",
    "end": "2855280"
  },
  {
    "text": "function splits the PII personally identifiable information out into it encrypted s3 bucket because we didn't",
    "start": "2855280",
    "end": "2861010"
  },
  {
    "text": "want to store that off in dynamo you know unencrypted and then the using the search metadata puts it up in dynamo DB",
    "start": "2861010",
    "end": "2867850"
  },
  {
    "text": "and then sends a little notification off to the hiring manager or the essay manager says somebody got feedback so",
    "start": "2867850",
    "end": "2874330"
  },
  {
    "text": "this application was actually built in four hours in my spare time one night a hotel up in Seattle working with the PM",
    "start": "2874330",
    "end": "2880150"
  },
  {
    "text": "we went to production about three weeks after I wrote the initial prototype and",
    "start": "2880150",
    "end": "2885940"
  },
  {
    "text": "you know it basically took a 39 week development effort and turned it into a",
    "start": "2885940",
    "end": "2891070"
  },
  {
    "text": "part-time effort over two or three weeks the application is really interesting to me because it actually a hosting cost on",
    "start": "2891070",
    "end": "2897609"
  },
  {
    "text": "this is about I don't know a penny a month you know because I really literally it's less than that I mean we",
    "start": "2897609",
    "end": "2903369"
  },
  {
    "text": "have a couple of freaking things up in s3 and then we have an API gateway configuration and we don't even pay for",
    "start": "2903369",
    "end": "2909520"
  },
  {
    "text": "until it's used and we have a lambda function configuration that doesn't get paid for until it's used and customers",
    "start": "2909520",
    "end": "2914680"
  },
  {
    "text": "and we probably get 158 you know form requests a month service from the customer right so I mean the land that",
    "start": "2914680",
    "end": "2920890"
  },
  {
    "text": "cost it's all free tier you know again the application was built does and deployed for less than the cost of",
    "start": "2920890",
    "end": "2927340"
  },
  {
    "text": "my lunch and and yet it can scale to support a million users if they showed up tomorrow I mean how do you I mean",
    "start": "2927340",
    "end": "2934210"
  },
  {
    "text": "that's the that is the real power of what we talk about when we talk about serverless compute is being able to leverage these",
    "start": "2934210",
    "end": "2940210"
  },
  {
    "text": "back playing services to deliver applications that could stand up to an amazing amount of scale at a",
    "start": "2940210",
    "end": "2946750"
  },
  {
    "text": "ridiculously low cost right I mean it's it's certainly a wave of the future it's also and kind of a something showing us",
    "start": "2946750",
    "end": "2953650"
  },
  {
    "text": "what what was the new thing with cloud right was all ec2 in VMs and demand you",
    "start": "2953650",
    "end": "2960100"
  },
  {
    "text": "know servers and whatnot that's now old news we're beyond that we're in the day a fully elastic compute backplane",
    "start": "2960100",
    "end": "2966730"
  },
  {
    "text": "services like DynamoDB api gateway and lambda that lets you do amazing things like this and so that's what I got for",
    "start": "2966730",
    "end": "2972850"
  },
  {
    "text": "you guys sorry we can get to go through the whole presentation but thank you very much for listening",
    "start": "2972850",
    "end": "2978720"
  }
]
[
  {
    "text": "okay good afternoon so my name is calm I'm principal engineer on elastic load",
    "start": "1490",
    "end": "9330"
  },
  {
    "text": "balancing which is a service hopefully every here is everyone here is probably",
    "start": "9330",
    "end": "14340"
  },
  {
    "text": "at least a little bit familiar with so actually joined it'll be about a year ago I've worked today list quite a bit",
    "start": "14340",
    "end": "21900"
  },
  {
    "text": "longer than that but I joined he'll be about a year ago spent the last year I'm",
    "start": "21900",
    "end": "27689"
  },
  {
    "text": "not just working on lb but also meeting a lot of our customers and figuring out",
    "start": "27689",
    "end": "32989"
  },
  {
    "text": "how they use the LB what we can do better for them all those kinds of things and pretty much everything that's",
    "start": "32989",
    "end": "39600"
  },
  {
    "text": "in this presentation comes from that comes from best practices that I've",
    "start": "39600",
    "end": "45960"
  },
  {
    "text": "learned from customers how they're how they're using ELB the patterns they're applying and how they're building it",
    "start": "45960",
    "end": "53129"
  },
  {
    "text": "into their businesses so we're gonna cover that and then we're gonna cover some some deep dives into parts of the",
    "start": "53129",
    "end": "61260"
  },
  {
    "text": "internal architecture of ELB how we do some specific security things how we",
    "start": "61260",
    "end": "67170"
  },
  {
    "text": "manage our availability and things like that so hopefully there'll be a lot to learn from just a very very quick primer",
    "start": "67170",
    "end": "74310"
  },
  {
    "text": "on elastic load balancer so we you create an elastic load balancer",
    "start": "74310",
    "end": "80670"
  },
  {
    "text": "it has listeners they listen on a tcp/ip port pair and they take traffic",
    "start": "80670",
    "end": "86960"
  },
  {
    "text": "ordinarily will terminate SSL as well for customers that's pretty popular",
    "start": "86960",
    "end": "93000"
  },
  {
    "text": "where will do will do I manage the encryption and then you register",
    "start": "93000",
    "end": "98400"
  },
  {
    "text": "instances or auto-scaling groups behind the low bouncer and we direct traffic to it right so that's he'll be at the very",
    "start": "98400",
    "end": "104790"
  },
  {
    "text": "very high level but we're gonna get into it a lot more detail than that and we're gonna cover three do it in three",
    "start": "104790",
    "end": "113040"
  },
  {
    "text": "sections first is gonna be security so how alb provides manages security for",
    "start": "113040",
    "end": "121079"
  },
  {
    "text": "the applications that are behind it and some of how we implement our own security features the second thing we're",
    "start": "121079",
    "end": "128310"
  },
  {
    "text": "going to cover is scalability right how ELB helps",
    "start": "128310",
    "end": "133350"
  },
  {
    "text": "you scale for your numbers of requests whether it's very small number is a very",
    "start": "133350",
    "end": "140010"
  },
  {
    "text": "large number is whether it's low bandwidth or very high bandwidth and finally we're gonna cover availability how will be integrates into keeping",
    "start": "140010",
    "end": "147890"
  },
  {
    "text": "keeping your installation online all the time okay so we'll start with security",
    "start": "147890",
    "end": "154430"
  },
  {
    "text": "so I want to emphasize that everything I'm gonna cover here in the Security",
    "start": "154430",
    "end": "160350"
  },
  {
    "text": "section it's true independent of whether you use elastic load balancer as a low",
    "start": "160350",
    "end": "168510"
  },
  {
    "text": "bouncer right so I'll give you an example I run my own personal just toy",
    "start": "168510",
    "end": "175910"
  },
  {
    "text": "instance and website on ec2 I have a t2 that micro because I don't I can't",
    "start": "175910",
    "end": "182850"
  },
  {
    "text": "justify spending any more money than that on my own Toby projects and it's just got some very old blogs and things that I just",
    "start": "182850",
    "end": "192120"
  },
  {
    "text": "want to keep on line but it's not availability critical or anything like that but just from my own can a peace of",
    "start": "192120",
    "end": "199680"
  },
  {
    "text": "mind and the ease of use I actually run that even though it's one instance behind an elastic load balancer and",
    "start": "199680",
    "end": "205590"
  },
  {
    "text": "there's now partly that's because I work on ELB and I want to be able to use on a",
    "start": "205590",
    "end": "211140"
  },
  {
    "text": "day-to-day basis and stay very familiar with how it works but it's also partially because it's it's doing things for me like SSL that I",
    "start": "211140",
    "end": "218910"
  },
  {
    "text": "no longer have to worry about on the back end and and helps protect me from from various threats so one best",
    "start": "218910",
    "end": "226530"
  },
  {
    "text": "practice when it comes to security stuff is to think about your trap model right water what are the things we're",
    "start": "226530",
    "end": "232530"
  },
  {
    "text": "defending against and there's some specific things that having that ELB",
    "start": "232530",
    "end": "238140"
  },
  {
    "text": "helps us with here the the tree I've highlighted are defending against",
    "start": "238140",
    "end": "246410"
  },
  {
    "text": "weaknesses and cryptographic protocols so we'll go into that software",
    "start": "246410",
    "end": "251640"
  },
  {
    "text": "vulnerabilities so just vulnerability in the software that you might be running behind an EOB explain a little a little",
    "start": "251640",
    "end": "257310"
  },
  {
    "text": "bit how we helped with that and and things like account disclosure such as simple things like passwords and so on",
    "start": "257310",
    "end": "262770"
  },
  {
    "text": "get lost right and it might it might seem strange and unfamiliar that ially can",
    "start": "262770",
    "end": "268560"
  },
  {
    "text": "help with those things but what I find out from talking to customers is that it's actually a really really common a",
    "start": "268560",
    "end": "273630"
  },
  {
    "text": "common reason why people are using a I'll be surprised me so I thought it was",
    "start": "273630",
    "end": "279120"
  },
  {
    "text": "worth going into here so the first of those is probably our most popular",
    "start": "279120",
    "end": "286020"
  },
  {
    "text": "feature and and thing that we've seen the most activity on over the last 18",
    "start": "286020",
    "end": "292860"
  },
  {
    "text": "months in particular which is SSL and defending and script or graphic vulnerabilities so the last 18 months",
    "start": "292860",
    "end": "300270"
  },
  {
    "text": "has seen a lot of new research and progress in the analysis of encryption",
    "start": "300270",
    "end": "308490"
  },
  {
    "text": "modes and the security properties of various protocols which is great that's",
    "start": "308490",
    "end": "315210"
  },
  {
    "text": "a really positive development the people are really scrutinizing these things and finding every weakness that's there so they can be improved but it also means",
    "start": "315210",
    "end": "322890"
  },
  {
    "text": "we've had to turn around and respond very quickly to each of those as they're",
    "start": "322890",
    "end": "328530"
  },
  {
    "text": "found so by terminating SSL on the EOB we",
    "start": "328530",
    "end": "334380"
  },
  {
    "text": "manage all that right so some examples of things that we've done there is when",
    "start": "334380",
    "end": "339450"
  },
  {
    "text": "the portal vulnerability came out which essentially said that SSL v3 is no longer secure so that came out of",
    "start": "339450",
    "end": "345060"
  },
  {
    "text": "November last year the the very same day the paper was released and made public we had a new lbph security policy to",
    "start": "345060",
    "end": "351630"
  },
  {
    "text": "disable SSL v3 and that was our new default if you created a new ELB that",
    "start": "351630",
    "end": "357120"
  },
  {
    "text": "day it would no longer have SSL v3 I mean also encouraged all of our customers to take their existing elby's",
    "start": "357120",
    "end": "363960"
  },
  {
    "text": "and migrate from them to that policy it's very easy to do you can do it in the console very quickly or with our API",
    "start": "363960",
    "end": "369590"
  },
  {
    "text": "we saw a very quick adoption with that and when in a day or two 62% of REO B's",
    "start": "369590",
    "end": "375870"
  },
  {
    "text": "had converted to that new security policy within a month it was in the high 90s so we saw great adoption there we",
    "start": "375870",
    "end": "384450"
  },
  {
    "text": "also saw earlier this year the the log jam vulnerability was disclosed which",
    "start": "384450",
    "end": "391229"
  },
  {
    "text": "was just improvements in how diffie-hellman encryption can be attacked and",
    "start": "391229",
    "end": "397389"
  },
  {
    "text": "and it was disclosed that you know certain key sizes and so long were no longer secure and so we took it I took a",
    "start": "397389",
    "end": "404919"
  },
  {
    "text": "very close look at that again the same day it was released we actually had new security policies available there just",
    "start": "404919",
    "end": "410889"
  },
  {
    "text": "completely disabled diffie-hellman encryption on your elby's that's okay",
    "start": "410889",
    "end": "417669"
  },
  {
    "text": "diffie-hellman encryption plays a role in my score called perfect forward secrecy I'll talk about that in a few",
    "start": "417669",
    "end": "423699"
  },
  {
    "text": "slides but there's actually a much more modern alternative available based on elliptic curves and so we felt that the most",
    "start": "423699",
    "end": "430479"
  },
  {
    "text": "pragmatic thing to do was just turn off turn off diffie-hellman we released that policy that same day and again we saw a",
    "start": "430479",
    "end": "437469"
  },
  {
    "text": "lot of people upgrading very quickly when when the Harpe lead Suffern ability was disclosed against open SSL again on",
    "start": "437469",
    "end": "445990"
  },
  {
    "text": "the same day we had upgraded every ELB without downtime which is pretty neat",
    "start": "445990",
    "end": "452909"
  },
  {
    "text": "and not quite a clear you know day on",
    "start": "452909",
    "end": "458469"
  },
  {
    "text": "which the rc4 encryption algorithm was just simply declared and secure it's more a theme that kind of gradually",
    "start": "458469",
    "end": "465250"
  },
  {
    "text": "became consensus over a period of months and years we had we have removed the rc4",
    "start": "465250",
    "end": "471400"
  },
  {
    "text": "encryption algorithm from our default security policies quite quite far in",
    "start": "471400",
    "end": "477580"
  },
  {
    "text": "advance of the coming out of things like the ratings tools that give you an SSL rating or various compliance programs",
    "start": "477580",
    "end": "486009"
  },
  {
    "text": "and so on so we're doing so we're keeping up to date with these policies essentially so you don't have to right",
    "start": "486009",
    "end": "493029"
  },
  {
    "text": "so when one of these things come out switch your policy to latest thing and",
    "start": "493029",
    "end": "500080"
  },
  {
    "text": "you should be you should be in a pretty good position one of the reasons we're able to do this and respond so quickly",
    "start": "500080",
    "end": "506699"
  },
  {
    "text": "to these things is we've actually been working and released over the summer our",
    "start": "506699",
    "end": "513518"
  },
  {
    "text": "own implementation of SSL and TLS so",
    "start": "513519",
    "end": "518560"
  },
  {
    "text": "it's called s twin which is short for signal-to-noise it's on github you can go look at the code you can see how the",
    "start": "518560",
    "end": "524169"
  },
  {
    "text": "project's doing it's written in about five times five thousand lines of code",
    "start": "524169",
    "end": "530240"
  },
  {
    "text": "which compares to about 150,000 lines of code to do the same functionality in",
    "start": "530240",
    "end": "537319"
  },
  {
    "text": "open SSL so we feel it's it's it's probably in a much better position against security vulnerabilities and so",
    "start": "537319",
    "end": "544279"
  },
  {
    "text": "on we're not using this yet in ELB we're gonna take a very conservative approach",
    "start": "544279",
    "end": "549559"
  },
  {
    "text": "to migrating the service over to it we're going to a lot of extensive security reviews we're working with a",
    "start": "549559",
    "end": "555829"
  },
  {
    "text": "lot of people in the community to analyze it as closely as possible but would be made will be migrating a SS",
    "start": "555829",
    "end": "562309"
  },
  {
    "text": "services including ELB to it but in the meantime it also means we have a deep expertise in SSL and TLS we know it at",
    "start": "562309",
    "end": "570559"
  },
  {
    "text": "the implementation level and we're involved in the community you know we attend things like the the SSL",
    "start": "570559",
    "end": "577670"
  },
  {
    "text": "standardization meetings and so on and so when these papers come out we're",
    "start": "577670",
    "end": "582889"
  },
  {
    "text": "pretty well positioned to make judgments around what to do I'll explain our",
    "start": "582889",
    "end": "589579"
  },
  {
    "text": "thinking process there a little right so if you go to our console if you go to our API you'll see that we support these",
    "start": "589579",
    "end": "596929"
  },
  {
    "text": "security policies and we also have custom policies so the security policies is just a pre-baked",
    "start": "596929",
    "end": "602329"
  },
  {
    "text": "set of policies here's the ciphers we support our default is always a set that",
    "start": "602329",
    "end": "608569"
  },
  {
    "text": "we think is balances trade-offs between security and compatibility and a custom",
    "start": "608569",
    "end": "614779"
  },
  {
    "text": "one you can you can pick and choose whatever you like you can literally go through all of the various protocols",
    "start": "614779",
    "end": "620480"
  },
  {
    "text": "that we support and decide which ones you he want and don't want and so as I",
    "start": "620480",
    "end": "625490"
  },
  {
    "text": "said we're trying to manage balanced trade-offs between security and compatibility right if we literally",
    "start": "625490",
    "end": "631639"
  },
  {
    "text": "boiled everything down to just the absolutely most secure you know most CPU",
    "start": "631639",
    "end": "638629"
  },
  {
    "text": "intensive encryption algorithm very very few clients would work with that right and and your sites and installations",
    "start": "638629",
    "end": "645079"
  },
  {
    "text": "just wouldn't work so that that wouldn't be acceptable and then on the other hand if we just included everything obviously",
    "start": "645079",
    "end": "651410"
  },
  {
    "text": "there would be unsecure protocols and modes in there so what we do is we take the set that's available which is quite",
    "start": "651410",
    "end": "657920"
  },
  {
    "text": "a lot and we first pair it down to encryption algorithms that's our secure",
    "start": "657920",
    "end": "663529"
  },
  {
    "text": "at all so today we're in our default policies we support AES and three days encryption",
    "start": "663529",
    "end": "670450"
  },
  {
    "text": "and then we always always always prefer perfect forward secrecy so what that",
    "start": "670450",
    "end": "676460"
  },
  {
    "text": "means is if that's an encryption mode where even if your certificate was somehow compromised even if the private",
    "start": "676460",
    "end": "683030"
  },
  {
    "text": "key leaked you know even if somebody lost it it was on a USB Drive somewhere or something somebody who got that key",
    "start": "683030",
    "end": "690050"
  },
  {
    "text": "wouldn't be able to go back and decrypt any of your traffic that they had previously collected right so it's a",
    "start": "690050",
    "end": "696440"
  },
  {
    "text": "really really good mode to operate in so we always always prefer that and we see",
    "start": "696440",
    "end": "701710"
  },
  {
    "text": "you know today thanks to browsers which all have adopted this now we see if your",
    "start": "701710",
    "end": "708920"
  },
  {
    "text": "if your clients are generally browsers you know way into the 90s percent of traffic now uses perfect forward secrecy",
    "start": "708920",
    "end": "714410"
  },
  {
    "text": "which is great after that we we always prefer AES the encryption at the AES",
    "start": "714410",
    "end": "722420"
  },
  {
    "text": "encryption algorithm over three days which is the other one we support in our",
    "start": "722420",
    "end": "728420"
  },
  {
    "text": "default some of our policies still include or see for that not our default policy we wouldn't recommend using those",
    "start": "728420",
    "end": "735200"
  },
  {
    "text": "policies and next you need them for extreme backwards compatibility reasons but even in those cases we do prioritize",
    "start": "735200",
    "end": "742010"
  },
  {
    "text": "or c4 all the way down and then there's things called authentication modes which",
    "start": "742010",
    "end": "747380"
  },
  {
    "text": "are just around making sure the traffic can't be forged or tampered with on the",
    "start": "747380",
    "end": "753710"
  },
  {
    "text": "on the wire and there's several different modes in these protocols we",
    "start": "753710",
    "end": "758780"
  },
  {
    "text": "use GCM which is a Galois counter mode that's a preferred mode that's the the",
    "start": "758780",
    "end": "764630"
  },
  {
    "text": "most modern most secure mode over CBC and aged Mac so we always prefer those",
    "start": "764630",
    "end": "769760"
  },
  {
    "text": "and then what we do is we take those sets ever proposed ok here's what we think we should do right and we simulate",
    "start": "769760",
    "end": "778100"
  },
  {
    "text": "what would happen with that set of cipher suites against literally billions",
    "start": "778100",
    "end": "783230"
  },
  {
    "text": "of connections from real-world clients that are hitting sites like amazon.com right so we we have systems and",
    "start": "783230",
    "end": "792440"
  },
  {
    "text": "measurement processes set up where we could take a look and we can say okay we want to take this site",
    "start": "792440",
    "end": "797640"
  },
  {
    "text": "out is that gonna be safe are we gonna drop so much traffic that it's gonna cause and availability issues or is",
    "start": "797640",
    "end": "804630"
  },
  {
    "text": "pretty much everything out there it already has the more modern things and it's gonna be fine okay so that's a",
    "start": "804630",
    "end": "810240"
  },
  {
    "text": "process some legacy clients can like",
    "start": "810240",
    "end": "815970"
  },
  {
    "text": "cause trickiness there thankfully we don't see this a lot right if you're if your clients are mostly phones right or",
    "start": "815970",
    "end": "823610"
  },
  {
    "text": "browsers everything's really up to date right we see a lot you know great software update uptake rate with those",
    "start": "823610",
    "end": "831290"
  },
  {
    "text": "but if your if your clients are you know embedded systems firmwares on",
    "start": "831290",
    "end": "837540"
  },
  {
    "text": "televisions things that were you know shipped six years ago and nobody thought to include an auto update mechanism then",
    "start": "837540",
    "end": "844800"
  },
  {
    "text": "it may still only support you know SSL v3 and so on so in those cases you can",
    "start": "844800",
    "end": "851460"
  },
  {
    "text": "take a really close look and you can say well the traffic I'm sending you know there's no credit card data there's no",
    "start": "851460",
    "end": "857250"
  },
  {
    "text": "password data it's probably okay to still use those protocols in in those",
    "start": "857250",
    "end": "864030"
  },
  {
    "text": "cases you can you can run on an old security policy if you really really choose to we always recommend our most",
    "start": "864030",
    "end": "871860"
  },
  {
    "text": "recent which is 2015 - l5 so I want to",
    "start": "871860",
    "end": "877320"
  },
  {
    "text": "talk a little bit about how you can go about making that analysis if you are in one of those kind of corner cases so",
    "start": "877320",
    "end": "886800"
  },
  {
    "text": "it's a long-standing feature TLB has which is access locks right great feature and always recommend turning it",
    "start": "886800",
    "end": "892980"
  },
  {
    "text": "on will we'll talk a little more about in detail later but essentially we log",
    "start": "892980",
    "end": "898800"
  },
  {
    "text": "every request that we see and we've a bunch of parameters that we record for",
    "start": "898800",
    "end": "904710"
  },
  {
    "text": "each one and we'll upload it to s3 periodically right it's we have partner",
    "start": "904710",
    "end": "912180"
  },
  {
    "text": "integrations so you can take from s3 and feed it into our various partners and they can provide you with nice ways to",
    "start": "912180",
    "end": "919200"
  },
  {
    "text": "analyze that data and various gooeys and analytics and so on which is really really cool",
    "start": "919200",
    "end": "924540"
  },
  {
    "text": "but two weeks ago we released two new fields that we we now record in",
    "start": "924540",
    "end": "931420"
  },
  {
    "text": "the access logs which is we actually record this the SSL cipher suite that",
    "start": "931420",
    "end": "937630"
  },
  {
    "text": "was negotiated by the client for this request and the protocol version right so if in future you you're having to sit",
    "start": "937630",
    "end": "946480"
  },
  {
    "text": "down and think you know I need to disable say TLS 1.0 right because maybe",
    "start": "946480",
    "end": "952839"
  },
  {
    "text": "the next PCI certification requires me to well I want to I want to make an informed decision about what impact",
    "start": "952839",
    "end": "958089"
  },
  {
    "text": "that's gonna have on my user base right am I gonna drop an unacceptable",
    "start": "958089",
    "end": "963460"
  },
  {
    "text": "percentage of my clients and so you can that do that with the logs right you can you can look at the we always prioritize",
    "start": "963460",
    "end": "970960"
  },
  {
    "text": "things so that the least secure protocols come last right that's that's what that prioritization process",
    "start": "970960",
    "end": "976270"
  },
  {
    "text": "achieves so you can look at the logs and you can say well how many clients are still using TLS 1.0 even though it's",
    "start": "976270",
    "end": "983529"
  },
  {
    "text": "even though it's very last in the list right so you know if you turned it off they wouldn't be able to connect anymore",
    "start": "983529",
    "end": "988779"
  },
  {
    "text": "and you can do a you know request by request analysis you can look at the user agents and you can say that's these",
    "start": "988779",
    "end": "994630"
  },
  {
    "text": "clients I need to get them to upgrade or that's this coastal remind I need to talk to them and so you can gauge the",
    "start": "994630",
    "end": "1000779"
  },
  {
    "text": "impact before it happens which is pretty neat so I actually did this exercise",
    "start": "1000779",
    "end": "1008390"
  },
  {
    "text": "with a customer a few months ago where we were we were turning our fastest at v3 and we were worried we were because",
    "start": "1008390",
    "end": "1015450"
  },
  {
    "text": "they're our first kind of pasture and I even Alice's showed that almost a percent 0.8 percent of traffic was still",
    "start": "1015450",
    "end": "1022650"
  },
  {
    "text": "coming in over SSL v3 and for them 0.8 percent of traffic is a lot they didn't",
    "start": "1022650",
    "end": "1028470"
  },
  {
    "text": "they didn't want to just lose it and so we went through the logs there they",
    "start": "1028470",
    "end": "1033569"
  },
  {
    "text": "turned on access logs we went through those access loves with them one by one and we found that actually the clients",
    "start": "1033569",
    "end": "1042390"
  },
  {
    "text": "were web scrapers was nuisance robot traffic that had been just running on",
    "start": "1042390",
    "end": "1048960"
  },
  {
    "text": "bots and so on for years and no one was keeping them all today and we were there actually pleased to block them they",
    "start": "1048960",
    "end": "1055340"
  },
  {
    "text": "became enthusiastic it's like no no let's turn off SSL v3 now we don't we were always trying to find creative ways",
    "start": "1055340",
    "end": "1060810"
  },
  {
    "text": "to keep the web scrapers away so that was that was pretty interesting",
    "start": "1060810",
    "end": "1066620"
  },
  {
    "text": "so access logs also form a part of how people are applying ELB as a form of",
    "start": "1066620",
    "end": "1077960"
  },
  {
    "text": "network compartmentalization and so with ELB you can you can spin uh",
    "start": "1077960",
    "end": "1085080"
  },
  {
    "text": "PL bees in VP CSV BC is a virtual private cloud where you can have your",
    "start": "1085080",
    "end": "1091289"
  },
  {
    "text": "own data center in the cloud and you can spin up publicly Oh bees that have",
    "start": "1091289",
    "end": "1096360"
  },
  {
    "text": "public IP addresses that take Internet traffic right those are your front and DL bees and we support private ones too",
    "start": "1096360",
    "end": "1103980"
  },
  {
    "text": "where they have internal IP addresses and we can bounce traffic from either of those two instances and so on but what",
    "start": "1103980",
    "end": "1112559"
  },
  {
    "text": "we're seeing is people setting up Bo bees or their policies such that you",
    "start": "1112559",
    "end": "1119610"
  },
  {
    "text": "know the public subnet can only be e of ease right so that it's all front-end",
    "start": "1119610",
    "end": "1125100"
  },
  {
    "text": "traffic everything that comes in from the internet has to at least go through an e lb and and the effect of that is",
    "start": "1125100",
    "end": "1132299"
  },
  {
    "text": "that they have a certain form of governance or or firewalling on the",
    "start": "1132299",
    "end": "1139049"
  },
  {
    "text": "traffic so l bees are inbound only right inbound will take traffic from the",
    "start": "1139049",
    "end": "1144179"
  },
  {
    "text": "internet will pass it on to the instances but there's there's no way to go the other way so if all you can",
    "start": "1144179",
    "end": "1150090"
  },
  {
    "text": "provision in your public subnet of ZL bees that gives you alert is there of defense against things like data",
    "start": "1150090",
    "end": "1156030"
  },
  {
    "text": "exfiltration or or just somebody spinning up an instance in the public subnet and now it has full internet",
    "start": "1156030",
    "end": "1163049"
  },
  {
    "text": "access and so on but then they they can also be set up with access logs enabled",
    "start": "1163049",
    "end": "1169140"
  },
  {
    "text": "on various other kinds of logging enabled to really scrutinize the traffic as it comes in there's a few things that",
    "start": "1169140",
    "end": "1176610"
  },
  {
    "text": "it can do right so the first is just regular VPC security group integrations",
    "start": "1176610",
    "end": "1181830"
  },
  {
    "text": "so you can set up security group rules on the EO b's the front end the elby's to say here's where i want traffic to be",
    "start": "1181830",
    "end": "1187559"
  },
  {
    "text": "permitted from we this can all be locked",
    "start": "1187559",
    "end": "1192720"
  },
  {
    "text": "down using our identity and access management systems with roll accounts such that you",
    "start": "1192720",
    "end": "1201840"
  },
  {
    "text": "know you can bless or or provide a policy that says this particular role",
    "start": "1201840",
    "end": "1206970"
  },
  {
    "text": "account and only this particular role account can access the EOB API can",
    "start": "1206970",
    "end": "1212640"
  },
  {
    "text": "create a elby's in the public subnet nothing else can create public IP s in the public subnet so therefore only the",
    "start": "1212640",
    "end": "1219930"
  },
  {
    "text": "people with that role account which might be people in the security department or somebody with a privilege",
    "start": "1219930",
    "end": "1226470"
  },
  {
    "text": "level of access can can give that front-end access can do things like load",
    "start": "1226470",
    "end": "1233940"
  },
  {
    "text": "the SSL certificate right so and they don't need to use a password right they can set it up with tokens and so on",
    "start": "1233940",
    "end": "1240120"
  },
  {
    "text": "because it's more security sensitive operation and so the effect of that straightaway is that now anything that's",
    "start": "1240120",
    "end": "1247470"
  },
  {
    "text": "happening in your private subnet it's a little easier to be more liberal about what people can spin up instances there",
    "start": "1247470",
    "end": "1253740"
  },
  {
    "text": "and get get their work done without having to risk you know exposing some",
    "start": "1253740",
    "end": "1260250"
  },
  {
    "text": "new public endpoint or some new SSL certificate and so on if the account we're to be compromised",
    "start": "1260250",
    "end": "1269100"
  },
  {
    "text": "in some way this very privileged account somehow if it was using a password and",
    "start": "1269100",
    "end": "1274380"
  },
  {
    "text": "password was simply lost and so on we do support cloud trail logging so every action and ELB creating anyway you'll be",
    "start": "1274380",
    "end": "1280260"
  },
  {
    "text": "and so on it shows up in the cloud trail log so you can be you can see what's",
    "start": "1280260",
    "end": "1285360"
  },
  {
    "text": "going on we have elby's own access logging which we just covered and and if",
    "start": "1285360",
    "end": "1291150"
  },
  {
    "text": "you're really super interested you can also enable vbz flow logging and see literally every packet that comes into",
    "start": "1291150",
    "end": "1296660"
  },
  {
    "text": "the EOB and why it might be gettin",
    "start": "1296660",
    "end": "1301890"
  },
  {
    "text": "dropped if a security group is dropping and and so on and so the effect of all that right is that we're protecting",
    "start": "1301890",
    "end": "1309240"
  },
  {
    "text": "against cryptographic weaknesses using the mechanisms and policies the Sofra",
    "start": "1309240",
    "end": "1314820"
  },
  {
    "text": "front abilities one is a little more interesting so because it because",
    "start": "1314820",
    "end": "1320610"
  },
  {
    "text": "everything is going through the ELB and being accessed loved it and then being",
    "start": "1320610",
    "end": "1326420"
  },
  {
    "text": "uploaded by us - to s3 if there is a software",
    "start": "1326420",
    "end": "1334600"
  },
  {
    "text": "vulnerability in the code on your instance right so you know I'm just running my blog on my instance and I'm",
    "start": "1334600",
    "end": "1341049"
  },
  {
    "text": "not always keeping my blog software up-to-date because I just forgot to and occasionally there's some vulnerability",
    "start": "1341049",
    "end": "1347110"
  },
  {
    "text": "in there where you know they can the attacker can post a URL and they get",
    "start": "1347110",
    "end": "1352749"
  },
  {
    "text": "database access or system access and so on and they get on to my box and the first thing they'll do is delete the",
    "start": "1352749",
    "end": "1358899"
  },
  {
    "text": "logs that are on my box right they want to cover their own cover their own tracks well because the ELB logged it",
    "start": "1358899",
    "end": "1366119"
  },
  {
    "text": "separately now we have a record actually here's where the attacker came in here's the request they made here's what their",
    "start": "1366119",
    "end": "1372159"
  },
  {
    "text": "IP address was and so on so makes it easier to defend things against and they",
    "start": "1372159",
    "end": "1377889"
  },
  {
    "text": "can't dystocia we covered by Iams it's pretty straightforward so that's that's",
    "start": "1377889",
    "end": "1383649"
  },
  {
    "text": "security and I want to move on to scalability so fundamentally what I",
    "start": "1383649",
    "end": "1393039"
  },
  {
    "text": "think of scalability what I think it's about is is speed right it's about",
    "start": "1393039",
    "end": "1399879"
  },
  {
    "text": "maintaining an acceptable level of latency or smoothness of operation or",
    "start": "1399879",
    "end": "1408340"
  },
  {
    "text": "consistency of operation towards end-users as the load increases and so",
    "start": "1408340",
    "end": "1413859"
  },
  {
    "text": "in systems theory and in kind of the",
    "start": "1413859",
    "end": "1419169"
  },
  {
    "text": "academic ways of modeling large systems we generally model load and systems and",
    "start": "1419169",
    "end": "1427299"
  },
  {
    "text": "servers and all those things using queueing theory right using queues and",
    "start": "1427299",
    "end": "1432659"
  },
  {
    "text": "probably the most fundamental kind of foundational theorem of queueing theory",
    "start": "1432659",
    "end": "1438129"
  },
  {
    "text": "is littles law that's Li TT le I'm from Ireland so my T's don't come out all the",
    "start": "1438129",
    "end": "1444639"
  },
  {
    "text": "time but and what that says essentially is that in a long-running system or a",
    "start": "1444639",
    "end": "1452289"
  },
  {
    "text": "system that's saturated these various technicalities the overall number of",
    "start": "1452289",
    "end": "1461120"
  },
  {
    "text": "operations in the system or people in the system we will call we would call load or capacity is just equal to the",
    "start": "1461120",
    "end": "1469210"
  },
  {
    "text": "rate of arrival times the average wait time right and we can flip those terms",
    "start": "1469210",
    "end": "1476210"
  },
  {
    "text": "around because we're more interested in the wait time that's what we're trying to optimize I put it in simpler terms",
    "start": "1476210",
    "end": "1483429"
  },
  {
    "text": "all it's really saying is that if your system can be modeled like a queue which",
    "start": "1483429",
    "end": "1488600"
  },
  {
    "text": "these systems can be and we're saying that latency is is proportionate to the",
    "start": "1488600",
    "end": "1496760"
  },
  {
    "text": "total load that you're receiving divided by the troop what you can do right so",
    "start": "1496760",
    "end": "1502220"
  },
  {
    "text": "the more throughput you can do to lower your latencies right really straightforward really obvious when when",
    "start": "1502220",
    "end": "1510590"
  },
  {
    "text": "when put like that and but not only are",
    "start": "1510590",
    "end": "1516790"
  },
  {
    "text": "you know systems and servers and instances moddable as cues and ELB is",
    "start": "1516790",
    "end": "1523820"
  },
  {
    "text": "the sales model of model able as a q-and-a and you could break down a system further and you could say inside",
    "start": "1523820",
    "end": "1530450"
  },
  {
    "text": "a system that's several queues because each CPU has its own queue and it's it's very complicated recursive pattern but",
    "start": "1530450",
    "end": "1538760"
  },
  {
    "text": "it still ultimately boils down to the faster your systems are responding the",
    "start": "1538760",
    "end": "1544910"
  },
  {
    "text": "more users they can do per second the lower your Layton sees will be the more consistent they will be really really",
    "start": "1544910",
    "end": "1550790"
  },
  {
    "text": "straightforward but we're gonna see how we exploit that law in low bouncing to kind of smooth over common issues so",
    "start": "1550790",
    "end": "1558080"
  },
  {
    "text": "there's three common patterns that kind",
    "start": "1558080",
    "end": "1563120"
  },
  {
    "text": "of fight us here that make latency harder than it should be right really",
    "start": "1563120",
    "end": "1569000"
  },
  {
    "text": "really common in a lot of systems the first one I want to highlight is garbage collection right so this is just a graph",
    "start": "1569000",
    "end": "1577309"
  },
  {
    "text": "of a typical memory usage on a system let's say a JVM or a Ruby process or",
    "start": "1577309",
    "end": "1584870"
  },
  {
    "text": "even a PHP process where it'll allocate",
    "start": "1584870",
    "end": "1589970"
  },
  {
    "text": "memory and it'll use more and more memory over time all these objects are being allocated as",
    "start": "1589970",
    "end": "1595110"
  },
  {
    "text": "by the code as it's executing and it's running whatever service or website it",
    "start": "1595110",
    "end": "1602320"
  },
  {
    "text": "is you're providing and at some point it reaches some magic limit and the system kicks in and decides to perform garbage",
    "start": "1602320",
    "end": "1609340"
  },
  {
    "text": "collection and free up some of that memory right and we'll typically see a pause and",
    "start": "1609340",
    "end": "1614590"
  },
  {
    "text": "performance at that point right we've seen systems with heaps and garbage",
    "start": "1614590",
    "end": "1621250"
  },
  {
    "text": "collection parameters set so large that you know literally the memory can just accrue for gigs and gigs for days and",
    "start": "1621250",
    "end": "1628480"
  },
  {
    "text": "days and days and then finally garbage collection kicks in and there the system pauses literally for minutes right not",
    "start": "1628480",
    "end": "1635050"
  },
  {
    "text": "even milliseconds but we really hard pauses so the system can be very very",
    "start": "1635050",
    "end": "1640450"
  },
  {
    "text": "very into just YouTube garbage collection pretty much all modern programming languages the code we use is",
    "start": "1640450",
    "end": "1647500"
  },
  {
    "text": "written in our garbage collected it's very convenient pattern for developers I",
    "start": "1647500",
    "end": "1652809"
  },
  {
    "text": "mean I'd love to use it it's it's something a lot of research goes into to",
    "start": "1652809",
    "end": "1658510"
  },
  {
    "text": "tune garbage collection but we still see this property a lot right so this is fighting us right occasionally systems",
    "start": "1658510",
    "end": "1664960"
  },
  {
    "text": "will just pause and that obviously has an impact of latency the second thing we",
    "start": "1664960",
    "end": "1670600"
  },
  {
    "text": "see is caching right so caching is pretty pervasive in in modern systems",
    "start": "1670600",
    "end": "1676780"
  },
  {
    "text": "architectures right we even have our own caching services that we provide and people use my caches are a great way to",
    "start": "1676780",
    "end": "1683890"
  },
  {
    "text": "speed up most technical problems right they're great great things but they also",
    "start": "1683890",
    "end": "1689080"
  },
  {
    "text": "lead to this variance in performance where you know everything is a cache hit cache hit cache hit cache hit and then",
    "start": "1689080",
    "end": "1695140"
  },
  {
    "text": "all of a sudden you get a cache miss because finally your cache entry expires and your latency goes through the roof",
    "start": "1695140",
    "end": "1701290"
  },
  {
    "text": "because now you gotta go do the work to generate that entry that was cached right maybe you got a query a database or",
    "start": "1701290",
    "end": "1708520"
  },
  {
    "text": "figure out some some workload or access disk when ordinarily wouldn't and so",
    "start": "1708520",
    "end": "1715030"
  },
  {
    "text": "this is a very similar looking graph to the previous one right you just have these long periods of everything being",
    "start": "1715030",
    "end": "1721120"
  },
  {
    "text": "relatively ok and low latency and then all of a sudden you've got a big spike and",
    "start": "1721120",
    "end": "1726710"
  },
  {
    "text": "hurt and then the third thing is just kind of the natural distribution of",
    "start": "1726710",
    "end": "1732669"
  },
  {
    "text": "workload and response time in in any given system so in general pretty much",
    "start": "1732669",
    "end": "1739580"
  },
  {
    "text": "any system I've measured it follows an exponential distribution where the most",
    "start": "1739580",
    "end": "1745669"
  },
  {
    "text": "requests are small right vast majority requests take small number of",
    "start": "1745669",
    "end": "1751010"
  },
  {
    "text": "milliseconds but there's there are mixed in there a long tail of larger workloads",
    "start": "1751010",
    "end": "1758539"
  },
  {
    "text": "and all that's really going on is you know you've got a bunch of small requests things like get slash which",
    "start": "1758539",
    "end": "1766250"
  },
  {
    "text": "just retrieves the homepage might just be a static page or a very simple front page where all the objects are cached",
    "start": "1766250",
    "end": "1772580"
  },
  {
    "text": "it's accessed so frequently that everything's hot and it's uh it's it's",
    "start": "1772580",
    "end": "1777830"
  },
  {
    "text": "pretty quick and responsive but then you might have another URL on the same system where you know here we're getting",
    "start": "1777830",
    "end": "1784250"
  },
  {
    "text": "the monthly report right and maybe the monthly report needs to go query you know several million rows in a database",
    "start": "1784250",
    "end": "1790850"
  },
  {
    "text": "somewhere and do some kind of pivot join on it and a lot of memory allocation and figure out what the report should look",
    "start": "1790850",
    "end": "1797090"
  },
  {
    "text": "like for the month and someone only calls it once a month so it's not worth optimizing all right it's not worth",
    "start": "1797090",
    "end": "1802610"
  },
  {
    "text": "fixing it so that it's much much faster but it ends up mixed in there right and so we got this property where you know a",
    "start": "1802610",
    "end": "1810710"
  },
  {
    "text": "server too recently can model it as aq is because really in in raw physics",
    "start": "1810710",
    "end": "1815990"
  },
  {
    "text": "terms it can only do one thing at a time right ultimately there's a CPU down there that's doing some work can only do",
    "start": "1815990",
    "end": "1822470"
  },
  {
    "text": "one thing at a time and there's a scheduler and queue managers and so on that are figuring out what it's a lab",
    "start": "1822470",
    "end": "1828500"
  },
  {
    "text": "deal with any given time and so queues build up right in the case of a server",
    "start": "1828500",
    "end": "1834049"
  },
  {
    "text": "you've got a scheduling queue you've also got an accept backlog of requests that are pending and so on and things",
    "start": "1834049",
    "end": "1840380"
  },
  {
    "text": "just have to wait on each other right so you can sometimes end up with small requests having to wait on big requests",
    "start": "1840380",
    "end": "1846110"
  },
  {
    "text": "to finish and so when you do the math and you take this distribution which we",
    "start": "1846110",
    "end": "1852049"
  },
  {
    "text": "looked at which is just a plot of you know request size versus how come and",
    "start": "1852049",
    "end": "1857690"
  },
  {
    "text": "they are slow versus he'll come and they are you do the math and you turn that into a probability distribution of like what's",
    "start": "1857690",
    "end": "1863900"
  },
  {
    "text": "the average wait time for a request it ends up looking like this right it's",
    "start": "1863900",
    "end": "1869510"
  },
  {
    "text": "just kind of a pretty gentle curve and and says most requests don't have to",
    "start": "1869510",
    "end": "1876320"
  },
  {
    "text": "wait too long right they're probably small there's probably only some other small requests in front of them but occasionally there'll be a",
    "start": "1876320",
    "end": "1882260"
  },
  {
    "text": "big request in front of me and I got it and I gotta wait so if you just had one server one big server that's what your",
    "start": "1882260",
    "end": "1888049"
  },
  {
    "text": "local plot would look like right and you'll see you know you'll see",
    "start": "1888049",
    "end": "1893720"
  },
  {
    "text": "reasonable average response times they'll probably be reasonably reasonably close to the fast response",
    "start": "1893720",
    "end": "1900320"
  },
  {
    "text": "times but your higher percent response times so say your 99th percentile will",
    "start": "1900320",
    "end": "1906049"
  },
  {
    "text": "probably be quite high right so if you've got just one server one thing managing requests to it and your average",
    "start": "1906049",
    "end": "1913460"
  },
  {
    "text": "request time is say 10 milliseconds your penis your p99 is probably over 100",
    "start": "1913460",
    "end": "1920029"
  },
  {
    "text": "maybe even over a second wouldn't be unusual for this kind of plot so the",
    "start": "1920029",
    "end": "1926000"
  },
  {
    "text": "first thing we can do right with loud bouncing to fix this well increase capacity but we want to scale",
    "start": "1926000",
    "end": "1932659"
  },
  {
    "text": "horizontally because we can't just build infinitely bigger and bigger boxes so we",
    "start": "1932659",
    "end": "1939830"
  },
  {
    "text": "we split the requests across multiple house right and so here I DS it's it's",
    "start": "1939830",
    "end": "1948470"
  },
  {
    "text": "kind of a weighted round robin style low bouncing there's not nothing smart going on or there then we're saying okay we've",
    "start": "1948470",
    "end": "1953779"
  },
  {
    "text": "got four instances I'm gonna take a request and it's got a one in four chance of going to any particular server",
    "start": "1953779",
    "end": "1959840"
  },
  {
    "text": "and I'm just kind of allocated they're more or less at random okay I like to",
    "start": "1959840",
    "end": "1964850"
  },
  {
    "text": "think about this like a supermarket checkout right because you've got multiple checkouts and you pick one and",
    "start": "1964850",
    "end": "1972399"
  },
  {
    "text": "you know well if you go to my supermarket odds are there's someone with a really big loud in front of you all the time and he's just gonna have to",
    "start": "1972399",
    "end": "1979100"
  },
  {
    "text": "wait on them to finish but even if you just do that right even if all you do is increase the number of instances and",
    "start": "1979100",
    "end": "1984980"
  },
  {
    "text": "spit things at random it improves things dramatically so I curve I showed you that's that's the",
    "start": "1984980",
    "end": "1991580"
  },
  {
    "text": "the dotted orange one becomes the green one right everything pulls in a little which means your average goes down your",
    "start": "1991580",
    "end": "1998480"
  },
  {
    "text": "average response time gets much better but more importantly your p99 those that",
    "start": "1998480",
    "end": "2005409"
  },
  {
    "text": "higher percentile of response times gets dramatically better quickly and all we've done here is done some simple",
    "start": "2005409",
    "end": "2013659"
  },
  {
    "text": "weighted round robin low bouncing so this is actually the mode we operate in if you're using ELB is a TCP low bouncer",
    "start": "2013659",
    "end": "2020559"
  },
  {
    "text": "so if you if you terminate TCP on us TCP directly on us you can enable SSL if you want that",
    "start": "2020559",
    "end": "2027220"
  },
  {
    "text": "still works we'll still still manage the SSL for you we will act as a weighted",
    "start": "2027220",
    "end": "2034149"
  },
  {
    "text": "round robin low bouncer towards the backends and this is the kind of improvement that you'll see right it's",
    "start": "2034149",
    "end": "2040690"
  },
  {
    "text": "pretty good and pretty dramatic but we can do better again right so if we try",
    "start": "2040690",
    "end": "2048760"
  },
  {
    "text": "to line things up so that instead of like the checkout queue it's more like the queue at a bank right where",
    "start": "2048760",
    "end": "2055270"
  },
  {
    "text": "everybody lines up in one line and then takes the next server available that's a",
    "start": "2055270",
    "end": "2060849"
  },
  {
    "text": "more optimal strategy now key to success here right is that the thing doing the",
    "start": "2060849",
    "end": "2067030"
  },
  {
    "text": "dispatching which in our case is ELB is not itself the bottleneck right if it",
    "start": "2067030",
    "end": "2072339"
  },
  {
    "text": "was the bottleneck this wouldn't work so it has to be faster at processing things than the instances are now that's true",
    "start": "2072339",
    "end": "2080589"
  },
  {
    "text": "in our case because you know you'll be when we take a request and we go to direct and figure out where it should be",
    "start": "2080589",
    "end": "2086710"
  },
  {
    "text": "we're not you know we're making a very simple decision around here's where it should go next we can do that quite",
    "start": "2086710",
    "end": "2092470"
  },
  {
    "text": "quickly we're not having to actually generate a page right we're not having to actually you know query data access",
    "start": "2092470",
    "end": "2099250"
  },
  {
    "text": "disks do all the complex work that goes into rendering a page or an API response",
    "start": "2099250",
    "end": "2105700"
  },
  {
    "text": "and so on it's pretty easy to see why routing requests can be much much faster than actually handling requests which is",
    "start": "2105700",
    "end": "2113530"
  },
  {
    "text": "which is why this works at all and what that does it improves things more",
    "start": "2113530",
    "end": "2120250"
  },
  {
    "text": "dramatically again right so the blue line here is what it looks like what",
    "start": "2120250",
    "end": "2125540"
  },
  {
    "text": "what we call least connections loud bouncing that's just an",
    "start": "2125540",
    "end": "2131720"
  },
  {
    "text": "industry-standard term so what what the load balancer does is it looks at all of",
    "start": "2131720",
    "end": "2137750"
  },
  {
    "text": "the instances and says okay well which instance has the least outstanding",
    "start": "2137750",
    "end": "2142850"
  },
  {
    "text": "requests against it at the moment so we're counting requests to each back-end right to each instance and you know if",
    "start": "2142850",
    "end": "2151010"
  },
  {
    "text": "three of them have ten and one of them have eight one of them has eight the next request will go to the one that has",
    "start": "2151010",
    "end": "2156260"
  },
  {
    "text": "eight right so we're looking at the we're looking at the server that is the least loaded and that pulls everything",
    "start": "2156260",
    "end": "2163100"
  },
  {
    "text": "into being this kind of hockey stick and so this has an even more dramatic effect",
    "start": "2163100",
    "end": "2169790"
  },
  {
    "text": "on p99 it will it will typically bring the p90 down p99 down much much closer",
    "start": "2169790",
    "end": "2175820"
  },
  {
    "text": "to the average because when you do get occasional outliers like that monthly",
    "start": "2175820",
    "end": "2181430"
  },
  {
    "text": "report and so on it will pretty much go to one server and it might hog that server for a while while that report is",
    "start": "2181430",
    "end": "2187370"
  },
  {
    "text": "being generated but it doesn't really impact the other requests because now the lower bounds are inspired enough to know I'm not gonna send anything to that",
    "start": "2187370",
    "end": "2194000"
  },
  {
    "text": "low to that guy he's too busy right which is which is pretty good so this",
    "start": "2194000",
    "end": "2201410"
  },
  {
    "text": "smooths out and makes things makes a lot of things much much better right it'll",
    "start": "2201410",
    "end": "2208670"
  },
  {
    "text": "kind of paper over garbage collection little paper over cash misses a little",
    "start": "2208670",
    "end": "2215060"
  },
  {
    "text": "paper over just differences in your workload it's great like that but just",
    "start": "2215060",
    "end": "2220700"
  },
  {
    "text": "have one big dangerous property right which is if you have a back-end or an",
    "start": "2220700",
    "end": "2226310"
  },
  {
    "text": "instance that is not handling traffic correctly so let's say it's returning five hundreds all the time doing",
    "start": "2226310",
    "end": "2232730"
  },
  {
    "text": "something harmful but it's doing it very very quickly right we're gonna send all",
    "start": "2232730",
    "end": "2237890"
  },
  {
    "text": "the requests there right that's that's not a that's it's not a good thing right",
    "start": "2237890",
    "end": "2243620"
  },
  {
    "text": "it's gonna it's gonna attract it's gonna gravitate all those requests to it almost the very worst place for them so",
    "start": "2243620",
    "end": "2250820"
  },
  {
    "text": "that's why it's key as we'll see later to configure health checks correctly so we actually know the healthiness of that",
    "start": "2250820",
    "end": "2256400"
  },
  {
    "text": "instance and would avoid sending it requests even no it's the fastest and the leaves loaded right so that's a really",
    "start": "2256400",
    "end": "2264140"
  },
  {
    "text": "important takeaway none of this works as I said if he lb is itself the bottleneck",
    "start": "2264140",
    "end": "2270650"
  },
  {
    "text": "right if the requests were getting choked up on the LB itself this this would fall",
    "start": "2270650",
    "end": "2277279"
  },
  {
    "text": "apart so we we ourselves have to scale right talk a little bit about how we do that so two different ways that we scale",
    "start": "2277279",
    "end": "2286309"
  },
  {
    "text": "our load bouncers today both pre-emptive",
    "start": "2286309",
    "end": "2291979"
  },
  {
    "text": "and reactive so a pre-emptive load bouncing is that if you register some",
    "start": "2291979",
    "end": "2300289"
  },
  {
    "text": "instances behind your low bounce err either directly or true auto-scaling groups will assume you're adding those",
    "start": "2300289",
    "end": "2308119"
  },
  {
    "text": "instances for a reason right we'll assume you're adding those instances because you're expecting a workload",
    "start": "2308119",
    "end": "2313809"
  },
  {
    "text": "you're gonna you're gonna do something with them and we'll go ahead and preemptively scale the ELB to match",
    "start": "2313809",
    "end": "2320390"
  },
  {
    "text": "right so we'll make the LB least as large more likely twice as large as",
    "start": "2320390",
    "end": "2327439"
  },
  {
    "text": "whatever you scale to because of our availability zone configurations and",
    "start": "2327439",
    "end": "2332509"
  },
  {
    "text": "we'll do that very quickly generally within two minutes and we'll keep it",
    "start": "2332509",
    "end": "2340309"
  },
  {
    "text": "like that for at least 24 hours so even if even if you don't send us any load even if nothing happens we'll leave it",
    "start": "2340309",
    "end": "2346999"
  },
  {
    "text": "that high for at least the next 24 hours after 24 hours we'll kind of slowly ramp",
    "start": "2346999",
    "end": "2352219"
  },
  {
    "text": "down and go back to our predictive model or reactive model and the way the",
    "start": "2352219",
    "end": "2357529"
  },
  {
    "text": "reactive model works is we actually look at the load that's coming in to the load balancer like how many requests you're",
    "start": "2357529",
    "end": "2363769"
  },
  {
    "text": "getting how many packets per second you're getting how many bytes per second all of these things in and out various",
    "start": "2363769",
    "end": "2371390"
  },
  {
    "text": "parameters if you're using SSL we'll look at how much CPU is being consumed by all of the various SSL parameters and",
    "start": "2371390",
    "end": "2378319"
  },
  {
    "text": "so on and will and will scale the ELB to to match that we've got pretty healthy",
    "start": "2378319",
    "end": "2384679"
  },
  {
    "text": "safety margins on top of that we actually scale every ELB so that we",
    "start": "2384679",
    "end": "2391069"
  },
  {
    "text": "could lose and availability zones worth of capacity at a moment's notice and still be fully",
    "start": "2391069",
    "end": "2396200"
  },
  {
    "text": "scaled to respond to your load so there's quite a bit of a safety margin in there and this is something we've",
    "start": "2396200",
    "end": "2403280"
  },
  {
    "text": "done a lot of work on just improving steadily and steadily over the last two years to the point now where the system",
    "start": "2403280",
    "end": "2412400"
  },
  {
    "text": "scales so rapidly that we've seen people handling the large super bowl style",
    "start": "2412400",
    "end": "2418100"
  },
  {
    "text": "events and you know everybody hitting us at once advertisement links and so on",
    "start": "2418100",
    "end": "2423820"
  },
  {
    "text": "without needing to do anything special the system will just scale to match it it's it's it's pretty neat to see you",
    "start": "2423820",
    "end": "2432890"
  },
  {
    "text": "can also use the elbe to help scale your own instances right we we provide 13 tab",
    "start": "2432890",
    "end": "2440720"
  },
  {
    "text": "locks metrics with every elastic no bouncer I'll talk about them in a while but all of those can be used to trigger",
    "start": "2440720",
    "end": "2447350"
  },
  {
    "text": "auto scaling as well so if if your node can be scaled on a parameter that",
    "start": "2447350",
    "end": "2454160"
  },
  {
    "text": "corresponds to one of those metrics it's a really common one is just requests right or bytes rather than having to",
    "start": "2454160",
    "end": "2460730"
  },
  {
    "text": "build that metric yourself or do any kind of aggregation you just use the metric that comes from ELB you can say",
    "start": "2460730",
    "end": "2466610"
  },
  {
    "text": "well scale my auto scaling group based on what the ELB in front of it is seeing which is which is pretty neat it's uh it",
    "start": "2466610",
    "end": "2478430"
  },
  {
    "text": "is important to choose the right metrics right you need insight into your own workload if you're if you're very data",
    "start": "2478430",
    "end": "2484790"
  },
  {
    "text": "heavy right then maybe bytes per second is more appropriate than requests per second on the other hand if you very CPU",
    "start": "2484790",
    "end": "2491870"
  },
  {
    "text": "intensive and you've got a lot of work per request but they're not necessarily large then requested a way to go and you",
    "start": "2491870",
    "end": "2498800"
  },
  {
    "text": "got to make that decision based on your own workload and what you think works best in your environment the as I",
    "start": "2498800",
    "end": "2507470"
  },
  {
    "text": "mentioned there's 13 cloud web metrics there's things like I just mentioned",
    "start": "2507470",
    "end": "2512900"
  },
  {
    "text": "like requests and bytes but there's also ones around the health of the load balancer itself how we're doing in terms",
    "start": "2512900",
    "end": "2518900"
  },
  {
    "text": "of response times and so on everything's provided at one minute granularity",
    "start": "2518900",
    "end": "2525020"
  },
  {
    "text": "they're pretty live pretty up today help respond to things in real-time",
    "start": "2525020",
    "end": "2530270"
  },
  {
    "text": "I think configure alarms on everything if you like to someone that's",
    "start": "2530270",
    "end": "2536810"
  },
  {
    "text": "particularly interesting is the healthy host count metric so that actually exposes our view of your instance health",
    "start": "2536810",
    "end": "2545810"
  },
  {
    "text": "all right so you got instances behind the load balancer hopefully you've got health checks configured",
    "start": "2545810",
    "end": "2551750"
  },
  {
    "text": "we're help checking them all the time this metric tells you okay well we're currently seeing seven of your your",
    "start": "2551750",
    "end": "2558470"
  },
  {
    "text": "instances healthy out of ten say and you can look at that on a zonal basis you can look at that on a picking look you",
    "start": "2558470",
    "end": "2566630"
  },
  {
    "text": "can look at the IRA get to across the load bouncer that's pretty neat if you",
    "start": "2566630",
    "end": "2571640"
  },
  {
    "text": "want to see how the performance of your site's doing you can look at our latency metrics so here we measure a bunch of",
    "start": "2571640",
    "end": "2579380"
  },
  {
    "text": "different time values we measure the time requests come in to the elbe and then we send it to the instance with the",
    "start": "2579380",
    "end": "2585470"
  },
  {
    "text": "request at the time that the the instance takes to respond and so on we",
    "start": "2585470",
    "end": "2590930"
  },
  {
    "text": "provide you with the min and Max and average and so on of all those numbers and you can get a sense for the overall",
    "start": "2590930",
    "end": "2597290"
  },
  {
    "text": "responsiveness of your site site at the moment and see how that's going if you",
    "start": "2597290",
    "end": "2604370"
  },
  {
    "text": "want really super granular detail into the individual requests that's where access logs will come in that a bit we",
    "start": "2604370",
    "end": "2615020"
  },
  {
    "text": "also expose Serge Q and spillover metrics so the search Q is just an",
    "start": "2615020",
    "end": "2623030"
  },
  {
    "text": "internal Q a buffer of requests that the EOB will hold on to when your instances",
    "start": "2623030",
    "end": "2630890"
  },
  {
    "text": "are refusing them right so let's say you've got some instances in the low bouncer we send them some requests but",
    "start": "2630890",
    "end": "2637430"
  },
  {
    "text": "then they they run out of their own capacity haven't quite Auto scaled yet so we don't have another instance we can send send traffic to will actually just",
    "start": "2637430",
    "end": "2646760"
  },
  {
    "text": "buffer up to a thousand of them just hold onto them for for a short while and then if an instance does become",
    "start": "2646760",
    "end": "2654140"
  },
  {
    "text": "available again we'll replay them and we'll we'll send them there and we can recover spillover is when we can't",
    "start": "2654140",
    "end": "2663190"
  },
  {
    "text": "even do that right when your instances are overwhelmed they're not keeping up with",
    "start": "2663190",
    "end": "2668590"
  },
  {
    "text": "the request r/a we've nowhere left to send traffic the surge queue fills then",
    "start": "2668590",
    "end": "2674470"
  },
  {
    "text": "we spill over which essentially means we start returning 503 s on your behalf",
    "start": "2674470",
    "end": "2679810"
  },
  {
    "text": "that's our last resort hopefully at that point your client might be able to do something smart like maybe try an",
    "start": "2679810",
    "end": "2685570"
  },
  {
    "text": "alternative site or do exponential back-off in case if the client is constantly trying and overloading the",
    "start": "2685570",
    "end": "2691960"
  },
  {
    "text": "site or something like that but both of these metrics they're really useful to",
    "start": "2691960",
    "end": "2697210"
  },
  {
    "text": "look at they're generally a sign that your instances are under scaled and you need to put them on larger instance",
    "start": "2697210",
    "end": "2703840"
  },
  {
    "text": "types or auto scale to just more of them they're super useful to have great thing",
    "start": "2703840",
    "end": "2711520"
  },
  {
    "text": "to configure alarms on so access logs all right here's the secret key to all",
    "start": "2711520",
    "end": "2720010"
  },
  {
    "text": "of these fields you'll find it in our documentation too but on a per request level we're",
    "start": "2720010",
    "end": "2725980"
  },
  {
    "text": "exposing pretty much everything that's in one of those 13 matrix and then cipher suite and SSL protocol version",
    "start": "2725980",
    "end": "2732930"
  },
  {
    "text": "which we which we just added and you can do some really neat stuff with these",
    "start": "2732930",
    "end": "2739240"
  },
  {
    "text": "right something I like to do with these is that well I'll sometimes just write",
    "start": "2739240",
    "end": "2744790"
  },
  {
    "text": "simple scripts that go through the access labs and I'll find you know what are the slowest requests like I'll just",
    "start": "2744790",
    "end": "2750790"
  },
  {
    "text": "order them very simple awk shell script and say well here's my you know top 10",
    "start": "2750790",
    "end": "2757570"
  },
  {
    "text": "bottom 10 depending on which way you want to view it worse requests what are they right now I'll dig in and",
    "start": "2757570",
    "end": "2764350"
  },
  {
    "text": "I'll go this request so slow and it's a great way to uncover little problems and",
    "start": "2764350",
    "end": "2769780"
  },
  {
    "text": "systems a great way to view the data another thing you use before you could replay requests right if you if you're",
    "start": "2769780",
    "end": "2776350"
  },
  {
    "text": "trying to validate a new stack or a new architecture you've got this great repository of you know requests real",
    "start": "2776350",
    "end": "2783070"
  },
  {
    "text": "people generated that you can try against the new stack and see how that",
    "start": "2783070",
    "end": "2788230"
  },
  {
    "text": "goes as I mention earlier we these 2x3 either once every five minutes",
    "start": "2788230",
    "end": "2793480"
  },
  {
    "text": "or once an hour whichever you prefer you can you can choose it either way",
    "start": "2793480",
    "end": "2799330"
  },
  {
    "text": "if you're worried about extra storage costs you can also use a tree data lifecycle policies and so on so you only",
    "start": "2799330",
    "end": "2805930"
  },
  {
    "text": "keep however much data you're comfortable with you know a day or two",
    "start": "2805930",
    "end": "2811119"
  },
  {
    "text": "days or a year whatever whatever it is you he feels the right choice for you from my own instance I've kept every log",
    "start": "2811119",
    "end": "2817510"
  },
  {
    "text": "ever it's a pretty small number of requests so I'm fine with that if you",
    "start": "2817510",
    "end": "2825280"
  },
  {
    "text": "need to scale beyond even a single region that is something we support",
    "start": "2825280",
    "end": "2832080"
  },
  {
    "text": "so he'll be has integration with Amazon route 53 a DNS service where if either",
    "start": "2832080",
    "end": "2842020"
  },
  {
    "text": "for vary availability critical operations or a very latency sensitive operations you can use route through the",
    "start": "2842020",
    "end": "2848770"
  },
  {
    "text": "trees latency based routing or now Geographic based routing to take you know different parts of the world and",
    "start": "2848770",
    "end": "2855070"
  },
  {
    "text": "send requests to different regions and have ELB ELB ease in those regions",
    "start": "2855070",
    "end": "2861369"
  },
  {
    "text": "handle them right it's pretty neat all right so none of these matters right",
    "start": "2861369",
    "end": "2868930"
  },
  {
    "text": "if we don't actually keep the website up if we don't if you don't keep you don't",
    "start": "2868930",
    "end": "2875830"
  },
  {
    "text": "keep things going we're 53 paise are pretty important role there as we'll see but the first kind of big availability",
    "start": "2875830",
    "end": "2887320"
  },
  {
    "text": "vana benefit that I wanted to point out",
    "start": "2887320",
    "end": "2893520"
  },
  {
    "text": "which is something that is so obvious it never occurred to me until I started",
    "start": "2893520",
    "end": "2899980"
  },
  {
    "text": "talking to customers about it is that having a low bouncer in front of your instance means you can do upgrades and",
    "start": "2899980",
    "end": "2907300"
  },
  {
    "text": "replacements without downtime right so really surprised me the number of",
    "start": "2907300",
    "end": "2912910"
  },
  {
    "text": "customers I spoke to just tell they all the one of the biggest reasons they use in the elbe way so that you know it used",
    "start": "2912910",
    "end": "2920080"
  },
  {
    "text": "to be they would upgrade their software or they would replace the stock they have to schedule it at 2:00 in the",
    "start": "2920080",
    "end": "2925150"
  },
  {
    "text": "morning and you know there'd be a 10-minute interruption as one server went away and another came back and they",
    "start": "2925150",
    "end": "2930820"
  },
  {
    "text": "made some DNS changes and all those things and so on how we handled things a little different when you deregister and",
    "start": "2930820",
    "end": "2937720"
  },
  {
    "text": "ELB or start when you d register an instance from an ELB or when the health checks on that instance start failing we",
    "start": "2937720",
    "end": "2945820"
  },
  {
    "text": "won't send any new traffic to it but the old stuff stays going right if there any connections in flight to that instance",
    "start": "2945820",
    "end": "2952480"
  },
  {
    "text": "we'll keep them alive so you can just register a new instance it'll start getting traffic pretty much straight",
    "start": "2952480",
    "end": "2959290"
  },
  {
    "text": "away you can watch traffic drain on the old instance and when it's done it's done right no downtime pretty great way",
    "start": "2959290",
    "end": "2967390"
  },
  {
    "text": "to keep availability this all works partially because of how checks right so",
    "start": "2967390",
    "end": "2975130"
  },
  {
    "text": "how checks probably the most important part of getting the availability",
    "start": "2975130",
    "end": "2981310"
  },
  {
    "text": "configuration correct behind an EOB right so when you when you add instances",
    "start": "2981310",
    "end": "2987250"
  },
  {
    "text": "TLB you can define a haltech they can be as simple as can we connect to a TCP",
    "start": "2987250",
    "end": "2993130"
  },
  {
    "text": "port or as complex as nope this is a full HTTP request has to get a 200",
    "start": "2993130",
    "end": "2999849"
  },
  {
    "text": "response to be considered healthy right and again these are something you've got",
    "start": "2999849",
    "end": "3005490"
  },
  {
    "text": "to be diligent about I'm smart about in terms of it matching your workload and",
    "start": "3005490",
    "end": "3011160"
  },
  {
    "text": "what's appropriate for your site right so for example if your application",
    "start": "3011160",
    "end": "3016460"
  },
  {
    "text": "depends on say a database right then maybe your health check should check if the database is alive right and",
    "start": "3016460",
    "end": "3023430"
  },
  {
    "text": "shouldn't be returning 200 if the database is having a problem because maybe it's better to fail the hell check",
    "start": "3023430",
    "end": "3030540"
  },
  {
    "text": "and have the logo elsewhere to a different instance that's using a different database and everything can be",
    "start": "3030540",
    "end": "3036420"
  },
  {
    "text": "everything can be better the the thing I like about how checks too is that",
    "start": "3036420",
    "end": "3043200"
  },
  {
    "text": "they're the kind of always happening all the time in the data plane right so",
    "start": "3043200",
    "end": "3051630"
  },
  {
    "text": "they're incredibly reliable it's a really really really reliable way of making sure that there's a problem it",
    "start": "3051630",
    "end": "3058450"
  },
  {
    "text": "won't spread another thing that's worth paying close attention to is their idle",
    "start": "3058450",
    "end": "3064839"
  },
  {
    "text": "timeouts so we let you configure the idle timeout to default 60 seconds you",
    "start": "3064839",
    "end": "3069910"
  },
  {
    "text": "can set it raise it up to an hour and that's how long we will keep a connection alive even if there is no",
    "start": "3069910",
    "end": "3076930"
  },
  {
    "text": "traffic on that connection so this is",
    "start": "3076930",
    "end": "3083440"
  },
  {
    "text": "useful if you're using keep alive connections so if the if an instance",
    "start": "3083440",
    "end": "3088749"
  },
  {
    "text": "responds to us with a connection keep alive Heather says you know it's safe to reuse this connection which helps with",
    "start": "3088749",
    "end": "3095619"
  },
  {
    "text": "latency this avoids all those setup costs especially if you're using SSL takes for round trips to establish a",
    "start": "3095619",
    "end": "3102789"
  },
  {
    "text": "connection to the backend so there's a time saver but you got to be careful",
    "start": "3102789",
    "end": "3108940"
  },
  {
    "text": "with this value because idle time and it's also kick in if you know if your",
    "start": "3108940",
    "end": "3115239"
  },
  {
    "text": "system just pauses or crashes and it's just in a hang State you wanna you want",
    "start": "3115239",
    "end": "3120999"
  },
  {
    "text": "to kill any connections that are genuinely idle right that there's really a problem with so you want this value to",
    "start": "3120999",
    "end": "3127749"
  },
  {
    "text": "match whatever is appropriate for your site you also want to think about like what's gonna happen when clients retry",
    "start": "3127749",
    "end": "3133359"
  },
  {
    "text": "right so if you've got one idle timeout in your system the thing you know keep",
    "start": "3133359",
    "end": "3139269"
  },
  {
    "text": "connections open for an hour but your client has an idle timeout that's set up",
    "start": "3139269",
    "end": "3144849"
  },
  {
    "text": "for like well just 60 seconds what's gonna happen is the clients gonna abandon it at 60 seconds but because",
    "start": "3144849",
    "end": "3151960"
  },
  {
    "text": "that's setting on the inside is still an hour you know we might keep that work darling even though there's no crying",
    "start": "3151960",
    "end": "3157719"
  },
  {
    "text": "around to listen for it anymore",
    "start": "3157719",
    "end": "3162210"
  },
  {
    "text": "so it always recommend setting up staggered idle time else they get smaller and smaller the further you are",
    "start": "3163019",
    "end": "3169660"
  },
  {
    "text": "from the client right to avoid that of fact avoids cascading failures which is",
    "start": "3169660",
    "end": "3176680"
  },
  {
    "text": "which is pretty cool the other kind of leg of availability is using multiple",
    "start": "3176680",
    "end": "3182979"
  },
  {
    "text": "availability zones so on ELB we will always always provision",
    "start": "3182979",
    "end": "3188120"
  },
  {
    "text": "is multiple availability zones even if you're only using one yourself your own instances so when you create an e I'll",
    "start": "3188120",
    "end": "3195530"
  },
  {
    "text": "be in a V PC you give us a subnet in each availability zone and that's where we actually launched the ELB we have",
    "start": "3195530",
    "end": "3202010"
  },
  {
    "text": "route 53 sitting in front of our availability zones using dns health",
    "start": "3202010",
    "end": "3208310"
  },
  {
    "text": "checks as a protection mechanism so if an availability zone we're to have say a power outage and so on what's actually",
    "start": "3208310",
    "end": "3215480"
  },
  {
    "text": "happening is that the rule 53 howtechs will kick in detect that and take it out",
    "start": "3215480",
    "end": "3221450"
  },
  {
    "text": "of service without us having to do anything right so when availabilities arm fails we're not going and making any",
    "start": "3221450",
    "end": "3228200"
  },
  {
    "text": "changes or doing anything complicated at all the DNS system is just saying stop",
    "start": "3228200",
    "end": "3233600"
  },
  {
    "text": "returning stop returning those IP addresses please which is great that's",
    "start": "3233600",
    "end": "3238760"
  },
  {
    "text": "another example of the kind of constant work factor pattern in general that we see with hell checks whether it's those",
    "start": "3238760",
    "end": "3244910"
  },
  {
    "text": "route 53 hell checks or our health checks towards your instances where instead of a system where when things go",
    "start": "3244910",
    "end": "3251690"
  },
  {
    "text": "wrong we suddenly start making a bunch of API calls and generating a bunch of changes you know that may or may not",
    "start": "3251690",
    "end": "3257780"
  },
  {
    "text": "succeed in the heat of an event we have systems that just do the same amount of work all the time whether things are healthy or on",
    "start": "3257780",
    "end": "3265640"
  },
  {
    "text": "unhealthy the as I said you need to",
    "start": "3265640",
    "end": "3270950"
  },
  {
    "text": "register different subnets a subnet pairs own in order for us to be able to",
    "start": "3270950",
    "end": "3276020"
  },
  {
    "text": "balance them this all comes at one slight challenge though which is because",
    "start": "3276020",
    "end": "3281690"
  },
  {
    "text": "we're doing simple DNS load bouncing in front of you'll be at the availability zone level we're using round-robin load",
    "start": "3281690",
    "end": "3288980"
  },
  {
    "text": "balancing effectively there you can see imbalances in load between the",
    "start": "3288980",
    "end": "3294140"
  },
  {
    "text": "availability zones so here for example we've got three availability zones and the green ones getting more traffic than",
    "start": "3294140",
    "end": "3300650"
  },
  {
    "text": "the other two the reason for that is there may be very few DNS servers that",
    "start": "3300650",
    "end": "3306320"
  },
  {
    "text": "are actually being queried and so one is sticky and one gets more goes to the",
    "start": "3306320",
    "end": "3311450"
  },
  {
    "text": "green availability zone this is because sorry this is generally not because DNS",
    "start": "3311450",
    "end": "3317390"
  },
  {
    "text": "details aren't being honored it's generally just because there sometimes like mobile networks in",
    "start": "3317390",
    "end": "3322660"
  },
  {
    "text": "particular it just may only be three painters in play we do have a workaround",
    "start": "3322660",
    "end": "3327670"
  },
  {
    "text": "for this I'm not gonna go through it in detail and clear it on the slide in case you're interested in it you can you can",
    "start": "3327670",
    "end": "3333700"
  },
  {
    "text": "grab it later but essentially uses wildcards and C names and it's a crazy embarrassing hack but does work to",
    "start": "3333700",
    "end": "3340420"
  },
  {
    "text": "essentially boost caches on mobile resolvers if you really really need to with a few people doing this on mobile",
    "start": "3340420",
    "end": "3346660"
  },
  {
    "text": "apps but while we generally recommend here is just enable cross download",
    "start": "3346660",
    "end": "3351969"
  },
  {
    "text": "balancing right so if you enable cross hold on sonar bouncing then our lb in",
    "start": "3351969",
    "end": "3359579"
  },
  {
    "text": "availability zone D here for example can actually route to instances in the other availability zone and so the load",
    "start": "3359579",
    "end": "3366279"
  },
  {
    "text": "converges right we cross onload bouncing enabled we see a more even spread requests between the availability zone",
    "start": "3366279",
    "end": "3374099"
  },
  {
    "text": "which is which is which is pretty neat we effectively end up absorbing that",
    "start": "3374099",
    "end": "3379539"
  },
  {
    "text": "Unbounce that comes out because of DNS caching which is pretty neat and then",
    "start": "3379539",
    "end": "3385749"
  },
  {
    "text": "the very last thing I wanted to cover is something we're seeing more and more off which is just ELB and DevOps so today",
    "start": "3385749",
    "end": "3396699"
  },
  {
    "text": "we're we're already tightly integrated with CloudFormation and ops works if you",
    "start": "3396699",
    "end": "3402489"
  },
  {
    "text": "use the elastic beanstalk you can get the L bees that way you'll be using those two container service or API",
    "start": "3402489",
    "end": "3409599"
  },
  {
    "text": "gateway or even third-party tools like Netflix is a Skerritt and so on there's a lot of automation and systems built",
    "start": "3409599",
    "end": "3415900"
  },
  {
    "text": "around spinning up and managing your bees we're seeing a lot of people do",
    "start": "3415900",
    "end": "3421749"
  },
  {
    "text": "Bluegreen deployments using lb as their gateway as their latch mechanism of how to switch and lastly because all of this",
    "start": "3421749",
    "end": "3430449"
  },
  {
    "text": "can be done programmatically with with Claire Claire loves and so on and roll",
    "start": "3430449",
    "end": "3436749"
  },
  {
    "text": "back we're seeing more people create whole stacks with new lb at the top and their new flips and that's something",
    "start": "3436749",
    "end": "3443140"
  },
  {
    "text": "we're building tighter and tighter support for making sure that al bees are provisioned ever more quickly to support",
    "start": "3443140",
    "end": "3449829"
  },
  {
    "text": "those work clothes and that's the final section that's scalable",
    "start": "3449829",
    "end": "3455260"
  },
  {
    "text": "so thank you all for coming hopefully you've learned some some things about how love balancing works and some things",
    "start": "3455260",
    "end": "3461410"
  },
  {
    "text": "that can be applied in your workouts",
    "start": "3461410",
    "end": "3464640"
  }
]
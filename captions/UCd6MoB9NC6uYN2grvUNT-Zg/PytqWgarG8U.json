[
  {
    "text": "hi and welcome to AWS innovate",
    "start": "280",
    "end": "3040"
  },
  {
    "text": "conference my name is Zeta in this",
    "start": "3040",
    "end": "6040"
  },
  {
    "text": "session we'll look at analytics through",
    "start": "6040",
    "end": "8230"
  },
  {
    "text": "the eyes of a business intelligence",
    "start": "8230",
    "end": "10030"
  },
  {
    "text": "analyst a data scientist and a data",
    "start": "10030",
    "end": "12880"
  },
  {
    "text": "engineer we'll also explore how to",
    "start": "12880",
    "end": "15400"
  },
  {
    "text": "quickly leverage Amazon redshift",
    "start": "15400",
    "end": "17520"
  },
  {
    "text": "redshift spectrum Amazon quit site and",
    "start": "17520",
    "end": "20500"
  },
  {
    "text": "Athena to create powerful yet",
    "start": "20500",
    "end": "22720"
  },
  {
    "text": "straightforward business solutions in",
    "start": "22720",
    "end": "25240"
  },
  {
    "text": "this session we'll start by looking at",
    "start": "25240",
    "end": "27550"
  },
  {
    "text": "the current trends in the data driven",
    "start": "27550",
    "end": "29320"
  },
  {
    "text": "development then we'll look at some of",
    "start": "29320",
    "end": "32080"
  },
  {
    "text": "the stakeholders in a data organization",
    "start": "32080",
    "end": "34780"
  },
  {
    "text": "and how AWS ecosystem maps to them in",
    "start": "34780",
    "end": "37989"
  },
  {
    "text": "the context of these stakeholders we'll",
    "start": "37989",
    "end": "40930"
  },
  {
    "text": "look how service like redshift is",
    "start": "40930",
    "end": "43270"
  },
  {
    "text": "evolving from a traditional data",
    "start": "43270",
    "end": "45250"
  },
  {
    "text": "warehouse and expanding its capabilities",
    "start": "45250",
    "end": "47680"
  },
  {
    "text": "to handle more sophisticated data",
    "start": "47680",
    "end": "49960"
  },
  {
    "text": "analytics use cases will then discuss",
    "start": "49960",
    "end": "52719"
  },
  {
    "text": "how to build advanced data-driven",
    "start": "52719",
    "end": "55300"
  },
  {
    "text": "applications with Athena spectrum and",
    "start": "55300",
    "end": "58149"
  },
  {
    "text": "Amazon quick site for visualization",
    "start": "58149",
    "end": "60750"
  },
  {
    "text": "finally we'll see how spark can be",
    "start": "60750",
    "end": "63730"
  },
  {
    "text": "leveraged and then we'll open the",
    "start": "63730",
    "end": "65799"
  },
  {
    "text": "session for Question and Answer and",
    "start": "65799",
    "end": "67390"
  },
  {
    "text": "remember this is a level 200 session",
    "start": "67390",
    "end": "70110"
  },
  {
    "text": "before we dive deep into the session let",
    "start": "70110",
    "end": "73420"
  },
  {
    "text": "me quickly introduce myself my name is",
    "start": "73420",
    "end": "76090"
  },
  {
    "text": "Zeta parasha and I'm an enterprise",
    "start": "76090",
    "end": "78130"
  },
  {
    "text": "solution architect manager based out of",
    "start": "78130",
    "end": "80439"
  },
  {
    "text": "our Mumbai office in India as a solution",
    "start": "80439",
    "end": "83350"
  },
  {
    "text": "architect I have had an opportunity to",
    "start": "83350",
    "end": "85390"
  },
  {
    "text": "work with several enterprises in their",
    "start": "85390",
    "end": "87700"
  },
  {
    "text": "cloud adoption journey these also",
    "start": "87700",
    "end": "89979"
  },
  {
    "text": "include customers they have deployed",
    "start": "89979",
    "end": "91810"
  },
  {
    "text": "their data leak platform and also",
    "start": "91810",
    "end": "94090"
  },
  {
    "text": "migrated their unclicks were close to a",
    "start": "94090",
    "end": "96400"
  },
  {
    "text": "SS so let's begin AWS provides the most",
    "start": "96400",
    "end": "100900"
  },
  {
    "text": "comprehensive secure scalable and",
    "start": "100900",
    "end": "103590"
  },
  {
    "text": "cost-effective portfolio of services to",
    "start": "103590",
    "end": "105970"
  },
  {
    "text": "Bill Kosmas data leak and annexation",
    "start": "105970",
    "end": "108960"
  },
  {
    "text": "customers can store the data from any of",
    "start": "108960",
    "end": "112060"
  },
  {
    "text": "the data sources in a data link using",
    "start": "112060",
    "end": "114549"
  },
  {
    "text": "standard space data formats they can",
    "start": "114549",
    "end": "117790"
  },
  {
    "text": "analyze the data with the largest set of",
    "start": "117790",
    "end": "120250"
  },
  {
    "text": "analytics engine from AWS and the most",
    "start": "120250",
    "end": "123130"
  },
  {
    "text": "partner solutions that have pre-built",
    "start": "123130",
    "end": "125680"
  },
  {
    "text": "integration",
    "start": "125680",
    "end": "126490"
  },
  {
    "text": "giving customers choice and ensuring",
    "start": "126490",
    "end": "128979"
  },
  {
    "text": "that their needs will be met for the",
    "start": "128979",
    "end": "130929"
  },
  {
    "text": "existing and future analytics use cases",
    "start": "130929",
    "end": "134110"
  },
  {
    "text": "as a result there are more customers",
    "start": "134110",
    "end": "136120"
  },
  {
    "text": "running their data leads and analytics",
    "start": "136120",
    "end": "138460"
  },
  {
    "text": "on AWS than anywhere else as you can see",
    "start": "138460",
    "end": "142810"
  },
  {
    "text": "on the slide that there are various",
    "start": "142810",
    "end": "144790"
  },
  {
    "text": "kinds of end users of a data leak who",
    "start": "144790",
    "end": "147400"
  },
  {
    "text": "would want to consume the data for",
    "start": "147400",
    "end": "149200"
  },
  {
    "text": "different purposes we'll be taking fear",
    "start": "149200",
    "end": "151900"
  },
  {
    "text": "of these personas and understanding",
    "start": "151900",
    "end": "153820"
  },
  {
    "text": "their need and how it can be achieved",
    "start": "153820",
    "end": "155320"
  },
  {
    "text": "using various analytic services by these",
    "start": "155320",
    "end": "158890"
  },
  {
    "text": "personas are not hard and fast but still",
    "start": "158890",
    "end": "161470"
  },
  {
    "text": "a good grouping of categories of users",
    "start": "161470",
    "end": "164370"
  },
  {
    "text": "we can expect a single individual could",
    "start": "164370",
    "end": "167920"
  },
  {
    "text": "wear multiple hats we also want to",
    "start": "167920",
    "end": "170620"
  },
  {
    "text": "emphasize that the flexibility Ada bliss",
    "start": "170620",
    "end": "173080"
  },
  {
    "text": "provides to match the use case to a",
    "start": "173080",
    "end": "175510"
  },
  {
    "text": "broad and rich set of antics tools",
    "start": "175510",
    "end": "178920"
  },
  {
    "text": "contrast to a lot of other existing",
    "start": "178920",
    "end": "181239"
  },
  {
    "text": "solutions that require a large capital",
    "start": "181239",
    "end": "183370"
  },
  {
    "text": "expense that logs your future questions",
    "start": "183370",
    "end": "185800"
  },
  {
    "text": "to previous platform decisions let's",
    "start": "185800",
    "end": "189010"
  },
  {
    "text": "start by looking at the bi analyst again",
    "start": "189010",
    "end": "192430"
  },
  {
    "text": "let's just keep in mind that these",
    "start": "192430",
    "end": "194440"
  },
  {
    "text": "personas are general characterization",
    "start": "194440",
    "end": "196330"
  },
  {
    "text": "and may have significant overlap",
    "start": "196330",
    "end": "198820"
  },
  {
    "text": "depending on whatever project you are",
    "start": "198820",
    "end": "201010"
  },
  {
    "text": "working on so what do bi analysts do",
    "start": "201010",
    "end": "204420"
  },
  {
    "text": "just to level set they spend most of",
    "start": "204420",
    "end": "207670"
  },
  {
    "text": "their time analyzing the data to figure",
    "start": "207670",
    "end": "210280"
  },
  {
    "text": "out market and business trends for",
    "start": "210280",
    "end": "212560"
  },
  {
    "text": "companies with a goal to increase",
    "start": "212560",
    "end": "214150"
  },
  {
    "text": "profits and efficiency for example they",
    "start": "214150",
    "end": "217030"
  },
  {
    "text": "analyze past range and current",
    "start": "217030",
    "end": "219250"
  },
  {
    "text": "conditions and then communicate those",
    "start": "219250",
    "end": "221350"
  },
  {
    "text": "trends using reports a typical use case",
    "start": "221350",
    "end": "225040"
  },
  {
    "text": "here is analyzing sales data for a",
    "start": "225040",
    "end": "227350"
  },
  {
    "text": "retail company to optimize profits for",
    "start": "227350",
    "end": "230140"
  },
  {
    "text": "these types of use cases like historical",
    "start": "230140",
    "end": "232570"
  },
  {
    "text": "analysis Amazon redshift is a great",
    "start": "232570",
    "end": "234970"
  },
  {
    "text": "platform for such foreclosure a bi",
    "start": "234970",
    "end": "237760"
  },
  {
    "text": "analyst can connect to a redshift using",
    "start": "237760",
    "end": "240280"
  },
  {
    "text": "three of the options they can install",
    "start": "240280",
    "end": "242739"
  },
  {
    "text": "either bi tools on ec2 which is our VM",
    "start": "242739",
    "end": "246280"
  },
  {
    "text": "capability and connect to that ship",
    "start": "246280",
    "end": "248370"
  },
  {
    "text": "secondly they can use Amazon quick cite",
    "start": "248370",
    "end": "251500"
  },
  {
    "text": "a very low cost bi tool that connects to",
    "start": "251500",
    "end": "254500"
  },
  {
    "text": "all your data in the cloud including red",
    "start": "254500",
    "end": "256870"
  },
  {
    "text": "ship we are working with our BI partners",
    "start": "256870",
    "end": "259900"
  },
  {
    "text": "like tableau TIBCO jaspersoft to",
    "start": "259900",
    "end": "262870"
  },
  {
    "text": "integrate Amazon quick site and we'll",
    "start": "262870",
    "end": "265210"
  },
  {
    "text": "discuss quick site in more detail in",
    "start": "265210",
    "end": "267190"
  },
  {
    "text": "later",
    "start": "267190",
    "end": "267550"
  },
  {
    "text": "sites B our analysts primarily use",
    "start": "267550",
    "end": "271000"
  },
  {
    "text": "sequel to manipulate data with redshift",
    "start": "271000",
    "end": "274000"
  },
  {
    "text": "they can extend sequel with doom",
    "start": "274000",
    "end": "276280"
  },
  {
    "text": "redshift sequel functions and add custom",
    "start": "276280",
    "end": "278949"
  },
  {
    "text": "functions via user-defined functions",
    "start": "278949",
    "end": "281139"
  },
  {
    "text": "also called as UDF's let's look at how",
    "start": "281139",
    "end": "284590"
  },
  {
    "text": "redshift is evolving from a traditional",
    "start": "284590",
    "end": "286629"
  },
  {
    "text": "data warehouse and expanding its",
    "start": "286629",
    "end": "288669"
  },
  {
    "text": "capabilities to handle more",
    "start": "288669",
    "end": "290229"
  },
  {
    "text": "sophisticated data antics use cases",
    "start": "290229",
    "end": "292979"
  },
  {
    "text": "redshift has a massively parallel",
    "start": "292979",
    "end": "295659"
  },
  {
    "text": "processing data warehouse architecture",
    "start": "295659",
    "end": "297580"
  },
  {
    "text": "which we also call it as MPP redshift",
    "start": "297580",
    "end": "301030"
  },
  {
    "text": "automatically distributes data and query",
    "start": "301030",
    "end": "303729"
  },
  {
    "text": "load across all the compute nodes to",
    "start": "303729",
    "end": "306610"
  },
  {
    "text": "take the advantage of available",
    "start": "306610",
    "end": "308560"
  },
  {
    "text": "resources this means that all the",
    "start": "308560",
    "end": "311050"
  },
  {
    "text": "queries are executed in parallel across",
    "start": "311050",
    "end": "313690"
  },
  {
    "text": "all these physical resources you can",
    "start": "313690",
    "end": "316449"
  },
  {
    "text": "extend native sequel with Python UDF's",
    "start": "316449",
    "end": "319330"
  },
  {
    "text": "or custom libraries pythons compile",
    "start": "319330",
    "end": "322629"
  },
  {
    "text": "bytecode also runs in parallel across",
    "start": "322629",
    "end": "325270"
  },
  {
    "text": "all your compute nodes this horizontal",
    "start": "325270",
    "end": "328389"
  },
  {
    "text": "scale out architecture makes it easy to",
    "start": "328389",
    "end": "330580"
  },
  {
    "text": "add notes to your data warehouse and",
    "start": "330580",
    "end": "333430"
  },
  {
    "text": "enables you to maintain fast query",
    "start": "333430",
    "end": "335860"
  },
  {
    "text": "performance as your data warehouse",
    "start": "335860",
    "end": "337330"
  },
  {
    "text": "closed another service which is Amazon",
    "start": "337330",
    "end": "340840"
  },
  {
    "text": "redshift spectrum enables you to run",
    "start": "340840",
    "end": "343479"
  },
  {
    "text": "Amazon rates of sequel queries against",
    "start": "343479",
    "end": "346029"
  },
  {
    "text": "exabytes of data in Amazon s3 with",
    "start": "346029",
    "end": "349240"
  },
  {
    "text": "redshift spectrum you can extend the",
    "start": "349240",
    "end": "351849"
  },
  {
    "text": "analytic power of Amazon redshift beyond",
    "start": "351849",
    "end": "354580"
  },
  {
    "text": "the data stored on your local disk in",
    "start": "354580",
    "end": "357069"
  },
  {
    "text": "your data warehouse to query vast",
    "start": "357069",
    "end": "359500"
  },
  {
    "text": "amounts of unstructured data in your",
    "start": "359500",
    "end": "361990"
  },
  {
    "text": "Amazon s3 which is your data link",
    "start": "361990",
    "end": "363969"
  },
  {
    "text": "without having you to load or transform",
    "start": "363969",
    "end": "366759"
  },
  {
    "text": "any kind of a data redshift spectrum",
    "start": "366759",
    "end": "369639"
  },
  {
    "text": "applies sophisticated query optimization",
    "start": "369639",
    "end": "372210"
  },
  {
    "text": "scaling processing across thousands of",
    "start": "372210",
    "end": "374979"
  },
  {
    "text": "nodes so results are fast even with the",
    "start": "374979",
    "end": "377979"
  },
  {
    "text": "large data sets and complex queries",
    "start": "377979",
    "end": "380099"
  },
  {
    "text": "redshift spectrum can query using the",
    "start": "380099",
    "end": "382960"
  },
  {
    "text": "open data formats you already use",
    "start": "382960",
    "end": "385150"
  },
  {
    "text": "including Avro CSV crock o RC parky RC F",
    "start": "385150",
    "end": "391360"
  },
  {
    "text": "file registered a sequence file txt file",
    "start": "391360",
    "end": "394960"
  },
  {
    "text": "and TSV since redshift supports the same",
    "start": "394960",
    "end": "399190"
  },
  {
    "text": "sequel syntax of Amazon redshift",
    "start": "399190",
    "end": "401860"
  },
  {
    "text": "you can run the sophisticated queries",
    "start": "401860",
    "end": "404169"
  },
  {
    "text": "using the same BI tools as you used",
    "start": "404169",
    "end": "406569"
  },
  {
    "text": "today you can also run the queries that",
    "start": "406569",
    "end": "409479"
  },
  {
    "text": "span the frequently accessed data stored",
    "start": "409479",
    "end": "412960"
  },
  {
    "text": "locally in Amazon redshift and your full",
    "start": "412960",
    "end": "415689"
  },
  {
    "text": "data sets stored cost-effectively",
    "start": "415689",
    "end": "418419"
  },
  {
    "text": "in Amazon s3 let's take an example and",
    "start": "418419",
    "end": "421569"
  },
  {
    "text": "get into some more details of redshift",
    "start": "421569",
    "end": "424000"
  },
  {
    "text": "spectrum it all starts when the redshift",
    "start": "424000",
    "end": "427300"
  },
  {
    "text": "spectrum queries are submitted to the",
    "start": "427300",
    "end": "429520"
  },
  {
    "text": "leader node of your Amazon redshift",
    "start": "429520",
    "end": "431590"
  },
  {
    "text": "cluster the leader node optimizes",
    "start": "431590",
    "end": "434699"
  },
  {
    "text": "compiles and pushes the query execution",
    "start": "434699",
    "end": "437529"
  },
  {
    "text": "to the compute nodes in your Amazon",
    "start": "437529",
    "end": "439900"
  },
  {
    "text": "redshift cluster the query plan is then",
    "start": "439900",
    "end": "443319"
  },
  {
    "text": "sent to all the compute nodes next the",
    "start": "443319",
    "end": "447099"
  },
  {
    "text": "compute nodes obtain the information",
    "start": "447099",
    "end": "449740"
  },
  {
    "text": "describing the external tables from your",
    "start": "449740",
    "end": "452199"
  },
  {
    "text": "data catalog dynamically pruning",
    "start": "452199",
    "end": "454569"
  },
  {
    "text": "non-relevant partitions based on the",
    "start": "454569",
    "end": "456879"
  },
  {
    "text": "filters and joints in your queries the",
    "start": "456879",
    "end": "460180"
  },
  {
    "text": "compute nodes also examine the data",
    "start": "460180",
    "end": "462610"
  },
  {
    "text": "available locally and pushdown",
    "start": "462610",
    "end": "465039"
  },
  {
    "text": "predicates to effectively scan only the",
    "start": "465039",
    "end": "467710"
  },
  {
    "text": "relevant objects in Amazon s3 the Amazon",
    "start": "467710",
    "end": "471699"
  },
  {
    "text": "redshift compute nodes then generate",
    "start": "471699",
    "end": "473949"
  },
  {
    "text": "multiple requests depending on the",
    "start": "473949",
    "end": "476560"
  },
  {
    "text": "number of objects that need to be",
    "start": "476560",
    "end": "478180"
  },
  {
    "text": "processed and submit them concurrently",
    "start": "478180",
    "end": "480729"
  },
  {
    "text": "to redshift spectrum which pools",
    "start": "480729",
    "end": "482830"
  },
  {
    "text": "thousands of Amazon ec2 instances or AWS",
    "start": "482830",
    "end": "486370"
  },
  {
    "text": "region the redshift spectrum volcko",
    "start": "486370",
    "end": "489490"
  },
  {
    "text": "nodes scan filter and aggregate your",
    "start": "489490",
    "end": "492969"
  },
  {
    "text": "data from Amazon s3 seaming the required",
    "start": "492969",
    "end": "496180"
  },
  {
    "text": "data for processing back to your Amazon",
    "start": "496180",
    "end": "498159"
  },
  {
    "text": "redshift cluster they the final join and",
    "start": "498159",
    "end": "501729"
  },
  {
    "text": "the merge operations are performed",
    "start": "501729",
    "end": "503490"
  },
  {
    "text": "locally in your cluster and the results",
    "start": "503490",
    "end": "506229"
  },
  {
    "text": "are returned to your client another tool",
    "start": "506229",
    "end": "509560"
  },
  {
    "text": "which is the key for business analysts",
    "start": "509560",
    "end": "511750"
  },
  {
    "text": "is the visualization tool quit site",
    "start": "511750",
    "end": "514719"
  },
  {
    "text": "allows business analysts to visualize",
    "start": "514719",
    "end": "517659"
  },
  {
    "text": "the data to access quit site you pick up",
    "start": "517659",
    "end": "520810"
  },
  {
    "text": "your favorite mobile device or a web",
    "start": "520810",
    "end": "522969"
  },
  {
    "text": "browser and connect through the user",
    "start": "522969",
    "end": "525220"
  },
  {
    "text": "interface to our core engine there's a",
    "start": "525220",
    "end": "528310"
  },
  {
    "text": "data connector that's built into the",
    "start": "528310",
    "end": "530230"
  },
  {
    "text": "product that automatically discovers and",
    "start": "530230",
    "end": "532690"
  },
  {
    "text": "connects to all AWS data sources",
    "start": "532690",
    "end": "535750"
  },
  {
    "text": "as the user you don't have to worry",
    "start": "535750",
    "end": "537940"
  },
  {
    "text": "about how to connect with our data",
    "start": "537940",
    "end": "539560"
  },
  {
    "text": "sources using JDBC ODBC drivers you can",
    "start": "539560",
    "end": "543160"
  },
  {
    "text": "also connect website directly to your",
    "start": "543160",
    "end": "545800"
  },
  {
    "text": "data sources even which are located in",
    "start": "545800",
    "end": "548230"
  },
  {
    "text": "your on-premise data centers we look",
    "start": "548230",
    "end": "550870"
  },
  {
    "text": "through the data sets and build your",
    "start": "550870",
    "end": "552970"
  },
  {
    "text": "data catalog using the metadata feature",
    "start": "552970",
    "end": "555360"
  },
  {
    "text": "once you select your data source you can",
    "start": "555360",
    "end": "558220"
  },
  {
    "text": "start to visualize it immediately or you",
    "start": "558220",
    "end": "560830"
  },
  {
    "text": "can use our data prep feature data prep",
    "start": "560830",
    "end": "564640"
  },
  {
    "text": "allows you to specify what subsets of",
    "start": "564640",
    "end": "567730"
  },
  {
    "text": "data you are interested in you can write",
    "start": "567730",
    "end": "570640"
  },
  {
    "text": "the filters reduce the scope of the data",
    "start": "570640",
    "end": "572800"
  },
  {
    "text": "set once you start interacting with the",
    "start": "572800",
    "end": "575560"
  },
  {
    "text": "data the spy scenes in fiction it",
    "start": "575560",
    "end": "578380"
  },
  {
    "text": "injects the data and responds to all the",
    "start": "578380",
    "end": "581590"
  },
  {
    "text": "queries really fast spice is a",
    "start": "581590",
    "end": "584650"
  },
  {
    "text": "technology that we have built right from",
    "start": "584650",
    "end": "587020"
  },
  {
    "text": "the ground shot spice stands for super",
    "start": "587020",
    "end": "589990"
  },
  {
    "text": "fast parallel in-memory calculation",
    "start": "589990",
    "end": "592720"
  },
  {
    "text": "engine what spice allows you to do is to",
    "start": "592720",
    "end": "596110"
  },
  {
    "text": "collect and compress the data in a",
    "start": "596110",
    "end": "598810"
  },
  {
    "text": "columnar way and optimize it for in",
    "start": "598810",
    "end": "601210"
  },
  {
    "text": "memory use the title data scientist is",
    "start": "601210",
    "end": "605230"
  },
  {
    "text": "relatively new and has been around for",
    "start": "605230",
    "end": "607990"
  },
  {
    "text": "only a few years it was actually coined",
    "start": "607990",
    "end": "610660"
  },
  {
    "text": "in 2008 by data and analytics leads at",
    "start": "610660",
    "end": "614050"
  },
  {
    "text": "LinkedIn and Facebook this title has",
    "start": "614050",
    "end": "617410"
  },
  {
    "text": "come to replace data analyst a data",
    "start": "617410",
    "end": "621160"
  },
  {
    "text": "scientist can have formal training in",
    "start": "621160",
    "end": "623710"
  },
  {
    "text": "quantitative field but they can also",
    "start": "623710",
    "end": "626200"
  },
  {
    "text": "emerge from any of the fields that has",
    "start": "626200",
    "end": "628420"
  },
  {
    "text": "got strong data and computational focus",
    "start": "628420",
    "end": "631060"
  },
  {
    "text": "a data scientist most basic and",
    "start": "631060",
    "end": "634360"
  },
  {
    "text": "universal skill is the ability to write",
    "start": "634360",
    "end": "636910"
  },
  {
    "text": "code but they also have a very solid",
    "start": "636910",
    "end": "639460"
  },
  {
    "text": "foundation in match in statistics",
    "start": "639460",
    "end": "642300"
  },
  {
    "text": "probability and even computer science",
    "start": "642300",
    "end": "644610"
  },
  {
    "text": "they work with the complex data sets and",
    "start": "644610",
    "end": "647650"
  },
  {
    "text": "they are good at converting masses of",
    "start": "647650",
    "end": "649990"
  },
  {
    "text": "unstructured data into structured data",
    "start": "649990",
    "end": "652120"
  },
  {
    "text": "and but most importantly getting into a",
    "start": "652120",
    "end": "654790"
  },
  {
    "text": "form that can be really analyzed often",
    "start": "654790",
    "end": "657580"
  },
  {
    "text": "they are creative in displaying the",
    "start": "657580",
    "end": "659260"
  },
  {
    "text": "information visually and making the",
    "start": "659260",
    "end": "661300"
  },
  {
    "text": "patterns define clear and compelling",
    "start": "661300",
    "end": "663540"
  },
  {
    "text": "let's look at some of the tool sets that",
    "start": "663540",
    "end": "666310"
  },
  {
    "text": "data scientist use to analyze the data",
    "start": "666310",
    "end": "669250"
  },
  {
    "text": "by data scientists can access sets of",
    "start": "669250",
    "end": "671860"
  },
  {
    "text": "data or they can also leverage Athena",
    "start": "671860",
    "end": "674290"
  },
  {
    "text": "with a server less and allows you to",
    "start": "674290",
    "end": "676930"
  },
  {
    "text": "access data using sequel after sequel r",
    "start": "676930",
    "end": "681519"
  },
  {
    "text": "is the most commonly programming",
    "start": "681519",
    "end": "683470"
  },
  {
    "text": "language used by the data scientists are",
    "start": "683470",
    "end": "685839"
  },
  {
    "text": "is a popular statistical programming",
    "start": "685839",
    "end": "688329"
  },
  {
    "text": "language with a number of extensions",
    "start": "688329",
    "end": "690459"
  },
  {
    "text": "that support the data processing and",
    "start": "690459",
    "end": "692439"
  },
  {
    "text": "machine learning tasks are provides a",
    "start": "692439",
    "end": "695800"
  },
  {
    "text": "rich software development for data",
    "start": "695800",
    "end": "698410"
  },
  {
    "text": "manipulation exploration including a",
    "start": "698410",
    "end": "701319"
  },
  {
    "text": "graphical display R is easily extended",
    "start": "701319",
    "end": "704500"
  },
  {
    "text": "using packages for example shiny server",
    "start": "704500",
    "end": "708129"
  },
  {
    "text": "is a visualization or package that",
    "start": "708129",
    "end": "710920"
  },
  {
    "text": "allows you to create interactive",
    "start": "710920",
    "end": "712990"
  },
  {
    "text": "dashboards similarly you can install",
    "start": "712990",
    "end": "715839"
  },
  {
    "text": "packages in our to query red ship for",
    "start": "715839",
    "end": "719800"
  },
  {
    "text": "example you can install the our JDBC",
    "start": "719800",
    "end": "723189"
  },
  {
    "text": "package to load redshift stay DBC driver",
    "start": "723189",
    "end": "725620"
  },
  {
    "text": "and then send sequel queries to Amazon",
    "start": "725620",
    "end": "728800"
  },
  {
    "text": "redshift the difference between the",
    "start": "728800",
    "end": "731649"
  },
  {
    "text": "Python UTS and our in this scenario is",
    "start": "731649",
    "end": "734589"
  },
  {
    "text": "that you have to take the data out of",
    "start": "734589",
    "end": "736449"
  },
  {
    "text": "the database to do your analysis you can",
    "start": "736449",
    "end": "739540"
  },
  {
    "text": "also write our code using deep higher",
    "start": "739540",
    "end": "742000"
  },
  {
    "text": "package to analyze your data in red ship",
    "start": "742000",
    "end": "744839"
  },
  {
    "text": "first you have to create a connection to",
    "start": "744839",
    "end": "747819"
  },
  {
    "text": "red ship via our post race equal packets",
    "start": "747819",
    "end": "750779"
  },
  {
    "text": "pancha disconnected to read check you",
    "start": "750779",
    "end": "753879"
  },
  {
    "text": "have the flexibility to add predictive",
    "start": "753879",
    "end": "756759"
  },
  {
    "text": "modeling using arts packages there's",
    "start": "756759",
    "end": "759759"
  },
  {
    "text": "also a good big data blog that shows you",
    "start": "759759",
    "end": "763120"
  },
  {
    "text": "how to connect our with redshift in a",
    "start": "763120",
    "end": "765879"
  },
  {
    "text": "detailed manner Athena is an interactive",
    "start": "765879",
    "end": "769750"
  },
  {
    "text": "query service which allows you to get",
    "start": "769750",
    "end": "772449"
  },
  {
    "text": "results fast and mostly in seconds",
    "start": "772449",
    "end": "775740"
  },
  {
    "text": "remember it is not a database neither a",
    "start": "775740",
    "end": "778750"
  },
  {
    "text": "data warehouse this is for querying data",
    "start": "778750",
    "end": "781600"
  },
  {
    "text": "which is stored in s3 and designed to",
    "start": "781600",
    "end": "784540"
  },
  {
    "text": "write your queries and give you results",
    "start": "784540",
    "end": "786910"
  },
  {
    "text": "in seconds",
    "start": "786910",
    "end": "788040"
  },
  {
    "text": "Athena directly query data from s3 so",
    "start": "788040",
    "end": "792339"
  },
  {
    "text": "you don't have to move or load the data",
    "start": "792339",
    "end": "794620"
  },
  {
    "text": "anywhere from s3 we want you to query",
    "start": "794620",
    "end": "798220"
  },
  {
    "text": "your data in draw format which can be",
    "start": "798220",
    "end": "800620"
  },
  {
    "text": "CSV TSV or",
    "start": "800620",
    "end": "802840"
  },
  {
    "text": "any other data formats it can queried",
    "start": "802840",
    "end": "805330"
  },
  {
    "text": "even the log files which are services",
    "start": "805330",
    "end": "807460"
  },
  {
    "text": "generates for example the elbe logs the",
    "start": "807460",
    "end": "810460"
  },
  {
    "text": "cloud watch logs or the B PC flow logs",
    "start": "810460",
    "end": "812830"
  },
  {
    "text": "and if you convert your data in or Z or",
    "start": "812830",
    "end": "817180"
  },
  {
    "text": "Parque formats these formats are",
    "start": "817180",
    "end": "819820"
  },
  {
    "text": "basically nothing but open source",
    "start": "819820",
    "end": "821740"
  },
  {
    "text": "formats which supports call them the",
    "start": "821740",
    "end": "824110"
  },
  {
    "text": "data and compression then you can even",
    "start": "824110",
    "end": "827290"
  },
  {
    "text": "go ahead and load your query cost to a",
    "start": "827290",
    "end": "830230"
  },
  {
    "text": "great extent and we will discuss the",
    "start": "830230",
    "end": "832480"
  },
  {
    "text": "pricing of Athena in next few slides you",
    "start": "832480",
    "end": "835870"
  },
  {
    "text": "can use a few lines of price park code",
    "start": "835870",
    "end": "838510"
  },
  {
    "text": "running on Amazon EMR to convert your",
    "start": "838510",
    "end": "841840"
  },
  {
    "text": "files to parquet for the best",
    "start": "841840",
    "end": "844180"
  },
  {
    "text": "performance and cost when you create a",
    "start": "844180",
    "end": "847630"
  },
  {
    "text": "table for Athena you are essentially",
    "start": "847630",
    "end": "850300"
  },
  {
    "text": "just creating a metadata and as you run",
    "start": "850300",
    "end": "853750"
  },
  {
    "text": "your queries the schema is applied to",
    "start": "853750",
    "end": "855910"
  },
  {
    "text": "the data the data is then streamed to",
    "start": "855910",
    "end": "858940"
  },
  {
    "text": "Athena from s3 it is not copy and there",
    "start": "858940",
    "end": "862180"
  },
  {
    "text": "is no ETL which is required",
    "start": "862180",
    "end": "863740"
  },
  {
    "text": "this makes Athena really ideal for",
    "start": "863740",
    "end": "866290"
  },
  {
    "text": "customers who are using s3 acid Italy",
    "start": "866290",
    "end": "870270"
  },
  {
    "text": "Athena uses pesto as the underlying",
    "start": "870270",
    "end": "873490"
  },
  {
    "text": "querying engine",
    "start": "873490",
    "end": "875410"
  },
  {
    "text": "and see sequel supports complex joints",
    "start": "875410",
    "end": "878259"
  },
  {
    "text": "nested queries window functions and even",
    "start": "878259",
    "end": "881529"
  },
  {
    "text": "some of the most complex data types we",
    "start": "881529",
    "end": "884199"
  },
  {
    "text": "also support partitioning your data in",
    "start": "884199",
    "end": "886540"
  },
  {
    "text": "s3 to reduce the amount of data that",
    "start": "886540",
    "end": "889269"
  },
  {
    "text": "Athena is scanning therefore improving",
    "start": "889269",
    "end": "892240"
  },
  {
    "text": "your performance and costs when you",
    "start": "892240",
    "end": "895149"
  },
  {
    "text": "write your query it will go to the",
    "start": "895149",
    "end": "897100"
  },
  {
    "text": "appropriate partition and read the data",
    "start": "897100",
    "end": "899139"
  },
  {
    "text": "from that partition rather than reading",
    "start": "899139",
    "end": "901420"
  },
  {
    "text": "all the data and hence improving both",
    "start": "901420",
    "end": "904300"
  },
  {
    "text": "the performance as well as cost",
    "start": "904300",
    "end": "906360"
  },
  {
    "text": "Athena is designed to be very cost",
    "start": "906360",
    "end": "909129"
  },
  {
    "text": "effective if you're not using it then",
    "start": "909129",
    "end": "912009"
  },
  {
    "text": "there is no charge there is no oddly",
    "start": "912009",
    "end": "914649"
  },
  {
    "text": "charge you are charged only when you are",
    "start": "914649",
    "end": "917439"
  },
  {
    "text": "running your query detail queries like",
    "start": "917439",
    "end": "920529"
  },
  {
    "text": "the ones which are necessary to create",
    "start": "920529",
    "end": "922449"
  },
  {
    "text": "tables or the failed queries are not",
    "start": "922449",
    "end": "925209"
  },
  {
    "text": "charged also since we charge you based",
    "start": "925209",
    "end": "929079"
  },
  {
    "text": "on the data scan and suppose you have a",
    "start": "929079",
    "end": "932110"
  },
  {
    "text": "terabyte of data if you compress the",
    "start": "932110",
    "end": "934600"
  },
  {
    "text": "data with a Phi which to one compression",
    "start": "934600",
    "end": "936250"
  },
  {
    "text": "ratio your data will become 200 GP then",
    "start": "936250",
    "end": "939850"
  },
  {
    "text": "instead of charging you on one terabyte",
    "start": "939850",
    "end": "942639"
  },
  {
    "text": "we will be charging you only for 200 GB",
    "start": "942639",
    "end": "945459"
  },
  {
    "text": "of data scan now let's go ahead and",
    "start": "945459",
    "end": "948310"
  },
  {
    "text": "switch our gates and look at the data",
    "start": "948310",
    "end": "950170"
  },
  {
    "text": "engineer role the difference between a",
    "start": "950170",
    "end": "953410"
  },
  {
    "text": "data scientist and a data engineer can",
    "start": "953410",
    "end": "956259"
  },
  {
    "text": "really vary depending on the",
    "start": "956259",
    "end": "957610"
  },
  {
    "text": "organization in some organization data",
    "start": "957610",
    "end": "961060"
  },
  {
    "text": "engineers enable data scientists to do",
    "start": "961060",
    "end": "963699"
  },
  {
    "text": "their jobs more effectively the data",
    "start": "963699",
    "end": "966430"
  },
  {
    "text": "engineer gathers and collects the data",
    "start": "966430",
    "end": "968680"
  },
  {
    "text": "stores it does batch processing or the",
    "start": "968680",
    "end": "972759"
  },
  {
    "text": "real-time processing on it and serves it",
    "start": "972759",
    "end": "975189"
  },
  {
    "text": "via an API to a data scientist who can",
    "start": "975189",
    "end": "978160"
  },
  {
    "text": "then easily query it but there can be",
    "start": "978160",
    "end": "980980"
  },
  {
    "text": "overlap also for instance a data",
    "start": "980980",
    "end": "984279"
  },
  {
    "text": "scientist might use the Hadoop ecosystem",
    "start": "984279",
    "end": "986370"
  },
  {
    "text": "to serve up the answers to their data",
    "start": "986370",
    "end": "989259"
  },
  {
    "text": "questions and the data engineer might be",
    "start": "989259",
    "end": "992350"
  },
  {
    "text": "programming and interacting machine",
    "start": "992350",
    "end": "994360"
  },
  {
    "text": "learning algorithm to run over a spark",
    "start": "994360",
    "end": "996519"
  },
  {
    "text": "cluster in a more general sense a data",
    "start": "996519",
    "end": "1000149"
  },
  {
    "text": "engineer working on an antic Splatt form",
    "start": "1000149",
    "end": "1002750"
  },
  {
    "text": "implements and supports the analytics",
    "start": "1002750",
    "end": "1005579"
  },
  {
    "text": "technologies that give end-users timely",
    "start": "1005579",
    "end": "1008189"
  },
  {
    "text": "and",
    "start": "1008189",
    "end": "1009030"
  },
  {
    "text": "structured access to the data in this",
    "start": "1009030",
    "end": "1012030"
  },
  {
    "text": "slide we will focus on a data engineer",
    "start": "1012030",
    "end": "1014400"
  },
  {
    "text": "who is using Hadoop and spark for",
    "start": "1014400",
    "end": "1016920"
  },
  {
    "text": "distributed computing and is connecting",
    "start": "1016920",
    "end": "1019170"
  },
  {
    "text": "to the redshift using a data bridge",
    "start": "1019170",
    "end": "1021150"
  },
  {
    "text": "spark redshift package in this diagram a",
    "start": "1021150",
    "end": "1024930"
  },
  {
    "text": "data engineer accessing redshift",
    "start": "1024930",
    "end": "1027810"
  },
  {
    "text": "using the spark redshift packets",
    "start": "1027810",
    "end": "1029579"
  },
  {
    "text": "installed on an EMR which is elastic",
    "start": "1029580",
    "end": "1032490"
  },
  {
    "text": "MapReduce spark cluster in three",
    "start": "1032490",
    "end": "1034800"
  },
  {
    "text": "different use cases in the first use",
    "start": "1034800",
    "end": "1037199"
  },
  {
    "text": "case the data engineer is using a spark",
    "start": "1037200",
    "end": "1039630"
  },
  {
    "text": "cluster for ETL unloading structured",
    "start": "1039630",
    "end": "1042510"
  },
  {
    "text": "data in redshift in the second use case",
    "start": "1042510",
    "end": "1045240"
  },
  {
    "text": "the data engineer is loading the data",
    "start": "1045240",
    "end": "1048120"
  },
  {
    "text": "directly from redshift",
    "start": "1048120",
    "end": "1049680"
  },
  {
    "text": "enriching it and transforming it and",
    "start": "1049680",
    "end": "1051930"
  },
  {
    "text": "saving it back to nature in the third",
    "start": "1051930",
    "end": "1055140"
  },
  {
    "text": "use case the data engineer is",
    "start": "1055140",
    "end": "1057290"
  },
  {
    "text": "integrating redshift as a data source",
    "start": "1057290",
    "end": "1060270"
  },
  {
    "text": "and allowing redshift to interoperate",
    "start": "1060270",
    "end": "1063020"
  },
  {
    "text": "seamlessly with the other data sources",
    "start": "1063020",
    "end": "1065630"
  },
  {
    "text": "accessible to your spark cluster let's",
    "start": "1065630",
    "end": "1069390"
  },
  {
    "text": "dive deeper into the spark spark",
    "start": "1069390",
    "end": "1072870"
  },
  {
    "text": "provides in-memory processing",
    "start": "1072870",
    "end": "1074690"
  },
  {
    "text": "capabilities and natively supports a",
    "start": "1074690",
    "end": "1077640"
  },
  {
    "text": "large number of programming languages it",
    "start": "1077640",
    "end": "1079890"
  },
  {
    "text": "includes libraries for popular machine",
    "start": "1079890",
    "end": "1082680"
  },
  {
    "text": "learning algorithms graph processing",
    "start": "1082680",
    "end": "1085010"
  },
  {
    "text": "stream processing and for sequel data",
    "start": "1085010",
    "end": "1088920"
  },
  {
    "text": "frames are a fundamental data structure",
    "start": "1088920",
    "end": "1091260"
  },
  {
    "text": "used for structured data processing the",
    "start": "1091260",
    "end": "1094500"
  },
  {
    "text": "spark sequel data sources api's provides",
    "start": "1094500",
    "end": "1097860"
  },
  {
    "text": "a pluggable mechanism for integration",
    "start": "1097860",
    "end": "1100080"
  },
  {
    "text": "with the structured data sources of all",
    "start": "1100080",
    "end": "1102660"
  },
  {
    "text": "kinds SPARC users can read data from a",
    "start": "1102660",
    "end": "1106800"
  },
  {
    "text": "variety of sources such as hive tables",
    "start": "1106800",
    "end": "1109410"
  },
  {
    "text": "JSON files columnar pocket tables and",
    "start": "1109410",
    "end": "1112830"
  },
  {
    "text": "many others it also integrates natively",
    "start": "1112830",
    "end": "1116400"
  },
  {
    "text": "with the large number of external input",
    "start": "1116400",
    "end": "1119010"
  },
  {
    "text": "sources including red chip you can",
    "start": "1119010",
    "end": "1122280"
  },
  {
    "text": "manipulate the data in all of the",
    "start": "1122280",
    "end": "1124320"
  },
  {
    "text": "languages that spark supports regardless",
    "start": "1124320",
    "end": "1126810"
  },
  {
    "text": "of how the data store",
    "start": "1126810",
    "end": "1129309"
  },
  {
    "text": "what sparks equal does is that it makes",
    "start": "1129309",
    "end": "1131950"
  },
  {
    "text": "it easy to join the data from different",
    "start": "1131950",
    "end": "1134620"
  },
  {
    "text": "data sources using a single interface",
    "start": "1134620",
    "end": "1137070"
  },
  {
    "text": "spot sequel integrates with third-party",
    "start": "1137070",
    "end": "1140200"
  },
  {
    "text": "sources like red chip using spark",
    "start": "1140200",
    "end": "1142899"
  },
  {
    "text": "packages the spark redshift packets",
    "start": "1142899",
    "end": "1146409"
  },
  {
    "text": "supports loading of the data from",
    "start": "1146409",
    "end": "1148990"
  },
  {
    "text": "redshift as well as saving the data back",
    "start": "1148990",
    "end": "1151509"
  },
  {
    "text": "to that ship the package allows you to",
    "start": "1151509",
    "end": "1154539"
  },
  {
    "text": "integrate large data sets from a",
    "start": "1154539",
    "end": "1157029"
  },
  {
    "text": "redshift database with datasets from",
    "start": "1157029",
    "end": "1159669"
  },
  {
    "text": "other data sources also now if you want",
    "start": "1159669",
    "end": "1163450"
  },
  {
    "text": "to read the data from redshift see you",
    "start": "1163450",
    "end": "1166869"
  },
  {
    "text": "want to process an entire table from",
    "start": "1166869",
    "end": "1169090"
  },
  {
    "text": "redshift or process a query which",
    "start": "1169090",
    "end": "1171610"
  },
  {
    "text": "returns a large number of rows in Spock",
    "start": "1171610",
    "end": "1173980"
  },
  {
    "text": "under the hood spark redshift executes a",
    "start": "1173980",
    "end": "1177759"
  },
  {
    "text": "red chip unload command which copies the",
    "start": "1177759",
    "end": "1180460"
  },
  {
    "text": "redshift table or results from a query",
    "start": "1180460",
    "end": "1183159"
  },
  {
    "text": "to a temporary s3 bucket that you",
    "start": "1183159",
    "end": "1185559"
  },
  {
    "text": "provide next",
    "start": "1185559",
    "end": "1187360"
  },
  {
    "text": "it reads these a three input files and",
    "start": "1187360",
    "end": "1189899"
  },
  {
    "text": "generates a data frame instance that you",
    "start": "1189899",
    "end": "1193539"
  },
  {
    "text": "can manipulate in your application let's",
    "start": "1193539",
    "end": "1196690"
  },
  {
    "text": "see how writing to redshift works to",
    "start": "1196690",
    "end": "1199450"
  },
  {
    "text": "write to redshift the spark redshift",
    "start": "1199450",
    "end": "1201759"
  },
  {
    "text": "library will first create the table in",
    "start": "1201759",
    "end": "1204279"
  },
  {
    "text": "redshift using JDBC it then copies the",
    "start": "1204279",
    "end": "1208749"
  },
  {
    "text": "partitioned data frame as Avro",
    "start": "1208749",
    "end": "1211059"
  },
  {
    "text": "partitions to a temporary s3 folder that",
    "start": "1211059",
    "end": "1214149"
  },
  {
    "text": "you specify finally it executes the",
    "start": "1214149",
    "end": "1217899"
  },
  {
    "text": "redshift copy command to copy the SC",
    "start": "1217899",
    "end": "1220690"
  },
  {
    "text": "contents to the newly created redshift",
    "start": "1220690",
    "end": "1222850"
  },
  {
    "text": "table a few years back if in the order",
    "start": "1222850",
    "end": "1225460"
  },
  {
    "text": "for engineers to make any sort of change",
    "start": "1225460",
    "end": "1227559"
  },
  {
    "text": "would take months to roll out now it",
    "start": "1227559",
    "end": "1230350"
  },
  {
    "text": "happens sometimes in the order of days",
    "start": "1230350",
    "end": "1232179"
  },
  {
    "text": "it up layers and the cloud enables to do",
    "start": "1232179",
    "end": "1234399"
  },
  {
    "text": "that",
    "start": "1234399",
    "end": "1234789"
  },
  {
    "text": "I am the - director of engineering at",
    "start": "1234789",
    "end": "1237309"
  },
  {
    "text": "grab crab is the leading right healing",
    "start": "1237309",
    "end": "1240070"
  },
  {
    "text": "service in Southeast Asia we do 1.5",
    "start": "1240070",
    "end": "1243220"
  },
  {
    "text": "million bookings if we are not running",
    "start": "1243220",
    "end": "1245710"
  },
  {
    "text": "basically transportation comes to a",
    "start": "1245710",
    "end": "1247899"
  },
  {
    "text": "standstill grab is a platform that",
    "start": "1247899",
    "end": "1250929"
  },
  {
    "text": "fundamentally serves two parties one",
    "start": "1250929",
    "end": "1254049"
  },
  {
    "text": "side of the market which is very evident",
    "start": "1254049",
    "end": "1256240"
  },
  {
    "text": "are the passengers there's another part",
    "start": "1256240",
    "end": "1258639"
  },
  {
    "text": "of it is just as important our drivers",
    "start": "1258639",
    "end": "1261009"
  },
  {
    "text": "we have got the biggest land fleet",
    "start": "1261009",
    "end": "1262790"
  },
  {
    "text": "Southeast Asia drivers depend on us",
    "start": "1262790",
    "end": "1264830"
  },
  {
    "text": "daily for their livelihoods with this",
    "start": "1264830",
    "end": "1267890"
  },
  {
    "text": "comes two challenges because of",
    "start": "1267890",
    "end": "1269780"
  },
  {
    "text": "tremendous amount of demand we need to",
    "start": "1269780",
    "end": "1272210"
  },
  {
    "text": "scale but because so many people depend",
    "start": "1272210",
    "end": "1275090"
  },
  {
    "text": "on us we need to stay stable and this",
    "start": "1275090",
    "end": "1277670"
  },
  {
    "text": "are two opposing forces you can scale",
    "start": "1277670",
    "end": "1281150"
  },
  {
    "text": "easily if you don't have to be stable",
    "start": "1281150",
    "end": "1282890"
  },
  {
    "text": "and you can be very stable if you don't",
    "start": "1282890",
    "end": "1285050"
  },
  {
    "text": "have the skill and the answer that came",
    "start": "1285050",
    "end": "1287360"
  },
  {
    "text": "after a lot of reflection on this was we",
    "start": "1287360",
    "end": "1290600"
  },
  {
    "text": "need to address the fundamentals and a",
    "start": "1290600",
    "end": "1292760"
  },
  {
    "text": "big part of the fundamentals is",
    "start": "1292760",
    "end": "1294230"
  },
  {
    "text": "infrastructure if we can make sure that",
    "start": "1294230",
    "end": "1296360"
  },
  {
    "text": "our infrastructure is built in a way",
    "start": "1296360",
    "end": "1298010"
  },
  {
    "text": "that just doesn't meet the needs of",
    "start": "1298010",
    "end": "1299360"
  },
  {
    "text": "today but also meets the needs of the",
    "start": "1299360",
    "end": "1300920"
  },
  {
    "text": "future it complete changes that the type",
    "start": "1300920",
    "end": "1303260"
  },
  {
    "text": "of conversations we have alw any bolts",
    "start": "1303260",
    "end": "1306170"
  },
  {
    "text": "that all these different components are",
    "start": "1306170",
    "end": "1307880"
  },
  {
    "text": "built to letter scale but then also be",
    "start": "1307880",
    "end": "1310820"
  },
  {
    "text": "reliable we started out using the bare",
    "start": "1310820",
    "end": "1314960"
  },
  {
    "text": "the basics as I would call it in in the",
    "start": "1314960",
    "end": "1318230"
  },
  {
    "text": "second eye creation we kind of expanded",
    "start": "1318230",
    "end": "1320480"
  },
  {
    "text": "the services that we use across the",
    "start": "1320480",
    "end": "1322670"
  },
  {
    "text": "board in order to support our scaling",
    "start": "1322670",
    "end": "1324800"
  },
  {
    "text": "needs we need to start thinking about",
    "start": "1324800",
    "end": "1326270"
  },
  {
    "text": "caching layer so that's where we started",
    "start": "1326270",
    "end": "1328070"
  },
  {
    "text": "using elastic cache redshift enabled a",
    "start": "1328070",
    "end": "1330470"
  },
  {
    "text": "lot of that big data computation so our",
    "start": "1330470",
    "end": "1332570"
  },
  {
    "text": "rate shift database is huge its massive",
    "start": "1332570",
    "end": "1336130"
  },
  {
    "text": "everybody in the company uses it it's",
    "start": "1336130",
    "end": "1338240"
  },
  {
    "text": "not just the engineers the product guys",
    "start": "1338240",
    "end": "1339590"
  },
  {
    "text": "use it the marketing team uses that the",
    "start": "1339590",
    "end": "1341630"
  },
  {
    "text": "data team uses it in addition to that we",
    "start": "1341630",
    "end": "1344870"
  },
  {
    "text": "are doing real-time computation and in",
    "start": "1344870",
    "end": "1347630"
  },
  {
    "text": "order to be able to do real-time demand",
    "start": "1347630",
    "end": "1350930"
  },
  {
    "text": "and supply matching we need to have",
    "start": "1350930",
    "end": "1353540"
  },
  {
    "text": "real-time data streams the end result is",
    "start": "1353540",
    "end": "1357500"
  },
  {
    "text": "this our drivers will be tall the demand",
    "start": "1357500",
    "end": "1360260"
  },
  {
    "text": "is at this place right now because",
    "start": "1360260",
    "end": "1362300"
  },
  {
    "text": "there's high demand the drivers will be",
    "start": "1362300",
    "end": "1364520"
  },
  {
    "text": "paid more what we are looking to move",
    "start": "1364520",
    "end": "1366230"
  },
  {
    "text": "towards though is even one step further",
    "start": "1366230",
    "end": "1367910"
  },
  {
    "text": "we want to start building predictive",
    "start": "1367910",
    "end": "1369980"
  },
  {
    "text": "models in two hours time this area is",
    "start": "1369980",
    "end": "1372860"
  },
  {
    "text": "going to have high demand if you want to",
    "start": "1372860",
    "end": "1374420"
  },
  {
    "text": "take advantage of that move to this area",
    "start": "1374420",
    "end": "1376970"
  },
  {
    "text": "and the way we can do that is by taking",
    "start": "1376970",
    "end": "1379040"
  },
  {
    "text": "into account multiple factors building",
    "start": "1379040",
    "end": "1381680"
  },
  {
    "text": "data models around it and using the",
    "start": "1381680",
    "end": "1383510"
  },
  {
    "text": "infrastructure to compute those models",
    "start": "1383510",
    "end": "1385640"
  },
  {
    "text": "and come up with an actionable item",
    "start": "1385640",
    "end": "1387410"
  },
  {
    "text": "there are many benefits to being on the",
    "start": "1387410",
    "end": "1389330"
  },
  {
    "text": "cloud not having to deal with physical",
    "start": "1389330",
    "end": "1391340"
  },
  {
    "text": "issues having to go down to a data",
    "start": "1391340",
    "end": "1393050"
  },
  {
    "text": "center at 3 a.m. in the morning",
    "start": "1393050",
    "end": "1394460"
  },
  {
    "text": "to change a failed hard-disk or server",
    "start": "1394460",
    "end": "1397850"
  },
  {
    "text": "that's overheating because the fan has",
    "start": "1397850",
    "end": "1399440"
  },
  {
    "text": "stopped rotating companies used to have",
    "start": "1399440",
    "end": "1401330"
  },
  {
    "text": "dedicated operational teams just dealing",
    "start": "1401330",
    "end": "1404120"
  },
  {
    "text": "with this sort of issues day in and day",
    "start": "1404120",
    "end": "1405710"
  },
  {
    "text": "out and that carries very little value",
    "start": "1405710",
    "end": "1407720"
  },
  {
    "text": "for the organization and more",
    "start": "1407720",
    "end": "1409190"
  },
  {
    "text": "importantly it carries very little value",
    "start": "1409190",
    "end": "1411010"
  },
  {
    "text": "for the engineers themselves every",
    "start": "1411010",
    "end": "1414170"
  },
  {
    "text": "engineering team and every engineer gets",
    "start": "1414170",
    "end": "1416750"
  },
  {
    "text": "an AWS account they can run full-blown",
    "start": "1416750",
    "end": "1418790"
  },
  {
    "text": "experiments in their sub account and",
    "start": "1418790",
    "end": "1420140"
  },
  {
    "text": "they would find things that might be a",
    "start": "1420140",
    "end": "1421700"
  },
  {
    "text": "problem three months from now six months",
    "start": "1421700",
    "end": "1423290"
  },
  {
    "text": "from now and giving engineers that",
    "start": "1423290",
    "end": "1425480"
  },
  {
    "text": "ability is unparalleled",
    "start": "1425480",
    "end": "1427190"
  },
  {
    "text": "it's my estimate that we probably saved",
    "start": "1427190",
    "end": "1429890"
  },
  {
    "text": "30 or 40 percent of resourcing and",
    "start": "1429890",
    "end": "1433070"
  },
  {
    "text": "manpower that that then went to serving",
    "start": "1433070",
    "end": "1437120"
  },
  {
    "text": "our core focus and our core focus is out",
    "start": "1437120",
    "end": "1439340"
  },
  {
    "text": "serving our customers the fact that the",
    "start": "1439340",
    "end": "1442040"
  },
  {
    "text": "team didn't have to worry about that",
    "start": "1442040",
    "end": "1443510"
  },
  {
    "text": "just allowed us to move significantly",
    "start": "1443510",
    "end": "1444980"
  },
  {
    "text": "faster and in the startup environment",
    "start": "1444980",
    "end": "1447440"
  },
  {
    "text": "that is make or break",
    "start": "1447440",
    "end": "1450700"
  },
  {
    "text": "[Music]",
    "start": "1451080",
    "end": "1459560"
  },
  {
    "text": "at FINRA we chose AWS because we wanted",
    "start": "1459560",
    "end": "1463650"
  },
  {
    "text": "to be able to deliver innovation at a",
    "start": "1463650",
    "end": "1466770"
  },
  {
    "text": "much larger scale and much more rapidly",
    "start": "1466770",
    "end": "1469470"
  },
  {
    "text": "to our core business I'm someone Michael",
    "start": "1469470",
    "end": "1472740"
  },
  {
    "text": "Farr I'm the senior vice president of",
    "start": "1472740",
    "end": "1474870"
  },
  {
    "text": "technology at the Financial Industry",
    "start": "1474870",
    "end": "1476610"
  },
  {
    "text": "Regulatory Authority FINRA is the",
    "start": "1476610",
    "end": "1479880"
  },
  {
    "text": "largest independent regulator of",
    "start": "1479880",
    "end": "1481700"
  },
  {
    "text": "financial markets in the u.s. we have",
    "start": "1481700",
    "end": "1484310"
  },
  {
    "text": "approximately 4,000 staff and we have",
    "start": "1484310",
    "end": "1488280"
  },
  {
    "text": "offices throughout the US we evaluated",
    "start": "1488280",
    "end": "1492090"
  },
  {
    "text": "and moved to AWS cloud for several",
    "start": "1492090",
    "end": "1494070"
  },
  {
    "text": "reasons one of them was the to get the",
    "start": "1494070",
    "end": "1497010"
  },
  {
    "text": "ability to do better analytics on Big",
    "start": "1497010",
    "end": "1499050"
  },
  {
    "text": "Data and more extensive analytics and",
    "start": "1499050",
    "end": "1502380"
  },
  {
    "text": "deeper looks at what's going on in",
    "start": "1502380",
    "end": "1504180"
  },
  {
    "text": "markets for regulatory purposes a second",
    "start": "1504180",
    "end": "1506850"
  },
  {
    "text": "reason we chose to move to AWS was to be",
    "start": "1506850",
    "end": "1509970"
  },
  {
    "text": "able to get better cost-effectiveness",
    "start": "1509970",
    "end": "1512160"
  },
  {
    "text": "compared to a private data center market",
    "start": "1512160",
    "end": "1516240"
  },
  {
    "text": "volumes can very easily a factor of 3x",
    "start": "1516240",
    "end": "1519750"
  },
  {
    "text": "during normal operations so we can",
    "start": "1519750",
    "end": "1522060"
  },
  {
    "text": "expand up and down with the volumes that",
    "start": "1522060",
    "end": "1523920"
  },
  {
    "text": "come in both in the ingestion pipeline",
    "start": "1523920",
    "end": "1526080"
  },
  {
    "text": "and the validation and the normalization",
    "start": "1526080",
    "end": "1527960"
  },
  {
    "text": "then in response to different things",
    "start": "1527960",
    "end": "1530940"
  },
  {
    "text": "that are happening in the markets we're",
    "start": "1530940",
    "end": "1532860"
  },
  {
    "text": "able to spin up clusters with EMR and",
    "start": "1532860",
    "end": "1536450"
  },
  {
    "text": "apply various query engines such as hi",
    "start": "1536450",
    "end": "1540030"
  },
  {
    "text": "to these two pools of data that come in",
    "start": "1540030",
    "end": "1543810"
  },
  {
    "text": "what we're able to do is allow the",
    "start": "1543810",
    "end": "1545490"
  },
  {
    "text": "regulatory analysts to interactively",
    "start": "1545490",
    "end": "1547590"
  },
  {
    "text": "query multi petabyte scale data and in",
    "start": "1547590",
    "end": "1551280"
  },
  {
    "text": "doing so zoom in on where the potential",
    "start": "1551280",
    "end": "1554520"
  },
  {
    "text": "problem areas are when you're receiving",
    "start": "1554520",
    "end": "1556470"
  },
  {
    "text": "75 billion records a day and processing",
    "start": "1556470",
    "end": "1561840"
  },
  {
    "text": "this and surveilling this information if",
    "start": "1561840",
    "end": "1563910"
  },
  {
    "text": "we can automate this process to the",
    "start": "1563910",
    "end": "1565770"
  },
  {
    "text": "highest degree possible we can be a lot",
    "start": "1565770",
    "end": "1567480"
  },
  {
    "text": "more efficient and this allowed us to",
    "start": "1567480",
    "end": "1570150"
  },
  {
    "text": "take this information in and have the",
    "start": "1570150",
    "end": "1572820"
  },
  {
    "text": "from the point of ingest to the point at",
    "start": "1572820",
    "end": "1575010"
  },
  {
    "text": "which the data is available for",
    "start": "1575010",
    "end": "1576510"
  },
  {
    "text": "analytics to operate without human",
    "start": "1576510",
    "end": "1578790"
  },
  {
    "text": "intervention to deal with errors",
    "start": "1578790",
    "end": "1581840"
  },
  {
    "text": "resubmissions and that type of activity",
    "start": "1581840",
    "end": "1584700"
  },
  {
    "text": "so this allowed us to redirect our",
    "start": "1584700",
    "end": "1587130"
  },
  {
    "text": "investment from production support and",
    "start": "1587130",
    "end": "1589650"
  },
  {
    "text": "operations",
    "start": "1589650",
    "end": "1591120"
  },
  {
    "text": "to software development and developing",
    "start": "1591120",
    "end": "1593760"
  },
  {
    "text": "better analytics because we're able to",
    "start": "1593760",
    "end": "1596059"
  },
  {
    "text": "undemanding resources what we're able to",
    "start": "1596059",
    "end": "1600600"
  },
  {
    "text": "provide is a rich set of analytics for",
    "start": "1600600",
    "end": "1603840"
  },
  {
    "text": "our regulatory staff in January of 2014",
    "start": "1603840",
    "end": "1608220"
  },
  {
    "text": "we began a two and a half year project",
    "start": "1608220",
    "end": "1611670"
  },
  {
    "text": "to rewrite re-implement we architect our",
    "start": "1611670",
    "end": "1616080"
  },
  {
    "text": "market regulation systems on AWS and",
    "start": "1616080",
    "end": "1619100"
  },
  {
    "text": "that project has been going on and has",
    "start": "1619100",
    "end": "1622050"
  },
  {
    "text": "been very successful to date we have",
    "start": "1622050",
    "end": "1624270"
  },
  {
    "text": "approximately 75% of the system's",
    "start": "1624270",
    "end": "1626610"
  },
  {
    "text": "already in production on AWS and we're",
    "start": "1626610",
    "end": "1629220"
  },
  {
    "text": "beginning already to realize the",
    "start": "1629220",
    "end": "1631050"
  },
  {
    "text": "benefits we make extensive use of s3 EMR",
    "start": "1631050",
    "end": "1634980"
  },
  {
    "text": "ec2 hive on EMR HBase on EMR we also",
    "start": "1634980",
    "end": "1640890"
  },
  {
    "text": "make extensive use of the various other",
    "start": "1640890",
    "end": "1643950"
  },
  {
    "text": "supporting systems around these when we",
    "start": "1643950",
    "end": "1646830"
  },
  {
    "text": "first started to look at AWS and",
    "start": "1646830",
    "end": "1648720"
  },
  {
    "text": "consider moving to AWS we weren't sure",
    "start": "1648720",
    "end": "1651090"
  },
  {
    "text": "what the support model would be like as",
    "start": "1651090",
    "end": "1652890"
  },
  {
    "text": "we've moved through the process and",
    "start": "1652890",
    "end": "1654809"
  },
  {
    "text": "engaged with AWS enterprise support and",
    "start": "1654809",
    "end": "1657480"
  },
  {
    "text": "the various channels that AWS provides",
    "start": "1657480",
    "end": "1659550"
  },
  {
    "text": "it's been anything but that and we've",
    "start": "1659550",
    "end": "1662100"
  },
  {
    "text": "received really the type of support that",
    "start": "1662100",
    "end": "1664920"
  },
  {
    "text": "we would expect and require as an",
    "start": "1664920",
    "end": "1667530"
  },
  {
    "text": "enterprise in moving mission critical",
    "start": "1667530",
    "end": "1670410"
  },
  {
    "text": "systems to the cloud environment",
    "start": "1670410",
    "end": "1674300"
  },
  {
    "text": "[Music]",
    "start": "1674300",
    "end": "1677789"
  },
  {
    "text": "you",
    "start": "1677789",
    "end": "1679850"
  },
  {
    "text": "so that brings us to the end of this",
    "start": "1680880",
    "end": "1683830"
  },
  {
    "text": "session and today if you would like to",
    "start": "1683830",
    "end": "1686740"
  },
  {
    "text": "learn more you can just go to",
    "start": "1686740",
    "end": "1688390"
  },
  {
    "text": "aws.amazon.com slash big - data here you",
    "start": "1688390",
    "end": "1694330"
  },
  {
    "text": "will find information on big data",
    "start": "1694330",
    "end": "1696280"
  },
  {
    "text": "analytic solutions partners case studies",
    "start": "1696280",
    "end": "1699700"
  },
  {
    "text": "and various are the technical resources",
    "start": "1699700",
    "end": "1702120"
  },
  {
    "text": "if you would like to gain hands-on",
    "start": "1702120",
    "end": "1705100"
  },
  {
    "text": "experience with AWS please watch our",
    "start": "1705100",
    "end": "1707890"
  },
  {
    "text": "instructional videos and explored the",
    "start": "1707890",
    "end": "1710590"
  },
  {
    "text": "self place labs you can also attend our",
    "start": "1710590",
    "end": "1714040"
  },
  {
    "text": "instructor-led classes and learn how to",
    "start": "1714040",
    "end": "1716950"
  },
  {
    "text": "design deploy and operate highly",
    "start": "1716950",
    "end": "1720280"
  },
  {
    "text": "available cost-effective and secure",
    "start": "1720280",
    "end": "1722440"
  },
  {
    "text": "applications on AWS you can get more",
    "start": "1722440",
    "end": "1725860"
  },
  {
    "text": "information by visiting our URL",
    "start": "1725860",
    "end": "1727930"
  },
  {
    "text": "aws.amazon.com slash training AWS also",
    "start": "1727930",
    "end": "1733600"
  },
  {
    "text": "has a white ecosystem of partners to",
    "start": "1733600",
    "end": "1736000"
  },
  {
    "text": "help you focus on your success and take",
    "start": "1736000",
    "end": "1738640"
  },
  {
    "text": "the full advantage of our business",
    "start": "1738640",
    "end": "1740380"
  },
  {
    "text": "benefits that AWS has to offer learn",
    "start": "1740380",
    "end": "1743290"
  },
  {
    "text": "more about how APN partners can help you",
    "start": "1743290",
    "end": "1746170"
  },
  {
    "text": "and find the right epin partner for your",
    "start": "1746170",
    "end": "1748870"
  },
  {
    "text": "needs by visiting our AWS APN booth at a",
    "start": "1748870",
    "end": "1752290"
  },
  {
    "text": "partner showcase thank you again for",
    "start": "1752290",
    "end": "1755590"
  },
  {
    "text": "attending the session and hope you found",
    "start": "1755590",
    "end": "1757330"
  },
  {
    "text": "it interesting do provide us with your",
    "start": "1757330",
    "end": "1759940"
  },
  {
    "text": "feedback and let us know how we can",
    "start": "1759940",
    "end": "1762220"
  },
  {
    "text": "improve the event experience for you in",
    "start": "1762220",
    "end": "1764770"
  },
  {
    "text": "the future",
    "start": "1764770",
    "end": "1767130"
  }
]
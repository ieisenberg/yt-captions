[
  {
    "start": "0",
    "end": "35000"
  },
  {
    "text": "so hi everyone my name is Yin even from the Container Services team and in the",
    "start": "430",
    "end": "5689"
  },
  {
    "text": "last few months have been actually leading our AI and ML solutions on solutions like kubernetes for example",
    "start": "5689",
    "end": "12469"
  },
  {
    "text": "and I'm going to show you why in a couple of minutes and I also have Mike",
    "start": "12469",
    "end": "17600"
  },
  {
    "text": "root with me who's a senior engineer and the open source team here in AWS as well and he's actually going to show you a",
    "start": "17600",
    "end": "23689"
  },
  {
    "text": "pretty nice demo and some of the things that we've been doing and the innovations which putting into some of the solving some of the specific",
    "start": "23689",
    "end": "30619"
  },
  {
    "text": "challenges that people have today on running their machine learning workloads",
    "start": "30619",
    "end": "35710"
  },
  {
    "start": "35000",
    "end": "95000"
  },
  {
    "text": "so let me start off by just saying that there's been a lot of hype around",
    "start": "35710",
    "end": "41090"
  },
  {
    "text": "machine learning and AI over the last few years and Gartner keeps running an",
    "start": "41090",
    "end": "48350"
  },
  {
    "text": "annual report and survey on the hype cycle of these kinds of emerging",
    "start": "48350",
    "end": "53840"
  },
  {
    "text": "technologies and each year machine learning and AI are kind of in the peak of their hype cycle so it's coming to a",
    "start": "53840",
    "end": "62240"
  },
  {
    "text": "tipping point in which the hype around this technology is actually starting to transform to real impact on businesses",
    "start": "62240",
    "end": "68390"
  },
  {
    "text": "like enterprises large companies and also startups or all looking to leverage and gain the benefits from what it is",
    "start": "68390",
    "end": "74990"
  },
  {
    "text": "and there has been a recent IDC report that shows that or predicts that in the next year or so about 40% of the digital",
    "start": "74990",
    "end": "82430"
  },
  {
    "text": "transformations are going to be involved with AI and ml so this is just to kind",
    "start": "82430",
    "end": "88909"
  },
  {
    "text": "of set the stage on why we're even seeing this and and how meaningful that can be for you our mission in AWS is to",
    "start": "88909",
    "end": "99200"
  },
  {
    "start": "95000",
    "end": "112000"
  },
  {
    "text": "be able to put machine learning in the hands of each and every one of you to do that we have built the broadest and",
    "start": "99200",
    "end": "106600"
  },
  {
    "text": "deepest compute platform to help support AI and machine learning workloads on",
    "start": "106600",
    "end": "112120"
  },
  {
    "start": "112000",
    "end": "163000"
  },
  {
    "text": "multiple stages so for the experts machine learning practitioners who one",
    "start": "112120",
    "end": "119090"
  },
  {
    "text": "have the control and the ability to deploy and develop test deploy and tune their own machine learning models we",
    "start": "119090",
    "end": "126680"
  },
  {
    "text": "have built frameworks that can run on our compute services as you probably know we have a pretty broad",
    "start": "126680",
    "end": "133050"
  },
  {
    "text": "range of compute offerings from P to s and P 3s the G instances the latest announced P 3",
    "start": "133050",
    "end": "139890"
  },
  {
    "text": "d n and some others that are right now in the works such as G 4 and the new",
    "start": "139890",
    "end": "145410"
  },
  {
    "text": "chip inferential which we announced that is going to be launched later on so and under those compute platforms you can",
    "start": "145410",
    "end": "152760"
  },
  {
    "text": "actually run a selected number of frameworks and interfaces of machine",
    "start": "152760",
    "end": "158310"
  },
  {
    "text": "learning including tensorflow Amex net and many many other flavors as well on the middle layer we have what we",
    "start": "158310",
    "end": "166230"
  },
  {
    "start": "163000",
    "end": "221000"
  },
  {
    "text": "call the ml services because unfortunately as it is today there are not enough machine learning experts and",
    "start": "166230",
    "end": "173250"
  },
  {
    "text": "specialists in the world so in order to put machine learning in the hands of each and every one of the data",
    "start": "173250",
    "end": "179280"
  },
  {
    "text": "scientists data engineers and machine learning practitioners we invented a",
    "start": "179280",
    "end": "184560"
  },
  {
    "text": "bunch of machine learning services for fronted by Sage maker who is an",
    "start": "184560",
    "end": "189660"
  },
  {
    "text": "end-to-end compute platform and machine learning platform destined to be able for you to get started with machine",
    "start": "189660",
    "end": "196050"
  },
  {
    "text": "learning very easily starting from the notebook experience so you can provision Jupiter notebooks following on with data",
    "start": "196050",
    "end": "203190"
  },
  {
    "text": "pre-processing training and then inference as well so it's a package that allows everyone to get started with",
    "start": "203190",
    "end": "209790"
  },
  {
    "text": "machine learning very easily and also comes pre-built with a lot of the models and the public more popular models that",
    "start": "209790",
    "end": "217440"
  },
  {
    "text": "are serving a lot of our customers to get started with machine learning and then on top of that we also produced a",
    "start": "217440",
    "end": "225030"
  },
  {
    "start": "221000",
    "end": "264000"
  },
  {
    "text": "bunch of AI specific platforms there are for those of you who do not want to be",
    "start": "225030",
    "end": "230880"
  },
  {
    "text": "able to model and build and train their models but just want it to be able to",
    "start": "230880",
    "end": "236130"
  },
  {
    "text": "leverage AI as part of your applications with a bunch of AI offering such as",
    "start": "236130",
    "end": "242430"
  },
  {
    "text": "vision speech language and many many others we introduced a bunch of managed",
    "start": "242430",
    "end": "248489"
  },
  {
    "text": "services like recognition comprehend and many many others which you can just",
    "start": "248489",
    "end": "253530"
  },
  {
    "text": "leverage with your existing or new applications running in the cloud and get started very easily and also drive",
    "start": "253530",
    "end": "260370"
  },
  {
    "text": "the time to market and the cost significantly down so to summarize all of that a very",
    "start": "260370",
    "end": "266700"
  },
  {
    "start": "264000",
    "end": "281000"
  },
  {
    "text": "deep in terms of breadth and depth compute an AI platform that allows each",
    "start": "266700",
    "end": "272490"
  },
  {
    "text": "of you whether it's an expert machinery practitioner somebody who's getting started or just want to leverage our",
    "start": "272490",
    "end": "278340"
  },
  {
    "text": "capabilities to do that with our services now obviously you cannot do machine",
    "start": "278340",
    "end": "283920"
  },
  {
    "start": "281000",
    "end": "337000"
  },
  {
    "text": "learning with just AI and m/l services machine learning usually requires a lot of data a lot of data processing and so",
    "start": "283920",
    "end": "291420"
  },
  {
    "text": "you need analytics tools such as EMR redshift and other services to be able to help",
    "start": "291420",
    "end": "297960"
  },
  {
    "text": "you digest pre-process the data and make it available for your machine learning",
    "start": "297960",
    "end": "303960"
  },
  {
    "text": "development lifecycle and training you also need a lot of storage as I will",
    "start": "303960",
    "end": "309120"
  },
  {
    "text": "show you a little bit later on some of the customers that we work with especially in autonomous vehicles",
    "start": "309120",
    "end": "314190"
  },
  {
    "text": "industry are processing huge amounts of data and to do that they are leveraging",
    "start": "314190",
    "end": "319710"
  },
  {
    "text": "a lot of our s3 services including deep archive which is very popular in that space in order to gain the benefits of",
    "start": "319710",
    "end": "326880"
  },
  {
    "text": "saving a lot of data and making it accessible to your application and training and inference models in the",
    "start": "326880",
    "end": "333060"
  },
  {
    "text": "fastest way and in the cheapest way possible but the reason we're all here",
    "start": "333060",
    "end": "339150"
  },
  {
    "start": "337000",
    "end": "363000"
  },
  {
    "text": "is kubernetes so kubernetes has been becoming very very popular in a",
    "start": "339150",
    "end": "346560"
  },
  {
    "text": "framework layer in order to run these machine learning processes or pipelines",
    "start": "346560",
    "end": "352440"
  },
  {
    "text": "and to end on the platform and this is what i'm going to focus on today to show you what customers are",
    "start": "352440",
    "end": "358470"
  },
  {
    "text": "using it for and how you can leverage that with AWS so first off why would we",
    "start": "358470",
    "end": "365850"
  },
  {
    "start": "363000",
    "end": "445000"
  },
  {
    "text": "use kubernetes to run machine learning I mean kubernetes is a general-purpose computer form container platform",
    "start": "365850",
    "end": "372420"
  },
  {
    "text": "orchestration why would you use it so people are using it from exactly the same reasons why they are using",
    "start": "372420",
    "end": "378510"
  },
  {
    "text": "kubernetes for their micro services for their apps or any other application for that matter so the ability to compose a",
    "start": "378510",
    "end": "386610"
  },
  {
    "text": "lot of different pieces and building blocks and build your own customized machine learning tool or framework using",
    "start": "386610",
    "end": "393630"
  },
  {
    "text": "your favorite models using your favorite IDE tools and choosing each step of the",
    "start": "393630",
    "end": "399660"
  },
  {
    "text": "way which bounine to which technology you want to leverage that's something that kubernetes and the frameworks that run",
    "start": "399660",
    "end": "405780"
  },
  {
    "text": "on top of it will provide you portability so the ability to actually take your machine learning workflow from",
    "start": "405780",
    "end": "412950"
  },
  {
    "text": "your laptop or your desktop GPUs to anywhere else including the cloud and be",
    "start": "412950",
    "end": "419580"
  },
  {
    "text": "able to remain consistent along the process and have the exact same pipeline running on all environments and",
    "start": "419580",
    "end": "425910"
  },
  {
    "text": "obviously scalability which is something that kubernetes offers you and especially if you're running on AWS you",
    "start": "425910",
    "end": "432780"
  },
  {
    "text": "will get all the benefits of the underlying auto scaling services that we have that really allow you to burst into",
    "start": "432780",
    "end": "438870"
  },
  {
    "text": "the hundreds or even more instances GPUs or CPU cores as required so I want to",
    "start": "438870",
    "end": "446730"
  },
  {
    "text": "break it down to talk a little bit about the machine learning workflow itself let's get down to the details what do",
    "start": "446730",
    "end": "452040"
  },
  {
    "text": "you have to do in order to run your machine learning workloads today so first of all people start off with",
    "start": "452040",
    "end": "459570"
  },
  {
    "start": "456000",
    "end": "523000"
  },
  {
    "text": "running some prototyping and usually the way that that works is through either jupiter notebooks or other types of",
    "start": "459570",
    "end": "466920"
  },
  {
    "text": "notebooks notebooks for those of you who doesn't know our popular technologies in",
    "start": "466920",
    "end": "473220"
  },
  {
    "text": "the machine onyx face and also analytics in general because they allow you to bring in a lot of code data all in the",
    "start": "473220",
    "end": "480480"
  },
  {
    "text": "same place and be able to share that with your peers or with other teams in your company and also interact from",
    "start": "480480",
    "end": "487320"
  },
  {
    "text": "within that notebook with other services for example in AWS you can actually invoke jobs that are run in EMR or run",
    "start": "487320",
    "end": "494700"
  },
  {
    "text": "in redshift straight from within a Jupiter or any other notebook that you will because basically it's all API",
    "start": "494700",
    "end": "501540"
  },
  {
    "text": "based some other machine learning practitioners preferred the IDE approach",
    "start": "501540",
    "end": "507060"
  },
  {
    "text": "so they like to program and code so they use Python or frameworks like pi torch and then there are others who use",
    "start": "507060",
    "end": "513450"
  },
  {
    "text": "frameworks like our brain for example which is a machine learning framework built on top of Jupiter so it's kind of",
    "start": "513450",
    "end": "519180"
  },
  {
    "text": "more tuned into the machine learning workflow one thing to note about that",
    "start": "519180",
    "end": "524820"
  },
  {
    "start": "523000",
    "end": "563000"
  },
  {
    "text": "process though is that the process is iterative so you start off your prototype you bring in a bunch of data",
    "start": "524820",
    "end": "531960"
  },
  {
    "text": "in order to test and be than train your model but then after you validate that with real data you may",
    "start": "531960",
    "end": "538800"
  },
  {
    "text": "find that the model is still now not where it needs to be which means it's not really behaving the way chewed on",
    "start": "538800",
    "end": "545220"
  },
  {
    "text": "datasets that have not been used before which means you have to go back and do some data wrangling re compute and tune",
    "start": "545220",
    "end": "552930"
  },
  {
    "text": "your model and then do the same process all over again so that can be an iterative process that can take however",
    "start": "552930",
    "end": "559949"
  },
  {
    "text": "time it is depending on the complexity of the model so let's see how that works so first of all in terms of Jupiter",
    "start": "559949",
    "end": "566519"
  },
  {
    "start": "563000",
    "end": "589000"
  },
  {
    "text": "Jupiter itself is a very popular technology a lot of the frameworks including our own sage maker cube flow",
    "start": "566519",
    "end": "573060"
  },
  {
    "text": "which we'll talk about in a second and others support Jupiter today as I said it's very well tuned to do analytics in",
    "start": "573060",
    "end": "580500"
  },
  {
    "text": "general but machine learning specifically so that's very nice yeah",
    "start": "580500",
    "end": "589290"
  },
  {
    "start": "589000",
    "end": "663000"
  },
  {
    "text": "let's bring it on so as I mentioned the data processing tool starts or the",
    "start": "589290",
    "end": "594959"
  },
  {
    "text": "machine learning workflow starts with data pre-processing so data pre-processing is basically bringing in",
    "start": "594959",
    "end": "601290"
  },
  {
    "text": "some clean data or raw data that comes in from multiple sources of your application or if you from your business",
    "start": "601290",
    "end": "606980"
  },
  {
    "text": "that data first and foremost needs to be cleansed sometimes you need to drop the",
    "start": "606980",
    "end": "613199"
  },
  {
    "text": "irrelevant data sometimes you're getting unstructured data that needs to be structured into a certain format in",
    "start": "613199",
    "end": "619230"
  },
  {
    "text": "order to run the machine learning process on it and build models so there could be multiple variations of how you",
    "start": "619230",
    "end": "624930"
  },
  {
    "text": "can clean and pre-process the data and then you get into an iterative process in which you're going to build your",
    "start": "624930",
    "end": "631800"
  },
  {
    "text": "model you're going to train it and then when you do validation you may have to go back and do some data wrangling which",
    "start": "631800",
    "end": "638339"
  },
  {
    "text": "will be an iterative process like I mentioned before at the end of the day you will get a model and that model",
    "start": "638339",
    "end": "643620"
  },
  {
    "text": "needs to be deployed on an endpoint so it can actually start serving our inference requests which are what we",
    "start": "643620",
    "end": "651449"
  },
  {
    "text": "actually came here to do we want our application to make a prediction and get a response from or make an API call and",
    "start": "651449",
    "end": "659490"
  },
  {
    "text": "get a prediction from the inference endpoint",
    "start": "659490",
    "end": "663800"
  },
  {
    "start": "663000",
    "end": "755000"
  },
  {
    "text": "so you can do all of the things that I just mentioned today on kubernetes alone without Q flow however when you do so",
    "start": "664800",
    "end": "673120"
  },
  {
    "text": "you will have to take care a lot of the things yourself so things like how do I",
    "start": "673120",
    "end": "678279"
  },
  {
    "text": "port the UX and the IDE that I want to work with in my desktop and how do I",
    "start": "678279",
    "end": "683529"
  },
  {
    "text": "switch that over to the cloud how do I use different models how do I use different tooling because the tooling",
    "start": "683529",
    "end": "689470"
  },
  {
    "text": "may change or evolve over time so cube flow really what it does is provide the",
    "start": "689470",
    "end": "694630"
  },
  {
    "text": "set of tools that can work across all those environments for you and allow you",
    "start": "694630",
    "end": "699910"
  },
  {
    "text": "to just set the stage on how your process should look like and have it run in a consistent matter across all of the",
    "start": "699910",
    "end": "706930"
  },
  {
    "text": "places that you're developing your machine learning models with so what is",
    "start": "706930",
    "end": "713170"
  },
  {
    "text": "Q flow Q flow is a collection of tools that help you as an ml practitioner to",
    "start": "713170",
    "end": "720310"
  },
  {
    "text": "get the job done so we mentioned some of those tools like the Jupiter notebook but there are other tools for example",
    "start": "720310",
    "end": "726700"
  },
  {
    "text": "there are framework operators so for example we have tensor flow operator and",
    "start": "726700",
    "end": "731709"
  },
  {
    "text": "M X net operator so those are different frameworks for machine learning training that you can leverage each of them using",
    "start": "731709",
    "end": "738279"
  },
  {
    "text": "the kubernetes operator that makes them available to cube flow and there are",
    "start": "738279",
    "end": "744310"
  },
  {
    "text": "other tools in that like Argo which is a workflow management system and I will",
    "start": "744310",
    "end": "749470"
  },
  {
    "text": "talk about coop flow pipeline which is another component which is relatively new on cube flow in a second so the good",
    "start": "749470",
    "end": "757630"
  },
  {
    "start": "755000",
    "end": "800000"
  },
  {
    "text": "news that if you want to get started with cube flow on AWS you can do so today we have a product page on the cube",
    "start": "757630",
    "end": "764410"
  },
  {
    "text": "flow project itself which has a deployment section that can get you started very easily so you'll gone",
    "start": "764410",
    "end": "770770"
  },
  {
    "text": "you're going to be installing a bunch of tools like cube cut' okay SONET obviously the command line for cube flow",
    "start": "770770",
    "end": "778810"
  },
  {
    "text": "itself and then the provisioning process is going to set up the entire eks cluster including the cube flow for you",
    "start": "778810",
    "end": "785560"
  },
  {
    "text": "so it's going to abstract a lot of those complexities that data practitioners or machine learning practitioners may run",
    "start": "785560",
    "end": "791890"
  },
  {
    "text": "into if they're not aware of the AWS constructs like vpceb",
    "start": "791890",
    "end": "797000"
  },
  {
    "text": "networking etc q flow pipelines is one",
    "start": "797000",
    "end": "803089"
  },
  {
    "start": "800000",
    "end": "886000"
  },
  {
    "text": "of the recently added features to cube flow what it does is it allows you to actually define a pipeline or a",
    "start": "803089",
    "end": "809420"
  },
  {
    "text": "machine-learning pipeline end-to-end so think about the process that I just mentioned earlier starting from the data",
    "start": "809420",
    "end": "816350"
  },
  {
    "text": "pre-processing training and inference all of those steps can now be represented as a step in the cube flow",
    "start": "816350",
    "end": "822769"
  },
  {
    "text": "pipeline now the Q flow pipeline is persistent so it can be replicated and maintained across environments and it",
    "start": "822769",
    "end": "829579"
  },
  {
    "text": "has a bunch of integrations to other tools that you can leverage to do different steps so for example for data",
    "start": "829579",
    "end": "835459"
  },
  {
    "text": "pre-processing you can today invoke an EMR job using spark and spark is one of",
    "start": "835459",
    "end": "842300"
  },
  {
    "text": "the most popular frameworks to date on processing large sets of data so the",
    "start": "842300",
    "end": "848569"
  },
  {
    "text": "benefit of using or leveraging EMR is that you will be able to offload the job",
    "start": "848569",
    "end": "854420"
  },
  {
    "text": "get a cluster or a spark cluster set up for you leverage spot instances which is",
    "start": "854420",
    "end": "860750"
  },
  {
    "text": "a way for you to reduce the costs with 70 to 90 percent from an on-demand pricing on AWS which can be very",
    "start": "860750",
    "end": "868250"
  },
  {
    "text": "significant because fart jobs typically run on large data sets so we topical talking about clusters of dozens or even",
    "start": "868250",
    "end": "874879"
  },
  {
    "text": "hundreds of compute intensive instances that can be costly to process and this",
    "start": "874879",
    "end": "880370"
  },
  {
    "text": "all gives you the ability to invoke all of that from within the cube flow pipeline itself so some of the benefits",
    "start": "880370",
    "end": "889459"
  },
  {
    "start": "886000",
    "end": "1028000"
  },
  {
    "text": "involved in leveraging cube flow on AWS some of which we already discussed so",
    "start": "889459",
    "end": "896360"
  },
  {
    "text": "cluster provisioning with eks Caudill that's basically what it means is it's going to abstract the complexity of",
    "start": "896360",
    "end": "903079"
  },
  {
    "text": "setting up AWS construct and the eks cluster from you so it's just a simple",
    "start": "903079",
    "end": "909769"
  },
  {
    "text": "command line you can have an eks cluster with the instance types that you choose and the cluster this and the size that",
    "start": "909769",
    "end": "916160"
  },
  {
    "text": "you choose set up with cube flow ready for you to get started with your ml process we also support a LB ingress",
    "start": "916160",
    "end": "924379"
  },
  {
    "text": "controller which means if you want it to set up and tensorflow serving endpoints",
    "start": "924379",
    "end": "931490"
  },
  {
    "text": "you can set it up through alb ingress controller so the way it's going to work is we're going to connect an optional",
    "start": "931490",
    "end": "937970"
  },
  {
    "text": "plugin which is the sto gateway and all of the traffic coming in from the alb ingress controller will be flowing",
    "start": "937970",
    "end": "944540"
  },
  {
    "text": "through the FCO gateway and then to the Ambassador inside the cluster itself we",
    "start": "944540",
    "end": "951620"
  },
  {
    "text": "also have a dedicated support today for storage and that's not just a cube flow feature it's a to Brady's feature so we",
    "start": "951620",
    "end": "958640"
  },
  {
    "text": "have drivers CSI drivers native to kubernetes for EBS EFS and fsx lustre",
    "start": "958640",
    "end": "965290"
  },
  {
    "text": "that can be really significant especially when it comes to large-scale processing and I'll talk about an",
    "start": "965290",
    "end": "971990"
  },
  {
    "text": "example of one of those workloads in a second then you also get the unified",
    "start": "971990",
    "end": "977810"
  },
  {
    "text": "cloud watch logging so all the kubernetes cluster control control plane logs will be routed to cloud watch so",
    "start": "977810",
    "end": "983930"
  },
  {
    "text": "you can monitor and see what's happening within your cluster if you're using the",
    "start": "983930",
    "end": "988970"
  },
  {
    "text": "alb ingress you also get TLS and auth with certificate manager and Cognito and then we recently introduced private",
    "start": "988970",
    "end": "996410"
  },
  {
    "text": "access to your communities cluster as kubernetes api server endpoints so you",
    "start": "996410",
    "end": "1001930"
  },
  {
    "text": "can leverage those as well if you didn't want them to be public and one last benefit is today when you're setting up",
    "start": "1001930",
    "end": "1009520"
  },
  {
    "text": "your cube flow on AWS with the eks integration the cube flow will detect if",
    "start": "1009520",
    "end": "1015370"
  },
  {
    "text": "you're running a GPU based cluster and consequently will provision or install the Nvidia device plugin on its own so",
    "start": "1015370",
    "end": "1022720"
  },
  {
    "text": "you don't have to worry about the device plug in manually being installed by you",
    "start": "1022720",
    "end": "1028530"
  },
  {
    "start": "1028000",
    "end": "1042000"
  },
  {
    "text": "so this covers all the way to the ml framework itself ie what is the set of",
    "start": "1028530",
    "end": "1034839"
  },
  {
    "text": "tooling that you will use when running that machine learning process let's talk",
    "start": "1034839",
    "end": "1040240"
  },
  {
    "text": "about training so first of all let's",
    "start": "1040240",
    "end": "1045370"
  },
  {
    "start": "1042000",
    "end": "1062000"
  },
  {
    "text": "talk about the framework tensorflow is a very popular framework that a lot of the developers and especially on kubernetes",
    "start": "1045370",
    "end": "1051670"
  },
  {
    "text": "I'd love to use so it's an open source library to develop and train animal models that was created by the Google",
    "start": "1051670",
    "end": "1058480"
  },
  {
    "text": "brain team originally and can pretty much run anywhere I think what a lot of",
    "start": "1058480",
    "end": "1063880"
  },
  {
    "start": "1062000",
    "end": "1074000"
  },
  {
    "text": "people don't know oh is that today 85% of all the tensorflow workloads that are running in",
    "start": "1063880",
    "end": "1071410"
  },
  {
    "text": "the cloud are actually running on AWS now not only that we actually took the",
    "start": "1071410",
    "end": "1079900"
  },
  {
    "start": "1074000",
    "end": "1154000"
  },
  {
    "text": "tensorflow implementation and customized it because what we have found and we'll",
    "start": "1079900",
    "end": "1085570"
  },
  {
    "text": "get there in a second but I'm giving you a heads up a lot of those large-scale training jobs especially in autonomous",
    "start": "1085570",
    "end": "1092260"
  },
  {
    "text": "vehicles require what we call distributed multi dpu multi node",
    "start": "1092260",
    "end": "1097960"
  },
  {
    "text": "training jobs now multi node training jobs means that you need to leverage a",
    "start": "1097960",
    "end": "1103750"
  },
  {
    "text": "lot of GPUs in order to increase your efficiency but as it happens the stock",
    "start": "1103750",
    "end": "1108850"
  },
  {
    "text": "tensorflow the one that comes pre-built does not scale as efficient as the",
    "start": "1108850",
    "end": "1114490"
  },
  {
    "text": "number of GPUs so if you scale your nodes to 256 GPUs for example you're",
    "start": "1114490",
    "end": "1120430"
  },
  {
    "text": "only going to get 65 percent efficiency increase rather than 100 with our tune",
    "start": "1120430",
    "end": "1126430"
  },
  {
    "text": "tensorflow algorithms however we managed to get it to an AWS optimized fraction",
    "start": "1126430",
    "end": "1132760"
  },
  {
    "text": "of a hundred percent efficiency scaling which means that effectively the more",
    "start": "1132760",
    "end": "1139180"
  },
  {
    "text": "GPUs you will add that's how much your efficiency will increase and that's very significant especially when it comes to",
    "start": "1139180",
    "end": "1145630"
  },
  {
    "text": "GPU instances which are not cheap and that allows you to basically bring out bring down the overall cost of your",
    "start": "1145630",
    "end": "1151990"
  },
  {
    "text": "training significantly now let's talk about one example for that and that is",
    "start": "1151990",
    "end": "1158050"
  },
  {
    "start": "1154000",
    "end": "1177000"
  },
  {
    "text": "the autonomous vehicle space so ever since we launched dks in June 2018 we have seen a lot of customers running a",
    "start": "1158050",
    "end": "1164440"
  },
  {
    "text": "lot of machine learning workloads high scale workloads running and some of them were from the autonomous vehicle space",
    "start": "1164440",
    "end": "1170950"
  },
  {
    "text": "so as we engage we started to understand what are the requirements that are driving this industry so it turns out",
    "start": "1170950",
    "end": "1178120"
  },
  {
    "start": "1177000",
    "end": "1247000"
  },
  {
    "text": "that the autonomous vehicle industry today is at a phase where they're trying to get and I'm sure all of you know that",
    "start": "1178120",
    "end": "1183570"
  },
  {
    "text": "to the highest level of automation possible and as standards go those",
    "start": "1183570",
    "end": "1189670"
  },
  {
    "text": "levels range between zero which means not automated at all and five which is pretty much the Nirvana that we are",
    "start": "1189670",
    "end": "1196540"
  },
  {
    "text": "looking to get which is we are fully automated and in terms of control monitoring and fallback this is all",
    "start": "1196540",
    "end": "1203539"
  },
  {
    "text": "being managed by the autonomous driving system rather than the driver of the human so typically those customers would",
    "start": "1203539",
    "end": "1210799"
  },
  {
    "text": "range between level three four if they're really advanced today and they're all experimenting and deploying",
    "start": "1210799",
    "end": "1218270"
  },
  {
    "text": "in production at the same time so if a certain company were able to reach sae level three for example that means they",
    "start": "1218270",
    "end": "1225620"
  },
  {
    "text": "will already have level four in their development lifecycle now as it happens with every new stage of autonomy the",
    "start": "1225620",
    "end": "1234559"
  },
  {
    "text": "amount of compute required is exponentially increasing which means that those customers incrementally",
    "start": "1234559",
    "end": "1240919"
  },
  {
    "text": "require more and more compute from both GPU and CPU perspective now let's talk",
    "start": "1240919",
    "end": "1249409"
  },
  {
    "start": "1247000",
    "end": "1391000"
  },
  {
    "text": "about some of the challenges that these customers are facing today so as I mentioned when it comes to training this",
    "start": "1249409",
    "end": "1256159"
  },
  {
    "text": "is distributed multi-gpu and often cases multi node training what are the",
    "start": "1256159",
    "end": "1261590"
  },
  {
    "text": "barriers or the challenges that they have told us that they have when trying to run those workloads so first off we",
    "start": "1261590",
    "end": "1268100"
  },
  {
    "text": "spoke about this machine learning practitioners they don't want to know V PC they don't want to know",
    "start": "1268100",
    "end": "1273559"
  },
  {
    "text": "EBS all they want is to set up their training jobs on their favorite tool run",
    "start": "1273559",
    "end": "1278870"
  },
  {
    "text": "tensor flow models or such and be done with it secondly large datasets on s3",
    "start": "1278870",
    "end": "1284650"
  },
  {
    "text": "they need to be copied somewhere and that somewhere needs to be some staging area in the cluster that the job can",
    "start": "1284650",
    "end": "1291590"
  },
  {
    "text": "then read in a very low latency high efficiency manner in order to run that multi node training next we have the",
    "start": "1291590",
    "end": "1300230"
  },
  {
    "text": "fact that the data needs to be shared across multiple nodes because again this is a distributed job so all the nodes",
    "start": "1300230",
    "end": "1306110"
  },
  {
    "text": "need to have access to the data there's also the thing about how do you",
    "start": "1306110",
    "end": "1311240"
  },
  {
    "text": "distribute the tensor flow algorithm that's not a trivial thing to do now tensor flow does have a built in",
    "start": "1311240",
    "end": "1318080"
  },
  {
    "text": "inherent API to parallelize and distribute the load but it's not as easy as you think",
    "start": "1318080",
    "end": "1323809"
  },
  {
    "text": "so people start coming off and figuring out hey is there a framework that can help us do some distributed workloads on",
    "start": "1323809",
    "end": "1331669"
  },
  {
    "text": "test though in a more easier fashion and we'll talk about that in a second and lastly capacity provisioning is not an",
    "start": "1331669",
    "end": "1340880"
  },
  {
    "text": "easy thing when it comes to those kind of things think about this you need I don't know 20 P 316 excels and not only",
    "start": "1340880",
    "end": "1350960"
  },
  {
    "text": "you need that that much you need them running in a single placement group because you need low latency and high",
    "start": "1350960",
    "end": "1356150"
  },
  {
    "text": "performance network because typically what happens in a distributed job there's a lot of parameter exchanges",
    "start": "1356150",
    "end": "1361760"
  },
  {
    "text": "between those nodes and so the efficiency of the job can easily be",
    "start": "1361760",
    "end": "1366950"
  },
  {
    "text": "bottlenecks if the network performance is not meeting the needs of the internal computing so how do you provision such",
    "start": "1366950",
    "end": "1374660"
  },
  {
    "text": "capacity well you have AWS but then how do you maintain that capacity and can",
    "start": "1374660",
    "end": "1380630"
  },
  {
    "text": "traditional auto scalars really hold on to that capacity in a way that's going to work well for GPU workloads and ml",
    "start": "1380630",
    "end": "1387770"
  },
  {
    "text": "workloads and we'll talk about that very very soon so one by one in terms of ml",
    "start": "1387770",
    "end": "1395150"
  },
  {
    "start": "1391000",
    "end": "1413000"
  },
  {
    "text": "practitioners and the abstraction we already discussed this we have cue flow on AWS the setup script will just",
    "start": "1395150",
    "end": "1402410"
  },
  {
    "text": "completely abstract the whole thing you will basically follow a simple list of commands run it and you will get a in",
    "start": "1402410",
    "end": "1408470"
  },
  {
    "text": "standard endpoint of queue flow ready to go on the large data sets that does",
    "start": "1408470",
    "end": "1416450"
  },
  {
    "start": "1413000",
    "end": "1548000"
  },
  {
    "text": "require copying but here's the good news first off we now have a driver for for",
    "start": "1416450",
    "end": "1422450"
  },
  {
    "text": "example fsx luster how many of you know what fsx lustre is in a show of hands so",
    "start": "1422450",
    "end": "1429350"
  },
  {
    "text": "fsx luster is a distributed file system which is meant to be high-performance",
    "start": "1429350",
    "end": "1436520"
  },
  {
    "text": "but still shared across multiple nodes so it's a read many a read write many",
    "start": "1436520",
    "end": "1444190"
  },
  {
    "text": "notion that a lot of nodes and a lot of processes a lot of pods can actually",
    "start": "1444190",
    "end": "1449510"
  },
  {
    "text": "access the same file system and typically provide millions of AI ops to",
    "start": "1449510",
    "end": "1455750"
  },
  {
    "text": "the typical average workload so with that file filesystem a lot of these",
    "start": "1455750",
    "end": "1461060"
  },
  {
    "text": "workloads have started to leverage significantly fsx lustre as their go-to platform to have that stage",
    "start": "1461060",
    "end": "1468470"
  },
  {
    "text": "data so the process only copies the data once to an fsx lustre and not only that",
    "start": "1468470",
    "end": "1474560"
  },
  {
    "text": "it can actually create that and provision that for you and it can do so dynamically and dynamically meaning that",
    "start": "1474560",
    "end": "1481610"
  },
  {
    "text": "by using the API it will actually generate a persistent volume in a persistent volume claim that you can",
    "start": "1481610",
    "end": "1487700"
  },
  {
    "text": "then use within your Cuba native code to access that file system or you can",
    "start": "1487700",
    "end": "1493760"
  },
  {
    "text": "create it statically by just creating the file system first and then handing over the file system ID to the",
    "start": "1493760",
    "end": "1500510"
  },
  {
    "text": "underlying code to be able to leverage but in either way NFS X luster has a",
    "start": "1500510",
    "end": "1506780"
  },
  {
    "text": "very interesting property that it can actually shadow an s3 bucket so you",
    "start": "1506780",
    "end": "1512630"
  },
  {
    "text": "don't actually need to copy any of the data yourself what you need to do is you need to have the customer or yourself as",
    "start": "1512630",
    "end": "1519560"
  },
  {
    "text": "a practitioner put all the staging data in s3 which it already is and then use",
    "start": "1519560",
    "end": "1525410"
  },
  {
    "text": "that as a path for the new fsx lustre filesystem to kind of cache all the data",
    "start": "1525410",
    "end": "1532640"
  },
  {
    "text": "from that location so all the staging of the data is actually done behind the",
    "start": "1532640",
    "end": "1537680"
  },
  {
    "text": "scenes by fsx lustre itself and by giving you the integrated CSI driver that will also get provisioned",
    "start": "1537680",
    "end": "1544400"
  },
  {
    "text": "seamlessly for you through kubernetes as far as the distributed training there is",
    "start": "1544400",
    "end": "1551300"
  },
  {
    "text": "a framework called hor Avadh that framework was originated by uber and was",
    "start": "1551300",
    "end": "1556310"
  },
  {
    "text": "open sourced we're finding that framework to be extremely popular across our customers that are leveraging",
    "start": "1556310",
    "end": "1562160"
  },
  {
    "text": "machine learning at that scale and that's actually accessible to you today through our cue flow itself so it does",
    "start": "1562160",
    "end": "1570830"
  },
  {
    "text": "nothing more than actually simplify the process of distributing the job in the",
    "start": "1570830",
    "end": "1576710"
  },
  {
    "text": "tensor flow across multiple GPUs or across multiple nodes or both and",
    "start": "1576710",
    "end": "1582760"
  },
  {
    "start": "1582000",
    "end": "1675000"
  },
  {
    "text": "finally from a capacity provisioning we introduced updates to a project called",
    "start": "1582760",
    "end": "1589010"
  },
  {
    "text": "escalator which is a project that's providing you with auto scaling capabilities that are more tuned to Xin",
    "start": "1589010",
    "end": "1596870"
  },
  {
    "text": "learning and batch workloads then the traditional kubernetes autoscaler or not' autoscale that you",
    "start": "1596870",
    "end": "1601899"
  },
  {
    "text": "all known well so at that point I want to introduce you to Mike Mike root who I",
    "start": "1601899",
    "end": "1608649"
  },
  {
    "text": "introduced in the beginning so he's gonna walk you over escalator and some of the improvements we made there and",
    "start": "1608649",
    "end": "1614289"
  },
  {
    "text": "show you a demo of how that actually works today with the cluster",
    "start": "1614289",
    "end": "1619378"
  },
  {
    "text": "[Applause]",
    "start": "1621250",
    "end": "1627380"
  },
  {
    "text": "okay",
    "start": "1669530",
    "end": "1672530"
  },
  {
    "text": "all right hi I would like to walk you through a demo of escalator so escalator",
    "start": "1674920",
    "end": "1681200"
  },
  {
    "text": "is a cluster autoscaler that was built by Atlassian it's an alternative to the",
    "start": "1681200",
    "end": "1686840"
  },
  {
    "text": "kubernetes cluster autoscaler and we're really excited about it because it has the potential to really help with",
    "start": "1686840",
    "end": "1694490"
  },
  {
    "text": "machine learning workloads it was designed to be a batch autoscaler and",
    "start": "1694490",
    "end": "1700070"
  },
  {
    "text": "and to try not to move pods around it's designed to grow your cluster as quickly as possible and try to keep it stable",
    "start": "1700070",
    "end": "1706880"
  },
  {
    "text": "while your workload runs to completion the toothed features i'd like to demo for you today one is already released in",
    "start": "1706880",
    "end": "1713240"
  },
  {
    "text": "upstream and one is coming soon the first is integration with AWS fleet AWS",
    "start": "1713240",
    "end": "1719210"
  },
  {
    "text": "fleet is an API that can be used to acquire capacity very quickly and and is",
    "start": "1719210",
    "end": "1726080"
  },
  {
    "text": "particularly useful when you're using very popular instance classes particularly like p3 classes which are",
    "start": "1726080",
    "end": "1733610"
  },
  {
    "text": "the big GPU instances that a lot of people use for training before we get started let me just let me just show you",
    "start": "1733610",
    "end": "1739790"
  },
  {
    "text": "a little bit about what we're going to be working with here it's gonna be a lot of black text on this or a lot of white",
    "start": "1739790",
    "end": "1744950"
  },
  {
    "text": "text on the screen the ants of AWS console I've got a basic eks cluster and",
    "start": "1744950",
    "end": "1750290"
  },
  {
    "text": "I've got three node groups in this cluster one node group is completely uninteresting that's our t3 large that's",
    "start": "1750290",
    "end": "1755960"
  },
  {
    "text": "just going to be running escalator for us I have a c5 x-large node group which",
    "start": "1755960",
    "end": "1762050"
  },
  {
    "text": "is going to be used to run a CPU intensive job and I have a p38 X large",
    "start": "1762050",
    "end": "1768860"
  },
  {
    "text": "node group that is going to be run to you going to be used to run a GPU intensive job I started each node group",
    "start": "1768860",
    "end": "1775700"
  },
  {
    "text": "out with a single instance this is not because escalator can't start from zero it's more that when escalator starts a",
    "start": "1775700",
    "end": "1783290"
  },
  {
    "text": "node group from zero it first much must launch one instance wait for it to warm up and then scale the cluster out so",
    "start": "1783290",
    "end": "1790100"
  },
  {
    "text": "it's just gonna be really boring if I if I make you wait through all of that so",
    "start": "1790100",
    "end": "1795680"
  },
  {
    "text": "let's take a look at our demo so we have",
    "start": "1795680",
    "end": "1800050"
  },
  {
    "start": "1802000",
    "end": "1832000"
  },
  {
    "text": "we have just a basic a degree a basic qks cluster a tourist notice our CNI but the the",
    "start": "1802270",
    "end": "1808700"
  },
  {
    "text": "other interesting part here is the Nvidia device plug-in demon set what this demon set does is it runs on it can",
    "start": "1808700",
    "end": "1815420"
  },
  {
    "text": "run on any instance type but if you have GPU accelerated instances it will tag",
    "start": "1815420",
    "end": "1821660"
  },
  {
    "text": "your instances with GPU capacity so that you can schedule your GPUs as resources",
    "start": "1821660",
    "end": "1827300"
  },
  {
    "text": "just like CPU so I'm going to run that everywhere on my cluster let's take a",
    "start": "1827300",
    "end": "1832730"
  },
  {
    "start": "1832000",
    "end": "1858000"
  },
  {
    "text": "quick look at what a escalator config looks like so I've got two auto scaling groups and these model the auto scaling",
    "start": "1832730",
    "end": "1838370"
  },
  {
    "text": "groups I have in the console one has a upper limit of 15 nodes that's our c5",
    "start": "1838370",
    "end": "1843860"
  },
  {
    "text": "group one has an upper limit of two nodes that's our p3 group I'm not going",
    "start": "1843860",
    "end": "1849200"
  },
  {
    "text": "to go super crazy on acquiring a ton at p3 capacity just because these are really popular instances and I don't",
    "start": "1849200",
    "end": "1855050"
  },
  {
    "text": "want to limit that for anybody so let's let's deploy this then there is we're",
    "start": "1855050",
    "end": "1862010"
  },
  {
    "start": "1858000",
    "end": "1889000"
  },
  {
    "text": "gonna take a look at this this is just the full version so I'm not going to step through that so let's deploy",
    "start": "1862010",
    "end": "1869750"
  },
  {
    "text": "escalator and we'll see that escalator",
    "start": "1869750",
    "end": "1875900"
  },
  {
    "text": "has launched on our t3 instance and",
    "start": "1875900",
    "end": "1882200"
  },
  {
    "text": "let's just take a look at the logs we've got here yeah there we go so escalator",
    "start": "1882200",
    "end": "1890510"
  },
  {
    "start": "1889000",
    "end": "1915000"
  },
  {
    "text": "has because we've configured it for a node groups you can see that it knows all about them it knows our upper and",
    "start": "1890510",
    "end": "1896090"
  },
  {
    "text": "lower bounds and because the cluster is in steady state there's nothing to be scheduled so no no demands on CPU or",
    "start": "1896090",
    "end": "1904460"
  },
  {
    "text": "memory and this is going to pull your auto-scaling groups about I've got it configured for once every 30 seconds but",
    "start": "1904460",
    "end": "1911090"
  },
  {
    "text": "by default you can change by default at 60 seconds and you can change that so let's take a let's let's deploy a",
    "start": "1911090",
    "end": "1917900"
  },
  {
    "start": "1915000",
    "end": "1921000"
  },
  {
    "text": "workload on here I've got a job that's mostly designed to just kind of sit and",
    "start": "1917900",
    "end": "1923480"
  },
  {
    "text": "pin down some cores just to just to give our cluster a time to to give our cluster time to scale the important",
    "start": "1923480",
    "end": "1930200"
  },
  {
    "text": "thing to note about this is it requires one CPU and a gig of ram that's probably a little excessive but it just gives us",
    "start": "1930200",
    "end": "1937040"
  },
  {
    "text": "something to to show on our cluster here so I'm going apply this and that job will create a",
    "start": "1937040",
    "end": "1951769"
  },
  {
    "text": "bunch of pods and those pods are going to sit in pending state and if we look back at escalator you can see that it",
    "start": "1951769",
    "end": "1957769"
  },
  {
    "start": "1953000",
    "end": "1968000"
  },
  {
    "text": "has it has detected that that there is a lot of work coming into the cluster and",
    "start": "1957769",
    "end": "1965210"
  },
  {
    "text": "that it should be scaling up the cluster so if we take a look at our AWS console you'll see that it is acquired and it",
    "start": "1965210",
    "end": "1972710"
  },
  {
    "text": "already has running 15 new nodes it's done this using the fleet API the nice",
    "start": "1972710",
    "end": "1978109"
  },
  {
    "text": "thing about the fleet API is when you request a set of nodes from it the way escalator uses its API they will either",
    "start": "1978109",
    "end": "1984559"
  },
  {
    "text": "all be immediately fulfilled to you or you will be not denied those nodes so there's no more dial up the auto scaling",
    "start": "1984559",
    "end": "1991190"
  },
  {
    "text": "group let capacity trickle in you're definitely going to get it if that API call succeeds and if it does an",
    "start": "1991190",
    "end": "1997759"
  },
  {
    "text": "escalator will continue to retry behind the scenes at its normal polling interval so those are all coming online",
    "start": "1997759",
    "end": "2003519"
  },
  {
    "text": "in my cluster we should be able to see see those nodes and yeah so those are",
    "start": "2003519",
    "end": "2016539"
  },
  {
    "text": "gonna those are kind of going to kind of trickle or those are gonna kind of come online and join the cluster they've just",
    "start": "2016539",
    "end": "2021849"
  },
  {
    "text": "booting up and doing the normal bootstrapping work letting the CNI come online so well I think that finish those",
    "start": "2021849",
    "end": "2027039"
  },
  {
    "text": "are gonna retire our work pretty quickly let's take a look then wow that's going",
    "start": "2027039",
    "end": "2032139"
  },
  {
    "text": "at a GPU job so this is the same job we've got all it does is pin down a a",
    "start": "2032139",
    "end": "2039429"
  },
  {
    "text": "core but it also now has limits around GPUs each one of these jobs is going to",
    "start": "2039429",
    "end": "2045609"
  },
  {
    "text": "try to hold down a single GPU so I've started my cluster out with a p38 x-large which has four GPU cores and I'm",
    "start": "2045609",
    "end": "2053260"
  },
  {
    "text": "going to try to run two of these at first",
    "start": "2053260",
    "end": "2057059"
  },
  {
    "text": "and so those pods are going to get running and you can see though you'll",
    "start": "2060210",
    "end": "2067210"
  },
  {
    "text": "you'll see them get scheduled on the",
    "start": "2067210",
    "end": "2071279"
  },
  {
    "text": "existing GPU and then if we take a look at our other Pods though we should see that our our PI job got done and",
    "start": "2072950",
    "end": "2082148"
  },
  {
    "text": "escalator will begin to scale down the auto scaling group past that the first",
    "start": "2082149",
    "end": "2087740"
  },
  {
    "start": "2086000",
    "end": "2139000"
  },
  {
    "text": "thing it's going to do is it's going to taint the nodes to allow the workloads to finish and drain off the nodes and",
    "start": "2087740",
    "end": "2093050"
  },
  {
    "text": "then it will batch terminate them I'm not gonna make you sit up here and wait for it but you'll basically see if we",
    "start": "2093050",
    "end": "2099290"
  },
  {
    "text": "were to wait for it you'd see all of those 15 running nodes now that they have no pending pods all the pods that",
    "start": "2099290",
    "end": "2105589"
  },
  {
    "text": "were scheduled on to them are completed we'll just be terminated and your auto scaling group will go back to the",
    "start": "2105589",
    "end": "2111470"
  },
  {
    "text": "minimum capacity bounds there we go and that's those are the two changes so",
    "start": "2111470",
    "end": "2117140"
  },
  {
    "text": "we've got GPU based cluster auto scaling which will be committed to the upstream",
    "start": "2117140",
    "end": "2123020"
  },
  {
    "text": "project hopefully pretty soon within the next week and we've got the fleet",
    "start": "2123020",
    "end": "2128030"
  },
  {
    "text": "instant capacity acquisition which is already in the project and should be",
    "start": "2128030",
    "end": "2133490"
  },
  {
    "text": "released very soon and then turn it back to you you need so let's talk about",
    "start": "2133490",
    "end": "2142130"
  },
  {
    "start": "2139000",
    "end": "2212000"
  },
  {
    "text": "inference so we talked about the fact that we require large-scale jobs so on",
    "start": "2142130",
    "end": "2150319"
  },
  {
    "text": "the training side that boils down to distributed training jobs multi-seat multi-gpu multi node what does that boil",
    "start": "2150319",
    "end": "2156890"
  },
  {
    "text": "down into when it comes to workloads or inference workloads so in autonomous vehicles specifically there is no real",
    "start": "2156890",
    "end": "2164089"
  },
  {
    "text": "inference taking place in the cloud the inference will eventually take place in the car but in order to build or",
    "start": "2164089",
    "end": "2171470"
  },
  {
    "text": "simulate an environment which is as close as possible to the landscape that",
    "start": "2171470",
    "end": "2176540"
  },
  {
    "text": "the sensors in the car are seeing there needs to be a lot of simulations going",
    "start": "2176540",
    "end": "2182060"
  },
  {
    "text": "on continuously testing out the models in like simulated conditions under under what we call like an artificially",
    "start": "2182060",
    "end": "2190130"
  },
  {
    "text": "generated vision environment which is as close as what we will get to what the",
    "start": "2190130",
    "end": "2195980"
  },
  {
    "text": "car will actually seen on the road so those are what we call the large-scale simulation workloads and I want to give",
    "start": "2195980",
    "end": "2202790"
  },
  {
    "text": "you a little bit of sense of like what that scale looks like and and those all cpu-based work those those are not",
    "start": "2202790",
    "end": "2208779"
  },
  {
    "text": "requiring GPUs but they are running at a very large scale so I want to talk to you about koalas we always used that",
    "start": "2208779",
    "end": "2217059"
  },
  {
    "start": "2212000",
    "end": "2320000"
  },
  {
    "text": "example because koala was a species that started to decline back in the 70s",
    "start": "2217059",
    "end": "2222910"
  },
  {
    "text": "so it's declined about 17% and the new University in Australia was very worried",
    "start": "2222910",
    "end": "2228219"
  },
  {
    "text": "about how we can actually impact that survival rate and what they done is they",
    "start": "2228219",
    "end": "2234130"
  },
  {
    "text": "actually conducted a research that examines first few factors of how the",
    "start": "2234130",
    "end": "2240069"
  },
  {
    "text": "habitat barriers and the climate conditions can actually affect what we call the DNA mutation or the evolution",
    "start": "2240069",
    "end": "2248619"
  },
  {
    "text": "and the genetic diversity of that species so in order to run that experiment and that was just a few years",
    "start": "2248619",
    "end": "2254410"
  },
  {
    "text": "ago they had to sequence I think about three billion base pairs of their gene",
    "start": "2254410",
    "end": "2260619"
  },
  {
    "text": "genome and that requires a lot of compute so they used AWS and ran the whole thing on spot instances and so",
    "start": "2260619",
    "end": "2269679"
  },
  {
    "text": "that thing was running on about three million cores overall averaging in about",
    "start": "2269679",
    "end": "2276189"
  },
  {
    "text": "five hundred to a thousand cores in parallel in each step of the genome",
    "start": "2276189",
    "end": "2282400"
  },
  {
    "text": "sequencing so that was a pretty amazing and and you know ambitious project at the time and now I want to show you what",
    "start": "2282400",
    "end": "2289089"
  },
  {
    "text": "the typical AV simulation workloads would require you know in terms of",
    "start": "2289089",
    "end": "2294099"
  },
  {
    "text": "compute compared to koala genomeics so for those of you with a 20/20 vision",
    "start": "2294099",
    "end": "2301539"
  },
  {
    "text": "there isn't short yellow line somewhere on the lower bar next to the word koala",
    "start": "2301539",
    "end": "2308319"
  },
  {
    "text": "genomics which you can barely see because that is the scale that our customers are now starting to run in",
    "start": "2308319",
    "end": "2314979"
  },
  {
    "text": "autonomous vehicles and that is the amount of compute and the concurrent CPUs that they would require and",
    "start": "2314979",
    "end": "2320789"
  },
  {
    "start": "2320000",
    "end": "2396000"
  },
  {
    "text": "similarly on the total requirement for the job that's also running at a pretty",
    "start": "2320789",
    "end": "2327579"
  },
  {
    "text": "different scale than what we seen with that previous example that I showed now I'm talking about autonomous vehicles",
    "start": "2327579",
    "end": "2333999"
  },
  {
    "text": "but this is starting to emerge in many many other industries so if you look at pharma pharmaceutical companies",
    "start": "2333999",
    "end": "2340330"
  },
  {
    "text": "robotics financial institutions so a lot of those industries and of course",
    "start": "2340330",
    "end": "2346240"
  },
  {
    "text": "manufacturing in robotics a lot of those industries are now starting to leverage machine learning at scales in order to",
    "start": "2346240",
    "end": "2352450"
  },
  {
    "text": "solve a lot of those industry specific problems that they have so tana most vehicles is actually one of the early",
    "start": "2352450",
    "end": "2358180"
  },
  {
    "text": "ones that have reached those kind of scales but this is definitely not the last ones we are working with a lot of",
    "start": "2358180",
    "end": "2363340"
  },
  {
    "text": "those industries to get them ramped up onto pretty much a lot of similar and",
    "start": "2363340",
    "end": "2368440"
  },
  {
    "text": "common challenges and actually involving a lot of the common models that these",
    "start": "2368440",
    "end": "2374280"
  },
  {
    "text": "deep learning I it's important to say it's not just traditional machine learning those are deep learning",
    "start": "2374280",
    "end": "2380170"
  },
  {
    "text": "algorithms which usually involve what we call convolutional Network cnn's or dns",
    "start": "2380170",
    "end": "2386430"
  },
  {
    "text": "and that that's the reason why they are more complicated require more computing",
    "start": "2386430",
    "end": "2391660"
  },
  {
    "text": "power and require those scales that we have just seen so just to give you a",
    "start": "2391660",
    "end": "2397990"
  },
  {
    "start": "2396000",
    "end": "2457000"
  },
  {
    "text": "sense if I'm looking at here these are the top 10 supercomputers on the planet",
    "start": "2397990",
    "end": "2403270"
  },
  {
    "text": "as of today and we're trying to measure that with what we call the amount of peda flops the floating-point operations",
    "start": "2403270",
    "end": "2410350"
  },
  {
    "text": "that they can process so on the bottom of that we're at about 20 or 27 pedo",
    "start": "2410350",
    "end": "2415840"
  },
  {
    "text": "flops so just to give you a sense a single p 3d and instance today at AWS",
    "start": "2415840",
    "end": "2421660"
  },
  {
    "text": "can produce one petaflop so if you take a network or a fleet of",
    "start": "2421660",
    "end": "2428710"
  },
  {
    "text": "20 p 3d n instances you have actually done or achieved what we call",
    "start": "2428710",
    "end": "2434860"
  },
  {
    "text": "supercomputer scale in terms of processing and this is this is basically where we want to be we want to be able",
    "start": "2434860",
    "end": "2441310"
  },
  {
    "text": "to provide our v customers and not just AV you can replace a V with any other",
    "start": "2441310",
    "end": "2446530"
  },
  {
    "text": "industry a supercomputer scale like one of the depth or top 10 supercomputers",
    "start": "2446530",
    "end": "2453490"
  },
  {
    "text": "that are available today for those kind of projects so going back to the",
    "start": "2453490",
    "end": "2460390"
  },
  {
    "start": "2457000",
    "end": "2525000"
  },
  {
    "text": "specifics there are a lot of challenges involved today with setting up containers for ml so how does containers",
    "start": "2460390",
    "end": "2467380"
  },
  {
    "text": "fit into all that story so think about this if you're a practitioner and you need to run in tensorflow on",
    "start": "2467380",
    "end": "2474010"
  },
  {
    "text": "of our instances how would you go about do that are you going to install your own Python are you going to customize",
    "start": "2474010",
    "end": "2479830"
  },
  {
    "text": "your tensorflow version so typically up until recently we would provide what we",
    "start": "2479830",
    "end": "2485620"
  },
  {
    "text": "call the deep learning ami which is our machine images you would customize that ami install whatever frameworks you want",
    "start": "2485620",
    "end": "2492850"
  },
  {
    "text": "on top of it that could be a little bit tricky and therefore a little bit complex to some of the data scientists",
    "start": "2492850",
    "end": "2500290"
  },
  {
    "text": "that have kind of told us that they don't want to be in the business of customizing Amazon ami is it's not there",
    "start": "2500290",
    "end": "2505960"
  },
  {
    "text": "for DES so what we have done is we actually launched what we call deep learning containers in March so deep",
    "start": "2505960",
    "end": "2513340"
  },
  {
    "text": "learning containers are nothing more than a predefined set of containers that are coming pre bundled with the",
    "start": "2513340",
    "end": "2520020"
  },
  {
    "text": "frameworks that you require in order to run your machine learning workloads so",
    "start": "2520020",
    "end": "2525730"
  },
  {
    "start": "2525000",
    "end": "2562000"
  },
  {
    "text": "basically think a bit of it as a permutation of running your favorite",
    "start": "2525730",
    "end": "2530830"
  },
  {
    "text": "framework like MX net and tensorflow along with some characteristics that are",
    "start": "2530830",
    "end": "2536950"
  },
  {
    "text": "more tuned to training or for inference depending on what you want to run more tuned to GPU vs. CPU and also with your",
    "start": "2536950",
    "end": "2545140"
  },
  {
    "text": "favorite Python version whether that's two point seven or three point six so those permutations are distributed as",
    "start": "2545140",
    "end": "2552280"
  },
  {
    "text": "specific containers that you can just take and inherit your base container",
    "start": "2552280",
    "end": "2557470"
  },
  {
    "text": "from and then add your custom code in order to run that so that's available to",
    "start": "2557470",
    "end": "2563950"
  },
  {
    "start": "2562000",
    "end": "2633000"
  },
  {
    "text": "you today through the marketplace and an ECR our container registry so pretty",
    "start": "2563950",
    "end": "2570100"
  },
  {
    "text": "much that's it for me to call outs one is if you want to get started with machine learning on AWS this is kind of",
    "start": "2570100",
    "end": "2577120"
  },
  {
    "text": "your I would say the simple getting started experience we also have blogs that are more complicated complicated",
    "start": "2577120",
    "end": "2584680"
  },
  {
    "text": "for the more advanced users but I would go if I would get it started with this experience I would get to that link",
    "start": "2584680",
    "end": "2590470"
  },
  {
    "text": "first check out the documentation try out all the startup scripts and and make",
    "start": "2590470",
    "end": "2597490"
  },
  {
    "text": "myself comfortable with the environment secondly I am very well interested if",
    "start": "2597490",
    "end": "2602680"
  },
  {
    "text": "any of you is running machine learning workloads today whether it's similar to the way I just described on kubernetes or",
    "start": "2602680",
    "end": "2609610"
  },
  {
    "text": "using some other framework whether it's Amazon or another vendor any way you",
    "start": "2609610",
    "end": "2615070"
  },
  {
    "text": "want I'm very very interested to talk to you and learn from you on how you run today and what are the challenges that",
    "start": "2615070",
    "end": "2621040"
  },
  {
    "text": "we can help solve for you in the future so I'll be around here until the end of the day if you guys want you can come",
    "start": "2621040",
    "end": "2626770"
  },
  {
    "text": "find me thank you so much [Applause]",
    "start": "2626770",
    "end": "2635469"
  }
]
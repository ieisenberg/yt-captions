[
  {
    "text": "good morning again of my name is Chandra and the partner solution architect Adobe",
    "start": "1580",
    "end": "8490"
  },
  {
    "text": "is your room host today thanks for joining us today hope you're enjoying",
    "start": "8490",
    "end": "14519"
  },
  {
    "text": "your summit on dater some housekeeping items we have an exit door a different",
    "start": "14519",
    "end": "21990"
  },
  {
    "text": "and at the back restrooms are out to your right when you exit out of the door",
    "start": "21990",
    "end": "27660"
  },
  {
    "text": "so I we thrive on feedback at it Amazon",
    "start": "27660",
    "end": "33750"
  },
  {
    "text": "so please take a moment to fill out the survey once the session is done so",
    "start": "33750",
    "end": "39870"
  },
  {
    "text": "without further ado I will hand it over to Sanjaya paddy he's going to talk",
    "start": "39870",
    "end": "45090"
  },
  {
    "text": "about and machine learning research thank you",
    "start": "45090",
    "end": "52820"
  },
  {
    "text": "so thank you so much for joining so I'll talk about a couple of things - later -",
    "start": "62010",
    "end": "67150"
  },
  {
    "text": "AI and machine learning I'm really thankful to Cornelia and least to join",
    "start": "67150",
    "end": "74110"
  },
  {
    "text": "us they will talk about how they apply machine learning or AI in for example",
    "start": "74110",
    "end": "82000"
  },
  {
    "text": "using a topic modeling for detection of hurricanes or detection of something where you can take timely action if you",
    "start": "82000",
    "end": "89890"
  },
  {
    "text": "know how to train it early enough right so some of the studies will talk about that just a brief recap if you talk to",
    "start": "89890",
    "end": "98080"
  },
  {
    "text": "ten people or hundred people in a given audience what is AI you'll get 100",
    "start": "98080",
    "end": "103540"
  },
  {
    "text": "different answers so in general we sometimes mix between machine learning and AI and sometimes",
    "start": "103540",
    "end": "110380"
  },
  {
    "text": "deep learning but these are three different distant subjects right so for the sake of discussion today we'll talk",
    "start": "110380",
    "end": "116410"
  },
  {
    "text": "about artificial intelligence is a system or a service that that can",
    "start": "116410",
    "end": "121420"
  },
  {
    "text": "perform tasks that usually requires human human intelligence there are a",
    "start": "121420",
    "end": "127119"
  },
  {
    "text": "couple of articles and web page you can find it here one can one can they have tutorials and how to how to train your",
    "start": "127119",
    "end": "133930"
  },
  {
    "text": "own models like how to do about that it's really a old system right AI was",
    "start": "133930",
    "end": "142180"
  },
  {
    "text": "started in 1950s there were biological degenerative models were there so it's",
    "start": "142180",
    "end": "147730"
  },
  {
    "text": "nothing very new for a long time it became for a long time in 1950s it",
    "start": "147730",
    "end": "153250"
  },
  {
    "text": "started but it was not didn't go too far until until in 1990s when machine",
    "start": "153250",
    "end": "158980"
  },
  {
    "text": "learning came where it started becoming more useful for example all you have now",
    "start": "158980",
    "end": "164170"
  },
  {
    "text": "all of our spam filters happens by machine learning in those days imagine",
    "start": "164170",
    "end": "170080"
  },
  {
    "text": "if you are searching for a cup I'm just making up here right you've as a new search for a cup in your search engine",
    "start": "170080",
    "end": "175980"
  },
  {
    "text": "you will not like the cup the cup you like is in page 42 you will not you will",
    "start": "175980",
    "end": "182950"
  },
  {
    "text": "not like it right so which means one need to order it based on your",
    "start": "182950",
    "end": "188920"
  },
  {
    "text": "preference and and preference can be only obtained based on what you",
    "start": "188920",
    "end": "194770"
  },
  {
    "text": "than what he looked at it and that became very interested and that's Amazon started working on that on its own way",
    "start": "194770",
    "end": "201610"
  },
  {
    "text": "but that started taking traction in 1990s they were also trying to for example networks was trying to predict",
    "start": "201610",
    "end": "208660"
  },
  {
    "text": "which movies you will like for example right and they were trying to give a million dollars award for even if you",
    "start": "208660",
    "end": "216340"
  },
  {
    "text": "can predict let's say ten percent of a given recommendation system so it slowly",
    "start": "216340",
    "end": "224800"
  },
  {
    "text": "started traction nineteen eight eight is still deep learning started coming up and one of the most important of deep",
    "start": "224800",
    "end": "232270"
  },
  {
    "text": "learning was because of GPUs on accelerated processing just just an",
    "start": "232270",
    "end": "238360"
  },
  {
    "text": "example is CPU will have tens of course right tens to hundreds but a GPU will",
    "start": "238360",
    "end": "244810"
  },
  {
    "text": "have roughly a thousands of course built inside so people started using deep learning and then convolution during",
    "start": "244810",
    "end": "251260"
  },
  {
    "text": "that came which can distinguished features and that became extremely vital so in this particular study we generally",
    "start": "251260",
    "end": "259600"
  },
  {
    "text": "AI and machine learning is classified typically in in kind of three categories",
    "start": "259600",
    "end": "265180"
  },
  {
    "text": "there are always a variation a combination of that right so one is what we call supervised learning and bulk of",
    "start": "265180",
    "end": "273100"
  },
  {
    "text": "the work we do is based on supervised learning then then there are something",
    "start": "273100",
    "end": "278350"
  },
  {
    "text": "called unsupervised learning you're very we are defining a cluster and methyl groups and within a group you find in",
    "start": "278350",
    "end": "284710"
  },
  {
    "text": "people of common interest so the third one is reinforcement learning so",
    "start": "284710",
    "end": "290740"
  },
  {
    "text": "reinforcement learning is reward based system basically if you learn something you will take action right so that's",
    "start": "290740",
    "end": "296560"
  },
  {
    "text": "reinforcement learning and best base bulk of the learning mechanism is really",
    "start": "296560",
    "end": "301690"
  },
  {
    "text": "a combination of all the three so we",
    "start": "301690",
    "end": "306790"
  },
  {
    "text": "started collaborating on specially on research side with with many folks in",
    "start": "306790",
    "end": "312100"
  },
  {
    "text": "there in the universities but also with National Science Foundation recently for example you go we started working with",
    "start": "312100",
    "end": "319300"
  },
  {
    "text": "NSF on some of the projects on under the umbrella of what we call big data where",
    "start": "319300",
    "end": "325120"
  },
  {
    "text": "NSF invested roughly about 20 20 25 million dollars in a solar station where roughly you know so many of the",
    "start": "325120",
    "end": "333099"
  },
  {
    "text": "studies they started researchers who got the award are started doing it I look at it detecting financial market",
    "start": "333099",
    "end": "339129"
  },
  {
    "text": "manipulation so I'll talk a little bit about that particular study but also domain adaption for example if you can",
    "start": "339129",
    "end": "345430"
  },
  {
    "text": "predict a hurricane in advance and even half an hour before you can take some",
    "start": "345430",
    "end": "350650"
  },
  {
    "text": "disaster management or you can talk to Red Cross to take some action even if you're 30 minutes before you predict it",
    "start": "350650",
    "end": "357069"
  },
  {
    "text": "so some of the example Diana will give on that particular study so today so",
    "start": "357069",
    "end": "362110"
  },
  {
    "text": "I'll touch base on what they did what we called disaster management but there are many awards people did in research and",
    "start": "362110",
    "end": "368590"
  },
  {
    "text": "they all are working on AWS on that so the particulars topic of the study is",
    "start": "368590",
    "end": "374289"
  },
  {
    "text": "really interesting it's called the big data for the for the for the market",
    "start": "374289",
    "end": "380020"
  },
  {
    "text": "manipulation this was done by University of Michigan in collaboration with us and National Science Foundation so what is",
    "start": "380020",
    "end": "385719"
  },
  {
    "text": "the study is the study is is is really to find a mechanism to detect or",
    "start": "385719",
    "end": "391590"
  },
  {
    "text": "mitigate market manipulation so what that mean imagine the stock market right",
    "start": "391590",
    "end": "398740"
  },
  {
    "text": "in a stock market there are billions of transition happens per day",
    "start": "398740",
    "end": "404159"
  },
  {
    "text": "imagine you start a company let's call it a company a and you say I want to bid",
    "start": "404159",
    "end": "412409"
  },
  {
    "text": "$400 for the stock but you have no interest in buying or selling that but",
    "start": "412409",
    "end": "418539"
  },
  {
    "text": "you're really doing a massive amount of requests to buy or sell that particular",
    "start": "418539",
    "end": "423610"
  },
  {
    "text": "thing and given many things are interconnected the prices will decrease",
    "start": "423610",
    "end": "428830"
  },
  {
    "text": "and that's a process called spoofing and it's illegal",
    "start": "428830",
    "end": "435300"
  },
  {
    "text": "how do stock exchange or in the country FINRA will monitor whether you're doing",
    "start": "435569",
    "end": "442330"
  },
  {
    "text": "it maybe you're really selling it and they just changed your mind right so spoofing is a mechanism to manipulate",
    "start": "442330",
    "end": "450219"
  },
  {
    "text": "the market such that you can buy our or you can sell it right and some machine",
    "start": "450219",
    "end": "457719"
  },
  {
    "text": "learning is a fantastic application where you train it on it trading events such that you should be",
    "start": "457719",
    "end": "464259"
  },
  {
    "text": "able to do that so this is this particular study versus got funded so I'll talk a little bit about this particular study so spoofing as I",
    "start": "464259",
    "end": "470650"
  },
  {
    "text": "mentioned is a it's a crime but should not be doing it but we also need mechanism to detect them and this is the",
    "start": "470650",
    "end": "477430"
  },
  {
    "text": "study is to do that so how do we happen in practice this is off it's a really a",
    "start": "477430",
    "end": "482830"
  },
  {
    "text": "practice of submitting large spurious order to buy or sell some security to",
    "start": "482830",
    "end": "488830"
  },
  {
    "text": "mislead the other traders so in this particular example you see I wanted to",
    "start": "488830",
    "end": "494800"
  },
  {
    "text": "show is that this is the true value order but somebody is putting a lower value and just try to lower the price or",
    "start": "494800",
    "end": "501400"
  },
  {
    "text": "increase the price so this this is a certain it done in collaboration with in",
    "start": "501400",
    "end": "507129"
  },
  {
    "text": "establish again and charge attack have AWS as well as an ACEF and all that so",
    "start": "507129",
    "end": "513159"
  },
  {
    "text": "how do we manipulate this is is you try to what we call model what is happening",
    "start": "513159",
    "end": "518740"
  },
  {
    "text": "in a daily trading so in this particular case we took the market data and was given by the financial regulation and",
    "start": "518740",
    "end": "525760"
  },
  {
    "text": "agencies to us to study it we modeled the background training and then try to",
    "start": "525760",
    "end": "533230"
  },
  {
    "text": "use machine learning to actually inject those behavior just so that you can and",
    "start": "533230",
    "end": "539440"
  },
  {
    "text": "again it's a live trading of 70 billion happen right there right and then inject",
    "start": "539440",
    "end": "544930"
  },
  {
    "text": "in and try to find your own own way and there is a process to do that that is",
    "start": "544930",
    "end": "552130"
  },
  {
    "text": "called agent based simulations where you you you do a given transaction at a",
    "start": "552130",
    "end": "558310"
  },
  {
    "text": "given function of time where either you model it as the background only behavior",
    "start": "558310",
    "end": "564339"
  },
  {
    "text": "or you start injecting different behavior right and that particular process is is begins with simulating the",
    "start": "564339",
    "end": "573250"
  },
  {
    "text": "market market financial market as a multi-agent system it behavior starts",
    "start": "573250",
    "end": "580120"
  },
  {
    "text": "with evaluating the performance on by the impact of spoofing so that means you",
    "start": "580120",
    "end": "585550"
  },
  {
    "text": "you first see how the spoof errs do it and then try to inject that in your",
    "start": "585550",
    "end": "591640"
  },
  {
    "text": "background only daily trading mechanism and there's a beautiful thing mechanism to do that and its core it",
    "start": "591640",
    "end": "598480"
  },
  {
    "text": "comes under the classification of unsupervised learning do you know unsupervised learning okay",
    "start": "598480",
    "end": "607420"
  },
  {
    "text": "let me give you a very simple example please do it don't generalize it let us imagine we want how do we learn about",
    "start": "607420",
    "end": "614220"
  },
  {
    "text": "which movies to watch when we were very young and beautiful in our school you go",
    "start": "614220",
    "end": "620290"
  },
  {
    "text": "to your class and you ask a good friend which movie shall I watch and your good friend said movie eight and there is not",
    "start": "620290",
    "end": "627640"
  },
  {
    "text": "so good friend you know he's you never talked with him he's not good in class and at all he said movie B which one",
    "start": "627640",
    "end": "634420"
  },
  {
    "text": "will you watch movie so what you're doing is you're cluster izing people of",
    "start": "634420",
    "end": "640060"
  },
  {
    "text": "same interest even if you never search for movie a I can predict it so you have",
    "start": "640060",
    "end": "646720"
  },
  {
    "text": "to find interest of same kind to cluster eyes it that's one of the mechanism of",
    "start": "646720",
    "end": "652510"
  },
  {
    "text": "what because unsupervised learning so I'm not defining any boundary conditions I'm just trying to define a given",
    "start": "652510",
    "end": "658900"
  },
  {
    "text": "pattern so one of the way of doing that is by also a generative model or we call",
    "start": "658900",
    "end": "664540"
  },
  {
    "text": "jams so what is Jancis so it's called",
    "start": "664540",
    "end": "670150"
  },
  {
    "text": "generative and better in the network so you start with a given function create a",
    "start": "670150",
    "end": "675640"
  },
  {
    "text": "generator and you you can you can train it on real images but also inject what",
    "start": "675640",
    "end": "683020"
  },
  {
    "text": "we call fake images such that you can do a differentiation that how much of the was fake is and if you can find it since",
    "start": "683020",
    "end": "690880"
  },
  {
    "text": "you are injecting it you know you can do a back propagation calculate a loss function and see how well you did so",
    "start": "690880",
    "end": "698620"
  },
  {
    "text": "it's it's really a interleaved training of two different neural net or use noise",
    "start": "698620",
    "end": "705490"
  },
  {
    "text": "as the vector R to generate what we call fake sample and a discriminate which basically tells you based on what to",
    "start": "705490",
    "end": "712240"
  },
  {
    "text": "learn whether it's a fake or not so we started working with this and and try to",
    "start": "712240",
    "end": "718390"
  },
  {
    "text": "model a given class of ordered what we call ordering a books evolution so you start with the time",
    "start": "718390",
    "end": "724780"
  },
  {
    "text": "series information how the real life happens and the generator outputs and we started",
    "start": "724780",
    "end": "733050"
  },
  {
    "text": "tracking the state of the history and this is the network which which looks like it's it has a given function which",
    "start": "733050",
    "end": "740940"
  },
  {
    "text": "has what we call LS TM lair long short term memory layer so that you can start doing the the at a time series data and",
    "start": "740940",
    "end": "748080"
  },
  {
    "text": "these are the given function at a set of time while also injecting injecting",
    "start": "748080",
    "end": "754230"
  },
  {
    "text": "noise so we started using the in this particular case we started using work",
    "start": "754230",
    "end": "759540"
  },
  {
    "text": "with a notebook to be the notebook how many people know about notebook okay so",
    "start": "759540",
    "end": "764670"
  },
  {
    "text": "I don't have to say anything ever notebook so these we start with the pre-trained notebook we started using a",
    "start": "764670",
    "end": "771090"
  },
  {
    "text": "sage maker so as you can imagine sage maker supports both machine",
    "start": "771090",
    "end": "776970"
  },
  {
    "text": "learning models like the example I gave clustering so you can do came in clustering but also it supports deep",
    "start": "776970",
    "end": "784980"
  },
  {
    "text": "learning models like a max net or tensor flow or things of that kind but it also provides you mechanism to bring your own",
    "start": "784980",
    "end": "792390"
  },
  {
    "text": "algorithm so Sage make is really a fantastic flavor framework where you start with your input data at a given",
    "start": "792390",
    "end": "800790"
  },
  {
    "text": "storage element let's Amazon s3 all you need to bring it is is your given training code access given barrio and",
    "start": "800790",
    "end": "807680"
  },
  {
    "text": "define your loss function and and do the training such that the N output is a",
    "start": "807680",
    "end": "813000"
  },
  {
    "text": "container you can store it in a given way but at the same time it has building",
    "start": "813000",
    "end": "818540"
  },
  {
    "text": "build an interface to CPUs and GPUs for your given training so we started sage maker and implemented the generative",
    "start": "818540",
    "end": "826770"
  },
  {
    "text": "adversary network or over there and at the end this is the results we get so",
    "start": "826770",
    "end": "832410"
  },
  {
    "text": "for example in the real life and this was like very quickly run right so this",
    "start": "832410",
    "end": "838050"
  },
  {
    "text": "particular parameter was so what are the power property you want to look price right so we put a real price from the",
    "start": "838050",
    "end": "844740"
  },
  {
    "text": "data from from from the stock markets and then we simulated directly using",
    "start": "844740",
    "end": "850200"
  },
  {
    "text": "this so you're doing price your quantity interval unit and various other",
    "start": "850200",
    "end": "855720"
  },
  {
    "text": "quantities such that you can start building a given discriminant in order to do that so this",
    "start": "855720",
    "end": "861750"
  },
  {
    "text": "in process but we are already loved targeting many of the things this is this is one of the one of the studies we",
    "start": "861750",
    "end": "868500"
  },
  {
    "text": "are doing so coming back to with Amazon so I gave one example of Han supervised",
    "start": "868500",
    "end": "874410"
  },
  {
    "text": "learning right but you can do anything so you can start with supervised learning if you do not know how to train",
    "start": "874410",
    "end": "881070"
  },
  {
    "text": "all but there are areas for computer vision you can do using Amazon recognition which is already having a",
    "start": "881070",
    "end": "887250"
  },
  {
    "text": "pre trained modules you can also do document speech languages and many other",
    "start": "887250",
    "end": "892380"
  },
  {
    "text": "things in many cases you have one needs data labeling and all if you don't know",
    "start": "892380",
    "end": "897620"
  },
  {
    "text": "tomato is the tomato you cannot predict matrix right so there is a mechanism to",
    "start": "897620",
    "end": "902700"
  },
  {
    "text": "do that called ground truth where you can do data leveling and then then you sh- it but also you can also work at the",
    "start": "902700",
    "end": "911400"
  },
  {
    "text": "infrastructure level as I said these are the set of services you have one can",
    "start": "911400",
    "end": "918570"
  },
  {
    "text": "start building train and deploying model machine learning at scale in everything",
    "start": "918570",
    "end": "924870"
  },
  {
    "text": "it's a basic common flat part you start with a pre pre build notebook then then",
    "start": "924870",
    "end": "930690"
  },
  {
    "text": "you define a 1:1 click training or to define a infrastructure then you do the",
    "start": "930690",
    "end": "937410"
  },
  {
    "text": "model optimization then you deploy it so I'll give you a couple of examples where",
    "start": "937410",
    "end": "942870"
  },
  {
    "text": "it can be useful I'll pick up a couple of them from diagnose and outcome cases as well as in healthcare and life",
    "start": "942870",
    "end": "949380"
  },
  {
    "text": "sciences so here is one study video this was started by Stanford University many",
    "start": "949380",
    "end": "954839"
  },
  {
    "text": "people get diabetes right it affects the nervous so as I mentioned in",
    "start": "954839",
    "end": "961730"
  },
  {
    "text": "convolutional net it has a beautiful property of detecting any deviation in that so embarrassing you start training",
    "start": "961730",
    "end": "968640"
  },
  {
    "text": "on naked eyes or call it background only hypothesis you have certain obvious so",
    "start": "968640",
    "end": "975420"
  },
  {
    "text": "if diabetics affects your eyes there will be change in this nerve vessel strike and that one came to use in",
    "start": "975420",
    "end": "982530"
  },
  {
    "text": "convolution neural net or deep learning for two direct diabetics so this is one",
    "start": "982530",
    "end": "988350"
  },
  {
    "text": "of them two for early detection of diabetics you can also do skin cancer detection at a very early stage",
    "start": "988350",
    "end": "994860"
  },
  {
    "text": "you can also study for this is fda-approved study for for medical imaging you can also detect if you have",
    "start": "994860",
    "end": "1003250"
  },
  {
    "text": "if there is a choke in the in the lungs or in the heart in the vessels so that",
    "start": "1003250",
    "end": "1009560"
  },
  {
    "text": "also you can do with with machine learning here or deep learning here this is one of the study we try to do is using Amazon recognition as well as",
    "start": "1009560",
    "end": "1018529"
  },
  {
    "text": "natural language processing I didn't talk a little word that but you can automatically get the checks x-ray NLP",
    "start": "1018529",
    "end": "1025520"
  },
  {
    "text": "will tell you that this is a HEPA or pH our information so nineteen parameters so you can detect automatically remove",
    "start": "1025520",
    "end": "1032178"
  },
  {
    "text": "it and then start using this as a training module to auto detect if somebody has a has a cancer not this",
    "start": "1032179",
    "end": "1039290"
  },
  {
    "text": "particular study is open and I it's available you can copy/paste and you can do it yourself as well I thought there",
    "start": "1039290",
    "end": "1045020"
  },
  {
    "text": "was a link but I can send you the link so this way for example you can detect if there is any deviation in the chest",
    "start": "1045020",
    "end": "1051440"
  },
  {
    "text": "x-ray in this particular study it's it's publicly available in our sites you should be able to find it so people are",
    "start": "1051440",
    "end": "1060440"
  },
  {
    "text": "also started using so this is for medical field but also people recently work with Nevada's to detect for example",
    "start": "1060440",
    "end": "1067400"
  },
  {
    "text": "big data to track wildfires for the quality so it can be also used for for",
    "start": "1067400",
    "end": "1073250"
  },
  {
    "text": "human really uses and this is they're trying to do it at Nevada you can one",
    "start": "1073250",
    "end": "1079250"
  },
  {
    "text": "example I picked up from my next speaker slide is can we train it on previous",
    "start": "1079250",
    "end": "1085760"
  },
  {
    "text": "hurricanes using using the data from other Twitter and other other media's",
    "start": "1085760",
    "end": "1090980"
  },
  {
    "text": "and start predicting it for the future or maybe one so that you can employ",
    "start": "1090980",
    "end": "1097460"
  },
  {
    "text": "let's say wild hurricanes are here let's say you can start employing relief",
    "start": "1097460",
    "end": "1103610"
  },
  {
    "text": "agencies like Red Cross so this particular study was done using you know past hurricanes and here what he sure",
    "start": "1103610",
    "end": "1110330"
  },
  {
    "text": "see is this is the predicted part of Medicaid Armagh and this is the real",
    "start": "1110330",
    "end": "1116120"
  },
  {
    "text": "part of our economic right so with that it's really a very exciting field many",
    "start": "1116120",
    "end": "1123559"
  },
  {
    "text": "people it's not very difficult to get started we have building modules but with that I introduce my next",
    "start": "1123559",
    "end": "1129920"
  },
  {
    "text": "speaker and she is going to go details into how you can also use machine learning or deep learning to start",
    "start": "1129920",
    "end": "1135860"
  },
  {
    "text": "predicting hurricanes thank you [Applause]",
    "start": "1135860",
    "end": "1147469"
  },
  {
    "text": "all right I'm really excited to be here I am an associate professor at",
    "start": "1162810",
    "end": "1170740"
  },
  {
    "text": "University of Illinois at Chicago and I'm really excited to talk about a",
    "start": "1170740",
    "end": "1176950"
  },
  {
    "text": "project that I did on deep learning for disaster management and response this is",
    "start": "1176950",
    "end": "1186750"
  },
  {
    "text": "so I start with acknowledgments so this project is made possible through support",
    "start": "1186750",
    "end": "1194500"
  },
  {
    "text": "from NSF through several NSF grants and",
    "start": "1194500",
    "end": "1200970"
  },
  {
    "text": "AWS and so I started working on on",
    "start": "1200970",
    "end": "1209430"
  },
  {
    "text": "disaster management on the own on this disaster-related project after one of my",
    "start": "1209430",
    "end": "1218910"
  },
  {
    "text": "personal experiences so I used to live in Texas and during the spring the",
    "start": "1218910",
    "end": "1225970"
  },
  {
    "text": "spring season there are a lot lot of storms lot of tornadoes and there was",
    "start": "1225970",
    "end": "1232900"
  },
  {
    "text": "one year one spring when there was a",
    "start": "1232900",
    "end": "1238290"
  },
  {
    "text": "tornado and there were lots of all alerts I wasn't really paying attention",
    "start": "1238290",
    "end": "1245130"
  },
  {
    "text": "so I thought there would be nothing and I was careless at the time so I went",
    "start": "1245130",
    "end": "1253270"
  },
  {
    "text": "home which was not safe instead of staying in the department and take",
    "start": "1253270",
    "end": "1260590"
  },
  {
    "text": "shelter so it was one of the the most terrifying experiences that I had that",
    "start": "1260590",
    "end": "1266920"
  },
  {
    "text": "the tornado just passed by through through the above my house and it was it",
    "start": "1266920",
    "end": "1273880"
  },
  {
    "text": "was terrible so I thought I would work on disaster management and try to help",
    "start": "1273880",
    "end": "1281830"
  },
  {
    "text": "people educate people as well as help disaster management focus their limited",
    "start": "1281830",
    "end": "1289740"
  },
  {
    "text": "efforts in the in the areas that I'd need most help so in doing so",
    "start": "1289740",
    "end": "1297100"
  },
  {
    "text": "we use social media and social networking sites such as Facebook",
    "start": "1297100",
    "end": "1304010"
  },
  {
    "text": "Twitter Instagram so these social networking sites connect us to the world",
    "start": "1304010",
    "end": "1311870"
  },
  {
    "text": "and they have become part of our daily lives so as the use of social media is",
    "start": "1311870",
    "end": "1322760"
  },
  {
    "text": "on the rise so is the use of social media during disaster events and as",
    "start": "1322760",
    "end": "1330580"
  },
  {
    "text": "deadly disasters happen almost every week communities that are affected by",
    "start": "1330580",
    "end": "1338030"
  },
  {
    "text": "these disasters have become the source of big disaster data for example during",
    "start": "1338030",
    "end": "1346220"
  },
  {
    "text": "the hurricane sandy there were which happened in 2012 there",
    "start": "1346220",
    "end": "1353060"
  },
  {
    "text": "were more than 20 million tweets that were posted during the disaster and this",
    "start": "1353060",
    "end": "1360190"
  },
  {
    "text": "shows the the distribution the number of tweets per day with the largest number",
    "start": "1360190",
    "end": "1366800"
  },
  {
    "text": "of tweets posted in the days when weather the hurricane hits the East",
    "start": "1366800",
    "end": "1373910"
  },
  {
    "text": "Coast similarly for Tohoku earthquake that",
    "start": "1373910",
    "end": "1382670"
  },
  {
    "text": "happened in Japan there were about 5,000 tweets that were posted every every",
    "start": "1382670",
    "end": "1392500"
  },
  {
    "text": "second and there were about 1.5 million",
    "start": "1392500",
    "end": "1397670"
  },
  {
    "text": "tweets that were tweeted posted in in",
    "start": "1397670",
    "end": "1404060"
  },
  {
    "text": "about 5 minutes in the in the time that the hurricane have the the earthquake",
    "start": "1404060",
    "end": "1410900"
  },
  {
    "text": "happened and this is this shows this plot this plot here shows the",
    "start": "1410900",
    "end": "1418750"
  },
  {
    "text": "communication that happened communication from Twitter that happened",
    "start": "1418750",
    "end": "1424520"
  },
  {
    "text": "during the earthquake so social media used in the",
    "start": "1424520",
    "end": "1437029"
  },
  {
    "text": "in the context of disaster events is very useful has very high value and so",
    "start": "1437029",
    "end": "1445070"
  },
  {
    "text": "researchers assess that I said that by standards on the ground are uniquely",
    "start": "1445070",
    "end": "1452630"
  },
  {
    "text": "positioned to share information that may not yet be available elsewhere",
    "start": "1452630",
    "end": "1459289"
  },
  {
    "text": "in the information space for example seeing this image that is uploaded in",
    "start": "1459289",
    "end": "1468200"
  },
  {
    "text": "Twitter we can easily understand what is the situation on the ground and try to",
    "start": "1468200",
    "end": "1477140"
  },
  {
    "text": "avoid the affected areas so scores of",
    "start": "1477140",
    "end": "1483380"
  },
  {
    "text": "disasters see hope in social media and they argue that social media can produce",
    "start": "1483380",
    "end": "1491840"
  },
  {
    "text": "more accurate results even in advance of official sources for example CNN still",
    "start": "1491840",
    "end": "1502330"
  },
  {
    "text": "social media is not very used by disaster management by Disaster Response",
    "start": "1502330",
    "end": "1509600"
  },
  {
    "text": "organizations and some of the reasons for this may be because they operate in",
    "start": "1509600",
    "end": "1518270"
  },
  {
    "text": "conditions of an era of extreme uncertainty and because there is an",
    "start": "1518270",
    "end": "1524539"
  },
  {
    "text": "exponential number of social media posts",
    "start": "1524539",
    "end": "1529880"
  },
  {
    "text": "tweets for example and this increases also the irrelevant information so this",
    "start": "1529880",
    "end": "1540620"
  },
  {
    "text": "irrelevant information diminishes people's ability to find information that they need in order to organize",
    "start": "1540620",
    "end": "1548409"
  },
  {
    "text": "relief efforts for response organizations to find help for people on",
    "start": "1548409",
    "end": "1557750"
  },
  {
    "text": "the ground and potentially to save lives",
    "start": "1557750",
    "end": "1564000"
  },
  {
    "text": "so how can we identify useful content in Twitter one approach that we can do",
    "start": "1564000",
    "end": "1572500"
  },
  {
    "text": "could be based on keywords based search",
    "start": "1572500",
    "end": "1577860"
  },
  {
    "text": "for example we can search for Oklahoma tornado or together or separate words",
    "start": "1577860",
    "end": "1586660"
  },
  {
    "text": "Oklahoma and tornado or hashtag Oklahoma tornado or we can do location-based",
    "start": "1586660",
    "end": "1594660"
  },
  {
    "text": "search collecting all the tweets that are posted based on their geolocation",
    "start": "1594660",
    "end": "1601890"
  },
  {
    "text": "however this retrieves not only relevant",
    "start": "1601950",
    "end": "1606970"
  },
  {
    "text": "information but a lot of tweets literally relevant as in this case there",
    "start": "1606970",
    "end": "1612970"
  },
  {
    "text": "is a tweet here an example I've lived in Oklahoma since I was born",
    "start": "1612970",
    "end": "1618670"
  },
  {
    "text": "so this has nothing to do with the Oklahoma tornado on the other hand so",
    "start": "1618670",
    "end": "1625300"
  },
  {
    "text": "this keyword based approach could be useful but again brings a lot of",
    "start": "1625300",
    "end": "1631540"
  },
  {
    "text": "irrelevant information a manual selection given the millions of tweets",
    "start": "1631540",
    "end": "1638800"
  },
  {
    "text": "that are posted in disasters is very time-consuming and is not feasible and",
    "start": "1638800",
    "end": "1645370"
  },
  {
    "text": "sustainable today hence there is an increasing need for automated approaches",
    "start": "1645370",
    "end": "1652330"
  },
  {
    "text": "for extracting appropriate information from a disaster Twitter which could",
    "start": "1652330",
    "end": "1659230"
  },
  {
    "text": "improve the disaster response so we",
    "start": "1659230",
    "end": "1667270"
  },
  {
    "text": "propose the framework that used",
    "start": "1667270",
    "end": "1673170"
  },
  {
    "text": "information sorry so that use the information from",
    "start": "1673170",
    "end": "1681240"
  },
  {
    "text": "disasters that happen before together with these asked with an own data from",
    "start": "1681240",
    "end": "1688270"
  },
  {
    "text": "an ongoing disaster in type of a domain adaptation approach",
    "start": "1688270",
    "end": "1693560"
  },
  {
    "text": "trying to transfer knowledge knowledge that we learn from previous disasters to",
    "start": "1693560",
    "end": "1699950"
  },
  {
    "text": "the disaster that just happens currently and particularly we do so because as a",
    "start": "1699950",
    "end": "1706550"
  },
  {
    "text": "disaster happens and it happens very quickly we don't have label data to",
    "start": "1706550",
    "end": "1713510"
  },
  {
    "text": "train supervised machine learning classifiers and so in that case what can",
    "start": "1713510",
    "end": "1718760"
  },
  {
    "text": "we do how can we use previous disasters the labor label data from previous",
    "start": "1718760",
    "end": "1725120"
  },
  {
    "text": "disasters to cope with the current disaster so if we propose this frame the",
    "start": "1725120",
    "end": "1731750"
  },
  {
    "text": "domain adaptation framework that use information from previous disasters to",
    "start": "1731750",
    "end": "1737420"
  },
  {
    "text": "cope with with current disaster with a",
    "start": "1737420",
    "end": "1743750"
  },
  {
    "text": "current disaster and we use deep learning as well as the",
    "start": "1743750",
    "end": "1750350"
  },
  {
    "text": "tools that are available from AWS for example the comprehend which I'll",
    "start": "1750350",
    "end": "1756530"
  },
  {
    "text": "describe a little later so then this",
    "start": "1756530",
    "end": "1765680"
  },
  {
    "text": "information that is that is extracted",
    "start": "1765680",
    "end": "1771230"
  },
  {
    "text": "using this deep learning approaches and tools from AWS is forwarded to the",
    "start": "1771230",
    "end": "1777740"
  },
  {
    "text": "response organizations and help them better manage their response so in the",
    "start": "1777740",
    "end": "1788060"
  },
  {
    "text": "workflow so that there is a data collection and analysis we use Twitter",
    "start": "1788060",
    "end": "1794300"
  },
  {
    "text": "API the Twitter streaming API to crawl the tweets and then we use NLP natural",
    "start": "1794300",
    "end": "1801920"
  },
  {
    "text": "language processing tools to process the tweets to extract the text from the",
    "start": "1801920",
    "end": "1811610"
  },
  {
    "text": "tweets to extract the hashtags some some of the user information if these are for",
    "start": "1811610",
    "end": "1819590"
  },
  {
    "text": "example official I use official sources like CNN or individuals people people on the",
    "start": "1819590",
    "end": "1830350"
  },
  {
    "text": "ground and then we also extract the geolocation when whenever this geolocation is available and then but",
    "start": "1830350",
    "end": "1837310"
  },
  {
    "text": "form text classification NLP and text analytics on the tweets so now given the",
    "start": "1837310",
    "end": "1845920"
  },
  {
    "text": "the stream of tweets and the text that we extracted from the tweets then we",
    "start": "1845920",
    "end": "1851650"
  },
  {
    "text": "perform several classification tasks for example first train a classifier that",
    "start": "1851650",
    "end": "1860380"
  },
  {
    "text": "will classify if the tweet is relevant to the disaster or not then if that",
    "start": "1860380",
    "end": "1868270"
  },
  {
    "text": "particular tweet is posted by eyewitnesses and if if it's posted by",
    "start": "1868270",
    "end": "1874930"
  },
  {
    "text": "eyewitnesses if it requires some urgency some some actions to be taken originally",
    "start": "1874930",
    "end": "1882610"
  },
  {
    "text": "and then if the tweets are are we posted",
    "start": "1882610",
    "end": "1887800"
  },
  {
    "text": "by eyewitnesses then if they are informative or not and then if they are",
    "start": "1887800",
    "end": "1895180"
  },
  {
    "text": "informative if they convey some type of situational awareness so if they contain",
    "start": "1895180",
    "end": "1902800"
  },
  {
    "text": "information about damages damages or injured people or missing people dead",
    "start": "1902800",
    "end": "1908620"
  },
  {
    "text": "people and so on so there are several classes like Sanjay",
    "start": "1908620",
    "end": "1916660"
  },
  {
    "text": "mentioned several classes of machine learning algorithms supervised",
    "start": "1916660",
    "end": "1921870"
  },
  {
    "text": "supervised learning that requires large amounts of label data domain adaptation",
    "start": "1921870",
    "end": "1930300"
  },
  {
    "text": "that uses and this is the this is the",
    "start": "1930300",
    "end": "1937120"
  },
  {
    "text": "approach that we proposed to use information knowledge from prior from",
    "start": "1937120",
    "end": "1943960"
  },
  {
    "text": "source disasters to cope with a target disaster and to transfer knowledge from",
    "start": "1943960",
    "end": "1951120"
  },
  {
    "text": "source to target disasters and then unsupervised",
    "start": "1951120",
    "end": "1957350"
  },
  {
    "text": "that will help us understand what kind of topics people are talking about in a",
    "start": "1957350",
    "end": "1962960"
  },
  {
    "text": "disaster so as I mentioned in our",
    "start": "1962960",
    "end": "1969800"
  },
  {
    "text": "framework we used AWS the Amazon comprehend which is a natural language",
    "start": "1969800",
    "end": "1977330"
  },
  {
    "text": "processing and text analytics tool and",
    "start": "1977330",
    "end": "1983050"
  },
  {
    "text": "so how does it work given the the stream of data the tweets",
    "start": "1983050",
    "end": "1991100"
  },
  {
    "text": "the input something else so anyway I can",
    "start": "1991100",
    "end": "2012040"
  },
  {
    "text": "continue talking so given the the stream of tweets the comprehend will identify",
    "start": "2012040",
    "end": "2020590"
  },
  {
    "text": "the type of keywords that the keywords or the hash tags from the tweets that",
    "start": "2020590",
    "end": "2026770"
  },
  {
    "text": "will help us categorize tweets based on for example as I mentioned before based",
    "start": "2026770",
    "end": "2032740"
  },
  {
    "text": "on their situational awareness like if the tweet is about missing people or",
    "start": "2032740",
    "end": "2038020"
  },
  {
    "text": "dead people or if there are if there is for example power loss in some area or a",
    "start": "2038020",
    "end": "2045550"
  },
  {
    "text": "bridge has was damaged damaged and so on so comprehend will help extract entities",
    "start": "2045550",
    "end": "2055230"
  },
  {
    "text": "will help will help us extract topics topics of discussion and if the slides",
    "start": "2055230",
    "end": "2064210"
  },
  {
    "text": "will be still available I can show I will show you some of the topics that we",
    "start": "2064210",
    "end": "2070659"
  },
  {
    "text": "extracted with comprehend we also can",
    "start": "2070660",
    "end": "2078070"
  },
  {
    "text": "track we can also predict the location of tweets based on the corn based based",
    "start": "2078070",
    "end": "2087370"
  },
  {
    "text": "on their content and then we can try the path of the heart of a particular",
    "start": "2087370",
    "end": "2093770"
  },
  {
    "text": "hurricane and how how it progresses geographically and so using comprehend",
    "start": "2093770",
    "end": "2101930"
  },
  {
    "text": "we were able and as also Sanjay mentioned we were able to very very",
    "start": "2101930",
    "end": "2109310"
  },
  {
    "text": "nicely predict the the path of the",
    "start": "2109310",
    "end": "2115820"
  },
  {
    "text": "hurricane which overlap quite nicely with the actual path of the hurricane so",
    "start": "2115820",
    "end": "2126280"
  },
  {
    "text": "so again using the AWS we can extract entities keywords hash the command hash",
    "start": "2126880",
    "end": "2134390"
  },
  {
    "text": "tags predict the location we also so in",
    "start": "2134390",
    "end": "2142880"
  },
  {
    "text": "addition to using the comprehend the Amazon comprehend tool we also designed",
    "start": "2142880",
    "end": "2150760"
  },
  {
    "text": "models that were deep learning models that were trained on disaster data and",
    "start": "2150760",
    "end": "2158510"
  },
  {
    "text": "as I mentioned on data from previous disasters and use this the deep learning",
    "start": "2158510",
    "end": "2169670"
  },
  {
    "text": "models to predict data from from a current ongoing disaster let's see if",
    "start": "2169670",
    "end": "2179450"
  },
  {
    "text": "it's if it's working",
    "start": "2179450",
    "end": "2184540"
  },
  {
    "text": "so I can show you some of the results that we obtained before I okay all right",
    "start": "2187800",
    "end": "2202600"
  },
  {
    "text": "great so and now this is not working",
    "start": "2202600",
    "end": "2209070"
  },
  {
    "text": "okay sorry water oh yeah so this is okay so",
    "start": "2216180",
    "end": "2240240"
  },
  {
    "text": "so these are the topics that we extracted that we extracted using the",
    "start": "2240540",
    "end": "2248470"
  },
  {
    "text": "Amazon comprehend and so these are the words that cluster together in a topic",
    "start": "2248470",
    "end": "2254790"
  },
  {
    "text": "hurricane they generate into tropical waves so the words that are that cluster",
    "start": "2254790",
    "end": "2263050"
  },
  {
    "text": "together are very very informative about this topic for example hurricane cyclone",
    "start": "2263050",
    "end": "2271180"
  },
  {
    "text": "wave and so on and then so these are the",
    "start": "2271180",
    "end": "2278710"
  },
  {
    "text": "results that we obtained using the deep learning approaches that we designed for",
    "start": "2278710",
    "end": "2286320"
  },
  {
    "text": "identifying informative tweets so we",
    "start": "2286320",
    "end": "2292990"
  },
  {
    "text": "trained deep learning the convolutional neural networks and recorded recurrent",
    "start": "2292990",
    "end": "2298030"
  },
  {
    "text": "neural networks long short term memory networks to predict if a tweet is",
    "start": "2298030",
    "end": "2304030"
  },
  {
    "text": "informative to a disaster response organization or not and as we can see",
    "start": "2304030",
    "end": "2309550"
  },
  {
    "text": "using the the CNN convolutional neural networks the performance is quite high",
    "start": "2309550",
    "end": "2314619"
  },
  {
    "text": "on both natural disasters and natural disasters and non natural",
    "start": "2314619",
    "end": "2320590"
  },
  {
    "text": "disasters and we compare this with traditional machine learning classifiers on features that were engineered",
    "start": "2320590",
    "end": "2328210"
  },
  {
    "text": "features that were extracted from the TWiT content and again as we can see",
    "start": "2328210",
    "end": "2335740"
  },
  {
    "text": "here the deep learning approaches perform much better than I did much",
    "start": "2335740",
    "end": "2341950"
  },
  {
    "text": "better than the traditional machine learning and this is this is the",
    "start": "2341950",
    "end": "2349740"
  },
  {
    "text": "hurricane the hurricane Harvey predicted path so as we can see here there is",
    "start": "2351510",
    "end": "2359650"
  },
  {
    "text": "quite a nice overlap between the predicted path with the actual path of",
    "start": "2359650",
    "end": "2365650"
  },
  {
    "text": "the hurricane and with this I'm I concluded the talk and I headed over to",
    "start": "2365650",
    "end": "2375330"
  },
  {
    "text": "please hello everybody my name is Lee",
    "start": "2375330",
    "end": "2389500"
  },
  {
    "text": "st. Denis from the University of Colorado's earth lab and today I'm going to be talking about a project that I've",
    "start": "2389500",
    "end": "2396130"
  },
  {
    "text": "been working on to mine social media data for emergency response and I'm also going to talk a little bit about a",
    "start": "2396130",
    "end": "2402430"
  },
  {
    "text": "collaboration I have we've had with the Amazon Web Services Disaster Response",
    "start": "2402430",
    "end": "2407530"
  },
  {
    "text": "Team that's helping us push this project forward in the next steps Sunday this is",
    "start": "2407530",
    "end": "2419160"
  },
  {
    "text": "so my background is in crisis informatics and my research focuses on",
    "start": "2422400",
    "end": "2427900"
  },
  {
    "text": "integration of social media and emergency response and as many of you",
    "start": "2427900",
    "end": "2433420"
  },
  {
    "text": "are familiar the use of social meet our social media and advancements in communication technologies have",
    "start": "2433420",
    "end": "2440560"
  },
  {
    "text": "fundamentally transformed how people communicate and share information in disaster and it's created new",
    "start": "2440560",
    "end": "2447790"
  },
  {
    "text": "opportunities for people to participate in disaster response but it's also",
    "start": "2447790",
    "end": "2453610"
  },
  {
    "text": "created a whole new set of challenges and I've been motivated by one particular challenge which is that at",
    "start": "2453610",
    "end": "2461440"
  },
  {
    "text": "the height of impact in a disaster when it's most important to identify relevant",
    "start": "2461440",
    "end": "2467200"
  },
  {
    "text": "information it's often incredibly challenging to do so for both emergency",
    "start": "2467200",
    "end": "2472270"
  },
  {
    "text": "responders and communities impacted by disaster so that the in large-scale",
    "start": "2472270",
    "end": "2478450"
  },
  {
    "text": "events can often generate millions of tweets as people around the world react and respond to what's happening on the",
    "start": "2478450",
    "end": "2484600"
  },
  {
    "text": "ground so my there's a slide missing Sanjay",
    "start": "2484600",
    "end": "2492760"
  },
  {
    "text": "so just to give you a little bit of background my research has been heavily participatory so to understand this to",
    "start": "2492760",
    "end": "2501280"
  },
  {
    "text": "understand the impacts of social media on emergency response IB I immersed",
    "start": "2501280",
    "end": "2506380"
  },
  {
    "text": "myself in the virtual operational support team community which is so I was",
    "start": "2506380",
    "end": "2514120"
  },
  {
    "text": "part of a supporting emergency response on over 40 emergency response",
    "start": "2514120",
    "end": "2519850"
  },
  {
    "text": "activations and so as part of that experience I've spent hundreds of hours participating in social media monitoring",
    "start": "2519850",
    "end": "2527080"
  },
  {
    "text": "with emergency responders and been part of the community the communications",
    "start": "2527080",
    "end": "2533530"
  },
  {
    "text": "between the teams on the ground and the virtual teams doing that support work and I've also as part of that then lots",
    "start": "2533530",
    "end": "2542650"
  },
  {
    "text": "of analysis of the social media data collected around those events in 20 2014",
    "start": "2542650",
    "end": "2550090"
  },
  {
    "text": "while I was supporting the team working on the Carlton complex wildfire",
    "start": "2550090",
    "end": "2555430"
  },
  {
    "text": "in eastern Washington State on July 17th",
    "start": "2555430",
    "end": "2561099"
  },
  {
    "text": "adverse conditions and a wind event and the evening caused that fire to blow up",
    "start": "2561099",
    "end": "2566710"
  },
  {
    "text": "by over a hundred thousand acres overnight and it burnt through the towns",
    "start": "2566710",
    "end": "2571720"
  },
  {
    "text": "of Pateros and Brewster and destroyed over three hundred and fifty three homes the picture on the left is what was left",
    "start": "2571720",
    "end": "2578680"
  },
  {
    "text": "of one of the homes in one of those communities which has become a familiar sight these days the fire progression",
    "start": "2578680",
    "end": "2585940"
  },
  {
    "text": "map on the right the dark blue and the the neighboring teal and that progression map gives you a feel for the",
    "start": "2585940",
    "end": "2592270"
  },
  {
    "text": "magnitude of the increase overnight of that fire and as part of that monitoring",
    "start": "2592270",
    "end": "2599740"
  },
  {
    "text": "team it was really hard the days following that blow up it was really hard to keep pace with the social media",
    "start": "2599740",
    "end": "2607530"
  },
  {
    "text": "conversation or the traffic on that fire and after that fire I met with the",
    "start": "2607530",
    "end": "2614710"
  },
  {
    "text": "public information team to go to go over my analysis of the data and the lead pio",
    "start": "2614710",
    "end": "2620470"
  },
  {
    "text": "and that fire a woman named Chris Erickson made a comment that really resonated with me which was she said you",
    "start": "2620470",
    "end": "2626200"
  },
  {
    "text": "know lease and the thick of it what I really need to know is what I don't know and I as I sat and I thought about it I",
    "start": "2626200",
    "end": "2634270"
  },
  {
    "text": "realized that every event that I had worked on that had rung true so when I worked on the 2013 floods there was a",
    "start": "2634270",
    "end": "2641650"
  },
  {
    "text": "particular tree that the one of the public information officers pointed to and said this is what keeps me up at",
    "start": "2641650",
    "end": "2647859"
  },
  {
    "text": "night that something like this will slip through the through the cracks and I thought about the study that we'd done",
    "start": "2647859",
    "end": "2654280"
  },
  {
    "text": "on the on Hurricane sandy when the 911",
    "start": "2654280",
    "end": "2659700"
  },
  {
    "text": "was overloaded and the traffic overflowed onto Twitter and people improvised and so following that",
    "start": "2659700",
    "end": "2667650"
  },
  {
    "text": "conversation I went back and I started thinking how do we solve this problem and so I started playing with this idea",
    "start": "2667650",
    "end": "2674160"
  },
  {
    "text": "that you could use what I could use what we knew and what I knew about social media communication and disaster to take",
    "start": "2674160",
    "end": "2681280"
  },
  {
    "text": "what we knew to get at what we didn't know essentially so playing with this idea and the data that I was using",
    "start": "2681280",
    "end": "2686890"
  },
  {
    "text": "for my analysis I turned it around and I thought how do i how can I safely take",
    "start": "2686890",
    "end": "2692380"
  },
  {
    "text": "what I know off the top and so the graph on the left is that idea applied to that",
    "start": "2692380",
    "end": "2697900"
  },
  {
    "text": "the day after the blow-up of the fire so the the line at the top of the graph is",
    "start": "2697900",
    "end": "2704290"
  },
  {
    "text": "the overall hourly volume on that day and the line at the bottom of the graph is what was remaining after I took the",
    "start": "2704290",
    "end": "2710950"
  },
  {
    "text": "knowns the safe known values off the top and it was what's remarkable about that",
    "start": "2710950",
    "end": "2716650"
  },
  {
    "text": "is that's one person's monitoring volume and I couldn't keep track of that in the day so that I thought was really",
    "start": "2716650",
    "end": "2722830"
  },
  {
    "text": "promising but really what was more",
    "start": "2722830",
    "end": "2727960"
  },
  {
    "text": "exciting to me was that what was left once I took that off the top what I",
    "start": "2727960",
    "end": "2733330"
  },
  {
    "text": "found was the content that emerged you know in contrast to media coverage which",
    "start": "2733330",
    "end": "2739630"
  },
  {
    "text": "tends to really focus on like the dramatic coverage and it's heavily",
    "start": "2739630",
    "end": "2746380"
  },
  {
    "text": "dominated by the same sort of details what you see when you strip out that",
    "start": "2746380",
    "end": "2752160"
  },
  {
    "text": "that common information as you start to see what's happening at the local level",
    "start": "2752160",
    "end": "2757780"
  },
  {
    "text": "and you pick up all the that individual all those individual details that paint",
    "start": "2757780",
    "end": "2763750"
  },
  {
    "text": "that fill in all the details and paint that detailed picture and I saw a lot of",
    "start": "2763750",
    "end": "2768790"
  },
  {
    "text": "value in that so this is having having been through that and I picked up this",
    "start": "2768790",
    "end": "2774010"
  },
  {
    "text": "is one person who I picked up a couple of their tweets and I realized how much more rich information was there but the",
    "start": "2774010",
    "end": "2780250"
  },
  {
    "text": "thing that really struck me is that is a great idea but it only works if you can do it in real time and so I realized",
    "start": "2780250",
    "end": "2787180"
  },
  {
    "text": "that it was a great candidate for machine learning and so the following",
    "start": "2787180",
    "end": "2793270"
  },
  {
    "text": "summer I trial the idea on three more wildfires and I was able to simulate it",
    "start": "2793270",
    "end": "2799600"
  },
  {
    "text": "in real time and then while I was finishing my dissertation and then in 2016 I joined CU earth lab where I had",
    "start": "2799600",
    "end": "2807370"
  },
  {
    "text": "access to the analytics hub and a team of machine learning at spirts and we began working on this idea",
    "start": "2807370",
    "end": "2813819"
  },
  {
    "text": "that we could build a neural net classifier but before I talk about that",
    "start": "2813819",
    "end": "2818920"
  },
  {
    "text": "and I also have been working with the other thing is we needed to collect the data in real time and so the disaster",
    "start": "2818920",
    "end": "2825160"
  },
  {
    "text": "response team has helped us with that piece and so they helped us so we could",
    "start": "2825160",
    "end": "2830410"
  },
  {
    "text": "focus on the classifier they've helped us build our data collection process and so we're using AWS tools its cloud-based",
    "start": "2830410",
    "end": "2838349"
  },
  {
    "text": "so it can expand to whatever size we need if we have a huge data collection we use secret mat secrets manager to",
    "start": "2838349",
    "end": "2846670"
  },
  {
    "text": "trigger the ingestion process it stores it in an s3 bucket and then we're using",
    "start": "2846670",
    "end": "2852119"
  },
  {
    "text": "glue and Athena to pull it out and manipulate it and prep it for classification and it's working great",
    "start": "2852119",
    "end": "2859359"
  },
  {
    "text": "for us we've been able to capture two seasons of catastrophic wildfires and",
    "start": "2859359",
    "end": "2865450"
  },
  {
    "text": "hurricane data moving forward they've helped it helped us figure out a",
    "start": "2865450",
    "end": "2870490"
  },
  {
    "text": "strategy for we realized that as we start collaborating with response teams we need to maintain independent",
    "start": "2870490",
    "end": "2877119"
  },
  {
    "text": "collections and run multiple processes and also as an earth analytics lab we",
    "start": "2877119",
    "end": "2882609"
  },
  {
    "text": "want to start kicking off really large-scale event our hazard specific data",
    "start": "2882609",
    "end": "2889690"
  },
  {
    "text": "collection so they've helped us figure out a strategy for doing that as well okay so I'm going to turn to our neural",
    "start": "2889690",
    "end": "2898240"
  },
  {
    "text": "net so we've been working on an Iran that classifier for for the Twitter data",
    "start": "2898240",
    "end": "2904020"
  },
  {
    "text": "and our classifier looks at information",
    "start": "2904020",
    "end": "2910359"
  },
  {
    "text": "about both the author and the tweet and",
    "start": "2910359",
    "end": "2914190"
  },
  {
    "text": "we've focused we've spent a lot of our energy focused on the account at this point and what we're really looking at",
    "start": "2916109",
    "end": "2923190"
  },
  {
    "text": "narrowing down narrowing in on is those accounts that are not part of official",
    "start": "2923190",
    "end": "2930880"
  },
  {
    "text": "or media they aren't there and they don't come from they're not",
    "start": "2930880",
    "end": "2936400"
  },
  {
    "text": "representative of official or media sources are part of that big mass of the public community and they're generating",
    "start": "2936400",
    "end": "2943869"
  },
  {
    "text": "personal nice content so to figure that out we take in information we take in the",
    "start": "2943869",
    "end": "2949390"
  },
  {
    "text": "profile picture we take in their profile descriptive text from the profile all the stats and we look we also calculate",
    "start": "2949390",
    "end": "2958210"
  },
  {
    "text": "statistics from their recent tweet behavior and all of that to do that we",
    "start": "2958210",
    "end": "2964479"
  },
  {
    "text": "use a number of different neural net models so for the profile picture we use a convolutional neural net for all of",
    "start": "2964479",
    "end": "2970839"
  },
  {
    "text": "the text we use bi-directional STM and then feed-forward for all the statistics",
    "start": "2970839",
    "end": "2977739"
  },
  {
    "text": "and we combined them into one end-to-end model and then intermediately we combine",
    "start": "2977739",
    "end": "2983970"
  },
  {
    "text": "and optimize those together so each of those influence the final predicted",
    "start": "2983970",
    "end": "2989619"
  },
  {
    "text": "classification so and we've actually",
    "start": "2989619",
    "end": "2995910"
  },
  {
    "text": "even we've had it our classifier even with a relatively small amount of data",
    "start": "2995910",
    "end": "3001680"
  },
  {
    "text": "this is the data from the the three fires and a set of data from the Kent recent camp in Woolsey fire it's really",
    "start": "3001680",
    "end": "3009059"
  },
  {
    "text": "good at predicting individual personalized content within that mass and there was the tweets that we're",
    "start": "3009059",
    "end": "3015539"
  },
  {
    "text": "getting the content is really good and since then we've there are certain",
    "start": "3015539",
    "end": "3022319"
  },
  {
    "text": "categories that don't occur very often and we've since gone in and and remedied that with some supplemental data and so",
    "start": "3022319",
    "end": "3030719"
  },
  {
    "text": "since then we've started to turn our attention to the tweet level and my",
    "start": "3030719",
    "end": "3036239"
  },
  {
    "text": "approach has always been to look at the classification from from two approaches",
    "start": "3036239",
    "end": "3041519"
  },
  {
    "text": "so I look at both filtering out things that are safe to filter out and then prioritizing content that that you can",
    "start": "3041519",
    "end": "3049499"
  },
  {
    "text": "prioritize I don't want to eliminate that middle ground because I found that there's a lot of value in that so at the",
    "start": "3049499",
    "end": "3057059"
  },
  {
    "text": "height of impact you may only have the bandwidth to look at those key life-safety and have specific hazards",
    "start": "3057059",
    "end": "3063479"
  },
  {
    "text": "but as that impact lessens you really don't you really want to look at the broader localized content so looking at",
    "start": "3063479",
    "end": "3071789"
  },
  {
    "text": "what you can filter out in any disaster there's a huge volume of what would categorize as just general",
    "start": "3071789",
    "end": "3077460"
  },
  {
    "text": "response so just general reaction gratitude Thanks",
    "start": "3077460",
    "end": "3083640"
  },
  {
    "text": "and well wishes exemplified by the tweets on the left and then this general synthesis of things like official",
    "start": "3083640",
    "end": "3090870"
  },
  {
    "text": "updates and media coverage on the right which I think are fairly easy to filter out and then the things that you want to",
    "start": "3090870",
    "end": "3098730"
  },
  {
    "text": "prioritize it's a longer list than this these are just general categories it's",
    "start": "3098730",
    "end": "3104280"
  },
  {
    "text": "based on my experience working with the teams and studies I've done on Hurricane",
    "start": "3104280",
    "end": "3109890"
  },
  {
    "text": "sandy the Colorado floods and then the fires that I've worked on and then the",
    "start": "3109890",
    "end": "3120480"
  },
  {
    "text": "next steps are so we're working on that data set I'm working on moving that into",
    "start": "3120480",
    "end": "3126540"
  },
  {
    "text": "a space where I can start gathering feedback from some of the teams that I work on and I'm also working on building",
    "start": "3126540",
    "end": "3132480"
  },
  {
    "text": "an application simple monitoring application that we would like to push forward and and use on a real responsive",
    "start": "3132480",
    "end": "3139170"
  },
  {
    "text": "Aust activation so we can start gathering feedback so that we can start finding validating my categories and",
    "start": "3139170",
    "end": "3145590"
  },
  {
    "text": "incorporating more into the next round and that's it",
    "start": "3145590",
    "end": "3150910"
  },
  {
    "text": "[Applause]",
    "start": "3150910",
    "end": "3154890"
  }
]
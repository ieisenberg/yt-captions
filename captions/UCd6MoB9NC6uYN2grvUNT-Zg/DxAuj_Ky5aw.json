[
  {
    "start": "0",
    "end": "31000"
  },
  {
    "text": "hi everyone thanks so much for coming uh my name is Rahul Pathak I'm the general manager for Amazon Athena and for Amazon",
    "start": "1319",
    "end": "9000"
  },
  {
    "text": "EMR and uh what I'd like to do today is to just give you an overview of Athena walk through some of its key features",
    "start": "9000",
    "end": "16080"
  },
  {
    "text": "talk a little bit about how some customers are using it and I'm going to try and finish up in time to take a few questions and again thank you so much",
    "start": "16080",
    "end": "22560"
  },
  {
    "text": "for your interest and for being here very excited to to uh launch the service at reinvent and we're already seeing",
    "start": "22560",
    "end": "28840"
  },
  {
    "text": "quite a bit of usage so this is is great uh so uh you know why did we build Athena so we we were talking to",
    "start": "28840",
    "end": "35480"
  },
  {
    "start": "31000",
    "end": "31000"
  },
  {
    "text": "customers and they found that they had uh had to do some work really to get to their data in S3 and uh sometimes that",
    "start": "35480",
    "end": "43000"
  },
  {
    "text": "work involved complex Transformations loading it into another system or spinning up an EMR cluster and while",
    "start": "43000",
    "end": "48879"
  },
  {
    "text": "those are relatively straightforward uh they still take effort and you typically do need some special skills uh to manage",
    "start": "48879",
    "end": "55800"
  },
  {
    "text": "a Hadoop cluster or a data warehouse and so we wanted to make this a little easier and uh you know quick",
    "start": "55800",
    "end": "61600"
  },
  {
    "text": "show of hands who has data in S3 here okay sounds about right and uh who",
    "start": "61600",
    "end": "68159"
  },
  {
    "text": "has familiarity with SQL all right so we're in the right place and we built the right product for",
    "start": "68159",
    "end": "73960"
  },
  {
    "text": "you I think um so we wanted to make this easier and so you know the the point of",
    "start": "73960",
    "end": "80400"
  },
  {
    "start": "77000",
    "end": "77000"
  },
  {
    "text": "view we took was we wanted to provide a query service that would let you query data in S3 without having to move it",
    "start": "80400",
    "end": "86320"
  },
  {
    "text": "query it in place and you could use standard SQL so so the reason I've highlighted interactive query service is",
    "start": "86320",
    "end": "92520"
  },
  {
    "text": "that we want to get you results fast so most results come back in seconds uh and it's also not a database so this is for",
    "start": "92520",
    "end": "98960"
  },
  {
    "text": "querying data in S3 uh it's not designed to be a database it's not designed to be a data warehouse It's allow you to it's",
    "start": "98960",
    "end": "104920"
  },
  {
    "text": "designed to allow you to write fast SQL queries with nothing to manage and so uh theena serverless um",
    "start": "104920",
    "end": "112719"
  },
  {
    "start": "110000",
    "end": "110000"
  },
  {
    "text": "essentially we are um taking care of all of the aspects of running queries for you so there's nothing for you to manage",
    "start": "112719",
    "end": "119039"
  },
  {
    "text": "or to pay attention to uh we maintain warm pools of compute capacity so when you log in and run a query you get a",
    "start": "119039",
    "end": "125119"
  },
  {
    "text": "response right away there's no waiting for anything to provision uh and because we're delivering it as an automated",
    "start": "125119",
    "end": "130920"
  },
  {
    "text": "managed service when we make updates to the service those are completely transparent you will not notice them you'll just see new capabilities and",
    "start": "130920",
    "end": "137360"
  },
  {
    "text": "features come into play uh and what we wanted to do was to make this super simple to use so the",
    "start": "137360",
    "end": "144360"
  },
  {
    "start": "140000",
    "end": "140000"
  },
  {
    "text": "idea is that you log into a console you're presented with something that looks a lot like a SQL editor and I'll",
    "start": "144360",
    "end": "149560"
  },
  {
    "text": "show you some screenshots in a second uh once you do that you have to define a table uh we chose to use Hive um Syntax",
    "start": "149560",
    "end": "157360"
  },
  {
    "text": "for our ddl statements or data description language uh and this is really because Hive is very flexible it",
    "start": "157360",
    "end": "163200"
  },
  {
    "text": "allows you to query and Define tables on a variety of data formats um and these are open formats so a lot of our",
    "start": "163200",
    "end": "169440"
  },
  {
    "text": "customers are using Technologies like EMR already and we wanted to make it easy to slot Athena into uh their",
    "start": "169440",
    "end": "175599"
  },
  {
    "text": "existing systems and the console also has an ad table wizard which will walk you through the process of uh pointing to data in S3",
    "start": "175599",
    "end": "183040"
  },
  {
    "text": "setting up a table uh and then once your table is set up you're essentially writing SQL queries as you would against",
    "start": "183040",
    "end": "188080"
  },
  {
    "text": "a normal database uh one other thing to keep in mind is that um you know all tables in Athena are defined as external",
    "start": "188080",
    "end": "195000"
  },
  {
    "text": "tables and what this means is that uh when you take a table out of the Athena catalog it it doesn't do anything to",
    "start": "195000",
    "end": "200920"
  },
  {
    "text": "your data on S3 we don't do any modification it's a readon service from an S3",
    "start": "200920",
    "end": "207360"
  },
  {
    "text": "perspective um it's highly available so we're running warm compute pools um in multiple availability zones you connect",
    "start": "207519",
    "end": "214040"
  },
  {
    "start": "208000",
    "end": "208000"
  },
  {
    "text": "to the Athena endpoint or log into the Athena console uh and so if there's any issue we'll automatically route queries",
    "start": "214040",
    "end": "220280"
  },
  {
    "text": "to an area where we do have access to capacity similarly your data is stored in S3 S3 is highly available and that's",
    "start": "220280",
    "end": "226959"
  },
  {
    "text": "uh that's 119 by the way that's our design point from a durability perspective so your data in S3 is",
    "start": "226959",
    "end": "232480"
  },
  {
    "text": "replicated automatically for you so what this means is the compute is highly available and the data is highly",
    "start": "232480",
    "end": "237720"
  },
  {
    "text": "available so you're you have a service that will be there when you need to run a query um and this is um this is true",
    "start": "237720",
    "end": "243280"
  },
  {
    "text": "for the console it's also true when you access Athena through a SQL client like a jdbc driver enabled client and I'll",
    "start": "243280",
    "end": "249640"
  },
  {
    "text": "talk about that as well uh but our goal was that um your data is there and you can run queries when you want to uh you",
    "start": "249640",
    "end": "255760"
  },
  {
    "text": "shouldn't be affected by anything that's going on uh and then another important consideration for us was uh querying",
    "start": "255760",
    "end": "262759"
  },
  {
    "start": "258000",
    "end": "258000"
  },
  {
    "text": "data directly from S3 so we didn't want you to have to move your data at all uh we wanted you to be able to query it in",
    "start": "262759",
    "end": "268560"
  },
  {
    "text": "your raw format and we support arranger formats text CSV Json web logs uh we",
    "start": "268560",
    "end": "275400"
  },
  {
    "text": "have customers querying elb logs cloudwatch logs so really every log that a service generates can sit in S3 you",
    "start": "275400",
    "end": "282080"
  },
  {
    "text": "can define a schema on it using Hive and uh begin running SQL queries against it",
    "start": "282080",
    "end": "287800"
  },
  {
    "text": "and uh if you convert your data to an optimized form so that's orc and paret",
    "start": "287800",
    "end": "292919"
  },
  {
    "text": "these are open source data formats that are columnar and that they support compression so this gets you better",
    "start": "292919",
    "end": "298759"
  },
  {
    "text": "performance uh it also lowers your query cost and I'll talk about the pricing model for atha in just a second so what",
    "start": "298759",
    "end": "305199"
  },
  {
    "text": "this means from our customers perspective is there's no data transformation needed uh there's nothing",
    "start": "305199",
    "end": "310479"
  },
  {
    "text": "ever stored anywhere in a cluster you're streaming data directly from S3 uh and this um this allows you to have S3 as",
    "start": "310479",
    "end": "317600"
  },
  {
    "text": "your primary data store backing everything so you get durability and availability for free uh there's also no",
    "start": "317600",
    "end": "323280"
  },
  {
    "text": "concept of loading data into Athena so there's when you're not using Athena there's no additional charge you're just paying for the data that's sitting in",
    "start": "323280",
    "end": "331639"
  },
  {
    "text": "S3 um it's anql so we use Presto as our query execution engine I'll talk about",
    "start": "331720",
    "end": "337759"
  },
  {
    "text": "about that in a second but this is an example it's unreadable but it's just designed to show you that it's a complex",
    "start": "337759",
    "end": "343720"
  },
  {
    "text": "query it's actually one of the tpch queries uh but it's got aliasing It's got multiple joins it's got subqueries",
    "start": "343720",
    "end": "350240"
  },
  {
    "text": "you can really write um pretty complex ANC squel and then with Presto there's",
    "start": "350240",
    "end": "355280"
  },
  {
    "text": "also support for window functions it's got Json functions approximation queries",
    "start": "355280",
    "end": "360800"
  },
  {
    "text": "uh so really a very powerful query engine and then we also support data partitioning in Athena so if you have",
    "start": "360800",
    "end": "366880"
  },
  {
    "text": "partition tables the idea with a partition table is think of a system with log data coming in every day you",
    "start": "366880",
    "end": "372680"
  },
  {
    "text": "might have a partition per day that gets added um as your data evolves and so Athena supports partition data out of",
    "start": "372680",
    "end": "379360"
  },
  {
    "text": "the box which means that when you're running queries against partitions it can go to the right partition rather",
    "start": "379360",
    "end": "384479"
  },
  {
    "text": "than having to read everything uh so this is a way to simplify your data operations and actually get better",
    "start": "384479",
    "end": "389639"
  },
  {
    "text": "performance and because you'll be scanning less data you you'll pay less and then Athena supports full Hive",
    "start": "389639",
    "end": "396440"
  },
  {
    "text": "partitioning so you can pick any column or set of columns to do that uh we're using familiar open",
    "start": "396440",
    "end": "404080"
  },
  {
    "start": "402000",
    "end": "402000"
  },
  {
    "text": "Technologies under the covers so we use presto presto is an in-memory distributed SQL engine that was",
    "start": "404080",
    "end": "409479"
  },
  {
    "text": "developed by Facebook it's open source uh we contribute to it and um the and",
    "start": "409479",
    "end": "415319"
  },
  {
    "text": "it's been proven out at Facebook scale so hundreds of pedabytes and that's part of the reason that we chose it it's fast",
    "start": "415319",
    "end": "421199"
  },
  {
    "text": "and it's very scalable and then we use Hive uh for defining tables this is just a standard in the Big Data world and it",
    "start": "421199",
    "end": "428680"
  },
  {
    "text": "gives you a lot of flexibility you can actually use a Rex to define a table on top of data so uh tons of flexibility in",
    "start": "428680",
    "end": "435240"
  },
  {
    "text": "defining your schemas and Athena And Hive generally use a concept called",
    "start": "435240",
    "end": "440960"
  },
  {
    "text": "schema on read so the schema is actually just metad data and when you run the query it's projected onto the query so",
    "start": "440960",
    "end": "447080"
  },
  {
    "text": "you don't have to move your data around at all and and different people can have different ways of defining tables on the",
    "start": "447080",
    "end": "452440"
  },
  {
    "text": "same data set um and they can all run their own queries as they see fit so it's a very powerful flexible system",
    "start": "452440",
    "end": "458479"
  },
  {
    "text": "that gives you a SQL interface without any need to move data around um and then because we're using",
    "start": "458479",
    "end": "465879"
  },
  {
    "text": "Hive we get access to a ton of the formats and flexibility that are supported uh I think um you know we've",
    "start": "465879",
    "end": "471800"
  },
  {
    "text": "talked about text files csvs arbitrary log files arbitrary delimiters you can use simple and nested",
    "start": "471800",
    "end": "478840"
  },
  {
    "text": "Json to directly uh we support compressed data so whether that's gzip or Snappy uh you can essentially have",
    "start": "478840",
    "end": "485720"
  },
  {
    "text": "your data compressed and we recommend that and I'll talk about um why compression is good it's really for",
    "start": "485720",
    "end": "490759"
  },
  {
    "text": "performance uh if you need to read less data to answer a query that query will complete faster and it's also for cost",
    "start": "490759",
    "end": "497759"
  },
  {
    "text": "we charge you based on the amount of data we scan so the less data we scan the less you'll pay for that query and",
    "start": "497759",
    "end": "503599"
  },
  {
    "text": "uh the columnar formats are what we recommend for use with Athena because um when you have a columnar format each",
    "start": "503599",
    "end": "510199"
  },
  {
    "text": "column in your table is stored independently so if you only query a subset of the columns we only read The",
    "start": "510199",
    "end": "515640"
  },
  {
    "text": "Columns that are relevant and so you end up saving and getting better performance so compress use columnar formats it'll",
    "start": "515640",
    "end": "522599"
  },
  {
    "text": "improve performance reduce cost and then I've already gotten uh probably several",
    "start": "522599",
    "end": "527760"
  },
  {
    "text": "dozen questions about Avro this we're getting support for Avo which is a a format that carries the schema",
    "start": "527760",
    "end": "533399"
  },
  {
    "text": "definition along with the data and that'll be coming uh pretty soon so just stay tuned uh we hear you those of you",
    "start": "533399",
    "end": "539480"
  },
  {
    "text": "you who've asked me for AO uh so we've also designed Athena to be fast this was important to us we",
    "start": "539480",
    "end": "545640"
  },
  {
    "text": "wanted to be interactive we wanted you to be able to type in a query and get back results right away and so we",
    "start": "545640",
    "end": "552240"
  },
  {
    "text": "automatically parallelize queries across multiple cores uh we stream results to the console we write also write results",
    "start": "552240",
    "end": "558959"
  },
  {
    "text": "to S3 so you can specify a result bucket uh so what this means is that you can uh run queries on data maybe you're",
    "start": "558959",
    "end": "565240"
  },
  {
    "text": "querying raw Json you'll then get a CSV written out to S3 and that can be used in a subsequent step or",
    "start": "565240",
    "end": "571519"
  },
  {
    "text": "Pipeline and um to improve performance compress use caler stores I'll I'll",
    "start": "571519",
    "end": "577399"
  },
  {
    "text": "probably talk about this a few times but um I'll show you at the end the gains can be pretty dramatic you can see 10x",
    "start": "577399",
    "end": "583120"
  },
  {
    "text": "Savings in performance and cost uh by using formats like uh orc and",
    "start": "583120",
    "end": "589480"
  },
  {
    "text": "Par uh so from a cost perspective we wanted to make Athena extremely cost effective uh when you're not using it",
    "start": "589760",
    "end": "595839"
  },
  {
    "start": "590000",
    "end": "590000"
  },
  {
    "text": "there's no charge uh there's no hourly charge or anything like that you're only charged when you run a query we charge 5",
    "start": "595839",
    "end": "602880"
  },
  {
    "text": "terabyte uh sorry $5 per terabyte scanned from S3 um and so uh and we also don't charge",
    "start": "602880",
    "end": "610399"
  },
  {
    "text": "you for ddl queries if you're defining tables if queries fail you're not charged for those and uh when you",
    "start": "610399",
    "end": "617040"
  },
  {
    "text": "compress data because we charge based on the volume scanned if you think about it if you have a terabyte table and you",
    "start": "617040",
    "end": "622440"
  },
  {
    "text": "have to scan the entire ter table that's a terabyte if you compress that table and it takes up and you get 5 to one",
    "start": "622440",
    "end": "628880"
  },
  {
    "text": "compression you're not going to scan a terab you'll scan 200 GB you'll pay 1 of the cost for",
    "start": "628880",
    "end": "634000"
  },
  {
    "text": "that same query just by compressing your data and then column formats get you even more efficiency if you imagine a",
    "start": "634000",
    "end": "640600"
  },
  {
    "text": "table with five columns uh you compressed it so you get a factor of Five Savings there if you only read one",
    "start": "640600",
    "end": "646600"
  },
  {
    "text": "column in your query because that's all you cared about you wanted to sum the sales for example over the past month you'd read 1/ fifth of the data so that",
    "start": "646600",
    "end": "653040"
  },
  {
    "text": "query would actually be 10 times H sorry one 1/5 of 1/5 so 125th of the initial",
    "start": "653040",
    "end": "658360"
  },
  {
    "text": "cost and that's uh dramatic savings from that perspective so if you do some work on compression uh you'll get uh dramatic",
    "start": "658360",
    "end": "665200"
  },
  {
    "text": "savings on the back end uh so let's talk about how this might be put into use so imagine data",
    "start": "665200",
    "end": "671320"
  },
  {
    "start": "667000",
    "end": "667000"
  },
  {
    "text": "sources this could be mobile devices this could be web application servers they're generating log files those log",
    "start": "671320",
    "end": "677440"
  },
  {
    "text": "files can go onto S3 uh you might use EMR to transform those log files into a form that's ready for inest into",
    "start": "677440",
    "end": "683959"
  },
  {
    "text": "redshift which is our data warehouse Service uh red shift's uh favorite data formats for gestion or compressed csvs",
    "start": "683959",
    "end": "691680"
  },
  {
    "text": "so you might see your Json being transformed into that form and then being brought into red shift and then",
    "start": "691680",
    "end": "696760"
  },
  {
    "text": "you might do some visualization using quick site uh which is our visualization um webbased visualization if you're not",
    "start": "696760",
    "end": "703560"
  },
  {
    "text": "familiar with it so how you how would you plug Athena into this uh there's a couple of places you could have ad hoc",
    "start": "703560",
    "end": "709880"
  },
  {
    "text": "SQL access to your raw data again there's no charge when you're not using it so you would just Define tables um",
    "start": "709880",
    "end": "716000"
  },
  {
    "text": "and then you can query that data whenever you want the instant it came in uh you might you can also choose to use",
    "start": "716000",
    "end": "721680"
  },
  {
    "text": "Athena on your compressed csvs when they're going into red shift so maybe you've done some D duping some sessionization and you've got that data",
    "start": "721680",
    "end": "728800"
  },
  {
    "text": "ready to go you can query it directly there and then we integrate with quick site as well so you can use Quick site",
    "start": "728800",
    "end": "734279"
  },
  {
    "text": "to visualize data in S3 through Athena's the query engine underneath so that gives you access to things like Json",
    "start": "734279",
    "end": "740760"
  },
  {
    "text": "parket files all of that so we wanted to make it as simple as possible to slot this into your existing data flows",
    "start": "740760",
    "end": "749959"
  },
  {
    "start": "749000",
    "end": "749000"
  },
  {
    "text": "uh so when we talk about some of the challenges that customers uh were facing we really wanted to make sure we addressed all of them so we want people",
    "start": "750040",
    "end": "756240"
  },
  {
    "text": "to be able to query without doing any data loading or data transformation uh we wanted people to",
    "start": "756240",
    "end": "761720"
  },
  {
    "text": "not just have access to aggregated data sets but also to their raw data and so Athena allows you to do that and we took",
    "start": "761720",
    "end": "768399"
  },
  {
    "text": "away all of the infrastructure to manage it on your behalf so essentially what you get is you log in and you run a",
    "start": "768399",
    "end": "774120"
  },
  {
    "text": "query and you get results uh so let's talk about what the workflow is to actually use uh Athena",
    "start": "774120",
    "end": "781720"
  },
  {
    "text": "Has anyone used it yet tried it yet few people okay uh so essentially when you",
    "start": "781720",
    "end": "787160"
  },
  {
    "text": "log into the console what you get is a very simple clean SQL client uh so",
    "start": "787160",
    "end": "792560"
  },
  {
    "text": "you've got a query editor it has keyboard binding so you can hit control enter and run your query um it's got a",
    "start": "792560",
    "end": "799160"
  },
  {
    "text": "result window Bel beneath it and then your database and tables are on the left hand side so simple three pain system if",
    "start": "799160",
    "end": "805360"
  },
  {
    "text": "anyone's used desktop SQL clients it'll feel very familiar",
    "start": "805360",
    "end": "810560"
  },
  {
    "text": "um when you um the query editor has autocomplete it also has SQL formatting so you can just paste in SQL format it",
    "start": "810560",
    "end": "817279"
  },
  {
    "text": "um you can use autocomplete for table and columns and um uh the catalog itself",
    "start": "817279",
    "end": "823079"
  },
  {
    "text": "is where you store your table definitions and metadata so uh you create a concept called a database this",
    "start": "823079",
    "end": "828720"
  },
  {
    "text": "is just a collection of metadata and then you create a table definition underneath that and that contains the",
    "start": "828720",
    "end": "834519"
  },
  {
    "text": "row the column structure of your table and you can click into it and you can see um all of the columns that go into",
    "start": "834519",
    "end": "841199"
  },
  {
    "text": "the table uh beneath that so again a very familiar interface from a data catalog and data browsing",
    "start": "841199",
    "end": "848240"
  },
  {
    "text": "perspective and if you click in you can start to there's a data catalog manager so you could start to see details about",
    "start": "848240",
    "end": "854000"
  },
  {
    "text": "your columns how they're defined and if you click further you can see more",
    "start": "854000",
    "end": "859160"
  },
  {
    "text": "detail about where the files backing that table definition actually live so in this case you can see that these are",
    "start": "859160",
    "end": "864839"
  },
  {
    "text": "cloudfront logs you can see the location is on S3 um and essentially the table metadata is just a schema that's",
    "start": "864839",
    "end": "871000"
  },
  {
    "text": "projected onto the DAT that S3 object unmodified at query",
    "start": "871000",
    "end": "876920"
  },
  {
    "text": "time and then when you run a query um you just run it in the SQL editor you'll",
    "start": "877720",
    "end": "883079"
  },
  {
    "text": "get back results streamed to the console those results are also written to a results bucket on S3 and um you know",
    "start": "883079",
    "end": "889880"
  },
  {
    "text": "that's where you can go if you want to actually use the output of those results we also have a download to desktop uh",
    "start": "889880",
    "end": "895000"
  },
  {
    "text": "capability so if you're you can if you want the results as a CSV on your laptop you can do that as",
    "start": "895000",
    "end": "900880"
  },
  {
    "text": "well and uh we also ship with a free jdbc driver out of the box so you can",
    "start": "900880",
    "end": "906120"
  },
  {
    "start": "901000",
    "end": "901000"
  },
  {
    "text": "connect it to your cql client I think these are screenshots of SQL workbench uh which is a free client and um",
    "start": "906120",
    "end": "912800"
  },
  {
    "text": "essentially you'd be downloading the driver configuring your client to use it and then this allows you to then run SQL",
    "start": "912800",
    "end": "918160"
  },
  {
    "text": "queries against Athena uh from a laptop or any device that you have and um even",
    "start": "918160",
    "end": "924480"
  },
  {
    "text": "though you're using a familiar SQL client you're actually connecting to the Athena service so you're not connect conting to an actual physical database",
    "start": "924480",
    "end": "931440"
  },
  {
    "text": "of some sorts you get all the benefits of high availability all your data is there uh you get all of the Power of",
    "start": "931440",
    "end": "936680"
  },
  {
    "text": "Athena just connected to it directly from a laptop uh or other",
    "start": "936680",
    "end": "941800"
  },
  {
    "text": "system um and then we wanted to make uh Athena straightforward to use with quick site um so quick site is our uh",
    "start": "941800",
    "end": "948440"
  },
  {
    "text": "visualization service at AWS so this makes it easy to visualize data in adws data sources and um quick site can",
    "start": "948440",
    "end": "956079"
  },
  {
    "text": "autodiscover your data sources in AWS and then it allows you to pick them bring them into Quick site and then",
    "start": "956079",
    "end": "961839"
  },
  {
    "text": "interact with them visually and so when you log into Quick",
    "start": "961839",
    "end": "967160"
  },
  {
    "text": "site you get a very straightforward um interface with the ability to pick your AWS data sources quick site can bring in",
    "start": "967160",
    "end": "973519"
  },
  {
    "text": "data directly from S3 or RDS or red shift uh Athena is also available and so",
    "start": "973519",
    "end": "979120"
  },
  {
    "text": "if you click that you essentially Define a name for your Athena data source and then you can go into it and",
    "start": "979120",
    "end": "985519"
  },
  {
    "text": "pick the tables that you want quick site to have access to uh and once that's done you can uh there's a concept in",
    "start": "985519",
    "end": "992560"
  },
  {
    "text": "quick site called spice this is a an in-memory layer that can you can stage your data in that for super fast access",
    "start": "992560",
    "end": "998800"
  },
  {
    "text": "to it uh but you can also use Athena in a direct query mode and run queries directly against data in S3 uh perhaps",
    "start": "998800",
    "end": "1005199"
  },
  {
    "text": "accessing data sets that might be too big to bring into spice for example and then once you're done with",
    "start": "1005199",
    "end": "1010880"
  },
  {
    "text": "that you have visual access to all of your data in S3 again with nothing to manage so it's a very powerful way to",
    "start": "1010880",
    "end": "1016720"
  },
  {
    "text": "get access uh this is a flight database um and you can uh quickly design",
    "start": "1016720",
    "end": "1021920"
  },
  {
    "text": "dashboards drag and drop and essentially what you're doing each time you modify is you're under interacting with your",
    "start": "1021920",
    "end": "1027798"
  },
  {
    "text": "data in S3 via Athena so anything that you can query with Athena you can visualize in quick",
    "start": "1027799",
    "end": "1035120"
  },
  {
    "text": "site and then with jdpc drivers um we've also designed these if you want to run",
    "start": "1035480",
    "end": "1041120"
  },
  {
    "text": "automation you want to Design programmatic Systems this is just sample Java code in our documentation this",
    "start": "1041120",
    "end": "1047160"
  },
  {
    "text": "allows you to set up automation so you can build systems um for example there",
    "start": "1047160",
    "end": "1052679"
  },
  {
    "text": "might be a scenario where you've got data that arrives in S3 you might want to generate a Lambda event when that data arrives and that Lambda event could",
    "start": "1052679",
    "end": "1060080"
  },
  {
    "text": "use the jdbc driver to update Athena's catalog to say that there's a new Partition um and so that data is then",
    "start": "1060080",
    "end": "1065960"
  },
  {
    "text": "available to be queried by whoever is using Athena and this is um sample Java code",
    "start": "1065960",
    "end": "1071200"
  },
  {
    "text": "we also have the ability for you to provide your own signer class so you don't have to use your AWS secret key in",
    "start": "1071200",
    "end": "1077280"
  },
  {
    "text": "credentials you can actually just use something to deliver assigned request using Im so uh those of you that are",
    "start": "1077280",
    "end": "1082880"
  },
  {
    "text": "experienced with automation on AWS um that capability is also there uh for you to use uh but this is as you can see",
    "start": "1082880",
    "end": "1089480"
  },
  {
    "text": "it's a very standard jdbc setup username password you define the output location",
    "start": "1089480",
    "end": "1094640"
  },
  {
    "text": "for your query results uh and then you can start and create a jdbc",
    "start": "1094640",
    "end": "1100080"
  },
  {
    "text": "connection and so this is just an example if you're creating a table uh you can see that you're basically",
    "start": "1100080",
    "end": "1105480"
  },
  {
    "text": "setting up a statement uh you're defining then a call to to Athena and",
    "start": "1105480",
    "end": "1110960"
  },
  {
    "text": "passing it the SQL and it's going to create a table it's got the S3 location there and once you do this this table",
    "start": "1110960",
    "end": "1117200"
  },
  {
    "text": "would then show up in the Athena catalog if you were to refresh the console or look at it on your uh database side and",
    "start": "1117200",
    "end": "1123640"
  },
  {
    "text": "then executing a query same sort of thing so you can build applications that programmatically have access to uh to",
    "start": "1123640",
    "end": "1129280"
  },
  {
    "text": "Athena using this system so let's talk about creating tables and how this process",
    "start": "1129280",
    "end": "1136480"
  },
  {
    "text": "works uh so we use hive ddl just folks familiar with Hive in the",
    "start": "1136480",
    "end": "1141679"
  },
  {
    "start": "1137000",
    "end": "1137000"
  },
  {
    "text": "room okay handful that's pretty good uh so Hive it's an Apache project it was um",
    "start": "1141679",
    "end": "1148640"
  },
  {
    "text": "one of the original analytic systems there and its uh Hive statements can be submitted directly to Athena so you can",
    "start": "1148640",
    "end": "1154919"
  },
  {
    "text": "punch them into the query window so if you have existing uh Hive based ddl infrastructure which you likely do if",
    "start": "1154919",
    "end": "1161280"
  },
  {
    "text": "you're using any of the Big Data stack that all of those ddl statements can just be pasted in uh it looks a lot like",
    "start": "1161280",
    "end": "1167840"
  },
  {
    "text": "SQL and it's schema on read so this is that concept of projecting schema at",
    "start": "1167840",
    "end": "1173000"
  },
  {
    "text": "query runtime uh and completely independently of the underlying data format and uh the external Concept in",
    "start": "1173000",
    "end": "1180600"
  },
  {
    "text": "Hive external tables are considered unmanaged by the system what that means is when you delete external tables from",
    "start": "1180600",
    "end": "1187360"
  },
  {
    "text": "Athena it has no impact on your data in S3 and so this is because we wanted to",
    "start": "1187360",
    "end": "1192480"
  },
  {
    "text": "focus on providing a read readon query service not anything that would modify your data in S3 uh so we only support",
    "start": "1192480",
    "end": "1199200"
  },
  {
    "text": "external tables in Athena and that's by Design we don't want you to be able to modify anything uh from this system it's",
    "start": "1199200",
    "end": "1205159"
  },
  {
    "text": "really designed for query uh big range of data formats uh that uh Sur is a",
    "start": "1205159",
    "end": "1211120"
  },
  {
    "text": "concept in Hive it stands for serializer and deserializer uh we ship with a range of",
    "start": "1211120",
    "end": "1216880"
  },
  {
    "text": "these essentially this is code that allows the system using the table to understand how to read and write from",
    "start": "1216880",
    "end": "1222799"
  },
  {
    "text": "that underlying data source and so um we have serializers and deserializers for",
    "start": "1222799",
    "end": "1227960"
  },
  {
    "text": "things like Jon as I mentioned we'll be adding it for Avro uh so your data always lives in S3",
    "start": "1227960",
    "end": "1234919"
  },
  {
    "text": "and then the metadata which is the table definition that's stored in Athena's internal catalog that also is highly",
    "start": "1234919",
    "end": "1240480"
  },
  {
    "text": "available uh and scalable so the internal metadata store",
    "start": "1240480",
    "end": "1245960"
  },
  {
    "start": "1244000",
    "end": "1244000"
  },
  {
    "text": "this is our internal catalog um this is what you see on the left pane uh of the console when you log in and all your",
    "start": "1245960",
    "end": "1252400"
  },
  {
    "text": "table definitions are stored here so tables columns partition data uh this a highly available Autos scaling system so",
    "start": "1252400",
    "end": "1259840"
  },
  {
    "text": "every element of the service is highly available uh there's nothing for you to manage you just enter your tables you",
    "start": "1259840",
    "end": "1265000"
  },
  {
    "text": "can uh click on the I icon to see uh get the table effectively just listed in the",
    "start": "1265000",
    "end": "1271120"
  },
  {
    "text": "console and you can click on the properties to see more details on that table like what when it was updated",
    "start": "1271120",
    "end": "1277480"
  },
  {
    "text": "where it's stored on S3 Etc and um it's Hive metast stor compatible so if anyone's using Hive",
    "start": "1277480",
    "end": "1283919"
  },
  {
    "text": "metast Stores um essentially everything that you do in that world you can do um in the Athena catalog from a ddl",
    "start": "1283919",
    "end": "1291960"
  },
  {
    "text": "perspective so when you're running queries it's uh straightforward this just shows the console query window",
    "start": "1291960",
    "end": "1297480"
  },
  {
    "text": "expanded uh to cover the full console it hides the table structure uh you paste in or type in SQL you can then uh uh hit",
    "start": "1297480",
    "end": "1306000"
  },
  {
    "text": "run it'll run the query you'll get back results we what we show you in the console and in the history is the query",
    "start": "1306000",
    "end": "1312360"
  },
  {
    "text": "run time how long it took to execute uh we also show you the amount of data scanned and the data scanned is really",
    "start": "1312360",
    "end": "1319000"
  },
  {
    "text": "all we had to read from S3 to respond to to generate the query results and that's",
    "start": "1319000",
    "end": "1324159"
  },
  {
    "text": "the unit of billing for uh for Athena there's no charge for anything else and um when we run queries we",
    "start": "1324159",
    "end": "1331880"
  },
  {
    "text": "automatically save the results to S3 and in the query History part of Athena uh which I guess I'll show you in a second",
    "start": "1331880",
    "end": "1338320"
  },
  {
    "text": "there's a history of all the queries that have been run and if you click on the results that show next to that we",
    "start": "1338320",
    "end": "1343679"
  },
  {
    "text": "show you the historical results from S3 of that query execution and then then uh when we talk",
    "start": "1343679",
    "end": "1349360"
  },
  {
    "text": "about columna formats I'm spending time on this just because I think it's important uh because it can help you",
    "start": "1349360",
    "end": "1354679"
  },
  {
    "text": "with performance as well as manage costs so park and orc are columna formats",
    "start": "1354679",
    "end": "1360400"
  },
  {
    "text": "they're open source they're part of the Apache ecosystem and um with Park this is a a",
    "start": "1360400",
    "end": "1366520"
  },
  {
    "text": "column columna format so data is stored in columns if you have a table with five columns it'll actually generate five",
    "start": "1366520",
    "end": "1372960"
  },
  {
    "text": "files underneath it and each column is stored separately and um the follows",
    "start": "1372960",
    "end": "1379279"
  },
  {
    "text": "along with the uh with the data itself and it's got built-in compression and it's got buil-in information about",
    "start": "1379279",
    "end": "1385919"
  },
  {
    "text": "what's in the actual columns so if you're doing things like counts doesn't have to read all of the data it stores",
    "start": "1385919",
    "end": "1391080"
  },
  {
    "text": "that information stores min max values uh and so what this means is when you're running queries it can optimize and",
    "start": "1391080",
    "end": "1398600"
  },
  {
    "text": "decide not to read things in order to respond to those queries if that metadata is available to it and then",
    "start": "1398600",
    "end": "1404080"
  },
  {
    "text": "predicate push down means that if you have filters on your on your data so you're looking for a date range perhaps",
    "start": "1404080",
    "end": "1409279"
  },
  {
    "text": "it can actually use that to eliminate things to scan so again we're trying to be as efficient as possible and read as",
    "start": "1409279",
    "end": "1415400"
  },
  {
    "text": "little as possible in order to return the results of the query and the less we read the less that query costs and",
    "start": "1415400",
    "end": "1421600"
  },
  {
    "text": "that's why we've spent a bunch of time uh trying to make sure that we can use data from S3 efficiently similarly orc",
    "start": "1421600",
    "end": "1428000"
  },
  {
    "text": "is just another choice of format that you uh can pick and um this is also a top level project in Apache similar idea",
    "start": "1428000",
    "end": "1435919"
  },
  {
    "text": "built-in compression it's a column format and it also supports predicate push down so it's really just a choice",
    "start": "1435919",
    "end": "1441480"
  },
  {
    "text": "if you standardize or one or the other uh you can use that essentially as with all things related to databases uh you",
    "start": "1441480",
    "end": "1447640"
  },
  {
    "text": "want to be testing to see which formats will give you the best performance with your data uh but that's all uh supported",
    "start": "1447640",
    "end": "1454640"
  },
  {
    "text": "natively and if you're converting data so you might have Json and you want to convert it into uh one of these",
    "start": "1454640",
    "end": "1460559"
  },
  {
    "start": "1455000",
    "end": "1455000"
  },
  {
    "text": "optimized formats like orc and Par Hive has a create table statement so that c",
    "start": "1460559",
    "end": "1466000"
  },
  {
    "text": "Taz stands for create table as select so essentially you're querying one table and then you're writing it into a form",
    "start": "1466000",
    "end": "1473120"
  },
  {
    "text": "and with Hive you can pick how to store that data so in this case it's stored as parket and you can run a select query",
    "start": "1473120",
    "end": "1479520"
  },
  {
    "text": "and the output of that query will be written into S3 in a parket form uh you can also use things like spark on EMR to",
    "start": "1479520",
    "end": "1486279"
  },
  {
    "text": "convert that data we've published uh some very simple code on github's completely open source that shows how",
    "start": "1486279",
    "end": "1491840"
  },
  {
    "text": "you can convert files into park and orc and uh it's about 20 lines of python and",
    "start": "1491840",
    "end": "1497880"
  },
  {
    "text": "this can convert a terabyte of text into 130 gigs of data on parquet and using a",
    "start": "1497880",
    "end": "1503360"
  },
  {
    "text": "compression technique called Snappy and uh the cost for this is five bucks so you can do it's a lowcost scale",
    "start": "1503360",
    "end": "1510120"
  },
  {
    "text": "out scalable way and if you already have existing Big Data workflows uh choosing to convert to parket is uh is pretty",
    "start": "1510120",
    "end": "1518480"
  },
  {
    "text": "straightforward uh so diving into cost a little bit uh so what we do with Athena",
    "start": "1518480",
    "end": "1523520"
  },
  {
    "text": "is we want you to only pay for when you're using the service to run queries so that means means you could provide",
    "start": "1523520",
    "end": "1528960"
  },
  {
    "text": "Athena to everyone in the organization but only when they run a query you actually pay anything for it uh we",
    "start": "1528960",
    "end": "1534399"
  },
  {
    "text": "charge based on the amount of data scanned so it's $5 per terabyte scanned",
    "start": "1534399",
    "end": "1539679"
  },
  {
    "text": "um and you can save money by compression using column stores using partitions and",
    "start": "1539679",
    "end": "1545320"
  },
  {
    "text": "the way you save is that every every one of these steps means that we read less data and uh again there aren't any",
    "start": "1545320",
    "end": "1551679"
  },
  {
    "text": "charges for data ddl queries or for failed queries if you do cancel a query we will create a charge for the amount",
    "start": "1551679",
    "end": "1558120"
  },
  {
    "text": "of data scanned up to that point so uh that's one thing to just keep in mind",
    "start": "1558120",
    "end": "1563279"
  },
  {
    "text": "and I I just wanted to show you in this example what we're doing here so the query on the top right is a pretty simple select and aggregate uh it's",
    "start": "1563279",
    "end": "1570559"
  },
  {
    "text": "going to about four columns the actual table this is on I think these are um elb log files elastic load balancer logs",
    "start": "1570559",
    "end": "1577720"
  },
  {
    "text": "there about 30 or so columns in the table so if you had the data stored as",
    "start": "1577720",
    "end": "1582840"
  },
  {
    "text": "text files uh they take up about a terabyte uncompressed running that query",
    "start": "1582840",
    "end": "1588320"
  },
  {
    "text": "on this data um in this example took uh 200 odd seconds and it scanned 1.15",
    "start": "1588320",
    "end": "1594559"
  },
  {
    "text": "terabytes so at $5 a terabyte the cost for that query is $5.75 uh if you converted that data into",
    "start": "1594559",
    "end": "1601919"
  },
  {
    "text": "Power K columnar and compressed uh it takes up about 130 gigb",
    "start": "1601919",
    "end": "1608159"
  },
  {
    "text": "on S3 so you're saving on your S3 costs the query runtime for this query scanning only four of the columns 5.13",
    "start": "1608159",
    "end": "1616320"
  },
  {
    "text": "seconds so uh dramatic ially faster almost 34x 34 times faster and then it's",
    "start": "1616320",
    "end": "1622799"
  },
  {
    "text": "scanning much less data instead of U 1.15 terabytes instead of a th000 plus gigabytes it's scanning only uh 2.7",
    "start": "1622799",
    "end": "1630799"
  },
  {
    "text": "gigabytes uh so it's about 99% less data is being scanned uh and so you've got a",
    "start": "1630799",
    "end": "1636279"
  },
  {
    "text": "query that cost that the same query on the same data getting back the same results if it's uncompressed TX you're",
    "start": "1636279",
    "end": "1642559"
  },
  {
    "text": "paying five bucks in change uh if you're running against paret it's costing you 1.3 C uh so please compress your data",
    "start": "1642559",
    "end": "1650360"
  },
  {
    "text": "use columna formats for data you query often so I want to talk to you about a",
    "start": "1650360",
    "end": "1656880"
  },
  {
    "text": "few customer use cases I also want to explain a little bit how we think about um Athena fitting into our ecosystem at",
    "start": "1656880",
    "end": "1664279"
  },
  {
    "text": "AWS so uh quick site is our visualization service it can query data from any of these systems it can also",
    "start": "1664279",
    "end": "1670519"
  },
  {
    "text": "load data directly from S3 and that gives you interactive visual queri ability for your data so you can play",
    "start": "1670519",
    "end": "1677039"
  },
  {
    "text": "with dashboards you can share dashboards with others in your company and um that makes it just very easy to consume uh",
    "start": "1677039",
    "end": "1684399"
  },
  {
    "text": "red shift is our pyte scale data warehousing service so if you're uh it's",
    "start": "1684399",
    "end": "1689760"
  },
  {
    "text": "essentially allows you to store two pedabytes of compressed data in a single cluster and redshift is our highest",
    "start": "1689760",
    "end": "1695120"
  },
  {
    "text": "performance SQL engine so if you're running very complex queries on structured data sets you'll get the best",
    "start": "1695120",
    "end": "1700519"
  },
  {
    "text": "performance out of redshift and it's great for large scale data warehousing uh emrs are Hadoop and Spark service and",
    "start": "1700519",
    "end": "1708279"
  },
  {
    "text": "that also interacts directly with S3 and it also supports a broad range of Open Source projects I think there's 16 out",
    "start": "1708279",
    "end": "1714399"
  },
  {
    "text": "of the box and you can run whatever you want and this is great for scenarios where you're not just doing SQL you",
    "start": "1714399",
    "end": "1719880"
  },
  {
    "text": "could be doing machine learning you might be using spark to do some of that um and so EMR gives you that capability",
    "start": "1719880",
    "end": "1726559"
  },
  {
    "text": "and then Athena sits alongside this um and gives you access to your data in S3 and it's for as a query service when you",
    "start": "1726559",
    "end": "1732880"
  },
  {
    "text": "just want to run ad hoc queries and you don't want to take the time to load or manage this data into the systems um",
    "start": "1732880",
    "end": "1739159"
  },
  {
    "text": "Athena is for you so it fits in there uh so these are some of customers",
    "start": "1739159",
    "end": "1744200"
  },
  {
    "start": "1742000",
    "end": "1742000"
  },
  {
    "text": "that been using Athena in the private beta live intent has um targeted email marketing uh they look at um events",
    "start": "1744200",
    "end": "1751360"
  },
  {
    "text": "clicks how people are interacting with those systems JW player is a video player and video advertising analytics",
    "start": "1751360",
    "end": "1758279"
  },
  {
    "text": "uh we'll talk about data zoo in just a second they're a real-time ad bidding platform and then you have uh ginosi",
    "start": "1758279",
    "end": "1764399"
  },
  {
    "text": "which is a a curated News application provider in Japan uh News Corp is a diversified media",
    "start": "1764399",
    "end": "1770519"
  },
  {
    "text": "conglomerate Japan taxi uses this NASDAQ I'm sure you're all familiar with and then inrix his use case is pretty",
    "start": "1770519",
    "end": "1776919"
  },
  {
    "text": "interesting they provide real-time traffic information and they actually have logs about their traffic tiles and",
    "start": "1776919",
    "end": "1782159"
  },
  {
    "text": "map tiles uh sitting in S3 and they use Athena to query that uh so here's an example of data Zoo",
    "start": "1782159",
    "end": "1789320"
  },
  {
    "text": "so data zoo is um a real-time ad bidding platform so if you're not familiar with this what this allows you to do is",
    "start": "1789320",
    "end": "1795440"
  },
  {
    "text": "essentially every time you look at a display ad on a web page online uh as that page loads uh you know dozens of",
    "start": "1795440",
    "end": "1802559"
  },
  {
    "text": "companies are essentially bidding for the right to show you the ad that goes on that page and that add and bid and",
    "start": "1802559",
    "end": "1808960"
  },
  {
    "text": "serving has to happen inside of 100 milliseconds end to end and so data Zoo",
    "start": "1808960",
    "end": "1814000"
  },
  {
    "text": "does about three million of these bid requests per second uh they generate about three pedabytes of raw log data",
    "start": "1814000",
    "end": "1820440"
  },
  {
    "text": "per day this compresses down to 180 terabytes of log data in S3 per day and",
    "start": "1820440",
    "end": "1825720"
  },
  {
    "text": "so this comes in through Kinesis which is our realtime streaming ingestion layer um and to give you some context if",
    "start": "1825720",
    "end": "1832000"
  },
  {
    "text": "you wanted to capture all of Twitter in Kinesis so 500 million tweets a day it would cost you about 76 cents an hour",
    "start": "1832000",
    "end": "1839080"
  },
  {
    "text": "it's a very lowcost high scale system uh they then transform that log data and load it onto S3 and they have custom",
    "start": "1839080",
    "end": "1845600"
  },
  {
    "text": "visualization that they've built uh they're now querying that data uh directly with uh with Amazon Athena and",
    "start": "1845600",
    "end": "1851679"
  },
  {
    "text": "they also use red shift to provide operational reporting on this so it's um it's exciting to see Athena being used",
    "start": "1851679",
    "end": "1858279"
  },
  {
    "text": "at high scale in this way but it also can be used um really for very simple use cases as well designed to go um",
    "start": "1858279",
    "end": "1864760"
  },
  {
    "text": "against data of any size uh but I think one of my favorite things is uh this tweet came through",
    "start": "1864760",
    "end": "1870760"
  },
  {
    "text": "yesterday I don't think Andy's keynote had finished yet and um uh this person was already up and running analyzing",
    "start": "1870760",
    "end": "1877159"
  },
  {
    "text": "their performance logs using athenon S3 and as uh you know the GM for the service it's really gratifying to see a",
    "start": "1877159",
    "end": "1882799"
  },
  {
    "text": "customer able to take advantage of it within an hour of it being out",
    "start": "1882799",
    "end": "1888120"
  },
  {
    "text": "uh and so thank you very much uh it's uh we're a little early we've got got time for questions uh if there any but thanks",
    "start": "1888120",
    "end": "1894720"
  },
  {
    "text": "very much for your attention",
    "start": "1894720",
    "end": "1898240"
  }
]
[
  {
    "start": "0",
    "end": "33000"
  },
  {
    "text": "yeah all right so hey welcome everybody so yeah Dave McGowan with cabbage so",
    "start": "60",
    "end": "5069"
  },
  {
    "text": "this is going to be more of like a story so hopefully we can use this to help",
    "start": "5069",
    "end": "10469"
  },
  {
    "text": "teach some other people other people are probably going to be in the middle of this process some people might be at the beginning of",
    "start": "10469",
    "end": "15870"
  },
  {
    "text": "this journey and some people might be at the end but the idea is towards the end of this there'll be some lessons learned",
    "start": "15870",
    "end": "21570"
  },
  {
    "text": "to hopefully help save some other companies some time and avoid some",
    "start": "21570",
    "end": "27000"
  },
  {
    "text": "headaches and pains that we went through so this is about our long strange trip to data DeMarcos Asian so a little bit",
    "start": "27000",
    "end": "35399"
  },
  {
    "start": "33000",
    "end": "70000"
  },
  {
    "text": "to get started I'm going to talk a little bit about cabbage first just so you have a little bit of context and kind of what our company does so",
    "start": "35399",
    "end": "42590"
  },
  {
    "text": "basically cabbage started with the idea that you know with access to data we",
    "start": "42590",
    "end": "48570"
  },
  {
    "text": "could help small businesses through lending and so that was basically how the company started it was using a set",
    "start": "48570",
    "end": "54930"
  },
  {
    "text": "of API is connecting out to PayPal connecting out to Amazon connecting out to eBay pulling data running models and",
    "start": "54930",
    "end": "62250"
  },
  {
    "text": "you know basically creating you know models that came up with a probability of default to help with a lending",
    "start": "62250",
    "end": "68460"
  },
  {
    "text": "process but we pretty quickly realized that we could do more and so we started",
    "start": "68460",
    "end": "74549"
  },
  {
    "start": "70000",
    "end": "102000"
  },
  {
    "text": "collecting more data and then we continued to collect more data and so that led to you know automating things",
    "start": "74549",
    "end": "81119"
  },
  {
    "text": "like Identity Management and led to fraud systems and led to us leaving the",
    "start": "81119",
    "end": "86430"
  },
  {
    "text": "offline market moving into leaving the online market and going into the offline market with direct access to bank data",
    "start": "86430",
    "end": "93900"
  },
  {
    "text": "and so we started collecting a lot more data this is kind of when our problems",
    "start": "93900",
    "end": "99930"
  },
  {
    "text": "started so this is going to be counting at the beginning of our journey this",
    "start": "99930",
    "end": "105090"
  },
  {
    "start": "102000",
    "end": "173000"
  },
  {
    "text": "goes back to like 2011 2010 when we were starting things up it was really easy to",
    "start": "105090",
    "end": "110810"
  },
  {
    "text": "just sign up for best part you know just click the button click the link everything was free don't worry about it",
    "start": "110810",
    "end": "118259"
  },
  {
    "text": "you know you'll end up paying for it later but at the time it made a lot of sense so but on that there was actually",
    "start": "118259",
    "end": "126299"
  },
  {
    "text": "a good bit of value there you know it worked for cabbage you know it gave us a couple of years where you know",
    "start": "126299",
    "end": "132110"
  },
  {
    "text": "things were running very well for us so you know while you know this is somewhat of like a negative slide in somewhat of",
    "start": "132110",
    "end": "137330"
  },
  {
    "text": "a lesson you know part of what we'll get to towards the end of this deck is you",
    "start": "137330",
    "end": "143780"
  },
  {
    "text": "know what makes sense for a company in any given time and you know not to over architect things so but you know so we",
    "start": "143780",
    "end": "150980"
  },
  {
    "text": "joined Bismarck we actually ran around instances on ec2 we actually started out in AWS fairly early on this was our run",
    "start": "150980",
    "end": "158450"
  },
  {
    "text": "time database it was also our warehouse we used it for all of our data aggregation we used it pretty much for",
    "start": "158450",
    "end": "164060"
  },
  {
    "text": "everything so it was a combination of MVC and C sharp AP is an MVC front-end",
    "start": "164060",
    "end": "169670"
  },
  {
    "text": "with a single server back-end pretty quickly we realized that this was",
    "start": "169670",
    "end": "175790"
  },
  {
    "start": "173000",
    "end": "316000"
  },
  {
    "text": "limiting our data scientists as they were doing a lot of transformations and pulling data out of this sequel server",
    "start": "175790",
    "end": "181820"
  },
  {
    "text": "and having to put it in all these different locations a lot of it was ad hoc solutions like on their laptops or",
    "start": "181820",
    "end": "187550"
  },
  {
    "text": "you know ad hoc ec2 so they were bringing up in our development environments and we were kind of losing control of data integrity as well as we",
    "start": "187550",
    "end": "195200"
  },
  {
    "text": "weren't really helping to create you know a system that was really working for our data scientists and our",
    "start": "195200",
    "end": "201320"
  },
  {
    "text": "analytics teams so that's when we made the decision to start working with cloud",
    "start": "201320",
    "end": "207920"
  },
  {
    "text": "era cloud era is what we selected so this solution also worked for us for a",
    "start": "207920",
    "end": "214010"
  },
  {
    "text": "time but it also came with a whole different set of problems so it allowed",
    "start": "214010",
    "end": "219470"
  },
  {
    "text": "us to keep using our Seigle server for our relational store so you know our",
    "start": "219470",
    "end": "225320"
  },
  {
    "text": "primary transactional database system but push all of our raw API responses",
    "start": "225320",
    "end": "230480"
  },
  {
    "text": "directly into Hadoop and from there our data Sciences could do a lot more data",
    "start": "230480",
    "end": "236480"
  },
  {
    "text": "discovery with all their machine learning as they were building out their models but pretty quickly it created",
    "start": "236480",
    "end": "244610"
  },
  {
    "text": "more problems than it probably solved so it it helped the data scientist but it",
    "start": "244610",
    "end": "249830"
  },
  {
    "text": "also made it very difficult for us to get the data back out of there for our other departments such as like marketing",
    "start": "249830",
    "end": "256040"
  },
  {
    "text": "and our other systems to run analytics on these systems and so we had like there was a very specialized skill set",
    "start": "256040",
    "end": "262760"
  },
  {
    "text": "that was needed to be able to use these systems not to mention as they started to create models that used different you",
    "start": "262760",
    "end": "270050"
  },
  {
    "text": "know aggregates and different data components that were things that were not stored in our relational store we",
    "start": "270050",
    "end": "275150"
  },
  {
    "text": "had problem executing those systems in our runtime database so our runtime system was still running on sequel",
    "start": "275150",
    "end": "280760"
  },
  {
    "text": "server whereas all of our data science and analytics was running and at this Hadoop cluster we also ended up building",
    "start": "280760",
    "end": "288230"
  },
  {
    "text": "it as a physical system so that was a massive lesson learned you know a 20",
    "start": "288230",
    "end": "293690"
  },
  {
    "text": "terabytes 12 node physical cluster we grew out of it really really quickly so",
    "start": "293690",
    "end": "299690"
  },
  {
    "text": "that was a bad decision but you know we learned a lot from this and we kept",
    "start": "299690",
    "end": "305000"
  },
  {
    "text": "moving forward and so we decided you know this was the time where we knew that we needed to reaaargh things again",
    "start": "305000",
    "end": "312500"
  },
  {
    "text": "and create like another solution so we",
    "start": "312500",
    "end": "318170"
  },
  {
    "start": "316000",
    "end": "372000"
  },
  {
    "text": "started going into the world of like POC in just about everything so we continued down like can we do claude err a",
    "start": "318170",
    "end": "324350"
  },
  {
    "text": "different way you know was it just our implementation that was the problem we started you know doing a lot of work",
    "start": "324350",
    "end": "331010"
  },
  {
    "text": "with Kafka and you know some of that's with persistent streams some of that was just as a transport mechanism we we also",
    "start": "331010",
    "end": "338720"
  },
  {
    "text": "started you know looking for generic ways for data ingestion and that's where like goblin and other solutions come",
    "start": "338720",
    "end": "345170"
  },
  {
    "text": "into place there and you know we played around with for a little bit it didn't really make the list we played",
    "start": "345170",
    "end": "351860"
  },
  {
    "text": "around with Cassandra and you know so we were just basically at the end we decided that we wanted to bring in some",
    "start": "351860",
    "end": "358190"
  },
  {
    "text": "someone to kind of help us to make some of these decisions because when we put up all of our pros and cons they all",
    "start": "358190",
    "end": "365060"
  },
  {
    "text": "have pros and cons and there wasn't like a clear winner in this you know POC in",
    "start": "365060",
    "end": "370160"
  },
  {
    "text": "this bake-off so we actually ended up bringing in we actually first originally",
    "start": "370160",
    "end": "376160"
  },
  {
    "text": "we brought we did a good bit of consulting and we found it pretty unhelpful everyone was kind of pushing",
    "start": "376160",
    "end": "382610"
  },
  {
    "text": "towards you know like EMR stick with the cloud era you know stick with HDFS and it was a lot of things",
    "start": "382610",
    "end": "389169"
  },
  {
    "text": "that we already knew so we ended up actually having a higher and the higher",
    "start": "389169",
    "end": "395350"
  },
  {
    "text": "was someone that came from a bar and so we heavily invested in map R and the",
    "start": "395350",
    "end": "400720"
  },
  {
    "text": "capital architecture and we spent a good 18 months building out a POC on this",
    "start": "400720",
    "end": "408340"
  },
  {
    "text": "system and to be honest in the end while we learned a lot and there's pieces of it that we're going to continue to use",
    "start": "408340",
    "end": "414220"
  },
  {
    "text": "as will continue we realized that this also was a failure for us so one of the",
    "start": "414220",
    "end": "421479"
  },
  {
    "text": "assumptions that we made along the way was that one system which is what we",
    "start": "421479",
    "end": "427330"
  },
  {
    "text": "wanted so this data democratization also was not just about getting data to everyone in the company but it was also",
    "start": "427330",
    "end": "433210"
  },
  {
    "text": "about you know having a single source of truth of data it's where everything can feed and run off of so we tried to shove",
    "start": "433210",
    "end": "440229"
  },
  {
    "text": "all of our problems into one solution and what I would say we learned from this in a lesson that I would hope",
    "start": "440229",
    "end": "446080"
  },
  {
    "text": "others can pick up from this is that it's okay to have multiple solutions to problems you can you can still come up",
    "start": "446080",
    "end": "452770"
  },
  {
    "text": "with ways and there's some slides coming up where I'll go through some of this to still have a central data store and it",
    "start": "452770",
    "end": "459280"
  },
  {
    "text": "can still be your primary store but you don't have copies of data everywhere and you're not worried about people whether or not they're looking at the right",
    "start": "459280",
    "end": "465039"
  },
  {
    "text": "versions but trying to shove everything into a single solution was a big",
    "start": "465039",
    "end": "470349"
  },
  {
    "text": "learning that we got from this exercise not everything made sense for streams streams didn't work well for batch",
    "start": "470349",
    "end": "477180"
  },
  {
    "text": "persistent streams were a problem when it came with like European data and like right to forget and then you want to go",
    "start": "477180",
    "end": "482710"
  },
  {
    "text": "like remove a user and that users data is all mixed into a stream I don't really want to wipe the entire stream so",
    "start": "482710",
    "end": "489160"
  },
  {
    "text": "there was a lot of different problems and we had solutions for a lot of those but it was getting really complicated",
    "start": "489160",
    "end": "494260"
  },
  {
    "text": "and also when we built out this system here and well one other point on this",
    "start": "494260",
    "end": "500860"
  },
  {
    "text": "slide here is the idea was single ingestion everything run through the streams everything was going to be",
    "start": "500860",
    "end": "507099"
  },
  {
    "text": "stored in map bar and then everyone could use whatever view they wanted so if you wanted to use influx",
    "start": "507099",
    "end": "512849"
  },
  {
    "text": "you wanted to use druid you wanted to use the rain go you wanted to push it out to a Postgres database whatever you",
    "start": "512849",
    "end": "518219"
  },
  {
    "text": "wanted it was fine that all made sense on paper and in our diagrams when we started to you know outline this it was",
    "start": "518219",
    "end": "526170"
  },
  {
    "text": "like you know if the analytics team wants this type of data we can just point this you know the you know do a",
    "start": "526170",
    "end": "532950"
  },
  {
    "text": "mapper and like point it out and build them out their own schema and they can hook up their own tool to that and you",
    "start": "532950",
    "end": "537959"
  },
  {
    "text": "know everything will be great but it ends up all those departments don't really want to operational 'support all",
    "start": "537959",
    "end": "543329"
  },
  {
    "text": "those systems so we found that we moved",
    "start": "543329",
    "end": "548670"
  },
  {
    "text": "into an operational nightmare here so this map our instance was running on our own self managed ec2 instances that we",
    "start": "548670",
    "end": "554760"
  },
  {
    "text": "were running so we were in AWS we didn't have elasticity we did have scale but we",
    "start": "554760",
    "end": "560430"
  },
  {
    "text": "found out I don't say about 70% of the actual data team was spending their time",
    "start": "560430",
    "end": "567570"
  },
  {
    "text": "to an operational work updating systems patching systems keeping systems running and it was also draining my DevOps teams",
    "start": "567570",
    "end": "574230"
  },
  {
    "text": "which were also you know at the company to support all of our feature development teams and API development or",
    "start": "574230",
    "end": "579720"
  },
  {
    "text": "corporate IT systems so it was a massive drain on resources so you know one it",
    "start": "579720",
    "end": "587610"
  },
  {
    "text": "was you know we had you know three column store databases and two time series databases and five different",
    "start": "587610",
    "end": "593820"
  },
  {
    "text": "relational stores because we kind of let everyone come in with the model of if we have all the data in this centralized",
    "start": "593820",
    "end": "599370"
  },
  {
    "text": "location you can create whatever view you want that was also a bad idea so kind of along the way here I'm there",
    "start": "599370",
    "end": "606930"
  },
  {
    "text": "is an end here where we came up with a few good ideas but what this is is to be kind of like a lesson of some things",
    "start": "606930",
    "end": "612959"
  },
  {
    "text": "that we learned along the way so yeah I mean we want our data engineers like",
    "start": "612959",
    "end": "619620"
  },
  {
    "text": "adding creating features and adding business value we want them you know you know creating new systems helping the",
    "start": "619620",
    "end": "625500"
  },
  {
    "text": "data scientists create more models pushing out features to the company not running patches and updates on systems",
    "start": "625500",
    "end": "632569"
  },
  {
    "text": "so basically you know what this came up",
    "start": "632569",
    "end": "637860"
  },
  {
    "start": "633000",
    "end": "723000"
  },
  {
    "text": "with is one I'll show you this is kind of a growth that we were having this was kind of just to illustrate some of our",
    "start": "637860",
    "end": "643230"
  },
  {
    "text": "issues here we were studying around like you know 10 you know somewhere between like 8 to 12 terabytes of data 2016 we",
    "start": "643230",
    "end": "650790"
  },
  {
    "text": "started to see an uptick and then 2017 we're seeing a massive growth in the",
    "start": "650790",
    "end": "655949"
  },
  {
    "text": "amount of data that we're having to pull in like on a nightly basis and this is due to a couple of different things the",
    "start": "655949",
    "end": "661019"
  },
  {
    "text": "number of users that are signing up to our system as well as the number of data sources that were connecting to so we're",
    "start": "661019",
    "end": "666209"
  },
  {
    "text": "somewhere closer to like 150 to 200 terabytes you ever take what you count as opposed to originally when we were",
    "start": "666209",
    "end": "673649"
  },
  {
    "text": "had not having issues with our sequel server at like 5 terabytes where the data so this isn't like a massive and",
    "start": "673649",
    "end": "679110"
  },
  {
    "text": "we're not talking like cut about today to here but what the problem really was here was this growth curve and not being",
    "start": "679110",
    "end": "686639"
  },
  {
    "text": "ready for it so back to some of the things we talked about here already kind",
    "start": "686639",
    "end": "692670"
  },
  {
    "text": "of went over these operational and efficiencies and you know at the bottom really what we kind of decided was what",
    "start": "692670",
    "end": "699089"
  },
  {
    "text": "we were going for with that map our solution was something to be able to handle a scale and a growth that we actually just we didn't really need",
    "start": "699089",
    "end": "705449"
  },
  {
    "text": "right now we were solving for a problem that we didn't really have it was more towards I just saw for the next two",
    "start": "705449",
    "end": "712139"
  },
  {
    "text": "years because things are gonna change between now and then anyway and then just continue to solve for you know the",
    "start": "712139",
    "end": "718649"
  },
  {
    "text": "following two years and just try to stay ahead of it so this is kind of where we",
    "start": "718649",
    "end": "725730"
  },
  {
    "start": "723000",
    "end": "1173000"
  },
  {
    "text": "landed this is our current solution that we have in place today and again will",
    "start": "725730",
    "end": "730889"
  },
  {
    "text": "continue to iterate on it I think someone in the in the presentation before was saying you know every 12",
    "start": "730889",
    "end": "735990"
  },
  {
    "text": "months you're probably going to be doing some refactoring and there's going to be new technologies and approaches out but where we landed here is one is we came",
    "start": "735990",
    "end": "744240"
  },
  {
    "text": "to the conclusion that one system couldn't solve both of our primary problems so our primary systems have two",
    "start": "744240",
    "end": "752009"
  },
  {
    "text": "things that they do we have real-time operations that need to happen or near real-time and then we have batch",
    "start": "752009",
    "end": "757439"
  },
  {
    "text": "operations that need to happen so from a real-time perspective this is a customer comes to our website they're filling out",
    "start": "757439",
    "end": "763439"
  },
  {
    "text": "an application they're giving us authorization to data sources and by the time that they get to the end of their dashboard for a good",
    "start": "763439",
    "end": "769399"
  },
  {
    "text": "user experience you need to have you know collected all the data aggregated the data run in number of bottles",
    "start": "769399",
    "end": "775910"
  },
  {
    "text": "created all those results come up with a decision and conclusion and you need to have done all that you know pretty fast",
    "start": "775910",
    "end": "781819"
  },
  {
    "text": "like sub-second for most of those systems the limiting factor there's like rate limiting on the API is to actually",
    "start": "781819",
    "end": "787009"
  },
  {
    "text": "collect the data so when they land on the dashboard they're not waiting with like a multi minute spinner because then",
    "start": "787009",
    "end": "792319"
  },
  {
    "text": "they're just going to close the page so that's our real time problems but at the same time at scale you know I've got",
    "start": "792319",
    "end": "799220"
  },
  {
    "text": "hundreds of thousands of users and hundreds of terabytes of data where I've got it then reprocess all of those",
    "start": "799220",
    "end": "804410"
  },
  {
    "text": "customers on a nightly basis and we spent a long time trying to make one system do both of those things well as",
    "start": "804410",
    "end": "811399"
  },
  {
    "text": "opposed to just stopping and making two separate systems for each one of the use cases and ensuring that they share and",
    "start": "811399",
    "end": "817910"
  },
  {
    "text": "pull their data from the same place so that was a big change that we pulled in that we you know that we landed on is",
    "start": "817910",
    "end": "824079"
  },
  {
    "text": "create the right solution to solve the problem as opposed to trying to shove everything into one so what we've got",
    "start": "824079",
    "end": "832009"
  },
  {
    "text": "here is our real-time systems they push through Kafka you know we do also",
    "start": "832009",
    "end": "837740"
  },
  {
    "text": "directly have listeners that go out into drouin for more time-series data you know we've got Mehta Base listed out",
    "start": "837740",
    "end": "843800"
  },
  {
    "text": "here but this could just as easily be you know liked a blog or fana name your bi tool connecting in to do like you",
    "start": "843800",
    "end": "851149"
  },
  {
    "text": "know funnel metrics and marketing metrics on like time series all data but what the EMR cluster here is on that",
    "start": "851149",
    "end": "856790"
  },
  {
    "text": "real-time system is that's where we do you know data normalization data",
    "start": "856790",
    "end": "862279"
  },
  {
    "text": "transformations and that happens there we generally do that in spark and we do that in scholar at this point but it",
    "start": "862279",
    "end": "870410"
  },
  {
    "text": "writes its results out to Aurora so and then from Aurora we can also give",
    "start": "870410",
    "end": "875480"
  },
  {
    "text": "analytics back out to the company but this also can be you know connections from our data systems and our API is in",
    "start": "875480",
    "end": "881029"
  },
  {
    "text": "our real-time system so this graph doesn't kind of represent everything it's more showing",
    "start": "881029",
    "end": "886259"
  },
  {
    "text": "they analytic side of things so that was a big surprise for us is when we started",
    "start": "886259",
    "end": "893100"
  },
  {
    "text": "a lot of this we were pretty certain that we weren't going to end on storing things back in a relational store when",
    "start": "893100",
    "end": "899279"
  },
  {
    "text": "we just come off having all these problems with you know the high availability and clustering issues and",
    "start": "899279",
    "end": "905100"
  },
  {
    "text": "scaling issues on our sequel server but it ends up you know storing all that data and getting a good processing layer",
    "start": "905100",
    "end": "912600"
  },
  {
    "text": "that can scale horizontally if you write the right tables and you optimize what you put into this relational store it's",
    "start": "912600",
    "end": "919769"
  },
  {
    "text": "actually one of the fastest and best ways for the analytics teams to actually do their job so that was a surprise Gus",
    "start": "919769",
    "end": "925939"
  },
  {
    "text": "this is also where Amazon from an operational standpoint really helped save us a lot of time I don't have to go",
    "start": "925939",
    "end": "933089"
  },
  {
    "text": "worrying about you know this reward cluster and upgrading the Postgres or you know I don't also have to worry",
    "start": "933089",
    "end": "938879"
  },
  {
    "text": "about going and creating my own like read replicas if I need like a read replica in another region or another zone you know the scaling of that system",
    "start": "938879",
    "end": "947339"
  },
  {
    "text": "so there are some size limitations that you have there but with our micro services approach where we're moving more towards a lot of",
    "start": "947339",
    "end": "954239"
  },
  {
    "text": "different services were a lot of different smaller databases versus one large database we're not too worried about it at least not for the next",
    "start": "954239",
    "end": "960299"
  },
  {
    "text": "couple of years and so that's kind of what we've got put in place from our real-time system now when you move into",
    "start": "960299",
    "end": "967350"
  },
  {
    "text": "our batch system it's using a lot of the same technology except it's slightly different but we've still got EMR we've",
    "start": "967350",
    "end": "974189"
  },
  {
    "text": "still got a drawer in there I've still got my sequel server everyone's probably familiar with legacy systems and it'll",
    "start": "974189",
    "end": "981119"
  },
  {
    "text": "probably be awhile around for a while but once we pull everything out of it that doesn't need to be there and we optimize it for what it was originally",
    "start": "981119",
    "end": "987660"
  },
  {
    "text": "intended to do it's not that much of a problem but we have migrated that sequel server into M AWS we're running it on",
    "start": "987660",
    "end": "996149"
  },
  {
    "text": "our own ec2 right now and eventually once we break it up we might push it into RDS but for here it doesn't really",
    "start": "996149",
    "end": "1002720"
  },
  {
    "text": "show a line but there's a line coming from both of these cabbage systems that are writing directly to s3 this is a",
    "start": "1002720",
    "end": "1009439"
  },
  {
    "text": "representation of s3 this is also a representation of sequel server here and",
    "start": "1009439",
    "end": "1014449"
  },
  {
    "text": "then from there it's also going into M and from EMR it's also using the same thing data enrichment normalization",
    "start": "1014449",
    "end": "1020850"
  },
  {
    "text": "again it lets us process large amounts of data really fast I mean the slowest",
    "start": "1020850",
    "end": "1026079"
  },
  {
    "text": "part of that is whether or not we want to pay for an always own cluster or whether not we want to bring it up on demand and wait a few minutes but from",
    "start": "1026079",
    "end": "1033400"
  },
  {
    "text": "in the batch standpoint we generally keep it cold we bring it up at night and find 850 nodes or hundred nodes or",
    "start": "1033400",
    "end": "1039100"
  },
  {
    "text": "whatever I need I fire up what I need one of our batch systems in our old process before we built this out we had",
    "start": "1039100",
    "end": "1046180"
  },
  {
    "text": "a job that was pushing 17 to 20 hours a night and once it hit 24 we were going",
    "start": "1046180",
    "end": "1051460"
  },
  {
    "text": "to have a problem and in this new arc it's actually we've got to run it in about 20 minutes so and there's further",
    "start": "1051460",
    "end": "1059200"
  },
  {
    "text": "optimizations to be done there so from there what we do for the data science",
    "start": "1059200",
    "end": "1064360"
  },
  {
    "text": "team is this data is pretty raw we do minimal normalization on it and",
    "start": "1064360",
    "end": "1069460"
  },
  {
    "text": "enrichment but we do some and we've pushed that out into different s3 buckets here and then from there we push",
    "start": "1069460",
    "end": "1076030"
  },
  {
    "text": "that out into an EMR cluster that the data scientists use and that way they get to used all their normal tools to do",
    "start": "1076030",
    "end": "1082840"
  },
  {
    "text": "all their machine learning so you know some of their stuff they're doing and MapReduce still some of they're doing in PI SPARC and you know and some are you",
    "start": "1082840",
    "end": "1089830"
  },
  {
    "text": "know doing some stuff in Scala and using various libraries and tools but at the same time at this layer where the",
    "start": "1089830",
    "end": "1096670"
  },
  {
    "text": "enrichment happened where we're writing like raw JSON out here for them to do whatever they want on this on this end",
    "start": "1096670",
    "end": "1102520"
  },
  {
    "text": "we're also still pushing things out into a defined feature in aggregate store and we're also using Aurora for that and",
    "start": "1102520",
    "end": "1109690"
  },
  {
    "text": "then we've also thrown presto Connor right here in the middle and from presto what we've given is there's a lot of",
    "start": "1109690",
    "end": "1115720"
  },
  {
    "text": "people on our analytics teams that are very familiar with sequel they were very familiar with the syntax this allows me",
    "start": "1115720",
    "end": "1121480"
  },
  {
    "text": "to you know do joins and do different connections behind the scenes with a common interface so we debated for a",
    "start": "1121480",
    "end": "1128350"
  },
  {
    "text": "while and whether or not this should be an API but we ended up with this just because of the skill sets of the people",
    "start": "1128350",
    "end": "1134020"
  },
  {
    "text": "that we had at the company and this allows them to automatically write queries and then we'll determine",
    "start": "1134020",
    "end": "1140550"
  },
  {
    "text": "where we pull the data from and if you imagine behind here if I added four or five different data sources depending on",
    "start": "1140550",
    "end": "1147570"
  },
  {
    "text": "that you know if I just give the data dictionaries to the teams here it won't really matter so the analysts don't",
    "start": "1147570",
    "end": "1153840"
  },
  {
    "text": "really have to worry what's behind the scenes here whereas the data scientists are always going to run the raw the data",
    "start": "1153840",
    "end": "1160560"
  },
  {
    "text": "scientists actually generally want to like skip all the way back to here but we saved them a good bit of time with",
    "start": "1160560",
    "end": "1166290"
  },
  {
    "text": "some enrichment in this process so this is kind of our new architecture that",
    "start": "1166290",
    "end": "1171540"
  },
  {
    "text": "we've got so a lot of this I talked",
    "start": "1171540",
    "end": "1176610"
  },
  {
    "start": "1173000",
    "end": "1221000"
  },
  {
    "text": "about you know this is you know using spark an EMR for our you know data",
    "start": "1176610",
    "end": "1182730"
  },
  {
    "text": "science environments and you know our you know using presto for some of our systems so a lot of this I kind of went",
    "start": "1182730",
    "end": "1188250"
  },
  {
    "text": "over on the previous slides but this is just kind of to help with",
    "start": "1188250",
    "end": "1193620"
  },
  {
    "text": "that data democratization you know that layer and you know what precedent might not be the layer that we keep there",
    "start": "1193620",
    "end": "1198690"
  },
  {
    "text": "forever but the idea is we do want a generic interface where we do not have",
    "start": "1198690",
    "end": "1203700"
  },
  {
    "text": "those users directly connecting any of those data sources and then we control that single data storage location which",
    "start": "1203700",
    "end": "1210000"
  },
  {
    "text": "right now we've kind of landed on that being s3 and then putting some processing in between and then creating",
    "start": "1210000",
    "end": "1215970"
  },
  {
    "text": "an abstraction layer where people can pull data out from a single interface so",
    "start": "1215970",
    "end": "1222690"
  },
  {
    "start": "1221000",
    "end": "1312000"
  },
  {
    "text": "I talked a lot of bit about this but you know a lot of the benefits here were",
    "start": "1222690",
    "end": "1228420"
  },
  {
    "text": "operational efficiencies I mean you know even when we were on on or you know managing our own data on our EBS volumes",
    "start": "1228420",
    "end": "1235560"
  },
  {
    "text": "are prior to that when we ran our colas and we were you know managing her own NASA's just managing and like",
    "start": "1235560",
    "end": "1242820"
  },
  {
    "text": "repartition and moving all that data around upgrading all those systems I mean it was literally taking you know",
    "start": "1242820",
    "end": "1248940"
  },
  {
    "text": "upwards of 60 to 70 percent of the teams to do their job was all operational and what we get out of Amazon is just not",
    "start": "1248940",
    "end": "1257130"
  },
  {
    "text": "having to worry about that not having to worry you know there are there is some maintenance that you have to do",
    "start": "1257130",
    "end": "1262279"
  },
  {
    "text": "you have to watch out for certain things but it's a fraction of what we were having to do for for you know the",
    "start": "1262279",
    "end": "1269840"
  },
  {
    "text": "automatic scaling you know I mentioned earlier when we talked about our Claude Eric Custer and you know it was a",
    "start": "1269840",
    "end": "1276229"
  },
  {
    "text": "physical cluster it was HP servers running in Iraq and it's a lot nicer to",
    "start": "1276229",
    "end": "1282679"
  },
  {
    "text": "be able to spin off a hundred nodes in EMR when I need him as opposed to trying to send something on to the data center and physically rack up eight more",
    "start": "1282679",
    "end": "1289070"
  },
  {
    "text": "servers so these are a lot of problems which is kind of funny because cabbage started in AWS and then we actually",
    "start": "1289070",
    "end": "1297169"
  },
  {
    "text": "moved some of our data systems into a Colo thinking we could get things that we we could do things faster with metal",
    "start": "1297169",
    "end": "1303139"
  },
  {
    "text": "and then now we are on our journey basically bringing everything back into AWS so that was fun so this last part",
    "start": "1303139",
    "end": "1315559"
  },
  {
    "start": "1312000",
    "end": "1418000"
  },
  {
    "text": "here that talked about a little bit earlier was on just picking the right solution so the solution that we have",
    "start": "1315559",
    "end": "1321799"
  },
  {
    "text": "right now my last is two years my last is three years but you're gonna be reacting things every year anyway and we spent so",
    "start": "1321799",
    "end": "1328369"
  },
  {
    "text": "much time you know trying to build out when we went down the map our route and scaling out that cluster to handle you",
    "start": "1328369",
    "end": "1335299"
  },
  {
    "text": "know petabytes of data and the traffic and the throughput in the testing we were solving a problem that we didn't actually have and so and you know what",
    "start": "1335299",
    "end": "1343700"
  },
  {
    "text": "we were talking earlier about like this spark and we were talking about how you know there was issues with our single",
    "start": "1343700",
    "end": "1349519"
  },
  {
    "text": "server but when we actually that system worked for us for like four years and it worked fine and then we migrated now to",
    "start": "1349519",
    "end": "1356029"
  },
  {
    "text": "a new system that I work for us for a few years and it's all about like just not over architecting and solving the",
    "start": "1356029",
    "end": "1362899"
  },
  {
    "text": "problems you have at hand decreasing you know any operational inefficiencies that you have and you know just engineers can",
    "start": "1362899",
    "end": "1370759"
  },
  {
    "text": "and I am guilty of doing the same thing but you know don't try to solve for a",
    "start": "1370759",
    "end": "1376099"
  },
  {
    "text": "problem that you don't have right now but don't not plan for the future so we see that growth curve and I can project",
    "start": "1376099",
    "end": "1381559"
  },
  {
    "text": "where it's going to be so I need to make sure I have a system that can hand things from a couple of years and then I",
    "start": "1381559",
    "end": "1386580"
  },
  {
    "text": "needed to start next year planning for a system that can handle things after that but we had 18 months where we invested",
    "start": "1386580",
    "end": "1392400"
  },
  {
    "text": "into a system that we ended up essentially throwing away and then rebuilt this new architecture in about four months in AWS and it's already",
    "start": "1392400",
    "end": "1400260"
  },
  {
    "text": "started solving our problems like I said with that one job that we've taken down from about 17 18 hours down to about 20",
    "start": "1400260",
    "end": "1407070"
  },
  {
    "text": "minutes that already has taken a load off of our sequel servers and sped up our entire production system and we",
    "start": "1407070",
    "end": "1412890"
  },
  {
    "text": "pulled that off in about three months so and yeah so that's our presentation yeah",
    "start": "1412890",
    "end": "1424460"
  },
  {
    "start": "1418000",
    "end": "1447000"
  },
  {
    "text": "Jaime thank you I think you should change the title from a long strange trip to a series of unfortunate events",
    "start": "1424460",
    "end": "1431670"
  },
  {
    "text": "but yeah yeah probably that was the other sounded better you're still standing and smiling I'm a question and",
    "start": "1431670",
    "end": "1438570"
  },
  {
    "text": "you guys you guys have questions slider comm ashtag start up I can understand",
    "start": "1438570",
    "end": "1444630"
  },
  {
    "text": "how you knew when what you were doing wasn't working and now they want to",
    "start": "1444630",
    "end": "1450570"
  },
  {
    "start": "1447000",
    "end": "1454000"
  },
  {
    "text": "bring you into this how did you know you mentioned one thing about you know reducing time from hours to 20 minutes",
    "start": "1450570",
    "end": "1456840"
  },
  {
    "start": "1454000",
    "end": "1593000"
  },
  {
    "text": "but how did you know when things were starting to work the right way and that you were on the right path I understand",
    "start": "1456840",
    "end": "1462540"
  },
  {
    "text": "you guys it was obvious we were on the wrong path but when did you start to know you were on the right path so yeah",
    "start": "1462540",
    "end": "1468929"
  },
  {
    "text": "I would say like last year when we started going down the path and like a lot of what we learned when we started",
    "start": "1468929",
    "end": "1474750"
  },
  {
    "text": "down that map our migration a lot of things that we learned during that process we're still using we're still",
    "start": "1474750",
    "end": "1481350"
  },
  {
    "text": "using streaming technologies we're still using Kafka we're still landing things out and druid those are those are parts",
    "start": "1481350",
    "end": "1487440"
  },
  {
    "text": "of that solution so we were seeing we were seeing solutions but it just wasn't",
    "start": "1487440",
    "end": "1492510"
  },
  {
    "text": "actually solving our business problems but technically we saw value in what we were doing what it was was essentially",
    "start": "1492510",
    "end": "1499110"
  },
  {
    "text": "it was when we shifted the team to stop being in like R&D POC mode solved all",
    "start": "1499110",
    "end": "1505410"
  },
  {
    "text": "the problems for the future of the world of our sis you know whatever you can think of and I changed it to we've got",
    "start": "1505410",
    "end": "1511260"
  },
  {
    "text": "these for use cases I've got this job and I to run in under 30 minutes and I need to",
    "start": "1511260",
    "end": "1517179"
  },
  {
    "text": "solve this problem and I have to solve it by the end of the year it's really what we did it was we started shifting the priorities to give more specific",
    "start": "1517179",
    "end": "1523270"
  },
  {
    "text": "business cases that had to be solved and within a timeframe now go use all the technologies that you you know that",
    "start": "1523270",
    "end": "1529809"
  },
  {
    "text": "you've learned from in the past and it was when we made that shift that we started seeing massive progress was that",
    "start": "1529809",
    "end": "1537279"
  },
  {
    "text": "when you made that shift was the relief or the success obvious like from the get-go and yeah it was definitely",
    "start": "1537279",
    "end": "1544360"
  },
  {
    "text": "obvious I mean so you you know you can immediately go from not having to do like sequel server maintenance windows",
    "start": "1544360",
    "end": "1550450"
  },
  {
    "text": "because you've taken a load off that server from an i/o standpoint so like you know my SLA is my uptime or",
    "start": "1550450",
    "end": "1555760"
  },
  {
    "text": "automatically up you know fewer you know misty tiel's and transforms and packages well yeah you've got like data loads",
    "start": "1555760",
    "end": "1562659"
  },
  {
    "text": "that relate going into like Salesforce or you know different email marketing systems and all those things are",
    "start": "1562659",
    "end": "1568299"
  },
  {
    "text": "starting to be more reliable and so the entire company like just by fixing one job which was hammering and taxing a",
    "start": "1568299",
    "end": "1575260"
  },
  {
    "text": "database every single night which was then having a trickling effect on downstream jobs which affected the",
    "start": "1575260",
    "end": "1580600"
  },
  {
    "text": "entire business by solving that one problem the whole company felt the success of that project Wow all right",
    "start": "1580600",
    "end": "1587440"
  },
  {
    "text": "let's get to this plant questions here any plans to increase the frequency of data refreshes yes so if it was up to us",
    "start": "1587440",
    "end": "1596350"
  },
  {
    "start": "1593000",
    "end": "1680000"
  },
  {
    "text": "we'd have everything we wouldn't have any batch so we're actually working with some of our vendors to get more",
    "start": "1596350",
    "end": "1602590"
  },
  {
    "text": "event-driven callbacks into our system so we get data all throughout the day the problem is is there's certain data",
    "start": "1602590",
    "end": "1609730"
  },
  {
    "text": "sources that we collect data from that will probably not create an event-driven callbacks to us where we will have to do",
    "start": "1609730",
    "end": "1615850"
  },
  {
    "text": "things in a batch mode so there's legacy banking systems and reporting systems and things that we",
    "start": "1615850",
    "end": "1622210"
  },
  {
    "text": "call from a fraud standpoint where you know with frankly they're probably still running on mainframes and they're doing nightly batch processes themselves so",
    "start": "1622210",
    "end": "1629140"
  },
  {
    "text": "but everywhere we can we want to move everything closer to the real-time architecture and do as little in the batch system as",
    "start": "1629140",
    "end": "1636169"
  },
  {
    "text": "possible but we did need to build our robust batching you know a batch architecture system because it's a problem that we know we're gonna have",
    "start": "1636169",
    "end": "1642019"
  },
  {
    "text": "for multiple years so question from Meg who's Meg raise your hand meg Meg I let",
    "start": "1642019",
    "end": "1650510"
  },
  {
    "text": "you answer this one what are you use for orchestration for everything I think",
    "start": "1650510",
    "end": "1659299"
  },
  {
    "text": "we're still using a lot in that we're moving more towards like terraform and some confirmation stuff but largely",
    "start": "1659299",
    "end": "1666320"
  },
  {
    "text": "terraformed good for you Meg",
    "start": "1666320",
    "end": "1673730"
  },
  {
    "text": "it seems like you evaluated everything but you redshift vs. Aurora or druid we",
    "start": "1673960",
    "end": "1681310"
  },
  {
    "start": "1680000",
    "end": "1778000"
  },
  {
    "text": "did right now a worker made sense we like the word made sense for what",
    "start": "1681310",
    "end": "1688720"
  },
  {
    "text": "we're doing right now so because of the single syntax and stuff it made sense",
    "start": "1688720",
    "end": "1695620"
  },
  {
    "text": "for right now I guess it can answer that second part of the question - why not HBase on EMR rather than our around",
    "start": "1695620",
    "end": "1702130"
  },
  {
    "text": "weight and so one thing on the top one thing I do have to unfortunately deal with right now is I you know we have partners that use",
    "start": "1702130",
    "end": "1708760"
  },
  {
    "text": "our platform in Europe and South America and in Canada and primarily Europe right",
    "start": "1708760",
    "end": "1714670"
  },
  {
    "text": "now I'm working on changing them but some of those banking partners that we",
    "start": "1714670",
    "end": "1720580"
  },
  {
    "text": "work with don't like AWS right now they're still everything's different in",
    "start": "1720580",
    "end": "1726760"
  },
  {
    "text": "the last three years there's been this massive transformation we've got and run in their QAS and AWS and things like that but one of the reasons why we pick",
    "start": "1726760",
    "end": "1733900"
  },
  {
    "text": "certain things like so for example even with like EMR so when I go to run that in a Colo if I do have to install that",
    "start": "1733900",
    "end": "1739300"
  },
  {
    "text": "into a data center in Europe I can't bring up my own Hadoop cluster and I can't rerun all my spark code and I can reuse just about everything I have so",
    "start": "1739300",
    "end": "1746380"
  },
  {
    "text": "one of the reasons to go with something worse you know like in Aurora we pick it with like Postgres compatibility mode so",
    "start": "1746380",
    "end": "1752560"
  },
  {
    "text": "I can install my own Postgres instance so redshift is kind of one of those tools that if I go all in",
    "start": "1752560",
    "end": "1758020"
  },
  {
    "text": "it's very much Amazon based so ideals I do still have to pick certain tools while managing getting the benefit of",
    "start": "1758020",
    "end": "1764680"
  },
  {
    "text": "AWS still allow me to with minimal effort run that technology within a Colo",
    "start": "1764680",
    "end": "1770800"
  },
  {
    "text": "if I have to so that drives some of these decisions that are that come up in",
    "start": "1770800",
    "end": "1776080"
  },
  {
    "text": "some of these questions there so does that drive the HBase on EMR rather than",
    "start": "1776080",
    "end": "1781420"
  },
  {
    "text": "Aurora decision as well so you want to answer that this case we actually still have H face",
    "start": "1781420",
    "end": "1788409"
  },
  {
    "text": "on our cloud era cluster that we're still still using but for this",
    "start": "1788409",
    "end": "1795100"
  },
  {
    "text": "particular use case we needed something like more I guess this will be easier to load in it was a little bit use of",
    "start": "1795100",
    "end": "1801130"
  },
  {
    "text": "advantage for people that are working with databases standard the party guys kind of stuff so yeah that's why you",
    "start": "1801130",
    "end": "1807460"
  },
  {
    "text": "would ever order this I mean we have a good many people that already knew Postgres and there are some slight",
    "start": "1807460",
    "end": "1813549"
  },
  {
    "start": "1809000",
    "end": "1877000"
  },
  {
    "text": "nuances between age case and Postgres and you know we mainly picked it based",
    "start": "1813549",
    "end": "1820120"
  },
  {
    "text": "on the skill sense that we had there were lots of conversations and some POC",
    "start": "1820120",
    "end": "1825130"
  },
  {
    "text": "is done on you know using s3 FS and pulling the data directly in the EMR and",
    "start": "1825130",
    "end": "1830649"
  },
  {
    "text": "then not having to push that data back out in Aurora and actually make h8rs tables that we can actually hit direct",
    "start": "1830649",
    "end": "1836740"
  },
  {
    "text": "and that is something that we will continue into investigate but it was a pretty simple transformation to push it",
    "start": "1836740",
    "end": "1842980"
  },
  {
    "text": "out into Aurora we actually also found that so one of the benefits is is we",
    "start": "1842980",
    "end": "1847990"
  },
  {
    "text": "needed get many reed replicas in multiple regions for our different office locations so from San Francisco",
    "start": "1847990",
    "end": "1853210"
  },
  {
    "text": "to Bangalore as well as some of our partners in Europe and they need read-only replicas with certain rules and some of the benefits that we got",
    "start": "1853210",
    "end": "1859390"
  },
  {
    "text": "from Aurora made that very easy or that is a little bit more difficult to do in EMR which is where we would be running",
    "start": "1859390",
    "end": "1865659"
  },
  {
    "text": "the HBase system so where's Kent Kent",
    "start": "1865659",
    "end": "1871090"
  },
  {
    "text": "alright this is a long question you mentioned provisioning EMR capacity for bulk jobs did you leave mastering cores",
    "start": "1871090",
    "end": "1878350"
  },
  {
    "start": "1877000",
    "end": "1933000"
  },
  {
    "text": "running running or create new clusters so we do both so we've got a small",
    "start": "1878350",
    "end": "1885429"
  },
  {
    "text": "long-running cluster that we use for the real-time system this is the current solution that we have right now is",
    "start": "1885429",
    "end": "1890980"
  },
  {
    "text": "because we can't script up the auto generation of that real-time cluster fast enough I lose a few minutes and in",
    "start": "1890980",
    "end": "1897460"
  },
  {
    "text": "that real-time scenario those minutes matter so we have a what we call like a",
    "start": "1897460",
    "end": "1902710"
  },
  {
    "text": "real-time EMR cluster right now I think we've got it around four to six nodes but everything that we do in batch since",
    "start": "1902710",
    "end": "1909370"
  },
  {
    "text": "in the minutes you know minutes don't matter those are straight and fresh clusters that reload their data and run every",
    "start": "1909370",
    "end": "1915500"
  },
  {
    "text": "time we actually build them out so we're actually doing both",
    "start": "1915500",
    "end": "1919780"
  },
  {
    "text": "all right you heard that um do you use",
    "start": "1923860",
    "end": "1930889"
  },
  {
    "text": "80s services for data cleansing not currently right now all of that custom",
    "start": "1930889",
    "end": "1936919"
  },
  {
    "start": "1933000",
    "end": "1968000"
  },
  {
    "text": "code that we've generated we are definitely looking in the tools to do some of that more effectively but most",
    "start": "1936919",
    "end": "1942710"
  },
  {
    "text": "of what we do right now from a data cleansing data normalization standpoint is a combination of stuff that we've",
    "start": "1942710",
    "end": "1948440"
  },
  {
    "text": "written our selves either in Python a good bit of its some of its indirectly in Python some of its in Python that we",
    "start": "1948440",
    "end": "1955279"
  },
  {
    "text": "run within pi spark and some of its in scala that we also run and spark ourselves so how do you validate data is",
    "start": "1955279",
    "end": "1962570"
  },
  {
    "text": "accurate what so and validate the dinners accurate so yeah that that's you",
    "start": "1962570",
    "end": "1970610"
  },
  {
    "start": "1968000",
    "end": "2078000"
  },
  {
    "text": "know that's kind of hard to do with 100% accuracy but we have checks in place where what we do is a lot of our for all",
    "start": "1970610",
    "end": "1978379"
  },
  {
    "text": "the stuff that comes in from like an ETL batch standpoint after we pull in all that data within to our systems we",
    "start": "1978379",
    "end": "1984499"
  },
  {
    "text": "generally have something that's going to react sport that data back out and then we're gonna do a mapping exercise we're",
    "start": "1984499",
    "end": "1990049"
  },
  {
    "text": "gonna do validation data validation run from that perspective we also do like",
    "start": "1990049",
    "end": "1996169"
  },
  {
    "text": "schema validation before we actually send anything out and when it comes from",
    "start": "1996169",
    "end": "2001389"
  },
  {
    "text": "like an aggregate perspective it's generally a combination of like reviewing the code as well as then",
    "start": "2001389",
    "end": "2007690"
  },
  {
    "text": "running over large data sets so if our data science team comes out with like a new model creates a whole new set of",
    "start": "2007690",
    "end": "2013990"
  },
  {
    "text": "features and a whole new sets a whole new set of calculations we're gonna run those calculations in two different",
    "start": "2013990",
    "end": "2019330"
  },
  {
    "text": "systems so they'll be run within that EMR cluster and then we'll also run them within a separate production cluster and",
    "start": "2019330",
    "end": "2024999"
  },
  {
    "text": "then we'll do baseline comparisons between all those values we have had",
    "start": "2024999",
    "end": "2030179"
  },
  {
    "text": "invalid calculations make it into production before so you know there's only so much you can do one of the",
    "start": "2030179",
    "end": "2036220"
  },
  {
    "text": "things that we've spent a lot of time as we refactored stuff so in the old days we had a lot of stored procedures that",
    "start": "2036220",
    "end": "2042759"
  },
  {
    "text": "were performing 50 different functions in a single sprach that were calculating a lot of aggregates performing a lot of",
    "start": "2042759",
    "end": "2048010"
  },
  {
    "text": "business logic couldn't check that stuff in a source control it couldn't have multiple people working around the same as we moved all of our jobs in a spark",
    "start": "2048010",
    "end": "2055010"
  },
  {
    "text": "we've moved more towards every aggregate and every feature is its own independent function so I can more easily unit test",
    "start": "2055010",
    "end": "2062000"
  },
  {
    "text": "it and then I can get into source control I can peer in code review it so that just process changes in changing",
    "start": "2062000",
    "end": "2068990"
  },
  {
    "text": "the language and the technology has made a world of difference in the data accuracy do you still use MVC for your",
    "start": "2068990",
    "end": "2077628"
  },
  {
    "text": "friend no we use because it was we had a",
    "start": "2077629",
    "end": "2083868"
  },
  {
    "text": "lot of people that didn't enjoy working in it we switched over a couple years ago and we have all of our front-end and",
    "start": "2083869",
    "end": "2091608"
  },
  {
    "text": "angular with our middle learning node we were actually pretty early in hindsight maybe I should have picked react but we",
    "start": "2091609",
    "end": "2097580"
  },
  {
    "text": "jumped on angular 2 and then we followed that whole journey where they rewrote it three or four different times",
    "start": "2097580",
    "end": "2104090"
  },
  {
    "text": "as we were trying to get our application launched so that was fun but we came out the other end it",
    "start": "2104090",
    "end": "2109100"
  },
  {
    "text": "stabilized we stayed current on our angular we've got our app fully segmented running in containers running",
    "start": "2109100",
    "end": "2115010"
  },
  {
    "text": "in AWS and completely separate VPC so it's forced to not break any rules and",
    "start": "2115010",
    "end": "2120109"
  },
  {
    "text": "you know only use our micro services to pull data out of our platform so that deployment that CI CD is fairly clean",
    "start": "2120109",
    "end": "2127000"
  },
  {
    "text": "our middle layer still in c-sharp just for our speed a lot of it we've started",
    "start": "2127000",
    "end": "2132770"
  },
  {
    "text": "to convert over to dotnet core an individual micro services so we can actually get those into containers and run those on Linux host and get those",
    "start": "2132770",
    "end": "2139280"
  },
  {
    "text": "deployed as well and then our back-end you saw in the slide on a lot of what we're changing in our back-end so I'm",
    "start": "2139280",
    "end": "2147140"
  },
  {
    "text": "gonna ask one more question you know you seem both of you seem pretty unflappable but you know you talk about DevOps hell",
    "start": "2147140",
    "end": "2154340"
  },
  {
    "start": "2149000",
    "end": "2219000"
  },
  {
    "text": "and like oh and then that didn't work how did you manage like how did you get through it yeah that helps I mean it's",
    "start": "2154340",
    "end": "2165109"
  },
  {
    "text": "it's just part of it I mean I think everyone probably goes through this maybe they just don't put it up on a",
    "start": "2165109",
    "end": "2170119"
  },
  {
    "text": "slide and and then come show it to everybody but you know part of this being you know like the you know the",
    "start": "2170119",
    "end": "2176420"
  },
  {
    "text": "theme of this what startups is you know the hope I had with the being blunt and direct with that journey",
    "start": "2176420",
    "end": "2182270"
  },
  {
    "text": "was it would help someone avoid some of those mistakes I think a lot of people are going through those same things they're probably just not talking about",
    "start": "2182270",
    "end": "2189200"
  },
  {
    "text": "it and if they're not going through those things and they're probably not taking enough risk and they're probably not experienced pyramiding enough anyway",
    "start": "2189200",
    "end": "2196030"
  },
  {
    "text": "you know I mean like any engineer where they go out and they go to build things most of what they build is probably",
    "start": "2196030",
    "end": "2201230"
  },
  {
    "text": "gonna get thrown away and they're gonna fail they're gonna learn from it before you end up with that great solution so I",
    "start": "2201230",
    "end": "2206540"
  },
  {
    "text": "actually find all those mistakes just a normal part of the software development process well David and Natalie cabbage",
    "start": "2206540",
    "end": "2215180"
  },
  {
    "text": "thanks for sharing and thanks for being so honest thank you guys yeah definitely Thanks",
    "start": "2215180",
    "end": "2220660"
  }
]
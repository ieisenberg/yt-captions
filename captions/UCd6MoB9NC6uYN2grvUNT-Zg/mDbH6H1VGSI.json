[
  {
    "start": "0",
    "end": "64000"
  },
  {
    "text": "so thanks everyone for coming we're gonna get started so today we're going",
    "start": "30",
    "end": "5490"
  },
  {
    "text": "to talk about operationalizing machine learning and this is sort of a process that us as delux are going through so",
    "start": "5490",
    "end": "13590"
  },
  {
    "text": "we're iterating on this so it's nothing that's been solved per se it's something",
    "start": "13590",
    "end": "19619"
  },
  {
    "text": "we're still working on but I think we have a lot of the pieces together and the reason that we picked this just",
    "start": "19619",
    "end": "25170"
  },
  {
    "text": "before I intro we picked this specific angle for looking at machine learning",
    "start": "25170",
    "end": "30720"
  },
  {
    "text": "because we see a lot of people at least from the data scientists we work with or IT people etc or developers where",
    "start": "30720",
    "end": "39059"
  },
  {
    "text": "they'll just look at adopting a service and then implementing it but really it does it have worth from an engineering",
    "start": "39059",
    "end": "45239"
  },
  {
    "text": "perspective or does it have worth from a business perspective like are you right using the right tool for the job and is",
    "start": "45239",
    "end": "51600"
  },
  {
    "text": "it well integrated into your pipeline so we try to focus on that and how we build around and for that so my name is",
    "start": "51600",
    "end": "58649"
  },
  {
    "text": "Constantine forms and I reject Patrick so we both work on a platform called",
    "start": "58649",
    "end": "65970"
  },
  {
    "start": "64000",
    "end": "162000"
  },
  {
    "text": "deluxe one and I'll get into that as well but just for the agenda today we",
    "start": "65970",
    "end": "72420"
  },
  {
    "text": "rethought you know we thought of breaking it up into a couple sections here so essentially that the most",
    "start": "72420",
    "end": "78060"
  },
  {
    "text": "important one and this is really relevant if you think about what we do for things for a supply chain for",
    "start": "78060",
    "end": "84689"
  },
  {
    "text": "example a lot of patterns for say media in the cloud are actually anti patterns",
    "start": "84689",
    "end": "91290"
  },
  {
    "text": "for us from like a design perspective or architecture perspective and that's simply because of the nature and the",
    "start": "91290",
    "end": "98520"
  },
  {
    "text": "types of files we have to move around and process something it helps to understand that in order to understand",
    "start": "98520",
    "end": "105960"
  },
  {
    "text": "how we arrived and at the you know various technical pieces that we use so",
    "start": "105960",
    "end": "112320"
  },
  {
    "text": "we'll go from there into what our strategy is and what our tooling is as",
    "start": "112320",
    "end": "117630"
  },
  {
    "text": "sort of like a core 4ml substrate if you will and then abs we'll talk about what",
    "start": "117630",
    "end": "124049"
  },
  {
    "text": "our actual platform architecture looks like how we separate out AWS accounts",
    "start": "124049",
    "end": "130110"
  },
  {
    "text": "where we put content where we process things etc after that we'll sort of bring",
    "start": "130110",
    "end": "136500"
  },
  {
    "text": "everything together and quickly go through a specific example of how we",
    "start": "136500",
    "end": "142050"
  },
  {
    "text": "process data and then we thought instead of just you know talking at the audience",
    "start": "142050",
    "end": "147210"
  },
  {
    "text": "about all of these things we're doing we'd open it up for Q&A and also talk",
    "start": "147210",
    "end": "152280"
  },
  {
    "text": "about some of the things that we're trying to bring onto a cloud compute net",
    "start": "152280",
    "end": "157710"
  },
  {
    "text": "of type approach as well so hopefully that'll be interesting so just to get",
    "start": "157710",
    "end": "163380"
  },
  {
    "start": "162000",
    "end": "280000"
  },
  {
    "text": "started I don't know if how many of you are familiar with delux but if you're",
    "start": "163380",
    "end": "169140"
  },
  {
    "text": "not it's a company that's been around since you know over a hundred years",
    "start": "169140",
    "end": "175550"
  },
  {
    "text": "started with film processing but really if you look at what is deluxe do it's",
    "start": "175550",
    "end": "182130"
  },
  {
    "text": "pretty much everything from creation of content as it comes off a camera all the way to distribution and fulfillment of",
    "start": "182130",
    "end": "189450"
  },
  {
    "text": "that content and this is important for us because whatever we build we",
    "start": "189450",
    "end": "194640"
  },
  {
    "text": "potentially look at could it also go outside of what we're doing now and be applied to say other lines of business",
    "start": "194640",
    "end": "203310"
  },
  {
    "text": "that are lifting and shifting their pipelines and their media processing on to say AWS how can we then retool or",
    "start": "203310",
    "end": "210660"
  },
  {
    "text": "reuse our tooling to allow them to take benefit of that as well without you know",
    "start": "210660",
    "end": "216600"
  },
  {
    "text": "reinventing the wheel so if you look at this across like you know from source to",
    "start": "216600",
    "end": "222000"
  },
  {
    "text": "destination here mastering of feature film episodic etc management of the",
    "start": "222000",
    "end": "230220"
  },
  {
    "text": "catalogs for that content advanced formats like IMF packaging etc and it's",
    "start": "230220",
    "end": "237330"
  },
  {
    "text": "also important to note here that when we deal with advanced formats and may go",
    "start": "237330",
    "end": "242519"
  },
  {
    "text": "into a library and we may have to process that at a later stage so it could be years down so there's a lot of",
    "start": "242519",
    "end": "248880"
  },
  {
    "text": "data that builds up in the system right in terms of how do we deal with different codecs and protocols and",
    "start": "248880",
    "end": "254010"
  },
  {
    "text": "delivery for that etc also encoding distribution both for theater theatrical",
    "start": "254010",
    "end": "260250"
  },
  {
    "text": "as well as for example digital like OTT deliveries etc and then if you mix in",
    "start": "260250",
    "end": "266940"
  },
  {
    "text": "thing localization multiple languages etc distribution of that data to different",
    "start": "266940",
    "end": "272310"
  },
  {
    "text": "countries for example as orders for supply chain all of these things sort of",
    "start": "272310",
    "end": "277620"
  },
  {
    "text": "factor in and influence each other so it we thought you know where should we",
    "start": "277620",
    "end": "283259"
  },
  {
    "start": "280000",
    "end": "392000"
  },
  {
    "text": "start right and you'll you'll see we have like a number of a number of these title screens have graphics behind them",
    "start": "283259",
    "end": "291240"
  },
  {
    "text": "and most of these come from other parts of the deluxe family so these are",
    "start": "291240",
    "end": "296639"
  },
  {
    "text": "typically feature films or episodic films that say method or a foam or other",
    "start": "296639",
    "end": "302490"
  },
  {
    "text": "entities have worked on either doing say color grading or visual effects or other",
    "start": "302490",
    "end": "307830"
  },
  {
    "text": "types of things but these are also things we're starting to look at now and we'll talk about that later but at least",
    "start": "307830",
    "end": "314849"
  },
  {
    "text": "for us in terms of supply chain right when you start you start with the asset",
    "start": "314849",
    "end": "321300"
  },
  {
    "text": "right so the weight here is we have to process a certain a certain size of",
    "start": "321300",
    "end": "327240"
  },
  {
    "text": "asset and that can vary from 25 to 500 plus gigabytes for an asset so there's a",
    "start": "327240",
    "end": "333599"
  },
  {
    "text": "challenge there how can I store and process that file fastly and efficiently and then if you look at how many assets",
    "start": "333599",
    "end": "340919"
  },
  {
    "text": "are in a title right those could be ten to a hundred plus and you can think of",
    "start": "340919",
    "end": "346830"
  },
  {
    "text": "that as probably something like your your core video asset and then all of",
    "start": "346830",
    "end": "352800"
  },
  {
    "text": "the addition audio tracks poster files in multiple languages subtitle files all of these things comprise what could you",
    "start": "352800",
    "end": "360569"
  },
  {
    "text": "know be factored into a package for delivery and then if we look at outputs this is where it gets more interesting",
    "start": "360569",
    "end": "367080"
  },
  {
    "text": "if we have to then deliver these assets to multiple locations around the globe",
    "start": "367080",
    "end": "372150"
  },
  {
    "text": "we can potentially be looking at say taking a mezzanine asset or you know",
    "start": "372150",
    "end": "377759"
  },
  {
    "text": "what we call a heavy asset one of these large and weigh the assets and creating say an HLS output for say a feature film",
    "start": "377759",
    "end": "385319"
  },
  {
    "text": "and that may have tens of thousands of chunks to get delivered encrypted etc so",
    "start": "385319",
    "end": "391949"
  },
  {
    "text": "from source to sink you know if you then look at distribution as the other end of",
    "start": "391949",
    "end": "396990"
  },
  {
    "start": "392000",
    "end": "443000"
  },
  {
    "text": "this spectrum if you will as to how these assets are deliver there's a scale at which we have to be",
    "start": "396990",
    "end": "405150"
  },
  {
    "text": "cognizant of in terms of the operation of the company right so you can see here",
    "start": "405150",
    "end": "411000"
  },
  {
    "text": "4.5 plus petabytes get delivered and I should add like a lot of this might be",
    "start": "411000",
    "end": "417930"
  },
  {
    "text": "on legacy and not fully cloud lifted into the cloud per se but these are",
    "start": "417930",
    "end": "424320"
  },
  {
    "text": "things that we have to bear in mind as we design because eventually we're going to have to deal with these challenges",
    "start": "424320",
    "end": "429720"
  },
  {
    "text": "from the business perspective so you can see the number of endpoints and also the",
    "start": "429720",
    "end": "435690"
  },
  {
    "text": "number of assets that are delivered delivered so there's a high velocity and amount of data if you will and then",
    "start": "435690",
    "end": "443880"
  },
  {
    "start": "443000",
    "end": "519000"
  },
  {
    "text": "because everyone likes metrics right there are a whole bunch of metrics here this is more granular as to you know how",
    "start": "443880",
    "end": "452100"
  },
  {
    "text": "many formats do we have to support for transcoding so for all these you know",
    "start": "452100",
    "end": "457530"
  },
  {
    "text": "say ps3 ps4 Fire TV whatever device has to get delivered to might need a",
    "start": "457530",
    "end": "463890"
  },
  {
    "text": "specific format to support delivery so that's a transcode profile that we then",
    "start": "463890",
    "end": "468930"
  },
  {
    "text": "have to look up and transcode to that spec for it to be playable so these are",
    "start": "468930",
    "end": "474450"
  },
  {
    "text": "all like multiplying factors on terms in terms of complexity that maybe we may have to deal with if we then drive down",
    "start": "474450",
    "end": "482580"
  },
  {
    "text": "to like which of these influence like tech decisions like how we design the platform right we know that we have to",
    "start": "482580",
    "end": "489480"
  },
  {
    "text": "deal with a certain and velocity and amount of content coming into the platform we know that there's a certain",
    "start": "489480",
    "end": "495570"
  },
  {
    "text": "amount of assets that get ingested and then we know that we have to provide a certain SLA support a certain amount of",
    "start": "495570",
    "end": "502830"
  },
  {
    "text": "formats and actually deliver those out right so I'll get to where we looked at",
    "start": "502830",
    "end": "508590"
  },
  {
    "text": "inserting things like machine learning into this but it's important to understand here that these are things",
    "start": "508590",
    "end": "515190"
  },
  {
    "text": "that we can't disrupt in this pipeline right in the platform and then",
    "start": "515190",
    "end": "520409"
  },
  {
    "start": "519000",
    "end": "579000"
  },
  {
    "text": "specifically I guess we look at it as not really machine learning but more",
    "start": "520410",
    "end": "526080"
  },
  {
    "text": "enhanced computation because if we can solve problems mathematically versus",
    "start": "526080",
    "end": "532170"
  },
  {
    "text": "using say deep learning we get an app's versus a confidence vector and if we can",
    "start": "532170",
    "end": "537690"
  },
  {
    "text": "be a hundred percent confident that whatever we have computed is valid we",
    "start": "537690",
    "end": "543150"
  },
  {
    "text": "can fully automate that workflow right so if you then look at these same points and you look at okay what is important",
    "start": "543150",
    "end": "549510"
  },
  {
    "text": "or what could we apply things like enhance computation or machine learning to obviously the automation that goes",
    "start": "549510",
    "end": "557550"
  },
  {
    "text": "through all of these things being processed all of the end assets being ingested that data is available for us",
    "start": "557550",
    "end": "564210"
  },
  {
    "text": "to do things like enrichment against if we're doing things are calculating proxies so that's sort of like that in a",
    "start": "564210",
    "end": "571920"
  },
  {
    "text": "nutshell all right to give you an idea of the the business challenge or the the",
    "start": "571920",
    "end": "577110"
  },
  {
    "text": "challenge we have to deal with right so it we've been looking at that like over",
    "start": "577110",
    "end": "582390"
  },
  {
    "start": "579000",
    "end": "598000"
  },
  {
    "text": "I'd say maybe six eight months plus something in that range yeah yeah we're",
    "start": "582390",
    "end": "589650"
  },
  {
    "text": "we're we're constantly iterating on this right so what is our what is our",
    "start": "589650",
    "end": "594690"
  },
  {
    "text": "strategy for applying machine learning to these use cases and I think the first",
    "start": "594690",
    "end": "599820"
  },
  {
    "start": "598000",
    "end": "703000"
  },
  {
    "text": "one is you start with feature engineering right so our feature engineering is basically the asset and a",
    "start": "599820",
    "end": "606900"
  },
  {
    "text": "pivot on that right so we look at okay if we have these size of assets what's the most computationally effective way",
    "start": "606900",
    "end": "614580"
  },
  {
    "text": "to process those very fast so that could be creating a low resolution proxy but",
    "start": "614580",
    "end": "621600"
  },
  {
    "text": "then what's the resolution that we need for the machine learning or deep learning or image recognition to be",
    "start": "621600",
    "end": "627060"
  },
  {
    "text": "actually effective at that resolution for the size of an object in say a scene",
    "start": "627060",
    "end": "632190"
  },
  {
    "text": "so that's one problem the other problem is things like conformance and this is",
    "start": "632190",
    "end": "637230"
  },
  {
    "text": "more for supply chain right so if I have an asset land that has an audio track and then I get a secondary audio track",
    "start": "637230",
    "end": "643830"
  },
  {
    "text": "that is uploaded I need to be able to automatically conform and map these two",
    "start": "643830",
    "end": "649080"
  },
  {
    "text": "together and that way I can remove what was typically done by a human out of the equation so it reduces our SLA and that",
    "start": "649080",
    "end": "656820"
  },
  {
    "text": "lets us deliver things fully automated without a human making mistakes so that's another area and in the third",
    "start": "656820",
    "end": "665070"
  },
  {
    "text": "areas if we're doing things like deep learning machine learning models or creating",
    "start": "665070",
    "end": "672209"
  },
  {
    "text": "datasets there's that volume of content we have to deal with so how do we effectively do things like say image",
    "start": "672209",
    "end": "679649"
  },
  {
    "text": "fingerprinting and then store that data effectively in a database so that's like",
    "start": "679649",
    "end": "685439"
  },
  {
    "text": "one of the challenges that we've had in terms of if I have hundreds of thousands",
    "start": "685439",
    "end": "691169"
  },
  {
    "text": "of fingerprints how do I do a quick look up against that without sort of having this downward ramp or downward spiral",
    "start": "691169",
    "end": "698389"
  },
  {
    "text": "you know of say database in ineffectiveness if you will so if we",
    "start": "698389",
    "end": "704639"
  },
  {
    "start": "703000",
    "end": "812000"
  },
  {
    "text": "look at that you know taking those earlier metrics and then looking from a",
    "start": "704639",
    "end": "709859"
  },
  {
    "text": "supply chain and a content processing perspective what are we doing with that",
    "start": "709859",
    "end": "715079"
  },
  {
    "text": "so these are all active projects some of them are actually in production some of",
    "start": "715079",
    "end": "720299"
  },
  {
    "text": "them are still in a design phase but essentially there's a lot of stuff that",
    "start": "720299",
    "end": "725429"
  },
  {
    "text": "we're doing here but effectively for supply chain there's a subset of these",
    "start": "725429",
    "end": "731009"
  },
  {
    "text": "right so we're doing things like spectrum analysis for audio fingerprinting for that earlier that",
    "start": "731009",
    "end": "736889"
  },
  {
    "text": "conformance I was talking about as one example we're also doing things like",
    "start": "736889",
    "end": "742649"
  },
  {
    "text": "video processing for things like automated Texas masters so that's a",
    "start": "742649",
    "end": "748619"
  },
  {
    "text": "situation where you have a media file that has text on it you want to find the",
    "start": "748619",
    "end": "754859"
  },
  {
    "text": "matching media file that doesn't have that and extract the frames and put them into the Texas master and you can think",
    "start": "754859",
    "end": "760589"
  },
  {
    "text": "of lots of use cases for that right where one language is burnt into the file but I need to distribute it and say",
    "start": "760589",
    "end": "768449"
  },
  {
    "text": "a country that doesn't speak that language and I want to be able to either burn in new languages or potentially",
    "start": "768449",
    "end": "776519"
  },
  {
    "text": "just overlay or not even show that on the file and then deep learning is is another area right so we're doing things",
    "start": "776519",
    "end": "783119"
  },
  {
    "text": "like rotoscoping to take faces out we're doing things like how do I do from an",
    "start": "783119",
    "end": "790589"
  },
  {
    "text": "automated perspective figure out if there are logos or people's faces at the",
    "start": "790589",
    "end": "795839"
  },
  {
    "text": "bottom of a video in order to reposition subtitles to the top so some of these",
    "start": "795839",
    "end": "801089"
  },
  {
    "text": "actually have best practices or industry practices",
    "start": "801089",
    "end": "806759"
  },
  {
    "text": "that you have to do right it's it's not an either-or or we don't have to do it so so taking that you know if we look at",
    "start": "806759",
    "end": "815399"
  },
  {
    "start": "812000",
    "end": "926000"
  },
  {
    "text": "what's the service stack that we built for this right to take care of all of these use cases if you will and probably",
    "start": "815399",
    "end": "823349"
  },
  {
    "text": "you know many of you that are familiar with AWS services sage maker etc you probably notice that those are absent",
    "start": "823349",
    "end": "829469"
  },
  {
    "text": "here and there's a real reason that those are absent we're we are looking at",
    "start": "829469",
    "end": "834989"
  },
  {
    "text": "them so we've gone through multiple iterations of you know could we use these services could we adapt that but",
    "start": "834989",
    "end": "842519"
  },
  {
    "text": "really we have a infrastructure full CI CD pipeline right now that is built on a",
    "start": "842519",
    "end": "848099"
  },
  {
    "text": "number of pieces that was easily adaptable to use things like ml so if",
    "start": "848099",
    "end": "853559"
  },
  {
    "text": "you think of what's the easiest way to do that all of our stuff is doc arised right now so all of our services are doc",
    "start": "853559",
    "end": "860849"
  },
  {
    "text": "arised we use Nomad and vault console etc pretty heavily with containers and",
    "start": "860849",
    "end": "867979"
  },
  {
    "text": "Spock is a natural fit for that right so it allows us to do things like use the",
    "start": "867979",
    "end": "873419"
  },
  {
    "text": "same cluster infrastructure that ABS we'll talk about later but be able to use that for deploying",
    "start": "873419",
    "end": "879119"
  },
  {
    "text": "either deep deep learning or machine learning or training as well as the",
    "start": "879119",
    "end": "884669"
  },
  {
    "text": "inference in terms of the lookups etc the toolset is pretty pretty common",
    "start": "884669",
    "end": "890909"
  },
  {
    "text": "right so we use a lot of things like ffmpeg we use things like d-lab for like",
    "start": "890909",
    "end": "896639"
  },
  {
    "text": "spectral plot set cetera we's things like tensorflow docker eyes at etc and then commercial partners to",
    "start": "896639",
    "end": "904589"
  },
  {
    "text": "fill out the voids right so it's a combination of a lot of these things and we're really consuming AWS primitives if",
    "start": "904589",
    "end": "912479"
  },
  {
    "text": "you will right so things like s3 ec2 auto scaling all of these common things",
    "start": "912479",
    "end": "917759"
  },
  {
    "text": "form our base and then we build on top of that and this essentially makes up our service stack if you will so one",
    "start": "917759",
    "end": "927419"
  },
  {
    "start": "926000",
    "end": "1055000"
  },
  {
    "text": "other thing I wanted to talk about here is the one the one thing we looked at in terms of how do we what's our strategy",
    "start": "927419",
    "end": "934589"
  },
  {
    "text": "for this is there there are three sections here right and if you look at this from the",
    "start": "934589",
    "end": "941190"
  },
  {
    "text": "left to the right this this is like a mode of where potentially I'm a company",
    "start": "941190",
    "end": "946770"
  },
  {
    "text": "or a startup or whatever looking to take on ml I can do it quick and it's easy if",
    "start": "946770",
    "end": "954060"
  },
  {
    "text": "I just have an inference pipeline with a managed service right service provider managers the model for me I just feed",
    "start": "954060",
    "end": "961260"
  },
  {
    "text": "that data I get results back I'm done I have nothing else to do that's an easy",
    "start": "961260",
    "end": "967110"
  },
  {
    "text": "model but Al's is essentially an environment if you think about the right-hand side here is something you",
    "start": "967110",
    "end": "973020"
  },
  {
    "text": "might see with say a third party ml company if you will providing you ml",
    "start": "973020",
    "end": "979980"
  },
  {
    "text": "services right so there are multi tenant they have multiple training pipelines you can potentially control those as",
    "start": "979980",
    "end": "986820"
  },
  {
    "text": "well but you would launch a service like this as say an ml based company right",
    "start": "986820",
    "end": "993240"
  },
  {
    "text": "using the right-hand side of this equation but really internally we have to facilitate that for all of these",
    "start": "993240",
    "end": "999780"
  },
  {
    "text": "business units that we have as well as our internal use cases so Al's more maps",
    "start": "999780",
    "end": "1005930"
  },
  {
    "text": "to not really the left side of the equation but the right side right because we need to control a training",
    "start": "1005930",
    "end": "1011720"
  },
  {
    "text": "pipeline because we have certain custom workflows that you know off-the-shelf",
    "start": "1011720",
    "end": "1017270"
  },
  {
    "text": "inference pipeline couldn't tackle for us we also have business approval right",
    "start": "1017270",
    "end": "1022670"
  },
  {
    "text": "so we want I'll say platform operations to have input into what our valid use",
    "start": "1022670",
    "end": "1028819"
  },
  {
    "text": "cases for machine learning so it's not driven entirely by say the development",
    "start": "1028820",
    "end": "1034069"
  },
  {
    "text": "team or the data science team if you will so they'll come up with that and",
    "start": "1034070",
    "end": "1039319"
  },
  {
    "text": "they'll generate policies right so there's that control over what's valid training data are you guys on the rails",
    "start": "1039320",
    "end": "1047180"
  },
  {
    "text": "or off the rails and then is this actually valid in a use case for the business across multiple",
    "start": "1047180",
    "end": "1052910"
  },
  {
    "text": "entities and then just to you know what",
    "start": "1052910",
    "end": "1058010"
  },
  {
    "start": "1055000",
    "end": "1131000"
  },
  {
    "text": "does the service integration look like for this right so this diagram here is",
    "start": "1058010",
    "end": "1064190"
  },
  {
    "text": "basically a portion of supply chain processing that we do",
    "start": "1064190",
    "end": "1069560"
  },
  {
    "text": "and essentially there a couple main parts here so I wouldn't try and read the text here apologies it's a little",
    "start": "1069560",
    "end": "1076340"
  },
  {
    "text": "small but essentially we're going from ingest we have user and interface user",
    "start": "1076340",
    "end": "1082310"
  },
  {
    "text": "interface and API interfaces to the system and then we have a notion of deliveries so end to end movement of",
    "start": "1082310",
    "end": "1089630"
  },
  {
    "text": "data right so if we look at where could we ply me apply machine learning the",
    "start": "1089630",
    "end": "1095300"
  },
  {
    "text": "natural part to put this or the natural place to put this would be materials",
    "start": "1095300",
    "end": "1100370"
  },
  {
    "text": "analysis in other words as the content comes in let's analyze the metadata let's extract it but we're potentially",
    "start": "1100370",
    "end": "1107150"
  },
  {
    "text": "already curating that the other place to do this is potentially an actual workflow right so we utilize conductor",
    "start": "1107150",
    "end": "1115460"
  },
  {
    "text": "for a lot of our workflows and we could bake it into there to do ml analysis at",
    "start": "1115460",
    "end": "1121310"
  },
  {
    "text": "that point in time and there are a number of these as you go through this in terms of where we could apply machine",
    "start": "1121310",
    "end": "1128030"
  },
  {
    "text": "machine learning but I'll hand it over to ABS to talk about platform and",
    "start": "1128030",
    "end": "1133190"
  },
  {
    "start": "1131000",
    "end": "1156000"
  },
  {
    "text": "architecture hi guys so I'll talk about",
    "start": "1133190",
    "end": "1139040"
  },
  {
    "text": "the platform in the architecture that drives everything that he just said so",
    "start": "1139040",
    "end": "1146420"
  },
  {
    "text": "when designing the platform he kind of mentioned some of the requirements we had to look at but there's a lot more",
    "start": "1146420",
    "end": "1153380"
  },
  {
    "text": "that we had to consider as part of designing the platform so these are some of the features that we took into",
    "start": "1153380",
    "end": "1159350"
  },
  {
    "start": "1156000",
    "end": "1288000"
  },
  {
    "text": "account when designing the platform security being the top one just because",
    "start": "1159350",
    "end": "1165280"
  },
  {
    "text": "we do we do contain studio content it may be pre-release content and at the",
    "start": "1165280",
    "end": "1170840"
  },
  {
    "text": "end of the day we're on the hook for it it's our responsibility to take care of that content so security is very",
    "start": "1170840",
    "end": "1176750"
  },
  {
    "text": "paradigm in the whole architecture the second one is content gravity as you",
    "start": "1176750",
    "end": "1183380"
  },
  {
    "text": "guys all know immediate content is very heavy very large so a lot of times it's not possible to move the data even",
    "start": "1183380",
    "end": "1191000"
  },
  {
    "text": "though it is possible it may take days it may take hours so you want to try to",
    "start": "1191000",
    "end": "1196160"
  },
  {
    "text": "limit the movement of data the next one was processing processing affinity",
    "start": "1196160",
    "end": "1202340"
  },
  {
    "text": "that's also along the lines of content gravity which is do I move the data to the process or do I move the process to",
    "start": "1202340",
    "end": "1209000"
  },
  {
    "text": "the data so depending on which one is more efficient we're able to switch between those two models the obvious one",
    "start": "1209000",
    "end": "1216169"
  },
  {
    "text": "horizontal scale most expected for most platforms these days distributed",
    "start": "1216169",
    "end": "1223100"
  },
  {
    "text": "services so originally we were a very monolithic model and as part of this",
    "start": "1223100",
    "end": "1229460"
  },
  {
    "text": "design we broke them up into several micro services so that we don't have a",
    "start": "1229460",
    "end": "1234830"
  },
  {
    "text": "single point of failure we're not one change is not taking the whole system down what does common micro service",
    "start": "1234830",
    "end": "1241760"
  },
  {
    "text": "related paradigms are at play here as well commonality so we also wanted to",
    "start": "1241760",
    "end": "1247610"
  },
  {
    "text": "make sure that from a developer perspective or from a platform customer perspective",
    "start": "1247610",
    "end": "1252950"
  },
  {
    "text": "everybody had a single pane of glass going in so whether you were writing a micro service whether you were doing",
    "start": "1252950",
    "end": "1258440"
  },
  {
    "text": "some sort of ML computation building a model training a model running some",
    "start": "1258440",
    "end": "1263840"
  },
  {
    "text": "backs process we wanted to make sure that the experience is the same and the reason for that would be so when you",
    "start": "1263840",
    "end": "1270919"
  },
  {
    "text": "grow and you add more services it's not hey now I gotta learn this new piece of technology or maybe I got to learn this",
    "start": "1270919",
    "end": "1276860"
  },
  {
    "text": "new piece of technology it's the same experience so you can hit the ground running given that they've already",
    "start": "1276860",
    "end": "1283010"
  },
  {
    "text": "designed other services to leverage the platform so moving on to scheduling",
    "start": "1283010",
    "end": "1290419"
  },
  {
    "start": "1288000",
    "end": "1521000"
  },
  {
    "text": "scheduling is one of our core components on how we're able to maintain our essays",
    "start": "1290419",
    "end": "1297820"
  },
  {
    "text": "so starting with process and content gravity we use process and content gravity to decide how to schedule the",
    "start": "1297820",
    "end": "1305240"
  },
  {
    "text": "job so as an example but to have a terabyte file rather than trying to say",
    "start": "1305240",
    "end": "1310370"
  },
  {
    "text": "pull down the file do some work on it and then push it back up we would",
    "start": "1310370",
    "end": "1315559"
  },
  {
    "text": "schedule the process in a place where it's closer so we cut the time down in",
    "start": "1315559",
    "end": "1321320"
  },
  {
    "text": "terms of how much time it takes in transit we also cut down on cost right",
    "start": "1321320",
    "end": "1327140"
  },
  {
    "text": "egress cost ingress cost we can schedule it's that shots such that were in a given region and that way we don't take",
    "start": "1327140",
    "end": "1333980"
  },
  {
    "text": "the cost of egress transmitted time as I said and then data awareness these kind of all go hand-in-hand",
    "start": "1333980",
    "end": "1340640"
  },
  {
    "text": "together but these are kind of like three bullet points that we use to schedule content and process it",
    "start": "1340640",
    "end": "1347030"
  },
  {
    "text": "accordingly second big item is access in",
    "start": "1347030",
    "end": "1353300"
  },
  {
    "text": "terms of access what is the process allowed to access especially when it",
    "start": "1353300",
    "end": "1359030"
  },
  {
    "text": "comes to content so isolation is very important depending on the scope of your process in the scope of your service",
    "start": "1359030",
    "end": "1364940"
  },
  {
    "text": "your service get scheduled accordingly and that way it's like a sandbox if you may for that process where it is only",
    "start": "1364940",
    "end": "1371870"
  },
  {
    "text": "able to access things that it absolutely needs otherwise you are not scheduled in that isolation zone if you may second",
    "start": "1371870",
    "end": "1379220"
  },
  {
    "text": "one would be internet your customer facing services or internet facing services obviously similar to a DMZ have",
    "start": "1379220",
    "end": "1386360"
  },
  {
    "text": "those isolated out as well third one is content given the the",
    "start": "1386360",
    "end": "1392540"
  },
  {
    "text": "scrutiny around content content in itself is isolated in its own area where there is no egress there is no ingress",
    "start": "1392540",
    "end": "1399050"
  },
  {
    "text": "it's not even a routable network it's a closed network completely locked down and then to access that content you",
    "start": "1399050",
    "end": "1406490"
  },
  {
    "text": "would need permissions or policies in order to do that the fourth one is",
    "start": "1406490",
    "end": "1412070"
  },
  {
    "text": "partners and clients so studios will give us content we'll do some work",
    "start": "1412070",
    "end": "1417560"
  },
  {
    "text": "against it sorry and then we'll deliver it back out the",
    "start": "1417560",
    "end": "1423740"
  },
  {
    "text": "area in which we accept content versus the area through which we deliver the content is also isolated out in that we",
    "start": "1423740",
    "end": "1431090"
  },
  {
    "text": "only want right access for data coming in into certain locations and then for delivery we may only want read access",
    "start": "1431090",
    "end": "1438640"
  },
  {
    "text": "certain sources and certain destinations",
    "start": "1438640",
    "end": "1443260"
  },
  {
    "text": "so for processing aside from the the two that I mentioned earlier in terms of",
    "start": "1445030",
    "end": "1450380"
  },
  {
    "text": "scheduling we also take into account what the process is going to do in order",
    "start": "1450380",
    "end": "1455450"
  },
  {
    "text": "to schedule the job so does it need a CPU does it need a GPU can it run in a",
    "start": "1455450",
    "end": "1461330"
  },
  {
    "text": "container does it just run as a regular process is it a batch job is it a long learning service",
    "start": "1461330",
    "end": "1468280"
  },
  {
    "text": "priorities right preemption shared clusters all of these items together",
    "start": "1468710",
    "end": "1475850"
  },
  {
    "text": "culminate to schedule a given job so we'll have a job spark job will never",
    "start": "1475850",
    "end": "1482700"
  },
  {
    "text": "run in certain clusters like I said earlier because of the isolation because it just won't be available there if",
    "start": "1482700",
    "end": "1489510"
  },
  {
    "text": "you're not allowed to it will not be there shared clusters are clusters where",
    "start": "1489510",
    "end": "1496160"
  },
  {
    "text": "you need the crosstalk between these isolation zone so you may have a service that's on the internet but then you may",
    "start": "1496160",
    "end": "1501929"
  },
  {
    "text": "have another service that needs to talk to content you don't want to expose that service directly but the other internet",
    "start": "1501929",
    "end": "1507570"
  },
  {
    "text": "facing service may need to talk to the content service so those in those cases",
    "start": "1507570",
    "end": "1513299"
  },
  {
    "text": "there's separate other zones that kind of allow you that sort of access right",
    "start": "1513299",
    "end": "1521780"
  },
  {
    "text": "communication so now we have all of these processes running we have all these services deployed the big question",
    "start": "1522140",
    "end": "1531299"
  },
  {
    "text": "is how do I locate these services so you service discovery at CD console we use",
    "start": "1531299",
    "end": "1537030"
  },
  {
    "text": "console to locate services now that you have the services and they're locatable",
    "start": "1537030",
    "end": "1542100"
  },
  {
    "text": "and you can discover them there's still the looming question of authentication authorization access control and then",
    "start": "1542100",
    "end": "1551130"
  },
  {
    "text": "exposing those services out to the internet or out to something customer-facing",
    "start": "1551130",
    "end": "1556730"
  },
  {
    "text": "so we use a tool called fabio it's an",
    "start": "1556730",
    "end": "1561840"
  },
  {
    "text": "open-source proxy and we've extended it to allow us to inline do authentication",
    "start": "1561840",
    "end": "1568230"
  },
  {
    "text": "authorization and policy based access control so you can draw a parallel with",
    "start": "1568230",
    "end": "1576000"
  },
  {
    "text": "say envoy whereon were is also a proxy imagine taking envoy if you're familiar with that and just adding the",
    "start": "1576000",
    "end": "1582799"
  },
  {
    "text": "authorization access control to it so when a service gets deployed they",
    "start": "1582799",
    "end": "1588510"
  },
  {
    "text": "inherently have those constructs available to them and they don't have to worry about",
    "start": "1588510",
    "end": "1594210"
  },
  {
    "text": "hey did I handle my session correctly oh did I secure this endpoint that kind of",
    "start": "1594210",
    "end": "1599820"
  },
  {
    "text": "gets abstracted away as a item two all processes and services and",
    "start": "1599820",
    "end": "1605260"
  },
  {
    "text": "then to communicate between all of these services and processes we use MQ as the",
    "start": "1605260",
    "end": "1611020"
  },
  {
    "text": "backend and we wrote a thin layer which we call Shotgun on top to kind of abstract that out so we can be back into",
    "start": "1611020",
    "end": "1617080"
  },
  {
    "text": "agnostic so come tomorrow we say hey MQ is not working out for us or we've hit the threshold at which we can scale",
    "start": "1617080",
    "end": "1623350"
  },
  {
    "text": "maybe we need to switch to Kafka maybe we need to switch to something else but having that thin layer in the front",
    "start": "1623350",
    "end": "1629140"
  },
  {
    "text": "allows us to agnostic Elise which out the backend without having to impact",
    "start": "1629140",
    "end": "1634450"
  },
  {
    "text": "another hundred services that then we'll have to go and change their code for this new back-end that we need to use",
    "start": "1634450",
    "end": "1641850"
  },
  {
    "start": "1643000",
    "end": "1685000"
  },
  {
    "text": "finally configuration this is what drives almost everything SSL logging",
    "start": "1643470",
    "end": "1653070"
  },
  {
    "text": "monitoring metrics storing your secrets retrieving your secrets these are all configuration values that",
    "start": "1653070",
    "end": "1659620"
  },
  {
    "text": "each service owner or each process can include as part of their deployment and",
    "start": "1659620",
    "end": "1664960"
  },
  {
    "text": "those are taken into account to provide the automatic authentication automatic",
    "start": "1664960",
    "end": "1670419"
  },
  {
    "text": "load balancing policy based access control so you're not going in and now",
    "start": "1670419",
    "end": "1675820"
  },
  {
    "text": "saying hey let me configure my logging or my metrics if you deploy to the",
    "start": "1675820",
    "end": "1681549"
  },
  {
    "text": "platform you get those for free finally all of this we control through a single",
    "start": "1681549",
    "end": "1687940"
  },
  {
    "start": "1685000",
    "end": "1728000"
  },
  {
    "text": "Nomad job this is a deployment descriptor but this one job file",
    "start": "1687940",
    "end": "1694360"
  },
  {
    "text": "contains all of the stuff that I just mentioned so your load balancing does my service need authentication does my",
    "start": "1694360",
    "end": "1701909"
  },
  {
    "text": "spark job have access to this content to perform some work against to the point",
    "start": "1701909",
    "end": "1708940"
  },
  {
    "text": "where when processes or jobs run all secrets are divvied out dynamically so",
    "start": "1708940",
    "end": "1714730"
  },
  {
    "text": "in the case of our ml pipeline even the person executing the job does not have",
    "start": "1714730",
    "end": "1720010"
  },
  {
    "text": "access to the content it is dynamically generated when the job is done those credentials disappear",
    "start": "1720010",
    "end": "1727169"
  },
  {
    "start": "1728000",
    "end": "1944000"
  },
  {
    "text": "so I'll go over now a little bit of how the isolation zones we call Han claves",
    "start": "1728650",
    "end": "1734470"
  },
  {
    "text": "are set up and there's about five of them I think we're missing one here but",
    "start": "1734470",
    "end": "1741300"
  },
  {
    "text": "the core one is your shared Enclave this",
    "start": "1741300",
    "end": "1747490"
  },
  {
    "text": "is where all the CI CD is this is where all your management happens this is where all you are operational folks",
    "start": "1747490",
    "end": "1756059"
  },
  {
    "text": "interact with with the platform your secrets your passwords your key rotation",
    "start": "1756059",
    "end": "1761820"
  },
  {
    "text": "basically all of management happens from this one place or this one isolation",
    "start": "1761820",
    "end": "1767980"
  },
  {
    "text": "zone and this one is special because it allows it has actually access to all the",
    "start": "1767980",
    "end": "1773230"
  },
  {
    "text": "other zones to actually schedule work or manage them but accessed into this",
    "start": "1773230",
    "end": "1778360"
  },
  {
    "text": "cluster obviously is fairly restricted so moving on to the internet facing zone",
    "start": "1778360",
    "end": "1786750"
  },
  {
    "text": "this is where we allow customers to interact with the platform with with",
    "start": "1786750",
    "end": "1792970"
  },
  {
    "text": "deluxe one this is where they upload the content potentially this is where they",
    "start": "1792970",
    "end": "1798580"
  },
  {
    "text": "would check the status on their order among other things if they need access",
    "start": "1798580",
    "end": "1803860"
  },
  {
    "text": "to api's this is where they would come in through but the all services that",
    "start": "1803860",
    "end": "1808929"
  },
  {
    "text": "would be customer facing or internet facing would be in this isolation zone",
    "start": "1808929",
    "end": "1814470"
  },
  {
    "text": "input-output this is the zone where content lands so there's nothing other",
    "start": "1815670",
    "end": "1823440"
  },
  {
    "text": "than content being delivered to us coming into this zone so this zone is",
    "start": "1823440",
    "end": "1830920"
  },
  {
    "text": "special in that you can only write to it you can't delete once it's written it's written and it's a one-way it's a",
    "start": "1830920",
    "end": "1837850"
  },
  {
    "text": "unidirectional path so that way the content provider can put stuff in but",
    "start": "1837850",
    "end": "1843280"
  },
  {
    "text": "they're not allowed to remove or access other portions of it the content zone",
    "start": "1843280",
    "end": "1850600"
  },
  {
    "text": "this is essentially a separate AWS account where everything is locked down there's no internet access it's not even",
    "start": "1850600",
    "end": "1857140"
  },
  {
    "text": "routable it's all internal no users nothing it's considered like a blank slate",
    "start": "1857140",
    "end": "1863110"
  },
  {
    "text": "account and so this one is obviously guarded the only thing you see happening",
    "start": "1863110",
    "end": "1869380"
  },
  {
    "text": "in this account is rebalancing of data say I want to move from one bucket to another I need to move data from this",
    "start": "1869380",
    "end": "1876400"
  },
  {
    "text": "one account a into our account into B I",
    "start": "1876400",
    "end": "1881559"
  },
  {
    "text": "want to put in a glacier request for resource but all content management or",
    "start": "1881559",
    "end": "1887440"
  },
  {
    "text": "the data movement of the content happens in this one zone with no external access",
    "start": "1887440",
    "end": "1895860"
  },
  {
    "text": "finally you're the crunch no zone if you may this is where all the fun stuff",
    "start": "1897120",
    "end": "1903370"
  },
  {
    "text": "happens this is where all the work is done as you see this is where transcoding happens this is where the",
    "start": "1903370",
    "end": "1908590"
  },
  {
    "text": "machine learning jobs run this where localization runs fingerprinting anything that needs to touch content",
    "start": "1908590",
    "end": "1915960"
  },
  {
    "text": "runs in this zone so now we have a full audit trail of who touched the content",
    "start": "1915960",
    "end": "1922090"
  },
  {
    "text": "when what they did with it what they wrote out etc so together all of these",
    "start": "1922090",
    "end": "1929830"
  },
  {
    "text": "different isolations don't loans together will then bubble up the whole platform and then depending on the",
    "start": "1929830",
    "end": "1935980"
  },
  {
    "text": "service or the job with the type of work or workflow you are trying to employ you",
    "start": "1935980",
    "end": "1941530"
  },
  {
    "text": "will it will schedule accordingly now to bring all of this together I know I gave",
    "start": "1941530",
    "end": "1946929"
  },
  {
    "start": "1944000",
    "end": "2366000"
  },
  {
    "text": "you guys a lot of facts but I'll go through a quick example of one of what",
    "start": "1946929",
    "end": "1952510"
  },
  {
    "text": "one of our ml computational enhancement pipelines look like so here we have the",
    "start": "1952510",
    "end": "1961419"
  },
  {
    "text": "services block the shared block content access and then content storage if you see these will line up with a with the",
    "start": "1961419",
    "end": "1968440"
  },
  {
    "text": "circular diagram you saw earlier so if a user SE wants to better let's say we get",
    "start": "1968440",
    "end": "1975760"
  },
  {
    "text": "a piece of content piece of content lands either a user or some automated",
    "start": "1975760",
    "end": "1981159"
  },
  {
    "text": "process will trigger the first step to it which is a services block so that will actually trigger a spark job that",
    "start": "1981159",
    "end": "1988809"
  },
  {
    "text": "spark job in turn will launch n number of other jobs and start reading the data and fingerprinting",
    "start": "1988809",
    "end": "1994679"
  },
  {
    "text": "once it's done stores it into the fingerprinting database and then we move on to the next step so it reads the data",
    "start": "1994679",
    "end": "2003269"
  },
  {
    "text": "from the VFS box you see there does some work once it's done updates the",
    "start": "2003269",
    "end": "2010200"
  },
  {
    "text": "fingerprinting database and then moves on so anytime a piece of content lands we just went through this cycle and",
    "start": "2010200",
    "end": "2015960"
  },
  {
    "text": "that's your call it your input phase if you may and then once those are handled",
    "start": "2015960",
    "end": "2024210"
  },
  {
    "text": "then we get into the actual details of the fingerprinting so we have two services one called DejaVu and the other",
    "start": "2024210",
    "end": "2030330"
  },
  {
    "text": "one called P hash P hash stands for purr I always get this one wrong so I'm going",
    "start": "2030330",
    "end": "2035940"
  },
  {
    "text": "to defer it to him perceptual perceptual hashing the first one does audio",
    "start": "2035940",
    "end": "2042659"
  },
  {
    "text": "fingerprinting the second one does video fingerprinting and those follow all the",
    "start": "2042659",
    "end": "2048690"
  },
  {
    "text": "same algorithms and paradigms that Kahn mentioned earlier for the audio portion is DejaVu and then the video",
    "start": "2048690",
    "end": "2055820"
  },
  {
    "text": "fingerprinting on P ash and then finally once all of this is done the content",
    "start": "2055820",
    "end": "2061950"
  },
  {
    "text": "goes to the content storage account and that's the end of that pipeline now the",
    "start": "2061950",
    "end": "2068220"
  },
  {
    "text": "details of that pipeline I'll hand over to Kahn to go over exactly what these individual pieces like deja vu or P hash",
    "start": "2068220",
    "end": "2074868"
  },
  {
    "text": "employ to kind of do the fingerprinting Thanks so I guess for some of you like",
    "start": "2074869",
    "end": "2084060"
  },
  {
    "text": "this is the one slide that matters right so just to explain and and if you look",
    "start": "2084060",
    "end": "2091169"
  },
  {
    "text": "at this from perspective of there's data prep on on the Left right that's blocked",
    "start": "2091169",
    "end": "2096450"
  },
  {
    "text": "out and as data analysis on the right that's blocked out and you can sort of",
    "start": "2096450",
    "end": "2101460"
  },
  {
    "text": "look at this as a flow from I need to extract the waveform right so in other words I'm taking the input codec I'm",
    "start": "2101460",
    "end": "2108599"
  },
  {
    "text": "decoding it converting it to PCM data I'm in taking the samples per second I'm",
    "start": "2108599",
    "end": "2115380"
  },
  {
    "text": "then sampling that putting that into buckets and then analyzing and fingerprinting each one of those as an",
    "start": "2115380",
    "end": "2120780"
  },
  {
    "text": "example so it's basically extracting the waveform here and then pivoting the",
    "start": "2120780",
    "end": "2126390"
  },
  {
    "text": "waveform for free and see in spectral analysis and you could probably start to see like if you",
    "start": "2126390",
    "end": "2132900"
  },
  {
    "text": "were looking at other ways to do this besides what we have here that this path could potentially go two ways right so",
    "start": "2132900",
    "end": "2139950"
  },
  {
    "text": "we could potentially take the spectral frequency that's being plotted here",
    "start": "2139950",
    "end": "2145140"
  },
  {
    "text": "right and passes through a deep learning pipeline and then we could do things",
    "start": "2145140",
    "end": "2150240"
  },
  {
    "text": "like image recognition against that using a pre trained model and try to figure out does this match up is a",
    "start": "2150240",
    "end": "2155910"
  },
  {
    "text": "certain language etc and we do that for some things but for these types of use",
    "start": "2155910",
    "end": "2161730"
  },
  {
    "text": "cases like I talked about earlier you know you have this you could go this direction of I'm gonna use deep learning",
    "start": "2161730",
    "end": "2168830"
  },
  {
    "text": "and then I'm gonna have a confidence factor and then it becomes exponentially harder for you to basically conform all",
    "start": "2168830",
    "end": "2176640"
  },
  {
    "text": "the data because there's so much data coming in how do we know that 80 percentile is good enough for us to",
    "start": "2176640",
    "end": "2183330"
  },
  {
    "text": "automatically conform this data right we don't so the the problem here is then if",
    "start": "2183330",
    "end": "2190020"
  },
  {
    "text": "you decide not to go that route then you're going down pure mathematical and",
    "start": "2190020",
    "end": "2195570"
  },
  {
    "text": "frequency analysis route right which is actually the data data analysis route that we have on the right hand side here",
    "start": "2195570",
    "end": "2201570"
  },
  {
    "text": "so we're not passing this to a model but we're using things like data bucketing",
    "start": "2201570",
    "end": "2208110"
  },
  {
    "text": "that you might see in deep learning right these are like common patterns if",
    "start": "2208110",
    "end": "2213390"
  },
  {
    "text": "you all but we're also doing other things like how do we do do identification so for example we'll take",
    "start": "2213390",
    "end": "2219870"
  },
  {
    "text": "that frequency analysis band and you can see the tooling is actually listed on the bottom here so we're not using",
    "start": "2219870",
    "end": "2226200"
  },
  {
    "text": "anything really fancy if you will it's just a lot of Python code or go or",
    "start": "2226200",
    "end": "2231210"
  },
  {
    "text": "whatever we decide to use to solve that equation but where is essentially extracting normalizing plotting and in",
    "start": "2231210",
    "end": "2239220"
  },
  {
    "text": "doing something with that so things like MATLAB matplotlib lebra Z for example",
    "start": "2239220",
    "end": "2245760"
  },
  {
    "text": "for the spectral analysis or image hashing these are all like core things for funk for Python that most people use",
    "start": "2245760",
    "end": "2253130"
  },
  {
    "text": "and then on the right hand side same kind of thing right so could do FFT or",
    "start": "2253130",
    "end": "2258420"
  },
  {
    "text": "we could use C QT that's built in to the lab Rosa library's right there's one example but essentially for this",
    "start": "2258420",
    "end": "2265890"
  },
  {
    "text": "part of the equation that we decided to go on the right hand side here it gives us a finite outcome that we can then say",
    "start": "2265890",
    "end": "2273809"
  },
  {
    "text": "this is good enough from say a ranking if you will and that's another problem",
    "start": "2273809",
    "end": "2279599"
  },
  {
    "text": "we have if we use different types of models how do how do we rank it but that's another another topic for",
    "start": "2279599",
    "end": "2284940"
  },
  {
    "text": "discussion but it since you will do things like peak detection and then we'll use libraries like fast DTW for",
    "start": "2284940",
    "end": "2292410"
  },
  {
    "text": "example to do things like time slow or stretch prediction or analysis so you",
    "start": "2292410",
    "end": "2299430"
  },
  {
    "text": "can think of if I land a first audio file a fingerprint it bring a second one",
    "start": "2299430",
    "end": "2304740"
  },
  {
    "text": "in but for some reason it's been time stretched how do I map those Peaks",
    "start": "2304740",
    "end": "2310470"
  },
  {
    "text": "together right so DTW is obviously one mechanism you can use for that and then",
    "start": "2310470",
    "end": "2317730"
  },
  {
    "text": "some of the guys on the data science team they're also using other interesting tooling right so we've looked at things like Astro align which",
    "start": "2317730",
    "end": "2325140"
  },
  {
    "text": "is actually for alignment of Astral images and it does it by you can think",
    "start": "2325140",
    "end": "2331740"
  },
  {
    "text": "of like a field with a number of people in it how do i align those and see if it's the same thing but i potentially",
    "start": "2331740",
    "end": "2337680"
  },
  {
    "text": "have a slight offset in where that is image wise so these are all interesting",
    "start": "2337680",
    "end": "2342930"
  },
  {
    "text": "tools that we're basically building together into this pipeline that runs as a job that ABS was talking about so",
    "start": "2342930",
    "end": "2351420"
  },
  {
    "text": "that's that's one example so like I said earlier we thought we talked maybe a",
    "start": "2351420",
    "end": "2356700"
  },
  {
    "text": "little about what we're working on now that we haven't actually deployed in the cloud as well as open it up for any Q&A",
    "start": "2356700",
    "end": "2366020"
  },
  {
    "start": "2366000",
    "end": "2424000"
  },
  {
    "text": "and we also wanted to say thank you to we're actually a pretty small team that works on this but these are I you know",
    "start": "2366020",
    "end": "2373230"
  },
  {
    "text": "if you look at data science and platform team for all these pieces there's a whole bunch of folks that work on this",
    "start": "2373230",
    "end": "2380569"
  },
  {
    "text": "so I guess we'd take any questions yeah",
    "start": "2380569",
    "end": "2390289"
  },
  {
    "text": "yes so the question is to allow developers to install their own tooling",
    "start": "2397160",
    "end": "2402299"
  },
  {
    "text": "on the images and yes for the most part yes unless we've identified that it's a",
    "start": "2402299",
    "end": "2409020"
  },
  {
    "text": "complete nono or there's a massive anti-pattern then we'll kind of guide them to say yeah don't do this but we",
    "start": "2409020",
    "end": "2417900"
  },
  {
    "text": "want to give them the freedom as well so that they can experiment and they can come up with good ideas yeah yeah we",
    "start": "2417900",
    "end": "2425430"
  },
  {
    "start": "2424000",
    "end": "2503000"
  },
  {
    "text": "don't really restrict the language we don't restrict the tooling but it's",
    "start": "2425430",
    "end": "2431039"
  },
  {
    "text": "mainly from perspective of auditing or security or how those how that",
    "start": "2431039",
    "end": "2438240"
  },
  {
    "text": "application code is say accessing things like databases or how frequently is it accessing things like s3 is it doing the",
    "start": "2438240",
    "end": "2444900"
  },
  {
    "text": "right way etc right so that's more where we will conform those things or provide",
    "start": "2444900",
    "end": "2450450"
  },
  {
    "text": "guidance for that but we won't try and drive people to any specific tool set",
    "start": "2450450",
    "end": "2455789"
  },
  {
    "text": "like our first iteration when we were copying content it was just a singular copy single thread copy it over right so",
    "start": "2455789",
    "end": "2463500"
  },
  {
    "text": "over time we see that then we'll say you know what instead do a couple of parallels do it apply chunking so that's",
    "start": "2463500",
    "end": "2471690"
  },
  {
    "text": "where we'll kind of interject if you make but otherwise not really any other",
    "start": "2471690",
    "end": "2479220"
  },
  {
    "text": "questions yeah",
    "start": "2479220",
    "end": "2484010"
  },
  {
    "text": "sorry can you repeat it so the question",
    "start": "2487710",
    "end": "2496690"
  },
  {
    "text": "is how do you manage the cost of all of these petabytes worth of data that you're storing I think you really have",
    "start": "2496690",
    "end": "2504280"
  },
  {
    "text": "to look at it in comparison to how you might have been doing that on Prem and",
    "start": "2504280",
    "end": "2510700"
  },
  {
    "text": "the TCO is that applies to how you might do it in the cloud right so we take",
    "start": "2510700",
    "end": "2517240"
  },
  {
    "text": "advantage of things like obviously everything gets life cycle into glaciar right and if we do a restore it's a",
    "start": "2517240",
    "end": "2524200"
  },
  {
    "text": "batch restore so there's a certain queue before things get pulled from that there's a finite set of time that",
    "start": "2524200",
    "end": "2531640"
  },
  {
    "text": "they're restored for for us to be able to do the work against that so if it's a transcode we'll know that it will",
    "start": "2531640",
    "end": "2537880"
  },
  {
    "text": "complete an X amount of time for Y amounts of say a feature and we're sort",
    "start": "2537880",
    "end": "2543400"
  },
  {
    "text": "of lucky for these kinds of things because dealing with episodic or feature based content many of these things are",
    "start": "2543400",
    "end": "2549940"
  },
  {
    "text": "within the same bucket of duration so we can get an estimate or a guesstimate of how long say a spot fleet is going to",
    "start": "2549940",
    "end": "2557050"
  },
  {
    "text": "take to process and transcode that so it's really controlling that life cycle right and then offsetting it against all",
    "start": "2557050",
    "end": "2564610"
  },
  {
    "text": "the sands all the tape based storage all the people to manage that on Prem that",
    "start": "2564610",
    "end": "2569920"
  },
  {
    "text": "you might have done before that you can now automate in the cloud if you will so",
    "start": "2569920",
    "end": "2577920"
  },
  {
    "text": "yes so a lot of the question was did we build our own platform for this a lot of",
    "start": "2577920",
    "end": "2584530"
  },
  {
    "text": "the tooling we're using is AWS specific like the tooling I talked about but it's",
    "start": "2584530",
    "end": "2589690"
  },
  {
    "text": "more the core and the primitives but everything else that we do on top of",
    "start": "2589690",
    "end": "2595030"
  },
  {
    "text": "that if it's for example scheduling jobs running them through pipelines service",
    "start": "2595030",
    "end": "2602140"
  },
  {
    "text": "or batch based processing that's all what we've built right so that that one diagram I showed with that full supply",
    "start": "2602140",
    "end": "2609010"
  },
  {
    "text": "chain flow those are all individual services that touch and manipulate the content is part of this platform",
    "start": "2609010",
    "end": "2615440"
  },
  {
    "text": "I have three questions yes slowly but",
    "start": "2615440",
    "end": "2628010"
  },
  {
    "text": "surely so the question was how do you manage the transfer of petabytes of",
    "start": "2628010",
    "end": "2634250"
  },
  {
    "start": "2631000",
    "end": "2726000"
  },
  {
    "text": "content to the cloud so there are number ways to do it right and probably speaking wider than our use case because",
    "start": "2634250",
    "end": "2641240"
  },
  {
    "text": "we have certain security constraints on the manner at which we can bring content",
    "start": "2641240",
    "end": "2646339"
  },
  {
    "text": "into the cloud and then secure it right but essentially you know it's either",
    "start": "2646339",
    "end": "2652970"
  },
  {
    "text": "Direct Connect as one Avenue right or public Internet if you have sufficient",
    "start": "2652970",
    "end": "2659000"
  },
  {
    "text": "connectivity from on-prem to get there right and then the second part of that",
    "start": "2659000",
    "end": "2664550"
  },
  {
    "text": "equation is it's more specific to what we do so we also use things like aspera",
    "start": "2664550",
    "end": "2670490"
  },
  {
    "text": "for example so udp-based acceleration there are many other options out there",
    "start": "2670490",
    "end": "2675740"
  },
  {
    "text": "Cygnet etcetera there's some I think there are some open source options too right but that's one one Avenue to look",
    "start": "2675740",
    "end": "2683660"
  },
  {
    "text": "at you know we we don't use things like transfer acceleration because we're actually fairly close to the region",
    "start": "2683660",
    "end": "2690140"
  },
  {
    "text": "where we need to land content but like I said it's a it's a it's a pipeline so",
    "start": "2690140",
    "end": "2696050"
  },
  {
    "text": "it's also a human based pipeline right of them digitizing tapes putting them into a transfer server and then",
    "start": "2696050",
    "end": "2703010"
  },
  {
    "text": "basically having that cranking at line speed 24/7 right so if you can do that",
    "start": "2703010",
    "end": "2709490"
  },
  {
    "text": "in multiple parallel paths and that we haven't even talked about things like snowball etc yet but if you can do at",
    "start": "2709490",
    "end": "2716960"
  },
  {
    "text": "that fashion and you can sort of project how much content you will land in AWS",
    "start": "2716960",
    "end": "2722329"
  },
  {
    "text": "right another question yep thanks yeah",
    "start": "2722329",
    "end": "2728390"
  },
  {
    "start": "2726000",
    "end": "2906000"
  },
  {
    "text": "we have used a combination of aspirin and a snowboarder the second one is do",
    "start": "2728390",
    "end": "2733940"
  },
  {
    "text": "you maintain any doctor history yes we do yeah right now we're using ECR we're",
    "start": "2733940",
    "end": "2742760"
  },
  {
    "text": "looking at just swapping out the ECR part for just a doctor distribution and then",
    "start": "2742760",
    "end": "2750950"
  },
  {
    "text": "still back it with s3 just cuz of the s Eleison UCR but so far we're just using",
    "start": "2750950",
    "end": "2756120"
  },
  {
    "text": "VCR it's private so that that shared zone that I was talking about that's where all the images live as well that's",
    "start": "2756120",
    "end": "2763530"
  },
  {
    "text": "where the registry lives so once again common things live in there and then we",
    "start": "2763530",
    "end": "2768570"
  },
  {
    "text": "manage that registry I'm and as part of the onboarding we also take care of creating setting up the policies and",
    "start": "2768570",
    "end": "2775110"
  },
  {
    "text": "just getting them bootstrapped and available okay third big question you",
    "start": "2775110",
    "end": "2781260"
  },
  {
    "text": "mentioned you have certain guardrails for the darker on in terms of tools or",
    "start": "2781260",
    "end": "2787860"
  },
  {
    "text": "security and the version control of the talkers so do you automate it or is it manual or",
    "start": "2787860",
    "end": "2795690"
  },
  {
    "text": "how do you do it which portion upgrading darker itself the images the containers",
    "start": "2795690",
    "end": "2802340"
  },
  {
    "text": "well first of all II in version control is maintained and how do you check the",
    "start": "2802340",
    "end": "2809220"
  },
  {
    "text": "guardrails like on security issues or if any tools that are not allowed here",
    "start": "2809220",
    "end": "2814890"
  },
  {
    "text": "so everything is driven from the CI CD pipeline so a single get push drives the",
    "start": "2814890",
    "end": "2820620"
  },
  {
    "text": "whole pipeline short of you deploying to like a production environment which it",
    "start": "2820620",
    "end": "2826380"
  },
  {
    "text": "which is on purpose a manual process everything else is automated now as part of that automation like I mentioned",
    "start": "2826380",
    "end": "2832710"
  },
  {
    "text": "earlier things like authentication it's not the developers problem it's a",
    "start": "2832710",
    "end": "2838440"
  },
  {
    "text": "platform service that gets provided you just tell us that you need authentication then the developer is",
    "start": "2838440",
    "end": "2843930"
  },
  {
    "text": "responsible for creating his policies and roles so that's one way we ensure the security and make sure we're not",
    "start": "2843930",
    "end": "2849900"
  },
  {
    "text": "leaking the second one is inline scans as part of the CI CD pipeline so as the",
    "start": "2849900",
    "end": "2857760"
  },
  {
    "text": "build completes the image may complete then there may be n number of processes that may scan each layer with something",
    "start": "2857760",
    "end": "2864480"
  },
  {
    "text": "like black docx or whatever to kind of see okay what did they put in their layer but the idea being then we would",
    "start": "2864480",
    "end": "2872040"
  },
  {
    "text": "just piggyback off of that and once all of those passed then the gate would open",
    "start": "2872040",
    "end": "2877200"
  },
  {
    "text": "for them to actually deploy that artifact sorry OOP that brings to another",
    "start": "2877200",
    "end": "2882369"
  },
  {
    "text": "question on the container security uh what are you using at the moment in which in which context to scan the",
    "start": "2882369",
    "end": "2890019"
  },
  {
    "text": "images or the images right now we're using something called black duck sorry black duck black any other questions you",
    "start": "2890019",
    "end": "2906609"
  },
  {
    "start": "2906000",
    "end": "3011000"
  },
  {
    "text": "mentioned that you you build some tool in-house and some tool using Amazon what",
    "start": "2906609",
    "end": "2912670"
  },
  {
    "text": "about the AI and machine learning stack are you developed in-house most of all",
    "start": "2912670",
    "end": "2918400"
  },
  {
    "text": "yeah most of most of that we develop in-house I'd say the approach of the data science",
    "start": "2918400",
    "end": "2925869"
  },
  {
    "text": "team is like I said we we deal with a large amount of content with a high velocity right so like I talked about",
    "start": "2925869",
    "end": "2933099"
  },
  {
    "text": "earlier sometimes we have to have an absolute as opposed to a confident",
    "start": "2933099",
    "end": "2939339"
  },
  {
    "text": "scoring factor but yet all of the almost everything we're doing is in-house so we",
    "start": "2939339",
    "end": "2946599"
  },
  {
    "text": "will use other things like Karis the tensorflow etc right so common things out there but we'll containerize that",
    "start": "2946599",
    "end": "2953849"
  },
  {
    "text": "but then we'll also use some tools like potentially recognition right as part of",
    "start": "2953849",
    "end": "2959859"
  },
  {
    "text": "like rotoscoping right to identify faces yeah so it's a I'd largely say it's it's",
    "start": "2959859",
    "end": "2967119"
  },
  {
    "text": "a mix but a lot of it is in-house and we try to solve it from the perspective of",
    "start": "2967119",
    "end": "2973769"
  },
  {
    "text": "this would be really easy to solve with ml or DL or AI if you all is there a way",
    "start": "2973769",
    "end": "2980529"
  },
  {
    "text": "for us to more effectively just do this through programming and math and solve the problem that way so I'd say that's",
    "start": "2980529",
    "end": "2986619"
  },
  {
    "text": "sort of the approach that we have thanks my second question is that as you know",
    "start": "2986619",
    "end": "2992019"
  },
  {
    "text": "that a customer nowaday asking more reach entertainment metadata right so",
    "start": "2992019",
    "end": "2997450"
  },
  {
    "text": "what's your strategy as delux to provide more metadata",
    "start": "2997450",
    "end": "3002930"
  },
  {
    "text": "like it keywords sentimental indicators casting crew night yeah Bertie facing so that that's",
    "start": "3002930",
    "end": "3011599"
  },
  {
    "start": "3011000",
    "end": "3171000"
  },
  {
    "text": "all managed through the platform a lot of that comes from the studio's always create curated if you will by the",
    "start": "3011599",
    "end": "3018710"
  },
  {
    "text": "supplier of the content so for example keywords etc synopses the genres etc",
    "start": "3018710",
    "end": "3028569"
  },
  {
    "text": "things like the windows for the content to be available that's all highly curated right as is things like the",
    "start": "3028569",
    "end": "3036049"
  },
  {
    "text": "subtitles right so that's that's done through mostly platforms like sfera that's also part of deluxe and but",
    "start": "3036049",
    "end": "3043700"
  },
  {
    "text": "through localization platform right and you can think of that like our equivalent of Mechanical Turk but for",
    "start": "3043700",
    "end": "3050450"
  },
  {
    "text": "language localization so we do have like we have the ability to do for example we",
    "start": "3050450",
    "end": "3056630"
  },
  {
    "text": "could say oh Team X we're gonna do a work order for you guys to go off and process all of this stuff so that we can",
    "start": "3056630",
    "end": "3062720"
  },
  {
    "text": "label it and then use it for deep learning so that's how internally we're able to reutilize resources without",
    "start": "3062720",
    "end": "3070640"
  },
  {
    "text": "having to form that out right so I think having the content and being able to do that as key for things like deep",
    "start": "3070640",
    "end": "3077960"
  },
  {
    "text": "learning a few all sorry to go off on a tangent but it's somewhat related I mean",
    "start": "3077960",
    "end": "3083599"
  },
  {
    "text": "to add to that like he said most of it is static either provided or some human puts it in but",
    "start": "3083599",
    "end": "3089990"
  },
  {
    "text": "there are certain divisions that do actually will do recognition on say Yoda right like find Yoda give me all the",
    "start": "3089990",
    "end": "3097849"
  },
  {
    "text": "scenes that has Yoda in it and the reason why I picked Yoda as an example because if you think about it from an",
    "start": "3097849",
    "end": "3103190"
  },
  {
    "text": "algorithmic perspective it's a lot I don't want to say simpler but it would be a bit more straightforward given",
    "start": "3103190",
    "end": "3109849"
  },
  {
    "text": "Yoda's features versus identify Khan in a picture so there are some areas where",
    "start": "3109849",
    "end": "3116750"
  },
  {
    "text": "we do take where we can where it's it's fairly easy I'm not gonna I'm using that",
    "start": "3116750",
    "end": "3122180"
  },
  {
    "text": "very carefully but it's not some far Fletch thing where the confidence value is going to be moved things like Yoda or",
    "start": "3122180",
    "end": "3130130"
  },
  {
    "text": "a lightsaber something that's just an odd shape that can easily be identified we do employ some labeling based on yeah",
    "start": "3130130",
    "end": "3138130"
  },
  {
    "text": "I mean that that's like a key use case and that if you took something off the shelf it would recognize say vectors on",
    "start": "3138130",
    "end": "3144370"
  },
  {
    "text": "a human face right but for like a cartoon or a sci-fi character right it",
    "start": "3144370",
    "end": "3150310"
  },
  {
    "text": "might not even recognize that I'll be able to label it per se so for a lot of those kind of like and we have to deal",
    "start": "3150310",
    "end": "3156970"
  },
  {
    "text": "with these kinds of areas esoteric use cases right because of the types of content we process to a lot of those use",
    "start": "3156970",
    "end": "3164350"
  },
  {
    "text": "cases we're going to use things like custom trained models from that",
    "start": "3164350",
    "end": "3169360"
  },
  {
    "text": "perspective I mean that that sort of gets into the like the what's next right",
    "start": "3169360",
    "end": "3174490"
  },
  {
    "start": "3171000",
    "end": "3371000"
  },
  {
    "text": "that's that's one aspect the other aspect is we're looking at things like color grading like for example could we",
    "start": "3174490",
    "end": "3183580"
  },
  {
    "text": "use machine learning or AI or deep learning or just mathematical functions to take say footage that has been graded",
    "start": "3183580",
    "end": "3192600"
  },
  {
    "text": "by an artist and it could be to to basically to normalize it so that you",
    "start": "3192600",
    "end": "3198490"
  },
  {
    "text": "can do VFX on top of that right so this is like a color light or a lookup table",
    "start": "3198490",
    "end": "3204040"
  },
  {
    "text": "right which is you can think of it like as a 3d cube and it's a one way set of mathematical functions but there's",
    "start": "3204040",
    "end": "3211240"
  },
  {
    "text": "complexity because it is one way so could you use something like deep learning to have an artist work on",
    "start": "3211240",
    "end": "3217630"
  },
  {
    "text": "content with a certain look to it and color grading isn't really you know just",
    "start": "3217630",
    "end": "3223690"
  },
  {
    "text": "in the contrast and the balance etc it's more of like what what is the artistic",
    "start": "3223690",
    "end": "3229150"
  },
  {
    "text": "look of the film so it could be you know deeper Browns etc but take that from an",
    "start": "3229150",
    "end": "3235000"
  },
  {
    "text": "artist let them do a couple frames or a couple plates as we call them and then transfer that either to the rest of the",
    "start": "3235000",
    "end": "3242710"
  },
  {
    "text": "scene or to all the other episodes in in that series right so like a good example",
    "start": "3242710",
    "end": "3249010"
  },
  {
    "text": "of what I mean by that and we're not actually doing this yet but it's it's",
    "start": "3249010",
    "end": "3254290"
  },
  {
    "text": "like a kind of a use case right if you looked at like say a show like The Walking Dead versus fear The Walking Dead if you watch those two shows the",
    "start": "3254290",
    "end": "3262600"
  },
  {
    "text": "one has a more really gritty and brown tint to it specifically to do things like invoke",
    "start": "3262600",
    "end": "3270860"
  },
  {
    "text": "you know fear or loathing or whatever in the viewer right from emotional",
    "start": "3270860",
    "end": "3275990"
  },
  {
    "text": "perspective and that's usually done by artist right so how do we actually use ml to transfer that the challenge that",
    "start": "3275990",
    "end": "3283700"
  },
  {
    "text": "we have there with those kinds of use cases not being on the cloud yet is",
    "start": "3283700",
    "end": "3289070"
  },
  {
    "text": "because each one of those plates or frames is about a hundred and thirty megabytes each right so it's a different",
    "start": "3289070",
    "end": "3296270"
  },
  {
    "text": "type of problem we have to solve before we can then figure out how to do the ML against it any other questions yeah so",
    "start": "3296270",
    "end": "3315230"
  },
  {
    "text": "we were actually talking we're laughing because we were talking about this at lunch I was like I should say something",
    "start": "3315230",
    "end": "3321050"
  },
  {
    "text": "to give people an idea the scrutiny that you have to deal with so the prime example I like to use is you would get a",
    "start": "3321050",
    "end": "3328790"
  },
  {
    "text": "job for let's say $100 but you may end up paying 10 times over or 20 times over",
    "start": "3328790",
    "end": "3338290"
  },
  {
    "text": "what you're gonna get paid to do the job so that's what I was saying earlier is once we get the content we're on the",
    "start": "3338290",
    "end": "3344420"
  },
  {
    "text": "hook so if it were to leak from us we're on the hook sorry yeah so it's it's like",
    "start": "3344420",
    "end": "3353890"
  },
  {
    "text": "to your point for a ten dollar job I may need $100,000 policy yeah",
    "start": "3353890",
    "end": "3359840"
  },
  {
    "text": "without saying much more the the scrutiny is very high to the point where",
    "start": "3359840",
    "end": "3366580"
  },
  {
    "text": "yeah it did let's just say it makes life very very interesting yeah so I mean we",
    "start": "3366580",
    "end": "3371870"
  },
  {
    "text": "go through the same kind of things like cuz Deluxe does obviously a swath of stuff on pram right so you the first",
    "start": "3371870",
    "end": "3380690"
  },
  {
    "text": "thing to bear in mind is we're not doing we're not holding the original assets or doing things like movie mastering etc",
    "start": "3380690",
    "end": "3386630"
  },
  {
    "text": "right we're doing distribution here right so it's mezzanine level assets not",
    "start": "3386630",
    "end": "3391790"
  },
  {
    "text": "master so there's also how does that factor into things like MPAA audits csa",
    "start": "3391790",
    "end": "3399320"
  },
  {
    "text": "etc so there's a lineman we have to do there in the cloud the same way that you do it on Prem if",
    "start": "3399320",
    "end": "3406600"
  },
  {
    "text": "you'll and there are groups that are looking at that I mean Amazon's working on that too TPM etc to basically figure",
    "start": "3406600",
    "end": "3415180"
  },
  {
    "text": "out a pattern for different types of workloads if it's supply chain or rendering or whatever it might be and",
    "start": "3415180",
    "end": "3421030"
  },
  {
    "text": "what the security controls are around that so we've actually taken some of",
    "start": "3421030",
    "end": "3426700"
  },
  {
    "text": "those and gone beyond what they expect for security purposes if you'll just as",
    "start": "3426700",
    "end": "3432850"
  },
  {
    "text": "an example yes so the question is the",
    "start": "3432850",
    "end": "3452790"
  },
  {
    "start": "3451000",
    "end": "3600000"
  },
  {
    "text": "crunch portion of the workflow that we showed where does the machine learning",
    "start": "3452790",
    "end": "3458290"
  },
  {
    "text": "portion run either on the ingest or the inference right think of the ingest and the delivery as",
    "start": "3458290",
    "end": "3464890"
  },
  {
    "text": "bookends this runs in the middle kind of in the middle yeah because you'll get",
    "start": "3464890",
    "end": "3470050"
  },
  {
    "text": "the content will do whatever checks we need to do I'll use a simple one let's say we virus scan it that's the bare",
    "start": "3470050",
    "end": "3475240"
  },
  {
    "text": "minimum right before we accept the content once the content is accepted then you have n number of steps that'll",
    "start": "3475240",
    "end": "3481510"
  },
  {
    "text": "happen in between maybe in parallel maybe in sequence until it makes it to",
    "start": "3481510",
    "end": "3486700"
  },
  {
    "text": "delivery so this would probably be not probably this is implicit it's like an",
    "start": "3486700",
    "end": "3492550"
  },
  {
    "text": "implicit task that happens in parallel so you get the content let's say you get some sort of a event or a message other",
    "start": "3492550",
    "end": "3499870"
  },
  {
    "text": "services may continue to do what they need to do and react to that event but in parallel there may be a spawn off to",
    "start": "3499870",
    "end": "3505480"
  },
  {
    "text": "basically say you got a fingerprint or run the analysis but those can happen in",
    "start": "3505480",
    "end": "3510670"
  },
  {
    "text": "parallel right but even if you look at that example we can leverage that too because then if we do scheduling",
    "start": "3510670",
    "end": "3515920"
  },
  {
    "text": "correctly we can grab the content once and run multiple processes against that",
    "start": "3515920",
    "end": "3521230"
  },
  {
    "text": "same download yeah cuz remember this is this is where things like nomad spark",
    "start": "3521230",
    "end": "3526720"
  },
  {
    "text": "etcetera as well as what is your SLA window are really important because if",
    "start": "3526720",
    "end": "3531910"
  },
  {
    "text": "you can defer the compute or if you can at a different time that means you can",
    "start": "3531910",
    "end": "3538000"
  },
  {
    "text": "do things like reduce the amount of ec2 instances you need to do X amount of pieces of content per hour so that then",
    "start": "3538000",
    "end": "3545410"
  },
  {
    "text": "does things like lowering your costs by deferring that and the only way you can do that is if you can land the content",
    "start": "3545410",
    "end": "3552640"
  },
  {
    "text": "somewhere on ingest and then process it in parallel like ads was talking about so as content lands coming into a spare",
    "start": "3552640",
    "end": "3560200"
  },
  {
    "text": "or whatever it then triggers something that has the ability to trigger multiple workflows to do a whole bunch of things",
    "start": "3560200",
    "end": "3567160"
  },
  {
    "text": "in parallel because it's an s3 yeah so",
    "start": "3567160",
    "end": "3593230"
  },
  {
    "text": "the question is actually can you repeat the question [Laughter]",
    "start": "3593230",
    "end": "3600140"
  },
  {
    "text": "yes it's an ongoing process right as as it is with any large organization that",
    "start": "3606840",
    "end": "3613030"
  },
  {
    "text": "has multiple business units with their own tiers of services you know we have",
    "start": "3613030",
    "end": "3619090"
  },
  {
    "text": "we have at least from our perspective the core up and running and then everything can migrate at its own speed",
    "start": "3619090",
    "end": "3626080"
  },
  {
    "text": "right so if you look at like what is the architecture look like there's still connectivity back to on-prem there's",
    "start": "3626080",
    "end": "3632260"
  },
  {
    "text": "still things that run on Prem potentially right so things like Direct Connect Direct Connect gateway we have",
    "start": "3632260",
    "end": "3637900"
  },
  {
    "text": "all of that stuff in operation right so it's more like the core is up and the",
    "start": "3637900",
    "end": "3644170"
  },
  {
    "text": "media ingest is flowing through that and now anything that's ancillary can either lift and shift at their leisure if you",
    "start": "3644170",
    "end": "3651490"
  },
  {
    "text": "will and bolt into the platform because the front-end api's are there or potentially Ryoka TechEd and deployers",
    "start": "3651490",
    "end": "3658180"
  },
  {
    "text": "you know brand new service if you will one question you guys have obviously",
    "start": "3658180",
    "end": "3664090"
  },
  {
    "text": "made a pretty big investment in data science and machine learning and just broadly speaking maybe a soft",
    "start": "3664090",
    "end": "3671010"
  },
  {
    "text": "question what would you say has been your sort of biggest return on investment in this in this area of",
    "start": "3671010",
    "end": "3678029"
  },
  {
    "text": "machine learning has it been cost reductions quality improvement product",
    "start": "3678029",
    "end": "3683940"
  },
  {
    "text": "enhancement or just and it generally curious if there has been sort of one area with its yeah I think the ML not ml",
    "start": "3683940",
    "end": "3691589"
  },
  {
    "text": "use case of conformance it is something that's been at least from our operations",
    "start": "3691589",
    "end": "3698190"
  },
  {
    "text": "folks it's been something that's it's been key for them right from that perspective from other use cases like",
    "start": "3698190",
    "end": "3706319"
  },
  {
    "text": "things like all the transcription etc that were that we're looking at I don't think we've we're still scratching the",
    "start": "3706319",
    "end": "3714000"
  },
  {
    "text": "surface on that even though we're pretty far along in terms of like complexity of platform I think it's more like we have",
    "start": "3714000",
    "end": "3721079"
  },
  {
    "text": "we have all the pieces in place and now it's figuring out from like pardon the",
    "start": "3721079",
    "end": "3727140"
  },
  {
    "text": "pun of the title of the talk but like from an operational perspective how can we like apply these things to this data",
    "start": "3727140",
    "end": "3733829"
  },
  {
    "text": "that we have right to enrich it if you will or to better the business from that perspective I mean to add to what he",
    "start": "3733829",
    "end": "3741930"
  },
  {
    "text": "just said if you look at traditionally when you're working with content there",
    "start": "3741930",
    "end": "3748859"
  },
  {
    "text": "are a lot of steps in the workflow that require you to watch the whole movie right like you said conformance you would have",
    "start": "3748859",
    "end": "3754920"
  },
  {
    "text": "to watch it to line up the audio or the subtitle or whatever it is hour and a half movie there's an hour and a half",
    "start": "3754920",
    "end": "3761789"
  },
  {
    "text": "just gone god forbid it's a Bollywood movie you're stuck for three hours right but I think",
    "start": "3761789",
    "end": "3767730"
  },
  {
    "text": "that that is where the biggest gain is obtained because now we can identify markers and do a pre lineup and now",
    "start": "3767730",
    "end": "3775880"
  },
  {
    "text": "whoever the operator is no longer has to sit at his desk lead through a whole movie just finding markers yeah I think",
    "start": "3775880",
    "end": "3784289"
  },
  {
    "text": "that's where the biggest game yeah well think of file names right as these files",
    "start": "3784289",
    "end": "3789599"
  },
  {
    "text": "arrive you don't have to have a taxonomy for naming the files if you're fingerprinting them you can fingerprint",
    "start": "3789599",
    "end": "3796170"
  },
  {
    "text": "something by canceling out the speech track and go okay this is potentially",
    "start": "3796170",
    "end": "3801619"
  },
  {
    "text": "same audio but in a different language right so whatever if someone makes a",
    "start": "3801619",
    "end": "3806720"
  },
  {
    "text": "typo on the file name before uploading it it's not something that would block us from ingesting the content and then",
    "start": "3806720",
    "end": "3813259"
  },
  {
    "text": "if if you multiply that out by all the amount or pieces of content landing right that's that's a huge one not to",
    "start": "3813259",
    "end": "3820309"
  },
  {
    "text": "have to even look at that as it gets ingested good thanks I think that's all",
    "start": "3820309",
    "end": "3828589"
  },
  {
    "text": "we have time for thanks [Applause]",
    "start": "3828589",
    "end": "3835920"
  }
]
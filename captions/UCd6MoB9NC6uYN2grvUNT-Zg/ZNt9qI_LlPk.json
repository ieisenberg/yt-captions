[
  {
    "text": "Hello, everyone, I'm Seema.",
    "start": "7415",
    "end": "9231"
  },
  {
    "text": "Today we have Deanne, from Autodesk, with us.",
    "start": "9231",
    "end": "11536"
  },
  {
    "text": "Welcome, Deanne. ",
    "start": "11536",
    "end": "12579"
  },
  {
    "text": "Hi, Seema, thank you, glad to be here. ",
    "start": "12579",
    "end": "14508"
  },
  {
    "text": "Can you tell us a little bit more about Autodesk",
    "start": "14508",
    "end": "16967"
  },
  {
    "text": "and your use case?",
    "start": "16967",
    "end": "18189"
  },
  {
    "text": "Yeah, Autodesk provides design and makes software",
    "start": "18190",
    "end": "21460"
  },
  {
    "text": "for innovators, for them to achieve the new possible.",
    "start": "21460",
    "end": "24098"
  },
  {
    "text": "Okay.",
    "start": "24098",
    "end": "24931"
  },
  {
    "text": "For our use case, this is our data pipeline.",
    "start": "24931",
    "end": "27427"
  },
  {
    "text": "And we have data coming in to S3,",
    "start": "27427",
    "end": "30833"
  },
  {
    "text": "in the volume of 13 terabytes, daily.",
    "start": "30833",
    "end": "34715"
  },
  {
    "text": "Once the data comes in, we trigger ",
    "start": "34715",
    "end": "38787"
  },
  {
    "text": "an event to simple notification service or SNS,",
    "start": "38787",
    "end": "42468"
  },
  {
    "text": "which then triggers invocations to the Lambdas that we have.",
    "start": "42469",
    "end": "46173"
  },
  {
    "text": "So our Lambdas do a lot of processing,",
    "start": "46173",
    "end": "48531"
  },
  {
    "text": "cleansing, the enrichment of the data,",
    "start": "48531",
    "end": "51071"
  },
  {
    "text": "and once those are done it actually writes metadata ",
    "start": "51071",
    "end": "55387"
  },
  {
    "text": "into DynamoDB.",
    "start": "55387",
    "end": "57492"
  },
  {
    "text": "And that metadata is actually read by",
    "start": "57492",
    "end": "60830"
  },
  {
    "text": "Elastic Container Service or ECS,",
    "start": "60830",
    "end": "63549"
  },
  {
    "text": "in order for it to do batch processing.",
    "start": "63549",
    "end": "67190"
  },
  {
    "text": "Okay.",
    "start": "67190",
    "end": "68221"
  },
  {
    "text": "And then, once ECS processing is done,",
    "start": "68221",
    "end": "71513"
  },
  {
    "text": "it actually writes data back into S3",
    "start": "71513",
    "end": "74243"
  },
  {
    "text": "for our end users to be able to use that data.",
    "start": "74243",
    "end": "77836"
  },
  {
    "text": "OK, what kind of batch processing",
    "start": "77836",
    "end": "80075"
  },
  {
    "text": "does ECS do?",
    "start": "80075",
    "end": "81666"
  },
  {
    "text": "Yeah, sure, so, ECS is actually a",
    "start": "81666",
    "end": "84783"
  },
  {
    "text": "Async RESTful Web API Service",
    "start": "84783",
    "end": "87509"
  },
  {
    "text": "and what it does is that it batches altogether ",
    "start": "87510",
    "end": "90451"
  },
  {
    "text": "the output JSONs from the Lambda",
    "start": "90451",
    "end": "92953"
  },
  {
    "text": "into a batch Parquet format for read efficiency.",
    "start": "92954",
    "end": "97504"
  },
  {
    "text": "OK, sure.",
    "start": "97504",
    "end": "99048"
  },
  {
    "text": "And how would SNS offer any other functionalities",
    "start": "99049",
    "end": "102711"
  },
  {
    "text": "that you're trying to achieve?",
    "start": "102711",
    "end": "104197"
  },
  {
    "text": "Yep, for SNS, actually, we use it in two ways.",
    "start": "104197",
    "end": "108344"
  },
  {
    "text": "One is this notification, and the other way is",
    "start": "108344",
    "end": "110956"
  },
  {
    "text": "these Lambdas, right, they actually have",
    "start": "110956",
    "end": "112983"
  },
  {
    "text": "an internal retry mechanism, ",
    "start": "112983",
    "end": "115183"
  },
  {
    "text": "and once that retry mechanism, the processing still fails, ",
    "start": "115183",
    "end": "119571"
  },
  {
    "text": "we actually trigger, send an event to SNS,",
    "start": "119571",
    "end": "122778"
  },
  {
    "text": "which then triggers another Lambda",
    "start": "122778",
    "end": "125178"
  },
  {
    "text": "to copy that erroneous file back into S3",
    "start": "125178",
    "end": "129162"
  },
  {
    "text": "for us to investigate what's going on with that file.",
    "start": "129163",
    "end": "132189"
  },
  {
    "text": "OK, so your data volume is always 13 terabytes?",
    "start": "132190",
    "end": "135634"
  },
  {
    "text": "That's an interesting question.",
    "start": "135634",
    "end": "137787"
  },
  {
    "text": "The data volume, it doesn't come in ",
    "start": "138357",
    "end": "139982"
  },
  {
    "text": "into a stream like this, it actually has peaks and ",
    "start": "139982",
    "end": "143019"
  },
  {
    "text": "troughs like that, so at one point in time",
    "start": "143019",
    "end": "145581"
  },
  {
    "text": "it can be as low as one terabyte, ",
    "start": "145581",
    "end": "147549"
  },
  {
    "text": "and at its peak it can actually go up to 13 terabytes.",
    "start": "147550",
    "end": "151232"
  },
  {
    "text": "In fact, one of the challenges that we were",
    "start": "151232",
    "end": "154401"
  },
  {
    "text": "trying to solve with this serverless architecture",
    "start": "154401",
    "end": "156831"
  },
  {
    "text": "is because of this.",
    "start": "156831",
    "end": "158579"
  },
  {
    "text": "In our traditional Spark-based processing,",
    "start": "158992",
    "end": "161436"
  },
  {
    "text": "in order for us to be able to process the peak data volume,",
    "start": "161436",
    "end": "165072"
  },
  {
    "text": "we have to provision memory, in order to be able to ",
    "start": "165072",
    "end": "168322"
  },
  {
    "text": "handle this, but in cases where",
    "start": "168322",
    "end": "171119"
  },
  {
    "text": "the data volume is at its low, it becomes",
    "start": "171119",
    "end": "173236"
  },
  {
    "text": "very inefficient and very costly.",
    "start": "173236",
    "end": "175398"
  },
  {
    "text": "That's the first, and the second one, actually,",
    "start": "175399",
    "end": "177818"
  },
  {
    "text": "is that as the data volume increases,",
    "start": "177818",
    "end": "179913"
  },
  {
    "text": "this is the data volume right now, ",
    "start": "179914",
    "end": "181956"
  },
  {
    "text": "but it keeps growing and growing.",
    "start": "181956",
    "end": "183902"
  },
  {
    "text": "So, our Spark-based data pipelines",
    "start": "183902",
    "end": "186472"
  },
  {
    "text": "are starting to struggle in processing that data,",
    "start": "186473",
    "end": "189866"
  },
  {
    "text": "so the data processing becomes longer and longer",
    "start": "189866",
    "end": "192914"
  },
  {
    "text": "and our users have to end up waiting a longer time",
    "start": "192914",
    "end": "195738"
  },
  {
    "text": "before data becomes available.",
    "start": "195738",
    "end": "197427"
  },
  {
    "text": "Whereas with this new event-based architecture,",
    "start": "197427",
    "end": "200163"
  },
  {
    "text": "data actually is provided to our users ",
    "start": "200163",
    "end": "203054"
  },
  {
    "text": "in near real time at a fraction of the cost.",
    "start": "203054",
    "end": "205409"
  },
  {
    "text": "OK, sure, and,",
    "start": "205409",
    "end": "208048"
  },
  {
    "text": "so, what are some of the challenges",
    "start": "208048",
    "end": "210409"
  },
  {
    "text": "or learnings that you have from this architecture,",
    "start": "210409",
    "end": "212937"
  },
  {
    "text": "and can you share with us?",
    "start": "212937",
    "end": "214157"
  },
  {
    "text": "Sure, this is actually an interesting use case",
    "start": "214158",
    "end": "216393"
  },
  {
    "text": "to be using Lambda for such a huge amount of data volume.",
    "start": "216393",
    "end": "219757"
  },
  {
    "text": "As with Lambda, it's not traditionally used for ",
    "start": "220787",
    "end": "223925"
  },
  {
    "text": "big data processing like this, ",
    "start": "223925",
    "end": "225956"
  },
  {
    "text": "but since it's an interesting use case",
    "start": "225956",
    "end": "228028"
  },
  {
    "text": "we just have to be mindful and smart about",
    "start": "228028",
    "end": "230978"
  },
  {
    "text": "how we're using Lambda, and the application code ",
    "start": "230978",
    "end": "233836"
  },
  {
    "text": "that we have should be very efficient",
    "start": "233837",
    "end": "236223"
  },
  {
    "text": "in processing such huge amounts of data volume.",
    "start": "236223",
    "end": "238639"
  },
  {
    "text": "That's the first one, and the second challenge, actually, ",
    "start": "238639",
    "end": "241577"
  },
  {
    "text": "that we met, this is not the original architecture, ",
    "start": "241577",
    "end": "244349"
  },
  {
    "text": "initially we were using S3",
    "start": "244350",
    "end": "246472"
  },
  {
    "text": "to read and write the metadata.",
    "start": "246472",
    "end": "249353"
  },
  {
    "text": "However, when we were doing that, we found that",
    "start": "249353",
    "end": "251667"
  },
  {
    "text": "the Lambdas were taking around 15 minutes ",
    "start": "251667",
    "end": "254335"
  },
  {
    "text": "to process and often times timing out.",
    "start": "254335",
    "end": "256913"
  },
  {
    "text": "And when we dug deeper, we found that, because of S3,",
    "start": "256913",
    "end": "261057"
  },
  {
    "text": "is not a service that is catered to ",
    "start": "261058",
    "end": "264580"
  },
  {
    "text": "low latency high throughput operations.",
    "start": "264580",
    "end": "267000"
  },
  {
    "text": "So, we actually did some research and found",
    "start": "267001",
    "end": "269195"
  },
  {
    "text": "that we had to replace it with a service ",
    "start": "269195",
    "end": "271464"
  },
  {
    "text": "that is fit for that purpose, which is DynamoDB. ",
    "start": "271464",
    "end": "274818"
  },
  {
    "text": "DynamoDB is a service that handles ",
    "start": "274818",
    "end": "277309"
  },
  {
    "text": "throughput and latency very well",
    "start": "277309",
    "end": "279129"
  },
  {
    "text": "and once we replaced that service, ",
    "start": "279129",
    "end": "282068"
  },
  {
    "text": "we actually bring down our processing time ",
    "start": "282068",
    "end": "284190"
  },
  {
    "text": "from 15 minutes down to 20 seconds. ",
    "start": "284190",
    "end": "286758"
  },
  {
    "text": "OK.",
    "start": "286758",
    "end": "287767"
  },
  {
    "text": "Are there any enhancements that you're",
    "start": "287767",
    "end": "289576"
  },
  {
    "text": "planning for the architecture?",
    "start": "289576",
    "end": "290932"
  },
  {
    "text": "Yep, one enhancement is actually this, ",
    "start": "290933",
    "end": "293567"
  },
  {
    "text": "right now, we plan to use, manage SQS",
    "start": "293567",
    "end": "297750"
  },
  {
    "text": "for better efficiency in handling the data",
    "start": "297750",
    "end": "300200"
  },
  {
    "text": "and handing the notifications.",
    "start": "300200",
    "end": "301950"
  },
  {
    "text": "That's one of the key changes to the architecture",
    "start": "301950",
    "end": "304448"
  },
  {
    "text": "that we want to make in the real near future.",
    "start": "304448",
    "end": "306632"
  },
  {
    "text": "OK, awesome.",
    "start": "306632",
    "end": "308317"
  },
  {
    "text": "So, I enjoyed this conversation,",
    "start": "309226",
    "end": "311277"
  },
  {
    "text": "hope you did enjoy as well.",
    "start": "311277",
    "end": "312868"
  },
  {
    "text": "Thank you so much.",
    "start": "312868",
    "end": "313792"
  },
  {
    "text": "'This is My Architecture'.",
    "start": "313792",
    "end": "315771"
  }
]
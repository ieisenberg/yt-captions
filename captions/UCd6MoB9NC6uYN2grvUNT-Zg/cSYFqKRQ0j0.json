[
  {
    "start": "0",
    "end": "30000"
  },
  {
    "text": "good welcome everyone for today's",
    "start": "30",
    "end": "5160"
  },
  {
    "text": "session on sage maker and how to enable sage maker and a highly regulated",
    "start": "5160",
    "end": "10410"
  },
  {
    "text": "environment myself Rita Shah work for Vanguard Group as a Senior Program",
    "start": "10410",
    "end": "17279"
  },
  {
    "text": "Manager for enabling AI and machine learning services Jana",
    "start": "17279",
    "end": "22800"
  },
  {
    "text": "my name is a home Pham I'm the lead engineer for the cloud alex services at",
    "start": "22800",
    "end": "28080"
  },
  {
    "text": "mango so to start to it let's start with the",
    "start": "28080",
    "end": "33239"
  },
  {
    "start": "30000",
    "end": "62000"
  },
  {
    "text": "agenda for today right we are gonna go high-level first with sage maker and",
    "start": "33239",
    "end": "39450"
  },
  {
    "text": "over we offered some of the key requirements that we had and then we start going deeper into how did we",
    "start": "39450",
    "end": "46770"
  },
  {
    "text": "enable sage maker reference architectures and designs how did we",
    "start": "46770",
    "end": "54149"
  },
  {
    "text": "secure it etc and some challenges and solutions that you can take away before",
    "start": "54149",
    "end": "62820"
  },
  {
    "start": "62000",
    "end": "94000"
  },
  {
    "text": "we go deeper into sage maker right quick question how many of you know Wanggaard",
    "start": "62820",
    "end": "68369"
  },
  {
    "text": "here ok 50 percent a quick Vanguard",
    "start": "68369",
    "end": "74490"
  },
  {
    "text": "intro slide right we are one of the top mutual fund companies in us our core",
    "start": "74490",
    "end": "82799"
  },
  {
    "text": "purpose is to take a stand for investor and help them save for their long-term",
    "start": "82799",
    "end": "89549"
  },
  {
    "text": "retirement and other goals let's start",
    "start": "89549",
    "end": "96360"
  },
  {
    "start": "94000",
    "end": "156000"
  },
  {
    "text": "with another question how many of you know what sage make arise ok 70% of the",
    "start": "96360",
    "end": "103500"
  },
  {
    "text": "people know but quick intro sage maker a managed service that offers full machine",
    "start": "103500",
    "end": "110909"
  },
  {
    "text": "learning capabilities for everybody to use you can belt train and deploy our",
    "start": "110909",
    "end": "118079"
  },
  {
    "text": "models that you build using sage maker and you can deploy it as endpoints that",
    "start": "118079",
    "end": "124259"
  },
  {
    "text": "can be called through micro services or you can run it as match more as a model",
    "start": "124259",
    "end": "132099"
  },
  {
    "text": "it also comes with optimized frameworks and algorithms that run on AWS",
    "start": "132099",
    "end": "139709"
  },
  {
    "text": "infrastructure efficiently and last but not least you can bring your own machine",
    "start": "139709",
    "end": "146530"
  },
  {
    "text": "learning models and algorithms if you don't see that the optimized ones don't",
    "start": "146530",
    "end": "152620"
  },
  {
    "text": "work for your use case next section is a",
    "start": "152620",
    "end": "158019"
  },
  {
    "start": "156000",
    "end": "336000"
  },
  {
    "text": "typical life cycle in and in Amazon sage maker right if you use it and why am I",
    "start": "158019",
    "end": "165310"
  },
  {
    "text": "talking about life cycle when this is a security conference right the most important thing I think we want to share",
    "start": "165310",
    "end": "172389"
  },
  {
    "text": "with all of you is most data scientists and machine learning engineers work in a",
    "start": "172389",
    "end": "178870"
  },
  {
    "text": "production environment they don't work like a typical developer or an engineer",
    "start": "178870",
    "end": "184000"
  },
  {
    "text": "where they have a development environment and then they have a test environment where they test and then",
    "start": "184000",
    "end": "190540"
  },
  {
    "text": "they deploy something to production they typically work right in production with",
    "start": "190540",
    "end": "195879"
  },
  {
    "text": "production data that is their development environment and then how do you securely enable that capability is",
    "start": "195879",
    "end": "204250"
  },
  {
    "text": "why life cycle in Sage Maker is very important first piece of the life cycle",
    "start": "204250",
    "end": "210910"
  },
  {
    "text": "is you build a machine learning algorithm or a model that meets your use",
    "start": "210910",
    "end": "216730"
  },
  {
    "text": "case and to build that you basically use a jupiter notebook you bring in your own",
    "start": "216730",
    "end": "223060"
  },
  {
    "text": "models or you bring in or utilize the ones provided by sage maker and also the",
    "start": "223060",
    "end": "229959"
  },
  {
    "text": "same notebook interface helps you prepare the data for the model while",
    "start": "229959",
    "end": "236409"
  },
  {
    "text": "you're working in a production environment next is once you do the",
    "start": "236409",
    "end": "243669"
  },
  {
    "text": "build of a model which is your development activity you train the model",
    "start": "243669",
    "end": "249459"
  },
  {
    "text": "so that you know that outcomes that it has to achieve are achieved using",
    "start": "249459",
    "end": "255099"
  },
  {
    "text": "algorithms that are that you are using and there are different techniques that people use to train their model like",
    "start": "255099",
    "end": "262840"
  },
  {
    "text": "hyper parameter tuning exact once you train the model you want to",
    "start": "262840",
    "end": "268780"
  },
  {
    "text": "validate your model make sure the model yields the outcomes that you are looking",
    "start": "268780",
    "end": "274630"
  },
  {
    "text": "for and if you're happy with it that's where your development lifecycle ends as",
    "start": "274630",
    "end": "280630"
  },
  {
    "text": "a typical data scientist where now you are ready to say my model is ready to be",
    "start": "280630",
    "end": "288460"
  },
  {
    "text": "put in production either as an endpoint or I can run it and match more every",
    "start": "288460",
    "end": "294010"
  },
  {
    "text": "other day and if it is an endpoint it can start taking traffic from other",
    "start": "294010",
    "end": "299200"
  },
  {
    "text": "micro services or web applications which brings to the final phase where you",
    "start": "299200",
    "end": "305920"
  },
  {
    "text": "deploy the model into production and it provides you that capability and at one",
    "start": "305920",
    "end": "312310"
  },
  {
    "text": "God we want the data scientist to perform all these activities themselves",
    "start": "312310",
    "end": "318160"
  },
  {
    "text": "with minimum IT intervention which is why explaining this typical life cycle",
    "start": "318160",
    "end": "324700"
  },
  {
    "text": "inside maker is important because it's the end business streams utilizing the",
    "start": "324700",
    "end": "331630"
  },
  {
    "text": "service to make everything function",
    "start": "331630",
    "end": "335940"
  },
  {
    "start": "336000",
    "end": "478000"
  },
  {
    "text": "before we went down that path we had some key requirements that we wanted to ensure are met first is anytime you have",
    "start": "336840",
    "end": "346690"
  },
  {
    "text": "a data scientist working in production environment we want them to work with",
    "start": "346690",
    "end": "351960"
  },
  {
    "text": "data that is encrypted at rest and while they are building their model or",
    "start": "351960",
    "end": "357670"
  },
  {
    "text": "training in transit it's encrypted there was a requirement next requirement was",
    "start": "357670",
    "end": "363550"
  },
  {
    "text": "we don't want data scientists to access public internet download algorithms that",
    "start": "363550",
    "end": "370660"
  },
  {
    "text": "are not thoroughly gone through a governance process at Vanguard so we",
    "start": "370660",
    "end": "375910"
  },
  {
    "text": "wanted to block access to general internet when they are using sage maker as a machine learning service all",
    "start": "375910",
    "end": "385030"
  },
  {
    "text": "actions which is the third requirement of all actions that the user performs",
    "start": "385030",
    "end": "391300"
  },
  {
    "text": "either during build or train or validation of the model needs to be",
    "start": "391300",
    "end": "396730"
  },
  {
    "text": "audited so that if we perform an internal audit and ask ourselves a question who train this",
    "start": "396730",
    "end": "404620"
  },
  {
    "text": "model or who built this model that got hosted on a website we should be able to",
    "start": "404620",
    "end": "410289"
  },
  {
    "text": "track it all back saying this is the user who did the building and then this",
    "start": "410289",
    "end": "416710"
  },
  {
    "text": "is the user who trained the model next when we deploy the model into production",
    "start": "416710",
    "end": "424300"
  },
  {
    "text": "as endpoints or batch we wanted to use CI CD based deployments so that data",
    "start": "424300",
    "end": "431469"
  },
  {
    "text": "scientist doesn't have to work or navigate through IT processes to get",
    "start": "431469",
    "end": "437020"
  },
  {
    "text": "something into production it should be as simple as push a button and their model gets elevated to production when",
    "start": "437020",
    "end": "444400"
  },
  {
    "text": "they want to next requirement like I",
    "start": "444400",
    "end": "450699"
  },
  {
    "text": "said earlier we wanted to minimize IT support needed so that business can self",
    "start": "450699",
    "end": "456550"
  },
  {
    "text": "provision and if we meet all these five requirements we wanted to also make sure",
    "start": "456550",
    "end": "462550"
  },
  {
    "text": "that sage maker service is easy to use so that data scientists don't get a tool",
    "start": "462550",
    "end": "470639"
  },
  {
    "text": "that has met all these requirements but is unusable by then next I want to good",
    "start": "470639",
    "end": "480819"
  },
  {
    "start": "478000",
    "end": "690000"
  },
  {
    "text": "at a 25k feet level of how did we enable sage maker across this entire lifecycle",
    "start": "480819",
    "end": "487839"
  },
  {
    "text": "and hang is gonna go deeper into each of these sections of the lifecycle and go",
    "start": "487839",
    "end": "494620"
  },
  {
    "text": "through some security and other concepts a first piece like I said we have data",
    "start": "494620",
    "end": "500469"
  },
  {
    "text": "scientists who work in production and actually build and code and develop",
    "start": "500469",
    "end": "507279"
  },
  {
    "text": "their model in production so that's the first phase where we enabled a Jupiter",
    "start": "507279",
    "end": "513159"
  },
  {
    "text": "notebook through AWS Service Catalog interface where data scientists can go",
    "start": "513159",
    "end": "519039"
  },
  {
    "text": "in and spin up their own sage maker notebook instance to write their algorithm and we provisioned them data",
    "start": "519039",
    "end": "527010"
  },
  {
    "text": "and we provision them access using I rolls and these notebooks are",
    "start": "527010",
    "end": "533420"
  },
  {
    "text": "pre-configured to use any algorithms that AWS provides or data scientists can",
    "start": "533420",
    "end": "541160"
  },
  {
    "text": "build their own docker images and bring their own algorithm and deploy it to ECR",
    "start": "541160",
    "end": "548320"
  },
  {
    "text": "next phase like I said we want data scientists to use everything so we",
    "start": "548949",
    "end": "554569"
  },
  {
    "text": "enable the same notebook interface as a mechanism to Train their model we could",
    "start": "554569",
    "end": "562160"
  },
  {
    "text": "have taken a different path where we could have said hey data scientists you go to AWS console and then set up a",
    "start": "562160",
    "end": "569120"
  },
  {
    "text": "training job but we did not do that because moment you do that you will lose added tracking of who ran what job at at",
    "start": "569120",
    "end": "577759"
  },
  {
    "text": "some point in time so we locked them into the notebook and allow them to do training using the notebook which leads",
    "start": "577759",
    "end": "586190"
  },
  {
    "text": "to the next phase of validating the model where we leverage the same name",
    "start": "586190",
    "end": "593360"
  },
  {
    "text": "notebook through which they spin up a batch seed maker batch mechanism and",
    "start": "593360",
    "end": "600139"
  },
  {
    "text": "they validate their model using the data set they want to validate the model with",
    "start": "600139",
    "end": "605290"
  },
  {
    "text": "at this point their development life cycle ends and then the data scientist",
    "start": "605290",
    "end": "612470"
  },
  {
    "text": "takes various artifacts from the validation phase uploads it to code",
    "start": "612470",
    "end": "620209"
  },
  {
    "text": "repositories like artifactory and big bucket and at times he also applauds if",
    "start": "620209",
    "end": "627319"
  },
  {
    "text": "they bring in a custom algorithm he or she would upload a docker image file",
    "start": "627319",
    "end": "632569"
  },
  {
    "text": "into a code repository post which we",
    "start": "632569",
    "end": "639350"
  },
  {
    "text": "have set up an automated bamboo based deployment process that would allow the",
    "start": "639350",
    "end": "644540"
  },
  {
    "text": "data scientists to take the model or the artifacts that they have checked then and they can then deploy the same model",
    "start": "644540",
    "end": "652130"
  },
  {
    "text": "to a development environment a test environment and eventually they will",
    "start": "652130",
    "end": "658130"
  },
  {
    "text": "deploy to production environment using a full CI CD cycle where",
    "start": "658130",
    "end": "664250"
  },
  {
    "text": "there's automated testing done and it also opens automated change records to audit track deployments of artifacts",
    "start": "664250",
    "end": "671810"
  },
  {
    "text": "reproduction this is where we end the",
    "start": "671810",
    "end": "677270"
  },
  {
    "text": "high-level 25k journey but Hong's gonna go deeper into each phase of the",
    "start": "677270",
    "end": "683360"
  },
  {
    "text": "lifecycle so the user is a data",
    "start": "683360",
    "end": "697220"
  },
  {
    "start": "690000",
    "end": "835000"
  },
  {
    "text": "scientist so what we focus on is how to make the self-service capability and how",
    "start": "697220",
    "end": "702950"
  },
  {
    "text": "very easy to use for data scientists so what we found out is a service catalog",
    "start": "702950",
    "end": "708800"
  },
  {
    "text": "can provide all this core functionality it's very easy to log into AWS console",
    "start": "708800",
    "end": "714820"
  },
  {
    "text": "to launch and to terminate service catalog for say Flickr Noble the user",
    "start": "714820",
    "end": "721880"
  },
  {
    "text": "can do it as a self-service on-demand without contacting any active team to",
    "start": "721880",
    "end": "727070"
  },
  {
    "text": "provision the infrastructure the other thing is the service catalog can provide",
    "start": "727070",
    "end": "732140"
  },
  {
    "text": "the standardization of the configurations the default behavior if the use of one creates a speaker Noble",
    "start": "732140",
    "end": "739880"
  },
  {
    "text": "they have to provide a lot of informations like VPC configurations KMS",
    "start": "739880",
    "end": "746030"
  },
  {
    "text": "key internet access service catalog can",
    "start": "746030",
    "end": "751130"
  },
  {
    "text": "provide automation of this component and also provide an abstraction layer of all",
    "start": "751130",
    "end": "757400"
  },
  {
    "text": "the security configurations in a distance we don't hire we don't have to provide the security configuration for",
    "start": "757400",
    "end": "765770"
  },
  {
    "text": "infrastructure for the users instead we provide the security to the I am Service",
    "start": "765770",
    "end": "771410"
  },
  {
    "text": "Catalog role during this project way we was able to implement the",
    "start": "771410",
    "end": "776900"
  },
  {
    "text": "authentications authorizations and auditor building and I wouldn't go over",
    "start": "776900",
    "end": "781910"
  },
  {
    "text": "the detail of that in the next couple of slide the beginning of the signature",
    "start": "781910",
    "end": "788270"
  },
  {
    "text": "implementation we didn't have with the gate integration for service can get",
    "start": "788270",
    "end": "793490"
  },
  {
    "text": "integration for Sage maker so what we did so into Great Sage mikono into the s3 right now we actually in",
    "start": "793490",
    "end": "800990"
  },
  {
    "text": "process a migrate that over to Co commit to allow the user to save and share and",
    "start": "800990",
    "end": "808310"
  },
  {
    "text": "wasn't controlled ennoble maybe four does signature also have a lot of Python",
    "start": "808310",
    "end": "815750"
  },
  {
    "text": "library and machining library inside the signature servers however there is",
    "start": "815750",
    "end": "820880"
  },
  {
    "text": "certainly use case that a days scientists require additional Python",
    "start": "820880",
    "end": "826339"
  },
  {
    "text": "library so what we did is we integrate with an account Vanguard managed",
    "start": "826339",
    "end": "832610"
  },
  {
    "text": "anaconda repository so here's a textured",
    "start": "832610",
    "end": "837709"
  },
  {
    "start": "835000",
    "end": "1049000"
  },
  {
    "text": "diagram for sage maker built service before the user can launch a service",
    "start": "837709",
    "end": "844279"
  },
  {
    "text": "catalog for six-week ennoble this is a one-time initial setup my data team for",
    "start": "844279",
    "end": "851149"
  },
  {
    "text": "example they have to create the IM role for the console access the sedgwick",
    "start": "851149",
    "end": "856339"
  },
  {
    "text": "ennoble execution role the training job execution role the s3 bucket and service",
    "start": "856339",
    "end": "863000"
  },
  {
    "text": "catalog para and portfolio once all the infrastructure is set up the dais",
    "start": "863000",
    "end": "869329"
  },
  {
    "text": "scientists can log into our internal application for Active Directory",
    "start": "869329",
    "end": "874910"
  },
  {
    "text": "credentials for authentications they can start launching their Service Catalog quarter and the sage Vickers Noble",
    "start": "874910",
    "end": "883550"
  },
  {
    "text": "actually live in Sedgwick V PC which is in AWS managed service account so as a",
    "start": "883550",
    "end": "891050"
  },
  {
    "text": "part of the automation of the Service Catalog quarter in our cloud formation to enforce a lot of standard security",
    "start": "891050",
    "end": "897350"
  },
  {
    "text": "configurations for example we disable internet access",
    "start": "897350",
    "end": "902690"
  },
  {
    "text": "for the noble we create the noble and map it to vanguard man it's V pcs what",
    "start": "902690",
    "end": "909770"
  },
  {
    "text": "it means is a behind the scene safe liquor create the e ni for all the",
    "start": "909770",
    "end": "915500"
  },
  {
    "text": "communications between the noble have to go to Vanguard be pcs for example on the",
    "start": "915500",
    "end": "922550"
  },
  {
    "text": "diagram if the six maker no but want to talk to our s3 bucket the cessation",
    "start": "922550",
    "end": "928640"
  },
  {
    "text": "worker know what happens go to the e ni and go to a vanguard vp cs3 endpoint",
    "start": "928640",
    "end": "934140"
  },
  {
    "text": "we're to talk to sv bucket there to type sv bucket on the diagram the first one",
    "start": "934140",
    "end": "941880"
  },
  {
    "text": "is that user works play s3 bucket which allowed the user the data scientists to",
    "start": "941880",
    "end": "947220"
  },
  {
    "text": "put their own data into and to do explore clean and transform the data",
    "start": "947220",
    "end": "953030"
  },
  {
    "text": "that's the experimentation area the second s3 bucket is a master data area",
    "start": "953030",
    "end": "959400"
  },
  {
    "text": "meaning the seismic ANOVA can only have a read-only access to this s3 bucket",
    "start": "959400",
    "end": "964680"
  },
  {
    "text": "this out gold copy and very tightly control the data in this master data",
    "start": "964680",
    "end": "970140"
  },
  {
    "text": "area is typically please bring into the adjacent process for example you have an",
    "start": "970140",
    "end": "975600"
  },
  {
    "text": "EMR cluster Charlie ingest data in and transform the data and store the data this massive data area so next we also",
    "start": "975600",
    "end": "985860"
  },
  {
    "text": "enforce those encryption address for s3",
    "start": "985860",
    "end": "991170"
  },
  {
    "text": "and EBS volume using server-side encryptions customer manage key one",
    "start": "991170",
    "end": "997200"
  },
  {
    "text": "thing to keep in mind for EBS encryption is the question for EBS only applicable",
    "start": "997200",
    "end": "1002900"
  },
  {
    "text": "to the machine learning storage volume it's a Chicano book there is a good",
    "start": "1002900",
    "end": "1009110"
  },
  {
    "text": "volume the route volume is only encrypt it using 2d for server-side encryptions",
    "start": "1009110",
    "end": "1014350"
  },
  {
    "text": "so when we tell are there scientists or anything you put from action in the notebook typically you say the data in",
    "start": "1014350",
    "end": "1020570"
  },
  {
    "text": "s3 bucket or if you want to save data locally you need to store data in the machine learning storage volume and with",
    "start": "1020570",
    "end": "1028880"
  },
  {
    "text": "the new recent release feature by Amazon we also disable root access into the sexual grenoble as well so now the user",
    "start": "1028880",
    "end": "1038959"
  },
  {
    "text": "is able to authenticate themselves to create the Noble the next step is",
    "start": "1038959",
    "end": "1046550"
  },
  {
    "text": "authorizations so by default when you",
    "start": "1046550",
    "end": "1052190"
  },
  {
    "start": "1049000",
    "end": "1271000"
  },
  {
    "text": "want either try to log into the noble the user is a signature authorize the",
    "start": "1052190",
    "end": "1057920"
  },
  {
    "text": "user based on the I am bro",
    "start": "1057920",
    "end": "1061600"
  },
  {
    "text": "with a specific technical permission create presided noble is enjoy",
    "start": "1063480",
    "end": "1068970"
  },
  {
    "text": "permissions however the authorization is at the I am",
    "start": "1068970",
    "end": "1075179"
  },
  {
    "text": "role level from Venga requirement perspective we have auditability",
    "start": "1075179",
    "end": "1080750"
  },
  {
    "text": "requirement then we have the track the user ID the user actions and s3 object",
    "start": "1080750",
    "end": "1089480"
  },
  {
    "text": "so the saw the prom what we did that we create a single tenant six week and",
    "start": "1089480",
    "end": "1096389"
  },
  {
    "text": "observers there's two reasons for that the first one is for auditability",
    "start": "1096389",
    "end": "1103139"
  },
  {
    "text": "meaning if you have a single tenants only single user in the noble it's",
    "start": "1103139",
    "end": "1108419"
  },
  {
    "text": "easier to implement an auditor building the second reason is its allow easier",
    "start": "1108419",
    "end": "1116250"
  },
  {
    "text": "for user experience seen it's very simple to create a service Calla part of",
    "start": "1116250",
    "end": "1122669"
  },
  {
    "text": "all demand for data scientist we don't see the reason why they need to share",
    "start": "1122669",
    "end": "1129600"
  },
  {
    "text": "the notebook with any other people in the tables so with that requirement we want to be",
    "start": "1129600",
    "end": "1136919"
  },
  {
    "text": "able to implement the authorization at the user ID level so what we did as we",
    "start": "1136919",
    "end": "1142860"
  },
  {
    "text": "create the I am tacking conditions to start a palm so when the service",
    "start": "1142860",
    "end": "1150659"
  },
  {
    "text": "calipari tried to launch the second oboe what we did we create a lambda functions",
    "start": "1150659",
    "end": "1156179"
  },
  {
    "text": "to be able to obtain the tagging condition of the sacred of the Service Catalog para",
    "start": "1156179",
    "end": "1161600"
  },
  {
    "text": "we're containing the user ID who launched the product and insert attacking condition into the seismic",
    "start": "1161600",
    "end": "1169409"
  },
  {
    "text": "ennoble tax we create on the screen right now who create a principle tab",
    "start": "1169409",
    "end": "1174769"
  },
  {
    "text": "with the format of row ID : use ID that's on the right hand side on the",
    "start": "1174769",
    "end": "1184889"
  },
  {
    "text": "left hand side we have a customer manage I am policies which using resort act of",
    "start": "1184889",
    "end": "1192659"
  },
  {
    "text": "the principle with the value of a dev yes Colin use ID the reason for that is",
    "start": "1192659",
    "end": "1200190"
  },
  {
    "text": "a AWS : user ID variable for federated login user ID had the same format of the",
    "start": "1200190",
    "end": "1207060"
  },
  {
    "text": "prints or tab that we created by doing so we enforce the user of",
    "start": "1207060",
    "end": "1216500"
  },
  {
    "text": "authorization meaning the user who launched Service Catalog product can",
    "start": "1216500",
    "end": "1222420"
  },
  {
    "text": "only that user can log into the notebook itself for example you have a user a and",
    "start": "1222420",
    "end": "1228930"
  },
  {
    "text": "user be in the same I enroll user a can login to the noble but user B cannot not",
    "start": "1228930",
    "end": "1237270"
  },
  {
    "text": "into that noble at all there is a second",
    "start": "1237270",
    "end": "1242460"
  },
  {
    "text": "I am conditions on the screen as well is an IP address the reason for that is we",
    "start": "1242460",
    "end": "1251820"
  },
  {
    "text": "want to enforce only Vanguard internal network can access this noble for",
    "start": "1251820",
    "end": "1259230"
  },
  {
    "text": "example if the user even even use a copy the access key and secret key into the",
    "start": "1259230",
    "end": "1265590"
  },
  {
    "text": "home laptop at home they cannot login to stage we can double so next thing is",
    "start": "1265590",
    "end": "1274470"
  },
  {
    "start": "1271000",
    "end": "1323000"
  },
  {
    "text": "only the building like we talked before way we want to be to track the user ID and use the action and s3 object by",
    "start": "1274470",
    "end": "1283740"
  },
  {
    "text": "before the I am permissions only track the I am role level in culture event",
    "start": "1283740",
    "end": "1289110"
  },
  {
    "text": "only so to solve that form what we need to be modified the Jupiter server",
    "start": "1289110",
    "end": "1295650"
  },
  {
    "text": "configurations and we create an environment variable quorum AWS execution env environment variable",
    "start": "1295650",
    "end": "1304380"
  },
  {
    "text": "for Sage makers server process that's what you see on the screen and the value",
    "start": "1304380",
    "end": "1310710"
  },
  {
    "text": "for that environment variable is a all the tag in the seismic ennoble which",
    "start": "1310710",
    "end": "1315930"
  },
  {
    "text": "also containing the principle tab which containing the user ID here's example in",
    "start": "1315930",
    "end": "1325470"
  },
  {
    "text": "the class of event we have a the event name is a get object",
    "start": "1325470",
    "end": "1331259"
  },
  {
    "text": "we have a bucket name we'll check out the s3 object key we also have a station",
    "start": "1331259",
    "end": "1338249"
  },
  {
    "text": "with a noble execution role in the cultural event that's a very typical cultural event but the important thing",
    "start": "1338249",
    "end": "1344339"
  },
  {
    "text": "on that screen is we have a user agent that user agent also containing the",
    "start": "1344339",
    "end": "1350999"
  },
  {
    "text": "value of the AWS execution environment variable that we defined previous",
    "start": "1350999",
    "end": "1356119"
  },
  {
    "text": "configurations and that has all the tacking can take conditions and also",
    "start": "1356119",
    "end": "1361769"
  },
  {
    "text": "contain the principal tab with the user ID in it so at this point we should attract the user ID the s3 actions and",
    "start": "1361769",
    "end": "1370649"
  },
  {
    "text": "s3 object so at this point the user able",
    "start": "1370649",
    "end": "1378959"
  },
  {
    "start": "1375000",
    "end": "1476000"
  },
  {
    "text": "to create the significant noble table to log into second noble the next step is",
    "start": "1378959",
    "end": "1387209"
  },
  {
    "text": "they want to create a training job so in order to create a training job they",
    "start": "1387209",
    "end": "1393659"
  },
  {
    "text": "didn't specify the data in s3 bucket and with the algorithm in ecr's so for",
    "start": "1393659",
    "end": "1404159"
  },
  {
    "text": "building algorithm and support framework the algorithm image is stored in EC or",
    "start": "1404159",
    "end": "1413039"
  },
  {
    "text": "that is managed in a desert managed service account so for the easy",
    "start": "1413039",
    "end": "1422159"
  },
  {
    "text": "experience we allowed user to create this training job right from the sedgwick ennoble they can't using model",
    "start": "1422159",
    "end": "1429029"
  },
  {
    "text": "3 and the SDK and in the API they can specify the isn't type number instance",
    "start": "1429029",
    "end": "1437579"
  },
  {
    "text": "the KMS key the VPC configurations so",
    "start": "1437579",
    "end": "1444719"
  },
  {
    "text": "cynical trainee Joe can create the infrastructure train the data and and",
    "start": "1444719",
    "end": "1450629"
  },
  {
    "text": "save the model or fight in s3 bucket the",
    "start": "1450629",
    "end": "1455639"
  },
  {
    "text": "challenge here is is we don't have a service catalog far out to enforce security configurations",
    "start": "1455639",
    "end": "1462300"
  },
  {
    "text": "like we did with the noble so this other form what we did is we create the cloud",
    "start": "1462300",
    "end": "1468420"
  },
  {
    "text": "watch use a cloud watch event and the lambda function to do the insecurity impossible for us so here's the key",
    "start": "1468420",
    "end": "1477750"
  },
  {
    "start": "1476000",
    "end": "1594000"
  },
  {
    "text": "enforcement that we did with the lambda functions we enforce the encryption at",
    "start": "1477750",
    "end": "1484470"
  },
  {
    "text": "rest for s3 and EBS volume using using the server-side encryption cmk customer",
    "start": "1484470",
    "end": "1491460"
  },
  {
    "text": "- key we also enforce encryption for multi node training for",
    "start": "1491460",
    "end": "1497370"
  },
  {
    "text": "intercommunications we also enforce that there is no internet access but making",
    "start": "1497370",
    "end": "1504360"
  },
  {
    "text": "sure that the user create a training job using our vbc configuration nice subnet",
    "start": "1504360",
    "end": "1511650"
  },
  {
    "text": "and security group we set the lambda function enforcement we're also using",
    "start": "1511650",
    "end": "1518309"
  },
  {
    "text": "the I am role to enforce authorizations meaning the notebook execution role can",
    "start": "1518309",
    "end": "1524940"
  },
  {
    "text": "only create a training job with the specific to the job execution wrong we",
    "start": "1524940",
    "end": "1530760"
  },
  {
    "text": "don't want the user to buy to any arbitrary I am law so there is couple",
    "start": "1530760",
    "end": "1538490"
  },
  {
    "text": "challenges with the training job way the first thing is we have a auditability",
    "start": "1538490",
    "end": "1545309"
  },
  {
    "text": "gap as we speak today way we're actively working with civic equality today to",
    "start": "1545309",
    "end": "1552809"
  },
  {
    "text": "figure out how to reserve the audit ability for the training job we actually review the design with the certificate",
    "start": "1552809",
    "end": "1559320"
  },
  {
    "text": "product team and they actually impossibly leave it at fix for us the",
    "start": "1559320",
    "end": "1564929"
  },
  {
    "text": "second challenge is the user experience even they can usually create the training job API in the noble but they",
    "start": "1564929",
    "end": "1572760"
  },
  {
    "text": "still have to specify the I am role the V PC configurations from a data",
    "start": "1572760",
    "end": "1578070"
  },
  {
    "text": "scientist perspective is a non-value-added why didn't they don't want to know about the infrastructure so that we also",
    "start": "1578070",
    "end": "1585420"
  },
  {
    "text": "provide a feedback to the Civic apart time to solder palm long-term",
    "start": "1585420",
    "end": "1592100"
  },
  {
    "start": "1594000",
    "end": "1641000"
  },
  {
    "text": "so at this point with the there are scientists be able to create a training job with the model or the factory store",
    "start": "1594600",
    "end": "1602139"
  },
  {
    "text": "and s3 bucket the data scientists want me to evaluate that model artifact what",
    "start": "1602139",
    "end": "1609759"
  },
  {
    "text": "we did that we create a say we use a signature back transform for the model evaluations the user would have to go to",
    "start": "1609759",
    "end": "1617669"
  },
  {
    "text": "the transform the data create the training job you veget the model to",
    "start": "1617669",
    "end": "1624519"
  },
  {
    "text": "multiple iterations eventually they found the model based on the metric that",
    "start": "1624519",
    "end": "1632559"
  },
  {
    "text": "meet the requirement they need to elevate that model to the hosting endpoint so here's our process - for the",
    "start": "1632559",
    "end": "1648070"
  },
  {
    "start": "1641000",
    "end": "1939000"
  },
  {
    "text": "cyclical deployed the important thing is at this point everything you the data",
    "start": "1648070",
    "end": "1654429"
  },
  {
    "text": "scientists do is that model development process now we call this process is they",
    "start": "1654429",
    "end": "1663399"
  },
  {
    "text": "want to deploy that model into productions we called operationalization process the hosting endpoint is going to",
    "start": "1663399",
    "end": "1672639"
  },
  {
    "text": "be consumed by client application in productions so it is true production",
    "start": "1672639",
    "end": "1677919"
  },
  {
    "text": "applications it's just like any other micro service applications so in order",
    "start": "1677919",
    "end": "1684159"
  },
  {
    "text": "to do that we have to follow the standard development lifecycle deployment process however the user in",
    "start": "1684159",
    "end": "1692739"
  },
  {
    "text": "this case is a data scientist they're not actually team to so in order to make",
    "start": "1692739",
    "end": "1697899"
  },
  {
    "text": "it easier for the users what we did is that we simplified the deployment",
    "start": "1697899",
    "end": "1702940"
  },
  {
    "text": "pipeline we create a single repository for containing all our infrastructure",
    "start": "1702940",
    "end": "1709210"
  },
  {
    "text": "code meaning all the cloud formations to create the create a certificate endpoint segment to employ configurations and say",
    "start": "1709210",
    "end": "1716559"
  },
  {
    "text": "speaker model and the data scientist would not need to know about any of this",
    "start": "1716559",
    "end": "1721809"
  },
  {
    "text": "configuration doesn't need to know about any of this infrastructure component that we look at that we look at",
    "start": "1721809",
    "end": "1729760"
  },
  {
    "text": "repository is managed by centralized infrastructure team the secondary party",
    "start": "1729760",
    "end": "1737350"
  },
  {
    "text": "on the screen is a data scientist management partially they only need to be only need to modify a cup of this the",
    "start": "1737350",
    "end": "1744190"
  },
  {
    "text": "parameter that we really can really find it for them for example the size vehicle",
    "start": "1744190",
    "end": "1750280"
  },
  {
    "text": "model name the URL the employ",
    "start": "1750280",
    "end": "1755470"
  },
  {
    "text": "configurations and the traffic distributions it's with very simple parameters when they submit that what we",
    "start": "1755470",
    "end": "1765910"
  },
  {
    "text": "go to the process they submitted for peer review and approval process this is just a standard normal sdlc process we",
    "start": "1765910",
    "end": "1774640"
  },
  {
    "text": "also create a template for the bill plan and deployment plan so their society",
    "start": "1774640",
    "end": "1780760"
  },
  {
    "text": "doesn't have to be worried about the pipeline we're going to make it very simple for them to use the meal plan",
    "start": "1780760",
    "end": "1787840"
  },
  {
    "text": "what it does behind the scene is it merged the parameter of the data scientists management pasturing and",
    "start": "1787840",
    "end": "1795690"
  },
  {
    "text": "without infrastructure repository and the model artifact in order Factory and",
    "start": "1795690",
    "end": "1803429"
  },
  {
    "text": "that most that most artifact is going to be we deploy to the deployment plan the",
    "start": "1803429",
    "end": "1811750"
  },
  {
    "text": "deployment plan will deploy that into engineer test and production environment",
    "start": "1811750",
    "end": "1818400"
  },
  {
    "text": "we actually in process whenever befriending the CI CD for this process it's currently out of scope this",
    "start": "1818400",
    "end": "1825190"
  },
  {
    "text": "presentations but the whole point of the ID of CI CDs is doing the build process",
    "start": "1825190",
    "end": "1831120"
  },
  {
    "text": "we should be able to create the seismic endpoint dynamically and create a",
    "start": "1831120",
    "end": "1837160"
  },
  {
    "text": "framework to submit infants into that silica endpoint and compare the output",
    "start": "1837160",
    "end": "1842190"
  },
  {
    "text": "match the expectation by their scientist and if that that output is match the",
    "start": "1842190",
    "end": "1847510"
  },
  {
    "text": "bill is passed that's our long-term vision of CI CD and we plan to grow that out so now the",
    "start": "1847510",
    "end": "1856330"
  },
  {
    "text": "deployment plan can deployed engineer tests and productions in the employ there's employ",
    "start": "1856330",
    "end": "1863020"
  },
  {
    "text": "configurations and also containing the production variants in the production",
    "start": "1863020",
    "end": "1869050"
  },
  {
    "text": "variants in containing the model and the traffic distribution so on the screen",
    "start": "1869050",
    "end": "1875920"
  },
  {
    "text": "for example the first elevations the days there are scientists deployed the variant one model one with hundred",
    "start": "1875920",
    "end": "1883930"
  },
  {
    "text": "percent traffic distributions and after that the data scientists do more",
    "start": "1883930",
    "end": "1892600"
  },
  {
    "text": "experimentations and actually modify the code create a new model based on new",
    "start": "1892600",
    "end": "1899710"
  },
  {
    "text": "even new words in the model or new algorithm for that end point the second deployment going to contain rare and -",
    "start": "1899710",
    "end": "1906250"
  },
  {
    "text": "and model two and they have ability to modify the traffic distributions for",
    "start": "1906250",
    "end": "1911800"
  },
  {
    "text": "example the current model one has a 90 percent traffic distributions and model",
    "start": "1911800",
    "end": "1917470"
  },
  {
    "text": "two has a ten percent of traffic distribution and they can model metrics and law to determine the model tube has",
    "start": "1917470",
    "end": "1925150"
  },
  {
    "text": "expected behavior after that they can decide to cut over 100 percent of the",
    "start": "1925150",
    "end": "1930460"
  },
  {
    "text": "traffic distributions and that's allowed Bluegreen deployment support so at this",
    "start": "1930460",
    "end": "1940540"
  },
  {
    "start": "1939000",
    "end": "1992000"
  },
  {
    "text": "point the data scientist is able to deploy sage maker endpoint the client",
    "start": "1940540",
    "end": "1950200"
  },
  {
    "text": "applications can start submit infants in the stationary endpoint and it only need",
    "start": "1950200",
    "end": "1956170"
  },
  {
    "text": "to have I am role with permission of invoke endpoint permissions for example",
    "start": "1956170",
    "end": "1962530"
  },
  {
    "text": "the application could be in ec2 EMR or lambda functions and we also created the",
    "start": "1962530",
    "end": "1973470"
  },
  {
    "text": "Amazon sage record one time endpoint so that the the the influence doesn't go",
    "start": "1973470",
    "end": "1980380"
  },
  {
    "text": "over the internet we also allow the sedgwick ennoble to submit infants in to",
    "start": "1980380",
    "end": "1986410"
  },
  {
    "text": "save occur endpoint for validation during the deployment process",
    "start": "1986410",
    "end": "1991440"
  },
  {
    "start": "1992000",
    "end": "2172000"
  },
  {
    "text": "the next one is a custom algorithm so after this point when we talk about the",
    "start": "1993119",
    "end": "1999309"
  },
  {
    "text": "trading job the best transplant job the hosting endpoint all of the process",
    "start": "1999309",
    "end": "2007259"
  },
  {
    "text": "doesn't change with chasm algorithm the only difference is for the mooing",
    "start": "2007259",
    "end": "2013379"
  },
  {
    "text": "algorithm and a supported framework the algorithm image is stored into AWS",
    "start": "2013379",
    "end": "2022289"
  },
  {
    "text": "managed easier for custom algorithm the docker container is developed and",
    "start": "2022289",
    "end": "2029429"
  },
  {
    "text": "created by data scientist and the group they're going to push that into Vanguard",
    "start": "2029429",
    "end": "2035039"
  },
  {
    "text": "ADF just account - easy on that's only difference so that's really two parts",
    "start": "2035039",
    "end": "2043619"
  },
  {
    "text": "the first part is docker image development process so data scientists",
    "start": "2043619",
    "end": "2049800"
  },
  {
    "text": "need to boot to create and customize the docker image in order to do that they",
    "start": "2049800",
    "end": "2054990"
  },
  {
    "text": "need to be to have a starting base image to build form so what we did is we",
    "start": "2054990",
    "end": "2060648"
  },
  {
    "text": "create a vanguard amazon sage maker docket base image that image also",
    "start": "2060649",
    "end": "2068010"
  },
  {
    "text": "support a common library and have a standard configurations for example it's",
    "start": "2068010",
    "end": "2074730"
  },
  {
    "text": "support Python or and have an integration with anaconda to bring in",
    "start": "2074730",
    "end": "2080040"
  },
  {
    "text": "additional library we also install the standard library like Jeju daikon and",
    "start": "2080040",
    "end": "2085849"
  },
  {
    "text": "the next or plumber and those library are now to serve the model so from that",
    "start": "2085849",
    "end": "2099150"
  },
  {
    "text": "base image the data scientists can use job Jupiter terminal to do dark pool",
    "start": "2099150",
    "end": "2107299"
  },
  {
    "text": "blue Condor install to write that custom configure some code and do a docker bill",
    "start": "2107299",
    "end": "2114630"
  },
  {
    "text": "and lock a post right from the noble when they push into easier what we did",
    "start": "2114630",
    "end": "2121230"
  },
  {
    "text": "is we create two separate type of issue pasturing the first type is the team",
    "start": "2121230",
    "end": "2130850"
  },
  {
    "text": "repository for experimentation area meaning doing that development process the data scientists need to push image",
    "start": "2130850",
    "end": "2138900"
  },
  {
    "text": "and delete the image and due to the model iteration event so that their experimentation area one once they",
    "start": "2138900",
    "end": "2147780"
  },
  {
    "text": "decide that docker image in ECR is what",
    "start": "2147780",
    "end": "2153270"
  },
  {
    "text": "they expect it to be and the way they do that is you click and create a training job the back transform job to validate",
    "start": "2153270",
    "end": "2159930"
  },
  {
    "text": "that docker image so one day they have",
    "start": "2159930",
    "end": "2164970"
  },
  {
    "text": "that very that docker image they want to operation align that image so just like",
    "start": "2164970",
    "end": "2173970"
  },
  {
    "start": "2172000",
    "end": "2217000"
  },
  {
    "text": "same concept with operationalization up to the hosting endpoint they have to go",
    "start": "2173970",
    "end": "2179760"
  },
  {
    "text": "to the SDR see process for the docker image as well so now they have to copy that doc you",
    "start": "2179760",
    "end": "2186720"
  },
  {
    "text": "find the custom algorithm code put in the bit bucket go to their review",
    "start": "2186720",
    "end": "2194400"
  },
  {
    "text": "process and we also creating the template for bamboo build plan and",
    "start": "2194400",
    "end": "2200880"
  },
  {
    "text": "deployment plan and the bamboo bill plan can build that artifact build the docker",
    "start": "2200880",
    "end": "2207720"
  },
  {
    "text": "image and push it out to test engineer in production easier we pass rate so",
    "start": "2207720",
    "end": "2220260"
  },
  {
    "text": "here's Kibaki take away from our project and we set up the project where you need",
    "start": "2220260",
    "end": "2226619"
  },
  {
    "text": "to have a clear requirement from the business from the user experience and also the security requirement and when",
    "start": "2226619",
    "end": "2234900"
  },
  {
    "text": "we find out is the AWS Service Catalog can provide you a very good self-service",
    "start": "2234900",
    "end": "2241619"
  },
  {
    "text": "capability we actually use that for seismic ennoble but also use that form EMR and actually our long term direction",
    "start": "2241619",
    "end": "2248910"
  },
  {
    "text": "is self-service enablement for all of our infrastructure adapt just lambda is",
    "start": "2248910",
    "end": "2256350"
  },
  {
    "text": "very good for enforcement I'm doing the presentation rate I talk a",
    "start": "2256350",
    "end": "2261900"
  },
  {
    "text": "lot about the development process and also the operationalization process um",
    "start": "2261900",
    "end": "2268829"
  },
  {
    "text": "the the output of the development process is going to be the input for operationalize it's in process to bill",
    "start": "2268829",
    "end": "2275819"
  },
  {
    "text": "to elevate that into production environment but the the issue here is the challenge here is how do you",
    "start": "2275819",
    "end": "2281940"
  },
  {
    "text": "integrate the development process to the operation Rises in process seamlessly",
    "start": "2281940",
    "end": "2287490"
  },
  {
    "text": "and make the user experience to be easy for their scientist even now for us it's",
    "start": "2287490",
    "end": "2293790"
  },
  {
    "text": "still a challenge and we plant a Santa palm long term the other thing is we",
    "start": "2293790",
    "end": "2300240"
  },
  {
    "text": "want to focus on client experience doing our project we partner with out there",
    "start": "2300240",
    "end": "2305910"
  },
  {
    "text": "scientists and get continuous feedback from them and that is very useful process in multiple situations to fix it",
    "start": "2305910",
    "end": "2312089"
  },
  {
    "text": "and let us continue going lastly um we",
    "start": "2312089",
    "end": "2317760"
  },
  {
    "text": "develop a close relationship with the signature product team and also professional services a lot of what you",
    "start": "2317760",
    "end": "2324750"
  },
  {
    "text": "saw in our diagram we actually have a lot of bug fix and feature requests to say to make a product team I think",
    "start": "2324750",
    "end": "2335069"
  },
  {
    "text": "that's it thank you for coming hope that helps [Applause]",
    "start": "2335069",
    "end": "2342850"
  }
]
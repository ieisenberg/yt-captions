[
  {
    "start": "0",
    "end": "33000"
  },
  {
    "text": "good morning everyone my name is Neil Mullin I'm a software development manager with lamda I've been with AWS",
    "start": "560",
    "end": "8280"
  },
  {
    "text": "about six years five dot with dynamodb and in more recent times lambda my team's own a bunch of the back-end",
    "start": "8280",
    "end": "13500"
  },
  {
    "text": "services on lambda and fundamentally I own the scheduling problem as what we decide to run where when you do",
    "start": "13500",
    "end": "19800"
  },
  {
    "text": "implications against lambda which makes for a pretty interesting problem space and today I'm here to talk about big",
    "start": "19800",
    "end": "26130"
  },
  {
    "text": "data analytics and machine learning on lambda and we - the agenda I want to",
    "start": "26130",
    "end": "33840"
  },
  {
    "start": "33000",
    "end": "82000"
  },
  {
    "text": "talk through fundamentally what kind of design patterns we see customers using lambda for to process big data workflows",
    "start": "33840",
    "end": "40800"
  },
  {
    "text": "and help you show what cuz see what customers are doing I want to talk through some of our own experiences",
    "start": "40800",
    "end": "46379"
  },
  {
    "text": "doing this kind of thing with the massive data sources that services like lambda are and how we've used those",
    "start": "46379",
    "end": "52860"
  },
  {
    "text": "design patterns to get value out of us and some of the lessons we've learned on that journey and finally I want to take",
    "start": "52860",
    "end": "59430"
  },
  {
    "text": "a similar path with machine learning inference show you how easy this is to do on a server this architecture and why",
    "start": "59430",
    "end": "65700"
  },
  {
    "text": "it's quite compelling and talk to against some of the design patterns that we see ourselves and other customers",
    "start": "65700",
    "end": "71640"
  },
  {
    "text": "doing using for this and then finally how we've actually used it internally ourselves in some of the services",
    "start": "71640",
    "end": "78659"
  },
  {
    "text": "backing AWS lambda so with that we'll move on to to talking about this so why",
    "start": "78659",
    "end": "86159"
  },
  {
    "start": "82000",
    "end": "116000"
  },
  {
    "text": "is serving us a good platform it's where I want to start you know increasingly we see modern analytics pipelines are",
    "start": "86159",
    "end": "92299"
  },
  {
    "text": "pulling multiple large data sources merging them aggregating them and",
    "start": "92299",
    "end": "97549"
  },
  {
    "text": "pushing that data around and service platforms make a really compelling environment to do that in they scale up",
    "start": "97549",
    "end": "104280"
  },
  {
    "text": "and down easily they can handle data that is both infrequent as well as streamed and put that all together at a",
    "start": "104280",
    "end": "110759"
  },
  {
    "text": "minimal cost to you because you're not paying for idle so the two key types of",
    "start": "110759",
    "end": "118829"
  },
  {
    "start": "116000",
    "end": "175000"
  },
  {
    "text": "data we see in these big data analytics platforms there's streaming data which",
    "start": "118829",
    "end": "124350"
  },
  {
    "text": "is your consistent data coming in via from a log source or otherwise through something like Kinesis into the system",
    "start": "124350",
    "end": "130739"
  },
  {
    "text": "or there's batch data where you data that isn't consistent it's coming in chunks it's time-based",
    "start": "130739",
    "end": "137720"
  },
  {
    "text": "maybe you've another data source that's aggregating once every period be it an hour otherwise that is pushing data in",
    "start": "137720",
    "end": "143750"
  },
  {
    "text": "or you've a data Lake that is getting updated and you want to pull it in and reallocate once that has occurred talk",
    "start": "143750",
    "end": "150440"
  },
  {
    "text": "through the theory quickly as to how we how we deal with some of these and then we'll move on to the practical stories",
    "start": "150440",
    "end": "156320"
  },
  {
    "text": "as to what we've done with us and finally a category on its own increasingly that we see on serverless",
    "start": "156320",
    "end": "161480"
  },
  {
    "text": "architectures is not produce it's a very common problem space one that delivers a lot of value so we want to talk through",
    "start": "161480",
    "end": "167570"
  },
  {
    "text": "that separately and again how lambda and Cerberus based environments can make for",
    "start": "167570",
    "end": "172580"
  },
  {
    "text": "a very powerful MapReduce engine so very quickly to just give the background on",
    "start": "172580",
    "end": "177710"
  },
  {
    "start": "175000",
    "end": "212000"
  },
  {
    "text": "data streaming for those who aren't overly familiar with us we're talking here about any kind of continuous data",
    "start": "177710",
    "end": "183260"
  },
  {
    "text": "flow so take the example of log files for example we pump those generally into Kinesis which provides our streaming",
    "start": "183260",
    "end": "189500"
  },
  {
    "text": "platform at AWS and each konista stream is made up of shards which you can up to",
    "start": "189500",
    "end": "195200"
  },
  {
    "text": "do up to five reads and writes of up to two and one megabytes a second respectively and you can pull from this",
    "start": "195200",
    "end": "201080"
  },
  {
    "text": "data for up to 24 hours and basically Kinesis provides that that consistent",
    "start": "201080",
    "end": "206240"
  },
  {
    "text": "streaming platform into whatever we want to do with us so the general design pattern we see here is that we have our",
    "start": "206240",
    "end": "213590"
  },
  {
    "start": "212000",
    "end": "236000"
  },
  {
    "text": "input our producer application whatever it is a service sitting on ec2 or otherwise or even another service",
    "start": "213590",
    "end": "219110"
  },
  {
    "text": "application itself that is pushing records into Kinesis and we're getting AWS lambda to pick up those records from",
    "start": "219110",
    "end": "226730"
  },
  {
    "text": "Kinesis and in terms of putting this together it's super easy I mean it's simply you create a stream",
    "start": "226730",
    "end": "232220"
  },
  {
    "text": "on Kinesis and you create an event source mapping to lambda from thus and it's this easy to quick commands and",
    "start": "232220",
    "end": "239090"
  },
  {
    "text": "you're up and running with a massively I'm not gonna use the word infinitely but in that territory scalable solution",
    "start": "239090",
    "end": "244700"
  },
  {
    "text": "that will pump whole from your log sources consistently scale with them as your service grows on the second side",
    "start": "244700",
    "end": "252830"
  },
  {
    "start": "251000",
    "end": "259000"
  },
  {
    "text": "we're talking about batch processing which processing which is your more traditional data analytics pipeline and",
    "start": "252830",
    "end": "258820"
  },
  {
    "text": "in this case we're talking about some kind of trigger as when you're when you",
    "start": "258820",
    "end": "264560"
  },
  {
    "text": "want to pull on your data and when you want lambda to act against that and the",
    "start": "264560",
    "end": "270199"
  },
  {
    "text": "use cases we have here such as processing log files Auto indexing contents of a directory and secondly a",
    "start": "270199",
    "end": "277930"
  },
  {
    "start": "275000",
    "end": "290000"
  },
  {
    "text": "periodical that you define and the common use cases here is you've a large data Lake sitting in s3 or something",
    "start": "277930",
    "end": "282949"
  },
  {
    "text": "like that and you want to re a grenade or recompute the information against that once some changes occurred so these",
    "start": "282949",
    "end": "290240"
  },
  {
    "start": "290000",
    "end": "313000"
  },
  {
    "text": "are the kind of design patterns you know this is this one of atreus batch analysis reference cases but these are",
    "start": "290240",
    "end": "296180"
  },
  {
    "text": "the kind this is the kind of function you see lambda perform within this serverless pipeline that you've got an",
    "start": "296180",
    "end": "301250"
  },
  {
    "text": "s3 manifest file where we simply define a trigger that on some action against an",
    "start": "301250",
    "end": "306409"
  },
  {
    "text": "s3 object it will automatically trigger a lambda function that will feed your date aid we'll just it's like your data",
    "start": "306409",
    "end": "312289"
  },
  {
    "text": "pipeline in terms of defining this it's super easy you actually define the",
    "start": "312289",
    "end": "317960"
  },
  {
    "start": "313000",
    "end": "332000"
  },
  {
    "text": "trigger on the s3 side so that you tell your Booker's that's when when there's a",
    "start": "317960",
    "end": "324229"
  },
  {
    "text": "configuration change it will trigger a lambda function and it's simply a case of mapping your lambda R to the s3 up",
    "start": "324229",
    "end": "330620"
  },
  {
    "text": "focus you can do it with an SDK as easily as you can with a CLI this is the",
    "start": "330620",
    "end": "335750"
  },
  {
    "start": "332000",
    "end": "341000"
  },
  {
    "text": "Python interface but it's a couple of simple lines and Europe and running with this data pipeline second side bus and",
    "start": "335750",
    "end": "343130"
  },
  {
    "text": "perhaps the more common one particularly when working with data lakes is the idea that you will periodically trigger",
    "start": "343130",
    "end": "348169"
  },
  {
    "text": "lambda when something occurs and there's the traditional side of things where you can simply use something as simple as a",
    "start": "348169",
    "end": "353930"
  },
  {
    "text": "cron expression that you would be familiar with or you can have cloud watch events do the work for you and",
    "start": "353930",
    "end": "359150"
  },
  {
    "text": "trigger lambda because of the nature of this that it's bursty and it's batch",
    "start": "359150",
    "end": "364430"
  },
  {
    "text": "based we tend to put a queue in the middle to smooth out some of that burstiness and start to feed into the fan-out we have from lambda and and then",
    "start": "364430",
    "end": "372500"
  },
  {
    "text": "we use those lambdas to perform whatever kind of aggregation we want and trigger as many of them as we need from this",
    "start": "372500",
    "end": "378770"
  },
  {
    "text": "queue to push the data to whatever data source we eventually want to consumer from whether that be a re-up dated",
    "start": "378770",
    "end": "385219"
  },
  {
    "text": "source in s3 or to push it into something like dynamodb or elastic cache where we want faster aggregated data",
    "start": "385219",
    "end": "391099"
  },
  {
    "text": "access to feed our applications in terms of setting this up you can do it both it",
    "start": "391099",
    "end": "398089"
  },
  {
    "start": "393000",
    "end": "403000"
  },
  {
    "text": "with a traditional cron expression or setting up something like defining a fixed rate of minutes through the console it's equally easy from an API or",
    "start": "398089",
    "end": "405590"
  },
  {
    "text": "command line you literally can use human readable sessions like every five minutes I just want to run this and",
    "start": "405590",
    "end": "412190"
  },
  {
    "text": "there you have your your scaleable five pipeline fed with lambda pulling from us whenever you want",
    "start": "412190",
    "end": "418390"
  },
  {
    "start": "417000",
    "end": "485000"
  },
  {
    "text": "finally the other area I wanted to talk to quickly to give us the background for all of this is MapReduce and MapReduce",
    "start": "418390",
    "end": "425360"
  },
  {
    "text": "is basically the use of a parallel or distributed and distributed algorithm to",
    "start": "425360",
    "end": "430640"
  },
  {
    "text": "crunch large data sets where we can bake break the problem up into a mapper and a reducer to basically pull the data",
    "start": "430640",
    "end": "437230"
  },
  {
    "text": "aggregators and then do the reduction on the data afterwards and simple use cases",
    "start": "437230",
    "end": "443930"
  },
  {
    "text": "like counting a summing data collating and sorting or you know getting distinct values from our data and the paths the",
    "start": "443930",
    "end": "450170"
  },
  {
    "text": "power of MapReduce is it allows us to use a large number of fairly simple machines to do the kind of crunching",
    "start": "450170",
    "end": "455690"
  },
  {
    "text": "which in the old days would have required big expensive machines and nowadays we can do it with server lists",
    "start": "455690",
    "end": "460970"
  },
  {
    "text": "which makes it even cheaper again because we can scale up and down with the needs for that reduction and where",
    "start": "460970",
    "end": "467300"
  },
  {
    "text": "my produced starts to come into itself is you can do distributed task execution you can do cross correlation which gives",
    "start": "467300",
    "end": "473930"
  },
  {
    "text": "you things powerful things like text analysis or more importantly for most of the kind of problem spaces we deal with",
    "start": "473930",
    "end": "478940"
  },
  {
    "text": "you can use MapReduce to do graph analysis which opens up a huge problems base to you so and sorry one example we",
    "start": "478940",
    "end": "487910"
  },
  {
    "start": "485000",
    "end": "539000"
  },
  {
    "text": "have is Fannie Mae are using servlets HPC and MapReduce for Monte Carlo simulations so that's the kind of power",
    "start": "487910",
    "end": "494150"
  },
  {
    "text": "you can get on a server this architecture with this stuff and in terms of setting it up this is what it",
    "start": "494150",
    "end": "499310"
  },
  {
    "text": "tends to look like that you hmm excuse me you have an input data source coming",
    "start": "499310",
    "end": "505730"
  },
  {
    "text": "from s3 which is triggering a set of lambda mappers those mappers perform the",
    "start": "505730",
    "end": "511490"
  },
  {
    "text": "initial crunching of the data and push that into another s3 bucket we use the",
    "start": "511490",
    "end": "517669"
  },
  {
    "text": "kind of s3 trigger we just discussed a few minutes ago to again trigger a second round of lambda functions to do",
    "start": "517670",
    "end": "523940"
  },
  {
    "text": "the reduce reduction of that data that we've pushed into s3 and pull the rest final results out into a bucket and this",
    "start": "523940",
    "end": "531380"
  },
  {
    "text": "is a super powerful that we can put together quite easily with a couple of small lambda functions",
    "start": "531380",
    "end": "536839"
  },
  {
    "text": "so let's take a look at what those look like so to do something like this we're looking at about 40 lines of code total",
    "start": "536839",
    "end": "543440"
  },
  {
    "start": "539000",
    "end": "565000"
  },
  {
    "text": "here's a mapper and a reducer which will scale as wide as we want depending on",
    "start": "543440",
    "end": "548870"
  },
  {
    "text": "the volume at the input data this comes from the reference configuration listed in the github link at the bottom and you",
    "start": "548870",
    "end": "554779"
  },
  {
    "text": "can use this to crunch as much data as you like very easily with very little code here what's getting even better is",
    "start": "554779",
    "end": "562700"
  },
  {
    "text": "what we announced on Wednesday we now have s3 select in the mix so historically we would have had to pull",
    "start": "562700",
    "end": "568579"
  },
  {
    "start": "565000",
    "end": "630000"
  },
  {
    "text": "all our data from s3 when we're doing this mapping phase whereas now we can",
    "start": "568579",
    "end": "573620"
  },
  {
    "text": "simply pull the columns we want and get some of the heavy lifting work of that mapping phase done on the s3 storage",
    "start": "573620",
    "end": "579320"
  },
  {
    "text": "hosts themselves if you've got a wide data set with a large number of columns that you're only interested in doing the",
    "start": "579320",
    "end": "585260"
  },
  {
    "text": "MapReduce against a small portion of that you can pull just the two to three columns you need and reduce your data",
    "start": "585260",
    "end": "592970"
  },
  {
    "text": "reduce the working data set significantly from the templated use case we have here that we saw the code",
    "start": "592970",
    "end": "599750"
  },
  {
    "text": "from the previous slide we're seeing improvements of about four hundred percent on execution time using s3",
    "start": "599750",
    "end": "605390"
  },
  {
    "text": "select over the existing pull everything and do the crunching so historically we",
    "start": "605390",
    "end": "611720"
  },
  {
    "text": "were doing this kind of thing where we're pulling all of the code and we're just doing a guest from s3 and then",
    "start": "611720",
    "end": "617899"
  },
  {
    "text": "we're doing a split on that where we're pulling at the two fields that we're interested in field zero and eight in this case so we're pulling everything",
    "start": "617899",
    "end": "624470"
  },
  {
    "text": "else in the middle for everything every single line we want there whereas",
    "start": "624470",
    "end": "630430"
  },
  {
    "start": "630000",
    "end": "696000"
  },
  {
    "text": "whereas now we can simply do a query to s3 and pull just the fields we want in",
    "start": "631750",
    "end": "639459"
  },
  {
    "text": "this case you use the s3 select interface and another function which",
    "start": "639459",
    "end": "644480"
  },
  {
    "text": "simply defines a select expression so",
    "start": "644480",
    "end": "649910"
  },
  {
    "text": "we're selecting column 1 and column 4 from the s3 object all of that is done on the s3 server you're only paying for",
    "start": "649910",
    "end": "656240"
  },
  {
    "text": "the reduced amount of data that comes over the wire and you're paying for significantly less execution time on the",
    "start": "656240",
    "end": "662089"
  },
  {
    "text": "lambda side as it deals with that after the fact so that's kind of I wanted to relatively",
    "start": "662089",
    "end": "668249"
  },
  {
    "text": "quickly move some through some of the key design patterns from you know the string transformations through big data",
    "start": "668249",
    "end": "674579"
  },
  {
    "text": "analytics through MapReduce so we've a bit of common terminology as to the kind of work we're doing in serving us big",
    "start": "674579",
    "end": "681899"
  },
  {
    "text": "data analytics and using that I want to talk through some of the systems we've",
    "start": "681899",
    "end": "687059"
  },
  {
    "text": "built and how we've solved some of these problems and what problems we've had along the way so hopefully you can avoid",
    "start": "687059",
    "end": "692939"
  },
  {
    "text": "some of the similar problems and some similar problems first of these that we",
    "start": "692939",
    "end": "699839"
  },
  {
    "text": "wanted to talk about it's sorry I've",
    "start": "699839",
    "end": "705809"
  },
  {
    "text": "just summarized all that apologies and slide ahead myself everything I've just",
    "start": "705809",
    "end": "712740"
  },
  {
    "text": "said and sorry first of these systems is a system we called lambda stats and in",
    "start": "712740",
    "end": "719850"
  },
  {
    "start": "715000",
    "end": "821000"
  },
  {
    "text": "this case lambda represents a huge big data source which is why I felt it made for a great story to talk about",
    "start": "719850",
    "end": "725759"
  },
  {
    "text": "here today we have vast numbers of invokes happening every second coming in",
    "start": "725759",
    "end": "731970"
  },
  {
    "text": "to a fleet of many many thousands on the front of lambda which we have to figure out the scheduling for again the problem",
    "start": "731970",
    "end": "738180"
  },
  {
    "text": "space I own as to where we're going to execute each of those functions but most importantly any customer whose requests",
    "start": "738180",
    "end": "744329"
  },
  {
    "text": "doing many many invokes against lambda and is actually executing their code against hundreds of different machines",
    "start": "744329",
    "end": "750720"
  },
  {
    "text": "and how you start to find out you know when they've been inconsistent experience what went on and how do we",
    "start": "750720",
    "end": "757980"
  },
  {
    "text": "make it better is a huge big data problem that it's very hard to analyze for us and one key customer pain point",
    "start": "757980",
    "end": "765120"
  },
  {
    "text": "with lambda is the idea of a cold start that there isn't an existing hot sandbox sitting there waiting for their execution which causes a delay when they",
    "start": "765120",
    "end": "772889"
  },
  {
    "text": "execute their invoke as a sandbox is populated with the necessary runtime and code to execute but we work to",
    "start": "772889",
    "end": "778920"
  },
  {
    "text": "constantly drive down and minimize those cold starts but how we understand what they're happening so we can go after the",
    "start": "778920",
    "end": "784800"
  },
  {
    "text": "next layer of them is a problem space we have secondly another customers can",
    "start": "784800",
    "end": "790110"
  },
  {
    "text": "experience variants and execution times and we want that don't want that we want consistency but these problems are very",
    "start": "790110",
    "end": "795569"
  },
  {
    "text": "hard to answer when you're dealing with a data set that's opening in a very tight time period",
    "start": "795569",
    "end": "800850"
  },
  {
    "text": "across hundreds of different machines out of a fleet of many many times that so what did we put together to deal with",
    "start": "800850",
    "end": "808190"
  },
  {
    "text": "first off on the front end of lambda we have a fleet of thousands of hosts that",
    "start": "808190",
    "end": "813750"
  },
  {
    "text": "are processing it sitting behind load balancers that are processing each and every invoke that comes in by a customer",
    "start": "813750",
    "end": "819420"
  },
  {
    "text": "those hosts produced service logs and we do a little on host aggregation on the",
    "start": "819420",
    "end": "824460"
  },
  {
    "start": "821000",
    "end": "978000"
  },
  {
    "text": "ec2 host there's nothing Cerberus about this yet but we're just you know breaking down the data in the service logs doing some",
    "start": "824460",
    "end": "831090"
  },
  {
    "text": "per host per period aggregation so we're getting aggregated records as to what went on on the host and we pushed that",
    "start": "831090",
    "end": "837090"
  },
  {
    "text": "out to Kinesis pretty much the very first design pattern we discussed earlier that of the streaming",
    "start": "837090",
    "end": "842190"
  },
  {
    "text": "transformation so lambda starts was built in about two days by a developer",
    "start": "842190",
    "end": "850140"
  },
  {
    "text": "who needed to solve this problem and that talks to the power of cloud computing so you can stand these things",
    "start": "850140",
    "end": "855270"
  },
  {
    "text": "up really fast you can add a lot of value it scales seamlessly it's great and here's quickly what we put together",
    "start": "855270",
    "end": "862590"
  },
  {
    "text": "so we took those service logs we fed them to Kinesis as I described we used",
    "start": "862590",
    "end": "869730"
  },
  {
    "text": "Kinesis to push into a lambda aggregator again just as we described in the first design pattern we saw earlier on we fed",
    "start": "869730",
    "end": "876990"
  },
  {
    "text": "that into ElastiCache and what this diagram doesn't represent is you know again you've many thousands of these",
    "start": "876990",
    "end": "882510"
  },
  {
    "text": "front-end servers running and each of them performing this first part of the workflow and all of them pushing in Tula",
    "start": "882510",
    "end": "888720"
  },
  {
    "text": "ElastiCache so at this point you've got the kind of reduction after the fact as you take all of those entries that are",
    "start": "888720",
    "end": "894570"
  },
  {
    "text": "flowing from the thousands of front-end hosts we trigger another lambda K lambda aggregator and we trigger it using a",
    "start": "894570",
    "end": "900660"
  },
  {
    "text": "periodical which is the second design pattern we discussed earlier to take the records that have arrived into",
    "start": "900660",
    "end": "905760"
  },
  {
    "text": "ElastiCache since the last time we executed and perform aggregation against those we push those into firehose again",
    "start": "905760",
    "end": "913620"
  },
  {
    "text": "because we want to smooth out the burstiness here if we're running on a period depending on how much data has",
    "start": "913620",
    "end": "918900"
  },
  {
    "text": "come in in that last period since that was a bench trigger of us beforehand we'll have varying amounts of data",
    "start": "918900",
    "end": "924360"
  },
  {
    "text": "coming out of that second lambda aggregator so we want to smooth that out that burstiness out again before we",
    "start": "924360",
    "end": "930210"
  },
  {
    "text": "start pushing it on further in our data pipeline is why we tend to put another Kinesis stage in here and in our case we push it",
    "start": "930210",
    "end": "937660"
  },
  {
    "text": "out to two sources we pushed it out Amazon redshift because we want a an SQL",
    "start": "937660",
    "end": "943240"
  },
  {
    "text": "query able interface to start to hunt through this data and look for patterns to help us solve those customer problems",
    "start": "943240",
    "end": "949450"
  },
  {
    "text": "which is the key issue behind this and we pushed the aggregation raw dating into s3 so that as we start to find bits",
    "start": "949450",
    "end": "956380"
  },
  {
    "text": "were interested in from that redshift analysis that our engineers might do we can go and hunt and pull out the real",
    "start": "956380",
    "end": "962560"
  },
  {
    "text": "logs backing it to help us dive in and understand what the problems look like so two days of work give or take a",
    "start": "962560",
    "end": "970930"
  },
  {
    "text": "pretty compelling data pipeline that are scaled for a year and a half with the massive growth that lambda undergoes and",
    "start": "970930",
    "end": "978269"
  },
  {
    "start": "978000",
    "end": "1066000"
  },
  {
    "text": "this is the amount of code that backs us so this is the first phase and how easy",
    "start": "978269",
    "end": "983290"
  },
  {
    "text": "and powerful these things are put together we're just pulling data sorry",
    "start": "983290",
    "end": "988420"
  },
  {
    "text": "we're just taking data as our input we've defined our Redis host where we want to put our data afterwards we do",
    "start": "988420",
    "end": "995140"
  },
  {
    "text": "some simple aggregation on this data and we push it out to Redis and the idea is that you know one of these is called",
    "start": "995140",
    "end": "1001290"
  },
  {
    "text": "with every single log push from every single invoke service host in parallel",
    "start": "1001290",
    "end": "1008010"
  },
  {
    "text": "and crunches that data and depending on whether it's a Sunday night which is our",
    "start": "1008010",
    "end": "1013350"
  },
  {
    "text": "Oh point or a Tuesday afternoon which is our high point and with the significant variance between them would absolutely",
    "start": "1013350",
    "end": "1018660"
  },
  {
    "text": "no maintenance on our site the second phase of it with that cloud watch events",
    "start": "1018660",
    "end": "1024089"
  },
  {
    "text": "as we discussed picks up triggers this second lambda to pull from elastic hash",
    "start": "1024089",
    "end": "1029490"
  },
  {
    "text": "and push us out to Kinesis fire hose again so again much as we look like looked at",
    "start": "1029490",
    "end": "1034530"
  },
  {
    "text": "with the MapReduce example earlier from the AWS repository here again is about 50 lines of code give or take which is",
    "start": "1034530",
    "end": "1041730"
  },
  {
    "text": "performing an incredibly powerful set of data aggregation and reduction that scales seamlessly and that's what the",
    "start": "1041730",
    "end": "1049410"
  },
  {
    "text": "herbalist data pipelines are about so this is what we built",
    "start": "1049410",
    "end": "1055350"
  },
  {
    "text": "I want to move on with it to look at what happened after the fact because we",
    "start": "1055350",
    "end": "1061049"
  },
  {
    "text": "built this in a rush it gave us a huge amount of value we definitely made some mistakes along the way so the kind of",
    "start": "1061049",
    "end": "1067470"
  },
  {
    "start": "1066000",
    "end": "1081000"
  },
  {
    "text": "problems we look us and in this case we have a customer with the concept of high leaked workers as we call us which means",
    "start": "1067470",
    "end": "1074250"
  },
  {
    "text": "we're seeing a lot more sand buses on the back end being used to execute the functions for this customer and then we",
    "start": "1074250",
    "end": "1079980"
  },
  {
    "text": "would expect in an ideal world and you know looking at the data we see these weird drops and spikes and maybe that's",
    "start": "1079980",
    "end": "1086370"
  },
  {
    "text": "exposing a bug in our algorithms which is causing us to share jewel incorrectly we took a look at the front door at the",
    "start": "1086370",
    "end": "1093390"
  },
  {
    "text": "ELB logs coming in before a lambda itself ever gets hold of this stuff and",
    "start": "1093390",
    "end": "1099539"
  },
  {
    "start": "1098000",
    "end": "1145000"
  },
  {
    "text": "we found this which is the lack of the same spikes and this data should roughly",
    "start": "1099539",
    "end": "1105419"
  },
  {
    "text": "match so in this case while we had the right operational telemetry around lambda stats is the service running is",
    "start": "1105419",
    "end": "1112770"
  },
  {
    "text": "approaching data that kind of thing what we were not correctly monitoring was is it dropping data and that was a reality",
    "start": "1112770",
    "end": "1120150"
  },
  {
    "text": "of what was happening here so as we dug into this one we found it wasn't or independent of the original",
    "start": "1120150",
    "end": "1125760"
  },
  {
    "text": "problem we found that we had a problem with our statistics gathering service that we had come to rely on and that's",
    "start": "1125760",
    "end": "1131700"
  },
  {
    "text": "key lesson number one is that you've got to put your monitoring both on the the consistency and the of your data as well",
    "start": "1131700",
    "end": "1139080"
  },
  {
    "text": "as just your operational is your service running is it responding is my latency okay is it scaling okay so what was",
    "start": "1139080",
    "end": "1144990"
  },
  {
    "text": "happening lund had been growing rapidly lambda stats had been running for about a year and we'd got to the point where",
    "start": "1144990",
    "end": "1151530"
  },
  {
    "text": "we were overloading Kinesis then we were dropping data at the first stage of this pipeline the number of pushes we were",
    "start": "1151530",
    "end": "1157320"
  },
  {
    "text": "doing in Kinesis it wasn't able to handle them so we fixed that by increasing the batch size we were",
    "start": "1157320",
    "end": "1163230"
  },
  {
    "text": "pushing to Kinesis essentially doing less calls that the front-end fleet had",
    "start": "1163230",
    "end": "1168270"
  },
  {
    "text": "probably tripled in size and the time since we launched lambda stats and it was simply too many pushes to Kinesis by",
    "start": "1168270",
    "end": "1173580"
  },
  {
    "text": "updating the batch size Kinesis started to play ball and all of the data started",
    "start": "1173580",
    "end": "1179940"
  },
  {
    "text": "to flow into our lambda gate lambda aggregators okay and it completely overwhelmed ElastiCache once we did the",
    "start": "1179940",
    "end": "1186690"
  },
  {
    "text": "data was still arriving in elastic hash we suddenly started to watch ourselves drift minutes hours and we even got as",
    "start": "1186690",
    "end": "1193160"
  },
  {
    "text": "far as three days behind reality before we got on top of this one so what we have to do was we have to shard the data",
    "start": "1193160",
    "end": "1199190"
  },
  {
    "text": "set and this is relatively scalable I think we're shared it to five at the",
    "start": "1199190",
    "end": "1204320"
  },
  {
    "text": "moment but we have alarms around this as to when we potentially start to see problems again and we can just",
    "start": "1204320",
    "end": "1209809"
  },
  {
    "text": "continually shard this data set over more and more elastic ashes and those elastic caches will each trigger",
    "start": "1209809",
    "end": "1215480"
  },
  {
    "text": "oh sorry lamda aggregators which the remainder of the data pipeline should",
    "start": "1215480",
    "end": "1220580"
  },
  {
    "text": "continue to flow the main point I'm getting at is you're going to need monitoring on each stage of your",
    "start": "1220580",
    "end": "1226250"
  },
  {
    "text": "pipeline monitoring both the latency and availability of the components of the",
    "start": "1226250",
    "end": "1231440"
  },
  {
    "text": "pipeline as well as the data quality which is the piece we missed because we built this one fast so this is a summary",
    "start": "1231440",
    "end": "1242450"
  },
  {
    "text": "of everything we've just discussed for the people who read these slides on the internet after the fact and but what",
    "start": "1242450",
    "end": "1250790"
  },
  {
    "start": "1250000",
    "end": "1385000"
  },
  {
    "text": "were the key lessons learned I mean the obvious one I've called out is you should connect drop date at every stage and like you know this seems like 101",
    "start": "1250790",
    "end": "1258620"
  },
  {
    "text": "stuff but the reality is we missed it as much as everyone else on this particular one we've built tons of other systems",
    "start": "1258620",
    "end": "1265220"
  },
  {
    "text": "where we remember it and the fact is that when you're moving fast you're going to make mistakes so hopefully you",
    "start": "1265220",
    "end": "1270830"
  },
  {
    "text": "guys can avoid this one by this from this story replayability of data is",
    "start": "1270830",
    "end": "1276380"
  },
  {
    "text": "another key one that we took from this that's you know learning that lesson as we drifted behind and fell ultimately",
    "start": "1276380",
    "end": "1282170"
  },
  {
    "text": "three days behind and in this case lambda starts was able to replay the data but it would have been a world of",
    "start": "1282170",
    "end": "1288140"
  },
  {
    "text": "pain if we weren't because you have to have a consistence window of data to be",
    "start": "1288140",
    "end": "1293450"
  },
  {
    "text": "able to query over after the fact or else you're in trouble finally something else we took from this",
    "start": "1293450",
    "end": "1300470"
  },
  {
    "text": "and kind of others as a tennis for the building of future analytics systems is that you know when you've tons and tons",
    "start": "1300470",
    "end": "1306470"
  },
  {
    "text": "of data it gets great that you can aggregate and you can mush different things together to more and more levels",
    "start": "1306470",
    "end": "1312110"
  },
  {
    "text": "of abstraction but sometimes you can go too far and you get to the point where you can't even explain why you have the",
    "start": "1312110",
    "end": "1320030"
  },
  {
    "text": "data you have and and we have found in some of our systems - problems in the data or you",
    "start": "1320030",
    "end": "1330030"
  },
  {
    "text": "get weird stuff you're trying to explain why it happened and you start getting to the point where you're questioning the",
    "start": "1330030",
    "end": "1335190"
  },
  {
    "text": "data as much as everything else so therefore something we've added in and that we review as we're contemplating",
    "start": "1335190",
    "end": "1340890"
  },
  {
    "text": "what levels of kind of aggregation we perform under the data we want is that it must be explainable we must be able",
    "start": "1340890",
    "end": "1347250"
  },
  {
    "text": "to clearly map back to the basic inputs of our system what this aggregated data means and that puts us on a much better",
    "start": "1347250",
    "end": "1353550"
  },
  {
    "text": "place we found in terms of building systems that are scalable sustainable and continue to add value for us so",
    "start": "1353550",
    "end": "1361800"
  },
  {
    "text": "lambda stats is the example of something we built fast we learned a bunch of",
    "start": "1361800",
    "end": "1367590"
  },
  {
    "text": "lessons second side of it is using those lessons we came back to building some",
    "start": "1367590",
    "end": "1372600"
  },
  {
    "text": "more serverless big data analytics pipelines and this time we very much",
    "start": "1372600",
    "end": "1377940"
  },
  {
    "text": "designed in advance we took our time and the lambda tuning pipeline is the second system I want to discuss today in this",
    "start": "1377940",
    "end": "1385200"
  },
  {
    "start": "1385000",
    "end": "1560000"
  },
  {
    "text": "case the use case is we wanted to leverage past function performance of customers function executions to predict",
    "start": "1385200",
    "end": "1393060"
  },
  {
    "text": "future function performance and schedulers appropriately to optimize execution and deal with that problem of",
    "start": "1393060",
    "end": "1398670"
  },
  {
    "text": "any variable execution basically trying to scrub that out and again the cold",
    "start": "1398670",
    "end": "1403830"
  },
  {
    "text": "start experience if we know things like how long a function is going to execute how much resources it's likely to",
    "start": "1403830",
    "end": "1409710"
  },
  {
    "text": "consume not relying on just what a customer has asked for the function tends to use we can do a much better job",
    "start": "1409710",
    "end": "1415980"
  },
  {
    "text": "of giving a more consistent customer experience - excuse me those functions so we're gonna use some of the design",
    "start": "1415980",
    "end": "1423090"
  },
  {
    "text": "patterns we discussed earlier in doing that so in this case we start out again with our lambda invoke service and we're",
    "start": "1423090",
    "end": "1430200"
  },
  {
    "text": "gonna use the same lambda stats redshift data store we have from the last time and one of the key architecture",
    "start": "1430200",
    "end": "1435570"
  },
  {
    "text": "decisions here we had was did we want to try and re our c't X the existing lambda",
    "start": "1435570",
    "end": "1440580"
  },
  {
    "text": "starts pipeline we've just talked through or did we want to take another approach which allowed us to move",
    "start": "1440580",
    "end": "1446070"
  },
  {
    "text": "Simplot move faster with less risk so ultimately the data we want is coming from the same service but rather than",
    "start": "1446070",
    "end": "1452670"
  },
  {
    "text": "having to go and rebuild the entire sir we have that is largely working despite the few glitches we discussed earlier we",
    "start": "1452670",
    "end": "1458970"
  },
  {
    "text": "were simply able to pull another source of data out of the invoke logs and trigger a cloud watch event per function",
    "start": "1458970",
    "end": "1464669"
  },
  {
    "text": "because what we're interested in here is the perfunctorily no stats has is only",
    "start": "1464669",
    "end": "1470370"
  },
  {
    "text": "the aggregates and very simply by pulling an event out of an existing",
    "start": "1470370",
    "end": "1475409"
  },
  {
    "text": "service we can augment the existing data store we have with another aggregator and get a very different view on the",
    "start": "1475409",
    "end": "1481919"
  },
  {
    "text": "data and build another data pipeline so this is the kind of more advanced design",
    "start": "1481919",
    "end": "1486990"
  },
  {
    "text": "pattern or advanced approach which again allows you to very quickly and very safely with having to get out but I'll",
    "start": "1486990",
    "end": "1493320"
  },
  {
    "text": "having to go re-engineer your existing systems get a lot more value from them and again with a similar pattern we push",
    "start": "1493320",
    "end": "1501480"
  },
  {
    "text": "this out to another s3 data store and DynamoDB index and what we're pushing out is using historical data from lambda",
    "start": "1501480",
    "end": "1509520"
  },
  {
    "text": "stats plus what has gone on in the current execution of how much resources that and duration are function consumed versus",
    "start": "1509520",
    "end": "1515820"
  },
  {
    "text": "predicted we're pushing in likelihoods of how how long this function will take",
    "start": "1515820",
    "end": "1523470"
  },
  {
    "text": "to run however subscribe over there's all that kind of stuff that we can use to make more optimal scheduling",
    "start": "1523470",
    "end": "1529260"
  },
  {
    "text": "decisions for future implications what we do is we take that data store and we",
    "start": "1529260",
    "end": "1534690"
  },
  {
    "text": "push it into another lambda aggregator we feed it into ElastiCache so that all",
    "start": "1534690",
    "end": "1540210"
  },
  {
    "text": "this data is there on recent customer executions with the the latest predictions we have from that",
    "start": "1540210",
    "end": "1546059"
  },
  {
    "text": "aggregation and we pass that into the lambda placement service that actually makes placement decisions about where to",
    "start": "1546059",
    "end": "1551909"
  },
  {
    "text": "put sand boxes within our fleet so if we",
    "start": "1551909",
    "end": "1558690"
  },
  {
    "text": "put all of this together we have our lambda start service at the start we add",
    "start": "1558690",
    "end": "1566190"
  },
  {
    "start": "1560000",
    "end": "1682000"
  },
  {
    "text": "in the lambda tuning pipeline that gives us a second source of data we pass this",
    "start": "1566190",
    "end": "1573270"
  },
  {
    "text": "into the lambda placement service and their end to end is a big data analytics",
    "start": "1573270",
    "end": "1579570"
  },
  {
    "text": "pipeline which helps us make decisions on what is a massively complex",
    "start": "1579570",
    "end": "1585419"
  },
  {
    "text": "distributed scheduling problem and by having that additional data from this pipeline allows us to make more",
    "start": "1585419",
    "end": "1590770"
  },
  {
    "text": "sensible decisions so the final piece of",
    "start": "1590770",
    "end": "1599500"
  },
  {
    "text": "this though is that this is a service pipeline and this is definitely the kind of powerful thing that we expect our",
    "start": "1599500",
    "end": "1606070"
  },
  {
    "text": "customers to be able to build but we have one admission here that as we came",
    "start": "1606070",
    "end": "1611230"
  },
  {
    "text": "to actually contemplating putting this live we weren't willing to place the",
    "start": "1611230",
    "end": "1616240"
  },
  {
    "text": "efficiency of lambda scheduling based on lambda because if lambda starts to fail and lambda scheduling starts to get",
    "start": "1616240",
    "end": "1622360"
  },
  {
    "text": "worse as lambda starts to have a problem and if lambda gets as big as I think lambda is going to get over the next",
    "start": "1622360",
    "end": "1627910"
  },
  {
    "text": "decade the world would probably end so",
    "start": "1627910",
    "end": "1633160"
  },
  {
    "text": "we ended up putting these two key pieces onto ec2 rather than lambda not to take that circular dependency it was real",
    "start": "1633160",
    "end": "1640540"
  },
  {
    "text": "easy to do because the code just runs you know whether your code is a lambda handler that executes server lessly",
    "start": "1640540",
    "end": "1646720"
  },
  {
    "text": "or whether you placed it on a traditional instance you can run exactly the same code and that again is part of",
    "start": "1646720",
    "end": "1652330"
  },
  {
    "text": "the compelling power that whether it's a an EC s container or a raw ec2 instance or a lambda function you can to a large",
    "start": "1652330",
    "end": "1659860"
  },
  {
    "text": "extent execute the same code in all places and so that what comes we're talking about serverless applications",
    "start": "1659860",
    "end": "1665590"
  },
  {
    "text": "we'll leave it like that here for today so that covers the first half of what I",
    "start": "1665590",
    "end": "1672730"
  },
  {
    "text": "wanted to talk about today which was kind of the big data analytics side what",
    "start": "1672730",
    "end": "1677830"
  },
  {
    "text": "we're seeing customers do what we've done ourselves the second part of what we wanted to talk about today was",
    "start": "1677830",
    "end": "1683710"
  },
  {
    "start": "1682000",
    "end": "1763000"
  },
  {
    "text": "machine learning inference because serverless is a really compelling platform for doing machine learning inference machine",
    "start": "1683710",
    "end": "1690549"
  },
  {
    "text": "learning consists of two phases there's the training phase where you're building your model which is a lot of",
    "start": "1690549",
    "end": "1696820"
  },
  {
    "text": "powerful are a lot of heavy duty number crunching you're gonna want to do you something with a lot of GPUs it's not",
    "start": "1696820",
    "end": "1704020"
  },
  {
    "text": "the sort of thing you're going to do on a service platform you're going to use something like Amazon ml and X net or",
    "start": "1704020",
    "end": "1709570"
  },
  {
    "text": "tensorflow to do that crunching and what we see a lot of people do as they get into this new space is they tend to use",
    "start": "1709570",
    "end": "1716380"
  },
  {
    "text": "those same instances for doing the inference after the fact as they used to build our model and a very different problem space in",
    "start": "1716380",
    "end": "1723220"
  },
  {
    "text": "fact in this case you have a much lighter level of compute you want to be",
    "start": "1723220",
    "end": "1728950"
  },
  {
    "text": "more scalable because you don't know what volume of inputs you're going to get so this is one that's much better",
    "start": "1728950",
    "end": "1735220"
  },
  {
    "text": "suited for lambda so let's talk about a",
    "start": "1735220",
    "end": "1740920"
  },
  {
    "text": "much easier workflow that we're going to see today how to build a machine learning inference on lambda because it's a lot",
    "start": "1740920",
    "end": "1747160"
  },
  {
    "text": "easier than it sounds and I wanted to walk through what's involved so that we can show you you know it's not hard and",
    "start": "1747160",
    "end": "1752830"
  },
  {
    "text": "you can get a lot of value from it easily and then we'll circle back and show again how we've used this",
    "start": "1752830",
    "end": "1757840"
  },
  {
    "text": "internally on some of our tools so first",
    "start": "1757840",
    "end": "1764890"
  },
  {
    "text": "off we're gonna take an Amazon machine learning model in this case we're going",
    "start": "1764890",
    "end": "1770800"
  },
  {
    "text": "to build a lambda function or build a bit of code first to read from that model we're gonna change maybe like the",
    "start": "1770800",
    "end": "1779590"
  },
  {
    "text": "lambda function to do the correct input and output that API gateway expects from that function and able to trust we need",
    "start": "1779590",
    "end": "1785620"
  },
  {
    "text": "between lambda and API gateway to call us we create an API sorry I'm ahead of",
    "start": "1785620",
    "end": "1790840"
  },
  {
    "text": "myself and this sounds like a significant list of steps but it's quite easy and it gives you a massively",
    "start": "1790840",
    "end": "1798130"
  },
  {
    "text": "scalable way to read from machine learning with no underlying servers or",
    "start": "1798130",
    "end": "1803890"
  },
  {
    "text": "maintenance of that pipeline so let's take a look first of what's involved in actually reading a machine learning",
    "start": "1803890",
    "end": "1810760"
  },
  {
    "start": "1807000",
    "end": "1835000"
  },
  {
    "text": "model and I've used Amazon ml in this case and I'm avoided doing anything",
    "start": "1810760",
    "end": "1816580"
  },
  {
    "text": "fancy with the model because I want to focus on the inference side that's what we're interested in here so it is a",
    "start": "1816580",
    "end": "1822070"
  },
  {
    "text": "couple of lines of code to pull what we need from a model and to do inference against that model just passing in the",
    "start": "1822070",
    "end": "1829090"
  },
  {
    "text": "inputs to our function here directly to the ml service service to do that inference in terms of how we make this",
    "start": "1829090",
    "end": "1839230"
  },
  {
    "start": "1835000",
    "end": "1877000"
  },
  {
    "text": "work you can create a lambda function with two calls we'll do this in real time in a few minutes you can call that",
    "start": "1839230",
    "end": "1844720"
  },
  {
    "text": "function and at the bottom there you have the results from your ml model giving your the prediction of 33% in",
    "start": "1844720",
    "end": "1853000"
  },
  {
    "text": "this case likelihood of actual success that gets you a",
    "start": "1853000",
    "end": "1858940"
  },
  {
    "text": "service query to your machine learning model but it doesn't get you something",
    "start": "1858940",
    "end": "1864100"
  },
  {
    "text": "that's scalable and something that's easily accessible through a web interface or anything like that to do",
    "start": "1864100",
    "end": "1869170"
  },
  {
    "text": "that we need to put it behind API gateway and to put it behind API gateway we need to change both the inputs and",
    "start": "1869170",
    "end": "1875380"
  },
  {
    "text": "outputs to our lambda function to make that happen and again this is super easy stuff",
    "start": "1875380",
    "end": "1880680"
  },
  {
    "start": "1877000",
    "end": "1911000"
  },
  {
    "text": "basically you need to align a couple of huh add a couple lines of standard code",
    "start": "1880680",
    "end": "1885940"
  },
  {
    "text": "to the front of your function which will just tell us where we're getting our input from depending on whether we're",
    "start": "1885940",
    "end": "1891580"
  },
  {
    "text": "getting called from API gateway or whether we're still getting called directly from lambda and equally you",
    "start": "1891580",
    "end": "1896980"
  },
  {
    "text": "want to push there to have the correct kind of JSON response that API is gateway is expecting out at the bottom",
    "start": "1896980",
    "end": "1904150"
  },
  {
    "text": "of your function finally you need to put",
    "start": "1904150",
    "end": "1911350"
  },
  {
    "start": "1911000",
    "end": "1946000"
  },
  {
    "text": "a trust relationship in place between API gateway and lambda that allows API",
    "start": "1911350",
    "end": "1918400"
  },
  {
    "text": "gateway to call your lambda function and that is done from the command line or from an API quite easily as well",
    "start": "1918400",
    "end": "1924970"
  },
  {
    "text": "so in two two statements you can create your function and you can add the appropriate trust between API gateway",
    "start": "1924970",
    "end": "1931810"
  },
  {
    "text": "and your lambda function that brings us on we have our machine learning model we have our lambda function and how do we",
    "start": "1931810",
    "end": "1939580"
  },
  {
    "text": "actually create the API gateway pieces we need to complete the stack here and give us a scalable web-based input into",
    "start": "1939580",
    "end": "1946150"
  },
  {
    "start": "1946000",
    "end": "1998000"
  },
  {
    "text": "the lambda function and this is the standard console interface to API gateway where you define your API and",
    "start": "1946150",
    "end": "1952420"
  },
  {
    "text": "there's other systems like swagger and that kind of thing you can use to manage this whole thing but I just wanted to",
    "start": "1952420",
    "end": "1958270"
  },
  {
    "text": "walk through the basics here initially first as to what are the steps involved in creating an API because the problem",
    "start": "1958270",
    "end": "1964660"
  },
  {
    "text": "is they look like too long and scary a list when you actually look at us and this looks like a pain you have to",
    "start": "1964660",
    "end": "1971110"
  },
  {
    "text": "create a REST API get resources create resources put methods response put",
    "start": "1971110",
    "end": "1976180"
  },
  {
    "text": "integrations and create a deployment so I wanted to walk through really that it",
    "start": "1976180",
    "end": "1982990"
  },
  {
    "text": "is not that painful and what is involved in actually doing that",
    "start": "1982990",
    "end": "1987660"
  },
  {
    "text": "so starting out of the console I said we're gonna take a basic model that we weren't going to worry about the",
    "start": "1995480",
    "end": "2001490"
  },
  {
    "start": "1998000",
    "end": "2133000"
  },
  {
    "text": "complexities of the model so using the standard Amazon ml sorry ml intro",
    "start": "2001490",
    "end": "2008270"
  },
  {
    "text": "tutorial if you go through that you will end up with this model which is it's a model of banking and market research",
    "start": "2008270",
    "end": "2015440"
  },
  {
    "text": "data which tells you based on various inputs you might want to give us the",
    "start": "2015440",
    "end": "2020690"
  },
  {
    "text": "likelihood of a customer responding successfully to market research query so it's not particularly complex stuff but",
    "start": "2020690",
    "end": "2026540"
  },
  {
    "text": "this is what we have and we have lambda so let's look at what's involved in what",
    "start": "2026540",
    "end": "2032450"
  },
  {
    "text": "we were talking about earlier so looking",
    "start": "2032450",
    "end": "2041330"
  },
  {
    "text": "at the same code we looked at earlier very simply and we have our standard",
    "start": "2041330",
    "end": "2048560"
  },
  {
    "text": "interface that we you know is this getting called from API gateway or otherwise we have the same small piece",
    "start": "2048560",
    "end": "2054590"
  },
  {
    "text": "of code we looked at to actually talk to our machine learning model and equally on the tail end of us we wrap it up in",
    "start": "2054590",
    "end": "2062060"
  },
  {
    "text": "the correct JSON structure and push it out again to API gateway and with that",
    "start": "2062060",
    "end": "2071210"
  },
  {
    "text": "code and I'm just gonna walk through the",
    "start": "2071210",
    "end": "2077628"
  },
  {
    "text": "steps involved so that's just testing that'll actually works so here we are we",
    "start": "2077629",
    "end": "2083388"
  },
  {
    "text": "execute that Python code in this case sorry",
    "start": "2083389",
    "end": "2088990"
  },
  {
    "text": "sorry about this so it actually invokes",
    "start": "2093450",
    "end": "2102710"
  },
  {
    "text": "service it tells us what is and there there's our prediction having come back so we take that and we create a lambda",
    "start": "2102710",
    "end": "2109800"
  },
  {
    "text": "function with it so we're simply pushing that function up into lambda we've created our function here 128 Meg function with Python and",
    "start": "2109800",
    "end": "2117960"
  },
  {
    "text": "it'll read the ML intro model if we now look here we have our function in place",
    "start": "2117960",
    "end": "2126078"
  },
  {
    "text": "and here's an opportunity to see what we",
    "start": "2126109",
    "end": "2130640"
  },
  {
    "text": "what we have launched this week this is the new cloud9 console so you can now",
    "start": "2132200",
    "end": "2138030"
  },
  {
    "start": "2133000",
    "end": "2152000"
  },
  {
    "text": "see a dash and debug your code in real time we can see the boto libraries that we're using with lambda and we can see",
    "start": "2138030",
    "end": "2144420"
  },
  {
    "text": "the same piece of code we just looked at on the terminal now there as a lambda function so now let's take the API",
    "start": "2144420",
    "end": "2151050"
  },
  {
    "text": "gateway piece all right let's prove this works first so the final piece we wanted",
    "start": "2151050",
    "end": "2157380"
  },
  {
    "start": "2152000",
    "end": "2222000"
  },
  {
    "text": "to do was we wanted to add that permission to talk to API gateway and then we want to actually invoke our",
    "start": "2157380",
    "end": "2163530"
  },
  {
    "text": "function so there's our function has executed and here's the output that comes from us we've got a prediction",
    "start": "2163530",
    "end": "2169710"
  },
  {
    "text": "score that based on what we gave us is someone who's divorced and somebody who",
    "start": "2169710",
    "end": "2175260"
  },
  {
    "text": "has an age of 32 has a likelihood of 0.33 in responding based on this particular model so that gives us the",
    "start": "2175260",
    "end": "2183060"
  },
  {
    "text": "first part of the piece it gives us a service function that can talk to our machine learning model second part of",
    "start": "2183060",
    "end": "2189599"
  },
  {
    "text": "the story is what we want to do to hook this up to API gateway so",
    "start": "2189599",
    "end": "2195799"
  },
  {
    "text": "again I'm just gonna walk through what's involved so with AP at Gateway we want",
    "start": "2196930",
    "end": "2208120"
  },
  {
    "text": "to go through that first phase of what we looked at and this other model sorry",
    "start": "2208120",
    "end": "2213460"
  },
  {
    "text": "on this initially we want to just create a rest IPA API and we want to create",
    "start": "2213460",
    "end": "2219490"
  },
  {
    "text": "resources attached to that so coming back to here that's all we've done we've",
    "start": "2219490",
    "end": "2224920"
  },
  {
    "text": "created and defined a model called our market research query and by default we",
    "start": "2224920",
    "end": "2230350"
  },
  {
    "text": "have to define an initial path of slash but we wanted to find a URL that we're actually gonna query this off and we're gonna define a slash query in this stage",
    "start": "2230350",
    "end": "2236950"
  },
  {
    "text": "in this case and now you can see that we should have one clunkiness with this",
    "start": "2236950",
    "end": "2248070"
  },
  {
    "text": "that's interesting okay not what I expected to see but it looks like we've",
    "start": "2253980",
    "end": "2260220"
  },
  {
    "text": "done a lot of these for some reason",
    "start": "2260220",
    "end": "2263299"
  },
  {
    "text": "sorry about this such as that such as demoing live and I have no idea which",
    "start": "2267950",
    "end": "2274230"
  },
  {
    "text": "one of them alright we're gonna take two minutes we're gonna clear up these API is very quickly so that we can do this",
    "start": "2274230",
    "end": "2280109"
  },
  {
    "text": "correctly",
    "start": "2280109",
    "end": "2282289"
  },
  {
    "text": "oh cool no we're not alright no problem",
    "start": "2292980",
    "end": "2305450"
  },
  {
    "text": "yeah we're gonna run this again anyway and we're gonna create our API as we've",
    "start": "2305450",
    "end": "2312570"
  },
  {
    "text": "described an we're gonna figure out which one in that UI it is and we're gonna do the second piece of this as",
    "start": "2312570",
    "end": "2317849"
  },
  {
    "text": "well as creating the API and just defining the slash query we're gonna define resources to go with us so for",
    "start": "2317849",
    "end": "2325050"
  },
  {
    "text": "the lambda API if you're doing a lambda n times connectivity like this you have to use a post it's the only thing that",
    "start": "2325050",
    "end": "2330089"
  },
  {
    "text": "lambda supports you can't use it yet so we define a post interface to this and we get an ID of that post interface",
    "start": "2330089",
    "end": "2336359"
  },
  {
    "text": "attached to the API gateway and with that we define responders as to what we",
    "start": "2336359",
    "end": "2342329"
  },
  {
    "text": "do for each of those methods and so we",
    "start": "2342329",
    "end": "2348540"
  },
  {
    "text": "define that there's a bottom was put method response 200 to each of these and then we define an integration against",
    "start": "2348540",
    "end": "2354810"
  },
  {
    "text": "that which is literally saying that sorry for a post put this query endpoint",
    "start": "2354810",
    "end": "2363569"
  },
  {
    "text": "we've defined we now connect us to the lambda function we want and we pass in",
    "start": "2363569",
    "end": "2371760"
  },
  {
    "text": "whatever comes through the front door so it's it's quite simple stuff it looks like a whole bunch of commands but what",
    "start": "2371760",
    "end": "2377640"
  },
  {
    "text": "I'm trying to get out is it's actually super easy to set all this stuff up and it's quite well documented within the",
    "start": "2377640",
    "end": "2383010"
  },
  {
    "text": "AWS SDK and at the end of that you just simply do a deployment of the API you've",
    "start": "2383010",
    "end": "2388740"
  },
  {
    "text": "created what that gives you is that I now have a URL that I can simply invoke",
    "start": "2388740",
    "end": "2393810"
  },
  {
    "text": "against with the same kind of arguments again and at the other end of the comes",
    "start": "2393810",
    "end": "2401310"
  },
  {
    "text": "the same predictions that we had earlier talking through lambda through my service stack",
    "start": "2401310",
    "end": "2408470"
  },
  {
    "text": "to to the machine learning model behind us and the nice piece about this is you",
    "start": "2408820",
    "end": "2414640"
  },
  {
    "text": "can stick route 50 through route 53 and an al B in front of this give it a DNS name to make it nicer than the kind of",
    "start": "2414640",
    "end": "2420730"
  },
  {
    "text": "URL we're calling here and then yuba seamlessly scalable machine learning inference engine it's super cheap you",
    "start": "2420730",
    "end": "2428290"
  },
  {
    "text": "only pay for what you're using and it's super easy to set up so let's go back and talk again within lamda what we've",
    "start": "2428290",
    "end": "2436030"
  },
  {
    "text": "done with this kind of model so we're",
    "start": "2436030",
    "end": "2442030"
  },
  {
    "text": "talking coming back to our placement problem again and so far we'd built a system which gives us a lot of",
    "start": "2442030",
    "end": "2447100"
  },
  {
    "text": "information on placement on what a function is likely to consume and what",
    "start": "2447100",
    "end": "2452200"
  },
  {
    "text": "that might do to help us decide where to place us we also want to understand how",
    "start": "2452200",
    "end": "2458410"
  },
  {
    "text": "much a customer is likely to call a function when the key pain points for customers is they're often bursty and",
    "start": "2458410",
    "end": "2463840"
  },
  {
    "text": "their use of lambda and that they might call hundreds of implications or they might call one and you know each time we",
    "start": "2463840",
    "end": "2470110"
  },
  {
    "text": "receive an indication if there isn't the sandbox to present we're gonna have to spin up a sandbox and the customer is gonna take that cold start here but",
    "start": "2470110",
    "end": "2476500"
  },
  {
    "text": "customers have patterns of behavior sometimes they tend to follow a cycle and we can build a model with that and",
    "start": "2476500",
    "end": "2483370"
  },
  {
    "text": "what we built is a model to help us understand what is the likelihood that we should spin up many more sand boxes",
    "start": "2483370",
    "end": "2489670"
  },
  {
    "text": "than just the invoke we've received from this customer because if we can get ahead of that curve slightly and start",
    "start": "2489670",
    "end": "2494890"
  },
  {
    "text": "pre-populating those sand boxes with the environment and the code the customer wants as they ramp up they're much",
    "start": "2494890",
    "end": "2501130"
  },
  {
    "text": "likely to receive those cold starts so",
    "start": "2501130",
    "end": "2506920"
  },
  {
    "text": "sorry what I've just told her so in this case we're gonna use some of the same design patterns we looked at before our",
    "start": "2506920",
    "end": "2513850"
  },
  {
    "text": "input this time is the dynamodb index in index that was the output of our lambda",
    "start": "2513850",
    "end": "2519280"
  },
  {
    "text": "tuning pipeline in this case we have used lambda again because this one won't",
    "start": "2519280",
    "end": "2524620"
  },
  {
    "text": "end the world of it starts failing and it'll just mean that customers get a bit more latency if we start having problems",
    "start": "2524620",
    "end": "2531190"
  },
  {
    "text": "with lambda we use and I'm as a machine learning model I'm much more complex one",
    "start": "2531190",
    "end": "2537310"
  },
  {
    "text": "than the one we just looked up to make the decision of what is the likelihood that this is going to do many invokes rather than",
    "start": "2537310",
    "end": "2544599"
  },
  {
    "text": "this just this invoke we've seen and we passed that information back into s3 so",
    "start": "2544599",
    "end": "2549880"
  },
  {
    "text": "we are so that model comes from s3 and we passed up information back into the same dynamo DB table and essentially",
    "start": "2549880",
    "end": "2556869"
  },
  {
    "text": "what we're doing is we're augmenting a column with the duck in the dynamodb table our trigger point into this system",
    "start": "2556869",
    "end": "2562330"
  },
  {
    "text": "is entries getting updated or added to that table so what we have is as we feed",
    "start": "2562330",
    "end": "2569710"
  },
  {
    "text": "data into that dynamodb table from the lambda tuning pipeline magic happens and that data gets automatically augmented",
    "start": "2569710",
    "end": "2576190"
  },
  {
    "text": "with additional information from the machine learning pipeline if there's if there is sufficient information in the",
    "start": "2576190",
    "end": "2581980"
  },
  {
    "text": "model on this particular customer or function so how does that play with what we looked at earlier we see this",
    "start": "2581980",
    "end": "2589869"
  },
  {
    "text": "completes the story here somebody really messed the alignment of my slide so this",
    "start": "2589869",
    "end": "2599500"
  },
  {
    "text": "is finally pretty much where we stand today we're gonna continue to oversee evolve these kind of pipelines as we",
    "start": "2599500",
    "end": "2605619"
  },
  {
    "text": "seek to optimize what we're scheduling for lambda and how we can continue to",
    "start": "2605619",
    "end": "2611050"
  },
  {
    "text": "more efficiently schedule things and drive down cold starts guarantee guarantee better execution for customers",
    "start": "2611050",
    "end": "2619470"
  },
  {
    "text": "so that's the end of the story here I'm",
    "start": "2620790",
    "end": "2626800"
  },
  {
    "start": "2624000",
    "end": "3070000"
  },
  {
    "text": "about five minutes ahead of where I intended to be but that's as much as I had to talk to you today so I'll ask",
    "start": "2626800",
    "end": "2632859"
  },
  {
    "text": "four questions at this point sorry I'll go back and let people take photos I saw the cameras up there",
    "start": "2632859",
    "end": "2639240"
  },
  {
    "text": "[Applause]",
    "start": "2647380",
    "end": "2653609"
  },
  {
    "text": "sorry increase which and so the question",
    "start": "2656869",
    "end": "2664039"
  },
  {
    "text": "is is there any plans to execute the increase the execution time of five minutes in a lambda and you've seams yes",
    "start": "2664039",
    "end": "2671269"
  },
  {
    "text": "is the short answer in the long term you've seen us this this this reinvent announced three gig functions which is",
    "start": "2671269",
    "end": "2676969"
  },
  {
    "text": "the start of you know denser compute roadmap we want to make functions bigger we want to make them longer but it's",
    "start": "2676969",
    "end": "2682309"
  },
  {
    "text": "it's it's coming eventually",
    "start": "2682309",
    "end": "2686380"
  },
  {
    "text": "and it's a fair point and it's something we're working on for lambda it's the short answer so it is coming and bus",
    "start": "2698400",
    "end": "2705950"
  },
  {
    "text": "London you are right it's because we replaced it with ec2 here that that is feasible in this case but lambda from",
    "start": "2705950",
    "end": "2712620"
  },
  {
    "text": "RESCUE s is a key customer asked it's definitely something we're looking at",
    "start": "2712620",
    "end": "2717440"
  },
  {
    "text": "there's a DynamoDB trigger you can define so on either create or update of either an object or even a row or column",
    "start": "2723800",
    "end": "2733260"
  },
  {
    "text": "within dynamodb you can trigger different lambda actions it's quite fine-grained you can do either hmm",
    "start": "2733260",
    "end": "2747859"
  },
  {
    "text": "and that's the mechanics of how the read",
    "start": "2749100",
    "end": "2754930"
  },
  {
    "text": "happens but that the trigger you define is on create or update or whatever you want up the DynamoDB object that it will",
    "start": "2754930",
    "end": "2761470"
  },
  {
    "text": "trigger a lambda the mechanics of how it happens is it's fed out through a stream which is what you read for from an your",
    "start": "2761470",
    "end": "2766510"
  },
  {
    "text": "lambda function",
    "start": "2766510",
    "end": "2769050"
  },
  {
    "text": "so the question is can I talk a bit to the MapReduce function and the s3 solution as opposed to spinning up a",
    "start": "2779250",
    "end": "2785070"
  },
  {
    "text": "huge a Hadoop cluster to do us and what you mean by talk a bit there are",
    "start": "2785070",
    "end": "2799619"
  },
  {
    "text": "different use cases for each and it depends on the complexity of the reduction you have to do fundamentally",
    "start": "2799619",
    "end": "2805130"
  },
  {
    "text": "you know we're back to talking about thus you have a five-minute execution time on lambda and lambda tend to run on",
    "start": "2805130",
    "end": "2812070"
  },
  {
    "text": "a essentially a single CPU core for the most part although with three gig functions you now get into two multi-core territory so you know it",
    "start": "2812070",
    "end": "2819420"
  },
  {
    "text": "depends on what you need to do in your reduction so know it's not a Hadoop killer there are definitely use cases where you have large data sets that you",
    "start": "2819420",
    "end": "2826260"
  },
  {
    "text": "need to do quite intense reduction on and basically you will still get better performance today from a Hadoop based",
    "start": "2826260",
    "end": "2832109"
  },
  {
    "text": "environment for those use cases but there's a huge amount of much of MapReduce which both tends to scale up",
    "start": "2832109",
    "end": "2841050"
  },
  {
    "text": "and down which is where lambda comes into its own if the input to your MapReduce tends to be highly variable you don't have to provision for peak",
    "start": "2841050",
    "end": "2847440"
  },
  {
    "text": "like you would with a traditional hoop Hadoop cluster and secondly that the reduction isn't as complex so running it",
    "start": "2847440",
    "end": "2853230"
  },
  {
    "text": "in a service pipeline makes a lot of sense",
    "start": "2853230",
    "end": "2857089"
  },
  {
    "text": "okay go here first",
    "start": "2860060",
    "end": "2864080"
  },
  {
    "text": "so the question is that each indication of lambda gets a new IP because it potentially runs on a different instance",
    "start": "2878770",
    "end": "2884990"
  },
  {
    "text": "and you asked is a an IP per invocation or per per call start you you have to",
    "start": "2884990",
    "end": "2892610"
  },
  {
    "text": "treat it when you're writing your code like it's per invocation and we will we will attempt in our scheduling to",
    "start": "2892610",
    "end": "2899180"
  },
  {
    "text": "optimize to existing hots down boxes to try and minimize those cold starts therefore there's a high likelihood if",
    "start": "2899180",
    "end": "2904850"
  },
  {
    "text": "you're just doing a sequential bunch of lambdas that you'll continue to land on the same sandbox but you cannot",
    "start": "2904850",
    "end": "2910100"
  },
  {
    "text": "guarantee it and particularly a high scale if you're doing a lot a lot of invokes and where if you've high",
    "start": "2910100",
    "end": "2916340"
  },
  {
    "text": "concurrency you'll actually be partitioned across different portions of the fleet at the back end so you'll be",
    "start": "2916340",
    "end": "2921890"
  },
  {
    "text": "load balancing across those so even with sequential invokes you may find yourself just landing on different pieces so from",
    "start": "2921890",
    "end": "2928280"
  },
  {
    "text": "a coding perspective you have to assume the worst",
    "start": "2928280",
    "end": "2932170"
  },
  {
    "text": "sometimes they into",
    "start": "2940780",
    "end": "2944890"
  },
  {
    "text": "recommendation like shoot morning",
    "start": "2945840",
    "end": "2950160"
  },
  {
    "text": "sorry the question is that you know that the inputs for machine learning can get quite complex and Jason is clergy for",
    "start": "2954960",
    "end": "2961749"
  },
  {
    "text": "doing this I don't have a good recommendation there I mean as much as I've done when I've been writing my code",
    "start": "2961749",
    "end": "2967660"
  },
  {
    "text": "as I tend to end up with some quite large JSON blobs bus yeah I I don't have",
    "start": "2967660",
    "end": "2980109"
  },
  {
    "text": "a good answer off the top of my head here because I haven't run up against the kind of six med limits of JSON blobs",
    "start": "2980109",
    "end": "2985299"
  },
  {
    "text": "that will cause dot to be a problem I'd serializing would be the first place I go and look if I was there but I can't",
    "start": "2985299",
    "end": "2991450"
  },
  {
    "text": "give you a good recommendation is the short answer on that one",
    "start": "2991450",
    "end": "2995700"
  },
  {
    "text": "well this is am blondest remit yes yeah",
    "start": "3000210",
    "end": "3015030"
  },
  {
    "text": "yeah I mean his concern isn't about how to do it those what I'm hearing it's the complexity of managing that JSON blob",
    "start": "3015720",
    "end": "3022690"
  },
  {
    "text": "and what you have to do in code to maintain that I think more than cells",
    "start": "3022690",
    "end": "3028200"
  },
  {
    "text": "yeah I mean you tend to build a data",
    "start": "3039420",
    "end": "3044940"
  },
  {
    "text": "structure a hash table of some sort that you know you have a function that converts stuff to Jason so you're",
    "start": "3044940",
    "end": "3050460"
  },
  {
    "text": "maintaining a data structure rather than maintaining adjacent blob and you just push that around doesn't need it",
    "start": "3050460",
    "end": "3056630"
  },
  {
    "text": "and speeds on the other side of the clearing and come it's it's not a",
    "start": "3066910",
    "end": "3074109"
  },
  {
    "text": "stateful data set it's more acting as a buffer just to collect so you've many",
    "start": "3074109",
    "end": "3080920"
  },
  {
    "text": "thousands of invoke hosts pumping into this last Akash the purpose this elastic hash is doing is it's collecting that",
    "start": "3080920",
    "end": "3087849"
  },
  {
    "text": "data from many hosts so that the next stage of the lambda aggregation can do the aggregation across all of the hosts",
    "start": "3087849",
    "end": "3093400"
  },
  {
    "text": "for a given time period so it's not stateful it's not something that the long-lived yes we could have approached",
    "start": "3093400",
    "end": "3098680"
  },
  {
    "text": "it with dynamo DB and a TTL to clean up afterwards but I don't know that we need to go there ElastiCache is much faster",
    "start": "3098680",
    "end": "3104859"
  },
  {
    "text": "yes dynamo DB with tax would be as fast on the read path on the far side of us but it would be much slower on the right",
    "start": "3104859",
    "end": "3111039"
  },
  {
    "text": "path you know you're talking about multiples anyway of the difference in",
    "start": "3111039",
    "end": "3116680"
  },
  {
    "text": "latency between an elastic hash right and a Dinah would be right you're talking 10x of high percentiles so again",
    "start": "3116680",
    "end": "3123309"
  },
  {
    "text": "you know what we want is this date pipeline to be fast to push large amounts of data quickly ElastiCache fits",
    "start": "3123309",
    "end": "3128920"
  },
  {
    "text": "the need i get the partitioning question but maintaining the elastic hash where we get our millisecond read and write is",
    "start": "3128920",
    "end": "3135220"
  },
  {
    "text": "what we want here rather than looking to something stateful that we wouldn't have had to shard",
    "start": "3135220",
    "end": "3141660"
  },
  {
    "text": "ElastiCache does do auto sharding we just wanted to control the sharding in this case because and we have knowledge",
    "start": "3145890",
    "end": "3153209"
  },
  {
    "start": "3146000",
    "end": "3197000"
  },
  {
    "text": "of the structure of that data that we could guarantee the evenness of the shard and I kind of thing it's a good",
    "start": "3153209",
    "end": "3161900"
  },
  {
    "text": "[Applause]",
    "start": "3177060",
    "end": "3180110"
  },
  {
    "text": "volume of data more than anything else and this is just a simple list am sorry",
    "start": "3184180",
    "end": "3197840"
  },
  {
    "start": "3197000",
    "end": "3270000"
  },
  {
    "text": "the question is why use sqs here rather than firehose in this particular example of where I'm pumping into lambda and",
    "start": "3197840",
    "end": "3203270"
  },
  {
    "text": "I've already been called out that I'm actually the only reason sqs works there at all is because it's ec2 rather than",
    "start": "3203270",
    "end": "3208910"
  },
  {
    "text": "lambda in this case I actually don't have a great answer on this one to be honest I mean ask us is easy and does",
    "start": "3208910",
    "end": "3216440"
  },
  {
    "text": "the job fine in this case it's just a very simple naive list it's not a large volume of data so really what we're just",
    "start": "3216440",
    "end": "3222440"
  },
  {
    "text": "doing is using that list to identify what we need to pull from it redshift",
    "start": "3222440",
    "end": "3228370"
  },
  {
    "text": "hmm",
    "start": "3234500",
    "end": "3237500"
  },
  {
    "text": "it does yes",
    "start": "3244410",
    "end": "3247579"
  },
  {
    "text": "yeah",
    "start": "3250070",
    "end": "3253070"
  },
  {
    "text": "and you could that's the beauty if there's a lot of options here sorry go",
    "start": "3255420",
    "end": "3261130"
  },
  {
    "text": "ahead I'm you've been waiting for a while and I don't know what what we have",
    "start": "3261130",
    "end": "3271360"
  },
  {
    "start": "3270000",
    "end": "3323000"
  },
  {
    "text": "now is an internal tool that we build fast that added a lot of value why I felt it was a good thing to talk about here is it it's a great example of what",
    "start": "3271360",
    "end": "3278140"
  },
  {
    "text": "the cloud kind of does for you it allows you to build these things real fast that are powerful because it was built real fast and that kind of thing it",
    "start": "3278140",
    "end": "3284260"
  },
  {
    "text": "definitely wasn't properly designed as well as it should be so what we are going to do is go back to the drawing",
    "start": "3284260",
    "end": "3290950"
  },
  {
    "text": "board on that one and build something that yes what are the customer use cases all of that kind of thing and so yes",
    "start": "3290950",
    "end": "3298270"
  },
  {
    "text": "we've just funded a team to go and tackle us and so yes it's something we're thinking about in the long run",
    "start": "3298270",
    "end": "3305400"
  },
  {
    "start": "3323000",
    "end": "3412000"
  },
  {
    "text": "I'm not gonna be able to tell you what we are or not going to do it's it's definitely a constant ask from customers",
    "start": "3323069",
    "end": "3328859"
  },
  {
    "text": "hey if I can give you some heads-up on what I'm going to do can you make that happen so I think we have to go there in",
    "start": "3328859",
    "end": "3335489"
  },
  {
    "text": "some fashion we definitely you know we purposefully kept the interface to lambda very simple",
    "start": "3335489",
    "end": "3341219"
  },
  {
    "text": "you only scale on a single dimension there's not a whole bunch of knobs you have to tune and we want to try and",
    "start": "3341219",
    "end": "3346440"
  },
  {
    "text": "continue to move down the simplicity plot to enable more people use lambda rather than to add a whole bunch of",
    "start": "3346440",
    "end": "3353130"
  },
  {
    "text": "configurable than that kind of thing but at the same time I'm conscious that there's two particular use cases we hear",
    "start": "3353130",
    "end": "3358769"
  },
  {
    "text": "a lot from customers there's one can I tell you what I'm about to do because I know what I'm about to do so you can",
    "start": "3358769",
    "end": "3364140"
  },
  {
    "text": "prep for it and there's two I have lambdas that I don't care how fast they run so okay can can I tag a function or",
    "start": "3364140",
    "end": "3374880"
  },
  {
    "text": "an execution for you no runners would in this SLA and I don't care and maybe run a cheaper so there are definitely two",
    "start": "3374880",
    "end": "3380849"
  },
  {
    "text": "places we hear a lot of feedback then we're gonna be thinking long and hard about",
    "start": "3380849",
    "end": "3385308"
  },
  {
    "text": "so the answer is the time limits still five minutes although we've increased a three gig yes the time limit is still",
    "start": "3396869",
    "end": "3402000"
  },
  {
    "text": "five minutes at this time",
    "start": "3402000",
    "end": "3404810"
  },
  {
    "text": "and we do not face that with these no and I mean we design and cut up what our",
    "start": "3409499",
    "end": "3416410"
  },
  {
    "start": "3412000",
    "end": "3514000"
  },
  {
    "text": "lambda functions do appropriately such that we know we're not going to hit that you know and that we're essentially",
    "start": "3416410",
    "end": "3422829"
  },
  {
    "text": "calling one lambda function per second per invoke server and we know we're not",
    "start": "3422829",
    "end": "3428739"
  },
  {
    "text": "going to process enough traffic for that batch of data to take any longer than about one minute never mind five minutes",
    "start": "3428739",
    "end": "3434289"
  },
  {
    "text": "we kind of hold our we are monitoring on execution late length is around the 1-minute mark if we start exceeding that",
    "start": "3434289",
    "end": "3440109"
  },
  {
    "text": "we will have to revisit this architecture so usually you know it's about chunking your algorithm such that",
    "start": "3440109",
    "end": "3446289"
  },
  {
    "text": "you're not going to get there I fully appreciate that we need to enable our customers do longer execution but it's",
    "start": "3446289",
    "end": "3451749"
  },
  {
    "text": "not something we have at this time you've been waiting a long time I'm sorry",
    "start": "3451749",
    "end": "3456749"
  },
  {
    "text": "throttling because you have too many concurrent rather than too many we don't",
    "start": "3472990",
    "end": "3485230"
  },
  {
    "text": "throttle on in vacations per second we only throttle on concurrency so how many lambdas you are executing at the same",
    "start": "3485230",
    "end": "3490780"
  },
  {
    "text": "time as the piece that gets traveled",
    "start": "3490780",
    "end": "3494069"
  },
  {
    "text": "yeah",
    "start": "3508300",
    "end": "3510930"
  },
  {
    "start": "3514000",
    "end": "3586000"
  },
  {
    "text": "you're not getting lambdas invoked because you have too many that are currently running based on your concurrency limit",
    "start": "3514380",
    "end": "3519599"
  },
  {
    "text": "so what we're throwing on is how many are running not how many invocations per second you're doing okay",
    "start": "3519599",
    "end": "3529369"
  },
  {
    "text": "they don't that they return to you with Emma 449 or something I think is how the",
    "start": "3531060",
    "end": "3537910"
  },
  {
    "text": "customer sees it on their end but you've exceeded your concurrency limit the concurrency limit by default is a thousand in most regions as three",
    "start": "3537910",
    "end": "3544480"
  },
  {
    "text": "thousand in u.s. East one but equally this customers who are many many times beyond that what Y we have those limits",
    "start": "3544480",
    "end": "3551320"
  },
  {
    "text": "in place is we'd like to engage with customers who are getting beyond those limits so we can sure they're doing the right things and that they're using",
    "start": "3551320",
    "end": "3557230"
  },
  {
    "text": "things in the right way before we let them get much bigger but if you have a real use case and you're hitting those limits like like reach out to your time",
    "start": "3557230",
    "end": "3563800"
  },
  {
    "text": "or reach out to us we're happy to make those limits a lot bigger they are not hard limits they're there to just stop",
    "start": "3563800",
    "end": "3570970"
  },
  {
    "text": "customers doing crazy things more than anything else okay yeah I guess so we've",
    "start": "3570970",
    "end": "3580450"
  },
  {
    "text": "been asked to move to the hole because they've got to tear the room down and reinvent is over so thank you very much",
    "start": "3580450",
    "end": "3586740"
  }
]
[
  {
    "start": "0",
    "end": "86000"
  },
  {
    "text": "all right welcome everybody you were here for optimizing network performance for it was on ec2 instances welcome so",
    "start": "0",
    "end": "8280"
  },
  {
    "text": "uh I'm Nick Matthews I'm a Solutions Architect my word a day job is I help our partners and customers do a lot of",
    "start": "8280",
    "end": "15509"
  },
  {
    "text": "network things a lot of times performance comes up we're also got the",
    "start": "15509",
    "end": "20520"
  },
  {
    "text": "fish over here he's going to help us out later with some of the details about how it works internally under the hood",
    "start": "20520",
    "end": "27570"
  },
  {
    "text": "so sort of the the reason while we're all here hopefully is for network",
    "start": "27570",
    "end": "33030"
  },
  {
    "text": "performance you know I've been a network engineer for a long time or relatively",
    "start": "33030",
    "end": "38579"
  },
  {
    "text": "long time I don't know and so these things make sense to me you know I think",
    "start": "38579",
    "end": "43739"
  },
  {
    "text": "one of the things I've learned especially here is that you know a lot of people aren't network engineers but",
    "start": "43739",
    "end": "50250"
  },
  {
    "text": "networking fortunately or unfortunately depending on what you like networking is everywhere and so it impacts you all the",
    "start": "50250",
    "end": "56760"
  },
  {
    "text": "time and one of the big questions always is like is the network to the problem or like if can I increase the performance",
    "start": "56760",
    "end": "63570"
  },
  {
    "text": "of my cluster or my application by improving the network or like what options do I have to improve network",
    "start": "63570",
    "end": "68580"
  },
  {
    "text": "performance and so the whole idea of that is you know for those of you that especially aren't maybe networking",
    "start": "68580",
    "end": "74189"
  },
  {
    "text": "experts can be a bit of a black box and so the concept here today is we're gonna go through so a few concepts and really",
    "start": "74189",
    "end": "80430"
  },
  {
    "text": "sort of look a little bit deeper inside network performance how it works and sort of what makes it tick so we're",
    "start": "80430",
    "end": "88200"
  },
  {
    "start": "86000",
    "end": "86000"
  },
  {
    "text": "gonna start with some basic performance concepts for some of you this might be basic for some of this might be sort of interesting basically global things that",
    "start": "88200",
    "end": "95939"
  },
  {
    "text": "exist everywhere in the world like TCP how they work and why they matter and a little bit of how to deal with some of",
    "start": "95939",
    "end": "102030"
  },
  {
    "text": "those parameters that come in from that we'll talk a little bit about what we have on ATS in terms of features and",
    "start": "102030",
    "end": "108860"
  },
  {
    "text": "Families instance families those kinds of things that will impact your performance then we'll talk about some",
    "start": "108860",
    "end": "114090"
  },
  {
    "text": "of the architectural decisions you can make about your you know the decisions you make and the components you use and",
    "start": "114090",
    "end": "120060"
  },
  {
    "text": "how that impacts your performance and then like this some of the testing methodology and some sort of tips they're so basic global performance",
    "start": "120060",
    "end": "127560"
  },
  {
    "text": "concepts these are some terms you some of you may know some of you may not bandwidth bandwidth",
    "start": "127560",
    "end": "133380"
  },
  {
    "text": "essentially you know how big is the possible throughput for that link so if you have a 10 gigabit per second link",
    "start": "133380",
    "end": "139410"
  },
  {
    "text": "that's the bandwidth of that link so that's usually what a lot will focus on for band for performance but it's not",
    "start": "139410",
    "end": "145710"
  },
  {
    "text": "always or in quite often is not actually the major impact for performance latency",
    "start": "145710",
    "end": "151500"
  },
  {
    "text": "is often the more likely cause of performance issues so we'll talk a little bit about that latency is a",
    "start": "151500",
    "end": "156720"
  },
  {
    "text": "famous where a fancy word for how long it takes for a packet to go from one place to another throughput is okay so",
    "start": "156720",
    "end": "164370"
  },
  {
    "text": "maybe I have a 10 gigabit per second circuit that's my bandwidth but how much traffic can I actually get on that so",
    "start": "164370",
    "end": "170430"
  },
  {
    "text": "whatever your effective bandwidth on that or your effective data transfer on that is your throughput and that's what",
    "start": "170430",
    "end": "176040"
  },
  {
    "text": "you actually care about because that's where the applications actually depend on it well as jitter jitter is just I",
    "start": "176040",
    "end": "181080"
  },
  {
    "text": "think it's a silly word I like it it's my favorite performance word but jitter is the basically the the",
    "start": "181080",
    "end": "186750"
  },
  {
    "text": "inter-arrival packet delays times so if I seem to do a packet every 20 milliseconds so you get a packet 20",
    "start": "186750",
    "end": "191760"
  },
  {
    "text": "seconds 20 milliseconds 20 milliseconds for 20 milliseconds 50 milliseconds 20 milliseconds you just experience jitter",
    "start": "191760",
    "end": "197640"
  },
  {
    "text": "we didn't lose any packets but that packet came in 30 milliseconds later than we thought it would and so that matters with things like",
    "start": "197640",
    "end": "203130"
  },
  {
    "text": "voice or IP applications and some real-time applications video where you're buffering and that can actually",
    "start": "203130",
    "end": "208470"
  },
  {
    "text": "be equivalent to losing the packet and so that you know we'll talk about some of those types of use cases you know to",
    "start": "208470",
    "end": "216210"
  },
  {
    "start": "216000",
    "end": "216000"
  },
  {
    "text": "show you exactly how it sort of TCP works in a nutshell we've got two messages here we're gonna transfer some",
    "start": "216210",
    "end": "222180"
  },
  {
    "text": "data between them so what does this look like we want transfer data what's the bandwidth of the circuit let's say is 10",
    "start": "222180",
    "end": "227700"
  },
  {
    "text": "gigs let's say the latency is 500 milliseconds so for us to send the data to the other side takes 500 milliseconds",
    "start": "227700",
    "end": "235500"
  },
  {
    "text": "now I'm gonna use lazy math because then the return path also takes five milliseconds so it takes one second yep",
    "start": "235500",
    "end": "242820"
  },
  {
    "text": "unless you're sending traffic through like a satellite this is not realistic but I for the purposes of us not wanting",
    "start": "242820",
    "end": "249209"
  },
  {
    "text": "to very complicated math today we're gonna assume that round-trip takes one second so what's the actual throughput",
    "start": "249209",
    "end": "254370"
  },
  {
    "text": "here the throughput is basically how are big that packet is so if that's a 1,400",
    "start": "254370",
    "end": "261060"
  },
  {
    "text": "byte packet we now have you know 1,400 bytes that we sent in one",
    "start": "261060",
    "end": "267090"
  },
  {
    "text": "that's not vermin II that's like 1.4 kilobytes right it's not very big so how do we improve that if we if we",
    "start": "267090",
    "end": "276000"
  },
  {
    "text": "know that latency in this case this is like that classic scenario if like I've got a 10 gig link why am I not getting 10 gigs and that's because there's",
    "start": "276000",
    "end": "282780"
  },
  {
    "text": "latency involved so for example if you have something that has 2 milliseconds or versus 200 milliseconds that could",
    "start": "282780",
    "end": "288630"
  },
  {
    "text": "change your effective bandwidth from something like 80 megabits per second to 8 kilobits per second depending upon",
    "start": "288630",
    "end": "295350"
  },
  {
    "text": "your sort of sizes the way you actually change this is do you can send more data",
    "start": "295350",
    "end": "301500"
  },
  {
    "text": "in that packet so change the the MTU so basically the maximum packet size the",
    "start": "301500",
    "end": "309240"
  },
  {
    "text": "internet and most normal networks or 1500 bytes that's very very standard you",
    "start": "309240",
    "end": "314970"
  },
  {
    "text": "can also do that with jumbo MTU so up to 9000 so if you own the network like in",
    "start": "314970",
    "end": "319979"
  },
  {
    "text": "your own BBC or period V PC it's up to 9000 you don't always have control of",
    "start": "319979",
    "end": "325229"
  },
  {
    "text": "that so the standard way to do this is actually through TCP it's a visible thing you never really care about our",
    "start": "325229",
    "end": "330479"
  },
  {
    "text": "control and every single time you do an HTTP sort of requests or anything over TCP this stuff there's some really",
    "start": "330479",
    "end": "337050"
  },
  {
    "text": "actually cool algorithms if you're cool like it you want to go into it but TCP is actually super super complicated the reason why it's lasted what is it 25",
    "start": "337050",
    "end": "343350"
  },
  {
    "text": "years old now it's because of these congestion window algorithms where they say you know how much how many package",
    "start": "343350",
    "end": "349169"
  },
  {
    "text": "should I send if I get some losses if there's latency that's it's very very complicated stuff but the short story is",
    "start": "349169",
    "end": "354390"
  },
  {
    "text": "you know if you're not dropping any packets they send more and more and more packets and so what you really want to",
    "start": "354390",
    "end": "360630"
  },
  {
    "text": "do is you want to optimize this in more and more packets to get higher bandwidth especially over high all agencies so",
    "start": "360630",
    "end": "366570"
  },
  {
    "text": "when is latency really matter there's a couple use cases what does any time you're doing sort of cross region",
    "start": "366570",
    "end": "371850"
  },
  {
    "start": "367000",
    "end": "367000"
  },
  {
    "text": "connectivity so if some sort of global application you may have users all over the world some of them might be coming",
    "start": "371850",
    "end": "377430"
  },
  {
    "text": "over Ethernet over barbed wire and so you really never know that that bandwidth or sort of the latency there",
    "start": "377430",
    "end": "383520"
  },
  {
    "text": "the other ones like for clustering sometimes those these clusters like nanoseconds and fractions and fractions",
    "start": "383520",
    "end": "389789"
  },
  {
    "text": "of a second basically can have a huge impacts on the bandwidth of the cluster as well as things like last Akash and",
    "start": "389789",
    "end": "396570"
  },
  {
    "text": "memcache that have that same sort of clustering functionality if you have a latency issue what can you",
    "start": "396570",
    "end": "402400"
  },
  {
    "text": "do you can tune it so you can set large room to use if you own the network if not you can do some TCP tuning we'll",
    "start": "402400",
    "end": "409330"
  },
  {
    "text": "talk about a few examples of that you can also just make the network more efficient so less loss and those kinds",
    "start": "409330",
    "end": "414490"
  },
  {
    "text": "of things so we'll go through some of those examples you can also just not fight it make",
    "start": "414490",
    "end": "421180"
  },
  {
    "text": "friends with physics fighting latency is a very very hard thing to do very people beat physics and so you can just make",
    "start": "421180",
    "end": "428350"
  },
  {
    "text": "your things closer together so exempt for example in the high level you can",
    "start": "428350",
    "end": "433870"
  },
  {
    "text": "choose the right regions to operate in which is in the range of tens of milliseconds you can choose maybe to operate in one region between different",
    "start": "433870",
    "end": "441100"
  },
  {
    "text": "availability zones or even a single availability zone that's gets you mean like the 1 to 2 millisecond sort of range or you can",
    "start": "441100",
    "end": "447580"
  },
  {
    "text": "also go into a placement group where we can guarantee your instances are very very close together and they're sort of",
    "start": "447580",
    "end": "452920"
  },
  {
    "text": "in that less than a millisecond sort of area in terms of packets per second",
    "start": "452920",
    "end": "459580"
  },
  {
    "text": "that's another very important input to the sort of performance equation so packets per second matters for a couple",
    "start": "459580",
    "end": "466780"
  },
  {
    "text": "things one is every single time your operating system receives a packet the kernel has to do some work on that",
    "start": "466780",
    "end": "473320"
  },
  {
    "text": "packet to find out how to process it how to manipulate the underlying data and so you you take CPU and i/o load to you",
    "start": "473320",
    "end": "481120"
  },
  {
    "text": "know do packet processing not just that but the underlying infrastructure the infrastructure the ativ s operates we",
    "start": "481120",
    "end": "488020"
  },
  {
    "text": "have to process all those packets as well and so every instance type has packets per second limits and what we",
    "start": "488020",
    "end": "493840"
  },
  {
    "text": "can do and what our hardware can do and so if especially if you have some type of applications that are particularly high packets per second transactional",
    "start": "493840",
    "end": "501070"
  },
  {
    "text": "systems routing and firewall sort of systems where you've got routing instances on a easy to instance any of",
    "start": "501070",
    "end": "508330"
  },
  {
    "text": "those kinds of things or if you've got very small packets for whatever reason the packets per second is likely one of",
    "start": "508330",
    "end": "515469"
  },
  {
    "text": "the things that you need to focus on so one of things you can do if you have control over it is the MTU so inside of",
    "start": "515470",
    "end": "524560"
  },
  {
    "text": "a V PC or peered V PC the maximum MTU is 9001 I think we just chose one extra",
    "start": "524560",
    "end": "530980"
  },
  {
    "text": "than 9-thousand to prove that we could nine thousand a very standard jumbo MTU size so you can do this and that this",
    "start": "530980",
    "end": "538240"
  },
  {
    "text": "means you have the same amount of packets per second but you're getting more effective data out of that and so",
    "start": "538240",
    "end": "544270"
  },
  {
    "text": "if you care about that type of thing and you think packets per second is an issue I would try increasing the MTU and see",
    "start": "544270",
    "end": "550089"
  },
  {
    "text": "if you get better performance the other one here is loss so if someone says hey",
    "start": "550089",
    "end": "555550"
  },
  {
    "text": "we've got one percent packet loss we're only dropping one out of a hundred packets is that bad yeah you don't want",
    "start": "555550",
    "end": "562210"
  },
  {
    "text": "that because even with one percent loss with most TCP algorithms one percent loss you're gonna have about 46 percent",
    "start": "562210",
    "end": "568990"
  },
  {
    "text": "of your entire throughput as opposed to if you had zero percent loss so if if",
    "start": "568990",
    "end": "575410"
  },
  {
    "text": "you can measure loss if you can look at those types of things on your systems that's one of a very very high effect of",
    "start": "575410",
    "end": "580540"
  },
  {
    "text": "your effective throughput and so you want to figure out where those losses happening and minimize that it might be because maybe you got too small an",
    "start": "580540",
    "end": "586330"
  },
  {
    "text": "instance and so the instance is just not able to handle the network path coming to it it could be because of your",
    "start": "586330",
    "end": "592839"
  },
  {
    "text": "carriers or other networks in the middle but network loss can be you know very very detrimental and it's probably the",
    "start": "592839",
    "end": "599050"
  },
  {
    "text": "biggest impact here if you're basically through your performance now this is different than UDP so UDP you lose a",
    "start": "599050",
    "end": "604900"
  },
  {
    "text": "packet it just keeps on sending packets it's just UDP just since that gets all day long it doesn't care if you get lost",
    "start": "604900",
    "end": "610810"
  },
  {
    "text": "and so that's actually useful testing technique we'll talk about later if you if you're not sure if your bandwidth is",
    "start": "610810",
    "end": "617140"
  },
  {
    "text": "higher or not you can test UDP traffic because it will saturate the length if you do actually want to check the loss",
    "start": "617140",
    "end": "622990"
  },
  {
    "text": "on your operating system and for a giving application you're gonna do a net stat and look for retransmissions and",
    "start": "622990",
    "end": "629620"
  },
  {
    "text": "that will tell you you know what level of loss you've got you may want to clear some of these over time because they can",
    "start": "629620",
    "end": "635440"
  },
  {
    "text": "tend to build up so let's take an example application so I'll talk about a couple of sort of high-level concepts so",
    "start": "635440",
    "end": "643150"
  },
  {
    "text": "two servers want to talk to each other in this case it could be a high transaction rate HTTP service so maybe",
    "start": "643150",
    "end": "649690"
  },
  {
    "text": "there's an API server or transactional server something like that so the actual testing scenario is",
    "start": "649690",
    "end": "655570"
  },
  {
    "start": "655000",
    "end": "655000"
  },
  {
    "text": "something like this where we have a server you have a client there's about 80 milliseconds of round-trip time so",
    "start": "655570",
    "end": "661390"
  },
  {
    "text": "that's roughly equivalent to maybe East Coast to West Coast a 1500 MTU so that's the standard",
    "start": "661390",
    "end": "667219"
  },
  {
    "text": "Internet packet size we're gonna do two hundred thousand requests for a you know",
    "start": "667219",
    "end": "672499"
  },
  {
    "text": "a ten thousand sized object so maybe just a fairly small webpage of some sort",
    "start": "672499",
    "end": "677959"
  },
  {
    "text": "or transaction and what we really want to do is we want to make sure that we're minimizing latency but we don't we don't",
    "start": "677959",
    "end": "685519"
  },
  {
    "text": "have necessarily control of the network so what can we do so in this scenario we're gonna mess with the initial window",
    "start": "685519",
    "end": "691309"
  },
  {
    "text": "size so initial congestion window basically says hey when you start sending me data send me three packets of",
    "start": "691309",
    "end": "697759"
  },
  {
    "text": "data at a time and if we're good with that and we you know that's going good for a while let's increase that over",
    "start": "697759",
    "end": "703939"
  },
  {
    "text": "time but you can modify that that for that tuning parameter to say like hey my",
    "start": "703939",
    "end": "710179"
  },
  {
    "text": "network quality I know is actually really good so let's start off by sending me more packets so with three",
    "start": "710179",
    "end": "715759"
  },
  {
    "text": "packets you know it takes three hundred twenty milliseconds to do that request and the average bandwidth is roughly you",
    "start": "715759",
    "end": "720919"
  },
  {
    "text": "know ten or sorry 12 megabits per second if we increase that to ten packets we",
    "start": "720919",
    "end": "726769"
  },
  {
    "text": "now get to decreasing the time by about 100 milliseconds 80 milliseconds like that and then sixteen if we go to",
    "start": "726769",
    "end": "733459"
  },
  {
    "text": "sixteen packets where it now 160 milliseconds is 1/2 megabits per second you know you can go pretty high on this",
    "start": "733459",
    "end": "739309"
  },
  {
    "text": "if you go too high then you know actually gonna send too much traffic you'll have some loss and then we'll",
    "start": "739309",
    "end": "745669"
  },
  {
    "text": "immediately back down so you have to find that sort of that Goldilocks zone where it's it's high enough for your",
    "start": "745669",
    "end": "751159"
  },
  {
    "text": "network but not too high and so you know we can basically increase the the latency or the bandwidth of this by you",
    "start": "751159",
    "end": "757519"
  },
  {
    "text": "know 79 percent just by tuning some operating system parameters the actual",
    "start": "757519",
    "end": "762529"
  },
  {
    "text": "example of this here is here where an IP route command I basically add this init",
    "start": "762529",
    "end": "767539"
  },
  {
    "text": "cwnd to 16 you know this session is not necessarily",
    "start": "767539",
    "end": "772759"
  },
  {
    "text": "an operating system tuning class this is really specific to you know how it relates to a to BS so we're not gonna go",
    "start": "772759",
    "end": "778789"
  },
  {
    "text": "into all the TCP tuning stuff so here's some other example things you can change so the receive window the congestion",
    "start": "778789",
    "end": "786409"
  },
  {
    "text": "control algorithms you know how fast or slow that the TCP algorithm will send",
    "start": "786409",
    "end": "791509"
  },
  {
    "text": "more or less packets retransmission timers and how long it will wait for a packet if you know your network is very",
    "start": "791509",
    "end": "798649"
  },
  {
    "text": "low latency you can set that window very small because if you just didn't getting after 100 milliseconds you know like it's just",
    "start": "798649",
    "end": "804830"
  },
  {
    "text": "gone we're never going to get it because we know what their average latency is 5 milliseconds or something like that so",
    "start": "804830",
    "end": "811810"
  },
  {
    "text": "up next we're going to talk about some of the ATS network performance features and sort of how performance works",
    "start": "811810",
    "end": "818690"
  },
  {
    "text": "specifically on a bass as well as some of the history of like what's going on in the hood of your instance and those",
    "start": "818690",
    "end": "824120"
  },
  {
    "text": "kinds of things so there's fresh everybody you see the cops me this time",
    "start": "824120",
    "end": "831500"
  },
  {
    "text": "[Applause]",
    "start": "831500",
    "end": "835070"
  },
  {
    "text": "ok so I wanted to talk briefly about how",
    "start": "836740",
    "end": "841790"
  },
  {
    "text": "you can achieve maximum network performance on ec2 instances but also about how we got to achieving that",
    "start": "841790",
    "end": "849050"
  },
  {
    "text": "maximum performance by the way spoiler alert to achieve the maximum performance just run our latest generation instances",
    "start": "849050",
    "end": "855080"
  },
  {
    "start": "851000",
    "end": "851000"
  },
  {
    "text": "you in most circumstances you would get pretty great performance but it's been a",
    "start": "855080",
    "end": "861860"
  },
  {
    "text": "journey so I want to talk about how we arrived there with what are substantial",
    "start": "861860",
    "end": "866930"
  },
  {
    "text": "improvements in latency packet rate and to hood and it's all about the nitrous",
    "start": "866930",
    "end": "872029"
  },
  {
    "text": "system it's an evolution of nitro which is a lightweight hypervisor that manages",
    "start": "872029",
    "end": "878060"
  },
  {
    "text": "CPU and memory efficiently and provides you with near bare-metal performance for most your applications",
    "start": "878060",
    "end": "884420"
  },
  {
    "text": "it's a nitro card which offloads a bunch of the processing functionality all of the offloads all of this storage and",
    "start": "884420",
    "end": "890720"
  },
  {
    "text": "network processing and bunch of virtual machine management to again provide you with more consistent jitter free",
    "start": "890720",
    "end": "897950"
  },
  {
    "text": "experience and there's a nitro security chip which is managing and monitoring our hardware to ensure that it's working",
    "start": "897950",
    "end": "905930"
  },
  {
    "text": "as efficiently as possible and in terms of networking the key feature for that",
    "start": "905930",
    "end": "911900"
  },
  {
    "text": "nitro delivers is enhanced networking now start working is a basically a technology that uses a CeraVe or PCI",
    "start": "911900",
    "end": "919370"
  },
  {
    "text": "pass-through to essentially get the hypervisor layer out of the way all of virtualization is premised on hyper",
    "start": "919370",
    "end": "926120"
  },
  {
    "text": "virtualization adding an overhead to your network path or your storage path we essentially take it out of the way by",
    "start": "926120",
    "end": "933050"
  },
  {
    "text": "providing you near access directly to the underlying hardware and that",
    "start": "933050",
    "end": "938980"
  },
  {
    "text": "improves both your latency and your packet rate as Nick was mentioning",
    "start": "938980",
    "end": "944930"
  },
  {
    "text": "packet rate is relevant in many circumstances many applications require small packets instead of being able to",
    "start": "944930",
    "end": "951800"
  },
  {
    "text": "use jumbo packets in those circumstances it's very important to send packets efficiently and fast so enhance that",
    "start": "951800",
    "end": "958670"
  },
  {
    "text": "working substantially improves your packet rate performance and substantially lowers your latency and jitter and just as a instantiation this",
    "start": "958670",
    "end": "969860"
  },
  {
    "start": "966000",
    "end": "966000"
  },
  {
    "text": "graph shows how latency has improved within a placement group in our network",
    "start": "969860",
    "end": "975080"
  },
  {
    "text": "this shows the last four generations of the compute optimized instance types",
    "start": "975080",
    "end": "980480"
  },
  {
    "text": "starting with CC - this is our first like this is the first instance that",
    "start": "980480",
    "end": "985940"
  },
  {
    "text": "gave us ten gigabytes networking however this was not using a NOS networking c3",
    "start": "985940",
    "end": "991190"
  },
  {
    "text": "was the first instance where we introduced this enhanced networking concept and you see a substantial decrease more than half the latency and",
    "start": "991190",
    "end": "999710"
  },
  {
    "text": "I'm showing you latency in both the average and the worst case because as you know many applications are very",
    "start": "999710",
    "end": "1006280"
  },
  {
    "text": "tuned to how your worst case performance is and our goal is to provide you with",
    "start": "1006280",
    "end": "1011740"
  },
  {
    "text": "the same consistent performance not just when you're operating normally but even when you're operating the worst case",
    "start": "1011740",
    "end": "1017830"
  },
  {
    "text": "environments what is not as clear in this graph because of the because of the",
    "start": "1017830",
    "end": "1026110"
  },
  {
    "text": "y-axis is how that performance has continued to improve across generations",
    "start": "1026110",
    "end": "1031900"
  },
  {
    "text": "this is the same announced networking technology it has transitioned we have added more and more features of nitro",
    "start": "1031900",
    "end": "1038250"
  },
  {
    "text": "that is led to near halving of the performance from latency performance",
    "start": "1038250",
    "end": "1044290"
  },
  {
    "text": "from c3 to c5 within two generations now we are under 50 microseconds this is",
    "start": "1044290",
    "end": "1051970"
  },
  {
    "text": "round-trip prime by the way within a placement group most applications can kind of would really like to have that",
    "start": "1051970",
    "end": "1059020"
  },
  {
    "text": "kind of performance and would be very efficient and running so you've seen a",
    "start": "1059020",
    "end": "1066580"
  },
  {
    "text": "improvement in performance I wanted to talk how that has evolved and what kind of technologies went in and how with",
    "start": "1066580",
    "end": "1072250"
  },
  {
    "text": "each imp with each generation we provided new your features that can that have benefitted do with c5 providing us",
    "start": "1072250",
    "end": "1080080"
  },
  {
    "text": "providing you the best possible networking experience today on eight of those so this is showing hardware and",
    "start": "1080080",
    "end": "1087640"
  },
  {
    "text": "software configuration of assisi to instance this was pre nitro it uses the",
    "start": "1087640",
    "end": "1093370"
  },
  {
    "text": "same hypervisor and uses para virtualization to send your storage and network traffic through dom0",
    "start": "1093370",
    "end": "1099820"
  },
  {
    "text": "and onto the underlying network resources obviously you're passing",
    "start": "1099820",
    "end": "1105399"
  },
  {
    "text": "through dom0 there are a lot of contention there there's a lot of functionality so you are inevitably",
    "start": "1105399",
    "end": "1111039"
  },
  {
    "text": "going to encounter some latency and jitter how do we get rid of those things",
    "start": "1111039",
    "end": "1117600"
  },
  {
    "text": "we bypass hypervisor we used a",
    "start": "1117600",
    "end": "1123100"
  },
  {
    "text": "technology called Azariah v which is basically single rutile virtualization it exposes virtual functions straight",
    "start": "1123100",
    "end": "1131620"
  },
  {
    "text": "into the instance that you're running and they are exposed as in using Intel",
    "start": "1131620",
    "end": "1137169"
  },
  {
    "text": "drivers directly to your elastic network interfaces what it achieves is we're",
    "start": "1137169",
    "end": "1143289"
  },
  {
    "text": "passing the hypervisor you latency falls down as we saw in the previous graph but",
    "start": "1143289",
    "end": "1148419"
  },
  {
    "text": "even more important your jitter your variation falls down substantially because not you're not in the non zero",
    "start": "1148419",
    "end": "1154690"
  },
  {
    "text": "path anymore we used just some geeking out a little",
    "start": "1154690",
    "end": "1160720"
  },
  {
    "text": "bit we used until 8:00 to 5:00 9:00 9:00 as our chip that that provided this",
    "start": "1160720",
    "end": "1166539"
  },
  {
    "text": "technology and as you can see there's a loopback cable that goes to our network",
    "start": "1166539",
    "end": "1172389"
  },
  {
    "text": "card which actually does all the V V PC processing provided a substantial",
    "start": "1172389",
    "end": "1179799"
  },
  {
    "text": "improvement but as you can see storage is still going through dom0 I wanted to",
    "start": "1179799",
    "end": "1187120"
  },
  {
    "start": "1183000",
    "end": "1183000"
  },
  {
    "text": "jump to c4 here there two things that happen differently one is we went to our second generation of nitro cards this",
    "start": "1187120",
    "end": "1194679"
  },
  {
    "text": "was actually based off under pune labs ASIC you might have heard that name of",
    "start": "1194679",
    "end": "1199760"
  },
  {
    "text": "times at the serene one or previous ones as well",
    "start": "1199760",
    "end": "1205430"
  },
  {
    "text": "it's a it was an Israeli starter that was developing this Asics that we really liked and we decided to incorporate them",
    "start": "1205430",
    "end": "1211880"
  },
  {
    "text": "in c4 we liked them so much that we actually acquired them around this time so now all this improvement that we have",
    "start": "1211880",
    "end": "1218570"
  },
  {
    "text": "seen including the a1 all these have come from custom Asics that we developed",
    "start": "1218570",
    "end": "1227020"
  },
  {
    "text": "the other new ones here to realize is that we started providing EBS optimized",
    "start": "1227710",
    "end": "1233930"
  },
  {
    "text": "by default what that meant is previous before c4 all the instances shared the",
    "start": "1233930",
    "end": "1241250"
  },
  {
    "text": "network and storage paths you could actually choose to enable EBS optimized as an option but that meant that your",
    "start": "1241250",
    "end": "1248180"
  },
  {
    "text": "network throughput would have been reduced with this option now you get a",
    "start": "1248180",
    "end": "1253550"
  },
  {
    "text": "dedicated network and storage by default no surcharge etcetera so while c4 was",
    "start": "1253550",
    "end": "1261320"
  },
  {
    "text": "still providing 10 gigabits of performance same as c3 you're actually getting more throughput for applications",
    "start": "1261320",
    "end": "1266960"
  },
  {
    "text": "that required both storage and network access that's led to a lot of improvement in bandwidth performance",
    "start": "1266960",
    "end": "1272510"
  },
  {
    "text": "obviously now let's jump to c5 I'm jumping a few steps here this is not a",
    "start": "1272510",
    "end": "1279230"
  },
  {
    "text": "nitro deep dive I would if you are interested in this I would highly encourage you to go to that nitro deep dive there is a lot of technology",
    "start": "1279230",
    "end": "1285740"
  },
  {
    "text": "underneath and a lot of discussion on how multiple evolutions happen but",
    "start": "1285740",
    "end": "1290900"
  },
  {
    "text": "jumping to c5 there are few things have changed here now one is as you can see inside the instance we have got ena so",
    "start": "1290900",
    "end": "1298100"
  },
  {
    "text": "this is something that we developed as our own custom network device now go",
    "start": "1298100",
    "end": "1304340"
  },
  {
    "text": "into a few more details on why that was relevant but that provided us the best possible performance and even higher",
    "start": "1304340",
    "end": "1310100"
  },
  {
    "text": "throughput and even over lower latency compared to what Intel was able to provide before and you see also the",
    "start": "1310100",
    "end": "1318200"
  },
  {
    "text": "nitro hypervisor this is a lightweight hypervisor that we develop that manages",
    "start": "1318200",
    "end": "1325970"
  },
  {
    "text": "the CPU and memory in an efficient way and allows you to get virtually all of the CPU resources and the memory",
    "start": "1325970",
    "end": "1332600"
  },
  {
    "text": "resources of the lying hardware directly for your applications many for you know our",
    "start": "1332600",
    "end": "1338660"
  },
  {
    "text": "customers have benchmarked this to be near bare metal performance so no virtualization overhead for most",
    "start": "1338660",
    "end": "1345020"
  },
  {
    "text": "applications that benefits obviously networking was already not bypassed but",
    "start": "1345020",
    "end": "1351290"
  },
  {
    "text": "now you can see your applications are benefiting and that actually leads to better performance across the board and",
    "start": "1351290",
    "end": "1356780"
  },
  {
    "text": "that's the evolution of nitro it's providing you the best possible performance getting our software out of",
    "start": "1356780",
    "end": "1363320"
  },
  {
    "text": "the way and delivering you the best possible application performance obviously we have done all this offload",
    "start": "1363320",
    "end": "1370550"
  },
  {
    "text": "so we decided we realized that we could have the hypervisor removed completely",
    "start": "1370550",
    "end": "1377060"
  },
  {
    "text": "and a bunch of the offload is already on the network cards so you can now use a",
    "start": "1377060",
    "end": "1385550"
  },
  {
    "text": "bare metal instance directly if your application requires for example virtualization functions that that the",
    "start": "1385550",
    "end": "1393080"
  },
  {
    "text": "underlying CPUs provide you can use bare metal instances this we launched this",
    "start": "1393080",
    "end": "1398750"
  },
  {
    "text": "year so this was kind of the evolution of nitro so now let's look back at one",
    "start": "1398750",
    "end": "1405950"
  },
  {
    "start": "1405000",
    "end": "1405000"
  },
  {
    "text": "of the technologies that I mentioned here which was ena as I mentioned we switched from Intel to ena were in this",
    "start": "1405950",
    "end": "1414860"
  },
  {
    "text": "evolution of nitro because as our",
    "start": "1414860",
    "end": "1420700"
  },
  {
    "text": "instances as our hardware was getting denser we are putting more and more CPU",
    "start": "1420700",
    "end": "1426230"
  },
  {
    "text": "and memory resources our customers were also asking for more performance network performance as I said C 3 and C 4 were",
    "start": "1426230",
    "end": "1432770"
  },
  {
    "text": "both providing 10 gigabits performance which is great but customers were asking for even more and how could we achieve",
    "start": "1432770",
    "end": "1437870"
  },
  {
    "text": "that we wanted to develop a driver that was future-proof beyond not just",
    "start": "1437870",
    "end": "1443570"
  },
  {
    "text": "thinking about 20 gigs or 25 gigs or so on but future proved to 400 gigs and if",
    "start": "1443570",
    "end": "1450290"
  },
  {
    "text": "you might have notice we did increase our performance yesterday on our latest generation instances we're at at",
    "start": "1450290",
    "end": "1458750"
  },
  {
    "text": "yesterday's at last night's keynote renowned c5n which delivers 100 gigabits",
    "start": "1458750",
    "end": "1464000"
  },
  {
    "text": "performance to your instant do a single instance play ene also provided other benefits",
    "start": "1464000",
    "end": "1472539"
  },
  {
    "text": "which is increasing the queues and this is very relevant for packet bound applications which Goods require high",
    "start": "1472539",
    "end": "1478509"
  },
  {
    "text": "packet processing using more queues spreads out performance across your",
    "start": "1478509",
    "end": "1483850"
  },
  {
    "text": "virtual CPUs so that you are not bottle necked inside your instance and trying to send high packet rate the increased",
    "start": "1483850",
    "end": "1491109"
  },
  {
    "text": "queues helps us also to deliver better performance for example c5 has eight",
    "start": "1491109",
    "end": "1496359"
  },
  {
    "text": "queues which is more than the two queues that Intel provided but now c5 when is gone push that up to 32 cues that can",
    "start": "1496359",
    "end": "1505320"
  },
  {
    "text": "delivering 100 gigs is is a multi-step process obviously you have to have the",
    "start": "1505320",
    "end": "1510700"
  },
  {
    "text": "network you have to have the hardware and you have to have the support inside the instance and optimizing your",
    "start": "1510700",
    "end": "1518320"
  },
  {
    "text": "instance requires using more queues so we have delivered that with seafarin you",
    "start": "1518320",
    "end": "1524440"
  },
  {
    "text": "need reduce the latency and jitter as we have seen before it's a new driver it is",
    "start": "1524440",
    "end": "1529479"
  },
  {
    "text": "now however it is now available for the for the last two years and we have had",
    "start": "1529479",
    "end": "1535389"
  },
  {
    "text": "broad operating system support across all of our partners something new here",
    "start": "1535389",
    "end": "1541179"
  },
  {
    "text": "at announcer is we just a couple of weeks back we introduced a 2.0 version of the driver still fully backward and",
    "start": "1541179",
    "end": "1548259"
  },
  {
    "text": "forward compatible if you're running one dot X version so you can run two righto however it actually further improves",
    "start": "1548259",
    "end": "1555309"
  },
  {
    "text": "your latency performance and your packet rate performance because of features that we introduced low latency queues",
    "start": "1555309",
    "end": "1561970"
  },
  {
    "text": "that can reduce your average and tail latency is even further and checksum offloads",
    "start": "1561970",
    "end": "1567399"
  },
  {
    "text": "just as an example going back to that graph I've added another line at the",
    "start": "1567399",
    "end": "1574179"
  },
  {
    "text": "another bar at then that shows the latency improvements with this ena to",
    "start": "1574179",
    "end": "1579220"
  },
  {
    "text": "dotto this is again available on the same see for instance that you're running all you need to do is just a update your driver and you get this",
    "start": "1579220",
    "end": "1586499"
  },
  {
    "text": "reduction of almost twenty percent in both your average and tail Layton sees",
    "start": "1586499",
    "end": "1592739"
  },
  {
    "text": "so we she seen the evolution on night ruins and shown it to you on",
    "start": "1592739",
    "end": "1599650"
  },
  {
    "text": "how latency has improved the way we",
    "start": "1599650",
    "end": "1604750"
  },
  {
    "start": "1604000",
    "end": "1604000"
  },
  {
    "text": "advertise our instances is obviously throughput and bandwidth and that's something that you guys can latch onto",
    "start": "1604750",
    "end": "1612100"
  },
  {
    "text": "directly from our instance specifications this is how we have",
    "start": "1612100",
    "end": "1619150"
  },
  {
    "text": "evolved our bandwidth two things to note here one is instance and storage",
    "start": "1619150",
    "end": "1625120"
  },
  {
    "text": "separation so you can see increasing performance from c3 to c4 and c4 to c5",
    "start": "1625120",
    "end": "1631600"
  },
  {
    "text": "and now obviously your networking is no longer bottleneck because of c5 and your",
    "start": "1631600",
    "end": "1637060"
  },
  {
    "text": "high performance computing applications can scale out even faster I wanted to",
    "start": "1637060",
    "end": "1643510"
  },
  {
    "text": "highlight something that is kind of implicit here all of these are running the same drivers standard drivers that",
    "start": "1643510",
    "end": "1650920"
  },
  {
    "text": "we run a c5 instance the machine image",
    "start": "1650920",
    "end": "1656770"
  },
  {
    "text": "that you're running on c5 you can start running on c5 N and get that performance improvement this is not a custom",
    "start": "1656770",
    "end": "1662730"
  },
  {
    "text": "implementation or custom driver where you need to rewrite your applications it's available natively the same secure",
    "start": "1662730",
    "end": "1669310"
  },
  {
    "text": "elastic way that we deliver all of ec2 it is available not just within a small",
    "start": "1669310",
    "end": "1674320"
  },
  {
    "text": "constrained cluster it's available within an availability zone within a region to and from s3 so your big data",
    "start": "1674320",
    "end": "1682390"
  },
  {
    "text": "applications can start running much faster because now you're downloading much faster and hydrating your data much",
    "start": "1682390",
    "end": "1688510"
  },
  {
    "text": "faster backing up data much faster your machine learning applications can run faster because of distributed",
    "start": "1688510",
    "end": "1694080"
  },
  {
    "text": "capabilities your network bound applications can scale up scale down",
    "start": "1694080",
    "end": "1699520"
  },
  {
    "text": "scale out independently now of CPN memory because your your throughput has increased",
    "start": "1699520",
    "end": "1704950"
  },
  {
    "text": "obviously 100 gigs is great but it's not just hundred gigs it's available on",
    "start": "1704950",
    "end": "1712000"
  },
  {
    "text": "smaller sizes so many of you don't run largest instance types or instance sizes",
    "start": "1712000",
    "end": "1720120"
  },
  {
    "text": "you can see that the smaller sizes can deliver up to 25 gigabits of performance",
    "start": "1720120",
    "end": "1727890"
  },
  {
    "text": "if your application is network bound c-51 would be great",
    "start": "1728430",
    "end": "1733870"
  },
  {
    "text": "it's not just about that it's about having a diverse choice so t3 our first",
    "start": "1733870",
    "end": "1739980"
  },
  {
    "text": "burstable instance I've built on nitro delivers up to 5 gigabytes of performance our general class families",
    "start": "1739980",
    "end": "1747760"
  },
  {
    "text": "of c-5m 5 are 5 these are the compute and memory optimized depending on your application you get you can choose which",
    "start": "1747760",
    "end": "1754750"
  },
  {
    "text": "instance type you're not constrained on networking performance if your if your",
    "start": "1754750",
    "end": "1760300"
  },
  {
    "text": "application is a network bound choose c5n and now you're going to get great performance there as well our goal here",
    "start": "1760300",
    "end": "1767590"
  },
  {
    "text": "is to have networking not be a bottleneck and we are trying to make",
    "start": "1767590",
    "end": "1772810"
  },
  {
    "text": "that varistor so I've talked a bit about",
    "start": "1772810",
    "end": "1779440"
  },
  {
    "text": "latency and throughput and the third thing is packet rate now packet rate is",
    "start": "1779440",
    "end": "1786580"
  },
  {
    "text": "kind of dependent on a multitude of factors applications instance",
    "start": "1786580",
    "end": "1791740"
  },
  {
    "text": "configuration VPC configuration so on and so forth so it's not it's hard to quantify how the improvement is there we",
    "start": "1791740",
    "end": "1798460"
  },
  {
    "text": "obviously see a lot of improvement as I showed 20x improvement but I wanted to quantify it better with a customer",
    "start": "1798460",
    "end": "1805950"
  },
  {
    "start": "1804000",
    "end": "1804000"
  },
  {
    "text": "anecdote Netflix is implementing a large",
    "start": "1805950",
    "end": "1811540"
  },
  {
    "text": "micro services architecture the characteristic there is you get a bunch",
    "start": "1811540",
    "end": "1817480"
  },
  {
    "text": "of requests you need to cash those requests and all of these micro services are going to go read from that request",
    "start": "1817480",
    "end": "1824380"
  },
  {
    "text": "cache every request is a single packet so lots of requests means lots of",
    "start": "1824380",
    "end": "1831280"
  },
  {
    "text": "packets and obviously it's based of memcache D so your average latency",
    "start": "1831280",
    "end": "1836400"
  },
  {
    "text": "requirements are really stringent you know obviously that means you would read locally from you have a distributed",
    "start": "1836400",
    "end": "1846370"
  },
  {
    "text": "system across Easy's for availability in redundancy you read locally and write globally",
    "start": "1846370",
    "end": "1853020"
  },
  {
    "text": "how did Netflix benefit here they when they when they when we launched C file",
    "start": "1853020",
    "end": "1860740"
  },
  {
    "start": "1854000",
    "end": "1854000"
  },
  {
    "text": "they benchmark C 5 they were running on M 4 which was by the way again an enhanced networking based instance",
    "start": "1860740",
    "end": "1867610"
  },
  {
    "text": "it was running in the Intel technology this is just a transition from an m4 to a c5 so enhanced networking to an ene",
    "start": "1867610",
    "end": "1874570"
  },
  {
    "text": "the capabilities of nitro system and the capabilities of ene has improved the",
    "start": "1874570",
    "end": "1880570"
  },
  {
    "text": "packet rate performance so substantially that they have now scaled down from ten instances to a single instance they",
    "start": "1880570",
    "end": "1887020"
  },
  {
    "text": "could run all of the region trafficker than a single instance obviously they will distribute it and have multiple",
    "start": "1887020",
    "end": "1892390"
  },
  {
    "text": "instances available one ejz etc but now they could run it so much more",
    "start": "1892390",
    "end": "1898960"
  },
  {
    "text": "efficiently at do a price analysis it's almost a 90 percent cost savings",
    "start": "1898960",
    "end": "1905440"
  },
  {
    "text": "obviously the latency improvement that I talked about also helped in improving their application performance but the",
    "start": "1905440",
    "end": "1912610"
  },
  {
    "text": "PPS drove down there cause substantially",
    "start": "1912610",
    "end": "1917700"
  },
  {
    "text": "so nitro is great ena is great how do you get that performance as I said most",
    "start": "1917700",
    "end": "1926620"
  },
  {
    "text": "of our newest generation instances are going to be built on nitro and running",
    "start": "1926620",
    "end": "1933730"
  },
  {
    "text": "those instances would require you to have ena capabilities so the one thing",
    "start": "1933730",
    "end": "1940330"
  },
  {
    "text": "that you need to do before you launch those instances is check that your ami",
    "start": "1940330",
    "end": "1945549"
  },
  {
    "text": "has announced networking enabled with ena obviously you would need to have the",
    "start": "1945549",
    "end": "1950950"
  },
  {
    "text": "drivers inside the the machine image so that it boots up properly once it's",
    "start": "1950950",
    "end": "1957970"
  },
  {
    "text": "launched but as I mentioned before most of our partners almost all of our",
    "start": "1957970",
    "end": "1963549"
  },
  {
    "text": "partners now have ena support enabled so if you take any market place army any",
    "start": "1963549",
    "end": "1968590"
  },
  {
    "text": "QuickStart army all of them have ena support built in just take a nap event",
    "start": "1968590",
    "end": "1976630"
  },
  {
    "text": "runner and you'll get the best performance that we could deliver today however that's not all ena is great for",
    "start": "1976630",
    "end": "1986740"
  },
  {
    "start": "1981000",
    "end": "1981000"
  },
  {
    "text": "most applications for most in fact almost all applications that are network",
    "start": "1986740",
    "end": "1992320"
  },
  {
    "text": "constrained can benefit from it there are certain applications that can be developed in a way to take advantage of",
    "start": "1992320",
    "end": "1999820"
  },
  {
    "text": "even better performance and that is based of this Intel data",
    "start": "1999820",
    "end": "2004980"
  },
  {
    "text": "plane development kit technology it's basically a set of C libraries and",
    "start": "2004980",
    "end": "2010350"
  },
  {
    "text": "drivers it enables faster processing by bypassing the kernel inside your",
    "start": "2010350",
    "end": "2016530"
  },
  {
    "text": "instance I talked a bit about bypassing the software and in our stack this is going into your instance and now",
    "start": "2016530",
    "end": "2022680"
  },
  {
    "text": "optimizing performance there you can get more control of packet processing you",
    "start": "2022680",
    "end": "2028080"
  },
  {
    "text": "can decide which queues are pinned where you can you can send traffic accordingly and you can reduce your CPU or add",
    "start": "2028080",
    "end": "2034770"
  },
  {
    "text": "further just getting a little bit deeper into it your typical application is",
    "start": "2034770",
    "end": "2041250"
  },
  {
    "text": "going to talk to through the Linux networking stack and to the drivers",
    "start": "2041250",
    "end": "2046500"
  },
  {
    "text": "there which goes down to our underlying Hardware a DP DK application instead",
    "start": "2046500",
    "end": "2053730"
  },
  {
    "text": "talks to a user space driver we have got support for ena in NDP DK 16x and beyond",
    "start": "2053730",
    "end": "2062638"
  },
  {
    "text": "and because of this bypass you're not going to get TCP obviously at the TCP",
    "start": "2062639",
    "end": "2069990"
  },
  {
    "text": "kernel stack but you can get much more control and can bypass the kernel so your performance improves the same way",
    "start": "2069990",
    "end": "2075480"
  },
  {
    "text": "that a bunch of the SR ivy technology improves our performance within our networking similar technologies can help",
    "start": "2075480",
    "end": "2082020"
  },
  {
    "text": "here improve your performance not question that it's not it's not based of",
    "start": "2082020",
    "end": "2090840"
  },
  {
    "text": "TCP so you're not going to be able to port an application straight away but if",
    "start": "2090840",
    "end": "2096179"
  },
  {
    "text": "your application if you you are but I would encourage you to review this and see if your application is suitable for",
    "start": "2096179",
    "end": "2102570"
  },
  {
    "text": "this kind of an access pattern we supported on both our enhanced networking modes obviously the Intel one",
    "start": "2102570",
    "end": "2108090"
  },
  {
    "text": "and ena and we've seen our customer be able to get substantial performance",
    "start": "2108090",
    "end": "2113970"
  },
  {
    "text": "improvement depending on whether their application can take advantage of those access patterns before I go on to a",
    "start": "2113970",
    "end": "2122190"
  },
  {
    "text": "handoff to Nick I just wanted to emphasize the key takeaway here they can",
    "start": "2122190",
    "end": "2128580"
  },
  {
    "text": "take an EMI with ena enabled run it on our latest generation instances",
    "start": "2128580",
    "end": "2133640"
  },
  {
    "text": "depending on your requirement see now have a diverse range available from up to five gigs on T 3 to 100 gigs",
    "start": "2133640",
    "end": "2142140"
  },
  {
    "text": "on c5n I'm sure you'd really like the",
    "start": "2142140",
    "end": "2147180"
  },
  {
    "text": "performance and but that'll switch to my",
    "start": "2147180",
    "end": "2161340"
  },
  {
    "text": "con yeah so we've sort of gone over like the the global basics we've talked about",
    "start": "2161340",
    "end": "2166710"
  },
  {
    "text": "what sort of available in a that's what sort weeks we can do like he says mostly you know usually to say instances use DP",
    "start": "2166710",
    "end": "2172410"
  },
  {
    "text": "DK if you want to really get that last little bit of performance increase out of your application and you're like writing probably C code so let's talk",
    "start": "2172410",
    "end": "2180480"
  },
  {
    "start": "2180000",
    "end": "2180000"
  },
  {
    "text": "about some other things that you've got control over so you have control over the type of architectural choices you make so whether or not you're going to",
    "start": "2180480",
    "end": "2186780"
  },
  {
    "text": "be using placement groups whether or not your traffic's going over VPN or Direct Connect or they're not what's where load",
    "start": "2186780",
    "end": "2193260"
  },
  {
    "text": "balancers you might be using for your applications as well as things like you know going to s3 and whatnot so if we",
    "start": "2193260",
    "end": "2200550"
  },
  {
    "text": "start off I you know I do a lot of performance sort of talks with customers and stuff and one of the common",
    "start": "2200550",
    "end": "2206010"
  },
  {
    "start": "2201000",
    "end": "2201000"
  },
  {
    "text": "questions I get and I love answering because it's such a fun answer they're like can I how much bandwidth can I get on my V PC answer is as much as you want",
    "start": "2206010",
    "end": "2212610"
  },
  {
    "text": "like you know unless you're gonna over run all the bandwidth we have in that region if you want to run like terabytes",
    "start": "2212610",
    "end": "2218430"
  },
  {
    "text": "of capacity over very smaller regions then you should probably talk to us but other than that you don't have to worry about it like there's no V PC level",
    "start": "2218430",
    "end": "2224340"
  },
  {
    "text": "bandwidth limit you need to worry about same thing goes for in a any given availability zone or subnet all premises",
    "start": "2224340",
    "end": "2231690"
  },
  {
    "text": "these things have limits because there's Hardware boxes running this we run sort of a different type of network you don't have to worry about that there's not",
    "start": "2231690",
    "end": "2237570"
  },
  {
    "text": "sort of a concrete thing that's gonna fall over if you send too much traffic to it",
    "start": "2237570",
    "end": "2242670"
  },
  {
    "text": "same thing for Internet gateway like how much is will my internet great gateway fall over if I send too much traffic to",
    "start": "2242670",
    "end": "2247950"
  },
  {
    "text": "it because you think like a gateways like a physical box that creeks and sort of squeaks whenever you send too much traffic to it not the case it's a",
    "start": "2247950",
    "end": "2254880"
  },
  {
    "text": "logical construct and you don't have to worry about the bandwidth of that thing so Internet gateway there's no limits on",
    "start": "2254880",
    "end": "2260790"
  },
  {
    "text": "that seen as much as you want they're not gateway he's got a similar story so",
    "start": "2260790",
    "end": "2266490"
  },
  {
    "text": "not gateway we provision a certain amount of bandwidth for for all customers and we sort of chose a number there and that number is you know",
    "start": "2266490",
    "end": "2272859"
  },
  {
    "text": "customers can send up to ten gigabits per second through an AK gateway on a sustained basis and it can burst above",
    "start": "2272859",
    "end": "2278829"
  },
  {
    "text": "that quite a bit but if you're gonna go and sustain more than ten gigs then you",
    "start": "2278829",
    "end": "2284410"
  },
  {
    "text": "should probably just provision more nack gateways or you come talk to us and we can figure something out but essentially",
    "start": "2284410",
    "end": "2291220"
  },
  {
    "text": "not gateway for most customers most use cases you won't need to worry about it although you do get 65,000 ports to a",
    "start": "2291220",
    "end": "2298480"
  },
  {
    "text": "single destination so maybe you run out of that before you run out bandwidth um the peering side of things when you do",
    "start": "2298480",
    "end": "2306099"
  },
  {
    "start": "2304000",
    "end": "2304000"
  },
  {
    "text": "VPC peering between two v pcs for most functionality those g pcs are now all",
    "start": "2306099",
    "end": "2311740"
  },
  {
    "text": "this sort of the same and so from a bandwidth perspective there's also not like a magic peering pipe like if you",
    "start": "2311740",
    "end": "2319630"
  },
  {
    "text": "send trapped between two V pcs and you have BBC peering there it's just like sending it within the same V PC there's",
    "start": "2319630",
    "end": "2325390"
  },
  {
    "text": "no performance impact it's just like it's in the same V PC from performance perspective there's no latency hitting",
    "start": "2325390",
    "end": "2330579"
  },
  {
    "text": "those kinds of things so you can send traffic between two VB sees no bandwidth limits no worries there so the places",
    "start": "2330579",
    "end": "2339280"
  },
  {
    "start": "2338000",
    "end": "2338000"
  },
  {
    "text": "where there are actual limits and things you need to design around is around the actual instance itself so every instance",
    "start": "2339280",
    "end": "2344559"
  },
  {
    "text": "itself has its own bandwidth and packet per second limits and those kinds of things and that's some of this is family",
    "start": "2344559",
    "end": "2350410"
  },
  {
    "text": "stuff the fish just talked about in terms of aggregate bandwidth limits each instance type and family has more and",
    "start": "2350410",
    "end": "2358240"
  },
  {
    "text": "different types of limits so ena based instances have limits is up to 25 gigs per second you can get that within a",
    "start": "2358240",
    "end": "2364420"
  },
  {
    "text": "placement group or across availability zones that's something we enabled in January of this year to s3 you can as of",
    "start": "2364420",
    "end": "2373450"
  },
  {
    "text": "again this year you can do 25 gig was per second to s3 I mean giving you still",
    "start": "2373450",
    "end": "2378609"
  },
  {
    "text": "have to might do some things in s3 around multi flows and those kinds of things but the network is not the bottleneck at s3 up to 25 gigs you know",
    "start": "2378609",
    "end": "2388990"
  },
  {
    "text": "I mention a place maker before and tour and sort of when we're talking about latency so placement group basically make sure that your instances are very",
    "start": "2388990",
    "end": "2395859"
  },
  {
    "text": "very close together so essentially like microseconds and because they're so",
    "start": "2395859",
    "end": "2401500"
  },
  {
    "text": "close we also able run larger flows there so a single TCP flow which means like one TCP port or",
    "start": "2401500",
    "end": "2408190"
  },
  {
    "text": "like one single HTTP application we'll",
    "start": "2408190",
    "end": "2413530"
  },
  {
    "text": "be able to get up to ten gigs per second so single TCP or UDP flow up to ten gigs per second",
    "start": "2413530",
    "end": "2418890"
  },
  {
    "text": "everywhere else if I didn't mention it five gigs if I did mention up here you were asking a question weren't sure",
    "start": "2418890",
    "end": "2425260"
  },
  {
    "text": "what it was five gigs so the instance the aggregate instance bandwidth is five",
    "start": "2425260",
    "end": "2430300"
  },
  {
    "text": "gigs and the the per flow limit is five gigs for pretty much anything I didn't mention here if we I start talking about",
    "start": "2430300",
    "end": "2438430"
  },
  {
    "start": "2438000",
    "end": "2438000"
  },
  {
    "text": "connectivity back to all purposes so if we create a VPN to our virtual private",
    "start": "2438430",
    "end": "2443560"
  },
  {
    "text": "gateway which is the service we have that does manage VPN I each were those VPN connections is made of two tunnels",
    "start": "2443560",
    "end": "2451050"
  },
  {
    "text": "most customers by far will only use one and that's probably the easiest each one",
    "start": "2451050",
    "end": "2456550"
  },
  {
    "text": "those tunnels can do 1.25 gigabits per second the aggregate limit for the virtual private gateway if you manage to",
    "start": "2456550",
    "end": "2462550"
  },
  {
    "text": "load up different traffic across different tunnels is about four gigs but for intents and purposes it's 1.25 gigs",
    "start": "2462550",
    "end": "2469900"
  },
  {
    "text": "for 4 VPN and that's specifically just for VPN so another question I get sometimes is what about Direct Connect",
    "start": "2469900",
    "end": "2476200"
  },
  {
    "text": "does that 1.25 gig limit matter for Direct Connect the answer is no so the only port where the only speed limit",
    "start": "2476200",
    "end": "2482230"
  },
  {
    "text": "you're dealing with when you have Direct Connect is the physical support port speeds of your Direct Connect so we can",
    "start": "2482230",
    "end": "2489070"
  },
  {
    "text": "do things like link aggregation so you can put if you want 40 gigabits per second of bandwidth you can get 410 gig",
    "start": "2489070",
    "end": "2495580"
  },
  {
    "text": "ports we can put them in link aggregation so they look like one big 40 gig port and you can get that into you",
    "start": "2495580",
    "end": "2501100"
  },
  {
    "text": "know very very high bandwidth so we're not really we've got a lot of speed",
    "start": "2501100",
    "end": "2506290"
  },
  {
    "text": "there on Direct Connect we're still limited by that five gig aggregate flow so any given instance over Direct",
    "start": "2506290",
    "end": "2512830"
  },
  {
    "text": "Connect is still limited to both the five gig aggregate limit as well as the five gig flow limit to show sort of an",
    "start": "2512830",
    "end": "2520360"
  },
  {
    "text": "interesting example of this is some customers have said like hey I want to do I don't know 10 20 gigabits per",
    "start": "2520360",
    "end": "2527170"
  },
  {
    "start": "2523000",
    "end": "2523000"
  },
  {
    "text": "second of VPN traffic over maybe Direct Connect or VPN because maybe they want",
    "start": "2527170",
    "end": "2533080"
  },
  {
    "text": "to encrypt direct next circuit something like that so I work with one apart called aviatrix they developed this",
    "start": "2533080",
    "end": "2539140"
  },
  {
    "text": "thing called insane mode for VPN where essentially they have their instances here we can see that up top there's two",
    "start": "2539140",
    "end": "2546339"
  },
  {
    "text": "instances these are sort of normal application instances there's this one in the middle like the four-door instance and you've got two on the",
    "start": "2546339",
    "end": "2552280"
  },
  {
    "text": "bottom which are sort of the the VPN instances and the way this actually works is to get around the five gig",
    "start": "2552280",
    "end": "2558220"
  },
  {
    "text": "limit per instance is they use the instance in the middle to essentially proxy or load balanced traffic across",
    "start": "2558220",
    "end": "2565210"
  },
  {
    "text": "many many instances up to five and this this model right so you said this is a",
    "start": "2565210",
    "end": "2570250"
  },
  {
    "text": "default route for pretty much all your ancestors then you create in this in this scenario I've drawn up two",
    "start": "2570250",
    "end": "2576310"
  },
  {
    "text": "instances so they each have tunnels going back on premises that can do up to five gigs if you decide to host your own",
    "start": "2576310",
    "end": "2583150"
  },
  {
    "text": "VPN on AVS you can go past the 1.25 my limits that we have a particularly",
    "start": "2583150",
    "end": "2588670"
  },
  {
    "text": "unlike c5 and m5 instances so in theory you get five gigs of bandwidth to these",
    "start": "2588670",
    "end": "2594730"
  },
  {
    "text": "each instance they forward to the the sort of proxy for der and then it a great stew bandwidth from all those VPN",
    "start": "2594730",
    "end": "2601510"
  },
  {
    "text": "instances and so they can get cumulatively up to about you know 22 to 25 gigs there in terms of self assessing",
    "start": "2601510",
    "end": "2608920"
  },
  {
    "text": "may have seen on c5 particularly round packets per second and VPN because you tend not to have very large packets",
    "start": "2608920",
    "end": "2613930"
  },
  {
    "text": "there you know they saw about a two gig per second increase from the c-4 to the c5 so a pretty cool story there a nice",
    "start": "2613930",
    "end": "2622630"
  },
  {
    "text": "little show with an example of how you can take some more limits and if you can horizontally scale you're probably better off with your application network",
    "start": "2622630",
    "end": "2630760"
  },
  {
    "start": "2630000",
    "end": "2630000"
  },
  {
    "text": "load balancer so network load balancers a high performance low balance for us the to load bouncers we recommend our",
    "start": "2630760",
    "end": "2636609"
  },
  {
    "text": "application load balancer and network load balancer application load balancer is for l7 HTTP path host base things",
    "start": "2636609",
    "end": "2643839"
  },
  {
    "text": "that do as a sell off load that kind of thing if you just want to send packets into packets fast Network load balancers",
    "start": "2643839",
    "end": "2649180"
  },
  {
    "text": "the suggested load balancer so it supports TCP as high performance you get one IP for each availability zone which",
    "start": "2649180",
    "end": "2655240"
  },
  {
    "text": "can be handy for whitelisting from a performance perspective when you launch a network load balancer you get roughly",
    "start": "2655240",
    "end": "2661240"
  },
  {
    "text": "five gigs of bandwidth just allocated to you and so on some of the older load",
    "start": "2661240",
    "end": "2666940"
  },
  {
    "text": "balancers like the classic load balancer you have to do things like pre-warming tell us you know like hey I'm about to",
    "start": "2666940",
    "end": "2672100"
  },
  {
    "text": "receive a lot of traffic can you give me some more capacity no workload bouncer is pretty much remove that in the way",
    "start": "2672100",
    "end": "2678760"
  },
  {
    "text": "that actually works is this little thing called hyperplane so we started talking about hyperplane last year at reinvent",
    "start": "2678760",
    "end": "2685530"
  },
  {
    "text": "it's a platform we've been using for some of our internal services well their",
    "start": "2685530",
    "end": "2691180"
  },
  {
    "text": "services that you actually use so hyperplane is essentially this horizontally scalable state management",
    "start": "2691180",
    "end": "2697330"
  },
  {
    "text": "fleet it has from a total capacity in the region and the range of terabytes of",
    "start": "2697330",
    "end": "2703420"
  },
  {
    "text": "bandwidth and it's currently supporting things like network load balancer EFS",
    "start": "2703420",
    "end": "2709090"
  },
  {
    "text": "mounts nat gateway private link and also now a transit gateway so we used may",
    "start": "2709090",
    "end": "2714580"
  },
  {
    "text": "have seen that released last night so the concept here is we've got this fleet as you add instances or attachments so",
    "start": "2714580",
    "end": "2723220"
  },
  {
    "text": "in this scenario you know a network load balancer into an availability zone or a",
    "start": "2723220",
    "end": "2728610"
  },
  {
    "text": "transit gateway attachment or an act gateway and that availability zone we basically give you with that network",
    "start": "2728610",
    "end": "2734920"
  },
  {
    "text": "interface this is also how you get one network interface for availability zone with that we give you shards of",
    "start": "2734920",
    "end": "2739990"
  },
  {
    "text": "bandwidth across that fleet and so with multiple customers we can distribute this load very fairly so that one no one",
    "start": "2739990",
    "end": "2747610"
  },
  {
    "text": "customer really overlaps with another so as you add more network interfaces and as we add more hosts and more tenants to",
    "start": "2747610",
    "end": "2754390"
  },
  {
    "text": "this we distribute all of that load requirements across the fleet so this makes sure that like if any given",
    "start": "2754390",
    "end": "2760120"
  },
  {
    "text": "instance fails that you don't have a bad day if any one of our customers wants to use a ton of bandwidth other people",
    "start": "2760120",
    "end": "2766870"
  },
  {
    "text": "don't have a bad day so this makes it very easy for us to scale horizontally and also keep latency low because in",
    "start": "2766870",
    "end": "2774520"
  },
  {
    "text": "this model we're about tens of microseconds of latency particularly for a network load balancer and so it's sort",
    "start": "2774520",
    "end": "2780970"
  },
  {
    "text": "of the underlying architecture that helps them understand like the performance when people ask me like you",
    "start": "2780970",
    "end": "2786310"
  },
  {
    "text": "know how does transit gateway perform like what bandwidth do I get through it or what's the latency or if I use",
    "start": "2786310",
    "end": "2791590"
  },
  {
    "text": "network load balance or what's the performance and a lot of it comes down to the same underlying concept and even",
    "start": "2791590",
    "end": "2798610"
  },
  {
    "text": "though the data plane is per availability zone and many times so like that gateway is only",
    "start": "2798610",
    "end": "2804280"
  },
  {
    "text": "one availabilities number like Network load balancer and transit gateway or regional concepts that sort of bring all those kind of concepts together to see",
    "start": "2804280",
    "end": "2812200"
  },
  {
    "text": "what this actually looks like for customers we did some tests last year on network load balancer and like well how well is this scale up like do we have",
    "start": "2812200",
    "end": "2819100"
  },
  {
    "text": "any limits or does this actually work the answer is yes luckily so we ran this",
    "start": "2819100",
    "end": "2825520"
  },
  {
    "text": "set with this test we have a tool called beast with the machine guns it basically sends out distributed sets of they call",
    "start": "2825520",
    "end": "2832630"
  },
  {
    "text": "bees that then do requests to your your server and you can just test tons of",
    "start": "2832630",
    "end": "2838630"
  },
  {
    "text": "bandwidth because if you can horizontally scale your application you can do lots of requests so we support we",
    "start": "2838630",
    "end": "2843820"
  },
  {
    "text": "did here looks like a million connections and we started scaling it up",
    "start": "2843820",
    "end": "2850060"
  },
  {
    "text": "I think that we started scaling around was about 1500 I don't know a lot all I",
    "start": "2850060",
    "end": "2857620"
  },
  {
    "text": "know is that we started around 8 gigs of bandwidth and scaled up to about 40 gigs bandwidth on the network load balancer",
    "start": "2857620",
    "end": "2863710"
  },
  {
    "text": "and we didn't have any sort of errors or timeouts or 500 or anything like that",
    "start": "2863710",
    "end": "2868900"
  },
  {
    "text": "through that process and then we decided to not stop wasting all the resources and just say 40 gigs is probably a lot",
    "start": "2868900",
    "end": "2876240"
  },
  {
    "text": "performance testing so ok so we've talked a little bit about you know some",
    "start": "2877680",
    "end": "2882820"
  },
  {
    "text": "of these concepts how do you actually test these things when it comes down to testing there's a lot of options so",
    "start": "2882820",
    "end": "2889120"
  },
  {
    "start": "2886000",
    "end": "2886000"
  },
  {
    "text": "there's there's a lot of different impacts so like can we get up here and tell you every number of every instance",
    "start": "2889120",
    "end": "2894610"
  },
  {
    "text": "and you know all the numbers and Mt use and all this theoretical stuff that you know there's a lot of inputs and outputs",
    "start": "2894610",
    "end": "2900220"
  },
  {
    "text": "to actually at the end of the day have one result to your application and so the answer is yes we could",
    "start": "2900220",
    "end": "2906850"
  },
  {
    "text": "and sometimes it's helpful but really really what you need to do is probably test it so like I said the amount of",
    "start": "2906850",
    "end": "2914290"
  },
  {
    "text": "flows you're using the location of those Layton sees the the type of application you're testing is a TCP or UDP as well",
    "start": "2914290",
    "end": "2920860"
  },
  {
    "text": "as like sometimes then you just have to test the network either first or last like if you think it's a network problem",
    "start": "2920860",
    "end": "2926200"
  },
  {
    "text": "you have to prove it's not if you've tested everything else and you're sure not sure what it is it might be a network problem and so knowing where",
    "start": "2926200",
    "end": "2933040"
  },
  {
    "text": "that's we're in that sort of performance testing scenario you're at is very important because doing all this testing and finding out",
    "start": "2933040",
    "end": "2939170"
  },
  {
    "text": "that oh hey we should just put some more pie ups on our EBS volume right you know",
    "start": "2939170",
    "end": "2944539"
  },
  {
    "text": "up creating bigger instance types and tweaking network settings may not help you there if you actually have a dis problem and so you this advice and this",
    "start": "2944539",
    "end": "2951200"
  },
  {
    "text": "a lot of this presentation quite honestly is it's helpful if you've already understood that the network is your bottleneck our network is the",
    "start": "2951200",
    "end": "2957079"
  },
  {
    "text": "problem so make sure you've actually gone and tested some of those other things you've got to look your cpu your memory your Numa configuration all bunch",
    "start": "2957079",
    "end": "2963739"
  },
  {
    "text": "of those types of other tweaks you can look at take improve performance without actually messing with the network if it",
    "start": "2963739",
    "end": "2968960"
  },
  {
    "text": "is the network then let's find that out there's a couple ways we can do that so you can do load testing like just how",
    "start": "2968960",
    "end": "2975289"
  },
  {
    "start": "2973000",
    "end": "2973000"
  },
  {
    "text": "much load cannot put on this thing at once or how many packets per second can I throw through this thing or how many transactions per second kind of do and",
    "start": "2975289",
    "end": "2981079"
  },
  {
    "text": "maybe if you know there's some like parts your application that work differently like one is a heavy load and one's a less load if you load it up on",
    "start": "2981079",
    "end": "2987140"
  },
  {
    "text": "the less load then you can find out what the actual limits are and so that's more of your application based testing you've",
    "start": "2987140",
    "end": "2993079"
  },
  {
    "text": "also got sort of the benchmark testing like just raw numbers like if I got this type of instance if I throw as much UDP",
    "start": "2993079",
    "end": "2999440"
  },
  {
    "text": "traffic as I can how much bandwidth or a packet per second do I get out of that and you can use that in combination with",
    "start": "2999440",
    "end": "3004779"
  },
  {
    "text": "your sort of environmental test to know whether the limits are at where you're gonna start running into problems you know if we get to this number we start",
    "start": "3004779",
    "end": "3011079"
  },
  {
    "text": "dropping packets so let's not do that amp in production and so maybe we need a larger instance type if we go to above",
    "start": "3011079",
    "end": "3016509"
  },
  {
    "text": "that number so on the tip side of things the first thing you can do is I like",
    "start": "3016509",
    "end": "3023589"
  },
  {
    "start": "3020000",
    "end": "3020000"
  },
  {
    "text": "testing with iperf it's my second favorite tool after ping so you can test",
    "start": "3023589",
    "end": "3029109"
  },
  {
    "text": "your latency you can test bandwidth I usually start with I use B capital P and do you know five or ten flows just to",
    "start": "3029109",
    "end": "3037150"
  },
  {
    "text": "see you know am i running any sort of flow limits you can do crazy things like test a hundred or a thousand of flows",
    "start": "3037150",
    "end": "3042849"
  },
  {
    "text": "just to see if that changes your performance characteristics sometimes I'll go in there I put the lowercase U",
    "start": "3042849",
    "end": "3048880"
  },
  {
    "text": "and therefore UDP that way I'll just throw as much bandwidth at it as I can and see what it can take even if you",
    "start": "3048880",
    "end": "3054999"
  },
  {
    "text": "know latency and other products are not really in the flow there we've got a link to the B's with machine gun stuff",
    "start": "3054999",
    "end": "3061150"
  },
  {
    "text": "if you want to play with that as well we've got some benchmark sort of articles on how to test this and we've",
    "start": "3061150",
    "end": "3068680"
  },
  {
    "text": "also recently published some operating system-level to tweaks what you can do on like Windows and Linux to make your network and your",
    "start": "3068680",
    "end": "3075700"
  },
  {
    "text": "operating system sort of play together what nicely so I mean the real summer here is TCP is a global concept",
    "start": "3075700",
    "end": "3081790"
  },
  {
    "start": "3079000",
    "end": "3079000"
  },
  {
    "text": "understand that the latency in some of the ways that those work with the system and especially your applications how",
    "start": "3081790",
    "end": "3087280"
  },
  {
    "text": "that might be interacting with your particular bottlenecks understand what we have you know use jumbo them to use",
    "start": "3087280",
    "end": "3093100"
  },
  {
    "text": "if you can you just use the latest instances make sure enhance networking is turned on know the right",
    "start": "3093100",
    "end": "3099160"
  },
  {
    "text": "architectures to know what the limits of the architecture are and you know try to scale out horizontally if you can cuz that tends to be how you get to very",
    "start": "3099160",
    "end": "3105340"
  },
  {
    "text": "high performance as well you know just test it out and be sort of very thorough about that if performance is really",
    "start": "3105340",
    "end": "3111310"
  },
  {
    "text": "important for your application so that's what we got thanks for coming we'll be",
    "start": "3111310",
    "end": "3116590"
  },
  {
    "text": "up here answering questions and and whatnot so thanks for coming [Applause]",
    "start": "3116590",
    "end": "3123349"
  }
]
[
  {
    "start": "0",
    "end": "110000"
  },
  {
    "text": "hi everybody my name is Nick really excited to be here today to tell you",
    "start": "50",
    "end": "5910"
  },
  {
    "text": "about the AWS database migration service before I get started with the slides I",
    "start": "5910",
    "end": "11820"
  },
  {
    "text": "want to give you a short background for context when I began my time with Amazon",
    "start": "11820",
    "end": "18000"
  },
  {
    "text": "actually started with the RDS service relational database service helped with initial launch helped with adding",
    "start": "18000",
    "end": "24330"
  },
  {
    "text": "features more features every time we added new features we would go and tell customers about it for example at the",
    "start": "24330",
    "end": "30750"
  },
  {
    "text": "reinvent conference customers were really excited about old features we were outing and they would ask questions",
    "start": "30750",
    "end": "37200"
  },
  {
    "text": "we would answer them we always had good answers except there was always one question they would ask that I wasn't",
    "start": "37200",
    "end": "43680"
  },
  {
    "text": "really satisfied with the answer they would ask ok I love these new features but how do I get my data in to RDS I",
    "start": "43680",
    "end": "50730"
  },
  {
    "text": "have a production application I have a lot of data I don't want it to go down how do I get it in and we would sort of",
    "start": "50730",
    "end": "58199"
  },
  {
    "text": "answer we would say well you can start fresh if you don't have any production",
    "start": "58199",
    "end": "63870"
  },
  {
    "text": "data to begin with you can start new projects and RDS really easily and you can even you know if you have an",
    "start": "63870",
    "end": "70560"
  },
  {
    "text": "application that can withstand a little bit of downtime you can shut it off real quick maybe at night move your data over",
    "start": "70560",
    "end": "76320"
  },
  {
    "text": "and then turn it back on again and if you really need to do it online and sort",
    "start": "76320",
    "end": "81509"
  },
  {
    "text": "of minimize your application downtime it's hard and we would sort of talk through all the complex steps to do it",
    "start": "81509",
    "end": "87150"
  },
  {
    "text": "manually and it's just I wasn't ever really satisfied with that answer because customers would walk away kind",
    "start": "87150",
    "end": "93540"
  },
  {
    "text": "of they weren't on satisfied they didn't really have a plan going home to fix the",
    "start": "93540",
    "end": "99119"
  },
  {
    "text": "problem so here I am today at today's summit giving you the answer that I like",
    "start": "99119",
    "end": "104610"
  },
  {
    "text": "we're actually going to talk about a service that makes this kind of migration and really easy so what you're",
    "start": "104610",
    "end": "112799"
  },
  {
    "start": "110000",
    "end": "270000"
  },
  {
    "text": "gonna hear about today is some of the challenges involved with migrating databases sort of what made the database",
    "start": "112799",
    "end": "120450"
  },
  {
    "text": "migrations service begin and I'll talk through how it works which includes a",
    "start": "120450",
    "end": "126030"
  },
  {
    "text": "demo talk a little bit about pricing and that sort of thing we'll get into the",
    "start": "126030",
    "end": "132030"
  },
  {
    "text": "schema conversion tool which is how related to the database migration service but a whole separate thing",
    "start": "132030",
    "end": "137599"
  },
  {
    "text": "including a demo for that and then we'll get into some Q&A so these days we're",
    "start": "137599",
    "end": "146760"
  },
  {
    "text": "hearing a lot of customers tell us they want to move their on-premise applications into the cloud but moving",
    "start": "146760",
    "end": "153209"
  },
  {
    "text": "applications is simpler than moving databases that they depend on applications are usually stateless and",
    "start": "153209",
    "end": "159510"
  },
  {
    "text": "can be moved fairly easily using a lift and shift approach now databases are",
    "start": "159510",
    "end": "165450"
  },
  {
    "text": "stateful and they require more care to move databases to AWS requires a data migration strategy when it comes to",
    "start": "165450",
    "end": "174989"
  },
  {
    "text": "designing these strategies customers want to be able to do it with the least possible inconvenience and visibility to",
    "start": "174989",
    "end": "181530"
  },
  {
    "text": "their customers once an application is migrated AWS it's not the end of the story often customers have several",
    "start": "181530",
    "end": "188599"
  },
  {
    "text": "applications some in the cloud some one premise someone hosted environments they need to be able to synchronize their",
    "start": "188599",
    "end": "194970"
  },
  {
    "text": "data between on-premise and cloud based applications at the same the same goes",
    "start": "194970",
    "end": "203819"
  },
  {
    "text": "for applications within AWS those applications often share data and customers want to be able to synchronize",
    "start": "203819",
    "end": "210479"
  },
  {
    "text": "and replicate data between various databases that they maintain within AWS",
    "start": "210479",
    "end": "215629"
  },
  {
    "text": "one of the thing customers moving applications to the cloud often see this as an opportunity to break free from the",
    "start": "215629",
    "end": "224699"
  },
  {
    "text": "commercial databases which tend to have heavy licensing burden we often hear our customers asking us if",
    "start": "224699",
    "end": "230729"
  },
  {
    "text": "there's a way to convert their commercial databases into AWS solutions such as already SMI sequel Postgres",
    "start": "230729",
    "end": "237180"
  },
  {
    "text": "Amazon Aurora and Amazon redshift so",
    "start": "237180",
    "end": "242269"
  },
  {
    "text": "these types of solutions have always been pretty expensive and time-consuming some commercial packages cost tens of",
    "start": "242269",
    "end": "250169"
  },
  {
    "text": "thousands of dollars they're challenging to configure and to keep working some",
    "start": "250169",
    "end": "257370"
  },
  {
    "text": "aspects of the migration won't transfer directly between engines compatibility",
    "start": "257370",
    "end": "263010"
  },
  {
    "text": "issues and depending on how much data needs to move application downtime may be significant",
    "start": "263010",
    "end": "269920"
  },
  {
    "text": "so that's where the Oedipus database migrations service came to be I'm going",
    "start": "269920",
    "end": "277300"
  },
  {
    "start": "270000",
    "end": "406000"
  },
  {
    "text": "to tell you a little bit mo how that works like all aw services it's easy to get and straightforward to get started",
    "start": "277300",
    "end": "283030"
  },
  {
    "text": "you can get started with your first migration tasks in 10 minutes or less you simply connect to your source and",
    "start": "283030",
    "end": "290230"
  },
  {
    "text": "target databases and their copies the data over begins to replicate the changes and the source to the target that means that you can keep your apps",
    "start": "290230",
    "end": "297070"
  },
  {
    "text": "running during the migration switchover when it's convenient for your business do you miss can be used to replicate",
    "start": "297070",
    "end": "303820"
  },
  {
    "text": "within to or from Amazon ec2 or already s databases basically from anywhere to",
    "start": "303820",
    "end": "311080"
  },
  {
    "text": "anywhere as long as one of them is an ADA boost resource again it's homogeneous there sorry heterogeneous so",
    "start": "311080",
    "end": "319450"
  },
  {
    "text": "that means that with DMS you can move data between engines supporting Oracle Microsoft sequel server my sequel",
    "start": "319450",
    "end": "326440"
  },
  {
    "text": "Postgres murray to be amazon aurora and was on redshift you know as RDS begins supporting more",
    "start": "326440",
    "end": "332770"
  },
  {
    "text": "databases will of course continue adding support for those as well if you'd like",
    "start": "332770",
    "end": "338200"
  },
  {
    "text": "to learn more there's a link here of course you can also listen to me I'll have more information too so using the",
    "start": "338200",
    "end": "346690"
  },
  {
    "text": "AWS database migration service to migrate data to AWS is simple you start",
    "start": "346690",
    "end": "352150"
  },
  {
    "text": "by spinning up a replication instance in your environment next from within DMS connect to both",
    "start": "352150",
    "end": "359200"
  },
  {
    "text": "your source and your target database endpoints then choose what data you want",
    "start": "359200",
    "end": "364360"
  },
  {
    "text": "to migrate DMS lets you migrate tables schemas the whole database then sit back",
    "start": "364360",
    "end": "370240"
  },
  {
    "text": "and let DMS do the rest it creates the tables loads the data best of all keeps them synchronized for",
    "start": "370240",
    "end": "377380"
  },
  {
    "text": "as long as you need that replication capability which keeps the source and",
    "start": "377380",
    "end": "382930"
  },
  {
    "text": "target data in sync it allows customers to switch applications over to point at",
    "start": "382930",
    "end": "388120"
  },
  {
    "text": "the AWS database at their leisure DMS eliminates the need for high-stakes",
    "start": "388120",
    "end": "393970"
  },
  {
    "text": "extended outages that might the sorry to migrate their production database into the cloud",
    "start": "393970",
    "end": "399009"
  },
  {
    "text": "DMS provides a graceful switchover capability and of course when you're done I'm going to delete your instance",
    "start": "399009",
    "end": "406469"
  },
  {
    "start": "406000",
    "end": "815000"
  },
  {
    "text": "so at this point I've told you a little bit about how it works I wanted to show",
    "start": "406469",
    "end": "412419"
  },
  {
    "text": "you a little demonstration of me using DMS to do a sample migration from one",
    "start": "412419",
    "end": "419349"
  },
  {
    "text": "Oracle database to another it's a video demo on the screen and I was going to",
    "start": "419349",
    "end": "424749"
  },
  {
    "text": "talk you through it so the first thing I did there is I went to the RDS section of the console where I'm going to show",
    "start": "424749",
    "end": "429939"
  },
  {
    "text": "you that I have two Oracle databases set up one of them is labeled source and one of them is labeled target pretend like",
    "start": "429939",
    "end": "437110"
  },
  {
    "text": "the source is your production database pretend like the target is a new RDS database that you've just set up to",
    "start": "437110",
    "end": "442960"
  },
  {
    "text": "migrate into here in sequel developer you can see that I've got them both connected and we're gonna look at the",
    "start": "442960",
    "end": "448689"
  },
  {
    "text": "source first you can see that it has an HR schema with a couple of tables in it I'm going to show you the content of one",
    "start": "448689",
    "end": "454930"
  },
  {
    "text": "of those tables it has on this source that has 4 rows regions not a very",
    "start": "454930",
    "end": "463509"
  },
  {
    "text": "interesting data table but the points to show you that is there and then here in the target you can see I'm scrolling down and the HR schema exists but there",
    "start": "463509",
    "end": "470800"
  },
  {
    "text": "are no tables and to show you that for sure we're going to go ahead and try to select from the region's table on the",
    "start": "470800",
    "end": "476559"
  },
  {
    "text": "target and see that the table does not exist so we want to solve this problem we want to put the data from the source",
    "start": "476559",
    "end": "482519"
  },
  {
    "text": "into the target to do that we're gonna go to the DMS section of the console and",
    "start": "482519",
    "end": "489539"
  },
  {
    "text": "you got to start with an instance you'll see I already created one this is the one we're gonna use but I also want to",
    "start": "489839",
    "end": "496659"
  },
  {
    "text": "show you how easy it is to create your own you can just click on create you give it a name give it a description you",
    "start": "496659",
    "end": "504959"
  },
  {
    "text": "can select some of the other options there but the defaults usually fine click on create takes about five minutes",
    "start": "504959",
    "end": "512078"
  },
  {
    "text": "to create varies a little bit in this case we're just going to delete it since we're going to use the one I already created sometimes you have to refresh",
    "start": "512079",
    "end": "523180"
  },
  {
    "text": "for the data to show",
    "start": "523180",
    "end": "526019"
  },
  {
    "text": "so the next step once you've got your replication instance I said that you have to connect to your endpoints so to",
    "start": "528600",
    "end": "535000"
  },
  {
    "text": "do that you have to start by defining your endpoints here this is really just duplicating metadata you've got",
    "start": "535000",
    "end": "540540"
  },
  {
    "text": "information about your databases that you know you know what type of database it is you know what the end point the",
    "start": "540540",
    "end": "545920"
  },
  {
    "text": "server name is you know the port use your name password you're just plugging in all this data in here you can see me",
    "start": "545920",
    "end": "551380"
  },
  {
    "text": "copy pasting some of it this series of",
    "start": "551380",
    "end": "558460"
  },
  {
    "text": "steps is by no means creating a database what you're doing here is you're sort of",
    "start": "558460",
    "end": "563710"
  },
  {
    "text": "instructing DMS how to access your database in some cases it might be an RDS database it might be one an ASA two",
    "start": "563710",
    "end": "569410"
  },
  {
    "text": "it might be one in your own promise environment and you'll need to test the",
    "start": "569410",
    "end": "574480"
  },
  {
    "text": "connectivity there what's what's happening here is that the replication instance is reaching out over that VPC",
    "start": "574480",
    "end": "579940"
  },
  {
    "text": "network to that database configuration and confirming that it's actually able",
    "start": "579940",
    "end": "585220"
  },
  {
    "text": "to connect using that endpoint name using the username and password you can see that this one was successful so",
    "start": "585220",
    "end": "592200"
  },
  {
    "text": "we're gonna go ahead and do the exact same thing for the target I probably",
    "start": "592200",
    "end": "603310"
  },
  {
    "text": "could have pre created one of these endpoints so you only have to sit",
    "start": "603310",
    "end": "608440"
  },
  {
    "text": "through one of them but the important thing about the target is the in the source the this scheme I when I migrate",
    "start": "608440",
    "end": "614950"
  },
  {
    "text": "is called HR and if I just use the standard master username for the second",
    "start": "614950",
    "end": "622390"
  },
  {
    "text": "source instance it would have gone into that schema and I really wanted to use the HR schema as you can see here that",
    "start": "622390",
    "end": "627760"
  },
  {
    "text": "I'm typing in the HR username and the HR password which is going to mean that the migration will put it into the HR schema",
    "start": "627760",
    "end": "635700"
  },
  {
    "text": "so once this connectivity is verified",
    "start": "636630",
    "end": "641860"
  },
  {
    "text": "the next thing we're going to do is actually create the task the task is what defines the the actual migration",
    "start": "641860",
    "end": "651130"
  },
  {
    "text": "what you want to move from where to where so you'll see here when we click",
    "start": "651130",
    "end": "657430"
  },
  {
    "text": "on who actually here check this out you can see that the HR scheme and the other scheme is on that sewer stretch listed",
    "start": "657430",
    "end": "663690"
  },
  {
    "text": "there too that's important because when you configure the task you need to specify which scheme or schemas you want",
    "start": "663690",
    "end": "668760"
  },
  {
    "text": "to use and so part of creating the endpoint involves pulling down and which schemas are available also so here",
    "start": "668760",
    "end": "675450"
  },
  {
    "text": "you'll see we're actually going through in creating the tasks there's a lot of defaults on there because I only have one source only one target and only one",
    "start": "675450",
    "end": "682529"
  },
  {
    "text": "instance so it's just picked those for me if you had more than one you'd have to pick and I did select that I wanted",
    "start": "682529",
    "end": "689370"
  },
  {
    "text": "to do ongoing replication and enable logging ongoing replication is really",
    "start": "689370",
    "end": "696630"
  },
  {
    "text": "important because you know I talked a little bit about how I you want to do the full load of your data and then be",
    "start": "696630",
    "end": "703710"
  },
  {
    "text": "able to change your application to point at the target when it's convenient for your business in in the absence of",
    "start": "703710",
    "end": "710610"
  },
  {
    "text": "ongoing replication you would really only have what your database looked like you know several hours or days or weeks",
    "start": "710610",
    "end": "716370"
  },
  {
    "text": "ago with ongoing replication it's actually going to be taking the transaction logs that are occurring on",
    "start": "716370",
    "end": "724410"
  },
  {
    "text": "that source during the full load and it's going to be applying them after the full load onto the target so this",
    "start": "724410",
    "end": "732120"
  },
  {
    "text": "process of creating and starting the replication task it kind of looks like",
    "start": "732120",
    "end": "740370"
  },
  {
    "text": "it's a while but once it actually gets going it's going to be reaching out to",
    "start": "740370",
    "end": "745430"
  },
  {
    "text": "the Oracle database source pulling out all the data as quickly as the database",
    "start": "745430",
    "end": "751410"
  },
  {
    "text": "connection lets it and for this particular migration this can be a quick one so you'll see that it'll move from",
    "start": "751410",
    "end": "756990"
  },
  {
    "text": "running to loading complete pretty quickly once that happens I'll give you",
    "start": "756990",
    "end": "764190"
  },
  {
    "text": "a little preview of what I'm going to do on the next screen I'm going to go back to Oracle sequel developer and show the",
    "start": "764190",
    "end": "769680"
  },
  {
    "text": "in addition to the source still having that table that we looked at with all the data in it the targets going to have",
    "start": "769680",
    "end": "775589"
  },
  {
    "text": "it too and I'm even gonna try putting some data into the source and showing the once",
    "start": "775589",
    "end": "784050"
  },
  {
    "text": "committed that'll show up in the in the target as well",
    "start": "784050",
    "end": "789930"
  },
  {
    "text": "allowing you to switch over at your leisure so here we go it looks like it",
    "start": "789930",
    "end": "796779"
  },
  {
    "text": "finished we're gonna look at the stats you'll see here it shows how many rows in each table got migrated for each of",
    "start": "796779",
    "end": "803230"
  },
  {
    "text": "those tables there's information and those are updated as you go so if you",
    "start": "803230",
    "end": "808870"
  },
  {
    "text": "had a very large migration you could look at it sort of every hour every day throughout the migration and see the",
    "start": "808870",
    "end": "814959"
  },
  {
    "text": "progress this here is more detailed logs which are enabled by the enable logging button that I clicked at the beginning",
    "start": "814959",
    "end": "822540"
  },
  {
    "start": "815000",
    "end": "940000"
  },
  {
    "text": "it's always good to enable logs because you can see if there's are any errors that occur that kind of thing here just",
    "start": "822540",
    "end": "828430"
  },
  {
    "text": "to refresh your memory I'm showing you what's there on the source we're going",
    "start": "828430",
    "end": "833529"
  },
  {
    "text": "to show again on the target now it actually is there when you run that selector there we're going to switch",
    "start": "833529",
    "end": "838779"
  },
  {
    "text": "back to the source now and we're gonna insert a new row we're gonna insert the",
    "start": "838779",
    "end": "844720"
  },
  {
    "text": "Chicago row so when we select you'll see that instead of four entries there's going to be five regions now it won't",
    "start": "844720",
    "end": "854649"
  },
  {
    "text": "yet be on the target because it's transactional inconsistent it's not going to you know push the data to the",
    "start": "854649",
    "end": "861339"
  },
  {
    "text": "target until after it's committed so when you go back and you finally commit that transaction on the source it does",
    "start": "861339",
    "end": "869639"
  },
  {
    "text": "replicate and you can see it'll be there on the target now and of course the same thing is true when when you're deleting",
    "start": "869639",
    "end": "876689"
  },
  {
    "text": "any transaction this current we're sort of we're pretending to be the application right now using the source",
    "start": "876689",
    "end": "882100"
  },
  {
    "text": "database while the migration is still in progress you'll see that I'm deleting it",
    "start": "882100",
    "end": "887589"
  },
  {
    "text": "of course removed it from the target as well so you can actually go back to DMS",
    "start": "887589",
    "end": "895120"
  },
  {
    "text": "now you can see on the tasks stats when you refresh it that the amount of sort",
    "start": "895120",
    "end": "904329"
  },
  {
    "text": "of post bulk load transactions are actually shown as part of those statistics some cases you have to",
    "start": "904329",
    "end": "911500"
  },
  {
    "text": "refresh because it's not immediately consistent it's sort of a little bit of an asynchronous process but you'll see",
    "start": "911500",
    "end": "917980"
  },
  {
    "text": "when i refresh it there will be an entry under the delete column as well to show that one row was in sir",
    "start": "917980",
    "end": "923710"
  },
  {
    "text": "and one row was deleted in that regions table and this is of course a simple",
    "start": "923710",
    "end": "929470"
  },
  {
    "text": "demo if you had a real production application in your database it would be a lot more going on and it would be able",
    "start": "929470",
    "end": "936100"
  },
  {
    "text": "to make you comfortable that all the all",
    "start": "936100",
    "end": "941740"
  },
  {
    "start": "940000",
    "end": "1140000"
  },
  {
    "text": "the data was being replicated from your source to your target and ready for the switchover now at that point once the",
    "start": "941740",
    "end": "948880"
  },
  {
    "text": "switchover started once the data is all replicated you would need to do a couple",
    "start": "948880",
    "end": "956110"
  },
  {
    "text": "steps to actually switch your application over it would involve briefly stopping the application or",
    "start": "956110",
    "end": "962260"
  },
  {
    "text": "putting in sort of a read-only or a sort of a maintenance mode where it's not manipulating the database and then you",
    "start": "962260",
    "end": "969279"
  },
  {
    "text": "would sort of decommission or disable the source database and then bring up",
    "start": "969279",
    "end": "975070"
  },
  {
    "text": "the application pointing at the target again and your customers would be able to use it within seconds or minutes",
    "start": "975070",
    "end": "980470"
  },
  {
    "text": "rather than you know weeks or months the data transfers can sometimes take so",
    "start": "980470",
    "end": "988089"
  },
  {
    "text": "this demo included a single source schema - a single target schema but it's",
    "start": "988089",
    "end": "993400"
  },
  {
    "text": "worth noting that you can do a one-to-many if for example you had a pretty heavily",
    "start": "993400",
    "end": "1000300"
  },
  {
    "text": "loaded source database that was doing a lot of different things for your business and over time you realized that it was a little bit more heavily loaded",
    "start": "1000300",
    "end": "1008190"
  },
  {
    "text": "than you want it to be as part of this migration you can take individual schemas your databases or tables or whatnot and move them into different",
    "start": "1008190",
    "end": "1014550"
  },
  {
    "text": "targets the opposite is true - you can take multiple sources and combine them",
    "start": "1014550",
    "end": "1021360"
  },
  {
    "text": "into the same target for example a lot of customers have been creating multiple",
    "start": "1021360",
    "end": "1026579"
  },
  {
    "text": "my sequel databases because there are some limitations on how much storage can",
    "start": "1026579",
    "end": "1032520"
  },
  {
    "text": "be included in a single RDS my sequel database but then when they're ready to migrate into Aurora",
    "start": "1032520",
    "end": "1038790"
  },
  {
    "text": "you'll have a much larger storage limitation there which allows you to",
    "start": "1038790",
    "end": "1044040"
  },
  {
    "text": "save a lot of money here if you're going to be migrating some my sequel databases that that are sort of less heavily",
    "start": "1044040",
    "end": "1052950"
  },
  {
    "text": "loaded on the transaction perspective you can load them into a single or database to consist in all of that",
    "start": "1052950",
    "end": "1058919"
  },
  {
    "text": "load from all those applications the other thing is that you don't have to take everything for some regulations you",
    "start": "1058919",
    "end": "1065850"
  },
  {
    "text": "will want at all but in others you'll want a subset or even just a",
    "start": "1065850",
    "end": "1071279"
  },
  {
    "text": "portion of some of the tables like like in this case you can you can even do some filtering rules too to limit like",
    "start": "1071279",
    "end": "1077909"
  },
  {
    "text": "which portion of the table you're going to take there might even be cases where there are tables you don't want at all",
    "start": "1077909",
    "end": "1083039"
  },
  {
    "text": "they can be easily excluded on the task it went through a little bit quickly",
    "start": "1083039",
    "end": "1088049"
  },
  {
    "text": "when we were looking at the demo but if you look at the task details there's a",
    "start": "1088049",
    "end": "1093059"
  },
  {
    "text": "section where you set up migration settings and there's some JSON that sort of describes which schemas which tables",
    "start": "1093059",
    "end": "1100049"
  },
  {
    "text": "are included or excluded and we did a really simple setting on that demo which",
    "start": "1100049",
    "end": "1105119"
  },
  {
    "text": "was the HR schema all tables but you can do any configuration to pull just what",
    "start": "1105119",
    "end": "1112740"
  },
  {
    "text": "you want out so again this demo was a",
    "start": "1112740",
    "end": "1118980"
  },
  {
    "text": "homogenous demo I showed Oracle to Oracle that's the simplest understand migration and is of course supported now",
    "start": "1118980",
    "end": "1127820"
  },
  {
    "text": "replications can also be heterogeneous from one database engine to another",
    "start": "1127820",
    "end": "1134490"
  },
  {
    "text": "we'll get into a little bit more detail on how that works later on so with the",
    "start": "1134490",
    "end": "1143730"
  },
  {
    "start": "1140000",
    "end": "1257000"
  },
  {
    "text": "AWS database migration service you pay for the migration instance that moves your data from your source database to",
    "start": "1143730",
    "end": "1150539"
  },
  {
    "text": "your target database that's the thing that we created the very beginning of the demo it it runs on ec2 it requires",
    "start": "1150539",
    "end": "1158519"
  },
  {
    "text": "some compute resource that's the cost that you're paying for on an hourly basis the endpoint metadata to describe",
    "start": "1158519",
    "end": "1164850"
  },
  {
    "text": "your database does not on carry an additional cost but of course the midbass itself if it's running in RDS",
    "start": "1164850",
    "end": "1172139"
  },
  {
    "text": "theresa - that would be of course it's its own cost the AWS database migration",
    "start": "1172139",
    "end": "1180059"
  },
  {
    "text": "service currently supports the t2 and the see for instance classes t2 instances are a low cost standard",
    "start": "1180059",
    "end": "1187500"
  },
  {
    "text": "instance designed to provide a baseline level of CPU before once with the ability to burst above the",
    "start": "1187500",
    "end": "1193710"
  },
  {
    "text": "baseline they're suitable for developing configuring testing your database migration process and for periodic data",
    "start": "1193710",
    "end": "1201690"
  },
  {
    "text": "and migration tasks that can benefit from the CPU burst capacity now the c4 are designed for delivering the highest",
    "start": "1201690",
    "end": "1208830"
  },
  {
    "text": "level of processor performance they achieve significantly higher packet per second performance lower network jitter",
    "start": "1208830",
    "end": "1215549"
  },
  {
    "text": "lower network latency you should use c4 instances for migrating large databases when you're looking to minimize the",
    "start": "1215549",
    "end": "1222419"
  },
  {
    "text": "migration time each database migration instance comes included with some",
    "start": "1222419",
    "end": "1227639"
  },
  {
    "text": "storage that's sufficient to migrate for the migration needs of the engine swap space logs etc this is attached to the",
    "start": "1227639",
    "end": "1236909"
  },
  {
    "text": "instance and and used to store that data now data transfer inbound is free and",
    "start": "1236909",
    "end": "1245279"
  },
  {
    "text": "you only pay additional charges if you're going to allocate additional storage for the migration logs or if",
    "start": "1245279",
    "end": "1252600"
  },
  {
    "text": "you're gonna be replicating to a database that's in another region or on-premise so resources that are",
    "start": "1252600",
    "end": "1262080"
  },
  {
    "start": "1257000",
    "end": "1347000"
  },
  {
    "text": "available to you as a customer if you go to the AWS console and you click on DMS",
    "start": "1262080",
    "end": "1267119"
  },
  {
    "text": "there's some section on the right there that has things like getting started information documentation can read in",
    "start": "1267119",
    "end": "1273359"
  },
  {
    "text": "more detail about it there's also an overview of some of the highlights of the features if you want to go back and",
    "start": "1273359",
    "end": "1278730"
  },
  {
    "text": "look at some of the things I'm talking about get a little bit more detail on them it's available their pricing um you",
    "start": "1278730",
    "end": "1284070"
  },
  {
    "text": "know I showed you a previous slide that has the current pricing it was only us East one it was only as of now it's of",
    "start": "1284070",
    "end": "1289529"
  },
  {
    "text": "course gonna change and if you're using a different region you want to get the details there um there's a forum for DMS",
    "start": "1289529",
    "end": "1296489"
  },
  {
    "text": "you can go in there and you can ask questions if you if you get started you're not sure what to do next you have",
    "start": "1296489",
    "end": "1302039"
  },
  {
    "text": "a question about it you can post there and members of of my team at AWS are",
    "start": "1302039",
    "end": "1307409"
  },
  {
    "text": "going to take a look and see if we can answer there's also a Java SDK if if you",
    "start": "1307409",
    "end": "1314700"
  },
  {
    "text": "want to sort of automate some of these tasks and you want to set up multiple migrations you don't want to use the",
    "start": "1314700",
    "end": "1319739"
  },
  {
    "text": "console you'd rather set up a java application that calls these api's for you I can download that SDK and then",
    "start": "1319739",
    "end": "1326760"
  },
  {
    "text": "of course there's also a command-line interface if you'd rather do it using that sort of technique so you might",
    "start": "1326760",
    "end": "1335460"
  },
  {
    "text": "recognize this slide I showed it already and we've talked through everything on it except for the last little bit which",
    "start": "1335460",
    "end": "1341130"
  },
  {
    "text": "is moving off of those expensive commercial databases it's a pretty important aspect for a lot of customers",
    "start": "1341130",
    "end": "1346140"
  },
  {
    "text": "that's really where the schema conversion tool comes in the schema",
    "start": "1346140",
    "end": "1352020"
  },
  {
    "start": "1347000",
    "end": "1409000"
  },
  {
    "text": "conversion tool helps automate many database schema and code conversion",
    "start": "1352020",
    "end": "1357030"
  },
  {
    "text": "tasks when migrating from Oracle and sequel server to open source database engines just read that but it's really",
    "start": "1357030",
    "end": "1363120"
  },
  {
    "text": "important if you don't know which engine",
    "start": "1363120",
    "end": "1370710"
  },
  {
    "text": "to migrate to it provides an assessment report to help you choose and it'll even",
    "start": "1370710",
    "end": "1376350"
  },
  {
    "text": "identify places where it needs a little bit of additional assistance from you to be successful there's some cases where a",
    "start": "1376350",
    "end": "1382500"
  },
  {
    "text": "feature on your source database may not be fully supported by the target",
    "start": "1382500",
    "end": "1387630"
  },
  {
    "text": "database that you've chosen and it'll sometimes give sort of a suggestion for",
    "start": "1387630",
    "end": "1392820"
  },
  {
    "text": "what it recommends you do and in some cases it will be an automatic solution other cases it'll require your direct",
    "start": "1392820",
    "end": "1400080"
  },
  {
    "text": "input to provide a choice and in the course of all this over time it'll be",
    "start": "1400080",
    "end": "1405540"
  },
  {
    "text": "doing a better job as time goes on so",
    "start": "1405540",
    "end": "1411050"
  },
  {
    "text": "this chart gives you a little overview as to which engines can be the source",
    "start": "1413030",
    "end": "1418470"
  },
  {
    "text": "and which can be the target I'm not gonna read through in detail but the overall view is sort of described by the",
    "start": "1418470",
    "end": "1423870"
  },
  {
    "text": "picture it helps to migrate from the expensive in enterprise engines to the",
    "start": "1423870",
    "end": "1430380"
  },
  {
    "text": "open source and Amazon provided engines so it basically allows you to take the",
    "start": "1430380",
    "end": "1436650"
  },
  {
    "text": "schemas tables indexes and views move them from the original into the new",
    "start": "1436650",
    "end": "1441660"
  },
  {
    "text": "engine same thing for packages of stored procedures functions and triggers these things all need a little bit of",
    "start": "1441660",
    "end": "1447420"
  },
  {
    "text": "manipulation and change in order to be compatible with your target engine same thing with sequences you define types",
    "start": "1447420",
    "end": "1453240"
  },
  {
    "text": "and synonyms the UI for it is almost impossible to",
    "start": "1453240",
    "end": "1459850"
  },
  {
    "text": "see in this screen and that's why I'm going to show you a little demo of how it's used to do a sample migration so in",
    "start": "1459850",
    "end": "1469870"
  },
  {
    "text": "this demo we're also going to start with the RDS section of the console",
    "start": "1469870",
    "end": "1475000"
  },
  {
    "text": "we're gonna go to the instances page and you'll see again the exact same list of instances but we're gonna use the oracle",
    "start": "1475000",
    "end": "1480910"
  },
  {
    "text": "source same one as we migrated from before but we're gonna use the Postgres one instead as the target and in each of",
    "start": "1480910",
    "end": "1489460"
  },
  {
    "text": "these cases I've just created RDS databases because it's the easiest for me to demonstrate but of course remember that your sources may be on premise or",
    "start": "1489460",
    "end": "1497170"
  },
  {
    "text": "other configurations here I'm just sort of showing that the the region table",
    "start": "1497170",
    "end": "1503470"
  },
  {
    "text": "still has the same data in it from the source Oracle instance and here's the PG",
    "start": "1503470",
    "end": "1508570"
  },
  {
    "text": "admin tool which shows the Postgres database that we're planning to migrate into to show here that the Postgres",
    "start": "1508570",
    "end": "1514990"
  },
  {
    "text": "database does not have the HR schema that's where we'd like to put it so to",
    "start": "1514990",
    "end": "1521410"
  },
  {
    "text": "do that we're gonna open up the AWS schema conversion tool and there's a",
    "start": "1521410",
    "end": "1527650"
  },
  {
    "text": "little getting started wizard here where you just sort of name your project you select information about your source",
    "start": "1527650",
    "end": "1534580"
  },
  {
    "text": "database so I've already run this once before recording a demo it's just got all the Oracle source information in",
    "start": "1534580",
    "end": "1540550"
  },
  {
    "text": "there we're gonna type in that password and what it does is it first gets the schemas you can see the HR schema the",
    "start": "1540550",
    "end": "1551770"
  },
  {
    "text": "one that we migrated before is on that list so we'll do the same thing here we're going to select HR and the next",
    "start": "1551770",
    "end": "1557170"
  },
  {
    "text": "thing it's gonna do here is build an assessment report it sort of shows you",
    "start": "1557170",
    "end": "1562950"
  },
  {
    "text": "what you're gonna have to do so for Amazon Aurora there's assessment number one it shows",
    "start": "1562950",
    "end": "1569230"
  },
  {
    "text": "you sort of which things you're going to need attention and then for Postgres there's another assessment different",
    "start": "1569230",
    "end": "1574690"
  },
  {
    "text": "things they have different levels of compatibility with the Oracle engine so in this demo I'll be using the Postgres",
    "start": "1574690",
    "end": "1581290"
  },
  {
    "text": "one which means that in this schema conversion tool when it asked me about the target I selected this can be",
    "start": "1581290",
    "end": "1588280"
  },
  {
    "text": "Postgres type in that information about my RTS post gross incidents and we say okay",
    "start": "1588280",
    "end": "1597600"
  },
  {
    "start": "1598000",
    "end": "1680000"
  },
  {
    "text": "excuse me so this UI basically has your source",
    "start": "1598919",
    "end": "1605019"
  },
  {
    "text": "information on the left you can see the HR schema is there its other schemas",
    "start": "1605019",
    "end": "1610269"
  },
  {
    "text": "from the Oracle database the the right hand side will eventually be the",
    "start": "1610269",
    "end": "1616690"
  },
  {
    "text": "post-grad side but to begin with I'm going to load up the assessment view",
    "start": "1616690",
    "end": "1621940"
  },
  {
    "text": "where it sort of shows me the things that it found that aren't fully compatible between this Oracle schema",
    "start": "1621940",
    "end": "1629590"
  },
  {
    "text": "and Postgres for example it has a read-only view and Oracle supports we",
    "start": "1629590",
    "end": "1634750"
  },
  {
    "text": "don't leave use but Postgres does not so it's drawing attention to that and to get more details about what it's going",
    "start": "1634750",
    "end": "1640210"
  },
  {
    "text": "to do about that I'm gonna actually do a conversion of the of the schema into this Postgres database not the data just",
    "start": "1640210",
    "end": "1647529"
  },
  {
    "text": "the schema and when we go back and look at the same information it's actually going to show me what it created on the",
    "start": "1647529",
    "end": "1653710"
  },
  {
    "text": "Postgres side it created the exact same view format it a little bit differently but it just excluded the with read-only",
    "start": "1653710",
    "end": "1659200"
  },
  {
    "text": "so it becomes our responsibility to decide if that's acceptable for our application is it okay to use a non",
    "start": "1659200",
    "end": "1665799"
  },
  {
    "text": "read-only view since Postgres doesn't support that here's another one where",
    "start": "1665799",
    "end": "1671529"
  },
  {
    "text": "it's got a two char command it says that you know the arguments are processed a little bit differently and it's drawing",
    "start": "1671529",
    "end": "1677049"
  },
  {
    "text": "our attention to that so that we can confirm it's acceptable for our means we'll just pretend like we went through",
    "start": "1677049",
    "end": "1682240"
  },
  {
    "start": "1680000",
    "end": "1925000"
  },
  {
    "text": "each and every one of those and we confirm that every one of them was acceptable to us it's a little bit it's the time consuming part of it and not",
    "start": "1682240",
    "end": "1688299"
  },
  {
    "text": "super relevant for this demo it'll be more relevant when you get your database up in there here we are now creating",
    "start": "1688299",
    "end": "1696279"
  },
  {
    "text": "this this postcard endpoint that we're going to use for the for the Postgres",
    "start": "1696279",
    "end": "1702190"
  },
  {
    "text": "import this one I almost certainly should have had included beforehand",
    "start": "1702190",
    "end": "1707200"
  },
  {
    "text": "because there's not a lot of interesting going on here other than realizing that it's the Postgres one this time I'm",
    "start": "1707200",
    "end": "1716860"
  },
  {
    "text": "going to be using the the master user name from the RDS instance the master password there's no",
    "start": "1716860",
    "end": "1724230"
  },
  {
    "text": "need to use another user in this case as there was for the Oracle one once it",
    "start": "1724230",
    "end": "1732830"
  },
  {
    "text": "once we actually create this endpoint the next thing we're going to do is get",
    "start": "1732830",
    "end": "1738149"
  },
  {
    "text": "into the the tasks screen again we're going to create another task and and",
    "start": "1738149",
    "end": "1745799"
  },
  {
    "text": "that task is going to be from the oracle source to the Postgres target this is",
    "start": "1745799",
    "end": "1750960"
  },
  {
    "text": "the first time we're going to be doing one where the engines of the source and target don't match you can see that it",
    "start": "1750960",
    "end": "1759090"
  },
  {
    "text": "auto selected the instance and the source again because I only have one of each but we have to actually pick which",
    "start": "1759090",
    "end": "1764840"
  },
  {
    "text": "target now since we have two and we're gonna leave as a standard migration",
    "start": "1764840",
    "end": "1771720"
  },
  {
    "text": "without changes just because it makes a little bit simpler I always enable logging just because if",
    "start": "1771720",
    "end": "1780090"
  },
  {
    "text": "something goes wrong or if you want more details you can't really add logging after the fact so just as a general",
    "start": "1780090",
    "end": "1787049"
  },
  {
    "text": "practice I always click that button in this demo I actually didn't show the",
    "start": "1787049",
    "end": "1793799"
  },
  {
    "text": "logs for the Postgres migration they are really similar to what you'll see from the Oracle to Oracle it just sort of",
    "start": "1793799",
    "end": "1798989"
  },
  {
    "text": "lists out how many rows from each table got migrated so at this point you have",
    "start": "1798989",
    "end": "1808309"
  },
  {
    "text": "schema pre-created on the Postgres instance that is the",
    "start": "1808309",
    "end": "1813509"
  },
  {
    "text": "schema conversion tools best guess what we want out of the Oracle one and and",
    "start": "1813509",
    "end": "1820919"
  },
  {
    "text": "then the second stage is this task which is going to be loading the data so a",
    "start": "1820919",
    "end": "1826019"
  },
  {
    "text": "first game I then data and optionally continuous replication after that this",
    "start": "1826019",
    "end": "1835379"
  },
  {
    "text": "one unfortunately took about a minute to create and I did not have a video editor handy to shorten it so apologies for",
    "start": "1835379",
    "end": "1842970"
  },
  {
    "text": "that once it finally does finish",
    "start": "1842970",
    "end": "1849899"
  },
  {
    "text": "creating and running what you'll see next is we're gonna go to the PG admin and we're",
    "start": "1849899",
    "end": "1856690"
  },
  {
    "text": "gonna refresh this schema you'll see in there that the HR schema does appear",
    "start": "1856690",
    "end": "1861940"
  },
  {
    "text": "there is data in it and I we were successful in getting the data and now",
    "start": "1861940",
    "end": "1867730"
  },
  {
    "text": "for a heterogeneous migration you might have a little bit more verification to do than just like a single table this",
    "start": "1867730",
    "end": "1874240"
  },
  {
    "text": "demo I'm just going to show you the contents of one table to prove that it happened but if you're trying to verify",
    "start": "1874240",
    "end": "1880450"
  },
  {
    "text": "that your application is compatible with the new engine you'll probably have a little bit more testing to do well you",
    "start": "1880450",
    "end": "1886330"
  },
  {
    "text": "have maybe a test version of your application you're going to point at sort of a test migration version running",
    "start": "1886330",
    "end": "1891940"
  },
  {
    "text": "on the new engine make sure that all the aspects of your application are still working properly so don't treat this",
    "start": "1891940",
    "end": "1900220"
  },
  {
    "text": "verification as sort of the be-all end-all all I'm doing is as you can see here I'm gonna refresh the schemas I'm",
    "start": "1900220",
    "end": "1906730"
  },
  {
    "text": "gonna see the HR is there I'm gonna go down to the tables I'm gonna select the",
    "start": "1906730",
    "end": "1911850"
  },
  {
    "text": "region one and you'll see when I click on the magic button of data the same",
    "start": "1911850",
    "end": "1918220"
  },
  {
    "text": "four regions are still there so what you've seen now is one demo where we did",
    "start": "1918220",
    "end": "1923890"
  },
  {
    "text": "a homogeneous import from Oracle to Oracle with a continuous change history",
    "start": "1923890",
    "end": "1931420"
  },
  {
    "start": "1925000",
    "end": "2219000"
  },
  {
    "text": "after the fact and then we did another one where it was from Oracle to Postgres with utilizing",
    "start": "1931420",
    "end": "1939280"
  },
  {
    "text": "the schema conversion tool to prepare the scheme ahead of time so pricing I a",
    "start": "1939280",
    "end": "1947950"
  },
  {
    "text": "whole slide earlier for the pricing details of the migration service this one's a little bit simpler you pay",
    "start": "1947950",
    "end": "1956170"
  },
  {
    "text": "nothing for the software license you do run it locally so you have to download the software installed on your local",
    "start": "1956170",
    "end": "1961809"
  },
  {
    "text": "workstation so in that way I guess you're paying for your local workstation but there's no software license of",
    "start": "1961809",
    "end": "1967720"
  },
  {
    "text": "course subject to some terms and conditions that you should of course fully review before using the service so",
    "start": "1967720",
    "end": "1975070"
  },
  {
    "text": "the application basically it's for use by aid abuse customers that are in good",
    "start": "1975070",
    "end": "1980290"
  },
  {
    "text": "standing to migrate their databases into AWS or out if",
    "start": "1980290",
    "end": "1985690"
  },
  {
    "text": "so choose so we've got a couple of big customers already using this I mean some",
    "start": "1985690",
    "end": "1991210"
  },
  {
    "text": "some of you might be thinking is this is this appropriate for my business you know my business is pretty big we've got",
    "start": "1991210",
    "end": "1996850"
  },
  {
    "text": "some important things going on who else has used this Expedia who a lot of us have have heard of I assume is",
    "start": "1996850",
    "end": "2003450"
  },
  {
    "text": "doing a migration of a bunch of their databases into Amazon Aurora and we've",
    "start": "2003450",
    "end": "2008879"
  },
  {
    "text": "got a quote here from a principal engineer there who says that the ease by which we do this using the AWS database",
    "start": "2008879",
    "end": "2016919"
  },
  {
    "text": "migration services simplify this process for us and enabled us to accelerate our migration efforts the ability to closely",
    "start": "2016919",
    "end": "2024389"
  },
  {
    "text": "monitor the process the detailed logging feature and the support we received from AWS have given us a great deal of",
    "start": "2024389",
    "end": "2031049"
  },
  {
    "text": "confidence in a successful migration now I showed you a bunch of these features as you went through you can you can feel",
    "start": "2031049",
    "end": "2039960"
  },
  {
    "text": "free to try it using your own your own data as well we also have Thomas",
    "start": "2039960",
    "end": "2046230"
  },
  {
    "text": "publishing another big company who needed to grow their database footprint using Oracle but but in that case you",
    "start": "2046230",
    "end": "2053310"
  },
  {
    "text": "can see it would have required a significant upfront investment in both infrastructure and licensing expense",
    "start": "2053310",
    "end": "2058618"
  },
  {
    "text": "they really wanted to move their databases to Amazon Arora before doing that scaling and the database migration",
    "start": "2058619",
    "end": "2065460"
  },
  {
    "text": "service automated most of that work it dramatically reduced the manual effort required for that code migration their",
    "start": "2065460",
    "end": "2073108"
  },
  {
    "text": "chief technology officer basically said that the AWS database migration service will be a key enabler for our plans to",
    "start": "2073109",
    "end": "2079378"
  },
  {
    "text": "migrate more databases to Amazon Aurora and 2016 they've done some already they're doing more they've liked it",
    "start": "2079379",
    "end": "2086158"
  },
  {
    "text": "they've liked it so much then we keep doing more I hope you guys like it too so if you're looking for more resources",
    "start": "2086159",
    "end": "2092878"
  },
  {
    "text": "you know how can I learn more if you go to the DMS section of the console same",
    "start": "2092879",
    "end": "2098460"
  },
  {
    "text": "places you go to use the migration service there's a section at the bottom for getting the ADA boom a conversion",
    "start": "2098460",
    "end": "2105450"
  },
  {
    "text": "tool there's the download link right there when you click it you'll see something a",
    "start": "2105450",
    "end": "2110790"
  },
  {
    "text": "little bit like this details on you know installing how to use a lot of the same",
    "start": "2110790",
    "end": "2116609"
  },
  {
    "text": "things that I've just walked through",
    "start": "2116609",
    "end": "2119568"
  },
  {
    "text": "it has its own form also if you need to ask any questions about it separate from",
    "start": "2121890",
    "end": "2127960"
  },
  {
    "text": "DMS is sort of keep those separate now if any of what I've talked about so far",
    "start": "2127960",
    "end": "2134410"
  },
  {
    "text": "ends up being a little bit more than you want to take on a loan you need a little bit of help we have several migration partners who",
    "start": "2134410",
    "end": "2140920"
  },
  {
    "text": "can who can help you out this list is also available on our website if you go to the DMS section of the console",
    "start": "2140920",
    "end": "2147010"
  },
  {
    "text": "there's a link at the top this is partners and these guys have a lot of",
    "start": "2147010",
    "end": "2152140"
  },
  {
    "text": "experience doing some of these more complex migrations in situations that are sort of beyond what you want to take",
    "start": "2152140",
    "end": "2158380"
  },
  {
    "text": "on on your own so you leave here you you",
    "start": "2158380",
    "end": "2166480"
  },
  {
    "text": "open up your laptop or maybe you go all the way home and get your sort of workstation at the office you want to do this you want to you want to try this",
    "start": "2166480",
    "end": "2172660"
  },
  {
    "text": "out what do you do well you first go to the DMS section of the console it's",
    "start": "2172660",
    "end": "2178119"
  },
  {
    "text": "right there it's the bottom link in the database section if you want to download",
    "start": "2178119",
    "end": "2183730"
  },
  {
    "text": "this name a conversion tool you do that if you were going to be doing a heterogeneous migration not necessary if",
    "start": "2183730",
    "end": "2190390"
  },
  {
    "text": "you're going to run the same engines you could then just click on the getting started section of the console the",
    "start": "2190390",
    "end": "2198190"
  },
  {
    "text": "getting started wizard includes sort of more of a step-by-step wizard like approach the demo that I gave you might",
    "start": "2198190",
    "end": "2203319"
  },
  {
    "text": "prefer that or of course the instance endpoint and tasks user interface is",
    "start": "2203319",
    "end": "2208329"
  },
  {
    "text": "also available as as I demonstrated in my video and that will allow you to to",
    "start": "2208329",
    "end": "2215230"
  },
  {
    "text": "create those resources and and get them get them running so I've finished a",
    "start": "2215230",
    "end": "2221980"
  },
  {
    "start": "2219000",
    "end": "2261000"
  },
  {
    "text": "little bit ahead of the allocated time but I have a little bit of an opportunity now to answer any questions",
    "start": "2221980",
    "end": "2227339"
  },
  {
    "text": "you guys might have for me about the service or the tools go ahead",
    "start": "2227339",
    "end": "2234030"
  },
  {
    "text": "so you asked how the comparison works and you mean for the schema conversion",
    "start": "2238619",
    "end": "2245470"
  },
  {
    "text": "tool part of it",
    "start": "2245470",
    "end": "2248190"
  },
  {
    "start": "2261000",
    "end": "2339000"
  },
  {
    "text": "so you're talking about a homogenous import where you're doing from Oracle to Oracle and how is it comparing do you",
    "start": "2261160",
    "end": "2268730"
  },
  {
    "text": "mean the schema or the data oh so what's changed after it began okay got it",
    "start": "2268730",
    "end": "2274970"
  },
  {
    "text": "so um so the initial part the bulk load is pretty straightforward it's using",
    "start": "2274970",
    "end": "2282580"
  },
  {
    "text": "effectively selects and inserts to get the data in the bulk load portion of the",
    "start": "2282820",
    "end": "2287960"
  },
  {
    "text": "of the process and from the moment that look load begins is using what we call",
    "start": "2287960",
    "end": "2294050"
  },
  {
    "text": "change data capture which utilizes a little bit different techniques depending on the source database but",
    "start": "2294050",
    "end": "2299150"
  },
  {
    "text": "commonly known as transaction logs and as the transaction logs are emitted for",
    "start": "2299150",
    "end": "2305360"
  },
  {
    "text": "those transactions that are occurring we store that change data on their",
    "start": "2305360",
    "end": "2311660"
  },
  {
    "text": "application instance so that once the initial load is complete it can begin applying that change data to the the",
    "start": "2311660",
    "end": "2321500"
  },
  {
    "text": "target instance to make it the same basically applying the same changes that got applied to the source",
    "start": "2321500",
    "end": "2330279"
  },
  {
    "text": "right so so you're saying that if you truncate a table there's a chance that you can get up sink there there are some",
    "start": "2338870",
    "end": "2345360"
  },
  {
    "start": "2339000",
    "end": "2397000"
  },
  {
    "text": "limitations in transaction log based tracking there are certain things you",
    "start": "2345360",
    "end": "2350970"
  },
  {
    "text": "can do to the source that won't be properly carried forward to the target and that's why it's important to make",
    "start": "2350970",
    "end": "2356490"
  },
  {
    "text": "sure that you're verifying consistency and evaluating whether anything that your application does is going to be",
    "start": "2356490",
    "end": "2362850"
  },
  {
    "text": "incompatible with how that engine does transaction log based replication in",
    "start": "2362850",
    "end": "2368490"
  },
  {
    "text": "most situations this can do the right thing and and you're right you'll want",
    "start": "2368490",
    "end": "2373950"
  },
  {
    "text": "to make sure that you verify for your specific use case that the databases are consistent before switching your",
    "start": "2373950",
    "end": "2379020"
  },
  {
    "text": "application over to it in front yes so",
    "start": "2379020",
    "end": "2397980"
  },
  {
    "start": "2397000",
    "end": "2493000"
  },
  {
    "text": "the question was if you can do replication from multiple sources to a single target you absolutely can the do",
    "start": "2397980",
    "end": "2409350"
  },
  {
    "text": "you mean for a migration or for ongoing sort of keeping things in the sink right",
    "start": "2409350",
    "end": "2416300"
  },
  {
    "text": "so um ongoing replication is something that a lot of customers are asking for",
    "start": "2416300",
    "end": "2423110"
  },
  {
    "text": "the the software does support that it it'll work but we want to make sure the",
    "start": "2423110",
    "end": "2429330"
  },
  {
    "text": "customers are aware of similar imitations with the ongoing replication there's certain types of hardware failure that could interrupt that",
    "start": "2429330",
    "end": "2435270"
  },
  {
    "text": "ongoing replication and we don't have automation built-in to automatically",
    "start": "2435270",
    "end": "2441900"
  },
  {
    "text": "restart so if the ongoing replication is sort of for a dev test kind of situation",
    "start": "2441900",
    "end": "2447690"
  },
  {
    "text": "great try it it'll work but it's not something that at this point we're recommending as a supported use case we",
    "start": "2447690",
    "end": "2455070"
  },
  {
    "text": "are of course hearing from a lot of customers they want it and so we're you know definitely looking at ways to make that supported on the side",
    "start": "2455070",
    "end": "2464240"
  },
  {
    "start": "2493000",
    "end": "2529000"
  },
  {
    "text": "I believe that once you start taking rights on the target database you can't",
    "start": "2493570",
    "end": "2500580"
  },
  {
    "text": "rely on the replication from the source to be accurately keeping things in up to",
    "start": "2500580",
    "end": "2508060"
  },
  {
    "text": "date anymore you would want the verification to be a read-only verification or you would want",
    "start": "2508060",
    "end": "2515260"
  },
  {
    "text": "to be prepared to do it again if you're going to be making changes to it that",
    "start": "2515260",
    "end": "2520600"
  },
  {
    "text": "you're prepared to throw out you know",
    "start": "2520600",
    "end": "2529390"
  },
  {
    "start": "2529000",
    "end": "2701000"
  },
  {
    "text": "each each test is gonna be a little bit different based on the needs of the specific application in some cases you",
    "start": "2529390",
    "end": "2535270"
  },
  {
    "text": "can test a read-only and make sure that everything is showing up and that does",
    "start": "2535270",
    "end": "2543820"
  },
  {
    "text": "not require any going back and just keep on taking the changes while you test it and read-only mode but as soon as you",
    "start": "2543820",
    "end": "2548950"
  },
  {
    "text": "start taking writes to that target database in AWS you cannot be sure that",
    "start": "2548950",
    "end": "2556290"
  },
  {
    "text": "rights from the original one won't conflict especially when you have",
    "start": "2556290",
    "end": "2561640"
  },
  {
    "text": "primary keys and sequences and all that kind of thing it can you can have conflicting data that came from your",
    "start": "2561640",
    "end": "2568780"
  },
  {
    "text": "real application in your test application pointed it the same database well I guess not really the same",
    "start": "2568780",
    "end": "2575410"
  },
  {
    "text": "database but it effectively is right I mean you have your real application pointing at your original database which",
    "start": "2575410",
    "end": "2581890"
  },
  {
    "text": "is replicating through to your target at the same time as you're testing your target so any inserts or updates that",
    "start": "2581890",
    "end": "2587440"
  },
  {
    "text": "occur from either of those applications we're going to both affect the target and they might not be compatible changes",
    "start": "2587440",
    "end": "2593110"
  },
  {
    "text": "so think that if you were going to do it in that mode you would want to do sort of a",
    "start": "2593110",
    "end": "2599640"
  },
  {
    "text": "test version of your application against the device version and if it's making",
    "start": "2599640",
    "end": "2605520"
  },
  {
    "text": "any changes you would want to go back um",
    "start": "2605520",
    "end": "2610619"
  },
  {
    "text": "there might be some some tricks to to improve that situation a little bit if you wanted to avoid doing to bulk loads",
    "start": "2610619",
    "end": "2619020"
  },
  {
    "text": "you might be able to do something like take a snapshot of the RDS instance before doing the test and then there is",
    "start": "2619020",
    "end": "2624960"
  },
  {
    "text": "actually a mode where you can start up a task in ongoing replication only where",
    "start": "2624960",
    "end": "2630660"
  },
  {
    "text": "we have it pick up the ongoing replication at the point in time before you started doing any of your testing",
    "start": "2630660",
    "end": "2636900"
  },
  {
    "text": "that would be something you'd want to try out and verify though I haven't actually tried that yeah right because",
    "start": "2636900",
    "end": "2646260"
  },
  {
    "text": "yes you can take a snapshot of the RDS database you can you can restore to that",
    "start": "2646260",
    "end": "2652080"
  },
  {
    "text": "snapshot and then on the restored instance you can create another task that just only does the replication on",
    "start": "2652080",
    "end": "2657900"
  },
  {
    "text": "that drop-down list when I was creating the task there was one option for data",
    "start": "2657900",
    "end": "2663480"
  },
  {
    "text": "only there's another option for data only but followed by ongoing replication and the third option was ongoing",
    "start": "2663480",
    "end": "2669150"
  },
  {
    "text": "replication only so in the case that you're describing you would create a second task that was ongoing replication",
    "start": "2669150",
    "end": "2675180"
  },
  {
    "text": "only and you would apply just the replication to a snapshot a restored snapshot of the initial bulk load",
    "start": "2675180",
    "end": "2683059"
  },
  {
    "text": "question from you",
    "start": "2684050",
    "end": "2687320"
  },
  {
    "text": "okay so the question basically is about four large databases how was the",
    "start": "2699440",
    "end": "2706260"
  },
  {
    "start": "2701000",
    "end": "2858000"
  },
  {
    "text": "performance like how long does it take and what about you know how well does it keep up the data transfer can be heavily",
    "start": "2706260",
    "end": "2713220"
  },
  {
    "text": "dependent on the source if you're doing from your own data center into AWS then",
    "start": "2713220",
    "end": "2718710"
  },
  {
    "text": "the the speed of that link is going to be the real deciding factor it's basically just reaching out to each",
    "start": "2718710",
    "end": "2725280"
  },
  {
    "text": "database and executing sequel on both so the speed that you can transfer the data figure out how many gigabytes you have",
    "start": "2725280",
    "end": "2732030"
  },
  {
    "text": "how many terabytes you have figure out the link speed and you can do the math to figure out how long we don't",
    "start": "2732030",
    "end": "2737190"
  },
  {
    "text": "recommend going above several terabytes because it starts to take longer than a",
    "start": "2737190",
    "end": "2742560"
  },
  {
    "text": "couple of weeks and that is sort of longer than you can reliably want to",
    "start": "2742560",
    "end": "2747810"
  },
  {
    "text": "wait for we're starting to look at some ways to support even larger imports but",
    "start": "2747810",
    "end": "2753120"
  },
  {
    "text": "I don't have much to share on that right now as far as the keeping up on the",
    "start": "2753120",
    "end": "2758220"
  },
  {
    "text": "transactions it's totally possible to",
    "start": "2758220",
    "end": "2763650"
  },
  {
    "text": "create a workload that is sufficiently heavy on your source that cannot be kept",
    "start": "2763650",
    "end": "2769920"
  },
  {
    "text": "up with on your target that's especially gonna be true if the target database is using a small limited instance type like",
    "start": "2769920",
    "end": "2779730"
  },
  {
    "text": "for example if you were using a very large source and like a micro target then it's highly likely that you can",
    "start": "2779730",
    "end": "2787080"
  },
  {
    "text": "generate a sufficient load on that target that it can't keep up on the source even if you had equivalent size",
    "start": "2787080",
    "end": "2792330"
  },
  {
    "text": "it's probably still possible actually to generate loads that won't work it's",
    "start": "2792330",
    "end": "2798480"
  },
  {
    "text": "worth trying in in situations where",
    "start": "2798480",
    "end": "2804320"
  },
  {
    "text": "customers are having trouble keeping up on those transaction logs we recommend doing it during sort of lower times of",
    "start": "2804320",
    "end": "2813360"
  },
  {
    "text": "activity if there is such a thing like maybe at nights or during a time of the year when your application is used less",
    "start": "2813360",
    "end": "2818880"
  },
  {
    "text": "heavily it's also possible sometimes to do one piece at a time",
    "start": "2818880",
    "end": "2824340"
  },
  {
    "text": "like how only one database or one schema from the source being replicated out so that you",
    "start": "2824340",
    "end": "2832470"
  },
  {
    "text": "can you can keep up more easily where that source is doing a lot more than the",
    "start": "2832470",
    "end": "2839280"
  },
  {
    "text": "replication has to be able to withstand in the back he uses Oracle redo logs",
    "start": "2839280",
    "end": "2860460"
  },
  {
    "start": "2858000",
    "end": "2908000"
  },
  {
    "text": "there's a little bit of a trick for Oracle though you have to turn on supplemental logging there's some",
    "start": "2860460",
    "end": "2867420"
  },
  {
    "text": "documentation I didn't go into the detail circus this introduction rather than a deep dive but if you're going to use Oracle is your source there's some",
    "start": "2867420",
    "end": "2873480"
  },
  {
    "text": "documentation that talks about turning on supplemental logging you have to do it as sort of a system-wide setting as",
    "start": "2873480",
    "end": "2879060"
  },
  {
    "text": "well as for each table and there's several things have to be tweaked if you don't do them all then you'll see in the",
    "start": "2879060",
    "end": "2885450"
  },
  {
    "text": "cloud watch logs errors that say you know can't do this because supplemental logging isn't turned on properly and you",
    "start": "2885450",
    "end": "2891720"
  },
  {
    "text": "know keep on searching for why until you fix it and then those logs will not have any errors in them anymore I made it look easy because I did all",
    "start": "2891720",
    "end": "2899280"
  },
  {
    "text": "the versions where I hit those areas before I started recording well so when",
    "start": "2899280",
    "end": "2909570"
  },
  {
    "start": "2908000",
    "end": "2947000"
  },
  {
    "text": "you provide a username and password for your endpoint that username and password",
    "start": "2909570",
    "end": "2916530"
  },
  {
    "text": "needs to be able to access that data I so the transaction logs that are being",
    "start": "2916530",
    "end": "2926100"
  },
  {
    "text": "generated on on that Oracle source can be retrieved by that user they're pulled",
    "start": "2926100",
    "end": "2931740"
  },
  {
    "text": "into that replication instance they're stored locally until it's time for them",
    "start": "2931740",
    "end": "2936810"
  },
  {
    "text": "to be applied",
    "start": "2936810",
    "end": "2939290"
  },
  {
    "start": "2947000",
    "end": "3011000"
  },
  {
    "text": "a very good question when we originally talked about this",
    "start": "2947769",
    "end": "2953150"
  },
  {
    "text": "service initial launch we we said that it did and then when we launched it it didn't we are hearing from a lot of",
    "start": "2953150",
    "end": "2960619"
  },
  {
    "text": "customers how important that is and I included it in this demo in this in these slides because we're working",
    "start": "2960619",
    "end": "2967130"
  },
  {
    "text": "really hard to make that true and although if you go to the web right now and try it's not there",
    "start": "2967130",
    "end": "2972890"
  },
  {
    "text": "stay tuned coming soon the question was",
    "start": "2972890",
    "end": "2978650"
  },
  {
    "text": "if you can migrate into redshift you know it's something that we realize from",
    "start": "2978650",
    "end": "2985219"
  },
  {
    "text": "a lot of customers how important it is it's just a little bit more complicated in the rest of them because there's there's the need to use s3 buckets for",
    "start": "2985219",
    "end": "2993619"
  },
  {
    "text": "the redshift copy command which is a little bit more complicated and just giving it a username and password so",
    "start": "2993619",
    "end": "3000160"
  },
  {
    "text": "there's a little bit more to make that work and coming soon so the database",
    "start": "3000160",
    "end": "3013299"
  },
  {
    "start": "3011000",
    "end": "3058000"
  },
  {
    "text": "migration service does it have the chakra already yes know the the",
    "start": "3013299",
    "end": "3019239"
  },
  {
    "text": "important thing is that either the source or the target must be an AWS",
    "start": "3019239",
    "end": "3024969"
  },
  {
    "text": "resource so you can go from on-premise into ec2 from on-premise into RDS from",
    "start": "3024969",
    "end": "3030609"
  },
  {
    "text": "AC to you and on-premise from RDS and on-premise from ec2 when to already ask as long as one of the pieces is AWS then",
    "start": "3030609",
    "end": "3037150"
  },
  {
    "text": "everything's fine if you try to use it for to on-premise I believe the replication software will not do it",
    "start": "3037150",
    "end": "3043029"
  },
  {
    "text": "because it's a violation of the agreement right",
    "start": "3043029",
    "end": "3050999"
  },
  {
    "start": "3058000",
    "end": "3140000"
  },
  {
    "text": "so DMS only runs within virtual private cloud which encourages customers to",
    "start": "3058489",
    "end": "3066059"
  },
  {
    "text": "think carefully about the network connections and permissions and settings",
    "start": "3066059",
    "end": "3072150"
  },
  {
    "text": "before running it we we take security very seriously and are working hard to",
    "start": "3072150",
    "end": "3080190"
  },
  {
    "text": "improve it even more but the default connections are not encrypted the SL",
    "start": "3080190",
    "end": "3089579"
  },
  {
    "text": "database connections I think you can in some cases do it like for example if use an Oracle database with the enhanced",
    "start": "3089579",
    "end": "3095609"
  },
  {
    "text": "security turned on and require as a cell I think that'll work but since it's not a supported option for each of the",
    "start": "3095609",
    "end": "3103019"
  },
  {
    "text": "database engines we don't yet talk about it as an officially supported future we",
    "start": "3103019",
    "end": "3110039"
  },
  {
    "text": "we really encourage customers to be thinking about their VPC network",
    "start": "3110039",
    "end": "3116940"
  },
  {
    "text": "settings at this point before before running the conversion on the corner",
    "start": "3116940",
    "end": "3127308"
  },
  {
    "text": "hmm so that's a really specific question asking about JSON B imports and that's",
    "start": "3138890",
    "end": "3144839"
  },
  {
    "start": "3140000",
    "end": "3180000"
  },
  {
    "text": "it I unfortunately don't know if I knew I would be happy to answer but I'm sorry",
    "start": "3144839",
    "end": "3150829"
  },
  {
    "text": "I I can probably if if you if we meet afterwards I can get your info and we",
    "start": "3150829",
    "end": "3156810"
  },
  {
    "text": "can maybe or if you post onto the forum I can make sure that your request gets answered okay",
    "start": "3156810",
    "end": "3164750"
  },
  {
    "start": "3180000",
    "end": "3248000"
  },
  {
    "text": "so the filtering is always evolving the initial version did not have",
    "start": "3180480",
    "end": "3185620"
  },
  {
    "text": "filtering where it was sort of you know all-or-none by default we've we're",
    "start": "3185620",
    "end": "3192550"
  },
  {
    "text": "continuing to make it easier and easier to select a subset of schema is a subset",
    "start": "3192550",
    "end": "3197740"
  },
  {
    "text": "of tables within this game as include next include columns within a table some",
    "start": "3197740",
    "end": "3204430"
  },
  {
    "text": "of these things may or may not be exposed in excuse me",
    "start": "3204430",
    "end": "3210730"
  },
  {
    "text": "in the user interface at this point but we're continuing to improve the documentation on how to do these things",
    "start": "3210730",
    "end": "3218590"
  },
  {
    "text": "manually as we simultaneously improve the user interface to expose that",
    "start": "3218590",
    "end": "3223630"
  },
  {
    "text": "functionality more easily towards the",
    "start": "3223630",
    "end": "3228820"
  },
  {
    "text": "back I'm sorry go ahead",
    "start": "3228820",
    "end": "3235890"
  },
  {
    "text": "if so the question is if you have a very large database on the order of 10 terabytes and you'd like to move it into",
    "start": "3247970",
    "end": "3256460"
  },
  {
    "start": "3248000",
    "end": "3302000"
  },
  {
    "text": "RDS maybe my sequel or Aurora can you do it in one shot at that size it's a",
    "start": "3256460",
    "end": "3263250"
  },
  {
    "text": "little bit larger than we would recommend doing in one shot I don't remember the exact number for what we recommend but it's it's in the handful",
    "start": "3263250",
    "end": "3270840"
  },
  {
    "text": "of terabytes maybe three to six I'd have to look it up to be sure ten is definitely more than we'd recommend so",
    "start": "3270840",
    "end": "3276990"
  },
  {
    "text": "if there's a way for you to do it in phases you can set up individual tasks to do each one and you can run them",
    "start": "3276990",
    "end": "3284400"
  },
  {
    "text": "either concurrently or one after the other if you do them concurrently it's",
    "start": "3284400",
    "end": "3291840"
  },
  {
    "text": "probably going to take just as long is if you did it all the once so you'd probably want to do them one after the other yeah it's probably best to",
    "start": "3291840",
    "end": "3304200"
  },
  {
    "start": "3302000",
    "end": "3329000"
  },
  {
    "text": "separate it into individually consumable pieces they can be migrated independently and once that first",
    "start": "3304200",
    "end": "3310620"
  },
  {
    "text": "section is migrated you know start with the other one and do that until you have",
    "start": "3310620",
    "end": "3317190"
  },
  {
    "text": "each piece migrated",
    "start": "3317190",
    "end": "3320119"
  },
  {
    "start": "3329000",
    "end": "3372000"
  },
  {
    "text": "so the question is if the statistics are sufficient to verify that everything is done I would treat them more as a guide",
    "start": "3329160",
    "end": "3335470"
  },
  {
    "text": "it gives you a little bit of a heads up as to the kind of progress or migration",
    "start": "3335470",
    "end": "3340990"
  },
  {
    "text": "is making if you're interested in making sure that your data is consistent valid and fully there there are probably some",
    "start": "3340990",
    "end": "3352260"
  },
  {
    "text": "additional checks that you'd want to make on your source and your target data",
    "start": "3352260",
    "end": "3357400"
  },
  {
    "text": "to be sure that that you're ready to enable the application on the on the",
    "start": "3357400",
    "end": "3363700"
  },
  {
    "text": "target endpoint there are some",
    "start": "3363700",
    "end": "3374110"
  },
  {
    "start": "3372000",
    "end": "3393000"
  },
  {
    "text": "commercial tools that make that possible we don't have any of that we specifically offer at this point but we",
    "start": "3374110",
    "end": "3379720"
  },
  {
    "text": "are hearing from a lot of customers that that's important so you know as we continue iterating on the service and",
    "start": "3379720",
    "end": "3386500"
  },
  {
    "text": "making things increasingly easy for customers it's definitely something that we'll be considering so um I think I'd",
    "start": "3386500",
    "end": "3396070"
  },
  {
    "start": "3393000",
    "end": "3416000"
  },
  {
    "text": "like to just finish up if any of you have questions you'd like to talk with me about afterwards I'll be here a few",
    "start": "3396070",
    "end": "3401440"
  },
  {
    "text": "more minutes and I'd like to thank you all for coming feel free to fill out the",
    "start": "3401440",
    "end": "3407700"
  },
  {
    "text": "evaluations for the talk either on the app or I think they're available outside",
    "start": "3407700",
    "end": "3412750"
  },
  {
    "text": "as well and thanks for coming",
    "start": "3412750",
    "end": "3416460"
  }
]
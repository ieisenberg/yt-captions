[
  {
    "start": "0",
    "end": "30000"
  },
  {
    "text": "everyone today i'd like to show you how",
    "start": "80",
    "end": "3040"
  },
  {
    "text": "to use sagemaker debugger",
    "start": "3040",
    "end": "5040"
  },
  {
    "text": "to debug a xgboost model",
    "start": "5040",
    "end": "8240"
  },
  {
    "text": "to predict customer churns we will walk",
    "start": "8240",
    "end": "11440"
  },
  {
    "text": "through the notebook",
    "start": "11440",
    "end": "12559"
  },
  {
    "text": "in a moment my name is qingwei lee i'm a",
    "start": "12559",
    "end": "15679"
  },
  {
    "text": "machine learning specialist",
    "start": "15679",
    "end": "17359"
  },
  {
    "text": "the only reason i'm here today is my",
    "start": "17359",
    "end": "19439"
  },
  {
    "text": "much more talented",
    "start": "19439",
    "end": "20720"
  },
  {
    "text": "colleague emily weber who usually make",
    "start": "20720",
    "end": "23840"
  },
  {
    "text": "those videos are not available today",
    "start": "23840",
    "end": "26160"
  },
  {
    "text": "she has a line of ceos to meet and greet",
    "start": "26160",
    "end": "30400"
  },
  {
    "start": "30000",
    "end": "150000"
  },
  {
    "text": "well let's talk about bugs building",
    "start": "30400",
    "end": "33680"
  },
  {
    "text": "and training machine learning models is",
    "start": "33680",
    "end": "35600"
  },
  {
    "text": "a mix of science and art right many",
    "start": "35600",
    "end": "37920"
  },
  {
    "text": "issues could happen",
    "start": "37920",
    "end": "39440"
  },
  {
    "text": "during the training process and that",
    "start": "39440",
    "end": "41440"
  },
  {
    "text": "could prevent your model",
    "start": "41440",
    "end": "43120"
  },
  {
    "text": "from correctly extracting",
    "start": "43120",
    "end": "46160"
  },
  {
    "text": "and learning patterns in your data set",
    "start": "46160",
    "end": "50079"
  },
  {
    "text": "right those failed training jobs are",
    "start": "50079",
    "end": "53280"
  },
  {
    "text": "usually caused by",
    "start": "53280",
    "end": "54480"
  },
  {
    "text": "bugs such as inappropriate",
    "start": "54480",
    "end": "57440"
  },
  {
    "text": "initialization of parameters",
    "start": "57440",
    "end": "59920"
  },
  {
    "text": "or a poor combination of hyperparameters",
    "start": "59920",
    "end": "62879"
  },
  {
    "text": "etc",
    "start": "62879",
    "end": "63920"
  },
  {
    "text": "and those issues unfortunately are not",
    "start": "63920",
    "end": "66960"
  },
  {
    "text": "immediately visible",
    "start": "66960",
    "end": "68479"
  },
  {
    "text": "and it's also very time consuming to",
    "start": "68479",
    "end": "71360"
  },
  {
    "text": "identify",
    "start": "71360",
    "end": "72320"
  },
  {
    "text": "and correct those bugs one suggestion i",
    "start": "72320",
    "end": "75200"
  },
  {
    "text": "have",
    "start": "75200",
    "end": "76240"
  },
  {
    "text": "do not use bug spray because box has",
    "start": "76240",
    "end": "78960"
  },
  {
    "text": "families too",
    "start": "78960",
    "end": "80560"
  },
  {
    "text": "we need to use sage maker debugger",
    "start": "80560",
    "end": "83759"
  },
  {
    "text": "so sagemaker debugger provide full",
    "start": "83759",
    "end": "86000"
  },
  {
    "text": "visibility",
    "start": "86000",
    "end": "87280"
  },
  {
    "text": "into model training by monitoring",
    "start": "87280",
    "end": "90240"
  },
  {
    "text": "recording",
    "start": "90240",
    "end": "91439"
  },
  {
    "text": "analyzing your training process right",
    "start": "91439",
    "end": "94560"
  },
  {
    "text": "and to enable you know",
    "start": "94560",
    "end": "98159"
  },
  {
    "text": "sagemaker debugger right you need to",
    "start": "98159",
    "end": "101600"
  },
  {
    "text": "initialize a hook right which attach",
    "start": "101600",
    "end": "104399"
  },
  {
    "text": "itself",
    "start": "104399",
    "end": "105280"
  },
  {
    "text": "to the training process and emits data",
    "start": "105280",
    "end": "107840"
  },
  {
    "text": "necessarily",
    "start": "107840",
    "end": "108799"
  },
  {
    "text": "for debugging and those data will be",
    "start": "108799",
    "end": "110799"
  },
  {
    "text": "saved in",
    "start": "110799",
    "end": "111840"
  },
  {
    "text": "s3 debuggers then use a set of rules",
    "start": "111840",
    "end": "115520"
  },
  {
    "text": "to analyze those data in a streaming",
    "start": "115520",
    "end": "117840"
  },
  {
    "text": "fashion so a rule here",
    "start": "117840",
    "end": "120240"
  },
  {
    "text": "is a piece of code which encapsulates",
    "start": "120240",
    "end": "122880"
  },
  {
    "text": "the logic for analyzing",
    "start": "122880",
    "end": "124560"
  },
  {
    "text": "debugging data stages maker debugger",
    "start": "124560",
    "end": "126960"
  },
  {
    "text": "provides a set of built-in rules",
    "start": "126960",
    "end": "129200"
  },
  {
    "text": "created by data scientists and engineers",
    "start": "129200",
    "end": "132400"
  },
  {
    "text": "at amazon to identify those common",
    "start": "132400",
    "end": "135280"
  },
  {
    "text": "problems",
    "start": "135280",
    "end": "136160"
  },
  {
    "text": "while training machinery models debugger",
    "start": "136160",
    "end": "139280"
  },
  {
    "text": "supports major machine learning",
    "start": "139280",
    "end": "141120"
  },
  {
    "text": "frameworks such as",
    "start": "141120",
    "end": "142480"
  },
  {
    "text": "tensorflow pytorch mxnet",
    "start": "142480",
    "end": "145760"
  },
  {
    "text": "and also decision maker pre-built",
    "start": "145760",
    "end": "147920"
  },
  {
    "text": "algorithm xg boost",
    "start": "147920",
    "end": "149760"
  },
  {
    "text": "all right let's start looking at our",
    "start": "149760",
    "end": "152959"
  },
  {
    "start": "150000",
    "end": "470000"
  },
  {
    "text": "sample notebook so in this notebook",
    "start": "152959",
    "end": "155440"
  },
  {
    "text": "right we",
    "start": "155440",
    "end": "156000"
  },
  {
    "text": "are going to look at a customer turner",
    "start": "156000",
    "end": "158800"
  },
  {
    "text": "example",
    "start": "158800",
    "end": "159840"
  },
  {
    "text": "by the way this notebook is adapted from",
    "start": "159840",
    "end": "162239"
  },
  {
    "text": "another stage maker example",
    "start": "162239",
    "end": "164239"
  },
  {
    "text": "which is available on our search maker",
    "start": "164239",
    "end": "167040"
  },
  {
    "text": "examples github",
    "start": "167040",
    "end": "168239"
  },
  {
    "text": "website so as we know that customer",
    "start": "168239",
    "end": "171280"
  },
  {
    "text": "churn",
    "start": "171280",
    "end": "171840"
  },
  {
    "text": "are very expensive for business right so",
    "start": "171840",
    "end": "173840"
  },
  {
    "text": "it would be great if we can use machine",
    "start": "173840",
    "end": "175760"
  },
  {
    "text": "learning",
    "start": "175760",
    "end": "176480"
  },
  {
    "text": "to identify customers who are about to",
    "start": "176480",
    "end": "179760"
  },
  {
    "text": "churn",
    "start": "179760",
    "end": "180560"
  },
  {
    "text": "right so this is how this model is about",
    "start": "180560",
    "end": "183840"
  },
  {
    "text": "right",
    "start": "183840",
    "end": "184560"
  },
  {
    "text": "so at the beginning of this notebook we",
    "start": "184560",
    "end": "187680"
  },
  {
    "text": "have a bunch of",
    "start": "187680",
    "end": "189200"
  },
  {
    "text": "you know housekeeping items such as",
    "start": "189200",
    "end": "191360"
  },
  {
    "text": "importing",
    "start": "191360",
    "end": "193280"
  },
  {
    "text": "necessary libraries for us",
    "start": "193280",
    "end": "197200"
  },
  {
    "text": "the data set we have is publicly",
    "start": "197200",
    "end": "200879"
  },
  {
    "text": "available",
    "start": "200879",
    "end": "202159"
  },
  {
    "text": "it is a data set from",
    "start": "202159",
    "end": "206000"
  },
  {
    "text": "a mobile operator right we",
    "start": "206000",
    "end": "209120"
  },
  {
    "text": "as you can see we can have a quick",
    "start": "209120",
    "end": "210720"
  },
  {
    "text": "overview of the data set",
    "start": "210720",
    "end": "212879"
  },
  {
    "text": "we have about 3 300 rows of data",
    "start": "212879",
    "end": "217440"
  },
  {
    "text": "with 22 columns the last column of the",
    "start": "217440",
    "end": "221040"
  },
  {
    "text": "data",
    "start": "221040",
    "end": "221680"
  },
  {
    "text": "is telling us the churn or not churn",
    "start": "221680",
    "end": "225200"
  },
  {
    "text": "status",
    "start": "225200",
    "end": "226080"
  },
  {
    "text": "of the customer we also have bunch of",
    "start": "226080",
    "end": "228480"
  },
  {
    "text": "informations about the customer",
    "start": "228480",
    "end": "230720"
  },
  {
    "text": "such as the location how long the",
    "start": "230720",
    "end": "233599"
  },
  {
    "text": "customer has been",
    "start": "233599",
    "end": "234879"
  },
  {
    "text": "with this mobile operator",
    "start": "234879",
    "end": "238159"
  },
  {
    "text": "the usage details like how many minutes",
    "start": "238159",
    "end": "242720"
  },
  {
    "text": "the customer use all right",
    "start": "242720",
    "end": "245920"
  },
  {
    "text": "a very typical tabular data set",
    "start": "245920",
    "end": "249360"
  },
  {
    "text": "we have right here the next step i have",
    "start": "249360",
    "end": "252480"
  },
  {
    "text": "here",
    "start": "252480",
    "end": "252959"
  },
  {
    "text": "is some data preprocessing i just",
    "start": "252959",
    "end": "256239"
  },
  {
    "text": "followed the same steps of the original",
    "start": "256239",
    "end": "260639"
  },
  {
    "text": "customer churn data set as you can see",
    "start": "260639",
    "end": "263759"
  },
  {
    "text": "here",
    "start": "263759",
    "end": "264560"
  },
  {
    "text": "we drop some unnecessary data columns",
    "start": "264560",
    "end": "267520"
  },
  {
    "text": "such as the phone number which is",
    "start": "267520",
    "end": "269600"
  },
  {
    "text": "not contributing to the term prediction",
    "start": "269600",
    "end": "272479"
  },
  {
    "text": "at all",
    "start": "272479",
    "end": "274880"
  },
  {
    "text": "we also did some embedding all right as",
    "start": "274880",
    "end": "277919"
  },
  {
    "text": "well",
    "start": "277919",
    "end": "278720"
  },
  {
    "text": "so at the end we split our data into",
    "start": "278720",
    "end": "281919"
  },
  {
    "text": "three",
    "start": "281919",
    "end": "282560"
  },
  {
    "text": "sets we have our training data set",
    "start": "282560",
    "end": "285199"
  },
  {
    "text": "validation data set",
    "start": "285199",
    "end": "286639"
  },
  {
    "text": "and test data set we upload those data",
    "start": "286639",
    "end": "289759"
  },
  {
    "text": "set to s3",
    "start": "289759",
    "end": "291120"
  },
  {
    "text": "all right and we start our training",
    "start": "291120",
    "end": "292960"
  },
  {
    "text": "process as you can see",
    "start": "292960",
    "end": "295280"
  },
  {
    "text": "we use x-reboost which is a built-in",
    "start": "295280",
    "end": "298479"
  },
  {
    "text": "algorithm",
    "start": "298479",
    "end": "299280"
  },
  {
    "text": "in sagemaker for our modeling",
    "start": "299280",
    "end": "302639"
  },
  {
    "text": "as i mentioned earlier i'm only a",
    "start": "302639",
    "end": "304720"
  },
  {
    "text": "mediocre",
    "start": "304720",
    "end": "305840"
  },
  {
    "text": "machine learning specialist so i'm very",
    "start": "305840",
    "end": "307840"
  },
  {
    "text": "lazy um",
    "start": "307840",
    "end": "310080"
  },
  {
    "text": "i did not think carefully about the",
    "start": "310080",
    "end": "313520"
  },
  {
    "text": "hyper parameters",
    "start": "313520",
    "end": "314960"
  },
  {
    "text": "i need to use for this machine learning",
    "start": "314960",
    "end": "317919"
  },
  {
    "text": "model",
    "start": "317919",
    "end": "318639"
  },
  {
    "text": "and i just copy and paste some hyper",
    "start": "318639",
    "end": "321520"
  },
  {
    "text": "parameters from",
    "start": "321520",
    "end": "323280"
  },
  {
    "text": "another extra boost model i used earlier",
    "start": "323280",
    "end": "326960"
  },
  {
    "text": "all right as you can tell this is a very",
    "start": "326960",
    "end": "329280"
  },
  {
    "text": "careless way",
    "start": "329280",
    "end": "330320"
  },
  {
    "text": "of setting up parameters and it's not",
    "start": "330320",
    "end": "332800"
  },
  {
    "text": "recommended",
    "start": "332800",
    "end": "333919"
  },
  {
    "text": "but you know i did it anyway so",
    "start": "333919",
    "end": "336960"
  },
  {
    "text": "uh this is how i started the training i",
    "start": "336960",
    "end": "339199"
  },
  {
    "text": "define",
    "start": "339199",
    "end": "340560"
  },
  {
    "text": "my extraboost estimator uh since we only",
    "start": "340560",
    "end": "343600"
  },
  {
    "text": "have",
    "start": "343600",
    "end": "343919"
  },
  {
    "text": "three thousand rows of data it's a",
    "start": "343919",
    "end": "346240"
  },
  {
    "text": "pretty small data set",
    "start": "346240",
    "end": "347520"
  },
  {
    "text": "i only use uh one incidence",
    "start": "347520",
    "end": "350560"
  },
  {
    "text": "for the training well this is where i",
    "start": "350560",
    "end": "354240"
  },
  {
    "text": "tell the estimator what kind of",
    "start": "354240",
    "end": "357360"
  },
  {
    "text": "high performance i'm going to use for",
    "start": "357360",
    "end": "359280"
  },
  {
    "text": "this argument and then i provide my",
    "start": "359280",
    "end": "361120"
  },
  {
    "text": "training data set",
    "start": "361120",
    "end": "362400"
  },
  {
    "text": "my edition data set and start the",
    "start": "362400",
    "end": "364160"
  },
  {
    "text": "training",
    "start": "364160",
    "end": "365600"
  },
  {
    "text": "so to save time i'm not going to",
    "start": "365600",
    "end": "367919"
  },
  {
    "text": "actually run",
    "start": "367919",
    "end": "368960"
  },
  {
    "text": "the training process here but because it",
    "start": "368960",
    "end": "371759"
  },
  {
    "text": "has been wrong",
    "start": "371759",
    "end": "373199"
  },
  {
    "text": "before all right we can just go directly",
    "start": "373199",
    "end": "376160"
  },
  {
    "text": "to the results",
    "start": "376160",
    "end": "377919"
  },
  {
    "text": "if you look at the",
    "start": "377919",
    "end": "381039"
  },
  {
    "text": "training arrow and the validation error",
    "start": "381039",
    "end": "383360"
  },
  {
    "text": "well it's",
    "start": "383360",
    "end": "384319"
  },
  {
    "text": "actually not that bad right um 0.12",
    "start": "384319",
    "end": "388400"
  },
  {
    "text": "for validation 0.09 for training",
    "start": "388400",
    "end": "391919"
  },
  {
    "text": "all right well so just to be safe right",
    "start": "391919",
    "end": "395199"
  },
  {
    "text": "i",
    "start": "395199",
    "end": "395759"
  },
  {
    "text": "said well before i turn this model over",
    "start": "395759",
    "end": "398800"
  },
  {
    "text": "to my teammates to my managers maybe i",
    "start": "398800",
    "end": "401680"
  },
  {
    "text": "can do",
    "start": "401680",
    "end": "402479"
  },
  {
    "text": "a further validation on the test data",
    "start": "402479",
    "end": "406400"
  },
  {
    "text": "this is where i deploy my model right as",
    "start": "406400",
    "end": "408960"
  },
  {
    "text": "you can see here",
    "start": "408960",
    "end": "410319"
  },
  {
    "text": "deploying a model in sync maker",
    "start": "410319",
    "end": "413440"
  },
  {
    "text": "is super easy i just use this one line",
    "start": "413440",
    "end": "415840"
  },
  {
    "text": "called said you know",
    "start": "415840",
    "end": "416960"
  },
  {
    "text": "deploy all right and that's it and then",
    "start": "416960",
    "end": "420000"
  },
  {
    "text": "i",
    "start": "420000",
    "end": "420479"
  },
  {
    "text": "set uh you know try to send",
    "start": "420479",
    "end": "424000"
  },
  {
    "text": "the test data that i have right",
    "start": "424000",
    "end": "427039"
  },
  {
    "text": "as you can see here this is my test data",
    "start": "427039",
    "end": "429520"
  },
  {
    "text": "to",
    "start": "429520",
    "end": "431360"
  },
  {
    "text": "the deploy the model and i want to see",
    "start": "431360",
    "end": "433520"
  },
  {
    "text": "how",
    "start": "433520",
    "end": "434479"
  },
  {
    "text": "the model is performing right and i will",
    "start": "434479",
    "end": "436880"
  },
  {
    "text": "look at the",
    "start": "436880",
    "end": "437759"
  },
  {
    "text": "f1 score and the confusion matrix well",
    "start": "437759",
    "end": "441680"
  },
  {
    "text": "i'm glad i looked right because if you",
    "start": "441680",
    "end": "444319"
  },
  {
    "text": "look at f1 score",
    "start": "444319",
    "end": "446160"
  },
  {
    "text": "the score is pretty low we only have",
    "start": "446160",
    "end": "449280"
  },
  {
    "text": "0.44 f1 score and if you look at",
    "start": "449280",
    "end": "452560"
  },
  {
    "text": "the confusion matrix for the",
    "start": "452560",
    "end": "456000"
  },
  {
    "text": "actual turn right we have 48",
    "start": "456000",
    "end": "459280"
  },
  {
    "text": "of those actual turns in our testing",
    "start": "459280",
    "end": "461360"
  },
  {
    "text": "data",
    "start": "461360",
    "end": "462479"
  },
  {
    "text": "and we only identify 14",
    "start": "462479",
    "end": "465599"
  },
  {
    "text": "out of 48 which is terribly poor",
    "start": "465599",
    "end": "470319"
  },
  {
    "start": "470000",
    "end": "640000"
  },
  {
    "text": "so clearly something's wrong here well",
    "start": "470319",
    "end": "473039"
  },
  {
    "text": "but",
    "start": "473039",
    "end": "473360"
  },
  {
    "text": "from the training right previous",
    "start": "473360",
    "end": "475599"
  },
  {
    "text": "training we only get the accuracy the",
    "start": "475599",
    "end": "477840"
  },
  {
    "text": "errors for validation training",
    "start": "477840",
    "end": "479680"
  },
  {
    "text": "we do not have any other informations",
    "start": "479680",
    "end": "482080"
  },
  {
    "text": "right so that's why",
    "start": "482080",
    "end": "483680"
  },
  {
    "text": "i think you know maybe i need to do it",
    "start": "483680",
    "end": "486479"
  },
  {
    "text": "differently",
    "start": "486479",
    "end": "487120"
  },
  {
    "text": "so this time i'm going to use debugger",
    "start": "487120",
    "end": "490400"
  },
  {
    "text": "in the training process as we mentioned",
    "start": "490400",
    "end": "492879"
  },
  {
    "text": "earlier right",
    "start": "492879",
    "end": "493759"
  },
  {
    "text": "debugger give you the capability to",
    "start": "493759",
    "end": "496240"
  },
  {
    "text": "identify",
    "start": "496240",
    "end": "497440"
  },
  {
    "text": "complex issues by collecting",
    "start": "497440",
    "end": "501039"
  },
  {
    "text": "analyzing tensors right the tensors are",
    "start": "501039",
    "end": "504720"
  },
  {
    "text": "representing the status of the states",
    "start": "504720",
    "end": "508160"
  },
  {
    "text": "in every iteration of the training all",
    "start": "508160",
    "end": "511280"
  },
  {
    "text": "right",
    "start": "511280",
    "end": "511520"
  },
  {
    "text": "it's actually very easy to set it up",
    "start": "511520",
    "end": "514000"
  },
  {
    "text": "right so",
    "start": "514000",
    "end": "514800"
  },
  {
    "text": "as you can see this is uh similarly this",
    "start": "514800",
    "end": "518159"
  },
  {
    "text": "is how we define our estimator",
    "start": "518159",
    "end": "520320"
  },
  {
    "text": "right nothing has been changed from",
    "start": "520320",
    "end": "522880"
  },
  {
    "text": "previous job",
    "start": "522880",
    "end": "524240"
  },
  {
    "text": "what we need to do differently this time",
    "start": "524240",
    "end": "527120"
  },
  {
    "text": "is we need to define",
    "start": "527120",
    "end": "528640"
  },
  {
    "text": "a debugger hook and this hook tells what",
    "start": "528640",
    "end": "533680"
  },
  {
    "text": "data what tensor we need to collect",
    "start": "533680",
    "end": "537200"
  },
  {
    "text": "and how often do we",
    "start": "537200",
    "end": "540560"
  },
  {
    "text": "connect those tensors so as you can see",
    "start": "540560",
    "end": "543360"
  },
  {
    "text": "we",
    "start": "543360",
    "end": "544080"
  },
  {
    "text": "want to collect metrics and",
    "start": "544080",
    "end": "547200"
  },
  {
    "text": "the trees generated by the x-ray boost",
    "start": "547200",
    "end": "550160"
  },
  {
    "text": "model",
    "start": "550160",
    "end": "550959"
  },
  {
    "text": "and we want to connect those two at the",
    "start": "550959",
    "end": "553120"
  },
  {
    "text": "same time the",
    "start": "553120",
    "end": "554399"
  },
  {
    "text": "interval for us to collect is every",
    "start": "554399",
    "end": "557760"
  },
  {
    "text": "three iterations",
    "start": "557760",
    "end": "559839"
  },
  {
    "text": "after that we need to define a set of",
    "start": "559839",
    "end": "562240"
  },
  {
    "text": "rules as",
    "start": "562240",
    "end": "563120"
  },
  {
    "text": "you remember earlier the rules are",
    "start": "563120",
    "end": "565760"
  },
  {
    "text": "predefined the logic",
    "start": "565760",
    "end": "568080"
  },
  {
    "text": "to analyze the saved tensors",
    "start": "568080",
    "end": "571920"
  },
  {
    "text": "you know i just picked a few rules that",
    "start": "571920",
    "end": "574640"
  },
  {
    "text": "i",
    "start": "574640",
    "end": "575360"
  },
  {
    "text": "think is important for me to identify",
    "start": "575360",
    "end": "578640"
  },
  {
    "text": "the problem",
    "start": "578640",
    "end": "579600"
  },
  {
    "text": "i picked a loss not decreasing right so",
    "start": "579600",
    "end": "583040"
  },
  {
    "text": "this tells me",
    "start": "583040",
    "end": "584880"
  },
  {
    "text": "if the loss function",
    "start": "584880",
    "end": "588560"
  },
  {
    "text": "of my model is not decreasing this will",
    "start": "588560",
    "end": "591279"
  },
  {
    "text": "alert me",
    "start": "591279",
    "end": "592080"
  },
  {
    "text": "all right similarly we have over",
    "start": "592080",
    "end": "593760"
  },
  {
    "text": "training overfeeding",
    "start": "593760",
    "end": "595680"
  },
  {
    "text": "and tree depth as you can see right you",
    "start": "595680",
    "end": "598959"
  },
  {
    "text": "can",
    "start": "598959",
    "end": "600240"
  },
  {
    "text": "add more collections right here in the",
    "start": "600240",
    "end": "603360"
  },
  {
    "text": "debugger hook",
    "start": "603360",
    "end": "604480"
  },
  {
    "text": "you can also add more rules and you can",
    "start": "604480",
    "end": "607440"
  },
  {
    "text": "also bring your own",
    "start": "607440",
    "end": "609040"
  },
  {
    "text": "rules to debugger as well right",
    "start": "609040",
    "end": "612240"
  },
  {
    "text": "so as you can see well now i have to",
    "start": "612240",
    "end": "614079"
  },
  {
    "text": "retrain the model",
    "start": "614079",
    "end": "615279"
  },
  {
    "text": "so if i knew earlier i probably could",
    "start": "615279",
    "end": "619519"
  },
  {
    "text": "start the training the first time with",
    "start": "619519",
    "end": "621519"
  },
  {
    "text": "debugger enabled right so this gives me",
    "start": "621519",
    "end": "623920"
  },
  {
    "text": "the flexibility",
    "start": "623920",
    "end": "625519"
  },
  {
    "text": "to analyze the training process if",
    "start": "625519",
    "end": "628640"
  },
  {
    "text": "needed",
    "start": "628640",
    "end": "629680"
  },
  {
    "text": "all right so now let's run the training",
    "start": "629680",
    "end": "632240"
  },
  {
    "text": "and",
    "start": "632240",
    "end": "634000"
  },
  {
    "text": "after the training job is done again we",
    "start": "634000",
    "end": "635839"
  },
  {
    "text": "are not going to wait",
    "start": "635839",
    "end": "637200"
  },
  {
    "text": "uh the real training process we can just",
    "start": "637200",
    "end": "639040"
  },
  {
    "text": "look at the results",
    "start": "639040",
    "end": "640480"
  },
  {
    "start": "640000",
    "end": "770000"
  },
  {
    "text": "and we can see what is the job summary",
    "start": "640480",
    "end": "644399"
  },
  {
    "text": "of this debugger job well",
    "start": "644399",
    "end": "647680"
  },
  {
    "text": "if you look at here loss not decreasing",
    "start": "647680",
    "end": "650640"
  },
  {
    "text": "if you look at this rule",
    "start": "650640",
    "end": "652640"
  },
  {
    "text": "we find some issues over training well",
    "start": "652640",
    "end": "655760"
  },
  {
    "text": "we it seems like we did not have",
    "start": "655760",
    "end": "658160"
  },
  {
    "text": "anything wrong with",
    "start": "658160",
    "end": "659440"
  },
  {
    "text": "overtraining right",
    "start": "659440",
    "end": "662480"
  },
  {
    "text": "no issue found overfit no issue fun",
    "start": "662480",
    "end": "665839"
  },
  {
    "text": "for tree depth yeah we found some issues",
    "start": "665839",
    "end": "668800"
  },
  {
    "text": "that means",
    "start": "668800",
    "end": "669680"
  },
  {
    "text": "although in our hyper parameter we set",
    "start": "669680",
    "end": "672720"
  },
  {
    "text": "the true depth is a higher a higher",
    "start": "672720",
    "end": "676480"
  },
  {
    "text": "number",
    "start": "676480",
    "end": "677360"
  },
  {
    "text": "but in the reality the model right",
    "start": "677360",
    "end": "680560"
  },
  {
    "text": "i have built trees that did not reach",
    "start": "680560",
    "end": "683360"
  },
  {
    "text": "that depth",
    "start": "683360",
    "end": "684160"
  },
  {
    "text": "right so now because we have those",
    "start": "684160",
    "end": "687279"
  },
  {
    "text": "data connected let's try to analyze it",
    "start": "687279",
    "end": "690800"
  },
  {
    "text": "and visualize it",
    "start": "690800",
    "end": "692000"
  },
  {
    "text": "so the first thing i want to do is to",
    "start": "692000",
    "end": "694320"
  },
  {
    "text": "define",
    "start": "694320",
    "end": "695360"
  },
  {
    "text": "a trial right so what is a stage maker",
    "start": "695360",
    "end": "698720"
  },
  {
    "text": "debugger trial",
    "start": "698720",
    "end": "699600"
  },
  {
    "text": "so as you recall that we collect",
    "start": "699600",
    "end": "703440"
  },
  {
    "text": "those tensors those data during the",
    "start": "703440",
    "end": "706079"
  },
  {
    "text": "training process and we save those in",
    "start": "706079",
    "end": "708079"
  },
  {
    "text": "s3 so a trial is",
    "start": "708079",
    "end": "711920"
  },
  {
    "text": "a simple way for us to load this data",
    "start": "711920",
    "end": "716560"
  },
  {
    "text": "and for us to do analysis right",
    "start": "716560",
    "end": "719680"
  },
  {
    "text": "we create a trial saying you know",
    "start": "719680",
    "end": "722720"
  },
  {
    "text": "based on the data that is saved in the",
    "start": "722720",
    "end": "725600"
  },
  {
    "text": "s3 path",
    "start": "725600",
    "end": "727040"
  },
  {
    "text": "from our latest debugger training job",
    "start": "727040",
    "end": "731120"
  },
  {
    "text": "all right we define two",
    "start": "731120",
    "end": "734480"
  },
  {
    "text": "simple functions one to get the data",
    "start": "734480",
    "end": "736959"
  },
  {
    "text": "from the trial",
    "start": "736959",
    "end": "737920"
  },
  {
    "text": "uh the other is just to plot uh you know",
    "start": "737920",
    "end": "741120"
  },
  {
    "text": "the",
    "start": "741120",
    "end": "742240"
  },
  {
    "text": "training error right so let's look at",
    "start": "742240",
    "end": "744320"
  },
  {
    "text": "that well from",
    "start": "744320",
    "end": "745760"
  },
  {
    "text": "validation and from training we can see",
    "start": "745760",
    "end": "748480"
  },
  {
    "text": "that through the 100 iterations",
    "start": "748480",
    "end": "751360"
  },
  {
    "text": "the training arrow in you know increased",
    "start": "751360",
    "end": "754480"
  },
  {
    "text": "and then declined and then stay flat so",
    "start": "754480",
    "end": "757440"
  },
  {
    "text": "at minimum",
    "start": "757440",
    "end": "758399"
  },
  {
    "text": "we can see from this chart from this",
    "start": "758399",
    "end": "760880"
  },
  {
    "text": "plot",
    "start": "760880",
    "end": "761680"
  },
  {
    "text": "is that we do not need to train",
    "start": "761680",
    "end": "764800"
  },
  {
    "text": "the rest of the 80 iterations maybe the",
    "start": "764800",
    "end": "767680"
  },
  {
    "text": "number alterations",
    "start": "767680",
    "end": "768880"
  },
  {
    "text": "is too long right so now let's look at",
    "start": "768880",
    "end": "771680"
  },
  {
    "start": "770000",
    "end": "967000"
  },
  {
    "text": "our hyperparameter because clearly",
    "start": "771680",
    "end": "774320"
  },
  {
    "text": "from this debugger job from this",
    "start": "774320",
    "end": "776160"
  },
  {
    "text": "analysis",
    "start": "776160",
    "end": "777920"
  },
  {
    "text": "we could tell that maybe our",
    "start": "777920",
    "end": "781200"
  },
  {
    "text": "hyperparameter",
    "start": "781200",
    "end": "782480"
  },
  {
    "text": "is not setting up correctly right so now",
    "start": "782480",
    "end": "785200"
  },
  {
    "text": "let's look at the hyper parameter well",
    "start": "785200",
    "end": "786880"
  },
  {
    "text": "the maximum depth is six",
    "start": "786880",
    "end": "789519"
  },
  {
    "text": "we use uh gamma to be 40. well if you",
    "start": "789519",
    "end": "792880"
  },
  {
    "text": "recall",
    "start": "792880",
    "end": "793839"
  },
  {
    "text": "right gamma is the loss reduction",
    "start": "793839",
    "end": "796639"
  },
  {
    "text": "required",
    "start": "796639",
    "end": "797600"
  },
  {
    "text": "to make further partition right this",
    "start": "797600",
    "end": "799760"
  },
  {
    "text": "number probably is said to be",
    "start": "799760",
    "end": "801680"
  },
  {
    "text": "really high because 40 is a relatively",
    "start": "801680",
    "end": "804079"
  },
  {
    "text": "large number",
    "start": "804079",
    "end": "805279"
  },
  {
    "text": "for the extra boost model to make",
    "start": "805279",
    "end": "808480"
  },
  {
    "text": "further partition",
    "start": "808480",
    "end": "809760"
  },
  {
    "text": "all right so the next question we have",
    "start": "809760",
    "end": "811680"
  },
  {
    "text": "is well",
    "start": "811680",
    "end": "813200"
  },
  {
    "text": "no we suspect that some of the hyper",
    "start": "813200",
    "end": "815440"
  },
  {
    "text": "parameters are not correct",
    "start": "815440",
    "end": "818000"
  },
  {
    "text": "how can we optimize this how can we find",
    "start": "818000",
    "end": "821839"
  },
  {
    "text": "the best high performance for this",
    "start": "821839",
    "end": "824399"
  },
  {
    "text": "training job",
    "start": "824399",
    "end": "825120"
  },
  {
    "text": "well stage maker also has the",
    "start": "825120",
    "end": "829120"
  },
  {
    "text": "automatic model tuning capability this",
    "start": "829120",
    "end": "832160"
  },
  {
    "text": "is also known as",
    "start": "832160",
    "end": "833560"
  },
  {
    "text": "hyperparameter tuning it can help us",
    "start": "833560",
    "end": "836639"
  },
  {
    "text": "find the best versions of a model by",
    "start": "836639",
    "end": "838720"
  },
  {
    "text": "running many",
    "start": "838720",
    "end": "840000"
  },
  {
    "text": "training jobs on your data set and all",
    "start": "840000",
    "end": "843199"
  },
  {
    "text": "you need to do",
    "start": "843199",
    "end": "844160"
  },
  {
    "text": "is to write the range of hype parameters",
    "start": "844160",
    "end": "847120"
  },
  {
    "text": "and the",
    "start": "847120",
    "end": "848000"
  },
  {
    "text": "high performance tuning job will be able",
    "start": "848000",
    "end": "851120"
  },
  {
    "text": "to find",
    "start": "851120",
    "end": "852000"
  },
  {
    "text": "the best hyper parameters that give you",
    "start": "852000",
    "end": "854880"
  },
  {
    "text": "the best",
    "start": "854880",
    "end": "855600"
  },
  {
    "text": "results for your training job all right",
    "start": "855600",
    "end": "858000"
  },
  {
    "text": "so this is what we're going to do",
    "start": "858000",
    "end": "859839"
  },
  {
    "text": "i have a few hyperventilators",
    "start": "859839",
    "end": "863199"
  },
  {
    "text": "that i have relatively high confidence",
    "start": "863199",
    "end": "867440"
  },
  {
    "text": "so i will treat those as fixed hyper",
    "start": "867440",
    "end": "869920"
  },
  {
    "text": "parameters",
    "start": "869920",
    "end": "870800"
  },
  {
    "text": "so and i also added a early stopping",
    "start": "870800",
    "end": "874000"
  },
  {
    "text": "runs to be",
    "start": "874000",
    "end": "874800"
  },
  {
    "text": "nine so that means if the",
    "start": "874800",
    "end": "878399"
  },
  {
    "text": "loss function is not improving after",
    "start": "878399",
    "end": "881279"
  },
  {
    "text": "nine",
    "start": "881279",
    "end": "882000"
  },
  {
    "text": "iterations i'm going to stop the",
    "start": "882000",
    "end": "884560"
  },
  {
    "text": "training job",
    "start": "884560",
    "end": "885920"
  },
  {
    "text": "i also reduce the tree depth a little",
    "start": "885920",
    "end": "887920"
  },
  {
    "text": "bit all right",
    "start": "887920",
    "end": "889120"
  },
  {
    "text": "and for those other four",
    "start": "889120",
    "end": "892160"
  },
  {
    "text": "i think very important type of",
    "start": "892160",
    "end": "894079"
  },
  {
    "text": "parameters now",
    "start": "894079",
    "end": "895199"
  },
  {
    "text": "i specify the range and the led",
    "start": "895199",
    "end": "898880"
  },
  {
    "text": "hyper parameter tuning job to identify",
    "start": "898880",
    "end": "901680"
  },
  {
    "text": "the best",
    "start": "901680",
    "end": "902959"
  },
  {
    "text": "hyper parameter for this data set",
    "start": "902959",
    "end": "906800"
  },
  {
    "text": "all right and after this is set i start",
    "start": "906800",
    "end": "910240"
  },
  {
    "text": "the high performance tuning job",
    "start": "910240",
    "end": "913760"
  },
  {
    "text": "the maximum job i set is to be 80 so",
    "start": "913760",
    "end": "916720"
  },
  {
    "text": "that means",
    "start": "916720",
    "end": "917600"
  },
  {
    "text": "at maximum 80 training jobs will be",
    "start": "917600",
    "end": "919760"
  },
  {
    "text": "wrong and five of them will be running",
    "start": "919760",
    "end": "922000"
  },
  {
    "text": "in parallel",
    "start": "922000",
    "end": "923360"
  },
  {
    "text": "okay this might take a while as you can",
    "start": "923360",
    "end": "926079"
  },
  {
    "text": "tell we have",
    "start": "926079",
    "end": "927199"
  },
  {
    "text": "80 training jobs and after the",
    "start": "927199",
    "end": "930320"
  },
  {
    "text": "harvard parameter tuning job is done we",
    "start": "930320",
    "end": "933440"
  },
  {
    "text": "can deploy the model so now with the",
    "start": "933440",
    "end": "937680"
  },
  {
    "text": "hyper parameter and let's look at",
    "start": "937680",
    "end": "941279"
  },
  {
    "text": "the f1 score and confusion matrix",
    "start": "941279",
    "end": "945279"
  },
  {
    "text": "on the same testing data well as you can",
    "start": "945279",
    "end": "948639"
  },
  {
    "text": "tell",
    "start": "948639",
    "end": "949519"
  },
  {
    "text": "we almost doubled the iframe score",
    "start": "949519",
    "end": "952800"
  },
  {
    "text": "and if you look at the confusion matrix",
    "start": "952800",
    "end": "954800"
  },
  {
    "text": "we have much better results",
    "start": "954800",
    "end": "957920"
  },
  {
    "text": "that's all we have for today and thanks",
    "start": "957920",
    "end": "960000"
  },
  {
    "text": "for your attention",
    "start": "960000",
    "end": "961120"
  },
  {
    "text": "at the end please do not forget delete",
    "start": "961120",
    "end": "964399"
  },
  {
    "text": "the endpoint to save cost",
    "start": "964399",
    "end": "966639"
  },
  {
    "text": "thank you",
    "start": "966639",
    "end": "969360"
  }
]
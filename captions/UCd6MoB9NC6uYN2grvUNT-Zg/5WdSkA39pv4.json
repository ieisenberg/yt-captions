[
  {
    "start": "0",
    "end": "122000"
  },
  {
    "text": "good afternoon everyone thank you very much for coming along today my name is Alex Smith I'm head of",
    "start": "1580",
    "end": "7230"
  },
  {
    "text": "media and entertainment solutions architecture for Amazon Web Services asia-pacific with me on stage days are",
    "start": "7230",
    "end": "13740"
  },
  {
    "text": "in Louisville head of post-production for Amazon Studios and what we're going to be talking about today is some of the",
    "start": "13740",
    "end": "19500"
  },
  {
    "text": "challenges in dealing with 4k video and how you also can take those lessons to",
    "start": "19500",
    "end": "24510"
  },
  {
    "text": "help you eventually win an Emmy Award as well now when we talk about processing or",
    "start": "24510",
    "end": "30359"
  },
  {
    "text": "sorry when we talk is any reinvent talk the first thing that we really like to frame is is the problem statements is is",
    "start": "30359",
    "end": "36660"
  },
  {
    "text": "what we're trying to address and for 4k video for any kind of large high-quality",
    "start": "36660",
    "end": "42210"
  },
  {
    "text": "video it's actually quite similar to dealing with HD content as well but the",
    "start": "42210",
    "end": "48120"
  },
  {
    "text": "problem really is just that it's bigger where you're dealing with UHD content that individual file sizes just start to",
    "start": "48120",
    "end": "54239"
  },
  {
    "text": "become out of control you still have to do many of the same kind of things you're still ingesting the content into",
    "start": "54239",
    "end": "61710"
  },
  {
    "text": "a platform usually from many different locations worldwide you're still storing that in a Content Lake in a digital",
    "start": "61710",
    "end": "68220"
  },
  {
    "text": "asset management system in an ass in a SAN you're still processing encoding",
    "start": "68220",
    "end": "73380"
  },
  {
    "text": "running them through your metadata analysis subtitling etc and you still",
    "start": "73380",
    "end": "78390"
  },
  {
    "text": "have to distribute them to your partners or to end-users now just to help paint a visual picture the",
    "start": "78390",
    "end": "86520"
  },
  {
    "text": "scale of what you're dealing with really has changed from what people see if you look in the bottom right you can see DVD",
    "start": "86520",
    "end": "92060"
  },
  {
    "text": "now for those not from a media background those not that familiar with media you'll know DVD it's still the",
    "start": "92060",
    "end": "98130"
  },
  {
    "text": "highest percentage consumption medium worldwide DVD is typically 480 or 560",
    "start": "98130",
    "end": "105600"
  },
  {
    "text": "sorry said 576 in Powell vertical lines now what 4k actually means is it's",
    "start": "105600",
    "end": "112619"
  },
  {
    "text": "nearly approximately 4,000 virtual lines and vertical lines so it's just a much",
    "start": "112619",
    "end": "118649"
  },
  {
    "text": "bigger scale it's harder to do because you've got more data and to look at this from a like-for-like comparison",
    "start": "118649",
    "end": "125759"
  },
  {
    "start": "122000",
    "end": "122000"
  },
  {
    "text": "first of all let's let's go through some of the terms here so first of all the source this is what",
    "start": "125759",
    "end": "131590"
  },
  {
    "text": "you edit within a studio this is the highest quality of content you are ever going to have to touch or deal with and",
    "start": "131590",
    "end": "137470"
  },
  {
    "text": "usually for HD 1080p this falls at about three gigabits per second so it's big but it's not terrifying",
    "start": "137470",
    "end": "144340"
  },
  {
    "text": "now you're dealing you down sample that you put it in a mezzanine formats mezzanine is the highest quality that we",
    "start": "144340",
    "end": "151630"
  },
  {
    "text": "deal with on a day to day basis it forms the master for encoding for OTT platforms pay-tv platforms consumption",
    "start": "151630",
    "end": "159160"
  },
  {
    "text": "downstream now if we take the mezzanine from HD this sits at 50 megabits per",
    "start": "159160",
    "end": "164920"
  },
  {
    "text": "second 50 megabits per second you might also realize is the smallest direct connect you can have so it's quite easy",
    "start": "164920",
    "end": "171250"
  },
  {
    "text": "to think of moving this around but to compare this with a compressed mezzanine for 4k content which sits at 2.5",
    "start": "171250",
    "end": "178569"
  },
  {
    "text": "gigabits per second it's a much bigger problem to deal with and what we really",
    "start": "178569",
    "end": "184690"
  },
  {
    "text": "trying to answer today and the entire points of this talk is to understand how we can deal with this and when I say we",
    "start": "184690",
    "end": "190750"
  },
  {
    "text": "specifically I mean we as Amazon and we as Amazon Studios so what I'm going to do is hand over to Erin who's going to",
    "start": "190750",
    "end": "196450"
  },
  {
    "text": "talk us through a little bit about how Amazon Studios has dealt with this problem thank you Alex um so I think it",
    "start": "196450",
    "end": "204100"
  },
  {
    "start": "204000",
    "end": "204000"
  },
  {
    "text": "would be good to kind of start with Amazon studios and let you know that we've had to solve a lot of this from",
    "start": "204100",
    "end": "209109"
  },
  {
    "text": "scratch we didn't have legacy systems to build off of of course we're only three",
    "start": "209109",
    "end": "214120"
  },
  {
    "text": "years old Disney Fox Warner Brothers those other studios they've kind of been around for years they've been iterating",
    "start": "214120",
    "end": "220120"
  },
  {
    "text": "and making their systems kind of their post production and production workflows",
    "start": "220120",
    "end": "225370"
  },
  {
    "text": "work to kind of meet the deliverables needs for all their customers around the world which is generally just broadcast",
    "start": "225370",
    "end": "231510"
  },
  {
    "text": "going back to the you know DVDs kind of size of things they solved a lot of",
    "start": "231510",
    "end": "238720"
  },
  {
    "text": "problems and it's a good starting point for us but it's not actually something that we could utilize we had to kind of",
    "start": "238720",
    "end": "245730"
  },
  {
    "text": "think about things on our own terms no one none of those studios are actually using 4k video deliverables at this",
    "start": "245730",
    "end": "253030"
  },
  {
    "text": "point it's basically Amazon and Netflix for the most part",
    "start": "253030",
    "end": "259010"
  },
  {
    "text": "and so we really had to kind of think about our own solution we had no",
    "start": "259010",
    "end": "264230"
  },
  {
    "text": "infrastructure when we started and then if you know anything about Amazon we kind of move at a lightning lightning",
    "start": "264230",
    "end": "270800"
  },
  {
    "text": "pace and we started producing content very fast in UHD and an HDR and then the",
    "start": "270800",
    "end": "278600"
  },
  {
    "text": "more content that we started to produce we started to realize that we are losing kind of grip on our asset management we",
    "start": "278600",
    "end": "285020"
  },
  {
    "text": "were starting to kind of lose the sense of our library and workflow started to",
    "start": "285020",
    "end": "291950"
  },
  {
    "text": "slow down they started to kind of we ran into problems that we weren't anticipating and what we ended up having",
    "start": "291950",
    "end": "299240"
  },
  {
    "text": "to do was kind of go back to the drawing board and think about an internal homegrown solution that would",
    "start": "299240",
    "end": "304970"
  },
  {
    "text": "essentially allow us to scale much easier and work in a 4k environment you",
    "start": "304970",
    "end": "310760"
  },
  {
    "text": "know from here on out so what we did is we kind of looked at the problem we said",
    "start": "310760",
    "end": "317240"
  },
  {
    "text": "well we can't just solve for size because the legacy systems that we are kind of using the post production",
    "start": "317240",
    "end": "323060"
  },
  {
    "text": "workloads that we were using don't quite fit that and so we couldn't just do legacy stuff - and then we had to",
    "start": "323060",
    "end": "329660"
  },
  {
    "text": "actually work on a more fundamental approach to everything so what we ended",
    "start": "329660",
    "end": "335600"
  },
  {
    "text": "up doing is we broke it down and ended up going piece by piece we looked at the",
    "start": "335600",
    "end": "342410"
  },
  {
    "text": "ingestion the storage the processing content processing and in the delivery",
    "start": "342410",
    "end": "348050"
  },
  {
    "text": "of all this content and that was the way that we're gonna actually get more control over an entire asset library our",
    "start": "348050",
    "end": "355720"
  },
  {
    "text": "asset library and then to have that control - we had a very high-level",
    "start": "355720",
    "end": "361190"
  },
  {
    "text": "directive which was to not stifle creativity meaning we couldn't pass down",
    "start": "361190",
    "end": "366380"
  },
  {
    "text": "draconian rules to people to say deliver content in this very limited format we",
    "start": "366380",
    "end": "371870"
  },
  {
    "text": "had to be very open towards people who wanted to deliver content from very",
    "start": "371870",
    "end": "377420"
  },
  {
    "text": "small production houses and people who wanted to deliver from very large studios so the workflow challenge was",
    "start": "377420",
    "end": "385250"
  },
  {
    "start": "384000",
    "end": "384000"
  },
  {
    "text": "essentially what I just went over its ingest package creation and delivery and you'll notice that in between each of",
    "start": "385250",
    "end": "391070"
  },
  {
    "text": "those is a sense quality control staff that's because much to my chagrin I kind of we have to",
    "start": "391070",
    "end": "399139"
  },
  {
    "text": "actually check all these assets there's many technical errors that generally come with delivery of final assets so",
    "start": "399139",
    "end": "405199"
  },
  {
    "text": "you have to put in those safety checks into all that content and make sure that you're getting a sound mezzanine file to",
    "start": "405199",
    "end": "413029"
  },
  {
    "text": "work with from beginning to end so this our challenge was to figure out how to",
    "start": "413029",
    "end": "418069"
  },
  {
    "text": "create a dam solution that works in 4k video and would hit all these steps with",
    "start": "418069",
    "end": "423319"
  },
  {
    "text": "quality control in each safety part and then also at the very end of course move",
    "start": "423319",
    "end": "428689"
  },
  {
    "text": "over to like archiving keeping a good archive of your content is also",
    "start": "428689",
    "end": "433930"
  },
  {
    "text": "beneficial for us in the terms of that it actually creates more monetization on",
    "start": "433930",
    "end": "439370"
  },
  {
    "text": "the back end we could essentially if the more organized and better archive your",
    "start": "439370",
    "end": "444680"
  },
  {
    "text": "content is it actually opens the door for stock footage resells and",
    "start": "444680",
    "end": "450580"
  },
  {
    "text": "distribution of content in a much more streamlined quicker manner so we kind of",
    "start": "450580",
    "end": "456050"
  },
  {
    "text": "thought about that and then also there's other challenges that are involved in that pipeline too which is essentially",
    "start": "456050",
    "end": "461479"
  },
  {
    "text": "you have to also be able to give access to internal groups such as marketing PR and legal for review and for",
    "start": "461479",
    "end": "468680"
  },
  {
    "text": "distribution of assets for a trailer creation and all this other kind of stuff that has to happen and then",
    "start": "468680",
    "end": "475159"
  },
  {
    "text": "there's localization that Alex kind of touched on - you have to send those assets out and you have to repackage",
    "start": "475159",
    "end": "480979"
  },
  {
    "text": "them again get them back in and it's just a constant cycle of assets in and out and to manage all that on a 4k level",
    "start": "480979",
    "end": "487999"
  },
  {
    "text": "is actually pretty challenging so what we did decided to do with this homegrown",
    "start": "487999",
    "end": "494059"
  },
  {
    "text": "solution is essentially design completely AWS based workflow us being Amazon",
    "start": "494059",
    "end": "501680"
  },
  {
    "start": "495000",
    "end": "495000"
  },
  {
    "text": "Studios we decided it would be best to kind of stay within that Amazon ecosystem",
    "start": "501680",
    "end": "507050"
  },
  {
    "text": "kind of eat our own dog food so to speak so our basic workflow overview is very",
    "start": "507050",
    "end": "512990"
  },
  {
    "text": "much this we have external post houses or post vendors who are gonna complete a",
    "start": "512990",
    "end": "519529"
  },
  {
    "text": "content it could complete a piece of content that would be say man in the",
    "start": "519529",
    "end": "524540"
  },
  {
    "text": "high castle a very popular show for us that post house will essentially create",
    "start": "524540",
    "end": "531110"
  },
  {
    "text": "a mezzanine file of a single episode which is somewhere in the neighborhood of 200 to 300 gigs what we will actually",
    "start": "531110",
    "end": "541160"
  },
  {
    "text": "do now is we will have that file ingested into our s3 buckets and then our s3 our dam which is actually I'll",
    "start": "541160",
    "end": "549319"
  },
  {
    "text": "get to in just one second is reach engine and that dam that digital asset management system is this backbone it",
    "start": "549319",
    "end": "555560"
  },
  {
    "text": "watches those s3 ingestion folders and it pulls that content into each engine",
    "start": "555560",
    "end": "562220"
  },
  {
    "text": "and then reach engine essentially then can kick off a workflow orchestration that essentially can repackage that",
    "start": "562220",
    "end": "569600"
  },
  {
    "text": "content and in numerous different ways we just descript out some workflows and then those workflows essentially we are",
    "start": "569600",
    "end": "576649"
  },
  {
    "text": "using elemental to transcode different flavors of files and then we put those",
    "start": "576649",
    "end": "581660"
  },
  {
    "text": "back into the dam and then the very last step would essentially be package and delivery to Amazon video we could also",
    "start": "581660",
    "end": "588649"
  },
  {
    "text": "package and delivery to pretty much any platform it just happens to be that obviously we are exclusive to amazon",
    "start": "588649",
    "end": "594680"
  },
  {
    "text": "video so that's the general workflow of just moving content around I want to",
    "start": "594680",
    "end": "602120"
  },
  {
    "text": "dive down a little bit into ingestion so the first question comes you know with",
    "start": "602120",
    "end": "608720"
  },
  {
    "text": "4k video is how much harder is it to ingest and the truth is between HD and",
    "start": "608720",
    "end": "615889"
  },
  {
    "text": "4k video it's not really that much harder it's just bigger we do we do use",
    "start": "615889",
    "end": "622970"
  },
  {
    "text": "a lot of products to move that content there is snowball I'm gonna start with snowball",
    "start": "622970",
    "end": "629660"
  },
  {
    "text": "actually 40 to 80 terabytes at a time it's a very good for archived content that's living on a sand somewhere you",
    "start": "629660",
    "end": "636589"
  },
  {
    "text": "can actually grab that content and throw it up into s3 and very quickly and very",
    "start": "636589",
    "end": "642680"
  },
  {
    "text": "efficiently for more production assets stuff that's kind of in the works still",
    "start": "642680",
    "end": "651230"
  },
  {
    "text": "we prefer as three transfer acceleration that's really good because it lets you",
    "start": "651230",
    "end": "656660"
  },
  {
    "text": "take advantage of the cloud front edge network in order to the improve speeds and latency globally",
    "start": "656660",
    "end": "663080"
  },
  {
    "text": "it really works from there and then AWS Direct Connect is actually a really",
    "start": "663080",
    "end": "668120"
  },
  {
    "text": "great tool that we use when you're using a facility predominantly let's say a",
    "start": "668120",
    "end": "674660"
  },
  {
    "text": "very large post house that houses a lot of your content or that does a lot of your post production workflows for a lot",
    "start": "674660",
    "end": "680240"
  },
  {
    "text": "of your content enabling them with a direct connect allows you to build that to bridge that production house direct",
    "start": "680240",
    "end": "689029"
  },
  {
    "text": "into an Amazon region and that can allow massive improvements in consistency of",
    "start": "689029",
    "end": "694430"
  },
  {
    "text": "performance and dedication of bandwidth up to like 10 gigabit links it's really",
    "start": "694430",
    "end": "699829"
  },
  {
    "text": "fantastic so I what I didn't touch on",
    "start": "699829",
    "end": "705350"
  },
  {
    "text": "here yet is third-party apps so that's Amazon eating Amazon you know but the",
    "start": "705350",
    "end": "713060"
  },
  {
    "text": "major players in the third party atmosphere are definitely aspera Cygnet cloud bean and these are really great to",
    "start": "713060",
    "end": "720220"
  },
  {
    "text": "what they obviously do is they don't use the TCP transfer protocols they kind of",
    "start": "720220",
    "end": "727339"
  },
  {
    "text": "they instead they use UDP to move content which actually reduces that chatter and increases performance a lot",
    "start": "727339",
    "end": "734779"
  },
  {
    "text": "and it's predominantly used by all the major media companies right Disney you",
    "start": "734779",
    "end": "741290"
  },
  {
    "text": "know again all the major studios and all the major house is basically heaviness in a spare or Signia to move content so",
    "start": "741290",
    "end": "749980"
  },
  {
    "text": "for us those traditional media ingestion systems they're great they don't what we",
    "start": "749980",
    "end": "756290"
  },
  {
    "start": "750000",
    "end": "750000"
  },
  {
    "text": "found is that they're great for moving content but the pricing models of those",
    "start": "756290",
    "end": "763160"
  },
  {
    "text": "did kind of limit us to a degree the pricing models for traditional media",
    "start": "763160",
    "end": "769610"
  },
  {
    "text": "ingestion the ingestion like Cygnet and espera is basically priced for peak so",
    "start": "769610",
    "end": "775699"
  },
  {
    "text": "you could pay a lot if you're moving a lot of content and you're using that full bandwidth or you could lower your",
    "start": "775699",
    "end": "782690"
  },
  {
    "text": "bandwidth but you're not taking and to limit cost but then you're not really taking advantage of the full pipelines",
    "start": "782690",
    "end": "789140"
  },
  {
    "text": "so what we ended up doing was we started to look at Amazon s3 transfer",
    "start": "789140",
    "end": "796430"
  },
  {
    "text": "acceleration as a alternative option as Amazon Studios again we wanted to make",
    "start": "796430",
    "end": "802220"
  },
  {
    "text": "something that just worked for all of our customers and letting each",
    "start": "802220",
    "end": "808819"
  },
  {
    "text": "individual production kind of choose aspera or to Cygnet or initiate some",
    "start": "808819",
    "end": "814130"
  },
  {
    "text": "sort of SFTP transfers it just wasn't really working for us on a large scale so what we ended up looking at was s3",
    "start": "814130",
    "end": "824180"
  },
  {
    "text": "accelerate transfer acceleration because it it gave us some new opt-ins that were",
    "start": "824180",
    "end": "829940"
  },
  {
    "text": "not really available to us at the time I mean obviously it's price based on transfer and it's going and there's no",
    "start": "829940",
    "end": "838459"
  },
  {
    "text": "management of instances which is great because it's you could just spin it up and you end it so essentially it's fast",
    "start": "838459",
    "end": "845329"
  },
  {
    "text": "or free meaning like if it doesn't actually live up to the transfer speeds",
    "start": "845329",
    "end": "850699"
  },
  {
    "text": "that you would get on just through normal s3 uploads you actually it could",
    "start": "850699",
    "end": "855800"
  },
  {
    "text": "be free I would let Alex kind of explain that more but so we ended up using that",
    "start": "855800",
    "end": "863000"
  },
  {
    "text": "and it's actually been very helpful for us because grant and tour I don't know if anyone's familiar with that show it's",
    "start": "863000",
    "end": "868970"
  },
  {
    "text": "our brand-new very fun alternative to top gear",
    "start": "868970",
    "end": "875660"
  },
  {
    "text": "it uses the s3 transfer acceleration to actually move content into Dublin region",
    "start": "875660",
    "end": "882550"
  },
  {
    "text": "buckets from London and then we actually can transfer that content over to SFO",
    "start": "882550",
    "end": "888770"
  },
  {
    "text": "buckets whereas where our digital asset management system resides in Northern California and the speeds are amazing",
    "start": "888770",
    "end": "895100"
  },
  {
    "text": "and the price is virtually you know free for us it's actually really great in",
    "start": "895100",
    "end": "902360"
  },
  {
    "text": "terms of like it's been a very solid way for us to move content from regions far",
    "start": "902360",
    "end": "908449"
  },
  {
    "text": "away and to get it into our management system very quickly but there are some considerations that",
    "start": "908449",
    "end": "915240"
  },
  {
    "text": "we realized when we started working with these massively large UHD files",
    "start": "915240",
    "end": "921649"
  },
  {
    "start": "921000",
    "end": "921000"
  },
  {
    "text": "obviously files are hundreds of gigabytes in episode again going back to man in the high castle we're looking at",
    "start": "921649",
    "end": "928140"
  },
  {
    "text": "something around 280 gigs for every single episode and that's just one",
    "start": "928140",
    "end": "933930"
  },
  {
    "text": "version we also we often reversion shows quite a bit for different regions and",
    "start": "933930",
    "end": "939470"
  },
  {
    "text": "the cloud has limits and I'll get to that in just a second so what we what we really wanted to do",
    "start": "939470",
    "end": "948709"
  },
  {
    "text": "with these considerations is make things as fast as possible that's the number",
    "start": "948709",
    "end": "954029"
  },
  {
    "text": "one goal unfortunately I would love a little bit more time to process that content unfortunately if they lock a cut",
    "start": "954029",
    "end": "961800"
  },
  {
    "text": "on Sunday night I better have it uploaded in to AV on you know Monday",
    "start": "961800",
    "end": "967410"
  },
  {
    "text": "morning at 9:00 a.m. it's not that tough but it's essentially it's a very quick turnaround that's expected of us well",
    "start": "967410",
    "end": "975000"
  },
  {
    "text": "what we ended up doing was when we started actually putting stuff up and",
    "start": "975000",
    "end": "981480"
  },
  {
    "text": "then we ran it through the elemental server through that dam that I had kind of touched on earlier we started to",
    "start": "981480",
    "end": "986970"
  },
  {
    "text": "realize that we ran into some very unexpected issues and that's where you",
    "start": "986970",
    "end": "993029"
  },
  {
    "text": "kind of have to be ready to MacGyver solutions and so again what you HD files",
    "start": "993029",
    "end": "1001459"
  },
  {
    "text": "are big elemental is in an AWS our assets are an s3 Elemental can transcode",
    "start": "1001459",
    "end": "1007690"
  },
  {
    "text": "directly from s3 so so far everything seems great but there was then we",
    "start": "1007690",
    "end": "1015140"
  },
  {
    "text": "started to realize okay there's a maximum of ten thousand parts per upload",
    "start": "1015140",
    "end": "1021079"
  },
  {
    "text": "that's an s3 limitation right and elemental on their back-end had set part",
    "start": "1021079",
    "end": "1027650"
  },
  {
    "text": "sizes I had 20 megabits per chunk so any",
    "start": "1027650",
    "end": "1033230"
  },
  {
    "text": "of you are really good at math here really quickly 20 mega bit chunky up a",
    "start": "1033230",
    "end": "1040900"
  },
  {
    "text": "200 gigabit file or gigabyte file sorry obviously that's",
    "start": "1040900",
    "end": "1046540"
  },
  {
    "text": "a problem for a file that is actually 280 gigabytes so we had to then suddenly",
    "start": "1046540",
    "end": "1052210"
  },
  {
    "text": "start to realize we had to re-engineer how we are actually transcoding our",
    "start": "1052210",
    "end": "1057520"
  },
  {
    "text": "files and moving them around within our s3 and elemental environments so and",
    "start": "1057520",
    "end": "1066210"
  },
  {
    "text": "this is kind of like this is an example of problems that you guys can definitely",
    "start": "1066210",
    "end": "1072130"
  },
  {
    "text": "encounter when trying to build digital asset management solutions so and this",
    "start": "1072130",
    "end": "1077740"
  },
  {
    "text": "is just a very good and solid example you guys would probably run into many challenges just be ready",
    "start": "1077740",
    "end": "1083940"
  },
  {
    "text": "so unfortunately because those those files were over 200 gigs they would",
    "start": "1083940",
    "end": "1091240"
  },
  {
    "text": "actually fail to be read written back to s3 so we had to figure out that solution what we ended and I'll take one quick",
    "start": "1091240",
    "end": "1099730"
  },
  {
    "text": "step back we had actually chosen elemental because their ability to you know read directly from s3 buckets",
    "start": "1099730",
    "end": "1106600"
  },
  {
    "text": "instead of having to pull down to local EBS volumes and then do trans codes so",
    "start": "1106600",
    "end": "1114690"
  },
  {
    "text": "we chose elemental because we're like okay we don't want to waste time pulling elements down into local EBS volumes",
    "start": "1114690",
    "end": "1121059"
  },
  {
    "text": "doing a trans code and then reuploading them back into s3 that was gonna be essentially a three time hop there's the",
    "start": "1121059",
    "end": "1129610"
  },
  {
    "text": "first time up into s3 there's the down to the local EBS volumes and then there's the back up to s3 it was for our",
    "start": "1129610",
    "end": "1136750"
  },
  {
    "text": "file sizes it was gonna take hours and it wasted too much time so when we chose",
    "start": "1136750",
    "end": "1142330"
  },
  {
    "text": "elemental we're like great they can at least read from s3 that cuts out one of our download steps but obviously we ran",
    "start": "1142330",
    "end": "1149230"
  },
  {
    "text": "into this problem what we ended up doing here is we built a three-step layer we",
    "start": "1149230",
    "end": "1155410"
  },
  {
    "start": "1153000",
    "end": "1153000"
  },
  {
    "text": "actually did transcode the assets in elemental from the s3 then we output to",
    "start": "1155410",
    "end": "1160660"
  },
  {
    "text": "an actual EBS volume within the elemental trend like VPC we talked to",
    "start": "1160660",
    "end": "1169600"
  },
  {
    "text": "elemental quite a bit we first off our first question was obviously can you up the the chunks limit from 20 megabits to you",
    "start": "1169600",
    "end": "1177530"
  },
  {
    "text": "know say 100 they said unfortunately no wasn't going to be that easy that quickly so what we ended up doing was",
    "start": "1177530",
    "end": "1184570"
  },
  {
    "text": "spinning up EBS volumes for each node of Elemental that we would run and we would",
    "start": "1184570",
    "end": "1190760"
  },
  {
    "text": "spin up essentially a 500 gigabyte volume and we would trance code from",
    "start": "1190760",
    "end": "1195950"
  },
  {
    "text": "there and output to that volume there and then we just needed to push our",
    "start": "1195950",
    "end": "1201530"
  },
  {
    "text": "assets from that EBS volume to our s3 buckets and we did that simply through",
    "start": "1201530",
    "end": "1206900"
  },
  {
    "text": "AWS CLI it was actually wasn't an elegant solution it wasn't perfect but",
    "start": "1206900",
    "end": "1214100"
  },
  {
    "text": "it was actually effective and today as of today we've already been talking to",
    "start": "1214100",
    "end": "1219740"
  },
  {
    "text": "elemental we're already increasing those chunk limits and we're essentially working on bigger EBS volumes and so",
    "start": "1219740",
    "end": "1227060"
  },
  {
    "text": "we're already kind of working through those problems but we actually had to figure this out in the short term interim to kind of get our process our",
    "start": "1227060",
    "end": "1233000"
  },
  {
    "text": "files processed so that's just like a very long you know way of a long example",
    "start": "1233000",
    "end": "1241130"
  },
  {
    "text": "of essentially what you guys would face when you're actually designing a digital",
    "start": "1241130",
    "end": "1246170"
  },
  {
    "text": "asset management system that's going to move these very large files around in a you know AWS or s3 environment so I'm",
    "start": "1246170",
    "end": "1254030"
  },
  {
    "text": "gonna turn it back over to Alex to kind of summarize I mean I think that's a",
    "start": "1254030",
    "end": "1259460"
  },
  {
    "text": "really good example from Aaron about how when you're building a system sometimes things that worked perfectly before",
    "start": "1259460",
    "end": "1265010"
  },
  {
    "text": "start to break so in this case it wasn't a matter of s3 not supporting large files it's not a matter of the",
    "start": "1265010",
    "end": "1271220"
  },
  {
    "text": "multi-part upload API being broken or bad or badly designed it's an existing system elemental which is a fantastic",
    "start": "1271220",
    "end": "1277910"
  },
  {
    "text": "product but starting to do more with it working at a scale where you simply didn't work before and if you start",
    "start": "1277910",
    "end": "1284390"
  },
  {
    "text": "testing this you think oh I'll just put through a small file i'll transcode a hundred Meg file because I want to just go back and you know have my life but I",
    "start": "1284390",
    "end": "1291290"
  },
  {
    "text": "really recommend when you start to do things look at service limits you don't expect look at testing with the",
    "start": "1291290",
    "end": "1297260"
  },
  {
    "text": "representative data because you'll start to find things breaking and creaking at a scale that you wouldn't have had otherwise so just keep that in mind",
    "start": "1297260",
    "end": "1304280"
  },
  {
    "text": "because it it can bite you in ways you don't expect so now we've got our assets they're",
    "start": "1304280",
    "end": "1310040"
  },
  {
    "text": "stored somewhere we need to think about actually dealing with those so I know I",
    "start": "1310040",
    "end": "1315740"
  },
  {
    "text": "keep saying large files and I know it's getting tedious for those in the audience who deal with terabytes on a day-to-day basis and but the whole",
    "start": "1315740",
    "end": "1322850"
  },
  {
    "text": "concept of moving around these files is very hard if we think about the workflow of a typical hybrid solution so many",
    "start": "1322850",
    "end": "1331910"
  },
  {
    "text": "many content providers many customers might already have an on-site storage platform and then they'll have an in AWS",
    "start": "1331910",
    "end": "1338720"
  },
  {
    "text": "processing unit now if we're dealing with this kind of content maybe a HD mezzanine if we're talking about three",
    "start": "1338720",
    "end": "1345950"
  },
  {
    "start": "1340000",
    "end": "1340000"
  },
  {
    "text": "to ten gigabytes it's not very difficult it's very easy for us to have an on-premise vault of all of our content",
    "start": "1345950",
    "end": "1351740"
  },
  {
    "text": "transfer in process in AWS and then push it up to a CDN push it up to a partner",
    "start": "1351740",
    "end": "1357380"
  },
  {
    "text": "push it up to something else so having this kind of typical HD workflow is actually quite straightforward it allows",
    "start": "1357380",
    "end": "1364070"
  },
  {
    "text": "you to keep the TCO of your old platform but when it comes to the migration or the processing and the scaling you know",
    "start": "1364070",
    "end": "1370340"
  },
  {
    "text": "the important things that cloud does well you still have that flexibility so",
    "start": "1370340",
    "end": "1375920"
  },
  {
    "text": "why is this actually harder with 4k well let's just revisit an earlier point in an earlier slide if we look again just",
    "start": "1375920",
    "end": "1382790"
  },
  {
    "text": "at the highlighted bits here sure the mezzanine can be uploaded easily but",
    "start": "1382790",
    "end": "1388070"
  },
  {
    "text": "actually uploading that file which sits at 2.4 2.5 gigabits per second is is",
    "start": "1388070",
    "end": "1394250"
  },
  {
    "text": "much harder and of course this isn't just one file this isn't just one workflow the problem is these files get",
    "start": "1394250",
    "end": "1401180"
  },
  {
    "text": "moved around through many many different points and this is where we start to come to the concepts of content gravity",
    "start": "1401180",
    "end": "1407230"
  },
  {
    "text": "it's a slightly overused term but I like it because it it describes how",
    "start": "1407230",
    "end": "1412660"
  },
  {
    "text": "processing moves towards content for a good reason it's because the content weighs more than that processing so",
    "start": "1412660",
    "end": "1419900"
  },
  {
    "text": "really the easy lesson and you please don't leave now is get your files into one",
    "start": "1419900",
    "end": "1425659"
  },
  {
    "start": "1420000",
    "end": "1420000"
  },
  {
    "text": "place and leave them now if I look at what I've learned over the last few",
    "start": "1425659",
    "end": "1431269"
  },
  {
    "text": "years and what I presented last year I actually presented this very slide so",
    "start": "1431269",
    "end": "1436460"
  },
  {
    "text": "I'm getting my content reuse metrics up but a lot of what I talk about here is",
    "start": "1436460",
    "end": "1441769"
  },
  {
    "text": "processing without having to move files around but there's one section in here which is actually incredibly difficult",
    "start": "1441769",
    "end": "1447679"
  },
  {
    "text": "to deal with and that is metadata so in content management in media metadata is",
    "start": "1447679",
    "end": "1453799"
  },
  {
    "text": "one of the most important and irritating things to deal with so let's have a",
    "start": "1453799",
    "end": "1458809"
  },
  {
    "text": "little bit of a deeper look for those of you not from a media background for what metadata means to us so typically it'll",
    "start": "1458809",
    "end": "1466519"
  },
  {
    "start": "1466000",
    "end": "1466000"
  },
  {
    "text": "be an XML or a similar formats it'll have information about the assets it'll tell you what it is the duration",
    "start": "1466519",
    "end": "1473019"
  },
  {
    "text": "it may go into some details around the coder so how its encoded the container and you can then use this when you're",
    "start": "1473019",
    "end": "1479929"
  },
  {
    "text": "building your digital asset management system or you're providing this to an upstream partner typically nobody agrees",
    "start": "1479929",
    "end": "1485389"
  },
  {
    "text": "on standards there's more standards than there are for everything else but you",
    "start": "1485389",
    "end": "1490850"
  },
  {
    "text": "will have one within your platform and you will accept many and you will be careful with what you output now just",
    "start": "1490850",
    "end": "1497120"
  },
  {
    "text": "going back to this and looking here I've just said yep extract and persist metadata using lambda so it sounds easy",
    "start": "1497120",
    "end": "1503389"
  },
  {
    "text": "like this lambdas easy so even with content in AWS you still have that",
    "start": "1503389",
    "end": "1509870"
  },
  {
    "text": "weight of content you still have to think about moving it around moving a 300 gigabyte file moving a terabyte big",
    "start": "1509870",
    "end": "1516049"
  },
  {
    "text": "file is not a free operation so we need to be more intelligence about how we",
    "start": "1516049",
    "end": "1521360"
  },
  {
    "text": "analyze that content how we process it and the actual problem of metadata extraction is a little bit difficult if",
    "start": "1521360",
    "end": "1528230"
  },
  {
    "text": "we look at how you might have done this on premise how you might have done this in a traditional workflow you trance",
    "start": "1528230",
    "end": "1534309"
  },
  {
    "text": "typically most things work on watch folders so a watch folder will see a file come in it will transfer it over to",
    "start": "1534309",
    "end": "1541190"
  },
  {
    "text": "a processing node it will read through that file until it works out where the metadata is because it is not",
    "start": "1541190",
    "end": "1546620"
  },
  {
    "text": "consistently at the beginning end or middle and it'll output it to a digital asset management just more something now when I presented",
    "start": "1546620",
    "end": "1553879"
  },
  {
    "text": "that slide year last year I had a very similar idea in my head you know you'd fetch your file from s3 in response to",
    "start": "1553879",
    "end": "1560570"
  },
  {
    "text": "an event you process it read through the file until the metadata is found and then you output it somewhere but if you",
    "start": "1560570",
    "end": "1568489"
  },
  {
    "text": "remember or know much about lambda you'll know there's a few restrictions there there's a 500 gear a 500 medal",
    "start": "1568489",
    "end": "1574159"
  },
  {
    "text": "file system scratch some studios don't like having files stored in lambda",
    "start": "1574159",
    "end": "1580429"
  },
  {
    "text": "because it's outside their controlled PPC it will cost more because you're transferring an entire file and as I",
    "start": "1580429",
    "end": "1587629"
  },
  {
    "text": "said because this metadata location is inconsistent sometimes you will find this at the beginning and sometimes at",
    "start": "1587629",
    "end": "1593059"
  },
  {
    "text": "the end you're effectively streaming the entire file and then at some point",
    "start": "1593059",
    "end": "1598909"
  },
  {
    "text": "you're like exhaust your lambda execution time or it just doesn't really work out too effectively so this is",
    "start": "1598909",
    "end": "1605389"
  },
  {
    "start": "1604000",
    "end": "1604000"
  },
  {
    "text": "where we enter with media info first of all it's free and open source it's BSD license you can use it package it and",
    "start": "1605389",
    "end": "1611570"
  },
  {
    "text": "build it into your applications that's good the best bit about it is that it's has",
    "start": "1611570",
    "end": "1617690"
  },
  {
    "text": "curl functionality you can give it an HTTP URL and it will intelligently scan",
    "start": "1617690",
    "end": "1623749"
  },
  {
    "text": "through that file fetching only small segments and persisting very very little to disk it",
    "start": "1623749",
    "end": "1629389"
  },
  {
    "text": "will export to XML and it gives you an incredible amount of information about the asset an example test I did earlier",
    "start": "1629389",
    "end": "1637210"
  },
  {
    "text": "process to 1.6 gig video file in two and a half seconds and I only used about 47",
    "start": "1637210",
    "end": "1643039"
  },
  {
    "text": "mega memory so it fits within the lambda container fits within the lambda concept very well and most of all for lambda it",
    "start": "1643039",
    "end": "1650570"
  },
  {
    "text": "is easy to statically compiled so you don't have to worry about external dependencies so some of you may have",
    "start": "1650570",
    "end": "1658549"
  },
  {
    "text": "seen this diagram but this is a very simple overview of how you do the actual",
    "start": "1658549",
    "end": "1663859"
  },
  {
    "text": "metadata processing with medium foam like most lambda things you get necessary notification at this point",
    "start": "1663859",
    "end": "1670879"
  },
  {
    "text": "there is a job that generates a one-time URL this is passed to the media info",
    "start": "1670879",
    "end": "1676639"
  },
  {
    "text": "binary media info will then start to make those calls scan through that",
    "start": "1676639",
    "end": "1682249"
  },
  {
    "text": "entire file and work out where to pull data and then at the end you can just now put that to dynamodb or whatever your",
    "start": "1682249",
    "end": "1688830"
  },
  {
    "text": "platform is whatever your digital asset management system or even if you just want to persistence or that locally and",
    "start": "1688830",
    "end": "1695240"
  },
  {
    "text": "unlike my slide last year this isn't conceptual there is a blog post owned by my colleague and there's a link at the",
    "start": "1695240",
    "end": "1701159"
  },
  {
    "text": "bottom there so I encourage you to just have a go and see if you can get this working for your use cases as opposed to",
    "start": "1701159",
    "end": "1706950"
  },
  {
    "text": "running through the typical kind of processing so now I've got my content",
    "start": "1706950",
    "end": "1712260"
  },
  {
    "text": "I've stored it I've extracted the metadata now what I need to do is store it and put that metadata into a digital",
    "start": "1712260",
    "end": "1718649"
  },
  {
    "text": "asset management system or a workflow system and this is again where Amazon studios have dealt with that so as I was",
    "start": "1718649",
    "end": "1731159"
  },
  {
    "text": "saying we needed to we need to figure out where to put stuff um this is again going back to our digital asset",
    "start": "1731159",
    "end": "1737309"
  },
  {
    "text": "management system that we have now are instituting is we architected this from",
    "start": "1737309",
    "end": "1744179"
  },
  {
    "text": "the very beginning and we said well it's obviously gonna be on AWS because we want it to be scalable nothing better",
    "start": "1744179",
    "end": "1749789"
  },
  {
    "text": "and more scalable than AWS and our opinions and all this and for us to it",
    "start": "1749789",
    "end": "1754980"
  },
  {
    "text": "definitely has to have an internal and external integrations meaning for us",
    "start": "1754980",
    "end": "1760669"
  },
  {
    "text": "specifically we can't just build a platform that works today we need",
    "start": "1760669",
    "end": "1765809"
  },
  {
    "text": "something that's going to be very fluid and modular and this in the sense that we can actually install new technologies",
    "start": "1765809",
    "end": "1772409"
  },
  {
    "text": "as they come along and kind of deprecated old ones that aren't really working for us anymore I'm thinking in terms of like stuff",
    "start": "1772409",
    "end": "1779370"
  },
  {
    "text": "where we're gonna start to work with subtitling we're a closed captioning we're closed we're going to actually start to parse raw footage information",
    "start": "1779370",
    "end": "1787409"
  },
  {
    "text": "and so we really wanted to make sure that our digital asset management system could plug into a bunch of different",
    "start": "1787409",
    "end": "1793529"
  },
  {
    "text": "kind of workflows because it would be essentially open-ended in that sense and",
    "start": "1793529",
    "end": "1799649"
  },
  {
    "text": "then of course orchestration is the main thing it's gonna do right it's going to take our files it's going to basically build packages and deliver those",
    "start": "1799649",
    "end": "1807120"
  },
  {
    "text": "packages at speed and at cost to all of our come to our distribution",
    "start": "1807120",
    "end": "1813330"
  },
  {
    "text": "partners again in our case essentially only him his home video but we are",
    "start": "1813330",
    "end": "1818730"
  },
  {
    "text": "already starting to distribute to other platforms as well we took all that we",
    "start": "1818730",
    "end": "1824159"
  },
  {
    "text": "kind of looked backwards and you know starting from the customer saying okay well they're gonna watch it and we got",
    "start": "1824159",
    "end": "1830220"
  },
  {
    "text": "to give it to the partner who's going to send it to them and we have to create packages that are correct for that",
    "start": "1830220",
    "end": "1835799"
  },
  {
    "text": "partner and we have to receive assets from our partners from our post-production partners that",
    "start": "1835799",
    "end": "1840809"
  },
  {
    "text": "essentially allow us to build those correct assets so we kind of worked our way backwards very amazonian thing to do of course so and of course it just",
    "start": "1840809",
    "end": "1850889"
  },
  {
    "text": "needed to work as well so really what I want to do now is kind of walk you",
    "start": "1850889",
    "end": "1855899"
  },
  {
    "start": "1853000",
    "end": "1853000"
  },
  {
    "text": "through a little bit more in depth about reach engine and what it does well you",
    "start": "1855899",
    "end": "1862559"
  },
  {
    "text": "knew we would we knew that our VPC and which by the way our VP C is in SFO",
    "start": "1862559",
    "end": "1871830"
  },
  {
    "text": "regions because it's actually the closest to Los Angeles and it works the best for us there we knew that that storage would have to be accessible for",
    "start": "1871830",
    "end": "1879210"
  },
  {
    "text": "multiple locations at different sources we have many post-production studio partners delivering content from around",
    "start": "1879210",
    "end": "1884519"
  },
  {
    "text": "the world so we needed it to be kind of very easy to access and we needed that",
    "start": "1884519",
    "end": "1889980"
  },
  {
    "text": "underlying infrastructure to reflect that kind of easy accessibility sorry so",
    "start": "1889980",
    "end": "1898999"
  },
  {
    "text": "again working backwards we obviously chose us three because it was going to be the most easiest to access from the",
    "start": "1898999",
    "end": "1904799"
  },
  {
    "text": "internet and then we deployed the reach engine on that and reach engine actually has a a child product called collaborate",
    "start": "1904799",
    "end": "1913350"
  },
  {
    "text": "and this is actually one of the reasons we chose them as well is it actually",
    "start": "1913350",
    "end": "1918690"
  },
  {
    "text": "simplifies asset delivery into a digital asset management system kind of eliminating the guesswork for for",
    "start": "1918690",
    "end": "1925739"
  },
  {
    "text": "vendors essentially one of our internal Amazon Studios employees creates a task",
    "start": "1925739",
    "end": "1930980"
  },
  {
    "text": "this task is then sent to the content provider the content provider that it",
    "start": "1930980",
    "end": "1937529"
  },
  {
    "text": "simply clicks upload matches the asset to this specific task and stun it could not be more easy and to be",
    "start": "1937529",
    "end": "1945080"
  },
  {
    "text": "honest that's how we progress and move the fastest because when we start",
    "start": "1945080",
    "end": "1950180"
  },
  {
    "text": "introducing challenging ways to send content to us even though they might be faster and a little bit better it just",
    "start": "1950180",
    "end": "1958580"
  },
  {
    "text": "ends up slowing the process down in a huge way so after we get those assets",
    "start": "1958580",
    "end": "1965510"
  },
  {
    "text": "through the collaborate it basically goes into our rain defense our back-end this this ring defense VPC exists again",
    "start": "1965510",
    "end": "1973400"
  },
  {
    "text": "in SF oh we have followed the tenants of the AWS well architected with our",
    "start": "1973400",
    "end": "1980180"
  },
  {
    "text": "deployment so that we can control all of the aspects from security to cost",
    "start": "1980180",
    "end": "1986050"
  },
  {
    "text": "essentially this is not public facing at all in fact you can only anything that",
    "start": "1986050",
    "end": "1995420"
  },
  {
    "text": "resides in our V PC can only be accessed with Bastion host and all those Bastion",
    "start": "1995420",
    "end": "2000970"
  },
  {
    "text": "hosts are essentially not permanently running they are only spun up when we need to access and they're actually",
    "start": "2000970",
    "end": "2006820"
  },
  {
    "text": "turned off when we're done and then because that nothing is public facing it's essentially there's no access to",
    "start": "2006820",
    "end": "2013630"
  },
  {
    "text": "this content when we're not spinning up those Bastion hosts this is obviously to follow our security group rules and",
    "start": "2013630",
    "end": "2021010"
  },
  {
    "text": "actually makes a very secure dam for us",
    "start": "2021010",
    "end": "2026220"
  },
  {
    "text": "and just to also mention to all of our s3 buckets are accessed through V PC",
    "start": "2026220",
    "end": "2032260"
  },
  {
    "text": "endpoints which again that never leaves that the AWS network so we've really",
    "start": "2032260",
    "end": "2038440"
  },
  {
    "text": "tried to architect this with the idea that we want it to be very very secure so that piracy is obviously a big issue",
    "start": "2038440",
    "end": "2046240"
  },
  {
    "text": "for everybody we wanted to protect our content to in the highest possible way that we could and I think we've actually",
    "start": "2046240",
    "end": "2052750"
  },
  {
    "text": "done pretty well on making that work so just to I'll make one quick hop out here",
    "start": "2052750",
    "end": "2058450"
  },
  {
    "text": "to reach engine uses essentially all these all these functions inside MongoDB",
    "start": "2058450",
    "end": "2064148"
  },
  {
    "text": "is the one thing that we are kind of very strongly encouraging reach engine to move away from and move towards",
    "start": "2064149",
    "end": "2070628"
  },
  {
    "text": "dynamic DynamoDB just because it's you know it's obviously again within the AWS Network",
    "start": "2070629",
    "end": "2076710"
  },
  {
    "text": " is not quite you know up to our security levels that we want and but",
    "start": "2076710",
    "end": "2084419"
  },
  {
    "text": "just to be also clear to we only access those we only access those who like",
    "start": "2084419",
    "end": "2090990"
  },
  {
    "text": "dedicated like ima users and stuff so it's it is still fairly secure for what it is the next step is once it's in",
    "start": "2090990",
    "end": "2102180"
  },
  {
    "text": "reach engine we actually then can start working with all that stuff pushing",
    "start": "2102180",
    "end": "2107790"
  },
  {
    "text": "everything to elemental doing transcodes there again across AWS no it's never",
    "start": "2107790",
    "end": "2112859"
  },
  {
    "text": "going outside of our environment and then everything cuz is kind of runs back into this and then the final step is",
    "start": "2112859",
    "end": "2118920"
  },
  {
    "text": "obviously to deliver those assets completed to Amazon video which we essentially use bucket a bucket",
    "start": "2118920",
    "end": "2124170"
  },
  {
    "text": "transfers over s3 and there are other",
    "start": "2124170",
    "end": "2129510"
  },
  {
    "text": "ways of course we could use again going back to espera signature or add things it just obviously happens that Amazon",
    "start": "2129510",
    "end": "2136770"
  },
  {
    "text": "video is also used otherwise thing s3 and we're just kind of keeping everything together and again we",
    "start": "2136770",
    "end": "2144180"
  },
  {
    "text": "designed this specifically or at least my solutions architected and designed",
    "start": "2144180",
    "end": "2150630"
  },
  {
    "text": "this thing to be the well tart well architected tenants to follow those to keep everything as secure as possible",
    "start": "2150630",
    "end": "2157020"
  },
  {
    "text": "and to keep it in AWS at all possible times we didn't choose elemental you",
    "start": "2157020",
    "end": "2162810"
  },
  {
    "text": "know just because they're an Amazon company we actually did choose them because they were you know the best",
    "start": "2162810",
    "end": "2169290"
  },
  {
    "text": "solution for us again going back to that earlier problem we weren't actually we",
    "start": "2169290",
    "end": "2176609"
  },
  {
    "text": "didn't want because they could transcode straight from s3 assets or you know that was a big plus for us and they actually",
    "start": "2176609",
    "end": "2183119"
  },
  {
    "text": "handled UHD 4k content quite often so is it's kind of a win-win situation for us",
    "start": "2183119",
    "end": "2190970"
  },
  {
    "text": "so that's kind of like the storage architecture of our entire dam again",
    "start": "2190970",
    "end": "2198109"
  },
  {
    "text": "keeping it in that ring defense was the the most important thing here and whenever you're designing those dams",
    "start": "2198109",
    "end": "2203820"
  },
  {
    "text": "that's number one thing is if you're gonna start to pass NPA security protocols and",
    "start": "2203820",
    "end": "2209670"
  },
  {
    "text": "even higher levels Marvel Disney they're all start to have these very very tight",
    "start": "2209670",
    "end": "2215630"
  },
  {
    "text": "tightly like guarded content dams and by",
    "start": "2215630",
    "end": "2221160"
  },
  {
    "text": "us following those well architected you know tenants we've actually designed a",
    "start": "2221160",
    "end": "2226590"
  },
  {
    "text": "system that we feel is essentially very very secure I'm gonna pass it over back",
    "start": "2226590",
    "end": "2231720"
  },
  {
    "text": "to Alex to talk about the the next steps thank you so I think this is a really",
    "start": "2231720",
    "end": "2238290"
  },
  {
    "text": "again a good example of where the traditional approaches of pushing things through a file system transferring files",
    "start": "2238290",
    "end": "2245790"
  },
  {
    "text": "over an RPC or something like that they do start to fall apart a bit if you actually if I just show you there if you",
    "start": "2245790",
    "end": "2252090"
  },
  {
    "text": "look at everything in this diagram you notice it's connected over REST API is or the s3 to s3 transfer is over an HTTP",
    "start": "2252090",
    "end": "2259470"
  },
  {
    "text": "API because if with you when you have distributed systems doing anything over",
    "start": "2259470",
    "end": "2265500"
  },
  {
    "text": "the more tightly coupled RPC style or any kind of POSIX style access and F",
    "start": "2265500",
    "end": "2271380"
  },
  {
    "text": "open or NFC just starts to fall apart so when you're building these larger platforms just treat an object like an",
    "start": "2271380",
    "end": "2277260"
  },
  {
    "start": "2274000",
    "end": "2274000"
  },
  {
    "text": "objects that's why I love the approach that meteor inflow of taken don't be tempted to do things like s3 FS and as",
    "start": "2277260",
    "end": "2284520"
  },
  {
    "text": "with many reinvent talks we release products the week that we deliver the talks and so with newly launched ability",
    "start": "2284520",
    "end": "2292050"
  },
  {
    "text": "sorry many of the newly launched abilities think about the way that you're going to use them and make sure",
    "start": "2292050",
    "end": "2297600"
  },
  {
    "text": "you're being true to the tenants of that architecture as opposed to trying to use",
    "start": "2297600",
    "end": "2302760"
  },
  {
    "text": "the wrong tool for the wrong job so now we've got our assets ingested and stored",
    "start": "2302760",
    "end": "2308010"
  },
  {
    "text": "now we need to actually take them from that quality level and start to process them so processing things faster and",
    "start": "2308010",
    "end": "2315990"
  },
  {
    "text": "scaling in AWS this is a 400 level talk I don't need to teach you to suck eggs",
    "start": "2315990",
    "end": "2321090"
  },
  {
    "text": "so I'll just quickly run through as with anything in cloud computing we can apply those different approaches to scaling",
    "start": "2321090",
    "end": "2327330"
  },
  {
    "text": "first of all you can change the physical size you can make it larger and easy and then you can add more of them you can do",
    "start": "2327330",
    "end": "2334410"
  },
  {
    "text": "horizontal scaling from hen - nn also quite straight Falls but then something that we sometimes forget about",
    "start": "2334410",
    "end": "2341039"
  },
  {
    "text": "is diagonal scaling I don't know if there's a better word for this so please email me afterwards if there is but",
    "start": "2341039",
    "end": "2346349"
  },
  {
    "text": "where you effectively change the type of your instance to fit and be more specialized so I'm going to start with",
    "start": "2346349",
    "end": "2352079"
  },
  {
    "text": "diagonal scaling and just talk about this a little bit so when you think about processing video you will probably",
    "start": "2352079",
    "end": "2359219"
  },
  {
    "text": "say hey you guys just launched elastic GPU that's brilliance let's use that for",
    "start": "2359219",
    "end": "2365219"
  },
  {
    "start": "2360000",
    "end": "2360000"
  },
  {
    "text": "those of you familiar with our g2 or p2 instances the years NVIDIA grid or Nvidia Tesla cards and both of these use",
    "start": "2365219",
    "end": "2372479"
  },
  {
    "text": "an architecture called Kepler now there's different supports for different",
    "start": "2372479",
    "end": "2379439"
  },
  {
    "text": "encodings different decoding 's and different Processing's across different architectures within 4k video and within",
    "start": "2379439",
    "end": "2387869"
  },
  {
    "text": "video at all a lot of video is encoded with h.264 it's a fantastically",
    "start": "2387869",
    "end": "2394259"
  },
  {
    "text": "efficient protocol but 4k tends to be a TBC and what you might notice there is",
    "start": "2394259",
    "end": "2400079"
  },
  {
    "text": "that there is no H EBC support so what this means is today with the elastic GPUs and the P 2 and G 2 instances that",
    "start": "2400079",
    "end": "2406709"
  },
  {
    "text": "we have we can't use that hardware acceleration because we need that for the 4k video component so what can we do",
    "start": "2406709",
    "end": "2414929"
  },
  {
    "text": "instead well you can scale bigger you can go back to the old instances as the",
    "start": "2414929",
    "end": "2421319"
  },
  {
    "text": "the old idea of doing on CPU and scale bigger so I thought I'd actually do some",
    "start": "2421319",
    "end": "2426539"
  },
  {
    "start": "2425000",
    "end": "2425000"
  },
  {
    "text": "benchmarks around this and I wanted to compare a generic instance an m4 large with a very powerful a much larger",
    "start": "2426539",
    "end": "2432839"
  },
  {
    "text": "instance in the same family and I found that there was an order of magnitude difference between these I get a less",
    "start": "2432839",
    "end": "2440369"
  },
  {
    "text": "than a frame per second from a standard m1 m4 Lodge and I got over eight from an m4 18 X Lodge which was great but",
    "start": "2440369",
    "end": "2448439"
  },
  {
    "text": "there's also an order of magnitude difference on the pricing you will be aware that m4 is not CPU optimized and",
    "start": "2448439",
    "end": "2456980"
  },
  {
    "text": "GPU processor sorry video encoding is not particularly memory heavy it's on a",
    "start": "2456980",
    "end": "2462590"
  },
  {
    "text": "frame-by-frame basis and the individual encode doesn't tend to use more than the pixel space of a single image so I",
    "start": "2462590",
    "end": "2469190"
  },
  {
    "text": "thought I'd look at the largest CPU instance and actually while it doesn't think code slightly quite as fast because it has a small",
    "start": "2469190",
    "end": "2475670"
  },
  {
    "text": "slightly lower CPU it does give me a much better price point so if I look at",
    "start": "2475670",
    "end": "2482780"
  },
  {
    "text": "this from justice straight I made up metric names you can see that the 8x large actually works out significantly",
    "start": "2482780",
    "end": "2488630"
  },
  {
    "text": "cheaper for cost per content hour than the m4 18x large it does take slightly",
    "start": "2488630",
    "end": "2495859"
  },
  {
    "text": "longer but if you do a like-for-like comparison it fits in pretty well however having spent a long time of my",
    "start": "2495859",
    "end": "2504770"
  },
  {
    "text": "career long past my career as a admin for the big spark boxes with lots of threads I enjoy things like this there's a lot of",
    "start": "2504770",
    "end": "2511550"
  },
  {
    "text": "threads which is great you can do lots of processing but the interruption of a",
    "start": "2511550",
    "end": "2516950"
  },
  {
    "text": "single process the degradation of a single instance can mean the loss of a job which is incredibly frustrating if",
    "start": "2516950",
    "end": "2524060"
  },
  {
    "text": "you go back to the idea that you can do 8 frames per second and if you're assuming a 60 frame per second file and",
    "start": "2524060",
    "end": "2531470"
  },
  {
    "text": "it's 2 hours long you're gonna have a bad time so what can we do here well the",
    "start": "2531470",
    "end": "2538640"
  },
  {
    "text": "other problem also to keep in mind is that there's that upper limit the largest I could go at that point was C 486 Lodge",
    "start": "2538640",
    "end": "2543980"
  },
  {
    "text": "maybe we launched some new instances this week so we can go higher but you still have that upper limit so that for",
    "start": "2543980",
    "end": "2549770"
  },
  {
    "text": "us leads horizontal scaling and many people know oh yeah I can do horizontal",
    "start": "2549770",
    "end": "2555380"
  },
  {
    "text": "scaling for web workloads I follow shared nothing architecture I've got a really good stateless app that's great",
    "start": "2555380",
    "end": "2560390"
  },
  {
    "text": "but what about from video so first of all let's have a look at what a video file actually is if you take a very",
    "start": "2560390",
    "end": "2568490"
  },
  {
    "start": "2563000",
    "end": "2563000"
  },
  {
    "text": "simplistic block level overview it is effectively a container which contains different data streams coordinated by",
    "start": "2568490",
    "end": "2575330"
  },
  {
    "text": "some metadata you'll typically have one or more video streams and one or more audio streams and that will make up a",
    "start": "2575330",
    "end": "2582020"
  },
  {
    "text": "single file and if we think about the bit that actually takes processing it's just the audio streams and video streams",
    "start": "2582020",
    "end": "2589200"
  },
  {
    "text": "status is easy and the containers can be swapped very easily because there's no encoding so what if we took these",
    "start": "2589200",
    "end": "2595079"
  },
  {
    "text": "sections and split them out and encoded them separately we have one encode to deal with video and one encoded deal",
    "start": "2595079",
    "end": "2600930"
  },
  {
    "text": "with audio okay we've already made life a little bit easier but audio processing",
    "start": "2600930",
    "end": "2606450"
  },
  {
    "text": "is significantly easier dealing with audio processing doesn't win us that much so what more can we do now I won't",
    "start": "2606450",
    "end": "2613920"
  },
  {
    "text": "go into too much detail about the way that a video file is built up but effectively it's lots of still images",
    "start": "2613920",
    "end": "2620280"
  },
  {
    "text": "with occasional keyframes to align those so we can think of it almost like a lot",
    "start": "2620280",
    "end": "2626760"
  },
  {
    "text": "of blocks a lot of chunks so what if we take that one file split it up into many",
    "start": "2626760",
    "end": "2632670"
  },
  {
    "text": "chunks and individually process those because we can actually think about a video file is nothing more than a",
    "start": "2632670",
    "end": "2639480"
  },
  {
    "text": "selection of images with a fancy wrapper random so what we can do is we can",
    "start": "2639480",
    "end": "2644609"
  },
  {
    "start": "2643000",
    "end": "2643000"
  },
  {
    "text": "parallelize the encoding at a chunk by chunk basis first of all we read the file in we decide when to start encoding",
    "start": "2644609",
    "end": "2652910"
  },
  {
    "text": "we then encode for a specific amount of time we output that newly encoded chunk",
    "start": "2652910",
    "end": "2659010"
  },
  {
    "text": "onto a shared file system and then something else groups this all together there's a couple of interesting",
    "start": "2659010",
    "end": "2665430"
  },
  {
    "text": "resources which I've linked at the bottom of the page obviously this will be available on SlideShare later and",
    "start": "2665430",
    "end": "2670460"
  },
  {
    "text": "Netflix have got a great example of how they do video content processing with massive parallelization as well you may",
    "start": "2670460",
    "end": "2678390"
  },
  {
    "text": "notice there said Amazon Amazon EFS or s3 here I recommend the use of a shared file",
    "start": "2678390",
    "end": "2684000"
  },
  {
    "text": "system where possible for the initial read because an F seek again over something like s3 FS is incredibly",
    "start": "2684000",
    "end": "2690810"
  },
  {
    "text": "difficult however the individual outputs can just go straight into s3 or - that collation note now to get us started I",
    "start": "2690810",
    "end": "2699410"
  },
  {
    "start": "2698000",
    "end": "2698000"
  },
  {
    "text": "use the jack of all tools which is a jack-of-all-trades tool which is ffmpeg or AV coms we'll do it just as good from",
    "start": "2699410",
    "end": "2706890"
  },
  {
    "text": "the top to the bottom we say dear ffmpeg please start encoding at this time I input my mezzanine file my high quality",
    "start": "2706890",
    "end": "2714420"
  },
  {
    "text": "to pick a bit file I then say how long I want my chunk to be in my case I've gone",
    "start": "2714420",
    "end": "2719640"
  },
  {
    "text": "for 60 seconds it's really it you can scale this as almost down to a second if you felt the wish to and then",
    "start": "2719640",
    "end": "2726410"
  },
  {
    "text": "i'm using the x265 library for encoding this is output to a TS file a transport",
    "start": "2726410",
    "end": "2732950"
  },
  {
    "text": "stream file which makes it easier for me to group these back together later on so now what I've got is lots of small files",
    "start": "2732950",
    "end": "2739910"
  },
  {
    "text": "and I can easily create a list of these",
    "start": "2739910",
    "end": "2744940"
  },
  {
    "text": "put it on a single node and then on that node use a different filter the concat",
    "start": "2744940",
    "end": "2750590"
  },
  {
    "text": "filter to group all of these back together this is an incredibly cheap operation because the files are already",
    "start": "2750590",
    "end": "2756650"
  },
  {
    "text": "encoded there's very little video processing at this point it's merely concatenating a lots of files together",
    "start": "2756650",
    "end": "2762220"
  },
  {
    "text": "writing the metadata around for the container and outputting that somewhere so I take my many many individual files",
    "start": "2762220",
    "end": "2769400"
  },
  {
    "text": "I group them back into one just larger video stream then I insert that back",
    "start": "2769400",
    "end": "2774440"
  },
  {
    "text": "into the container so I've got it it's brilliant now some of you guys",
    "start": "2774440",
    "end": "2780110"
  },
  {
    "text": "might be looking at this and thinking that sounds familiar taking a big file splitting up into lots",
    "start": "2780110",
    "end": "2785510"
  },
  {
    "text": "of different things processing it and then putting it back together you might be like isn't that the same as Amazon EMR or any kind of MapReduce operation",
    "start": "2785510",
    "end": "2792290"
  },
  {
    "text": "and yeah effectively it is a very very similar approach you take a large",
    "start": "2792290",
    "end": "2797900"
  },
  {
    "text": "difficult to deal with problem split it down into component parts and concatenate it back together you just",
    "start": "2797900",
    "end": "2804650"
  },
  {
    "text": "need to be a bit more careful about doing with this doing this in video I guess in summary really it's it's about",
    "start": "2804650",
    "end": "2810920"
  },
  {
    "start": "2809000",
    "end": "2809000"
  },
  {
    "text": "taking lessons we already know in dealing with other things and applying them to new problems I'd love to get to",
    "start": "2810920",
    "end": "2816230"
  },
  {
    "text": "the point where I have an earmark job itself which handles the coordination especially given some of the releases",
    "start": "2816230",
    "end": "2821450"
  },
  {
    "text": "we've seen over the last couple of weeks driving that innovation within EMR and also don't forget that that paralyzation",
    "start": "2821450",
    "end": "2828290"
  },
  {
    "text": "step will make your life safer and easier when you don't have to worry about one interrupted encoder taking",
    "start": "2828290",
    "end": "2835040"
  },
  {
    "text": "down an entire job Netflix's example is that they have to do many different localizations many different languages",
    "start": "2835040",
    "end": "2841190"
  },
  {
    "text": "and at least ten devices and if that was all being processed through warm workflow if any one of those failed",
    "start": "2841190",
    "end": "2847820"
  },
  {
    "text": "they'd lose all of it so just think about that when you're parallelizing and do it as early as possible",
    "start": "2847820",
    "end": "2853780"
  },
  {
    "text": "so now finally I come to the distribution step now from an Amazon Studios point of view their life is",
    "start": "2853780",
    "end": "2860330"
  },
  {
    "text": "quite easy they only have one person a one person one person they need to distribute to and that's an Amazon video",
    "start": "2860330",
    "end": "2866440"
  },
  {
    "text": "so in their case delivery is the same as ingest and for most production houses",
    "start": "2866440",
    "end": "2871609"
  },
  {
    "text": "delivery is the same as ingest but then they can deliver to Amazon video through",
    "start": "2871609",
    "end": "2876830"
  },
  {
    "text": "an s3 to s3 bucket transfer but also it really helps to be permissive in what",
    "start": "2876830",
    "end": "2883250"
  },
  {
    "text": "you can do here be accepting and always realize that your partner's your upstream are the ones who are actually",
    "start": "2883250",
    "end": "2888410"
  },
  {
    "text": "calling the shots so be flexible user Sparrow use s3 ta and so on because",
    "start": "2888410",
    "end": "2894800"
  },
  {
    "text": "it'll make your life a lot easier but effectively you can reuse a lot of the investment you made in your digital asset management system for ingest to",
    "start": "2894800",
    "end": "2902060"
  },
  {
    "text": "deliver to third parties know the",
    "start": "2902060",
    "end": "2907339"
  },
  {
    "text": "distribution to users again the kind of standard approach is have a CDN use your adaptive delivery more methods have HLS",
    "start": "2907339",
    "end": "2915020"
  },
  {
    "text": "have MPEG DASH whatever it's quite quite straight forwards and it's very similar to what you had in HD now just to level",
    "start": "2915020",
    "end": "2922940"
  },
  {
    "text": "set for a little bit on what adaptive delivery looks like for anybody who isn't familiar typically and this is HLS",
    "start": "2922940",
    "end": "2928820"
  },
  {
    "start": "2927000",
    "end": "2927000"
  },
  {
    "text": "p3 you have a manifest file that manifest file has children manifests",
    "start": "2928820",
    "end": "2933830"
  },
  {
    "text": "which define the chunks for individual quality levels so in my example here I",
    "start": "2933830",
    "end": "2938869"
  },
  {
    "text": "have one at one megabits and one at two megabits and then below I have these individual chunks your player starts",
    "start": "2938869",
    "end": "2946580"
  },
  {
    "text": "playing one back it'll select the top and then keep going through there and it will adaptively choose the right bit",
    "start": "2946580",
    "end": "2951859"
  },
  {
    "text": "rate over time using heuristics built into the player and this is a pretty well-documented very common use case so",
    "start": "2951859",
    "end": "2960980"
  },
  {
    "text": "again as I said it'll start going through select and then switch bit rates as appropriate now for 4k this is harder",
    "start": "2960980",
    "end": "2969530"
  },
  {
    "text": "but not impossible simple lessons are things like keep your content closer to your users but as you if you're using a",
    "start": "2969530",
    "end": "2978589"
  },
  {
    "text": "content delivery network naturally you want it to be cached closer to them but at this point cache width becomes a",
    "start": "2978589",
    "end": "2984589"
  },
  {
    "text": "problem because this can be in two ways first of all if you have sixty three edge locations worldwide and you have a user",
    "start": "2984589",
    "end": "2991550"
  },
  {
    "text": "selecting querying through every single one of those that means you have 63 calls to your origin this week we",
    "start": "2991550",
    "end": "2998630"
  },
  {
    "text": "launched regional edge caches which make the next 15 slides completely redundant but if we didn't what I will be talking",
    "start": "2998630",
    "end": "3004570"
  },
  {
    "text": "about here is this but with those with that wide regional a sorry that wide cache with you do need",
    "start": "3004570",
    "end": "3011380"
  },
  {
    "text": "to think about the origin site but secondly you also need to think about the population for your end users",
    "start": "3011380",
    "end": "3016440"
  },
  {
    "text": "because you're constantly racing to fashion that chunk I mentioned that I'm",
    "start": "3016440",
    "end": "3021880"
  },
  {
    "text": "based in Asia Pacific I live in Singapore we have an AWS region and we've got a cloud from pop which is fantastic however even though the",
    "start": "3021880",
    "end": "3029890"
  },
  {
    "text": "connectivity between s3 and CloudFront is good we haven't yet managed to solve a problem with the speed of light so",
    "start": "3029890",
    "end": "3036220"
  },
  {
    "text": "there's some things that you need to think about while you're dealing with this especially if you're dealing with the country or a group of people with a",
    "start": "3036220",
    "end": "3043540"
  },
  {
    "text": "big diaspora so a good example is if you have content stored in the US but then",
    "start": "3043540",
    "end": "3048730"
  },
  {
    "text": "you have a lot of consumption in the Philippines for every single one of those HTTP requests is incredibly chatty",
    "start": "3048730",
    "end": "3054400"
  },
  {
    "text": "and it's very difficult to ensure that the next chunk has been loaded before it's about to be requested if it's not",
    "start": "3054400",
    "end": "3061000"
  },
  {
    "text": "good quality people will just stop watching and go do something else so how can we get around this how can we keep",
    "start": "3061000",
    "end": "3067000"
  },
  {
    "text": "our content consistently close to all of our users without the worry of content distribution well you could look at",
    "start": "3067000",
    "end": "3075790"
  },
  {
    "text": "doing things like s3 cross region replication but as you may know this can't be changed you can only replicate one level so if I",
    "start": "3075790",
    "end": "3084160"
  },
  {
    "text": "was going to store my content master in Frankfurt and I wanted to change everywhere globally it's simply not",
    "start": "3084160",
    "end": "3089830"
  },
  {
    "text": "possible and the second problem is if I'm using Amazon Cloud France Amazon CloudFront needs to address its origin by name an",
    "start": "3089830",
    "end": "3097260"
  },
  {
    "text": "s3 bucket names can't be duplicated so if I add assets to an XJS tyonne I",
    "start": "3097260",
    "end": "3103450"
  },
  {
    "text": "wouldn't be able to have that same name in many buckets worldwide so what can I",
    "start": "3103450",
    "end": "3108640"
  },
  {
    "text": "do and this is where I want to talk about one of my customers which are not in",
    "start": "3108640",
    "end": "3115280"
  },
  {
    "text": "this room so I can present this slide they've built a way to feed the firehose",
    "start": "3115280",
    "end": "3120530"
  },
  {
    "text": "of content consumption by building mid tier caches they've built strategic layers inside ec2 regions worldwide very",
    "start": "3120530",
    "end": "3128930"
  },
  {
    "text": "similar to the regional edge cache that you will have heard about this week they're doing a little more with it but I'll start with them this is built on",
    "start": "3128930",
    "end": "3135830"
  },
  {
    "text": "ec2 and nginx they're also using lure plus the AWS earth plugin and they pull",
    "start": "3135830",
    "end": "3142460"
  },
  {
    "text": "in using one-time urls files into that they have a wide dedicated EBS cache and",
    "start": "3142460",
    "end": "3148430"
  },
  {
    "text": "this is massively improved their local performance because it's pull based only",
    "start": "3148430",
    "end": "3155330"
  },
  {
    "text": "replicates when needed so you don't have to worry about hey I've got my new file I'll push it out to all of my regions and because they've been clever and they",
    "start": "3155330",
    "end": "3163370"
  },
  {
    "text": "they've implemented it with software that's extensible it gives you the ability to have further logic and be",
    "start": "3163370",
    "end": "3169730"
  },
  {
    "text": "able to do more things so we've got this intelligence in nginx what else could we",
    "start": "3169730",
    "end": "3176480"
  },
  {
    "text": "do to improve that performance so if we look at this model again a stream is",
    "start": "3176480",
    "end": "3182600"
  },
  {
    "text": "really just a collection of chunks it's just a collection of TS files or similar that are pulled sequentially what if we",
    "start": "3182600",
    "end": "3189620"
  },
  {
    "text": "decided to proactively prefetch because we know we're on chunk one now and we're on the lowest bit rate it makes sense",
    "start": "3189620",
    "end": "3195830"
  },
  {
    "text": "that we start on the lowest but that quick channel change that quits playback but then over time we want to go up so",
    "start": "3195830",
    "end": "3201800"
  },
  {
    "text": "what if we start to prefetch those files proactively because we've already got this intelligence layer in place so",
    "start": "3201800",
    "end": "3208990"
  },
  {
    "text": "spool the company I mentioned earlier make a lower sis call from nginx every",
    "start": "3208990",
    "end": "3215270"
  },
  {
    "text": "time a request for content comes in they persist that URL that this requested to",
    "start": "3215270",
    "end": "3221060"
  },
  {
    "text": "a queueing service running locally on the same ec2 instance they could also run that on sqs and then there's aq",
    "start": "3221060",
    "end": "3228650"
  },
  {
    "text": "worker running on each of those mid tier servers which reads the queue builds",
    "start": "3228650",
    "end": "3233840"
  },
  {
    "text": "every possible URL that they would want to request and an execute curl locally",
    "start": "3233840",
    "end": "3238850"
  },
  {
    "text": "against that node this pulls the content in and it improves the performance and because they have the control they say we want",
    "start": "3238850",
    "end": "3246050"
  },
  {
    "text": "various different renditions which all kick off all these requests happen without the user having to do it and",
    "start": "3246050",
    "end": "3252840"
  },
  {
    "text": "this means that by default the end user performance is better because the end users request isn't blocked on these",
    "start": "3252840",
    "end": "3258630"
  },
  {
    "text": "requests coming in because if were pulling in six different segments all at once it enables our customers have a lot",
    "start": "3258630",
    "end": "3264660"
  },
  {
    "text": "more change up and change down so just to put some numbers in from Spall's data",
    "start": "3264660",
    "end": "3270210"
  },
  {
    "text": "thank you very much daniel miller if he is in the audience this is their kind of this is how the data looked when they",
    "start": "3270210",
    "end": "3278370"
  },
  {
    "text": "were doing straights against clarence s3 with a global distribution so again",
    "start": "3278370",
    "end": "3283710"
  },
  {
    "text": "content stored in the US consumption in let's say singapore average is around 8",
    "start": "3283710",
    "end": "3289770"
  },
  {
    "text": "to 9 megabits per second now by adding in this caching layer they were able to",
    "start": "3289770",
    "end": "3297410"
  },
  {
    "text": "mccoshen plus prefetching well you can see that the first file still pulls in at about AIDS",
    "start": "3297410",
    "end": "3303060"
  },
  {
    "text": "the next files the sequential files pull in at a hundred megabits per second in Singapore a place where I have a gig",
    "start": "3303060",
    "end": "3309000"
  },
  {
    "text": "internet for $50 this kind of performance is very important so we can",
    "start": "3309000",
    "end": "3314580"
  },
  {
    "text": "see that they've taken a really intelligent approach of building a system to meet a very specific need but",
    "start": "3314580",
    "end": "3321270"
  },
  {
    "start": "3316000",
    "end": "3316000"
  },
  {
    "text": "then looking at that and saying hey what else can we do how can we be customer obsessed how can we start to do more",
    "start": "3321270",
    "end": "3327030"
  },
  {
    "text": "with the intelligence and logic we have if you have that layer look at something else to do with it and build on top of",
    "start": "3327030",
    "end": "3333240"
  },
  {
    "text": "it so really now to wrap up I've said it",
    "start": "3333240",
    "end": "3339060"
  },
  {
    "start": "3337000",
    "end": "3337000"
  },
  {
    "text": "quite a few times but 4k has the same problems but at a scale where things start to break in ways it simply didn't",
    "start": "3339060",
    "end": "3344430"
  },
  {
    "text": "expect make sure that when you're testing things use the same approaches but start to modify but test with that",
    "start": "3344430",
    "end": "3350760"
  },
  {
    "text": "data of the actual size that you need to we're still building in this space when",
    "start": "3350760",
    "end": "3357540"
  },
  {
    "text": "I present a fork a talk at reinvent mixture I intend to have live video editing and drones on stage but we're",
    "start": "3357540",
    "end": "3364260"
  },
  {
    "text": "about a year off but all of the new trendy stuff aside M&E and video is",
    "start": "3364260",
    "end": "3370770"
  },
  {
    "text": "still quite a traditional in this so it's actually quite difficult to drive that innovation things have to",
    "start": "3370770",
    "end": "3377099"
  },
  {
    "text": "work first and then be innovative and that's where people like Amazon Studios will be able to set away and give people",
    "start": "3377099",
    "end": "3382769"
  },
  {
    "text": "confidence that they can do that innovation so just again to recap the things that I've covered today when you",
    "start": "3382769",
    "end": "3389279"
  },
  {
    "text": "are ingesting things will break at scale so test with data that's actually representative of what you have a look",
    "start": "3389279",
    "end": "3396599"
  },
  {
    "text": "out for API limits look the things that you didn't expect to break and make sure you've done that end-to-end test with files bigger than you ever expected to",
    "start": "3396599",
    "end": "3403559"
  },
  {
    "text": "use for me I still encourage you to keep",
    "start": "3403559",
    "end": "3408900"
  },
  {
    "text": "things API based and avoid trying to treat an object like a file ensure that you're dealing with things in the way",
    "start": "3408900",
    "end": "3414930"
  },
  {
    "text": "that they meant to be and avoid POSIX requirements within your application don't assume that you can do an F open",
    "start": "3414930",
    "end": "3420510"
  },
  {
    "text": "and then I have to see kind of file because it's an incredibly expensive operation in certain cases I don't need",
    "start": "3420510",
    "end": "3429029"
  },
  {
    "text": "to say more than parallelization will help you in many many ways when it comes to processing video contents especially",
    "start": "3429029",
    "end": "3434400"
  },
  {
    "text": "because it mitigates your risk factors and finally feeding the firehose feeding",
    "start": "3434400",
    "end": "3439589"
  },
  {
    "text": "the the consumption can be incredibly difficult but where you can reuse that layer reuse the capabilities and reuse",
    "start": "3439589",
    "end": "3446099"
  },
  {
    "text": "your ability to influence customers for good improve your customer performance first and they'll stay and with that I'd",
    "start": "3446099",
    "end": "3453990"
  },
  {
    "text": "like to thank everybody for coming along and please enjoy your trip home and have a great day",
    "start": "3453990",
    "end": "3461029"
  }
]
[
  {
    "start": "0",
    "end": "84000"
  },
  {
    "text": "welcome I don't know if you've seen the",
    "start": "949",
    "end": "7470"
  },
  {
    "text": "keynote yesterday but we list a product called sage maker to allow you to do a",
    "start": "7470",
    "end": "13219"
  },
  {
    "text": "scalable machine learning on AWS we're",
    "start": "13219",
    "end": "18660"
  },
  {
    "text": "going to be talking about the algorithms that went into sage maker and how we",
    "start": "18660",
    "end": "24240"
  },
  {
    "text": "deal with them and we built them my name is IDO Liberty I'm the principal",
    "start": "24240",
    "end": "30210"
  },
  {
    "text": "scientist and manager of the algorithms group and we want to tell you about all the work that went into Sage make it",
    "start": "30210",
    "end": "36239"
  },
  {
    "text": "algorithms wise in the last year and a half we have Tom fallow Habra here one of our principal engineers who helped",
    "start": "36239",
    "end": "43290"
  },
  {
    "text": "build sage maker we are going to cover",
    "start": "43290",
    "end": "48410"
  },
  {
    "text": "for just for context what sage maker is as a whole and then cover for very",
    "start": "48410",
    "end": "56370"
  },
  {
    "text": "shortly what challenges we see in machine learning and the algorithm space what design we have chosen for our",
    "start": "56370",
    "end": "64260"
  },
  {
    "text": "algorithms and what choices we've made for you and then go over a few infinitely scalable algorithms and I'll",
    "start": "64260",
    "end": "72060"
  },
  {
    "text": "define what infinitely scalable means and then in the end I'll just give you a few examples on how how you can use",
    "start": "72060",
    "end": "78810"
  },
  {
    "text": "those algorithms in Sage major today ok",
    "start": "78810",
    "end": "83780"
  },
  {
    "start": "84000",
    "end": "173000"
  },
  {
    "text": "so first thing what is sage maker so sage maker is a platform that allows you",
    "start": "84350",
    "end": "90360"
  },
  {
    "text": "to do machine learning and really takes the burden off of a lot of what",
    "start": "90360",
    "end": "95490"
  },
  {
    "text": "scientists and engineers do today in production systems that have to do with have to do machine learning and so we",
    "start": "95490",
    "end": "101490"
  },
  {
    "text": "you know our view of machine learning is not different than I guess what most of you already experience which is there's",
    "start": "101490",
    "end": "107939"
  },
  {
    "text": "some exploration phase where scientists or research engineers work with the data",
    "start": "107939",
    "end": "113000"
  },
  {
    "text": "they get insights they design features they have some more exploration",
    "start": "113000",
    "end": "119850"
  },
  {
    "text": "scientific process then there's there are training jobs usually on large amounts of data that contain both the",
    "start": "119850",
    "end": "128819"
  },
  {
    "text": "training of the models themselves as well as hyper Palomita tuning so you might have training jobs simultaneously or one",
    "start": "128819",
    "end": "134159"
  },
  {
    "text": "after the other and once you're done and you have a model you're happy with you really have to go and host it and make",
    "start": "134159",
    "end": "140069"
  },
  {
    "text": "it available to your applications and that usually of course creates more data",
    "start": "140069",
    "end": "145680"
  },
  {
    "text": "which again gets fed into further insights and further exploration and so on and we observe that often times the",
    "start": "145680",
    "end": "155340"
  },
  {
    "text": "quality of the solution is not necessarily how good the single model is but rather how many times you went",
    "start": "155340",
    "end": "160769"
  },
  {
    "text": "through this cycle have more insights understand how what worked what didn't work fix it and do it again and again",
    "start": "160769",
    "end": "165810"
  },
  {
    "text": "again the more times you go around the better and say Jamaica allows you to make that cycle much tighter than it",
    "start": "165810",
    "end": "171989"
  },
  {
    "text": "currently is so let me go through machine learning as a whole right now in",
    "start": "171989",
    "end": "178069"
  },
  {
    "start": "173000",
    "end": "213000"
  },
  {
    "text": "very broad strokes and what what our customers tell us is are their",
    "start": "178069",
    "end": "184379"
  },
  {
    "text": "challenges so machine learning really in",
    "start": "184379",
    "end": "190560"
  },
  {
    "text": "the highest possible level is you take data you compute you compute a model so",
    "start": "190560",
    "end": "198150"
  },
  {
    "text": "data plus compute and you create a function you create a model and that model is is then deployed and used again",
    "start": "198150",
    "end": "204900"
  },
  {
    "text": "it's the most you know so the insult to the whole field and this is like really",
    "start": "204900",
    "end": "211669"
  },
  {
    "text": "too simplistic but when we when we work with our customers you know we most of",
    "start": "211669",
    "end": "218069"
  },
  {
    "text": "them have too much data to be crunched on one machine so they need many machines through the compute and they",
    "start": "218069",
    "end": "223290"
  },
  {
    "text": "want to compute very complicated models and so that becomes a significant",
    "start": "223290",
    "end": "230280"
  },
  {
    "text": "engineering effort as well there are many open source and non open source",
    "start": "230280",
    "end": "236519"
  },
  {
    "text": "software solutions that help you do that this is really just a sample tiny sample",
    "start": "236519",
    "end": "241739"
  },
  {
    "text": "of some of those but each of in every",
    "start": "241739",
    "end": "247139"
  },
  {
    "text": "one of those is a significant and pretty like pretty significant investment",
    "start": "247139",
    "end": "254639"
  },
  {
    "text": "software engineering wise to get this to work but our customers are still somehow",
    "start": "254639",
    "end": "262169"
  },
  {
    "start": "260000",
    "end": "359000"
  },
  {
    "text": "saying that there's something there's something missing and if you talk to the large companies out there",
    "start": "262169",
    "end": "268060"
  },
  {
    "text": "all of them at wrote at least some of their machine learning stack of",
    "start": "268060",
    "end": "273310"
  },
  {
    "text": "themselves and some of them wrote the entire thing from scratch okay and you might understand why this when you talk",
    "start": "273310",
    "end": "280000"
  },
  {
    "text": "when you you look at those numbers so Shahar size are from the vp architecture",
    "start": "280000",
    "end": "285669"
  },
  {
    "text": "of IV digital says that a data warehouse is 100 terabytes we are processing 2",
    "start": "285669",
    "end": "291310"
  },
  {
    "text": "terabytes daily we're running mostly gradient boosted trees ldaa k-means k-means clustering and",
    "start": "291310",
    "end": "299169"
  },
  {
    "text": "collaborate filtering ok this is quite a lot of data and they're doing it very on a very regular",
    "start": "299169",
    "end": "304960"
  },
  {
    "text": "basis data's who has 3 million ad requests a second with a hundred hundred",
    "start": "304960",
    "end": "310449"
  },
  {
    "text": "thousand features per request that's 150 trillion per day feature series and you",
    "start": "310449",
    "end": "317169"
  },
  {
    "text": "know that's not your run-of-the-mill data science problem I completely agree with Bill Simon's the CTO of them of",
    "start": "317169",
    "end": "322240"
  },
  {
    "text": "data Zoo a natural have 160 million events daily in the rimmel pipeline",
    "start": "322240",
    "end": "327669"
  },
  {
    "text": "they're run training over the last 15 days and into completely less than one hour ok there's like and the models are very",
    "start": "327669",
    "end": "335379"
  },
  {
    "text": "big there's more than 100 million features in in a single model and this is valentino for long in their cereal ok",
    "start": "335379",
    "end": "342629"
  },
  {
    "text": "so when you try to deploy systems that have these essays and and need to",
    "start": "342629",
    "end": "351039"
  },
  {
    "text": "operate at that scale the this the the open source software that we talked",
    "start": "351039",
    "end": "357189"
  },
  {
    "text": "about just doesn't quite cut it for you so what are the pain points that they have first is when you have a when you",
    "start": "357189",
    "end": "365979"
  },
  {
    "start": "359000",
    "end": "412000"
  },
  {
    "text": "look when you run a job it's the trade-off that you get on our like time and cost and if you run a job on a",
    "start": "365979",
    "end": "374710"
  },
  {
    "text": "single machine you might be happy with how much it costs but it might take weeks days or weeks to run you might be",
    "start": "374710",
    "end": "382900"
  },
  {
    "text": "able to spin it on a bunch of machines and have a distributed job do the same thing it might conclude in hours or maybe even",
    "start": "382900",
    "end": "390430"
  },
  {
    "text": "minutes but it might be very expensive and so if you look at the Pareto optimal",
    "start": "390430",
    "end": "395740"
  },
  {
    "text": "curve that says like for every hardware configuration that you can create you get some trade-off",
    "start": "395740",
    "end": "402510"
  },
  {
    "text": "between running time and cost that most companies tell us is just not good",
    "start": "402510",
    "end": "408180"
  },
  {
    "text": "enough it's it's either they wanted to go faster or they want it to be cheaper the second thing is model selection",
    "start": "408180",
    "end": "414870"
  },
  {
    "start": "412000",
    "end": "435000"
  },
  {
    "text": "people say you know the high parlament optimization is hard for them especially",
    "start": "414870",
    "end": "420390"
  },
  {
    "text": "because those jobs are expensive right so when they run a job and they want to",
    "start": "420390",
    "end": "426540"
  },
  {
    "text": "tweak the parameters they need to run the exact same job again with slightly different parameters and if it was expensive before running it a hundred",
    "start": "426540",
    "end": "432240"
  },
  {
    "text": "times is a hundred times as expensive incremental training is also a problem",
    "start": "432240",
    "end": "437250"
  },
  {
    "start": "435000",
    "end": "468000"
  },
  {
    "text": "if you in the beginning of the talk I gave the ad roll example they trained on",
    "start": "437250",
    "end": "442410"
  },
  {
    "text": "15 days of data what happens when they get the data for the 16th day they essentially ignore the first and have to",
    "start": "442410",
    "end": "450120"
  },
  {
    "text": "train on the second to the 16th day so days 2 to 4 days 2 to 15 have already",
    "start": "450120",
    "end": "456060"
  },
  {
    "text": "been processed and so if you do incremental training you know 14 out of 15 days you have already trained on so",
    "start": "456060",
    "end": "462870"
  },
  {
    "text": "that's you know that is potentially wasted compute that you could have reused and lastly and maybe probably the",
    "start": "462870",
    "end": "471570"
  },
  {
    "start": "468000",
    "end": "500000"
  },
  {
    "text": "biggest pain point is the production readiness of most of these solutions ok",
    "start": "471570",
    "end": "476660"
  },
  {
    "text": "we know that when you increase the data size or whether you require more",
    "start": "476660",
    "end": "482700"
  },
  {
    "text": "complicated bigger models they become less stable they become more numerically",
    "start": "482700",
    "end": "487740"
  },
  {
    "text": "sensitive they become more you know it's either more data it's it's more prone to be to have anomalies or just things you",
    "start": "487740",
    "end": "495180"
  },
  {
    "text": "haven't considered and those things tend to be hard to make to harden for production services and so if you have",
    "start": "495180",
    "end": "501780"
  },
  {
    "start": "500000",
    "end": "551000"
  },
  {
    "text": "some reasonable level of investment it doesn't matter if your company it's it's one person for one week or a hundred",
    "start": "501780",
    "end": "507540"
  },
  {
    "text": "people for a year there is something that you're happy to do and those often intersect that line well below the",
    "start": "507540",
    "end": "516870"
  },
  {
    "text": "amount of data that you actually have or the complexity of the model that you want so if you say I'm happy to invest",
    "start": "516870",
    "end": "523979"
  },
  {
    "text": "you know I'm happy to have two or three guys working on something for three months and beyond that I'm not happy to you know I'm not happy to",
    "start": "523979",
    "end": "530430"
  },
  {
    "text": "more you your company might have you know I know 20 30 terabytes of data that",
    "start": "530430",
    "end": "535620"
  },
  {
    "text": "you have collected which you cannot use you might only be able to train on like 10 gigabytes because that's what you're",
    "start": "535620",
    "end": "540720"
  },
  {
    "text": "what you could build can handle so you know I think you've collected too much data and you shouldn't say that you",
    "start": "540720",
    "end": "547200"
  },
  {
    "text": "shouldn't say that or you should use different tools so when we started say",
    "start": "547200",
    "end": "554970"
  },
  {
    "start": "551000",
    "end": "591000"
  },
  {
    "text": "Jamaica we decided those challenges are algorithmic challenges the problem is",
    "start": "554970",
    "end": "561060"
  },
  {
    "text": "that the algorithms that we have out there just cannot handle these kind of use cases and we need to really build",
    "start": "561060",
    "end": "568920"
  },
  {
    "text": "something from scratch that could solve all these problems in one fell swoop and",
    "start": "568920",
    "end": "577470"
  },
  {
    "text": "so in the in the next section of the talk I'm just going to talk about design principles in the architecture of kind",
    "start": "577470",
    "end": "584070"
  },
  {
    "text": "of the data flow of our algorithms I'm not going to talk about any of the specific algorithms just yet okay so",
    "start": "584070",
    "end": "589200"
  },
  {
    "text": "this is this section the first design choice to remain is we said algorithms",
    "start": "589200",
    "end": "596760"
  },
  {
    "start": "591000",
    "end": "713000"
  },
  {
    "text": "are all of infinitely scalable algorithms are all streaming okay that",
    "start": "596760",
    "end": "602160"
  },
  {
    "text": "means that they see the data once they expect to see every data point once",
    "start": "602160",
    "end": "607760"
  },
  {
    "text": "changed some internal state and then never expect to see that data point again not only that their state is",
    "start": "607760",
    "end": "615300"
  },
  {
    "text": "finite and fixed in size so it doesn't matter how much data you strip with",
    "start": "615300",
    "end": "621450"
  },
  {
    "text": "these teams extremes to the algorithm that state that data structure is not",
    "start": "621450",
    "end": "628170"
  },
  {
    "text": "going to grow all right so the your mental model of this algorithm should be",
    "start": "628170",
    "end": "633870"
  },
  {
    "text": "I see some piece of data or some mini batch of data I change my internal representation of",
    "start": "633870",
    "end": "639360"
  },
  {
    "text": "what my state should be and I move on I forget it and move on ok this this makes",
    "start": "639360",
    "end": "649430"
  },
  {
    "text": "this has a lot of advantages but I want to say before I before I go into the",
    "start": "649430",
    "end": "655920"
  },
  {
    "text": "advantages I want to say that if you haven't thought about algorithms running in this mode you should think about",
    "start": "655920",
    "end": "661829"
  },
  {
    "text": "because it's fascinating you could do a lot of really interesting things but there are a lot of basic things you cannot do for example just",
    "start": "661829",
    "end": "668410"
  },
  {
    "text": "give if your data is just a bunch of numbers you cannot compute their median okay and if you you know you can pretty",
    "start": "668410",
    "end": "674500"
  },
  {
    "text": "much convince yourself that in this model you cannot compute the median because to compute the median you have to store all the numbers sort and take",
    "start": "674500",
    "end": "681040"
  },
  {
    "text": "the middle one right but you cannot sort if you don't have the data right if you",
    "start": "681040",
    "end": "686110"
  },
  {
    "text": "your memory is one megabyte and I stream a terabyte of data through that algorithm then you cannot sort right so",
    "start": "686110",
    "end": "693400"
  },
  {
    "text": "the question is how can you approximate the median and if you haven't you know try to think about it this is like a",
    "start": "693400",
    "end": "698529"
  },
  {
    "text": "take home you know brain twister okay",
    "start": "698529",
    "end": "705390"
  },
  {
    "text": "but you still can't if you you know there is new research to show that you can do a lot of these things",
    "start": "705390",
    "end": "711000"
  },
  {
    "text": "surprisingly accurately okay the the engineering advantage of course is",
    "start": "711000",
    "end": "716230"
  },
  {
    "start": "713000",
    "end": "746000"
  },
  {
    "text": "amazing right so the data the memory footprint of algorithms are going to be fixed it doesn't matter if it's the",
    "start": "716230",
    "end": "721990"
  },
  {
    "text": "first or the hundreds gigabyte the you stream to the algorithm the memory footprint is going to be exactly the",
    "start": "721990",
    "end": "727480"
  },
  {
    "text": "same moreover the run time in the cost are going to be exactly near with the amount",
    "start": "727480",
    "end": "732520"
  },
  {
    "text": "of data right so if you trained on a tell by the data and it cost you twelve bucks if you use another tell about it",
    "start": "732520",
    "end": "739150"
  },
  {
    "text": "it cost you exactly twelve bucks more it's now going to explode it's not going to behave in some weird way okay it's",
    "start": "739150",
    "end": "744820"
  },
  {
    "text": "really important the next thing is incremental training this was a picture",
    "start": "744820",
    "end": "750130"
  },
  {
    "start": "746000",
    "end": "801000"
  },
  {
    "text": "before right used to be fit you had days I'd say it's days one and two and then",
    "start": "750130",
    "end": "755140"
  },
  {
    "text": "two and three the way you can do it now is you can take days one and two and",
    "start": "755140",
    "end": "761470"
  },
  {
    "text": "when you're done with training just persist the state just save it serialize it and when you get the data for the",
    "start": "761470",
    "end": "767830"
  },
  {
    "text": "third day just DISA realize the state you know restart the machine to exactly",
    "start": "767830",
    "end": "774339"
  },
  {
    "text": "where it was before and and process day number three so the advantage of course",
    "start": "774339",
    "end": "779440"
  },
  {
    "text": "is that you've saved compute because now you don't have to retrain on day number two but there's another advantage now",
    "start": "779440",
    "end": "785470"
  },
  {
    "text": "your machine learning model actually consists of days one two and three you don't really have to choose how far back",
    "start": "785470",
    "end": "790930"
  },
  {
    "text": "you go you just trained on all of the history so it's both faster and cheaper",
    "start": "790930",
    "end": "796990"
  },
  {
    "text": "more accurate okay so it's a slam-dunk but this wasn't enough we said we okay",
    "start": "796990",
    "end": "803920"
  },
  {
    "text": "they're streaming that's good but they still need to be more efficient so the first thing we did we said okay all our",
    "start": "803920",
    "end": "809290"
  },
  {
    "text": "algorithms are going to be able to work both on CPU and GPU and whenever you run them on a GPU machine we'll try to take as much as an advantage as you can from",
    "start": "809290",
    "end": "816279"
  },
  {
    "text": "that machine and reduce your running time the next thing is distribution",
    "start": "816279",
    "end": "821740"
  },
  {
    "start": "819000",
    "end": "856000"
  },
  {
    "text": "right so now the obvious next step is to say you know I this you know because of",
    "start": "821740",
    "end": "829540"
  },
  {
    "text": "algorithms scale exactly linearly if I",
    "start": "829540",
    "end": "835959"
  },
  {
    "text": "give each machine a third of the data it would run in a third of the time pinyon right three times faster which of course",
    "start": "835959",
    "end": "842890"
  },
  {
    "text": "we support and we allow you to do that but the obvious problem with that is",
    "start": "842890",
    "end": "848800"
  },
  {
    "text": "that the state that each machine has might diverge right and so once you you're done training you're not in",
    "start": "848800",
    "end": "854800"
  },
  {
    "text": "exactly sure what to do so we've actually have we actually have a another",
    "start": "854800",
    "end": "860560"
  },
  {
    "start": "856000",
    "end": "894000"
  },
  {
    "text": "component of this thing that that creates a shared State it's another set",
    "start": "860560",
    "end": "866829"
  },
  {
    "text": "of processes that's their whole job is to make sure that there is a global state that all these machine share and",
    "start": "866829",
    "end": "873790"
  },
  {
    "text": "so their local state is almost fully synchronized with with the global state",
    "start": "873790",
    "end": "879250"
  },
  {
    "text": "and each machine just does something very simple it just sees the data batch",
    "start": "879250",
    "end": "884560"
  },
  {
    "text": "and command changes the local state in the in the in the shared state the parameter servers is synchronized as it",
    "start": "884560",
    "end": "892390"
  },
  {
    "text": "all with the different machines what you get is that if you had that Pareto",
    "start": "892390",
    "end": "897520"
  },
  {
    "text": "optimal curve of performance you could before then we see significantly improved performance in terms of cost",
    "start": "897520",
    "end": "903790"
  },
  {
    "text": "versus running time and by the way all these when I when I plot these things",
    "start": "903790",
    "end": "908950"
  },
  {
    "text": "you have to remember that this is for a given level of accuracy okay if you're not required to keep the same accuracy I",
    "start": "908950",
    "end": "914980"
  },
  {
    "text": "can be very fast I can just say you know just give you a blank model you know so",
    "start": "914980",
    "end": "920860"
  },
  {
    "text": "this you know you have to always keep in mind that you know you want to be you want to play fair and make sure that you",
    "start": "920860",
    "end": "926199"
  },
  {
    "text": "you get to a specific accuracy and then see how much kostyan how long it took it to run the",
    "start": "926199",
    "end": "933529"
  },
  {
    "start": "932000",
    "end": "980000"
  },
  {
    "text": "last design choice we've made is you",
    "start": "933529",
    "end": "938930"
  },
  {
    "text": "know we because we because we assume",
    "start": "938930",
    "end": "944540"
  },
  {
    "text": "this one pass model we know that we can ingest Kinesis dreams as input streams",
    "start": "944540",
    "end": "951949"
  },
  {
    "text": "right and so if your model if you're not happy with the parameters you've set in the beginning if your data is on 1 X 3",
    "start": "951949",
    "end": "959420"
  },
  {
    "text": "you can rerun the training but if your data is a camisa stream you cannot go back and say you know give me the entire",
    "start": "959420",
    "end": "964999"
  },
  {
    "text": "truth it doesn't exist anymore it just gone right and so we want to make sure that from the state that you have you",
    "start": "964999",
    "end": "971059"
  },
  {
    "text": "can actually generate a lot of different models you can do some of that exploration post training ok",
    "start": "971059",
    "end": "977360"
  },
  {
    "text": "and not only pre training which of course gives you the added advantage and",
    "start": "977360",
    "end": "983689"
  },
  {
    "start": "980000",
    "end": "1033000"
  },
  {
    "text": "when you do hyper parameter optimization you don't the picture doesn't look like that you don't reprocess the single sink",
    "start": "983689",
    "end": "989480"
  },
  {
    "text": "that twice you can actually finish the training and then take the state and generate a few different models just to",
    "start": "989480",
    "end": "995930"
  },
  {
    "text": "give you an example when you do clustering usually you have to choose the number of clusters ahead of time",
    "start": "995930",
    "end": "1001660"
  },
  {
    "text": "with our implementation of clustering you just say I want up to 500 clusters",
    "start": "1001660",
    "end": "1006699"
  },
  {
    "text": "say and when you're done you can say ok does you know please generate a model with 100 ok and see how that works for",
    "start": "1006699",
    "end": "1014379"
  },
  {
    "text": "you if that's good enough great if not maybe I should try 200 right and all of those could be possible from that state",
    "start": "1014379",
    "end": "1021819"
  },
  {
    "text": "and I want to say it doesn't just pick the first 100 or first 200 that's not that doesn't give you actually a good",
    "start": "1021819",
    "end": "1027130"
  },
  {
    "text": "solution if you ask for 100 200 dollars of process actually those are probably not overlap at all and the last thing",
    "start": "1027130",
    "end": "1035380"
  },
  {
    "start": "1033000",
    "end": "1076000"
  },
  {
    "text": "that we get is because we have decided to work in this unified framework we can",
    "start": "1035380",
    "end": "1040899"
  },
  {
    "text": "abstract away most of the heavy lifting for algorithms into a very thick SDK",
    "start": "1040899",
    "end": "1048220"
  },
  {
    "text": "that we have and we are able to actually have each one of the algorithms be",
    "start": "1048220",
    "end": "1053520"
  },
  {
    "text": "relatively small in in terms of amount of code and we are able to run kind of",
    "start": "1053520",
    "end": "1061330"
  },
  {
    "text": "develop on a dev desktop on a kind of CPU machine and containerized and run it on a distribute",
    "start": "1061330",
    "end": "1068350"
  },
  {
    "text": "the GPU environment in sage maker pretty much right there with all the testing and regressions and everything already",
    "start": "1068350",
    "end": "1075160"
  },
  {
    "text": "happening all right what you get is this production ready environment not only",
    "start": "1075160",
    "end": "1082150"
  },
  {
    "start": "1076000",
    "end": "1098000"
  },
  {
    "text": "from the algorithms but also from Sage Maker that once you get it to run essentially it just runs if it ran on a",
    "start": "1082150",
    "end": "1089890"
  },
  {
    "text": "gigabyte of data it will run on a terabyte on 100 terabytes I mean as long as you keep it running it will run okay",
    "start": "1089890",
    "end": "1097740"
  },
  {
    "text": "so these are these were the design principles that we that we chose I want",
    "start": "1098950",
    "end": "1104980"
  },
  {
    "text": "to go into the actual algorithms that you would have in if you log into sage",
    "start": "1104980",
    "end": "1110770"
  },
  {
    "text": "maker today yeah let's let's go into",
    "start": "1110770",
    "end": "1117520"
  },
  {
    "text": "that unfortunately I will not be able to go very deep into exactly how everything works I hope to live for at least a few",
    "start": "1117520",
    "end": "1124180"
  },
  {
    "text": "minutes for questions later",
    "start": "1124180",
    "end": "1127080"
  },
  {
    "start": "1125000",
    "end": "1175000"
  },
  {
    "text": "all right the first time derivative is linear",
    "start": "1138210",
    "end": "1143650"
  },
  {
    "text": "regression and linear classification both very simple models but maybe",
    "start": "1143650",
    "end": "1151870"
  },
  {
    "text": "because of the simplicity and the way that because we know pretty much everything there is to know about them they're very they're very useful and",
    "start": "1151870",
    "end": "1161290"
  },
  {
    "text": "very common what we've done with what",
    "start": "1161290",
    "end": "1167110"
  },
  {
    "text": "we've done with linear regression and with binary classification is we've",
    "start": "1167110",
    "end": "1173260"
  },
  {
    "text": "decided we notice that that people don't we notice that people actually don't",
    "start": "1173260",
    "end": "1180400"
  },
  {
    "text": "usually optimize for the things that they really care about so with linear regression or with the linear classification people use hinge loss or",
    "start": "1180400",
    "end": "1186760"
  },
  {
    "text": "square loss or log loss but what they really care about is a you see zero one loss was just a mistake number of",
    "start": "1186760",
    "end": "1192610"
  },
  {
    "text": "mistakes or some F one measure okay what we do for what we do internally in sage",
    "start": "1192610",
    "end": "1199870"
  },
  {
    "text": "maker is we will train on a bunch of different on a bunch of different regularization loss functions and",
    "start": "1199870",
    "end": "1207630"
  },
  {
    "text": "different settings of the algorithm itself including in different learning rates and so on and we do this all",
    "start": "1207630",
    "end": "1213850"
  },
  {
    "text": "internally in GPU so that is super efficient so it's actually not much less efficient to just training one model and",
    "start": "1213850",
    "end": "1220120"
  },
  {
    "text": "by the end of the process when you just try to fit for your if you're trying to get good AUC or if you're trying to get",
    "start": "1220120",
    "end": "1226810"
  },
  {
    "text": "good mistake out or some F one measure then we do that by taking linear",
    "start": "1226810",
    "end": "1234310"
  },
  {
    "text": "combinations of those models some of it's much more efficient okay so if you",
    "start": "1234310",
    "end": "1241540"
  },
  {
    "start": "1239000",
    "end": "1293000"
  },
  {
    "text": "look at what what happens when you run sage make it in regression or classification in terms of accuracy we",
    "start": "1241540",
    "end": "1251040"
  },
  {
    "text": "match almost everywhere the type of",
    "start": "1251040",
    "end": "1256540"
  },
  {
    "text": "accuracy that we could get from other tools our algorithm requires is",
    "start": "1256540",
    "end": "1262360"
  },
  {
    "text": "essentially zero training is zero or tweaking kind of worked out of the box",
    "start": "1262360",
    "end": "1267720"
  },
  {
    "text": "and for the same running time you look at the right so again this is",
    "start": "1267720",
    "end": "1272860"
  },
  {
    "text": "the plot that we said there's a running time on the on the bottom and cost on the on the on the y axis for the if",
    "start": "1272860",
    "end": "1280510"
  },
  {
    "text": "you're trying to shoot for a five-minute running time ballpark then you get a get",
    "start": "1280510",
    "end": "1286750"
  },
  {
    "text": "a 40 cents on the dollar saving just for running in sage maker the next algorithm",
    "start": "1286750",
    "end": "1294880"
  },
  {
    "start": "1293000",
    "end": "1404000"
  },
  {
    "text": "is factorization machines in factorization machines it's a generalization of linear regression in",
    "start": "1294880",
    "end": "1300910"
  },
  {
    "text": "the sense that in linear regression usually you are you you can think about",
    "start": "1300910",
    "end": "1307330"
  },
  {
    "text": "it as as assigning a weight for each feature in the factorization machines you're actually assigning a full k",
    "start": "1307330",
    "end": "1314170"
  },
  {
    "text": "dimensional vector for each feature and then your prediction is of this form it's the sum of all interactions and dot",
    "start": "1314170",
    "end": "1320890"
  },
  {
    "text": "products of those features in the in the example that you have plus a linear plus",
    "start": "1320890",
    "end": "1327340"
  },
  {
    "text": "a linear term so if you get if you put if you set all the VIS and V J's to 0",
    "start": "1327340",
    "end": "1333310"
  },
  {
    "text": "you get the linear model okay so this is a generalization of that the best tool that we know about the most common tool",
    "start": "1333310",
    "end": "1340060"
  },
  {
    "text": "that we use for factorization machines could only work on one machine so what we're showing you here is that not only",
    "start": "1340060",
    "end": "1346600"
  },
  {
    "text": "do we match the accuracy when you kind of compare in inflow put when compare",
    "start": "1346600",
    "end": "1351910"
  },
  {
    "text": "log loss and f1 score we are as accurate as as the other solution but we also",
    "start": "1351910",
    "end": "1358540"
  },
  {
    "text": "scale completely linearly so on the right hand side you see the running time when you train on all the way from 10 to",
    "start": "1358540",
    "end": "1365410"
  },
  {
    "text": "50 machines and you see exactly almost exactly a five times speed-up okay so",
    "start": "1365410",
    "end": "1370780"
  },
  {
    "text": "you get the same performance and same speed on a single machine but then infinite scaling on the number of",
    "start": "1370780",
    "end": "1376750"
  },
  {
    "text": "machines okay and by the way this is I",
    "start": "1376750",
    "end": "1382720"
  },
  {
    "text": "know if you'll see on the left hand side training on a terabyte of advertising data which is not usually not an easy",
    "start": "1382720",
    "end": "1393790"
  },
  {
    "text": "task here cost us on Sage maker roughly somewhere between eighty and a hundred",
    "start": "1393790",
    "end": "1399160"
  },
  {
    "text": "dollars okay this is in computing it's not a huge amount",
    "start": "1399160",
    "end": "1405650"
  },
  {
    "start": "1404000",
    "end": "1433000"
  },
  {
    "text": "k-means in k-means you're you're expected to find centers for points we",
    "start": "1405650",
    "end": "1412650"
  },
  {
    "text": "have points in high dimensional space these excise and you're expected to find centers mu J here and the measure of",
    "start": "1412650",
    "end": "1420780"
  },
  {
    "text": "error is the average squared distance or the just the sum of squared distances from every point to its closest center",
    "start": "1420780",
    "end": "1427440"
  },
  {
    "text": "okay it's a very common thing probably one of the most common clustering algorithms the best known solution for",
    "start": "1427440",
    "end": "1437100"
  },
  {
    "start": "1433000",
    "end": "1547000"
  },
  {
    "text": "that is the Lord's algorithm it's an iterative Ian type algorithm",
    "start": "1437100",
    "end": "1443870"
  },
  {
    "text": "unfortunately it's a batch process you have to have the data in memory there's there's hundreds actually thousands of",
    "start": "1443870",
    "end": "1451260"
  },
  {
    "text": "publications on k-means and making more efficient including some of mine unfortunately we came into this problem",
    "start": "1451260",
    "end": "1457230"
  },
  {
    "text": "we figured when we try to match the accuracy of lloyd's with the performance",
    "start": "1457230",
    "end": "1462990"
  },
  {
    "text": "of the streaming algorithms we found that the rest we couldn't really find one of the published variants that that",
    "start": "1462990",
    "end": "1468930"
  },
  {
    "text": "actually does that and we had to redesign the algorithm from scratch to be both provably correct to work in one",
    "start": "1468930",
    "end": "1475920"
  },
  {
    "text": "pass and produce empirically produce good results as good as slow it's by the way k-means is a it's computationally",
    "start": "1475920",
    "end": "1484290"
  },
  {
    "text": "like provably computationally hard problems so there's you can like you can probably solve it you can only",
    "start": "1484290",
    "end": "1489840"
  },
  {
    "text": "approximate a solution and so if we compare the solution of k-means to the",
    "start": "1489840",
    "end": "1495630"
  },
  {
    "text": "best iterative algorithm we see that it actually matches all the accuracies on",
    "start": "1495630",
    "end": "1501420"
  },
  {
    "text": "on the left hand side so this is sum of squared distances and it matches those",
    "start": "1501420",
    "end": "1507660"
  },
  {
    "text": "accuracies on the instances we were actually able to run some other solution if you try to run on if we try to run it",
    "start": "1507660",
    "end": "1514350"
  },
  {
    "text": "on 127 gigabytes of memory with 500 clusters we just couldn't get other",
    "start": "1514350",
    "end": "1519630"
  },
  {
    "text": "solutions to work they just crapped out on us okay our algorithm had no problem with it on",
    "start": "1519630",
    "end": "1529110"
  },
  {
    "text": "the right hand side is actually a different algorithm it's the fastest algorithm we could find outside of sage",
    "start": "1529110",
    "end": "1534330"
  },
  {
    "text": "maker and you can see that for the same for when we try for different values of",
    "start": "1534330",
    "end": "1540640"
  },
  {
    "text": "K different values of numbers of classes our algorithm runs roughly 10 times faster PCA PCA is probably the oldest",
    "start": "1540640",
    "end": "1553240"
  },
  {
    "start": "1547000",
    "end": "1586000"
  },
  {
    "text": "workhorse of data mining and machine learning and unsupervised machine",
    "start": "1553240",
    "end": "1558430"
  },
  {
    "text": "learning it's used for dimension reduction for signal denoising it's been",
    "start": "1558430",
    "end": "1564070"
  },
  {
    "text": "around since the early 19th century le yeah no it's been around for long times",
    "start": "1564070",
    "end": "1572890"
  },
  {
    "text": "like Pearson correlation you can you can think that that's essentially that so",
    "start": "1572890",
    "end": "1580210"
  },
  {
    "text": "the question is how how to compute PCA quickly and efficiently again this is",
    "start": "1580210",
    "end": "1588250"
  },
  {
    "start": "1586000",
    "end": "1656000"
  },
  {
    "text": "something that I myself spent a long time researching this is surprised",
    "start": "1588250",
    "end": "1593920"
  },
  {
    "text": "there's some surprising results there when you do it with sage maker today you",
    "start": "1593920",
    "end": "1600250"
  },
  {
    "text": "were we're actually able to accelerate this algorithm in a very significant way there is all both the deterministic and",
    "start": "1600250",
    "end": "1605890"
  },
  {
    "text": "a randomized version of our algorithm available for you the randomized one is slightly less accurate but way but",
    "start": "1605890",
    "end": "1611950"
  },
  {
    "text": "faster and you can see that even the slower algorithm that we have is significantly faster more than 10 times",
    "start": "1611950",
    "end": "1618430"
  },
  {
    "text": "way more than 10 times faster than the best out of the solution that we can find and it costs like cents on the",
    "start": "1618430",
    "end": "1625210"
  },
  {
    "text": "dollar compute twice if you look at the right it just shows you the linear the",
    "start": "1625210",
    "end": "1630480"
  },
  {
    "text": "almost perfect scalability horizontally so if you look at the megabytes per",
    "start": "1630480",
    "end": "1636880"
  },
  {
    "text": "second per machine if I run the randomized algorithm it gets slightly more than 100 megabytes per second per",
    "start": "1636880",
    "end": "1642310"
  },
  {
    "text": "machine and it doesn't matter if you spin up eight or 10 or 20 machines it just remains the same the best we could",
    "start": "1642310",
    "end": "1649840"
  },
  {
    "text": "get out of the competition was about slightly less than 10",
    "start": "1649840",
    "end": "1655350"
  },
  {
    "start": "1656000",
    "end": "1746000"
  },
  {
    "text": "newald topic modeling topic modeling as a whole has to do with finding assigning",
    "start": "1658679",
    "end": "1668750"
  },
  {
    "text": "a science of creating topics topics are distributions over words and and then",
    "start": "1668750",
    "end": "1676620"
  },
  {
    "text": "describing documents as distribution over topics okay so let me give you an",
    "start": "1676620",
    "end": "1682919"
  },
  {
    "text": "example if you have if you have a an article about you know football injuries",
    "start": "1682919",
    "end": "1688230"
  },
  {
    "text": "it might be you know you might be a mix of topic about medicine or injuries and",
    "start": "1688230",
    "end": "1695760"
  },
  {
    "text": "you know sports okay and given a corpus",
    "start": "1695760",
    "end": "1700830"
  },
  {
    "text": "of a corpus of text the the the goal is to find those topics and to model the",
    "start": "1700830",
    "end": "1707100"
  },
  {
    "text": "data this way by the way texts and documents is you know could be replaced with pretty much any set of tokens it",
    "start": "1707100",
    "end": "1713490"
  },
  {
    "text": "doesn't have to be texting could people do today noel top topic modeling on images on many different things but kind",
    "start": "1713490",
    "end": "1719970"
  },
  {
    "text": "of the mental model of texas is not a bad one and when you when you train a",
    "start": "1719970",
    "end": "1725669"
  },
  {
    "text": "neural tapa so when you train on normal topic modeling on this data set and this",
    "start": "1725669",
    "end": "1732000"
  },
  {
    "text": "is just an example it actually works for most data sets that we've tried you get significant lifts in terms of log loss",
    "start": "1732000",
    "end": "1738840"
  },
  {
    "text": "so you actually get more accurate models than you could otherwise and still work in this environment that I taught you on",
    "start": "1738840",
    "end": "1746360"
  },
  {
    "start": "1746000",
    "end": "1817000"
  },
  {
    "text": "the last item in this part of the talk is timeseriesforecasting this is an",
    "start": "1746360",
    "end": "1753360"
  },
  {
    "text": "algorithm that we have used internally in amazon for a long time for forecasting a lot of different things",
    "start": "1753360",
    "end": "1759179"
  },
  {
    "text": "you can imagine you know getting stuff to your doorstep in time requires a lot",
    "start": "1759179",
    "end": "1765750"
  },
  {
    "text": "of different forecasting is having the items and you know the the traffic like everything needs to be kind of you have",
    "start": "1765750",
    "end": "1772500"
  },
  {
    "text": "to figure out a lot of things and you have to be able to forecast a lot of things the the most straightforward",
    "start": "1772500",
    "end": "1780270"
  },
  {
    "text": "competitor to the kinds of algorithm that we are releasing it's actually",
    "start": "1780270",
    "end": "1785399"
  },
  {
    "text": "available in our but we were not able to run it on the largest examples and we're pretty consistently",
    "start": "1785399",
    "end": "1793020"
  },
  {
    "text": "more accurate than what you could get with other algorithms by the way if you look at the large prediction job at like",
    "start": "1793020",
    "end": "1800160"
  },
  {
    "text": "180 times sequence 180 K time sequences that couldn't be run on our here with",
    "start": "1800160",
    "end": "1809340"
  },
  {
    "text": "sage make it's roughly 1 hour and a p2 instance which you cost roughly of $1",
    "start": "1809340",
    "end": "1814550"
  },
  {
    "text": "now that I would also say that except",
    "start": "1814550",
    "end": "1820170"
  },
  {
    "start": "1817000",
    "end": "1839000"
  },
  {
    "text": "for algorithms that work in this model we have a few more great algorithms that we decided to put in because customers",
    "start": "1820170",
    "end": "1826620"
  },
  {
    "text": "said that they wanted to have them and you know the fact that an algorithm is not streaming is not infinitely scalable",
    "start": "1826620",
    "end": "1833070"
  },
  {
    "text": "doesn't mean it's not great and it's not usable in fact some of the best algorithms that we have don't work in",
    "start": "1833070",
    "end": "1839040"
  },
  {
    "start": "1839000",
    "end": "1870000"
  },
  {
    "text": "this way so first of all we've included special LD a it's it's another topic",
    "start": "1839040",
    "end": "1845370"
  },
  {
    "text": "modeling algorithm that should work again more than ten times faster on",
    "start": "1845370",
    "end": "1851240"
  },
  {
    "text": "medium to medium type medium-sized datasets and that's the same algorithm",
    "start": "1851240",
    "end": "1858360"
  },
  {
    "text": "you be you know you'd be able to use this algorithm also as a part of",
    "start": "1858360",
    "end": "1864510"
  },
  {
    "text": "comprehend which is another service for text analytics that we've released yesterday the next is X G boosts one of",
    "start": "1864510",
    "end": "1872730"
  },
  {
    "start": "1870000",
    "end": "1913000"
  },
  {
    "text": "the most commonly used algorithms for for decision trees out there it's it's",
    "start": "1872730",
    "end": "1879570"
  },
  {
    "text": "available as a part of sage maker and we",
    "start": "1879570",
    "end": "1885840"
  },
  {
    "text": "actually worked quite a lot to optimize it for you make sure it runs on the right instances that communication is",
    "start": "1885840",
    "end": "1891630"
  },
  {
    "text": "optimized the distribution is done correctly and so you see here we'll just",
    "start": "1891630",
    "end": "1896730"
  },
  {
    "text": "measure the running time and the throughput that we get out of 64 c48 a",
    "start": "1896730",
    "end": "1902190"
  },
  {
    "text": "text large machines and you get roughly 1.3 gigabyte per second that's just not",
    "start": "1902190",
    "end": "1909740"
  },
  {
    "text": "unimpressive in my opinion the next one is sequence to sequence so",
    "start": "1909740",
    "end": "1919330"
  },
  {
    "start": "1913000",
    "end": "1972000"
  },
  {
    "text": "it's based off of Sakai which is a project for doing machine translation",
    "start": "1919330",
    "end": "1925419"
  },
  {
    "text": "it's an open-source project for doing machine translation we have an Italian implementation of it an integration of",
    "start": "1925419",
    "end": "1931840"
  },
  {
    "text": "it into into a into sage maker you see",
    "start": "1931840",
    "end": "1937690"
  },
  {
    "text": "that when you use when use our sequence to sequence pretty much out the box on",
    "start": "1937690",
    "end": "1944730"
  },
  {
    "text": "on a translation data from English to German after a few hours you pretty much",
    "start": "1944730",
    "end": "1950470"
  },
  {
    "text": "converge to the best possible the best known result the best publish result which is this in terms of the Blue",
    "start": "1950470",
    "end": "1955809"
  },
  {
    "text": "Square it's kind of the standard measurement of translation quality I",
    "start": "1955809",
    "end": "1961590"
  },
  {
    "text": "want to say also that you know it also lets you kind of tweak the algorithm and choose either RNA or CNN is any",
    "start": "1961590",
    "end": "1969520"
  },
  {
    "text": "coordinate decoders and the last algorithm that I'll be talking about is",
    "start": "1969520",
    "end": "1976000"
  },
  {
    "start": "1972000",
    "end": "2091000"
  },
  {
    "text": "the is image specification a lot of you a lot of our customers said that they",
    "start": "1976000",
    "end": "1981490"
  },
  {
    "text": "have image data that they want to work with and while there all of these",
    "start": "1981490",
    "end": "1986760"
  },
  {
    "text": "publications and you know there's these open sources and so on that lets you",
    "start": "1986760",
    "end": "1994240"
  },
  {
    "text": "feature eyes images and so on they're not quite as available as they would have wanted okay and so we've",
    "start": "1994240",
    "end": "2001169"
  },
  {
    "text": "implemented resonate in this framework we're going to include more standard",
    "start": "2001169",
    "end": "2007679"
  },
  {
    "text": "networks coming soon such as Denson ed in Inception and maybe others and so you",
    "start": "2007679",
    "end": "2017010"
  },
  {
    "text": "can now essentially use those things out of the box take image data and train on it directly with your labels in sage",
    "start": "2017010",
    "end": "2024120"
  },
  {
    "text": "maker today you want to say that one of the coolest feature about this algorithm",
    "start": "2024120",
    "end": "2029190"
  },
  {
    "text": "is that it comes with the ability to transfer transfer learning out the gate",
    "start": "2029190",
    "end": "2034890"
  },
  {
    "text": "most of the you know in many cases I should say you don't have enough quite",
    "start": "2034890",
    "end": "2040230"
  },
  {
    "text": "enough labeled images to to train a great classifier those those are complex",
    "start": "2040230",
    "end": "2046110"
  },
  {
    "text": "models require 100 or sorry millions sometimes at least tens of thousands of images and if you",
    "start": "2046110",
    "end": "2054480"
  },
  {
    "text": "don't have enough your knowledge it's not going to converge right so what we've done is we've actually created a pre trained models on pre-trained",
    "start": "2054480",
    "end": "2061860"
  },
  {
    "text": "network on imagenet which is one of the largest classified image data sets out",
    "start": "2061860",
    "end": "2069510"
  },
  {
    "text": "there so you can trine you can start your training from an already trained model and just adapt it to your data set",
    "start": "2069510",
    "end": "2077070"
  },
  {
    "text": "which shows great value and on the right",
    "start": "2077070",
    "end": "2082230"
  },
  {
    "text": "I'm just showing the speed up with you you know if you scale it to more machines so you actually get almost",
    "start": "2082230",
    "end": "2088020"
  },
  {
    "text": "linear scale up if you want to train faster the last day the last comment",
    "start": "2088020",
    "end": "2094139"
  },
  {
    "start": "2091000",
    "end": "2134000"
  },
  {
    "text": "that I want to say is that you know you should go to the Amazon sage maker documentation and look at the algorithms",
    "start": "2094140",
    "end": "2100140"
  },
  {
    "text": "that explain much better much in much better detail and all these algorithms",
    "start": "2100140",
    "end": "2106140"
  },
  {
    "text": "have many pending improve improvements that are going to be shipped regularly",
    "start": "2106140",
    "end": "2112710"
  },
  {
    "text": "over the next few months documentation and more examples are come more",
    "start": "2112710",
    "end": "2117960"
  },
  {
    "text": "documentation more examples are coming and more algorithms are coming so this list is going to become longer and",
    "start": "2117960",
    "end": "2123090"
  },
  {
    "text": "longer over time ok so I see if you need large-scale algorithms you know frequent that page just go go",
    "start": "2123090",
    "end": "2130530"
  },
  {
    "text": "there every month and see what's new ok",
    "start": "2130530",
    "end": "2134780"
  },
  {
    "start": "2134000",
    "end": "2172000"
  },
  {
    "text": "the last thing we'll cover is how to use how to use Amazon stage maker algorithms",
    "start": "2137630",
    "end": "2143780"
  },
  {
    "text": "in you know one of the beers alright so",
    "start": "2143780",
    "end": "2154850"
  },
  {
    "text": "you might think that using those so we talked about streaming data in s3 and",
    "start": "2154850",
    "end": "2161660"
  },
  {
    "text": "Kinesis and you know and Paulo meter servers and shared stuff and just hold this whole thing's like it looks like a",
    "start": "2161660",
    "end": "2167900"
  },
  {
    "text": "pretty complex setup and you might think it's it's pretty hard to run but in fact sage maker makes it incredibly simple to",
    "start": "2167900",
    "end": "2174860"
  },
  {
    "start": "2172000",
    "end": "2230000"
  },
  {
    "text": "run those things so the first obvious thing the the first thing you can do is",
    "start": "2174860",
    "end": "2180680"
  },
  {
    "text": "essentially call those algorithms directly through the command line for sage made from sage maker like sausage",
    "start": "2180680",
    "end": "2186800"
  },
  {
    "text": "maker so you put your profile in your your role and then you name the job",
    "start": "2186800",
    "end": "2192980"
  },
  {
    "text": "basically and you know this is just an example a command line run of I think",
    "start": "2192980",
    "end": "2199220"
  },
  {
    "text": "it's k-means yeah and you see this is",
    "start": "2199220",
    "end": "2207410"
  },
  {
    "text": "again you pretty much had to set up nothing right you just specify the data",
    "start": "2207410",
    "end": "2212810"
  },
  {
    "text": "set and the type of algorithm that you want the features that you want for the Argonne so number of clusters and so on the point is of the data in s3 and you",
    "start": "2212810",
    "end": "2221480"
  },
  {
    "text": "essentially tell it how much and what kind of hardware you wanted to use okay and that's it that's that's the first",
    "start": "2221480",
    "end": "2228500"
  },
  {
    "text": "example the second example is something I'm personally very excited about is",
    "start": "2228500",
    "end": "2236390"
  },
  {
    "start": "2230000",
    "end": "2351000"
  },
  {
    "text": "that we we make this accessible directly through spark that so now you can you",
    "start": "2236390",
    "end": "2244220"
  },
  {
    "text": "can actually take those algorithms and use them as estimators and transformers",
    "start": "2244220",
    "end": "2249650"
  },
  {
    "text": "in your spark cluster okay and note that",
    "start": "2249650",
    "end": "2254680"
  },
  {
    "text": "when you do this the algorithm doesn't actually run on the spark cluster that you have it utilizes sage maker hardware",
    "start": "2254680",
    "end": "2264350"
  },
  {
    "text": "and that's very important because the type of hardware that you use for ETL jobs is usually very different",
    "start": "2264350",
    "end": "2270720"
  },
  {
    "text": "how do you need for crunching those machine learning algorithms so you might while you might need ten you know high",
    "start": "2270720",
    "end": "2279090"
  },
  {
    "text": "memory not very not very strong CPU wise machines to run your ETL if to train",
    "start": "2279090",
    "end": "2286260"
  },
  {
    "text": "your deep learning model you might need a very strong like free you know P two instances right if you try to do all of",
    "start": "2286260",
    "end": "2292859"
  },
  {
    "text": "that on the same hardware you will end up paying you know paying too much or having poor performance right and so",
    "start": "2292859",
    "end": "2299460"
  },
  {
    "text": "what happens when I run fit here at the bottom it actually creates the call and",
    "start": "2299460",
    "end": "2306390"
  },
  {
    "text": "change the data on on sage maker you'll see by the way that you can of course",
    "start": "2306390",
    "end": "2312240"
  },
  {
    "text": "then use transform on it one of the coolest thing here and you know I think maybe this you know so one of the things",
    "start": "2312240",
    "end": "2322170"
  },
  {
    "text": "so let me say this when you run k-means it might not look very impressive because yeah i might have it might be",
    "start": "2322170",
    "end": "2330210"
  },
  {
    "text": "faster or something but I already have k-means in spark you from spark ml but",
    "start": "2330210",
    "end": "2335609"
  },
  {
    "text": "you can do this now with XG boost okay so now you can run you know extra boost",
    "start": "2335609",
    "end": "2340650"
  },
  {
    "text": "on sixty-four machines from your spark pipeline which if I mean without this",
    "start": "2340650",
    "end": "2346589"
  },
  {
    "text": "would be I wouldn't want to do it the",
    "start": "2346589",
    "end": "2351990"
  },
  {
    "start": "2351000",
    "end": "2449000"
  },
  {
    "text": "the next and I think simplest and most",
    "start": "2351990",
    "end": "2359070"
  },
  {
    "text": "straightforward example for how you should be using this is from say Jack",
    "start": "2359070",
    "end": "2364380"
  },
  {
    "text": "sage maker notebooks themselves with so",
    "start": "2364380",
    "end": "2369810"
  },
  {
    "text": "sage maker comes with hosted notebooks you can open and create a session",
    "start": "2369810",
    "end": "2375260"
  },
  {
    "text": "essentially the part of the notebook that just trains the job looks like this",
    "start": "2375260",
    "end": "2380550"
  },
  {
    "text": "you create a session I create a sage make your estimator you give it the hardware and the kind of the",
    "start": "2380550",
    "end": "2387330"
  },
  {
    "text": "configuration that they estimate o needs you set the parameters for the job and",
    "start": "2387330",
    "end": "2392460"
  },
  {
    "text": "you try and run fit on it and again this",
    "start": "2392460",
    "end": "2398160"
  },
  {
    "text": "doesn't happen on the notebook it happens the distributed containerized environment",
    "start": "2398160",
    "end": "2404500"
  },
  {
    "text": "that we talked about and the most exciting thing is oh one of the most exciting things is when you're done with",
    "start": "2404500",
    "end": "2412180"
  },
  {
    "text": "this from the notebook directly you can deploy your model so here it's PCA but",
    "start": "2412180",
    "end": "2417760"
  },
  {
    "text": "what deploy does is actually pushed the model and put it behind the HTTP endpoint and makes it immediately",
    "start": "2417760",
    "end": "2423760"
  },
  {
    "text": "available for your applications so with its extra boost or or image",
    "start": "2423760",
    "end": "2429099"
  },
  {
    "text": "classification or k-means or PCA or linear learn or whatever love is your model is you can directly form the",
    "start": "2429099",
    "end": "2436540"
  },
  {
    "text": "notebook host it and have it available for your applications in like pretty much immediately thereafter okay so I",
    "start": "2436540",
    "end": "2446020"
  },
  {
    "text": "want to wrap up and leave some time for questions you know with just tell you",
    "start": "2446020",
    "end": "2451780"
  },
  {
    "start": "2449000",
    "end": "2492000"
  },
  {
    "text": "you know just telling you go to Sage Maker you know this is what you'll get you can create your own notebooks you'll",
    "start": "2451780",
    "end": "2459010"
  },
  {
    "text": "go when you'll have a lot of example notebooks that show you how to do some stuff play with it figure out how to use",
    "start": "2459010",
    "end": "2466210"
  },
  {
    "text": "it if you come up with great usage examples you figure out you can do cool things with it blog about it tell us",
    "start": "2466210",
    "end": "2473319"
  },
  {
    "text": "about it we'd love to hear those stories if you find something if you find that",
    "start": "2473319",
    "end": "2478390"
  },
  {
    "text": "you really want to do something that it's it's actually not very easy to do or that you think we should enable we'd",
    "start": "2478390",
    "end": "2483940"
  },
  {
    "text": "even be happier to learn about that and with that I will conclude they'll be",
    "start": "2483940",
    "end": "2489640"
  },
  {
    "text": "happy to take questions [Laughter]",
    "start": "2489640",
    "end": "2498380"
  },
  {
    "start": "2492000",
    "end": "2561000"
  },
  {
    "text": "so the question is what what about normalization of data right so the the pre like the okay so the so first of all",
    "start": "2504170",
    "end": "2516420"
  },
  {
    "text": "you can use spark and you can use other tools for ETL jobs you know in the",
    "start": "2516420",
    "end": "2521970"
  },
  {
    "text": "notebook or from spark directly or other tools that you have we have you know",
    "start": "2521970",
    "end": "2528330"
  },
  {
    "text": "glue and and other of course EMR for doing that we specifically in this",
    "start": "2528330",
    "end": "2535590"
  },
  {
    "text": "context focused on getting the machine learning done at scale and in in its",
    "start": "2535590",
    "end": "2540840"
  },
  {
    "text": "speed and not trying to reinvent ETL as a whole but yeah we know that this is",
    "start": "2540840",
    "end": "2548910"
  },
  {
    "text": "something that people need again sorry",
    "start": "2548910",
    "end": "2559160"
  },
  {
    "text": "oh good excellent so one thing I didn't",
    "start": "2559990",
    "end": "2565210"
  },
  {
    "start": "2561000",
    "end": "2645000"
  },
  {
    "text": "go into is actually the bring your own model or bring your own you know so we have showed them some algorithms as a",
    "start": "2565210",
    "end": "2573190"
  },
  {
    "text": "whole in Sage maker our camp encapsulated in containers and you can pretty much bring",
    "start": "2573190",
    "end": "2579580"
  },
  {
    "text": "your own container you can put whatever you want in it I didn't go into again with sage make and run just generic tens",
    "start": "2579580",
    "end": "2585790"
  },
  {
    "text": "of flow where max net whatever deep learning you can pretty much run whatever algorithm you want we provide",
    "start": "2585790",
    "end": "2591550"
  },
  {
    "text": "you a lot of tools on how to containerize some of them if you whatever wacky thing you can come up",
    "start": "2591550",
    "end": "2597190"
  },
  {
    "text": "with if you can conform to the container specifications which are it's pretty uh opinion and it's kind of a pretty",
    "start": "2597190",
    "end": "2603160"
  },
  {
    "text": "straightforward thing you can run it on sage maker so you could you don't have to use our training environment for",
    "start": "2603160",
    "end": "2608560"
  },
  {
    "text": "example use our hosting you can bring our own you can you know if you if you specify the algorithm you can train it",
    "start": "2608560",
    "end": "2614140"
  },
  {
    "text": "or if you just specify a model container you can host it",
    "start": "2614140",
    "end": "2619080"
  },
  {
    "text": "okay",
    "start": "2640750",
    "end": "2643470"
  },
  {
    "start": "2645000",
    "end": "2770000"
  },
  {
    "text": "so the question is about cross-validation and what I mean what we do about it so it's a great question",
    "start": "2645850",
    "end": "2652700"
  },
  {
    "text": "because we've we've we thought about",
    "start": "2652700",
    "end": "2657880"
  },
  {
    "text": "incorporating kind of best practices in machine learning into the framework and",
    "start": "2657880",
    "end": "2664570"
  },
  {
    "text": "we decided against it and we decided against it because there",
    "start": "2664570",
    "end": "2669740"
  },
  {
    "text": "are 500 different ways to do it and everybody has their own way we can offer some ideas on how you should or",
    "start": "2669740",
    "end": "2676640"
  },
  {
    "text": "shouldn't be doing machine learning we should we design algorithms that try to",
    "start": "2676640",
    "end": "2682250"
  },
  {
    "text": "not over fit when you can but we try to be an opening it in the sense that you",
    "start": "2682250",
    "end": "2687350"
  },
  {
    "text": "know if you run whatever you were used to doing you should be doing that and you know will enable you to do that",
    "start": "2687350",
    "end": "2693320"
  },
  {
    "text": "faster easier more you know more frictionless but when we don't want to",
    "start": "2693320",
    "end": "2699550"
  },
  {
    "text": "you know we don't want to enforce any type of like validation schema on you",
    "start": "2699550",
    "end": "2705070"
  },
  {
    "text": "what I could ten cross-validation or whatever all that stuff I mean this is",
    "start": "2705070",
    "end": "2710920"
  },
  {
    "text": "exactly so if you need to do cross-validation you should just run testing on you know again we can think",
    "start": "2716150",
    "end": "2722520"
  },
  {
    "text": "about it if that becomes an issue we can we can always at the very least give examples on how it should be done or",
    "start": "2722520",
    "end": "2728490"
  },
  {
    "text": "maybe even create like a fool",
    "start": "2728490",
    "end": "2732050"
  },
  {
    "text": "yeah that's a great question and again something we struggle with quite a lot",
    "start": "2768849",
    "end": "2774140"
  },
  {
    "start": "2770000",
    "end": "2952000"
  },
  {
    "text": "you know we built sage make it essentially as three different surveys",
    "start": "2774140",
    "end": "2780049"
  },
  {
    "text": "actually probably four or five but mainly three main parts which is the notebooks and the tree you know the",
    "start": "2780049",
    "end": "2786529"
  },
  {
    "text": "exploration the training and the hosting and we wanted to make it",
    "start": "2786529",
    "end": "2793699"
  },
  {
    "text": "he wanted to pay kind of a la carte right so if you want to do just one or not the other you can pretty much mix and match and you know do whatever you",
    "start": "2793699",
    "end": "2799910"
  },
  {
    "text": "want some people have a great training environment and they really need the hosting on vice versa sorry and then",
    "start": "2799910",
    "end": "2805279"
  },
  {
    "text": "your question comes in - you know I trained a model on sage maker now I want to use it in my environment I want to",
    "start": "2805279",
    "end": "2810529"
  },
  {
    "text": "deploy it in my non inside maker safe how do you do that option number one and the one that I",
    "start": "2810529",
    "end": "2816439"
  },
  {
    "text": "would think is the most straightforward is to take the container as is and there's entry points to the container so",
    "start": "2816439",
    "end": "2822439"
  },
  {
    "text": "that you can deploy you know you can use that container itself as in your system",
    "start": "2822439",
    "end": "2827869"
  },
  {
    "text": "right so with outsider beta base so you don't have a mean so you you know so you",
    "start": "2827869",
    "end": "2836779"
  },
  {
    "text": "would have like the logic and that you know everything that you need to do that inside the container right I think that's the most safe kind of sane way to",
    "start": "2836779",
    "end": "2846229"
  },
  {
    "text": "do this I think so Tom do we is the feature of pooling the",
    "start": "2846229",
    "end": "2854630"
  },
  {
    "text": "container this the sage make a container is that is that possible today I'm not",
    "start": "2854630",
    "end": "2860209"
  },
  {
    "text": "sure like when you finish training",
    "start": "2860209",
    "end": "2864069"
  },
  {
    "text": "yeah",
    "start": "2916069",
    "end": "2918910"
  },
  {
    "text": "yeah yeah so if it's your container of",
    "start": "2944230",
    "end": "2954620"
  },
  {
    "start": "2952000",
    "end": "2984000"
  },
  {
    "text": "the or kind of the more deep learning or",
    "start": "2954620",
    "end": "2959900"
  },
  {
    "text": "other of this kind of standard containers you you could get the container itself I believe our",
    "start": "2959900",
    "end": "2965690"
  },
  {
    "text": "algorithms I'm not sure you'll be able to actually get the container itself you might you might need to be you might",
    "start": "2965690",
    "end": "2971240"
  },
  {
    "text": "need to deploy with AWS",
    "start": "2971240",
    "end": "2974680"
  },
  {
    "text": "not yet the question was does we support",
    "start": "2980509",
    "end": "2985920"
  },
  {
    "start": "2984000",
    "end": "3060000"
  },
  {
    "text": "cloud 9 right so we don't directly support cloud 9 but you should be able to use all these tools from cloud 9",
    "start": "2985920",
    "end": "2991349"
  },
  {
    "text": "we haven't actually tried it yet it's on our agenda but so so it's an important point all these sage maker tools are kind of",
    "start": "2991349",
    "end": "2998130"
  },
  {
    "text": "usable from anywhere you can get access we provide the Jupiter notebook they get",
    "start": "2998130",
    "end": "3003410"
  },
  {
    "text": "that lets you just get on board and start playing super easily through your AWS console but if you have your own",
    "start": "3003410",
    "end": "3010700"
  },
  {
    "text": "Jupiter installation if you're using cloud 9 if you're one of my colleagues is like why would anyone use any one",
    "start": "3010700",
    "end": "3017089"
  },
  {
    "text": "anything but BIM to write programs right that's it's not my opinion exactly but",
    "start": "3017089",
    "end": "3023390"
  },
  {
    "text": "that's a that's a perfectly acceptable one and you can you could do that",
    "start": "3023390",
    "end": "3029079"
  },
  {
    "text": "yeah so calling prediction there are two",
    "start": "3058179",
    "end": "3064069"
  },
  {
    "start": "3060000",
    "end": "3116000"
  },
  {
    "text": "ways to call prediction which are basically identical but which one you choose depends on the rest of your environment once you've deployed a model",
    "start": "3064069",
    "end": "3071150"
  },
  {
    "text": "you can use a standard Amazon API it's a cig v4 authenticated API to call from a",
    "start": "3071150",
    "end": "3077509"
  },
  {
    "text": "lambda function or call anywhere else to get a new prediction right so from your java web server or your web app any any",
    "start": "3077509",
    "end": "3085039"
  },
  {
    "text": "intermediate app anywhere you need inference you can just call it get it and this is of course the great advantage of deployment it's available",
    "start": "3085039",
    "end": "3091400"
  },
  {
    "text": "anywhere users who don't want to you who for whatever reason don't want to use the SDKs directly Amazon you know the",
    "start": "3091400",
    "end": "3097939"
  },
  {
    "text": "boto or the Java builder SDKs can just do HTTP the magic is you got to",
    "start": "3097939",
    "end": "3105559"
  },
  {
    "text": "do the cig for the ZigBee for auth which is documented but a little tricky",
    "start": "3105559",
    "end": "3110529"
  },
  {
    "text": "yeah it's super simple and you can you can just copy the prediction examples that we have in the notebooks understood",
    "start": "3115420",
    "end": "3121790"
  },
  {
    "text": "you can also so we have two levels of interaction at the Python level um we have the the standard AWS API the boto",
    "start": "3121790",
    "end": "3128750"
  },
  {
    "text": "calls which work at any in any language and the golang or wherever you are um we",
    "start": "3128750",
    "end": "3133940"
  },
  {
    "text": "also have a Python SDK which is what I eat oh was showing there where it looks a lot more like sort of a traditional so",
    "start": "3133940",
    "end": "3139579"
  },
  {
    "text": "I can learn environment and is a little bit easier to deal with I prefer that one but but I use both how",
    "start": "3139579",
    "end": "3151880"
  },
  {
    "text": "are we on time by the way I have okay I guess we can do one quick question",
    "start": "3151880",
    "end": "3159400"
  },
  {
    "start": "3172000",
    "end": "3248000"
  },
  {
    "text": "so I'm not sure what you mean by that there's there's an input format that you",
    "start": "3172390",
    "end": "3179390"
  },
  {
    "text": "pretty much have to conform to yeah I mean it's it's an input format it's like",
    "start": "3179390",
    "end": "3186670"
  },
  {
    "text": "not exactly so I think you know this again you these are great discussions",
    "start": "3196900",
    "end": "3202400"
  },
  {
    "text": "because you're touching on a lot of the things that we struggled with right when designing this product and we we really",
    "start": "3202400",
    "end": "3211069"
  },
  {
    "text": "these we decided to be as unappealing in it as we can and should not enforce our",
    "start": "3211069",
    "end": "3216280"
  },
  {
    "text": "convictions on on customers and you know whether you believe one hot encoding is",
    "start": "3216280",
    "end": "3223339"
  },
  {
    "text": "better for rnns then something else then you know go right ahead and do it you",
    "start": "3223339",
    "end": "3228859"
  },
  {
    "text": "know we try to just support every possible thing we'll try the documentation just say you know we think",
    "start": "3228859",
    "end": "3234260"
  },
  {
    "text": "this works better but basically you know which I'll let you do pretty much whatever you want all right so I think",
    "start": "3234260",
    "end": "3241760"
  },
  {
    "text": "we're out of time right all right",
    "start": "3241760",
    "end": "3247660"
  }
]
[
  {
    "text": "- Hi, I'm Andrea from AWS.",
    "start": "240",
    "end": "2580"
  },
  {
    "text": "- Hi, this is Imtiaz from Experian,",
    "start": "2580",
    "end": "4500"
  },
  {
    "text": "and this is my architecture.",
    "start": "4500",
    "end": "6023"
  },
  {
    "text": "(upbeat music)",
    "start": "6023",
    "end": "8690"
  },
  {
    "text": "- Thanks for being on the show, Imtiaz.",
    "start": "16650",
    "end": "18480"
  },
  {
    "text": "What business problem did you solve",
    "start": "18480",
    "end": "19920"
  },
  {
    "text": "with this architecture on AWS?",
    "start": "19920",
    "end": "21870"
  },
  {
    "text": "- The business problem\nthat we try to solve",
    "start": "21870",
    "end": "23730"
  },
  {
    "text": "is bringing the client's\ncustom models into Experian.",
    "start": "23730",
    "end": "26852"
  },
  {
    "text": "What used to take several months",
    "start": "27750",
    "end": "29590"
  },
  {
    "text": "is now we are able to onboard those models",
    "start": "30570",
    "end": "33030"
  },
  {
    "text": "in a matter of few\ndays, if not few clicks,",
    "start": "33030",
    "end": "36510"
  },
  {
    "text": "to take them to production.",
    "start": "36510",
    "end": "37679"
  },
  {
    "text": "- Fantastic, let's dive\ninto the architecture.",
    "start": "37680",
    "end": "39870"
  },
  {
    "text": "- Sure.\n- Okay.",
    "start": "39870",
    "end": "40890"
  },
  {
    "text": "So in this case, who do\nyou define as your user?",
    "start": "40890",
    "end": "43770"
  },
  {
    "text": "- Our users are data scientists\nwho are building the models",
    "start": "43770",
    "end": "46350"
  },
  {
    "text": "and using our model development toolkit.",
    "start": "46350",
    "end": "48449"
  },
  {
    "text": "What they do then is we actually\nprovide them a UI portal,",
    "start": "48450",
    "end": "51990"
  },
  {
    "text": "which gives them a seamless experience",
    "start": "51990",
    "end": "54660"
  },
  {
    "text": "to follow a sequence of steps\nto upload the model artifacts,",
    "start": "54660",
    "end": "58380"
  },
  {
    "text": "which is usually a Python serialized file,",
    "start": "58380",
    "end": "61200"
  },
  {
    "text": "a pickle file that they're uploading,",
    "start": "61200",
    "end": "62610"
  },
  {
    "text": "and an attributes or Pi file",
    "start": "62610",
    "end": "63990"
  },
  {
    "text": "that defines what the model is about.",
    "start": "63990",
    "end": "66300"
  },
  {
    "text": "And sometimes, library dependencies",
    "start": "66300",
    "end": "67860"
  },
  {
    "text": "that they basically define as\npart of the upload process.",
    "start": "67860",
    "end": "71220"
  },
  {
    "text": "- I see, so they, okay,\nupload all those files.",
    "start": "71220",
    "end": "75150"
  },
  {
    "text": "And how do you initiate this request now?",
    "start": "75150",
    "end": "77550"
  },
  {
    "text": "Like, now that they've kind\nof initiated a request,",
    "start": "77550",
    "end": "80160"
  },
  {
    "text": "what's the next in the flow?",
    "start": "80160",
    "end": "81600"
  },
  {
    "text": "- So once the artifacts are\nuploaded through the UI,",
    "start": "81600",
    "end": "85260"
  },
  {
    "text": "you have a platform\nAPI that gets kicked in",
    "start": "85260",
    "end": "88340"
  },
  {
    "text": "in the backend of these\nAPIs running pocket.",
    "start": "88340",
    "end": "91320"
  },
  {
    "text": "What we do then is\nbasically create an entry",
    "start": "91320",
    "end": "94260"
  },
  {
    "text": "in our model registry.",
    "start": "94260",
    "end": "95580"
  },
  {
    "text": "So we call our open-source service",
    "start": "95580",
    "end": "97440"
  },
  {
    "text": "that allows you to create\nan entry in our data store.",
    "start": "97440",
    "end": "100680"
  },
  {
    "text": "At the same time, we write the\nartifacts to the S3 bucket,",
    "start": "100680",
    "end": "104970"
  },
  {
    "text": "and then we write an\nevent to the Kafka topic.",
    "start": "104970",
    "end": "109320"
  },
  {
    "text": "- [Andrea] I see.\n- [Imtiaz] And the scale",
    "start": "109320",
    "end": "110580"
  },
  {
    "text": "to initiate the build process.",
    "start": "110580",
    "end": "112050"
  },
  {
    "text": "- Okay, so now it's\nready for build process.",
    "start": "112050",
    "end": "114360"
  },
  {
    "text": "And then take us",
    "start": "114360",
    "end": "115350"
  },
  {
    "text": "through the kind of\nseries of stuff involved",
    "start": "115350",
    "end": "117390"
  },
  {
    "text": "in the actual build process.\n- Sure.",
    "start": "117390",
    "end": "119520"
  },
  {
    "text": "So once the event is\nreturned to the Kafka queue,",
    "start": "119520",
    "end": "121710"
  },
  {
    "text": "because this is an\nevent-driven architecture,",
    "start": "121710",
    "end": "124260"
  },
  {
    "text": "you have a consumer app which is running,",
    "start": "124260",
    "end": "126090"
  },
  {
    "text": "in this case the build machine",
    "start": "126090",
    "end": "127380"
  },
  {
    "text": "happens to be running on EC2 instances.",
    "start": "127380",
    "end": "129330"
  },
  {
    "text": "- [Andrea] I see.\n- What it does is the event,",
    "start": "129330",
    "end": "131700"
  },
  {
    "text": "once it is written, it\ntriggers the build process.",
    "start": "131700",
    "end": "135330"
  },
  {
    "text": "The build process\nessentially in the machine",
    "start": "135330",
    "end": "138450"
  },
  {
    "text": "basically copies artifacts\nfrom S3 to its local drive",
    "start": "138450",
    "end": "142650"
  },
  {
    "text": "and then it also posts other\nlibraries from Artifactory,",
    "start": "142650",
    "end": "147390"
  },
  {
    "text": "and they are base files that are required",
    "start": "147390",
    "end": "149760"
  },
  {
    "text": "for quantitizing this",
    "start": "149760",
    "end": "151049"
  },
  {
    "text": "and building a SageMaker-compatible image.",
    "start": "151050",
    "end": "152657"
  },
  {
    "text": "- [Andrea] I see.\n- [Imtiaz] So there's Docker",
    "start": "152657",
    "end": "153750"
  },
  {
    "text": "installed on EC2,",
    "start": "153750",
    "end": "154650"
  },
  {
    "text": "and we build a Docker image,",
    "start": "154650",
    "end": "156239"
  },
  {
    "text": "and that image then, once it is built,",
    "start": "156240",
    "end": "158760"
  },
  {
    "text": "gets pushed into ECR report.",
    "start": "158760",
    "end": "161010"
  },
  {
    "text": "- Okay. So the build\nprocess essentially means",
    "start": "161010",
    "end": "163080"
  },
  {
    "text": "that you containerize it,\nyou put it in a registry,",
    "start": "163080",
    "end": "165960"
  },
  {
    "text": "and is ready now, right?",
    "start": "165960",
    "end": "167730"
  },
  {
    "text": "- Yes.\n- For deployment.",
    "start": "167730",
    "end": "169140"
  },
  {
    "text": "Tell us a little bit more\nabout, I see, SageMaker.",
    "start": "169140",
    "end": "171141"
  },
  {
    "text": "And I'm just curious like\nwhy did you choose SageMaker",
    "start": "171141",
    "end": "174150"
  },
  {
    "text": "for this specific use case?",
    "start": "174150",
    "end": "176040"
  },
  {
    "text": "- Because SageMaker is a\nmanaged service that AWS offers.",
    "start": "176040",
    "end": "180120"
  },
  {
    "text": "It allows you to build, deploy, test,",
    "start": "180120",
    "end": "182040"
  },
  {
    "text": "and train your models at scale.",
    "start": "182040",
    "end": "183782"
  },
  {
    "text": "And you have the luxury",
    "start": "184680",
    "end": "187019"
  },
  {
    "text": "of focusing on your core\nbusiness capabilities,",
    "start": "187020",
    "end": "188940"
  },
  {
    "text": "rather than trying to worry\nabout the infrastructure",
    "start": "188940",
    "end": "191160"
  },
  {
    "text": "in order to provision the services.",
    "start": "191160",
    "end": "192557"
  },
  {
    "text": "- I see, and how do\nyou call the SageMaker?",
    "start": "192557",
    "end": "193390"
  },
  {
    "text": "- Yeah, so once the image\nis pushed to ECR report,",
    "start": "195240",
    "end": "198780"
  },
  {
    "text": "the next step is basically creating",
    "start": "198780",
    "end": "200459"
  },
  {
    "text": "the endpoint configuration.",
    "start": "200460",
    "end": "202620"
  },
  {
    "text": "And once the endpoint\nconfiguration is created,",
    "start": "202620",
    "end": "204239"
  },
  {
    "text": "the endpoint configuration",
    "start": "204240",
    "end": "205073"
  },
  {
    "text": "deals with trying to pick the\nright instance type, right?",
    "start": "205073",
    "end": "209340"
  },
  {
    "text": "Trying to figure out\nwhat the scaling policy",
    "start": "209340",
    "end": "210989"
  },
  {
    "text": "is gonna be attached to\nthis particular model.",
    "start": "210990",
    "end": "213990"
  },
  {
    "text": "And once the endpoint\nconfiguration is created,",
    "start": "213990",
    "end": "216570"
  },
  {
    "text": "then you create the endpoint.",
    "start": "216570",
    "end": "218040"
  },
  {
    "text": "That's essentially the\nstart of model inferencing.",
    "start": "218040",
    "end": "221250"
  },
  {
    "text": "- I see, and tell me a little bit more",
    "start": "221250",
    "end": "222810"
  },
  {
    "text": "about those endpoints,",
    "start": "222810",
    "end": "224040"
  },
  {
    "text": "like what were some decision criterias",
    "start": "224040",
    "end": "225422"
  },
  {
    "text": "that went into creating them?",
    "start": "225423",
    "end": "227730"
  },
  {
    "text": "- So as part of the endpoint creation,",
    "start": "227730",
    "end": "230190"
  },
  {
    "text": "the endpoint conflation,",
    "start": "230190",
    "end": "231960"
  },
  {
    "text": "we have the intelligence baked in,",
    "start": "231960",
    "end": "233700"
  },
  {
    "text": "where depending on the ML\nframework that you have chosen,",
    "start": "233700",
    "end": "236069"
  },
  {
    "text": "depending on the number of features",
    "start": "236070",
    "end": "237300"
  },
  {
    "text": "that this model is\nactually going to consume,",
    "start": "237300",
    "end": "239760"
  },
  {
    "text": "and depending upon the kind of workloads",
    "start": "239760",
    "end": "242340"
  },
  {
    "text": "that you're expecting in production,",
    "start": "242340",
    "end": "243599"
  },
  {
    "text": "we are able to then basically\npick the right instance type",
    "start": "243600",
    "end": "246150"
  },
  {
    "text": "and attach the scaling policies.",
    "start": "246150",
    "end": "247590"
  },
  {
    "text": "- Oh, wonderful.",
    "start": "247590",
    "end": "248700"
  },
  {
    "text": "All right, so now you're\nusing SageMaker endpoints.",
    "start": "248700",
    "end": "252239"
  },
  {
    "text": "At any given point in time in\nthis process, as a consumer,",
    "start": "252240",
    "end": "256290"
  },
  {
    "text": "I wanna know the status of my work.",
    "start": "256290",
    "end": "258600"
  },
  {
    "text": "How do you initiate,",
    "start": "258600",
    "end": "259799"
  },
  {
    "text": "how do you get that\ninformation back to the user?",
    "start": "259800",
    "end": "261989"
  },
  {
    "text": "- [Imtiaz] Yeah, because\nit's a asynchronous process,",
    "start": "261990",
    "end": "264419"
  },
  {
    "text": "things that are happening\nin the background, right?",
    "start": "264420",
    "end": "266370"
  },
  {
    "text": "And they can take\nanywhere from few minutes",
    "start": "266370",
    "end": "268410"
  },
  {
    "text": "to, depending upon the moral context,",
    "start": "268410",
    "end": "270720"
  },
  {
    "text": "it might take some time.",
    "start": "270720",
    "end": "272580"
  },
  {
    "text": "So we actually have a\nprocess built in here",
    "start": "272580",
    "end": "275699"
  },
  {
    "text": "where SageMaker is emitting those events",
    "start": "275700",
    "end": "278130"
  },
  {
    "text": "to EventBridge, right?",
    "start": "278130",
    "end": "279930"
  },
  {
    "text": "And there is a Lambda\nfunction that is written",
    "start": "279930",
    "end": "282600"
  },
  {
    "text": "that's actually watching for these events",
    "start": "282600",
    "end": "284160"
  },
  {
    "text": "and gets triggered when\nthere's a endpoint change",
    "start": "284160",
    "end": "288690"
  },
  {
    "text": "right when the endpoint is built.",
    "start": "288690",
    "end": "290400"
  },
  {
    "text": "And this Lambda actually",
    "start": "290400",
    "end": "291419"
  },
  {
    "text": "essentially then does the same thing.",
    "start": "291420",
    "end": "292710"
  },
  {
    "text": "It writes an event to the Kafka topic",
    "start": "292710",
    "end": "293992"
  },
  {
    "text": "because then you can build a consumer app,",
    "start": "293992",
    "end": "296340"
  },
  {
    "text": "which is essentially sitting\nhere, that gets triggered.",
    "start": "296340",
    "end": "300600"
  },
  {
    "text": "And this consumer app,\nwhich is sitting on Fargate,",
    "start": "300600",
    "end": "305040"
  },
  {
    "text": "writes a message back to the portal",
    "start": "305040",
    "end": "306840"
  },
  {
    "text": "so that the status can be viewed-",
    "start": "306840",
    "end": "308400"
  },
  {
    "text": "- [Andrea] I see.\n- By the end user,",
    "start": "308400",
    "end": "309577"
  },
  {
    "text": "whether the model\ndeployment succeeded or not.",
    "start": "309577",
    "end": "312389"
  },
  {
    "text": "And also, if it succeeded,",
    "start": "312390",
    "end": "314220"
  },
  {
    "text": "then we actually update\nthe endpoint information",
    "start": "314220",
    "end": "316380"
  },
  {
    "text": "back to the model industry\nso that the end users",
    "start": "316380",
    "end": "319140"
  },
  {
    "text": "doesn't have to worry about\nthe internal mechanisms",
    "start": "319140",
    "end": "321330"
  },
  {
    "text": "or the URI is,",
    "start": "321330",
    "end": "322319"
  },
  {
    "text": "they just can't refer\nto the model indicator,",
    "start": "322320",
    "end": "324570"
  },
  {
    "text": "unable to invoke the\nmodel for inferencing.",
    "start": "324570",
    "end": "326700"
  },
  {
    "text": "- I love this architecture.",
    "start": "326700",
    "end": "327870"
  },
  {
    "text": "And so what benefits\ndoes your consumers get",
    "start": "327870",
    "end": "331350"
  },
  {
    "text": "from using this architecture?",
    "start": "331350",
    "end": "333630"
  },
  {
    "text": "- Definitely, I think, as I said,",
    "start": "333630",
    "end": "335400"
  },
  {
    "text": "the time to market is\none of the big factors.",
    "start": "335400",
    "end": "337440"
  },
  {
    "text": "The second thing is the scale\nat which this can be deployed.",
    "start": "337440",
    "end": "340260"
  },
  {
    "text": "So today, consumers don't have to worry",
    "start": "340260",
    "end": "341970"
  },
  {
    "text": "about whether they should\nreally need to work with us.",
    "start": "341970",
    "end": "344730"
  },
  {
    "text": "They can have a peace of mind",
    "start": "344730",
    "end": "346080"
  },
  {
    "text": "that if they deploy this\nmodel in our environment,",
    "start": "346080",
    "end": "348389"
  },
  {
    "text": "that's going to scale\nregardless of the the cycle.",
    "start": "348390",
    "end": "352290"
  },
  {
    "text": "So you can have a Thanksgiving\nevent, a major event,",
    "start": "352290",
    "end": "355380"
  },
  {
    "text": "so you have TP workload\ngoing through the roof.",
    "start": "355380",
    "end": "357570"
  },
  {
    "text": "You don't have to worry about that,",
    "start": "357570",
    "end": "358403"
  },
  {
    "text": "whether this is gonna scale or not.",
    "start": "358403",
    "end": "359910"
  },
  {
    "text": "- Thank you so much for being on the show.",
    "start": "359910",
    "end": "361320"
  },
  {
    "text": "- Thank you for hosting.",
    "start": "361320",
    "end": "362497"
  },
  {
    "text": "(upbeat music)",
    "start": "362497",
    "end": "365164"
  }
]
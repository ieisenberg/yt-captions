[
  {
    "text": "okay please come in we have some more seats in the front it's pretty harmless",
    "start": "30",
    "end": "7220"
  },
  {
    "text": "right I won't throw stuff at you you know so it's all fine you can sit right",
    "start": "7220",
    "end": "12900"
  },
  {
    "text": "here",
    "start": "12900",
    "end": "15080"
  },
  {
    "text": "more sits in the front you can come all the way up here looks like it's gonna be",
    "start": "38990",
    "end": "47840"
  },
  {
    "text": "a full room Wow impressive",
    "start": "47840",
    "end": "51070"
  },
  {
    "text": "[Music]",
    "start": "54610",
    "end": "57820"
  },
  {
    "text": "all right please move all the way to the front we have some more seats here you will have a perfect view on sage maker",
    "start": "80150",
    "end": "85940"
  },
  {
    "text": "right even more impressive when you take a look up close all right so welcome",
    "start": "85940",
    "end": "94940"
  },
  {
    "text": "everybody I hope you enjoyed the keynote my name is Julian I'm a tech evangelist",
    "start": "94940",
    "end": "100130"
  },
  {
    "text": "with the WS focusing on AI and machine learning and the really cool thing about",
    "start": "100130",
    "end": "105470"
  },
  {
    "text": "this session is it's completely free of slides right so that's why you here I",
    "start": "105470",
    "end": "110600"
  },
  {
    "text": "guess so zero slides and we're going to talk about sage maker actually we're",
    "start": "110600",
    "end": "116300"
  },
  {
    "text": "going to use sage maker we're gonna run through some some demos and and see what",
    "start": "116300",
    "end": "122720"
  },
  {
    "text": "this service can can do for you okay so maybe just a quick quick show of hands",
    "start": "122720",
    "end": "128630"
  },
  {
    "text": "before before we start who is who is a developer who's writing code every day",
    "start": "128630",
    "end": "135459"
  },
  {
    "text": "all right welcome who is a twisting machine learning even at small scale",
    "start": "135459",
    "end": "142730"
  },
  {
    "text": "even you know even small stuff alright quite a few people all right okay so I",
    "start": "142730",
    "end": "149959"
  },
  {
    "text": "guess you heard about sage maker already because it's been out for a few months now it came out at it came out at",
    "start": "149959",
    "end": "156170"
  },
  {
    "text": "reinvent and it's a it's a new service that lets you build end-to-end machine",
    "start": "156170",
    "end": "162950"
  },
  {
    "text": "learning workflows and the key promise actually the key feature in in Sage",
    "start": "162950",
    "end": "169790"
  },
  {
    "text": "Maker is that you focus on the machine learning tasks and you actually spend no",
    "start": "169790",
    "end": "175190"
  },
  {
    "text": "time managing any kind of infrastructure and as you probably know if you already",
    "start": "175190",
    "end": "180650"
  },
  {
    "text": "do data processing and machine learning at scale the the the actual DevOps part",
    "start": "180650",
    "end": "187280"
  },
  {
    "text": "of machine learning is quite it's quite important you know you have to build training clusters prediction clusters",
    "start": "187280",
    "end": "193580"
  },
  {
    "text": "and sure you know it's important those things need to work properly but they",
    "start": "193580",
    "end": "199760"
  },
  {
    "text": "just stand in the way right when you do machine learning you want to iterate fast you want to explore different algos",
    "start": "199760",
    "end": "205310"
  },
  {
    "text": "different models different parameters and the last thing you want to do is to mess with a you know ec2 instances",
    "start": "205310",
    "end": "213599"
  },
  {
    "text": "and big clusters that you have to manage yourself and this is what sage maker solves for you you know among other",
    "start": "213599",
    "end": "219750"
  },
  {
    "text": "things all right you can please move all the way to the front we have some more seats right you don't want to stand so",
    "start": "219750",
    "end": "227750"
  },
  {
    "text": "what I'm gonna do today is just run a few demos a few different things use",
    "start": "227750",
    "end": "233069"
  },
  {
    "text": "some some of the built-in al goes in in sage maker show you as well how to",
    "start": "233069",
    "end": "238560"
  },
  {
    "text": "integrate Amazon sage maker with a Apache spark which i think is an",
    "start": "238560",
    "end": "244500"
  },
  {
    "text": "interesting use case and and we'll see and time permitting will just run more stuff right",
    "start": "244500",
    "end": "249690"
  },
  {
    "text": "there's plenty so for those of you probably never use sage maker well this",
    "start": "249690",
    "end": "256859"
  },
  {
    "text": "is the console it's it's super simple one thing that you might want to start",
    "start": "256859",
    "end": "262109"
  },
  {
    "text": "with is created notebook instance which is exactly what the name says it's a pre-installed instance that comes with",
    "start": "262109",
    "end": "269310"
  },
  {
    "text": "all the the Python and all the deep learning tools and and and the Jupiter",
    "start": "269310",
    "end": "274410"
  },
  {
    "text": "environment that you need to get started so I'm not even just gonna show you how to do this you just click on create notebook instance and you feel a couple",
    "start": "274410",
    "end": "281729"
  },
  {
    "text": "of parameters and it's it's done right so now when you open it you will",
    "start": "281729",
    "end": "286830"
  },
  {
    "text": "actually jump straight away into into Jupiter okay and you will see a number",
    "start": "286830",
    "end": "296639"
  },
  {
    "text": "of existing notebooks that are already installed here and these are really",
    "start": "296639",
    "end": "302490"
  },
  {
    "text": "really good examples if they move please show up yeah here they are you'll see",
    "start": "302490",
    "end": "308160"
  },
  {
    "text": "those sample notebooks right that are here they're also available on github if",
    "start": "308160",
    "end": "314070"
  },
  {
    "text": "you want to if you want to look them up I really really recommend them as a great learning resource so let me find",
    "start": "314070",
    "end": "321570"
  },
  {
    "text": "those things here Sage main river yeah",
    "start": "321570",
    "end": "327950"
  },
  {
    "text": "and I would say if you want to learn sage maker reading the the documentation and and going through those examples on",
    "start": "327950",
    "end": "336000"
  },
  {
    "text": "github is probably your best your best bet right okay look I've slow internet",
    "start": "336000",
    "end": "343380"
  },
  {
    "text": "right now okay that's fine let's open that page later on okay so I'm gonna use",
    "start": "343380",
    "end": "350160"
  },
  {
    "text": "some of those notebooks today and some of my own so let's maybe let's start",
    "start": "350160",
    "end": "357080"
  },
  {
    "text": "let's start with the first example so sage maker oh let's go all the way up",
    "start": "357080",
    "end": "362640"
  },
  {
    "text": "here can you read in the back or is it too small yeah is it good alright thank",
    "start": "362640",
    "end": "371130"
  },
  {
    "text": "you if it's too small at some point just just wave right so one of the cool",
    "start": "371130",
    "end": "377130"
  },
  {
    "text": "feeders in sage maker is actually the collection of built-in algorithms that yet that you'll find there so it's not",
    "start": "377130",
    "end": "383940"
  },
  {
    "text": "just a service that lets you manage infrastructure easily it's it's also",
    "start": "383940",
    "end": "389970"
  },
  {
    "text": "service that provides a number of built-in algos that have been implemented by Amazon and AWS so you can",
    "start": "389970",
    "end": "397350"
  },
  {
    "text": "expect them to scale and you can just take those off-the-shelf algos and get the job done okay so here's an example",
    "start": "397350",
    "end": "403380"
  },
  {
    "text": "of that and sure you'll find I would say the traditional stuff you know linear regression and clustering and",
    "start": "403380",
    "end": "410960"
  },
  {
    "text": "classification etc but you will also find some more advanced stuff and this is one of the more advanced stuff a more",
    "start": "410960",
    "end": "418350"
  },
  {
    "text": "advanced one it's called deep AR it's actually been invented by by LWS there's",
    "start": "418350",
    "end": "423930"
  },
  {
    "text": "a research paper for that and this style goal lets you build time series lets you",
    "start": "423930",
    "end": "430200"
  },
  {
    "text": "predict a time series so let's take this this style go and see what we can do",
    "start": "430200",
    "end": "435570"
  },
  {
    "text": "with it so here I'm gonna use a data set from from Berkeley University and it's",
    "start": "435570",
    "end": "443070"
  },
  {
    "text": "it's a data set storing world temperature okay so",
    "start": "443070",
    "end": "448440"
  },
  {
    "text": "there's a world there's a daily measure a global temperature measure for every",
    "start": "448440",
    "end": "453630"
  },
  {
    "text": "day since 1880 right so first thing I",
    "start": "453630",
    "end": "458700"
  },
  {
    "text": "need to do of course and again working on a notebook instance here I need to download this data set remove",
    "start": "458700",
    "end": "465150"
  },
  {
    "text": "some useless lines that I don't need okay and this is what my dataset looks",
    "start": "465150",
    "end": "470580"
  },
  {
    "text": "like okay few columns you know date well year month day and and the",
    "start": "470580",
    "end": "477000"
  },
  {
    "text": "temperature which is actually it's not the actual temperature it's it's a delta versus a global average okay but I'll",
    "start": "477000",
    "end": "483360"
  },
  {
    "text": "convert it again okay so I have temperatures from 1880 to 2014 average",
    "start": "483360",
    "end": "489300"
  },
  {
    "text": "temperature was 868 over that whole period so this Delta zero actually need",
    "start": "489300",
    "end": "494880"
  },
  {
    "text": "to be applied to X 68 and let's say I want to predict thirty days of",
    "start": "494880",
    "end": "500670"
  },
  {
    "text": "temperatures okay so whenever I have a time Siri time series I want to predict the next 30 days so that's what we call",
    "start": "500670",
    "end": "507270"
  },
  {
    "text": "the prediction length okay so I'm going to I need to load this file okay so",
    "start": "507270",
    "end": "514830"
  },
  {
    "text": "first thing I need to do is to actually build the time series themselves so I'm going to load this file using Python put",
    "start": "514830",
    "end": "523320"
  },
  {
    "text": "everything in a Python dictionary just make sure I have you know one entry per year with all the temperatures right",
    "start": "523320",
    "end": "530190"
  },
  {
    "text": "this is really Python stuff here okay and and so when I'm done with that and",
    "start": "530190",
    "end": "537690"
  },
  {
    "text": "don't worry if you don't understand the finer details of Python all that stuff is on github I'll share the link at the",
    "start": "537690",
    "end": "543510"
  },
  {
    "text": "end once I've done that actually I've loaded my file as a Python dictionary",
    "start": "543510",
    "end": "548850"
  },
  {
    "text": "and and hopefully yes I've got either 365 or 366 measures for each year right",
    "start": "548850",
    "end": "556580"
  },
  {
    "text": "which means my data is complete so now I can actually plot it it's something that",
    "start": "556580",
    "end": "562260"
  },
  {
    "text": "we usually do when we work with data we want to take a look at that at that data set so there you go global temperatures",
    "start": "562260",
    "end": "571350"
  },
  {
    "text": "from 1880 to 2014 right come up with your own conclusion I'm not here to talk",
    "start": "571350",
    "end": "577080"
  },
  {
    "text": "about politics I'm here to talk about machine learning okay so yeah anyway so",
    "start": "577080",
    "end": "582360"
  },
  {
    "text": "then I need as always to split my data between a training set and a validation",
    "start": "582360",
    "end": "587910"
  },
  {
    "text": "set okay it's what you do when you do machine learning use the bulk of the data to",
    "start": "587910",
    "end": "593120"
  },
  {
    "text": "train and you set some data side to actually measure the accuracy of your model so when you work with I would say",
    "start": "593120",
    "end": "601630"
  },
  {
    "text": "traditional L goes like probably let's say renal regression or classification",
    "start": "601630",
    "end": "606710"
  },
  {
    "text": "you just take the data set as it is and you split it maybe 80/20 or 90/10 and",
    "start": "606710",
    "end": "613670"
  },
  {
    "text": "that's it for time series it's a bit different because actually the the",
    "start": "613670",
    "end": "619130"
  },
  {
    "text": "training set will be the test sets re will be the full data set okay because",
    "start": "619130",
    "end": "626570"
  },
  {
    "text": "we want to compare the predicted time series to the actual values that we have initially and the training set is the",
    "start": "626570",
    "end": "634640"
  },
  {
    "text": "full data set okay - in this case the thirty last data points in each time",
    "start": "634640",
    "end": "641150"
  },
  {
    "text": "series so my training set is actually the time series for each year where I remove the month of December right the",
    "start": "641150",
    "end": "648200"
  },
  {
    "text": "last 30 data points and that's what I do here right in my training set as you can see I just copy the full set - the last",
    "start": "648200",
    "end": "656570"
  },
  {
    "text": "30 values and the test set is just everything that's how you work with Time series okay so yeah I do have a bug for",
    "start": "656570",
    "end": "665240"
  },
  {
    "text": "2014 so I've just ignore in 2014 not sure what's going on here okay so now",
    "start": "665240",
    "end": "671300"
  },
  {
    "text": "I've got my training set and my test set so I need to write those two files and I",
    "start": "671300",
    "end": "677660"
  },
  {
    "text": "need to pay attention to the file format that deep AR requires okay and you'll",
    "start": "677660",
    "end": "683690"
  },
  {
    "text": "find a lot all of that in the documentation so no no worries so deep AR requires the time series to be stored",
    "start": "683690",
    "end": "690170"
  },
  {
    "text": "in JSON format okay actually JSON lines so each line as you can see here okay",
    "start": "690170",
    "end": "697310"
  },
  {
    "text": "each line in my life data set is going to be one JS document so this is 1948",
    "start": "697310",
    "end": "704630"
  },
  {
    "text": "for whatever reason and then the target array is actually the 365 values for",
    "start": "704630",
    "end": "713720"
  },
  {
    "text": "that year okay and it's the same for every single year okay is 1949 etc etc",
    "start": "713720",
    "end": "719330"
  },
  {
    "text": "so I need to write those that data set into that JSON format because again this is what dpr",
    "start": "719330",
    "end": "726740"
  },
  {
    "text": "expects okay and for different alcohols it's gonna be different formats I mean a lot of the algos use protobuf some of",
    "start": "726740",
    "end": "734420"
  },
  {
    "text": "them can also take CSV but DPR is bit different it takes Jason okay so now",
    "start": "734420",
    "end": "742100"
  },
  {
    "text": "I've got locally on my notebook instance my data set in JSON format and now I need to upload it to a stream because",
    "start": "742100",
    "end": "748370"
  },
  {
    "text": "this is why this is where sage maker is gonna pick up the data okay so define some some locations in s3",
    "start": "748370",
    "end": "756550"
  },
  {
    "text": "upload the training set upload the test set and define the location where the",
    "start": "756550",
    "end": "763370"
  },
  {
    "text": "train model will be saved okay once again all activity happens in s3 your day Thomas ministry and the",
    "start": "763370",
    "end": "771050"
  },
  {
    "text": "model will be saved in s3 okay and I can see all the all the different paths here",
    "start": "771050",
    "end": "776200"
  },
  {
    "text": "okay so that's it so now our data set is",
    "start": "776200",
    "end": "781940"
  },
  {
    "text": "is ready and uploaded in s3 and now I need to actually configure my training",
    "start": "781940",
    "end": "787310"
  },
  {
    "text": "job and as you may know all the if you if you look under the hood of sage maker",
    "start": "787310",
    "end": "794089"
  },
  {
    "text": "it's all running on docker ok so that all the training jobs and all the prediction jobs are actually based on",
    "start": "794089",
    "end": "800150"
  },
  {
    "text": "docker containers ok so what I need to do here basically is to select the",
    "start": "800150",
    "end": "806200"
  },
  {
    "text": "container that contains the DPR I'll go for the region I'm running in so here",
    "start": "806200",
    "end": "812570"
  },
  {
    "text": "I'm running in US East one so I will just go and pick the image that",
    "start": "812570",
    "end": "818480"
  },
  {
    "text": "corresponds to that region ok and again all those containers are defined in the dock so you don't need to",
    "start": "818480",
    "end": "823790"
  },
  {
    "text": "go in search for that ok and as you can see they're hosted in ECR which is our talker repository",
    "start": "823790",
    "end": "829430"
  },
  {
    "text": "okay so that's the algo I'm gonna use right deep a are hosting in US East one",
    "start": "829430",
    "end": "836589"
  },
  {
    "text": "and now we get to the good stuff we get to actually configuring the training job",
    "start": "836589",
    "end": "842350"
  },
  {
    "text": "so I'm gonna use the sage maker SDK here to do this it's a Python SDK",
    "start": "842350",
    "end": "847960"
  },
  {
    "text": "we have this high-level estimator object that lets us define everything so I'm",
    "start": "847960",
    "end": "853779"
  },
  {
    "text": "gonna select the container that I need okay pass the iron role for Sage maker",
    "start": "853779",
    "end": "859899"
  },
  {
    "text": "because it needs permission to access s3 and so on and I'm gonna use 1c for 8xl",
    "start": "859899",
    "end": "867670"
  },
  {
    "text": "instance to Train and that's as much infrastructure as you need to work with okay if you wanted to do distributed",
    "start": "867670",
    "end": "875260"
  },
  {
    "text": "training and you wanted let's say ten instances because you had a really big data set that's what you would do and",
    "start": "875260",
    "end": "880420"
  },
  {
    "text": "Sage Maker will automatically fire up those ten instances and they're fully managed and they terminate automatically",
    "start": "880420",
    "end": "886510"
  },
  {
    "text": "wants training is done so you never spend a minute managing those servers okay which again is one of the key",
    "start": "886510",
    "end": "892120"
  },
  {
    "text": "features in Sage Maker okay so that's the training job I need to define some",
    "start": "892120",
    "end": "897130"
  },
  {
    "text": "parameters so these are more algo specific obviously so I'm not going to go through all of them but the important",
    "start": "897130",
    "end": "903610"
  },
  {
    "text": "ones are prediction lengths okay so I want to predict 30 data points in that",
    "start": "903610",
    "end": "908800"
  },
  {
    "text": "time series my values in the time series are actually daily values you can go",
    "start": "908800",
    "end": "914529"
  },
  {
    "text": "from minutes to years okay and then I",
    "start": "914529",
    "end": "919810"
  },
  {
    "text": "can define some parameters for the structure of up the deep AR Network I'm",
    "start": "919810",
    "end": "926920"
  },
  {
    "text": "gonna train for quite a while 258 bucks I can define the batch size I",
    "start": "926920",
    "end": "933220"
  },
  {
    "text": "can define the learning rate so again these are algo specific parameters and",
    "start": "933220",
    "end": "938800"
  },
  {
    "text": "you can find them in documentation and of course you can read the the research paper if you want to know exactly what",
    "start": "938800",
    "end": "944110"
  },
  {
    "text": "these are and now this one's interesting too it's called early stopping actually you never when you train for the first",
    "start": "944110",
    "end": "949959"
  },
  {
    "text": "few times you never quite know how long you should train for right so you could",
    "start": "949959",
    "end": "955060"
  },
  {
    "text": "actually train for a very for a huge number of epochs like this and define early stopping and early stopping really",
    "start": "955060",
    "end": "961839"
  },
  {
    "text": "says if the if the accuracy of the model hasn't improved in ten epochs stop",
    "start": "961839",
    "end": "968350"
  },
  {
    "text": "training okay so it takes the the guessing part away you don't have to run",
    "start": "968350",
    "end": "973750"
  },
  {
    "text": "multiple tries to okay did I train for long enough and no should I try for longer and or maybe longer just define a",
    "start": "973750",
    "end": "980020"
  },
  {
    "text": "large number of and early stopping and then it stops automatically when there are no more",
    "start": "980020",
    "end": "985570"
  },
  {
    "text": "improvements okay so then I can okay set the parameters for this I'll go define",
    "start": "985570",
    "end": "992020"
  },
  {
    "text": "the location of my training data on my test data and then train okay and so",
    "start": "992020",
    "end": "998800"
  },
  {
    "text": "what again what this does is automatically it's gonna fire up that instance that I created",
    "start": "998800",
    "end": "1003960"
  },
  {
    "text": "pull the darker container storing DPR to that to that instance inject your",
    "start": "1003960",
    "end": "1010170"
  },
  {
    "text": "parameters point everything at your data and then it drains okay so it trains for",
    "start": "1010170",
    "end": "1015240"
  },
  {
    "text": "a while and you have that training a full training log okay and this is also",
    "start": "1015240",
    "end": "1020760"
  },
  {
    "text": "available in cloud watch logs because sometimes you're not using notebook instances you're just running jobs",
    "start": "1020760",
    "end": "1026100"
  },
  {
    "text": "running training jobs automatically so obviously you need a place to go and grab the log and that would be cloud",
    "start": "1026100",
    "end": "1031380"
  },
  {
    "text": "watch logs okay so heat transfer a while and I guess it does it does get stopped early",
    "start": "1031380",
    "end": "1037520"
  },
  {
    "text": "what's the last epic here yeah epic 119 okay so it does actually use early",
    "start": "1037520",
    "end": "1044160"
  },
  {
    "text": "stopping to stop it saves the model in s3 and then I can deploy it okay so when",
    "start": "1044160",
    "end": "1054570"
  },
  {
    "text": "you deploy models you could just deploy it you could basically say you could use",
    "start": "1054570",
    "end": "1060420"
  },
  {
    "text": "that same object here and you could say estimator dot deploy and you would just deploy it in a very simple and automated",
    "start": "1060420",
    "end": "1067050"
  },
  {
    "text": "way or you could maybe go down one level and use more and more custom behavior",
    "start": "1067050",
    "end": "1073260"
  },
  {
    "text": "and this is what we do here so actually when we deploy we first create an endpoint configuration and then we",
    "start": "1073260",
    "end": "1080550"
  },
  {
    "text": "deploy and the purpose of that endpoint configuration which which you see here is it lets you it lets you configure",
    "start": "1080550",
    "end": "1091830"
  },
  {
    "text": "multiple models behind the same endpoint so let's say you want you have an",
    "start": "1091830",
    "end": "1097080"
  },
  {
    "text": "existing model that you trained last week and you want to deploy a new model that you just trained you could actually",
    "start": "1097080",
    "end": "1103410"
  },
  {
    "text": "keep the same endpoint to keep the same prediction endpoint running and have the two models actually running behind it",
    "start": "1103410",
    "end": "1111419"
  },
  {
    "text": "at that endpoint and you can split traffic across those two models it could be two three four okay so it's just a",
    "start": "1111419",
    "end": "1117749"
  },
  {
    "text": "good way to do maybe AV testing or it's a good way to do very safe deployment gradually bring a new model into",
    "start": "1117749",
    "end": "1124049"
  },
  {
    "text": "production and check that everything is fine and then switch all traffic to the new model okay and you can see this in",
    "start": "1124049",
    "end": "1130739"
  },
  {
    "text": "the I'm sorry you can see this in the stage maker console as well okay you have this end pointed figuration which",
    "start": "1130739",
    "end": "1136979"
  },
  {
    "text": "is really what what is the model or what are our models that are actually living",
    "start": "1136979",
    "end": "1142320"
  },
  {
    "text": "behind the endpoint and then you have the endpoint itself okay so this is what",
    "start": "1142320",
    "end": "1148049"
  },
  {
    "text": "we do here we deploy it we deploy to an M for a single and for excel instance",
    "start": "1148049",
    "end": "1153809"
  },
  {
    "text": "once again automatically Sage maker will create the instance deploy the model and",
    "start": "1153809",
    "end": "1159559"
  },
  {
    "text": "and create the HTTP endpoint to start",
    "start": "1159559",
    "end": "1164669"
  },
  {
    "text": "serving predictions okay and again you see here I could that's probably this",
    "start": "1164669",
    "end": "1170369"
  },
  {
    "text": "one here yeah okay and here's the here's the URL okay so now we could HTTP POST",
    "start": "1170369",
    "end": "1178579"
  },
  {
    "text": "new samples to to this endpoint and get some predictions okay so let's try and",
    "start": "1178579",
    "end": "1187079"
  },
  {
    "text": "do this so I'm going to bill the prediction requests and again it needs",
    "start": "1187079",
    "end": "1193169"
  },
  {
    "text": "to be JSON formatted okay so it needs to look a bit like those samples you you saw previously right so it has start and",
    "start": "1193169",
    "end": "1201419"
  },
  {
    "text": "it has a target etc so I just need to to come up with that again when you predict",
    "start": "1201419",
    "end": "1207869"
  },
  {
    "text": "where the time series things are a bit different when you predict let's say when you classify samples you get a",
    "start": "1207869",
    "end": "1214079"
  },
  {
    "text": "single result right you get a single prediction and that's what you use when you predict with time series actually",
    "start": "1214079",
    "end": "1220529"
  },
  {
    "text": "you predict a number of predictions right and this is this num samples thing",
    "start": "1220529",
    "end": "1226409"
  },
  {
    "text": "that you see here so you're going to ask that model to predict maybe 50 samples okay because time series are extremely",
    "start": "1226409",
    "end": "1233399"
  },
  {
    "text": "volatile so from one to the next you know you could have you could have a lot of differences so if you predict just",
    "start": "1233399",
    "end": "1238919"
  },
  {
    "text": "one value it doesn't necessarily give you a perfect view of the other other results here so actually",
    "start": "1238919",
    "end": "1246830"
  },
  {
    "text": "we're predicting many different time series and we are asking DPR to output",
    "start": "1246830",
    "end": "1253960"
  },
  {
    "text": "the mean for the photos let's say 50 samples and as well as the quantiles",
    "start": "1253960",
    "end": "1259910"
  },
  {
    "text": "okay so you could ask for the 10th or the 19th quantile and for example the",
    "start": "1259910",
    "end": "1265280"
  },
  {
    "text": "90th quintile value as we will see tells you that 90% of values are actually",
    "start": "1265280",
    "end": "1270980"
  },
  {
    "text": "lower than this right and so it gives you like a statistical view of the time",
    "start": "1270980",
    "end": "1276440"
  },
  {
    "text": "series predictions okay so that's how we need that's what I need to build here okay then I need to extract some",
    "start": "1276440",
    "end": "1283670"
  },
  {
    "text": "information and I want to plot it and this is I would look like okay so let's",
    "start": "1283670",
    "end": "1290630"
  },
  {
    "text": "say let's say I want to I want to compare I want to check if my prediction",
    "start": "1290630",
    "end": "1295640"
  },
  {
    "text": "is actually good so I'm going to compare the prediction for the last 30 days of",
    "start": "1295640",
    "end": "1300950"
  },
  {
    "text": "1984 and hopefully that rings a bell -",
    "start": "1300950",
    "end": "1306130"
  },
  {
    "text": "to the actual to the actual values so I just use those functions that I said",
    "start": "1306130",
    "end": "1312020"
  },
  {
    "text": "that I showed you right I built a prediction request I actually used the",
    "start": "1312020",
    "end": "1317120"
  },
  {
    "text": "sage maker SDK - HTTP POST that request to my model and then I can plot my",
    "start": "1317120",
    "end": "1322820"
  },
  {
    "text": "results and as you can see here I I see so the is it purple on the screen - yes",
    "start": "1322820",
    "end": "1328990"
  },
  {
    "text": "the purple line is the actual is the truth okay so it's the the values from",
    "start": "1328990",
    "end": "1335840"
  },
  {
    "text": "the data set the blue line is the mean from the from the samples that I",
    "start": "1335840",
    "end": "1342020"
  },
  {
    "text": "predicted okay so again I asked DPR to predict many different samples and the",
    "start": "1342020",
    "end": "1348650"
  },
  {
    "text": "blue and I know the blue line is the mean of that okay the yellow line is the 10th percentile so 10 10 percent of of",
    "start": "1348650",
    "end": "1356929"
  },
  {
    "text": "those predicted values are lower and 90 percent of the predicted values are higher the green line is that is the",
    "start": "1356929",
    "end": "1363710"
  },
  {
    "text": "19th percentile so that tells me 90% of the predicted values are lower and 10",
    "start": "1363710",
    "end": "1369770"
  },
  {
    "text": "percent of the predicted values are higher so that channel right that the channel between the green and",
    "start": "1369770",
    "end": "1375510"
  },
  {
    "text": "and yellow line are actually a good guess that my prediction should be there",
    "start": "1375510",
    "end": "1380940"
  },
  {
    "text": "right 80% of my prediction should actually be in that channel and if I",
    "start": "1380940",
    "end": "1386130"
  },
  {
    "text": "plot a single sample that's the red line here okay so actually we see that if you",
    "start": "1386130",
    "end": "1393720"
  },
  {
    "text": "compare the purple line and the blue line they're pretty close right and and",
    "start": "1393720",
    "end": "1400230"
  },
  {
    "text": "the the purple line except for that end over there is pretty much within the",
    "start": "1400230",
    "end": "1406020"
  },
  {
    "text": "channel that I define right so it gives you confidence that your prediction is is kind of okay actually so now you have",
    "start": "1406020",
    "end": "1413970"
  },
  {
    "text": "to decide which one you want to use actually okay if you need to use one single time series in your app which one",
    "start": "1413970",
    "end": "1420660"
  },
  {
    "text": "would you take so let's take an example let's say you're predicting attendance for a restaurant right you want to know",
    "start": "1420660",
    "end": "1426330"
  },
  {
    "text": "how many people will show will show up at your restaurant tonight because you need to plan for you know you need to",
    "start": "1426330",
    "end": "1432150"
  },
  {
    "text": "shop and you need to have any extra staff and etc etc so if you predict and",
    "start": "1432150",
    "end": "1438059"
  },
  {
    "text": "you use the 19th percentile okay this is a very conservative prediction because",
    "start": "1438059",
    "end": "1444780"
  },
  {
    "text": "again 90% of the real predictions will",
    "start": "1444780",
    "end": "1450390"
  },
  {
    "text": "be lower than that so you could you could buy you know food and plant for staff according to the 19th percentile",
    "start": "1450390",
    "end": "1456990"
  },
  {
    "text": "but then again most of the time the real value will be lower okay so maybe you",
    "start": "1456990",
    "end": "1463230"
  },
  {
    "text": "spend too much money on food and maybe you plan for extra stuff that's not really needed so you could say okay",
    "start": "1463230",
    "end": "1468780"
  },
  {
    "text": "maybe the mean is a more reasonable way right because the mean is like you know I could use the mean spend less on",
    "start": "1468780",
    "end": "1476750"
  },
  {
    "text": "groceries and stuff and have maybe some contingency plan if there is really a peak of an unexpected peak of attendance",
    "start": "1476750",
    "end": "1484290"
  },
  {
    "text": "so again depending on your business problem you might use maybe the mean or you might use the 90th percentile or",
    "start": "1484290",
    "end": "1490260"
  },
  {
    "text": "something else okay but this is pretty pretty much how you work time series and",
    "start": "1490260",
    "end": "1496200"
  },
  {
    "text": "here's another example so I just build a bogus time series with temperatures for",
    "start": "1496200",
    "end": "1502410"
  },
  {
    "text": "2018 okay so just with a mean of nine a variation of three so I build 90",
    "start": "1502410",
    "end": "1509610"
  },
  {
    "text": "values here okay and I try to predict the next one okay and again well this is",
    "start": "1509610",
    "end": "1516600"
  },
  {
    "text": "these are my predictions for the next 30 days following my my time serie and well",
    "start": "1516600",
    "end": "1522929"
  },
  {
    "text": "again you can see you know the the random sample the red one is pretty much straight in the middle of the channel so",
    "start": "1522929",
    "end": "1529470"
  },
  {
    "text": "you know it looks like black my prediction is working right it looks like your prediction is working here so",
    "start": "1529470",
    "end": "1535289"
  },
  {
    "text": "again you could decide which one of the of the percentiles you want to use okay and then when you're done of course you",
    "start": "1535289",
    "end": "1541980"
  },
  {
    "text": "can clean up and delete everything so this is the first example of using a super complex I'll go I mean this is",
    "start": "1541980",
    "end": "1548880"
  },
  {
    "text": "really a state-of-the-art I'll go it came out last year to predict time series at scale you could be predicting you know billions of data points with",
    "start": "1548880",
    "end": "1556710"
  },
  {
    "text": "this but you never actually write a single line of machine learning code you just select and I'll go off the shelf",
    "start": "1556710",
    "end": "1562500"
  },
  {
    "text": "and you prepare your data which you would have to do anyway and and you train and then you predict okay so all",
    "start": "1562500",
    "end": "1569880"
  },
  {
    "text": "you have to understand it is how to use deep AR and then you can predict time series and again I would refer you to",
    "start": "1569880",
    "end": "1576030"
  },
  {
    "text": "the research paper if you if you want to know more okay let's look at let's look",
    "start": "1576030",
    "end": "1581340"
  },
  {
    "text": "at a second example so this one is another built-in algo and",
    "start": "1581340",
    "end": "1588360"
  },
  {
    "text": "it's it's for image classification so we have a service we have a high level service cause I'm called Amazon",
    "start": "1588360",
    "end": "1594690"
  },
  {
    "text": "recognition which I'm guessing you you've heard about and it's it's great",
    "start": "1594690",
    "end": "1599700"
  },
  {
    "text": "but it's a general-purpose service so what if I need to actually train and and",
    "start": "1599700",
    "end": "1604770"
  },
  {
    "text": "and build a model on my own custom set of images that are maybe domain specific",
    "start": "1604770",
    "end": "1609990"
  },
  {
    "text": "and that are not classified and recognized properly by recognition so we",
    "start": "1609990",
    "end": "1616770"
  },
  {
    "text": "have a built in Allegan for this it's actually based on a deeper learning model which you could use in two ways so",
    "start": "1616770",
    "end": "1623130"
  },
  {
    "text": "you could actually you could train from scratch so if you have a large data set of images that you want to classify you",
    "start": "1623130",
    "end": "1629970"
  },
  {
    "text": "could bring that to a three train from scratch using that deep learning network okay",
    "start": "1629970",
    "end": "1635620"
  },
  {
    "text": "that's one way or you could do what we call transfer learning and transfer",
    "start": "1635620",
    "end": "1641890"
  },
  {
    "text": "learning means you take a pre trade version of that network okay and network that has been trained on the millions of",
    "start": "1641890",
    "end": "1648190"
  },
  {
    "text": "images okay so that a network that already knows how to detect a lot of",
    "start": "1648190",
    "end": "1653679"
  },
  {
    "text": "shapes and a lot of objects and you can just retrain it for a bit on your own",
    "start": "1653679",
    "end": "1659409"
  },
  {
    "text": "data set okay this is also called fine tuning it's a very very powerful technique because it lets you get to",
    "start": "1659409",
    "end": "1666159"
  },
  {
    "text": "really high accuracy even when you have very little data right you don't need a lot of data here because the network has",
    "start": "1666159",
    "end": "1672580"
  },
  {
    "text": "already been trained and all you do is train it again okay so that's what we're doing here ok so",
    "start": "1672580",
    "end": "1681429"
  },
  {
    "text": "again starts the same I have to go and pick that container from the region I'm",
    "start": "1681429",
    "end": "1687130"
  },
  {
    "text": "running in ok and here I'm going to fine tune on so the the the pre-trained",
    "start": "1687130",
    "end": "1694210"
  },
  {
    "text": "network has been trained on the data set called image net so image net is a reference image data set with millions",
    "start": "1694210",
    "end": "1700570"
  },
  {
    "text": "and millions of images and thousands of categories ok so it already knows how to",
    "start": "1700570",
    "end": "1707289"
  },
  {
    "text": "recognize a lot of things but here just gonna take a smaller data set called Caltech 256 and as you can guess it has",
    "start": "1707289",
    "end": "1715510"
  },
  {
    "text": "256 classes ok and it has a small number of images right just oops just thirty",
    "start": "1715510",
    "end": "1723159"
  },
  {
    "text": "thousand which which is pretty small okay and that could be you know that",
    "start": "1723159",
    "end": "1728200"
  },
  {
    "text": "could be typical of a deal I said that you have many different classes but not so many images per class and so I'm",
    "start": "1728200",
    "end": "1734529"
  },
  {
    "text": "going to retrain my pre-trained network on Caltech 56 ok so I need to download",
    "start": "1734529",
    "end": "1740110"
  },
  {
    "text": "the data set upload it to s3 ok no big deal and then I need to define some",
    "start": "1740110",
    "end": "1747490"
  },
  {
    "text": "training parameters ok so actually I'm I can select the depth of the deep",
    "start": "1747490",
    "end": "1754149"
  },
  {
    "text": "Learning Network that I'm gonna use for for those of you who already 2d planning",
    "start": "1754149",
    "end": "1759549"
  },
  {
    "text": "this is it's a ResNet network ok so I'm gonna use 18 layers which is quite small",
    "start": "1759549",
    "end": "1765399"
  },
  {
    "text": "actually I need to define the shut the size of the images how many",
    "start": "1765399",
    "end": "1771630"
  },
  {
    "text": "training samples I have how many classes I have so it says 257 because we",
    "start": "1771630",
    "end": "1777360"
  },
  {
    "text": "actually have 256 classes okay objects etc and there's a like a catch-all",
    "start": "1777360",
    "end": "1782400"
  },
  {
    "text": "category so that's why 257 batch size number of epochs and as you can see here",
    "start": "1782400",
    "end": "1789840"
  },
  {
    "text": "I'm only training for two ed box which is very very low right again I can afford to do this because I'm just",
    "start": "1789840",
    "end": "1795600"
  },
  {
    "text": "fine-tuning I'm not training from scratch and again this is another of the advantages of fine tuning you can",
    "start": "1795600",
    "end": "1801480"
  },
  {
    "text": "actually train for a very very limited amount of time just with your own images",
    "start": "1801480",
    "end": "1806520"
  },
  {
    "text": "and get very good results so it's not it's not a it's a fast and unexpensive technique okay so so these are my my",
    "start": "1806520",
    "end": "1815820"
  },
  {
    "text": "parameters so I need to put all that stuff in a JSON document okay defining",
    "start": "1815820",
    "end": "1822150"
  },
  {
    "text": "again the location of my data set how much infrastructure do I want so here",
    "start": "1822150",
    "end": "1828150"
  },
  {
    "text": "I'm gonna train on a single p2 instance okay the eiper parameters etc etc okay",
    "start": "1828150",
    "end": "1833720"
  },
  {
    "text": "where the data is and all this stuff is really boilerplate right you can really cut and paste and use your own values",
    "start": "1833720",
    "end": "1840090"
  },
  {
    "text": "here okay and then I'm going to use the",
    "start": "1840090",
    "end": "1845420"
  },
  {
    "text": "let's say to make your API to create a training job okay and and this is a",
    "start": "1845420",
    "end": "1852060"
  },
  {
    "text": "synchronous call so this is the low-level API in sage maker actually so I'm going to create the training job and",
    "start": "1852060",
    "end": "1859410"
  },
  {
    "text": "and then I can use a waiter to see when the job is actually complete okay so it",
    "start": "1859410",
    "end": "1865920"
  },
  {
    "text": "trains for a while okay and then the trainee job is complete right and then I",
    "start": "1865920",
    "end": "1871680"
  },
  {
    "text": "can deploy I can deploy the model so I will first say the model in stage maker register it to Sage maker here okay and",
    "start": "1871680",
    "end": "1879050"
  },
  {
    "text": "then I can create that endpoint configuration which I was talking about earlier okay so here you see all the",
    "start": "1879050",
    "end": "1886680"
  },
  {
    "text": "actual steps that are involved so here of course I'm deploying a single model and all traffic goes to that model but",
    "start": "1886680",
    "end": "1894180"
  },
  {
    "text": "this is where you could say hey let's have maybe yesterday's model and today's model and",
    "start": "1894180",
    "end": "1899399"
  },
  {
    "text": "split traffic 50/50 to make sure the new model actually works okay so here's the actual end point configuration here then",
    "start": "1899399",
    "end": "1906989"
  },
  {
    "text": "create the end points okay so again create an instance deploy everything to the instance wait for it",
    "start": "1906989",
    "end": "1914820"
  },
  {
    "text": "to be ready and then we can predict right so I can grab any of the images so",
    "start": "1914820",
    "end": "1921419"
  },
  {
    "text": "this is a bathtub image which is one of the categories in Caltech 256 so just",
    "start": "1921419",
    "end": "1926609"
  },
  {
    "text": "grab one of them from the web and we can display it so yeah it is a bathtub and",
    "start": "1926609",
    "end": "1932399"
  },
  {
    "text": "then I can pass that image to post it to",
    "start": "1932399",
    "end": "1938609"
  },
  {
    "text": "the end point okay and and read the highest probability and you can see the",
    "start": "1938609",
    "end": "1944849"
  },
  {
    "text": "categories here a baseball glove and bathtub and beer mug and all kinds of",
    "start": "1944849",
    "end": "1951210"
  },
  {
    "text": "thing 256 of them and so the highest probability is actually the one",
    "start": "1951210",
    "end": "1957779"
  },
  {
    "text": "corresponding to bathtub okay so this is how in again just a couple of epics",
    "start": "1957779",
    "end": "1963509"
  },
  {
    "text": "which took maybe I don't know 10 minutes to Train I can take a pre trained deep",
    "start": "1963509",
    "end": "1969690"
  },
  {
    "text": "learning model apply my own data set to it and just get really good results okay",
    "start": "1969690",
    "end": "1976229"
  },
  {
    "text": "so what if you wanted to invoke this thing from your app because here I'm using the SDK in a notebook and it's",
    "start": "1976229",
    "end": "1983729"
  },
  {
    "text": "probably not it's good for experimentation but it's probably not the way you're gonna do it right you want to deploy that model to the",
    "start": "1983729",
    "end": "1989489"
  },
  {
    "text": "endpoint and then you want your application to actually invoke it okay so can we can we do this with a proper",
    "start": "1989489",
    "end": "1997799"
  },
  {
    "text": "app so here I'm going to use I'm going",
    "start": "1997799",
    "end": "2007580"
  },
  {
    "text": "to use an alias open source project project called chalice that lets you",
    "start": "2007580",
    "end": "2013129"
  },
  {
    "text": "deploy Python web services in the API gateway",
    "start": "2013129",
    "end": "2019090"
  },
  {
    "text": "and lambda so literally going to deploy a serverless app that lets me invoke and",
    "start": "2019090",
    "end": "2027250"
  },
  {
    "text": "pre process and post process data with that endpoint so it's actually not a lot",
    "start": "2027250",
    "end": "2032350"
  },
  {
    "text": "of code right it's not a lot of code and",
    "start": "2032350",
    "end": "2041080"
  },
  {
    "text": "if you if you have Python programmers in the room who use flask this is very very",
    "start": "2041080",
    "end": "2048129"
  },
  {
    "text": "similar to flask it's like flask or server list as I call it okay so I'm going to create a web",
    "start": "2048130",
    "end": "2054820"
  },
  {
    "text": "service to which I can post and so what what I'm going to post a base64 encoded",
    "start": "2054820",
    "end": "2061600"
  },
  {
    "text": "image to to this to this API okay",
    "start": "2061600",
    "end": "2066669"
  },
  {
    "text": "so the first thing that I need to grab is over of course the data in the body decoded I'm going to grab the endpoint",
    "start": "2066669",
    "end": "2073690"
  },
  {
    "text": "name which is stored as an environment variable in the lambda function and then",
    "start": "2073690",
    "end": "2080889"
  },
  {
    "text": "optionally I have a topic a variable that tells me how many probabilities do",
    "start": "2080890",
    "end": "2087940"
  },
  {
    "text": "I want to see actually for this image because most of the time I guess I don't want to see 256 probabilities I don't",
    "start": "2087940",
    "end": "2094179"
  },
  {
    "text": "care maybe I want the top five right so if that top k variable is passed and",
    "start": "2094179",
    "end": "2099400"
  },
  {
    "text": "says five then I'm just gonna output the top five probabilities okay and then I",
    "start": "2099400",
    "end": "2104440"
  },
  {
    "text": "get sage maker client I invoke the endpoints right to the folder the sage",
    "start": "2104440",
    "end": "2110290"
  },
  {
    "text": "maker in point IJ code the result and I",
    "start": "2110290",
    "end": "2117010"
  },
  {
    "text": "just sort those 256 probabilities and output the top k right so pretty simple",
    "start": "2117010",
    "end": "2126250"
  },
  {
    "text": "code so this is how you would invoke it so let's let's deploy this thing which",
    "start": "2126250",
    "end": "2134230"
  },
  {
    "text": "is as easy as challenge deploy okay and",
    "start": "2134230",
    "end": "2139270"
  },
  {
    "text": "so this automatically creates a deployment package for the lambda function deploys the lambda function",
    "start": "2139270",
    "end": "2145270"
  },
  {
    "text": "creates an api gateway and here's the end points that has been created so there",
    "start": "2145270",
    "end": "2150910"
  },
  {
    "text": "you go right and now I can invoke that thing and see how it works so I have a",
    "start": "2150910",
    "end": "2158170"
  },
  {
    "text": "small script to do that okay so I'm gonna take a couple of sample images and",
    "start": "2158170",
    "end": "2164740"
  },
  {
    "text": "yeah it's an American data set so hamburger will do just fine and I am",
    "start": "2164740",
    "end": "2170200"
  },
  {
    "text": "just literally posting that yeah posting that base64 encoded image to my chalice",
    "start": "2170200",
    "end": "2178380"
  },
  {
    "text": "web service which will invoke the stage maker endpoints get the 256",
    "start": "2178380",
    "end": "2184810"
  },
  {
    "text": "probabilities and just output the top three in this case so let's try and do",
    "start": "2184810",
    "end": "2190300"
  },
  {
    "text": "this hopefully it's gonna work yes okay",
    "start": "2190300",
    "end": "2197800"
  },
  {
    "text": "so it tells me the top three probabilities for this image are 95 147",
    "start": "2197800",
    "end": "2204250"
  },
  {
    "text": "226 but 95 is really the one that I care about 97% so now either you trust me",
    "start": "2204250",
    "end": "2210670"
  },
  {
    "text": "that 95 is the hamburger class or you don't so I can feel that you don't",
    "start": "2210670",
    "end": "2216180"
  },
  {
    "text": "you're right I'm French don't trust me never never trust an evangelist anyway",
    "start": "2216180",
    "end": "2223800"
  },
  {
    "text": "so let's check let's go into that verbs in to the dataset 95 yeah",
    "start": "2223800",
    "end": "2238600"
  },
  {
    "text": "and burgers right so see I didn't lie so this is an example of creating a small",
    "start": "2238600",
    "end": "2245350"
  },
  {
    "text": "web service that will do maybe pre-processing let's say maybe you need",
    "start": "2245350",
    "end": "2250780"
  },
  {
    "text": "to inject additional data into the prediction right so you maybe you would pull it from a back end somewhere",
    "start": "2250780",
    "end": "2257110"
  },
  {
    "text": "DynamoDB and then call the sage maker endpoint most of the time you will need to do post processing as well filter out",
    "start": "2257110",
    "end": "2263770"
  },
  {
    "text": "the probabilities like I like a deal here so it's just a very simple and an expensive way to to get the job done and",
    "start": "2263770",
    "end": "2272080"
  },
  {
    "text": "as you can see deployment is is really is really a breeze right chalice is a is",
    "start": "2272080",
    "end": "2277240"
  },
  {
    "text": "a really really good tool not only for this alright so here's an example of going all the way training model",
    "start": "2277240",
    "end": "2282970"
  },
  {
    "text": "deploying the endpoint and then actually invoking it from let's say an external web service alright do you have time for",
    "start": "2282970",
    "end": "2292120"
  },
  {
    "text": "one more yeah I think we have so let's",
    "start": "2292120",
    "end": "2301120"
  },
  {
    "text": "go for this one here so so far I showed",
    "start": "2301120",
    "end": "2307450"
  },
  {
    "text": "you how to use the Python SDK to do to get the job done with a sage maker but",
    "start": "2307450",
    "end": "2313030"
  },
  {
    "text": "there's another SDK for a spark okay which is available in Scala and PI spark",
    "start": "2313030",
    "end": "2319810"
  },
  {
    "text": "so you can actually invoke sage maker from your from your spark cluster okay",
    "start": "2319810",
    "end": "2326950"
  },
  {
    "text": "why would you want to do that well as you probably know spark is extremely good at data processing and it's a",
    "start": "2326950",
    "end": "2333520"
  },
  {
    "text": "popular choice for data cleaning data filtering aggregation etc and chances",
    "start": "2333520",
    "end": "2340510"
  },
  {
    "text": "are if you have a large conflict data set you have to do that before you train your model okay and again spark is a",
    "start": "2340510",
    "end": "2347590"
  },
  {
    "text": "popular way to do that so you could create a spark cluster with",
    "start": "2347590",
    "end": "2353630"
  },
  {
    "text": "the best instance type okay for that job do the cleaning then create the training",
    "start": "2353630",
    "end": "2360800"
  },
  {
    "text": "job on sage maker and train with the best instance type as well and then deploy the model and then run",
    "start": "2360800",
    "end": "2366770"
  },
  {
    "text": "predictions from your spark cluster so here I'm going to build a simple spam classifier so it's a simple data set",
    "start": "2366770",
    "end": "2375010"
  },
  {
    "text": "it's got two files one with spam what with not spam one line per one line per message okay",
    "start": "2375010",
    "end": "2383359"
  },
  {
    "text": "so here of course I'm gonna do really basic cleaning you could you could probably do a lot more and a lot more",
    "start": "2383359",
    "end": "2391579"
  },
  {
    "text": "complicated things so here I'm just putting everything into lower case",
    "start": "2391579",
    "end": "2397180"
  },
  {
    "text": "removing everything that's not a letter so punctuation numbers etc and removing",
    "start": "2397180",
    "end": "2403069"
  },
  {
    "text": "whitespace okay so I've got my two data frames here in our rdd's actually",
    "start": "2403069",
    "end": "2410390"
  },
  {
    "text": "inspark containing those data sets okay and now",
    "start": "2410390",
    "end": "2415670"
  },
  {
    "text": "what I want to do is I'm going to hash I'm going to build a feature vectors",
    "start": "2415670",
    "end": "2422150"
  },
  {
    "text": "from those text messages so I'm good I'm using a an object called a ship hashing TF which will actually build word",
    "start": "2422150",
    "end": "2429619"
  },
  {
    "text": "vectors so 200 word vectors with a word",
    "start": "2429619",
    "end": "2435380"
  },
  {
    "text": "index and a word frequency okay and the the intuition here is some words if you",
    "start": "2435380",
    "end": "2441770"
  },
  {
    "text": "see some specific words in a message it's probably spam right spam tends to",
    "start": "2441770",
    "end": "2447470"
  },
  {
    "text": "be really you know a caricature so so that's the basic idea we want to take",
    "start": "2447470",
    "end": "2454130"
  },
  {
    "text": "the top 200 words and and build vectors for spam and not spam and hopefully",
    "start": "2454130",
    "end": "2460670"
  },
  {
    "text": "that's gonna help us figure out which is which okay so this is what I'm doing here splitting the the lines into words",
    "start": "2460670",
    "end": "2467720"
  },
  {
    "text": "and and building those vectors so here's an example for it so that's a proper",
    "start": "2467720",
    "end": "2473750"
  },
  {
    "text": "proper sample so it's a vector and here that message has worth 25 40 199 146",
    "start": "2473750",
    "end": "2481369"
  },
  {
    "text": "whatever they are and we have the word frequencies here okay and this is actually what we're",
    "start": "2481369",
    "end": "2486930"
  },
  {
    "text": "going to classify we transform the word into into integers and and the messages",
    "start": "2486930",
    "end": "2493890"
  },
  {
    "text": "into word vectors with frequencies so I'm going to label spam messages with",
    "start": "2493890",
    "end": "2499470"
  },
  {
    "text": "one non spam messages with zero okay so this just adds a label as you can see",
    "start": "2499470",
    "end": "2506520"
  },
  {
    "text": "here to my samples then I'm going to put the two together right shuffle them and",
    "start": "2506520",
    "end": "2512810"
  },
  {
    "text": "split the data set into training and validation again splitting 8020 okay so",
    "start": "2512810",
    "end": "2520920"
  },
  {
    "text": "now I've got two two rdd's one with the training set one with the test set okay",
    "start": "2520920",
    "end": "2527550"
  },
  {
    "text": "so now I'm ready to train so I'm using extra boost the XJ bus classifier to do",
    "start": "2527550",
    "end": "2533850"
  },
  {
    "text": "this which is one of the built-in algos in in Sage Maker and this one is a bit",
    "start": "2533850",
    "end": "2540720"
  },
  {
    "text": "different compared to the others it does require data to be in a specific format",
    "start": "2540720",
    "end": "2546270"
  },
  {
    "text": "called Lib SVM okay so no big deal because there's a there's a function in the inspark to do that okay and so",
    "start": "2546270",
    "end": "2554760"
  },
  {
    "text": "that's my data set right there okay so just convert it again just like we converted to JSON for a GPR we need to",
    "start": "2554760",
    "end": "2561960"
  },
  {
    "text": "convert to leave SVM for extra boost okay and then I can just configure my",
    "start": "2561960",
    "end": "2568320"
  },
  {
    "text": "training job okay so using the spark SDK for stage maker I'm going to create that",
    "start": "2568320",
    "end": "2575820"
  },
  {
    "text": "extra boost estimator define my training infrastructure define my prediction for",
    "start": "2575820",
    "end": "2581820"
  },
  {
    "text": "a structure define some parameters for the training job I'm really building a",
    "start": "2581820",
    "end": "2587250"
  },
  {
    "text": "binary classifier here and then I can train okay so from the spark cluster",
    "start": "2587250",
    "end": "2593730"
  },
  {
    "text": "here I'm firing up a training instance and just like we've done before and so",
    "start": "2593730",
    "end": "2600270"
  },
  {
    "text": "sage maker will actually train using the extra boost built-in I'll go just like we've done before okay and it terminates",
    "start": "2600270",
    "end": "2607410"
  },
  {
    "text": "automatically okay it deploys the endpoint and then I can predict okay so",
    "start": "2607410",
    "end": "2614730"
  },
  {
    "text": "once again I'm gonna take my test set converted to leave as VM and just invoke",
    "start": "2614730",
    "end": "2622400"
  },
  {
    "text": "my model from spark okay invoke the sage maker endpoint from spark and get",
    "start": "2622400",
    "end": "2628039"
  },
  {
    "text": "predictions right so this you really get the best of both worlds here because you",
    "start": "2628039",
    "end": "2633710"
  },
  {
    "text": "can you can configure and size your spark cluster in the best possible way",
    "start": "2633710",
    "end": "2639589"
  },
  {
    "text": "right using the best instance type the best size etc etc and then you can do",
    "start": "2639589",
    "end": "2645470"
  },
  {
    "text": "the same for the sage maker training cluster and the sage make a prediction cluster so maybe you know maybe you want",
    "start": "2645470",
    "end": "2652039"
  },
  {
    "text": "em for instances for spark because you need a lot of memory maybe you need P three instances to train because you",
    "start": "2652039",
    "end": "2658670"
  },
  {
    "text": "want GPUs and you need a lot of power and maybe you need you know c4 or c5 to",
    "start": "2658670",
    "end": "2664520"
  },
  {
    "text": "predict because you want very fast predictions right so by splitting those three concerns right ETL training and",
    "start": "2664520",
    "end": "2671569"
  },
  {
    "text": "deploying you actually get the best of all those worlds first was trying to do",
    "start": "2671569",
    "end": "2676789"
  },
  {
    "text": "everything on a spark cluster which will be some kind of compromise right and here you can really avoid that",
    "start": "2676789",
    "end": "2683990"
  },
  {
    "text": "compromise and do everything yourself and of course we could compute accuracy",
    "start": "2683990",
    "end": "2689779"
  },
  {
    "text": "okay so looking at my predicted data okay so that's the original label and",
    "start": "2689779",
    "end": "2694819"
  },
  {
    "text": "that's the predictor label for those samples I can I can count the number of",
    "start": "2694819",
    "end": "2701260"
  },
  {
    "text": "predictions that are actually correct divide everything by the total number of",
    "start": "2701260",
    "end": "2706609"
  },
  {
    "text": "predictions and this gives me 97 plus accuracy I'm not sure if it's good or",
    "start": "2706609",
    "end": "2712430"
  },
  {
    "text": "great but okay it's not too bad okay so here's an example of mixing both okay mixing both sage maker and spark for the",
    "start": "2712430",
    "end": "2721700"
  },
  {
    "text": "best the best of all worlds I guess all right I think we're done so if you if",
    "start": "2721700",
    "end": "2730190"
  },
  {
    "text": "you need if you need more resources I would really point you to let me show",
    "start": "2730190",
    "end": "2736640"
  },
  {
    "text": "you maybe one single slide if I can find my deck",
    "start": "2736640",
    "end": "2742328"
  },
  {
    "text": "[Applause] if you if you want to get started with",
    "start": "2743880",
    "end": "2750349"
  },
  {
    "text": "with sage maker come on PowerPoint these are the yeah",
    "start": "2750349",
    "end": "2758570"
  },
  {
    "text": "the the good links to look at there we go",
    "start": "2758570",
    "end": "2765099"
  },
  {
    "text": "so obviously the the the product page for sage maker that has also customer references etc the sage maker examples",
    "start": "2765140",
    "end": "2772460"
  },
  {
    "text": "is the the github repository where you will find all the notebooks that show you how to use sage maker in many",
    "start": "2772460",
    "end": "2778310"
  },
  {
    "text": "different ways the built in articles etc the sage maker SDK there's also like I",
    "start": "2778310",
    "end": "2784099"
  },
  {
    "text": "said a spark SDK which you'll find on github as well and if you want an overview of sage maker and how to use it",
    "start": "2784099",
    "end": "2790520"
  },
  {
    "text": "in different configurations with tensorflow and and so on this is the youtube video to look at okay and last",
    "start": "2790520",
    "end": "2797690"
  },
  {
    "text": "but not least my blog where I tend to post a lot of stuff on the Jeep running MX net sage maker and you'll find more",
    "start": "2797690",
    "end": "2805550"
  },
  {
    "text": "examples there alright thank you very much and enjoy the rest of your day [Applause]",
    "start": "2805550",
    "end": "2815380"
  }
]
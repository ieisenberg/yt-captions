[
  {
    "text": "hello uh welcome everybody uh thanks for coming I know it's the last session of the day it's been a long day and I",
    "start": "560",
    "end": "6279"
  },
  {
    "text": "appreciate your attendance here uh on the stage with me is eigor the CTO of 7 Bridges genomics today we're going to be",
    "start": "6279",
    "end": "12400"
  },
  {
    "text": "talking about security and compliance on a petabyte scale uh eigor is going to handle the first part of the talk and",
    "start": "12400",
    "end": "17800"
  },
  {
    "text": "I'll come back up for a second thank",
    "start": "17800",
    "end": "21160"
  },
  {
    "text": "you for coming and uh I would like to thank Amazon for inviting us to actually",
    "start": "23160",
    "end": "30000"
  },
  {
    "text": "share this talk with you so what you're going to see during this talk and what we actually want to share with you is",
    "start": "30000",
    "end": "36600"
  },
  {
    "text": "actually a little bit of background uh around the unique challenges that we actually faced when we had to secure",
    "start": "36600",
    "end": "43719"
  },
  {
    "text": "genomics information at this scale we're going to work to the case study of how we plan to democratize the access to the",
    "start": "43719",
    "end": "50800"
  },
  {
    "text": "cancer genome Atlas or So-Cal tcga data and we're plan to do this to S Bridges",
    "start": "50800",
    "end": "56359"
  },
  {
    "text": "cancer genomics Cloud platform and we're also going to go to couple of deep Dives how we actually manage to leverage AWS",
    "start": "56359",
    "end": "63280"
  },
  {
    "text": "to support and secure all this data and how to meet the compliance that's needed",
    "start": "63280",
    "end": "68880"
  },
  {
    "text": "to in order to actually give people access to the data so let's first start",
    "start": "68880",
    "end": "75360"
  },
  {
    "text": "with why is securing genomics data so hard there are many reasons but we",
    "start": "75360",
    "end": "81119"
  },
  {
    "text": "actually believe that there are three major components to that first of all is actually that genomics data is big and",
    "start": "81119",
    "end": "87880"
  },
  {
    "text": "it's only getting bigger at this image behind me you can actually see that that",
    "start": "87880",
    "end": "93960"
  },
  {
    "text": "we are in an influx point now and that the as the number of sequencers is growing and the data that's being",
    "start": "93960",
    "end": "100520"
  },
  {
    "text": "produced is actually expanding uh on on on uh at such a huge",
    "start": "100520",
    "end": "107640"
  },
  {
    "text": "pace and that we only between 2014 and 2018 expect expected the production of",
    "start": "107640",
    "end": "114560"
  },
  {
    "text": "new ngsd data will exceed two exhibites so besides that genomes are inherently",
    "start": "114560",
    "end": "121119"
  },
  {
    "text": "sensitive they're very personal data and you cannot really fully anonymize this information with current paradigms and",
    "start": "121119",
    "end": "128360"
  },
  {
    "text": "once it's out there you can't really take it back pretty much the same like with the fingerprints and besides",
    "start": "128360",
    "end": "137040"
  },
  {
    "text": "that research is highly collaborative and diverse activity it occurs in large",
    "start": "137360",
    "end": "142800"
  },
  {
    "text": "teams and numerous analytical tools are being used to process this data and these tools are not being built with",
    "start": "142800",
    "end": "149440"
  },
  {
    "text": "either security or scalability in mind that said we the challenge we are",
    "start": "149440",
    "end": "154879"
  },
  {
    "text": "trying to to meet here is to enable thousands of researchers that are using hundreds of custom tools to analyze the",
    "start": "154879",
    "end": "161280"
  },
  {
    "text": "pites of highly sensitive data in a secure and compliant environment and",
    "start": "161280",
    "end": "166800"
  },
  {
    "text": "we're going to work you now through the case study how we actually plan to bring the tcga data to the",
    "start": "166800",
    "end": "172040"
  },
  {
    "text": "cloud so I believe that at least certain part of you is familiar what tcj data is",
    "start": "172040",
    "end": "179120"
  },
  {
    "text": "but just for for those of you that are not familiar with it it's one of the richest and most complete genomics data",
    "start": "179120",
    "end": "184280"
  },
  {
    "text": "sets in the world it contains 34 tumor types from thousands of patients analyz",
    "start": "184280",
    "end": "190040"
  },
  {
    "text": "across the multiple Dimensions just to mention a few it's a it's a micro RNA uh",
    "start": "190040",
    "end": "197080"
  },
  {
    "text": "data it's a copy variant data it's a squish genomic data so it's it's being",
    "start": "197080",
    "end": "203959"
  },
  {
    "text": "develop it's actually being produced in last 10 years by researchers all across the United States and so far it costed",
    "start": "203959",
    "end": "210560"
  },
  {
    "text": "two more than $375 million to produce this data and we're talking about more",
    "start": "210560",
    "end": "216400"
  },
  {
    "text": "than 1.5 pabes of data expected to grow to 3.5 pedabytes just in next",
    "start": "216400",
    "end": "223519"
  },
  {
    "text": "year that said learning from the data is very challenging to put it in a",
    "start": "223519",
    "end": "228560"
  },
  {
    "text": "perspective imagine that you want to move 2.5 pedabytes to your local storage in case you have a local storage and you",
    "start": "228560",
    "end": "235640"
  },
  {
    "text": "have have actually a place where you can store such such a large amounts of data it will take you took you take you over",
    "start": "235640",
    "end": "242400"
  },
  {
    "text": "23 days to download this data to through 10 GB connection and that's all assuming",
    "start": "242400",
    "end": "247799"
  },
  {
    "text": "that you don't have any Network glitches and any problem with the storage which which is highly unlikely to happen and",
    "start": "247799",
    "end": "254439"
  },
  {
    "text": "not not only that it costs more than $2 million per year to just store this data",
    "start": "254439",
    "end": "259919"
  },
  {
    "text": "and not only that this data is actually being replicated among across the multiple data centers across the United",
    "start": "259919",
    "end": "265840"
  },
  {
    "text": "States which which brings us to much larger sums of money that's being currently spent on just storing the data",
    "start": "265840",
    "end": "272600"
  },
  {
    "text": "and this data just to get any meaningful results out of that requires significant",
    "start": "272600",
    "end": "277880"
  },
  {
    "text": "computational resources which means that you also have to transfer that data somewhere in order to process it and to",
    "start": "277880",
    "end": "284320"
  },
  {
    "text": "bring because you have to always bring computation to that data not other way around and collaborating in real time",
    "start": "284320",
    "end": "291000"
  },
  {
    "text": "using this structure is very challenging so to meet this challenge uh",
    "start": "291000",
    "end": "297720"
  },
  {
    "text": "NCI NH actually uh announced the cancer genomic Cloud pilot and they're trying",
    "start": "297720",
    "end": "303280"
  },
  {
    "text": "to address this difficulties directly this whole this whole program was initiated by Dr Hollard varas in 2014 an",
    "start": "303280",
    "end": "311080"
  },
  {
    "text": "announcement was issued in January 2014 and three Pilots have been awarded in",
    "start": "311080",
    "end": "316120"
  },
  {
    "text": "September 2014 Broad Institute Institute for systems biology and S British genomics",
    "start": "316120",
    "end": "322759"
  },
  {
    "text": "so what's our approach to actually democratize this this access to dcj data",
    "start": "322759",
    "end": "329400"
  },
  {
    "text": "uh so there are a couple of components we like to talk about it first of all is data what we actually trying to do is to",
    "start": "329400",
    "end": "336199"
  },
  {
    "text": "immediately to actually enable researchers to immediately and securely access the pedabytes of both open access",
    "start": "336199",
    "end": "342560"
  },
  {
    "text": "and control access cancer genomics data and also as an NH trusted partner 7 Bridges genomics is able to author",
    "start": "342560",
    "end": "349880"
  },
  {
    "text": "authorize approved researchers to even access the control access data and this is the first control access genomic data",
    "start": "349880",
    "end": "356479"
  },
  {
    "text": "set on AWS also very important component that of that is reproducibility because in",
    "start": "356479",
    "end": "363759"
  },
  {
    "text": "order to share the results and in order to actually replicate the results across the different groups that are studying",
    "start": "363759",
    "end": "369880"
  },
  {
    "text": "this data you need to be able to uh to actually execute this workflow and always get the same result which means",
    "start": "369880",
    "end": "376800"
  },
  {
    "text": "that basically you always have to do it with the same versions of the tools and this you always have to be able to",
    "start": "376800",
    "end": "382720"
  },
  {
    "text": "replicate result otherwise the research is meaningless the third component is actually we're trying to do this through",
    "start": "382720",
    "end": "389599"
  },
  {
    "text": "Open Standards we are we are actually enabling the native execution of Docker based common workow language which is",
    "start": "389599",
    "end": "396319"
  },
  {
    "text": "slowly becoming the standard standard in our industry and and that means that you can actually if you build your pipeline",
    "start": "396319",
    "end": "402759"
  },
  {
    "text": "on our platform you can always move this this pipeline to some other platform that also supports the standards and",
    "start": "402759",
    "end": "409080"
  },
  {
    "text": "vice versa and also you can integrate with us and actually have a greater level of interoperability by using our",
    "start": "409080",
    "end": "416360"
  },
  {
    "text": "API and all that is actually implemented through our genomics platform this is just a illustration just a diagram to",
    "start": "416360",
    "end": "423680"
  },
  {
    "text": "show that there are so many components that actually have to scale and work securely in order to meet this Challenge",
    "start": "423680",
    "end": "429960"
  },
  {
    "text": "and so how we actually Leverage The AWS to support secure and compliant genomics",
    "start": "429960",
    "end": "436400"
  },
  {
    "text": "research so we are going to talk to both about security and compliance they're connected but separate in a way you",
    "start": "436400",
    "end": "443680"
  },
  {
    "text": "can't really say that if you if you've built secure platform that you're actually meeting any compliance clients",
    "start": "443680",
    "end": "450400"
  },
  {
    "text": "and that you are actually able to talk with the language with other institutions and that they have a full",
    "start": "450400",
    "end": "455960"
  },
  {
    "text": "trust in your in your both your security and processes around that and and vice versa you can have compliant platform",
    "start": "455960",
    "end": "462960"
  },
  {
    "text": "that has all the standards met but it doesn't mean that you're actually meeting any security standards that are",
    "start": "462960",
    "end": "468639"
  },
  {
    "text": "higher than just basic required by compliance so let's reflect a little bit",
    "start": "468639",
    "end": "473960"
  },
  {
    "text": "about security we're just going to walk work through networking data security",
    "start": "473960",
    "end": "479520"
  },
  {
    "text": "that are we trying to build on our side this is what you're going to see is a very simplified system architecture",
    "start": "479520",
    "end": "486919"
  },
  {
    "text": "diagram and we have many more basically environments that are than that are",
    "start": "486919",
    "end": "492120"
  },
  {
    "text": "shown here but I just want to share with you the very controll data flow that has",
    "start": "492120",
    "end": "497319"
  },
  {
    "text": "to happen in order to to actually have a secure platform and that you you have to restrict the the resources and and and",
    "start": "497319",
    "end": "505280"
  },
  {
    "text": "sharing and and transfer and data transfer between the between the various resour and various environments in in",
    "start": "505280",
    "end": "511560"
  },
  {
    "text": "your in your platform for instance you don't want to really share the the the",
    "start": "511560",
    "end": "517200"
  },
  {
    "text": "the all the data that's that's that's actually secure and and and basically stored in the production environment and",
    "start": "517200",
    "end": "524080"
  },
  {
    "text": "that's basically personal envir personal data with with necessarily with the",
    "start": "524080",
    "end": "529279"
  },
  {
    "text": "processes that are running in our development environment or staging environment Etc and in order to do that one of the",
    "start": "529279",
    "end": "537160"
  },
  {
    "text": "things that we actually have to do just a second actually that you have to secure",
    "start": "537160",
    "end": "544240"
  },
  {
    "text": "a n network we are both we are both separating our accounts and have a",
    "start": "544240",
    "end": "550040"
  },
  {
    "text": "different level of compliance in our Amazon account but you also want to isolate isolate the network further and",
    "start": "550040",
    "end": "556240"
  },
  {
    "text": "actually have separate vpcs for different environments in the same at the same account and you also want",
    "start": "556240",
    "end": "562920"
  },
  {
    "text": "further use control groups and isolate the instances and far all the instances in order to to limit access to the to",
    "start": "562920",
    "end": "571200"
  },
  {
    "text": "the to the resources on in your network and also you want to secure your data",
    "start": "571200",
    "end": "579160"
  },
  {
    "text": "and and encrypt your data both at rest and in transit and that basically mean",
    "start": "579160",
    "end": "585160"
  },
  {
    "text": "that we are leveraging the the service side encryption in sree and you can also",
    "start": "585160",
    "end": "590800"
  },
  {
    "text": "you can also leverage both the key management that's that's built in on the server side encryption and Amazon but",
    "start": "590800",
    "end": "597000"
  },
  {
    "text": "you we can always integrate with a separate service side with separate KMS",
    "start": "597000",
    "end": "602279"
  },
  {
    "text": "Solutions and we also leverage extensively a EBS encryption and we",
    "start": "602279",
    "end": "607680"
  },
  {
    "text": "encrypt fmar storage on our side as well because all the data no matter whether",
    "start": "607680",
    "end": "613040"
  },
  {
    "text": "it's Phi and Control Data or not is is being is resided on on our on encrypted",
    "start": "613040",
    "end": "619720"
  },
  {
    "text": "storage in on Amazon instances and also we are encrypting all the transit data",
    "start": "619720",
    "end": "624800"
  },
  {
    "text": "in transit we are never actually never sharing the data without Inc",
    "start": "624800",
    "end": "630720"
  },
  {
    "text": "but unless we it's actually being transferred to the encrypted Channel and also in if you want to integrate your",
    "start": "630720",
    "end": "638480"
  },
  {
    "text": "own buckets to our platform you can do so by giving us giving us rights to ACLS",
    "start": "638480",
    "end": "646040"
  },
  {
    "text": "and to ACs on on on IM am and actually give us just read access in order to",
    "start": "646040",
    "end": "651440"
  },
  {
    "text": "actually share your data with us and so just to also moreover we are not only",
    "start": "651440",
    "end": "659360"
  },
  {
    "text": "leveraging leveraging that but we are not sharing the whole buckets with anybody you never want to share your",
    "start": "659360",
    "end": "665079"
  },
  {
    "text": "bucket with with all Control Data from your all your customers to your instances you always want to limit the",
    "start": "665079",
    "end": "671880"
  },
  {
    "text": "the access only to the to to the level that particular process or user has to",
    "start": "671880",
    "end": "676920"
  },
  {
    "text": "see so we always sign the particular Amazon objects that that should be used",
    "start": "676920",
    "end": "684240"
  },
  {
    "text": "on on on machines that this this tools are going to be executed and we never",
    "start": "684240",
    "end": "690040"
  },
  {
    "text": "use any we never process the data on instances that they don't have dedicated",
    "start": "690040",
    "end": "695480"
  },
  {
    "text": "tency that actually means that in order to process if you running the your your",
    "start": "695480",
    "end": "701760"
  },
  {
    "text": "processing on some Amazon instance you're you're never sharing the hypervisor with anybody else it's this",
    "start": "701760",
    "end": "708680"
  },
  {
    "text": "machine is completely under your control and it's you have complete physical is isolation from the other Amazon users",
    "start": "708680",
    "end": "716480"
  },
  {
    "text": "and we are only using encrypted storage and we strictly Pur the data that actually means that in between the the",
    "start": "716480",
    "end": "722720"
  },
  {
    "text": "processing stages we are removing the data from the disk and not only that Amazon also purchase the dis at the end",
    "start": "722720",
    "end": "729959"
  },
  {
    "text": "when you actually don't want to use this instance anymore that",
    "start": "729959",
    "end": "735360"
  },
  {
    "text": "said security is nice but you still have to enable parall file access at scale",
    "start": "735360",
    "end": "741079"
  },
  {
    "text": "and it's not enough just to it's not enough only to actually secure this data you have to have to enable users to do",
    "start": "741079",
    "end": "748880"
  },
  {
    "text": "the massive processing on such a large data set and so I would like to share one Deep dive on how we actually",
    "start": "748880",
    "end": "754880"
  },
  {
    "text": "leverage AWS infrastructure to to actually to have a very very a very very",
    "start": "754880",
    "end": "760639"
  },
  {
    "text": "huge number of instances that are actually accessing the the same data set so what was the challenge so there is",
    "start": "760639",
    "end": "767920"
  },
  {
    "text": "the large number of bionformatics tasks that require sharing of the intermediate results between the multiple instances",
    "start": "767920",
    "end": "774040"
  },
  {
    "text": "for instance you have processing stage one processing stage two but you still want to run them on the multiple",
    "start": "774040",
    "end": "779680"
  },
  {
    "text": "instances and still have to share the the results between them without actually transferring unnecessary",
    "start": "779680",
    "end": "784959"
  },
  {
    "text": "amounts of data between the stages or just run of course you could run this particular task on one instance but it",
    "start": "784959",
    "end": "791440"
  },
  {
    "text": "could last for days or weeks so the common solution that we used at the",
    "start": "791440",
    "end": "796519"
  },
  {
    "text": "beginning was very simple used the coordinator instance with NFS server that would basically share that would",
    "start": "796519",
    "end": "803360"
  },
  {
    "text": "act as a sharing service between the clients that were processing the actual data so this this was great and it BR",
    "start": "803360",
    "end": "810680"
  },
  {
    "text": "nice up up until you actually have the eight clients that were working on the same data and this is this was enough",
    "start": "810680",
    "end": "817800"
  },
  {
    "text": "for for pretty much many tasks including the whole genome processing but you",
    "start": "817800",
    "end": "822920"
  },
  {
    "text": "couldn't scale further especially for some population genomics test like the population calling you couldn't really",
    "start": "822920",
    "end": "829480"
  },
  {
    "text": "do it on just eight and just and eight workers sufficiently so we actually",
    "start": "829480",
    "end": "835880"
  },
  {
    "text": "started thinking about how we could how we could utilize this the the the infrastructure we have to enable the",
    "start": "835880",
    "end": "841839"
  },
  {
    "text": "access on the multiple machines so we tried to we actually want to remove the NFS server band with ball neck and so",
    "start": "841839",
    "end": "850800"
  },
  {
    "text": "we've observed how S3 was behaving and that we didn't see theg gradation of performance when we were accessing the",
    "start": "850800",
    "end": "857160"
  },
  {
    "text": "same data object with the multiple machines and that means that perhaps you",
    "start": "857160",
    "end": "862320"
  },
  {
    "text": "could use that to leverage leverage this infrastructure in order to access this data from from the hundreds of machines",
    "start": "862320",
    "end": "870120"
  },
  {
    "text": "both in if you're reading this data and basically also you can store the",
    "start": "870120",
    "end": "875199"
  },
  {
    "text": "intermediary data on S3 and perhaps there is no particular degradation if you use the parallel axis and parallel",
    "start": "875199",
    "end": "881079"
  },
  {
    "text": "transfer and we had this hypothesis that total breed right speed on a shared S3 object should significantly exceed this",
    "start": "881079",
    "end": "888759"
  },
  {
    "text": "the the the architecture we have had with anfs server solution more than 10 workers so this is the just a diagram of",
    "start": "888759",
    "end": "897240"
  },
  {
    "text": "how how this infrastructure should look like and it's very simple so what what are the results that",
    "start": "897240",
    "end": "903399"
  },
  {
    "text": "we achieved so uh this is this diagram shows you the on x-axis number of",
    "start": "903399",
    "end": "908959"
  },
  {
    "text": "compute instances that were accessing the data and there's the the the Epsilon",
    "start": "908959",
    "end": "914759"
  },
  {
    "text": "axis that shows the trut in megabytes per second so the first first actually",
    "start": "914759",
    "end": "920680"
  },
  {
    "text": "the Blue Line shows the reads toal re with the prefetching on the same data",
    "start": "920680",
    "end": "926240"
  },
  {
    "text": "objects on that that was acting pretty much linear and with green green line shows the how",
    "start": "926240",
    "end": "933279"
  },
  {
    "text": "how the parallel rights were behaving on on a m of course this is not these are",
    "start": "933279",
    "end": "938319"
  },
  {
    "text": "not the rights on the same object but the multiple object and the red red one is actually particularly interesting we",
    "start": "938319",
    "end": "944759"
  },
  {
    "text": "would we also implemented local caching that so because computational task could",
    "start": "944759",
    "end": "949959"
  },
  {
    "text": "benefit if you for instance download certain blocks of data locally you could cach in on local local drive on on SS",
    "start": "949959",
    "end": "957600"
  },
  {
    "text": "drive and actually in a second pass you could achieve much greater speed because you were no longer relying on your",
    "start": "957600",
    "end": "963199"
  },
  {
    "text": "network but you could actually do do do do the local axis and have much greater speeds of aess than you you had before",
    "start": "963199",
    "end": "970920"
  },
  {
    "text": "that actually means that that if you go change of perspective a little bit if you look at",
    "start": "970920",
    "end": "978040"
  },
  {
    "text": "the cumulative worker performance that this and this is this Epsilon X is now",
    "start": "978040",
    "end": "983079"
  },
  {
    "text": "shows the gigabytes per second that we could achieve much greater speeds than we actually in much greater scale that",
    "start": "983079",
    "end": "989120"
  },
  {
    "text": "we actually had with the with the NFS server so the one so the lines are",
    "start": "989120",
    "end": "995480"
  },
  {
    "text": "pretty much the same and especially it's interesting that this is this line shows",
    "start": "995480",
    "end": "1000680"
  },
  {
    "text": "where NF server Solutions started to break and theg grade in speed because the I was completely saturated at with a",
    "start": "1000680",
    "end": "1006600"
  },
  {
    "text": "with a network so we were no longer CPU bound but iio bound but with this kind",
    "start": "1006600",
    "end": "1011680"
  },
  {
    "text": "of solution we would we were able to scale on on hundreds of instances and also moreover this is it",
    "start": "1011680",
    "end": "1019079"
  },
  {
    "text": "is not enough because speed is great but we still have to implement the secure data access and we had to meet both",
    "start": "1019079",
    "end": "1026360"
  },
  {
    "text": "security and compliance standards with the sgfs so uh the important thing is as",
    "start": "1026360",
    "end": "1032880"
  },
  {
    "text": "as I said we never actually show the whole S3 bucket in order to to actually",
    "start": "1032880",
    "end": "1038600"
  },
  {
    "text": "users to be or processes to see the data through the sgfs you first go to our",
    "start": "1038600",
    "end": "1045480"
  },
  {
    "text": "file and metadata database service that actually just limits the access and visibility to only the files that this",
    "start": "1045480",
    "end": "1052720"
  },
  {
    "text": "particular task the user should see of course moreover you can use the sgfs to",
    "start": "1052720",
    "end": "1058240"
  },
  {
    "text": "to mount the data on your side as well on your local machine you're not limited only to to just worker instances and of",
    "start": "1058240",
    "end": "1065440"
  },
  {
    "text": "course in order to meet the many compliance requirements for instance hipper you have to you have to keep the",
    "start": "1065440",
    "end": "1072160"
  },
  {
    "text": "audit logs in for S years and we aggregate all the all the all the logs",
    "start": "1072160",
    "end": "1078039"
  },
  {
    "text": "using the El key stack which is basically lock stash elastic search and kibana where you can inspect your data",
    "start": "1078039",
    "end": "1085120"
  },
  {
    "text": "both through elastic search interface or kibana interface depending on what's what serves the purpose better that said",
    "start": "1085120",
    "end": "1093080"
  },
  {
    "text": "it's not only enough to enable the file access you also have to do the computation of the data and how we're",
    "start": "1093080",
    "end": "1098840"
  },
  {
    "text": "actually going to do this with by using the researcher contributed tools which that that can be written in pretty much",
    "start": "1098840",
    "end": "1105200"
  },
  {
    "text": "anything with with any standards so challenge was is that there",
    "start": "1105200",
    "end": "1110640"
  },
  {
    "text": "are more than 10,000 bionformatics tools and just there are more than 50 tools just using single tcgr marker by paper",
    "start": "1110640",
    "end": "1118080"
  },
  {
    "text": "moreover there are various versions of tools and pipelines that just and this complex complexity just explodes so our",
    "start": "1118080",
    "end": "1125919"
  },
  {
    "text": "Approach at the beginning before we we switched to different architecture was to the package the ec2 image with bunch",
    "start": "1125919",
    "end": "1133240"
  },
  {
    "text": "of dependencies so you can just put your tools and that perhaps should work fine but that was not the case when we when",
    "start": "1133240",
    "end": "1140320"
  },
  {
    "text": "we hit more than 100 of tools that became the dependency hell so what was our approach so we actually package the",
    "start": "1140320",
    "end": "1147760"
  },
  {
    "text": "tools in the docker image that are going together with the common veral veral language wrapper that",
    "start": "1147760",
    "end": "1154159"
  },
  {
    "text": "describes this particular tool that means that those are the building blocks of the genomic pipeline where you",
    "start": "1154159",
    "end": "1159640"
  },
  {
    "text": "describe the inputs and output of that particular tool and what are the parameters that this tool actually is",
    "start": "1159640",
    "end": "1165520"
  },
  {
    "text": "using so that means that you could just ship US ship us your Docker container",
    "start": "1165520",
    "end": "1171440"
  },
  {
    "text": "with package dependency and you we can just put it on minimal image on our platform so this was this was much",
    "start": "1171440",
    "end": "1179080"
  },
  {
    "text": "easier now for us to actually manage because we don't have to package the all the dependencies and we could we could",
    "start": "1179080",
    "end": "1184960"
  },
  {
    "text": "just package the minimal images and run this on our platform and build a larger",
    "start": "1184960",
    "end": "1190240"
  },
  {
    "text": "building blocks of the pipelines on much much much much easier fashion than before so one of the benefits that we",
    "start": "1190240",
    "end": "1198320"
  },
  {
    "text": "actually so by using the docker to deploys the these tools Docker actually enables the solid resource isolation in",
    "start": "1198320",
    "end": "1204640"
  },
  {
    "text": "the container level and that means that you you can limit the the visibility of",
    "start": "1204640",
    "end": "1210280"
  },
  {
    "text": "particular Docker image not only to to dis space like with regular Unix jails you can limit the network access you can",
    "start": "1210280",
    "end": "1217000"
  },
  {
    "text": "also the limit visibility of do a doer image what name space of processes it can see and it also as as a previously",
    "start": "1217000",
    "end": "1224280"
  },
  {
    "text": "side simplifies deploying and managing tools at scale so this this is not all",
    "start": "1224280",
    "end": "1229720"
  },
  {
    "text": "that simple there are security risks that are posed by use of do Docker so Docker demon first of all runs in their",
    "start": "1229720",
    "end": "1236200"
  },
  {
    "text": "root Pages which mean which means you could if if if you manage to penetrate Docker you you could can probably end up",
    "start": "1236200",
    "end": "1243280"
  },
  {
    "text": "with having the brute pages in this particular computational instance and also user can also package",
    "start": "1243280",
    "end": "1249840"
  },
  {
    "text": "unintentionally or intention intentionally malicious apps that means that if you include particular",
    "start": "1249840",
    "end": "1257000"
  },
  {
    "text": "particular Tools in your pipeline that are that on on a Marketplace uh and that means that",
    "start": "1257000",
    "end": "1264320"
  },
  {
    "text": "somebody could probably do something with your data export the data or or or just just monitor a network or see the",
    "start": "1264320",
    "end": "1270960"
  },
  {
    "text": "packages that are running through a network so if you're not setting the resource management properly application",
    "start": "1270960",
    "end": "1276760"
  },
  {
    "text": "could do damage outside its container and how we actually address",
    "start": "1276760",
    "end": "1281919"
  },
  {
    "text": "this we're trying to address the secure use of Docker containers by first",
    "start": "1281919",
    "end": "1287520"
  },
  {
    "text": "isolating private and public resources Docker container shouldn't see more than it should do should see to actually do",
    "start": "1287520",
    "end": "1294120"
  },
  {
    "text": "the actual job and moreover we also isting network resources for each",
    "start": "1294120",
    "end": "1299200"
  },
  {
    "text": "container we fire the resources resources uh at at a local container level and we are always careful with",
    "start": "1299200",
    "end": "1306559"
  },
  {
    "text": "linking containers and of course we are aggregating locks for any forensic or or",
    "start": "1306559",
    "end": "1312000"
  },
  {
    "text": "audit that we need to do in case something bad happens and that brings us finally how we actually this is great",
    "start": "1312000",
    "end": "1319039"
  },
  {
    "text": "but how you actually help people collaborate how you actually help them to work together because this is all",
    "start": "1319039",
    "end": "1324480"
  },
  {
    "text": "fine you can isolate the tools you can isolate the data but people still still need to share the data and do something",
    "start": "1324480",
    "end": "1329720"
  },
  {
    "text": "with it to achieve anything meaningful on top of our platform so first of all is just enabling the secure access for",
    "start": "1329720",
    "end": "1337039"
  },
  {
    "text": "instance in this particular case we are not only enabling users to access their own accounts and SBG platform we you",
    "start": "1337039",
    "end": "1344720"
  },
  {
    "text": "actually have to integrate with various authentication mechanisms and and and you have to meet you have to live",
    "start": "1344720",
    "end": "1351360"
  },
  {
    "text": "outside your container and outside your world so we are actually supporting Federated Au authentication and single",
    "start": "1351360",
    "end": "1357440"
  },
  {
    "text": "sign up that actually means in practice in in case of tcj data you can log in",
    "start": "1357440",
    "end": "1362760"
  },
  {
    "text": "with your NIH account and you can you can access the open data but you can",
    "start": "1362760",
    "end": "1367799"
  },
  {
    "text": "also log in on using the ear comments account to and actually have the access",
    "start": "1367799",
    "end": "1372960"
  },
  {
    "text": "to restricted dcga data on a platform of course we are also and we also auditing",
    "start": "1372960",
    "end": "1379480"
  },
  {
    "text": "the access and we can only see if somebody was trying somebody tried to access this data and was not authorized",
    "start": "1379480",
    "end": "1385320"
  },
  {
    "text": "moreover theab is actually refreshing the US user database every 24 hours so",
    "start": "1385320",
    "end": "1391720"
  },
  {
    "text": "that means in Cas we have to we have to be careful about and lug out the users if they don't have the access to this",
    "start": "1391720",
    "end": "1398320"
  },
  {
    "text": "particular data every 24 days 24 hours and moreover so people have to",
    "start": "1398320",
    "end": "1404840"
  },
  {
    "text": "collaborate somehow so SBG platform provides the isolation of resources is on a project level that means that in",
    "start": "1404840",
    "end": "1410840"
  },
  {
    "text": "case you want to share the files with somebody or share the pipeline with with somebody you can you can actually embed",
    "start": "1410840",
    "end": "1416919"
  },
  {
    "text": "this in in a project and you can actually limit the access and control the access to your project you can give",
    "start": "1416919",
    "end": "1423200"
  },
  {
    "text": "just a read WR and just have give somebody a bright to see what's in the project see the files see the pipelines",
    "start": "1423200",
    "end": "1430159"
  },
  {
    "text": "but you can also enable users to actually work and write on your on your projects and this is completely separate",
    "start": "1430159",
    "end": "1436360"
  },
  {
    "text": "from execution because execution actually spend some resources and can actually and can actually spend your",
    "start": "1436360",
    "end": "1441840"
  },
  {
    "text": "money so that said what's we also in order to just be able to see what's",
    "start": "1441840",
    "end": "1449320"
  },
  {
    "text": "going on in our platform we we also have to we are closely monitoring and testing our platform so we are doing penetration",
    "start": "1449320",
    "end": "1456039"
  },
  {
    "text": "testing we are doing strict patch management and and we Monitor and our platform and we also aggregate this as",
    "start": "1456039",
    "end": "1462960"
  },
  {
    "text": "as I previously said the log we are auditing the the all the services and all what's going on our platform and you",
    "start": "1462960",
    "end": "1469679"
  },
  {
    "text": "can always inspect the locks or or revise what what was going on in case there was any problem with with with",
    "start": "1469679",
    "end": "1475919"
  },
  {
    "text": "your plat with your actual account or if if there was any problem with with you",
    "start": "1475919",
    "end": "1481600"
  },
  {
    "text": "access access to your data so to put it all together U in general what what's",
    "start": "1481600",
    "end": "1488080"
  },
  {
    "text": "the interactions so user can log into our platform can up upload and download",
    "start": "1488080",
    "end": "1493200"
  },
  {
    "text": "the data to a secure Channel it you can basically run some tasks and share the data through a projects our platform is",
    "start": "1493200",
    "end": "1500520"
  },
  {
    "text": "actually managing the execution of this task and tasks and actual parallelization based on how you",
    "start": "1500520",
    "end": "1506159"
  },
  {
    "text": "actually set a set up how how your P pipeline should be executed and how your tools should be executed the final",
    "start": "1506159",
    "end": "1512399"
  },
  {
    "text": "results are actually living on Amazon as free and you can access only data and that that you actually have privileges",
    "start": "1512399",
    "end": "1518919"
  },
  {
    "text": "to access and you can always download and interact with with this data outside of the AWS or SBG platform if you want",
    "start": "1518919",
    "end": "1528039"
  },
  {
    "text": "so what are the general lessons that we learn from the in in this particular",
    "start": "1528039",
    "end": "1533480"
  },
  {
    "text": "case and and this so first of all you should always isolate resources as much",
    "start": "1533480",
    "end": "1540120"
  },
  {
    "text": "as possible that means that you shouldn't share any resource file or whatever the resource is unless it's",
    "start": "1540120",
    "end": "1547360"
  },
  {
    "text": "unless it's needed for for either process or some other users to see we",
    "start": "1547360",
    "end": "1552399"
  },
  {
    "text": "actually encrypt everything and if you encrypt the data it will just make your life much much easier you just don't",
    "start": "1552399",
    "end": "1557960"
  },
  {
    "text": "have to to think whether you comply to something or not and you also have to",
    "start": "1557960",
    "end": "1563039"
  },
  {
    "text": "understand what's the actual scale of data I'm security and and and",
    "start": "1563039",
    "end": "1568080"
  },
  {
    "text": "scalability looks very different on a gigabyte level on terabyte level and a paby level and you should measure",
    "start": "1568080",
    "end": "1575000"
  },
  {
    "text": "everything you can't really act upon any any of these metrics either whether it's",
    "start": "1575000",
    "end": "1580039"
  },
  {
    "text": "security or scalability unless you actually measure it and also you should leverage the infrastructure in this",
    "start": "1580039",
    "end": "1586760"
  },
  {
    "text": "particular case we were able to leverage Amazon S3 and and to achieve much High",
    "start": "1586760",
    "end": "1592200"
  },
  {
    "text": "higher speeds and much higher scalability than we could by just a very very simple anifest solution and",
    "start": "1592200",
    "end": "1598399"
  },
  {
    "text": "moreover we you can always you should always understand the platform you're running on so you would be able to",
    "start": "1598399",
    "end": "1604559"
  },
  {
    "text": "extract as much as is possible from it and that said I would just like to leave",
    "start": "1604559",
    "end": "1610039"
  },
  {
    "text": "you with with with one thought that if there if Amazon was not have meeting all",
    "start": "1610039",
    "end": "1615320"
  },
  {
    "text": "the standards that we that we actually had to meet as well we wouldn't be able to bring the D DB Gap data and meet the",
    "start": "1615320",
    "end": "1621840"
  },
  {
    "text": "DB Gap compliance to meet the heppa compliance and we are in the process of Isa 27,000 one uh compliance and we are",
    "start": "1621840",
    "end": "1629120"
  },
  {
    "text": "also in the process of being achieving the fisma moderate compliance but without the building blocks that",
    "start": "1629120",
    "end": "1634720"
  },
  {
    "text": "actually Amazon provides we wouldn't be able to do that so that said I would like to give you angel that said going",
    "start": "1634720",
    "end": "1641559"
  },
  {
    "text": "to say well bit more about that thank you excuse me thank you V I'm going to",
    "start": "1641559",
    "end": "1647640"
  },
  {
    "text": "talk about the which is compliance uh you just saw a",
    "start": "1647640",
    "end": "1653760"
  },
  {
    "text": "review of security and the technology that enables security and meeting actual uh controls uh for data for compute for",
    "start": "1653760",
    "end": "1660799"
  },
  {
    "text": "user management uh and we're going to talk about what that means in in respect to compliance so when we're talking",
    "start": "1660799",
    "end": "1667559"
  },
  {
    "text": "about compliance what are we really talking about we're talking about building trust between separate parties",
    "start": "1667559",
    "end": "1672640"
  },
  {
    "text": "a compliance certification is actually a uh not so much technical aspect to it",
    "start": "1672640",
    "end": "1678799"
  },
  {
    "text": "but more of a shared trust model and in order for any two parties to communicate they have to agree on the language of",
    "start": "1678799",
    "end": "1685640"
  },
  {
    "text": "that uh shared trust model and the language we use for compliance is of course compliance",
    "start": "1685640",
    "end": "1693240"
  },
  {
    "text": "Frameworks for ISO 2 or 27001 uh you could do a binary solo out",
    "start": "1693240",
    "end": "1700960"
  },
  {
    "text": "of that 00101 but for ISO 27001 it provides a framework for",
    "start": "1700960",
    "end": "1706279"
  },
  {
    "text": "General Security Management within an organ organization that includes putting in processes for categorization of data",
    "start": "1706279",
    "end": "1712200"
  },
  {
    "text": "is this sensitive data or not as well as doing an authori of folks to have access",
    "start": "1712200",
    "end": "1718200"
  },
  {
    "text": "to that data and what is the um uh recategorization of data over the long term so uh when you think of iso this",
    "start": "1718200",
    "end": "1725559"
  },
  {
    "text": "ISO standard it's really within an organization putting in processes in place Hippa uh which actually stands for",
    "start": "1725559",
    "end": "1733120"
  },
  {
    "text": "health information portability and accountability act a lot of folks confuse that with health information",
    "start": "1733120",
    "end": "1739320"
  },
  {
    "text": "protection and accountability act that's that's actually a misnomer it's it's it's portability its whole uh purpose in",
    "start": "1739320",
    "end": "1745360"
  },
  {
    "text": "life was actually to enable transfer of sensitive data across different types of",
    "start": "1745360",
    "end": "1752960"
  },
  {
    "text": "organizations DB Gap is actually not a compliance framework it stands for the database of genotypes and phenotypes",
    "start": "1753279",
    "end": "1759440"
  },
  {
    "text": "it's a repository of sensitive data but in order to get access to the DB Gap data you have to fill out a research",
    "start": "1759440",
    "end": "1766559"
  },
  {
    "text": "plan so that research plan is is comes with a",
    "start": "1766559",
    "end": "1772000"
  },
  {
    "text": "set of recommendations called the NIH genomic data sharing",
    "start": "1772000",
    "end": "1777200"
  },
  {
    "text": "policy and that policy itself is there to protect the individuals who have",
    "start": "1777200",
    "end": "1782799"
  },
  {
    "text": "donated that data under research uh purposes uh so that it's not used for",
    "start": "1782799",
    "end": "1788600"
  },
  {
    "text": "other purposes outside of the research application that was it was given so from the bottom we have within",
    "start": "1788600",
    "end": "1796480"
  },
  {
    "text": "organization security models where's well uh the second one was the",
    "start": "1796480",
    "end": "1803679"
  },
  {
    "text": "Cross organization security model so how do you build trust across organizations and the third is again for the user the",
    "start": "1803679",
    "end": "1810320"
  },
  {
    "text": "use of the data make sure it's not being used for nefarious purposes when we talk about compliance for AWS I'm sure you've",
    "start": "1810320",
    "end": "1816960"
  },
  {
    "text": "seen pictures like this about shared responsibility uh shared responsibility when it comes to compliance it means",
    "start": "1816960",
    "end": "1822840"
  },
  {
    "text": "compliance coordin coordination we talk about security of the cloud separated",
    "start": "1822840",
    "end": "1828039"
  },
  {
    "text": "from security in the cloud and AWS as the cloud provider uh manages the",
    "start": "1828039",
    "end": "1833840"
  },
  {
    "text": "security and compliance of the cloud that means facilities infrastructure virtualization API and service endpoints",
    "start": "1833840",
    "end": "1841240"
  },
  {
    "text": "and then stacked upon that our customers which include uh which include",
    "start": "1841240",
    "end": "1848960"
  },
  {
    "text": "Partners build their security and compliance practices on top of what we",
    "start": "1849120",
    "end": "1855600"
  },
  {
    "text": "provide this means the uh data security data Providence service endpoints OS",
    "start": "1855600",
    "end": "1860679"
  },
  {
    "text": "Network and what have you and then I keep pressing the wrong button sorry about that uh the end users can rely on",
    "start": "1860679",
    "end": "1867880"
  },
  {
    "text": "those two other platforms to do their work but they",
    "start": "1867880",
    "end": "1873039"
  },
  {
    "text": "still have some responsibility in in authorizing access to the data they put",
    "start": "1873039",
    "end": "1878279"
  },
  {
    "text": "on a platform finally third party audits you",
    "start": "1878279",
    "end": "1883399"
  },
  {
    "text": "aren't compliant on anything until somebody's verified all the way down through the stack that that they that",
    "start": "1883399",
    "end": "1888600"
  },
  {
    "text": "the user is not doing things that they shouldn't be doing with that data sharing it with folks they shouldn't be",
    "start": "1888600",
    "end": "1893880"
  },
  {
    "text": "sharing it with uh using the uh protocols that are given by their",
    "start": "1893880",
    "end": "1899639"
  },
  {
    "text": "platform provider and that the platform provider in turn uses the service endpoints of AWS or the infrastructure",
    "start": "1899639",
    "end": "1905600"
  },
  {
    "text": "to make sure that everything on through that entire stack uh goes along with the",
    "start": "1905600",
    "end": "1911039"
  },
  {
    "text": "rules let's take a let's take a particular use case here with the three",
    "start": "1911039",
    "end": "1916360"
  },
  {
    "text": "compliance Frameworks that we had talked about before so sensitive data let's assume",
    "start": "1916360",
    "end": "1923120"
  },
  {
    "text": "you have a survey coming from uh a a case Report",
    "start": "1923120",
    "end": "1929760"
  },
  {
    "text": "Form or something from a clinical trial you have a patient coming in AWS",
    "start": "1929760",
    "end": "1935000"
  },
  {
    "text": "provides you infrastructure for securing that data in transit and at rest uh and and meets uh",
    "start": "1935000",
    "end": "1942120"
  },
  {
    "text": "the the guidelines to of iso internally uh giving you something to build your",
    "start": "1942120",
    "end": "1947480"
  },
  {
    "text": "product on top of and and so on and so forth uh for Hippa we have security",
    "start": "1947480",
    "end": "1952559"
  },
  {
    "text": "controls and service endpoints that allow you to put in Hippa eligible applications on top of our",
    "start": "1952559",
    "end": "1957639"
  },
  {
    "text": "infrastructure the service provider would then take those uh service endpoints and and service features",
    "start": "1957639",
    "end": "1963679"
  },
  {
    "text": "utilize them in the right way uh such as when you have sensitive data it's",
    "start": "1963679",
    "end": "1969919"
  },
  {
    "text": "encrypted and it's on the restricted set of services I refer you to the compliance Hippa website for for more",
    "start": "1969919",
    "end": "1975960"
  },
  {
    "text": "information there and then the researcher themselves",
    "start": "1975960",
    "end": "1981559"
  },
  {
    "text": "uses what the infrastructure provider has given what the platform provider has given and doesn't do things to",
    "start": "1981559",
    "end": "1988159"
  },
  {
    "text": "circumvent the the uh security best practices here for instance if you have a case report form and you create this",
    "start": "1988159",
    "end": "1996039"
  },
  {
    "text": "file this PDF file and submit it as you know first name last name social security number and address just so you",
    "start": "1996039",
    "end": "2002519"
  },
  {
    "text": "can keep track of who it's who it's from that actually breaks Hippa right from a user level so so everybody here has some",
    "start": "2002519",
    "end": "2009960"
  },
  {
    "text": "some uh some responsibility to meet the the particular",
    "start": "2009960",
    "end": "2016320"
  },
  {
    "text": "guideline all right so that that g that that closes out compliance in a nutshell",
    "start": "2016799",
    "end": "2022240"
  },
  {
    "text": "for the three security Frameworks I'd like to take this back down to the level of you are a researcher you are somebody",
    "start": "2022240",
    "end": "2029399"
  },
  {
    "text": "who wants to analyze the data at petabyte scale or uh alternatively you are a central it organization that wants",
    "start": "2029399",
    "end": "2036039"
  },
  {
    "text": "to make these data available at scale to your user base one of the best ways of doing that",
    "start": "2036039",
    "end": "2042559"
  },
  {
    "text": "on our platform is to leverage platform",
    "start": "2042559",
    "end": "2047200"
  },
  {
    "text": "providers having said that uh bringing back our our model of security and",
    "start": "2047839",
    "end": "2053800"
  },
  {
    "text": "compliance best practice is stack set of responsibilities when you try to integrate other parts of your",
    "start": "2053800",
    "end": "2060240"
  },
  {
    "text": "environment with the platform there's the understood notion that sometimes you're going to have things outside of",
    "start": "2060240",
    "end": "2066560"
  },
  {
    "text": "that platform and and you take on a larger burden of the security and compliance",
    "start": "2066560",
    "end": "2074679"
  },
  {
    "text": "uh capabilities when you do that you have to be careful not to circumvent anything",
    "start": "2074679",
    "end": "2082480"
  },
  {
    "text": "that was given to you by the platform here so that in addition to this stacked responsibility model there's a",
    "start": "2082480",
    "end": "2087520"
  },
  {
    "text": "horizontal responsibility model between different uh parts of your",
    "start": "2087520",
    "end": "2093118"
  },
  {
    "text": "environment for the use case we'll we're going to talk about analyzing the personal genome project data uh personal",
    "start": "2093119",
    "end": "2099240"
  },
  {
    "text": "Genome Project data is uh uh started by George Church at Harvard folks have been",
    "start": "2099240",
    "end": "2104320"
  },
  {
    "text": "submitting voluntarily their genomic data as well as phenotype information um",
    "start": "2104320",
    "end": "2110960"
  },
  {
    "text": "in the public domain so there's actually no consent forms to sign for this data so it's an interesting data set to look",
    "start": "2110960",
    "end": "2117599"
  },
  {
    "text": "at uh but there's a slight problem with it in that it is not alumina data",
    "start": "2117599",
    "end": "2123440"
  },
  {
    "text": "alumina controls 90% of the sequencing in the world it's complete genomics data so you need some set of tools and some",
    "start": "2123440",
    "end": "2130119"
  },
  {
    "text": "platform in order to analyze and transform the data to make it uh",
    "start": "2130119",
    "end": "2135359"
  },
  {
    "text": "integratable with other resources like the Thousand genomes uh thousand genomes actually is 2500 genomes at this point",
    "start": "2135359",
    "end": "2142240"
  },
  {
    "text": "so maybe they should think about changing their name uh and tcga uh which we had talked about before so with the",
    "start": "2142240",
    "end": "2149119"
  },
  {
    "text": "platform you can integrate the complete genomics tool set do the transformation",
    "start": "2149119",
    "end": "2154160"
  },
  {
    "text": "at scale and not have to worry about the operations and then finally start bringing it down into your Downstream",
    "start": "2154160",
    "end": "2160119"
  },
  {
    "text": "processing Tools in this case in this very simple use case we're going to use the excellent uh",
    "start": "2160119",
    "end": "2167200"
  },
  {
    "text": "Gemini uh you can uh project or uh a python notebook to start inspecting the",
    "start": "2167200",
    "end": "2173960"
  },
  {
    "text": "the data that comes out from a population analysis the types of queries you can do down here and and why you would want to",
    "start": "2173960",
    "end": "2180680"
  },
  {
    "text": "do this outside of the platform because there's a lot of iterative queries over data like this for instance with Gemini",
    "start": "2180680",
    "end": "2186040"
  },
  {
    "text": "you can ask a question like identify every unknown loss of function variant",
    "start": "2186040",
    "end": "2193079"
  },
  {
    "text": "in my data set that means it isn't showing up anywhere else in the rest of the population and there's an interesting phenotype attached to those",
    "start": "2193079",
    "end": "2199599"
  },
  {
    "text": "variants that might be something as a pharmaceutical provider or as a researcher I might want to tackle as a",
    "start": "2199599",
    "end": "2205319"
  },
  {
    "text": "downstream analysis program so the strategies to follow here is rely on your platform as much as",
    "start": "2205319",
    "end": "2212119"
  },
  {
    "text": "possible in this previous uh slide right we could have trans translated all of",
    "start": "2212119",
    "end": "2218319"
  },
  {
    "text": "the data outside of the platform into something that can go uh uh with the",
    "start": "2218319",
    "end": "2223640"
  },
  {
    "text": "complete genomics tools that can go straight into an analysis with these other data sets but why would you do",
    "start": "2223640",
    "end": "2229440"
  },
  {
    "text": "that why wouldn't you just install the tools here a custom tools into the platform itself so that you can utilize",
    "start": "2229440",
    "end": "2235359"
  },
  {
    "text": "the same infrastructure other strategies to follow is is redefine manual please uh",
    "start": "2235359",
    "end": "2241560"
  },
  {
    "text": "you know often too often we find that folks actually don't follow the AWS best",
    "start": "2241560",
    "end": "2247319"
  },
  {
    "text": "practice practices uh when they are working on our platform and it it boggles my mind and third to make the uh",
    "start": "2247319",
    "end": "2253560"
  },
  {
    "text": "the Box Checkers happy so the compliance team have a checklist you know have a actual Todo item that you're going to uh",
    "start": "2253560",
    "end": "2260920"
  },
  {
    "text": "use to do these these Integrations with your platform providers so for for our checklist here we have AWS security",
    "start": "2260920",
    "end": "2268040"
  },
  {
    "text": "right so are you doing the right thing with with vpcs are you creating uh",
    "start": "2268040",
    "end": "2273119"
  },
  {
    "text": "security groups that are principal of lease practice are you encrypting storage and can you prove do so are you",
    "start": "2273119",
    "end": "2278880"
  },
  {
    "text": "protecting your AWS credentials as much as possible I can't tell you how many times that I've personally have to help",
    "start": "2278880",
    "end": "2286160"
  },
  {
    "text": "our customer base uh from a GitHub error protect uh platform credentials",
    "start": "2286160",
    "end": "2293560"
  },
  {
    "text": "right uh platform providers usually give API endpoints and with that give you",
    "start": "2293560",
    "end": "2300040"
  },
  {
    "text": "authorization tokens if you somehow uh lose these credentials out in the wild",
    "start": "2300040",
    "end": "2306119"
  },
  {
    "text": "you've circumvented the entire security model that you're you're supposed to be taking advantage of so it's critical to",
    "start": "2306119",
    "end": "2311280"
  },
  {
    "text": "protect not only AWS security credentials but also any other credentials Associated uh with working",
    "start": "2311280",
    "end": "2317400"
  },
  {
    "text": "with this data you should have standard operating procedures for your operating system application updates and",
    "start": "2317400",
    "end": "2322839"
  },
  {
    "text": "management and deployment uh of course audit logging of activities that are outside of the platform to make sure you",
    "start": "2322839",
    "end": "2329119"
  },
  {
    "text": "maintain that horizontal responsibility and then data Providence and life cycle that uh stack on top of AWS that you're",
    "start": "2329119",
    "end": "2336839"
  },
  {
    "text": "you're undergo going so here's a simplified architecture uh we have a VPC",
    "start": "2336839",
    "end": "2342680"
  },
  {
    "text": "with with a single zone uh and a security group around a single instance that is launched with an IM am instance",
    "start": "2342680",
    "end": "2351440"
  },
  {
    "text": "profile for access to Seven Bridges we're going to go and attach an internet gateway and and perform operations over",
    "start": "2351440",
    "end": "2358240"
  },
  {
    "text": "https or SSL so in transit and going onto our uh encrypted storage you can either do that through the internet or",
    "start": "2358240",
    "end": "2364599"
  },
  {
    "text": "through VPC peering uh for our we'll use something like",
    "start": "2364599",
    "end": "2371000"
  },
  {
    "text": "packer.edu can use the same stack and same code and",
    "start": "2371000",
    "end": "2378440"
  },
  {
    "text": "same development process to go into the platform itself as well as your own",
    "start": "2378440",
    "end": "2384560"
  },
  {
    "text": "infrastructure here and finally this uh the use of IM",
    "start": "2384560",
    "end": "2390200"
  },
  {
    "text": "IM instance profiles allows you to protect the credentials uh of a AWS and",
    "start": "2390200",
    "end": "2395480"
  },
  {
    "text": "other credentials and other sensitive data that you might want to have on the instance at runtime but you don't want",
    "start": "2395480",
    "end": "2401440"
  },
  {
    "text": "to expose any anything outside of that instance so let's take a quick look at code because this is a a coder's",
    "start": "2401440",
    "end": "2407680"
  },
  {
    "text": "conference uh this is a uh how uh I took a quick stab at supplying sensitive data",
    "start": "2407680",
    "end": "2414240"
  },
  {
    "text": "through the user user data uh metadata let's zoom in a little bit for the folks in the back for this section",
    "start": "2414240",
    "end": "2420440"
  },
  {
    "text": "for securing the platform provider",
    "start": "2420440",
    "end": "2425680"
  },
  {
    "text": "right this long long wacky string here is the uh API key that I've encrypted",
    "start": "2425680",
    "end": "2431839"
  },
  {
    "text": "beforehand with the uh Key Management Service key here and since I launched",
    "start": "2431839",
    "end": "2437520"
  },
  {
    "text": "this instance with an instance profile I can do really simple things like use the AWS CLI to",
    "start": "2437520",
    "end": "2444800"
  },
  {
    "text": "decrypt this plain text key and then uh write it out to disk for my applications",
    "start": "2444800",
    "end": "2450359"
  },
  {
    "text": "to use I mean really simple stuff but there's so many uh of our customer base",
    "start": "2450359",
    "end": "2455520"
  },
  {
    "text": "that that don't do this they start shifting and sshing the keys in there",
    "start": "2455520",
    "end": "2460640"
  },
  {
    "text": "whereas they don't really need to they don't need to have exposed themselves necessarily and this is more",
    "start": "2460640",
    "end": "2467040"
  },
  {
    "text": "automatable uh this is for the really blind folks in case you didn't see that but uh and then on top of that you know",
    "start": "2467040",
    "end": "2475359"
  },
  {
    "text": "uh here we're using a generated random key for the local encrypted storage I'm sorry I had to punk out here but uh this",
    "start": "2475359",
    "end": "2481960"
  },
  {
    "text": "is a this is a blog post and writing we're we're starting to develop uh real information for folks to use in this",
    "start": "2481960",
    "end": "2488240"
  },
  {
    "text": "space uh for Best Practices so how do we do right and for our",
    "start": "2488240",
    "end": "2494000"
  },
  {
    "text": "compliance checklist for this very simple example well I think we did a decent job with AWS security right with",
    "start": "2494000",
    "end": "2499920"
  },
  {
    "text": "cloud formation we can validate that we have a secure VPC secure uh security",
    "start": "2499920",
    "end": "2505000"
  },
  {
    "text": "groups and encrypted storage all within a a uh checkm process we protected our AWS credentials",
    "start": "2505000",
    "end": "2512480"
  },
  {
    "text": "by really you know putting into our standard operating procedures of deploying uh applications uh using IM",
    "start": "2512480",
    "end": "2519319"
  },
  {
    "text": "instance profiles and manage policies we protected our platform cred",
    "start": "2519319",
    "end": "2525960"
  },
  {
    "text": "credentials by leveraging uh KMS and we have standard operating procedures for",
    "start": "2525960",
    "end": "2531160"
  },
  {
    "text": "osm application updates that are standardized across the platform and anything you do within AWS by virtue of",
    "start": "2531160",
    "end": "2537280"
  },
  {
    "text": "using Packer with some devops framework behind it like ansible audit and logging is left up for",
    "start": "2537280",
    "end": "2543920"
  },
  {
    "text": "homework I mean that's always particular to a given envir uh edted Providence and life cycle is",
    "start": "2543920",
    "end": "2549880"
  },
  {
    "text": "always case use case specific and that's all that's a problem that's never going to go away um that might be a different",
    "start": "2549880",
    "end": "2558160"
  },
  {
    "text": "platform to use for a Global Perspective uh or leverage the platform that you have and just have standard operating",
    "start": "2558160",
    "end": "2564680"
  },
  {
    "text": "procedures that say we only take data out temporarily and and uh and then",
    "start": "2564680",
    "end": "2570720"
  },
  {
    "text": "delete it at hand and any any long liveed data asset goes back into the",
    "start": "2570720",
    "end": "2575960"
  },
  {
    "text": "platform and that's what we certify as our process so that's a very simple data Providence and life cycle standard",
    "start": "2575960",
    "end": "2581400"
  },
  {
    "text": "operating procedure enforcing that becomes the rub so a couple of notes I'd like to",
    "start": "2581400",
    "end": "2588200"
  },
  {
    "text": "thank everybody here a couple of notes thank eore for coming uh the cancer genomics Cloud will provide access to",
    "start": "2588200",
    "end": "2594720"
  },
  {
    "text": "the tcga as a public data set on AWS it will be open up to Beta users uh in mid",
    "start": "2594720",
    "end": "2601760"
  },
  {
    "text": "November so look forward to that and if you need more information see us after the talk there are other public data",
    "start": "2601760",
    "end": "2607920"
  },
  {
    "text": "sets that we're doing if there are public data sets of Interest please come come contact me later uh and if you have",
    "start": "2607920",
    "end": "2614680"
  },
  {
    "text": "any questions we'll take them now do you want to come up in case we have",
    "start": "2614680",
    "end": "2621599"
  },
  {
    "text": "questions great [Applause]",
    "start": "2622800",
    "end": "2629879"
  }
]
[
  {
    "text": "alright hello everybody so we should be going live fairly soon here and I'm just",
    "start": "30",
    "end": "5460"
  },
  {
    "text": "gonna wait for a little bit while everybody kind of joins joins in might",
    "start": "5460",
    "end": "13559"
  },
  {
    "text": "take a second it's like my presentation is messed up but that's a ping still",
    "start": "13559",
    "end": "23130"
  },
  {
    "text": "waiting for people to join in trying to",
    "start": "23130",
    "end": "37649"
  },
  {
    "text": "hide the notes so today we're gonna be talking about machine learning and the",
    "start": "37649",
    "end": "45480"
  },
  {
    "text": "Twitter API and a number of other different components that go into building a server list Twitter bot now I",
    "start": "45480",
    "end": "53360"
  },
  {
    "text": "know you see some slides on the screen right now that's just sort of to give you some context for Who I am and what",
    "start": "53360",
    "end": "60510"
  },
  {
    "text": "this presentation is about we have in the twitch chat the ability for you to ask whatever questions you want so feel",
    "start": "60510",
    "end": "67470"
  },
  {
    "text": "free to go ahead and say who you are say introduce yourself say I'm watching",
    "start": "67470",
    "end": "74220"
  },
  {
    "text": "from this country or I'm joining in from here over there or whatever if you want",
    "start": "74220",
    "end": "80729"
  },
  {
    "text": "an example of what we're building today it looks a little bit like this so you",
    "start": "80729",
    "end": "85920"
  },
  {
    "text": "can go in to Twitter and you can say hey at where AM L I'd like to find out where",
    "start": "85920",
    "end": "93150"
  },
  {
    "text": "this picture is so you post a picture from your camera roll doesn't ever have",
    "start": "93150",
    "end": "98159"
  },
  {
    "text": "to have been on the internet before and once you post it the Twitter bot will",
    "start": "98159",
    "end": "103439"
  },
  {
    "text": "receive it it will go and talk to a couple of different AWS services and then it will return until you where in the world that thinks that picture is",
    "start": "103439",
    "end": "109409"
  },
  {
    "text": "and I'll include a little static Google Maps image as well so the way that this works architecture Allah is we have",
    "start": "109409",
    "end": "116490"
  },
  {
    "text": "Twitter and Twitter has their API now their API has a subset of actions",
    "start": "116490",
    "end": "126000"
  },
  {
    "text": "called web hooks and web hooks are calls that Twitter makes on your behalf out to an endpoint that you're hosting",
    "start": "126000",
    "end": "132950"
  },
  {
    "text": "which is to quickly a server but in a service application it's actually going to be a service called API gateway that will",
    "start": "132950",
    "end": "139410"
  },
  {
    "text": "take the webhook invocation from from the to from Twitter's API it will hit",
    "start": "139410",
    "end": "147209"
  },
  {
    "text": "that API gateway endpoint and it will invoke a lambda function and a lambda function as a service function that",
    "start": "147209",
    "end": "152459"
  },
  {
    "text": "allows you to kind of write whatever code you want do whatever you want now that lambda function subsequently will",
    "start": "152459",
    "end": "159900"
  },
  {
    "text": "call the inference endpoint and Amazon sage maker and I'll jump into what Amazon sage maker is ad in-depth in a",
    "start": "159900",
    "end": "165300"
  },
  {
    "text": "little while that's the machine learning part of all of this the various sub",
    "start": "165300",
    "end": "170310"
  },
  {
    "text": "components that go into this we can dive deep on each one of those but before we do that I just I'm curious if the people",
    "start": "170310",
    "end": "177300"
  },
  {
    "text": "who are watching on the stream don't mind putting in chat what's your experience with machine learning how how",
    "start": "177300",
    "end": "183180"
  },
  {
    "text": "much of a primary do you need are you guys do you consider yourselves AI experts or are you more learners and",
    "start": "183180",
    "end": "190140"
  },
  {
    "text": "tinker's I'm happy to go into whatever depth you guys want and let's see Doug",
    "start": "190140",
    "end": "197220"
  },
  {
    "text": "Chopin says looking forward to learning some learning learnings reports of some machine learning we have M pride d9 says",
    "start": "197220",
    "end": "205500"
  },
  {
    "text": "hello from Auckland New Zealand watched rod says hi from Toronto so and then we",
    "start": "205500",
    "end": "211769"
  },
  {
    "text": "have the the trolls on the stream thanks for joining so anybody have any questions",
    "start": "211769",
    "end": "218910"
  },
  {
    "text": "oh you're saying that you are new gotcha so never done anything in practice ok",
    "start": "218910",
    "end": "227100"
  },
  {
    "text": "well let's let's get some let's kind of talk about this a bit so I have some",
    "start": "227100",
    "end": "234720"
  },
  {
    "text": "videos here that kind of help understand what machine learning is at its core so",
    "start": "234720",
    "end": "241500"
  },
  {
    "text": "AI is not new it's actually been around probably for 70 plus years and the way",
    "start": "241500",
    "end": "247890"
  },
  {
    "text": "that this works is you you have data or",
    "start": "247890",
    "end": "254459"
  },
  {
    "text": "you have some kind of concept and in the typical programmatic sense you would",
    "start": "254459",
    "end": "259530"
  },
  {
    "text": "have you know this data coming and you would have a series of if statements or switch statements or something like that",
    "start": "259530",
    "end": "265050"
  },
  {
    "text": "and you would make some imperative determination about what should happen based on that",
    "start": "265050",
    "end": "271290"
  },
  {
    "text": "incoming data however if you think about the way that your brain works the way that your visual cortex works you have",
    "start": "271290",
    "end": "278030"
  },
  {
    "text": "your you know I'm looking at a screen right now I'm looking at a couple of",
    "start": "278030",
    "end": "283920"
  },
  {
    "text": "different screens and what's happening is the light from the screen is hitting my eye it's going through my lens it's",
    "start": "283920",
    "end": "290520"
  },
  {
    "text": "hitting my retina my retina is triggering my optic nerve and generating some electricity in my brain and inside",
    "start": "290520",
    "end": "296160"
  },
  {
    "text": "of a part of my brain called the visual cortex a series of connected neurons are",
    "start": "296160",
    "end": "302420"
  },
  {
    "text": "going and firing off and coalescing into some concept so when I see the screen in",
    "start": "302420",
    "end": "309060"
  },
  {
    "text": "front of me it coalesces into this concept of screen but if we think about how that happens and how that model",
    "start": "309060",
    "end": "315390"
  },
  {
    "text": "happens it's a lot easier if we kind of break it down into a smaller sample than",
    "start": "315390",
    "end": "321240"
  },
  {
    "text": "just this kind of object detection that I'm talking about right now with screens so let's take the example of a numbered",
    "start": "321240",
    "end": "330990"
  },
  {
    "text": "data set a handwritten digit so this is called the in this data set and it's a very very common data set to start right",
    "start": "330990",
    "end": "337169"
  },
  {
    "text": "and the way that it works is you have this neuronal network this neural",
    "start": "337169",
    "end": "344490"
  },
  {
    "text": "network modeled after the visual cortex of individual neurons and fully connected layers and you are connecting",
    "start": "344490",
    "end": "353190"
  },
  {
    "text": "all of these and you're having an activation bias for each one of these",
    "start": "353190",
    "end": "358760"
  },
  {
    "text": "individual kind of neurons now you have several layers within this network and",
    "start": "358760",
    "end": "364560"
  },
  {
    "text": "when we talk about deep learning what we're talking about is having many many many many layers and lots more data this",
    "start": "364560",
    "end": "371729"
  },
  {
    "text": "network that we're training today is actually I wouldn't consider it deep deep learning it's just a simple fully",
    "start": "371729",
    "end": "379050"
  },
  {
    "text": "connected network so you see we have these 784 neurons coming in that's going into a layer of sixteen followed by",
    "start": "379050",
    "end": "385710"
  },
  {
    "text": "another layer of sixteen and in the process of training our model what we're doing is we are just finding the correct",
    "start": "385710",
    "end": "392729"
  },
  {
    "text": "weights and biases in order to trigger these different neurons and that doesn't make sense let's look at an example so",
    "start": "392729",
    "end": "398400"
  },
  {
    "text": "let's take the number is here and what we're gonna do is a 28",
    "start": "398400",
    "end": "404490"
  },
  {
    "text": "pixel by 28 pixel image so we're going to break that down into the various sub",
    "start": "404490",
    "end": "412680"
  },
  {
    "text": "components so this is the number eight and we've broken that down into each of the 784 pixels and then we're going and",
    "start": "412680",
    "end": "418560"
  },
  {
    "text": "we're firing off and we're saying okay these neurons are lighting up these neurons are letting up and the final",
    "start": "418560",
    "end": "424860"
  },
  {
    "text": "layer that output layer often called like a soft next layer or something is going to say this is a number eight and",
    "start": "424860",
    "end": "432180"
  },
  {
    "text": "I will confidently state that so when you're doing machine learning all you're really doing is just trying to identify",
    "start": "432180",
    "end": "438440"
  },
  {
    "text": "what these weights and biases need to be and there are a couple different processes by which you can do that and",
    "start": "438440",
    "end": "444090"
  },
  {
    "text": "the very common one is a process called back propagation and the way that that works is you start out with kind of",
    "start": "444090",
    "end": "451259"
  },
  {
    "text": "randomly initialized variables and values and you say okay well I put in",
    "start": "451259",
    "end": "456930"
  },
  {
    "text": "this pixel or this this number and I know that this number is a nine but my",
    "start": "456930",
    "end": "462630"
  },
  {
    "text": "network with its randomly initiated weights and biases told me that it was a number four so I need to go backwards",
    "start": "462630",
    "end": "469320"
  },
  {
    "text": "and calculate what the error function is what the how far off I was from the the",
    "start": "469320",
    "end": "476669"
  },
  {
    "text": "answer I desired and I need to adjust the weights and biases across the network in order to do that now you",
    "start": "476669",
    "end": "482909"
  },
  {
    "text": "don't typically do this for and for a single pardon me you don't typically do",
    "start": "482909",
    "end": "489719"
  },
  {
    "text": "this for a single image you know when you're training in networks like this you're typically doing this for batches of images so you know ten at a time 100",
    "start": "489719",
    "end": "497190"
  },
  {
    "text": "at a time a thousand at a time and the reason that you do this in batches is that you want to try to save on some of",
    "start": "497190",
    "end": "503039"
  },
  {
    "text": "the computational complexity involved in back propagating all of this data and doing all of this all these calculations",
    "start": "503039",
    "end": "511169"
  },
  {
    "text": "and so we have some people joining in thanks for joining everybody thanks for",
    "start": "511169",
    "end": "517409"
  },
  {
    "text": "coming in from Brisbane Australia set the trader and the smasher says if the",
    "start": "517409",
    "end": "523200"
  },
  {
    "text": "volume is a bit low let me see if I can turn this up a bit is that okay for",
    "start": "523200",
    "end": "528630"
  },
  {
    "text": "everybody or did it get worse",
    "start": "528630",
    "end": "531740"
  },
  {
    "text": "could be is this a little bit better",
    "start": "536750",
    "end": "543720"
  },
  {
    "text": "everybody I'm gonna keep adjusting I'm sorry about this keep adjusting that is",
    "start": "543720",
    "end": "551160"
  },
  {
    "text": "about as loud as I can make it go without also adding in some static and",
    "start": "551160",
    "end": "557910"
  },
  {
    "text": "stuff oh boy I've ruined everything now",
    "start": "557910",
    "end": "565519"
  },
  {
    "text": "so it's getting better okay I think that's the most that I can go without kind of messing with the audio more",
    "start": "565519",
    "end": "574110"
  },
  {
    "text": "substantially I'm doing another stream later today so I'll try and get a bit better during that time so hopping back",
    "start": "574110",
    "end": "583350"
  },
  {
    "text": "on track here and then we have chat nyah from India thanks for joining this is",
    "start": "583350",
    "end": "592800"
  },
  {
    "text": "what the the typical machine learning process looks like the view you have these different layers that are kind of",
    "start": "592800",
    "end": "598380"
  },
  {
    "text": "identifying different parts of the pixels that you're putting in and then",
    "start": "598380",
    "end": "603870"
  },
  {
    "text": "your intuition may say okay well maybe this is identifying the edges you know that would be what a convolutional",
    "start": "603870",
    "end": "609089"
  },
  {
    "text": "neural network typically does is it defines these little kernels and it says hey I want to identify the different edges and then maybe the second layer is",
    "start": "609089",
    "end": "615500"
  },
  {
    "text": "calling out and it's identifying the number nine has a very long straight",
    "start": "615500",
    "end": "621360"
  },
  {
    "text": "mark and then a circular part on top of that and a question that's often posed",
    "start": "621360",
    "end": "628620"
  },
  {
    "text": "is does the network that you've trained actually do this and in some cases the",
    "start": "628620",
    "end": "635519"
  },
  {
    "text": "answer is yes but in many cases the answer is we don't know so Google has",
    "start": "635519",
    "end": "640890"
  },
  {
    "text": "actually been working at what some researchers at Google have actually been working on a series of different",
    "start": "640890",
    "end": "645920"
  },
  {
    "text": "techniques for visualizing how networks learn and visualizing how these deep",
    "start": "645920",
    "end": "651060"
  },
  {
    "text": "neural networks are interacting and I think a number of those are pretty useful so I'll skip ahead a bit let's",
    "start": "651060",
    "end": "659550"
  },
  {
    "text": "let's hop into some code how does that sound so the first thing that we could",
    "start": "659550",
    "end": "666480"
  },
  {
    "text": "do and and Bob Luc's asks what's a good resource to start machine learning and",
    "start": "666480",
    "end": "672360"
  },
  {
    "text": "deep learning many of the videos that I just showed you are not made by me they're actually made by somebody named grant Sanderson and he has a YouTube",
    "start": "672360",
    "end": "679560"
  },
  {
    "text": "channel called three blue one brown and he has a series on that YouTube channel called how to neural networks work and I",
    "start": "679560",
    "end": "686910"
  },
  {
    "text": "strongly suggest if you are a beginner and you're trying to learn more about machine learning hopping over into that",
    "start": "686910",
    "end": "692279"
  },
  {
    "text": "series because there's a lot of really good content there and you can become an expert in machine learning over the",
    "start": "692279",
    "end": "698999"
  },
  {
    "text": "course of maybe two or three hours which is the most condensed course I've ever seen and it's not really written like a",
    "start": "698999",
    "end": "706829"
  },
  {
    "text": "course it's not really written like a series of exams or anything like that it's more written like a narrative and",
    "start": "706829",
    "end": "713459"
  },
  {
    "text": "there's a little bit of historical detail and there's a little bit of math detail and I'll write it here it's",
    "start": "713459",
    "end": "720059"
  },
  {
    "text": "called three blue one brown and I just",
    "start": "720059",
    "end": "725279"
  },
  {
    "text": "strongly recommend checking that channel out I've I've learned a lot from it not just in the space of not just in the",
    "start": "725279",
    "end": "734670"
  },
  {
    "text": "space of the machine learning space you know there's a lot of good math on there",
    "start": "734670",
    "end": "740790"
  },
  {
    "text": "too so now that we have some people in",
    "start": "740790",
    "end": "745829"
  },
  {
    "text": "the stream I'm gonna ask the the interesting question of we're gonna build a Twitter bot today what do you",
    "start": "745829",
    "end": "752490"
  },
  {
    "text": "want to call this Twitter bot so in the past when I've asked people to name",
    "start": "752490",
    "end": "758879"
  },
  {
    "text": "these Twitter BOTS I have gotten some interesting results so body mcboatface",
    "start": "758879",
    "end": "764309"
  },
  {
    "text": "is off the off the off the table and",
    "start": "764309",
    "end": "771139"
  },
  {
    "text": "unfortunately we can't allow anybody but the mods to post links but if you want to send it to me in a DM I'd be happy to",
    "start": "771139",
    "end": "777089"
  },
  {
    "text": "post it for use at the trader so does anybody have a name for this bot that",
    "start": "777089",
    "end": "782850"
  },
  {
    "text": "we're gonna build today okay doesn't seem like we've got a name so I'm just gonna call the bot you know the bot so",
    "start": "782850",
    "end": "794240"
  },
  {
    "text": "what I like to do when I'm getting started with things is I start up with a",
    "start": "794240",
    "end": "799259"
  },
  {
    "text": "Jupiter notebook or a Jupiter lab and that's a really good kind of typing environment and I'll open this in",
    "start": "799259",
    "end": "810149"
  },
  {
    "text": "a new tab here and the reason that I try",
    "start": "810149",
    "end": "815490"
  },
  {
    "text": "and do most of my prototyping in a Jupiter lab is even though I can open up a bunch of things in them and stuff like",
    "start": "815490",
    "end": "821069"
  },
  {
    "text": "that there's a Amazon Web service called sage maker and that service also lets me",
    "start": "821069",
    "end": "828779"
  },
  {
    "text": "build these notebook instances that can have access to all of my data that's stored on AWS so it typically lets me",
    "start": "828779",
    "end": "838730"
  },
  {
    "text": "take whatever I'm prototyping with locally I can upload it to this notebook instance on sage maker and let's say my",
    "start": "838730",
    "end": "845399"
  },
  {
    "text": "local machine doesn't have that much power I can go to a notebook instance that's you know a p3 16 X large or",
    "start": "845399",
    "end": "852389"
  },
  {
    "text": "something like absurd like that and I can have these GPUs and other stuff available to me to run these large",
    "start": "852389",
    "end": "858480"
  },
  {
    "text": "computations and then once I figured out what exactly it is I want to do on my on",
    "start": "858480",
    "end": "867869"
  },
  {
    "text": "my bot and or you know with my model that I'm training and experimenting with I can go into the training service of",
    "start": "867869",
    "end": "874049"
  },
  {
    "text": "sage maker and the training service will actually run that training job for me completely serverless lee so I don't",
    "start": "874049",
    "end": "879809"
  },
  {
    "text": "have to worry about any of the underlying infrastructure I don't have to maintain it and there's another sub component of that training called hyper",
    "start": "879809",
    "end": "885749"
  },
  {
    "text": "parameter optimization and I think my colleague Julian is going to talk about that a lot more then we get over to the",
    "start": "885749",
    "end": "893399"
  },
  {
    "text": "inference side and the inference side is what we're mostly going to be focusing on today with this bot but in the",
    "start": "893399",
    "end": "899399"
  },
  {
    "text": "meantime I'm going to create a notebook instance just and it'll take a little bit to provision but that's fine we have our local notebook running as well I'm",
    "start": "899399",
    "end": "905759"
  },
  {
    "text": "just going to call this hello Nov and I'm gonna use a slightly larger than",
    "start": "905759",
    "end": "911819"
  },
  {
    "text": "normal instance and I'm just gonna create this it'll run for a while and",
    "start": "911819",
    "end": "919529"
  },
  {
    "text": "then on my local machine and I'm gonna start an instance so let's talk about",
    "start": "919529",
    "end": "927420"
  },
  {
    "text": "the Twitter API for a second and renal do abetik asks if the slides will be",
    "start": "927420",
    "end": "934379"
  },
  {
    "text": "available the slides are actually already on and I'm happy to share them with anybody who is curious so Deb duck twitter.com",
    "start": "934379",
    "end": "943490"
  },
  {
    "text": "and let's look at the api's that we have",
    "start": "943490",
    "end": "949550"
  },
  {
    "text": "available so we have the direct messages",
    "start": "949550",
    "end": "956209"
  },
  {
    "text": "API and this is going to allow us to send direct messages and and do really",
    "start": "956209",
    "end": "963230"
  },
  {
    "text": "whatever we want and then we have the account activity API which is very",
    "start": "963230",
    "end": "969230"
  },
  {
    "text": "similar to the direct messages API and the way that it works and it works on a concept called web hooks and what",
    "start": "969230",
    "end": "975980"
  },
  {
    "text": "happens here is you provision an application and you take the credentials",
    "start": "975980",
    "end": "981139"
  },
  {
    "text": "from that application which are typically your application secret it's it's Olaf if you've ever heard that term before it's this application secret this",
    "start": "981139",
    "end": "988370"
  },
  {
    "text": "application access token and consumer key and there are different names for",
    "start": "988370",
    "end": "994370"
  },
  {
    "text": "the different subcomponents of how autism implemented and you're basically",
    "start": "994370",
    "end": "1001600"
  },
  {
    "text": "taking these various sub components and you're you are using them to cryptographically sign or verify",
    "start": "1001600",
    "end": "1008110"
  },
  {
    "text": "requests that are either coming to your app or requests that you were making it back to Twitter so the way that this",
    "start": "1008110",
    "end": "1015879"
  },
  {
    "text": "works in practice is you can actually have people so often in authenticate",
    "start": "1015879",
    "end": "1021339"
  },
  {
    "text": "into your application and then you can make actions on their behalf as an application so in this case Twitter",
    "start": "1021339",
    "end": "1028390"
  },
  {
    "text": "makes it very easy for you to provision an access token for just yourself and you don't need any kind of white listing",
    "start": "1028390",
    "end": "1034390"
  },
  {
    "text": "or or additional review of the application in order to allow that so what we've done is we've created this",
    "start": "1034390",
    "end": "1040899"
  },
  {
    "text": "application where an L and we're going to teach it to go and talk to these",
    "start": "1040899",
    "end": "1046990"
  },
  {
    "text": "various web bugs and we may not finish this bot in the amount of time that we",
    "start": "1046990",
    "end": "1054520"
  },
  {
    "text": "have so if there is a section of this that you are more interested in seeing I",
    "start": "1054520",
    "end": "1059980"
  },
  {
    "text": "can talk more about the machine learning side or I can talk more about the service integration side it's really up",
    "start": "1059980",
    "end": "1067090"
  },
  {
    "text": "to you guys so in the meantime we're gonna make use of another service",
    "start": "1067090",
    "end": "1072350"
  },
  {
    "text": "oh and this is already done provisioning so I'll open that up so we're gonna make",
    "start": "1072350",
    "end": "1080180"
  },
  {
    "text": "use of another service called secrets manager and the reason we're gonna use and yes the code is actually already",
    "start": "1080180",
    "end": "1089030"
  },
  {
    "text": "available not this exact code that we're building today but some code that we've built also on twitch in the past I can",
    "start": "1089030",
    "end": "1096020"
  },
  {
    "text": "post the location to that right now so I",
    "start": "1096020",
    "end": "1102100"
  },
  {
    "text": "did allow twitch to name the previous version of this code so that is the code",
    "start": "1102100",
    "end": "1112730"
  },
  {
    "text": "I'm sorry there's no readme or anything like that I but as you can see we built",
    "start": "1112730",
    "end": "1118610"
  },
  {
    "text": "this live on twitch and we kind of thanked all the people who joined in so",
    "start": "1118610",
    "end": "1124090"
  },
  {
    "text": "and it seems like we have one vote for the service integration side and hi dr.",
    "start": "1124090",
    "end": "1130070"
  },
  {
    "text": "Wolfram Sydney so the service integration side we can start talking about that the the way that we're going",
    "start": "1130070",
    "end": "1139820"
  },
  {
    "text": "to get access to our credentials here is we're going to use as another AWS service called credentials manager now",
    "start": "1139820",
    "end": "1145370"
  },
  {
    "text": "credentials manager is or or sorry we're gonna use secrets manager and secrets",
    "start": "1145370",
    "end": "1151430"
  },
  {
    "text": "manager is a new service previously prior to the release of secrets manager I actually used the the parameter store",
    "start": "1151430",
    "end": "1161300"
  },
  {
    "text": "so if you go over to systems manager within AWS there's another service called parameter store and this is how I",
    "start": "1161300",
    "end": "1175430"
  },
  {
    "text": "used to store all of my various keys however secrets manager has a built-in",
    "start": "1175430",
    "end": "1182570"
  },
  {
    "text": "rotation mechanism that's pretty powerful and that rotation mechanism",
    "start": "1182570",
    "end": "1188150"
  },
  {
    "text": "will actually allow me to write my own lambda functions to go out to Twitter and refresh my tokens whenever they run",
    "start": "1188150",
    "end": "1196010"
  },
  {
    "text": "out so if I want to use this I kind of just need to use boat",
    "start": "1196010",
    "end": "1202980"
  },
  {
    "text": "Bodo three is the Python SDK so boto is named after the amazon river boat o",
    "start": "1202980",
    "end": "1210570"
  },
  {
    "text": "dolphin and i I didn't name it I'm sorry it was me so because it's the Amazon Web Services",
    "start": "1210570",
    "end": "1217770"
  },
  {
    "text": "SDK yeah and what we're gonna do is you're just gonna say import photo three we're gonna create a secrets manager",
    "start": "1217770",
    "end": "1223050"
  },
  {
    "text": "object so secrets equals photo 3 client secrets manager and then I'm going to",
    "start": "1223050",
    "end": "1229350"
  },
  {
    "text": "say region name equals u.s. west two because that's the region that I'm using",
    "start": "1229350",
    "end": "1234480"
  },
  {
    "text": "today and from there I'll say secrets get see well I don't actually remember",
    "start": "1234480",
    "end": "1241680"
  },
  {
    "text": "what the API call is so I'll just say secrets dot get secret value and then",
    "start": "1241680",
    "end": "1249150"
  },
  {
    "text": "we'll say secret well I I also don't remember what the API perimeter is so",
    "start": "1249150",
    "end": "1255180"
  },
  {
    "text": "I'll just call out to help and I'll say secret ID is what I need so",
    "start": "1255180",
    "end": "1262590"
  },
  {
    "text": "I will say secrets dot get secret secret",
    "start": "1262590",
    "end": "1267600"
  },
  {
    "text": "value secrets ID equals and then we just",
    "start": "1267600",
    "end": "1273810"
  },
  {
    "text": "as you saw before we have our ID here so we can just copy this and that's gonna",
    "start": "1273810",
    "end": "1279150"
  },
  {
    "text": "be my credentials to talk to Twitter and",
    "start": "1279150",
    "end": "1287850"
  },
  {
    "text": "of course there was some sort of error secrets ID versus secret ID cool so now",
    "start": "1287850",
    "end": "1295770"
  },
  {
    "text": "we have my credentials but in order to do things with those credentials we need to basically use the Python Twitter SDK",
    "start": "1295770",
    "end": "1304980"
  },
  {
    "text": "luckily I already have this installed if you don't have this installed you could run something simple like pip install",
    "start": "1304980",
    "end": "1311690"
  },
  {
    "text": "Python Twitter and that would kind of get you off to the races",
    "start": "1312410",
    "end": "1317600"
  },
  {
    "text": "so from here I'll say import Twitter and I'm going to basically need to unpack",
    "start": "1317600",
    "end": "1328590"
  },
  {
    "text": "that dictionary that's returned from the secrets manager and I'm actually gonna",
    "start": "1328590",
    "end": "1335700"
  },
  {
    "text": "do this off really fast just in case I accidentally exposed my credentials so I don't",
    "start": "1335700",
    "end": "1342029"
  },
  {
    "text": "remember the exact invocation so I'm just gonna make sure that I have this",
    "start": "1342029",
    "end": "1347970"
  },
  {
    "text": "right and I didn't so I'm glad I did",
    "start": "1347970",
    "end": "1365070"
  },
  {
    "text": "that off screen weekly so we also were",
    "start": "1365070",
    "end": "1371850"
  },
  {
    "text": "gonna import JSON here and just to keep all of this a little bit easier to run",
    "start": "1371850",
    "end": "1378539"
  },
  {
    "text": "since there's no real cost and running all of this again we'll do it like this we'll put it all in that first one and",
    "start": "1378539",
    "end": "1384750"
  },
  {
    "text": "we'll say a JSON that loads string and this should load it as a dictionary so",
    "start": "1384750",
    "end": "1393179"
  },
  {
    "text": "now we have our credential string and we really just want to unpack this so I I",
    "start": "1393179",
    "end": "1399179"
  },
  {
    "text": "know that Twitter accepts the expects",
    "start": "1399179",
    "end": "1405690"
  },
  {
    "text": "the input in a certain order but I don't remember exactly what that order is so I'm just gonna go Python Twitter API and",
    "start": "1405690",
    "end": "1413159"
  },
  {
    "text": "look up what the instantiation is and if",
    "start": "1413159",
    "end": "1420720"
  },
  {
    "text": "we go over here to getting started we",
    "start": "1420720",
    "end": "1427230"
  },
  {
    "text": "can see our little API keys and consumer key consumer secret and again I just",
    "start": "1427230",
    "end": "1435149"
  },
  {
    "text": "have to go off-screen for one second to make sure I have the right values here",
    "start": "1435149",
    "end": "1441629"
  },
  {
    "text": "so we have consumer key consumer secret access token access token secret we do",
    "start": "1441629",
    "end": "1449460"
  },
  {
    "text": "indeed have the right values excellent so one of the cool things about Python",
    "start": "1449460",
    "end": "1454470"
  },
  {
    "text": "is I can actually just have this run and",
    "start": "1454470",
    "end": "1459899"
  },
  {
    "text": "I can instantiate Twitter by saying Twitter equals R sorry I I guess I need",
    "start": "1459899",
    "end": "1465090"
  },
  {
    "text": "to import it import Twitter and I can say C",
    "start": "1465090",
    "end": "1470440"
  },
  {
    "text": "equals I guess I should really call this a Twitter API equals Twitter dot I and",
    "start": "1470440",
    "end": "1482350"
  },
  {
    "text": "then I just unpacked that creds object and of course I spelled access token",
    "start": "1482350",
    "end": "1490180"
  },
  {
    "text": "wrong did I let's see access token key",
    "start": "1490180",
    "end": "1499570"
  },
  {
    "text": "is what it's called so let me just there's an easy way of fixing this which",
    "start": "1499570",
    "end": "1505060"
  },
  {
    "text": "is to hop over back into the secrets manager console and change it from access token to access tokens secret",
    "start": "1505060",
    "end": "1512880"
  },
  {
    "text": "these are the this is the fun of live coding everybody so let's change this to",
    "start": "1512880",
    "end": "1524820"
  },
  {
    "text": "access token key and then we can run",
    "start": "1529830",
    "end": "1535180"
  },
  {
    "text": "this again and we have our Twitter API and just to verify that we have the",
    "start": "1535180",
    "end": "1540670"
  },
  {
    "text": "righty you know Twitter API we can say verify credentials and then we can say a screen",
    "start": "1540670",
    "end": "1547000"
  },
  {
    "text": "name and our screen name is where I'm ill so we've got our bot working so",
    "start": "1547000",
    "end": "1552120"
  },
  {
    "text": "previously Twitter had an API called the kind of user streams API so you would go",
    "start": "1552120",
    "end": "1560290"
  },
  {
    "text": "and you would say you know Twitter API dot get user stream and you would just",
    "start": "1560290",
    "end": "1571840"
  },
  {
    "text": "have kind of a while loop where you were taking the results of Twitter stream and doing things with it",
    "start": "1571840",
    "end": "1577840"
  },
  {
    "text": "however they have deprecated those api's they're going away in August so now you have to use the web hooks API and the",
    "start": "1577840",
    "end": "1584500"
  },
  {
    "text": "web hooks API is actually much better for a service environment because it allows us to go out to the AWS console",
    "start": "1584500",
    "end": "1592180"
  },
  {
    "text": "like API gateway and we can create our own little API here so I can create a new API I can",
    "start": "1592180",
    "end": "1599530"
  },
  {
    "text": "call it where ml so this is the Amazon API gateway [Music]",
    "start": "1599530",
    "end": "1605099"
  },
  {
    "text": "console and we're just going to create a completely new API where ml webhooks API",
    "start": "1605099",
    "end": "1617758"
  },
  {
    "text": "and we're gonna define a new method and",
    "start": "1618239",
    "end": "1623969"
  },
  {
    "text": "this is just going to be any and we're",
    "start": "1623969",
    "end": "1629320"
  },
  {
    "text": "gonna invoke a lambda function with that and we're gonna make it a proxy invocation now the proxy invocation is there are two",
    "start": "1629320",
    "end": "1638799"
  },
  {
    "text": "different ways of invoking lambda the first is to rely on some of the underlying parts of the API gateway to",
    "start": "1638799",
    "end": "1647009"
  },
  {
    "text": "transform the incoming message so the incoming message could and could be JSON",
    "start": "1647009",
    "end": "1652749"
  },
  {
    "text": "it could be binary it could be whatever kind of data it is we want to make sure",
    "start": "1652749",
    "end": "1657969"
  },
  {
    "text": "that we are performing as much as possible outside of the lambda function before give it to the lambda function so",
    "start": "1657969",
    "end": "1664629"
  },
  {
    "text": "that the data is in the format we expect now because of the way that the authentication and other variant sub",
    "start": "1664629",
    "end": "1670899"
  },
  {
    "text": "components of this lambda work I'm gonna use a proxy invocation because sometimes",
    "start": "1670899",
    "end": "1676329"
  },
  {
    "text": "we're gonna get a an HTTP GET request sub judice capital GE T and that get",
    "start": "1676329",
    "end": "1682299"
  },
  {
    "text": "request is going to ask us to prove that we are who we say we are that our web",
    "start": "1682299",
    "end": "1689559"
  },
  {
    "text": "hook has the right credentials and we're gonna have to do some cryptographic signing and stuff just to make that work and sometimes we're going to get a post",
    "start": "1689559",
    "end": "1699489"
  },
  {
    "text": "request and that post request is going to be the same kind of style where we",
    "start": "1699489",
    "end": "1706359"
  },
  {
    "text": "have to take the content the body out of the out of the request and we have to",
    "start": "1706359",
    "end": "1714849"
  },
  {
    "text": "transform it and decode it from JSON and perhaps also unencrypted and the",
    "start": "1714849",
    "end": "1720190"
  },
  {
    "text": "advantage of the proxy integration is that rather than having to define this as two completely separate components I",
    "start": "1720190",
    "end": "1725619"
  },
  {
    "text": "can kind of keep the related cryptographic stuff inside that said I",
    "start": "1725619",
    "end": "1731460"
  },
  {
    "text": "there are also advantages to defining the",
    "start": "1731460",
    "end": "1736570"
  },
  {
    "text": "methods but we'll just do this for now but I don't have a lambda function yet",
    "start": "1736570",
    "end": "1742179"
  },
  {
    "text": "so before I can even go and build all of this I'm gonna go and make a lambda function so I'm just gonna do this right",
    "start": "1742179",
    "end": "1750789"
  },
  {
    "text": "here in the console and I'm gonna say create a new function and we'll just",
    "start": "1750789",
    "end": "1758470"
  },
  {
    "text": "call this where ml and Volker we're gonna do this in Python we're gonna use",
    "start": "1758470",
    "end": "1763630"
  },
  {
    "text": "Python 3 because we are modern and good and we're just gonna use an existing",
    "start": "1763630",
    "end": "1771388"
  },
  {
    "text": "role that I have for my lambda functions",
    "start": "1771840",
    "end": "1777028"
  },
  {
    "text": "[Music] so we've created the function it's",
    "start": "1778220",
    "end": "1787059"
  },
  {
    "text": "loading loading loading loading I'm",
    "start": "1787059",
    "end": "1797139"
  },
  {
    "text": "gonna refresh because it normally is ready and sent aeneas Lee and doesn't need any of this and I'm actually gonna",
    "start": "1797139",
    "end": "1808059"
  },
  {
    "text": "go ahead and bump this all the way up to 3 gigs and I'm gonna set the timeout to 30 seconds so the function is actually",
    "start": "1808059",
    "end": "1821230"
  },
  {
    "text": "ready to go it's just this editor that's not loading I don't know why but it",
    "start": "1821230",
    "end": "1831009"
  },
  {
    "text": "doesn't matter we can hop back over to API gateway we can take our any method take our proxy on vacation and we can",
    "start": "1831009",
    "end": "1838659"
  },
  {
    "text": "say we want to use where AM L invoker so I'll click Save okay and now we have a",
    "start": "1838659",
    "end": "1849149"
  },
  {
    "text": "napi gateway so I think if we test this it should just kind of return and we got",
    "start": "1849149",
    "end": "1860139"
  },
  {
    "text": "an internal server here of course that's because we're not returning our stuff in the right format there we go so the",
    "start": "1860139",
    "end": "1868480"
  },
  {
    "text": "format that is expected from a proxy invocation is actually something like this so it's",
    "start": "1868480",
    "end": "1874810"
  },
  {
    "text": "supposed to be returned status code and then you know is it a 200 or 400 or",
    "start": "1874810",
    "end": "1882190"
  },
  {
    "text": "whatever in this case we're just going to say 200 and then we're gonna have our body and our body in this case is going",
    "start": "1882190",
    "end": "1888160"
  },
  {
    "text": "to be and one of my favorite parts of",
    "start": "1888160",
    "end": "1893740"
  },
  {
    "text": "this is that it supports it supports vim mode in this new editor so you can press",
    "start": "1893740",
    "end": "1901120"
  },
  {
    "text": "escape and you immediately have the mode enabled even with like little macro",
    "start": "1901120",
    "end": "1907330"
  },
  {
    "text": "recording and stuff too but that's the super nerdy stuff and we're just gonna say hello world to start we'll click",
    "start": "1907330",
    "end": "1914800"
  },
  {
    "text": "Save and we'll test this again and you",
    "start": "1914800",
    "end": "1921760"
  },
  {
    "text": "can see we got back this result so it is working now we need to deploy this and given that we're developers we're",
    "start": "1921760",
    "end": "1928840"
  },
  {
    "text": "definitely gonna just deploy a prod so production yay",
    "start": "1928840",
    "end": "1934890"
  },
  {
    "text": "don't ever deploy directly to prod so",
    "start": "1934890",
    "end": "1940930"
  },
  {
    "text": "we'll deploy this and you can see we get this handy-dandy URL and if we invoke it we get this little end point so you can",
    "start": "1940930",
    "end": "1948700"
  },
  {
    "text": "even curl this you can say curl let me get this hello world and you guys are welcome to try that out and there's all",
    "start": "1948700",
    "end": "1958390"
  },
  {
    "text": "kinds of good little controls we can put in place like we can enable throttling so no more than you know 1,000 requests",
    "start": "1958390",
    "end": "1965230"
  },
  {
    "text": "per second I'm actually gonna bring this down to like 1,000 and burst of 2000",
    "start": "1965230",
    "end": "1971370"
  },
  {
    "text": "save those changes and we can enable a cache and that casual provision and",
    "start": "1971370",
    "end": "1978640"
  },
  {
    "text": "elastic cache storage memcache key instance for me all kinds of really good",
    "start": "1978640",
    "end": "1984100"
  },
  {
    "text": "stuff we can even set stage specific variables so if we were in dev we could say we want to set our log level to",
    "start": "1984100",
    "end": "1989260"
  },
  {
    "text": "debug if we were in production we could say our log level is err all that good",
    "start": "1989260",
    "end": "1995140"
  },
  {
    "text": "stuff and we can op over the dashboard and we can see the number of API calls that are coming in very good very cool",
    "start": "1995140",
    "end": "2001800"
  },
  {
    "text": "useful service now what we want to do is we want to tell",
    "start": "2001800",
    "end": "2006930"
  },
  {
    "text": "Twitter to invoke this endpoint whenever something happens but before we can do",
    "start": "2006930",
    "end": "2013890"
  },
  {
    "text": "that we're gonna need a little bit more I context and content in order to be",
    "start": "2013890",
    "end": "2020970"
  },
  {
    "text": "able to correctly sign these messages that are going to come in so we have to go back to Twitter and we have to look",
    "start": "2020970",
    "end": "2026250"
  },
  {
    "text": "and see what a web hook looks like so if we hop over to guides we can see getting",
    "start": "2026250",
    "end": "2033390"
  },
  {
    "text": "started with web bugs and it says you know you apply for your developer account and do all this stuff which",
    "start": "2033390",
    "end": "2040170"
  },
  {
    "text": "we've already done and now I know that I need to call out to this web hook URL",
    "start": "2040170",
    "end": "2045240"
  },
  {
    "text": "web hooks JSON URL and then I need to",
    "start": "2045240",
    "end": "2050879"
  },
  {
    "text": "work on securing the web hook so to secure the web hook I have to do a challenge response to check and this is",
    "start": "2050880",
    "end": "2056610"
  },
  {
    "text": "gonna take the the tokens that credit from the credentials that I had earlier",
    "start": "2056610",
    "end": "2062610"
  },
  {
    "text": "and it's going to use them to cryptographically sign the response and the amusing thing is is actually code",
    "start": "2062610",
    "end": "2069629"
  },
  {
    "text": "that that I wrote a long time ago this",
    "start": "2069630",
    "end": "2077370"
  },
  {
    "text": "API is kind of old so let's go over here and we want to define a method sign CRC",
    "start": "2077370",
    "end": "2087080"
  },
  {
    "text": "crc we're gonna say and we're going to need to import a couple of tools you're going to need to import h Mac and I mean",
    "start": "2087080",
    "end": "2093480"
  },
  {
    "text": "a lot of this is outlined right here so we could kind of start from this if we wanted to but we're gonna change it",
    "start": "2093480",
    "end": "2101070"
  },
  {
    "text": "slightly so consider two cell below",
    "start": "2101070",
    "end": "2106370"
  },
  {
    "text": "we're gonna have this method import",
    "start": "2106820",
    "end": "2111920"
  },
  {
    "text": "base64 import JSON well we're already",
    "start": "2111920",
    "end": "2117000"
  },
  {
    "text": "gonna have JSON available to us we're going to say sign CRC so what we want to do is we want to take those credentials",
    "start": "2117000",
    "end": "2122790"
  },
  {
    "text": "that we had earlier and we want to grab the consumer secret then from the input",
    "start": "2122790",
    "end": "2133530"
  },
  {
    "text": "we want to say you know the crc is something that we're gonna extract from the from the incoming",
    "start": "2133530",
    "end": "2141640"
  },
  {
    "text": "request and - - too bad C's asks can you",
    "start": "2141640",
    "end": "2148030"
  },
  {
    "text": "install any Python 3.6 packages in there you absolutely can there are two ways of deploying lambda",
    "start": "2148030",
    "end": "2155230"
  },
  {
    "text": "functions the first is to do the method that I I most commonly do which is just",
    "start": "2155230",
    "end": "2160809"
  },
  {
    "text": "kind of zip it up locally and the second is to use cloud 9 and Sam and say hey I want you to pull down all of my",
    "start": "2160809",
    "end": "2166869"
  },
  {
    "text": "dependencies for me and just build it in and deploy I'll probably not be doing it",
    "start": "2166869",
    "end": "2172030"
  },
  {
    "text": "that way today though and we don't have a ton of time left I think in fact we",
    "start": "2172030",
    "end": "2177339"
  },
  {
    "text": "only have about 10 minutes left so just give me one second here let me see what",
    "start": "2177339",
    "end": "2189010"
  },
  {
    "text": "time is this supposed to end 5:40 so we have about 20 minutes left so I'm gonna I'm gonna speed up a little bit if you have any questions feel free to ask them",
    "start": "2189010",
    "end": "2195339"
  },
  {
    "text": "but I'm gonna I'm gonna go quite a bit faster now just to try and get everything done so we're gonna say that",
    "start": "2195339",
    "end": "2201309"
  },
  {
    "text": "we're you're gonna have our hash and we're gonna say H Manu and we're going to convert this into bytes we're gonna",
    "start": "2201309",
    "end": "2207549"
  },
  {
    "text": "say we want our our consumer secret here",
    "start": "2207549",
    "end": "2215670"
  },
  {
    "text": "and this H mac is just a method of signing a request so we're gonna grab",
    "start": "2218039",
    "end": "2223809"
  },
  {
    "text": "this and then the other thing that we need to do is we actually need to convert we need to tell the the byte",
    "start": "2223809",
    "end": "2230710"
  },
  {
    "text": "encoder that we're calling here how to convert the input because strings in",
    "start": "2230710",
    "end": "2235779"
  },
  {
    "text": "Python are in Python 3 are unicode by",
    "start": "2235779",
    "end": "2241299"
  },
  {
    "text": "default and the HVAC encoder for some reason doesn't accept that and they're going to say digest mod equals and this",
    "start": "2241299",
    "end": "2248109"
  },
  {
    "text": "is where we need to import sha-256 from hashlib so we're going to say import",
    "start": "2248109",
    "end": "2255869"
  },
  {
    "text": "hash Lib so we'll say from ashleighb",
    "start": "2255869",
    "end": "2262119"
  },
  {
    "text": "import sha-256 da-da-da-da-da and",
    "start": "2262119",
    "end": "2267480"
  },
  {
    "text": "sha-256 is going to be our means of encrypting and you can see this is really just the exact same as what's",
    "start": "2267480",
    "end": "2275070"
  },
  {
    "text": "what's happening below we're just doing",
    "start": "2275070",
    "end": "2280410"
  },
  {
    "text": "it in a better way than this sample code was and from there we have our H max so",
    "start": "2280410",
    "end": "2290820"
  },
  {
    "text": "this is the hatch that we need and we just need to return that signed message",
    "start": "2290820",
    "end": "2296820"
  },
  {
    "text": "so from we can return this as a string",
    "start": "2296820",
    "end": "2304500"
  },
  {
    "text": "or we can return it really however we want I'm gonna return it as a JSON",
    "start": "2304500",
    "end": "2310020"
  },
  {
    "text": "string so we're gonna save the response token is going to be and it will put",
    "start": "2310020",
    "end": "2318770"
  },
  {
    "text": "sha-256 equals in front of this just to comply with what Twitter is asking us to do here we hop over to securing web",
    "start": "2318770",
    "end": "2326310"
  },
  {
    "text": "hooks should tell us what it's supposed to look like we're worried we're gonna",
    "start": "2326310",
    "end": "2338400"
  },
  {
    "text": "say sha-256 plus base64 so we'll say",
    "start": "2338400",
    "end": "2346800"
  },
  {
    "text": "from base64 import be 64 and code be 64",
    "start": "2346800",
    "end": "2354900"
  },
  {
    "text": "encode we'll get to perhaps a digest of",
    "start": "2354900",
    "end": "2360450"
  },
  {
    "text": "that thing that we just created and we'll call decode and that'll turn this",
    "start": "2360450",
    "end": "2369530"
  },
  {
    "text": "basic C for object into a string pretty straightforward so then if we call sign",
    "start": "2369530",
    "end": "2378119"
  },
  {
    "text": "and CRC sign CRC blah blah blah we get",
    "start": "2378119",
    "end": "2388890"
  },
  {
    "text": "our little response token which we can use and send that back to Twitter which is the first part of creating our web",
    "start": "2388890",
    "end": "2395760"
  },
  {
    "text": "hook so we can kind of copy all of this and put it into our lambda function",
    "start": "2395760",
    "end": "2403290"
  },
  {
    "text": "so we can say okay gate wait sorry we're gonna need we need all of this as",
    "start": "2403290",
    "end": "2415650"
  },
  {
    "text": "well so I'm gonna clean this up over in the lambda function now don't really",
    "start": "2415650",
    "end": "2423690"
  },
  {
    "text": "need Twitter and we don't need to specify the region since we are already",
    "start": "2423690",
    "end": "2429420"
  },
  {
    "text": "in uswest - all those you know sometimes explicitly stating the region is better",
    "start": "2429420",
    "end": "2435600"
  },
  {
    "text": "than not explicitly stating it and then this is all we need to do in order to",
    "start": "2435600",
    "end": "2441090"
  },
  {
    "text": "verify the webhook so you know we could define another method which is verify",
    "start": "2441090",
    "end": "2447780"
  },
  {
    "text": "request which I suppose we could do that now it's really just the exact same",
    "start": "2447780",
    "end": "2452850"
  },
  {
    "text": "process that we've done here with sign CRC except in Reverse so we're being given the CRC and we're decrypting which",
    "start": "2452850",
    "end": "2459690"
  },
  {
    "text": "is the code that you see here so instead of consumer secret I'm gonna say creds",
    "start": "2459690",
    "end": "2466250"
  },
  {
    "text": "consumer secret and just to check that all this kind of is syntactically",
    "start": "2466250",
    "end": "2472410"
  },
  {
    "text": "correct I'm gonna go down here and let's see oh yeah",
    "start": "2472410",
    "end": "2477960"
  },
  {
    "text": "well it doesn't have the right region and mr. robot asks if this will be",
    "start": "2477960",
    "end": "2483030"
  },
  {
    "text": "available later it should be yes and I'm gonna be doing another session later tonight I'm I'm just coming off of a",
    "start": "2483030",
    "end": "2489780"
  },
  {
    "text": "very long flight and I haven't slept in about 40 hours or so so later tonight I",
    "start": "2489780",
    "end": "2495630"
  },
  {
    "text": "might be a little bit more on my game and stop making so many mistakes so the",
    "start": "2495630",
    "end": "2504780"
  },
  {
    "text": "next thing that we want to do is we want to kind of figure out how to parse the",
    "start": "2504780",
    "end": "2512430"
  },
  {
    "text": "incoming event so we can say that if this event get path is gonna be you know",
    "start": "2512430",
    "end": "2523290"
  },
  {
    "text": "maybe maybe we have is web hope then you",
    "start": "2523290",
    "end": "2531840"
  },
  {
    "text": "know do the right thing return actually it's probably better to set",
    "start": "2531840",
    "end": "2538569"
  },
  {
    "text": "this up as a negative it's probably better to say if event Sukkot path does not equal webhook then we want to return",
    "start": "2538569",
    "end": "2546220"
  },
  {
    "text": "like a 404 or something return status",
    "start": "2546220",
    "end": "2552670"
  },
  {
    "text": "code for for and body equals this path",
    "start": "2552670",
    "end": "2559119"
  },
  {
    "text": "is not valid now or something like that now what we wanted you is if the event",
    "start": "2559119",
    "end": "2566250"
  },
  {
    "text": "Duquette p.m. method equals equals get",
    "start": "2566250",
    "end": "2572020"
  },
  {
    "text": "and so if it's a get request as opposed to some other kind of request and we know that the CRC is going to be a van",
    "start": "2572020",
    "end": "2577990"
  },
  {
    "text": "to get query string parameter string",
    "start": "2577990",
    "end": "2585220"
  },
  {
    "text": "I cannot spell this to save my life query string parameters and we'll will",
    "start": "2585220",
    "end": "2593980"
  },
  {
    "text": "populate this with an empty dictionary just in case we don't have the right thing here CRC token and if not if not",
    "start": "2593980",
    "end": "2607200"
  },
  {
    "text": "CRC then we want to return again a status code 500 will say 401 and the",
    "start": "2607200",
    "end": "2617589"
  },
  {
    "text": "body will be scroll up sorry guys this is better sorry about that",
    "start": "2617589",
    "end": "2625299"
  },
  {
    "text": "we're gonna say let me actually adjust this screen a little bit I'll turn off",
    "start": "2625299",
    "end": "2631720"
  },
  {
    "text": "the image that should make it a little bit easier to see and I can also make it",
    "start": "2631720",
    "end": "2637000"
  },
  {
    "text": "bigger so from it's nice that you guys",
    "start": "2637000",
    "end": "2643960"
  },
  {
    "text": "said something in check because it makes me feel like somebody's watching and we'll just say CRC not provided or",
    "start": "2643960",
    "end": "2650260"
  },
  {
    "text": "invalid and then we return status code",
    "start": "2650260",
    "end": "2660270"
  },
  {
    "text": "200 and body sign CRC and that's CRC",
    "start": "2660270",
    "end": "2667809"
  },
  {
    "text": "that we just kind of took out now if you're skiing how exactly we're supposed to",
    "start": "2667809",
    "end": "2675670"
  },
  {
    "text": "grab this and and do stuff with it one",
    "start": "2675670",
    "end": "2681069"
  },
  {
    "text": "of the one of the frustrating parts of Python is that there is no kind of boundaries so you have to rely on white",
    "start": "2681069",
    "end": "2688029"
  },
  {
    "text": "space here to know exactly what's happening so you know I could probably make this a little bit easier to read if",
    "start": "2688029",
    "end": "2693099"
  },
  {
    "text": "I threw an else in here and I said hey let me do it like this but it's not the",
    "start": "2693099",
    "end": "2700450"
  },
  {
    "text": "most pythonic thing in the world to do that so we're gonna keep it the way that it is and we're gonna say you know",
    "start": "2700450",
    "end": "2708999"
  },
  {
    "text": "return this status code 200 body whatever so that's gonna call out to our",
    "start": "2708999",
    "end": "2715869"
  },
  {
    "text": "CRC function which is going to say hey calculate this H Mac in return and that",
    "start": "2715869",
    "end": "2722859"
  },
  {
    "text": "is all that we need in order to sign up a web hook to do stuff for this function",
    "start": "2722859",
    "end": "2730359"
  },
  {
    "text": "now given the amount of time that we have left I don't want to replace the",
    "start": "2730359",
    "end": "2738910"
  },
  {
    "text": "existing working webhook on the where AM L bought with this one just because we",
    "start": "2738910",
    "end": "2744009"
  },
  {
    "text": "haven't really implemented the machine learning side of this algorithm yet so I",
    "start": "2744009",
    "end": "2749469"
  },
  {
    "text": "have about ten minutes left and I'm gonna use those ten minutes to hop into how the machine learning side of this",
    "start": "2749469",
    "end": "2756430"
  },
  {
    "text": "bot works so I'm gonna skip over most of",
    "start": "2756430",
    "end": "2761829"
  },
  {
    "text": "the sage maker part here sorry lots of",
    "start": "2761829",
    "end": "2770410"
  },
  {
    "text": "slides okay so the goal of this bot was",
    "start": "2770410",
    "end": "2777519"
  },
  {
    "text": "to be able to identify where in the world picture was based on the pixels in",
    "start": "2777519",
    "end": "2783789"
  },
  {
    "text": "the image alone and nothing more now that is a hard concept right typically",
    "start": "2783789",
    "end": "2789309"
  },
  {
    "text": "photos are posted with metadata they're posted with something called exif data",
    "start": "2789309",
    "end": "2794979"
  },
  {
    "text": "that contains latitude and longitude now there's a dataset uh that's hosted",
    "start": "2794979",
    "end": "2801400"
  },
  {
    "text": "in AWS public datasets repo I'll show you this now",
    "start": "2801400",
    "end": "2805979"
  },
  {
    "text": "so I'll show you the public datasets you'll excuse me for just one second I'm",
    "start": "2811500",
    "end": "2818020"
  },
  {
    "text": "gonna yes I will definitely provide the slides so if we look for the multimedia",
    "start": "2818020",
    "end": "2828450"
  },
  {
    "text": "Commons data set this is a collection of a more than 100 million Creative Commons",
    "start": "2828450",
    "end": "2834520"
  },
  {
    "text": "license Flickr images and videos so this is a huge huge huge data set 100 million",
    "start": "2834520",
    "end": "2841060"
  },
  {
    "text": "different image files and video files the videos add up to around 8 thousand",
    "start": "2841060",
    "end": "2846730"
  },
  {
    "text": "hours of video with an average video length of 37 and a medium medium video length of 28 seconds",
    "start": "2846730",
    "end": "2852190"
  },
  {
    "text": "so that's 99 million image files and of those 99 million many of them contain",
    "start": "2852190",
    "end": "2859560"
  },
  {
    "text": "exif data so they contain the data that we need in order to be able to create",
    "start": "2859560",
    "end": "2867400"
  },
  {
    "text": "this machine Learning Network so some researchers some researchers at Berkeley not me they took the 33 point nine",
    "start": "2867400",
    "end": "2877390"
  },
  {
    "text": "million images from that data set and they built on top of an existing image",
    "start": "2877390",
    "end": "2884860"
  },
  {
    "text": "recognition classification network called ResNet and it's a very ResNet was",
    "start": "2884860",
    "end": "2889930"
  },
  {
    "text": "originally created back in I think 2015 by Microsoft Research they took that ResNet architecture which was originally",
    "start": "2889930",
    "end": "2896260"
  },
  {
    "text": "designed to identify you know whether or not it was a picture of a dog or whether or not it was a picture of a cat or a",
    "start": "2896260",
    "end": "2901780"
  },
  {
    "text": "picture of a bicycle or a picture of a whiteboard or a microphone anything like that if they took that same network and",
    "start": "2901780",
    "end": "2909360"
  },
  {
    "text": "they took out the very last layer of the network so instead of being a",
    "start": "2909360",
    "end": "2914710"
  },
  {
    "text": "classification layer for objects they replaced it with a geometrical",
    "start": "2914710",
    "end": "2920950"
  },
  {
    "text": "classification layer and so that they provided fifteen thousand five hundred and twenty seven different",
    "start": "2920950",
    "end": "2927420"
  },
  {
    "text": "classifications and they took those 33 point nine million geotagged images and they just iterated over them and figured",
    "start": "2927420",
    "end": "2934390"
  },
  {
    "text": "out where in that fifteen thousand five hundred twenty a set of classifications each image",
    "start": "2934390",
    "end": "2942100"
  },
  {
    "text": "belonged and they were able to train the network that way and that took about nine days on a single P to 16s x-large",
    "start": "2942100",
    "end": "2949060"
  },
  {
    "text": "and the resulting model was around 218 megabytes",
    "start": "2949060",
    "end": "2954070"
  },
  {
    "text": "now on a p3 16x large and on a machine",
    "start": "2954070",
    "end": "2960130"
  },
  {
    "text": "where you can actually or in a framework where you can actually go and spread",
    "start": "2960130",
    "end": "2965410"
  },
  {
    "text": "that training job out I've actually been able to train for more epochs and",
    "start": "2965410",
    "end": "2970530"
  },
  {
    "text": "converge a little bit faster parallel in only one day so I'm able to train the",
    "start": "2970530",
    "end": "2975850"
  },
  {
    "text": "exact same amount of data and everything in one single day which is kind of cool",
    "start": "2975850",
    "end": "2981180"
  },
  {
    "text": "and just in case you've never seen what the resonant architecture looks like before it's really straightforward I'm",
    "start": "2981180",
    "end": "2986920"
  },
  {
    "text": "sure everyone understands this and doesn't really need me to explain it makes sense right makes perfect sense",
    "start": "2986920",
    "end": "2993300"
  },
  {
    "text": "it seems like there's a lot of stuff happening the thing that resonate does is it kind of has a cheat code so what",
    "start": "2993300",
    "end": "2999370"
  },
  {
    "text": "Microsoft Research proposed and you know they were these people working at Microsoft C's research what they",
    "start": "2999370",
    "end": "3005460"
  },
  {
    "text": "proposed was instead of having layer after layer after layer after layer go",
    "start": "3005460",
    "end": "3012150"
  },
  {
    "text": "through and propagate its results to the next layer they built in a cheat code in",
    "start": "3012150",
    "end": "3017460"
  },
  {
    "text": "some of the layers that says if the signal is strong enough we actually want to propagate over to this other channel",
    "start": "3017460",
    "end": "3022620"
  },
  {
    "text": "and come over outside of the the existing flow of the network and go down into a layer where we know that this",
    "start": "3022620",
    "end": "3029250"
  },
  {
    "text": "signal will be relevant now the reason that you do that is that the more layers",
    "start": "3029250",
    "end": "3034290"
  },
  {
    "text": "that you add to these networks the more you suffer from loss so the output",
    "start": "3034290",
    "end": "3042150"
  },
  {
    "text": "signal the error function that you calculate between your your your given",
    "start": "3042150",
    "end": "3047970"
  },
  {
    "text": "results in the network and the result that you wanted that error becomes harder and harder to propagate and it",
    "start": "3047970",
    "end": "3054440"
  },
  {
    "text": "backwards it's harder to get that back to the neurons that matter and say hey this is what we need to do so what the",
    "start": "3054440",
    "end": "3065180"
  },
  {
    "text": "planet paper did and this was from Google research they they came up with",
    "start": "3065180",
    "end": "3070560"
  },
  {
    "text": "this ideas they took the s2 multiscale partitioning library and they went through all of",
    "start": "3070560",
    "end": "3077519"
  },
  {
    "text": "this and they basically split the earth into thousands and thousands of",
    "start": "3077519",
    "end": "3083430"
  },
  {
    "text": "different little cells so if you look at the places that are very densely populated you'll see that there are a lot more cells there now the reason that",
    "start": "3083430",
    "end": "3090630"
  },
  {
    "text": "that happens is the way they calculated this index was they actually took the",
    "start": "3090630",
    "end": "3097380"
  },
  {
    "text": "existing data set of those 33 million images and they they used a piece of",
    "start": "3097380",
    "end": "3102839"
  },
  {
    "text": "fractal geometry called the Hilbert curve to figure out how dense each region needed to be based on the number",
    "start": "3102839",
    "end": "3109410"
  },
  {
    "text": "of images that were in that region so this allows them to represent the space",
    "start": "3109410",
    "end": "3117869"
  },
  {
    "text": "available in a very very small way so this is what a Hilbert curve looks like",
    "start": "3117869",
    "end": "3123390"
  },
  {
    "text": "if you've never seen one before I don't know why it's not playing their way to",
    "start": "3123390",
    "end": "3128999"
  },
  {
    "text": "play this let me see if I can find",
    "start": "3128999",
    "end": "3133670"
  },
  {
    "text": "Hilbert curb animation I'm just gonna",
    "start": "3134660",
    "end": "3143160"
  },
  {
    "text": "see if I can find this really really quickly I only have about five minutes left everybody so this is how a Hilbert",
    "start": "3143160",
    "end": "3152430"
  },
  {
    "text": "curve works so you start out like this",
    "start": "3152430",
    "end": "3159359"
  },
  {
    "text": "and then you repeat that step and you go into the same number of points now this",
    "start": "3159359",
    "end": "3166949"
  },
  {
    "text": "has a really really cool feature in that it allows you to go from two dimensions",
    "start": "3166949",
    "end": "3172319"
  },
  {
    "text": "into one dimension while preserving locality so you can preserve the",
    "start": "3172319",
    "end": "3177630"
  },
  {
    "text": "locality of x and y coordinates in a number line through this kind of compression algorithm all right not",
    "start": "3177630",
    "end": "3184140"
  },
  {
    "text": "compression algorithm but this piece of fractal geometry so you can see a repeated time and time again pretty cool",
    "start": "3184140",
    "end": "3192959"
  },
  {
    "text": "and so that is what this animation is",
    "start": "3192959",
    "end": "3198719"
  },
  {
    "text": "supposed to show now the advantage of using some",
    "start": "3198719",
    "end": "3204990"
  },
  {
    "text": "like ResNet and a classification layer at the end is that the resulting model is actually quite small so the the model",
    "start": "3204990",
    "end": "3211860"
  },
  {
    "text": "that Google proposed with their planet paper was on the order of 20 gigs and it did not have the best performance now",
    "start": "3211860",
    "end": "3219420"
  },
  {
    "text": "I'm not trying to like beat on Google or anything it's it's still a really brilliant idea so their work is what",
    "start": "3219420",
    "end": "3226560"
  },
  {
    "text": "allowed this later work to happen but the the 20 gigabyte model means it's not",
    "start": "3226560",
    "end": "3232320"
  },
  {
    "text": "something you could host no lambda function right it's kind of it's a big and expensive thing that you would have",
    "start": "3232320",
    "end": "3239400"
  },
  {
    "text": "to run a big server so the advantage of having a much smaller model than 300 megabyte model from that resonant",
    "start": "3239400",
    "end": "3245490"
  },
  {
    "text": "network is that the inferences are faster you don't have to go through as much data and you get in fact better",
    "start": "3245490",
    "end": "3252600"
  },
  {
    "text": "performance so not only can you train it faster you can also get better performance at inference runtime so",
    "start": "3252600",
    "end": "3260420"
  },
  {
    "text": "again the way that this works is we have twitter calling out to api gateway calling out to lambda function calling up to stage maker inference in point",
    "start": "3260420",
    "end": "3266040"
  },
  {
    "text": "and I've only got a few minutes left so I'm just gonna skip through here this is all the code okay",
    "start": "3266040",
    "end": "3272130"
  },
  {
    "text": "so how do we load the model in the way that we load the model in is we import",
    "start": "3272130",
    "end": "3277890"
  },
  {
    "text": "name X net and then we load the model now sage maker when you bring your own",
    "start": "3277890",
    "end": "3283320"
  },
  {
    "text": "model is going to kind of populate a bunch of different environment variables for me so this model name part is going",
    "start": "3283320",
    "end": "3290220"
  },
  {
    "text": "to be populated for me as an environment variable and I'll load that in and then I'm gonna bind that model to you know I",
    "start": "3290220",
    "end": "3296970"
  },
  {
    "text": "can just show this in the code it's a little bit easier to that see you from there predict so you can see here I'm",
    "start": "3296970",
    "end": "3309750"
  },
  {
    "text": "loading the model path and the model name and this is the ResNet 101",
    "start": "3309750",
    "end": "3316730"
  },
  {
    "text": "pre-trained all that good stuff now I'm loading the 12th epoch of this",
    "start": "3316730",
    "end": "3323700"
  },
  {
    "text": "model and I'm saying I want to bind this to the CPU now once I've found this to",
    "start": "3323700",
    "end": "3328980"
  },
  {
    "text": "the CPU I need to provide the parameter so the input shape the shape of the data that I'm going to be taking it and this",
    "start": "3328980",
    "end": "3334980"
  },
  {
    "text": "is going to be 224 by 2 24 pixels image and it's gonna be grayscale all",
    "start": "3334980",
    "end": "3342030"
  },
  {
    "text": "right I think it's actually going to be RGB I can't remember so we set some",
    "start": "3342030",
    "end": "3347160"
  },
  {
    "text": "parameters and these are just the parameters that we've loaded in from this load and then we do meaning the",
    "start": "3347160",
    "end": "3353790"
  },
  {
    "text": "image and this is just taking the mean of all the different images and kind of making it easier for the network to train that way if you have a bunch of",
    "start": "3353790",
    "end": "3360420"
  },
  {
    "text": "images that are really really black and a bunch of images that are really really yellow you're not you know mistakenly",
    "start": "3360420",
    "end": "3366830"
  },
  {
    "text": "throwing those images into the wrong place then you create a batch and then",
    "start": "3366830",
    "end": "3373170"
  },
  {
    "text": "you open this grids text op file now that grids text op file if I open this",
    "start": "3373170",
    "end": "3380250"
  },
  {
    "text": "really quickly this as you can see is",
    "start": "3380250",
    "end": "3389370"
  },
  {
    "text": "just it's basically a CSV so all it's saying is I have a couple of different IDs and this is the starting bounding",
    "start": "3389370",
    "end": "3395430"
  },
  {
    "text": "box and that's the ending bounding box for every single one of these so that is what that multi scale architecture was",
    "start": "3395430",
    "end": "3402150"
  },
  {
    "text": "that we were talking about before so we can go over to what was that other file",
    "start": "3402150",
    "end": "3407310"
  },
  {
    "text": "we had open we can go and we can load this in and it's only about one Meg that whole file and then we do some",
    "start": "3407310",
    "end": "3414810"
  },
  {
    "text": "pre-processing on in the image and this just says if the image is in portrait mode or it's in landscape mode we want",
    "start": "3414810",
    "end": "3420750"
  },
  {
    "text": "to kind of crop it towards this 224 by 224 section so that's all you know it",
    "start": "3420750",
    "end": "3427260"
  },
  {
    "text": "might seem like some complicated math is happening here but all we're really doing is we're just applying that mean",
    "start": "3427260",
    "end": "3432390"
  },
  {
    "text": "image that that recolor izing that we needed to do to the image and we're transforming it to the size that we want",
    "start": "3432390",
    "end": "3438680"
  },
  {
    "text": "and then in order to call the prediction all we have to do is take that Network",
    "start": "3438680",
    "end": "3444840"
  },
  {
    "text": "and forward propagate that batch that batch of one image we just have to say",
    "start": "3444840",
    "end": "3450600"
  },
  {
    "text": "it hey give us the output now that output is going to give us 15,000",
    "start": "3450600",
    "end": "3456420"
  },
  {
    "text": "different answers or 15,000 527 different answers and all we want to do is you want to sort by the probability",
    "start": "3456420",
    "end": "3463470"
  },
  {
    "text": "of each of those answers because we're basically taking the entire end layer of the network and we're saying hey what",
    "start": "3463470",
    "end": "3468990"
  },
  {
    "text": "are the results so we only really care about the max predictions which I think",
    "start": "3468990",
    "end": "3474260"
  },
  {
    "text": "in this case I set to 20 or three or something so we want the first three",
    "start": "3474260",
    "end": "3479330"
  },
  {
    "text": "predictions organized by probability we want to return those results and then we do a little bit of stuff with enriching",
    "start": "3479330",
    "end": "3486920"
  },
  {
    "text": "the data putting emojis on it and all that good stuff so if you want to see an example of this",
    "start": "3486920",
    "end": "3492320"
  },
  {
    "text": "you just sort of hop over to twitter.com slash where ml and you will see it",
    "start": "3492320",
    "end": "3501530"
  },
  {
    "text": "oops sorry those twitch sorry twitter.com slash where ml and it's the",
    "start": "3501530",
    "end": "3507350"
  },
  {
    "text": "end of my presentation because you're gonna hear from one of my colleagues next and what happens here is someone",
    "start": "3507350",
    "end": "3516350"
  },
  {
    "text": "posts something so someone posts an image like this and it'll tell you where",
    "start": "3516350",
    "end": "3522530"
  },
  {
    "text": "in the world it is so why is it posting the same one again this is a picture of",
    "start": "3522530",
    "end": "3531350"
  },
  {
    "text": "Vancouver British Columbia so it's showing Vancouver and we put emojis in there just to keep the Millennials happy",
    "start": "3531350",
    "end": "3540730"
  },
  {
    "text": "so someone posts a picture of this castle and it just figures it's in",
    "start": "3540910",
    "end": "3547730"
  },
  {
    "text": "Nuremberg so that is how the bot works I know that we didn't cover all the",
    "start": "3547730",
    "end": "3553940"
  },
  {
    "text": "various components and depth I will post all of the relevant content into this",
    "start": "3553940",
    "end": "3560030"
  },
  {
    "text": "but next you're gonna hear from a colleague of mine called cabe and he's going to walk through app sync and some",
    "start": "3560030",
    "end": "3566540"
  },
  {
    "text": "of the other cool stuff that people are building on top of it so thank you all for joining I'll be around a little bit",
    "start": "3566540",
    "end": "3573080"
  },
  {
    "text": "later today as well I hope you enjoyed this presentation and I will see you",
    "start": "3573080",
    "end": "3578840"
  },
  {
    "text": "next time",
    "start": "3578840",
    "end": "3581620"
  }
]
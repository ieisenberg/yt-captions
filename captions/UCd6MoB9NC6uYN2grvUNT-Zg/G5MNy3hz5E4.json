[
  {
    "text": "good afternoon how are you guys doing having a good time at at the summit yeah",
    "start": "1399",
    "end": "8730"
  },
  {
    "text": "all right good thanks for coming I appreciate it my name is Michael Shaw and I'm the general",
    "start": "8730",
    "end": "14610"
  },
  {
    "text": "manager for AWS glue and a new service AWS lake formation today I'll be talking",
    "start": "14610",
    "end": "23369"
  },
  {
    "text": "about how you can build data lakes in a few days using lake formation and in fact at the",
    "start": "23369",
    "end": "28859"
  },
  {
    "text": "end of this talk you'll know how to use lake formation to create a data Lake because we'll try to get it done within",
    "start": "28859",
    "end": "34469"
  },
  {
    "text": "a matter of a few minutes we'll be giving you a demo and I have with me our",
    "start": "34469",
    "end": "39680"
  },
  {
    "text": "customer partner and friend Sreenivas revelry said 'i know how to pronounce",
    "start": "39680",
    "end": "46350"
  },
  {
    "text": "his name and he's from Alcon and he's the head of IT analytics at Alcon and",
    "start": "46350",
    "end": "53640"
  },
  {
    "text": "he'll be giving you his story on how they built their data Lake on AWS",
    "start": "53640",
    "end": "60589"
  },
  {
    "text": "alright before we get started I want to take a few minutes to talk about the trends that are driving this change into",
    "start": "61219",
    "end": "67920"
  },
  {
    "text": "building data lakes give you a few insights into what day lakes really are",
    "start": "67920",
    "end": "73400"
  },
  {
    "text": "why they're hard today to build and then finally show you that you can build a",
    "start": "73400",
    "end": "79740"
  },
  {
    "text": "data Lake in Amazon on AWS very easily using lake formation we're gonna",
    "start": "79740",
    "end": "85320"
  },
  {
    "text": "actually do it live and with me I have our lead PM chunnu who's gonna be running the demo all right so let's get",
    "start": "85320",
    "end": "93509"
  },
  {
    "text": "into it if you looked in the 90s and early 2000s most enterprises were",
    "start": "93509",
    "end": "99450"
  },
  {
    "text": "building large data warehouses it was sort of the information hub around which",
    "start": "99450",
    "end": "105049"
  },
  {
    "text": "decision-making in an enterprise is to revolve around ok these were structured",
    "start": "105049",
    "end": "111329"
  },
  {
    "text": "warehouses of data so emotionally you know columns rows and tables very flat",
    "start": "111329",
    "end": "117299"
  },
  {
    "text": "and all of this data is coming in from your operational databases in your organization again other relational",
    "start": "117299",
    "end": "123540"
  },
  {
    "text": "systems or structured systems and it goes through an ETL process where you combined aggregate clean that data and",
    "start": "123540",
    "end": "132209"
  },
  {
    "text": "then put it into the data warehouse and the ETL process is very centralized and",
    "start": "132209",
    "end": "137760"
  },
  {
    "text": "then finally when all that information gets there and often took months if not years to set this stuff up then you",
    "start": "137760",
    "end": "144180"
  },
  {
    "text": "could use BI tools and reporting tools to get insights from that data to then run your business and optimize your",
    "start": "144180",
    "end": "150180"
  },
  {
    "text": "business well that's no longer the case these data warehouses are still useful",
    "start": "150180",
    "end": "156660"
  },
  {
    "text": "but they're no longer the central hub for organizations there's a couple of reasons for that",
    "start": "156660",
    "end": "162120"
  },
  {
    "text": "one big reason is that the data that enterprises want to manage no longer",
    "start": "162120",
    "end": "168090"
  },
  {
    "text": "really fit in these data warehouses there's a lot more data and it's just",
    "start": "168090",
    "end": "173519"
  },
  {
    "text": "not cost-effective to scale these data warehouses for that data and the data is",
    "start": "173519",
    "end": "178980"
  },
  {
    "text": "much more diverse so now you must know that in your organization you probably",
    "start": "178980",
    "end": "184230"
  },
  {
    "text": "have applications that are generating logs you want to do analysis over those logs you have customers that are looking",
    "start": "184230",
    "end": "191340"
  },
  {
    "text": "at social networking feeds they're looking at web clicks or you know mobile",
    "start": "191340",
    "end": "199340"
  },
  {
    "text": "events from your phones or from their customer base all these things are generating unstructured or semi",
    "start": "199340",
    "end": "206310"
  },
  {
    "text": "structured data sets that are constantly evolving and changing and putting that stuff into a data warehouse is also hard",
    "start": "206310",
    "end": "213060"
  },
  {
    "text": "to manage across our customer base when we're looking at our customers what we find on average is that their data sets",
    "start": "213060",
    "end": "220260"
  },
  {
    "text": "are growing by an order of magnitude 10x every five years and typically when",
    "start": "220260",
    "end": "226019"
  },
  {
    "text": "you're trying to put out a data platform that your organization is going to you know leverage and what an you want you",
    "start": "226019",
    "end": "231750"
  },
  {
    "text": "don't want to do it every year you kind of want to have it last for a decade or decade and a half and so what that means",
    "start": "231750",
    "end": "237180"
  },
  {
    "text": "is during the lifetime of that platform it's gonna have to scale from terabytes to petabytes these days petabytes are",
    "start": "237180",
    "end": "245189"
  },
  {
    "text": "almost you know you know par for the course and we're gonna need platforms that scale from petabytes to exabytes",
    "start": "245189",
    "end": "253640"
  },
  {
    "text": "the other thing that's happening is that you have more people that are accessing the data more different types of",
    "start": "253640",
    "end": "260070"
  },
  {
    "text": "personas we're not just looking at business analysts anymore we have data scientists people building",
    "start": "260070",
    "end": "266050"
  },
  {
    "text": "applications over real-time streaming data scientific science users engineers",
    "start": "266050",
    "end": "273700"
  },
  {
    "text": "IT admins and so on and so forth and they want to analyze the data in",
    "start": "273700",
    "end": "278740"
  },
  {
    "text": "different ways right again we're not just doing sequel based analytics anymore people want to they analyze the",
    "start": "278740",
    "end": "284320"
  },
  {
    "text": "data to do machine learning they want to do scientific and analyses they want to",
    "start": "284320",
    "end": "290650"
  },
  {
    "text": "do you know short quick analyses over real-time streaming data to get very quick results so there's all kinds of",
    "start": "290650",
    "end": "297370"
  },
  {
    "text": "things that people want to do that aren't just really amenable to what you would do in a data warehouse and then",
    "start": "297370",
    "end": "303010"
  },
  {
    "text": "finally there are just a lot more rules around who can access data and when there are regulatory requirements gdpr",
    "start": "303010",
    "end": "310840"
  },
  {
    "text": "I'm sure everybody has run into one of these things before there are requirements and and governance policies",
    "start": "310840",
    "end": "317169"
  },
  {
    "text": "across your organization depending on what level you're at and you know what department that you're in the good news",
    "start": "317169",
    "end": "325090"
  },
  {
    "text": "is we have the cloud the AWS cloud and it's been a game changer one of the things that you get is you",
    "start": "325090",
    "end": "330940"
  },
  {
    "text": "get to choose which type of analytics engine you want to use on your data it's not just one it's not just a sequel data",
    "start": "330940",
    "end": "337870"
  },
  {
    "text": "warehouse you can pick a data warehouse like redshift still very useful or you can pick Amazon sage maker to do machine",
    "start": "337870",
    "end": "344620"
  },
  {
    "text": "learning or you can use EMR for doing big data analysis quick cite Athena for",
    "start": "344620",
    "end": "350320"
  },
  {
    "text": "just doing ad hoc analytics and all of this stuff is available on demand and pay-as-you-go the other cool thing about",
    "start": "350320",
    "end": "358450"
  },
  {
    "text": "the cloud is Amazon s3 it's amazing what you can do with this thing it's in a you",
    "start": "358450",
    "end": "363760"
  },
  {
    "text": "biggest store that gives you 11 nines of durability what this means is you can",
    "start": "363760",
    "end": "369850"
  },
  {
    "text": "actually finally centralize all of your data sets whether they're on-premise batch data sets or data sets coming in",
    "start": "369850",
    "end": "376870"
  },
  {
    "text": "real time streaming in from IOT devices your applications video streams whatever",
    "start": "376870",
    "end": "382360"
  },
  {
    "text": "you have you can put all of that stuff into Amazon s3 and now what you need is",
    "start": "382360",
    "end": "388960"
  },
  {
    "text": "an efficient mechanism for organizing this information for securing this information",
    "start": "388960",
    "end": "394650"
  },
  {
    "text": "and efficiently multiplexing this information across all the services that you're going to use to analyze that data",
    "start": "394650",
    "end": "401190"
  },
  {
    "text": "and this is what a data Lake is right it's a centralized repository that",
    "start": "401190",
    "end": "408240"
  },
  {
    "text": "enables you to secure discover share analyze structured and unstructured data",
    "start": "408240",
    "end": "415650"
  },
  {
    "text": "at any scale a lot of people talk about data lakes as a way of democratizing",
    "start": "415650",
    "end": "421229"
  },
  {
    "text": "data across your organization there's no single bottleneck now like an ETL process or an admin that has to give you",
    "start": "421229",
    "end": "428280"
  },
  {
    "text": "access and when that breaks you know everybody is down now it's really spread",
    "start": "428280",
    "end": "433620"
  },
  {
    "text": "across the organization and people can pick it up as they need pick up the datasets that they want as they need we",
    "start": "433620",
    "end": "442350"
  },
  {
    "text": "have on AWS more customers building more data Lakes and doing analytics than",
    "start": "442350",
    "end": "447660"
  },
  {
    "text": "anywhere else I believe the the the running number is",
    "start": "447660",
    "end": "453389"
  },
  {
    "text": "like ten thousand or more data lakes on AWS today and this is just a smattering",
    "start": "453389",
    "end": "458490"
  },
  {
    "text": "of some of the customers but we have thousands of customers doing this but",
    "start": "458490",
    "end": "463830"
  },
  {
    "text": "even still with all the services that we have building data snakes still can take",
    "start": "463830",
    "end": "469080"
  },
  {
    "text": "months why is that well let's take a look at the typical steps in building a",
    "start": "469080",
    "end": "474810"
  },
  {
    "text": "day Lake okay there's actually three different steps and those three different steps are",
    "start": "474810",
    "end": "480199"
  },
  {
    "text": "handled by three different types of users or three different personas the",
    "start": "480199",
    "end": "485370"
  },
  {
    "text": "one that you've probably heard about over and over again is the process of ingesting and cleaning your data to get",
    "start": "485370",
    "end": "490500"
  },
  {
    "text": "into a data Lake everybody has to do it whether you're doing just simple analytics in a data warehouse or whether",
    "start": "490500",
    "end": "495539"
  },
  {
    "text": "you're doing it in a de lake the first thing that you have to do is you have to set up landing areas in particular if",
    "start": "495539",
    "end": "500760"
  },
  {
    "text": "you're gonna do it on s3 buckets right where you're gonna put your raw data and",
    "start": "500760",
    "end": "505830"
  },
  {
    "text": "other areas where you might put processed data and then optimize data for analytics the next thing you have to",
    "start": "505830",
    "end": "512520"
  },
  {
    "text": "do is you have to go identify all of your sources whether they be structured databases no sequel databases logs",
    "start": "512520",
    "end": "518909"
  },
  {
    "text": "sitting in s3 or in streaming systems like Kafka and Kinesis and so on and",
    "start": "518909",
    "end": "525329"
  },
  {
    "text": "then you got to get that data out moved into data Lake into your landing areas and",
    "start": "525329",
    "end": "530610"
  },
  {
    "text": "then after you've got them into your landing areas that's when you actually do the heavy work of cleaning combining",
    "start": "530610",
    "end": "538160"
  },
  {
    "text": "cataloging and prepping your data so that it's optimized for doing analytics",
    "start": "538160",
    "end": "544370"
  },
  {
    "text": "typically this is done by a data engineer in your system and they have access to various systems sort of they",
    "start": "544370",
    "end": "553320"
  },
  {
    "text": "have access to various systems across your enterprise the next step is to",
    "start": "553320",
    "end": "558960"
  },
  {
    "text": "actually secure your data and configure and enforce of these various security and compliance policies that you have",
    "start": "558960",
    "end": "565350"
  },
  {
    "text": "your in your organization this is also difficult today and typically it's done",
    "start": "565350",
    "end": "571500"
  },
  {
    "text": "by a data security officer and then finally you're gonna make this data",
    "start": "571500",
    "end": "576840"
  },
  {
    "text": "available to a variety of different types of end-users I've labeled this person as a as a data analyst but the",
    "start": "576840",
    "end": "583920"
  },
  {
    "text": "data analyst may have different access controls depending on what they do as I",
    "start": "583920",
    "end": "590310"
  },
  {
    "text": "mentioned before data preparation is expensive here's a survey that was done by CrowdFlower CrowdFlower",
    "start": "590310",
    "end": "595650"
  },
  {
    "text": "where they looked at the time that it takes to prepare data for analytics and what you see is about 80% of the work is",
    "start": "595650",
    "end": "602100"
  },
  {
    "text": "going into just basically cleaning the data okay cleaning and sort of refining the data",
    "start": "602100",
    "end": "607580"
  },
  {
    "text": "what they didn't look at is the amount of work it takes because they weren't looking at this in the setting of a data",
    "start": "607580",
    "end": "613560"
  },
  {
    "text": "Lake the amount of work it takes to actually organize the data and secure it so let's take a look at what that looks",
    "start": "613560",
    "end": "620490"
  },
  {
    "text": "like on AWS today first thing you have",
    "start": "620490",
    "end": "625620"
  },
  {
    "text": "to do is find all the data sources that you that you want to this is for setting up a data Lake you have to find all your",
    "start": "625620",
    "end": "631440"
  },
  {
    "text": "data sources in this case what we're seeing are the Amazon RDS databases that this is that this account has then you",
    "start": "631440",
    "end": "640140"
  },
  {
    "text": "got to set up your landing areas in s3 and then you get a set of policies on",
    "start": "640140",
    "end": "645990"
  },
  {
    "text": "who gets to access what on s3 and in fact which you'll see is you'll have to set up these policies in different",
    "start": "645990",
    "end": "652740"
  },
  {
    "text": "places for the same set of users in different ways and this can get very complicated over here is a policy that",
    "start": "652740",
    "end": "658470"
  },
  {
    "text": "tells you what API access is and what individual object or what individual buckets that people",
    "start": "658470",
    "end": "664279"
  },
  {
    "text": "can access and these policies have limits on them on how big they can get",
    "start": "664279",
    "end": "669430"
  },
  {
    "text": "you got to then map your individual objects into collections called let's call them tables and create a",
    "start": "669430",
    "end": "676310"
  },
  {
    "text": "schema around them and then you're gonna have to bring the data in you're gonna",
    "start": "676310",
    "end": "682160"
  },
  {
    "text": "use some ETL tool to do that in this particular case we have AWS glue and even in glue you're gonna need a",
    "start": "682160",
    "end": "687980"
  },
  {
    "text": "developer that actually helped you know looks at a script and gets it running this is a Python script or sorry a PI",
    "start": "687980",
    "end": "694220"
  },
  {
    "text": "spark script that gets it running to convert your data and load it in into your data Lake you're not done yet",
    "start": "694220",
    "end": "701959"
  },
  {
    "text": "you've catalogued your data but then you're gonna need to be able to secure the metadata as well around the data the",
    "start": "701959",
    "end": "708170"
  },
  {
    "text": "table definitions the schema and so on and again these things are JSON policies",
    "start": "708170",
    "end": "714110"
  },
  {
    "text": "that you express in the I am language just wait one more thing you have to now",
    "start": "714110",
    "end": "720230"
  },
  {
    "text": "go to the various services that you're gonna use to analyze that data this is a you know a piece equal prompt that's",
    "start": "720230",
    "end": "725899"
  },
  {
    "text": "connected to a redshift instance you got to set up database users rolls and then make sure those rolls have access to the",
    "start": "725899",
    "end": "732410"
  },
  {
    "text": "various metadata and data sets sitting in s3 and then you get to do it again",
    "start": "732410",
    "end": "738920"
  },
  {
    "text": "and again and again for every data set for every user as they come and go as",
    "start": "738920",
    "end": "744800"
  },
  {
    "text": "their permissions change and for every other service that's out there like Athena or EMR or quick site and so on",
    "start": "744800",
    "end": "752540"
  },
  {
    "text": "and as you can imagine this gets harder and harder as you have more and more users as the kind of policies that you",
    "start": "752540",
    "end": "759080"
  },
  {
    "text": "want to implement change and it's quite manual and trying to make sure that all of these things align sometimes can be",
    "start": "759080",
    "end": "766010"
  },
  {
    "text": "extremely difficult in some cases you can't actually get what you want and you end up giving more access than you want",
    "start": "766010",
    "end": "772490"
  },
  {
    "text": "or restricting people from getting access to data that they need alright",
    "start": "772490",
    "end": "779360"
  },
  {
    "text": "well let's show you what you can do with lake formation which basically simplifies all of these steps and you can actually do it all in a single place",
    "start": "779360",
    "end": "785990"
  },
  {
    "text": "so we're gonna go and actually do a demo here but before we get to the demo let me give you the three main value",
    "start": "785990",
    "end": "792470"
  },
  {
    "text": "proposition Lake of lake formation the first thing is that it simplifies data preparation it",
    "start": "792470",
    "end": "798670"
  },
  {
    "text": "allows you to easily ingest data and get it prepared for analytics and we do that",
    "start": "798670",
    "end": "803740"
  },
  {
    "text": "with a feature called blueprints and we'll show you that today the second and",
    "start": "803740",
    "end": "808810"
  },
  {
    "text": "main thing that it does is it allows you to secure your data in a single place in lake formation and all of these various",
    "start": "808810",
    "end": "816130"
  },
  {
    "text": "services redshift and Athena and EMR can",
    "start": "816130",
    "end": "821560"
  },
  {
    "text": "will enforce those security policies so you don't have to configure it it everywhere else in different ways and",
    "start": "821560",
    "end": "827860"
  },
  {
    "text": "then you can multiplex this data across all of these engines and the third main",
    "start": "827860",
    "end": "833380"
  },
  {
    "text": "set of features that we provided is the ability to annotate your data sets and",
    "start": "833380",
    "end": "839680"
  },
  {
    "text": "then search over those data sets so that you can discover share and collaborate",
    "start": "839680",
    "end": "844960"
  },
  {
    "text": "across your organization all right so",
    "start": "844960",
    "end": "850930"
  },
  {
    "text": "let's go over to the demo the first thing that I want to show you is how you can actually ingest the data inside of",
    "start": "850930",
    "end": "856330"
  },
  {
    "text": "your data Lake so let's and clean it and so let's set it up on an actual account",
    "start": "856330",
    "end": "863620"
  },
  {
    "text": "that we have in AWS that we've prepared for you the first thing we're going to do is we're going to go and register a",
    "start": "863620",
    "end": "871089"
  },
  {
    "text": "location and s3 as something that's going to be managed by lake formation so chuny over here has",
    "start": "871089",
    "end": "878709"
  },
  {
    "text": "picked a particular bucket and that bucket is going to is going to be",
    "start": "878709",
    "end": "884470"
  },
  {
    "text": "managed by lake formation as part of a data Lake what he what we have what he",
    "start": "884470",
    "end": "890050"
  },
  {
    "text": "just showed you is all of the all of the users that are currently in the system when you hit location all the users that",
    "start": "890050",
    "end": "895990"
  },
  {
    "text": "might have access to that location in this particular case there's no such users so he closes that and then he's",
    "start": "895990",
    "end": "901750"
  },
  {
    "text": "providing a role this role has the ability that you're passing to Lake",
    "start": "901750",
    "end": "907089"
  },
  {
    "text": "formation so you're giving Lake formation permissions the ability to carve up this location and vend pieces",
    "start": "907089",
    "end": "913900"
  },
  {
    "text": "of that location to various engines so you need some set of permissions that you're going to pass and so that's what",
    "start": "913900",
    "end": "919600"
  },
  {
    "text": "he's done here go ahead and hit register location all right great there you go the the location has been",
    "start": "919600",
    "end": "926560"
  },
  {
    "text": "registered and that's going to be the landing area for the data that we're gonna bring in and in this demo what we're gonna do is",
    "start": "926560",
    "end": "932050"
  },
  {
    "text": "we're gonna bring in cloud trail data it's normally in JSON we're gonna bring it in we're gonna convert it into park'",
    "start": "932050",
    "end": "938110"
  },
  {
    "text": "and then we're gonna allow various types of users to see different parts of that cloud trail stream cloud trail basically",
    "start": "938110",
    "end": "945130"
  },
  {
    "text": "logs all of the API accesses that your account has been has done or hit across",
    "start": "945130",
    "end": "950890"
  },
  {
    "text": "AWS in a single place all right so now that you've added those locations what",
    "start": "950890",
    "end": "958750"
  },
  {
    "text": "we need to do is you need to you need to give a principal an IM user or an IM",
    "start": "958750",
    "end": "963880"
  },
  {
    "text": "role the ability to store stuff into that location so we're gonna do that with a very simple grant and revoked",
    "start": "963880",
    "end": "969580"
  },
  {
    "text": "style pattern you see this in databases all the time same thing the role that",
    "start": "969580",
    "end": "974890"
  },
  {
    "text": "he's gonna give access to is a workflow role it's actually gonna do the work of ingesting and the location that that",
    "start": "974890",
    "end": "981130"
  },
  {
    "text": "role has access to is the bucket that he has already chosen to register in the system these are different things he",
    "start": "981130",
    "end": "987340"
  },
  {
    "text": "registered the DOE location into lake formation so the lake formation is managing that area and he's telling lake",
    "start": "987340",
    "end": "993160"
  },
  {
    "text": "formation allow this particular role to use and read and write to that location",
    "start": "993160",
    "end": "999220"
  },
  {
    "text": "okay so go ahead and grant okay great so now you have that role and it's already",
    "start": "999220",
    "end": "1004260"
  },
  {
    "text": "been granted notice there's no JSON policies all you're doing is looking at the individual objects and granting",
    "start": "1004260",
    "end": "1010230"
  },
  {
    "text": "users those permissions the next things he's going to do is he's gonna create a database okay now this is an important",
    "start": "1010230",
    "end": "1017490"
  },
  {
    "text": "distinction that we've made in lake formation and in AWS which is there's this decoupling that's happening between",
    "start": "1017490",
    "end": "1023160"
  },
  {
    "text": "the storage and the metadata so the database is the metadata it's all the information about the store the objects",
    "start": "1023160",
    "end": "1030000"
  },
  {
    "text": "that you have the storage is s3 all right and so what he's doing is he's",
    "start": "1030000",
    "end": "1035010"
  },
  {
    "text": "creating a database that's gonna point to that location you see this in other systems as well and then after he's created the database",
    "start": "1035010",
    "end": "1042870"
  },
  {
    "text": "all he's done is pointed to that location go ahead and create the database he's gonna grant that workflow",
    "start": "1042870",
    "end": "1050070"
  },
  {
    "text": "role",
    "start": "1050070",
    "end": "1052519"
  },
  {
    "text": "the ability to create tables in that database so now that role is going to be",
    "start": "1056159",
    "end": "1061510"
  },
  {
    "text": "able to write into that location and then create tables so that you can create that table it's going to be the",
    "start": "1061510",
    "end": "1067690"
  },
  {
    "text": "cloud trail table and what he's given is a bunch of accesses if you go back to that real quick just click on grant he's",
    "start": "1067690",
    "end": "1076270"
  },
  {
    "text": "basically give given a bunch of accesses that look like sequel based accesses you",
    "start": "1076270",
    "end": "1081340"
  },
  {
    "text": "can do select you can do drop you can do alter you can create tables so again",
    "start": "1081340",
    "end": "1087850"
  },
  {
    "text": "it's not an API based map model it's a model based on the actions that you would do at a at a at a larger",
    "start": "1087850",
    "end": "1094840"
  },
  {
    "text": "granularity across your data lake okay you can cancel that because we already done that okay great perfect so now what",
    "start": "1094840",
    "end": "1102640"
  },
  {
    "text": "we're gonna do is we're gonna go and actually use a blueprint what is a blueprint go ahead and click on it",
    "start": "1102640",
    "end": "1107740"
  },
  {
    "text": "a blueprint so we have a list of workflows in here a blueprint is",
    "start": "1107740",
    "end": "1113080"
  },
  {
    "text": "basically a template we've got a bunch of prepackaged templates already ready for you we've got one for cloud trail",
    "start": "1113080",
    "end": "1119140"
  },
  {
    "text": "we've got some for getting tables from RDS various databases we've got one for",
    "start": "1119140",
    "end": "1124360"
  },
  {
    "text": "you know ELB and alb logs and he's gonna you know click on the cloud trail",
    "start": "1124360",
    "end": "1129960"
  },
  {
    "text": "blueprint colossal blueprint allows you to pick a cloud trail trail a trail is",
    "start": "1129960",
    "end": "1136929"
  },
  {
    "text": "basically a sequence of API actions and then he's gonna pick the cloud trail records or files to go over for the",
    "start": "1136929",
    "end": "1145299"
  },
  {
    "text": "particular day today is July 11th that's when the talk is and then he's gonna",
    "start": "1145299",
    "end": "1151390"
  },
  {
    "text": "tell the system that tell the blueprint where what database to put this data into what location to put it into what",
    "start": "1151390",
    "end": "1157149"
  },
  {
    "text": "format let's see what other formats are available I think we have Pirkei and CSV let's pick Parque because that's",
    "start": "1157149",
    "end": "1162700"
  },
  {
    "text": "optimized for analytics import frequency basically tells you whether you want to do it one time run on-demand or you can",
    "start": "1162700",
    "end": "1170409"
  },
  {
    "text": "actually do it incrementally so you can actually keep running this over and over again okay and then finally he's gonna",
    "start": "1170409",
    "end": "1178210"
  },
  {
    "text": "create a workflow so what is a workflow it's basically a schedule that includes",
    "start": "1178210",
    "end": "1184360"
  },
  {
    "text": "all the things that you need to do to be able to get the data into the system now this is going to be",
    "start": "1184360",
    "end": "1189760"
  },
  {
    "text": "stamped out by the blue friend so the blueprints create workflows these workflows are actually in AWS Gloup",
    "start": "1189760",
    "end": "1196360"
  },
  {
    "text": "Gloup is the underlying platform on top of which lake formation is built so what",
    "start": "1196360",
    "end": "1203770"
  },
  {
    "text": "he did was he created a workflow the workflow has to have some permissions and that's why he gave that workflow the",
    "start": "1203770",
    "end": "1210610"
  },
  {
    "text": "permissions from that workflow role and in the behind the scenes the workflow is",
    "start": "1210610",
    "end": "1216370"
  },
  {
    "text": "being created inside of glue ok give it a cut a couple of seconds the workflow is going to show up cross your fingers",
    "start": "1216370",
    "end": "1222970"
  },
  {
    "text": "it's a real demo so make sure it shows up there you go",
    "start": "1222970",
    "end": "1229120"
  },
  {
    "text": "there's the workflow you can see that there's a new workflow at the top of that list AWS summit demo",
    "start": "1229120",
    "end": "1235870"
  },
  {
    "text": "and it hasn't started so he's gonna start it now great now it started it's",
    "start": "1235870",
    "end": "1243550"
  },
  {
    "text": "running you can see the last status so you can see the aggregate status of that workflow like you know discovering your",
    "start": "1243550",
    "end": "1250510"
  },
  {
    "text": "data or importing your data the other thing you can do is you can actually look at the underlying graph that that",
    "start": "1250510",
    "end": "1257140"
  },
  {
    "text": "workflow is composed of right and so now he's actually moved into AWS glue he's",
    "start": "1257140",
    "end": "1264280"
  },
  {
    "text": "gonna go and take a look at that what that workflow looks like you want to scroll up a little bit and there it is",
    "start": "1264280",
    "end": "1270610"
  },
  {
    "text": "so you can see all the various actions that this workflow is doing you don't have to go here I'm just trying to open",
    "start": "1270610",
    "end": "1276640"
  },
  {
    "text": "up the kimono a little bit and show you what's going on under the covers and you can do it as well it's basically a",
    "start": "1276640",
    "end": "1281950"
  },
  {
    "text": "sequence of actions you're triggering various crawlers crawlers were going in",
    "start": "1281950",
    "end": "1287800"
  },
  {
    "text": "and I can tell you a little bit about them in a second on discovering the datasets and their structure and then we",
    "start": "1287800",
    "end": "1293590"
  },
  {
    "text": "automatically spin up ETL processes we know exactly how much you know how much",
    "start": "1293590",
    "end": "1299260"
  },
  {
    "text": "resources to use to be able to convert that data we then you know run those processes and then you know create those",
    "start": "1299260",
    "end": "1305590"
  },
  {
    "text": "tables on your behalf in your lake all behind the scenes for you what you're",
    "start": "1305590",
    "end": "1310600"
  },
  {
    "text": "seeing over here and the green is basically what's been finished and the",
    "start": "1310600",
    "end": "1315690"
  },
  {
    "text": "the gray is basically all the stuff that remains okay let's go back to lake formation okay so while this is running",
    "start": "1315690",
    "end": "1324540"
  },
  {
    "text": "let's talk a little bit more about lake formation go ahead you can see this",
    "start": "1324540",
    "end": "1329700"
  },
  {
    "text": "status has changed to discovering okay so that was the demo and in case that",
    "start": "1329700",
    "end": "1334770"
  },
  {
    "text": "didn't work we have backup slides so I'm just gonna come right through it we all",
    "start": "1334770",
    "end": "1340980"
  },
  {
    "text": "prepared for this so we talked about blueprints the cool thing is that you can do this you know at one time or",
    "start": "1340980",
    "end": "1347580"
  },
  {
    "text": "incremental so these workflows can be run over and over again this is this is",
    "start": "1347580",
    "end": "1355200"
  },
  {
    "text": "sort of an architectural diagram I should say a layering diagram for lake formation the blueprints mechanism is",
    "start": "1355200",
    "end": "1362970"
  },
  {
    "text": "built on top of glue workflows which are composed of ETL jobs and crawlers I'll tell you a little bit more about what",
    "start": "1362970",
    "end": "1368670"
  },
  {
    "text": "those things are and then all of the security mechanisms are actually built on top of the glue",
    "start": "1368670",
    "end": "1374250"
  },
  {
    "text": "data catalog and the data catalog is composed of databases and tables and columns and",
    "start": "1374250",
    "end": "1380100"
  },
  {
    "text": "that's going to come in handy in a second so let's took a look at some of the glue components just so that you",
    "start": "1380100",
    "end": "1387000"
  },
  {
    "text": "have an understanding of what's going on underneath the data catalog that glue has by the way is the one in the same",
    "start": "1387000",
    "end": "1392730"
  },
  {
    "text": "what did Lake formation catalog they hold the same state okay long it's a",
    "start": "1392730",
    "end": "1398400"
  },
  {
    "text": "metadata repository it stores the information about databases and tables its hive Metascore compatible so it",
    "start": "1398400",
    "end": "1404520"
  },
  {
    "text": "integrates with all these various services and it comes with crawlers which automatically discover the",
    "start": "1404520",
    "end": "1410550"
  },
  {
    "text": "structure and layout of your data sets we also have a serverless engine that",
    "start": "1410550",
    "end": "1415620"
  },
  {
    "text": "runs PI spark or Scala spark scripts you",
    "start": "1415620",
    "end": "1421740"
  },
  {
    "text": "can also give it just Python scripts and we'll just run not a cluster but a",
    "start": "1421740",
    "end": "1426870"
  },
  {
    "text": "single machine for you and you can do this interactively under bash fashion and then finally we have a workflow",
    "start": "1426870",
    "end": "1433170"
  },
  {
    "text": "system as orchestration system that allows you to you know create flexible schedules for running various jobs in a",
    "start": "1433170",
    "end": "1441300"
  },
  {
    "text": "in a complex fashion and we have inner integrations with external services",
    "start": "1441300",
    "end": "1447070"
  },
  {
    "text": "here's what the data catalogue looks like when it's done okay I'm not gonna go into this and the demo but here's an",
    "start": "1447070",
    "end": "1453010"
  },
  {
    "text": "example where we actually ran a crawl over github data this is the github",
    "start": "1453010",
    "end": "1460210"
  },
  {
    "text": "timeline and you know no matter how complicated data set is in this particular case the gate up timeline is",
    "start": "1460210",
    "end": "1467200"
  },
  {
    "text": "composed of lots of different event types and when you create a schema for it you end up with more than 300 350",
    "start": "1467200",
    "end": "1473080"
  },
  {
    "text": "columns no matter the crawler can figure all this stuff out it picks up the main columns and the",
    "start": "1473080",
    "end": "1479380"
  },
  {
    "text": "schema and then you can double click into the different structures and see what those structures look like what's",
    "start": "1479380",
    "end": "1485200"
  },
  {
    "text": "more important here is it also automatically figures out how this stuff is laid out on s3 in terms of partitions",
    "start": "1485200",
    "end": "1490960"
  },
  {
    "text": "so your engines can very quickly narrow in on the data sets and the pieces of the data set that they want to they want",
    "start": "1490960",
    "end": "1497350"
  },
  {
    "text": "to query it also gives you gives you some amount of profiling information about how big your records are how many",
    "start": "1497350",
    "end": "1503710"
  },
  {
    "text": "records you have from the sample that occurred that it's taking we've taken",
    "start": "1503710",
    "end": "1510610"
  },
  {
    "text": "the catalog and we've enhanced it in lake formation to make it more of a business data catalog so what you can do",
    "start": "1510610",
    "end": "1517360"
  },
  {
    "text": "now is search across your catalog using keywords and this search worker current",
    "start": "1517360",
    "end": "1523480"
  },
  {
    "text": "works across all metadata including attributes that you specify on tables",
    "start": "1523480",
    "end": "1529330"
  },
  {
    "text": "and on columns so you can actually specify key value attributes per table",
    "start": "1529330",
    "end": "1535300"
  },
  {
    "text": "and per column in that table and you can search over all of these things so it's very useful for putting business context",
    "start": "1535300",
    "end": "1541990"
  },
  {
    "text": "in there for example you might want to record who the owners or the stewards of that data are or where that data",
    "start": "1541990",
    "end": "1547960"
  },
  {
    "text": "originated from or where that column originated from or what that column means you might also even want to store",
    "start": "1547960",
    "end": "1553960"
  },
  {
    "text": "information like the data sensitivity level for that data is it PII data is it",
    "start": "1553960",
    "end": "1559480"
  },
  {
    "text": "only meant for executives is it meant for admins is it meant for every user and so on and then of course you can",
    "start": "1559480",
    "end": "1566230"
  },
  {
    "text": "query all this data yet search through all this data to find out which data sets are relevant to you so it really",
    "start": "1566230",
    "end": "1572890"
  },
  {
    "text": "helps to make it easier to collaborate another cool thing that we've done is as",
    "start": "1572890",
    "end": "1579520"
  },
  {
    "text": "part of the lake formation offering is providing machine learning transforms for data integration in",
    "start": "1579520",
    "end": "1585220"
  },
  {
    "text": "particular it's for finding doing fuzzy matching or fuzzy deduplication between",
    "start": "1585220",
    "end": "1592559"
  },
  {
    "text": "between datasets so imagine for example you have a catalog of products and the",
    "start": "1592559",
    "end": "1599440"
  },
  {
    "text": "products are not labeled exactly the same way how do you how do you find the ones that are exactly you know similar",
    "start": "1599440",
    "end": "1604809"
  },
  {
    "text": "or should be the same it's kind of a hard problem programmatically you know you're gonna end up by writing a bunch",
    "start": "1604809",
    "end": "1610809"
  },
  {
    "text": "of rules and those rules may or may not work what you really need is something that looks like a human looks at it and",
    "start": "1610809",
    "end": "1616600"
  },
  {
    "text": "says I think these things are the same and that's what machine learning transforms and do for you these",
    "start": "1616600",
    "end": "1621700"
  },
  {
    "text": "deduplication transforms do for you so an example here is a shoe that's built",
    "start": "1621700",
    "end": "1627400"
  },
  {
    "text": "by sari made by Trask and it's labeled on the left hand side I know it's hard to read it's labeled Trask men's Sadler",
    "start": "1627400",
    "end": "1635700"
  },
  {
    "text": "and on the right hand side because this is a different catalog it's the Zappos catalog it's just labeled Trask Sadler",
    "start": "1635700",
    "end": "1643420"
  },
  {
    "text": "and you know we can look at it and say these are the same shoes because they look the same they have the same types",
    "start": "1643420",
    "end": "1649420"
  },
  {
    "text": "of you know colors that are available there in the in the same range of prices these two products are the same but to",
    "start": "1649420",
    "end": "1656860"
  },
  {
    "text": "do that programmatically is pretty difficult and so what we have is a way of training transforms with your data",
    "start": "1656860",
    "end": "1663940"
  },
  {
    "text": "set refining that training and then and then running those transforms across",
    "start": "1663940",
    "end": "1670000"
  },
  {
    "text": "your data sets so first you know use the ETL tools to be able to combine those data sets you run you know our our",
    "start": "1670000",
    "end": "1677290"
  },
  {
    "text": "transforms to go and figure out where the matches are there may or may not work very well so what you want to do then is train it by giving it positive",
    "start": "1677290",
    "end": "1684040"
  },
  {
    "text": "and negative examples and then you kind of iterate on this over and over again and all of this is now built into glue",
    "start": "1684040",
    "end": "1689650"
  },
  {
    "text": "using a set of api's and a and a user experience around the machine learning",
    "start": "1689650",
    "end": "1694870"
  },
  {
    "text": "okay I want to dive a little bit deeper to tell you a little bit about some of",
    "start": "1694870",
    "end": "1700000"
  },
  {
    "text": "the technology that actually that actually supports these things in",
    "start": "1700000",
    "end": "1705700"
  },
  {
    "text": "particular for deduplication you know the naive way of doing this is to look at all pairs of records that you",
    "start": "1705700",
    "end": "1712960"
  },
  {
    "text": "in a data set score those pairs come up with some way of saying hey these things are similar and the things that are",
    "start": "1712960",
    "end": "1719559"
  },
  {
    "text": "similar kind of grouped them and say these things are the same thing and those are those are the three main",
    "start": "1719559",
    "end": "1724779"
  },
  {
    "text": "things that you can do with with our ml transforms of three main things that you",
    "start": "1724779",
    "end": "1730090"
  },
  {
    "text": "can control but we we actually developed this technology with Amazon retail internally and it's now available",
    "start": "1730090",
    "end": "1736029"
  },
  {
    "text": "through glue what we've done is we've actually given you a lot more controls and made this these this process a lot",
    "start": "1736029",
    "end": "1743169"
  },
  {
    "text": "faster so in particular the first phase where you're trying to figure out what pairs to consider what we do is we",
    "start": "1743169",
    "end": "1749350"
  },
  {
    "text": "actually use locality sensitive hashing to decide which two records are likely",
    "start": "1749350",
    "end": "1755350"
  },
  {
    "text": "to be similar and put them into different bins and then in a particular bin we consider all N squared",
    "start": "1755350",
    "end": "1762100"
  },
  {
    "text": "possibilities so we don't look at it across the entire data set that speeds up the processing by orders of magnitude",
    "start": "1762100",
    "end": "1768399"
  },
  {
    "text": "and you can actually control how big these bins are and they vary the trade-off between how accurate risk is",
    "start": "1768399",
    "end": "1775299"
  },
  {
    "text": "how inexpensive the processing is going to be the second thing that that we have",
    "start": "1775299",
    "end": "1782230"
  },
  {
    "text": "is a random forest model that actually creates these scores and you can tune this model with glue ml with positive",
    "start": "1782230",
    "end": "1790360"
  },
  {
    "text": "and negative examples for your particular data set and then the third",
    "start": "1790360",
    "end": "1795490"
  },
  {
    "text": "thing that we have is a better partitioning scheme that takes into account more than just the individual",
    "start": "1795490",
    "end": "1802570"
  },
  {
    "text": "weights that you get from the scores to give you a better precision or present a better recall and you can actually",
    "start": "1802570",
    "end": "1808210"
  },
  {
    "text": "trade-off between the two recall meaning you know making sure that you get behind all possible matches but you might have",
    "start": "1808210",
    "end": "1813700"
  },
  {
    "text": "false positives or precision meaning finding only the ones you really are sure about but you know then end up with",
    "start": "1813700",
    "end": "1820600"
  },
  {
    "text": "a bunch that you miss you can tune all of this instead of glue ml main point",
    "start": "1820600",
    "end": "1826779"
  },
  {
    "text": "that I want to make is there's a lot of technology that we built in-house and retail that we've made available for you if you use the previous sets of",
    "start": "1826779",
    "end": "1834159"
  },
  {
    "text": "algorithms you know working over 400 million rows 7.5 billion candidate pairs it would have taken you weeks if not",
    "start": "1834159",
    "end": "1840789"
  },
  {
    "text": "months to solve this problem we can do it in a couple of hours all right let's see if we're done can we",
    "start": "1840789",
    "end": "1848140"
  },
  {
    "text": "go back to our demo all right so let's go back to our demo it's been done for a while but I took a little bit longer",
    "start": "1848140",
    "end": "1854110"
  },
  {
    "text": "than I should have all right so we're now gonna do as you can see that that particular workflow",
    "start": "1854110",
    "end": "1859570"
  },
  {
    "text": "finished and it probably created a couple of tables inside of our database shall we go over there all right there's",
    "start": "1859570",
    "end": "1866530"
  },
  {
    "text": "our database summit demo let's take a look at the tables we have some tables",
    "start": "1866530",
    "end": "1871870"
  },
  {
    "text": "under you know starting with underscore there's our temporary tables and then that's the main table that was created at the top and then what are we gonna do",
    "start": "1871870",
    "end": "1879070"
  },
  {
    "text": "now we're gonna go and give permissions to two different users let's imagine one user is an IT admin that has access to",
    "start": "1879070",
    "end": "1885730"
  },
  {
    "text": "everything in the cloud trail data and that IT admin is using redshift so we've",
    "start": "1885730",
    "end": "1890890"
  },
  {
    "text": "created a role that redshift will use to access that data we're gonna give it",
    "start": "1890890",
    "end": "1896260"
  },
  {
    "text": "access to that particular database we're going to give it access to that particular table and then it has all the",
    "start": "1896260",
    "end": "1903340"
  },
  {
    "text": "columns and we're gonna give it and select access but nothing else so you can't delete or insert into there and I",
    "start": "1903340",
    "end": "1908590"
  },
  {
    "text": "know we're gonna do a grant pretty simple right okay great now let's get another user and let's imagine this is",
    "start": "1908590",
    "end": "1915159"
  },
  {
    "text": "just your sort of average user that has access to the public information in cloud trail let's call them an analyst",
    "start": "1915159",
    "end": "1920770"
  },
  {
    "text": "if you will same data same table same database same table but now they're only",
    "start": "1920770",
    "end": "1927159"
  },
  {
    "text": "allowed to access a few columns let's pick those columns user identity event",
    "start": "1927159",
    "end": "1934330"
  },
  {
    "text": "time event source event name great and that's it now this",
    "start": "1934330",
    "end": "1942460"
  },
  {
    "text": "user is going to go to Athena and there's only going to be able to see just those four columns and won't know any different whether more columns",
    "start": "1942460",
    "end": "1949059"
  },
  {
    "text": "existed or not and we're gonna give him select access to those columns okay all",
    "start": "1949059",
    "end": "1954220"
  },
  {
    "text": "right let's go over to actually now I think we want to switch back right okay",
    "start": "1954220",
    "end": "1963789"
  },
  {
    "text": "great all right so how is this gonna work we've given access to these users and we",
    "start": "1963789",
    "end": "1969440"
  },
  {
    "text": "given them both column level and row level access I started column level and table level access right the way this is",
    "start": "1969440",
    "end": "1976370"
  },
  {
    "text": "gonna work is the administrator just saw trying to go do this process they're going to give access to those things the",
    "start": "1976370",
    "end": "1984980"
  },
  {
    "text": "users are then going to access that data in that data Lake through one of various services we mentioned to redshift and",
    "start": "1984980",
    "end": "1990680"
  },
  {
    "text": "Athena redshift and Athena are then going to consult lake formation and then",
    "start": "1990680",
    "end": "1995960"
  },
  {
    "text": "decide whether they're gonna run the query and over what portions of the data to run the query on and I've said this",
    "start": "1995960",
    "end": "2002460"
  },
  {
    "text": "once before and I'll say it once again you get to control dat data access in a very granular fashion with very simple",
    "start": "2002460",
    "end": "2009340"
  },
  {
    "text": "grant and revoke permissions on tables as well as subsets of columns and the",
    "start": "2009340",
    "end": "2014440"
  },
  {
    "text": "nice thing about that is now you don't have to create all kinds of redundancy in your system where you create",
    "start": "2014440",
    "end": "2019870"
  },
  {
    "text": "substance of data just for the people that has to have to access them and then as you have more and more roles you have",
    "start": "2019870",
    "end": "2025870"
  },
  {
    "text": "sort of an explosion of data that you have to manage and because you're all doing all of this in a single place you",
    "start": "2025870",
    "end": "2032260"
  },
  {
    "text": "can also audit all of the accesses to all of the data sets that you have in your data leak how does it work",
    "start": "2032260",
    "end": "2040960"
  },
  {
    "text": "you're gonna send a query okay users gonna send a query for some table T the",
    "start": "2040960",
    "end": "2047950"
  },
  {
    "text": "query is going to request access to lake formation for all the objects that are in T lake formation is going to send",
    "start": "2047950",
    "end": "2054878"
  },
  {
    "text": "back the short term I am credentials that allow these engines to access all",
    "start": "2054879",
    "end": "2060220"
  },
  {
    "text": "of those objects including all the columns they're also going to send back information about which columns that",
    "start": "2060220",
    "end": "2065888"
  },
  {
    "text": "user is allowed to see then these engines step number four they're going",
    "start": "2065889",
    "end": "2071470"
  },
  {
    "text": "to request access to those objects directly to s3 notice there's no intermediary between the engines and s3",
    "start": "2071470",
    "end": "2078510"
  },
  {
    "text": "so the normal processing that these engines do over s3 continues and then",
    "start": "2078510",
    "end": "2084310"
  },
  {
    "text": "these objects are returned whole and then the engines themselves are actually doing the filtering okay and these users",
    "start": "2084310",
    "end": "2091870"
  },
  {
    "text": "can be I am users I am roles and if you're coming through EMR with SPARC your users can actually be",
    "start": "2091870",
    "end": "2098220"
  },
  {
    "text": "Active Directory users and Active Directory groups so you don't have to go through this Federation process okay all",
    "start": "2098220",
    "end": "2106619"
  },
  {
    "text": "right three key takeaways no intermediary in the data path so your performance is maintained the services",
    "start": "2106619",
    "end": "2114780"
  },
  {
    "text": "are the ones that are doing the the filtering you don't have an extra hop there's no extra cost in terms of",
    "start": "2114780",
    "end": "2120480"
  },
  {
    "text": "networking or moving data and then all of this stuff is done in a central place so you can actually get audits of all",
    "start": "2120480",
    "end": "2128250"
  },
  {
    "text": "the accesses so let's let's actually take a look at what that looks like let's go back to the demo all right so",
    "start": "2128250",
    "end": "2137580"
  },
  {
    "text": "now we're in redshift why don't we have you already created the schema okay great we run the query so what this is",
    "start": "2137580",
    "end": "2147000"
  },
  {
    "text": "doing is telling redshift hey please can you know create a schema for that database I mean and connect to that data",
    "start": "2147000",
    "end": "2152099"
  },
  {
    "text": "catalog and create a schema around it oh you need to restart this ran out no",
    "start": "2152099",
    "end": "2159480"
  },
  {
    "text": "problem we can go back to the all right",
    "start": "2159480",
    "end": "2165150"
  },
  {
    "text": "that's just well he's doing that let me kind of forward through this and tell",
    "start": "2165150",
    "end": "2172080"
  },
  {
    "text": "you another thing and then we'll go back and finish the demo okay",
    "start": "2172080",
    "end": "2176900"
  },
  {
    "text": "the glue data catalog and the lake formation catalog are one in the same",
    "start": "2177890",
    "end": "2184070"
  },
  {
    "text": "okay the state is one in the same so your existing Bloo crawlers your jobs your",
    "start": "2184070",
    "end": "2190410"
  },
  {
    "text": "triggers and your workflows all your glue resources that are governed by I am policies they will continue to work you",
    "start": "2190410",
    "end": "2196800"
  },
  {
    "text": "don't have to do a forklift upgrade to lake formation what you can do is once",
    "start": "2196800",
    "end": "2204920"
  },
  {
    "text": "once the lake formation and once you are using the information you can incrementally change the permissions on",
    "start": "2204920",
    "end": "2212160"
  },
  {
    "text": "each one of your databases each one of your tables until your entire catalog is going over to lake formation we did not",
    "start": "2212160",
    "end": "2219599"
  },
  {
    "text": "want you to have to do a forklift migration and so that's not what you have to do okay",
    "start": "2219599",
    "end": "2225030"
  },
  {
    "text": "are we back all right cool let's finish the demo all right",
    "start": "2225030",
    "end": "2230970"
  },
  {
    "text": "that's okay statements successfully competed he's got a database let's see",
    "start": "2230970",
    "end": "2236970"
  },
  {
    "text": "what you can see there all right there it is let's take a look this is the IT",
    "start": "2236970",
    "end": "2242040"
  },
  {
    "text": "admin and you'll see that the admin has access to many many different columns and then he can run a simple query over",
    "start": "2242040",
    "end": "2248910"
  },
  {
    "text": "that those columns and you can actually run arbitrary sequel and a antsy sequel",
    "start": "2248910",
    "end": "2255960"
  },
  {
    "text": "in redshift so you get access to everything that's there pretty cool right let's go over to Athena now this",
    "start": "2255960",
    "end": "2264089"
  },
  {
    "text": "is your sort of average everyday user they only have access to a subset of the",
    "start": "2264089",
    "end": "2269310"
  },
  {
    "text": "columns let's take a look at the columns",
    "start": "2269310",
    "end": "2277500"
  },
  {
    "text": "that they have access to those four that we decided at the top as well as the partition columns because those can't be",
    "start": "2277500",
    "end": "2282930"
  },
  {
    "text": "hidden those are stored and how you actually lay out the data and they help you actually locate the datasets that",
    "start": "2282930",
    "end": "2288210"
  },
  {
    "text": "you care about the subsets all right and then now we're gonna go run a simple query in Athena and you'll see the",
    "start": "2288210",
    "end": "2295260"
  },
  {
    "text": "results come up the important thing is the Athena user but an average user doesn't even know that their aim there",
    "start": "2295260",
    "end": "2302250"
  },
  {
    "text": "are other columns in this data set okay it's named the same it's the same database but you only get a subset of",
    "start": "2302250",
    "end": "2308339"
  },
  {
    "text": "the columns cool and it's simple as that",
    "start": "2308339",
    "end": "2314369"
  },
  {
    "text": "now let's go over to look at the audit logs here are the audit logs for all the accesses that we may it's all in a",
    "start": "2314369",
    "end": "2321180"
  },
  {
    "text": "single place the admin can take a look at it and the individual accesses you can actually look at the events in this",
    "start": "2321180",
    "end": "2328079"
  },
  {
    "text": "particular case the daily lake user was accessing the data set and you can actually see the Select query that they",
    "start": "2328079",
    "end": "2333839"
  },
  {
    "text": "actually ran cool right all in a single place that's it it's as",
    "start": "2333839",
    "end": "2339210"
  },
  {
    "text": "simple as that to get a data Lake setup using lake formation you can do it in 40 minutes so we already talked about the",
    "start": "2339210",
    "end": "2345720"
  },
  {
    "text": "fact that you can do move the data catalog from Glu to lake formation incrementally pricing for lake formation",
    "start": "2345720",
    "end": "2354270"
  },
  {
    "text": "there's no additional charge this is all basically the charge of the underlying",
    "start": "2354270",
    "end": "2359640"
  },
  {
    "text": "services that you're using glue athena redshift EMR you don't pay for all of this extra",
    "start": "2359640",
    "end": "2367839"
  },
  {
    "text": "functionality you just get to use it to conclude data lakes are the evolution of",
    "start": "2367839",
    "end": "2373720"
  },
  {
    "text": "data warehousing okay lake formation makes sending up securing and using data",
    "start": "2373720",
    "end": "2379150"
  },
  {
    "text": "lakes simple and we have loads more to come we're gonna do act we're gonna do attribute attribute based or tag based",
    "start": "2379150",
    "end": "2386140"
  },
  {
    "text": "access control that business metadata will help you actually specify security policies using that we're gonna give you",
    "start": "2386140",
    "end": "2392619"
  },
  {
    "text": "data lineage to be able to understand how data was derived from one to another and then we're also going to add more ml",
    "start": "2392619",
    "end": "2399490"
  },
  {
    "text": "transforms to detect things like PII data or entities like emails and",
    "start": "2399490",
    "end": "2404619"
  },
  {
    "text": "addresses in your system with that I'd like to hand it over to Sreenivas he'll",
    "start": "2404619",
    "end": "2410170"
  },
  {
    "text": "tell you about the the data Lake story that all Alcon has gone under thank you",
    "start": "2410170",
    "end": "2417240"
  },
  {
    "text": "thank you my Hill one of the best Devils I've seen I mean I know there are always",
    "start": "2420590",
    "end": "2425940"
  },
  {
    "text": "some peaches here in their great demo thank you guys my name is strenuous",
    "start": "2425940",
    "end": "2431040"
  },
  {
    "text": "rebel City I am The IT analytics lead in alcohol the reason I am here is to talk",
    "start": "2431040",
    "end": "2438210"
  },
  {
    "text": "about how our data leak journey but also talk about how we are going to be using",
    "start": "2438210",
    "end": "2443520"
  },
  {
    "text": "lake formation going forward if for the guys who are not familiar with alcohol",
    "start": "2443520",
    "end": "2448770"
  },
  {
    "text": "alcohol is is a surgical eye care contact lense and contact lens care",
    "start": "2448770",
    "end": "2454800"
  },
  {
    "text": "product company we touch millions of lives across the globe we have two",
    "start": "2454800",
    "end": "2460740"
  },
  {
    "text": "franchises surgical and vision care we Nairobi ranked number one in surgical",
    "start": "2460740",
    "end": "2466520"
  },
  {
    "text": "customer satisfaction and also a vision vision care products are are one of the",
    "start": "2466520",
    "end": "2472620"
  },
  {
    "text": "most rustic I think most of you guys are at least the guys who are actually wearing contact lens must have heard",
    "start": "2472620",
    "end": "2479070"
  },
  {
    "text": "about alcohol if you have not heard about alcohol give it some time when you age you will see that you are going to",
    "start": "2479070",
    "end": "2485610"
  },
  {
    "text": "be knowing about alcohol because you see all the diseases on the right side let me put that so it's a thirty billion",
    "start": "2485610",
    "end": "2495450"
  },
  {
    "text": "dollar industry we are a seven billion dollar market share again I'm gonna try",
    "start": "2495450",
    "end": "2502830"
  },
  {
    "text": "to go quickly here because of the time and I know you have a lot of questions well there is a lot of advanced",
    "start": "2502830",
    "end": "2509370"
  },
  {
    "text": "analytics capabilities that we use now we invest invest a lot of money into",
    "start": "2509370",
    "end": "2514680"
  },
  {
    "text": "artificial intelligence ml and also automation and connectivity for speed of",
    "start": "2514680",
    "end": "2521790"
  },
  {
    "text": "discovery but also we have some state of the art manufacturing facilities around the world and we have a strong Quality",
    "start": "2521790",
    "end": "2527970"
  },
  {
    "text": "Assurance team that basically ensures compliance and integrity I know in in a",
    "start": "2527970",
    "end": "2533580"
  },
  {
    "text": "medical device company it is very important so this is one of the key things for us now one of the things I'm",
    "start": "2533580",
    "end": "2541440"
  },
  {
    "text": "here is to talk about data leaks but I'm just going to talk about what my team does so we look at the entire portfolio",
    "start": "2541440",
    "end": "2547410"
  },
  {
    "text": "of all the data warehouses all the data leaks data Mart's that are in the",
    "start": "2547410",
    "end": "2552690"
  },
  {
    "text": "company we look at the platforms as well so tableaus clicks you know and you name it right we have around 16 platforms so",
    "start": "2552690",
    "end": "2559830"
  },
  {
    "text": "it's a big broad complex landscape and there are different teams that manage",
    "start": "2559830",
    "end": "2565170"
  },
  {
    "text": "various tools and technologies why what is the problem statement I think this is",
    "start": "2565170",
    "end": "2571350"
  },
  {
    "text": "a problem statement I am sure everyone echoes the data is scattered people don't know what to trust what not to",
    "start": "2571350",
    "end": "2577890"
  },
  {
    "text": "trust and what muscle was mentioning before lot of time is actually spent in",
    "start": "2577890",
    "end": "2583040"
  },
  {
    "text": "preparing the data it's a common theme across our company everywhere I go",
    "start": "2583040",
    "end": "2588270"
  },
  {
    "text": "we we started looking at that and said what can we do for that right so one of",
    "start": "2588270",
    "end": "2593460"
  },
  {
    "text": "the things that was key for us is also to bring in data ownership this is data management and also agility to give us",
    "start": "2593460",
    "end": "2600810"
  },
  {
    "text": "that centralized data trusted data repository so our approach was to build",
    "start": "2600810",
    "end": "2607200"
  },
  {
    "text": "something centralized data repository and also built-in data management data management is very crucial I'm going to",
    "start": "2607200",
    "end": "2613800"
  },
  {
    "text": "touch upon that a bit because we talked about the data Lake and you know 10,000",
    "start": "2613800",
    "end": "2619440"
  },
  {
    "text": "little lakes I'm sure there are a lot of swamps in there like people swimming already so we're trying to avoid that",
    "start": "2619440",
    "end": "2625020"
  },
  {
    "text": "and in my experience last five years it's been it's not been easy to actually maintain a data Lake so what does what",
    "start": "2625020",
    "end": "2633540"
  },
  {
    "text": "is our journey what what is our journey so far being right and where we are going so we had a lot of in the past",
    "start": "2633540",
    "end": "2639570"
  },
  {
    "text": "how do infrastructures in our in place a lot of data warehouses lot of data",
    "start": "2639570",
    "end": "2644820"
  },
  {
    "text": "Mart's everyone creates their own data Mart's because everyone thinks they are special anyway and there are so many servers and forget about the security",
    "start": "2644820",
    "end": "2652290"
  },
  {
    "text": "models everyone I touch has their own security model so how do we handle all this so AWS gives us that ability now",
    "start": "2652290",
    "end": "2661230"
  },
  {
    "text": "because the platform is so much scaleable it helps us it helps us to actually bring all that data together",
    "start": "2661230",
    "end": "2666720"
  },
  {
    "text": "the best part of bringing the data together is not just looking at when you talk about a IML it's not about just the",
    "start": "2666720",
    "end": "2673680"
  },
  {
    "text": "depth of the data but it's the breadth you want to find answers from the data not just knowing the problem and going",
    "start": "2673680",
    "end": "2680970"
  },
  {
    "text": "to try to answer it you want to actually look at the problem that your data is telling you that can only come from not just the",
    "start": "2680970",
    "end": "2687510"
  },
  {
    "text": "depth but also the breadth so that's one of the reasons what we decided is our data is our data and we wanted it to be",
    "start": "2687510",
    "end": "2693240"
  },
  {
    "text": "honest three so that all our data is segregated from the compute so we have",
    "start": "2693240",
    "end": "2698610"
  },
  {
    "text": "storage and computes completely separated the reason we did this is because we had suffered enough with",
    "start": "2698610",
    "end": "2704070"
  },
  {
    "text": "Hadoop where our cluster just keep going going and are paying money every day",
    "start": "2704070",
    "end": "2709710"
  },
  {
    "text": "it's like Netflix you know it just keeps going on every month so we decided let's",
    "start": "2709710",
    "end": "2715650"
  },
  {
    "text": "you know let's get a good architecture in place where we pay as we go so we had",
    "start": "2715650",
    "end": "2721590"
  },
  {
    "text": "that in place then we are using all the AWS services as much as possible and we",
    "start": "2721590",
    "end": "2726600"
  },
  {
    "text": "wanted to get a consistent and simplified security model in place so",
    "start": "2726600",
    "end": "2731780"
  },
  {
    "text": "what is that we want what does a user really want is simple thing a simple user a data scientist a simple analyst",
    "start": "2731780",
    "end": "2738180"
  },
  {
    "text": "what does he want he wants to just look at what data is out there in the company do some pick the data get access to it",
    "start": "2738180",
    "end": "2744510"
  },
  {
    "text": "and start doing visualizations but imagine the life of these guys they go talk to ten people ten forms you know go",
    "start": "2744510",
    "end": "2751770"
  },
  {
    "text": "to different departments finally figure out if ten different tools to even draw a small tableau dashboard or a small",
    "start": "2751770",
    "end": "2758610"
  },
  {
    "text": "click dashboard and a small organizations is a 1-story big organization it's another story altogether how do we simplify that so",
    "start": "2758610",
    "end": "2764970"
  },
  {
    "text": "our goal is that we actually give them the ability to simply be a simplified",
    "start": "2764970",
    "end": "2770220"
  },
  {
    "text": "experience so that they can browse through the data and actually get the access and do the analysis that they need and obviously one of the key motive",
    "start": "2770220",
    "end": "2777480"
  },
  {
    "text": "for us is we make the users in a lie we we make sure that people are spending",
    "start": "2777480",
    "end": "2782550"
  },
  {
    "text": "more time in analyzing the data and drawing insights and not preparing the data so we are using all the HW services",
    "start": "2782550",
    "end": "2788970"
  },
  {
    "text": "there one of the things that resonates with me when Meryl mentioned is like it took years I mean I have been doing this",
    "start": "2788970",
    "end": "2794610"
  },
  {
    "text": "data like thing for almost three to four years now it always takes a year to implement any data like at an enterprise level minimum but we can do it in a",
    "start": "2794610",
    "end": "2802920"
  },
  {
    "text": "month we have done a fantastic job we have a fantastic team in Alcon we consider ourself as a start-up company",
    "start": "2802920",
    "end": "2808230"
  },
  {
    "text": "so we have done a great job we launched something in two months but that's not",
    "start": "2808230",
    "end": "2813390"
  },
  {
    "text": "sufficient enough so that's where lake formation comes into picture and I'll tell you why",
    "start": "2813390",
    "end": "2819829"
  },
  {
    "text": "so this is our architecture the green box that you see is the foresight you",
    "start": "2820900",
    "end": "2827120"
  },
  {
    "text": "know you can relate its sight alcanz branding to datalink is called foresight",
    "start": "2827120",
    "end": "2832300"
  },
  {
    "text": "we have four different components here guys one is data management as I told you it is very important for us and then",
    "start": "2832300",
    "end": "2838700"
  },
  {
    "text": "lake formation is where we tend to we want to go right now it is on all on s3 and we use glue it's all in jest or the",
    "start": "2838700",
    "end": "2845780"
  },
  {
    "text": "data there visualization tools now just this is an indication I'm not talking about these are the only tools I wish",
    "start": "2845780",
    "end": "2851270"
  },
  {
    "text": "these were the only tools but they are not if I put all the tools here it'll be three or four slides but that's a different story then we have all these",
    "start": "2851270",
    "end": "2857660"
  },
  {
    "text": "data science tools and data preparation tools that we want to get how do we get these things to work together seamlessly",
    "start": "2857660",
    "end": "2863050"
  },
  {
    "text": "why do people have to go through so much of you know technology you know you to",
    "start": "2863050",
    "end": "2868940"
  },
  {
    "text": "get certified in ten things before you actually access the data so we wanted to make it simple you can see the data",
    "start": "2868940",
    "end": "2874850"
  },
  {
    "text": "sources there's wide variety of cloud data sources that we have we have on-prem data sources we also have data",
    "start": "2874850",
    "end": "2881960"
  },
  {
    "text": "that we want to give it to universities where they can actually help us again think about that right the cases where",
    "start": "2881960",
    "end": "2888020"
  },
  {
    "text": "we try to work with universities but it takes months to actually get the data to that give them the infrastructure to",
    "start": "2888020",
    "end": "2893840"
  },
  {
    "text": "actually work on a model but I think this simplifies for for for us okay what",
    "start": "2893840",
    "end": "2900200"
  },
  {
    "text": "is a complexity with the current model the biggest complexity is as three bucket policies there is no way we can",
    "start": "2900200",
    "end": "2907310"
  },
  {
    "text": "get the security at the data level without the security model being complex right now and what we have done we have",
    "start": "2907310",
    "end": "2913640"
  },
  {
    "text": "done a lot of custom development to manage the security model you may be thinking about why do you even need to",
    "start": "2913640",
    "end": "2919580"
  },
  {
    "text": "do any custom development think about building something at the enterprise level you have hundreds and thousands of buckets you need to catalog them you",
    "start": "2919580",
    "end": "2926840"
  },
  {
    "text": "need to have data stewards you need to have data ownership who is giving the access how do you have to revoke the access and all that stuff to manage that",
    "start": "2926840",
    "end": "2933950"
  },
  {
    "text": "at the s3 bucket policy level is a nightmare but we have done it we know what the",
    "start": "2933950",
    "end": "2940240"
  },
  {
    "text": "issues are what the gaps are but that's what Blake formation comes into picture so other part is everything in AWS great",
    "start": "2940240",
    "end": "2948560"
  },
  {
    "text": "when you act when you are actually using tools every every day every month you know all the if you",
    "start": "2948560",
    "end": "2953990"
  },
  {
    "text": "go to these Expos every time there is always new tools coming up now how do you make sure that these tools are able",
    "start": "2953990",
    "end": "2959090"
  },
  {
    "text": "to access the data easily so we've come up with some model where we can get get these tools to access the data give the",
    "start": "2959090",
    "end": "2964880"
  },
  {
    "text": "leverage to the user so that they can use the tool of their choice to get the data and actually analyze the data and",
    "start": "2964880",
    "end": "2971380"
  },
  {
    "text": "the limitation of some of the limitations are the size and then obviously other thing is when you don't",
    "start": "2971380",
    "end": "2977120"
  },
  {
    "text": "have column level and other level of Security's is it's always replicating the data again and again you know derive",
    "start": "2977120",
    "end": "2983300"
  },
  {
    "text": "data data sets the Wylie lake formation well it simply it just simplifies our",
    "start": "2983300",
    "end": "2991160"
  },
  {
    "text": "security model and you've seen that in the demo it's actually I was really impressed the way it was the flow was",
    "start": "2991160",
    "end": "2997550"
  },
  {
    "text": "fantastic it Alps us with that security model simplification data cataloging I",
    "start": "2997550",
    "end": "3003430"
  },
  {
    "text": "know a lot of people may be thinking about what does it really mean about etiquette and where do we even actually do this they get data cataloging for his",
    "start": "3003430",
    "end": "3010450"
  },
  {
    "text": "business data and cataloging when when we are in industry like medical device industry we need to know exactly what",
    "start": "3010450",
    "end": "3016540"
  },
  {
    "text": "the data is all about what are the compliance requirements security requirements on the data set is it from",
    "start": "3016540",
    "end": "3022540"
  },
  {
    "text": "a particular region is it GD P R is it GX p non GX p how do we capture all that",
    "start": "3022540",
    "end": "3028120"
  },
  {
    "text": "because in the past it used to be in the documents now we want to bring that very close to the data now we've been using",
    "start": "3028120",
    "end": "3034570"
  },
  {
    "text": "data management tools that are external to the data to manage this but now with the ability to actually have business",
    "start": "3034570",
    "end": "3041290"
  },
  {
    "text": "metadata it's fantastic that you can actually query the data using these metadata tags imagine you know you only",
    "start": "3041290",
    "end": "3048730"
  },
  {
    "text": "you know people cannot see data in a certain certain country based on a particular tag or a column based on a",
    "start": "3048730",
    "end": "3055030"
  },
  {
    "text": "particular time it's great and it's that the simple model actually helps us very much so what does it do when we build",
    "start": "3055030",
    "end": "3061480"
  },
  {
    "text": "the data data link in the last two months I was very proud of it that we build something very fast but imagine we",
    "start": "3061480",
    "end": "3066730"
  },
  {
    "text": "spend it on 70% of the time just building the security model because it is complicated at enterprise level this",
    "start": "3066730",
    "end": "3073540"
  },
  {
    "text": "actually makes it much easier data like a lake formation makes it much easier for us security management okay you go",
    "start": "3073540",
    "end": "3080500"
  },
  {
    "text": "live how do you can you sustain can you maintain it it's been very difficult to do that lake formation makes it very",
    "start": "3080500",
    "end": "3085660"
  },
  {
    "text": "very easy the biggest part problem is the custom",
    "start": "3085660",
    "end": "3090970"
  },
  {
    "text": "code you know people just keep writing custom code to you know adapt to the security models so one of the things",
    "start": "3090970",
    "end": "3096400"
  },
  {
    "text": "this does is it actually helps us reduce that data redundancy as I talked about it before glue catalog one of the things",
    "start": "3096400",
    "end": "3104589"
  },
  {
    "text": "is just to touch upon this topic what do what we have right now is we have a data management tool and AWS both of them are",
    "start": "3104589",
    "end": "3111700"
  },
  {
    "text": "sitting on a table I mean you know it the data cataloging tool is also on AWS but our cataloging business metadata",
    "start": "3111700",
    "end": "3117460"
  },
  {
    "text": "cataloging is actually happening in the data management tool what we do is we enforce all the security or we trigger",
    "start": "3117460",
    "end": "3123880"
  },
  {
    "text": "the security from data management tools it's great it is working well the",
    "start": "3123880",
    "end": "3129460"
  },
  {
    "text": "problem with it is I cannot still pass them a business metadata to my data I mean I cannot take it closer to the data",
    "start": "3129460",
    "end": "3136270"
  },
  {
    "text": "because how does that help user friendly search one one example and also enforce",
    "start": "3136270",
    "end": "3142240"
  },
  {
    "text": "security in future so that is a big big big thing for us the best party thinking",
    "start": "3142240",
    "end": "3148569"
  },
  {
    "text": "I think is the migration is very simple you don't have to do much and the tool is going to work seamlessly especially",
    "start": "3148569",
    "end": "3155770"
  },
  {
    "text": "with if you are using Athena or ODBC drivers it's much it's very clean easy",
    "start": "3155770",
    "end": "3161440"
  },
  {
    "text": "you don't have to do anything at the user end it just simplifies the whole thing",
    "start": "3161440",
    "end": "3167640"
  },
  {
    "text": "thank you we're happy to take questions",
    "start": "3167640",
    "end": "3176099"
  },
  {
    "text": "we have about another seven minutes left so go ahead",
    "start": "3176099",
    "end": "3182490"
  },
  {
    "text": "you're asking me or him okay I asked him he's the one who does it I'd",
    "start": "3199200",
    "end": "3205720"
  },
  {
    "text": "also it's one of their I can tell you that it's one of our biggest challenges but we do it now is the integration the",
    "start": "3205720",
    "end": "3212050"
  },
  {
    "text": "best integration that we could have no but we do have a say P data in their Salesforce data in there we have direct",
    "start": "3212050",
    "end": "3219190"
  },
  {
    "text": "integration Salesforce is pretty straightforward because it's API driven it's ap is always a little bit more",
    "start": "3219190",
    "end": "3224950"
  },
  {
    "text": "convoluted and complicated so what we do right now is we still use traditional model of actually pumping the data into",
    "start": "3224950",
    "end": "3231040"
  },
  {
    "text": "the data Lake but we do pump them into the s3 buckets and n for security the the biggest thing just to touch upon",
    "start": "3231040",
    "end": "3237520"
  },
  {
    "text": "that is because the finance data is so secure our goal is that we have moved",
    "start": "3237520",
    "end": "3243460"
  },
  {
    "text": "away from IT owning the ownership of any of these data sets so when I talked about the data management tool by",
    "start": "3243460",
    "end": "3250540"
  },
  {
    "text": "default all the data on the s3 buckets does not have any implicit access no one",
    "start": "3250540",
    "end": "3257470"
  },
  {
    "text": "has access the only person who has access is the data owner which could be a finance user or ASAP data owner right",
    "start": "3257470",
    "end": "3263710"
  },
  {
    "text": "and he's the one who will actually give the access to the data did I answer your question sure that's a great question so",
    "start": "3263710",
    "end": "3276819"
  },
  {
    "text": "right now at the time of GA most of the API is that you can use to access to",
    "start": "3276819",
    "end": "3286000"
  },
  {
    "text": "access these things through lake formation are going to be internal api's for these services but our plan is to",
    "start": "3286000",
    "end": "3291550"
  },
  {
    "text": "open up those api's once we get some more experience and making sure that these things are secure and that they're",
    "start": "3291550",
    "end": "3298450"
  },
  {
    "text": "in the form that we want them for these third-party services so the answer is yes but it'll take some time okay go",
    "start": "3298450",
    "end": "3305800"
  },
  {
    "text": "ahead yeah it's a great it's a great question",
    "start": "3305800",
    "end": "3313010"
  },
  {
    "text": "so do we have a roadmap for future blueprints so we're gonna create more blueprints for other types of databases",
    "start": "3313010",
    "end": "3319520"
  },
  {
    "text": "not just the four main types that we have right now with our TS we are also",
    "start": "3319520",
    "end": "3325670"
  },
  {
    "text": "gonna make blueprints programmable so underneath the covers these blueprints are programmable like we've actually built a bunch of Python that actually",
    "start": "3325670",
    "end": "3333020"
  },
  {
    "text": "implements this workflow and all that stuff right and so the idea is once we've gotten those API is just right and",
    "start": "3333020",
    "end": "3339740"
  },
  {
    "text": "you know we need a little bit of time to make sure that that's scoped well enough so that you can't break out of our",
    "start": "3339740",
    "end": "3344930"
  },
  {
    "text": "security right then what we'll do is we'll open it up so that you can build your own blueprints and this way you",
    "start": "3344930",
    "end": "3351260"
  },
  {
    "text": "know every organization is going to have slightly different data set a slightly different type of format a slightly",
    "start": "3351260",
    "end": "3356510"
  },
  {
    "text": "different type of database they can use the underlying glue primitives which are quite flexible to be able to build your",
    "start": "3356510",
    "end": "3362930"
  },
  {
    "text": "own blueprints and then you can then serve those up to all of your customers internally within your organization make",
    "start": "3362930",
    "end": "3369410"
  },
  {
    "text": "sense",
    "start": "3369410",
    "end": "3371680"
  },
  {
    "text": "yep that's it's coming shortly after so that will be fast following with row-level security where you're gonna be",
    "start": "3377250",
    "end": "3383230"
  },
  {
    "text": "able to do simple predicates over you know over the rows a challenge there of",
    "start": "3383230",
    "end": "3388930"
  },
  {
    "text": "course is deciding what predicate language to use and to make sure that all of the various engines obey the same",
    "start": "3388930",
    "end": "3395520"
  },
  {
    "text": "semantics around those predicates and it can be tricky depending on the types of columns that you have types of data that",
    "start": "3395520",
    "end": "3401980"
  },
  {
    "text": "you have I have asked them that question at least four or five times already yeah go ahead so what tools we use to query",
    "start": "3401980",
    "end": "3422890"
  },
  {
    "text": "the data so the general the way users are using it is generally if they have",
    "start": "3422890",
    "end": "3427990"
  },
  {
    "text": "to run sequel queries for example to analyze the data they can go to Athena ok yes at the end of the day yes you're",
    "start": "3427990",
    "end": "3437320"
  },
  {
    "text": "right but it at end of the day what happens is once the unstructured data is actually you know the insights are being",
    "start": "3437320",
    "end": "3442840"
  },
  {
    "text": "drawn they gets converted into some kind of structured data then it's that's when we use Athena but our goal is again I do",
    "start": "3442840",
    "end": "3451030"
  },
  {
    "text": "realize that not everyone is you know wants to do sequel queries right so we do have all these tools we make sure",
    "start": "3451030",
    "end": "3458680"
  },
  {
    "text": "that all the tools that we have in our landscape actually work to the drivers that EWS provides to access the data",
    "start": "3458680",
    "end": "3464530"
  },
  {
    "text": "whether it is as I said right a blow click or Alteryx or whatever that tool that is available so and and to that I",
    "start": "3464530",
    "end": "3472030"
  },
  {
    "text": "mean we did have to create a couple of custom components for example to make",
    "start": "3472030",
    "end": "3477100"
  },
  {
    "text": "that seamless for the users",
    "start": "3477100",
    "end": "3481230"
  },
  {
    "text": "it's it's not it's not the same performance so again the we look at it one by one right so the data",
    "start": "3493620",
    "end": "3500500"
  },
  {
    "text": "provisioning when it comes finally it could be again going back your database data warehouse it could be you know let",
    "start": "3500500",
    "end": "3507970"
  },
  {
    "text": "me step back so we have different layers right we have Raleigh years we have trusted layers we have additional layers",
    "start": "3507970",
    "end": "3513040"
  },
  {
    "text": "the final product could be a data warehouse it had shipped or some other database the goal is when we looked at",
    "start": "3513040",
    "end": "3519850"
  },
  {
    "text": "all the data warehouses we found that not a lot of data warehouses data Mart's",
    "start": "3519850",
    "end": "3525070"
  },
  {
    "text": "are actually used for interactive Perrine there are data warehouses that are sitting that are running like maybe",
    "start": "3525070",
    "end": "3530590"
  },
  {
    "text": "once a day a query to populate what to get an extract into tableau why the hell",
    "start": "3530590",
    "end": "3537070"
  },
  {
    "text": "do I need a database and a server to do that wasting money for no apparent reason we said you don't need that",
    "start": "3537070",
    "end": "3543310"
  },
  {
    "text": "let tableau directly go to user Athena query get the data do your reporting same thing with qlik because think about",
    "start": "3543310",
    "end": "3549970"
  },
  {
    "text": "the visualization tools especially they have all in memory in memory capabilities now they want the data in their system so that they can give you",
    "start": "3549970",
    "end": "3556660"
  },
  {
    "text": "the best performance so that's what what what what we have done is we have eliminated a lot of data data Mart's and",
    "start": "3556660",
    "end": "3563080"
  },
  {
    "text": "data sources there to your point if a user is coming if a sales analyst is coming trying to query the performance",
    "start": "3563080",
    "end": "3568330"
  },
  {
    "text": "maybe not as good as what you would see in a data warehouse but again it case",
    "start": "3568330",
    "end": "3574360"
  },
  {
    "text": "but we take it case-by-case if that is a real requirement for a business capability we will do it you're not",
    "start": "3574360",
    "end": "3579970"
  },
  {
    "text": "going to tell them you know this is the only way to do it so we have time for one more question and we can take",
    "start": "3579970",
    "end": "3585700"
  },
  {
    "text": "follow-up outside go ahead in the front",
    "start": "3585700",
    "end": "3590430"
  },
  {
    "text": "yeah yeah that's a great question which is you know once you've put give it",
    "start": "3597279",
    "end": "3602599"
  },
  {
    "text": "under once you've put data under lake formation management is it possible to still use the s3 api's to get access to",
    "start": "3602599",
    "end": "3609200"
  },
  {
    "text": "the data and the short answer is yes you can get access to the data through s3",
    "start": "3609200",
    "end": "3614239"
  },
  {
    "text": "api's but now you're back to using s3 bucket policies for those accesses okay",
    "start": "3614239",
    "end": "3619999"
  },
  {
    "text": "so you're responsible now for securing those so if you you know have a bunch of",
    "start": "3619999",
    "end": "3625130"
  },
  {
    "text": "policies in lake formation and somebody has a side channel through s3 that they can get access data through then you've",
    "start": "3625130",
    "end": "3630799"
  },
  {
    "text": "basically overcome all of the column level controls some people and we're not preventing you from doing that you know",
    "start": "3630799",
    "end": "3636769"
  },
  {
    "text": "there's a lot of customers with existing applications on s3 and we want to help you migrate over but it's not going to",
    "start": "3636769",
    "end": "3642859"
  },
  {
    "text": "happen in day one so in that case we do allow you to just register like we did existing locations and you don't",
    "start": "3642859",
    "end": "3649789"
  },
  {
    "text": "actually have to do any movement you can actually just run a crawler and it'll automatically create those tables for",
    "start": "3649789",
    "end": "3655579"
  },
  {
    "text": "you and then do all of that work without ever having to move the data I know some customers have petabytes of data and you",
    "start": "3655579",
    "end": "3661160"
  },
  {
    "text": "don't want to move it you don't have to okay and you can keep that access alive until you're done moving everything over",
    "start": "3661160",
    "end": "3668769"
  },
  {
    "text": "okay thank you very much guys and if you have more questions we'll be on [Applause]",
    "start": "3668769",
    "end": "3676328"
  }
]
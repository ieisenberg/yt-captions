[
  {
    "text": "fantastic application of the cloud leverages the the fact that all of our resources are connected to the internet",
    "start": "719",
    "end": "6720"
  },
  {
    "text": "uh with rich security controls in place but also rich capabilities for sharing and opening up access to your data into",
    "start": "6720",
    "end": "13040"
  },
  {
    "text": "your machine images and other aws hosted resources and so very early on we saw a pattern that was developed at with nasa",
    "start": "13040",
    "end": "20160"
  },
  {
    "text": "and with several of our academic partners uh to create collaborative research environments in the cloud and what i",
    "start": "20160",
    "end": "25680"
  },
  {
    "text": "mean by this is a an environment where you're treating the cloud as a neutral environment of switzerland if you will",
    "start": "25680",
    "end": "31199"
  },
  {
    "text": "where researchers from many institutions instead of having to negotiate firewall rules having to figure out okay who's",
    "start": "31199",
    "end": "37280"
  },
  {
    "text": "going to hold a copy of the data or which institutions will have many copies of the data how do we synchronize source",
    "start": "37280",
    "end": "42879"
  },
  {
    "text": "code do we you know do we ship source code and then recompile in all these environments and then run some tests to see if these are consistent instead of",
    "start": "42879",
    "end": "49360"
  },
  {
    "text": "going through all of that hoopla you instead have a common environment with shared machine images shared containers",
    "start": "49360",
    "end": "55120"
  },
  {
    "text": "shared data sets in in amazon and you have maybe you have subsets of your data that are",
    "start": "55120",
    "end": "60879"
  },
  {
    "text": "selectively available to maybe individual members of the collaboration and some of this is available to the world we give you the tools and",
    "start": "60879",
    "end": "66960"
  },
  {
    "text": "capabilities to create these collaborative research environments uh with uh in a way that's both not only",
    "start": "66960",
    "end": "73040"
  },
  {
    "text": "cost effective but more importantly very accessible and and secure for your collaboration",
    "start": "73040",
    "end": "78479"
  },
  {
    "text": "um citizen science applications which we'll talk about too um have leveraged the scale and the global accessibility of",
    "start": "78479",
    "end": "85520"
  },
  {
    "text": "amazon's resources so when you have projects like the xenoverse and the galaxy zoo project uh that might one day",
    "start": "85520",
    "end": "91840"
  },
  {
    "text": "you know start with just you know 10 users and then then quickly grow to 100 000 visitors to their site we can",
    "start": "91840",
    "end": "97200"
  },
  {
    "text": "seamlessly handle of course the scale of the web infrastructure behind these applications and the databases and other technologies that are needed to support",
    "start": "97200",
    "end": "103759"
  },
  {
    "text": "these these types of applications and then more importantly make the the research data products from these",
    "start": "103759",
    "end": "109680"
  },
  {
    "text": "applications accessible in a broader context with other data products that combined bring more value to all of that",
    "start": "109680",
    "end": "115280"
  },
  {
    "text": "data and then finally we have science as a service applications and so by this we",
    "start": "115280",
    "end": "121680"
  },
  {
    "text": "mean those types of applications that abstract away all of the infrastructure and give the researcher the ability to",
    "start": "121680",
    "end": "127360"
  },
  {
    "text": "just focus on the science and maybe in the case of genomics upload genomic data files and have",
    "start": "127360",
    "end": "134959"
  },
  {
    "text": "a managed application handle alignment variant calling all of the processing of your genomic data so",
    "start": "134959",
    "end": "140560"
  },
  {
    "text": "that you can then focus on identifying linkage between specific biomarkers and the diseases that are correlated with",
    "start": "140560",
    "end": "146720"
  },
  {
    "text": "those and treatments that that might prove effective with those with those specific disorders",
    "start": "146720",
    "end": "152959"
  },
  {
    "text": "so the value proposition that we see for scientific computing on amazon really focuses in these areas we help you the",
    "start": "152959",
    "end": "160319"
  },
  {
    "text": "the cost savings are are important to researchers but far more important is the the time to science benefits the",
    "start": "160319",
    "end": "166480"
  },
  {
    "text": "fact that we don't have queues you don't have to wait uh you know minutes hours weeks or even months to be able to get",
    "start": "166480",
    "end": "172480"
  },
  {
    "text": "access to high performance computing or high throughput computing resource instead these resources are available",
    "start": "172480",
    "end": "177519"
  },
  {
    "text": "instantaneously and this does two things if you have a research project that's you know that you can predict needing",
    "start": "177519",
    "end": "183519"
  },
  {
    "text": "infrastructure for some some period of time down the road we can get to the infrastructure just",
    "start": "183519",
    "end": "188640"
  },
  {
    "text": "when you need it but more importantly when you have an idea as you're driving or riding the bus to to your office in",
    "start": "188640",
    "end": "194640"
  },
  {
    "text": "the morning you have the infrastructure available instantaneously to to take that thought experiment and and turn it",
    "start": "194640",
    "end": "201200"
  },
  {
    "text": "into a computational experiment which then might translate into a much larger investigation so effectively we're",
    "start": "201200",
    "end": "207360"
  },
  {
    "text": "allowing you to have access to science at the speed of thought instead of being constrained by availability of resources",
    "start": "207360",
    "end": "214400"
  },
  {
    "text": "and then of course the global accessibility and the security of the cloud are incredibly important we'll",
    "start": "214400",
    "end": "220080"
  },
  {
    "text": "talk about uh security especially as it relates to genomic applications",
    "start": "220080",
    "end": "226239"
  },
  {
    "text": "so why why does amazon care about scientific computing it really bundles into uh three broad categories one you know",
    "start": "226239",
    "end": "233040"
  },
  {
    "text": "two to a person within within amazon this is across all of amazon.com we love",
    "start": "233040",
    "end": "238959"
  },
  {
    "text": "science we love the outcomes of science we want to make our world a better place",
    "start": "238959",
    "end": "244400"
  },
  {
    "text": "and uh if we can support and accelerate the pace of discovery find cures for",
    "start": "244400",
    "end": "249439"
  },
  {
    "text": "disease help us better understand the impacts of climate change and potential mitigations we can help better understand the origins of the universe",
    "start": "249439",
    "end": "255760"
  },
  {
    "text": "that that excites us that causes us to wake up and say this is a great place to work secondly this is a valuable this is a",
    "start": "255760",
    "end": "261440"
  },
  {
    "text": "valid business model for amazon it's a profitable business for us and so this means that it's sustainable in the long term for us to focus on",
    "start": "261440",
    "end": "267680"
  },
  {
    "text": "scientific computing and invest in teams like mine and and on the partnerships that we've formed",
    "start": "267680",
    "end": "273199"
  },
  {
    "text": "thirdly and this one's really interesting the the scientific community uniquely brings the types of",
    "start": "273199",
    "end": "278560"
  },
  {
    "text": "requirements that you really can't find elsewhere we'll talk about the square kilometer array for example is a project",
    "start": "278560",
    "end": "283759"
  },
  {
    "text": "that's really the biggest of big data projects out there if we can meet the needs of projects that that are working with zettabytes",
    "start": "283759",
    "end": "290240"
  },
  {
    "text": "and publishing exabytes of data we can meet the needs of our commercial customers for many years to come and so",
    "start": "290240",
    "end": "296000"
  },
  {
    "text": "by working with the scientific community we feel that we're positioned to better serve all of our customers in the future",
    "start": "296000",
    "end": "302560"
  },
  {
    "text": "so i'll talk about a couple of programs that relate to the work that we're doing with scientific computing one of which is our research grants program",
    "start": "302560",
    "end": "309440"
  },
  {
    "text": "and amazon's offered a number of forms of grants both for education and research over the years the research",
    "start": "309440",
    "end": "315280"
  },
  {
    "text": "grants program and you can see the link to it on the slide allows us to invest",
    "start": "315280",
    "end": "320960"
  },
  {
    "text": "in capabilities that accelerate time to research and make access to computational data intensive algorithms",
    "start": "320960",
    "end": "328000"
  },
  {
    "text": "tools data sets and papers and resources we help make these more accessible to",
    "start": "328000",
    "end": "333680"
  },
  {
    "text": "the to the global research community and so you can think of this as an applied research grant program where we're giving grants to organizations like the",
    "start": "333680",
    "end": "340880"
  },
  {
    "text": "uc berkeley amp lab to the university of washington and to to to many researchers who are either",
    "start": "340880",
    "end": "347759"
  },
  {
    "text": "proving that something's possible to the world doing it for the first time clearing a path for others to follow or",
    "start": "347759",
    "end": "353520"
  },
  {
    "text": "we're helping them helping a researcher to take a well understood workload that's been proven to be possible in the",
    "start": "353520",
    "end": "358800"
  },
  {
    "text": "cloud and do a little bit more work to package that up and make it easy for researchers you know thousands or",
    "start": "358800",
    "end": "364560"
  },
  {
    "text": "hundreds of thousands of researchers around the world to then follow that path in a way that's going to reduce their risk accelerate their time to",
    "start": "364560",
    "end": "370080"
  },
  {
    "text": "science and and reduce the the cost of using cloud resources for these types of workloads",
    "start": "370080",
    "end": "375919"
  },
  {
    "text": "so if you have an idea that you think would be well aligned with this project would encourage you to take a look at the page and apply",
    "start": "375919",
    "end": "382319"
  },
  {
    "text": "the second thing that we we've done to make scientific computing on aws easier is focus on our partnerships with",
    "start": "382319",
    "end": "388319"
  },
  {
    "text": "education and research networks around the world and so we today we have peering in place with every major academic and research",
    "start": "388319",
    "end": "395840"
  },
  {
    "text": "network you see a few of the the major examples displayed on the slide here and uh furthermore we're we're now",
    "start": "395840",
    "end": "402800"
  },
  {
    "text": "starting to waive egress fees for research workers for research workloads that are data or",
    "start": "402800",
    "end": "408080"
  },
  {
    "text": "computationally intensive and the purpose of this is to make uh the the the cost of using",
    "start": "408080",
    "end": "413440"
  },
  {
    "text": "aws very predictable for the research community so that it's easier to write cloud resources into into the grants",
    "start": "413440",
    "end": "418880"
  },
  {
    "text": "that you're submitting and so if you'd like more information on this program i encourage you to reach out to your aws",
    "start": "418880",
    "end": "424080"
  },
  {
    "text": "account manager and we can we can help you take advantage of cloud resources and uh and simplify procurement of aws",
    "start": "424080",
    "end": "432400"
  },
  {
    "text": "uh maybe one more thing on the on the topic of research networks in addition to having peering with with the networks",
    "start": "432400",
    "end": "438479"
  },
  {
    "text": "in the way that many institutions do we've also now begun to build a dedicated appearing",
    "start": "438479",
    "end": "443919"
  },
  {
    "text": "for specific projects so the the large hadron collider at cern for example generates a pretty sizable",
    "start": "443919",
    "end": "449680"
  },
  {
    "text": "amount of data each year and the energy sciences network uh esnet which is the the department of energy's network has",
    "start": "449680",
    "end": "456240"
  },
  {
    "text": "partnered with amazon and pacific northwest gigapop to uh to establish 100",
    "start": "456240",
    "end": "461440"
  },
  {
    "text": "gigabit peering through our our u.s west 2 region in oregon all the way to cern so now the",
    "start": "461440",
    "end": "467680"
  },
  {
    "text": "high energy physics community has access to all of amazon's resources and the ability to easily transfer data back and",
    "start": "467680",
    "end": "473440"
  },
  {
    "text": "forth at scale something else that our team focuses on",
    "start": "473440",
    "end": "478720"
  },
  {
    "text": "is a public policy so great if you can you have the means to acquire amazon you",
    "start": "478720",
    "end": "483840"
  },
  {
    "text": "figure out building we've simplified that you have the network capacity but it sometimes takes a little while",
    "start": "483840",
    "end": "490000"
  },
  {
    "text": "for policy to catch up with the capabilities that the cloud offers and one area that that was a little bit murky a little bit",
    "start": "490000",
    "end": "496080"
  },
  {
    "text": "cloudy for researchers was genomics especially human genomics applications and so if you looked at the nih policy",
    "start": "496080",
    "end": "502319"
  },
  {
    "text": "around working with with human genomic data in a cloud environment a year ago the policy stated you can't have this",
    "start": "502319",
    "end": "508960"
  },
  {
    "text": "type of data on computers that are connected to the internet and so we've worked very closely with the nih",
    "start": "508960",
    "end": "514800"
  },
  {
    "text": "to say is the vpc is amazon virtual private cloud and vpns",
    "start": "514800",
    "end": "520399"
  },
  {
    "text": "and using ipsec encryption is that the internet or is that something different and so we i worked very closely with the",
    "start": "520399",
    "end": "526160"
  },
  {
    "text": "nih and with a number of the institutions at the nih funds to develop security best practices that show very",
    "start": "526160",
    "end": "531279"
  },
  {
    "text": "clearly how one could safely and securely and respecting patient privacy store and analyze",
    "start": "531279",
    "end": "536800"
  },
  {
    "text": "and access this data and collaborate on these types of human genomics applications in a cloud environment and so a policy that was announced by the",
    "start": "536800",
    "end": "543279"
  },
  {
    "text": "nih director francis collins last week references this document that was co-authored by",
    "start": "543279",
    "end": "549120"
  },
  {
    "text": "a couple of folks with an amazon that that says here is step by step how you could deploy these types of applications",
    "start": "549120",
    "end": "554480"
  },
  {
    "text": "in the cloud so if you're working with these types of workloads please take a look at slash genomics link to those papers on the",
    "start": "554480",
    "end": "559839"
  },
  {
    "text": "left-hand side of the page and so i wanted to now focus shift a bit and focus on some specific ways that",
    "start": "559839",
    "end": "566240"
  },
  {
    "text": "researchers are using aws so i've talked a little bit about cern so the large hadron collider just just",
    "start": "566240",
    "end": "572560"
  },
  {
    "text": "came back online it's been shut down for about a year and a half as they've been going through an upgrade to increase the the energy of the of the",
    "start": "572560",
    "end": "579760"
  },
  {
    "text": "accelerator so that you've got these protons accelerating and smashing it at higher and higher speeds and also to",
    "start": "579760",
    "end": "585600"
  },
  {
    "text": "increase the sensitivity of these large digital cameras the particle detectors cms and atlas",
    "start": "585600",
    "end": "591600"
  },
  {
    "text": "and over this past year and a half while the engineers were improving the physical instruments we've been working",
    "start": "591600",
    "end": "596959"
  },
  {
    "text": "with the atlas experiment one of the biggest particle detectors at cern to help them determine you know how",
    "start": "596959",
    "end": "603360"
  },
  {
    "text": "could we leverage aws at scale especially ec2 spot both to do stimulation of what might happen when",
    "start": "603360",
    "end": "610079"
  },
  {
    "text": "you have interactions of various types and also to analyze the data of actual interactions to to then be able to",
    "start": "610079",
    "end": "616240"
  },
  {
    "text": "compare those results and it's when you see a difference in what you predicted would happen versus what you observed",
    "start": "616240",
    "end": "621360"
  },
  {
    "text": "that you get a nobel prize and as you can imagine when there's a hint",
    "start": "621360",
    "end": "626560"
  },
  {
    "text": "that you're getting close to maybe understanding the higgs boson or understanding dark matter",
    "start": "626560",
    "end": "631839"
  },
  {
    "text": "there's a race to be the first person to be able to analyze that data and and and show demonstrably how this how this",
    "start": "631839",
    "end": "637839"
  },
  {
    "text": "actually works and so when these type when the conference comes up or when these results are about to be published",
    "start": "637839",
    "end": "644480"
  },
  {
    "text": "there's massive need for computational resources and so we worked with the atlas experiment initially and now cms",
    "start": "644480",
    "end": "650800"
  },
  {
    "text": "to to show that their infrastructure was capable of leveraging hundreds of thousands of cores concurrently using",
    "start": "650800",
    "end": "656880"
  },
  {
    "text": "ec2 spot our available capacity that's not being used uh to very cost effectively and very",
    "start": "656880",
    "end": "664079"
  },
  {
    "text": "quickly run these simulations and analyze the data from the large hadron collider and so now that lhc is back online",
    "start": "664079",
    "end": "671279"
  },
  {
    "text": "we expect to see continued usage of aws by both of the major experiments there",
    "start": "671279",
    "end": "677440"
  },
  {
    "text": "another project we're very excited about is the square kilometer ray so the ska is a radio astronomy project this is the",
    "start": "678320",
    "end": "684079"
  },
  {
    "text": "biggest of big data projects that i'm aware of it's going to it has two phases the first phase will create 2500 linked",
    "start": "684079",
    "end": "690560"
  },
  {
    "text": "radio telescopes across western australia and south africa at the second phase we'll have a quarter million of",
    "start": "690560",
    "end": "695760"
  },
  {
    "text": "these telescopes the first phase will generate exabyte or so i will generate zettabytes zettabytes of raw data which",
    "start": "695760",
    "end": "701680"
  },
  {
    "text": "will then be reduced to three to five exabytes annually of data that will then be published to the global astronomy community and so we're working with the",
    "start": "701680",
    "end": "708720"
  },
  {
    "text": "the ska to help develop the app store for astronomy in the cloud and so i",
    "start": "708720",
    "end": "713920"
  },
  {
    "text": "would encourage you to pay attention to the sk if you're interested in the field of astronomy or super big data",
    "start": "713920",
    "end": "720160"
  },
  {
    "text": "to see ways that you could get involved in helping to create that app store and make it easier for astronomers to not only",
    "start": "720160",
    "end": "725920"
  },
  {
    "text": "manage and work with data at the scale but also to make it easier for astronomers to access data intensive and computational techniques that",
    "start": "725920",
    "end": "732480"
  },
  {
    "text": "maybe are a little bit harder than they should be today a couple of examples of high performance",
    "start": "732480",
    "end": "737920"
  },
  {
    "text": "computing we have automotive manufacturers that are running workloads that maybe many of you thought wouldn't be possible",
    "start": "737920",
    "end": "743040"
  },
  {
    "text": "to run in the cloud this is computational fluid dynamics it's crash simulations these are tightly coupled workloads that are being run in an an",
    "start": "743040",
    "end": "750240"
  },
  {
    "text": "ensemble approach and by that we mean having smaller clusters that are each focusing on on a portion of this",
    "start": "750240",
    "end": "756240"
  },
  {
    "text": "simulation you know working in a very tightly coupled fashion but in aggregate having many clusters that are dividing",
    "start": "756240",
    "end": "761440"
  },
  {
    "text": "up the larger simulation and then merging these results together this has been a very successful approach and we",
    "start": "761440",
    "end": "767440"
  },
  {
    "text": "now see many many members of the automotive community around the world that are sharing these techniques with each other and and starting to",
    "start": "767440",
    "end": "774000"
  },
  {
    "text": "standardize on this this cloud back this cloud-based approach you may have heard about some of the",
    "start": "774000",
    "end": "780320"
  },
  {
    "text": "very large scale workloads that are being run coordinated by cycle computing a great example uh is the uh the",
    "start": "780320",
    "end": "786399"
  },
  {
    "text": "schrodinger uh example of of creating better of analyzing and simulating compounds that might be",
    "start": "786399",
    "end": "792639"
  },
  {
    "text": "uh the next best technology for uh for solar panels and in solar electricity generation and so a researcher at usc um",
    "start": "792639",
    "end": "800959"
  },
  {
    "text": "simulated with molecular dynamics software running on ec2 spot uh 205 000 organic compounds to find which would be",
    "start": "800959",
    "end": "808079"
  },
  {
    "text": "potentially the best for for photovoltaic cells um an amazing amount of work in that you",
    "start": "808079",
    "end": "813680"
  },
  {
    "text": "know 264 years of computation being completed in just 18 hours at a very very reasonable cost for the types of",
    "start": "813680",
    "end": "819920"
  },
  {
    "text": "results that they get and then examples of science as a service applications um the genomics",
    "start": "819920",
    "end": "826160"
  },
  {
    "text": "example that i was mentioning earlier we have many instances of these types of applications running on amazon globus genomics a long time partner of",
    "start": "826160",
    "end": "832560"
  },
  {
    "text": "ours founded out of university of chicago in argonne national lab dna nexus seven bridges genomics there's",
    "start": "832560",
    "end": "838079"
  },
  {
    "text": "there's many players in this field that are making it very easy for clinicians and researchers to work with human",
    "start": "838079",
    "end": "844639"
  },
  {
    "text": "genomic data in a safe and secure and private way on amazon and letting researchers focus",
    "start": "844639",
    "end": "850000"
  },
  {
    "text": "on the science instead of the infrastructure similarly the weather company we have a link to their case study published below using amazon you",
    "start": "850000",
    "end": "857360"
  },
  {
    "text": "know continuing to use amazon at scale to produce some of the world's most accurate weather forecasts and make",
    "start": "857360",
    "end": "862399"
  },
  {
    "text": "these available to consumers and businesses around the world running these simulations on amazon and in a",
    "start": "862399",
    "end": "867839"
  },
  {
    "text": "constant space using our many of our high performance computing instances and then the last example i wanted to",
    "start": "867839",
    "end": "873199"
  },
  {
    "text": "talk about is a it's one that's near and dear to me which is the a project we did with planetary resources an asteroid mining company in",
    "start": "873199",
    "end": "880320"
  },
  {
    "text": "bellevue washington just outside of seattle and nasa tournament labs in the catalina sky survey so we onboarded a",
    "start": "880320",
    "end": "886160"
  },
  {
    "text": "large repository of of of imagery of observations of the night sky",
    "start": "886160",
    "end": "891519"
  },
  {
    "text": "the catalina sky survey as a new amazon public data set and we worked with nasa tournament labs to",
    "start": "891519",
    "end": "897279"
  },
  {
    "text": "have developers create new machine learning algorithms that would run on top of amazon ec2 to",
    "start": "897279",
    "end": "903040"
  },
  {
    "text": "analyze this data to come up with a better mechanism for determining these objects in the sky that are",
    "start": "903040",
    "end": "908880"
  },
  {
    "text": "changing over time are these asteroids is it a satellite is it something else and the result of this work is that",
    "start": "908880",
    "end": "914000"
  },
  {
    "text": "there's now an algorithm machine learning algorithm that's 18 percent better at finding asteroids",
    "start": "914000",
    "end": "919839"
  },
  {
    "text": "and you know this this video which you won't be able to see the whole thing shows just the pace at which new asteroids are being discovered",
    "start": "919839",
    "end": "926560"
  },
  {
    "text": "there's there's several hundred thousand asteroids that are already known using the the previous algorithms we expect to find tens of thousands of new asteroids",
    "start": "926560",
    "end": "933759"
  },
  {
    "text": "by going back through the entire catalina sky survey with this uh with this new algorithm um and doing so at a",
    "start": "933759",
    "end": "939519"
  },
  {
    "text": "very very low cost uh we expect to submit tens of thousands of new asteroids hopefully none of these are on their way you know on their way towards",
    "start": "939519",
    "end": "945759"
  },
  {
    "text": "earth in a dangerous trajectory if they are we'll use the cloud to find that and",
    "start": "945759",
    "end": "951040"
  },
  {
    "text": "come up with a plan um so at this point i'd like to invite uh mike franklin to to come up and talk",
    "start": "951040",
    "end": "957680"
  },
  {
    "text": "about some of the work that's being done at the uc berkeley amp lab so thank you mike for for joining us today",
    "start": "957680",
    "end": "963040"
  },
  {
    "text": "okay well thank you jamie great well um",
    "start": "963040",
    "end": "970000"
  },
  {
    "text": "thanks for having me here um yeah what i want to do is tell you a little bit about uh what we've been",
    "start": "970000",
    "end": "976320"
  },
  {
    "text": "doing at the uh the amp lab across the bay um amazon web services has been one of our",
    "start": "976320",
    "end": "983120"
  },
  {
    "text": "main sponsors and and partners since the beginning of the lab and so um i'm happy to be here to to be able to tell you a",
    "start": "983120",
    "end": "989360"
  },
  {
    "text": "little bit about what we've been up to so um the amp lab is a uh collaboration",
    "start": "989360",
    "end": "996320"
  },
  {
    "text": "in the computer science department at berkeley um we've gotten some nice press about some",
    "start": "996320",
    "end": "1001360"
  },
  {
    "text": "of the impact we've been able to have but the idea is it's a group of about 80 faculty postdocs graduate students",
    "start": "1001360",
    "end": "1008720"
  },
  {
    "text": "undergrads and some staff they come from kind of the spectrum across the spectrum of",
    "start": "1008720",
    "end": "1013839"
  },
  {
    "text": "computer science and so uh if you might know some of the some of the faculty involved",
    "start": "1013839",
    "end": "1019839"
  },
  {
    "text": "but you know our expertise is in data management in machine learning in computer systems uh we have some",
    "start": "1019839",
    "end": "1026558"
  },
  {
    "text": "people who help with security with uh human computer interface and and so on um",
    "start": "1026559",
    "end": "1032160"
  },
  {
    "text": "one of the interesting things about the way we set up the lab is we're about half funded from the federal government",
    "start": "1032160",
    "end": "1038558"
  },
  {
    "text": "so we were one of the projects that was announced when the obama administration",
    "start": "1038559",
    "end": "1045520"
  },
  {
    "text": "put together their big data research initiative back in 2012",
    "start": "1045520",
    "end": "1050640"
  },
  {
    "text": "and we also have 28 companies that we work with closely um as industrial",
    "start": "1050640",
    "end": "1056160"
  },
  {
    "text": "sponsors again amazon uh you know being one of the one of the leading ones um and what we're doing in the amp lab",
    "start": "1056160",
    "end": "1062799"
  },
  {
    "text": "kind of dovetails well with uh some of the examples jamie was just giving the name amp stands for uh algorithms",
    "start": "1062799",
    "end": "1070160"
  },
  {
    "text": "machines and people and the idea is that these are the three very different resources that you have",
    "start": "1070160",
    "end": "1076559"
  },
  {
    "text": "available to make sense of big data so algorithms you know we think about machine learning statistical inference",
    "start": "1076559",
    "end": "1082720"
  },
  {
    "text": "and so on when we talk about machines obviously we're thinking about cloud computing",
    "start": "1082720",
    "end": "1087919"
  },
  {
    "text": "large scale cluster computing so how do you how do you do scale out processing and elastic processing",
    "start": "1087919",
    "end": "1093360"
  },
  {
    "text": "to make sense of big data and then just like we saw in the previous example in the citizen science domain",
    "start": "1093360",
    "end": "1099520"
  },
  {
    "text": "the idea of people here is really twofold one is of course we want to support data scientists and analysts who",
    "start": "1099520",
    "end": "1105600"
  },
  {
    "text": "are trying to make sense of data but the other is you can think about crowds of people uh whether expert and",
    "start": "1105600",
    "end": "1111039"
  },
  {
    "text": "non-expert as a as a resource and in fact we're heavy users of amazon mechanical turk um",
    "start": "1111039",
    "end": "1118000"
  },
  {
    "text": "and other crowd sourcing platforms like that to to to actually uh get people out on the internet to help us collect data",
    "start": "1118000",
    "end": "1124240"
  },
  {
    "text": "to help us uh clean data and even uh to help answer some of the questions uh or",
    "start": "1124240",
    "end": "1130320"
  },
  {
    "text": "the parts of questions that the algorithms and the machines uh can't quite handle yet and so the the the kind",
    "start": "1130320",
    "end": "1136720"
  },
  {
    "text": "of the overall goal of the amp lab is is to build the the the foundation and the infrastructure that can help you combine",
    "start": "1136720",
    "end": "1142880"
  },
  {
    "text": "these three very different types of resources uh in the right proportions uh to solve whatever data analytics problem",
    "start": "1142880",
    "end": "1148960"
  },
  {
    "text": "you're trying to solve okay so that's at a high level what we're doing um more specifically we've been releasing a",
    "start": "1148960",
    "end": "1155919"
  },
  {
    "text": "lot of open source software um so we've we're building something called the berkeley data analytics stack uh those",
    "start": "1155919",
    "end": "1162320"
  },
  {
    "text": "of you some of you might have heard of it it's pronounced it's uh abbreviated bdas that acronym acronym is pronounced",
    "start": "1162320",
    "end": "1168640"
  },
  {
    "text": "badass and um probably the most famous thing we've built is if i don't kill myself here uh",
    "start": "1168640",
    "end": "1175280"
  },
  {
    "text": "is this thing called spark it's now known as apache spark and i'll tell you a little bit more about it but it's it's a",
    "start": "1175280",
    "end": "1181600"
  },
  {
    "text": "it's a processing engine for doing scale out computing but if you look at what we've done all the things in blue are",
    "start": "1181600",
    "end": "1187200"
  },
  {
    "text": "things that we've built in our lab they've all been open sourced a couple of them haven't been quite released yet but they'll be coming out before the",
    "start": "1187200",
    "end": "1193200"
  },
  {
    "text": "summer but you know if you go down to the bottom we've got resource virtualization for taking",
    "start": "1193200",
    "end": "1199120"
  },
  {
    "text": "large physical clusters and allowing people to treat them as individual virtual clusters",
    "start": "1199120",
    "end": "1204159"
  },
  {
    "text": "we do a lot of stuff at the storage level not in actual file systems you know in file systems we use s3 and",
    "start": "1204159",
    "end": "1209919"
  },
  {
    "text": "hadoop file system but you know we've got tachyon which is a caching layer uh built on top of those platforms succinct",
    "start": "1209919",
    "end": "1217200"
  },
  {
    "text": "is a compression layer we've got some work we're doing on encryption and so on in the middle is spark which i'll tell",
    "start": "1217200",
    "end": "1223840"
  },
  {
    "text": "you more about and then above that we have a bunch of different ways of processing data so if you want to run",
    "start": "1223840",
    "end": "1230720"
  },
  {
    "text": "sql queries we have a system called spark sql that lets you do that if you want to run graph algorithms",
    "start": "1230720",
    "end": "1237039"
  },
  {
    "text": "graph x is a way of doing that spark r lets you take programs written in the statistical",
    "start": "1237039",
    "end": "1243360"
  },
  {
    "text": "language r and run those on a cluster using spark we have a streaming interface for uh real-time processing",
    "start": "1243360",
    "end": "1250240"
  },
  {
    "text": "and then we have over on the your right a bunch of stuff for machine learning so",
    "start": "1250240",
    "end": "1257039"
  },
  {
    "text": "ml lib is a very popular distributed machine learning library we have some tools built on top of that to",
    "start": "1257039",
    "end": "1263280"
  },
  {
    "text": "to make machine learning easier to use and then velox is a new system we're building for doing real-time machine",
    "start": "1263280",
    "end": "1269360"
  },
  {
    "text": "learning so we drive our work using a bunch of",
    "start": "1269360",
    "end": "1274480"
  },
  {
    "text": "applications that i'm going to tell you about next but the the basic idea is that um you know each one of these boxes",
    "start": "1274480",
    "end": "1280559"
  },
  {
    "text": "is sort of one or two phd theses you know where we're an academic lab but our students are really committed to",
    "start": "1280559",
    "end": "1286880"
  },
  {
    "text": "building usable um you know industrial strength open source software and so um you know each",
    "start": "1286880",
    "end": "1293440"
  },
  {
    "text": "of these is is is being released um as part of this overall all system that we're doing",
    "start": "1293440",
    "end": "1299600"
  },
  {
    "text": "so um a big part of what we do at amp lab is community building um around the",
    "start": "1299600",
    "end": "1305520"
  },
  {
    "text": "the badass stack and so um um just some things that we do we started",
    "start": "1305520",
    "end": "1312400"
  },
  {
    "text": "about three years ago a meet-up group for spark in san francisco we had you know a few dozen people show up there",
    "start": "1312400",
    "end": "1318320"
  },
  {
    "text": "are now as of last night according to meetup.com uh 57 meetup",
    "start": "1318320",
    "end": "1323520"
  },
  {
    "text": "groups around the world in what 21 different countries",
    "start": "1323520",
    "end": "1328720"
  },
  {
    "text": "we run something called the spark summit we just had our first spark summit east in new york a few weeks ago there'll be",
    "start": "1328720",
    "end": "1335280"
  },
  {
    "text": "another one here in san francisco in the summer where people from the spark community",
    "start": "1335280",
    "end": "1341200"
  },
  {
    "text": "get together to to you know talk about the future of spark and and what they're doing with it uh",
    "start": "1341200",
    "end": "1347120"
  },
  {
    "text": "and then the amp lab itself runs a bunch of things called we call amp camp which are tutorials for for teaching uh people",
    "start": "1347120",
    "end": "1353919"
  },
  {
    "text": "how to use the system so you know part of what we do is is the research and the software development but we're also very",
    "start": "1353919",
    "end": "1359679"
  },
  {
    "text": "active in in building the community around it um in terms of applications i'm just going",
    "start": "1359679",
    "end": "1365679"
  },
  {
    "text": "to mention a couple of them you know in order to figure out whether what we're building is actually going to",
    "start": "1365679",
    "end": "1371039"
  },
  {
    "text": "be useful we looked around campus and in some other universities for scientific",
    "start": "1371039",
    "end": "1377360"
  },
  {
    "text": "applications and other applications to help us drive the research um in terms of genomics we've built a genomics",
    "start": "1377360",
    "end": "1383679"
  },
  {
    "text": "processing pipeline i'm going to tell you about a little later in in the presentation a system called adam",
    "start": "1383679",
    "end": "1390159"
  },
  {
    "text": "and adam was actually uh used recently by some collaborators at uc san francisco",
    "start": "1390159",
    "end": "1396159"
  },
  {
    "text": "to help diagnose uh a very rare disease that the young man in the picture uh had",
    "start": "1396159",
    "end": "1402320"
  },
  {
    "text": "um where he had shown up at a hospital in wisconsin they couldn't figure out what was wrong with him uh they",
    "start": "1402320",
    "end": "1409039"
  },
  {
    "text": "took a sample of his brain fluid sent it to our collaborators at uc san francisco and using our software and a bunch of",
    "start": "1409039",
    "end": "1416080"
  },
  {
    "text": "other stuff that those people had developed they were able to extract out sort of all the human dna and rna in the",
    "start": "1416080",
    "end": "1421600"
  },
  {
    "text": "sample look at what was left and then diagnosed what was wrong with this this boy and and helped cure him so um",
    "start": "1421600",
    "end": "1428960"
  },
  {
    "text": "you know we use this as an example to show that you know there's a lot of people interested in",
    "start": "1428960",
    "end": "1434799"
  },
  {
    "text": "big data you know for serving ads and for you know uh doing all sorts of",
    "start": "1434799",
    "end": "1440080"
  },
  {
    "text": "things but if you can process this kind of information really quickly you can have you know a real impact on on people's",
    "start": "1440080",
    "end": "1446960"
  },
  {
    "text": "lives so i'll tell you a little bit more about that another thing i'll just mention briefly",
    "start": "1446960",
    "end": "1453120"
  },
  {
    "text": "is an application we built called carrot which basically runs on a cell phone",
    "start": "1453120",
    "end": "1458960"
  },
  {
    "text": "watches what applications you're running and what's happening uh to the battery with those applica when those applications",
    "start": "1458960",
    "end": "1465440"
  },
  {
    "text": "are running and then collects all that information uh into the cloud um and then builds models of how different",
    "start": "1465440",
    "end": "1472480"
  },
  {
    "text": "applications use the battery on different phones with different operating systems and what that lets you",
    "start": "1472480",
    "end": "1477520"
  },
  {
    "text": "do is you know for any individual user you know you these reports get uploaded to",
    "start": "1477520",
    "end": "1483200"
  },
  {
    "text": "the cloud they get a report back that says hey you know we noticed that with your phone you know whenever you run you",
    "start": "1483200",
    "end": "1489520"
  },
  {
    "text": "know this certain application your battery drains really quickly and we can tell from looking at",
    "start": "1489520",
    "end": "1495200"
  },
  {
    "text": "other examples that if you stopped running that application your battery would last an extra you know hour and 27",
    "start": "1495200",
    "end": "1501120"
  },
  {
    "text": "minutes a day right um or we could say hey you know whenever you run this map application",
    "start": "1501120",
    "end": "1506320"
  },
  {
    "text": "your battery drains really fast other people that have your phone don't have that problem um so maybe you need to",
    "start": "1506320",
    "end": "1512159"
  },
  {
    "text": "uninstall it and reinstall it because something's wrong there and the reason i like to show this example is because",
    "start": "1512159",
    "end": "1517360"
  },
  {
    "text": "it's sort of the classic example of of big data and why it's important because if you do this type of analysis on a",
    "start": "1517360",
    "end": "1524000"
  },
  {
    "text": "couple dozen phones you don't see anything there's no useful information there but",
    "start": "1524000",
    "end": "1529360"
  },
  {
    "text": "if you can start to get more and more information and in our case we've had almost a million downloads of this application now",
    "start": "1529360",
    "end": "1536000"
  },
  {
    "text": "that's when you can start to see these greater patterns okay so you can see patterns across the whole population and",
    "start": "1536000",
    "end": "1542000"
  },
  {
    "text": "then you can use what you find in those patterns to then make very specific recommendations back to people about",
    "start": "1542000",
    "end": "1547200"
  },
  {
    "text": "what they should be doing and you know it's maybe a little glib but you don't have to think too hard to",
    "start": "1547200",
    "end": "1552320"
  },
  {
    "text": "to look at this pattern and this and say okay well that's how medicine is gonna work in the future right that's certainly how advertising is working",
    "start": "1552320",
    "end": "1558559"
  },
  {
    "text": "today um and so you know a lot of times people ask me as a researcher what does big data mean",
    "start": "1558559",
    "end": "1565039"
  },
  {
    "text": "this is my example that it's when you finally when you've collected enough data at enough detail to see things that",
    "start": "1565039",
    "end": "1571120"
  },
  {
    "text": "you couldn't see if you if you had less data that's that's the carrot application",
    "start": "1571120",
    "end": "1577200"
  },
  {
    "text": "so what we've been doing in terms of building out the the badass stack is um you know we're inspired like a lot of",
    "start": "1577200",
    "end": "1583679"
  },
  {
    "text": "people by the google map reduce system um for for doing scalable parallel processing and what a lot of people did",
    "start": "1583679",
    "end": "1590559"
  },
  {
    "text": "is they said hey you know mapreduce is really good but it's not really good for what i want to do right because i want to do graph",
    "start": "1590559",
    "end": "1596720"
  },
  {
    "text": "processing or i want to run database queries or i want to do real-time processing and so there was this",
    "start": "1596720",
    "end": "1602159"
  },
  {
    "text": "explosion of new systems developed across the world where people took the basic idea of",
    "start": "1602159",
    "end": "1607919"
  },
  {
    "text": "mapreduce but then changed it in some way so to solve their particular problem so",
    "start": "1607919",
    "end": "1613200"
  },
  {
    "text": "they they basically specialized it and the problem with that of course is",
    "start": "1613200",
    "end": "1618880"
  },
  {
    "text": "if you as a user want to build a real end-to-end application you end up having to use all these different",
    "start": "1618880",
    "end": "1624400"
  },
  {
    "text": "systems that were not built together you often have to copy data from you",
    "start": "1624400",
    "end": "1630080"
  },
  {
    "text": "know into one system process it write it out read it into the next system and so on so it's very inefficient and it's",
    "start": "1630080",
    "end": "1635840"
  },
  {
    "text": "incredibly error-prone because all these systems are you know open source they're always changing uh frequently so amplab",
    "start": "1635840",
    "end": "1642240"
  },
  {
    "text": "took a different approach and we said okay well rather than specialize mapreduce to solve all these different problems let's generalize it let's make",
    "start": "1642240",
    "end": "1648880"
  },
  {
    "text": "it do more and have a single system that solves a lot of problems and so it turns out that",
    "start": "1648880",
    "end": "1654960"
  },
  {
    "text": "you really only have to make two two basic changes to map reduce to pull this off um one is you need to be able to do",
    "start": "1654960",
    "end": "1661600"
  },
  {
    "text": "more than map and reduce right so you have to have more general um more general processing uh",
    "start": "1661600",
    "end": "1668960"
  },
  {
    "text": "models uh in particular uh directed acyclic graph solves a lot of the problems so you want to have a richer",
    "start": "1668960",
    "end": "1674480"
  },
  {
    "text": "programming model and then the second thing is you want to allow the different parts of your computation to ch to share",
    "start": "1674480",
    "end": "1680320"
  },
  {
    "text": "data without having to write it back out to the file system and read it back in and if you solve those two problems you",
    "start": "1680320",
    "end": "1686960"
  },
  {
    "text": "can then address all those different use cases we saw before so what we've done here is we're",
    "start": "1686960",
    "end": "1692799"
  },
  {
    "text": "using spark as sort of an underlying substrate and then on top of that we've built a sql engine we've built a",
    "start": "1692799",
    "end": "1698080"
  },
  {
    "text": "streaming engine we've built a graph analytics engine we've built a machine learning system and what's nice about this is then",
    "start": "1698080",
    "end": "1704399"
  },
  {
    "text": "within that single unifying framework you can look at the data the way you",
    "start": "1704399",
    "end": "1709840"
  },
  {
    "text": "need to look at it for the particular problem you're trying to solve you can cobble together all these different modalities these different ways of",
    "start": "1709840",
    "end": "1716320"
  },
  {
    "text": "working with data without having to copy from one system to the next and so this is what we've built in the",
    "start": "1716320",
    "end": "1721440"
  },
  {
    "text": "badass stack and um you know to our pleasant i won't say surprise because",
    "start": "1721440",
    "end": "1726720"
  },
  {
    "text": "that's why we built it but we're you know to we're very pleased that a lot of people are finding this to be a very",
    "start": "1726720",
    "end": "1731919"
  },
  {
    "text": "useful way of thinking about big data uh and and and find that the the ability to",
    "start": "1731919",
    "end": "1737520"
  },
  {
    "text": "to to look at the same data set through all these different lenses is a useful and an important thing and so that's a",
    "start": "1737520",
    "end": "1743120"
  },
  {
    "text": "lot of what's driving uh the adoption of spark out in the real world so spark is sort of at the core of it",
    "start": "1743120",
    "end": "1750480"
  },
  {
    "text": "and um really what made spark catch on is we were able to show that for certain important types",
    "start": "1750480",
    "end": "1757360"
  },
  {
    "text": "of applications it could be a lot faster than hadoop mapreduce",
    "start": "1757360",
    "end": "1762720"
  },
  {
    "text": "and so and i've already told you that we've built the rest of the stack on it and",
    "start": "1762720",
    "end": "1767919"
  },
  {
    "text": "about two years ago maybe a little less we donated it to the apache foundation and",
    "start": "1767919",
    "end": "1773919"
  },
  {
    "text": "it's really sort of taken off from that now it's called apache spark so",
    "start": "1773919",
    "end": "1779120"
  },
  {
    "text": "um just quickly um one of the nice things about doing everything in the open source is we get",
    "start": "1779120",
    "end": "1785360"
  },
  {
    "text": "to expand our developer footprint so in the current release of spark there's over 400 developers um and if you look",
    "start": "1785360",
    "end": "1791520"
  },
  {
    "text": "at sort of activity across open source big data projects you know spark has got a lot more going on than than you know a",
    "start": "1791520",
    "end": "1799120"
  },
  {
    "text": "lot of the other projects so there's just a lot of enthusiasm and excitement behind spark right now it's really all these graphs are showing",
    "start": "1799120",
    "end": "1805679"
  },
  {
    "text": "so so really in a nutshell what's interesting about spark um so before spark you know as i mentioned",
    "start": "1805679",
    "end": "1812240"
  },
  {
    "text": "mapreduce was sort of the start of a lot of the excitement around big data processing and the way hadoop mapreduce",
    "start": "1812240",
    "end": "1817440"
  },
  {
    "text": "works is you know if you had some if you're trying to build a model or learn a model on a bunch of data",
    "start": "1817440",
    "end": "1822480"
  },
  {
    "text": "you'd start off with an initial model um you'd have some training data you'd read it in you'd run your maps on it you'd",
    "start": "1822480",
    "end": "1828880"
  },
  {
    "text": "run you know you'd reduce that you'd collect the results and reduce you'd learn the model and you have to write that back out to disk you got a new",
    "start": "1828880",
    "end": "1836640"
  },
  {
    "text": "model and then you say okay well now i want to improve my model and so basically i want to iterate through this process of um",
    "start": "1836640",
    "end": "1843120"
  },
  {
    "text": "of of improving the model right because this is the way a lot of machine learning algorithms work and hadoop map",
    "start": "1843120",
    "end": "1848880"
  },
  {
    "text": "mapreduce forced you basically at each stage to read the data in from disk do",
    "start": "1848880",
    "end": "1854480"
  },
  {
    "text": "your processing write it back out to disk and then when you go to do the next iteration you'd have to read it in from disk again",
    "start": "1854480",
    "end": "1860799"
  },
  {
    "text": "maybe to a completely different machine than the previous uh iteration ran on and so this caused a lot of",
    "start": "1860799",
    "end": "1866000"
  },
  {
    "text": "inefficiencies um you know there's all these reads that you're doing for the maps there's all",
    "start": "1866000",
    "end": "1872399"
  },
  {
    "text": "the writing that you're having to do uh between stages and then having to read it back in again and so",
    "start": "1872399",
    "end": "1878559"
  },
  {
    "text": "what we do in spark is actually pretty kind of obvious once you've seen that that's the problem is we're going to",
    "start": "1878559",
    "end": "1884720"
  },
  {
    "text": "make a much more aggressive and efficient use of memory so what you do is you read the training",
    "start": "1884720",
    "end": "1891039"
  },
  {
    "text": "data into memory and remember where you've put it okay and then you allow the different",
    "start": "1891039",
    "end": "1896480"
  },
  {
    "text": "parts of the computation to communicate not through the disk which is about the slowest way you can communicate on a",
    "start": "1896480",
    "end": "1901760"
  },
  {
    "text": "computer but through memory and when you do this all of a sudden you get",
    "start": "1901760",
    "end": "1907440"
  },
  {
    "text": "these kind of 10x 100x speedups for those iterative applications um",
    "start": "1907440",
    "end": "1912880"
  },
  {
    "text": "compared to uh the hadoop mapreduce type of platform and and you know that was sort of the thing that got people",
    "start": "1912880",
    "end": "1918559"
  },
  {
    "text": "excited about spark when we first released it okay the way we're we're able to do it",
    "start": "1918559",
    "end": "1924960"
  },
  {
    "text": "um is through an abstraction we call uh rdds or resilient distributed data sets",
    "start": "1924960",
    "end": "1930240"
  },
  {
    "text": "and um basically they're just collections of data that span the cluster so that's why it works so well",
    "start": "1930240",
    "end": "1936480"
  },
  {
    "text": "for cloud computing and the important thing is that you want to",
    "start": "1936480",
    "end": "1942320"
  },
  {
    "text": "be able to leverage memory but not lose the fault tolerance benefits that you got in a hadoop map reduced system because",
    "start": "1942320",
    "end": "1948320"
  },
  {
    "text": "when you're running in a big cluster things can happen if you're doing a long computation it's quite likely that a you know a machine",
    "start": "1948320",
    "end": "1955360"
  },
  {
    "text": "or two will fail or somebody will get slow and so you want to be able to recover these pieces individually so that's",
    "start": "1955360",
    "end": "1961519"
  },
  {
    "text": "really what the rdd abstraction lets you do is by having a very narrow interface uh that where you're not allowed to",
    "start": "1961519",
    "end": "1967840"
  },
  {
    "text": "update the rdds but what you can do is transform them into new rdds you can then very efficiently keep track of all",
    "start": "1967840",
    "end": "1973919"
  },
  {
    "text": "the the the lineage or the recipe that got you any piece of data in any part of your computation if you lose that piece",
    "start": "1973919",
    "end": "1980720"
  },
  {
    "text": "of data it's then very easy to go back and recreate just the part of the data that you've lost and so that's what rdds",
    "start": "1980720",
    "end": "1986320"
  },
  {
    "text": "let you do and as we've discussed that simple",
    "start": "1986320",
    "end": "1991760"
  },
  {
    "text": "model this idea of of of data sets that are spread across the cluster that you're not allowed to change you can",
    "start": "1991760",
    "end": "1997760"
  },
  {
    "text": "only transform through this limited um alphabet of uh or language of transformations",
    "start": "1997760",
    "end": "2004399"
  },
  {
    "text": "is powerful enough to represent a bunch of the way people want to process big data so that's kind of the key insight",
    "start": "2004399",
    "end": "2010399"
  },
  {
    "text": "behind behind spark is this idea of rdds if you want to sort of understand this",
    "start": "2010399",
    "end": "2016240"
  },
  {
    "text": "idea of generalization you know basically this is a subset of the operators that spark lets you run on an",
    "start": "2016240",
    "end": "2022720"
  },
  {
    "text": "rdd so you create a new drdd by applying a map or by applying a reduce or by",
    "start": "2022720",
    "end": "2028480"
  },
  {
    "text": "applying any of these other types of functions so if you're a database person you'll recognize join and group by and",
    "start": "2028480",
    "end": "2035039"
  },
  {
    "text": "you know count and things like that and you know there's other transformations so there's",
    "start": "2035039",
    "end": "2040720"
  },
  {
    "text": "a few dozen transformations that you can run on rdds okay so that's what the spark system",
    "start": "2040720",
    "end": "2047039"
  },
  {
    "text": "lets you do um the current release of spark is is uh",
    "start": "2047039",
    "end": "2052638"
  },
  {
    "text": "1.3 it was released uh last month and it comes with um",
    "start": "2052639",
    "end": "2058480"
  },
  {
    "text": "you know these these features here you know the core spark the streaming graph processing machine learning and sql",
    "start": "2058480",
    "end": "2064320"
  },
  {
    "text": "processor um and um as we're building in the lab we're",
    "start": "2064320",
    "end": "2069839"
  },
  {
    "text": "building these other functions um we're making sure that they integrate with the open source version of spark so we're",
    "start": "2069839",
    "end": "2076320"
  },
  {
    "text": "not doing a lot of spark development in the lab anymore um but we're basically like a lot of other people in the world",
    "start": "2076320",
    "end": "2082240"
  },
  {
    "text": "using it as a core component and then we're building around that so what i wanted to do just um",
    "start": "2082240",
    "end": "2088960"
  },
  {
    "text": "to focus on the subject of this particular session is is pull out that genomics application",
    "start": "2088960",
    "end": "2095358"
  },
  {
    "text": "that i mentioned briefly already just to give you a feel for what i think the power of um or the",
    "start": "2095359",
    "end": "2101440"
  },
  {
    "text": "opportunity really is of bringing kind of modern big data technology uh to scientific processing so um we've been",
    "start": "2101440",
    "end": "2110240"
  },
  {
    "text": "working on a genomics uh processing uh pipeline and uh trying to look at at how to",
    "start": "2110240",
    "end": "2118160"
  },
  {
    "text": "um leverage you know cloud computing and this is a big part of our our",
    "start": "2118160",
    "end": "2124720"
  },
  {
    "text": "collaboration with amazon and these types of uh spark based big data infrastructures that that are people are",
    "start": "2124720",
    "end": "2131839"
  },
  {
    "text": "using you know across industries to to process big data and the reason this is important is because genomic data is",
    "start": "2131839",
    "end": "2139119"
  },
  {
    "text": "exploding right so the cost of sequencing genomes is going down much much much faster than the cost of",
    "start": "2139119",
    "end": "2144400"
  },
  {
    "text": "computing and there are new initiatives starting up that are going to collect you know terabytes petabytes of data",
    "start": "2144400",
    "end": "2151520"
  },
  {
    "text": "by sequencing lots of genomes and then being able to do uh comparisons across them and so um in order to be able to do",
    "start": "2151520",
    "end": "2158960"
  },
  {
    "text": "this work you have to be able to run uh efficiently and in order to be able to run efficiently we believe you have to",
    "start": "2158960",
    "end": "2164480"
  },
  {
    "text": "be able to leverage modern hardware and software appropriately",
    "start": "2164480",
    "end": "2169520"
  },
  {
    "text": "so um you know if you look at the state of the art in genomics",
    "start": "2169520",
    "end": "2174640"
  },
  {
    "text": "processing or or you know what people typically do um you know there's a bunch of file formats out there that really",
    "start": "2174640",
    "end": "2180480"
  },
  {
    "text": "aren't meant they don't play very well with existing or with modern uh big data technology",
    "start": "2180480",
    "end": "2187119"
  },
  {
    "text": "a lot of the pipelines are built in a way that there's there's a lot of hidden hidden dependencies in terms of the ordering of",
    "start": "2187119",
    "end": "2193920"
  },
  {
    "text": "the data and the structuring of data so if you wanted to take an existing genomics pipeline and change a little",
    "start": "2193920",
    "end": "2199280"
  },
  {
    "text": "piece of it you could very easily break things because there's some invariant in there that you you've now violated that maybe",
    "start": "2199280",
    "end": "2206000"
  },
  {
    "text": "wasn't even documented anywhere so these pipelines are very brittle and",
    "start": "2206000",
    "end": "2211200"
  },
  {
    "text": "you know beyond that they're just written you know typically at a very low level and so there's a productivity hit",
    "start": "2211200",
    "end": "2217440"
  },
  {
    "text": "and so you know if you look at big data technology and you look at database technology you know for decades people",
    "start": "2217440",
    "end": "2222800"
  },
  {
    "text": "have been trying to solve these exact problems right so there's the idea of data independence where you can specify",
    "start": "2222800",
    "end": "2229200"
  },
  {
    "text": "kind of a logical level what the data needs to look like but separate out sort of the physical implementation of your",
    "start": "2229200",
    "end": "2235680"
  },
  {
    "text": "actual data structures from the way your applications are written okay and this is an incredibly powerful concept",
    "start": "2235680",
    "end": "2241520"
  },
  {
    "text": "something that's been largely missing from scientific computing until recently and so what",
    "start": "2241520",
    "end": "2247760"
  },
  {
    "text": "we've done is we said okay let's take a step back we understand a lot about how to do data processing",
    "start": "2247760",
    "end": "2254079"
  },
  {
    "text": "in commercial environments in a bunch of environments how do we apply those lessons like data independence to",
    "start": "2254079",
    "end": "2259760"
  },
  {
    "text": "scientific computing so in the genomic space we've built a system called atom and um basically it defines these three",
    "start": "2259760",
    "end": "2266960"
  },
  {
    "text": "things there's a data schema so write a logical description of the data and then a way to lay that data out on disk in a",
    "start": "2266960",
    "end": "2273520"
  },
  {
    "text": "way that you can then exploit cluster and elastic resources there's a programming interface that lets you do",
    "start": "2273520",
    "end": "2280240"
  },
  {
    "text": "distributed processing just the way mapreduce or spark kind of lets you leverage parallel computing and then",
    "start": "2280240",
    "end": "2287520"
  },
  {
    "text": "there's you know tools like command line interfaces and other things so you can have an interactive experience when",
    "start": "2287520",
    "end": "2293760"
  },
  {
    "text": "you're working with the data another way to look at atom is really um",
    "start": "2293760",
    "end": "2300800"
  },
  {
    "text": "you know in this kind of layered stack where it's the where at the bottom you sort of have your physical storage and",
    "start": "2300800",
    "end": "2305839"
  },
  {
    "text": "then you know um various data structures at the top you have your your end",
    "start": "2305839",
    "end": "2311359"
  },
  {
    "text": "applications and then the modeling that you do and where they kind of meet is in the middle is is the logical data schema okay so",
    "start": "2311359",
    "end": "2319440"
  },
  {
    "text": "the idea is if you can describe the data logically you can then leverage",
    "start": "2319440",
    "end": "2324480"
  },
  {
    "text": "lots of lots of developments and improvements at the lower levels in terms of storage formats and in terms of",
    "start": "2324480",
    "end": "2330560"
  },
  {
    "text": "you know physical data storage and at the same time you can you know innovate at the at the higher levels for",
    "start": "2330560",
    "end": "2337520"
  },
  {
    "text": "new algorithms and so it's it's not a new lesson it's it's the way you know database systems have been developed",
    "start": "2337520",
    "end": "2343359"
  },
  {
    "text": "since the relational model was was created we're just trying to bring that knowledge you know into the scientific",
    "start": "2343359",
    "end": "2348560"
  },
  {
    "text": "computing realm and so if if you kind of look at what's happening at that middle level we're using open source uh",
    "start": "2348560",
    "end": "2355520"
  },
  {
    "text": "tools like avro to describe the data schema and then that opens up the whole open source",
    "start": "2355520",
    "end": "2361520"
  },
  {
    "text": "world so at the lower levels we're using parquet to store the data we're using spark and hadoop to process the data and",
    "start": "2361520",
    "end": "2368400"
  },
  {
    "text": "so on so the key message here is if you want to get scientific computing moved from sort of",
    "start": "2368400",
    "end": "2374720"
  },
  {
    "text": "the the you know the the kind of the ad hoc bespoke traditional way it's been done",
    "start": "2374720",
    "end": "2381359"
  },
  {
    "text": "into a world where it can leverage all the excitement and the innovation that's happening at big data we believe that the way to do that is by defining a",
    "start": "2381359",
    "end": "2387920"
  },
  {
    "text": "logical schema the right way and so that's the approach we took in adam you're not supposed to be able to read this but the bottom line is the schema",
    "start": "2387920",
    "end": "2394720"
  },
  {
    "text": "is not that complicated okay and again we use the avro format so it it's compatible with a lot of",
    "start": "2394720",
    "end": "2401280"
  },
  {
    "text": "different tools out there and",
    "start": "2401280",
    "end": "2406480"
  },
  {
    "text": "you know there's some details about how we handle metadata and whatever but the important things is it's extensible okay",
    "start": "2406560",
    "end": "2412960"
  },
  {
    "text": "so you define the schema and then you can extend it as applications change and as the underlying data changes",
    "start": "2412960",
    "end": "2419440"
  },
  {
    "text": "um one level below the schema we're going to use modern storage formats to actually put the data on disk in a",
    "start": "2419440",
    "end": "2426400"
  },
  {
    "text": "useful way and so we use parquet which is a a an apache incubator project based on",
    "start": "2426400",
    "end": "2433119"
  },
  {
    "text": "google dremel and what it does is it it's a format for doing uh you know highly uh performant",
    "start": "2433119",
    "end": "2440000"
  },
  {
    "text": "and compressed columnist storage it lets you push predicates down into the file system so you don't have",
    "start": "2440000",
    "end": "2446079"
  },
  {
    "text": "to read all the data every time you want to find something and you know this has benefits like",
    "start": "2446079",
    "end": "2451680"
  },
  {
    "text": "benefits of compression benefits of faster access but more importantly than that um",
    "start": "2451680",
    "end": "2458319"
  },
  {
    "text": "by separating the logical schema from this physical implementation you don't have to worry about things like sort",
    "start": "2458319",
    "end": "2463920"
  },
  {
    "text": "order and and and dependencies from one stage of your processing to the next because that all works out you know at",
    "start": "2463920",
    "end": "2470240"
  },
  {
    "text": "these lower levels of the system okay and so you know this is kind of the key to making it work um",
    "start": "2470240",
    "end": "2477760"
  },
  {
    "text": "i'm going to skip that just right to what this lets you do so this is a bit of an eye chart and i",
    "start": "2477760",
    "end": "2483520"
  },
  {
    "text": "apologize but at the top we ran sort of the traditional what's called the gatk",
    "start": "2483520",
    "end": "2489359"
  },
  {
    "text": "genomics pipeline where you know from the beginning to the end it takes um in this particular case",
    "start": "2489359",
    "end": "2495680"
  },
  {
    "text": "about 20 you know two what's it say 2075 minutes so um",
    "start": "2495680",
    "end": "2502160"
  },
  {
    "text": "you have to do the math on that in terms of how many uh hours that is to run on a single node",
    "start": "2502160",
    "end": "2509040"
  },
  {
    "text": "with our system atom we can run on a single node at about the same speed um these are old results i'll show you",
    "start": "2509040",
    "end": "2515040"
  },
  {
    "text": "some in in a second they're a little better than this but we can run it about the same speed on a single node but then",
    "start": "2515040",
    "end": "2520240"
  },
  {
    "text": "because we're using you know these modern data formats and these major modern tools we can start spreading out",
    "start": "2520240",
    "end": "2526319"
  },
  {
    "text": "across the cluster and across the cloud and so you can run with 32 process 32 machines 64 machine machines 128",
    "start": "2526319",
    "end": "2533359"
  },
  {
    "text": "machines and what you can see is we can get that time down from 2 100 hours down",
    "start": "2533359",
    "end": "2538640"
  },
  {
    "text": "to about uh i'm sorry 2100 minutes down to about a little over an hour okay and the cost",
    "start": "2538640",
    "end": "2545040"
  },
  {
    "text": "on on amazon at the time we were in the experiments was about a third okay",
    "start": "2545040",
    "end": "2550480"
  },
  {
    "text": "so there's not a lot of magic going on here it's just saying let's not use the old file formats that kind of constrain",
    "start": "2550480",
    "end": "2556480"
  },
  {
    "text": "us into doing single node processing let's open up to the modern big data world",
    "start": "2556480",
    "end": "2564079"
  },
  {
    "text": "and then take advantage of scale out processing like everybody else is doing with big data and then you get the",
    "start": "2564079",
    "end": "2569200"
  },
  {
    "text": "advantage of that type of scale out processing okay and so that's really the the lesson here",
    "start": "2569200",
    "end": "2575119"
  },
  {
    "text": "this is a more recent result that shows we can actually run on a single node faster than this gatk um",
    "start": "2575119",
    "end": "2582160"
  },
  {
    "text": "platform uh and then you know we're for the various phases of the of the processing and most of them we're",
    "start": "2582160",
    "end": "2587599"
  },
  {
    "text": "getting sort of linear linear um scalability up to 128 nodes",
    "start": "2587599",
    "end": "2593359"
  },
  {
    "text": "and we have a little work to do on some of them um okay so just to wrap up um you know",
    "start": "2593359",
    "end": "2600000"
  },
  {
    "text": "the the atom pro project is one part of what we're doing in amp lab you know we're building an entire uh you know top",
    "start": "2600000",
    "end": "2606160"
  },
  {
    "text": "to bottom stack for big data processing and the key message for scientific computing is that if you want to use you",
    "start": "2606160",
    "end": "2612960"
  },
  {
    "text": "know our stack or a stack like it you really want to start thinking about what's the logical schema of your data",
    "start": "2612960",
    "end": "2618960"
  },
  {
    "text": "use some of the lessons that people have learned the hard way over data management over decades of separating",
    "start": "2618960",
    "end": "2624319"
  },
  {
    "text": "logical data design from the physical data design to you know from the applications that",
    "start": "2624319",
    "end": "2629440"
  },
  {
    "text": "you're actually running and what we're now doing in in our project is we're kind of moving up the",
    "start": "2629440",
    "end": "2635280"
  },
  {
    "text": "stack and so we're looking at how do we make it easier to build these analytics applications how do we make machine",
    "start": "2635280",
    "end": "2640800"
  },
  {
    "text": "learning easier how do we automate a lot of the process of choosing um you know parameter settings for different",
    "start": "2640800",
    "end": "2646480"
  },
  {
    "text": "algorithms for choosing which algorithm to use to do a certain analysis and so on and so if you keep an eye on what",
    "start": "2646480",
    "end": "2651920"
  },
  {
    "text": "we're doing at the amp lab you'll see some of those new systems uh coming out and so um that's really all i have to",
    "start": "2651920",
    "end": "2658400"
  },
  {
    "text": "say if you're interested in what we're doing there's uh the place to find us but with that i think jamie's going to",
    "start": "2658400",
    "end": "2664160"
  },
  {
    "text": "come up and we'll take some questions thank you thanks mike",
    "start": "2664160",
    "end": "2671119"
  },
  {
    "text": "so i'm just going to point you to a couple of additional resources so if you'd like to learn more about high performance computing on amazon big data",
    "start": "2672480",
    "end": "2678960"
  },
  {
    "text": "genomics compliance security we have pages that make it easy to find someone stay up here mike okay",
    "start": "2678960",
    "end": "2685359"
  },
  {
    "text": "but now we'd like to end the presentation and switch over to questions and so but before we take the",
    "start": "2685359",
    "end": "2691839"
  },
  {
    "text": "first question i just want to remind you that uh we we're eagerly seeking your feedback on this presentation so if you could take some time and just complete",
    "start": "2691839",
    "end": "2698000"
  },
  {
    "text": "the survey and let us know what you thought of the presentation we'll we'll read any of those comments uh but at this point if you have",
    "start": "2698000",
    "end": "2703520"
  },
  {
    "text": "questions about psycho about badass technologies then the floor is",
    "start": "2703520",
    "end": "2709599"
  },
  {
    "text": "eventually yours into like the global genomic alliance and kind of the future project and those",
    "start": "2717280",
    "end": "2723359"
  },
  {
    "text": "other overarching data management strategies and then two",
    "start": "2723359",
    "end": "2728800"
  },
  {
    "text": "will this project become",
    "start": "2728800",
    "end": "2733280"
  },
  {
    "text": "if you repeat the question sure so uh there's a twofold question one is um",
    "start": "2739119",
    "end": "2744319"
  },
  {
    "text": "is adam uh going to be part of uh some of these bigger initiatives like the global genomics alliance um so honestly",
    "start": "2744319",
    "end": "2750960"
  },
  {
    "text": "that one first so um the the the main people from our lab who were involved in creating adam were",
    "start": "2750960",
    "end": "2757280"
  },
  {
    "text": "also involved in uh the creation of the the genome alliance and so",
    "start": "2757280",
    "end": "2763040"
  },
  {
    "text": "you know we we're trying to be involved we'd love to be involved and and you know those conversations are ongoing",
    "start": "2763040",
    "end": "2768960"
  },
  {
    "text": "um the second part of the question was what about relationships with cloud errors genomics in particular cloud era's",
    "start": "2768960",
    "end": "2775200"
  },
  {
    "text": "genomics efforts and um i'm not aware of any conversations",
    "start": "2775200",
    "end": "2781839"
  },
  {
    "text": "going on specifically with cloudera but i will say the the the amp lab has been doing",
    "start": "2781839",
    "end": "2787040"
  },
  {
    "text": "everything in in the open source and so um a lot of our software has been picked up by cloudera and and and many of the",
    "start": "2787040",
    "end": "2793760"
  },
  {
    "text": "other uh you know big data vendors and so i i you know it's quite it's quite possible that",
    "start": "2793760",
    "end": "2799839"
  },
  {
    "text": "that you know some of the stuff might end up there uh certainly i think the philosophy that we've had uh in terms of",
    "start": "2799839",
    "end": "2806160"
  },
  {
    "text": "of of how to move scientific computing into this bigger framework of big data processing",
    "start": "2806160",
    "end": "2813200"
  },
  {
    "text": "i think a lot of people will be doing that yeah i'll just add to that a little bit so amazon actually at the invitation of the amp",
    "start": "2813200",
    "end": "2819200"
  },
  {
    "text": "lab really got involved very early on with the global alliance for genomics and health ga4gh",
    "start": "2819200",
    "end": "2825280"
  },
  {
    "text": "and we have several members of aws that are active participants on",
    "start": "2825280",
    "end": "2830720"
  },
  {
    "text": "normalizing or trying to come up with more consistent health policies genomics uh privacy policies around the world to",
    "start": "2830720",
    "end": "2836880"
  },
  {
    "text": "develop better tools and apis for exchanging information and doing analysis across multiple large-scale",
    "start": "2836880",
    "end": "2842400"
  },
  {
    "text": "repositories of genomic data and and publishing technical and economic benchmarks on on various approaches that",
    "start": "2842400",
    "end": "2848480"
  },
  {
    "text": "you might use so that we can come up with the best techniques for analyzing this data at scale so that we can get to those fantastic outcomes and so this is",
    "start": "2848480",
    "end": "2854880"
  },
  {
    "text": "it's very important i think to both of our organizations yes any other any other questions",
    "start": "2854880",
    "end": "2860720"
  },
  {
    "text": "yes",
    "start": "2860720",
    "end": "2862960"
  },
  {
    "text": "no no i wish we could take credit for that so the question is did you know was it amazon who was",
    "start": "2866880",
    "end": "2872160"
  },
  {
    "text": "responsible for the discovery of the higgs boson no that wasn't us um the but the the teams that the the cms and the",
    "start": "2872160",
    "end": "2878559"
  },
  {
    "text": "atlas particle detectors that you know the and the the collaborations of several thousand researchers behind each",
    "start": "2878559",
    "end": "2883760"
  },
  {
    "text": "of those um that found the higgs boson um have been using aws to do some of the",
    "start": "2883760",
    "end": "2890079"
  },
  {
    "text": "simulations and analysis up to the up leading up to the the first of the long shutdowns now that lhc the large",
    "start": "2890079",
    "end": "2896480"
  },
  {
    "text": "hydrogen collector is back online they're focusing on you know questions related to super symmetry dark matter",
    "start": "2896480",
    "end": "2901520"
  },
  {
    "text": "dark energy um and and finding some you know some particles uh at higher energies and amazon will play will play",
    "start": "2901520",
    "end": "2908960"
  },
  {
    "text": "a very significant role in in the compute and data analysis uh behind those discoveries but the science yeah",
    "start": "2908960",
    "end": "2914800"
  },
  {
    "text": "that's uh that's members of a very large global community of high energy physicists",
    "start": "2914800",
    "end": "2920559"
  },
  {
    "text": "thanks",
    "start": "2920559",
    "end": "2923520"
  }
]
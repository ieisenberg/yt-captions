[
  {
    "text": "all right hopefully everyone's nice and full from lunch this is the Amazon rev",
    "start": "0",
    "end": "7170"
  },
  {
    "text": "53 deep dive session on delivering resiliency and minimizing latency I'm Li Ming Zen dev manager for the rep 53 team",
    "start": "7170",
    "end": "14009"
  },
  {
    "text": "Yosef Munoz should re here from La Glee I'm gonna be talking primarily about increasing your applications",
    "start": "14009",
    "end": "20340"
  },
  {
    "text": "availability through the use of route 53 and what we really want to do is",
    "start": "20340",
    "end": "25859"
  },
  {
    "text": "increase the resiliency of your infrastructure to failure and minimize the latency to recovery we'll also touch",
    "start": "25859",
    "end": "32700"
  },
  {
    "text": "briefly on network latency but focus mainly on reducing downtime for your web applications so what are we going to",
    "start": "32700",
    "end": "41280"
  },
  {
    "text": "talk about today we're going to first talk about routing within a region and specifically how you can actually shift",
    "start": "41280",
    "end": "46950"
  },
  {
    "text": "traffic between different parts of your stack in a particular region it will also touch briefly on deployment",
    "start": "46950",
    "end": "52739"
  },
  {
    "text": "strategies how you can actually model your deployment strategy in conjunction with the routing that we're going to talk about we'll talk about conditional",
    "start": "52739",
    "end": "59850"
  },
  {
    "text": "routing trees this is the real meat of the presentation here we'll be talking about how you can actually use health",
    "start": "59850",
    "end": "65158"
  },
  {
    "text": "checks and alias trees to come up with really interesting decision tree systems",
    "start": "65159",
    "end": "70650"
  },
  {
    "text": "for your routing in route 53 Munoz will talk about how lovely uses some of the",
    "start": "70650",
    "end": "75960"
  },
  {
    "text": "techniques that I'll be talking about and then we'll finally talk about multi region routing in route 53 across your",
    "start": "75960",
    "end": "81840"
  },
  {
    "text": "global infrastructure and then some things you can do with the client to improve your availability we're not",
    "start": "81840",
    "end": "88140"
  },
  {
    "text": "going to show a whole lot of code but we are going to show a lot of diagrams and this is really the most tech screen to",
    "start": "88140",
    "end": "93869"
  },
  {
    "text": "see all day so please bow your seatbelts",
    "start": "93869",
    "end": "99890"
  },
  {
    "text": "all right let's build a web application so we're going to walk through building",
    "start": "99890",
    "end": "105119"
  },
  {
    "text": "an application from the ground up and how at each step as the application grows we increase its resiliency and its",
    "start": "105119",
    "end": "112920"
  },
  {
    "text": "availability so we're all about building products iteratively here at AWS so",
    "start": "112920",
    "end": "119460"
  },
  {
    "text": "we'll start with a blank slate nothing what's the bare minimum we need for",
    "start": "119460",
    "end": "124469"
  },
  {
    "text": "application we need a way to point traffic at our applications so let's buy a domain in a hosted zone you can do",
    "start": "124469",
    "end": "132120"
  },
  {
    "text": "that with route 53 we have domain registrations so we'll register we and dotnet don't try to do",
    "start": "132120",
    "end": "138579"
  },
  {
    "text": "that actually I actually do own this domain so please don't try to register it and you comes with a hosted zone and we'll",
    "start": "138579",
    "end": "145840"
  },
  {
    "text": "will point that to a load balancer and that load balancer will have a bunch of instances underneath it most of you",
    "start": "145840",
    "end": "151269"
  },
  {
    "text": "probably are familiar with a configuration that looks like this and we have an auto scaling group for those instances you may decide that hey let's",
    "start": "151269",
    "end": "159370"
  },
  {
    "text": "build it let's make it more tiered let's let's make this thing a little bit better so we'll put it into a BBC and",
    "start": "159370",
    "end": "164400"
  },
  {
    "text": "we'll have some back-end instances and then we'll use route 53 private DNS to",
    "start": "164400",
    "end": "169720"
  },
  {
    "text": "do the naming within the V PC so far so good and this should probably look relatively familiar to mostly people in",
    "start": "169720",
    "end": "176049"
  },
  {
    "text": "this room now we want to monitor the",
    "start": "176049",
    "end": "181420"
  },
  {
    "text": "health of the system and make sure that the system is not failing you can do that in the route 53 console through",
    "start": "181420",
    "end": "187780"
  },
  {
    "text": "setting up alarming so in the replica console in health checks you can click on create alarm and here is the dialog",
    "start": "187780",
    "end": "194859"
  },
  {
    "text": "that you would get will configure the alarm and we can action on it so here we actually publish the failure to an SNS",
    "start": "194859",
    "end": "201459"
  },
  {
    "text": "topic but we don't want to just rely on alarming we want to actually do something about it and you can think of",
    "start": "201459",
    "end": "207340"
  },
  {
    "text": "doing this in two ways one is after you get the alarm do something or have",
    "start": "207340",
    "end": "212889"
  },
  {
    "text": "something happen automatically in conjunction with the alarm and use DNS failover and we'll go through the",
    "start": "212889",
    "end": "218169"
  },
  {
    "text": "comparison between these two things so I'm assuming everyone here is relatively familiar with revell 53 health checks",
    "start": "218169",
    "end": "223180"
  },
  {
    "text": "and the ability to associate them with resource record sets so at the time of",
    "start": "223180",
    "end": "229720"
  },
  {
    "text": "failure it takes about 30 seconds for detection so this is assuming we are",
    "start": "229720",
    "end": "235389"
  },
  {
    "text": "using a health check with 10 second intervals and three consecutive checks for the health check to declare that system as unhealthy so after the",
    "start": "235389",
    "end": "243909"
  },
  {
    "text": "detection there's notification so route 53 integrates with cloud watch we published the metric you receive the",
    "start": "243909",
    "end": "249699"
  },
  {
    "text": "notification on SNS and then you do something about it so that's going to take you another 5 minutes and 30 seconds so now we're at 5 minutes and 30",
    "start": "249699",
    "end": "255909"
  },
  {
    "text": "seconds you may decide to update DNS as part of the failure replica to change",
    "start": "255909",
    "end": "262210"
  },
  {
    "text": "propagation is really fast it's 60 seconds your dns propagation happens in sixty Seconds to our 50-plus edge",
    "start": "262210",
    "end": "267940"
  },
  {
    "text": "locations around the world and then let's assume that the record has a TTL of 60 seconds then it will take seven",
    "start": "267940",
    "end": "274420"
  },
  {
    "text": "minutes and thirty seconds from the time of failure before the application is recovered in comparison we have the",
    "start": "274420",
    "end": "283330"
  },
  {
    "text": "failure the detection but if we rely on DNS failover it happens instantaneously",
    "start": "283330",
    "end": "289450"
  },
  {
    "text": "and the reason for this is all of our health checkers in RAL 53 are publishing the health status to every one of our",
    "start": "289450",
    "end": "296320"
  },
  {
    "text": "DNS servers globally so every one of those DNS servers is constantly picking up the status of the health and deciding",
    "start": "296320",
    "end": "303490"
  },
  {
    "text": "to route and return answers differently based on that and again we have the TTL",
    "start": "303490",
    "end": "309310"
  },
  {
    "text": "so by relying on failover you go on DNS failover your going to get a one minute thirty one second",
    "start": "309310",
    "end": "315250"
  },
  {
    "text": "recovery from the time of failure so that's a huge difference in the time your application is down so really what",
    "start": "315250",
    "end": "321370"
  },
  {
    "text": "I want to emphasize here is as much as possible in your applications use DNS failover to recover as fast as you can",
    "start": "321370",
    "end": "329020"
  },
  {
    "text": "and then use the notification more as a recovery step or more as a replacing",
    "start": "329020",
    "end": "334270"
  },
  {
    "text": "step than as the actual immediate mitigation step let's go back to the",
    "start": "334270",
    "end": "340600"
  },
  {
    "text": "application we were building reinvent so originally I had this diagram with all",
    "start": "340600",
    "end": "345730"
  },
  {
    "text": "these hosts behind that you'll be here I'm just going to use a single ELB to represent the stack so now we are going",
    "start": "345730",
    "end": "351760"
  },
  {
    "text": "to bring up two stacks prod 1 and prod 2 in addition to those two stacks we're",
    "start": "351760",
    "end": "357370"
  },
  {
    "text": "also going to add another thing to this to this diagram which is the fail wail some of you may be familiar with this",
    "start": "357370",
    "end": "362980"
  },
  {
    "text": "concept or this term it's also called a Gone Fishing page if you're not familiar with the term fail wail but the idea is",
    "start": "362980",
    "end": "368950"
  },
  {
    "text": "to have something that you can fall back to that's either some kind of degraded experience or some message saying hey we",
    "start": "368950",
    "end": "375580"
  },
  {
    "text": "know there's a problem and this is this is a common set up you might have where you have two stacks you want to deploy",
    "start": "375580",
    "end": "381400"
  },
  {
    "text": "to or shift traffic between and then a really you know worst-case scenario fail wail so you might imagine this diagram",
    "start": "381400",
    "end": "390730"
  },
  {
    "text": "and as we're going to show a lot of these kind of health routing diagrams going forward this is the first example of a conditional read entry we're going",
    "start": "390730",
    "end": "396460"
  },
  {
    "text": "to talk about so just to level set Green Arrow's or the green lines rather",
    "start": "396460",
    "end": "401620"
  },
  {
    "text": "represent the health of the endpoint being checked and the arrows represent traffic flowing and if the line is red",
    "start": "401620",
    "end": "408610"
  },
  {
    "text": "that means the endpoint is unhealthy so here we have prod 1 and prod 2 that are",
    "start": "408610",
    "end": "414280"
  },
  {
    "text": "both healthy and traffic is going to both of them they're weighted in a weighted round robins setup 95 and 5 so",
    "start": "414280",
    "end": "420670"
  },
  {
    "text": "we have more traffic going to prod 1 there's also this concept if you're familiar with rap 53 called evaluate",
    "start": "420670",
    "end": "426910"
  },
  {
    "text": "target health and the idea there is the under long as there's at least one",
    "start": "426910",
    "end": "432340"
  },
  {
    "text": "underlying path that is healthy then the path itself is healthy so here there's an intermediate path between the first",
    "start": "432340",
    "end": "439210"
  },
  {
    "text": "health check and the second health plus weight check that path is healthy for",
    "start": "439210",
    "end": "444610"
  },
  {
    "text": "evaluate target health as long as at least one of the tasks to either prod one or prod to is healthy so let's do a",
    "start": "444610",
    "end": "453220"
  },
  {
    "text": "deployment here so we'll deploy to prod 2 and let's assume that that deployment",
    "start": "453220",
    "end": "459310"
  },
  {
    "text": "goes fine so you have new software running and prod to you now so let's say",
    "start": "459310",
    "end": "466210"
  },
  {
    "text": "we like that software and we dial up the traffic to 50/50 so now we have more traffic flowing to prod 2 with our new",
    "start": "466210",
    "end": "472750"
  },
  {
    "text": "software but let's assume something goes wrong let's assume that there was some",
    "start": "472750",
    "end": "478390"
  },
  {
    "text": "error that we didn't detect at the 5% level but now at the 50% level things whatever reason don't work out if that's",
    "start": "478390",
    "end": "485170"
  },
  {
    "text": "the case the health check will fail and all traffic will go to prod 1 instead and as I mentioned with the evaluate",
    "start": "485170",
    "end": "491230"
  },
  {
    "text": "target health we're still going to come down this path since there's at least one healthy path let's say things are",
    "start": "491230",
    "end": "498400"
  },
  {
    "text": "really weird and for some reason we wrote some shared state and now prod 1 is also failing well if that's true then",
    "start": "498400",
    "end": "505690"
  },
  {
    "text": "evaluate target health will see that the underlying two paths are both unhealthy and it'll Herot the fact that both paths",
    "start": "505690",
    "end": "512950"
  },
  {
    "text": "aren't healthy so it itself becomes unhealthy and now all the traffic will flow to our fail whale this is actually",
    "start": "512950",
    "end": "520840"
  },
  {
    "text": "really easy to set up and route 53 as far as record sets are concerned so the first two record sets represent that",
    "start": "520840",
    "end": "526870"
  },
  {
    "text": "very top of the tree we just looked at so there's the rien net alias to the",
    "start": "526870",
    "end": "532120"
  },
  {
    "text": "prod and then there's the other part that's the failover you can see it's weighted",
    "start": "532120",
    "end": "537730"
  },
  {
    "text": "at zero and I should mention that failover actually works not just with the failover routing type but with any",
    "start": "537730",
    "end": "544000"
  },
  {
    "text": "routing type in route 53 so you can use lbr if you're familiar with that geo dns",
    "start": "544000",
    "end": "549930"
  },
  {
    "text": "wrrr or failover all those actually work with health checks alright so I'm going",
    "start": "549930",
    "end": "559420"
  },
  {
    "text": "to take a brief digression and talk about deployment strategies so in the previous example we discussed a simple a",
    "start": "559420",
    "end": "566890"
  },
  {
    "text": "B style deployment where we were deploying to one stack and then trying to spit up more traffic on that stack",
    "start": "566890",
    "end": "572910"
  },
  {
    "text": "let's go over some other ways to think about how we can actually do deployments to minimize blast waves because that's",
    "start": "572910",
    "end": "578560"
  },
  {
    "text": "what we were really doing we were trying to minimize the blast radius as we were going from small to large so here's a",
    "start": "578560",
    "end": "587950"
  },
  {
    "text": "diagram showing kind of what we were trying to do earlier where we're going to prod - which represents the smaller",
    "start": "587950",
    "end": "593230"
  },
  {
    "text": "of the blast radius is and then we'll push the software to more of the system which represents the larger of the blast",
    "start": "593230",
    "end": "599230"
  },
  {
    "text": "radius here is actually how route 53",
    "start": "599230",
    "end": "605080"
  },
  {
    "text": "deploys its software for DNS servers route 53 has a concept called stripes so",
    "start": "605080",
    "end": "611710"
  },
  {
    "text": "if you're familiar with creating a hosted zone in route 53 you get four name servers when you create a hosted",
    "start": "611710",
    "end": "616870"
  },
  {
    "text": "zone each one of those four name servers corresponds to one stripe and every one",
    "start": "616870",
    "end": "622540"
  },
  {
    "text": "of our edge locations serves exactly one stripe so your four name servers correspond to multiple edge locations so",
    "start": "622540",
    "end": "629950"
  },
  {
    "text": "you may have 10 edge locations responsible for one of your stripes you may have another dozen edge locations",
    "start": "629950",
    "end": "635860"
  },
  {
    "text": "responsible for the second of your stripes etc but each edge location only serves one stripe but one stripe is",
    "start": "635860",
    "end": "643000"
  },
  {
    "text": "served by multiple edge locations and the way we do the software push as we go",
    "start": "643000",
    "end": "648370"
  },
  {
    "text": "from our test or staging environment to the first production edge location and",
    "start": "648370",
    "end": "653560"
  },
  {
    "text": "that's in one stripe so at most we're affecting one of your name servers out",
    "start": "653560",
    "end": "658990"
  },
  {
    "text": "of the four and as we continue pushing the software we stay within that one stripe so we'll push two other edge",
    "start": "658990",
    "end": "665320"
  },
  {
    "text": "locations that are with that same strike so we won't cross strike boundaries so as we're pushing",
    "start": "665320",
    "end": "670990"
  },
  {
    "text": "out the software initially at worst in some kind of catastrophic failure scenario we would only be affecting one",
    "start": "670990",
    "end": "677440"
  },
  {
    "text": "out of the four name servers and then as we continue pushing forward we're only touching one stripe at a time so this is",
    "start": "677440",
    "end": "684100"
  },
  {
    "text": "one way for us to minimize the blast radius as we deploy our software throughout the system so we're matching",
    "start": "684100",
    "end": "689440"
  },
  {
    "text": "our deployment strategy to the failure conditions that exist in DNS our API",
    "start": "689440",
    "end": "697780"
  },
  {
    "text": "works a different way we have three different fleets in our API we have a batch fleet in operations fleet and a",
    "start": "697780",
    "end": "704410"
  },
  {
    "text": "customer fleet the batch fleet is used to process metrics metering small things",
    "start": "704410",
    "end": "711370"
  },
  {
    "text": "like that the operations fleet is used to process a lot of the change propagation or other",
    "start": "711370",
    "end": "717940"
  },
  {
    "text": "things that are relevant to the operation of the system but not directly customer-facing if something goes wrong",
    "start": "717940",
    "end": "723100"
  },
  {
    "text": "with the operation suite it will impact the service but not immediately to the customer experience and then there's the",
    "start": "723100",
    "end": "729580"
  },
  {
    "text": "customer fleet which actually services API requests from customers like yourselves where you're making changes",
    "start": "729580",
    "end": "735820"
  },
  {
    "text": "or listing resource records sets that's that fleet and so we push again from the",
    "start": "735820",
    "end": "741760"
  },
  {
    "text": "smallest blast radius to the largest blast radius we also do something interesting in our staging environment",
    "start": "741760",
    "end": "747880"
  },
  {
    "text": "we have a mixed mode where we run the old version of the software in the new",
    "start": "747880",
    "end": "753670"
  },
  {
    "text": "version of the software at the same time and we do this so that when we run our integration tests we ensure that the",
    "start": "753670",
    "end": "759880"
  },
  {
    "text": "software can run together with no incompatibilities so really what you want to take away from this and think",
    "start": "759880",
    "end": "766030"
  },
  {
    "text": "about is how can you model your own systems and in your own deployment strategy to follow your own blast radius",
    "start": "766030",
    "end": "773610"
  },
  {
    "text": "we actually talk a lot more about this on the AWS architecture blog I encourage you to visit it this is an article on",
    "start": "774090",
    "end": "781060"
  },
  {
    "text": "there called organizing software deployments to match failure conditions",
    "start": "781060",
    "end": "786420"
  },
  {
    "text": "now let's get back to conditional routing trees so we had a really simple simple example and the idea behind",
    "start": "787920",
    "end": "794860"
  },
  {
    "text": "conditional routing trees is to utilize alias resource record sets with health checks",
    "start": "794860",
    "end": "800300"
  },
  {
    "text": "and combine them into decision trees capable of making complex routing",
    "start": "800300",
    "end": "806000"
  },
  {
    "text": "decisions and I'm going to introduce this in in a very simple way we're going to actually talk about a simple example",
    "start": "806000",
    "end": "812840"
  },
  {
    "text": "that that shows us how we can actually return different answers and then we're going to go into a more complex example",
    "start": "812840",
    "end": "818950"
  },
  {
    "text": "later on so in the first example one way we can increase resiliency is to return",
    "start": "818950",
    "end": "825140"
  },
  {
    "text": "more than one record back to a specific client this is especially relevant for web browsers web browsers if they",
    "start": "825140",
    "end": "831410"
  },
  {
    "text": "receive multiple answers in DNS will retry on the other answers they receive if one of them doesn't work how can we",
    "start": "831410",
    "end": "838610"
  },
  {
    "text": "do this you can imagine a decision tree that looks like this it's very simple is host a healthy if it is let's check if",
    "start": "838610",
    "end": "847520"
  },
  {
    "text": "host B is healthy and it host B is healthy let's return the two things together if",
    "start": "847520",
    "end": "853850"
  },
  {
    "text": "host B is not healthy then we just want to return host a and if host a is not",
    "start": "853850",
    "end": "859040"
  },
  {
    "text": "healthy we'll also check if host B is healthy and of course we'll return host beyond on its own if host B is healthy",
    "start": "859040",
    "end": "865160"
  },
  {
    "text": "at this point and if host B is not healthy that means neither end point is healthy we always recommend people as",
    "start": "865160",
    "end": "871220"
  },
  {
    "text": "much as possible they'll open right so here we're gonna return both host day and host B because returning something",
    "start": "871220",
    "end": "877010"
  },
  {
    "text": "is better than returning nothing at least this is a chance that the client can connect to something this is actually exactly how health checks in R",
    "start": "877010",
    "end": "883790"
  },
  {
    "text": "alpha p3 work as well if you have multiple endpoints set up and all the health checks fail route 53 will return",
    "start": "883790",
    "end": "890660"
  },
  {
    "text": "at least one of those things as an answer how does this work in terms of",
    "start": "890660",
    "end": "896180"
  },
  {
    "text": "how to actually configure this in your resource record sets the way to do this",
    "start": "896180",
    "end": "901850"
  },
  {
    "text": "is to always work backwards from the very leaf nodes so we'll first start by",
    "start": "901850",
    "end": "907880"
  },
  {
    "text": "creating the records for the leaf nodes the host a host B record the host a",
    "start": "907880",
    "end": "913550"
  },
  {
    "text": "record and the host B records so you can see the corresponding resource record sets that we would create in route 53 to",
    "start": "913550",
    "end": "919070"
  },
  {
    "text": "represent that as part of our conditional read entry then we're going to build out the internal nodes in this",
    "start": "919070",
    "end": "925520"
  },
  {
    "text": "decision tree this node will call a healthy is represented by these two",
    "start": "925520",
    "end": "932210"
  },
  {
    "text": "records the way this works is at this point we already know that a is healthy so we'll",
    "start": "932210",
    "end": "938660"
  },
  {
    "text": "call the record a healthy and what we want to check is we want to check is be healthy and if it is you'll see that the",
    "start": "938660",
    "end": "944510"
  },
  {
    "text": "value of return is both that's the primary record the failure the failover scenario the secondary record is to",
    "start": "944510",
    "end": "950900"
  },
  {
    "text": "return just host a meaning that host B is not healthy at this point and we'll",
    "start": "950900",
    "end": "956090"
  },
  {
    "text": "do the same thing for the other internal node in the tree I apologize the screen resolution seems to have adjusted the",
    "start": "956090",
    "end": "962300"
  },
  {
    "text": "way that the highlighting works and then finally host a it's the very bottom set",
    "start": "962300",
    "end": "968600"
  },
  {
    "text": "of Records it will return that's how we can actually construct the final trace so we'll point at those two other",
    "start": "968600",
    "end": "974540"
  },
  {
    "text": "internal nodes from this right top node and this material is actually available",
    "start": "974540",
    "end": "981250"
  },
  {
    "text": "online what we've actually constructed is a what we call a rubber tree if you're familiar we actually released an",
    "start": "981250",
    "end": "986900"
  },
  {
    "text": "open-source library last year called route 53 infamous it's available on github and that",
    "start": "986900",
    "end": "993020"
  },
  {
    "text": "actually allows you to construct rubber trees what we've constructed here is a rubber tree with an answer set of two so",
    "start": "993020",
    "end": "1001180"
  },
  {
    "text": "let's go back to our example of Rhian net let's say we have the traffic dial to 50 50 like we were talking about in",
    "start": "1001180",
    "end": "1007930"
  },
  {
    "text": "our active active configuration and instead of things failing is actually working this time even when it's set up",
    "start": "1007930",
    "end": "1014320"
  },
  {
    "text": "like this 50 50 the workload may not actually be consistent between these two endpoints",
    "start": "1014320",
    "end": "1019860"
  },
  {
    "text": "the reason for this is DNS round robin depends on the resolver and clients behind that resolver and so one resolver",
    "start": "1019860",
    "end": "1026530"
  },
  {
    "text": "may have thousands of clients another resolver may only have one you can also imagine API calls being different some",
    "start": "1026530",
    "end": "1033430"
  },
  {
    "text": "API calls cost more than others and you can imagine the traffic pattern making that make making ones endpoint",
    "start": "1033430",
    "end": "1041439"
  },
  {
    "text": "loaded more than the other it'd be great if we can somehow route based on load so",
    "start": "1041440",
    "end": "1048100"
  },
  {
    "text": "route 53 doesn't offer load based routing but we can proxy we can",
    "start": "1048100",
    "end": "1054100"
  },
  {
    "text": "approximate load based routing using conditional writing trees and simple binary health checks this is a contrived",
    "start": "1054100",
    "end": "1061000"
  },
  {
    "text": "example that I made to go through but it shows you the power of conditional routing trees so first we're going to",
    "start": "1061000",
    "end": "1066490"
  },
  {
    "text": "create a health check that sees if prod won that stack has a load less than 50% so if the health",
    "start": "1066490",
    "end": "1072490"
  },
  {
    "text": "check succeeds that means the load on prod 1 is less than 50% if the health check fails it means that the load is",
    "start": "1072490",
    "end": "1078340"
  },
  {
    "text": "greater we'll have another health check that checks to see if prod twos load is less than 50% and again it's a binary",
    "start": "1078340",
    "end": "1085510"
  },
  {
    "text": "thing it's it's true if it's less than 50 it's false if it's greater and if",
    "start": "1085510",
    "end": "1091540"
  },
  {
    "text": "both these things are true will return a record set representing these two things weighted at 50/50 if it fails you can",
    "start": "1091540",
    "end": "1099310"
  },
  {
    "text": "imagine we might want to wait prod one a little bit more because that means prod 2 has more than 50% load and we can go",
    "start": "1099310",
    "end": "1106900"
  },
  {
    "text": "the other way if prod ones load is less than 50% we can start chaining these things together we might check to see if",
    "start": "1106900",
    "end": "1112270"
  },
  {
    "text": "prod ones load is less than 90% maybe we care about this in between case and if",
    "start": "1112270",
    "end": "1117820"
  },
  {
    "text": "it's greater than 90% we can say well let's just shift as much as we can away from prod 1 we'll leave a little bit for",
    "start": "1117820",
    "end": "1123220"
  },
  {
    "text": "it just in case but let's focus mostly on prod 2 in terms of awaiting if prod 1 is between 50 and 90 in terms",
    "start": "1123220",
    "end": "1132340"
  },
  {
    "text": "of its load we might check fraud 2 and here we might decide that if prod 2 is",
    "start": "1132340",
    "end": "1138310"
  },
  {
    "text": "less than 50% we can afford to send more traffic toward prod 2 and if not maybe",
    "start": "1138310",
    "end": "1144190"
  },
  {
    "text": "we just give up and say 50/50 again this is a contrived example what I really want to demonstrate here is you can",
    "start": "1144190",
    "end": "1150040"
  },
  {
    "text": "chain these trees into really complex things like this this only fits on the slide I can bid more right you can make",
    "start": "1150040",
    "end": "1156220"
  },
  {
    "text": "this even deeper you could have even more branches you can add more health checks to add more conditions and this",
    "start": "1156220",
    "end": "1162640"
  },
  {
    "text": "is going to be a feedback loop as the weights get shifted the load is going to shift on the endpoints and the results",
    "start": "1162640",
    "end": "1168550"
  },
  {
    "text": "of the health checks will change and I just want to show quickly what some of",
    "start": "1168550",
    "end": "1174070"
  },
  {
    "text": "the records might look like so again we're going to work backwards from the leaf nodes and create those records so here we have the final thing we want to",
    "start": "1174070",
    "end": "1181450"
  },
  {
    "text": "return which is that what we call the 50/50 stack and then we'll have the internal nodes that we create as well so",
    "start": "1181450",
    "end": "1187420"
  },
  {
    "text": "if you actually go through the exercise of doing this you'll end up with a table that might look something like this so",
    "start": "1187420",
    "end": "1196840"
  },
  {
    "text": "I've talked a lot about various routing techniques I want to hand it off to Munoz tell us about how lovely does this Thank",
    "start": "1196840",
    "end": "1202680"
  },
  {
    "text": "You Lee my name is Manoj and I work for log Lee so what we're going to talk",
    "start": "1202680",
    "end": "1208290"
  },
  {
    "text": "about today is primarily how route 53 we use at logging and how extensive the",
    "start": "1208290",
    "end": "1214350"
  },
  {
    "text": "uses but before we do that I have a question how many of you guys are currently using log management in your",
    "start": "1214350",
    "end": "1222350"
  },
  {
    "text": "product or in your ID ah that's pretty",
    "start": "1222350",
    "end": "1227490"
  },
  {
    "text": "pretty impressive I'm hope I hope it's log lee but if not you guys can always",
    "start": "1227490",
    "end": "1233280"
  },
  {
    "text": "try it out it for free so before and they're a bunch of people I saw who are",
    "start": "1233280",
    "end": "1238740"
  },
  {
    "text": "not using so for the benefit of them let's look at what log Lee does and what log management is so we have a set stage",
    "start": "1238740",
    "end": "1246900"
  },
  {
    "text": "for route 53 usage so log management is basically having all your logs get",
    "start": "1246900",
    "end": "1253500"
  },
  {
    "text": "accumulated at one centralized place so you're debugging your alerting and your",
    "start": "1253500",
    "end": "1258660"
  },
  {
    "text": "analysis become easy so if we take a typical example as Lee's been talking",
    "start": "1258660",
    "end": "1264990"
  },
  {
    "text": "about web applications I'll pick example of web application if you have a web application where you have let's say 20",
    "start": "1264990",
    "end": "1271800"
  },
  {
    "text": "web server 10 app servers and then no sequel databases all of them are",
    "start": "1271800",
    "end": "1277230"
  },
  {
    "text": "generating logs and you want those logs to be all those logs will sit on each of",
    "start": "1277230",
    "end": "1282600"
  },
  {
    "text": "their servers on the local file system so if you have to debug or look into it you have to log into each of those",
    "start": "1282600",
    "end": "1289080"
  },
  {
    "text": "machines to do any kind of analysis or any kind of track what log Lee allows you to do is look at",
    "start": "1289080",
    "end": "1296040"
  },
  {
    "text": "them from one single place from browser so what you can do with it once all your",
    "start": "1296040",
    "end": "1301470"
  },
  {
    "text": "log goes to log Lee you can come to the browser you can search those logs in near-real-time",
    "start": "1301470",
    "end": "1307260"
  },
  {
    "text": "you can debug your logs from that single browser you can create alerts with",
    "start": "1307260",
    "end": "1314760"
  },
  {
    "text": "detect anomalies and in real time and generate alerts for you and also you can",
    "start": "1314760",
    "end": "1320550"
  },
  {
    "text": "basically do the trend analysis log Lee is a completely multi tenant SAS",
    "start": "1320550",
    "end": "1326070"
  },
  {
    "text": "application built on a distributed architecture on top of AWS and we have more than",
    "start": "1326070",
    "end": "1332250"
  },
  {
    "text": "5,000 customers using it so let's look at a little bit log Li data pipeline and",
    "start": "1332250",
    "end": "1339210"
  },
  {
    "text": "how we basically process the logs coming from our customer but we you we say at",
    "start": "1339210",
    "end": "1346799"
  },
  {
    "text": "log lease every single company has a big data problem whether we realize it or",
    "start": "1346799",
    "end": "1351899"
  },
  {
    "text": "not and that first big data problem is log blogs how many times you have seen a",
    "start": "1351899",
    "end": "1359279"
  },
  {
    "text": "DevOps or a IT person get a page at night saying hey the server is running",
    "start": "1359279",
    "end": "1364620"
  },
  {
    "text": "out of this the first thing happens he he wake up go to CD go to the directory",
    "start": "1364620",
    "end": "1370830"
  },
  {
    "text": "of our log truncate the directory and move on but guess that's the most important part of your product because",
    "start": "1370830",
    "end": "1379169"
  },
  {
    "text": "that you need for analysis anyhow so we solve that problem using log lis data",
    "start": "1379169",
    "end": "1384360"
  },
  {
    "text": "pipeline and we divide our pipeline into two part first is ingestion part",
    "start": "1384360",
    "end": "1390799"
  },
  {
    "text": "ingestion part has one mission to collect logs as fast as possible it's",
    "start": "1390799",
    "end": "1397649"
  },
  {
    "text": "pretty much at a network speed line we can collect the log and not drop those log and the first component in this",
    "start": "1397649",
    "end": "1404820"
  },
  {
    "text": "ingestion part is route 53 and we'll talk about that in a detail in next slides and the second part is a",
    "start": "1404820",
    "end": "1413070"
  },
  {
    "text": "processing part what it does is it pulls the log collected by ingestion part",
    "start": "1413070",
    "end": "1419460"
  },
  {
    "text": "which is collector and and basically do our event decorating who this even",
    "start": "1419460",
    "end": "1426600"
  },
  {
    "text": "belongs to convert that unstructured log into structured logs so the analysis can",
    "start": "1426600",
    "end": "1431850"
  },
  {
    "text": "be done and put it into Kafka Kafka for those who don't know is a distributed",
    "start": "1431850",
    "end": "1437789"
  },
  {
    "text": "messaging system it's an open source project out started at LinkedIn and now",
    "start": "1437789",
    "end": "1443789"
  },
  {
    "text": "it's an Apache project so the idea is why we do the storage of logs at every",
    "start": "1443789",
    "end": "1450720"
  },
  {
    "text": "step so that if any machine goes down or any process dies we don't lose",
    "start": "1450720",
    "end": "1457180"
  },
  {
    "text": "any of the log we just basically keep the logs intact and then what we do at",
    "start": "1457180",
    "end": "1462730"
  },
  {
    "text": "the final stage is we pick that logs which is decorated and put it into elasticsearch elasticsearch is another",
    "start": "1462730",
    "end": "1470200"
  },
  {
    "text": "open source it's a search engine which is basically is done by a company named",
    "start": "1470200",
    "end": "1476710"
  },
  {
    "text": "elasticsearch and that's why the product name is but the biggest thing to keep in mind through this pipeline is our",
    "start": "1476710",
    "end": "1483490"
  },
  {
    "text": "customers expect that this whole process get done on in seconds not in a minute",
    "start": "1483490",
    "end": "1490060"
  },
  {
    "text": "if you are sending logs to us you can't wait for it to show in a minute you want",
    "start": "1490060",
    "end": "1495070"
  },
  {
    "text": "that log to show in seconds right there and then and that's that's the big",
    "start": "1495070",
    "end": "1501190"
  },
  {
    "text": "mission of this pipeline so let's look at how route 53 oops I think this dies",
    "start": "1501190",
    "end": "1510420"
  },
  {
    "text": "okay I'll use this for now let's look at the",
    "start": "1510420",
    "end": "1515470"
  },
  {
    "text": "log Lee use case and why route 53 fits our need and is best for us so one of",
    "start": "1515470",
    "end": "1522370"
  },
  {
    "text": "the key requirement we had in the injection part is we should able to handle per part more than 100,000 event",
    "start": "1522370",
    "end": "1530770"
  },
  {
    "text": "per second and event here is equal to each log line which we received from our",
    "start": "1530770",
    "end": "1538330"
  },
  {
    "text": "customer it should able to handle the unpredictable traffic pattern and this",
    "start": "1538330",
    "end": "1543670"
  },
  {
    "text": "is the key and the most important point and a lot of SAS companies you must have",
    "start": "1543670",
    "end": "1549160"
  },
  {
    "text": "heard say talk about it but very few have implemented it what does this mean",
    "start": "1549160",
    "end": "1555250"
  },
  {
    "text": "is that let's take an example of a customer customer sending us a log at a",
    "start": "1555250",
    "end": "1561040"
  },
  {
    "text": "constant pace and suddenly they have a fire and they start sending a huge burst",
    "start": "1561040",
    "end": "1566410"
  },
  {
    "text": "of log so normal rate could be 10 kilobytes per second and suddenly they have issue and they started generating",
    "start": "1566410",
    "end": "1572590"
  },
  {
    "text": "bunch of stack traces it starts sending at that 20 megabytes per second so we",
    "start": "1572590",
    "end": "1578020"
  },
  {
    "text": "should able to handle that load the product the ingestion part should be fault-tolerant it should be",
    "start": "1578020",
    "end": "1584720"
  },
  {
    "text": "fault tolerant to region by zone we should able to use geolocation and the",
    "start": "1584720",
    "end": "1590090"
  },
  {
    "text": "key is we should able to support all these protocols UDP TCP tcp over SSL STP",
    "start": "1590090",
    "end": "1595549"
  },
  {
    "text": "STPs UDP we support because syslog which is the logging library and the RFC for",
    "start": "1595549",
    "end": "1603110"
  },
  {
    "text": "that requires the syslog receivers to implement that and then we basically",
    "start": "1603110",
    "end": "1608390"
  },
  {
    "text": "needed support for port 515 540 now how",
    "start": "1608390",
    "end": "1614150"
  },
  {
    "text": "route 53 helps us because we had these use cases we were evaluating lot of technologies which want to use now",
    "start": "1614150",
    "end": "1622059"
  },
  {
    "text": "unpredictable pattern route 53 handles for us really well because it doesn't",
    "start": "1622059",
    "end": "1628220"
  },
  {
    "text": "require any pre warmup time even if the cousin if you have certain boss from 10",
    "start": "1628220",
    "end": "1633980"
  },
  {
    "text": "kilobytes per second to 200 megabytes per second the traffic will flow at the",
    "start": "1633980",
    "end": "1639380"
  },
  {
    "text": "same rate there is no performance penalty it supports UDP it's supposed TCP all of",
    "start": "1639380",
    "end": "1645500"
  },
  {
    "text": "this it's just transparent to is basically route 53 doesn't care about it",
    "start": "1645500",
    "end": "1650690"
  },
  {
    "text": "and then it obviously allow us to grow geographically and have our ingestion",
    "start": "1650690",
    "end": "1657590"
  },
  {
    "text": "parts serve the servers which is near to the that geolocation so that that's the",
    "start": "1657590",
    "end": "1663919"
  },
  {
    "text": "another thing we needed for the future so how how is our configuration of route",
    "start": "1663919",
    "end": "1669860"
  },
  {
    "text": "53 looks like so this is just the elaborated view of our my previous",
    "start": "1669860",
    "end": "1675440"
  },
  {
    "text": "diagram so we have route 53 as a first component bunch of collector sitting behind that and then the log lea",
    "start": "1675440",
    "end": "1681799"
  },
  {
    "text": "pipeline so each record set is basically has a routing policy which is weighted",
    "start": "1681799",
    "end": "1688100"
  },
  {
    "text": "each record set has a weight of 100 so we can get a simple round-robin through",
    "start": "1688100",
    "end": "1694940"
  },
  {
    "text": "it and we have hope we have lot of health check and that's what I'm going",
    "start": "1694940",
    "end": "1700220"
  },
  {
    "text": "to focus on and our health check was pretty much for every protocol we support collector has a health check for",
    "start": "1700220",
    "end": "1706549"
  },
  {
    "text": "that just to give some numbers we have 600 plus the card set",
    "start": "1706549",
    "end": "1711980"
  },
  {
    "text": "we have 30 health check and we use CLI 53 for",
    "start": "1711980",
    "end": "1717549"
  },
  {
    "text": "managing most of this stuff but the key point to take away is that we do lot of",
    "start": "1717549",
    "end": "1723850"
  },
  {
    "text": "health check across our route 53 deployment and how how that helped us in",
    "start": "1723850",
    "end": "1731110"
  },
  {
    "text": "scaling our application so in normal course of action this is how it looks",
    "start": "1731110",
    "end": "1739210"
  },
  {
    "text": "collector is all function the health cloud watch shows everything is healthy",
    "start": "1739210",
    "end": "1744460"
  },
  {
    "text": "but let's say one of the collector has an issue and it goes out of service",
    "start": "1744460",
    "end": "1750130"
  },
  {
    "text": "route 53 detects that it generates an alarm and what happened is health check",
    "start": "1750130",
    "end": "1759669"
  },
  {
    "text": "detects the collector out of service it sends a notification to us a new",
    "start": "1759669",
    "end": "1765460"
  },
  {
    "text": "collector get added previously so each collector has an elastic IP assigned to",
    "start": "1765460",
    "end": "1771159"
  },
  {
    "text": "it so now when the collector went out of the service route would be three detected it it generated the",
    "start": "1771159",
    "end": "1778090"
  },
  {
    "text": "notification we've spin the new collector and we assign the previous IP of the collector",
    "start": "1778090",
    "end": "1785860"
  },
  {
    "text": "we just had an issue to the new collector so it's just seamless for our customers and it basically helped with",
    "start": "1785860",
    "end": "1793299"
  },
  {
    "text": "no downtime or a performance degradation now as we mentioned that we should rely",
    "start": "1793299",
    "end": "1800260"
  },
  {
    "text": "on the DNS failover this step is more of coming back to full capacity but when",
    "start": "1800260",
    "end": "1807250"
  },
  {
    "text": "the collector goes read the traffic gets served through DNS by rest of the collector so we rely on the most",
    "start": "1807250",
    "end": "1813640"
  },
  {
    "text": "efficient way but then we use health check to recover back the collector which gone back and then once the",
    "start": "1813640",
    "end": "1821860"
  },
  {
    "text": "collector get recover all the health checks become normal and we are back into the state and no no intervention is",
    "start": "1821860",
    "end": "1828220"
  },
  {
    "text": "needed so that's that's the huge advantage the route 53 gave us so just",
    "start": "1828220",
    "end": "1834549"
  },
  {
    "text": "few learnings and in the interest of time I'll go a little faster with this the key and the most important one for",
    "start": "1834549",
    "end": "1842169"
  },
  {
    "text": "us was no warm-up required because the load",
    "start": "1842169",
    "end": "1847750"
  },
  {
    "text": "pattern on our system is very unpredictable we are able to add or",
    "start": "1847750",
    "end": "1853120"
  },
  {
    "text": "scale our ingestion part really easy we can spin off behind the DNS the number",
    "start": "1853120",
    "end": "1859390"
  },
  {
    "text": "of ingestion part and we can scale it across the globe healthcheck huge huge",
    "start": "1859390",
    "end": "1865510"
  },
  {
    "text": "advantage I absolutely say you guys should use as much as you can for the",
    "start": "1865510",
    "end": "1872410"
  },
  {
    "text": "your route 53 deployment it has been a really pleasant experience of using that",
    "start": "1872410",
    "end": "1878020"
  },
  {
    "text": "and obviously then round robin which it provides out of the box so that's all I",
    "start": "1878020",
    "end": "1885370"
  },
  {
    "text": "have but if you have any question I'll be here after the presentation to answer anything you have thank you very much",
    "start": "1885370",
    "end": "1892330"
  },
  {
    "text": "and now we will talk going global no so",
    "start": "1892330",
    "end": "1902130"
  },
  {
    "text": "thanks for sharing your use case Manoj so going back to our example application",
    "start": "1903300",
    "end": "1908410"
  },
  {
    "text": "let's say we did all the conditional routing tree stuff that we talked about we have this system that's routing",
    "start": "1908410",
    "end": "1914530"
  },
  {
    "text": "really well it's resilient to deployment failures we're able to balance on load inside each region but people are",
    "start": "1914530",
    "end": "1922510"
  },
  {
    "text": "starting to complain about latency and if we look at the reports in our example let's say it might turn out that there",
    "start": "1922510",
    "end": "1927520"
  },
  {
    "text": "are a lot of customers now using our application in Europe and Asia one quick",
    "start": "1927520",
    "end": "1932710"
  },
  {
    "text": "solution to this would be just throw cloud front in front of our application but that may not work exactly",
    "start": "1932710",
    "end": "1938050"
  },
  {
    "text": "and by the way if you do want to learn more about cloud front you should check out the performance track session 303",
    "start": "1938050",
    "end": "1943390"
  },
  {
    "text": "that's tomorrow it talks a lot about cool tuning tips for cloud front but in our example using cloud front may not be",
    "start": "1943390",
    "end": "1951030"
  },
  {
    "text": "enough so it's going to help us do things like keep persistent connections open it's going to help us with better",
    "start": "1951030",
    "end": "1957070"
  },
  {
    "text": "path back to our system from all over the globe but it's not going to alleviate the fact",
    "start": "1957070",
    "end": "1962170"
  },
  {
    "text": "that a single user halfway around the world is still going to have to come all the way back to the US so what do we do",
    "start": "1962170",
    "end": "1968620"
  },
  {
    "text": "well we could spin up multiple other regions running the same stack and then",
    "start": "1968620",
    "end": "1974590"
  },
  {
    "text": "there's a question of well how do I route to that well Ralph 53 provides the building blocks for routing across your global",
    "start": "1974590",
    "end": "1980740"
  },
  {
    "text": "infrastructure so let's spin up our three different stacks so here the load",
    "start": "1980740",
    "end": "1987370"
  },
  {
    "text": "balancer icon is now representing the entire stack that we talked about earlier it might be the two prod 1 prod",
    "start": "1987370",
    "end": "1992530"
  },
  {
    "text": "2 stacks or you could just imagine one prod one stack either way and one thing I want to point out is that as you spin",
    "start": "1992530",
    "end": "1998320"
  },
  {
    "text": "up each of these stacks in different regions one of the cool things you can do is you can actually associate the",
    "start": "1998320",
    "end": "2003330"
  },
  {
    "text": "same private DNS zone that we had associated with the V PC with every single one of the pcs in these regions",
    "start": "2003330",
    "end": "2009480"
  },
  {
    "text": "so private DNS allows you to associate multiple V pcs to a single zone and share that configuration",
    "start": "2009480",
    "end": "2015200"
  },
  {
    "text": "so let's route between these different stacks using latency based routing if",
    "start": "2015200",
    "end": "2020640"
  },
  {
    "text": "you're not familiar route 53 offers latency based routing which routes based on the latency of the end user to the",
    "start": "2020640",
    "end": "2027180"
  },
  {
    "text": "edge located to the location that's being requested so if a user were coming from Japan they would likely get routed",
    "start": "2027180",
    "end": "2034140"
  },
  {
    "text": "to AP North East one if a user were coming from California they would get likely routed to us West - it's called",
    "start": "2034140",
    "end": "2040890"
  },
  {
    "text": "latency based routing because we have observed times when actually latency is not exactly the same as geography so",
    "start": "2040890",
    "end": "2047070"
  },
  {
    "text": "there are times when a customer from Singapore may be better served actually out of Japan than from Singapore itself",
    "start": "2047070",
    "end": "2052230"
  },
  {
    "text": "this is the way this is due to the way that certain ISPs have their have their networks configured you may also imagine",
    "start": "2052230",
    "end": "2060929"
  },
  {
    "text": "that you might have customers in places where AWS doesn't have regions so for example Africa you could use route 53",
    "start": "2060929",
    "end": "2067770"
  },
  {
    "text": "geo DNS in conjunction with lbr to configure this example so here we can",
    "start": "2067770",
    "end": "2073980"
  },
  {
    "text": "actually route customers from Africa to your own Africa data center that you've set up and then if they're not coming",
    "start": "2073980",
    "end": "2080340"
  },
  {
    "text": "from Africa they'll hit the default record and then still be used they'll still use latency based routing to route",
    "start": "2080340",
    "end": "2086520"
  },
  {
    "text": "them to your infrastructure so you can combine these two concepts together if",
    "start": "2086520",
    "end": "2091980"
  },
  {
    "text": "you're not familiar with geo DNS the way it works is it always uses the most specific routing possible so here",
    "start": "2091980",
    "end": "2098040"
  },
  {
    "text": "someone's coming from Africa it I'll use that path ever if it's not specific enough it'll use the default and of",
    "start": "2098040",
    "end": "2104880"
  },
  {
    "text": "course failover works with all these routing types as I mentioned earlier so if any one of these endpoints were",
    "start": "2104880",
    "end": "2110080"
  },
  {
    "text": "fail route 53 will not serve that answer back assuming you have health checks configured for that end point so it may",
    "start": "2110080",
    "end": "2119260"
  },
  {
    "text": "turn out that you have this set up it's working great latency is reduced for your end users but you may have specific",
    "start": "2119260",
    "end": "2126160"
  },
  {
    "text": "tax requirements let's say in Japan where they have consumption tax you can actually easily bypass Li and C based",
    "start": "2126160",
    "end": "2133120"
  },
  {
    "text": "routing and just route directly to ap northeast one using geo DNS so again the flexibility in the power of using these",
    "start": "2133120",
    "end": "2139690"
  },
  {
    "text": "conditional write entries with some of the multi region rounding features that route 53 has I should know that you",
    "start": "2139690",
    "end": "2146890"
  },
  {
    "text": "can't you still want to do application layer checks because we're not really sure for sure if someone's coming from",
    "start": "2146890",
    "end": "2152140"
  },
  {
    "text": "Chan you can imagine someone's using a Japanese was Oliver but maybe their client is somewhere else you can maybe over VPN or something like that so you",
    "start": "2152140",
    "end": "2158710"
  },
  {
    "text": "want to do the application layer check but here at least we've reduced a lot of the checks that have to happen up front",
    "start": "2158710",
    "end": "2165060"
  },
  {
    "text": "all right so at this point we've built a multi vision application that does a number of pretty interesting routing",
    "start": "2165060",
    "end": "2170530"
  },
  {
    "text": "techniques we talked about routing unload and kind of being able to be resilient to failures how else can we",
    "start": "2170530",
    "end": "2175990"
  },
  {
    "text": "actually reduce the latency during a failure and increase the resiliency of our application so as we talked about a",
    "start": "2175990",
    "end": "2182680"
  },
  {
    "text": "little bit before some clients have smart retry behavior in the case of browsers using multiple IPS if we",
    "start": "2182680",
    "end": "2189700"
  },
  {
    "text": "control the client we can actually do some other interesting things in route 53 as well the first one I'll talk about",
    "start": "2189700",
    "end": "2196990"
  },
  {
    "text": "is shuffle sharding I'm not going to go super in-depth on this we actually have some material online and in previous",
    "start": "2196990",
    "end": "2203440"
  },
  {
    "text": "talks that talk about shuffle sharding but I wanted to give a quick overview since I feel like it I'd be remiss in not mentioning this technique typical",
    "start": "2203440",
    "end": "2211180"
  },
  {
    "text": "sharding gives customers their own stacks so you can imagine one stack per customer typically when you think about",
    "start": "2211180",
    "end": "2217060"
  },
  {
    "text": "sharding in shuffle charting what we're doing is we're going to give a customer a unique combination of endpoints and",
    "start": "2217060",
    "end": "2223810"
  },
  {
    "text": "have guarantees about how much overlap there is between those combinations in the example here we're going to give",
    "start": "2223810",
    "end": "2230770"
  },
  {
    "text": "each customer two of the endpoints and guarantee that only one of those endpoints will ever overlap with some",
    "start": "2230770",
    "end": "2237010"
  },
  {
    "text": "other customers combination and that helps us in a failure for example",
    "start": "2237010",
    "end": "2243010"
  },
  {
    "text": "imagine customer one in our diagram who's using shuffle shard one somehow Browns out the",
    "start": "2243010",
    "end": "2250120"
  },
  {
    "text": "end points overloads it and we have poor throttling or something on our service or perhaps there's a poison pill in the",
    "start": "2250120",
    "end": "2255670"
  },
  {
    "text": "API and they generate some kind of API call that takes the API down that we didn't know about some bug well if that",
    "start": "2255670",
    "end": "2261610"
  },
  {
    "text": "were to happen that would only affect customer ones instances and customer two",
    "start": "2261610",
    "end": "2267310"
  },
  {
    "text": "is isolated from this effect so while customer two shares one instance customer two still has another",
    "start": "2267310",
    "end": "2274060"
  },
  {
    "text": "instance that is guaranteed not to be shared by the nature of the way we generate the combinations you can",
    "start": "2274060",
    "end": "2281950"
  },
  {
    "text": "actually learn more about this again on the AWS architecture blog and I also mentioned replica three in from that",
    "start": "2281950",
    "end": "2287530"
  },
  {
    "text": "earlier the open source library also helps you build shuffle shards another",
    "start": "2287530",
    "end": "2295660"
  },
  {
    "text": "thing we can do is reduce failover latency via cache busting you may have heard this term cache busting before in",
    "start": "2295660",
    "end": "2302050"
  },
  {
    "text": "the context of denial of service attacks so typically cache busting is used in a DDoS to make it harder for the server to",
    "start": "2302050",
    "end": "2309220"
  },
  {
    "text": "respond by giving it more work because it's uncashed it's going to cause the server to have to perform more work so",
    "start": "2309220",
    "end": "2315400"
  },
  {
    "text": "that's typically how it's used in an attack perspective if you're interested in that I highly recommend going to the security track talk 3:07 that's tomorrow",
    "start": "2315400",
    "end": "2322960"
  },
  {
    "text": "as well they're going to be talking about DDoS there but here we're going to actually use this attack technique for",
    "start": "2322960",
    "end": "2329230"
  },
  {
    "text": "good we're going to ensure that a queries are not cached by the DNS resolver thus reducing our failover",
    "start": "2329230",
    "end": "2336400"
  },
  {
    "text": "latency time so again assuming we have a ten-second health check with three consecutive failures the detection is",
    "start": "2336400",
    "end": "2344020"
  },
  {
    "text": "going to take 30 seconds the failover happens relatively instantaneously but then we're dealing with cached answers",
    "start": "2344020",
    "end": "2349360"
  },
  {
    "text": "from that point on for the 60 second TTL of our record so it's that's the one minute 31 seconds I mentioned earlier in",
    "start": "2349360",
    "end": "2356680"
  },
  {
    "text": "the automated failover case if we apply cache busting immediately after failover",
    "start": "2356680",
    "end": "2363130"
  },
  {
    "text": "the next query that comes for this particular record is going to be uncashed and so you've shaved off an",
    "start": "2363130",
    "end": "2369220"
  },
  {
    "text": "entire minute off your to cut off your time to recovery and this is very easy",
    "start": "2369220",
    "end": "2374470"
  },
  {
    "text": "to configure what you can do is you can create a wild card record for the API endpoint so an",
    "start": "2374470",
    "end": "2380299"
  },
  {
    "text": "example before we were using a PID and net and pointing at the prod one prata to stack here we have a wild card API",
    "start": "2380299",
    "end": "2387619"
  },
  {
    "text": "Ram net pointing at the prod 1 prod 2 stacks and then in the client you",
    "start": "2387619",
    "end": "2393530"
  },
  {
    "text": "control whether that be your JavaScript web application or your iOS app or your",
    "start": "2393530",
    "end": "2399470"
  },
  {
    "text": "Android app you will generate a unique gooood or UUID each time to ensure that",
    "start": "2399470",
    "end": "2406220"
  },
  {
    "text": "you're getting a new record in this way it's guaranteed to be uncashed so what",
    "start": "2406220",
    "end": "2416630"
  },
  {
    "text": "have we covered we talked about delivering resiliency specifically utilizing conditional routing trees to",
    "start": "2416630",
    "end": "2423290"
  },
  {
    "text": "help you get more resiliency out of your application we talked about two specific examples returning multiple answers to",
    "start": "2423290",
    "end": "2430220"
  },
  {
    "text": "clients and also proxying load using conditional write entries to effect",
    "start": "2430220",
    "end": "2436579"
  },
  {
    "text": "routing we also briefly touched on deployment strategies and matching your",
    "start": "2436579",
    "end": "2442970"
  },
  {
    "text": "blast radius to the way you deploy your software we talked about minimizing",
    "start": "2442970",
    "end": "2448970"
  },
  {
    "text": "latency we talked about this in the context of actually reducing the latency of your application utilizing some of",
    "start": "2448970",
    "end": "2455390"
  },
  {
    "text": "the rev 53 multi-region routing options like geo and lbr we talked about how you",
    "start": "2455390",
    "end": "2462799"
  },
  {
    "text": "can minimize the failure latency by taking advantage of DNS failover and utilizing cache busting and shuffle",
    "start": "2462799",
    "end": "2469430"
  },
  {
    "text": "sharding to increase the resiliency and latency of the application by controlling the client we hope that you",
    "start": "2469430",
    "end": "2475309"
  },
  {
    "text": "can take these techniques take them back with you and apply them to your own applications to make them even more",
    "start": "2475309",
    "end": "2481579"
  },
  {
    "text": "available thank",
    "start": "2481579",
    "end": "2484930"
  },
  {
    "text": "you",
    "start": "2488790",
    "end": "2490850"
  }
]
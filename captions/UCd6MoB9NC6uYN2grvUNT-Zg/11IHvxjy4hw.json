[
  {
    "start": "0",
    "end": "87000"
  },
  {
    "text": "all right hi everyone and welcome to session dat 207 migrating database to",
    "start": "0",
    "end": "7830"
  },
  {
    "text": "the cloud with the Amazon with AWS database migration service with special",
    "start": "7830",
    "end": "13799"
  },
  {
    "text": "guests from Verizon and I'm excited to see you here my name is Aaron Chester",
    "start": "13799",
    "end": "18930"
  },
  {
    "text": "and I'm the principal product manager for the AWS database migration service",
    "start": "18930",
    "end": "24960"
  },
  {
    "text": "and the AWS schema conversion tools which we're going to talk about in this",
    "start": "24960",
    "end": "30929"
  },
  {
    "text": "session and I'm excited to see all of you here I two years ago we got this",
    "start": "30929",
    "end": "37590"
  },
  {
    "text": "small room and last year we got a big room but only 30 percent showed up so",
    "start": "37590",
    "end": "43980"
  },
  {
    "text": "now it's good to see that the room is big and it's full and I hope you get a",
    "start": "43980",
    "end": "50460"
  },
  {
    "text": "good use of your time in the next 50 minutes if you do if you've learned something if the speaker was effective",
    "start": "50460",
    "end": "57840"
  },
  {
    "text": "please fill out the survey if we did not if you did not learn anything and we were not effective still fill out the",
    "start": "57840",
    "end": "65430"
  },
  {
    "text": "survey so we can get better for doing this next year and fortunately for you",
    "start": "65430",
    "end": "73470"
  },
  {
    "text": "I'll be the least one speaking today I have guests here I have jug and Sandeep",
    "start": "73470",
    "end": "81390"
  },
  {
    "text": "from Verizon and David from Anaya Tech",
    "start": "81390",
    "end": "86600"
  },
  {
    "text": "and we have a packed agenda first of all we go over a quick overview of the AWS",
    "start": "86600",
    "end": "94470"
  },
  {
    "start": "87000",
    "end": "182000"
  },
  {
    "text": "database migration service and the AWS schema conversion tool then we'll hear",
    "start": "94470",
    "end": "100560"
  },
  {
    "text": "from Verizon about their experience we'll talk a little bit about the",
    "start": "100560",
    "end": "106560"
  },
  {
    "text": "migration playbooks which are the best practices for converting databases",
    "start": "106560",
    "end": "114500"
  },
  {
    "text": "highlights and Q&A if we do not have time for Q&A we will we will stay here",
    "start": "114500",
    "end": "123270"
  },
  {
    "text": "okay here or in the hallway so you can ask us the questions in private",
    "start": "123270",
    "end": "129539"
  },
  {
    "text": "I also publish my email at the end of this presentation so if",
    "start": "129539",
    "end": "134620"
  },
  {
    "text": "you have questions please reach out all right one last main housekeeping stuff",
    "start": "134620",
    "end": "144220"
  },
  {
    "text": "we have related database migration sessions today at 5:30 my colleague will",
    "start": "144220",
    "end": "152650"
  },
  {
    "text": "demo and talk about migrating no sequel databases to dynamo using DMS then we",
    "start": "152650",
    "end": "160480"
  },
  {
    "text": "have workshops and chalk talks and this",
    "start": "160480",
    "end": "165579"
  },
  {
    "text": "is just tip of the iceberg and we've already been doing this for two and a",
    "start": "165579",
    "end": "171310"
  },
  {
    "text": "half days now by the way workshop just to be clear is three hours two and a",
    "start": "171310",
    "end": "178870"
  },
  {
    "text": "half three hours a hands-on workshop alright so moving a database moving a",
    "start": "178870",
    "end": "187510"
  },
  {
    "start": "182000",
    "end": "269000"
  },
  {
    "text": "data warehouse or moving data in general is a journey it's a multi-phase journey",
    "start": "187510",
    "end": "193569"
  },
  {
    "text": "and there are many many reasons for embarking on this journey some of them financial reasons for",
    "start": "193569",
    "end": "201090"
  },
  {
    "text": "examining these millions of dollars to the specific vendor every year sorry I",
    "start": "201090",
    "end": "207760"
  },
  {
    "text": "should say vendors every year and then they send me their audits and they ask",
    "start": "207760",
    "end": "213579"
  },
  {
    "text": "for more money because I turned on one or two features oh there are technology",
    "start": "213579",
    "end": "219959"
  },
  {
    "text": "reasons I chose my database ten years ago and it doesn't fit my needs anymore",
    "start": "219959",
    "end": "225879"
  },
  {
    "text": "it doesn't do the job it's supposed to do for the application in the modern world you mobile IOT you name it and",
    "start": "225879",
    "end": "234090"
  },
  {
    "text": "then there are good reasons so I want to enjoy the richness of the cloud I want",
    "start": "234090",
    "end": "239379"
  },
  {
    "text": "to enjoy the 19 global regions that AWS offers with five coming soon or I wanna",
    "start": "239379",
    "end": "250599"
  },
  {
    "text": "enjoy one of the hundred and forty and Counting services that we offer on AWS",
    "start": "250599",
    "end": "258659"
  },
  {
    "text": "so and we acknowledge that it's a journey and it's not an easy one",
    "start": "258659",
    "end": "264220"
  },
  {
    "text": "and we embarked when we embarked on the journey ourselves we launched DMS and",
    "start": "264220",
    "end": "273040"
  },
  {
    "text": "SCT which is the abbreviated name for the database migration service and the",
    "start": "273040",
    "end": "278110"
  },
  {
    "text": "schema conversion tool with the goal to allow our customers the freedom to",
    "start": "278110",
    "end": "284710"
  },
  {
    "text": "choose the best data platform for their needs or in one world",
    "start": "284710",
    "end": "290130"
  },
  {
    "text": "hashtag DB freedom so we want to allow",
    "start": "290130",
    "end": "295150"
  },
  {
    "text": "you to choose and move to what is best for you and for that we introduced to",
    "start": "295150",
    "end": "303940"
  },
  {
    "text": "two products the schema conversion tool SCT and the database migration service",
    "start": "303940",
    "end": "310470"
  },
  {
    "text": "DMS these are close related cousins in short the schema conversion tool helps",
    "start": "310470",
    "end": "318610"
  },
  {
    "text": "you move and convert your schema and the database migration service helps you",
    "start": "318610",
    "end": "325360"
  },
  {
    "text": "migrate and replicate your data when we",
    "start": "325360",
    "end": "332440"
  },
  {
    "start": "331000",
    "end": "557000"
  },
  {
    "text": "talk about the service we talked about three main use cases the modernize the",
    "start": "332440",
    "end": "338530"
  },
  {
    "text": "migrate and the replicate modernize when",
    "start": "338530",
    "end": "345490"
  },
  {
    "text": "you want to realize again the value from",
    "start": "345490",
    "end": "350500"
  },
  {
    "text": "your database and you want to move off of one of the commercial engines either",
    "start": "350500",
    "end": "356650"
  },
  {
    "text": "Oracle sequel server or db2 l UW version 2 and open source engines such as",
    "start": "356650",
    "end": "364000"
  },
  {
    "text": "post-christmas equal or one of the aurora engines which are both based on",
    "start": "364000",
    "end": "369570"
  },
  {
    "text": "my sequel or Postgres will help you modernize we help you move we help you",
    "start": "369570",
    "end": "376210"
  },
  {
    "text": "convert we also help you assess you can run the SCT assessment report and see",
    "start": "376210",
    "end": "382390"
  },
  {
    "text": "the compatibility of your database to one of these open source engines but not",
    "start": "382390",
    "end": "387460"
  },
  {
    "text": "only the compatibility but also a very detailed list of action items that you",
    "start": "387460",
    "end": "394570"
  },
  {
    "text": "will need to take in order to convert your skin but we it's not only about",
    "start": "394570",
    "end": "400940"
  },
  {
    "text": "assessment we only also automatically convert these schemas and we're at about",
    "start": "400940",
    "end": "408700"
  },
  {
    "text": "90% on average 90% conversion automation from these sources to open source to",
    "start": "408700",
    "end": "420020"
  },
  {
    "text": "open source engines with the 10% left",
    "start": "420020",
    "end": "425200"
  },
  {
    "text": "manual work some of it so we we have best practices some of some of it will",
    "start": "425200",
    "end": "431690"
  },
  {
    "text": "be covered by David later in this presentation but we also help you modernize your data",
    "start": "431690",
    "end": "439310"
  },
  {
    "text": "warehouses so if you have one of the six",
    "start": "439310",
    "end": "444620"
  },
  {
    "text": "data warehouses the Oracle the sequel server it is a green plant vertical",
    "start": "444620",
    "end": "449840"
  },
  {
    "text": "Terra data you can also convert and migrate those to Amazon redshift",
    "start": "449840",
    "end": "456520"
  },
  {
    "text": "so that's modernize the migrate is the obvious one and this is just a partial",
    "start": "456520",
    "end": "463400"
  },
  {
    "text": "list and what I enjoy the most is that when I travel globally and I meet",
    "start": "463400",
    "end": "470090"
  },
  {
    "text": "customers I always learn about new usage of DMS and how they use the product the",
    "start": "470090",
    "end": "477470"
  },
  {
    "text": "most common one is the first one is the migrate business critical application why migrate business critical",
    "start": "477470",
    "end": "483350"
  },
  {
    "text": "applications because we allow the source database to be to be operational",
    "start": "483350",
    "end": "490990"
  },
  {
    "text": "throughout the migration until the source and time and target are in full",
    "start": "490990",
    "end": "496160"
  },
  {
    "text": "sync and then you can switch your application to work with the new target",
    "start": "496160",
    "end": "501590"
  },
  {
    "text": "we also see again customers migrating to Amazon redshift we see customers",
    "start": "501590",
    "end": "508480"
  },
  {
    "text": "upgrading minor versions without downtime one of the more common recently",
    "start": "508480",
    "end": "517310"
  },
  {
    "text": "use cases is consolidating shards because of my sequel limitations you can",
    "start": "517310",
    "end": "524120"
  },
  {
    "text": "now enjoy the size and richness of Aurora we see customers moving their",
    "start": "524120",
    "end": "529550"
  },
  {
    "text": "char and consolidating their shots into a single Aurora cluster and the last one",
    "start": "529550",
    "end": "536220"
  },
  {
    "text": "is that we also acknowledge that you are free to move between technologies so you",
    "start": "536220",
    "end": "544290"
  },
  {
    "text": "can we allow you to move between no sequel to sequel sequel to no sequel and",
    "start": "544290",
    "end": "549450"
  },
  {
    "text": "no sequel to sequel and that's something that is unique for DMS when we talk",
    "start": "549450",
    "end": "559230"
  },
  {
    "start": "557000",
    "end": "646000"
  },
  {
    "text": "about replicate the name the name of the product is AWS migration service but we",
    "start": "559230",
    "end": "565230"
  },
  {
    "text": "see a growing community of customers using the service to replicate there are",
    "start": "565230",
    "end": "571470"
  },
  {
    "text": "three main use cases for using DMS for application the create cross region",
    "start": "571470",
    "end": "578250"
  },
  {
    "text": "replica now working in one region but I need the copy in another region because",
    "start": "578250",
    "end": "583380"
  },
  {
    "text": "I'm going globally run your analytics in the cloud whether I'm doing it on",
    "start": "583380",
    "end": "591090"
  },
  {
    "text": "redshift or or LDS for Foursquare Saudi as for my sequel we see customers",
    "start": "591090",
    "end": "598130"
  },
  {
    "text": "replicating critical data mission-critical data in real time to",
    "start": "598130",
    "end": "605190"
  },
  {
    "text": "the cloud using DMS and the last one is our support to s3 buckets so you can use",
    "start": "605190",
    "end": "612900"
  },
  {
    "text": "s3 as a source or a target customer replicate and build the data lakes from",
    "start": "612900",
    "end": "620250"
  },
  {
    "text": "transactional data to s3 through DMS so",
    "start": "620250",
    "end": "626700"
  },
  {
    "text": "these are the main three buckets of use cases but there are hundreds because every time we see customers we see new",
    "start": "626700",
    "end": "635370"
  },
  {
    "text": "use cases and we enjoy it and we try to support as many as we can",
    "start": "635370",
    "end": "640850"
  },
  {
    "text": "Verizon will testify later about that statement when we talk about the",
    "start": "640850",
    "end": "647790"
  },
  {
    "start": "646000",
    "end": "711000"
  },
  {
    "text": "supported environment the top row orders are supported sources as you can see",
    "start": "647790",
    "end": "654570"
  },
  {
    "text": "different technology relational no sequel data warehouse and the bottom are",
    "start": "654570",
    "end": "662070"
  },
  {
    "text": "always supported target elasticsearch and kisses are marked because they are new we launched them",
    "start": "662070",
    "end": "668740"
  },
  {
    "text": "last week so now you can stream data for elastic search for search and you can",
    "start": "668740",
    "end": "676830"
  },
  {
    "text": "stream real-time data to Kinesis for online analytics or just you know spread",
    "start": "676830",
    "end": "684910"
  },
  {
    "text": "it across different different data sources data target I should say one",
    "start": "684910",
    "end": "692170"
  },
  {
    "text": "caveat here is that the data warehouse is the six that I mentioned can only",
    "start": "692170",
    "end": "698200"
  },
  {
    "text": "move to redshift the others can move you can move Oracle to any of the bottom",
    "start": "698200",
    "end": "707160"
  },
  {
    "text": "targets before I hand the clicker to my",
    "start": "707160",
    "end": "715750"
  },
  {
    "start": "711000",
    "end": "877000"
  },
  {
    "text": "friends from Verizon I want to give you a few highlights that are sometimes lost in translation we support both",
    "start": "715750",
    "end": "723550"
  },
  {
    "text": "homogeneous and heterogeneous it means that we support my sequel to my sequel",
    "start": "723550",
    "end": "730530"
  },
  {
    "text": "phosphorous to phosphorus Oracle to Oracle but we also support Oracle to",
    "start": "730530",
    "end": "735790"
  },
  {
    "text": "Aurora we also support sequel server to my sequel we help you assess and I",
    "start": "735790",
    "end": "744430"
  },
  {
    "text": "mentioned it help you assess the efforts that it will the efforts and the compatibility it will take you to move",
    "start": "744430",
    "end": "752800"
  },
  {
    "text": "to a different database platform and that's something we're enhancing all the time and new features are coming all the",
    "start": "752800",
    "end": "759220"
  },
  {
    "text": "time we can convert not just a schema we",
    "start": "759220",
    "end": "764740"
  },
  {
    "text": "can convert your functions and your procedures and we can also look at your",
    "start": "764740",
    "end": "770650"
  },
  {
    "text": "code your application code identified embedded sequel statement and attempt to",
    "start": "770650",
    "end": "777340"
  },
  {
    "text": "convert those based on the target engine that you chose so that's something",
    "start": "777340",
    "end": "783310"
  },
  {
    "text": "that's useful and important and some sometimes is a little bit lost before",
    "start": "783310",
    "end": "790270"
  },
  {
    "text": "you start your migration we verify that your migration we",
    "start": "790270",
    "end": "796940"
  },
  {
    "text": "we try to prevent failures of migrations for example if data types are not",
    "start": "796940",
    "end": "803100"
  },
  {
    "text": "supported will alert you before you start your migration we call it the",
    "start": "803100",
    "end": "808980"
  },
  {
    "text": "in-flight feature the pre-flight feature and then we also validate so we make",
    "start": "808980",
    "end": "816450"
  },
  {
    "text": "sure that every record that you attempted to migrate made it to the",
    "start": "816450",
    "end": "823140"
  },
  {
    "text": "target to the destination and that's not just a normo genius micro action that's also in heterogeneous",
    "start": "823140",
    "end": "829500"
  },
  {
    "text": "marriage okay so if you're moving oracle to post quests and you did data",
    "start": "829500",
    "end": "834770"
  },
  {
    "text": "transformation which you're probably gonna do data data data type conversion",
    "start": "834770",
    "end": "843029"
  },
  {
    "text": "sorry then we will validate that the record arrived in the proper format and",
    "start": "843029",
    "end": "851210"
  },
  {
    "text": "the last one is that it's secure and it meets all the certification the Amazon",
    "start": "851210",
    "end": "861470"
  },
  {
    "text": "keeps tracks off and is very very",
    "start": "861470",
    "end": "866630"
  },
  {
    "text": "adamant about having a secure solution",
    "start": "866630",
    "end": "872660"
  },
  {
    "text": "with that I will hand the clicker to Jack Thank You Erin hi good afternoon",
    "start": "872660",
    "end": "882030"
  },
  {
    "text": "thanks for joining this session I'm Jack category or senior manager at Verizon tech ops organization no agenda today we",
    "start": "882030",
    "end": "891000"
  },
  {
    "text": "have or I'm going to talk about the current state application architecture key DB requirements bb/d our proposed",
    "start": "891000",
    "end": "899280"
  },
  {
    "text": "guidelines and here with me I have Sandeep who is going to talk about migration strategy tools used for the",
    "start": "899280",
    "end": "905130"
  },
  {
    "text": "migration lessons learned and key takeaways we have been around trim this",
    "start": "905130",
    "end": "913650"
  },
  {
    "text": "is architecture so we have divided our main categories or applications into three categories mission critical",
    "start": "913650",
    "end": "919140"
  },
  {
    "text": "business critical and non-critical here for our DB migration case study I am going to mainly focus on mission and",
    "start": "919140",
    "end": "926010"
  },
  {
    "text": "business critical applications so as you most of you aware that business critical applications are those",
    "start": "926010",
    "end": "931470"
  },
  {
    "text": "that support the core business functions such as e-commerce billing customer care",
    "start": "931470",
    "end": "937920"
  },
  {
    "text": "and self-service applications and they will be directly attributed to the bottom line revenue of the company for",
    "start": "937920",
    "end": "945029"
  },
  {
    "text": "that these type of applications we have an entire architecture where income which includes a local ETA and activate",
    "start": "945029",
    "end": "952709"
  },
  {
    "text": "you across geo locations obviously given the nature of these applications the",
    "start": "952709",
    "end": "959190"
  },
  {
    "text": "recovery time objective is less than 15 minutes coming to the business critical applications those applications support",
    "start": "959190",
    "end": "966600"
  },
  {
    "text": "the internal business functions and which has less impact in case of a crisis and for this type of applications",
    "start": "966600",
    "end": "974579"
  },
  {
    "text": "we have active passive they are solutions in place with a recovery time objective of less than four hours so",
    "start": "974579",
    "end": "982680"
  },
  {
    "start": "982000",
    "end": "1089000"
  },
  {
    "text": "here is a key require database requirements when we migrate our applications to the cloud the main",
    "start": "982680",
    "end": "988709"
  },
  {
    "text": "requirement here is when we migrate applications to the cloud is high availability meaning we need to run our",
    "start": "988709",
    "end": "996750"
  },
  {
    "text": "applications and systems 24 by 7 by 365",
    "start": "996750",
    "end": "1002500"
  },
  {
    "text": "we are achieving this by in on-prem by having local h.a wherein if we have 1 DB",
    "start": "1002500",
    "end": "1010790"
  },
  {
    "text": "node fails we will our third node will be becoming pick up the transactions",
    "start": "1010790",
    "end": "1015890"
  },
  {
    "text": "automatically we are two seemed to have the seamless business continuity and the same seamless business continuity for",
    "start": "1015890",
    "end": "1022520"
  },
  {
    "text": "all the scheduled maintenance such as DB",
    "start": "1022520",
    "end": "1028010"
  },
  {
    "text": "patches and and so on so forth in addition to the local HJ we also need a",
    "start": "1028010",
    "end": "1034150"
  },
  {
    "text": "dr side wherein if all the DB nodes of a cluster has issues or DB crash scenario",
    "start": "1034150",
    "end": "1042319"
  },
  {
    "text": "we need to failure the application to the other side seamlessly to have a",
    "start": "1042319",
    "end": "1048410"
  },
  {
    "text": "customer to to don't I will mean to not",
    "start": "1048410",
    "end": "1053870"
  },
  {
    "text": "disrupt the customer transactions are applicable activities so",
    "start": "1053870",
    "end": "1059960"
  },
  {
    "text": "in addition to the high availability and active active across geo locations we",
    "start": "1059960",
    "end": "1068360"
  },
  {
    "text": "also need to serve our customers in sub second customer transactions in sub",
    "start": "1068360",
    "end": "1073520"
  },
  {
    "text": "second and we will be able me should be able to serve anywhere between 500 to",
    "start": "1073520",
    "end": "1078950"
  },
  {
    "text": "2,000 transactions per second so with",
    "start": "1078950",
    "end": "1087590"
  },
  {
    "text": "that he mean with the architecture I am the requirement we have came up with the",
    "start": "1087590",
    "end": "1095450"
  },
  {
    "text": "proposed guidelines with partnering with ADA players to have the same",
    "start": "1095450",
    "end": "1101920"
  },
  {
    "text": "availability of the applications in the cloud so so here if you look at the BIS core bas core business impact analysis",
    "start": "1101920",
    "end": "1110300"
  },
  {
    "text": "so mission-critical applications fall into the be a score of high where it",
    "start": "1110300",
    "end": "1115940"
  },
  {
    "text": "maps to the on-premise as well as in AWS ec2 and Aurora so so and again in in",
    "start": "1115940",
    "end": "1124820"
  },
  {
    "text": "case of ICI Aurora specifically to the Postgres ADA place as per the SS roadmap",
    "start": "1124820",
    "end": "1131200"
  },
  {
    "text": "the bi-directional capabilities will be available soon so when in few days I mean we were",
    "start": "1131200",
    "end": "1141380"
  },
  {
    "text": "attending some sessions like and we've been told that by direction capability should have been soon so we're in we can",
    "start": "1141380",
    "end": "1147740"
  },
  {
    "text": "do cross regional application for the business business critical applications whereas mission-critical applications",
    "start": "1147740",
    "end": "1154580"
  },
  {
    "text": "sorry so for the coming to the business critical applications they fall into the be a score of medium where it Maps right",
    "start": "1154580",
    "end": "1161630"
  },
  {
    "text": "now out of the on current on-premise to it easy to and Aurora and they have the",
    "start": "1161630",
    "end": "1168230"
  },
  {
    "text": "multi region dr capabilities and dr solutions in place and in addition in",
    "start": "1168230",
    "end": "1174050"
  },
  {
    "text": "cloud there is a pilot light where you can run your lighter version of applications always in the cloud and",
    "start": "1174050",
    "end": "1180710"
  },
  {
    "text": "when the time comes for the recovery you can actually provision the full scale of application within a few few minutes or",
    "start": "1180710",
    "end": "1187700"
  },
  {
    "text": "seconds so with that now I'll go handle no to Sandeep who is going to cover the technicalities of the migrations",
    "start": "1187700",
    "end": "1194130"
  },
  {
    "text": "thank you good afternoon everyone so I'm",
    "start": "1194130",
    "end": "1201510"
  },
  {
    "start": "1201000",
    "end": "1350000"
  },
  {
    "text": "going to talk about the migration strategy we at Verizon followed so we have decided to migrate from the",
    "start": "1201510",
    "end": "1208140"
  },
  {
    "text": "commercial database engines to Aurora Postgres meaning the Oracle and the sequel server databases we are on the",
    "start": "1208140",
    "end": "1214620"
  },
  {
    "text": "path to migrate them to Aurora Postgres so based on our criticality of the applications we have divided our",
    "start": "1214620",
    "end": "1221250"
  },
  {
    "text": "strategy starting with the mission-critical applications the approach we took is lift and shift",
    "start": "1221250",
    "end": "1227130"
  },
  {
    "text": "meaning we would migrate the databases the same database engine as these to AWS",
    "start": "1227130",
    "end": "1232970"
  },
  {
    "text": "today I'm going to talk about what we have done for a Oracle footprint so in the case of Oracle we put them on RDS or",
    "start": "1232970",
    "end": "1240570"
  },
  {
    "text": "ec2 again based on what is the size of your database what are the IRS requirements are there any features that",
    "start": "1240570",
    "end": "1247800"
  },
  {
    "text": "are not being supported RDS and easier need to have a full control of your database based on those factors we have",
    "start": "1247800",
    "end": "1253860"
  },
  {
    "text": "placed our workloads a few of them an RDS and few of them an ec2 so far we",
    "start": "1253860",
    "end": "1259080"
  },
  {
    "text": "have migrated most of our non production workloads to AWS in this lift and shift model and we are in the process of",
    "start": "1259080",
    "end": "1264870"
  },
  {
    "text": "migrating our production workloads the end goal is to get to Aurora Posterous",
    "start": "1264870",
    "end": "1270090"
  },
  {
    "text": "but the primary reason we took this approach for mission-critical is we wanted to minimize the risk to the",
    "start": "1270090",
    "end": "1276150"
  },
  {
    "text": "business right so this is obviously a new database platform you are getting into we want to familiarize ourselves",
    "start": "1276150",
    "end": "1281190"
  },
  {
    "text": "with the new engine try to get operational experience try to find out any shoes that we might run into and we",
    "start": "1281190",
    "end": "1288300"
  },
  {
    "text": "when migrated disciplic a shion's another reason is at Verizon the",
    "start": "1288300",
    "end": "1293460"
  },
  {
    "text": "approach you wanted to take for a mission-critical migration to cloud is n +1 and being the number of data centers",
    "start": "1293460",
    "end": "1300030"
  },
  {
    "text": "on Prem and one being the region in AWS there is a need to keep the data in sync to serve the application in an N plus",
    "start": "1300030",
    "end": "1307560"
  },
  {
    "text": "one model and there are tools which we could use to replicate the data from an Oracle database on-premise to aurora",
    "start": "1307560",
    "end": "1314370"
  },
  {
    "text": "Postgres but so far this hasn't been any tool that could replicate the data back",
    "start": "1314370",
    "end": "1319440"
  },
  {
    "text": "from Aurora Postgres to Oracle on-prem that's something we are working with AWS and other vendors so",
    "start": "1319440",
    "end": "1325510"
  },
  {
    "text": "then we started pushing our business critical and non-critical and any of the",
    "start": "1325510",
    "end": "1330820"
  },
  {
    "text": "new applications that we are building - Aurora passe Chris so for the business critical we started the refactoring most",
    "start": "1330820",
    "end": "1337780"
  },
  {
    "text": "of our Oracle and sequel server applications are being migrated to Aurora Postgres we have migrated a few",
    "start": "1337780",
    "end": "1344860"
  },
  {
    "text": "of them we have departed few of them in production so what are the tools we used to do this refactoring a city and DMS a city to",
    "start": "1344860",
    "end": "1353470"
  },
  {
    "start": "1350000",
    "end": "1366000"
  },
  {
    "text": "convert the database code objects and DMS to migrate the data I'm going to",
    "start": "1353470",
    "end": "1360880"
  },
  {
    "text": "talk about what are the lessons learned and challenges for each of these tools starting with a CD as Yudin pointed out",
    "start": "1360880",
    "end": "1368290"
  },
  {
    "start": "1366000",
    "end": "1570000"
  },
  {
    "text": "the first step for migrating any database using an SCT is to run an assessment report",
    "start": "1368290",
    "end": "1373810"
  },
  {
    "text": "so we appointed the SCT tool over on premise databases and chose the appropriate version and the engine we",
    "start": "1373810",
    "end": "1380410"
  },
  {
    "text": "wanted on AWS what we have seen is an 80% conversion rate most of the database storage objects",
    "start": "1380410",
    "end": "1387130"
  },
  {
    "text": "like tables indexes constraints SCT was able to generate the code in Postgres",
    "start": "1387130",
    "end": "1392950"
  },
  {
    "text": "whereas the database code objects like PL sequel packages functions procedures",
    "start": "1392950",
    "end": "1398800"
  },
  {
    "text": "there were cases where SCT would try to convert them in some way in some cases",
    "start": "1398800",
    "end": "1404800"
  },
  {
    "text": "it would say this particular feature is not available in Postgres or in some cases it would need a human intervention",
    "start": "1404800",
    "end": "1411760"
  },
  {
    "text": "to rewrite the code and one thing we wanted to mandate during this migration",
    "start": "1411760",
    "end": "1417550"
  },
  {
    "text": "sees to try to push the code out of the database meaning we wanted the code to",
    "start": "1417550",
    "end": "1423010"
  },
  {
    "text": "be sitting in the application layer so that we could have the applications DB agnostic so that if we want to really",
    "start": "1423010",
    "end": "1429340"
  },
  {
    "text": "decide to migrate to another database in the future we need not go through the exercise of converting the code right so",
    "start": "1429340",
    "end": "1436630"
  },
  {
    "text": "now going into the issues we have seen with the sed partition table conversion",
    "start": "1436630",
    "end": "1441700"
  },
  {
    "text": "so till Postgres 10 there was no a declarative partitioning available so",
    "start": "1441700",
    "end": "1447580"
  },
  {
    "text": "what was happening till Postgres 9.6 or 9.8 was the only way to create a partition table is by a child table",
    "start": "1447580",
    "end": "1454210"
  },
  {
    "text": "inheritance so each of your partition in the source table would be like a child table in and we have to create triggers on top of",
    "start": "1454210",
    "end": "1462580"
  },
  {
    "text": "each of the child tables and the parent table is just empty it's just used to view the data so even though Postgres 10",
    "start": "1462580",
    "end": "1469060"
  },
  {
    "text": "had the declarative partitioning SCT was not able to generate the compatible code and then we worked with the SCT teams",
    "start": "1469060",
    "end": "1475420"
  },
  {
    "text": "and looks like they pushed an update out and we could now convert the code appropriately to create those tables the",
    "start": "1475420",
    "end": "1484330"
  },
  {
    "text": "next issue is the data type issues so in an Oracle database if we we had a lot of as everyone we had a lot of numbered",
    "start": "1484330",
    "end": "1491080"
  },
  {
    "text": "data types if we had a number with a precision defined SCT would convert that to be numeric whereas if there was no",
    "start": "1491080",
    "end": "1498970"
  },
  {
    "text": "precision defined SCT was converting that to be a double precision data type in Postgres so that was causing issues",
    "start": "1498970",
    "end": "1505300"
  },
  {
    "text": "where applications were not able to insert data or read data so we had to manually modify all these data types to",
    "start": "1505300",
    "end": "1513160"
  },
  {
    "text": "be a numeric or in some cases if there was no need for a precision for that",
    "start": "1513160",
    "end": "1518680"
  },
  {
    "text": "data type or the particular column you would make that an integer to basically get a better performance next one",
    "start": "1518680",
    "end": "1526920"
  },
  {
    "text": "default date conversions most of our transaction tables we try to partition",
    "start": "1526920",
    "end": "1532660"
  },
  {
    "text": "them to to tune the performance or to better maintain them so we had a lot of tables where when we would default the",
    "start": "1532660",
    "end": "1540610"
  },
  {
    "text": "create date to be a assist date so SCT was trying to generate code for the",
    "start": "1540610",
    "end": "1546310"
  },
  {
    "text": "generation of that default date the way it does is it's basically creating a function and that function would",
    "start": "1546310",
    "end": "1552520"
  },
  {
    "text": "internally convert the date so it had at some analyst calendar parameters and we",
    "start": "1552520",
    "end": "1558580"
  },
  {
    "text": "had to update those parameters and in some cases or remove the analyst calendar parameters to basically get the",
    "start": "1558580",
    "end": "1565510"
  },
  {
    "text": "date converted moving onto the issues with DMS the main thing we we really",
    "start": "1565510",
    "end": "1574470"
  },
  {
    "start": "1570000",
    "end": "1790000"
  },
  {
    "text": "liked about DMS is not only to be able to do the data copy but also to keep the",
    "start": "1574470",
    "end": "1580120"
  },
  {
    "text": "data in sync that's very critical because once we migrate the data we are",
    "start": "1580120",
    "end": "1585160"
  },
  {
    "text": "not going to be doing the cutover immediately we want to be able to validate the data even though DMS does",
    "start": "1585160",
    "end": "1590920"
  },
  {
    "text": "its own validation to do the manual validation have the application teams validate and once the",
    "start": "1590920",
    "end": "1596320"
  },
  {
    "text": "validation is complete that's when we would have the on purim applications shut down and then bring up the",
    "start": "1596320",
    "end": "1603610"
  },
  {
    "text": "applications on AWS for that we use the continuous replication post data copy",
    "start": "1603610",
    "end": "1608860"
  },
  {
    "text": "feature of DMS next one using the standby on the source to reduce the",
    "start": "1608860",
    "end": "1614290"
  },
  {
    "text": "impact when DMS is running or reading the data from the on-premise databases there were cases where especially for",
    "start": "1614290",
    "end": "1622420"
  },
  {
    "text": "the really large tables or heavily transactional tables while reading the",
    "start": "1622420",
    "end": "1627730"
  },
  {
    "text": "data the applications that are using them on on-prem would see some slowness or see some performance issues so then",
    "start": "1627730",
    "end": "1634960"
  },
  {
    "text": "we have pointed the DMS to connect to the standby instant so that we could reduce the load on the primary database",
    "start": "1634960",
    "end": "1642100"
  },
  {
    "text": "and not impact the applications while doing the migrations next one regarding",
    "start": "1642100",
    "end": "1649030"
  },
  {
    "text": "the large table copy for any large table if we started the data migration using a single thread it was taking a really",
    "start": "1649030",
    "end": "1655090"
  },
  {
    "text": "long time so we use the parallel option of dividing the each of the tasks into",
    "start": "1655090",
    "end": "1660760"
  },
  {
    "text": "subtasks by basically defining conditions on the primary key and defining a range to speed up the process",
    "start": "1660760",
    "end": "1670560"
  },
  {
    "text": "Dryden's needed before production migration I would say this is the most important lesson we learned with DMS so",
    "start": "1670560",
    "end": "1677050"
  },
  {
    "text": "based on the size of the database the characteristic of the database the number of tables you have in a schema",
    "start": "1677050",
    "end": "1682900"
  },
  {
    "text": "the type of columns you have in a table do you have any alibies what kind of copy are doing limited lob full lob",
    "start": "1682900",
    "end": "1689860"
  },
  {
    "text": "based on all these factors the copy time has varied so when we initially started",
    "start": "1689860",
    "end": "1695290"
  },
  {
    "text": "a migration of a terabyte of a database it was actually taking more than ID so we had to go through multiple iterations",
    "start": "1695290",
    "end": "1701530"
  },
  {
    "text": "to find out okay what are the tables that it is taking the longer time on how do we group the tables and how do we",
    "start": "1701530",
    "end": "1708550"
  },
  {
    "text": "divide some of the tables into subtasks this is all basically done through only",
    "start": "1708550",
    "end": "1714340"
  },
  {
    "text": "we were only able to get to an optimized or a better timing based on the number of runs we did so finally after doing",
    "start": "1714340",
    "end": "1721420"
  },
  {
    "text": "multiple runs a one terabyte migration which was taking more than a day finally at the after these runs it came",
    "start": "1721420",
    "end": "1728770"
  },
  {
    "text": "down to around eight hours right so going into the issues again the data migration for large database it ties",
    "start": "1728770",
    "end": "1735220"
  },
  {
    "text": "back to my previous thing still if you really have a multi terabyte of database it is actually going to take longer than",
    "start": "1735220",
    "end": "1742750"
  },
  {
    "text": "what we want it to be but I was told one of the features that DMS 3.1 not too has",
    "start": "1742750",
    "end": "1748540"
  },
  {
    "text": "is instead of us defining the subtasks for each of your partition tables now",
    "start": "1748540",
    "end": "1753910"
  },
  {
    "text": "DMS has a feature of it would automatically detect if it is a partition table and it would try to",
    "start": "1753910",
    "end": "1760540"
  },
  {
    "text": "unload in multiple threads for all the sub partitions and partitions hopefully that should help with the partition",
    "start": "1760540",
    "end": "1766690"
  },
  {
    "text": "tables but would still like to see some improvements on getting the migrated you",
    "start": "1766690",
    "end": "1771910"
  },
  {
    "text": "are migrating the data faster the next one the option to specify to copy more",
    "start": "1771910",
    "end": "1777670"
  },
  {
    "text": "than eight tables at a time this was also recently addressed I believe so we will be able to get to up to fifty",
    "start": "1777670",
    "end": "1784840"
  },
  {
    "text": "threads based on if your source database can take the load so overall during these migrations what",
    "start": "1784840",
    "end": "1791920"
  },
  {
    "start": "1790000",
    "end": "2057000"
  },
  {
    "text": "are our key takeaways first one one size does not fit all so there are play books",
    "start": "1791920",
    "end": "1799930"
  },
  {
    "text": "you know everyone has those play books what to do when you start the migration of a database but there is no one way to",
    "start": "1799930",
    "end": "1805780"
  },
  {
    "text": "do any migration it depends upon what what is the nature of the database right what is the size what amount of code do",
    "start": "1805780",
    "end": "1812650"
  },
  {
    "text": "you have in the DB what are the requirements from the application side meaning we have requirements to have the",
    "start": "1812650",
    "end": "1818560"
  },
  {
    "text": "data in sync across regions data in sync back to one Prem so we had to go through",
    "start": "1818560",
    "end": "1824290"
  },
  {
    "text": "an exercise of identifying all these points or go through the play books and based on outcome of each of the step we",
    "start": "1824290",
    "end": "1831760"
  },
  {
    "text": "would devise our strategy so it's there is no one strategy to migrate a database it's going to differ based on your needs",
    "start": "1831760",
    "end": "1840510"
  },
  {
    "text": "next one choosing the right tools so far for our business critical applications",
    "start": "1840510",
    "end": "1846520"
  },
  {
    "text": "which we have migrated DMS and SCT have sufficed the need but while going into",
    "start": "1846520",
    "end": "1852790"
  },
  {
    "text": "the migrations for mission-critical there is again really a need to get a tool out which we could do outbound",
    "start": "1852790",
    "end": "1858980"
  },
  {
    "text": "application again that something hopefully will Suz we'll see soon next",
    "start": "1858980",
    "end": "1864260"
  },
  {
    "text": "one conducting dry runs this is this is in specific to DMS and validations and bringing up the applications so it's",
    "start": "1864260",
    "end": "1872210"
  },
  {
    "text": "really mandatory to do multiple iterations of dry runs to get the",
    "start": "1872210",
    "end": "1877760"
  },
  {
    "text": "optimal time for your data copy and to validate and make sure the data quality that has been on the data quality of the",
    "start": "1877760",
    "end": "1884570"
  },
  {
    "text": "data that has been migrated is good right in the last one performance testing I would say this is the most",
    "start": "1884570",
    "end": "1890450"
  },
  {
    "text": "critical aspect comparing with an on-prem footprint a lot of things are",
    "start": "1890450",
    "end": "1896540"
  },
  {
    "text": "changing when we move to it obvious right the server architecture is different your storage is different the",
    "start": "1896540",
    "end": "1902870"
  },
  {
    "text": "network layer is different again the database engine is different too so to",
    "start": "1902870",
    "end": "1909919"
  },
  {
    "text": "get to the right sizing of the instances or to tune the database engine parameters and in some cases we had to",
    "start": "1909919",
    "end": "1917270"
  },
  {
    "text": "also tune the sequel server running on a non from Oracle database we had some",
    "start": "1917270",
    "end": "1922669"
  },
  {
    "text": "queries running faster what we found out is we had to create or actually in some",
    "start": "1922669",
    "end": "1927830"
  },
  {
    "text": "cases create indexes that we are not needed and on trim or in some cases modify the index definitions to achieve",
    "start": "1927830",
    "end": "1935090"
  },
  {
    "text": "better or similar performance so it's really critical for each of the databases to go through this exercise of",
    "start": "1935090",
    "end": "1941620"
  },
  {
    "text": "doing the performance testing so so far we migrated our business-critical",
    "start": "1941620",
    "end": "1948049"
  },
  {
    "text": "as I've been saying so what would help us get there faster to AWS what would help us to migrate our mission-critical",
    "start": "1948049",
    "end": "1954830"
  },
  {
    "text": "applications the first two ones the cross region and hybrid and multi master we have been attending some sessions",
    "start": "1954830",
    "end": "1961940"
  },
  {
    "text": "adora sessions and also meeting with their or development folks hopefully they would be out next year which would",
    "start": "1961940",
    "end": "1967669"
  },
  {
    "text": "speed up our migrations and the conversion of packages yes SCT does try",
    "start": "1967669",
    "end": "1973520"
  },
  {
    "text": "to convert the code from an Oracle to a Postgres but we would like to see better",
    "start": "1973520",
    "end": "1978590"
  },
  {
    "text": "conversion rate right and also minimize the manual work needed or workforce",
    "start": "1978590",
    "end": "1985309"
  },
  {
    "text": "needed to my cry to rewrite the code last one conversion of shell scripts we have a lot of shell script we can",
    "start": "1985309",
    "end": "1992490"
  },
  {
    "text": "have on-prem which would do data loads data massaging or aggregating data we",
    "start": "1992490",
    "end": "1998670"
  },
  {
    "text": "would like to see SCT also convert the DB specific code in those shell scripts",
    "start": "1998670",
    "end": "2003740"
  },
  {
    "text": "to be pusk√°s compatible it has been exciting journey for us coming from a",
    "start": "2003740",
    "end": "2009500"
  },
  {
    "text": "traditional DBM mode to now being responsible for the computerized database engine working on automations",
    "start": "2009500",
    "end": "2016190"
  },
  {
    "text": "to build all these services migrating them and we are continuously trying to upskill ourselves and try to improve our",
    "start": "2016190",
    "end": "2023179"
  },
  {
    "text": "process Amazon has done a good job of providing the tools like AWS DMS and SCT",
    "start": "2023179",
    "end": "2029630"
  },
  {
    "text": "to have the migration to cloud doable but it is far from seamless they're",
    "start": "2029630",
    "end": "2034910"
  },
  {
    "text": "continuously updating their tools or building new tools to make it easier for customers but till then the success of",
    "start": "2034910",
    "end": "2041870"
  },
  {
    "text": "the database migration would depend on the preparation we do ahead of time with",
    "start": "2041870",
    "end": "2047090"
  },
  {
    "text": "that thank you very much juggen sandy",
    "start": "2047090",
    "end": "2053148"
  },
  {
    "text": "for sharing this story with us as I mentioned it's a journey it's a journey that has multi phases and we're trying",
    "start": "2053149",
    "end": "2059628"
  },
  {
    "start": "2057000",
    "end": "2114000"
  },
  {
    "text": "to help with automation and improving the product as we go along by the way",
    "start": "2059629",
    "end": "2065388"
  },
  {
    "text": "just one comment we release an SCT version every month so it's currently",
    "start": "2065389",
    "end": "2071950"
  },
  {
    "text": "version six to one so if you run at a month later you're gonna probably get",
    "start": "2071950",
    "end": "2078760"
  },
  {
    "text": "improvement in conversion saying for by the way DMS DMS and new capabilities go",
    "start": "2078760",
    "end": "2084590"
  },
  {
    "text": "out all the time as a service with that",
    "start": "2084590",
    "end": "2089658"
  },
  {
    "text": "I'd like to invite David David is the city of nya tech and helped us build the",
    "start": "2089659",
    "end": "2098610"
  },
  {
    "text": "practices the best practices for converting Oracle and sequel server to",
    "start": "2098610",
    "end": "2105930"
  },
  {
    "text": "open source engine David thank you Ron can you hear the music here or just",
    "start": "2105930",
    "end": "2111550"
  },
  {
    "text": "there is music there's music he's like a nice vibe so hi everyone I'm",
    "start": "2111550",
    "end": "2119830"
  },
  {
    "start": "2114000",
    "end": "2635000"
  },
  {
    "text": "David I'm at city of Natick we are a database consulting firm located in the San Francisco Bay Area an Amazon partner",
    "start": "2119830",
    "end": "2127870"
  },
  {
    "text": "and part of the Amazon database freedom program as such a lot of what we do is",
    "start": "2127870",
    "end": "2135160"
  },
  {
    "text": "helping clients move their existing commercial traditional workloads on to",
    "start": "2135160",
    "end": "2140170"
  },
  {
    "text": "AWS leveraging cloud native database technologies such as Aurora RDS and",
    "start": "2140170",
    "end": "2146260"
  },
  {
    "text": "redshift and I'm here on stage today to share with you an initiative that we",
    "start": "2146260",
    "end": "2152320"
  },
  {
    "text": "have been working together with Amazon for the past year or so which is the database migration playbooks which are",
    "start": "2152320",
    "end": "2159880"
  },
  {
    "text": "essentially guides containing the best practices blueprints and procedures on",
    "start": "2159880",
    "end": "2165460"
  },
  {
    "text": "how to move existing workloads running for on oracle and sequel server",
    "start": "2165460",
    "end": "2170710"
  },
  {
    "text": "databases to Aurora Mike sequel and Aurora Postgres now as",
    "start": "2170710",
    "end": "2177100"
  },
  {
    "text": "you saw in the presentation from Verizon Amazon has tools that can help simplify",
    "start": "2177100",
    "end": "2183370"
  },
  {
    "text": "the migration process and can help execute those on-prem traditional",
    "start": "2183370",
    "end": "2188560"
  },
  {
    "text": "commercial database migrations to AWS cloud native services and a success rate",
    "start": "2188560",
    "end": "2193750"
  },
  {
    "text": "for for example SCT which is the schema conversion tool is very high for Verizon it was approximately 80 percent which is",
    "start": "2193750",
    "end": "2200560"
  },
  {
    "text": "great but then the question that you may ask is so what do we do if the rest of",
    "start": "2200560",
    "end": "2206110"
  },
  {
    "text": "the 20% because there are some proprietary features and schema objects",
    "start": "2206110",
    "end": "2211150"
  },
  {
    "text": "that you may have in your source databases that cannot be converted automatically or maybe can be partially",
    "start": "2211150",
    "end": "2218200"
  },
  {
    "text": "converted automatically but some manual involvement is still required so as such",
    "start": "2218200",
    "end": "2223810"
  },
  {
    "text": "what we have done is essentially take what we believe is the most commonly you",
    "start": "2223810",
    "end": "2230810"
  },
  {
    "text": "features that you will find a most production Oracle in sequel server",
    "start": "2230810",
    "end": "2236030"
  },
  {
    "text": "databases this can include schema objects and vendor specifics ape AP is that you",
    "start": "2236030",
    "end": "2242960"
  },
  {
    "text": "might be using inside your stored procedures such as Oracle DBMS packages but also operational infrastructure",
    "start": "2242960",
    "end": "2249200"
  },
  {
    "text": "level features such as you know Oracle Arman Oracle flashback for example so we",
    "start": "2249200",
    "end": "2254600"
  },
  {
    "text": "took all of those different features attributes that can cause stickiness to a certain database platform and try to",
    "start": "2254600",
    "end": "2261410"
  },
  {
    "text": "provide first of all provide an exam an overview if this feature can be",
    "start": "2261410",
    "end": "2267440"
  },
  {
    "text": "converted automatically using SCT fully maybe not fully but still to some degree and if not provide workarounds including",
    "start": "2267440",
    "end": "2275600"
  },
  {
    "text": "actual code blueprints for you to be able to manually do the 20% that's kind",
    "start": "2275600",
    "end": "2282680"
  },
  {
    "text": "of like remaining for the migration process those 20% that cannot be converted automatically so we encourage",
    "start": "2282680",
    "end": "2288980"
  },
  {
    "text": "you to use those database migration playbooks and I'll show you in a moment there are structure and outline and",
    "start": "2288980",
    "end": "2295250"
  },
  {
    "text": "where you can find them as kind of your reference guide when you perform your",
    "start": "2295250",
    "end": "2300620"
  },
  {
    "text": "database migrations to AWS these guys are meant to augment you know using a CT and diem s because SCT and EMS can take",
    "start": "2300620",
    "end": "2307610"
  },
  {
    "text": "you most of the way so maybe for the final that last mile will you need to do some manual you know hands on DBA",
    "start": "2307610",
    "end": "2315350"
  },
  {
    "text": "related tasks to get some of those tricky schema objects converted such as partition tables so as was mentioned you",
    "start": "2315350",
    "end": "2323390"
  },
  {
    "text": "know for example Oracle has declarative partitioning and sequel server also in Postgres 9.6 does not so in case you do",
    "start": "2323390",
    "end": "2331610"
  },
  {
    "text": "need to create like manual parent and child tables with table inheritance and triggers how do you do that so we wanted",
    "start": "2331610",
    "end": "2337790"
  },
  {
    "text": "to provide the templates for you to do so also maybe you have seen a names in your Oracle database in this process",
    "start": "2337790",
    "end": "2344030"
  },
  {
    "text": "support them should you use views as workarounds what do you do if you have index organized tables or maybe even you",
    "start": "2344030",
    "end": "2350300"
  },
  {
    "text": "are relying on Oracle Flash book database is there anything in your aura that can provide you similar functionality so all of these can be",
    "start": "2350300",
    "end": "2356990"
  },
  {
    "text": "found in those in our play books that we have created with Amazon and just as a spoiler alert each one of those guides",
    "start": "2356990",
    "end": "2363320"
  },
  {
    "text": "and we observe is almost I think the average is like 400 pages long so they make for really",
    "start": "2363320",
    "end": "2369170"
  },
  {
    "text": "fascinating reading material but you know the more the merrier right so how",
    "start": "2369170",
    "end": "2375799"
  },
  {
    "text": "do you find the database migration playbooks and let's see why we cannot",
    "start": "2375799",
    "end": "2381049"
  },
  {
    "text": "see the browser on the screen so maybe fall exit this presentation let's",
    "start": "2381049",
    "end": "2387799"
  },
  {
    "text": "minimize it nope still has the slide on C R and you know why we can't see the",
    "start": "2387799",
    "end": "2394369"
  },
  {
    "text": "browser technical editor here okay",
    "start": "2394369",
    "end": "2400719"
  },
  {
    "text": "you need to stop the presentation out ever no no no video is like a different",
    "start": "2406270",
    "end": "2413990"
  },
  {
    "text": "desktop or something oh yeah you have two desktops here so and just there we",
    "start": "2413990",
    "end": "2419540"
  },
  {
    "text": "go there's our missing browser window so you can find those database migration playbooks on the DMS websites as you see",
    "start": "2419540",
    "end": "2426740"
  },
  {
    "text": "we have a bunch of them already available you know Oracle to read chief Oracle to",
    "start": "2426740",
    "end": "2433280"
  },
  {
    "text": "or my sequel or Oracle to Amazon or Postgres and sequel server to Amazon or my sequel we have a bunch more that we",
    "start": "2433280",
    "end": "2440510"
  },
  {
    "text": "are currently working on that should be published soon soon so keep checking the DMS webpage DMS getting started in",
    "start": "2440510",
    "end": "2447829"
  },
  {
    "text": "resources web pages for additional Playworks as we publish them and just to give you an example of how those Play",
    "start": "2447829",
    "end": "2453829"
  },
  {
    "text": "Books look like so for example maybe we can we have like one of them open here so this is the Microsoft sequel server",
    "start": "2453829",
    "end": "2460250"
  },
  {
    "text": "to Amazon arora with my sequel compatibility migration playbook so again these are very long documents very",
    "start": "2460250",
    "end": "2465650"
  },
  {
    "text": "extensive documents very technical very hands-on and the way that we structured them to help you perform your database",
    "start": "2465650",
    "end": "2472460"
  },
  {
    "text": "migrations is that we kind of cover like most of the I think most most of the",
    "start": "2472460",
    "end": "2477880"
  },
  {
    "text": "vendor specific database engine specific features that you can find in your",
    "start": "2477880",
    "end": "2483020"
  },
  {
    "text": "source database and then both kind of try to show if there is automation for",
    "start": "2483020",
    "end": "2489079"
  },
  {
    "text": "the migration Vict or if there is anything or any manual work that needs to be done as part of it so you see we",
    "start": "2489079",
    "end": "2495230"
  },
  {
    "text": "have a very cool table of compatibility where we basically for each feature and you saw I'll show you some example in the moment we show you how much is the",
    "start": "2495230",
    "end": "2502309"
  },
  {
    "text": "source feature compatible with in this case or or my sequel so it could be we",
    "start": "2502309",
    "end": "2508010"
  },
  {
    "text": "could have low compatibility medium compatibility or high compatibility but we also kind of factor in what's the SAT",
    "start": "2508010",
    "end": "2513980"
  },
  {
    "text": "automation level for conversion because you want to know even maybe before you're starting to convert your database",
    "start": "2513980",
    "end": "2519079"
  },
  {
    "text": "if you know that you are heavily using a certain vendor specific feature you might be interested to it before you",
    "start": "2519079",
    "end": "2525319"
  },
  {
    "text": "even run a city kind of figure out is this gonna be covered by a city and if so to what extent and many many many",
    "start": "2525319",
    "end": "2531710"
  },
  {
    "text": "features as many schema objects are fully converted some some of the trickiest one",
    "start": "2531710",
    "end": "2537930"
  },
  {
    "text": "not and as you can see when you start scrolling down and browsing through these play books you see that you're",
    "start": "2537930",
    "end": "2543780"
  },
  {
    "text": "basically and this is the same structure that we use for all of them we list the source feature and again we cover both",
    "start": "2543780",
    "end": "2549900"
  },
  {
    "text": "schema schema objects data types server level features and attributes and then",
    "start": "2549900",
    "end": "2556079"
  },
  {
    "text": "we present you the best equivalent lesson what's the best equivalent feature in the target engine or my",
    "start": "2556079",
    "end": "2562980"
  },
  {
    "text": "signal in this case and also as you see by the database in your icons how much",
    "start": "2562980",
    "end": "2569970"
  },
  {
    "text": "it is convertible and how much automation can be done so again strolling through this list you see we cover a lot of stuff so you can click on",
    "start": "2569970",
    "end": "2576780"
  },
  {
    "text": "each one of those features and essentially get as a link to the page in",
    "start": "2576780",
    "end": "2582809"
  },
  {
    "text": "the guide that covers the sequel server side so then giving you a brief overview of what does this feature mean is equal",
    "start": "2582809",
    "end": "2590339"
  },
  {
    "text": "server and then code blueprints on how you can convert it to the target engine",
    "start": "2590339",
    "end": "2596099"
  },
  {
    "text": "or on my sequel or Postgres so again these are meant to be very hands-on technical playbooks providing all of the",
    "start": "2596099",
    "end": "2602970"
  },
  {
    "text": "blueprints and I do encourage you to use those play books as part of your migration journey alongside SCT and EMS",
    "start": "2602970",
    "end": "2609930"
  },
  {
    "text": "and hopefully you know they will make your life just a little bit easier so thank you very much thank you David",
    "start": "2609930",
    "end": "2622160"
  },
  {
    "text": "let me try and get back here to move it to the other desktop all right music",
    "start": "2622220",
    "end": "2629670"
  },
  {
    "text": "still playing so we're good clicker is here all right so we have 15",
    "start": "2629670",
    "end": "2638480"
  },
  {
    "start": "2635000",
    "end": "2673000"
  },
  {
    "text": "more minutes left so I speak for five minutes and then 10 minutes will ask questions and answers all of us just",
    "start": "2638480",
    "end": "2646849"
  },
  {
    "text": "have again quick product highlights for SCT the assessment report we talked",
    "start": "2646849",
    "end": "2652550"
  },
  {
    "text": "about it helps you understand what is the most compatible engine for your needs with a list of action items",
    "start": "2652550",
    "end": "2660310"
  },
  {
    "text": "convert schema encode and it can extract and migrate data warehouses to Amazon",
    "start": "2660310",
    "end": "2668930"
  },
  {
    "text": "redshift all the six data warehouses that we mentioned earlier the DMS",
    "start": "2668930",
    "end": "2674150"
  },
  {
    "start": "2673000",
    "end": "2745000"
  },
  {
    "text": "highlight the pre mi Gration assessment we validate that before you start the",
    "start": "2674150",
    "end": "2679369"
  },
  {
    "text": "migration everything is well not everything but we are improving it as we go along but the configuration of your",
    "start": "2679369",
    "end": "2687890"
  },
  {
    "text": "migration will not fail or will minimize",
    "start": "2687890",
    "end": "2693470"
  },
  {
    "text": "failure during the migration data validation very important for compliance",
    "start": "2693470",
    "end": "2700099"
  },
  {
    "text": "but also to make sure that everything you migrated we wanted to migrate or you",
    "start": "2700099",
    "end": "2707030"
  },
  {
    "text": "plan to migrate actually made it to the target a true genius environments as well that's I think one of the key elements",
    "start": "2707030",
    "end": "2713450"
  },
  {
    "text": "here and we have the snowball integration for large data base so we",
    "start": "2713450",
    "end": "2719390"
  },
  {
    "text": "released that last year if you're familiar with snowball its appliance",
    "start": "2719390",
    "end": "2724400"
  },
  {
    "text": "device a heavy one you get it you download the your data base you send it",
    "start": "2724400",
    "end": "2729950"
  },
  {
    "text": "we upload it to the region that you asked for and then DMS picks up the",
    "start": "2729950",
    "end": "2735500"
  },
  {
    "text": "changes that happen since you downloaded the migration and it didn't take me five",
    "start": "2735500",
    "end": "2741710"
  },
  {
    "text": "minutes it took me two minutes so we have now by the way I didn't I forgot to",
    "start": "2741710",
    "end": "2749420"
  },
  {
    "start": "2745000",
    "end": "2803000"
  },
  {
    "text": "mention that we celebrated a hundred thousand dr. bass migrate instance",
    "start": "2749420",
    "end": "2754550"
  },
  {
    "text": "migrations I forgot to bring the stickers so",
    "start": "2754550",
    "end": "2761470"
  },
  {
    "text": "apologize for that maybe you have stickers you have okay so we we have",
    "start": "2761470",
    "end": "2767210"
  },
  {
    "text": "stickers to celebrate with us what we often do is we release our best",
    "start": "2767210",
    "end": "2775010"
  },
  {
    "text": "practices as blogs okay so go to our blogs amazon.com AWS amazon.com blogs",
    "start": "2775010",
    "end": "2782780"
  },
  {
    "text": "databases with it's a these are technical blogs these are not marketing vlogs we also make announcements of",
    "start": "2782780",
    "end": "2789890"
  },
  {
    "text": "releases for example the elasticsearch and Kimmy scenes are there plus instructions on how to set it up and how",
    "start": "2789890",
    "end": "2797840"
  },
  {
    "text": "to work the solution with that that's my",
    "start": "2797840",
    "end": "2805190"
  },
  {
    "start": "2803000",
    "end": "3570000"
  },
  {
    "text": "email my name my email my I publish everything on Twitter all the releases",
    "start": "2805190",
    "end": "2811700"
  },
  {
    "text": "because I heard that about a hundred percent if not more of our customers I",
    "start": "2811700",
    "end": "2818150"
  },
  {
    "text": "don't know what's new what's coming or what what we released so I publish it",
    "start": "2818150",
    "end": "2824930"
  },
  {
    "text": "there if you wanna track or through the blog is also fine and we will take",
    "start": "2824930",
    "end": "2831170"
  },
  {
    "text": "questions now if you have any we'll be more than happy to answer but you'll",
    "start": "2831170",
    "end": "2838490"
  },
  {
    "text": "have to say who you're and I don't know how does it work yeah I can mic or",
    "start": "2838490",
    "end": "2844490"
  },
  {
    "text": "something any questions by the way oh we did a perfect job okay here I'll repeat",
    "start": "2844490",
    "end": "2853640"
  },
  {
    "text": "the question the Verizon okay yeah we did see some",
    "start": "2853640",
    "end": "2870800"
  },
  {
    "text": "repeat the question the question the question is once we did the migrations",
    "start": "2870800",
    "end": "2877070"
  },
  {
    "text": "from two Postgres what kind of issues did we see so so far most of them are",
    "start": "2877070",
    "end": "2883160"
  },
  {
    "text": "related to the applications folks not being much familiar with how the process",
    "start": "2883160",
    "end": "2888260"
  },
  {
    "text": "works so we needed to work with some performance tuning and apart from that we haven't seen any major issues mostly",
    "start": "2888260",
    "end": "2894980"
  },
  {
    "text": "related to getting familiar with the new database engine yes please there's a",
    "start": "2894980",
    "end": "2907250"
  },
  {
    "text": "question for me or Verizon okay have you used a validation fee we did but we also",
    "start": "2907250",
    "end": "2912830"
  },
  {
    "text": "it does slow down the process of the data copy right and also some cases we",
    "start": "2912830",
    "end": "2919310"
  },
  {
    "text": "had to do again another round of validation so we basically turn it off and try to do it ourselves so it's a",
    "start": "2919310",
    "end": "2925940"
  },
  {
    "text": "work in progress we're improving performance we're splitting it into two different tasks so performance will not",
    "start": "2925940",
    "end": "2931880"
  },
  {
    "text": "be interrupted or you not see you won't",
    "start": "2931880",
    "end": "2938420"
  },
  {
    "text": "see any degradation because of the validation no what",
    "start": "2938420",
    "end": "2946450"
  },
  {
    "text": "I'm not allowed to comment on and I'm on film here so ya are getting me to travel",
    "start": "2946970",
    "end": "2953580"
  },
  {
    "text": "yes please know so far what we migrated",
    "start": "2953580",
    "end": "2965130"
  },
  {
    "text": "are like reveal and the question is did we decouple our applications because",
    "start": "2965130",
    "end": "2971310"
  },
  {
    "text": "most of the applications talk to each other but what we migrated are the applications which are standalone mostly",
    "start": "2971310",
    "end": "2978030"
  },
  {
    "text": "business critical functions like serving internal customers so the applications you are talking about fall under the",
    "start": "2978030",
    "end": "2984180"
  },
  {
    "text": "mission-critical category we are still in the process of migrating yes please",
    "start": "2984180",
    "end": "2992000"
  },
  {
    "text": "yeah",
    "start": "3005110",
    "end": "3008110"
  },
  {
    "text": "sure sure the question is what we did for the application layer for the",
    "start": "3020650",
    "end": "3026680"
  },
  {
    "text": "databases we migrated to aid abuse yes they were also migrated most of them were using again commercial database",
    "start": "3026680",
    "end": "3033190"
  },
  {
    "text": "engines like WebLogic WebSphere they were migrated to apache tomcat and they had to rewrite some of them and yes but",
    "start": "3033190",
    "end": "3040570"
  },
  {
    "text": "more all the uplink all the databases which we migrated have the application start sitting in AWS as well and they're",
    "start": "3040570",
    "end": "3046840"
  },
  {
    "text": "running on an ec2 instance the largest",
    "start": "3046840",
    "end": "3052450"
  },
  {
    "text": "one we migrated so far is 1.5 terabytes",
    "start": "3052450",
    "end": "3056700"
  },
  {
    "text": "no mainly with the data migration right it was taken really long but once we did",
    "start": "3059040",
    "end": "3066010"
  },
  {
    "text": "the migration we did the cutover within a day or two so we haven't seen much",
    "start": "3066010",
    "end": "3071110"
  },
  {
    "text": "issues not a day downtime rate we also have the continuous replication in place",
    "start": "3071110",
    "end": "3077170"
  },
  {
    "text": "so once the we did all our validations as well we just did a cut over so there was no downtime yes yes DMS has a",
    "start": "3077170",
    "end": "3086020"
  },
  {
    "text": "continuous replication right so we can yeah it does support abuse I saw questions here please",
    "start": "3086020",
    "end": "3093720"
  },
  {
    "text": "the support for db2 we support db2 l UW as a source same as any other engine and",
    "start": "3093720",
    "end": "3100660"
  },
  {
    "text": "we so you can amend the conversions as well with the city yes please",
    "start": "3100660",
    "end": "3111330"
  },
  {
    "text": "you mean converting the columns the code certain cultures and functions how much",
    "start": "3118890",
    "end": "3125050"
  },
  {
    "text": "manual work payables most of it SCT does right so there are a few columns which we had to like I said an example about",
    "start": "3125050",
    "end": "3131800"
  },
  {
    "text": "the number data type where we had to change it sed does the hundred percent for the column level but coming to the",
    "start": "3131800",
    "end": "3138940"
  },
  {
    "text": "sequel code it depends upon what kind of procedures of functions you have right so twenty percent by twenty percent is",
    "start": "3138940",
    "end": "3147130"
  },
  {
    "text": "twenty twenty percent is what we had to rewrite to make it work and we keep iterating and improving so we learn",
    "start": "3147130",
    "end": "3155290"
  },
  {
    "text": "based on samples and keep we have a huge sample databases in our labs and we see",
    "start": "3155290",
    "end": "3162280"
  },
  {
    "text": "that with every version of SCT which goes out every month the percentage goes",
    "start": "3162280",
    "end": "3167860"
  },
  {
    "text": "of manual work goes down plus you have the books that they were not available",
    "start": "3167860",
    "end": "3175690"
  },
  {
    "text": "at the time so it has they are now the books the books yes but you're reading",
    "start": "3175690",
    "end": "3183690"
  },
  {
    "text": "the rice and you're populated no we were",
    "start": "3183690",
    "end": "3193390"
  },
  {
    "text": "seeing latency so we are always trying to run both application stack and the database in a debase",
    "start": "3193390",
    "end": "3199859"
  },
  {
    "text": "know what we saw most of our databases are which we use Oracle so we got a",
    "start": "3208400",
    "end": "3213690"
  },
  {
    "text": "better conversion rate by going to Postgres so yeah so it's more compatible",
    "start": "3213690",
    "end": "3220800"
  },
  {
    "text": "it more most of the code we had in Oracle we need to do less rewrites to make it work in Postgres",
    "start": "3220800",
    "end": "3228559"
  },
  {
    "text": "what variants I would say around twenty",
    "start": "3229700",
    "end": "3237180"
  },
  {
    "text": "to thirty percent for our per our databases I'm talking about only what we have seen with our database there's an interesting news case online",
    "start": "3237180",
    "end": "3245750"
  },
  {
    "text": "forget the name of the company sorry that used SCT to evaluate which is the",
    "start": "3246410",
    "end": "3252540"
  },
  {
    "text": "best platform for their needs for moving off of Oracle and where is he Trimble",
    "start": "3252540",
    "end": "3260100"
  },
  {
    "text": "sorry please",
    "start": "3260100",
    "end": "3264830"
  },
  {
    "text": "yes yes the question is is there a tool to convert SSI packages and the answer",
    "start": "3276220",
    "end": "3284329"
  },
  {
    "text": "is currently no but maybe in the future",
    "start": "3284329",
    "end": "3292930"
  },
  {
    "text": "we are trying to convert them to be basically for most of our databases",
    "start": "3299170",
    "end": "3304630"
  },
  {
    "text": "which we migrate we still have an ec2 server which we are using like a jumps over for running any of the bad jobs we",
    "start": "3304630",
    "end": "3310690"
  },
  {
    "text": "can try to convert them into a bad job and try to run them through cron yeah but there are extinctions available for",
    "start": "3310690",
    "end": "3317440"
  },
  {
    "text": "Posterous I don't know if they're available yet on Aurora Post crest but they said they will be available soon so",
    "start": "3317440",
    "end": "3322869"
  },
  {
    "text": "which we could use like a baby similar to DBMS scheduler yes please no dumb",
    "start": "3322869",
    "end": "3330579"
  },
  {
    "text": "questions from post quest to post press",
    "start": "3330579",
    "end": "3345190"
  },
  {
    "text": "it's usually pretty smooth it's very I'm not sure that you yeah but you can",
    "start": "3345190",
    "end": "3351910"
  },
  {
    "text": "evaluate it using using the tools and see yeah and yeah yeah I close to 100%",
    "start": "3351910",
    "end": "3359940"
  },
  {
    "text": "yeah I supposed to be pleased so we",
    "start": "3359940",
    "end": "3372219"
  },
  {
    "text": "recommend as a sorry the question is about snowball migration what's the volume of migration the rule of thumb is",
    "start": "3372219",
    "end": "3379959"
  },
  {
    "text": "six terabytes go to snowball but we've already seen customer migrate over 20",
    "start": "3379959",
    "end": "3386380"
  },
  {
    "text": "terabytes using TMS over the network it also depends on the speed of the network",
    "start": "3386380",
    "end": "3392920"
  },
  {
    "text": "the strength of the network so there are many elements here that you need to take into account rule of thumb again six",
    "start": "3392920",
    "end": "3399819"
  },
  {
    "text": "Tara terabytes is is that oh I need to",
    "start": "3399819",
    "end": "3408249"
  },
  {
    "text": "move to the center sorry there was a question here",
    "start": "3408249",
    "end": "3412828"
  },
  {
    "text": "I don't know I'm supposed to talk about numbers but yeah there was significant cost savings I would say it's an enterprise and moving away from Oracle",
    "start": "3434300",
    "end": "3442880"
  },
  {
    "text": "and then support wise yeah we we just work with directly with the Amazon support to on any kind of issues we run",
    "start": "3442880",
    "end": "3448849"
  },
  {
    "text": "into they helped us out they were they would point us to what can be done to fix the issue in some cases yes so far",
    "start": "3448849",
    "end": "3463990"
  },
  {
    "text": "hopefully no reason not to be",
    "start": "3463990",
    "end": "3469670"
  },
  {
    "text": "last question sorry please",
    "start": "3469670",
    "end": "3473559"
  },
  {
    "text": "here we have the sequel server database expert in migrations around",
    "start": "3481510",
    "end": "3489700"
  },
  {
    "text": "guys thank you very much we're out of time we're we're thank you [Applause]",
    "start": "3563359",
    "end": "3571719"
  }
]
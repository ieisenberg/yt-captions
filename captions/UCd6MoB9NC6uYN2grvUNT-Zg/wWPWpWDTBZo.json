[
  {
    "text": "[Music]",
    "start": "410",
    "end": "11999"
  },
  {
    "text": "hello i'm bunny a cloud support engineer",
    "start": "12719",
    "end": "15360"
  },
  {
    "text": "here at the aws office in northern",
    "start": "15360",
    "end": "17520"
  },
  {
    "text": "virginia today i am going to show you",
    "start": "17520",
    "end": "20480"
  },
  {
    "text": "how you can resolve the error container",
    "start": "20480",
    "end": "23039"
  },
  {
    "text": "killed on request exit code is 137 in",
    "start": "23039",
    "end": "26640"
  },
  {
    "text": "spark on an amazon emr cluster",
    "start": "26640",
    "end": "29599"
  },
  {
    "text": "let's get started",
    "start": "29599",
    "end": "31519"
  },
  {
    "text": "when a container or spark executor runs",
    "start": "31519",
    "end": "34320"
  },
  {
    "text": "out of memory yarn automatically kills",
    "start": "34320",
    "end": "36719"
  },
  {
    "text": "it",
    "start": "36719",
    "end": "37520"
  },
  {
    "text": "this causes a container killed on",
    "start": "37520",
    "end": "39120"
  },
  {
    "text": "request exit code is 137 error",
    "start": "39120",
    "end": "42719"
  },
  {
    "text": "these errors can happen in different job",
    "start": "42719",
    "end": "44960"
  },
  {
    "text": "stages",
    "start": "44960",
    "end": "46000"
  },
  {
    "text": "both in narrow and wide transformations",
    "start": "46000",
    "end": "49360"
  },
  {
    "text": "to resolve this error you can use one or",
    "start": "49360",
    "end": "52239"
  },
  {
    "text": "more of the following methods",
    "start": "52239",
    "end": "54320"
  },
  {
    "text": "increase driver or executor memory",
    "start": "54320",
    "end": "57039"
  },
  {
    "text": "add more spark partitions reduce the",
    "start": "57039",
    "end": "59760"
  },
  {
    "text": "number of executor cores",
    "start": "59760",
    "end": "62399"
  },
  {
    "text": "increase driver or executor memory",
    "start": "62399",
    "end": "65280"
  },
  {
    "text": "increase container memory by tuning the",
    "start": "65280",
    "end": "67439"
  },
  {
    "text": "spark.executor.memory",
    "start": "67439",
    "end": "69439"
  },
  {
    "text": "or",
    "start": "69439",
    "end": "70280"
  },
  {
    "text": "spark.driver.memory parameters depending",
    "start": "70280",
    "end": "72400"
  },
  {
    "text": "on which container calls the error",
    "start": "72400",
    "end": "75200"
  },
  {
    "text": "on the running amazon emr cluster",
    "start": "75200",
    "end": "77920"
  },
  {
    "text": "modify sparkdefaults.conf",
    "start": "77920",
    "end": "80080"
  },
  {
    "text": "on the masternode",
    "start": "80080",
    "end": "82080"
  },
  {
    "text": "for a single job use the executor memory",
    "start": "82080",
    "end": "84880"
  },
  {
    "text": "or driver memory option to increase the",
    "start": "84880",
    "end": "87360"
  },
  {
    "text": "memory when you run spark submit",
    "start": "87360",
    "end": "91439"
  },
  {
    "text": "add more spark partitions if you can't",
    "start": "91520",
    "end": "94079"
  },
  {
    "text": "increase container memory for example if",
    "start": "94079",
    "end": "97119"
  },
  {
    "text": "you're using maximize resource",
    "start": "97119",
    "end": "98720"
  },
  {
    "text": "allocation on the node",
    "start": "98720",
    "end": "100400"
  },
  {
    "text": "increase the number of spark partitions",
    "start": "100400",
    "end": "103360"
  },
  {
    "text": "this reduces the amount of data that's",
    "start": "103360",
    "end": "106079"
  },
  {
    "text": "processed by a single spark task",
    "start": "106079",
    "end": "108799"
  },
  {
    "text": "which reduces the overall memory used by",
    "start": "108799",
    "end": "111520"
  },
  {
    "text": "a single executor",
    "start": "111520",
    "end": "113680"
  },
  {
    "text": "use this color code to add more spark",
    "start": "113680",
    "end": "115759"
  },
  {
    "text": "partitions",
    "start": "115759",
    "end": "118399"
  },
  {
    "text": "if the error happens during a white",
    "start": "119520",
    "end": "121439"
  },
  {
    "text": "transformation for example join or group",
    "start": "121439",
    "end": "124560"
  },
  {
    "text": "by add more shuffle partitions the",
    "start": "124560",
    "end": "127200"
  },
  {
    "text": "default value is 200",
    "start": "127200",
    "end": "129840"
  },
  {
    "text": "on the running emr cluster modify",
    "start": "129840",
    "end": "132920"
  },
  {
    "text": "sparkdefaults.com on the master node",
    "start": "132920",
    "end": "135920"
  },
  {
    "text": "for a single job use the conf",
    "start": "135920",
    "end": "140000"
  },
  {
    "text": "spark.sequel.shuffle.partitions option",
    "start": "140360",
    "end": "142239"
  },
  {
    "text": "to add more shuffle partitions when you",
    "start": "142239",
    "end": "144400"
  },
  {
    "text": "run spark submit",
    "start": "144400",
    "end": "147439"
  },
  {
    "text": "reduce the number of executor cores",
    "start": "148720",
    "end": "151280"
  },
  {
    "text": "this reduces the maximum number of tasks",
    "start": "151280",
    "end": "153760"
  },
  {
    "text": "that the executor processes",
    "start": "153760",
    "end": "155519"
  },
  {
    "text": "simultaneously",
    "start": "155519",
    "end": "156800"
  },
  {
    "text": "which reduces the amount of memory that",
    "start": "156800",
    "end": "158640"
  },
  {
    "text": "the container uses",
    "start": "158640",
    "end": "160480"
  },
  {
    "text": "on the running emr cluster modify",
    "start": "160480",
    "end": "162560"
  },
  {
    "text": "sparkdefaults.com",
    "start": "162560",
    "end": "164160"
  },
  {
    "text": "on the masternode",
    "start": "164160",
    "end": "165920"
  },
  {
    "text": "for a single job use the executor cores",
    "start": "165920",
    "end": "168720"
  },
  {
    "text": "option",
    "start": "168720",
    "end": "169599"
  },
  {
    "text": "to reduce the number of executor cores",
    "start": "169599",
    "end": "171840"
  },
  {
    "text": "when you run spark submit",
    "start": "171840",
    "end": "174239"
  },
  {
    "text": "so now you know how to resolve the error",
    "start": "174239",
    "end": "176720"
  },
  {
    "text": "container killed on request exit code is",
    "start": "176720",
    "end": "179120"
  },
  {
    "text": "137 in spark on an emr cluster",
    "start": "179120",
    "end": "183200"
  },
  {
    "text": "thanks for watching and happy cloud",
    "start": "183200",
    "end": "184800"
  },
  {
    "text": "computing from all of us here at aws",
    "start": "184800",
    "end": "188760"
  },
  {
    "text": "[Music]",
    "start": "188760",
    "end": "194969"
  }
]
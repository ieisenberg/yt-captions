[
  {
    "text": "in this video you'll see how to enable",
    "start": "799",
    "end": "2560"
  },
  {
    "text": "end users to launch amazon emr clusters",
    "start": "2560",
    "end": "5120"
  },
  {
    "text": "using aws service catalog",
    "start": "5120",
    "end": "7680"
  },
  {
    "text": "with aws service catalog you can make",
    "start": "7680",
    "end": "9920"
  },
  {
    "text": "your emr platform self-serviceable",
    "start": "9920",
    "end": "12080"
  },
  {
    "text": "reduce the emr learning curve for your",
    "start": "12080",
    "end": "13840"
  },
  {
    "text": "users and ensure adherence to security",
    "start": "13840",
    "end": "16320"
  },
  {
    "text": "standards and best practices",
    "start": "16320",
    "end": "18960"
  },
  {
    "text": "amazon emr is a managed cluster platform",
    "start": "18960",
    "end": "21600"
  },
  {
    "text": "that simplifies running big data",
    "start": "21600",
    "end": "23279"
  },
  {
    "text": "frameworks",
    "start": "23279",
    "end": "24000"
  },
  {
    "text": "such as apache hadoop and apache spark",
    "start": "24000",
    "end": "26400"
  },
  {
    "text": "on aws",
    "start": "26400",
    "end": "27359"
  },
  {
    "text": "to process and analyze vast amounts of",
    "start": "27359",
    "end": "29359"
  },
  {
    "text": "data as an administrator in aws service",
    "start": "29359",
    "end": "32398"
  },
  {
    "text": "catalog",
    "start": "32399",
    "end": "33120"
  },
  {
    "text": "you can provide emr as a self-serve",
    "start": "33120",
    "end": "35040"
  },
  {
    "text": "extract transform load or etl",
    "start": "35040",
    "end": "37360"
  },
  {
    "text": "platform at scale while hiding all the",
    "start": "37360",
    "end": "39440"
  },
  {
    "text": "security and network configurations from",
    "start": "39440",
    "end": "41280"
  },
  {
    "text": "end users",
    "start": "41280",
    "end": "42399"
  },
  {
    "text": "to see what this solution might look",
    "start": "42399",
    "end": "43840"
  },
  {
    "text": "like in an organization let's navigate",
    "start": "43840",
    "end": "45760"
  },
  {
    "text": "to service catalog",
    "start": "45760",
    "end": "48800"
  },
  {
    "text": "in this sample organization we have",
    "start": "49360",
    "end": "51280"
  },
  {
    "text": "already created a portfolio containing a",
    "start": "51280",
    "end": "53280"
  },
  {
    "text": "variety of predefined emr clusters for",
    "start": "53280",
    "end": "55600"
  },
  {
    "text": "data engineers",
    "start": "55600",
    "end": "57520"
  },
  {
    "text": "as you can see two service catalog",
    "start": "57520",
    "end": "59680"
  },
  {
    "text": "products have already been set up for",
    "start": "59680",
    "end": "61039"
  },
  {
    "text": "users",
    "start": "61039",
    "end": "61920"
  },
  {
    "text": "let's select the emr etl engine for",
    "start": "61920",
    "end": "64080"
  },
  {
    "text": "executing spark and hive jobs",
    "start": "64080",
    "end": "67439"
  },
  {
    "text": "here you can see that a cloud formation",
    "start": "67439",
    "end": "68960"
  },
  {
    "text": "template was used to create all the",
    "start": "68960",
    "end": "70479"
  },
  {
    "text": "required aws resources for the types of",
    "start": "70479",
    "end": "72880"
  },
  {
    "text": "etl jobs performed in the organization",
    "start": "72880",
    "end": "77118"
  },
  {
    "text": "in this case two product versions have",
    "start": "77360",
    "end": "79040"
  },
  {
    "text": "been provided",
    "start": "79040",
    "end": "80960"
  },
  {
    "text": "next let's see how an end user can use",
    "start": "80960",
    "end": "82880"
  },
  {
    "text": "these products to submit an etl job for",
    "start": "82880",
    "end": "85119"
  },
  {
    "text": "processing",
    "start": "85119",
    "end": "87840"
  },
  {
    "text": "as a data scientist let's navigate to",
    "start": "88000",
    "end": "90240"
  },
  {
    "text": "service catalog",
    "start": "90240",
    "end": "91200"
  },
  {
    "text": "to provision an emr cluster for an etl",
    "start": "91200",
    "end": "93600"
  },
  {
    "text": "job",
    "start": "93600",
    "end": "95840"
  },
  {
    "text": "first we'll specify a name for the",
    "start": "96640",
    "end": "98159"
  },
  {
    "text": "provision product and then select which",
    "start": "98159",
    "end": "100159"
  },
  {
    "text": "version we want to use",
    "start": "100159",
    "end": "101840"
  },
  {
    "text": "in this case we'll use version 5.29.0",
    "start": "101840",
    "end": "107039"
  },
  {
    "text": "next we'll specify the cluster",
    "start": "109280",
    "end": "110720"
  },
  {
    "text": "parameters for our purposes we'll start",
    "start": "110720",
    "end": "113600"
  },
  {
    "text": "a spark etl job",
    "start": "113600",
    "end": "115119"
  },
  {
    "text": "using a script that's been placed in an",
    "start": "115119",
    "end": "116799"
  },
  {
    "text": "amazon simple storage service or amazon",
    "start": "116799",
    "end": "119119"
  },
  {
    "text": "s3 bucket",
    "start": "119119",
    "end": "121920"
  },
  {
    "text": "optionally users can be allowed to add",
    "start": "123600",
    "end": "125600"
  },
  {
    "text": "tags to emr clusters they create",
    "start": "125600",
    "end": "129840"
  },
  {
    "text": "users can enable provision product event",
    "start": "130000",
    "end": "132080"
  },
  {
    "text": "notifications to be streamed to an",
    "start": "132080",
    "end": "133760"
  },
  {
    "text": "amazon simple notification service or",
    "start": "133760",
    "end": "135760"
  },
  {
    "text": "amazon sns topic",
    "start": "135760",
    "end": "139120"
  },
  {
    "text": "let's review the settings and launch the",
    "start": "139440",
    "end": "141040"
  },
  {
    "text": "product",
    "start": "141040",
    "end": "143840"
  },
  {
    "text": "while the emr cluster is provisioning",
    "start": "144400",
    "end": "146319"
  },
  {
    "text": "let's switch back to the administrator's",
    "start": "146319",
    "end": "147840"
  },
  {
    "text": "view of the aws console",
    "start": "147840",
    "end": "151440"
  },
  {
    "text": "as you can see the emr cluster",
    "start": "152959",
    "end": "154720"
  },
  {
    "text": "provisioned by the end user",
    "start": "154720",
    "end": "156000"
  },
  {
    "text": "is initializing",
    "start": "156000",
    "end": "158879"
  },
  {
    "text": "here you can see the cluster is waiting",
    "start": "159440",
    "end": "161040"
  },
  {
    "text": "on another spark or hive job to be",
    "start": "161040",
    "end": "162879"
  },
  {
    "text": "requested",
    "start": "162879",
    "end": "163840"
  },
  {
    "text": "indicating that the user's job is",
    "start": "163840",
    "end": "165360"
  },
  {
    "text": "completed you can also see other",
    "start": "165360",
    "end": "167680"
  },
  {
    "text": "parameters associated with the emr",
    "start": "167680",
    "end": "169519"
  },
  {
    "text": "cluster",
    "start": "169519",
    "end": "170239"
  },
  {
    "text": "such as tags that were specified by the",
    "start": "170239",
    "end": "172000"
  },
  {
    "text": "cloudformation template",
    "start": "172000",
    "end": "174239"
  },
  {
    "text": "you can also see and review the",
    "start": "174239",
    "end": "175760"
  },
  {
    "text": "networking configuration settings",
    "start": "175760",
    "end": "179360"
  },
  {
    "text": "the security and access parameters for",
    "start": "181519",
    "end": "183360"
  },
  {
    "text": "the ec2 instances",
    "start": "183360",
    "end": "184720"
  },
  {
    "text": "were automatically assigned through the",
    "start": "184720",
    "end": "186239"
  },
  {
    "text": "cloudformation template for the cluster",
    "start": "186239",
    "end": "188000"
  },
  {
    "text": "as well",
    "start": "188000",
    "end": "190400"
  },
  {
    "text": "here you can see the hardware used by",
    "start": "194080",
    "end": "195760"
  },
  {
    "text": "the emr cluster",
    "start": "195760",
    "end": "197280"
  },
  {
    "text": "you can also view or modify cluster",
    "start": "197280",
    "end": "199280"
  },
  {
    "text": "scaling policies",
    "start": "199280",
    "end": "201200"
  },
  {
    "text": "setting these policies can reduce",
    "start": "201200",
    "end": "202720"
  },
  {
    "text": "computational costs and help track the",
    "start": "202720",
    "end": "204799"
  },
  {
    "text": "computational resources being utilized",
    "start": "204799",
    "end": "208879"
  },
  {
    "text": "here you can see that the task node of",
    "start": "210319",
    "end": "212000"
  },
  {
    "text": "the cluster has been assigned an auto",
    "start": "212000",
    "end": "213760"
  },
  {
    "text": "scaling policy",
    "start": "213760",
    "end": "215440"
  },
  {
    "text": "you can edit the policy from here",
    "start": "215440",
    "end": "218959"
  },
  {
    "text": "you can choose to make auto scaling more",
    "start": "219440",
    "end": "221280"
  },
  {
    "text": "or less sensitive or you can increase or",
    "start": "221280",
    "end": "223280"
  },
  {
    "text": "decrease the threshold to trigger auto",
    "start": "223280",
    "end": "225040"
  },
  {
    "text": "scaling let's leave these parameters as",
    "start": "225040",
    "end": "227280"
  },
  {
    "text": "they are",
    "start": "227280",
    "end": "229599"
  },
  {
    "text": "on the steps tab you can see events",
    "start": "232159",
    "end": "234080"
  },
  {
    "text": "corresponding to computational jobs",
    "start": "234080",
    "end": "235920"
  },
  {
    "text": "performed by the cluster",
    "start": "235920",
    "end": "237840"
  },
  {
    "text": "this step corresponds to the spark etl",
    "start": "237840",
    "end": "240080"
  },
  {
    "text": "job requested by the end user",
    "start": "240080",
    "end": "242480"
  },
  {
    "text": "you can expand this step to see the job",
    "start": "242480",
    "end": "244239"
  },
  {
    "text": "parameters specified by the end user",
    "start": "244239",
    "end": "247360"
  },
  {
    "text": "now that the cluster is provisioned and",
    "start": "247360",
    "end": "248879"
  },
  {
    "text": "the job is completed let's switch back",
    "start": "248879",
    "end": "250720"
  },
  {
    "text": "to the end user's perspective",
    "start": "250720",
    "end": "254159"
  },
  {
    "text": "the end user navigates to the s3",
    "start": "254159",
    "end": "256079"
  },
  {
    "text": "management console to see the data",
    "start": "256079",
    "end": "257600"
  },
  {
    "text": "output",
    "start": "257600",
    "end": "258479"
  },
  {
    "text": "this is the s3 bucket containing the",
    "start": "258479",
    "end": "260320"
  },
  {
    "text": "logs for the emr cluster",
    "start": "260320",
    "end": "262079"
  },
  {
    "text": "the etl job scripts and the output for",
    "start": "262079",
    "end": "264320"
  },
  {
    "text": "the spark job",
    "start": "264320",
    "end": "265440"
  },
  {
    "text": "let's open the spark folder to see the",
    "start": "265440",
    "end": "267120"
  },
  {
    "text": "output",
    "start": "267120",
    "end": "269840"
  },
  {
    "text": "we'll select the first data output to",
    "start": "270080",
    "end": "271759"
  },
  {
    "text": "ensure the script worked",
    "start": "271759",
    "end": "274720"
  },
  {
    "text": "right from here we can extract the",
    "start": "274720",
    "end": "276240"
  },
  {
    "text": "records in parquet and generate a",
    "start": "276240",
    "end": "278160"
  },
  {
    "text": "preview before writing back to amazon s3",
    "start": "278160",
    "end": "281199"
  },
  {
    "text": "this preview incurs a usage charge",
    "start": "281199",
    "end": "284800"
  },
  {
    "text": "the reviews have been successfully",
    "start": "284800",
    "end": "286240"
  },
  {
    "text": "generated from the etl job",
    "start": "286240",
    "end": "288960"
  },
  {
    "text": "now let's return to service catalog to",
    "start": "288960",
    "end": "290800"
  },
  {
    "text": "submit another job to the same cluster",
    "start": "290800",
    "end": "294638"
  },
  {
    "text": "from the update page users can change",
    "start": "294720",
    "end": "296720"
  },
  {
    "text": "any of the parameters they initially set",
    "start": "296720",
    "end": "298560"
  },
  {
    "text": "for the provision product before",
    "start": "298560",
    "end": "300000"
  },
  {
    "text": "submitting the new job",
    "start": "300000",
    "end": "302560"
  },
  {
    "text": "let's use the same emr version we",
    "start": "302560",
    "end": "304320"
  },
  {
    "text": "previously selected",
    "start": "304320",
    "end": "307360"
  },
  {
    "text": "because we are updating a provisioned",
    "start": "307840",
    "end": "309440"
  },
  {
    "text": "product the same cluster will be used",
    "start": "309440",
    "end": "311280"
  },
  {
    "text": "for the job",
    "start": "311280",
    "end": "313840"
  },
  {
    "text": "this time let's use hive as the etl job",
    "start": "313840",
    "end": "316160"
  },
  {
    "text": "type and modify the job parameters",
    "start": "316160",
    "end": "320000"
  },
  {
    "text": "accordingly",
    "start": "322840",
    "end": "325840"
  },
  {
    "text": "while the cluster updates let's return",
    "start": "327039",
    "end": "328880"
  },
  {
    "text": "to the aws console as the administrator",
    "start": "328880",
    "end": "333199"
  },
  {
    "text": "you can see here that another etl job",
    "start": "337360",
    "end": "339360"
  },
  {
    "text": "was submitted on the same emr cluster",
    "start": "339360",
    "end": "343360"
  },
  {
    "text": "the second etl job is now completed",
    "start": "343919",
    "end": "346880"
  },
  {
    "text": "let's return to the end user's",
    "start": "346880",
    "end": "348160"
  },
  {
    "text": "perspective and view the data output",
    "start": "348160",
    "end": "349919"
  },
  {
    "text": "associated with the hive job",
    "start": "349919",
    "end": "352320"
  },
  {
    "text": "the hive script we ran reads amazon",
    "start": "352320",
    "end": "354240"
  },
  {
    "text": "reviews data from amazon s3",
    "start": "354240",
    "end": "356240"
  },
  {
    "text": "and discovers the top toys based on",
    "start": "356240",
    "end": "358000"
  },
  {
    "text": "customer ratings",
    "start": "358000",
    "end": "359680"
  },
  {
    "text": "let's go see the results",
    "start": "359680",
    "end": "362880"
  },
  {
    "text": "this time we'll preview the data in csv",
    "start": "363759",
    "end": "365919"
  },
  {
    "text": "format",
    "start": "365919",
    "end": "368400"
  },
  {
    "text": "here you can see the top toys by amazon",
    "start": "369039",
    "end": "370960"
  },
  {
    "text": "review score as tab separated values",
    "start": "370960",
    "end": "374160"
  },
  {
    "text": "you've just seen how to enable end users",
    "start": "374160",
    "end": "375919"
  },
  {
    "text": "to launch amazon emr clusters using aws",
    "start": "375919",
    "end": "378720"
  },
  {
    "text": "service catalog",
    "start": "378720",
    "end": "380560"
  },
  {
    "text": "thanks for watching now it's your turn",
    "start": "380560",
    "end": "382080"
  },
  {
    "text": "to try",
    "start": "382080",
    "end": "386478"
  }
]
[
  {
    "text": "(upbeat electronic music)",
    "start": "0",
    "end": "3660"
  },
  {
    "text": "- Hey, hey, this is Dr. Nashlie Sephus",
    "start": "3660",
    "end": "5970"
  },
  {
    "text": "and I'm a principal AI scientist\nat Amazon Web Services.",
    "start": "5970",
    "end": "9510"
  },
  {
    "text": "I specialize in responsible AI,",
    "start": "9510",
    "end": "11610"
  },
  {
    "text": "and today, we're gonna\ntalk to Alicia, Mia,",
    "start": "11610",
    "end": "14580"
  },
  {
    "text": "as well as Valeria, who work\non the responsible AI team,",
    "start": "14580",
    "end": "17700"
  },
  {
    "text": "about the work that they've\ndone, and we're gonna show you",
    "start": "17700",
    "end": "20130"
  },
  {
    "text": "how you can get more involved, as well.",
    "start": "20130",
    "end": "21602"
  },
  {
    "text": "(upbeat electronic music)",
    "start": "21602",
    "end": "23670"
  },
  {
    "text": "There are different\ndimensions of responsible AI,",
    "start": "23670",
    "end": "26280"
  },
  {
    "text": "and so, there's the data,\nthere's the end results,",
    "start": "26280",
    "end": "29460"
  },
  {
    "text": "the guardrails, but you're\nfocusing directly on the model.",
    "start": "29460",
    "end": "32369"
  },
  {
    "text": "I know you've done a lot of great work,",
    "start": "32370",
    "end": "33899"
  },
  {
    "text": "but I know there's one paper in particular",
    "start": "33900",
    "end": "35910"
  },
  {
    "text": "that really caught my interest",
    "start": "35910",
    "end": "37290"
  },
  {
    "text": "and it's called \"Talking Nonsense.\"",
    "start": "37290",
    "end": "39300"
  },
  {
    "text": "Can you tell us a little about that paper?",
    "start": "39300",
    "end": "41399"
  },
  {
    "text": "- I'm interested in taking\nthis huge foundational model,",
    "start": "41400",
    "end": "45630"
  },
  {
    "text": "but then exploring,",
    "start": "45630",
    "end": "46680"
  },
  {
    "text": "okay, what kind of\nvulnerabilities does it have?",
    "start": "46680",
    "end": "48840"
  },
  {
    "text": "How can we make it\nactually safe and secure?",
    "start": "48840",
    "end": "52290"
  },
  {
    "text": "The paper is about finding that,",
    "start": "52290",
    "end": "55440"
  },
  {
    "text": "when you prompt the model with some text",
    "start": "55440",
    "end": "58079"
  },
  {
    "text": "that doesn't make any sense to humans,",
    "start": "58080",
    "end": "59670"
  },
  {
    "text": "it looks like completely gibberish text,",
    "start": "59670",
    "end": "62429"
  },
  {
    "text": "the model can actually output\nsomething meaningful to you,",
    "start": "62430",
    "end": "66210"
  },
  {
    "text": "but you can basically manipulate the model",
    "start": "66210",
    "end": "67950"
  },
  {
    "text": "and respond to it with whatever you want,",
    "start": "67950",
    "end": "70409"
  },
  {
    "text": "even something that the model\nis not supposed to tell you,",
    "start": "70410",
    "end": "73653"
  },
  {
    "text": "like, for example,\nmaybe some harmful text,",
    "start": "74730",
    "end": "76950"
  },
  {
    "text": "or, for example, maybe,\nlike, giving you a refund",
    "start": "76950",
    "end": "80729"
  },
  {
    "text": "from the chat-bot side\nthat would be really bad",
    "start": "80730",
    "end": "83520"
  },
  {
    "text": "for the company deploying that chat-bot.",
    "start": "83520",
    "end": "86280"
  },
  {
    "text": "- You're saying that we can\nuse just totally, like...",
    "start": "86280",
    "end": "90150"
  },
  {
    "text": "Say I just, like, type something,",
    "start": "90150",
    "end": "91830"
  },
  {
    "text": "it doesn't make any sense,\ndoesn't even spell a word,",
    "start": "91830",
    "end": "95070"
  },
  {
    "text": "and I can use that in an adversarial way",
    "start": "95070",
    "end": "97470"
  },
  {
    "text": "to intentionally attack the\nmodel to get me what I want",
    "start": "97470",
    "end": "101100"
  },
  {
    "text": "under the radar without anybody noticing,",
    "start": "101100",
    "end": "103470"
  },
  {
    "text": "and that definitely is a problem, right?",
    "start": "103470",
    "end": "106110"
  },
  {
    "text": "- It's not like you can\ntype whatever you want,",
    "start": "106110",
    "end": "108990"
  },
  {
    "text": "you need to use some kind of optimization",
    "start": "108990",
    "end": "111180"
  },
  {
    "text": "to actually find that problem",
    "start": "111180",
    "end": "112560"
  },
  {
    "text": "that would manipulate the model and...",
    "start": "112560",
    "end": "113948"
  },
  {
    "text": "(indistinct)",
    "start": "113948",
    "end": "114781"
  },
  {
    "text": "In the paper, we ask\nquestions about, like,",
    "start": "114781",
    "end": "117810"
  },
  {
    "text": "when does it happen, what exactly\nhappens inside the models,",
    "start": "117810",
    "end": "120750"
  },
  {
    "text": "and try to explore the\nproblem from that perspective.",
    "start": "120750",
    "end": "123360"
  },
  {
    "text": "- Wow, this is so fascinating to me",
    "start": "123360",
    "end": "125610"
  },
  {
    "text": "because it touches on some of\nthe responsible AI dimensions",
    "start": "125610",
    "end": "129240"
  },
  {
    "text": "like privacy and security,\nalso controllability,",
    "start": "129240",
    "end": "133710"
  },
  {
    "text": "where you're trying to understand",
    "start": "133710",
    "end": "135750"
  },
  {
    "text": "and make sure you have tests\nin place for your models",
    "start": "135750",
    "end": "139080"
  },
  {
    "text": "that don't just use the model",
    "start": "139080",
    "end": "141300"
  },
  {
    "text": "in a way you anticipate users using it,",
    "start": "141300",
    "end": "143580"
  },
  {
    "text": "but use it in a way",
    "start": "143580",
    "end": "144510"
  },
  {
    "text": "that you probably wouldn't anticipate them",
    "start": "144510",
    "end": "146549"
  },
  {
    "text": "using it to, you know,\nkind of hack the system.",
    "start": "146550",
    "end": "150270"
  },
  {
    "text": "I think that is really\nimportant, what you're doing,",
    "start": "150270",
    "end": "152640"
  },
  {
    "text": "and so, with some of the\nresults that you saw,",
    "start": "152640",
    "end": "155010"
  },
  {
    "text": "what do you conclude?",
    "start": "155010",
    "end": "156209"
  },
  {
    "text": "- What we can conclude is that,",
    "start": "156210",
    "end": "158520"
  },
  {
    "text": "just like with any other\nmachine-learning models,",
    "start": "158520",
    "end": "161010"
  },
  {
    "text": "those language models,",
    "start": "161010",
    "end": "162689"
  },
  {
    "text": "they are sensitive to\nvarious adversarial inputs,",
    "start": "162690",
    "end": "166050"
  },
  {
    "text": "but the good news is that...",
    "start": "166050",
    "end": "168330"
  },
  {
    "text": "About those gibberish prompts,",
    "start": "168330",
    "end": "169890"
  },
  {
    "text": "there are methods to check\nthat the input is gibberish",
    "start": "169890",
    "end": "173400"
  },
  {
    "text": "and you can filter them out.",
    "start": "173400",
    "end": "175110"
  },
  {
    "text": "The interesting part is\nthat actually the model",
    "start": "175110",
    "end": "178110"
  },
  {
    "text": "knows that this is gibberish\nadversarial prompt,",
    "start": "178110",
    "end": "181743"
  },
  {
    "text": "we can see that from the\nmodel representations,",
    "start": "182580",
    "end": "186150"
  },
  {
    "text": "and maybe you can use that",
    "start": "186150",
    "end": "187795"
  },
  {
    "text": "to kind of defend against\nthose adversarial inputs.",
    "start": "187795",
    "end": "191643"
  },
  {
    "text": "- You're focusing directly on the model,",
    "start": "192510",
    "end": "194730"
  },
  {
    "text": "and how you can manipulate the model,",
    "start": "194730",
    "end": "196950"
  },
  {
    "text": "and understand how the model works,",
    "start": "196950",
    "end": "198480"
  },
  {
    "text": "and understand where\nit has vulnerabilities.",
    "start": "198480",
    "end": "200849"
  },
  {
    "text": "- Yes, that's very interesting to me,",
    "start": "200850",
    "end": "203250"
  },
  {
    "text": "to, like, first kind of\nidentify those vulnerabilities,",
    "start": "203250",
    "end": "205920"
  },
  {
    "text": "but then, try to understand,\nokay, where do they come from?",
    "start": "205920",
    "end": "208680"
  },
  {
    "text": "What's really going on inside the model?",
    "start": "208680",
    "end": "210480"
  },
  {
    "text": "Why does that happen, and\nwhat can we do about that?",
    "start": "210480",
    "end": "213140"
  },
  {
    "text": "(upbeat electronic music)",
    "start": "213141",
    "end": "216641"
  }
]
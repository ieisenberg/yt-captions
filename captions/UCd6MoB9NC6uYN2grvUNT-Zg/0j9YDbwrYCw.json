[
  {
    "start": "0",
    "end": "67000"
  },
  {
    "text": "thank you all for coming I hope you guys have been enjoying the summit as much as I have so I'm gonna kick off this",
    "start": "30",
    "end": "5810"
  },
  {
    "text": "breakout session here in accelerating analytics for the future of genomics so",
    "start": "5810",
    "end": "10860"
  },
  {
    "text": "I know that this entire summit is not necessarily all biologists hopefully",
    "start": "10860",
    "end": "18210"
  },
  {
    "text": "this audience if you're here right we've got a higher concentration of biologists but just to make sure we're all on the",
    "start": "18210",
    "end": "25920"
  },
  {
    "text": "same page and you know this is sort of will help with the next talk as well I'm just gonna cover a few basics right so",
    "start": "25920",
    "end": "32820"
  },
  {
    "text": "we're talking about genomics what is genomics these are some of the slides I showed at the keynote yesterday but basically right organisms like humans",
    "start": "32820",
    "end": "40020"
  },
  {
    "text": "we're all made of cells cells have a nucleus inside the nucleus or chromosomes and the chromosomes",
    "start": "40020",
    "end": "45180"
  },
  {
    "text": "themselves are made of DNA right and so genomics or the genome of an organism will be the sum total the entire",
    "start": "45180",
    "end": "53070"
  },
  {
    "text": "collection of DNA that's present within nucleus that should be the same in all",
    "start": "53070",
    "end": "58230"
  },
  {
    "text": "the cells in the organism but as we know that's not necessarily true anymore but it should be the same in all the cells",
    "start": "58230",
    "end": "63600"
  },
  {
    "text": "in the organism and that's what we call the organism's genome okay so we always",
    "start": "63600",
    "end": "69000"
  },
  {
    "start": "67000",
    "end": "67000"
  },
  {
    "text": "see DNA drawn is this sort of double helix from the famous structure paper at",
    "start": "69000",
    "end": "74010"
  },
  {
    "text": "a slightly deeper level this would be the chemical structure okay so this is all hopefully familiar stuff to you guys",
    "start": "74010",
    "end": "80939"
  },
  {
    "text": "we abbreviate this with GSA's T's and C's okay we have these sort of rules",
    "start": "80939",
    "end": "86520"
  },
  {
    "text": "about base pairing and if you really think about it one of the reasons we're",
    "start": "86520",
    "end": "91530"
  },
  {
    "text": "here one of the reasons that you know computing is so important for genomics at this point right G 80 and C those are",
    "start": "91530",
    "end": "98939"
  },
  {
    "text": "the four bases that we use to represent DNA if the sequence of those things is very important as well so just like ones",
    "start": "98939",
    "end": "105509"
  },
  {
    "text": "and zeros the sequence you know gives you a different file or a different program here we have four bases which of",
    "start": "105509",
    "end": "112200"
  },
  {
    "text": "course is the same as two bits and so it's explicitly digital and very natural for computation okay and so this is why",
    "start": "112200",
    "end": "119490"
  },
  {
    "text": "genomics as genomics has grown our hunger or our need for computation has",
    "start": "119490",
    "end": "125130"
  },
  {
    "text": "grown in parallel with this as well so how is genomics grown or what are kind",
    "start": "125130",
    "end": "130410"
  },
  {
    "start": "127000",
    "end": "127000"
  },
  {
    "text": "of some of the big issues that we're dealing with today to address that I want to start with a just a little very brief history of DNA",
    "start": "130410",
    "end": "137300"
  },
  {
    "text": "sequencing technology right so as I mentioned we've got G's ace T's and C's it's the order of the GAA and C just",
    "start": "137300",
    "end": "143150"
  },
  {
    "text": "like the order of the bits matter in your file so the order matters and to get that order we do a process called",
    "start": "143150",
    "end": "149569"
  },
  {
    "text": "DNA sequencing essentially reading off that order so DNA sequencing we've known",
    "start": "149569",
    "end": "154610"
  },
  {
    "text": "about DNA of course for quite some time and DNA sequencing really started with maximum Gilbert this is just some",
    "start": "154610",
    "end": "161390"
  },
  {
    "text": "figures about how they did this but they used chemical reactions and radiation so DNA right it's inside of cell as we",
    "start": "161390",
    "end": "167180"
  },
  {
    "text": "mentioned it's got a chemical structure so you can manipulate that and take advantage of the differences between GA",
    "start": "167180",
    "end": "172730"
  },
  {
    "text": "T and C using chemistry so that you can break this and essentially read off the sequence from from this gel after you",
    "start": "172730",
    "end": "180709"
  },
  {
    "text": "radio label them okay as time went on the technology got better we started miniaturizing this and",
    "start": "180709",
    "end": "187760"
  },
  {
    "text": "parallelizing this so that we could do this in higher throughput okay and so there's another technology called",
    "start": "187760",
    "end": "193400"
  },
  {
    "text": "capillary sequencing that came out about 15 years later and then this is really the next phase was really what we call",
    "start": "193400",
    "end": "200600"
  },
  {
    "text": "second generation sequencing at the time of course it was called next-generation sequencing we all know that that's not a great name because then the next one is",
    "start": "200600",
    "end": "206810"
  },
  {
    "text": "next next or next er or next distt right so this was second we typically call the second generation sequencing",
    "start": "206810",
    "end": "213139"
  },
  {
    "text": "now and again we're continuing down this path with even higher density and that image down there is really the data that",
    "start": "213139",
    "end": "219319"
  },
  {
    "text": "you're getting out from the sequencer the raw data from the sequencer is actually an image or a movie right it's",
    "start": "219319",
    "end": "226040"
  },
  {
    "text": "a sequence of images and you interpret that and then translate that into the G's the digital G's Ice T's and C's okay",
    "start": "226040",
    "end": "233000"
  },
  {
    "text": "and I think you can hopefully see where this is going the last iteration or the",
    "start": "233000",
    "end": "238130"
  },
  {
    "text": "most recent iteration are what we would call third-generation sequencers now okay and this is exemplified by Cinco",
    "start": "238130",
    "end": "244670"
  },
  {
    "text": "sir such as the Oxford nanopore sequencer where we're doing direct electric current detection okay so if",
    "start": "244670",
    "end": "250579"
  },
  {
    "text": "you if you look back we started with relying on the chemical structure of DNA okay we started with relying on the",
    "start": "250579",
    "end": "256849"
  },
  {
    "text": "chemical reactivity of DNA we're still around on the chemical structure that differentiates the gsa's T's and C's but",
    "start": "256849",
    "end": "263180"
  },
  {
    "text": "now that's converted directly into kind of a physical property where that affects",
    "start": "263180",
    "end": "268270"
  },
  {
    "text": "current flow through a small pore okay so we no longer need chemistry necessarily we no longer in principle",
    "start": "268270",
    "end": "275380"
  },
  {
    "text": "need radiation to do this detection and as we're going as we've been going across this development of DNA",
    "start": "275380",
    "end": "282400"
  },
  {
    "text": "sequencing technologies really it's been a continuous process of miniaturization",
    "start": "282400",
    "end": "287490"
  },
  {
    "text": "parallelization and digitization right and this is of course why sequencing has",
    "start": "287490",
    "end": "294790"
  },
  {
    "text": "become such a big thing and in terms of how big has this gotten or how fast how",
    "start": "294790",
    "end": "300400"
  },
  {
    "text": "much progress have we made in DNA sequencing so you know again I showed",
    "start": "300400",
    "end": "306880"
  },
  {
    "text": "this idea previously in the and the keynote I'm sure you're all familiar with Moore's Law it's really hard to",
    "start": "306880",
    "end": "312820"
  },
  {
    "text": "keep up with Moore's law to begin with okay that's an exponential rate of progress and you have to keep making",
    "start": "312820",
    "end": "318400"
  },
  {
    "text": "exponential like leaps and bounds every year and then in genomics it looks like",
    "start": "318400",
    "end": "323470"
  },
  {
    "text": "this right so the y-axis is a log scale and we're doing cost per unit sequencing",
    "start": "323470",
    "end": "328630"
  },
  {
    "text": "or cost per compute right so genomics is genomics is going even faster than",
    "start": "328630",
    "end": "335920"
  },
  {
    "start": "334000",
    "end": "334000"
  },
  {
    "text": "Moore's law so genomics data is exploding and it's and what I mean by in the usual way right so when we talk",
    "start": "335920",
    "end": "341770"
  },
  {
    "text": "about Moore's Law and this exponential way to progress we're very familiar with that that's been going on for decades",
    "start": "341770",
    "end": "346930"
  },
  {
    "text": "now and by some accounts maybe that's been going on for centuries in terms of the progress of computing and knowledge",
    "start": "346930",
    "end": "352990"
  },
  {
    "text": "and information genomics is exploding because we're going even because it when",
    "start": "352990",
    "end": "358930"
  },
  {
    "text": "I mean the usual way it is also in an exponential fashion but that also means that analytics or ability analyze that",
    "start": "358930",
    "end": "366010"
  },
  {
    "start": "363000",
    "end": "363000"
  },
  {
    "text": "DNA is imploding because we're falling behind our compute power okay and this",
    "start": "366010",
    "end": "372670"
  },
  {
    "text": "is if you just map this out in a long-term trend this is just simply unsustainable okay so I call this this",
    "start": "372670",
    "end": "378820"
  },
  {
    "text": "falling behind exponentially I call this the hyper more gap right and that's exponentially growing that means that",
    "start": "378820",
    "end": "385510"
  },
  {
    "text": "you know long term if we wanted to run our own servers we want to run our own compute we'd have to invest an",
    "start": "385510",
    "end": "391630"
  },
  {
    "text": "exponentially increasing budget on computers even even as the computers",
    "start": "391630",
    "end": "396730"
  },
  {
    "text": "keep getting faster right we'd have to keep spending more and more money and of course this is just this is the",
    "start": "396730",
    "end": "401830"
  },
  {
    "text": "justification this is why we're here at the AWS summit obviously for a single",
    "start": "401830",
    "end": "407230"
  },
  {
    "text": "Institute to do this is not sustainable but tapping into AWS infrastructure gives us the capacity to bridge this",
    "start": "407230",
    "end": "412900"
  },
  {
    "text": "hyper more gap okay so what I want to do now is talk about how do we harness that",
    "start": "412900",
    "end": "419440"
  },
  {
    "text": "capacity and I'm gonna be kind of honest with you guys here okay I'm gonna sort",
    "start": "419440",
    "end": "424960"
  },
  {
    "text": "of open the door into what's going on at GIS and what our journey was I'm gonna",
    "start": "424960",
    "end": "431170"
  },
  {
    "text": "talk about how the how our genomics compute has evolved over the past say five years which is really driven by",
    "start": "431170",
    "end": "437440"
  },
  {
    "text": "this data scale that hyper more rate of progress and it's all a lot of this has been enabled up enabled by AWS okay and",
    "start": "437440",
    "end": "445750"
  },
  {
    "text": "I should say as a bit of background so GIS it's the genome Institute of Singapore we are a dedicated genomics",
    "start": "445750",
    "end": "452980"
  },
  {
    "text": "Research Institute it's a national initiative from the Singapore government we're funded by the Singapore government we're the largest sequencing academic",
    "start": "452980",
    "end": "459790"
  },
  {
    "text": "sequencing facility in Singapore and we collaborate with all the universities and hospitals okay so so we were kind of",
    "start": "459790",
    "end": "466180"
  },
  {
    "text": "the people in in Singapore that are supposed to be the experts I come at genomics here okay this is what GIS used",
    "start": "466180",
    "end": "476890"
  },
  {
    "text": "to look like a very simplified view okay and again I'm being honest with you guys here so pre AWS this is what it looked",
    "start": "476890",
    "end": "483490"
  },
  {
    "text": "like so I'm gonna point over here on this side on the left right so we had user workstations right so there over",
    "start": "483490",
    "end": "489880"
  },
  {
    "text": "here is an office area there's all these numbers here with network speeds we had what we call snps or you know sort of",
    "start": "489880",
    "end": "496600"
  },
  {
    "text": "multi CPU high ram high ram workstations we had a cluster we had different",
    "start": "496600",
    "end": "502720"
  },
  {
    "text": "classes of storage with different sizes and different access speeds etc etc etc okay",
    "start": "502720",
    "end": "508480"
  },
  {
    "text": "the bottom line is this is all organically grown over approximately ten",
    "start": "508480",
    "end": "514719"
  },
  {
    "text": "years we kept adding on systems as we as we were outgrowing them and you know",
    "start": "514719",
    "end": "520150"
  },
  {
    "text": "we're upgrading not just hardware not just storage network switches the workstations were all different",
    "start": "520150",
    "end": "525580"
  },
  {
    "text": "etc etc etc okay now I'm not even talking about software right now but the challenges here clearly right as an",
    "start": "525580",
    "end": "532630"
  },
  {
    "start": "529000",
    "end": "529000"
  },
  {
    "text": "academic as academic institution and we're researching stupid we have lots of academic PI's their academic group",
    "start": "532630",
    "end": "539050"
  },
  {
    "text": "leaders we also have a lot of graduate students are there there's a lot of people that are first-time command-line",
    "start": "539050",
    "end": "545020"
  },
  {
    "text": "users right and where that's kind of our job is we are there to help train people and bring them up to speed and help them",
    "start": "545020",
    "end": "552339"
  },
  {
    "text": "to process genomic data workloads so they can go out into industry or go up so postdoc and and or go be professor",
    "start": "552339",
    "end": "558490"
  },
  {
    "text": "somewhere else okay so we have a lot of first time coming command-line users as I mentioned this is a simplified version",
    "start": "558490",
    "end": "565570"
  },
  {
    "text": "but you can already see I I think and hopefully some of you identify with this it's a heterogeneous compute storage and",
    "start": "565570",
    "end": "572920"
  },
  {
    "text": "like everything was just heterogeneous okay and the thing is you know even I have trouble sort of telling you exactly",
    "start": "572920",
    "end": "579640"
  },
  {
    "text": "how everything was organized here right but for these first line command line users they have no or low experience and",
    "start": "579640",
    "end": "585550"
  },
  {
    "text": "sort of managing different job submissions on the cluster they have no or low experience in",
    "start": "585550",
    "end": "591040"
  },
  {
    "text": "optimizing their jobs software configuration okay again I'm not talking about this at all but even just to sort",
    "start": "591040",
    "end": "597130"
  },
  {
    "text": "of get software running like not just getting software and stuff but like to read the documentation and get that",
    "start": "597130",
    "end": "602380"
  },
  {
    "text": "thing running we're doing a lot of support on this as well one of the other things that is so particular to genomics",
    "start": "602380",
    "end": "608770"
  },
  {
    "text": "is oftentimes our workloads are very spiky we'll do a lot of sequencing when a project comes in and we do all the",
    "start": "608770",
    "end": "614529"
  },
  {
    "text": "patient recruitment and then we we we have to do all the amount analysis like of that sequence that comes off the",
    "start": "614529",
    "end": "620100"
  },
  {
    "text": "sequencer and then there can be a very long period of maybe a year or two in that project where we're doing validation or redoing the analysis or",
    "start": "620100",
    "end": "627670"
  },
  {
    "text": "something like this right so it's very spiky at the end of the day okay one of",
    "start": "627670",
    "end": "633940"
  },
  {
    "text": "the key key challenges that we really had was at the end of the day you put all this stuff together and we would we",
    "start": "633940",
    "end": "640870"
  },
  {
    "text": "were doing self-inflicted denial of service constantly okay so I was on I was on one of the teams I was helping",
    "start": "640870",
    "end": "646540"
  },
  {
    "text": "with some of the software configuration across the cluster we were having this every two weeks the SMP would go down",
    "start": "646540",
    "end": "653709"
  },
  {
    "text": "and then all the jobs are were running on the SMP they will go down okay someone ate too much RAM or someone you",
    "start": "653709",
    "end": "660040"
  },
  {
    "text": "know we locked up the NFS file system because they were doing some mass file transfer you know where you're supposed",
    "start": "660040",
    "end": "666940"
  },
  {
    "text": "to be you the fast scratch pool storage right this fast scratch storage but they're putting this on there the the sort of office",
    "start": "666940",
    "end": "673870"
  },
  {
    "text": "file and FS because they didn't know any better right or you take down the head node no one can submit any jobs anymore right",
    "start": "673870",
    "end": "680050"
  },
  {
    "text": "this was happening or about once every two weeks and it was happening in a different way seemingly every time okay so these were",
    "start": "680050",
    "end": "686740"
  },
  {
    "text": "the these were the big challenges it's this sort of denial of service and then",
    "start": "686740",
    "end": "691839"
  },
  {
    "text": "also it's partially related to the fact that we had many first-time command-line users so what do we do so there's a",
    "start": "691839",
    "end": "700449"
  },
  {
    "start": "696000",
    "end": "696000"
  },
  {
    "text": "capacity issue but then I'm just gonna focus on the simplicity partner or how we sort of moved up to Amazon and tried",
    "start": "700449",
    "end": "706930"
  },
  {
    "text": "to solve some of these issues so our first iteration and and this was very gradual right so as we were learning how",
    "start": "706930",
    "end": "714459"
  },
  {
    "text": "to use AWS phase one was really at some level a very very simple thing let's",
    "start": "714459",
    "end": "720519"
  },
  {
    "text": "just re-implemented mps for you know the symmetric",
    "start": "720519",
    "end": "726670"
  },
  {
    "text": "multiprocessing it's the the big the big machine that wasn't sitting behind a cluster submission okay so you could",
    "start": "726670",
    "end": "733389"
  },
  {
    "text": "just log in and just run jobs it had huge where it had you know a terabyte of RAM it had maybe 128 CPUs or something",
    "start": "733389",
    "end": "740350"
  },
  {
    "text": "like this okay and with Amazon what we could do is we could actually just say okay fine all you guys just spin up your",
    "start": "740350",
    "end": "745870"
  },
  {
    "text": "own SMP pick how much RAM you want just go for it it's cheaper than having the",
    "start": "745870",
    "end": "751389"
  },
  {
    "text": "whole thing come down and this really right oh let's see so that very",
    "start": "751389",
    "end": "758350"
  },
  {
    "text": "effectively solved this denial of service attack problem between different users right so you can bring down your",
    "start": "758350",
    "end": "764019"
  },
  {
    "text": "Ellison own SMP and then that was great because it wouldn't affect anybody else okay and essentially we had infinite capacity",
    "start": "764019",
    "end": "769829"
  },
  {
    "text": "another awesome thing about infra capacity is you also at the same time",
    "start": "769829",
    "end": "774970"
  },
  {
    "text": "get infinite potential for waste and then the the other thing is the other",
    "start": "774970",
    "end": "780189"
  },
  {
    "text": "sort of so in terms of pros like this was great it was easy for users to sort",
    "start": "780189",
    "end": "785500"
  },
  {
    "text": "of switch over immediately okay so that Barry was pretty low but we expose them",
    "start": "785500",
    "end": "790870"
  },
  {
    "text": "to the full complexity so this didn't actually help the users right this helped that denial of service problem but it didn't actually help with the",
    "start": "790870",
    "end": "797380"
  },
  {
    "text": "first time users who weren't really clear as to what they should be doing okay and in terms of full complexity",
    "start": "797380",
    "end": "803320"
  },
  {
    "text": "right so you've never used a command line you're just out of college and you",
    "start": "803320",
    "end": "809589"
  },
  {
    "text": "say okay we'll just spin up your own computer right and then you these are the choices you have to make and that's just page one right and you're gonna",
    "start": "809589",
    "end": "815050"
  },
  {
    "text": "pick your operating system and then you're gonna figure out how to configure your software I mean we obviously these",
    "start": "815050",
    "end": "820089"
  },
  {
    "text": "are services we could provide but at the very beginning the the simple version you know like letting the advanced users",
    "start": "820089",
    "end": "826720"
  },
  {
    "text": "do this right this wasn't helping our first-time users okay so this is just a listing a small listing of some of the",
    "start": "826720",
    "end": "832990"
  },
  {
    "text": "choices you would have for instance types on ec2 okay so then you know we",
    "start": "832990",
    "end": "838959"
  },
  {
    "start": "837000",
    "end": "837000"
  },
  {
    "text": "went through a couple of other stages and I'm gonna sort of skip ahead now to to serve with our current what we think",
    "start": "838959",
    "end": "844360"
  },
  {
    "text": "is going to be our best practice right so obviously just reimplemented like you just spin up an instance you you you",
    "start": "844360",
    "end": "850810"
  },
  {
    "text": "gain this sort of capacity but you don't take advantage of many other things that AWS can provide right like elastic",
    "start": "850810",
    "end": "857200"
  },
  {
    "text": "provisioning or sort of right sizing your machines okay or sort of having you",
    "start": "857200",
    "end": "862810"
  },
  {
    "text": "know the parallelization that you can do with a cluster so we do now the thing that we're trying to push forward now is",
    "start": "862810",
    "end": "869080"
  },
  {
    "text": "we're using next flow plus AWS Bastian I'll talk about this a little bit more and this you know the the spinning up of",
    "start": "869080",
    "end": "876610"
  },
  {
    "text": "individual instances at some level is just okay let's just buy a new computer right that's all it really was and there really wasn't a cloud solution we could",
    "start": "876610",
    "end": "884740"
  },
  {
    "text": "actually just done that by spending a lot of money and just behind new computers right but so now this is a",
    "start": "884740",
    "end": "890800"
  },
  {
    "text": "totally new paradigm which is enabled by the cloud okay and the way this works is basically you can see that this diagram",
    "start": "890800",
    "end": "896140"
  },
  {
    "text": "becomes much much easier they still have to deal with where their data is and you know they sort of learn how to use s3",
    "start": "896140",
    "end": "901390"
  },
  {
    "text": "but at the end of the day then they're sitting here they just sort of issue a single command or they run a command and",
    "start": "901390",
    "end": "907600"
  },
  {
    "text": "the next flow will take care of an entire processing pipeline they tell where the data is and it'll go pull the",
    "start": "907600",
    "end": "913390"
  },
  {
    "text": "data it'll it'll kick out - aw bash - provision clusters your it'll kick out",
    "start": "913390",
    "end": "919600"
  },
  {
    "text": "to a toe is bash the provision cluster nodes all those cluster nodes will get configured individually based on what",
    "start": "919600",
    "end": "926410"
  },
  {
    "text": "next flow is telling them they need to do right and then so they don't have to deal with all this stuff and and this really becomes much much much easier now",
    "start": "926410",
    "end": "933400"
  },
  {
    "text": "for our first-time users okay and at this point we not only solve the denial-of-service problem users are",
    "start": "933400",
    "end": "940810"
  },
  {
    "text": "isolated because everything is spun up individually for them every time they want to run a different analysis we get",
    "start": "940810",
    "end": "947170"
  },
  {
    "text": "the scalability right this thing shuts down automatically on its own when once the thing is done and all that is sort",
    "start": "947170",
    "end": "952480"
  },
  {
    "text": "of controlled by next flow communicating with AWS batch okay so this is a more",
    "start": "952480",
    "end": "957510"
  },
  {
    "text": "cloud native paradigm for us to use and just to give you a sense of what's going",
    "start": "957510",
    "end": "964240"
  },
  {
    "text": "on in the background right so next flow which the reason that there's some simplicity for next flow so next flow is",
    "start": "964240",
    "end": "971079"
  },
  {
    "text": "an open source sort of pipeline manager or workflow manager okay so it allows",
    "start": "971079",
    "end": "976089"
  },
  {
    "text": "you to sort of specify okay I want to do this first with this data and the output goes into this thing and then you know you can branch off like this and then",
    "start": "976089",
    "end": "982269"
  },
  {
    "text": "these two things run two separate things that those outputs then get combined into a third step etc etc and all that",
    "start": "982269",
    "end": "987640"
  },
  {
    "text": "stuff is done it'll keep track of job failures restart them etc but you do",
    "start": "987640",
    "end": "993250"
  },
  {
    "text": "have to have that job description you do have to have that workflow description",
    "start": "993250",
    "end": "998529"
  },
  {
    "text": "and we've been working with the community the nf core community which is an outgrowth of next flow so next slowly",
    "start": "998529",
    "end": "1004890"
  },
  {
    "text": "get to be clear is is not our software it's it's it's it's it's open source but",
    "start": "1004890",
    "end": "1010890"
  },
  {
    "text": "it's run by somebody else and so this job repository right has curated genomic",
    "start": "1010890",
    "end": "1017880"
  },
  {
    "text": "workflows that we've been contributing to and other people have been contributing to so we can share best practices and people can do consistent",
    "start": "1017880",
    "end": "1024750"
  },
  {
    "text": "job runs you can reproduce other people's data etc okay and so this this",
    "start": "1024750",
    "end": "1030058"
  },
  {
    "text": "is really important and this a job description from NF core then comes down",
    "start": "1030059",
    "end": "1035280"
  },
  {
    "text": "and then you've got a bunch of tasks right so as I said you've got job one you taken the data you you do something",
    "start": "1035280",
    "end": "1041069"
  },
  {
    "text": "so to use some genomics terms right so you might you might trim your fast queue files and then you do mapping after that and then you do the ovarian calling etc",
    "start": "1041069",
    "end": "1048150"
  },
  {
    "text": "etc etc and so all these are different job tasks for each of these job tasks they can kick out to Ada will use batch",
    "start": "1048150",
    "end": "1054270"
  },
  {
    "text": "to actually do the processing okay so when you kick out to AWS batch the NATO is batch will spin up all the instances",
    "start": "1054270",
    "end": "1059760"
  },
  {
    "text": "that we really need or you know based on what's specified in the job file and I can also depend that can also be",
    "start": "1059760",
    "end": "1066000"
  },
  {
    "text": "programmatically scaled based on the data so it spins up all the the base instances it",
    "start": "1066000",
    "end": "1071220"
  },
  {
    "text": "pulls these docker images from a docker repository and then now so what docker",
    "start": "1071220",
    "end": "1077250"
  },
  {
    "text": "does right is is it's a container that then has all of the software configuration done properly already",
    "start": "1077250",
    "end": "1083760"
  },
  {
    "text": "right so every single one of these commands actually gets its own essentially gets its own computer which",
    "start": "1083760",
    "end": "1089730"
  },
  {
    "text": "is configured specifically to run that specific program that's spun out dynamically you run that program and",
    "start": "1089730",
    "end": "1096180"
  },
  {
    "text": "then spun back down okay so and then of course then they need to sort of just",
    "start": "1096180",
    "end": "1101940"
  },
  {
    "text": "make sure they keep track of their data and these guys all know where to get their data from okay so the interesting",
    "start": "1101940",
    "end": "1106980"
  },
  {
    "text": "thing about this right and and really one of the kind of nice things that we realize as we became more mature with",
    "start": "1106980",
    "end": "1113820"
  },
  {
    "text": "AWS okay this is clearly much more sophisticated it's cloud native it's",
    "start": "1113820",
    "end": "1119310"
  },
  {
    "text": "much more complicated it requires a lot more infrastructure right but the tying together all these services really was",
    "start": "1119310",
    "end": "1125370"
  },
  {
    "text": "done very well by a drupe us batch and then come and then next flow was then written to basically control a Tobias",
    "start": "1125370",
    "end": "1131220"
  },
  {
    "text": "batch so solving the simplicity problem ironically required us learning a lot of",
    "start": "1131220",
    "end": "1138630"
  },
  {
    "text": "extra complexity right but we sort of crossed this this valley of complexity or maybe hill of complexity like once we",
    "start": "1138630",
    "end": "1144930"
  },
  {
    "text": "got past a certain point and actually became easier for the end user to actually go back and do this stuff right",
    "start": "1144930",
    "end": "1150150"
  },
  {
    "text": "because what because at the end of the",
    "start": "1150150",
    "end": "1156870"
  },
  {
    "text": "day what the user sees all that stuff is hidden all that stuff is managed by the workflow manager as well as AWS batch",
    "start": "1156870",
    "end": "1162690"
  },
  {
    "text": "you know all other software configuration and instance spin ups and stuff like that okay and so again why do",
    "start": "1162690",
    "end": "1171030"
  },
  {
    "start": "1171000",
    "end": "1171000"
  },
  {
    "text": "we need this kind of complexity and I think you'll hear a bit about this this is a very famous slide from from the",
    "start": "1171030",
    "end": "1178440"
  },
  {
    "text": "Institute where the other speakers coming from the Broad Institute this is a very standard genomics workflow right",
    "start": "1178440",
    "end": "1185070"
  },
  {
    "text": "and so each of these little boxes is another step in the workflow and again",
    "start": "1185070",
    "end": "1191340"
  },
  {
    "text": "if you imagine that you're a first-year graduate student and you've never used a command line before and you've got to",
    "start": "1191340",
    "end": "1196710"
  },
  {
    "text": "figure out how to run all these things all these are different programs there are multiple choices for how to do all this stuff you",
    "start": "1196710",
    "end": "1201929"
  },
  {
    "text": "really know which ones to choose I mean you can pick a paper and read it but this this is daunting for people but",
    "start": "1201929",
    "end": "1209460"
  },
  {
    "text": "what we've been able to do together with the community is workflows like this are",
    "start": "1209460",
    "end": "1214860"
  },
  {
    "text": "encapsulated in 2nf core now as job descriptions that you can actually you don't even have to download them you can",
    "start": "1214860",
    "end": "1220919"
  },
  {
    "text": "always get the latest one because NF because next level will go up and pull the latest job description file down and",
    "start": "1220919",
    "end": "1227100"
  },
  {
    "text": "then run that on your data whenever you issue that from your from your laptop ok so this is really kind of a couple of",
    "start": "1227100",
    "end": "1237059"
  },
  {
    "start": "1233000",
    "end": "1233000"
  },
  {
    "text": "the steps that we went through and you know we're still working on this we're still trying to roll this out to our users but you know I think the change",
    "start": "1237059",
    "end": "1244350"
  },
  {
    "text": "from our initial complexity which transmitted complexity to the user okay",
    "start": "1244350",
    "end": "1251999"
  },
  {
    "text": "to a complexity on AWS that now transmits simplicity to the user and",
    "start": "1251999",
    "end": "1257999"
  },
  {
    "text": "that also then gives them scale and gives them the ability to harness that capacity this has been totally dramatic",
    "start": "1257999",
    "end": "1264179"
  },
  {
    "text": "for us okay and we're super excited about implementing this and rolling this out to the rest of our and the rest of",
    "start": "1264179",
    "end": "1270029"
  },
  {
    "text": "our guys okay so what's the impact bein a GIS is a couple of slides real quick so for us you know I talked about",
    "start": "1270029",
    "end": "1277529"
  },
  {
    "start": "1275000",
    "end": "1275000"
  },
  {
    "text": "Moore's Law it's already hard to keep up with Moore's Law but you know it turns out the computer industry has done it",
    "start": "1277529",
    "end": "1282869"
  },
  {
    "text": "and so his genomics so I just took a collection of papers from the same Institute some same anonymous Institute",
    "start": "1282869",
    "end": "1288749"
  },
  {
    "text": "and if you I'm a bacterial guy so if you look at the number of bacterial genomes",
    "start": "1288749",
    "end": "1293789"
  },
  {
    "text": "that's present in each of these published reports it actually really closely tracks Moore's law interestingly",
    "start": "1293789",
    "end": "1299909"
  },
  {
    "text": "okay @gi yes you know I would say that we got there a little bit later to the",
    "start": "1299909",
    "end": "1306360"
  },
  {
    "text": "game so we weren't doing this as early as some of these other Institute's but with a lot of the scale that we've been",
    "start": "1306360",
    "end": "1312629"
  },
  {
    "text": "able to harness from AWS we've gone we've gone a hundred x in four years in terms of our scale so we are now like",
    "start": "1312629",
    "end": "1319590"
  },
  {
    "text": "this is what we wanted to do right we need to go faster than Moore's law and we can finally do this we've seen this",
    "start": "1319590",
    "end": "1325049"
  },
  {
    "text": "and I can see from the projects that are coming in today we're going to go another 10x we're gonna go another TEDx",
    "start": "1325049",
    "end": "1331320"
  },
  {
    "text": "in the next two years as well right we're going to keep up with this pace absolutely crucial that we have Amazon",
    "start": "1331320",
    "end": "1337510"
  },
  {
    "text": "Web Services to be able to do this what does that look like just to give you a visual again I'm showing you a lot of",
    "start": "1337510",
    "end": "1344910"
  },
  {
    "text": "like internal kind of things here hopefully you can identify this a little bit I mean this is the type of stuff we",
    "start": "1344910",
    "end": "1350950"
  },
  {
    "text": "used to deliver okay so this is what's called a phylogenetic tree where you know there may be ten bacterial strains",
    "start": "1350950",
    "end": "1356470"
  },
  {
    "text": "and we've sequence and this is how they're related fast-forward four years and this is what these trees look like right so we're up to 10,000 strains in a",
    "start": "1356470",
    "end": "1363730"
  },
  {
    "text": "single tree this gives us you know we've got all sorts of things that we can sort of mark on these so that this ends up",
    "start": "1363730",
    "end": "1370180"
  },
  {
    "text": "being obviously related to how these guys ancestrally are related but we can put into context Singaporean strains in",
    "start": "1370180",
    "end": "1377260"
  },
  {
    "text": "a global database sorry we can take Singaporean strains maybe a hundred download everything that's been released",
    "start": "1377260",
    "end": "1384280"
  },
  {
    "text": "they've been released in public databases put them all together with the same processing pipeline put them all",
    "start": "1384280",
    "end": "1389470"
  },
  {
    "text": "into context and this gives us much higher resolution and much more perspective on doing the analysis and",
    "start": "1389470",
    "end": "1395500"
  },
  {
    "text": "and helps deliver better answers to our collaborators okay so that's capacity",
    "start": "1395500",
    "end": "1401500"
  },
  {
    "text": "simplicity that gives us scale okay and then the last thing I just want to touch on real quick is you know if is there a",
    "start": "1401500",
    "end": "1407920"
  },
  {
    "text": "way that instead of just keeping up with the data flow rate can we actually get ahead of this are there new",
    "start": "1407920",
    "end": "1413200"
  },
  {
    "text": "opportunities that being able to harness this scale actually gives us right so can a ws fundamentally change our",
    "start": "1413200",
    "end": "1421210"
  },
  {
    "text": "thinking because if you think about everything I've said really it's just we're just doing more of what we did",
    "start": "1421210",
    "end": "1426400"
  },
  {
    "text": "before right but we're actually still using the same pipelines we just reorganize them and put them onto the cloud and we've just put them on the",
    "start": "1426400",
    "end": "1434920"
  },
  {
    "text": "cloud basically okay so again I showed this before we're undergoing this Internet of Things transition in genomics right we're",
    "start": "1434920",
    "end": "1441220"
  },
  {
    "text": "sequencing machines this is a machine that was available in 2011 it's about the size of a minivan okay and this is",
    "start": "1441220",
    "end": "1449320"
  },
  {
    "text": "one of the machines that you could buy three actually just three years ago so four years later we went through a form factor change that took 40 years in",
    "start": "1449320",
    "end": "1456100"
  },
  {
    "text": "computing okay and that's really one of the amazing things about what's going on genomics and so - in order to deal with",
    "start": "1456100",
    "end": "1463090"
  },
  {
    "text": "this we're clearly seeing a future where these will be out in the field right and again I",
    "start": "1463090",
    "end": "1468549"
  },
  {
    "start": "1468000",
    "end": "1468000"
  },
  {
    "text": "on this in the keynote I'll go pretty quickly about pretty quickly through this in Singapore there's a lot of great infrastructure that we can just simply",
    "start": "1468549",
    "end": "1475929"
  },
  {
    "text": "do an upgrade on especially fact we have those devices and actually Singapore is wanting to do this upgrade they're",
    "start": "1475929",
    "end": "1481839"
  },
  {
    "text": "already wanting to put sensors out throughout the entire city throughout the entire nation to monitor temperature",
    "start": "1481839",
    "end": "1487089"
  },
  {
    "text": "its monitor pollution right to monitor its closed-circuit TV cameras and if we",
    "start": "1487089",
    "end": "1493089"
  },
  {
    "text": "could put one of those devices one of those genomic devices out there as well just imagine the possibilities right so",
    "start": "1493089",
    "end": "1498570"
  },
  {
    "text": "for this particular case these dengue inspections where they're looking for mosquitoes that potentially can transmit",
    "start": "1498570",
    "end": "1504969"
  },
  {
    "text": "this infectious disease called dengue Singapore has a monitoring infrastructure that does a million",
    "start": "1504969",
    "end": "1510429"
  },
  {
    "text": "inspections a year all right it's completely amazing and if we can just put these devices in the hands of the",
    "start": "1510429",
    "end": "1516159"
  },
  {
    "text": "field agents right we could imagine that you know it's sort of like this right these guys are just out there constantly",
    "start": "1516159",
    "end": "1522909"
  },
  {
    "start": "1517000",
    "end": "1517000"
  },
  {
    "text": "delivering genomic data streams and if we're talking about a million genomic data streams how are we gonna do this I think the only way we really can do this",
    "start": "1522909",
    "end": "1529479"
  },
  {
    "text": "is we have to move to a server list event driven model right massive scale no user intervention this again is",
    "start": "1529479",
    "end": "1535599"
  },
  {
    "text": "another way that it's fundamentally cloud native right and and we really need IDs in order to do this okay and",
    "start": "1535599",
    "end": "1542619"
  },
  {
    "text": "then this enables continuous monitoring so so again this is a future project this is something we're looking to move",
    "start": "1542619",
    "end": "1548679"
  },
  {
    "text": "into it's clear that this is going to happen I think it may happen first in Singapore because of the outstanding infrastructure and so what we've what",
    "start": "1548679",
    "end": "1556299"
  },
  {
    "text": "we've done is we took one step it's actually from that Jaya take a pipeline it's it's listing that J take how gatk",
    "start": "1556299",
    "end": "1563169"
  },
  {
    "text": "pipeline it's it's varying calling okay so that's a very common thing that we have to do for genomics we actually",
    "start": "1563169",
    "end": "1568690"
  },
  {
    "text": "didn't use GI TK for this but the the concept is still the same we re implemented variant calling we put it",
    "start": "1568690",
    "end": "1574719"
  },
  {
    "text": "onto AWS lambda okay which is one of their server lists technology's just",
    "start": "1574719",
    "end": "1580479"
  },
  {
    "text": "that one step we drop the Compu time for six hours and 15 minutes right the way we did that basically was we had to sort",
    "start": "1580479",
    "end": "1586629"
  },
  {
    "text": "of rethink the the the way we organize that compute and so we do an automated scatter gather with very very high",
    "start": "1586629",
    "end": "1593200"
  },
  {
    "text": "parallelism much more than what you would normally be able to do on your own cluster hardware okay and then well we",
    "start": "1593200",
    "end": "1599499"
  },
  {
    "text": "could show this we could do a thousand genomes with with five million gigabytes seconds gigabase",
    "start": "1599499",
    "end": "1604600"
  },
  {
    "text": "seconds gigabyte seconds and this was all done with no intervention okay this",
    "start": "1604600",
    "end": "1610090"
  },
  {
    "text": "is something that rate we can really deliver this kind of scale to our first-time users and this is extremely",
    "start": "1610090",
    "end": "1616240"
  },
  {
    "text": "powerful because then they can go downstream right and then focus on more of the genomics analysis or more the",
    "start": "1616240",
    "end": "1622360"
  },
  {
    "text": "downstream genomics analysis instead of like a lot of this dealing with all the infrastructure to get this stuff run and",
    "start": "1622360",
    "end": "1627850"
  },
  {
    "text": "I think you know what's really cool is it lambda right ad was actually giving a lot of free calls on lambda so we could",
    "start": "1627850",
    "end": "1634570"
  },
  {
    "text": "actually do 12 genomes a month on lambda in the free tier okay and so what that ended up doing for us is it saved us 20x",
    "start": "1634570",
    "end": "1640180"
  },
  {
    "text": "on cost just for that one step okay obviously we there's I showed you that pipeline there's a lot of steps there we",
    "start": "1640180",
    "end": "1647470"
  },
  {
    "text": "think there's a lot more savings to be gained from this and a lot more performance we can extract from this and so this is super exciting for us okay so",
    "start": "1647470",
    "end": "1654130"
  },
  {
    "text": "I'm gonna end there this clearly is moving us towards this vision of ubiquitous or pervasive genomics we think that a well we think",
    "start": "1654130",
    "end": "1663670"
  },
  {
    "text": "that AWS and genomics are really going to sort of push towards this well this is just a little flashy animation the",
    "start": "1663670",
    "end": "1670900"
  },
  {
    "text": "Singapore government has a smart nation initiative where they really are trying to upgrade their existing outstanding infrastructure with all these other",
    "start": "1670900",
    "end": "1677950"
  },
  {
    "text": "sensors and we really think genomics is going to be one of those and can provide a lot of benefits for food safety for",
    "start": "1677950",
    "end": "1683380"
  },
  {
    "text": "forensics for infection outbreaks for healthcare etc okay so that's what I have for you today here are some",
    "start": "1683380",
    "end": "1688870"
  },
  {
    "text": "acknowledgments I really have to sort of highlight Jun Chien who's the guy that",
    "start": "1688870",
    "end": "1694000"
  },
  {
    "text": "did the AWS Lambda reimplementation andreas and Chi Chuan are the guys and",
    "start": "1694000",
    "end": "1700330"
  },
  {
    "text": "our bar leaders of the bioinformatics core for us that have done all the hard work at exploring how we should use AWS",
    "start": "1700330",
    "end": "1707070"
  },
  {
    "text": "the AWS team provides us a lot of great support and AWS is powering a lot of the",
    "start": "1707070",
    "end": "1712330"
  },
  {
    "text": "genomics initiatives that we have at the genome Institute of Singapore okay so I",
    "start": "1712330",
    "end": "1717370"
  },
  {
    "text": "think what we're gonna do is we're gonna switch to the next speaker and then we'll if you guys have questions we will take questions at the",
    "start": "1717370",
    "end": "1722980"
  },
  {
    "text": "end okay so the next speaker is Ruchi moonshee who is a project manager for a",
    "start": "1722980",
    "end": "1728200"
  },
  {
    "text": "Cromwell at the Broad Institute please",
    "start": "1728200",
    "end": "1733600"
  },
  {
    "text": "[Applause]",
    "start": "1733600",
    "end": "1740770"
  },
  {
    "text": "hey everybody today so today similar to how dr. Swain Chen talked about how they",
    "start": "1743090",
    "end": "1750300"
  },
  {
    "text": "used cloud services to transform genomics analysis in Singapore that's very much the sort of core of what I'm",
    "start": "1750300",
    "end": "1757140"
  },
  {
    "text": "presenting as well it's just how at the Broad Institute we leveraged cloud resources to take genomic processing to",
    "start": "1757140",
    "end": "1764340"
  },
  {
    "text": "the next level great so the key thing I'm gonna focus",
    "start": "1764340",
    "end": "1769650"
  },
  {
    "text": "on today is talking about Cromwell which is also a workflow management tool",
    "start": "1769650",
    "end": "1775050"
  },
  {
    "text": "similar to how you heard about next flow and it's really focused and crumbles",
    "start": "1775050",
    "end": "1780480"
  },
  {
    "text": "main focus is providing flexibility for a user to take the analysis that they want to run and possibly go run it in",
    "start": "1780480",
    "end": "1787650"
  },
  {
    "text": "various different platforms so I'll dig into that in a second okay so for us the",
    "start": "1787650",
    "end": "1794220"
  },
  {
    "start": "1792000",
    "end": "1792000"
  },
  {
    "text": "story at the Broad really started getting active at the end of 2012 where",
    "start": "1794220",
    "end": "1799650"
  },
  {
    "text": "exactly like you heard before when the cost of sequencing dropped there was an",
    "start": "1799650",
    "end": "1805050"
  },
  {
    "text": "incredible rise in the amount of data being generated and I really loved the term I heard earlier that like what we",
    "start": "1805050",
    "end": "1812730"
  },
  {
    "text": "started noticing right away is that with all this data jate data being generated we didn't have the analytic tools to",
    "start": "1812730",
    "end": "1819090"
  },
  {
    "text": "keep up with processing that so this is the same example of the hyper more gap that we heard about earlier so on one",
    "start": "1819090",
    "end": "1828660"
  },
  {
    "start": "1827000",
    "end": "1827000"
  },
  {
    "text": "hand we started realizing we were producing lots of data and not able to process it right away and similarly we",
    "start": "1828660",
    "end": "1836370"
  },
  {
    "text": "started noticing another trend at the Broad Institute that we had a lot of different groups scattered throughout",
    "start": "1836370",
    "end": "1842100"
  },
  {
    "text": "the organization that we're all sort of trying to do the same thing and trying to tackle the same problem in similar",
    "start": "1842100",
    "end": "1848490"
  },
  {
    "text": "but slightly different ways so we'd noticed that researchers from completely",
    "start": "1848490",
    "end": "1853920"
  },
  {
    "text": "different core groups so for example our our operations team which really focuses on pre-processing data our gatk",
    "start": "1853920",
    "end": "1860940"
  },
  {
    "text": "development team that really focuses on building the algorithm behind the genomics tools and our Cancer",
    "start": "1860940",
    "end": "1867679"
  },
  {
    "text": "Genome analysis team what that just focuses on cancer they all shared one problem that they were solving which is",
    "start": "1867679",
    "end": "1874730"
  },
  {
    "text": "that they were all looking for workflow solutions and in the past what they'd all done is a create they'd created",
    "start": "1874730",
    "end": "1880789"
  },
  {
    "text": "their own infrastructure and their own workflow management tools and so what that meant was there was a lot of",
    "start": "1880789",
    "end": "1886759"
  },
  {
    "text": "duplication of effort across those various groups and that also meant that the infrastructure is that each group",
    "start": "1886759",
    "end": "1893389"
  },
  {
    "text": "had created were not really interoperable so it was very hard for those groups to share data and to be",
    "start": "1893389",
    "end": "1899120"
  },
  {
    "text": "able to use each other's tools and so that led to sort of siloing within the organization so it's just there were all",
    "start": "1899120",
    "end": "1905389"
  },
  {
    "text": "these scattered implementations of workflow management tools and so something didn't quite sit right there",
    "start": "1905389",
    "end": "1912639"
  },
  {
    "text": "so then we decided to take a step back and think about how we would try to",
    "start": "1912789",
    "end": "1918289"
  },
  {
    "start": "1913000",
    "end": "1913000"
  },
  {
    "text": "solve this problem if you we could just start from scratch and so that's when we'd started investigating and looking",
    "start": "1918289",
    "end": "1924409"
  },
  {
    "text": "at cloud technologies and cloud resources and how we could potentially use those things to solve the problems",
    "start": "1924409",
    "end": "1930830"
  },
  {
    "text": "we just talked about so the traditional way research usually happens is that",
    "start": "1930830",
    "end": "1937179"
  },
  {
    "text": "every institution has their own setup just like you heard that they manage their own compute infrastructure every",
    "start": "1937179",
    "end": "1944809"
  },
  {
    "text": "Institute every researcher has their own copy of the data that they're working with in their local shared file system",
    "start": "1944809",
    "end": "1950090"
  },
  {
    "text": "and every group kind of has their own security implementation setup to manage",
    "start": "1950090",
    "end": "1956090"
  },
  {
    "text": "data access so everything is really just duplicated between different groups and",
    "start": "1956090",
    "end": "1961279"
  },
  {
    "text": "so we thought well why not take advantage of cloud resources to really centralize as much of this as possible",
    "start": "1961279",
    "end": "1967639"
  },
  {
    "text": "so instead of bringing data to researchers let's bring the researchers",
    "start": "1967639",
    "end": "1972830"
  },
  {
    "text": "to where data lives so the goal here is that we can really enable true data",
    "start": "1972830",
    "end": "1978799"
  },
  {
    "text": "sharing between groups at the same institution but also beyond that between",
    "start": "1978799",
    "end": "1984110"
  },
  {
    "text": "different institutions providing an easy way to share like this growth massive",
    "start": "1984110",
    "end": "1989659"
  },
  {
    "text": "growth of genomics data that's now available and the nice thing about the cloud is that because of Elastic Compute",
    "start": "1989659",
    "end": "1996830"
  },
  {
    "text": "story attached to where all this data lives as well in the same cloud platform services",
    "start": "1996830",
    "end": "2003260"
  },
  {
    "text": "it it's a lot easier for people to not have to worry about their own infrastructure but come and use",
    "start": "2003260",
    "end": "2009110"
  },
  {
    "text": "something that's already readily available and much more scalable out of the box and thirdly and this is",
    "start": "2009110",
    "end": "2015620"
  },
  {
    "text": "important because there's a lot of policy implications around managing genomics data and so if there was a",
    "start": "2015620",
    "end": "2023450"
  },
  {
    "text": "common infrastructure that means there could be a common security implementation that manages data and",
    "start": "2023450",
    "end": "2029149"
  },
  {
    "text": "compute access around this whole sort of story so that was also very important to",
    "start": "2029149",
    "end": "2034399"
  },
  {
    "text": "consider and another thing we definitely heard about as well is that genomics",
    "start": "2034399",
    "end": "2041690"
  },
  {
    "start": "2036000",
    "end": "2036000"
  },
  {
    "text": "data is quite spiky so when the first graph I showed you we were looking at the data accumulated in quarters and",
    "start": "2041690",
    "end": "2050179"
  },
  {
    "text": "here though is a more detailed view of the data on a day-by-day basis so what",
    "start": "2050179",
    "end": "2055490"
  },
  {
    "text": "this is is that there's a very spiky amount of genomics data being produced day by day so the true advantage of",
    "start": "2055490",
    "end": "2063050"
  },
  {
    "text": "using cloud resources is that you can tolerate the spikes because you can elastically and ask for compute when you",
    "start": "2063050",
    "end": "2070190"
  },
  {
    "text": "need it don't pay for it when you don't want it and you're not forced to track a bat a backlog because you're working",
    "start": "2070190",
    "end": "2076820"
  },
  {
    "text": "with a fixed amount of compute so that was a huge plus for us and the other",
    "start": "2076820",
    "end": "2083628"
  },
  {
    "start": "2082000",
    "end": "2082000"
  },
  {
    "text": "thing not necessarily cloud specific but an important paradigm that we were",
    "start": "2083629",
    "end": "2089690"
  },
  {
    "text": "hoping to solve is that we wanted the scientific analysis that any group does",
    "start": "2089690",
    "end": "2095000"
  },
  {
    "text": "to be portable and reproducible because that's just super important from the perspective of general science in all",
    "start": "2095000",
    "end": "2101750"
  },
  {
    "text": "realms to be a genomics or anywhere else and so what we really wanted to do is encourage whatever system we built we",
    "start": "2101750",
    "end": "2109280"
  },
  {
    "text": "really wanted to encourage the use of containers and containers are nothing but an encapsulation of all the software",
    "start": "2109280",
    "end": "2116180"
  },
  {
    "text": "dependencies required to be able to execute a program so what we wanted to do in our solution is ensure that there",
    "start": "2116180",
    "end": "2122660"
  },
  {
    "text": "is a way for people to leverage this technology so that it takes the guesswork out of running an analysis and",
    "start": "2122660",
    "end": "2129710"
  },
  {
    "text": "you can always get reproducible okay so this is where Cromwell and",
    "start": "2129710",
    "end": "2137710"
  },
  {
    "start": "2133000",
    "end": "2133000"
  },
  {
    "text": "Whittle come into the picture so crumble I've given a little blurb about the pink",
    "start": "2137710",
    "end": "2142720"
  },
  {
    "text": "piggy over there is our mascot slash icon for Cromwell so you'll see the little guy everywhere but Cromwell is",
    "start": "2142720",
    "end": "2149950"
  },
  {
    "text": "truly the execution engine that we developed to help run batch analysis and",
    "start": "2149950",
    "end": "2156730"
  },
  {
    "text": "the way it's built is that it's fairly flexible it doesn't have to only work",
    "start": "2156730",
    "end": "2162310"
  },
  {
    "text": "with cloud resources although that's the most common use case for it you can also use it to develop locally or if you have",
    "start": "2162310",
    "end": "2168520"
  },
  {
    "text": "an on-premises like an HPC cluster you can run Cromwell there as well so it's meant to be fairly flexible and it's",
    "start": "2168520",
    "end": "2175810"
  },
  {
    "text": "very stable scalable based on needs especially when run against a cloud platform and it's and the premise of",
    "start": "2175810",
    "end": "2184420"
  },
  {
    "text": "Cromwell was that it wasn't necessarily targeted just for bioinformatics so as",
    "start": "2184420",
    "end": "2189700"
  },
  {
    "text": "an engine it's fairly abstract and built for all different kinds of use cases kind of like the ones you heard about",
    "start": "2189700",
    "end": "2195280"
  },
  {
    "text": "earlier so Widow is a new term here it's the workflow description language and",
    "start": "2195280",
    "end": "2202180"
  },
  {
    "text": "that's the pipelining language that Cromwell understands I'm going to dig into the details around that further",
    "start": "2202180",
    "end": "2208450"
  },
  {
    "text": "down but the general premise behind Whittle was that we just wanted a human readable in writable language for",
    "start": "2208450",
    "end": "2214839"
  },
  {
    "text": "researchers or any analysts to be able to use so that one isn't required to learn a programming language you know in",
    "start": "2214839",
    "end": "2222609"
  },
  {
    "text": "order to run any kind of batch analysis so if you have understanding of like some basic scripting languages then",
    "start": "2222609",
    "end": "2228700"
  },
  {
    "text": "that's that's all you need in order to be able to leverage Whittle and to be able to run an analysis on Cromwell ok",
    "start": "2228700",
    "end": "2237010"
  },
  {
    "start": "2236000",
    "end": "2236000"
  },
  {
    "text": "so I'm gonna go into some details about Cromwell so there's two main ways that one runs",
    "start": "2237010",
    "end": "2243730"
  },
  {
    "text": "Cromwell there is a run mode which is really meant for one-off analysis so if",
    "start": "2243730",
    "end": "2248829"
  },
  {
    "text": "you're developing a pipeline if you're doing quick iteration cycles you're testing out some kind of new data so",
    "start": "2248829",
    "end": "2254680"
  },
  {
    "text": "it's all about sort of independent analysis so Cromwell has a run mode to support that and all of it is",
    "start": "2254680",
    "end": "2260230"
  },
  {
    "text": "encapsulated inside of one Java command and then there is another way to use crumble",
    "start": "2260230",
    "end": "2265960"
  },
  {
    "text": "which is server mode and that's when you're kind of hosting a shared instance",
    "start": "2265960",
    "end": "2271030"
  },
  {
    "text": "of a service that a whole group can access so the way one interacts with chrome one server mode is through like",
    "start": "2271030",
    "end": "2276940"
  },
  {
    "text": "REST API calls that mode is just meant to be scalable and meant to handle more",
    "start": "2276940",
    "end": "2283300"
  },
  {
    "text": "throughput of data going through it definitely needs a little more maintenance than run mode and it's truly",
    "start": "2283300",
    "end": "2290290"
  },
  {
    "text": "appropriate for production environments and for a shared instance and in",
    "start": "2290290",
    "end": "2296140"
  },
  {
    "text": "addition an a really desired feature that's really important for analysts when using crombel is that it provides",
    "start": "2296140",
    "end": "2302950"
  },
  {
    "text": "the functionality of call case of call caching which is truly just a way to ensure that if you've read a certain",
    "start": "2302950",
    "end": "2309970"
  },
  {
    "text": "type of analysis on a certain container before with the exact same data data then Cromwell tries to be smart about it",
    "start": "2309970",
    "end": "2316840"
  },
  {
    "text": "and make sure that instead of reanalyzing that job again it just remembers the results and is able to",
    "start": "2316840",
    "end": "2323440"
  },
  {
    "text": "reference you to the outputs so that it it reduces the need to sort of reduce",
    "start": "2323440",
    "end": "2329950"
  },
  {
    "text": "certain analyses over and over again and you can sort of resume from where you've stopped okay so today Cromwell runs in a",
    "start": "2329950",
    "end": "2340810"
  },
  {
    "start": "2337000",
    "end": "2337000"
  },
  {
    "text": "couple of different places so you can run it locally something like your laptop you can get started right away",
    "start": "2340810",
    "end": "2346350"
  },
  {
    "text": "you can run it against an HPC cluster currently we're in active development of",
    "start": "2346350",
    "end": "2352570"
  },
  {
    "text": "building AWS support for Cromwell by leveraging the AWS batch API in addition",
    "start": "2352570",
    "end": "2358600"
  },
  {
    "text": "you can run to it you can run Cromwell on Google cloud platform you can also",
    "start": "2358600",
    "end": "2363880"
  },
  {
    "text": "run it on Ally cloud ok so this is the general this is the general sort of",
    "start": "2363880",
    "end": "2371050"
  },
  {
    "start": "2367000",
    "end": "2367000"
  },
  {
    "text": "high-level architectural diagram of how Cromwell interacts with different cloud services so on the right hand side with",
    "start": "2371050",
    "end": "2380710"
  },
  {
    "text": "the cloud you'll see that there's some you'll see that crumble is essentially",
    "start": "2380710",
    "end": "2385720"
  },
  {
    "text": "sending requests to AWS batch API and it's AWS batch that knows how to",
    "start": "2385720",
    "end": "2391780"
  },
  {
    "text": "interact with a managed compute environment and that's where all your compute actually and so crumbles main job is really to",
    "start": "2391780",
    "end": "2399700"
  },
  {
    "text": "orchestrate sending jobs to different cloud platforms and the second most important thing that Cromwell does is it",
    "start": "2399700",
    "end": "2406030"
  },
  {
    "text": "makes sure that data is staged in and out of those machines between the times",
    "start": "2406030",
    "end": "2412420"
  },
  {
    "text": "in before and after an analysis as run because that's the most important part",
    "start": "2412420",
    "end": "2417820"
  },
  {
    "text": "of all of these jobs is that in the case of genomics research large files have to be brought over to the machines so",
    "start": "2417820",
    "end": "2424210"
  },
  {
    "text": "Krummel does all the heavy lifting of staging data in and out of the machines",
    "start": "2424210",
    "end": "2429990"
  },
  {
    "start": "2431000",
    "end": "2431000"
  },
  {
    "text": "so this is more of just a more detail around what I just spoke about which is",
    "start": "2431190",
    "end": "2438310"
  },
  {
    "text": "that Cromwell leverages AWS batch and submits to AWS patch job queues queues",
    "start": "2438310",
    "end": "2445089"
  },
  {
    "text": "in order to manage a users workflow and it takes and the actual description of",
    "start": "2445089",
    "end": "2455050"
  },
  {
    "text": "that workflow and the subset of those jobs is all defined by the work is all",
    "start": "2455050",
    "end": "2460390"
  },
  {
    "text": "defined within the workflow description language and I'm going to jump into details around that so oh yes one",
    "start": "2460390",
    "end": "2467920"
  },
  {
    "text": "wonderful feature about AWS patch and it's quite unique to AWS in this sense",
    "start": "2467920",
    "end": "2473349"
  },
  {
    "text": "is that it makes priority management of your jobs very simple and this is a really nice to have in a production",
    "start": "2473349",
    "end": "2479859"
  },
  {
    "text": "environment where usually when there is a normal flow of jobs coming in there's",
    "start": "2479859",
    "end": "2484990"
  },
  {
    "text": "a you can run most of your jobs through a low priority job - which could be connected to sort of a low cost computer",
    "start": "2484990",
    "end": "2491260"
  },
  {
    "text": "environment that's using spot instances for example and then when you have more",
    "start": "2491260",
    "end": "2496510"
  },
  {
    "text": "we have high party jobs coming through that one can just set up a high priority job queue and submit certain jobs",
    "start": "2496510",
    "end": "2503079"
  },
  {
    "text": "through there and so it can leverage so it gets priority over the low priority",
    "start": "2503079",
    "end": "2508569"
  },
  {
    "text": "jobs and if there isn't enough space even in your spot compute environment you can throw on an on-demand compute",
    "start": "2508569",
    "end": "2516099"
  },
  {
    "text": "environment so immediately you have more flexibility and a way to urgently run high priority jobs okay so I'm gonna",
    "start": "2516099",
    "end": "2523810"
  },
  {
    "start": "2522000",
    "end": "2522000"
  },
  {
    "text": "dive into Whittle a little bit which is the workflow description language and just the sort of design around the",
    "start": "2523810",
    "end": "2530779"
  },
  {
    "text": "language in general so on the left-hand side you have a workflow describe a workflow definition really and the key",
    "start": "2530779",
    "end": "2537859"
  },
  {
    "text": "components of that are in the yellow bubble you have highlighted the inputs coming in to that workflow or being",
    "start": "2537859",
    "end": "2544369"
  },
  {
    "text": "leveraged by that workflow and below those are instantiation are call",
    "start": "2544369",
    "end": "2550969"
  },
  {
    "text": "statements which are instantiation of a task and on the right hand side there's",
    "start": "2550969",
    "end": "2555979"
  },
  {
    "text": "a task definition a task definition in layman's terms is simply a function so",
    "start": "2555979",
    "end": "2561229"
  },
  {
    "text": "it's just something that has inputs an actual command that's executed using",
    "start": "2561229",
    "end": "2566660"
  },
  {
    "text": "those inputs and it generates outputs so that's what it is at the end of the day and the language provides easy syntax to",
    "start": "2566660",
    "end": "2573410"
  },
  {
    "text": "be able to reference types like files strings arrays and things like that just",
    "start": "2573410",
    "end": "2578599"
  },
  {
    "text": "sort of normal objects you would need and be able to like manipulate data and so that's your task definition a sort of",
    "start": "2578599",
    "end": "2586160"
  },
  {
    "text": "unique component to the task definition is the runtime block and that's where",
    "start": "2586160",
    "end": "2591949"
  },
  {
    "text": "you can a user has the option to be able to do more detailed resource management",
    "start": "2591949",
    "end": "2597109"
  },
  {
    "text": "for that job so you can specify things like the amount of CPU needed the amount of disk space needed and if you wanted",
    "start": "2597109",
    "end": "2603049"
  },
  {
    "text": "to use a low cost instance so the details around the resource management is handled inside the runtime block and",
    "start": "2603049",
    "end": "2611140"
  },
  {
    "text": "a workflow is really just a chaining of all these task calls and that's what it",
    "start": "2611140",
    "end": "2617179"
  },
  {
    "text": "is at the end of the day so here's an example of an actual sort of hello world",
    "start": "2617179",
    "end": "2622609"
  },
  {
    "text": "example for a task so the command block is the actual script that gets executed",
    "start": "2622609",
    "end": "2629289"
  },
  {
    "text": "the runtime block which is where one provides the runtime details like docker",
    "start": "2629289",
    "end": "2636559"
  },
  {
    "text": "containers if you're using one and the resource requirements we just talked about and potential cost savings in",
    "start": "2636559",
    "end": "2643189"
  },
  {
    "text": "there and the easiest way to write a tip or to be able to run a task is you",
    "start": "2643189",
    "end": "2648349"
  },
  {
    "text": "simply call it so this is like a two-line workflow underneath okay so",
    "start": "2648349",
    "end": "2656479"
  },
  {
    "start": "2656000",
    "end": "2656000"
  },
  {
    "text": "there's the wittle language is built to have easy syntax in order to create data",
    "start": "2656479",
    "end": "2661660"
  },
  {
    "text": "floo just very intuitive from a workflow author perspective so the of course there's ways to linearly chain tasks so",
    "start": "2661660",
    "end": "2668619"
  },
  {
    "text": "the simple sort of way of just piping inputs and outputs in a linear fashion there's also ways to do multiple inputs",
    "start": "2668619",
    "end": "2676299"
  },
  {
    "text": "and outputs in the same vein and probably the most desired feature in",
    "start": "2676299",
    "end": "2681880"
  },
  {
    "text": "Whittle and the most used feature is the ability to scatter the same task over a",
    "start": "2681880",
    "end": "2688829"
  },
  {
    "text": "list of different inputs and in this case what one has to do is just provide",
    "start": "2688829",
    "end": "2694299"
  },
  {
    "text": "an array of inputs in the same task that gets four gets run against those inputs",
    "start": "2694299",
    "end": "2700450"
  },
  {
    "text": "in parallel at the same time so it's not quite a loop but it's sort of parallel execution of these tasks and then",
    "start": "2700450",
    "end": "2705819"
  },
  {
    "text": "there's an easy syntactical way to gather all the outputs without any extra effort and to be able to sort of split",
    "start": "2705819",
    "end": "2712030"
  },
  {
    "text": "and combine where needed okay so an interesting thing about Whittle is that",
    "start": "2712030",
    "end": "2718510"
  },
  {
    "start": "2714000",
    "end": "2714000"
  },
  {
    "text": "it's been out and open to the community both Cromwell and Whittle are open source projects at the broad and Whittle",
    "start": "2718510",
    "end": "2725380"
  },
  {
    "text": "has been has gained a lot of traction in the community over time so what ended up happening is that very recently Whittle",
    "start": "2725380",
    "end": "2732849"
  },
  {
    "text": "was handed over to the government to governance by sort of an open community standard so it has been sort of it's",
    "start": "2732849",
    "end": "2740430"
  },
  {
    "text": "transformed from Whittle to open Whittle so I I'm sure I've thrown in a github link for it somewhere here but you can",
    "start": "2740430",
    "end": "2746799"
  },
  {
    "text": "go and read more about it and the basic premise is that as new features get added into the Whittle language it's",
    "start": "2746799",
    "end": "2752680"
  },
  {
    "text": "really driven by the needs of the community okay so in addition if if by",
    "start": "2752680",
    "end": "2760420"
  },
  {
    "text": "informatics languages and bioinformatics pipelines are sort of like your hotspot in your day to day then you may have",
    "start": "2760420",
    "end": "2767410"
  },
  {
    "text": "already heard about cwl which is another workflow language the common workflow language that's very popular in the by",
    "start": "2767410",
    "end": "2773500"
  },
  {
    "text": "informatics community and very recently crumble added support for running cwl",
    "start": "2773500",
    "end": "2778539"
  },
  {
    "text": "workflows as well by sort of leveraging this concept of a workflow object model",
    "start": "2778539",
    "end": "2784059"
  },
  {
    "text": "that ties the core concepts of Whittle and C they'll do well together ok great",
    "start": "2784059",
    "end": "2789309"
  },
  {
    "start": "2788000",
    "end": "2788000"
  },
  {
    "text": "so of course the most exciting thing for us is just sort of watching how the community use",
    "start": "2789309",
    "end": "2794800"
  },
  {
    "text": "Cromwell and like the growth at which analysis happens through this tool so",
    "start": "2794800",
    "end": "2801190"
  },
  {
    "text": "there's a hosted instance of there's a few hosted instances of Cromwell at the Broad Institute and so over the over",
    "start": "2801190",
    "end": "2808570"
  },
  {
    "text": "just like the last two years we've processed close to fifty million jobs which is a really which is a really exciting milestone for us and yeah the",
    "start": "2808570",
    "end": "2818710"
  },
  {
    "text": "that's the gist of it I'm happy to take questions and of course feel free to reach out to me if you wanted to talk",
    "start": "2818710",
    "end": "2824770"
  },
  {
    "text": "more about Cromwell Whittle or maybe just interested in getting started so thank you",
    "start": "2824770",
    "end": "2829860"
  },
  {
    "text": "[Applause]",
    "start": "2829860",
    "end": "2834860"
  }
]
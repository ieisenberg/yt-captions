[
  {
    "start": "0",
    "end": "64000"
  },
  {
    "text": "hi everyone I'm Andy Copeland's I'm the general manager for Amazon ElastiCache I",
    "start": "0",
    "end": "5850"
  },
  {
    "text": "also manage Amazon Elastic search service and Amazon Neptune our new graph",
    "start": "5850",
    "end": "10860"
  },
  {
    "text": "database I know it's right after lunch right now this music was super relaxing",
    "start": "10860",
    "end": "16170"
  },
  {
    "text": "and if you don't fall asleep I promise I will try not to fall asleep myself so",
    "start": "16170",
    "end": "22380"
  },
  {
    "text": "stay alert Redis is all about speed and high performance and just in time at the rapid application development so you",
    "start": "22380",
    "end": "29550"
  },
  {
    "text": "definitely have to stay awake how many of you are not using Redis today ok",
    "start": "29550",
    "end": "36750"
  },
  {
    "text": "that's quite a few I really hope that by the end of this session I wet your appetite for Redis and you'll see why I",
    "start": "36750",
    "end": "43020"
  },
  {
    "text": "think it's such an awesome technology out of those who are using Redis who is not using ElastiCache ok quite a few so",
    "start": "43020",
    "end": "52829"
  },
  {
    "text": "I guess I have two goals today for those who don't already so I'll try and whet your appetite and for those who are not using ElastiCache maybe give you some",
    "start": "52829",
    "end": "60539"
  },
  {
    "text": "some reasons why you should give this service a try what I'll do today is talk",
    "start": "60539",
    "end": "66780"
  },
  {
    "start": "64000",
    "end": "107000"
  },
  {
    "text": "about Redis why I think Redis is awesome and some of the new things that have come along in Redis and I'll talk about",
    "start": "66780",
    "end": "73590"
  },
  {
    "text": "Amazon ElastiCache service and a specific Amazon ElastiCache for Redis",
    "start": "73590",
    "end": "79280"
  },
  {
    "text": "talk about how customers are using it talk about some of the use cases and then I'll also give you a bit of a",
    "start": "79280",
    "end": "85259"
  },
  {
    "text": "glimpse of what's new in ElastiCache if you haven't looked for a while and what some of our kind of short-term plans are",
    "start": "85259",
    "end": "91890"
  },
  {
    "text": "around elastic cash and we do have a full 60 minutes so if we have some time",
    "start": "91890",
    "end": "97380"
  },
  {
    "text": "left over I'm more than happy to answer any questions that you have if we run out of time we can gather on the side",
    "start": "97380",
    "end": "103500"
  },
  {
    "text": "and I'm happy to answer any more questions you have so to get started I",
    "start": "103500",
    "end": "108990"
  },
  {
    "start": "107000",
    "end": "241000"
  },
  {
    "text": "wanted to give you a bit of a context on how we think about Redis at AWS and how it fits into our database portfolio and",
    "start": "108990",
    "end": "114990"
  },
  {
    "text": "our focus is really on delivering the best purpose-built databases and there",
    "start": "114990",
    "end": "121680"
  },
  {
    "text": "are a number of purpose-built databases we deliver and and the reason why we have multiple databases and not just one",
    "start": "121680",
    "end": "128640"
  },
  {
    "text": "is because the application development requirements are really changing rapidly and it is really hard to find one",
    "start": "128640",
    "end": "134670"
  },
  {
    "text": "database that's gonna rule them all and solve all the problems so data volumes are explosive or exploding you know",
    "start": "134670",
    "end": "141270"
  },
  {
    "text": "we're not in the gigabytes anymore we're in the terabytes and if you look at that little site petabytes and even exabytes",
    "start": "141270",
    "end": "148020"
  },
  {
    "text": "of data and applications are not simple request/response monolithic applications",
    "start": "148020",
    "end": "154290"
  },
  {
    "text": "where 250 millisecond Atta based query is good enough to meet your end user",
    "start": "154290",
    "end": "159710"
  },
  {
    "text": "requirements we're seeing micro service based architectures lots of API calls lots of database calls in the backend to",
    "start": "159710",
    "end": "167460"
  },
  {
    "text": "the point refer many of our customers if we can deliver you know single met single digit millisecond latency zhan",
    "start": "167460",
    "end": "174209"
  },
  {
    "text": "database calls some of those applications aren't going to perform well and and we also get requirements",
    "start": "174209",
    "end": "180180"
  },
  {
    "text": "for sub millisecond response times into microseconds we're not dealing with tens",
    "start": "180180",
    "end": "186150"
  },
  {
    "text": "of thousands of requests per second anymore at the database tier or hundreds of thousands we see customers who",
    "start": "186150",
    "end": "191370"
  },
  {
    "text": "actually need to do millions of requests per second and that's not even concurrent users right there'll be like 100 million concurrent users but that",
    "start": "191370",
    "end": "198239"
  },
  {
    "text": "could be millions of requests per second that's really really hard to do and then",
    "start": "198239",
    "end": "203250"
  },
  {
    "text": "in addition to that we've got to build these applications really really fast and more feature-rich than any time",
    "start": "203250",
    "end": "210239"
  },
  {
    "text": "before so the radio isn't gonna just be one way or one databases that's going to",
    "start": "210239",
    "end": "216300"
  },
  {
    "text": "solve that there have been attempts at that like the relational database vendor started to add key value capabilities",
    "start": "216300",
    "end": "222660"
  },
  {
    "text": "document capabilities even graph capabilities but I think what we've learned is every database has a purpose",
    "start": "222660",
    "end": "230550"
  },
  {
    "text": "and if we focus on delivering the best tool for the job you guys are gonna know how to take",
    "start": "230550",
    "end": "237720"
  },
  {
    "text": "advantage of that and really deliver awesome applications and probably the",
    "start": "237720",
    "end": "242760"
  },
  {
    "start": "241000",
    "end": "263000"
  },
  {
    "text": "person that says his best is Verner or CTO he wrote a really good blog if you haven't read it I suggest you read it",
    "start": "242760",
    "end": "248100"
  },
  {
    "text": "and he basically what he said is one size fit one size fits all databases",
    "start": "248100",
    "end": "253370"
  },
  {
    "text": "doesn't fit anyone that's pretty much what I'm saying you're not gonna find a",
    "start": "253370",
    "end": "258630"
  },
  {
    "text": "single database that is going to fit everything that you need to get done",
    "start": "258630",
    "end": "264630"
  },
  {
    "start": "263000",
    "end": "521000"
  },
  {
    "text": "and the reason is we just have a lot of different models that we're trying to represent within our applications right",
    "start": "264630",
    "end": "270570"
  },
  {
    "text": "we have the traditional relational model which is super valuable right it's acid its strong schema you know those",
    "start": "270570",
    "end": "278100"
  },
  {
    "text": "databases aren't gonna go away we have Aurora which is a very very awesome database and and it's growing very very",
    "start": "278100",
    "end": "285270"
  },
  {
    "text": "fast but then we also have you know databases like dynamo a key value database that gives you a single-digit",
    "start": "285270",
    "end": "291660"
  },
  {
    "text": "millisecond response with Dax even microsecond response but really gives",
    "start": "291660",
    "end": "296670"
  },
  {
    "text": "you pretty much infinite scale and so for certain use cases when you need you",
    "start": "296670",
    "end": "302130"
  },
  {
    "text": "know the highest availability the availability you can get and super low latency is that's a kind of database",
    "start": "302130",
    "end": "309300"
  },
  {
    "text": "you'd want to use for specific capability then of course there's document there's graph graph is really",
    "start": "309300",
    "end": "317040"
  },
  {
    "text": "focused at extracting the maximum value out of the connections between data points and that's why we launched Amazon",
    "start": "317040",
    "end": "324510"
  },
  {
    "text": "Neptune in May and then last but not least but I'm going to be talking to about is in memory and in-memory",
    "start": "324510",
    "end": "331650"
  },
  {
    "text": "databases and Redis really being the leader in the in memory database space what's really what's really special",
    "start": "331650",
    "end": "340200"
  },
  {
    "text": "about the in-memory databases is they don't have to worry about how data gets",
    "start": "340200",
    "end": "345810"
  },
  {
    "text": "persisted on disk and what the right you know data structure is so you could actually also write this thing to disk",
    "start": "345810",
    "end": "352080"
  },
  {
    "text": "in an effective way the focus for a memory databases is exposing really",
    "start": "352080",
    "end": "358740"
  },
  {
    "text": "useful and viable data structures to developers that can get can both deliver",
    "start": "358740",
    "end": "364380"
  },
  {
    "text": "a lot of functionality but can also deliver super high performance and it's",
    "start": "364380",
    "end": "370560"
  },
  {
    "text": "so I don't need to go away just thinking it's just about performance it's also about the convenience and the",
    "start": "370560",
    "end": "376050"
  },
  {
    "text": "convenience of the data structures that we can much more easily represent in memory then we can represent elsewhere",
    "start": "376050",
    "end": "384710"
  },
  {
    "text": "so how does Redis fit in and Redis is really awesome at low latency most of",
    "start": "386240",
    "end": "393510"
  },
  {
    "text": "the requests will will basically return in on milisecond it's not atypical to see",
    "start": "393510",
    "end": "399580"
  },
  {
    "text": "about 350 microsecond response times and Redis is also very good at high",
    "start": "399580",
    "end": "404889"
  },
  {
    "text": "throughput especially if you look at things like caching use cases being able to use a single instance and do about",
    "start": "404889",
    "end": "411300"
  },
  {
    "text": "200,000 requests per second can not only give it can not only help you deliver",
    "start": "411300",
    "end": "416979"
  },
  {
    "text": "awesome apps and also mend user experiences but it can also dramatically take down the cost of your overall",
    "start": "416979",
    "end": "422590"
  },
  {
    "text": "application and I'll show you an example of a customer who actually was able to deliver that some really interesting use",
    "start": "422590",
    "end": "431439"
  },
  {
    "text": "case I'll talk more later on about them like ride-hailing social media gaming",
    "start": "431439",
    "end": "437020"
  },
  {
    "text": "media streaming a lot of these born for the web applications they need to reach hundreds of millions of users and need",
    "start": "437020",
    "end": "443919"
  },
  {
    "text": "super low latency and while it's in memory we don't just measure Redis is",
    "start": "443919",
    "end": "450550"
  },
  {
    "text": "capabilities in gigabytes we can actually deliver terabytes of data in memory through our bigger instances and",
    "start": "450550",
    "end": "458229"
  },
  {
    "text": "sharding an action on elastic cache for Redis service we can do up 270 terabytes",
    "start": "458229",
    "end": "465159"
  },
  {
    "text": "of data in a single cluster so don't only think small and later on I'm going",
    "start": "465159",
    "end": "470979"
  },
  {
    "text": "to talk about a new feature in Redis where which I think is going to become super appealing and in that use case",
    "start": "470979",
    "end": "478270"
  },
  {
    "text": "well I definitely think you know terabytes of data may definitely become the norm we talked about microsecond",
    "start": "478270",
    "end": "484719"
  },
  {
    "text": "agencies with about at least 200,000 requests per second per machine it doesn't take a lot to actually get to",
    "start": "484719",
    "end": "491319"
  },
  {
    "text": "millions of requests per second on Redis and last but not least it's an open API",
    "start": "491319",
    "end": "497620"
  },
  {
    "text": "it's open source there's lots of client libraries out there the actual interface",
    "start": "497620",
    "end": "502960"
  },
  {
    "text": "is very very convenient to use I'll talk about a little bit more later and so from in a database perspective as",
    "start": "502960",
    "end": "509560"
  },
  {
    "text": "we look at our purpose-built portfolio Redis is really kind of our primary",
    "start": "509560",
    "end": "515909"
  },
  {
    "text": "database for the in-memory use case",
    "start": "515909",
    "end": "521070"
  },
  {
    "text": "so bit more about Redis for those who are new to Redis and it is the most",
    "start": "522880",
    "end": "527980"
  },
  {
    "text": "popular in memory database according to DB engines comm also if you",
    "start": "527980",
    "end": "533529"
  },
  {
    "text": "just look at all general databases whether that's relational or search or a document key value Redis is consistently",
    "start": "533529",
    "end": "541690"
  },
  {
    "text": "in the top eight databases in the market so super super popular being used you",
    "start": "541690",
    "end": "548350"
  },
  {
    "text": "know across the globe by many applications and like many of its",
    "start": "548350",
    "end": "553930"
  },
  {
    "text": "open-source peers here has just gotten huge distribution through the open source model and through a Linux",
    "start": "553930",
    "end": "560560"
  },
  {
    "text": "distribution and other vehicles so what",
    "start": "560560",
    "end": "565600"
  },
  {
    "start": "563000",
    "end": "667000"
  },
  {
    "text": "makes her ready so awesome so we talked about the speed I talked a bit about the simplicity and the easy-to-use API and",
    "start": "565600",
    "end": "571779"
  },
  {
    "text": "another really awesome thing about Redis it actually supports replication that's",
    "start": "571779",
    "end": "576790"
  },
  {
    "text": "not that typical like if you remember memcache memcache is super fast it's a key value store but it doesn't really",
    "start": "576790",
    "end": "582790"
  },
  {
    "text": "give you that kind of replication and get that kind of availability Redis does so you can actually build a cluster of",
    "start": "582790",
    "end": "588790"
  },
  {
    "text": "Redis with read replicas talk a bit later on on how we leverage that to",
    "start": "588790",
    "end": "593889"
  },
  {
    "text": "deliver more scalable and available systems but that's really at the core of one of the things that makes red is",
    "start": "593889",
    "end": "599740"
  },
  {
    "text": "really special the over 200 commands and those commands a lot of them are geared",
    "start": "599740",
    "end": "605079"
  },
  {
    "text": "towards manipulating really interesting sophisticated data structures so",
    "start": "605079",
    "end": "610870"
  },
  {
    "text": "probably the easiest way to think about Redis it's a data structure server it's",
    "start": "610870",
    "end": "616329"
  },
  {
    "text": "got lots of data structures like lists like hashes like sorted sets streams and",
    "start": "616329",
    "end": "622500"
  },
  {
    "text": "you can use those data structures ready to best optimize for the use cases and",
    "start": "622500",
    "end": "628779"
  },
  {
    "text": "I'll talk about some of the use cases and what data structures you would want to think about as you're building",
    "start": "628779",
    "end": "634480"
  },
  {
    "text": "applications with that use case and last but not least even though it's in memory and in memory of course isn't persistent",
    "start": "634480",
    "end": "641579"
  },
  {
    "text": "Redis does have a nice snapshot and capability so you can actually take periodic snapshots and backup your data",
    "start": "641579",
    "end": "648430"
  },
  {
    "text": "and then rehydrate clusters with those backups through a restore mechanism",
    "start": "648430",
    "end": "654270"
  },
  {
    "text": "so it's a you know pretty awesome in-memory technology lots of options",
    "start": "654270",
    "end": "659339"
  },
  {
    "text": "around data structures and lots of enterprises capabilities like",
    "start": "659339",
    "end": "664500"
  },
  {
    "text": "replication and backup and restore so what are some of the use cases the first",
    "start": "664500",
    "end": "671010"
  },
  {
    "start": "667000",
    "end": "778000"
  },
  {
    "text": "most popular use case has been caching and and there are lots of variants on",
    "start": "671010",
    "end": "676470"
  },
  {
    "text": "how you apply caching but and caching is usually a very simple key value kind of",
    "start": "676470",
    "end": "682620"
  },
  {
    "text": "relationship so there's a key the baddy is a string so it's not already a sophisticated data structure and that's",
    "start": "682620",
    "end": "688860"
  },
  {
    "text": "what I will call kind of this simple caching use case but the nice thing is that Redis also supports maps that",
    "start": "688860",
    "end": "695940"
  },
  {
    "text": "supports lots of other data structures so for example you know session stores session management is probably pride",
    "start": "695940",
    "end": "703350"
  },
  {
    "text": "another primary use case for Redis you'd often use a hash map for that because in a user session you actually want to you",
    "start": "703350",
    "end": "710790"
  },
  {
    "text": "want to store multiple attributes if you build a chat application Redis has a pub",
    "start": "710790",
    "end": "716760"
  },
  {
    "text": "sub a pop sub mechanism where you can actually do a publish and subscribe I'll",
    "start": "716760",
    "end": "722520"
  },
  {
    "text": "talk a bit later about a new data structure that's come along and how that potentially could eclipse the pops up",
    "start": "722520",
    "end": "728720"
  },
  {
    "text": "capability in Redis that existed until today but so far there's just a lot of",
    "start": "728720",
    "end": "733890"
  },
  {
    "text": "choice and those choices often match up with specific use cases Redis is pretty",
    "start": "733890",
    "end": "739920"
  },
  {
    "text": "much a de facto standard for gaming leaderboards so if you're if you're playing games where kids are playing",
    "start": "739920",
    "end": "744959"
  },
  {
    "text": "games and you see the leaderboards I would say it's probably you know 80% chance and that's a guesstimate not a",
    "start": "744959",
    "end": "752100"
  },
  {
    "text": "specific number that behind the scenes it's actually a Redis sorted set keeping",
    "start": "752100",
    "end": "758459"
  },
  {
    "text": "the leader the leaderboard for the real time for the real time gaming application and what's of course very",
    "start": "758459",
    "end": "765029"
  },
  {
    "text": "typical in game in gaming is you have super high volume super high requests per second and so being able to do a",
    "start": "765029",
    "end": "772050"
  },
  {
    "text": "leaderboard at scale at a relatively low cost is really one of Redis sweet spots",
    "start": "772050",
    "end": "779149"
  },
  {
    "start": "778000",
    "end": "966000"
  },
  {
    "text": "Redis is getting a lot better so October 17th new version came out Redis 5 I'm",
    "start": "779450",
    "end": "786300"
  },
  {
    "text": "super excited about Redis rattus five I think is really one of the",
    "start": "786300",
    "end": "793690"
  },
  {
    "text": "major version unlike the major versions we had before it adds in your data structure called Redis dreams which has",
    "start": "793690",
    "end": "801670"
  },
  {
    "text": "which initially was actually slated for Redis for but it took longer to develop and it actually ended up being released",
    "start": "801670",
    "end": "807610"
  },
  {
    "text": "under Redis 5 and that's a new data structure which is a log based data structure which is optimized for",
    "start": "807610",
    "end": "814690"
  },
  {
    "text": "streaming use cases and there are a lot of possibilities around ready stream so I'm going to talk about today so I think",
    "start": "814690",
    "end": "820690"
  },
  {
    "text": "that you're gonna discover as you play around with Redis but that specific",
    "start": "820690",
    "end": "826570"
  },
  {
    "text": "feature in my opinion is going to give read as additional tailwind in the market is going to continue to",
    "start": "826570",
    "end": "832570"
  },
  {
    "text": "accelerate adoption and I'm going to dive a lot deeper into what other streams is how you should think about",
    "start": "832570",
    "end": "838420"
  },
  {
    "text": "using it and and what kind of use cases it could potentially address there are",
    "start": "838420",
    "end": "845140"
  },
  {
    "text": "lots of other additions in Redis 5 so an optimized hyper log-log algorithm for",
    "start": "845140",
    "end": "852070"
  },
  {
    "text": "those who don't know what hyperbolic is it's a way to basically estimate how many distinct values you have in a set",
    "start": "852070",
    "end": "858330"
  },
  {
    "text": "super useful for a number of applications and and that contribution was actually made by the person who",
    "start": "858330",
    "end": "865120"
  },
  {
    "text": "wrote the paper that described a new better faster more optimized hyper",
    "start": "865120",
    "end": "871090"
  },
  {
    "text": "log-log algorithms so a really nice community contribution from the person",
    "start": "871090",
    "end": "876490"
  },
  {
    "text": "who actually did the research all the way to implementation in Redis Redis 5",
    "start": "876490",
    "end": "881740"
  },
  {
    "text": "also upgraded the je the j-man och so the je malloc memory manager and so it",
    "start": "881740",
    "end": "888580"
  },
  {
    "text": "is higher performance has less fragmentation and in general is another",
    "start": "888580",
    "end": "894130"
  },
  {
    "text": "step up for managed memory management offices an in-memory database memory",
    "start": "894130",
    "end": "900190"
  },
  {
    "text": "management is super critical especially as Redis will run for a very very long time and we need to make sure that",
    "start": "900190",
    "end": "906220"
  },
  {
    "text": "fragmentations stays down and then just lots of other enhancements sorted sets",
    "start": "906220",
    "end": "912160"
  },
  {
    "text": "of garden you know pop and block operation support lots of bug fixes lots of performance enhancements and",
    "start": "912160",
    "end": "919939"
  },
  {
    "text": "you know fresh off the press we actually just we already support Rattus five and",
    "start": "919939",
    "end": "925309"
  },
  {
    "text": "ElastiCache four Redis it took us less than four weeks part of that that the",
    "start": "925309",
    "end": "933289"
  },
  {
    "text": "release date for Redis was known upfront and so that really helped us and I'd say the rest of the community to prepare and",
    "start": "933289",
    "end": "940699"
  },
  {
    "text": "make sure that we could test it secure it and offer it on the service now we",
    "start": "940699",
    "end": "947239"
  },
  {
    "text": "published a blog post that actually goes through in a lot more detail on what's new in Redis five so if you go to the",
    "start": "947239",
    "end": "952579"
  },
  {
    "text": "following URL aws.amazon.com / writer / what's neuritis five you can read a lot",
    "start": "952579",
    "end": "960019"
  },
  {
    "text": "more about Rattus five the new features and how you can take advantage of them",
    "start": "960019",
    "end": "966459"
  },
  {
    "start": "966000",
    "end": "1036000"
  },
  {
    "text": "but for now what I would like to talk about is ready streams because that is by far I think the most impactful",
    "start": "966459",
    "end": "972169"
  },
  {
    "text": "feature and the most interesting feature in Redis five it's like it actually made",
    "start": "972169",
    "end": "978079"
  },
  {
    "text": "me spend hours and hours of playing around with it and reading about it and you know I'm personally super excited I",
    "start": "978079",
    "end": "983779"
  },
  {
    "text": "don't get a lot of time anymore to geek out with the tech but this definitely",
    "start": "983779",
    "end": "988909"
  },
  {
    "text": "caught enough of my attention that I spent a considerable amount of time on it so the way to think about Redis",
    "start": "988909",
    "end": "994279"
  },
  {
    "text": "streams it's a kind of timestamp indexed append-only log so basically these",
    "start": "994279",
    "end": "1000069"
  },
  {
    "text": "records come in and they get timestamp by Redis typically and they're basically",
    "start": "1000069",
    "end": "1006819"
  },
  {
    "text": "stored as a log it leverages the fact that Redis is high performance so it can",
    "start": "1006819",
    "end": "1014619"
  },
  {
    "text": "really deal with log flow that's coming in very very fast and and some of the things you may want to put in there are",
    "start": "1014619",
    "end": "1020709"
  },
  {
    "text": "you know click stream analytics from your web application or chat application",
    "start": "1020709",
    "end": "1026188"
  },
  {
    "text": "you could use it for Messick's Message Queuing there are lots of ways to use streams as an underlying primitive to",
    "start": "1026189",
    "end": "1033250"
  },
  {
    "text": "build applications on top of it I'm going to touch on a few of those going",
    "start": "1033250",
    "end": "1038319"
  },
  {
    "start": "1036000",
    "end": "1287000"
  },
  {
    "text": "into a bit more detail and ready streams was basically implemented as a radix",
    "start": "1038319",
    "end": "1044048"
  },
  {
    "text": "tree it was implemented by Salvatori Sanfilippo who is the creator of Redis",
    "start": "1044049",
    "end": "1049269"
  },
  {
    "text": "and he actually took he built a really nice radix library called Rex and that is open source on",
    "start": "1049269",
    "end": "1056529"
  },
  {
    "text": "github outside of Redis because he felt like this was a awesome implementation the people could actually use for other",
    "start": "1056529",
    "end": "1062350"
  },
  {
    "text": "use cases so if you're a si developer you play you like playing around with these things you could also get this",
    "start": "1062350",
    "end": "1067779"
  },
  {
    "text": "implementation outside of Redis and use it in some of your applications what's really special about radix trees and how",
    "start": "1067779",
    "end": "1075490"
  },
  {
    "text": "we implemented it is that it provides superfast lookups it gives you sorted",
    "start": "1075490",
    "end": "1082450"
  },
  {
    "text": "range queries which is which are used here for the timestamp queries and it really reduces memory usage so it's it's",
    "start": "1082450",
    "end": "1090460"
  },
  {
    "text": "very very frugal on memory usage super fast and gives you really nice capabilities especially the time",
    "start": "1090460",
    "end": "1097570"
  },
  {
    "text": "ordering if you looked a little sample message I put up there and I'm gonna go",
    "start": "1097570",
    "end": "1102580"
  },
  {
    "text": "into a bit more detail I'm kind of going to going to show you a small example of how you could think about a chat",
    "start": "1102580",
    "end": "1108549"
  },
  {
    "text": "application within the ready streams context but just to give you an idea of what like a single log and she could",
    "start": "1108549",
    "end": "1115000"
  },
  {
    "text": "look like it would have an entry ID that entry ID is time-stamped it also has a",
    "start": "1115000",
    "end": "1120340"
  },
  {
    "text": "sequence number just in case two messages come in at the same time we still want to be able to distinguish",
    "start": "1120340",
    "end": "1126460"
  },
  {
    "text": "between them so Redis actually takes care of that for you and then within a message I can put as",
    "start": "1126460",
    "end": "1132250"
  },
  {
    "text": "many kind of key value pairs as I want so in my little chat application I put",
    "start": "1132250",
    "end": "1137830"
  },
  {
    "text": "the message which in this case is high and I put the user ID who actually wrote",
    "start": "1137830",
    "end": "1143080"
  },
  {
    "text": "the message and then you can then you have consumers who basically make Redis",
    "start": "1143080",
    "end": "1148840"
  },
  {
    "text": "connections and make TCP connections to write a server and they can start reading from this log and as long as",
    "start": "1148840",
    "end": "1155350"
  },
  {
    "text": "that as long as that log hasn't been trimmed anyone who has permission can actually come in and read the log and do",
    "start": "1155350",
    "end": "1162669"
  },
  {
    "text": "what they want what makes it really powerful is I mentioned earlier that read is used to",
    "start": "1162669",
    "end": "1168730"
  },
  {
    "text": "support pop sub the problem in the Redis implementation of pub sub if something",
    "start": "1168730",
    "end": "1174010"
  },
  {
    "text": "goes wrong like the decline by mistake that disconnects and then wants to reconnect you know that message may be",
    "start": "1174010",
    "end": "1179950"
  },
  {
    "text": "gone in this kind of streaming capability you know that that message sticks around for quite some time until",
    "start": "1179950",
    "end": "1186190"
  },
  {
    "text": "we decide we too much in memory we want to trim the log and so if you have a disconnection",
    "start": "1186190",
    "end": "1191440"
  },
  {
    "text": "the client can just come back reconnect kind of remembers what it read last and then use arranged query to basically",
    "start": "1191440",
    "end": "1199360"
  },
  {
    "text": "read from that point onwards and so that model really delivers a lot of opportunity to build really",
    "start": "1199360",
    "end": "1205690"
  },
  {
    "text": "sophisticated log based applications ready streams also copied an idea from",
    "start": "1205690",
    "end": "1212890"
  },
  {
    "text": "Kafka and I don't know if Kafka invented it or copied it from somewhere else but",
    "start": "1212890",
    "end": "1218500"
  },
  {
    "text": "that idea is called consumer groups consumer groups is a special feature on top of this which basically guarantee if",
    "start": "1218500",
    "end": "1225370"
  },
  {
    "text": "clients are using consumer groups it means two things one the Redis server actually knows who the clients are and",
    "start": "1225370",
    "end": "1232660"
  },
  {
    "text": "the second thing is consumer groups will make sure that every that every piece of",
    "start": "1232660",
    "end": "1237820"
  },
  {
    "text": "data is only read by one client and so",
    "start": "1237820",
    "end": "1242860"
  },
  {
    "text": "basically guarantees that that a record is only processed by one client and that is also a really cool feature because if",
    "start": "1242860",
    "end": "1250000"
  },
  {
    "text": "you think about something like implementing a job queue you could you know through the system have multiple",
    "start": "1250000",
    "end": "1255670"
  },
  {
    "text": "worker processes write their worker servers but make sure that every job is",
    "start": "1255670",
    "end": "1260830"
  },
  {
    "text": "only executed once by a specific worker so that probably gives you a bit of a",
    "start": "1260830",
    "end": "1266440"
  },
  {
    "text": "taste of the kind of flexibility you get here you both have kind of the general log where anyone can come in and read from",
    "start": "1266440",
    "end": "1273040"
  },
  {
    "text": "the log and kind of reread different positions but you also have the consumer groups feature for certain use cases we",
    "start": "1273040",
    "end": "1280420"
  },
  {
    "text": "can basically guarantee unique data being read by specific clients now let",
    "start": "1280420",
    "end": "1288070"
  },
  {
    "start": "1287000",
    "end": "1429000"
  },
  {
    "text": "me kind of just demonstrate you know without code what I would look like although there's a tiny bit of code here",
    "start": "1288070",
    "end": "1293410"
  },
  {
    "text": "there's some Redis commands here so you can see the producer you can see the",
    "start": "1293410",
    "end": "1299170"
  },
  {
    "text": "stream in the middle and you can see the consumer and I've got a little command written there called X add my stream",
    "start": "1299170",
    "end": "1305800"
  },
  {
    "text": "star message hello that basically sends a record into the stream with a key",
    "start": "1305800",
    "end": "1314620"
  },
  {
    "text": "value pair of message alone so X head basically adds a message",
    "start": "1314620",
    "end": "1320190"
  },
  {
    "text": "the star says Redis please generate the unique ID for me and then of course",
    "start": "1320190",
    "end": "1327520"
  },
  {
    "text": "message hello which is the payload and then what you could see is the message",
    "start": "1327520",
    "end": "1333310"
  },
  {
    "text": "went into the stream and what I got back from Redis was basically my unique ID",
    "start": "1333310",
    "end": "1338820"
  },
  {
    "text": "which is the timestamp and the sequence number that was also assigned for me and",
    "start": "1338820",
    "end": "1344650"
  },
  {
    "text": "then I can you know I can save that for future reference so if I'm the guy who wrote this log entry I know what it is",
    "start": "1344650",
    "end": "1350680"
  },
  {
    "text": "and I can go and you know read from any position after that for example if I",
    "start": "1350680",
    "end": "1356110"
  },
  {
    "text": "want to and then there's a bunch of commands that actually help you read",
    "start": "1356110",
    "end": "1361240"
  },
  {
    "text": "logs so consumers can come in they can use something called they can do a range query like X range they can do a revert",
    "start": "1361240",
    "end": "1367870"
  },
  {
    "text": "a reverse range query like X Rev range or they can just use a single data point",
    "start": "1367870",
    "end": "1373240"
  },
  {
    "text": "X read and when you contain the return what God returned was basically the",
    "start": "1373240",
    "end": "1379480"
  },
  {
    "text": "timestamp and then the bag of the key values which in this case we only had one and we showed message hello so",
    "start": "1379480",
    "end": "1388000"
  },
  {
    "text": "that's kind of the very simplistic way on how it works obviously you know the the number of use cases and applications",
    "start": "1388000",
    "end": "1394690"
  },
  {
    "text": "you can build with this is our pretty extensive I also just want to remind I",
    "start": "1394690",
    "end": "1400600"
  },
  {
    "text": "mentioned consumer groups before in this example basically the consumer could read with these commands that I",
    "start": "1400600",
    "end": "1407530"
  },
  {
    "text": "mentioned the consumer could read any part of the Lord but if you use the commands like X cube X regroup then",
    "start": "1407530",
    "end": "1414730"
  },
  {
    "text": "you're actually using the consumer group feature dad as I said before you could",
    "start": "1414730",
    "end": "1420100"
  },
  {
    "text": "leverage in something like a job queue use case when you want to guarantee that a message is only processed by a single",
    "start": "1420100",
    "end": "1426880"
  },
  {
    "text": "consumer so let's see how you would potentially implement a very you know",
    "start": "1426880",
    "end": "1435640"
  },
  {
    "start": "1429000",
    "end": "1575000"
  },
  {
    "text": "simplistic chat application this is kind of an IRC application or you know you",
    "start": "1435640",
    "end": "1441010"
  },
  {
    "text": "have a channel you could join a channel and I've got three consumers here I'm gonna refer to the consumers just as",
    "start": "1441010",
    "end": "1447160"
  },
  {
    "text": "their last digit so I have consumer three consumer to consumer nine I don't",
    "start": "1447160",
    "end": "1452620"
  },
  {
    "text": "know if the text is very you're here but I'll just kind of read it out loud so consumer to put in the",
    "start": "1452620",
    "end": "1459460"
  },
  {
    "text": "first message and that message basically just says hi and then consumer and then",
    "start": "1459460",
    "end": "1466899"
  },
  {
    "text": "consumer three basically responded and said hi hi how are you and that went",
    "start": "1466899",
    "end": "1474130"
  },
  {
    "text": "into log but at the same time consumer two was actually not done and he sent another message saying how are you both",
    "start": "1474130",
    "end": "1481269"
  },
  {
    "text": "of those messages reached a server at exactly the same time and so what you can see is the the signed unique ID that",
    "start": "1481269",
    "end": "1488769"
  },
  {
    "text": "both of these messages got is almost identical except for the last sequence number that is different so that kind of",
    "start": "1488769",
    "end": "1496779"
  },
  {
    "text": "shows you some that ease of use and power of read of streams where you don't really have to think about this too much",
    "start": "1496779",
    "end": "1502299"
  },
  {
    "text": "Ready's will kind of do all the heavy lifting for you and basically starts assembling this as a queue and then we",
    "start": "1502299",
    "end": "1508539"
  },
  {
    "text": "have a third consumer that joins consumer nine that basically sends a message hey can I join you guys so by",
    "start": "1508539",
    "end": "1516490"
  },
  {
    "text": "now we have kind of four messages in the queue and because we're not using consumer groups all these consumers can",
    "start": "1516490",
    "end": "1522909"
  },
  {
    "text": "basically see all the messages so very easy not only for all of these for the",
    "start": "1522909",
    "end": "1528309"
  },
  {
    "text": "first two bit to basically see the chat between each other when consumer nine joins the chat he could actually see the",
    "start": "1528309",
    "end": "1536440"
  },
  {
    "text": "history of the chat and so there are a lot of applications where you actually would want a client that connects you",
    "start": "1536440",
    "end": "1543100"
  },
  {
    "text": "know that kind of laid binds into a log you would want that kind to actually be able to not just read the log going",
    "start": "1543100",
    "end": "1549070"
  },
  {
    "text": "forward but also kind of go back in time and read the rest of the log and so that",
    "start": "1549070",
    "end": "1555039"
  },
  {
    "text": "you know to chat application is obviously a very simplistic example of how to use this but there are lots of",
    "start": "1555039",
    "end": "1560409"
  },
  {
    "text": "different ways you could use this whether it's in message brokers job queues pop you know pop sub any kind of",
    "start": "1560409",
    "end": "1569049"
  },
  {
    "text": "streaming analytics lots of opportunities to use Redis streams we've",
    "start": "1569049",
    "end": "1576309"
  },
  {
    "start": "1575000",
    "end": "1607000"
  },
  {
    "text": "published a couple of blogs on our website on aws.amazon.com status and",
    "start": "1576309",
    "end": "1582100"
  },
  {
    "text": "those blog posts going to be more detail on ready streams and the first one is a bit more",
    "start": "1582100",
    "end": "1587410"
  },
  {
    "text": "for general ready streams article and the second one talks more specifically about message queues and how you could",
    "start": "1587410",
    "end": "1593920"
  },
  {
    "text": "think about implementing message queues in Redis so that's Redis now let's talk",
    "start": "1593920",
    "end": "1601660"
  },
  {
    "text": "a bit about Amazon ElastiCache paredes which is our fully managed service for Redis basically we launched Amazon",
    "start": "1601660",
    "end": "1610750"
  },
  {
    "start": "1607000",
    "end": "1683000"
  },
  {
    "text": "ElastiCache for Redis in 2013 and we basically launched it because we're",
    "start": "1610750",
    "end": "1616720"
  },
  {
    "text": "doing what we're usually doing which was listening to our customers and many of you were telling us that you really",
    "start": "1616720",
    "end": "1622450"
  },
  {
    "text": "liked this thing called Redis but Redis was really hard to manage like you",
    "start": "1622450",
    "end": "1627670"
  },
  {
    "text": "didn't want to be have to provision this all on your own you didn't want to have to patch the full stack all the time on your own you",
    "start": "1627670",
    "end": "1634780"
  },
  {
    "text": "know start to provision it in a highly available way across AZ's as a non-trivial effort scaling Redis over",
    "start": "1634780",
    "end": "1642100"
  },
  {
    "text": "time is also a non-trivial effort not just because you need to set up the topology there's lots of little nuances",
    "start": "1642100",
    "end": "1648070"
  },
  {
    "text": "where replication can back up and you know all sorts of operational issues and",
    "start": "1648070",
    "end": "1653880"
  },
  {
    "text": "see you basically came to us and said hey can you do the same for Redis as you",
    "start": "1653880",
    "end": "1659200"
  },
  {
    "text": "did for my sequel and already yes and that's pretty much what we did with ElastiCache for Redis and you know last",
    "start": "1659200",
    "end": "1666520"
  },
  {
    "text": "thing I also wanted to note is the other feedback we get consistently on these services is you know if I have to go and",
    "start": "1666520",
    "end": "1673870"
  },
  {
    "text": "hire all these developers they're going to build these service and keep them up 24/7 right it ends up also being pretty",
    "start": "1673870",
    "end": "1680620"
  },
  {
    "text": "expensive for us all right so that's why we that's why we launched ElastiCache paredes so that service has been up for",
    "start": "1680620",
    "end": "1688030"
  },
  {
    "start": "1683000",
    "end": "1881000"
  },
  {
    "text": "over five years and it's a you know very important service for us it's been very",
    "start": "1688030",
    "end": "1694000"
  },
  {
    "text": "successful we see a large amount of customers taking advantage of it from caching use cases beyond and just in a",
    "start": "1694000",
    "end": "1701590"
  },
  {
    "text": "nutshell there's a few things you know I think issue keep keep in mind as far as this service is concerned first of all",
    "start": "1701590",
    "end": "1709450"
  },
  {
    "text": "we don't like talking about high performance we like talking about extreme performance you know we see ourselves as the most performant",
    "start": "1709450",
    "end": "1715630"
  },
  {
    "text": "database database at AWS obviously there's always a trade-off",
    "start": "1715630",
    "end": "1721330"
  },
  {
    "text": "right we're not asked to compliant that we don't do other things but we do what we do well is we can deliver microsecond",
    "start": "1721330",
    "end": "1727180"
  },
  {
    "text": "latencies we're fully managed so we manage the whole stack for you we update",
    "start": "1727180",
    "end": "1733090"
  },
  {
    "text": "the operating system would keep this we keep the stack healthy and keep the service healthy and if you know if",
    "start": "1733090",
    "end": "1740020"
  },
  {
    "text": "Hardware goes bad or anything we replace it for you make sure that the environment is up we've made it you know",
    "start": "1740020",
    "end": "1746920"
  },
  {
    "text": "increasingly easy to scale red is for you and not only being able to add read replicas we also enable sharded Redis",
    "start": "1746920",
    "end": "1754000"
  },
  {
    "text": "now with sharded Redis you can actually not just scale on reads you can also",
    "start": "1754000",
    "end": "1759400"
  },
  {
    "text": "scale on writes and and I'll talk a bit later about a recent announcement we made in the past couple of weeks of",
    "start": "1759400",
    "end": "1765370"
  },
  {
    "text": "another significant milestone and getting to a new level of scale but that",
    "start": "1765370",
    "end": "1770740"
  },
  {
    "text": "has been a huge huge focus for us and then from an availability perspective we give you a multi AZ environment we do",
    "start": "1770740",
    "end": "1777520"
  },
  {
    "text": "multi Z failover and probably most important and this is part of where our secret sauce is we",
    "start": "1777520",
    "end": "1783580"
  },
  {
    "text": "have very very deep monitoring so we're consistently monitoring the systems at a very deep level and you know if a fan",
    "start": "1783580",
    "end": "1790780"
  },
  {
    "text": "goes out on a piece of hardware and there's an instance you know instance issue or there's some other issues you",
    "start": "1790780",
    "end": "1797770"
  },
  {
    "text": "know we remediate we do automatic failover or we take some other action or we let you take action depending on what",
    "start": "1797770",
    "end": "1804040"
  },
  {
    "text": "you've configured like with most of our services security and compliance is",
    "start": "1804040",
    "end": "1809230"
  },
  {
    "text": "super important and so we support the ElastiCache within VPC environments",
    "start": "1809230",
    "end": "1815070"
  },
  {
    "text": "we've put a huge focus on going through compliance in the past year and so we're",
    "start": "1815070",
    "end": "1820240"
  },
  {
    "text": "now HIPAA compatible we got PCI compliance we just got FedRAMP the compliance and we're going to continue",
    "start": "1820240",
    "end": "1827110"
  },
  {
    "text": "to expand expand the amount of compliance programs we're gonna go we're going to go through we encrypt",
    "start": "1827110",
    "end": "1834100"
  },
  {
    "text": "everything we said we do encryption encryption and rest encryption and transit and we also support event",
    "start": "1834100",
    "end": "1840070"
  },
  {
    "text": "occasion and then last but not least we always try and make sure we have the latest and greatest Redis available for",
    "start": "1840070",
    "end": "1847810"
  },
  {
    "text": "you I would say to be you know self-critical in the past year we really didn't do a great job like with Redis",
    "start": "1847810",
    "end": "1854130"
  },
  {
    "text": "or it took us too much time to get the latest version onto the service with Redis 5 we did it under four weeks and",
    "start": "1854130",
    "end": "1860670"
  },
  {
    "text": "really going forward we're gonna have a huge focus on making sure that this service continues to be updated we don't",
    "start": "1860670",
    "end": "1867240"
  },
  {
    "text": "want to be too fast because we have to test it and we got to make sure it's secure but I would say within weeks we",
    "start": "1867240",
    "end": "1873180"
  },
  {
    "text": "want to make sure we have major versions on the service and you can really enjoy the latest greatest features our",
    "start": "1873180",
    "end": "1879030"
  },
  {
    "text": "greatest dreams on this service so talk about some of the customers we have we",
    "start": "1879030",
    "end": "1885510"
  },
  {
    "start": "1881000",
    "end": "2093000"
  },
  {
    "text": "have some really exciting news cases Expedia they built a real-time analytics",
    "start": "1885510",
    "end": "1890880"
  },
  {
    "text": "application initially was not using Reddit and they're getting really bad performance and you know they were using",
    "start": "1890880",
    "end": "1898920"
  },
  {
    "text": "good databases but the problem was they had such scale they had 200 million messages of data they had to process",
    "start": "1898920",
    "end": "1904500"
  },
  {
    "text": "that just those repeated database calls were just adding up and so that's a",
    "start": "1904500",
    "end": "1910080"
  },
  {
    "text": "prime example where even a you know tens of milliseconds or a single-digit millisecond you know was not fast enough",
    "start": "1910080",
    "end": "1917040"
  },
  {
    "text": "in this specific use case so they took Redis they used it to cache data as part",
    "start": "1917040",
    "end": "1924600"
  },
  {
    "text": "of this analytics process and they significantly increased throughput they reduced latencies by a significant",
    "start": "1924600",
    "end": "1932790"
  },
  {
    "text": "factor and probably most important they saved six times the cost on their data stores and that's just because Redis was",
    "start": "1932790",
    "end": "1941400"
  },
  {
    "text": "able to give such fast performance and so much throughput at a very reasonable cost that that caching basically allowed",
    "start": "1941400",
    "end": "1948870"
  },
  {
    "text": "them to provision less of the other database that they had and so that cost saving was very very significant grab",
    "start": "1948870",
    "end": "1956070"
  },
  {
    "text": "uses a Redis for many use cases but I'd say one of the use cases also for",
    "start": "1956070",
    "end": "1961740"
  },
  {
    "text": "real-time analytics of over four million rides they do a day and kind of similar",
    "start": "1961740",
    "end": "1967680"
  },
  {
    "text": "example but they've estimated that they save up to 30 to 40% of manpower by",
    "start": "1967680",
    "end": "1973920"
  },
  {
    "text": "basically using managed services and really letting us to old on undifferentiated heavy lifting to make",
    "start": "1973920",
    "end": "1981720"
  },
  {
    "text": "sure that the environments are consistently up and supported one of my favorites is pet",
    "start": "1981720",
    "end": "1987570"
  },
  {
    "text": "for those who don't know peloton it's basically kind of an in-home stationary bike but it's cloud-connected and it's",
    "start": "1987570",
    "end": "1993989"
  },
  {
    "text": "got a it's got a video stream and you can take classes similar to going into a spinning class but it's also got a",
    "start": "1993989",
    "end": "2000559"
  },
  {
    "text": "social component to it so actually as you're joining classes you're actually doing the classes with other people in",
    "start": "2000559",
    "end": "2006710"
  },
  {
    "text": "real time and so they're using sorted sets you know for leader boards as part",
    "start": "2006710",
    "end": "2012409"
  },
  {
    "text": "of that so while while you're actually you know biking at home exercising and sweating you can actually see where you",
    "start": "2012409",
    "end": "2018889"
  },
  {
    "text": "rank and I haven't tried peloton quite yet but I know that I'm never in the top",
    "start": "2018889",
    "end": "2024919"
  },
  {
    "text": "spot so I probably wouldn't show up anywhere there and then last but not least GE which is doing session",
    "start": "2024919",
    "end": "2032509"
  },
  {
    "text": "management for a container --less platform that they offer to their developers and house and they've been",
    "start": "2032509",
    "end": "2038269"
  },
  {
    "text": "using hash maps to basically deliver session state if you remember I mentioned earlier session state tends to",
    "start": "2038269",
    "end": "2045619"
  },
  {
    "text": "have a bundle of key value pairs and so hash maps are you know really really",
    "start": "2045619",
    "end": "2051108"
  },
  {
    "text": "nice way to deliver that what's important about sessions is if you think about your website and the customer logs",
    "start": "2051109",
    "end": "2056599"
  },
  {
    "text": "in and you know maybe it's an e-commerce site or something else you need a retain state you know making",
    "start": "2056599",
    "end": "2062690"
  },
  {
    "text": "a database call - like a sequel database or some other database every time the customer moves from page to page is just",
    "start": "2062690",
    "end": "2069589"
  },
  {
    "text": "far too expensive and slow and so that's like a really good example that just by using Redis hashmaps",
    "start": "2069589",
    "end": "2075888"
  },
  {
    "text": "you know you can both deliver a better customer experience but you can do like 200 thousands of those per second you",
    "start": "2075889",
    "end": "2082490"
  },
  {
    "text": "know on the single you know relatively small instance so it's also not going to",
    "start": "2082490",
    "end": "2087648"
  },
  {
    "text": "cost you as much if you actually have to drive a pretty high workload and then",
    "start": "2087649",
    "end": "2095148"
  },
  {
    "start": "2093000",
    "end": "2131000"
  },
  {
    "text": "you know we have a lot of customers in different verticals you know McDonald's",
    "start": "2095149",
    "end": "2100250"
  },
  {
    "text": "uses Redis thermo Fisher in the industrials a lot of media entertainment I really mentioned gaming pretty much",
    "start": "2100250",
    "end": "2108530"
  },
  {
    "text": "every game as a leaderboard which means most of these games have Redis telcos",
    "start": "2108530",
    "end": "2113599"
  },
  {
    "text": "ride-hailing financial services and now especially now as we've added encryption and we've added compliance capabilities",
    "start": "2113599",
    "end": "2119839"
  },
  {
    "text": "to the service we're definitely seeing an increasing amount of traditional enterprises picking up Redis and using it for their",
    "start": "2119839",
    "end": "2127820"
  },
  {
    "text": "mission-critical applications so that's",
    "start": "2127820",
    "end": "2133580"
  },
  {
    "start": "2131000",
    "end": "2501000"
  },
  {
    "text": "not a bit about the service and what's been going on in the past 18 months so just going back to last year's reinvent",
    "start": "2133580",
    "end": "2139280"
  },
  {
    "text": "and I'm not going to spend a lot of time on this last year is reinvent we talked a lot about Redis cluster which is the",
    "start": "2139280",
    "end": "2144890"
  },
  {
    "text": "sharded version of Redis and we had just announced online Redis cluster we",
    "start": "2144890",
    "end": "2150620"
  },
  {
    "text": "sharding which means you can basically change the amount of shards online while you're still serving requests and so if",
    "start": "2150620",
    "end": "2158210"
  },
  {
    "text": "you need higher write throughput or more capacity you can basically do that online that's also when we announced",
    "start": "2158210",
    "end": "2164210"
  },
  {
    "text": "encryption everywhere encryption at rest encryption in transit and we also announced HIPAA eligibility 2008 and I",
    "start": "2164210",
    "end": "2174080"
  },
  {
    "text": "think became even more exciting just with the recent announcement of support for Redis 5 we just announced support",
    "start": "2174080",
    "end": "2182420"
  },
  {
    "text": "for M 5 and R 5 instances but this announcement is more special than some of the past instance announcements we've",
    "start": "2182420",
    "end": "2188180"
  },
  {
    "text": "made so I'm gonna talk in a bit more detail on you know what that announcement was about and why you",
    "start": "2188180",
    "end": "2194210"
  },
  {
    "text": "should care about it we've seen customers use a lot more Redis but also",
    "start": "2194210",
    "end": "2199820"
  },
  {
    "text": "use a lot more reticent scale and so the previous limitations of 19 nodes in a",
    "start": "2199820",
    "end": "2205070"
  },
  {
    "text": "cluster of 15 shards just weren't working for some of our customers so we've just announced support for much",
    "start": "2205070",
    "end": "2212390"
  },
  {
    "text": "bigger scale we can do 250 nodes you know in a single Redis cluster today",
    "start": "2212390",
    "end": "2217700"
  },
  {
    "text": "we've also increased the amount of shards we support from 15 shards to 250",
    "start": "2217700",
    "end": "2224240"
  },
  {
    "text": "shards and if you think about every shard basically the master node defines",
    "start": "2224240",
    "end": "2229910"
  },
  {
    "text": "how much memory you use from a write you can use from a write and data perspective right the read replicas",
    "start": "2229910",
    "end": "2236240"
  },
  {
    "text": "don't count and so going from 15 charts to 250 actually means that the amount of",
    "start": "2236240",
    "end": "2241790"
  },
  {
    "text": "unique data you can save in our environment now is over 16 fold and you",
    "start": "2241790",
    "end": "2247460"
  },
  {
    "text": "could do before so it's a very very significant change for our customers especially those who have been pushing",
    "start": "2247460",
    "end": "2253880"
  },
  {
    "text": "us but to go to higher and higher scale we also in the last year open-source sir",
    "start": "2253880",
    "end": "2260460"
  },
  {
    "text": "encryption and transit support so we last year we announced encryption in transit we built on an encryption trend",
    "start": "2260460",
    "end": "2267060"
  },
  {
    "text": "as a in transit is a very hard feature to build it's gotta be operationally sound it's got to be really secure we",
    "start": "2267060",
    "end": "2274290"
  },
  {
    "text": "also used a library that we open sourced as Amazon called s to n which is",
    "start": "2274290",
    "end": "2280410"
  },
  {
    "text": "basically an open ssl replacement which we believe you know performs better and has a lot of benefits especially it's a",
    "start": "2280410",
    "end": "2287490"
  },
  {
    "text": "much more lighter weight simple library so it's easier to kind of also make sure that it's you know kind of remained",
    "start": "2287490",
    "end": "2293760"
  },
  {
    "text": "secure and so on until we we leverage that apache to licensed s 2n library",
    "start": "2293760",
    "end": "2299730"
  },
  {
    "text": "that we had open sourced a couple of years ago and basically built encryption and transit and then we open sourced",
    "start": "2299730",
    "end": "2305790"
  },
  {
    "text": "encryption and transit capability we still haven't gotten that all the way upstream into Redis but we're definitely",
    "start": "2305790",
    "end": "2312450"
  },
  {
    "text": "you know into the Redis creator to see if we can kind of you know continue to",
    "start": "2312450",
    "end": "2318870"
  },
  {
    "text": "work on that patch and make sure that it fits kind of the coding standards of Redis so you can hopefully get into",
    "start": "2318870",
    "end": "2324450"
  },
  {
    "text": "upstream Redis with that we were able to get through PCI compliance FedRAMP",
    "start": "2324450",
    "end": "2329940"
  },
  {
    "text": "compliance and we continue to go through the rest of the compliance certifications a lot of your feedback to",
    "start": "2329940",
    "end": "2338040"
  },
  {
    "text": "us has been I don't really understand what's happening I you know if something goes slow the CPU metrics aren't really",
    "start": "2338040",
    "end": "2343890"
  },
  {
    "text": "clear to me you know Redis a single-threaded so how can I really kind of you know draw a parallel between CPU",
    "start": "2343890",
    "end": "2350520"
  },
  {
    "text": "metrics and how busy Redis is the simple answer is it's actually really hard so I",
    "start": "2350520",
    "end": "2356520"
  },
  {
    "text": "don't have the perfect answer for you but we do give an additional metric that gives you a specific metric on the Redis",
    "start": "2356520",
    "end": "2362370"
  },
  {
    "text": "process itself so not just to read the Machine CPU metric but also the Redis CPU metric I'll talk about some of the",
    "start": "2362370",
    "end": "2370320"
  },
  {
    "text": "futures in a couple of minutes and you'll see that this even this metric we'll have to think about how to fit in",
    "start": "2370320",
    "end": "2376140"
  },
  {
    "text": "into the future but it is another way for us to kind of show you give you some more transparency about what's happening",
    "start": "2376140",
    "end": "2383390"
  },
  {
    "text": "the other thing you asked us for is you know until today we didn't support snapshots auto failover with t two's the primary",
    "start": "2383390",
    "end": "2391230"
  },
  {
    "text": "reason was the T 2's are just very small instances and you know we were concerned that they weren't operationally sound",
    "start": "2391230",
    "end": "2397109"
  },
  {
    "text": "enough for production environments and we still don't recommend them today because they you know you could run out",
    "start": "2397109",
    "end": "2402450"
  },
  {
    "text": "of cpu credits and then bad things could happen but we did want to make sure that you could use T tools in dev and test to",
    "start": "2402450",
    "end": "2410130"
  },
  {
    "text": "build environments they were very comparable at least in configuration to the production environments you had so",
    "start": "2410130",
    "end": "2416220"
  },
  {
    "text": "for that we basically launched support just a few weeks ago for snapshotting on",
    "start": "2416220",
    "end": "2421230"
  },
  {
    "text": "T twos we also support auto failover 42s right now and you know we'd love to",
    "start": "2421230",
    "end": "2427109"
  },
  {
    "text": "continue to hear your feedback on what you want to see us do around the kind of lower end of the instances and",
    "start": "2427109",
    "end": "2434130"
  },
  {
    "text": "especially as our Hardware keeps on getting better at AWS I think there's going to be a lot of interesting",
    "start": "2434130",
    "end": "2439650"
  },
  {
    "text": "opportunities in the future with actually some of the lower end end instances to deliver some nice",
    "start": "2439650",
    "end": "2444930"
  },
  {
    "text": "production capabilities and then last but not least one of the things that we",
    "start": "2444930",
    "end": "2451230"
  },
  {
    "text": "were missing is we weren't supporting in-place version upgrades for Redis cluster which is the Charlotte Redis and",
    "start": "2451230",
    "end": "2457740"
  },
  {
    "text": "that's also something we announced so if you look at Jeff bars blog where he describes the Redis 5 launch you'll see",
    "start": "2457740",
    "end": "2463950"
  },
  {
    "text": "that he actually kind of shows two screenshots and he shows how he migrated his Redis for cluster to Rattus five in",
    "start": "2463950",
    "end": "2472740"
  },
  {
    "text": "one click of a button so our big goal here is ready to make management as easy",
    "start": "2472740",
    "end": "2477960"
  },
  {
    "text": "as possible give you as much flexibility as you can we still have a lot of work ahead of us to continue to push the",
    "start": "2477960",
    "end": "2484140"
  },
  {
    "text": "envelope and how easy and scalable that the environment is but there's a you know a lot of investment we're making in",
    "start": "2484140",
    "end": "2490730"
  },
  {
    "text": "making sure that the service continues to meet the needs of your applications and the increasing amount of you know",
    "start": "2490730",
    "end": "2497730"
  },
  {
    "text": "variance in use case that we're seeing around Redis so let's talk a bit about",
    "start": "2497730",
    "end": "2503820"
  },
  {
    "start": "2501000",
    "end": "2757000"
  },
  {
    "text": "this new m5 r5 instances so first of all you know m5 and r5 instances are",
    "start": "2503820",
    "end": "2510810"
  },
  {
    "text": "actually quite special our hardware teams are Radian evading on the hardware and they built a system called the nitro",
    "start": "2510810",
    "end": "2518160"
  },
  {
    "text": "system nitrous system is a way for us to offloads the you know hypervisor hypervisor work",
    "start": "2518160",
    "end": "2524549"
  },
  {
    "text": "security networking and so on off instance and basically freeing up a lot",
    "start": "2524549",
    "end": "2530579"
  },
  {
    "text": "of the cpu to actually do what it's supposed to do which is actually run your applications and our goal and",
    "start": "2530579",
    "end": "2537270"
  },
  {
    "text": "pretty much what our Hardware team has achieved is by using this AWS nitro",
    "start": "2537270",
    "end": "2542400"
  },
  {
    "text": "system on the m5 and our five instances and many of our future instances are going to use it to we're basically",
    "start": "2542400",
    "end": "2548579"
  },
  {
    "text": "delivering virtualized instances with the performance that is pretty much indistinguishable from bare metal",
    "start": "2548579",
    "end": "2555089"
  },
  {
    "text": "performance and so that hypervisor overhead is going away and that is especially important in something like",
    "start": "2555089",
    "end": "2561569"
  },
  {
    "text": "Redis and in-memory because when you're in memory and you're running that fast and you're doing system calls and you're",
    "start": "2561569",
    "end": "2567210"
  },
  {
    "text": "doing memory management you know that's where you're really gonna feel it you're not gonna feel it quite as much on like",
    "start": "2567210",
    "end": "2572640"
  },
  {
    "text": "a java-based application because there's so much overhead from just the Java Runtime the memory manager you'll feel",
    "start": "2572640",
    "end": "2579150"
  },
  {
    "text": "it but not quite as extreme as you'll feel it on Redis and so what we did here",
    "start": "2579150",
    "end": "2584339"
  },
  {
    "text": "is we ran some benchmarks and these are pretty simple benchmarks they're key value benchmarks where the values are",
    "start": "2584339",
    "end": "2590880"
  },
  {
    "text": "200 bytes it's an 80% we 20% write workload so",
    "start": "2590880",
    "end": "2595920"
  },
  {
    "text": "it's not the most scientifically perfect benchmarks but it's pretty good to kind of show you you know kind of what step",
    "start": "2595920",
    "end": "2601530"
  },
  {
    "text": "function and performance you could assume and if we just take you know vanilla our fours and been in our 5s as",
    "start": "2601530",
    "end": "2608400"
  },
  {
    "text": "is with Amazon Linux you can see that there was a dramatic jump between the",
    "start": "2608400",
    "end": "2613859"
  },
  {
    "text": "pink and the purple there in performance in fact the jump is somewhere between the Pentagon the instance type between",
    "start": "2613859",
    "end": "2621329"
  },
  {
    "text": "59 and 144 percent throughput improvement we also saw so",
    "start": "2621329",
    "end": "2627839"
  },
  {
    "text": "Layton sees go down 23% so not only are",
    "start": "2627839",
    "end": "2632910"
  },
  {
    "text": "you able to you know use a lot more of it which i think is probably the primary benefit because that really helps you",
    "start": "2632910",
    "end": "2639180"
  },
  {
    "text": "manage your cost but you're also getting much better latencies but that was not",
    "start": "2639180",
    "end": "2645390"
  },
  {
    "text": "all in addition to that we did we were like hey we just gotta try and get the",
    "start": "2645390",
    "end": "2651030"
  },
  {
    "text": "performance up as huh as much as we can and we worked with a hardware team and we put a lot of effort into really",
    "start": "2651030",
    "end": "2657920"
  },
  {
    "text": "optimizing the kernel configuration the hypervisor and so on and that's that red",
    "start": "2657920",
    "end": "2663059"
  },
  {
    "text": "bar so kind of when you get ElastiCache for Redis you're getting you know Redis",
    "start": "2663059",
    "end": "2669000"
  },
  {
    "text": "on Amazon Linux you know on the Nitro system but also we've really spent a lot",
    "start": "2669000",
    "end": "2675059"
  },
  {
    "text": "of time just to configure the neck the networking queues the interrupts the",
    "start": "2675059",
    "end": "2681210"
  },
  {
    "text": "timer is lots of things in the system just to make sure you really are maximizing what you get and in some",
    "start": "2681210",
    "end": "2686490"
  },
  {
    "text": "cases just those configurations actually add another 30% in throughput so these",
    "start": "2686490",
    "end": "2692220"
  },
  {
    "text": "are not negligible numbers especially if you start running Redis at scale this really adds up and with introduction of",
    "start": "2692220",
    "end": "2700500"
  },
  {
    "text": "this and then the 250 knows clusters you can actually want an environment like",
    "start": "2700500",
    "end": "2706470"
  },
  {
    "text": "this now on up to 170 terabytes so you",
    "start": "2706470",
    "end": "2711720"
  },
  {
    "text": "can write you can run some really big r5 instant space Redis clusters and and",
    "start": "2711720",
    "end": "2717900"
  },
  {
    "text": "probably last thing I should say so these are built on custom Intel Xeon designed for AWS and just this system as",
    "start": "2717900",
    "end": "2725849"
  },
  {
    "text": "a whole is a really really awesome system so if you're running on our force today I definitely would recommend that",
    "start": "2725849",
    "end": "2731880"
  },
  {
    "text": "you tried our five and in fact our fives are also cheaper than our force on a per",
    "start": "2731880",
    "end": "2738450"
  },
  {
    "text": "hour basis so there's really almost no reason not to use our files but you know",
    "start": "2738450",
    "end": "2745740"
  },
  {
    "text": "give it a try it could be application specific but these are you know very very reproducible benchmarks just with a",
    "start": "2745740",
    "end": "2752910"
  },
  {
    "text": "very simple kind of key value request paradigm to give you a short case study",
    "start": "2752910",
    "end": "2760440"
  },
  {
    "start": "2757000",
    "end": "2855000"
  },
  {
    "text": "fit r5 so r5 just came out a few on ElastiCache came out a few weeks ago and",
    "start": "2760440",
    "end": "2765799"
  },
  {
    "text": "then after they came out you know epic games got in touch with us they're using elastic cash for Redis for fortnight ago",
    "start": "2765799",
    "end": "2774359"
  },
  {
    "text": "telling us you know we have a huge surge event coming up we want to dramatically increase this the cluster size and",
    "start": "2774359",
    "end": "2781049"
  },
  {
    "text": "because we have online you know scale out scale down support with Redis",
    "start": "2781049",
    "end": "2786450"
  },
  {
    "text": "cluster that's definitely an option but they were already running at such a large scale that not only would it have",
    "start": "2786450",
    "end": "2793229"
  },
  {
    "text": "been operationally complex to continue to push that scale for them but also",
    "start": "2793229",
    "end": "2798299"
  },
  {
    "text": "would have gotten very very expensive and so you know we kind of when we heard",
    "start": "2798299",
    "end": "2803400"
  },
  {
    "text": "that were like you know maybe we can do something good here and I can make sure that they're not spending any more money but are meeting their surgeon and",
    "start": "2803400",
    "end": "2810720"
  },
  {
    "text": "requirements until we suggested you know why didn't you go and try to our five we just got them out now they're super",
    "start": "2810720",
    "end": "2817079"
  },
  {
    "text": "optimized they seem to fit your use case and they basically migrated that",
    "start": "2817079",
    "end": "2822509"
  },
  {
    "text": "environment to our fives they didn't have to scale up whatsoever and that",
    "start": "2822509",
    "end": "2827809"
  },
  {
    "text": "surge event went through without a breeze and in fact they told us afterwards that they saw the CPU type go",
    "start": "2827809",
    "end": "2835619"
  },
  {
    "text": "down by about two-thirds while that event was actually going on so they saw",
    "start": "2835619",
    "end": "2842130"
  },
  {
    "text": "a super big impact you know not just from a performance perspective but",
    "start": "2842130",
    "end": "2847680"
  },
  {
    "text": "ultimately also operational risk and cost went significantly down that we",
    "start": "2847680",
    "end": "2857339"
  },
  {
    "start": "2855000",
    "end": "3084000"
  },
  {
    "text": "have a very rich role map over the next year I'm not gonna go and I'm not going to talk to our roadmap you'll see that",
    "start": "2857339",
    "end": "2862829"
  },
  {
    "text": "roadmap evolve and as we make announcements but I did want to highlight a few things that were kind of",
    "start": "2862829",
    "end": "2868019"
  },
  {
    "text": "very short-term they're kind of almost out but we didn't quite get them out in",
    "start": "2868019",
    "end": "2873269"
  },
  {
    "text": "time for reinvent so if you kind of you know cool interesting things the first",
    "start": "2873269",
    "end": "2878579"
  },
  {
    "text": "one is this performance journey with the m5 and our five instances really gave us",
    "start": "2878579",
    "end": "2884279"
  },
  {
    "text": "the appetite to try and do better and so we've actually done even more work since",
    "start": "2884279",
    "end": "2889319"
  },
  {
    "text": "then and have looked at how can we actually leverage as you go and provision like are five extra larges and",
    "start": "2889319",
    "end": "2895589"
  },
  {
    "text": "up and multi-core environments how we can really make sure we take more advantage of the course so you know",
    "start": "2895589",
    "end": "2902460"
  },
  {
    "text": "quite shortly we're going to see another step function in throughput coming out",
    "start": "2902460",
    "end": "2908910"
  },
  {
    "text": "by us having done more work on really optimizing the network processing and",
    "start": "2908910",
    "end": "2914160"
  },
  {
    "text": "that's going to just kind of come out as part of you know Redis 5 on the r5 and",
    "start": "2914160",
    "end": "2919170"
  },
  {
    "text": "m5 instances and actually probably also support some the older census and you were gonna get those",
    "start": "2919170",
    "end": "2924660"
  },
  {
    "text": "dramatic throughput benefits as part of you know just using our instances the",
    "start": "2924660",
    "end": "2931260"
  },
  {
    "text": "second thing which may seem like a really small feature but we've been consistently asked to do this is",
    "start": "2931260",
    "end": "2937070"
  },
  {
    "text": "supporting the rename support command lots of our customers that you put",
    "start": "2937070",
    "end": "2943109"
  },
  {
    "text": "reticent to production you know the nice thing about Redis is it's really easy for developers to connect to it and kind",
    "start": "2943109",
    "end": "2948390"
  },
  {
    "text": "of look around and you know while it's in production kind of see what's going on however there's also a few commands",
    "start": "2948390",
    "end": "2954780"
  },
  {
    "text": "that if you run them on a production environment by mistake just with good intentions I'm trying to figure out you",
    "start": "2954780",
    "end": "2960300"
  },
  {
    "text": "know what's going on in an environment you could significant negative impact on your Redis environment one of the",
    "start": "2960300",
    "end": "2967800"
  },
  {
    "text": "favorite commands that people like running is keys which basically returns all your keys and Redis and don't try",
    "start": "2967800",
    "end": "2974609"
  },
  {
    "text": "this at home if you have a really heavy-duty Redis environment and you go in and you're on keys you know your boss",
    "start": "2974609",
    "end": "2981270"
  },
  {
    "text": "isn't gonna be very happy and so those are the kind of you know so those are",
    "start": "2981270",
    "end": "2986790"
  },
  {
    "text": "the kind of commands that we've been asked you know to rename so that you know people accessing the environment",
    "start": "2986790",
    "end": "2993780"
  },
  {
    "text": "don't just by mistake forget or maybe maybe they have a development environment in one window under console",
    "start": "2993780",
    "end": "2999589"
  },
  {
    "text": "the production on the right and you know never happened to anyone you wrote to you wrote the the wrong command in the",
    "start": "2999589",
    "end": "3006500"
  },
  {
    "text": "wrong window or the right command in the wrong window and things weren't bad trying to make sure we eliminate you",
    "start": "3006500",
    "end": "3013310"
  },
  {
    "text": "know those kind of issues and then last but not least we've also been asked to make you know service patching easier",
    "start": "3013310",
    "end": "3019430"
  },
  {
    "text": "today we have a service window which you can select and then we'll make sure that security updates and other updates are",
    "start": "3019430",
    "end": "3025640"
  },
  {
    "text": "basically patched within that service window but we've gotten a lot of feedback from you that you know it's",
    "start": "3025640",
    "end": "3031550"
  },
  {
    "text": "great that you that we give you the opportunity to configure that service window but your business is changing all",
    "start": "3031550",
    "end": "3037369"
  },
  {
    "text": "the time or was a good service window two months ago is not a good service window this month and you want to have a",
    "start": "3037369",
    "end": "3043460"
  },
  {
    "text": "bit more control over when these things run so we're gonna be introducing something called self-service patching",
    "start": "3043460",
    "end": "3049089"
  },
  {
    "text": "which means that we will actually let you know when you have to patch you'll be able to patch through an API call or",
    "start": "3049089",
    "end": "3056470"
  },
  {
    "text": "through the console just by hitting a button and then the patching process will start and we're gonna you know go",
    "start": "3056470",
    "end": "3062109"
  },
  {
    "text": "no by node and and an upgrade your environment now if you don't take action at some point we're we're gonna do it",
    "start": "3062109",
    "end": "3068830"
  },
  {
    "text": "within your service window for you but at least this way we're gonna give you the choice to take ownership as a",
    "start": "3068830",
    "end": "3076150"
  },
  {
    "text": "patching ahead of time and doing doing it at some time which is convenient for",
    "start": "3076150",
    "end": "3081700"
  },
  {
    "text": "your business there's lots more sessions",
    "start": "3081700",
    "end": "3087849"
  },
  {
    "start": "3084000",
    "end": "3129000"
  },
  {
    "text": "about Redis at this conference today at 3:15 we have one of our lead specialist",
    "start": "3087849",
    "end": "3094240"
  },
  {
    "text": "ace that's worked with most of our large customers to a deeper dive into Redis",
    "start": "3094240",
    "end": "3099340"
  },
  {
    "text": "and design pattern patterns run in memory data stores tomorrow we're gonna",
    "start": "3099340",
    "end": "3104619"
  },
  {
    "text": "have a chalk talk if you really if I got your attention with ready streams and",
    "start": "3104619",
    "end": "3110140"
  },
  {
    "text": "you have appetite to learn more there's going to be really nice chalk talk tomorrow where some of the folks on my",
    "start": "3110140",
    "end": "3116320"
  },
  {
    "text": "team are gonna take you through a the streams and show you how you can build an application with it and then on friday friday we have another hand",
    "start": "3116320",
    "end": "3122970"
  },
  {
    "text": "hands-on tutorial or workshop on the last akash for Redis so I hope within",
    "start": "3122970",
    "end": "3130599"
  },
  {
    "start": "3129000",
    "end": "3600000"
  },
  {
    "text": "this session I was able to you know meet both objectives those are not using Redis I hope I built enough appetite for",
    "start": "3130599",
    "end": "3137260"
  },
  {
    "text": "you to go and try Redis right now and for those who are not using ElastiCache I hope you'll give us an opportunity to",
    "start": "3137260",
    "end": "3145210"
  },
  {
    "text": "show you show you what we can do we have time for questions first of all I can",
    "start": "3145210",
    "end": "3151420"
  },
  {
    "text": "take questions right now there's also my email address up on the screen and you",
    "start": "3151420",
    "end": "3158080"
  },
  {
    "text": "could you should feel free to email me any questions or also feedback if there are things you would like us to do better on the service things you would",
    "start": "3158080",
    "end": "3164859"
  },
  {
    "text": "like to see shoot me an email and you know we would love to get the feedback and frankly our roadmap is really",
    "start": "3164859",
    "end": "3171609"
  },
  {
    "text": "defined by the feedback you're giving us",
    "start": "3171609",
    "end": "3176338"
  },
  {
    "text": "[Applause] so do we have any questions here yeah go",
    "start": "3180870",
    "end": "3188290"
  },
  {
    "text": "ahead the web support to support what oh",
    "start": "3188290",
    "end": "3196590"
  },
  {
    "text": "you mean like cross region replication okay the question was will we ever",
    "start": "3196590",
    "end": "3201910"
  },
  {
    "text": "support cross region replication I take cross region replication is like is an ass that comes up you know on multiple",
    "start": "3201910",
    "end": "3208450"
  },
  {
    "text": "database services right we just supported on dynamo we've had some other services where you know we've talked",
    "start": "3208450",
    "end": "3214750"
  },
  {
    "text": "about it so it's definitely something we're really kind of thinking about as part of feedback we're getting I can",
    "start": "3214750",
    "end": "3221170"
  },
  {
    "text": "tell you any timelines or any specific road map but it's it's good feedback and it's you know it's feedback that we've",
    "start": "3221170",
    "end": "3227530"
  },
  {
    "text": "heard anyone else have any questions can",
    "start": "3227530",
    "end": "3236350"
  },
  {
    "text": "see yeah go ahead",
    "start": "3236350",
    "end": "3239100"
  },
  {
    "text": "oh the question is that what is the maximum size for the value of redis",
    "start": "3242440",
    "end": "3247510"
  },
  {
    "text": "streams when you say value mean the overall stream or the record that's a",
    "start": "3247510",
    "end": "3252700"
  },
  {
    "text": "great question I don't know I know I know a string in Redis I think the maximum is 512 megabytes and I don't",
    "start": "3252700",
    "end": "3259750"
  },
  {
    "text": "know if that equates to where the streams that's a great question that's something I got to check out excuse me",
    "start": "3259750",
    "end": "3268109"
  },
  {
    "text": "okay yeah send me an email and I'll check it out yeah go ahead Oh",
    "start": "3268109",
    "end": "3274140"
  },
  {
    "text": "yes sir the question is is accessing ElastiCache the same as accessing Redis anywhere with for example PI Redis the",
    "start": "3283490",
    "end": "3289820"
  },
  {
    "text": "answer is yes we're compatible with all the drivers some drivers are better than others but they do work with us and we",
    "start": "3289820",
    "end": "3296930"
  },
  {
    "text": "do typically recommend for production environments you use what's called Redis cluster which is not the best name but",
    "start": "3296930",
    "end": "3303470"
  },
  {
    "text": "Redis cluster is two sharded Redis which has smart client like has smart clients",
    "start": "3303470",
    "end": "3309080"
  },
  {
    "text": "that actually figure out what the topology is and then failover is much faster and a bunch of other benefits",
    "start": "3309080",
    "end": "3315460"
  },
  {
    "text": "so for Redis cluster not all clients are equal some are better than others you",
    "start": "3315460",
    "end": "3320780"
  },
  {
    "text": "can also send me an email and I can you know make a recommendation in your preferred programming language which",
    "start": "3320780",
    "end": "3326120"
  },
  {
    "text": "client you should be using yeah go ahead",
    "start": "3326120",
    "end": "3330580"
  },
  {
    "text": "how would I compare the new ready streams with Kafka I have no idea to be",
    "start": "3331780",
    "end": "3336950"
  },
  {
    "text": "honest and I mean I would say that at the very high level I'm not a Kafka expert I mean I know Kafka okay but not",
    "start": "3336950",
    "end": "3344240"
  },
  {
    "text": "great I would tell you know Kafka is you know Kafka writes to disk right it will",
    "start": "3344240",
    "end": "3349790"
  },
  {
    "text": "support a lot more than what you can support in DRAM with ready streams it's probably as a result also gonna be a bit",
    "start": "3349790",
    "end": "3355430"
  },
  {
    "text": "slower Kafka is a very broad ecosystem right of adapters and so on so I would",
    "start": "3355430",
    "end": "3361490"
  },
  {
    "text": "say that you know my guesstimate is we're gonna see a lot of customers who use both alright so for like you know",
    "start": "3361490",
    "end": "3368900"
  },
  {
    "text": "log and lytic streaming like operation logs you'll probably use Kafka because you can you can you know you can",
    "start": "3368900",
    "end": "3376310"
  },
  {
    "text": "basically retain those logs for like 24 hours you know and make sure you can kind of you know not pay for in memory",
    "start": "3376310",
    "end": "3383420"
  },
  {
    "text": "right for all of that but then I think for a lot of these kind of interactive real-time applications where the stream",
    "start": "3383420",
    "end": "3388970"
  },
  {
    "text": "is going to be awesome and I think it's a it's at the real-time real-time level where we're gonna I",
    "start": "3388970",
    "end": "3395150"
  },
  {
    "text": "think we're going to see quite a lot of adoption of ready streams including replacing some of the things you could do in Redis before without streams like",
    "start": "3395150",
    "end": "3402890"
  },
  {
    "text": "pop sub and other patterns which may actually be more effective to do with register streams yeah a question in the",
    "start": "3402890",
    "end": "3409610"
  },
  {
    "text": "back yep",
    "start": "3409610",
    "end": "3416510"
  },
  {
    "text": "yeah okay so the question here was you know we",
    "start": "3432910",
    "end": "3439330"
  },
  {
    "text": "have a did you know we have a DNS entry for master of course but we don't like a war my sequel for example has a single",
    "start": "3439330",
    "end": "3446260"
  },
  {
    "text": "reader end point right that gives you basically all the read replicas that is something that's on our roadmap so it's",
    "start": "3446260",
    "end": "3452860"
  },
  {
    "text": "something that it's not the first time we've gotten that feedback it's something we want to make sure that happens so it is there is a blog post",
    "start": "3452860",
    "end": "3459850"
  },
  {
    "text": "section how you can work around it and build it on your own but our goal ultimately is to make sure that our service deliver a single reader",
    "start": "3459850",
    "end": "3466930"
  },
  {
    "text": "endpoints get in the back and then we'll get to you",
    "start": "3466930",
    "end": "3472170"
  },
  {
    "text": "the question was are we gonna have support for Redis modules on the roadmap and I think you know what we really are",
    "start": "3482810",
    "end": "3489320"
  },
  {
    "text": "looking for feedback on that like send me an email you know what you use cases and so on",
    "start": "3489320",
    "end": "3495230"
  },
  {
    "text": "and so forth we have seen that from some customers have had some interest in things like graph generally Neptune is a",
    "start": "3495230",
    "end": "3501050"
  },
  {
    "text": "better fit Neptune is one of my other services which is a graph database service and so you know we are thinking",
    "start": "3501050",
    "end": "3507200"
  },
  {
    "text": "about hey could be to use a canoe so stream or something and then write in to Neptune and Android and to register at the same time I do think like",
    "start": "3507200",
    "end": "3514130"
  },
  {
    "text": "purpose-built graph databases especially as graph database is very difficult to",
    "start": "3514130",
    "end": "3519170"
  },
  {
    "text": "build and you need a skill to billions of edges in many cases are probably going to be more cost effective than",
    "start": "3519170",
    "end": "3524780"
  },
  {
    "text": "doing it in Redis but we are definitely listening to kind of general feedback on Redis modules and if we get enough",
    "start": "3524780",
    "end": "3531470"
  },
  {
    "text": "feedback that certain modules are needed we'll build those modules yeah Jason is",
    "start": "3531470",
    "end": "3537890"
  },
  {
    "text": "also a nice module yeah go ahead yeah",
    "start": "3537890",
    "end": "3548380"
  },
  {
    "text": "yeah yeah so the question was are we do have any plans on improving order automatic failover we're constantly",
    "start": "3549220",
    "end": "3556270"
  },
  {
    "text": "trying to improve it both the monitoring in the auto detection and then also to fail over",
    "start": "3556270",
    "end": "3561550"
  },
  {
    "text": "time so Redis cluster gives you some benefits but it's still not sufficient right because one is the monitoring time",
    "start": "3561550",
    "end": "3567010"
  },
  {
    "text": "and then the second piece is actually to trigger the failover so that is a big area of focus of ours and I think you're",
    "start": "3567010",
    "end": "3572589"
  },
  {
    "text": "going to see us in the next few months get you know continuously better on really eliminating those gaps you know I",
    "start": "3572589",
    "end": "3581349"
  },
  {
    "text": "don't remember the exact window I think detection can depending on ec2 and you know things can take probably 30 plus",
    "start": "3581349",
    "end": "3587680"
  },
  {
    "text": "seconds but I'm throwing these numbers out without remembering the exact numbers Redis cluster itself once you",
    "start": "3587680",
    "end": "3593470"
  },
  {
    "text": "trigger to failover I think goes much faster sorry about a 20-second failover time but it really depends on the",
    "start": "3593470",
    "end": "3599500"
  },
  {
    "text": "scenario and we are working on reducing that that failover time significantly",
    "start": "3599500",
    "end": "3605380"
  },
  {
    "text": "I think we have time for one more question yeah yeah",
    "start": "3605380",
    "end": "3617010"
  },
  {
    "text": "yes I'm not the hyper log-log expert to be honest on the implementation if you send me an email I'll send you a link to",
    "start": "3621340",
    "end": "3628480"
  },
  {
    "text": "the paper also but it's basically doesn't change the functionality but I",
    "start": "3628480",
    "end": "3634030"
  },
  {
    "text": "do believe it makes it both faster and also it is more it is more accurate",
    "start": "3634030",
    "end": "3639850"
  },
  {
    "text": "especially when you merge hyper log logs together so this is kind of another kind",
    "start": "3639850",
    "end": "3645580"
  },
  {
    "text": "of significant improvement for a hyper log logs at what use case are using it for okay using it for counting okay",
    "start": "3645580",
    "end": "3657720"
  }
]
[
  {
    "start": "0",
    "end": "70000"
  },
  {
    "text": "good morning everyone thanks for joining the webinar today and we'll get started",
    "start": "60",
    "end": "5670"
  },
  {
    "text": "on time yeah my name is Ray I'm a Senior Product Manager with Amazon Web Services",
    "start": "5670",
    "end": "12000"
  },
  {
    "text": "and today co-presenting with me we have Cara Cara's a Senior Product",
    "start": "12000",
    "end": "18420"
  },
  {
    "text": "Marketing Manager with Splunk we also have David David is an SVP of technology",
    "start": "18420",
    "end": "24539"
  },
  {
    "text": "platform a true car so in today's webinar and we will have an overview of",
    "start": "24539",
    "end": "30960"
  },
  {
    "text": "all the AWS big data services and different capabilities and specifically",
    "start": "30960",
    "end": "36690"
  },
  {
    "text": "we'll go a bit deeper on the data streaming service here at Amazon Web service called Amazon Kinesis then we'll",
    "start": "36690",
    "end": "44550"
  },
  {
    "text": "have Cara give you guys some brief overview of the Splunk capability on AWS then we're gonna hand the stage to David",
    "start": "44550",
    "end": "51719"
  },
  {
    "text": "to talk about how to car is leveraging both AWS and Splunk capabilities to gain",
    "start": "51719",
    "end": "57899"
  },
  {
    "text": "insights from their data in near real-time and lastly we'll have some time to open up for Q&A sessions and as",
    "start": "57899",
    "end": "64559"
  },
  {
    "text": "we go through the webinar you can submit a question through the webinar panel ok so put your data to work with big data",
    "start": "64559",
    "end": "71520"
  },
  {
    "start": "70000",
    "end": "200000"
  },
  {
    "text": "services from AWS and Splunk first of all why should I choose AWS for my big",
    "start": "71520",
    "end": "79140"
  },
  {
    "text": "data solutions and applications first of war it's immediately available and you",
    "start": "79140",
    "end": "87420"
  },
  {
    "text": "just go to the APIs console provision the resource you want or go to leverage the service you want to use and all",
    "start": "87420",
    "end": "93329"
  },
  {
    "text": "these resources and capabilities are available to you right away so that you",
    "start": "93329",
    "end": "98790"
  },
  {
    "text": "can start building your analytics applications and solutions right away and not spending any time on any of the",
    "start": "98790",
    "end": "105750"
  },
  {
    "text": "undifferentiated heavy liftings second is the broad and deep capabilities of",
    "start": "105750",
    "end": "110909"
  },
  {
    "text": "AWS big data services from the next slide you'll see we have a pro set of",
    "start": "110909",
    "end": "116070"
  },
  {
    "text": "services that give you different capabilities from storage analytics visualization data import real-time",
    "start": "116070",
    "end": "123600"
  },
  {
    "text": "streaming and etc and third of course data security is super important because",
    "start": "123600",
    "end": "130050"
  },
  {
    "text": "you're leveraging AWS to analyze and store critical data and of your business and",
    "start": "130050",
    "end": "135420"
  },
  {
    "text": "at AWS we spend a lot of energy and resource on security so that we make",
    "start": "135420",
    "end": "141060"
  },
  {
    "text": "sure when you leverage database platform your data is securely stored and analyzed only by you and lastly which is",
    "start": "141060",
    "end": "149010"
  },
  {
    "text": "super important as well is scalability so as you gain scale with your business",
    "start": "149010",
    "end": "155190"
  },
  {
    "text": "your data falling is gonna go up and if you choose to use AWS all of these Big",
    "start": "155190",
    "end": "160590"
  },
  {
    "text": "Data Services are designed for very large scale so as you scale your business your data platform you do not",
    "start": "160590",
    "end": "167250"
  },
  {
    "text": "need to redo your solution so friendly very beginning you've set ups for the success for the long term data growth",
    "start": "167250",
    "end": "173550"
  },
  {
    "text": "and as I mentioned previously abs we have a broader range of different services for you to collect your data",
    "start": "173550",
    "end": "179730"
  },
  {
    "text": "store your data and analyze your data for an open source framework like Amazon",
    "start": "179730",
    "end": "185070"
  },
  {
    "text": "EMR from servitors compute like lambda data streaming like Kinesis and different set of storage services based",
    "start": "185070",
    "end": "192420"
  },
  {
    "text": "on your storage requirement we have s3 we have glacier we have elastic file",
    "start": "192420",
    "end": "197850"
  },
  {
    "text": "system and etc and today's focus I want to take a bit deeper into streaming data",
    "start": "197850",
    "end": "204720"
  },
  {
    "start": "200000",
    "end": "305000"
  },
  {
    "text": "service Amazon Kinesis so first of all what is streaming data streaming data is really referring to the type of data",
    "start": "204720",
    "end": "211680"
  },
  {
    "text": "that is continuously being produced and generated and it turns out vast majority",
    "start": "211680",
    "end": "218820"
  },
  {
    "text": "of the data in the world today they are being generated continuously for example",
    "start": "218820",
    "end": "224040"
  },
  {
    "text": "if you have a mobile application your user interaction there with your app is generated continuously so does web click",
    "start": "224040",
    "end": "231570"
  },
  {
    "text": "stream as your user your customers go to your website and click on your website all these events are generated",
    "start": "231570",
    "end": "237660"
  },
  {
    "text": "continuously your log data is not a big one all the application servers web",
    "start": "237660",
    "end": "243000"
  },
  {
    "text": "servers they're writing log data to local server in real time and continuously and also meeting records a",
    "start": "243000",
    "end": "249870"
  },
  {
    "text": "good example will be AWS so as our customers use elevated resources we",
    "start": "249870",
    "end": "254970"
  },
  {
    "text": "continuously meter the usage and calculate a bill for our customers and then our tea use case another big one or",
    "start": "254970",
    "end": "262860"
  },
  {
    "text": "the Audi sensors small buildings these data are general continuously but oftentimes",
    "start": "262860",
    "end": "268880"
  },
  {
    "text": "traditionally we see customers analyze these data in a bachelor anyway it's not",
    "start": "268880",
    "end": "275340"
  },
  {
    "text": "because these data not naturally generated continuously it's because we only have this bachelor and a tool and",
    "start": "275340",
    "end": "282270"
  },
  {
    "text": "to start with but now things have changed we start seeing a lot more",
    "start": "282270",
    "end": "287280"
  },
  {
    "text": "attraction law at more evolvement in streaming there are technologies which enable our customers to collect analyze",
    "start": "287280",
    "end": "294000"
  },
  {
    "text": "data in real time then why should I do that why should I care about it because",
    "start": "294000",
    "end": "299070"
  },
  {
    "text": "it has been working fine for our business use cases so far why should I care about it well the real reason is",
    "start": "299070",
    "end": "305460"
  },
  {
    "text": "simply explained by this very simple graph because this is diminishing value of theta over time so as time goes on",
    "start": "305460",
    "end": "313410"
  },
  {
    "text": "the value can generate out of your data goes down dramatically so for example we",
    "start": "313410",
    "end": "319350"
  },
  {
    "text": "say you run a web server and all of sudden you're hitting a website issue when your developers log on to your",
    "start": "319350",
    "end": "327240"
  },
  {
    "text": "logging server you want to make sure he can see that mo whose recent law data right away so that he can start",
    "start": "327240",
    "end": "333420"
  },
  {
    "text": "troubleshooting that fix the issue and in the traditional bachelor in a way you might have minutes or even hours of",
    "start": "333420",
    "end": "340170"
  },
  {
    "text": "delay so that really impacts the way you can leverage these data and gain value",
    "start": "340170",
    "end": "345390"
  },
  {
    "text": "out of these data and so we talked about you know real-time processing what are some of the core requirements and",
    "start": "345390",
    "end": "352130"
  },
  {
    "start": "347000",
    "end": "463000"
  },
  {
    "text": "elements for real-time streaming they're a pipeline so first capability you gotta",
    "start": "352130",
    "end": "357840"
  },
  {
    "text": "have to figure out a way to ingest these data continuously at very large scale",
    "start": "357840",
    "end": "362960"
  },
  {
    "text": "secondly a lot of data is generated in a very raw form you gotta have to transform the data into a particular",
    "start": "362960",
    "end": "370820"
  },
  {
    "text": "machine understandable way or with a particular schema so that you can analyze them later on and once you",
    "start": "370820",
    "end": "377400"
  },
  {
    "text": "analyze the data figure out a pattern you need a way to react to that data in real time then oftentimes afterwards you",
    "start": "377400",
    "end": "384750"
  },
  {
    "text": "also want to possess the data the streaming data for long-term storage and later on for historical analysis so we",
    "start": "384750",
    "end": "391650"
  },
  {
    "text": "really see a streaming data as complementary to the traditional",
    "start": "391650",
    "end": "396750"
  },
  {
    "text": "bachelor and ER data analytics so this way you can gain in in real-time take real-time reactions",
    "start": "396750",
    "end": "402749"
  },
  {
    "text": "and at the same time store these data for long-term analysis as you always have been doing and what are the key",
    "start": "402749",
    "end": "409770"
  },
  {
    "text": "requirements for streaming they're a pipeline like this first of all you gotta make sure data is durable so that",
    "start": "409770",
    "end": "415649"
  },
  {
    "text": "you never lose any critical business data second and third it has to be",
    "start": "415649",
    "end": "421050"
  },
  {
    "text": "continuous and fast because as I mentioned the whole value proposition of a streaming data pipeline is you're able",
    "start": "421050",
    "end": "427139"
  },
  {
    "text": "to react to the data quick enough in real time and be able to continuously",
    "start": "427139",
    "end": "432569"
  },
  {
    "text": "process them another three elements correct reactive and reliable these are",
    "start": "432569",
    "end": "437729"
  },
  {
    "text": "very common requirements and elements for data analysis part I probably gotta",
    "start": "437729",
    "end": "443459"
  },
  {
    "text": "have to make sure the result is correct you gotta have to make sure it's consistent and reliable you'll always produce the same results by popping",
    "start": "443459",
    "end": "450659"
  },
  {
    "text": "through the same data and the same logic and also it has to be reactive because it's in the real time case you wanted to",
    "start": "450659",
    "end": "458099"
  },
  {
    "text": "analyze it there in real time because you gotta have to react to the data in real time at a double yes we have Amazon",
    "start": "458099",
    "end": "464879"
  },
  {
    "start": "463000",
    "end": "599000"
  },
  {
    "text": "Kinesis services and these are set of services that offers different streaming",
    "start": "464879",
    "end": "470159"
  },
  {
    "text": "data analysis capabilities today we have three services under Amazon Kinesis the",
    "start": "470159",
    "end": "476639"
  },
  {
    "text": "first one is called Kansas Dreams it stores your data as a replayable",
    "start": "476639",
    "end": "481709"
  },
  {
    "text": "continuous data stream that enables you to write your own applications to",
    "start": "481709",
    "end": "486809"
  },
  {
    "text": "process and analyze these data you can use the Kinesis client library which is",
    "start": "486809",
    "end": "492389"
  },
  {
    "text": "an abstraction layer for you to process the streaming data out of Kinesis stream you can also use Erebus lanta function",
    "start": "492389",
    "end": "499649"
  },
  {
    "text": "you can use spark different kind of tools of your choice the second service",
    "start": "499649",
    "end": "505559"
  },
  {
    "text": "is called Kinesis firehose it loads the streaming data into different destinations such as s3 redshift and",
    "start": "505559",
    "end": "513089"
  },
  {
    "text": "elastic search service so what firehose service allows you to do is you can configure a data producers",
    "start": "513089",
    "end": "520050"
  },
  {
    "text": "to continuously push in the data to the service and then the data will be continuously delivering to these",
    "start": "520050",
    "end": "526199"
  },
  {
    "text": "different destinations so the benefit of the service is you still use the tool you've always been using like a data",
    "start": "526199",
    "end": "533010"
  },
  {
    "text": "warehouse a search engine or visualization tools but but in this case instead of waiting for the",
    "start": "533010",
    "end": "539870"
  },
  {
    "text": "data to show up on an hourly or daily basis you get to have the data and make them accessible continuously with",
    "start": "539870",
    "end": "546680"
  },
  {
    "text": "minutes and even seconds latency the third service called Kinesis analytics it allows you to use a standard or",
    "start": "546680",
    "end": "553970"
  },
  {
    "text": "sequel statement to query again against the data stream the key difference between Seco engine on top of the data",
    "start": "553970",
    "end": "562459"
  },
  {
    "text": "stream mmm versus say a traditional data warehouse or a storage system is that you will be able to query the data much",
    "start": "562459",
    "end": "569839"
  },
  {
    "text": "faster often with milliseconds or seconds latency and second it's a",
    "start": "569839",
    "end": "575209"
  },
  {
    "text": "continuous time window because as you can imagine as a data continuously coming in it's actually a dynamic data",
    "start": "575209",
    "end": "582230"
  },
  {
    "text": "stream the time keeps changing so in this case the sequel action allows you",
    "start": "582230",
    "end": "587779"
  },
  {
    "text": "to do a sliding window tumbling tumbling window so it'll be a continuous query",
    "start": "587779",
    "end": "593720"
  },
  {
    "text": "and the time window then you're gonna specifying the Seco will keep moving forward with the time so as I mentioned",
    "start": "593720",
    "end": "600410"
  },
  {
    "text": "this is a typical data flow for Canisius streams you configure your data producers push the data into the Kinesis",
    "start": "600410",
    "end": "608240"
  },
  {
    "text": "stream service it'll store the data in a streaming manner if durably and reliably then on the other side you can use the",
    "start": "608240",
    "end": "615470"
  },
  {
    "text": "tool of your choice to write your processing logic to process the data and react to the data in real-time Kinesis",
    "start": "615470",
    "end": "623060"
  },
  {
    "text": "firehose on the left hand side it's fairly similar to Kinesis streams you configure data producers being mobile",
    "start": "623060",
    "end": "630529"
  },
  {
    "text": "devices web servers ECT instances applications to push data to the service",
    "start": "630529",
    "end": "635930"
  },
  {
    "text": "on the other side it'll push the data into different destinations and a few",
    "start": "635930",
    "end": "641600"
  },
  {
    "text": "weeks back we were pretty excited announced that Splunk is going to be a supported natively supported this nation",
    "start": "641600",
    "end": "648140"
  },
  {
    "text": "for firehose delivery and this new feature fire-hosed whose Splunk is now",
    "start": "648140",
    "end": "653149"
  },
  {
    "text": "in beta so if you guys are interesting and testing and trying out this feature in the end of this webinar we'll have a",
    "start": "653149",
    "end": "660529"
  },
  {
    "text": "link for sign up for this better access Kinesis analytics as i mentioned you",
    "start": "660529",
    "end": "665959"
  },
  {
    "text": "know it's a sequin john ruskin continuously query against the data stream you can attach kinesins analytics",
    "start": "665959",
    "end": "672289"
  },
  {
    "text": "applications against the Kinesis stream or Kinesis firehose then on the other side we can emit the result in two",
    "start": "672289",
    "end": "678589"
  },
  {
    "text": "different data storage or the real-time dashboard you can also trigger a lambda function for real-time reaction to the",
    "start": "678589",
    "end": "686089"
  },
  {
    "text": "analysis result for example what you can do is to count your number of error",
    "start": "686089",
    "end": "691849"
  },
  {
    "text": "messages that got triggered by your application and if it breached a certain threshold you can trigger a lambda",
    "start": "691849",
    "end": "698299"
  },
  {
    "text": "function you can send notification center alarm or even shut down the application or resize the cluster and",
    "start": "698299",
    "end": "704839"
  },
  {
    "text": "etc so Kinesis has been in the market for 3 years we've seen adoption across",
    "start": "704839",
    "end": "710529"
  },
  {
    "start": "705000",
    "end": "730000"
  },
  {
    "text": "different segments for an enterprise customers to start up using four different industries from media to IOT",
    "start": "710529",
    "end": "718159"
  },
  {
    "text": "to retail and of course TrueCar is a longtime customer of Kinesis and david",
    "start": "718159",
    "end": "724009"
  },
  {
    "text": "later on will have a deeper and discussion about how TrueCar is leveraging Kinesis and its plant",
    "start": "724009",
    "end": "729529"
  },
  {
    "text": "services alright given that I'll hand over to Kara to talk a little bit but about the",
    "start": "729529",
    "end": "735289"
  },
  {
    "start": "730000",
    "end": "765000"
  },
  {
    "text": "Splunk capability for big data Kara I'm in product marketing at Splunk and today",
    "start": "735289",
    "end": "742129"
  },
  {
    "text": "I hope that there are three things that you take away from my section one is what Splunk does and the kinds of",
    "start": "742129",
    "end": "749239"
  },
  {
    "text": "problems that it solves the second is what makes Splunk different and how it's",
    "start": "749239",
    "end": "754549"
  },
  {
    "text": "super valuable to your business or how it could be and also how Splunk an AWS",
    "start": "754549",
    "end": "759709"
  },
  {
    "text": "work together for our customers to be successful like TrueCar so if i just take a step back we're all aware that",
    "start": "759709",
    "end": "766399"
  },
  {
    "text": "there has been an explosion of growth of IT data center technologies so with the advent of you know the Internet of",
    "start": "766399",
    "end": "772579"
  },
  {
    "text": "Things mobile apps and virtualization just to name a few there's been an increased efficiency and utilization in",
    "start": "772579",
    "end": "779419"
  },
  {
    "text": "those technologies but with that also increased IT complexity and as ray mentioned all of those streaming data",
    "start": "779419",
    "end": "785720"
  },
  {
    "text": "sources there's just a lot going on and so with that increased complexity there",
    "start": "785720",
    "end": "790939"
  },
  {
    "start": "788000",
    "end": "817000"
  },
  {
    "text": "are lots of disparate and silo based solutions and more often than not that leads to war rooms turning to",
    "start": "790939",
    "end": "797209"
  },
  {
    "text": "finger-pointing and teams can spend hours and hours trying to bug an issue because information is",
    "start": "797209",
    "end": "804170"
  },
  {
    "text": "sequestered in silos and all these issues lead to IT spending less time innovating and more time just keeping",
    "start": "804170",
    "end": "811309"
  },
  {
    "text": "the lights on so you might be wondering ok cool how to Splunk help with that so spunk if you're not familiar is the",
    "start": "811309",
    "end": "818959"
  },
  {
    "start": "817000",
    "end": "905000"
  },
  {
    "text": "leading platform for machine data it digests all machine data so anything",
    "start": "818959",
    "end": "824540"
  },
  {
    "text": "from AWS data sources and services to servers and network whether it's",
    "start": "824540",
    "end": "830149"
  },
  {
    "text": "on-premises or in the cloud and Splunk enables you to then quickly analyze that data and rapidly obtain insight from it",
    "start": "830149",
    "end": "837559"
  },
  {
    "text": "Splunk collects machine data securely and reliably from wherever it's generated and in any format and it does",
    "start": "837559",
    "end": "845329"
  },
  {
    "text": "this by storing and indexing the data in real time in a centralized location and protecting it with role based access",
    "start": "845329",
    "end": "851569"
  },
  {
    "text": "controls and our platform was designed around the premise of being able to consume any type of machine data even if",
    "start": "851569",
    "end": "859790"
  },
  {
    "text": "the format changes which is something a relational database cannot achieve so you can monitor both real-time as the",
    "start": "859790",
    "end": "866959"
  },
  {
    "text": "data is streaming and historical data and you can have many lenses to the same data for basically any use case that you",
    "start": "866959",
    "end": "874459"
  },
  {
    "text": "can think of enabling Splunk software to turn all of that data into answers to",
    "start": "874459",
    "end": "879620"
  },
  {
    "text": "the questions that you might have for example you can troubleshoot your network problems and investigate",
    "start": "879620",
    "end": "885860"
  },
  {
    "text": "security incidents in minutes not hours or days and you can monitor your end-to-end infrastructure to avoid",
    "start": "885860",
    "end": "892519"
  },
  {
    "text": "service degradation or outages and you can gain real-time visibility and",
    "start": "892519",
    "end": "897620"
  },
  {
    "text": "critical insights into your customer experience such as your transactions and your customers behavior so there are a",
    "start": "897620",
    "end": "905179"
  },
  {
    "start": "905000",
    "end": "952000"
  },
  {
    "text": "couple things that makes Punk different for example Splunk s-- real-time architecture fast time to value and the",
    "start": "905179",
    "end": "912049"
  },
  {
    "text": "ability to scale from you know just your desktop for one user to the most complex",
    "start": "912049",
    "end": "917329"
  },
  {
    "text": "data centers or cloud environments really differentiates Splunk to our 14,000 plus customers and these",
    "start": "917329",
    "end": "924079"
  },
  {
    "text": "differentiators lead to real business impact they save our customers time when resolving an",
    "start": "924079",
    "end": "929870"
  },
  {
    "text": "issue they help our customers improve user experience and we",
    "start": "929870",
    "end": "935630"
  },
  {
    "text": "a lot of cost savings and greater productivity so that our customers don't",
    "start": "935630",
    "end": "940640"
  },
  {
    "text": "spend as much time just worrying about managing their environment and making sure that they have uptime but they can",
    "start": "940640",
    "end": "946430"
  },
  {
    "text": "actually innovate and become more productive and whatever it is that they're trying to accomplish for the business so when we say we enable you to",
    "start": "946430",
    "end": "953960"
  },
  {
    "start": "952000",
    "end": "990000"
  },
  {
    "text": "get data from anywhere we really mean it we offer a range of plugins templates",
    "start": "953960",
    "end": "959750"
  },
  {
    "text": "and full-fledged apps that are available to help you collect analyze and harness data from every layer of your technology",
    "start": "959750",
    "end": "966590"
  },
  {
    "text": "stack so even if you're using a product that's not listed here Splunk still does",
    "start": "966590",
    "end": "971870"
  },
  {
    "text": "not limit you you can still index data from that technology and one of the key benefits of using slow software and",
    "start": "971870",
    "end": "978620"
  },
  {
    "text": "cloud services is the ability to correlate machine data across silos providing visibility across the entire",
    "start": "978620",
    "end": "984830"
  },
  {
    "text": "application delivering an IT operations landscape and so for the purposes of this talk I wanted to delve a little",
    "start": "984830",
    "end": "991310"
  },
  {
    "start": "990000",
    "end": "1128000"
  },
  {
    "text": "deeper into slow cloud which is what TrueCar is currently using and Splunk cloud delivers the benefits of Smoak",
    "start": "991310",
    "end": "997730"
  },
  {
    "text": "enterprise which is the easiest way to aggregate analyze and get answers from your machine data but it's deployed and",
    "start": "997730",
    "end": "1004180"
  },
  {
    "text": "managed securely reliably and scale ibly as a service so smoke cloud there are a",
    "start": "1004180",
    "end": "1009520"
  },
  {
    "text": "couple things to remember about it one it's a SAS service our customers can subscribe to too it is owned and managed",
    "start": "1009520",
    "end": "1017770"
  },
  {
    "text": "by Splunk the architecture and it's a service and three it's already set up",
    "start": "1017770",
    "end": "1023770"
  },
  {
    "text": "and ready to go on purchase it's available once a customer forwards data this one cloud and there are a couple",
    "start": "1023770",
    "end": "1030310"
  },
  {
    "text": "things that really differentiates one cloud it offers the fastest time to value so you can get to go live very",
    "start": "1030310",
    "end": "1037449"
  },
  {
    "text": "quickly in as early as two days eliminating infrastructure requirements and enabling you to save money or time",
    "start": "1037449",
    "end": "1044620"
  },
  {
    "text": "on servers storage and people it minimizes the delays and change management processes for upgrades and",
    "start": "1044620",
    "end": "1051850"
  },
  {
    "text": "your employees don't have to worry about the plumbing so they can focus on building data automation dashboards",
    "start": "1051850",
    "end": "1058030"
  },
  {
    "text": "reporting and alerts it also enables you to expand your Splunk deployment quite",
    "start": "1058030",
    "end": "1063220"
  },
  {
    "text": "quickly so as you scale we offer a one terabyte incremental capacity available within two days",
    "start": "1063220",
    "end": "1069520"
  },
  {
    "text": "and of course you can operate premium Splunk solutions like Splunk IT service intelligence and enterprise security at",
    "start": "1069520",
    "end": "1076270"
  },
  {
    "text": "the highest level of maturity and availability within weeks and of course I think everybody cares about this last",
    "start": "1076270",
    "end": "1083320"
  },
  {
    "text": "one the most small cloud offers a total low cost of ownership often less than the cost of running smoke on your own",
    "start": "1083320",
    "end": "1089110"
  },
  {
    "text": "and there are 400 plus lunk base apps ready for small cloud deployments with",
    "start": "1089110",
    "end": "1094540"
  },
  {
    "text": "ready to use analytics alerts dashboards and visualizations and I always like to",
    "start": "1094540",
    "end": "1100720"
  },
  {
    "text": "tell people that's one cloud adheres to very rigorous security standards something that we take very seriously it's lunk so just to avoid confusion",
    "start": "1100720",
    "end": "1108850"
  },
  {
    "text": "what's one cloud is not Splunk is not a customer running their own spunk license",
    "start": "1108850",
    "end": "1114100"
  },
  {
    "text": "on AWS which would be a bring your own license that is not what's one cloud is it is not a customer managing your own",
    "start": "1114100",
    "end": "1120400"
  },
  {
    "text": "architecture and it is not a customer who is responsible for installation and setup because one takes care of it for",
    "start": "1120400",
    "end": "1127240"
  },
  {
    "text": "you so a couple of things I wanted to highlight about how Splunk and EWS work together in conjunction with AWS Splunk",
    "start": "1127240",
    "end": "1134200"
  },
  {
    "text": "developed an app and an add-on for AWS and the app in the add-on for AWS helped",
    "start": "1134200",
    "end": "1139720"
  },
  {
    "text": "you gain end-to-end visibility across your AWS environment helping you to move",
    "start": "1139720",
    "end": "1144820"
  },
  {
    "text": "your mission critical workloads to AWS with agility security and of course",
    "start": "1144820",
    "end": "1150280"
  },
  {
    "text": "confidence so the difference is that Splunk add-on for AWS gets your data",
    "start": "1150280",
    "end": "1155490"
  },
  {
    "text": "from AWS into Splunk while the Splunk app for AWS provides users with dashboards",
    "start": "1155490",
    "end": "1162100"
  },
  {
    "text": "visualizations and alerts right out of the box and the Splunk app offers a rich",
    "start": "1162100",
    "end": "1167350"
  },
  {
    "text": "set of pre-built dashboards and reports that help you analyze and visualize data from numerous AWS services and data",
    "start": "1167350",
    "end": "1173590"
  },
  {
    "text": "sources including AWS cloud trail AWS config config rules Amazon inspector",
    "start": "1173590",
    "end": "1180760"
  },
  {
    "text": "Amazon RDS Amazon Cloud watch Amazon BBC flow logs s3 ec2 cloud front yes PLB",
    "start": "1180760",
    "end": "1189370"
  },
  {
    "text": "billing and that's all just from a single free app that we offer with your license and there are several ways to",
    "start": "1189370",
    "end": "1196630"
  },
  {
    "text": "use the app including for security for operations and for cost management for",
    "start": "1196630",
    "end": "1202120"
  },
  {
    "text": "example for opera you can visualize your entire AWS environment you can view resource",
    "start": "1202120",
    "end": "1207640"
  },
  {
    "text": "relationships you can gain a playback history and for security you have full",
    "start": "1207640",
    "end": "1213880"
  },
  {
    "text": "view of user activity you can gain a full audit trail and detect anomalous behavior and of course for cost",
    "start": "1213880",
    "end": "1221799"
  },
  {
    "text": "management very importantly you can gain a view into your resource costs you can",
    "start": "1221799",
    "end": "1226870"
  },
  {
    "text": "improve planning and utilization and you can actually monitor spend verse forecasts so it's very powerful and",
    "start": "1226870",
    "end": "1234520"
  },
  {
    "text": "we're very happy to work with the AWS on that app but that's not the only way to",
    "start": "1234520",
    "end": "1239590"
  },
  {
    "start": "1239000",
    "end": "1287000"
  },
  {
    "text": "get data into AWS as ray mentioned we have the Kinesis firehose integration we",
    "start": "1239590",
    "end": "1244630"
  },
  {
    "text": "just launched a couple weeks ago and as you can see on the slides Lunken just a plethora of AWS data sources and",
    "start": "1244630",
    "end": "1251260"
  },
  {
    "text": "services to help you meet your toughest IT security and application delivery",
    "start": "1251260",
    "end": "1256890"
  },
  {
    "text": "challenges one of our newest integrations is the Kinesis firehose which streams data right into Splunk",
    "start": "1256890",
    "end": "1264220"
  },
  {
    "text": "from amazon Kinesis stream AWS iot data amazon cloud watch blogs and events and",
    "start": "1264220",
    "end": "1271890"
  },
  {
    "text": "we are really excited about our ever expanding integrations with AWS but I",
    "start": "1271890",
    "end": "1277900"
  },
  {
    "text": "want to now hand it over to David to talk a little bit about how they use Splunk cloud in AWS a TrueCar including",
    "start": "1277900",
    "end": "1285220"
  },
  {
    "text": "his use of Kinesis for logging thank you Karen and ray now let me jump in here so",
    "start": "1285220",
    "end": "1291669"
  },
  {
    "start": "1287000",
    "end": "1743000"
  },
  {
    "text": "I'm David Geffen SVP of the technology platform so my team's basically enable",
    "start": "1291669",
    "end": "1297760"
  },
  {
    "text": "all of our developers here at TrueCar to basically build an automotive marketplace everything that sits on top",
    "start": "1297760",
    "end": "1305740"
  },
  {
    "text": "of AWS my team's basically are the interface into that so historically we",
    "start": "1305740",
    "end": "1311950"
  },
  {
    "text": "came from a world where we actually had a data center and we're doing basically a migration to get out of the data",
    "start": "1311950",
    "end": "1318730"
  },
  {
    "text": "center and into the cloud and so the data center inherently had lots and lots of logs it was you know full of logs",
    "start": "1318730",
    "end": "1325510"
  },
  {
    "text": "that were you know going basically nowhere when we first showed up here and",
    "start": "1325510",
    "end": "1330730"
  },
  {
    "text": "so we decided to go through this whole log consolidation effort to try to get a platform that that would actually allow us to",
    "start": "1330730",
    "end": "1337580"
  },
  {
    "text": "visualize logs and aggregate them so initially we get that with the use of of",
    "start": "1337580",
    "end": "1343280"
  },
  {
    "text": "Kafka and so Kafka would stream out and and all the data sent along as we go",
    "start": "1343280",
    "end": "1348980"
  },
  {
    "text": "through that but as we were doing the migration into AWS we wanted to just to",
    "start": "1348980",
    "end": "1354260"
  },
  {
    "text": "basically look at the various technologies that AWS had to offer such as Kinesis and then also sort of",
    "start": "1354260",
    "end": "1360200"
  },
  {
    "text": "standardize the way that our applications talk to the logging service so as we did the migration we looked at",
    "start": "1360200",
    "end": "1368270"
  },
  {
    "text": "some of the newer technologies like docker and said okay well if we're gonna leverage docker what's the right way to",
    "start": "1368270",
    "end": "1373960"
  },
  {
    "text": "basically have docker send logs out and so with docker you can actually just log",
    "start": "1373960",
    "end": "1380240"
  },
  {
    "text": "to standard out and standard error those end up getting processed by the docker daemon and then we can basically take",
    "start": "1380240",
    "end": "1387470"
  },
  {
    "text": "all those log messages and then ship them off into Kinesis so it ended up",
    "start": "1387470",
    "end": "1392810"
  },
  {
    "text": "being a very straightforward and easy way to basically ship logs around the",
    "start": "1392810",
    "end": "1400100"
  },
  {
    "text": "other thing that we said is that we also wanted to get a standard logging format I know most logs end up just being a log",
    "start": "1400100",
    "end": "1405710"
  },
  {
    "text": "line you're basically writing a message to yourself like hey something like oh but we wanted to be a little more clever",
    "start": "1405710",
    "end": "1412910"
  },
  {
    "text": "there and actually put the logs into a JSON format so that we could have basically key value pairs that",
    "start": "1412910",
    "end": "1420160"
  },
  {
    "text": "represented the various data within the logs so we did all of that as sort of a prep work to really kind of get their",
    "start": "1420160",
    "end": "1426890"
  },
  {
    "text": "logs into like a format that's common across all applications before so in our",
    "start": "1426890",
    "end": "1432530"
  },
  {
    "text": "previous solution we were doing everything with Elkin so I mentioned you know we had basically Kafka coming in",
    "start": "1432530",
    "end": "1438340"
  },
  {
    "text": "elkwood basically you know aggregate all of the logs that we had but this was an",
    "start": "1438340",
    "end": "1444980"
  },
  {
    "text": "in-house solution that we had to basically maintain we had a team of people that would constantly be sort of",
    "start": "1444980",
    "end": "1451870"
  },
  {
    "text": "putting ELQ back up you know once it would follow what once it had fallen over had become unresponsive and there",
    "start": "1451870",
    "end": "1459890"
  },
  {
    "text": "weren't any third-party integrations right it didn't integrate with Nero like",
    "start": "1459890",
    "end": "1465200"
  },
  {
    "text": "it didn't integrate with any of the other sort of tooling that we had around you know the various metrics and",
    "start": "1465200",
    "end": "1472270"
  },
  {
    "text": "application metrics that we have so he started to look around and you know and came across Splunk and so if you look at",
    "start": "1472270",
    "end": "1479890"
  },
  {
    "text": "Splunk cloud and the way that we integrate with it so we have a legacy data center I mentioned Koster again",
    "start": "1479890",
    "end": "1485350"
  },
  {
    "text": "what we end up doing is taking that Kafka screen actually streaming it back into Kinesis then there's a land ajob",
    "start": "1485350",
    "end": "1492160"
  },
  {
    "text": "that basically puts it down into cases fire hose and then shoves it off to cold storage and the reason we do this is",
    "start": "1492160",
    "end": "1498549"
  },
  {
    "text": "because we want to make sure that our logs aren't ever tampered with if the attacker did come in and let's say they",
    "start": "1498549",
    "end": "1504549"
  },
  {
    "text": "compromised Splunk our hoping that ever happens but if they did you know we still have a backup of whatever logs are",
    "start": "1504549",
    "end": "1511330"
  },
  {
    "text": "there and we can actually go to that you know cold storage and actually see them so we actually we actually shipped the",
    "start": "1511330",
    "end": "1517299"
  },
  {
    "text": "logs to two different separate AWS accounts to make sure that nobody ever campers with them we also have the cloud",
    "start": "1517299",
    "end": "1524200"
  },
  {
    "text": "watch events that are coming back in the other way and then every new app the so",
    "start": "1524200",
    "end": "1529510"
  },
  {
    "text": "that logging infrastructure that told you about with the docker daemon all of those flow directly into Kinesis and",
    "start": "1529510",
    "end": "1534580"
  },
  {
    "text": "then into spawn if you have the lambda jobs so we're looking forward to the new Kinesis firehose integration because",
    "start": "1534580",
    "end": "1540460"
  },
  {
    "text": "that'll reduce some of the complexity that we have in our overall logging architecture at the moment so",
    "start": "1540460",
    "end": "1545770"
  },
  {
    "text": "implementing spud cloud was actually super simple we use octa for login Federation that allows every employee at",
    "start": "1545770",
    "end": "1554110"
  },
  {
    "text": "TrueCar to basically have access into Splunk we leverage the have reef order",
    "start": "1554110",
    "end": "1559620"
  },
  {
    "text": "via lambda to basically get those Canisius streams out and then into spawn",
    "start": "1559620",
    "end": "1564669"
  },
  {
    "text": "cloud and then there was some instances where you know we had some black holes in the in the data center and so we were",
    "start": "1564669",
    "end": "1571510"
  },
  {
    "text": "able to use some of the you know the other Universal forwarders and that sort of thing in the data center to get access into those sort of black holes",
    "start": "1571510",
    "end": "1578110"
  },
  {
    "text": "and logging all in all sport has just a well-rounded set of tools to get your",
    "start": "1578110",
    "end": "1583900"
  },
  {
    "text": "data out into spoink clouds that's it's it's a very very useful tool set so you",
    "start": "1583900",
    "end": "1589240"
  },
  {
    "text": "know we've had lots of success we've actually you know as soon as we had Splunk enabled our security team went out",
    "start": "1589240",
    "end": "1595360"
  },
  {
    "text": "created dashboards I'll show them to you a little bit later we did integrations with our AWS billing we were able to",
    "start": "1595360",
    "end": "1603640"
  },
  {
    "text": "integrate with New Relic and there's just a just a whole lot of data that now we have visibility into an aggregation",
    "start": "1603640",
    "end": "1610810"
  },
  {
    "text": "and which we didn't have before and it's really allowed us to to one feel a",
    "start": "1610810",
    "end": "1616870"
  },
  {
    "text": "little bit more comfortable with our security we're able to you know see when things go sideways we're able to iterate",
    "start": "1616870",
    "end": "1623530"
  },
  {
    "text": "quicker on our development and it's really just been a great tool and also just the fact that we don't have to",
    "start": "1623530",
    "end": "1629680"
  },
  {
    "text": "carry the burden of operating any of this infrastructure so here's what the",
    "start": "1629680",
    "end": "1635020"
  },
  {
    "text": "security team built out really quickly so this is basically authentication",
    "start": "1635020",
    "end": "1640810"
  },
  {
    "text": "insights you can actually kind of go and see how many successful login attempts we have see how many failed login",
    "start": "1640810",
    "end": "1646420"
  },
  {
    "text": "attempts and this is through the integration with octa and here's where now you can drill in and you can see",
    "start": "1646420",
    "end": "1651970"
  },
  {
    "text": "from a given IP address these are the number of failures that have happened and also what browsers and and and",
    "start": "1651970",
    "end": "1659590"
  },
  {
    "text": "really kind of dive in and see if if there is a specific IP address that maybe we need to basically block at our",
    "start": "1659590",
    "end": "1666700"
  },
  {
    "text": "firewall we also have the integration with New Relic going so you can see here's all of our applications and and",
    "start": "1666700",
    "end": "1672490"
  },
  {
    "text": "their overall apdex score if an application does go sideways you we have",
    "start": "1672490",
    "end": "1677830"
  },
  {
    "text": "a dashboard that represents that you can actually see see it turn red and then we can dive in quickly and and fix those",
    "start": "1677830",
    "end": "1684070"
  },
  {
    "text": "things we've integrated it with our Jenkins build jobs so every time our applications build you can actually see",
    "start": "1684070",
    "end": "1691000"
  },
  {
    "text": "whether the build failed or passed within a spark and then we've also integrated with our internal build tools",
    "start": "1691000",
    "end": "1697990"
  },
  {
    "text": "so spacepods is a tool that allows any developer at true cards to basically",
    "start": "1697990",
    "end": "1703270"
  },
  {
    "text": "come in and get their own version of TrueCar and so what we do is we use",
    "start": "1703270",
    "end": "1708400"
  },
  {
    "text": "terraform to allow infrastructure as code so that we're actually spinning up the whole entire AWS ecosystem",
    "start": "1708400",
    "end": "1715810"
  },
  {
    "text": "everything from RDS to the databases to the caching so all of that",
    "start": "1715810",
    "end": "1720820"
  },
  {
    "text": "infrastructure is actually defined as code and then spacepods will go out and deploy that for you so here you can see",
    "start": "1720820",
    "end": "1726730"
  },
  {
    "text": "where people are spinning up a pod their own instance of TrueCar and you can see how many have been creative pods",
    "start": "1726730",
    "end": "1732610"
  },
  {
    "text": "typically get destroyed within 24 hours so you can see the or history and everything else here so",
    "start": "1732610",
    "end": "1738269"
  },
  {
    "text": "with that I'm going to turn it back to Ray he's gonna lead us to the end thank you David and Cara so um as I mentioned",
    "start": "1738269",
    "end": "1746249"
  },
  {
    "start": "1743000",
    "end": "1985000"
  },
  {
    "text": "that here are a few resources for you guys to get started after this session the first link show up on the screen is",
    "start": "1746249",
    "end": "1753779"
  },
  {
    "text": "the better sign up link with a feature for using Kinesis firehose to stream",
    "start": "1753779",
    "end": "1758879"
  },
  {
    "text": "data being AWS they turn on ma WS data in real time into his plant cluster in",
    "start": "1758879",
    "end": "1764639"
  },
  {
    "text": "his link and if a interesting bit of testing this future get early access and you can go ahead and fill up the form",
    "start": "1764639",
    "end": "1770700"
  },
  {
    "text": "will send out invitation from time to time and the second link is free to",
    "start": "1770700",
    "end": "1776129"
  },
  {
    "text": "launch a Splunk cluster from database marketplace super simple everything is being set up you just go launch an ec2",
    "start": "1776129",
    "end": "1782639"
  },
  {
    "text": "instance with a Splunk installation already on it and the third link is free to learn more by the Kinesis services we",
    "start": "1782639",
    "end": "1789629"
  },
  {
    "text": "have three different services four different capabilities and use cases and you can get an overview in and deeper",
    "start": "1789629",
    "end": "1796440"
  },
  {
    "text": "understanding of these different capabilities from this website and lastly more information about blank on",
    "start": "1796440",
    "end": "1803279"
  },
  {
    "text": "AWS and it's on the marketplace page you can read a bit more about the Splunk",
    "start": "1803279",
    "end": "1808289"
  },
  {
    "text": "capability on AWS so given that our we'll start pick a few questions from",
    "start": "1808289",
    "end": "1813690"
  },
  {
    "text": "the audience and start answering this question so the first one that I got",
    "start": "1813690",
    "end": "1819119"
  },
  {
    "text": "here and it's it's a few questions saying what are AWS and thus plants plan",
    "start": "1819119",
    "end": "1825690"
  },
  {
    "text": "for doing data security and compliance so I can answer and for an Amazon",
    "start": "1825690",
    "end": "1831330"
  },
  {
    "text": "Kinesis first in our hand off the card to talk a bit about you know the security and compliance from Splunk site",
    "start": "1831330",
    "end": "1836340"
  },
  {
    "text": "so for Amazon Kinesis and we have a lot a lot and customers using Kinesis for",
    "start": "1836340",
    "end": "1842669"
  },
  {
    "text": "streaming sensitive customer data or data with regulatory reasons needs to be encrypted or protected so in Kinesis and",
    "start": "1842669",
    "end": "1850320"
  },
  {
    "text": "actually a few weeks back we just shipped the server-side encryption feature which allows you t ship",
    "start": "1850320",
    "end": "1856350"
  },
  {
    "text": "plaintext data and into fire hose or Kinesis then we'll encrypt the data on the server side and you can always also",
    "start": "1856350",
    "end": "1864359"
  },
  {
    "text": "encrypt the data from the client side before you send it up into the kinesio service",
    "start": "1864359",
    "end": "1869530"
  },
  {
    "text": "and also when firehose deliver the data into for example s3 destination we also",
    "start": "1869530",
    "end": "1875640"
  },
  {
    "text": "support an s3 server-side encryption so as file host rich data into s3 it'll",
    "start": "1875640",
    "end": "1881980"
  },
  {
    "text": "trigger Amazon s3 and server-side data encryption as well on the compliance",
    "start": "1881980",
    "end": "1887470"
  },
  {
    "text": "front we're currently working through a few different compliance that are required by different and government agencies and industries and some",
    "start": "1887470",
    "end": "1894850"
  },
  {
    "text": "examples are unfair to ramp HIPAA sock and PCI so these are the other focuses",
    "start": "1894850",
    "end": "1902950"
  },
  {
    "text": "that we can we can and I'm going to get certification from these compliance it's down the road so you should expect to",
    "start": "1902950",
    "end": "1908830"
  },
  {
    "text": "see these compliance is coming up online for the Kinesis service shortly so Carrie you want to talk a bit about",
    "start": "1908830",
    "end": "1914500"
  },
  {
    "text": "securing compliance capabilities in Splunk sure I also have a small cloud",
    "start": "1914500",
    "end": "1920530"
  },
  {
    "text": "architect on but I can take it the first part sews one cloud as I mentioned it here's two very rigorous security",
    "start": "1920530",
    "end": "1926380"
  },
  {
    "text": "standards we have a dedicated cloud environment for each customer a single tenant infrastructure for compute we",
    "start": "1926380",
    "end": "1932740"
  },
  {
    "text": "also are certified in ISO 27001 and Sauk to type 2 certified we also offer",
    "start": "1932740",
    "end": "1939760"
  },
  {
    "text": "encryption in transit so any data traveling over a network is SSL encrypted by default and we also offer",
    "start": "1939760",
    "end": "1946659"
  },
  {
    "text": "on AWS marketplace an optional an optional encryption at rest so stored",
    "start": "1946659",
    "end": "1952179"
  },
  {
    "text": "data can be encrypted at an incremental cost so can a mirror moves ours for",
    "start": "1952179",
    "end": "1957340"
  },
  {
    "text": "cloud architect do you have any other security features that you'd like to highlight thanks Kara that's actually",
    "start": "1957340",
    "end": "1963640"
  },
  {
    "text": "very comprehensive right there with respect to Splunk yes everything is",
    "start": "1963640",
    "end": "1969429"
  },
  {
    "text": "encrypted on in-flight and also we have our compliance standards with Sauk to",
    "start": "1969429",
    "end": "1975940"
  },
  {
    "text": "you and ISO 27001 so I got nothing else",
    "start": "1975940",
    "end": "1981480"
  },
  {
    "text": "thank you that cool thank you guys so another question that I got here is when",
    "start": "1981480",
    "end": "1987760"
  },
  {
    "start": "1985000",
    "end": "2135000"
  },
  {
    "text": "I collect data and send them to Kinesis from different application servers or web servers how do I do that is there an",
    "start": "1987760",
    "end": "1994270"
  },
  {
    "text": "agent so the kinesio services or for a REST API call so you can actually use a",
    "start": "1994270",
    "end": "1999940"
  },
  {
    "text": "W SDK to ride your theater a producer and send data into these services we also offer a",
    "start": "1999940",
    "end": "2007159"
  },
  {
    "text": "java-based agent called Kinesis agent that you can link stall on these things",
    "start": "2007159",
    "end": "2012860"
  },
  {
    "text": "since this or servers what it does is it'll monitor a local doc file and it'll",
    "start": "2012860",
    "end": "2018559"
  },
  {
    "text": "manage rotation as well so as new data gets written and into these log files",
    "start": "2018559",
    "end": "2023600"
  },
  {
    "text": "it'll pick it up and for these into Kinesis services and the next one I",
    "start": "2023600",
    "end": "2029270"
  },
  {
    "text": "believe it's for David so in the in the architectural diagram David showed the using Lam a function to process some of",
    "start": "2029270",
    "end": "2036260"
  },
  {
    "text": "the data for Anna Kinesis streams and then forward that into firehose so the question is what kind of processing are",
    "start": "2036260",
    "end": "2043370"
  },
  {
    "text": "you doing on that lambda function yes actually are doing very little processing it's really just the the act",
    "start": "2043370",
    "end": "2050358"
  },
  {
    "text": "of forwarding and all along so we actually have historically dynamic",
    "start": "2050359",
    "end": "2056089"
  },
  {
    "text": "processing with grok which is part of the ELQ stack and so we still have some",
    "start": "2056089",
    "end": "2061158"
  },
  {
    "text": "of that going on and we've moved that out into AWS and and typically what we're doing there is we're we're",
    "start": "2061159",
    "end": "2067658"
  },
  {
    "text": "reformatting some of the log lines basically filtering in some cases taking out logs that we don't want to end up in",
    "start": "2067659",
    "end": "2074240"
  },
  {
    "text": "swamp things like that and making sure that the logs are in a clean state cool",
    "start": "2074240",
    "end": "2079700"
  },
  {
    "text": "thank you David and the next one and it's a good one and the question is is Splunk on AWS purely offered as a",
    "start": "2079700",
    "end": "2086570"
  },
  {
    "text": "software-as-a-service or can i also set up Splunk within a database private VPC I'll take this one",
    "start": "2086570",
    "end": "2094460"
  },
  {
    "text": "we offer it's one cloud as a software-as-a-service option which is what I highlighted",
    "start": "2094460",
    "end": "2100550"
  },
  {
    "text": "during the presentation but we also offer you the ability to bring your own license so if you purchase a license",
    "start": "2100550",
    "end": "2106430"
  },
  {
    "text": "from Splunk you can actually spin that up you through the AWS marketplace in a",
    "start": "2106430",
    "end": "2112550"
  },
  {
    "text": "Splunk ami that we have available Kim do you have anything else you'd like to offer on that again I think you covered",
    "start": "2112550",
    "end": "2119359"
  },
  {
    "text": "it very well one additional additional point is we also offer cloud formation",
    "start": "2119359",
    "end": "2124550"
  },
  {
    "text": "templates that can leverage the marketplace a mize to deploy larger",
    "start": "2124550",
    "end": "2130940"
  },
  {
    "text": "bring your own license instances as well cool thank you and the next one can I run machine learning capabilities",
    "start": "2130940",
    "end": "2138680"
  },
  {
    "start": "2135000",
    "end": "2420000"
  },
  {
    "text": "on a streaming data pipeline so good one the answer is yes and from the three",
    "start": "2138680",
    "end": "2145160"
  },
  {
    "text": "Kinesis services one of them's called Kinesis analytics if you recall it allows you to run sequel query it's a",
    "start": "2145160",
    "end": "2151369"
  },
  {
    "text": "sequel engine on top of data stream and it's also integrated with multiple machine learning algorithms and we're",
    "start": "2151369",
    "end": "2157249"
  },
  {
    "text": "going to keep expanding that list so today a very popular algorithm we have",
    "start": "2157249",
    "end": "2163009"
  },
  {
    "text": "in the Canisius analytic service is a non myth detection it's unsupervised so you do not need to",
    "start": "2163009",
    "end": "2168859"
  },
  {
    "text": "provide any training beforehand as the data points keep coming in it'll score",
    "start": "2168859",
    "end": "2173900"
  },
  {
    "text": "anomaly score on each of the data point and you can trigger an alert or trigger an action if the anomaly score goes",
    "start": "2173900",
    "end": "2179690"
  },
  {
    "text": "really high so we actually have one airline customers and because as you",
    "start": "2179690",
    "end": "2185509"
  },
  {
    "text": "guys know airline all the different airlines they have a pricing system to decide how much they want to prize for a",
    "start": "2185509",
    "end": "2191150"
  },
  {
    "text": "particular ticket on a particular flight and that number keeps changing and depending on different market situations",
    "start": "2191150",
    "end": "2196970"
  },
  {
    "text": "and from time to time there's going there's an anomaly happening the pricing engine so you will have an awfully low",
    "start": "2196970",
    "end": "2202880"
  },
  {
    "text": "price on a particular ticket and that triggers a lot of revenue loss for the",
    "start": "2202880",
    "end": "2208190"
  },
  {
    "text": "airline companies so they actually using Kinesis analytics an army tection algorithm to collect all these pricing",
    "start": "2208190",
    "end": "2215660"
  },
  {
    "text": "data over these different websites and also the airline's own pricing system as soon as it detects hey based on all the",
    "start": "2215660",
    "end": "2222650"
  },
  {
    "text": "marketing condition all the inputs this price locks variable they you slam a function to bring that ticket and bring",
    "start": "2222650",
    "end": "2229819"
  },
  {
    "text": "that price down temporarily and trigger an alert so the human being will get involved review the price and fix that",
    "start": "2229819",
    "end": "2236450"
  },
  {
    "text": "issue so that's a very uncool use case I think that really helps that airline save a lot of costs and they do not need",
    "start": "2236450",
    "end": "2243499"
  },
  {
    "text": "to have any you know streaming data expertise mission learning expertise before hand everything is already built",
    "start": "2243499",
    "end": "2249470"
  },
  {
    "text": "in and you just use a sequel statement or a sequel template for that the next one I think is for Kara for Splunk and",
    "start": "2249470",
    "end": "2256460"
  },
  {
    "text": "for application and analytics what are the typical use cases you see Splunk",
    "start": "2256460",
    "end": "2261710"
  },
  {
    "text": "customers do to analyze their application logs and patterns sure I did",
    "start": "2261710",
    "end": "2267410"
  },
  {
    "text": "actually want to invite to also talk about machine learning for streaming data real quick and small sure",
    "start": "2267410",
    "end": "2273840"
  },
  {
    "text": "let's do that is that okay absolutely so the answer can actually fall with",
    "start": "2273840",
    "end": "2279060"
  },
  {
    "text": "both both questions actually so with respect to the machine learning toolkit that we actually integrated into the AWS",
    "start": "2279060",
    "end": "2286290"
  },
  {
    "text": "app it powers a lot of our insights that we have these insights are basically",
    "start": "2286290",
    "end": "2291450"
  },
  {
    "text": "taking a look at your data from AWS and telling you hey you might want to remove this security group you might want to",
    "start": "2291450",
    "end": "2297510"
  },
  {
    "text": "upgrade or downgrade this particular instance based on usage and patterns a very simple pattern at least in the",
    "start": "2297510",
    "end": "2304530"
  },
  {
    "text": "beginning with AWS app but it also starts looking at other things such as potentially security anomalies or",
    "start": "2304530",
    "end": "2310200"
  },
  {
    "text": "billing anomalies and alerting you on that information as well so that leads",
    "start": "2310200",
    "end": "2315360"
  },
  {
    "text": "to the next question which is what do people normally use Splunk for and",
    "start": "2315360",
    "end": "2320690"
  },
  {
    "text": "obviously being able to look at their AWS environment and obviously the TrueCar has done as well looking at",
    "start": "2320690",
    "end": "2326610"
  },
  {
    "text": "application logs it's a very diverse platform for machine data so you have",
    "start": "2326610",
    "end": "2332340"
  },
  {
    "text": "people looking at from a security standpoint but you also have people looking at for an application standpoint and then you have people looking at from",
    "start": "2332340",
    "end": "2338700"
  },
  {
    "text": "IIT and other very ingenious ways of looking at data so it's a it's a pure",
    "start": "2338700",
    "end": "2345390"
  },
  {
    "text": "imagination so you're only limited by your imagination of what you can do with this data what we see a lot of customers",
    "start": "2345390",
    "end": "2350730"
  },
  {
    "text": "using specifically around applications are around application delivery as well as application management or something",
    "start": "2350730",
    "end": "2356970"
  },
  {
    "text": "we're calling application performance analytics so not only are you seeing a lot of DevOps use cases and developers",
    "start": "2356970",
    "end": "2363570"
  },
  {
    "text": "you know using spunk to monitor their entire dev build pipeline integrating",
    "start": "2363570",
    "end": "2369660"
  },
  {
    "text": "all the tools that they're using to make sure that their code releases are happening as productively as possible",
    "start": "2369660",
    "end": "2374880"
  },
  {
    "text": "because we integrate across that entire tool chain but we're also seeing once those applications are in production to",
    "start": "2374880",
    "end": "2381060"
  },
  {
    "text": "be able to monitor how they're performing is super important and so we see a lot of people in ops roles using",
    "start": "2381060",
    "end": "2389190"
  },
  {
    "text": "some APM tools in conjunction with spunk because we not only take that deep",
    "start": "2389190",
    "end": "2396120"
  },
  {
    "text": "application data into account but we also enable you to correlate that data across the entire tech stack to see",
    "start": "2396120",
    "end": "2402030"
  },
  {
    "text": "where the failure points because most infrastructure issues that you see are not only going to be happening in the",
    "start": "2402030",
    "end": "2409250"
  },
  {
    "text": "application itself so those are two other areas that we see a lot of our",
    "start": "2409250",
    "end": "2415039"
  },
  {
    "text": "customers using Splunk specifically for applications cool thank you Karen and",
    "start": "2415039",
    "end": "2420109"
  },
  {
    "start": "2420000",
    "end": "2510000"
  },
  {
    "text": "the next one I think it's for M David it's a good question so the question is how long did it take for true car to",
    "start": "2420109",
    "end": "2426740"
  },
  {
    "text": "implement this solution this architecture from the very beginning until where you are right now so I think",
    "start": "2426740",
    "end": "2433369"
  },
  {
    "text": "that sort of wanted you to talk a bit about you know how long does it take how much resources spent and and how does it",
    "start": "2433369",
    "end": "2439369"
  },
  {
    "text": "compare to your previous solution yeah that was a good question I think you know generally when when we first",
    "start": "2439369",
    "end": "2445460"
  },
  {
    "text": "started we we spent a lot of time really kind of tuning and getting coughed up",
    "start": "2445460",
    "end": "2451430"
  },
  {
    "text": "and running in a place where it was actually able to process all the logs",
    "start": "2451430",
    "end": "2456680"
  },
  {
    "text": "and get them into ELQ and so I want to say we it was probably on the order of months of ops people really kind of",
    "start": "2456680",
    "end": "2463640"
  },
  {
    "text": "diving into that system making sure that it was doing the right things tuning it and holding it to basically get the logs",
    "start": "2463640",
    "end": "2469700"
  },
  {
    "text": "to where they needed to go and then when we moved into AWS it was it was much",
    "start": "2469700",
    "end": "2475970"
  },
  {
    "text": "different right so with Canisius we're able to basically within and I was like 15 minutes basically spin up a Kinesis",
    "start": "2475970",
    "end": "2482750"
  },
  {
    "text": "stream and and start writing data into that and it's a it's a managed service",
    "start": "2482750",
    "end": "2488450"
  },
  {
    "text": "just like Kafka and so it just checked that burden completely away and then once once we had spawn cloud it was like",
    "start": "2488450",
    "end": "2494779"
  },
  {
    "text": "okay now we're just gonna forward those messages in this point cloud and and we just turned that pipe on and it just",
    "start": "2494779",
    "end": "2501410"
  },
  {
    "text": "went so I think generally you know if you look at what we had to do in the data center versus what we had to do in",
    "start": "2501410",
    "end": "2507200"
  },
  {
    "text": "AWS it was order magnitudes difference cool thank you David the next one I think the the audience",
    "start": "2507200",
    "end": "2515059"
  },
  {
    "start": "2510000",
    "end": "2648000"
  },
  {
    "text": "interesting the security use case widths plan so Kara can you talk bit more about",
    "start": "2515059",
    "end": "2520190"
  },
  {
    "text": "what are the the security use case of this Blanc and what are some of the custom examples that you can share or I",
    "start": "2520190",
    "end": "2527029"
  },
  {
    "text": "actually sit on the IT side of the house so my colleague in security might be a",
    "start": "2527029",
    "end": "2532400"
  },
  {
    "text": "better fit for this but we see a lot of security use cases using swung so smoke platform just splendid cloud or SPARC",
    "start": "2532400",
    "end": "2539330"
  },
  {
    "text": "Enterprise we offers a lot of a lot of capabilities around security",
    "start": "2539330",
    "end": "2544430"
  },
  {
    "text": "investigation so reducing the time it takes to detect analyze and resolve any",
    "start": "2544430",
    "end": "2550460"
  },
  {
    "text": "threats to your environment we also offer fraud and compliance use cases and we actually offer a premium",
    "start": "2550460",
    "end": "2557870"
  },
  {
    "text": "solution called user behavior analytics that specializes in machine learning around making sure that the behavior in",
    "start": "2557870",
    "end": "2564110"
  },
  {
    "text": "your environment is is appropriate and then in terms of our sim product at our",
    "start": "2564110",
    "end": "2570770"
  },
  {
    "text": "price security that has a very deep UI and use cases around making sure that",
    "start": "2570770",
    "end": "2577610"
  },
  {
    "text": "any kind of anomaly detection that you find or reaches your firewall or using",
    "start": "2577610",
    "end": "2585320"
  },
  {
    "text": "basically all the same data that you would for infrastructure monitoring or application performance analytics but making sure that there is no nonsense",
    "start": "2585320",
    "end": "2591440"
  },
  {
    "text": "essentially happening in your security posture and it's really helping you beef up how protected you are against threats",
    "start": "2591440",
    "end": "2599690"
  },
  {
    "text": "that could be anything from malware to a malicious hacker or maybe a data breach",
    "start": "2599690",
    "end": "2606560"
  },
  {
    "text": "or a leak that you could have and you see a lot of this happen in the news like the Equifax breach and so you know",
    "start": "2606560",
    "end": "2612680"
  },
  {
    "text": "making you prepared for things that could happen that would threaten the",
    "start": "2612680",
    "end": "2617990"
  },
  {
    "text": "security of your business is really what swung for security specializes in and kam I don't know if you have any",
    "start": "2617990",
    "end": "2623120"
  },
  {
    "text": "addition we also offer the ability to integrate with new AWS security services",
    "start": "2623120",
    "end": "2628490"
  },
  {
    "text": "like Macy in addition to ones like cloud trail and inspector and configural --zz and we also offer something called the",
    "start": "2628490",
    "end": "2635180"
  },
  {
    "text": "adaptive response initiative which is a collection of partners including AWS that enable you to take specific actions",
    "start": "2635180",
    "end": "2641150"
  },
  {
    "text": "based on certain use cases or data sources that you would want to resolve in real time cool Thank You Kara the",
    "start": "2641150",
    "end": "2648860"
  },
  {
    "start": "2648000",
    "end": "2898000"
  },
  {
    "text": "next question is can talk a bit more about the integration between Kinesis and Splunk so I can I can speak to that",
    "start": "2648860",
    "end": "2656690"
  },
  {
    "text": "and so the particular integration is between the Kinesis firehose service and and Splunk",
    "start": "2656690",
    "end": "2662510"
  },
  {
    "text": "so the Kinesis firehose service allows you to stream data from different data sources and transform the data then",
    "start": "2662510",
    "end": "2669650"
  },
  {
    "text": "getting to the destination so the integration between firehose and with Splunk is leveraging Splunk HTTP",
    "start": "2669650",
    "end": "2675890"
  },
  {
    "text": "event collector and when we build a reliability layer on top of the HEC an",
    "start": "2675890",
    "end": "2681080"
  },
  {
    "text": "endpoint so that all the data will be acknowledged after index versus after receiving the",
    "start": "2681080",
    "end": "2686630"
  },
  {
    "text": "data and you can use Kinesis firehose to actually stream data from different a degrace data sources for example today",
    "start": "2686630",
    "end": "2692900"
  },
  {
    "text": "we support streaming data from cloud washcloths directly into Kinesis firehose service which means you can do",
    "start": "2692900",
    "end": "2700070"
  },
  {
    "text": "any log data within cloud washcloth such as VPC flow log your lambda function log",
    "start": "2700070",
    "end": "2705380"
  },
  {
    "text": "or your custom log and give these data streamed through firehose ink is Splunk directly firehose service is also",
    "start": "2705380",
    "end": "2712310"
  },
  {
    "text": "integrated with Crouch events and within that cloud watch event service we have cloud trail data so all the API call",
    "start": "2712310",
    "end": "2719120"
  },
  {
    "text": "monitoring log data you see to change events s3 events or these data you can",
    "start": "2719120",
    "end": "2724820"
  },
  {
    "text": "stream into spunky near real-time through the fire service we also integrated with ADA based IOT service",
    "start": "2724820",
    "end": "2731330"
  },
  {
    "text": "which means if you have our two use cases you can use mqtt protocol to speak to the database",
    "start": "2731330",
    "end": "2737000"
  },
  {
    "text": "IOT service collects sensor data from your iot devices and then stream through fire housing to Splunk and we're going",
    "start": "2737000",
    "end": "2743660"
  },
  {
    "text": "to keep expanding the list of the D supported data sources and the integration the point is if you want to",
    "start": "2743660",
    "end": "2749390"
  },
  {
    "text": "make a super easy for you to be able to analyze all these data source data using Splunk so the user experience we want it",
    "start": "2749390",
    "end": "2756260"
  },
  {
    "text": "to be is say for example we want to analyze VPC flow log using sprung cluster you just go to firehose set up",
    "start": "2756260",
    "end": "2763850"
  },
  {
    "text": "the PC flow log within cloud watch as a data source then choose a Splunk endpoint to stream",
    "start": "2763850",
    "end": "2769370"
  },
  {
    "text": "the data in on splash side we have this Kinesis file add-on which is fairly",
    "start": "2769370",
    "end": "2775190"
  },
  {
    "text": "similar to the car nativist add-on it'll have the different data to a data source tag for a nativist log data so if you",
    "start": "2775190",
    "end": "2782450"
  },
  {
    "text": "choose VPC flow log the sprung classic we just parse the data and convert that",
    "start": "2782450",
    "end": "2787580"
  },
  {
    "text": "into readable schema and analyzable schema and he can run search you can run",
    "start": "2787580",
    "end": "2792860"
  },
  {
    "text": "dashboard right away so we're pretty excited about this integration for you to combine the capability of streaming",
    "start": "2792860",
    "end": "2800360"
  },
  {
    "text": "data on AWS and the rich analytics capability on splint so encourage you to go ahead and sign up",
    "start": "2800360",
    "end": "2806720"
  },
  {
    "text": "for the better program if you're interesting this integration let's see how it works and we're working hard to get this GA and get it to a broad set of",
    "start": "2806720",
    "end": "2813920"
  },
  {
    "text": "customers out there given that another question for David I think I will take",
    "start": "2813920",
    "end": "2819470"
  },
  {
    "text": "this as the last one and for David and we'll conclude today's webinar so the question is as TrueCar tried any of the",
    "start": "2819470",
    "end": "2827090"
  },
  {
    "text": "analytic services we in the Hadoop ecosystem like MapReduce or spark yeah",
    "start": "2827090",
    "end": "2832280"
  },
  {
    "text": "so we we actually do use MapReduce we do use spark we we tend to not use them for",
    "start": "2832280",
    "end": "2838340"
  },
  {
    "text": "for logging however so we we do analyze clickstream data we do analyze a lot of",
    "start": "2838340",
    "end": "2844250"
  },
  {
    "text": "our sort of dealer feeds and pricing feeds and all those sorts of things they all end up in s3 and then we'll actually",
    "start": "2844250",
    "end": "2851780"
  },
  {
    "text": "use MapReduce to do transformation their aggregate the data there and actually",
    "start": "2851780",
    "end": "2857720"
  },
  {
    "text": "provide and actually create elasticsearch and elixirs that ended up eventually powering our website so so we",
    "start": "2857720",
    "end": "2864530"
  },
  {
    "text": "do use it but we don't use it for logging thank you David yeah it's 1/2 to the X as I mentioned we think streaming",
    "start": "2864530",
    "end": "2870620"
  },
  {
    "text": "technology versus patch oriented technology would do Pacific one we think they're not complimentary for different",
    "start": "2870620",
    "end": "2877010"
  },
  {
    "text": "kind of use cases and if eventually I think you need both different capabilities for different kind of use",
    "start": "2877010",
    "end": "2882530"
  },
  {
    "text": "cases Korea given that I want to first thank David and Kara for presenting the",
    "start": "2882530",
    "end": "2888110"
  },
  {
    "text": "webinar today with me and also want to thank all the audience to joining with",
    "start": "2888110",
    "end": "2893150"
  },
  {
    "text": "this webinar session this morning and thanks again for joining us for the webinar this morning thank you guys",
    "start": "2893150",
    "end": "2900400"
  }
]
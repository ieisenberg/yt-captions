[
  {
    "text": "hello everyone this is Rajesh panii and I'm a Solutions architect at Amazon web",
    "start": "3120",
    "end": "9320"
  },
  {
    "text": "services in this session we are going to start with a series on the topic of open tables on AWS",
    "start": "9320",
    "end": "17400"
  },
  {
    "text": "Workshop we will start with what the workshop is about what it entails and what we are going to cover",
    "start": "18560",
    "end": "25480"
  },
  {
    "text": "in this section we'll switch to the console to do a demo walk through and",
    "start": "25480",
    "end": "30960"
  },
  {
    "text": "finally conclude with references so let's get this started",
    "start": "30960",
    "end": "36360"
  },
  {
    "text": "here with this tutorial so this is the Open Table formats on AWS to access this Workshop",
    "start": "36360",
    "end": "44399"
  },
  {
    "text": "use this QR code AS highlighted in this slide because this is uh content of this",
    "start": "44399",
    "end": "54000"
  },
  {
    "text": "Workshop is going to be big I'm going to break it down into three section the first one this session we will cover the",
    "start": "54000",
    "end": "61879"
  },
  {
    "text": "base functionalities in EMR serverless and glue in the second part we going to",
    "start": "61879",
    "end": "67960"
  },
  {
    "text": "cover the advanced functionalities again with the EMR and glue finally we'll conclude with the",
    "start": "67960",
    "end": "73960"
  },
  {
    "text": "third part focusing on aena for base aena for advanced and how we can use",
    "start": "73960",
    "end": "80159"
  },
  {
    "text": "atina for the consumption part so let's get this started with the",
    "start": "80159",
    "end": "86040"
  },
  {
    "text": "console going to switch to the console here",
    "start": "86040",
    "end": "91439"
  },
  {
    "text": "this is a workshop that I was referring in the slide just to give a brief overview of",
    "start": "93040",
    "end": "99759"
  },
  {
    "text": "the Open Table format as you might know by now the modern data Lake architecture has been",
    "start": "99759",
    "end": "106520"
  },
  {
    "text": "providing lot of benefits in the in the in the current architecture in providing the cost",
    "start": "106520",
    "end": "113520"
  },
  {
    "text": "Advantage as well as flexibility and scalability as data arise from more and",
    "start": "113520",
    "end": "119439"
  },
  {
    "text": "more data sources and at a different variety velocity Etc however there are",
    "start": "119439",
    "end": "125560"
  },
  {
    "text": "certain areas where it still lacks some benefits",
    "start": "125560",
    "end": "130640"
  },
  {
    "text": "and the database like capabilities are one such thing to ensure that the data",
    "start": "130640",
    "end": "137280"
  },
  {
    "text": "consistency to be maintained across multiple concurrent concurrent writers and readers meaning as more and more",
    "start": "137280",
    "end": "144760"
  },
  {
    "text": "application trying to access the data we need to ensure that the data is consistent",
    "start": "144760",
    "end": "150239"
  },
  {
    "text": "and also it is fail proof as multiple writers operations happen and that",
    "start": "150239",
    "end": "157519"
  },
  {
    "text": "should not corrupt the data as well right so these are the different um uh deficiencies that the Open Table format",
    "start": "157519",
    "end": "164440"
  },
  {
    "text": "tries to overcome and here's a quick uh very high level list that the benefits that Open",
    "start": "164440",
    "end": "170640"
  },
  {
    "text": "Table forment brings transaction support providing asset guarantees schema",
    "start": "170640",
    "end": "176840"
  },
  {
    "text": "Evolution that we'll be walking over in just a second here and so on and so forth",
    "start": "176840",
    "end": "184319"
  },
  {
    "text": "okay as mentioned here in terms of the prerequisits we will have to start with the EMR Studio as outline in the",
    "start": "184480",
    "end": "192400"
  },
  {
    "text": "workshop in the console when you type EMR you will land up in this page click on",
    "start": "192400",
    "end": "200879"
  },
  {
    "text": "Studios create Studio think of this studio as a integrated development environment for",
    "start": "200879",
    "end": "208159"
  },
  {
    "text": "big data processing and the data process needs right and so we are setting up this environment right now the workshop",
    "start": "208159",
    "end": "216920"
  },
  {
    "text": "highlights that we edit this settings to point to Studio",
    "start": "216920",
    "end": "223080"
  },
  {
    "text": "One pointing to the S3 location for the workshop storage and here in this case",
    "start": "223840",
    "end": "229720"
  },
  {
    "text": "it's going to be this studio storage also existing service role to",
    "start": "229720",
    "end": "238239"
  },
  {
    "text": "Studio service role we'll also need to change the workspace settings to workspace",
    "start": "238239",
    "end": "246000"
  },
  {
    "text": "one and the application settings as well",
    "start": "248599",
    "end": "253720"
  },
  {
    "text": "okay we say application one and also choose a runtime rule as",
    "start": "253720",
    "end": "260239"
  },
  {
    "text": "EMR Studio runtime rule these are the different settings in creation of the AMR",
    "start": "260239",
    "end": "266680"
  },
  {
    "text": "Studio since I have already created one so I'm going to to cancel however if you'll be doing this for the very first",
    "start": "266680",
    "end": "273199"
  },
  {
    "text": "time you will select this create Studio I'll cancel this the studio has",
    "start": "273199",
    "end": "279080"
  },
  {
    "text": "already been created it'll provide a studio access URL clicking here will take to the page",
    "start": "279080",
    "end": "286199"
  },
  {
    "text": "just like this click on the workspaces and we will",
    "start": "286199",
    "end": "291520"
  },
  {
    "text": "already have a workspace by now based on the settings earlier clicking this workspace will",
    "start": "291520",
    "end": "297800"
  },
  {
    "text": "launch a workspace something like this okay the very first time you will not see anything you will see the",
    "start": "297800",
    "end": "305479"
  },
  {
    "text": "launcher however the workshop also provides a notebook for EMR Basics so",
    "start": "305479",
    "end": "310800"
  },
  {
    "text": "you click on here upload files you browse to your location and",
    "start": "310800",
    "end": "316680"
  },
  {
    "text": "point it to the file and you will upload the file here EMR Ice book Basics python",
    "start": "316680",
    "end": "324039"
  },
  {
    "text": "notebook this is a notebook environment however as we are accessing the um code",
    "start": "324039",
    "end": "331919"
  },
  {
    "text": "development we need to compute environment as well and here in this case for the",
    "start": "331919",
    "end": "337560"
  },
  {
    "text": "workshop we are pointing this Compu to the serverless application to make it simple and the",
    "start": "337560",
    "end": "344240"
  },
  {
    "text": "serverless application is attached to the workspace okay when you are opening up",
    "start": "344240",
    "end": "351840"
  },
  {
    "text": "this file it will take you to the page just like this what are we going to do in this",
    "start": "351840",
    "end": "357160"
  },
  {
    "text": "basic functionality in EMR uh a set of cred operations if you want",
    "start": "357160",
    "end": "364000"
  },
  {
    "text": "to make it in a very simple uh explanation we going to create a iceborg",
    "start": "364000",
    "end": "369120"
  },
  {
    "text": "table read data from the table update delete and in the fifth step we are",
    "start": "369120",
    "end": "375960"
  },
  {
    "text": "going to do a roll back and roll forward and finally conclude the",
    "start": "375960",
    "end": "381680"
  },
  {
    "text": "notebook with schema Evolution and how it is different from a traditional database style architecture",
    "start": "381680",
    "end": "388560"
  },
  {
    "text": "right and it's the iceberg uniqueness as well we'll be working on two",
    "start": "388560",
    "end": "394720"
  },
  {
    "text": "tables the prepared customer is for this basic U functionality prepared web sales",
    "start": "394720",
    "end": "401720"
  },
  {
    "text": "we will cover we will use this data set for the in the advanced functionality this data set is already",
    "start": "401720",
    "end": "408880"
  },
  {
    "text": "prepopulated as a part of the workshop however you can still also",
    "start": "408880",
    "end": "414479"
  },
  {
    "text": "refer back to the original version of the data database and the table from this",
    "start": "414479",
    "end": "420120"
  },
  {
    "text": "website TPC data the customer table and the web",
    "start": "420120",
    "end": "426039"
  },
  {
    "text": "sales the customer table will have 2 million records and the web sales have",
    "start": "426039",
    "end": "432000"
  },
  {
    "text": "72 million records okay now that we have",
    "start": "432000",
    "end": "439080"
  },
  {
    "text": "this uh setup right now couple of changes we need to make",
    "start": "439080",
    "end": "445560"
  },
  {
    "text": "the first one is in this particular self where the code is there to create Ice",
    "start": "445560",
    "end": "450919"
  },
  {
    "text": "book catalog we will have to make a edit here and um point back to your account",
    "start": "450919",
    "end": "457360"
  },
  {
    "text": "ID to make this location unique if in",
    "start": "457360",
    "end": "464240"
  },
  {
    "text": "doubt go back to the original console page click here copy the account",
    "start": "464240",
    "end": "471039"
  },
  {
    "text": "ID come back and make it when you will be opening up this notebook for the very",
    "start": "471039",
    "end": "477039"
  },
  {
    "text": "first time you will see a placeholder uh account ID and that's where you will have",
    "start": "477039",
    "end": "482400"
  },
  {
    "text": "to edit it this is one place and the second place where you",
    "start": "482400",
    "end": "488400"
  },
  {
    "text": "have to modify the data is again in the second cell as well these are the two",
    "start": "488400",
    "end": "494520"
  },
  {
    "text": "places where you have to place your account information and uh if in doubt you can",
    "start": "494520",
    "end": "501680"
  },
  {
    "text": "also go back to the S3 table and here you will see this same",
    "start": "501680",
    "end": "508479"
  },
  {
    "text": "information this is F ID as well okay once you",
    "start": "508479",
    "end": "514839"
  },
  {
    "text": "placed I have already executed all the steps in the interest of time however if",
    "start": "514839",
    "end": "521360"
  },
  {
    "text": "um you can use shift enter to enter this um execute this code or click on run",
    "start": "521360",
    "end": "528480"
  },
  {
    "text": "here as well okay the first step here is creation of the IB",
    "start": "528480",
    "end": "536399"
  },
  {
    "text": "catalog the second one is setting up certain environmental variables that we",
    "start": "536800",
    "end": "542000"
  },
  {
    "text": "will be using in the further sections down below bucket name as I mentioned um we",
    "start": "542000",
    "end": "548640"
  },
  {
    "text": "are pointing to our uh S3 bucket one thing to point out is um when",
    "start": "548640",
    "end": "557240"
  },
  {
    "text": "you are using the EMR serverless section of the base and the catalog that we will",
    "start": "557240",
    "end": "563120"
  },
  {
    "text": "be create in the database that we'll be creating attaches a word EMR _ icebug",
    "start": "563120",
    "end": "569399"
  },
  {
    "text": "database the service name when you will be using for um glue in the next section",
    "start": "569399",
    "end": "576959"
  },
  {
    "text": "you will see glue _ Iceberg _ database so that makes the database unique and",
    "start": "576959",
    "end": "582160"
  },
  {
    "text": "the tables underneath as well okay that's a nice way to segregate and make it um in isolated",
    "start": "582160",
    "end": "589600"
  },
  {
    "text": "fashion so I have executed this successfully here are some of the",
    "start": "589600",
    "end": "595440"
  },
  {
    "text": "libraries that we need to import uh import p 3 J etc etc and as a part of",
    "start": "595440",
    "end": "603120"
  },
  {
    "text": "the cred operation on the iceberg table we will be using some uh act",
    "start": "603120",
    "end": "608519"
  },
  {
    "text": "actions and this notebook provides a convenient way that the function has been created for each and every action",
    "start": "608519",
    "end": "615160"
  },
  {
    "text": "that we will be doing down below the cred operations Etc right so list files",
    "start": "615160",
    "end": "621360"
  },
  {
    "text": "um printing files show table files um just make a note um in a in in your",
    "start": "621360",
    "end": "627360"
  },
  {
    "text": "memory that we will be referring to this function and providing the table name to",
    "start": "627360",
    "end": "632920"
  },
  {
    "text": "get some information about the tables show data files current metadata pointer and so on",
    "start": "632920",
    "end": "639320"
  },
  {
    "text": "and so forth so this is one stop place where all the functions have been defined and kept it for our future use",
    "start": "639320",
    "end": "649560"
  },
  {
    "text": "okay now we are importing pandas here most of you as a data Engineers must be",
    "start": "650200",
    "end": "656839"
  },
  {
    "text": "familiar with this one so um I'm going to move down by default the current catalog",
    "start": "656839",
    "end": "663440"
  },
  {
    "text": "points to the spark catalog we are just validating that this is showing a spark catalog however in",
    "start": "663440",
    "end": "670720"
  },
  {
    "text": "the first very first step we have created the iceberg catalog that's where we are going to um access our data and",
    "start": "670720",
    "end": "678079"
  },
  {
    "text": "the tables underneath this catalog so we are going to use this change it to from",
    "start": "678079",
    "end": "683399"
  },
  {
    "text": "spark to Iceberg validating this current catalog now points to Iceberg so it",
    "start": "683399",
    "end": "688760"
  },
  {
    "text": "moved from spark to Iceberg now the",
    "start": "688760",
    "end": "696200"
  },
  {
    "text": "data um that we saw the the customer data the 2 million records are currently",
    "start": "696200",
    "end": "702320"
  },
  {
    "text": "in the spark catalog we can still access the database",
    "start": "702320",
    "end": "707760"
  },
  {
    "text": "and the tables information from in a different catalog however we need to specify the fully qualified uh name",
    "start": "707760",
    "end": "713519"
  },
  {
    "text": "space information and that's what we are seeing here the the database information",
    "start": "713519",
    "end": "719279"
  },
  {
    "text": "there are six of them this is the modified version of the customer and the web sales as I",
    "start": "719279",
    "end": "725600"
  },
  {
    "text": "mentioned the customer information will be used in this base uh functionality",
    "start": "725600",
    "end": "731160"
  },
  {
    "text": "validation and for the advanced functionality we'll be using the web sales one in this catalog we are going to",
    "start": "731160",
    "end": "737920"
  },
  {
    "text": "create the database using this spark SQL command create database it run",
    "start": "737920",
    "end": "745440"
  },
  {
    "text": "successfully and within this database we are going to use the table",
    "start": "745440",
    "end": "750800"
  },
  {
    "text": "creation right so these are the environment variables that was uh",
    "start": "750800",
    "end": "757160"
  },
  {
    "text": "referenced in the second step of this notebook earlier okay this table will",
    "start": "757160",
    "end": "763240"
  },
  {
    "text": "have five columns as you are seeing here now the table has been created",
    "start": "763240",
    "end": "770800"
  },
  {
    "text": "currently it is empty but however this is a table name and this is a um",
    "start": "770800",
    "end": "776360"
  },
  {
    "text": "database name here okay this particular command provides um",
    "start": "776360",
    "end": "782279"
  },
  {
    "text": "description about the table as we saw there are five columns and then the metadata information about",
    "start": "782279",
    "end": "788920"
  },
  {
    "text": "those columns and the table metadata as well okay we are also seeing the table",
    "start": "788920",
    "end": "795600"
  },
  {
    "text": "properties through this SQL command this snapshot information will",
    "start": "795600",
    "end": "801839"
  },
  {
    "text": "be make sense when we come down below before going down to exe showing",
    "start": "801839",
    "end": "808639"
  },
  {
    "text": "the other set I just want to point out that this Iceberg um uh table structure",
    "start": "808639",
    "end": "814600"
  },
  {
    "text": "follows this three layers the catalog layer metadata and the",
    "start": "814600",
    "end": "820079"
  },
  {
    "text": "data the catalog will point to the most recent metadata file in this metadata",
    "start": "820079",
    "end": "825199"
  },
  {
    "text": "layer there are two components metadata file which has a collection of the",
    "start": "825199",
    "end": "832440"
  },
  {
    "text": "snapshots and the Manifest list file which points to one specific unique",
    "start": "832440",
    "end": "839600"
  },
  {
    "text": "snapshot as you seeing here in this pointer this list",
    "start": "839600",
    "end": "844759"
  },
  {
    "text": "file is pointing to only snapshot zero and this list file points to snapshot",
    "start": "844759",
    "end": "852600"
  },
  {
    "text": "one and the Manifest",
    "start": "853240",
    "end": "857440"
  },
  {
    "text": "files will po will point back to the different data files",
    "start": "858440",
    "end": "864959"
  },
  {
    "text": "individually the Manifest list file will also point to the list of all the Manifest files as you seeing here this",
    "start": "864959",
    "end": "872440"
  },
  {
    "text": "list file can contain one or more manifest files and this manifest file",
    "start": "872440",
    "end": "878320"
  },
  {
    "text": "each one will corresponding to one data files okay one thing to point out in a",
    "start": "878320",
    "end": "884360"
  },
  {
    "text": "very summarized fashion is every operation here there can be",
    "start": "884360",
    "end": "889959"
  },
  {
    "text": "different kind of operation commit roll back roll forward Etc creates a new metadata file which",
    "start": "889959",
    "end": "896600"
  },
  {
    "text": "means that it creates if you're doing a commit operation each one creates a",
    "start": "896600",
    "end": "903160"
  },
  {
    "text": "metadata file and anytime the new metadata file creates the catalog will point to the",
    "start": "903160",
    "end": "909680"
  },
  {
    "text": "most recent one okay in here in this case as we are moving forward from left",
    "start": "909680",
    "end": "915680"
  },
  {
    "text": "to right when there will be a metadata file created in the future this catalog",
    "start": "915680",
    "end": "921560"
  },
  {
    "text": "will point to that not this one so it always points to the most recent one",
    "start": "921560",
    "end": "929120"
  },
  {
    "text": "one other uniqueness we also want to point out is in the within the commit",
    "start": "929120",
    "end": "935519"
  },
  {
    "text": "operation which means that it can be a insert update or delete will create a",
    "start": "935519",
    "end": "940720"
  },
  {
    "text": "new snapshot okay the rest of the operation will not",
    "start": "940720",
    "end": "946399"
  },
  {
    "text": "create a snapshot it will only create a new metadata file okay meaning those",
    "start": "946399",
    "end": "952079"
  },
  {
    "text": "commits the insert update delete touches the actual data file meaning we are",
    "start": "952079",
    "end": "958160"
  },
  {
    "text": "creating something we are updating something we are deleting something which means that this data file has been",
    "start": "958160",
    "end": "964600"
  },
  {
    "text": "touched so that creates some manifest and the snapshots and that's why uh it's given",
    "start": "964600",
    "end": "973759"
  },
  {
    "text": "here okay now back to the table",
    "start": "973759",
    "end": "978480"
  },
  {
    "text": "notebook so we seeing the show table",
    "start": "979600",
    "end": "984360"
  },
  {
    "text": "files when when you're using this for the very first time it will show differently not this one we just see a",
    "start": "985279",
    "end": "991759"
  },
  {
    "text": "couple of only one metadata file you can also access information like this go to",
    "start": "991759",
    "end": "997079"
  },
  {
    "text": "the S3 table Workshop data data",
    "start": "997079",
    "end": "1003560"
  },
  {
    "text": "sets we talking about ice EMR EMR iceb the catalog information the",
    "start": "1003560",
    "end": "1012839"
  },
  {
    "text": "table and it this consists of two folders the metadata file which will consist of all the metadata",
    "start": "1012839",
    "end": "1019519"
  },
  {
    "text": "related information one thing to also point in this juncture",
    "start": "1019519",
    "end": "1026160"
  },
  {
    "text": "is whenever you see a file metadata. Json it always points to the metadata",
    "start": "1026160",
    "end": "1033360"
  },
  {
    "text": "file here okay and whenever you see a file that points",
    "start": "1033360",
    "end": "1042038"
  },
  {
    "text": "to snap Dash something it points back to the Manifest list file remember we",
    "start": "1042039",
    "end": "1051160"
  },
  {
    "text": "told the Manifest list file will refer back to the snapshot so snap Dash something always means it is a manifest",
    "start": "1051160",
    "end": "1058640"
  },
  {
    "text": "list file and then the individual manifest files are referred here as m0 M1 Etc",
    "start": "1058640",
    "end": "1070640"
  },
  {
    "text": "okay um just so that you keep that in mind here this information entire metadata information is in the metadata",
    "start": "1070640",
    "end": "1077679"
  },
  {
    "text": "folder and also a separate data folder which consists of all the data changes",
    "start": "1077679",
    "end": "1083039"
  },
  {
    "text": "that happen here okay now that we have this we are",
    "start": "1083039",
    "end": "1091720"
  },
  {
    "text": "seeing the current metadata file which means that the most recent metadata file consists of the table with",
    "start": "1091720",
    "end": "1101159"
  },
  {
    "text": "this five columns schemas the very first time we don't",
    "start": "1101159",
    "end": "1106280"
  },
  {
    "text": "have any snapshot because this table is still empty there's no snapshots created yet and now this is a point where we are",
    "start": "1106280",
    "end": "1113679"
  },
  {
    "text": "inserting the data up until this point the table has been created as I said No data yet right",
    "start": "1113679",
    "end": "1122640"
  },
  {
    "text": "here before inserting the data we are just verifying one more time that the from The Spar catalog we are seeing the",
    "start": "1122640",
    "end": "1130120"
  },
  {
    "text": "customer table a sample of them um five columns and the sample list",
    "start": "1130120",
    "end": "1137919"
  },
  {
    "text": "we are taking this information from the spark catalog and inserting back into our Ice book catalog and the Ice Book",
    "start": "1137919",
    "end": "1145080"
  },
  {
    "text": "Table and there are 2 million records as we pointed",
    "start": "1145080",
    "end": "1151760"
  },
  {
    "text": "out this information is just as I mentioned here the metadata files is the",
    "start": "1152240",
    "end": "1157760"
  },
  {
    "text": "file that is ending with metadata. Json anything that's snap Das something build",
    "start": "1157760",
    "end": "1163280"
  },
  {
    "text": "this build the Manifest list file you can think of this manifest list file or the",
    "start": "1163280",
    "end": "1169440"
  },
  {
    "text": "metadata information of the Manifest files and by this show table file this",
    "start": "1169440",
    "end": "1177240"
  },
  {
    "text": "is a function that you saw in the very second cell and by giving that customer",
    "start": "1177240",
    "end": "1183080"
  },
  {
    "text": "table name it's printing back the root information and all the data and the",
    "start": "1183080",
    "end": "1188760"
  },
  {
    "text": "metadata which can also be accessed in this uh S3 uh table as",
    "start": "1188760",
    "end": "1196880"
  },
  {
    "text": "well now that we have inserted the data at this point we would be seeing one",
    "start": "1197280",
    "end": "1203360"
  },
  {
    "text": "snapshot um and also metad pointer is pointing to the most recent",
    "start": "1203360",
    "end": "1210159"
  },
  {
    "text": "one if you think about it this metadata. Json in the visual",
    "start": "1210159",
    "end": "1218280"
  },
  {
    "text": "view would be this one okay because the very first",
    "start": "1218280",
    "end": "1225120"
  },
  {
    "text": "time later after the steps we will also be doing some other",
    "start": "1225120",
    "end": "1230240"
  },
  {
    "text": "additional work which means that new metadata file will be created so just so",
    "start": "1230240",
    "end": "1236440"
  },
  {
    "text": "that I want to correlate um the information that we saw in the notebook back in the visual view okay going back",
    "start": "1236440",
    "end": "1243640"
  },
  {
    "text": "here we inserted the data now querying the data querying the Ice Book Table can",
    "start": "1243640",
    "end": "1251000"
  },
  {
    "text": "come in two forms like as we are seeing here in the spark SQL form also in the dat data frame APA form",
    "start": "1251000",
    "end": "1260240"
  },
  {
    "text": "as well so both ways we can access the data and Ice book support both of them",
    "start": "1260240",
    "end": "1265760"
  },
  {
    "text": "um this is the SQL style that we have seen uh earlier in up until now in the",
    "start": "1265760",
    "end": "1271880"
  },
  {
    "text": "notebook we are seeing a sample list of all the entries from the data frame side we we",
    "start": "1271880",
    "end": "1279200"
  },
  {
    "text": "also seeing the similar information or the same information now continue on with the CED",
    "start": "1279200",
    "end": "1285440"
  },
  {
    "text": "operation we are updating the record here we are before updating we are just",
    "start": "1285440",
    "end": "1291559"
  },
  {
    "text": "validating One customer record entry with the identifier 15 we are seeing that there is no last",
    "start": "1291559",
    "end": "1298640"
  },
  {
    "text": "name or the email address and this is where we are going to update the",
    "start": "1298640",
    "end": "1304080"
  },
  {
    "text": "records in this update statement we are setting the last name here and the email address to",
    "start": "1304080",
    "end": "1310360"
  },
  {
    "text": "this and this cell we are validating again what we have changed",
    "start": "1310360",
    "end": "1317559"
  },
  {
    "text": "right so the last name has been changed from non nothing to John and the email",
    "start": "1317559",
    "end": "1323480"
  },
  {
    "text": "address from nothing to this ABX do.com this update also results in the",
    "start": "1323480",
    "end": "1331000"
  },
  {
    "text": "new data file as you seeing here in the insert at the insert",
    "start": "1331000",
    "end": "1337400"
  },
  {
    "text": "time it the 209 time frame we are seeing the one data file and after updating we",
    "start": "1337400",
    "end": "1344000"
  },
  {
    "text": "have seen a different data file pointing to the most recent time time",
    "start": "1344000",
    "end": "1350440"
  },
  {
    "text": "stamp now that we have updated it we are going to delete it what we going to",
    "start": "1350440",
    "end": "1355640"
  },
  {
    "text": "delete is the same entry that we got updated delete from where the identifier",
    "start": "1355640",
    "end": "1361840"
  },
  {
    "text": "equal to 15 and so the data has been deleted",
    "start": "1361840",
    "end": "1368400"
  },
  {
    "text": "okay now this resulted in the third data file which means that this most recent",
    "start": "1368400",
    "end": "1374080"
  },
  {
    "text": "one as of 24 the data that we have currently will have all the entries except the customer",
    "start": "1374080",
    "end": "1382559"
  },
  {
    "text": "idore SK equal to 15 okay this is the very first set of data which is",
    "start": "1382559",
    "end": "1391120"
  },
  {
    "text": "inserted this is the updated one where the customer uh email and the last name",
    "start": "1391120",
    "end": "1399080"
  },
  {
    "text": "has been updated for SK equal to 15 and here the deletion",
    "start": "1399080",
    "end": "1406400"
  },
  {
    "text": "okay up until now again referring back we have completed all the crit operations now the second category",
    "start": "1406640",
    "end": "1414080"
  },
  {
    "text": "is time travel and roll back this is a quick preview of all the",
    "start": "1414080",
    "end": "1420320"
  },
  {
    "text": "um metadata information here the snapshots manifest list file",
    "start": "1420320",
    "end": "1426520"
  },
  {
    "text": "will point to the snapshot as I mentioned",
    "start": "1426520",
    "end": "1431320"
  },
  {
    "text": "right and here in a traditional database sense we",
    "start": "1431760",
    "end": "1437200"
  },
  {
    "text": "would have lost the date permanently right however using Iceberg",
    "start": "1437200",
    "end": "1443039"
  },
  {
    "text": "tables roll back and roll forward we are able to go back in time and able to recover in case of in inadvertent data",
    "start": "1443039",
    "end": "1450760"
  },
  {
    "text": "loss before that we are just doing a quick uh",
    "start": "1450760",
    "end": "1456679"
  },
  {
    "text": "status this first uh line item is the parent which is a data insertion very",
    "start": "1456840",
    "end": "1462240"
  },
  {
    "text": "first time so that created a snapshot because this is the first one there's no parent ID",
    "start": "1462240",
    "end": "1469120"
  },
  {
    "text": "next we inserted uh made some updates that created a new snapshot I as",
    "start": "1469120",
    "end": "1475799"
  },
  {
    "text": "you're seeing here and this is referring back to the old one as the",
    "start": "1475799",
    "end": "1482320"
  },
  {
    "text": "parent the third scenario is where we have deleted the",
    "start": "1482320",
    "end": "1487480"
  },
  {
    "text": "data this deletion is based on the previous snapshot and so this one is pointing back to this and this points",
    "start": "1487480",
    "end": "1494919"
  },
  {
    "text": "back to this okay so we will be we can go back in time by using this snapshot",
    "start": "1494919",
    "end": "1502960"
  },
  {
    "text": "IDs okay here is a quick uh um code to",
    "start": "1502960",
    "end": "1509120"
  },
  {
    "text": "extract the two Snapshot IDs the most recent one the second and the latest one",
    "start": "1509120",
    "end": "1515399"
  },
  {
    "text": "using this information we can get the data which means the select star from",
    "start": "1515399",
    "end": "1522080"
  },
  {
    "text": "this table as of this snapshot ID right the second snapshot ID points back",
    "start": "1522080",
    "end": "1528600"
  },
  {
    "text": "to this and in this case if you still recollect and following we have updated the last name",
    "start": "1528600",
    "end": "1535559"
  },
  {
    "text": "and the email address the third snapshot we would have",
    "start": "1535559",
    "end": "1540799"
  },
  {
    "text": "lost that information",
    "start": "1540799",
    "end": "1544158"
  },
  {
    "text": "right and um here is where we are seeing the data",
    "start": "1546799",
    "end": "1552279"
  },
  {
    "text": "files again three of the data file that we saw earlier now",
    "start": "1552279",
    "end": "1560240"
  },
  {
    "text": "we are going to roll forward we are going to say update this",
    "start": "1560960",
    "end": "1566000"
  },
  {
    "text": "information with the latest snapshot ID which means",
    "start": "1566000",
    "end": "1572640"
  },
  {
    "text": "that we have removed that ID",
    "start": "1573039",
    "end": "1577840"
  },
  {
    "text": "again okay so we are roll back meaning",
    "start": "1578720",
    "end": "1588559"
  },
  {
    "text": "from here we have come back to this one this snapshot ID where we have here in this",
    "start": "1589159",
    "end": "1596360"
  },
  {
    "text": "situation we have deleted the data for SK equal to 15 however we have rolled back to this original situation where we",
    "start": "1596360",
    "end": "1604720"
  },
  {
    "text": "now have that info the entry okay with the last name and the email address this",
    "start": "1604720",
    "end": "1610520"
  },
  {
    "text": "is what and this parent ID is again referring back to the original one okay",
    "start": "1610520",
    "end": "1618799"
  },
  {
    "text": "so this table file again um this standard function going back to the root location and all the data and the",
    "start": "1619840",
    "end": "1626279"
  },
  {
    "text": "metadata information schema",
    "start": "1626279",
    "end": "1631360"
  },
  {
    "text": "evolution in a traditional sense um once the structure has been created on a",
    "start": "1631360",
    "end": "1638880"
  },
  {
    "text": "database um changing the column information is is a combersome process",
    "start": "1638880",
    "end": "1647240"
  },
  {
    "text": "and without impact the data right which means that either renaming the column moving the column or adding um here in",
    "start": "1647240",
    "end": "1655440"
  },
  {
    "text": "this following steps you'll be able to see that ice book allows it to have it much easier without having to touch the",
    "start": "1655440",
    "end": "1664440"
  },
  {
    "text": "data as you might know from now we have five columns and the last column is the",
    "start": "1664440",
    "end": "1669880"
  },
  {
    "text": "email address in the two variations of schema Evolution the first one we are going to",
    "start": "1669880",
    "end": "1675240"
  },
  {
    "text": "see that we are going to change the column name to a different",
    "start": "1675240",
    "end": "1682000"
  },
  {
    "text": "one from email address to email and that can be considered with",
    "start": "1682000",
    "end": "1687559"
  },
  {
    "text": "the alter table command now selecting a sample list of",
    "start": "1687559",
    "end": "1694360"
  },
  {
    "text": "dat information you are seeing that this information has been",
    "start": "1694360",
    "end": "1699679"
  },
  {
    "text": "updated however the data is not been touched yet so that's the uniqueness of",
    "start": "1699679",
    "end": "1705120"
  },
  {
    "text": "the iceberg table because we have the different layers abstracted whatever change that we are",
    "start": "1705120",
    "end": "1711279"
  },
  {
    "text": "making at um the the schema level is only at the metadata layer not at the",
    "start": "1711279",
    "end": "1717240"
  },
  {
    "text": "data layer okay to confirm that we are seeing that",
    "start": "1717240",
    "end": "1723080"
  },
  {
    "text": "data file has not created a new data file which means that still continues to",
    "start": "1723080",
    "end": "1728399"
  },
  {
    "text": "have the old set of data however the metadata file has",
    "start": "1728399",
    "end": "1734559"
  },
  {
    "text": "changed telling that this is the first one which had the old um column",
    "start": "1734559",
    "end": "1742360"
  },
  {
    "text": "name to this new column name",
    "start": "1742360",
    "end": "1747278"
  },
  {
    "text": "okay and the second variation of the schema evolution is to add a new column here adding a",
    "start": "1748000",
    "end": "1755600"
  },
  {
    "text": "column um with the birth date information and the integer",
    "start": "1755600",
    "end": "1761278"
  },
  {
    "text": "type now when we are executing this select statement",
    "start": "1761880",
    "end": "1768159"
  },
  {
    "text": "or 10 rows we are seeing that the new column has been added again the data has",
    "start": "1768159",
    "end": "1773559"
  },
  {
    "text": "not been touched yet anything we still continue to have the new modified column name okay so these",
    "start": "1773559",
    "end": "1781760"
  },
  {
    "text": "are the two variations of the schema Evolution the renaming of the column and",
    "start": "1781760",
    "end": "1787799"
  },
  {
    "text": "then adding a new column by itself okay so that brings down to all the steps as",
    "start": "1787799",
    "end": "1794799"
  },
  {
    "text": "outlined in the workshop for EMR serverless on Open Table",
    "start": "1794799",
    "end": "1801679"
  },
  {
    "text": "format just a quick summary on the data sets in the data uh S3",
    "start": "1801919",
    "end": "1809640"
  },
  {
    "text": "tables we start with the workshop data EMR Ice book this is the name that",
    "start": "1809640",
    "end": "1817600"
  },
  {
    "text": "we have given database name the table information and that consists of two",
    "start": "1817600",
    "end": "1825279"
  },
  {
    "text": "folders all the variations that we we have done for cred operation roll back roll forward Etc has captured in these",
    "start": "1825279",
    "end": "1833000"
  },
  {
    "text": "two uh three sets of files the metadata",
    "start": "1833000",
    "end": "1838720"
  },
  {
    "text": "Json and then the snap Dash the numbers is a manifest list file",
    "start": "1838799",
    "end": "1846440"
  },
  {
    "text": "and the ones with the dash M number is the Manifest",
    "start": "1846440",
    "end": "1851600"
  },
  {
    "text": "files and one level above is the data files okay for insert update and delete",
    "start": "1851600",
    "end": "1862039"
  },
  {
    "text": "operations now in the continuation of",
    "start": "1862639",
    "end": "1867799"
  },
  {
    "text": "this for glue glue um if you follow the steps you will",
    "start": "1867799",
    "end": "1874279"
  },
  {
    "text": "actually create a glue notebook upload the glue notebook as outlined in the",
    "start": "1874279",
    "end": "1881200"
  },
  {
    "text": "workshop the very similar structure um as you were seeing from the",
    "start": "1882320",
    "end": "1888639"
  },
  {
    "text": "EMR serverless except that we are executing everything from the glue spark",
    "start": "1888639",
    "end": "1895440"
  },
  {
    "text": "session instead of going from complete to top down I just want to give a glimpse of a sample here as we have",
    "start": "1895440",
    "end": "1903440"
  },
  {
    "text": "updated the account name in this first cell here and also in the third one here as",
    "start": "1903440",
    "end": "1912000"
  },
  {
    "text": "well here are the two places where you have to update when you're going through the workshop",
    "start": "1912000",
    "end": "1919840"
  },
  {
    "text": "however the rest of them is completely identical right um I created a executed a set of steps",
    "start": "1920159",
    "end": "1930360"
  },
  {
    "text": "here like down below if you recollect we started with",
    "start": "1930360",
    "end": "1936440"
  },
  {
    "text": "the default spark catalog then change to Iceberg catalog validated it and the",
    "start": "1936440",
    "end": "1942960"
  },
  {
    "text": "different tables available in the spark catalog the customer and the web sales",
    "start": "1942960",
    "end": "1949519"
  },
  {
    "text": "everything is identical except that the environment um that we are executing",
    "start": "1949519",
    "end": "1954960"
  },
  {
    "text": "this notebook is in glue and not in EMR okay again if I start going down",
    "start": "1954960",
    "end": "1962679"
  },
  {
    "text": "completely then it would become a repetitive one but since we have completed everything in the EMR",
    "start": "1962679",
    "end": "1969120"
  },
  {
    "text": "serverless um you will be able to complete in glow without any",
    "start": "1969120",
    "end": "1975919"
  },
  {
    "text": "issues okay now going back to",
    "start": "1975919",
    "end": "1982360"
  },
  {
    "text": "this slides here are the Qui two quick references that I wanted to share the first one is the open data on AWS",
    "start": "1982399",
    "end": "1989679"
  },
  {
    "text": "Workshop uh here is a QR code if you're interested in this topic and want to get",
    "start": "1989679",
    "end": "1996240"
  },
  {
    "text": "to know more about the Apache Iceberg um Open Table format and here's a documentation as",
    "start": "1996240",
    "end": "2004320"
  },
  {
    "text": "well I thank you for your time and joining me in this first part series of",
    "start": "2004440",
    "end": "2009760"
  },
  {
    "text": "the open tables on AWS I hope to see you on the next",
    "start": "2009760",
    "end": "2015279"
  },
  {
    "text": "session thank you so much bye",
    "start": "2015279",
    "end": "2020279"
  }
]
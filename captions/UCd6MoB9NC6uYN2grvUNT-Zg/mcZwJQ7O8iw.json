[
  {
    "start": "0",
    "end": "90000"
  },
  {
    "text": "[Music] welcome to build with dynamodb my name is Evans uak I'm a dynamo DB specialist",
    "start": "700",
    "end": "6839"
  },
  {
    "text": "I say my name is Rick Houlihan I'm a principal technologies for no SQL for AWS alright today we're diving into a",
    "start": "6839",
    "end": "14280"
  },
  {
    "text": "real-world use case of data modeling where we have actually more complex relationships than what we had last time",
    "start": "14280",
    "end": "21630"
  },
  {
    "text": "when we did a fairly simple straightforward schema for a for a movie database also where we have our",
    "start": "21630",
    "end": "29340"
  },
  {
    "text": "moderators in a chat room who are ready to answer questions and some of those questions they'll forward to us so that",
    "start": "29340",
    "end": "37200"
  },
  {
    "text": "we can also answer them live so please send us your questions don't be shy and I think we're ready - sure throw right",
    "start": "37200",
    "end": "45030"
  },
  {
    "text": "now there we go all right thanks and so yeah my is wrinkle Hana I do a lot of no SQL work",
    "start": "45030",
    "end": "50760"
  },
  {
    "text": "at AWS I'm sure some of you who are watching the video I've seen some of my sessions at reinvent and whatnot and so",
    "start": "50760",
    "end": "57870"
  },
  {
    "text": "what we're here talking about today is actually data modeling into SQL and this is and we're gonna just jump right into",
    "start": "57870",
    "end": "63570"
  },
  {
    "text": "it I know this is a series of videos that we've done here to kind of dive into various use cases and whatnot so I",
    "start": "63570",
    "end": "69540"
  },
  {
    "text": "can explain a lot about what we're talking about this is the third or third now in the series server this was show",
    "start": "69540",
    "end": "76409"
  },
  {
    "text": "number five show number five all right yeah so go back in time and watch the",
    "start": "76409",
    "end": "81450"
  },
  {
    "text": "other one so if you want to know a little bit more about what we're talking about but this is what we're going to talk about today is a service it's called the collection rights database",
    "start": "81450",
    "end": "87630"
  },
  {
    "text": "service it's an internal service at Amazon that we use to help our Kindle",
    "start": "87630",
    "end": "94740"
  },
  {
    "text": "customers understand what collections and items within those collections actually have rights to yeah so if you",
    "start": "94740",
    "end": "101549"
  },
  {
    "text": "look at the service here it's very specific set of access patterns that we run against this has with all no SQL",
    "start": "101549",
    "end": "108090"
  },
  {
    "text": "databases when we understand the access patterns we have a better time modeling the data and so this is a really good",
    "start": "108090",
    "end": "114119"
  },
  {
    "text": "example of a service like that so what do they do with the with the collection rice database again they track the user",
    "start": "114119",
    "end": "119189"
  },
  {
    "text": "rights to objects and collections they want to authorize the access to digital media and they support the use of the",
    "start": "119189",
    "end": "125700"
  },
  {
    "text": "use of a recommendation engine right so when users go to checkout and they want to see what other items we",
    "start": "125700",
    "end": "131280"
  },
  {
    "text": "might be interested in and will consult the collection rights database to see what items and collections users",
    "start": "131280",
    "end": "136500"
  },
  {
    "text": "actually have so this is what that entity model looks like real shortly and then lower left there we have customers",
    "start": "136500",
    "end": "143459"
  },
  {
    "text": "customers own collections collections can be owned by many customers obviously and customers can own many collections",
    "start": "143459",
    "end": "148950"
  },
  {
    "text": "there's a many-to-many relationship between those two entities and then collections have items there's a one to",
    "start": "148950",
    "end": "154980"
  },
  {
    "text": "many relationship between items but customers can also own items they don't necessarily own the whole collection of",
    "start": "154980",
    "end": "160530"
  },
  {
    "text": "items they might own just a few of the items in a particular collection so there's a many-to-many between customers",
    "start": "160530",
    "end": "166770"
  },
  {
    "text": "and items and there's a one-to-many between collections and items so an interesting kind of hierarchical model there if you look at the access patterns",
    "start": "166770",
    "end": "175350"
  },
  {
    "text": "they're pretty straightforward for a given customer we want to get all of the owned items for a given collection and",
    "start": "175350",
    "end": "181860"
  },
  {
    "text": "then we want to get those items that are sorted in a couple of dimensions I was by acquisition time so when we customer",
    "start": "181860",
    "end": "188040"
  },
  {
    "text": "goes to checkout we want to know what was the most recently purchased item across all collections so maybe when we",
    "start": "188040",
    "end": "193530"
  },
  {
    "text": "do to fill out a recommendation say hey you might also be interested in or you know knowing that maybe they haven't",
    "start": "193530",
    "end": "198930"
  },
  {
    "text": "visited or seen the collection since maybe new items were added and then the",
    "start": "198930",
    "end": "204390"
  },
  {
    "text": "latest read time so we can see not only when the customer actually last acquired an item within that collection but also",
    "start": "204390",
    "end": "210329"
  },
  {
    "text": "when they last touched an item within that collection so that's an interesting access pattern so we're gonna sort the customers items and collections by",
    "start": "210329",
    "end": "218340"
  },
  {
    "text": "latest read time and then also sorted by the position of the items right so you",
    "start": "218340",
    "end": "224549"
  },
  {
    "text": "know if you think of a collection of items might be a series and you might have volume 1 volume 2 volume 3 so these",
    "start": "224549",
    "end": "231780"
  },
  {
    "text": "items have you know positions also as well so they want to get these collections sorted by position and then",
    "start": "231780",
    "end": "237900"
  },
  {
    "text": "we want to also get all the owned collections for a given user in pages it's interesting we look across our user",
    "start": "237900",
    "end": "243209"
  },
  {
    "text": "base because some users have you know potentially thousands of collections so maybe we have like you know companies",
    "start": "243209",
    "end": "248700"
  },
  {
    "text": "that or libraries for example to have a library account that might have large numbers of collections and other other",
    "start": "248700",
    "end": "254239"
  },
  {
    "text": "customers have very small number of collections and again we want those collections sorted by acquisition time",
    "start": "254239",
    "end": "259650"
  },
  {
    "text": "and by I know which which which collections customers have been reading when and",
    "start": "259650",
    "end": "265590"
  },
  {
    "text": "when they most recently read those collection right so um and again",
    "start": "265590",
    "end": "270990"
  },
  {
    "text": "obviously we're dealing with relationships and it's just kind of curious what was the main reason why",
    "start": "270990",
    "end": "276990"
  },
  {
    "text": "they decided to go with dynamodb for this oh yeah so again the this was a this is what we call tier one service",
    "start": "276990",
    "end": "283380"
  },
  {
    "text": "inside of Amazon and Amazon had a project recently to migrate all of our",
    "start": "283380",
    "end": "289200"
  },
  {
    "text": "relational workloads to no SQL technologies and our Tier one services",
    "start": "289200",
    "end": "294240"
  },
  {
    "text": "are the ones that are actually revenue generators all right so when my service is making money for Amazon we classify",
    "start": "294240",
    "end": "299610"
  },
  {
    "text": "that service as a Tier one service we have three hundred fifty some odd Tier one services and every one of those services was mandated to migrate to no",
    "start": "299610",
    "end": "306480"
  },
  {
    "text": "SQL technologies for many reasons mostly because of scale right and if you think about the Kindle service is one of our",
    "start": "306480",
    "end": "312500"
  },
  {
    "text": "fairly well scaled out services this is an example of one of these services and",
    "start": "312500",
    "end": "317730"
  },
  {
    "text": "starting to push the edge of the limits of what a relational database could provide so we ended up looking at the",
    "start": "317730",
    "end": "323760"
  },
  {
    "text": "primary driver for this with scale yeah yeah so it really goes back to the",
    "start": "323760",
    "end": "328770"
  },
  {
    "text": "original reasons why we have no sequels databases I mean internet scale and what",
    "start": "328770",
    "end": "334440"
  },
  {
    "text": "we mean by owner scale is just like not just the number of users but it's also potentially number of concurrent",
    "start": "334440",
    "end": "341040"
  },
  {
    "text": "connections number of users and that's",
    "start": "341040",
    "end": "347130"
  },
  {
    "text": "really what we get into we talk about these access patterns what we're talking about now is the shape of these patterns when we get into actually looking at how",
    "start": "347130",
    "end": "353430"
  },
  {
    "text": "we're gonna model the data what we want to think about is the velocity of those patterns right how frequently are these patterns being executed and how fast is",
    "start": "353430",
    "end": "359550"
  },
  {
    "text": "the data being requested because that makes a big difference when we start to model yeah and and and yeah from",
    "start": "359550",
    "end": "366240"
  },
  {
    "text": "everything that I see all the time it comes down to a couple of things in addition to scale right I mean its",
    "start": "366240",
    "end": "372750"
  },
  {
    "text": "performance the scale and then the cost this is the key right so it's a I talk",
    "start": "372750",
    "end": "380310"
  },
  {
    "text": "about why no SQL right it's is really why have we ever evolved our database technologies because at some point we",
    "start": "380310",
    "end": "386970"
  },
  {
    "text": "get into a situation where the data pressure on the system and this is the ability the system to process the amount",
    "start": "386970",
    "end": "392190"
  },
  {
    "text": "of data that's being asked to process at a reasonable cost or within a reasonable time when one of those dimensions is",
    "start": "392190",
    "end": "398039"
  },
  {
    "text": "broken we need to invent something and we invented no SQL technology because the relational databases were failing us",
    "start": "398039",
    "end": "403620"
  },
  {
    "text": "scale right absolutely so last two patterns to talk about here",
    "start": "403620",
    "end": "408870"
  },
  {
    "text": "basically for a given collection we might get all the customers for a given collection for a given item when I get all the customers were given item and",
    "start": "408870",
    "end": "414810"
  },
  {
    "text": "it's important to look at those patterns because those are the ones where the the number of customers that own a collection can be extremely large and",
    "start": "414810",
    "end": "421560"
  },
  {
    "text": "the number of customers owned an item within a collection can also be very very large so these are the ones where",
    "start": "421560",
    "end": "426840"
  },
  {
    "text": "we have to start worrying about scale we were just talking about scale and why do we choose no SQL you know when we start",
    "start": "426840",
    "end": "432150"
  },
  {
    "text": "talking about modeling the data we took a look at the size of the data the velocity the data the shape of the data and those queries right they're probably",
    "start": "432150",
    "end": "438630"
  },
  {
    "text": "the ones that can bring the largest result sets back and so it's interesting when you look at those queries because we have to actually account for them",
    "start": "438630",
    "end": "444599"
  },
  {
    "text": "specifically and we'll look at that when we get into the actual schema so this is",
    "start": "444599",
    "end": "449940"
  },
  {
    "text": "the schema for this table it looks like a whole lot at the beginning but again if you've been following the series you",
    "start": "449940",
    "end": "455010"
  },
  {
    "text": "know that we like to build things as single tables we like to put multiple types of items on the same table we like",
    "start": "455010",
    "end": "460140"
  },
  {
    "text": "to build partitions and a representative of the entities in our in our relationship model and we like to fill",
    "start": "460140",
    "end": "465660"
  },
  {
    "text": "those partitions with items that kind of denote the one to many and the many to many relationships here we've gotten",
    "start": "465660",
    "end": "470910"
  },
  {
    "text": "plenty of those right so yeah let's talk about what kind of partitions we've created here's the first partition we",
    "start": "470910",
    "end": "476940"
  },
  {
    "text": "have is our customer partition and within the customer partition we have a couple items we have collection items we",
    "start": "476940",
    "end": "483000"
  },
  {
    "text": "have item records collection records and item records collection records obviously describe top level collections",
    "start": "483000",
    "end": "488940"
  },
  {
    "text": "so whenever a user acquires an item an item belongs to a collection they're gonna get two items within their",
    "start": "488940",
    "end": "494130"
  },
  {
    "text": "partition one is going to be items it's the item record and the other is gonna be item that is the collection record yeah and and and also what we're doing",
    "start": "494130",
    "end": "502020"
  },
  {
    "text": "here is really we're saying we're how we're modeling this is we have a",
    "start": "502020",
    "end": "507300"
  },
  {
    "text": "partition for each entity right well we have a partition for each entity we have a partition for each customer right and",
    "start": "507300",
    "end": "515490"
  },
  {
    "text": "inside of these customer partitions were connecting the collections and the items using these edges right so this is a",
    "start": "515490",
    "end": "520860"
  },
  {
    "text": "classic what we call it and saying those are those are present relationships those represent",
    "start": "520860",
    "end": "527120"
  },
  {
    "text": "relationships and every customer on this table can have a copy or an item that indicates that he owns a particular",
    "start": "527120",
    "end": "532850"
  },
  {
    "text": "collection or particularly or an item within that collection right so again our access patterns we're get me all the",
    "start": "532850",
    "end": "539050"
  },
  {
    "text": "items the customer owns and this particular case starts with IR which is the item record prefix that we determine",
    "start": "539050",
    "end": "545450"
  },
  {
    "text": "for this particular table and customer ID equals x sort key starts with IR",
    "start": "545450",
    "end": "550760"
  },
  {
    "text": "gives me all the items the customer owns that was one of our access patterns gave me all the collections similarly give me",
    "start": "550760",
    "end": "556490"
  },
  {
    "text": "the starts with the CR on the sort key brings back all the collection items and then what we're gonna start doing is",
    "start": "556490",
    "end": "562490"
  },
  {
    "text": "indexing these items because the other items on the table we're never really selecting the collection item we're never really selecting the item item",
    "start": "562490",
    "end": "568610"
  },
  {
    "text": "right we're selecting who owns the collection who owns the items right those were the access patterns so we",
    "start": "568610",
    "end": "574130"
  },
  {
    "text": "don't really care about those those particular individual items but we do need them because we're gonna be",
    "start": "574130",
    "end": "579920"
  },
  {
    "text": "indexing you know to take you know group the customers by those particular partitions so here's how that actually",
    "start": "579920",
    "end": "586640"
  },
  {
    "text": "breaks out if you look at the first two GS is GSI one GSI two they're gonna share the same partition key and they're",
    "start": "586640",
    "end": "593060"
  },
  {
    "text": "gonna same share the same partition key is the table these could actually be LS is they don't have to be GS is I use GS",
    "start": "593060",
    "end": "598940"
  },
  {
    "text": "is in this particular case because they're flexible we can create them and delete them at any time if these access patterns change LS eyes are more rigid",
    "start": "598940",
    "end": "606200"
  },
  {
    "text": "right they're created when the table is created they can't ever be removed you know so this particular case it wasn't",
    "start": "606200",
    "end": "611420"
  },
  {
    "text": "strong consistency wasn't a big issue for us because the data is not really all that highly mutable and so we said",
    "start": "611420",
    "end": "617750"
  },
  {
    "text": "okay we'll use GS eyes and the first GSI is gonna be sorted by and I'm sorry but",
    "start": "617750",
    "end": "623120"
  },
  {
    "text": "the on my screen that's even a little small for me with classes but is that acquisition time that we're looking at there yep okay and then on the next GSI",
    "start": "623120",
    "end": "632870"
  },
  {
    "text": "GS I too will be our it would be our read time sword so GS i1 sorted by acquisition time GSI to sorted by read",
    "start": "632870",
    "end": "639500"
  },
  {
    "text": "time and every time we go and touch an item or a customer opens up their Kindle and reads a particular book then what",
    "start": "639500",
    "end": "647060"
  },
  {
    "text": "we're gonna do is update the the read time for the book and the read time for the collection that the book belongs to",
    "start": "647060",
    "end": "652280"
  },
  {
    "text": "all right so both of those queries will return and just a quick somebody's danger X",
    "start": "652280",
    "end": "662070"
  },
  {
    "text": "danger X word this is rhomin 13 danger 13 user is asking what as our",
    "start": "662070",
    "end": "669330"
  },
  {
    "text": "and CR stand for maybe okay sure say these worries so when we start to build the keys and let's go back real quick to",
    "start": "669330",
    "end": "675870"
  },
  {
    "text": "look at those when we build these sort keys what we're really doing is using those prefixes to determine what type of",
    "start": "675870",
    "end": "680940"
  },
  {
    "text": "item is this so we'll see this a lot when we create item hark hierarchies within partitions sometimes the IDS of",
    "start": "680940",
    "end": "687330"
  },
  {
    "start": "682000",
    "end": "1151000"
  },
  {
    "text": "the items are not necessarily informative dozen really tell me what the item is in our particular use case",
    "start": "687330",
    "end": "692460"
  },
  {
    "text": "we said give me all the collections for a given customer right so if I use a prefix for a collection record which is",
    "start": "692460",
    "end": "697560"
  },
  {
    "text": "CR then when I say I sort key condition starts with CR then it's gonna bring back all collection records right right",
    "start": "697560",
    "end": "703860"
  },
  {
    "text": "if I use a sort key that starts with IR then that's going to bring back all item records right so CR is a collection",
    "start": "703860",
    "end": "710280"
  },
  {
    "text": "record IR is an item record and these are just simply alphanumeric prefixes that we determined what the customer",
    "start": "710280",
    "end": "716430"
  },
  {
    "text": "would mean this type of item that type of in other words if you're modeling your own database you come up with your",
    "start": "716430",
    "end": "723120"
  },
  {
    "text": "own convention sure what makes sense and also well in terms of what kind of name",
    "start": "723120",
    "end": "728520"
  },
  {
    "text": "you want to select but also prefixing scheme to set up a hierarchy that's why",
    "start": "728520",
    "end": "735450"
  },
  {
    "text": "you set up a hierarchy using this prefixing so we use this in many ways like an example could be an event",
    "start": "735450",
    "end": "742290"
  },
  {
    "text": "collection by customer or by device and those events might have different states then state could be part of the prefix I",
    "start": "742290",
    "end": "748320"
  },
  {
    "text": "could have an info warning critical and then maybe Mysore key could be state and date give me all the critical events in",
    "start": "748320",
    "end": "756510"
  },
  {
    "text": "the last 24 hours and I could say is between critical - you know 24 hours ago",
    "start": "756510",
    "end": "761970"
  },
  {
    "text": "and critical - now Gragas or key conditions at state sortable and it's faceted and also to confirm danger 13 is",
    "start": "761970",
    "end": "770010"
  },
  {
    "text": "asking again and this is adjacency lists pattern yes so what we're talking about",
    "start": "770010",
    "end": "775680"
  },
  {
    "text": "here is adjacent silly yeah these items are actually designated there's a connection to the Winnick when a",
    "start": "775680",
    "end": "782550"
  },
  {
    "text": "customer buys an item or establishes ownership a part collection then there will be an item",
    "start": "782550",
    "end": "787900"
  },
  {
    "text": "created within their partition that describes how that connection what you know what that connection is when was",
    "start": "787900",
    "end": "793990"
  },
  {
    "text": "the last read time when was the acquisition time of the item when was the last time when was the last acquisition time of the collection right",
    "start": "793990",
    "end": "800860"
  },
  {
    "text": "those are all edges those are properties of the edge right how is the guys were related to the collection how is the",
    "start": "800860",
    "end": "805900"
  },
  {
    "text": "customer related to the item exactly so one way that that I used to distinguish what's the entity specific obviously",
    "start": "805900",
    "end": "812890"
  },
  {
    "text": "there's data here about each entity for example customer that does not involve any other entities sure and that's a tax",
    "start": "812890",
    "end": "820570"
  },
  {
    "text": "entity specific but once you have data in a record that in fact references that",
    "start": "820570",
    "end": "826990"
  },
  {
    "text": "says something about another entity and in this case it will in fact reference",
    "start": "826990",
    "end": "832300"
  },
  {
    "text": "somehow a different entity that's the relationship and that's the edge and that is the edge in this case right it",
    "start": "832300",
    "end": "838270"
  },
  {
    "text": "relates this is really an edge that connects two partitions to nodes on the graph in some way and so if you look at",
    "start": "838270",
    "end": "844090"
  },
  {
    "text": "the different types of nodes that we have created or different types of partitions we have a customer partition we have collection partitions we have",
    "start": "844090",
    "end": "849850"
  },
  {
    "text": "item partitions and what we're doing is connecting these things in various ways and we'll start to see how these",
    "start": "849850",
    "end": "856230"
  },
  {
    "text": "aggregates are performed or are created when we look at these GSIS right so in the case of you know customers with",
    "start": "856230",
    "end": "863470"
  },
  {
    "text": "centric data we're looking for collections sorted by acquisition time collections sorted by read time those",
    "start": "863470",
    "end": "870340"
  },
  {
    "text": "are just simply re sorting the data within the customers partition basically resorting the edges or the relationships",
    "start": "870340",
    "end": "875830"
  },
  {
    "text": "that the customer has with these items and collections right by dates as we get",
    "start": "875830",
    "end": "880870"
  },
  {
    "text": "into the rest of these GS is right we look at GSI 3 GSI 3 what we're doing is",
    "start": "880870",
    "end": "885970"
  },
  {
    "text": "starting to look at get me all the collections all the all the customers that own a collection now I started to",
    "start": "885970",
    "end": "891130"
  },
  {
    "text": "query across the partitions right I'm starting to look at the other side of that many-to-many right there's a many-to-many between customers and",
    "start": "891130",
    "end": "896830"
  },
  {
    "text": "collections how many many customers can own a collection and many customers can own the collection so now I need to query the other side of that that",
    "start": "896830",
    "end": "904660"
  },
  {
    "text": "relationship and so the way we're going to do that is by partitioning on a right",
    "start": "904660",
    "end": "910180"
  },
  {
    "text": "sharded key right because we have many any customers millions of customers and so as customers start to you know",
    "start": "910180",
    "end": "916110"
  },
  {
    "text": "acquire these these items within these collections that's going to build very very large partitions and so when we",
    "start": "916110",
    "end": "921810"
  },
  {
    "text": "want to query that data since dynamodb has a partition level throughput of 1,000 WCU's or 3,000 RC use as the",
    "start": "921810",
    "end": "930060"
  },
  {
    "text": "number of collections and the number of customers who own those collections increase I'm gonna have to add additional logical storage partitions to",
    "start": "930060",
    "end": "937020"
  },
  {
    "text": "be able to increase the throughput of that workload and so every time a customer buys an item this is what we're gonna end up doing is we're gonna go in",
    "start": "937020",
    "end": "943290"
  },
  {
    "text": "there we're gonna say on that right sharted key we're gonna add a partition between 0 to n depending on the size of",
    "start": "943290",
    "end": "949710"
  },
  {
    "text": "the collection every single you know some collections are more popular than others some items are much more popular",
    "start": "949710",
    "end": "955920"
  },
  {
    "text": "than others so every single collection every single item gets that first partition that zero partition and as we",
    "start": "955920",
    "end": "961980"
  },
  {
    "text": "start to as we query the zero partition inside of there there's going to be a little item on this and you can see",
    "start": "961980",
    "end": "967410"
  },
  {
    "text": "number of partitions if you look at those items down below where it says collection item or item items there's a",
    "start": "967410",
    "end": "972930"
  },
  {
    "text": "number of partitions attribute it tells you how many additional partitions there are right there's the thing about that",
    "start": "972930",
    "end": "978570"
  },
  {
    "text": "is this really kind of goes back to how important it is to know your data that's",
    "start": "978570",
    "end": "984600"
  },
  {
    "text": "correct basic right this is the velocity part right this we're saying how much data how what is the volume of the data and",
    "start": "984600",
    "end": "990360"
  },
  {
    "text": "that's the high velocity of the queries was the frequency of the query and this",
    "start": "990360",
    "end": "995760"
  },
  {
    "text": "tells us essentially how many partitions do we need to add if maybe a hundred thousand customers own a single",
    "start": "995760",
    "end": "1001730"
  },
  {
    "text": "collection then that's not too many but if a million own the same collection then maybe that is too many sure so now",
    "start": "1001730",
    "end": "1008450"
  },
  {
    "text": "we'll look at the size of the item then the the the nature of the query right",
    "start": "1008450",
    "end": "1013550"
  },
  {
    "text": "does the query want to return all that data as fast as possible does the query is the query okay to paginate through",
    "start": "1013550",
    "end": "1018860"
  },
  {
    "text": "the data can we rate limit the data so this is one of the things when you get into no SQL data modeling is extremely",
    "start": "1018860",
    "end": "1025730"
  },
  {
    "text": "important is to understand the velocity in the shape and the frequency of your access patterns and and we talked about",
    "start": "1025730",
    "end": "1031760"
  },
  {
    "text": "right sharding also we if you watched one of the previous episodes we went",
    "start": "1031760",
    "end": "1037490"
  },
  {
    "text": "over that pattern but it's also in the documentation if you go to the section about best practices",
    "start": "1037490",
    "end": "1043938"
  },
  {
    "text": "dynamodb documentation you'll find more right snorting and also what the",
    "start": "1043939",
    "end": "1049730"
  },
  {
    "text": "limitations are around partitions you know as as you know already right each",
    "start": "1049730",
    "end": "1057529"
  },
  {
    "text": "partition can only support so much both in terms of data volume and reads and",
    "start": "1057529",
    "end": "1063559"
  },
  {
    "text": "writes and so for writes we talk about partition limits of 1,000 write capacity",
    "start": "1063559",
    "end": "1069200"
  },
  {
    "text": "units per petition tree and also 3,000 and read capacity units per petition",
    "start": "1069200",
    "end": "1075259"
  },
  {
    "text": "this is why we sometimes need to introduce right sharding when we know",
    "start": "1075259",
    "end": "1080539"
  },
  {
    "text": "that these limits will get exceeded and that was the case in this particular speaker query because when they wanted",
    "start": "1080539",
    "end": "1086809"
  },
  {
    "text": "to go get all of the users that owned a given item or all of the users to own a",
    "start": "1086809",
    "end": "1091820"
  },
  {
    "text": "given collection they needed to return that data as fast as possible so in this particular case there was a need to be",
    "start": "1091820",
    "end": "1098210"
  },
  {
    "text": "able to potentially scan in parallel more than one partition because if millions of customers owned the same",
    "start": "1098210",
    "end": "1104179"
  },
  {
    "text": "collection then they couldn't it would have to paginate through the day they would take multiple seconds to return the data right and and by the way when",
    "start": "1104179",
    "end": "1111500"
  },
  {
    "text": "you are querying you can see what the consume read capacity is and you can use",
    "start": "1111500",
    "end": "1116870"
  },
  {
    "text": "that to essentially limit the rate at which you I was bragging and that's a",
    "start": "1116870",
    "end": "1122480"
  },
  {
    "text": "good point I mean oftentimes people ask me how do I rate limit my processes if",
    "start": "1122480",
    "end": "1127669"
  },
  {
    "text": "you turn on the returned consume capacity and drivers you can keep a running total of the last seconds worth",
    "start": "1127669",
    "end": "1134960"
  },
  {
    "text": "of consumed capacity just by maintaining a counter in the application and then that way you can kind of know when to",
    "start": "1134960",
    "end": "1141019"
  },
  {
    "text": "pause or so to speak or rate limit yourself so oftentimes I'll do that with certain processes absolutely all right",
    "start": "1141019",
    "end": "1147799"
  },
  {
    "text": "so this there's there's the the third GSI and then the fourth GSI again is going to be sorted being sorting the",
    "start": "1147799",
    "end": "1153110"
  },
  {
    "start": "1151000",
    "end": "1502000"
  },
  {
    "text": "items of customer owns within a collection by position so again we're gonna go to the customer key and",
    "start": "1153110",
    "end": "1159799"
  },
  {
    "text": "collection ID and then sorting individualized by position because we want to get those customer ions by collection by position all right so",
    "start": "1159799",
    "end": "1166809"
  },
  {
    "text": "let's take a look at what those indexes actually look like when we go to query those things again if we go to our first",
    "start": "1166809",
    "end": "1173480"
  },
  {
    "text": "GSI one and two there's the acquisition time and the read indexes same partition key is a table",
    "start": "1173480",
    "end": "1179059"
  },
  {
    "text": "querying by customer key we can start with CR gives us the cuz collection",
    "start": "1179059",
    "end": "1184549"
  },
  {
    "text": "records by acquisition time so the key the query here is actually a limit query where they're gonna say give me the most",
    "start": "1184549",
    "end": "1190549"
  },
  {
    "text": "recently accessed collection they don't care about the actual sorted order of collections they want to what was the",
    "start": "1190549",
    "end": "1196070"
  },
  {
    "text": "one you'll most recently touched right so to say starts with CR limit one comes back with this just the top you know the",
    "start": "1196070",
    "end": "1202220"
  },
  {
    "text": "one that most recently took same things with items within a collection starts with collection key and the other limit",
    "start": "1202220",
    "end": "1208309"
  },
  {
    "text": "one right and that gives me the item within a collection right and then same thing for read time when was last time",
    "start": "1208309",
    "end": "1214340"
  },
  {
    "text": "he read something within the collection was last time you read an item will use those same keys key queries here to",
    "start": "1214340",
    "end": "1220639"
  },
  {
    "text": "return those moving on to our GSI three and four which is our collection and",
    "start": "1220639",
    "end": "1225980"
  },
  {
    "text": "position indexes items by collection and and whatnot this is where we that GSI",
    "start": "1225980",
    "end": "1232039"
  },
  {
    "text": "three is our right Sharda GSI so when I want to get all of the customers who own a given collection the first thing I'm",
    "start": "1232039",
    "end": "1237620"
  },
  {
    "text": "going to do is query collection key pipe zero which is the zero partition everything has a zero partition and",
    "start": "1237620",
    "end": "1242779"
  },
  {
    "text": "what's going to come back from that is interesting because we're gonna get not only all of the customers that own those",
    "start": "1242779",
    "end": "1248029"
  },
  {
    "text": "collections their latest acquisition time latest read time in those collections but we're also going to get",
    "start": "1248029",
    "end": "1253039"
  },
  {
    "text": "the collection item because that's what exists in the zero partition and that collection item is gonna have that",
    "start": "1253039",
    "end": "1258620"
  },
  {
    "text": "little attribute in this case a how many additional items do we do it's actually just metadata right its metadata",
    "start": "1258620",
    "end": "1265370"
  },
  {
    "text": "describes the collection and describes the number of partitions that are required to hold this aggregated data",
    "start": "1265370",
    "end": "1270500"
  },
  {
    "text": "right and so I'll read that zero partition it'll come back with that first item the first item I process will tell me how many additional partitions",
    "start": "1270500",
    "end": "1276950"
  },
  {
    "text": "so the application layer they'll get that item and they'll say oh let me spin off an additional two three four processes depending on how many if it's",
    "start": "1276950",
    "end": "1283880"
  },
  {
    "text": "one of our more popular collections and they might have actually spread out those users across a larger number of",
    "start": "1283880",
    "end": "1290450"
  },
  {
    "text": "collections right our larger number of partitions same thing goes with items if",
    "start": "1290450",
    "end": "1295690"
  },
  {
    "text": "an item within a collection is extremely popular we're gonna have to shard that item out across multiple partitions but",
    "start": "1295690",
    "end": "1301279"
  },
  {
    "text": "every item will have that initial partition the zero partition which contains the metadata item which informs",
    "start": "1301279",
    "end": "1307279"
  },
  {
    "text": "the application any additional partitions to read so that's kind of how the data lays out on the on that GSI and then GSI for again",
    "start": "1307279",
    "end": "1314460"
  },
  {
    "text": "very straightforward by collection by position for a given customer writes a",
    "start": "1314460",
    "end": "1319919"
  },
  {
    "text": "customer key collection key is our partition key and then the soar key is the partition of the given item so these",
    "start": "1319919",
    "end": "1327299"
  },
  {
    "text": "query out fairly straightforward on the one we just described the right charted partition always query the zero",
    "start": "1327299",
    "end": "1333000"
  },
  {
    "text": "partition and follow up with additional partitions if necessary same thing for items and then the",
    "start": "1333000",
    "end": "1338580"
  },
  {
    "text": "attributes that we have in fact in these GSIS are essentially attributes that we",
    "start": "1338580",
    "end": "1344549"
  },
  {
    "text": "need to have for the given view right the application yeah if some of these say and these items are actually partial",
    "start": "1344549",
    "end": "1351150"
  },
  {
    "text": "views this schema is partial views there's extended attributes on all these items and it's irrelevant to the query so I'm not showing those in this actual",
    "start": "1351150",
    "end": "1357390"
  },
  {
    "text": "schema these eyes are a little larger than what we're seeing here not much that there's you know a good half a dozen other",
    "start": "1357390",
    "end": "1363330"
  },
  {
    "text": "attributes exist on all these items that are really irrelevant or yeah the really cool thing about dynamos DynamoDB GS",
    "start": "1363330",
    "end": "1370470"
  },
  {
    "text": "eyes with global secondary indexes is that you can tailor those views to",
    "start": "1370470",
    "end": "1376010"
  },
  {
    "text": "projections for your GSIS to match the view that you really need for your",
    "start": "1376010",
    "end": "1381150"
  },
  {
    "text": "application right and each view though each projection or HGS I should say also",
    "start": "1381150",
    "end": "1386400"
  },
  {
    "text": "will always have the primary key from the table of project it yes and so",
    "start": "1386400",
    "end": "1392070"
  },
  {
    "text": "sometimes you need that right yeah sometimes you need that absolutely and and you can choose to project some or",
    "start": "1392070",
    "end": "1398220"
  },
  {
    "text": "all of the attributes from your other from the primary table into the GSI so it's a good point because sometimes the",
    "start": "1398220",
    "end": "1404100"
  },
  {
    "text": "items that you're storing on the table are relatively large but the access pattern that I need to go look up",
    "start": "1404100",
    "end": "1409320"
  },
  {
    "text": "against doesn't need all of the data in that item and so it's sometimes often it's much more cost efficient to project",
    "start": "1409320",
    "end": "1416970"
  },
  {
    "text": "only some of the attributes onto the GSI because when I actually go to query that GSI that pattern only needs a subset of",
    "start": "1416970",
    "end": "1422909"
  },
  {
    "text": "attributes and maybe there's you know 100 kilobytes of data that I'm leaving on the table that's wcu cost that's RCU cost that",
    "start": "1422909",
    "end": "1430260"
  },
  {
    "text": "storage cost and that's doubling all that cost if I if I project everything to the GSI whereas if I maybe carve out",
    "start": "1430260",
    "end": "1437880"
  },
  {
    "text": "the big data and leave that sitting on the tape and the whatsits on the index is a subset of that data it's gonna cost me",
    "start": "1437880",
    "end": "1443620"
  },
  {
    "text": "less to store it's gonna cost me less to query it again it's also important to understand the access patterns in detail",
    "start": "1443620",
    "end": "1450399"
  },
  {
    "text": "when you're when you're designing your new SQL schema all these reasons and I",
    "start": "1450399",
    "end": "1455440"
  },
  {
    "text": "think my rule of thumb is usually if it's a read heavy read oriented use case you will benefit from it from a GSI",
    "start": "1455440",
    "end": "1462789"
  },
  {
    "text": "that's tailored for those reads and and then your queries really just use that",
    "start": "1462789",
    "end": "1469840"
  },
  {
    "text": "GSI that's right the idea is you use a single materialized view whether it's a",
    "start": "1469840",
    "end": "1474909"
  },
  {
    "text": "table or a GSI to get your data that's right your access pattern knows what index it needs to query to get the data",
    "start": "1474909",
    "end": "1481450"
  },
  {
    "text": "right you're structuring the indexes to support those secondary access patterns that's how no SQL works it's actually",
    "start": "1481450",
    "end": "1487299"
  },
  {
    "text": "you know it works most efficiently when when the when they when the developer",
    "start": "1487299",
    "end": "1492460"
  },
  {
    "text": "decides which table which index the query absolutely right alright so let's",
    "start": "1492460",
    "end": "1497620"
  },
  {
    "text": "get back to the the mapping of our data and our access patterns to our query",
    "start": "1497620",
    "end": "1503010"
  },
  {
    "text": "patterns here this is what we end up with at the end of every phase so if you kind of if you're those of you have been",
    "start": "1503010",
    "end": "1508029"
  },
  {
    "text": "watching our series here understand that we have a pretty straightforward process to how we develop no SQL applications",
    "start": "1508029",
    "end": "1514299"
  },
  {
    "text": "right we're gonna you know we're going to define the entity relationship model we're gonna identify the access patterns",
    "start": "1514299",
    "end": "1519760"
  },
  {
    "text": "we're gonna characterize those patterns then we're gonna denormalize the the model to support those access patterns",
    "start": "1519760",
    "end": "1525130"
  },
  {
    "text": "and in the end what we're gonna do is line up the queries to each individual pattern so this is what we've done we",
    "start": "1525130",
    "end": "1530230"
  },
  {
    "text": "had you know we described any relationship model we gave you a table of access patterns we're gonna extend the table and tell you okay now which",
    "start": "1530230",
    "end": "1536440"
  },
  {
    "text": "table or GSI are we gonna queries to support this pattern which sort key conditions we are which partition of",
    "start": "1536440",
    "end": "1542919"
  },
  {
    "text": "primary key conditions between the partition key and the sort key if there's any extended filter conditions",
    "start": "1542919",
    "end": "1548620"
  },
  {
    "text": "in this particular use case there were no filter conditions and many use cases where we end up applying filter conditions and as a matter of fact I",
    "start": "1548620",
    "end": "1555370"
  },
  {
    "text": "think in our next example that I'm going to be here for we'll talk a little bit about that right when when filter",
    "start": "1555370",
    "end": "1560529"
  },
  {
    "text": "conditions are just as effective as selective indexes and why filter conditions can save you a lot of money",
    "start": "1560529",
    "end": "1566559"
  },
  {
    "text": "even though the reads can be fatter so but in this particular case what we have is a collection of our access patterns",
    "start": "1566559",
    "end": "1572940"
  },
  {
    "text": "for a given customer gave me all the collections sorted on these dimensions given given all the owned items sorted",
    "start": "1572940",
    "end": "1578280"
  },
  {
    "text": "on these dimensions and then again for a given collection all the customers give me a given item all the customers and that's the on the right two columns",
    "start": "1578280",
    "end": "1585059"
  },
  {
    "text": "those are the tables and the and the query conditions that we're gonna execute to satisfy each one of those queries and this is how we know in the",
    "start": "1585059",
    "end": "1592230"
  },
  {
    "text": "end that we have addressed every single one of the access patterns and if you want to know where do you get the access",
    "start": "1592230",
    "end": "1597690"
  },
  {
    "text": "patterns these access patterns are really they're distilled from the user stories which would make up the",
    "start": "1597690",
    "end": "1603840"
  },
  {
    "text": "requirements of your application right so you just want a user story is gonna tell you how you're gonna be accessing",
    "start": "1603840",
    "end": "1609900"
  },
  {
    "text": "the data each one of those things defines the access patterns against the data I can go through every one of the",
    "start": "1609900",
    "end": "1615690"
  },
  {
    "text": "user stories that we've accepted for a given you know a sprint and given you",
    "start": "1615690",
    "end": "1621030"
  },
  {
    "text": "know version of the product and and define this exact table to show the team exactly how they're gonna be using their",
    "start": "1621030",
    "end": "1627360"
  },
  {
    "text": "data it's extremely effective process and a good tool to do that right and in",
    "start": "1627360",
    "end": "1632790"
  },
  {
    "start": "1632000",
    "end": "1710000"
  },
  {
    "text": "this case we have three distinct GS eyes correct and these days for is that right",
    "start": "1632790",
    "end": "1638640"
  },
  {
    "text": "oh yeah yeah and so yeah used to be that you can only have five right now that",
    "start": "1638640",
    "end": "1645870"
  },
  {
    "text": "limit has been raised to 24 right so you can really go beyond just a few GS eyes",
    "start": "1645870",
    "end": "1653309"
  },
  {
    "text": "and keep creating new materialized views that may be new or it quite a busy that's also true but if you live in the",
    "start": "1653309",
    "end": "1658830"
  },
  {
    "text": "schema we actually overloaded this yes I know yes yes I agree is used for multiple access patterns right GSI is",
    "start": "1658830",
    "end": "1666240"
  },
  {
    "text": "one and two or do singles for multiple access patterns as well because again both the collection and the items are",
    "start": "1666240",
    "end": "1672540"
  },
  {
    "text": "being indexed by acquisition time and by read time right yeah and we're reusing the acquisition time GSI and the read",
    "start": "1672540",
    "end": "1679559"
  },
  {
    "text": "time GSI for both collections and items right so there's two overloaded patterns on each one of those if we were to index",
    "start": "1679559",
    "end": "1686160"
  },
  {
    "text": "those individually that would be four GS is instead of two same thing for this GSI three that could be another 2 GS",
    "start": "1686160",
    "end": "1692940"
  },
  {
    "text": "eyes so if we had if we had instead of using GSI overloading right if we had just gone ahead and",
    "start": "1692940",
    "end": "1698810"
  },
  {
    "text": "indexed the actual fully named attributes associated collections and and and and items we would end up with",
    "start": "1698810",
    "end": "1705410"
  },
  {
    "text": "seven GS is yeah so we reduced GS eyes by three using overloading right right",
    "start": "1705410",
    "end": "1710450"
  },
  {
    "text": "and that's really one of the advantages of flexible schema with no sequel and",
    "start": "1710450",
    "end": "1716750"
  },
  {
    "text": "and you know what's funny when when we talk with people who are used to relational databases and strict you know",
    "start": "1716750",
    "end": "1723650"
  },
  {
    "text": "enforcement schema and so so on you know for them it's unusual it almost seems",
    "start": "1723650",
    "end": "1729530"
  },
  {
    "text": "kind of hacky like to be using these conditions that are all but that's",
    "start": "1729530",
    "end": "1734600"
  },
  {
    "text": "really the the nature of no sequel it's the flexibility that you get and and it",
    "start": "1734600",
    "end": "1739940"
  },
  {
    "text": "really allows you to control different access patterns in your application",
    "start": "1739940",
    "end": "1745760"
  },
  {
    "text": "rather than in the database itself it's a it's a thing to understand is that you",
    "start": "1745760",
    "end": "1751640"
  },
  {
    "text": "know with relational databases were used to tables that have homogenous you know collections of items and we're gonna use",
    "start": "1751640",
    "end": "1758840"
  },
  {
    "text": "an ad hoc query engine to join the data to produce the views with no SQL what",
    "start": "1758840",
    "end": "1764300"
  },
  {
    "text": "we're doing is we're creating collections that have a heterogeneous you know set of items and then we're",
    "start": "1764300",
    "end": "1769700"
  },
  {
    "text": "gonna use indexes to group those items and produce the joins that we would have produced with the relational database so",
    "start": "1769700",
    "end": "1775670"
  },
  {
    "text": "it's actually the mechanism is actually much more simple from a querying",
    "start": "1775670",
    "end": "1780710"
  },
  {
    "text": "perspective because now instead of having to have join queries which cost me a lot of CPU all I hear filter",
    "start": "1780710",
    "end": "1786440"
  },
  {
    "text": "queries filter expressions select star from where x equals there's anybody who works with relational databases is going",
    "start": "1786440",
    "end": "1793040"
  },
  {
    "text": "to tell you wow that's a much simpler query than even joining two tables this is why no SQL database is scale beyond",
    "start": "1793040",
    "end": "1800630"
  },
  {
    "text": "the the level of relational databases but it's also one of the reasons why they don't support those ad hoc queries",
    "start": "1800630",
    "end": "1807410"
  },
  {
    "text": "and the unknown access pattern so it's important to understand the workload in this particular use case what we just",
    "start": "1807410",
    "end": "1812630"
  },
  {
    "text": "described is a very transactional workload but it's an OLTP application these access patterns will not change",
    "start": "1812630",
    "end": "1819050"
  },
  {
    "text": "and they're always going to execute the exact same way so we can build a data structure that services that but if",
    "start": "1819050",
    "end": "1825350"
  },
  {
    "text": "somebody comes along tomorrow and says hey you know I got a a totally new pattern against this data and I don't want do those patterns",
    "start": "1825350",
    "end": "1830820"
  },
  {
    "text": "anymore and now sudden we're broken right so it's important to understand",
    "start": "1830820",
    "end": "1836250"
  },
  {
    "text": "the nature of your application the nature of the access patterns and in detail now one last thing to talk about",
    "start": "1836250",
    "end": "1841560"
  },
  {
    "start": "1840000",
    "end": "1943000"
  },
  {
    "text": "this scheme as we just talked about we had you know we got 4G sis we're sorting on multiple dimensions so how could it",
    "start": "1841560",
    "end": "1847710"
  },
  {
    "text": "possibly be better than what we just did right I mean since I just showed you with overloading we went from 7gs eyes",
    "start": "1847710",
    "end": "1853380"
  },
  {
    "text": "to four and so how might we be able to do this better and and this this is",
    "start": "1853380",
    "end": "1859020"
  },
  {
    "text": "something we actually as we went through this iterative process is the other thing we talked about when you're developing a new SQL data model it's not",
    "start": "1859020",
    "end": "1865350"
  },
  {
    "text": "a you know lowest common denominator and we're done it's an iterative process man",
    "start": "1865350",
    "end": "1871620"
  },
  {
    "text": "and so one of the things we did to optimize this model in discussion was to come back and say hey look the primary",
    "start": "1871620",
    "end": "1876960"
  },
  {
    "text": "table was using a full you know the composite key for items on the primary table was using the item ID and we had a",
    "start": "1876960",
    "end": "1882870"
  },
  {
    "text": "use case that says get the items sorted by position well position is unique within a collection so I don't",
    "start": "1882870",
    "end": "1888180"
  },
  {
    "text": "necessarily need to use item ID to find uniqueness I can actually use position so when we define the item that is owned",
    "start": "1888180",
    "end": "1893790"
  },
  {
    "text": "when we add winning when a customer buys the item and establishes the edge that connects them to the item instead of",
    "start": "1893790",
    "end": "1899370"
  },
  {
    "text": "using the item ID in the store key I use the items position and that eliminates dsi for because now when I say select",
    "start": "1899370",
    "end": "1905790"
  },
  {
    "text": "star from table where customer ID equals X starts with IR guess what all the items come back and sort in order by",
    "start": "1905790",
    "end": "1911910"
  },
  {
    "text": "collection right and that's next another thing about sort keys right I'll always basically give you the ability to to",
    "start": "1911910",
    "end": "1920090"
  },
  {
    "text": "group your data the way the way you want right way exactly one that's exactly",
    "start": "1920090",
    "end": "1925350"
  },
  {
    "text": "right and in this particular case but yeah we went now we went from for geo size to 3GS eyes that's huge because",
    "start": "1925350",
    "end": "1930840"
  },
  {
    "text": "again less wcu less storage cost right then the RC use are the same because",
    "start": "1930840",
    "end": "1936420"
  },
  {
    "text": "we're hitting the data from the table instead of the GSI but I don't have to do that I don't have to replicate the data and pay for twice the storage and",
    "start": "1936420",
    "end": "1942510"
  },
  {
    "text": "twice the donors and while this might not matter early on in your basically",
    "start": "1942510",
    "end": "1947600"
  },
  {
    "start": "1943000",
    "end": "2021000"
  },
  {
    "text": "application or business when you're not scaled out once you start scaling out these all these things add up",
    "start": "1947600",
    "end": "1953970"
  },
  {
    "text": "oh yeah and tremendously so right I mean this is these can be enormous cost so if",
    "start": "1953970",
    "end": "1959130"
  },
  {
    "text": "you think about if I have a well provisioned at a hundred thousand WCU's and and I put a GSI up on that",
    "start": "1959130",
    "end": "1965510"
  },
  {
    "text": "table and you know what 90% of those items or even 100% of those items translate to the GSI what have I done",
    "start": "1965510",
    "end": "1970520"
  },
  {
    "text": "now I need a GSI add a hundred thousand WCU's that's a big GSI that's a lot of",
    "start": "1970520",
    "end": "1976010"
  },
  {
    "text": "workload if I can satin use the same table to satisfy multiple access patterns in this case gave me all the",
    "start": "1976010",
    "end": "1981830"
  },
  {
    "text": "items of customer owns and get me all the items of customer no sorted by position use the same data on the same",
    "start": "1981830",
    "end": "1987080"
  },
  {
    "text": "table I have to the wcu cost and have to the storage cost and in fact that kind",
    "start": "1987080",
    "end": "1992750"
  },
  {
    "text": "of really touches on a question from the user Kay Falc who says I'm trying to understand the",
    "start": "1992750",
    "end": "1999110"
  },
  {
    "text": "value of single field design now that transactions are available in my own design single table design helps me get",
    "start": "1999110",
    "end": "2005950"
  },
  {
    "text": "parent and children in one query but I might as well make a simultaneous get item for the parent and query for the",
    "start": "2005950",
    "end": "2013180"
  },
  {
    "text": "children so is it actually just as efficient to just use a separate table for each entity am I missing something",
    "start": "2013180",
    "end": "2020050"
  },
  {
    "text": "well so you just you just answered your own question because you say you know I it wouldn't be just as efficient to make",
    "start": "2020050",
    "end": "2027190"
  },
  {
    "start": "2021000",
    "end": "2081000"
  },
  {
    "text": "two queries instead of one no it's not it's like the twice as efficient to use",
    "start": "2027190",
    "end": "2033580"
  },
  {
    "text": "ran query right so and this is the key to signal table designs right we wanted what query for the hierarchy of items",
    "start": "2033580",
    "end": "2039790"
  },
  {
    "text": "were like query for the collections of items I'll make one round trip to the database if I start to spread the data out across multiple tables I have to",
    "start": "2039790",
    "end": "2046630"
  },
  {
    "text": "make multiple queries and oftentimes when I make those multiple queries they cannot even be done in parallel so",
    "start": "2046630",
    "end": "2051730"
  },
  {
    "text": "although I might be able to say give me all the orders for a customer in parallel it would be very difficult to",
    "start": "2051730",
    "end": "2056919"
  },
  {
    "text": "say get me all the orders for a customer all the items on those orders all the invoices for those orders and all the bills that were ever paid all in one",
    "start": "2056919",
    "end": "2063850"
  },
  {
    "text": "query right you would never be able to do that you would have to get the orders and the customers you could do that in parallel then I would iterate through",
    "start": "2063850",
    "end": "2070060"
  },
  {
    "text": "the orders result set and query the order items table for every single order",
    "start": "2070060",
    "end": "2075100"
  },
  {
    "text": "then I would have to query the bills table for every single bill the exactly yeah and these queries quickly",
    "start": "2075100",
    "end": "2082908"
  },
  {
    "start": "2081000",
    "end": "2125000"
  },
  {
    "text": "go from from basically doing a single query for the entire data set including relationships and everything N squared",
    "start": "2082909",
    "end": "2089270"
  },
  {
    "text": "it's a dozens or it doesn't settle down through a complex hierarchy right it's one thing if you have just a one single",
    "start": "2089270",
    "end": "2095720"
  },
  {
    "text": "simple parent-child but what if I have parent-child the child the child where I have many too many or I have you know",
    "start": "2095720",
    "end": "2101420"
  },
  {
    "text": "again it just becomes a nightmare of trying to manage you know the explosion",
    "start": "2101420",
    "end": "2106430"
  },
  {
    "text": "of queries that you're gonna have to execute bottom line normalized data models belong in a relational database",
    "start": "2106430",
    "end": "2112010"
  },
  {
    "text": "context where I have an ad hoc query engine that is capable of doing joins if you cannot do joins efficiently then you",
    "start": "2112010",
    "end": "2118070"
  },
  {
    "text": "should not be you know modeling your data in a normalized manner that's just a fundamental principle of no SQL danger",
    "start": "2118070",
    "end": "2124520"
  },
  {
    "text": "thirteen says aren't index is basically pre-calculated joins yes or how we",
    "start": "2124520",
    "end": "2131720"
  },
  {
    "text": "produce joins in new SQL that's a very astute observation race is what we do we create a table with heterogeneous",
    "start": "2131720",
    "end": "2137120"
  },
  {
    "text": "results those those heterogeneous items those items share attributes is that",
    "start": "2137120",
    "end": "2142370"
  },
  {
    "text": "those indexed attributes share values and that's how we're gonna join those items together to satisfy and you can",
    "start": "2142370",
    "end": "2147920"
  },
  {
    "text": "almost look at the table as your first index a that's an inverted index partitions and we load items into those",
    "start": "2147920",
    "end": "2153350"
  },
  {
    "text": "partitions we're sharing the share partition key attribute that equals x if",
    "start": "2153350",
    "end": "2159410"
  },
  {
    "start": "2159000",
    "end": "2220000"
  },
  {
    "text": "you're looking at a many-to-many relationship one side of that relationship one view materialized views",
    "start": "2159410",
    "end": "2164690"
  },
  {
    "text": "are presented provided by the table itself and the other one by that by the GSI writes and and you can almost see",
    "start": "2164690",
    "end": "2170870"
  },
  {
    "text": "and this is why fundamentally this is why you know when people start talking about the differences between a document",
    "start": "2170870",
    "end": "2176960"
  },
  {
    "text": "store and in a wide column store it tells me that they really don't understand no SQL very well because a",
    "start": "2176960",
    "end": "2182930"
  },
  {
    "text": "document store is an indexed partition key only table and there they are the same right you know by default the",
    "start": "2182930",
    "end": "2189050"
  },
  {
    "text": "document store supports a key value access pattern which is the document ID get me that and if I want anything else",
    "start": "2189050",
    "end": "2194660"
  },
  {
    "text": "I add indexes yeah a partition key table does the exact same thing get me the anything gave me the item that has a",
    "start": "2194660",
    "end": "2200270"
  },
  {
    "text": "partition key of X right the only difference between a wide column in a document store is that the Y column store allows you to create a sort key on",
    "start": "2200270",
    "end": "2206450"
  },
  {
    "text": "the table which turns to the table into the first inverted index and in a document store actually I have",
    "start": "2206450",
    "end": "2211680"
  },
  {
    "text": "to define an inverted index on the document collection but there other than that there's no difference between the",
    "start": "2211680",
    "end": "2217560"
  },
  {
    "text": "two and the data models are exactly the same an actor chord they're they're essentially what we call if you will in",
    "start": "2217560",
    "end": "2223320"
  },
  {
    "start": "2220000",
    "end": "2229000"
  },
  {
    "text": "a theory of no sequel databases they're both key value that's great a basis absolutely and what distinguishes them",
    "start": "2223320",
    "end": "2230400"
  },
  {
    "start": "2229000",
    "end": "2284000"
  },
  {
    "text": "it's just different API so that's correct one focuses on basically document access patterns and and the",
    "start": "2230400",
    "end": "2237780"
  },
  {
    "text": "other one basically really focuses on kind of column based you know there is",
    "start": "2237780",
    "end": "2246090"
  },
  {
    "text": "no such thing as a document access pattern or a wide column access pattern that's just the data structure that",
    "start": "2246090",
    "end": "2251790"
  },
  {
    "text": "holds the data yeah yeah well the query API you know granted there's differences",
    "start": "2251790",
    "end": "2258750"
  },
  {
    "text": "in the query API and functionality the query API is and all this right regardless but there's a there's",
    "start": "2258750",
    "end": "2264150"
  },
  {
    "text": "certainly a the fundamental data modelling between the two you know the document store why com'st stored they",
    "start": "2264150",
    "end": "2271110"
  },
  {
    "text": "are the exactly the same and I will model the data exactly the same right is exactly the same tenants and will use",
    "start": "2271110",
    "end": "2276180"
  },
  {
    "text": "exactly the same process and procedures and in the end this shape of the data will be exactly the same exactly alright",
    "start": "2276180",
    "end": "2282720"
  },
  {
    "text": "so for more information we've got to obviously online we have some good stuff for you DynamoDB design patterns best",
    "start": "2282720",
    "end": "2288900"
  },
  {
    "start": "2284000",
    "end": "2336000"
  },
  {
    "text": "practices that's part of our documentation I definitely recommend anyone go search for that we just we",
    "start": "2288900",
    "end": "2294660"
  },
  {
    "text": "describe in detail all these patterns we talked about right right sharding GSI overloading vertical partitioning you",
    "start": "2294660",
    "end": "2301680"
  },
  {
    "text": "know all the things we just mentioned in this discussion today are described in detail on the online there and the best",
    "start": "2301680",
    "end": "2307020"
  },
  {
    "text": "practices and then of course there's the session I did last reinvent last November on the advanced design patterns",
    "start": "2307020",
    "end": "2313530"
  },
  {
    "text": "for dynamodb we talked a lot about how we break down this entity relationship model and take that data and move it into a shape and a structure that",
    "start": "2313530",
    "end": "2322070"
  },
  {
    "text": "represents the relationships that you need to support your applications access patterns because again all the data is",
    "start": "2322070",
    "end": "2327870"
  },
  {
    "text": "relational just because it's a no SQL database doesn't mean we don't have any relational data here if it wasn't",
    "start": "2327870",
    "end": "2332970"
  },
  {
    "text": "relational we wouldn't care about so that's what I got for you if there's anything else by",
    "start": "2332970",
    "end": "2338080"
  },
  {
    "start": "2336000",
    "end": "2380000"
  },
  {
    "text": "our way we've got some time here if anyone would have any additional questions and then that would go from there right and I'm just checking the",
    "start": "2338080",
    "end": "2346440"
  },
  {
    "text": "chat room here let's see real quick all",
    "start": "2346440",
    "end": "2352540"
  },
  {
    "text": "right could you please discuss some strategies for write heavy items sure now that's a really good question as a",
    "start": "2352540",
    "end": "2358450"
  },
  {
    "text": "matter of fact is winte yeah well it's like when you optimize for the read versus the right and this question came",
    "start": "2358450",
    "end": "2363460"
  },
  {
    "text": "from Rack sackcloth okay so right sharding is really the the",
    "start": "2363460",
    "end": "2371230"
  },
  {
    "text": "strategy of choice food for high high velocity right workloads right so and then again they velocity or is it about",
    "start": "2371230",
    "end": "2380230"
  },
  {
    "text": "right heavy he has he has actually a concrete example if for instance a post it receives a high volume uploads in a",
    "start": "2380230",
    "end": "2387040"
  },
  {
    "text": "short period of time the read pattern requires is to show the current number of up votes key scattering is often",
    "start": "2387040",
    "end": "2393310"
  },
  {
    "text": "recommended however do I initialize every single item scattered across multiple items okay should I scale the",
    "start": "2393310",
    "end": "2399490"
  },
  {
    "text": "number of items dynamically keep in mind this is under load imagine a popular reddit post yeah sure",
    "start": "2399490",
    "end": "2405250"
  },
  {
    "text": "so yeah we actually have this problem we did tracking variety scenarios with you know product product out downloads for",
    "start": "2405250",
    "end": "2412840"
  },
  {
    "text": "Kindle and and Amazon music whatnot likes or likes and whatnot and so",
    "start": "2412840",
    "end": "2418690"
  },
  {
    "text": "typically what we're dealing here is a situation where you have a high velocity counter the value of the counter",
    "start": "2418690",
    "end": "2424330"
  },
  {
    "text": "instantaneously in the accuracy of that counter is irrelevant because it's changing at a high frequency so really",
    "start": "2424330",
    "end": "2429490"
  },
  {
    "text": "what we want to do is capture a read of the counter that is relatively that is relative to the state at the time that",
    "start": "2429490",
    "end": "2435520"
  },
  {
    "text": "the query was made okay and so what we're doing here is I've got some high velocity right pattern on the table",
    "start": "2435520",
    "end": "2440620"
  },
  {
    "text": "every time some I you know an update comes in or a response comes in on a post or a thread we're gonna go ahead",
    "start": "2440620",
    "end": "2447280"
  },
  {
    "text": "and use right sharding on the table to distribute those posts and those around the around a set of partitions to support the workload in these cases",
    "start": "2447280",
    "end": "2454540"
  },
  {
    "text": "understand that you're gonna get a thousand writes per second most these posts are gonna be probably under a kilobyte and even the busiest of busy",
    "start": "2454540",
    "end": "2460990"
  },
  {
    "text": "threads is unlikely to start exceeding much more than a thousand or 2,000 post a second so we're gonna be distributing these",
    "start": "2460990",
    "end": "2467470"
  },
  {
    "text": "rights across the small number of partitions but the problem is that counter right that counter is going to be taking an update for every single",
    "start": "2467470",
    "end": "2473830"
  },
  {
    "start": "2468000",
    "end": "2514000"
  },
  {
    "text": "time a post gets made right so how do we maintain the counter so the way to do this is actually by leveraging lambo",
    "start": "2473830",
    "end": "2480070"
  },
  {
    "text": "right we're gonna put a lambda function out there as these post read and the stream we're gonna read the data off the stream and then this lambda functions",
    "start": "2480070",
    "end": "2486250"
  },
  {
    "text": "gonna maintain some internal counters and then they're just gonna dump that it's gonna dump that counter it out to the table you know honest like every",
    "start": "2486250",
    "end": "2492940"
  },
  {
    "text": "five seconds or so just to decrease the key pressure on the counter metadata alright so this is what we do with",
    "start": "2492940",
    "end": "2499110"
  },
  {
    "text": "Amazon music when Amazon music you know it's songs are being downloaded you know when they're when popular songs start",
    "start": "2499110",
    "end": "2505090"
  },
  {
    "text": "getting downloaded a lot we're not hitting the counter every single time we've got a lambda function of the background that's kind of caching those",
    "start": "2505090",
    "end": "2511180"
  },
  {
    "text": "downloads and pushing up to the to the table and it's a distributed Connor that's right really distribute counter",
    "start": "2511180",
    "end": "2516880"
  },
  {
    "start": "2514000",
    "end": "2546000"
  },
  {
    "text": "this is what's happening right so as the lambda functions are firing they're firing across shards and the tables are not all one function processing all",
    "start": "2516880",
    "end": "2523120"
  },
  {
    "text": "items as many functions processing all these items so all they're doing is saying hey since the last time I dumped",
    "start": "2523120",
    "end": "2528250"
  },
  {
    "text": "I've counted 100 downloads let me go update the counter plus 100 and so I got",
    "start": "2528250",
    "end": "2533710"
  },
  {
    "text": "many you know too many lambda functions coming to make these incremental updates but they're doing them on standard",
    "start": "2533710",
    "end": "2539710"
  },
  {
    "text": "intervals and they're doing them you know with bad stuff or even more correct",
    "start": "2539710",
    "end": "2548650"
  },
  {
    "text": "lower case and it could just be just has to it just has to catch up it just has to cache for a couple seconds right just",
    "start": "2548650",
    "end": "2554290"
  },
  {
    "text": "to decrease the key pressure if I've got let's say 10,000 writes a second coming in I you know for some reason that would",
    "start": "2554290",
    "end": "2559420"
  },
  {
    "text": "be the busiest reddit post in history but let's say we had 10,000 you know posts coming in a second on the reddit",
    "start": "2559420",
    "end": "2564880"
  },
  {
    "text": "thread you know that would necessarily mean I'd be writing across 10 logical",
    "start": "2564880",
    "end": "2570220"
  },
  {
    "text": "shards to get that throughput and that's gonna hit me with basically 10 lambda functions in order to decrease the key",
    "start": "2570220",
    "end": "2577360"
  },
  {
    "text": "pressure on the post item to you know less than 1,000 writes a second I would only need I would update the counter",
    "start": "2577360",
    "end": "2583450"
  },
  {
    "text": "every you know 10 seconds or so I'd be basically grabbing 10,000 worth 10,000 updates and then updating them",
    "start": "2583450",
    "end": "2590500"
  },
  {
    "text": "all in one second right right and this is this is where you can use maximum batch size for lambda to essentially",
    "start": "2590500",
    "end": "2598750"
  },
  {
    "start": "2593000",
    "end": "2635000"
  },
  {
    "text": "increase this time there's no direct way to say I want this lambda function to",
    "start": "2598750",
    "end": "2605380"
  },
  {
    "text": "fire so often oh no no but it's basically what you do is once the land it becomes resident memory it just has",
    "start": "2605380",
    "end": "2611410"
  },
  {
    "text": "it has a five second loop and it just every five seconds it dumps its counter out to the metadata item and zeros in so",
    "start": "2611410",
    "end": "2617650"
  },
  {
    "text": "right right and lambda state reckon resident I forget how many minutes three minutes 15 that lambda functions in",
    "start": "2617650",
    "end": "2626020"
  },
  {
    "text": "memory is just gonna be dumping every 5 seconds if there's anything in my counters and then just clearing the counters and starting over again so it's",
    "start": "2626020",
    "end": "2632050"
  },
  {
    "text": "pretty simple very simple process yeah yeah let's see looking for using lambda",
    "start": "2632050",
    "end": "2639580"
  },
  {
    "start": "2635000",
    "end": "2801000"
  },
  {
    "text": "to cache the counter so we just we just went over that I hope that answers your question danger 13 and let's see what",
    "start": "2639580",
    "end": "2648190"
  },
  {
    "text": "strategy do you use for choosing how wide to scatter a given key that is right heavy sure that's another good",
    "start": "2648190",
    "end": "2654520"
  },
  {
    "text": "question he says I'm using sqs in this case not Kinesis this is event sourced",
    "start": "2654520",
    "end": "2659860"
  },
  {
    "text": "okay okay so in this particular case really what you're gonna be looking at",
    "start": "2659860",
    "end": "2665560"
  },
  {
    "text": "is the number of events that are coming in per second the size of those events and that's gonna dictate how much throughput you need and then what I'll",
    "start": "2665560",
    "end": "2671830"
  },
  {
    "text": "do is add some sort of a cushion for future growth all right so let's say I'm processing today you know we pull 10,000",
    "start": "2671830",
    "end": "2679270"
  },
  {
    "text": "events per second right and those events are all under one kilobyte and I'm gonna need ten shards today but if I expect",
    "start": "2679270",
    "end": "2685540"
  },
  {
    "text": "this workload to grow you know by a factor of 2x over the next 5 years that I might increase that you know to you",
    "start": "2685540",
    "end": "2692950"
  },
  {
    "text": "know 20 partitions the other other other often times what we find is that these",
    "start": "2692950",
    "end": "2699460"
  },
  {
    "text": "are not necessarily balanced workloads right some customers are big they're the whales other customers are not so big",
    "start": "2699460",
    "end": "2704950"
  },
  {
    "text": "and this is like if you look at a lot of AWS services the way AWS services are configured they have soft limits and",
    "start": "2704950",
    "end": "2710950"
  },
  {
    "text": "sometimes the soft limits are there because of resource constraints like infrastructure issues right like if you want a million you know WCU's i dynamodb",
    "start": "2710950",
    "end": "2717990"
  },
  {
    "text": "table and probably gonna need a rack some hardware for you so we'll have some soft limits on how much you can provision without coming and talking to",
    "start": "2717990",
    "end": "2724680"
  },
  {
    "text": "you kind of just the gate check a check other times those soft limits are for configuration items right like you know",
    "start": "2724680",
    "end": "2732030"
  },
  {
    "text": "if we have you know customers might need a certain number of configuration items within a given service and by default",
    "start": "2732030",
    "end": "2738840"
  },
  {
    "text": "that'll live within a single partition on their DynamoDB table because most of our AWS services use DynamoDB for the",
    "start": "2738840",
    "end": "2744510"
  },
  {
    "text": "prefiguration data but if a customer needs more and some of our enterprise customers might need more right and then",
    "start": "2744510",
    "end": "2750840"
  },
  {
    "text": "they'll say okay well how many would you need and they say well okay we need 10 million configuration items we say ok",
    "start": "2750840",
    "end": "2756000"
  },
  {
    "text": "great here you mister customer we will add another five logical partitions to support your workload and so when the",
    "start": "2756000",
    "end": "2762330"
  },
  {
    "text": "workflow processes fire for this particular customer they're gonna read again that zero partition like we saw",
    "start": "2762330",
    "end": "2767400"
  },
  {
    "text": "with cord most collections most collections live in one partition you know a number of customers are only",
    "start": "2767400",
    "end": "2772590"
  },
  {
    "text": "giving collection is less than one partitions worth of data so things like Lord of the Rings millions of people",
    "start": "2772590",
    "end": "2780780"
  },
  {
    "text": "right so now listen we need to add you know more partitions right so and we use application layer configuration data to",
    "start": "2780780",
    "end": "2787470"
  },
  {
    "text": "dictate whether we're reading one or more in the case of the Accord service you saw the zero partition contains a",
    "start": "2787470",
    "end": "2792780"
  },
  {
    "text": "metadata item in the case of other services it'll be a top-level configuration item for the customer",
    "start": "2792780",
    "end": "2798960"
  },
  {
    "text": "account right exactly couple of more questions a question how to handle query patterns a change after",
    "start": "2798960",
    "end": "2807060"
  },
  {
    "start": "2801000",
    "end": "2935000"
  },
  {
    "text": "the application is released the question is from K Phalke do you have any hints for managing complexity of GSI keys when",
    "start": "2807060",
    "end": "2814260"
  },
  {
    "text": "you have a combination of relationship plus filter value plus sort key it gets",
    "start": "2814260",
    "end": "2820110"
  },
  {
    "text": "exponentially complicated to encode it all in a string and measure many GS I sure so I okay a couple questions there",
    "start": "2820110",
    "end": "2827250"
  },
  {
    "text": "I what was the first one was do you have any hints for managing complexity of geosite keys when you have a combination",
    "start": "2827250",
    "end": "2833940"
  },
  {
    "text": "or do something about adding additional access patterns right yeah how to handle",
    "start": "2833940",
    "end": "2841530"
  },
  {
    "text": "query patterns that change after the application is it I believe so yeah Corey Patterson changed actually",
    "start": "2841530",
    "end": "2847650"
  },
  {
    "text": "after the applications released so typically what we see and I see this a lot is the what we're gonna have is new",
    "start": "2847650",
    "end": "2853290"
  },
  {
    "text": "features right enhancements to existing features changing slight tweaks and the",
    "start": "2853290",
    "end": "2858540"
  },
  {
    "text": "access patterns it's it's hot it's it's it's rare that you might see somebody saying oh yeah we don't really need that",
    "start": "2858540",
    "end": "2864420"
  },
  {
    "text": "access pattern anymore right it's going to be more like oh we need it but we need to do this instead or we need it",
    "start": "2864420",
    "end": "2869670"
  },
  {
    "text": "right or we need these different patterns so in this particular case what typically ends up happening is there's",
    "start": "2869670",
    "end": "2874860"
  },
  {
    "text": "usually some sort of ETL involved with the existing data I might need to run a process to do a table scan and annotate",
    "start": "2874860",
    "end": "2880200"
  },
  {
    "text": "items of a particular type with additional metadata or or tweak the keys in this in a way to provide different",
    "start": "2880200",
    "end": "2885869"
  },
  {
    "text": "sorts or whatnot alrights time limited data then you can basically just use yeah or you know we",
    "start": "2885869",
    "end": "2894210"
  },
  {
    "text": "might be adding new entities into the system we might add new partitions and then we might need to find new relationships to these new partitions",
    "start": "2894210",
    "end": "2901440"
  },
  {
    "text": "again it's it's more of an ETL it's an enhancement of the existing model it's adding to it and then we might need to",
    "start": "2901440",
    "end": "2907470"
  },
  {
    "text": "create additional indexes right to support some others you know secondary access matters so changes to the",
    "start": "2907470",
    "end": "2912690"
  },
  {
    "text": "patterns I'm not terribly worried about it typically involves tweaks to the model now if you're telling me that",
    "start": "2912690",
    "end": "2918210"
  },
  {
    "text": "you're changing the applications you know data model then if you're",
    "start": "2918210",
    "end": "2924210"
  },
  {
    "text": "fundamentally if the fundamental access patterns were wrong then we made a mistake it's time to go fire your marketing team okay yeah and the second",
    "start": "2924210",
    "end": "2932430"
  },
  {
    "text": "question was do you have any hints for managing complexity of JSI keys when you",
    "start": "2932430",
    "end": "2938130"
  },
  {
    "start": "2935000",
    "end": "3061000"
  },
  {
    "text": "have a combination of relationship plus filter value plus word key okay is exponentially complicated yeah so",
    "start": "2938130",
    "end": "2943740"
  },
  {
    "text": "typically what you try you're gonna try to do is you sort key conditions to give you initial slice of the result set",
    "start": "2943740",
    "end": "2949170"
  },
  {
    "text": "right so you know kind of your initial filter and then dynamodb is really neat because it allows you to have any number",
    "start": "2949170",
    "end": "2955350"
  },
  {
    "text": "of additional filter conditions that apply after the sort key condition is read and I use this a lot so understand",
    "start": "2955350",
    "end": "2961920"
  },
  {
    "text": "that within an RC you you're gonna get multiple items you know that are less",
    "start": "2961920",
    "end": "2967650"
  },
  {
    "text": "than one kilobyte it all adds up right so you know it's four kilobytes of data and if you have a hundred items to make",
    "start": "2967650",
    "end": "2973170"
  },
  {
    "text": "up those four kilobytes then that's great it's more kilobytes now RC you cost you one RC you if I read",
    "start": "2973170",
    "end": "2979150"
  },
  {
    "text": "if I use my sort key conditioning it returns let's say 80 items and those 80 items all make up less than one RCU and",
    "start": "2979150",
    "end": "2985570"
  },
  {
    "text": "then I apply a filter conditioning it knocks out 75 of those items guess how much that read cost me one",
    "start": "2985570",
    "end": "2991330"
  },
  {
    "text": "hour to use and so we'll use this trick a lot right where it's like Mysore key condition is not as selective as it",
    "start": "2991330",
    "end": "2997690"
  },
  {
    "text": "needs to be it brings back a much bigger result set than I want but I'm gonna data apply some filter conditions again",
    "start": "2997690",
    "end": "3003480"
  },
  {
    "text": "knock that result set down to exactly what I want so this is how we're gonna try and craft our queries and understand",
    "start": "3003480",
    "end": "3009090"
  },
  {
    "text": "that it doesn't always have to be the minimum RCU cost right that query might actually cost me five hours to use and I",
    "start": "3009090",
    "end": "3014700"
  },
  {
    "text": "return less than 1 hours to use with the data but it's still a pretty efficient query right if I'm not if I'm not",
    "start": "3014700",
    "end": "3020640"
  },
  {
    "text": "executing a thousands of times a second all right so this is the other case the other thing is when as a filter",
    "start": "3020640",
    "end": "3025830"
  },
  {
    "text": "condition makes sense well it makes sense when the cost of the query with the filter condition is not significantly more than the cost of the",
    "start": "3025830",
    "end": "3031950"
  },
  {
    "text": "query without it and it would cost me more to maintain or it would cost me more to maintain a selective index than",
    "start": "3031950",
    "end": "3038730"
  },
  {
    "text": "it would cost me to use the filter condition because the query velocity and frequency is not that high right so",
    "start": "3038730",
    "end": "3044940"
  },
  {
    "text": "these are the trade-offs we're making in no SQL right when do I use filter conditions versus a selective sort key",
    "start": "3044940",
    "end": "3050130"
  },
  {
    "text": "when do I create a selective GSI right these are the things we're gonna be analyzing about our application",
    "start": "3050130",
    "end": "3055880"
  },
  {
    "text": "understanding about our access patterns that's why we have to understand our access patterns in detail I saw one",
    "start": "3055880",
    "end": "3061980"
  },
  {
    "start": "3061000",
    "end": "3204000"
  },
  {
    "text": "question then that I want to bring up actually was a couple of questions from",
    "start": "3061980",
    "end": "3067020"
  },
  {
    "text": "this user tjak X the first one is what",
    "start": "3067020",
    "end": "3072900"
  },
  {
    "text": "are the main differences between and dynamo and and I will just say MongoDB and dynamo I I think it's a",
    "start": "3072900",
    "end": "3080940"
  },
  {
    "text": "great question and then he's asking another question that sort of related is that most suitable for high frequency",
    "start": "3080940",
    "end": "3087750"
  },
  {
    "text": "data for example sensor data or is that use case better suited for redshift",
    "start": "3087750",
    "end": "3094290"
  },
  {
    "text": "actually that's not necessarily so related to the first my first question what's the difference to MongoDB and",
    "start": "3094290",
    "end": "3100140"
  },
  {
    "text": "DynamoDB for properly modeled data for no SQL the answer is nothing",
    "start": "3100140",
    "end": "3105240"
  },
  {
    "text": "and we just described that what's the difference to a wide palm story document store from the data modeling perspective",
    "start": "3105240",
    "end": "3110490"
  },
  {
    "text": "absolutely from a query API perspective there's a big difference right MongoDB has a wide",
    "start": "3110490",
    "end": "3116260"
  },
  {
    "text": "variety of query operators that allow kind of I guess you'd say what a lot of people kind of refer to as the missing",
    "start": "3116260",
    "end": "3123369"
  },
  {
    "text": "ad-hoc query engine for no SQL and to this I'll respond that I spent a year or",
    "start": "3123369",
    "end": "3128859"
  },
  {
    "text": "more a little bit over a year at MongoDB and I spent a lot of time unwinding a lot of those aggregation framework",
    "start": "3128859",
    "end": "3134589"
  },
  {
    "text": "queries because the problem with those is it's the same problem the relational database has joining data is expensive",
    "start": "3134589",
    "end": "3140440"
  },
  {
    "text": "ad hoc queries are expensive right if you're trying to use the CPU to churn through volumes and volumes of data to",
    "start": "3140440",
    "end": "3146230"
  },
  {
    "text": "produce computed aggregates and result sets and whatnot then you're going to be burning your system alive and that's what happens when you run aggregate in",
    "start": "3146230",
    "end": "3152650"
  },
  {
    "text": "queries so it's why the key obstacles to the Elise scale absolutely and it's one of the biggest problems MongoDB users",
    "start": "3152650",
    "end": "3158799"
  },
  {
    "text": "have when I especially at scale when you when you start to bring the you know when you're when you're running out there with a small workload that's never",
    "start": "3158799",
    "end": "3165250"
  },
  {
    "text": "really pushing the limits of the system you're never gonna notice that that you have these problems when customers scale",
    "start": "3165250",
    "end": "3170319"
  },
  {
    "text": "typically that's when I get involved because they start to experience problems and so they're well maybe Medina Modi's the answer so we'll go",
    "start": "3170319",
    "end": "3177339"
  },
  {
    "text": "talk to them about what they're doing and most the time 90% of the time what I do is I'll muck with their data model",
    "start": "3177339",
    "end": "3182529"
  },
  {
    "text": "I'll tweak their things and we'll get them running and they don't have to change anything other than how they're accessing their data and they'll stay",
    "start": "3182529",
    "end": "3187990"
  },
  {
    "text": "there just fine they stay on their MongoDB cluster and you know they won't ever scale to the point where they start feeling more pain now there is a scale",
    "start": "3187990",
    "end": "3194529"
  },
  {
    "text": "point with MongoDB with Cassandra with every off-the-shelf no SQL database that you're gonna start feeling scale pain",
    "start": "3194529",
    "end": "3199720"
  },
  {
    "text": "that's when you can talk to me about cloud native solutions right that's what we get in a mode and and in fact I was",
    "start": "3199720",
    "end": "3205119"
  },
  {
    "start": "3204000",
    "end": "3336000"
  },
  {
    "text": "just gonna say that the one other point of difference between those two is the fact that DynamoDB is a cloud native",
    "start": "3205119",
    "end": "3211000"
  },
  {
    "text": "that's great yeah and what does that even mean well sure I can run MongoDB in the cloud as",
    "start": "3211000",
    "end": "3217150"
  },
  {
    "text": "well I can I can run any of these databases in the cloud but a difference is dynamodb was designed to run in a",
    "start": "3217150",
    "end": "3223599"
  },
  {
    "text": "clog and provides abstractions that you use to essentially make the whole thing",
    "start": "3223599",
    "end": "3230710"
  },
  {
    "text": "easier yeah it's a fully multi-tenant database right it's not designed to be deployed on Prem it won't do is never",
    "start": "3230710",
    "end": "3237160"
  },
  {
    "text": "you don't deal with servers exactly and that's the other thing you don't deal with servers and I say this because it is a one sort of",
    "start": "3237160",
    "end": "3244049"
  },
  {
    "text": "difference that we see people struggling with a little bit because they're used to dealing with their clusters and nodes",
    "start": "3244049",
    "end": "3250170"
  },
  {
    "text": "in the cluster and servers and and in fact if you really think about it your capacity planning becomes much easier if",
    "start": "3250170",
    "end": "3256289"
  },
  {
    "text": "you don't have to figure out what is the amount of scale I get from a single",
    "start": "3256289",
    "end": "3262619"
  },
  {
    "text": "server right for your capacity planning you just need to know the data volume and then reads and writes you don't with",
    "start": "3262619",
    "end": "3271319"
  },
  {
    "text": "every single legacy no SQL technology out there you're gonna have to provision for peak and leave it there they leave",
    "start": "3271319",
    "end": "3277079"
  },
  {
    "text": "it you're never gonna be able to take that capacity away with DynamoDB you get just-in-time provisioning you get auto",
    "start": "3277079",
    "end": "3282359"
  },
  {
    "text": "scaling you can go up and go down and an elastic scaling and elastics incremental and you only pay for this is the",
    "start": "3282359",
    "end": "3288599"
  },
  {
    "text": "difference between cloud native and legacy right the legacy technologies the MongoDB Cassandra I mean you got to",
    "start": "3288599",
    "end": "3294809"
  },
  {
    "text": "think about guys these things were built you know 10 15 years ago and they were designed to be deployed on Prem you know",
    "start": "3294809",
    "end": "3300660"
  },
  {
    "text": "on Prem data centers they are pre cloud technologies right they do not scale the same way as a DynamoDB or any other",
    "start": "3300660",
    "end": "3307499"
  },
  {
    "text": "cloud native database with that and in fact I said you need to know your your reads and writes kind of and in fact",
    "start": "3307499",
    "end": "3314219"
  },
  {
    "text": "with with DynamoDB now you don't even need to know in a lot of cases what a",
    "start": "3314219",
    "end": "3322729"
  },
  {
    "text": "spiky spurious workload where when it comes it hits me in a hundred miles an hour but I went but I don't know when",
    "start": "3322759",
    "end": "3328829"
  },
  {
    "text": "it's coming right and it doesn't come all the time becomes bit on demand on demands of the medical technology for",
    "start": "3328829",
    "end": "3334529"
  },
  {
    "text": "this right so one question from the same user was about when to use redshift vs.",
    "start": "3334529",
    "end": "3344579"
  },
  {
    "start": "3336000",
    "end": "3481000"
  },
  {
    "text": "so TJX is that much suitable for high frequency data sensor data or is that",
    "start": "3344579",
    "end": "3350640"
  },
  {
    "text": "better suited yeah no absolutely so no any redshift I mean that's a data warehousing solution it's great scales to you know a petabyte",
    "start": "3350640",
    "end": "3358319"
  },
  {
    "text": "scale dynamodb is certainly suitable for your high frequency sensor data again depends on the access pattern right so",
    "start": "3358319",
    "end": "3364769"
  },
  {
    "text": "my redshift is going to provide dimensional ad-hoc queries right you can get a dimensional stars or snowflake",
    "start": "3364769",
    "end": "3371099"
  },
  {
    "text": "schema where you're going to be able to run some you know level that hoc queries dynamodb is not going",
    "start": "3371099",
    "end": "3376839"
  },
  {
    "text": "to support those types of ad hoc queries if you have an OLTP workload running against your sensor data absolutely and we have iot workloads that use DynamoDB",
    "start": "3376839",
    "end": "3384309"
  },
  {
    "text": "they're scaling beyond anything I've ever seen from any other no SQL database literally I think I've last I heard our",
    "start": "3384309",
    "end": "3389650"
  },
  {
    "text": "fastest table is going which is over seven million transactions per se a lot of times it's not either even a question",
    "start": "3389650",
    "end": "3395170"
  },
  {
    "text": "of either/or because that's true that's right that's true the decision support systems and the workloads of run against",
    "start": "3395170",
    "end": "3401529"
  },
  {
    "text": "those are different than the workloads of run against you know SQL database I might need that sense of Bonita online for my OLTP workloads I might need it in",
    "start": "3401529",
    "end": "3409089"
  },
  {
    "text": "a factory where it can be queried more ad hoc exactly so so for your",
    "start": "3409089",
    "end": "3414160"
  },
  {
    "text": "essentially real-time needs OLTP right decision support views you'd be using",
    "start": "3414160",
    "end": "3420250"
  },
  {
    "text": "dynamo DB but then you you you use fetch it for analytics that's right and",
    "start": "3420250",
    "end": "3425289"
  },
  {
    "text": "possibly use dynamodb streams to essentially stream this work or copy",
    "start": "3425289",
    "end": "3431200"
  },
  {
    "text": "table or data pipeline or a variety of other technologies as well so we're running up on the end of the hour here",
    "start": "3431200",
    "end": "3437619"
  },
  {
    "text": "that's right I think we're gonna have to wrap it up thanks a lot for questions and we'll see you next time all right thank you thank you",
    "start": "3437619",
    "end": "3445680"
  },
  {
    "text": "[Music]",
    "start": "3451870",
    "end": "3482239"
  }
]
[
  {
    "start": "0",
    "end": "74000"
  },
  {
    "text": "- Welcome to \"Back to Basics\".",
    "start": "6570",
    "end": "8790"
  },
  {
    "text": "In this episode, we will discuss",
    "start": "8790",
    "end": "11220"
  },
  {
    "text": "how you can seamlessly integrate\nand securely extract data",
    "start": "11220",
    "end": "15660"
  },
  {
    "text": "from third party SaaS based applications",
    "start": "15660",
    "end": "18750"
  },
  {
    "text": "using Amazon AppFlow",
    "start": "18750",
    "end": "21030"
  },
  {
    "text": "to build analytics pipelines with no code.",
    "start": "21030",
    "end": "24243"
  },
  {
    "text": "In my past experience, I\nworked on multiple integrations",
    "start": "25350",
    "end": "29880"
  },
  {
    "text": "with third party SaaS based applications",
    "start": "29880",
    "end": "32879"
  },
  {
    "text": "to extract the data\ninto the data warehouse",
    "start": "32880",
    "end": "36030"
  },
  {
    "text": "for analyzing and\nderiving insights from it.",
    "start": "36030",
    "end": "40170"
  },
  {
    "text": "However, because different\nSaaS applications provide",
    "start": "40170",
    "end": "43800"
  },
  {
    "text": "different mechanisms\nof extracting the data,",
    "start": "43800",
    "end": "46680"
  },
  {
    "text": "a single approach didn't\nwork all the time.",
    "start": "46680",
    "end": "49143"
  },
  {
    "text": "We had to build custom extractors",
    "start": "50160",
    "end": "52890"
  },
  {
    "text": "for each SaaS based application.",
    "start": "52890",
    "end": "55920"
  },
  {
    "text": "It left the company with a\nbunch of data source connectors",
    "start": "55920",
    "end": "59820"
  },
  {
    "text": "and code repositories that\nare expensive to maintain.",
    "start": "59820",
    "end": "63183"
  },
  {
    "text": "Let's look at how easily\nyou can extract data",
    "start": "64260",
    "end": "67500"
  },
  {
    "text": "from SaaS based\napplications like Salesforce",
    "start": "67500",
    "end": "70620"
  },
  {
    "text": "with no code using AWS services.",
    "start": "70620",
    "end": "73923"
  },
  {
    "start": "74000",
    "end": "146000"
  },
  {
    "text": "We will start with AppFlow,",
    "start": "74970",
    "end": "77220"
  },
  {
    "text": "which is a fully managed\nintegration service",
    "start": "77220",
    "end": "80130"
  },
  {
    "text": "that enables you to securely transfer data",
    "start": "80130",
    "end": "83340"
  },
  {
    "text": "between third party SaaS\napplication and AWS services.",
    "start": "83340",
    "end": "87573"
  },
  {
    "text": "With AppFlow, you can run data flow",
    "start": "88590",
    "end": "91200"
  },
  {
    "text": "at nearly any scale and frequency.",
    "start": "91200",
    "end": "94860"
  },
  {
    "text": "Using AppFlow, you can\nconfigure data transformations",
    "start": "94860",
    "end": "98580"
  },
  {
    "text": "such as data masking and\nconcatenation of field,",
    "start": "98580",
    "end": "102300"
  },
  {
    "text": "as well as validate and filter data",
    "start": "102300",
    "end": "105660"
  },
  {
    "text": "to generate ready to use data",
    "start": "105660",
    "end": "107850"
  },
  {
    "text": "as part of the flow itself\nwithout additional steps.",
    "start": "107850",
    "end": "111603"
  },
  {
    "text": "Now let's take a look at",
    "start": "112500",
    "end": "114660"
  },
  {
    "text": "how Salesforce is integrated with AppFlow.",
    "start": "114660",
    "end": "118710"
  },
  {
    "text": "In AppFlow, you create a\nconnection by selecting source,",
    "start": "118710",
    "end": "122729"
  },
  {
    "text": "destination and login details.",
    "start": "122730",
    "end": "125790"
  },
  {
    "text": "Next, you specify flow\ntrigger and map the fields",
    "start": "125790",
    "end": "129990"
  },
  {
    "text": "from source to destination.",
    "start": "129990",
    "end": "132600"
  },
  {
    "text": "Then you add filters,\nvalidation, transformation,",
    "start": "132600",
    "end": "136980"
  },
  {
    "text": "and at the end, activate\nyour flow to transfer data",
    "start": "136980",
    "end": "141330"
  },
  {
    "text": "between your third party application",
    "start": "141330",
    "end": "143700"
  },
  {
    "text": "and destination application.",
    "start": "143700",
    "end": "145532"
  },
  {
    "start": "146000",
    "end": "300000"
  },
  {
    "text": "Let's look at another AWS\nservice, AWS Glue DataBrew",
    "start": "146760",
    "end": "151760"
  },
  {
    "text": "which has a native console\nintegration with AppFlow,",
    "start": "152130",
    "end": "156210"
  },
  {
    "text": "allowing users to connect to data",
    "start": "156210",
    "end": "159030"
  },
  {
    "text": "from Salesforce and other\nSaaS based applications.",
    "start": "159030",
    "end": "163650"
  },
  {
    "text": "Glue Data Brew is a visual\ndata preparation tool",
    "start": "163650",
    "end": "167220"
  },
  {
    "text": "that makes it easy to\nclean and normalized data",
    "start": "167220",
    "end": "170820"
  },
  {
    "text": "using pre-built transformations",
    "start": "170820",
    "end": "173430"
  },
  {
    "text": "for data preparation all without\nthe need to write any code.",
    "start": "173430",
    "end": "177752"
  },
  {
    "text": "When creating a new data set in DataBrew,",
    "start": "179010",
    "end": "182040"
  },
  {
    "text": "you can now create a flow via AppFlow",
    "start": "182040",
    "end": "184920"
  },
  {
    "text": "that loads data into Amazon S3.",
    "start": "184920",
    "end": "188760"
  },
  {
    "text": "Once the flow has been established to S3,",
    "start": "188760",
    "end": "191849"
  },
  {
    "text": "you can easily clean, normalize\nand transform this data",
    "start": "191850",
    "end": "196590"
  },
  {
    "text": "in DataBrew and join it with\ndataset from SaaS applications.",
    "start": "196590",
    "end": "201590"
  },
  {
    "text": "Once the data is in S3, which\nis an object-based storage,",
    "start": "202620",
    "end": "206459"
  },
  {
    "text": "you can consume it from multiple\nAWS services per analysis.",
    "start": "206460",
    "end": "211460"
  },
  {
    "text": "One of these services is Amazon Athena.",
    "start": "211980",
    "end": "215670"
  },
  {
    "text": "It is an interactive query service",
    "start": "215670",
    "end": "218099"
  },
  {
    "text": "that makes it easy to\nanalyze data directly in S3",
    "start": "218100",
    "end": "222270"
  },
  {
    "text": "using standard SQL language\nto run adhoc queries",
    "start": "222270",
    "end": "226740"
  },
  {
    "text": "and get results in seconds.",
    "start": "226740",
    "end": "229260"
  },
  {
    "text": "With Athena, there is no\nneed for complex ETL jobs",
    "start": "229260",
    "end": "233220"
  },
  {
    "text": "to prepare your data for analysis,",
    "start": "233220",
    "end": "236400"
  },
  {
    "text": "Athena uses the AWS Glue Data catalog,",
    "start": "236400",
    "end": "240390"
  },
  {
    "text": "which is a centralized metadata repository",
    "start": "240390",
    "end": "243960"
  },
  {
    "text": "for all your data sets",
    "start": "243960",
    "end": "245970"
  },
  {
    "text": "to store and retrieve table\nmetadata for the S3 data.",
    "start": "245970",
    "end": "250830"
  },
  {
    "text": "The table metadata lets\nthe Athena query in general",
    "start": "250830",
    "end": "254790"
  },
  {
    "text": "find, read, and process the data",
    "start": "254790",
    "end": "258509"
  },
  {
    "text": "that you want to query.",
    "start": "258510",
    "end": "259773"
  },
  {
    "text": "It is essential to secure the data",
    "start": "261000",
    "end": "263850"
  },
  {
    "text": "by encrypting the data in\ntransit and data at rest.",
    "start": "263850",
    "end": "268173"
  },
  {
    "text": "AppFlow provides both AWS\nmanaged and customer managed CMKs",
    "start": "269070",
    "end": "274070"
  },
  {
    "text": "for encrypting connection data",
    "start": "274560",
    "end": "276810"
  },
  {
    "text": "and data stored in S3\nwhen it is a destination.",
    "start": "276810",
    "end": "280889"
  },
  {
    "text": "We recommend that you\nuse customer managed CMKs",
    "start": "280890",
    "end": "284790"
  },
  {
    "text": "as it puts you in full control\nover your encrypted data.",
    "start": "284790",
    "end": "289140"
  },
  {
    "text": "Check out the links for more details.",
    "start": "289140",
    "end": "291300"
  },
  {
    "text": "Thank you for watching \"Back\nto Basics\". See you next time!",
    "start": "291300",
    "end": "295633"
  }
]
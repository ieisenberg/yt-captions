[
  {
    "text": "In this video, you’ll see how to configure \nthe AWS Distro for OpenTelemetry (ADOT)",
    "start": "0",
    "end": "6241"
  },
  {
    "text": "Kafka Receiver and Exporter \nusing confmap providers.",
    "start": "6241",
    "end": "9660"
  },
  {
    "text": "With this solution, you can send and receive \ntelemetry signals from a Kafka cluster,",
    "start": "9995",
    "end": "14535"
  },
  {
    "text": "use a Kafka topic as an intermediate\nbuffer between multiple data sources",
    "start": "14535",
    "end": "18450"
  },
  {
    "text": "and backends, and efficiently manage\nconfiguration of ADOT collectors.",
    "start": "18450",
    "end": "22539"
  },
  {
    "text": "Before getting started, let's go over the \nkey components of the solution we'll",
    "start": "23837",
    "end": "27933"
  },
  {
    "text": "implement in this demonstration.",
    "start": "27933",
    "end": "29908"
  },
  {
    "text": "We'll use a Kafka topic as an intermediate",
    "start": "30794",
    "end": "33383"
  },
  {
    "text": "buffer to decouple the data flow \nbetween producers and consumers.",
    "start": "33383",
    "end": "37281"
  },
  {
    "text": "This will make it possible to consolidate\n data from various telemetry sources",
    "start": "37541",
    "end": "41888"
  },
  {
    "text": "and send it to backends such as Amazon \nOpenSearch, Amazon Managed Service",
    "start": "41888",
    "end": "46216"
  },
  {
    "text": "for Prometheus, Amazon CloudWatch, \nAWS X-Ray, or third-party monitoring",
    "start": "46216",
    "end": "51975"
  },
  {
    "text": "tools; to SIEM tools; or to a \nreal-time analytics pipeline.",
    "start": "51975",
    "end": "56244"
  },
  {
    "text": "We’ll also use confmap providers \nto configure two ADOT collectors.",
    "start": "58532",
    "end": "62805"
  },
  {
    "text": "A confmap provider is a type of \nOpenTelemetry collector component",
    "start": "63431",
    "end": "67307"
  },
  {
    "text": "that is responsible for fetching \nconfiguration from a URI.",
    "start": "67307",
    "end": "70854"
  },
  {
    "text": "The ADOT collector supports confmap \nproviders for file location, environment",
    "start": "71160",
    "end": "75733"
  },
  {
    "text": "variables, YAML files, HTTP and \nHTTPS servers, and Amazon S3 buckets.",
    "start": "75733",
    "end": "82918"
  },
  {
    "text": "You can learn about the available \nconfmap providers in this documentation,",
    "start": "83651",
    "end": "87710"
  },
  {
    "text": "which is provided in the links for this video.",
    "start": "87710",
    "end": "90076"
  },
  {
    "text": "To get started, we need an Amazon Managed \nStreaming for Apache Kafka (Amazon MSK)",
    "start": "92304",
    "end": "98741"
  },
  {
    "text": "cluster and a topic inside the cluster.",
    "start": "98741",
    "end": "101258"
  },
  {
    "text": "For demonstration purposes, these resources \nare already created and active in our accounts.",
    "start": "101579",
    "end": "106999"
  },
  {
    "text": "Let’s view the client information.",
    "start": "107426",
    "end": "109494"
  },
  {
    "text": "We’ll copy the private broker endpoints, \nwhich we’ll use when configuring the",
    "start": "110440",
    "end": "114008"
  },
  {
    "text": "Kafka Exporter and Receiver.",
    "start": "114008",
    "end": "115804"
  },
  {
    "text": "We have also launched two Amazon Elastic \nCompute Cloud (Amazon EC2) instances.",
    "start": "117605",
    "end": "123381"
  },
  {
    "text": "On Instance A, we are going to run an ADOT \ncollector with the Kafka Exporter configuration.",
    "start": "123686",
    "end": "129000"
  },
  {
    "text": "On Instance B, we are going to run the ADOT \ncollector with the Kafka Receiver configuration.",
    "start": "129290",
    "end": "134528"
  },
  {
    "text": "For our purposes, we'll use an Amazon \nSimple Storage Service (Amazon S3)",
    "start": "135170",
    "end": "139877"
  },
  {
    "text": "confmap provider to fetch \nour collector configurations.",
    "start": "139878",
    "end": "143441"
  },
  {
    "text": "Both configurations have already \nbeen stored in this S3 bucket.",
    "start": "143883",
    "end": "147508"
  },
  {
    "text": "Let's take a look at each one.",
    "start": "147737",
    "end": "149141"
  },
  {
    "text": "This is the configuration for collector instance A.",
    "start": "151353",
    "end": "154116"
  },
  {
    "text": "This Kafka Exporter component is \nresponsible for streaming telemetry",
    "start": "155153",
    "end": "158788"
  },
  {
    "text": "data from the StatsD receiver to \nour Kafka topic, “adot-kafka-demo.”",
    "start": "158788",
    "end": "163573"
  },
  {
    "text": "The configuration specifies the broker \nendpoints for our Amazon MSK cluster.",
    "start": "164046",
    "end": "168882"
  },
  {
    "text": "This is the configuration \nfor collector instance B.",
    "start": "171934",
    "end": "174528"
  },
  {
    "text": "The Kafka Receiver component is responsible \nfor reading telemetry data from our Kafka topic.",
    "start": "175673",
    "end": "180548"
  },
  {
    "text": "It will then stream the data to the stdout of \nthe AWS collector, using this logging exporter.",
    "start": "181678",
    "end": "187545"
  },
  {
    "text": "Again, we’ve specified the broker \nendpoints of the Amazon MSK cluster.",
    "start": "188690",
    "end": "192451"
  },
  {
    "text": "Let’s now start the collector\n on both collector instances.",
    "start": "193550",
    "end": "196686"
  },
  {
    "text": "To do that, we’ve logged in to both instances.",
    "start": "198761",
    "end": "201157"
  },
  {
    "text": "The terminal on the left is for collector instance A; \nthe one on the right is for collector instance B.",
    "start": "201462",
    "end": "206842"
  },
  {
    "text": "We’ll enter a command to start each collector.",
    "start": "207880",
    "end": "210000"
  },
  {
    "text": "Notice that the command utilizes the S3 bucket URI \nwhere we have stored our collector configurations.",
    "start": "213693",
    "end": "219592"
  },
  {
    "text": "Next, we’ll confirm whether the \ncollectors are running successfully.",
    "start": "220935",
    "end": "224338"
  },
  {
    "text": "Both collectors are running.",
    "start": "230473",
    "end": "231976"
  },
  {
    "text": "Working in instance A, we’ll send some \ntelemetry data to the StatsD receiver so",
    "start": "232602",
    "end": "236614"
  },
  {
    "text": "the Kafka Exporter can submit it to our topic.",
    "start": "236614",
    "end": "239240"
  },
  {
    "text": "The data is starting to come in.",
    "start": "240141",
    "end": "241613"
  },
  {
    "text": "From collector instance B, we’ll \ntail the ADOT collector log file.",
    "start": "242758",
    "end": "246394"
  },
  {
    "text": "Immediately, the metric data is showing up.",
    "start": "247189",
    "end": "249371"
  },
  {
    "text": "This simple example showed how you \ncan use the ADOT Kafka Exporter and",
    "start": "250241",
    "end": "254267"
  },
  {
    "text": "Receiver to send and receive \ndata from a Kafka topic.",
    "start": "254267",
    "end": "258000"
  },
  {
    "text": "Now, let’s use this updated Kafka \nreceiver configuration to send some",
    "start": "260213",
    "end": "264377"
  },
  {
    "text": "ADOT Kafka metrics using the AWS\nEMF exporter, and some Prometheus",
    "start": "264377",
    "end": "269909"
  },
  {
    "text": "metrics using the Prometheus \nRemote Write exporter.",
    "start": "269909",
    "end": "273000"
  },
  {
    "text": "The exporters have already been \nconfigured in the collector pipeline.",
    "start": "273900",
    "end": "277195"
  },
  {
    "text": "First, let’s go to the S3 bucket and upload \nthis updated Kafka receiver configuration.",
    "start": "278111",
    "end": "283177"
  },
  {
    "text": "We’ll select the file.",
    "start": "285000",
    "end": "286260"
  },
  {
    "text": "The upload is complete.",
    "start": "293921",
    "end": "295210"
  },
  {
    "text": "Let’s return to our IDE and open the terminal.",
    "start": "295424",
    "end": "298003"
  },
  {
    "text": "We’ll start the agent again \nusing the new configuration.",
    "start": "301910",
    "end": "304572"
  },
  {
    "text": "Now, let’s generate some sample metric data on \nthe Kafka exporter instance to see the telemetry",
    "start": "306282",
    "end": "312214"
  },
  {
    "text": "data being sent to CloudWatch and \nAmazon Managed Service for Prometheus.",
    "start": "312214",
    "end": "316841"
  },
  {
    "text": "We’ll generate some stats for the \nreceiver using our sample metrics script.",
    "start": "317346",
    "end": "321367"
  },
  {
    "text": "Next, we’ll run a node exporter to \ngenerate some Prometheus metrics.",
    "start": "322298",
    "end": "325861"
  },
  {
    "text": "Let's navigate to the CloudWatch console.",
    "start": "326609",
    "end": "328852"
  },
  {
    "text": "The telemetry data is being \nreceived by the CloudWatch backend.",
    "start": "333491",
    "end": "336826"
  },
  {
    "text": "Now, let’s navigate to the Grafana \nconsole to visualize the metrics from",
    "start": "338535",
    "end": "342170"
  },
  {
    "text": "the Amazon Managed Service \nfor Prometheus workspace.",
    "start": "342170",
    "end": "345601"
  },
  {
    "text": "We can browse all the metrics that are being sent \nfrom the node exporter, or search for a specific one.",
    "start": "346425",
    "end": "351201"
  },
  {
    "text": "We can narrow the results.",
    "start": "356274",
    "end": "357763"
  },
  {
    "text": "Let’s use this query.",
    "start": "361350",
    "end": "362662"
  },
  {
    "text": "The Prometheus metric we queried is being \nvisualized using Managed Service for Grafana.",
    "start": "364737",
    "end": "369460"
  },
  {
    "text": "You’ve just seen how to configure the ADOT Kafka \nReceiver and Exporter with confmap providers.",
    "start": "372360",
    "end": "378000"
  },
  {
    "text": "You can learn more about this topic in \nthe description and links for this video.",
    "start": "379023",
    "end": "382833"
  },
  {
    "text": "Thanks for watching. Now it’s your turn to try.",
    "start": "383398",
    "end": "386540"
  }
]
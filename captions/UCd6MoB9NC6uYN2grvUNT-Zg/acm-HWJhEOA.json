[
  {
    "start": "0",
    "end": "40000"
  },
  {
    "text": "Welcome to 'This is My Architecture'.\nToday I have here, Kevin from Careem.",
    "start": "7625",
    "end": "11833"
  },
  {
    "text": "-Hi, Kevin.\n-Hello, Kamran.",
    "start": "11875",
    "end": "13125"
  },
  {
    "text": "Can you tell me a bit more about Careem?",
    "start": "13875",
    "end": "15583"
  },
  {
    "text": "Yeah, so Careem started in 2012\nas a ride hailing company.",
    "start": "15958",
    "end": "19208"
  },
  {
    "text": "And then over the next eight years,\nwe grew to be one of the region's most successful startups.",
    "start": "19583",
    "end": "24500"
  },
  {
    "text": "That led us to be acquired by Uber last year,\nand now we're expanding into an array of different services",
    "start": "24958",
    "end": "30958"
  },
  {
    "text": "such as food deliveries, grocery deliveries,\nP2P transactions, payments,",
    "start": "31000",
    "end": "35208"
  },
  {
    "text": "and that's in an attempt to become\nthe region's leading super app.",
    "start": "35625",
    "end": "38875"
  },
  {
    "text": "I definitely love to use Careem.",
    "start": "39500",
    "end": "41083"
  },
  {
    "start": "40000",
    "end": "75000"
  },
  {
    "text": "So, can you tell me,\nwe have a very interesting architecture here.",
    "start": "41250",
    "end": "44458"
  },
  {
    "text": "Can you tell me the use case that you're looking at?",
    "start": "44708",
    "end": "47292"
  },
  {
    "text": "Yeah, so essentially, we wanted to build\na fraud-detection system that covers all of Careem.",
    "start": "47833",
    "end": "52792"
  },
  {
    "text": "So traditionally, we'd see a fraud pattern,",
    "start": "52833",
    "end": "55333"
  },
  {
    "text": "and then we'd build a project or a model\nspecifically for that one pattern,",
    "start": "55375",
    "end": "58708"
  },
  {
    "text": "whereas now we want like a blanket approach\nto cover all different types of fraud.",
    "start": "59000",
    "end": "62208"
  },
  {
    "text": "So, can you give me an example of fraud that happens?",
    "start": "62667",
    "end": "64875"
  },
  {
    "text": "Yes, so, one of the most common ones\nis users gaining access to stolen credit card details",
    "start": "65167",
    "end": "70125"
  },
  {
    "text": "and then using that credit card to make purchases,\nbook rides, do anything on the platform.",
    "start": "70167",
    "end": "74583"
  },
  {
    "start": "75000",
    "end": "168000"
  },
  {
    "text": "So, let's dive in.\nCan you explain to me how this works?",
    "start": "75042",
    "end": "78667"
  },
  {
    "text": "Yeah, so the entire project is what we call CrazyWall.",
    "start": "79000",
    "end": "82583"
  },
  {
    "text": "And so, initially, for the project,",
    "start": "83292",
    "end": "85042"
  },
  {
    "text": "we need a database that is populated\nwith all of our historical data about our users.",
    "start": "85417",
    "end": "90042"
  },
  {
    "text": "So, everything you see above this line here\nis all the historical data.",
    "start": "90083",
    "end": "93750"
  },
  {
    "text": "So, we have our data warehouse\nhosted on S3, running on Hive,",
    "start": "94667",
    "end": "99667"
  },
  {
    "text": "and we then have an EMR cluster that extracts all of the data\nand uses PySpark to run an ETL pipeline,",
    "start": "100083",
    "end": "106167"
  },
  {
    "text": "which extracts, transforms, and loads the data in the format\nthat's needed by the Neptune database.",
    "start": "106208",
    "end": "111542"
  },
  {
    "text": "And so, at the moment, once we've done all that,",
    "start": "112917",
    "end": "115375"
  },
  {
    "text": "we have a graph database\nthat's a historical snapshot of all our users.",
    "start": "115417",
    "end": "119167"
  },
  {
    "text": "So, why a graph database?",
    "start": "120042",
    "end": "121625"
  },
  {
    "text": "So, the idea behind the project\nis to have a representation of the identity of all of our users.",
    "start": "122625",
    "end": "129041"
  },
  {
    "text": "So, graph is a perfect way to do that,",
    "start": "129083",
    "end": "130666"
  },
  {
    "text": "where we have users as nodes on all of their data points\non their profile as nodes as well.",
    "start": "130708",
    "end": "135583"
  },
  {
    "text": "And then users who share different data points\nthat'd be represented as edges in the graph.",
    "start": "136000",
    "end": "140000"
  },
  {
    "text": "So, the data points like credit card details\nand those kinds of things are all there.",
    "start": "140417",
    "end": "143625"
  },
  {
    "text": "Yeah, exactly.",
    "start": "143667",
    "end": "144667"
  },
  {
    "text": "So, I know you have a few choices\nwhen you choose the graph database.",
    "start": "144708",
    "end": "148083"
  },
  {
    "text": "Why Neptune?",
    "start": "148125",
    "end": "149125"
  },
  {
    "text": "Yeah, so we compared quite\na number of different frameworks,",
    "start": "149417",
    "end": "151917"
  },
  {
    "text": "and we ended up choosing Neptune firstly,\nbecause as you can see,",
    "start": "151958",
    "end": "155542"
  },
  {
    "text": "we have a lot of different services already hosted on AWS,",
    "start": "155583",
    "end": "158750"
  },
  {
    "text": "and secondly, Neptune is fully managed by AWS,",
    "start": "159208",
    "end": "162000"
  },
  {
    "text": "so we don't have to worry about scalability,\nmaintenance, backups, anything like that.",
    "start": "162042",
    "end": "166042"
  },
  {
    "text": "-And focus on your use case, actually.\n-Mm-hmm.",
    "start": "166250",
    "end": "168250"
  },
  {
    "start": "168000",
    "end": "238000"
  },
  {
    "text": "So, we looked into historical data,\nwhat about real-time events?",
    "start": "168583",
    "end": "171792"
  },
  {
    "text": "Yeah, so everything that you see below the line\nis the process in real-time.",
    "start": "172292",
    "end": "176750"
  },
  {
    "text": "So, we have a system developed by our engineers\nknown as PI Event Processor,",
    "start": "178083",
    "end": "182167"
  },
  {
    "text": "and this essentially processes every event\nthat users perform on the app.",
    "start": "182458",
    "end": "186750"
  },
  {
    "text": "So, if they log in, if they book a ride, make a purchase,\neverything is processed by the system.",
    "start": "186792",
    "end": "191375"
  },
  {
    "text": "So, as these events happen,",
    "start": "191958",
    "end": "193292"
  },
  {
    "text": "they're streamed in real-time through this SQS queue,\ninto our core code base in Beanstalk.",
    "start": "193333",
    "end": "198458"
  },
  {
    "text": "And that data is then, again,\nprocessed and transformed and written to the database.",
    "start": "198917",
    "end": "203458"
  },
  {
    "text": "And then once that ride happens,\nit triggers a second read as well.",
    "start": "204125",
    "end": "207625"
  },
  {
    "text": "And this read is, again, our core code base,",
    "start": "208000",
    "end": "210792"
  },
  {
    "text": "extracting all the data about this user\nand their surrounding neighbors in the graph.",
    "start": "211000",
    "end": "216250"
  },
  {
    "text": "Once we've extracted that data,",
    "start": "216833",
    "end": "218125"
  },
  {
    "text": "we then have a simple set of rules\nthat run in here to try to decide",
    "start": "218167",
    "end": "222667"
  },
  {
    "text": "whether that action performed by the user\nis likely to be fraudulent or not.",
    "start": "222708",
    "end": "225875"
  },
  {
    "text": "Okay, so what kind of accuracy are you\ngetting from this rule-based setup?",
    "start": "226292",
    "end": "229958"
  },
  {
    "text": "Yes, it's a very simple set of rules at the moment,\nbut we're already hitting a precision of right about 90%.",
    "start": "230000",
    "end": "235667"
  },
  {
    "text": "That's very impressive.\nOkay, and what do you do with the other 10%?",
    "start": "235958",
    "end": "240000"
  },
  {
    "text": "So, what happens once we make a classification\nwhether a user is fraudulent or not,",
    "start": "241208",
    "end": "245500"
  },
  {
    "text": "the decision is written to the database,\nand then that decision can go one of two ways.",
    "start": "245917",
    "end": "250583"
  },
  {
    "text": "So, we have another project that measures\nhow valuable customers are to us.",
    "start": "250625",
    "end": "254167"
  },
  {
    "text": "So, if they're a high-value customer,",
    "start": "254542",
    "end": "258833"
  },
  {
    "text": "they're added to a queue in a ticketing system\nto be manually reviewed.",
    "start": "258875",
    "end": "262333"
  },
  {
    "text": "So, it requires some manual intervention to see\nif that user should be blocked or not.",
    "start": "262708",
    "end": "267250"
  },
  {
    "text": "Otherwise, if they're a lower-value user,\nthey're just automatically blocked by the project.",
    "start": "267667",
    "end": "271457"
  },
  {
    "text": "Because you don't want your high-value customer\nto be blocked in an automatic manner.",
    "start": "271583",
    "end": "274708"
  },
  {
    "text": "Yeah, exactly, with 90% precision,\nwe don't want to be having 10% false positives of genuine users.",
    "start": "275083",
    "end": "280333"
  },
  {
    "text": "And what kind of scale are we talking\nabout in terms of blocking?",
    "start": "280583",
    "end": "282625"
  },
  {
    "start": "283000",
    "end": "353000"
  },
  {
    "text": "And so, to date, since we launched the project,\nwe've blocked about 35,000 users.",
    "start": "283042",
    "end": "288375"
  },
  {
    "text": "So, 35,000 bad actors?",
    "start": "289000",
    "end": "291042"
  },
  {
    "text": "Yeah, pretty much.",
    "start": "291125",
    "end": "292167"
  },
  {
    "text": "So, you have many divisions within the company.",
    "start": "293208",
    "end": "295292"
  },
  {
    "text": "How do they get benefit from this\narchitecture that you've created?",
    "start": "295333",
    "end": "299417"
  },
  {
    "text": "So, we built this huge graph,\nobviously with the intention for fraud detection project,",
    "start": "300208",
    "end": "305042"
  },
  {
    "text": "but obviously, once we realized we have\nall this wealth of data in the graph,",
    "start": "305500",
    "end": "309250"
  },
  {
    "text": "it could be used by all different teams across Careem.",
    "start": "309500",
    "end": "312625"
  },
  {
    "text": "So, we expose the graph to an API,\nand this allows anyone in Careem to then query the graph,",
    "start": "312875",
    "end": "318750"
  },
  {
    "text": "get the details about a user\nand their identity in the graph.",
    "start": "318792",
    "end": "323125"
  },
  {
    "text": "This can be used by teams in Careem\nfor downstream tasks,",
    "start": "323542",
    "end": "326875"
  },
  {
    "text": "such as building different machine learning models\nthat use this data.",
    "start": "326917",
    "end": "330082"
  },
  {
    "text": "Otherwise, another example is we have a UI,\nwhich allows anyone to view a particular user in the graph",
    "start": "330417",
    "end": "336250"
  },
  {
    "text": "and see what they look like\nand who they're sharing data with.",
    "start": "336292",
    "end": "338957"
  },
  {
    "text": "Yep, okay. So, what's next for you\nin terms of the architecture?",
    "start": "339792",
    "end": "342375"
  },
  {
    "text": "So, as I said, we have a very simple rule-based approach here,",
    "start": "343458",
    "end": "346708"
  },
  {
    "text": "and the aim was always to add more intelligence\nto the system to the use of machine learning.",
    "start": "347208",
    "end": "352000"
  },
  {
    "text": "So, what we're doing that for version two of the project\nis we're replacing our rules with Neptune ML.",
    "start": "352750",
    "end": "358208"
  },
  {
    "start": "353000",
    "end": "458000"
  },
  {
    "text": "And this is a framework developed by Neptune,\nwhich allows you to train deep learning models on the graph.",
    "start": "358583",
    "end": "362750"
  },
  {
    "text": "So, we're training a graph convolutional network\non all the data and users in the graph.",
    "start": "363042",
    "end": "366582"
  },
  {
    "text": "And the idea here is we'll be able to more accurately predict\nwhich users are fraudulent or not.",
    "start": "367208",
    "end": "372292"
  },
  {
    "text": "So ideally, we want to improve this\n90% precision closer to 100%.",
    "start": "372750",
    "end": "377042"
  },
  {
    "text": "And secondly, we want to improve the recall,",
    "start": "377458",
    "end": "379208"
  },
  {
    "text": "which means we will be increasing\nthe number of users we block as well.",
    "start": "379250",
    "end": "382042"
  },
  {
    "text": "And with this improved precision,\nif we get it high enough,",
    "start": "382583",
    "end": "387333"
  },
  {
    "text": "we'll be confident enough to get rid\nof this manually review system,",
    "start": "387375",
    "end": "390125"
  },
  {
    "text": "and then the whole project will be 100% automated.",
    "start": "390417",
    "end": "392625"
  },
  {
    "text": "That would be a great benefit for your company.",
    "start": "393333",
    "end": "395792"
  },
  {
    "text": "So, what is part of your wish list from AWS?",
    "start": "396417",
    "end": "399542"
  },
  {
    "text": "Yeah, so first of all, as I explained,\nwe're integrating Neptune ML now, and that was the plan.",
    "start": "400542",
    "end": "405167"
  },
  {
    "text": "But before Neptune released Neptune ML,\nwe had the plan to build this full deep-learning pipeline",
    "start": "405750",
    "end": "411750"
  },
  {
    "text": "completely in-house on our own,\nwhich would be a huge amount of work.",
    "start": "411792",
    "end": "414582"
  },
  {
    "text": "So, now that Neptune has released Neptune ML,\nit takes a lot of the workload off of us",
    "start": "414875",
    "end": "418583"
  },
  {
    "text": "and we can focus on building\nthe most powerful model possible.",
    "start": "418625",
    "end": "421792"
  },
  {
    "text": "And secondly, a lot of our data.",
    "start": "422375",
    "end": "423958"
  },
  {
    "text": "In a graph, you have properties on both nodes and edges.",
    "start": "424667",
    "end": "427582"
  },
  {
    "text": "And we have a huge amount of properties\non both the nodes and edges,",
    "start": "428042",
    "end": "431042"
  },
  {
    "text": "but currently, most deep learning models\nonly focus on the node properties,",
    "start": "431083",
    "end": "435000"
  },
  {
    "text": "whereas now Neptune ML,\nwe're working with the Neptune ML team",
    "start": "435042",
    "end": "438417"
  },
  {
    "text": "to develop a new type of model that will also use\nall of these properties on edges that we have in the graph.",
    "start": "438458",
    "end": "442833"
  },
  {
    "text": "That makes a lot of sense.",
    "start": "443083",
    "end": "444125"
  },
  {
    "text": "Kevin, thank you for sharing your work with me today.",
    "start": "444500",
    "end": "447083"
  },
  {
    "text": "Thank you, Kamran.",
    "start": "447292",
    "end": "448292"
  },
  {
    "text": "And thank you for joining 'This is My Architecture'.",
    "start": "448917",
    "end": "451250"
  }
]
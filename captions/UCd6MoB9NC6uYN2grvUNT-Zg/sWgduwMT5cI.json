[
  {
    "text": "hello can you guys hear me again",
    "start": "2179",
    "end": "6980"
  },
  {
    "text": "Thanks great so welcome to ATC 3:02 session",
    "start": "7589",
    "end": "14389"
  },
  {
    "text": "today we are going to talk about life lessons and I'll talk about my life",
    "start": "14389",
    "end": "19820"
  },
  {
    "text": "journey so my superpower is like I can sleep anywhere anytime in any position so",
    "start": "19820",
    "end": "27449"
  },
  {
    "text": "extending I can sleep literally I was coming with these guys from MGM to here",
    "start": "27449",
    "end": "33300"
  },
  {
    "text": "and I was sleeping in the bus so that's the my superpower let's talk about we",
    "start": "33300",
    "end": "39840"
  },
  {
    "text": "just superpower no okay let's talk about digital advertising business in today's",
    "start": "39840",
    "end": "46710"
  },
  {
    "text": "session we are going to talk about how we implemented Google double-click",
    "start": "46710",
    "end": "53820"
  },
  {
    "text": "campaign data using few AWS services we did the machine learning part and also",
    "start": "53820",
    "end": "59010"
  },
  {
    "text": "the data transformation part with me today we have Abraham from Amazon a 19",
    "start": "59010",
    "end": "64699"
  },
  {
    "text": "VJ his solution builder working in solution a great team and myself Shashi",
    "start": "64700",
    "end": "69840"
  },
  {
    "text": "working in AWS as well",
    "start": "69840",
    "end": "73700"
  },
  {
    "text": "so in today's world we are working with huge data set we accumulate so much of",
    "start": "78710",
    "end": "87180"
  },
  {
    "text": "the data in few weeks if not months and we are talking in petabytes nowadays and",
    "start": "87180",
    "end": "92490"
  },
  {
    "text": "in digital advertising we are proud to play with such data set right and",
    "start": "92490",
    "end": "98810"
  },
  {
    "text": "machine learning has not been new in this organization in digital advertising",
    "start": "98810",
    "end": "103890"
  },
  {
    "text": "we have been using as a developer data scientist whenever we go to any slot",
    "start": "103890",
    "end": "109410"
  },
  {
    "text": "machine we try to figure out the probability of winning and then try to win from that and sometimes we do so",
    "start": "109410",
    "end": "118259"
  },
  {
    "text": "similarly you might be also using few processors the ways of actually running",
    "start": "118259",
    "end": "123810"
  },
  {
    "text": "the digital advertising like look like model cost optimization campaign",
    "start": "123810",
    "end": "129479"
  },
  {
    "text": "optimization but when you are starting",
    "start": "129479",
    "end": "136440"
  },
  {
    "text": "in digital advertising world with",
    "start": "136440",
    "end": "141810"
  },
  {
    "text": "machine learning part right like let's suppose you are running a lot of big data core concepts but if you are",
    "start": "141810",
    "end": "148650"
  },
  {
    "text": "getting in the machine learning part there are a few challenges initially if you are around infrastructure like",
    "start": "148650",
    "end": "155579"
  },
  {
    "text": "scaling can you scale up or down based on your requirement then processing time",
    "start": "155579",
    "end": "161250"
  },
  {
    "text": "how fast can you get the outcome because businesses don't want to wait for the outcome and neither we do want to wait",
    "start": "161250",
    "end": "167760"
  },
  {
    "text": "and look at our machine and its processing processing processing so that one part and the second part is also",
    "start": "167760",
    "end": "174359"
  },
  {
    "text": "around the skill set itself if you are pretty good at what we do but suddenly",
    "start": "174359",
    "end": "180000"
  },
  {
    "text": "there is a new technology we need to use are we good at that do we need to start",
    "start": "180000",
    "end": "185010"
  },
  {
    "text": "learning on that just to get our day job to be done AWS helps simplifies those challenges",
    "start": "185010",
    "end": "193380"
  },
  {
    "text": "with it up with advent of AWS cloud computing or cloud computing in general",
    "start": "193380",
    "end": "199109"
  },
  {
    "text": "we got to touch such a huge compute resources memory power right now we can",
    "start": "199109",
    "end": "206010"
  },
  {
    "text": "run process huge amount of data and now when we start machine",
    "start": "206010",
    "end": "211080"
  },
  {
    "text": "to start actually process these data AWS can help with the core concepts like",
    "start": "211080",
    "end": "219240"
  },
  {
    "text": "scaling you can easily scale up or down based on the requirement how fast you",
    "start": "219240",
    "end": "224850"
  },
  {
    "text": "want to actually get your outcome to be done how fast you want to process the data you can easily scale up based on",
    "start": "224850",
    "end": "230580"
  },
  {
    "text": "that and whenever you need to actually save cost you go ahead and scale down within few minutes if not seconds then",
    "start": "230580",
    "end": "239370"
  },
  {
    "text": "other part of it is again the skill set with so many AWS managed services you",
    "start": "239370",
    "end": "245640"
  },
  {
    "text": "don't need to start learning from scratch everything what you need to do for the new technology you are actually",
    "start": "245640",
    "end": "251190"
  },
  {
    "text": "going to adopt you can use these manage services and with those manage services",
    "start": "251190",
    "end": "256260"
  },
  {
    "text": "you will be able to get started right away it's always circle with this what",
    "start": "256260",
    "end": "266160"
  },
  {
    "text": "we are trying is when's first it start from the business understanding in the",
    "start": "266160",
    "end": "271310"
  },
  {
    "text": "data analysis part once we have some understanding that this is what exactly want me to we want to do we go ahead and",
    "start": "271310",
    "end": "278550"
  },
  {
    "text": "understand the data first data is understood next we prepare the data",
    "start": "278550",
    "end": "283740"
  },
  {
    "text": "which is like transformation piece exploring the data once that part is done then you start building your",
    "start": "283740",
    "end": "290510"
  },
  {
    "text": "training part you are training your data getting the evaluation getting the performance you don't like the",
    "start": "290510",
    "end": "297150"
  },
  {
    "text": "performance you go back and train more you add more features once you have done that again check the performance when",
    "start": "297150",
    "end": "304500"
  },
  {
    "text": "you find it pretty well you go ahead next and deploy it and you get the outcome and businesses are happy in",
    "start": "304500",
    "end": "312960"
  },
  {
    "text": "today's session we are going to go through two demos around data analysis",
    "start": "312960",
    "end": "320220"
  },
  {
    "text": "and the transformation part we will use all the AWS services which is related to",
    "start": "320220",
    "end": "325710"
  },
  {
    "text": "these two demo and then I will hand over to a Braham from Amazon a nine who will",
    "start": "325710",
    "end": "331650"
  },
  {
    "text": "take us to the Luca like modeling who heated using fewer del play services let",
    "start": "331650",
    "end": "339840"
  },
  {
    "text": "us understand the workflow we are going to work with two data set",
    "start": "339840",
    "end": "344910"
  },
  {
    "text": "one is activity table and another is impression activity I mean you guys must",
    "start": "344910",
    "end": "350430"
  },
  {
    "text": "be already aware but just to give introduction with activity the data which is user is already converted that",
    "start": "350430",
    "end": "357630"
  },
  {
    "text": "means he or she has already purchased versus impression table which is more like all the users who have browsed the",
    "start": "357630",
    "end": "364740"
  },
  {
    "text": "session and the images were placed on those sessions so impression table in general will be huge compared to what",
    "start": "364740",
    "end": "371160"
  },
  {
    "text": "you will get in activity table the data transformation piece we want to do is",
    "start": "371160",
    "end": "376650"
  },
  {
    "text": "CSV to park' because all the data we are getting in CSV format initially and then",
    "start": "376650",
    "end": "383850"
  },
  {
    "text": "we go deeper in the machine learning aspect what do we want to do in the",
    "start": "383850",
    "end": "388950"
  },
  {
    "text": "workflow also about the data side the",
    "start": "388950",
    "end": "394260"
  },
  {
    "text": "activity table and impression table we are going to use very few specific columns because you know that like",
    "start": "394260",
    "end": "399690"
  },
  {
    "text": "hundreds of columns in the activity or a compression table so we will use few generic ones like activity ID user ID",
    "start": "399690",
    "end": "407190"
  },
  {
    "text": "site ID and then we'll have you specifics to the features like browser",
    "start": "407190",
    "end": "412440"
  },
  {
    "text": "ID platform ID or operating system ID so this is the workflow looks like we are",
    "start": "412440",
    "end": "420840"
  },
  {
    "text": "going to go for the data transformation piece where we will actually do the transformation exploration and also",
    "start": "420840",
    "end": "428280"
  },
  {
    "text": "visualization and then we will have the second workflow in which we will go ahead and do the data feature",
    "start": "428280",
    "end": "434460"
  },
  {
    "text": "engineering let's dive deeper in the first one now in the first one our",
    "start": "434460",
    "end": "441540"
  },
  {
    "text": "assumption is that your all data is coming from all the whole world like",
    "start": "441540",
    "end": "448710"
  },
  {
    "text": "from ad exchanges your parts and you are streaming all those data in log format",
    "start": "448710",
    "end": "453780"
  },
  {
    "text": "or for activity and impression and ending up at central location in our",
    "start": "453780",
    "end": "460440"
  },
  {
    "text": "case say s3 bucket once you have all the data at the s3 bucket that is where we",
    "start": "460440",
    "end": "466290"
  },
  {
    "text": "take it from there right CSV format that's what we have in this trie bucket your data is time",
    "start": "466290",
    "end": "473190"
  },
  {
    "text": "series format we are going to use AWS glue AWS glue is",
    "start": "473190",
    "end": "478930"
  },
  {
    "text": "ETL extract transform load fully managed service which we will use to do the",
    "start": "478930",
    "end": "484060"
  },
  {
    "text": "transformation piece once we have that we go ahead and explore the data are using AWS Athena which is sequel query",
    "start": "484060",
    "end": "491770"
  },
  {
    "text": "interface where you can run your all interesting and favorite sequel queries and then at the end we will use quick",
    "start": "491770",
    "end": "498310"
  },
  {
    "text": "site to actually go ahead and visualize the data and that will also be helpful",
    "start": "498310",
    "end": "504789"
  },
  {
    "text": "to business intelligence builds business analyst team to create lot of reports",
    "start": "504789",
    "end": "510580"
  },
  {
    "text": "share it with your customer vendors or even internal teams so let's switch to",
    "start": "510580",
    "end": "517029"
  },
  {
    "text": "the demo so this is the first demo and we are trying to go live so if it",
    "start": "517029",
    "end": "523990"
  },
  {
    "text": "doesn't work we have backup plan so we are starting with AWS glue as I said we",
    "start": "523990",
    "end": "531040"
  },
  {
    "text": "have we are assuming that your whole data set is already coming to a thrips bucket in central location you might be",
    "start": "531040",
    "end": "538000"
  },
  {
    "text": "using say AWS Canisius to stream all the data and once you have that we start",
    "start": "538000",
    "end": "543490"
  },
  {
    "text": "using glue for the next stage at the left side you will see there are multiple section under AWS glue the",
    "start": "543490",
    "end": "551050"
  },
  {
    "text": "first part is data catalog data catalog actually helps to create and automatically creates the metadata and",
    "start": "551050",
    "end": "558670"
  },
  {
    "text": "the indices of your data how will it do it it will actually do it through",
    "start": "558670",
    "end": "564279"
  },
  {
    "text": "crawler so we'll create a crawler which will crawl through your source data and",
    "start": "564279",
    "end": "569770"
  },
  {
    "text": "understand the data even if you are changing the data set it can actually understand that and update in that - and",
    "start": "569770",
    "end": "576450"
  },
  {
    "text": "it will create the indices for you you don't have to go ahead and could do it so let's actually go ahead and try to",
    "start": "576450",
    "end": "583839"
  },
  {
    "text": "create a crawler which will help us to create the table as well right in the database under data catalog crawler name",
    "start": "583839",
    "end": "592000"
  },
  {
    "text": "so there are just like five six steps pretty easy ones we'll just walk through",
    "start": "592000",
    "end": "597040"
  },
  {
    "text": "few steps this is where we actually tell where is the data stored so this is the data",
    "start": "597040",
    "end": "602709"
  },
  {
    "text": "source we are going to check so with the name you can understand it's a",
    "start": "602709",
    "end": "608360"
  },
  {
    "text": "synthetic data so this is the source where we have the data where the crawler",
    "start": "608360",
    "end": "613579"
  },
  {
    "text": "will go ahead and crawl it's asking if you need to add more data stored in our",
    "start": "613579",
    "end": "620329"
  },
  {
    "text": "case we'll just go with none next yeah here AWS glue needs to talk to s3 bucket",
    "start": "620329",
    "end": "626839"
  },
  {
    "text": "right so you have to give permission for AWS glue to talk to s3 so for that you",
    "start": "626839",
    "end": "632689"
  },
  {
    "text": "have to have an iamb role in our case we already created that role and we'll go with that next this is interesting the",
    "start": "632689",
    "end": "640939"
  },
  {
    "text": "crawler you can assign how frequently you want this caller to run and refresh",
    "start": "640939",
    "end": "646009"
  },
  {
    "text": "the data and push it in a tabular format so you can go hourly daily weekly",
    "start": "646009",
    "end": "651560"
  },
  {
    "text": "however your requirement is we're in the business just for this one will go with run on-demand and now we actually create",
    "start": "651560",
    "end": "661939"
  },
  {
    "text": "the table under the database so we have the database already created we add prefix just to recognize what the",
    "start": "661939",
    "end": "669050"
  },
  {
    "text": "actually table will be and that's it done so go ahead and close it we already",
    "start": "669050",
    "end": "674089"
  },
  {
    "text": "have this X following exact same steps one of these two crawler can you hover",
    "start": "674089",
    "end": "680810"
  },
  {
    "text": "on the crawler just to show which one yeah CSV so this is the one which we created with exactly the same process no",
    "start": "680810",
    "end": "687680"
  },
  {
    "text": "change so once we have that it gives us a table which is in CSV format like it's",
    "start": "687680",
    "end": "694339"
  },
  {
    "text": "reading the CSV data but really we need to do the transformation piece we want to transform the data from CSV to",
    "start": "694339",
    "end": "701420"
  },
  {
    "text": "parquet so that it will be easily readable with the distributed system so",
    "start": "701420",
    "end": "706790"
  },
  {
    "text": "for that you have to actually go for jobs and that's what it will transform so in our case we'll create a job go",
    "start": "706790",
    "end": "714800"
  },
  {
    "text": "ahead and click Add job again you have to give a role because it will in our",
    "start": "714800",
    "end": "722449"
  },
  {
    "text": "case we are fetching the data from s3 bucket and we are pushing it back as well as a degree audit so in our case we",
    "start": "722449",
    "end": "730399"
  },
  {
    "text": "had we go ahead and select so in this case we have to do script and temporary directory where it will actually go",
    "start": "730399",
    "end": "736939"
  },
  {
    "text": "ahead and do its transformation temporarily and the scriptura tree next",
    "start": "736939",
    "end": "743670"
  },
  {
    "text": "to choose the CSP one right here you are",
    "start": "743670",
    "end": "748740"
  },
  {
    "text": "creating the target where do you want to push it back so in our case we will go ahead and select s3 and the format we",
    "start": "748740",
    "end": "756690"
  },
  {
    "text": "want to select is parking brake and the target path variable you want in the s3",
    "start": "756690",
    "end": "762720"
  },
  {
    "text": "side next you'll see the mapping so the",
    "start": "762720",
    "end": "769290"
  },
  {
    "text": "first magic part that crawler actually created the indices and now it is asking do you want mapping one on one if just",
    "start": "769290",
    "end": "777720"
  },
  {
    "text": "for the demo we'll go with one on one but this is where you can actually edit it as well if you want to and do next",
    "start": "777720",
    "end": "783300"
  },
  {
    "text": "and that's it now you have a job which can transform the data from CSV to Park",
    "start": "783300",
    "end": "789480"
  },
  {
    "text": "a close and we created this job just to",
    "start": "789480",
    "end": "794880"
  },
  {
    "text": "show you guys here I did so remember when I was actually talking",
    "start": "794880",
    "end": "801750"
  },
  {
    "text": "about that you have if you have to start a new technology you have to learn a lot",
    "start": "801750",
    "end": "806880"
  },
  {
    "text": "add new skills that in your team so if you are not like working with PI spark",
    "start": "806880",
    "end": "812940"
  },
  {
    "text": "say and if you are not doing data transformation this way AWS blue is helping to do that so what",
    "start": "812940",
    "end": "819390"
  },
  {
    "text": "we did in turn behind the scene it actually went ahead and created automatically script for us in PI spark",
    "start": "819390",
    "end": "826080"
  },
  {
    "text": "format which you can understand edit if you want or if you just wanted to transform the data from CSV to park' you",
    "start": "826080",
    "end": "833100"
  },
  {
    "text": "could have done that so this is pretty cool I like that because I don't know PI's Parker so now close it and we have",
    "start": "833100",
    "end": "840270"
  },
  {
    "text": "that job running now can you go back to tables we have second table which is",
    "start": "840270",
    "end": "845820"
  },
  {
    "text": "actually once the transformation is done it's in part a format in s3 buckets somewhere so I have to create another",
    "start": "845820",
    "end": "851910"
  },
  {
    "text": "crawler which will crawl through the data of park' and create the table and that's what we did here and we have the",
    "start": "851910",
    "end": "858870"
  },
  {
    "text": "table ready so if you want to visualize this data and you really want to use",
    "start": "858870",
    "end": "864330"
  },
  {
    "text": "sequel query so there is a direct connection from blue to Athena so this is",
    "start": "864330",
    "end": "869980"
  },
  {
    "text": "magic what it happens here is Athena can talk to glue that occurred a lot",
    "start": "869980",
    "end": "875530"
  },
  {
    "text": "indirectly now you have the database which you created in the glue part is directly showing up here and now you can",
    "start": "875530",
    "end": "881680"
  },
  {
    "text": "start running queries so the transformation has happened you have the interface run your favorite",
    "start": "881680",
    "end": "887530"
  },
  {
    "text": "sequel queries here and explore the data as much as you can so Vijay ran like",
    "start": "887530",
    "end": "892810"
  },
  {
    "text": "first few 10 columns 10 rows just to show it second part is if you want to",
    "start": "892810",
    "end": "900430"
  },
  {
    "text": "create another table through aw Athena can you go back naina so you have an",
    "start": "900430",
    "end": "907480"
  },
  {
    "text": "option create table and now we have applied that you can automatically create a table in the blue catalog and",
    "start": "907480",
    "end": "915520"
  },
  {
    "text": "this if he clicks it will go back to the crawler section of AWS glue and you can",
    "start": "915520",
    "end": "920770"
  },
  {
    "text": "create the table so pretty well interconnected between the data transformation piece and the sequel",
    "start": "920770",
    "end": "927730"
  },
  {
    "text": "query interface piece so now we have done the transformation we have done the exploration next we want to actually",
    "start": "927730",
    "end": "934270"
  },
  {
    "text": "visualize we want to create a report or something for that we are going to use quick side so we will create a new",
    "start": "934270",
    "end": "939520"
  },
  {
    "text": "analysis a new data set and here you are",
    "start": "939520",
    "end": "945010"
  },
  {
    "text": "able to select Athena so now it's fully connected from glue to Athena to quick",
    "start": "945010",
    "end": "950170"
  },
  {
    "text": "side so quick side is able to talk to the same table we created inside the AWS glue and if I want to explore the data I",
    "start": "950170",
    "end": "957490"
  },
  {
    "text": "want to actually edit the script directly inside the quick side itself",
    "start": "957490",
    "end": "964660"
  },
  {
    "text": "and don't go back and forth between Athena I can do that so edit yeah so",
    "start": "964660",
    "end": "971050"
  },
  {
    "text": "table left side so this gives me option",
    "start": "971050",
    "end": "976930"
  },
  {
    "text": "to edit and run the sequel query in the quick set itself so I can do my",
    "start": "976930",
    "end": "982090"
  },
  {
    "text": "visualization customize it however I want so I just this is just for the demo",
    "start": "982090",
    "end": "987160"
  },
  {
    "text": "part like you can you have an interface here as well can you go back to AWS quick search yeah so I created one similar to that my",
    "start": "987160",
    "end": "995410"
  },
  {
    "text": "visualization is actually showing three fields one is user ID site ID",
    "start": "995410",
    "end": "1003480"
  },
  {
    "text": "and third is I'm grouping by Weiss I tidy and every like if you hover on one",
    "start": "1003480",
    "end": "1010829"
  },
  {
    "text": "yeah so what it is trying to show is that I have a glasses and I did not put",
    "start": "1010829",
    "end": "1016199"
  },
  {
    "text": "it so the site ID is 1 5 7 3 3 1 8 has so many users sorted down and showing",
    "start": "1016199",
    "end": "1023430"
  },
  {
    "text": "how many times certain user visited this site ID for the given period for the",
    "start": "1023430",
    "end": "1030120"
  },
  {
    "text": "data so if I have like in my case I have data for 30 days it's showing user first user ID actually visited 27 times on",
    "start": "1030120",
    "end": "1038130"
  },
  {
    "text": "this site so again this is just an example you can do whatever you want and create a lot of good reports for your",
    "start": "1038130",
    "end": "1044730"
  },
  {
    "text": "team and vendors right so that's the part for the visualization switch to the",
    "start": "1044730",
    "end": "1051450"
  },
  {
    "text": "plantation thanks yeah",
    "start": "1051450",
    "end": "1058309"
  },
  {
    "text": "so to summarize what we did we actually first assume that you have all the data",
    "start": "1058309",
    "end": "1064350"
  },
  {
    "text": "coming in s3 bucket and central location once you have that we used AWS blue for",
    "start": "1064350",
    "end": "1069510"
  },
  {
    "text": "the transformation piece from CSV to park' then we explored through sequel query on AWS Athena and then we used",
    "start": "1069510",
    "end": "1076200"
  },
  {
    "text": "quick site for reporting purposes awesome now let's get in the data",
    "start": "1076200",
    "end": "1083100"
  },
  {
    "text": "feature engineering this is the second piece for this the architecture we are",
    "start": "1083100",
    "end": "1088650"
  },
  {
    "text": "using is again starting from s3 where you have raw data in CSV format for",
    "start": "1088650",
    "end": "1095400"
  },
  {
    "text": "activity table in and impression table this time we are going to do the transformation peace with EMR spark",
    "start": "1095400",
    "end": "1102090"
  },
  {
    "text": "cluster once we have done that we get the data transform which is readily",
    "start": "1102090",
    "end": "1108240"
  },
  {
    "text": "available for machine learning library of spark which we can utilize for the machine learning features we also have",
    "start": "1108240",
    "end": "1115470"
  },
  {
    "text": "Jupiter notebook which is actually not available on EMR spark cluster natively",
    "start": "1115470",
    "end": "1121410"
  },
  {
    "text": "you have Zeppelin for sure but just so we could use Jupiter notebook we",
    "start": "1121410",
    "end": "1127679"
  },
  {
    "text": "integrated you put a notebook with the EMR spark cluster and we J actually helped to create this reference",
    "start": "1127679",
    "end": "1132809"
  },
  {
    "text": "architecture which I do you want to talk about like what you did behind the scene having an EMR clustered the",
    "start": "1132809",
    "end": "1141639"
  },
  {
    "text": "pod on a private subnet and having jupiter integrated with EMR cluster",
    "start": "1141639",
    "end": "1147399"
  },
  {
    "text": "which is not readily or natively available at the moment and then we have the alb that's all sitting on top of the",
    "start": "1147399",
    "end": "1155019"
  },
  {
    "text": "EMR clusters so that we do not have that port forwarding or foxy proxy to be done",
    "start": "1155019",
    "end": "1160509"
  },
  {
    "text": "and secondly we have SPARC ml which has a very robust integration of algorithms",
    "start": "1160509",
    "end": "1167769"
  },
  {
    "text": "for model training so we are having Spock ml deployed on an EMR cluster and",
    "start": "1167769",
    "end": "1174009"
  },
  {
    "text": "we are running this complete solution so let's go ahead with the demo yeah so Before we jump to demo one question you",
    "start": "1174009",
    "end": "1180879"
  },
  {
    "text": "may ask is why are using some time AWS glue sometimes he must Sparkle ester to",
    "start": "1180879",
    "end": "1185919"
  },
  {
    "text": "do same thing both has its own advantages with EMR Sparkle ester you get to control the cluster size you can",
    "start": "1185919",
    "end": "1192820"
  },
  {
    "text": "scale up or scale down however you want it has sparked so it has a lot of open source goodies like machine learning in",
    "start": "1192820",
    "end": "1199090"
  },
  {
    "text": "my case and it AWS glue it's fully automated service you could see that just for with few clicks me not knowing",
    "start": "1199090",
    "end": "1206559"
  },
  {
    "text": "PI spark could easily start transformation from CSV to park' and I",
    "start": "1206559",
    "end": "1211720"
  },
  {
    "text": "can have a cron job running for me and I don't have to worry so both has its own good in this case we went with Sparkle",
    "start": "1211720",
    "end": "1218769"
  },
  {
    "text": "ester okay let's actually when to go to demo for",
    "start": "1218769",
    "end": "1225309"
  },
  {
    "text": "the demo which I built a clot formation script which we he actually talked about that how the components look like and he",
    "start": "1225309",
    "end": "1233200"
  },
  {
    "text": "has this link which is going for the alb and this al be points to jupiter",
    "start": "1233200",
    "end": "1238509"
  },
  {
    "text": "notebook and this Jupiter notebook is secured",
    "start": "1238509",
    "end": "1245720"
  },
  {
    "text": "through password which is safe that's why you didn't see but really it's secured so this is the notebook we have",
    "start": "1245720",
    "end": "1253390"
  },
  {
    "text": "so let's actually talk about what are we trying to do here with the machine",
    "start": "1253390",
    "end": "1260180"
  },
  {
    "text": "learning piece first and foremost this is synthetic data we are working on we",
    "start": "1260180",
    "end": "1266210"
  },
  {
    "text": "tried to make it as real as possible but it's really synthetic data we have",
    "start": "1266210",
    "end": "1272450"
  },
  {
    "text": "activity table and impression table both have purely synthetic data in the",
    "start": "1272450",
    "end": "1278450"
  },
  {
    "text": "summary I just wanted to let you guys know before I go stepboys our idea is to",
    "start": "1278450",
    "end": "1284510"
  },
  {
    "text": "actually understand the user behavior so user is first like we are creating",
    "start": "1284510",
    "end": "1290270"
  },
  {
    "text": "different features say we want to understand certain you like what browser",
    "start": "1290270",
    "end": "1295970"
  },
  {
    "text": "IDs users are preferring say chrome versus Internet Explorer or Firefox",
    "start": "1295970",
    "end": "1301060"
  },
  {
    "text": "similarly we want to understand what operating system ID user is preferring like iOS or Windows operating system so",
    "start": "1301060",
    "end": "1309470"
  },
  {
    "text": "and then we have another feature based on add ID so we just combine all these",
    "start": "1309470",
    "end": "1314510"
  },
  {
    "text": "and evaluate based on the evaluation week whatever performance we get we work",
    "start": "1314510",
    "end": "1320390"
  },
  {
    "text": "on that performance on the test data set and the performance will help us to",
    "start": "1320390",
    "end": "1326660"
  },
  {
    "text": "create the subset of the main data set which will actually be good and at least",
    "start": "1326660",
    "end": "1332870"
  },
  {
    "text": "we hope it will be good for our next campaign so that we are getting better conversion rate and that's our plan",
    "start": "1332870",
    "end": "1339550"
  },
  {
    "text": "we followed five steps after the transformation first was we did feature",
    "start": "1339550",
    "end": "1344900"
  },
  {
    "text": "ization then we went ahead and split the data in two pieces test data and train",
    "start": "1344900",
    "end": "1350150"
  },
  {
    "text": "data we actually did the orchestration for train data we did the model training",
    "start": "1350150",
    "end": "1355550"
  },
  {
    "text": "on the train data once the training has been done we went towards the test data",
    "start": "1355550",
    "end": "1361100"
  },
  {
    "text": "to evaluate the performance and then we used who graphs to understand the",
    "start": "1361100",
    "end": "1366230"
  },
  {
    "text": "performance better so let's actually go through the whole step so VI is actually",
    "start": "1366230",
    "end": "1373010"
  },
  {
    "text": "running this live and hoping it will work otherwise we have better plan so he's the data set",
    "start": "1373010",
    "end": "1382450"
  },
  {
    "text": "size is like 15 gig for impression table and activity table is few megabytes so",
    "start": "1382450",
    "end": "1387779"
  },
  {
    "text": "the first part is really loading the data on in the spark memory for the",
    "start": "1387779",
    "end": "1393340"
  },
  {
    "text": "activity and impression table once we load the data in the memory we go ahead",
    "start": "1393340",
    "end": "1398590"
  },
  {
    "text": "and do some cleanup work you know with cleanup I mean like deduplication of the data removing all the garbage which is",
    "start": "1398590",
    "end": "1404980"
  },
  {
    "text": "like meaningless in the set once we have the cleaner part is the cleaner part done then we actually dive first part we",
    "start": "1404980",
    "end": "1413260"
  },
  {
    "text": "are doing doing is feature addition we used one hot encoder for that which is",
    "start": "1413260",
    "end": "1418659"
  },
  {
    "text": "going to help us to convert column of indices to column of vectors once we",
    "start": "1418659",
    "end": "1424779"
  },
  {
    "text": "have done that we actually go ahead and split the data in test and train test",
    "start": "1424779",
    "end": "1430510"
  },
  {
    "text": "and train data why because we are going to do the model training on the train data and then we will test the evaluate",
    "start": "1430510",
    "end": "1436809"
  },
  {
    "text": "the performance on the test data so first we will analyze the data separation we use histogram for that go",
    "start": "1436809",
    "end": "1446020"
  },
  {
    "text": "closer to train so that train data is showing the histogram is showing converted versus non converted users",
    "start": "1446020",
    "end": "1452919"
  },
  {
    "text": "split and then similarly it is showing four test data converted versus non",
    "start": "1452919",
    "end": "1458559"
  },
  {
    "text": "converted so test looks good let's go ahead and do the actual work model training for that we are going to use",
    "start": "1458559",
    "end": "1465870"
  },
  {
    "text": "logic regression model we set up the",
    "start": "1465870",
    "end": "1470950"
  },
  {
    "text": "pipeline like I said this is the orchestration part once we have done that we go ahead and train the data training",
    "start": "1470950",
    "end": "1478240"
  },
  {
    "text": "has happened did it happen yes this",
    "start": "1478240",
    "end": "1484000"
  },
  {
    "text": "looks good yeah it's working so far now we will understand the performance first",
    "start": "1484000",
    "end": "1490029"
  },
  {
    "text": "let's clear all our confusion using confusion matrix so can you scroll down",
    "start": "1490029",
    "end": "1495370"
  },
  {
    "text": "to the confusion matrix yeah so the true positive rate is looking one nine zero",
    "start": "1495370",
    "end": "1502360"
  },
  {
    "text": "nine is the value what we are getting again this is synthetic data so with real world it",
    "start": "1502360",
    "end": "1508840"
  },
  {
    "text": "I don't know I'm into how the data will look like or the result will look like so now let's go for the compute and we",
    "start": "1508840",
    "end": "1515440"
  },
  {
    "text": "are using a UC for with the binary classifier so the output we are getting",
    "start": "1515440",
    "end": "1520870"
  },
  {
    "text": "here is 0.6 t7 which is like 67% and brahim was saying who has in-depth",
    "start": "1520870",
    "end": "1528480"
  },
  {
    "text": "experience with the real data set that this looks amazing I'm like okay so once",
    "start": "1528480",
    "end": "1536289"
  },
  {
    "text": "we have this 0.67 we actually go ahead and start doing curves graphs actually",
    "start": "1536289",
    "end": "1543870"
  },
  {
    "text": "so the graph we are first creating is ROC in the ROC we want to actually the",
    "start": "1543870",
    "end": "1551019"
  },
  {
    "text": "perfect graph would be if we go closer to 1.2 which is like left top right so towards the true positive rate that will",
    "start": "1551019",
    "end": "1558580"
  },
  {
    "text": "give us the perfect result but in our case we are based on point 67 result we",
    "start": "1558580",
    "end": "1564220"
  },
  {
    "text": "are getting the graph towards the true positive rate but on an average once we",
    "start": "1564220",
    "end": "1569679"
  },
  {
    "text": "have that we go for the precision recall with the precision recall if you go down",
    "start": "1569679",
    "end": "1576519"
  },
  {
    "text": "yeah on the graph part we are seeing the precision side that that's the relevant data how much did relevant data we actually",
    "start": "1576519",
    "end": "1583960"
  },
  {
    "text": "captured and all of that how much data we retrieved from the relevant data and",
    "start": "1583960",
    "end": "1589149"
  },
  {
    "text": "the result on an average is looking pretty awesome which is 0.85 again",
    "start": "1589149",
    "end": "1595299"
  },
  {
    "text": "result will differ in your own data set this is just what we got so let's also",
    "start": "1595299",
    "end": "1601840"
  },
  {
    "text": "talk about the why did we use the amar spark part the spark part actually",
    "start": "1601840",
    "end": "1607059"
  },
  {
    "text": "helped you could see that we could create graphs understand the performance in many different ways so spark helped",
    "start": "1607059",
    "end": "1613510"
  },
  {
    "text": "us to do that if you guys are data scientist you love Python you can run your Python script so you can use PI",
    "start": "1613510",
    "end": "1619210"
  },
  {
    "text": "spark for that if you like Escalon modules you can go ahead and use a scale and module so open source community is",
    "start": "1619210",
    "end": "1625929"
  },
  {
    "text": "so good with spark I don't have to like tell a lot about it you guys already aware it helps a lot to go with this",
    "start": "1625929",
    "end": "1633760"
  },
  {
    "text": "part in this case once we are done with this we have the good result we have the",
    "start": "1633760",
    "end": "1639520"
  },
  {
    "text": "better data set which is the subset of the bigger set which we are going to use for our next",
    "start": "1639520",
    "end": "1646179"
  },
  {
    "text": "campaign and we are hoping we will have better conversion and businesses will be",
    "start": "1646179",
    "end": "1651399"
  },
  {
    "text": "happy cuz that's it and then we just clean up the memory of spark the last",
    "start": "1651399",
    "end": "1656620"
  },
  {
    "text": "that was the last step to start our new job if we need to great thanks and we",
    "start": "1656620",
    "end": "1662710"
  },
  {
    "text": "switch thanks so now we are back to demo",
    "start": "1662710",
    "end": "1668429"
  },
  {
    "text": "sorry the presentation so in summary what we did once we had the s3 bucket with all",
    "start": "1668429",
    "end": "1676000"
  },
  {
    "text": "the data in RAW format for for activity and impression table we went ahead and",
    "start": "1676000",
    "end": "1681429"
  },
  {
    "text": "used EMR spark cluster for the data feature engineering with the machine",
    "start": "1681429",
    "end": "1687340"
  },
  {
    "text": "land level machine learning library and then we used Jupiter notebook to run all",
    "start": "1687340",
    "end": "1692620"
  },
  {
    "text": "the steps and I am hoping the data scientist in the middle will love to see",
    "start": "1692620",
    "end": "1698500"
  },
  {
    "text": "the notebooks now I will hand over to a prom will walk us through how he used few AWS",
    "start": "1698500",
    "end": "1706000"
  },
  {
    "text": "services to create look-alike model yeah",
    "start": "1706000",
    "end": "1711129"
  },
  {
    "text": "thank you yes I am Abraham I am from a nine which is an Amazon company in Palo",
    "start": "1711129",
    "end": "1716889"
  },
  {
    "text": "Alto and we work on advertising particular the science side of",
    "start": "1716889",
    "end": "1722110"
  },
  {
    "text": "advertising so we've seen today how different AWS services can be used to do",
    "start": "1722110",
    "end": "1727960"
  },
  {
    "text": "lots of interesting things in advertising I'm going to talk about one aspect which is targeting this equation",
    "start": "1727960",
    "end": "1736919"
  },
  {
    "text": "is pretty much everything you need to know about advertising has all the major",
    "start": "1736919",
    "end": "1742750"
  },
  {
    "text": "pieces in there so every ad server you'll ever see works something like this first we take a list of ads that",
    "start": "1742750",
    "end": "1750220"
  },
  {
    "text": "are eligible for a given request I denote this by a of X or X is the request and then we calculate an",
    "start": "1750220",
    "end": "1757690"
  },
  {
    "text": "expected value that's what the B function comes in that expected value then we select the one that has a",
    "start": "1757690",
    "end": "1764470"
  },
  {
    "text": "highest value and then leave it it's a little bit simplified but these are the",
    "start": "1764470",
    "end": "1769690"
  },
  {
    "text": "main components of an ad targeting system you've got bidding which is something that computes the",
    "start": "1769690",
    "end": "1775720"
  },
  {
    "text": "expected value then you have ad selection and before you can even get started with all that you have targeting",
    "start": "1775720",
    "end": "1781090"
  },
  {
    "text": "and so if you have a double click bid manager campaign one of the things you",
    "start": "1781090",
    "end": "1787330"
  },
  {
    "text": "have the most control is of is the targeting how you set up that campaign how you do the targeting and so in order",
    "start": "1787330",
    "end": "1794200"
  },
  {
    "text": "to understand you know what targeting is we're gonna dive in a little bit deeper into what that looks like so I like to",
    "start": "1794200",
    "end": "1801310"
  },
  {
    "text": "think of targeting as a set of if-then rules or triggers you might think of it",
    "start": "1801310",
    "end": "1807460"
  },
  {
    "text": "as if a particular function gets evaluated on the requests or the context",
    "start": "1807460",
    "end": "1813040"
  },
  {
    "text": "and that returns true then this ad is eligible to be shown so then that function we saw earlier of a of X would",
    "start": "1813040",
    "end": "1819700"
  },
  {
    "text": "be all the ads that are eligible to be shown for the user so that's all the triggers that return true now there are",
    "start": "1819700",
    "end": "1826390"
  },
  {
    "text": "many different ways to do ad targeting we'll talk about some of the major ones here the first is what you'd call state",
    "start": "1826390",
    "end": "1833980"
  },
  {
    "text": "based ad targeting and that's where demographics and geography tend to come",
    "start": "1833980",
    "end": "1839230"
  },
  {
    "text": "in these are properties of the user that don't change very often they're very popular in display ads the next is",
    "start": "1839230",
    "end": "1846430"
  },
  {
    "text": "behavior based targeting which tends to look at what people have done in the past retargeting is a great example you",
    "start": "1846430",
    "end": "1853210"
  },
  {
    "text": "see an ad on Amazon and for the next month you're going to be seeing that ad wherever you go I don't I'm not in",
    "start": "1853210",
    "end": "1861250"
  },
  {
    "text": "charge of that part of business so then beyond behavior that looked at the past",
    "start": "1861250",
    "end": "1869050"
  },
  {
    "text": "data the context looks at what's happening right now so our at this moment you might be sitting in a room looking at your phone",
    "start": "1869050",
    "end": "1875260"
  },
  {
    "text": "playing a game and not paying attention to me and that might be very useful for advertising or later you might be",
    "start": "1875260",
    "end": "1881200"
  },
  {
    "text": "jogging in the park at night and a little bit creeped out about our showing you ads like that but that's an example",
    "start": "1881200",
    "end": "1887110"
  },
  {
    "text": "of context based targeting and the next one doesn't look at the past it doesn't look at the present it looks at the",
    "start": "1887110",
    "end": "1893380"
  },
  {
    "text": "future which is predictive based targeting so then that tells us you know what are we going to do are we going to",
    "start": "1893380",
    "end": "1899890"
  },
  {
    "text": "buy a product in the future are we likely to be a high-value customer or strike it big in the casino",
    "start": "1899890",
    "end": "1906480"
  },
  {
    "text": "these are all things that haven't happened yet but we can predict him and the way I like to look at predictive",
    "start": "1906480",
    "end": "1913620"
  },
  {
    "text": "targeting is by these boxes here so imagine that the entire universe of",
    "start": "1913620",
    "end": "1918660"
  },
  {
    "text": "users who can see ads is the big box the smaller box which I call the targetable",
    "start": "1918660",
    "end": "1924510"
  },
  {
    "text": "population are those users you can actually show an ad to not everybody's have seeing ads right now not",
    "start": "1924510",
    "end": "1931140"
  },
  {
    "text": "everybody's in your target customer base so a subset of these can actually see ads now some of the users you actually",
    "start": "1931140",
    "end": "1938820"
  },
  {
    "text": "care about are what we'll call the target users some of them you can show as to some of them you can't but we",
    "start": "1938820",
    "end": "1945330"
  },
  {
    "text": "actually ran an ad campaign and we found the reach users those are the users that saw the ads so right now there isn't a",
    "start": "1945330",
    "end": "1951840"
  },
  {
    "text": "lot of overlap between these users and over the process of look-alike modeling and predictive targeting we'd like to",
    "start": "1951840",
    "end": "1958770"
  },
  {
    "text": "take the reuse errs we can actually reach through targeting and match it to the target users and we'll talk a little",
    "start": "1958770",
    "end": "1965460"
  },
  {
    "text": "bit about how that works so look-alike modelling which is the subject of our",
    "start": "1965460",
    "end": "1972179"
  },
  {
    "text": "discussion now is a form of predictive targeting and sometimes the term can be confusing to people because there's",
    "start": "1972179",
    "end": "1978330"
  },
  {
    "text": "actually two different ways to do it there's one which is called similarity based targeting which is what most",
    "start": "1978330",
    "end": "1984990"
  },
  {
    "text": "people think of when they hear the term look-alike modeling because users look like other users the challenge with",
    "start": "1984990",
    "end": "1992130"
  },
  {
    "text": "similarity based targeting is no one knows how to define similarity there could be a problem and if we come up",
    "start": "1992130",
    "end": "1999059"
  },
  {
    "text": "with a definition how does that translate into an advertisers performance just because two users doing",
    "start": "1999059",
    "end": "2004520"
  },
  {
    "text": "the same thing in the past how does that mean that they're going to like buy the same product in the future so it works",
    "start": "2004520",
    "end": "2010490"
  },
  {
    "text": "great if you just have a target list of customers that you don't really know why they're important but you think they're",
    "start": "2010490",
    "end": "2016640"
  },
  {
    "text": "important classification based look-alike modeling now talks about",
    "start": "2016640",
    "end": "2022250"
  },
  {
    "text": "performance so now the users perform like the target users we can then solve for the direct advertisers problem like",
    "start": "2022250",
    "end": "2029270"
  },
  {
    "text": "conversions this can then be easily translated into revenue and the budget",
    "start": "2029270",
    "end": "2034429"
  },
  {
    "text": "that you'll be interested in and we can compute ROI based on the model and this is a great fit for activities",
    "start": "2034429",
    "end": "2040760"
  },
  {
    "text": "that we see in the double-click bid manager data such as purchases leads and signups and other sorts of things",
    "start": "2040760",
    "end": "2046820"
  },
  {
    "text": "usually targeted by pixels so now our predictive targeting looks a lot like",
    "start": "2046820",
    "end": "2053419"
  },
  {
    "text": "the trigger that we talked about before so instead of saying this user did or did not do something we have a",
    "start": "2053420",
    "end": "2059090"
  },
  {
    "text": "probability we can look at the probability that the user is going to take this action in some number of days",
    "start": "2059090",
    "end": "2065000"
  },
  {
    "text": "in the future and if that's bigger than a specific threshold we're going to show the ad so that's a fairly complicated",
    "start": "2065000",
    "end": "2071480"
  },
  {
    "text": "statement so we're going to break it down all the different pieces the user then refers to a representation we have",
    "start": "2071480",
    "end": "2078230"
  },
  {
    "text": "to define some way of looking at users we toss all earlier about different kinds of features that we could define",
    "start": "2078230",
    "end": "2084200"
  },
  {
    "text": "that's an example of a representation the next is our attribution window which is how long in the future are we gonna",
    "start": "2084200",
    "end": "2090379"
  },
  {
    "text": "wait if we show this ad to a user and it takes him a hundred days to convert that's not necessarily a great use of",
    "start": "2090380",
    "end": "2097010"
  },
  {
    "text": "our advertising budget but if he converts in the next five to seven days that might not be so bad and then the",
    "start": "2097010",
    "end": "2103070"
  },
  {
    "text": "probability is where the classifier comes in so we're going to use an ml model to predict how likely the user is",
    "start": "2103070",
    "end": "2109250"
  },
  {
    "text": "going to respond and finally there's the threshold the threshold is our main control that gives us the ability to",
    "start": "2109250",
    "end": "2116090"
  },
  {
    "text": "have a larger budget or a smaller budget it gives us a way to rank order all of the users based on that score and put",
    "start": "2116090",
    "end": "2123350"
  },
  {
    "text": "our budget where does the most good so we've seen a couple of examples of data",
    "start": "2123350",
    "end": "2129320"
  },
  {
    "text": "pipelines and I'm going to show two here the first is the training data pipeline",
    "start": "2129320",
    "end": "2134390"
  },
  {
    "text": "and that takes data from double-click we'd manager through s3 runs through EMR",
    "start": "2134390",
    "end": "2140270"
  },
  {
    "text": "into something similar to what we saw earlier zand basic machine learning models and then that can run say weekly",
    "start": "2140270",
    "end": "2147140"
  },
  {
    "text": "gives you a finally a model that you can reuse in the future then there is a scoring pipeline well it takes that same",
    "start": "2147140",
    "end": "2154340"
  },
  {
    "text": "data that might come in today scores the model against all the users and comes up with a list that then can",
    "start": "2154340",
    "end": "2160670"
  },
  {
    "text": "be uploaded into your favorite DSP and this is how you can create your own custom user segments so here's an",
    "start": "2160670",
    "end": "2168590"
  },
  {
    "text": "example of how users could be represented this is an anonymized data said it's not",
    "start": "2168590",
    "end": "2173880"
  },
  {
    "text": "a real data set but you can see all the major fields are there and you might be surprised to learn that there aren't",
    "start": "2173880",
    "end": "2180329"
  },
  {
    "text": "that many fields present you might think that we know lots of things but most of what we know comes from browser os sites",
    "start": "2180329",
    "end": "2187319"
  },
  {
    "text": "time of day and there's lots of different combinations of that we're",
    "start": "2187319",
    "end": "2192329"
  },
  {
    "text": "going to group them all of these records then by user ID which is the one thing that we have in common here and then",
    "start": "2192329",
    "end": "2198030"
  },
  {
    "text": "once we do that we're gonna generate a simple representation I call it a bag of events similar to a bag of words that",
    "start": "2198030",
    "end": "2204089"
  },
  {
    "text": "you may have heard about other areas here's a quick code snippet of how to do",
    "start": "2204089",
    "end": "2210450"
  },
  {
    "text": "this in Pais Park we're just gonna group by user ID and that's it not super",
    "start": "2210450",
    "end": "2216059"
  },
  {
    "text": "complicated there and now we're in a position once we have all the data group by user ID we can start to build our",
    "start": "2216059",
    "end": "2224220"
  },
  {
    "text": "training examples for our model and we're going to split up our data into three distinct periods the first is the",
    "start": "2224220",
    "end": "2230579"
  },
  {
    "text": "training period that's the period of time relative to the time that the actual event occurs so let's say that",
    "start": "2230579",
    "end": "2236849"
  },
  {
    "text": "you were to convert in an ad let's say yesterday you became a convertor and so we're gonna look and say n days in the",
    "start": "2236849",
    "end": "2243390"
  },
  {
    "text": "past and say how long ago do we have history for you maybe we have a month worth of history so that day - a month",
    "start": "2243390",
    "end": "2249990"
  },
  {
    "text": "is our training period then we have the target period that's where the conversion window comes in to say well",
    "start": "2249990",
    "end": "2255630"
  },
  {
    "text": "you converted today but I'm gonna look back and say the next seven days and see if you converted on any particular ad",
    "start": "2255630",
    "end": "2262650"
  },
  {
    "text": "and now we can have a predict from the training period into the targeting",
    "start": "2262650",
    "end": "2268530"
  },
  {
    "text": "period there's a section in the middle that's called the blind period now this is an important part of your modeling",
    "start": "2268530",
    "end": "2275069"
  },
  {
    "text": "process because what tends to happen is that there's a latency between the time that the user sees the ad and can",
    "start": "2275069",
    "end": "2281670"
  },
  {
    "text": "convert but in that time and the time that you can actually get the data running it through EMR generate the the",
    "start": "2281670",
    "end": "2288450"
  },
  {
    "text": "model's score the new users upload them to an ad system and have the ads shown again that could be a while yeah day or",
    "start": "2288450",
    "end": "2295680"
  },
  {
    "text": "two maybe a few days it could be a long time that has to be accounted for in your model because if you're saying well",
    "start": "2295680",
    "end": "2301020"
  },
  {
    "text": "whatever you did five minutes ago is super useful for predict performance I can't do anything about",
    "start": "2301020",
    "end": "2306499"
  },
  {
    "text": "that because I takes me a data upload a user list so when we build our",
    "start": "2306499",
    "end": "2312529"
  },
  {
    "text": "classification model we're going to create basically positive and negative example so one easy way to define those",
    "start": "2312529",
    "end": "2318589"
  },
  {
    "text": "is that if a user had the activity there positive and if they didn't have the activity there negative there are lots",
    "start": "2318589",
    "end": "2324440"
  },
  {
    "text": "of different nuances to how you can define the target labels in here and we could talk about those after the session",
    "start": "2324440",
    "end": "2330920"
  },
  {
    "text": "if you're interested so here's the quick code snippet the way I like to generate",
    "start": "2330920",
    "end": "2336980"
  },
  {
    "text": "this data is I first generate the target labels which could be a much smaller and tend to have the activities or cliques",
    "start": "2336980",
    "end": "2344180"
  },
  {
    "text": "associated with them and then I joined them with the user data and then do the",
    "start": "2344180",
    "end": "2349279"
  },
  {
    "text": "feature extraction at that time this cuts down the data set for training it makes it really efficient once we've",
    "start": "2349279",
    "end": "2356539"
  },
  {
    "text": "done all of our training you saw earlier about the precision recall curve that we saw this is a little bit different this",
    "start": "2356539",
    "end": "2363349"
  },
  {
    "text": "is a reach and precision curve the main difference here is that Reach is different from recall and reaches the",
    "start": "2363349",
    "end": "2370279"
  },
  {
    "text": "the number of users you expect to reach in your ad campaign now those of you paying attention realize that reach and",
    "start": "2370279",
    "end": "2377569"
  },
  {
    "text": "false-positive are the same thing so you could call it a false-positive curve but if you take your ad budget and",
    "start": "2377569",
    "end": "2383869"
  },
  {
    "text": "you take the total number of users because this is a user base model multiply that by a frequency cap and add",
    "start": "2383869",
    "end": "2390380"
  },
  {
    "text": "in the average CPM for your ad campaign you can kind of get at a number that's",
    "start": "2390380",
    "end": "2396049"
  },
  {
    "text": "close to the total budget size and so that's where that threshold that we talked about in the beginning comes in",
    "start": "2396049",
    "end": "2401150"
  },
  {
    "text": "the threshold gives you a cut point on the reach so now you can use that threshold to decide whether you want to",
    "start": "2401150",
    "end": "2407210"
  },
  {
    "text": "spend more or less to run show your ads we're trying to give you the best users for the budget that you have so if you",
    "start": "2407210",
    "end": "2416029"
  },
  {
    "text": "actually wanted to work on on this and build your own look-alike models it might be a good idea to run some basic",
    "start": "2416029",
    "end": "2421489"
  },
  {
    "text": "data checks the first thing is do the users in your data set have enough history to make this thing even make",
    "start": "2421489",
    "end": "2428390"
  },
  {
    "text": "sense and the so the kind of plot you can do here is to say well how many different days of history do I have for",
    "start": "2428390",
    "end": "2435739"
  },
  {
    "text": "a given use what you're looking for in this plot is a curve that sort of goes up towards the",
    "start": "2435739",
    "end": "2441380"
  },
  {
    "text": "end that means that users keep on coming back to your site we keep seeing them more and more often if all your users",
    "start": "2441380",
    "end": "2447230"
  },
  {
    "text": "started at the very beginning I don't know if you can see that but there's a peak at zero days here these are users",
    "start": "2447230",
    "end": "2452630"
  },
  {
    "text": "that tend not to save their cookies and so that's not very helpful for looking like modeling the next check is all",
    "start": "2452630",
    "end": "2460400"
  },
  {
    "text": "those features that we saw in the representation section how many of them are there how many different browsers",
    "start": "2460400",
    "end": "2465470"
  },
  {
    "text": "are there how many different operating systems which is basically all we know about users and different sites and you",
    "start": "2465470",
    "end": "2471440"
  },
  {
    "text": "can see a nice distribution here this is on a sample data set and the same thing",
    "start": "2471440",
    "end": "2477440"
  },
  {
    "text": "for sites and ads so one feature that people don't always pay attention to and lookalike modeling is the previous ads",
    "start": "2477440",
    "end": "2484820"
  },
  {
    "text": "the users have seen because there's actually a lot of information in targeting another ads so having the",
    "start": "2484820",
    "end": "2490640"
  },
  {
    "text": "historical ads people saw can be helpful too so now we've calculated all those",
    "start": "2490640",
    "end": "2497120"
  },
  {
    "text": "different accounts of things we're in a good position to start training our models we don't want to something with a",
    "start": "2497120",
    "end": "2504500"
  },
  {
    "text": "huge number of cardinality and you don't want something with a little cardinality so once we've trained all that we draw",
    "start": "2504500",
    "end": "2511580"
  },
  {
    "text": "our precision versus reach curve now those of you who can see the numbers over here will see that the precision is",
    "start": "2511580",
    "end": "2517520"
  },
  {
    "text": "actually very bad unlike the synthetic data set that was presented earlier that had amazing precision so this is a much",
    "start": "2517520",
    "end": "2525050"
  },
  {
    "text": "more realistic data set the precision tends to be very bad in advertising I'm sorry and but the point is that we can",
    "start": "2525050",
    "end": "2534440"
  },
  {
    "text": "now order our users a little bit better than random so when we started this ad campaign we targeted a hundred percent",
    "start": "2534440",
    "end": "2540920"
  },
  {
    "text": "of users and that gets us the precision at the very far end of this plot which is really bad but now with our",
    "start": "2540920",
    "end": "2547760"
  },
  {
    "text": "look-alike model we can score our users we can rank them we can pick the top ones and so if we were to just say",
    "start": "2547760",
    "end": "2553570"
  },
  {
    "text": "concentrate our budget from seven million users to the top ten percent we",
    "start": "2553570",
    "end": "2558800"
  },
  {
    "text": "could spend our budget more efficiently and we get three times higher precision which probably you could think",
    "start": "2558800",
    "end": "2566440"
  },
  {
    "text": "so we've seen how the dear various services in AWS can help with a",
    "start": "2566440",
    "end": "2572000"
  },
  {
    "text": "look-alike modeling one is s3 which is mostly where we keep all the data and that's very helpful and the second thing",
    "start": "2572000",
    "end": "2579560"
  },
  {
    "text": "is EMR we've run all of our data processing on EMR using PI spark and",
    "start": "2579560",
    "end": "2585010"
  },
  {
    "text": "technologies we can put those data pipelines into AWS data pipeline which",
    "start": "2585010",
    "end": "2590600"
  },
  {
    "text": "will run them every day or every week as needed so how could we make this better",
    "start": "2590600",
    "end": "2596900"
  },
  {
    "text": "well you've seen a lot of different extensions of using AWS today one way we",
    "start": "2596900",
    "end": "2602300"
  },
  {
    "text": "can do this is we can make this better using easy to innocence so we could build our own better so instead of",
    "start": "2602300",
    "end": "2607880"
  },
  {
    "text": "having to rely on double-click good manager to run your ad campaigns you can build your own bidder and I believe",
    "start": "2607880",
    "end": "2613010"
  },
  {
    "text": "there was a talk earlier today about how to do that the next part is Kinesis we",
    "start": "2613010",
    "end": "2618500"
  },
  {
    "text": "can gets real-time streaming data going through this thing and start to build our targeting segments and update our",
    "start": "2618500",
    "end": "2624050"
  },
  {
    "text": "models in real time we can then use SNS to listen for different conversions that are going to happen and we can respond",
    "start": "2624050",
    "end": "2630890"
  },
  {
    "text": "as soon as somebody buy something we can stop targeting them with the same ad or other stuff",
    "start": "2630890",
    "end": "2636560"
  },
  {
    "text": "and finally there's dynamo DB where we can put all this data into a giant lookup table and get data as fast as we",
    "start": "2636560",
    "end": "2644150"
  },
  {
    "text": "need it so I'll leave it now - exactly",
    "start": "2644150",
    "end": "2649599"
  },
  {
    "text": "thanks a crowd so before you walk back I have questions",
    "start": "2649869",
    "end": "2655750"
  },
  {
    "text": "Thanks so do you have a blog post coming around this yeah which you want to share",
    "start": "2655750",
    "end": "2662180"
  },
  {
    "text": "yeah that's right we'll be working on a blog post that covers how to do all of this stuff it's worked on and it's gonna",
    "start": "2662180",
    "end": "2669619"
  },
  {
    "text": "be your launch soon nice and also I heard like you called out that you can",
    "start": "2669619",
    "end": "2674869"
  },
  {
    "text": "actually do the same time series data based on the users which also pretty good right for like if you keep adding",
    "start": "2674869",
    "end": "2682400"
  },
  {
    "text": "your time series data based on the user ID that actually gives lot of benefit",
    "start": "2682400",
    "end": "2687650"
  },
  {
    "text": "when you are adding a lot of different models great so to learn more you can go",
    "start": "2687650",
    "end": "2694460"
  },
  {
    "text": "to the link we have provided the below we have all the resources",
    "start": "2694460",
    "end": "2700160"
  },
  {
    "text": "there and we are going to add more there is a Contact Us link as well under that",
    "start": "2700160",
    "end": "2706490"
  },
  {
    "text": "page where you can go ahead and click to get deeper deep dive session with our",
    "start": "2706490",
    "end": "2712040"
  },
  {
    "text": "team and even requires to workshop where we can go through the whole process we",
    "start": "2712040",
    "end": "2717349"
  },
  {
    "text": "actually demoed today and Vijay and his team is creating one-click solution as",
    "start": "2717349",
    "end": "2724069"
  },
  {
    "text": "well which you can deploy in your environment and play with the synthetic",
    "start": "2724069",
    "end": "2729559"
  },
  {
    "text": "data or if you want you can switch it to the real-life data set so that will be",
    "start": "2729559",
    "end": "2734839"
  },
  {
    "text": "coming soon so that's all we had how much time do we have 15 minutes yeah",
    "start": "2734839",
    "end": "2744079"
  },
  {
    "text": "so we can take questions if you guys have any",
    "start": "2744079",
    "end": "2748058"
  }
]
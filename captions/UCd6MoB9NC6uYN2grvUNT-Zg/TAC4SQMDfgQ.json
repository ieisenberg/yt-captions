[
  {
    "start": "0",
    "end": "31000"
  },
  {
    "text": "hello and welcome to how globe telecom does primary backups be a store reduced",
    "start": "709",
    "end": "6060"
  },
  {
    "text": "to AWS my name is Isaiah whiner I'm the senior manager of solutions architecture for AWS",
    "start": "6060",
    "end": "11519"
  },
  {
    "text": "in the partner organization and I'll be your host and moderator for today's webinar in addition to my directory",
    "start": "11519",
    "end": "19710"
  },
  {
    "text": "presentation on AWS I've been recovering word can you hear today from Hugh Emerson CTO of store",
    "start": "19710",
    "end": "26340"
  },
  {
    "text": "reduce and end Ella Cardona Infrastructure architects at Globe Telecom when we talk with customers at",
    "start": "26340",
    "end": "33390"
  },
  {
    "start": "31000",
    "end": "84000"
  },
  {
    "text": "AWS Oh a lot of customers tell us the challenges they have with storage on",
    "start": "33390",
    "end": "40950"
  },
  {
    "text": "premises and there's lots of categorizations of storage of course there's everything from primary storage",
    "start": "40950",
    "end": "47670"
  },
  {
    "text": "to backup and recovery archives and even solutions related to to BCD are what our",
    "start": "47670",
    "end": "55050"
  },
  {
    "text": "customers generally tell us is that when they address the challenges on Prem they",
    "start": "55050",
    "end": "62039"
  },
  {
    "text": "are trying to address issues around logistical complexity capital expenditure requirements the difficulty",
    "start": "62039",
    "end": "69600"
  },
  {
    "text": "of audit and regulatory compliance verification and then lastly just the",
    "start": "69600",
    "end": "75930"
  },
  {
    "text": "actual cost components the way that we try to meet those challenges is through",
    "start": "75930",
    "end": "82290"
  },
  {
    "text": "the building blocks of AWS the way that we try to address those challenges through the building blocks of AWS",
    "start": "82290",
    "end": "89369"
  },
  {
    "start": "84000",
    "end": "254000"
  },
  {
    "text": "services largely have to do with taking advantage of things that are managed and",
    "start": "89369",
    "end": "95670"
  },
  {
    "text": "what that means is that customers seek to relocate those workloads in a way",
    "start": "95670",
    "end": "101100"
  },
  {
    "text": "that gives them less infrastructure to worry about and they seek to fill the",
    "start": "101100",
    "end": "106530"
  },
  {
    "text": "gap between where those building blocks services end and where the requirements",
    "start": "106530",
    "end": "112049"
  },
  {
    "text": "begin with third-party solutions so that is an opportunity for the AWS partner",
    "start": "112049",
    "end": "117840"
  },
  {
    "text": "ecosystem to come in and fill the requirements gap what our customers tell",
    "start": "117840",
    "end": "123960"
  },
  {
    "text": "us is that by using AWS technology partner solutions like store it is they",
    "start": "123960",
    "end": "131340"
  },
  {
    "text": "enjoy the fact that they are existing workloads oftentimes the the workflow",
    "start": "131340",
    "end": "137040"
  },
  {
    "text": "itself doesn't have to change that much sometimes it doesn't have to change at all and in the process of performing the",
    "start": "137040",
    "end": "144510"
  },
  {
    "text": "integration not only are they gaining efficiencies where where it pertains to",
    "start": "144510",
    "end": "149819"
  },
  {
    "text": "cost because there's no capital expenditure but they're also having to only pay for what they use that utility",
    "start": "149819",
    "end": "156540"
  },
  {
    "text": "pricing model is something that extends not only to things like AWS ec2 and s3",
    "start": "156540",
    "end": "163440"
  },
  {
    "text": "but for our partners that embrace this similar licensing model and who can be",
    "start": "163440",
    "end": "169260"
  },
  {
    "text": "procured through the AWS marketplace that utility computing procurement model",
    "start": "169260",
    "end": "175950"
  },
  {
    "text": "extends to their solutions as well so especially in the case of where customers maybe wouldn't have an",
    "start": "175950",
    "end": "182670"
  },
  {
    "text": "opportunity to or wouldn't have an ability to perform some kind of large capex on traditional legacy applications",
    "start": "182670",
    "end": "189000"
  },
  {
    "text": "or traditional legacy solutions the ability to actually do it on an hourly basis through a davis marketplace is",
    "start": "189000",
    "end": "195359"
  },
  {
    "text": "something that's new and it not only adds to the cost efficiency but it adds just to the logistical simplicity in",
    "start": "195359",
    "end": "201720"
  },
  {
    "text": "addition to the logistical simplicity our customers tell us that using things",
    "start": "201720",
    "end": "207120"
  },
  {
    "text": "that can be deployed in a scale-out manner and adopting the cat'll approach",
    "start": "207120",
    "end": "212790"
  },
  {
    "text": "in the pet's versus cattle analogy of legacy IT workloads being pets and things in the cloud being a little bit",
    "start": "212790",
    "end": "219660"
  },
  {
    "text": "more cattle like not having to pay so much attention to the individual properties of each component but worry",
    "start": "219660",
    "end": "225419"
  },
  {
    "text": "rather you know what's my business outcome they can do that with AWS and then lastly I'm a security component the",
    "start": "225419",
    "end": "233459"
  },
  {
    "text": "ability to have repeatable and honorable environments that you can turn up you",
    "start": "233459",
    "end": "238859"
  },
  {
    "text": "know we know in a one-click fashion through things like confirmation templates and an automated QuickStart",
    "start": "238859",
    "end": "244470"
  },
  {
    "text": "set innate abuse marketplace automation means that not only are the initial",
    "start": "244470",
    "end": "250470"
  },
  {
    "text": "bring ups secure but they're also repeatedly secure and and that's really what when's the itself to the all",
    "start": "250470",
    "end": "257160"
  },
  {
    "start": "254000",
    "end": "343000"
  },
  {
    "text": "durability so the APN or Amazon partner Network strives to really highlight the",
    "start": "257160",
    "end": "265099"
  },
  {
    "text": "the best of when it comes to AWS technology partner",
    "start": "265099",
    "end": "270210"
  },
  {
    "text": "solutions and our managed services there's a lot of components to our services we have over 90 services it's",
    "start": "270210",
    "end": "276180"
  },
  {
    "text": "even hard to keep track of them we jokingly referred to it sometimes as that periodic table of services because",
    "start": "276180",
    "end": "281370"
  },
  {
    "text": "you know just a short while ago they really weren't that many services out there but now with that number very",
    "start": "281370",
    "end": "286650"
  },
  {
    "text": "quickly approaching 100 it's confusing sometimes and difficult to understand",
    "start": "286650",
    "end": "291750"
  },
  {
    "text": "where customers integrate you know some things are very easy and intuitive s3 is the Swiss Army knife storage I am for",
    "start": "291750",
    "end": "299610"
  },
  {
    "text": "example you know you're gonna have something to do with Identity Management there but then there's a whole lot of",
    "start": "299610",
    "end": "304890"
  },
  {
    "text": "things that people just maybe don't understand or see how they can they can",
    "start": "304890",
    "end": "310830"
  },
  {
    "text": "integrate with easily so if you're a startup or if you're very much on the",
    "start": "310830",
    "end": "316560"
  },
  {
    "text": "cutting edge of technology if you're developing an application there's a lot of things that you might take advantage",
    "start": "316560",
    "end": "321630"
  },
  {
    "text": "of that simply aren't applicable in a traditional IT workload for example if",
    "start": "321630",
    "end": "326940"
  },
  {
    "text": "it's an application you don't control how would you integrate it with something like you know KMS or rescue us",
    "start": "326940",
    "end": "332730"
  },
  {
    "text": "and that's where the APN technology partners come in because they've done the work for you and they get to take",
    "start": "332730",
    "end": "339420"
  },
  {
    "text": "advantage of all of these amazing developer tools but then present to our",
    "start": "339420",
    "end": "345510"
  },
  {
    "start": "343000",
    "end": "458000"
  },
  {
    "text": "customers top to bottom a complete solution so there's building blocks that I referred",
    "start": "345510",
    "end": "351000"
  },
  {
    "text": "to a lot of folks know about s3 because it was our first service it's an object storage platform I won't go into what",
    "start": "351000",
    "end": "358320"
  },
  {
    "text": "distinguishes object semantics from others but I will make analogies so for",
    "start": "358320",
    "end": "363570"
  },
  {
    "text": "example EBS our elastic block store that's a block interface other examples",
    "start": "363570",
    "end": "369060"
  },
  {
    "text": "of block interfaces are the hard drive in your computer or the flash in your phone if you have an iSCSI appliance in",
    "start": "369060",
    "end": "376350"
  },
  {
    "text": "your office that's another example of a block interface a fiber channel networks and those are all block interfaces so",
    "start": "376350",
    "end": "383850"
  },
  {
    "text": "people know about ec2 they know about EBS often is so their boot device less",
    "start": "383850",
    "end": "389340"
  },
  {
    "text": "well-known or other services like Amazon EFS which presents a unmanaged way to do",
    "start": "389340",
    "end": "397610"
  },
  {
    "text": "file interface using the NFS protocol those use cases of legacy IT workloads",
    "start": "397610",
    "end": "405440"
  },
  {
    "text": "on that are file based often take advantage of things like um fest but they can also take advantage of things",
    "start": "405440",
    "end": "410840"
  },
  {
    "text": "like EBS file system on top of them when we talk about hybrid workflows EBS is",
    "start": "410840",
    "end": "416690"
  },
  {
    "text": "something that can only be used in the cloud so hybrid workflows don't take advantage of that and for that reason a",
    "start": "416690",
    "end": "423110"
  },
  {
    "text": "lot of our technology partners are orbiting things like Amazon s3 an Amazon",
    "start": "423110",
    "end": "429830"
  },
  {
    "text": "glacier the main difference between s3 and glacier is that glacier is really designed for tape replacement a good",
    "start": "429830",
    "end": "436130"
  },
  {
    "text": "rule of thumb is if it was on tape before nature is a good place for it if not you may want to reevaluate that",
    "start": "436130",
    "end": "442220"
  },
  {
    "text": "integration with other ingest mechanisms ingest mechanisms and our minds are things like AWS snowball and using aid",
    "start": "442220",
    "end": "449570"
  },
  {
    "text": "abuse Direct Connect to guarantee the bandwidth that guaranteed bandwidth is important when you have any kind of SLA",
    "start": "449570",
    "end": "456530"
  },
  {
    "text": "that you're trying to meet when when it comes to talking with the cloud or putting data in or taking it out in many",
    "start": "456530",
    "end": "463820"
  },
  {
    "start": "458000",
    "end": "539000"
  },
  {
    "text": "cases the Internet's just fine but the Internet as we all know what doesn't have QoS in AWS we have a shared",
    "start": "463820",
    "end": "470660"
  },
  {
    "text": "responsibility model when it comes to security and that shared responsibility model means that we're prepared to take",
    "start": "470660",
    "end": "476510"
  },
  {
    "text": "care of everything effectively up to the VPC so we take care of the all the physical components",
    "start": "476510",
    "end": "483200"
  },
  {
    "text": "where we have third party audit certifications around you know who can",
    "start": "483200",
    "end": "489860"
  },
  {
    "text": "who has access and in what capacity we take care of the all of our overlay",
    "start": "489860",
    "end": "495260"
  },
  {
    "text": "networks we take care of all of our all the routing topologies we take care of all of the hardware availability because",
    "start": "495260",
    "end": "502040"
  },
  {
    "text": "after all we are it is still real hardware that part we haven't been able to get away from and then from the vbc",
    "start": "502040",
    "end": "508130"
  },
  {
    "text": "layer and on up and the customers responsible for it and that can be a fairly large scope that's another great",
    "start": "508130",
    "end": "514070"
  },
  {
    "text": "reason for using AWS technology partners is it reduces the scope that the customer really has to worry about by",
    "start": "514070",
    "end": "521380"
  },
  {
    "text": "effectively offloading large portions of the security model the shared security",
    "start": "521380",
    "end": "526670"
  },
  {
    "text": "model to the partner solution so for example in the case of store reduce today you",
    "start": "526670",
    "end": "534149"
  },
  {
    "text": "know they have a great way of interacting with AWS services following",
    "start": "534149",
    "end": "540089"
  },
  {
    "start": "539000",
    "end": "595000"
  },
  {
    "text": "our security best practices and they're able to ensure that the data is not only",
    "start": "540089",
    "end": "546089"
  },
  {
    "text": "protected from a client-side perspective but over the wire and then at rest when",
    "start": "546089",
    "end": "551880"
  },
  {
    "text": "it lands in s3 some of those certifications that I refer to are up on the screen right now again all of these",
    "start": "551880",
    "end": "557640"
  },
  {
    "text": "are certifications that have to do with things like endpoint compliance and the physical components so if any of these",
    "start": "557640",
    "end": "563850"
  },
  {
    "text": "compliance or icons or certifications are relevant to your organization if you've ever asked the question will I be",
    "start": "563850",
    "end": "570000"
  },
  {
    "text": "able to retain them or attain them inside of the cloud the answer is emphatically yes you're eligible for",
    "start": "570000",
    "end": "576870"
  },
  {
    "text": "those things there's there's even more than these is a subsection of the",
    "start": "576870",
    "end": "582320"
  },
  {
    "text": "certifications and assurance programs that we participate in so when I say you're eligible for them what I mean is",
    "start": "582320",
    "end": "588870"
  },
  {
    "text": "we've done our part and in any case where there's compliance or assurance that you're then responsible for and",
    "start": "588870",
    "end": "595589"
  },
  {
    "start": "595000",
    "end": "619000"
  },
  {
    "text": "that shared responsibility model you know you all the parts that we have to do are taking care of for you and you",
    "start": "595589",
    "end": "602160"
  },
  {
    "text": "don't have to worry about that we have third-party verification components that we can help with and then you actually",
    "start": "602160",
    "end": "608760"
  },
  {
    "text": "just have to do your end of it so now I introduce to you a human person CTO of store it is huge take it away Thank You",
    "start": "608760",
    "end": "615420"
  },
  {
    "text": "Isaiah hi everyone I'm Hugh Emerson I'm the chief technology officer of storages",
    "start": "615420",
    "end": "621440"
  },
  {
    "text": "my accent is not from the US but storage is is actually a u.s. corporation and",
    "start": "621440",
    "end": "626730"
  },
  {
    "text": "I'm resident in the US and we have key teams across the US and elsewhere so",
    "start": "626730",
    "end": "631949"
  },
  {
    "text": "storage juice is a scale out Software Defined digit location engine for object",
    "start": "631949",
    "end": "637350"
  },
  {
    "text": "storage like Amazon s3 storage juice can do deduplication of data I can do",
    "start": "637350",
    "end": "645140"
  },
  {
    "text": "deduplicated replication of data between regions and clouds which is great for ibrid cloud and it can do cloning which",
    "start": "645140",
    "end": "652560"
  },
  {
    "text": "is near-instantaneous copying of entire cloud data sets as many times as you",
    "start": "652560",
    "end": "657569"
  },
  {
    "text": "need it works on backup workloads also on data that does not deduplicate",
    "start": "657569",
    "end": "662790"
  },
  {
    "text": "including Big Data and Internet of Things data today we are going to focus",
    "start": "662790",
    "end": "668820"
  },
  {
    "text": "on the deduplication aspect of storage use and the new storage use cases that enables for your backups as shown in the",
    "start": "668820",
    "end": "675870"
  },
  {
    "text": "top two diagrams here the first is moving your primary backups of purpose-built backup appliances like -",
    "start": "675870",
    "end": "683760"
  },
  {
    "text": "domains and veritas appliances and instead storing that data to cloud which",
    "start": "683760",
    "end": "688770"
  },
  {
    "text": "saves you up to 80% on the total cost of ownership basis secondly moving data off",
    "start": "688770",
    "end": "694500"
  },
  {
    "text": "tape and storing to cloud saving up to 60% storage juice enables you to deploy",
    "start": "694500",
    "end": "699630"
  },
  {
    "text": "on commodity Hardware in your existing backup solution on-premises and with the mere configuration change you can point",
    "start": "699630",
    "end": "706800"
  },
  {
    "text": "petabytes where the backups away from backup appliances like data domain and various appliances and tape to the cloud",
    "start": "706800",
    "end": "713760"
  },
  {
    "text": "I will walk through architectures outline performance and do a demo at the end of the webinar I will list a demo",
    "start": "713760",
    "end": "720660"
  },
  {
    "text": "how you can use generic cloud services on the primary backup and archival data that you have moved to the cloud to",
    "start": "720660",
    "end": "727260"
  },
  {
    "text": "access that data in route near real time and derive better search and recovery data mining and more on it the backup",
    "start": "727260",
    "end": "734640"
  },
  {
    "text": "and archives of a company are typically the longest history and sometimes the largest pool of data that that company",
    "start": "734640",
    "end": "741000"
  },
  {
    "text": "has now enterprises with hundreds of terabytes to hundreds of petabytes locked on tape or - domains can move",
    "start": "741000",
    "end": "748140"
  },
  {
    "text": "data to the cloud they can store it in a single pool on cloud and then be able to use best debris cloud services to search",
    "start": "748140",
    "end": "755310"
  },
  {
    "text": "to Train algorithms against historical trades or events and to do AI or",
    "start": "755310",
    "end": "760740"
  },
  {
    "text": "sentiment analysis across that data in real-time or near real-time not only",
    "start": "760740",
    "end": "766260"
  },
  {
    "text": "does storages give you a saving of up to 80% and much better durability and scalability for storing your data it can",
    "start": "766260",
    "end": "773970"
  },
  {
    "text": "now give you insights that provide you an enormous competitive advantage and here's the workflow that little demo",
    "start": "773970",
    "end": "780570"
  },
  {
    "text": "later so data comes in for armed purpose-built or off purpose-built backup appliances",
    "start": "780570",
    "end": "786570"
  },
  {
    "text": "or tapes or directly from your backup application into store reduce and the stored into Amazon s3 we can then",
    "start": "786570",
    "end": "793770"
  },
  {
    "text": "extract mess data from that data and put that data into the search and research services or",
    "start": "793770",
    "end": "801630"
  },
  {
    "text": "machine learning services analytic services for instance and use those to derive intelligence from your data for",
    "start": "801630",
    "end": "809519"
  },
  {
    "text": "instance you can search inside all of the backups that you've ever made for",
    "start": "809519",
    "end": "814589"
  },
  {
    "text": "any word or phrase in those backups which is very useful for people who have got very high compliance requirements",
    "start": "814589",
    "end": "821010"
  },
  {
    "start": "815000",
    "end": "945000"
  },
  {
    "text": "like banks and it's much easier than just looking through a catalog a catalog",
    "start": "821010",
    "end": "826260"
  },
  {
    "text": "of backups which just gives you a list of the file names that you've backed up over time so this is how storages works",
    "start": "826260",
    "end": "833209"
  },
  {
    "text": "the Storage Server is a single piece of software that can deploy on premises it",
    "start": "833209",
    "end": "839970"
  },
  {
    "text": "can deploy as a VMware virtual machine or as a docker container on your bare",
    "start": "839970",
    "end": "846540"
  },
  {
    "text": "metal hardware or it can deploy as an ami in Amazon ec2 the data comes in to",
    "start": "846540",
    "end": "852899"
  },
  {
    "text": "store a juice over the s3 interface we have the same interface as Amazon history and that data is deduplicated a",
    "start": "852899",
    "end": "859800"
  },
  {
    "text": "high speed in real time and the deduplicated data which is much much smaller is then stored into Amazon s3 so",
    "start": "859800",
    "end": "868709"
  },
  {
    "text": "storage is reduces the cost of storing that data into the cloud and also the cost of transferring it into the cloud",
    "start": "868709",
    "end": "875339"
  },
  {
    "text": "that the data that's stored in there includes all of the metadata that we use to deduplicate it and this means that if",
    "start": "875339",
    "end": "882329"
  },
  {
    "text": "the storage server has ever lost for any reason if there's a hardware failure or if the data center burns down then you",
    "start": "882329",
    "end": "889649"
  },
  {
    "text": "can recover the data that's stored simply by pointing a new storage server at the bucket in Amazon s3 and",
    "start": "889649",
    "end": "897240"
  },
  {
    "text": "recovering all of the data out of there and we have optimizations that make that a very fast process now the data comes",
    "start": "897240",
    "end": "904860"
  },
  {
    "text": "in storages from anything that has an s3 API our clients so most major backup",
    "start": "904860",
    "end": "911850"
  },
  {
    "text": "software has an s3 client lots of file system gateways like Q star have history",
    "start": "911850",
    "end": "918630"
  },
  {
    "text": "and anything else that has an s3 client for instance like the Amazon s3 CLI can",
    "start": "918630",
    "end": "923970"
  },
  {
    "text": "be used to move data in storages the only hardware requirement the store is that it requires a small amount of",
    "start": "923970",
    "end": "931019"
  },
  {
    "text": "SSD it works less than 0.2 percent of the volume of data that's written through storages so if you have one",
    "start": "931019",
    "end": "939149"
  },
  {
    "text": "petabyte store through store reduce then it requires less than 2 terabytes of commodity SSD a lot of other systems",
    "start": "939149",
    "end": "946410"
  },
  {
    "start": "945000",
    "end": "1081000"
  },
  {
    "text": "that deduplicate data and move it to the cloud will require at least 20% of the data that's towards the cloud to be also",
    "start": "946410",
    "end": "953669"
  },
  {
    "text": "staged or cached on local highly redundant discs like a SAN and this can",
    "start": "953669",
    "end": "959549"
  },
  {
    "text": "cost you tens of thousands of dollars per site storages may be removed all of these issues a petabyte scale these are",
    "start": "959549",
    "end": "966479"
  },
  {
    "text": "some of the characteristics of storage use firstly it's fast a single instance that's a single server of storages can",
    "start": "966479",
    "end": "974009"
  },
  {
    "text": "do 2.5 gigabytes per second of ingest multiple servers can be going together",
    "start": "974009",
    "end": "979679"
  },
  {
    "text": "into a cluster to produce even higher throughputs in fact we can cluster to",
    "start": "979679",
    "end": "984779"
  },
  {
    "text": "tens or hundreds of instances storage uses digital occation is in line",
    "start": "984779",
    "end": "989879"
  },
  {
    "text": "it happens in memory in real time we don't cache the data and do duplicate",
    "start": "989879",
    "end": "995459"
  },
  {
    "text": "later it's multi-threaded you can handle hundreds or thousands of simultaneous",
    "start": "995459",
    "end": "1001069"
  },
  {
    "text": "streams of data coming storage use our discipline algorithm is a variable",
    "start": "1001069",
    "end": "1007999"
  },
  {
    "text": "length block size algorithm and produces duplication results as good as the best appliances the storage of server as I",
    "start": "1007999",
    "end": "1015199"
  },
  {
    "text": "discussed before is stateless and this means that all the metadata and data is stored safely in the cloud you know you",
    "start": "1015199",
    "end": "1021980"
  },
  {
    "text": "can afford to lose the service if if that happens the storage server is also",
    "start": "1021980",
    "end": "1027350"
  },
  {
    "text": "scalable you can cluster servers together but you don't pay per instance of the the server you only pay for the",
    "start": "1027350",
    "end": "1034579"
  },
  {
    "text": "amount of data that's stored through storages so it's great for multi-site deployments and storages has a single",
    "start": "1034579",
    "end": "1041659"
  },
  {
    "text": "namespace so there are no silos you don't have to move your backups from one silo to another when that's other starts",
    "start": "1041659",
    "end": "1048500"
  },
  {
    "text": "to fill up as I've discussed before it's completely software-defined and storage",
    "start": "1048500",
    "end": "1053870"
  },
  {
    "text": "juicers Enterprise ready it has high availability and region to region or",
    "start": "1053870",
    "end": "1058970"
  },
  {
    "text": "cloud to cloud replication as well and finally going back to the Amazon shared security module model storage",
    "start": "1058970",
    "end": "1066440"
  },
  {
    "text": "uses secure all data that goes in and out of storages goes over TLS or SSL so",
    "start": "1066440",
    "end": "1073340"
  },
  {
    "text": "it's encrypted in flight and data can be encrypted before it's stored through to s3 are using our client-side encryption",
    "start": "1073340",
    "end": "1081130"
  },
  {
    "start": "1081000",
    "end": "1134000"
  },
  {
    "text": "we support getting keys from Amazon kms service or any hardware security module",
    "start": "1081130",
    "end": "1087650"
  },
  {
    "text": "or key management system that supports the came UPS protocol and finally we support the Amazon s3",
    "start": "1087650",
    "end": "1094340"
  },
  {
    "text": "sse extension which enables you to encrypt the data inside s3 just before",
    "start": "1094340",
    "end": "1101330"
  },
  {
    "text": "it lands on the disks this is the architecture of a storages cluster you",
    "start": "1101330",
    "end": "1106610"
  },
  {
    "text": "can gang any odd number of storages servers together to form a cluster and",
    "start": "1106610",
    "end": "1113780"
  },
  {
    "text": "this gives you a single namespace it's highly available it gives you a single-digit pool across the entire",
    "start": "1113780",
    "end": "1120650"
  },
  {
    "text": "cluster you get 24/7 throughput because there's no buffering in the system",
    "start": "1120650",
    "end": "1125780"
  },
  {
    "text": "there's no buffers to fill up and you can run 24/7 365 and it's all built out",
    "start": "1125780",
    "end": "1132110"
  },
  {
    "text": "of commodity hardware there's nothing that's shared in here except for the network and the object store Amazon s3",
    "start": "1132110",
    "end": "1138770"
  },
  {
    "text": "in this case now this all relies on your having good bandwidth to the cloud in order to get good throughputs",
    "start": "1138770",
    "end": "1144170"
  },
  {
    "text": "as something like an Amazon Direct Connect is a really good way to go and",
    "start": "1144170",
    "end": "1149390"
  },
  {
    "text": "get the spam with and storage juice gives you a digital plication speeds of",
    "start": "1149390",
    "end": "1154880"
  },
  {
    "text": "tens or hundreds of gigabits per second through into Amazon s3 matching or",
    "start": "1154880",
    "end": "1161930"
  },
  {
    "text": "exceeding the speeds of leading backup appliances so this is a storages cluster",
    "start": "1161930",
    "end": "1167720"
  },
  {
    "text": "running in Amazon ec2 at the time that the screenshot was taken it had eleven",
    "start": "1167720",
    "end": "1172850"
  },
  {
    "text": "point two petabytes of data stored in the cluster which was deduplicated down to about 570 terabytes as a DJ ratio of",
    "start": "1172850",
    "end": "1181520"
  },
  {
    "text": "95 percent or roughly twenty to one this was a nine server cluster nine Amazon c3",
    "start": "1181520",
    "end": "1189530"
  },
  {
    "text": "8x larges so it was a midsize cluster for us and basically you can scale a cluster",
    "start": "1189530",
    "end": "1196370"
  },
  {
    "text": "like this to increase your throughput just by adding more servers and in fact we will demo another cluster zone that",
    "start": "1196370",
    "end": "1203600"
  },
  {
    "text": "has even more nodes and higher throughputs if you have more service to the cluster then you get a linear",
    "start": "1203600",
    "end": "1210139"
  },
  {
    "text": "increase in throughput and this does not drop off as the amount of data stored increases so for instance a 35 node",
    "start": "1210139",
    "end": "1218659"
  },
  {
    "text": "cluster could ingest about 100 petabytes per month this cluster was ingesting",
    "start": "1218659",
    "end": "1223669"
  },
  {
    "text": "about 750 terabytes a day and storages works with Amazon snowball or snowmobile",
    "start": "1223669",
    "end": "1229220"
  },
  {
    "text": "which are great ways to actually seed your first backups into AWS by taking the network out of the equation so this",
    "start": "1229220",
    "end": "1236059"
  },
  {
    "text": "is the major use case essentially what story juice enables you to do is to decommission your existing backup",
    "start": "1236059",
    "end": "1242990"
  },
  {
    "text": "appliances or tape libraries and instead point the data that's coming out of your",
    "start": "1242990",
    "end": "1248450"
  },
  {
    "text": "backup worker application to store reduce and then enter the Amazon Cloud this can give you a TCO or total cost of",
    "start": "1248450",
    "end": "1255620"
  },
  {
    "text": "ownership saving of up to 80% and there's a TCO calculator available from AWS or on the storages website and the",
    "start": "1255620",
    "end": "1265909"
  },
  {
    "text": "storage use has the additional benefits that there's no single points of failure",
    "start": "1265909",
    "end": "1271220"
  },
  {
    "text": "in the architecture because the storage is clusters are highly available you can lose any one or two servers in the",
    "start": "1271220",
    "end": "1277129"
  },
  {
    "start": "1276000",
    "end": "1314000"
  },
  {
    "text": "cluster and keep on going you have no silos so you don't have that problem of shuffling your data around as",
    "start": "1277129",
    "end": "1283850"
  },
  {
    "text": "your appliances start fill up it's scalable you can add more instances as",
    "start": "1283850",
    "end": "1289220"
  },
  {
    "text": "you need more throughput or more capacity and you can use cloud services on the migrated data which is something",
    "start": "1289220",
    "end": "1296120"
  },
  {
    "text": "I'll be demonstrating later and the most compelling proposition here is removing",
    "start": "1296120",
    "end": "1301220"
  },
  {
    "text": "backup appliances like - domains or veritas appliances or quantum DX eyes as they come up for renewal and then",
    "start": "1301220",
    "end": "1308360"
  },
  {
    "text": "providing a more scalable affordable and durable storage for your data in the cloud now storages works with most major",
    "start": "1308360",
    "end": "1315440"
  },
  {
    "start": "1314000",
    "end": "1357000"
  },
  {
    "text": "backup applications storage uses a very test technology partner and we work with very test net backup seven point seven",
    "start": "1315440",
    "end": "1322250"
  },
  {
    "text": "and above we're in the net backup seven point seven console",
    "start": "1322250",
    "end": "1327679"
  },
  {
    "text": "VAM will soon have necessary interface and convolved as well as necessary and face that we can work with other backup",
    "start": "1327679",
    "end": "1334309"
  },
  {
    "text": "systems have which have a surface or NFS interface can be used via skew star",
    "start": "1334309",
    "end": "1340070"
  },
  {
    "text": "which provides a an interface between sifts interface and is 3 for 4 storages",
    "start": "1340070",
    "end": "1347059"
  },
  {
    "text": "and now we're just going to have a quick audience poll and the question here is what AWS services would you use on your",
    "start": "1347059",
    "end": "1353870"
  },
  {
    "text": "backups that store reducers moved into the AWS cloud ok and thank you everyone",
    "start": "1353870",
    "end": "1360409"
  },
  {
    "start": "1357000",
    "end": "1485000"
  },
  {
    "text": "um I'd like now like to thank our clients Globe Telecom for doing this webinar today and especially thank dan",
    "start": "1360409",
    "end": "1367669"
  },
  {
    "text": "yellow card card owner a great infrastructure architect with globe telecom who helped implement this",
    "start": "1367669",
    "end": "1374169"
  },
  {
    "text": "architecture egg grove Thank You Daniella hey guys i am danny",
    "start": "1374169",
    "end": "1379490"
  },
  {
    "text": "lockhart/gardner and infrastructure i could take up globe telecom i will i",
    "start": "1379490",
    "end": "1384590"
  },
  {
    "text": "will be discussing today how we archive our primary backup data from the resume into AWS cloud let me just give you a",
    "start": "1384590",
    "end": "1391370"
  },
  {
    "text": "brief background about globe telecom globe telecom is the largest telecommunication company in the",
    "start": "1391370",
    "end": "1397130"
  },
  {
    "text": "Philippines with over 65 million subscribers we have different type of",
    "start": "1397130",
    "end": "1402940"
  },
  {
    "text": "application deployed in AWS and also in our own private cloud and some are still",
    "start": "1402940",
    "end": "1409429"
  },
  {
    "text": "deployed in on-premise physical servers we do have a backup solution where we",
    "start": "1409429",
    "end": "1415010"
  },
  {
    "text": "back up our own friend service data to EMC data domain a problem arise when we",
    "start": "1415010",
    "end": "1420710"
  },
  {
    "text": "are already running out of capacity due to growth in a retention of backup of",
    "start": "1420710",
    "end": "1426020"
  },
  {
    "text": "data so we are now looking for another solution where we can help that can help",
    "start": "1426020",
    "end": "1431600"
  },
  {
    "text": "us in addressing our problem the goal of our solution is to repurpose our current",
    "start": "1431600",
    "end": "1438590"
  },
  {
    "text": "on-premise appliances also we need to be able to archive all backups from the a",
    "start": "1438590",
    "end": "1444919"
  },
  {
    "text": "domain to a SS rather than before chasing additional storage in our backup",
    "start": "1444919",
    "end": "1450650"
  },
  {
    "text": "appliances as they are expensive and we also want to leverage the costs a bishop",
    "start": "1450650",
    "end": "1458419"
  },
  {
    "text": "we were going to get it will go into use cloud storage and aside from this we",
    "start": "1458419",
    "end": "1464750"
  },
  {
    "text": "also want to all of this happen through automation there are some challenges that we encountered in making the",
    "start": "1464750",
    "end": "1471230"
  },
  {
    "text": "solution like some of our systems mostly billing systems has data that has up to",
    "start": "1471230",
    "end": "1478279"
  },
  {
    "text": "10 years data retention and we found out that archiving this long retention data",
    "start": "1478279",
    "end": "1483710"
  },
  {
    "text": "is too expensive without the duplication in terms of our network and security requirements our",
    "start": "1483710",
    "end": "1490730"
  },
  {
    "start": "1485000",
    "end": "1570000"
  },
  {
    "text": "solution must utilize our own a table as the reconnect line to AWS and equation",
    "start": "1490730",
    "end": "1498260"
  },
  {
    "text": "over this wire should should be encrypted as well encryption at rest we",
    "start": "1498260",
    "end": "1505460"
  },
  {
    "text": "also want a solution that scales with data growth and we didn't want to change our existing workflow we have we have a",
    "start": "1505460",
    "end": "1513440"
  },
  {
    "text": "sub arm scripted backup solution and we want distribution can integrate or this",
    "start": "1513440",
    "end": "1521510"
  },
  {
    "text": "can integrate with our current solution will be able us to store our data to",
    "start": "1521510",
    "end": "1527149"
  },
  {
    "text": "cloud after study ends searching up different solution software we found a",
    "start": "1527149",
    "end": "1534679"
  },
  {
    "text": "very interesting software that promise of having an inline deduplication to a",
    "start": "1534679",
    "end": "1539779"
  },
  {
    "text": "double sawbuck storage and that is star reduce we found it in one of the posts",
    "start": "1539779",
    "end": "1546620"
  },
  {
    "text": "in AWS AP and blog and the best thing about it is that it's available in AWS",
    "start": "1546620",
    "end": "1553880"
  },
  {
    "text": "to marketplace so we can do self service procurement and try the software as soon as we want as I have been able to back",
    "start": "1553880",
    "end": "1561890"
  },
  {
    "text": "up our data to AWS it also work with our own existing hardware so there's no new",
    "start": "1561890",
    "end": "1569299"
  },
  {
    "text": "investment new investment requirement also it is scalable and achieves an",
    "start": "1569299",
    "end": "1575149"
  },
  {
    "start": "1570000",
    "end": "1678000"
  },
  {
    "text": "excellent on the duplication ratio the decreases backup window times bandwidth",
    "start": "1575149",
    "end": "1581179"
  },
  {
    "text": "and storage costs and we also able to integrate story this into our existing",
    "start": "1581179",
    "end": "1587419"
  },
  {
    "text": "backup square using the AWS CLI to enable backup retention",
    "start": "1587419",
    "end": "1594080"
  },
  {
    "text": "the men and also in AWS s3 so these are previous design we do have systems that",
    "start": "1594080",
    "end": "1603010"
  },
  {
    "text": "backing up their data in our data domain and we do have our own we created our",
    "start": "1603010",
    "end": "1610039"
  },
  {
    "text": "own backups clip to do to automate this we validate the solution by performing",
    "start": "1610039",
    "end": "1617600"
  },
  {
    "text": "up up concept and this our solution that we have as you can see we started this",
    "start": "1617600",
    "end": "1625549"
  },
  {
    "text": "in one of our BN and have started this helped us in creating the script or",
    "start": "1625549",
    "end": "1631120"
  },
  {
    "text": "automating the process of archiving to s3 and data retention we also use our",
    "start": "1631120",
    "end": "1637220"
  },
  {
    "text": "existing proxy form to be able to leverage our own direct connect line to",
    "start": "1637220",
    "end": "1642440"
  },
  {
    "text": "AWS s3 and we use s3 frequent access for",
    "start": "1642440",
    "end": "1649549"
  },
  {
    "text": "storage we are using we are deployed our servers in Singapore region up AWS and",
    "start": "1649549",
    "end": "1657919"
  },
  {
    "text": "currently our nature started available but sooner if they sure will be available on that will be another",
    "start": "1657919",
    "end": "1665360"
  },
  {
    "text": "savings the POC was quick and upper class we were able to upload and",
    "start": "1665360",
    "end": "1672320"
  },
  {
    "text": "download three months worth of backups of one of our system with just a week after that we were able to move straight",
    "start": "1672320",
    "end": "1679460"
  },
  {
    "start": "1678000",
    "end": "1708000"
  },
  {
    "text": "to the production from POC without having to upload all of this data and we",
    "start": "1679460",
    "end": "1684860"
  },
  {
    "text": "have successfully launched it to production last June 30 2016 these are the results as you can see on",
    "start": "1684860",
    "end": "1692330"
  },
  {
    "text": "the screen of our vo C so we do we were able to upload to I repeat the gig back",
    "start": "1692330",
    "end": "1698960"
  },
  {
    "text": "up pal in less than five hours and 20 minutes we had an initial duplication of",
    "start": "1698960",
    "end": "1705769"
  },
  {
    "text": "70% and we just only utilized the bandwidth up right there vicuna per only",
    "start": "1705769",
    "end": "1711289"
  },
  {
    "text": "10 megabits per second and we also tried to rehydrate the data back to our data",
    "start": "1711289",
    "end": "1718309"
  },
  {
    "text": "domain and with that I repeat the gig a backup we were able to recover it for",
    "start": "1718309",
    "end": "1724669"
  },
  {
    "text": "only 6 hours and 40 minutes so overall the successful backup and",
    "start": "1724669",
    "end": "1729680"
  },
  {
    "text": "recovery of our POC is 100% so this darker in the duplication statistic that",
    "start": "1729680",
    "end": "1735710"
  },
  {
    "text": "we have right now in our production is there and as of August 2017 so we have",
    "start": "1735710",
    "end": "1744080"
  },
  {
    "text": "already uploaded 94 terabytes and with 88.8% in application we just only able",
    "start": "1744080",
    "end": "1750800"
  },
  {
    "text": "to start our we have able to have the duplicated into 10.50 part DB bytes so",
    "start": "1750800",
    "end": "1757970"
  },
  {
    "text": "that's it we are able to archive most of our data with story dose in a doubles s3",
    "start": "1757970",
    "end": "1763910"
  },
  {
    "start": "1758000",
    "end": "1810000"
  },
  {
    "text": "which we trust as a very secure joint solution that shared responsibility the",
    "start": "1763910",
    "end": "1770300"
  },
  {
    "text": "security model was ideal for our requirements the infrastructure combination of AWS cloud storage and",
    "start": "1770300",
    "end": "1777050"
  },
  {
    "text": "services with a B and partner text or reduce delivered the total solution that",
    "start": "1777050",
    "end": "1783800"
  },
  {
    "text": "we required so that is for our session I hope that you learned something from this and I'll be no turning over you",
    "start": "1783800",
    "end": "1790700"
  },
  {
    "text": "thievish member son for the live demo hello everyone that's here in here again",
    "start": "1790700",
    "end": "1796390"
  },
  {
    "text": "yeah thank you Dan July for presenting and discussing the or your experiences",
    "start": "1796390",
    "end": "1803090"
  },
  {
    "text": "with storages and AWS cloud so this is the the storage use dashboard with this",
    "start": "1803090",
    "end": "1810110"
  },
  {
    "start": "1810000",
    "end": "1897000"
  },
  {
    "text": "is a cluster running in Amazon ec2 on about 15 servers and as you can and what",
    "start": "1810110",
    "end": "1818750"
  },
  {
    "text": "Sergey shows you here is firstly how much data is stored within the system so we have currently just over 4 petabytes",
    "start": "1818750",
    "end": "1826820"
  },
  {
    "text": "of data stored before deduplication and",
    "start": "1826820",
    "end": "1831970"
  },
  {
    "text": "roughly 130 terabytes after you can also see the network activity this is data",
    "start": "1831970",
    "end": "1839030"
  },
  {
    "text": "coming into storages server we're averaging somewhere around 12 to 13",
    "start": "1839030",
    "end": "1844120"
  },
  {
    "text": "gigabytes a second of data coming in which is roughly a petabyte a day just",
    "start": "1844120",
    "end": "1850790"
  },
  {
    "text": "clicking to the next tab this is the storage use Explorer basically it's like",
    "start": "1850790",
    "end": "1858980"
  },
  {
    "text": "the Amazon is three consult if you're familiar with that and here are the buckets that are",
    "start": "1858980",
    "end": "1864470"
  },
  {
    "text": "stored within storage juice from here we can basically click into a bucket and",
    "start": "1864470",
    "end": "1870680"
  },
  {
    "text": "see the data that's stored in there this bucket contains the test data generated by one of our test scripts we",
    "start": "1870680",
    "end": "1879140"
  },
  {
    "text": "can do other things like you know create a new bucket I've already used fred james and you know pop data and have a",
    "start": "1879140",
    "end": "1889700"
  },
  {
    "text": "look in there we can upload files into the bucket again just like the amazon",
    "start": "1889700",
    "end": "1894860"
  },
  {
    "text": "history console and there you can see the date has been uploaded into storages and we can also download the data from",
    "start": "1894860",
    "end": "1902780"
  },
  {
    "start": "1897000",
    "end": "1951000"
  },
  {
    "text": "storage juice and check there so it's worked of course most of the data that comes in storage juice doesn't come in",
    "start": "1902780",
    "end": "1909200"
  },
  {
    "text": "through the dashboard it comes in through the s3 API and from other",
    "start": "1909200",
    "end": "1914540"
  },
  {
    "text": "machines now store juice is very easy to setup even though if you're setting up a",
    "start": "1914540",
    "end": "1921650"
  },
  {
    "text": "cluster essentially all you have to do is fill out this form which just contains things like the Amazon region",
    "start": "1921650",
    "end": "1929780"
  },
  {
    "text": "that you're connecting to and the buckets in this tree that you're going to use a few other things about",
    "start": "1929780",
    "end": "1936050"
  },
  {
    "text": "encryption security and so forth and then all you have to do is push the Save",
    "start": "1936050",
    "end": "1941060"
  },
  {
    "text": "Settings button now if you're even if you love sticking up a cluster all you have to do is configure one server you",
    "start": "1941060",
    "end": "1948080"
  },
  {
    "text": "then join all the other servers in the cluster to this one server and storages",
    "start": "1948080",
    "end": "1953630"
  },
  {
    "text": "is a masterless system that means that every server in the cluster has both a",
    "start": "1953630",
    "end": "1958970"
  },
  {
    "text": "master and the slave there's no master that you have to worry about protecting if they're all equivalent and you can",
    "start": "1958970",
    "end": "1967700"
  },
  {
    "text": "see this dashboard from any one of those the servers in the cluster this is the",
    "start": "1967700",
    "end": "1973460"
  },
  {
    "text": "cluster management screen it shows you the service in the cluster you can see there are peer dressers version of",
    "start": "1973460",
    "end": "1980960"
  },
  {
    "text": "storages that they're running when they were last restarted and so forth and you can see that the portions of the",
    "start": "1980960",
    "end": "1987530"
  },
  {
    "text": "namespace that each of the servers is responsible for what we can see here is",
    "start": "1987530",
    "end": "1992630"
  },
  {
    "text": "that this server is set up as a single replicas or this cluster is set up as a single replica cluster each server has",
    "start": "1992630",
    "end": "1998960"
  },
  {
    "text": "is a replica of one of the other servers in the cluster and this means that the cluster can withstand the loss of any",
    "start": "1998960",
    "end": "2005080"
  },
  {
    "start": "2005000",
    "end": "2055000"
  },
  {
    "text": "one server in the cluster and it will keep on going we can also configure",
    "start": "2005080",
    "end": "2010360"
  },
  {
    "text": "storage new servers so that they can withstand all clusters so they can withstand the loss of two or more",
    "start": "2010360",
    "end": "2015370"
  },
  {
    "text": "servers within the cluster and can need to need to function a storage juice has a identity and access management system",
    "start": "2015370",
    "end": "2023050"
  },
  {
    "text": "a little bit like Amazon and this allows you to assign IDs create users within",
    "start": "2023050",
    "end": "2030670"
  },
  {
    "text": "the system and also then assign permissions to two buckets to say which",
    "start": "2030670",
    "end": "2036580"
  },
  {
    "text": "users can access those buckets or I should say policies and we use the Amazon policy language so if you're",
    "start": "2036580",
    "end": "2043480"
  },
  {
    "text": "familiar with that and using I am then you're familiar with using storages and its exists control as well now that's",
    "start": "2043480",
    "end": "2049929"
  },
  {
    "text": "all I've got for this one final thing actually if story juice ever has any",
    "start": "2049929",
    "end": "2055090"
  },
  {
    "text": "problems if it starts running out of disk space for instance on the server or something like that it will display notifications up here",
    "start": "2055090",
    "end": "2061690"
  },
  {
    "text": "you can also configure it so that can send you an email if it starts running into problems now that's all I've got to",
    "start": "2061690",
    "end": "2069429"
  },
  {
    "text": "show for this cluster but I've got another system to show you here and this is a product that will be going general",
    "start": "2069429",
    "end": "2077260"
  },
  {
    "text": "availability sometime next month it's called store reduce insights and",
    "start": "2077260",
    "end": "2082888"
  },
  {
    "text": "storage use insights is the system that allows us to derive business value and",
    "start": "2082889",
    "end": "2089408"
  },
  {
    "text": "insights from data that's been uploaded via storages into the Amazon Cloud now",
    "start": "2089409",
    "end": "2096128"
  },
  {
    "text": "what I have here is a Windows Server in here I've got a data set with a bunch of",
    "start": "2096129",
    "end": "2102160"
  },
  {
    "text": "documents in it these documents were scraped off the internet there's about a thousand",
    "start": "2102160",
    "end": "2108700"
  },
  {
    "start": "2105000",
    "end": "2149000"
  },
  {
    "text": "documents in the day say it and I've used nip backup yeah this is very testing it back up eight to backup that",
    "start": "2108700",
    "end": "2116230"
  },
  {
    "text": "data set a couple of times into storages here is the storages server that we we backed them up into and here you can see",
    "start": "2116230",
    "end": "2123520"
  },
  {
    "text": "if you're familiar with their backup you can see familiar-looking net backup policy names",
    "start": "2123520",
    "end": "2130450"
  },
  {
    "text": "and and files dr. system structures now the data that's gone into the system is",
    "start": "2130450",
    "end": "2137500"
  },
  {
    "text": "being inspected by a store reducing site server and the insight server is pulling",
    "start": "2137500",
    "end": "2142870"
  },
  {
    "text": "out that data and the metadata associated with it the metadata gets",
    "start": "2142870",
    "end": "2149890"
  },
  {
    "start": "2149000",
    "end": "2266000"
  },
  {
    "text": "injected into a elasticsearch cluster and the elasticsearch cluster then",
    "start": "2149890",
    "end": "2155890"
  },
  {
    "text": "allows us to do queries over that data so for instance here is we're using",
    "start": "2155890",
    "end": "2162130"
  },
  {
    "text": "Cabana to just inspect the results the elasticsearch cluster and we can see",
    "start": "2162130",
    "end": "2167650"
  },
  {
    "text": "that we've got we're looking at the archive files table within Cabana with an elastic search and we can see that",
    "start": "2167650",
    "end": "2174310"
  },
  {
    "text": "we've got about two thousand and eight files in the table these are files that have been backed up from from the from",
    "start": "2174310",
    "end": "2183070"
  },
  {
    "text": "the Windows Server that we saw before and we can see the metadata that we've",
    "start": "2183070",
    "end": "2188500"
  },
  {
    "text": "been able to extract from the data that was backed up we've got you know the the",
    "start": "2188500",
    "end": "2194950"
  },
  {
    "text": "backup run the backup ID the file name that was backed up and and so forth and",
    "start": "2194950",
    "end": "2201310"
  },
  {
    "text": "there's a lot more information here we've got access times the change times the the group and the user who created",
    "start": "2201310",
    "end": "2209410"
  },
  {
    "text": "this file and a much much more information and that but the neat thing",
    "start": "2209410",
    "end": "2214420"
  },
  {
    "text": "we can do with this is that we can search it for instance we can run a search for contract now this will go and",
    "start": "2214420",
    "end": "2220090"
  },
  {
    "text": "find all the files in the system that either have the word contract in their",
    "start": "2220090",
    "end": "2225370"
  },
  {
    "text": "file name like these ones here or we can find files that have the word contract",
    "start": "2225370",
    "end": "2233110"
  },
  {
    "text": "inside the file we've got a link to the file so we can actually go and download",
    "start": "2233110",
    "end": "2239230"
  },
  {
    "text": "that file or we can do other things like we can export that link to another system which can then analyze the",
    "start": "2239230",
    "end": "2245530"
  },
  {
    "text": "contents of that file we can also use kibana or any other system that understands",
    "start": "2245530",
    "end": "2251080"
  },
  {
    "text": "elasticsearch to do analysis on the on the system so we can look at for",
    "start": "2251080",
    "end": "2258610"
  },
  {
    "text": "instance what dates the farm modificator were made on or what years we can see",
    "start": "2258610",
    "end": "2264670"
  },
  {
    "text": "for instance who are the most frequent users or most frequent file modifiers",
    "start": "2264670",
    "end": "2270790"
  },
  {
    "start": "2266000",
    "end": "2384000"
  },
  {
    "text": "within the system but any piece of metadata that you can pull out of the system it can be fed into this and can",
    "start": "2270790",
    "end": "2277960"
  },
  {
    "text": "be used to derive insights about your data and because everything is exposed",
    "start": "2277960",
    "end": "2283420"
  },
  {
    "text": "via an API in this case we have the elastic search API and just HTTP for",
    "start": "2283420",
    "end": "2289780"
  },
  {
    "text": "getting the files you can feed that data into any other application they can",
    "start": "2289780",
    "end": "2295870"
  },
  {
    "text": "understand those and derive insights from it for instance you can use data mail mining applications analysis",
    "start": "2295870",
    "end": "2302560"
  },
  {
    "text": "applications machine learning applications and this is only because",
    "start": "2302560",
    "end": "2308590"
  },
  {
    "text": "storages stores your data in the single namespace on cloud with open api's and",
    "start": "2308590",
    "end": "2314470"
  },
  {
    "text": "it has scale out with very high throughput that enable you to pull back your data in near real time and that's",
    "start": "2314470",
    "end": "2321910"
  },
  {
    "text": "the demo we're finished here I think it's time for to hand over to Isaiah for",
    "start": "2321910",
    "end": "2327790"
  },
  {
    "text": "for cue questions and answers awesome I'm this is so cool actually I you know",
    "start": "2327790",
    "end": "2334090"
  },
  {
    "text": "I I worked closely with you guys for last couple of years and we've always talked about you know what insights you",
    "start": "2334090",
    "end": "2341170"
  },
  {
    "text": "could derive from that kind of information and so seeing it live this is the first time I'm actually seeing",
    "start": "2341170",
    "end": "2347350"
  },
  {
    "text": "this this is so cool this is really neat I mean I'm thinking about our customers who need you know face basically like",
    "start": "2347350",
    "end": "2354940"
  },
  {
    "text": "all the features that you would get and like an enterprise ball type scenario but without having the you know high",
    "start": "2354940",
    "end": "2360010"
  },
  {
    "text": "costs and without having you know sort of a vendor lock-in right I mean you",
    "start": "2360010",
    "end": "2365770"
  },
  {
    "text": "know ELQ and the whole elasticsearch in Cabana component is just it's pretty",
    "start": "2365770",
    "end": "2371260"
  },
  {
    "text": "well accepted amongst you know the internet world as you know it's open",
    "start": "2371260",
    "end": "2377590"
  },
  {
    "text": "source and you know you'll you'll be able to benefit from some things as that  this forward there's a couple of",
    "start": "2377590",
    "end": "2383560"
  },
  {
    "text": "questions that people have had that I think are really pertinent around how to get the best value out of story juice on",
    "start": "2383560",
    "end": "2389770"
  },
  {
    "text": "Tim asked in what order and combination should you employ",
    "start": "2389770",
    "end": "2395250"
  },
  {
    "text": "deduplication compression and encryption so it's a good question and you know a",
    "start": "2395250",
    "end": "2400690"
  },
  {
    "text": "lot of times people maybe they thought their own attempts to optimize things can you provide any best practices for",
    "start": "2400690",
    "end": "2406750"
  },
  {
    "text": "what they should do or not do to data before putting it into storage yes so encryption and in compression",
    "start": "2406750",
    "end": "2415930"
  },
  {
    "text": "tends to kill deduplication so what we do is we we take the data in",
    "start": "2415930",
    "end": "2422170"
  },
  {
    "text": "uncompressed and unencrypted preferably and then we actually do the after",
    "start": "2422170",
    "end": "2428530"
  },
  {
    "text": "deduplication storage juice actually does compression and encryption so",
    "start": "2428530",
    "end": "2434020"
  },
  {
    "text": "that's the optimal order to do it in and it gives you the the best results",
    "start": "2434020",
    "end": "2441030"
  },
  {
    "text": "got it okay Doug had a great question about incorporating glaciar his question",
    "start": "2441420",
    "end": "2448600"
  },
  {
    "text": "specifically was just store reduce support direct writes to Glacier but I'd like to just take a step back and",
    "start": "2448600",
    "end": "2454540"
  },
  {
    "text": "understand if I'm a story juice customer how can I take advantage of Glacier yes I stir juice does not support direct",
    "start": "2454540",
    "end": "2461800"
  },
  {
    "text": "writes to Glacier but we can move data in and out of Glacier by lifecycle",
    "start": "2461800",
    "end": "2468100"
  },
  {
    "text": "policies I was just gonna say that you know the list of people who support direct like direct rides to Glacier is",
    "start": "2468100",
    "end": "2474670"
  },
  {
    "text": "actually incredibly small something like 70 odd storage partners I think there might be one one partner that supports",
    "start": "2474670",
    "end": "2480850"
  },
  {
    "text": "for writes to Glacier I know the API is different and there's at least one feature such as some glacier wall lock",
    "start": "2480850",
    "end": "2488440"
  },
  {
    "text": "that you can take advantage of by by using direct writes to Glacier but in your experience with the D dupe ratios",
    "start": "2488440",
    "end": "2495820"
  },
  {
    "text": "that you get from customers is it really necessary you know does it from a cost",
    "start": "2495820",
    "end": "2501310"
  },
  {
    "text": "perspective is it prohibitive to do lifecycle policy migrations I what's been your experience with customers what",
    "start": "2501310",
    "end": "2507580"
  },
  {
    "text": "have they told you most of our customers after looking at glacier have decided",
    "start": "2507580",
    "end": "2513790"
  },
  {
    "start": "2509000",
    "end": "2637000"
  },
  {
    "text": "against it just for the simple reason that it has another layer of complexity",
    "start": "2513790",
    "end": "2519250"
  },
  {
    "text": "to the situation that said that at very very large scale when you're talking hundreds of petabytes of tape",
    "start": "2519250",
    "end": "2526390"
  },
  {
    "text": "they've been migrated Glacia does actually start to look very like a very attractive solution of course that the",
    "start": "2526390",
    "end": "2533380"
  },
  {
    "text": "downside of using place here is that it takes a long time to pull data out of",
    "start": "2533380",
    "end": "2538930"
  },
  {
    "text": "glacier and you know that's by design but it means that you can't use cloud",
    "start": "2538930",
    "end": "2546549"
  },
  {
    "text": "services against that data so you can't do stuff like storages insights against",
    "start": "2546549",
    "end": "2552039"
  },
  {
    "text": "the data that's stored you could perhaps look at some of the metadata but not the data that's there therefore we were",
    "start": "2552039",
    "end": "2559089"
  },
  {
    "text": "interrupted April target the is 3ia layer and they get you know very good",
    "start": "2559089",
    "end": "2567190"
  },
  {
    "text": "cost savings because if 3ia is inexpensive and also because they",
    "start": "2567190",
    "end": "2572500"
  },
  {
    "text": "have digication and I know that like when you you know that even though the",
    "start": "2572500",
    "end": "2577960"
  },
  {
    "text": "glacier cost model and the even the s3 a model are a little bit complicated when you put it into you know Excel or",
    "start": "2577960",
    "end": "2584829"
  },
  {
    "text": "something and you start putting in the numbers as 3ia is pretty well down the middle of s3 in glacier I mean when you",
    "start": "2584829",
    "end": "2591220"
  },
  {
    "text": "combine that with the great DD ratio the value is definitely there Tim had a",
    "start": "2591220",
    "end": "2596230"
  },
  {
    "text": "follow-up question tim was the person who asked about deduplication",
    "start": "2596230",
    "end": "2601480"
  },
  {
    "text": "compression encryption around using store reduce with with on-prem object",
    "start": "2601480",
    "end": "2608380"
  },
  {
    "text": "stores I think it's a great time to remind our audience that you can use stories with on-prem object stores um so",
    "start": "2608380",
    "end": "2615640"
  },
  {
    "text": "his question specifically was if you run it with cloudy and cluster and then tear the data from cloudy into s3 or glacier",
    "start": "2615640",
    "end": "2622509"
  },
  {
    "text": "you know will this work and I think when he asked the question will this work he's referring to you know can I will I",
    "start": "2622509",
    "end": "2629319"
  },
  {
    "text": "be able to do restores or you know well I still get my deduplication results can",
    "start": "2629319",
    "end": "2634509"
  },
  {
    "text": "you comment on that yeah absolutely so we've got a really great hybrid story we",
    "start": "2634509",
    "end": "2641049"
  },
  {
    "start": "2637000",
    "end": "2929000"
  },
  {
    "text": "can work with most of the major on-prem object stores cloudian being one of them",
    "start": "2641049",
    "end": "2646660"
  },
  {
    "text": "and data can be for instance tiered first into an on-prem object store and",
    "start": "2646660",
    "end": "2651730"
  },
  {
    "text": "then I'm a synchronously replicated up into Amazon s3 for for longer-term",
    "start": "2651730",
    "end": "2657400"
  },
  {
    "text": "archives so that gives you you that the benefit of having an on-prem object store for very fast recovery",
    "start": "2657400",
    "end": "2663839"
  },
  {
    "text": "especially if you don't have a great network connection and then the long-term cost advantage of having",
    "start": "2663839",
    "end": "2670200"
  },
  {
    "text": "Amazon s3 for your your long-term storage or is 3ia and yet in addition to",
    "start": "2670200",
    "end": "2678579"
  },
  {
    "text": "supporting deduplicated replication so the data is deduplicated before it it",
    "start": "2678579",
    "end": "2685539"
  },
  {
    "text": "leaves your premises and as always remains deduplicated you also and so",
    "start": "2685539",
    "end": "2691839"
  },
  {
    "text": "which gives you a bandwidth saving as you're moving the data into history and of course the cost saving as you're",
    "start": "2691839",
    "end": "2698319"
  },
  {
    "text": "storing it in history in addition to that you can also run a storages cluster",
    "start": "2698319",
    "end": "2703630"
  },
  {
    "text": "in this tree and you can point it to the same bucket so you can actually pull out your data in Amazon and you can you can",
    "start": "2703630",
    "end": "2712569"
  },
  {
    "text": "use your data up in Amazon as well as being able to recover it very quickly on-premises ok Bob Roger had asked a",
    "start": "2712569",
    "end": "2721749"
  },
  {
    "text": "question about licensing or you know with capacity based licensing is it reflective of the front end data that's",
    "start": "2721749",
    "end": "2728200"
  },
  {
    "text": "being protected or is it reflective of the back end data it's the DB value so",
    "start": "2728200",
    "end": "2733630"
  },
  {
    "text": "it's reflected of the front end the the before at the tube limit but we've",
    "start": "2733630",
    "end": "2739180"
  },
  {
    "text": "designed our licensing models so that you will always save money and you'll",
    "start": "2739180",
    "end": "2744369"
  },
  {
    "text": "usually save around 80% over other on-premise deduplicating appliances and",
    "start": "2744369",
    "end": "2752259"
  },
  {
    "text": "around you know 40 to 60 percent over tape excellent ok a question for Dan del",
    "start": "2752259",
    "end": "2757839"
  },
  {
    "text": "ho the question Dan de ello is you know when you were implementing this you do",
    "start": "2757839",
    "end": "2763839"
  },
  {
    "text": "you have any any bumps or hiccups along the way that you could share with customers that you know maybe you",
    "start": "2763839",
    "end": "2772059"
  },
  {
    "text": "already figured out the answer to a lot of times when people go down the path of",
    "start": "2772059",
    "end": "2778469"
  },
  {
    "text": "implementing something new there aren't any real blockers but sometimes there's",
    "start": "2778469",
    "end": "2783549"
  },
  {
    "text": "speed bumps if you know what I mean things that would slow you down if you could have a conversation with yourself",
    "start": "2783549",
    "end": "2788789"
  },
  {
    "text": "in the past is there any advice that you would give yourself one of the problem that we counter this",
    "start": "2788789",
    "end": "2795580"
  },
  {
    "text": "is to integrate this clip to leverage our ADA was Direct Connect but storages",
    "start": "2795580",
    "end": "2801190"
  },
  {
    "text": "were able to help us by setting the proxy in our script so so far we didn't",
    "start": "2801190",
    "end": "2809410"
  },
  {
    "text": "leave the aside from that we didn't encounter any problems with implementation so just integrating rips",
    "start": "2809410",
    "end": "2817600"
  },
  {
    "text": "got it and when you say I'm integrating the scripts with Direct Connect you mean just you know the changing the targets",
    "start": "2817600",
    "end": "2823600"
  },
  {
    "text": "from from something like s3 to the to the store reduce endpoints what were",
    "start": "2823600",
    "end": "2830320"
  },
  {
    "text": "some of the things that you have to end up changing in your workflow how we just",
    "start": "2830320",
    "end": "2835450"
  },
  {
    "text": "configure the proxy settings of the study those to point to them to the endpoint of our proxy partner so that it",
    "start": "2835450",
    "end": "2843280"
  },
  {
    "text": "will go into Utah I see right because you wanted to be able to you want that reverse proxy form so that",
    "start": "2843280",
    "end": "2849700"
  },
  {
    "text": "you could scale up your ingest component I gotcha okay I'm awesome Thank You Vendela question for hue hue we have a",
    "start": "2849700",
    "end": "2858070"
  },
  {
    "text": "poll and it was one of our our attendees asked about JD PR and for those people",
    "start": "2858070",
    "end": "2864460"
  },
  {
    "text": "who don't know what gdpr is it stands for general data protection regulation it's an EU regulation where addressing",
    "start": "2864460",
    "end": "2873609"
  },
  {
    "text": "the export of personal data and specifically it's about giving control back to people so that they can purge",
    "start": "2873609",
    "end": "2880000"
  },
  {
    "text": "data after the fact you know seeing this the insights the the kibana interface",
    "start": "2880000",
    "end": "2886780"
  },
  {
    "text": "and being a most search for things um I think that there might be something here for you to talk about all specifically",
    "start": "2886780",
    "end": "2893109"
  },
  {
    "text": "was wondering you know if you're a if you're hosting personalized data and if",
    "start": "2893109",
    "end": "2899380"
  },
  {
    "text": "a customer or user wants to remove specific data what would your approach be for finding",
    "start": "2899380",
    "end": "2905590"
  },
  {
    "text": "that data related to the client so that it can be purged and and I you know it",
    "start": "2905590",
    "end": "2911260"
  },
  {
    "text": "seems like that you might need to know what your schema is so that you have metadata that it's canonical for each",
    "start": "2911260",
    "end": "2916390"
  },
  {
    "text": "user can you talk about how the metadata gets discovered is there ways to add custom",
    "start": "2916390",
    "end": "2921880"
  },
  {
    "text": "metadata it's a little bit outside the scope of what we've talked about but I think it it's close enough that it's worth addressing",
    "start": "2921880",
    "end": "2928260"
  },
  {
    "text": "that's a very interesting question Isaiah yes uh I think though there",
    "start": "2928260",
    "end": "2933850"
  },
  {
    "start": "2929000",
    "end": "3060000"
  },
  {
    "text": "there's a way to do this with insights so insights when it's looking at your data with the data that's passed through",
    "start": "2933850",
    "end": "2940900"
  },
  {
    "text": "it it's indexed I can inject that data into an elastic search cluster and",
    "start": "2940900",
    "end": "2946860"
  },
  {
    "text": "elastic search has the ability to run filters across data that's injected into",
    "start": "2946860",
    "end": "2953590"
  },
  {
    "text": "it and so you can design it so that it can understand custom schemas therefore",
    "start": "2953590",
    "end": "2960250"
  },
  {
    "text": "you could for instance have a filter that understands your custom database schema or whatever your your file for",
    "start": "2960250",
    "end": "2967540"
  },
  {
    "text": "matters that then pulls out you know for instance things like sensitive names or",
    "start": "2967540",
    "end": "2974050"
  },
  {
    "text": "something like that and gives you the ability to actually find all of the data that mentions a person or organization",
    "start": "2974050",
    "end": "2982030"
  },
  {
    "text": "and then you can go through your your backups basically and purge the data out",
    "start": "2982030",
    "end": "2987130"
  },
  {
    "text": "of your backups delete the data else to reduce and and I think you've you've",
    "start": "2987130",
    "end": "2992380"
  },
  {
    "text": "accomplished the task interesting that's fantastic because there really aren't very many solutions just because it's in",
    "start": "2992380",
    "end": "2998590"
  },
  {
    "text": "a fairly new regulation well actually it's not specifically new but the deadline for being compliant is is",
    "start": "2998590",
    "end": "3004500"
  },
  {
    "text": "coming up or has recently passed you know this is the kind of thing that cloud backups often don't necessarily",
    "start": "3004500",
    "end": "3010380"
  },
  {
    "text": "address which is how do you how do you actually get rid of the data when you want to lifecycle policies are great if",
    "start": "3010380",
    "end": "3016350"
  },
  {
    "text": "the data is sort of in its native format and s3 but when you're changing that",
    "start": "3016350",
    "end": "3022410"
  },
  {
    "text": "format because you want to take advantage of deduplication then you're reliant on the technology partners to",
    "start": "3022410",
    "end": "3027960"
  },
  {
    "text": "actually actually leverage that for you all right well that's all the time we",
    "start": "3027960",
    "end": "3034320"
  },
  {
    "text": "have I really want to thank our attendees and our speaker stand dello thank you so much I know you're you're",
    "start": "3034320",
    "end": "3040530"
  },
  {
    "text": "in the Philippines so it's it's quite late there right now it's coming up on midnight and I'm actually into the right",
    "start": "3040530",
    "end": "3045930"
  },
  {
    "text": "houses today I'm a Hugh and thank you very much for all of the insight and for",
    "start": "3045930",
    "end": "3051900"
  },
  {
    "text": "showing us what's coming the insights that's really really cool and thank you for attending ok thank you as I have",
    "start": "3051900",
    "end": "3059580"
  },
  {
    "text": "thank you guys",
    "start": "3059580",
    "end": "3062300"
  }
]
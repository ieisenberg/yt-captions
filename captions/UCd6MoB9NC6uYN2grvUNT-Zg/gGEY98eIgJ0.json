[
  {
    "start": "0",
    "end": "108000"
  },
  {
    "text": "I'm gonna continue along the theme that we explored earlier so by now hopefully",
    "start": "0",
    "end": "5400"
  },
  {
    "text": "you're convinced that sage maker is awesome right yeah it is pretty cool right it is",
    "start": "5400",
    "end": "12750"
  },
  {
    "text": "pretty cool it's you know it's still very new just came out a month and a",
    "start": "12750",
    "end": "19650"
  },
  {
    "text": "half ago so yeah you know it's not obviously not perfect and you could make",
    "start": "19650",
    "end": "25350"
  },
  {
    "text": "it even easier to use etc but you know I find it's really a step in the right direction I mean if you've again if",
    "start": "25350",
    "end": "31529"
  },
  {
    "text": "you've done machine learning the normal way a lot of those steps that look super",
    "start": "31529",
    "end": "37860"
  },
  {
    "text": "obvious in sage maker well they could take a few weeks of work right so having",
    "start": "37860",
    "end": "47190"
  },
  {
    "text": "said that maybe you don't want to use the image maker right maybe you want to",
    "start": "47190",
    "end": "52500"
  },
  {
    "text": "work you want to keep working with MX net or maybe you want to keep working with another framework and maybe you",
    "start": "52500",
    "end": "60359"
  },
  {
    "text": "want to use ec2 instances and the Jeep running ami because you know that's the",
    "start": "60359",
    "end": "65430"
  },
  {
    "text": "way your your stack is set up for now and you know we understand that not",
    "start": "65430",
    "end": "70979"
  },
  {
    "text": "everybody is gonna jump into sage maker in an instant maybe you want to experiment with it before you move it",
    "start": "70979",
    "end": "76950"
  },
  {
    "text": "into production so in this talk you know I'm going to pretend that sage maker",
    "start": "76950",
    "end": "82049"
  },
  {
    "text": "doesn't exist all right actually it's a talk I did at reinvent so probably the very same day",
    "start": "82049",
    "end": "89700"
  },
  {
    "text": "sage maker was announced and this is focusing on I would like to say it's",
    "start": "89700",
    "end": "98340"
  },
  {
    "text": "pretty much everything I know put into slides when it comes to MMX that it's",
    "start": "98340",
    "end": "103409"
  },
  {
    "text": "pretty close to that actually I don't think I forgot anything major so it's",
    "start": "103409",
    "end": "110659"
  },
  {
    "start": "108000",
    "end": "108000"
  },
  {
    "text": "all the techniques and the tips that you should use to make your training process",
    "start": "110659",
    "end": "117750"
  },
  {
    "text": "more efficient right and there are two angles to this there is obviously the",
    "start": "117750",
    "end": "124979"
  },
  {
    "text": "model performance the one we all obsess on Oh what should be my learning rate why should be my optimization I'll go",
    "start": "124979",
    "end": "131720"
  },
  {
    "text": "how many airbox should I run you know the stuff that keeps you awake at night",
    "start": "131720",
    "end": "136900"
  },
  {
    "text": "but I find that there's a second topic which are called infrastructure performance that is at least as",
    "start": "136900",
    "end": "143510"
  },
  {
    "text": "important right because if you're running if you're training jobs run too",
    "start": "143510",
    "end": "149540"
  },
  {
    "text": "slowly then you're not going to be able to iterate fast enough right you're",
    "start": "149540",
    "end": "155690"
  },
  {
    "text": "going to wait for hours and days for training to complete and so that means you're not going to get many chances to",
    "start": "155690",
    "end": "161660"
  },
  {
    "text": "update the model and tweak the model so I think these two things go hand in hand so you need the infrastructure to run at",
    "start": "161660",
    "end": "169220"
  },
  {
    "text": "full speed with maximum performance during training and that gives you the",
    "start": "169220",
    "end": "174770"
  },
  {
    "text": "ability to tweak and tweak and tweak and tweak the machine learning and deep learning part right okay makes sense so",
    "start": "174770",
    "end": "183230"
  },
  {
    "text": "some of the stuff I'm going to say is really advanced so some of the slides",
    "start": "183230",
    "end": "188420"
  },
  {
    "text": "will make you go oh right they still make me go home sometimes fine so don't",
    "start": "188420",
    "end": "193550"
  },
  {
    "text": "worry it's not supposed to be it's very dense it's not supposed to be understood in one go and the last thing I want to",
    "start": "193550",
    "end": "199640"
  },
  {
    "text": "say is it is really level 666 it's it is very very advanced and some of that",
    "start": "199640",
    "end": "206630"
  },
  {
    "text": "stuff also makes sense for other frameworks so although I am talking about an X net a lot of the tips here",
    "start": "206630",
    "end": "213890"
  },
  {
    "text": "are also applied to tensorflow or other frameworks okay so if you're not using",
    "start": "213890",
    "end": "219440"
  },
  {
    "text": "MX net don't leave the room listen anyway you probably will pick some good tips for for the other for the other",
    "start": "219440",
    "end": "227450"
  },
  {
    "text": "libraries and then at the end of the session hopefully my effects classification notebook will be complete and I can show it to you right hopefully",
    "start": "227450",
    "end": "234640"
  },
  {
    "text": "so let's start with optimizing infrastructure ok so here's again the",
    "start": "234640",
    "end": "239900"
  },
  {
    "text": "name of the game is I'm on the training jobs to run as fast as possible because that saves me money right because you're",
    "start": "239900",
    "end": "246530"
  },
  {
    "text": "paying by the second sure but right you want to save some seconds huh and save some money and the faster they run the",
    "start": "246530",
    "end": "253730"
  },
  {
    "text": "more you get to the more you they get you get to iterate and and try something",
    "start": "253730",
    "end": "259070"
  },
  {
    "text": "else if that wasn't too efficient anyway so the first problem here and somebody",
    "start": "259070",
    "end": "266970"
  },
  {
    "start": "264000",
    "end": "264000"
  },
  {
    "text": "asked the question earlier about sharing the data set right actually it's a very good question how do you efficiently",
    "start": "266970",
    "end": "274169"
  },
  {
    "text": "deploy a large data set to to multiple",
    "start": "274169",
    "end": "279330"
  },
  {
    "text": "instances the data set i've worked with today they're really tiny right there they're megabytes so no issue at all",
    "start": "279330",
    "end": "287180"
  },
  {
    "text": "imagenet I'm gonna show you image net hopefully afterwards it's it's 150 gigs",
    "start": "287180",
    "end": "295740"
  },
  {
    "text": "right so that's a lot and it's a million files and more so it's not easy to move",
    "start": "295740",
    "end": "301949"
  },
  {
    "text": "around right so the first technique that you really you should implement is to",
    "start": "301949",
    "end": "309180"
  },
  {
    "text": "pack the data set into a record IO file okay and tensorflow has that same notion",
    "start": "309180",
    "end": "315900"
  },
  {
    "text": "they're called TF record files if you remember when I downloaded my my data",
    "start": "315900",
    "end": "322169"
  },
  {
    "text": "set the on that image classification notebook I just downloaded a dot rec",
    "start": "322169",
    "end": "327360"
  },
  {
    "text": "file and that's exactly what this is so it's one file storing the images and the",
    "start": "327360",
    "end": "332789"
  },
  {
    "text": "labels okay and it's okay it's one big file but it's only one file so it's much easier to move one very large file than",
    "start": "332789",
    "end": "340229"
  },
  {
    "text": "to move millions of small files okay plus if you want to do distributed",
    "start": "340229",
    "end": "345840"
  },
  {
    "text": "training the structure of the record i of files help instances split the work",
    "start": "345840",
    "end": "351750"
  },
  {
    "text": "among them because they're records so it's easier to say you take this chunk and I take this chunk and you take this",
    "start": "351750",
    "end": "357060"
  },
  {
    "text": "joke okay so it's super easy to use there's a tool in the MX that called I",
    "start": "357060",
    "end": "362190"
  },
  {
    "text": "am to rec to pack those files it doesn't take long and you know you do it once",
    "start": "362190",
    "end": "368729"
  },
  {
    "text": "but you train many times right so take the time to pack your data set you will thank me okay it's a it's a really good",
    "start": "368729",
    "end": "375750"
  },
  {
    "text": "way and again you can do the same thing in terms of flow so once that you have that you have your huge data set into",
    "start": "375750",
    "end": "383750"
  },
  {
    "text": "okay I forgot to say you know I love image classification example so I am",
    "start": "383750",
    "end": "389639"
  },
  {
    "text": "always talking about images so you have an image record IO file and which works best for images and you have",
    "start": "389639",
    "end": "396069"
  },
  {
    "text": "a generic record aisle file that could be anything right so it's not just for images important important precision",
    "start": "396069",
    "end": "402610"
  },
  {
    "text": "here so now once you have your data set where do you copy it right what's well",
    "start": "402610",
    "end": "408819"
  },
  {
    "text": "you could say well you know s3 makes sense maybe but not only s3 so one",
    "start": "408819",
    "end": "415719"
  },
  {
    "start": "411000",
    "end": "411000"
  },
  {
    "text": "pretty fun technique that I have is I copy that data set on a dedicated EBS",
    "start": "415719",
    "end": "422530"
  },
  {
    "text": "volume so I create an EB as well you might mount it on an instance and I I",
    "start": "422530",
    "end": "428159"
  },
  {
    "text": "jump the dog drag files in there okay and I take snap I take a snapshot",
    "start": "428159",
    "end": "435090"
  },
  {
    "text": "because once you've done that even if the data set is you know gigabytes you",
    "start": "435090",
    "end": "442509"
  },
  {
    "text": "can super quickly create a volume from the snapshot and attach it to the",
    "start": "442509",
    "end": "448029"
  },
  {
    "text": "instance so there's no copying involved right so because if you put in an s3 you",
    "start": "448029",
    "end": "453279"
  },
  {
    "text": "have to copy it or access it from s3 which means maybe slower so if you put it in a volume snapshot it right that",
    "start": "453279",
    "end": "460930"
  },
  {
    "text": "takes maybe a while but then creating a volume from a snapshot takes seconds and then you attach it to the to the",
    "start": "460930",
    "end": "467590"
  },
  {
    "text": "instance you want to train on and and you're done right and if you need ten volumes because you want to do",
    "start": "467590",
    "end": "474219"
  },
  {
    "text": "distributed training then you can create ten volumes from the same snapshot attach them to their instances and",
    "start": "474219",
    "end": "480520"
  },
  {
    "text": "you're done so in seconds right and that's easy to script automate so in seconds you could make very very large",
    "start": "480520",
    "end": "486819"
  },
  {
    "text": "datasets available to instances just by using that okay the only downside is",
    "start": "486819",
    "end": "493000"
  },
  {
    "text": "you're paying for the cost of the EBS volume and and the snapshots okay which",
    "start": "493000",
    "end": "500199"
  },
  {
    "text": "is maybe a little more than s3 but in any case you know it's super fast it's the fastest way to deploy actually so if",
    "start": "500199",
    "end": "508509"
  },
  {
    "text": "you don't want to do that of course you can store them in s3 you can you have an s3 connector in an X that provided that",
    "start": "508509",
    "end": "515050"
  },
  {
    "text": "you built a mix that with the use s3 flag right just try it and if it says",
    "start": "515050",
    "end": "521948"
  },
  {
    "text": "sorry you need to use the users three flag okay you need to rebuild and now you can",
    "start": "521949",
    "end": "528230"
  },
  {
    "text": "access files directly from history using the typical syntax so very cool s3",
    "start": "528230",
    "end": "533960"
  },
  {
    "text": "unlimited storage high durability problem maybe you know lower performance",
    "start": "533960",
    "end": "540200"
  },
  {
    "text": "you know you will get lower throughput from history than EBS okay so for very",
    "start": "540200",
    "end": "545600"
  },
  {
    "text": "large trainings maybe that's a problem and maybe it's more of a theoretical problem I had never actually faced it",
    "start": "545600",
    "end": "552380"
  },
  {
    "text": "but you could have a hot spot if if you have you know hundred instances learning",
    "start": "552380",
    "end": "557810"
  },
  {
    "text": "from the same doc Trek file hosted in the same servers maybe there's a hot",
    "start": "557810",
    "end": "563420"
  },
  {
    "text": "spot but it's more of a me being paranoid than a real problem another",
    "start": "563420",
    "end": "569720"
  },
  {
    "text": "option would be to use EFS okay the the point here would be EFS what an EFS",
    "start": "569720",
    "end": "578000"
  },
  {
    "text": "volume can be shared across instances right it's NFS so you could mount the same volume on multiple instances and",
    "start": "578000",
    "end": "585830"
  },
  {
    "text": "share the data set okay so it's very simple for distributed training no",
    "start": "585830",
    "end": "590960"
  },
  {
    "text": "copying no nothing the problem in is EFS is more expensive than EBS and s3 okay",
    "start": "590960",
    "end": "597620"
  },
  {
    "text": "so a long term if you have a large data set that's probably not the right way right maybe you need s3 for long-term",
    "start": "597620",
    "end": "603800"
  },
  {
    "text": "storage and EFS for training intense periods of time and then kill the FS",
    "start": "603800",
    "end": "610550"
  },
  {
    "text": "volume and EFS performance modes are you",
    "start": "610550",
    "end": "617540"
  },
  {
    "text": "know needs to be investigated you have two modes you have a general-purpose mode which which is fine and you have a",
    "start": "617540",
    "end": "625940"
  },
  {
    "text": "max IO performance mode that delivers more throughput but usually at the cost",
    "start": "625940",
    "end": "631520"
  },
  {
    "text": "of added latency that could be a problem for training you know you could stall your instances because they are waiting",
    "start": "631520",
    "end": "637520"
  },
  {
    "text": "for EFS to answer okay again I never really faced it but I'm guessing this",
    "start": "637520",
    "end": "642950"
  },
  {
    "text": "could happen right ok so that's it for storage so three different options s3",
    "start": "642950",
    "end": "648740"
  },
  {
    "text": "EBS EFS you know you make up your own mind ok and all of that stuff obviously is",
    "start": "648740",
    "end": "654160"
  },
  {
    "text": "applied to any and make any any deep learning library",
    "start": "654160",
    "end": "659270"
  },
  {
    "text": "now the second thing is okay so you've got storage taken care of now how do you",
    "start": "659270",
    "end": "666750"
  },
  {
    "text": "keep the GPUs running at full speed okay these are really hungry beasts right and",
    "start": "666750",
    "end": "673530"
  },
  {
    "text": "that's a problem because the faster they get the faster everything else needs to",
    "start": "673530",
    "end": "679650"
  },
  {
    "text": "get so you should be able to feed them at the right speed otherwise they work",
    "start": "679650",
    "end": "686820"
  },
  {
    "text": "and they stop and they work and they stop and you never get the food throughput and that happens a lot okay",
    "start": "686820",
    "end": "693710"
  },
  {
    "text": "so how do you know what the right speed should be well if you've been running",
    "start": "693710",
    "end": "701220"
  },
  {
    "text": "trainings before you have some benchmarks you should look at load logs you could say well you know I know this",
    "start": "701220",
    "end": "706530"
  },
  {
    "text": "should train at you know 500 images per second or blah blah blah so you shouldn't that's that's a training",
    "start": "706530",
    "end": "713090"
  },
  {
    "text": "benchmark a training indicator that you could track maybe you could look at numbers and benchmarks reported by",
    "start": "713090",
    "end": "719700"
  },
  {
    "text": "others you know people tend to share their training data etc so you should look at well what kind of performance",
    "start": "719700",
    "end": "725490"
  },
  {
    "text": "people get and do you get something close enough or or not okay and then of",
    "start": "725490",
    "end": "730950"
  },
  {
    "text": "course you should look at how the NVIDIA GPUs are running okay so there's a tool called Nvidia SMI and it's going to give",
    "start": "730950",
    "end": "738240"
  },
  {
    "text": "you the list of GPUs and their power consumption and how busy they are right",
    "start": "738240",
    "end": "743400"
  },
  {
    "text": "and you should look at that and the rule here is simple they should all be at one",
    "start": "743400",
    "end": "749940"
  },
  {
    "text": "order to send and stable at 100% right if you see you know 50 120 70 well",
    "start": "749940",
    "end": "758220"
  },
  {
    "text": "that's not good because it means they're you know they're stalling and they're not being fed fast enough okay so there",
    "start": "758220",
    "end": "765450"
  },
  {
    "text": "is a throughput issue somewhere it could be storage could be something else all",
    "start": "765450",
    "end": "770640"
  },
  {
    "text": "right so one parameter is batch size",
    "start": "770640",
    "end": "775970"
  },
  {
    "start": "774000",
    "end": "774000"
  },
  {
    "text": "okay so the batch size is hard which slice the data set and how big those",
    "start": "775970",
    "end": "782190"
  },
  {
    "text": "slices are when we push them through the network for training okay so this is an",
    "start": "782190",
    "end": "787380"
  },
  {
    "text": "important parameter usually people will agree that a larger",
    "start": "787380",
    "end": "794190"
  },
  {
    "text": "batch size is more efficient okay because you push more data at the GPU so",
    "start": "794190",
    "end": "799350"
  },
  {
    "text": "you keep them really busy right you can keep more cores on the GPU busy but a",
    "start": "799350",
    "end": "806700"
  },
  {
    "text": "smaller batch size usually gets you to better results because you take smaller",
    "start": "806700",
    "end": "812120"
  },
  {
    "text": "smaller steps through the data set so you know it's usually better so not too",
    "start": "812120",
    "end": "817440"
  },
  {
    "text": "big not too small right not very scientific but you need to find something in between so here are a",
    "start": "817440",
    "end": "825840"
  },
  {
    "text": "couple of suggestions if you have a small data set with a few classes like m",
    "start": "825840",
    "end": "831030"
  },
  {
    "text": "nest right 56 60 k samples 10 classes or psy far 50 k samples 10",
    "start": "831030",
    "end": "839910"
  },
  {
    "text": "classes then a good rule of thumb is 32 multiplied by the number of GPUs or",
    "start": "839910",
    "end": "846270"
  },
  {
    "text": "training on ok that's a good starting point and you don't want to go too big",
    "start": "846270",
    "end": "851640"
  },
  {
    "text": "right because if you go with really big batch sizes imagine you have 50 K",
    "start": "851640",
    "end": "858060"
  },
  {
    "text": "samples right if you have 1024 let's say a thousand as the batch size you will go",
    "start": "858060",
    "end": "864839"
  },
  {
    "text": "through one through the data set in 50 steps right 50 times 1,000 so that means",
    "start": "864839",
    "end": "870930"
  },
  {
    "text": "for one epoch you only get 50 steps to learn and to run back propagation in the",
    "start": "870930",
    "end": "877080"
  },
  {
    "text": "deep Learning Network right so that's not enough probably so if you use let's",
    "start": "877080",
    "end": "883050"
  },
  {
    "text": "say 4000 you know maybe that's 12 steps so for each epoch you only learn you",
    "start": "883050",
    "end": "889800"
  },
  {
    "text": "only get to adjust the way it's 12 times and probably that's not enough okay so",
    "start": "889800",
    "end": "895200"
  },
  {
    "text": "don't go too high otherwise your training process will be screwed up okay so you need to be reasonable on the",
    "start": "895200",
    "end": "902010"
  },
  {
    "text": "other hand if you have a large data set like image that you know millions of images a thousand classes then you",
    "start": "902010",
    "end": "908940"
  },
  {
    "text": "should use the large possible batch size and how do you find out well it's pretty",
    "start": "908940",
    "end": "914280"
  },
  {
    "text": "funny you just you start at this and you increase it until MX net fails because",
    "start": "914280",
    "end": "921510"
  },
  {
    "text": "the GPUs memory okay so you just push it you see Jeep you see memory usage in that Nvidia",
    "start": "921510",
    "end": "927720"
  },
  {
    "text": "SMI tool so just push it to the max okay if I have to make a snarky comment right",
    "start": "927720",
    "end": "935370"
  },
  {
    "text": "at the end of the day I'm allowed to do that you cannot use this technique with tensorflow because tensorflow",
    "start": "935370",
    "end": "941370"
  },
  {
    "text": "allocates the full GPU memory even if it doesn't need it so if you have 10 gigs",
    "start": "941370",
    "end": "947370"
  },
  {
    "text": "on the GPU John allocate the 10 gigs so when you look and say oh I have allocated 10 gigs I'm running at best",
    "start": "947370",
    "end": "953819"
  },
  {
    "text": "performance no obviously not ok the the memory usage you will see for",
    "start": "953819",
    "end": "959100"
  },
  {
    "text": "MX 10 is the real memory usage so if you change the batch size you will actually see this series going up I did write",
    "start": "959100",
    "end": "965639"
  },
  {
    "text": "write a blog post on time ago on this got really funny reactions but hey I was",
    "start": "965639",
    "end": "971819"
  },
  {
    "text": "right so never mind so MX that you know it's pretty conservative so it tells you",
    "start": "971819",
    "end": "978029"
  },
  {
    "text": "exactly how much memory usage so just push it increase it right and until you get an X net to yell at you saying no",
    "start": "978029",
    "end": "985189"
  },
  {
    "text": "you will get an ugly error message saying GPU out of memory or something and okay well then you know you went too",
    "start": "985189",
    "end": "991620"
  },
  {
    "text": "far okay so that's fine we were pushing",
    "start": "991620",
    "end": "998790"
  },
  {
    "start": "994000",
    "end": "994000"
  },
  {
    "text": "as much data as we can into the GPUs okay and using as Nvidia SMI we should",
    "start": "998790",
    "end": "1007220"
  },
  {
    "text": "see that the memory is fully used and yet maybe GPU usage is not a 100% so",
    "start": "1007220",
    "end": "1014389"
  },
  {
    "text": "we're filling up the GPUs but they still stall right so it's like hey here's the",
    "start": "1014389",
    "end": "1019610"
  },
  {
    "text": "big bunch they go through it and then they stop oh here's another big bunch and then they go through it and they",
    "start": "1019610",
    "end": "1025520"
  },
  {
    "text": "stop because you don't feed them fast enough right they're really hungry",
    "start": "1025520",
    "end": "1031100"
  },
  {
    "text": "so remember a deep learning job of course it's running on the GPU right the",
    "start": "1031100",
    "end": "1037459"
  },
  {
    "text": "training pot but there's a Python process running next to that okay it could be the notebook it could be your",
    "start": "1037459",
    "end": "1043880"
  },
  {
    "text": "own Python process the script that you're running okay the training script",
    "start": "1043880",
    "end": "1049100"
  },
  {
    "text": "does not run on the GPU it runs on the CPU a lot of people forget that okay so",
    "start": "1049100",
    "end": "1056860"
  },
  {
    "text": "here's that is that process keeping up right the iterator remember that we saw",
    "start": "1056860",
    "end": "1062030"
  },
  {
    "text": "that morning the the object that feeds the data to to the GPU is it running",
    "start": "1062030",
    "end": "1068240"
  },
  {
    "text": "fast enough because if not you know you're stalling so you can use all usual",
    "start": "1068240",
    "end": "1075110"
  },
  {
    "text": "techniques you could you stop to check the load to count how many threads are running and generally get us and stuff",
    "start": "1075110",
    "end": "1082250"
  },
  {
    "text": "you know is this machine busy enough right if you see the GPU stalling and if",
    "start": "1082250",
    "end": "1088010"
  },
  {
    "text": "your cpu load is like 5% that's it the CPU is not working hard enough to feed",
    "start": "1088010",
    "end": "1094520"
  },
  {
    "text": "the GPUs ok so you need to make sure that python process is working hard to",
    "start": "1094520",
    "end": "1101990"
  },
  {
    "text": "read the data from storage and push it through the GPUs and another good reason",
    "start": "1101990",
    "end": "1107179"
  },
  {
    "text": "to use those record IO files is that you can specify the number of threads that are working on the IO ok so you could",
    "start": "1107179",
    "end": "1115070"
  },
  {
    "text": "say giving more threads read more stuff in parallel and push it to the GPU all the time so just make sure you max out",
    "start": "1115070",
    "end": "1121900"
  },
  {
    "text": "that Python process make it work as hard as possible because if it if it's too",
    "start": "1121900",
    "end": "1127760"
  },
  {
    "text": "you know relaxed then it's gonna start the GPUs and your training times are gonna explode literally right so if the",
    "start": "1127760",
    "end": "1136370"
  },
  {
    "text": "python process is really you know maxed and you have the max number of decoding",
    "start": "1136370",
    "end": "1141710"
  },
  {
    "text": "threads here then maybe you have a an i/o problem right maybe it's the i/o layer that is actually slow and again",
    "start": "1141710",
    "end": "1148880"
  },
  {
    "text": "top would tell you that you should look at the the idle time for the Python process it would tell you yeah you know",
    "start": "1148880",
    "end": "1155420"
  },
  {
    "text": "I'm doing what I can but I keep waiting for i/o so we need faster reo so you",
    "start": "1155420",
    "end": "1160940"
  },
  {
    "text": "know top and i/o stat and maybe will help you figure it out",
    "start": "1160940",
    "end": "1166929"
  },
  {
    "text": "I've never run into a problem with EBS EBS what's always fast enough but ok who",
    "start": "1166929",
    "end": "1172610"
  },
  {
    "text": "knows so maybe you could look at you know local storage you could do some instant store storage that's faster or",
    "start": "1172610",
    "end": "1180559"
  },
  {
    "text": "why not use around disk the good old technique from the 80s with Windows three zero that works superfast right",
    "start": "1180559",
    "end": "1187060"
  },
  {
    "text": "these instances they have hundreds of gigabytes update of RAM so you could",
    "start": "1187060",
    "end": "1192100"
  },
  {
    "text": "create a ram disk put the data set in there and you know the I your problem is solved right and if something happens to",
    "start": "1192100",
    "end": "1201220"
  },
  {
    "text": "the instance no big deal you have the storage the EBS storage backing you up so I tend to use Ram disk which is a bit",
    "start": "1201220",
    "end": "1209410"
  },
  {
    "text": "of a silly technique but it kind of solves the i/o problem right think about that distributed training so I told you",
    "start": "1209410",
    "end": "1219520"
  },
  {
    "start": "1216000",
    "end": "1216000"
  },
  {
    "text": "this morning MX that scales very well it's kills nearly almost linear linearly up to 256 GPUs so how do you get to 256",
    "start": "1219520",
    "end": "1228640"
  },
  {
    "text": "GPUs well you use 16 instances with 16 GPUs and you throw them at the same data",
    "start": "1228640",
    "end": "1234850"
  },
  {
    "text": "set right it's an expensive demo don't write again I'm not paying my bills it's",
    "start": "1234850",
    "end": "1240580"
  },
  {
    "text": "it's very easy to set up it's really really easy to set up there's a good demo here right and again record iOS are",
    "start": "1240580",
    "end": "1248110"
  },
  {
    "text": "pretty much mandatory it's pretty much mandatory here because I said again it's gonna help instances split the data set",
    "start": "1248110",
    "end": "1254950"
  },
  {
    "text": "easily okay so I'm not going through the full set up but it's you can really set",
    "start": "1254950",
    "end": "1260470"
  },
  {
    "text": "it up in ten minutes there is nothing weird about that okay that's that's all",
    "start": "1260470",
    "end": "1266740"
  },
  {
    "start": "1265000",
    "end": "1265000"
  },
  {
    "text": "great and you know more power to GPUs but what if you don't have a GPU or what",
    "start": "1266740",
    "end": "1275680"
  },
  {
    "text": "if you don't have the budget for GPUs now you saw the prices for GPU instances this morning and what if you want to",
    "start": "1275680",
    "end": "1282760"
  },
  {
    "text": "work on your own machine well you have some libraries that help speed up",
    "start": "1282760",
    "end": "1289350"
  },
  {
    "text": "machine learning and deep running on CPUs okay so you have two options one",
    "start": "1289350",
    "end": "1295510"
  },
  {
    "text": "which I'll show you which I will demo it's called the Intel MKL",
    "start": "1295510",
    "end": "1301740"
  },
  {
    "text": "so it's a kernel it's a math library optimized for Broadwell and especially",
    "start": "1301740",
    "end": "1308260"
  },
  {
    "text": "skylake architectures so you there is a compilation option for it okay so it's",
    "start": "1308260",
    "end": "1315280"
  },
  {
    "text": "very easy to see if MX net has been built in with this when you start it if it doesn't say mkl",
    "start": "1315280",
    "end": "1321639"
  },
  {
    "text": "bla bla bla with a version number then you don't have it okay there is an open-source alternative called NN PAC",
    "start": "1321639",
    "end": "1328320"
  },
  {
    "text": "anyone knows that one yeah I like this one it's not as fast as I'm kale but I",
    "start": "1328320",
    "end": "1335049"
  },
  {
    "text": "love it because it works with raspberry PI's right it does support the and then the arm7 architecture okay and yeah it's",
    "start": "1335049",
    "end": "1344590"
  },
  {
    "text": "a cool project you can also use performance libraries like like JPEG",
    "start": "1344590",
    "end": "1351610"
  },
  {
    "text": "turbo and Gemma Locke and Google first tools to speed up very various parts of the process you know image manipulation",
    "start": "1351610",
    "end": "1357940"
  },
  {
    "text": "and and memory allocation these are usually not built-in but a",
    "start": "1357940",
    "end": "1365230"
  },
  {
    "text": "feel free to try that okay again the biggest benefit will come from probably",
    "start": "1365230",
    "end": "1370990"
  },
  {
    "text": "using mkl okay so mkl it's you can find",
    "start": "1370990",
    "end": "1379779"
  },
  {
    "start": "1376000",
    "end": "1376000"
  },
  {
    "text": "it on github and basically it's optimized implementations for all these",
    "start": "1379779",
    "end": "1385240"
  },
  {
    "text": "operations that we'll be talking about today so convolution activation pooling",
    "start": "1385240",
    "end": "1390789"
  },
  {
    "text": "plus all the math all the matrix algebra right you know optimized versions for",
    "start": "1390789",
    "end": "1396549"
  },
  {
    "text": "Intel chips okay so it makes a big big difference as you will see so if you",
    "start": "1396549",
    "end": "1401980"
  },
  {
    "text": "want to run training and prediction on on see five instances right like I said",
    "start": "1401980",
    "end": "1408549"
  },
  {
    "text": "this morning it's a the cost-effective way to do it make sure you use them care you will see why in a few minutes of",
    "start": "1408549",
    "end": "1416080"
  },
  {
    "start": "1416000",
    "end": "1416000"
  },
  {
    "text": "course you could use you could use spot instances so I told you this morning was",
    "start": "1416080",
    "end": "1421450"
  },
  {
    "text": "very very hard to grab P three instances in spot right now it's easier to grab",
    "start": "1421450",
    "end": "1428950"
  },
  {
    "text": "pizzas right here's an example this is from September the end of September so",
    "start": "1428950",
    "end": "1436419"
  },
  {
    "text": "it's not that old and that's a uswest - so the it's the Oregon region and I",
    "start": "1436419",
    "end": "1442990"
  },
  {
    "text": "could find some P - 16 X L so 16 nvidia gpus at 89% discount",
    "start": "1442990",
    "end": "1451310"
  },
  {
    "text": "right so that's that's pretty good right that's a good deal okay p3 is more difficult right now I",
    "start": "1451310",
    "end": "1458660"
  },
  {
    "text": "don't know if I mentioned that example already but I don't remember but Clemson University ran a few months ago a very",
    "start": "1458660",
    "end": "1466520"
  },
  {
    "text": "large natural language processing job on 1.1 million virtual CPUs so that means",
    "start": "1466520",
    "end": "1474760"
  },
  {
    "text": "five hundred thousand and fifty five yeah 5 5k no scratch that",
    "start": "1474760",
    "end": "1482420"
  },
  {
    "text": "five five zero K actual physical cores okay so five hundred five hundred",
    "start": "1482420",
    "end": "1488990"
  },
  {
    "text": "thousand plus physical cores only ws okay so people ask me about the scale",
    "start": "1488990",
    "end": "1494570"
  },
  {
    "text": "available yes okay so one customer can do this right for a few hours on spot at",
    "start": "1494570",
    "end": "1502790"
  },
  {
    "text": "a very low price I don't know the exact budget for this but if they were clever you know it's probably a silly low",
    "start": "1502790",
    "end": "1510140"
  },
  {
    "text": "number for that kind of processing power 500,000 cores you know it's like one of those top ten",
    "start": "1510140",
    "end": "1516820"
  },
  {
    "text": "supercomputers right that's the kind of thing you the kind of performance you get for I don't I don't want to say any",
    "start": "1516820",
    "end": "1523580"
  },
  {
    "text": "number cuz I don't on the number I can only guess but a ridiculous amount a really good is the small amount of money",
    "start": "1523580",
    "end": "1529640"
  },
  {
    "text": "right so here's a hint on the scale a bit about yes okay of course it's pretty",
    "start": "1529640",
    "end": "1536480"
  },
  {
    "text": "easy to select which GPUs you want a job to run so you know if you have 16 GPUs",
    "start": "1536480",
    "end": "1541970"
  },
  {
    "text": "on a machine and you have 16 developers in the team well again it's a silly trick but just say hey you're number one",
    "start": "1541970",
    "end": "1548840"
  },
  {
    "text": "and you're number two and number three and right you could use one instance and share the GPUs across developers people",
    "start": "1548840",
    "end": "1555470"
  },
  {
    "text": "don't think about this right but you know I think it's you know it works works for me right okay so let's look at",
    "start": "1555470",
    "end": "1564140"
  },
  {
    "text": "c5 and mkl right quick demo here",
    "start": "1564140",
    "end": "1570340"
  },
  {
    "text": "okay so okay so this is what is this",
    "start": "1572249",
    "end": "1578999"
  },
  {
    "text": "yeah okay so that's a c5 instance okay so skylake architecture no GPUs and",
    "start": "1578999",
    "end": "1588599"
  },
  {
    "text": "I think this one is the non mkl version so it's just vanilla I mixed net okay",
    "start": "1588599",
    "end": "1595090"
  },
  {
    "text": "that I build so we have a cool little script here called benchmark score and",
    "start": "1595090",
    "end": "1601749"
  },
  {
    "text": "now let's run that yeah and so what it does is it builds a number of network",
    "start": "1601749",
    "end": "1609359"
  },
  {
    "text": "architectures and runs prediction on random images okay and of course you see",
    "start": "1609359",
    "end": "1615639"
  },
  {
    "text": "how many images per seconds you get to so it starts with Alex net which is a it's an older CNN now this very popular",
    "start": "1615639",
    "end": "1622899"
  },
  {
    "text": "few years ago so it builds completely random data and pushes it through the",
    "start": "1622899",
    "end": "1628899"
  },
  {
    "text": "network here the goal is read to see how many images per second can we do right okay so and we do with batch size from 1",
    "start": "1628899",
    "end": "1636580"
  },
  {
    "text": "to 32 right so predicting one single image or predicting 32 images right",
    "start": "1636580",
    "end": "1643059"
  },
  {
    "text": "which gives you a sense of can we do let's say a real-time video analysis",
    "start": "1643059",
    "end": "1649059"
  },
  {
    "text": "with this right can we do 24 images per second right okay okay and then it tries",
    "start": "1649059",
    "end": "1654159"
  },
  {
    "text": "the inception Network okay so let it run and now let's use the same instance same",
    "start": "1654159",
    "end": "1664450"
  },
  {
    "text": "instance type but this one Ferb's this",
    "start": "1664450",
    "end": "1672219"
  },
  {
    "text": "one is built as mkl built in",
    "start": "1672219",
    "end": "1677580"
  },
  {
    "text": "so if I was clever I'd do something like this well what do you think so as you",
    "start": "1683700",
    "end": "1704409"
  },
  {
    "text": "can see it says mkl blah blah blah so not so that's how you know you have em Cal running so let's look at inception",
    "start": "1704409",
    "end": "1712210"
  },
  {
    "text": "for example when predicting one image at a time we can do 4.8 images per second",
    "start": "1712210",
    "end": "1718950"
  },
  {
    "text": "without mkl we can do and that's a crazy",
    "start": "1718950",
    "end": "1724360"
  },
  {
    "text": "number we can do 86 images per second so",
    "start": "1724360",
    "end": "1730210"
  },
  {
    "text": "we see the speed-up that you get right and you can you just use that thing for free just read make sure you build a",
    "start": "1730210",
    "end": "1736360"
  },
  {
    "text": "mixed net with this okay and then right",
    "start": "1736360",
    "end": "1741789"
  },
  {
    "text": "same thing here two images per second on Inception v3 which is a real number 33",
    "start": "1741789",
    "end": "1748120"
  },
  {
    "text": "images so you could you could go video right you could stream a video to this",
    "start": "1748120",
    "end": "1753580"
  },
  {
    "text": "and still be able to make 24 images per second right so depending on the",
    "start": "1753580",
    "end": "1759789"
  },
  {
    "text": "networks you get different results but right I rest my case you have to use MX net now you have to",
    "start": "1759789",
    "end": "1766389"
  },
  {
    "text": "use mkl when you use an extract",
    "start": "1766389",
    "end": "1769649"
  },
  {
    "text": "yeah but MX net is MX net is not it's C++ code right so you can optimize it",
    "start": "1779150",
    "end": "1787740"
  },
  {
    "text": "you can use GCC and use all the optimization flags that you want right you will not you will not get to that",
    "start": "1787740",
    "end": "1794070"
  },
  {
    "text": "same level here because mkl it's you know it's assembly code written by Intel tweaked for their instruction set it's",
    "start": "1794070",
    "end": "1800970"
  },
  {
    "text": "the the processor maker writing the code well it does it does well it does I'm",
    "start": "1800970",
    "end": "1809280"
  },
  {
    "text": "sorry right and it's not just instruction it's the the way you run the computation the way you do matrix",
    "start": "1809280",
    "end": "1815340"
  },
  {
    "text": "multiplication the way you do convolution etc etc right in one here",
    "start": "1815340",
    "end": "1821070"
  },
  {
    "text": "you use I would say portable C++ code and here you use highly optimized",
    "start": "1821070",
    "end": "1826290"
  },
  {
    "text": "assembly code and it makes a huge difference you can trust Intel to know their chips here as you can see yep I",
    "start": "1826290",
    "end": "1842220"
  },
  {
    "text": "don't want to use the Intel compiler I want to use my compiler I see your point",
    "start": "1842220",
    "end": "1847230"
  },
  {
    "text": "but right to me that's the faster route",
    "start": "1847230",
    "end": "1852320"
  },
  {
    "text": "and here okay let's compare this okay so let me",
    "start": "1852320",
    "end": "1858900"
  },
  {
    "text": "put that one here oh that's weird can I steal scroll okay and this one is",
    "start": "1858900",
    "end": "1869150"
  },
  {
    "text": "okay this one is a pea 3/16 Excel so that's like the top one lucky I could",
    "start": "1869150",
    "end": "1875940"
  },
  {
    "text": "grab one so eight eight Tesla chips okay",
    "start": "1875940",
    "end": "1881660"
  },
  {
    "text": "so super-powerful and let's run the same script I'm gonna run it on one GPU what",
    "start": "1881660",
    "end": "1887760"
  },
  {
    "text": "I want to show you here is the PUF the difference in performance between one voltage chip and one c5 instance with",
    "start": "1887760",
    "end": "1896220"
  },
  {
    "text": "mkl see how far away they are or not",
    "start": "1896220",
    "end": "1901700"
  },
  {
    "text": "okay so we can see here we are running on GPU zero so which one is this one",
    "start": "1904240",
    "end": "1912190"
  },
  {
    "text": "okay it's Alex net okay yeah okay",
    "start": "1912190",
    "end": "1917270"
  },
  {
    "text": "so Alex net huge difference but I would say no one uses that one anymore let's",
    "start": "1917270",
    "end": "1922760"
  },
  {
    "text": "look at inception where is that one number here okay okay so inception on",
    "start": "1922760",
    "end": "1932840"
  },
  {
    "text": "the c5 was 86 images per second if I do one image at a time on a GPU its",
    "start": "1932840",
    "end": "1940400"
  },
  {
    "text": "111 so sure its higher but it's only 50% better right given the cost the relative",
    "start": "1940400",
    "end": "1949070"
  },
  {
    "text": "costs I would say you should you see five right now if you go to now if you",
    "start": "1949070",
    "end": "1954830"
  },
  {
    "text": "want to do let's say video prediction you want to do you have batches of images you know 32 by 32 showing up then",
    "start": "1954830",
    "end": "1962480"
  },
  {
    "text": "sure the difference is much bigger because on the GPU you are so many cores",
    "start": "1962480",
    "end": "1968060"
  },
  {
    "text": "that you can you know you can run that batch in one go write the voltage chip",
    "start": "1968060",
    "end": "1973400"
  },
  {
    "text": "it has five thousand cores or so so yeah it's much more than this the c5 but as",
    "start": "1973400",
    "end": "1980210"
  },
  {
    "text": "you in most cases and let's maybe look at another one inception v3 71 when you",
    "start": "1980210",
    "end": "1987770"
  },
  {
    "text": "do image per image 33 when you do image per image so okay it's a two-to-one",
    "start": "1987770",
    "end": "1993950"
  },
  {
    "text": "ratio for performance but it's much more than two to one on price especially if",
    "start": "1993950",
    "end": "2000040"
  },
  {
    "text": "you do spot where it's much easier to grab c5 than to grab P threes okay so if",
    "start": "2000040",
    "end": "2005200"
  },
  {
    "text": "you want to do prediction for let's say mobile app you know people take pictures and you want to they take a picture and",
    "start": "2005200",
    "end": "2011260"
  },
  {
    "text": "they want to run the prediction okay it's an image by image thing as you can see inference with c5 is much more",
    "start": "2011260",
    "end": "2016900"
  },
  {
    "text": "economical if you want to process high-resolution real-time video feeds",
    "start": "2016900",
    "end": "2023400"
  },
  {
    "text": "yeah depending on the network architecture you know maybe the GPU",
    "start": "2023400",
    "end": "2028660"
  },
  {
    "text": "works better maybe depends right but sure as you increase the batch size the",
    "start": "2028660",
    "end": "2035620"
  },
  {
    "text": "thousands of course of the GP they just destroy everything else okay but a lot of tasks are really",
    "start": "2035620",
    "end": "2042549"
  },
  {
    "text": "classifying one image at a time okay so here's a good example here okay well you",
    "start": "2042549",
    "end": "2058720"
  },
  {
    "text": "have some consumer versions of those chips I mean the the Titan did you see that one it was a good gift for",
    "start": "2058720",
    "end": "2065980"
  },
  {
    "text": "Christmas the Titan and video yeah you saw that one that's $3,000 I didn't get",
    "start": "2065980",
    "end": "2072760"
  },
  {
    "text": "one but I have a Mac anyway so yeah you could you could you as long as you have",
    "start": "2072760",
    "end": "2080560"
  },
  {
    "text": "a GPU a recent and video GPU you can you can do that stuff right but the problem",
    "start": "2080560",
    "end": "2087368"
  },
  {
    "text": "is I would say if you need to build a development machine right and you want",
    "start": "2087369",
    "end": "2093310"
  },
  {
    "text": "to be autonomous then okay go and buy a reasonably sized GPU and and use deep",
    "start": "2093310",
    "end": "2098590"
  },
  {
    "text": "running with it but if you need to scale this for production right again",
    "start": "2098590",
    "end": "2104530"
  },
  {
    "text": "instances are pretty expensive if you want to do your own infrastructure hosting that stuff in a data center is",
    "start": "2104530",
    "end": "2111190"
  },
  {
    "text": "going to cost a lot because you pay for electricity and cooling right and GPUs",
    "start": "2111190",
    "end": "2116950"
  },
  {
    "text": "you know they tend to need a lot of that so right I would say for development",
    "start": "2116950",
    "end": "2122470"
  },
  {
    "text": "machines or test environments why not why not go and buy something and build it but for for production you know just",
    "start": "2122470",
    "end": "2129490"
  },
  {
    "text": "just use instances and that that's what I would do right but again if you have a mobile lab and you have millions of",
    "start": "2129490",
    "end": "2136450"
  },
  {
    "text": "users uploading what photo 1 photo at a time for prediction you cannot beat a",
    "start": "2136450",
    "end": "2141760"
  },
  {
    "text": "fleet of c-5 spot instances right because you're going to be able to even",
    "start": "2141760",
    "end": "2147760"
  },
  {
    "text": "from a web serving point of view right you want to scale out so same old same old",
    "start": "2147760",
    "end": "2152830"
  },
  {
    "text": "one super powerful GPU instance or two super powerful GPU instance there will be less scalable for from a request",
    "start": "2152830",
    "end": "2159940"
  },
  {
    "text": "point of view than 50 c-5s right but if you need to do again high resolution",
    "start": "2159940",
    "end": "2166150"
  },
  {
    "text": "video analysis probably you need to be peeled okay but try it okay let's talk about",
    "start": "2166150",
    "end": "2174250"
  },
  {
    "text": "model performance so model performance",
    "start": "2174250",
    "end": "2179570"
  },
  {
    "start": "2178000",
    "end": "2178000"
  },
  {
    "text": "means I want to build the best model possible the most accurate model possible so one cool technique to",
    "start": "2179570",
    "end": "2186020"
  },
  {
    "text": "improve your data set let's go in order is to use data augmentation and maybe",
    "start": "2186020",
    "end": "2191690"
  },
  {
    "text": "you've heard about that one so they're argumentation means you take your existing data set and you build more",
    "start": "2191690",
    "end": "2197119"
  },
  {
    "text": "samples so you flip the pictures you resize them you crop them you distort",
    "start": "2197119",
    "end": "2202340"
  },
  {
    "text": "them you change the colors right if you flip a cat picture or isn't elite still a cat all right so with depending",
    "start": "2202340",
    "end": "2209510"
  },
  {
    "text": "on the settings you could build maybe 16 or more different images from a single",
    "start": "2209510",
    "end": "2214790"
  },
  {
    "text": "sample and that will help your data set get bigger and that will help your data set grow more general okay so MX net and",
    "start": "2214790",
    "end": "2223700"
  },
  {
    "text": "Cara's they have those data augmentation tools and you should definitely use them",
    "start": "2223700",
    "end": "2228800"
  },
  {
    "text": "okay they're really they're really nice especially when you want to do",
    "start": "2228800",
    "end": "2234580"
  },
  {
    "text": "fine-tuning you know if you have just a few thousand images right data augmentation is a good way to move from",
    "start": "2234580",
    "end": "2241160"
  },
  {
    "text": "a few thousand to a few tens of thousands and maybe help more help build a more robust model so then you need to",
    "start": "2241160",
    "end": "2251180"
  },
  {
    "start": "2248000",
    "end": "2248000"
  },
  {
    "text": "look at initialization so initialization means you need to start all your weights",
    "start": "2251180",
    "end": "2257450"
  },
  {
    "text": "or all the weights for the neural network they need to have an initial",
    "start": "2257450",
    "end": "2262609"
  },
  {
    "text": "value right and usually something tells me well we could just start with zero",
    "start": "2262609",
    "end": "2267970"
  },
  {
    "text": "right well the problem is if you have symmetric and in identical values in the",
    "start": "2267970",
    "end": "2275300"
  },
  {
    "text": "network chances are that some networks will have actually the exact same",
    "start": "2275300",
    "end": "2280910"
  },
  {
    "text": "training right because when you adjust the weights you're going to adjust all the weights in the same direction or with the same increments or decrements",
    "start": "2280910",
    "end": "2287480"
  },
  {
    "text": "and that's not what you want so you need to start with random values right to break that symmetrical effect so they",
    "start": "2287480",
    "end": "2294800"
  },
  {
    "text": "shouldn't be too large or too small right which is something yes you see a lot",
    "start": "2294800",
    "end": "2301270"
  },
  {
    "text": "that's that's that's not you that's not helpful okay so the consensus is and I'm",
    "start": "2301270",
    "end": "2306430"
  },
  {
    "text": "sure you could do a PhD thesis and you could use your whole career on this probably so I don't at that time is to",
    "start": "2306430",
    "end": "2314440"
  },
  {
    "text": "use the Xavier technique that's actually the name of the guy who invented it for",
    "start": "2314440",
    "end": "2320050"
  },
  {
    "text": "CNN's it's quite popular I see that in all samples in all code samples from all",
    "start": "2320050",
    "end": "2325240"
  },
  {
    "text": "leading researchers it's gotta be good I trust those guys and for everything else",
    "start": "2325240",
    "end": "2331119"
  },
  {
    "text": "just random values between zero and one just pick a normal distribution and you will have those initializers okay so I",
    "start": "2331119",
    "end": "2338110"
  },
  {
    "text": "wouldn't try to go I will play smart and I wouldn't play smart and use anything",
    "start": "2338110",
    "end": "2344020"
  },
  {
    "text": "else I don't know any better this seems to work fine don't spend too long on",
    "start": "2344020",
    "end": "2349140"
  },
  {
    "text": "initialization just use those techniques and spend your time on something else such as the learning rate which is",
    "start": "2349140",
    "end": "2355450"
  },
  {
    "start": "2353000",
    "end": "2353000"
  },
  {
    "text": "everybody's nightmare again should be too small it should be too large if it's too small you will never learn if it's",
    "start": "2355450",
    "end": "2362710"
  },
  {
    "text": "too large you will never converge right so you will never find the minimum for the loss function for the error function",
    "start": "2362710",
    "end": "2369070"
  },
  {
    "text": "and you will bounce back and forth so that's not good what I know is that it's",
    "start": "2369070",
    "end": "2377500"
  },
  {
    "text": "actually a good a good technique to try to keep a learning rate a large",
    "start": "2377500",
    "end": "2382710"
  },
  {
    "text": "quote/unquote learning rate for a long time because you will get closer to the",
    "start": "2382710",
    "end": "2388750"
  },
  {
    "text": "minimum faster right if you take large steps for a while then chances are you",
    "start": "2388750",
    "end": "2395320"
  },
  {
    "text": "know you will converge fast and get closer to the minimum for the loss",
    "start": "2395320",
    "end": "2401260"
  },
  {
    "text": "function and then reduce it right imagine you're walking in Stockholm you're walking from here to some some",
    "start": "2401260",
    "end": "2409030"
  },
  {
    "text": "location near the train station right you know the train stations that way I guess so you can work pretty fast for 10",
    "start": "2409030",
    "end": "2416740"
  },
  {
    "text": "or even 15 minutes I don't know I took a taxi all right so you can walk that",
    "start": "2416740",
    "end": "2423369"
  },
  {
    "text": "direction pretty fast and then you can see okay I'm getting near so now I'm going to slow down and actually start looking at the signs right so that's the",
    "start": "2423369",
    "end": "2431080"
  },
  {
    "text": "intuition here so here are some techniques and you could use that with any kind of",
    "start": "2431080",
    "end": "2436300"
  },
  {
    "text": "framework so you could keep it simple and stick with a fixed learning rate say okay I'm gonna use 0.01 and if it trains",
    "start": "2436300",
    "end": "2444280"
  },
  {
    "text": "for three days fine I'm not in a rush but if you're running list on the WS you",
    "start": "2444280",
    "end": "2450130"
  },
  {
    "text": "still are paying for by the second so thank you but we'd like you to save money another technique is to use steps",
    "start": "2450130",
    "end": "2457060"
  },
  {
    "text": "so you could say I'm gonna run with this learning rate for 20 a box or a thousand",
    "start": "2457060",
    "end": "2467680"
  },
  {
    "text": "batches or you know you could take different steps and then I'm gonna reduce it okay so like I said walk fast",
    "start": "2467680",
    "end": "2474400"
  },
  {
    "text": "and then slow down and then slow down and then slow down and the closer you get to the destination the the fast the",
    "start": "2474400",
    "end": "2482440"
  },
  {
    "text": "closer you get to the destination the slower you learn to explore and make sure you really find that local minimum",
    "start": "2482440",
    "end": "2488380"
  },
  {
    "text": "or and that's my obviously my favorite option because I'm lazy is to use an",
    "start": "2488380",
    "end": "2495010"
  },
  {
    "text": "optimization algorithm that figures it out for me right if you've run some deep",
    "start": "2495010",
    "end": "2501280"
  },
  {
    "text": "learning tutorials probably you used an optimization algorithm that is called",
    "start": "2501280",
    "end": "2506490"
  },
  {
    "text": "the SGD right stochastic gradient descent and you need to have a learning",
    "start": "2506490",
    "end": "2511600"
  },
  {
    "text": "rate and then Stiga that's too small or how much college soon and we'll see in a couple of slides you have algos that",
    "start": "2511600",
    "end": "2518500"
  },
  {
    "text": "actually ignore this and they figure it out they adapt automatically the learning rate to the situation that's",
    "start": "2518500",
    "end": "2525460"
  },
  {
    "text": "fantastic right no nightmares so if you want to do steps this is how you would",
    "start": "2525460",
    "end": "2532750"
  },
  {
    "text": "do it in this is how you would do it in a max net and you can do it similarly in other libraries so you could say well",
    "start": "2532750",
    "end": "2540540"
  },
  {
    "text": "every time you have run a hundred batches reduce the learning rate by 0.9",
    "start": "2540540",
    "end": "2548200"
  },
  {
    "text": "or I'll have multiplied the landing rate by 0.9 decrease it by 10% okay or you",
    "start": "2548200",
    "end": "2555130"
  },
  {
    "text": "could say well these are my epic steps okay so each each time I reach one of",
    "start": "2555130",
    "end": "2560800"
  },
  {
    "text": "those epic numbers just multiply the learning rate by 0.9 okay but I'm not",
    "start": "2560800",
    "end": "2567190"
  },
  {
    "text": "what I don't really like this is that yeah I see that gentlemen because it's you you would have to know",
    "start": "2567190",
    "end": "2575440"
  },
  {
    "text": "what to expect right it's like why 109 one not 150 it's like yeah guesstimates",
    "start": "2575440",
    "end": "2585490"
  },
  {
    "text": "right so I don't really like that way of doing things but you can see that if you",
    "start": "2585490",
    "end": "2591190"
  },
  {
    "text": "have prior knowledge of your training if you've been training this thing for a",
    "start": "2591190",
    "end": "2596200"
  },
  {
    "text": "month and you looked at the car at the graphs for the accuracy etc you you know",
    "start": "2596200",
    "end": "2602170"
  },
  {
    "text": "you say okay up until that point I can learn very very fast and then I need to slow down and learn slower to improve",
    "start": "2602170",
    "end": "2607900"
  },
  {
    "text": "etc so maybe as a late optimization",
    "start": "2607900",
    "end": "2613090"
  },
  {
    "text": "stage for a very mature model very much room training process that's okay because you know what your training is",
    "start": "2613090",
    "end": "2618430"
  },
  {
    "text": "going to look like but in the beginning I don't think that works right because you tend to assume that hmm 100 epic 100",
    "start": "2618430",
    "end": "2626410"
  },
  {
    "text": "is important and you know so either you know or you're assuming and if you're",
    "start": "2626410",
    "end": "2631510"
  },
  {
    "text": "assuming it's not optimal okay so that",
    "start": "2631510",
    "end": "2636520"
  },
  {
    "start": "2635000",
    "end": "2635000"
  },
  {
    "text": "brings me to optimizers so we have many like other libraries and the only thing",
    "start": "2636520",
    "end": "2642430"
  },
  {
    "text": "I know for sure is that none of them works all the time right I would love to tell you use that",
    "start": "2642430",
    "end": "2649450"
  },
  {
    "text": "one all the time and you'll get the best results well that's not like that here's a silly example that um this data said",
    "start": "2649450",
    "end": "2659560"
  },
  {
    "text": "that you saw earlier this morning that training that I run okay with the lunette convolutional neural network I",
    "start": "2659560",
    "end": "2666099"
  },
  {
    "text": "tried it with a bunch of optimization algorithms okay so here's the time for",
    "start": "2666099",
    "end": "2672609"
  },
  {
    "text": "epic and use the validation accuracy I get after 28 bucks so you can see a lot",
    "start": "2672609",
    "end": "2679420"
  },
  {
    "text": "of pretty large differences right so for example that one you know it's super",
    "start": "2679420",
    "end": "2685780"
  },
  {
    "text": "slow right super slow so training is literally six times slower than vanilla",
    "start": "2685780",
    "end": "2691630"
  },
  {
    "text": "SGD and yet it gets to a lower accuracy so duh right science doesn't always work",
    "start": "2691630",
    "end": "2700900"
  },
  {
    "text": "okay and well that one is only twice slower but you know I get a much better result",
    "start": "2700900",
    "end": "2708350"
  },
  {
    "text": "than SGD so that brings me to the",
    "start": "2708350",
    "end": "2716210"
  },
  {
    "text": "difficult subject of well you gotta try them all right it's like Pokemon right you gotta catch",
    "start": "2716210",
    "end": "2721970"
  },
  {
    "text": "them all you know programming right I've got kids I don't worry I don't play pokemon but",
    "start": "2721970",
    "end": "2728420"
  },
  {
    "text": "it's the same thing you have to try them all one of them for that specific network and that specific data set and",
    "start": "2728420",
    "end": "2734660"
  },
  {
    "text": "that specific set of parameters is gonna work best okay and if you were here for",
    "start": "2734660",
    "end": "2740870"
  },
  {
    "text": "the stage maker talk I said in preview we were working on hyper parameter",
    "start": "2740870",
    "end": "2746930"
  },
  {
    "text": "optimization and that's because we want to solve that problem for you you could experiment with this for days and weeks",
    "start": "2746930",
    "end": "2753050"
  },
  {
    "text": "and tweak and try to find it so what if sage maker could tell you well try this",
    "start": "2753050",
    "end": "2759110"
  },
  {
    "text": "try this kid it's gonna work right try to give you automatically the best",
    "start": "2759110",
    "end": "2766550"
  },
  {
    "text": "settings possible you could trick for this try it I mean it takes a while but until you do that you should really try",
    "start": "2766550",
    "end": "2774770"
  },
  {
    "text": "them all okay you should try them all so you have multiple techniques and combine this with the learning rate okay okay",
    "start": "2774770",
    "end": "2781910"
  },
  {
    "text": "let's say you want to try 10 different learning rates with six optimizers okay",
    "start": "2781910",
    "end": "2788930"
  },
  {
    "text": "60 combinations multiplied by two or three initialization techniques okay",
    "start": "2788930",
    "end": "2794810"
  },
  {
    "text": "that's about 200 problems 300 trainings to run and well maybe you're algo has",
    "start": "2794810",
    "end": "2800420"
  },
  {
    "text": "other parameters too right so pretty quickly the combinations become pretty bad so there are",
    "start": "2800420",
    "end": "2808580"
  },
  {
    "text": "techniques to do that people do grid exploration etc so they they build that",
    "start": "2808580",
    "end": "2815770"
  },
  {
    "text": "let's say 3d matrix with learning rate and optimizer and maybe initialization",
    "start": "2815770",
    "end": "2823070"
  },
  {
    "text": "and they they pick 200 random set of values in there and and they train 200",
    "start": "2823070",
    "end": "2829670"
  },
  {
    "text": "models with those parameters and they see which one is best that's what people do right so that's what I'm saying you think",
    "start": "2829670",
    "end": "2836990"
  },
  {
    "text": "you've trained one model and your job is done maybe you were extremely lucky right or maybe you need to keep trying",
    "start": "2836990",
    "end": "2845170"
  },
  {
    "text": "right so probably something we need to fix for you guys okay a few more things",
    "start": "2845170",
    "end": "2853330"
  },
  {
    "start": "2851000",
    "end": "2851000"
  },
  {
    "text": "so you can reduce model size so there are two techniques so the all the",
    "start": "2853330",
    "end": "2859310"
  },
  {
    "text": "weights there are 32 bit floats there's a technical mixed precision",
    "start": "2859310",
    "end": "2866900"
  },
  {
    "text": "training where you actually truncate them to 16 floats during training so you",
    "start": "2866900",
    "end": "2873020"
  },
  {
    "text": "end up having a model that's twice smaller so for cloud based architectures",
    "start": "2873020",
    "end": "2878330"
  },
  {
    "text": "it doesn't really mean anything but for my Raspberry Pi you know the difference between two hundred Meg's and 100 Meg's",
    "start": "2878330",
    "end": "2884660"
  },
  {
    "text": "that's that's worthwhile right so for IOT applications that's interesting and there's even a project that does",
    "start": "2884660",
    "end": "2890930"
  },
  {
    "text": "binary weights right so it's not even floats it's minus 1 or plus 1 values ok",
    "start": "2890930",
    "end": "2899900"
  },
  {
    "text": "and obviously they get too crazy small models as you can see here right the",
    "start": "2899900",
    "end": "2907670"
  },
  {
    "text": "same model is shrinked from 44 Meg's to",
    "start": "2907670",
    "end": "2913910"
  },
  {
    "text": "1.5 Meg so that would really fit anywhere and they only lose 4 percent",
    "start": "2913910",
    "end": "2920510"
  },
  {
    "text": "accuracy so that's a lot right it's a lot 4 percent but it's the difference",
    "start": "2920510",
    "end": "2926390"
  },
  {
    "text": "between not being able to do deep learning on that device imagine it's the tiniest thing it could be a fire",
    "start": "2926390",
    "end": "2932900"
  },
  {
    "text": "detector or something right fire detectors they're not gonna have 64",
    "start": "2932900",
    "end": "2937940"
  },
  {
    "text": "Meg's of memory no way too expensive maybe they can have 2 Meg's right so",
    "start": "2937940",
    "end": "2943310"
  },
  {
    "text": "it's the difference between no deep running at all or slightly degraded deep",
    "start": "2943310",
    "end": "2949130"
  },
  {
    "text": "running so this is this technique its reopening up deep running to very very",
    "start": "2949130",
    "end": "2954170"
  },
  {
    "text": "constrained devices so if you're interested if you work in IOT you should look at this ok you can monitor the",
    "start": "2954170",
    "end": "2961610"
  },
  {
    "start": "2960000",
    "end": "2960000"
  },
  {
    "text": "training process you saw that in my logs you do this by creating a call back",
    "start": "2961610",
    "end": "2966680"
  },
  {
    "text": "saying well every time you've run ten batches just display the accuracy right so batch",
    "start": "2966680",
    "end": "2974770"
  },
  {
    "text": "ten batch twenty etcetera okay just to get some logs and don't forget to save",
    "start": "2974770",
    "end": "2980140"
  },
  {
    "text": "parameters after each epoch right you're gonna train for 200 day talks okay and",
    "start": "2980140",
    "end": "2987400"
  },
  {
    "text": "maybe okay you could say well then I'm gonna use them the model that that I get",
    "start": "2987400",
    "end": "2993190"
  },
  {
    "text": "after 200 that box right that's got to be the best one right because I trained longer so it's better right not always",
    "start": "2993190",
    "end": "3002150"
  },
  {
    "text": "because something like this could happen right so training accuracy goes up you",
    "start": "3002150",
    "end": "3008280"
  },
  {
    "start": "3004000",
    "end": "3004000"
  },
  {
    "text": "saw this in my examples and you will get to 100% remain if you saw that synthetic",
    "start": "3008280",
    "end": "3014310"
  },
  {
    "text": "data set example this morning you will be able to learn anything perfectly given enough time and a large enough",
    "start": "3014310",
    "end": "3021060"
  },
  {
    "text": "network ok the last function so the difference between the prediction and",
    "start": "3021060",
    "end": "3027030"
  },
  {
    "text": "the actual truth will go to 0 right see but maybe you'll see something like this",
    "start": "3027030",
    "end": "3034290"
  },
  {
    "text": "in validation accuracy it starts to drop after a point so you definitely don't",
    "start": "3034290",
    "end": "3040140"
  },
  {
    "text": "want to use this model a pork whatever you want to use that one so how do you",
    "start": "3040140",
    "end": "3047820"
  },
  {
    "text": "know if you didn't save the models after each epoch right so you want to save the",
    "start": "3047820",
    "end": "3055980"
  },
  {
    "text": "models after each epoch and then looking at your training graph you could say uh",
    "start": "3055980",
    "end": "3061640"
  },
  {
    "text": "here's the best one you could plot the validation accuracy and say well",
    "start": "3061640",
    "end": "3066810"
  },
  {
    "text": "actually I poke one two three was the best not two hundred okay and what happens here is called",
    "start": "3066810",
    "end": "3073080"
  },
  {
    "text": "overfitting it's you learn your training sets so well that it's the only thing",
    "start": "3073080",
    "end": "3079440"
  },
  {
    "text": "you know basically and you're not able to generalize to data that you haven't seen ok that's a really really bad",
    "start": "3079440",
    "end": "3086250"
  },
  {
    "text": "problem ok and we again we saw it with this synthetic example this morning we're able to learn crap perfectly but",
    "start": "3086250",
    "end": "3094440"
  },
  {
    "text": "when we look at real samples it's meaningless right overfitting so very",
    "start": "3094440",
    "end": "3099510"
  },
  {
    "text": "bad problem so as a conclusion so there's a lot of",
    "start": "3099510",
    "end": "3106220"
  },
  {
    "start": "3103000",
    "end": "3103000"
  },
  {
    "text": "literature on that stuff just Google you",
    "start": "3106220",
    "end": "3112500"
  },
  {
    "text": "know what learning rate should I pick right and well you get weeks of reading",
    "start": "3112500",
    "end": "3118940"
  },
  {
    "text": "so good you know read some stuff but the",
    "start": "3118940",
    "end": "3124559"
  },
  {
    "text": "the truth will come out of your own experiments okay because what worked for",
    "start": "3124559",
    "end": "3130710"
  },
  {
    "text": "that guy in that university is a different problem than than yours right",
    "start": "3130710",
    "end": "3138869"
  },
  {
    "text": "different data set maybe different network different parameters so there is no absolute truth right that's the only",
    "start": "3138869",
    "end": "3146670"
  },
  {
    "text": "thing I know and you have to try with your own data and your own network so",
    "start": "3146670",
    "end": "3152190"
  },
  {
    "text": "there are some guidelines you know not too small not too big but okay run your",
    "start": "3152190",
    "end": "3157260"
  },
  {
    "text": "examples and train a thousand models and pick the best one if there's a single",
    "start": "3157260",
    "end": "3162930"
  },
  {
    "text": "truth to deep learning that's probably it okay which leads me to you need to have",
    "start": "3162930",
    "end": "3170220"
  },
  {
    "text": "the right infrastructure to do it okay and maybe it's not a thousand maybe it's 100 right but I'm French and",
    "start": "3170220",
    "end": "3176970"
  },
  {
    "text": "exaggerating I can't I cannot help it train a lot of different models with a",
    "start": "3176970",
    "end": "3182579"
  },
  {
    "text": "lot of different values and and pick the best one I actually pick the best ones because there's a good technical",
    "start": "3182579",
    "end": "3189119"
  },
  {
    "text": "ensamble learning where people let's say train a lot of models and they pick the",
    "start": "3189119",
    "end": "3195539"
  },
  {
    "text": "five best ones and the runt prediction for the five and the average it okay the",
    "start": "3195539",
    "end": "3202710"
  },
  {
    "text": "idea here is each network is gonna make silly mistakes on some samples",
    "start": "3202710",
    "end": "3207829"
  },
  {
    "text": "absolutely silly mistakes so if you average it then okay the other networks",
    "start": "3207829",
    "end": "3213480"
  },
  {
    "text": "more pink to save mistakes so they will look a little less bad right and if you see all the competitions for image",
    "start": "3213480",
    "end": "3220230"
  },
  {
    "text": "recognition etc all the winners now they use and sample learning and several",
    "start": "3220230",
    "end": "3225869"
  },
  {
    "text": "techniques for prediction and sample prediction so anyway you need to make sure your infrastructure infrastructure",
    "start": "3225869",
    "end": "3231359"
  },
  {
    "text": "runs very well because you're going to train a lot okay compute storage everything that we",
    "start": "3231359",
    "end": "3239369"
  },
  {
    "text": "we saw that's all important right don't lose sleep over that you know but if something's not working you should see",
    "start": "3239369",
    "end": "3246690"
  },
  {
    "text": "it and fix it because it can literally multiply training time by two or three if they don't run right okay it happened",
    "start": "3246690",
    "end": "3253140"
  },
  {
    "text": "to me spot instances to optimize prices and it's really missing the lines say or",
    "start": "3253140",
    "end": "3259589"
  },
  {
    "text": "you could use the edge maker all right which and now you understand this predates the stage maker release so it's",
    "start": "3259589",
    "end": "3268109"
  },
  {
    "text": "not a clever marketing speech on my behalf because I can't really do that anyway but as you can see stage maker is",
    "start": "3268109",
    "end": "3276809"
  },
  {
    "text": "actually solving a lot of these problems and it's the reason why stage maker was built is to help customers you not worry",
    "start": "3276809",
    "end": "3286289"
  },
  {
    "text": "so much about these not all of these go away but a lot of these go away with",
    "start": "3286289",
    "end": "3291539"
  },
  {
    "text": "sage maker okay okay still I fully recognize edge maker is not it's not the",
    "start": "3291539",
    "end": "3297059"
  },
  {
    "text": "right tool for some some tasks I would love to hear about that okay so if you are running not necessarily later on if",
    "start": "3297059",
    "end": "3305940"
  },
  {
    "text": "you are running sage maker if you are running deep running or machine learning tasks on your own infrastructure or on",
    "start": "3305940",
    "end": "3313670"
  },
  {
    "text": "ec2 instances and you tried sage maker and you didn't like it or it didn't work",
    "start": "3313670",
    "end": "3319470"
  },
  {
    "text": "right for you I would love to hear about that you know I love it when people say it's great I love it even more when they",
    "start": "3319470",
    "end": "3326579"
  },
  {
    "text": "say man it sucks or we would like to love it but this and this and this are you know making us hail it so if you",
    "start": "3326579",
    "end": "3334650"
  },
  {
    "text": "have negative feedback on sage maker please PLEASE ping me on Twitter or LinkedIn and send it to me right you",
    "start": "3334650",
    "end": "3341069"
  },
  {
    "text": "might even win some edibles goodies who knows all right no promises okay so well",
    "start": "3341069",
    "end": "3347670"
  },
  {
    "text": "I hope this is useful I know it's a lot of different techniques but you know you really need to worry about all of this",
    "start": "3347670",
    "end": "3354119"
  },
  {
    "text": "as well so some resources and that's tiny but so again the amazon blog the MX",
    "start": "3354119",
    "end": "3363660"
  },
  {
    "start": "3355000",
    "end": "3355000"
  },
  {
    "text": "net code base and and websites and some blog",
    "start": "3363660",
    "end": "3368829"
  },
  {
    "text": "posts that I wrote on specifically on those problems how to use and unpack in",
    "start": "3368829",
    "end": "3375730"
  },
  {
    "text": "MX net how to do that tuning process on the Python proton record i/o et cetera",
    "start": "3375730",
    "end": "3383790"
  },
  {
    "text": "with C five instances etc etcetera so these are really you know more of the",
    "start": "3383790",
    "end": "3390550"
  },
  {
    "text": "same but with details and code and stuff that you can actually reuse ok so just give you the overview but if you wanna",
    "start": "3390550",
    "end": "3397210"
  },
  {
    "text": "zoom in please go there and and take a look okay so let me take a final look at",
    "start": "3397210",
    "end": "3405790"
  },
  {
    "text": "that classification notebook I'm so sorry to taking that long oh yeah okay",
    "start": "3405790",
    "end": "3414730"
  },
  {
    "text": "so if you were not there you're wondering what the hell I'm doing okay this is one of the examples I couldn't",
    "start": "3414730",
    "end": "3420280"
  },
  {
    "text": "complete in time in the previous session so here I'm using sage maker with the",
    "start": "3420280",
    "end": "3425800"
  },
  {
    "text": "built-in image classification algorithm and I took a pre trained image image",
    "start": "3425800",
    "end": "3431859"
  },
  {
    "text": "classification network I fine-tuned it on my data set and now I want to do predictions right so I've got some",
    "start": "3431859",
    "end": "3439960"
  },
  {
    "text": "predict some images that correspond to the classes that I have in the data set",
    "start": "3439960",
    "end": "3445530"
  },
  {
    "text": "alright so I guess that's a dog which is good because I have dogs in the data set",
    "start": "3445530",
    "end": "3452020"
  },
  {
    "text": "that I learned okay so now let's run",
    "start": "3452020",
    "end": "3458020"
  },
  {
    "text": "that image through the model and yeah 92 percent says it's it's a dog so that",
    "start": "3458020",
    "end": "3467349"
  },
  {
    "text": "worked okay and keep in mind I only trained I only trained for ten epochs so",
    "start": "3467349",
    "end": "3477940"
  },
  {
    "text": "the training job was actually I'm trying to look at how long it took not at the",
    "start": "3477940",
    "end": "3486490"
  },
  {
    "text": "time but maybe ten minutes or something it's do I have the training log",
    "start": "3486490",
    "end": "3492839"
  },
  {
    "text": "no I don't have in here okay it's in cloud watch logs but I just trained for",
    "start": "3495000",
    "end": "3503170"
  },
  {
    "text": "you know just a few minutes so I didn't train from scratch so let's try the bird",
    "start": "3503170",
    "end": "3508630"
  },
  {
    "text": "maybe okay so that's a bird but does my",
    "start": "3508630",
    "end": "3515110"
  },
  {
    "text": "model say 56 percent okay it's still a bird right the other choice would be",
    "start": "3515110",
    "end": "3524770"
  },
  {
    "text": "this class I don't know what that is but yeah okay but it's still a bird so two",
    "start": "3524770",
    "end": "3531040"
  },
  {
    "text": "for two let's try the horse this one's",
    "start": "3531040",
    "end": "3541870"
  },
  {
    "text": "wrong no it's not a deer right all right so two out of three but you only see the",
    "start": "3541870",
    "end": "3550630"
  },
  {
    "text": "head of the horse so maybe the data set has really you know full force pictures who knows and should we try the truck",
    "start": "3550630",
    "end": "3561180"
  },
  {
    "text": "okay crossing my fingers here yeah okay no",
    "start": "3562410",
    "end": "3567520"
  },
  {
    "text": "doubt that's the truck right so as you",
    "start": "3567520",
    "end": "3572560"
  },
  {
    "text": "can see that's that's a really cool technique right I've been talking about fine tuning for a while over and over",
    "start": "3572560",
    "end": "3579400"
  },
  {
    "text": "today and this is a really this is a really simple technique right so if you",
    "start": "3579400",
    "end": "3585910"
  },
  {
    "text": "want to contrast this to how would you do this manually well you would create an ec2 instance with the Jeep running mi",
    "start": "3585910",
    "end": "3592990"
  },
  {
    "text": "you would upload your data set to the ends to the instance probably you would",
    "start": "3592990",
    "end": "3598450"
  },
  {
    "text": "need to pick you would need to write an MX net or tensorflow script downloading",
    "start": "3598450",
    "end": "3607090"
  },
  {
    "text": "a pre-trained network from wherever right loading the datasets",
    "start": "3607090",
    "end": "3612690"
  },
  {
    "text": "loading the data set launching a training process etc etcetera so it you can definitely do it I've got all the",
    "start": "3612690",
    "end": "3618400"
  },
  {
    "text": "demos that do that right so you could do it without sage maker but we'll stage",
    "start": "3618400",
    "end": "3624100"
  },
  {
    "text": "maker the only thing that you do right sorry for those of you who have seen this before and I'll close on that right you pick",
    "start": "3624100",
    "end": "3631849"
  },
  {
    "text": "the darker image in your region that implements that image classification",
    "start": "3631849",
    "end": "3637069"
  },
  {
    "text": "algo you download the data set to Sage maker and is that record io5 I was",
    "start": "3637069",
    "end": "3642950"
  },
  {
    "text": "talking about right just one file for the training set and one file for the validation set you define some training",
    "start": "3642950",
    "end": "3650750"
  },
  {
    "text": "parameters how many epics how many classes etc etc the learning rate you",
    "start": "3650750",
    "end": "3659900"
  },
  {
    "text": "put that stuff in a JSON document right this is really the same thing in JSON",
    "start": "3659900",
    "end": "3665630"
  },
  {
    "text": "form you say where the training set is where the validation set is and you fire",
    "start": "3665630",
    "end": "3670970"
  },
  {
    "text": "up the training job right and you say well I want an M for instance where did",
    "start": "3670970",
    "end": "3678859"
  },
  {
    "text": "I set up here oh no it's running on a p2 instance here one instance done so you",
    "start": "3678859",
    "end": "3684859"
  },
  {
    "text": "wait for a few minutes and then you do",
    "start": "3684859",
    "end": "3690140"
  },
  {
    "text": "the same thing to deploy the model create a configuration m4 deploy etc",
    "start": "3690140",
    "end": "3697779"
  },
  {
    "text": "okay so that's a different way so if stage maker is enough for you",
    "start": "3697779",
    "end": "3702859"
  },
  {
    "text": "please use sage maker you're gonna save a whole lot of trouble managing all the stuff I actually talked about in this",
    "start": "3702859",
    "end": "3709819"
  },
  {
    "text": "last talk if sage maker is not enough please tell me why get in touch and use the used",
    "start": "3709819",
    "end": "3716180"
  },
  {
    "text": "tensorflow MX net your favorite deep learning library on on the Jeep running ami and using all the techniques that I",
    "start": "3716180",
    "end": "3722660"
  },
  {
    "text": "describe you should be able to get good infrastructure performance and good model performance but as you can see",
    "start": "3722660",
    "end": "3727849"
  },
  {
    "text": "it's a bit of work so a sage maker will be your friend here yes",
    "start": "3727849",
    "end": "3732730"
  },
  {
    "text": "so I'm actually not I'm actually it's in",
    "start": "3736830",
    "end": "3744790"
  },
  {
    "text": "the data set so here where's that data set here where does it",
    "start": "3744790",
    "end": "3751420"
  },
  {
    "text": "come from all the way up okay here what this record I'll file is is really is my",
    "start": "3751420",
    "end": "3758170"
  },
  {
    "text": "fifty thousand training images organized in classes okay so the way it usually",
    "start": "3758170",
    "end": "3765130"
  },
  {
    "text": "looks is I've got one directory per class so all horses etc etc and the",
    "start": "3765130",
    "end": "3771700"
  },
  {
    "text": "model knows nothing about horses or trucks right it knows about it knows about class zero class 1 class 2 class 3",
    "start": "3771700",
    "end": "3778450"
  },
  {
    "text": "that's it okay and it's just me at the end saying okay class 2 is a horse and",
    "start": "3778450",
    "end": "3785500"
  },
  {
    "text": "I'm pretty horse but it's all about numbers right there is no dominant",
    "start": "3785500",
    "end": "3790750"
  },
  {
    "text": "domain knowledge in here at all okay yes",
    "start": "3790750",
    "end": "3798300"
  },
  {
    "text": "yes",
    "start": "3801870",
    "end": "3804870"
  },
  {
    "text": "doesn't do something with yep and then",
    "start": "3819650",
    "end": "3850530"
  },
  {
    "text": "you have a client on the other side for the time today I mean I do understand that but many fiims doesn't understand",
    "start": "3850530",
    "end": "3857280"
  },
  {
    "text": "that so when you every single day every",
    "start": "3857280",
    "end": "3871380"
  },
  {
    "text": "single day yeah every single day there's one specific I'll go in stage maker I'm not gonna name it I still haven't gotten",
    "start": "3871380",
    "end": "3877589"
  },
  {
    "text": "it to work correctly and well it's my fault but it is a tricky situation",
    "start": "3877589",
    "end": "3885359"
  },
  {
    "text": "because the usually it's hard to say always in this case but usually it's all",
    "start": "3885359",
    "end": "3892680"
  },
  {
    "text": "about the data set right the typical problems that you will have is that if",
    "start": "3892680",
    "end": "3898230"
  },
  {
    "text": "you look at the training set here",
    "start": "3898230",
    "end": "3902539"
  },
  {
    "text": "training sets and that's very tiny I'm sorry but these are really tiny images",
    "start": "3903410",
    "end": "3908869"
  },
  {
    "text": "training sets tend to be very nice right so if you look at this one here I don't",
    "start": "3908869",
    "end": "3918119"
  },
  {
    "text": "know if you look at the deer's even with very tiny images here edge it's clear",
    "start": "3918119",
    "end": "3924990"
  },
  {
    "text": "it's a deer right so there's one single thing in the picture right this one",
    "start": "3924990",
    "end": "3930660"
  },
  {
    "text": "doesn't even have a background okay you see the antlers very clearly so these",
    "start": "3930660",
    "end": "3937799"
  },
  {
    "text": "are deep learning friendly pictures you know in your and that's the training set",
    "start": "3937799",
    "end": "3944640"
  },
  {
    "text": "and the validation data set is the same thing because it's the validation data set is a part of this so look at the",
    "start": "3944640",
    "end": "3951510"
  },
  {
    "text": "sheep pictures I mean there really nice ship pictures there is no doubt this is a ship right",
    "start": "3951510",
    "end": "3956970"
  },
  {
    "text": "but real-life pictures they're never like that okay maybe the subject is not",
    "start": "3956970",
    "end": "3963780"
  },
  {
    "text": "center centered in the picture or maybe there's other stuff in the background yeah maybe there's a maybe there's a dog",
    "start": "3963780",
    "end": "3970830"
  },
  {
    "text": "and maybe there is a person next to the dog right so even though that dataset doesn't know anything about persons I",
    "start": "3970830",
    "end": "3977089"
  },
  {
    "text": "know it's noise could confuse them I don't want to say people look like dogs but maybe some do but you know what I",
    "start": "3977089",
    "end": "3984480"
  },
  {
    "text": "mean those training pictures they look very nice and and they probably don't look",
    "start": "3984480",
    "end": "3989640"
  },
  {
    "text": "like what end-users will will upload and use if you think that you know pictures",
    "start": "3989640",
    "end": "3995400"
  },
  {
    "text": "that people take with them their mobile phones none of them is really gonna look like that they're gonna be you know",
    "start": "3995400",
    "end": "4002410"
  },
  {
    "text": "fuzzy and overexposed and there would be all sorts of objects around the subject",
    "start": "4002410",
    "end": "4009680"
  },
  {
    "text": "etc etc so that's actually something I",
    "start": "4009680",
    "end": "4015470"
  },
  {
    "text": "didn't talk about because it's really data set management but it's important that you inject in your training set",
    "start": "4015470",
    "end": "4021880"
  },
  {
    "text": "pictures that will really or in a validation set pictures that will really really look like what real-life samples",
    "start": "4021880",
    "end": "4030950"
  },
  {
    "text": "will look like because if you have a very nice data set like this yeah you",
    "start": "4030950",
    "end": "4036619"
  },
  {
    "text": "can learn it pretty well and then people say okay now we've got real life pictures and you push them through that",
    "start": "4036619",
    "end": "4042589"
  },
  {
    "text": "and they don't work because they are too different so the distribution of the of",
    "start": "4042589",
    "end": "4049099"
  },
  {
    "text": "the of the training set should be similar top close maybe not similar but",
    "start": "4049099",
    "end": "4056599"
  },
  {
    "text": "should should include the training set the training set should include some low",
    "start": "4056599",
    "end": "4062359"
  },
  {
    "text": "quality real life pictures because your network needs to learn how to recognize",
    "start": "4062359",
    "end": "4067880"
  },
  {
    "text": "them and actually data augmentation is a good if you don't have those samples data augmentation is a good way to do",
    "start": "4067880",
    "end": "4074210"
  },
  {
    "text": "that because data augmentation is going to distort the pictures it's going to you know change the colors going to flip",
    "start": "4074210",
    "end": "4080420"
  },
  {
    "text": "them it's going to stretch them crop them etc so some of the Augmented pictures they look",
    "start": "4080420",
    "end": "4086160"
  },
  {
    "text": "crap right but that's actually good because if you say well I'm let's say I",
    "start": "4086160",
    "end": "4092099"
  },
  {
    "text": "take this I don't know this dog here and I'm cropping the picture like this so",
    "start": "4092099",
    "end": "4097380"
  },
  {
    "text": "maybe I can see only one eye you know half of the dog's face and maybe you know I tweaked the color and the dog",
    "start": "4097380",
    "end": "4103798"
  },
  {
    "text": "becomes you know slightly greenish or something okay if you show that to a kid",
    "start": "4103799",
    "end": "4108960"
  },
  {
    "text": "or person they will still say it's a dog so the network should be able to face",
    "start": "4108960",
    "end": "4114480"
  },
  {
    "text": "those adversarial samples and say yeah okay it's low quality maybe the",
    "start": "4114480",
    "end": "4120120"
  },
  {
    "text": "probability that will be output will be lower but I will still classify this as a dog so it's really you know that's and",
    "start": "4120120",
    "end": "4127620"
  },
  {
    "text": "that's a difficult issue so if you have real-life samples throw some of them into the training set right not just",
    "start": "4127620",
    "end": "4135988"
  },
  {
    "text": "very clean and nice samples like this and that's gonna help a lot but you will never be done there will be mistakes so",
    "start": "4135989",
    "end": "4144000"
  },
  {
    "text": "the thing is if you if you should go to your customer and say my network is 99% accurate right if I was the customer I'd",
    "start": "4144000",
    "end": "4151588"
  },
  {
    "text": "say okay show me the validation set because if the validation set is looking like this I'm gonna say okay no I want I",
    "start": "4151589",
    "end": "4160620"
  },
  {
    "text": "want 99% on a crappy validation set so go and build a crappy set learn it 99% right and then okay",
    "start": "4160620",
    "end": "4168568"
  },
  {
    "text": "we're done but they shouldn't use that",
    "start": "4168569",
    "end": "4179100"
  },
  {
    "text": "technology they should use Amazon recognition yeah yeah so yeah it's a",
    "start": "4179100",
    "end": "4187890"
  },
  {
    "text": "good point so if they're not sophisticated enough to understand what kind of work is required from them which",
    "start": "4187890",
    "end": "4194670"
  },
  {
    "text": "is okay show me your data set what kind of samples would you like me to predict",
    "start": "4194670",
    "end": "4199739"
  },
  {
    "text": "right what's the business problem oh I want to classify images that my users",
    "start": "4199739",
    "end": "4204750"
  },
  {
    "text": "upload via the mobile app okay can I get a thousand of those no okay well okay so",
    "start": "4204750",
    "end": "4213330"
  },
  {
    "text": "I'm gonna pretend I have a thousand of those by building crappy looking samples using data augmentations",
    "start": "4213330",
    "end": "4220150"
  },
  {
    "text": "and maybe we can start from there but you need to be very nasty to the training set right",
    "start": "4220150",
    "end": "4227950"
  },
  {
    "text": "that's the robustness issue comes a lot from them yeah you can you should be",
    "start": "4227950",
    "end": "4235430"
  },
  {
    "text": "able to demonstrate that you score high on these kind of pictures right oh yeah it's iterative iterative as hell",
    "start": "4235430",
    "end": "4245080"
  },
  {
    "text": "that's why I'm saying train 100 networks train all the time train all the time try different it data augmentation just",
    "start": "4245080",
    "end": "4251830"
  },
  {
    "text": "yeah try to make the network as robust as possible to two ugly samples and like",
    "start": "4251830",
    "end": "4259400"
  },
  {
    "text": "my ugly nine right so it's the ugly nine syndrome yeah you need to have the those",
    "start": "4259400",
    "end": "4265460"
  },
  {
    "text": "you need to score high on those crappy looking pictures if you do that then",
    "start": "4265460",
    "end": "4270620"
  },
  {
    "text": "probably your network is doing a good job yeah so so if we add a deer and a",
    "start": "4270620",
    "end": "4284180"
  },
  {
    "text": "dog in the same picture your guess is as good as mine right so again you know it",
    "start": "4284180",
    "end": "4295160"
  },
  {
    "text": "depends maybe it's gonna maybe the helicopter is gonna be don't we have",
    "start": "4295160",
    "end": "4301820"
  },
  {
    "text": "airplanes in that one yeah I think we do know maybe it's class one okay so if we",
    "start": "4301820",
    "end": "4309260"
  },
  {
    "text": "have other objects that kind of look like that it might it might trip the",
    "start": "4309260",
    "end": "4315920"
  },
  {
    "text": "network let's say if we have a bear you know some dogs some big dogs you know",
    "start": "4315920",
    "end": "4322670"
  },
  {
    "text": "they they have a similar shape and color to bear so you you saw that I'm saying",
    "start": "4322670",
    "end": "4329870"
  },
  {
    "text": "it depends okay so obviously okay that's nuts not a bear but you know that big",
    "start": "4329870",
    "end": "4337160"
  },
  {
    "text": "dog here you never know so there will be",
    "start": "4337160",
    "end": "4342290"
  },
  {
    "text": "some mismatch I mean there there's a famous example of did you see that the muffin and the Chihuahua yeah it it's",
    "start": "4342290",
    "end": "4350420"
  },
  {
    "text": "it's very cool you take a blueberry muffin picture with the blueberries can Alou and look",
    "start": "4350420",
    "end": "4356480"
  },
  {
    "text": "Anna looking like the dog's eyes and the nose and you try that with deep running networks and it says it's a chihuahua",
    "start": "4356480",
    "end": "4362660"
  },
  {
    "text": "and the other way around and you take an ugly she wa and it takes it says it's a blueberry muffin because at the end of",
    "start": "4362660",
    "end": "4368810"
  },
  {
    "text": "the day it's all about you know geometric shapes so sure you know those networks they get better all the time",
    "start": "4368810",
    "end": "4374570"
  },
  {
    "text": "but they will still make mistakes they will still make mistakes so that's why you need very large datasets lots of",
    "start": "4374570",
    "end": "4381710"
  },
  {
    "text": "samples per class data augmentation etc exceptional absolutely very good point",
    "start": "4381710",
    "end": "4395060"
  },
  {
    "text": "the more classes you have the harder it gets because it's a it's an easy task to",
    "start": "4395060",
    "end": "4402110"
  },
  {
    "text": "say is this or narrow plane or something else versus is this an airplane or a",
    "start": "4402110",
    "end": "4409460"
  },
  {
    "text": "truck right so sure so it's like the hot dog not hot dog silly thing right so",
    "start": "4409460",
    "end": "4416210"
  },
  {
    "text": "saying it is this one thing or not is easy that's an easy task so if your",
    "start": "4416210",
    "end": "4423140"
  },
  {
    "text": "business problem is I'm only interested in detecting trucks right maybe it's at",
    "start": "4423140",
    "end": "4430760"
  },
  {
    "text": "all or something I don't know so you don't care if it's a car you don't care if it's a motorcycle you don't care if it's anything or a moose",
    "start": "4430760",
    "end": "4437540"
  },
  {
    "text": "on the highway right you don't care you want to know if it's a truck so you could say well I got two classes what",
    "start": "4437540",
    "end": "4443570"
  },
  {
    "text": "class zero is trucks class one is there everything else and you would dump you know all the other images in anything",
    "start": "4443570",
    "end": "4450200"
  },
  {
    "text": "else and you will learn that very well very very well right of course the more classes you get into you know",
    "start": "4450200",
    "end": "4458570"
  },
  {
    "text": "some horses can be confused for years as you can see and probably some dogs could be confused as cats and because you know",
    "start": "4458570",
    "end": "4465470"
  },
  {
    "text": "some of them are kind of similar right so all right well thank you very much",
    "start": "4465470",
    "end": "4473060"
  },
  {
    "text": "for sticking sticking around I hope you learned a lot and if you so you will get",
    "start": "4473060",
    "end": "4480230"
  },
  {
    "text": "the slides you should receive an email in the next in the next few days with a link if you don't",
    "start": "4480230",
    "end": "4487059"
  },
  {
    "text": "well just either connect on LinkedIn and ask me for the link Julie ASIMO iws",
    "start": "4487059",
    "end": "4494690"
  },
  {
    "text": "there's only one and/or ping me on Twitter and and just ask me for the link",
    "start": "4494690",
    "end": "4501320"
  },
  {
    "text": "okay happy to help and if you have questions later on just you know get in touch that's what I do as well right I just don't I don't only stand and give",
    "start": "4501320",
    "end": "4510409"
  },
  {
    "text": "silly examples and silly talks I also actually help people when they need me right all right thank you very much and",
    "start": "4510409",
    "end": "4516559"
  },
  {
    "text": "I hope you had a good day with us oh I sure had a good day thank you very much [Applause]",
    "start": "4516559",
    "end": "4523180"
  }
]
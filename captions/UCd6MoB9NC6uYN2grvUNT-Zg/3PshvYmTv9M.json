[
  {
    "start": "0",
    "end": "64000"
  },
  {
    "text": "good evening everyone I think it's evening it's always hard to tell in Vegas put in a nice dark room no windows",
    "start": "800",
    "end": "8429"
  },
  {
    "text": "my name is grant McCallister I'm a senior principal engineer work for AWS as you might have guessed from the logo",
    "start": "8429",
    "end": "14250"
  },
  {
    "text": "I work on RTS and most of the time I spend with the Postgres engines today what we're gonna do is we're gonna dive",
    "start": "14250",
    "end": "20220"
  },
  {
    "text": "into Aurora Postgres we're gonna look at the changes we've made why we made them",
    "start": "20220",
    "end": "25680"
  },
  {
    "text": "and why you might care about those well also talk about the things we've delivered in the last year four or",
    "start": "25680",
    "end": "31920"
  },
  {
    "text": "Postgres and how you migrate to it so one of the first things I wanted to talk about was RTS in general there's a lot",
    "start": "31920",
    "end": "39270"
  },
  {
    "text": "of confusion that Aurora is not part of RTS and it actually is it just has separate branding marketing folks wanted",
    "start": "39270",
    "end": "45360"
  },
  {
    "text": "to brand it separately but it's run under the same management platform that all seven of our engines or two aurora",
    "start": "45360",
    "end": "51360"
  },
  {
    "text": "engines are two commercial engines and are three other open-source engines so all these capabilities that you get from",
    "start": "51360",
    "end": "57300"
  },
  {
    "text": "a managed RDS system are true with aurora as well but because it's our engine we've made some other changes",
    "start": "57300",
    "end": "62699"
  },
  {
    "text": "right so from an RDS perspective we actually have two flavors of Postgres we have RDS",
    "start": "62699",
    "end": "69810"
  },
  {
    "text": "Postgres which is community Postgres with just a few small changes for security and it runs on ec2 runs on an",
    "start": "69810",
    "end": "76590"
  },
  {
    "text": "EBS volume right so this is pretty much standard the same way you would do it if you were just running an ec2 on the",
    "start": "76590",
    "end": "82170"
  },
  {
    "text": "other side what we have is Aurora Postgres and this is quite a bit different because of the storage so we have Aurora storage and so this is",
    "start": "82170",
    "end": "88259"
  },
  {
    "text": "database aware storage so that's fundamentally different than a block store and I'll get into what those",
    "start": "88259",
    "end": "95070"
  },
  {
    "text": "changes mean for you running your application but the cool thing from your perspective if you have a client you",
    "start": "95070",
    "end": "100320"
  },
  {
    "text": "want to connect to either one of these it's gonna work exactly the same they talk the same protocol if whether you're",
    "start": "100320",
    "end": "105600"
  },
  {
    "text": "connecting with P sequel ODBC JDBC whatever it's gonna look exactly the same same objects same commands and just",
    "start": "105600",
    "end": "112740"
  },
  {
    "text": "to run through like in more detail you can see that we support POSIX grass nine six and ten for both of these engines we",
    "start": "112740",
    "end": "119909"
  },
  {
    "text": "have the same extensions on both of them we have the same backup recovery and p ITR capabilities we have a high",
    "start": "119909",
    "end": "126240"
  },
  {
    "text": "availability and durability story for both these engines we they're both secure by default and actually this is",
    "start": "126240",
    "end": "131700"
  },
  {
    "text": "one of the cool new features that we've just released which is our I am or identity and access management ability to use those credentials to log",
    "start": "131700",
    "end": "138659"
  },
  {
    "text": "into your database so you don't have to have passwords anymore so that's a really nice feature on both of these engines they both support read replicas",
    "start": "138659",
    "end": "145079"
  },
  {
    "text": "they both support cross region snapshots and scale compute and online scale storage now the storage on the RDS one",
    "start": "145079",
    "end": "152970"
  },
  {
    "text": "is up to thirty two terabytes 64 terabytes on Aurora there's two features that we're still working on to get to",
    "start": "152970",
    "end": "158489"
  },
  {
    "text": "parity one of them is cross region replication and the other is outbound logical and I'll talk more about those in presentation I want to highlight that",
    "start": "158489",
    "end": "165989"
  },
  {
    "text": "right now the max version that we support is version 10 for both these engines but for RDS Postgres we have a",
    "start": "165989",
    "end": "171870"
  },
  {
    "text": "preview region where we have version 11 and 11 0 in it and we're rapidly working",
    "start": "171870",
    "end": "177450"
  },
  {
    "text": "on getting 11 for Aurora as well so that's coming so let's start with one of",
    "start": "177450",
    "end": "184680"
  },
  {
    "start": "182000",
    "end": "288000"
  },
  {
    "text": "the fundamental differences this is log based storage and so because of that",
    "start": "184680",
    "end": "189720"
  },
  {
    "text": "there's a lot of fundamentals that change with how Aurora works so the first one is that we have no log buffer",
    "start": "189720",
    "end": "195269"
  },
  {
    "text": "and to explain that I'm going to walk through what happens on Postgres and Aurora Postgres so the queued work there",
    "start": "195269",
    "end": "200970"
  },
  {
    "text": "in the red those eight blocks you can think of them as eight commits for example that have happened on different sessions so they're already everybody",
    "start": "200970",
    "end": "207359"
  },
  {
    "text": "hits commit at once modern databases have this really nice feature group commit so they can all go into the log buffer at the same time but one of the",
    "start": "207359",
    "end": "215250"
  },
  {
    "text": "problems with the log buffer is once it's getting ready to flush nothing else can go into it right so if more acute",
    "start": "215250",
    "end": "221579"
  },
  {
    "text": "work comes in it's got to wait until that log buffer gets flushed down to storage and acknowledged right and then",
    "start": "221579",
    "end": "227519"
  },
  {
    "text": "the queued work can go so you can see how this is a single point of bottlenecking right now on Aurora it's",
    "start": "227519",
    "end": "233639"
  },
  {
    "text": "quite different when the transactions come in they just flow down to the storage as they're happening right and",
    "start": "233639",
    "end": "239609"
  },
  {
    "text": "so it's an ordered system and you want it to be durable so we actually have to keep track of these things so we have",
    "start": "239609",
    "end": "246090"
  },
  {
    "text": "what I like to call durability tracking so we use a 406 quorum in Aurora so means we need four acknowledgments from",
    "start": "246090",
    "end": "252750"
  },
  {
    "text": "our storage system to say we're good right so we keep track of these and I'm illustrating that we're you know after a",
    "start": "252750",
    "end": "259739"
  },
  {
    "text": "tiny a little bit of time we've got a couple of them in two places some of them in 0 some of them 1 and then",
    "start": "259739",
    "end": "264840"
  },
  {
    "text": "finally we get a 2/4 right so then you would I knowledge that commits back to the client but you'll notice that C is also",
    "start": "264840",
    "end": "271020"
  },
  {
    "text": "at four well we're good right we should be able to mark that one durable but this is an order database right and",
    "start": "271020",
    "end": "276150"
  },
  {
    "text": "because B happened before C we need it to get to for durability as well before we can actually mark C as durable so you",
    "start": "276150",
    "end": "283080"
  },
  {
    "text": "know and you can see the same thing is happening with either where we have to wait for D to get committed so the other",
    "start": "283080",
    "end": "289500"
  },
  {
    "start": "288000",
    "end": "420000"
  },
  {
    "text": "thing with Aurora is we write a lot less let's walk through the differences so on Postgres if you have a tuple you know",
    "start": "289500",
    "end": "297330"
  },
  {
    "text": "just a row in your heat block that's what I'm showing that block in memory and you go do an update well an update",
    "start": "297330",
    "end": "303810"
  },
  {
    "text": "in Postgres is essentially a delete and insert right so you end up touching both of those tuples and those are gonna get",
    "start": "303810",
    "end": "309660"
  },
  {
    "text": "logged to the wall right so this is for crash durability but you'll notice something else showed up there right a",
    "start": "309660",
    "end": "314790"
  },
  {
    "text": "full block why did I get a full copy of the block in the log well this is for",
    "start": "314790",
    "end": "320250"
  },
  {
    "text": "another form of crash recovery and I'll talk about why we do that now we only do",
    "start": "320250",
    "end": "325740"
  },
  {
    "text": "that the first time you touch the block after a checkpoint so if I go and do another thing like update the tuple",
    "start": "325740",
    "end": "331260"
  },
  {
    "text": "again or insert a new row that's just gonna get just the log vector is gonna",
    "start": "331260",
    "end": "336810"
  },
  {
    "text": "go into the storage right so this is all normal Postgres at some point you want a",
    "start": "336810",
    "end": "342480"
  },
  {
    "text": "checkpoint right you want to make that block durable on disk right so you don't need the recovery log anymore and the",
    "start": "342480",
    "end": "348180"
  },
  {
    "text": "wall has to be archived and that archive has to be copied s3 so it's backed up and then we take snapshots of the data",
    "start": "348180",
    "end": "353460"
  },
  {
    "text": "file right but when you do a checkpoint it's actually not just a single write write in Postgres the default block size",
    "start": "353460",
    "end": "359910"
  },
  {
    "text": "is a K but for example Linux which is what we run on is 4k iOS so if you're in",
    "start": "359910",
    "end": "364979"
  },
  {
    "text": "the middle of doing that checkpoint and guess what the system crashes you might have only got half of that right to disk",
    "start": "364979",
    "end": "370050"
  },
  {
    "text": "guess what would happen some point later you'd find out you have a crop block right so Postgres handles this by taking",
    "start": "370050",
    "end": "375870"
  },
  {
    "text": "that full block and during crash recovery using it to repair this split block right this works great it's been",
    "start": "375870",
    "end": "382560"
  },
  {
    "text": "used for a long time but it involves a lot of writing on the Aurora side it's",
    "start": "382560",
    "end": "387570"
  },
  {
    "text": "quite different we have no checkpoint no full-page writes so when we do the update we get the same thing happening",
    "start": "387570",
    "end": "394410"
  },
  {
    "text": "the two tuples changed we eject those log vectors to storage and that's it",
    "start": "394410",
    "end": "399419"
  },
  {
    "text": "right if we do another one so there's no full blocks there's no check pointing there's no writing of",
    "start": "399419",
    "end": "404819"
  },
  {
    "text": "data blocks right we only write log vectors so we back this up continuously from Aurora storage to s3 so that's how",
    "start": "404819",
    "end": "412559"
  },
  {
    "text": "we get you point in time durability for recovery and again no checkpoints no",
    "start": "412559",
    "end": "418680"
  },
  {
    "text": "full-page writes so you're saying well how does this all magically happen well we have this",
    "start": "418680",
    "end": "423809"
  },
  {
    "start": "420000",
    "end": "511000"
  },
  {
    "text": "really intelligent storage layer right and this is comprised of a lot of different storage servers in the backend and I'm just illustrating one of them",
    "start": "423809",
    "end": "430680"
  },
  {
    "text": "here so if you have a read write note and it doesn't update that log vector is gonna flow into the incoming queue and",
    "start": "430680",
    "end": "436860"
  },
  {
    "text": "this is an in-memory queue once it's there and then gets processed into the update queue which is basically the",
    "start": "436860",
    "end": "442710"
  },
  {
    "text": "durable form on disk once that's done we can actually acknowledge back to the client you know one of the one of the",
    "start": "442710",
    "end": "449219"
  },
  {
    "text": "nodes is acknowledged right so the interesting thing here is this is the only synchronous thing that happens all",
    "start": "449219",
    "end": "454620"
  },
  {
    "text": "the other things I'm going to show you our background pieces right so at this point that vector will go into the hot",
    "start": "454620",
    "end": "461490"
  },
  {
    "text": "log which can be used for a peer-to-peer gossips and we also do coalescing of the block right so we read blocks so we",
    "start": "461490",
    "end": "469949"
  },
  {
    "text": "actually have to apply the log vectors so you can think of this happening on a block by block basis that we're essentially doing recovery continuously",
    "start": "469949",
    "end": "476339"
  },
  {
    "text": "right so as I said the peer-to-peer storage we do repair via these logs and",
    "start": "476339",
    "end": "481860"
  },
  {
    "text": "then we also push both the log vectors and the blocks out to s3 so that you can have a point in time to any point you",
    "start": "481860",
    "end": "487740"
  },
  {
    "text": "want within 35 days so again when you read you don't read log vectors you got",
    "start": "487740",
    "end": "493259"
  },
  {
    "text": "to read a block right that's how post rest works so if the block has been coalesced then that's what you read if",
    "start": "493259",
    "end": "499439"
  },
  {
    "text": "it hasn't then we do an on-the-fly coalesce and coalesce whatever log changes we need to make a block right so",
    "start": "499439",
    "end": "506399"
  },
  {
    "text": "you never have a long crash recovery with Aurora because we're doing this continuously to kind of show what this",
    "start": "506399",
    "end": "512610"
  },
  {
    "start": "511000",
    "end": "536000"
  },
  {
    "text": "looks like in practice I created a little test I do an insert test I built a table with nine columns",
    "start": "512610",
    "end": "518159"
  },
  {
    "text": "they're all different kinds some are random some are right-leaning different object types and then I indexed every",
    "start": "518159",
    "end": "523500"
  },
  {
    "text": "column now that's not normal right but it is normal to have a lot of indexes on a big table I mean I've had tables I've",
    "start": "523500",
    "end": "530519"
  },
  {
    "text": "seen tables that have 75 indexes on two or three-hundred columns right so this isn't really on you",
    "start": "530519",
    "end": "536300"
  },
  {
    "start": "536000",
    "end": "623000"
  },
  {
    "text": "so when we go run that insert work load vertical axis is inserts per second and",
    "start": "536300",
    "end": "541860"
  },
  {
    "text": "so you know figure is better right the blue line is sort of regular Postgres right and we see that we get like 25,000",
    "start": "541860",
    "end": "549750"
  },
  {
    "text": "writes per store inserts per second right off the bat it's pretty good right but it drops really quickly and the",
    "start": "549750",
    "end": "555330"
  },
  {
    "text": "reason for that is as the database gets larger as you've inserted more data you have more blocks right and your indexes",
    "start": "555330",
    "end": "562140"
  },
  {
    "text": "get larger so the chance that you're touching a block between checkpoints gets higher and so that full-page writes",
    "start": "562140",
    "end": "568890"
  },
  {
    "text": "increase increase increase as your database gets larger so your performance basically slowly goes down so if your",
    "start": "568890",
    "end": "576030"
  },
  {
    "text": "DBA you say well I can fix that I can make my checkpoints longer right I'll just increase the max wall segments and",
    "start": "576030",
    "end": "581460"
  },
  {
    "text": "so that's what I did in the purple line right and you can see that help for about 20 minutes but then the database got large enough",
    "start": "581460",
    "end": "587760"
  },
  {
    "text": "that again we started getting full page rights and we see this degradation of performance right will notice on the",
    "start": "587760",
    "end": "593640"
  },
  {
    "text": "yellow line there is that this is Aurora we don't have checkpoints we don't have full page rights so we have very stable",
    "start": "593640",
    "end": "599610"
  },
  {
    "text": "performance even as the database grows and grows right so not only do we have stable performance but we have better",
    "start": "599610",
    "end": "605070"
  },
  {
    "text": "performance right and this is the same if we do updates I did the same test same tables updated to columns and you",
    "start": "605070",
    "end": "612480"
  },
  {
    "text": "can see we're getting about three times the performance with Aurora that we were with even tuned Postgres and again this",
    "start": "612480",
    "end": "618630"
  },
  {
    "text": "is because we don't have a log buffer we don't that single point of contention we don't full-page writes so the other",
    "start": "618630",
    "end": "624840"
  },
  {
    "start": "623000",
    "end": "713000"
  },
  {
    "text": "critical thing about writing more is that you don't necessarily want to take a long time to crash recover which is",
    "start": "624840",
    "end": "630780"
  },
  {
    "text": "very typical for most databases to illustrate this I have a chart where the vertical axis is recovery time you'd like that to be low and then the",
    "start": "630780",
    "end": "637470"
  },
  {
    "text": "horizontal axis is writes per second you want that to be high so you want that to be far down the range so when we start",
    "start": "637470",
    "end": "643530"
  },
  {
    "text": "pushing post grass what we see is that as we start we got like three gig of",
    "start": "643530",
    "end": "648870"
  },
  {
    "text": "redo generated on the first arrow right we're doing about 18,000 TPS it's not",
    "start": "648870",
    "end": "654510"
  },
  {
    "text": "bad but as I add more clients to push the database harder guess what my recovery time goes up by quite a bit to",
    "start": "654510",
    "end": "661950"
  },
  {
    "text": "50 seconds and I've only doubled my throughput so if I keep pushing the database what you see up here we're",
    "start": "661950",
    "end": "668010"
  },
  {
    "text": "generating 30 gig between checkpoints and my recovery time is taking over two minutes right this is",
    "start": "668010",
    "end": "673919"
  },
  {
    "text": "a dramatic increase and so this has always been one of the trade-offs with most relational databases is you had to make you had to say what I like to be",
    "start": "673919",
    "end": "679829"
  },
  {
    "text": "able to write really fast or what I like to have low crash recovery so can you guys see that little dot out to the far",
    "start": "679829",
    "end": "685259"
  },
  {
    "text": "right it's really hard to see so I circled it for you that's Aurora so reward it does",
    "start": "685259",
    "end": "693809"
  },
  {
    "text": "continuous recovery right so we don't actually have to do crash recovery so it takes three seconds for roar to come back up in this case but you'll also see",
    "start": "693809",
    "end": "700829"
  },
  {
    "text": "we're doing dramatically more writes like 3x right compared to a Postgres",
    "start": "700829",
    "end": "706379"
  },
  {
    "text": "even at the largest scale so this is one of the nice things with Aurora you don't actually have to make this trade-off of these two different capabilities so",
    "start": "706379",
    "end": "714659"
  },
  {
    "start": "713000",
    "end": "891000"
  },
  {
    "text": "let's talk more about the base architecture of Aurora Postgres so I'm demonstrating or showing here three",
    "start": "714659",
    "end": "720269"
  },
  {
    "text": "availability zones that's very typical for our regions and the blue block is essentially Aurora storage you want to",
    "start": "720269",
    "end": "726389"
  },
  {
    "text": "think of it sort of virtually right it's across all the availability zones the little blue ones inside of those are",
    "start": "726389",
    "end": "731999"
  },
  {
    "text": "individual storage servers now I'm just showing six in each one but usually there's hundreds or thousands right when",
    "start": "731999",
    "end": "737429"
  },
  {
    "text": "you go and provision an application and you say I want a database Aurora Postgres what's gonna happen is we're",
    "start": "737429",
    "end": "743189"
  },
  {
    "text": "gonna go take ten gig chunk segments and put them on these storage servers right and that's what I'm illustrating with",
    "start": "743189",
    "end": "749129"
  },
  {
    "text": "the six different colors because we get six copies right so you can have you can",
    "start": "749129",
    "end": "754529"
  },
  {
    "text": "connect applications from multiple AZ's that's always a good idea for availability when we do writes again we",
    "start": "754529",
    "end": "759929"
  },
  {
    "text": "write log records right so they're gonna get written to all six places we only need four of them to get a commit done",
    "start": "759929",
    "end": "765359"
  },
  {
    "text": "but you'll see that though all the different colors are involved right when we read we read blocks back and",
    "start": "765359",
    "end": "771569"
  },
  {
    "text": "typically we're gonna read from the local a-z because it's gonna be fastest but we actually do that on a periodic",
    "start": "771569",
    "end": "776819"
  },
  {
    "text": "basis to see which one's going to be faster so we don't have to do a quorum read or anything you know crazy like",
    "start": "776819",
    "end": "781829"
  },
  {
    "text": "that that's gonna take a long time so sometimes you actually have problems",
    "start": "781829",
    "end": "787559"
  },
  {
    "text": "with getting quorum right sometimes two of those rights may not show up so what",
    "start": "787559",
    "end": "793229"
  },
  {
    "text": "do we do then well we can actually do repair as I said peer-to-peer gossip between the different nodes and they'll",
    "start": "793229",
    "end": "799349"
  },
  {
    "text": "actually send the missing log records to the other node right in the case of a failure of a whole node",
    "start": "799349",
    "end": "805230"
  },
  {
    "text": "will actually make a copy of that segment on to a different node right we'll also do this for hotspot",
    "start": "805230",
    "end": "811080"
  },
  {
    "text": "management so if you're pushing hard will actually move things around so there's enough resources on that node",
    "start": "811080",
    "end": "816210"
  },
  {
    "text": "stuff you don't actually have to worry about so the other thing that's really cool about aurora is that there's",
    "start": "816210",
    "end": "821970"
  },
  {
    "text": "read-only nodes and the difference between sort of regular Postgres is when you make a read-only node you have to",
    "start": "821970",
    "end": "827460"
  },
  {
    "text": "copy the data but here you don't because the storage is shared right and so what I call clustered storage right so as",
    "start": "827460",
    "end": "834750"
  },
  {
    "text": "soon as you fire it up you can read the data out of that storage you don't have to make a copy now you'll notice that little sort of purple line going between",
    "start": "834750",
    "end": "841170"
  },
  {
    "text": "the readwrite node and the read-only node we do communicate we do send information from the readwrite node to",
    "start": "841170",
    "end": "846960"
  },
  {
    "text": "the read-only node but we only do to invalidate things in cache we don't actually have to send it over so it can be written and you can have more than",
    "start": "846960",
    "end": "854430"
  },
  {
    "text": "one read-only node in fact you can have up to 50 you can have a lot right and so you can have different applications",
    "start": "854430",
    "end": "859890"
  },
  {
    "text": "using different read-only nodes for different purposes now the big thing",
    "start": "859890",
    "end": "864960"
  },
  {
    "text": "about having multiple nodes is that in the case of a failure what's really nice is the good thing is your data is",
    "start": "864960",
    "end": "870090"
  },
  {
    "text": "durable no matter what right so you don't actually have to worry about data durability for having extra nodes but if you want a fast failover you want to",
    "start": "870090",
    "end": "876480"
  },
  {
    "text": "have a note so what we're gonna do is we're gonna promote one of your read-only nodes to a readwrite node and it's gonna start being able to write so",
    "start": "876480",
    "end": "882450"
  },
  {
    "text": "this this happens in typically about 3035 seconds with including the DNS propagation and you can actually connect",
    "start": "882450",
    "end": "888810"
  },
  {
    "text": "to all the nodes so you don't actually have to wait for DNS propagation so let's talk a little bit about why we",
    "start": "888810",
    "end": "894120"
  },
  {
    "start": "891000",
    "end": "1022000"
  },
  {
    "text": "picked 406 quorum so when we started RDS backed like almost ten years ago we we",
    "start": "894120",
    "end": "901380"
  },
  {
    "text": "knew that we probably want to do some form of durability but when you first released it it was basically just a single azy product right so when you",
    "start": "901380",
    "end": "908670"
  },
  {
    "text": "would do a commit you're basically gonna write to EBS and get a response back but it's actually a little more complicated than that because EBS behind the scenes",
    "start": "908670",
    "end": "915480"
  },
  {
    "text": "actually has two machines right it's mirroring your data so when you're writing you're actually writing to the first machine then you're writing to the",
    "start": "915480",
    "end": "922200"
  },
  {
    "text": "saut writing to the second machine getting acknowledgment back and all the way back to your server right and at that point you're good you're committed",
    "start": "922200",
    "end": "928370"
  },
  {
    "text": "but guess what this only works if you don't have a problem in that AZ right so",
    "start": "928370",
    "end": "934680"
  },
  {
    "text": "this is where you want to have a Daisie solution that actually replicates the data synchronously so we actually",
    "start": "934680",
    "end": "940020"
  },
  {
    "text": "looked at having one or two different you know two or three copies so first we",
    "start": "940020",
    "end": "945810"
  },
  {
    "text": "said well okay let's look at just having a secondary or maybe having a tertiary so we actually played with having you",
    "start": "945810",
    "end": "951210"
  },
  {
    "text": "know multiple copies so just illustrate what happens when you have three locations you basically do that commit",
    "start": "951210",
    "end": "956580"
  },
  {
    "text": "and you send out rights and the read rights are the remote ones so the look the black ones are local so the red ones",
    "start": "956580",
    "end": "963060"
  },
  {
    "text": "are going to be slower and in some cases your a Z's are farther apart right so the rights take longer to happen",
    "start": "963060",
    "end": "968880"
  },
  {
    "text": "so as we're progressing you'll see that the local copy is actually moving along quite well and the remote ones are just",
    "start": "968880",
    "end": "974520"
  },
  {
    "text": "getting started right so at this point you've got basically two of them done",
    "start": "974520",
    "end": "980130"
  },
  {
    "text": "right but you have to wait for the third one if it's synchronous replication so we got to wait for a couple more you know maybe milliseconds for this to",
    "start": "980130",
    "end": "986340"
  },
  {
    "text": "finally finish now the other thing with this kind of replication is the more copies you have the more chance you can",
    "start": "986340",
    "end": "992670"
  },
  {
    "text": "have for one of them not to respond right so if this last right doesn't actually come back you never get that",
    "start": "992670",
    "end": "997860"
  },
  {
    "text": "acknowledgement at some point you time it out right and at that point you actually have to fence the system to figure out who's the live nodes and so",
    "start": "997860",
    "end": "1004940"
  },
  {
    "text": "you'd be like oh well the primary and secondary are still alive we'll leave them in the you know sort of group and we'll kick out the tertiary when the",
    "start": "1004940",
    "end": "1012050"
  },
  {
    "text": "tertiary comes back it actually has to catch up all the stuff that was missing right it's not just one right that you",
    "start": "1012050",
    "end": "1018260"
  },
  {
    "text": "skip it's all of them right and this is quite different on our world so we did a bunch of testing and these are numbers",
    "start": "1018260",
    "end": "1024890"
  },
  {
    "start": "1022000",
    "end": "1070000"
  },
  {
    "text": "from quite a while ago EBS has gotten quite a bit faster and network latency has gotten better but this is just to illustrate sort of the",
    "start": "1024890",
    "end": "1031430"
  },
  {
    "text": "difference when you have two nodes and four copies or three nodes and six copies so the blue is the two nodes the",
    "start": "1031430",
    "end": "1037490"
  },
  {
    "text": "green is the three so latency on the vertical axis you'd like it to be lower so the 50th percentile writes you can",
    "start": "1037490",
    "end": "1042949"
  },
  {
    "text": "see that really there's not a lot of difference it's six to seven milliseconds right you're like hey that doesn't seem expensive I love this give",
    "start": "1042950",
    "end": "1048470"
  },
  {
    "text": "me three copies right but the problem occurs when you start looking at like the four nines percentile like this is",
    "start": "1048470",
    "end": "1054320"
  },
  {
    "text": "only one in 10,000 iOS but the difference is basically 4x on going to",
    "start": "1054320",
    "end": "1061010"
  },
  {
    "text": "the third copy and that's because you have more jitter in a system when you have more copies right so we looked at",
    "start": "1061010",
    "end": "1066020"
  },
  {
    "text": "this and in the end we said now we're just going to do two-way multi easy for Stan yes but when it came to Aurora we",
    "start": "1066020",
    "end": "1072230"
  },
  {
    "start": "1070000",
    "end": "1129000"
  },
  {
    "text": "thought we can do better because we have a different storage system so what you'll notice here is I have my three",
    "start": "1072230",
    "end": "1077540"
  },
  {
    "text": "availability zones again and I have my primary but you'll notice I don't have a tertiary or you know secondary node",
    "start": "1077540",
    "end": "1083210"
  },
  {
    "text": "because I don't need those right my my storage is my durability so when I do",
    "start": "1083210",
    "end": "1088760"
  },
  {
    "text": "commit on Aurora essentially we're gonna send out six simultaneous write requests and they're gonna go out to all the",
    "start": "1088760",
    "end": "1095570"
  },
  {
    "text": "storage nodes and then they're gonna start getting responses back and as soon as we get the first four back you'll notice we're able to come in so if these",
    "start": "1095570",
    "end": "1103610"
  },
  {
    "text": "other two never show up that's okay because we'll do peer-to-peer replication to catch up but if they just",
    "start": "1103610",
    "end": "1110480"
  },
  {
    "text": "miss one right we don't stop writing to that node right we'll just be behind that one little transaction and it'll",
    "start": "1110480",
    "end": "1117140"
  },
  {
    "text": "get fixed by one of the other replicas right or storage notes to be clear so this is quite good that we don't",
    "start": "1117140",
    "end": "1122900"
  },
  {
    "text": "actually have this really coarse model right it's a very granular system of",
    "start": "1122900",
    "end": "1128180"
  },
  {
    "text": "repair so what does this result in this results in much better latency so this",
    "start": "1128180",
    "end": "1134270"
  },
  {
    "start": "1129000",
    "end": "1193000"
  },
  {
    "text": "is suspense the p95 response time right this is a thousand clients so this is a",
    "start": "1134270",
    "end": "1139490"
  },
  {
    "text": "high skill workload and we've got a 30 gig working set so the blue line is RDS",
    "start": "1139490",
    "end": "1146000"
  },
  {
    "text": "Postgres single lazy no backups the yellow line is Aurora and what you can see is that Aurora is very consistent",
    "start": "1146000",
    "end": "1152480"
  },
  {
    "text": "right over time it's very good it doesn't have a lot of variability now the blue is all over the place",
    "start": "1152480",
    "end": "1158450"
  },
  {
    "text": "can anyone guess what that these blue kind of sections are where it goes up and down like that",
    "start": "1158450",
    "end": "1163900"
  },
  {
    "text": "that's checkpoints exactly correct right so what's happening here on regular Postgres is the checkpoints are",
    "start": "1163900",
    "end": "1170360"
  },
  {
    "text": "basically fighting for the iOS with that log buffer being flushed right so at the",
    "start": "1170360",
    "end": "1175670"
  },
  {
    "text": "bottom of the graph it's pretty good that's when it's not check pointing and the you know it's pretty good but you'll",
    "start": "1175670",
    "end": "1180830"
  },
  {
    "text": "also notice this is single a Z we're not actually durable here across multiple a Z's this is actually not even a really a",
    "start": "1180830",
    "end": "1186920"
  },
  {
    "text": "good fair comparison because if you made this multi Z the blue line would be even higher right so let's talk a little bit",
    "start": "1186920",
    "end": "1194990"
  },
  {
    "start": "1193000",
    "end": "1321000"
  },
  {
    "text": "more about what we do for a replication and a cool feature called clones so",
    "start": "1194990",
    "end": "1203510"
  },
  {
    "text": "in Postgres RTS Postgres if you asked for a replica we're gonna basically take",
    "start": "1203510",
    "end": "1208820"
  },
  {
    "text": "a snapshot of the EBS volume we're gonna restore that EBS volume then we're gonna fire up a read-only ec2 instance on it",
    "start": "1208820",
    "end": "1216200"
  },
  {
    "text": "and great but you still have to catch up from that all happening right and that takes a bit of time on a really high",
    "start": "1216200",
    "end": "1221779"
  },
  {
    "text": "right workload this could take an hour or two for it to catch up once it's all caught up if you do an update",
    "start": "1221779",
    "end": "1227529"
  },
  {
    "text": "essentially what you're gonna do is you're gonna write to EBS you're gonna get that response back so that's all",
    "start": "1227529",
    "end": "1233480"
  },
  {
    "text": "good and at the same time you're sending an asynchronous request across to the read-only node now it might actually have to read that block into memory",
    "start": "1233480",
    "end": "1239870"
  },
  {
    "text": "before I can write it out again so that's a lot of work that has to happen on Aurora this is quite different we",
    "start": "1239870",
    "end": "1246350"
  },
  {
    "text": "have just a rar storage so when you want to read only node BAM we just pop one up it takes a couple minutes right because",
    "start": "1246350",
    "end": "1252289"
  },
  {
    "text": "it's just firing up an ec2 instance and attaching it to the storage when you do an update on Aurora that same thing has",
    "start": "1252289",
    "end": "1259159"
  },
  {
    "text": "to happen we write to storage right and we have the asynchronous replication going across but it's just doing it for",
    "start": "1259159",
    "end": "1264710"
  },
  {
    "text": "anything in memory so it's only updating the blocks in memory and it doesn't have to write on the other side because the",
    "start": "1264710",
    "end": "1270950"
  },
  {
    "text": "data is in the storage right it's shared so I wanted to show this and I thought",
    "start": "1270950",
    "end": "1276740"
  },
  {
    "text": "well I'll use PG bench and it has a read write mode in a read-only mode so I was gonna run the readwrite node with the",
    "start": "1276740",
    "end": "1282620"
  },
  {
    "text": "read or the write workload and on the read-only node already read from it so there's four tables they all get",
    "start": "1282620",
    "end": "1290210"
  },
  {
    "text": "modified on the readwrite workload on the select only workload it's only the accounts table it gets read so you start",
    "start": "1290210",
    "end": "1296690"
  },
  {
    "text": "off post press it looks like this but then as soon as you start doing asynchronous requests guess what that node actually has to load those other",
    "start": "1296690",
    "end": "1303080"
  },
  {
    "text": "tables into memory because it's got to be able to apply the changes to those tables as they happen in Aurora this is",
    "start": "1303080",
    "end": "1309049"
  },
  {
    "text": "quite different in that we're only doing this stuff in memory so the accounts table is the only one that ever gets",
    "start": "1309049",
    "end": "1314059"
  },
  {
    "text": "touched because it's being read by the the select only benchmark so this is actually really important for what",
    "start": "1314059",
    "end": "1319490"
  },
  {
    "text": "happens about replication lag to illustrate that I took a replica I'm running 8000 TPS writes on the primary",
    "start": "1319490",
    "end": "1327649"
  },
  {
    "start": "1321000",
    "end": "1433000"
  },
  {
    "text": "and on the read-only note I'm doing 200,000 read-only requests right so it's pretty impressive and this is stock",
    "start": "1327649",
    "end": "1334789"
  },
  {
    "text": "Postgres right RDS Postgres this is the cloud watch metrics from the replica and you'll notice sort of the",
    "start": "1334789",
    "end": "1340700"
  },
  {
    "text": "thin orange line is the rights that are happening so it's going along quite well and then where the big arrow is I did a",
    "start": "1340700",
    "end": "1348310"
  },
  {
    "text": "really not nice thing to my database I back filled the whole PG bench history table I have dated every row right in",
    "start": "1348310",
    "end": "1354140"
  },
  {
    "text": "one transaction so that's not something you'd like to see but guess what it happens in production where people need",
    "start": "1354140",
    "end": "1359210"
  },
  {
    "text": "to do backfill right what you'll notice is the green line so the Green Line is the replication delay in seconds and so",
    "start": "1359210",
    "end": "1366260"
  },
  {
    "text": "the reason people ask me why is it in seconds well when we first started RDS it was my sequel my sequel had kind of",
    "start": "1366260",
    "end": "1372410"
  },
  {
    "text": "poor replication and we you know the lag was always in many seconds and so we said seconds is a fine number to use as",
    "start": "1372410",
    "end": "1379610"
  },
  {
    "text": "granularity nowadays for Postgres is not really applicable but we haven't gone back to fix this yet so as soon as I do",
    "start": "1379610",
    "end": "1385880"
  },
  {
    "text": "this backfill what happens is that thing is essentially like a snake trying to eat a watermelon right it's got to go",
    "start": "1385880",
    "end": "1391970"
  },
  {
    "text": "through the whole system and it clogs it up and what you start to see at that red arrow is that we're losing 30 seconds",
    "start": "1391970",
    "end": "1398120"
  },
  {
    "text": "for every wall clock minute of replication delay and after 19 minutes were 10 minutes behind on this replica",
    "start": "1398120",
    "end": "1404690"
  },
  {
    "text": "but you'll also notice another thing that blue line starts to pick up about halfway through and it's doing a lot of",
    "start": "1404690",
    "end": "1410600"
  },
  {
    "text": "reads on the replica why is it doing that well because it didn't have all the PG bench history in",
    "start": "1410600",
    "end": "1416260"
  },
  {
    "text": "RAM so it actually had to start loading it off disk which slows the replication down even more and now we're losing",
    "start": "1416260",
    "end": "1422570"
  },
  {
    "text": "almost 40 seconds for every wall clock minute right so this is how on a regular RTS Postgres instance you can actually",
    "start": "1422570",
    "end": "1428990"
  },
  {
    "text": "have a lot of replication problems if you do things like backfills or have any other issues this is the same benchmark",
    "start": "1428990",
    "end": "1434870"
  },
  {
    "start": "1433000",
    "end": "1460000"
  },
  {
    "text": "running on Ororo so the big difference is we use milliseconds for our latency",
    "start": "1434870",
    "end": "1440540"
  },
  {
    "text": "for a replication lag and if I didn't have the red arrow there would you be able to tell where I did the backfill",
    "start": "1440540",
    "end": "1446780"
  },
  {
    "text": "you wouldn't right because the replication lag basically didn't change because I'm back filling a table that",
    "start": "1446780",
    "end": "1452660"
  },
  {
    "text": "it's gonna send those rights over and then it's gonna find that they're not in memory and not do anything with them so there's no update that happens the other",
    "start": "1452660",
    "end": "1461360"
  },
  {
    "start": "1460000",
    "end": "1577000"
  },
  {
    "text": "really cool feature that we launched in the last year it's called fast clones so I'm illustrating sort of the same setup",
    "start": "1461360",
    "end": "1467330"
  },
  {
    "text": "we've had before I've just kind of changed the storage to look a little different where I have blah instead of the storage nodes just illustrate some of the concepts here so",
    "start": "1467330",
    "end": "1474290"
  },
  {
    "text": "let's say your business wants to do a lot of reporting but they want the data frozen at midnight well you could do a",
    "start": "1474290",
    "end": "1480890"
  },
  {
    "text": "point-in-time recovery fire that up I'd be great but you have to you know allocate all that storage",
    "start": "1480890",
    "end": "1486020"
  },
  {
    "text": "let's say it's 20 terabytes instead what you can do you can have your reporting application create a clone and so this",
    "start": "1486020",
    "end": "1492830"
  },
  {
    "text": "is a really cool thing in that you get clone storage what do I mean by clone storage well clone storage doesn't",
    "start": "1492830",
    "end": "1498770"
  },
  {
    "text": "actually exist all it is is pointers to the primary storage to start with so if you clone a twenty terabyte database",
    "start": "1498770",
    "end": "1504740"
  },
  {
    "text": "you're not paying for 20 terabytes of storage you're paying for nothing until you modify it so in actuality what",
    "start": "1504740",
    "end": "1511429"
  },
  {
    "text": "happens with when you start actually running your application here is when you do a read it's gonna go find the",
    "start": "1511429",
    "end": "1517790"
  },
  {
    "text": "address in the clone storage but it's actually gonna go read from the primary storage right so you don't actually have to duplicate it so that works but what",
    "start": "1517790",
    "end": "1525200"
  },
  {
    "text": "happens when I try to do a write I don't want to modify the primary storage so we do copy-on-write at that point so before",
    "start": "1525200",
    "end": "1531020"
  },
  {
    "text": "the block is modified it gets copied down to the clone storage right and we basically unlink the relationship",
    "start": "1531020",
    "end": "1536150"
  },
  {
    "text": "between those two blocks you can create new blocks they're just gonna go in your clone stores and there's no relationship",
    "start": "1536150",
    "end": "1541400"
  },
  {
    "text": "to the primary storage there when the original rewrite master basically writes",
    "start": "1541400",
    "end": "1546919"
  },
  {
    "text": "a log record you'll see that it only updates the primary storage it doesn't actually make changes to the clone",
    "start": "1546919",
    "end": "1552290"
  },
  {
    "text": "storage because they're separated at the time you clone right it's not any kind of lagging updates or anything and when",
    "start": "1552290",
    "end": "1559760"
  },
  {
    "text": "the read write node modifies the current block that's shared by both of them basically we do that same copy-on-write",
    "start": "1559760",
    "end": "1564860"
  },
  {
    "text": "in Reverse and you know give the new block two or new block for the primer the old block goes to the clone storage",
    "start": "1564860",
    "end": "1570770"
  },
  {
    "text": "right so this is a fantastic tool for using for reporting for testing for benchmarking to illustrate this I ran a",
    "start": "1570770",
    "end": "1578750"
  },
  {
    "start": "1577000",
    "end": "1636000"
  },
  {
    "text": "PG bench readwrite benchmark and I set a target rate of 10 or 20,000 TPS and it's",
    "start": "1578750",
    "end": "1585980"
  },
  {
    "text": "a 10,000 row or 10 scale 10k sorry which results in about 150 gig so one of the",
    "start": "1585980",
    "end": "1593450"
  },
  {
    "text": "things that people ask me is well this clone stuff sounds great but does it impact my performance so I'm running along on purple right that's my primary",
    "start": "1593450",
    "end": "1600049"
  },
  {
    "text": "that I started and I requested a clone at about I think 20 minutes right you'll notice there's no",
    "start": "1600049",
    "end": "1606409"
  },
  {
    "text": "degradation in performance when I did that and about 15 minutes later my clone was finished being created I wasn't",
    "start": "1606409",
    "end": "1613309"
  },
  {
    "text": "actually keeping absolute track of it so about 18 minutes or 20 minutes later I fired up the same sorry I fired up the",
    "start": "1613309",
    "end": "1619429"
  },
  {
    "text": "same benchmark on the blue and you can see that we actually get the exact same performance on the clone right and we",
    "start": "1619429",
    "end": "1626659"
  },
  {
    "text": "see no degradation in the performance of either them so this is a way where you can go get a copy of your production system and then go run tests on it for",
    "start": "1626659",
    "end": "1633049"
  },
  {
    "text": "example and it's quite inexpensive so as I mentioned earlier to the features that",
    "start": "1633049",
    "end": "1640639"
  },
  {
    "start": "1636000",
    "end": "1740000"
  },
  {
    "text": "we're still working on for parody our replication related ones and I'm going to talk about them now so the first one",
    "start": "1640639",
    "end": "1645740"
  },
  {
    "text": "is logical replication support so this how many people are familiar with logical replication in Postgres some not",
    "start": "1645740",
    "end": "1652399"
  },
  {
    "text": "too many so this is the ability for Postgres to take the physical changes that go into the wall stream the right ahead log and convert them back to",
    "start": "1652399",
    "end": "1658940"
  },
  {
    "text": "sequel so that you can take them from your instance and use them to you know a data warehouse or a lot of different",
    "start": "1658940",
    "end": "1665210"
  },
  {
    "text": "things so we support this already as Postgres today and we're working on a forum so if you have an Aurora instance",
    "start": "1665210",
    "end": "1670700"
  },
  {
    "text": "what you're gonna be able to do in the future is you're gonna necessarily you could fire up an ec2 instance and you can enable logical decoding plug-in and",
    "start": "1670700",
    "end": "1677210"
  },
  {
    "text": "we support three of them today you can choose which one you want to use and the ec2 instance basically going to talk to the Aurora instance and get those",
    "start": "1677210",
    "end": "1683299"
  },
  {
    "text": "logical changes and then it can ship it to something like Kinesis for example right the other thing you can do with",
    "start": "1683299",
    "end": "1688519"
  },
  {
    "text": "this is you can fire up our DMS service our data migration service which is really a replication service at heart",
    "start": "1688519",
    "end": "1694039"
  },
  {
    "text": "and you can have it talk to your instance and pull changes off and you can send those two already asks you can",
    "start": "1694039",
    "end": "1699440"
  },
  {
    "text": "send them to s3 you can send them to dynamo you can send them to redshift shows all kinds of places that you can",
    "start": "1699440",
    "end": "1705110"
  },
  {
    "text": "move your data to right now this is really nice but as you can see it involves having another box and some",
    "start": "1705110",
    "end": "1710720"
  },
  {
    "text": "stuff happening right if you just want to replicate between Postgres instances in v10 we're gonna be able to support",
    "start": "1710720",
    "end": "1717529"
  },
  {
    "text": "publish and subscribe so this is if you have an ec2 instance running Postgres and RDS instance you can actually set up",
    "start": "1717529",
    "end": "1724460"
  },
  {
    "text": "publish on one side and subscribe on the other you don't have to have any secondary boxes and you can move logical",
    "start": "1724460",
    "end": "1729559"
  },
  {
    "text": "data between the two of them again this is for you can use an RDS instance for Postgres or another Aurora instance will",
    "start": "1729559",
    "end": "1736039"
  },
  {
    "text": "be able to work like this so this is really high if you want to move data around so the other thing customers really talk to us",
    "start": "1736039",
    "end": "1742349"
  },
  {
    "start": "1740000",
    "end": "1865000"
  },
  {
    "text": "a lot about is being able to have dr and so the feature that is going to support that is our cross region replication so",
    "start": "1742349",
    "end": "1749070"
  },
  {
    "text": "here I'm showing region a with an Aurora cluster what you want is region B to",
    "start": "1749070",
    "end": "1754679"
  },
  {
    "text": "have a copy right so we're introducing some new new features the first is that",
    "start": "1754679",
    "end": "1759779"
  },
  {
    "text": "we're having a replication server a replication replication agent that's the little boxes in purple and the goal of",
    "start": "1759779",
    "end": "1766469"
  },
  {
    "text": "those is to support this cross region replication when you do a log write",
    "start": "1766469",
    "end": "1772320"
  },
  {
    "text": "which is all we do right on the primary it's gonna flow to a bunch of different",
    "start": "1772320",
    "end": "1777419"
  },
  {
    "text": "places so goes to the read-only notes do that in validation as I talked about it flows down to the storage level for the",
    "start": "1777419",
    "end": "1782849"
  },
  {
    "text": "durability and it goes to the replication server the replication server is going to forward that on to the replicate replication agent on the",
    "start": "1782849",
    "end": "1789330"
  },
  {
    "text": "other side and then it's going to apply it to the read-only node for again cache invalidation purposes or updates and",
    "start": "1789330",
    "end": "1796559"
  },
  {
    "text": "it's gonna flow to Aurora storage right so this way you can actually physically",
    "start": "1796559",
    "end": "1802169"
  },
  {
    "text": "get all the physical changes on both sides it's gonna be very low latency and very efficient now one of the things",
    "start": "1802169",
    "end": "1808830"
  },
  {
    "text": "that can happen is you can sometimes lose log vectors and the nice thing is that we actually can handle that we can",
    "start": "1808830",
    "end": "1815309"
  },
  {
    "text": "also handle having multiple really nodes in the future we're going to support multiple regions as well at the same",
    "start": "1815309",
    "end": "1820950"
  },
  {
    "text": "time so the replication server and agent talked to the storage servers as well and they can actually pick log vectors",
    "start": "1820950",
    "end": "1828450"
  },
  {
    "text": "or blocks from the one side and move them to the other right so we can actually do catch-up in multiple ways for repair purposes so you can use this",
    "start": "1828450",
    "end": "1837269"
  },
  {
    "text": "in a dr scenario where you know something's happen to a region or you could move use it to move one region to",
    "start": "1837269",
    "end": "1843509"
  },
  {
    "text": "another we had a lot of customers when new regions pop up sometimes they're closer to their customers than our current regions and this is a really",
    "start": "1843509",
    "end": "1849839"
  },
  {
    "text": "nice way where you can just basically go and promote the new one to be the new writer and at that point you know you",
    "start": "1849839",
    "end": "1856139"
  },
  {
    "text": "have your same cluster you can have all the same read-only nodes and everything else so this can also be used for you",
    "start": "1856139",
    "end": "1862019"
  },
  {
    "text": "know remote reads in other regions as well so caching we made a bunch of",
    "start": "1862019",
    "end": "1867179"
  },
  {
    "start": "1865000",
    "end": "2008000"
  },
  {
    "text": "changes in Aurora for caching we'll walk through that so on on our 4:16 XL very large box 180",
    "start": "1867179",
    "end": "1874529"
  },
  {
    "text": "gig of ram right so when we set up RDS Postgres we basically allow about 25% of",
    "start": "1874529",
    "end": "1881129"
  },
  {
    "text": "that RAM for Postgres processes in the OS about another 25 percent goes to the shared buffers for inside the database",
    "start": "1881129",
    "end": "1887399"
  },
  {
    "text": "and the rest goes to the Linux page cache so this is actually where Postgres is different than most databases in that",
    "start": "1887399",
    "end": "1892620"
  },
  {
    "text": "it uses two caches right most just have something like shared buffers now there",
    "start": "1892620",
    "end": "1898259"
  },
  {
    "text": "are advantages and disadvantages to that so the first is when you're selecting data the Postgres process is going to go",
    "start": "1898259",
    "end": "1904139"
  },
  {
    "text": "look for and shared buffers and if it doesn't find it there it's going to ask for storage it might find it in the page cache if it doesn't it's gonna go to EBS",
    "start": "1904139",
    "end": "1910080"
  },
  {
    "text": "and pick it up and then it has to return all the way back up the stack so this works well but there's a little overhead",
    "start": "1910080",
    "end": "1915659"
  },
  {
    "text": "the other thing is because you have two caches you get duplicate buffers so even though we have 75% of the space for",
    "start": "1915659",
    "end": "1922049"
  },
  {
    "text": "caching in actuality we only end up caching about 50% of the blocks right so only about 240 gig of cache space is",
    "start": "1922049",
    "end": "1929190"
  },
  {
    "text": "used there on Aurora it's quite different because we still need the space for Postgres in the OS but we",
    "start": "1929190",
    "end": "1935879"
  },
  {
    "text": "don't have a page cache because we don't have a opera era filesystem we'd write directly to our storage so we're going",
    "start": "1935879",
    "end": "1942210"
  },
  {
    "text": "to use all of that remaining RAM for shared buffers so 75% when we do a read",
    "start": "1942210",
    "end": "1948299"
  },
  {
    "text": "from Postgres again the same thing we're gonna look at shared buffers but if it's not there we're gonna directly get it from Aurora storage and return it so",
    "start": "1948299",
    "end": "1956460"
  },
  {
    "text": "Postgres can die right as a process and that's fine because you know it's",
    "start": "1956460",
    "end": "1962940"
  },
  {
    "text": "durable but you want it to come back up and be fast right so you want to have your buffers but your buffers also go",
    "start": "1962940",
    "end": "1969179"
  },
  {
    "text": "away when post rest eyes but the Linux page cache doesn't so guess what you're happy because your blocks are in cache",
    "start": "1969179",
    "end": "1976320"
  },
  {
    "text": "and your databases backup and it's all working fine right so we had the difficult decision of being like well we",
    "start": "1976320",
    "end": "1983279"
  },
  {
    "text": "don't have a file system cache so we're not going to get that benefit so we actually had to go build a feature called survivable cache so this is where",
    "start": "1983279",
    "end": "1990299"
  },
  {
    "text": "we go and do invalidation on the cache when the Postgres process dies we actually have the shared buffer",
    "start": "1990299",
    "end": "1995429"
  },
  {
    "text": "separated from the Postgres process and therefore they can survive we just need to invalidate a little bit of metadata",
    "start": "1995429",
    "end": "2001340"
  },
  {
    "text": "and then BAM it's all good right so this gives us the exact same sort of story around caching",
    "start": "2001340",
    "end": "2007869"
  },
  {
    "text": "but there are some advantages so to show that I ran a read-only benchmark right",
    "start": "2007869",
    "end": "2013279"
  },
  {
    "start": "2008000",
    "end": "2125000"
  },
  {
    "text": "so this is just reads scale 22,000 so that's 350 gig working set right but it",
    "start": "2013279",
    "end": "2018499"
  },
  {
    "text": "should fit in Ram because we have 488 gig right so in our 462 Excel and the blue I'm",
    "start": "2018499",
    "end": "2023809"
  },
  {
    "text": "showing Aurora with a 75% cache we're getting 600 almost six hundred and ninety thousand TPS so this is really",
    "start": "2023809",
    "end": "2030980"
  },
  {
    "text": "cool when you just think about as a raw number I mean that's like a very fast system right so I went to ran that on",
    "start": "2030980",
    "end": "2036110"
  },
  {
    "text": "RDS Postgres with it's 25% shared buffers and I got 1.6 times slower and I",
    "start": "2036110",
    "end": "2043399"
  },
  {
    "text": "was like what's going on here I didn't expect that well it turned out I was doing 18,000 read items and the reason",
    "start": "2043399",
    "end": "2049940"
  },
  {
    "text": "was because this size of working set didn't fit because of the double counting of buffers right that we had",
    "start": "2049940",
    "end": "2055638"
  },
  {
    "text": "the overhead of that so to fix that what a lot of people recommend in the Postgres universe is to make the cache",
    "start": "2055639",
    "end": "2061190"
  },
  {
    "text": "smaller right make the shared buffer smaller give it all to Linux page cache and so that's what I did I went down to",
    "start": "2061190",
    "end": "2067819"
  },
  {
    "text": "a 10% cash so it would all fit in cache and I got a lower number and I was like",
    "start": "2067819",
    "end": "2073398"
  },
  {
    "text": "my hand I'm doing something wrong so I wouldn't said what's going on here why am I being slower well as it turns out",
    "start": "2073399",
    "end": "2079819"
  },
  {
    "text": "because the overhead of Haffner Reede both the shared buffers and check for it there and then go to the file system",
    "start": "2079819",
    "end": "2085429"
  },
  {
    "text": "cache and then go back up through those layers burn CPU this is a heavy CPU benchmark right and so I'm stealing CPU",
    "start": "2085429",
    "end": "2092990"
  },
  {
    "text": "cycles to do that which means I can't do more transactions and so this is why I'm actually slower and to demonstrate",
    "start": "2092990",
    "end": "2098720"
  },
  {
    "text": "there's no goofy business with Postgres if I make the cache 75% the shared buffers we get the basically the exact",
    "start": "2098720",
    "end": "2104960"
  },
  {
    "text": "same number as Aurora because reading blocks from memory is essentially the same on both of them but guess what if",
    "start": "2104960",
    "end": "2110000"
  },
  {
    "text": "you configure RDS Postgres like this and the Postgres process dies no survivable cache right so this is one of the again",
    "start": "2110000",
    "end": "2116990"
  },
  {
    "text": "the cool differences that we've improved on with Aurora so this is all great when",
    "start": "2116990",
    "end": "2122450"
  },
  {
    "text": "you know just the Postgres process dies but what happens when I have to do a failover right what about my cache then",
    "start": "2122450",
    "end": "2128780"
  },
  {
    "start": "2125000",
    "end": "2192000"
  },
  {
    "text": "so to illustrate that I'm running PG bench with a 20x read-only to a 1x",
    "start": "2128780",
    "end": "2133819"
  },
  {
    "text": "readwrite benchmark on a node right it's 160 gig in cache",
    "start": "2133819",
    "end": "2138980"
  },
  {
    "text": "and vertical accesses transactions per second and I'm doing about I think what was it like 350,000 total transactions",
    "start": "2138980",
    "end": "2146270"
  },
  {
    "text": "between the reads and writes and at ten minutes in I basically do a failover right and it takes 32 seconds to come",
    "start": "2146270",
    "end": "2153530"
  },
  {
    "text": "back up and that's including DNS and I just had PG bench and a little loop just trying to connect right so as soon as DNS propagated it connected and it was",
    "start": "2153530",
    "end": "2159980"
  },
  {
    "text": "all good right but if you look at the 90th percentile of my performance right I should be much closer to about 320,000",
    "start": "2159980",
    "end": "2167780"
  },
  {
    "text": "if that's what my application needs right so it actually took three hundred and forty seconds to get back to having",
    "start": "2167780",
    "end": "2174260"
  },
  {
    "text": "the cache all warmed up and to get back to that baseline performance right so when we talk about failover we're",
    "start": "2174260",
    "end": "2180530"
  },
  {
    "text": "actually not being very good when we say oh yeah it's failed over in 32 seconds but you know from an application users",
    "start": "2180530",
    "end": "2185690"
  },
  {
    "text": "perspective it really didn't right it took a lot longer so to get around this we built a new feature called cluster",
    "start": "2185690",
    "end": "2191750"
  },
  {
    "text": "cache management or CCM as I like to call it so again we got the same",
    "start": "2191750",
    "end": "2196760"
  },
  {
    "start": "2192000",
    "end": "2283000"
  },
  {
    "text": "standard set up and I'm we introduced a new term which is failover priority so this is a feature that we've had in Aurora and you can actually designate",
    "start": "2196760",
    "end": "2203990"
  },
  {
    "text": "your nodes for which failover priority with zero being the highest priority I know that seeing it sounds kind of",
    "start": "2203990",
    "end": "2209119"
  },
  {
    "text": "backwards but it's easier to figure out you know which one to go to so you notice that the readwrite one and the",
    "start": "2209119",
    "end": "2214700"
  },
  {
    "text": "one read-only know during our failover priority zero so this is gonna be where we go first all these other read-only nodes I mean I've labeled failover",
    "start": "2214700",
    "end": "2221000"
  },
  {
    "text": "priority one now that doesn't mean we won't failover to them it just means that we'll consider them less likely to happen because we're gonna try the other",
    "start": "2221000",
    "end": "2227900"
  },
  {
    "text": "nodes first right so once you've done this and if you turn",
    "start": "2227900",
    "end": "2233000"
  },
  {
    "text": "on a PG CCM enabled in your parameter group at the cluster level essentially",
    "start": "2233000",
    "end": "2239150"
  },
  {
    "text": "we're gonna start doing extra stuff and the first thing is the read-only node is gonna send a bloom filter of what the",
    "start": "2239150",
    "end": "2244340"
  },
  {
    "text": "replicas cache looks like back to the readwrite node the readwrite node is gonna compare that with what it's got in",
    "start": "2244340",
    "end": "2249920"
  },
  {
    "text": "cache and then it's gonna send the addresses of the blocks that it wants to load on the read-only node and then the",
    "start": "2249920",
    "end": "2255590"
  },
  {
    "text": "read-only node in the background is basically going to slowly read those blocks in I shouldn't say slowly over a",
    "start": "2255590",
    "end": "2260960"
  },
  {
    "text": "little bit of time read them in and you'll now notice the color on the read-only node is the same as the readwrite node because the caches are",
    "start": "2260960",
    "end": "2267109"
  },
  {
    "text": "basically very similar now now we don't do this for every block every change because you know if",
    "start": "2267109",
    "end": "2272750"
  },
  {
    "text": "you had a lot of cash churn you only really want the stuff that's hot in the cash to be coming across right because",
    "start": "2272750",
    "end": "2278150"
  },
  {
    "text": "it is extra read workload on your read only note but there's a reason why you want to do this so I ran the exact same",
    "start": "2278150",
    "end": "2284510"
  },
  {
    "start": "2283000",
    "end": "2316000"
  },
  {
    "text": "benchmark same fail over at 600 seconds and the blue is with CCM enabled and the",
    "start": "2284510",
    "end": "2290510"
  },
  {
    "text": "red is the original right so we have the three hundred forty seconds so now we're back to 32 seconds for failover but",
    "start": "2290510",
    "end": "2296450"
  },
  {
    "text": "we're 32 seconds for failover and back to our 90th percentile performance right so now we truly have failover at 32",
    "start": "2296450",
    "end": "2303560"
  },
  {
    "text": "seconds not 340 right so this is a very important feature it's also going to",
    "start": "2303560",
    "end": "2309170"
  },
  {
    "text": "allow us over time to try to get that 32 seconds down further because there's less disruption to the customer when you",
    "start": "2309170",
    "end": "2314360"
  },
  {
    "text": "do these fail overs so one of the other things that we've worked on is",
    "start": "2314360",
    "end": "2319400"
  },
  {
    "start": "2316000",
    "end": "2446000"
  },
  {
    "text": "performance to illustrate performance one of the other tools we built was performance insights this is available",
    "start": "2319400",
    "end": "2325730"
  },
  {
    "text": "across a lot of our engines but Aurora Post Rose was the first one we had and this is a really nice tool for being",
    "start": "2325730",
    "end": "2331220"
  },
  {
    "text": "able to see what's going on with performance in your database right so what I'm illustrating here is that my application was running along fine and",
    "start": "2331220",
    "end": "2337490"
  },
  {
    "text": "then at some point it kind of went off the rails right so the green is CPU usage and that little black line across",
    "start": "2337490",
    "end": "2343700"
  },
  {
    "text": "the top is my actual number of CPUs so it basically means I have the box pinned to the wall right it's just flat out",
    "start": "2343700",
    "end": "2349670"
  },
  {
    "text": "running but I'm like well it wasn't doing that before what's what's changed so I drill in and I look at the current",
    "start": "2349670",
    "end": "2355790"
  },
  {
    "text": "run what's going on right now all the CPU usage and I can see it's this query and it's hopefully you can see that it's",
    "start": "2355790",
    "end": "2362420"
  },
  {
    "text": "it's basically a an analytics query right that I'm running in SPG bench history and you know that seems kind of",
    "start": "2362420",
    "end": "2368600"
  },
  {
    "text": "horrible but wait let's go look at it before well it was running before and it was running fine so what happened right",
    "start": "2368600",
    "end": "2374510"
  },
  {
    "text": "so as it turns out the plans have changed so before what I was doing was I was",
    "start": "2374510",
    "end": "2379640"
  },
  {
    "text": "getting a nested loop bitmap heat scan a bitmap index scan right afterwards I'm",
    "start": "2379640",
    "end": "2385340"
  },
  {
    "text": "now getting a hash join and I'm getting sequential scans right so this is a dramatically worse plan well why did",
    "start": "2385340",
    "end": "2392120"
  },
  {
    "text": "that happen well it could be a stats change could be analyzed it could be a config change it could be an index",
    "start": "2392120",
    "end": "2397850"
  },
  {
    "text": "I mean it's obably not an index change in this case right but all these things can cause plans to change on you and",
    "start": "2397850",
    "end": "2403340"
  },
  {
    "text": "dramatic fashions right as it turns out the reason why this happened was me I changed a couple parameters right not that",
    "start": "2403340",
    "end": "2410030"
  },
  {
    "text": "anyone's ever inadvertently set the wrong parameter in their database right",
    "start": "2410030",
    "end": "2415450"
  },
  {
    "text": "so I did this deliberately just to show that you know the plans can dramatically",
    "start": "2416109",
    "end": "2421520"
  },
  {
    "text": "change and you know that's a bad thing right so if you come from enterprise",
    "start": "2421520",
    "end": "2427790"
  },
  {
    "text": "databases you know running fast is great but running consistently is actually",
    "start": "2427790",
    "end": "2433040"
  },
  {
    "text": "probably more important right your manager if you're if your database running 2% faster it's gonna be happy if",
    "start": "2433040",
    "end": "2438200"
  },
  {
    "text": "on the other hand your database blows up because it goes 500 percent slower right your manager is gonna be in your office",
    "start": "2438200",
    "end": "2444290"
  },
  {
    "text": "yelling at you right so to get around this we've got a new feature out in our new latest release of 10 10 5 it's also",
    "start": "2444290",
    "end": "2452569"
  },
  {
    "start": "2446000",
    "end": "2557000"
  },
  {
    "text": "going to come on our 9 version in our next release called query plan management or qpm so what this allows",
    "start": "2452569",
    "end": "2458809"
  },
  {
    "text": "you to do is capture statements right so as the statements are running in the database you can actually capture them",
    "start": "2458809",
    "end": "2463940"
  },
  {
    "text": "so in this case I'm showing query a plan version 1 query be in the sort of pink",
    "start": "2463940",
    "end": "2469099"
  },
  {
    "text": "plan v1 right so you can then approve these plans you can do this automatically or manually and once you",
    "start": "2469099",
    "end": "2475609"
  },
  {
    "text": "say they're good they're marked as approved then you can institute a baseline by instituting a baseline",
    "start": "2475609",
    "end": "2481849"
  },
  {
    "text": "you're telling the optimizer to basically use these plans right and to not deviate from that so this allows for",
    "start": "2481849",
    "end": "2487849"
  },
  {
    "text": "planned stability right so you're not going to get weird plants so when a new version of this plan shows up it's not",
    "start": "2487849",
    "end": "2494299"
  },
  {
    "text": "going to automatically be used by the optimizer right it's it's gonna be discarded because it's not the approved",
    "start": "2494299",
    "end": "2499880"
  },
  {
    "text": "plan it's not in the baseline right but the challenge with this if you do this",
    "start": "2499880",
    "end": "2504980"
  },
  {
    "text": "right now someone comes along and says I'm gonna build an index now to make that query better right and this plan v3",
    "start": "2504980",
    "end": "2512089"
  },
  {
    "text": "might actually be better but it won't use it right because I've got the baseline well we allow you to evolve to better",
    "start": "2512089",
    "end": "2517970"
  },
  {
    "text": "plans and we do this by having a comparison utility that allows you to compare plans and figure out based on",
    "start": "2517970",
    "end": "2523690"
  },
  {
    "text": "elapsed time and cost whether it's better and if it is then you can just approve that plan and it's going to be",
    "start": "2523690",
    "end": "2529670"
  },
  {
    "text": "used in place of the original plan right to illustrate like what happens when you use baselines let's go back to my p i--",
    "start": "2529670",
    "end": "2536660"
  },
  {
    "text": "screen and you'll see that this is what i institute the baselines back on right my plans go",
    "start": "2536660",
    "end": "2542480"
  },
  {
    "text": "back to exactly how they were before and my performance gets very predictable right so this this shows you that you",
    "start": "2542480",
    "end": "2549050"
  },
  {
    "text": "can actually have you know control of your plans and a much more predictable database performance than you had before",
    "start": "2549050",
    "end": "2556540"
  },
  {
    "text": "one of the other things around predictable performance you need vacuuming if you're running Postgres right so this is just a benchmark I ran",
    "start": "2556540",
    "end": "2564560"
  },
  {
    "start": "2557000",
    "end": "2606000"
  },
  {
    "text": "a long time ago that shows what happens if you turn off vacuuming right the red line is where you'd like to be at and",
    "start": "2564560",
    "end": "2570170"
  },
  {
    "text": "the black line is sort of what happens over time it just drifts down because you have more bloat in your system right",
    "start": "2570170",
    "end": "2575480"
  },
  {
    "text": "so you need to vacuum to maintain performance the other thing is you need to maintain the cleanup of transaction",
    "start": "2575480",
    "end": "2582770"
  },
  {
    "text": "IDs Postgres has a limit and if you run out of them you basically are going to be down and tell you vacuum so this is a",
    "start": "2582770",
    "end": "2588860"
  },
  {
    "text": "very important thing so as part of the building of arora Postgres it was great you know we got the benchmarks we're",
    "start": "2588860",
    "end": "2594560"
  },
  {
    "text": "writing three times faster this is all great and then we sat there and said well wait a minute if we're writing three times faster and vacuum is running",
    "start": "2594560",
    "end": "2601100"
  },
  {
    "text": "at the same speed that's just going to be a recipe for disaster right so we went and did vacuum improvements so the one that we've done",
    "start": "2601100",
    "end": "2608420"
  },
  {
    "start": "2606000",
    "end": "2721000"
  },
  {
    "text": "so far is called intelligent vacuum prefetch so in Postgres when it's vacuuming it has two things a visibility",
    "start": "2608420",
    "end": "2615110"
  },
  {
    "text": "in a frozen map and these are great improvements that we're done in a while back in Postgres that allows Postgres",
    "start": "2615110",
    "end": "2620150"
  },
  {
    "text": "not to have to scan the entire table to figure out what to vacuum and in this case i'm showing basically an illustration of the frozen map where the",
    "start": "2620150",
    "end": "2626330"
  },
  {
    "text": "blue are things blocks that are frozen or and the red ones are not that mains",
    "start": "2626330",
    "end": "2631490"
  },
  {
    "text": "still need to be vacuumed ok so Postgres is gonna go and read the ones that it needs and it's gonna go vacuum them",
    "start": "2631490",
    "end": "2637130"
  },
  {
    "text": "right so you'd expect it to do basically what I've Illustrated for the red arrows right but because Postgres uses a file",
    "start": "2637130",
    "end": "2644030"
  },
  {
    "text": "system cache it's trying to get read ahead so it actually has an instruction that says if those red blocks are within",
    "start": "2644030",
    "end": "2649370"
  },
  {
    "text": "32 of each other then just read them all right so this actually causes a lot more",
    "start": "2649370",
    "end": "2656720"
  },
  {
    "text": "effort to have to happen right and so I'm not actually sure it on modern SSDs",
    "start": "2656720",
    "end": "2662540"
  },
  {
    "text": "if this still makes sense but it's what Postgres does today I think it's you know we may want to look at that in the",
    "start": "2662540",
    "end": "2667550"
  },
  {
    "text": "future but for us we don't have a file system cache we don't do read ahead in the sort of normal way it's quite",
    "start": "2667550",
    "end": "2673910"
  },
  {
    "text": "different so on Postgres that took 402 seconds when I did this vacuum on Aurora what we",
    "start": "2673910",
    "end": "2679250"
  },
  {
    "text": "do is we collect the block addresses of the things that need to be vacuumed we gather those all together and then we",
    "start": "2679250",
    "end": "2685910"
  },
  {
    "text": "submit one i/o right and it's got one up to 256 blocks can get returned from this",
    "start": "2685910",
    "end": "2691670"
  },
  {
    "text": "one il right and so this is much more efficient the other thing with Aurora Postgres is because we're not doing",
    "start": "2691670",
    "end": "2697610"
  },
  {
    "text": "checkpoints or full-page writes vacuuming costs less to actually do so the combination of those two things",
    "start": "2697610",
    "end": "2703100"
  },
  {
    "text": "means that Aurora Postgres did the same vacuuming in 163 seconds so more than twice as fast as regular Postgres so",
    "start": "2703100",
    "end": "2710570"
  },
  {
    "text": "this was a nice improvement that really changed for a lot of our customers they used to have problems with vacuums on",
    "start": "2710570",
    "end": "2716210"
  },
  {
    "text": "Postgres and they're not having any on award now so how many people are aware",
    "start": "2716210",
    "end": "2722540"
  },
  {
    "start": "2721000",
    "end": "2839000"
  },
  {
    "text": "of rora serverless cool well i'm very happy",
    "start": "2722540",
    "end": "2727580"
  },
  {
    "text": "to announce that we now have Aurora Postgres as serverless in preview yeah",
    "start": "2727580",
    "end": "2733880"
  },
  {
    "text": "it's very exciting very exciting yeah this is a really cool feature I think is",
    "start": "2733880",
    "end": "2739670"
  },
  {
    "text": "gonna you know dramatically change for a lot of people how they run their databases so what this is is a little",
    "start": "2739670",
    "end": "2745910"
  },
  {
    "text": "different model though you have a database endpoint just like you always have an RDS we have this new thing called a request router in that sort of",
    "start": "2745910",
    "end": "2752330"
  },
  {
    "text": "light purple box and you'll notice that I have Aurora there but there's no server right now and there's just the",
    "start": "2752330",
    "end": "2758810"
  },
  {
    "text": "storage so when you provision something that's all you start with right you don't actually have a server running it's not until your application goes to",
    "start": "2758810",
    "end": "2765950"
  },
  {
    "text": "do work that you actually fire up a server right I mean you can configure it to always be there but you don't have to",
    "start": "2765950",
    "end": "2771080"
  },
  {
    "text": "so at that time we're gonna pull an instance out of our warm pool and we're gonna attach it to your storage and then",
    "start": "2771080",
    "end": "2777260"
  },
  {
    "text": "it's gonna start executing queries for you right and as you push harder essentially we'll go through and we'll",
    "start": "2777260",
    "end": "2783770"
  },
  {
    "text": "actually scale this up or scale it down so you know if you just keep pushing harder you're gonna get a bigger bigger instance right and this happens quite",
    "start": "2783770",
    "end": "2791350"
  },
  {
    "text": "quickly right so I'll show in a second the it takes about five minutes of you",
    "start": "2791350",
    "end": "2796520"
  },
  {
    "text": "know increased CPU to cause that to trigger but the cool thing is because you have this request router in the",
    "start": "2796520",
    "end": "2801710"
  },
  {
    "text": "middle you don't actually draw up sessions right you don't lose connections when we do this so this is",
    "start": "2801710",
    "end": "2807020"
  },
  {
    "text": "all seamless from application perspective it just goes up and down right the other cool thing is you pay per second in one minute",
    "start": "2807020",
    "end": "2813530"
  },
  {
    "text": "minimums when you spin up right so if you have a application that only runs for four hours a day",
    "start": "2813530",
    "end": "2819380"
  },
  {
    "text": "it'll just basically go to sleep and then the next time somebody connects to it will fire back up so from a economics perspective this is",
    "start": "2819380",
    "end": "2825859"
  },
  {
    "text": "very helpful for those kind of applications and the other cool thing of course is Aurora Storage can grow on its",
    "start": "2825859",
    "end": "2832250"
  },
  {
    "text": "own so you don't have to worry about that and as I said as soon as your application goes away guess what so can",
    "start": "2832250",
    "end": "2838070"
  },
  {
    "text": "your box right to illustrate this we ran a benchmark where we just sort of were pushing harder so the the blue line is",
    "start": "2838070",
    "end": "2845960"
  },
  {
    "start": "2839000",
    "end": "2899000"
  },
  {
    "text": "the number of service compete units of capacity and the orange line was CPU so",
    "start": "2845960",
    "end": "2852560"
  },
  {
    "text": "I start the benchmark I'm basically at zero right so I'm not doing anything as soon as I connect and start pushing we",
    "start": "2852560",
    "end": "2858650"
  },
  {
    "text": "scale up right and then I continue to increase the benchmark so it continued to ask for more and more CPU and we just",
    "start": "2858650",
    "end": "2864680"
  },
  {
    "text": "kept scaling up right till we got to the largest size that I capped it at 64 units and you can go all the way up to",
    "start": "2864680",
    "end": "2871910"
  },
  {
    "text": "256 units ie the largest blocks we have like an r4 16 Excel and then basically I",
    "start": "2871910",
    "end": "2877190"
  },
  {
    "text": "ramped the same benchmark down and it scaled back down and then I stopped it and guess what my instance went away",
    "start": "2877190",
    "end": "2883099"
  },
  {
    "text": "right so this is really useful as a tool for lots of different ones especially",
    "start": "2883099",
    "end": "2888470"
  },
  {
    "text": "for a lot of people who do IOT based stuff where it's completely in predictable demand this is a great great",
    "start": "2888470",
    "end": "2894500"
  },
  {
    "text": "solution so this is all great people say or I like it how do I get to it well so",
    "start": "2894500",
    "end": "2899690"
  },
  {
    "text": "that's migration right so there's four primary methods to come in if you're on",
    "start": "2899690",
    "end": "2904970"
  },
  {
    "text": "Postgres one of the things you can do is pg dump restore I'm not going to talk about that in great detail because most people are pretty familiar with those",
    "start": "2904970",
    "end": "2910750"
  },
  {
    "text": "data migration service I'll cover snapshot import was our initial implementation for moving from RDS",
    "start": "2910750",
    "end": "2916730"
  },
  {
    "text": "Postgres but I'm gonna really talk about the read replica model because I think it's a superior method for moving in so",
    "start": "2916730",
    "end": "2923540"
  },
  {
    "text": "DMS is a really cool tool I was so excited when we built this we had a lot of customers talk to us about moving",
    "start": "2923540",
    "end": "2929359"
  },
  {
    "text": "from either one database the same you know moving from Postgres to Postgres but in a lot of cases customers wanted",
    "start": "2929359",
    "end": "2934910"
  },
  {
    "text": "to move from Oracle or sequel server to Postgres right so any of these engines are supported on the left there",
    "start": "2934910",
    "end": "2941450"
  },
  {
    "text": "and all you do is you fire up a Postgres instance and or or Postgres instance and then you fire up a DMS instance and you",
    "start": "2941450",
    "end": "2948230"
  },
  {
    "text": "configure DMS and you tell it go connect to this database figure out what things to you know pull from it and once you do",
    "start": "2948230",
    "end": "2954560"
  },
  {
    "text": "that it will basically do a consistent select where it does a full load right now this is fine but that takes quite a",
    "start": "2954560",
    "end": "2961339"
  },
  {
    "text": "while to run right and so in the meantime your application is still doing stuff that's the magic of logical",
    "start": "2961339",
    "end": "2967160"
  },
  {
    "text": "replication and DMS is it uses the change data capture and all these engines to basically allow you to catch",
    "start": "2967160",
    "end": "2972680"
  },
  {
    "text": "back up from when you started that copy right so then your database gets to the same state as on both sides so once it's",
    "start": "2972680",
    "end": "2980000"
  },
  {
    "text": "essentially caught up you stop the application and you started on the other",
    "start": "2980000",
    "end": "2985040"
  },
  {
    "text": "side right and this is a great way to migrate in especially if you're coming from a different engine on the other",
    "start": "2985040",
    "end": "2990680"
  },
  {
    "text": "hand if you're in RDS there's a much easier way if you're an RDS Postgres you have your application you already has",
    "start": "2990680",
    "end": "2996050"
  },
  {
    "start": "2991000",
    "end": "3055000"
  },
  {
    "text": "Postgres instance you basically ask us to do a migration or be in a reed",
    "start": "2996050",
    "end": "3001420"
  },
  {
    "text": "replica in aurora we take a snapshot then we have to do some conversion to",
    "start": "3001420",
    "end": "3006579"
  },
  {
    "text": "make it into aurora so that's what happens there and once that's done you know that takes a tiny bit of time tiny",
    "start": "3006579",
    "end": "3012460"
  },
  {
    "text": "bit of time a little bit of time but you again have done more transactions right so we actually make it a reed replica so",
    "start": "3012460",
    "end": "3018730"
  },
  {
    "text": "it catches up via a synchronous wall replication just like a normal Postgres instance so at this point it's just like",
    "start": "3018730",
    "end": "3025000"
  },
  {
    "text": "you have a normal reed replica it just happens to be Aurora right so you could keep running it for a while you can choose when to migrate but once it's all",
    "start": "3025000",
    "end": "3032140"
  },
  {
    "text": "caught up you essentially need to just stop your application let the last bit of wall flow through the system right and then you can stop the replication",
    "start": "3032140",
    "end": "3039880"
  },
  {
    "text": "and promote the Aurora Postgres instance right so we've had people do this migration in a couple minutes from RDS",
    "start": "3039880",
    "end": "3046420"
  },
  {
    "text": "Postgres so this is really nice if you want to move from RDS Postgres to aurora Postgres yeah and so that's how you can",
    "start": "3046420",
    "end": "3054040"
  },
  {
    "text": "get into Aurora as a note we have some more breakouts on these subjects the",
    "start": "3054040",
    "end": "3060579"
  },
  {
    "start": "3055000",
    "end": "3088000"
  },
  {
    "text": "first one obviously Tuesday that one's already gone by tomorrow we have a talk by some of my colleagues on RDS Postgres",
    "start": "3060579",
    "end": "3068530"
  },
  {
    "text": "and sort of Postgres in the AWS universe it's going to talk more about identity access management and some of the other",
    "start": "3068530",
    "end": "3074720"
  },
  {
    "text": "we've done across both engines and then my colleague David who's sitting here in",
    "start": "3074720",
    "end": "3079910"
  },
  {
    "text": "the front he's going to be with another one of my colleagues Jim doing a deep dive on performance on Thursday in Oriya",
    "start": "3079910",
    "end": "3087290"
  },
  {
    "text": "so with that thank you very much [Applause]",
    "start": "3087290",
    "end": "3095649"
  },
  {
    "start": "3088000",
    "end": "3116000"
  },
  {
    "text": "all happy to take some questions off to the side now and the other thing is if",
    "start": "3098950",
    "end": "3105110"
  },
  {
    "text": "you have any other general RTS questions we have people down at the booth all all-conference long so we have lots of",
    "start": "3105110",
    "end": "3111380"
  },
  {
    "text": "Engineers there so if you have other questions you can come down there and talk to us there",
    "start": "3111380",
    "end": "3116440"
  }
]
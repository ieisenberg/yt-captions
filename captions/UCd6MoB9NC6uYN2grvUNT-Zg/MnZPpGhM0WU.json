[
  {
    "text": "today I'm going to talk to you about cloud watch logs and ADA bias lambda and how to do some more advanced",
    "start": "60",
    "end": "5640"
  },
  {
    "text": "functionality with processing your logs and aggregating your logs and using them",
    "start": "5640",
    "end": "11219"
  },
  {
    "text": "with elasticsearch as well so what to expect in this session first we're going",
    "start": "11219",
    "end": "16320"
  },
  {
    "text": "to look at some industry trends that we see that are impacting monitoring and logging then we're going to learn a",
    "start": "16320",
    "end": "21840"
  },
  {
    "text": "little bit about cloud watch in general and cloud watch logs specifically and",
    "start": "21840",
    "end": "26849"
  },
  {
    "text": "we're going to talk about several monitoring use cases and how to use lambda and cloud watch to help of those",
    "start": "26849",
    "end": "33239"
  },
  {
    "text": "use cases so we're also going to talk about three different scenarios here and",
    "start": "33239",
    "end": "38399"
  },
  {
    "text": "I'll show you actual demos with how to how to you know make these scenarios",
    "start": "38399",
    "end": "44690"
  },
  {
    "text": "something that you can use their services for so the first one is centralizing your logs so you're gonna",
    "start": "44690",
    "end": "50370"
  },
  {
    "text": "take logs that are on an ELB or an alb load balancer and you're going to use",
    "start": "50370",
    "end": "56120"
  },
  {
    "text": "you're gonna put all those logs in s3 buckets and you're gonna send those logs from s3 into a cloud watch logs from",
    "start": "56120",
    "end": "62789"
  },
  {
    "text": "where you can do further analysis with them then we're going to talk about customizing your alarms so you can",
    "start": "62789",
    "end": "69210"
  },
  {
    "text": "generate alarms from cloud watch and cloud watch logs but how do you get the alarms to give you the information that",
    "start": "69210",
    "end": "74250"
  },
  {
    "text": "you actually need so actionable information that you can resolve the",
    "start": "74250",
    "end": "80250"
  },
  {
    "text": "alarms from and we're gonna look at how do you analyze your actual logs so how do you build a quick on-demand at",
    "start": "80250",
    "end": "86820"
  },
  {
    "text": "elastic search cluster just just as you need to to analyze your logs and then",
    "start": "86820",
    "end": "92490"
  },
  {
    "text": "shut it down really quickly so let's talk about a common scenario that I certainly have seen before both in my",
    "start": "92490",
    "end": "98909"
  },
  {
    "text": "previous life as a DevOps engineer and with customers I work with now so this",
    "start": "98909",
    "end": "105149"
  },
  {
    "text": "is this is your typical sre right and there's an incident going on and but",
    "start": "105149",
    "end": "111329"
  },
  {
    "text": "they don't really know that anything's happening until well let me tell you the story so this story again is mostly true",
    "start": "111329",
    "end": "118200"
  },
  {
    "text": "I have changed the names not to you know to protect the innocent and so you've",
    "start": "118200",
    "end": "125159"
  },
  {
    "text": "got an app your app is down but you don't know that it's down until one of",
    "start": "125159",
    "end": "130890"
  },
  {
    "text": "your customers actually writes a ticket so that's the first red flag there now you have to have a customer let you know that your apps down John the",
    "start": "130890",
    "end": "137820"
  },
  {
    "text": "on-call developer is page through the ticketing system because of this call because of this customer ticket but none",
    "start": "137820",
    "end": "144360"
  },
  {
    "text": "of your alarms fired so we'll call this the blissful ignorance stage of the",
    "start": "144360",
    "end": "149640"
  },
  {
    "text": "incident so if John starts to look at service dashboards and he doesn't really see",
    "start": "149640",
    "end": "156360"
  },
  {
    "text": "anything that impacts availability so he doesn't really know how to begin to",
    "start": "156360",
    "end": "161490"
  },
  {
    "text": "solve this problem so Jonathan decides to escalate to a",
    "start": "161490",
    "end": "166590"
  },
  {
    "text": "manager that's on call and so we'll call this the confusion stage of the incident",
    "start": "166590",
    "end": "171920"
  },
  {
    "text": "so then more customer tickets are pouring in the escalation manager Jane joins the event and starts trying to",
    "start": "171920",
    "end": "178830"
  },
  {
    "text": "figure out what's going on and then even worse John and Janes CTO notices the problem and sends Jane and I am saying",
    "start": "178830",
    "end": "185940"
  },
  {
    "text": "Jane what's what's going on here so this is where the stress part of the incident starts and so John and Jane then recall",
    "start": "185940",
    "end": "194489"
  },
  {
    "text": "a recent other issue where certain customers started to issue expensive",
    "start": "194489",
    "end": "199860"
  },
  {
    "text": "operations on the database this caused the similar kind of problem so John starts just SSA Qing into",
    "start": "199860",
    "end": "206130"
  },
  {
    "text": "production at hosts and trying to look into the logs to see if this is in fact the issue John thinks he's got a suspect",
    "start": "206130",
    "end": "213510"
  },
  {
    "text": "customer figured out and Jane cuts a ticket and premieres a configuration change to block that customer so this is",
    "start": "213510",
    "end": "220560"
  },
  {
    "text": "the the false hope step of the incident and another team engages and they just",
    "start": "220560",
    "end": "226920"
  },
  {
    "text": "confirm that they haven't actually changed any code or anything and Jane and John also confirmed that the problem",
    "start": "226920",
    "end": "235049"
  },
  {
    "text": "still exists even after blocking the customer so they're out of ideas so they",
    "start": "235049",
    "end": "240930"
  },
  {
    "text": "just decide to failover to the standby so it's the you know have you tried rebooting stage so we'll call this",
    "start": "240930",
    "end": "246390"
  },
  {
    "text": "desperation but that actually fixes the incident right so that's unexpected but",
    "start": "246390",
    "end": "252360"
  },
  {
    "text": "it actually worked as rebooting usually knows and so they later found out that there's",
    "start": "252360",
    "end": "258540"
  },
  {
    "text": "a software update that happened and there's a new G DBC version that was introduced this had a memory leak",
    "start": "258540",
    "end": "264630"
  },
  {
    "text": "leading to Java heap exhaustion that's what the problem so they fix the problem they",
    "start": "264630",
    "end": "269980"
  },
  {
    "text": "add new alarms usage and they tune their service alarms but and this is you know",
    "start": "269980",
    "end": "276760"
  },
  {
    "text": "now they think they're enlightened but we can do better than that there's a lot of things that were missed here so",
    "start": "276760",
    "end": "281890"
  },
  {
    "text": "there's missing alarms some of the arms that they did get weren't actionable",
    "start": "281890",
    "end": "287070"
  },
  {
    "text": "they didn't have access to the right logs that SSH into hosts and and and you",
    "start": "287070",
    "end": "292960"
  },
  {
    "text": "know that wastes a lot of time and their dashboards didn't tell them that they were actually down they had to you know",
    "start": "292960",
    "end": "298420"
  },
  {
    "text": "be notified that they were down by one of their customers so we see this over and over again",
    "start": "298420",
    "end": "304000"
  },
  {
    "text": "monitoring Early's monitoring the right things and getting actionable alerts on them is really hard so let's talk about",
    "start": "304000",
    "end": "309880"
  },
  {
    "text": "some trends that we see across the industry more and more of our customers are moving toward micro services based",
    "start": "309880",
    "end": "315820"
  },
  {
    "text": "applications so applications are becoming smaller but each of these have",
    "start": "315820",
    "end": "321340"
  },
  {
    "text": "their own logging that they need applications are being written in different languages different frameworks",
    "start": "321340",
    "end": "326670"
  },
  {
    "text": "and workloads are running more on containers so on things like you see us",
    "start": "326670",
    "end": "332170"
  },
  {
    "text": "and docker in general on serverless compute platforms such as lambda and",
    "start": "332170",
    "end": "337300"
  },
  {
    "text": "again these all also need logging as well and we see per specialization and the persistence here as well so some",
    "start": "337300",
    "end": "345310"
  },
  {
    "text": "vacations are using no sequel some applications are using Postgres my sequel Oracle sequel server right and we",
    "start": "345310",
    "end": "354400"
  },
  {
    "text": "see that and there's a move toward part of the move toward micro services is",
    "start": "354400",
    "end": "360130"
  },
  {
    "text": "that every small change is always continuously built tested and deployed so continuing duration continues",
    "start": "360130",
    "end": "366430"
  },
  {
    "text": "delivery in his deployment and this is causing the scale of infrastructure to",
    "start": "366430",
    "end": "373810"
  },
  {
    "text": "grow and also the logging needs of that infrastructure to grow so CIC D&M ops in",
    "start": "373810",
    "end": "380320"
  },
  {
    "text": "general is a forcing function toward automation and the increased automation means you need good monitoring and we",
    "start": "380320",
    "end": "387130"
  },
  {
    "text": "also notice that applications are global and customer behavior is unpredictable so as your application goes global",
    "start": "387130",
    "end": "393160"
  },
  {
    "text": "you're now bound to just one time zone or one season your apps always-on it's always has to be working and has to be",
    "start": "393160",
    "end": "399370"
  },
  {
    "text": "prepared for spikes and you at any given time also we're seeing that",
    "start": "399370",
    "end": "405759"
  },
  {
    "text": "actual rolls of applications have a significant impact on business outcomes",
    "start": "405759",
    "end": "412599"
  },
  {
    "text": "so security is really important uptime is really important all this is having an impact on the bottom line of our",
    "start": "412599",
    "end": "419169"
  },
  {
    "text": "customers and rapidly evolving applications is really important to gain",
    "start": "419169",
    "end": "424210"
  },
  {
    "text": "competitive advantage against others in your field and also customers are increasing their expectations so I used",
    "start": "424210",
    "end": "431560"
  },
  {
    "text": "to see applications all time that we're like down on the weekends or only open during business hours and I'm seeing",
    "start": "431560",
    "end": "437020"
  },
  {
    "text": "that a lot less customers expect the applications they used to be on all the time and working all the time and then",
    "start": "437020",
    "end": "445000"
  },
  {
    "text": "another trend is that monitoring is no longer the standalone thing it's a part of the application lifecycle so whether",
    "start": "445000",
    "end": "451659"
  },
  {
    "text": "you're doing configuration management or provisioning your infrastructure or governance and compliance or resource optimization you're using logging",
    "start": "451659",
    "end": "457870"
  },
  {
    "text": "monitoring 10400 decisions with how you act them at all those stages so let's",
    "start": "457870",
    "end": "463509"
  },
  {
    "text": "talk about cloud wash logs or cloud watch and cloud much logs which are monitoring and logging services and so",
    "start": "463509",
    "end": "469630"
  },
  {
    "text": "cloud watch allows you to use a the base generated metrics such as you know for instances for example CP usage network",
    "start": "469630",
    "end": "475690"
  },
  {
    "text": "out so lets you use logs and events so logs such as things that you know for",
    "start": "475690",
    "end": "483159"
  },
  {
    "text": "example lambda generates and events such as we have a cloud watch event service",
    "start": "483159",
    "end": "488830"
  },
  {
    "text": "as well so you can act upon a certain event monitoring event and I'll talk about that as well and so you can use",
    "start": "488830",
    "end": "495069"
  },
  {
    "text": "these things to understand the behavior of your system you can also publish any kind of custom metrics so things that we",
    "start": "495069",
    "end": "501129"
  },
  {
    "text": "don't provide out of box you can just write a custom metric for you can publish your own logs to our cloud watch log service and you can use these again",
    "start": "501129",
    "end": "509469"
  },
  {
    "text": "for your for making informed decisions for scaling up scaling down reacting to incidents you can also set up automatic",
    "start": "509469",
    "end": "517570"
  },
  {
    "text": "notifications if you reach some thresholds that you define based on rules that you define and not only can",
    "start": "517570",
    "end": "525220"
  },
  {
    "text": "you do notifications you can also you can also diagnose issues so you can",
    "start": "525220",
    "end": "530410"
  },
  {
    "text": "inspect your logs you can correlate across different metrics and this is so new you can actually jump to your",
    "start": "530410",
    "end": "535839"
  },
  {
    "text": "from your metrics so if you have a metrical generator from custom log you can see all the actual logs that are",
    "start": "535839",
    "end": "541569"
  },
  {
    "text": "generating that are causing that metric to go off and you can also automatically",
    "start": "541569",
    "end": "547660"
  },
  {
    "text": "correct issues so you can trigger scaling event so you can trigger notifications you can trigger lambda functions and do all kinds of things to",
    "start": "547660",
    "end": "554110"
  },
  {
    "text": "resolve your actual issues let's talk about some recent improvements with them last year in cloud cloud watch & Klarich",
    "start": "554110",
    "end": "561309"
  },
  {
    "text": "logs as well so we've dropped the prices of custom metrics we've added more metrics from different services we've",
    "start": "561309",
    "end": "568689"
  },
  {
    "text": "made navigating from those metrics to your logs a lot easier as I mentioned earlier we've upgraded metric retention",
    "start": "568689",
    "end": "574660"
  },
  {
    "text": "so it used to be that your cloud much data would only be there for two weeks it's now up to 15 months we've added",
    "start": "574660",
    "end": "581860"
  },
  {
    "text": "support for arbitrary metric percentiles we've added a click D plugin which is good really big so that's a lot easier",
    "start": "581860",
    "end": "587920"
  },
  {
    "text": "to do custom metrics with that we've improved how our dashboards functionality works and the console",
    "start": "587920",
    "end": "593920"
  },
  {
    "text": "experience in general and just recently we took metrics resolution from a",
    "start": "593920",
    "end": "599139"
  },
  {
    "text": "minimum of one minute to one second so you can get much more detailed metrics",
    "start": "599139",
    "end": "604300"
  },
  {
    "text": "resolution now and we've allowed you to choose how you treat missing log data so do you treat that as good or bad and you",
    "start": "604300",
    "end": "611620"
  },
  {
    "text": "can also add default values for missing log data as well so aside from cloud",
    "start": "611620",
    "end": "618730"
  },
  {
    "text": "watch every team of our customers they all have unique needs and we have a rich",
    "start": "618730",
    "end": "625629"
  },
  {
    "text": "partner ecosystem so we have all kinds of partners I'm sure some of them are out there in the exhibit hall it can also help you with logging and our tools",
    "start": "625629",
    "end": "631779"
  },
  {
    "text": "integrate with our partner services as well pretty often so the locks part of",
    "start": "631779",
    "end": "639759"
  },
  {
    "text": "the cloud watch services cloud watch logs so you can both control you have a lot of flexibility on what goes into",
    "start": "639759",
    "end": "646120"
  },
  {
    "text": "cloud watch logs and where it sends those logs so you can take logs from ec2 from cloud trail from lambda from ECS",
    "start": "646120",
    "end": "653139"
  },
  {
    "text": "and also from any custom source with a cloud watch log of the agent or you're just using our API and then you can take",
    "start": "653139",
    "end": "660939"
  },
  {
    "text": "those logs you can search them centralize that monitor them retain them in caller watch logs because of them",
    "start": "660939",
    "end": "667360"
  },
  {
    "text": "send them to s3 to lambda2 elasticsearch took two Kinesis as well",
    "start": "667360",
    "end": "673170"
  },
  {
    "text": "so before i start with talking about specific examples here let's just do a really high-level overview what lambda",
    "start": "673170",
    "end": "679360"
  },
  {
    "text": "is because it's going to be part of these examples so so lambda is our server list compute service so you can",
    "start": "679360",
    "end": "686770"
  },
  {
    "text": "run arbitrary code without having to spin up any servers or even any containers or anything you just give us",
    "start": "686770",
    "end": "693130"
  },
  {
    "text": "the code right now we support Java nodejs c-sharp and python and lambda and",
    "start": "693130",
    "end": "700240"
  },
  {
    "text": "it's event-driven so you can kick it off on a schedule you can cook it off arbitrarily or you can kick it off from",
    "start": "700240",
    "end": "705400"
  },
  {
    "text": "something like a file dropping in tennis three bucket which I'll show you how to do so let's look at our first example",
    "start": "705400",
    "end": "711760"
  },
  {
    "text": "and what I'm going to do is I'm going to walk through the example of screenshots and then I'm going to show you on my actual computer how this actually works",
    "start": "711760",
    "end": "718060"
  },
  {
    "text": "so the first example is we're going to centralize logs from Anna I'll be using",
    "start": "718060",
    "end": "724000"
  },
  {
    "text": "Amazon s3 based bucket triggers so let's take a look at the actual problem here",
    "start": "724000",
    "end": "729330"
  },
  {
    "text": "so log data by default if you have logs on your nginx or Apache or whatever your",
    "start": "729330",
    "end": "736720"
  },
  {
    "text": "web server is there are going to be scattered on each instance or different s3 buckets and we'd like to centralize",
    "start": "736720",
    "end": "743530"
  },
  {
    "text": "those logs now one thing you can do is just put the cloud watch logs agent on your instance but what if you just want",
    "start": "743530",
    "end": "748570"
  },
  {
    "text": "to have the log collection happen add the load balancer so you'll be an ale be have this option for excess logs so you",
    "start": "748570",
    "end": "755650"
  },
  {
    "text": "just have to enable it and then those logs go to s3 which is great but once they're in s3 what if we want to push",
    "start": "755650",
    "end": "762100"
  },
  {
    "text": "them to cloud watch logs so we can do these metrics filters on them and all kinds of more advanced functionality with analyzing those logs so how do we",
    "start": "762100",
    "end": "769870"
  },
  {
    "text": "do this well so we take the logs that are in s3 we enable we use a a s3 to",
    "start": "769870",
    "end": "777760"
  },
  {
    "text": "trigger a lambda function so every time there's a new object created in in the specific bucket in s3 it's gonna trigger",
    "start": "777760",
    "end": "783550"
  },
  {
    "text": "the slam in the function the lambda function is going to read the log from this three bucket and publishes a cloud watch logs so what you should do to do",
    "start": "783550",
    "end": "791740"
  },
  {
    "text": "this is you would spin up three ec2 instances they should be running Apache or nginx or any other kind of web server",
    "start": "791740",
    "end": "797680"
  },
  {
    "text": "you then configure a little balancer with those three instances in them",
    "start": "797680",
    "end": "803040"
  },
  {
    "text": "the load balancer it will assuming it's an al B is gonna have a target group again with the three instances you're",
    "start": "803040",
    "end": "809040"
  },
  {
    "text": "going to enable log delivery to an s3 bucket from that ELB or al B and then",
    "start": "809040",
    "end": "815910"
  },
  {
    "text": "you're going to configure your trigger so your trigger is gonna take anything that's created in this bucket it's gonna",
    "start": "815910",
    "end": "822120"
  },
  {
    "text": "trigger the lambda function so what the lambda function does and this codes all",
    "start": "822120",
    "end": "827160"
  },
  {
    "text": "on on our github repo I'll have a link to it later and you'll be have access to copies of these slides so it reads the",
    "start": "827160",
    "end": "835139"
  },
  {
    "text": "logs from this three bucket by using this three get object API it then posts",
    "start": "835139",
    "end": "841079"
  },
  {
    "text": "logs into cloud watch logs using the put logs events API which is a cloud watch loggers API and all you need again is to",
    "start": "841079",
    "end": "849750"
  },
  {
    "text": "just go to your ill be generate some traffic so I hit you know refresh on your yell B and you can watch the logs",
    "start": "849750",
    "end": "856260"
  },
  {
    "text": "then show up it takes about five minutes for them to show up in s3 once they're in s3 you can then almost",
    "start": "856260",
    "end": "863940"
  },
  {
    "text": "immediately see them also populate in cloud watch logs once they're in cloud watch logs you can do things that you",
    "start": "863940",
    "end": "870389"
  },
  {
    "text": "can't do when there's just straight in s3 so you can for example search for all HTTP gets in the last 24 hours and that",
    "start": "870389",
    "end": "877649"
  },
  {
    "text": "you just do get HTTP it's pretty simple search if you do more advanced things you can set up a filter pattern that",
    "start": "877649",
    "end": "884010"
  },
  {
    "text": "extracts requests but only with the latency of more than one millisecond so you can get slow requests and then once",
    "start": "884010",
    "end": "891810"
  },
  {
    "text": "you have that metric filter it's gonna what it's going to do is it's going to give you a custom cloud watch metric",
    "start": "891810",
    "end": "899130"
  },
  {
    "text": "once you have the metric you'll be able to graph it so you can see over time your Layton's or the highlight how many",
    "start": "899130",
    "end": "905880"
  },
  {
    "text": "high latency requests are T or lb so the key takeaways here are you can take",
    "start": "905880",
    "end": "912600"
  },
  {
    "text": "anything that's in s3 and send it to cloud watch logs and you can search and extract those metrics in real time so",
    "start": "912600",
    "end": "918240"
  },
  {
    "text": "let's switch to my screen here I'll show you how this actually works all right so",
    "start": "918240",
    "end": "923510"
  },
  {
    "text": "here's my screen so here's my ec2 instance so this is just an EOB the elbe",
    "start": "923510",
    "end": "931860"
  },
  {
    "text": "and my OB I have you listener on port 80 and here we go",
    "start": "931860",
    "end": "936870"
  },
  {
    "text": "is gonna refresh all right so it's gonna",
    "start": "936870",
    "end": "942120"
  },
  {
    "text": "have a listener on port 80 there we go let me actually move this up and I've",
    "start": "942120",
    "end": "949380"
  },
  {
    "text": "got one instance in my in my LB and my",
    "start": "949380",
    "end": "956400"
  },
  {
    "text": "instance is just just running nginx so this is the actual instance let's",
    "start": "956400",
    "end": "962090"
  },
  {
    "text": "refresh it a few times so nothing special here and so on my TLB I have",
    "start": "962090",
    "end": "967530"
  },
  {
    "text": "logs enabled so as you can see here I have logs enable 2-3 bucket and we can",
    "start": "967530",
    "end": "977160"
  },
  {
    "text": "see the logs right here so here are the extra logs these are but these are zip",
    "start": "977160",
    "end": "984060"
  },
  {
    "text": "files right so they're not super useful to me I'm entitled them and attract them",
    "start": "984060",
    "end": "989190"
  },
  {
    "text": "and look into them so what I'm going to do instead is I have this lambda function here so my lambda function has",
    "start": "989190",
    "end": "996000"
  },
  {
    "text": "a trigger so that trigger again it's",
    "start": "996000",
    "end": "1001040"
  },
  {
    "text": "looking at this s3 bucket it's looking for object created so anytime a new file",
    "start": "1001040",
    "end": "1006320"
  },
  {
    "text": "drops in here it's gonna trigger this lambda function and we can see here it's been triggered a few times over the last",
    "start": "1006320",
    "end": "1012620"
  },
  {
    "text": "a few minutes and if we go to cloud watch logs this is my let me just go",
    "start": "1012620",
    "end": "1019190"
  },
  {
    "text": "back here I have different allowed groups so if we go to the log group for nginx logs I can actually see all of my",
    "start": "1019190",
    "end": "1027589"
  },
  {
    "text": "logs centralized in one location here so this is a pretty simple one to setup so",
    "start": "1027589",
    "end": "1033500"
  },
  {
    "text": "let's go back to my slides and we'll look at example number two here so in",
    "start": "1033500",
    "end": "1038990"
  },
  {
    "text": "the second example I'm going to take alarms and generally when you get an",
    "start": "1038990",
    "end": "1044000"
  },
  {
    "text": "alarm from cloud watch it just tells you you have an alarm this metric has been",
    "start": "1044000",
    "end": "1049070"
  },
  {
    "text": "this threshold has been exceeded which is great but I'd love to get like more specific information on that so I'm",
    "start": "1049070",
    "end": "1055370"
  },
  {
    "text": "gonna do it an actual a custom email that it's gonna send me every time an alarm is sugar that gives me more information",
    "start": "1055370",
    "end": "1060830"
  },
  {
    "text": "so the flow of vents here is I've cloud watch logs and air in the law",
    "start": "1060830",
    "end": "1067100"
  },
  {
    "text": "generates an alarm metal our that gets posted 10 s and s topic my email address",
    "start": "1067100",
    "end": "1072830"
  },
  {
    "text": "is a subscriber of that SMS topic so I get an email every time there's an alarm but again that just tells me there's an",
    "start": "1072830",
    "end": "1080120"
  },
  {
    "text": "arm happening it's not super useful so what I'm also going to do is I'm gonna have this SNS topic trigger another",
    "start": "1080120",
    "end": "1086809"
  },
  {
    "text": "lambda function this lambda function is gonna get the actual log results that are triggering the alert and it's gonna",
    "start": "1086809",
    "end": "1093110"
  },
  {
    "text": "email me those log results and it's also going to email me a link to which AWS account it is the playbook or runbook",
    "start": "1093110",
    "end": "1101120"
  },
  {
    "text": "for how to fix the specific thing a lot any anything else you want to add to it it's going to use Amazon SES to send",
    "start": "1101120",
    "end": "1107120"
  },
  {
    "text": "that email so what I would do here is you spin up an ec2 instance that you see to instance again can have a little say",
    "start": "1107120",
    "end": "1113299"
  },
  {
    "text": "Tomcat running in it we're gonna install the cloud watch logs agent on the",
    "start": "1113299",
    "end": "1119600"
  },
  {
    "text": "instance the agent is gonna send all of the logs so we've got Patchi running on",
    "start": "1119600",
    "end": "1124940"
  },
  {
    "text": "the instance it's proxying to Tomcat it's the pachi access logs are all being",
    "start": "1124940",
    "end": "1129980"
  },
  {
    "text": "sent to cloud watch logs so they show up watch logs then we're going to find another filter",
    "start": "1129980",
    "end": "1135049"
  },
  {
    "text": "pattern here so what I want to know is any time someone tries to do an unauthorized access attempt against my",
    "start": "1135049",
    "end": "1142510"
  },
  {
    "text": "my Tomcat here so it's gonna look for status code for ones and anytime I get a",
    "start": "1142510",
    "end": "1148460"
  },
  {
    "text": "status code for one it's gonna add another value to this metric here I'm",
    "start": "1148460",
    "end": "1153679"
  },
  {
    "text": "gonna call unauthorized access so then I'm going to create an alarm off of that",
    "start": "1153679",
    "end": "1158780"
  },
  {
    "text": "metric so in this alarm we're gonna say if there are more than 500 authorized access attempts over one minute then",
    "start": "1158780",
    "end": "1166250"
  },
  {
    "text": "this alarm is going to be triggered and that alarm is gonna send an email to an",
    "start": "1166250",
    "end": "1171350"
  },
  {
    "text": "SNS topic again we're gonna hook up that SNS topic to a lambda function that's",
    "start": "1171350",
    "end": "1176900"
  },
  {
    "text": "gonna be the trigger do you lambda function and what it's gonna do is it's gonna get the metric filter information",
    "start": "1176900",
    "end": "1181940"
  },
  {
    "text": "using describe metric filters the API it's gonna then get the actual log data",
    "start": "1181940",
    "end": "1187580"
  },
  {
    "text": "by invoking the filter log events API and it's gonna then use SES to send me",
    "start": "1187580",
    "end": "1193669"
  },
  {
    "text": "an email with the log data letting me know what's actually going on here and so then just to trigger it all I need to",
    "start": "1193669",
    "end": "1200210"
  },
  {
    "text": "do is actually cause a 401 so I'm gonna go to a web page where I need to authenticate and hit cancel a login page a few times",
    "start": "1200210",
    "end": "1206640"
  },
  {
    "text": "and this is the email that I would get just from the regular alarm so in this",
    "start": "1206640",
    "end": "1212580"
  },
  {
    "text": "email it's telling me you know what they'll arm actually is and the threshold has been crossed it's great",
    "start": "1212580",
    "end": "1218940"
  },
  {
    "text": "again not super useful this is the alarm that my lambda functions gonna send me so it's gonna give me a link to the run",
    "start": "1218940",
    "end": "1224580"
  },
  {
    "text": "book it's gonna give me an account ID which I've taken out here and it's gonna",
    "start": "1224580",
    "end": "1231030"
  },
  {
    "text": "tell me what region this is in you know tell me the exact time of the alarm and the most useful part is going to show me",
    "start": "1231030",
    "end": "1236430"
  },
  {
    "text": "the actual logs it's gonna show me the contents of the locks so let's switch",
    "start": "1236430",
    "end": "1242100"
  },
  {
    "text": "back to my screen alright so let me just let's see if I get the right window here yep this is it",
    "start": "1242100",
    "end": "1252750"
  },
  {
    "text": "so I've got my instance so this is Tomcat right here so just running Tomcat on my instance I've got a dashboard this",
    "start": "1252750",
    "end": "1260820"
  },
  {
    "text": "is actually the metric it's showing me every time this is triggered so before we do anything let's go to my tomcat instance and I'm going to trigger a few",
    "start": "1260820",
    "end": "1266910"
  },
  {
    "text": "more of these alarms here so I'm just gonna cancel just a few times so",
    "start": "1266910",
    "end": "1274710"
  },
  {
    "text": "hopefully it'll send me an email soon so let's take a look at again what we have",
    "start": "1274710",
    "end": "1280020"
  },
  {
    "text": "here so this is again this is just I have the cloud watch logs agent running",
    "start": "1280020",
    "end": "1285570"
  },
  {
    "text": "on my instance and see it's far along HTTP access logs so it's sending that and it creates a different log stream",
    "start": "1285570",
    "end": "1291630"
  },
  {
    "text": "for every instance since I'm running this on only one instance there's only one mock stream and here's the actual logging data and then what I have here",
    "start": "1291630",
    "end": "1300420"
  },
  {
    "text": "is so if we look at the logs I've got one I've got one filter here so this is",
    "start": "1300420",
    "end": "1308790"
  },
  {
    "text": "again the filter that I made in the screenshot so you know just looking for for Oh ones so if I test my pattern I've",
    "start": "1308790",
    "end": "1316410"
  },
  {
    "text": "got 38 matches on it and I've got an alarm attached to this and my alarm",
    "start": "1316410",
    "end": "1321530"
  },
  {
    "text": "again right now it's ok it's gonna take a few minutes I think to process but",
    "start": "1321530",
    "end": "1327300"
  },
  {
    "text": "basically what happens is I've got my lambda function here if we look at the triggers its triggering off of this SNS",
    "start": "1327300",
    "end": "1333690"
  },
  {
    "text": "topic if we look at the monitoring here this is how often it's been invoked and let",
    "start": "1333690",
    "end": "1340830"
  },
  {
    "text": "me just see here one second so yep I actually just got some emails here I'll",
    "start": "1340830",
    "end": "1347310"
  },
  {
    "text": "show you what I got so this is my email for the actual one",
    "start": "1347310",
    "end": "1355080"
  },
  {
    "text": "generated by the alarm itself so again not super useful and then this is the email generated by my lambda function so",
    "start": "1355080",
    "end": "1362940"
  },
  {
    "text": "this is way more useful so this national log data so that works so let's switch",
    "start": "1362940",
    "end": "1369420"
  },
  {
    "text": "back to the slides and as you can see it sent me that email almost",
    "start": "1369420",
    "end": "1375900"
  },
  {
    "text": "instantaneously so the nice thing is like I should be the demo right but as I",
    "start": "1375900",
    "end": "1380910"
  },
  {
    "text": "was doing it it took about a minute for me to get an alarm that something was going on that I was trying to do",
    "start": "1380910",
    "end": "1386190"
  },
  {
    "text": "authorities accessed against my Tomcat instance so again just some takeaways from this example you can customize your alarms to",
    "start": "1386190",
    "end": "1393660"
  },
  {
    "text": "add specific details that you need when you see a spike in a metric you can also get those specific logs triggered by the",
    "start": "1393660",
    "end": "1398880"
  },
  {
    "text": "alarm and you can give them near real-time and you can use lambda to give",
    "start": "1398880",
    "end": "1405990"
  },
  {
    "text": "the specific information and again the lambda function you're paying every time",
    "start": "1405990",
    "end": "1411480"
  },
  {
    "text": "is triggered so by the hundred milliseconds it's very inexpensive you don't have to a permanent instance",
    "start": "1411480",
    "end": "1417240"
  },
  {
    "text": "running to process these things which is great so let's take a look at the third example here so we have this Amazon",
    "start": "1417240",
    "end": "1424740"
  },
  {
    "text": "Elastic search service and its built-in functionality in in flow logs and",
    "start": "1424740",
    "end": "1431310"
  },
  {
    "text": "specifically in a in cloud watch logs they you can send any of your cloud watch log streams to Amazon Elastic",
    "start": "1431310",
    "end": "1437640"
  },
  {
    "text": "search but what if I don't want to have a permanent running cluster what if just one some incident happens or one",
    "start": "1437640",
    "end": "1442680"
  },
  {
    "text": "specific need arises I want to I want to spin up an on-demand elasticsearch",
    "start": "1442680",
    "end": "1448170"
  },
  {
    "text": "cluster I want to send some log data to that cluster in this case we're gonna do",
    "start": "1448170",
    "end": "1453210"
  },
  {
    "text": "VPC flow logs for a certain time period and I want to build that cluster from",
    "start": "1453210",
    "end": "1459030"
  },
  {
    "text": "this historical data I want to do some analysis of it and then I want to shut it down so I don't want to have to pay",
    "start": "1459030",
    "end": "1464070"
  },
  {
    "text": "for a I'm going cluster so the flow of events here is we've got our cloud watch logs they're",
    "start": "1464070",
    "end": "1470790"
  },
  {
    "text": "going they're getting stored in or we got our flow logs they're being stored in cloud watch logs we're gonna take a",
    "start": "1470790",
    "end": "1478230"
  },
  {
    "text": "specific time frame so I don't want all of them I just want a specific time frame like a day or a week we're going to export them to s3 we're going to use",
    "start": "1478230",
    "end": "1485370"
  },
  {
    "text": "again the s3 objects being created as a trigger for a lambda function the lament",
    "start": "1485370",
    "end": "1491550"
  },
  {
    "text": "of function of what it's going to do is it's gonna actually transform that log data from the native flow logs format",
    "start": "1491550",
    "end": "1500100"
  },
  {
    "text": "into JSON which is something that elasticsearch can it can read and it's gonna send those two elasticsearch and",
    "start": "1500100",
    "end": "1506990"
  },
  {
    "text": "you're gonna take a look at your elasticsearch cluster you're gonna take a look Kabana you're gonna analyze them you're going to shut down your cluster",
    "start": "1506990",
    "end": "1512520"
  },
  {
    "text": "so the first thing you have to do is turn on flow logging you can turn on flow logging on a VP sea level or per",
    "start": "1512520",
    "end": "1519690"
  },
  {
    "text": "eni in this case I'm just turning on for my whole VP see you can almost",
    "start": "1519690",
    "end": "1525030"
  },
  {
    "text": "immediately then see the actual contents of the flow logs in your cloud watch logs we're then gonna spin up an elastic",
    "start": "1525030",
    "end": "1533040"
  },
  {
    "text": "search domain we're gonna have this lambda function the lambda function is",
    "start": "1533040",
    "end": "1539940"
  },
  {
    "text": "gonna again every time that the the every time that is triggered it's gonna",
    "start": "1539940",
    "end": "1546210"
  },
  {
    "text": "actually use the get object API which is part of its 3 API and it's gonna read",
    "start": "1546210",
    "end": "1551790"
  },
  {
    "text": "the flow logs from this three bucket it's gonna transform them into JSON document and then it's going to ingest",
    "start": "1551790",
    "end": "1557700"
  },
  {
    "text": "them into my elastic search service and then to actually do this I'll show you",
    "start": "1557700",
    "end": "1566490"
  },
  {
    "text": "how to do it in a second but basically you just export the flow logs to s3 certain interval of them you verify that",
    "start": "1566490",
    "end": "1573240"
  },
  {
    "text": "they're actually showing up in s3 and then you look at them kumano and the elastic search and do whatever you need",
    "start": "1573240",
    "end": "1579600"
  },
  {
    "text": "to do with them and then you get all kinds of cool dashboards and you can",
    "start": "1579600",
    "end": "1586110"
  },
  {
    "text": "then shut it down on you too so let's switch back to my screen here alright so",
    "start": "1586110",
    "end": "1593389"
  },
  {
    "text": "let's take a look at this here",
    "start": "1593690",
    "end": "1598039"
  },
  {
    "text": "all right so we've got my V PC here just",
    "start": "1600289",
    "end": "1606179"
  },
  {
    "text": "to show you I have a flow log enabled here so it's going for all traffic in my",
    "start": "1606179",
    "end": "1611700"
  },
  {
    "text": "V PC we can see this if we look at my actual logs I don't have a lot of stuff",
    "start": "1611700",
    "end": "1618869"
  },
  {
    "text": "running in my V PC but these are all the elastic network interfaces at my V PC and this is all of the raw data so this",
    "start": "1618869",
    "end": "1625200"
  },
  {
    "text": "is the actual flow log data which is great but what we actually want to do is",
    "start": "1625200",
    "end": "1630739"
  },
  {
    "text": "we want to export this data so you go here so yeah I want to export and say",
    "start": "1630739",
    "end": "1637759"
  },
  {
    "text": "the last so let's say a month's worth of data into this s3 bucket that I have so",
    "start": "1637759",
    "end": "1644519"
  },
  {
    "text": "I'm just going to export it and so I'll just verify the direction here so this",
    "start": "1644519",
    "end": "1649739"
  },
  {
    "text": "is -3 bucket that I just exported to so it looks like we've got a bunch of different folders here yeah this is the",
    "start": "1649739",
    "end": "1656399"
  },
  {
    "text": "new one right so this is the actual export right so these are all the logs but again they're gzip so they're not",
    "start": "1656399",
    "end": "1661529"
  },
  {
    "text": "super useful so let's take a look at my show lambda function now so here's lambda here is this the trigger for it",
    "start": "1661529",
    "end": "1671309"
  },
  {
    "text": "again is so anytime something goes into this s3 bucket I just showed you this",
    "start": "1671309",
    "end": "1677519"
  },
  {
    "text": "triggers the function we can take a look here at the so every time it gets",
    "start": "1677519",
    "end": "1682919"
  },
  {
    "text": "triggered and let's take a look at the actual logs let's see this another cool thing that you can do here so again",
    "start": "1682919",
    "end": "1689369"
  },
  {
    "text": "we're back in cloud much logs and these are the actual execution logs of my lambda function so here let's take a",
    "start": "1689369",
    "end": "1695220"
  },
  {
    "text": "look at a recent execution so you know so we can see here it looked at one of",
    "start": "1695220",
    "end": "1701700"
  },
  {
    "text": "the gzip files that unzipped it it read it there's a bad line in there but otherwise it imported all the data in",
    "start": "1701700",
    "end": "1707099"
  },
  {
    "text": "here successfully all right so let's",
    "start": "1707099",
    "end": "1713519"
  },
  {
    "text": "also take a look here just well the only thing I really configured in this functional is I just",
    "start": "1713519",
    "end": "1719580"
  },
  {
    "text": "put in my actual end point for my elasticsearch cluster my actual elasticsearch it's right here it's",
    "start": "1719580",
    "end": "1724950"
  },
  {
    "text": "pretty simple I didn't do anything special I just spun it up and waited a few minutes and so let's take a look at",
    "start": "1724950",
    "end": "1730050"
  },
  {
    "text": "my actual Cabana here so this might take just gonna take a few seconds to load",
    "start": "1730050",
    "end": "1735270"
  },
  {
    "text": "looks it does it will just show me a dashboard with all of my actual logs in",
    "start": "1735270",
    "end": "1742080"
  },
  {
    "text": "it and then I can yeah there we go",
    "start": "1742080",
    "end": "1746630"
  },
  {
    "text": "yep so this is my logs I can see a timeline I just created this VPC today",
    "start": "1747560",
    "end": "1753540"
  },
  {
    "text": "so only got traffic from today but this is all the traffic and I can look at it and inspect it and look through all the",
    "start": "1753540",
    "end": "1759420"
  },
  {
    "text": "fields and all that cool stuff alright so let's go back to my slides so just",
    "start": "1759420",
    "end": "1765240"
  },
  {
    "text": "some key takeaways so we can take any period of historical data we can export",
    "start": "1765240",
    "end": "1771150"
  },
  {
    "text": "it to an elastic search cluster we can shut down the cluster and it makes troubleshooting a lot easier so just to",
    "start": "1771150",
    "end": "1778260"
  },
  {
    "text": "recap so monitoring is really important but it's also hard and our services are",
    "start": "1778260",
    "end": "1784560"
  },
  {
    "text": "here so cloud watching Club which long as lambda elastic search all here to make logging easier for you and there",
    "start": "1784560",
    "end": "1790590"
  },
  {
    "text": "are powerful tools that you can use to tailor to your specific needs and just some useful links here we've got our",
    "start": "1790590",
    "end": "1796710"
  },
  {
    "text": "website for a cloud watch we've got really good documentation on a blog and",
    "start": "1796710",
    "end": "1801720"
  },
  {
    "text": "more importantly the last part here is all of the code for all the demos I showed you it's on our ADA based labs",
    "start": "1801720",
    "end": "1808620"
  },
  {
    "text": "github repo so you can do this at home pretty easily and there's walkthroughs and pretty good documentation all this",
    "start": "1808620",
    "end": "1814980"
  },
  {
    "text": "and so thank you for your time remember to complete your evaluations and enjoy",
    "start": "1814980",
    "end": "1821790"
  },
  {
    "text": "the rest of the summit Thanks [Applause]",
    "start": "1821790",
    "end": "1827700"
  }
]
[
  {
    "start": "0",
    "end": "144000"
  },
  {
    "text": "Hey nice to see if that there is almost full room I'm a little bit disappointed",
    "start": "0",
    "end": "7830"
  },
  {
    "text": "though there are free seats everywhere and I just heard that this Netflix guy",
    "start": "7830",
    "end": "12840"
  },
  {
    "text": "is having like a team presentations here Oh like so I'm not there yet and yeah my",
    "start": "12840",
    "end": "22590"
  },
  {
    "text": "name is Henry Hayes panin I'm from Finland this is how we talk so you can",
    "start": "22590",
    "end": "29490"
  },
  {
    "text": "actually play a game today there are other people from Finland so spot F in a",
    "start": "29490",
    "end": "36890"
  },
  {
    "text": "yeah great to be here in Las Vegas this is actually my second time in u.s. last",
    "start": "37309",
    "end": "44100"
  },
  {
    "text": "time I have I've seen Miami both times I had the transfer in JFK do",
    "start": "44100",
    "end": "49980"
  },
  {
    "text": "you know what actually combines all these three nice cities yeah that one",
    "start": "49980",
    "end": "59930"
  },
  {
    "text": "they have the best crime-scene investigators in the world have you",
    "start": "59930",
    "end": "65430"
  },
  {
    "text": "watched the show it's amazing I mean it's like this gil grissom great guy he",
    "start": "65430",
    "end": "74159"
  },
  {
    "text": "has a great team I mean it's like that's like really some team like what I would like to have a cross-functional team",
    "start": "74159",
    "end": "81060"
  },
  {
    "text": "they have coroner coroner but anyone can pick up a scalpel in the in the one",
    "start": "81060",
    "end": "88770"
  },
  {
    "text": "scene and start like cutting people and I mean that's what I like there are like expert on some area but then everyone",
    "start": "88770",
    "end": "94920"
  },
  {
    "text": "can do something a little bit something so I kind of if someone joins my team I",
    "start": "94920",
    "end": "101070"
  },
  {
    "text": "always tell them to hey watch the episode and CSI where they buried this",
    "start": "101070",
    "end": "106979"
  },
  {
    "text": "guy in there and then like one of the members of the team and then they try to find it like that's that's teamwork",
    "start": "106979",
    "end": "113070"
  },
  {
    "text": "I also they actually look great when they are doing that work they are doing",
    "start": "113070",
    "end": "118320"
  },
  {
    "text": "so I actually suggest it to HR that should we have like personal appearance",
    "start": "118320",
    "end": "123810"
  },
  {
    "text": "as a part of our targets HR they didn't like it that's why I have a little bit",
    "start": "123810",
    "end": "130289"
  },
  {
    "text": "of this it's not on my kpi's maybe next year okay",
    "start": "130289",
    "end": "139190"
  },
  {
    "text": "so building a lake of wisdom before we",
    "start": "139190",
    "end": "145470"
  },
  {
    "start": "144000",
    "end": "162000"
  },
  {
    "text": "start a little bit more Who am I",
    "start": "145470",
    "end": "150379"
  },
  {
    "text": "according to Hollywood comm I'm a Hollywood production executive but",
    "start": "150650",
    "end": "158700"
  },
  {
    "text": "Hollywood hasn't called me back yet that's why I'm moonlighting as a data",
    "start": "158700",
    "end": "164760"
  },
  {
    "start": "162000",
    "end": "196000"
  },
  {
    "text": "engineering lead at Romeo games I recently got promoted now I'm a director",
    "start": "164760",
    "end": "170519"
  },
  {
    "text": "of data engineering and you all know what that means all the recruitment image which used to",
    "start": "170519",
    "end": "178319"
  },
  {
    "text": "start like hey are you interested they are like oh do you know anyone who is interested so I don't know if I have a",
    "start": "178319",
    "end": "185030"
  },
  {
    "text": "any career after Rovio gig or after they",
    "start": "185030",
    "end": "190859"
  },
  {
    "text": "speak so yeah I've been doing software",
    "start": "190859",
    "end": "199040"
  },
  {
    "start": "196000",
    "end": "266000"
  },
  {
    "text": "development for 20 years I profile myself as a coding architect 20 years is",
    "start": "199040",
    "end": "209160"
  },
  {
    "text": "quite a long time I some time ago I had a meeting like talking about big data",
    "start": "209160",
    "end": "214950"
  },
  {
    "text": "trains to our chairman of the board like what are the big data trains but because",
    "start": "214950",
    "end": "220889"
  },
  {
    "text": "I wasn't able to talk about machine learning so I was all like talking",
    "start": "220889",
    "end": "226200"
  },
  {
    "text": "everything but machine learning so then I I said to him that well the rents are in my opinion that if you would be in",
    "start": "226200",
    "end": "232709"
  },
  {
    "text": "like deep-frozen for 20 years and then you would be kind of broken up again I",
    "start": "232709",
    "end": "238849"
  },
  {
    "text": "claimed that nothing really has changed because all the peak data processing and everything it's like running SQL in some",
    "start": "238849",
    "end": "245040"
  },
  {
    "text": "like database I think that like SQL might be like what COBOL was for like 97",
    "start": "245040",
    "end": "252299"
  },
  {
    "text": "or something like that so please HR people keep eye out of those like for",
    "start": "252299",
    "end": "259739"
  },
  {
    "text": "the 50 something guys database administrators and database engineers",
    "start": "259739",
    "end": "267020"
  },
  {
    "text": "I've been now doing five years of analytics so I was in my previous",
    "start": "267150",
    "end": "275010"
  },
  {
    "text": "company I was the I was in a telecom",
    "start": "275010",
    "end": "281639"
  },
  {
    "text": "company who was doing this kind of a mediation software and then they acquire the analytics company and I was",
    "start": "281639",
    "end": "288750"
  },
  {
    "text": "responsible to then I was a lead architect and I was my my job was to",
    "start": "288750",
    "end": "293820"
  },
  {
    "text": "integrate that into into this Jellico product so that was my intro into actual",
    "start": "293820",
    "end": "301169"
  },
  {
    "text": "analytics and then after doing that for two years I then joined Rovio as a well",
    "start": "301169",
    "end": "306510"
  },
  {
    "text": "at the mall then I was like analytics lead but I pretty much have the same to him for all that time",
    "start": "306510",
    "end": "314389"
  },
  {
    "start": "314000",
    "end": "384000"
  },
  {
    "text": "then Lake of wisdom how many have you",
    "start": "314690",
    "end": "319979"
  },
  {
    "text": "seen the movie Angry Birds so for you you should see it",
    "start": "319979",
    "end": "327000"
  },
  {
    "text": "it's really great I hope I can advertise because from kind",
    "start": "327000",
    "end": "333300"
  },
  {
    "text": "of advertising Amazon as well so I think we can like hey it's really great and",
    "start": "333300",
    "end": "338789"
  },
  {
    "text": "there's a scene there's a this lake of wisdom is the place where this wise",
    "start": "338789",
    "end": "344900"
  },
  {
    "text": "Mighty Eagle lives and he lives next to this Lake of wisdom and and actually in",
    "start": "344900",
    "end": "352860"
  },
  {
    "text": "that movie something happens and it's quite funny this is a little bit of",
    "start": "352860",
    "end": "359970"
  },
  {
    "text": "spoiler but there is a little bit of pee in the water and I don't want you to",
    "start": "359970",
    "end": "365940"
  },
  {
    "text": "associate that the idea was that it's something about something that that's",
    "start": "365940",
    "end": "373080"
  },
  {
    "text": "like you can associate with data lakes and also do a Angry Birds brand so yes",
    "start": "373080",
    "end": "380820"
  },
  {
    "text": "we are talking about data Lake here today a little bit of agenda so first I",
    "start": "380820",
    "end": "386909"
  },
  {
    "start": "384000",
    "end": "408000"
  },
  {
    "text": "will talk a little bit like a little bit about Rovio and what data means to us and then I talk walk you through on semi",
    "start": "386909",
    "end": "396900"
  },
  {
    "text": "high-level how did we build this data Lake and then I also share a few of the",
    "start": "396900",
    "end": "402330"
  },
  {
    "text": "learnings what we learned during this process possible takeaways you can see",
    "start": "402330",
    "end": "411479"
  },
  {
    "start": "408000",
    "end": "439000"
  },
  {
    "text": "on the screen I would say that the main one is that one highlighted there that",
    "start": "411479",
    "end": "417199"
  },
  {
    "text": "how if you are planning of building this data like how should you build it and I",
    "start": "417199",
    "end": "424710"
  },
  {
    "text": "don't say that you should build it exactly how I did it depends a little bit on your use case but hopefully this",
    "start": "424710",
    "end": "431039"
  },
  {
    "text": "gives you some ideas of the services and methods that are out there for you to",
    "start": "431039",
    "end": "436590"
  },
  {
    "text": "build it up then about Rovio and data",
    "start": "436590",
    "end": "445370"
  },
  {
    "start": "445000",
    "end": "535000"
  },
  {
    "text": "some fact sheet of Rovio so we are the",
    "start": "445639",
    "end": "451440"
  },
  {
    "text": "Angry Birds company we are nowadays public company then I need that's why I need to be a little bit careful what I",
    "start": "451440",
    "end": "457289"
  },
  {
    "text": "say so these are corporate approved fact",
    "start": "457289",
    "end": "464210"
  },
  {
    "text": "you can read them maybe something a little bit more interesting I just hey there is like 11 million daily active",
    "start": "464960",
    "end": "471719"
  },
  {
    "text": "users so that's how many people play our games on daily basis and but we are not",
    "start": "471719",
    "end": "479189"
  },
  {
    "text": "just Angry Birds company we we do other things as well for example game called paddle Bay it's",
    "start": "479189",
    "end": "486389"
  },
  {
    "text": "a real-time multiplayer battle with boats so think about World of Tanks kind of",
    "start": "486389",
    "end": "493110"
  },
  {
    "text": "thing but with boats it's awesome so guy sitting there who is top 10",
    "start": "493110",
    "end": "500669"
  },
  {
    "text": "I suppose so if you need any tips on the game just try to corrupt him anyway",
    "start": "500669",
    "end": "508979"
  },
  {
    "text": "we all saw bit Angry Birds movie and sequel is also in the mix so but we kind",
    "start": "508979",
    "end": "515669"
  },
  {
    "text": "of identify ourselves as a game's first entertainment company so game building",
    "start": "515669",
    "end": "521640"
  },
  {
    "text": "great games is the core what we do and then we ensure that we have a good game",
    "start": "521640",
    "end": "527519"
  },
  {
    "text": "strong brand and then we can do some prime licensing on top of that using that brand so that's that's our business",
    "start": "527519",
    "end": "534269"
  },
  {
    "text": "and so what does this mean there for the daytime so as any I would say all the",
    "start": "534269",
    "end": "543470"
  },
  {
    "text": "mobile games free to big companies we are like really really data to remain",
    "start": "543470",
    "end": "549660"
  },
  {
    "text": "company so for example when we start a game project we first do some market",
    "start": "549660",
    "end": "557699"
  },
  {
    "text": "research a panty it's like really open for example what games are out there",
    "start": "557699",
    "end": "564839"
  },
  {
    "text": "what they are what they are making how many users they have it's like really open in this business so you can take",
    "start": "564839",
    "end": "571079"
  },
  {
    "text": "data from a Pawnee and try to find range what kind of game we should make and",
    "start": "571079",
    "end": "576870"
  },
  {
    "text": "once we decided what came we should make those and prototyping and what not and finally when the game is done getting",
    "start": "576870",
    "end": "585750"
  },
  {
    "text": "back to that soon it's all about you user acquisition so how do we get those",
    "start": "585750",
    "end": "592199"
  },
  {
    "text": "users in and how do we optimize that a user",
    "start": "592199",
    "end": "597779"
  },
  {
    "text": "acquisition funnel make decisions for example that because we have portfolio",
    "start": "597779",
    "end": "604980"
  },
  {
    "text": "of games so we have many games so we need to for example make a decision that ok at this point should we actually show",
    "start": "604980",
    "end": "610950"
  },
  {
    "text": "this person or device a cross-promotion or should we act in fact show an ad from",
    "start": "610950",
    "end": "617160"
  },
  {
    "text": "a network because that way we could get that revenue then also nowadays when a",
    "start": "617160",
    "end": "625110"
  },
  {
    "text": "game is out there it's not actually done yet so after we initial release we have",
    "start": "625110",
    "end": "630540"
  },
  {
    "text": "the players in we start optimizing the game running a/b testing and try to find ok how do we make the players play more",
    "start": "630540",
    "end": "639029"
  },
  {
    "text": "what's the how do we make this game more fun what works what doesn't work so in",
    "start": "639029",
    "end": "646529"
  },
  {
    "text": "the context of this presentation we focus on this performance marketing and",
    "start": "646529",
    "end": "651990"
  },
  {
    "text": "game optimization piece we have a data",
    "start": "651990",
    "end": "659220"
  },
  {
    "start": "657000",
    "end": "784000"
  },
  {
    "text": "philosophy one thing is really important for us that we have a single source of",
    "start": "659220",
    "end": "666300"
  },
  {
    "text": "truth so if if you have multiple dashboards and all those dashboards or",
    "start": "666300",
    "end": "672930"
  },
  {
    "text": "different numbers different da you different retention numbers that's that",
    "start": "672930",
    "end": "678540"
  },
  {
    "text": "makes like people cannot entrust the data what is the right people shouldn't like question that ok what I see here is",
    "start": "678540",
    "end": "688140"
  },
  {
    "text": "that the truth we should only have one truth even if we have multiple dashboards they should show if they have",
    "start": "688140",
    "end": "693930"
  },
  {
    "text": "retention it should show the same numbers in all those dashboards we also",
    "start": "693930",
    "end": "699089"
  },
  {
    "text": "have this idea of sharing is caring so that applies in our game teams for",
    "start": "699089",
    "end": "705300"
  },
  {
    "text": "example game studios when they make a hit or they make a not-so hit or some really wait let's say it's just bad game",
    "start": "705300",
    "end": "712020"
  },
  {
    "text": "they will share their experiences so this applies also for the data we we",
    "start": "712020",
    "end": "719070"
  },
  {
    "text": "want to kind of a share data we want to for example even provide anyone who",
    "start": "719070",
    "end": "724500"
  },
  {
    "text": "wants to access that data and run the queries if they so want to",
    "start": "724500",
    "end": "731399"
  },
  {
    "text": "and then the third one we own our future so we we value and protect data of our",
    "start": "731399",
    "end": "742019"
  },
  {
    "text": "players so but we are not in a data",
    "start": "742019",
    "end": "747540"
  },
  {
    "text": "business our business is to make great games so we want to ensure that whatever happens tomorrow we don't want to kind",
    "start": "747540",
    "end": "755370"
  },
  {
    "text": "of be kind of a somehow blocked on doing those great games we need to ensure that",
    "start": "755370",
    "end": "763290"
  },
  {
    "text": "we are able to do where we think we are",
    "start": "763290",
    "end": "768839"
  },
  {
    "text": "the best no matter what happens so",
    "start": "768839",
    "end": "774320"
  },
  {
    "start": "784000",
    "end": "1006000"
  },
  {
    "text": "okay sorry about that so this is the",
    "start": "784660",
    "end": "790150"
  },
  {
    "text": "architecture that we had before lake",
    "start": "790150",
    "end": "797160"
  },
  {
    "text": "well I think it's quite traditional big",
    "start": "799380",
    "end": "804460"
  },
  {
    "text": "data architecture I would say so we have let me see if this works at all sorry",
    "start": "804460",
    "end": "810570"
  },
  {
    "text": "okay but we have here in the left hand side we have a the game client we have",
    "start": "810570",
    "end": "817840"
  },
  {
    "text": "an SDK or internal SDK and from the game client you can send analytics events into our collection API you can also we",
    "start": "817840",
    "end": "826690"
  },
  {
    "text": "have also services like a login service if you do a purchase you there's a purchase service that validates your",
    "start": "826690",
    "end": "833230"
  },
  {
    "text": "purchases and ensures that you get the codes in the game that you you write and then also for example we if you if we",
    "start": "833230",
    "end": "843550"
  },
  {
    "text": "show ads we we use add service to that so also those services send data into",
    "start": "843550",
    "end": "848560"
  },
  {
    "text": "our data collection endpoint this collection m2 endpoint is really simple",
    "start": "848560",
    "end": "853930"
  },
  {
    "text": "it's just decodes the package and sorry encodes the packets and then stores it",
    "start": "853930",
    "end": "859120"
  },
  {
    "text": "to the sorry decodes the packets and stores that to Kafka and then from Kafka",
    "start": "859120",
    "end": "864430"
  },
  {
    "text": "we have actually two two different modules so we have a thing that we call",
    "start": "864430",
    "end": "871150"
  },
  {
    "text": "packager so basically that's our streams the raw events into s3 and then we have",
    "start": "871150",
    "end": "879400"
  },
  {
    "text": "some real-time functionality we use APIs flink to that but that's basically",
    "start": "879400",
    "end": "885850"
  },
  {
    "text": "basically for monitoring purposes so we do we have this way to do this kind of customized aggregates like aggregate",
    "start": "885850",
    "end": "893710"
  },
  {
    "text": "data like unique unique visitors during last 10 minutes or something like that",
    "start": "893710",
    "end": "899710"
  },
  {
    "text": "and then we publish that information in - portal purely monitoring like are we",
    "start": "899710",
    "end": "906880"
  },
  {
    "text": "showing or our ads placement for working for example most our reporting is done",
    "start": "906880",
    "end": "912820"
  },
  {
    "text": "in the bad side of things so we here",
    "start": "912820",
    "end": "918340"
  },
  {
    "text": "on the from the raw data we do daily aggregation or we did daily aggregation",
    "start": "918340",
    "end": "923620"
  },
  {
    "text": "of the data started on the play we aggregated the data on the daily and player level and then we store that data",
    "start": "923620",
    "end": "929950"
  },
  {
    "text": "into Amazon redshift database and we also had this raw data import process",
    "start": "929950",
    "end": "935830"
  },
  {
    "text": "where we imported the data into a third party analytics system and from the",
    "start": "935830",
    "end": "941529"
  },
  {
    "text": "redshift we basically then calculate the KPIs and published in that basically",
    "start": "941529",
    "end": "948820"
  },
  {
    "text": "import that data to click cents or into the beacon tool which I talked about",
    "start": "948820",
    "end": "954000"
  },
  {
    "text": "later we also store the profiles into the Cassandra database so we can serve",
    "start": "954000",
    "end": "959730"
  },
  {
    "text": "different services provide a player profiles and some insight to the actual",
    "start": "959730",
    "end": "965560"
  },
  {
    "text": "game servers for example all this is then kind of orchestrated using this",
    "start": "965560",
    "end": "973000"
  },
  {
    "text": "azkaban workflow manager so take think",
    "start": "973000",
    "end": "982570"
  },
  {
    "text": "about this architecture and then yeah especially I want to highlight this like",
    "start": "982570",
    "end": "989200"
  },
  {
    "text": "we had he we have raw data but it was a little bit far away from the actual",
    "start": "989200",
    "end": "994620"
  },
  {
    "text": "dashboards which is kind of what you would consider those as a tool for the kind of the a little bit higher level",
    "start": "994620",
    "end": "1001140"
  },
  {
    "text": "tool for for known data engineers okay",
    "start": "1001140",
    "end": "1007110"
  },
  {
    "start": "1006000",
    "end": "1048000"
  },
  {
    "text": "so if you think about that architecture and then compare it into our data philosophy so did we have single truth",
    "start": "1007110",
    "end": "1014360"
  },
  {
    "text": "actually we didn't we had multiple dashboards all based on the raw data so",
    "start": "1014360",
    "end": "1020480"
  },
  {
    "text": "or some of them based on raw data so different dashboards actually did show",
    "start": "1020480",
    "end": "1025620"
  },
  {
    "text": "different numbers what about sharing well there was some",
    "start": "1025620",
    "end": "1033928"
  },
  {
    "text": "sharing but the fact was that there was like really limited access to the dashboard and the raw data and what",
    "start": "1033929",
    "end": "1042990"
  },
  {
    "text": "about did we on our future well I suppose we did but the main point was",
    "start": "1042990",
    "end": "1049350"
  },
  {
    "start": "1048000",
    "end": "1057000"
  },
  {
    "text": "that well it's not perf but I I think we have more important things to do so nothing was basically",
    "start": "1049350",
    "end": "1056420"
  },
  {
    "text": "done and then this happened we got this email which pretty much said that okay",
    "start": "1056420",
    "end": "1063460"
  },
  {
    "start": "1057000",
    "end": "1073000"
  },
  {
    "text": "that third party analytics platform that you saw in the architecture that was acquired by another mobile games company",
    "start": "1063460",
    "end": "1072790"
  },
  {
    "start": "1073000",
    "end": "1166000"
  },
  {
    "text": "so before we go into what we did let's have a quick look what we actually",
    "start": "1073780",
    "end": "1080420"
  },
  {
    "text": "already had so I've mentioned beacon and it was in the architects of slides so",
    "start": "1080420",
    "end": "1086660"
  },
  {
    "text": "what is big and so beacon is our cloud service platform that you can use to run",
    "start": "1086660",
    "end": "1094250"
  },
  {
    "text": "games and I I think you all heard these",
    "start": "1094250",
    "end": "1099890"
  },
  {
    "text": "games as a service so that's pretty much it super run live operations for example",
    "start": "1099890",
    "end": "1107060"
  },
  {
    "text": "for your game so it had features like analytics it had tools for a be testing",
    "start": "1107060",
    "end": "1113890"
  },
  {
    "text": "tools for segmentation for example we had a churn prediction or a running",
    "start": "1113890",
    "end": "1121970"
  },
  {
    "text": "chirp churn prediction for players which we can then use to for example prioritize or support tickets we also",
    "start": "1121970",
    "end": "1133070"
  },
  {
    "text": "have a system for managing the IEP purchase catalogs we have like mentioned",
    "start": "1133070",
    "end": "1141260"
  },
  {
    "text": "ads and then we have also tool for push that's not widely used push at least in",
    "start": "1141260",
    "end": "1147500"
  },
  {
    "text": "the US but other countries where server-side push is still support you",
    "start": "1147500",
    "end": "1154460"
  },
  {
    "text": "can do it so that's where we can use that so we had all these great tools but",
    "start": "1154460",
    "end": "1162220"
  },
  {
    "text": "sauce or it is okay but what was missing was the ability to for date analysts to",
    "start": "1164170",
    "end": "1173390"
  },
  {
    "start": "1166000",
    "end": "1225000"
  },
  {
    "text": "build these game specific dashboards using game event joined with portfolio",
    "start": "1173390",
    "end": "1179240"
  },
  {
    "text": "wired games business data so with the game-specific dashboards I mean that all",
    "start": "1179240",
    "end": "1185720"
  },
  {
    "text": "these dashboards that we had in beacon and in click since they were kind of really game agnostic like I said like",
    "start": "1185720",
    "end": "1192620"
  },
  {
    "text": "how many users did we have this day what was their attention and how much money what was the average revenue per user so",
    "start": "1192620",
    "end": "1201320"
  },
  {
    "text": "that they didn't really care what was the underlying game so with this I mean for example level funnels games have",
    "start": "1201320",
    "end": "1209630"
  },
  {
    "text": "different means to define what is a level so we all these all these",
    "start": "1209630",
    "end": "1216920"
  },
  {
    "text": "dashboards that we were like measuring how game-like be a Meccano me works there's they were done with this",
    "start": "1216920",
    "end": "1222200"
  },
  {
    "text": "third-party tool so this is what the",
    "start": "1222200",
    "end": "1227570"
  },
  {
    "start": "1225000",
    "end": "1275000"
  },
  {
    "text": "situation was and then we were kind of thinking ok what should we do should we buy yet another app analytics vendor or",
    "start": "1227570",
    "end": "1236000"
  },
  {
    "text": "the solution or should be built it's ourselves so damn it so we decided to I",
    "start": "1236000",
    "end": "1247400"
  },
  {
    "text": "don't know why this is not working well like they told me that it takes time for the slide to change that's why I'm not",
    "start": "1247400",
    "end": "1253760"
  },
  {
    "text": "spamming this but I mean it just doesn't receive that command anyway so we",
    "start": "1253760",
    "end": "1261050"
  },
  {
    "text": "decided to build it so all good but we had only seven weeks time to do it",
    "start": "1261050",
    "end": "1268840"
  },
  {
    "text": "and so we move into how we did it so",
    "start": "1269530",
    "end": "1276320"
  },
  {
    "start": "1275000",
    "end": "1336000"
  },
  {
    "text": "let's recap what we need so we need petabyte scale data warehouse people",
    "start": "1276320",
    "end": "1283040"
  },
  {
    "text": "don't like that word so that's why the double quotes with fast access to raw",
    "start": "1283040",
    "end": "1288830"
  },
  {
    "text": "data sets we also want to efficiently query this data and process the data",
    "start": "1288830",
    "end": "1296210"
  },
  {
    "text": "from multiple systems so meaning with multiple systems I mean that someone",
    "start": "1296210",
    "end": "1301760"
  },
  {
    "text": "might want to use pork someone won't just use SQL someone wants to use some",
    "start": "1301760",
    "end": "1307179"
  },
  {
    "text": "notebook something like that so we want to system that you can kind of or we",
    "start": "1307179",
    "end": "1313160"
  },
  {
    "text": "don't want to have like only one system that we can use that and then we also want to have a data",
    "start": "1313160",
    "end": "1319429"
  },
  {
    "text": "visualization SDK so some way of someone to create a nice dashboard and publish",
    "start": "1319429",
    "end": "1326150"
  },
  {
    "text": "that hopefully in our peak on UI so that we don't it would appear for this user that actually it's the only only one",
    "start": "1326150",
    "end": "1333350"
  },
  {
    "text": "product behind the lines and when we",
    "start": "1333350",
    "end": "1339050"
  },
  {
    "start": "1336000",
    "end": "1372000"
  },
  {
    "text": "started looking into this well data lakes we're all the rage I think they still are this is a snippet",
    "start": "1339050",
    "end": "1348230"
  },
  {
    "text": "from Wikipedia definition of data like but maybe they with few words I would",
    "start": "1348230",
    "end": "1356300"
  },
  {
    "text": "say that like having data on it's like",
    "start": "1356300",
    "end": "1361520"
  },
  {
    "text": "original format RAW format somewhere and schema on read they are quite often",
    "start": "1361520",
    "end": "1368270"
  },
  {
    "text": "mentioned so if you think about this didn't we then have already a data like",
    "start": "1368270",
    "end": "1375770"
  },
  {
    "start": "1372000",
    "end": "1452000"
  },
  {
    "text": "we had those that data in the s3 already partitioned there in the JSON format so",
    "start": "1375770",
    "end": "1382850"
  },
  {
    "text": "I think we could do a scheme on read so we had it all right all right no I don't",
    "start": "1382850",
    "end": "1390770"
  },
  {
    "text": "think we actually had because we had like huge human latency because we",
    "start": "1390770",
    "end": "1396020"
  },
  {
    "text": "didn't basically if you wanted to start querying the day that you had the first launch of cluster we didn't have any",
    "start": "1396020",
    "end": "1401480"
  },
  {
    "text": "clusters up and running all the time there was no schema anywhere so it",
    "start": "1401480",
    "end": "1407720"
  },
  {
    "text": "pretty much meant that if for example you run something on hive you first create the external table you should",
    "start": "1407720",
    "end": "1412790"
  },
  {
    "text": "know what is inside those JSON documents there was also query latency we were running a for example lot of hive",
    "start": "1412790",
    "end": "1419300"
  },
  {
    "text": "queries so it takes two takes time for you to run a hive query it's more a tool",
    "start": "1419300",
    "end": "1425420"
  },
  {
    "text": "for scheduled processing and all this kind of resulted into a fact that there",
    "start": "1425420",
    "end": "1431600"
  },
  {
    "text": "were only few people I say tens of people in the company who knew how to",
    "start": "1431600",
    "end": "1437840"
  },
  {
    "text": "access that data or who really wanted to there would have been maybe the",
    "start": "1437840",
    "end": "1443210"
  },
  {
    "text": "technical competence for people to access the data but it was like so difficult so let those guys do it so",
    "start": "1443210",
    "end": "1448429"
  },
  {
    "text": "then we had data in bottleneck in our company so why we",
    "start": "1448429",
    "end": "1454130"
  },
  {
    "start": "1452000",
    "end": "1551000"
  },
  {
    "text": "think then thought about Amazon I see enough so we were already like Romeo is",
    "start": "1454130",
    "end": "1460220"
  },
  {
    "text": "using Amazon in our cloud services we were really fluent with it didn't really",
    "start": "1460220",
    "end": "1469190"
  },
  {
    "text": "feel like chasing a provider we we",
    "start": "1469190",
    "end": "1475970"
  },
  {
    "text": "wanted to have the data and the processing layers separated so many of",
    "start": "1475970",
    "end": "1482060"
  },
  {
    "text": "the services where you for example those like Big Data MPP databases so they kind",
    "start": "1482060",
    "end": "1489230"
  },
  {
    "text": "of join the both so if you want to have the processing it kind of involves also having the disks and so it kind of if",
    "start": "1489230",
    "end": "1496400"
  },
  {
    "text": "you needed more disks you actually also bought more processing power and it",
    "start": "1496400",
    "end": "1503810"
  },
  {
    "text": "becomes really really or may become really really expensive and then also it",
    "start": "1503810",
    "end": "1510680"
  },
  {
    "text": "had this paper used billing so a lot of",
    "start": "1510680",
    "end": "1516110"
  },
  {
    "text": "our clusters we had some both for",
    "start": "1516110",
    "end": "1521480"
  },
  {
    "text": "example now we know it is run a presto cluster so there is some they are not running like 100% all the time",
    "start": "1521480",
    "end": "1528320"
  },
  {
    "text": "so there is some overhead and when we provision the clusters like sometimes",
    "start": "1528320",
    "end": "1534020"
  },
  {
    "text": "they are running a little bit cold so we really enjoy the fact that they okay you could just run a query and then pay for",
    "start": "1534020",
    "end": "1540080"
  },
  {
    "text": "what you are querying and then performance needs to be at at least on",
    "start": "1540080",
    "end": "1545720"
  },
  {
    "text": "par with alternative solutions so let's",
    "start": "1545720",
    "end": "1551720"
  },
  {
    "start": "1551000",
    "end": "1628000"
  },
  {
    "text": "look at the performance first so here we we run this is like we run many tests",
    "start": "1551720",
    "end": "1558950"
  },
  {
    "text": "and this looks like really simple but this kind of we be quite often work on",
    "start": "1558950",
    "end": "1564740"
  },
  {
    "text": "this thing bound so this just shows like okay really simple simple examples what",
    "start": "1564740",
    "end": "1570590"
  },
  {
    "text": "our day to day work is so for example here we first run it",
    "start": "1570590",
    "end": "1576120"
  },
  {
    "text": "so we run these queries on the database X which is a solution from another",
    "start": "1576120",
    "end": "1582179"
  },
  {
    "text": "vendor then we have run a like medium-sized presto cluster 2520 knock",
    "start": "1582179",
    "end": "1590610"
  },
  {
    "text": "one notes and then we run these queries on Watson as well so first we run this and chase on this JSON sequence",
    "start": "1590610",
    "end": "1597510"
  },
  {
    "text": "gzip format was our raw data format at the time and as you can see athena",
    "start": "1597510",
    "end": "1603570"
  },
  {
    "text": "performed quite well compared into the Presto cluster but it wasn't the layer",
    "start": "1603570",
    "end": "1608850"
  },
  {
    "text": "on the level what we wanted then we converted the data into work format and",
    "start": "1608850",
    "end": "1615090"
  },
  {
    "text": "the performance was like improved significantly and nine seconds was like",
    "start": "1615090",
    "end": "1620880"
  },
  {
    "text": "hey well this this works so we were happy with that one so from this we got",
    "start": "1620880",
    "end": "1630779"
  },
  {
    "text": "okay we need to have a columnar format and we also need to flatten and repartition and manage the schema more",
    "start": "1630779",
    "end": "1638580"
  },
  {
    "text": "about this on later slides but this is the conclusion that we got into in but",
    "start": "1638580",
    "end": "1644730"
  },
  {
    "start": "1644000",
    "end": "1782000"
  },
  {
    "text": "also we are we don't only kind of need that raw data we also need profiles and",
    "start": "1644730",
    "end": "1649770"
  },
  {
    "text": "here when I talk profiles I know that there's a little bit like there is for",
    "start": "1649770",
    "end": "1655140"
  },
  {
    "text": "example this GDP or legislation coming in in in Europe so I I just want to say",
    "start": "1655140",
    "end": "1663870"
  },
  {
    "text": "that here I'm not talking about profiles like as a technical term and as for example diamonds and in a our",
    "start": "1663870",
    "end": "1672000"
  },
  {
    "text": "reporting not as a way to do like automated decision making significant",
    "start": "1672000",
    "end": "1679350"
  },
  {
    "text": "decision-making that would be harmful for the end and end user so just to make",
    "start": "1679350",
    "end": "1684690"
  },
  {
    "text": "that clear all legal set that I need to everyone got that now right okay so yeah",
    "start": "1684690",
    "end": "1694649"
  },
  {
    "text": "so analysis almost always is done on some specific player cohort and in that",
    "start": "1694649",
    "end": "1701970"
  },
  {
    "text": "third party system that we had actually eats raw event had this",
    "start": "1701970",
    "end": "1709560"
  },
  {
    "text": "our state which also had the user origin and the court like okay where did this player come it was kind of baked in into",
    "start": "1709560",
    "end": "1715530"
  },
  {
    "text": "that raw data role so that's a little bit bad because we have noticed that we",
    "start": "1715530",
    "end": "1723900"
  },
  {
    "text": "quite often need to fix the data for example being me too for example we",
    "start": "1723900",
    "end": "1729240"
  },
  {
    "text": "notice that hey this is actually hacked device so we should ignore it so if we for example and also a lot another thing",
    "start": "1729240",
    "end": "1736650"
  },
  {
    "text": "is that we actually track the users own journey by like running a craft analysis",
    "start": "1736650",
    "end": "1742620"
  },
  {
    "text": "on the player IDs where did different IDs that this player has so it might be",
    "start": "1742620",
    "end": "1747630"
  },
  {
    "text": "that the user already in chases overtime when we find a cessation that okay hey these actually these clusters are",
    "start": "1747630",
    "end": "1754800"
  },
  {
    "text": "actually the same so we may have two years of raw data and if all of those",
    "start": "1754800",
    "end": "1761010"
  },
  {
    "text": "roles would have a information also about user origin then we would have to",
    "start": "1761010",
    "end": "1766430"
  },
  {
    "text": "reprocess all those raw data rows to get that data in so we wanted to build a",
    "start": "1766430",
    "end": "1772110"
  },
  {
    "text": "system where we or could we actually build a system where we don't need to",
    "start": "1772110",
    "end": "1777450"
  },
  {
    "text": "bake in the player state and run still efficient queries using joints so how",
    "start": "1777450",
    "end": "1782880"
  },
  {
    "start": "1782000",
    "end": "1821000"
  },
  {
    "text": "about joints in Athena so it's a little bit different query actually they even",
    "start": "1782880",
    "end": "1788490"
  },
  {
    "text": "the raw data port but the main point with this one is that the data amount",
    "start": "1788490",
    "end": "1794790"
  },
  {
    "text": "was exactly the same so and this query is a little bit more complicated so as",
    "start": "1794790",
    "end": "1800940"
  },
  {
    "text": "you can see there was very little overhead from the original query coming",
    "start": "1800940",
    "end": "1808410"
  },
  {
    "text": "from the join so looked really good so sorry",
    "start": "1808410",
    "end": "1815030"
  },
  {
    "text": "so it works so and fewer more words",
    "start": "1819210",
    "end": "1824610"
  },
  {
    "start": "1821000",
    "end": "1920000"
  },
  {
    "text": "about the player profiles I'm not covering that much in this talk I'm",
    "start": "1824610",
    "end": "1829680"
  },
  {
    "text": "actually focusing the rest of the slides on the X or raw data processing but just to let you know that the like I said the",
    "start": "1829680",
    "end": "1835440"
  },
  {
    "text": "profile is kind of the user journey across our portfolio okay where did this",
    "start": "1835440",
    "end": "1840660"
  },
  {
    "text": "player come from they tweaked it we get him from the cross promotion or did we",
    "start": "1840660",
    "end": "1846060"
  },
  {
    "text": "actually buy it by the user how much time did you spend in our games how many",
    "start": "1846060",
    "end": "1852600"
  },
  {
    "text": "purchases does this player have and then we have predictions as well so a lifetime value predictions turn the",
    "start": "1852600",
    "end": "1859800"
  },
  {
    "text": "cheating just to name a few and then these daily aggregates I did to",
    "start": "1859800",
    "end": "1866580"
  },
  {
    "text": "added to these profiles we also have these aggregates like which are again like game agnostic daily and cumulative",
    "start": "1866580",
    "end": "1873840"
  },
  {
    "text": "activities so how much time did this you'll have this user spent until this day and also on on this day and all this",
    "start": "1873840",
    "end": "1883800"
  },
  {
    "text": "datum profiles and aggregates they were in a mahjong redshift database and we",
    "start": "1883800",
    "end": "1891990"
  },
  {
    "text": "basically to get this available for our kind of dashboards we we also dumped",
    "start": "1891990",
    "end": "1899880"
  },
  {
    "text": "this data into s3 and converted that into work format but I'm not actually talking the examples are not covering",
    "start": "1899880",
    "end": "1908430"
  },
  {
    "text": "this but it had really similar similar",
    "start": "1908430",
    "end": "1914600"
  },
  {
    "text": "architecture and similar techniques used so it's it doesn't differ that much and",
    "start": "1914600",
    "end": "1920480"
  },
  {
    "start": "1920000",
    "end": "1959000"
  },
  {
    "text": "this is the technology selections that we had so we we took so APIs orc for the",
    "start": "1920480",
    "end": "1929220"
  },
  {
    "text": "data format Amazon Athena for the query engine and then we pick this really - I",
    "start": "1929220",
    "end": "1936330"
  },
  {
    "text": "don't know have you heard about it it's like a quite small company it's like",
    "start": "1936330",
    "end": "1942000"
  },
  {
    "text": "really lightweight and easily integrally integrated really easily so integrate",
    "start": "1942000",
    "end": "1950040"
  },
  {
    "text": "nicely with Athena as well but yeah take a look anyway so now let's",
    "start": "1950040",
    "end": "1962660"
  },
  {
    "start": "1959000",
    "end": "1992000"
  },
  {
    "text": "have a look on our data how does this",
    "start": "1962660",
    "end": "1968270"
  },
  {
    "text": "work so it's this part from the architecture",
    "start": "1968270",
    "end": "1973370"
  },
  {
    "text": "actually there is a little bit of spoiler so during this time we also changed our package share which was the",
    "start": "1973370",
    "end": "1979940"
  },
  {
    "text": "internal tool that was copying data into s3 we actually replace it with shaker",
    "start": "1979940",
    "end": "1985990"
  },
  {
    "text": "great tool for someone who needs to store data from Kafka to s3 ok this is",
    "start": "1985990",
    "end": "1992900"
  },
  {
    "start": "1992000",
    "end": "2056000"
  },
  {
    "text": "how our analytics event look like they",
    "start": "1992900",
    "end": "1998060"
  },
  {
    "text": "are produced by game clients and our services they have standard headers and custom message body so as you can see",
    "start": "1998060",
    "end": "2005680"
  },
  {
    "text": "here for example there is a seat is a game see very stable client version the",
    "start": "2005680",
    "end": "2013420"
  },
  {
    "text": "game version a ID one is for example the device ID want to highlight here that",
    "start": "2013420",
    "end": "2018790"
  },
  {
    "text": "everything is like an anonymized so for example if we now allow people to access",
    "start": "2018790",
    "end": "2024040"
  },
  {
    "text": "the data we don't want to have any personal information available there and",
    "start": "2024040",
    "end": "2030510"
  },
  {
    "text": "then this part in the block in block in the way below that's the game specific",
    "start": "2030510",
    "end": "2038410"
  },
  {
    "text": "part so there can be pretty much anything the game developer wants to put there oh and yes the Chasen format is",
    "start": "2038410",
    "end": "2047650"
  },
  {
    "text": "used when it's stored to disk so only the integration with the game client it uses product of packets and then our",
    "start": "2047650",
    "end": "2057460"
  },
  {
    "start": "2056000",
    "end": "2088000"
  },
  {
    "text": "Kafka topics so main point on this slide is that we had when you send events from",
    "start": "2057460",
    "end": "2065710"
  },
  {
    "text": "our game clients they end up into a game specific Kafka topic but then if for",
    "start": "2065710",
    "end": "2070780"
  },
  {
    "text": "example Andy refers to is using ads or game use ads then they gain client data",
    "start": "2070780",
    "end": "2077080"
  },
  {
    "text": "is stored into ads topic and all the game data is then mixed all the games",
    "start": "2077080",
    "end": "2082388"
  },
  {
    "text": "are mixed in that topic at topic and then this is how the data",
    "start": "2082389",
    "end": "2089740"
  },
  {
    "text": "is then in s3 so we have the wealth",
    "start": "2089740",
    "end": "2096069"
  },
  {
    "text": "there is def basically the Kafka topic process date and then we have the gzipped files for for each topic and the",
    "start": "2096069",
    "end": "2108940"
  },
  {
    "text": "the data format so they are compressed sequence files and the one Chasen",
    "start": "2108940",
    "end": "2114849"
  },
  {
    "text": "objects per row and where we want to actually go with this",
    "start": "2114849",
    "end": "2120609"
  },
  {
    "start": "2118000",
    "end": "2204000"
  },
  {
    "text": "based on our test we want to store the data in our C format we want to",
    "start": "2120609",
    "end": "2128200"
  },
  {
    "text": "partition the data by game and event type so why pick y with game because we",
    "start": "2128200",
    "end": "2137710"
  },
  {
    "text": "wanted to optimize this for game team so each game team is basically working on their own game so we wanted to optimize",
    "start": "2137710",
    "end": "2144339"
  },
  {
    "text": "that so that's why we wanted to partition the data so that it's per game so you don't need to process the other",
    "start": "2144339",
    "end": "2149710"
  },
  {
    "text": "games if you don't want them and also the event type partitioning we wanted to add because that additional event type",
    "start": "2149710",
    "end": "2156579"
  },
  {
    "text": "partition really improved the performance significantly over the standard work suit basically also index",
    "start": "2156579",
    "end": "2164520"
  },
  {
    "text": "some however the and optimize it but this really I don't have any numbers but",
    "start": "2164520",
    "end": "2172240"
  },
  {
    "text": "it was significant the the data is like really skewed in our case for example if",
    "start": "2172240",
    "end": "2177549"
  },
  {
    "text": "you think about adds clicks and then adds requests so it's that can be like",
    "start": "2177549",
    "end": "2184809"
  },
  {
    "text": "one two hundred times there so there is a huge queue on the data per event type",
    "start": "2184809",
    "end": "2190150"
  },
  {
    "text": "so that's why we wanted to do it so if you want to analyze clicks we don't need to go all through all that volume of",
    "start": "2190150",
    "end": "2197109"
  },
  {
    "text": "those huge volumes of like at requests",
    "start": "2197109",
    "end": "2203339"
  },
  {
    "text": "and then the final schema in the",
    "start": "2203339",
    "end": "2208559"
  },
  {
    "start": "2204000",
    "end": "2250000"
  },
  {
    "text": "database if you will or in Athena so this is how we wanted it to look like",
    "start": "2208559",
    "end": "2214119"
  },
  {
    "text": "so it basically we wanted it to have a flat structure so quite many DP tools don't like any",
    "start": "2214119",
    "end": "2221250"
  },
  {
    "text": "nested elements like structs or maps or whatnot that you could really do in in for",
    "start": "2221250",
    "end": "2227770"
  },
  {
    "text": "example in Athena but we wanted it to be like end-user experience would be as",
    "start": "2227770",
    "end": "2235180"
  },
  {
    "text": "with traditional databases we wanted to have a table pair Kafka topic and schema",
    "start": "2235180",
    "end": "2241660"
  },
  {
    "text": "per game and we wanted to have those tables look like they would be partitioned by date and event type one",
    "start": "2241660",
    "end": "2252180"
  },
  {
    "text": "thing we had to figure out quite early was that hey this org scheme I have a",
    "start": "2252180",
    "end": "2257710"
  },
  {
    "text": "loose and so we have years of raw data from multiple games and services so and",
    "start": "2257710",
    "end": "2266730"
  },
  {
    "text": "monthly game updates they introduce new field so and reprocessing everything",
    "start": "2266730",
    "end": "2271990"
  },
  {
    "text": "takes time and it's expensive so we don't want to change that every time we we get a new field in so the solution",
    "start": "2271990",
    "end": "2278800"
  },
  {
    "text": "there was actually to maintain the org Falcom politic compile it compatibility and you can do it by following these",
    "start": "2278800",
    "end": "2284320"
  },
  {
    "text": "rules so if you don't remove any files ever and you don't change the data path sorry data type of the fields and you",
    "start": "2284320",
    "end": "2292210"
  },
  {
    "text": "always up into new fields in the end and how did we then do schema discovery so",
    "start": "2292210",
    "end": "2299410"
  },
  {
    "start": "2296000",
    "end": "2330000"
  },
  {
    "text": "actually doing this kind of scaleable discovery of your JSON data is like",
    "start": "2299410",
    "end": "2305380"
  },
  {
    "text": "really really simple so it's that amount of spark code you can just take a",
    "start": "2305380",
    "end": "2311140"
  },
  {
    "text": "picture and yeah so so actually with",
    "start": "2311140",
    "end": "2316570"
  },
  {
    "text": "this so you can basically get the nice JSON presentation on your data that hey",
    "start": "2316570",
    "end": "2321609"
  },
  {
    "text": "this is the chase and aggregate decision scheme of your of your data but then the",
    "start": "2321609",
    "end": "2330970"
  },
  {
    "start": "2330000",
    "end": "2344000"
  },
  {
    "text": "actual schema discovery pipeline is a little bit more complicated so this part",
    "start": "2330970",
    "end": "2336250"
  },
  {
    "text": "here is the actual spark job that I wrote so it will then output this kind",
    "start": "2336250",
    "end": "2341320"
  },
  {
    "text": "of schema Jason but from that schema we actually what we want to do if we want",
    "start": "2341320",
    "end": "2347740"
  },
  {
    "start": "2344000",
    "end": "2396000"
  },
  {
    "text": "to maintain ties or quark compatibility so then we actually look previously discolored schema and merged",
    "start": "2347740",
    "end": "2355570"
  },
  {
    "text": "that and also then add these new fields in the end of the schema and then we",
    "start": "2355570",
    "end": "2360670"
  },
  {
    "text": "also have this blacklist thing so there is a lot of noise in our later so there",
    "start": "2360670",
    "end": "2366910"
  },
  {
    "text": "might be some hack devices there might be some errors from our test QA builds",
    "start": "2366910",
    "end": "2372400"
  },
  {
    "text": "so we also want to filter out some of the fields for the record it might be",
    "start": "2372400",
    "end": "2378940"
  },
  {
    "text": "that we change this a little bit not to do a schema discovery but instead let the game teams to define this schema but",
    "start": "2378940",
    "end": "2387130"
  },
  {
    "text": "let's see we haven't decided that yet maybe we need to do it now because I",
    "start": "2387130",
    "end": "2392710"
  },
  {
    "text": "went public with okay so we merge that and then we produce the actual schema",
    "start": "2392710",
    "end": "2400030"
  },
  {
    "start": "2396000",
    "end": "2438000"
  },
  {
    "text": "and then we have this this is by the way these scripts are mostly Python so then",
    "start": "2400030",
    "end": "2406870"
  },
  {
    "text": "we have a generator that takes this JSON file and then it basically creates a",
    "start": "2406870",
    "end": "2412650"
  },
  {
    "text": "bulk of different hive hive scripts like",
    "start": "2412650",
    "end": "2417790"
  },
  {
    "text": "hive script to create tables have scripts to alter the and adding new",
    "start": "2417790",
    "end": "2423130"
  },
  {
    "text": "partitions if needed insert into statements which are basically how we",
    "start": "2423130",
    "end": "2429280"
  },
  {
    "text": "converted data more about that in the following slides and then also a scope and workflows also auto-generated and we",
    "start": "2429280",
    "end": "2436780"
  },
  {
    "text": "have a Dem system that you we store that into it hub and then we basically what",
    "start": "2436780",
    "end": "2443290"
  },
  {
    "text": "we have a process then that's what you push to github is it like depending on the branch and everything it goes into",
    "start": "2443290",
    "end": "2448870"
  },
  {
    "text": "our smoke sorry the test environment staging and then finally to the",
    "start": "2448870",
    "end": "2454420"
  },
  {
    "text": "production environment one problem that",
    "start": "2454420",
    "end": "2459970"
  },
  {
    "start": "2458000",
    "end": "2515000"
  },
  {
    "text": "we actually had was a number of problem with part number of partitions so for example Angry Birds had 73,000",
    "start": "2459970",
    "end": "2468250"
  },
  {
    "text": "partitions and actually add columns and my one of guys in my team actually said",
    "start": "2468250",
    "end": "2474640"
  },
  {
    "text": "that maybe this add columns wasn't even in Athena when we started but once we noticed that ok there is not something",
    "start": "2474640",
    "end": "2480820"
  },
  {
    "text": "it wasn't actually working for a huge table like this so scheme update actually needed drop and",
    "start": "2480820",
    "end": "2487810"
  },
  {
    "text": "create table but then if we do that actually the MSC G C M is CK Ripper",
    "start": "2487810",
    "end": "2497640"
  },
  {
    "text": "table and drop table those were actually climbing out so as a workaround we had",
    "start": "2497640",
    "end": "2503230"
  },
  {
    "text": "to add and remove these partitions of matches of sin and then paralyze that",
    "start": "2503230",
    "end": "2508390"
  },
  {
    "text": "and also add a service limit increase for the DDL statements and then about",
    "start": "2508390",
    "end": "2516550"
  },
  {
    "start": "2515000",
    "end": "2537000"
  },
  {
    "text": "how they would be actually converted data so data conversion is quite simple",
    "start": "2516550",
    "end": "2522730"
  },
  {
    "text": "again so it's basically just copying data from a table with some JSON gzip",
    "start": "2522730",
    "end": "2529180"
  },
  {
    "text": "format into a external table that has this org format format defined so it's",
    "start": "2529180",
    "end": "2535540"
  },
  {
    "text": "actually really really simple few things that we had to tune so for some reason this dynamic partitioning messed up the",
    "start": "2535540",
    "end": "2544240"
  },
  {
    "start": "2537000",
    "end": "2593000"
  },
  {
    "text": "system was it so that it actually failed or was like super slow so we wanted to disable it and it was performing quite",
    "start": "2544240",
    "end": "2551170"
  },
  {
    "text": "well but then I mentioned about this queue because if you set this it will I",
    "start": "2551170",
    "end": "2557680"
  },
  {
    "text": "think it will then create a mapper pair a partition where you've right to and",
    "start": "2557680",
    "end": "2563050"
  },
  {
    "text": "then if the data is really skewed it doesn't for example if we have these add",
    "start": "2563050",
    "end": "2568240"
  },
  {
    "text": "three quests like hundred times more than clicks it actually creates only one mapper for this hundred times more data",
    "start": "2568240",
    "end": "2575589"
  },
  {
    "text": "and it's super slow so the poor that as a workaround we use this distribute by",
    "start": "2575589",
    "end": "2581400"
  },
  {
    "text": "Clause very basically distributed doing this hashing things so we can we",
    "start": "2581400",
    "end": "2587050"
  },
  {
    "text": "basically paralyze it for 10 uppers this was really handy and again you saw that",
    "start": "2587050",
    "end": "2595300"
  },
  {
    "start": "2593000",
    "end": "2669000"
  },
  {
    "text": "that's like nice clean script but then the excel pipeline is a little bit more complicated so few here we have the",
    "start": "2595300",
    "end": "2604089"
  },
  {
    "text": "left-hand side we have the JSON events so what we do we again first Paul that",
    "start": "2604089",
    "end": "2609849"
  },
  {
    "text": "the day is complete we actually do it in sake or well there's a way that we",
    "start": "2609849",
    "end": "2615609"
  },
  {
    "text": "actually check that all our all the partitions from Kafka received from someday so once that's completed we I",
    "start": "2615609",
    "end": "2625510"
  },
  {
    "text": "haven't changed this light okay so this is actually wrong but yeah we we basically add the partitions for the",
    "start": "2625510",
    "end": "2631000"
  },
  {
    "text": "Chasen we do it actually in the start of the day already so that's a little bit wrong order but anyway and then once the",
    "start": "2631000",
    "end": "2639760"
  },
  {
    "text": "data is available we run that hive job that converts that data into orc and also so then the data is in in s3",
    "start": "2639760",
    "end": "2650050"
  },
  {
    "text": "and finally we also generate this at partition script to add okay now there's",
    "start": "2650050",
    "end": "2656860"
  },
  {
    "text": "a new day at a new day into the work table schema and at these new partitions",
    "start": "2656860",
    "end": "2662110"
  },
  {
    "text": "as well if there's for example you haven't pipes coming we need to add those as well and yeah so sorry so as you can see we",
    "start": "2662110",
    "end": "2672850"
  },
  {
    "text": "have two metal stores so we have one which is for like presto or internal",
    "start": "2672850",
    "end": "2679690"
  },
  {
    "text": "metal store and then we update also Latino meta store this is basically I",
    "start": "2679690",
    "end": "2685080"
  },
  {
    "text": "mentioned this in the following slides of baseball but currently a Tina doesn't support insert into statements so if you",
    "start": "2685080",
    "end": "2692020"
  },
  {
    "text": "want to do this kind of report in state tables interim tape or its kind of aggregate tables you don't want to",
    "start": "2692020",
    "end": "2698020"
  },
  {
    "text": "always run a query on the raw data then you need to at the moment you some other",
    "start": "2698020",
    "end": "2703030"
  },
  {
    "text": "technology for that maybe they are known something today or like during this week",
    "start": "2703030",
    "end": "2708790"
  },
  {
    "text": "so let's see I don't I don't have any inside info by the way so just really",
    "start": "2708790",
    "end": "2715300"
  },
  {
    "text": "hoping so this is now the architecture that we are running so I want to",
    "start": "2715300",
    "end": "2725860"
  },
  {
    "start": "2717000",
    "end": "2778000"
  },
  {
    "text": "highlight so I mentioned this shaker thing already but then we actually have",
    "start": "2725860",
    "end": "2732070"
  },
  {
    "text": "another process as you can see we convert the data into s or format raw",
    "start": "2732070",
    "end": "2737890"
  },
  {
    "text": "data store that into the s3 and then we also have this cohort data coming from",
    "start": "2737890",
    "end": "2743640"
  },
  {
    "text": "redshift we also streamlined it a little bit our pipeline so we actually only",
    "start": "2743640",
    "end": "2749140"
  },
  {
    "text": "have like one Rovio business KPI pipeline that produce that about beacon and clixsense and now",
    "start": "2749140",
    "end": "2756040"
  },
  {
    "text": "now we have this presto and Athena clusters serving queries from really -",
    "start": "2756040",
    "end": "2763500"
  },
  {
    "text": "so it works really really nicely",
    "start": "2763500",
    "end": "2769560"
  },
  {
    "text": "ok so let's recap what was our deliverable we now have a well-defined",
    "start": "2771510",
    "end": "2781390"
  },
  {
    "start": "2778000",
    "end": "2815000"
  },
  {
    "text": "schema maybe I wanted to highlight for example one service that wasn't pinched",
    "start": "2781390",
    "end": "2786700"
  },
  {
    "text": "at this supermoon the name is really really bad but anyway so that for",
    "start": "2786700",
    "end": "2792040"
  },
  {
    "text": "example is a service that tells in which a be testing group this user was so know that data is there as well and then if",
    "start": "2792040",
    "end": "2799270"
  },
  {
    "text": "you want to analyze your tests you basically can just join that a B that's",
    "start": "2799270",
    "end": "2804460"
  },
  {
    "text": "the information into your game session and then build nice graphs to test for",
    "start": "2804460",
    "end": "2810730"
  },
  {
    "text": "your tests and analyze them then you can query that data using Amazon Athena this",
    "start": "2810730",
    "end": "2818260"
  },
  {
    "start": "2815000",
    "end": "2829000"
  },
  {
    "text": "is actually a snapshot from from readers so you can basically build that dashboards by first running creating a",
    "start": "2818260",
    "end": "2824110"
  },
  {
    "text": "SQL query and then we saw lies it and then finally we integrated this into our",
    "start": "2824110",
    "end": "2832540"
  },
  {
    "start": "2829000",
    "end": "2860000"
  },
  {
    "text": "beacon - so actually you built the - ports in in readers but then you can actually publish it in the pig and a",
    "start": "2832540",
    "end": "2839050"
  },
  {
    "text": "sport so then the game teams don't actually know they have a one portal where they can go and see there how is",
    "start": "2839050",
    "end": "2846130"
  },
  {
    "text": "my game - what stay how is how is the business side and how is our axle level",
    "start": "2846130",
    "end": "2852310"
  },
  {
    "text": "funnels and some game specific data at the moment so it's it's it's great and",
    "start": "2852310",
    "end": "2859680"
  },
  {
    "text": "as a bonus we also got the lake so we can use Athena pressed for SQL but also",
    "start": "2859680",
    "end": "2867760"
  },
  {
    "text": "some guys who are doing really advanced stuff for example using spark so then",
    "start": "2867760",
    "end": "2872770"
  },
  {
    "text": "you don't need to for example first from square queries to spark and pull that data into that spark cluster you could",
    "start": "2872770",
    "end": "2878920"
  },
  {
    "text": "actually kind of a you could just query that directly using for example spark",
    "start": "2878920",
    "end": "2884140"
  },
  {
    "text": "SQL so it it works nicely",
    "start": "2884140",
    "end": "2888269"
  },
  {
    "text": "so now a few learnings so when you are",
    "start": "2889480",
    "end": "2894670"
  },
  {
    "start": "2893000",
    "end": "2975000"
  },
  {
    "text": "thinking like okay what data format I should use we took an orc but as it turns out market is currently a little",
    "start": "2894670",
    "end": "2902470"
  },
  {
    "text": "bit more widely used so are supported by different for example Alma redshift",
    "start": "2902470",
    "end": "2908530"
  },
  {
    "text": "spectrum first really support for parkette so think about that if you're building an org has worked really well",
    "start": "2908530",
    "end": "2915130"
  },
  {
    "text": "for us but if depends a little bit what you use that so keep an eye out on that",
    "start": "2915130",
    "end": "2921790"
  },
  {
    "text": "one then this insert into support that I already told you though at the moment we need to run this presto cluster we have",
    "start": "2921790",
    "end": "2929050"
  },
  {
    "text": "games actually that do all the queries from the raw data for example angry pets",
    "start": "2929050",
    "end": "2934900"
  },
  {
    "text": "- they are actually running this for their - they have two years of raw data",
    "start": "2934900",
    "end": "2940480"
  },
  {
    "text": "and they every time when they build run their dashboard daily dashboards they",
    "start": "2940480",
    "end": "2946089"
  },
  {
    "text": "actually run on the road a that their queries so it works even for that and I",
    "start": "2946089",
    "end": "2952210"
  },
  {
    "text": "think that the bill is not that big even even so and it has worked",
    "start": "2952210",
    "end": "2959920"
  },
  {
    "text": "it's like really well during last few weeks so I'm just curious maybe they",
    "start": "2959920",
    "end": "2965260"
  },
  {
    "text": "have over provision to cluster now before my talk I don't know okay and",
    "start": "2965260",
    "end": "2975849"
  },
  {
    "start": "2975000",
    "end": "3000000"
  },
  {
    "text": "then this external meta store support we need to update this two different meta stores our own and the genome at the",
    "start": "2975849",
    "end": "2983410"
  },
  {
    "text": "store so I think it's now possible to use a Tina or this clue meta store as",
    "start": "2983410",
    "end": "2988510"
  },
  {
    "text": "your own meta store as well but we would rather do it another way around we would want to Ameri have our own meta story it",
    "start": "2988510",
    "end": "2994089"
  },
  {
    "text": "works really nicely and use that in Athena but maybe it's not possible",
    "start": "2994089",
    "end": "2999779"
  },
  {
    "start": "3000000",
    "end": "3011000"
  },
  {
    "text": "mine - number of partitions so this we covered already so actually the biggest performance problems that we had were",
    "start": "3000089",
    "end": "3006240"
  },
  {
    "text": "with DDL statements and concurrent query",
    "start": "3006240",
    "end": "3012960"
  },
  {
    "text": "limits you can kind of increase your limits but it's still really low I mean",
    "start": "3012960",
    "end": "3019140"
  },
  {
    "text": "the d4 so actually I think five is like way too",
    "start": "3019140",
    "end": "3025770"
  },
  {
    "text": "little be you're going to increase it but I think you should by default very like create a amount of of concurrent",
    "start": "3025770",
    "end": "3035130"
  },
  {
    "text": "query queries and take a look or be like really follow what new products and",
    "start": "3035130",
    "end": "3041910"
  },
  {
    "start": "3037000",
    "end": "3070000"
  },
  {
    "text": "services are out there I'm coming for example during the time that we implemented this architecture there was",
    "start": "3041910",
    "end": "3049230"
  },
  {
    "text": "for example the Amazon clue introduced Amazon",
    "start": "3049230",
    "end": "3054270"
  },
  {
    "text": "sorry redshifts per spectrum for example these two services or something that most likely have would have maybe well",
    "start": "3054270",
    "end": "3062520"
  },
  {
    "text": "at least a clue might have been really really interesting to take a look at we haven't been decorated into that money",
    "start": "3062520",
    "end": "3068310"
  },
  {
    "text": "yet and yes Pima discovery is really easy what the actual schema management",
    "start": "3068310",
    "end": "3073950"
  },
  {
    "start": "3070000",
    "end": "3088000"
  },
  {
    "text": "can get really really complicated so again I'm sorry I've mentioned this clue I haven't used clue so I don't know is",
    "start": "3073950",
    "end": "3081240"
  },
  {
    "text": "that good or not but have a look before you start building your own system and",
    "start": "3081240",
    "end": "3088010"
  },
  {
    "start": "3088000",
    "end": "3115000"
  },
  {
    "text": "this one is like so bias so really hard to find like unbiased information so if",
    "start": "3088010",
    "end": "3096540"
  },
  {
    "text": "you if you want to kind of if you all can please test your use case we did",
    "start": "3096540",
    "end": "3102720"
  },
  {
    "text": "actually it didn't take that long actually to sell it like if use different vendors for example test it",
    "start": "3102720",
    "end": "3108270"
  },
  {
    "text": "out and it really paid like K was comforting that okay this is a system that we can actually use and as a final",
    "start": "3108270",
    "end": "3116670"
  },
  {
    "start": "3115000",
    "end": "3180000"
  },
  {
    "text": "note Amazon Athena pressed Ohio spark they are really create together so I",
    "start": "3116670",
    "end": "3123020"
  },
  {
    "text": "think this Athena provides the data for a wider audience but then you can use",
    "start": "3123020",
    "end": "3129360"
  },
  {
    "text": "like a little bit more low level stuff if you want to and one thing I want to",
    "start": "3129360",
    "end": "3134700"
  },
  {
    "text": "highlight that this architecture actually we have quite only rate",
    "start": "3134700",
    "end": "3139740"
  },
  {
    "text": "safeties and Athena kind of can be considered like vendor like that we have",
    "start": "3139740",
    "end": "3145500"
  },
  {
    "text": "some sort of vendor working but for example presto presto and work for material like open source data format so",
    "start": "3145500",
    "end": "3152250"
  },
  {
    "text": "we are not we don't have that when they're looking at the moment using these tools so maybe something worth",
    "start": "3152250",
    "end": "3158940"
  },
  {
    "text": "considering so using services that are still like based on open source technologies I think it's a good idea",
    "start": "3158940",
    "end": "3167000"
  },
  {
    "text": "all right so thank you that was my presentation",
    "start": "3167000",
    "end": "3172349"
  },
  {
    "text": "piece and I was told I need to make it clear that this was the official part and then now some questions may be",
    "start": "3172349",
    "end": "3182088"
  }
]
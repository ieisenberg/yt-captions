[
  {
    "start": "0",
    "end": "28000"
  },
  {
    "text": "my name is Kumar Venkateswara I run the product management team for Amazon Sage maker and I I'm here to talk about",
    "start": "30",
    "end": "8330"
  },
  {
    "text": "DevOps of machine learning with with Amazon Sage maker I truly appreciate the",
    "start": "8330",
    "end": "15509"
  },
  {
    "text": "amount of time that youyou guys have are spending with me and and the enthusiasm",
    "start": "15509",
    "end": "20820"
  },
  {
    "text": "that you you have first H maker and hopefully this will be a useful bit of",
    "start": "20820",
    "end": "26609"
  },
  {
    "text": "time that you spend with me so overall I want to talk about some of the DevOps",
    "start": "26609",
    "end": "32279"
  },
  {
    "start": "28000",
    "end": "94000"
  },
  {
    "text": "challenges that people encounter in machine learning in general not not necessarily related to to stage maker or",
    "start": "32279",
    "end": "39930"
  },
  {
    "text": "AWS and part of the reasons for the genesis of those those challenges and",
    "start": "39930",
    "end": "46050"
  },
  {
    "text": "and then we can talk a little bit about sage maker what customers say about it",
    "start": "46050",
    "end": "51539"
  },
  {
    "text": "in in AWS we typically like to illustrate these things through customer",
    "start": "51539",
    "end": "57719"
  },
  {
    "text": "examples so I have an example that I'd like to talk about and then I'll give a brief introduction as to what sage maker",
    "start": "57719",
    "end": "64860"
  },
  {
    "text": "is and then I'll talk about how sage maker can be used as part of a portfolio",
    "start": "64860",
    "end": "72750"
  },
  {
    "text": "of services that you would use to address those DevOps challenges and then",
    "start": "72750",
    "end": "77790"
  },
  {
    "text": "I'd like to take some questions I know we're running a little late overall between this talk and and the talk on",
    "start": "77790",
    "end": "86210"
  },
  {
    "text": "automatic model tuning that's coming up later I'll try and get you guys out of here by 1:00 so we can have lunch on",
    "start": "86210",
    "end": "92100"
  },
  {
    "text": "time so let's go ahead and and dive in and talk about some of the challenges",
    "start": "92100",
    "end": "98310"
  },
  {
    "start": "94000",
    "end": "113000"
  },
  {
    "text": "that people encounter when they're trying to operationalize machine learning because really that's the thing",
    "start": "98310",
    "end": "103619"
  },
  {
    "text": "that that I'm focused on as as the sage maker product owner and it's something",
    "start": "103619",
    "end": "110280"
  },
  {
    "text": "that I think is very critical in general if we how many of you have seen this",
    "start": "110280",
    "end": "116430"
  },
  {
    "start": "113000",
    "end": "337000"
  },
  {
    "text": "slide before only a few of you okay great so in general machine learning the",
    "start": "116430",
    "end": "123270"
  },
  {
    "text": "machine learning process is pretty hard there's a lot of stages that you go through it's something that is very",
    "start": "123270",
    "end": "129569"
  },
  {
    "text": "unique to machine learning and is not by the rest of software development which means that it's even harder",
    "start": "129569",
    "end": "135319"
  },
  {
    "text": "because there are no processes set up around it first and and the reason for",
    "start": "135319",
    "end": "141349"
  },
  {
    "text": "that is because it's primarily machine learning originated out of data science experimentation so the way people think",
    "start": "141349",
    "end": "148310"
  },
  {
    "text": "about this is as a science experiment how do I experiment how do I do this one-off and then at the end of it I get",
    "start": "148310",
    "end": "155750"
  },
  {
    "text": "a model what you do with that model who knows right there's a model and that's",
    "start": "155750",
    "end": "161870"
  },
  {
    "text": "the way people have traditionally thought about it so you end up with a lot of these non repeatable heavy",
    "start": "161870",
    "end": "167599"
  },
  {
    "text": "lifting processes first at the initially you try and set up an environment where you can safely store your data and be",
    "start": "167599",
    "end": "176390"
  },
  {
    "text": "able to analyze that data process that data and so on and that generally ends",
    "start": "176390",
    "end": "181909"
  },
  {
    "text": "up taking a bit of time as you try and secure the environment sometimes it's the data scientists laptop ideally it's",
    "start": "181909",
    "end": "190120"
  },
  {
    "text": "something that's a little more secure than that and can't be lost at an airport and so on but you you set up",
    "start": "190120",
    "end": "196730"
  },
  {
    "text": "this environment you load in the tools you get it set up exactly right so that",
    "start": "196730",
    "end": "201889"
  },
  {
    "text": "you have the drivers all lined up this software all lined up I actually in the",
    "start": "201889",
    "end": "208639"
  },
  {
    "text": "past I've I've set up an environment like this it's taken me hours to make sure that all of the driver versions",
    "start": "208639",
    "end": "215060"
  },
  {
    "text": "compiled into the software as well as installed on the on the Box are the same",
    "start": "215060",
    "end": "220730"
  },
  {
    "text": "it ends up taking somewhere between hours and weeks to set up this environment and then there's a challenge",
    "start": "220730",
    "end": "226010"
  },
  {
    "text": "around labeling the data so you you have a bunch of data it's usually dirty in some way or the other",
    "start": "226010",
    "end": "231769"
  },
  {
    "text": "it's non-uniform you need people to pre-process it you need to be able to add annotation to that so it has the",
    "start": "231769",
    "end": "238910"
  },
  {
    "text": "labels that you need in order to answer the machine learning question so then a couple of weeks have gone by you finally",
    "start": "238910",
    "end": "245239"
  },
  {
    "text": "got your environment you're ready to process through it and then you say okay",
    "start": "245239",
    "end": "250579"
  },
  {
    "text": "I'm ready to start training and initially if you've got small data you take a sample of the data and you train",
    "start": "250579",
    "end": "257329"
  },
  {
    "text": "and you're like okay I've got this this trained model I think it'll work well on",
    "start": "257329",
    "end": "263090"
  },
  {
    "text": "a bigger set of data and in order to work on that bigger set of data I'm gonna try and use a cluster",
    "start": "263090",
    "end": "270410"
  },
  {
    "text": "for it and that's hard setting up a distributed cluster to do machine",
    "start": "270410",
    "end": "276020"
  },
  {
    "text": "learning training is hard time-consuming in fact it's so hard that a lot of the",
    "start": "276020",
    "end": "281870"
  },
  {
    "text": "customers that I've talked to end up leaving their clusters up and running paying for it the entire time 24/7 and",
    "start": "281870",
    "end": "289490"
  },
  {
    "text": "then they have a priority queue that says certain jobs need to be prioritized over others and and and so on in order",
    "start": "289490",
    "end": "296630"
  },
  {
    "text": "to make sure that they're utilizing that cluster correctly it's it's a mess scaling up and and making these",
    "start": "296630",
    "end": "303500"
  },
  {
    "text": "algorithms work is really hard and then once you have this model you need to put it into an application because the model",
    "start": "303500",
    "end": "311120"
  },
  {
    "text": "itself does no good to anybody unless it's incorporated into an application so they take that model and hand it over to",
    "start": "311120",
    "end": "318920"
  },
  {
    "text": "DevOps at that point and you look at it and you're like what do I do with this model it's not going to meet any of my",
    "start": "318920",
    "end": "325940"
  },
  {
    "text": "operational characteristics so you end up with this cycle that takes anywhere",
    "start": "325940",
    "end": "331880"
  },
  {
    "text": "between 6 and 18 months in order to get this model into production and part of",
    "start": "331880",
    "end": "338570"
  },
  {
    "start": "337000",
    "end": "385000"
  },
  {
    "text": "the challenge is that machine learning tools are different than the ones that are traditionally used by DevOps",
    "start": "338570",
    "end": "344360"
  },
  {
    "text": "audiences so you have a set of things like anaconda and scikit-learn and some",
    "start": "344360",
    "end": "349610"
  },
  {
    "text": "of those are that are the easier tools to use and then you have deep learning tools that are pretty sophisticated hard",
    "start": "349610",
    "end": "357590"
  },
  {
    "text": "to get right have a lot of adjustments that you need to do and I'm not even",
    "start": "357590",
    "end": "364670"
  },
  {
    "text": "talking about things like MPI and Avadh which are really truly hard to get set up right and then you have SPARC and",
    "start": "364670",
    "end": "372110"
  },
  {
    "text": "and there's even a set of things like Apache airflow and ml flow where people",
    "start": "372110",
    "end": "377990"
  },
  {
    "text": "are trying to develop these machine learning specific tools to help with the operationalization of machine learning",
    "start": "377990",
    "end": "383830"
  },
  {
    "text": "and part of that is because the ml challenges are different than the DevOps",
    "start": "383830",
    "end": "391010"
  },
  {
    "start": "385000",
    "end": "462000"
  },
  {
    "text": "challenges when you talk about DevOps you have a whole set of things around is the software compliant is it in the",
    "start": "391010",
    "end": "397940"
  },
  {
    "text": "right regions can we audit it can we look at the security of it is actually",
    "start": "397940",
    "end": "404150"
  },
  {
    "text": "maintaining the security of the data when it's a one-off experiment you don't need to think about these things when",
    "start": "404150",
    "end": "409670"
  },
  {
    "text": "you're doing this day after day in a repeatable process all of these things become important is it portable can I",
    "start": "409670",
    "end": "416060"
  },
  {
    "text": "actually take that that application and move it to different environments if I need it can I take the model from iOS to",
    "start": "416060",
    "end": "423170"
  },
  {
    "text": "Android so that I can develop an Android app can I take it from on-premises to the cloud or you know essentially you",
    "start": "423170",
    "end": "430910"
  },
  {
    "text": "need to be able to move it around and all of that needs to be done in an environment where it's always up and",
    "start": "430910",
    "end": "438020"
  },
  {
    "text": "running so it's one thing if you're doing this one-off but if it's something",
    "start": "438020",
    "end": "443330"
  },
  {
    "text": "that you're building a business on it needs to be up and running all the time and that's a different challenge altogether and then if you're successful",
    "start": "443330",
    "end": "450980"
  },
  {
    "text": "you're lucky then you need to scale it out so that it takes your your peak",
    "start": "450980",
    "end": "456800"
  },
  {
    "text": "loads and all of these are different challenges than the machine learning challenges that we talked about so what",
    "start": "456800",
    "end": "463100"
  },
  {
    "start": "462000",
    "end": "498000"
  },
  {
    "text": "happens is DevOps and gets involved too late this is really the root of the problem the scientists are will work on",
    "start": "463100",
    "end": "470900"
  },
  {
    "text": "these small data sets and then they say okay I'm good it might be pretty clean",
    "start": "470900",
    "end": "477680"
  },
  {
    "text": "so I'll have a data engineer clean up that data for me so that it works well",
    "start": "477680",
    "end": "483020"
  },
  {
    "text": "for machine learning it's not necessarily a production ready process so it may be done in a non repeatable",
    "start": "483020",
    "end": "489020"
  },
  {
    "text": "way and you end up doing this in a very dedicated environment that is separate",
    "start": "489020",
    "end": "495860"
  },
  {
    "text": "from the production environment so these science project things get tossed over",
    "start": "495860",
    "end": "501200"
  },
  {
    "text": "the wall and DevOps doesn't know how to implement them in production and then all of this all of the DevOps challenges",
    "start": "501200",
    "end": "508790"
  },
  {
    "text": "are something of an afterthought and what ends up happening is that it",
    "start": "508790",
    "end": "515150"
  },
  {
    "text": "doesn't end up being as useful in production as it was in the science",
    "start": "515150",
    "end": "520760"
  },
  {
    "text": "experiment so everyone ends up being disappointed with this entire process it",
    "start": "520760",
    "end": "526130"
  },
  {
    "text": "took too long it ended up in production way too late and the results were not great so what",
    "start": "526130",
    "end": "536209"
  },
  {
    "start": "534000",
    "end": "539000"
  },
  {
    "text": "is sage maker I usually talk about sage maker in the context of the overall AWS",
    "start": "536209",
    "end": "543290"
  },
  {
    "text": "ml stack because we're not trying to sage maker itself isn't the silver",
    "start": "543290",
    "end": "549980"
  },
  {
    "text": "bullet solution for all of your ml problems we believe that there is this entire spectrum of needs that you have",
    "start": "549980",
    "end": "556820"
  },
  {
    "text": "and we have different services to meet different needs within your organization the AI services the top layer of the",
    "start": "556820",
    "end": "564860"
  },
  {
    "text": "stack here those services are the easy to use I'm not I have this problem that",
    "start": "564860",
    "end": "572360"
  },
  {
    "text": "I know machine learning can help with Amazon help me with solving these",
    "start": "572360",
    "end": "577790"
  },
  {
    "text": "problems pick out pick out objects from images or recognize entities from blocks",
    "start": "577790",
    "end": "584899"
  },
  {
    "text": "of unstructured text that kind of thing where these are common problems across a lot of industries and Amazon has good",
    "start": "584899",
    "end": "591980"
  },
  {
    "text": "expertise to bring in order to make that easy so that AI services are actually the",
    "start": "591980",
    "end": "596990"
  },
  {
    "text": "easiest to use out-of-the-box but then there's a set of problems that is unique",
    "start": "596990",
    "end": "602480"
  },
  {
    "text": "to your business what is a unique value that you can provide to your customers that you want to develop that you",
    "start": "602480",
    "end": "608930"
  },
  {
    "text": "believe is the core of your business so in order to help with that our goal",
    "start": "608930",
    "end": "614060"
  },
  {
    "text": "is to make it so that you can bring your data in that you can develop expertise in in that area and that you can",
    "start": "614060",
    "end": "620540"
  },
  {
    "text": "operationalize it and that's where sage maker fits in and this is built on a foundation of a lot of open source",
    "start": "620540",
    "end": "628670"
  },
  {
    "text": "projects that we contribute to that we participate in this whole community is something that we are dedicated to",
    "start": "628670",
    "end": "635510"
  },
  {
    "text": "making a difference in and this foundation is is what it's built on top",
    "start": "635510",
    "end": "640790"
  },
  {
    "text": "of this along with things like Intel based compute Nvidia based GPUs of a",
    "start": "640790",
    "end": "649149"
  },
  {
    "text": "strong storage infrastructure that infrastructure layer is what enables us",
    "start": "649149",
    "end": "654829"
  },
  {
    "text": "to provide services that enable you to move quickly so the goal here is that",
    "start": "654829",
    "end": "662470"
  },
  {
    "start": "659000",
    "end": "703000"
  },
  {
    "text": "this is your quickest path from idea to production I've personally been involved",
    "start": "662470",
    "end": "668050"
  },
  {
    "text": "in machine learning projects where it took me six months to go from the the",
    "start": "668050",
    "end": "674350"
  },
  {
    "text": "data science telling me hey this is this is working out really well against historical data let's push it into",
    "start": "674350",
    "end": "680650"
  },
  {
    "text": "production six months later it gets into production this is not the way to do machine learning machine learning builds",
    "start": "680650",
    "end": "687190"
  },
  {
    "text": "on machine learning you learn more as you go along it's iterative you need to be able to push things into production",
    "start": "687190",
    "end": "692980"
  },
  {
    "text": "within days to weeks at at worst weeks at worst so sage maker is intended to",
    "start": "692980",
    "end": "699580"
  },
  {
    "text": "help you push things into your production environment and how the sage",
    "start": "699580",
    "end": "704860"
  },
  {
    "start": "703000",
    "end": "856000"
  },
  {
    "text": "maker do it it it basically helps you with all of the challenges that I",
    "start": "704860",
    "end": "710500"
  },
  {
    "text": "outlined through the entire cycle or it tries to help with a lot of these",
    "start": "710500",
    "end": "716320"
  },
  {
    "text": "challenges so you have these notebook environments that are customizable that",
    "start": "716320",
    "end": "721780"
  },
  {
    "text": "integrate together which are with your git repository so you're bringing the",
    "start": "721780",
    "end": "726850"
  },
  {
    "text": "data scientist into the rest of the DevOps ecosystem in that way it has built-in security features it uses the",
    "start": "726850",
    "end": "735070"
  },
  {
    "text": "AWS virtual private cloud and private link it encrypts the storage using a",
    "start": "735070",
    "end": "740470"
  },
  {
    "text": "customer provided key so it maintains the security of the data it's something",
    "start": "740470",
    "end": "746170"
  },
  {
    "text": "that you can feel confident that if you use these environments that your data is held securely it provides you with",
    "start": "746170",
    "end": "753820"
  },
  {
    "text": "automatic cluster setup and teardown it provides you with algorithms that you can use to get started it provides you",
    "start": "753820",
    "end": "759850"
  },
  {
    "text": "with frameworks there's an AWS marketplace for machine learning in",
    "start": "759850",
    "end": "765010"
  },
  {
    "text": "which you can purchase the work of other people and use those algorithms as well so the idea there is you would be able",
    "start": "765010",
    "end": "771220"
  },
  {
    "text": "to get up and running as quickly as possible why will you develop your own expertise in the area it provides",
    "start": "771220",
    "end": "778089"
  },
  {
    "text": "automatic model tuning which is something that we'll talk about in our in our next time together after this",
    "start": "778089",
    "end": "785380"
  },
  {
    "text": "talk is over and it provides this in a way like because it provides cluster",
    "start": "785380",
    "end": "791110"
  },
  {
    "text": "setup and teardown it actually provides you with a lower cost solution than the solutions",
    "start": "791110",
    "end": "796940"
  },
  {
    "text": "that people usually use which is this persistent cluster that runs regardless of whether you're actually doing machine",
    "start": "796940",
    "end": "803480"
  },
  {
    "text": "learning training or not instead of having that persistent cluster you can spin up and spin down and it provides",
    "start": "803480",
    "end": "809029"
  },
  {
    "text": "you with a good way to reduce costs there as well the next if you look at",
    "start": "809029",
    "end": "815060"
  },
  {
    "text": "how it gets deployed again it lets you set up these clusters on demand you only",
    "start": "815060",
    "end": "820910"
  },
  {
    "text": "pay for they the instances that are up and running which means that you are",
    "start": "820910",
    "end": "826420"
  },
  {
    "text": "having reduced cost there as well and it has integrated auto scaling which means",
    "start": "826420",
    "end": "831589"
  },
  {
    "text": "it can scale up to meet your peak demand and scale down as well it's integrated",
    "start": "831589",
    "end": "836750"
  },
  {
    "text": "with cloud watch for monitoring and it has features that allow you to optimize",
    "start": "836750",
    "end": "842270"
  },
  {
    "text": "for hardware as well so Sage maker neo will compile a model for a specific",
    "start": "842270",
    "end": "847279"
  },
  {
    "text": "hardware target and we provide elastic inference which will further reduce the",
    "start": "847279",
    "end": "853010"
  },
  {
    "text": "cost on the inference side and this is something that intuitive is one of the",
    "start": "853010",
    "end": "859820"
  },
  {
    "start": "856000",
    "end": "953000"
  },
  {
    "text": "early customers that has realized a lot of benefit with Sage maker first they",
    "start": "859820",
    "end": "864950"
  },
  {
    "text": "moved one model over and then they said wow this is going really great and in",
    "start": "864950",
    "end": "870980"
  },
  {
    "text": "the in the next I think the first model took them six months to move over and",
    "start": "870980",
    "end": "876110"
  },
  {
    "text": "then they moved another five over and I think that took roughly six months to",
    "start": "876110",
    "end": "882080"
  },
  {
    "text": "move over and then they're they're moving another 25 over so if you look at the way these things progress they're",
    "start": "882080",
    "end": "888440"
  },
  {
    "text": "able to move a lot quicker and they're able to develop these models much much",
    "start": "888440",
    "end": "893510"
  },
  {
    "text": "faster than they were able to prior to Sage maker what I what I heard from the Intel folks",
    "start": "893510",
    "end": "900110"
  },
  {
    "text": "when I talked to them at at at reinvent is that they were able to bring their",
    "start": "900110",
    "end": "906589"
  },
  {
    "text": "model development time from over six months down to less than two weeks which",
    "start": "906589",
    "end": "913279"
  },
  {
    "text": "is amazing if you think about it this is the kind of thing that you need to be able to do if you're building a machine",
    "start": "913279",
    "end": "919430"
  },
  {
    "text": "learning company you need to be able to do these things in a repeatable fashion and you need to do them fast and if you",
    "start": "919430",
    "end": "926000"
  },
  {
    "text": "look at at Intuit this is a this is a company that deals with I want to say something",
    "start": "926000",
    "end": "932730"
  },
  {
    "text": "like sixty percent of the u.s. the u.s. is tax data so they have a very very",
    "start": "932730",
    "end": "938519"
  },
  {
    "text": "high bar for security they're very concerned about things like fraud and they're able to put their critical",
    "start": "938519",
    "end": "945629"
  },
  {
    "text": "critical machine learning problems on Sage maker and they're able to run",
    "start": "945629",
    "end": "951089"
  },
  {
    "text": "faster as a result so part of what sage maker provides is",
    "start": "951089",
    "end": "957920"
  },
  {
    "start": "953000",
    "end": "1040000"
  },
  {
    "text": "this notion of modularity and this notion of being able to choose exactly",
    "start": "957920",
    "end": "963959"
  },
  {
    "text": "how you want to use Sage maker and a lot of data scientists and machine learning",
    "start": "963959",
    "end": "970139"
  },
  {
    "text": "scientists are very particular about the way they work and they want to use their own tools they want to use the",
    "start": "970139",
    "end": "975930"
  },
  {
    "text": "environment that they're familiar with and the reason for that is because they're solving really hard problems so",
    "start": "975930",
    "end": "981149"
  },
  {
    "text": "if you say hey you know what I'm gonna give you a toolset and you have to use this tool set and you have to solve",
    "start": "981149",
    "end": "987300"
  },
  {
    "text": "these really difficult problems it becomes a double challenge so instead what we decided was we built sage maker",
    "start": "987300",
    "end": "994529"
  },
  {
    "text": "in a way that it works with the data scientists it works with the way you work so if they want to use this the",
    "start": "994529",
    "end": "1001600"
  },
  {
    "text": "hosted the the hosted notebook instances on on Sage maker those are there if they",
    "start": "1001600",
    "end": "1010370"
  },
  {
    "text": "want to use their own laptop that works too you can still use it from your own laptop you can use it from Sparky you",
    "start": "1010370",
    "end": "1016399"
  },
  {
    "text": "can use it I actually have one customer who's who's using their entire machine",
    "start": "1016399",
    "end": "1023720"
  },
  {
    "text": "learning workflow workflow is from the console which is a little surprising to me but you know we provide this because",
    "start": "1023720",
    "end": "1031909"
  },
  {
    "text": "we think they're useful even for small numbers of customers and we're trying to",
    "start": "1031909",
    "end": "1037668"
  },
  {
    "text": "make it so that you build it your own way similarly for training we want it to",
    "start": "1037669",
    "end": "1043970"
  },
  {
    "start": "1040000",
    "end": "1110000"
  },
  {
    "text": "work the way that you want to work with zero setup we want it to be so that you",
    "start": "1043970",
    "end": "1050480"
  },
  {
    "text": "can use a built-in algorithm so you can use the marketplace algorithms if you feel like you have IP that you would",
    "start": "1050480",
    "end": "1058190"
  },
  {
    "text": "want to share with other people and you'd want to be able to monetize it you can even use the marketplace as a way that you can",
    "start": "1058190",
    "end": "1064380"
  },
  {
    "text": "publish your own work and provide others with a way that they can easily use your",
    "start": "1064380",
    "end": "1069710"
  },
  {
    "text": "your IP in-house we also work with all frameworks so we have example containers",
    "start": "1069710",
    "end": "1078090"
  },
  {
    "text": "that we've provided for tensorflow for MX net for pi torch for chainer",
    "start": "1078090",
    "end": "1084780"
  },
  {
    "text": "it's not limited to those all of those containers we've even open sourced them so if you want to take them and fork",
    "start": "1084780",
    "end": "1091620"
  },
  {
    "text": "them and develop your own in-house docker containers you can do that or I",
    "start": "1091620",
    "end": "1097650"
  },
  {
    "text": "mean essentially you can use docker for your own custom algorithms and you can bring your own expertise in your own IP",
    "start": "1097650",
    "end": "1104310"
  },
  {
    "text": "and still use sage maker in in all of the ways that I describe I'll just talk",
    "start": "1104310",
    "end": "1112980"
  },
  {
    "start": "1110000",
    "end": "1191000"
  },
  {
    "text": "a little bit briefly about about the built-in algorithms the built-in algorithms are nice for traditional",
    "start": "1112980",
    "end": "1119400"
  },
  {
    "text": "machine learning problems because they're built for really high scale and built for reliability and it's the",
    "start": "1119400",
    "end": "1126660"
  },
  {
    "text": "quickest way to get started with with things like you know linear regression",
    "start": "1126660",
    "end": "1132660"
  },
  {
    "text": "or gradient boosted trees or the like and the it really doesn't it isn't",
    "start": "1132660",
    "end": "1140970"
  },
  {
    "text": "necessary to have multiple implementations of of linear regression",
    "start": "1140970",
    "end": "1146190"
  },
  {
    "text": "or PCA or k-means there there really is a very few efficient implementations of",
    "start": "1146190",
    "end": "1152010"
  },
  {
    "text": "that so as a result we've provided a set of I think it's up to 18 now built-in",
    "start": "1152010",
    "end": "1157680"
  },
  {
    "text": "built-in algorithms that you can use for various problems to everything from the general-purpose to things like a",
    "start": "1157680",
    "end": "1164820"
  },
  {
    "text": "sequence to sequence language focused ones object detection semantic segmentation for for images and we even",
    "start": "1164820",
    "end": "1172710"
  },
  {
    "text": "launched IP insights which helps you with login anomaly detection in the",
    "start": "1172710",
    "end": "1177900"
  },
  {
    "text": "security space so the idea there is we'll provide you with a good set of built-in algorithms and the marketplace",
    "start": "1177900",
    "end": "1184200"
  },
  {
    "text": "will provide you with additional algorithms that you can use even if you don't have that expertise Union house",
    "start": "1184200",
    "end": "1190560"
  },
  {
    "text": "and then you can deploy your own ways well you can deploy into into sage maker",
    "start": "1190560",
    "end": "1196929"
  },
  {
    "start": "1191000",
    "end": "1240000"
  },
  {
    "text": "and I'll talk a little bit later about about the deployment methods but",
    "start": "1196929",
    "end": "1202270"
  },
  {
    "text": "essentially you can even bring your bottle in from outside of sage maker if you chose to train in the sage maker",
    "start": "1202270",
    "end": "1208179"
  },
  {
    "text": "notebook or if you chose to train in SPARC I have customers that are training",
    "start": "1208179",
    "end": "1213490"
  },
  {
    "text": "in their own on-premises spark clusters and they say this deployment part of",
    "start": "1213490",
    "end": "1218500"
  },
  {
    "text": "sage maker is is really useful for us so we'll just use deployment sage maker is",
    "start": "1218500",
    "end": "1223990"
  },
  {
    "text": "is the set of loosely coupled services that you can use in order to help you",
    "start": "1223990",
    "end": "1231250"
  },
  {
    "text": "speed up your machine learning workflow we're not going to say you must use all of the sage maker components in order to",
    "start": "1231250",
    "end": "1238030"
  },
  {
    "text": "get use out of it and and similarly you can also automatically tune models the",
    "start": "1238030",
    "end": "1245740"
  },
  {
    "start": "1240000",
    "end": "1260000"
  },
  {
    "text": "one thing that I want to call out here is that you can automatically tune models that you brought yourself so even",
    "start": "1245740",
    "end": "1252520"
  },
  {
    "text": "if you brought in a docker container with your own secret sauce algorithm you can still use it for hyper parameter",
    "start": "1252520",
    "end": "1258429"
  },
  {
    "text": "tuning so the goal here is that we want",
    "start": "1258429",
    "end": "1263650"
  },
  {
    "text": "to make common development tools easier to use for ml we want to make a docker",
    "start": "1263650",
    "end": "1269710"
  },
  {
    "text": "easy so for the most part even though docker is the underlying technology that",
    "start": "1269710",
    "end": "1275470"
  },
  {
    "text": "we use for a lot of sage maker data scientists don't really need to know how",
    "start": "1275470",
    "end": "1280900"
  },
  {
    "text": "to interact with docker in order to use sage maker for that purpose similarly we announced git integration",
    "start": "1280900",
    "end": "1288640"
  },
  {
    "text": "and and I can demo that shortly we announced git integration that allows",
    "start": "1288640",
    "end": "1294760"
  },
  {
    "text": "the data scientist to work with git and one of one of my my customers said we",
    "start": "1294760",
    "end": "1301210"
  },
  {
    "text": "have we just had a data scientist consultant start with us and she for the",
    "start": "1301210",
    "end": "1307240"
  },
  {
    "text": "for the life of her won't use git she can't figure out how to use use git she",
    "start": "1307240",
    "end": "1313360"
  },
  {
    "text": "can't check in stuff she really just doesn't want to use it and for that",
    "start": "1313360",
    "end": "1319030"
  },
  {
    "text": "reason I mean it goes back to what I was saying about data scientists like their tools they want to use only their tools",
    "start": "1319030",
    "end": "1325419"
  },
  {
    "text": "and they are really focused on hard problems which means that the tools need to work with",
    "start": "1325419",
    "end": "1332080"
  },
  {
    "text": "them and that's the philosophy that we used in order to develop these integrations similarly with AWS step functions when",
    "start": "1332080",
    "end": "1340120"
  },
  {
    "text": "it comes time to operationalize these we integrated together with step step functions and and Apache airflow so that",
    "start": "1340120",
    "end": "1348039"
  },
  {
    "text": "you can take the processes that scientists use and operationalize them very easily using sage maker and the",
    "start": "1348039",
    "end": "1355120"
  },
  {
    "text": "integrations with other services and then it also integrates with Auto scale",
    "start": "1355120",
    "end": "1361059"
  },
  {
    "text": "and and monitoring and logging so that you can use that in the same way that you use other AWS services so let me",
    "start": "1361059",
    "end": "1369549"
  },
  {
    "start": "1368000",
    "end": "1384000"
  },
  {
    "text": "quickly kind of show you what it looks like and and do a little demo of of it and then we can we can continue talking",
    "start": "1369549",
    "end": "1378460"
  },
  {
    "text": "about how you can use sage maker 2 to address these challenges so I've got the",
    "start": "1378460",
    "end": "1386010"
  },
  {
    "text": "console loaded up and one of the things that that you you notice as as part of",
    "start": "1386010",
    "end": "1393370"
  },
  {
    "text": "the instance settings is that you're able to specify a git repository as as",
    "start": "1393370",
    "end": "1400149"
  },
  {
    "text": "part of the configuration likewise you can supply security groups you can",
    "start": "1400149",
    "end": "1408250"
  },
  {
    "text": "enable or disable internet access and all of the traffic from this to my V PC",
    "start": "1408250",
    "end": "1415570"
  },
  {
    "text": "because I've specified a subnet and I've specified a V PC at instance creation",
    "start": "1415570",
    "end": "1421600"
  },
  {
    "text": "all of this traffic will go through Amazon networks none of the traffic goes through the public internet as long as",
    "start": "1421600",
    "end": "1427960"
  },
  {
    "text": "I'm accessing private link endpoints which is a really big plus for companies",
    "start": "1427960",
    "end": "1434110"
  },
  {
    "text": "that are dealing with sensitive data financial data healthcare data government data that kind of thing so if",
    "start": "1434110",
    "end": "1442269"
  },
  {
    "text": "I actually let me do it from here so I'll open up the open up the Jupiter lab",
    "start": "1442269",
    "end": "1450700"
  },
  {
    "text": "notebook view and it goes straight into into Jupiter lab which is I guess they",
    "start": "1450700",
    "end": "1459490"
  },
  {
    "text": "can't open up two of them it goes straight into Jupiter lab which is a convenient environment that data",
    "start": "1459490",
    "end": "1465100"
  },
  {
    "text": "scientists are very used to this is the kind of thing that they work with on a",
    "start": "1465100",
    "end": "1470170"
  },
  {
    "text": "regular basis but at the same time you have get integration with it and they",
    "start": "1470170",
    "end": "1477190"
  },
  {
    "text": "don't need to think about it it syncs the it syncs the changes it detects these changes you can push push those",
    "start": "1477190",
    "end": "1485770"
  },
  {
    "text": "committed changes very easily you can stage the changes for commit so if I put",
    "start": "1485770",
    "end": "1491140"
  },
  {
    "text": "in comments here I can I can stage those changes and so on so it provides a",
    "start": "1491140",
    "end": "1497710"
  },
  {
    "text": "really convenient environment in which the data scientists can work and they",
    "start": "1497710",
    "end": "1502750"
  },
  {
    "text": "can stay in this environment and they're not forced to switch between tools that",
    "start": "1502750",
    "end": "1508180"
  },
  {
    "text": "they're familiar with and unfamiliar with in order to work with DevOps in your organization so let's go back to",
    "start": "1508180",
    "end": "1517210"
  },
  {
    "text": "this",
    "start": "1517210",
    "end": "1519360"
  },
  {
    "text": "so again we look at we look at these",
    "start": "1524330",
    "end": "1530510"
  },
  {
    "text": "develops challenges I briefly mentioned them how does sage maker work in order to",
    "start": "1530510",
    "end": "1536990"
  },
  {
    "text": "address these challenges to start with for compliance and audit AWS have used",
    "start": "1536990",
    "end": "1543620"
  },
  {
    "text": "this as a shared responsibility between you guys and and us so we will maintain",
    "start": "1543620",
    "end": "1550600"
  },
  {
    "text": "the compliance of the cloud and you maintain compliance in the cloud and",
    "start": "1550600",
    "end": "1556060"
  },
  {
    "text": "that's the way that we look at it so as part of that there are certain services",
    "start": "1556060",
    "end": "1561530"
  },
  {
    "text": "that are in scope for several compliance regimes for sage maker in particular",
    "start": "1561530",
    "end": "1567470"
  },
  {
    "text": "we're in scope for ISO we're in scope for PCI DSS we're in scope for for sock",
    "start": "1567470",
    "end": "1574820"
  },
  {
    "text": "one two and three and we are compatible with gdpr and and HIPAA for those that",
    "start": "1574820",
    "end": "1582080"
  },
  {
    "text": "deal with healthcare data and and ITAR as well which is sort of a more US",
    "start": "1582080",
    "end": "1589760"
  },
  {
    "text": "specific thing this is a list that continually grows this is a list that",
    "start": "1589760",
    "end": "1596510"
  },
  {
    "text": "we're trying to make sure that we have our compliant with various regimes and",
    "start": "1596510",
    "end": "1602000"
  },
  {
    "text": "part of this is because we know this is important for operationalization like it's great if it's a science experiment",
    "start": "1602000",
    "end": "1607880"
  },
  {
    "text": "if it's a one-off usually you can get your internal people to sign off on something that's internal only in an",
    "start": "1607880",
    "end": "1614120"
  },
  {
    "text": "experiment but when it comes time to production you actually have to make sure that you're adhering to the",
    "start": "1614120",
    "end": "1619880"
  },
  {
    "text": "appropriate laws when it comes to dealing with the√°-- we're in a similar fashion we're",
    "start": "1619880",
    "end": "1627340"
  },
  {
    "text": "available in in 14 different regions including India which is something that",
    "start": "1627340",
    "end": "1632630"
  },
  {
    "text": "we launched in in November we're continuing to be aggressive about regional expansion we know that's",
    "start": "1632630",
    "end": "1638300"
  },
  {
    "text": "something that's that's important for people who deal with data that has to stay within the borders the the goal is",
    "start": "1638300",
    "end": "1645410"
  },
  {
    "text": "that you would be able to use sage maker for all of these these types of problems and we integrate automatically with AWS",
    "start": "1645410",
    "end": "1652280"
  },
  {
    "text": "croute the cloud trail which means that you have an audit log of all of these actions being recorded in a place that's",
    "start": "1652280",
    "end": "1658190"
  },
  {
    "text": "convenient to work with for compliance purposes another thing that we've spent",
    "start": "1658190",
    "end": "1665779"
  },
  {
    "start": "1663000",
    "end": "1816000"
  },
  {
    "text": "a great deal of effort on is security because the data that people usually",
    "start": "1665779",
    "end": "1670879"
  },
  {
    "text": "want to do machine learning with I've had customers that that come to me usually the first thing that they say is",
    "start": "1670879",
    "end": "1677600"
  },
  {
    "text": "we want to put business critical data and do machine learning with our business critical data frankly that's",
    "start": "1677600",
    "end": "1684350"
  },
  {
    "text": "not what I would recommend starting out with I would recommend starting out with something that's a little easier and",
    "start": "1684350",
    "end": "1690919"
  },
  {
    "text": "doesn't have as many challenges as your business critical data but that's clearly where customers want to get and",
    "start": "1690919",
    "end": "1696529"
  },
  {
    "text": "because it's business critical data it's it's the data that is most crucial to your business we want to make sure that",
    "start": "1696529",
    "end": "1703190"
  },
  {
    "text": "we're acting as good stewards and providing the appropriate level of",
    "start": "1703190",
    "end": "1708259"
  },
  {
    "text": "security for that so we we do things like sage maker itself doesn't store",
    "start": "1708259",
    "end": "1716539"
  },
  {
    "text": "data except for intermediate data and ground truth and an in-ear media data",
    "start": "1716539",
    "end": "1723679"
  },
  {
    "text": "within things like like training and so",
    "start": "1723679",
    "end": "1728690"
  },
  {
    "text": "on we don't persist that data the data gets persisted in your account under",
    "start": "1728690",
    "end": "1733909"
  },
  {
    "text": "your control encrypted with your key and this is important because we we don't",
    "start": "1733909",
    "end": "1739190"
  },
  {
    "text": "retain any control of the data we don't retain any data we actually provide all",
    "start": "1739190",
    "end": "1744559"
  },
  {
    "text": "of that data back to you put it in your account so you can control it delete it do whatever is",
    "start": "1744559",
    "end": "1749840"
  },
  {
    "text": "needed in order to manage your own internal policies so you manage the",
    "start": "1749840",
    "end": "1755240"
  },
  {
    "text": "lifecycle of the data and all of the artifacts everything that is associated with it and because of that we we don't retain",
    "start": "1755240",
    "end": "1763940"
  },
  {
    "text": "permission to the data either so in order to have permission to access your",
    "start": "1763940",
    "end": "1769039"
  },
  {
    "text": "data in order to use your your docker containers and so on you pass in a role",
    "start": "1769039",
    "end": "1774440"
  },
  {
    "text": "you pass into an iamb role to Sage makers so sage maker has that permission",
    "start": "1774440",
    "end": "1779450"
  },
  {
    "text": "for as long as we hold hold on to the I am role and then once the operation is",
    "start": "1779450",
    "end": "1784850"
  },
  {
    "text": "done once training is done or once we're done with auto-scaling we toss that role away so that we",
    "start": "1784850",
    "end": "1791280"
  },
  {
    "text": "longer have permissions to that data we also don't use shared instances so the",
    "start": "1791280",
    "end": "1797100"
  },
  {
    "text": "instances that we use are dedicated to you and that that means that relative to",
    "start": "1797100",
    "end": "1803780"
  },
  {
    "text": "some of the attacks that we've seen meltdown inspector and so on earlier in",
    "start": "1803780",
    "end": "1809580"
  },
  {
    "text": "the year that's not something that's as much of a concern because those instances aren't being shared we also if",
    "start": "1809580",
    "end": "1819510"
  },
  {
    "text": "you specify a key that you manage we use that key for encryption at rest we",
    "start": "1819510",
    "end": "1824610"
  },
  {
    "text": "encrypt all of the artifacts including the model artifacts if you specify a key",
    "start": "1824610",
    "end": "1829950"
  },
  {
    "text": "for that we encrypt those and you may ask why the model artifacts because is",
    "start": "1829950",
    "end": "1837000"
  },
  {
    "text": "that really important to encrypt and what I would say to you is there there",
    "start": "1837000",
    "end": "1843000"
  },
  {
    "text": "are these attacks that are model inversion attacks that can potentially regenerate some of the data based on",
    "start": "1843000",
    "end": "1850460"
  },
  {
    "text": "taking the model and having some of the data available they're able to regenerate some of the other data these",
    "start": "1850460",
    "end": "1857100"
  },
  {
    "text": "these are attacks that are pretty sophisticated and sort of Nation",
    "start": "1857100",
    "end": "1862770"
  },
  {
    "text": "attacked and researchy attacks at this point but at the same time when you start putting this production models",
    "start": "1862770",
    "end": "1870540"
  },
  {
    "text": "into production and you put business critical data into production we want to make sure that you have the tools that",
    "start": "1870540",
    "end": "1875850"
  },
  {
    "text": "you need in order to secure all of the information including the model artifacts and then in transit we use we",
    "start": "1875850",
    "end": "1883740"
  },
  {
    "text": "we use TLS between all of the components that we have we we also support virtual",
    "start": "1883740",
    "end": "1891930"
  },
  {
    "text": "private clouds which means that none of this none of this data will go over the",
    "start": "1891930",
    "end": "1897810"
  },
  {
    "text": "public Internet we encrypt it but we also give you the ability to make sure",
    "start": "1897810",
    "end": "1903960"
  },
  {
    "text": "that none of this data goes over the public Internet so it's encrypted even within the Amazon Network and we support",
    "start": "1903960",
    "end": "1911670"
  },
  {
    "text": "we support private link so that when you access those those jupiter' notebook",
    "start": "1911670",
    "end": "1917280"
  },
  {
    "text": "instances you can access them through your V PC so even that data doesn't go through the public internet and",
    "start": "1917280",
    "end": "1923010"
  },
  {
    "text": "and so on so we treat this as something that is critical to provide you the",
    "start": "1923010",
    "end": "1928710"
  },
  {
    "text": "tools with so that you can operationalize machine learning it's not a one-off experiment it's something that",
    "start": "1928710",
    "end": "1933990"
  },
  {
    "text": "you need to be able to do repeatedly it's something that you need to have templates for to create this environment",
    "start": "1933990",
    "end": "1939990"
  },
  {
    "text": "is something that you need to customize for your environment and be able to when",
    "start": "1939990",
    "end": "1945000"
  },
  {
    "text": "a data scientist gets on-boarded into your organization be able to say here's your notebook instance you can get up",
    "start": "1945000",
    "end": "1951990"
  },
  {
    "text": "and running quickly and we know this is an environment that has the tools for you is secure to use with the data that you",
    "start": "1951990",
    "end": "1959400"
  },
  {
    "text": "need to access so that you can get up and running we also give you the ability",
    "start": "1959400",
    "end": "1968010"
  },
  {
    "start": "1964000",
    "end": "1977000"
  },
  {
    "text": "to configure the notebooks so that they don't have internet access and and so on in order to make it a truly sequestered",
    "start": "1968010",
    "end": "1975710"
  },
  {
    "text": "environment so the next thing is we have",
    "start": "1975710",
    "end": "1982080"
  },
  {
    "start": "1977000",
    "end": "2093000"
  },
  {
    "text": "heard from quite a few customers that they're looking for portability between",
    "start": "1982080",
    "end": "1988170"
  },
  {
    "text": "environments some of the applications that they have are appropriate for Sage maker and some are not and some need to",
    "start": "1988170",
    "end": "1994110"
  },
  {
    "text": "run in on-premises for business reasons these are things that we want to enable and yes we're we're very happy if we're",
    "start": "1994110",
    "end": "2001880"
  },
  {
    "text": "able to serve you with with sage maker hosting and in the cloud but that's the same time we know that there are",
    "start": "2001880",
    "end": "2007790"
  },
  {
    "text": "business considerations that make it such that not every workload is able to run that way so sage makers is designed",
    "start": "2007790",
    "end": "2015860"
  },
  {
    "text": "in a way that lends itself to portability it uses docker containers those docker containers the ones where",
    "start": "2015860",
    "end": "2021950"
  },
  {
    "text": "we produce our open sourced the libraries that we produce whether it's the Python library that you can use on",
    "start": "2021950",
    "end": "2030290"
  },
  {
    "text": "your on your desktop or in the notebook instances the Python libraries are open source the SPARC library is open source",
    "start": "2030290",
    "end": "2036710"
  },
  {
    "text": "we really want to produce an environment that allows you to seamlessly move from",
    "start": "2036710",
    "end": "2042620"
  },
  {
    "text": "environment to environment as your business dictates we re believe that a",
    "start": "2042620",
    "end": "2047840"
  },
  {
    "text": "large part of it is best in the cloud but at the same time if you have business constraints that make it so",
    "start": "2047840",
    "end": "2054050"
  },
  {
    "text": "that you can't use the cloud for everything we still want to enable your business so we we've",
    "start": "2054050",
    "end": "2060050"
  },
  {
    "text": "designed things to allow you to be able to take advantage of some of our work even in other environments and we also",
    "start": "2060050",
    "end": "2068899"
  },
  {
    "text": "deploy with availability in mind so AWS in in general has multiple availability",
    "start": "2068900",
    "end": "2075620"
  },
  {
    "text": "zones per region and we automatically deploy into multiple availability zones",
    "start": "2075620",
    "end": "2080870"
  },
  {
    "text": "in order to maintain high availability and of course just like everything else we monitor the infrastructure in order",
    "start": "2080870",
    "end": "2087200"
  },
  {
    "text": "to make sure that everything is up and running and and work seamlessly so the",
    "start": "2087200",
    "end": "2094879"
  },
  {
    "start": "2093000",
    "end": "2127000"
  },
  {
    "text": "last challenge that I want to talk about is is scalability and this is one of",
    "start": "2094880",
    "end": "2100310"
  },
  {
    "text": "those challenges that you only encounter once you're in a production environment which is why it becomes much more of a",
    "start": "2100310",
    "end": "2107510"
  },
  {
    "text": "challenge that's the point at which if if you go with the toss the model over",
    "start": "2107510",
    "end": "2112910"
  },
  {
    "text": "the fence kind of approach you end up with stuff like this where you know how do you operationalize",
    "start": "2112910",
    "end": "2120950"
  },
  {
    "text": "it if you have this kind of spiky workload and it wasn't designed with",
    "start": "2120950",
    "end": "2125960"
  },
  {
    "text": "that in mind the way we do it is we provide integration with AWS application",
    "start": "2125960",
    "end": "2132770"
  },
  {
    "start": "2127000",
    "end": "2204000"
  },
  {
    "text": "auto scaling and you can basically set the min and Max instances you can set",
    "start": "2132770",
    "end": "2138260"
  },
  {
    "text": "the number of target invitations so that you're able to say each instance we",
    "start": "2138260",
    "end": "2144620"
  },
  {
    "text": "believe it should be able to take this many invitations I think we recommend",
    "start": "2144620",
    "end": "2149870"
  },
  {
    "text": "that you use scale-up at at 50% of the max invitations so that you have a",
    "start": "2149870",
    "end": "2154970"
  },
  {
    "text": "little bit of buffer and it'll scale up at the point at which you choose so once",
    "start": "2154970",
    "end": "2161330"
  },
  {
    "text": "you actually see this in action you essentially see the the load go up and",
    "start": "2161330",
    "end": "2168040"
  },
  {
    "text": "once auto scaling kicks in when it's above that threshold you see the number",
    "start": "2168040",
    "end": "2173960"
  },
  {
    "text": "of invitations per instance actually goes down because you transitioned over to the point where you have an",
    "start": "2173960",
    "end": "2179540"
  },
  {
    "text": "additional instance in this particular case I think we transition from from one to two instances so it's pretty dramatic",
    "start": "2179540",
    "end": "2187210"
  },
  {
    "text": "in in most cases if you actually look at a product work load it's not going to be that",
    "start": "2187210",
    "end": "2192470"
  },
  {
    "text": "dramatic it's going to drop a little but because you're already running at scale and you're just adjusting the number of",
    "start": "2192470",
    "end": "2198650"
  },
  {
    "text": "instances to suit the traffic it won't be quite this dramatic the the reason",
    "start": "2198650",
    "end": "2206240"
  },
  {
    "start": "2204000",
    "end": "2261000"
  },
  {
    "text": "the reason we chose the the scaling criteria as as the typical scaling",
    "start": "2206240",
    "end": "2212060"
  },
  {
    "text": "criteria as being invocation per second per instance is because there's a great",
    "start": "2212060",
    "end": "2218510"
  },
  {
    "text": "deal of non uniformity between the requirements of each of these algorithms",
    "start": "2218510",
    "end": "2223780"
  },
  {
    "text": "there's different memory requirements different CPU different GPU requirements all of that kind of thing which means",
    "start": "2223780",
    "end": "2230660"
  },
  {
    "text": "that essentially the indications seems to be the lowest common denominator",
    "start": "2230660",
    "end": "2235880"
  },
  {
    "text": "scaling parameter that you can use of course if you develop your own custom",
    "start": "2235880",
    "end": "2240950"
  },
  {
    "text": "algorithms and you'e meant to cloud wash you can actually use those there's no particular restriction on what scaling",
    "start": "2240950",
    "end": "2247940"
  },
  {
    "text": "parameter you can use we can consume anything based on on the instances CloudWatch metrics but because we wanted",
    "start": "2247940",
    "end": "2255680"
  },
  {
    "text": "to provide a pattern that could easily be used by you we we chose the invitations per second and if you look",
    "start": "2255680",
    "end": "2262820"
  },
  {
    "text": "at the way that these are are specified it's actually specified in a in a pretty",
    "start": "2262820",
    "end": "2269030"
  },
  {
    "text": "simple format you just register the scaleable target and you provide the",
    "start": "2269030",
    "end": "2275060"
  },
  {
    "text": "parameters for scaling min and Max instances and that kind of thing and",
    "start": "2275060",
    "end": "2280849"
  },
  {
    "text": "then you provide the policy that you would use in order to make it scale on",
    "start": "2280849",
    "end": "2287900"
  },
  {
    "text": "in this case number of invitations per second so if you scale by utilization in",
    "start": "2287900",
    "end": "2294680"
  },
  {
    "start": "2292000",
    "end": "2301000"
  },
  {
    "text": "this way this is this is essentially the way that that the scaling works out so",
    "start": "2294680",
    "end": "2303070"
  },
  {
    "start": "2301000",
    "end": "2393000"
  },
  {
    "text": "if you look at a sage maker sage maker",
    "start": "2303070",
    "end": "2308930"
  },
  {
    "text": "itself we also provide you with a number of options for deploying I've talked a",
    "start": "2308930",
    "end": "2315740"
  },
  {
    "text": "bit about some of the really the scalability characteristics are mostly centered around real time deployment but",
    "start": "2315740",
    "end": "2322880"
  },
  {
    "text": "that's only one the options that you can use for deployment and it isn't necessarily the right one for all of the business use",
    "start": "2322880",
    "end": "2329150"
  },
  {
    "text": "cases which is why we provide you with multiple options for doing that you have",
    "start": "2329150",
    "end": "2334190"
  },
  {
    "text": "real-time deployment but you also have batch transformation we integrate",
    "start": "2334190",
    "end": "2339560"
  },
  {
    "text": "together with Greengrass ml which allows you to deploy two devices you can even",
    "start": "2339560",
    "end": "2345380"
  },
  {
    "text": "take the model artifacts out and you can deploy them straight to devices using your own pipeline I know there's there's",
    "start": "2345380",
    "end": "2352370"
  },
  {
    "text": "customers I have customers like GE Healthcare who deploy to x-ray machines",
    "start": "2352370",
    "end": "2357680"
  },
  {
    "text": "I mean you can't really expect Greengrass to be running on on their x-ray machine so they have their own",
    "start": "2357680",
    "end": "2363650"
  },
  {
    "text": "deployment pipeline that they use they have their own processes around that but they're still able to use sage maker for",
    "start": "2363650",
    "end": "2369500"
  },
  {
    "text": "training and they're still able to operationally deploy it to all of their devices using that and you can even",
    "start": "2369500",
    "end": "2375860"
  },
  {
    "text": "deploy on whatever local environment you want because all of those artifacts all",
    "start": "2375860",
    "end": "2381680"
  },
  {
    "text": "of the results of training are in your account they're fully under your control you can do whatever you like with them",
    "start": "2381680",
    "end": "2388460"
  },
  {
    "text": "at that point you're not locked into sage maker so the the two options that",
    "start": "2388460",
    "end": "2396890"
  },
  {
    "start": "2393000",
    "end": "2452000"
  },
  {
    "text": "are built into sage maker are real time and and batch batch transformation batch",
    "start": "2396890",
    "end": "2403970"
  },
  {
    "text": "transformation is something that we launched in July real time we had it at launch in in November of 2017",
    "start": "2403970",
    "end": "2412870"
  },
  {
    "text": "there's two different really two different use cases for that you can get",
    "start": "2412870",
    "end": "2418760"
  },
  {
    "text": "some of the goodness of both of those cases depending on on what your business use cases some customers actually will",
    "start": "2418760",
    "end": "2426260"
  },
  {
    "text": "do things like if the data doesn't change over the course of a day and they",
    "start": "2426260",
    "end": "2431360"
  },
  {
    "text": "still want low latency characteristics they'll do things like batch transformation loaded into dynamodb and",
    "start": "2431360",
    "end": "2438200"
  },
  {
    "text": "then use use that dynamo jeebies low latency access time in order to pull in",
    "start": "2438200",
    "end": "2444770"
  },
  {
    "text": "the inferences so you can do things like that in order to address some of the use",
    "start": "2444770",
    "end": "2450230"
  },
  {
    "text": "cases both of these are similar in the",
    "start": "2450230",
    "end": "2455270"
  },
  {
    "start": "2452000",
    "end": "2519000"
  },
  {
    "text": "way that they work they use similar containers and part of that is an advantage as well because if you actually look at how data",
    "start": "2455270",
    "end": "2463400"
  },
  {
    "text": "scientists work data scientists typically end up working in a lot of batch environments they don't have a lot",
    "start": "2463400",
    "end": "2469820"
  },
  {
    "text": "of real time because if you think about real time as an ocean that's something",
    "start": "2469820",
    "end": "2475340"
  },
  {
    "text": "that's a production characteristic so when they're working on historical data they don't really have this notion of",
    "start": "2475340",
    "end": "2481190"
  },
  {
    "text": "real time it's a little strange to set up a real time endpoint and then feed things to it in batch so the advantage",
    "start": "2481190",
    "end": "2488300"
  },
  {
    "text": "of using this type of environment and using an environment in which you have the same docker container in both",
    "start": "2488300",
    "end": "2494090"
  },
  {
    "text": "real-time and batch is that when the data scientist works on this in a batch",
    "start": "2494090",
    "end": "2500090"
  },
  {
    "text": "environment they're able to take that same container and then as a DevOps engineer you can deploy that same",
    "start": "2500090",
    "end": "2505940"
  },
  {
    "text": "container into real time and then you don't have a discrepancy between the",
    "start": "2505940",
    "end": "2511160"
  },
  {
    "text": "environment in which the data scientists are working and the environment in which you're you're going into production just",
    "start": "2511160",
    "end": "2520670"
  },
  {
    "start": "2519000",
    "end": "2569000"
  },
  {
    "text": "briefly talking about the benefits of batch transform it's pretty low cost and",
    "start": "2520670",
    "end": "2527060"
  },
  {
    "text": "it's pay-as-you-go because sage maker just like for training will setup and teardown the",
    "start": "2527060",
    "end": "2532580"
  },
  {
    "text": "clusters you don't have any persistent instances and during the course of time",
    "start": "2532580",
    "end": "2538700"
  },
  {
    "text": "when you're actually doing inferences because of the embarrassingly parallel nature of inferences you end up with",
    "start": "2538700",
    "end": "2545840"
  },
  {
    "text": "very very high utilization which also contributes to lower cost for inferences",
    "start": "2545840",
    "end": "2551300"
  },
  {
    "text": "of course if you need real-time and if you need that lowly and see a response you can also use a sage maker in these",
    "start": "2551300",
    "end": "2559310"
  },
  {
    "text": "real-time environments I'll kind of skip over this this is the way that you would",
    "start": "2559310",
    "end": "2565250"
  },
  {
    "text": "configure a real-time endpoint briefly",
    "start": "2565250",
    "end": "2571220"
  },
  {
    "start": "2569000",
    "end": "2630000"
  },
  {
    "text": "talking about how you would update an endpoint because again this is a",
    "start": "2571220",
    "end": "2576530"
  },
  {
    "text": "production environment so when it's integrated together with your application you don't necessarily want",
    "start": "2576530",
    "end": "2582050"
  },
  {
    "text": "to have to do an application deployment every time you update your model which means that you need to be able to update",
    "start": "2582050",
    "end": "2587930"
  },
  {
    "text": "those and we do blue/green deployments within maker in order to update the model which",
    "start": "2587930",
    "end": "2593640"
  },
  {
    "text": "means that at all times there's a model up and running and serving your application so you're able to swap it",
    "start": "2593640",
    "end": "2600000"
  },
  {
    "text": "without any loss of availability in addition the same infrastructure can be",
    "start": "2600000",
    "end": "2605250"
  },
  {
    "text": "used for doing things like a be testing if you actually want to try and do",
    "start": "2605250",
    "end": "2611789"
  },
  {
    "text": "incremental training or if you want to try new models and update the algorithms you can actually deploy both of them",
    "start": "2611789",
    "end": "2618539"
  },
  {
    "text": "behind the same end point you can provide a weight and you can see whether you're your KPIs have changed as the",
    "start": "2618539",
    "end": "2626069"
  },
  {
    "text": "result of of deployment just briefly to",
    "start": "2626069",
    "end": "2632279"
  },
  {
    "start": "2630000",
    "end": "2740000"
  },
  {
    "text": "kind of talk about a few things that I didn't really touch on there's a lot",
    "start": "2632279",
    "end": "2637890"
  },
  {
    "text": "more there's a lot more sage maker is really focused on making sure that you're able to operationalize machine",
    "start": "2637890",
    "end": "2643980"
  },
  {
    "text": "learning so I encourage you to go and",
    "start": "2643980",
    "end": "2648990"
  },
  {
    "text": "look at the talks that were we're done at reinvent on ground truth ground truth",
    "start": "2648990",
    "end": "2654150"
  },
  {
    "text": "is way that you can operationalize human in the loop in order to label your data",
    "start": "2654150",
    "end": "2659269"
  },
  {
    "text": "we've also worked on reinforcement learning which enables you to easily set",
    "start": "2659269",
    "end": "2665819"
  },
  {
    "text": "up reinforcement learning environments the same way that you would set up more traditional supervised and unsupervised",
    "start": "2665819",
    "end": "2671940"
  },
  {
    "text": "learning environments you're able to compile models for specific hardware",
    "start": "2671940",
    "end": "2677819"
  },
  {
    "text": "targets you can even go back and trace from from a deployed model back to the",
    "start": "2677819",
    "end": "2684809"
  },
  {
    "text": "training data set using sage maker search that's something that we launched beta should be going gea soon and with",
    "start": "2684809",
    "end": "2692970"
  },
  {
    "text": "step functions we had a customer cox automotive basically show that you can",
    "start": "2692970",
    "end": "2699539"
  },
  {
    "text": "use the sage the sage maker step functions integrations that were announced in order to put a human",
    "start": "2699539",
    "end": "2706619"
  },
  {
    "text": "approval loop as part of your model deployment process so they have this pipeline created in in step functions",
    "start": "2706619",
    "end": "2713700"
  },
  {
    "text": "that automatically trains the model with data on a regular basis and then takes",
    "start": "2713700",
    "end": "2719670"
  },
  {
    "text": "that data passes or it takes that model houses into the to the data scientist for human approval",
    "start": "2719670",
    "end": "2726600"
  },
  {
    "text": "and once they approve then the model gets deployed into production so you can",
    "start": "2726600",
    "end": "2732420"
  },
  {
    "text": "do a number of these things in order to make sure that you have the right processes in order to operationalize",
    "start": "2732420",
    "end": "2738300"
  },
  {
    "text": "your machine learning and with that I'll take a few brief questions I know we're",
    "start": "2738300",
    "end": "2743390"
  },
  {
    "start": "2740000",
    "end": "2764000"
  },
  {
    "text": "quite a bit over time but I'll try and take a few questions if that's okay with",
    "start": "2743390",
    "end": "2749730"
  },
  {
    "text": "you thank you all for the time go ahead",
    "start": "2749730",
    "end": "2757950"
  },
  {
    "text": "please",
    "start": "2757950",
    "end": "2760220"
  },
  {
    "start": "2764000",
    "end": "2889000"
  },
  {
    "text": "yeah so sage maker does not use shared instances yes so it is not one docker",
    "start": "2765710",
    "end": "2779840"
  },
  {
    "text": "container and and so so what I'll say is we use darker not as a way to share the",
    "start": "2779840",
    "end": "2787370"
  },
  {
    "text": "instance with other customers it's it's your own instance but the reason we use",
    "start": "2787370",
    "end": "2792710"
  },
  {
    "text": "docker is that it's a convenient way to deploy code onto an instance you can",
    "start": "2792710",
    "end": "2799910"
  },
  {
    "text": "deploy multiple docker containers of your own container onto real time",
    "start": "2799910",
    "end": "2806180"
  },
  {
    "text": "scoring so we have the notion of these pipelines so you can deploy up to five instances in a pipeline into the real",
    "start": "2806180",
    "end": "2814430"
  },
  {
    "text": "time scoring environment we also have a another docker container to help facilitate connections with monitoring",
    "start": "2814430",
    "end": "2822310"
  },
  {
    "text": "to help facilitate connections to with the data and so on",
    "start": "2822310",
    "end": "2827420"
  },
  {
    "text": "Dockers use more as a as a deployment mechanism rather than to share that",
    "start": "2827420",
    "end": "2834410"
  },
  {
    "text": "instance with other consumers does that make sense yes No",
    "start": "2834410",
    "end": "2842530"
  },
  {
    "text": "so so green grass itself I'm not to",
    "start": "2850740",
    "end": "2856359"
  },
  {
    "text": "confess I'm not an expert on green grass but essentially what green grass is able",
    "start": "2856359",
    "end": "2861430"
  },
  {
    "text": "to do is it's it interacts with sage maker and is aware of the models that",
    "start": "2861430",
    "end": "2867730"
  },
  {
    "text": "are compatible with device deployment so if you go to green grass ml and you say",
    "start": "2867730",
    "end": "2872770"
  },
  {
    "text": "I want to deploy a machine learning model it knows which models that were trained in sage maker are compatible",
    "start": "2872770",
    "end": "2878470"
  },
  {
    "text": "with devices deployment and it'll let you select that and deploy those neveri",
    "start": "2878470",
    "end": "2884020"
  },
  {
    "text": "here go ahead",
    "start": "2884020",
    "end": "2888660"
  },
  {
    "start": "2889000",
    "end": "2961000"
  },
  {
    "text": "[Music]",
    "start": "2896650",
    "end": "2906880"
  },
  {
    "text": "so the question is around redshift and and sage maker we we don't have a",
    "start": "2906880",
    "end": "2912739"
  },
  {
    "text": "specific integration with redshift in general the way that we view that you",
    "start": "2912739",
    "end": "2918559"
  },
  {
    "text": "would want to work with sage maker is that you'd want to use s3 as your data link and sage maker will work with s3 so",
    "start": "2918559",
    "end": "2925579"
  },
  {
    "text": "we have so yes so so the communication",
    "start": "2925579",
    "end": "2933200"
  },
  {
    "text": "with s3 is actually optimized in a in a very specific way in order to make sure that we have an optimal connection",
    "start": "2933200",
    "end": "2939709"
  },
  {
    "text": "between s3 and the compute instances and and that's the reason why the answer",
    "start": "2939709",
    "end": "2945019"
  },
  {
    "text": "there is we don't have a specific integration with redshift because the way we see most customers working with",
    "start": "2945019",
    "end": "2952809"
  },
  {
    "text": "with sage maker is with data that's in s3 one more question and then I probably",
    "start": "2952809",
    "end": "2959569"
  },
  {
    "text": "have to move on",
    "start": "2959569",
    "end": "2962469"
  },
  {
    "start": "2961000",
    "end": "3181000"
  },
  {
    "text": "yes yes",
    "start": "2967560",
    "end": "2971040"
  },
  {
    "text": "great question thank you for that question so so the question was I",
    "start": "2976609",
    "end": "2983029"
  },
  {
    "text": "mentioned sage maker set up locally because it takes time for the instance to spin up and yes that's absolutely one",
    "start": "2983029",
    "end": "2991140"
  },
  {
    "text": "of the reasons why we created sage maker local mode you can actually use sage maker local mode within the notebook",
    "start": "2991140",
    "end": "2998760"
  },
  {
    "text": "instances which lets you do a little training iteration very quickly we the",
    "start": "2998760",
    "end": "3005210"
  },
  {
    "text": "way the way that we view it is there's there's two stages where you want to try",
    "start": "3005210",
    "end": "3011119"
  },
  {
    "text": "and do this training one is I'm experimenting with small amounts of data",
    "start": "3011119",
    "end": "3017150"
  },
  {
    "text": "I really need the results fast and I want to iterate through to see what",
    "start": "3017150",
    "end": "3022220"
  },
  {
    "text": "works with you know a 1% sample or a 10% sample of that kind of thing and for",
    "start": "3022220",
    "end": "3027770"
  },
  {
    "text": "that you would use sage maker local mode you can use sage maker local mode on your laptop if you want or you can use",
    "start": "3027770",
    "end": "3034549"
  },
  {
    "text": "sage maker local mode in the notebook instances and then train on the local local",
    "start": "3034549",
    "end": "3040460"
  },
  {
    "text": "notebook instance locally it's similar",
    "start": "3040460",
    "end": "3045650"
  },
  {
    "text": "API so you can use all of the containers I'm still working on that you can use",
    "start": "3045650",
    "end": "3050990"
  },
  {
    "text": "the deep learning containers because they're all open-source as we open source more and more containers you'll",
    "start": "3050990",
    "end": "3056690"
  },
  {
    "text": "have more containers that that you have access to but essentially that's the that's the gating factor for which one's",
    "start": "3056690",
    "end": "3063020"
  },
  {
    "text": "you you can use in in local mode and and there's a few that are that are coming",
    "start": "3063020",
    "end": "3070000"
  },
  {
    "text": "where we know that we know that that's a bit of a pain point then at the point at",
    "start": "3070000",
    "end": "3077270"
  },
  {
    "text": "which you're able to do that training locally and you're satisfied with the training and you want to actually train",
    "start": "3077270",
    "end": "3082880"
  },
  {
    "text": "on a full data set the the way that we we think is more appropriate to",
    "start": "3082880",
    "end": "3087920"
  },
  {
    "text": "operationalize it and to work with large data is sage maker training and it's really built for moving from small data",
    "start": "3087920",
    "end": "3095869"
  },
  {
    "text": "sets to these these larger I mean up to petabyte scale data sets that's really",
    "start": "3095869",
    "end": "3101809"
  },
  {
    "text": "the appropriate environment keeping the notebook instance persistent and and up and running",
    "start": "3101809",
    "end": "3108150"
  },
  {
    "text": "frankly into it into it and and I worked",
    "start": "3108150",
    "end": "3113560"
  },
  {
    "text": "on on that the initial way that data scientists were working with sage maker",
    "start": "3113560",
    "end": "3118690"
  },
  {
    "text": "was they had these persistent notebook instances and then into it came to me and said hey our cost is really high I'm",
    "start": "3118690",
    "end": "3125380"
  },
  {
    "text": "like yeah because you've got data scientists that are running these m416 X XLS 24 hours a day of course the cost is",
    "start": "3125380",
    "end": "3133150"
  },
  {
    "text": "high let's try and move them towards training where they're using samples of",
    "start": "3133150",
    "end": "3139540"
  },
  {
    "text": "data in smaller instances on these these hosted notebook instances and when it",
    "start": "3139540",
    "end": "3144610"
  },
  {
    "text": "comes time to training they're spinning up on demand clusters of these instances",
    "start": "3144610",
    "end": "3150040"
  },
  {
    "text": "whether it's single ones you know a single m416 excel or if they want even",
    "start": "3150040",
    "end": "3155710"
  },
  {
    "text": "ten m4x cells they're able to spin it up they're able to do that training really quickly and that's the model that we",
    "start": "3155710",
    "end": "3162820"
  },
  {
    "text": "view so experimentation locally and then for operational large data training that",
    "start": "3162820",
    "end": "3169869"
  },
  {
    "text": "you would want to be able to use training makes sense thank you all very much I appreciate the time and hopefully",
    "start": "3169869",
    "end": "3176680"
  },
  {
    "text": "some of you will stick around for the talking parameters unique",
    "start": "3176680",
    "end": "3182400"
  }
]
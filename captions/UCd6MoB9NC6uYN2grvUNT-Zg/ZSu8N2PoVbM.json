[
  {
    "text": "it's time for the map produce lab where",
    "start": "120",
    "end": "2000"
  },
  {
    "text": "you get a chance to actually build and",
    "start": "2000",
    "end": "3679"
  },
  {
    "text": "run some of the code that uh I was using",
    "start": "3679",
    "end": "6560"
  },
  {
    "text": "previously so this lab is a code that",
    "start": "6560",
    "end": "10360"
  },
  {
    "text": "parses a Wikipedia dump the Wikipedia",
    "start": "10360",
    "end": "13000"
  },
  {
    "text": "dump consists of a bunch of text files",
    "start": "13000",
    "end": "15759"
  },
  {
    "text": "that have been uploaded at S3 where",
    "start": "15759",
    "end": "17279"
  },
  {
    "text": "every Wikipedia page the XML for it has",
    "start": "17279",
    "end": "19880"
  },
  {
    "text": "been put on an separate line that means",
    "start": "19880",
    "end": "22400"
  },
  {
    "text": "that you can process that data without",
    "start": "22400",
    "end": "24760"
  },
  {
    "text": "having to worry about issues of",
    "start": "24760",
    "end": "26240"
  },
  {
    "text": "splitting XML across lines and the",
    "start": "26240",
    "end": "28760"
  },
  {
    "text": "output from this is top Byram so it's a",
    "start": "28760",
    "end": "31320"
  },
  {
    "text": "standard thing of like counting the",
    "start": "31320",
    "end": "32398"
  },
  {
    "text": "occurrence of character Pairs and the",
    "start": "32399",
    "end": "34559"
  },
  {
    "text": "output from it is tab separated value",
    "start": "34559",
    "end": "36960"
  },
  {
    "text": "text files you actually wind up with two",
    "start": "36960",
    "end": "38840"
  },
  {
    "text": "sets of outputs one is just the raw data",
    "start": "38840",
    "end": "41120"
  },
  {
    "text": "and then there's a second job which",
    "start": "41120",
    "end": "42360"
  },
  {
    "text": "winds up sorting that so you get sorted",
    "start": "42360",
    "end": "44039"
  },
  {
    "text": "counts where it's sorted from high to",
    "start": "44039",
    "end": "45800"
  },
  {
    "text": "low by Byram",
    "start": "45800",
    "end": "47960"
  },
  {
    "text": "occurrence in order to run this lab",
    "start": "47960",
    "end": "49879"
  },
  {
    "text": "you've got to be set up in AWS which",
    "start": "49879",
    "end": "51760"
  },
  {
    "text": "means you've got an AWS account set up",
    "start": "51760",
    "end": "53079"
  },
  {
    "text": "you've done all the things that we",
    "start": "53079",
    "end": "54199"
  },
  {
    "text": "talked about at the very beginning where",
    "start": "54199",
    "end": "56600"
  },
  {
    "text": "you need to uh access to request access",
    "start": "56600",
    "end": "60199"
  },
  {
    "text": "for elastic map reduce uh you need to",
    "start": "60199",
    "end": "63039"
  },
  {
    "text": "make sure you've got your AWS Management",
    "start": "63039",
    "end": "65720"
  },
  {
    "text": "console um working and then if that's",
    "start": "65720",
    "end": "69479"
  },
  {
    "text": "all good now you can go and you can",
    "start": "69479",
    "end": "71560"
  },
  {
    "text": "download the Wikipedia lab uh it's",
    "start": "71560",
    "end": "74040"
  },
  {
    "text": "located in S3 bucket of course Wikipedia",
    "start": "74040",
    "end": "76720"
  },
  {
    "text": "lab. tgz once you've downloaded it you",
    "start": "76720",
    "end": "79200"
  },
  {
    "text": "can expand it and then inside of that",
    "start": "79200",
    "end": "81759"
  },
  {
    "text": "expanded directory there's a readme file",
    "start": "81759",
    "end": "84360"
  },
  {
    "text": "and that's something that you should",
    "start": "84360",
    "end": "85759"
  },
  {
    "text": "then uh read through once and then",
    "start": "85759",
    "end": "87960"
  },
  {
    "text": "follow the instructions so let's go take",
    "start": "87960",
    "end": "90040"
  },
  {
    "text": "a look at",
    "start": "90040",
    "end": "91000"
  },
  {
    "text": "that okay we're in the",
    "start": "91000",
    "end": "93600"
  },
  {
    "text": "directory if I list you can see there's",
    "start": "93600",
    "end": "95799"
  },
  {
    "text": "there's actually two readmes one is the",
    "start": "95799",
    "end": "97479"
  },
  {
    "text": "readme uh which is about the lab there's",
    "start": "97479",
    "end": "99399"
  },
  {
    "text": "another one called read me- splitting",
    "start": "99399",
    "end": "101600"
  },
  {
    "text": "which talks about how to use a second",
    "start": "101600",
    "end": "103159"
  },
  {
    "text": "tool that's part of this lab that is",
    "start": "103159",
    "end": "105439"
  },
  {
    "text": "actually the thing that generated these",
    "start": "105439",
    "end": "107439"
  },
  {
    "text": "split XML files so if I go and",
    "start": "107439",
    "end": "111479"
  },
  {
    "text": "I open up that readme file uh it talks",
    "start": "111479",
    "end": "115000"
  },
  {
    "text": "about the prerequisites here and then it",
    "start": "115000",
    "end": "117280"
  },
  {
    "text": "has some steps so one of the first",
    "start": "117280",
    "end": "119320"
  },
  {
    "text": "things youve got to do do is go and",
    "start": "119320",
    "end": "120320"
  },
  {
    "text": "create a bucket in S3 as we talked about",
    "start": "120320",
    "end": "122719"
  },
  {
    "text": "before you need to have a bucket in S3",
    "start": "122719",
    "end": "124960"
  },
  {
    "text": "uh where your job jar is located and",
    "start": "124960",
    "end": "128239"
  },
  {
    "text": "also that's where your logs are going to",
    "start": "128239",
    "end": "129959"
  },
  {
    "text": "wind up and the results are going to go",
    "start": "129959",
    "end": "132040"
  },
  {
    "text": "so let's switch over to AWS",
    "start": "132040",
    "end": "136599"
  },
  {
    "text": "console let's go into",
    "start": "136599",
    "end": "138920"
  },
  {
    "text": "S3 and the very first thing we want to",
    "start": "138920",
    "end": "140840"
  },
  {
    "text": "do here is we want to create that bucket",
    "start": "140840",
    "end": "142720"
  },
  {
    "text": "and remember bucket names have to be",
    "start": "142720",
    "end": "144160"
  },
  {
    "text": "globally unique so in this case I'm",
    "start": "144160",
    "end": "147800"
  },
  {
    "text": "going to use AWS test 999",
    "start": "147800",
    "end": "150480"
  },
  {
    "text": "you should use something different like",
    "start": "150480",
    "end": "151760"
  },
  {
    "text": "AWS test- and your initials then inside",
    "start": "151760",
    "end": "155280"
  },
  {
    "text": "that bucket we create a couple folders",
    "start": "155280",
    "end": "157519"
  },
  {
    "text": "so one of them is called job and this is",
    "start": "157519",
    "end": "159239"
  },
  {
    "text": "where we're going to upload the job jar",
    "start": "159239",
    "end": "161440"
  },
  {
    "text": "uh we have another one called",
    "start": "161440",
    "end": "163159"
  },
  {
    "text": "logs and we've got a third one called",
    "start": "163159",
    "end": "166159"
  },
  {
    "text": "results so now S3 is all set up so we",
    "start": "166159",
    "end": "169080"
  },
  {
    "text": "can actually go and build the job jar so",
    "start": "169080",
    "end": "171120"
  },
  {
    "text": "we're going to switch back to the",
    "start": "171120",
    "end": "172040"
  },
  {
    "text": "terminal and I can do an ant clean job",
    "start": "172040",
    "end": "175440"
  },
  {
    "text": "and what this thing's going to do is",
    "start": "175440",
    "end": "176920"
  },
  {
    "text": "compile the code and it's going to build",
    "start": "176920",
    "end": "179080"
  },
  {
    "text": "that standard Hadoop job jar you can see",
    "start": "179080",
    "end": "182040"
  },
  {
    "text": "the output is right here in build",
    "start": "182040",
    "end": "183799"
  },
  {
    "text": "Wikipedia engrs job. jar so now I can",
    "start": "183799",
    "end": "187840"
  },
  {
    "text": "upload that into the job directory",
    "start": "187840",
    "end": "192640"
  },
  {
    "text": "here and so I have to pick the file that",
    "start": "192640",
    "end": "195159"
  },
  {
    "text": "I want to upload so I'm going to go to",
    "start": "195159",
    "end": "197400"
  },
  {
    "text": "my desktop into my EMR folder into the",
    "start": "197400",
    "end": "200440"
  },
  {
    "text": "Wikipedia lab and inside of build",
    "start": "200440",
    "end": "203760"
  },
  {
    "text": "there's my Wikipedia ingrams job",
    "start": "203760",
    "end": "207239"
  },
  {
    "text": "jar select that to do the upload I think",
    "start": "207239",
    "end": "210319"
  },
  {
    "text": "it's about 7 or eight megabytes so it'll",
    "start": "210319",
    "end": "212560"
  },
  {
    "text": "take maybe 20 seconds to do",
    "start": "212560",
    "end": "216319"
  },
  {
    "text": "this now if I switch back over to the",
    "start": "216319",
    "end": "218760"
  },
  {
    "text": "instructions you can see that after I",
    "start": "218760",
    "end": "220239"
  },
  {
    "text": "build the job jar here um it lets me",
    "start": "220239",
    "end": "222959"
  },
  {
    "text": "know that I can actually try and run",
    "start": "222959",
    "end": "225239"
  },
  {
    "text": "that same job jar from the command line",
    "start": "225239",
    "end": "226799"
  },
  {
    "text": "just to give it a try so I'm going to",
    "start": "226799",
    "end": "228680"
  },
  {
    "text": "copy this right here this assumes of",
    "start": "228680",
    "end": "230640"
  },
  {
    "text": "course that I've got hop set up on my",
    "start": "230640",
    "end": "233319"
  },
  {
    "text": "local machine here where I can actually",
    "start": "233319",
    "end": "235680"
  },
  {
    "text": "give it a try to run it and it goes and",
    "start": "235680",
    "end": "238560"
  },
  {
    "text": "it runs through through the two",
    "start": "238560",
    "end": "240079"
  },
  {
    "text": "different jobs one to create the Byram",
    "start": "240079",
    "end": "242200"
  },
  {
    "text": "counts and the second one to actually",
    "start": "242200",
    "end": "243519"
  },
  {
    "text": "sort them from high to low when it's",
    "start": "243519",
    "end": "246200"
  },
  {
    "text": "done there's going to be",
    "start": "246200",
    "end": "247480"
  },
  {
    "text": "output written out to build test sorted",
    "start": "247480",
    "end": "252159"
  },
  {
    "text": "counts so if I take a look at that you",
    "start": "252159",
    "end": "254720"
  },
  {
    "text": "can see I've got a part file in there",
    "start": "254720",
    "end": "257040"
  },
  {
    "text": "and if I do a more on that part",
    "start": "257040",
    "end": "260479"
  },
  {
    "text": "file you can see I've got byrams here",
    "start": "260479",
    "end": "263320"
  },
  {
    "text": "with counts eace occurs 4,025",
    "start": "263320",
    "end": "268000"
  },
  {
    "text": "times",
    "start": "268600",
    "end": "270160"
  },
  {
    "text": "now if we go back over here you can see",
    "start": "270160",
    "end": "271800"
  },
  {
    "text": "that",
    "start": "271800",
    "end": "273160"
  },
  {
    "text": "um we are now in a position where we can",
    "start": "273160",
    "end": "275520"
  },
  {
    "text": "actually Define our job flow and this is",
    "start": "275520",
    "end": "277919"
  },
  {
    "text": "the same set of uh steps that we went",
    "start": "277919",
    "end": "280000"
  },
  {
    "text": "through at the very beginning here of",
    "start": "280000",
    "end": "281960"
  },
  {
    "text": "this entire course so I'm going to go",
    "start": "281960",
    "end": "283960"
  },
  {
    "text": "back over to the AWS Management",
    "start": "283960",
    "end": "286680"
  },
  {
    "text": "console I'm going to switch to elastic",
    "start": "286680",
    "end": "288720"
  },
  {
    "text": "map",
    "start": "288720",
    "end": "290960"
  },
  {
    "text": "reduce and I'm going to create a new job",
    "start": "291240",
    "end": "293520"
  },
  {
    "text": "flow so the first thing I do is give it",
    "start": "293520",
    "end": "295919"
  },
  {
    "text": "a reasonable name like Wikipedia lab",
    "start": "295919",
    "end": "300840"
  },
  {
    "text": "and we are running our own application",
    "start": "300840",
    "end": "302840"
  },
  {
    "text": "and the job type is a custom",
    "start": "302840",
    "end": "305000"
  },
  {
    "text": "jar this next step here I have to",
    "start": "305000",
    "end": "307120"
  },
  {
    "text": "specify where the job is that I've",
    "start": "307120",
    "end": "308720"
  },
  {
    "text": "uploaded into",
    "start": "308720",
    "end": "310000"
  },
  {
    "text": "S3 so it's in this bucket inside the job",
    "start": "310000",
    "end": "314479"
  },
  {
    "text": "directory it's",
    "start": "314479",
    "end": "316520"
  },
  {
    "text": "Wikipedia",
    "start": "316520",
    "end": "319240"
  },
  {
    "text": "engrams job. jar and then I've got my",
    "start": "319240",
    "end": "322720"
  },
  {
    "text": "jar arguments so I'm going to flip back",
    "start": "322720",
    "end": "324919"
  },
  {
    "text": "over to here to the instructions and",
    "start": "324919",
    "end": "327560"
  },
  {
    "text": "there it shows that I need to specify an",
    "start": "327560",
    "end": "329240"
  },
  {
    "text": "inp put file path here and an output",
    "start": "329240",
    "end": "331960"
  },
  {
    "text": "directory a few other parameters going",
    "start": "331960",
    "end": "334639"
  },
  {
    "text": "to grab those paste them in here so the",
    "start": "334639",
    "end": "337639"
  },
  {
    "text": "input file we're processing one of the",
    "start": "337639",
    "end": "340120"
  },
  {
    "text": "roughly 117 part files so we're going to",
    "start": "340120",
    "end": "342280"
  },
  {
    "text": "process part 100 the output directory",
    "start": "342280",
    "end": "344960"
  },
  {
    "text": "here as a placeholder for my bucket",
    "start": "344960",
    "end": "347880"
  },
  {
    "text": "which is AWS test 99 of course and that",
    "start": "347880",
    "end": "350680"
  },
  {
    "text": "results directory that I previously",
    "start": "350680",
    "end": "352080"
  },
  {
    "text": "created I'm going to process 10% of it",
    "start": "352080",
    "end": "354280"
  },
  {
    "text": "I'm going to use a single reducer so",
    "start": "354280",
    "end": "356000"
  },
  {
    "text": "that I wind up with one output file one",
    "start": "356000",
    "end": "357840"
  },
  {
    "text": "part file that has everything sorted in",
    "start": "357840",
    "end": "359319"
  },
  {
    "text": "it",
    "start": "359319",
    "end": "361479"
  },
  {
    "text": "now I get to set up the size of the",
    "start": "362560",
    "end": "365000"
  },
  {
    "text": "cluster so I can use an M1 small for the",
    "start": "365000",
    "end": "367960"
  },
  {
    "text": "master that's fine I'm going to use two",
    "start": "367960",
    "end": "370160"
  },
  {
    "text": "M1 larges for the cor instance Group",
    "start": "370160",
    "end": "372440"
  },
  {
    "text": "which is what actually is running the",
    "start": "372440",
    "end": "373520"
  },
  {
    "text": "task tracker and the data",
    "start": "373520",
    "end": "376560"
  },
  {
    "text": "nodes here I've set up my ec2 key pair",
    "start": "376919",
    "end": "380080"
  },
  {
    "text": "to be AWS test in case I wanted to log",
    "start": "380080",
    "end": "382160"
  },
  {
    "text": "into the",
    "start": "382160",
    "end": "383639"
  },
  {
    "text": "master the location of the logs files uh",
    "start": "383639",
    "end": "386360"
  },
  {
    "text": "now note that here it's an s3n colon SL",
    "start": "386360",
    "end": "389520"
  },
  {
    "text": "SL uh protocol that I have to specify",
    "start": "389520",
    "end": "392800"
  },
  {
    "text": "and uh because this is something that's",
    "start": "392800",
    "end": "394160"
  },
  {
    "text": "getting passed to Hadoop bucket name is",
    "start": "394160",
    "end": "396400"
  },
  {
    "text": "again AWS test 99 and it's the log",
    "start": "396400",
    "end": "399319"
  },
  {
    "text": "subdirectory in there that I previously",
    "start": "399319",
    "end": "401880"
  },
  {
    "text": "created I don't need any special",
    "start": "401880",
    "end": "404520"
  },
  {
    "text": "debugging and I don't need to keep the",
    "start": "404520",
    "end": "406039"
  },
  {
    "text": "cluster alive when I'm done I don't have",
    "start": "406039",
    "end": "408639"
  },
  {
    "text": "any special bootstrap actions so here I",
    "start": "408639",
    "end": "412039"
  },
  {
    "text": "can double check all the",
    "start": "412039",
    "end": "413599"
  },
  {
    "text": "settings of the job and if it looks",
    "start": "413599",
    "end": "415800"
  },
  {
    "text": "right I can say I want to create the job",
    "start": "415800",
    "end": "418479"
  },
  {
    "text": "flow",
    "start": "418479",
    "end": "420120"
  },
  {
    "text": "so what's going to happen here is status",
    "start": "420120",
    "end": "422039"
  },
  {
    "text": "will be starting for a couple minutes as",
    "start": "422039",
    "end": "424360"
  },
  {
    "text": "it uh acquires all the servers that I",
    "start": "424360",
    "end": "426800"
  },
  {
    "text": "need for my cluster and then Provisions",
    "start": "426800",
    "end": "428639"
  },
  {
    "text": "them with Hadoop and actually starts",
    "start": "428639",
    "end": "430560"
  },
  {
    "text": "running the job and once the job starts",
    "start": "430560",
    "end": "431919"
  },
  {
    "text": "running then the status here will change",
    "start": "431919",
    "end": "433080"
  },
  {
    "text": "to running and it'll start tracking my",
    "start": "433080",
    "end": "435199"
  },
  {
    "text": "total elapse time for the job will start",
    "start": "435199",
    "end": "436840"
  },
  {
    "text": "getting charged and remember how I",
    "start": "436840",
    "end": "438720"
  },
  {
    "text": "talked about pricing being a step",
    "start": "438720",
    "end": "440039"
  },
  {
    "text": "function so instantly I'm going to get",
    "start": "440039",
    "end": "441479"
  },
  {
    "text": "charged for one hour's worth of time",
    "start": "441479",
    "end": "444000"
  },
  {
    "text": "which in this case will be roughly I",
    "start": "444000",
    "end": "445879"
  },
  {
    "text": "don't know 90 cents given the size of",
    "start": "445879",
    "end": "447520"
  },
  {
    "text": "the cluster that I've got",
    "start": "447520",
    "end": "450680"
  },
  {
    "text": "now at this point it's still starting up",
    "start": "450680",
    "end": "453000"
  },
  {
    "text": "but I do have a master public DNS name",
    "start": "453000",
    "end": "456440"
  },
  {
    "text": "so it's gotten that far in the process",
    "start": "456440",
    "end": "458639"
  },
  {
    "text": "of setting up the cluster so I can copy",
    "start": "458639",
    "end": "460960"
  },
  {
    "text": "that and then I can switch back over to",
    "start": "460960",
    "end": "464120"
  },
  {
    "text": "the terminal window and now what I can",
    "start": "464120",
    "end": "465560"
  },
  {
    "text": "do is set up a proxy so that I can",
    "start": "465560",
    "end": "468120"
  },
  {
    "text": "actually use the Hadoop GUI to watch",
    "start": "468120",
    "end": "469960"
  },
  {
    "text": "what's going on with my job so to set up",
    "start": "469960",
    "end": "471479"
  },
  {
    "text": "a proxy um you'll see that in the",
    "start": "471479",
    "end": "475120"
  },
  {
    "text": "Wikipedia lab I already copied this awst",
    "start": "475120",
    "end": "477960"
  },
  {
    "text": "test. pem file which is the private key",
    "start": "477960",
    "end": "480000"
  },
  {
    "text": "file that I created and then downloaded",
    "start": "480000",
    "end": "482039"
  },
  {
    "text": "using the AWS Management console",
    "start": "482039",
    "end": "483840"
  },
  {
    "text": "previously so at this point I can SSH",
    "start": "483840",
    "end": "486120"
  },
  {
    "text": "and I can specify I want to use that",
    "start": "486120",
    "end": "488800"
  },
  {
    "text": "file and here I need to specify the port",
    "start": "488800",
    "end": "492199"
  },
  {
    "text": "and uh normally by default you'd set up",
    "start": "492199",
    "end": "494520"
  },
  {
    "text": "as Port 8157 I use port",
    "start": "494520",
    "end": "497360"
  },
  {
    "text": "6666 and then you need to be proxying as",
    "start": "497360",
    "end": "500319"
  },
  {
    "text": "the Hadoop user to that Master public",
    "start": "500319",
    "end": "505360"
  },
  {
    "text": "DNS and if I do that it's going to say",
    "start": "505360",
    "end": "507800"
  },
  {
    "text": "is this one something that I want to add",
    "start": "507800",
    "end": "509680"
  },
  {
    "text": "to my known host and I say yes and now",
    "start": "509680",
    "end": "512120"
  },
  {
    "text": "it's proxying so if I switch back over",
    "start": "512120",
    "end": "514360"
  },
  {
    "text": "to here and I refresh you'll see that",
    "start": "514360",
    "end": "517518"
  },
  {
    "text": "I'm now running at this",
    "start": "517519",
    "end": "520760"
  },
  {
    "text": "point if I open",
    "start": "520760",
    "end": "523399"
  },
  {
    "text": "up um a new window and I access that",
    "start": "523399",
    "end": "527240"
  },
  {
    "text": "public uh Master uh the master public",
    "start": "527240",
    "end": "530399"
  },
  {
    "text": "DNS at Port",
    "start": "530399",
    "end": "532320"
  },
  {
    "text": "9100 I'll get the Hadoop guey and for",
    "start": "532320",
    "end": "535600"
  },
  {
    "text": "this to work I have foxy proxy installed",
    "start": "535600",
    "end": "538160"
  },
  {
    "text": "and configured and running and that's",
    "start": "538160",
    "end": "540640"
  },
  {
    "text": "something that I talked about way back",
    "start": "540640",
    "end": "542120"
  },
  {
    "text": "at the very first section about how to",
    "start": "542120",
    "end": "544120"
  },
  {
    "text": "how to follow instructions to do that um",
    "start": "544120",
    "end": "546800"
  },
  {
    "text": "so this point the cluster set up uh the",
    "start": "546800",
    "end": "549360"
  },
  {
    "text": "job hasn't actually been submitted so I",
    "start": "549360",
    "end": "551720"
  },
  {
    "text": "don't have any running jobs",
    "start": "551720",
    "end": "553760"
  },
  {
    "text": "yet um if I refresh eventually I'll see",
    "start": "553760",
    "end": "557440"
  },
  {
    "text": "the running",
    "start": "557440",
    "end": "558760"
  },
  {
    "text": "job there's the running job and I can",
    "start": "558760",
    "end": "561839"
  },
  {
    "text": "drill into it right these are all links",
    "start": "561839",
    "end": "563200"
  },
  {
    "text": "just like the regular Hadoop GUI so you",
    "start": "563200",
    "end": "564920"
  },
  {
    "text": "can see here that I'm 75% of the way",
    "start": "564920",
    "end": "567160"
  },
  {
    "text": "done on the map side now one of the",
    "start": "567160",
    "end": "569320"
  },
  {
    "text": "limitations of this with elastic map",
    "start": "569320",
    "end": "571240"
  },
  {
    "text": "redu is I can drill into uh the map",
    "start": "571240",
    "end": "573880"
  },
  {
    "text": "tasks and in fact I can then look at an",
    "start": "573880",
    "end": "577399"
  },
  {
    "text": "individual map task and the issue is if",
    "start": "577399",
    "end": "580760"
  },
  {
    "text": "I click here on the logs what it's",
    "start": "580760",
    "end": "583360"
  },
  {
    "text": "trying to do is access um an IP address",
    "start": "583360",
    "end": "587200"
  },
  {
    "text": "and that IP address is an internal only",
    "start": "587200",
    "end": "588920"
  },
  {
    "text": "IP address that foxy proxy doesn't know",
    "start": "588920",
    "end": "591480"
  },
  {
    "text": "how to proxy because it's proxying based",
    "start": "591480",
    "end": "594240"
  },
  {
    "text": "on uh patterns and that's just a random",
    "start": "594240",
    "end": "597200"
  },
  {
    "text": "IP address so there is some some limit",
    "start": "597200",
    "end": "599760"
  },
  {
    "text": "however I can click on counters and I",
    "start": "599760",
    "end": "601760"
  },
  {
    "text": "will get all the counters here for",
    "start": "601760",
    "end": "603800"
  },
  {
    "text": "example Pages parse Pages skipped",
    "start": "603800",
    "end": "605959"
  },
  {
    "text": "engrams created these are my Custom",
    "start": "605959",
    "end": "607440"
  },
  {
    "text": "Counters that are set up in that",
    "start": "607440",
    "end": "608519"
  },
  {
    "text": "Wikipedia",
    "start": "608519",
    "end": "610160"
  },
  {
    "text": "lab um if I go here and",
    "start": "610160",
    "end": "613640"
  },
  {
    "text": "refresh uh the lab is still running so I",
    "start": "613640",
    "end": "616880"
  },
  {
    "text": "can back out here up",
    "start": "616880",
    "end": "619560"
  },
  {
    "text": "to the top level for the particular job",
    "start": "619560",
    "end": "623440"
  },
  {
    "text": "and if I refresh",
    "start": "623440",
    "end": "626200"
  },
  {
    "text": "here you can see it's actually finished",
    "start": "626200",
    "end": "628480"
  },
  {
    "text": "up um it finished all six map tasks and",
    "start": "628480",
    "end": "631360"
  },
  {
    "text": "all three reduced tasks and I've got a",
    "start": "631360",
    "end": "633560"
  },
  {
    "text": "total of about uh 10,000 pages that I",
    "start": "633560",
    "end": "637639"
  },
  {
    "text": "parsed and if I go back over here and",
    "start": "637639",
    "end": "641000"
  },
  {
    "text": "refresh uh at this point it's",
    "start": "641000",
    "end": "643680"
  },
  {
    "text": "essentially in its uh finishing up stage",
    "start": "643680",
    "end": "646320"
  },
  {
    "text": "where what it's doing is copying logs",
    "start": "646320",
    "end": "648800"
  },
  {
    "text": "from the cluster into S3 so it'll take",
    "start": "648800",
    "end": "652399"
  },
  {
    "text": "depending on the size of the logs",
    "start": "652399",
    "end": "653600"
  },
  {
    "text": "anywhere from just a few minutes to you",
    "start": "653600",
    "end": "656040"
  },
  {
    "text": "know if you go crazy with lots and lots",
    "start": "656040",
    "end": "658079"
  },
  {
    "text": "of logging could take 10 or 15 minutes",
    "start": "658079",
    "end": "659839"
  },
  {
    "text": "to copy you know millions of lines of of",
    "start": "659839",
    "end": "662440"
  },
  {
    "text": "log data from your uh from what's",
    "start": "662440",
    "end": "664720"
  },
  {
    "text": "getting what was created in your hdfs",
    "start": "664720",
    "end": "667360"
  },
  {
    "text": "cluster up into S3 so if I go over to",
    "start": "667360",
    "end": "671360"
  },
  {
    "text": "S3 in anticipation of that copying",
    "start": "671360",
    "end": "673920"
  },
  {
    "text": "finishing",
    "start": "673920",
    "end": "675040"
  },
  {
    "text": "up here I can see the list of buckets",
    "start": "675040",
    "end": "677160"
  },
  {
    "text": "that I previously created I've got this",
    "start": "677160",
    "end": "678639"
  },
  {
    "text": "one",
    "start": "678639",
    "end": "680480"
  },
  {
    "text": "bucket and over here you can see I've",
    "start": "680480",
    "end": "682639"
  },
  {
    "text": "got the directories I created job logs",
    "start": "682639",
    "end": "684440"
  },
  {
    "text": "and results if I look in the results",
    "start": "684440",
    "end": "687959"
  },
  {
    "text": "directory",
    "start": "687959",
    "end": "690000"
  },
  {
    "text": "you can see I've got two output",
    "start": "690000",
    "end": "691160"
  },
  {
    "text": "directories raw counts and sorted counts",
    "start": "691160",
    "end": "693560"
  },
  {
    "text": "sorted counts is the final step of a",
    "start": "693560",
    "end": "695160"
  },
  {
    "text": "two-step job here so here's a part",
    "start": "695160",
    "end": "698000"
  },
  {
    "text": "file if I double click on that part",
    "start": "698000",
    "end": "701040"
  },
  {
    "text": "file it's going to set up to download it",
    "start": "701040",
    "end": "703399"
  },
  {
    "text": "but I'm going to open it up with BB edit",
    "start": "703399",
    "end": "708079"
  },
  {
    "text": "my editor of",
    "start": "708079",
    "end": "710240"
  },
  {
    "text": "choice and what I'll",
    "start": "710240",
    "end": "712360"
  },
  {
    "text": "see are a list of all the engrams the",
    "start": "712360",
    "end": "716279"
  },
  {
    "text": "first one the most common one is two",
    "start": "716279",
    "end": "717639"
  },
  {
    "text": "spaces followed by ER eace",
    "start": "717639",
    "end": "721600"
  },
  {
    "text": "Etc if I go back over here and I go up",
    "start": "722040",
    "end": "726320"
  },
  {
    "text": "to the bucket and I look in the logs",
    "start": "726320",
    "end": "728600"
  },
  {
    "text": "directory here I'm going to see a list",
    "start": "728600",
    "end": "730399"
  },
  {
    "text": "of all the jobs that I've run you know",
    "start": "730399",
    "end": "732399"
  },
  {
    "text": "and each one of these is a unique job",
    "start": "732399",
    "end": "733760"
  },
  {
    "text": "number so I would uh have to switch back",
    "start": "733760",
    "end": "736839"
  },
  {
    "text": "over to elastic map produce and I could",
    "start": "736839",
    "end": "739639"
  },
  {
    "text": "get the job number and then once I had",
    "start": "739639",
    "end": "741040"
  },
  {
    "text": "the job number I'd be able to drill into",
    "start": "741040",
    "end": "744199"
  },
  {
    "text": "the directory here and I would see in",
    "start": "744199",
    "end": "745959"
  },
  {
    "text": "here A bunch of subdirectories one for",
    "start": "745959",
    "end": "747600"
  },
  {
    "text": "each sort of aspect of the job the one",
    "start": "747600",
    "end": "749920"
  },
  {
    "text": "where my logging is is going to be",
    "start": "749920",
    "end": "751240"
  },
  {
    "text": "inside of steps inside of directory one",
    "start": "751240",
    "end": "754480"
  },
  {
    "text": "and here you'd see for example standard",
    "start": "754480",
    "end": "756639"
  },
  {
    "text": "out this is where uh my logs will go to",
    "start": "756639",
    "end": "761120"
  },
  {
    "text": "and you can see it's just the regular",
    "start": "761120",
    "end": "762360"
  },
  {
    "text": "dump for both jobs the original job that",
    "start": "762360",
    "end": "764639"
  },
  {
    "text": "was creating the engrams and then the",
    "start": "764639",
    "end": "766519"
  },
  {
    "text": "second job that was sorting them",
    "start": "766519",
    "end": "771199"
  }
]
[
  {
    "text": "hi there folks my name is Bobby Lindsay",
    "start": "440",
    "end": "2879"
  },
  {
    "text": "and with me today is a fantastic",
    "start": "2879",
    "end": "4440"
  },
  {
    "text": "colleague of mine Tony chin we're both",
    "start": "4440",
    "end": "6960"
  },
  {
    "text": "AIML specialist Solutions Architects",
    "start": "6960",
    "end": "9160"
  },
  {
    "text": "here at AWS and you know today we wanted",
    "start": "9160",
    "end": "12000"
  },
  {
    "text": "to explore um some ways to help you",
    "start": "12000",
    "end": "14120"
  },
  {
    "text": "increase efficiencies when it comes to",
    "start": "14120",
    "end": "17039"
  },
  {
    "text": "um experimenting with and deploying",
    "start": "17039",
    "end": "19039"
  },
  {
    "text": "Foundation models at scale as you can",
    "start": "19039",
    "end": "21359"
  },
  {
    "text": "imagine Foundation models are large and",
    "start": "21359",
    "end": "23599"
  },
  {
    "text": "can be costly to deploy at scale and",
    "start": "23599",
    "end": "26080"
  },
  {
    "text": "building with a foundation model is a",
    "start": "26080",
    "end": "28039"
  },
  {
    "text": "very iterative process which requires a",
    "start": "28039",
    "end": "30359"
  },
  {
    "text": "lot of experimentation with models and",
    "start": "30359",
    "end": "32078"
  },
  {
    "text": "prompts so with these challenges um",
    "start": "32079",
    "end": "34920"
  },
  {
    "text": "let's focus on two key areas to help us",
    "start": "34920",
    "end": "37559"
  },
  {
    "text": "gain more efficiency let's first take a",
    "start": "37559",
    "end": "39680"
  },
  {
    "text": "look at prompt management as a practice",
    "start": "39680",
    "end": "42200"
  },
  {
    "text": "and why it's important to have a",
    "start": "42200",
    "end": "43640"
  },
  {
    "text": "systematic way to manage and track your",
    "start": "43640",
    "end": "46079"
  },
  {
    "text": "prompts as mentioned earlier building",
    "start": "46079",
    "end": "48879"
  },
  {
    "text": "with Foundation models is a highly",
    "start": "48879",
    "end": "51000"
  },
  {
    "text": "iterative process so we've broken down",
    "start": "51000",
    "end": "53440"
  },
  {
    "text": "prompt management into four pillars to",
    "start": "53440",
    "end": "56000"
  },
  {
    "text": "help you accelerate experimentation the",
    "start": "56000",
    "end": "58280"
  },
  {
    "text": "first is to provide the ability to",
    "start": "58280",
    "end": "60239"
  },
  {
    "text": "select Foundation models to experiment",
    "start": "60239",
    "end": "62160"
  },
  {
    "text": "with now there are a lot of foundation",
    "start": "62160",
    "end": "64400"
  },
  {
    "text": "models out there some are proprietary",
    "start": "64400",
    "end": "66680"
  },
  {
    "text": "others are open source it's likely that",
    "start": "66680",
    "end": "68880"
  },
  {
    "text": "you'll explore a lot of these Foundation",
    "start": "68880",
    "end": "70799"
  },
  {
    "text": "models as you build out your gen",
    "start": "70799",
    "end": "73000"
  },
  {
    "text": "application and you might also be",
    "start": "73000",
    "end": "74799"
  },
  {
    "text": "considering factors like the task at",
    "start": "74799",
    "end": "77119"
  },
  {
    "text": "hand or latency tolerances and this will",
    "start": "77119",
    "end": "80799"
  },
  {
    "text": "uh influence your model selection as",
    "start": "80799",
    "end": "82560"
  },
  {
    "text": "well prop management should also",
    "start": "82560",
    "end": "84200"
  },
  {
    "text": "encourage a tight feedback loop with",
    "start": "84200",
    "end": "86400"
  },
  {
    "text": "your selected models so that you can",
    "start": "86400",
    "end": "87840"
  },
  {
    "text": "quickly iterate and refine your prompts",
    "start": "87840",
    "end": "90280"
  },
  {
    "text": "over time and figure out the ones that",
    "start": "90280",
    "end": "92119"
  },
  {
    "text": "work well for your model and",
    "start": "92119",
    "end": "94439"
  },
  {
    "text": "requirements you'll also need to",
    "start": "94439",
    "end": "96320"
  },
  {
    "text": "evaluate your model and prompts to get",
    "start": "96320",
    "end": "98880"
  },
  {
    "text": "more quantitative metrics on how well",
    "start": "98880",
    "end": "101320"
  },
  {
    "text": "they perform on your task and finally",
    "start": "101320",
    "end": "104799"
  },
  {
    "text": "prompt management as a practice should",
    "start": "104799",
    "end": "106560"
  },
  {
    "text": "include a way to catalog and keep track",
    "start": "106560",
    "end": "109240"
  },
  {
    "text": "of high- Performing prompts for a given",
    "start": "109240",
    "end": "111399"
  },
  {
    "text": "model and task so if we follow these",
    "start": "111399",
    "end": "113439"
  },
  {
    "text": "prompt management pillars we avoid",
    "start": "113439",
    "end": "116799"
  },
  {
    "text": "multiple uh teams prompt smithing from",
    "start": "116799",
    "end": "119399"
  },
  {
    "text": "scratch",
    "start": "119399",
    "end": "120360"
  },
  {
    "text": "they can instead search the catalog of",
    "start": "120360",
    "end": "122439"
  },
  {
    "text": "for high performing prompts for their",
    "start": "122439",
    "end": "124320"
  },
  {
    "text": "given task at hand and just iterate from",
    "start": "124320",
    "end": "126759"
  },
  {
    "text": "there so this prevents unnecessary",
    "start": "126759",
    "end": "129319"
  },
  {
    "text": "experimentation and also helps to reduce",
    "start": "129319",
    "end": "132280"
  },
  {
    "text": "costs and because we're cataloging the",
    "start": "132280",
    "end": "135200"
  },
  {
    "text": "results of our experiments we also get",
    "start": "135200",
    "end": "137560"
  },
  {
    "text": "visibility into things like performance",
    "start": "137560",
    "end": "139640"
  },
  {
    "text": "metrics the evaluation data set used um",
    "start": "139640",
    "end": "142959"
  },
  {
    "text": "model inference parameters and prompts",
    "start": "142959",
    "end": "146120"
  },
  {
    "text": "and finally because this is such a",
    "start": "146120",
    "end": "147599"
  },
  {
    "text": "highly iterative process we've now got",
    "start": "147599",
    "end": "149720"
  },
  {
    "text": "the the flexibility we need to run such",
    "start": "149720",
    "end": "151879"
  },
  {
    "text": "experiments across a variety of",
    "start": "151879",
    "end": "154120"
  },
  {
    "text": "different Foundation models so now that",
    "start": "154120",
    "end": "156200"
  },
  {
    "text": "we've discussed ways to optimize",
    "start": "156200",
    "end": "157680"
  },
  {
    "text": "experimentation let's now shift our",
    "start": "157680",
    "end": "159360"
  },
  {
    "text": "Focus to optimizing our deployment",
    "start": "159360",
    "end": "161400"
  },
  {
    "text": "resources often times we see cases where",
    "start": "161400",
    "end": "164000"
  },
  {
    "text": "organizations that have many teams",
    "start": "164000",
    "end": "166000"
  },
  {
    "text": "deploy the same Foundation models in",
    "start": "166000",
    "end": "167480"
  },
  {
    "text": "their environments which can get",
    "start": "167480",
    "end": "168879"
  },
  {
    "text": "expensive due to duplication of",
    "start": "168879",
    "end": "170720"
  },
  {
    "text": "resources leveraging an AI Gateway",
    "start": "170720",
    "end": "172920"
  },
  {
    "text": "architecture can help address this",
    "start": "172920",
    "end": "174480"
  },
  {
    "text": "problem if we had a set of foundation",
    "start": "174480",
    "end": "176560"
  },
  {
    "text": "models we want to deploy let's say using",
    "start": "176560",
    "end": "178480"
  },
  {
    "text": "Amazon sagemaker we can deploy these",
    "start": "178480",
    "end": "180599"
  },
  {
    "text": "behind an API management layer using a",
    "start": "180599",
    "end": "182560"
  },
  {
    "text": "service like Amazon API",
    "start": "182560",
    "end": "185040"
  },
  {
    "text": "Gateway with this layer we can leverage",
    "start": "185040",
    "end": "187360"
  },
  {
    "text": "security features for authentication and",
    "start": "187360",
    "end": "190000"
  },
  {
    "text": "authorization we can also configure",
    "start": "190000",
    "end": "191920"
  },
  {
    "text": "throttling to protect our foundation",
    "start": "191920",
    "end": "193360"
  },
  {
    "text": "models from being overwhelmed you can",
    "start": "193360",
    "end": "195360"
  },
  {
    "text": "also monitor usage and performance",
    "start": "195360",
    "end": "197120"
  },
  {
    "text": "through a single pane of class all the",
    "start": "197120",
    "end": "199959"
  },
  {
    "text": "components as a whole is what we refer",
    "start": "199959",
    "end": "201840"
  },
  {
    "text": "to as an AI Gateway you can have",
    "start": "201840",
    "end": "203840"
  },
  {
    "text": "multiple AI gateways you can have one",
    "start": "203840",
    "end": "205920"
  },
  {
    "text": "that's used by Builders who are",
    "start": "205920",
    "end": "207400"
  },
  {
    "text": "experimenting with models you can have",
    "start": "207400",
    "end": "209159"
  },
  {
    "text": "another AI Gateway that's dedicated for",
    "start": "209159",
    "end": "211239"
  },
  {
    "text": "production workloads where in this case",
    "start": "211239",
    "end": "213280"
  },
  {
    "text": "the hosted models behind the API",
    "start": "213280",
    "end": "214840"
  },
  {
    "text": "management layer may need additional",
    "start": "214840",
    "end": "216519"
  },
  {
    "text": "computing power to meet latency",
    "start": "216519",
    "end": "218159"
  },
  {
    "text": "requirements as well as redundancy",
    "start": "218159",
    "end": "219959"
  },
  {
    "text": "across multiple availability zones to",
    "start": "219959",
    "end": "221920"
  },
  {
    "text": "achieve your availability goals and just",
    "start": "221920",
    "end": "223879"
  },
  {
    "text": "to reiterate the benefits of",
    "start": "223879",
    "end": "225120"
  },
  {
    "text": "implementing an AI Gateway we're able to",
    "start": "225120",
    "end": "227000"
  },
  {
    "text": "reduce cost by avoiding redundancy in",
    "start": "227000",
    "end": "228720"
  },
  {
    "text": "our deployments we can also accelerate",
    "start": "228720",
    "end": "230840"
  },
  {
    "text": "experimentation by providing Builders",
    "start": "230840",
    "end": "232680"
  },
  {
    "text": "access to Foundation models through a",
    "start": "232680",
    "end": "234360"
  },
  {
    "text": "single pan of class lastly we can",
    "start": "234360",
    "end": "236439"
  },
  {
    "text": "leverage the security and scalability of",
    "start": "236439",
    "end": "238319"
  },
  {
    "text": "the API management layer not just for",
    "start": "238319",
    "end": "240200"
  },
  {
    "text": "model experimentation but also Mission",
    "start": "240200",
    "end": "242040"
  },
  {
    "text": "critical production workloads so let's",
    "start": "242040",
    "end": "244319"
  },
  {
    "text": "go through a demo that showcases some of",
    "start": "244319",
    "end": "246040"
  },
  {
    "text": "the concepts that we discussed today",
    "start": "246040",
    "end": "247879"
  },
  {
    "text": "like prompt management and AI Gateway in",
    "start": "247879",
    "end": "250640"
  },
  {
    "text": "this example we have an AI Gateway",
    "start": "250640",
    "end": "252760"
  },
  {
    "text": "that's used for foundation model",
    "start": "252760",
    "end": "254519"
  },
  {
    "text": "experimentation so the first thing I",
    "start": "254519",
    "end": "256280"
  },
  {
    "text": "want to do here is essentially just",
    "start": "256280",
    "end": "257959"
  },
  {
    "text": "choose a model that's available via our",
    "start": "257959",
    "end": "259720"
  },
  {
    "text": "AI Gateway in this example I've chosen a",
    "start": "259720",
    "end": "262880"
  },
  {
    "text": "a llama 2 model for",
    "start": "262880",
    "end": "265360"
  },
  {
    "text": "experimentation so one of the first",
    "start": "265360",
    "end": "267240"
  },
  {
    "text": "steps we want to do is just specify that",
    "start": "267240",
    "end": "269000"
  },
  {
    "text": "AI Gateway Target um where our model",
    "start": "269000",
    "end": "272360"
  },
  {
    "text": "lives and then we actually want to start",
    "start": "272360",
    "end": "274440"
  },
  {
    "text": "developing a prompt template in our case",
    "start": "274440",
    "end": "277000"
  },
  {
    "text": "we want to develop a prompt template to",
    "start": "277000",
    "end": "278560"
  },
  {
    "text": "summarize some user input so you can see",
    "start": "278560",
    "end": "281160"
  },
  {
    "text": "that we do that here our first template",
    "start": "281160",
    "end": "283120"
  },
  {
    "text": "is to just summarize the following and",
    "start": "283120",
    "end": "285600"
  },
  {
    "text": "you can see the response is a bit of a",
    "start": "285600",
    "end": "287280"
  },
  {
    "text": "lengthy summary so yeah let's go ahead",
    "start": "287280",
    "end": "289759"
  },
  {
    "text": "and try to um make this better we'll go",
    "start": "289759",
    "end": "292479"
  },
  {
    "text": "ahead and reward the template we'll say",
    "start": "292479",
    "end": "294400"
  },
  {
    "text": "summarize the below into bullet points",
    "start": "294400",
    "end": "297479"
  },
  {
    "text": "and as you can see here uh the results",
    "start": "297479",
    "end": "299759"
  },
  {
    "text": "it's a lot better more concise uh we get",
    "start": "299759",
    "end": "302360"
  },
  {
    "text": "our bullet points but let's see if we",
    "start": "302360",
    "end": "304400"
  },
  {
    "text": "could do maybe even better uh let's ask",
    "start": "304400",
    "end": "306520"
  },
  {
    "text": "our model to explain the user input in",
    "start": "306520",
    "end": "309560"
  },
  {
    "text": "just one sentence so we'll go ahead and",
    "start": "309560",
    "end": "311720"
  },
  {
    "text": "run the",
    "start": "311720",
    "end": "312880"
  },
  {
    "text": "prompt and we'll get our results our",
    "start": "312880",
    "end": "315560"
  },
  {
    "text": "response and uh this is a lot better",
    "start": "315560",
    "end": "317600"
  },
  {
    "text": "it's very concise uh maybe we let's try",
    "start": "317600",
    "end": "320400"
  },
  {
    "text": "rewarding and rephrasing this uh this",
    "start": "320400",
    "end": "322520"
  },
  {
    "text": "prompt so we'll ask them all to explain",
    "start": "322520",
    "end": "324440"
  },
  {
    "text": "just the main concept of the",
    "start": "324440",
    "end": "326840"
  },
  {
    "text": "excerpt and this uh looks a lot better I",
    "start": "326840",
    "end": "329880"
  },
  {
    "text": "like it Bobby likes it so we'll go ahead",
    "start": "329880",
    "end": "332400"
  },
  {
    "text": "and actually evaluate um perform",
    "start": "332400",
    "end": "334759"
  },
  {
    "text": "evaluation using the prompts that we've",
    "start": "334759",
    "end": "336759"
  },
  {
    "text": "defined so we'll uh create a data",
    "start": "336759",
    "end": "339039"
  },
  {
    "text": "configuration which points to a test",
    "start": "339039",
    "end": "340880"
  },
  {
    "text": "data set uh this test data set is",
    "start": "340880",
    "end": "343360"
  },
  {
    "text": "specific or is specific for testing",
    "start": "343360",
    "end": "346440"
  },
  {
    "text": "summarization task we'll go ahead and",
    "start": "346440",
    "end": "348680"
  },
  {
    "text": "run evaluation and we'll go ahead and",
    "start": "348680",
    "end": "350960"
  },
  {
    "text": "print the results perfect so we have our",
    "start": "350960",
    "end": "354000"
  },
  {
    "text": "results in a dictionary let's go ahead",
    "start": "354000",
    "end": "356360"
  },
  {
    "text": "and save these results to our catalog",
    "start": "356360",
    "end": "359199"
  },
  {
    "text": "we'll go ahead ahe and create a catalog",
    "start": "359199",
    "end": "361039"
  },
  {
    "text": "and we'll go ahead and save these",
    "start": "361039",
    "end": "362479"
  },
  {
    "text": "evaluation results to our",
    "start": "362479",
    "end": "364639"
  },
  {
    "text": "catalog and just to make sure that this",
    "start": "364639",
    "end": "367479"
  },
  {
    "text": "has been saved to our catalog we'll go",
    "start": "367479",
    "end": "369160"
  },
  {
    "text": "ahead and show the catalog and as you",
    "start": "369160",
    "end": "371560"
  },
  {
    "text": "can see here our metrics our user input",
    "start": "371560",
    "end": "374840"
  },
  {
    "text": "template and all our necessary",
    "start": "374840",
    "end": "377000"
  },
  {
    "text": "information that we want to keep track",
    "start": "377000",
    "end": "378520"
  },
  {
    "text": "of is available in our",
    "start": "378520",
    "end": "380599"
  },
  {
    "text": "catalog let's go ahead and evaluate",
    "start": "380599",
    "end": "382960"
  },
  {
    "text": "another prompt template uh we want to",
    "start": "382960",
    "end": "384720"
  },
  {
    "text": "evaluate the prompt um where we ask our",
    "start": "384720",
    "end": "388160"
  },
  {
    "text": "model to explain the put in just one",
    "start": "388160",
    "end": "390400"
  },
  {
    "text": "sentence we'll go ahead and perform",
    "start": "390400",
    "end": "392759"
  },
  {
    "text": "evaluation again and then we'll also",
    "start": "392759",
    "end": "395360"
  },
  {
    "text": "print the results perfect so we have our",
    "start": "395360",
    "end": "398360"
  },
  {
    "text": "results again in a dictionary we'll go",
    "start": "398360",
    "end": "400360"
  },
  {
    "text": "ahead and save these results to the",
    "start": "400360",
    "end": "402120"
  },
  {
    "text": "catalog just like the first",
    "start": "402120",
    "end": "404280"
  },
  {
    "text": "example and then we can actually look at",
    "start": "404280",
    "end": "407319"
  },
  {
    "text": "the viewr catalog and sort by the metric",
    "start": "407319",
    "end": "410319"
  },
  {
    "text": "that we're interested in in this case",
    "start": "410319",
    "end": "412039"
  },
  {
    "text": "we're interested in the average F1 score",
    "start": "412039",
    "end": "414479"
  },
  {
    "text": "so we'll go ahead and just sort our",
    "start": "414479",
    "end": "417039"
  },
  {
    "text": "records based on that metric and we can",
    "start": "417039",
    "end": "420039"
  },
  {
    "text": "see which prom template gave us the best",
    "start": "420039",
    "end": "422479"
  },
  {
    "text": "result and if we want to view just the",
    "start": "422479",
    "end": "425680"
  },
  {
    "text": "top performer uh the top performing",
    "start": "425680",
    "end": "427960"
  },
  {
    "text": "prompt we can use the top K argument and",
    "start": "427960",
    "end": "431160"
  },
  {
    "text": "just get the first result in our",
    "start": "431160",
    "end": "433720"
  },
  {
    "text": "catalog thank you so much for joining us",
    "start": "433720",
    "end": "435879"
  },
  {
    "text": "today we hope you got something out of",
    "start": "435879",
    "end": "437440"
  },
  {
    "text": "it and we'll see you next time thanks",
    "start": "437440",
    "end": "442280"
  }
]
[
  {
    "text": "hello and welcome back to aws glue",
    "start": "480",
    "end": "3600"
  },
  {
    "text": "studio learning series part three",
    "start": "3600",
    "end": "6080"
  },
  {
    "text": "my name is harshwat adipati and i am a",
    "start": "6080",
    "end": "8800"
  },
  {
    "text": "specialist senior solutions architect",
    "start": "8800",
    "end": "10639"
  },
  {
    "text": "covering",
    "start": "10639",
    "end": "11120"
  },
  {
    "text": "analytics at amazon web services",
    "start": "11120",
    "end": "14400"
  },
  {
    "text": "please do watch parts 1 and 2 using the",
    "start": "14400",
    "end": "16800"
  },
  {
    "text": "links under this video",
    "start": "16800",
    "end": "18240"
  },
  {
    "text": "to learn how blue studio helps you",
    "start": "18240",
    "end": "20720"
  },
  {
    "text": "rapidly develop",
    "start": "20720",
    "end": "21760"
  },
  {
    "text": "any batch etf job using a hybrid",
    "start": "21760",
    "end": "24480"
  },
  {
    "text": "development experience",
    "start": "24480",
    "end": "26480"
  },
  {
    "text": "today you're going to learn the benefits",
    "start": "26480",
    "end": "28960"
  },
  {
    "text": "of fusing glue studio for streaming etl",
    "start": "28960",
    "end": "31439"
  },
  {
    "text": "jobs",
    "start": "31439",
    "end": "32160"
  },
  {
    "text": "and how to rapidly develop streaming apl",
    "start": "32160",
    "end": "35040"
  },
  {
    "text": "jobs using glue studio",
    "start": "35040",
    "end": "38559"
  },
  {
    "text": "blue studio is built to continue to",
    "start": "39680",
    "end": "41600"
  },
  {
    "text": "empower the developers",
    "start": "41600",
    "end": "43120"
  },
  {
    "text": "by providing a hybrid development",
    "start": "43120",
    "end": "45039"
  },
  {
    "text": "experience where the developers can use",
    "start": "45039",
    "end": "47440"
  },
  {
    "text": "the best of both from",
    "start": "47440",
    "end": "48719"
  },
  {
    "text": "visually authoring part of their job",
    "start": "48719",
    "end": "50960"
  },
  {
    "text": "without writing any code",
    "start": "50960",
    "end": "52800"
  },
  {
    "text": "to writing handwritten code for complex",
    "start": "52800",
    "end": "56000"
  },
  {
    "text": "transformations where necessary",
    "start": "56000",
    "end": "59840"
  },
  {
    "text": "with respect to stream processing",
    "start": "59920",
    "end": "62079"
  },
  {
    "text": "applications",
    "start": "62079",
    "end": "63280"
  },
  {
    "text": "value glue studio ads is multi-fold",
    "start": "63280",
    "end": "68080"
  },
  {
    "text": "using the visual studio you can",
    "start": "68080",
    "end": "70240"
  },
  {
    "text": "seamlessly integrate with",
    "start": "70240",
    "end": "72240"
  },
  {
    "text": "aws kinesis data streams or manage kafka",
    "start": "72240",
    "end": "75520"
  },
  {
    "text": "in aws",
    "start": "75520",
    "end": "76560"
  },
  {
    "text": "or self-managed kafka without writing",
    "start": "76560",
    "end": "80080"
  },
  {
    "text": "any code",
    "start": "80080",
    "end": "81119"
  },
  {
    "text": "and that helps developers to be more",
    "start": "81119",
    "end": "83759"
  },
  {
    "text": "agile",
    "start": "83759",
    "end": "84479"
  },
  {
    "text": "when building streaming applications if",
    "start": "84479",
    "end": "87520"
  },
  {
    "text": "you are using kinesis data streams as a",
    "start": "87520",
    "end": "89439"
  },
  {
    "text": "source",
    "start": "89439",
    "end": "90320"
  },
  {
    "text": "then there is simply no connection",
    "start": "90320",
    "end": "92320"
  },
  {
    "text": "management and",
    "start": "92320",
    "end": "93600"
  },
  {
    "text": "glue handles that all for you under the",
    "start": "93600",
    "end": "96079"
  },
  {
    "text": "covers",
    "start": "96079",
    "end": "97520"
  },
  {
    "text": "if you are using kinesis data stream as",
    "start": "97520",
    "end": "99840"
  },
  {
    "text": "a source",
    "start": "99840",
    "end": "100880"
  },
  {
    "text": "then there is simply no connection",
    "start": "100880",
    "end": "102479"
  },
  {
    "text": "management and glue handles at all for",
    "start": "102479",
    "end": "104799"
  },
  {
    "text": "you under the covers",
    "start": "104799",
    "end": "106479"
  },
  {
    "text": "when kafka is used as a source then all",
    "start": "106479",
    "end": "109119"
  },
  {
    "text": "you need to do is simply",
    "start": "109119",
    "end": "110399"
  },
  {
    "text": "create a glue connection using the",
    "start": "110399",
    "end": "112240"
  },
  {
    "text": "broker endpoint and you're all",
    "start": "112240",
    "end": "114000"
  },
  {
    "text": "set again no need to worry about",
    "start": "114000",
    "end": "116479"
  },
  {
    "text": "connector code not drivers to manage",
    "start": "116479",
    "end": "119759"
  },
  {
    "text": "consumers for both kinesis data streams",
    "start": "119759",
    "end": "122320"
  },
  {
    "text": "and kafka",
    "start": "122320",
    "end": "123200"
  },
  {
    "text": "in most use cases are required to manage",
    "start": "123200",
    "end": "125840"
  },
  {
    "text": "checkpointing",
    "start": "125840",
    "end": "126960"
  },
  {
    "text": "to keep track of what they have read and",
    "start": "126960",
    "end": "129360"
  },
  {
    "text": "how to resume in case of failure",
    "start": "129360",
    "end": "132480"
  },
  {
    "text": "these consumers often rely on external",
    "start": "132480",
    "end": "135040"
  },
  {
    "text": "persistent stores such as",
    "start": "135040",
    "end": "136800"
  },
  {
    "text": "dynamodb hbase another kafka topic",
    "start": "136800",
    "end": "140800"
  },
  {
    "text": "s3 hdfs etc and write code to keep track",
    "start": "140800",
    "end": "144800"
  },
  {
    "text": "of",
    "start": "144800",
    "end": "145200"
  },
  {
    "text": "offsets in kafka partitions that they",
    "start": "145200",
    "end": "147760"
  },
  {
    "text": "have processed",
    "start": "147760",
    "end": "148800"
  },
  {
    "text": "or the shard iterator ids in kinesis",
    "start": "148800",
    "end": "151760"
  },
  {
    "text": "charts",
    "start": "151760",
    "end": "152319"
  },
  {
    "text": "that they have processed blue studio",
    "start": "152319",
    "end": "155040"
  },
  {
    "text": "simplifies that checkpointing",
    "start": "155040",
    "end": "157200"
  },
  {
    "text": "experience by managing it for you under",
    "start": "157200",
    "end": "159360"
  },
  {
    "text": "the cover so you can focus on",
    "start": "159360",
    "end": "161519"
  },
  {
    "text": "business logic or building the business",
    "start": "161519",
    "end": "163599"
  },
  {
    "text": "logic for processing the stream data",
    "start": "163599",
    "end": "167519"
  },
  {
    "text": "oftentimes customer oftentimes",
    "start": "167519",
    "end": "170959"
  },
  {
    "text": "stream analytic use cases require",
    "start": "170959",
    "end": "173680"
  },
  {
    "text": "joining stream data with reference data",
    "start": "173680",
    "end": "176560"
  },
  {
    "text": "that is in another persistent store such",
    "start": "176560",
    "end": "178720"
  },
  {
    "text": "as your enterprise data warehouse",
    "start": "178720",
    "end": "180400"
  },
  {
    "text": "whether it be on-prem or aws",
    "start": "180400",
    "end": "182800"
  },
  {
    "text": "or rdbms etc and glue simplifies using",
    "start": "182800",
    "end": "186879"
  },
  {
    "text": "those",
    "start": "186879",
    "end": "187280"
  },
  {
    "text": "lookup sources in your stream processing",
    "start": "187280",
    "end": "191120"
  },
  {
    "text": "code or application without writing any",
    "start": "191120",
    "end": "193360"
  },
  {
    "text": "code using the glue connector",
    "start": "193360",
    "end": "195599"
  },
  {
    "text": "framework so with no further delay",
    "start": "195599",
    "end": "198640"
  },
  {
    "text": "let's jump right in similar to the",
    "start": "198640",
    "end": "202000"
  },
  {
    "text": "batch etl jobs glue simplifies streaming",
    "start": "202000",
    "end": "206080"
  },
  {
    "text": "analytic job development using the",
    "start": "206080",
    "end": "207680"
  },
  {
    "text": "hybrid development experience",
    "start": "207680",
    "end": "209519"
  },
  {
    "text": "and just like for the glue batch etl",
    "start": "209519",
    "end": "212720"
  },
  {
    "text": "jobs stream retail jobs offer",
    "start": "212720",
    "end": "214560"
  },
  {
    "text": "a single pin of glass for monitoring",
    "start": "214560",
    "end": "217519"
  },
  {
    "text": "jobs and",
    "start": "217519",
    "end": "218319"
  },
  {
    "text": "is also fully serverless",
    "start": "218319",
    "end": "221760"
  },
  {
    "text": "let's consider a demo scenario where the",
    "start": "221760",
    "end": "224159"
  },
  {
    "text": "developer needs to",
    "start": "224159",
    "end": "225280"
  },
  {
    "text": "generate new york city taxi trip",
    "start": "225280",
    "end": "228000"
  },
  {
    "text": "statistics such as",
    "start": "228000",
    "end": "229440"
  },
  {
    "text": "number of passengers total amount etc",
    "start": "229440",
    "end": "232640"
  },
  {
    "text": "by vendor id every 100 seconds",
    "start": "232640",
    "end": "236560"
  },
  {
    "text": "new york city taxi data is streamed real",
    "start": "236560",
    "end": "239439"
  },
  {
    "text": "time",
    "start": "239439",
    "end": "240319"
  },
  {
    "text": "using the kinesis data stream as a",
    "start": "240319",
    "end": "242799"
  },
  {
    "text": "source",
    "start": "242799",
    "end": "244319"
  },
  {
    "text": "and then the taxi vendor lookup table is",
    "start": "244319",
    "end": "247519"
  },
  {
    "text": "in redshift data warehouse",
    "start": "247519",
    "end": "249200"
  },
  {
    "text": "which is used to join with the stream",
    "start": "249200",
    "end": "251760"
  },
  {
    "text": "data",
    "start": "251760",
    "end": "252560"
  },
  {
    "text": "and the chip statistics are calculated",
    "start": "252560",
    "end": "255599"
  },
  {
    "text": "using the custom transform function",
    "start": "255599",
    "end": "258479"
  },
  {
    "text": "these statistics are then",
    "start": "258479",
    "end": "260320"
  },
  {
    "text": "published to the s3 data lake with a",
    "start": "260320",
    "end": "263360"
  },
  {
    "text": "glue",
    "start": "263360",
    "end": "264080"
  },
  {
    "text": "catalog table as a target for further",
    "start": "264080",
    "end": "266840"
  },
  {
    "text": "views",
    "start": "266840",
    "end": "268400"
  },
  {
    "text": "though outside the scope of this demo",
    "start": "268400",
    "end": "270479"
  },
  {
    "text": "you can think of the target",
    "start": "270479",
    "end": "272000"
  },
  {
    "text": "trip statistic table which is refreshed",
    "start": "272000",
    "end": "274479"
  },
  {
    "text": "every 100 seconds can be used by",
    "start": "274479",
    "end": "276320"
  },
  {
    "text": "downstream applications for sending",
    "start": "276320",
    "end": "278320"
  },
  {
    "text": "alerts when when when a threshold is",
    "start": "278320",
    "end": "280560"
  },
  {
    "text": "reached and similarly",
    "start": "280560",
    "end": "282080"
  },
  {
    "text": "that data can also be used for",
    "start": "282080",
    "end": "283680"
  },
  {
    "text": "publishing real-time bi dashboards",
    "start": "283680",
    "end": "286320"
  },
  {
    "text": "using quick site or we're using advanced",
    "start": "286320",
    "end": "289120"
  },
  {
    "text": "analytics",
    "start": "289120",
    "end": "290560"
  },
  {
    "text": "ml models which are all again outside",
    "start": "290560",
    "end": "292720"
  },
  {
    "text": "the scope of this demo",
    "start": "292720",
    "end": "294479"
  },
  {
    "text": "but no further delay let's jump right",
    "start": "294479",
    "end": "296479"
  },
  {
    "text": "down",
    "start": "296479",
    "end": "298160"
  },
  {
    "text": "so before going into glue studio let's",
    "start": "298160",
    "end": "300960"
  },
  {
    "text": "take a look at the kinesis stream source",
    "start": "300960",
    "end": "303520"
  },
  {
    "text": "and make sure we're getting the data",
    "start": "303520",
    "end": "304880"
  },
  {
    "text": "into the stream this is the name of the",
    "start": "304880",
    "end": "307199"
  },
  {
    "text": "kinesis stream that we're using for this",
    "start": "307199",
    "end": "309280"
  },
  {
    "text": "demo",
    "start": "309280",
    "end": "310000"
  },
  {
    "text": "and we're sending roughly about 100 100",
    "start": "310000",
    "end": "313360"
  },
  {
    "text": "events per second into the stream",
    "start": "313360",
    "end": "315440"
  },
  {
    "text": "and here at the bottom i'm going to just",
    "start": "315440",
    "end": "317199"
  },
  {
    "text": "validate i'm getting all the 100",
    "start": "317199",
    "end": "319039"
  },
  {
    "text": "of these records and you can see that we",
    "start": "319039",
    "end": "321680"
  },
  {
    "text": "are getting it",
    "start": "321680",
    "end": "322800"
  },
  {
    "text": "and i'll also show you the schema of the",
    "start": "322800",
    "end": "325759"
  },
  {
    "text": "data that we're",
    "start": "325759",
    "end": "326720"
  },
  {
    "text": "getting sending into the stream and you",
    "start": "326720",
    "end": "329600"
  },
  {
    "text": "see it's the it has the vendor id",
    "start": "329600",
    "end": "331840"
  },
  {
    "text": "the pickup date time event etc and more",
    "start": "331840",
    "end": "335120"
  },
  {
    "text": "importantly the metrics that we need to",
    "start": "335120",
    "end": "336800"
  },
  {
    "text": "calculate",
    "start": "336800",
    "end": "337840"
  },
  {
    "text": "off of the tip amount the total amounts",
    "start": "337840",
    "end": "341039"
  },
  {
    "text": "the number of passengers the trip id",
    "start": "341039",
    "end": "343280"
  },
  {
    "text": "etc and each of these json records",
    "start": "343280",
    "end": "346960"
  },
  {
    "text": "are specific to a particular trip",
    "start": "346960",
    "end": "350400"
  },
  {
    "text": "now take a look at one of the",
    "start": "350400",
    "end": "352560"
  },
  {
    "text": "prerequisites required",
    "start": "352560",
    "end": "354400"
  },
  {
    "text": "before using this stream within the glue",
    "start": "354400",
    "end": "357440"
  },
  {
    "text": "studio",
    "start": "357440",
    "end": "358160"
  },
  {
    "text": "and the prerequisite is for you to",
    "start": "358160",
    "end": "360080"
  },
  {
    "text": "create a",
    "start": "360080",
    "end": "361680"
  },
  {
    "text": "table in glue catalog manually or using",
    "start": "361680",
    "end": "364560"
  },
  {
    "text": "an api",
    "start": "364560",
    "end": "365680"
  },
  {
    "text": "that points to the glue that points to",
    "start": "365680",
    "end": "368800"
  },
  {
    "text": "kinesis stream",
    "start": "368800",
    "end": "369919"
  },
  {
    "text": "that you've seen earlier and i'm going",
    "start": "369919",
    "end": "372080"
  },
  {
    "text": "to come here and",
    "start": "372080",
    "end": "373280"
  },
  {
    "text": "add a table and give it a name",
    "start": "373280",
    "end": "376319"
  },
  {
    "text": "demo stream taxi and select the database",
    "start": "376319",
    "end": "380400"
  },
  {
    "text": "that i'd like to",
    "start": "380400",
    "end": "381360"
  },
  {
    "text": "store this table under and i'll choose",
    "start": "381360",
    "end": "383840"
  },
  {
    "text": "demodb",
    "start": "383840",
    "end": "385120"
  },
  {
    "text": "and hit next the source is kinesis so",
    "start": "385120",
    "end": "389199"
  },
  {
    "text": "i'm going to select the name of the",
    "start": "389199",
    "end": "392160"
  },
  {
    "text": "stream",
    "start": "392160",
    "end": "393360"
  },
  {
    "text": "which is this stream that we looked at",
    "start": "393360",
    "end": "395680"
  },
  {
    "text": "earlier and the name has to match here",
    "start": "395680",
    "end": "397600"
  },
  {
    "text": "which is basically the source for this",
    "start": "397600",
    "end": "399600"
  },
  {
    "text": "blue catalog table so it's kinesis id",
    "start": "399600",
    "end": "401840"
  },
  {
    "text": "lab demo",
    "start": "401840",
    "end": "403199"
  },
  {
    "text": "i'm going to say can assist id",
    "start": "403199",
    "end": "407039"
  },
  {
    "text": "demo",
    "start": "407039",
    "end": "409840"
  },
  {
    "text": "i want to select the kinesis source url",
    "start": "410319",
    "end": "412880"
  },
  {
    "text": "which is",
    "start": "412880",
    "end": "413599"
  },
  {
    "text": "the public endpoint for kinesis and this",
    "start": "413599",
    "end": "416800"
  },
  {
    "text": "is for usc s1 which is where",
    "start": "416800",
    "end": "418800"
  },
  {
    "text": "my lab environment is so i'm going to",
    "start": "418800",
    "end": "422319"
  },
  {
    "text": "hit next and select the source format",
    "start": "422319",
    "end": "424479"
  },
  {
    "text": "which is json for this",
    "start": "424479",
    "end": "426880"
  },
  {
    "text": "stream and then i'm going to leave the",
    "start": "426880",
    "end": "429039"
  },
  {
    "text": "rest",
    "start": "429039",
    "end": "430160"
  },
  {
    "text": "defaults because the glue is going to be",
    "start": "430160",
    "end": "433759"
  },
  {
    "text": "able to",
    "start": "433759",
    "end": "434639"
  },
  {
    "text": "infer the schema from the stream due to",
    "start": "434639",
    "end": "437280"
  },
  {
    "text": "which i don't have to add the columns",
    "start": "437280",
    "end": "439440"
  },
  {
    "text": "explicitly so i'm going to hit next and",
    "start": "439440",
    "end": "441919"
  },
  {
    "text": "then",
    "start": "441919",
    "end": "442479"
  },
  {
    "text": "click finish so now we have the table",
    "start": "442479",
    "end": "445840"
  },
  {
    "text": "that's pointing to the glue stream",
    "start": "445840",
    "end": "448319"
  },
  {
    "text": "and another prerequisite is to crawl",
    "start": "448319",
    "end": "451039"
  },
  {
    "text": "redshift",
    "start": "451039",
    "end": "451919"
  },
  {
    "text": "and catalog the stream preference data",
    "start": "451919",
    "end": "455680"
  },
  {
    "text": "which is the",
    "start": "455680",
    "end": "456960"
  },
  {
    "text": "vendor id lookup data and we've already",
    "start": "456960",
    "end": "459520"
  },
  {
    "text": "done that",
    "start": "459520",
    "end": "460160"
  },
  {
    "text": "for the purposes of this demo and you",
    "start": "460160",
    "end": "461759"
  },
  {
    "text": "can see it's pointing to retro",
    "start": "461759",
    "end": "464160"
  },
  {
    "text": "so at this point we're ready to use glue",
    "start": "464160",
    "end": "466800"
  },
  {
    "text": "studio to author the",
    "start": "466800",
    "end": "468479"
  },
  {
    "text": "author or ppl job so i'm going to click",
    "start": "468479",
    "end": "471280"
  },
  {
    "text": "on",
    "start": "471280",
    "end": "471759"
  },
  {
    "text": "jobs link here and plan graph",
    "start": "471759",
    "end": "474800"
  },
  {
    "text": "to author the job and let's give it a",
    "start": "474800",
    "end": "477840"
  },
  {
    "text": "name",
    "start": "477840",
    "end": "478720"
  },
  {
    "text": "let me say demo stream etl",
    "start": "478720",
    "end": "483360"
  },
  {
    "text": "and we'll select our kinesis stream",
    "start": "483360",
    "end": "485520"
  },
  {
    "text": "source first",
    "start": "485520",
    "end": "487360"
  },
  {
    "text": "and here we go where the database is",
    "start": "487360",
    "end": "490080"
  },
  {
    "text": "under demodb",
    "start": "490080",
    "end": "491280"
  },
  {
    "text": "and then the table name which is demo",
    "start": "491280",
    "end": "494800"
  },
  {
    "text": "stream taxi",
    "start": "494800",
    "end": "497120"
  },
  {
    "text": "the second source let's select that one",
    "start": "497120",
    "end": "500240"
  },
  {
    "text": "which is our redshift source and you see",
    "start": "500240",
    "end": "502800"
  },
  {
    "text": "we selected",
    "start": "502800",
    "end": "503919"
  },
  {
    "text": "the database and the reference table for",
    "start": "503919",
    "end": "506240"
  },
  {
    "text": "the stream",
    "start": "506240",
    "end": "507199"
  },
  {
    "text": "so now that we have our sources both the",
    "start": "507199",
    "end": "509599"
  },
  {
    "text": "sources stream and the reference source",
    "start": "509599",
    "end": "512080"
  },
  {
    "text": "let's go ahead and add a transform that",
    "start": "512080",
    "end": "514560"
  },
  {
    "text": "will process the stream data",
    "start": "514560",
    "end": "516320"
  },
  {
    "text": "and join the stream data with the",
    "start": "516320",
    "end": "518159"
  },
  {
    "text": "reference data and performs few",
    "start": "518159",
    "end": "520159"
  },
  {
    "text": "aggregates",
    "start": "520159",
    "end": "521039"
  },
  {
    "text": "to create flip statistics so for that",
    "start": "521039",
    "end": "524240"
  },
  {
    "text": "given there is no pre-created",
    "start": "524240",
    "end": "527279"
  },
  {
    "text": "stream transformation window functions",
    "start": "527279",
    "end": "529440"
  },
  {
    "text": "etc as a part of the transform functions",
    "start": "529440",
    "end": "531600"
  },
  {
    "text": "we're going to",
    "start": "531600",
    "end": "532160"
  },
  {
    "text": "create custom code and use the power of",
    "start": "532160",
    "end": "534640"
  },
  {
    "text": "the",
    "start": "534640",
    "end": "535440"
  },
  {
    "text": "you know hybrid development so i'm going",
    "start": "535440",
    "end": "537200"
  },
  {
    "text": "to search the custom transform function",
    "start": "537200",
    "end": "540080"
  },
  {
    "text": "and um and here from the node properties",
    "start": "540080",
    "end": "542959"
  },
  {
    "text": "we'll use both the sources",
    "start": "542959",
    "end": "544560"
  },
  {
    "text": "so i'm going to select the second source",
    "start": "544560",
    "end": "546959"
  },
  {
    "text": "redshift as well",
    "start": "546959",
    "end": "548320"
  },
  {
    "text": "so at this point i have my custom",
    "start": "548320",
    "end": "550640"
  },
  {
    "text": "transform",
    "start": "550640",
    "end": "551360"
  },
  {
    "text": "which is ready to accept the code so",
    "start": "551360",
    "end": "554320"
  },
  {
    "text": "i've already copied",
    "start": "554320",
    "end": "556240"
  },
  {
    "text": "from my other window the code that i",
    "start": "556240",
    "end": "558560"
  },
  {
    "text": "wanted to use",
    "start": "558560",
    "end": "559760"
  },
  {
    "text": "so i'm going to pretty much",
    "start": "559760",
    "end": "562800"
  },
  {
    "text": "copy paste that so here i strongly",
    "start": "562800",
    "end": "565120"
  },
  {
    "text": "encourage you to",
    "start": "565120",
    "end": "566720"
  },
  {
    "text": "see my part two of the video",
    "start": "566720",
    "end": "569839"
  },
  {
    "text": "where i talk more about how to build",
    "start": "569839",
    "end": "572720"
  },
  {
    "text": "complex transformations and",
    "start": "572720",
    "end": "574640"
  },
  {
    "text": "dynamics what a dynamic frame collection",
    "start": "574640",
    "end": "576480"
  },
  {
    "text": "is and how you use you know",
    "start": "576480",
    "end": "578399"
  },
  {
    "text": "send and return uh multiple sources and",
    "start": "578399",
    "end": "582399"
  },
  {
    "text": "dynamic frames etc right so so please do",
    "start": "582399",
    "end": "584959"
  },
  {
    "text": "watch that",
    "start": "584959",
    "end": "586080"
  },
  {
    "text": "we're getting both the data sets you can",
    "start": "586080",
    "end": "587600"
  },
  {
    "text": "use the stream and the",
    "start": "587600",
    "end": "589680"
  },
  {
    "text": "redshift reference data and here i'm",
    "start": "589680",
    "end": "592399"
  },
  {
    "text": "just using some print statements to just",
    "start": "592399",
    "end": "594480"
  },
  {
    "text": "see in my log a little later",
    "start": "594480",
    "end": "597519"
  },
  {
    "text": "to make sure i'm getting the data in the",
    "start": "597519",
    "end": "599440"
  },
  {
    "text": "format i wanted and",
    "start": "599440",
    "end": "600640"
  },
  {
    "text": "you know just just quick validation from",
    "start": "600640",
    "end": "602240"
  },
  {
    "text": "the logs so i'm creating",
    "start": "602240",
    "end": "604160"
  },
  {
    "text": "temp tables uh just so i can start using",
    "start": "604160",
    "end": "607040"
  },
  {
    "text": "spock sql",
    "start": "607040",
    "end": "608079"
  },
  {
    "text": "and here in the spark sql i'm actually",
    "start": "608079",
    "end": "609839"
  },
  {
    "text": "performing the transformation which is",
    "start": "609839",
    "end": "612000"
  },
  {
    "text": "you know",
    "start": "612000",
    "end": "612560"
  },
  {
    "text": "a simple select simple uh sql statement",
    "start": "612560",
    "end": "616000"
  },
  {
    "text": "when i'm grouping by vendor id and",
    "start": "616000",
    "end": "618320"
  },
  {
    "text": "creating aggregates",
    "start": "618320",
    "end": "619680"
  },
  {
    "text": "on passenger count passenger crown",
    "start": "619680",
    "end": "623200"
  },
  {
    "text": "trip count and you know some of the tip",
    "start": "623200",
    "end": "626959"
  },
  {
    "text": "amount",
    "start": "626959",
    "end": "627839"
  },
  {
    "text": "and the sum of tolls from the stream",
    "start": "627839",
    "end": "631360"
  },
  {
    "text": "table and i'm joining that",
    "start": "631360",
    "end": "633040"
  },
  {
    "text": "with the reference table with with which",
    "start": "633040",
    "end": "636480"
  },
  {
    "text": "is in redshift that we brought so that",
    "start": "636480",
    "end": "638480"
  },
  {
    "text": "there is one denormalized data with both",
    "start": "638480",
    "end": "641040"
  },
  {
    "text": "the strip statistics as well as the",
    "start": "641040",
    "end": "642560"
  },
  {
    "text": "vendor details",
    "start": "642560",
    "end": "643600"
  },
  {
    "text": "so that's essentially what we're doing",
    "start": "643600",
    "end": "645120"
  },
  {
    "text": "and then again sort of print statements",
    "start": "645120",
    "end": "646720"
  },
  {
    "text": "and then returning that back into the",
    "start": "646720",
    "end": "648800"
  },
  {
    "text": "data frame or the clear frame collection",
    "start": "648800",
    "end": "651200"
  },
  {
    "text": "so at this point",
    "start": "651200",
    "end": "652880"
  },
  {
    "text": "the transformation is completed",
    "start": "652880",
    "end": "656000"
  },
  {
    "text": "so i'm going to add another transform",
    "start": "656000",
    "end": "658240"
  },
  {
    "text": "just to",
    "start": "658240",
    "end": "659040"
  },
  {
    "text": "select the output that we've got from",
    "start": "659040",
    "end": "662160"
  },
  {
    "text": "the custom transform which is",
    "start": "662160",
    "end": "663680"
  },
  {
    "text": "frame 0. we only have one data frame",
    "start": "663680",
    "end": "667600"
  },
  {
    "text": "in the collection that we've sent as",
    "start": "667600",
    "end": "669600"
  },
  {
    "text": "output so i'm going to continue to use",
    "start": "669600",
    "end": "671120"
  },
  {
    "text": "that",
    "start": "671120",
    "end": "671760"
  },
  {
    "text": "so now that we have the transformed data",
    "start": "671760",
    "end": "673760"
  },
  {
    "text": "set let's go ahead and add a target",
    "start": "673760",
    "end": "676079"
  },
  {
    "text": "to persist that data and then build a",
    "start": "676079",
    "end": "678160"
  },
  {
    "text": "catalog table on top of that in the s3",
    "start": "678160",
    "end": "680160"
  },
  {
    "text": "data lake so we can query on that",
    "start": "680160",
    "end": "682399"
  },
  {
    "text": "stream statistics data set so for that",
    "start": "682399",
    "end": "685200"
  },
  {
    "text": "i'm going to select s3 as my target",
    "start": "685200",
    "end": "688240"
  },
  {
    "text": "and we selected the target format for",
    "start": "688240",
    "end": "690959"
  },
  {
    "text": "the files that will be written from the",
    "start": "690959",
    "end": "692959"
  },
  {
    "text": "stream output and the location in s3",
    "start": "692959",
    "end": "695839"
  },
  {
    "text": "and the glue catalog table that will be",
    "start": "695839",
    "end": "697440"
  },
  {
    "text": "created a new table under the database",
    "start": "697440",
    "end": "699279"
  },
  {
    "text": "demodb",
    "start": "699279",
    "end": "700079"
  },
  {
    "text": "and with this particular name so at this",
    "start": "700079",
    "end": "702880"
  },
  {
    "text": "point the job authoring is complete so",
    "start": "702880",
    "end": "705279"
  },
  {
    "text": "the job would create a script such as",
    "start": "705279",
    "end": "708640"
  },
  {
    "text": "this",
    "start": "708640",
    "end": "709440"
  },
  {
    "text": "and i'd like to point out at a couple",
    "start": "709440",
    "end": "712240"
  },
  {
    "text": "key",
    "start": "712240",
    "end": "712880"
  },
  {
    "text": "things here which is the window size",
    "start": "712880",
    "end": "715839"
  },
  {
    "text": "typically stream",
    "start": "715839",
    "end": "716880"
  },
  {
    "text": "operations are performed on window",
    "start": "716880",
    "end": "718800"
  },
  {
    "text": "functions whether it be",
    "start": "718800",
    "end": "720160"
  },
  {
    "text": "a tumbling window or a sliding window by",
    "start": "720160",
    "end": "723279"
  },
  {
    "text": "default",
    "start": "723279",
    "end": "724240"
  },
  {
    "text": "kinesis by default glue streaming jobs",
    "start": "724240",
    "end": "726959"
  },
  {
    "text": "use a tumbling window of size 100",
    "start": "726959",
    "end": "728839"
  },
  {
    "text": "seconds",
    "start": "728839",
    "end": "730079"
  },
  {
    "text": "and you can certainly change that but",
    "start": "730079",
    "end": "732560"
  },
  {
    "text": "you have to change it outside of blue",
    "start": "732560",
    "end": "734399"
  },
  {
    "text": "studio",
    "start": "734399",
    "end": "735519"
  },
  {
    "text": "and the other thing i wanted to point",
    "start": "735519",
    "end": "737519"
  },
  {
    "text": "out is the checkpointing location which",
    "start": "737519",
    "end": "739120"
  },
  {
    "text": "i pointed out earlier that",
    "start": "739120",
    "end": "740720"
  },
  {
    "text": "glue manages to pointing for you under",
    "start": "740720",
    "end": "742800"
  },
  {
    "text": "the covers keeping track of the offsets",
    "start": "742800",
    "end": "745200"
  },
  {
    "text": "that it has read from kafka partitions",
    "start": "745200",
    "end": "746959"
  },
  {
    "text": "or keeping track of the",
    "start": "746959",
    "end": "748800"
  },
  {
    "text": "kinesis chart iterator ids that it has",
    "start": "748800",
    "end": "751360"
  },
  {
    "text": "read from each of the kinesis shards and",
    "start": "751360",
    "end": "753360"
  },
  {
    "text": "the source",
    "start": "753360",
    "end": "754160"
  },
  {
    "text": "so all of that go into the temp",
    "start": "754160",
    "end": "755680"
  },
  {
    "text": "directory which is in the stamp location",
    "start": "755680",
    "end": "759040"
  },
  {
    "text": "and i strongly encourage you to change",
    "start": "759040",
    "end": "761760"
  },
  {
    "text": "this path",
    "start": "761760",
    "end": "762880"
  },
  {
    "text": "to be a unique part for every job so",
    "start": "762880",
    "end": "766079"
  },
  {
    "text": "that each job has its own checkpointing",
    "start": "766079",
    "end": "768399"
  },
  {
    "text": "uh",
    "start": "768399",
    "end": "768880"
  },
  {
    "text": "reference we can save it and",
    "start": "768880",
    "end": "772480"
  },
  {
    "text": "run the job so at this point once the",
    "start": "772480",
    "end": "776560"
  },
  {
    "text": "job",
    "start": "776560",
    "end": "776959"
  },
  {
    "text": "is complete it'll take a few minutes so",
    "start": "776959",
    "end": "778720"
  },
  {
    "text": "i'm going to show you",
    "start": "778720",
    "end": "780079"
  },
  {
    "text": "a previous job stream job that was",
    "start": "780079",
    "end": "782320"
  },
  {
    "text": "completed and it actually",
    "start": "782320",
    "end": "784000"
  },
  {
    "text": "created the stream output as you can see",
    "start": "784000",
    "end": "787040"
  },
  {
    "text": "and when i ran this query you can see",
    "start": "787040",
    "end": "790399"
  },
  {
    "text": "that it actually",
    "start": "790399",
    "end": "792000"
  },
  {
    "text": "creates the um",
    "start": "792000",
    "end": "795200"
  },
  {
    "text": "trip statistics which is by vendor id",
    "start": "795200",
    "end": "798720"
  },
  {
    "text": "and",
    "start": "798720",
    "end": "799200"
  },
  {
    "text": "the the number of passengers the trip",
    "start": "799200",
    "end": "801680"
  },
  {
    "text": "counts etc that that this stream output",
    "start": "801680",
    "end": "804399"
  },
  {
    "text": "has created",
    "start": "804399",
    "end": "806639"
  },
  {
    "text": "and this will keep refreshing every 100",
    "start": "806639",
    "end": "808480"
  },
  {
    "text": "seconds you can keep running the query",
    "start": "808480",
    "end": "810160"
  },
  {
    "text": "and then it'll it'll populate it",
    "start": "810160",
    "end": "812800"
  },
  {
    "text": "this concludes the demo so let's quickly",
    "start": "812800",
    "end": "815279"
  },
  {
    "text": "summarize what you've learned in this",
    "start": "815279",
    "end": "817279"
  },
  {
    "text": "video so you've learned the benefits of",
    "start": "817279",
    "end": "819760"
  },
  {
    "text": "glue studio for",
    "start": "819760",
    "end": "820959"
  },
  {
    "text": "stream processing applications and how",
    "start": "820959",
    "end": "823680"
  },
  {
    "text": "it can",
    "start": "823680",
    "end": "824399"
  },
  {
    "text": "help you rapidly develop streaming",
    "start": "824399",
    "end": "826560"
  },
  {
    "text": "application",
    "start": "826560",
    "end": "827519"
  },
  {
    "text": "using its hybrid visual interface",
    "start": "827519",
    "end": "830720"
  },
  {
    "text": "and also allowing you to use lookup",
    "start": "830720",
    "end": "833600"
  },
  {
    "text": "reference data that may be in an",
    "start": "833600",
    "end": "835360"
  },
  {
    "text": "external database",
    "start": "835360",
    "end": "836880"
  },
  {
    "text": "and use it in a stream processing job",
    "start": "836880",
    "end": "839040"
  },
  {
    "text": "when writing your stream",
    "start": "839040",
    "end": "840839"
  },
  {
    "text": "applications so with that",
    "start": "840839",
    "end": "843680"
  },
  {
    "text": "i thank you for watching you this video",
    "start": "843680",
    "end": "845680"
  },
  {
    "text": "and looking forward to",
    "start": "845680",
    "end": "847199"
  },
  {
    "text": "seeing you in the next video thank you",
    "start": "847199",
    "end": "856160"
  }
]
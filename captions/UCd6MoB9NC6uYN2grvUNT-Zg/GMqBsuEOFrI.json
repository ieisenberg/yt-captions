[
  {
    "start": "0",
    "end": "97000"
  },
  {
    "text": "had some some good sessions I know we we did our best to pull together some good speakers to share the sort of the best",
    "start": "0",
    "end": "5850"
  },
  {
    "text": "of the most interesting things that we're seeing in market and I hope to extend that today so the session that",
    "start": "5850",
    "end": "11160"
  },
  {
    "text": "we'll go through is talking about data leaks on AWS now I think probably all of",
    "start": "11160",
    "end": "16949"
  },
  {
    "text": "you have heard about data Lakes and you're in this room because you're curious about what is it really and and",
    "start": "16949",
    "end": "22109"
  },
  {
    "text": "how do we build them so what I'm gonna share with you is as we look across some of the most interesting customers that",
    "start": "22109",
    "end": "28019"
  },
  {
    "text": "we have and the big customers and the small customers how are they approaching this idea of there's a whole lot of data",
    "start": "28019",
    "end": "34590"
  },
  {
    "text": "that there's something interesting in it but it doesn't play nice in a traditional environment so I'll give you",
    "start": "34590",
    "end": "40890"
  },
  {
    "text": "a little bit of background about why I care about this so much and then we'll dig into what best practices look like so as you may have heard my name is",
    "start": "40890",
    "end": "47820"
  },
  {
    "text": "Craig I'm based out of Singapore but in Asia almost 20 years and I've been working in the analytics industry for",
    "start": "47820",
    "end": "53489"
  },
  {
    "text": "about that same amount of time I come from a behavioral analytics background and at that time so 20 years ago we were",
    "start": "53489",
    "end": "60809"
  },
  {
    "text": "doing analytics right we were processing data in big scale but it tended to be a few companies that could afford the very",
    "start": "60809",
    "end": "67189"
  },
  {
    "text": "specialized skills of we call them data miners at the time and they could afford really big hardware well the way that we",
    "start": "67189",
    "end": "74340"
  },
  {
    "text": "solve problems at that time was by buying really big boxes right and so when we worked with the casinos when we",
    "start": "74340",
    "end": "79890"
  },
  {
    "text": "worked at the banks and we worked with some of these really large organizations then they had to buy super huge",
    "start": "79890",
    "end": "86189"
  },
  {
    "text": "infrastructure just to get started now that's changed a lot and what's available to you today looks very",
    "start": "86189",
    "end": "92100"
  },
  {
    "text": "different than it did several years ago so what kind of talk through a little bit around how this stuff actually fits",
    "start": "92100",
    "end": "97140"
  },
  {
    "start": "97000",
    "end": "215000"
  },
  {
    "text": "together to solve some problems now we'd like to put Netflix up on screen not only because we love to watch Netflix",
    "start": "97140",
    "end": "103829"
  },
  {
    "text": "but Netflix is very interesting and part of the reason that we hold them is such an interesting customer Netflix does",
    "start": "103829",
    "end": "110549"
  },
  {
    "text": "things that just have never been done before at the scale that they operate so Netflix at peak you've probably heard",
    "start": "110549",
    "end": "117240"
  },
  {
    "text": "something similar to this is at peak consumption in North America they consume 38 percent of all Internet",
    "start": "117240",
    "end": "122969"
  },
  {
    "text": "traffic whoo it's huge right what also means is that they are looking",
    "start": "122969",
    "end": "128310"
  },
  {
    "text": "at the amount of human behavior that they track is pretty extraordinary now in order for net flow",
    "start": "128310",
    "end": "133980"
  },
  {
    "text": "to operate and be as successful as they are they have to give great content recommendations and those little bars",
    "start": "133980",
    "end": "139530"
  },
  {
    "text": "that you see at the bottom those generate about 80% of all views of Netflix content comes through",
    "start": "139530",
    "end": "145500"
  },
  {
    "text": "recommendations now how do they get good recommendations they build a couple of insights one is they look across",
    "start": "145500",
    "end": "152280"
  },
  {
    "text": "everybody who's watching and they build things called cohorts people who look like other people and they start to then",
    "start": "152280",
    "end": "157379"
  },
  {
    "text": "build profiles around what kind of mood might you be in so based on your cohort and looking at do we think that are you",
    "start": "157379",
    "end": "164159"
  },
  {
    "text": "pausing a lot you leave for three minutes you come back I don't know maybe you've got small kids in the room and they're kind of distracting you maybe",
    "start": "164159",
    "end": "170129"
  },
  {
    "text": "you're bored and you've got to do something else they do something called playback analytics and playback analytics is the process of capturing",
    "start": "170129",
    "end": "176900"
  },
  {
    "text": "these sort of interesting winding streams of human behavior of how people watch they consume video that doesn't",
    "start": "176900",
    "end": "184440"
  },
  {
    "text": "fit into a data warehouse so for Netflix to be able to produce not just these two recommendation bars but to build the",
    "start": "184440",
    "end": "190769"
  },
  {
    "text": "hundreds of recommendation bars that sit underneath they have to be able to capture every single bit of data even",
    "start": "190769",
    "end": "197579"
  },
  {
    "text": "when it doesn't look like nice transactional data so they've built a data Lake that operates now into the hundreds of terabytes and into petabytes",
    "start": "197579",
    "end": "204660"
  },
  {
    "text": "and some of their because they they have sort of distributed data lakes so Netflix has to move over to and we'll",
    "start": "204660",
    "end": "210389"
  },
  {
    "text": "talk about the design but they have to move to data Lake to be able to operate the scale that they do now if there's",
    "start": "210389",
    "end": "216450"
  },
  {
    "start": "215000",
    "end": "297000"
  },
  {
    "text": "any gamers in the room we're all friends you can you can admit it so yeah clash of clans it was a huge game for",
    "start": "216450",
    "end": "223019"
  },
  {
    "text": "six years clash of clans was the number one daily revenue earner of all mobile games until",
    "start": "223019",
    "end": "229280"
  },
  {
    "text": "Pokemon go right so anyway so but until then for six years of the number-one earner and why clash of clans and",
    "start": "229280",
    "end": "236220"
  },
  {
    "text": "supercell specifically being the company that runs them is able to detect your mood so as your gaming and you've died",
    "start": "236220",
    "end": "242970"
  },
  {
    "text": "three times they know if you're a person who's going to get frustrated and you're likely to leave and if you are are you",
    "start": "242970",
    "end": "249780"
  },
  {
    "text": "competitive are they going to put up something like a leaderboard are you a social person are they going to put up here's somebody who's recently come",
    "start": "249780",
    "end": "254970"
  },
  {
    "text": "online who's a friend of yours are they going to say here's the next level here's how far you need to go to get to the next level if you watch other people",
    "start": "254970",
    "end": "261930"
  },
  {
    "text": "who are playing they'll be getting different sorts of indications things that are going to trigger them to stay in the game",
    "start": "261930",
    "end": "267480"
  },
  {
    "text": "these are things based off of your propensity and then you're basically looking at your behavior profile in",
    "start": "267480",
    "end": "273090"
  },
  {
    "text": "order for them to capture that and detect that again this is not nice transactional data this includes things",
    "start": "273090",
    "end": "279150"
  },
  {
    "text": "like your location GPS location it looks at your behaviors within the game and more importantly what's captured in that",
    "start": "279150",
    "end": "285060"
  },
  {
    "text": "data Lake needs to build models that are in the hundreds of milliseconds for response time so when they detect that",
    "start": "285060",
    "end": "290730"
  },
  {
    "text": "you've changed your state they're able to give you some sort of recommendation that happens within hundreds of",
    "start": "290730",
    "end": "295860"
  },
  {
    "text": "milliseconds so how do they start to build this let's walk back a little bit and think about what's changed why data",
    "start": "295860",
    "end": "302700"
  },
  {
    "start": "297000",
    "end": "482000"
  },
  {
    "text": "lakes look fundamentally different from what we had years ago now kind of in 1985",
    "start": "302700",
    "end": "308160"
  },
  {
    "text": "you know before I think the majority of us were in in tech there we had this idea of by big boxes and solve big",
    "start": "308160",
    "end": "314850"
  },
  {
    "text": "problems and these were data warehouse machines they typically were hardware that had some software integrated",
    "start": "314850",
    "end": "320550"
  },
  {
    "text": "pre-configured to run an optimal level and that held for a whole bunch of years",
    "start": "320550",
    "end": "325830"
  },
  {
    "text": "that held for about 30 years start about 20 years and so that sort of held until",
    "start": "325830",
    "end": "331560"
  },
  {
    "text": "about 2000 mid 2000s when a big search internet search company had this problem",
    "start": "331560",
    "end": "336600"
  },
  {
    "text": "and said buying big machines is not going to solve this so I need to take this problem of searching the web and break it on into a lot of small parts",
    "start": "336600",
    "end": "343020"
  },
  {
    "text": "and sort of that was the genesis around that time of creating Hadoop if you're not familiar with Hadoop it this is",
    "start": "343020",
    "end": "349290"
  },
  {
    "text": "important for a later discussion because Hadoop takes this idea of big problems split them into a lot of small pieces",
    "start": "349290",
    "end": "355740"
  },
  {
    "text": "that could be asked at the same time and stick them on to cheap hardware it lets you scale out and it essentially buys",
    "start": "355740",
    "end": "361620"
  },
  {
    "text": "you time so that you're able to solve really big questions in a shorter amount of time that was good and Hadoop was",
    "start": "361620",
    "end": "367680"
  },
  {
    "text": "really useful but if anybody here has ever installed and managed a Hadoop cluster",
    "start": "367680",
    "end": "372750"
  },
  {
    "text": "I'd like you to smile for me valve is terrible right so it's okay if you're",
    "start": "372750",
    "end": "378510"
  },
  {
    "text": "operating at a small scale but when you move past eight nodes or sixteen nodes and you're doing patch management and it's just kind of like it's it's a",
    "start": "378510",
    "end": "384930"
  },
  {
    "text": "pretty miserable process and so we got a lot of feedback saying can you make this process easier so we decoupled the",
    "start": "384930",
    "end": "391470"
  },
  {
    "text": "storage and the compute because fundamentally when you're building Hadoop and you need to extend your clusters it's never because you run out",
    "start": "391470",
    "end": "398370"
  },
  {
    "text": "of compute it's because you run out of storage you need more disk you need more HDFS you need to",
    "start": "398370",
    "end": "403379"
  },
  {
    "text": "put more in so you're buying more machines you're basically buying like big computers just for the disk which",
    "start": "403379",
    "end": "409020"
  },
  {
    "text": "isn't really great for you so we split out with our Hadoop implementation called Amazon Elastic MapReduce or EMR",
    "start": "409020",
    "end": "415529"
  },
  {
    "text": "we created something which is a decoupling is the EMR file system that allows you to store all your HDFS in s3",
    "start": "415529",
    "end": "422009"
  },
  {
    "text": "and then you can turn that cluster on you can turn it off if you want to scale it you can scale the cluster up and down",
    "start": "422009",
    "end": "427949"
  },
  {
    "text": "and you're only paying for the hours that you run compute on this totally changed the model of how people thought",
    "start": "427949",
    "end": "434819"
  },
  {
    "text": "about using Hadoop instead of it being the place where you store data it became an engine to process data I'll",
    "start": "434819",
    "end": "441839"
  },
  {
    "text": "say that one more time Hadoop's role change from being the place that people thought about being a data Lake into just an engine to process",
    "start": "441839",
    "end": "449999"
  },
  {
    "text": "data with the storage becoming the data Lake the storage being the place where the data lives because if you're paying",
    "start": "449999",
    "end": "456599"
  },
  {
    "text": "s3 prices which are I think run two and a half cents per gig per month it's very different than having to buy disk on a",
    "start": "456599",
    "end": "463019"
  },
  {
    "text": "whole bunch of machines so this process of thinking differently about where does storage fit into this bigger picture and",
    "start": "463019",
    "end": "470189"
  },
  {
    "text": "I won't go through all those sort of details and I'll talk a little bit later about redshift and how we're actually moving more and more towards not even",
    "start": "470189",
    "end": "476399"
  },
  {
    "text": "running servers at all and moving towards server lists and cluster las' services so I'll talk about this a bit",
    "start": "476399",
    "end": "482099"
  },
  {
    "start": "482000",
    "end": "535000"
  },
  {
    "text": "later now kind of the next big shift that came out of this was not only are",
    "start": "482099",
    "end": "487829"
  },
  {
    "text": "we moving away from this idea of by big integrated machines to solve problems because they don't scale well but also",
    "start": "487829",
    "end": "494939"
  },
  {
    "text": "this idea that what if we could decouple better what if we could create data pipelines so instead of having these",
    "start": "494939",
    "end": "500789"
  },
  {
    "text": "huge batch jobs that have to run to move data from source a into target B we",
    "start": "500789",
    "end": "506939"
  },
  {
    "text": "could say every time that there is a change in data let's start streaming through data in data pipelines it",
    "start": "506939",
    "end": "512880"
  },
  {
    "text": "typically follows a pattern like this you have data this store it's ingested it's stored analyzed there's a we sort",
    "start": "512880",
    "end": "519328"
  },
  {
    "text": "of cycle it a couple times and then it's consumed and what you'll see is that this changes the whole economic model of",
    "start": "519329",
    "end": "525600"
  },
  {
    "text": "how data flows through a system it's you don't have to provision three years in the future you're only paying for what",
    "start": "525600",
    "end": "531449"
  },
  {
    "text": "you're using in that moment so again a very different model around keep out how to move that data and it",
    "start": "531449",
    "end": "537270"
  },
  {
    "start": "535000",
    "end": "570000"
  },
  {
    "text": "tends to be represented like this as you look at sort of AWS customers that are operating at scale they tend to",
    "start": "537270",
    "end": "544080"
  },
  {
    "text": "structure their data flows into data pipelines in event pipelines so data",
    "start": "544080",
    "end": "549720"
  },
  {
    "text": "pipelines set across the top and if you're if you come from a data architecture background you may be familiar with this concept of lamda",
    "start": "549720",
    "end": "555780"
  },
  {
    "text": "architectures something similar to that you have a batch layer and a real-time layer but essentially you have data",
    "start": "555780",
    "end": "561420"
  },
  {
    "text": "pipelines and event pipelines the data pipeline moves source data all the way",
    "start": "561420",
    "end": "566430"
  },
  {
    "text": "through to some sort of data processing facility that then the user is able to pick up so what does that pipeline",
    "start": "566430",
    "end": "572760"
  },
  {
    "start": "570000",
    "end": "602000"
  },
  {
    "text": "actually look like so it's a fully decoupled system ideally starts with Amazon s3 which you",
    "start": "572760",
    "end": "578910"
  },
  {
    "text": "mentioned simple storage service which is that really durable 11:9 of durability so you never lose",
    "start": "578910",
    "end": "584340"
  },
  {
    "text": "objects it comes out of the box with things like tick box encryption you've got versioning you're able to stick this",
    "start": "584340",
    "end": "590550"
  },
  {
    "text": "stuff down at a cold storage okay so things land first into a landing zone this is very different from batch",
    "start": "590550",
    "end": "596850"
  },
  {
    "text": "loading things from a source into a database we first put it into an object based store in a landing zone there's a",
    "start": "596850",
    "end": "603240"
  },
  {
    "start": "602000",
    "end": "643000"
  },
  {
    "text": "trigger that runs off the bottom and that trigger says the moment that I see new data the buckets responsive and it",
    "start": "603240",
    "end": "609120"
  },
  {
    "text": "runs a bit of code and says okay I've got something push this down into the data processing layer they did a",
    "start": "609120",
    "end": "614520"
  },
  {
    "text": "processing layer in this case we see customers that operate at scale they often prefer to use Hadoop with SPARC",
    "start": "614520",
    "end": "621900"
  },
  {
    "text": "there's some libraries that are good for processing semi structured data and processing data at scale which is if you",
    "start": "621900",
    "end": "628020"
  },
  {
    "text": "look at Nasdaq's and FINRA's and are very large customers they tend to use this model if you're smaller you may",
    "start": "628020",
    "end": "634440"
  },
  {
    "text": "choose just to use something like a lambda script or you can use talent or material it doesn't really matter the",
    "start": "634440",
    "end": "640200"
  },
  {
    "text": "important thing is it's part of that pipeline now there's a bit that sits on",
    "start": "640200",
    "end": "645600"
  },
  {
    "start": "643000",
    "end": "682000"
  },
  {
    "text": "the bottom now so we've released a service called glue and glue is it does a few things for you and I'll talk a bit",
    "start": "645600",
    "end": "651450"
  },
  {
    "text": "more in detail but essentially it's helping you run your ETL jobs and keep track of what data has been produced and",
    "start": "651450",
    "end": "657240"
  },
  {
    "text": "where it's stored that data then goes in lands into the data like the data like again is another s3 set of buckets",
    "start": "657240",
    "end": "664550"
  },
  {
    "text": "now once it's in the data lake whether you push that into a data warehouse or it goes into a no sequel store it",
    "start": "664550",
    "end": "671339"
  },
  {
    "text": "goes into elasticsearch wherever you want to consume it the important thing is we put the controls and the access",
    "start": "671339",
    "end": "677819"
  },
  {
    "text": "controls and governance at this layer into s3 so one of the core services we",
    "start": "677819",
    "end": "684540"
  },
  {
    "text": "mentioned if you're not familiar with glue this kind of takes away some of the heavy lifting of okay I'm storing stuff",
    "start": "684540",
    "end": "690000"
  },
  {
    "text": "in my data Lake how do I catalog it in a way that I can search and find it so glue has three parts to it glue does",
    "start": "690000",
    "end": "696569"
  },
  {
    "text": "crawling of data which is my data is landed somewhere please tell me what the shape of it is what are the fields what",
    "start": "696569",
    "end": "702240"
  },
  {
    "text": "are the data types is it numeric and so on so it helps with that categorization of data then there is the ETL execution",
    "start": "702240",
    "end": "709380"
  },
  {
    "text": "which does what it sounds like and then the third is cataloging now the decision was made if you've ever done data",
    "start": "709380",
    "end": "716040"
  },
  {
    "text": "catalogues before the format that's often used are hive meta stores and we've chosen for glue to also use a hive",
    "start": "716040",
    "end": "722970"
  },
  {
    "text": "Metis or so that you can sync if you have existing catalogs you can sync it or if you have other management tools",
    "start": "722970",
    "end": "729060"
  },
  {
    "text": "that you like to use you always have the ability to move to and from glue so you don't end up getting locked into any any",
    "start": "729060",
    "end": "734910"
  },
  {
    "text": "given tool so the idea behind a data Lake why we're building it is much of it",
    "start": "734910",
    "end": "742470"
  },
  {
    "start": "736000",
    "end": "811000"
  },
  {
    "text": "is because a we have those types of data like clickstream behaviors we have geolocation data we have anything that's",
    "start": "742470",
    "end": "749250"
  },
  {
    "text": "really coming off digital assets doesn't play nice in a data warehouse if we're getting third-party data or data in from",
    "start": "749250",
    "end": "755399"
  },
  {
    "text": "API services it doesn't play nice in the data warehouse so we need to be able to build something that can handle",
    "start": "755399",
    "end": "761630"
  },
  {
    "text": "transactional data handle ERP data handle social media data can handle video files audio whatever it is that we",
    "start": "761630",
    "end": "768029"
  },
  {
    "text": "need the data where the data like needs to be able to support that the other is if I look across this room and we did a",
    "start": "768029",
    "end": "774870"
  },
  {
    "text": "survey around your technical skills there's gonna be people here who are super hardcore data analysts probably",
    "start": "774870",
    "end": "780810"
  },
  {
    "text": "even up to the data science level and then there's gonna be people here who are just curious who don't even write",
    "start": "780810",
    "end": "786300"
  },
  {
    "text": "sequel right so there's quite a range and it's all people who have needs for information so the data like needs to",
    "start": "786300",
    "end": "792750"
  },
  {
    "text": "support different types of tool access it cannot only be available for one different one type of role so again",
    "start": "792750",
    "end": "799889"
  },
  {
    "text": "thinking about role based access to the data so having iving in anywhere depending on granularity and having good search",
    "start": "799889",
    "end": "806220"
  },
  {
    "text": "mechanisms so we can know what's in the data like what's been vetted when it was updated and so on so what it looks like",
    "start": "806220",
    "end": "813060"
  },
  {
    "start": "811000",
    "end": "1014000"
  },
  {
    "text": "these are just this is kind of a bit of an eye chart but it's looking at the services that tend to be used to build",
    "start": "813060",
    "end": "818100"
  },
  {
    "text": "the data like s3 and then there's the ingestion layer we mentioned this before",
    "start": "818100",
    "end": "823710"
  },
  {
    "text": "but because we've been building the cloud for a long time since 2006 we have a lot of mechanisms to move data into",
    "start": "823710",
    "end": "830910"
  },
  {
    "text": "the cloud so whether you're using storage gateways if you're in a regulated industry where you can't ever",
    "start": "830910",
    "end": "836790"
  },
  {
    "text": "let your data move across the internet you might use a bit of fibre that goes from your data centers to ours it's called a direct connect there's many",
    "start": "836790",
    "end": "843300"
  },
  {
    "text": "ways that you can move data in we also have the consumption now the consumption there's a whole lot of tools this is by",
    "start": "843300",
    "end": "849690"
  },
  {
    "text": "no means comprehensive data warehousing elasticsearch direct query capabilities bi tools so there's a lot of ways you",
    "start": "849690",
    "end": "857339"
  },
  {
    "text": "can even bring your own if you're a tableau user or a click or a MicroStrategy user on that side now this",
    "start": "857339",
    "end": "865290"
  },
  {
    "text": "part is super important for making sure that data Lake has the right control so",
    "start": "865290",
    "end": "870780"
  },
  {
    "text": "you can find out what's in it there's a service called Macy and if you haven't heard of Macy before Macy is an AI based",
    "start": "870780",
    "end": "878400"
  },
  {
    "text": "data categorization and data classification tool all right that was a",
    "start": "878400",
    "end": "884040"
  },
  {
    "text": "big mouthful try it again Macy looks at data and it tells you is there PII is there personally",
    "start": "884040",
    "end": "890730"
  },
  {
    "text": "identifiable information are there national ID numbers or their phone numbers or their addresses it can also",
    "start": "890730",
    "end": "896190"
  },
  {
    "text": "look for if you have other things that are sensitive to your business you can write rules for it but it learns it's a",
    "start": "896190",
    "end": "902370"
  },
  {
    "text": "machine it's a machine learning based AI tool that once you've said this is the kind",
    "start": "902370",
    "end": "907380"
  },
  {
    "text": "of data I'm looking for it can also learn and improve over time this is helpful if you say have data this coming",
    "start": "907380",
    "end": "914250"
  },
  {
    "text": "in you think that it's got certain content but you want to validate it before it drops into the data lake you",
    "start": "914250",
    "end": "920010"
  },
  {
    "text": "can put a level of protection on that so you can check that data in addition you can use it to say from a data loss",
    "start": "920010",
    "end": "926580"
  },
  {
    "text": "prevention standpoint somebody who's coming in accessing the data lake you can always make sure that when they've",
    "start": "926580",
    "end": "931650"
  },
  {
    "text": "created they've merged together data sets they haven't created something that should not be exported out of the system so Macy helps you with",
    "start": "931650",
    "end": "938430"
  },
  {
    "text": "some of the tricky data classification and DLP sort of issues there's also glue which we talked about",
    "start": "938430",
    "end": "945210"
  },
  {
    "text": "which is really around talking being able to categorize what's in the data like how did it get there and if you're",
    "start": "945210",
    "end": "951690"
  },
  {
    "text": "searching for it what how what the what the rules are around that data there's",
    "start": "951690",
    "end": "956790"
  },
  {
    "text": "another piece for access and without going into sort of each one of these it's essentially whether you're coming in through a mobile interface you're",
    "start": "956790",
    "end": "963180"
  },
  {
    "text": "coming in through your computer you're coming in through different servers being able to apply access controls",
    "start": "963180",
    "end": "968550"
  },
  {
    "text": "based on role at the bottom this is really around securing access to the",
    "start": "968550",
    "end": "974160"
  },
  {
    "text": "data sets why we focus so much on applying this governance to s3 is that",
    "start": "974160",
    "end": "981240"
  },
  {
    "text": "if we applied at the data lake level then it doesn't matter what tool people bring and in the old world what we had",
    "start": "981240",
    "end": "987480"
  },
  {
    "text": "to do was every single access tool we had to apply security controls into that tool and it's a little hard because you",
    "start": "987480",
    "end": "994320"
  },
  {
    "text": "can never keep that in sync especially as you add tools so if we put programmatic controls and we put role",
    "start": "994320",
    "end": "1000860"
  },
  {
    "text": "based access controls at each bucket level we can ensure that no matter who comes and accesses it what tools extract",
    "start": "1000860",
    "end": "1007100"
  },
  {
    "text": "from it they have to follow the same rules data cannot be used improperly or can't be accessed by people who",
    "start": "1007100",
    "end": "1013130"
  },
  {
    "text": "shouldn't see it so the downstream service that you'll almost always see",
    "start": "1013130",
    "end": "1018260"
  },
  {
    "start": "1014000",
    "end": "1087000"
  },
  {
    "text": "title into a data lake so you have data lake which is typically for just from a structure if you're curious about that",
    "start": "1018260",
    "end": "1023540"
  },
  {
    "text": "double click down typically we see data that comes in gets stored into a columnar format so for those who aren't",
    "start": "1023540",
    "end": "1030230"
  },
  {
    "text": "super interested in this next slide down you can kind of check out for about a minute but for the ones who want to know",
    "start": "1030230",
    "end": "1035270"
  },
  {
    "text": "like what does it usually look like typically it's a columnar format I get stored in there's three kind of main",
    "start": "1035270",
    "end": "1040970"
  },
  {
    "text": "formats we see whether it's Avro or Core Park a parquet seems to kind of be winning the battle just because it's",
    "start": "1040970",
    "end": "1047180"
  },
  {
    "text": "consumable by different number of different downstream services and one of",
    "start": "1047180",
    "end": "1052280"
  },
  {
    "text": "those services being the ability to import that into redshift so redshift is a data warehouse and data warehouses are",
    "start": "1052280",
    "end": "1058520"
  },
  {
    "text": "good at answering dimensional questions a dimensional question is what something looks like over time or a person's",
    "start": "1058520",
    "end": "1064910"
  },
  {
    "text": "purchase purchase history basically you've got a set of tables and they sort of look across those",
    "start": "1064910",
    "end": "1070310"
  },
  {
    "text": "mentions that's called a schema and if you know what your schema is a data warehouse is great at answering those",
    "start": "1070310",
    "end": "1076220"
  },
  {
    "text": "questions at scale and its speed but you don't always know the schema that you",
    "start": "1076220",
    "end": "1081770"
  },
  {
    "text": "want sometimes you want to ask questions ad hoc questions so I'll go a little bit a little bit deeper on that now here's",
    "start": "1081770",
    "end": "1090380"
  },
  {
    "start": "1087000",
    "end": "1166000"
  },
  {
    "text": "the pattern now you saw before we had the consumer we had the source and then there's the pipeline that sits in between what Nasdaq is doing is Nasdaq",
    "start": "1090380",
    "end": "1098510"
  },
  {
    "text": "is looking at a whole lot of queries that come in through the day and they insert this is 4.8 but they vary between",
    "start": "1098510",
    "end": "1104840"
  },
  {
    "text": "about 5 and 8 billion rows that need to be added to the database and Nasdaq of course being the tech exchange for",
    "start": "1104840",
    "end": "1110810"
  },
  {
    "text": "stocks in the US so they have a whole lot of challenges they have a lot of challenges they need to look at and one",
    "start": "1110810",
    "end": "1117080"
  },
  {
    "text": "of them was if you remember back in I think it was around 2008 goldman sachs had a crazy their high-frequency trading",
    "start": "1117080",
    "end": "1123680"
  },
  {
    "text": "system what kind of went berserk and there's a flash crash and they had to shut the markets for a bit and I wasn't",
    "start": "1123680",
    "end": "1128690"
  },
  {
    "text": "a great result so Nasdaq was tasked with can you please find intraday anomalies",
    "start": "1128690",
    "end": "1133820"
  },
  {
    "text": "and their existing systems they couldn't so they just had to shut markets when things look weird so by building a data",
    "start": "1133820",
    "end": "1140330"
  },
  {
    "text": "Lake that they can then apply any sort of whether they want to run a thousand node hoodoo pluster to do data",
    "start": "1140330",
    "end": "1145970"
  },
  {
    "text": "processing at night or they want to do intraday loads into the data warehouse so this is where you'll see did a data",
    "start": "1145970",
    "end": "1151520"
  },
  {
    "text": "coming in from source goes into a data Lake and now it feeds into a EMR for data processing and it goes into",
    "start": "1151520",
    "end": "1157250"
  },
  {
    "text": "redshift for trend analysis so again that same sort of pattern we see it",
    "start": "1157250",
    "end": "1162380"
  },
  {
    "text": "replicated across a number of our customers who operate at scale now let's",
    "start": "1162380",
    "end": "1168260"
  },
  {
    "start": "1166000",
    "end": "1241000"
  },
  {
    "text": "say that you want to look at data that doesn't all need to be hot so most of the most industries say ok well",
    "start": "1168260",
    "end": "1174860"
  },
  {
    "text": "sometimes I I work in a very high volume business I only care about what's happened in the last six months",
    "start": "1174860",
    "end": "1179990"
  },
  {
    "text": "typically anything beyond that I might do annual reporting for seasonality or I might want to look at data that's",
    "start": "1179990",
    "end": "1185630"
  },
  {
    "text": "historical data what I don't want to pay to have all of that sitting in the warehouse so what we've introduced is",
    "start": "1185630",
    "end": "1191180"
  },
  {
    "text": "something called spectrum which is kind of like cold it's a cold tier for your data warehouse and what this means is",
    "start": "1191180",
    "end": "1197450"
  },
  {
    "text": "that a person who's issuing one of these dimensional queries to say hey can you show me all my trends over time",
    "start": "1197450",
    "end": "1204020"
  },
  {
    "text": "they would get they don't have to write multiple queries it goes into the warehouse the warehouse runs it says oh",
    "start": "1204020",
    "end": "1209750"
  },
  {
    "text": "I've got six months that's hot and the rest of it that's aged out in the data warehouse I can now just pull and run",
    "start": "1209750",
    "end": "1215510"
  },
  {
    "text": "the query and there's a little bit of a performance hit but the benefit is you can store as much as you want historical",
    "start": "1215510",
    "end": "1221240"
  },
  {
    "text": "data and s3 is essentially unlimited and all you're paying is storage costs until",
    "start": "1221240",
    "end": "1226490"
  },
  {
    "text": "the moment you query and you pay for query execution time it's a totally shreds the the model on how much you're",
    "start": "1226490",
    "end": "1232490"
  },
  {
    "text": "paying for data that is kind of dark or data that you don't normally query so again just optimization models that a",
    "start": "1232490",
    "end": "1238550"
  },
  {
    "text": "data like opens up if you're running running a data warehouse and this is how Cisco Cisco if you're not familiar with",
    "start": "1238550",
    "end": "1244760"
  },
  {
    "start": "1241000",
    "end": "1293000"
  },
  {
    "text": "them they're kind of one of the these huge companies that sits behind the scenes they're one of the largest food distributors for aircraft so if you see",
    "start": "1244760",
    "end": "1252500"
  },
  {
    "text": "like the sky chefs trucks that go in his stock planes these are the people who bring them the food food into hospitals",
    "start": "1252500",
    "end": "1258020"
  },
  {
    "text": "food into number of different industries so cisco is looking at food distribution essentially so they pull data out of a",
    "start": "1258020",
    "end": "1264950"
  },
  {
    "text": "s400 so they've got all sorts of legacy infrastructure so it comes out of those",
    "start": "1264950",
    "end": "1270050"
  },
  {
    "text": "systems pulls into that staging layer goes through some ETL they've choose to",
    "start": "1270050",
    "end": "1276560"
  },
  {
    "text": "use redshift to do some of the data processing just because it operates great at scale moving into a data like",
    "start": "1276560",
    "end": "1282680"
  },
  {
    "text": "and it's consumed by redshift for doing these very very large historical data queries so again just just sort of an",
    "start": "1282680",
    "end": "1289610"
  },
  {
    "text": "example of how these services tend to stitch together in a pretty recognizable pattern now I mentioned before that",
    "start": "1289610",
    "end": "1296090"
  },
  {
    "start": "1293000",
    "end": "1338000"
  },
  {
    "text": "you've got dimensional queries which is I know what I want to ask before I load the data like I wanted to ask about my",
    "start": "1296090",
    "end": "1302870"
  },
  {
    "text": "customers my suppliers I want to look at some demand forecasts but sometimes I'm getting log files and I don't have a",
    "start": "1302870",
    "end": "1309320"
  },
  {
    "text": "schema I don't have preset questions that I know I want to ask I want to explore that data so direct query tools",
    "start": "1309320",
    "end": "1316370"
  },
  {
    "text": "something like Amazon Athena that data just lives in a columnar format sitting",
    "start": "1316370",
    "end": "1321410"
  },
  {
    "text": "in the data lake and you can come and just ask it a question so it's been registered in that meta store and the",
    "start": "1321410",
    "end": "1326450"
  },
  {
    "text": "those catalogs Athena comes in says what are all my available data sources come in and query that directly and you can",
    "start": "1326450",
    "end": "1333020"
  },
  {
    "text": "do exploration without having to load data and without having to pay for a cluster so how does this kind of all stitch",
    "start": "1333020",
    "end": "1340370"
  },
  {
    "start": "1338000",
    "end": "1744000"
  },
  {
    "text": "together so we have the we still have the same lady the data analyst is sitting on the ride and maybe we'll say",
    "start": "1340370",
    "end": "1345980"
  },
  {
    "text": "that she's a financial analyst so she's she's got some sequel sequel skills and she uses tableau typically data sources",
    "start": "1345980",
    "end": "1352580"
  },
  {
    "text": "will live in some sort of transactional ERP system so let's say in this case you've got maybe Oracle sitting",
    "start": "1352580",
    "end": "1357590"
  },
  {
    "text": "financials and you've got an SI p r3 system we have a number of different",
    "start": "1357590",
    "end": "1363110"
  },
  {
    "text": "ways to import that data into the cloud and this is just very simple example but there's many many of those you can kind",
    "start": "1363110",
    "end": "1369050"
  },
  {
    "text": "of bring whatever you want we have 2900 products that are sitting in our marketplace you probably find one that",
    "start": "1369050",
    "end": "1374120"
  },
  {
    "text": "will help you export from whatever data source you have in this case we look at maybe the Oracle data pump that's fine",
    "start": "1374120",
    "end": "1380270"
  },
  {
    "text": "we can use that to move data from Oracle into s3 a common pattern or maybe coming out of our three our three is sort of",
    "start": "1380270",
    "end": "1386810"
  },
  {
    "text": "notorious for having all sorts of crazy tables with German names and it's super hard to decipher so bright one of our",
    "start": "1386810",
    "end": "1392630"
  },
  {
    "text": "technology partners is has worked on fixing that problem so to be able to do a sensible extract data out of our three",
    "start": "1392630",
    "end": "1398390"
  },
  {
    "text": "into s3 so again just sort of picking a couple tools to pull that in it lands into a landing zone and then it gets",
    "start": "1398390",
    "end": "1406040"
  },
  {
    "text": "loaded into the data Lake now we've already looked at what that data pipeline looks like on the double-click so this is just a simplified view of",
    "start": "1406040",
    "end": "1412430"
  },
  {
    "text": "that at which point she has the questions she knows that would be",
    "start": "1412430",
    "end": "1417800"
  },
  {
    "text": "answered on a monthly basis which are her dashboards and she might use tableau to access those she might then use",
    "start": "1417800",
    "end": "1425270"
  },
  {
    "text": "tableau also to go to Athena for data exploration so without the users having",
    "start": "1425270",
    "end": "1430970"
  },
  {
    "text": "to change their tools they're able to just issue queries down against the underlying services in the most suitable",
    "start": "1430970",
    "end": "1437120"
  },
  {
    "text": "way to access the data like now let's look at a different user let's say we have that's fine for a financial analyst",
    "start": "1437120",
    "end": "1443870"
  },
  {
    "text": "but maybe we've got a business user who doesn't write any sequel doesn't have any sort of a knowledge of that sort of",
    "start": "1443870",
    "end": "1449990"
  },
  {
    "text": "data structure you might look in the data lake and he's saying okay well that's fine if I look at maybe customer",
    "start": "1449990",
    "end": "1455720"
  },
  {
    "text": "patterns that I've observed through transactions what if I pull in social media data where does that come from so",
    "start": "1455720",
    "end": "1461720"
  },
  {
    "text": "events streaming he first looks in the data Lake the transactional data I've kind of simplified that Oracle data",
    "start": "1461720",
    "end": "1467090"
  },
  {
    "text": "Pampas all but you have the batch data that loads across the top now if data and I haven't put all the icons up",
    "start": "1467090",
    "end": "1473600"
  },
  {
    "text": "here but if you're curious what that typically looks like is event data is fundamentally different streaming data",
    "start": "1473600",
    "end": "1478999"
  },
  {
    "text": "is different because it's not doesn't come in these nice sort of tables it's sometimes out of sequence and you have",
    "start": "1478999",
    "end": "1484399"
  },
  {
    "text": "to build windows and make sure that you've captured a full event before it gets loaded for analysis so it's a",
    "start": "1484399",
    "end": "1489769"
  },
  {
    "text": "little bit of nuance so typically they'll run Kinesis streams to capture that data they may even run a very very",
    "start": "1489769",
    "end": "1495679"
  },
  {
    "text": "small for node spark cluster and use the Scala libraries to do some of that data windowing but essentially pac at that",
    "start": "1495679",
    "end": "1502610"
  },
  {
    "text": "and then move it up to the data processing layer now he may use again a data warehouse for running his reports",
    "start": "1502610",
    "end": "1510259"
  },
  {
    "text": "out through say quick site or he might use Cabana using on the back side using a elasticsearch if he's looking at",
    "start": "1510259",
    "end": "1516320"
  },
  {
    "text": "understanding stream data or looking at events that are that are in flight so",
    "start": "1516320",
    "end": "1522139"
  },
  {
    "text": "I'll simplify that one more time so you all kind of know there's some icons underneath I just want to drown you with it so we're just gonna simplify",
    "start": "1522139",
    "end": "1528049"
  },
  {
    "text": "essentially the architecture tends to look like batch data and event data at some point rolls up and gets put into a",
    "start": "1528049",
    "end": "1535070"
  },
  {
    "text": "data link however here's the reality that's fine if you're just saying",
    "start": "1535070",
    "end": "1540409"
  },
  {
    "text": "loading data for reporting but what if you want to load data you say before I just make a data swamp of capturing the",
    "start": "1540409",
    "end": "1548090"
  },
  {
    "text": "entire Twitter universe and storing that my data Lake which is crazy and sometimes people will have an idea that",
    "start": "1548090",
    "end": "1554600"
  },
  {
    "text": "we need to capture all the data actually a better pattern is when you start to sample new data sources and your data",
    "start": "1554600",
    "end": "1561679"
  },
  {
    "text": "scientists need to build models we create a layer in between it's called a sandbox and so sand boxes are again",
    "start": "1561679",
    "end": "1569029"
  },
  {
    "text": "there it's a data status store where new data that's coming in can be tested",
    "start": "1569029",
    "end": "1574100"
  },
  {
    "text": "hypotheses can be tested is there a correlation between when somebody pauses",
    "start": "1574100",
    "end": "1579169"
  },
  {
    "text": "a video and they come back three minutes later and they're moved like I don't know I want to test that I want to run some data science against that I want to",
    "start": "1579169",
    "end": "1586399"
  },
  {
    "text": "be able to run different sort of analytic models against that so it gets stored into the into the sandbox the",
    "start": "1586399",
    "end": "1592519"
  },
  {
    "text": "data scientist is then able to use tools like whether it's spark ml whether they",
    "start": "1592519",
    "end": "1598340"
  },
  {
    "text": "using sage maker you are SAS whatever it is that you're your tool of choice runs",
    "start": "1598340",
    "end": "1603440"
  },
  {
    "text": "against that sandbox and it's good and models that have some weight some significance are created the",
    "start": "1603440",
    "end": "1610250"
  },
  {
    "text": "output data sets not all the raw data the output data sets are published to",
    "start": "1610250",
    "end": "1615590"
  },
  {
    "text": "the data lake it's a very different model than sometimes where people say capture everything store everything and",
    "start": "1615590",
    "end": "1622280"
  },
  {
    "text": "then you hope that there's value in it using that sandbox to say vet the data only publish the score datasets and then",
    "start": "1622280",
    "end": "1629720"
  },
  {
    "text": "only the source data that had that business relevance that's what publishes to the data lake this strategy is what helps companies",
    "start": "1629720",
    "end": "1636950"
  },
  {
    "text": "not end up with these massive stores of stuff that has no that's useless basically to the business so again this",
    "start": "1636950",
    "end": "1643220"
  },
  {
    "text": "sort of vetting and publishing process simplify it one more time we'll just call that the ML analytics layer and",
    "start": "1643220",
    "end": "1649160"
  },
  {
    "text": "this is just kind of simplified view of that now you want to use AI services",
    "start": "1649160",
    "end": "1654800"
  },
  {
    "text": "that are really cool like there's all sorts of stuff that that we've invested in and bringing to market around language services and vision services",
    "start": "1654800",
    "end": "1661580"
  },
  {
    "text": "and so on now on the event layer initially that data scientist has built",
    "start": "1661580",
    "end": "1667430"
  },
  {
    "text": "something not just scored data sets but they build something called predictive models and a predictive model can be",
    "start": "1667430",
    "end": "1673070"
  },
  {
    "text": "published in either say a PMML format or if it's neural networks that might be owned in an X but essentially they take",
    "start": "1673070",
    "end": "1679760"
  },
  {
    "text": "that model and they move it down into a layer that is it's responding to events so an event will happen now the event",
    "start": "1679760",
    "end": "1687140"
  },
  {
    "text": "continues to be captured to look at patterns over time but then there's a response to it there's a little lambda trigger that pushes it up to a scoring",
    "start": "1687140",
    "end": "1693770"
  },
  {
    "text": "engine scoring engine says based on this should I give that person a leaderboard or should I give that person something",
    "start": "1693770",
    "end": "1699920"
  },
  {
    "text": "else like maybe a social response and then there's another little lambda trigger that says now that I have that",
    "start": "1699920",
    "end": "1705590"
  },
  {
    "text": "answer I go down to the action layer now when you're integrating with your systems let's say that you're in ad tech",
    "start": "1705590",
    "end": "1711500"
  },
  {
    "text": "or gaming or something that's you're running mobile apps and you need very fast response you'll publish it out to a",
    "start": "1711500",
    "end": "1717230"
  },
  {
    "text": "no sequel data source like DynamoDB and then the app pulls that that's tends to",
    "start": "1717230",
    "end": "1722360"
  },
  {
    "text": "be a really low latency pattern or maybe you've got a queuing system and you just need soon as you get a response you fire",
    "start": "1722360",
    "end": "1728240"
  },
  {
    "text": "that out through through sqs or something like that so again there's a few different connectors that sit on the",
    "start": "1728240",
    "end": "1733370"
  },
  {
    "text": "sides but if you kind of want to peel the covers back and look at how our big best customer",
    "start": "1733370",
    "end": "1738830"
  },
  {
    "text": "pattern the use of data lakes within a bigger architecture it tends to look like this so I'm gonna close up in just",
    "start": "1738830",
    "end": "1746899"
  },
  {
    "text": "a minute but what I want to leave you with is you don't have to sort of build all of this on your own from scratch",
    "start": "1746899",
    "end": "1752299"
  },
  {
    "text": "because there's a little bit of nuance underneath and how you build access controls and how you put together some",
    "start": "1752299",
    "end": "1758659"
  },
  {
    "text": "of the searching and cataloging features so what we've released a market is something called a solution builder and",
    "start": "1758659",
    "end": "1763880"
  },
  {
    "text": "you can either write down that link or easier it's kind of the easier one is you can just search for that title on",
    "start": "1763880",
    "end": "1769789"
  },
  {
    "text": "the web and know it'll pull up so look for AWS data Lakes and what you'll download is a set of cloud formation",
    "start": "1769789",
    "end": "1776299"
  },
  {
    "text": "templates which you run inside of your account and then that will just get the initial framework set up for you you can",
    "start": "1776299",
    "end": "1782960"
  },
  {
    "text": "take that and you can test it tweak it see if that's a good starting point for you and in a minimum you can look and",
    "start": "1782960",
    "end": "1788990"
  },
  {
    "text": "see how we've seen that as a best pad best practice and then you can choose to learn from those patterns so what I",
    "start": "1788990",
    "end": "1799100"
  },
  {
    "start": "1795000",
    "end": "1898000"
  },
  {
    "text": "recommend for getting started and this is just my own experience of having worked with with customers across a",
    "start": "1799100",
    "end": "1804950"
  },
  {
    "text": "number of our regions step away for a little bit just sort of step back from",
    "start": "1804950",
    "end": "1810200"
  },
  {
    "text": "this idea that the way that you succeed with the data like is capturing everything and then question mark",
    "start": "1810200",
    "end": "1815480"
  },
  {
    "text": "question mark profit just just step back from that for a minute what we see is a more successful pattern is shortlist a",
    "start": "1815480",
    "end": "1822260"
  },
  {
    "text": "set of projects and specifically projects that have some sort of baseline metric for how your customers love your",
    "start": "1822260",
    "end": "1829279"
  },
  {
    "text": "product or service how they respond some sort of baseline Abul metric because then when you load that first set of",
    "start": "1829279",
    "end": "1836389"
  },
  {
    "text": "data through a pipeline and you load that first bit into your data warehouse or into starting to the data Lake you",
    "start": "1836389",
    "end": "1841970"
  },
  {
    "text": "can test you make a change to your operations and you can test and see is this affecting my customer response is",
    "start": "1841970",
    "end": "1849200"
  },
  {
    "text": "it giving a better customer experience the reason I recommend that is those projects ripple really well through the",
    "start": "1849200",
    "end": "1855679"
  },
  {
    "text": "business because they matter to the business so starting with a short list of projects and then incrementally build",
    "start": "1855679",
    "end": "1861200"
  },
  {
    "text": "your data lake as opposed to starting with a big bang second is data pipelines will probably be new for people again if",
    "start": "1861200",
    "end": "1868520"
  },
  {
    "text": "you start small it gives you a chance to learn at a small scale before you start to move up to bigger and bigger more complex",
    "start": "1868520",
    "end": "1874429"
  },
  {
    "text": "challenges and the third is we invest a whole lot in a resources for you like we",
    "start": "1874429",
    "end": "1879929"
  },
  {
    "text": "have solution architects so you can talk to your account manager this is the person who comes in as sanity checks as you're building your design the essay",
    "start": "1879929",
    "end": "1886470"
  },
  {
    "text": "can come and say okay that's a good pattern or I don't know why you're doing it that way but you can have a good adult",
    "start": "1886470",
    "end": "1891539"
  },
  {
    "text": "conversation with them if you need hands on keyboard we have partners and we have professional services to help you with",
    "start": "1891539",
    "end": "1897000"
  },
  {
    "text": "Hansel in keyboard so with that I want to thank you and I do want to invite to stage to share with us mr. Pradesh Kelly",
    "start": "1897000",
    "end": "1905279"
  },
  {
    "start": "1898000",
    "end": "1923000"
  },
  {
    "text": "who is the head of big data in IOT analytics as part of group data analytics L is with Aditya Birla Group",
    "start": "1905279",
    "end": "1912090"
  },
  {
    "text": "and he's going to share with you their journey on how they have been building data Lakes so with that I want to thank",
    "start": "1912090",
    "end": "1917730"
  },
  {
    "text": "you very much I hope you guys have an awesome conference thanks",
    "start": "1917730",
    "end": "1922518"
  }
]
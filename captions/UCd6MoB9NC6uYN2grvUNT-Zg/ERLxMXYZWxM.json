[
  {
    "text": "thanks for coming in today my name is Matt and kitchen I've been talking about big data at AWS for many years now I've",
    "start": "6589",
    "end": "12990"
  },
  {
    "text": "been with AWS for almost four years and today we're going to follow on what we were talking about earlier with a",
    "start": "12990",
    "end": "19070"
  },
  {
    "text": "conversation about streaming data and a deep dive into Kinesis the point of this is that let's set let's level set what",
    "start": "19070",
    "end": "25560"
  },
  {
    "text": "is streaming data mean what type of data are we actually talking about generally speaking these days it means some kind",
    "start": "25560",
    "end": "31289"
  },
  {
    "text": "of messy JSON today we're talking about streaming data which is typically like information logs and in this case you",
    "start": "31289",
    "end": "37200"
  },
  {
    "text": "could have a metering record MQTT which is a way of writing data in a protocol",
    "start": "37200",
    "end": "43230"
  },
  {
    "text": "associated with it that is more lightweight that is used in a lot of IOT devices like our AWS IOT service most",
    "start": "43230",
    "end": "48960"
  },
  {
    "text": "commonly probably sis logs or common log entries that's a an Apache log right",
    "start": "48960",
    "end": "54480"
  },
  {
    "text": "there following the standard Apache log format this is a syslog like a Linux UNIX to syslog what I'm seeing a lot of",
    "start": "54480",
    "end": "60570"
  },
  {
    "text": "I work with large software partners I'm seeing a lot of oil and gas firms now manufacturing firms both in an IOT",
    "start": "60570",
    "end": "66540"
  },
  {
    "text": "context and just they have sort of smart pipes and stuff in the oil industry if you think of your home electrical meter",
    "start": "66540",
    "end": "73229"
  },
  {
    "text": "these smart meters these smart meters are not because the electrical companies actually love you it's because they're",
    "start": "73229",
    "end": "78420"
  },
  {
    "text": "getting massive subsidies and those subsidies are contingent on rolling out smart meters to the American household so the smart meters is one we're seeing",
    "start": "78420",
    "end": "86490"
  },
  {
    "text": "a lot of streaming data increasingly we have connected devices in our hands and our houses on our pipelines everywhere",
    "start": "86490",
    "end": "92369"
  },
  {
    "text": "and you need some way to collect that data and what was a few megabytes or kilobytes or even gigabytes a year or",
    "start": "92369",
    "end": "98700"
  },
  {
    "text": "two ago is now suddenly petabytes and it's actually a real fun and hard problem in terms of how you collect that",
    "start": "98700",
    "end": "105540"
  },
  {
    "text": "data at scale and how you do it in such a way that when your business blows up when you're like a sonos for example a successful company and suddenly",
    "start": "105540",
    "end": "111360"
  },
  {
    "text": "everyone's buying your stuff and you're a little company how do you do an architecture that you don't have to redo in 6 months when your product blows up",
    "start": "111360",
    "end": "117719"
  },
  {
    "text": "such that you can handle that inbound scale and also process at scale without blowing the bank we saji and I and",
    "start": "117719",
    "end": "123840"
  },
  {
    "text": "others work with a lot of companies who are kind of victims of their own success they have all this data flowing in or",
    "start": "123840",
    "end": "128849"
  },
  {
    "text": "they've acquired a company that has a massive trove of data sitting on in the case of one company in",
    "start": "128849",
    "end": "134329"
  },
  {
    "text": "Connecticut sitting in containers on their front yard and they're literally out of grass to hold it containers with the tapes and they don't know how to",
    "start": "134329",
    "end": "140180"
  },
  {
    "text": "handle that that's static data let alone all the streaming data coming in at them so here's some industry use cases some of the stuff I was just talking about",
    "start": "140180",
    "end": "145909"
  },
  {
    "text": "seeing a lot of sensor stuff also just clickstream data even if you're a web designer if anyone's in a graphic design",
    "start": "145909",
    "end": "152180"
  },
  {
    "text": "or web you'll know that the days of kind of you know boring static websites are over and the days of having just a",
    "start": "152180",
    "end": "158540"
  },
  {
    "text": "simple bug are over to you're now doing advanced telemetry I'll give you a specific example you can actually sell",
    "start": "158540",
    "end": "163700"
  },
  {
    "text": "ad space on more best advanced web sites based on where people are swiping or clicking or where their mouths are and",
    "start": "163700",
    "end": "169549"
  },
  {
    "text": "there's whole companies that have built their business on sort of that type of telemetry where are the hot spots on a mobile app where the hot spots on a",
    "start": "169549",
    "end": "176000"
  },
  {
    "text": "website you can actually sell ads in real time at higher rates which fluctuates depending on how people are using the mobile app or the website",
    "start": "176000",
    "end": "182090"
  },
  {
    "text": "that's a lot of streaming data that's just not a little transparent pics on the top right that's a lot of advanced sort of JavaScript that's pumping data",
    "start": "182090",
    "end": "188750"
  },
  {
    "text": "somewhere and it has to go into a back-end system and you have to be able to process it quickly so that you can",
    "start": "188750",
    "end": "193819"
  },
  {
    "text": "sell that ad in time to still capture the user while they're engaging with your app or your website increasingly",
    "start": "193819",
    "end": "200000"
  },
  {
    "text": "advertising on the streets we work with a company now called intersection used to be called control group you may know them from the the New York City phone",
    "start": "200000",
    "end": "208280"
  },
  {
    "text": "booths they've converted into high-speed wireless internet that we can profit from now they also do kind of smart advertising so we're seeing this across",
    "start": "208280",
    "end": "215030"
  },
  {
    "text": "many different industries many different applications it's not just limited to kind of log processing but that's how",
    "start": "215030",
    "end": "221479"
  },
  {
    "text": "most of us starting quite frankly that's like the bulk of the work we're doing we talked about a few different use cases how does that map kind of on a high",
    "start": "221479",
    "end": "227150"
  },
  {
    "text": "level more often though it comes down to alerting you know if any of you are in operations and DevOps and you have",
    "start": "227150",
    "end": "233199"
  },
  {
    "text": "telemetry really now in your applications where you have alerts happening based on data feeding into",
    "start": "233199",
    "end": "239239"
  },
  {
    "text": "state cloud watch cloud watch is a good streaming data application or we have our friends from cloud checker like anything that's sort of monitoring the",
    "start": "239239",
    "end": "245449"
  },
  {
    "text": "state of your infrastructure of your costs spend of how things are going and taking actions accordingly as processing streaming data and then there's micro",
    "start": "245449",
    "end": "251900"
  },
  {
    "text": "batching and this is something that we're still sort of seeing emerging but increasingly now big data analytics into",
    "start": "251900",
    "end": "260180"
  },
  {
    "text": "talking the analytics is more about streaming data than it is about batch processing and it's sort of a lie to say",
    "start": "260180",
    "end": "265849"
  },
  {
    "text": "streaming what it really is micro batching like if you think of you think of most people doing streaming video analytics they're",
    "start": "265849",
    "end": "271750"
  },
  {
    "text": "actually chopping the data into little discrete pieces and micro batching because it's inefficient for example if",
    "start": "271750",
    "end": "276849"
  },
  {
    "text": "you have a less than one kilobyte JSON record right it would be inefficient to",
    "start": "276849",
    "end": "282060"
  },
  {
    "text": "to do date big data processing over that it's much more efficient to compress a",
    "start": "282060",
    "end": "287110"
  },
  {
    "text": "bunch of those together and have little chunks and then store them on say as three and then iterate against them and",
    "start": "287110",
    "end": "292449"
  },
  {
    "text": "do real time streaming so the efficiencies you get in scale and architecture are much better than the reverse when you have to allocate say a",
    "start": "292449",
    "end": "300099"
  },
  {
    "text": "worker in Hadoop cluster to every single tiny little JSON piece so that's what micro batching is is aggregating",
    "start": "300099",
    "end": "306370"
  },
  {
    "text": "collections of little teeny tiny bits of data so that you can operate on them and it looks like streaming but it's",
    "start": "306370",
    "end": "311470"
  },
  {
    "text": "actually little micro batches in fact spark is a good example of something sparks streaming that uses that approach",
    "start": "311470",
    "end": "316720"
  },
  {
    "text": "so let's jump right in to do some architectures and I'll pull back from this in a second and go through the different components and and focus on",
    "start": "316720",
    "end": "323229"
  },
  {
    "text": "Kinesis here's a really sort of everyday streaming use case it's hilarious because this is now like every day",
    "start": "323229",
    "end": "328419"
  },
  {
    "text": "whereas two years ago people have been like oh my god yeah whereas this is now pretty no I wouldn't say run-of-the-mill",
    "start": "328419",
    "end": "333580"
  },
  {
    "text": "because it's not like every company is doing streaming data processing but this is much much much more common so here we",
    "start": "333580",
    "end": "339669"
  },
  {
    "text": "have some kind of a red web front-end the easiest way to deploy a web app other than the server list way the saj you just described which is my",
    "start": "339669",
    "end": "345610"
  },
  {
    "text": "preference is to throw your war up on elastic Beanstalk and have us handle the scaling and the rest and then it's",
    "start": "345610",
    "end": "352419"
  },
  {
    "text": "pushing data into Kinesis streams which we're going to focus on today and you can think of Kinesis really just like a giant queue but it's different from SQS",
    "start": "352419",
    "end": "360190"
  },
  {
    "text": "and its really designed for handling streaming data rather than just arbitrary sort of chunks of data that",
    "start": "360190",
    "end": "366069"
  },
  {
    "text": "you'll pick up in a sort of a typical q use case it's more for streaming data processing and then from Kinesis streams",
    "start": "366069",
    "end": "372219"
  },
  {
    "text": "expressed in Hadoop in the artist or in this case spark so running elastic MapReduce EMR and we're running spark",
    "start": "372219",
    "end": "378009"
  },
  {
    "text": "streaming on Hadoop going from here to here we're going to talk actually about a couple ways to get it from the front",
    "start": "378009",
    "end": "384159"
  },
  {
    "text": "end two streams but we're gonna there's you can use things like log4j I use like",
    "start": "384159",
    "end": "389229"
  },
  {
    "text": "a Kinesis sort of a where log4j pusher you can use the kpl and write your own application there's a lot of ways to get",
    "start": "389229",
    "end": "394330"
  },
  {
    "text": "stuff into Kinesis increasingly third parties or our Kinesis aware sod you just talked about event based",
    "start": "394330",
    "end": "402790"
  },
  {
    "text": "server lyst computing well this paradigm is actually applying to streaming data too it's no longer good enough to say as",
    "start": "402790",
    "end": "408920"
  },
  {
    "text": "streaming data comes in kind of have a constantly running data processing layer sometimes that's a inefficient you don't",
    "start": "408920",
    "end": "415970"
  },
  {
    "text": "want to pay for say EMR all the time what if you only care about data when",
    "start": "415970",
    "end": "421010"
  },
  {
    "text": "it's interesting to you for that particular use case for example if you're writing a security application",
    "start": "421010",
    "end": "426260"
  },
  {
    "text": "you might have some basic checks that indicate that this might be a security",
    "start": "426260",
    "end": "431960"
  },
  {
    "text": "threat you don't want to act on every single log entry coming through and do sort of deep analysis you want to reserve the deep analysis for something",
    "start": "431960",
    "end": "438170"
  },
  {
    "text": "that has a higher likelihood of being a problem so this is where you could use a lambda function and you can actually",
    "start": "438170",
    "end": "443810"
  },
  {
    "text": "have Kinesis and Kinesis streams and the events associated with them due to sort of fire on different conditions think of",
    "start": "443810",
    "end": "451400"
  },
  {
    "text": "our i OT service or if you're familiar with this if a certain condition is met then you can process the iot data coming",
    "start": "451400",
    "end": "457940"
  },
  {
    "text": "in you don't want to process all of the data coming from all those sensors all the time so selective processing and processing it when needed with lambda is",
    "start": "457940",
    "end": "465620"
  },
  {
    "text": "really really important this is here what we're actually describing that was using lambda to trigger a push into s3",
    "start": "465620",
    "end": "472780"
  },
  {
    "text": "using fire hose so streaming sparks streaming to some kind of data transformation often data comes in from",
    "start": "472780",
    "end": "479480"
  },
  {
    "text": "a lot of different sources you bought that company the uses that other web server to use a simple example has a different log format then your log",
    "start": "479480",
    "end": "486320"
  },
  {
    "text": "processing analytics engine breaks so rather than write a crazy filter for the new log format you can have spark",
    "start": "486320",
    "end": "492740"
  },
  {
    "text": "streaming normalize the data and put it all in some kind of a common format an s3 in a way that red shift doesn't barf",
    "start": "492740",
    "end": "498530"
  },
  {
    "text": "all over it we know that schemas change all the time so I'd you just talk to you about no sequel and the flexibility of",
    "start": "498530",
    "end": "504050"
  },
  {
    "text": "not having sort of rigid schemas and that's where real-time data streaming data processing data normalization comes",
    "start": "504050",
    "end": "510020"
  },
  {
    "text": "in really really handy you can take any stream from any disparate source normalize it here using Hadoop at scale",
    "start": "510020",
    "end": "516110"
  },
  {
    "text": "and then dump it into s3 for processing there's a lot of pieces here to",
    "start": "516110",
    "end": "521630"
  },
  {
    "text": "coordinate so data pipeline you can think of it kind of like cron as a service and your data coordinator it can",
    "start": "521630",
    "end": "528370"
  },
  {
    "text": "kick off different parts of this architecture at different times according different conditions or even on a",
    "start": "528370",
    "end": "533630"
  },
  {
    "text": "schedule so for example if you have some kind of streaming data coming in from different log sources and it hits",
    "start": "533630",
    "end": "539540"
  },
  {
    "text": "Kinesis streams and then you use a dupe to normalize that data so all the data is relatively similarly structured you",
    "start": "539540",
    "end": "545750"
  },
  {
    "text": "then dump it into s3 and load it in a redshift you can have data pipeline kick off that loads a nightly or hourly from",
    "start": "545750",
    "end": "552980"
  },
  {
    "text": "s 3 inch red shift on a regular basis and then of course these the analysis part we're not going to cover all this architectures today but none of this",
    "start": "552980",
    "end": "559610"
  },
  {
    "text": "would be useful without someone looking at it or a human or a computer or some kind of algorithm deriving data or story",
    "start": "559610",
    "end": "566780"
  },
  {
    "text": "value from your data and that's I think the part that a lot of us nerds forget about is we get all wrapped up and spark",
    "start": "566780",
    "end": "571820"
  },
  {
    "text": "and all this exciting stuff like Kinesis we forget that we're working for a company that has a business and I know I",
    "start": "571820",
    "end": "577550"
  },
  {
    "text": "forget that a lot and this part is actually the most important part is how do you derive value ultimately from the",
    "start": "577550",
    "end": "583430"
  },
  {
    "text": "data what are you really doing here are you doing threat analytics to prevent nasty people from doing nasty stuff on",
    "start": "583430",
    "end": "589460"
  },
  {
    "text": "your infrastructure are you looking for some kind of new insight into your customers behavior so you can sell new products are you looking the case",
    "start": "589460",
    "end": "596510"
  },
  {
    "text": "earlier for a certain behavior that would cause you to sell a certain type of AD on that particular platform to that user at that very moment so this",
    "start": "596510",
    "end": "603200"
  },
  {
    "text": "part is really important to be able to analyze both in an exploratory function when you don't know what you're looking for and in a reactive function that",
    "start": "603200",
    "end": "610400"
  },
  {
    "text": "you've already predefined such as serving the right kind of add to the right person and that difference between exploratory analysis and sort of",
    "start": "610400",
    "end": "617300"
  },
  {
    "text": "pre-programmed analysis is super important and I'll get into that later and it's one of the awesome things about",
    "start": "617300",
    "end": "622550"
  },
  {
    "text": "having this kind of decoupled architecture because often you don't know what you're looking for and people",
    "start": "622550",
    "end": "627890"
  },
  {
    "text": "forget this sometimes they load their data into a giant Oracle database or under redshift and they forget then they have to write these huge complex queries",
    "start": "627890",
    "end": "634370"
  },
  {
    "text": "and it turns out that that's actually really hard and the people in the white lab coats who come up with these giant queries are very expensive and you need",
    "start": "634370",
    "end": "641030"
  },
  {
    "text": "to have very easy ways to allow normal mortals to explore your data when it's crazy in a bunch of different schemas",
    "start": "641030",
    "end": "646760"
  },
  {
    "text": "and this is where this piece plus this comes in handy here's another one we talked about micro batching so same",
    "start": "646760",
    "end": "652340"
  },
  {
    "text": "thing we have some clients with a web front-end on elastic Beanstalk this time we're using Kinesis fire hose which is a",
    "start": "652340",
    "end": "659570"
  },
  {
    "text": "framework that really to boil it down makes it easier to get your Kinesis data into somewhere else",
    "start": "659570",
    "end": "665279"
  },
  {
    "text": "the most common use case is you can push to fire hose and it auto automatically",
    "start": "665279",
    "end": "670529"
  },
  {
    "text": "micro batches and compresses your data into little chunks and then pushes them forward them to s3 for you if you were",
    "start": "670529",
    "end": "676499"
  },
  {
    "text": "to do that yourself think about it you'd have to write some kind of an application that would take all those little log snippet so those little teeny",
    "start": "676499",
    "end": "681990"
  },
  {
    "text": "json or xml snippets and then buffer them and if you're buffering them you need somewhere to store them temporarily",
    "start": "681990",
    "end": "687839"
  },
  {
    "text": "so that's a risk because what if you lose that buffer in midstream then you've lost that data so that because then you have to have high availability",
    "start": "687839",
    "end": "693930"
  },
  {
    "text": "of the buffering layer and then you need somebody to compress it that's CPU time which means you have to pay for CPU time",
    "start": "693930",
    "end": "699089"
  },
  {
    "text": "and then you need something that can understand how to push to s3 what if you get like throttling because you're pushing to s3 too much or you haven't",
    "start": "699089",
    "end": "705870"
  },
  {
    "text": "done your keys properly there's all these things that can happen at scale everyone's like oh yeah I wrote this",
    "start": "705870",
    "end": "711059"
  },
  {
    "text": "thing to push the Knesset's it's four lines of Python great but what happens when that box with the four lines of",
    "start": "711059",
    "end": "716160"
  },
  {
    "text": "Python falls over or when you're pushing five terabytes per second to s3 suddenly",
    "start": "716160",
    "end": "721529"
  },
  {
    "text": "doesn't work so well so firehose kind of solves all those problems it handles all that hard stuff for you it's kind of",
    "start": "721529",
    "end": "727259"
  },
  {
    "text": "classic Amazon we always say undifferentiated heavy lifting firehose makes pushing stuff into s3 and",
    "start": "727259",
    "end": "733040"
  },
  {
    "text": "leveraging Kinesis without you having really to think about it super easy so it's kind of Kinesis without all the fun",
    "start": "733040",
    "end": "739139"
  },
  {
    "text": "but with making a lot easier so that's really what the fire hose is handling the micro bashing the compression the",
    "start": "739139",
    "end": "744899"
  },
  {
    "text": "all the other stuff behind the scenes such that you can get nice little G zips or whatever it has three that you can",
    "start": "744899",
    "end": "750569"
  },
  {
    "text": "nicely load into redshift so let's talk about some real customers before we dive in so here's a glue mobile with some",
    "start": "750569",
    "end": "756389"
  },
  {
    "text": "suspect games good customer for us how many of your deer hunter fans so",
    "start": "756389",
    "end": "761879"
  },
  {
    "text": "telemetry and games is it was a really obvious use case we're seeing this more more as games get bigger like literally",
    "start": "761879",
    "end": "767490"
  },
  {
    "text": "when you're wondering on these worlds and especially hard to keep track of what different users are doing in different parts of these virtual worlds",
    "start": "767490",
    "end": "773639"
  },
  {
    "text": "and maybe you have a game that sort of changes over time and so keeping track of not only how users use the games",
    "start": "773639",
    "end": "779459"
  },
  {
    "text": "themselves so you can improve on the features that are most popular or maybe pull back development on features that are not or identify bugs there's also",
    "start": "779459",
    "end": "787139"
  },
  {
    "text": "this whole concept of how do I invest more in two parts of like a giant virtual world that users are wandering",
    "start": "787139",
    "end": "792240"
  },
  {
    "text": "off into that I didn't really anticipate or maybe they're building crazy stuff and so telemetry in games in real time the idea of games becoming real",
    "start": "792240",
    "end": "798990"
  },
  {
    "text": "I'm in becoming giant world's is super super important it's not just about kind of debugging and feature development like it was even just a few years ago",
    "start": "798990",
    "end": "805230"
  },
  {
    "text": "even how users are interacting there's tons of data around usage of applications not just limited to games",
    "start": "805230",
    "end": "810930"
  },
  {
    "text": "but you see game gaming companies and other companies that are involved in illicit things often being the leading",
    "start": "810930",
    "end": "816930"
  },
  {
    "text": "edge for capturing user engagement and behavior you're going to start to see some really similar patterns so I know I",
    "start": "816930",
    "end": "823050"
  },
  {
    "text": "speak quickly but hopefully we repeat the same patterns enough times that you'll see that whether it's gaming or",
    "start": "823050",
    "end": "828450"
  },
  {
    "text": "oil and gas or you know your nest or whatever the patterns for aggregating",
    "start": "828450",
    "end": "834570"
  },
  {
    "text": "and processing the streaming data are very similar across many industries and use cases so in this case just like that",
    "start": "834570",
    "end": "840540"
  },
  {
    "text": "web front-end we had before you have you know the clients and we have 70 million",
    "start": "840540",
    "end": "845580"
  },
  {
    "text": "to two billion events per day good example the company that's done well and that that guy the summer interns Python",
    "start": "845580",
    "end": "851790"
  },
  {
    "text": "script from two years ago probably isn't working for them anymore so they had to move to a better model so in this case",
    "start": "851790",
    "end": "857370"
  },
  {
    "text": "they're using Kinesis which think of it like a cue to capture the inbound streaming data now they're using storm",
    "start": "857370",
    "end": "863220"
  },
  {
    "text": "instead of you know the Kinesis client library or in the other case spark",
    "start": "863220",
    "end": "868829"
  },
  {
    "text": "streaming these are all there's different ways of pulling data out of your queue out of Kinesis out of your",
    "start": "868829",
    "end": "874320"
  },
  {
    "text": "buffer and processing and modifying it which you choose is kind of up to your use case we don't have time to really",
    "start": "874320",
    "end": "880410"
  },
  {
    "text": "get into the pros and cons of spark streaming versus storm vs. Kinesis client library if you want have a side conversation I'm more than happy to all",
    "start": "880410",
    "end": "887040"
  },
  {
    "text": "I can tell you about storm is that Twitter's not using it anymore they kind of came up with it now they've announced",
    "start": "887040",
    "end": "892230"
  },
  {
    "text": "some other framework so storm is great for certain use cases we'll get into a separately but in this case they're",
    "start": "892230",
    "end": "898260"
  },
  {
    "text": "using a framework storm spark streaming Kinesis client library it could be anything which is running on some ec2",
    "start": "898260",
    "end": "903839"
  },
  {
    "text": "instances to to pull out data do some normalization and structures the data",
    "start": "903839",
    "end": "910589"
  },
  {
    "text": "such that it can be loaded into an RDS database in this case and they're using the Kinesis connectors which are a",
    "start": "910589",
    "end": "916440"
  },
  {
    "text": "series of libraries that allow you to connect Kinesis to other AWS services to connect to s3 and in this case then",
    "start": "916440",
    "end": "923339"
  },
  {
    "text": "they're batch loading into redshift now this is probably old this architecture I imagine it's evolved since now if you",
    "start": "923339",
    "end": "929160"
  },
  {
    "text": "remember the last slide they probably could have replaced this and this with kini his fire hose and they might not even",
    "start": "929160",
    "end": "934800"
  },
  {
    "text": "really need this so things evolved all the time but the general flow remains the same you know you have some kind of",
    "start": "934800",
    "end": "940920"
  },
  {
    "text": "like what we call a lamb dark sorry lambda architecture here we have sort of the cold data for long-term analysis",
    "start": "940920",
    "end": "947160"
  },
  {
    "text": "with tableau and the the hot data with a lightweight front end to sort of make real-time decisions on user behavior so",
    "start": "947160",
    "end": "954360"
  },
  {
    "text": "I mentioned sonos before so if you don't have a sonos yet they're overpriced but so worth it and they work well with the",
    "start": "954360",
    "end": "960510"
  },
  {
    "text": "your echo if you have one of those you just have to write a lambda function then it works fine so in this case a lot",
    "start": "960510",
    "end": "967290"
  },
  {
    "text": "of telemetry on your sonos it's an internet-connected speaker they need to know what version you're running maybe they want to know how you're using the",
    "start": "967290",
    "end": "973320"
  },
  {
    "text": "device whether you're using tunein radio more than sonos or whatever or sorry more than spotify what volume you have",
    "start": "973320",
    "end": "979230"
  },
  {
    "text": "it set on what your equalizer settings are if everyone has their base way up maybe the base on that appliance by",
    "start": "979230",
    "end": "985080"
  },
  {
    "text": "default is too low I mean this is actually really important decisions that can affect whether customers like your",
    "start": "985080",
    "end": "990450"
  },
  {
    "text": "product out of the box or not so they're doing a lot of sorts ulema tree and metrics and they need to push all that data somewhere so they push it too",
    "start": "990450",
    "end": "996950"
  },
  {
    "text": "kinesis so in this case they have a custom collector so think of it like",
    "start": "996950",
    "end": "1002120"
  },
  {
    "text": "just a back-end thing running on ec2 on AWS all these speakers ever in the world are pushing to these the scalable fleets",
    "start": "1002120",
    "end": "1008390"
  },
  {
    "text": "of ec2 servers running their proprietary software and then that's actually getting forwarded to Kinesis we'll get",
    "start": "1008390",
    "end": "1013700"
  },
  {
    "text": "into what this means in a second and they're using instead of storm in this case the or spark streaming they're",
    "start": "1013700",
    "end": "1019340"
  },
  {
    "text": "actually using our Kinesis client library which is no better or worse than any other frameworks it's just a way of getting your data out of Kinesis out of",
    "start": "1019340",
    "end": "1025939"
  },
  {
    "text": "your queue and they're pushing it to three terabytes of data s3 and then they're using sparks actually analyze",
    "start": "1025940",
    "end": "1032150"
  },
  {
    "text": "the data directly at s3 the cool thing here is there's no red shift remember saji was talking about serverless",
    "start": "1032150",
    "end": "1038660"
  },
  {
    "text": "websites well that's just the beginning of the story what about serverless or temporary server data and analysis or",
    "start": "1038660",
    "end": "1045829"
  },
  {
    "text": "you know I'm increasingly seeing people doing data warehouse workloads with no clusters we can get into that separately",
    "start": "1045829",
    "end": "1051350"
  },
  {
    "text": "but you can use sparks to talk directly to s3 and you can have your EMR cluster that you fire up every Sunday night",
    "start": "1051350",
    "end": "1057530"
  },
  {
    "text": "because when Monday the CFO wants their report on the desk you fire it up for one hour you read the data readout of s3",
    "start": "1057530",
    "end": "1062750"
  },
  {
    "text": "and then you shut down your cluster so you pay for one hour of EMR you as opposed to you know seven days a week",
    "start": "1062750",
    "end": "1068690"
  },
  {
    "text": "of reggie fuse that's from another talk though and then they're using all sorts different ways Splunk neo4j for a graph",
    "start": "1068690",
    "end": "1075170"
  },
  {
    "text": "database cabana to visualize it similar architecture you have kind of your your cold long store and you're you're hot or",
    "start": "1075170",
    "end": "1081680"
  },
  {
    "text": "faster data for a sort of real-time response like of a lot of slowness around the world or to use the french",
    "start": "1081680",
    "end": "1087500"
  },
  {
    "text": "crapping out then you probably want to raise a ticket and maybe there's a sev to happening a big alerts and you want",
    "start": "1087500",
    "end": "1093740"
  },
  {
    "text": "to your firmware upgrade you just pushed out wasn't highest build quality so that's where that hot day that comes in really handy but the longtail stuff like",
    "start": "1093740",
    "end": "1100610"
  },
  {
    "text": "hey what are people really doing with their equalizers that's not really high priority you can sort of D prioritize",
    "start": "1100610",
    "end": "1106010"
  },
  {
    "text": "that and and attack it on a batch basis this will make a little more sense in a",
    "start": "1106010",
    "end": "1111110"
  },
  {
    "text": "few more slides but the key thing to retain here is that think of Kinesis like a queue where you can dump",
    "start": "1111110",
    "end": "1116870"
  },
  {
    "text": "streaming data the framework that you use to pull the data out of that cue you can be flexible in that regard you if",
    "start": "1116870",
    "end": "1123410"
  },
  {
    "text": "you've ever heard of Kafka anyone heard of Kafka Kinesis in Kafka share a lot in common they're they're really quite",
    "start": "1123410",
    "end": "1131030"
  },
  {
    "text": "similar and so the first takeaway yeah Kinesis is like a Kafka SQ and as far as",
    "start": "1131030",
    "end": "1136550"
  },
  {
    "text": "architectures go you always want to think of your data in tiered ways everyone's thought of data before is like how valuable that data is to you",
    "start": "1136550",
    "end": "1145070"
  },
  {
    "text": "maybe if the data is not value you put it in reduce redundancy storage and s3 you could also think of your data how",
    "start": "1145070",
    "end": "1150230"
  },
  {
    "text": "quickly i need the insights from that data and that's what this is and all the other things i just showed you this is if i need some insights quickly so",
    "start": "1150230",
    "end": "1156560"
  },
  {
    "text": "higher priority things i need fast answers to and this is more batch analytics data that i can pull out a",
    "start": "1156560",
    "end": "1162200"
  },
  {
    "text": "Kinesis and process on a less regular basis on a non real-time basis and and tearing your data like that is extremely",
    "start": "1162200",
    "end": "1167750"
  },
  {
    "text": "powerful because then you're not wasting resources for data that you might not really need until that sunday night so ads advertisers no surprise you know you",
    "start": "1167750",
    "end": "1175310"
  },
  {
    "text": "log on a website based on cookie and a bunch of other data is aggregated and it makes a decision about who they think",
    "start": "1175310",
    "end": "1180320"
  },
  {
    "text": "you are and what you would probably click on and by that happens in a split second or more like one two three seconds and companies like data zoo sit",
    "start": "1180320",
    "end": "1187460"
  },
  {
    "text": "at the middle of all those decisions in this case they run essentially like an ad exchange or they work with ad exchanges and they are think of them",
    "start": "1187460",
    "end": "1193820"
  },
  {
    "text": "like the real-time bidding company an ad roll is another one there's a there's a bunch of these big companies",
    "start": "1193820",
    "end": "1199110"
  },
  {
    "text": "that provide platforms for the people both selling the ads and buying the ads",
    "start": "1199110",
    "end": "1204419"
  },
  {
    "text": "and then the people that the ads are actually about to kind of come together on a platform to all make money at our expense and so here they have a CDN this",
    "start": "1204419",
    "end": "1213210"
  },
  {
    "text": "is flume which is a log aggregator a real-time bidding system these are all collections of servers that may or may",
    "start": "1213210",
    "end": "1218820"
  },
  {
    "text": "not be on ec2 i'm not sure like the logos ec2 so let's go with ec2 and an ad retargeting platform point is is that",
    "start": "1218820",
    "end": "1225269"
  },
  {
    "text": "disparate things are all pushing to Kinesis so again think of Kinesis like Kafka think of it like a queue thinking",
    "start": "1225269",
    "end": "1231299"
  },
  {
    "text": "of it as a durable place where you can safely store streaming data temporarily while you figure what out what to do",
    "start": "1231299",
    "end": "1237120"
  },
  {
    "text": "with it and then they can replay what actually happened in the bids using an EMR cluster in this case push the results to s3 and they analyze it using",
    "start": "1237120",
    "end": "1243809"
  },
  {
    "text": "one of our friendly partners that I love called cue ball or maybe for some of the cold data that they don't necessarily",
    "start": "1243809",
    "end": "1249179"
  },
  {
    "text": "need to analyze immediately they archive it they're using the Kinesis client library again to pull the data out of",
    "start": "1249179",
    "end": "1254460"
  },
  {
    "text": "Kinesis and dumped at s3 here they're also using canisius client library to push the real-time applications that",
    "start": "1254460",
    "end": "1259649"
  },
  {
    "text": "maybe do some real time analysis on the bidding maybe if the rates the ad rates",
    "start": "1259649",
    "end": "1265620"
  },
  {
    "text": "are way off and bidding is is going way down you kind of know about that quickly and make some real-time adjustments to",
    "start": "1265620",
    "end": "1271200"
  },
  {
    "text": "your ad bid ratios or whatever the metric may be so this is a really good example of a lot of boxes but of them",
    "start": "1271200",
    "end": "1277350"
  },
  {
    "text": "tearing their data how things are streaming through the system what systems they're sending it to based on the importance of how quickly and we're",
    "start": "1277350",
    "end": "1283169"
  },
  {
    "text": "in what depth you need to know about that data in this case maybe they're not doing like full-blown reporting or analysis it's just kind of like based on",
    "start": "1283169",
    "end": "1289740"
  },
  {
    "text": "some certain conditions that indicate there might be a problem they push it to the real-time app how do you make recommendations not only on a website",
    "start": "1289740",
    "end": "1295169"
  },
  {
    "text": "but also in a store and that's also a streaming data problem these are similar problems to what we're talking about here is data coming into a Kinesis",
    "start": "1295169",
    "end": "1301620"
  },
  {
    "text": "stream whether it's from a location-based app or a mobile app lambda functions to react in real time based on what is coming into the stream",
    "start": "1301620",
    "end": "1308130"
  },
  {
    "text": "and you can set conditions you only fire off a function if certain conditions are met and then depending on the conditions",
    "start": "1308130",
    "end": "1314279"
  },
  {
    "text": "that data either gets cold data goes to red shift or sort of deep analysis or maybe hot data goes into dynamo DB which",
    "start": "1314279",
    "end": "1320279"
  },
  {
    "text": "in turn can trigger a lambda function which can then go off and do something else so these chained events associate",
    "start": "1320279",
    "end": "1325649"
  },
  {
    "text": "with the streaming data are becoming increasingly common and the idea that you only do something when you have to is",
    "start": "1325649",
    "end": "1331680"
  },
  {
    "text": "incredibly powerful in a streaming data context just collecting the data is one thing but real time reaction and only",
    "start": "1331680",
    "end": "1338220"
  },
  {
    "text": "paying for micro seconds of reaction in the form of lambda functions and not having a cluster sitting around waiting for something to happen is cheap I tell",
    "start": "1338220",
    "end": "1346410"
  },
  {
    "text": "the true story that I have a streaming data alerts in my pocket on my Amazon mobile app or Nagas i get a text through",
    "start": "1346410",
    "end": "1353370"
  },
  {
    "text": "twilio i think but if my amazon bill my cloud watch billing alert goes above five dollars a month my personal bill",
    "start": "1353370",
    "end": "1359460"
  },
  {
    "text": "definitely on my AWS bill if my personal amazon AWS bill goes over five dollars a month i got a huge like a text and phone",
    "start": "1359460",
    "end": "1366090"
  },
  {
    "text": "call because i use one hundred percent serverless and i actually run an EMR",
    "start": "1366090",
    "end": "1371160"
  },
  {
    "text": "cluster once a month but my bill is never over about these days three dollars 53 cents a month and I Ron 9 websites and all this stuff from for my",
    "start": "1371160",
    "end": "1377430"
  },
  {
    "text": "family so when I'm showing all these complex architectures don't think that they're expensive what we're talking",
    "start": "1377430",
    "end": "1383070"
  },
  {
    "text": "about here is aggregating or taking in I don't take in terabytes of data but it's",
    "start": "1383070",
    "end": "1388290"
  },
  {
    "text": "it's normalizing data it's processing data it's reacting as data at huge scale but at little cost so we talked a lot",
    "start": "1388290",
    "end": "1394800"
  },
  {
    "text": "about canisius without explaining to you what it is it's just a place to store your streaming data in a scalable and",
    "start": "1394800",
    "end": "1401310"
  },
  {
    "text": "safe way so when you have a bunch of saved servers in a data center or different parts of your cloud deployment",
    "start": "1401310",
    "end": "1407730"
  },
  {
    "text": "and you need to push all of those logs to a place and you don't want to lose those logs and you don't have to worry",
    "start": "1407730",
    "end": "1413430"
  },
  {
    "text": "about if you add another 500,000 servers what am I going to do do any day like grow my giant data collection cluster",
    "start": "1413430",
    "end": "1419280"
  },
  {
    "text": "this used to be a huge problem for people um data collection became a big data problem data storage of your logs",
    "start": "1419280",
    "end": "1425880"
  },
  {
    "text": "became a big data problem and it's funny because you were probably analyzing the logs with big data so it was kind of this you know circular argument so",
    "start": "1425880",
    "end": "1434250"
  },
  {
    "text": "Kinesis provides a way to easily scale both on ingest egress and ingress both",
    "start": "1434250",
    "end": "1439950"
  },
  {
    "text": "on putting your data in and getting your data out in a way that you don't have to think about it it does things like sharding makes that easy if you've ever",
    "start": "1439950",
    "end": "1446040"
  },
  {
    "text": "worked with any large database you all know that sharding is rarely easy in any context it's high throughput so you have",
    "start": "1446040",
    "end": "1451740"
  },
  {
    "text": "to worry about you know how many megabytes per second of data you're pushing in it's really easy we provide a",
    "start": "1451740",
    "end": "1457800"
  },
  {
    "text": "bunch of libraries on both the pushing in and the pulling out side we also have a wide partner ecosystem so",
    "start": "1457800",
    "end": "1463559"
  },
  {
    "text": "mentioned like you know spark and the associated company data bricks storm you",
    "start": "1463559",
    "end": "1469620"
  },
  {
    "text": "know from Twitter there's a lot of other frameworks and commercial companies that work with Kinesis directly we work hard",
    "start": "1469620",
    "end": "1475320"
  },
  {
    "text": "and that's my team and it works well with other AWS services so if using ER today with spark to analyze data or if",
    "start": "1475320",
    "end": "1482220"
  },
  {
    "text": "you're using red shift tomorrow if you switch to vertical that's cool vertical might be a little harder but it'll still",
    "start": "1482220",
    "end": "1487440"
  },
  {
    "text": "work and most importantly it's like almost all other AWS services it's pay-as-you-go the Kinesis is one of the",
    "start": "1487440",
    "end": "1493980"
  },
  {
    "text": "cheapest things you'll ever use if you add Kinesis to your bill today you know may go from three dollars and fifty-three sense to three dollars and",
    "start": "1493980",
    "end": "1499919"
  },
  {
    "text": "fifty five cents like in my case and that's like at high volume kinesis is a lot of things though now it used to be just kind of this queue thing I've been",
    "start": "1499919",
    "end": "1506070"
  },
  {
    "text": "using the term kind of loosely what I should be saying is Kinesis streams you can tell i've been at amazon awhile because there's Kinesis other stuff so",
    "start": "1506070",
    "end": "1512850"
  },
  {
    "text": "kinesis firehose as I'll show you in a second is awesome because it solves what turns out is a really hard problem which",
    "start": "1512850",
    "end": "1518940"
  },
  {
    "text": "is putting data in dec nieces it's easy enough to say oh yeah i'll just write a little bash script to push logs in Kinesis like sorta but what about the",
    "start": "1518940",
    "end": "1526200"
  },
  {
    "text": "problem if you've ever used red shift when you're loading data into a database at all if you're going to do a think of",
    "start": "1526200",
    "end": "1532649"
  },
  {
    "text": "a regular my sequel database if you're going to do an insert for every single record that quickly becomes inefficient",
    "start": "1532649",
    "end": "1538200"
  },
  {
    "text": "there's a lot of overhead associated with that insert so imagine if you have 1,000,000,000 log tiny little json log",
    "start": "1538200",
    "end": "1544230"
  },
  {
    "text": "snippets per hour that's a billion inserts on your my sequel database suddenly you're my sequel database capacity has been totally exhausted by",
    "start": "1544230",
    "end": "1550559"
  },
  {
    "text": "crappy little inserts for logs that most of what you don't care about so there's this concept called you know micro",
    "start": "1550559",
    "end": "1555960"
  },
  {
    "text": "batching and you can compress things so you take a bunch of those teeny little JSON snippets you whack together into",
    "start": "1555960",
    "end": "1561360"
  },
  {
    "text": "one megabyte compressed chunks so maybe there's like a hundred thousand probably more little pieces of logs in each",
    "start": "1561360",
    "end": "1566970"
  },
  {
    "text": "little chunk and then you load those chunks in every ten minutes and if you can meet your sort of data analysis SLA",
    "start": "1566970",
    "end": "1572340"
  },
  {
    "text": "in 10 minutes you don't need every millisecond that the little log is coming in you gotta look at where is",
    "start": "1572340",
    "end": "1577740"
  },
  {
    "text": "your value come in handy how often do you need this data and then compress and bash it accordingly and fire hose makes",
    "start": "1577740",
    "end": "1583259"
  },
  {
    "text": "that super easy so you can tell a fire hose collect my data buffer it for me safely so I won't lose those little",
    "start": "1583259",
    "end": "1589499"
  },
  {
    "text": "chunks wrap it into gzip make like five megabytes and push it into my s3 bucket",
    "start": "1589499",
    "end": "1596580"
  },
  {
    "text": "for example every 60 seconds that solves a pretty major problem whereas before you'd have to have that running on an ec2 instance",
    "start": "1596580",
    "end": "1602130"
  },
  {
    "text": "and as you were buffering things and matching things there was always that risk that the ec2 instance because you",
    "start": "1602130",
    "end": "1607140"
  },
  {
    "text": "were I don't know mining bitcoins or something and you you hoe is the instance and you lose that data that you",
    "start": "1607140",
    "end": "1612330"
  },
  {
    "text": "were buffering on that instance so it solves a data scalability problem when it comes to data in jest increases",
    "start": "1612330",
    "end": "1618270"
  },
  {
    "text": "analytics which is coming soon I might be able to show you a quick site later but I can't show you can use analytics",
    "start": "1618270",
    "end": "1625110"
  },
  {
    "text": "yet it basically think of it as like a sequel layer on topic Kinesis because",
    "start": "1625110",
    "end": "1630270"
  },
  {
    "text": "this was sort of a problem before you could actually look at Kinesis streams using high using sequel before a",
    "start": "1630270",
    "end": "1636180"
  },
  {
    "text": "little-known kind of non secret but that was a pain you had to spin up a Hadoop cluster and spin up TMR or and then use",
    "start": "1636180",
    "end": "1642660"
  },
  {
    "text": "the hive use the Kinesis hive connector and then know how to do that the first place and then you could do like select star from Kinesis stream but turns out",
    "start": "1642660",
    "end": "1649620"
  },
  {
    "text": "is actually hard to look into a Kinesis stream you have to write a bunch of java or do what i just described and Kinesis analytics solves that problem instead of",
    "start": "1649620",
    "end": "1656280"
  },
  {
    "text": "having to write an application or use a spark or something else you can use our",
    "start": "1656280",
    "end": "1661680"
  },
  {
    "text": "console or our api's and be like select star from my Kinesis stream so why would you ever want to do this let me give you",
    "start": "1661680",
    "end": "1667260"
  },
  {
    "text": "a real world example I think it's from there's a joke at amazon that whenever you say netflix you have to do a shot so",
    "start": "1667260",
    "end": "1673560"
  },
  {
    "text": "i'm try not to do say netflix but i think was netflix where they just wanted",
    "start": "1673560",
    "end": "1679170"
  },
  {
    "text": "to see like the last 10 records in the stream for debugging purposes which is like a really common use case right like you're pushing stuff and in Kinesis",
    "start": "1679170",
    "end": "1684720"
  },
  {
    "text": "you're not really sure if it's working properly and you want to see if stuff is going there so it turns out it's actually kinda hard to do you know",
    "start": "1684720",
    "end": "1690060"
  },
  {
    "text": "select star from my stream limit 10 you can't do that so you can think of Kinesis analytics is a sequel interface",
    "start": "1690060",
    "end": "1695730"
  },
  {
    "text": "to your Kinesis streams what is Kinesis how is it actually architected so we use",
    "start": "1695730",
    "end": "1700860"
  },
  {
    "text": "this term shard and the size of your stream by pretty much any metric cost",
    "start": "1700860",
    "end": "1706880"
  },
  {
    "text": "ability to ingest data ability to pull data out number of records you can put in per second how many megabytes per",
    "start": "1706880",
    "end": "1712740"
  },
  {
    "text": "second you can go in or out of your of your stream of your cue that's determined by the number of shards in",
    "start": "1712740",
    "end": "1718320"
  },
  {
    "text": "your Kinesis stream what's nice about our way of doing sharding is if you use",
    "start": "1718320",
    "end": "1724170"
  },
  {
    "text": "our libraries you don't have to worry about the shards because normally when you char database that becomes a total",
    "start": "1724170",
    "end": "1729570"
  },
  {
    "text": "headache because you have to remember that like records from a 2n where in this chart and records from you know Oh to whatever we're in the other schardt with",
    "start": "1729570",
    "end": "1734820"
  },
  {
    "text": "with our libraries we kind of take care of that for you so for most of you you don't have to think about shards but",
    "start": "1734820",
    "end": "1739980"
  },
  {
    "text": "just understand that a shard is a unit of capacity really how fast and what the",
    "start": "1739980",
    "end": "1745140"
  },
  {
    "text": "throughput both in and out can be for your stream so data sources pushing through like any other aw service an API",
    "start": "1745140",
    "end": "1752280"
  },
  {
    "text": "endpoint you do you do puts into a collection of shards things get spread",
    "start": "1752280",
    "end": "1758070"
  },
  {
    "text": "across the shards based on like a key just like a no sequel database depending",
    "start": "1758070",
    "end": "1764490"
  },
  {
    "text": "on what your key is it gets put in a different shark we'll talk about that in a second and then you pull stuff out again you need applications or libraries",
    "start": "1764490",
    "end": "1772140"
  },
  {
    "text": "that are shard aware because data is spread across multiple shards and so you need something like our Kinesis library",
    "start": "1772140",
    "end": "1777990"
  },
  {
    "text": "or spark streaming or storm things that are know how to toxic Kinesis and know about shards to take care of that for",
    "start": "1777990",
    "end": "1784470"
  },
  {
    "text": "you and they can pull data out of the shards so and then the last piece is how do you actually process or where does this data land you can land it in a",
    "start": "1784470",
    "end": "1790800"
  },
  {
    "text": "bunch of places we have connectors for s3 most people in the using Kinect Kinesis they push in a Kinesis usually",
    "start": "1790800",
    "end": "1796650"
  },
  {
    "text": "now with the fire hose they landed in s3 and then they either loaded and redshift or they analyze the data directly in s3",
    "start": "1796650",
    "end": "1802740"
  },
  {
    "text": "using EMR with either spark or MapReduce or whatever so that would cover these",
    "start": "1802740",
    "end": "1807840"
  },
  {
    "text": "two use cases increasingly we're seeing people with events with Kinesis streams and other stuff processed data or do",
    "start": "1807840",
    "end": "1814620"
  },
  {
    "text": "things with the data on the fly using lambda then you don't need a cluster you can do little mini miniature data",
    "start": "1814620",
    "end": "1819810"
  },
  {
    "text": "processing or take actions against things coming into your stream using lambda and then EMR as our sort of",
    "start": "1819810",
    "end": "1825420"
  },
  {
    "text": "Hadoop as a service or offering which again can be used to do data processing",
    "start": "1825420",
    "end": "1832110"
  },
  {
    "text": "your data analysis or all sorts of stuff in terms of what can send in you can use our library so the Kinesis producer",
    "start": "1832110",
    "end": "1838080"
  },
  {
    "text": "library the AWS sdk the mobile sdk log4j supports Kinesis or some variation of it",
    "start": "1838080",
    "end": "1843540"
  },
  {
    "text": "flume does fluent d if you're in the ops space if you're a DevOps dude or dudette you are probably familiar with these and",
    "start": "1843540",
    "end": "1850590"
  },
  {
    "text": "all of these can push data into Kinesis kind of natively and then to pull it out again this is sort of a reiteration plus",
    "start": "1850590",
    "end": "1856050"
  },
  {
    "text": "a couple third-party things storm works well spark works incredibly well I can tell you personally if you appoint you",
    "start": "1856050",
    "end": "1863490"
  },
  {
    "text": "guys if you want to link of a YouTube talk that I gave are given a few times we're going to give again a",
    "start": "1863490",
    "end": "1868560"
  },
  {
    "text": "Chicago in a couple weeks that in about 30 minutes you can go from knowing",
    "start": "1868560",
    "end": "1873900"
  },
  {
    "text": "nothing to pushing data into Kinesis to pulling it out and transforming it using spark streaming to analyzing it using",
    "start": "1873900",
    "end": "1879960"
  },
  {
    "text": "red shift and tableau in like 30 minutes maybe 40 and I'll show you that after it's not as hard as it seems with all",
    "start": "1879960",
    "end": "1886290"
  },
  {
    "text": "this stuff so this is an example of how it actually works from a stream perspective is yeah so I did a lot of",
    "start": "1886290",
    "end": "1892170"
  },
  {
    "text": "which I just said when I said that streams are shards represent capacity for every shard you get one megabyte per",
    "start": "1892170",
    "end": "1899130"
  },
  {
    "text": "second and up to 1,000 transactions a puts per second and likewise for every shard you can pull out two megabytes per",
    "start": "1899130",
    "end": "1905220"
  },
  {
    "text": "second so can anyone guess why the egress or ability to pull out data is higher than ability to put in data well",
    "start": "1905220",
    "end": "1911490"
  },
  {
    "text": "cuz there's a problem like what if you put a bunch of data into the queue or in your stream or to Kinesis and then like you forget to process it or you don't",
    "start": "1911490",
    "end": "1919260"
  },
  {
    "text": "want to process until the spot price goes below a certain rate so the retention is typically you're not typically processing data at the same",
    "start": "1919260",
    "end": "1925380"
  },
  {
    "text": "rate going out as you are going in and also you tend to process in batch so it",
    "start": "1925380",
    "end": "1932220"
  },
  {
    "text": "pushing data in a 1 by the second steady state you want be able to pull out batches at higher rates so batches less",
    "start": "1932220",
    "end": "1939120"
  },
  {
    "text": "often in bigger batches you used to be this was 24 hours retention but now it's seven days so this is important just",
    "start": "1939120",
    "end": "1945300"
  },
  {
    "text": "think of a server generating logs and it's generating every second or every 10 seconds every minute some kind of a log",
    "start": "1945300",
    "end": "1951570"
  },
  {
    "text": "and then you have multiplied that by 50 billion and you have a bunch of shards corresponding to what that data rate is on the ingest so you sighs your your",
    "start": "1951570",
    "end": "1958890"
  },
  {
    "text": "stream according to on an ingest perspective how many servers and how much data per hour on a maximum you",
    "start": "1958890",
    "end": "1964440"
  },
  {
    "text": "would you would need right and you can set Claude watch alerts that if you're exceeding or getting near that threshold",
    "start": "1964440",
    "end": "1969600"
  },
  {
    "text": "you just add new shards on the way out though if they were both 1 megabyte per",
    "start": "1969600",
    "end": "1974850"
  },
  {
    "text": "second you would have to have a cluster or some kind of mechanism running all the time to pull data out as well all the time but what if you don't want to",
    "start": "1974850",
    "end": "1981060"
  },
  {
    "text": "or that cluster falls over you don't want to lose that data because there's a retention window and it used to be just",
    "start": "1981060",
    "end": "1986970"
  },
  {
    "text": "24 hours and after 24 hours we would throw away your data now we've since increased that to seven days but I",
    "start": "1986970",
    "end": "1993150"
  },
  {
    "text": "should have put an Oscar there at asterisk there because 24 hours is included in the price but for every hour be",
    "start": "1993150",
    "end": "1998400"
  },
  {
    "text": "24 hours that you store data in a Kinesis q there's an additional cost now it's like a Kinesis cost so it's teeny",
    "start": "1998400",
    "end": "2004580"
  },
  {
    "text": "but it adds up if you're smart about it you can be like hey you know turns out like 4 p.m. on sundays or well maybe not",
    "start": "2004580",
    "end": "2010340"
  },
  {
    "text": "don't wait that long but like for every day at 4pm the spot price for ec2 if you're familiar with spot goes down to",
    "start": "2010340",
    "end": "2015860"
  },
  {
    "text": "like some really low so i'm going to wait until i do some data process until that time and then do batch operations 2 megabytes a second and pay less for my",
    "start": "2015860",
    "end": "2022010"
  },
  {
    "text": "processing cluster than I would at 3pm when the price was higher it's getting a little ahead of ourselves but like that's a really good use case actually",
    "start": "2022010",
    "end": "2027650"
  },
  {
    "text": "where you can see companies saving hundreds of thousand dollars a year just by making those minor changes so you can",
    "start": "2027650",
    "end": "2033800"
  },
  {
    "text": "replay data up to 24 hours 168 can't say this enough because people like a nice it sounds great why don't I just use it",
    "start": "2033800",
    "end": "2039650"
  },
  {
    "text": "as instead of s3 because the answer is we throw your data away that's why and you know where as it's highly durable a",
    "start": "2039650",
    "end": "2046220"
  },
  {
    "text": "che up to seven days and after that case it's gone so important just don't forget",
    "start": "2046220",
    "end": "2052010"
  },
  {
    "text": "this kinesis is a temporary staging area for your streaming data and that's why all of those pictures we saw before",
    "start": "2052010",
    "end": "2058158"
  },
  {
    "text": "we're pulling data out and persisting the data in s3 because s3 is durable a little stick around I didn't mention",
    "start": "2058159",
    "end": "2063560"
  },
  {
    "text": "glacier but you know a lot of people who tiered data so Luca nieces for the hottest data and then sort of standard storage s3 and then in frequent access",
    "start": "2063560",
    "end": "2071120"
  },
  {
    "text": "s34 like older data say older than a month and then glacier for older than three months because turns out you don't",
    "start": "2071120",
    "end": "2077060"
  },
  {
    "text": "need those apache logs very often except if you get audited so you can put them in glacier and pull them out when you need it later it's a it's a put",
    "start": "2077060",
    "end": "2082669"
  },
  {
    "text": "interface there's a few ways to put it data in but the important takeaway here is a partition key so just like a no",
    "start": "2082669",
    "end": "2090350"
  },
  {
    "text": "sequel database or just like any kind of data storage the key of the object that",
    "start": "2090350",
    "end": "2095389"
  },
  {
    "text": "you're putting into the stream determines where it lands in the shard and this is important for a couple reasons that will get into a second but",
    "start": "2095390",
    "end": "2101660"
  },
  {
    "text": "that's how on the back end we decide where to put stuff just like an s3 you may not know this but s3 is essentially",
    "start": "2101660",
    "end": "2107720"
  },
  {
    "text": "kind of the same architecture it's like a bunch of servers behind the scenes and depending on the name of your object in",
    "start": "2107720",
    "end": "2113210"
  },
  {
    "text": "s3 we put it in a storage location we take a hash of the object name and based on the hash value we put it in a certain",
    "start": "2113210",
    "end": "2119810"
  },
  {
    "text": "data storage location so we effectively shard data or spray the data around",
    "start": "2119810",
    "end": "2125000"
  },
  {
    "text": "different shards kinesis is the same with except instead of the object key you use an explicit partition key in",
    "start": "2125000",
    "end": "2131570"
  },
  {
    "text": "your put and then you get a sequence number now conesus does not guarantee ordering it",
    "start": "2131570",
    "end": "2139800"
  },
  {
    "text": "there is a sequence number but you shouldn't think of it if you need like guaranteed sequence you'll have to use",
    "start": "2139800",
    "end": "2144810"
  },
  {
    "text": "an additional framework like storm that's really good at that kind of thing and we'll get into some design patterns but you shouldn't really think of it as",
    "start": "2144810",
    "end": "2150330"
  },
  {
    "text": "an order q it's effectively like an unordered queue that doesn't guarantee a hundred percent sort of consistency in order but there's ways you can get",
    "start": "2150330",
    "end": "2155850"
  },
  {
    "text": "around that when you're sizing the ministry is just think about how many how much inbound data you need and think of that one megabyte per second metric",
    "start": "2155850",
    "end": "2161640"
  },
  {
    "text": "and then 1000 TPS and you should be able to figure it out pretty easily and because it's pay-as-you-go doesn't",
    "start": "2161640",
    "end": "2166890"
  },
  {
    "text": "really matter you could just add more shards or remove showers later don't stress too much about sizing the time that you spent stressing about sizing is",
    "start": "2166890",
    "end": "2175080"
  },
  {
    "text": "probably translates into money for your company which could just be invested in more shards how to size your kanisa stream think about this so say you have",
    "start": "2175080",
    "end": "2180690"
  },
  {
    "text": "two producers two servers with logs and they're each producing two kilobyte records sort of normal at five hundred kilobytes per second so in this case",
    "start": "2180690",
    "end": "2187200"
  },
  {
    "text": "you'll need two shards probably the more to be honest give you little Headroom but minimum of two chars required in this case oh this is 24 hours is old",
    "start": "2187200",
    "end": "2193890"
  },
  {
    "text": "it's actually up to seven days but say you have three consuming applications for different uses and we didn't really",
    "start": "2193890",
    "end": "2199170"
  },
  {
    "text": "talk about this but this was another reason that makes Kinesis kind of powerful and s3 when you store data in",
    "start": "2199170",
    "end": "2204780"
  },
  {
    "text": "Kinesis just like when you store data s3 you can have multiple applications multiple clusters pointing to the same",
    "start": "2204780",
    "end": "2210150"
  },
  {
    "text": "data set and processing it in parallel so in this case you may have payment processing fraud detection your credit",
    "start": "2210150",
    "end": "2215340"
  },
  {
    "text": "card companies are doing or doing this they're looking not only a process in the payment but also seeing if there's any irregularities and they paralyze",
    "start": "2215340",
    "end": "2221220"
  },
  {
    "text": "those things so you can have multiple things pointing at the same two shards but this is another reason why the",
    "start": "2221220",
    "end": "2226680"
  },
  {
    "text": "egress rate is going to be bigger than the ingress rate not only for catch up but because you may have multiple clusters multiple applications looking",
    "start": "2226680",
    "end": "2232770"
  },
  {
    "text": "at the same data set simultaneously and therefore will consume more overall bandwidth so in this case yeah if each",
    "start": "2232770",
    "end": "2239640"
  },
  {
    "text": "needs one Meg um yeah so you'll need 6 megabytes total so you need to add another shard there I took took away the",
    "start": "2239640",
    "end": "2246690"
  },
  {
    "text": "animation but there's a little animation that has another shard does that make sense s3 is the same way when you store",
    "start": "2246690",
    "end": "2252570"
  },
  {
    "text": "data in s3 you can have a spark cluster may be doing financial analysis for your CFO you could have like some other some",
    "start": "2252570",
    "end": "2260430"
  },
  {
    "text": "other thing that's loading stuff in a redshift you could have some other thing that's running Hadoop with hive because your guys no sequel",
    "start": "2260430",
    "end": "2266160"
  },
  {
    "text": "for your advertising division and this saves you a lot of money in complexity because you can have one single source",
    "start": "2266160",
    "end": "2272070"
  },
  {
    "text": "of truth with data whether it's your streaming data or your s3 data and have multiple applications looking at the same thing this is what I wanted to get",
    "start": "2272070",
    "end": "2277500"
  },
  {
    "text": "to though is that partition key is important to think about because of ordering and sometimes it's important to",
    "start": "2277500",
    "end": "2282930"
  },
  {
    "text": "know what order things came in if you need to do replays of events for example",
    "start": "2282930",
    "end": "2288630"
  },
  {
    "text": "to figure out what specific order came to a certain condition in a debugging",
    "start": "2288630",
    "end": "2294060"
  },
  {
    "text": "operation or whatever you need to know what order they came in and it turns out sequence numbers across shards is not it's it's hard because you have separate",
    "start": "2294060",
    "end": "2301140"
  },
  {
    "text": "shards in different sequence numbers in each shard it's hard to fully replay that order just using Kinesis itself so",
    "start": "2301140",
    "end": "2306840"
  },
  {
    "text": "one way you can do it is actually control the partition P now they're partition key itself be represent order",
    "start": "2306840",
    "end": "2312360"
  },
  {
    "text": "but the problem with that is it'll be kind of cereal because you'll have like partition key one Partridge key to partition key three and then because we",
    "start": "2312360",
    "end": "2318090"
  },
  {
    "text": "take a hash in our partition key and spray into a shard based on the partition key it'll take one two three and put it in the same shard and then",
    "start": "2318090",
    "end": "2323790"
  },
  {
    "text": "four five six and put in the same chart whereas just like s3 if you give it a random name it would spray it around different shards because each hash will",
    "start": "2323790",
    "end": "2329580"
  },
  {
    "text": "be very different because the name is very different right it's the same with partition keys so the way you get around that if you want to have both the",
    "start": "2329580",
    "end": "2336900"
  },
  {
    "text": "ability to process unordered very quickly in order to fully saturate the throughput of all of your shards but",
    "start": "2336900",
    "end": "2343290"
  },
  {
    "text": "also know what order things came in this is where DynamoDB could come in it's a fully consistent data store so you",
    "start": "2343290",
    "end": "2348570"
  },
  {
    "text": "actually maintain a list of these random partition keys in order in a dynamo DB table so it involves two two rights or",
    "start": "2348570",
    "end": "2355230"
  },
  {
    "text": "two API calls one to dynamo and one in parallel to Kinesis but it is a way of guaranteeing sort of order while not",
    "start": "2355230",
    "end": "2361410"
  },
  {
    "text": "sacrificing performance by using sort of a serial partition key sort of an advanced topic but I think it's",
    "start": "2361410",
    "end": "2367050"
  },
  {
    "text": "important to plant that seed we have a canisius agent if all this sounds kind of hard then don't do it we have a",
    "start": "2367050",
    "end": "2372390"
  },
  {
    "text": "Kinesis asian that can put for you like i said before you can use flu more fluent d most people honestly are not",
    "start": "2372390",
    "end": "2377940"
  },
  {
    "text": "writing this code themselves they're they're using the agent or our libraries or Kinesis producer library or some",
    "start": "2377940",
    "end": "2384360"
  },
  {
    "text": "other way to handle all these nuances for them and honestly I encourage you to do the same unless you have a really strong reason are to do things like",
    "start": "2384360",
    "end": "2391950"
  },
  {
    "text": "guaranteed ordering or other stuff most of us just want to get our data in there and get it out so use the agent use",
    "start": "2391950",
    "end": "2398400"
  },
  {
    "text": "fluent use flume whatever the case may be is all well documented on the website before we get into actually processing data just two",
    "start": "2398400",
    "end": "2405660"
  },
  {
    "text": "concepts I want to make sure we all understand say you have three shards and you move back to two shards we don't squish the shards together what we",
    "start": "2405660",
    "end": "2412500"
  },
  {
    "text": "actually do is like decommission the third shard and then you effectively drain that third shard so it blocks it",
    "start": "2412500",
    "end": "2419760"
  },
  {
    "text": "from additional puts and then you effectively drain that all the sequence numbers all the partition keys from that",
    "start": "2419760",
    "end": "2424799"
  },
  {
    "text": "shard so it's invisible for new rights but you can still visible for reads that's what's really happening when",
    "start": "2424799",
    "end": "2430109"
  },
  {
    "text": "we're merging chars we're not merging stars we're actually just taking one off and letting you drain that and likewise",
    "start": "2430109",
    "end": "2436319"
  },
  {
    "text": "when you split a sharp when you take two we call it splitting and in the mental picture you think we're just splitting one in half and making the three that's",
    "start": "2436319",
    "end": "2442289"
  },
  {
    "text": "that's actually not really what is happening we're adding a new shard and",
    "start": "2442289",
    "end": "2448049"
  },
  {
    "text": "it's intelligent enough on the back end that that it starts distributing across",
    "start": "2448049",
    "end": "2453390"
  },
  {
    "text": "all three automatically because of the partition key in the way it sort of sprays across so the merge and split is kind of a misnomer that's why I put it",
    "start": "2453390",
    "end": "2459119"
  },
  {
    "text": "up there and it's not like you lose the data of the third shower when you when you go from three showers to two shards there is a mechanism there it allows you",
    "start": "2459119",
    "end": "2465390"
  },
  {
    "text": "to drain it and the mechanism that makes a lot of the season two is the client library so I mentioned there's a producer library to put in there's an",
    "start": "2465390",
    "end": "2471869"
  },
  {
    "text": "agent to put in likewise for pulling out you don't really have to do this yourself we have a client library now",
    "start": "2471869",
    "end": "2477480"
  },
  {
    "text": "client library does things like worries about merging xand splittings and all this other stuff it also worries about the partition keys and iterators all",
    "start": "2477480",
    "end": "2484200"
  },
  {
    "text": "these things you have to do when you're processing data in a cube of any kind is not just Kinesis so it takes care of all",
    "start": "2484200",
    "end": "2489270"
  },
  {
    "text": "this stuff for you but importantly it also takes care of a very important concept which is scaling out ec2",
    "start": "2489270",
    "end": "2494700"
  },
  {
    "text": "instances to process this stuff so what happens if your game is really",
    "start": "2494700",
    "end": "2500279"
  },
  {
    "text": "successful and suddenly you have like for you you know someone like Taylor Swift tweets about your game and some of you go from like five users to like",
    "start": "2500279",
    "end": "2506339"
  },
  {
    "text": "50,000 users in like one hour so you have all this new telemetry coming your game scales wonderfully what happens on",
    "start": "2506339",
    "end": "2511859"
  },
  {
    "text": "the back end like if yours real-time streaming data process that needs to happen if you had like one crappy little Python script on an ec2 server that was",
    "start": "2511859",
    "end": "2517799"
  },
  {
    "text": "handling your five users just fine what happens when it moves to 50,000 users well yeah you can scale out but then you",
    "start": "2517799",
    "end": "2523650"
  },
  {
    "text": "have to think about the ec2 api's you have to deploy your library to process how do you coordinate amongst all the",
    "start": "2523650",
    "end": "2528960"
  },
  {
    "text": "different instances who's talking to what shard who's how are you keeping track of the sea it's number how do you know that you're",
    "start": "2528960",
    "end": "2534180"
  },
  {
    "text": "not doing duplicate processing suddenly these are big data problems so my advice you is not think about that and use the",
    "start": "2534180",
    "end": "2539850"
  },
  {
    "text": "Kinesis client library because not only does it handle deduplication it handles sort of only once processing it also",
    "start": "2539850",
    "end": "2545010"
  },
  {
    "text": "handles the auto scaling stuff the ec2 AP is and we'll add new Kinesis workers in the form of ec2 instances on as",
    "start": "2545010",
    "end": "2551070"
  },
  {
    "text": "needed to scale with the size of your Kinesis stream so if you suddenly have a lot more puts and a lot more shards the",
    "start": "2551070",
    "end": "2557940"
  },
  {
    "text": "canisius client library will actually add more ec2 instances to then go and process that data and you can set limits",
    "start": "2557940",
    "end": "2563250"
  },
  {
    "text": "you don't you know Taylor Swift doesn't ddos you in the form of financial bills at the end of the month but the bottom",
    "start": "2563250",
    "end": "2570060"
  },
  {
    "text": "line is it makes certainly the infrastructure part in addition to code a lot easier and I love this actually",
    "start": "2570060",
    "end": "2575130"
  },
  {
    "text": "because we often talk about the cloud is the merging of infrastructure and code it's I think that's mostly bowl for the",
    "start": "2575130",
    "end": "2581280"
  },
  {
    "text": "most part but this is this is for real this is there's total blurring of the lines between your code and infrastructure ec2 as servers is is no",
    "start": "2581280",
    "end": "2589470"
  },
  {
    "text": "different from processing logic to keep track of iterators and sequence numbers etc so Jesus Clyburn very cool in",
    "start": "2589470",
    "end": "2597180"
  },
  {
    "text": "reality though most people are not even using Kinesis client library they're using spark streaming and storm and all",
    "start": "2597180",
    "end": "2603390"
  },
  {
    "text": "these higher level frameworks and guess what spark streaming actually uses the Kinesis client library under the covers",
    "start": "2603390",
    "end": "2608940"
  },
  {
    "text": "they tell you that deep in the documentation so take away if you want to write a streaming data processing",
    "start": "2608940",
    "end": "2615270"
  },
  {
    "text": "framework use the KCl if you don't just use spark streaming or storm or you know",
    "start": "2615270",
    "end": "2620490"
  },
  {
    "text": "some other higher level framework because the value you get out by the way these frameworks are free the value you",
    "start": "2620490",
    "end": "2625920"
  },
  {
    "text": "get out of having a customized KCl for most mortals is limited we want to make this easy for you so start there and",
    "start": "2625920",
    "end": "2631619"
  },
  {
    "text": "work backwards lastly connector I talked about this a lot their libraries such that Kinesis can talk to other AWS",
    "start": "2631619",
    "end": "2638609"
  },
  {
    "text": "services for example persisting to s3 or dynamo dB it's a way of taking your data",
    "start": "2638609",
    "end": "2644460"
  },
  {
    "text": "and we talked to a dynamo a lot earlier if you want data coming in in Kinesis matching some conditions to then land in",
    "start": "2644460",
    "end": "2653400"
  },
  {
    "text": "a dynamo DB table you could leverage the Kinesis connector library to write a little thin application that makes a",
    "start": "2653400",
    "end": "2659010"
  },
  {
    "text": "decision based on the content of the data and then pushes maybe some subset of the data into dynamo DB table if it meets those conditions",
    "start": "2659010",
    "end": "2665579"
  },
  {
    "text": "and remember even this most of you don't have to write just use Kinesis fire hose which guess what uses the Kinesis",
    "start": "2665579",
    "end": "2672010"
  },
  {
    "text": "connector library under the covers to talk to s3 and to take your data to aggregated to compress it into pushing",
    "start": "2672010",
    "end": "2677230"
  },
  {
    "text": "into s3 so I talked a lot about spark most people approach spark from Scala and Scala is not easy and so it appears",
    "start": "2677230",
    "end": "2683980"
  },
  {
    "text": "that spark is hard and most people associate spark with giant clusters in Hadoop spark is is actually fairly very",
    "start": "2683980",
    "end": "2690849"
  },
  {
    "text": "easy to get started i'll tell you why there's less lines of code you can use Scala but you don't have to use Scala",
    "start": "2690849",
    "end": "2696010"
  },
  {
    "text": "there's also Python for spark you're not locked into Scala and increasing there's",
    "start": "2696010",
    "end": "2701079"
  },
  {
    "text": "additional language support for spark really think of spark is a more modern alternative to MapReduce think of Hadoop",
    "start": "2701079",
    "end": "2707470"
  },
  {
    "text": "is like the family and MapReduce is one way to leverage that cluster to process data and spark is a new arguably much",
    "start": "2707470",
    "end": "2714940"
  },
  {
    "text": "better way to process the data it makes much better use of in-memory processing it paralyzes thing a lot better so it's",
    "start": "2714940",
    "end": "2720730"
  },
  {
    "text": "just another application that runs on a Hadoop cluster that is a lot faster than and more flexible than MapReduce and",
    "start": "2720730",
    "end": "2726460"
  },
  {
    "text": "spark is not just one thing there's sparks sequel which is a sequel interface you can use that cluster to",
    "start": "2726460",
    "end": "2732040"
  },
  {
    "text": "use sequel to interact with data it can talk to s3 their spark streaming for streaming data there's a graph component",
    "start": "2732040",
    "end": "2737200"
  },
  {
    "text": "to spark there's a lot of different projects within spark itself but the easiest way to think about it is like a MapReduce alternative an execution",
    "start": "2737200",
    "end": "2743859"
  },
  {
    "text": "engine a data processing engine that runs on Hadoop clusters and with sparks streaming and spark in general can talk",
    "start": "2743859",
    "end": "2750609"
  },
  {
    "text": "to kanisa so it can read from Kinesis streams it can process data to Kinesis and it can write to Kinesis and it's",
    "start": "2750609",
    "end": "2756790"
  },
  {
    "text": "easy because Scala is confusing at first but is very is not verbose you can write",
    "start": "2756790",
    "end": "2762819"
  },
  {
    "text": "really like what used to take like huge amount of Java in a custom MapReduce job",
    "start": "2762819",
    "end": "2767920"
  },
  {
    "text": "you can condense down to a few lines of Scala and run much more quickly on spark the good news is you don't even have to",
    "start": "2767920",
    "end": "2773560"
  },
  {
    "text": "do this you can use sparks equal and use sequel and still get the advantages of that that fast back end so you can do",
    "start": "2773560",
    "end": "2779680"
  },
  {
    "text": "that select star from my Kinesis stream using spark streaming or sparks equal rather in this case we're using spark",
    "start": "2779680",
    "end": "2785589"
  },
  {
    "text": "for batch processing of or rather just for interacting with it with the Kinesis",
    "start": "2785589",
    "end": "2790690"
  },
  {
    "text": "stream we're probably actually in this case we're probably using spark streaming but you can do things like",
    "start": "2790690",
    "end": "2796060"
  },
  {
    "text": "windowing functions etc to pull data out too persistent to hdfs or two I don't",
    "start": "2796060",
    "end": "2802240"
  },
  {
    "text": "know why it says HDFS here probably what you would normally do is persistent to s3 and then copy it into red shift from",
    "start": "2802240",
    "end": "2807910"
  },
  {
    "text": "there there are rare cases where it's better to use local HDFS than s3 on Hadoop clusters this may be one of them in the same way in Kinesis you have sort",
    "start": "2807910",
    "end": "2814720"
  },
  {
    "text": "of workers in the Kinesis client library you need to scale up both the infrastructure back end and the amount of threads process the data it's the",
    "start": "2814720",
    "end": "2820990"
  },
  {
    "text": "same thing with spark and executors so using spark it has a certain number of",
    "start": "2820990",
    "end": "2826240"
  },
  {
    "text": "executors and corresponding to a certain number of Kinesis receivers that is effectively a scaling mechanism for processing data as scale and Kinesis and",
    "start": "2826240",
    "end": "2832930"
  },
  {
    "text": "corresponding the number of shards in your Kinesis stream that was a mouthful so your executors there is a spark",
    "start": "2832930",
    "end": "2839530"
  },
  {
    "text": "concept about basically corresponding to the number of cores that's not entirely accurate because you can tune that but",
    "start": "2839530",
    "end": "2846640"
  },
  {
    "text": "you can tune all this basically the long story i guess if i was to distill this all down is you can tune how how fast",
    "start": "2846640",
    "end": "2854260"
  },
  {
    "text": "spark can process and how it processes data in a Kinesis stream so there's a correlation between the amount of data",
    "start": "2854260",
    "end": "2859690"
  },
  {
    "text": "and how you process the data in Kinesis the amount of executors using and how that's linked to the cores on your cluster how big your cluster is how fast",
    "start": "2859690",
    "end": "2865900"
  },
  {
    "text": "it can go so in this case we're talking about IM RFS which is an s3 backed file system to persist or to read and write",
    "start": "2865900",
    "end": "2872260"
  },
  {
    "text": "out of s3 so this is just a really fancy way of saying you can use spark as a data processing execution algorithm or a",
    "start": "2872260",
    "end": "2878860"
  },
  {
    "text": "story engine to pull data out of Kinesis process it give you an example convert all semicolons in all log files to",
    "start": "2878860",
    "end": "2886300"
  },
  {
    "text": "commas or to remove take a bunch of crazy apache logs or i'll give you some",
    "start": "2886300",
    "end": "2891490"
  },
  {
    "text": "crazy logs omniture logs how many of you have ever worked with Omniture logs no no no advertising people okay i'm going",
    "start": "2891490",
    "end": "2897400"
  },
  {
    "text": "to sure familiar with a name they they have like the worst or longest craziest most highly changing log format I've",
    "start": "2897400",
    "end": "2903520"
  },
  {
    "text": "ever seen in my life people have written whole like Pig libraries about this stuff and turns out that one Omniture",
    "start": "2903520",
    "end": "2909040"
  },
  {
    "text": "log does not look like another Omniture log and if you try to take this stuff and stuff it into a structured database like red shift or my sequel everything",
    "start": "2909040",
    "end": "2915610"
  },
  {
    "text": "blows up so you need something in the middle there that takes all these disparate log formats and inconsistencies like that weird ?",
    "start": "2915610",
    "end": "2921160"
  },
  {
    "text": "instead of a comma and normalizes it and looks for problems with the data cleanses the data takes up columns you",
    "start": "2921160",
    "end": "2927160"
  },
  {
    "text": "don't need and picks up the actual subset of data you need orders it nicely with commas in between so that you can",
    "start": "2927160",
    "end": "2932200"
  },
  {
    "text": "load it into reg if it doesn't blow up I mean spark is perfect for that it can iterate through huge amount of data very very very",
    "start": "2932200",
    "end": "2938420"
  },
  {
    "text": "quickly take out pieces the data you can think of it like the world's most powerful regex can do a lot more but",
    "start": "2938420",
    "end": "2944359"
  },
  {
    "text": "most of us would have written bash scripts with like said and regex and regular expressions like pearl you know",
    "start": "2944359",
    "end": "2950900"
  },
  {
    "text": "like you don't do that anymore you can do it with Scala or Python with spark and it happens a lot faster and in",
    "start": "2950900",
    "end": "2956420"
  },
  {
    "text": "parallel on a cluster say you have an application that's pushing pushing to Kinesis in the Kinesis stream can",
    "start": "2956420",
    "end": "2961549"
  },
  {
    "text": "actually trigger events and if you were listening to saji before you know that lambda is a service that you pay for by",
    "start": "2961549",
    "end": "2969380"
  },
  {
    "text": "the millisecond you can think of it as like functions as a service so until now I've been talking about clusters of ec2",
    "start": "2969380",
    "end": "2975109"
  },
  {
    "text": "instances that are processing this data right and using the Kinesis client library for example you push a bunch of",
    "start": "2975109",
    "end": "2980660"
  },
  {
    "text": "data into Indyk Kinesis and then you fire up a bunch of ec2 instances and they're running the Kinesis client",
    "start": "2980660",
    "end": "2986119"
  },
  {
    "text": "library and you pull out data maybe you don't need that cluster maybe you only care about some of the data so as the",
    "start": "2986119",
    "end": "2993289"
  },
  {
    "text": "date is coming in to your point earlier it can fire an event saying hey I'm new data I'm here and that event can trigger",
    "start": "2993289",
    "end": "2999049"
  },
  {
    "text": "a lambda function that lambda function can maybe do basic normalization of the data it could maybe load that data into",
    "start": "2999049",
    "end": "3004599"
  },
  {
    "text": "s3 if you don't wanna use fire hose it can maybe make a quick determination is this data I care about and maybe",
    "start": "3004599",
    "end": "3009759"
  },
  {
    "text": "ninety-nine point nine nine percent of data you don't care about which is usually the case and lambda can dump the data and only push interesting data into",
    "start": "3009759",
    "end": "3016089"
  },
  {
    "text": "your database saving you money because you don't pay for as much storage so think of lambda as a very thin it's not",
    "start": "3016089",
    "end": "3022630"
  },
  {
    "text": "as powerful as a huge ec2 cluster is certainly not as powerful as a massive spark streaming cluster but for most mortals it does the trick and it can be",
    "start": "3022630",
    "end": "3029589"
  },
  {
    "text": "a great shim between like to do basic data transformation that maybe you don't need a spark cluster to just replace",
    "start": "3029589",
    "end": "3035289"
  },
  {
    "text": "that comma like I was referencing before so AWS lambda is this sort of functions",
    "start": "3035289",
    "end": "3040690"
  },
  {
    "text": "as a service that we have the lambda architecture is sort of what we were looking at before where you tier your",
    "start": "3040690",
    "end": "3045789"
  },
  {
    "text": "data in terms of whether it's hot or cold and you can push your hot data into DynamoDB for example and push your cold",
    "start": "3045789",
    "end": "3051970"
  },
  {
    "text": "data into s3 and glacier and redshift for sort of batch processing later so you have streaming processing with batch processing that's the lambda",
    "start": "3051970",
    "end": "3058029"
  },
  {
    "text": "architecture now this is apparently a play on lambda architecture this is the",
    "start": "3058029",
    "end": "3063309"
  },
  {
    "text": "AWS lambda architecture to sort of try and confuse you and all this is is that the lambda architecture is that sort of tiered hot",
    "start": "3063309",
    "end": "3069609"
  },
  {
    "text": "and cold model we were talking about earlier where's a Davis Lando is a service this is a good application and this sort of illustrates actually a",
    "start": "3069609",
    "end": "3075130"
  },
  {
    "text": "lambda architecture using lambda so here you have Kinesis data coming into Kinesis firing events the trigger lambda",
    "start": "3075130",
    "end": "3081580"
  },
  {
    "text": "functions based on the contents of the data or the characteristics of the data they may be pushes the the batch stuff",
    "start": "3081580",
    "end": "3086890"
  },
  {
    "text": "the colder data if you will to our data warehouse redshift for later processing it pushes the hot data may be something",
    "start": "3086890",
    "end": "3093130"
  },
  {
    "text": "that fronts or rather backs a dashboard to dynamo dB and it pushes the really long tail stuff you don't know what to",
    "start": "3093130",
    "end": "3099070"
  },
  {
    "text": "do with yet or maybe it's in a format that you need to normalize later using a spark streaming or spark cluster into s3",
    "start": "3099070",
    "end": "3104560"
  },
  {
    "text": "so having again this is exactly what I just described having lambda is kind of a shim between the different places",
    "start": "3104560",
    "end": "3110950"
  },
  {
    "text": "where you may want to either persist or analyze your data so canisius fire hose again makes that putting in easy so if",
    "start": "3110950",
    "end": "3117580"
  },
  {
    "text": "you have that lambda architecture yeah this is fine but somebody has to write all these lambda functions and what if",
    "start": "3117580",
    "end": "3123640"
  },
  {
    "text": "you don't want to spend your time grappling with like node and you know you're really not used to Shawne owed in",
    "start": "3123640",
    "end": "3130450"
  },
  {
    "text": "general has asynchronous programming model you'll pull your hair out I promise so instead of using writing all these lambda functions why don't just",
    "start": "3130450",
    "end": "3136240"
  },
  {
    "text": "use fire hose it turns out fire hose is really easy let me show you the code it's easier okay so you asked before",
    "start": "3136240",
    "end": "3143380"
  },
  {
    "text": "about you know how much code are we talking about here how hard is it gonna be well this is the complete code that I wrote using Python like on my lap like",
    "start": "3143380",
    "end": "3151210"
  },
  {
    "text": "while feeding my child to push data from a weblog line by line into fire hose now",
    "start": "3151210",
    "end": "3159820"
  },
  {
    "text": "behind the scenes what fire hose is actually going to do for me is as I push these lines now this is trivial fake",
    "start": "3159820",
    "end": "3166000"
  },
  {
    "text": "code okay my first one to say that but it's complete you could take this code and run it with like Python this code",
    "start": "3166000",
    "end": "3171400"
  },
  {
    "text": "would work and if you had a weblog to read line by line called weblog and it's",
    "start": "3171400",
    "end": "3176589"
  },
  {
    "text": "going to put it's going to fake it really is going to put a line by line log just as if you were streaming logs into Kinesis but what fire hose is going",
    "start": "3176589",
    "end": "3183250"
  },
  {
    "text": "to do is the other 500 lines that I don't need to include here and that is take the data buffer it up to a Meg wait",
    "start": "3183250",
    "end": "3190480"
  },
  {
    "text": "60 seconds compress it into gzip persistent in s3 that's a lot of code and that's a lot of potential error",
    "start": "3190480",
    "end": "3197230"
  },
  {
    "text": "because if in that time my ec2 instance falls over lose that mega vlogs and I may lose forever the threat that the hacker was",
    "start": "3197230",
    "end": "3204160"
  },
  {
    "text": "you know because the hacker knows i was using ec2 and they take out that ec2 instance so i hope they have no trace of their work whereas with fire hose i put",
    "start": "3204160",
    "end": "3210430"
  },
  {
    "text": "it in there it takes care of all the buffering the compression and putting into s3 and i think looking at code is",
    "start": "3210430",
    "end": "3215950"
  },
  {
    "text": "not always a good idea on the screen but in this case I hope it illustrates how many lines of code are not here and how",
    "start": "3215950",
    "end": "3221319"
  },
  {
    "text": "firehose makes a lot easier similarly once we release analytics I'll have a similar slide that just has some sequel",
    "start": "3221319",
    "end": "3227470"
  },
  {
    "text": "that says like select matt from don't worry this talk is not as almost over you know whatever table and doing that",
    "start": "3227470",
    "end": "3233950"
  },
  {
    "text": "in spark would take firing up mr cluster going into the sparks equal shell etc i said a lot of steps were with Kinesis",
    "start": "3233950",
    "end": "3240430"
  },
  {
    "text": "analytics you could just write one line of code in our console and you get the contents from the streams or from the",
    "start": "3240430",
    "end": "3245589"
  },
  {
    "text": "stream rather so they say some other stuff here but that's really what I",
    "start": "3245589",
    "end": "3251290"
  },
  {
    "text": "wanted to tell you today I threw a lot at you but I hope at least you understand a couple things and that's",
    "start": "3251290",
    "end": "3256980"
  },
  {
    "text": "why Kinesis streams Kinesis fire hose and Kinesis analytics eventually are useful and I hope that you also",
    "start": "3256980",
    "end": "3263650"
  },
  {
    "text": "understand the difference between s3 da no way to be kinesis and really how it's not as hard as it may initially seem to",
    "start": "3263650",
    "end": "3269740"
  },
  {
    "text": "both put data in a Kinesis and pull data out and most importantly and this is why i was so good that you asked that question earlier why it's important to",
    "start": "3269740",
    "end": "3275799"
  },
  {
    "text": "use something like Kinesis to decouple the parts of your application so that when like the kids at Twitter come out",
    "start": "3275799",
    "end": "3281109"
  },
  {
    "text": "with the next thing or the the people that sparked you know all quit and I have to use the next framework it's not",
    "start": "3281109",
    "end": "3287200"
  },
  {
    "text": "a big deal because all your data's and Kinesis getting persist in s3 and all I have to do is change that middle part in the middle and it's it's not as much",
    "start": "3287200",
    "end": "3292930"
  },
  {
    "text": "code or hassle as it would have been otherwise",
    "start": "3292930",
    "end": "3296250"
  },
  {
    "text": "you",
    "start": "3301290",
    "end": "3303350"
  }
]
[
  {
    "text": "- Hi, I'm Andrea from AWS.",
    "start": "210",
    "end": "2550"
  },
  {
    "text": "- Hi, I'm Syed from Experian\nand this is my architecture.",
    "start": "2550",
    "end": "6083"
  },
  {
    "text": "(light music)",
    "start": "6084",
    "end": "8584"
  },
  {
    "text": "- Thanks for being on the show, Syed,",
    "start": "16200",
    "end": "18240"
  },
  {
    "text": "what do you guys do at Experian?",
    "start": "18240",
    "end": "19980"
  },
  {
    "text": "- Experian is a data analytics\nand credit scoring company.",
    "start": "19980",
    "end": "23460"
  },
  {
    "text": "So we get data from\n400,000 plus institutions,",
    "start": "23460",
    "end": "26550"
  },
  {
    "text": "financial institutions, across the nation.",
    "start": "26550",
    "end": "28830"
  },
  {
    "text": "We aggregate the data and\nprovide consumers credit reports",
    "start": "28830",
    "end": "32970"
  },
  {
    "text": "and the financial institutions",
    "start": "32970",
    "end": "34770"
  },
  {
    "text": "to take decisions on their",
    "start": "34770",
    "end": "36460"
  },
  {
    "text": "credit offerings like loans, auto loans,",
    "start": "37313",
    "end": "39329"
  },
  {
    "text": "mortgage, et cetera.",
    "start": "39330",
    "end": "40380"
  },
  {
    "text": "- Wonderful, so earlier we\nlearned that Experian had",
    "start": "40380",
    "end": "44311"
  },
  {
    "text": "simplified the machine\nlearning model deployment",
    "start": "44311",
    "end": "47820"
  },
  {
    "text": "for clients.",
    "start": "47820",
    "end": "49920"
  },
  {
    "text": "So what are we going to talk about today?",
    "start": "49920",
    "end": "53399"
  },
  {
    "text": "What business problem do you\nsolve with the architecture",
    "start": "53399",
    "end": "55079"
  },
  {
    "text": "that you also run on AWS?",
    "start": "55080",
    "end": "57120"
  },
  {
    "text": "- Machine learning model\nonboarding is just a part",
    "start": "57120",
    "end": "59370"
  },
  {
    "text": "of the MLOps platform, right?",
    "start": "59370",
    "end": "61170"
  },
  {
    "text": "What comes after that is\ntesting those machine learning",
    "start": "61170",
    "end": "63839"
  },
  {
    "text": "models to work fine and training them",
    "start": "63840",
    "end": "66460"
  },
  {
    "text": "to make it perfect and\ndeploying them to production",
    "start": "67359",
    "end": "69870"
  },
  {
    "text": "and running them in production\nfor batch and real use case.",
    "start": "69870",
    "end": "73020"
  },
  {
    "text": "- Great, so let's dive straight to it.",
    "start": "73020",
    "end": "74759"
  },
  {
    "text": "- Absolutely.",
    "start": "74760",
    "end": "75866"
  },
  {
    "text": "- All right, so let's\ngo through the journey.",
    "start": "75866",
    "end": "77430"
  },
  {
    "text": "Who's the user and how do\nthey initiate a request?",
    "start": "77430",
    "end": "81175"
  },
  {
    "text": "- [Syed] Yep, so we have\ndifferent sets of users.",
    "start": "81175",
    "end": "82560"
  },
  {
    "text": "One of the main user is the data scientist",
    "start": "82560",
    "end": "85049"
  },
  {
    "text": "who uses the portal to kick\nout these batch runs from jobs.",
    "start": "85050",
    "end": "87900"
  },
  {
    "text": "- Okay. With that request,\ndo they have to submit",
    "start": "87900",
    "end": "91200"
  },
  {
    "text": "any specific data or files?",
    "start": "91200",
    "end": "93570"
  },
  {
    "text": "- [Syed] When they do\nit through the portal,",
    "start": "93570",
    "end": "95940"
  },
  {
    "text": "that information is just good enough",
    "start": "95940",
    "end": "97710"
  },
  {
    "text": "to execute the entire campaign.",
    "start": "97710",
    "end": "99510"
  },
  {
    "text": "- [Andrea] Wonderful, and you\nsend it to a managed Kafka?",
    "start": "99510",
    "end": "102330"
  },
  {
    "text": "- [Syed] Correct.",
    "start": "102330",
    "end": "103806"
  },
  {
    "text": "- [Andrea] Correct, okay.",
    "start": "103806",
    "end": "104775"
  },
  {
    "text": "So walk us through kind of the backend.",
    "start": "104775",
    "end": "106911"
  },
  {
    "text": "I see a lot of other AWS\nservices, so what's the logic?",
    "start": "106911",
    "end": "109140"
  },
  {
    "text": "- [Syed] Yeah, so when the\nfirst message is written",
    "start": "109140",
    "end": "112304"
  },
  {
    "text": "to the Kafka topic, so it is attached",
    "start": "112304",
    "end": "113970"
  },
  {
    "text": "to this consumer, it is\nthe orchestration consumer.",
    "start": "113970",
    "end": "116670"
  },
  {
    "text": "They call it the orchestrator,",
    "start": "116670",
    "end": "117960"
  },
  {
    "text": "which is on Fargate ECS.",
    "start": "117960",
    "end": "119460"
  },
  {
    "text": "Correct.",
    "start": "119460",
    "end": "120293"
  },
  {
    "text": "This guy determines the execution plan.",
    "start": "121424",
    "end": "123240"
  },
  {
    "text": "- [Andrea] Okay.",
    "start": "123240",
    "end": "124170"
  },
  {
    "text": "- Right.",
    "start": "124170",
    "end": "125609"
  },
  {
    "text": "So now you have the execution plan.",
    "start": "125609",
    "end": "126660"
  },
  {
    "text": "What's the set of events\nthat is triggered?",
    "start": "126660",
    "end": "129000"
  },
  {
    "text": "- Yes, so once they orchestrator,",
    "start": "129000",
    "end": "132390"
  },
  {
    "text": "it reminds the execution\nplan, it writes the message",
    "start": "132390",
    "end": "135120"
  },
  {
    "text": "to another topic on MSK,",
    "start": "135120",
    "end": "137250"
  },
  {
    "text": "which is managed streaming\nfor Kafka, right?",
    "start": "137250",
    "end": "139380"
  },
  {
    "text": "- [Andrea] I see.",
    "start": "139380",
    "end": "140213"
  },
  {
    "text": "- [Syed] Which is consumed by\none or more consumers here.",
    "start": "140213",
    "end": "143099"
  },
  {
    "text": "- [Andrea] And that\nsits on Fargate as well?",
    "start": "143100",
    "end": "144840"
  },
  {
    "text": "- [Syed] That is true.",
    "start": "144840",
    "end": "145672"
  },
  {
    "text": "- And this is on a topic you mentioned?",
    "start": "145673",
    "end": "147510"
  },
  {
    "text": "- Yes.",
    "start": "147510",
    "end": "148502"
  },
  {
    "text": "- Does that mean that\nyou can have multiple",
    "start": "148502",
    "end": "149459"
  },
  {
    "text": "of these happening at the same time?",
    "start": "149460",
    "end": "151200"
  },
  {
    "text": "- Yes, exactly.",
    "start": "151200",
    "end": "152032"
  },
  {
    "text": "So this whole architecture is event-driven",
    "start": "152033",
    "end": "155160"
  },
  {
    "text": "and these four units are, we call it",
    "start": "155160",
    "end": "158850"
  },
  {
    "text": "as a operational functional unit.",
    "start": "158850",
    "end": "160740"
  },
  {
    "text": "- Okay.",
    "start": "160740",
    "end": "161731"
  },
  {
    "text": "- And they are independent",
    "start": "161731",
    "end": "162564"
  },
  {
    "text": "and they can be executed\nin parallel or sequential.",
    "start": "162564",
    "end": "165870"
  },
  {
    "text": "- So these are, what do you define this?",
    "start": "165870",
    "end": "168120"
  },
  {
    "text": "Is it your processing engine, pretty much?",
    "start": "168120",
    "end": "170461"
  },
  {
    "text": "- Yes, it is the processing\nengine for the batch.",
    "start": "170462",
    "end": "171835"
  },
  {
    "text": "- Okay, so let's go a little\nbit deeper here, right.",
    "start": "171835",
    "end": "173880"
  },
  {
    "text": "So I see EMR, SageMaker,\nwhat are they used for?",
    "start": "173880",
    "end": "176523"
  },
  {
    "text": "- [Syed] Yes, once the\nexecution plant is determined,",
    "start": "178451",
    "end": "179760"
  },
  {
    "text": "the orchestrator and this consumer,",
    "start": "179760",
    "end": "182580"
  },
  {
    "text": "which is the operational\nconsumer, will know whether",
    "start": "182580",
    "end": "185640"
  },
  {
    "text": "to execute a pre-processing job",
    "start": "185640",
    "end": "187740"
  },
  {
    "text": "or any kind of job on a EMR cluster.",
    "start": "187740",
    "end": "190140"
  },
  {
    "text": "Or it has to trigger a batch\non a batch transform job",
    "start": "190140",
    "end": "194250"
  },
  {
    "text": "on a SageMaker.",
    "start": "194250",
    "end": "195210"
  },
  {
    "text": "- [Andrea] I see, give us some examples.",
    "start": "195210",
    "end": "197100"
  },
  {
    "text": "Like, why would you use\nEMR for pre-processing?",
    "start": "197100",
    "end": "201180"
  },
  {
    "text": "- [Syed] So when a job\nis triggered, right,",
    "start": "201180",
    "end": "204510"
  },
  {
    "text": "it could be relying on",
    "start": "204510",
    "end": "206370"
  },
  {
    "text": "more than one data source,",
    "start": "206370",
    "end": "207659"
  },
  {
    "text": "and these data sources could\nbe in different formats.",
    "start": "207660",
    "end": "210030"
  },
  {
    "text": "So we use an EMR cluster",
    "start": "210030",
    "end": "211590"
  },
  {
    "text": "to get the data from different sources.",
    "start": "211590",
    "end": "213599"
  },
  {
    "text": "Make it available in a different format so",
    "start": "213600",
    "end": "215850"
  },
  {
    "text": "that it can be easily\nconsumed by the SageMaker.",
    "start": "215850",
    "end": "217680"
  },
  {
    "text": "- [Andrea] I see, so\ntransforming the data,",
    "start": "217680",
    "end": "220049"
  },
  {
    "text": "pretty much for you?",
    "start": "220050",
    "end": "220883"
  },
  {
    "text": "- [Syed] Yes.",
    "start": "220883",
    "end": "221944"
  },
  {
    "text": "- [Andrea] Into SageMaker, what you do.",
    "start": "221945",
    "end": "223648"
  },
  {
    "text": "Okay, model.",
    "start": "223648",
    "end": "224480"
  },
  {
    "text": "And then in SageMaker,\nyou provide an endpoint,",
    "start": "224481",
    "end": "225870"
  },
  {
    "text": "this is the deployment or testing?",
    "start": "225870",
    "end": "227790"
  },
  {
    "text": "Testing of the model, is that correct?",
    "start": "227790",
    "end": "229379"
  },
  {
    "text": "- So this architecture could be just used",
    "start": "229380",
    "end": "231780"
  },
  {
    "text": "for testing, training",
    "start": "231780",
    "end": "233250"
  },
  {
    "text": "as the last production batch models.",
    "start": "233250",
    "end": "234960"
  },
  {
    "text": "- And production.",
    "start": "234960",
    "end": "235950"
  },
  {
    "text": "- Yes.",
    "start": "235950",
    "end": "236782"
  },
  {
    "text": "- Wonderful, and any given\npoint in time, as a user,",
    "start": "236783",
    "end": "240030"
  },
  {
    "text": "say in this case a data\nscientist, I want to get an update",
    "start": "240030",
    "end": "243209"
  },
  {
    "text": "as to where this is.",
    "start": "243210",
    "end": "245250"
  },
  {
    "text": "- Oh yeah.",
    "start": "245250",
    "end": "246083"
  },
  {
    "text": "- How do you facilitate that?",
    "start": "246083",
    "end": "247019"
  },
  {
    "text": "- Yeah, so when this consumer\ntriggers the jobs, right?",
    "start": "247020",
    "end": "251460"
  },
  {
    "text": "So it writes the message to a Kafka topic.",
    "start": "251460",
    "end": "256242"
  },
  {
    "text": "So that the next sequential\naction can be triggered, right?",
    "start": "256242",
    "end": "258570"
  },
  {
    "text": "And not just that, it\nalso writes the message",
    "start": "258570",
    "end": "260700"
  },
  {
    "text": "to the open source service,",
    "start": "260700",
    "end": "262109"
  },
  {
    "text": "which is our metadata store.",
    "start": "262110",
    "end": "263729"
  },
  {
    "text": "- [Andrea] So you can then\nsee kind of the status.",
    "start": "263730",
    "end": "265410"
  },
  {
    "text": "- [Syed] Exactly.",
    "start": "265410",
    "end": "266698"
  },
  {
    "text": "- [Andrea] Okay.",
    "start": "266698",
    "end": "267531"
  },
  {
    "text": "- So there are APIs which pulls the data",
    "start": "267531",
    "end": "268800"
  },
  {
    "text": "from the open source store\nand release the current state",
    "start": "268800",
    "end": "271289"
  },
  {
    "text": "of job for the users.",
    "start": "271290",
    "end": "273150"
  },
  {
    "text": "- [Andrea] What's the\nfunction of the EventBridge?",
    "start": "273150",
    "end": "274889"
  },
  {
    "text": "- Good question, so the\nentire architecture is",
    "start": "274890",
    "end": "277830"
  },
  {
    "text": "event-driven, like I said.",
    "start": "277830",
    "end": "279270"
  },
  {
    "text": "So when there are jobs status,\nstate changes happening on",
    "start": "279270",
    "end": "282900"
  },
  {
    "text": "the EMR cluster or the\nSageMaker, they are written",
    "start": "282900",
    "end": "286050"
  },
  {
    "text": "or they're actually emitted to\nEventBridge, we consume that.",
    "start": "286050",
    "end": "288960"
  },
  {
    "text": "Right, this consumes the message",
    "start": "288960",
    "end": "292050"
  },
  {
    "text": "and based on the rules it writes\nto, actually it is consumed",
    "start": "292050",
    "end": "296729"
  },
  {
    "text": "by another Fargate consumer,",
    "start": "296730",
    "end": "298380"
  },
  {
    "text": "which writes the messages\nto the Kafka topic,",
    "start": "298380",
    "end": "300030"
  },
  {
    "text": "which determines the\nnext sequence of actions.",
    "start": "300030",
    "end": "301830"
  },
  {
    "text": "- Oh, so you can run many,\nmany different ensembles?",
    "start": "301830",
    "end": "304710"
  },
  {
    "text": "Pretty much, right, of these.",
    "start": "304710",
    "end": "306150"
  },
  {
    "text": "Okay, wonderful.",
    "start": "306150",
    "end": "307620"
  },
  {
    "text": "And I also see another Fargate here.",
    "start": "307620",
    "end": "309570"
  },
  {
    "text": "- [Syed] Oh yeah, so this\nis the last consumer,",
    "start": "309570",
    "end": "313110"
  },
  {
    "text": "which is actually the notifier.",
    "start": "313110",
    "end": "314729"
  },
  {
    "text": "So this consumer or consumers,",
    "start": "314730",
    "end": "318300"
  },
  {
    "text": "so can do sequential steps, right.",
    "start": "318300",
    "end": "321120"
  },
  {
    "text": "But this consumer is the action consumer",
    "start": "321120",
    "end": "323669"
  },
  {
    "text": "or the notify consumer,",
    "start": "323670",
    "end": "325140"
  },
  {
    "text": "which consumers the messages all along",
    "start": "325140",
    "end": "327540"
  },
  {
    "text": "and determines if it is the end",
    "start": "327540",
    "end": "328920"
  },
  {
    "text": "of the execution of a batch campaign.",
    "start": "328920",
    "end": "331215"
  },
  {
    "text": "- [Andrea] Okay.",
    "start": "331215",
    "end": "332048"
  },
  {
    "text": "- [Syed] And when this consumer determines",
    "start": "332048",
    "end": "333510"
  },
  {
    "text": "that it is the end of the execution.",
    "start": "333510",
    "end": "335250"
  },
  {
    "text": "So I write a message to the portal",
    "start": "335250",
    "end": "338310"
  },
  {
    "text": "through different mechanism",
    "start": "338310",
    "end": "339660"
  },
  {
    "text": "and it writes a message to\nthe open source service.",
    "start": "340710",
    "end": "342900"
  },
  {
    "text": "So it lets the consumer...",
    "start": "342900",
    "end": "343860"
  },
  {
    "text": "- [Andrea] Notifies the user.",
    "start": "343860",
    "end": "344939"
  },
  {
    "text": "- [Syed] Exactly.",
    "start": "344940",
    "end": "345773"
  },
  {
    "text": "- Wonderful.",
    "start": "345773",
    "end": "347103"
  },
  {
    "text": "And you're probably running\nthis at scale, is that correct?",
    "start": "347103",
    "end": "349560"
  },
  {
    "text": "So tell us a little bit more.",
    "start": "349560",
    "end": "350760"
  },
  {
    "text": "Like at what scale is this?",
    "start": "350760",
    "end": "352560"
  },
  {
    "text": "- Yeah, we usually run about like hundreds",
    "start": "352560",
    "end": "354780"
  },
  {
    "text": "of batch campaigns,",
    "start": "354780",
    "end": "355800"
  },
  {
    "text": "thousands of models and jobs",
    "start": "355800",
    "end": "357750"
  },
  {
    "text": "and billions of consumers,\nactually tens of billions",
    "start": "357750",
    "end": "360150"
  },
  {
    "text": "of consumers every month.",
    "start": "360150",
    "end": "361620"
  },
  {
    "text": "And it is easily scalable.",
    "start": "361620",
    "end": "363600"
  },
  {
    "text": "That's the whole point of\nthis whole architecture.",
    "start": "363600",
    "end": "365940"
  },
  {
    "text": "- That's really impressive.",
    "start": "365940",
    "end": "367830"
  },
  {
    "text": "Syed, thanks so much\nfor sharing this story.",
    "start": "367830",
    "end": "369960"
  },
  {
    "text": "- Thank you, and absolutely\na pleasure to be here.",
    "start": "369960",
    "end": "373104"
  },
  {
    "text": "(light music)",
    "start": "373105",
    "end": "375605"
  }
]
[
  {
    "start": "0",
    "end": "50000"
  },
  {
    "text": "all right hello everybody uh good to see everybody today",
    "start": "80",
    "end": "7440"
  },
  {
    "text": "uh i am sorry that i haven't been streaming in a while i broke my leg and so i have",
    "start": "7440",
    "end": "13920"
  },
  {
    "text": "been recovering from that i just want to make sure before we get going that the audio is good so",
    "start": "13920",
    "end": "19359"
  },
  {
    "text": "i'm randall uh this is sunil hey guys uh we're gonna be talking to you guys",
    "start": "19359",
    "end": "25439"
  },
  {
    "text": "today about deep learning and mxnet and keras and just basic concepts",
    "start": "25439",
    "end": "32238"
  },
  {
    "text": "around machine learning and deep learning and i am here as a student as well so sunil",
    "start": "32239",
    "end": "38079"
  },
  {
    "text": "is the expert i am the novice and so he's going to be teaching me and i'm going to be asking a",
    "start": "38079",
    "end": "43440"
  },
  {
    "text": "bunch of questions along the way but one of the things that sunil asked me to do before we got started was to",
    "start": "43440",
    "end": "49440"
  },
  {
    "text": "spin up our deep learning ami so i'm going to go ahead and do that now i'm just going to log in to our console here",
    "start": "49440",
    "end": "56239"
  },
  {
    "text": "it shouldn't take very long",
    "start": "56239",
    "end": "59840"
  },
  {
    "text": "um and this is what i call one and a half factors of authentication",
    "start": "62719",
    "end": "69200"
  },
  {
    "text": "because i have a little hotkey that auto generates the uh anyway",
    "start": "70560",
    "end": "76000"
  },
  {
    "text": "so we'll hop over into ec2 and i'm going to launch an instance this",
    "start": "76000",
    "end": "81680"
  },
  {
    "text": "is in us east one i guess i could launch this a little bit closer to home let's go to",
    "start": "81680",
    "end": "87759"
  },
  {
    "text": "us west",
    "start": "87759",
    "end": "90560"
  },
  {
    "text": "so we can launch this instance i am going to do",
    "start": "95040",
    "end": "101520"
  },
  {
    "text": "it's deep learning",
    "start": "101680",
    "end": "108479"
  },
  {
    "text": "so this is the deep learning ami ubuntu version is that the one we want the ubuntu version yes",
    "start": "109040",
    "end": "115040"
  },
  {
    "text": "okay so i'm gonna launch this",
    "start": "115040",
    "end": "120479"
  },
  {
    "text": "oh by the way i'm gonna give you a little hint it's actually not just marketplace now you can actually",
    "start": "122159",
    "end": "129200"
  },
  {
    "text": "get it from the drop down uh within the ami list oh cool",
    "start": "129200",
    "end": "135040"
  },
  {
    "text": "yeah let me actually do that because i've never done that before",
    "start": "135040",
    "end": "142440"
  },
  {
    "text": "in the drop down yeah so if you go back uh just like quick start",
    "start": "143360",
    "end": "148480"
  },
  {
    "text": "and the quick start oh i see it yeah look at that at the uh should i go with",
    "start": "148480",
    "end": "153680"
  },
  {
    "text": "the amazon linux version uh ubuntu is good um",
    "start": "153680",
    "end": "160000"
  },
  {
    "text": "okay",
    "start": "160480",
    "end": "162800"
  },
  {
    "text": "uh all right one seems more up to date too",
    "start": "165840",
    "end": "172239"
  },
  {
    "text": "and because i like cool things i'm gonna go with this p216x large",
    "start": "172239",
    "end": "179390"
  },
  {
    "text": "[Laughter] that's not exactly in keeping with the",
    "start": "179390",
    "end": "184640"
  },
  {
    "text": "frugal nature of amazon but um i think in 8xl um we'll we'll we'll",
    "start": "184640",
    "end": "190480"
  },
  {
    "text": "see we'll uh we'll use some um you know we'll try to use and parallelize with the gpus and see if we can get speed up",
    "start": "190480",
    "end": "197920"
  },
  {
    "text": "but our data set is tiny so uh but definitely that is going to be speed",
    "start": "197920",
    "end": "204319"
  },
  {
    "text": "up using cpu vs gpu",
    "start": "204319",
    "end": "208400"
  },
  {
    "text": "righty let's launch this",
    "start": "211040",
    "end": "215280"
  },
  {
    "text": "so if this is only a two hour broadcast this will only cost like four dollars",
    "start": "217920",
    "end": "223360"
  },
  {
    "text": "not bad i probably should have done a spot instance spotted since we probably could have gotten by with like",
    "start": "224000",
    "end": "230480"
  },
  {
    "text": "30 cents oh well yeah next time next time",
    "start": "230480",
    "end": "235519"
  },
  {
    "text": "so this is gonna launch this is gonna take a second to uh come up i don't think it'll take too long though",
    "start": "235519",
    "end": "241760"
  },
  {
    "text": "yeah it should be less than uh less than a minute usually i don't actually know how to log into",
    "start": "241760",
    "end": "248319"
  },
  {
    "text": "the ubuntu instances we have uh ahmet koloski who's asking what",
    "start": "248319",
    "end": "255439"
  },
  {
    "text": "instance type is good to save money uh you know what we we should be able to train with a cpu so uh like a c4 large",
    "start": "255439",
    "end": "264880"
  },
  {
    "text": "should be good enough but if you um if you if you want to spend a g uh um",
    "start": "264880",
    "end": "271759"
  },
  {
    "text": "use a gpu you can use a g2 um xl as well g two xl so",
    "start": "271759",
    "end": "278639"
  },
  {
    "text": "between between those two you should be good",
    "start": "278639",
    "end": "283840"
  },
  {
    "text": "alrighty",
    "start": "293919",
    "end": "296919"
  },
  {
    "text": "and then imtjk asked if we could balance the levels on the voices uh is it my",
    "start": "300160",
    "end": "306400"
  },
  {
    "text": "voice that's louder or sunils",
    "start": "306400",
    "end": "310680"
  },
  {
    "text": "yeah i can fix that so we're just waiting here for this instance to spin up and then i'm going",
    "start": "326720",
    "end": "332080"
  },
  {
    "text": "to kick it over to the data set and what's going to happen is while uh sumiya's trying to to fix all of this",
    "start": "332080",
    "end": "339600"
  },
  {
    "text": "and build it all i'm going to be following along and asking questions and i'm going to try and do it on",
    "start": "339600",
    "end": "345759"
  },
  {
    "text": "on my side on my screen as well so hopefully we should be able to",
    "start": "345759",
    "end": "352880"
  },
  {
    "text": "get all that situated so this is still initializing",
    "start": "352880",
    "end": "360919"
  },
  {
    "text": "and then we'll show people how to set up a tunnel uh so that they can just",
    "start": "366400",
    "end": "371600"
  },
  {
    "text": "um you know use the browser to connect to this instance yeah sweet okay cool so i have this and",
    "start": "371600",
    "end": "379199"
  },
  {
    "text": "i'm just gonna run talk and",
    "start": "379199",
    "end": "383759"
  },
  {
    "text": "we have a whole lot of stuff this is way cool this is a huge",
    "start": "384240",
    "end": "389680"
  },
  {
    "text": "instance [Laughter]",
    "start": "389680",
    "end": "395390"
  },
  {
    "text": "got 720 gigs of ram yeah uh wow",
    "start": "398720",
    "end": "405120"
  },
  {
    "text": "okay so i think we're good to go i've got my instance for this um",
    "start": "405120",
    "end": "410880"
  },
  {
    "text": "i lowered my voice level a little bit i think we are ready to",
    "start": "410880",
    "end": "416560"
  },
  {
    "text": "switch over to you yeah um you want to show like how to set up jupiter um so just run jupiter",
    "start": "416560",
    "end": "424639"
  },
  {
    "start": "420000",
    "end": "655000"
  },
  {
    "text": "is jupiter already on here yeah so it comes the cool thing about the instance is it comes bundled with all",
    "start": "424639",
    "end": "430960"
  },
  {
    "text": "the deep learning frameworks and all the python libraries an anaconda set up as well",
    "start": "430960",
    "end": "437599"
  },
  {
    "text": "so keras mxnet tensorflow uh cafe all of it is uh available",
    "start": "437599",
    "end": "444400"
  },
  {
    "text": "uh all the cool dnn drivers um everything um is a single click right",
    "start": "444400",
    "end": "449520"
  },
  {
    "text": "like you we didn't need to download all the nvidia drivers so you know in a couple of minutes or three",
    "start": "449520",
    "end": "455280"
  },
  {
    "text": "minutes uh we have a big instance up and running um and also jupiter is available so we",
    "start": "455280",
    "end": "462400"
  },
  {
    "text": "can just uh so i just run like jupiter notebook yeah just jupiter notebook and",
    "start": "462400",
    "end": "468880"
  },
  {
    "text": "you're all good to go i mean you you might want to know hop it so that you know no half an ampersand so it's",
    "start": "468880",
    "end": "475120"
  },
  {
    "text": "running in the background and that's fine so you know why it's not starting yet",
    "start": "475120",
    "end": "482638"
  },
  {
    "text": "oh there we go okay so",
    "start": "483919",
    "end": "489039"
  },
  {
    "text": "um let me like yeah and then one more time you know set up a tunnel",
    "start": "490000",
    "end": "497680"
  },
  {
    "text": "come on",
    "start": "504080",
    "end": "507319"
  },
  {
    "text": "okay and how do i do the tunnel setup uh give me a second i'll give you the",
    "start": "509280",
    "end": "514560"
  },
  {
    "text": "command i imagine it's just like a ssh",
    "start": "514560",
    "end": "519518"
  },
  {
    "text": "yeah let me give you let me paste in the chat so that everybody",
    "start": "520959",
    "end": "527279"
  },
  {
    "text": "has um i'm just modifying the ports to reflect",
    "start": "527279",
    "end": "536560"
  },
  {
    "text": "i haven't set up an ssh tunnel in years but i'm pretty sure it's going to be ssh-capital l and then yeah",
    "start": "542880",
    "end": "550720"
  },
  {
    "text": "so yeah i i pasted that so essentially we're just saying hey uh",
    "start": "550720",
    "end": "558000"
  },
  {
    "text": "localhost mapping on your laptop you know eight eight eight eight and then uh it's running on eight",
    "start": "558000",
    "end": "564800"
  },
  {
    "text": "eight eight a dash i point it to your uh pointed to your pem",
    "start": "564800",
    "end": "571120"
  },
  {
    "text": "key and then ubuntu because we've used ubuntu here ubuntu app the ip address",
    "start": "571120",
    "end": "578240"
  },
  {
    "text": "now folks if you're using amazon linux it would be ec2 user",
    "start": "578240",
    "end": "586879"
  },
  {
    "text": "so i think that worked that looks good so now if i go to localhost",
    "start": "589600",
    "end": "596720"
  },
  {
    "text": "and then yeah you can copy the link that the jupiter notebook through because you'll need the passcode",
    "start": "596720",
    "end": "604480"
  },
  {
    "text": "and they can copy that as yeah we can copy that as well",
    "start": "604480",
    "end": "609040"
  },
  {
    "text": "there you go",
    "start": "610959",
    "end": "614279"
  },
  {
    "text": "sweet so now i have this thing this shindig running on this giant powerful instance with 720",
    "start": "619760",
    "end": "627680"
  },
  {
    "text": "like a couple teraflops of compute i'm excited",
    "start": "627680",
    "end": "632959"
  },
  {
    "text": "okay i'm going to try and follow along with everything that you're going to do next uh okay",
    "start": "632959",
    "end": "638800"
  },
  {
    "text": "but this is so cool like running a notebook remotely yeah all right i like this so far um",
    "start": "638800",
    "end": "645640"
  },
  {
    "text": "okay all right i think uh your screen",
    "start": "647200",
    "end": "652800"
  },
  {
    "text": "yeah awesome uh yeah so what we'll do is we'll um take a really",
    "start": "652800",
    "end": "659040"
  },
  {
    "start": "655000",
    "end": "775000"
  },
  {
    "text": "simple problem which is we'll do sentiment analysis on movie reviews um for simplicity we'll just say",
    "start": "659040",
    "end": "667839"
  },
  {
    "text": "hey the review is positive or the review is negative so we'll just have two two classes essentially",
    "start": "667839",
    "end": "674480"
  },
  {
    "text": "uh is just saying whether or not the words in the post come across as a whole as",
    "start": "674480",
    "end": "683440"
  },
  {
    "text": "positive or as negative yeah so um yeah the model eventually learns uh",
    "start": "683440",
    "end": "690640"
  },
  {
    "text": "how uh it's not just looking for particular um uh it's hard to say but more uh more",
    "start": "690640",
    "end": "697600"
  },
  {
    "text": "likely than not the model actually learns uh how the words interact with each other and the overall sentiment of",
    "start": "697600",
    "end": "705920"
  },
  {
    "text": "um the structure of what we put in there is positive or negative",
    "start": "705920",
    "end": "711360"
  },
  {
    "text": "and at the end we'll we'll use this for movie reviews but uh my aim is that we will type in arbitrary",
    "start": "711360",
    "end": "718880"
  },
  {
    "text": "text and we'll we'll test it at uh as well so if i could have done something like yeah i really hated this it was",
    "start": "718880",
    "end": "727200"
  },
  {
    "text": "awful it like somebody leaving a review of our twitch stream for instance they could say like this is just everything",
    "start": "727200",
    "end": "732800"
  },
  {
    "text": "that's wrong with the world yeah and that would have a negative sentiment",
    "start": "732800",
    "end": "738000"
  },
  {
    "text": "yeah hopefully um uh i'm sure it will so out of curiosity is that like a",
    "start": "738000",
    "end": "743360"
  },
  {
    "text": "binary classification then since it's either positive or negative yeah so um",
    "start": "743360",
    "end": "749600"
  },
  {
    "text": "yeah so we can say that as binary classification but what we'll do is",
    "start": "749600",
    "end": "754800"
  },
  {
    "text": "we'll create two classes and we'll find the probability of how likely is that",
    "start": "754800",
    "end": "761760"
  },
  {
    "text": "sentiment positive and negative so we'll attach probabilities to both rather than just having it uh discretely one or zero",
    "start": "761760",
    "end": "769920"
  },
  {
    "text": "so then it's like a confidence value correct correct cool okay",
    "start": "769920",
    "end": "775120"
  },
  {
    "start": "775000",
    "end": "945000"
  },
  {
    "text": "and this data set has 50 000 movie reviews uh they're all tagged and",
    "start": "775120",
    "end": "780639"
  },
  {
    "text": "labeled so if you can go ahead and download this data set um there'll be x-start",
    "start": "780639",
    "end": "788959"
  },
  {
    "text": "so this is going to be uh ai.stanford.edu",
    "start": "788959",
    "end": "794050"
  },
  {
    "text": "[Music] yeah i'm going to paste it so that oh ",
    "start": "794050",
    "end": "801040"
  },
  {
    "text": "oh i changed my screen sorry guys",
    "start": "801040",
    "end": "805759"
  },
  {
    "text": "all right there you go oh uh i have to figure out what's the best",
    "start": "808000",
    "end": "814639"
  },
  {
    "text": "way to uh post link on uh twitch here let me mod you really fast and then the",
    "start": "814639",
    "end": "820959"
  },
  {
    "text": "link won't get deleted uh all right",
    "start": "820959",
    "end": "826880"
  },
  {
    "text": "just a minute i'll go ahead and post it",
    "start": "826880",
    "end": "831440"
  },
  {
    "text": "okay so i'm gonna download this um",
    "start": "833440",
    "end": "839040"
  },
  {
    "text": "and as you're downloading let me let me start coding here so let's load",
    "start": "839519",
    "end": "846800"
  },
  {
    "text": "the i have to turn off my alexa sorry",
    "start": "846800",
    "end": "851760"
  },
  {
    "text": "the data [Music]",
    "start": "852079",
    "end": "859680"
  },
  {
    "text": "just importing some of the basic libraries here uh so path equal to",
    "start": "859680",
    "end": "866720"
  },
  {
    "text": "so so as you can see i've already",
    "start": "866959",
    "end": "872800"
  },
  {
    "text": "downloaded so ac aclmdb this is the path",
    "start": "872800",
    "end": "879600"
  },
  {
    "text": "so i already like um",
    "start": "881920",
    "end": "885600"
  },
  {
    "text": "oh that was um trying to",
    "start": "895279",
    "end": "900720"
  },
  {
    "text": "trying to just show one level three i've not used this command and",
    "start": "900720",
    "end": "907920"
  },
  {
    "text": "ages one of my favorite things about this ubuntu ami so far is i i was just",
    "start": "907920",
    "end": "913760"
  },
  {
    "text": "grabbing the data and normally i always type i always have this habit of typing wbit but yeah wgit is never installed by",
    "start": "913760",
    "end": "920639"
  },
  {
    "text": "default like curl is always installed by default but that never is and i as soon as i type w get and press",
    "start": "920639",
    "end": "927279"
  },
  {
    "text": "enter i was like oh i'm going to have to pseudo app get install this and then it is actually already installed so thank",
    "start": "927279",
    "end": "932480"
  },
  {
    "text": "you for i hear you i i even have wget on my mac",
    "start": "932480",
    "end": "939120"
  },
  {
    "text": "it's a much uh it's a more preferable tool to download things than curve",
    "start": "939680",
    "end": "944720"
  },
  {
    "text": "um so yeah as you can see like um there's the tree structure",
    "start": "944720",
    "end": "950639"
  },
  {
    "text": "uh of our data set and using that i am going to",
    "start": "950639",
    "end": "956720"
  },
  {
    "text": "um yeah i'm going to try and load all the",
    "start": "956720",
    "end": "964240"
  },
  {
    "text": "almost two i'll just basically create an array of all the paths",
    "start": "964240",
    "end": "972320"
  },
  {
    "text": "it's um um and then we'll just add",
    "start": "981440",
    "end": "987920"
  },
  {
    "text": "uh all the lists basically so for f",
    "start": "987920",
    "end": "993120"
  },
  {
    "text": "f and os dot list",
    "start": "993120",
    "end": "997839"
  },
  {
    "text": "essentially",
    "start": "1002000",
    "end": "1005000"
  },
  {
    "text": "yeah this should should give me so if i were gonna write that in python uh",
    "start": "1012399",
    "end": "1020160"
  },
  {
    "text": "to be like cross-platform i would probably do like os.path that join pass yeah",
    "start": "1020160",
    "end": "1026558"
  },
  {
    "text": "i know yeah i am uh i'm taking shortcuts here given the",
    "start": "1026559",
    "end": "1032798"
  },
  {
    "text": "amount of time and uh i'm not going to be necessarily pepe compliant [Laughter]",
    "start": "1032799",
    "end": "1041490"
  },
  {
    "text": "yeah so so this is just a list comprehension for building out the list of files that",
    "start": "1044000",
    "end": "1049200"
  },
  {
    "text": "we're going to use and this is just the positive files that we're looking at right now yeah now i'll just uh",
    "start": "1049200",
    "end": "1055039"
  },
  {
    "text": "i'll just build a array of uh all the paths essentially a list of all the paths right",
    "start": "1055039",
    "end": "1061440"
  },
  {
    "text": "so it's easier search so train um so we'll keep all the",
    "start": "1061440",
    "end": "1067600"
  },
  {
    "text": "uh uh like we'll keep it alternating so um",
    "start": "1067600",
    "end": "1073120"
  },
  {
    "text": "all right and um so uh practicum",
    "start": "1075440",
    "end": "1080720"
  },
  {
    "text": "i don't know if i'm saying that name right but it's a username so uh we'll just go with it",
    "start": "1080720",
    "end": "1086720"
  },
  {
    "text": "uh says that what approach are we using for sentiment analysis is it naive phase classifier",
    "start": "1086720",
    "end": "1092799"
  },
  {
    "text": "logistic regression or binary classification and i think the answer in this case is that we already have some",
    "start": "1092799",
    "end": "1098880"
  },
  {
    "text": "form of classification that's coming in from this data set like they've already been",
    "start": "1098880",
    "end": "1105360"
  },
  {
    "text": "categorized into positive reviews or negative reviews whether that was done by humans or some other method",
    "start": "1105360",
    "end": "1110480"
  },
  {
    "text": "we we have some idea and what we're doing is we're using that classification",
    "start": "1110480",
    "end": "1115520"
  },
  {
    "text": "to build a model that can recognize future examples",
    "start": "1115520",
    "end": "1122679"
  },
  {
    "text": "is that accurate or am i totally off yeah no no that's fair um i think",
    "start": "1122720",
    "end": "1127919"
  },
  {
    "text": "what the user probably is asking is what method are we going to use so it's going to come to that after we",
    "start": "1127919",
    "end": "1134160"
  },
  {
    "text": "do data but uh at a higher we'll use multi-layer perceptron um so it's one of the simplest uh",
    "start": "1134160",
    "end": "1141760"
  },
  {
    "text": "uh simplest neural network they're random multi-layer perceptron that sounds like",
    "start": "1141760",
    "end": "1148000"
  },
  {
    "text": "a transformer what exactly is that um",
    "start": "1148000",
    "end": "1153919"
  },
  {
    "text": "i'll i'll start um you know once we load the data i think we'll wait for more users to come in",
    "start": "1153919",
    "end": "1159919"
  },
  {
    "start": "1155000",
    "end": "1435000"
  },
  {
    "text": "i have a whole slide on some of the basics uh you know well we'll we'll go",
    "start": "1159919",
    "end": "1164960"
  },
  {
    "text": "we'll get there slowly um so let's uh um like i want to talk about how we format",
    "start": "1164960",
    "end": "1172960"
  },
  {
    "text": "the data how to think about the data first and kind of bridge the gap between data to problem and then we",
    "start": "1172960",
    "end": "1180160"
  },
  {
    "text": "can go into how we actually end up solving the problem so okay for folks who are curious",
    "start": "1180160",
    "end": "1186240"
  },
  {
    "text": "multi-layer perceptron um that's a that's a very easy network to comprehend",
    "start": "1186240",
    "end": "1193039"
  },
  {
    "text": "but the concepts that we're going to learn are applicable to future complex networks that we'll build in this series",
    "start": "1193039",
    "end": "1201600"
  },
  {
    "text": "okay all right i never know if uh this is gonna compile but we'll see",
    "start": "1204880",
    "end": "1211440"
  },
  {
    "text": "um um what you're gonna do is",
    "start": "1211440",
    "end": "1217919"
  },
  {
    "text": "so for each file um actually i don't think this is gonna work because what we",
    "start": "1217919",
    "end": "1222960"
  },
  {
    "text": "want is a list of all files instead of expanded array",
    "start": "1222960",
    "end": "1229200"
  },
  {
    "text": "yeah i think you're missing a comma by the way on the um yeah um",
    "start": "1229200",
    "end": "1236559"
  },
  {
    "text": "well you know what i i probably could just append",
    "start": "1236640",
    "end": "1242640"
  },
  {
    "text": "right this is why i love jupiter i'm going to show you why i love jupiter now um",
    "start": "1244000",
    "end": "1251600"
  },
  {
    "text": "so i'm slowly but surely following along here i am writing the code in my own way though yeah you should uh yeah we have a",
    "start": "1258400",
    "end": "1264559"
  },
  {
    "text": "cleaner way of doing uh than i have so i'm trying to keep up though and talk at",
    "start": "1264559",
    "end": "1270480"
  },
  {
    "text": "the same time we'll see if i can actually do that when you say where it's like multi-layer",
    "start": "1270480",
    "end": "1275919"
  },
  {
    "text": "perceptron i start to get pretty scared",
    "start": "1275919",
    "end": "1279840"
  },
  {
    "text": "i'll just see oops there you go first syntax error",
    "start": "1282159",
    "end": "1289679"
  },
  {
    "text": "second two i think it's just uh it doesn't like",
    "start": "1289679",
    "end": "1297039"
  },
  {
    "text": "uh all right yep",
    "start": "1298320",
    "end": "1304400"
  },
  {
    "text": "fun of life coding nope uh i think that's where the os dot path",
    "start": "1304400",
    "end": "1312080"
  },
  {
    "text": "that join thing failed so yeah yep no i i actually think it's on the train",
    "start": "1312080",
    "end": "1319200"
  },
  {
    "text": "and test or maybe on the end of the path variable",
    "start": "1319200",
    "end": "1324320"
  },
  {
    "text": "oh yeah sorry yeah of course yep",
    "start": "1324400",
    "end": "1330919"
  },
  {
    "text": "yeah see i think uh we've got we've got what we want so that now we can iterate through all the files",
    "start": "1333919",
    "end": "1340559"
  },
  {
    "text": "um also um i'd say like most of the common data sets that people you end up using",
    "start": "1340559",
    "end": "1347120"
  },
  {
    "text": "is the mnist dataset which is which is essentially handwritten digit",
    "start": "1347120",
    "end": "1354000"
  },
  {
    "text": "recognition and frankly it seems like it's been beaten to death by",
    "start": "1354000",
    "end": "1359600"
  },
  {
    "text": "so many people so i wanted to try and use a different data set here which is a little cooler",
    "start": "1359600",
    "end": "1366240"
  },
  {
    "text": "so i want to thank david ping one of uh colleagues here",
    "start": "1366240",
    "end": "1371520"
  },
  {
    "text": "who attempted to do it with this data set so thanks to him",
    "start": "1371520",
    "end": "1378000"
  },
  {
    "text": "and then uh should we have one",
    "start": "1378000",
    "end": "1383200"
  },
  {
    "text": "jeff bart points out that we have slash test slash neg twice should one of those be slash test slash",
    "start": "1383200",
    "end": "1388799"
  },
  {
    "text": "pause oh yes thanks jeff good call",
    "start": "1388799",
    "end": "1396000"
  },
  {
    "text": "thank you um all right uh for",
    "start": "1396960",
    "end": "1402880"
  },
  {
    "text": "f and files uh now um what we'll do is we'll open up so we'll",
    "start": "1402880",
    "end": "1409039"
  },
  {
    "text": "read the file right um and uh we'll strip some uh characters out um so",
    "start": "1409039",
    "end": "1416799"
  },
  {
    "text": "for example you know let's let's take a look at this",
    "start": "1416799",
    "end": "1422000"
  },
  {
    "text": "file see what the contents look like",
    "start": "1422000",
    "end": "1427400"
  },
  {
    "text": "well um yeah some of these uh uh have like angle",
    "start": "1432080",
    "end": "1438240"
  },
  {
    "start": "1435000",
    "end": "1905000"
  },
  {
    "text": "braces and so on so we'll um we'll need a regular expression",
    "start": "1438240",
    "end": "1444640"
  },
  {
    "text": "um to substitute for those things um",
    "start": "1444640",
    "end": "1450960"
  },
  {
    "text": "yeah so and also what we'll do is we'll just create our",
    "start": "1450960",
    "end": "1456080"
  },
  {
    "text": "uh what we'll call is um input",
    "start": "1456080",
    "end": "1461600"
  },
  {
    "text": "our input text essentially uh we'll we'll create a 5 50 000 large",
    "start": "1461600",
    "end": "1467919"
  },
  {
    "text": "uh vector essentially where we'll store all of this we'll we'll iterate through all the",
    "start": "1467919",
    "end": "1474080"
  },
  {
    "text": "files uh we'll remove whatever uh characters that we don't need and we'll put it in here",
    "start": "1474080",
    "end": "1480720"
  },
  {
    "text": "so files um uh we can do something like",
    "start": "1480720",
    "end": "1488400"
  },
  {
    "text": "i'm gonna just i mean i don't want to do inline i want to be more readable",
    "start": "1488400",
    "end": "1495600"
  },
  {
    "text": "uh huh",
    "start": "1496000",
    "end": "1499720"
  },
  {
    "text": "uh huh holies so we have this",
    "start": "1501600",
    "end": "1507120"
  },
  {
    "text": "yeah a little bit easier than yeah to read readability so",
    "start": "1507120",
    "end": "1513360"
  },
  {
    "text": "f dot read lines um well this will essentially give us all the lines right so",
    "start": "1513360",
    "end": "1519360"
  },
  {
    "text": "um what what we want to do is uh we'll say",
    "start": "1519360",
    "end": "1526880"
  },
  {
    "text": "i'll put equal to we'll we'll have some i'll define a function called remove tags",
    "start": "1527039",
    "end": "1533679"
  },
  {
    "text": "uh that's going to do this from uh do this functionality for us so remove tags is going to take",
    "start": "1533679",
    "end": "1541520"
  },
  {
    "text": "uh we're just going to keep going i'm just saying i gotta catch up with you here because i had paused to like",
    "start": "1541520",
    "end": "1547520"
  },
  {
    "text": "watch but now um [Music]",
    "start": "1547520",
    "end": "1553160"
  },
  {
    "text": "something like this we're just going to substitute uh the text just nothing but we need to",
    "start": "1553760",
    "end": "1560000"
  },
  {
    "text": "create the our tag regular expression so re dot",
    "start": "1560000",
    "end": "1566559"
  },
  {
    "text": "compile no uh yeah compile yes i think so",
    "start": "1566559",
    "end": "1572000"
  },
  {
    "text": "we're gonna say angle braces um what else um",
    "start": "1572000",
    "end": "1578799"
  },
  {
    "text": "right um [Music]",
    "start": "1581000",
    "end": "1587479"
  },
  {
    "text": "well i don't know it's been a while since i've done",
    "start": "1588480",
    "end": "1593600"
  },
  {
    "text": "always gets this is always uh you know it's like i feel envious about people who can just write regular expressions",
    "start": "1593600",
    "end": "1600000"
  },
  {
    "text": "immediately um i think this is good enough for now um",
    "start": "1600000",
    "end": "1606880"
  },
  {
    "text": "yeah if you're just looking for those two things that should be good and then uh x",
    "start": "1610000",
    "end": "1615760"
  },
  {
    "text": "z zero points out that you need to do out plus equals probably yeah no no i'm gonna uh i'm gonna add it",
    "start": "1615760",
    "end": "1622960"
  },
  {
    "text": "to uh so essentially um not the most pythonic",
    "start": "1622960",
    "end": "1629520"
  },
  {
    "text": "of ways but we'll do it out actually what we need to do is join",
    "start": "1629520",
    "end": "1636559"
  },
  {
    "text": "all the words together so let's paste our chime",
    "start": "1636559",
    "end": "1642080"
  },
  {
    "text": "okay let's see what happens nope expected string or buffer",
    "start": "1642720",
    "end": "1650240"
  },
  {
    "text": "okay attacks read lines um redlines is going to come in as an array",
    "start": "1650240",
    "end": "1656559"
  },
  {
    "text": "of lines i think yeah um if you want the regex to apply",
    "start": "1656559",
    "end": "1663200"
  },
  {
    "text": "go globally i think you can put a flag in there like re.global that'll",
    "start": "1663200",
    "end": "1668640"
  },
  {
    "text": "go across lines and then you can put like a raw string in front of that yeah i i",
    "start": "1668640",
    "end": "1673840"
  },
  {
    "text": "you know what yeah so",
    "start": "1673840",
    "end": "1679039"
  },
  {
    "text": "what what i probably i'll just join the lines um so what i'll do here is",
    "start": "1679039",
    "end": "1687600"
  },
  {
    "text": "right because yeah i'll just join all the lines and give it a single text",
    "start": "1687919",
    "end": "1694640"
  },
  {
    "text": "yeah that should do it yeah that worked",
    "start": "1695840",
    "end": "1700720"
  },
  {
    "text": "well that seems reasonable",
    "start": "1703279",
    "end": "1708120"
  },
  {
    "text": "okay all right so so now comes um",
    "start": "1712480",
    "end": "1719200"
  },
  {
    "text": "the the portion right so we we don't necessarily deal with sentences but we want to deal with words because",
    "start": "1719200",
    "end": "1726000"
  },
  {
    "text": "we want to see how words interact with each other so",
    "start": "1726000",
    "end": "1731679"
  },
  {
    "text": "in general text processing natural language processing there's a whole",
    "start": "1731679",
    "end": "1737520"
  },
  {
    "text": "is a whole process where we tokenize uh the sentences so what we'll do is we'll",
    "start": "1737520",
    "end": "1742960"
  },
  {
    "text": "break down we'll just keep a dictionary of words essentially that um",
    "start": "1742960",
    "end": "1749279"
  },
  {
    "text": "that that occurs in our corpus so whatever the movie corpus that we",
    "start": "1749279",
    "end": "1756159"
  },
  {
    "text": "have let's get what all the unique words exist and we'll just keep a mapping of where and how these",
    "start": "1756159",
    "end": "1762880"
  },
  {
    "text": "words occur so because ultimately the neural network doesn't understand",
    "start": "1762880",
    "end": "1768960"
  },
  {
    "text": "um say sentences you know we need uh it it just knows oh uh this word number 55",
    "start": "1768960",
    "end": "1777840"
  },
  {
    "text": "appeared here and 60 appeared next to it seems like there's a big pattern of 55",
    "start": "1777840",
    "end": "1783120"
  },
  {
    "text": "and 60 appearing together so that's what ultimately the network learns so we need to convert into that format",
    "start": "1783120",
    "end": "1790640"
  },
  {
    "text": "and is it just single pairs of words is it three words is it",
    "start": "1790640",
    "end": "1796320"
  },
  {
    "text": "four words does it yeah so yeah so that's a good question so uh",
    "start": "1796320",
    "end": "1801440"
  },
  {
    "text": "there are techniques where we will take something called as bag of words or continuous uh",
    "start": "1801440",
    "end": "1806880"
  },
  {
    "text": "uh you know we'll we'll do a sliding window um in this case we'll just do very simple uh we'll just take each word as",
    "start": "1806880",
    "end": "1814080"
  },
  {
    "text": "it is okay so we'll just take single word and is that like we're assigning a word a",
    "start": "1814080",
    "end": "1819440"
  },
  {
    "text": "numeric value because you know each unique word is going to get some sort of numeric value",
    "start": "1819440",
    "end": "1824799"
  },
  {
    "text": "and then that word is going to have a",
    "start": "1824799",
    "end": "1829919"
  },
  {
    "text": "basically a vector that moves the entire sentence or phrase in a direction of",
    "start": "1829919",
    "end": "1835039"
  },
  {
    "text": "positive or negative uh the collection essentially yes um so we'll come to that particular aspect as",
    "start": "1835039",
    "end": "1842159"
  },
  {
    "text": "we dive into how the neural network behaves um but for now i think the the intuition",
    "start": "1842159",
    "end": "1848399"
  },
  {
    "text": "is we need to break down uh the sentences into words uh and we're looking at word relations",
    "start": "1848399",
    "end": "1854960"
  },
  {
    "text": "okay um so that's that's what so what we'll do is we'll use a library from",
    "start": "1854960",
    "end": "1860240"
  },
  {
    "text": "keras which actually has some pre-processing things like a tokenizer so what it will do is",
    "start": "1860240",
    "end": "1868240"
  },
  {
    "text": "tokenize break all the words but also it's going to build an index uh essentially given a word uh you know",
    "start": "1868240",
    "end": "1875600"
  },
  {
    "text": "which um you know which words occur in which documents and so on",
    "start": "1875600",
    "end": "1881279"
  },
  {
    "text": "so it's pretty pretty useful we won't use the inverted index necessarily here",
    "start": "1881279",
    "end": "1886480"
  },
  {
    "text": "but we want unique tokens so i think it's here cast.pre-processing",
    "start": "1886480",
    "end": "1895880"
  },
  {
    "text": "processing so we will use this library",
    "start": "1900559",
    "end": "1907519"
  },
  {
    "start": "1905000",
    "end": "2172000"
  },
  {
    "text": "before we jump into this what is keras exactly sorry so yeah so keras is a high level",
    "start": "1907519",
    "end": "1915919"
  },
  {
    "text": "um you know deep learning interface um which",
    "start": "1915919",
    "end": "1921279"
  },
  {
    "text": "which actually understands on top of other frameworks so what it does is um",
    "start": "1921279",
    "end": "1927360"
  },
  {
    "text": "you know as uh you know say deep learning frameworks kind of came about um when there was theano and tensorflow",
    "start": "1927360",
    "end": "1934640"
  },
  {
    "text": "it appeared to be more complex because of the declarative nature of the frameworks",
    "start": "1934640",
    "end": "1942960"
  },
  {
    "text": "so you know franco francois came up with uh keras uh",
    "start": "1942960",
    "end": "1950240"
  },
  {
    "text": "essentially building a a simpler kind of abstraction over uh",
    "start": "1950240",
    "end": "1955760"
  },
  {
    "text": "so that it was much easier for developers to pick up so",
    "start": "1955760",
    "end": "1961440"
  },
  {
    "text": "uh keras currently actually has uh uh mxnet as a back end as well so you can",
    "start": "1961440",
    "end": "1966720"
  },
  {
    "text": "have um theano tensorflow or mxnet so you can",
    "start": "1966720",
    "end": "1972240"
  },
  {
    "text": "write code in keras but switch the actual underlying uh back-end",
    "start": "1972240",
    "end": "1978000"
  },
  {
    "text": "and it's pretty uh useful for people who want to you know already have keras code uh we announced uh um you know",
    "start": "1978000",
    "end": "1985519"
  },
  {
    "text": "the community announced support for uh keras 1.2 two um as i maxing it as a back end",
    "start": "1985519",
    "end": "1993039"
  },
  {
    "text": "and given the scalability that mxnet has um you know across multiple gpus it's",
    "start": "1993039",
    "end": "2000240"
  },
  {
    "text": "really cool you can take the same code now run across multiple gpus with minimal change",
    "start": "2000240",
    "end": "2005360"
  },
  {
    "text": "uh and i'll i'll come yeah so we'll we'll just import",
    "start": "2005360",
    "end": "2013679"
  },
  {
    "text": "um",
    "start": "2016000",
    "end": "2019000"
  },
  {
    "text": "okay so um yeah so",
    "start": "2023919",
    "end": "2029519"
  },
  {
    "text": "let me see the twitch channel it's hard to switch between have any questions",
    "start": "2029519",
    "end": "2037440"
  },
  {
    "text": "oh there you go i think people are talking about chaos",
    "start": "2039760",
    "end": "2044240"
  },
  {
    "text": "i think it's weird that mccandy's code got listed as a deleted link because it's definitely not",
    "start": "2045279",
    "end": "2052960"
  },
  {
    "text": "he's but the the code that mccandy posted or mccandy7 posted was just review.scan looking for the word",
    "start": "2052960",
    "end": "2059599"
  },
  {
    "text": "good uh one or more instances it's just a regex or bad one or more instances",
    "start": "2059599",
    "end": "2065599"
  },
  {
    "text": "and then returning the count and figuring out which one is more but the problem is",
    "start": "2065599",
    "end": "2071679"
  },
  {
    "text": "uh if you do that you um",
    "start": "2071679",
    "end": "2077520"
  },
  {
    "text": "what about the phrase not bad not bad has a positive sentiment",
    "start": "2077520",
    "end": "2083679"
  },
  {
    "text": "so tokenizer so you can see it takes uh",
    "start": "2085040",
    "end": "2090480"
  },
  {
    "text": "so if you look at what the tokenizer takes it takes a number of words uh so",
    "start": "2090639",
    "end": "2096638"
  },
  {
    "text": "essentially when we talk tokenize we want to say hey uh this is our working set of you know",
    "start": "2096639",
    "end": "2103920"
  },
  {
    "text": "words certain words we're not really interested in so we're going to chop and discard that",
    "start": "2103920",
    "end": "2109599"
  },
  {
    "text": "and then we can have filters and so on so we're going to say",
    "start": "2109599",
    "end": "2116640"
  },
  {
    "text": "so i'm just choosing um 10 000 is a good number right so we'll just have 10 000 words in our",
    "start": "2116640",
    "end": "2123200"
  },
  {
    "text": "vocabulary and we'll tokenize them um so talk dot fit sentences i think it's",
    "start": "2123200",
    "end": "2131680"
  },
  {
    "text": "all fixed now fit on",
    "start": "2131680",
    "end": "2135200"
  },
  {
    "text": "let's see yeah so we'll use this method fit on",
    "start": "2137839",
    "end": "2143599"
  },
  {
    "text": "texts to essentially take this entire corpus that we have and",
    "start": "2143599",
    "end": "2150640"
  },
  {
    "text": "generate our tokens",
    "start": "2150640",
    "end": "2153760"
  },
  {
    "text": "text um so what i'll do is i'm just gonna run that",
    "start": "2156560",
    "end": "2162640"
  },
  {
    "text": "and oops sorry fit on text and this used a gpu it looks like",
    "start": "2165680",
    "end": "2173040"
  },
  {
    "start": "2172000",
    "end": "2450000"
  },
  {
    "text": "uh well uh so um so thiano",
    "start": "2173040",
    "end": "2179520"
  },
  {
    "text": "you know outputs what it's actually present the tokenizer itself",
    "start": "2179520",
    "end": "2185760"
  },
  {
    "text": "doesn't necessarily use the gpu so we can uh we can",
    "start": "2185760",
    "end": "2191838"
  },
  {
    "text": "we'll just inspect what's in that object right so it's fun to see so as you can see",
    "start": "2193599",
    "end": "2199520"
  },
  {
    "text": "there's a word index there are word counts uh index docs",
    "start": "2199520",
    "end": "2204640"
  },
  {
    "text": "um so very very useful kind of people who have done um say tf idf processing and",
    "start": "2204640",
    "end": "2210800"
  },
  {
    "text": "you know word so this can this can do pretty efficiently",
    "start": "2210800",
    "end": "2216880"
  },
  {
    "text": "um kind of just one stop all there are other libraries as well like",
    "start": "2216880",
    "end": "2222079"
  },
  {
    "text": "mltk there's some stuff with nltk that can do",
    "start": "2222079",
    "end": "2227520"
  },
  {
    "text": "this but what i like here is it's kind of this pre-processing library has brought",
    "start": "2227520",
    "end": "2233359"
  },
  {
    "text": "all the goodies together just kind of what we need so it's a much cleaner interface i feel",
    "start": "2233359",
    "end": "2240839"
  },
  {
    "text": "than using nltk a bunch of stuff in nltk that's totally an option as well",
    "start": "2240839",
    "end": "2249200"
  },
  {
    "text": "okay um so the next thing is um",
    "start": "2253760",
    "end": "2261039"
  },
  {
    "text": "actually um what i'm going to do is only use",
    "start": "2266000",
    "end": "2271079"
  },
  {
    "text": "huh that's okay i was just thinking if we should reduce the set uh but not the problem when you say reduce the set",
    "start": "2271680",
    "end": "2278400"
  },
  {
    "text": "what's the advantage of that because i i noticed that you put in like the numbers i was thinking like do we really need",
    "start": "2278400",
    "end": "2284720"
  },
  {
    "text": "all the documents is kind of what i was thinking like some of the words are repeated and so on but",
    "start": "2284720",
    "end": "2290079"
  },
  {
    "text": "um that's fine we'll we'll see we'll we'll change if we need to",
    "start": "2290079",
    "end": "2297119"
  },
  {
    "text": "now the next uh process is actually creating our training set so we'll",
    "start": "2297200",
    "end": "2302640"
  },
  {
    "text": "create our training and test that so um we're lucky that our data set is already kind of shaped into you know",
    "start": "2302640",
    "end": "2309280"
  },
  {
    "text": "training set and test set but typically when you get data what",
    "start": "2309280",
    "end": "2315599"
  },
  {
    "text": "we'll do is uh split it into three ways so what we'll do is split into training",
    "start": "2315599",
    "end": "2321119"
  },
  {
    "text": "set validation set and a test set um so a test set is when you know our",
    "start": "2321119",
    "end": "2328560"
  },
  {
    "text": "model is completely ready or uh data that the model hasn't seen at all",
    "start": "2328560",
    "end": "2334240"
  },
  {
    "text": "uh we can just uh run so that we see the accuracy",
    "start": "2334240",
    "end": "2339359"
  },
  {
    "text": "but typically we'll use a validation set along with a training set when we train",
    "start": "2339359",
    "end": "2345359"
  },
  {
    "text": "so the idea there is we'll keep this validation set hidden from",
    "start": "2345359",
    "end": "2350960"
  },
  {
    "text": "um from uh the model as we run through you",
    "start": "2350960",
    "end": "2356079"
  },
  {
    "text": "know different iterations the idea there is um you know as the model kind of sees",
    "start": "2356079",
    "end": "2362720"
  },
  {
    "text": "the same kind of data it really learns the pattern right and",
    "start": "2362720",
    "end": "2368160"
  },
  {
    "text": "we don't we don't necessarily want that completely because ultimately the model is going to predict",
    "start": "2368160",
    "end": "2374079"
  },
  {
    "text": "on something that is novel so is that like over training",
    "start": "2374079",
    "end": "2379440"
  },
  {
    "text": "yeah so overfitting it's called overfitting okay yeah so the validation set what it does is",
    "start": "2379440",
    "end": "2386480"
  },
  {
    "text": "it keeps an eye so we we look at you know how accurate it is um",
    "start": "2386480",
    "end": "2392560"
  },
  {
    "text": "as we go um oh randall yeah my my video cut out",
    "start": "2392560",
    "end": "2399119"
  },
  {
    "text": "sorry okay all right just just confirming",
    "start": "2399119",
    "end": "2405119"
  },
  {
    "text": "all right you can keep going you can still hear me right yeah so um so yeah the validation uh you know",
    "start": "2408800",
    "end": "2416880"
  },
  {
    "text": "kind of set keeps it in check so ideally we want the point where",
    "start": "2416880",
    "end": "2423040"
  },
  {
    "text": "uh yeah ideally if you're training the validation accuracy and the um",
    "start": "2423040",
    "end": "2429359"
  },
  {
    "text": "training accuracy increases uh together so let me actually um",
    "start": "2429359",
    "end": "2435950"
  },
  {
    "text": "[Music]",
    "start": "2435950",
    "end": "2439089"
  },
  {
    "text": "this is really cool um i'll just keep this",
    "start": "2443520",
    "end": "2450160"
  },
  {
    "start": "2450000",
    "end": "2952000"
  },
  {
    "text": "oh yeah so do you see this uh curve",
    "start": "2450160",
    "end": "2455119"
  },
  {
    "text": "uh i do yes all right yeah so what as you can see look at the",
    "start": "2455520",
    "end": "2461520"
  },
  {
    "text": "blue one right like where uh when there's overfitting what you'll see is the validation accuracy will drop",
    "start": "2461520",
    "end": "2468560"
  },
  {
    "text": "it doesn't go along with the training accuracy so in the blue line essentially",
    "start": "2468560",
    "end": "2475040"
  },
  {
    "text": "uh you know this sort of this point or this area is where our best model",
    "start": "2475040",
    "end": "2480400"
  },
  {
    "text": "generalized model uh you know is there so",
    "start": "2480400",
    "end": "2485680"
  },
  {
    "text": "so this is kind of where we want ideally if our models learning really",
    "start": "2485680",
    "end": "2492880"
  },
  {
    "text": "generalize things we'll see the green curve in terms of validation accuracy",
    "start": "2492880",
    "end": "2499440"
  },
  {
    "text": "okay okay okay so let's go um",
    "start": "2500079",
    "end": "2507119"
  },
  {
    "text": "so we'll um we'll actually do is um we'll",
    "start": "2507119",
    "end": "2513280"
  },
  {
    "text": "we'll um we'll actually uh now",
    "start": "2513280",
    "end": "2519359"
  },
  {
    "text": "change uh or rather will convert the text uh to sequences so",
    "start": "2519359",
    "end": "2524400"
  },
  {
    "text": "the idea is um our model does not necessarily",
    "start": "2524400",
    "end": "2529440"
  },
  {
    "text": "understand words right so so the sequence is going to convert it into numbers we're going to replace",
    "start": "2529440",
    "end": "2535119"
  },
  {
    "text": "words with numbers so i'll show you what i mean uh text to",
    "start": "2535119",
    "end": "2541119"
  },
  {
    "text": "sequence sequences i think it's sequence",
    "start": "2541119",
    "end": "2546160"
  },
  {
    "text": "um so input text",
    "start": "2546160",
    "end": "2551920"
  },
  {
    "text": "so we only want the training data right so we have 50 000 so we're only going to get 25 000 here",
    "start": "2551920",
    "end": "2560799"
  },
  {
    "text": "i've added sequences no",
    "start": "2562079",
    "end": "2566160"
  },
  {
    "text": "aha twitch fit on c twitch fit on is asking uh if it makes sense to do any",
    "start": "2567920",
    "end": "2575040"
  },
  {
    "text": "shuffling of the training validation and test sets absolutely",
    "start": "2575040",
    "end": "2580880"
  },
  {
    "text": "shuffling is a good idea so what we're going to do later is we're going to declare iterators",
    "start": "2580880",
    "end": "2588720"
  },
  {
    "text": "in mxnet and we'll just literally set a flag says shuffle equal to true and that's going to do all the magic for us",
    "start": "2588720",
    "end": "2596960"
  },
  {
    "text": "awesome so let's you know let's inspect",
    "start": "2599119",
    "end": "2605040"
  },
  {
    "text": "um",
    "start": "2605040",
    "end": "2607839"
  },
  {
    "text": "something's off here uh so it didn't return anything",
    "start": "2612400",
    "end": "2618079"
  },
  {
    "text": "fit on sequences fit on sequence um",
    "start": "2618079",
    "end": "2625040"
  },
  {
    "text": "i have to move my laptop to see the bottom of your screen i think i'm using the wrong",
    "start": "2626319",
    "end": "2634920"
  },
  {
    "text": "i think i'm using the wrong what's it called i think it's uh we're converting from text right so text",
    "start": "2637839",
    "end": "2644160"
  },
  {
    "text": "to sequences that's probably what was",
    "start": "2644160",
    "end": "2651520"
  },
  {
    "text": "aha gotcha and that's what's giving it those correct okay",
    "start": "2651520",
    "end": "2656640"
  },
  {
    "text": "see that um so let's do some sanity right so let's do",
    "start": "2656640",
    "end": "2662480"
  },
  {
    "text": "length of and length of you know",
    "start": "2662480",
    "end": "2668800"
  },
  {
    "text": "i input text of zero",
    "start": "2668800",
    "end": "2672319"
  },
  {
    "text": "so certain things have been uh you know chopped because",
    "start": "2674720",
    "end": "2680319"
  },
  {
    "text": "we really didn't need them gotcha",
    "start": "2680319",
    "end": "2686319"
  },
  {
    "text": "and there's a reason you're you're only passing in like the first 25 000",
    "start": "2686319",
    "end": "2691520"
  },
  {
    "text": "no that's our positive uh so that's our first uh um 25k",
    "start": "2691520",
    "end": "2697440"
  },
  {
    "text": "um because that's the entirety of our",
    "start": "2697440",
    "end": "2702640"
  },
  {
    "text": "training data set right so in our training data set remember um",
    "start": "2702640",
    "end": "2708319"
  },
  {
    "text": "yeah i get that we joined it all together but is there a reason we're keeping that like all in the same variable",
    "start": "2708319",
    "end": "2714160"
  },
  {
    "text": "because we have to do this yeah so that's our that's our entire training set so this is our training corpus is 25",
    "start": "2714160",
    "end": "2720319"
  },
  {
    "text": "000. uh we're going to keep the next 25 000 for training so what we'll do is something like this x train",
    "start": "2720319",
    "end": "2729359"
  },
  {
    "text": "equal to so let's redo this but we'll just switch the",
    "start": "2729359",
    "end": "2736079"
  },
  {
    "text": "right so that'll be our that x for input so we'll have our y so",
    "start": "2736079",
    "end": "2742800"
  },
  {
    "text": "we'll use x as our input y as our label so essentially so x test will be our the",
    "start": "2742800",
    "end": "2749680"
  },
  {
    "text": "rest of the um gotcha okay",
    "start": "2749680",
    "end": "2756240"
  },
  {
    "text": "um but we also need the uh the y right so",
    "start": "2756240",
    "end": "2761760"
  },
  {
    "text": "y train um so we we actually need to",
    "start": "2761760",
    "end": "2767599"
  },
  {
    "text": "generate our labels right so",
    "start": "2767599",
    "end": "2772200"
  },
  {
    "text": "our label said this is actually easy because uh if you think about",
    "start": "2774079",
    "end": "2779200"
  },
  {
    "text": "uh we have very sequential labels right so we have uh our training set which is 25 000 but we have",
    "start": "2779200",
    "end": "2787359"
  },
  {
    "text": "12 and a half k as our um as our positive uh",
    "start": "2787359",
    "end": "2793680"
  },
  {
    "text": "reviews uh and then our negative reviews right so um",
    "start": "2793680",
    "end": "2799760"
  },
  {
    "text": "so so what we'll do is uh we'll say",
    "start": "2799760",
    "end": "2806880"
  },
  {
    "text": "labels equal to so we we can we can declare um we'll",
    "start": "2807839",
    "end": "2813440"
  },
  {
    "text": "just declare our tuple so we'll say",
    "start": "2813440",
    "end": "2819280"
  },
  {
    "text": "we'll give negative positive as one so into twelve thousand five hundred",
    "start": "2819280",
    "end": "2828440"
  },
  {
    "text": "right does that make sense",
    "start": "2830079",
    "end": "2833280"
  },
  {
    "text": "i'm bad at math but yes sorry yeah that's",
    "start": "2836160",
    "end": "2842480"
  },
  {
    "text": "there you go but remember um",
    "start": "2842480",
    "end": "2847280"
  },
  {
    "text": "so we need to multiply this by two because for our test set so we'll have our 50 000",
    "start": "2849040",
    "end": "2854160"
  },
  {
    "text": "essentially we have our 50 000 uh labels so this will be",
    "start": "2854160",
    "end": "2859920"
  },
  {
    "text": "our for our training data set our labels will be you know",
    "start": "2859920",
    "end": "2865119"
  },
  {
    "text": "like this and y test",
    "start": "2865119",
    "end": "2871720"
  },
  {
    "text": "right okay",
    "start": "2874160",
    "end": "2879680"
  },
  {
    "text": "uh zeeb asks why we chose a 50 50 split for a chain and test when most people",
    "start": "2879680",
    "end": "2884720"
  },
  {
    "text": "choose 80 20 or 90 10. um nothing in particular we just happen to",
    "start": "2884720",
    "end": "2891200"
  },
  {
    "text": "have the data set this way we're lucky in this data set that we have enough samples for testing",
    "start": "2891200",
    "end": "2897760"
  },
  {
    "text": "but generally anywhere between 10 to 30 percent is a really good idea to",
    "start": "2897760",
    "end": "2904800"
  },
  {
    "text": "keep aside gotcha",
    "start": "2904800",
    "end": "2909960"
  },
  {
    "text": "just because i mean it's arranged that way right so uh i thought it'd be",
    "start": "2914079",
    "end": "2919920"
  },
  {
    "text": "um okay um so now um",
    "start": "2920319",
    "end": "2925920"
  },
  {
    "text": "let's actually start uh so here's one thing right we can um let",
    "start": "2925920",
    "end": "2931920"
  },
  {
    "text": "me let me do this x train",
    "start": "2931920",
    "end": "2937359"
  },
  {
    "text": "of five",
    "start": "2937359",
    "end": "2941240"
  },
  {
    "text": "so i'm just going to print out the length of um",
    "start": "2946160",
    "end": "2950640"
  },
  {
    "start": "2952000",
    "end": "3072000"
  },
  {
    "text": "see look at that there's such there's a lot of variability in terms of the review size right",
    "start": "2952240",
    "end": "2957760"
  },
  {
    "text": "right somewhere so what we want to do is",
    "start": "2957760",
    "end": "2963040"
  },
  {
    "text": "normalize right um so as we train the network everything needs to be the input sequence length needs to be",
    "start": "2963040",
    "end": "2971599"
  },
  {
    "text": "you know consistent across all our inputs so what we'll do is uh we need we now need to pad",
    "start": "2971599",
    "end": "2979040"
  },
  {
    "text": "our sequences so padding is processor will make everything a uniform size so",
    "start": "2979040",
    "end": "2984640"
  },
  {
    "text": "if we have 155 characters we'll add another 345",
    "start": "2984640",
    "end": "2990240"
  },
  {
    "text": "um let's say 500 is a good number if you look at um",
    "start": "2990240",
    "end": "2996000"
  },
  {
    "text": "kind of look everything is kind of you know roughly you know around that and also i think",
    "start": "2996000",
    "end": "3002400"
  },
  {
    "text": "that's enough text at that point to say if the review is positive or negative we're not doing something",
    "start": "3002400",
    "end": "3008720"
  },
  {
    "text": "super fancy so i'm gonna say uh we'll just uh pat it with like 500 so",
    "start": "3008720",
    "end": "3016480"
  },
  {
    "text": "uh bad plan so when we",
    "start": "3016480",
    "end": "3021760"
  },
  {
    "text": "look what are we exactly padding it up with is it uh so it can be uh it can be anything um",
    "start": "3021760",
    "end": "3030559"
  },
  {
    "text": "you know so generally speaking we want to add something that is neutral value",
    "start": "3030559",
    "end": "3035839"
  },
  {
    "text": "right um so it's a good practice to just use spaces in other words it's an empty",
    "start": "3035839",
    "end": "3041280"
  },
  {
    "text": "word right it's not going to determine anything uh but actually honestly like you can try and just put randall as a",
    "start": "3041280",
    "end": "3047839"
  },
  {
    "text": "padding and it will still work because you randall appears like the network learns",
    "start": "3047839",
    "end": "3054079"
  },
  {
    "text": "that well randall's useless in this case no that's true",
    "start": "3054079",
    "end": "3059940"
  },
  {
    "text": "[Laughter] so",
    "start": "3059940",
    "end": "3065200"
  },
  {
    "text": "let's um so i'm going to say x train equal to",
    "start": "3065200",
    "end": "3071200"
  },
  {
    "text": "ah so we'll need to export another library",
    "start": "3071200",
    "end": "3077680"
  },
  {
    "text": "sequence there you go so we use this essentially we're using",
    "start": "3077680",
    "end": "3082800"
  },
  {
    "text": "this api uh to see pad sequence api",
    "start": "3082800",
    "end": "3088079"
  },
  {
    "text": "call uh to do this so we'll do from [Music]",
    "start": "3088079",
    "end": "3093520"
  },
  {
    "text": "import",
    "start": "3093520",
    "end": "3096520"
  },
  {
    "text": "sequences i'll do",
    "start": "3100160",
    "end": "3104240"
  },
  {
    "text": "i think it's just x max",
    "start": "3108319",
    "end": "3111839"
  },
  {
    "text": "uh what does it take it takes sequences in max lens so we're",
    "start": "3113839",
    "end": "3119280"
  },
  {
    "text": "gonna say and we're going to do the same for our",
    "start": "3119280",
    "end": "3125599"
  },
  {
    "text": "test data set",
    "start": "3125599",
    "end": "3128640"
  },
  {
    "text": "right make sense",
    "start": "3131680",
    "end": "3136400"
  },
  {
    "text": "yeah uh but also it does is uh it converge so",
    "start": "3136839",
    "end": "3142720"
  },
  {
    "text": "so a lot of us may be familiar with numpy so i'm gonna import",
    "start": "3142720",
    "end": "3148640"
  },
  {
    "text": "numpy uh it's gonna be helpful because we're looking we need to convert everything into an array",
    "start": "3148640",
    "end": "3155520"
  },
  {
    "text": "to be fed into it's easier to operate on",
    "start": "3155520",
    "end": "3160559"
  },
  {
    "text": "these arrays we can do some nice matrix multiplications and so on",
    "start": "3160559",
    "end": "3165680"
  },
  {
    "text": "and we can feed it to mx9 um",
    "start": "3165680",
    "end": "3171359"
  },
  {
    "text": "okay so we'll i think it was y train",
    "start": "3172160",
    "end": "3177920"
  },
  {
    "text": "array i will do the same for",
    "start": "3177920",
    "end": "3183440"
  },
  {
    "text": "test okay so we've converted all of this into array",
    "start": "3186160",
    "end": "3192640"
  },
  {
    "text": "um so let's just print all these guys",
    "start": "3192640",
    "end": "3198400"
  },
  {
    "text": "um",
    "start": "3198400",
    "end": "3200720"
  },
  {
    "text": "actually let's just do a sanity check so as you can see here right um",
    "start": "3206839",
    "end": "3213440"
  },
  {
    "text": "the uh the label shape so we have our vector essentially looks like 25 000",
    "start": "3213440",
    "end": "3220079"
  },
  {
    "text": "into 500 so everything is uniform and our y train is 25 000 comma",
    "start": "3220079",
    "end": "3226880"
  },
  {
    "text": "uh nothing essentially it means that we just have a scalar value there right so because it's just a zero or a one",
    "start": "3226880",
    "end": "3234800"
  },
  {
    "text": "so right so we we have that",
    "start": "3235520",
    "end": "3243838"
  },
  {
    "text": "okay so next is we'll we'll actually use uh so",
    "start": "3244720",
    "end": "3251839"
  },
  {
    "text": "we'll create we'll create iterators",
    "start": "3251839",
    "end": "3256760"
  },
  {
    "text": "um no i mean we can pad it with uh we were just saying is um you know i just took a",
    "start": "3290240",
    "end": "3296960"
  },
  {
    "text": "really quick stab at you know how uh yeah it's gonna take more time as well it's gonna take more memory uh but",
    "start": "3296960",
    "end": "3304000"
  },
  {
    "text": "i just took a quick distribution pass at you know here uh when sampling i just",
    "start": "3304000",
    "end": "3309760"
  },
  {
    "text": "feel like it's just an overkill if we went for a thousand words right it's just an overkill um so it's gonna train faster",
    "start": "3309760",
    "end": "3317200"
  },
  {
    "text": "um it's not gonna add more value so",
    "start": "3317200",
    "end": "3322480"
  },
  {
    "text": "it might be different for other use cases so uh one way to look at it is if every word and for your use",
    "start": "3322480",
    "end": "3330240"
  },
  {
    "text": "case it's really important we can take the max length of the review and pad",
    "start": "3330240",
    "end": "3335599"
  },
  {
    "text": "everything to that right but every this is different from things that i'm",
    "start": "3335599",
    "end": "3341200"
  },
  {
    "text": "used to working with because a lot of the stuff that i do in my day-to-day job is more database oriented and every",
    "start": "3341200",
    "end": "3347760"
  },
  {
    "text": "single piece of text matters it's you know the right concern on every piece of information is it has to be replicated",
    "start": "3347760",
    "end": "3354640"
  },
  {
    "text": "in six availability zones so on so forth um but this is this is more this is almost",
    "start": "3354640",
    "end": "3361040"
  },
  {
    "text": "like a it's almost like artistry and science blended together it's interesting i've never thought about",
    "start": "3361040",
    "end": "3366480"
  },
  {
    "text": "this before so all the data yeah so we were thinking about the access right so it's like well do i",
    "start": "3366480",
    "end": "3373200"
  },
  {
    "start": "3372000",
    "end": "3600000"
  },
  {
    "text": "here's what i'm trying to do with more data um does more data really add value",
    "start": "3373200",
    "end": "3378480"
  },
  {
    "text": "is the question it's like well what's the least amount of information i need to make a decision",
    "start": "3378480",
    "end": "3384720"
  },
  {
    "text": "right um so so that's kind of the rationale is and we can certainly maybe if we have",
    "start": "3384720",
    "end": "3391280"
  },
  {
    "text": "time at the end we can use uh uh we can rerun the code with uh the entire uh",
    "start": "3391280",
    "end": "3396880"
  },
  {
    "text": "keeping everything constant and more data and uh rather keeping all say thousand",
    "start": "3396880",
    "end": "3402559"
  },
  {
    "text": "uh words and see if we get something better that's that's worth trying uh i'm making an educated guess here",
    "start": "3402559",
    "end": "3409440"
  },
  {
    "text": "because um you know we're doing something simple",
    "start": "3409440",
    "end": "3414559"
  },
  {
    "text": "we're doing something simple so it's you know if if if you're doing so you didn't have to",
    "start": "3414559",
    "end": "3420480"
  },
  {
    "text": "wait for the last 500 words to bash a movie or say something good",
    "start": "3420480",
    "end": "3426000"
  },
  {
    "text": "so that's that's my",
    "start": "3427599",
    "end": "3431960"
  },
  {
    "text": "900 words about a movie is maybe inception or interstellar or the martian you know just",
    "start": "3435200",
    "end": "3441200"
  },
  {
    "text": "uh luxury of time uh i hope",
    "start": "3441200",
    "end": "3446920"
  },
  {
    "text": "so we'll look at the ndna interface with mxnet",
    "start": "3446960",
    "end": "3452400"
  },
  {
    "text": "if you go to mxnet.io i'm lazy to do",
    "start": "3452400",
    "end": "3459200"
  },
  {
    "text": "so it takes um you know three uh parameters essentially if you look at this",
    "start": "3459200",
    "end": "3464960"
  },
  {
    "text": "um so data iterators are good uh uh because you can you know um they have",
    "start": "3464960",
    "end": "3472079"
  },
  {
    "text": "interfaces where it's simple to interact with if you think about parallelizing the operations you can just run yield",
    "start": "3472079",
    "end": "3478960"
  },
  {
    "text": "operations to kind of extract so generators you don't need to keep",
    "start": "3478960",
    "end": "3484799"
  },
  {
    "text": "everything in memory you can get things in on demand right so so it's a nice interface memory efficient uh easy to",
    "start": "3484799",
    "end": "3492640"
  },
  {
    "text": "paralyze um and in this case uh as you can see we have shuffle",
    "start": "3492640",
    "end": "3498559"
  },
  {
    "text": "uh we have a lot of things that are built in that we can just leverage",
    "start": "3498559",
    "end": "3503920"
  },
  {
    "text": "so it's a good practice to use iterators",
    "start": "3503920",
    "end": "3508798"
  },
  {
    "text": "so that's that's the iterator",
    "start": "3509359",
    "end": "3515440"
  },
  {
    "text": "we'll need to give it data and labels right so our data",
    "start": "3515440",
    "end": "3520559"
  },
  {
    "text": "so endear illustrator so x train was our array and y train is our labels right so and",
    "start": "3520559",
    "end": "3528720"
  },
  {
    "text": "then what we'll do is we'll say shuffle equal to true uh but there's also another uh component",
    "start": "3528720",
    "end": "3536000"
  },
  {
    "text": "here as you saw is called patch size",
    "start": "3536000",
    "end": "3542400"
  },
  {
    "text": "right so now what",
    "start": "3542400",
    "end": "3547440"
  },
  {
    "text": "what we do is when we uh train um",
    "start": "3547440",
    "end": "3552799"
  },
  {
    "text": "we we don't we don't go through single samples at a time",
    "start": "3552799",
    "end": "3559520"
  },
  {
    "text": "the uh the reason being uh we're you know let's say we're using gpu gpus are really good",
    "start": "3559520",
    "end": "3566160"
  },
  {
    "text": "at parallel operations so to be computationally efficient we need we",
    "start": "3566160",
    "end": "3573040"
  },
  {
    "text": "usually batch the data and compute the error uh on an average uh in the batch",
    "start": "3573040",
    "end": "3579440"
  },
  {
    "text": "so so batching is a good idea and so you say matching is that",
    "start": "3579440",
    "end": "3585599"
  },
  {
    "text": "one whole review that we're batching or is this going to be the set of words that we're matching um so if you look at",
    "start": "3585599",
    "end": "3592960"
  },
  {
    "text": "the array we have in here right so a review is a collection",
    "start": "3592960",
    "end": "3600640"
  },
  {
    "text": "of words so so let's say we we have 20 our input vector is 25 000. so each row",
    "start": "3600640",
    "end": "3607119"
  },
  {
    "text": "if you look at each row is a collection of words we converted the collection of words to",
    "start": "3607119",
    "end": "3614480"
  },
  {
    "text": "a collection of numbers essentially because we converted words to numbers",
    "start": "3614480",
    "end": "3620880"
  },
  {
    "text": "correct correct um but what we'll do is we'll we'll take 128 reviews at a time",
    "start": "3620880",
    "end": "3627680"
  },
  {
    "text": "and send it together gotcha because i i was just trying to keep the shape of the data in my head",
    "start": "3627680",
    "end": "3633760"
  },
  {
    "text": "and it's a little bit hard because we have we have a few different variables that are",
    "start": "3633760",
    "end": "3638960"
  },
  {
    "text": "the same shape and then there's some that are are a different shape and it i'm just right making sure i'm keeping",
    "start": "3638960",
    "end": "3645119"
  },
  {
    "text": "track of all of it yeah so i'll i'll summarize again so if we look at x strain",
    "start": "3645119",
    "end": "3650960"
  },
  {
    "text": "um so x strain of zero this is how it looks like so what it's done is",
    "start": "3650960",
    "end": "3658400"
  },
  {
    "text": "see 500 words right and um and you can see it's a it's a bunch of",
    "start": "3658400",
    "end": "3666000"
  },
  {
    "text": "um oh sorry so it's uh it's padded with zero right",
    "start": "3666000",
    "end": "3672480"
  },
  {
    "text": "and then uh so we've we've padded uh uh initial words um rather than padding",
    "start": "3672480",
    "end": "3679280"
  },
  {
    "text": "it at the end it just did that by default it really doesn't matter for this use case",
    "start": "3679280",
    "end": "3685440"
  },
  {
    "text": "so this is where our actual review words are right the last 155 or so words",
    "start": "3685440",
    "end": "3693599"
  },
  {
    "text": "gotcha so does that make sense it does",
    "start": "3693599",
    "end": "3698799"
  },
  {
    "text": "and we basically go through 128 of those and then another 128 and",
    "start": "3698799",
    "end": "3704319"
  },
  {
    "text": "then another 128 right",
    "start": "3704319",
    "end": "3709119"
  },
  {
    "text": "okay x test and y test right so",
    "start": "3711200",
    "end": "3716720"
  },
  {
    "text": "so we're gonna create iterators and we can [Music]",
    "start": "3716720",
    "end": "3724230"
  },
  {
    "text": "okay all right",
    "start": "3724240",
    "end": "3727838"
  },
  {
    "text": "like a situation",
    "start": "3731359",
    "end": "3734480"
  },
  {
    "text": "and twitchy ml is asking how much should we sanitize the data before putting it through the training because we've we've",
    "start": "3736400",
    "end": "3742720"
  },
  {
    "text": "not really done too much data sanitation here we've just stripped out kind of the angle brackets correct yeah so",
    "start": "3742720",
    "end": "3748960"
  },
  {
    "text": "um this data set we're lucky that um you know it's been sanitized for the most",
    "start": "3748960",
    "end": "3754720"
  },
  {
    "text": "part and uh you know i just tried to remove a few like um you know whatever angle brackets",
    "start": "3754720",
    "end": "3762400"
  },
  {
    "text": "because there was script from html i thought that you know we didn't need that um so typically",
    "start": "3762400",
    "end": "3769040"
  },
  {
    "text": "um you would spend a lot more time on sanitization uh in this case also because it's words",
    "start": "3769040",
    "end": "3776640"
  },
  {
    "text": "uh we just said uh well um you know if if things appear uh we",
    "start": "3776640",
    "end": "3782640"
  },
  {
    "text": "could have gone and you know scraped you know flower braces or something else we think was not useful from a word we",
    "start": "3782640",
    "end": "3789200"
  },
  {
    "text": "could have just kept alpha numeric and so on um",
    "start": "3789200",
    "end": "3794319"
  },
  {
    "text": "yeah i don't know if that answers it no i think that makes sense one thing i'm curious about is the regex that we",
    "start": "3794319",
    "end": "3801119"
  },
  {
    "text": "wrote earlier and i'm sorry that i keep interrupting because we're kind of messing with the flow here the wretched",
    "start": "3801119",
    "end": "3806559"
  },
  {
    "text": "that we wrote earlier we're stripping out the angle brackets but we're not necessarily stripping out the html",
    "start": "3806559",
    "end": "3811680"
  },
  {
    "text": "within those angle brackets are we yeah we didn't like i was just that was purely me showing",
    "start": "3811680",
    "end": "3818480"
  },
  {
    "text": "that hey um this is a step you can do this uh so trying to be more",
    "start": "3818480",
    "end": "3824960"
  },
  {
    "text": "generic and maybe some steps are not necessary for this use case uh but",
    "start": "3824960",
    "end": "3831039"
  },
  {
    "text": "i'm i want to walk through what are the general practices what do you do",
    "start": "3831039",
    "end": "3836839"
  },
  {
    "text": "um how do you think about this so that's kind of uh what what i want to do as",
    "start": "3836839",
    "end": "3842319"
  },
  {
    "text": "well yeah no it makes sense okay",
    "start": "3842319",
    "end": "3848319"
  },
  {
    "text": "all right time to build all right guys",
    "start": "3848319",
    "end": "3854400"
  },
  {
    "text": "all right now it's time to build a model",
    "start": "3854559",
    "end": "3859760"
  },
  {
    "text": "okay um what i'm gonna do is actually have a",
    "start": "3860400",
    "end": "3866640"
  },
  {
    "text": "little uh cheat sheet i'm excellent cheat sheet that i had created",
    "start": "3866640",
    "end": "3871680"
  },
  {
    "text": "um that we can use so",
    "start": "3871680",
    "end": "3876880"
  },
  {
    "text": "um this is always cool because uh you know it's hard to remember syntax uh it's also",
    "start": "3876880",
    "end": "3882480"
  },
  {
    "text": "uh one less thing for your brain to remember as long as you know where to look at um",
    "start": "3882480",
    "end": "3888079"
  },
  {
    "text": "so kind of like really cool examples here that we can just pick and choose uh to",
    "start": "3888079",
    "end": "3894480"
  },
  {
    "text": "create our network so we're going to use this multi-layer perceptron network",
    "start": "3894480",
    "end": "3902079"
  },
  {
    "text": "and i was looking to see you know what are the stuff that we need",
    "start": "3902079",
    "end": "3907280"
  },
  {
    "text": "to declare this um so mxnet",
    "start": "3907280",
    "end": "3913440"
  },
  {
    "text": "so we saw right there's a data par there's a data input part and there's a",
    "start": "3913440",
    "end": "3918480"
  },
  {
    "text": "output part so input and label essentially so we need to declare a placeholder",
    "start": "3918480",
    "end": "3925119"
  },
  {
    "text": "variable so most of these uh deep learning frameworks are",
    "start": "3925119",
    "end": "3931359"
  },
  {
    "text": "declarative in nature so some something like a tensorflow which is declarative which means",
    "start": "3931359",
    "end": "3936880"
  },
  {
    "text": "uh it's similar to sql right where you write uh you write a query the",
    "start": "3936880",
    "end": "3942720"
  },
  {
    "text": "engine underlying engine optimizes the query for you but it's less flexible in terms of hey how do you write loops uh",
    "start": "3942720",
    "end": "3950720"
  },
  {
    "text": "how do you do more things that are imperative right like we saw with the whole data",
    "start": "3950720",
    "end": "3956559"
  },
  {
    "text": "processing thing it was super easy with python so um",
    "start": "3956559",
    "end": "3961760"
  },
  {
    "text": "mxnet kind of combines this which is for mixed networks it combines this",
    "start": "3961760",
    "end": "3967440"
  },
  {
    "text": "with um both imperative and declarative interface",
    "start": "3967440",
    "end": "3972799"
  },
  {
    "text": "um so that people can write uh programs in a more flexible manner",
    "start": "3972799",
    "end": "3979680"
  },
  {
    "text": "so the network itself will be declarative so uh so we need placeholder variables so",
    "start": "3979680",
    "end": "3987440"
  },
  {
    "text": "you know our data so mx not",
    "start": "3987440",
    "end": "3993200"
  },
  {
    "text": "symbol so we need to declare our data variable and we'll need to",
    "start": "3993200",
    "end": "3999280"
  },
  {
    "text": "declare our target which is our output right so",
    "start": "3999280",
    "end": "4006720"
  },
  {
    "text": "so if i could just summarize what you said to make sure that i understand it it's basically like symbolic math that",
    "start": "4006720",
    "end": "4013280"
  },
  {
    "text": "we're doing here it you know we're defining the pipeline that we want the the data to flow through and then",
    "start": "4013280",
    "end": "4019680"
  },
  {
    "text": "we're going to click at the end and just say run it correct correct",
    "start": "4019680",
    "end": "4026240"
  },
  {
    "text": "so as you can see you know by default",
    "start": "4026240",
    "end": "4032240"
  },
  {
    "text": "the um by default our data uh iterators have",
    "start": "4033359",
    "end": "4040240"
  },
  {
    "text": "taken the data name as data and softmax label that's just uh that's just what the iterator does so we're just going to",
    "start": "4040240",
    "end": "4047280"
  },
  {
    "text": "say we're just going to declare those variables placeholders",
    "start": "4047280",
    "end": "4052880"
  },
  {
    "text": "okay so we'll do one additional thing at this",
    "start": "4052880",
    "end": "4058559"
  },
  {
    "text": "point is we need to create a word embedding so we",
    "start": "4058559",
    "end": "4064799"
  },
  {
    "text": "have all these words uh but it doesn't quite make sense to the",
    "start": "4064799",
    "end": "4070960"
  },
  {
    "text": "neural network what these words are or their relationships so we'll use a technique called",
    "start": "4070960",
    "end": "4076079"
  },
  {
    "text": "embedding so embedding is essentially quite simply put going from words to numbers",
    "start": "4076079",
    "end": "4083039"
  },
  {
    "text": "uh in in a vector space a word to real numbers so what i did was i",
    "start": "4083039",
    "end": "4089119"
  },
  {
    "text": "created a little um is that visible",
    "start": "4089119",
    "end": "4094400"
  },
  {
    "text": "yeah i can see it so you know our algorithms don't understand",
    "start": "4094400",
    "end": "4099838"
  },
  {
    "text": "text we need to kind of transform this into a continuous space and also",
    "start": "4099839",
    "end": "4104880"
  },
  {
    "text": "we have a lot of words uh you know our vocabulary was like what 10 000 words um",
    "start": "4104880",
    "end": "4111359"
  },
  {
    "text": "so it's the dimensionality is pretty huge so what we'll do is with this embedding technique we're going to",
    "start": "4111359",
    "end": "4117679"
  },
  {
    "text": "reduce the uh we're going to bring it to a lower dimension uh so that you know we can visualize we",
    "start": "4117679",
    "end": "4125120"
  },
  {
    "text": "can kind of inherently create a similar similarity between words a",
    "start": "4125120",
    "end": "4130960"
  },
  {
    "text": "contextual similarity so there are many techniques to do this uh one of the",
    "start": "4130960",
    "end": "4136000"
  },
  {
    "text": "common embedding technique is called word to work i have a little link here which i can share with people how to",
    "start": "4136000",
    "end": "4141679"
  },
  {
    "text": "create it but intuitively what it is doing is trying to put words that are similar together",
    "start": "4141679",
    "end": "4149199"
  },
  {
    "text": "so maybe we'll have apple orange and other things you know coexist in a",
    "start": "4149199",
    "end": "4155040"
  },
  {
    "text": "space whereas like hockey football soccer might exist in",
    "start": "4155040",
    "end": "4160880"
  },
  {
    "text": "what is the data structure that creates that kind of embedding because i",
    "start": "4160880",
    "end": "4167838"
  },
  {
    "text": "i like you said there's so many different dimensions i like you just highlight a few here verb tense male female country capital like yeah",
    "start": "4167839",
    "end": "4175040"
  },
  {
    "text": "are we just going with positive negative in this case or we're grouping on on synonym i mean i no so so the embedding",
    "start": "4175040",
    "end": "4182880"
  },
  {
    "text": "takes a dimension so what it does is it converts the word so let's say",
    "start": "4182880",
    "end": "4189520"
  },
  {
    "text": "we convert into a vector so we'll take uh the word and say",
    "start": "4189520",
    "end": "4194800"
  },
  {
    "text": "hey our embedding size or dimension is 12. so it'll be a vector of size 12.",
    "start": "4194800",
    "end": "4201520"
  },
  {
    "text": "okay so so essentially we go from words to into a let's say we",
    "start": "4201520",
    "end": "4207120"
  },
  {
    "text": "pick 32 as our dimension uh it'll be a 32 um yeah dimension vector",
    "start": "4207120",
    "end": "4212719"
  },
  {
    "text": "so that's kind of what this example kind of shows you well what's cool is uh because these",
    "start": "4212719",
    "end": "4220880"
  },
  {
    "text": "words with similar context will um uh you know kind of like end up together",
    "start": "4220880",
    "end": "4226159"
  },
  {
    "text": "we can actually uh you know move uh or calculate distances",
    "start": "4226159",
    "end": "4232000"
  },
  {
    "text": "between these so the word to work uh there's a cool example where they've shown uh when in",
    "start": "4232000",
    "end": "4238080"
  },
  {
    "text": "bed um let's say like man uh ma if you subtract man",
    "start": "4238080",
    "end": "4243520"
  },
  {
    "text": "where by woman it's the same distance as king minus queen",
    "start": "4243520",
    "end": "4249760"
  },
  {
    "text": "right so so it kind of ends up in this",
    "start": "4249760",
    "end": "4255920"
  },
  {
    "text": "uniform space but so we create a uniform space continuous space uh so that the",
    "start": "4255920",
    "end": "4262080"
  },
  {
    "text": "network can learn uh because it doesn't work yeah because it doesn't understand",
    "start": "4262080",
    "end": "4268800"
  },
  {
    "text": "raw text or like how the text structure is so we're giving it a structure",
    "start": "4268800",
    "end": "4274640"
  },
  {
    "text": "cool and it's pretty simple i mean we don't",
    "start": "4275199",
    "end": "4280800"
  },
  {
    "text": "we we don't need to do anything except you know calling uh",
    "start": "4280800",
    "end": "4286719"
  },
  {
    "text": "um calling an embedding function so embedding",
    "start": "4286719",
    "end": "4293120"
  },
  {
    "text": "so comparing",
    "start": "4293920",
    "end": "4297480"
  },
  {
    "text": "so it takes data and then uh the other thing is we need to have our",
    "start": "4300560",
    "end": "4305920"
  },
  {
    "text": "uh dimension set so we'll we'll basically say uh data equal to data here",
    "start": "4305920",
    "end": "4314000"
  },
  {
    "text": "input dimension um remember that was our",
    "start": "4314000",
    "end": "4319360"
  },
  {
    "text": "vocab size which was 10 000 i believe and there you go number of words",
    "start": "4319360",
    "end": "4325920"
  },
  {
    "text": "and our output dimensions see we're going from words to vectors right so output dimension",
    "start": "4325920",
    "end": "4331520"
  },
  {
    "text": "will be um let's say embed size is 32 right so everything is a 32 um",
    "start": "4331520",
    "end": "4339440"
  },
  {
    "text": "uh vector so we can we can just give it a little name called",
    "start": "4339440",
    "end": "4345280"
  },
  {
    "text": "embedding layer okay okay um what what we're going to do now",
    "start": "4345280",
    "end": "4352960"
  },
  {
    "text": "is actually um so",
    "start": "4352960",
    "end": "4358719"
  },
  {
    "text": "the network doesn't you know we're gonna actually change the dimension of our array",
    "start": "4358719",
    "end": "4364400"
  },
  {
    "text": "and we're just gonna flatten it we're just gonna make it a single uh from a nd array essentially to a um",
    "start": "4364400",
    "end": "4372239"
  },
  {
    "text": "for lack of better word a single array so we're going to use this function to flatten this so that our network can",
    "start": "4372239",
    "end": "4381120"
  },
  {
    "text": "it goes through the network um",
    "start": "4383120",
    "end": "4389800"
  },
  {
    "text": "and we'll pass it through the embedding layer right so we'll um we'll",
    "start": "4403760",
    "end": "4409280"
  },
  {
    "text": "basically as you can see what i'm doing is connecting a chain right does that",
    "start": "4409280",
    "end": "4415520"
  },
  {
    "text": "um do you see that uh",
    "start": "4415520",
    "end": "4421840"
  },
  {
    "text": "yeah i mean i see that you're the input of one is the right output the output of one is the input of",
    "start": "4423920",
    "end": "4430400"
  },
  {
    "text": "the other i see that you're building this like pipeline yeah um",
    "start": "4430400",
    "end": "4436080"
  },
  {
    "text": "i think uh what i'll do is now let me actually switch to",
    "start": "4436080",
    "end": "4441360"
  },
  {
    "text": "some basics i think it's about time that we learn uh maybe a little bit about",
    "start": "4441360",
    "end": "4446960"
  },
  {
    "text": "neural networks before we actually go code them okay",
    "start": "4446960",
    "end": "4453199"
  },
  {
    "text": "basic structure so a neural network has three essential three types of layers",
    "start": "4453199",
    "end": "4458880"
  },
  {
    "text": "input hidden and output uh input layer of course it's obvious",
    "start": "4458880",
    "end": "4464640"
  },
  {
    "text": "this is our input output layer actually is um what uh what the network spits out",
    "start": "4464640",
    "end": "4472080"
  },
  {
    "text": "remember in this case uh we want to say hey how likely is um",
    "start": "4472080",
    "end": "4479440"
  },
  {
    "text": "is the network um you know um or what is the network thing",
    "start": "4479679",
    "end": "4486560"
  },
  {
    "text": "is the review positive or negative that's our output layer here",
    "start": "4486560",
    "end": "4492400"
  },
  {
    "text": "and in between is the hidden layers so the hidden layers is where all the magic",
    "start": "4492400",
    "end": "4497679"
  },
  {
    "text": "happens so it's being transformed in in our case we'll have an embedding",
    "start": "4497679",
    "end": "4503600"
  },
  {
    "text": "layer an embedding layer is going to connect to another layer where it's going to map all these inputs and figure",
    "start": "4503600",
    "end": "4510239"
  },
  {
    "text": "out the relationship between the words um and then it's going to build um",
    "start": "4510239",
    "end": "4517440"
  },
  {
    "text": "and it's going to pass on to the next layer uh what it's defining some of the",
    "start": "4517440",
    "end": "4522560"
  },
  {
    "text": "layers but then there are sub layers essentially that are happening in this hidden layer section",
    "start": "4522560",
    "end": "4528640"
  },
  {
    "text": "that mxnet is responsible for is that right um no you're actually implementing the",
    "start": "4528640",
    "end": "4534480"
  },
  {
    "text": "you're saying what the hidden layers look like so we're defining uh so we have to",
    "start": "4534480",
    "end": "4540159"
  },
  {
    "text": "define what type of a network it is so in fact we're literally building this",
    "start": "4540159",
    "end": "4545360"
  },
  {
    "text": "network where we'll have um we'll basically have two hidden layers",
    "start": "4545360",
    "end": "4551360"
  },
  {
    "text": "um so and this is called a fully connected layer um because uh",
    "start": "4551360",
    "end": "4558800"
  },
  {
    "text": "you know from its name if you can't infer it's basically means that all the neurons in this layer are connected to",
    "start": "4558800",
    "end": "4565199"
  },
  {
    "text": "every other neuron in the previous layer so gotcha that's a fully connected layer",
    "start": "4565199",
    "end": "4571440"
  },
  {
    "text": "okay so you know what what",
    "start": "4573520",
    "end": "4578880"
  },
  {
    "text": "what we are essentially trying to do is figure out uh so as you see there's a",
    "start": "4578880",
    "end": "4584719"
  },
  {
    "text": "connection between each of these neurons and it's associated with a weight",
    "start": "4584719",
    "end": "4590880"
  },
  {
    "text": "so how strongly are these two neurons connected right",
    "start": "4591040",
    "end": "4596400"
  },
  {
    "text": "so so that and every every connection pair essentially has a weight",
    "start": "4596400",
    "end": "4602080"
  },
  {
    "text": "and the whole job of training is to figure out what these weights are",
    "start": "4602080",
    "end": "4607199"
  },
  {
    "text": "like that's essentially what we're doing in a neural network",
    "start": "4607199",
    "end": "4612480"
  },
  {
    "text": "so we're basically assigning vectors from one node to the next node",
    "start": "4613679",
    "end": "4619280"
  },
  {
    "text": "to the next node correct so we we have uh so each so we'll basically have a weight matrix um",
    "start": "4619280",
    "end": "4626960"
  },
  {
    "text": "and uh and we're computing the weights so we'll initialize the weights",
    "start": "4626960",
    "end": "4632400"
  },
  {
    "text": "uh with some random values and what we're trying to do is oh",
    "start": "4632400",
    "end": "4637600"
  },
  {
    "text": "that doesn't quite work that's a wrong so whole process is finding that",
    "start": "4637600",
    "end": "4642719"
  },
  {
    "text": "weight the right set of weights or parameters uh for our",
    "start": "4642719",
    "end": "4648719"
  },
  {
    "text": "uh for our uh you know classification function here make sense it does",
    "start": "4648719",
    "end": "4655840"
  },
  {
    "text": "and and you see you can see that right so as a change in any of the weights uh",
    "start": "4655840",
    "end": "4661280"
  },
  {
    "text": "it means that there's a change in the output right because uh it's kind of a weighted uh put it very",
    "start": "4661280",
    "end": "4668719"
  },
  {
    "text": "naively it's a weighted sum at the end um more complex than that but you know in",
    "start": "4668719",
    "end": "4674719"
  },
  {
    "text": "simplistic terms it's a weighted sum so if you change the weights the output uh",
    "start": "4674719",
    "end": "4680400"
  },
  {
    "text": "probabilities will change um loosely but like our um",
    "start": "4680400",
    "end": "4688170"
  },
  {
    "text": "[Music] you know it kind of looks like this where your neurons connected our",
    "start": "4688170",
    "end": "4695520"
  },
  {
    "text": "function i i i swear we won't go a lot into math but",
    "start": "4695520",
    "end": "4701600"
  },
  {
    "text": "essentially what we're trying to do is um we could we're trying to compute a function which is",
    "start": "4701600",
    "end": "4707440"
  },
  {
    "text": "uh a sum of all the weights and all the inputs",
    "start": "4707440",
    "end": "4713199"
  },
  {
    "text": "plus a bias so wi is the weights at the eighth layer x i",
    "start": "4713199",
    "end": "4720480"
  },
  {
    "text": "are all the inputs at the eighth layer uh or neuron essentially and then uh",
    "start": "4720480",
    "end": "4727679"
  },
  {
    "text": "we that's our neural network",
    "start": "4727679",
    "end": "4731440"
  },
  {
    "text": "function you're with me so far so just to",
    "start": "4732840",
    "end": "4738080"
  },
  {
    "text": "because i get that not everybody knows mathematical notation frankly i haven't looked at this stuff in",
    "start": "4738080",
    "end": "4744880"
  },
  {
    "text": "literally 10 years uh my god i'm getting old",
    "start": "4744880",
    "end": "4750320"
  },
  {
    "text": "um so that's some notation if you scroll down again sorry yeah",
    "start": "4750320",
    "end": "4757199"
  },
  {
    "text": "uh that's some notation where you have",
    "start": "4757199",
    "end": "4762960"
  },
  {
    "text": "the this x0 so this is like layer 1 x0 is the actual neuron that's the actual",
    "start": "4762960",
    "end": "4769440"
  },
  {
    "text": "node in the graph that's the the value yeah and then you have a weight which is w0",
    "start": "4769440",
    "end": "4777199"
  },
  {
    "text": "correct okay and that forms the the the connection of those two items forms",
    "start": "4777199",
    "end": "4784480"
  },
  {
    "text": "the the pointer the the edge between the two",
    "start": "4784480",
    "end": "4790480"
  },
  {
    "text": "nodes yeah so let me just simplify i we we don't need to necessarily know all of",
    "start": "4790480",
    "end": "4796080"
  },
  {
    "text": "this just remember we're trying to compute some weights right the neurons are connected to each other",
    "start": "4796080",
    "end": "4801760"
  },
  {
    "text": "uh we have a weight matrix we're trying to find the weights like that's that's our problem",
    "start": "4801760",
    "end": "4809280"
  },
  {
    "text": "so i'm not going to go too much into how it's done but here's the learning process right so",
    "start": "4809360",
    "end": "4815920"
  },
  {
    "text": "here all the weights are initialized but what happens is",
    "start": "4815920",
    "end": "4822320"
  },
  {
    "text": "you know we have a label x but our rather our output is expected output is x",
    "start": "4822320",
    "end": "4828880"
  },
  {
    "text": "but let's say when we send a sample through it our value is x prime because you know",
    "start": "4828880",
    "end": "4835360"
  },
  {
    "text": "we just initialized everything with random weights correct the whole process is hey how different",
    "start": "4835360",
    "end": "4842480"
  },
  {
    "text": "is x from x prime and that is determined by something called",
    "start": "4842480",
    "end": "4849280"
  },
  {
    "text": "as a loss function so the loss function tells us you know how",
    "start": "4849280",
    "end": "4855920"
  },
  {
    "text": "different x and x prime is and we compute a delta and that delta",
    "start": "4855920",
    "end": "4862640"
  },
  {
    "text": "is the correction in weights",
    "start": "4862640",
    "end": "4867600"
  },
  {
    "text": "that we need to change okay so that process is called back propagation so",
    "start": "4868320",
    "end": "4874480"
  },
  {
    "text": "we are we have arrived so we went you know we went through the network",
    "start": "4874480",
    "end": "4880159"
  },
  {
    "text": "we arrived at a value but that was not the correct value we wanted so we we found out hey what's the",
    "start": "4880159",
    "end": "4887679"
  },
  {
    "text": "we then compute hey how far uh off are uh these uh this value",
    "start": "4887679",
    "end": "4893600"
  },
  {
    "text": "and this is done with respect to every weight in the network right so every new",
    "start": "4893600",
    "end": "4899520"
  },
  {
    "text": "we're and there's nothing preventing us from computing those in a parallel fashion right so",
    "start": "4899520",
    "end": "4905440"
  },
  {
    "text": "we can we can compute every single weight and then we get to this value and we back propagate and we say okay well",
    "start": "4905440",
    "end": "4911840"
  },
  {
    "text": "this is the difference from where we were looking for so let's go and run this again",
    "start": "4911840",
    "end": "4917440"
  },
  {
    "text": "right so we go back essentially so uh we our loss function uh essentially",
    "start": "4917440",
    "end": "4924719"
  },
  {
    "text": "uh tells us how far it is so we actually calculate what's called a derivative",
    "start": "4924719",
    "end": "4930480"
  },
  {
    "text": "and this is where it gets into math which i promised to stay away from but",
    "start": "4930480",
    "end": "4936400"
  },
  {
    "text": "essentially we calculated some delta correction in the weights and as we go",
    "start": "4936400",
    "end": "4941760"
  },
  {
    "text": "back through the layers we correct uh we rectify the weights so the weights",
    "start": "4941760",
    "end": "4947840"
  },
  {
    "text": "get weights change in the back propagation phase and this is how the network learns right",
    "start": "4947840",
    "end": "4953120"
  },
  {
    "text": "so we're saying hey get closer get closer x and x prime should get really close",
    "start": "4953120",
    "end": "4958719"
  },
  {
    "text": "and when you get close that means that well i i'm i have the right weights to",
    "start": "4958719",
    "end": "4964080"
  },
  {
    "text": "do uh what i'm doing gotcha all right",
    "start": "4964080",
    "end": "4969520"
  },
  {
    "text": "this is one crazy slide and i'm gonna",
    "start": "4969520",
    "end": "4974560"
  },
  {
    "text": "i'm gonna talk about this and then we'll code essentially what we're trying to do is we're trying to find",
    "start": "4974560",
    "end": "4980560"
  },
  {
    "text": "we're trying not to get trapped in these like local minima on this plane of existence of correct you know different",
    "start": "4980560",
    "end": "4986639"
  },
  {
    "text": "and we want to figure out a way using and the loss function allows us to get to the global minimum instead of this",
    "start": "4986639",
    "end": "4992800"
  },
  {
    "text": "like so this is kind of um you know if we can visualize the space",
    "start": "4992800",
    "end": "4998159"
  },
  {
    "text": "of the last function this is how it looks like but the idea is",
    "start": "4998159",
    "end": "5004000"
  },
  {
    "text": "that we we have to go and find a direction where we can get to the global minima so",
    "start": "5004000",
    "end": "5011120"
  },
  {
    "text": "this kind of optimization is called non-convex non-convex because",
    "start": "5011120",
    "end": "5016159"
  },
  {
    "text": "the function has many crests and many uh mountains so think of this analogy as",
    "start": "5016159",
    "end": "5022000"
  },
  {
    "text": "like we're skiing down right so we're top of the mountain we need to get to you know the lowest point and um we're",
    "start": "5022000",
    "end": "5029120"
  },
  {
    "text": "trying to see hey if i go in that direction i can i can actually",
    "start": "5029120",
    "end": "5035360"
  },
  {
    "text": "uh get to the global minima so we go we take steps",
    "start": "5035360",
    "end": "5041360"
  },
  {
    "text": "in that direction where we think it's the steepest and that's going to eventually lead us to the global minima",
    "start": "5041360",
    "end": "5049040"
  },
  {
    "text": "right so that's the whole process and we can we have a parameter where we can",
    "start": "5049040",
    "end": "5055360"
  },
  {
    "text": "adjust how many steps we take in that direction",
    "start": "5055360",
    "end": "5060400"
  },
  {
    "text": "okay all right time to go code again",
    "start": "5064159",
    "end": "5070760"
  },
  {
    "text": "so the thing is we just need to know all we need to do maybe as developers",
    "start": "5074960",
    "end": "5081199"
  },
  {
    "text": "and just know that that's happening we don't need to do anything we just need to say hey take five steps at a time",
    "start": "5081199",
    "end": "5087920"
  },
  {
    "text": "take 100 steps at a time something like this uh what we call is a running rate and",
    "start": "5087920",
    "end": "5093199"
  },
  {
    "text": "depending upon that rate uh we're just gonna tune uh our network so we don't",
    "start": "5093199",
    "end": "5098560"
  },
  {
    "text": "need to do all this math uh we we don't need to know necessarily know exactly what it is doing",
    "start": "5098560",
    "end": "5104960"
  },
  {
    "text": "we just need to know well based on what i see in the network we",
    "start": "5104960",
    "end": "5110080"
  },
  {
    "text": "need to take faster steps or we need to slow down that's what we need to know",
    "start": "5110080",
    "end": "5115678"
  },
  {
    "text": "okay so so i'm going to declare",
    "start": "5116560",
    "end": "5122480"
  },
  {
    "text": "our first fully connected network um",
    "start": "5122480",
    "end": "5127840"
  },
  {
    "text": "but as you saw um if the weights were linear",
    "start": "5127840",
    "end": "5133280"
  },
  {
    "text": "right like so there are weights between there are weights between uh there you",
    "start": "5133280",
    "end": "5139600"
  },
  {
    "text": "go yeah the weights between these networks now if they're linear then you know we're",
    "start": "5139600",
    "end": "5145920"
  },
  {
    "text": "not gonna get uh um we're not gonna get really complex models what we need is",
    "start": "5145920",
    "end": "5152560"
  },
  {
    "text": "um you know fractional values or we need non-linearity",
    "start": "5152560",
    "end": "5158320"
  },
  {
    "text": "uh to to be able to solve more complex problems um",
    "start": "5158320",
    "end": "5165040"
  },
  {
    "text": "so also because as we back propagate we're actually running a gradient or a differentiation function if it's step",
    "start": "5165040",
    "end": "5172560"
  },
  {
    "text": "function uh then our derivatives are not gonna we're not gonna be computing derivatives",
    "start": "5172560",
    "end": "5178400"
  },
  {
    "text": "so we need like a nice curve so we'll add that non-linearity",
    "start": "5178400",
    "end": "5185040"
  },
  {
    "text": "so just know simple thing is we'll have a fully",
    "start": "5186560",
    "end": "5191600"
  },
  {
    "text": "connected layer we need to add a non-linearity in our functions and",
    "start": "5191600",
    "end": "5197280"
  },
  {
    "text": "we can just use built-in built-in functions uh so",
    "start": "5197280",
    "end": "5203920"
  },
  {
    "text": "so we're basically saying we don't want a you know a pointer to a node we want a direction",
    "start": "5203920",
    "end": "5211040"
  },
  {
    "text": "to travel towards a node yeah i mean that's that's computed but",
    "start": "5211040",
    "end": "5217120"
  },
  {
    "text": "what i was saying is um we we can't we can't achieve those uh crazy functions and shapes if you're",
    "start": "5217120",
    "end": "5225040"
  },
  {
    "text": "not using non-linearities uh because the whole point is so there's something",
    "start": "5225040",
    "end": "5230400"
  },
  {
    "text": "called as the universal uh approximation theorem so um",
    "start": "5230400",
    "end": "5236480"
  },
  {
    "text": "essentially a neural network uh can approximately solve any problem",
    "start": "5236480",
    "end": "5243600"
  },
  {
    "text": "like it's it there's a mathematical proof now as fancy as it sounds it's really",
    "start": "5243600",
    "end": "5249440"
  },
  {
    "text": "difficult to achieve the right parameters the right inputs it takes a lot to kind of model the problem",
    "start": "5249440",
    "end": "5255920"
  },
  {
    "text": "in the right way so that's where the difficulty is so theoretically we can solve anything but",
    "start": "5255920",
    "end": "5263120"
  },
  {
    "text": "practically whether it's the algorithms data",
    "start": "5263120",
    "end": "5268719"
  },
  {
    "text": "the actual compute needed to do that",
    "start": "5268719",
    "end": "5273199"
  },
  {
    "text": "so we'll use something called as relu which is rectified linear unit",
    "start": "5276239",
    "end": "5282080"
  },
  {
    "text": "and",
    "start": "5282080",
    "end": "5284480"
  },
  {
    "text": "i won't go into details let's let's let's continue coding and we can go into theory",
    "start": "5287440",
    "end": "5293199"
  },
  {
    "text": "if people want to know so just treat this as a black box for now",
    "start": "5293199",
    "end": "5299360"
  },
  {
    "text": "so we'll pass the activation i'm okay with that num",
    "start": "5299360",
    "end": "5304800"
  },
  {
    "text": "so in this case um what we'll do is at the end",
    "start": "5305120",
    "end": "5311199"
  },
  {
    "text": "we'll just use a number of hidden nodes as",
    "start": "5311199",
    "end": "5318000"
  },
  {
    "text": "2. any idea why two randall uh is it because those are the two well",
    "start": "5320840",
    "end": "5326719"
  },
  {
    "text": "when you say number of hidden nodes do you mean the number of hidden layers no number of hidden uh so it's the",
    "start": "5326719",
    "end": "5332960"
  },
  {
    "text": "number of neurons at the end at the end",
    "start": "5332960",
    "end": "5338000"
  },
  {
    "text": "right so yeah so since we have",
    "start": "5338000",
    "end": "5343360"
  },
  {
    "text": "uh just two we're just trying to compute the probabilities how likely is it negative",
    "start": "5343360",
    "end": "5348880"
  },
  {
    "text": "and how likely is it positive we need to here gotcha",
    "start": "5348880",
    "end": "5354400"
  },
  {
    "text": "so every [Music] okay",
    "start": "5354639",
    "end": "5360880"
  },
  {
    "text": "why are those called hidden",
    "start": "5363120",
    "end": "5366400"
  },
  {
    "text": "uh they just came up with players yeah because i",
    "start": "5368400",
    "end": "5373440"
  },
  {
    "text": "i don't know the exact my my speculation is because a lot of people um we were",
    "start": "5373440",
    "end": "5379360"
  },
  {
    "text": "operating in non-linear spaces it's hard to visualize know what's happening it's",
    "start": "5379360",
    "end": "5384639"
  },
  {
    "text": "kind of like hey there's a lot of magic and hence probably the name hidden okay",
    "start": "5384639",
    "end": "5392080"
  },
  {
    "text": "might be a better answer to that but uh yeah",
    "start": "5392080",
    "end": "5399198"
  },
  {
    "text": "i don't think that should do um so we can actually plot our network so",
    "start": "5399600",
    "end": "5405920"
  },
  {
    "text": "this is really cool um really cool too",
    "start": "5405920",
    "end": "5411920"
  },
  {
    "text": "clearly i missed something um [Music]",
    "start": "5411920",
    "end": "5417120"
  },
  {
    "text": "to actually see how our network uh target should be capital v",
    "start": "5417120",
    "end": "5423119"
  },
  {
    "text": "yeah so um what's our variable yeah",
    "start": "5426800",
    "end": "5434360"
  },
  {
    "text": "now target should be capital b oh yeah yeah yeah",
    "start": "5434719",
    "end": "5440560"
  },
  {
    "text": "okay there you go",
    "start": "5440560",
    "end": "5443760"
  },
  {
    "text": "confined argument output dim maybe it's output",
    "start": "5445679",
    "end": "5452400"
  },
  {
    "text": "and all right there you go wow okay",
    "start": "5453600",
    "end": "5461280"
  },
  {
    "text": "and then the non-linearization component yeah so",
    "start": "5464800",
    "end": "5470400"
  },
  {
    "text": "yeah so this is what's happening our data is fed into the embed layer we flatten the data",
    "start": "5470400",
    "end": "5476639"
  },
  {
    "text": "and there's a layer there's a fully connected layer which has 200 neurons right",
    "start": "5476639",
    "end": "5483679"
  },
  {
    "text": "now the output of those uh get through our activation",
    "start": "5483679",
    "end": "5488840"
  },
  {
    "text": "function then it gets mapped to a fully connected layer with two neurons and each are going to kind of map to",
    "start": "5488840",
    "end": "5495440"
  },
  {
    "text": "positive and negative and then we send it through an output layer",
    "start": "5495440",
    "end": "5501199"
  },
  {
    "text": "we use something called as a max output now the softmax is essentially",
    "start": "5501199",
    "end": "5508400"
  },
  {
    "text": "um again there's a lot of math the easiest way is to say is uh it's",
    "start": "5508400",
    "end": "5514560"
  },
  {
    "text": "it's it's a log likelihood what it's going to do is suppress things that are it's going to normalize how our",
    "start": "5514560",
    "end": "5522719"
  },
  {
    "text": "our values and we're going to get probabilities uh on which defined as negative likelihood",
    "start": "5522719",
    "end": "5529440"
  },
  {
    "text": "so we'll see hey how likely is um something",
    "start": "5529440",
    "end": "5535040"
  },
  {
    "text": "to be positive how likely is something to be negative so we're just converting into probabilities in the log scale",
    "start": "5535040",
    "end": "5540560"
  },
  {
    "text": "because um we just there might be bigger values and so on right",
    "start": "5540560",
    "end": "5547199"
  },
  {
    "text": "okay so there you go that is our network is ready",
    "start": "5547199",
    "end": "5553840"
  },
  {
    "text": "so remember we're gonna we had this concept of iterations right so we were gonna",
    "start": "5554880",
    "end": "5560480"
  },
  {
    "text": "show the network um you know um we're gonna show the network the same",
    "start": "5560480",
    "end": "5566880"
  },
  {
    "text": "set of samples many times so that the network learns that's always a good idea so those are called epochs",
    "start": "5566880",
    "end": "5572880"
  },
  {
    "text": "and epoch is when the entire training set has been seen",
    "start": "5572880",
    "end": "5578000"
  },
  {
    "text": "by uh the network once that's an epoch",
    "start": "5578000",
    "end": "5583360"
  },
  {
    "text": "so so i'm going to declare uh you know our",
    "start": "5585679",
    "end": "5591440"
  },
  {
    "text": "i'm just going to call it model so mxnet has a module interface",
    "start": "5591440",
    "end": "5597199"
  },
  {
    "text": "so you can kind of see here um so this is what it does so we can",
    "start": "5600000",
    "end": "5607440"
  },
  {
    "text": "i'm going to try and copy this or",
    "start": "5607440",
    "end": "5613639"
  },
  {
    "text": "all right so a module takes the symbol in this case we're going to say mlp",
    "start": "5620239",
    "end": "5627760"
  },
  {
    "text": "that's a symbol context i'll just keep it cpu for now uh we'll",
    "start": "5629440",
    "end": "5634560"
  },
  {
    "text": "just see some uh we'll just see some fun um and uh actually sorry",
    "start": "5634560",
    "end": "5643719"
  },
  {
    "text": "uh we can skip the data names um uh or we",
    "start": "5646239",
    "end": "5651440"
  },
  {
    "text": "can just have it so these are the placeholder variables that we declared we didn't really change",
    "start": "5651440",
    "end": "5658239"
  },
  {
    "text": "them so we can leave them as default that's fine",
    "start": "5658239",
    "end": "5663120"
  },
  {
    "text": "whoa what's going on with those quotes yeah i know it doesn't uh",
    "start": "5666159",
    "end": "5673040"
  },
  {
    "text": "it tries to be smart and then it doesn't allow you to just have a",
    "start": "5673040",
    "end": "5679280"
  },
  {
    "text": "single",
    "start": "5679280",
    "end": "5681599"
  },
  {
    "text": "so we're to use this uh function now now that we've declared it we're",
    "start": "5684560",
    "end": "5689920"
  },
  {
    "text": "just going to run the network so here's the whole thing right remember you were talking about building a pipeline and",
    "start": "5689920",
    "end": "5695679"
  },
  {
    "text": "then entering so we'll just literally call a fit a function called fit and what it's going to do is",
    "start": "5695679",
    "end": "5702159"
  },
  {
    "text": "get all it's going to do all the heavy lifting for us get all the nodes uh get",
    "start": "5702159",
    "end": "5707280"
  },
  {
    "text": "get all the data it's going to distribute the data it's actually going to",
    "start": "5707280",
    "end": "5713040"
  },
  {
    "text": "um you know train we just need to give it parameters that that's that's as easy",
    "start": "5713040",
    "end": "5719440"
  },
  {
    "text": "um so i don't know if i have an example for fit function here",
    "start": "5719440",
    "end": "5726480"
  },
  {
    "text": "there you go so give it the",
    "start": "5726480",
    "end": "5732239"
  },
  {
    "text": "the callback and the callback is just like a progress checker",
    "start": "5732239",
    "end": "5738000"
  },
  {
    "text": "yeah so correct so module",
    "start": "5738000",
    "end": "5743199"
  },
  {
    "text": "interface as soon as you start training this i am going to run go get some water but",
    "start": "5743199",
    "end": "5750400"
  },
  {
    "text": "if it drips in like two seconds i'm gonna be disappointed you should be happy no it's a cpu it's",
    "start": "5750400",
    "end": "5756400"
  },
  {
    "text": "probably not going to um be in that space so we'll give it the",
    "start": "5756400",
    "end": "5762639"
  },
  {
    "text": "iterator so so it'll give uh so we'll say nitrator this is our evaluation data",
    "start": "5762639",
    "end": "5768719"
  },
  {
    "text": "remember there's a validation set we'll just use the test iterator for now",
    "start": "5768719",
    "end": "5774400"
  },
  {
    "text": "so we have different optimizers so the simplest one is called stochastic",
    "start": "5774400",
    "end": "5780480"
  },
  {
    "text": "gradient descent remember the whole the process of going",
    "start": "5780480",
    "end": "5786080"
  },
  {
    "text": "sarcastic gradient descent that's how that's the whole process of walking down",
    "start": "5786080",
    "end": "5792239"
  },
  {
    "text": "that slope remember that's easy that's the truth that thing's doing the magic yes that optimizer",
    "start": "5792239",
    "end": "5798400"
  },
  {
    "text": "uh we'll use something more modern it's called adam",
    "start": "5798400",
    "end": "5803440"
  },
  {
    "text": "again so up so remember i was talking about",
    "start": "5804400",
    "end": "5811199"
  },
  {
    "text": "the steps you take down that's called the learning rate so",
    "start": "5811199",
    "end": "5816239"
  },
  {
    "text": "i'll just uh point one is a little high we typically might end up using 0.01 or",
    "start": "5816239",
    "end": "5822000"
  },
  {
    "text": "001 it's usually a good learning rate to start with and we'll see how network you",
    "start": "5822000",
    "end": "5827040"
  },
  {
    "text": "know performs so eval metric is",
    "start": "5827040",
    "end": "5833280"
  },
  {
    "text": "so essentially after et park or after each batch we want to see hey how accurate is this",
    "start": "5833280",
    "end": "5838840"
  },
  {
    "text": "network so you can define your own custom you know",
    "start": "5838840",
    "end": "5844159"
  },
  {
    "text": "evaluation metrics but what i'm going to do is use just accuracy which is essentially a direct comparison",
    "start": "5844159",
    "end": "5850400"
  },
  {
    "text": "it's going to say hey um one equal to one or one equal to zero",
    "start": "5850400",
    "end": "5855760"
  },
  {
    "text": "and so on right it's just going to do a direct comparison",
    "start": "5855760",
    "end": "5860800"
  },
  {
    "text": "okay what we'll do is i'm gonna add a callback function",
    "start": "5860800",
    "end": "5868320"
  },
  {
    "text": "um just so that we get some really nice things that you know",
    "start": "5868320",
    "end": "5874239"
  },
  {
    "text": "some some some typing here uh uh some print messages",
    "start": "5874239",
    "end": "5880880"
  },
  {
    "text": "call it's called speedometer speedometer",
    "start": "5880880",
    "end": "5887920"
  },
  {
    "text": "um that's uh so i'm going to say hey call back um",
    "start": "5887920",
    "end": "5896840"
  },
  {
    "text": "every 10 batches or something",
    "start": "5897119",
    "end": "5901360"
  },
  {
    "text": "and that should work but what i need is um i need to enable",
    "start": "5904320",
    "end": "5910480"
  },
  {
    "text": "logging i always forget it's uh get basic logger",
    "start": "5910480",
    "end": "5917360"
  },
  {
    "text": "um yeah logging e basic logger or like if you if you want",
    "start": "5917360",
    "end": "5923760"
  },
  {
    "text": "to do like logging.basicconfig or something like that",
    "start": "5923760",
    "end": "5928239"
  },
  {
    "text": "i think and then yeah missing a g on there",
    "start": "5929840",
    "end": "5935520"
  },
  {
    "text": "where oh yeah",
    "start": "5937280",
    "end": "5941440"
  },
  {
    "text": "uh and i forget uh i think that should do it right uh i",
    "start": "5942320",
    "end": "5948159"
  },
  {
    "text": "think i need to set level to remember um debug or logging.info yep",
    "start": "5948159",
    "end": "5955920"
  },
  {
    "text": "um what's that info okay",
    "start": "5956080",
    "end": "5961920"
  },
  {
    "text": "all right we're gonna hit we're gonna train now",
    "start": "5961920",
    "end": "5968239"
  },
  {
    "text": "okay well uh get basic logger do you know or uh i can",
    "start": "5971760",
    "end": "5979600"
  },
  {
    "text": "find out really fast i if you just do um logging",
    "start": "5979600",
    "end": "5984719"
  },
  {
    "text": "help um",
    "start": "5984719",
    "end": "5989119"
  },
  {
    "text": "oh yeah there you go okay it's raining now",
    "start": "5989840",
    "end": "5995760"
  },
  {
    "text": "okay you wanna get your water yeah i'm gonna run go get some water we'll be right back yeah",
    "start": "5995760",
    "end": "6002719"
  },
  {
    "text": "let me see if",
    "start": "6002960",
    "end": "6006840"
  },
  {
    "text": "[Music]",
    "start": "6011800",
    "end": "6014849"
  },
  {
    "text": "all right guys as you can see um you know it's taking a bunch of time",
    "start": "6018159",
    "end": "6023280"
  },
  {
    "text": "uh we're still in the first epoch so what i'm going to do is really pause",
    "start": "6023280",
    "end": "6028639"
  },
  {
    "text": "and show the power of gpu right so we executed for 30 seconds or so",
    "start": "6028639",
    "end": "6035119"
  },
  {
    "text": "so it's as easy as changing one parameter there as you see like context dot gpu",
    "start": "6035119",
    "end": "6041920"
  },
  {
    "text": "uh uh mx.gpu can be cpu i'll also show you how to do this on multiple",
    "start": "6041920",
    "end": "6047840"
  },
  {
    "text": "channels so randall so remember like our progress was pretty",
    "start": "6047840",
    "end": "6053840"
  },
  {
    "text": "slow so i decided to use the gpu right so it was as easy as you can see how",
    "start": "6053840",
    "end": "6061119"
  },
  {
    "text": "quickly it just like goes boom is it done",
    "start": "6061119",
    "end": "6067679"
  },
  {
    "text": "it's printing a lot it's not done quite maybe i'll increase the bat size so that you don't get too much printing",
    "start": "6067920",
    "end": "6075679"
  },
  {
    "text": "so you can see here our training accuracy is increasing kind of sort of um here we started at 44 percent",
    "start": "6075679",
    "end": "6083920"
  },
  {
    "text": "it's increasing",
    "start": "6083920",
    "end": "6087040"
  },
  {
    "text": "and it's the goal to just train it until it's at 99 or something yeah i mean we'll see uh we'll see how",
    "start": "6090000",
    "end": "6096320"
  },
  {
    "text": "much we can achieve uh but yeah something like that so we want to get to",
    "start": "6096320",
    "end": "6101920"
  },
  {
    "text": "are you ready we want to get to as high as possible right like we might not be able to achieve um",
    "start": "6101920",
    "end": "6107679"
  },
  {
    "text": "that so",
    "start": "6107679",
    "end": "6111520"
  },
  {
    "text": "is it bad that it's going back and forth",
    "start": "6114080",
    "end": "6120080"
  },
  {
    "text": "sort of um uh i mean in the first epoch it's it's really hard to say",
    "start": "6120080",
    "end": "6126239"
  },
  {
    "text": "uh so we only got about 40 accuracy um",
    "start": "6126239",
    "end": "6131280"
  },
  {
    "text": "we trained the first one switched to gpus does it go faster i",
    "start": "6131280",
    "end": "6136880"
  },
  {
    "text": "mean i don't know if you're running this on a gpu or running this loop no no it is so it does it does speed up",
    "start": "6136880",
    "end": "6143280"
  },
  {
    "text": "um so what i'll show folks is how easy it is",
    "start": "6143280",
    "end": "6151440"
  },
  {
    "text": "to i might have other things running here so i'll just say",
    "start": "6151440",
    "end": "6157920"
  },
  {
    "text": "mx.gpu i [Music]",
    "start": "6157920",
    "end": "6165119"
  },
  {
    "text": "i'll just use four gpus and see that's how we can do distributed training",
    "start": "6165119",
    "end": "6171920"
  },
  {
    "text": "that's about it i literally go from having",
    "start": "6171920",
    "end": "6178880"
  },
  {
    "text": "[Music] you know changing that line into a list",
    "start": "6178880",
    "end": "6185760"
  },
  {
    "text": "so too many slices are empty so i'm i'm gonna redo my um",
    "start": "6187280",
    "end": "6193760"
  },
  {
    "text": "it just gets into a weird state if we just reset the kernel too many",
    "start": "6193760",
    "end": "6199920"
  },
  {
    "text": "slices uh",
    "start": "6199920",
    "end": "6204360"
  },
  {
    "text": "when i get into this state i just restart yeah i kind of i'm trying to avoid that but yeah sure",
    "start": "6205679",
    "end": "6213520"
  },
  {
    "text": "all right we'll go execute everything again maybe a good time to recap as well right",
    "start": "6214480",
    "end": "6221040"
  },
  {
    "text": "so we get the data we cleanse the data",
    "start": "6221040",
    "end": "6228239"
  },
  {
    "text": "we tokenize the data remember we we don't want to have words",
    "start": "6228239",
    "end": "6234320"
  },
  {
    "text": "excuse me sorry yeah now we're gonna have our test and uh",
    "start": "6234320",
    "end": "6242000"
  },
  {
    "text": "training set um sequenced we're going to create our labels",
    "start": "6242000",
    "end": "6249199"
  },
  {
    "text": "we're going to pad because we want everything to be of the same shape",
    "start": "6250880",
    "end": "6256239"
  },
  {
    "text": "gpus we created our network",
    "start": "6257199",
    "end": "6262800"
  },
  {
    "text": "and now we train um i probably have too few",
    "start": "6262880",
    "end": "6270320"
  },
  {
    "text": "batches",
    "start": "6270320",
    "end": "6273320"
  },
  {
    "text": "i'm using four gpus i'll just use if i want to",
    "start": "6276639",
    "end": "6281040"
  },
  {
    "text": "we just have too few samples to actually really use all the horsepower here",
    "start": "6284960",
    "end": "6292080"
  },
  {
    "text": "oh i'll just stick to a single gpus right now [Music]",
    "start": "6297600",
    "end": "6304850"
  },
  {
    "text": "so this is the first epic it's going to run for a while",
    "start": "6310239",
    "end": "6314638"
  },
  {
    "text": "yeah so um i don't know how much time we have",
    "start": "6315679",
    "end": "6320960"
  },
  {
    "text": "randall um um we're about done we have maybe 15 minutes left",
    "start": "6320960",
    "end": "6326400"
  },
  {
    "text": "yeah so i was thinking maybe i'll um use a trained model and uh",
    "start": "6326400",
    "end": "6332320"
  },
  {
    "text": "you know show you guys how you know complete the rest of the 15 minutes or so",
    "start": "6332320",
    "end": "6339440"
  },
  {
    "text": "what's your idea uh yeah that sounds fine",
    "start": "6340239",
    "end": "6346080"
  },
  {
    "text": "okay let me",
    "start": "6346480",
    "end": "6351760"
  },
  {
    "text": "so um saving the model so let's say the model was saved we can literally do",
    "start": "6356880",
    "end": "6363119"
  },
  {
    "text": "something like save checkpoint",
    "start": "6363119",
    "end": "6367679"
  },
  {
    "text": "and give it a like a name um which is essentially a prefix",
    "start": "6369199",
    "end": "6376960"
  },
  {
    "text": "and the number of epochs like that's how easy it is to save a",
    "start": "6376960",
    "end": "6382080"
  },
  {
    "text": "model and just just as you can imagine right loading the model is",
    "start": "6382080",
    "end": "6389199"
  },
  {
    "text": "equally yeah equally simple",
    "start": "6389679",
    "end": "6394239"
  },
  {
    "text": "so i'm just going to stop this guy so that we can run",
    "start": "6397920",
    "end": "6403119"
  },
  {
    "text": "um [Music] i think i have a model called imdb",
    "start": "6403119",
    "end": "6409920"
  },
  {
    "text": "oops sorry yeah don't save over it yeah",
    "start": "6409920",
    "end": "6415840"
  },
  {
    "text": "i think it's called num epoch uh",
    "start": "6418880",
    "end": "6424520"
  },
  {
    "text": "[Music] again cheat sheet",
    "start": "6424520",
    "end": "6429840"
  },
  {
    "text": "um well uh because i didn't checkpoint uh the whole thing so i'm going to use a",
    "start": "6431040",
    "end": "6436960"
  },
  {
    "text": "different interface uh it's actually in the model object so we'll just do",
    "start": "6436960",
    "end": "6443280"
  },
  {
    "text": "um i think that should be this aren't you",
    "start": "6443280",
    "end": "6450198"
  },
  {
    "text": "i think it's load um",
    "start": "6468000",
    "end": "6471840"
  },
  {
    "text": "um can't remember i mean you can always run help on like",
    "start": "6477440",
    "end": "6484239"
  },
  {
    "text": "yeah i just want to avoid uh imdb symbol so we don't have the file",
    "start": "6484239",
    "end": "6491440"
  },
  {
    "text": "well i'll just do this oh i don't have it i think it's called",
    "start": "6491440",
    "end": "6497600"
  },
  {
    "text": "uh",
    "start": "6497600",
    "end": "6499840"
  },
  {
    "text": "i got this guy",
    "start": "6503440",
    "end": "6507000"
  },
  {
    "text": "there you go all right there we have so we have our",
    "start": "6514560",
    "end": "6520560"
  },
  {
    "text": "model um",
    "start": "6520560",
    "end": "6525440"
  },
  {
    "text": "so we now need to actually uh bind our",
    "start": "6525600",
    "end": "6531600"
  },
  {
    "text": "so we'll just bind our mod we'll just say hey uh because the module object is interchangeable we use the same thing",
    "start": "6531600",
    "end": "6536880"
  },
  {
    "text": "for training we'll just say hey we're gonna not um",
    "start": "6536880",
    "end": "6542719"
  },
  {
    "text": "we're gonna not not be training with this model that we just loaded so we only want to perform the forward pass",
    "start": "6542719",
    "end": "6549440"
  },
  {
    "text": "right we won't back propagate",
    "start": "6549440",
    "end": "6553239"
  },
  {
    "text": "of our training [Music] and then uh we need to give it uh the",
    "start": "6555199",
    "end": "6560960"
  },
  {
    "text": "data shape that it's gonna learn um or rather",
    "start": "6560960",
    "end": "6566719"
  },
  {
    "text": "it's going to expect so in this case we'll say",
    "start": "6566719",
    "end": "6571840"
  },
  {
    "text": "hey it's called uh the variable is called data and the shape is going to be 1 because",
    "start": "6571840",
    "end": "6577679"
  },
  {
    "text": "we're going to send we're not going to batch we're just going to say one right and we're going to say",
    "start": "6577679",
    "end": "6584638"
  },
  {
    "text": "numbers uh 500 what's that variable called",
    "start": "6584679",
    "end": "6590719"
  },
  {
    "text": "max link yeah excellent",
    "start": "6590719",
    "end": "6597320"
  },
  {
    "text": "right so we're going to use max length here",
    "start": "6597600",
    "end": "6602158"
  },
  {
    "text": "uh the shapes",
    "start": "6602639",
    "end": "6608678"
  },
  {
    "text": "that is always annoying when uh",
    "start": "6615040",
    "end": "6621920"
  },
  {
    "text": "there we go all right so we got our model um",
    "start": "6621920",
    "end": "6628239"
  },
  {
    "text": "the thing is um we'll we'll we'll create a little uh input",
    "start": "6628239",
    "end": "6633840"
  },
  {
    "text": "widget um i think uh randall what i'm gonna do is i'm going to cheat a little bit i'm going to copy paste some code",
    "start": "6633840",
    "end": "6641199"
  },
  {
    "text": "so that we can we can quickly show the outputs",
    "start": "6641199",
    "end": "6648800"
  },
  {
    "text": "so i'm going to use a widget text area essentially create a little widget that we can",
    "start": "6648800",
    "end": "6655679"
  },
  {
    "text": "you know type in a review and see how the model does so it's really cool that you can embed",
    "start": "6655679",
    "end": "6661920"
  },
  {
    "text": "all this in jupiter right but what we'll need is we'll need a submit function",
    "start": "6661920",
    "end": "6668320"
  },
  {
    "text": "um [Music] so we'll need a submit function here it's just like def handle submit",
    "start": "6668320",
    "end": "6674719"
  },
  {
    "text": "data into yeah so what this is gonna say is uh",
    "start": "6674719",
    "end": "6680560"
  },
  {
    "text": "hey i'm gonna get some value i'm gonna run it through this prediction sentiment uh",
    "start": "6680560",
    "end": "6687199"
  },
  {
    "text": "you know this model variable uh we're gonna call it",
    "start": "6687199",
    "end": "6692320"
  },
  {
    "text": "red underscore model uh and whatever the text value and we're gonna capture that in two",
    "start": "6692320",
    "end": "6699040"
  },
  {
    "text": "uh uh two two labels here but we also need to",
    "start": "6699040",
    "end": "6704080"
  },
  {
    "text": "remember we did all this processing with our input data right so the output data also needs to kind of match and ha has",
    "start": "6704080",
    "end": "6712000"
  },
  {
    "text": "to be treated the same way right so um i have this little uh",
    "start": "6712000",
    "end": "6718000"
  },
  {
    "text": "helper function here that we can use",
    "start": "6718000",
    "end": "6724320"
  },
  {
    "text": "um so what it does is uh we'll take whatever sentences come",
    "start": "6724320",
    "end": "6730080"
  },
  {
    "text": "we'll make it into a sequence again we'll tokenize it we'll convert into sequence",
    "start": "6730080",
    "end": "6735920"
  },
  {
    "text": "what we'll do is we'll essentially use the word index that we created earlier",
    "start": "6735920",
    "end": "6741679"
  },
  {
    "text": "right so we had a word index right so um this guy",
    "start": "6741679",
    "end": "6748320"
  },
  {
    "text": "this toke we're going to use that uh index to actually create our sequence",
    "start": "6748320",
    "end": "6753520"
  },
  {
    "text": "because we need to have we need to map to the same words that was in our training set",
    "start": "6753520",
    "end": "6759360"
  },
  {
    "text": "so essentially as we type these words will be tokenized then we'll make it into sequence we'll",
    "start": "6759360",
    "end": "6765599"
  },
  {
    "text": "pad it and then uh we'll send it to the model and then we just if we use a word that's",
    "start": "6765599",
    "end": "6772560"
  },
  {
    "text": "not in the data set we just um no it's going to throw an error right",
    "start": "6772560",
    "end": "6777599"
  },
  {
    "text": "like uh and we can try that as well so",
    "start": "6777599",
    "end": "6782719"
  },
  {
    "text": "uh widgets widgets uh from pi i need to improve",
    "start": "6782719",
    "end": "6789280"
  },
  {
    "text": "by the time yeah yeah",
    "start": "6789280",
    "end": "6793638"
  },
  {
    "text": "all right there you go little box um so if you just put in randall randall",
    "start": "6795679",
    "end": "6801040"
  },
  {
    "text": "randall randall randall rambler handle since that's not in the data set probably it'll just as you can see there you go",
    "start": "6801040",
    "end": "6808000"
  },
  {
    "text": "uh actually uh it just for some other reason but it's actually gonna",
    "start": "6808000",
    "end": "6814159"
  },
  {
    "text": "let's see to the different models",
    "start": "6814159",
    "end": "6818480"
  },
  {
    "text": "there you go yeah okay",
    "start": "6819440",
    "end": "6824638"
  },
  {
    "text": "so if we do randall as this is",
    "start": "6825040",
    "end": "6833000"
  },
  {
    "text": "right to try and yeah what i'm thinking is uh i'll just",
    "start": "6847360",
    "end": "6855040"
  },
  {
    "text": "i'll just get a i'll just get a pre-trained one uh over here",
    "start": "6855040",
    "end": "6861040"
  },
  {
    "text": "and do it there so",
    "start": "6861040",
    "end": "6864159"
  },
  {
    "text": "okay randall is actually probability from positive sentiment is",
    "start": "6866719",
    "end": "6872560"
  },
  {
    "text": "100 i'm just saying so let's let's do this uh",
    "start": "6872560",
    "end": "6880000"
  },
  {
    "text": "singing in the rain is one of",
    "start": "6880239",
    "end": "6886320"
  },
  {
    "text": "my favorite things boom",
    "start": "6886320",
    "end": "6891440"
  },
  {
    "text": "that's positive that's positive",
    "start": "6891440",
    "end": "6895280"
  },
  {
    "text": "what happens if you say least favorite things",
    "start": "6897040",
    "end": "6901440"
  },
  {
    "text": "good good point let's see see a model is not that good uh in terms of",
    "start": "6902480",
    "end": "6909760"
  },
  {
    "text": "my one of my least favorite things i i still think it'll probably be the same i'm just curious",
    "start": "6909760",
    "end": "6916320"
  },
  {
    "text": "so actually that's so here's another thing",
    "start": "6916880",
    "end": "6923679"
  },
  {
    "text": "right remember uh so our data set was too uh like we didn't have a lot of uh",
    "start": "6923679",
    "end": "6932000"
  },
  {
    "text": "values that were really small right so we we need to have something that is representative of the same so you can't",
    "start": "6932000",
    "end": "6938560"
  },
  {
    "text": "expect so you're going to expect to have all the input values that we trained with something that's crazy",
    "start": "6938560",
    "end": "6944880"
  },
  {
    "text": "long and then give it something short because it doesn't necessarily have it's not learned that so it's really",
    "start": "6944880",
    "end": "6950719"
  },
  {
    "text": "important too on twitch you guys should type your review of this episode type a very positive review and then type a",
    "start": "6950719",
    "end": "6956800"
  },
  {
    "text": "very negative review and we'll see if our model can detect that yeah make it make it you know",
    "start": "6956800",
    "end": "6962639"
  },
  {
    "text": "100 words 50 words at least yeah 50 something of that",
    "start": "6962639",
    "end": "6969440"
  },
  {
    "text": "let me get something um let me get something from the data set itself",
    "start": "6969440",
    "end": "6975119"
  },
  {
    "text": "so that we can",
    "start": "6975119",
    "end": "6978760"
  },
  {
    "text": "we have a request to try uh i don't like this movie so what sunil",
    "start": "6993440",
    "end": "6999280"
  },
  {
    "text": "was saying for the people on twitch is the the data set wasn't trained on short",
    "start": "6999280",
    "end": "7004320"
  },
  {
    "text": "sentences it was trained on like longer reviews of movies it's very negative oh my god",
    "start": "7004320",
    "end": "7011040"
  },
  {
    "text": "a mean-spirited repulsive horror film about three murdering children yeah yeah there you go right as you can",
    "start": "7011040",
    "end": "7017520"
  },
  {
    "text": "see that's like overwhelmingly negative [Laughter]",
    "start": "7017520",
    "end": "7022639"
  },
  {
    "text": "so uh so yeah so that there's an example so we can",
    "start": "7022639",
    "end": "7028840"
  },
  {
    "text": "um so we need to say um you know something that is at least in a couple of sentences so",
    "start": "7028840",
    "end": "7036639"
  },
  {
    "text": "um i'll send you something now my review of this episode",
    "start": "7036639",
    "end": "7043638"
  },
  {
    "text": "so let's say blake edwards legendary fiasco biggins pointless combination of",
    "start": "7045920",
    "end": "7051040"
  },
  {
    "text": "eagle look at that that's that's",
    "start": "7051040",
    "end": "7056159"
  },
  {
    "text": "still pretty negative that was negative",
    "start": "7056159",
    "end": "7060239"
  },
  {
    "text": "i was thinking um if anybody is on the new england side i",
    "start": "7067040",
    "end": "7072320"
  },
  {
    "text": "think let's see if it uh you know we like to say um wicked cool a lot so let's see if that's",
    "start": "7072320",
    "end": "7078960"
  },
  {
    "text": "positive or negative um we have a request from twitch to put in",
    "start": "7078960",
    "end": "7084320"
  },
  {
    "text": "the input of i don't like this movie",
    "start": "7084320",
    "end": "7088638"
  },
  {
    "text": "this is too small so i'm going to say because",
    "start": "7089840",
    "end": "7096880"
  },
  {
    "text": "there are too",
    "start": "7097599",
    "end": "7100639"
  },
  {
    "text": "i don't know let's see yeah oh negative great",
    "start": "7105599",
    "end": "7111920"
  },
  {
    "text": "so again we didn't we didn't really train so the model that i trained was about 85 accurate um so",
    "start": "7112159",
    "end": "7119199"
  },
  {
    "text": "you know we we need to find where uh you know times where we can get actually um",
    "start": "7119199",
    "end": "7125679"
  },
  {
    "text": "get uh to you know 95 98 accuracy",
    "start": "7125679",
    "end": "7131280"
  },
  {
    "text": "uh and some of that is enhancing the data set uh so uh as we saw here you",
    "start": "7131280",
    "end": "7138080"
  },
  {
    "text": "know we only use 25 000 words maybe we can use more",
    "start": "7138080",
    "end": "7143599"
  },
  {
    "text": "and then we can change with different optimizers and so on so",
    "start": "7143599",
    "end": "7150159"
  },
  {
    "text": "also instead of looking at one word at a time we can look at words that appear",
    "start": "7150159",
    "end": "7155360"
  },
  {
    "text": "together right so we can have like least favorite or something that's negat uh",
    "start": "7155360",
    "end": "7161760"
  },
  {
    "text": "you know a double negative things like that so are usually captured when you use something called as n grams",
    "start": "7161760",
    "end": "7169440"
  },
  {
    "text": "n grams is essentially a sliding window uh over the word so we'll capture",
    "start": "7169440",
    "end": "7174560"
  },
  {
    "text": "four words at a time and five words at a time rather than um you know just a",
    "start": "7174560",
    "end": "7179840"
  },
  {
    "text": "single word right does that make sense",
    "start": "7179840",
    "end": "7185440"
  },
  {
    "text": "it does i think that's like a google interview question is how do engrams work and how do you build them",
    "start": "7185440",
    "end": "7193440"
  },
  {
    "text": "i had some uh somebody from boston asking for something cool let's see",
    "start": "7194159",
    "end": "7200480"
  },
  {
    "text": "uh",
    "start": "7200480",
    "end": "7203480"
  },
  {
    "text": "okay that's positive",
    "start": "7214639",
    "end": "7218719"
  },
  {
    "text": "sorry i couldn't exactly use what you had there but uh",
    "start": "7221119",
    "end": "7226400"
  },
  {
    "text": "so uh i think we we gotta close it out this is kind of the end here but this is way",
    "start": "7226400",
    "end": "7232480"
  },
  {
    "text": "cool where we're gonna post this code on the twitch page itself for everybody to look at for",
    "start": "7232480",
    "end": "7238400"
  },
  {
    "text": "sure right yeah we'll upload this notebook for everybody to check yeah i'll upload i'll upload these uh basic",
    "start": "7238400",
    "end": "7244239"
  },
  {
    "text": "slides you know talking about embedding the cheat sheet i'll post that as well",
    "start": "7244239",
    "end": "7249840"
  },
  {
    "text": "um but yeah hopefully this was useful and this is kind of some of the basics i",
    "start": "7249840",
    "end": "7255280"
  },
  {
    "text": "would say um wait randall so you had a data set right",
    "start": "7255280",
    "end": "7260400"
  },
  {
    "text": "like maybe we should give people a homework yeah so there's some",
    "start": "7260400",
    "end": "7265599"
  },
  {
    "text": "there's this well sunil pointed this out to me there is a steam reviews data set can you bring that up or should i bring",
    "start": "7265599",
    "end": "7272000"
  },
  {
    "text": "it up uh i can bring it up um there you go",
    "start": "7272000",
    "end": "7277198"
  },
  {
    "text": "all right guys well this is actually cool so this data set",
    "start": "7278000",
    "end": "7284080"
  },
  {
    "text": "has reviews of uh you know video games um but rather than doing sentiment analysis",
    "start": "7284080",
    "end": "7290880"
  },
  {
    "text": "we'll we'll use what we have learned today to do something slightly different the data",
    "start": "7290880",
    "end": "7296800"
  },
  {
    "text": "actually has uh how how many number of hours that a person has viewed uh so",
    "start": "7296800",
    "end": "7304719"
  },
  {
    "text": "maybe we can build something to predict we'll read the review and say hey this guy has",
    "start": "7304719",
    "end": "7309840"
  },
  {
    "text": "played 500 of the game or 50 hours of the game and so on so maybe we can build a model to do that",
    "start": "7309840",
    "end": "7316480"
  },
  {
    "text": "so i i would say the homework is go take what we've done today and then",
    "start": "7316480",
    "end": "7322960"
  },
  {
    "text": "next week on thursday if anybody has a model that they want us to try if they've built their own model for",
    "start": "7322960",
    "end": "7329440"
  },
  {
    "text": "this uh i will write a review of a game because i have played all of",
    "start": "7329440",
    "end": "7334560"
  },
  {
    "text": "these games except for football manager 2015 i whatever",
    "start": "7334560",
    "end": "7340159"
  },
  {
    "text": "um but i've played all of these other games and i will write a review of these games",
    "start": "7340159",
    "end": "7345280"
  },
  {
    "text": "uh and you can see if you can predict how close i am to my actual number of hours in steam uh",
    "start": "7345280",
    "end": "7353520"
  },
  {
    "text": "and we'll actually like try your model live on twitch if anybody gets these done and if not i think that we could",
    "start": "7353520",
    "end": "7359199"
  },
  {
    "text": "probably spend a few minutes building our own model in the next episode right yeah we'll just recap",
    "start": "7359199",
    "end": "7364719"
  },
  {
    "text": "for people who are just joining in um but yeah i mean one tip i would say guys is uh uh try to uh try to like",
    "start": "7364719",
    "end": "7373040"
  },
  {
    "text": "bucket the um the actual number of hours played um so kind of say",
    "start": "7373040",
    "end": "7378719"
  },
  {
    "text": "you know 50 100 200 so on um just discretize it so that",
    "start": "7378719",
    "end": "7384480"
  },
  {
    "text": "it's easier and similar rather than trying to predict the exact number of hours",
    "start": "7384480",
    "end": "7389599"
  },
  {
    "text": "because i don't think we have enough data here you can't quantize it because there's not enough data to generate the",
    "start": "7389599",
    "end": "7397040"
  },
  {
    "text": "you played 15 minutes more than so-and-so so you have to choose like a 10 hours yeah buckets okay yeah",
    "start": "7397040",
    "end": "7405440"
  },
  {
    "text": "yeah so and is the bucketing strategy like orders of magnitude is it you know",
    "start": "7405440",
    "end": "7410480"
  },
  {
    "text": "discrete intervals is it yeah so what i would look at is the uh distribution",
    "start": "7410480",
    "end": "7415679"
  },
  {
    "text": "right so let's say uh the max uh uh so we have anybody from uh 100 hours to",
    "start": "7415679",
    "end": "7423280"
  },
  {
    "text": "10 000 right so we want like buckets where things will evenly kind of fall",
    "start": "7423280",
    "end": "7429440"
  },
  {
    "text": "uh so that they make sense uh because you don't want one bucket to be with just two reviews uh another",
    "start": "7429440",
    "end": "7436400"
  },
  {
    "text": "bucket with 50 reviews or 500 000 reviews right like we want to make sure that they're fairly balanced",
    "start": "7436400",
    "end": "7445040"
  },
  {
    "text": "okay cool so i'm going to try to",
    "start": "7445119",
    "end": "7450800"
  },
  {
    "text": "build a model for this my own model over the course of the next week we have a lot of other work to do obviously but",
    "start": "7450800",
    "end": "7456000"
  },
  {
    "text": "this is this is fun uh and i'm gonna see if i can kind of make it my side project to build out my",
    "start": "7456000",
    "end": "7461199"
  },
  {
    "text": "own model yeah uh so next next yeah next week we'll do uh",
    "start": "7461199",
    "end": "7466880"
  },
  {
    "text": "convolutional neural networks we'll deal with images um we'll try and find a cool problem and",
    "start": "7466880",
    "end": "7472960"
  },
  {
    "text": "build a classifier to you know detect uh images or classify them",
    "start": "7472960",
    "end": "7479040"
  },
  {
    "text": "um so if you have ideas let us know um we will and any cool data set that is",
    "start": "7479040",
    "end": "7485280"
  },
  {
    "text": "open uh so please if you're sharing things uh give us open data sets so that other people can learn uh while they do",
    "start": "7485280",
    "end": "7493520"
  },
  {
    "text": "uh uh you know the exercise so yeah we'll be back with convolutional neural",
    "start": "7493520",
    "end": "7498719"
  },
  {
    "text": "networks okay so again thanks everybody next week uh we will do some more i'm hoping over",
    "start": "7498719",
    "end": "7507440"
  },
  {
    "text": "the next few weeks we get the chance to also show you how to take these models and throw them up on a lambda function",
    "start": "7507440",
    "end": "7512719"
  },
  {
    "text": "and you can build kind of an api that can use this model to to give a value to your end users uh so so we'll",
    "start": "7512719",
    "end": "7520320"
  },
  {
    "text": "probably get to that at some point and uh again",
    "start": "7520320",
    "end": "7525520"
  },
  {
    "text": "our twitter handles i'll put them up again now um these are our twitter handles",
    "start": "7525520",
    "end": "7532960"
  },
  {
    "text": "uh and i strongly recommend you also shoot me",
    "start": "7532960",
    "end": "7538159"
  },
  {
    "text": "an email so this is my email at amazon uh you're more than welcome to tell me",
    "start": "7538159",
    "end": "7544320"
  },
  {
    "text": "things that you want to see on this stream we've got uh four solid episodes",
    "start": "7544320",
    "end": "7549679"
  },
  {
    "text": "for this deep learning series planned but if you guys come up with anything if",
    "start": "7549679",
    "end": "7555119"
  },
  {
    "text": "there's anything you want to build or do i'm certain that we could figure out a way to do that so any data sets that you're",
    "start": "7555119",
    "end": "7562320"
  },
  {
    "text": "interested in any models that you want to build definitely let us know through twitter or here on the twitch channel i",
    "start": "7562320",
    "end": "7568159"
  },
  {
    "text": "think it'll really help us build some stuff",
    "start": "7568159",
    "end": "7574080"
  },
  {
    "text": "again thanks for joining i hope everybody has a good day i'm gonna in the stream and uh hopefully next week i",
    "start": "7574080",
    "end": "7581440"
  },
  {
    "text": "won't be in a cast so bye everybody thanks so much good luck see you guys",
    "start": "7581440",
    "end": "7587920"
  }
]
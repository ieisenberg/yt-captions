[
  {
    "start": "0",
    "end": "131000"
  },
  {
    "text": "hello everyone I'm Lee pang a genomic",
    "start": "30",
    "end": "2879"
  },
  {
    "text": "specialist with Amazon Web Services hey",
    "start": "2879",
    "end": "5279"
  },
  {
    "text": "everybody I'm Ruchi Munchie a product",
    "start": "5279",
    "end": "8099"
  },
  {
    "text": "manager over at the Byrd Institute and",
    "start": "8099",
    "end": "10080"
  },
  {
    "text": "in this video we're gonna give you a",
    "start": "10080",
    "end": "11519"
  },
  {
    "text": "couple demonstrations of running",
    "start": "11519",
    "end": "13110"
  },
  {
    "text": "Cromwell on AWS if you haven't already I",
    "start": "13110",
    "end": "15990"
  },
  {
    "text": "recommend that you watch our webinar",
    "start": "15990",
    "end": "17789"
  },
  {
    "text": "that goes into the details of genomics",
    "start": "17789",
    "end": "20189"
  },
  {
    "text": "workflows patterns and services and how",
    "start": "20189",
    "end": "23160"
  },
  {
    "text": "to use Cromwell as we covered in our",
    "start": "23160",
    "end": "26939"
  },
  {
    "text": "webinar here are key considerations when",
    "start": "26939",
    "end": "30510"
  },
  {
    "text": "working with genomic data first genomic",
    "start": "30510",
    "end": "33030"
  },
  {
    "text": "data sets are big depending on the",
    "start": "33030",
    "end": "35790"
  },
  {
    "text": "amount of date detail a single genomics",
    "start": "35790",
    "end": "37770"
  },
  {
    "text": "experiment can range from tens of",
    "start": "37770",
    "end": "39270"
  },
  {
    "text": "gigabytes to several petabytes second",
    "start": "39270",
    "end": "42030"
  },
  {
    "text": "converting raw DNA sequencer data to",
    "start": "42030",
    "end": "44489"
  },
  {
    "text": "scientific insight takes a lot of",
    "start": "44489",
    "end": "46140"
  },
  {
    "text": "computational steps each with their own",
    "start": "46140",
    "end": "48809"
  },
  {
    "text": "unique resource requirements handling",
    "start": "48809",
    "end": "52860"
  },
  {
    "text": "genomic data involves processing",
    "start": "52860",
    "end": "54300"
  },
  {
    "text": "pipelines or workflows so for example",
    "start": "54300",
    "end": "56730"
  },
  {
    "text": "here is the broast genome and analysis",
    "start": "56730",
    "end": "59370"
  },
  {
    "text": "best practices workflow as you can see",
    "start": "59370",
    "end": "61710"
  },
  {
    "text": "there are many steps to get the data to",
    "start": "61710",
    "end": "64650"
  },
  {
    "text": "get to the data that scientists would",
    "start": "64650",
    "end": "67020"
  },
  {
    "text": "use for analysis this is where chrome",
    "start": "67020",
    "end": "70619"
  },
  {
    "text": "bell comes into play Cromwell is an open",
    "start": "70619",
    "end": "73049"
  },
  {
    "text": "source workflow orchestration engine",
    "start": "73049",
    "end": "74700"
  },
  {
    "text": "that runs both on local machines",
    "start": "74700",
    "end": "76740"
  },
  {
    "text": "and in the cloud Cromwell reads workflow",
    "start": "76740",
    "end": "80610"
  },
  {
    "text": "definitions written in languages like",
    "start": "80610",
    "end": "82850"
  },
  {
    "text": "wdl or Whittle and cwl and then launches",
    "start": "82850",
    "end": "88020"
  },
  {
    "text": "the resources needed to run the jobs",
    "start": "88020",
    "end": "90060"
  },
  {
    "text": "defined with AWS Cromwell acts as an",
    "start": "90060",
    "end": "95070"
  },
  {
    "text": "interface to AWS batch workflow jobs are",
    "start": "95070",
    "end": "98970"
  },
  {
    "text": "submitted to batch queues and run on",
    "start": "98970",
    "end": "101220"
  },
  {
    "text": "batch compute environments in the next",
    "start": "101220",
    "end": "103530"
  },
  {
    "text": "few minutes I'm gonna walk you through",
    "start": "103530",
    "end": "105450"
  },
  {
    "text": "setting up Cromwell on AWS and running a",
    "start": "105450",
    "end": "108240"
  },
  {
    "text": "simple workflow to start you're gonna",
    "start": "108240",
    "end": "111869"
  },
  {
    "text": "need the following things an ec2",
    "start": "111869",
    "end": "114869"
  },
  {
    "text": "instance to serve as your Cromwell",
    "start": "114869",
    "end": "116460"
  },
  {
    "text": "server a custom ami for running genomic",
    "start": "116460",
    "end": "119759"
  },
  {
    "text": "workflow jobs and talking with Cromwell",
    "start": "119759",
    "end": "122189"
  },
  {
    "text": "an s3 bucket for workflow inputs and",
    "start": "122189",
    "end": "125610"
  },
  {
    "text": "outputs and a batch compute environment",
    "start": "125610",
    "end": "129060"
  },
  {
    "text": "and job queue",
    "start": "129060",
    "end": "132050"
  },
  {
    "start": "131000",
    "end": "331000"
  },
  {
    "text": "the first thing you're going to need to",
    "start": "134200",
    "end": "136130"
  },
  {
    "text": "do is create a custom ami so if you head",
    "start": "136130",
    "end": "138710"
  },
  {
    "text": "over to our documentation site for",
    "start": "138710",
    "end": "140540"
  },
  {
    "text": "genomics workflows on AWS and go to the",
    "start": "140540",
    "end": "143660"
  },
  {
    "text": "section on creating a custom ami you'll",
    "start": "143660",
    "end": "147140"
  },
  {
    "text": "find a couple of cloud formation",
    "start": "147140",
    "end": "148580"
  },
  {
    "text": "templates that you can use to walk you",
    "start": "148580",
    "end": "150410"
  },
  {
    "text": "through the process text",
    "start": "150410",
    "end": "159550"
  },
  {
    "text": "pick your ami type in this case you'll",
    "start": "159550",
    "end": "162470"
  },
  {
    "text": "want to pick Cromwell and specify the",
    "start": "162470",
    "end": "165110"
  },
  {
    "text": "scratch mount point as Cromwell root and",
    "start": "165110",
    "end": "171650"
  },
  {
    "text": "hit next again and next one last time",
    "start": "171650",
    "end": "178540"
  },
  {
    "text": "and click the check box to acknowledge",
    "start": "179440",
    "end": "184100"
  },
  {
    "text": "that AWS cloud formation will create I",
    "start": "184100",
    "end": "187160"
  },
  {
    "text": "am resources and hit create",
    "start": "187160",
    "end": "191110"
  },
  {
    "text": "when the process completes select the",
    "start": "194540",
    "end": "197909"
  },
  {
    "text": "stack and take note of the ami ID on the",
    "start": "197909",
    "end": "201780"
  },
  {
    "text": "outputs tag you'll use this ID later",
    "start": "201780",
    "end": "205200"
  },
  {
    "text": "when you set up your batch environment",
    "start": "205200",
    "end": "208730"
  },
  {
    "text": "to create the remaining resources you",
    "start": "211730",
    "end": "214230"
  },
  {
    "text": "need you can use the cloud formation",
    "start": "214230",
    "end": "216569"
  },
  {
    "text": "stacks that we've provided in our",
    "start": "216569",
    "end": "218640"
  },
  {
    "text": "genomics workflows documentation you can",
    "start": "218640",
    "end": "221700"
  },
  {
    "text": "either use the full stack which creates",
    "start": "221700",
    "end": "223799"
  },
  {
    "text": "your s3 bucket VPC I am roles and batch",
    "start": "223799",
    "end": "229680"
  },
  {
    "text": "job queue in compute environments or you",
    "start": "229680",
    "end": "233489"
  },
  {
    "text": "can use a cloud formation template that",
    "start": "233489",
    "end": "235859"
  },
  {
    "text": "will launch these resources in an",
    "start": "235859",
    "end": "238170"
  },
  {
    "text": "existing vbc or you can use individual",
    "start": "238170",
    "end": "241560"
  },
  {
    "text": "templates for creating the s3 bucket by",
    "start": "241560",
    "end": "244170"
  },
  {
    "text": "itself",
    "start": "244170",
    "end": "244590"
  },
  {
    "text": "I am rules roles and the AWS batch",
    "start": "244590",
    "end": "249590"
  },
  {
    "text": "environment independently to use these",
    "start": "249590",
    "end": "256530"
  },
  {
    "text": "simply click on the button click Next",
    "start": "256530",
    "end": "264019"
  },
  {
    "text": "specify your AWS bucket",
    "start": "266210",
    "end": "270100"
  },
  {
    "text": "keep air",
    "start": "274380",
    "end": "277280"
  },
  {
    "text": "availability zones",
    "start": "277410",
    "end": "280680"
  },
  {
    "text": "and provide the ami ID use the AMIA that",
    "start": "282650",
    "end": "286910"
  },
  {
    "text": "you created using the custom ami script",
    "start": "286910",
    "end": "292360"
  },
  {
    "text": "next and next again to create your",
    "start": "293380",
    "end": "299110"
  },
  {
    "text": "infrastructure",
    "start": "299110",
    "end": "302110"
  },
  {
    "text": "when your infrastructure is complete go",
    "start": "303950",
    "end": "308040"
  },
  {
    "text": "to the batch stack go to outputs and",
    "start": "308040",
    "end": "314600"
  },
  {
    "text": "record or take note of the two job",
    "start": "314600",
    "end": "318180"
  },
  {
    "text": "queues that were created in this",
    "start": "318180",
    "end": "320910"
  },
  {
    "text": "walkthrough we're going to use the high",
    "start": "320910",
    "end": "322080"
  },
  {
    "text": "priority job queue copy this value for",
    "start": "322080",
    "end": "326400"
  },
  {
    "text": "later next you're going to need to",
    "start": "326400",
    "end": "333960"
  },
  {
    "start": "331000",
    "end": "507000"
  },
  {
    "text": "create an ec2 instance that will act as",
    "start": "333960",
    "end": "336330"
  },
  {
    "text": "your Cromwell server go to I am",
    "start": "336330",
    "end": "338669"
  },
  {
    "text": "management console and create an",
    "start": "338669",
    "end": "340440"
  },
  {
    "text": "instance profile that this instance will",
    "start": "340440",
    "end": "342480"
  },
  {
    "text": "use to access AWS services",
    "start": "342480",
    "end": "346700"
  },
  {
    "text": "you",
    "start": "351110",
    "end": "353169"
  },
  {
    "text": "you",
    "start": "358009",
    "end": "360069"
  },
  {
    "text": "attached in-line policies to this role",
    "start": "364400",
    "end": "366680"
  },
  {
    "text": "to allow it to create jobs and job",
    "start": "366680",
    "end": "368870"
  },
  {
    "text": "definitions in batch",
    "start": "368870",
    "end": "371800"
  },
  {
    "text": "you",
    "start": "377289",
    "end": "379349"
  },
  {
    "text": "and allow read-only access to your",
    "start": "402660",
    "end": "405780"
  },
  {
    "text": "bucket in s3",
    "start": "405780",
    "end": "408800"
  },
  {
    "text": "you",
    "start": "412820",
    "end": "414880"
  },
  {
    "text": "next go to your ec2 console and launch",
    "start": "450440",
    "end": "453360"
  },
  {
    "text": "an instance specifying the instance role",
    "start": "453360",
    "end": "455580"
  },
  {
    "text": "you just created",
    "start": "455580",
    "end": "458240"
  },
  {
    "text": "you",
    "start": "463849",
    "end": "465909"
  },
  {
    "text": "when your instance is available connect",
    "start": "498900",
    "end": "501390"
  },
  {
    "text": "to it via SSH",
    "start": "501390",
    "end": "504470"
  },
  {
    "start": "507000",
    "end": "621000"
  },
  {
    "text": "once you can",
    "start": "507889",
    "end": "509360"
  },
  {
    "text": "to your server download the most recent",
    "start": "509360",
    "end": "511789"
  },
  {
    "text": "version of Cromwell",
    "start": "511789",
    "end": "514839"
  },
  {
    "text": "and create a config file",
    "start": "522050",
    "end": "525459"
  },
  {
    "text": "replace the placeholders for s3 bucket",
    "start": "535980",
    "end": "541529"
  },
  {
    "text": "and batch QR",
    "start": "555920",
    "end": "559240"
  },
  {
    "text": "create the following files a hello Widow",
    "start": "581320",
    "end": "584980"
  },
  {
    "text": "file with a single task called hello and",
    "start": "584980",
    "end": "588160"
  },
  {
    "text": "a workflow WF underscore hello that",
    "start": "588160",
    "end": "592540"
  },
  {
    "text": "calls that task this task will simply",
    "start": "592540",
    "end": "596050"
  },
  {
    "text": "echo the command hello and addressee",
    "start": "596050",
    "end": "599380"
  },
  {
    "text": "welcome to Chrome well on AWS it'll use",
    "start": "599380",
    "end": "602829"
  },
  {
    "text": "the another file for inputs in this",
    "start": "602829",
    "end": "606220"
  },
  {
    "text": "input file put this JSON formatted data",
    "start": "606220",
    "end": "611490"
  },
  {
    "text": "WF hello dot hello",
    "start": "611490",
    "end": "613810"
  },
  {
    "text": "addressee and world",
    "start": "613810",
    "end": "617730"
  },
  {
    "start": "621000",
    "end": "829000"
  },
  {
    "text": "you mean I start the Cromwell server on",
    "start": "623290",
    "end": "625630"
  },
  {
    "text": "your ec2 instance",
    "start": "625630",
    "end": "628500"
  },
  {
    "text": "in this case I'm using an SSH tunnel",
    "start": "644580",
    "end": "648230"
  },
  {
    "text": "between my local machine and the remote",
    "start": "648230",
    "end": "651779"
  },
  {
    "text": "instance on port 8000 so I can navigate",
    "start": "651779",
    "end": "658560"
  },
  {
    "text": "in a web browser to localhost port 8000",
    "start": "658560",
    "end": "663410"
  },
  {
    "text": "and see cromwell's swagger UI",
    "start": "663410",
    "end": "668660"
  },
  {
    "text": "we can use this to submit the workflow",
    "start": "671560",
    "end": "674230"
  },
  {
    "text": "that we created in the previous step",
    "start": "674230",
    "end": "678029"
  },
  {
    "text": "while this workflow runs you can monitor",
    "start": "704160",
    "end": "706740"
  },
  {
    "text": "its status in the logs or via the AWS",
    "start": "706740",
    "end": "713699"
  },
  {
    "text": "batch console",
    "start": "713699",
    "end": "716389"
  },
  {
    "text": "here we see one job has been submitted",
    "start": "720800",
    "end": "722990"
  },
  {
    "text": "and is in the runnable State",
    "start": "722990",
    "end": "726550"
  },
  {
    "text": "you should see that the desired CPU",
    "start": "741160",
    "end": "744129"
  },
  {
    "text": "count increases when the job is ready to",
    "start": "744129",
    "end": "747579"
  },
  {
    "text": "start and that in the ec2 instance or in",
    "start": "747579",
    "end": "753160"
  },
  {
    "text": "ec2 management console you should see",
    "start": "753160",
    "end": "755800"
  },
  {
    "text": "instances queuing up",
    "start": "755800",
    "end": "758878"
  },
  {
    "text": "when the workflow successfully completes",
    "start": "778010",
    "end": "780440"
  },
  {
    "text": "you should receive a notification and",
    "start": "780440",
    "end": "785960"
  },
  {
    "text": "you should be able to see successful",
    "start": "785960",
    "end": "790160"
  },
  {
    "text": "completion in the logs",
    "start": "790160",
    "end": "795100"
  },
  {
    "text": "you should also be able to find outputs",
    "start": "812970",
    "end": "815560"
  },
  {
    "text": "that the workflow generated in your s3",
    "start": "815560",
    "end": "817930"
  },
  {
    "text": "bucket",
    "start": "817930",
    "end": "820230"
  },
  {
    "start": "829000",
    "end": "1379000"
  },
  {
    "text": "so that concludes my part of the demo",
    "start": "829250",
    "end": "831560"
  },
  {
    "text": "I'm gonna hand it over to Ruchi who's",
    "start": "831560",
    "end": "833480"
  },
  {
    "text": "going to show you something a little bit",
    "start": "833480",
    "end": "834889"
  },
  {
    "text": "more complicated so the next workflow",
    "start": "834889",
    "end": "838189"
  },
  {
    "text": "we're going to demonstrate in terms of",
    "start": "838189",
    "end": "840170"
  },
  {
    "text": "running Chrome wall on the AWS patch",
    "start": "840170",
    "end": "842529"
  },
  {
    "text": "back-end is a hap type what we call a",
    "start": "842529",
    "end": "846319"
  },
  {
    "text": "haplotype color workflow and the habitat",
    "start": "846319",
    "end": "850160"
  },
  {
    "text": "color is the gatk s leading germline",
    "start": "850160",
    "end": "853399"
  },
  {
    "text": "color tool and with a focus on short",
    "start": "853399",
    "end": "856550"
  },
  {
    "text": "variant discovery so in the case of this",
    "start": "856550",
    "end": "858740"
  },
  {
    "text": "workflow the input is a band file that",
    "start": "858740",
    "end": "862189"
  },
  {
    "text": "goes through two specific tasks where",
    "start": "862189",
    "end": "866180"
  },
  {
    "text": "help type color which performs short",
    "start": "866180",
    "end": "868519"
  },
  {
    "text": "bearing discovery on a single sample",
    "start": "868519",
    "end": "871579"
  },
  {
    "text": "across multiple genomic intervals so we",
    "start": "871579",
    "end": "874310"
  },
  {
    "text": "see a scatter step taking place which",
    "start": "874310",
    "end": "877629"
  },
  {
    "text": "splits up the genomic data into various",
    "start": "877629",
    "end": "880850"
  },
  {
    "text": "shards and then performs haplotype or",
    "start": "880850",
    "end": "884240"
  },
  {
    "text": "runs haplotype color or variant",
    "start": "884240",
    "end": "886189"
  },
  {
    "text": "discovery across those shards and then",
    "start": "886189",
    "end": "888649"
  },
  {
    "text": "there is a final step to merge that",
    "start": "888649",
    "end": "890810"
  },
  {
    "text": "those various shards into a final gbcm",
    "start": "890810",
    "end": "893959"
  },
  {
    "text": "file so that's the sort of flow for this",
    "start": "893959",
    "end": "897079"
  },
  {
    "text": "workflow and and this is available for",
    "start": "897079",
    "end": "901250"
  },
  {
    "text": "this is a publicly available workflow",
    "start": "901250",
    "end": "903620"
  },
  {
    "text": "for provided by the gatk in addition in",
    "start": "903620",
    "end": "907670"
  },
  {
    "text": "in this case I've collected all the",
    "start": "907670",
    "end": "910850"
  },
  {
    "text": "required input files needed for this",
    "start": "910850",
    "end": "912740"
  },
  {
    "text": "workflow such as a sample input BAM all",
    "start": "912740",
    "end": "915620"
  },
  {
    "text": "the reference files the Dockers or the",
    "start": "915620",
    "end": "918470"
  },
  {
    "text": "command is encapsulated and sort of the",
    "start": "918470",
    "end": "921290"
  },
  {
    "text": "other optimization parameters in",
    "start": "921290",
    "end": "925009"
  },
  {
    "text": "addition in order to be able to run",
    "start": "925009",
    "end": "927019"
  },
  {
    "text": "crombel on AWS I also require an AWS",
    "start": "927019",
    "end": "929600"
  },
  {
    "text": "config so this is very similar to the",
    "start": "929600",
    "end": "933379"
  },
  {
    "text": "config we presented earlier except I",
    "start": "933379",
    "end": "935660"
  },
  {
    "text": "have my own execution directory as well",
    "start": "935660",
    "end": "938389"
  },
  {
    "text": "as my own batch queue that's been",
    "start": "938389",
    "end": "940759"
  },
  {
    "text": "configured for use so now I'll jump over",
    "start": "940759",
    "end": "944240"
  },
  {
    "text": "to my terminal window to show you what",
    "start": "944240",
    "end": "946730"
  },
  {
    "text": "it's like running krummel from the",
    "start": "946730",
    "end": "948829"
  },
  {
    "text": "command line mode to run the haplotype",
    "start": "948829",
    "end": "951500"
  },
  {
    "text": "caller workflow for the purposes of this",
    "start": "951500",
    "end": "955370"
  },
  {
    "text": "demo I've collected all the files that",
    "start": "955370",
    "end": "959179"
  },
  {
    "text": "will be required to be able to run a",
    "start": "959179",
    "end": "961339"
  },
  {
    "text": "workflow",
    "start": "961339",
    "end": "962259"
  },
  {
    "text": "Cromwell on AWS so for example I have",
    "start": "962259",
    "end": "964929"
  },
  {
    "text": "the inputs JSON we just looked at which",
    "start": "964929",
    "end": "967809"
  },
  {
    "text": "are all the inputs files required for",
    "start": "967809",
    "end": "969790"
  },
  {
    "text": "the workflow the actual Whittle file",
    "start": "969790",
    "end": "972160"
  },
  {
    "text": "which is the workflow descriptor file",
    "start": "972160",
    "end": "974199"
  },
  {
    "text": "the AWS config which includes",
    "start": "974199",
    "end": "977350"
  },
  {
    "text": "information about the queue where these",
    "start": "977350",
    "end": "981160"
  },
  {
    "text": "jobs are going to be dispatched I have a",
    "start": "981160",
    "end": "983529"
  },
  {
    "text": "Cromwell jar that I've downloaded so",
    "start": "983529",
    "end": "986470"
  },
  {
    "text": "that's all that's needed to get started",
    "start": "986470",
    "end": "989079"
  },
  {
    "text": "so what I'm going to do is string",
    "start": "989079",
    "end": "991389"
  },
  {
    "text": "together the various components into the",
    "start": "991389",
    "end": "993069"
  },
  {
    "text": "required command for Cromwell",
    "start": "993069",
    "end": "995350"
  },
  {
    "text": "so the first thing I'm going to do is",
    "start": "995350",
    "end": "997569"
  },
  {
    "text": "point to the appropriate config file and",
    "start": "997569",
    "end": "1001129"
  },
  {
    "text": "then the appropriate Java file and then",
    "start": "1001129",
    "end": "1006959"
  },
  {
    "text": "the next required component for running",
    "start": "1006959",
    "end": "1010499"
  },
  {
    "text": "Cromwell on the run mode or what we call",
    "start": "1010499",
    "end": "1013439"
  },
  {
    "text": "command line mode is the path to the",
    "start": "1013439",
    "end": "1017100"
  },
  {
    "text": "Whittle in this case it's available",
    "start": "1017100",
    "end": "1019279"
  },
  {
    "text": "right within the same directory along",
    "start": "1019279",
    "end": "1021509"
  },
  {
    "text": "with an inputs file which uses a - I",
    "start": "1021509",
    "end": "1024630"
  },
  {
    "text": "parameter and the fault has - the inputs",
    "start": "1024630",
    "end": "1028649"
  },
  {
    "text": "JSON in this case and that's all that",
    "start": "1028649",
    "end": "1031889"
  },
  {
    "text": "should be needed to start off the run",
    "start": "1031889",
    "end": "1034339"
  },
  {
    "text": "you'll notice from observing the screen",
    "start": "1034339",
    "end": "1037918"
  },
  {
    "text": "in a couple of seconds that the Cromwell",
    "start": "1037919",
    "end": "1040709"
  },
  {
    "text": "logs can be quite verbose but we'll see",
    "start": "1040709",
    "end": "1044970"
  },
  {
    "text": "sort of a color shift when jobs have",
    "start": "1044970",
    "end": "1048840"
  },
  {
    "text": "been initialized prepared and dispatched",
    "start": "1048840",
    "end": "1051450"
  },
  {
    "text": "to the AWS batch back-end I'm starting",
    "start": "1051450",
    "end": "1056490"
  },
  {
    "text": "to see the this is the actual task",
    "start": "1056490",
    "end": "1061080"
  },
  {
    "text": "definition that was written inside of",
    "start": "1061080",
    "end": "1063629"
  },
  {
    "text": "the workflow so I'm seeing instantiation",
    "start": "1063629",
    "end": "1066299"
  },
  {
    "text": "of it being said - the batch back-end",
    "start": "1066299",
    "end": "1070309"
  },
  {
    "text": "and jobs that have started running",
    "start": "1073860",
    "end": "1078720"
  },
  {
    "text": "so while this workflow runs in the",
    "start": "1078720",
    "end": "1081060"
  },
  {
    "text": "background and since this is a fairly",
    "start": "1081060",
    "end": "1083310"
  },
  {
    "text": "computationally intensive workflow even",
    "start": "1083310",
    "end": "1085650"
  },
  {
    "text": "when running on a downsampled data set",
    "start": "1085650",
    "end": "1088460"
  },
  {
    "text": "it's going to take quite some time to",
    "start": "1088460",
    "end": "1092040"
  },
  {
    "text": "finish so what have what I've done in",
    "start": "1092040",
    "end": "1094590"
  },
  {
    "text": "lieu in place for this demo is to copy",
    "start": "1094590",
    "end": "1099690"
  },
  {
    "text": "down the results from the s3 bucket so I",
    "start": "1099690",
    "end": "1102870"
  },
  {
    "text": "have a results directory here which",
    "start": "1102870",
    "end": "1105930"
  },
  {
    "text": "includes all the outputs files generated",
    "start": "1105930",
    "end": "1108030"
  },
  {
    "text": "by one of the tasks in the workflow so",
    "start": "1108030",
    "end": "1110940"
  },
  {
    "text": "if you're wondering how you would find",
    "start": "1110940",
    "end": "1112230"
  },
  {
    "text": "these outputs themselves in the aid of",
    "start": "1112230",
    "end": "1114270"
  },
  {
    "text": "the socket as well then inside of your",
    "start": "1114270",
    "end": "1117420"
  },
  {
    "text": "crumble config itself you've declared",
    "start": "1117420",
    "end": "1121710"
  },
  {
    "text": "the s3 bucket used to store your outputs",
    "start": "1121710",
    "end": "1127280"
  },
  {
    "text": "so if you look at your AWS config",
    "start": "1127280",
    "end": "1130400"
  },
  {
    "text": "there's a line there's a key called",
    "start": "1130400",
    "end": "1133170"
  },
  {
    "text": "route which includes an s3 file path so",
    "start": "1133170",
    "end": "1136860"
  },
  {
    "text": "in this case all the all the various",
    "start": "1136860",
    "end": "1140360"
  },
  {
    "text": "work flex accuse performed using this",
    "start": "1140360",
    "end": "1143730"
  },
  {
    "text": "config file all fall within that",
    "start": "1143730",
    "end": "1146600"
  },
  {
    "text": "structure and within that bucket in s3",
    "start": "1146600",
    "end": "1151789"
  },
  {
    "text": "so what I'm going to do is list this",
    "start": "1152090",
    "end": "1156270"
  },
  {
    "text": "directory that I've specified in my kws",
    "start": "1156270",
    "end": "1161160"
  },
  {
    "text": "config file to make sure that the",
    "start": "1161160",
    "end": "1163680"
  },
  {
    "text": "workflow outputs are being added there",
    "start": "1163680",
    "end": "1166200"
  },
  {
    "text": "as I would expect so using the AWS CLI I",
    "start": "1166200",
    "end": "1171500"
  },
  {
    "text": "can Ellis is this directory structure",
    "start": "1171500",
    "end": "1178940"
  },
  {
    "text": "Aptech color is the name of my workflow",
    "start": "1178940",
    "end": "1180710"
  },
  {
    "text": "I can take an example run in the past",
    "start": "1180710",
    "end": "1189010"
  },
  {
    "text": "I can look specifically at the outputs",
    "start": "1189120",
    "end": "1191580"
  },
  {
    "text": "of the haplotype collar job or the merge",
    "start": "1191580",
    "end": "1195350"
  },
  {
    "text": "GBCs job and since this job was charted",
    "start": "1195350",
    "end": "1203790"
  },
  {
    "text": "across a single sample over various",
    "start": "1203790",
    "end": "1205530"
  },
  {
    "text": "genomic intervals and just want to take",
    "start": "1205530",
    "end": "1207210"
  },
  {
    "text": "the first one and here are the various",
    "start": "1207210",
    "end": "1211559"
  },
  {
    "text": "output files generated by this",
    "start": "1211559",
    "end": "1213840"
  },
  {
    "text": "particular task there is something",
    "start": "1213840",
    "end": "1217350"
  },
  {
    "text": "called there's something which is the RC",
    "start": "1217350",
    "end": "1220380"
  },
  {
    "text": "text which is the return code file which",
    "start": "1220380",
    "end": "1223140"
  },
  {
    "text": "represents the return code essentially",
    "start": "1223140",
    "end": "1226950"
  },
  {
    "text": "returned behind a program that was",
    "start": "1226950",
    "end": "1228420"
  },
  {
    "text": "executed inside of the command the",
    "start": "1228420",
    "end": "1230670"
  },
  {
    "text": "standard error and standard out produced",
    "start": "1230670",
    "end": "1232200"
  },
  {
    "text": "by the command as well along with any",
    "start": "1232200",
    "end": "1234540"
  },
  {
    "text": "final @ along with any outputs declared",
    "start": "1234540",
    "end": "1236820"
  },
  {
    "text": "in the task definition so since we have",
    "start": "1236820",
    "end": "1240660"
  },
  {
    "text": "local copies of the results we can start",
    "start": "1240660",
    "end": "1245130"
  },
  {
    "text": "off by checking out the contents of the",
    "start": "1245130",
    "end": "1246960"
  },
  {
    "text": "RC file so if a job succeeds at least",
    "start": "1246960",
    "end": "1251070"
  },
  {
    "text": "one using gatk the expected return code",
    "start": "1251070",
    "end": "1253320"
  },
  {
    "text": "is zero and this is something that can",
    "start": "1253320",
    "end": "1255360"
  },
  {
    "text": "differ from various tools but in this",
    "start": "1255360",
    "end": "1257640"
  },
  {
    "text": "case assuming that my job succeeded I",
    "start": "1257640",
    "end": "1261030"
  },
  {
    "text": "expect the contents of the return code",
    "start": "1261030",
    "end": "1262650"
  },
  {
    "text": "file to be zero and in case of debugging",
    "start": "1262650",
    "end": "1265890"
  },
  {
    "text": "any kinds of failures the return code",
    "start": "1265890",
    "end": "1268260"
  },
  {
    "text": "file is perfectly to start to understand",
    "start": "1268260",
    "end": "1270360"
  },
  {
    "text": "what was the final outcome of a command",
    "start": "1270360",
    "end": "1273950"
  },
  {
    "text": "secondarily it can also help when",
    "start": "1273950",
    "end": "1276330"
  },
  {
    "text": "debugging to look at the any contents",
    "start": "1276330",
    "end": "1280050"
  },
  {
    "text": "inside of the standard error Wow",
    "start": "1280050",
    "end": "1282120"
  },
  {
    "text": "so in this case the gatk outputted the",
    "start": "1282120",
    "end": "1285270"
  },
  {
    "text": "actual command the full command being",
    "start": "1285270",
    "end": "1288000"
  },
  {
    "text": "run by the gatk along with any default",
    "start": "1288000",
    "end": "1290309"
  },
  {
    "text": "parameters that are being applied which",
    "start": "1290309",
    "end": "1292860"
  },
  {
    "text": "can be helpful along with a standard out",
    "start": "1292860",
    "end": "1296010"
  },
  {
    "text": "file which includes which includes just",
    "start": "1296010",
    "end": "1302280"
  },
  {
    "text": "a lot of information being emitted by",
    "start": "1302280",
    "end": "1303870"
  },
  {
    "text": "the tool and it can be verbose it cannot",
    "start": "1303870",
    "end": "1307830"
  },
  {
    "text": "be it just really depends on the kind of",
    "start": "1307830",
    "end": "1309690"
  },
  {
    "text": "toolkit you're using and in this",
    "start": "1309690",
    "end": "1312420"
  },
  {
    "text": "particular case since my sample",
    "start": "1312420",
    "end": "1314130"
  },
  {
    "text": "succeeded I'm not going to dig too far",
    "start": "1314130",
    "end": "1316410"
  },
  {
    "text": "into my standard out file but instead",
    "start": "1316410",
    "end": "1319040"
  },
  {
    "text": "what I want to be able to do is just",
    "start": "1319040",
    "end": "1321679"
  },
  {
    "text": "investigate",
    "start": "1321679",
    "end": "1322930"
  },
  {
    "text": "the file contents of the actual output",
    "start": "1322930",
    "end": "1325120"
  },
  {
    "text": "file generated so I see that the VCF",
    "start": "1325120",
    "end": "1330220"
  },
  {
    "text": "produced is right here I'm going to",
    "start": "1330220",
    "end": "1336330"
  },
  {
    "text": "since this is AG zipped file I can",
    "start": "1336330",
    "end": "1339070"
  },
  {
    "text": "simply gun zip and extract the VCF",
    "start": "1339070",
    "end": "1342430"
  },
  {
    "text": "inside of this oh and I should be able",
    "start": "1342430",
    "end": "1347050"
  },
  {
    "text": "to ahead and look at the header of the",
    "start": "1347050",
    "end": "1350080"
  },
  {
    "text": "museum so I know that my VCF was",
    "start": "1350080",
    "end": "1353410"
  },
  {
    "text": "generated the header looks as if",
    "start": "1353410",
    "end": "1355180"
  },
  {
    "text": "expected with some of the sort of normal",
    "start": "1355180",
    "end": "1357940"
  },
  {
    "text": "attributes for it and so this gives me",
    "start": "1357940",
    "end": "1360730"
  },
  {
    "text": "confidence that my job succeeded and",
    "start": "1360730",
    "end": "1362800"
  },
  {
    "text": "then you can take this VCF or the cheese",
    "start": "1362800",
    "end": "1366070"
  },
  {
    "text": "up to VCF and pass it down to a tool",
    "start": "1366070",
    "end": "1368290"
  },
  {
    "text": "downstream so while this job runs the",
    "start": "1368290",
    "end": "1373930"
  },
  {
    "text": "workflows presented here should simply",
    "start": "1373930",
    "end": "1376780"
  },
  {
    "text": "reach success on the order of minutes",
    "start": "1376780",
    "end": "1379950"
  },
  {
    "start": "1379000",
    "end": "1428000"
  },
  {
    "text": "thanks Richie that was an awesome",
    "start": "1379950",
    "end": "1381940"
  },
  {
    "text": "demonstration thanks Lee I hope you all",
    "start": "1381940",
    "end": "1384610"
  },
  {
    "text": "get a chance to try out the various",
    "start": "1384610",
    "end": "1386380"
  },
  {
    "text": "tutorials and we would love to hear any",
    "start": "1386380",
    "end": "1388720"
  },
  {
    "text": "feedback you have so that concludes our",
    "start": "1388720",
    "end": "1391210"
  },
  {
    "text": "demonstrations if you'd like to learn",
    "start": "1391210",
    "end": "1393070"
  },
  {
    "text": "more I recommend checking out the docs",
    "start": "1393070",
    "end": "1394780"
  },
  {
    "text": "for cromwell and running genomics",
    "start": "1394780",
    "end": "1396820"
  },
  {
    "text": "workflows on AWS taking a look at",
    "start": "1396820",
    "end": "1399550"
  },
  {
    "text": "Cromwell's github repository and looking",
    "start": "1399550",
    "end": "1402100"
  },
  {
    "text": "at what you can do with wittle' at open",
    "start": "1402100",
    "end": "1404230"
  },
  {
    "text": "wittle detto RG if you'd like to learn",
    "start": "1404230",
    "end": "1406480"
  },
  {
    "text": "more about other scientific workloads on",
    "start": "1406480",
    "end": "1408220"
  },
  {
    "text": "AWS I recommend you check out our pages",
    "start": "1408220",
    "end": "1410770"
  },
  {
    "text": "on research and technical computing take",
    "start": "1410770",
    "end": "1415360"
  },
  {
    "text": "a look at our research cloud and cloud",
    "start": "1415360",
    "end": "1418210"
  },
  {
    "text": "credits for research programs and",
    "start": "1418210",
    "end": "1419850"
  },
  {
    "text": "explore datasets we host on a registry",
    "start": "1419850",
    "end": "1422650"
  },
  {
    "text": "of open data and with that I want to",
    "start": "1422650",
    "end": "1424690"
  },
  {
    "text": "thank everyone for watching I'm Lea I'm",
    "start": "1424690",
    "end": "1426880"
  },
  {
    "text": "Ruchi go build",
    "start": "1426880",
    "end": "1430170"
  }
]
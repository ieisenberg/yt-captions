[
  {
    "text": "Now our job flow is ready so lets SSH into\nthe master node.",
    "start": "4870",
    "end": "8842"
  },
  {
    "text": "The command line client provides an easy way\nto do this, just specify the SSH option and",
    "start": "8842",
    "end": "13639"
  },
  {
    "text": "give it a job flow ID.",
    "start": "13639",
    "end": "16420"
  },
  {
    "text": "The command runs SSH and soon you'll be connected\nto the master node.",
    "start": "16420",
    "end": "20660"
  },
  {
    "text": "Type Hive to start the Hive command line interface.",
    "start": "20660",
    "end": "24939"
  },
  {
    "text": "From here you'll be able to create tables\nand run queries.",
    "start": "24939",
    "end": "29328"
  },
  {
    "text": "Our tables are stored in JSON format. In order\nto read them, we'll need to use a custom JSON",
    "start": "29329",
    "end": "37219"
  },
  {
    "text": "SerDe.",
    "start": "37219",
    "end": "38219"
  },
  {
    "text": "SerDe is a feature of Hive and stands for\nSerializer/Deserializer.",
    "start": "38219",
    "end": "41760"
  },
  {
    "text": "They are written in Java and used to read\ncustom data formats.",
    "start": "41760",
    "end": "46338"
  },
  {
    "text": "To use the SerDe, we need to make Hive aware\nof it by calling \"add jar\". The location should",
    "start": "46339",
    "end": "52000"
  },
  {
    "text": "be a path in S3.",
    "start": "52000",
    "end": "53969"
  },
  {
    "text": "This specific SerDe was written by Amazon\nand can read JSON files.",
    "start": "53969",
    "end": "61469"
  },
  {
    "text": "Now, let's create some tables.",
    "start": "61469",
    "end": "63539"
  },
  {
    "text": "First we can type \"show tables\" and see that\nnone currently exist.",
    "start": "63539",
    "end": "67070"
  },
  {
    "text": "I am going to continue with the advertising\ncompany story.",
    "start": "67070",
    "end": "71660"
  },
  {
    "text": "We have two tables that are published by our\nad servers.",
    "start": "71660",
    "end": "74710"
  },
  {
    "text": "One that logs each impression and one that\nlogs each ad click.",
    "start": "74710",
    "end": "78869"
  },
  {
    "text": "Every five minutes the servers roll their\nlogs and upload them to S3.",
    "start": "78870",
    "end": "83410"
  },
  {
    "text": "The tables are partitioned by time, so the\nad servers have to stick the files in a specific",
    "start": "83410",
    "end": "88060"
  },
  {
    "text": "directory with other logs from that time period.",
    "start": "88060",
    "end": "91960"
  },
  {
    "text": "In order to read the table, Hive must know\nabout both the partition format and the table",
    "start": "91960",
    "end": "97159"
  },
  {
    "text": "SerDe.",
    "start": "97160",
    "end": "98160"
  },
  {
    "text": "Let's go ahead and create the impressions\ntable.",
    "start": "98160",
    "end": "100560"
  },
  {
    "text": "You'll notice the create table statement is\nsimilar to those in relational databases,",
    "start": "100560",
    "end": "104380"
  },
  {
    "text": "but with a few custom parameters.",
    "start": "104380",
    "end": "107310"
  },
  {
    "text": "This is an external table, which means that\nHive is aware of the table, but doesn't manage",
    "start": "107310",
    "end": "111500"
  },
  {
    "text": "the underlying storage itself.",
    "start": "111500",
    "end": "114070"
  },
  {
    "text": "I specify \"if not exists\" so that Hive won't\ndelete the table if it already exists.",
    "start": "114070",
    "end": "120040"
  },
  {
    "text": "I'll define each of the columns and tell Hive\nabout their type.",
    "start": "120040",
    "end": "124000"
  },
  {
    "text": "This table is partitioned. By default, Hive\noverwrites the table upon insert, but if it",
    "start": "124000",
    "end": "129229"
  },
  {
    "text": "is partitioned, then it can overwrite just\none partition, allowing you to perform inserts.",
    "start": "129229",
    "end": "134040"
  },
  {
    "text": "Hive can also use the partition information\nto limit the amount of data it scans if you",
    "start": "134040",
    "end": "138159"
  },
  {
    "text": "include the partition in the where clause.",
    "start": "138159",
    "end": "140799"
  },
  {
    "text": "This table is partitioned with a date time\nstring, which we must include in the create",
    "start": "140799",
    "end": "145310"
  },
  {
    "text": "table statement.",
    "start": "145310",
    "end": "146689"
  },
  {
    "text": "The files in our table contain one JSON object\nper line.",
    "start": "146689",
    "end": "150569"
  },
  {
    "text": "In order for Hive to read the table, we need\nto tell it to use our custom SerDe.",
    "start": "150569",
    "end": "154890"
  },
  {
    "text": "Since we already included the jar file containing\nthe SerDe, now we can reference it by class",
    "start": "154890",
    "end": "159790"
  },
  {
    "text": "name.",
    "start": "159790",
    "end": "161629"
  },
  {
    "text": "You can configure the SerDe with the SerDe\nproperties statement.",
    "start": "161629",
    "end": "165510"
  },
  {
    "text": "Our SerDe takes a path option which allows\nus to extract items from the JSON object by",
    "start": "165510",
    "end": "170389"
  },
  {
    "text": "specifying their path.",
    "start": "170389",
    "end": "173250"
  },
  {
    "text": "Each path corresponds to a column above.",
    "start": "173250",
    "end": "177480"
  },
  {
    "text": "Finally, we point to the location of our table\nin S3.",
    "start": "177480",
    "end": "183340"
  },
  {
    "text": "Hit enter and our table will be created.",
    "start": "183340",
    "end": "187170"
  },
  {
    "text": "Hive keeps track of table partitions in its\nmetadata store.",
    "start": "187170",
    "end": "190709"
  },
  {
    "text": "Right now, Hive does not know about any of\nour partitions because the table was just",
    "start": "190709",
    "end": "195510"
  },
  {
    "text": "created.",
    "start": "195510",
    "end": "196969"
  },
  {
    "text": "We could inform Hive of the partitions one\nby one, but this would be time consuming.",
    "start": "196969",
    "end": "201980"
  },
  {
    "text": "Fortunately, we added a feature to Hive that\nlets you recover partitions.",
    "start": "201980",
    "end": "206150"
  },
  {
    "text": "If you type \"alter table recover partitions\",\nHive will scan the table location and discover",
    "start": "206150",
    "end": "211370"
  },
  {
    "text": "all the partitions automatically.",
    "start": "211370",
    "end": "213870"
  },
  {
    "text": "If we type \"show partitions\" again, we can\nsee all partitions it discovered.",
    "start": "213870",
    "end": "219609"
  },
  {
    "text": "To prove to ourselves that the table is configured\nproperly, we can perform a select * on the",
    "start": "219609",
    "end": "224370"
  },
  {
    "text": "table.",
    "start": "224370",
    "end": "225370"
  },
  {
    "text": "This will print all the results to the screen.\nSince the table is large, we'll limit it to",
    "start": "225370",
    "end": "229689"
  },
  {
    "text": "ten rows.",
    "start": "229689",
    "end": "231299"
  },
  {
    "text": "Everything looks okay.",
    "start": "231299",
    "end": "232980"
  },
  {
    "text": "I'd also like to point out that the last column\nis the partition name.",
    "start": "232980",
    "end": "237629"
  },
  {
    "text": "If you filter on this in the where clause,\nHive will only read from the necessary files",
    "start": "237629",
    "end": "242450"
  },
  {
    "text": "and won't perform a full table scan.",
    "start": "242450",
    "end": "244950"
  },
  {
    "text": "Now lets go ahead and create our other table\nwhich includes information on ad clicks.",
    "start": "244950",
    "end": "250159"
  },
  {
    "text": "This is a similar process to creating the\nimpressions table, but clicks has fewer columns.",
    "start": "250159",
    "end": "256030"
  },
  {
    "text": "Don't forget to include the partition information\nand JSON SerDe.",
    "start": "256030",
    "end": "260850"
  },
  {
    "text": "This table is also stored in Amazon S3.",
    "start": "260850",
    "end": "265039"
  },
  {
    "text": "Since this table was just created, Hive doesn't\nknow about its partitions.",
    "start": "265039",
    "end": "268870"
  },
  {
    "text": "We can use recover partitions again to automatically\nadd them.",
    "start": "268870",
    "end": "273050"
  },
  {
    "text": "Let's make sure that worked correctly by listing\nthe partitions again.",
    "start": "273050",
    "end": "276810"
  },
  {
    "text": "Yep, everything looks okay.",
    "start": "276810",
    "end": "279550"
  },
  {
    "text": "Now that we are done with our input tables,\nit is time to create the output table.",
    "start": "279550",
    "end": "283620"
  },
  {
    "text": "This will contain the result of joining the\nimpressions and clicks tables.",
    "start": "283620",
    "end": "287020"
  },
  {
    "text": "We will call this table joined_impressions.",
    "start": "287020",
    "end": "290710"
  },
  {
    "text": "It contains all the columns from impressions,\nplus a new column called clicked.",
    "start": "290710",
    "end": "295590"
  },
  {
    "text": "Clicked will be set to true if that impression\nresulted in an ad click.",
    "start": "295590",
    "end": "300750"
  },
  {
    "text": "This table will be partitioned on two values:\nday and hour.",
    "start": "300750",
    "end": "304960"
  },
  {
    "text": "This allows us to schedule an hourly job which\ntakes the last hours worth of data from our",
    "start": "304960",
    "end": "309669"
  },
  {
    "text": "input tables and inserts it into this table.",
    "start": "309669",
    "end": "313080"
  },
  {
    "text": "Instead of using JSON, this table will be\nstored on disk in sequence file format.",
    "start": "313080",
    "end": "318439"
  },
  {
    "text": "Sequence file is a storage container that\nships with Hadoop and offers better performance",
    "start": "318440",
    "end": "323210"
  },
  {
    "text": "and more compression than JSON.",
    "start": "323210",
    "end": "325979"
  },
  {
    "text": "Finally, we point to the location in S3 where\nwe want to store our table.",
    "start": "325979",
    "end": "331580"
  },
  {
    "text": "This table does not contain any data yet,\nso there is no need to recover partitions.",
    "start": "331580",
    "end": "337000"
  },
  {
    "text": "Now lets go ahead and create the query used\ndata into this table.",
    "start": "337000",
    "end": "341039"
  },
  {
    "text": "We begin with a simple \"insert overwrite table\".",
    "start": "341039",
    "end": "345340"
  },
  {
    "text": "By default, this will erase all data in the\ntable. However, our table is partitioned,",
    "start": "345340",
    "end": "350800"
  },
  {
    "text": "so we can overwrite just a single partition.",
    "start": "350800",
    "end": "353909"
  },
  {
    "text": "When inserting into a partitioned table, we\nmust tell Hive which partition we are writing",
    "start": "353909",
    "end": "358629"
  },
  {
    "text": "to with the partition statement.",
    "start": "358629",
    "end": "361280"
  },
  {
    "text": "This statement takes a value for each of the\ntable's partitions, which in our case is day",
    "start": "361280",
    "end": "366310"
  },
  {
    "text": "and hour.",
    "start": "366310",
    "end": "368009"
  },
  {
    "text": "We have told Hive where to put the data, now\nwe need to tell it where to read the data",
    "start": "368009",
    "end": "372199"
  },
  {
    "text": "using a select statement.",
    "start": "372199",
    "end": "375139"
  },
  {
    "text": "As Hive joins the tables, we would also like\nto perform a transformation on request begin",
    "start": "375139",
    "end": "380330"
  },
  {
    "text": "time and convert it from a unix timestamp\ninto a human readable date.",
    "start": "380330",
    "end": "385520"
  },
  {
    "text": "This can be done easily using some of Hive's\nbuilt in functions.",
    "start": "385520",
    "end": "389189"
  },
  {
    "text": "Hive supports user defined functions so you\ncan create your own as well.",
    "start": "389189",
    "end": "394360"
  },
  {
    "text": "We will be joining the tables using a left\nouter join. The results will include every",
    "start": "394360",
    "end": "399138"
  },
  {
    "text": "impression from our time period.",
    "start": "399139",
    "end": "401150"
  },
  {
    "text": "If the impression resulted in an ad click,\nthen the corresponding row from the clicks",
    "start": "401150",
    "end": "405830"
  },
  {
    "text": "table will be included with the impression,\notherwise the click will be null.",
    "start": "405830",
    "end": "411400"
  },
  {
    "text": "This means we can set our clicked boolean\nby testing if the clicked row is null.",
    "start": "411400",
    "end": "417789"
  },
  {
    "text": "We tell Hive which tables to read from and\ntell it to join them on impression ID.",
    "start": "417789",
    "end": "424240"
  },
  {
    "text": "Finally, we limit our query to a certain time\nrange using the where clause.",
    "start": "424240",
    "end": "429090"
  },
  {
    "text": "Since we are filtering on the partition column,\nHive should read only the minimum number of",
    "start": "429090",
    "end": "433800"
  },
  {
    "text": "files necessary to retrieve our data.",
    "start": "433800",
    "end": "436939"
  },
  {
    "text": "You may notice the time range we are using\nfor the clicks table extends twenty minutes",
    "start": "436939",
    "end": "441379"
  },
  {
    "text": "longer than that of the impressions table.",
    "start": "441379",
    "end": "443990"
  },
  {
    "text": "This is to take into account that clicks don't\noccur at the same time as the impression.",
    "start": "443990",
    "end": "449240"
  },
  {
    "text": "Our software accepts clicks that occur up\nto twenty minutes after the impression.",
    "start": "449240",
    "end": "454979"
  },
  {
    "text": "When I hit enter, Hive parses the query and\ncompiles it into a series of MapReduce jobs.",
    "start": "454979",
    "end": "460210"
  },
  {
    "text": "This is a fairly simple query, so Hive is\nable to perform all the calculations in one",
    "start": "460210",
    "end": "465780"
  },
  {
    "text": "MapReduce pass.",
    "start": "465780",
    "end": "468860"
  },
  {
    "text": "Hive automatically submits your job to the\nHadoop cluster and waits for it to finish.",
    "start": "468860",
    "end": "475198"
  },
  {
    "text": "Here we can see the progress of the map and\nreduce stages.",
    "start": "475199",
    "end": "478520"
  },
  {
    "text": "I've sped up the video to make it go faster.",
    "start": "478520",
    "end": "484860"
  },
  {
    "text": "Once the job has finished, we can look at\nour data to make sure it looks okay.",
    "start": "484860",
    "end": "490698"
  },
  {
    "text": "Let's select just ten rows so we can get a\nsense of the data.",
    "start": "490699",
    "end": "495819"
  },
  {
    "text": "Notice how the clicked boolean is set in the\ntable.",
    "start": "495819",
    "end": "499080"
  },
  {
    "text": "Also, you can see the day and hour partitions\nin the results.",
    "start": "499080",
    "end": "504360"
  },
  {
    "text": "If you look at the very first column in each\nrow, you'll notice that the request begin",
    "start": "504360",
    "end": "508550"
  },
  {
    "text": "time is now in an easy to read format and\nis no longer a unix timestamp.",
    "start": "508550",
    "end": "514890"
  },
  {
    "text": "I've just demonstrated a data warehouse-like\nquery that joins data from two tables.",
    "start": "514890",
    "end": "520388"
  },
  {
    "text": "I ran this in interactive mode and only processed\none hours worth of data.",
    "start": "520389",
    "end": "524790"
  },
  {
    "text": "If you were using this query in production,\nyou would use the Hive batch mode and have",
    "start": "524790",
    "end": "529120"
  },
  {
    "text": "a schedular that automatically submits steps\nto Elastic MapReduce.",
    "start": "529120",
    "end": "534490"
  },
  {
    "text": "For more Hive examples within this use case,\nyou can read the tutorials on our website",
    "start": "534490",
    "end": "539300"
  },
  {
    "text": "at aws.amazon.com/elasticmapreduce.",
    "start": "539300",
    "end": "545380"
  },
  {
    "text": "Thank you for listening.",
    "start": "545380",
    "end": "546490"
  }
]
[
  {
    "text": "Amazon FSx for Lustre is a service that provides\ncost-effective, high-performance, scalable file",
    "start": "1160",
    "end": "7120"
  },
  {
    "text": "systems for compute workloads. Integrated with\nAmazon S3, FSx for Lustre makes it easy to",
    "start": "7120",
    "end": "12160"
  },
  {
    "text": "process S3 datasets with a high-performance file\nsystem. In this demo, we’ll see how to create an",
    "start": "12160",
    "end": "18160"
  },
  {
    "text": "FSx for Lustre file system and link it to our S3\nbuckets, allowing us to keep our S3 objects and",
    "start": "18160",
    "end": "23119"
  },
  {
    "text": "file system contents synchronized automatically.\nLet’s begin by creating the file system from the",
    "start": "23120",
    "end": "29000"
  },
  {
    "text": "Amazon FSx service page. We’ll select “Amazon\nFSx for Lustre” and click Next. Let’s call our file",
    "start": "29000",
    "end": "35400"
  },
  {
    "text": "system “fsx-demo” and configure its storage and\nthroughput settings. We’ll give it 2.4 TiB of storage",
    "start": "35400",
    "end": "42120"
  },
  {
    "text": "capacity on a Persistent SDD file system, with\n1,000 MB/s/TiB of throughput, which equates to",
    "start": "42120",
    "end": "48160"
  },
  {
    "text": "2400 MB/s. For the VPC Security Group, we’ll\nchoose the “fsx-demo” security group, which was",
    "start": "48160",
    "end": "57800"
  },
  {
    "text": "created ahead of this demo. This security group is\nconfigured to allow TCP access on the required",
    "start": "57800",
    "end": "62120"
  },
  {
    "text": "Lustre traffic ports from an existing EC2 instance\nthat we’ll be using to mount the file system. Under",
    "start": "62120",
    "end": "68799"
  },
  {
    "text": "data repository import/export, we'll check this box\nto indicate that this file system will be used to link",
    "start": "68800",
    "end": "73120"
  },
  {
    "text": "to an S3 data repository. This disables automatic\nbackups, which are not allowed on file systems",
    "start": "73120",
    "end": "79800"
  },
  {
    "text": "linked to S3 buckets, as your S3 buckets are still\nthe primary storage location for the full data set.",
    "start": "79800",
    "end": "84400"
  },
  {
    "text": "In the Logging card, we can choose to log failures\nand warnings in Amazon CloudWatch Logs so",
    "start": "84400",
    "end": "90000"
  },
  {
    "text": "that we’ll have visibility into any issues that arise when \nimporting from or exporting to the linked S3 bucket.",
    "start": "90000",
    "end": "95800"
  },
  {
    "text": "After clicking Next, we confirm our settings\nand click Create file system.",
    "start": "95800",
    "end": "100120"
  },
  {
    "text": "And in just a few minutes, the file system is ready. Now, let’s\nopen up our new file system in the console and link up",
    "start": "100120",
    "end": "107120"
  },
  {
    "text": "our S3 buckets from the Data Repository tab.\nLinks to S3 buckets, or prefixes within those",
    "start": "107120",
    "end": "112160"
  },
  {
    "text": "buckets, are called data repository associations\n(or DRAs), and a file system can have multiple",
    "start": "112160",
    "end": "119400"
  },
  {
    "text": "DRAs. Let’s create two of them. The file system\npath is the directory on the file system, under the",
    "start": "119400",
    "end": "125400"
  },
  {
    "text": "mount target directory, that will be mapped 1 to 1 with \nthe S3 bucket or the specified prefix on the S3 bucket.",
    "start": "125400",
    "end": "132000"
  },
  {
    "text": "We’ll enter “/dra1” as the directory name and \nlink this directory to the “sample” prefix",
    "start": "132000",
    "end": "138120"
  },
  {
    "text": "in an existing S3 bucket called “fsx-demo-bucket”.\nWe also have the option to load metadata for S3",
    "start": "138120",
    "end": "146120"
  },
  {
    "text": "objects in the data repository after the link is\ncreated, which will populate the file system with",
    "start": "146120",
    "end": "150120"
  },
  {
    "text": "file metadata and directory listings for the objects\nin the S3 bucket. We’ll skip the option to load",
    "start": "150120",
    "end": "156799"
  },
  {
    "text": "metadata for S3 objects in favor of using a data\nrepository task later. This can be advantageous if",
    "start": "156800",
    "end": "161120"
  },
  {
    "text": "you plan to use only a subset of the files under the\nprefix initially. The default automatic import and",
    "start": "161120",
    "end": "167400"
  },
  {
    "text": "export policies will keep the file system and the S3\nbucket synchronized with each other by",
    "start": "167400",
    "end": "171159"
  },
  {
    "text": "automatically importing updates from S3 and\nautomatically exporting updates on the file system",
    "start": "171160",
    "end": "177120"
  },
  {
    "text": "to the linked S3 bucket. We'll leave this\nconfiguration as it is. Now that the first DRA is",
    "start": "177120",
    "end": "184400"
  },
  {
    "text": "created, we’ll quickly create the second one. The\nprocess is the same as before, except this time",
    "start": "184400",
    "end": "189120"
  },
  {
    "text": "we’ll use “dra2” as the directory name and link it to\nan existing S3 bucket called",
    "start": "189120",
    "end": "194120"
  },
  {
    "text": "“fsx-demo-results-bucket”. We’ll use this 2nd DRA\nas a target for some file system operations that",
    "start": "194120",
    "end": "201000"
  },
  {
    "text": "we’ll run later on. Let’s mount our new file system\nonto an EC2 instance and see how everything looks.",
    "start": "201000",
    "end": "207400"
  },
  {
    "text": "If we open the file system in the console and click \nAttach to see the instructions on how to do so.",
    "start": "207400",
    "end": "213400"
  },
  {
    "text": "First, we switch over to our existing EC2 instance running \nAmazon Linux 2 and install the open-source Lustre client.",
    "start": "213400",
    "end": "219400"
  },
  {
    "text": "Then, we create a directory to use as a mount target. \nAnd finally, we copy and paste the mount command ",
    "start": "219400",
    "end": "225799"
  },
  {
    "text": "from the earlier screen. Now that the file system is \nmounted, we can see both of our buckets under",
    "start": "225800",
    "end": "230120"
  },
  {
    "text": "the “/fsx” directory; however, they both seem to be empty. \nThis is because we haven’t actually",
    "start": "230120",
    "end": "236000"
  },
  {
    "text": "loaded any of the bucket metadata yet. Let’s switch back \nto the console really quick to take care of that.",
    "start": "236000",
    "end": "242000"
  },
  {
    "text": "We’ll select both DRAs and click Import Task. For the \n“fsx-demo-bucket”, we’ll have it import metadata",
    "start": "242000",
    "end": "249120"
  },
  {
    "text": "from the prefix “sample/input”, and for the \n“fsx-demo-results-bucket”, we’ll have it import",
    "start": "249120",
    "end": "255799"
  },
  {
    "text": "metadata from the “output” prefix. Since we\nenabled Logging when creating the file system",
    "start": "255800",
    "end": "260799"
  },
  {
    "text": "earlier, we can leave the Completion report option\ndisabled, as any errors in the import process will",
    "start": "260800",
    "end": "265159"
  },
  {
    "text": "be recorded in CloudWatch Logs. The required metadata \nhas now been imported into the file system.",
    "start": "265160",
    "end": "271160"
  },
  {
    "text": "Let’s go back to our EC2 instance. Great!\nNow we can see all of the files from the",
    "start": "271160",
    "end": "276160"
  },
  {
    "text": "“sample/input” prefix in the “fsx-demo-bucket”. \nLet’s make some changes on the S3 side.",
    "start": "276160",
    "end": "283000"
  },
  {
    "text": "We’ll upload a new file to the S3 bucket, \nupload a new version of README.txt,",
    "start": "283000",
    "end": "290000"
  },
  {
    "text": "and delete the DELETE_ME.txt file.",
    "start": "290000",
    "end": "296000"
  },
  {
    "text": "Looking at the file system again, we see the DELETE_ME.txt \nfile is gone, NEWFILE.txt has been added, and README.txt",
    "start": "296000",
    "end": "305400"
  },
  {
    "text": "now says “Hello, world!” instead of the previous sample text. \nThis synchronization works both ways: Let’s move the",
    "start": "305400",
    "end": "312000"
  },
  {
    "text": "README.txt file to the “/fsx/dra2/output” directory,\nwhich is linked to “fsx-demo-results-bucket”, and is",
    "start": "312000",
    "end": "320000"
  },
  {
    "text": "currently empty. The README.txt has disappeared from \nthe first bucket and is now in the results bucket.",
    "start": "320000",
    "end": "327000"
  },
  {
    "text": "And finally, if we modify the README.txt file on the file \nsystem, we can see our changes reflected when we",
    "start": "327000",
    "end": "333120"
  },
  {
    "text": "download it from the S3 bucket in the AWS console. \nTo learn more about Amazon FSx for Lustre's",
    "start": "333120",
    "end": "339000"
  },
  {
    "text": "integration with Amazon S3, visit \naws.amazon.com/fsx/lustre.",
    "start": "339000",
    "end": "345177"
  }
]
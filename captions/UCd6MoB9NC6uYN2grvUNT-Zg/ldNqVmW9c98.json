[
  {
    "start": "0",
    "end": "48000"
  },
  {
    "text": "hi everybody and welcome we get to start we're gonna start anyway okay so my name",
    "start": "230",
    "end": "6779"
  },
  {
    "text": "is Mike Olsen I'm a Solutions Architect on the world wide public sector team for AWS I'm here with Dean Cleese's who's",
    "start": "6779",
    "end": "13740"
  },
  {
    "text": "gonna talk to you about what he's done with Jo APL I'm really excited about this project it was one of the first",
    "start": "13740",
    "end": "19650"
  },
  {
    "text": "customer meetings that I had when I came to Amazon and what they've done with",
    "start": "19650",
    "end": "25250"
  },
  {
    "text": "their Cerberus capability with our service capability and their project I think is going to be mind-blowing and no",
    "start": "25250",
    "end": "31320"
  },
  {
    "text": "pun intended so quick agenda of what we're gonna get into I'm going to level",
    "start": "31320",
    "end": "37140"
  },
  {
    "text": "set on some of the server some of the services that they're using and then I'm gonna kick it over to Dean who's gonna",
    "start": "37140",
    "end": "43230"
  },
  {
    "text": "tell you how he tried to break lambda which should be pretty interesting so in",
    "start": "43230",
    "end": "49320"
  },
  {
    "start": "48000",
    "end": "48000"
  },
  {
    "text": "the beginning there was virtual servers and it was good we were all happy with them we understood them ec2 made sense",
    "start": "49320",
    "end": "56699"
  },
  {
    "text": "but as time went on we realized that we needed to get out of just managing",
    "start": "56699",
    "end": "61980"
  },
  {
    "text": "servers and help customers get out of that Operations game so out came managed",
    "start": "61980",
    "end": "68340"
  },
  {
    "text": "services think RDS as we went through the maturity cycle and the paradigm",
    "start": "68340",
    "end": "73950"
  },
  {
    "text": "shift of what it meant to run things in the cloud the eye as play was great for",
    "start": "73950",
    "end": "80189"
  },
  {
    "text": "some pieces but we needed more and that's where serverless technology really came in because it allows us to",
    "start": "80189",
    "end": "85320"
  },
  {
    "text": "step away from that Operations mentality of I have to patch I have to manage I have to ensure and it allows us to get",
    "start": "85320",
    "end": "92490"
  },
  {
    "text": "to functions as a service I'm sure you've heard the the fast term around a lot so what is servos bring us well",
    "start": "92490",
    "end": "99780"
  },
  {
    "start": "96000",
    "end": "96000"
  },
  {
    "text": "serverless gives us the capability to not have to provision servers first of all it scales",
    "start": "99780",
    "end": "105990"
  },
  {
    "text": "easily and when we are not using it we're not paying for it which is a big piece of the operations side for cloud",
    "start": "105990",
    "end": "113520"
  },
  {
    "text": "so that's really exciting stuff but in addition to that how do we how are we",
    "start": "113520",
    "end": "120479"
  },
  {
    "start": "116000",
    "end": "116000"
  },
  {
    "text": "actually function within the the serverless paradigm well we're basically",
    "start": "120479",
    "end": "125759"
  },
  {
    "text": "building code and from that code we're saying I want to run the smallest piece of my application at the",
    "start": "125759",
    "end": "133410"
  },
  {
    "text": "the exact time that it's going to be called and then turn it off right we don't want to continue running that",
    "start": "133410",
    "end": "138810"
  },
  {
    "text": "service so lowers our security vector that we can be attacked on improves our",
    "start": "138810",
    "end": "143880"
  },
  {
    "text": "overall security posture and takes away from that that constant operational",
    "start": "143880",
    "end": "151350"
  },
  {
    "text": "challenge I'm gonna mention operational challenges a lot because that's really what we're trying to drive away from so",
    "start": "151350",
    "end": "156630"
  },
  {
    "start": "156000",
    "end": "156000"
  },
  {
    "text": "any missed lambda is obviously our server lists service that's out there",
    "start": "156630",
    "end": "161820"
  },
  {
    "text": "for you one of many actually now as you've heard through the announcements this week it allows you to go through",
    "start": "161820",
    "end": "169650"
  },
  {
    "text": "and say I'm gonna drop my operations management I'm gonna provision by this",
    "start": "169650",
    "end": "174690"
  },
  {
    "text": "by the actual utilization five minute bursts of compute it's still running",
    "start": "174690",
    "end": "181470"
  },
  {
    "text": "underlying on servers but you're not having to worry about what that instance looks like you're looking at it from ok",
    "start": "181470",
    "end": "188190"
  },
  {
    "text": "how much CPU do I need how much networking am I going to leverage and and what's that memory gonna look like",
    "start": "188190",
    "end": "194340"
  },
  {
    "text": "and then how many requests are we gonna see run now when you start thinking about what this means and we're",
    "start": "194340",
    "end": "200850"
  },
  {
    "text": "splitting out an application we're going to the serverless capability we think that ok we could start with one and",
    "start": "200850",
    "end": "206820"
  },
  {
    "text": "that's how a lot of people start we're gonna start really really Stinney we're gonna have one function that we're gonna call and that function is gonna do X",
    "start": "206820",
    "end": "213290"
  },
  {
    "text": "well what quickly happens is we realize that that function can call other functions and now we're trigger",
    "start": "213290",
    "end": "219630"
  },
  {
    "text": "triggering new events and as we're triggering off of that last function it starts to get even more complex because",
    "start": "219630",
    "end": "226260"
  },
  {
    "text": "we keep building these functions we're shutting down servers and we're getting really excited about what's URLs can do right and then we say well hey what if",
    "start": "226260",
    "end": "232590"
  },
  {
    "text": "we actually started dumping this into a database that's kind of cool and what if we take that data and we have a queue",
    "start": "232590",
    "end": "238290"
  },
  {
    "text": "for it because now we have so much data that's coming up we need to keep moving it around and we have to figure out all",
    "start": "238290",
    "end": "243300"
  },
  {
    "text": "right now the next functions going to be called how do we get that going well all of this gets a little complex to manage",
    "start": "243300",
    "end": "249450"
  },
  {
    "text": "right so that's where step functions comes in so step functions allows us to",
    "start": "249450",
    "end": "257010"
  },
  {
    "text": "coordinate and manage the way that an application state runs and it allows us",
    "start": "257010",
    "end": "262140"
  },
  {
    "text": "to kind of build out a script like equivalency to how we want to run",
    "start": "262140",
    "end": "267150"
  },
  {
    "text": "through our process and have that order and soup-to-nuts run through of our",
    "start": "267150",
    "end": "274460"
  },
  {
    "text": "functions so it allows for productivity step functions awesome it helping with",
    "start": "274460",
    "end": "280350"
  },
  {
    "start": "275000",
    "end": "275000"
  },
  {
    "text": "the distributed components piece it's awesome for agility it's going to allow",
    "start": "280350",
    "end": "285510"
  },
  {
    "text": "us to debug faster because we can actually track where something's happening is a chain it allows for",
    "start": "285510",
    "end": "293100"
  },
  {
    "text": "resiliency because before you know we weren't we'd have the lambda function run but if it didn't complete the the",
    "start": "293100",
    "end": "300479"
  },
  {
    "text": "job how would we know we needed to be able to dig in a little bit more and we needed maybe to be able to kick it off again if it didn't happen or we didn't",
    "start": "300479",
    "end": "307590"
  },
  {
    "start": "307000",
    "end": "307000"
  },
  {
    "text": "get the expected result so within the the lifecycle of a step function we're",
    "start": "307590",
    "end": "314550"
  },
  {
    "text": "gonna define a workflow a workflow is really just a series of steps that we're gonna go through we can set the",
    "start": "314550",
    "end": "320789"
  },
  {
    "text": "transition period as we go through each step this is called a state transition we're really good at naming things in",
    "start": "320789",
    "end": "326370"
  },
  {
    "text": "Amazon as you know and as we move through these these states state",
    "start": "326370",
    "end": "331560"
  },
  {
    "text": "functions it's all through JSON like you're used to building with a CloudFormation template and it allows us",
    "start": "331560",
    "end": "337470"
  },
  {
    "text": "to actually define each phase and then monitor and execute and evaluate as we roll through our step function process",
    "start": "337470",
    "end": "345740"
  },
  {
    "text": "so another service that Dean in GSU EPL",
    "start": "345740",
    "end": "351450"
  },
  {
    "start": "346000",
    "end": "346000"
  },
  {
    "text": "brought to bear was dynamo so you're familiar with dynamo I'm sure you've been listening to it a lot this week so",
    "start": "351450",
    "end": "358680"
  },
  {
    "text": "it's a no sequel database service it's a fully managed service there's no administration necessary and it's really",
    "start": "358680",
    "end": "365640"
  },
  {
    "text": "really low single-digit millisecond latency so it'll scale on demand you you",
    "start": "365640",
    "end": "371760"
  },
  {
    "text": "don't have to worry about the management piece and it's gonna give you the their required resources when you need it",
    "start": "371760",
    "end": "378800"
  },
  {
    "start": "377000",
    "end": "377000"
  },
  {
    "text": "so what do you use dynamo DB for well anything you're going to use a no sequel",
    "start": "378860",
    "end": "384120"
  },
  {
    "text": "database for you manage it for key pairings you can have just standard table sets in there",
    "start": "384120",
    "end": "390570"
  },
  {
    "text": "you can have reindex key pairing you can do document management even including",
    "start": "390570",
    "end": "396840"
  },
  {
    "text": "your JSON documents and it's going to scale as you need it so I went as fast as I",
    "start": "396840",
    "end": "404039"
  },
  {
    "text": "could to give this guy as much time as possible so I'm gonna introduce Dean now and he's gonna take it away thanks Mike",
    "start": "404039",
    "end": "415499"
  },
  {
    "text": "so like you said my name is Dean classes and gonna be talking to you today about",
    "start": "415499",
    "end": "420689"
  },
  {
    "text": "a project we've been working on for a while it's really exciting stuff so I've recently left Johns Hopkins Applied Physics Laboratory for a small startup",
    "start": "420689",
    "end": "428369"
  },
  {
    "text": "small data science company that we started but before that I spent about six or seven years at JHU APL worked on",
    "start": "428369",
    "end": "434879"
  },
  {
    "text": "a lots of different things but we spent a lot of time in this new field of high resolution connectomics where we're trying to do high-resolution brain",
    "start": "434879",
    "end": "441209"
  },
  {
    "text": "mapping for various reasons and today we're going to talk about kind of a culmination of a lot of that work that's",
    "start": "441209",
    "end": "446999"
  },
  {
    "text": "a large program that we help support this part of the brain initiative and you know the system we built in all the lessons we learned there so this program",
    "start": "446999",
    "end": "453629"
  },
  {
    "text": "it's called our upon microns eye ARPA's the intelligence Advanced Research Project activity it's kind of like the",
    "start": "453629",
    "end": "460679"
  },
  {
    "text": "they fund a lot of Advanced Research for the intelligence community the program",
    "start": "460679",
    "end": "466019"
  },
  {
    "text": "is currently being run by David Markowitz it's in its second phase and you know what this program sets out to",
    "start": "466019",
    "end": "472830"
  },
  {
    "text": "do is revolutionize machine learning by trying to understand how the brain works we can understand representations",
    "start": "472830",
    "end": "479309"
  },
  {
    "text": "transformations learning rules employed by the brain maybe we can make you know smarter machine learning algorithms and",
    "start": "479309",
    "end": "484589"
  },
  {
    "text": "we're not talking about copy-paste brain to a computer but more can we constrain these models with something that's more",
    "start": "484589",
    "end": "490559"
  },
  {
    "text": "biologically plausible obviously it works pretty well maybe we can learn a little bit about how you know biology",
    "start": "490559",
    "end": "496169"
  },
  {
    "text": "works and implement better architectures for machine learning and so what was",
    "start": "496169",
    "end": "502079"
  },
  {
    "text": "interesting about this program it's it's definitely designed to be this dialogue and in this structured you know exchange",
    "start": "502079",
    "end": "507959"
  },
  {
    "text": "between computer science data science neuroscientists physicists this large multi-disciplined project because of all",
    "start": "507959",
    "end": "514768"
  },
  {
    "text": "the technology developments required to kind of do the work they're setting out to do and so the way this thing is set",
    "start": "514769",
    "end": "520439"
  },
  {
    "text": "up is you know these teams proposed is about 30 some organizations will talk about at the end they propose some",
    "start": "520439",
    "end": "527009"
  },
  {
    "text": "machine learning framework that they think might be you know neroli plausible they actually create a behavior",
    "start": "527009",
    "end": "533070"
  },
  {
    "text": "bearment with some animal models so like a mouse or a rat that gets trained to do something and then they image that",
    "start": "533070",
    "end": "539730"
  },
  {
    "text": "animals brain while it's alive doing that activity probably learning or some sort of object recognition or something",
    "start": "539730",
    "end": "546750"
  },
  {
    "text": "like that and then they actually take the brain out image it structurally put",
    "start": "546750",
    "end": "551850"
  },
  {
    "text": "it all together and have to Co register is multi modal datasets that get huge and try to extract you know what's the",
    "start": "551850",
    "end": "558780"
  },
  {
    "text": "network graph of those neurons how do those neurons fire and try to use that",
    "start": "558780",
    "end": "563880"
  },
  {
    "text": "to better understand what's going on in the brain during some you know learning tasks and like that and so very",
    "start": "563880",
    "end": "570750"
  },
  {
    "text": "challenging problem so I ARPA dumped a bunch of money into it kind of boosted this field for which",
    "start": "570750",
    "end": "576120"
  },
  {
    "text": "is really exciting and so this program set up to be this iterative thing so phase one everyone did 100 cubic microns",
    "start": "576120",
    "end": "585300"
  },
  {
    "text": "of tissue and now on Phase two and you kind of reap redo the whole process at a cubic millimeter and that's where things",
    "start": "585300",
    "end": "591360"
  },
  {
    "text": "get challenging and that's kind of why we had to spend all this effort to build",
    "start": "591360",
    "end": "596370"
  },
  {
    "start": "595000",
    "end": "595000"
  },
  {
    "text": "out this infrastructure and so you know this stuff has been happened has been talked about a lot there's been all kinds of programs to try to make you",
    "start": "596370",
    "end": "603900"
  },
  {
    "text": "know biologically inspired machine learning they don't haven't been very fruitful you know in motional networks",
    "start": "603900",
    "end": "611040"
  },
  {
    "text": "you don't consider them now to be neroli inspired I mean they were considered merely inspired but they're not a bio",
    "start": "611040",
    "end": "616350"
  },
  {
    "text": "fidella corner lis plausible and what we mean by that is you know the operations",
    "start": "616350",
    "end": "622110"
  },
  {
    "text": "that current neural networks use daren't there's no known way to implement that",
    "start": "622110",
    "end": "627990"
  },
  {
    "text": "in biology so we're doing some tricks we're doing something that works and is reasonable but it's not the same and and",
    "start": "627990",
    "end": "634920"
  },
  {
    "text": "so the whole idea is that maybe there's something to learn there and so previous",
    "start": "634920",
    "end": "640710"
  },
  {
    "text": "programs have kind of looked at kind of a zoomed out view of the brain or maybe a very zoomed in view because that's",
    "start": "640710",
    "end": "646500"
  },
  {
    "text": "kind of what we were able to do until today we couldn't really interrogate what we call this meso scale so on the",
    "start": "646500",
    "end": "653220"
  },
  {
    "text": "order of a hundred a thousand to like a million neurons something like a cubic millimeter of brain like we just have",
    "start": "653220",
    "end": "658740"
  },
  {
    "text": "another technology until very recently to be able to do this and so this program is unique in that it goes after",
    "start": "658740",
    "end": "664350"
  },
  {
    "text": "that miso scale for the first time does a co-registration of structure and bunk function together and you know what",
    "start": "664350",
    "end": "672129"
  },
  {
    "text": "the researchers actually measure what's going on in the brain and so what's exciting about this is there's this",
    "start": "672129",
    "end": "678269"
  },
  {
    "text": "theory that you know the brain is set up with these things they call in cortical columns where on the order of a cubic",
    "start": "678269",
    "end": "683589"
  },
  {
    "text": "millimeter you've got this repeating motifs of some sort of circuits that do some sort of magical things that we",
    "start": "683589",
    "end": "689230"
  },
  {
    "text": "don't quite understand yet and so if we can actually look at it for the first time we'll learn lots of new information information and so what this is a pity",
    "start": "689230",
    "end": "697300"
  },
  {
    "text": "of is actually a 3d volume of tissue in an alive animal that was collected at",
    "start": "697300",
    "end": "705069"
  },
  {
    "text": "Cornell and Baylor it's part of this program what you see there is those little flashes of green are actually",
    "start": "705069",
    "end": "711579"
  },
  {
    "text": "neurons firing that's in the animal alive doing some tasks you can see you",
    "start": "711579",
    "end": "717519"
  },
  {
    "text": "know these neurons are firing and you just look at it as a picture it's kind of cool not necessarily useful",
    "start": "717519",
    "end": "723370"
  },
  {
    "text": "but if you do a lot of data analysis on this you can actually start to understand you know what there's what these circuits are starting to do so",
    "start": "723370",
    "end": "729939"
  },
  {
    "text": "when I say functional imaging we're measuring actually what each individual neuron is doing at a single neuron level",
    "start": "729939",
    "end": "735300"
  },
  {
    "text": "and like I said this is a 3d multi channel time series data set so as you",
    "start": "735300",
    "end": "741220"
  },
  {
    "text": "collect the long videos of it of this type starts adding up starts getting difficult to store getting difficult to",
    "start": "741220",
    "end": "747399"
  },
  {
    "text": "analyze so you need to do something to help that then like I said after you image it while the animal is alive and",
    "start": "747399",
    "end": "754029"
  },
  {
    "start": "749000",
    "end": "749000"
  },
  {
    "text": "you sacrifice it and take a little piece of brain out chop it up really really small and you're actually image with an",
    "start": "754029",
    "end": "760449"
  },
  {
    "text": "electron microscope every single slice these are 40 nanometer slices cut with like a diamond knife and so you can see",
    "start": "760449",
    "end": "766839"
  },
  {
    "text": "this resolution here is actually showing an individual synapse that's where two neurons actually meet and exchange information and this was done by taking",
    "start": "766839",
    "end": "774910"
  },
  {
    "text": "a piece of tissue and cutting it with a diamond knife that's been sharpened to like approximately an atom thick and",
    "start": "774910",
    "end": "780759"
  },
  {
    "text": "you're shaving off these 40 nanometer slices they're floating on the surface tension of the water and this little",
    "start": "780759",
    "end": "786189"
  },
  {
    "text": "boat you see they're getting picked up at the very bottom that video with some tape this is a video by Jeff Lichtman",
    "start": "786189",
    "end": "793089"
  },
  {
    "text": "and Bob because theory and Daniel Berger and at Harvard University this program and you can see as we zoom",
    "start": "793089",
    "end": "798560"
  },
  {
    "text": "in on one of these dyes the incredible resolution that you can get by using this imaging technique and well that's",
    "start": "798560",
    "end": "803930"
  },
  {
    "text": "awesome it's a pain for us because one of these",
    "start": "803930",
    "end": "809180"
  },
  {
    "text": "datasets that they're about to stat they're collecting right now is around two 2nf petabytes that's a single 3d",
    "start": "809180",
    "end": "816310"
  },
  {
    "text": "registered image volume so you need to do some sort of analysis to reconstruct",
    "start": "816310",
    "end": "823520"
  },
  {
    "text": "that graph to trace every neuron to find every synapse and so the challenge is not just how do I store on disk but how",
    "start": "823520",
    "end": "828830"
  },
  {
    "text": "do I store it make it accessible provide interface for machine learning algorithms to actually go through these",
    "start": "828830",
    "end": "834260"
  },
  {
    "text": "data and automatically segment everything and extract all the information because attitude to enough",
    "start": "834260",
    "end": "841010"
  },
  {
    "text": "petabytes these datasets that are being generated right now are so large that we probably think no human is ever going to",
    "start": "841010",
    "end": "846650"
  },
  {
    "text": "actually look at it it's so big and so dense you have to rely on you know",
    "start": "846650",
    "end": "852770"
  },
  {
    "text": "machine learning and AI and computer vision to actually analyze the data for you and so in these volumes that are",
    "start": "852770",
    "end": "860030"
  },
  {
    "text": "being created right now it's gonna be about a hundred thousand neurons maybe like a hundred million synapses and",
    "start": "860030",
    "end": "865100"
  },
  {
    "text": "what's interesting is each one of these little voxels each each pixel in that image is four by four by 30 nanometers",
    "start": "865100",
    "end": "872180"
  },
  {
    "text": "or 40 nanometers depending on the technology in use so it's incredibly high resolution and then the final thing",
    "start": "872180",
    "end": "880550"
  },
  {
    "text": "of why this is so cool and I took some time to explain all this because it is so cool but also kind of motivates why we're doing all this and why we had to",
    "start": "880550",
    "end": "886640"
  },
  {
    "text": "build so much work is this not its actual ability to Co register so these teams now are actually taking data from",
    "start": "886640",
    "end": "893420"
  },
  {
    "text": "that first data set the functional image which is a light microscopy technique and Co registering it with this other",
    "start": "893420",
    "end": "900440"
  },
  {
    "text": "structural imaging data set and so you can see the red lining up that is actually highlighting blood vessels so",
    "start": "900440",
    "end": "905780"
  },
  {
    "text": "that white bear this is an x-ray of a piece of tissue you can see the vasculature going into the brain and you",
    "start": "905780",
    "end": "911540"
  },
  {
    "text": "pop on that green and red and that's actually this other data set from the same animal at the same exact spot and",
    "start": "911540",
    "end": "918140"
  },
  {
    "text": "this is a very new and unique capability and to do that scale is what the challenge is and what's very unique about this program and so for the first",
    "start": "918140",
    "end": "924740"
  },
  {
    "text": "time you know researchers are going to be able to have some idea of the stimulus or the input",
    "start": "924740",
    "end": "930019"
  },
  {
    "text": "to the system they're gonna be able to know the behavior the output of the system they're gonna know the connectome",
    "start": "930019",
    "end": "937459"
  },
  {
    "text": "which is the circuit diagram and the activity which you can kind of think of us like the voltages and possibly with",
    "start": "937459",
    "end": "942739"
  },
  {
    "text": "all this information at scale for the first time you'll be able to learn something new and unique and useful to",
    "start": "942739",
    "end": "947929"
  },
  {
    "text": "constrain these models and better understand how how learning works in the brain and so why do we think we can do",
    "start": "947929",
    "end": "957889"
  },
  {
    "text": "this now why is this program finally getting off the ground and it's because basically technology advancements and",
    "start": "957889",
    "end": "963589"
  },
  {
    "text": "engineering so tons of work on this program was done on the engineering side especially all the microscopy all the",
    "start": "963589",
    "end": "970279"
  },
  {
    "text": "advances required there to just scale out the whole process increased",
    "start": "970279",
    "end": "976189"
  },
  {
    "text": "computing power is finally enabled this automated analysis and the automated analysis methods are finally getting",
    "start": "976189",
    "end": "982189"
  },
  {
    "text": "good enough to be able to actually analyze the data so we now have you know deep learning GPUs to to be able to all",
    "start": "982189",
    "end": "988549"
  },
  {
    "text": "the image processing which wasn't really available before now reduced storage costs because it's regenerating an",
    "start": "988549",
    "end": "994519"
  },
  {
    "text": "incredible amount of data and you know by moving everything to the cloud it gives us this ability to scale when",
    "start": "994519",
    "end": "1000369"
  },
  {
    "text": "needed and facilitate sharing of this large distributed program and so what we",
    "start": "1000369",
    "end": "1006160"
  },
  {
    "text": "did to kind of deal with this problem so we have this this issue of we need to store its spatial multi-dimensional data",
    "start": "1006160",
    "end": "1012339"
  },
  {
    "text": "it's big it needs to be analyzed and read by computer vision algorithms and",
    "start": "1012339",
    "end": "1018069"
  },
  {
    "text": "results written back needs to be visualized in a browser and collaboratively shared and so we built the system we call the boss for blocking",
    "start": "1018069",
    "end": "1026438"
  },
  {
    "text": "object storage service because you have to have an acronym and so what this is is this multi-dimensional database",
    "start": "1026439",
    "end": "1032139"
  },
  {
    "text": "system that we've certainly kind of provide as a managed service for the teams on Amazon and kind of what this is",
    "start": "1032139",
    "end": "1039788"
  },
  {
    "text": "illustrating is you know data comes off of a microscope comes off on these is these two-dimensional images that gets",
    "start": "1039789",
    "end": "1045370"
  },
  {
    "text": "registered and we dice it up and store it in this internal representation we call a cuboid which is you know reformat",
    "start": "1045370",
    "end": "1051039"
  },
  {
    "text": "the data into a small three-dimensional matrix that we then can store an s3 index with dynamo and then we can do",
    "start": "1051039",
    "end": "1057429"
  },
  {
    "text": "arbitrary retrieval of any subvolume within this data set you want to go you know do a cut out over here over",
    "start": "1057429",
    "end": "1064300"
  },
  {
    "text": "there or a slice or an any dimension we can go and get that data pretty quickly and insert it back to the user we also",
    "start": "1064300",
    "end": "1070720"
  },
  {
    "text": "store we call annotations which is basically unique identifier and voxel so you did some computer vision algorithm",
    "start": "1070720",
    "end": "1077680"
  },
  {
    "text": "you say this is a synapse this is a neuron this is something I care about and you can actually label the data and store that all code registered in the",
    "start": "1077680",
    "end": "1083770"
  },
  {
    "text": "same space and visualize it and we'll actually see that towards the end in a",
    "start": "1083770",
    "end": "1089260"
  },
  {
    "text": "demo so this is our high-level system",
    "start": "1089260",
    "end": "1094660"
  },
  {
    "start": "1092000",
    "end": "1092000"
  },
  {
    "text": "architecture and it's more of like the high-level engineering system architecture is like a marketing diagram",
    "start": "1094660",
    "end": "1099790"
  },
  {
    "text": "but there's a bunch of simplification that was done here but the way the system works is we run single sign-on",
    "start": "1099790",
    "end": "1106450"
  },
  {
    "text": "service that's used for all the applications that want to integrate with the boss and so we use key clock which",
    "start": "1106450",
    "end": "1112450"
  },
  {
    "text": "is kind of an open source that's a soap provider and we run that and a high",
    "start": "1112450",
    "end": "1118690"
  },
  {
    "text": "availability kind of set up with using my sequel on the backend and find a",
    "start": "1118690",
    "end": "1124630"
  },
  {
    "text": "little balance and all of that and we we then use that to authenticate request our API through our visualization tools",
    "start": "1124630",
    "end": "1130390"
  },
  {
    "text": "other users can build tools that that work off of this database and just share",
    "start": "1130390",
    "end": "1135670"
  },
  {
    "text": "credentials and get roles and just you know integrate right in because we we just built it from day one off of this",
    "start": "1135670",
    "end": "1141690"
  },
  {
    "text": "single sign-on service we currently use vault as our secret stores we run that the whole thing sits in a V PC with a",
    "start": "1141690",
    "end": "1148990"
  },
  {
    "text": "bastion server and we spent a lot of time building a lot of developer automation which is incredibly useful so",
    "start": "1148990",
    "end": "1155140"
  },
  {
    "text": "you know with a single command line you can spin up a little developer stack that's the entire system you know as you",
    "start": "1155140",
    "end": "1160270"
  },
  {
    "text": "get more complicated it gets really hard to you know develop let alone maintain it and so you know our automation will",
    "start": "1160270",
    "end": "1166540"
  },
  {
    "text": "spin all this up for a user and their own little V PC and then to the left is the primary system where we have a lot",
    "start": "1166540",
    "end": "1174580"
  },
  {
    "text": "of balancers sitting in front of a you know auto-scaling fleet of ec2 instances that serve our API a REST API and then",
    "start": "1174580",
    "end": "1183730"
  },
  {
    "text": "is the kind of the core data infrastructure where we use Redis to",
    "start": "1183730",
    "end": "1189190"
  },
  {
    "text": "track state and do some caching so we can get really fast response it for",
    "start": "1189190",
    "end": "1194529"
  },
  {
    "text": "commonly accessed data there's you know a couple different access patterns you know it's always challenging to kind of",
    "start": "1194529",
    "end": "1200299"
  },
  {
    "text": "model your users in your designing a system we've been doing this for a little while previous to this project",
    "start": "1200299",
    "end": "1205600"
  },
  {
    "text": "there is something called the open connectome project which then turned in this thing called neuro data at johns",
    "start": "1205600",
    "end": "1211429"
  },
  {
    "text": "hopkins kind of one of our key collaborators where a lot of this underlying concepts of how to represent the data and index the data was",
    "start": "1211429",
    "end": "1217669"
  },
  {
    "text": "originally developed and you know so we have an eight REST API that kind of",
    "start": "1217669",
    "end": "1223220"
  },
  {
    "text": "models a lot of that same interactions that we've done in the past and so also",
    "start": "1223220",
    "end": "1231980"
  },
  {
    "text": "the interesting thing is we use lambda and SQS to shuttle data between us three",
    "start": "1231980",
    "end": "1237590"
  },
  {
    "text": "MS cache so if you a common thing is there might be some really interesting region the data and the researchers",
    "start": "1237590",
    "end": "1244399"
  },
  {
    "text": "share it amongst themselves and look at it the viewer and so this thing gets read over and over and over and so instead of going and reading it out of",
    "start": "1244399",
    "end": "1250220"
  },
  {
    "text": "s3 every time and reformatting it we just keep it loaded decompressed in and Redis and can serve it out real fast",
    "start": "1250220",
    "end": "1256190"
  },
  {
    "text": "like a vis tool for example and we do all of that eviction and migration and",
    "start": "1256190",
    "end": "1261590"
  },
  {
    "text": "all of that using lambda and SQS between s3 and this Redis layer it's kind of",
    "start": "1261590",
    "end": "1266749"
  },
  {
    "text": "like the high-level core system and there's a whole bunch of other peripheral services that we built mainly",
    "start": "1266749",
    "end": "1272779"
  },
  {
    "text": "using serverless technology to kind of add functionality and that's kind of what we're really going to drill into today so like I said the boss is",
    "start": "1272779",
    "end": "1280759"
  },
  {
    "start": "1276000",
    "end": "1276000"
  },
  {
    "text": "accessible through a version REST API and we don't need to really go in then much of this in detail but you know we",
    "start": "1280759",
    "end": "1286759"
  },
  {
    "text": "have the ability to create users and manage users and we have a an abstraction of how you organize the data",
    "start": "1286759",
    "end": "1291860"
  },
  {
    "text": "and all of that manage that you can get arbitrary volumes and our objects and",
    "start": "1291860",
    "end": "1296869"
  },
  {
    "text": "tiles which is like a 2d image that gets rendered as an actual image but the two things we're going to kind of dig in",
    "start": "1296869",
    "end": "1302899"
  },
  {
    "text": "today a little bit are this service we call like a down sample service and which we use to build a resolution",
    "start": "1302899",
    "end": "1310909"
  },
  {
    "text": "hierarchy so kind of like if you think of Google Maps and you zoom in and out and you get big tiles and small tiles how can you do that efficiently at scale",
    "start": "1310909",
    "end": "1318340"
  },
  {
    "text": "and then our ingest service which is how we shuttle you know data from a",
    "start": "1318340",
    "end": "1324499"
  },
  {
    "text": "microscope stored in some crazy arbitrary way but some universe city and how do you get that into the cloud into the system and how do you do",
    "start": "1324499",
    "end": "1331039"
  },
  {
    "text": "that quickly when you have to do two petabytes and so you know we do while we",
    "start": "1331039",
    "end": "1338480"
  },
  {
    "start": "1335000",
    "end": "1335000"
  },
  {
    "text": "run some ec2 instances for some certain pieces the architecture like you saw we do leverage server lists and a lot of",
    "start": "1338480",
    "end": "1344840"
  },
  {
    "text": "amazon managed services a lot because you know it makes you go faster and it deals with a lot of our challenges of",
    "start": "1344840",
    "end": "1351230"
  },
  {
    "text": "scale and also managing our cost this is you know a government-funded project we have a budget to start and you feel most",
    "start": "1351230",
    "end": "1358730"
  },
  {
    "text": "designed to that budget and so managing cost is really important making sure that you can meet the needs of the teams",
    "start": "1358730",
    "end": "1365690"
  },
  {
    "text": "because there's also this interesting deadline situation you deal with where",
    "start": "1365690",
    "end": "1370750"
  },
  {
    "text": "everybody has the same deadline so everybody needs capacity at the same time so how do you build something that",
    "start": "1370750",
    "end": "1376460"
  },
  {
    "text": "can scale well and so we use dynamo heavily for all of our indexing we use",
    "start": "1376460",
    "end": "1383539"
  },
  {
    "text": "lamda heavily for a down sampling ingest and moving cache data around and dns",
    "start": "1383539",
    "end": "1388580"
  },
  {
    "text": "updates and we're gonna go into down sampling ingest in detail we use sqs a lot we wrote a lot of our own workflows",
    "start": "1388580",
    "end": "1395870"
  },
  {
    "text": "with sqs and lambda because high reliable execution of lambda was",
    "start": "1395870",
    "end": "1401179"
  },
  {
    "text": "important to us we the system runs essentially eventually consistent so someone post some data and we say we got",
    "start": "1401179",
    "end": "1408409"
  },
  {
    "text": "it and so we don't block on the user side so they can keep going but that data still needs to make its way through",
    "start": "1408409",
    "end": "1414019"
  },
  {
    "text": "lambda and do some other things and so we built a lot of highly reliable workflows using sqs to make sure that we",
    "start": "1414019",
    "end": "1421340"
  },
  {
    "text": "never lose a lambda function if it fails and then step functions came out and we'll talk about step functions a little",
    "start": "1421340",
    "end": "1426440"
  },
  {
    "text": "bit what you really can simplify that workflow a lot for you you know if you roll yourself you got a spin up sq sq",
    "start": "1426440",
    "end": "1433309"
  },
  {
    "text": "and you got to do a dead letter Q or you can do now with lambda also has dead letter Q's natively within the",
    "start": "1433309",
    "end": "1439250"
  },
  {
    "text": "application within lambda but kind of we did that ourselves about a year and a half ago and then step functions we'll",
    "start": "1439250",
    "end": "1448370"
  },
  {
    "text": "talk about and obviously we use s3 for our scale out storage object storage so",
    "start": "1448370",
    "end": "1454389"
  },
  {
    "text": "kind of a quick aside on step functions because",
    "start": "1454389",
    "end": "1460480"
  },
  {
    "text": "you know we when they were announced last year at reinvent yeah mounts last",
    "start": "1460480",
    "end": "1465700"
  },
  {
    "text": "year reinvent I was like oh this is cool we did a lot of us ourselves we should try using it and one of our engineers",
    "start": "1465700",
    "end": "1472680"
  },
  {
    "text": "Derek who I was like go look into this he looked at it and found it hard to use",
    "start": "1472680",
    "end": "1477730"
  },
  {
    "text": "because of both from maintaining the json spec and actually writing it and",
    "start": "1477730",
    "end": "1482920"
  },
  {
    "text": "he's like I'm gonna make a tool and then he made this awesome library we call it Heaviside so it's a",
    "start": "1482920",
    "end": "1490240"
  },
  {
    "text": "Python library and a DSL so a domain-specific language that's much simpler way to write and maintain your",
    "start": "1490240",
    "end": "1496780"
  },
  {
    "text": "set functions and the compiler then generates the JSON that the step function application expects and so that",
    "start": "1496780",
    "end": "1506830"
  },
  {
    "text": "DSL and compiler greatly simplifies writing and maintaining your step functions and what's also nice is it has",
    "start": "1506830",
    "end": "1512530"
  },
  {
    "text": "a built in some built-in tools and helper functions for creating and executing step functions uploading them",
    "start": "1512530",
    "end": "1518080"
  },
  {
    "text": "and configuring them and a framework for running activity servers activities are",
    "start": "1518080",
    "end": "1523540"
  },
  {
    "text": "a way to use the step function infrastructure but run your own server",
    "start": "1523540",
    "end": "1528730"
  },
  {
    "text": "so you so if you have some really long-running process for example and you",
    "start": "1528730",
    "end": "1533830"
  },
  {
    "text": "can't run it and lame because it's gonna timeout you can run activity server temporarily and kick that that to that",
    "start": "1533830",
    "end": "1539650"
  },
  {
    "text": "it'll still use that same infrastructure of scheduling it within a step function which is very useful for certain certain",
    "start": "1539650",
    "end": "1545620"
  },
  {
    "text": "cases and so we built this tool it's open source it's all in Python we'll talk about more at the end but it's",
    "start": "1545620",
    "end": "1551890"
  },
  {
    "text": "called Heaviside it's in our github repository feel free to use it we've gotten some some use and feedback from",
    "start": "1551890",
    "end": "1557500"
  },
  {
    "text": "people in community which has been good and we find it useful so like I said this is this is an example script this",
    "start": "1557500",
    "end": "1563410"
  },
  {
    "start": "1560000",
    "end": "1560000"
  },
  {
    "text": "is actually this is a workflow we use when somebody deletes a project in our",
    "start": "1563410",
    "end": "1569650"
  },
  {
    "text": "system that means we gotta go delete all this stuff there's cuboid data and s3 there's annotations in this database",
    "start": "1569650",
    "end": "1575770"
  },
  {
    "text": "there's stuff in a sequel database like how do you go remove all that and you",
    "start": "1575770",
    "end": "1580960"
  },
  {
    "text": "could be deleting tens of terabytes hundreds of terabytes so it's gonna take a while maybe and so we use step",
    "start": "1580960",
    "end": "1587050"
  },
  {
    "text": "function we have a step function that does this you know runs through the state machine of no deleting the metadata finding all the",
    "start": "1587050",
    "end": "1593789"
  },
  {
    "text": "cubes kicking a deletion of all those cubes to a fuss you know a bunch of lambda functions to go and delete all",
    "start": "1593789",
    "end": "1599129"
  },
  {
    "text": "those all the data out of s3 because it might take a while and so on the left is",
    "start": "1599129",
    "end": "1604529"
  },
  {
    "text": "our heavy side script that's mostly comments actually if you would look at",
    "start": "1604529",
    "end": "1610110"
  },
  {
    "text": "it it's pretty simple way to declare like you know run these three things in parallel retry with this back off you",
    "start": "1610110",
    "end": "1616529"
  },
  {
    "text": "know if this happened then error occurs go do this and then the thing in the middle that you can't read because it's",
    "start": "1616529",
    "end": "1621990"
  },
  {
    "text": "so long is the JSON for the step function and the thing on the far right it's actually that step function visualized in the state machine little",
    "start": "1621990",
    "end": "1630450"
  },
  {
    "text": "widget they have in the console and so this is really useful for us we use it",
    "start": "1630450",
    "end": "1635600"
  },
  {
    "text": "regularly still so if you are interested in playing around step functions I recommend checking it out let us know",
    "start": "1635600",
    "end": "1641009"
  },
  {
    "text": "what you think it's it's pretty useful so with that in mind let's talk a little",
    "start": "1641009",
    "end": "1648149"
  },
  {
    "start": "1644000",
    "end": "1644000"
  },
  {
    "text": "bit about this down sample workflow which is a pretty easy problem a pretty",
    "start": "1648149",
    "end": "1655590"
  },
  {
    "text": "easy you know conceptually thing to do and a good example of how we use step functions so so for this use case the",
    "start": "1655590",
    "end": "1663990"
  },
  {
    "text": "data comes in at native resolution it comes in you know off the microscope",
    "start": "1663990",
    "end": "1669179"
  },
  {
    "text": "registered it's big and we need to then build this resolution hierarchy so you",
    "start": "1669179",
    "end": "1674460"
  },
  {
    "text": "can zoom out effectively like you would slice a like an ax zoom Google Maps or you want to analyze the data at a lower",
    "start": "1674460",
    "end": "1679679"
  },
  {
    "text": "resolution than native because you know you want to save compute time you don't need all the the resolution you don't",
    "start": "1679679",
    "end": "1686309"
  },
  {
    "text": "need all the details so to do that you essentially need to pass the whole data set through some down sample process",
    "start": "1686309",
    "end": "1693960"
  },
  {
    "text": "that's gonna take the data and interpolate and write new data out and update indexes and so what's unique",
    "start": "1693960",
    "end": "1700350"
  },
  {
    "text": "about this is it runs infrequently it's basically once the users done uploading a data set it runs but it's triggered by",
    "start": "1700350",
    "end": "1707190"
  },
  {
    "text": "a user so you don't know when it's gonna happen you can't plan for it they're gonna upload something and say",
    "start": "1707190",
    "end": "1712200"
  },
  {
    "text": "downsample and it's gonna got it's got a kick off and so we wanted to build",
    "start": "1712200",
    "end": "1717330"
  },
  {
    "text": "something that just could be you know consume no resources when no one's using it but when someone who does go to use",
    "start": "1717330",
    "end": "1722549"
  },
  {
    "text": "it it could scale from you know 2 gigabytes to 2 petabyte and so what we ended up doing was using",
    "start": "1722549",
    "end": "1728850"
  },
  {
    "text": "a step function to manage this process of iteratively down sampling and then just a bunch of lambda functions to go",
    "start": "1728850",
    "end": "1734640"
  },
  {
    "text": "get the data down sample write the data back to s3 and so why this was good for",
    "start": "1734640",
    "end": "1741510"
  },
  {
    "text": "us is it you know we don't have to worry about about high availability you don't have to worry about servers keeping them up in case somebody happens don't want",
    "start": "1741510",
    "end": "1747690"
  },
  {
    "text": "to down sample something you know it's scales massively for a short period of time we have a pretty high limit on our",
    "start": "1747690",
    "end": "1753960"
  },
  {
    "text": "lambda capacity because we we let that being fan out and run real fast and then you know it's done and so kind of the",
    "start": "1753960",
    "end": "1761430"
  },
  {
    "start": "1760000",
    "end": "1760000"
  },
  {
    "text": "result of this would be something like you've got this full resolution electron microscopy image and then you have to",
    "start": "1761430",
    "end": "1767340"
  },
  {
    "text": "create so you take those two petabytes and then you process that and you create a 500 you know terabyte version and then",
    "start": "1767340",
    "end": "1774450"
  },
  {
    "text": "you process that you create 128 and so on and so the step function is actually quite simple up in that top corner just",
    "start": "1774450",
    "end": "1780180"
  },
  {
    "text": "iteratively loops calling lambda functions until it's done checking if it needs the you know increments how much",
    "start": "1780180",
    "end": "1786600"
  },
  {
    "text": "it's down sampling from and then you know you let this thing run and after a",
    "start": "1786600",
    "end": "1791670"
  },
  {
    "text": "little while you have the full resolution hierarchy available and in our system as soon as the data is",
    "start": "1791670",
    "end": "1797160"
  },
  {
    "text": "written it's available so as this thing's running you could go in the viewer and you'll start zooming out and you'll start seeing I think the lower",
    "start": "1797160",
    "end": "1803340"
  },
  {
    "text": "res data show up which is kind of cool and so kind of digging into how this",
    "start": "1803340",
    "end": "1808470"
  },
  {
    "start": "1805000",
    "end": "1805000"
  },
  {
    "text": "actually works is you know user makes an API call so they hit R that's one",
    "start": "1808470",
    "end": "1814830"
  },
  {
    "text": "request that goes to a server we actually have to make sure it's live and then from that point on it's all just on AWS infrastructure running and the step",
    "start": "1814830",
    "end": "1822840"
  },
  {
    "text": "function so the step function starts that base resolution kicks off a bunch",
    "start": "1822840",
    "end": "1829290"
  },
  {
    "text": "of lambda functions that ask this index table is there a cube here that I should Dan sample if it is you know in parallel",
    "start": "1829290",
    "end": "1837210"
  },
  {
    "text": "all these limit functions then download for cubes the data turn them into one",
    "start": "1837210",
    "end": "1842310"
  },
  {
    "text": "cubed data write it back and then update that index table saying that this",
    "start": "1842310",
    "end": "1847410"
  },
  {
    "text": "new data is available and this just happens it early in parallel until it's done and because of the step function it",
    "start": "1847410",
    "end": "1856260"
  },
  {
    "text": "will ensure the lambda functions complete if Elena function fails it'll retry it with some back off for certain amount of time before it",
    "start": "1856260",
    "end": "1862440"
  },
  {
    "text": "fails completely and all that's really managed for you if you use step functions and set them up properly which",
    "start": "1862440",
    "end": "1867540"
  },
  {
    "text": "is very nice it kind of simplifies some of the the bookkeeping you need to do to make sure that every all the data runs",
    "start": "1867540",
    "end": "1873360"
  },
  {
    "text": "through because the last thing you want is you zoom in and we did have a bug at one point when we first implemented this",
    "start": "1873360",
    "end": "1879690"
  },
  {
    "start": "1874000",
    "end": "1874000"
  },
  {
    "text": "where you zoom out then there would just be a little black square and you're like oh no like you missed one skew from one",
    "start": "1879690",
    "end": "1885570"
  },
  {
    "text": "little cube in the whole thing it's like how do I go back and get that one I don't know so being able to make sure",
    "start": "1885570",
    "end": "1890760"
  },
  {
    "text": "that you're getting almost guaranteeing everything will run completion or you know it fails is an important thing for us all right",
    "start": "1890760",
    "end": "1900440"
  },
  {
    "text": "so the next thing I want to talk about a little bit more complicated but",
    "start": "1903920",
    "end": "1909120"
  },
  {
    "text": "something I was really happy with when we got it working was this ingest workflow and this is kind of how we we",
    "start": "1909120",
    "end": "1916770"
  },
  {
    "text": "broke lamda which is cool so the problem here is you've got all these",
    "start": "1916770",
    "end": "1922980"
  },
  {
    "text": "universities creating data they store it in their own random unique way on their",
    "start": "1922980",
    "end": "1928170"
  },
  {
    "text": "own whatever infrastructure from you know the Allen Institute for brain science",
    "start": "1928170",
    "end": "1933210"
  },
  {
    "text": "they have you know essentially like enterprise-grade engineers and infrastructure it's well",
    "start": "1933210",
    "end": "1939990"
  },
  {
    "text": "organized and it's great but they may have really small internet connection to someone like Harvard where they're",
    "start": "1939990",
    "end": "1946950"
  },
  {
    "text": "awesome but it's all homegrown in the lab but they have like this crazy internet connection this huge pipe and",
    "start": "1946950",
    "end": "1953160"
  },
  {
    "text": "so it's all over the place people store it all differently and so how can we build something that supports all these users and can meet the needs of the",
    "start": "1953160",
    "end": "1959580"
  },
  {
    "text": "program namely that you know everybody waits the last minute probably guarantee",
    "start": "1959580",
    "end": "1965100"
  },
  {
    "text": "you that you know right before the deadline everyone's gonna be sending us data as hard as they can and so we need",
    "start": "1965100",
    "end": "1970140"
  },
  {
    "text": "to build something that could scale really really well the trends for these large amounts of",
    "start": "1970140",
    "end": "1975480"
  },
  {
    "text": "data get them into the cloud and get them reformatted so they are now you",
    "start": "1975480",
    "end": "1980640"
  },
  {
    "text": "know in the boss cuboid structure loaded indexed and ready to go and so we",
    "start": "1980640",
    "end": "1986280"
  },
  {
    "text": "implemented this kind of kind of ETL process that uses sqs s3 lamda DynamoDB",
    "start": "1986280",
    "end": "1992820"
  },
  {
    "text": "and a python-based client that runs both multi-process and distributed and with",
    "start": "1992820",
    "end": "2001640"
  },
  {
    "text": "just that kind of setup which we'll talk about in detail we're able to again when",
    "start": "2001640",
    "end": "2007700"
  },
  {
    "text": "no one's loading sending us data we don't want to keep anything on so no one's sending us data nothing's happening and as soon as someone decides",
    "start": "2007700",
    "end": "2013520"
  },
  {
    "text": "to start a job we don't even need to know about it they click a button upload this file things start rolling and",
    "start": "2013520",
    "end": "2018920"
  },
  {
    "text": "everything just starts to scale so I'll kind of step you through how this",
    "start": "2018920",
    "end": "2024290"
  },
  {
    "text": "process works because it's a little can be a little confusing but it's pretty",
    "start": "2024290",
    "end": "2029780"
  },
  {
    "text": "interesting so again because it's on-demand and you can't be prepared for it you need things to kind of be",
    "start": "2029780",
    "end": "2037820"
  },
  {
    "text": "automated and so the way this works is we have a pretty simple JSON spec that specifies the ingest job like how big is",
    "start": "2037820",
    "end": "2044960"
  },
  {
    "text": "the data set you know what's the size of image tiles what's the name of the",
    "start": "2044960",
    "end": "2050870"
  },
  {
    "text": "project that's loading in - pretty simple stuff like that we have a tool it kind of helps configure that so basically you just post this JSON spec",
    "start": "2050870",
    "end": "2056990"
  },
  {
    "text": "to our API so again that's the only machine we really need to manage ourselves you say here's the here's the",
    "start": "2056990",
    "end": "2064429"
  },
  {
    "text": "what I'm about to do or our system quickly then generates an upload task queue in SQS and enumerates basically",
    "start": "2064429",
    "end": "2074389"
  },
  {
    "start": "2072000",
    "end": "2072000"
  },
  {
    "text": "every file that needs to get put up into the system and this isn't interesting in that you know sqs scales really really",
    "start": "2074390",
    "end": "2081260"
  },
  {
    "text": "well you can do tons of requests to it but it's a little odd that you can't put messages into it that quickly you can",
    "start": "2081260",
    "end": "2089510"
  },
  {
    "text": "only do up to like 35 at a time I think and so from a single thread it actually takes a long time you know we'll have a",
    "start": "2089510",
    "end": "2096500"
  },
  {
    "text": "data set will be millions of files that needs to get need to get written and in phase 2 is an even more like tens of",
    "start": "2096500",
    "end": "2102440"
  },
  {
    "text": "millions or more at a time and so actually populate a task queue sqs queue it like a million files takes like hours",
    "start": "2102440",
    "end": "2108320"
  },
  {
    "text": "if you do it single thread so we ended up actually using another little step function that when that user says do",
    "start": "2108320",
    "end": "2114860"
  },
  {
    "text": "this job we figure out all the files need to get generated based on this information they gave us and then we fan out on us on lambda a",
    "start": "2114860",
    "end": "2122120"
  },
  {
    "text": "bunch of workers to just jut Jam all these into an sqs queue and once that's full",
    "start": "2122120",
    "end": "2129780"
  },
  {
    "text": "oh yeah a little animation see so as messages go up in that queue in parallel",
    "start": "2129780",
    "end": "2136130"
  },
  {
    "text": "and once that's done the system now is like ready to go ready to ingest those",
    "start": "2136130",
    "end": "2142260"
  },
  {
    "start": "2138000",
    "end": "2138000"
  },
  {
    "text": "that's that function it's gone those lambda functions are gone and this other kind of service infrastructure pops up",
    "start": "2142260",
    "end": "2148890"
  },
  {
    "text": "where this client we wrote this ingest client like I said you can run it",
    "start": "2148890",
    "end": "2154290"
  },
  {
    "text": "multi-threaded distributed so the Harvard team that really stressed test helped a stress test this in the",
    "start": "2154290",
    "end": "2160320"
  },
  {
    "text": "beginning you know they run this on to big beefy boxes that are both connected",
    "start": "2160320",
    "end": "2166200"
  },
  {
    "text": "Internet to and so they can really shove a lot of data up to us which is pretty",
    "start": "2166200",
    "end": "2171270"
  },
  {
    "text": "interesting and so the way this works and why it's like a resilient again we got to make sure every single file gets",
    "start": "2171270",
    "end": "2176400"
  },
  {
    "text": "in we can't drop a single file or else you lose you know if you've one bit of missing data you've corrupted this data",
    "start": "2176400",
    "end": "2182430"
  },
  {
    "text": "set and so the way it works is that in just client thread just says give me a task just gets a message from sqs queue",
    "start": "2182430",
    "end": "2189030"
  },
  {
    "text": "and that message tells it what file to send up and so it loads the file using",
    "start": "2189030",
    "end": "2194190"
  },
  {
    "text": "some a little like plugin for that specific person and how their data gets loaded and writes that data up into an",
    "start": "2194190",
    "end": "2200400"
  },
  {
    "text": "s3 tile bucket so it's like a temporary bucket we provision when you start this job and that bucket has a trigger that",
    "start": "2200400",
    "end": "2208080"
  },
  {
    "text": "calls the lambda function so every time you put a function every time you put a file in that bucket triggers a lambda",
    "start": "2208080",
    "end": "2214470"
  },
  {
    "text": "function and that lambda function then I'll I clicked it fast so what this",
    "start": "2214470",
    "end": "2221070"
  },
  {
    "text": "happens this happens over and over and over right and the lambda function checks this index table and dine up and",
    "start": "2221070",
    "end": "2226740"
  },
  {
    "text": "dynamodb that's keeping track of all the files that have made it successfully up in this bucket because like I said we've got this three dimensional",
    "start": "2226740",
    "end": "2231920"
  },
  {
    "text": "representation of our data so we can't load any data in until we get enough in",
    "start": "2231920",
    "end": "2237330"
  },
  {
    "text": "3d so this thing's sitting there waiting waiting waiting and as soon as there's enough of tiles in a specific region",
    "start": "2237330",
    "end": "2244160"
  },
  {
    "start": "2244000",
    "end": "2244000"
  },
  {
    "text": "it's all good to go and we actually invoke asynchronously another lambda function that then goes and pulls those",
    "start": "2244160",
    "end": "2251010"
  },
  {
    "text": "temporary tiles reformats them into our little cube representation writes them",
    "start": "2251010",
    "end": "2256560"
  },
  {
    "text": "into s3 and updates an index table now that data is available like if ul again if you have a vist or Vistal open",
    "start": "2256560",
    "end": "2262780"
  },
  {
    "text": "as that's running you'll start seeing data pop up as soon as it's in that index table you can read it and so this",
    "start": "2262780",
    "end": "2269860"
  },
  {
    "text": "oh yeah and then deletes a temporary data tiles",
    "start": "2269860",
    "end": "2275460"
  },
  {
    "text": "and so this workflow has been really useful in that it lets us you know scale",
    "start": "2275460",
    "end": "2282880"
  },
  {
    "start": "2276000",
    "end": "2276000"
  },
  {
    "text": "on demand be highly resilient to temporary errors you know we've had",
    "start": "2282880",
    "end": "2288700"
  },
  {
    "text": "trouble with you know a network issue all of a sudden drop a bunch of tiles fail a bunch of lambda rights but",
    "start": "2288700",
    "end": "2294970"
  },
  {
    "text": "because it's based on this sqs queue that's just the task that task doesn't get deleted until the very end and so if",
    "start": "2294970",
    "end": "2302410"
  },
  {
    "text": "that file didn't make it up after the timeout it's just gonna show back up on",
    "start": "2302410",
    "end": "2308290"
  },
  {
    "text": "show show up in the queue again and when some worker thread is gonna grab that and re-upload it again and so we've been",
    "start": "2308290",
    "end": "2314260"
  },
  {
    "text": "able to get pretty reliable transfer rates you know we peaked over with some initial testing again just with just",
    "start": "2314260",
    "end": "2320530"
  },
  {
    "text": "with two machines and kind of small tiles so it wasn't really optimized but you know we were getting sis bursts over",
    "start": "2320530",
    "end": "2326560"
  },
  {
    "text": "4 gigabits per second sustained around 3 gigabits per second so we were able to load just run sustain it for you if it's",
    "start": "2326560",
    "end": "2333070"
  },
  {
    "text": "per second through this fully server list workflow and not have to scale any of our infrastructure you know we still",
    "start": "2333070",
    "end": "2338140"
  },
  {
    "text": "had an API server to running if that and this thing scales out I want to say",
    "start": "2338140",
    "end": "2343180"
  },
  {
    "text": "something like 1500 lambda functions maybe a bit more kind of in parallel",
    "start": "2343180",
    "end": "2348760"
  },
  {
    "text": "always going dynamo DB scaling automatically and we're able to stream",
    "start": "2348760",
    "end": "2353770"
  },
  {
    "text": "all this data from this on-prem site right into the system all right and so",
    "start": "2353770",
    "end": "2365550"
  },
  {
    "text": "another interesting kind of side effect",
    "start": "2365550",
    "end": "2371980"
  },
  {
    "text": "of how this was built was because we built it straight on Amazon services you",
    "start": "2371980",
    "end": "2378010"
  },
  {
    "text": "know we do have some users and in general you know you maybe you don't have an internet connection that can send two petabytes it'll just take too",
    "start": "2378010",
    "end": "2384400"
  },
  {
    "text": "long you don't have an internet to connection you don't you don't have the bandwidth and so there's some work and",
    "start": "2384400",
    "end": "2390240"
  },
  {
    "text": "some some work we're gonna be doing to enable using snowball so since this runs",
    "start": "2390240",
    "end": "2395369"
  },
  {
    "text": "off of a bucket trigger you just upload the tiles with been just client into a snowball instead of sitting over the",
    "start": "2395369",
    "end": "2402000"
  },
  {
    "text": "Internet snowball shows up at Amazon they plug it in as those files hit that bucket they just kick through the same exact process",
    "start": "2402000",
    "end": "2408180"
  },
  {
    "text": "with like minimal code change there's a really nice way to be able to go both from just streaming it over the web",
    "start": "2408180",
    "end": "2413970"
  },
  {
    "text": "which is preferred from from our perspective but also if you can't just send a snowball and so what's nice about",
    "start": "2413970",
    "end": "2420900"
  },
  {
    "text": "this design and why we did this way is you know this ingest rate is limited by the users local resources and bandwidth",
    "start": "2420900",
    "end": "2426390"
  },
  {
    "text": "you never wanted you know somebody waiting on us to scale out or you know",
    "start": "2426390",
    "end": "2432480"
  },
  {
    "text": "if we crash how do we pull it back get the data in how do we catch up it's basically you know because we just sit",
    "start": "2432480",
    "end": "2437940"
  },
  {
    "text": "straight on top of amazon's infrastructure the user can send us the data as fast as user can send us the data we've been able to to load it into",
    "start": "2437940",
    "end": "2445020"
  },
  {
    "text": "the system and so now we want to just touch on a couple things we learned",
    "start": "2445020",
    "end": "2452369"
  },
  {
    "start": "2446000",
    "end": "2446000"
  },
  {
    "text": "through this process of you know trying to really implement some interesting",
    "start": "2452369",
    "end": "2458790"
  },
  {
    "text": "serverless workflows in this system and so the first is some things to think about when you if you want to start",
    "start": "2458790",
    "end": "2464250"
  },
  {
    "text": "using lambda for something you're working on well actually I guess not anymore but you know we got announced",
    "start": "2464250",
    "end": "2471869"
  },
  {
    "text": "today they can go up to the three gigabytes in memory but you know lambda isn't a cure-all it's not a panacea it's",
    "start": "2471869",
    "end": "2477060"
  },
  {
    "text": "not gonna work in all use cases we have some use cases where you we wished we could use lambda but we need a more memory maybe now we can do that since",
    "start": "2477060",
    "end": "2483540"
  },
  {
    "text": "they've upped it to three but for tests that are well-suited for lambda it's awesome in my opinion and so",
    "start": "2483540",
    "end": "2490950"
  },
  {
    "text": "some things to keep in mind is that again if your task needs run more than five minutes or over three gigabytes of memory probably is gonna be a good",
    "start": "2490950",
    "end": "2497670"
  },
  {
    "text": "solution for you but if it's under that it might be another thing to think about is more memory equals more CPU this can",
    "start": "2497670",
    "end": "2504600"
  },
  {
    "text": "be counterintuitive because that means gonna be paying for more money per hundred millisecond of execution but",
    "start": "2504600",
    "end": "2510270"
  },
  {
    "text": "your lambda function might run faster so this is an interesting thing that to play with and optimize once you get",
    "start": "2510270",
    "end": "2515730"
  },
  {
    "text": "things working is if you only need you know the minimum about a memory but it's a kind of CPU intensive process you",
    "start": "2515730",
    "end": "2522030"
  },
  {
    "text": "actually add more memory you get some more CPU allocation and your function can finish faster and",
    "start": "2522030",
    "end": "2527720"
  },
  {
    "text": "ultimately cost you less money that's something to always think about optimizing after you get things working",
    "start": "2527720",
    "end": "2533690"
  },
  {
    "text": "and another interesting thing that's a limitation that might not be great is",
    "start": "2533690",
    "end": "2538970"
  },
  {
    "text": "there's a limit to the we use Python lots there's a limit to like the virtual environment you upload your lambda",
    "start": "2538970",
    "end": "2544460"
  },
  {
    "text": "function it's 250 megabytes and so you know we pack in a bunch of image",
    "start": "2544460",
    "end": "2549589"
  },
  {
    "text": "processing libraries and all sorts of things and eventually ran into not being able to actually upload or upload we",
    "start": "2549589",
    "end": "2555829"
  },
  {
    "text": "somebody added like scikit-learn or something I meant just we couldn't deploy our lambda function anymore",
    "start": "2555829",
    "end": "2561019"
  },
  {
    "text": "because it's too big so you know you sometimes need to play games there and you can't just use a really giant",
    "start": "2561019",
    "end": "2569410"
  },
  {
    "text": "environment because you're limited and the other thing too that's kind of",
    "start": "2569499",
    "end": "2576499"
  },
  {
    "text": "counterintuitive when you start when you run into it for the first time it you'll",
    "start": "2576499",
    "end": "2581779"
  },
  {
    "text": "be like oh okay but the idea that lambda capacity is tied to execution duration so if your",
    "start": "2581779",
    "end": "2589670"
  },
  {
    "text": "lambda function service if your lambda function calls anything external so like DynamoDB s 3 RDS anything you don't have",
    "start": "2589670",
    "end": "2597440"
  },
  {
    "text": "to realize that network and external agencies of X affect your execution time which effectively affects your capacity",
    "start": "2597440",
    "end": "2605390"
  },
  {
    "text": "so if you're chugging along and you're like not getting throttles and everything's happy and then all of a sudden the latency to your database",
    "start": "2605390",
    "end": "2611839"
  },
  {
    "text": "doubles you could just all of a sudden start getting throttles and then everything cascades because then Dinah",
    "start": "2611839",
    "end": "2617029"
  },
  {
    "text": "then lambda will start retrying and so you get even more if you've got the lambda capacity I mean the land that",
    "start": "2617029",
    "end": "2622609"
  },
  {
    "text": "limits it high enough and eventually you will you know everything will tumble and",
    "start": "2622609",
    "end": "2628249"
  },
  {
    "text": "you got I think these dominoes just crash and so these cascading failures",
    "start": "2628249",
    "end": "2634910"
  },
  {
    "text": "are interesting thing to worry about and so you know definitely recommend thinking about in your design how can",
    "start": "2634910",
    "end": "2640819"
  },
  {
    "text": "you implement some sort of circuit breaker or some sort of way to detect when your latency is happening or if",
    "start": "2640819",
    "end": "2646400"
  },
  {
    "text": "you're getting alarms due to throttles what can you do to to back things off gracefully and deal with your",
    "start": "2646400",
    "end": "2652430"
  },
  {
    "text": "your-your-your limit to get back because otherwise you know in beginning when we didn't",
    "start": "2652430",
    "end": "2659049"
  },
  {
    "text": "really know how to deal with this we kinda just would have to be like everybody stop what you're doing and then wait for like all the lambda functions to like echo through the",
    "start": "2659049",
    "end": "2664809"
  },
  {
    "text": "system because I keep retrying and eventually you're like back in business and then once we realize oh it's because",
    "start": "2664809",
    "end": "2669869"
  },
  {
    "text": "you know this network thing was configured wrong or this database wasn't quite right but being able to have that",
    "start": "2669869",
    "end": "2675940"
  },
  {
    "text": "circuit breakers in there from the beginning so you can shut things off and get back to good is is kind of important",
    "start": "2675940",
    "end": "2681690"
  },
  {
    "text": "and oh yeah and so we use dynamodb a lot",
    "start": "2681690",
    "end": "2691180"
  },
  {
    "start": "2689000",
    "end": "2689000"
  },
  {
    "text": "and again we're in some interesting problems there I love DynamoDB I think it's awesome but",
    "start": "2691180",
    "end": "2696729"
  },
  {
    "text": "it's also the same thing it's not the solution for everything we granted some challenges where we got we had you know",
    "start": "2696729",
    "end": "2703690"
  },
  {
    "text": "had the spreadsheet went through and like oh this will work great this won't be a problem and then of course somebody",
    "start": "2703690",
    "end": "2708700"
  },
  {
    "text": "did something we didn't quite expect and we ended up having a bunch of really large key that a bunch of really large",
    "start": "2708700",
    "end": "2714789"
  },
  {
    "text": "values in a couple keys that were getting hit a lot and that eventually caused us to have some crazy dynamo",
    "start": "2714789",
    "end": "2721239"
  },
  {
    "text": "crazy dynamo throttling event so we couldn't figure out so you have to remember that you know object size",
    "start": "2721239",
    "end": "2728440"
  },
  {
    "text": "drives capacity so the bigger an object gets the more capacity that write or read operation consumes which again is",
    "start": "2728440",
    "end": "2735519"
  },
  {
    "text": "maybe a little counterintuitive and also a few users can influence that size of that object it's not fixed size which in",
    "start": "2735519",
    "end": "2742390"
  },
  {
    "text": "our case you know these a key was storing and indexed and if the user was writing data spatially very big region",
    "start": "2742390",
    "end": "2750219"
  },
  {
    "text": "which we didn't anticipate happening that key you started getting bigger and bigger and bigger the point where you",
    "start": "2750219",
    "end": "2755410"
  },
  {
    "text": "know that largest record size uses 400 times the capacity of the smallest size record you can write so it's something",
    "start": "2755410",
    "end": "2761229"
  },
  {
    "text": "to keep in mind and another thing to kind of be aware of is you know when",
    "start": "2761229",
    "end": "2767799"
  },
  {
    "text": "you're paying for capacity you're actually paying for partitions and so the big challenge with dynamo that we",
    "start": "2767799",
    "end": "2775209"
  },
  {
    "text": "ran into is this idea like hot partition this is when you have a read or write to this to a bunch of reader rights to the",
    "start": "2775209",
    "end": "2782079"
  },
  {
    "text": "same keys that are in the same partition and so you know dynamos metering you at",
    "start": "2782079",
    "end": "2789519"
  },
  {
    "text": "once second you've got if you've got lots of fast operations the same partition in your dynamo table you can burn up your",
    "start": "2789519",
    "end": "2796900"
  },
  {
    "text": "capacity really quickly and you'll be surprised because you'll go and look and you'll be like oh my request seemed so much farther down from where my line is",
    "start": "2796900",
    "end": "2804610"
  },
  {
    "text": "if you're looking like an cloud watching something it looks like I have so much capacity what's going on and it's",
    "start": "2804610",
    "end": "2809770"
  },
  {
    "text": "because you're probably hitting all your capacity is spent in the same partition and so you know the expensive way to fix",
    "start": "2809770",
    "end": "2818350"
  },
  {
    "text": "that is you double your capacity you double your capacity you'll split the partition and most likely you'll be good to go but you can also try to change",
    "start": "2818350",
    "end": "2825670"
  },
  {
    "text": "your key design and a big thing to do is always try to spread your keys around on the partitions right so if you preach",
    "start": "2825670",
    "end": "2831580"
  },
  {
    "text": "all of our keys on a dynamo we prepend a hash a kind of a deterministic hash that",
    "start": "2831580",
    "end": "2837220"
  },
  {
    "text": "we know we can recreate so we can say the key that we know let me hash that",
    "start": "2837220",
    "end": "2842800"
  },
  {
    "text": "and generate this deterministic ash and prepend it so that every key is kind of spread around at random along your",
    "start": "2842800",
    "end": "2848710"
  },
  {
    "text": "partitions and it kind of helps with this issue of a hot partition which is probably one of the big things you'll",
    "start": "2848710",
    "end": "2853930"
  },
  {
    "text": "run into if you really start you know haven't been too thoughtful in the design of your keys or just having an",
    "start": "2853930",
    "end": "2859870"
  },
  {
    "text": "interesting use case what happens and so [Music] yeah and then and then scaling up so we",
    "start": "2859870",
    "end": "2870880"
  },
  {
    "start": "2865000",
    "end": "2865000"
  },
  {
    "text": "built the system it worked pretty good we were like high-fives all around a table and then our partners at Harvard",
    "start": "2870880",
    "end": "2877960"
  },
  {
    "text": "we're like okay how much how fast can we send you the data I don't like I don't know just whatever you think you can do and the guys okay and he fires it up and",
    "start": "2877960",
    "end": "2884490"
  },
  {
    "text": "like instantly everything explodes and so this is when we did our took us",
    "start": "2884490",
    "end": "2890830"
  },
  {
    "text": "awhile to figure this out we actually ended up getting on like a live stream with three AWS engineers that were on",
    "start": "2890830",
    "end": "2897070"
  },
  {
    "text": "the back end doing something and we were getting this interesting failure mode",
    "start": "2897070",
    "end": "2902080"
  },
  {
    "text": "where everything's chugging along great and then all of a sudden just lambda",
    "start": "2902080",
    "end": "2908200"
  },
  {
    "text": "functions were disappearing in the ether there was no logging we had like no idea what was happening and one of the",
    "start": "2908200",
    "end": "2914530"
  },
  {
    "text": "engineers was just like I got an idea and he goes in and just sets our Eni limit which is the elastic network",
    "start": "2914530",
    "end": "2921120"
  },
  {
    "text": "interface to something really high and all of a sudden like 20,000 lambda",
    "start": "2921120",
    "end": "2926230"
  },
  {
    "text": "functions fired huh thank you the same and so we're like okay this is what's going on and which is really interesting",
    "start": "2926230",
    "end": "2931330"
  },
  {
    "text": "is that you have to remember what we were doing is we were projecting our VPC we were projecting the lambda function",
    "start": "2931330",
    "end": "2937330"
  },
  {
    "text": "into a V PC and so when you do that you got to set up your network and I you know attach whatever subnets you want to",
    "start": "2937330",
    "end": "2942880"
  },
  {
    "text": "do and every time you do that you use an E and I you actually use a network adapter which we didn't really realize and we're not heavy easy to instance",
    "start": "2942880",
    "end": "2949720"
  },
  {
    "text": "users right we're using all the service stuff so currently I think it's still this way like your E and I limits tied",
    "start": "2949720",
    "end": "2956350"
  },
  {
    "text": "your ec2 limits so if you don't if you haven't it never turned up your ec2 limits you have the stock and I limit",
    "start": "2956350",
    "end": "2964060"
  },
  {
    "text": "and so if you try to do anything complex with a couple subnets on your lambda functions and use lots of lambda",
    "start": "2964060",
    "end": "2969880"
  },
  {
    "text": "functions it doesn't work which is really through I spend a lot of time to figure that one out but we did",
    "start": "2969880",
    "end": "2975250"
  },
  {
    "text": "everything worked great that's a big thing to remember also another thing we",
    "start": "2975250",
    "end": "2980350"
  },
  {
    "text": "kind of failed with in the beginning too is if you do project your lambda function in your V PC you have to make",
    "start": "2980350",
    "end": "2986920"
  },
  {
    "text": "sure your network architecture can handle the bandwidth it's kind of this thing you take for granted you're like this works great and then lambda fans",
    "start": "2986920",
    "end": "2993520"
  },
  {
    "text": "out you forget there's now like 2000 versions of whatever code running and if it's moving you know a couple Meg's",
    "start": "2993520",
    "end": "3000870"
  },
  {
    "text": "around all of a sudden your network infrastructure needs to make sure that you can handle that so we had some is configured you know s3 endpoints and",
    "start": "3000870",
    "end": "3007170"
  },
  {
    "text": "Internet gateways and and whatnot and once you kind of get that going I was very important and again also we",
    "start": "3007170",
    "end": "3014850"
  },
  {
    "text": "did a thing where if you're using s3 heavily you can pre share your bucket this was a big thing for us as well team",
    "start": "3014850",
    "end": "3020490"
  },
  {
    "text": "was streaming this data and in App hat we were creating so many objects so fast as three started throttling us and saying wait you can't do that and we",
    "start": "3020490",
    "end": "3027210"
  },
  {
    "text": "weren't gracefully handling that and so things tipped over again but you can actually go and have your bucket pre sharded and then you won't get those",
    "start": "3027210",
    "end": "3033630"
  },
  {
    "text": "throttle events from s3 which is really great for DynamoDB use auto scaling we",
    "start": "3033630",
    "end": "3039090"
  },
  {
    "text": "were previously using a third-party tool that ran and lambda and upped your and",
    "start": "3039090",
    "end": "3044220"
  },
  {
    "text": "checked your metrics and updated your capacity for you automatically but now it's all built in which is awesome and",
    "start": "3044220",
    "end": "3050010"
  },
  {
    "text": "one thing they would know about dynamo auto scaling which is kind of we learned hard way but you know",
    "start": "3050010",
    "end": "3056930"
  },
  {
    "text": "diam no can dynamically scale up infinitely but you can only go down four times a day so I think they take that in",
    "start": "3056930",
    "end": "3063230"
  },
  {
    "text": "account pretty well and the built-in dynamo auto-scaling about something keep in mind like you'll see this thing step up real nicely as your capacity",
    "start": "3063230",
    "end": "3069770"
  },
  {
    "text": "goes and then it'll stay high even if your load drops off and then come down eventually throughout the day and again",
    "start": "3069770",
    "end": "3077000"
  },
  {
    "text": "also look into error and log aggregators it gets really complicated and AWS has been building tools or some third-party",
    "start": "3077000",
    "end": "3082430"
  },
  {
    "text": "vendors but you know when you start doing things that scale and they tip",
    "start": "3082430",
    "end": "3089720"
  },
  {
    "text": "over it's really hard to figure out what happened and so original like at the very beginning of like all right we'll just send ours to a nest SNS topic that",
    "start": "3089720",
    "end": "3097520"
  },
  {
    "text": "sends me a text message and that ended very poorly one night when my wife was",
    "start": "3097520",
    "end": "3102920"
  },
  {
    "text": "like what's going on with your phone and and literally I didn't think iOS could",
    "start": "3102920",
    "end": "3110330"
  },
  {
    "text": "do that but that's not that's not sped up and this ran for like ten minutes I",
    "start": "3110330",
    "end": "3118220"
  },
  {
    "text": "got like like 15,000 text messages or something insane so don't do that use",
    "start": "3118220",
    "end": "3125930"
  },
  {
    "text": "some sort of a guy or Gator or you know something like century or x-ray or something like that to help you debug",
    "start": "3125930",
    "end": "3131510"
  },
  {
    "text": "your your serverless applications because they can get really complicated especially things where things are at scale you just kind of have no idea",
    "start": "3131510",
    "end": "3138050"
  },
  {
    "text": "what's going on at some time times and so it's a little bit of time left I'm",
    "start": "3138050",
    "end": "3144830"
  },
  {
    "text": "gonna show you a little quick demo we'll see how this works with Wi-Fi might be",
    "start": "3144830",
    "end": "3151040"
  },
  {
    "text": "questionable but so the culmination of all this work this is an actual data set",
    "start": "3151040",
    "end": "3157840"
  },
  {
    "text": "generated by the Allen Institute did the",
    "start": "3157840",
    "end": "3162860"
  },
  {
    "text": "electron microscopy and Princeton Sebastian Seung's lab at Princeton did the reconstruction the segmentation and",
    "start": "3162860",
    "end": "3169880"
  },
  {
    "text": "so what we're seeing here is this is this web viewer which is kind of cool it's open source it was actually built",
    "start": "3169880",
    "end": "3175370"
  },
  {
    "text": "by Google it's called neuro glance er Google is doing a little bit of work in this space as well and it's kind of been adopted by",
    "start": "3175370",
    "end": "3182030"
  },
  {
    "text": "a bunch of people in community we took it added in or off plug in a couple herbal things to and this is now integrated with our",
    "start": "3182030",
    "end": "3187670"
  },
  {
    "text": "single sign-on service and so any user that can go in our system can open up any data set and just view it in this 3d",
    "start": "3187670",
    "end": "3192890"
  },
  {
    "text": "in this a WebGL based viewer and so I can kind of you know go up and down what you're seeing is in the top left is kind",
    "start": "3192890",
    "end": "3200870"
  },
  {
    "text": "of the in plain view and then on the right you've these orthogonal views that are lower res because you know we have",
    "start": "3200870",
    "end": "3208190"
  },
  {
    "text": "this that's slicing that happen and what you're seeing here is actually you know",
    "start": "3208190",
    "end": "3213260"
  },
  {
    "text": "this greenish thing is one piece of a neuron this purplish thing here is another piece of a neuron this this",
    "start": "3213260",
    "end": "3220040"
  },
  {
    "text": "darker highlighted region is actually a synapse detection and this was all done using computer vision automatically an",
    "start": "3220040",
    "end": "3225350"
  },
  {
    "text": "automatic analysis and so I can like I said screw up and down I can like let me",
    "start": "3225350",
    "end": "3231830"
  },
  {
    "text": "turn off something I can do this and I can you know scroll which is kind of",
    "start": "3231830",
    "end": "3238250"
  },
  {
    "text": "cool and zoom way out and it'll load",
    "start": "3238250",
    "end": "3244660"
  },
  {
    "text": "from dynamically and so you can see all these little different colored circles",
    "start": "3244660",
    "end": "3252080"
  },
  {
    "text": "are actually snare on cell bodies and this big white thing is a blood vessel and it's actually pretty impressive that",
    "start": "3252080",
    "end": "3257900"
  },
  {
    "text": "this was done automatically and it worked and and now I'm trying to go into scale and what's also cool is we can do",
    "start": "3257900",
    "end": "3263750"
  },
  {
    "text": "3d rendering and so each one of these labels it's a volumetric image you can mesh them you can render them using WebGL and",
    "start": "3263750",
    "end": "3271190"
  },
  {
    "text": "so what we're seeing here is you know this orange neuron and this blue neuron",
    "start": "3271190",
    "end": "3278240"
  },
  {
    "text": "they get nice and close which is kind of interesting and I can carefully right-click there let me zoom in a",
    "start": "3278240",
    "end": "3285500"
  },
  {
    "text": "little bit oops I'm not used to not doing it but",
    "start": "3285500",
    "end": "3292520"
  },
  {
    "text": "it's interesting you can like zoom in and move around and it gives you know users this interesting way to kind of",
    "start": "3292520",
    "end": "3297800"
  },
  {
    "text": "actually inspect the data which you know like I said we do lots of automatic",
    "start": "3297800",
    "end": "3302900"
  },
  {
    "text": "analysis but being able to just go and visualize it right there is incredibly useful for people especially the data",
    "start": "3302900",
    "end": "3307940"
  },
  {
    "text": "generators they upload this stuff they can go and they can look at it they can share something interesting with a collaborator it's been really useful for",
    "start": "3307940",
    "end": "3314630"
  },
  {
    "text": "people and it also looks really cool and yeah let me go back over here so all",
    "start": "3314630",
    "end": "3327769"
  },
  {
    "text": "that was being loaded dynamically from the system over the Wi-Fi that's a",
    "start": "3327769",
    "end": "3333730"
  },
  {
    "text": "smaller data set this was from phase one this is a couple terabytes but you know because we can do this arbitrary cut out",
    "start": "3333730",
    "end": "3340609"
  },
  {
    "text": "with the resolution hierarchy you can you know over the internet just access it and analyze the data so just want to",
    "start": "3340609",
    "end": "3346670"
  },
  {
    "start": "3345000",
    "end": "3345000"
  },
  {
    "text": "give a couple quick acknowledgments to this project because it is so huge and all the data I showed you and all the",
    "start": "3346670",
    "end": "3352130"
  },
  {
    "text": "work was done by these awesome groups so you know the boss was built at j2 APL",
    "start": "3352130",
    "end": "3357829"
  },
  {
    "text": "with a great team and we have some collaborators at Johns Hopkins University proper and Randall burns his",
    "start": "3357829",
    "end": "3364309"
  },
  {
    "text": "lab and you know IRA uh ran this program three major teams all those universities",
    "start": "3364309",
    "end": "3370309"
  },
  {
    "text": "on the far side all those logos everyone participating this program it's a huge collaborative effort it's been it was",
    "start": "3370309",
    "end": "3377059"
  },
  {
    "text": "incredibly fun to work on and if you go to github we have all of our code the",
    "start": "3377059",
    "end": "3384200"
  },
  {
    "text": "whole system is open source so you can actually see a lot of ways we've implemented these things Heaviside again",
    "start": "3384200",
    "end": "3390470"
  },
  {
    "text": "it's a tool you can use it's open source as well and our github organization it's github.com slash JHU APL - boss there's",
    "start": "3390470",
    "end": "3397249"
  },
  {
    "text": "also a website now called boss DB org and all of our stuff is on there there's",
    "start": "3397249",
    "end": "3404599"
  },
  {
    "text": "a paper that kind of goes a little bit more detail and what the architecture is like and that's the program website so",
    "start": "3404599",
    "end": "3411549"
  },
  {
    "text": "thank you very much [Applause]",
    "start": "3411549",
    "end": "3418090"
  }
]
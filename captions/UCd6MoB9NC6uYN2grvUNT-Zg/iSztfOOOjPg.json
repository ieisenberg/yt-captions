[
  {
    "start": "0",
    "end": "35000"
  },
  {
    "text": "hi",
    "start": "3679",
    "end": "4000"
  },
  {
    "text": "everyone my name is alex ignatov i'm",
    "start": "4000",
    "end": "7200"
  },
  {
    "text": "senior data scientist in aws",
    "start": "7200",
    "end": "9599"
  },
  {
    "text": "professional services",
    "start": "9599",
    "end": "13040"
  },
  {
    "text": "and i'm radula bala subramanian i'm a",
    "start": "13360",
    "end": "15679"
  },
  {
    "text": "senior solutions architect with aws",
    "start": "15679",
    "end": "17920"
  },
  {
    "text": "provide public sector solutions",
    "start": "17920",
    "end": "19600"
  },
  {
    "text": "architecture",
    "start": "19600",
    "end": "22000"
  },
  {
    "text": "today we are going to talk about",
    "start": "22000",
    "end": "23920"
  },
  {
    "text": "generative pre-trained transformers",
    "start": "23920",
    "end": "26400"
  },
  {
    "text": "and how you can quickly start",
    "start": "26400",
    "end": "28480"
  },
  {
    "text": "experimenting with gpt2 model",
    "start": "28480",
    "end": "31199"
  },
  {
    "text": "available in aws marketplace",
    "start": "31199",
    "end": "36000"
  },
  {
    "start": "35000",
    "end": "520000"
  },
  {
    "text": "generative pre-trained transformer",
    "start": "37360",
    "end": "39520"
  },
  {
    "text": "concept or",
    "start": "39520",
    "end": "40719"
  },
  {
    "text": "gpt was first published by open air",
    "start": "40719",
    "end": "43680"
  },
  {
    "text": "organization in",
    "start": "43680",
    "end": "44879"
  },
  {
    "text": "june 2018 in a paper called",
    "start": "44879",
    "end": "48559"
  },
  {
    "text": "improving language understanding by",
    "start": "48559",
    "end": "50879"
  },
  {
    "text": "generative per training",
    "start": "50879",
    "end": "53199"
  },
  {
    "text": "previously most of the approaches to",
    "start": "53199",
    "end": "55280"
  },
  {
    "text": "generate text",
    "start": "55280",
    "end": "56399"
  },
  {
    "text": "were based on the recurrent neural",
    "start": "56399",
    "end": "58480"
  },
  {
    "text": "networks",
    "start": "58480",
    "end": "59920"
  },
  {
    "text": "rnns such as lstm neural networks",
    "start": "59920",
    "end": "63760"
  },
  {
    "text": "are usually were restricted by short",
    "start": "63760",
    "end": "67040"
  },
  {
    "text": "range of",
    "start": "67040",
    "end": "67680"
  },
  {
    "text": "input sequences they could effectively",
    "start": "67680",
    "end": "70159"
  },
  {
    "text": "perform on in this paper",
    "start": "70159",
    "end": "73520"
  },
  {
    "text": "authors for the first time outlined",
    "start": "73520",
    "end": "75920"
  },
  {
    "text": "approaches on how transformers can be",
    "start": "75920",
    "end": "78400"
  },
  {
    "text": "used to utilize pre-trained",
    "start": "78400",
    "end": "81040"
  },
  {
    "text": "uh in a supervised manner model",
    "start": "81040",
    "end": "84080"
  },
  {
    "text": "and the proven capturing of longer range",
    "start": "84080",
    "end": "86960"
  },
  {
    "text": "linguistic structures for purposes of",
    "start": "86960",
    "end": "89439"
  },
  {
    "text": "generating new text",
    "start": "89439",
    "end": "92240"
  },
  {
    "text": "in february 2019 second version gpt2",
    "start": "92240",
    "end": "96640"
  },
  {
    "text": "came out",
    "start": "96640",
    "end": "98079"
  },
  {
    "text": "gpg2 is very large transformer-based",
    "start": "98079",
    "end": "101200"
  },
  {
    "text": "language model trained on a massive data",
    "start": "101200",
    "end": "103920"
  },
  {
    "text": "set that features much larger number of",
    "start": "103920",
    "end": "106560"
  },
  {
    "text": "parameters",
    "start": "106560",
    "end": "108720"
  },
  {
    "text": "this model became significantly improved",
    "start": "108720",
    "end": "111119"
  },
  {
    "text": "successor of gpt",
    "start": "111119",
    "end": "113119"
  },
  {
    "text": "it received wide publicity for its",
    "start": "113119",
    "end": "115439"
  },
  {
    "text": "capability to generate very plausible",
    "start": "115439",
    "end": "118159"
  },
  {
    "text": "looking assays",
    "start": "118159",
    "end": "120640"
  },
  {
    "text": "recently gpt3 paper was published gpt3",
    "start": "120640",
    "end": "124719"
  },
  {
    "text": "has even larger number of parameters",
    "start": "124719",
    "end": "127680"
  },
  {
    "text": "but today we are going to focus on gpt2",
    "start": "127680",
    "end": "130399"
  },
  {
    "text": "model",
    "start": "130399",
    "end": "131680"
  },
  {
    "text": "all these three models have some main",
    "start": "131680",
    "end": "134400"
  },
  {
    "text": "concepts which allow them to generate",
    "start": "134400",
    "end": "136959"
  },
  {
    "text": "highly coherent text based on provided",
    "start": "136959",
    "end": "140080"
  },
  {
    "text": "input text sequence",
    "start": "140080",
    "end": "143840"
  },
  {
    "text": "first concept is masked self-attention",
    "start": "144239",
    "end": "147840"
  },
  {
    "text": "self-attention is one of the key",
    "start": "147840",
    "end": "149920"
  },
  {
    "text": "components of what is called",
    "start": "149920",
    "end": "151760"
  },
  {
    "text": "transformers architecture",
    "start": "151760",
    "end": "154480"
  },
  {
    "text": "the core idea of attention is to focus",
    "start": "154480",
    "end": "157200"
  },
  {
    "text": "on the most",
    "start": "157200",
    "end": "157920"
  },
  {
    "text": "relevant parts of the input sequence for",
    "start": "157920",
    "end": "160480"
  },
  {
    "text": "each output",
    "start": "160480",
    "end": "162480"
  },
  {
    "text": "here you can see visualization of",
    "start": "162480",
    "end": "164640"
  },
  {
    "text": "attention mechanism",
    "start": "164640",
    "end": "167040"
  },
  {
    "text": "the sentence machine learning is great",
    "start": "167040",
    "end": "169280"
  },
  {
    "text": "for humanity",
    "start": "169280",
    "end": "170400"
  },
  {
    "text": "it helps let's imagine that model is",
    "start": "170400",
    "end": "174000"
  },
  {
    "text": "trying to predict the word helps",
    "start": "174000",
    "end": "176480"
  },
  {
    "text": "based on the previous words we are using",
    "start": "176480",
    "end": "179920"
  },
  {
    "text": "attention visualization tool to see",
    "start": "179920",
    "end": "182720"
  },
  {
    "text": "which parts of input sequence have more",
    "start": "182720",
    "end": "185440"
  },
  {
    "text": "influence on what next token model will",
    "start": "185440",
    "end": "188239"
  },
  {
    "text": "generate",
    "start": "188239",
    "end": "190000"
  },
  {
    "text": "you can see on that picture that word",
    "start": "190000",
    "end": "192239"
  },
  {
    "text": "helps is contextually influenced by",
    "start": "192239",
    "end": "194959"
  },
  {
    "text": "machine learning",
    "start": "194959",
    "end": "196720"
  },
  {
    "text": "which is at the beginning of the",
    "start": "196720",
    "end": "198319"
  },
  {
    "text": "previous sentence",
    "start": "198319",
    "end": "200000"
  },
  {
    "text": "you can also notice there is an",
    "start": "200000",
    "end": "202239"
  },
  {
    "text": "influence by word humanity",
    "start": "202239",
    "end": "206159"
  },
  {
    "text": "attention mechanism allows model to look",
    "start": "206239",
    "end": "209040"
  },
  {
    "text": "further in the input",
    "start": "209040",
    "end": "210720"
  },
  {
    "text": "because often nearest word may not have",
    "start": "210720",
    "end": "213360"
  },
  {
    "text": "enough context to predict what should be",
    "start": "213360",
    "end": "215840"
  },
  {
    "text": "next",
    "start": "215840",
    "end": "217519"
  },
  {
    "text": "this picture is just a representation of",
    "start": "217519",
    "end": "219840"
  },
  {
    "text": "attention in one layer",
    "start": "219840",
    "end": "221519"
  },
  {
    "text": "and one head of a model other",
    "start": "221519",
    "end": "224560"
  },
  {
    "text": "combinations of layers and",
    "start": "224560",
    "end": "226480"
  },
  {
    "text": "hats can have much more less obvious",
    "start": "226480",
    "end": "229360"
  },
  {
    "text": "relations between",
    "start": "229360",
    "end": "230879"
  },
  {
    "text": "position in a given sequence of tokens",
    "start": "230879",
    "end": "233920"
  },
  {
    "text": "used to generate next word",
    "start": "233920",
    "end": "237280"
  },
  {
    "text": "in this picture the darker blue color",
    "start": "237280",
    "end": "239599"
  },
  {
    "text": "corresponds to higher attention scores",
    "start": "239599",
    "end": "243040"
  },
  {
    "text": "this is a good way to have a 10 000 feet",
    "start": "243040",
    "end": "245920"
  },
  {
    "text": "view",
    "start": "245920",
    "end": "246400"
  },
  {
    "text": "on how attention works",
    "start": "246400",
    "end": "250079"
  },
  {
    "text": "positional encoding enables transformer",
    "start": "251120",
    "end": "254000"
  },
  {
    "text": "model to keep track of",
    "start": "254000",
    "end": "255599"
  },
  {
    "text": "absolute or relative positions and",
    "start": "255599",
    "end": "258000"
  },
  {
    "text": "distances between",
    "start": "258000",
    "end": "259280"
  },
  {
    "text": "sequence elements gpt2 is the model with",
    "start": "259280",
    "end": "263280"
  },
  {
    "text": "absolute positional embeddings",
    "start": "263280",
    "end": "266400"
  },
  {
    "text": "this method allows model to attend on",
    "start": "266400",
    "end": "269120"
  },
  {
    "text": "order of the words and distance between",
    "start": "269120",
    "end": "271680"
  },
  {
    "text": "them",
    "start": "271680",
    "end": "273280"
  },
  {
    "text": "to show what it is i have plotted mean",
    "start": "273280",
    "end": "276400"
  },
  {
    "text": "values of positional embeddings for each",
    "start": "276400",
    "end": "279040"
  },
  {
    "text": "position",
    "start": "279040",
    "end": "279759"
  },
  {
    "text": "in a sequence on the right you can see a",
    "start": "279759",
    "end": "283360"
  },
  {
    "text": "large scale of 500",
    "start": "283360",
    "end": "285520"
  },
  {
    "text": "000 words and the mean value of",
    "start": "285520",
    "end": "288479"
  },
  {
    "text": "positional term",
    "start": "288479",
    "end": "290000"
  },
  {
    "text": "follows a sine wave",
    "start": "290000",
    "end": "293120"
  },
  {
    "text": "on the left we have the same values but",
    "start": "293120",
    "end": "295759"
  },
  {
    "text": "only for first hundred tokens",
    "start": "295759",
    "end": "298800"
  },
  {
    "text": "in fact it has more complex structure",
    "start": "298800",
    "end": "301360"
  },
  {
    "text": "it's not strictly sine",
    "start": "301360",
    "end": "303039"
  },
  {
    "text": "wave positional encoding values are",
    "start": "303039",
    "end": "306800"
  },
  {
    "text": "essentially",
    "start": "306800",
    "end": "307680"
  },
  {
    "text": "values that being summed up with word",
    "start": "307680",
    "end": "310560"
  },
  {
    "text": "and patents inside the model",
    "start": "310560",
    "end": "312479"
  },
  {
    "text": "to adjust meaning of each word depending",
    "start": "312479",
    "end": "315840"
  },
  {
    "text": "on their order and position in a",
    "start": "315840",
    "end": "318080"
  },
  {
    "text": "sentence",
    "start": "318080",
    "end": "320638"
  },
  {
    "text": "subword tokenization method is based on",
    "start": "323360",
    "end": "326320"
  },
  {
    "text": "byte pairing coding method",
    "start": "326320",
    "end": "328720"
  },
  {
    "text": "byte pairing coding is multi-pass data",
    "start": "328720",
    "end": "331440"
  },
  {
    "text": "compression technique in which the most",
    "start": "331440",
    "end": "333759"
  },
  {
    "text": "common pairs of consecutive bytes of",
    "start": "333759",
    "end": "336639"
  },
  {
    "text": "data is replaced",
    "start": "336639",
    "end": "338320"
  },
  {
    "text": "with byte that does not occur within",
    "start": "338320",
    "end": "341520"
  },
  {
    "text": "that data",
    "start": "341520",
    "end": "343520"
  },
  {
    "text": "gpt-2 sub-vorteconization merges most",
    "start": "343520",
    "end": "346880"
  },
  {
    "text": "frequent character pairs found in text",
    "start": "346880",
    "end": "349600"
  },
  {
    "text": "corpus",
    "start": "349600",
    "end": "350639"
  },
  {
    "text": "into n-gram tokens and record them",
    "start": "350639",
    "end": "353680"
  },
  {
    "text": "into vocabulary this process runs",
    "start": "353680",
    "end": "356960"
  },
  {
    "text": "iteratively",
    "start": "356960",
    "end": "357840"
  },
  {
    "text": "until either desired vocabulary size is",
    "start": "357840",
    "end": "360639"
  },
  {
    "text": "reached",
    "start": "360639",
    "end": "361759"
  },
  {
    "text": "or when there is no more merge",
    "start": "361759",
    "end": "363840"
  },
  {
    "text": "operations can be done",
    "start": "363840",
    "end": "366639"
  },
  {
    "text": "besides that there are several specific",
    "start": "366639",
    "end": "370639"
  },
  {
    "text": "to text generation parameters that you",
    "start": "370639",
    "end": "373039"
  },
  {
    "text": "can adjust to produce",
    "start": "373039",
    "end": "374560"
  },
  {
    "text": "better output text first is the",
    "start": "374560",
    "end": "378840"
  },
  {
    "text": "temperature temperature controls the",
    "start": "378840",
    "end": "381280"
  },
  {
    "text": "randomness of predictions",
    "start": "381280",
    "end": "383280"
  },
  {
    "text": "higher temperature increases sensitivity",
    "start": "383280",
    "end": "386479"
  },
  {
    "text": "to low probability board candidates",
    "start": "386479",
    "end": "390080"
  },
  {
    "text": "however that decreases output tax",
    "start": "390080",
    "end": "392840"
  },
  {
    "text": "coherence therefore tags produced",
    "start": "392840",
    "end": "395600"
  },
  {
    "text": "might be less meaningful values lower",
    "start": "395600",
    "end": "399039"
  },
  {
    "text": "than one",
    "start": "399039",
    "end": "399759"
  },
  {
    "text": "make output more conservative but you",
    "start": "399759",
    "end": "402800"
  },
  {
    "text": "might get the same result for specific",
    "start": "402800",
    "end": "405280"
  },
  {
    "text": "input tags over and over top k sampling",
    "start": "405280",
    "end": "409680"
  },
  {
    "text": "limits sampling pool of output tokens to",
    "start": "409680",
    "end": "412960"
  },
  {
    "text": "k",
    "start": "412960",
    "end": "413280"
  },
  {
    "text": "number of candidates with highest",
    "start": "413280",
    "end": "415520"
  },
  {
    "text": "probability",
    "start": "415520",
    "end": "417599"
  },
  {
    "text": "for example as you can see in the bar",
    "start": "417599",
    "end": "420319"
  },
  {
    "text": "graph on the left",
    "start": "420319",
    "end": "422319"
  },
  {
    "text": "when you specify k equals 2 you are",
    "start": "422319",
    "end": "425360"
  },
  {
    "text": "telling the model to choose the",
    "start": "425360",
    "end": "427280"
  },
  {
    "text": "subsequent word for the sentence on the",
    "start": "427280",
    "end": "429919"
  },
  {
    "text": "left",
    "start": "429919",
    "end": "430479"
  },
  {
    "text": "from only top two suggestions",
    "start": "430479",
    "end": "434240"
  },
  {
    "text": "this sampling technique eliminates",
    "start": "434240",
    "end": "436319"
  },
  {
    "text": "possibility of choosing non-suitable",
    "start": "436319",
    "end": "438720"
  },
  {
    "text": "candidates for the next generated token",
    "start": "438720",
    "end": "441680"
  },
  {
    "text": "even if temperature parameters set to",
    "start": "441680",
    "end": "444160"
  },
  {
    "text": "high value",
    "start": "444160",
    "end": "446720"
  },
  {
    "text": "top b sampling copy is a nuclear",
    "start": "446720",
    "end": "449919"
  },
  {
    "text": "sampling",
    "start": "449919",
    "end": "450880"
  },
  {
    "text": "and unlike top k chooses from the whole",
    "start": "450880",
    "end": "453680"
  },
  {
    "text": "distribution",
    "start": "453680",
    "end": "455520"
  },
  {
    "text": "nuclear sampling optimized for the",
    "start": "455520",
    "end": "457919"
  },
  {
    "text": "minimum number of candidate tokens to",
    "start": "457919",
    "end": "460560"
  },
  {
    "text": "sample with highest combined probability",
    "start": "460560",
    "end": "464080"
  },
  {
    "text": "for example when top p equals 0.9",
    "start": "464080",
    "end": "468240"
  },
  {
    "text": "it looked for all the potential",
    "start": "468240",
    "end": "470720"
  },
  {
    "text": "candidates with a",
    "start": "470720",
    "end": "472000"
  },
  {
    "text": "cumulative probability of 0.9 and then",
    "start": "472000",
    "end": "475120"
  },
  {
    "text": "choose the smallest set in this case",
    "start": "475120",
    "end": "478479"
  },
  {
    "text": "you can see that with three boards",
    "start": "478479",
    "end": "481680"
  },
  {
    "text": "and story and law it was able to form",
    "start": "481680",
    "end": "485280"
  },
  {
    "text": "that nucleus to choose",
    "start": "485280",
    "end": "486960"
  },
  {
    "text": "from with very high probability without",
    "start": "486960",
    "end": "490160"
  },
  {
    "text": "limiting to a specific number of samples",
    "start": "490160",
    "end": "492800"
  },
  {
    "text": "to choose from",
    "start": "492800",
    "end": "494560"
  },
  {
    "text": "depending on a specific text and context",
    "start": "494560",
    "end": "497440"
  },
  {
    "text": "stop p",
    "start": "497440",
    "end": "498080"
  },
  {
    "text": "sampling may produce better results than",
    "start": "498080",
    "end": "500800"
  },
  {
    "text": "top k",
    "start": "500800",
    "end": "501440"
  },
  {
    "text": "sampling and vice versa",
    "start": "501440",
    "end": "504960"
  },
  {
    "text": "now i will pass it to maroot to talk",
    "start": "504960",
    "end": "507440"
  },
  {
    "text": "about gpt2 use cases",
    "start": "507440",
    "end": "510000"
  },
  {
    "text": "architecture and demo",
    "start": "510000",
    "end": "521839"
  },
  {
    "start": "520000",
    "end": "810000"
  },
  {
    "text": "gpt2 has a number of use cases",
    "start": "524480",
    "end": "528000"
  },
  {
    "text": "but really the primary use case is to",
    "start": "528000",
    "end": "530080"
  },
  {
    "text": "generate text",
    "start": "530080",
    "end": "531920"
  },
  {
    "text": "and it does this by taking an input",
    "start": "531920",
    "end": "534399"
  },
  {
    "text": "prompt as context",
    "start": "534399",
    "end": "536160"
  },
  {
    "text": "and predicting the next set of text so",
    "start": "536160",
    "end": "538720"
  },
  {
    "text": "in this drawing example",
    "start": "538720",
    "end": "540480"
  },
  {
    "text": "i start with a really short prompt a",
    "start": "540480",
    "end": "543040"
  },
  {
    "text": "couple words",
    "start": "543040",
    "end": "544000"
  },
  {
    "text": "nlp is and gpt2 provides me",
    "start": "544000",
    "end": "548000"
  },
  {
    "text": "predictions with associated",
    "start": "548000",
    "end": "550399"
  },
  {
    "text": "probabilities for the top three",
    "start": "550399",
    "end": "552000"
  },
  {
    "text": "candidates",
    "start": "552000",
    "end": "553440"
  },
  {
    "text": "i pick the top prediction and i use that",
    "start": "553440",
    "end": "556959"
  },
  {
    "text": "to continue my prompt",
    "start": "556959",
    "end": "559600"
  },
  {
    "text": "and the model then generates additional",
    "start": "559600",
    "end": "562160"
  },
  {
    "text": "predictions",
    "start": "562160",
    "end": "563120"
  },
  {
    "text": "based on this longer context and so it",
    "start": "563120",
    "end": "566080"
  },
  {
    "text": "continues",
    "start": "566080",
    "end": "567200"
  },
  {
    "text": "now this is a simple use case for auto",
    "start": "567200",
    "end": "570560"
  },
  {
    "text": "completion",
    "start": "570560",
    "end": "572080"
  },
  {
    "text": "but you can use large models like gpd to",
    "start": "572080",
    "end": "575360"
  },
  {
    "text": "excel",
    "start": "575360",
    "end": "576320"
  },
  {
    "text": "to provide more purpose text generation",
    "start": "576320",
    "end": "580000"
  },
  {
    "text": "by using its longer context window",
    "start": "580000",
    "end": "583040"
  },
  {
    "text": "of 1024 tokens to prime the model",
    "start": "583040",
    "end": "587760"
  },
  {
    "text": "so gpt2 has been performing",
    "start": "587760",
    "end": "590399"
  },
  {
    "text": "state-of-the-art",
    "start": "590399",
    "end": "591760"
  },
  {
    "text": "on text generation but it is",
    "start": "591760",
    "end": "595360"
  },
  {
    "text": "also performed on other language tasks",
    "start": "595360",
    "end": "599120"
  },
  {
    "text": "such as",
    "start": "599120",
    "end": "599680"
  },
  {
    "text": "reading comprehension natural question",
    "start": "599680",
    "end": "602560"
  },
  {
    "text": "answering",
    "start": "602560",
    "end": "603279"
  },
  {
    "text": "summarization and unsupervised language",
    "start": "603279",
    "end": "606000"
  },
  {
    "text": "translation",
    "start": "606000",
    "end": "608640"
  },
  {
    "text": "generative models are an active area of",
    "start": "609120",
    "end": "611600"
  },
  {
    "text": "research",
    "start": "611600",
    "end": "612399"
  },
  {
    "text": "because the insights that they provide",
    "start": "612399",
    "end": "616160"
  },
  {
    "text": "from their behavior help",
    "start": "616160",
    "end": "619440"
  },
  {
    "text": "researchers understand how unsupervised",
    "start": "619440",
    "end": "621760"
  },
  {
    "text": "learning works",
    "start": "621760",
    "end": "623440"
  },
  {
    "text": "and research is underway to find",
    "start": "623440",
    "end": "626000"
  },
  {
    "text": "generalized architectures",
    "start": "626000",
    "end": "627920"
  },
  {
    "text": "where you can create an architecture",
    "start": "627920",
    "end": "631839"
  },
  {
    "text": "which can",
    "start": "631839",
    "end": "632560"
  },
  {
    "text": "perform across various language tasks",
    "start": "632560",
    "end": "637519"
  },
  {
    "text": "by using no fine tuning but instead",
    "start": "637519",
    "end": "640880"
  },
  {
    "text": "by using in-context learning or",
    "start": "640880",
    "end": "642959"
  },
  {
    "text": "meta-learning",
    "start": "642959",
    "end": "645120"
  },
  {
    "text": "another area of interest is model bias",
    "start": "645120",
    "end": "648399"
  },
  {
    "text": "where researchers are looking into the",
    "start": "648399",
    "end": "651120"
  },
  {
    "text": "neurons of the",
    "start": "651120",
    "end": "653279"
  },
  {
    "text": "model to figure out",
    "start": "653279",
    "end": "656320"
  },
  {
    "text": "if there is a bias and methods to",
    "start": "656320",
    "end": "659760"
  },
  {
    "text": "mitigate that",
    "start": "659760",
    "end": "660959"
  },
  {
    "text": "uh usually using attention visualization",
    "start": "660959",
    "end": "663600"
  },
  {
    "text": "techniques",
    "start": "663600",
    "end": "664959"
  },
  {
    "text": "an interpretation of predictions is uh",
    "start": "664959",
    "end": "668160"
  },
  {
    "text": "an area that is of interest across",
    "start": "668160",
    "end": "671920"
  },
  {
    "text": "various deep learning models",
    "start": "671920",
    "end": "674240"
  },
  {
    "text": "now gpt2 has been trained predominantly",
    "start": "674240",
    "end": "676880"
  },
  {
    "text": "on text data",
    "start": "676880",
    "end": "678560"
  },
  {
    "text": "but there is interest from various",
    "start": "678560",
    "end": "683360"
  },
  {
    "text": "research organizations in incorporating",
    "start": "683360",
    "end": "686720"
  },
  {
    "text": "images audio and other modalities of",
    "start": "686720",
    "end": "689440"
  },
  {
    "text": "data",
    "start": "689440",
    "end": "690160"
  },
  {
    "text": "so that the model can be adapted to",
    "start": "690160",
    "end": "692480"
  },
  {
    "text": "tasks such as",
    "start": "692480",
    "end": "693440"
  },
  {
    "text": "visual question answering music",
    "start": "693440",
    "end": "695920"
  },
  {
    "text": "generation",
    "start": "695920",
    "end": "696720"
  },
  {
    "text": "code completion etc",
    "start": "696720",
    "end": "700319"
  },
  {
    "text": "so in the demo segment of this uh",
    "start": "701279",
    "end": "703839"
  },
  {
    "text": "presentation",
    "start": "703839",
    "end": "704880"
  },
  {
    "text": "i will be using a gpd2 extra large model",
    "start": "704880",
    "end": "708959"
  },
  {
    "text": "that i subscribed",
    "start": "708959",
    "end": "710480"
  },
  {
    "text": "from aws marketplace and",
    "start": "710480",
    "end": "713600"
  },
  {
    "text": "these are the steps that i took to",
    "start": "713600",
    "end": "716800"
  },
  {
    "text": "deploy it onto amazon sagemaker",
    "start": "716800",
    "end": "719920"
  },
  {
    "text": "so first aws marketplace",
    "start": "719920",
    "end": "723279"
  },
  {
    "text": "is a place where you can go",
    "start": "723279",
    "end": "726480"
  },
  {
    "text": "try out and buy different",
    "start": "726480",
    "end": "729920"
  },
  {
    "text": "algorithms or model packages that you",
    "start": "729920",
    "end": "733200"
  },
  {
    "text": "can then deploy onto amazon sagemaker",
    "start": "733200",
    "end": "736720"
  },
  {
    "text": "and these training and inference",
    "start": "736720",
    "end": "738560"
  },
  {
    "text": "containers",
    "start": "738560",
    "end": "740240"
  },
  {
    "text": "are in network isolation mode",
    "start": "740240",
    "end": "744079"
  },
  {
    "text": "and these containers when they're",
    "start": "744079",
    "end": "745519"
  },
  {
    "text": "deployed have no internet access",
    "start": "745519",
    "end": "748240"
  },
  {
    "text": "for advanced security",
    "start": "748240",
    "end": "751279"
  },
  {
    "text": "and as a user you can configure your",
    "start": "751279",
    "end": "753600"
  },
  {
    "text": "endpoint",
    "start": "753600",
    "end": "754480"
  },
  {
    "text": "in your amazon virtual private cloud and",
    "start": "754480",
    "end": "758240"
  },
  {
    "text": "create those identity and access",
    "start": "758240",
    "end": "760000"
  },
  {
    "text": "management policies",
    "start": "760000",
    "end": "762079"
  },
  {
    "text": "so that you can give granular permission",
    "start": "762079",
    "end": "764000"
  },
  {
    "text": "to sagemaker",
    "start": "764000",
    "end": "765279"
  },
  {
    "text": "to access resources inside your aws",
    "start": "765279",
    "end": "767760"
  },
  {
    "text": "account",
    "start": "767760",
    "end": "770160"
  },
  {
    "text": "and the inferences itself that you make",
    "start": "770160",
    "end": "772959"
  },
  {
    "text": "can be either real-time",
    "start": "772959",
    "end": "774800"
  },
  {
    "text": "or asynchronous dodge transform",
    "start": "774800",
    "end": "777920"
  },
  {
    "text": "method and the the api",
    "start": "777920",
    "end": "781360"
  },
  {
    "text": "call itself is secured in transit",
    "start": "781360",
    "end": "784959"
  },
  {
    "text": "on ssl",
    "start": "784959",
    "end": "788480"
  },
  {
    "text": "so in the demo i use an amazon sagemaker",
    "start": "790000",
    "end": "793600"
  },
  {
    "text": "jupyter notebook to make inferences",
    "start": "793600",
    "end": "797440"
  },
  {
    "text": "against sagemaker endpoint",
    "start": "797440",
    "end": "801040"
  },
  {
    "text": "and there's also code in there that you",
    "start": "801040",
    "end": "803279"
  },
  {
    "text": "can try for doing patch transforms",
    "start": "803279",
    "end": "806720"
  },
  {
    "text": "so on to the demo",
    "start": "806720",
    "end": "809680"
  },
  {
    "start": "810000",
    "end": "849000"
  },
  {
    "text": "so here i am inside amazon sage maker",
    "start": "813760",
    "end": "816800"
  },
  {
    "text": "jupiter notebook",
    "start": "816800",
    "end": "819760"
  },
  {
    "text": "and first off let me show you how to",
    "start": "820079",
    "end": "823760"
  },
  {
    "text": "go to aws marketplace to find the",
    "start": "823760",
    "end": "826240"
  },
  {
    "text": "product",
    "start": "826240",
    "end": "826800"
  },
  {
    "text": "of interest so here this is gpt to excel",
    "start": "826800",
    "end": "830720"
  },
  {
    "text": "for text generation inside of aws",
    "start": "830720",
    "end": "833760"
  },
  {
    "text": "marketplace",
    "start": "833760",
    "end": "835040"
  },
  {
    "text": "you can look through the overview the",
    "start": "835040",
    "end": "837760"
  },
  {
    "text": "highlights",
    "start": "837760",
    "end": "838800"
  },
  {
    "text": "and the usage information that",
    "start": "838800",
    "end": "842560"
  },
  {
    "text": "helps you understand how to use this",
    "start": "842560",
    "end": "845519"
  },
  {
    "text": "model",
    "start": "845519",
    "end": "846320"
  },
  {
    "text": "and maybe some sample code",
    "start": "846320",
    "end": "849760"
  },
  {
    "start": "849000",
    "end": "895000"
  },
  {
    "text": "and back to the jupyter notebook itself",
    "start": "849920",
    "end": "854079"
  },
  {
    "text": "i start off by installing various",
    "start": "854079",
    "end": "856399"
  },
  {
    "text": "libraries",
    "start": "856399",
    "end": "857440"
  },
  {
    "text": "and one of them is wordpress package",
    "start": "857440",
    "end": "859760"
  },
  {
    "text": "which is an open source",
    "start": "859760",
    "end": "861519"
  },
  {
    "text": "uh self-attention visualization package",
    "start": "861519",
    "end": "866160"
  },
  {
    "text": "and we provide you a snippet of code",
    "start": "866160",
    "end": "868720"
  },
  {
    "text": "where you can go explore",
    "start": "868720",
    "end": "870639"
  },
  {
    "text": "and see how self-attention works inside",
    "start": "870639",
    "end": "873600"
  },
  {
    "text": "gpt2",
    "start": "873600",
    "end": "874639"
  },
  {
    "text": "so in this case for example if you focus",
    "start": "874639",
    "end": "878000"
  },
  {
    "text": "on a word it shows you the contextual",
    "start": "878000",
    "end": "881040"
  },
  {
    "text": "relationship of that word to",
    "start": "881040",
    "end": "882880"
  },
  {
    "text": "other tokens in sequence and that helps",
    "start": "882880",
    "end": "886240"
  },
  {
    "text": "you understand",
    "start": "886240",
    "end": "887360"
  },
  {
    "text": "gives you insights into how the model",
    "start": "887360",
    "end": "890800"
  },
  {
    "text": "makes its decision in predicting the",
    "start": "890800",
    "end": "893360"
  },
  {
    "text": "next",
    "start": "893360",
    "end": "894000"
  },
  {
    "text": "set of words on to the use cases",
    "start": "894000",
    "end": "899600"
  },
  {
    "start": "895000",
    "end": "932000"
  },
  {
    "text": "um so one of the important",
    "start": "899600",
    "end": "902800"
  },
  {
    "text": "parameter of course is your input prompt",
    "start": "902800",
    "end": "905120"
  },
  {
    "text": "which where you provide the string",
    "start": "905120",
    "end": "907040"
  },
  {
    "text": "to condition your model to prompt it for",
    "start": "907040",
    "end": "909920"
  },
  {
    "text": "text generation",
    "start": "909920",
    "end": "911199"
  },
  {
    "text": "but in addition there are a number of",
    "start": "911199",
    "end": "913040"
  },
  {
    "text": "other parameters that you can tweak",
    "start": "913040",
    "end": "916160"
  },
  {
    "text": "to influence that model behavior",
    "start": "916160",
    "end": "919519"
  },
  {
    "text": "one of them is length for example so in",
    "start": "919519",
    "end": "922079"
  },
  {
    "text": "this case the default",
    "start": "922079",
    "end": "923440"
  },
  {
    "text": "is 50 words that will generate in the",
    "start": "923440",
    "end": "926399"
  },
  {
    "text": "output but you can increase or decrease",
    "start": "926399",
    "end": "928399"
  },
  {
    "text": "this value",
    "start": "928399",
    "end": "929519"
  },
  {
    "text": "and there are a number of other",
    "start": "929519",
    "end": "930560"
  },
  {
    "text": "parameters that you can explore",
    "start": "930560",
    "end": "933519"
  },
  {
    "start": "932000",
    "end": "967000"
  },
  {
    "text": "so um in this notebook we",
    "start": "933519",
    "end": "936959"
  },
  {
    "text": "look at a use case where",
    "start": "936959",
    "end": "940160"
  },
  {
    "text": "you can use gpd2 as a writing assistant",
    "start": "940160",
    "end": "943759"
  },
  {
    "text": "so let's say for example that you're a",
    "start": "943759",
    "end": "945519"
  },
  {
    "text": "writer of prose",
    "start": "945519",
    "end": "947360"
  },
  {
    "text": "and you haven't yet decided what to",
    "start": "947360",
    "end": "948959"
  },
  {
    "text": "write about so",
    "start": "948959",
    "end": "950480"
  },
  {
    "text": "this first example here just gives you",
    "start": "950480",
    "end": "954079"
  },
  {
    "text": "a starting token without any specific",
    "start": "954079",
    "end": "957839"
  },
  {
    "text": "prompt and then it lets you",
    "start": "957839",
    "end": "960880"
  },
  {
    "text": "just go ahead and execute it and you'll",
    "start": "960880",
    "end": "963199"
  },
  {
    "text": "see some",
    "start": "963199",
    "end": "964720"
  },
  {
    "text": "unconditional sample that gets generated",
    "start": "964720",
    "end": "967440"
  },
  {
    "start": "967000",
    "end": "1005000"
  },
  {
    "text": "by gpd2",
    "start": "967440",
    "end": "968880"
  },
  {
    "text": "but let's say now that you've decided on",
    "start": "968880",
    "end": "970639"
  },
  {
    "text": "a topic you can provide",
    "start": "970639",
    "end": "972880"
  },
  {
    "text": "that as a short prompt to the model to",
    "start": "972880",
    "end": "976240"
  },
  {
    "text": "prime it and then when you execute it",
    "start": "976240",
    "end": "980079"
  },
  {
    "text": "you will see",
    "start": "980079",
    "end": "981360"
  },
  {
    "text": "that the model generates text which is",
    "start": "981360",
    "end": "984320"
  },
  {
    "text": "related",
    "start": "984320",
    "end": "985600"
  },
  {
    "text": "uh to your prompt so that's one way of",
    "start": "985600",
    "end": "989839"
  },
  {
    "text": "using gpd2 to assist you in coming up",
    "start": "989839",
    "end": "992560"
  },
  {
    "text": "with ideas",
    "start": "992560",
    "end": "994240"
  },
  {
    "text": "for writing and of course you can tweak",
    "start": "994240",
    "end": "996480"
  },
  {
    "text": "the different model parameters for",
    "start": "996480",
    "end": "998079"
  },
  {
    "text": "length",
    "start": "998079",
    "end": "999519"
  },
  {
    "text": "and if you don't want too much",
    "start": "999519",
    "end": "1000800"
  },
  {
    "text": "repetition you can have a higher",
    "start": "1000800",
    "end": "1003600"
  },
  {
    "text": "repetition penalty value",
    "start": "1003600",
    "end": "1007040"
  },
  {
    "text": "um you can also use gpt2",
    "start": "1007040",
    "end": "1010320"
  },
  {
    "text": "to autonomously author for example in",
    "start": "1010320",
    "end": "1013279"
  },
  {
    "text": "this case i look at",
    "start": "1013279",
    "end": "1016240"
  },
  {
    "text": "using the model to write a",
    "start": "1016320",
    "end": "1018279"
  },
  {
    "text": "shakespeare-inspired",
    "start": "1018279",
    "end": "1019839"
  },
  {
    "text": "poem by giving it a prompt",
    "start": "1019839",
    "end": "1025278"
  },
  {
    "text": "and just running it and you will see",
    "start": "1025520",
    "end": "1028959"
  },
  {
    "text": "in the output that it tries to mimic",
    "start": "1028959",
    "end": "1032959"
  },
  {
    "text": "the style of the prompt that i provided",
    "start": "1032959",
    "end": "1036558"
  },
  {
    "text": "so this gives you an insight into kind",
    "start": "1036559",
    "end": "1038798"
  },
  {
    "text": "of its chameleon",
    "start": "1038799",
    "end": "1040160"
  },
  {
    "text": "uh like quality where it's adapting uh",
    "start": "1040160",
    "end": "1043678"
  },
  {
    "text": "its text generation uh based on uh the",
    "start": "1043679",
    "end": "1046720"
  },
  {
    "text": "conditioning that provides that's",
    "start": "1046720",
    "end": "1048319"
  },
  {
    "text": "provided in the prompt",
    "start": "1048319",
    "end": "1051600"
  },
  {
    "text": "um and you can of course tweak various",
    "start": "1051600",
    "end": "1054799"
  },
  {
    "text": "parameters like temperature",
    "start": "1054799",
    "end": "1056640"
  },
  {
    "text": "uh which is sensitivity to low",
    "start": "1056640",
    "end": "1059520"
  },
  {
    "text": "probability words",
    "start": "1059520",
    "end": "1060799"
  },
  {
    "text": "so a default value of one is uh more",
    "start": "1060799",
    "end": "1064160"
  },
  {
    "text": "conservative models so it's",
    "start": "1064160",
    "end": "1066240"
  },
  {
    "text": "highly sensitive so it doesn't use",
    "start": "1066240",
    "end": "1069600"
  },
  {
    "text": "as much of those low property words",
    "start": "1069600",
    "end": "1073440"
  },
  {
    "text": "and so you can pick a",
    "start": "1073440",
    "end": "1076559"
  },
  {
    "text": "sample pool of words",
    "start": "1076559",
    "end": "1080080"
  },
  {
    "text": "that you want the model to use in its",
    "start": "1080080",
    "end": "1082480"
  },
  {
    "text": "output by specifying",
    "start": "1082480",
    "end": "1084080"
  },
  {
    "text": "specifying the value of top k",
    "start": "1084080",
    "end": "1087440"
  },
  {
    "start": "1085000",
    "end": "1108000"
  },
  {
    "text": "so one of the things that you can do is",
    "start": "1087440",
    "end": "1090400"
  },
  {
    "text": "for the same given prompt",
    "start": "1090400",
    "end": "1092720"
  },
  {
    "text": "change the values of these model",
    "start": "1092720",
    "end": "1094640"
  },
  {
    "text": "parameters so in this case for example",
    "start": "1094640",
    "end": "1096640"
  },
  {
    "text": "same prompt but a higher value of",
    "start": "1096640",
    "end": "1098799"
  },
  {
    "text": "temperature",
    "start": "1098799",
    "end": "1100480"
  },
  {
    "text": "which means the model is now less",
    "start": "1100480",
    "end": "1102320"
  },
  {
    "text": "conservative",
    "start": "1102320",
    "end": "1103919"
  },
  {
    "text": "and see the difference in creativity of",
    "start": "1103919",
    "end": "1107039"
  },
  {
    "text": "the output from the model",
    "start": "1107039",
    "end": "1109360"
  },
  {
    "start": "1108000",
    "end": "1138000"
  },
  {
    "text": "so that was the primary use case uh",
    "start": "1109360",
    "end": "1112480"
  },
  {
    "text": "with generating text for prose or poetry",
    "start": "1112480",
    "end": "1116400"
  },
  {
    "text": "now let's do some additional",
    "start": "1116400",
    "end": "1118240"
  },
  {
    "text": "experimentation with language",
    "start": "1118240",
    "end": "1120000"
  },
  {
    "text": "tasks such as reading comprehension",
    "start": "1120000",
    "end": "1123120"
  },
  {
    "text": "where i provide a context and then",
    "start": "1123120",
    "end": "1126559"
  },
  {
    "text": "a question with a structure such as",
    "start": "1126559",
    "end": "1129600"
  },
  {
    "text": "queue",
    "start": "1129600",
    "end": "1130720"
  },
  {
    "text": "to indicate that it's a question and",
    "start": "1130720",
    "end": "1132720"
  },
  {
    "text": "then see",
    "start": "1132720",
    "end": "1134400"
  },
  {
    "text": "what the model comes up with so in this",
    "start": "1134400",
    "end": "1136240"
  },
  {
    "text": "case it comes up with an answer",
    "start": "1136240",
    "end": "1138240"
  },
  {
    "text": "with a so this is um",
    "start": "1138240",
    "end": "1141520"
  },
  {
    "text": "where i'm i'm basically experimenting",
    "start": "1141520",
    "end": "1144000"
  },
  {
    "text": "with the structure",
    "start": "1144000",
    "end": "1145600"
  },
  {
    "text": "or the frame of the prompt itself",
    "start": "1145600",
    "end": "1148720"
  },
  {
    "text": "to see if the model will recognize that",
    "start": "1148720",
    "end": "1151440"
  },
  {
    "text": "specific task",
    "start": "1151440",
    "end": "1152880"
  },
  {
    "text": "and i'm doing this in a zero zero short",
    "start": "1152880",
    "end": "1156000"
  },
  {
    "text": "setting which means uh that i have not",
    "start": "1156000",
    "end": "1158400"
  },
  {
    "text": "fine-tuned this model",
    "start": "1158400",
    "end": "1160080"
  },
  {
    "text": "for any specific task but instead i'm",
    "start": "1160080",
    "end": "1162799"
  },
  {
    "text": "using the prompt at",
    "start": "1162799",
    "end": "1164080"
  },
  {
    "text": "inference time to train the model",
    "start": "1164080",
    "end": "1168720"
  },
  {
    "start": "1167000",
    "end": "1197000"
  },
  {
    "text": "you can additionally explore what is",
    "start": "1169039",
    "end": "1171919"
  },
  {
    "text": "called flu shot",
    "start": "1171919",
    "end": "1172960"
  },
  {
    "text": "setting which means in addition to",
    "start": "1172960",
    "end": "1175679"
  },
  {
    "text": "providing the",
    "start": "1175679",
    "end": "1177120"
  },
  {
    "text": "prompt context you can also provide some",
    "start": "1177120",
    "end": "1181039"
  },
  {
    "text": "additional examples",
    "start": "1181039",
    "end": "1182240"
  },
  {
    "text": "of q a so that",
    "start": "1182240",
    "end": "1185280"
  },
  {
    "text": "you are letting the model know what type",
    "start": "1185280",
    "end": "1188000"
  },
  {
    "text": "of task that you're trying to perform",
    "start": "1188000",
    "end": "1189679"
  },
  {
    "text": "and give it some examples",
    "start": "1189679",
    "end": "1191520"
  },
  {
    "text": "and then when you run it it tries to",
    "start": "1191520",
    "end": "1193919"
  },
  {
    "text": "come up with an",
    "start": "1193919",
    "end": "1194640"
  },
  {
    "text": "answer based on that context",
    "start": "1194640",
    "end": "1198640"
  },
  {
    "start": "1197000",
    "end": "1224000"
  },
  {
    "text": "so that was for reading comprehension",
    "start": "1198640",
    "end": "1202400"
  },
  {
    "text": "question answering so this is just",
    "start": "1202400",
    "end": "1204000"
  },
  {
    "text": "natural question answering where you",
    "start": "1204000",
    "end": "1205679"
  },
  {
    "text": "don't",
    "start": "1205679",
    "end": "1206000"
  },
  {
    "text": "provide a context but you just ask a",
    "start": "1206000",
    "end": "1208240"
  },
  {
    "text": "question of the model",
    "start": "1208240",
    "end": "1209840"
  },
  {
    "text": "and then based on its training on",
    "start": "1209840",
    "end": "1214080"
  },
  {
    "text": "8 million pages of web text",
    "start": "1214080",
    "end": "1217440"
  },
  {
    "text": "which is now encoded in its 1.5 billion",
    "start": "1217440",
    "end": "1219919"
  },
  {
    "text": "parameters",
    "start": "1219919",
    "end": "1221039"
  },
  {
    "text": "it comes up with answers to your",
    "start": "1221039",
    "end": "1223520"
  },
  {
    "text": "questions",
    "start": "1223520",
    "end": "1225520"
  },
  {
    "text": "summarization is another language task",
    "start": "1225520",
    "end": "1228000"
  },
  {
    "text": "where you provide",
    "start": "1228000",
    "end": "1229200"
  },
  {
    "text": "a much longer context so maybe a whole",
    "start": "1229200",
    "end": "1232080"
  },
  {
    "text": "article",
    "start": "1232080",
    "end": "1232880"
  },
  {
    "text": "because the input context window for gpt",
    "start": "1232880",
    "end": "1235600"
  },
  {
    "text": "to excel",
    "start": "1235600",
    "end": "1236320"
  },
  {
    "text": "is 1024 tokens so you can use that",
    "start": "1236320",
    "end": "1240799"
  },
  {
    "text": "to provide these longer context",
    "start": "1240799",
    "end": "1244159"
  },
  {
    "text": "and then have the model prompt the model",
    "start": "1244159",
    "end": "1246880"
  },
  {
    "text": "with",
    "start": "1246880",
    "end": "1247520"
  },
  {
    "text": "dots to come up with a summary",
    "start": "1247520",
    "end": "1250640"
  },
  {
    "text": "for that article um",
    "start": "1250640",
    "end": "1254080"
  },
  {
    "text": "in this experiment i look at",
    "start": "1254080",
    "end": "1255760"
  },
  {
    "text": "unsupervised language translation",
    "start": "1255760",
    "end": "1258000"
  },
  {
    "text": "where i provide a french passage",
    "start": "1258000",
    "end": "1263039"
  },
  {
    "text": "and prompt the model for english",
    "start": "1263039",
    "end": "1265360"
  },
  {
    "text": "translation by providing this keyword",
    "start": "1265360",
    "end": "1268000"
  },
  {
    "start": "1267000",
    "end": "1298000"
  },
  {
    "text": "and the model comes up with a",
    "start": "1268000",
    "end": "1269679"
  },
  {
    "text": "translation so in this case i'm not",
    "start": "1269679",
    "end": "1271520"
  },
  {
    "text": "really looking for the accuracy of the",
    "start": "1271520",
    "end": "1273280"
  },
  {
    "text": "translation",
    "start": "1273280",
    "end": "1274320"
  },
  {
    "text": "as much as i'm looking for ways that i",
    "start": "1274320",
    "end": "1277120"
  },
  {
    "text": "can",
    "start": "1277120",
    "end": "1278240"
  },
  {
    "text": "make the model recognize the task by",
    "start": "1278240",
    "end": "1280880"
  },
  {
    "text": "using different",
    "start": "1280880",
    "end": "1282159"
  },
  {
    "text": "structure in the prompts so a slight",
    "start": "1282159",
    "end": "1284880"
  },
  {
    "text": "variation from the previous",
    "start": "1284880",
    "end": "1287120"
  },
  {
    "text": "again start with a french passage but",
    "start": "1287120",
    "end": "1290240"
  },
  {
    "text": "this time i give it",
    "start": "1290240",
    "end": "1291360"
  },
  {
    "text": "english equals as a prompt to see",
    "start": "1291360",
    "end": "1294960"
  },
  {
    "text": "if it will come up with a translation",
    "start": "1294960",
    "end": "1299760"
  },
  {
    "text": "so i highly encourage you to continue to",
    "start": "1299840",
    "end": "1303120"
  },
  {
    "text": "explore with the various prompts",
    "start": "1303120",
    "end": "1305679"
  },
  {
    "text": "various structure of prompts and",
    "start": "1305679",
    "end": "1307679"
  },
  {
    "text": "different settings for model parameters",
    "start": "1307679",
    "end": "1309919"
  },
  {
    "text": "to see how you can use gpd2 for your own",
    "start": "1309919",
    "end": "1312559"
  },
  {
    "text": "use case",
    "start": "1312559",
    "end": "1313679"
  },
  {
    "text": "and once you're done feel free to delete",
    "start": "1313679",
    "end": "1316320"
  },
  {
    "text": "the sagemaker endpoint so you don't get",
    "start": "1316320",
    "end": "1318640"
  },
  {
    "text": "charged for it",
    "start": "1318640",
    "end": "1320720"
  },
  {
    "start": "1319000",
    "end": "1333000"
  },
  {
    "text": "and everything that i did with the",
    "start": "1320720",
    "end": "1323440"
  },
  {
    "text": "influence endpoint",
    "start": "1323440",
    "end": "1324400"
  },
  {
    "text": "you can do in an asynchronous fashion",
    "start": "1324400",
    "end": "1326960"
  },
  {
    "text": "with the",
    "start": "1326960",
    "end": "1327520"
  },
  {
    "text": "sagemaker batch transform as well",
    "start": "1327520",
    "end": "1330559"
  },
  {
    "text": "and this notebook is available available",
    "start": "1330559",
    "end": "1334240"
  },
  {
    "start": "1333000",
    "end": "1355000"
  },
  {
    "text": "to you",
    "start": "1334240",
    "end": "1334880"
  },
  {
    "text": "on github and i will show that you in",
    "start": "1334880",
    "end": "1337039"
  },
  {
    "text": "just a second",
    "start": "1337039",
    "end": "1338799"
  },
  {
    "text": "and there are in addition to",
    "start": "1338799",
    "end": "1343120"
  },
  {
    "text": "this gpd2 model you can explore",
    "start": "1343120",
    "end": "1346400"
  },
  {
    "text": "other models in aws marketplace",
    "start": "1346400",
    "end": "1349600"
  },
  {
    "text": "and some of them are listed here and see",
    "start": "1349600",
    "end": "1352640"
  },
  {
    "text": "if these will serve your use case",
    "start": "1352640",
    "end": "1356400"
  },
  {
    "start": "1355000",
    "end": "1391000"
  },
  {
    "text": "so let's go to the github repo",
    "start": "1356559",
    "end": "1360400"
  },
  {
    "text": "where you can find amazon sagemaker",
    "start": "1360400",
    "end": "1362240"
  },
  {
    "text": "examples and",
    "start": "1362240",
    "end": "1363600"
  },
  {
    "text": "under aws marketplace",
    "start": "1363600",
    "end": "1366640"
  },
  {
    "text": "you will see model packages",
    "start": "1366640",
    "end": "1369679"
  },
  {
    "text": "and creative writing writing with gpd2",
    "start": "1369679",
    "end": "1373120"
  },
  {
    "text": "is the notebook that i just demonstrated",
    "start": "1373120",
    "end": "1376799"
  },
  {
    "text": "to you",
    "start": "1376799",
    "end": "1378080"
  },
  {
    "text": "please feel free to explore further",
    "start": "1378080",
    "end": "1382960"
  },
  {
    "text": "for your own use cases",
    "start": "1382960",
    "end": "1389840"
  },
  {
    "start": "1391000",
    "end": "1429000"
  },
  {
    "text": "some additional resources for you",
    "start": "1392480",
    "end": "1396240"
  },
  {
    "text": "please go to aws marketplace where you",
    "start": "1396559",
    "end": "1399280"
  },
  {
    "text": "can check out",
    "start": "1399280",
    "end": "1400799"
  },
  {
    "text": "different algorithms different model",
    "start": "1400799",
    "end": "1403280"
  },
  {
    "text": "packages",
    "start": "1403280",
    "end": "1404880"
  },
  {
    "text": "and then you can see youtube videos on",
    "start": "1404880",
    "end": "1406799"
  },
  {
    "text": "how to use them",
    "start": "1406799",
    "end": "1408240"
  },
  {
    "text": "read blogs and of course you can try",
    "start": "1408240",
    "end": "1411600"
  },
  {
    "text": "products",
    "start": "1411600",
    "end": "1412240"
  },
  {
    "text": "and use sample notebooks",
    "start": "1412240",
    "end": "1416320"
  },
  {
    "text": "to help you try those products and if",
    "start": "1416320",
    "end": "1418559"
  },
  {
    "text": "you have any questions",
    "start": "1418559",
    "end": "1420480"
  },
  {
    "text": "you can reach out to the aws marketplace",
    "start": "1420480",
    "end": "1423440"
  },
  {
    "text": "team",
    "start": "1423440",
    "end": "1424240"
  },
  {
    "text": "at the alias shown thank you",
    "start": "1424240",
    "end": "1431840"
  }
]
[
  {
    "start": "0",
    "end": "25000"
  },
  {
    "text": "in this video you will learn how to set",
    "start": "0",
    "end": "3300"
  },
  {
    "text": "up data quality checks in your ETL",
    "start": "3300",
    "end": "5580"
  },
  {
    "text": "pipeline to prevent bad data from",
    "start": "5580",
    "end": "8639"
  },
  {
    "text": "entering your data repositories",
    "start": "8639",
    "end": "11099"
  },
  {
    "text": "ultimately leading to improved data for",
    "start": "11099",
    "end": "13920"
  },
  {
    "text": "your business teams",
    "start": "13920",
    "end": "15420"
  },
  {
    "text": "my name is Dean I'm a senior solution",
    "start": "15420",
    "end": "18000"
  },
  {
    "text": "architect at AWS and I'm going to",
    "start": "18000",
    "end": "20580"
  },
  {
    "text": "demonstrate glue data quality",
    "start": "20580",
    "end": "22199"
  },
  {
    "text": "capabilities for ETL pipeline",
    "start": "22199",
    "end": "26340"
  },
  {
    "start": "25000",
    "end": "48000"
  },
  {
    "text": "for this demo I have two CSV data sets",
    "start": "26340",
    "end": "29699"
  },
  {
    "text": "stored in Amazon S3 first is customer",
    "start": "29699",
    "end": "32340"
  },
  {
    "text": "data set it is a list of customer farmer",
    "start": "32340",
    "end": "35399"
  },
  {
    "text": "department store",
    "start": "35399",
    "end": "36960"
  },
  {
    "text": "next is sales transaction data set which",
    "start": "36960",
    "end": "40440"
  },
  {
    "text": "I am going to use as a reference to",
    "start": "40440",
    "end": "43020"
  },
  {
    "text": "ensure that all customers have purchased",
    "start": "43020",
    "end": "45540"
  },
  {
    "text": "some item from the store",
    "start": "45540",
    "end": "48600"
  },
  {
    "start": "48000",
    "end": "61000"
  },
  {
    "text": "let's now add evaluate data quality",
    "start": "48600",
    "end": "51960"
  },
  {
    "text": "transform where you can author your data",
    "start": "51960",
    "end": "55199"
  },
  {
    "text": "quality roles",
    "start": "55199",
    "end": "57059"
  },
  {
    "text": "let's choose both data set as input to",
    "start": "57059",
    "end": "60539"
  },
  {
    "text": "this transform",
    "start": "60539",
    "end": "62100"
  },
  {
    "start": "61000",
    "end": "148000"
  },
  {
    "text": "my goal is to check for the data quality",
    "start": "62100",
    "end": "64978"
  },
  {
    "text": "of the customer data set and identify",
    "start": "64979",
    "end": "68119"
  },
  {
    "text": "error records for this data set hence I",
    "start": "68119",
    "end": "71460"
  },
  {
    "text": "will specify my primary data set as",
    "start": "71460",
    "end": "74040"
  },
  {
    "text": "customer",
    "start": "74040",
    "end": "74900"
  },
  {
    "text": "sales data set is going to be used as",
    "start": "74900",
    "end": "77760"
  },
  {
    "text": "one of the reference data set",
    "start": "77760",
    "end": "79740"
  },
  {
    "text": "let's go and add the data quality check",
    "start": "79740",
    "end": "82020"
  },
  {
    "text": "first I want to ensure that there is at",
    "start": "82020",
    "end": "85259"
  },
  {
    "text": "least 100 records in my data set",
    "start": "85259",
    "end": "88320"
  },
  {
    "text": "to do this I will use row count rule",
    "start": "88320",
    "end": "91500"
  },
  {
    "text": "that validates the number of Records in",
    "start": "91500",
    "end": "94320"
  },
  {
    "text": "the primary data set",
    "start": "94320",
    "end": "96180"
  },
  {
    "text": "next I want to ensure that customer ID",
    "start": "96180",
    "end": "99900"
  },
  {
    "text": "is not null and unique using is primary",
    "start": "99900",
    "end": "104280"
  },
  {
    "text": "key root",
    "start": "104280",
    "end": "106619"
  },
  {
    "text": "next I will check that the first name",
    "start": "106619",
    "end": "108540"
  },
  {
    "text": "column length is greater than 2.",
    "start": "108540",
    "end": "111840"
  },
  {
    "text": "sometimes you need to implement complex",
    "start": "111840",
    "end": "114659"
  },
  {
    "text": "business rules",
    "start": "114659",
    "end": "116399"
  },
  {
    "text": "glue data quality provides custom SQL",
    "start": "116399",
    "end": "119280"
  },
  {
    "text": "rule type to accomplish this",
    "start": "119280",
    "end": "123119"
  },
  {
    "text": "here I will check that at least phone or",
    "start": "123119",
    "end": "126479"
  },
  {
    "text": "email is present for each row in the",
    "start": "126479",
    "end": "128819"
  },
  {
    "text": "file let's now add a data quality rule",
    "start": "128819",
    "end": "131580"
  },
  {
    "text": "to ensure that all customer have sales",
    "start": "131580",
    "end": "134040"
  },
  {
    "text": "record to do so I will add a referential",
    "start": "134040",
    "end": "138000"
  },
  {
    "text": "Integrity rule by providing the source",
    "start": "138000",
    "end": "141180"
  },
  {
    "text": "field reference field and a threshold",
    "start": "141180",
    "end": "144900"
  },
  {
    "text": "our rule authoring is now complete to",
    "start": "144900",
    "end": "148800"
  },
  {
    "text": "identify records that failed data",
    "start": "148800",
    "end": "151739"
  },
  {
    "text": "quality check I will choose original",
    "start": "151739",
    "end": "153540"
  },
  {
    "text": "data that will output my primary data",
    "start": "153540",
    "end": "156540"
  },
  {
    "text": "set and then enable add new columns to",
    "start": "156540",
    "end": "160379"
  },
  {
    "text": "indicate data quality errors",
    "start": "160379",
    "end": "162720"
  },
  {
    "text": "this will add new node called row level",
    "start": "162720",
    "end": "166440"
  },
  {
    "text": "outcomes in the output schema of this",
    "start": "166440",
    "end": "169319"
  },
  {
    "start": "167000",
    "end": "203000"
  },
  {
    "text": "node you can see four new columns are",
    "start": "169319",
    "end": "172200"
  },
  {
    "text": "added in addition to the primary data",
    "start": "172200",
    "end": "174360"
  },
  {
    "text": "data quality rules pass will show all",
    "start": "174360",
    "end": "177360"
  },
  {
    "text": "the past rows for that particular row",
    "start": "177360",
    "end": "180180"
  },
  {
    "text": "data quality rules fail will show all",
    "start": "180180",
    "end": "182879"
  },
  {
    "text": "the failed rules",
    "start": "182879",
    "end": "184500"
  },
  {
    "text": "there are some rule types such as row",
    "start": "184500",
    "end": "186720"
  },
  {
    "text": "count that are not applied at individual",
    "start": "186720",
    "end": "189360"
  },
  {
    "text": "row level these rules are recorded in",
    "start": "189360",
    "end": "192599"
  },
  {
    "text": "data qualities rule skip column",
    "start": "192599",
    "end": "195659"
  },
  {
    "text": "finally data quality evaluation result",
    "start": "195659",
    "end": "198840"
  },
  {
    "text": "shows the overall past failed result at",
    "start": "198840",
    "end": "202860"
  },
  {
    "text": "a row level now going back to evaluate",
    "start": "202860",
    "end": "206280"
  },
  {
    "start": "203000",
    "end": "215000"
  },
  {
    "text": "data quality node",
    "start": "206280",
    "end": "207840"
  },
  {
    "text": "I will also choose data quality results",
    "start": "207840",
    "end": "212040"
  },
  {
    "text": "this will add a new node rule outcomes",
    "start": "212040",
    "end": "215180"
  },
  {
    "start": "215000",
    "end": "249000"
  },
  {
    "text": "it will show results summarized at role",
    "start": "215180",
    "end": "219300"
  },
  {
    "text": "level",
    "start": "219300",
    "end": "220140"
  },
  {
    "text": "I will write this output to separate S3",
    "start": "220140",
    "end": "223140"
  },
  {
    "text": "bucket for detailed analysis and",
    "start": "223140",
    "end": "225420"
  },
  {
    "text": "visualization",
    "start": "225420",
    "end": "228140"
  },
  {
    "text": "again going back to evaluate data",
    "start": "228980",
    "end": "231959"
  },
  {
    "text": "quality node to choose the action based",
    "start": "231959",
    "end": "235260"
  },
  {
    "text": "on the data quality evaluation result",
    "start": "235260",
    "end": "238200"
  },
  {
    "text": "you can choose from continue with job",
    "start": "238200",
    "end": "240480"
  },
  {
    "text": "which is default fail job after loading",
    "start": "240480",
    "end": "244200"
  },
  {
    "text": "the target data",
    "start": "244200",
    "end": "245819"
  },
  {
    "text": "or field job without loading the target",
    "start": "245819",
    "end": "248340"
  },
  {
    "text": "data",
    "start": "248340",
    "end": "249599"
  },
  {
    "start": "249000",
    "end": "276000"
  },
  {
    "text": "in my job I will go with the default",
    "start": "249599",
    "end": "252060"
  },
  {
    "text": "option of continue with the job from row",
    "start": "252060",
    "end": "255599"
  },
  {
    "text": "level outcomes node I will filter field",
    "start": "255599",
    "end": "258600"
  },
  {
    "text": "record from password card using",
    "start": "258600",
    "end": "261380"
  },
  {
    "text": "conditional router",
    "start": "261380",
    "end": "264419"
  },
  {
    "text": "let's provide the group name and add",
    "start": "264419",
    "end": "266940"
  },
  {
    "text": "condition",
    "start": "266940",
    "end": "268680"
  },
  {
    "text": "I will filter Based on data quality",
    "start": "268680",
    "end": "271320"
  },
  {
    "text": "evaluation result",
    "start": "271320",
    "end": "273240"
  },
  {
    "text": "column matches field",
    "start": "273240",
    "end": "276540"
  },
  {
    "start": "276000",
    "end": "298000"
  },
  {
    "text": "default group will have all the past",
    "start": "276540",
    "end": "279600"
  },
  {
    "text": "record",
    "start": "279600",
    "end": "281880"
  },
  {
    "text": "I will write the output of these node to",
    "start": "281880",
    "end": "284220"
  },
  {
    "text": "different stage location",
    "start": "284220",
    "end": "287220"
  },
  {
    "text": "pass record will go to past folder and",
    "start": "287220",
    "end": "290820"
  },
  {
    "text": "field record will go to the field",
    "start": "290820",
    "end": "292380"
  },
  {
    "text": "folders",
    "start": "292380",
    "end": "294979"
  },
  {
    "start": "298000",
    "end": "320000"
  },
  {
    "text": "view Studio automatically generates the",
    "start": "298860",
    "end": "301440"
  },
  {
    "text": "code that you can view",
    "start": "301440",
    "end": "303180"
  },
  {
    "text": "you can easily take this code",
    "start": "303180",
    "end": "305419"
  },
  {
    "text": "parameterize it and reuse the same job",
    "start": "305419",
    "end": "308699"
  },
  {
    "text": "for different data sources and data",
    "start": "308699",
    "end": "311400"
  },
  {
    "text": "quality rules thus reducing your overall",
    "start": "311400",
    "end": "315120"
  },
  {
    "text": "development time let's save and run this",
    "start": "315120",
    "end": "318060"
  },
  {
    "text": "job",
    "start": "318060",
    "end": "320240"
  },
  {
    "text": "the job execution is successful",
    "start": "321300",
    "end": "323880"
  },
  {
    "text": "let's check the data quality result in",
    "start": "323880",
    "end": "326400"
  },
  {
    "text": "the data quality tab",
    "start": "326400",
    "end": "329479"
  },
  {
    "text": "as you can see three out of five rules",
    "start": "329520",
    "end": "332220"
  },
  {
    "text": "passed and overall score is 60 percent",
    "start": "332220",
    "end": "337039"
  },
  {
    "start": "336000",
    "end": "383000"
  },
  {
    "text": "let's look at some of the field record",
    "start": "337139",
    "end": "341180"
  },
  {
    "text": "you can see the field record and the",
    "start": "342720",
    "end": "344880"
  },
  {
    "text": "failure reason for each of the records",
    "start": "344880",
    "end": "348660"
  },
  {
    "text": "I can now work with my source system",
    "start": "348660",
    "end": "350940"
  },
  {
    "text": "owners to fix this data issue at the",
    "start": "350940",
    "end": "354419"
  },
  {
    "text": "source or identify and apply new",
    "start": "354419",
    "end": "357479"
  },
  {
    "text": "transformation to improve data quality",
    "start": "357479",
    "end": "359759"
  },
  {
    "text": "in this demo I showed you how you can",
    "start": "359759",
    "end": "362340"
  },
  {
    "text": "use glue data quality in your ETL",
    "start": "362340",
    "end": "364259"
  },
  {
    "text": "pipeline to identify and filter bad data",
    "start": "364259",
    "end": "367080"
  },
  {
    "text": "from your high quality data we would",
    "start": "367080",
    "end": "370199"
  },
  {
    "text": "love to hear your feedback please feel",
    "start": "370199",
    "end": "372780"
  },
  {
    "text": "free to reach out to us using contact us",
    "start": "372780",
    "end": "375000"
  },
  {
    "text": "link on data quality tab thank you",
    "start": "375000",
    "end": "380240"
  }
]
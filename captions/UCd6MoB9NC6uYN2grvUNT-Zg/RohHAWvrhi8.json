[
  {
    "start": "0",
    "end": "50000"
  },
  {
    "text": "hey everybody uh we're gonna get started here so try and grab a seat and uh get settled in this is a web 301",
    "start": "1280",
    "end": "6799"
  },
  {
    "text": "operational web log analysis hopefully this is the session that you were looking for uh with that i've got a lot of content to",
    "start": "6799",
    "end": "12960"
  },
  {
    "text": "get through and unfortunately only 45 minutes to get through it so with that i'd like to get started",
    "start": "12960",
    "end": "18240"
  },
  {
    "text": "my name is chris muns i'm a solutions architect for amazon web services based out of our new york city office i've been with aws for a little over three",
    "start": "18240",
    "end": "24320"
  },
  {
    "text": "years this point in time real quick just want to note to say that unfortunately i'm not going to stick around for questions after the session",
    "start": "24320",
    "end": "30880"
  },
  {
    "text": "i actually have another talk directly after this at 2 15 deployment automation in room 3001 so if",
    "start": "30880",
    "end": "37840"
  },
  {
    "text": "you like me enough follow me on over there and maybe you can ask me questions about this session after that one otherwise you can hit me up at twitter",
    "start": "37840",
    "end": "44160"
  },
  {
    "text": "at chrismunds or email me munz amazon.com for any questions that you might have",
    "start": "44160",
    "end": "50719"
  },
  {
    "start": "50000",
    "end": "75000"
  },
  {
    "text": "so i always like to get a good idea of who's in the room here who here feels like they do a good job",
    "start": "50719",
    "end": "56160"
  },
  {
    "text": "of processing understanding collecting aggregating their log data today okay so",
    "start": "56160",
    "end": "62160"
  },
  {
    "text": "good hands that's good who thinks that they could improve upon it awesome well hopefully you'll get some ideas",
    "start": "62160",
    "end": "68560"
  },
  {
    "text": "here today or to both either start doing this process or approve upon the process that you have already today",
    "start": "68560",
    "end": "74560"
  },
  {
    "text": "i like to start my talk sometimes with quotes uh this one is on the importance of logs and essentially what it says is",
    "start": "74560",
    "end": "79920"
  },
  {
    "start": "75000",
    "end": "118000"
  },
  {
    "text": "that log data contains some of the most valuable raw information you can gather and analyze about your infrastructures and",
    "start": "79920",
    "end": "85280"
  },
  {
    "text": "applications this was clearly set by said by a very very wise person uh actually it was said by me in a blog",
    "start": "85280",
    "end": "91439"
  },
  {
    "text": "post back in may on our startup blog and so i wrote this post for our startup blog when we first launched it",
    "start": "91439",
    "end": "97680"
  },
  {
    "text": "and was actually very very surprised by the feedback i got reached out to by a whole ton of customers of all",
    "start": "97680",
    "end": "102720"
  },
  {
    "text": "different sizes even though it was on our startup blog i got reached out to by enterprises and they said we need help with this",
    "start": "102720",
    "end": "107840"
  },
  {
    "text": "we're not doing it well how can we do it better and so it kind of influenced me with the idea of doing this talk here at re",
    "start": "107840",
    "end": "113520"
  },
  {
    "text": "invent and so essentially that's hopefully why we're all here in this room today",
    "start": "113520",
    "end": "118560"
  },
  {
    "start": "118000",
    "end": "156000"
  },
  {
    "text": "so what is it that makes logs important right essentially there's just a ton of information that you can",
    "start": "118560",
    "end": "124079"
  },
  {
    "text": "garner from the logs that exist inside of your infrastructure generated by your applications of",
    "start": "124079",
    "end": "129200"
  },
  {
    "text": "all sorts of shapes and sizes you know things such as you know how is your your website or your application or whatever",
    "start": "129200",
    "end": "134720"
  },
  {
    "text": "process it might be inside of your your large infrastructure performing are there errors in your code are people",
    "start": "134720",
    "end": "140800"
  },
  {
    "text": "potentially attacking your site right security based information you could find in logs are those attacks successful are they",
    "start": "140800",
    "end": "146400"
  },
  {
    "text": "not successful uh what type of content are people you know accessing frequently and you know other information even",
    "start": "146400",
    "end": "152879"
  },
  {
    "text": "things such as you know where are my customers coming from unfortunately though working with",
    "start": "152879",
    "end": "158080"
  },
  {
    "start": "156000",
    "end": "248000"
  },
  {
    "text": "with logs can be very very hard uh there's a lot of different things about working with logs that that make it",
    "start": "158080",
    "end": "163200"
  },
  {
    "text": "difficult uh starting with the fact that there could be numerous sources right throughout your infrastructure you might have various different resources that",
    "start": "163200",
    "end": "170160"
  },
  {
    "text": "are capable of generating many many many logs and again even on an individual instance",
    "start": "170160",
    "end": "175360"
  },
  {
    "text": "for instance if you start up an amazon linux instance today you're going to find a little over a dozen log files that are generating",
    "start": "175360",
    "end": "181680"
  },
  {
    "text": "log entries just by the instance running so you know os based logs application",
    "start": "181680",
    "end": "186720"
  },
  {
    "text": "level logs web server logs all sorts of different things that might exist there there's also very very high velocity data typically",
    "start": "186720",
    "end": "193920"
  },
  {
    "text": "if you think of a typical request to a website that maybe has some css some images some javascript",
    "start": "193920",
    "end": "200000"
  },
  {
    "text": "other content embedded upon it that single page load could be generating",
    "start": "200000",
    "end": "205040"
  },
  {
    "text": "10 plus times the amount of log entries for that single request again based on all these other assets",
    "start": "205040",
    "end": "210959"
  },
  {
    "text": "that you might have there on that page when you take into account that you might have multiple tiers inside of a single application flow",
    "start": "210959",
    "end": "216879"
  },
  {
    "text": "for instance you know typical three tier application where you've got a web server talking to an application server talking",
    "start": "216879",
    "end": "222080"
  },
  {
    "text": "to a database server you could be generating logs across each of those various places as part of that one single request so it",
    "start": "222080",
    "end": "229200"
  },
  {
    "text": "can be very very high data velocity much higher than your actual traffic or user request base",
    "start": "229200",
    "end": "235120"
  },
  {
    "text": "uh you also run into varied log patterns we'll talk about this a little bit later here in this talk and then lastly it's very much like",
    "start": "235120",
    "end": "240959"
  },
  {
    "text": "searching for toothpicks in a pile of toothpicks right when you look at log files in the raw it's nearly impossible to be able to",
    "start": "240959",
    "end": "246959"
  },
  {
    "text": "pick out the things that are important to you again talking a little bit about where logs can come from if you look at this",
    "start": "246959",
    "end": "252560"
  },
  {
    "start": "248000",
    "end": "278000"
  },
  {
    "text": "diagram here today we have an application maybe it's being accessed by a native mobile client maybe there's a browser-based aspect to",
    "start": "252560",
    "end": "259120"
  },
  {
    "text": "it serving our content from a cdn that cdn then is reaching back to origin maybe for static assets from s3",
    "start": "259120",
    "end": "265919"
  },
  {
    "text": "reaching back to our actual web server through elb to our web tier through another elb to an app tier to a",
    "start": "265919",
    "end": "272320"
  },
  {
    "text": "database and if you were to think of which components it is in this infrastructure that could be generating log files for",
    "start": "272320",
    "end": "277520"
  },
  {
    "text": "you today the fact of it is all of these things nowadays many native applications that",
    "start": "277520",
    "end": "282800"
  },
  {
    "start": "278000",
    "end": "312000"
  },
  {
    "text": "people are writing for ios and android they're actually doing log collection on performance and access patterns",
    "start": "282800",
    "end": "288000"
  },
  {
    "text": "shipping that back to them and you also see people doing a lot of you know real user management and metric",
    "start": "288000",
    "end": "293280"
  },
  {
    "text": "collection from actual user actions on web pages as well and once again when you're looking at",
    "start": "293280",
    "end": "299199"
  },
  {
    "text": "this pile of toothpicks you have to figure out which one of these matters the most here which one of these is going to be",
    "start": "299199",
    "end": "304240"
  },
  {
    "text": "insightful all right looking at this how do we know that this one is important first this one over here and the reality",
    "start": "304240",
    "end": "309919"
  },
  {
    "text": "of is unfortunately we're not looking at toothpicks we're looking at wonderful walls of text like this that goes scrolling by if",
    "start": "309919",
    "end": "315520"
  },
  {
    "text": "you've ever tailed a log file in a very active system and the same question implies do we care about this one or do we care",
    "start": "315520",
    "end": "322800"
  },
  {
    "text": "about this one so a lot of things here again that make working with logs very very hard and it potentially a complicated process inside",
    "start": "322800",
    "end": "329440"
  },
  {
    "text": "of your your day-to-day operational workflows so i like to kind of step back and kind of bring us forward into how we got into",
    "start": "329440",
    "end": "335360"
  },
  {
    "text": "where we are today with logs so let's go back to the beginning here a little bit and work ourselves forward",
    "start": "335360",
    "end": "341520"
  },
  {
    "start": "341000",
    "end": "424000"
  },
  {
    "text": "essentially syslog is really kind of the the modern interpretation of log analysis or log collection that we see today it",
    "start": "341520",
    "end": "348479"
  },
  {
    "text": "actually dates itself back quite some time now over 30 years to a gentleman by the name of eric allman who was working at uc berkeley",
    "start": "348479",
    "end": "355199"
  },
  {
    "text": "on the send mail project and when he was working on cinema he was looking for a common structured way that he could",
    "start": "355199",
    "end": "360720"
  },
  {
    "text": "collect logs from send mail and came up with syslog which at that time was just a pattern for log files",
    "start": "360720",
    "end": "366639"
  },
  {
    "text": "and not a daemon or more of a process that you would see today and so uh he came up with the standard",
    "start": "366639",
    "end": "372319"
  },
  {
    "text": "and it was actually very well received by the eunuchs community and so it became kind of a loose standard inside of unix and kind of",
    "start": "372319",
    "end": "378560"
  },
  {
    "text": "spread like wildfire from there to the point where you see syslog integrated into hardware devices today",
    "start": "378560",
    "end": "384080"
  },
  {
    "text": "from various network providers and other pieces of hardware that exist and then eventually in 2001 almost 20",
    "start": "384080",
    "end": "390800"
  },
  {
    "text": "years later it actually got standardized into an rfc rfc 3164 which became the",
    "start": "390800",
    "end": "395919"
  },
  {
    "text": "bsd syslog protocol one of the key things that syslog defined was this concept of a facility",
    "start": "395919",
    "end": "401919"
  },
  {
    "text": "and a severity and essentially you could think of a facility as the the process or the thing that was creating this message",
    "start": "401919",
    "end": "408880"
  },
  {
    "text": "and then a severity pretty straightforward how important was this message to me what type of content might it be covering",
    "start": "408880",
    "end": "415120"
  },
  {
    "text": "and then eventually later in 2009 this rfc was superseded by rfc 5425 which is the more common one",
    "start": "415120",
    "end": "421919"
  },
  {
    "text": "that is known and used today if we go back and look at what rfc 5425",
    "start": "421919",
    "end": "427520"
  },
  {
    "start": "424000",
    "end": "472000"
  },
  {
    "text": "defines as a syslog message we see what is this line entry right here and this is actually the example that they",
    "start": "427520",
    "end": "433759"
  },
  {
    "text": "have from the documentation and if we want to break this down and understand what it is in that nice little complicated line",
    "start": "433759",
    "end": "439520"
  },
  {
    "text": "of text what we see at top is that there is the facility which has a number representation",
    "start": "439520",
    "end": "445199"
  },
  {
    "text": "numerical representation multiplied by eight added with the severity we have a",
    "start": "445199",
    "end": "450560"
  },
  {
    "text": "version of syslog potentially there's a timestamp which has its own rfc",
    "start": "450560",
    "end": "455599"
  },
  {
    "text": "there's a hostname an app name a proc id if this was a process that was running structured data that could be passed in",
    "start": "455599",
    "end": "462479"
  },
  {
    "text": "a message id message encoding and a message so a lot of different things in this one log line that tell us about what's going",
    "start": "462479",
    "end": "469039"
  },
  {
    "text": "on in our application or in our infrastructure on an instance for us so this sounds pretty easy right it has",
    "start": "469039",
    "end": "474800"
  },
  {
    "start": "472000",
    "end": "483000"
  },
  {
    "text": "a common structure it's well defined we've got some facility we've got severity the unix world likes it",
    "start": "474800",
    "end": "480479"
  },
  {
    "text": "everything should be great and wonderful unfortunately it wasn't great and wonderful for everybody and so you",
    "start": "480479",
    "end": "486240"
  },
  {
    "start": "483000",
    "end": "511000"
  },
  {
    "text": "started to get was differing syslog protocols that started to exist so in 1992 the national center for super",
    "start": "486240",
    "end": "492479"
  },
  {
    "text": "community applications uh released their version of httpd which was based on the original one that tim's",
    "start": "492479",
    "end": "498000"
  },
  {
    "text": "berner lee had wrote and then eventually in 1995 this became apache which we all know today",
    "start": "498000",
    "end": "503599"
  },
  {
    "text": "and apache and actually technically the ncshpd had its own log format which became",
    "start": "503599",
    "end": "508800"
  },
  {
    "text": "known as common log format so commonlock format is something that we're probably much much more familiar",
    "start": "508800",
    "end": "514000"
  },
  {
    "start": "511000",
    "end": "531000"
  },
  {
    "text": "with today you'll see this on windows servers on linux servers across application types if you get cdn logs",
    "start": "514000",
    "end": "519680"
  },
  {
    "text": "they look very similar to this load balancer logs anything that's processing hdp these days pretty much follows",
    "start": "519680",
    "end": "525360"
  },
  {
    "text": "uh this type of log pattern format so uh again a little bit more readable here",
    "start": "525360",
    "end": "530399"
  },
  {
    "text": "and if we want to break this down and do the comparison of again what these different fields mean what we see up first is we have an ip address",
    "start": "530399",
    "end": "536959"
  },
  {
    "start": "531000",
    "end": "584000"
  },
  {
    "text": "we have a user identifier for the old identd protocol which is actually largely dead but by default this is still something",
    "start": "536959",
    "end": "542880"
  },
  {
    "text": "that gets logged we have a user id if this was going to be an httpd or cgi cgi-based",
    "start": "542880",
    "end": "548399"
  },
  {
    "text": "application with for authentication again nowadays most people are not using that for authentication they're using something",
    "start": "548399",
    "end": "554080"
  },
  {
    "text": "inside of their application to do that so another kind of dead fields we have a time stamp again one that has",
    "start": "554080",
    "end": "559680"
  },
  {
    "text": "its own rfc we have our actual request in this case getting the the root document of this",
    "start": "559680",
    "end": "564720"
  },
  {
    "text": "web server we have an http status code a size and response",
    "start": "564720",
    "end": "569839"
  },
  {
    "text": "in bytes in this case the size of the response sorry we have a referrer if there was one and then we have the user agent so",
    "start": "569839",
    "end": "575839"
  },
  {
    "text": "pretty straightforward a lot easier to read a lot easier to understand some debt information in here but this",
    "start": "575839",
    "end": "581120"
  },
  {
    "text": "at least gets us forward into where we are today with logs so again a little bit of a history lesson but now",
    "start": "581120",
    "end": "587279"
  },
  {
    "start": "584000",
    "end": "590000"
  },
  {
    "text": "let's let's move forward and actually take this and make something useful out of it so what we'll talk to you today is my",
    "start": "587279",
    "end": "593200"
  },
  {
    "start": "590000",
    "end": "608000"
  },
  {
    "text": "four-ish steps to operational log analysis with an asterisk being there that these",
    "start": "593200",
    "end": "598240"
  },
  {
    "text": "four steps are actually several mini steps but i like to saying four instead of saying like 29 or something like that i",
    "start": "598240",
    "end": "603680"
  },
  {
    "text": "think it makes it seem a little simpler so let's go into these now",
    "start": "603680",
    "end": "608959"
  },
  {
    "start": "608000",
    "end": "639000"
  },
  {
    "text": "so the first one is to generate useful log data pretty straightforward here right if we're going to be trying to do something with this data",
    "start": "608959",
    "end": "614880"
  },
  {
    "text": "we want the data that we're generating to be as useful as possible there was an earlier talk today at uh 11",
    "start": "614880",
    "end": "620959"
  },
  {
    "text": "o'clock on web server optimization where a peer of mine and justin lynch from chart beat",
    "start": "620959",
    "end": "626000"
  },
  {
    "text": "talked about how generating logs on your web server is actually an impactful thing right you're eating out potentially disc",
    "start": "626000",
    "end": "631360"
  },
  {
    "text": "cycles you're using up some cpu so if you're going to be doing that you want those log files to be worth exactly",
    "start": "631360",
    "end": "636720"
  },
  {
    "text": "the resources that you're consuming with them so if you go back and look at my example apache log line that i have here",
    "start": "636720",
    "end": "644320"
  },
  {
    "start": "639000",
    "end": "666000"
  },
  {
    "text": "in this case this is from pingdom hitting my web server to make sure that it's up and alive uh what we can see in the bottom box",
    "start": "644320",
    "end": "650720"
  },
  {
    "text": "here is how apache represents this log file inside of its configuration file so apache does this wonderful",
    "start": "650720",
    "end": "656959"
  },
  {
    "text": "percent letter symbol thing here to help us define what these fields represent and essentially what we can do is we can",
    "start": "656959",
    "end": "662880"
  },
  {
    "text": "play with this and configure it and make it more worthwhile to us i if you go and dig into the apache docs",
    "start": "662880",
    "end": "668640"
  },
  {
    "start": "666000",
    "end": "772000"
  },
  {
    "text": "you'll see that there are a couple dozen actually different parameters that you could generate inside of a a potential log entry for instance here",
    "start": "668640",
    "end": "675920"
  },
  {
    "text": "percent d is the time taken to reserve the quest in microseconds percent t is the time taken to serve the request",
    "start": "675920",
    "end": "682720"
  },
  {
    "text": "in seconds uh hopefully we're not dealing with second based web page generation but still does happen and then towards the",
    "start": "682720",
    "end": "688880"
  },
  {
    "text": "bottom here the more interesting ones uh percent and then in brackets some variable in this case foo bar c and",
    "start": "688880",
    "end": "694320"
  },
  {
    "text": "below that foo bar n for c in this case you can actually pass in cooking information to your log files",
    "start": "694320",
    "end": "701279"
  },
  {
    "text": "and then n is from a functionality of apache called apache note which languages like php and others can",
    "start": "701279",
    "end": "706720"
  },
  {
    "text": "actually toss data into a log file from inside of your applications so lots of",
    "start": "706720",
    "end": "711760"
  },
  {
    "text": "different customizable capabilities that we have here in generating these log files so if you",
    "start": "711760",
    "end": "717360"
  },
  {
    "text": "go back to my example here again i have this pattern up top initially this is the default that comes inside of apache and we can see how i",
    "start": "717360",
    "end": "725360"
  },
  {
    "text": "have these these two kind of useless hash marks for me next to the ip address in the second box and there's other data that i'd like to",
    "start": "725360",
    "end": "731600"
  },
  {
    "text": "add so in this case what i'm going to do is remove those two hash marks the percent l symbol the percent u",
    "start": "731600",
    "end": "738079"
  },
  {
    "text": "and replace those with percent v which is going to show the host that is actually handling this request for me and then",
    "start": "738079",
    "end": "743600"
  },
  {
    "text": "i'm going to add in later on percent d which is going to show me the time that it took in microseconds to serve this request",
    "start": "743600",
    "end": "749920"
  },
  {
    "text": "again you can think that that would be a lot more useful information for me gathering that that bit of information and then using",
    "start": "749920",
    "end": "755440"
  },
  {
    "text": "it later in my log analysis and again there's just a ton of things that you could add into a log file like this",
    "start": "755440",
    "end": "761360"
  },
  {
    "text": "and then the result is kind of the bottom box here where you can see that this request was served from php",
    "start": "761360",
    "end": "766639"
  },
  {
    "text": "dash app one and then we can see the time and microseconds that it took for this web page to be served",
    "start": "766639",
    "end": "772880"
  },
  {
    "text": "and not to sidetrack and ignore nginx in this again something that many many people in this room are probably using",
    "start": "772880",
    "end": "778000"
  },
  {
    "text": "it has very similar capabilities of altering your log files uh wonderfully enough in nginx it's",
    "start": "778000",
    "end": "783600"
  },
  {
    "text": "actually a lot cleaner to understand the syntax of what these log files look like you can see example here you know dollar",
    "start": "783600",
    "end": "788880"
  },
  {
    "text": "remote underscore address is a lot easier to understand than percent h",
    "start": "788880",
    "end": "794560"
  },
  {
    "start": "794000",
    "end": "810000"
  },
  {
    "text": "so uh we've got to made our log data useful right we've cleaned out things that we don't need we've added in some",
    "start": "794560",
    "end": "799760"
  },
  {
    "text": "fields that we do need that's important to us the next thing that we need to do is actually do something with this data after it's been generated",
    "start": "799760",
    "end": "806000"
  },
  {
    "text": "and so the first thing that we want to do is get this data off of our web instance if possible so i see there being kind of two",
    "start": "806000",
    "end": "811760"
  },
  {
    "start": "810000",
    "end": "829000"
  },
  {
    "text": "different patterns and ways that this could be done the first is to centralize the log data in its raw format first and then do",
    "start": "811760",
    "end": "817760"
  },
  {
    "text": "analysis on that centralized data the second is to do analysis on the host and centralize the results",
    "start": "817760",
    "end": "824000"
  },
  {
    "text": "so two different patterns here at the end though still kind of a common result that we're going to get out of it",
    "start": "824000",
    "end": "829120"
  },
  {
    "start": "829000",
    "end": "835000"
  },
  {
    "text": "and essentially either way you want to make sure that you're getting your log data off of your host as quickly as possible",
    "start": "829120",
    "end": "835600"
  },
  {
    "start": "835000",
    "end": "843000"
  },
  {
    "text": "and many people would say why did that why does that matter why can't i sync it up once a night why can't i sync it up every hour",
    "start": "835600",
    "end": "842000"
  },
  {
    "text": "and the reason is essentially that instance failure happens right hardware can die instances can kernel panic all sorts of",
    "start": "842000",
    "end": "849199"
  },
  {
    "start": "843000",
    "end": "878000"
  },
  {
    "text": "things can happen you could potentially fill your disks depending on if you had a large burst of traffic and you weren't prepared for it",
    "start": "849199",
    "end": "855519"
  },
  {
    "text": "and then lastly if you use auto scaling and you have instances being brought up and down if those instances are",
    "start": "855519",
    "end": "861120"
  },
  {
    "text": "allowed to scale down and be terminated on you if you aren't doing something to get those logs off ahead of time you're",
    "start": "861120",
    "end": "866480"
  },
  {
    "text": "potentially taking data and throwing it away so again i really encourage the idea of taking this log data in",
    "start": "866480",
    "end": "872160"
  },
  {
    "text": "as close to synchronously as possible getting it off of the host as soon as the data has been generated",
    "start": "872160",
    "end": "878880"
  },
  {
    "text": "so if we go with the option of centralizing the data first and then we'll analyze it later there's a number of different options that we have here",
    "start": "878880",
    "end": "884959"
  },
  {
    "text": "and we're going to kind of go through a bunch of these here now so the first is kind of the most straightforward what i kind of consider the lowest level here",
    "start": "884959",
    "end": "891279"
  },
  {
    "start": "887000",
    "end": "1012000"
  },
  {
    "text": "the open source options for log centralization syslog ng r syslog nx log these are all kind of based on",
    "start": "891279",
    "end": "898639"
  },
  {
    "text": "the original concept around syslog and syslog d which was kind of the first daemon used for centralizing log data in",
    "start": "898639",
    "end": "904880"
  },
  {
    "text": "unix operating systems uh syslog ng and r syslog are usually primarily linux based",
    "start": "904880",
    "end": "910480"
  },
  {
    "text": "nx log is a popular windows server log centralizing tool and again they're both variants or",
    "start": "910480",
    "end": "916000"
  },
  {
    "text": "they're all variants off of syslog but advanced in terms that they now offer things like tcp as a delivery",
    "start": "916000",
    "end": "922560"
  },
  {
    "text": "mechanism security filtering and other good things there typically these will run as an os",
    "start": "922560",
    "end": "928000"
  },
  {
    "text": "process and entail and capture your log data and then ship it off to some centralized place we can see here in the kind of the",
    "start": "928000",
    "end": "933680"
  },
  {
    "text": "diagram of how this works i'd be running one of these daemons on top of one of my instances and then they would be pushing into some",
    "start": "933680",
    "end": "939839"
  },
  {
    "text": "sort of a centralized place and the other great thing is that usually these diamonds can take logs from third-party places",
    "start": "939839",
    "end": "946000"
  },
  {
    "text": "uh in the centralized aspect that is so you could take your hardware syslog capabilities and point",
    "start": "946000",
    "end": "951360"
  },
  {
    "text": "that at a centralized syslog ng your rsys log server and collect that data from your network",
    "start": "951360",
    "end": "956399"
  },
  {
    "text": "devices so these are the pros of the open source options that you have here",
    "start": "956399",
    "end": "961839"
  },
  {
    "text": "but there are some cons right so this is only part of the problem for us this is going to get that log data moved",
    "start": "961839",
    "end": "966880"
  },
  {
    "text": "into a central place which is useful but then after that we still need things like analytics dashboarding",
    "start": "966880",
    "end": "972320"
  },
  {
    "text": "and so we're going to be needing to add at least other tools on top of this here typically this centralized component",
    "start": "972320",
    "end": "978480"
  },
  {
    "text": "that we have here which again is a very common pattern at scale can become a bit of a bottleneck all right you have to worry",
    "start": "978480",
    "end": "984160"
  },
  {
    "text": "about scaling that one server you have to worry about overwhelming it i've actually seen in very high traffic situations where",
    "start": "984160",
    "end": "990240"
  },
  {
    "text": "spikes of traffic can cause a syslog server to become overwhelmed and that overwhelmingly that this log server could have you know ripple",
    "start": "990240",
    "end": "996880"
  },
  {
    "text": "effects upon other parts of the infrastructure and again the scaling aspect of this becomes a problem at some point you have",
    "start": "996880",
    "end": "1002959"
  },
  {
    "text": "to think about federating out among multiple different centralized syslog servers and so it's not really a simple clear path to doing this at very",
    "start": "1002959",
    "end": "1009600"
  },
  {
    "text": "very very large scale the next next option is kind of the complete opposite of this",
    "start": "1009600",
    "end": "1014880"
  },
  {
    "start": "1012000",
    "end": "1100000"
  },
  {
    "text": "is to go with an enterprise tool potentially something similar to splunk so we saw splunk on stage today",
    "start": "1014880",
    "end": "1020639"
  },
  {
    "text": "inverters keynote a very awesome product right enterprise grade lots of huge enterprise customers",
    "start": "1020639",
    "end": "1025918"
  },
  {
    "text": "using it across you know federal government customers health care startups everything in between extremely scalable",
    "start": "1025919",
    "end": "1033038"
  },
  {
    "text": "product i've personally used splunk in a multiple hundred gigabyte log day sorry multiple hundreds of",
    "start": "1033039",
    "end": "1039360"
  },
  {
    "text": "gigabytes of log data being generated in a single day at a previous job and so we splunk very",
    "start": "1039360",
    "end": "1045360"
  },
  {
    "text": "heavily and it just was rock solid in terms of being able to aggregate store and then present out my data to me",
    "start": "1045360",
    "end": "1051760"
  },
  {
    "text": "splunk offers up built-in fault tolerance there's security of the data that you can have layered on top of it",
    "start": "1051760",
    "end": "1058000"
  },
  {
    "text": "it can technically also accept data from third parties so you can push this log data into splunk which is pretty cool",
    "start": "1058000",
    "end": "1063520"
  },
  {
    "text": "and then the thing about splunk is that it really is that full package right so it's going to give you log forwarding it's going to give you analyzing",
    "start": "1063520",
    "end": "1069120"
  },
  {
    "text": "capabilities dashboarding capabilities and third-party apps that you could plug into it we see here in the example of",
    "start": "1069120",
    "end": "1075520"
  },
  {
    "text": "the network what i'd be running in this case is either a light splunk forwarder or the spelunk agent on the rest of my",
    "start": "1075520",
    "end": "1081039"
  },
  {
    "text": "infrastructure and then pushing that data into my indexers they support the ability of you",
    "start": "1081039",
    "end": "1086400"
  },
  {
    "text": "being able to essentially round robin across the indexers which is a great way to scale and handle",
    "start": "1086400",
    "end": "1092160"
  },
  {
    "text": "again burst in traffic and high availability and redundancy",
    "start": "1092160",
    "end": "1097200"
  },
  {
    "text": "so again pros here on splunk and enterprise grade services like it you know some cons unfortunately with",
    "start": "1097200",
    "end": "1103360"
  },
  {
    "start": "1100000",
    "end": "1148000"
  },
  {
    "text": "enterprise quality applications comes enterprise pricing and licensing right not the freest of",
    "start": "1103360",
    "end": "1111440"
  },
  {
    "text": "services and pieces of software that are out there but again very much worthwhile to the money that you'd spend",
    "start": "1111440",
    "end": "1116640"
  },
  {
    "text": "on it and then in terms of scaling potential bottlenecks the indexers can become that bottleneck",
    "start": "1116640",
    "end": "1122880"
  },
  {
    "text": "typically with splunk you license based on the amount that you're going to index in a given time period",
    "start": "1122880",
    "end": "1127919"
  },
  {
    "text": "split up across the number of indexers that you have and so these indexers become a little bit of a rigid aspect in this case",
    "start": "1127919",
    "end": "1134559"
  },
  {
    "text": "and i think that's kind of why you know splunk has this really great sas offering now and it helps you kind of get around any",
    "start": "1134559",
    "end": "1141039"
  },
  {
    "text": "of the hard resource requirement bottlenecks that you might run into so we've covered kind of the very low level",
    "start": "1141039",
    "end": "1146559"
  },
  {
    "text": "open source we've covered enterprise and then now i'd like to cover another option which is a little bit more in the middle here",
    "start": "1146559",
    "end": "1151679"
  },
  {
    "start": "1148000",
    "end": "1263000"
  },
  {
    "text": "another open source option which is called logstash this is part of what is known as the elk stack these days we'll",
    "start": "1151679",
    "end": "1156960"
  },
  {
    "text": "talk a little bit about that further on uh this is another open source tool it's extremely scalable",
    "start": "1156960",
    "end": "1162240"
  },
  {
    "text": "it has fault tolerance built in it's actually supported by the company that makes elasticsearch",
    "start": "1162240",
    "end": "1167360"
  },
  {
    "text": "called elasticsearch very very active this these days i have been following logstash for the",
    "start": "1167360",
    "end": "1173280"
  },
  {
    "text": "better part of the last two years and have been seeing it pop up all over the place massive enterprises",
    "start": "1173280",
    "end": "1178799"
  },
  {
    "text": "startups again kind of everything in between uh very active code base a lot of people",
    "start": "1178799",
    "end": "1184720"
  },
  {
    "text": "committing code to it and so that's kind of contributed to its popularity it's very pluggable if you go to the",
    "start": "1184720",
    "end": "1190000"
  },
  {
    "text": "website you will find a ton of different options for plugging into it and working",
    "start": "1190000",
    "end": "1195120"
  },
  {
    "text": "with it and then lastly it does tie directly into dashboard and analytics tools which is the completeness of what's",
    "start": "1195120",
    "end": "1201120"
  },
  {
    "text": "known as the elk stack and again we'll be talking a little bit later the diagram here you can see",
    "start": "1201120",
    "end": "1206480"
  },
  {
    "text": "is a bit more complicated right i've got my my web and application servers at the top there are a couple of different log",
    "start": "1206480",
    "end": "1212480"
  },
  {
    "text": "stash forwarding agents that can run they have a light forwarder and then they also have the",
    "start": "1212480",
    "end": "1218000"
  },
  {
    "text": "regular logstash application that you can use the lighter one is usually is a lumberjack",
    "start": "1218000",
    "end": "1223600"
  },
  {
    "text": "and there's a couple others out there that are kind of part of that ecosystem so i'd be running that on my actual application in web instances and",
    "start": "1223600",
    "end": "1230880"
  },
  {
    "text": "then typically what you would do for scalability reasons is send those logs into some sort of a queue or a buffer space",
    "start": "1230880",
    "end": "1237440"
  },
  {
    "text": "many people choose to use redis for this and so here you can see you know maybe i'm using elastic redis to handle this so i don't have to",
    "start": "1237440",
    "end": "1243200"
  },
  {
    "text": "manage it myself and then you need something to pull those logs out of that redis queue or buffer if you",
    "start": "1243200",
    "end": "1248799"
  },
  {
    "text": "will so you use the actual logstash daemon which then puts the logs into elasticsearch as",
    "start": "1248799",
    "end": "1254320"
  },
  {
    "text": "its backend index and this is where you would send the logs for longer term storage and eventual analysis",
    "start": "1254320",
    "end": "1260720"
  },
  {
    "text": "so a little bit more complicated than the other options so far um and that kind of is really the",
    "start": "1260720",
    "end": "1265919"
  },
  {
    "start": "1263000",
    "end": "1321000"
  },
  {
    "text": "biggest con today i see with logstash as part of the overall elk stack it's just kind of this complexity of the very different",
    "start": "1265919",
    "end": "1271919"
  },
  {
    "text": "components that you have to manage and run yourself so there's there's definitely a lot of you know do-it-yourself that you would",
    "start": "1271919",
    "end": "1277760"
  },
  {
    "text": "need to do in order to get the full elk stack up and running for you a lot of it's based on java",
    "start": "1277760",
    "end": "1283600"
  },
  {
    "text": "you're going to spend some time becoming familiar with the jvm at some point if you get to a very large scale which if you're not familiar with you",
    "start": "1283600",
    "end": "1289440"
  },
  {
    "text": "know take some time and tuning and then uh the last bullet point here that i have listed as a con many people",
    "start": "1289440",
    "end": "1295039"
  },
  {
    "text": "would see this as a pro and i i find it kind of straddles the fence when you have open source",
    "start": "1295039",
    "end": "1300080"
  },
  {
    "text": "projects like this that are very rapidly moving very rapidly changing sometimes what that can mean is you",
    "start": "1300080",
    "end": "1305360"
  },
  {
    "text": "could be kind of left in the dust very quickly in terms of new capabilities new functionalities incompatibilities between versions and",
    "start": "1305360",
    "end": "1311440"
  },
  {
    "text": "stuff like that but that said it's still a really really great tool and i think probably the most popular",
    "start": "1311440",
    "end": "1317600"
  },
  {
    "text": "open source option that i see out there today and then lastly we have hosted options",
    "start": "1317600",
    "end": "1322880"
  },
  {
    "text": "um so hosted options pretty self-explanatory you're going with a third party to host the log collection storage analyzing of",
    "start": "1322880",
    "end": "1329440"
  },
  {
    "text": "your data um great things about hosted right very easy to get started with you don't need to do anything usually on",
    "start": "1329440",
    "end": "1335280"
  },
  {
    "text": "your own to get this going um these will work usually either via an agent or via some sort of syslog daemon",
    "start": "1335280",
    "end": "1341520"
  },
  {
    "text": "sending log data to the hosted sas offering that you're working with you don't have to deal with scaling",
    "start": "1341520",
    "end": "1346880"
  },
  {
    "text": "yourself which is great they typically usually have very flexible pricing models they have support options and built-in",
    "start": "1346880",
    "end": "1354880"
  },
  {
    "text": "dashboardings usually is part of all of these and lastly which i think is probably the most important part of you know any sas",
    "start": "1354880",
    "end": "1360240"
  },
  {
    "text": "offering or cloud in general is that they obviously have this company behind these products",
    "start": "1360240",
    "end": "1365440"
  },
  {
    "text": "that are continually building and adding features and and watching these things grow in complexity and capability for you so you",
    "start": "1365440",
    "end": "1372960"
  },
  {
    "text": "know a couple of uh all of the logos that you see here on the bottom left are partners of ours uh many of them are here today this week",
    "start": "1372960",
    "end": "1379919"
  },
  {
    "text": "at the expo so i definitely encourage you to go and take a look at them for those not familiar with the little uh",
    "start": "1379919",
    "end": "1385840"
  },
  {
    "text": "beaver guy down there that's a log lease mascot and so again lots of pros here to sas",
    "start": "1385840",
    "end": "1392080"
  },
  {
    "text": "models and lightening any sort of operational burden from me yourself in terms of cons right pretty",
    "start": "1392080",
    "end": "1397760"
  },
  {
    "text": "straightforward understanding what sas models mean for you versus doing it yourself uh you know if you're super concerned about",
    "start": "1397760",
    "end": "1403600"
  },
  {
    "text": "your data right you want to work with these companies and understand how they're securing and storing your data for you um you know what kind of",
    "start": "1403600",
    "end": "1409919"
  },
  {
    "text": "controls are in place to protect your data in their environments and then obviously you're slightly restricted by",
    "start": "1409919",
    "end": "1416480"
  },
  {
    "text": "what these various sas based options might be able to do right",
    "start": "1416480",
    "end": "1421600"
  },
  {
    "text": "there's going to be restrictiveness in terms of how the agents work how you're getting the logs to them and then potentially",
    "start": "1421600",
    "end": "1427200"
  },
  {
    "text": "how you're actually analyzing the data viewing the data and so forth so again depending on what",
    "start": "1427200",
    "end": "1432320"
  },
  {
    "text": "kind of level of flexibility you're looking for in complexity you kind of have to make that decision",
    "start": "1432320",
    "end": "1437919"
  },
  {
    "text": "that said i'm a huge proponent of sas model type things i feel that if you are you",
    "start": "1437919",
    "end": "1443840"
  },
  {
    "text": "know a very small team that maybe doesn't have a ton of extra operations time or extra development",
    "start": "1443840",
    "end": "1448880"
  },
  {
    "text": "time right why spend the time to figure out how to do something like the elk stack or one of these other solutions",
    "start": "1448880",
    "end": "1454080"
  },
  {
    "text": "right just take it and outsource it and worry about bringing it back inside someday when you have more time more money whatever it might",
    "start": "1454080",
    "end": "1460240"
  },
  {
    "text": "be so that's the conceptual idea of centralizing the log data first",
    "start": "1460240",
    "end": "1465279"
  },
  {
    "text": "how about analyzing the data first so in this case we're not talking about doing super deep analysis it's mostly around",
    "start": "1465279",
    "end": "1471440"
  },
  {
    "text": "generating some data or metric collection about the log files and then taking those metrics and sending them to another place",
    "start": "1471440",
    "end": "1477760"
  },
  {
    "text": "you essentially still need a central point to go to uh whether it's it's a hosted one or it's local insider infrastructure so that's not going to",
    "start": "1477760",
    "end": "1484000"
  },
  {
    "text": "change and you still need some sort of agent process whatever it might be to look at your log data and generate",
    "start": "1484000",
    "end": "1490320"
  },
  {
    "text": "those metrics so we're going to talk about a couple of those options here now the first one is an amazon service so",
    "start": "1490320",
    "end": "1496080"
  },
  {
    "start": "1493000",
    "end": "1541000"
  },
  {
    "text": "this is a cloudwatch logs which we launched this past summer cloudwatch logs is a component of cloudwatch it's been",
    "start": "1496080",
    "end": "1502559"
  },
  {
    "text": "around for a very very long time and essentially you can use either an agent the cli or the sdk to take",
    "start": "1502559",
    "end": "1508240"
  },
  {
    "text": "logs from your hosts and applications send them up to cloudwatch and then be able to interact with them after that",
    "start": "1508240",
    "end": "1514640"
  },
  {
    "text": "you centralize those logs and you can go and view the raw logs yourself but more importantly the power of cloudwatch logs is that you can generate",
    "start": "1514640",
    "end": "1521200"
  },
  {
    "text": "metrics on the fly based on your log data send those metrics to cloudwatch and then you get all the nice capabilities",
    "start": "1521200",
    "end": "1526880"
  },
  {
    "text": "of cloudwatch in terms of generating alerts based on those metrics that can go to a number of places",
    "start": "1526880",
    "end": "1532400"
  },
  {
    "text": "being able to pull that metric out via you know the apis or sdks into other infrastructure components",
    "start": "1532400",
    "end": "1538799"
  },
  {
    "text": "monitoring whatever may have you really really straightforward and easy to get going with cloudwatch logs",
    "start": "1538799",
    "end": "1544799"
  },
  {
    "start": "1541000",
    "end": "1602000"
  },
  {
    "text": "this is an example on a linux system in this case an amazon linux system i install the aws logs package",
    "start": "1544799",
    "end": "1552240"
  },
  {
    "text": "after that i need to create a configuration file and essentially this these bottom seven lines here are the ones that i care about",
    "start": "1552240",
    "end": "1558320"
  },
  {
    "text": "uh in terms of wanting to follow the access log that's created by apache you can see there's a couple of",
    "start": "1558320",
    "end": "1563840"
  },
  {
    "text": "configuration parameters that i have to fill in and then over here on the far left uh your right in this case is the command",
    "start": "1563840",
    "end": "1570480"
  },
  {
    "text": "that i'm going to use to put a metric filter into cloudwatch and so what i'm doing here is i am defining a filter name",
    "start": "1570480",
    "end": "1576960"
  },
  {
    "text": "a filter pattern and then saying which part of that pattern i want to send up as a metric",
    "start": "1576960",
    "end": "1582400"
  },
  {
    "text": "in this case what i'm looking for is the metric request time so that is the request time",
    "start": "1582400",
    "end": "1588320"
  },
  {
    "text": "that i added into my apache log file before when i added in the percent capital d so again we want to",
    "start": "1588320",
    "end": "1594400"
  },
  {
    "text": "worry about the data that's important to us and you know act on that analyze that graph that whatever it might be",
    "start": "1594400",
    "end": "1602000"
  },
  {
    "text": "this is the result that you would see in the console if you want to look at this log data once it's been centralized",
    "start": "1602000",
    "end": "1607200"
  },
  {
    "text": "what i've done here is kind of highlighted that value over there on the far right of what i care about in terms of what",
    "start": "1607200",
    "end": "1613039"
  },
  {
    "text": "i'm looking to analyze down at the bottom here you can see the metric that's generated by this i you know i was doing this on my own",
    "start": "1613039",
    "end": "1618960"
  },
  {
    "text": "test server it wasn't serving anything really interesting or exciting so there's actually not too much variation here in request time if you",
    "start": "1618960",
    "end": "1625200"
  },
  {
    "text": "look at the actual values but again super powerful all right i could very easily now add",
    "start": "1625200",
    "end": "1630799"
  },
  {
    "text": "some sort of a alarm on top of this if i want to say you know don't allow the site to get above a certain point i can use this metric to do things such",
    "start": "1630799",
    "end": "1637520"
  },
  {
    "text": "as trigger auto scaling lots of capabilities once this data exists inside of cloudwatch for me",
    "start": "1637520",
    "end": "1642960"
  },
  {
    "text": "and again very very easy to set up in windows it's actually even easier",
    "start": "1642960",
    "end": "1648159"
  },
  {
    "start": "1646000",
    "end": "1658000"
  },
  {
    "text": "on a windows ami once fired up you go and load the ec2 service properties tool",
    "start": "1648159",
    "end": "1654159"
  },
  {
    "text": "click over on this checkbox here for enabling cloudwatch logs then there is this wonderful json file",
    "start": "1654159",
    "end": "1659840"
  },
  {
    "start": "1658000",
    "end": "1670000"
  },
  {
    "text": "that you can edit to say which logs you want to tail on the system and then again in cloudwatch you can set that metric",
    "start": "1659840",
    "end": "1666240"
  },
  {
    "text": "and get the graphs that we saw on the previous slide so that's cloudwatch logs the next one",
    "start": "1666240",
    "end": "1672480"
  },
  {
    "start": "1670000",
    "end": "1776000"
  },
  {
    "text": "up is something that's near and dear to me i used to work at etsy previous to working at amazon a",
    "start": "1672480",
    "end": "1678559"
  },
  {
    "text": "pretty popular website based in new york city and they released an open source tool called logster a number of years",
    "start": "1678559",
    "end": "1683840"
  },
  {
    "text": "back and essentially lobster allows you to generate metrics from log files and kind of like the cloudwatch logs",
    "start": "1683840",
    "end": "1689760"
  },
  {
    "text": "agent allows you to take those metrics and send them someplace so that could be some place like gangly",
    "start": "1689760",
    "end": "1695200"
  },
  {
    "text": "or graphite or actually even cloudwatch so you could use this on-prem in your own data center and send this data up to",
    "start": "1695200",
    "end": "1701760"
  },
  {
    "text": "cloudwatch very very easily typically though it runs via acron as opposed to running as a daemonized agent like the",
    "start": "1701760",
    "end": "1707840"
  },
  {
    "text": "cloudwatch logs agent does so you have to set up a cron entry pretty straightforward and then it also depends on the log tail",
    "start": "1707840",
    "end": "1714480"
  },
  {
    "text": "package which you'll find on almost any linux distribution today so what it's going to do is it's going to",
    "start": "1714480",
    "end": "1719679"
  },
  {
    "text": "periodically again via that cron job tell my log file it keeps a marker on where it left off from the previous",
    "start": "1719679",
    "end": "1725520"
  },
  {
    "text": "iteration and that allows me to generate statistics about my my log data in this case and then again send that",
    "start": "1725520",
    "end": "1733520"
  },
  {
    "text": "generated metric off to whatever destination is that i'm looking to send it to in this case i'm doing an example of",
    "start": "1733520",
    "end": "1738880"
  },
  {
    "text": "sending the output to ganglia which is a graphing tool that's very popular in the monterey metrics worlds",
    "start": "1738880",
    "end": "1744799"
  },
  {
    "text": "and what you can see down below is the example of the geometric command which is what you use to send data to ganglia and",
    "start": "1744799",
    "end": "1751360"
  },
  {
    "text": "it's kind of difficult to tell here but in the very bottom right hand corner is that 0.5 33333 kind of repeating metric",
    "start": "1751360",
    "end": "1758320"
  },
  {
    "text": "that is uh the requests per second that i'm getting to this server again this is not a high traffic server",
    "start": "1758320",
    "end": "1764159"
  },
  {
    "text": "so half a request per second not very much interesting going on here but again really really straightforward",
    "start": "1764159",
    "end": "1769760"
  },
  {
    "text": "to use very easy to install very easy to generate these metrics from your log files",
    "start": "1769760",
    "end": "1776480"
  },
  {
    "start": "1776000",
    "end": "1887000"
  },
  {
    "text": "going back to log stash here again log stash is really really powerful tool it's very multifaceted you can actually also generate metric",
    "start": "1776480",
    "end": "1782880"
  },
  {
    "text": "data from logstash running on your actual end instance um you can do this both here on your you",
    "start": "1782880",
    "end": "1789120"
  },
  {
    "text": "know every server in your infrastructure you could also do it on those centralized connect collection nodes that are passing the data back into",
    "start": "1789120",
    "end": "1794880"
  },
  {
    "text": "elasticsearch and so again it can process logs on the fly based on tailing log files that are",
    "start": "1794880",
    "end": "1801360"
  },
  {
    "text": "being created on your your host and it has again such a huge huge huge collection of outputs that i",
    "start": "1801360",
    "end": "1807840"
  },
  {
    "text": "can send it to here we're seeing just a brief example so again cloudwatch ganglia graphite via the statsd plugin",
    "start": "1807840",
    "end": "1814799"
  },
  {
    "text": "third-party tools like boundary and datadog many many others that exist out there that you can send this metric data to",
    "start": "1814799",
    "end": "1820799"
  },
  {
    "text": "that uh logstash has plugins again from many of these different third-party companies logstash runs as a constantly running",
    "start": "1820799",
    "end": "1826960"
  },
  {
    "text": "process so it's not the kind of thing that has to wake up as part of a cron job and then again a little bit",
    "start": "1826960",
    "end": "1833840"
  },
  {
    "text": "easier than logster you can see over here on the far right an example of a configuration that i would need in order to generate this",
    "start": "1833840",
    "end": "1839520"
  },
  {
    "text": "data basically filter it essentially match it against a pattern and then take a value that i care about",
    "start": "1839520",
    "end": "1846000"
  },
  {
    "text": "from that pattern and send it off to statsd so very very straightforward kind",
    "start": "1846000",
    "end": "1852399"
  },
  {
    "text": "of configuration to do this and again this configuration here could live as part of your larger configuration for centralizing your logs",
    "start": "1852399",
    "end": "1859200"
  },
  {
    "text": "at the same time so logstash could both generate metrics and centralize logs all at the same time part of the same",
    "start": "1859200",
    "end": "1865039"
  },
  {
    "text": "process very very straightforward so we've seen kind of the two options",
    "start": "1865039",
    "end": "1870159"
  },
  {
    "text": "here for getting this data off of our host again we can either centralize the raw log data analyze it later",
    "start": "1870159",
    "end": "1875279"
  },
  {
    "text": "we could or do the other option which is get metrics that we care about from our log data centralize that to another location so",
    "start": "1875279",
    "end": "1882559"
  },
  {
    "text": "once we've done that the next thing that we'd want to do is analyze that data which usually happens in the form of",
    "start": "1882559",
    "end": "1888080"
  },
  {
    "text": "dashboards for those who don't know the historical context behind the word dashboard essentially you can see it",
    "start": "1888080",
    "end": "1894000"
  },
  {
    "text": "highlighted here in this carriage dashboard was used to protect you from having mud flinged on you by horses when",
    "start": "1894000",
    "end": "1900720"
  },
  {
    "text": "they were to dash i learned this recently from the history channel good stuff so essentially that was the original",
    "start": "1900720",
    "end": "1906799"
  },
  {
    "text": "context of it as cars came about became the place where gauges sat on and nowadays all of us in the it world",
    "start": "1906799",
    "end": "1912720"
  },
  {
    "text": "have taken this to me in a place where we look at pretty lines and graphs and things like that so",
    "start": "1912720",
    "end": "1918159"
  },
  {
    "start": "1918000",
    "end": "2011000"
  },
  {
    "text": "some tips on dashboarding this is another topic very near and dear to me that i could spend a whole lot of time on you want to make all the metrics",
    "start": "1918159",
    "end": "1924240"
  },
  {
    "text": "available that you possibly can for inside of your organization you know enable as much cross-team metric collection as possible",
    "start": "1924240",
    "end": "1930399"
  },
  {
    "text": "you'd be surprised at what one team looking at a graph might pull out of it from another team all based on the same graph sometimes",
    "start": "1930399",
    "end": "1937120"
  },
  {
    "text": "focus your your main landing or you know dashboards you have up on tvs in your office on metrics that are",
    "start": "1937120",
    "end": "1942720"
  },
  {
    "text": "really important to the business or your end users first that's something that i don't see a lot of people doing",
    "start": "1942720",
    "end": "1948480"
  },
  {
    "text": "these days i see things like ram utilization on a big tv in someone's office and i say how many of you stop and look at ram",
    "start": "1948480",
    "end": "1954640"
  },
  {
    "text": "utilization in a day and draw something useful out of a metric like that right nowhere near as important as things like",
    "start": "1954640",
    "end": "1960640"
  },
  {
    "text": "checkouts logins login failures other sorts of useful user actions that you might have",
    "start": "1960640",
    "end": "1967120"
  },
  {
    "text": "another one is uh and lastly again you'll find a way to highlight organizational events and changes",
    "start": "1967120",
    "end": "1973440"
  },
  {
    "text": "inside of your infrastructure so if you have deployments configuration changes",
    "start": "1973440",
    "end": "1978720"
  },
  {
    "text": "potential outages anything that might happen find a way to put that up on that dashboard you'll see very commonly people draw a vertical",
    "start": "1978720",
    "end": "1985039"
  },
  {
    "text": "line and correlate that vertical line in the graph with some sort of action and many different graphing and monitoring tools allow you to do that",
    "start": "1985039",
    "end": "1992720"
  },
  {
    "text": "so again talking about metrics that matter we have two examples here from cloudwatch the top one is cpu",
    "start": "1992720",
    "end": "1999200"
  },
  {
    "text": "utilization from an individual host the bottom one is latency from an elastic load balancer",
    "start": "1999200",
    "end": "2005200"
  },
  {
    "text": "now ask yourself which one of these is going to be more important to you if you said the elastic load balancer",
    "start": "2005200",
    "end": "2011120"
  },
  {
    "start": "2011000",
    "end": "2038000"
  },
  {
    "text": "latency that's correct right this is something that's correlating directly to what your users are experiencing",
    "start": "2011120",
    "end": "2017440"
  },
  {
    "text": "you could run web servers at 100 cpu 24 7 and if the latency of your page request",
    "start": "2017440",
    "end": "2023760"
  },
  {
    "text": "time is low enough who cares but if your page latency is very high",
    "start": "2023760",
    "end": "2029360"
  },
  {
    "text": "and your cpu load is very low right again you want to be paying attention to those metrics that are actually",
    "start": "2029360",
    "end": "2034480"
  },
  {
    "text": "impacting the business and impacting your users so a number of different dashboards out there again going back to splunk really",
    "start": "2034480",
    "end": "2040799"
  },
  {
    "start": "2038000",
    "end": "2106000"
  },
  {
    "text": "awesome product that we heard a little bit more about today splunk has very very powerful web interface",
    "start": "2040799",
    "end": "2046640"
  },
  {
    "text": "that has a very very complex and powerful query and filter syntax for looking at",
    "start": "2046640",
    "end": "2052240"
  },
  {
    "text": "log data and correlating it doing all sorts of good stuff has a number of really cool visualization plugins uh one of my",
    "start": "2052240",
    "end": "2057839"
  },
  {
    "text": "favorite ones is that it puts up a map it can show you where requests are coming from on that map in your real time that's",
    "start": "2057839",
    "end": "2064320"
  },
  {
    "text": "pretty fun and then a number of third-party apps that you can drop and plug into that that interface to do all",
    "start": "2064320",
    "end": "2070320"
  },
  {
    "text": "sorts of other you know visualizations and understanding of your data we have an app for splunk that pulls in",
    "start": "2070320",
    "end": "2075760"
  },
  {
    "text": "things like cloudtrail data so that's extremely useful and then the",
    "start": "2075760",
    "end": "2080960"
  },
  {
    "text": "other great thing about it is that you can actually it actually exposes an api so many companies have written their own dashboards using their own dashboard",
    "start": "2080960",
    "end": "2087358"
  },
  {
    "text": "tools using the data from spelunk and then portraying that into that dashboard this can be really useful if you have",
    "start": "2087359",
    "end": "2093280"
  },
  {
    "text": "many different places that you're collecting data from you're not going to have to go back and look at one dashboard look at the other",
    "start": "2093280",
    "end": "2098800"
  },
  {
    "text": "dashboard look at the other one you can kind of suck all of this stuff in together so that's pretty nice and again it scales really really well",
    "start": "2098800",
    "end": "2105920"
  },
  {
    "text": "so just a quick screenshot of the splunk web interface uh pretty straightforward here i have and sorry if",
    "start": "2105920",
    "end": "2112560"
  },
  {
    "start": "2106000",
    "end": "2142000"
  },
  {
    "text": "it's a little difficult to see in the back i'm saying which file i want to have my source and then i'm looking for 400 messages in it now i'm not",
    "start": "2112560",
    "end": "2119520"
  },
  {
    "text": "specifying where in the log file there's going to be a 400 i could have actually filtered this down based on a certain field",
    "start": "2119520",
    "end": "2125520"
  },
  {
    "text": "but in this case a very generic search of show me anything this log file that matches a 400 so again my",
    "start": "2125520",
    "end": "2132400"
  },
  {
    "text": "not very exciting personal website it doesn't generate a whole lot of log information nor does it generate a whole lot of 400s",
    "start": "2132400",
    "end": "2139040"
  },
  {
    "text": "but you can see a couple of that happened here next up is kibana this is the k in the",
    "start": "2139040",
    "end": "2144960"
  },
  {
    "start": "2142000",
    "end": "2241000"
  },
  {
    "text": "elk stack uh with e being elasticsearch which we're not going to talk too much about here today uh cabana was an open source project",
    "start": "2144960",
    "end": "2152320"
  },
  {
    "text": "that the main developer on it actually joined elasticsearch sometime in the last 12 months maybe a little bit longer same thing actually",
    "start": "2152320",
    "end": "2158960"
  },
  {
    "text": "goes for the original developer of logsdash so it's actually pretty cool you had three open source projects",
    "start": "2158960",
    "end": "2164240"
  },
  {
    "text": "one that became a commercial entity which was elasticsearch which then brought in the other two people that had kind of",
    "start": "2164240",
    "end": "2170560"
  },
  {
    "text": "put together this trifecta of application stack which is now called the elk stack",
    "start": "2170560",
    "end": "2176720"
  },
  {
    "text": "so cabana really really powerful open source dashboarding tool for log stash and elasticsearch",
    "start": "2176720",
    "end": "2181920"
  },
  {
    "text": "again it integrates with elasticsearch as the back end that's going to pull data from lots of great search filters and",
    "start": "2181920",
    "end": "2188160"
  },
  {
    "text": "features also great visualizations very customizable right it's an open source tool you can go in there",
    "start": "2188160",
    "end": "2194079"
  },
  {
    "text": "play with the code make it work exactly the way that you want to or customize the way that you want to and the other thing is that it can also",
    "start": "2194079",
    "end": "2199680"
  },
  {
    "text": "read data from other centralizing tools such as flume or fluent date so kibana here's an example of a",
    "start": "2199680",
    "end": "2206320"
  },
  {
    "text": "dashboard again what i have here is a histogram showing the requests over a period of time",
    "start": "2206320",
    "end": "2213040"
  },
  {
    "text": "then down below you can see a couple of other dashboard components i have the http method used",
    "start": "2213040",
    "end": "2219359"
  },
  {
    "text": "again unfortunately for me not too exciting of data the user agents and then the response code that my very",
    "start": "2219359",
    "end": "2226240"
  },
  {
    "text": "exciting personal web page is generating um but what was really great is that again you can",
    "start": "2226240",
    "end": "2231760"
  },
  {
    "text": "drag and drop just play with this customize it the kind of thing you could throw up on a tv in your office or somewhere",
    "start": "2231760",
    "end": "2237359"
  },
  {
    "text": "and be able to see again a whole lot of data in one place both of these examples in this case both",
    "start": "2237359",
    "end": "2242480"
  },
  {
    "start": "2241000",
    "end": "2545000"
  },
  {
    "text": "splunk and cabana with the oak stack you know i took the time to set them up here",
    "start": "2242480",
    "end": "2247920"
  },
  {
    "text": "both of the examples individually took less than an hour right this is really straightforward to go through their how-to and set up guides",
    "start": "2247920",
    "end": "2254480"
  },
  {
    "text": "follow through and be able to do this so again neither of these are so complex that it should take",
    "start": "2254480",
    "end": "2260240"
  },
  {
    "text": "weeks of time this is the kind of thing that you could spend part of an afternoon getting started with and of course obviously iterate over time with it",
    "start": "2260240",
    "end": "2268400"
  },
  {
    "text": "so we've gone through the first three steps of our four-ish steps to web operational log analysis greatness uh",
    "start": "2268400",
    "end": "2274160"
  },
  {
    "text": "generate useful log information right let's let's make sure that our logs have some sort of value to us get that data off of our web instance",
    "start": "2274160",
    "end": "2280640"
  },
  {
    "text": "right get it to the centralized place that we're going to hopefully redundantly store that log data analyze that data",
    "start": "2280640",
    "end": "2286720"
  },
  {
    "text": "in this case we're talking about manual analyzing tools here and then now the fourth step is to",
    "start": "2286720",
    "end": "2291920"
  },
  {
    "text": "actually do something further acting on that data right so alarm and act on that data",
    "start": "2291920",
    "end": "2298000"
  },
  {
    "text": "or trend it or do something useful here and actually this is the part of the talk that i while working on these slides felt that",
    "start": "2298000",
    "end": "2304320"
  },
  {
    "text": "i couldn't go anywhere near into as much depth as i wanted to when you talk about things like dashboards they're a very",
    "start": "2304320",
    "end": "2310960"
  },
  {
    "text": "you know manual human aspect to looking at those and surprisingly enough us humans and our eyes and our brains",
    "start": "2310960",
    "end": "2317440"
  },
  {
    "text": "are really really poor at doing log analysis you really want to have something that is automated that is looking through these",
    "start": "2317440",
    "end": "2323920"
  },
  {
    "text": "things that is grepping looking for patterns looking for out you know outline data",
    "start": "2323920",
    "end": "2329200"
  },
  {
    "text": "that doesn't make sense and so that's the kind of thing that you really want to rely on other tools for",
    "start": "2329200",
    "end": "2334560"
  },
  {
    "text": "splunk and a number of other tools allow you to do things such as find you know confidence bands predictive analysis there's a number of",
    "start": "2334560",
    "end": "2341280"
  },
  {
    "text": "third-party open source tools that exist out there today that can do these things as well right you know being able to say okay",
    "start": "2341280",
    "end": "2347040"
  },
  {
    "text": "there's a spike in this graph does it something that i care about or something that i don't in a large environment where you might",
    "start": "2347040",
    "end": "2352079"
  },
  {
    "text": "have hundreds of data points to look at it's difficult to say well if i'm looking at a 24-hour window how does",
    "start": "2352079",
    "end": "2357520"
  },
  {
    "text": "that correlate to a seven-day window a 30-day window and being able to say okay this is something that's a problem this is",
    "start": "2357520",
    "end": "2363359"
  },
  {
    "text": "something that i should alarm on so essentially you know again it's very difficult i feel that alarms are a bit",
    "start": "2363359",
    "end": "2369280"
  },
  {
    "text": "of an art first and then a science kind of second and essentially the whole purpose of collecting this data in an operational",
    "start": "2369280",
    "end": "2374880"
  },
  {
    "text": "sense to have a deeper understanding of what's going on infrastructure being able to react to it so when it",
    "start": "2374880",
    "end": "2380480"
  },
  {
    "text": "comes to reacting to information in your logs again you want to follow the same kind of patterns that you would for looking at dashboards",
    "start": "2380480",
    "end": "2387040"
  },
  {
    "text": "what aspect of these logs is important to my end users primarily and then to me as an operational organization secondly",
    "start": "2387040",
    "end": "2393520"
  },
  {
    "text": "so first you know basic things is the site up are my servers up or things responding the way that they should be",
    "start": "2393520",
    "end": "2398960"
  },
  {
    "text": "is the site slow are page response times higher than they were previously and again determining what",
    "start": "2398960",
    "end": "2404400"
  },
  {
    "text": "slow means for you is obviously very much an individual type of a thing are certain user actions failing more",
    "start": "2404400",
    "end": "2409920"
  },
  {
    "text": "than others right are people getting through the site searching picking a product but then checkout is failing right",
    "start": "2409920",
    "end": "2415440"
  },
  {
    "text": "that's the kind of thing you would want to know about very very quickly and log data is kind of one of the best places to know about that",
    "start": "2415440",
    "end": "2420960"
  },
  {
    "text": "and then again it's something like checkout much slower than it should be does it normally take you know 200 milliseconds and right now",
    "start": "2420960",
    "end": "2427040"
  },
  {
    "text": "it's taking four seconds right what could be causing that again log data one of the best places that you could get that information about so after you",
    "start": "2427040",
    "end": "2433359"
  },
  {
    "text": "focus on what's important to your customers then it makes sense to do alarm alarming and alerting on data that is more",
    "start": "2433359",
    "end": "2440160"
  },
  {
    "text": "kind of infrastructure operational so things like filling disks on databases uh other",
    "start": "2440160",
    "end": "2445760"
  },
  {
    "text": "technical capability sorry limits capacity limits that something like auto scaling can't get away from",
    "start": "2445760",
    "end": "2451520"
  },
  {
    "text": "you know our internal services down or slow for instance you know paying attention to log data",
    "start": "2451520",
    "end": "2457520"
  },
  {
    "text": "that tells you again that the site is down or that things are taking a very long time to to run it matters a lot more than",
    "start": "2457520",
    "end": "2464079"
  },
  {
    "text": "potentially say alerting on something from some sort of internal daemons process that doesn't affect your end users",
    "start": "2464079",
    "end": "2471440"
  },
  {
    "text": "when it comes to actually doing something again in terms of reacting on the log data that you have it's going to be very much dependent on what tool",
    "start": "2471440",
    "end": "2477440"
  },
  {
    "text": "you're using to collect and analyze that log data cloudwatch has built in a whole bunch of ways that i can reach out to you via sns",
    "start": "2477440",
    "end": "2483680"
  },
  {
    "text": "simple notification service so that could be cloudwatch again sorry that could be https email",
    "start": "2483680",
    "end": "2489920"
  },
  {
    "text": "amazon what does that should be sms is or amazon sqs logstash has integration",
    "start": "2489920",
    "end": "2496480"
  },
  {
    "text": "with things like nagios also sms email a bunch of third-party tools same thing with splunk lots of plugins",
    "start": "2496480",
    "end": "2503760"
  },
  {
    "text": "for email nagios third-party tools and then lastly if you go with a sas option you see a lot of integration",
    "start": "2503760",
    "end": "2508960"
  },
  {
    "text": "today also with these things down at the bottom three really awesome tools for handling things such as",
    "start": "2508960",
    "end": "2514640"
  },
  {
    "text": "getting messages out to your team if you have an operational team and you rotate the pager and who has it page",
    "start": "2514640",
    "end": "2521200"
  },
  {
    "text": "duty ops genie victor ops can all help you do that kind of operational rotation and escalations and responding to",
    "start": "2521200",
    "end": "2527920"
  },
  {
    "text": "incidents and stuff like that so we've gone through our four-ish steps again",
    "start": "2527920",
    "end": "2533040"
  },
  {
    "text": "all of which are represented by many sub steps but there's actually kind of a fifth point",
    "start": "2533040",
    "end": "2538160"
  },
  {
    "text": "that comes after the fact of all of the kind of useful operational things that we would do with our log data",
    "start": "2538160",
    "end": "2544480"
  },
  {
    "text": "the first part of that is log backup and archiving and this is what i always like to say to some to a company when we talk about",
    "start": "2544480",
    "end": "2550319"
  },
  {
    "start": "2545000",
    "end": "2631000"
  },
  {
    "text": "this is you know we're just going to delete the logs after a couple days right if you have a two week window that you've been storing",
    "start": "2550319",
    "end": "2555839"
  },
  {
    "text": "data for you're not just going to toss that away on that 15th day and there's lots of reasons why you wouldn't want to do that for many",
    "start": "2555839",
    "end": "2561839"
  },
  {
    "text": "companies today across many sectors there's regulatory needs to keep log data of varying different aspects about your",
    "start": "2561839",
    "end": "2567599"
  },
  {
    "text": "end users sometimes it can be very useful to keep logs for long-term trending and analysis potential product",
    "start": "2567599",
    "end": "2574160"
  },
  {
    "text": "uses so i've seen recommendations generated by logs i've seen features that we go and look",
    "start": "2574160",
    "end": "2579200"
  },
  {
    "text": "at things like a b testing based on log data and the lastly things like security reviews right you have the ability to go",
    "start": "2579200",
    "end": "2584800"
  },
  {
    "text": "back and look at people that might have been doing attacks against your web server a month ago versus today how has that",
    "start": "2584800",
    "end": "2589839"
  },
  {
    "text": "changed and so forth log back up in archive i actually think this is a very easy thing to do properly",
    "start": "2589839",
    "end": "2596240"
  },
  {
    "text": "again many of the tools that we talked about today have the ability for you to dump your data up into s3 logstash can dump into s3 sas options",
    "start": "2596240",
    "end": "2604160"
  },
  {
    "text": "like log lean paper trail allow you to toss things up into s3 and then splunk which i don't believe",
    "start": "2604160",
    "end": "2609920"
  },
  {
    "text": "has the capability to do this though if you're storing your data on ebs you can always make snapshots keep those snapshots for some period of time",
    "start": "2609920",
    "end": "2616480"
  },
  {
    "text": "so once you get the data into s3 for long long-term storage again if regulatory needs tell you need to keep log data for potentially up to 10",
    "start": "2616480",
    "end": "2622880"
  },
  {
    "text": "years you're going to want to get that data into something like glacier and so that might sound hard but it's",
    "start": "2622880",
    "end": "2627920"
  },
  {
    "text": "actually really really easy so if we take the example of using cloud formation to do this cloud formation",
    "start": "2627920",
    "end": "2633280"
  },
  {
    "text": "another aws service that i really love and try to use as often as possible we can see here is an example of a",
    "start": "2633280",
    "end": "2640000"
  },
  {
    "text": "couple of lines in cloud formation how to split it across two windows here but essentially i'm defining an s3",
    "start": "2640000",
    "end": "2645680"
  },
  {
    "text": "bucket that s3 bucket has a life cycle configuration where i'm specifying that data that is",
    "start": "2645680",
    "end": "2652720"
  },
  {
    "text": "in this bucket prefixed by the word logs after 30 days will get rotated to glacier",
    "start": "2652720",
    "end": "2658800"
  },
  {
    "text": "and then we'll be kept there for 365 days and i had to do nothing more to enable that or to work with that than to",
    "start": "2658800",
    "end": "2664720"
  },
  {
    "text": "have this set in the definition of this resource and cloud formation",
    "start": "2664720",
    "end": "2670160"
  },
  {
    "text": "another thing that's really important in terms of logs that we're going to cover today is security of logs again because this represents such",
    "start": "2670160",
    "end": "2675599"
  },
  {
    "start": "2671000",
    "end": "2745000"
  },
  {
    "text": "important information to your website or to your application securing it is a really really important thing to do so obviously restrict access",
    "start": "2675599",
    "end": "2682720"
  },
  {
    "text": "to the raw log data to where it's being stored to where it's being backed up security groups network acls local",
    "start": "2682720",
    "end": "2689200"
  },
  {
    "text": "access restrictions on your hosts right you wouldn't want someone modifying your security logs to clear their tracks of what they're",
    "start": "2689200",
    "end": "2695440"
  },
  {
    "text": "doing that might be nefarious on your systems you know protract protect and track any",
    "start": "2695440",
    "end": "2701280"
  },
  {
    "text": "sort of changes to those logs right things like md5 sums controlling an iem who has access to these s3 buckets",
    "start": "2701280",
    "end": "2707599"
  },
  {
    "text": "uh ebs snapshots or whatever it might be and then another really great trick with log data because of its importance",
    "start": "2707599",
    "end": "2713280"
  },
  {
    "text": "is actually ship it to an s3 bucket that is owned by a different account than your primary account",
    "start": "2713280",
    "end": "2719040"
  },
  {
    "text": "which you can do these days with cross account sharing of s3 data and then enable mfa delete and",
    "start": "2719040",
    "end": "2724079"
  },
  {
    "text": "versioning on that data what this does essentially is make it very difficult for anyone to get access to this bucket",
    "start": "2724079",
    "end": "2730079"
  },
  {
    "text": "and potentially delete the data again without an mfa token and then take that mfa token that you've",
    "start": "2730079",
    "end": "2735119"
  },
  {
    "text": "used and put it in a bank safe or something like that right make it so that it's very very difficult for anyone",
    "start": "2735119",
    "end": "2740160"
  },
  {
    "text": "to ever get access to your account and then potentially delete this very important data",
    "start": "2740160",
    "end": "2745599"
  },
  {
    "start": "2745000",
    "end": "2795000"
  },
  {
    "text": "uh and then lastly really automation of logs right you don't want to be going in and configuring",
    "start": "2745599",
    "end": "2750880"
  },
  {
    "text": "log stash in every host by hand that's just not going to scale well use you know configuration management",
    "start": "2750880",
    "end": "2756400"
  },
  {
    "text": "tools chef puppet ansible salt whatever you might have cloud formation obviously with metadata",
    "start": "2756400",
    "end": "2761440"
  },
  {
    "text": "and user data you can also set this up when your instances start and i what i always like to do is have some basic level of log centralization",
    "start": "2761440",
    "end": "2768400"
  },
  {
    "text": "or metric collection built into every ami that i have all right if i have some sort of higher level process",
    "start": "2768400",
    "end": "2773680"
  },
  {
    "text": "like a chef or a puppet that's going to be taking my log or configuring some aspect of my host",
    "start": "2773680",
    "end": "2779200"
  },
  {
    "text": "later on but that has the potential to fail then i want to make sure that my host as soon as it starts still capable of sending me",
    "start": "2779200",
    "end": "2785440"
  },
  {
    "text": "the logs that would be generated by those processes so again have that base ami have something",
    "start": "2785440",
    "end": "2790560"
  },
  {
    "text": "that's in place already to send those logs so we've covered quite a bit here today my",
    "start": "2790560",
    "end": "2796319"
  },
  {
    "start": "2795000",
    "end": "2849000"
  },
  {
    "text": "my four-ish steps that you could follow to doing log operational analysis in the case of web logs or other logs",
    "start": "2796319",
    "end": "2802560"
  },
  {
    "text": "again with that kind of asterisk fifth bullet point down here of backup and archive security and automation again pay",
    "start": "2802560",
    "end": "2808880"
  },
  {
    "text": "attention to the data that you're generating for your applications and web servers make sure that it's pertinent and important to you",
    "start": "2808880",
    "end": "2814160"
  },
  {
    "text": "right cut out the credit that doesn't matter add in the aspects that do get that data off of your web instance",
    "start": "2814160",
    "end": "2819280"
  },
  {
    "text": "as quickly as possible right get it someplace where you're going to be able to later analyze it in an effective way without",
    "start": "2819280",
    "end": "2825119"
  },
  {
    "text": "potential for loss then analyze that data right figure out what metrics matter to you take those",
    "start": "2825119",
    "end": "2830319"
  },
  {
    "text": "metrics put them into some sort of a dashboard or some sort of a tool where you can track them trend them and then eventually potentially alert or",
    "start": "2830319",
    "end": "2836560"
  },
  {
    "text": "alarm on them and have better understanding so in closing again",
    "start": "2836560",
    "end": "2841839"
  },
  {
    "text": "logs are super super important i find that logs are fun look at this guy here he's having a ball",
    "start": "2841839",
    "end": "2847280"
  },
  {
    "text": "right now dealing with logs and again spend the time to do log analysis right it's super super valuable",
    "start": "2847280",
    "end": "2852880"
  },
  {
    "start": "2849000",
    "end": "2870000"
  },
  {
    "text": "to an organization these days a critical part of how your infrastructure is working behaving",
    "start": "2852880",
    "end": "2858079"
  },
  {
    "text": "how your users are interfacing with your services and if you're doing nothing with this data you're really losing a whole lot of",
    "start": "2858079",
    "end": "2863599"
  },
  {
    "text": "value again here kind of the five points a little over my time here you know again",
    "start": "2863599",
    "end": "2869760"
  },
  {
    "text": "unfortunately i'm not gonna be able to take questions right after this session you can email me my last name munz",
    "start": "2869760",
    "end": "2875040"
  },
  {
    "start": "2870000",
    "end": "2879000"
  },
  {
    "text": "amazon.com and i'm happy to have further conversations with you i really do appreciate any feedback that you can",
    "start": "2875040",
    "end": "2880400"
  },
  {
    "start": "2879000",
    "end": "2896000"
  },
  {
    "text": "offer up on this session to help me understand what you liked what you didn't like what you'd like to hear more about",
    "start": "2880400",
    "end": "2885680"
  },
  {
    "text": "and with that thank you again for joining us here at re invent this year and have a good rest of your week",
    "start": "2885680",
    "end": "2898400"
  }
]
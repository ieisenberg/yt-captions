[
  {
    "start": "0",
    "end": "47000"
  },
  {
    "text": "all right folks can you all hear me awesome okay",
    "start": "880",
    "end": "6160"
  },
  {
    "text": "thank you very much for coming out today we really appreciate y'all's attendance and your time um we're here at reinvent to do this for",
    "start": "6160",
    "end": "12400"
  },
  {
    "text": "you so i hope you take something out of it my name is ben clay i'm a developer with amazon dynamodb and today with brett",
    "start": "12400",
    "end": "19760"
  },
  {
    "text": "mccleary from precision exams i'm going to be talking about building high scale high performance applications on top of",
    "start": "19760",
    "end": "26240"
  },
  {
    "text": "dynamodb in the first half of this talk i'll give a series of best practices towards",
    "start": "26240",
    "end": "31760"
  },
  {
    "text": "building scalable data models on top of dynamodb in the second half i'll hand over to",
    "start": "31760",
    "end": "36800"
  },
  {
    "text": "brett mccleary with precision exams and he'll talk about how his organization is architected on top of dynamodb and in",
    "start": "36800",
    "end": "43440"
  },
  {
    "text": "particular how they've done load and performance testing so the outline for my half of the talk",
    "start": "43440",
    "end": "49760"
  },
  {
    "start": "47000",
    "end": "86000"
  },
  {
    "text": "is as follows first i'll give a short background on why we built dynamodb what it is",
    "start": "49760",
    "end": "55120"
  },
  {
    "text": "then i'll give a little primer on how we scale under the covers because it's very important to understand what we're doing",
    "start": "55120",
    "end": "60320"
  },
  {
    "text": "with your data as we scale you so that you can take advantage of our capabilities",
    "start": "60320",
    "end": "66240"
  },
  {
    "text": "then i'll go into sources of application latency what is standing between your application when you're making requests",
    "start": "66240",
    "end": "72240"
  },
  {
    "text": "to dynamodb and your data as it lives in dynamodb then i'll go into these best practices",
    "start": "72240",
    "end": "78400"
  },
  {
    "text": "talking about how you can design your data model and your access patterns to get the most out of us and",
    "start": "78400",
    "end": "83920"
  },
  {
    "text": "then i'll hand over to brett so first real quick why did we build",
    "start": "83920",
    "end": "89280"
  },
  {
    "start": "86000",
    "end": "135000"
  },
  {
    "text": "dynamodb when we started to design dynamodb we went to our customers we saw a need in the market but we surveyed our",
    "start": "89280",
    "end": "95600"
  },
  {
    "text": "customers to see what they were really looking for in a next generation nosql database",
    "start": "95600",
    "end": "101360"
  },
  {
    "text": "they really want a reliably low latency at any scale this is typically an area that relational databases fall over with",
    "start": "101360",
    "end": "107840"
  },
  {
    "text": "as you scale them out horizontally latency takes a hit they also wanted elastic throughput and",
    "start": "107840",
    "end": "113200"
  },
  {
    "text": "storage they wanted to be able to scale these two factors independently dial them up and down as their business needs",
    "start": "113200",
    "end": "119439"
  },
  {
    "text": "changed they wanted flexible queries flexible data models strong consistency and above",
    "start": "119439",
    "end": "125360"
  },
  {
    "text": "all they wanted really good availability and fault tolerance because this is a database product and not only would they",
    "start": "125360",
    "end": "130720"
  },
  {
    "text": "store their data in it but they want to store their own customers data in it this is very important so in response we built and have",
    "start": "130720",
    "end": "137280"
  },
  {
    "start": "135000",
    "end": "165000"
  },
  {
    "text": "iterated upon dynamodb it's a fully managed nosql database service it",
    "start": "137280",
    "end": "142480"
  },
  {
    "text": "consistently gives single-digit millisecond latency it scales in throughput and storage",
    "start": "142480",
    "end": "147920"
  },
  {
    "text": "independently i'll talk about that a little bit more in a minute as of october of this year it suppose",
    "start": "147920",
    "end": "153120"
  },
  {
    "text": "supports both document and key key value data models and it uses automatic data",
    "start": "153120",
    "end": "158480"
  },
  {
    "text": "replication across three facilities to give very good availability and fault tolerance characteristics",
    "start": "158480",
    "end": "165840"
  },
  {
    "start": "165000",
    "end": "176000"
  },
  {
    "text": "so briefly i want to give a primer on how we scale under the covers this is a 400 level talk so i'm assuming that most",
    "start": "165920",
    "end": "171680"
  },
  {
    "text": "of you know this but it's very important that everyone's on the same page in this regard",
    "start": "171680",
    "end": "176800"
  },
  {
    "text": "so very briefly we scale for size and throughput independently if you put more items in your table or you ask for more",
    "start": "176800",
    "end": "182080"
  },
  {
    "text": "ios per second we respond by partitioning we cut your table into pieces and we spread these pieces across",
    "start": "182080",
    "end": "188319"
  },
  {
    "text": "more and more physical hardware it's classic horizontal scaling",
    "start": "188319",
    "end": "194319"
  },
  {
    "start": "194000",
    "end": "218000"
  },
  {
    "text": "when we do this we chop the provision throughput on your table equally amongst the partitions",
    "start": "194560",
    "end": "201040"
  },
  {
    "text": "so in this little toy example we have a customer that's asked for 1500 writes per second on his or her table",
    "start": "201040",
    "end": "207440"
  },
  {
    "text": "we've in the background cut it into three partitions to meet these throughput or storage demands and so",
    "start": "207440",
    "end": "213440"
  },
  {
    "text": "every partition gets 500 writes per second simple right now",
    "start": "213440",
    "end": "219599"
  },
  {
    "start": "218000",
    "end": "255000"
  },
  {
    "text": "talking about accesses and partitions every item in dynamodb has a hash key when you define a table you tell us",
    "start": "219599",
    "end": "226959"
  },
  {
    "text": "this is my hash key attribute and this is my range key attribute the rest is schema-less but every item must have",
    "start": "226959",
    "end": "232959"
  },
  {
    "text": "those fields the hash key is super important because this determines not only what partition this item will live",
    "start": "232959",
    "end": "238959"
  },
  {
    "text": "on but where in that partition you can think of every partition as a discrete key range every partition has a start",
    "start": "238959",
    "end": "245599"
  },
  {
    "text": "key and an n key so when you hand us an item or ask for an item we look at that hash key and then figure out which",
    "start": "245599",
    "end": "251760"
  },
  {
    "text": "partition this item is going to live on so putting these two things together the",
    "start": "251760",
    "end": "257280"
  },
  {
    "text": "fact that every partition gets equal throughput an equal slice of that pie and the fact that every hash key maps to",
    "start": "257280",
    "end": "264160"
  },
  {
    "text": "one partition exactly we really need you to spread your your workload uniformly across your",
    "start": "264160",
    "end": "270880"
  },
  {
    "text": "key space because that spreads it uniformly across the partitions now we don't require you to do that you don't",
    "start": "270880",
    "end": "276479"
  },
  {
    "text": "have to we have plenty of users that have non-uniform workloads but if you",
    "start": "276479",
    "end": "282000"
  },
  {
    "text": "can spread evenly you can really take advantage of your our scale if you have what we call hotkeys these",
    "start": "282000",
    "end": "288000"
  },
  {
    "text": "are keys that are over popular relative to their peers and what happens is the partition on which that key lives get",
    "start": "288000",
    "end": "293840"
  },
  {
    "text": "really gets really hot and the other ones are cool and because you paid for provision throughput and we've chopped",
    "start": "293840",
    "end": "299280"
  },
  {
    "text": "it equally those cool partitions you're really not getting your money's worth so why is this important for latency why",
    "start": "299280",
    "end": "306880"
  },
  {
    "text": "does this matter for performance before we go into these best practices",
    "start": "306880",
    "end": "311919"
  },
  {
    "start": "310000",
    "end": "339000"
  },
  {
    "text": "of how to architect around this problem i've been alluding to i want to go through some of the sources going down",
    "start": "311919",
    "end": "317199"
  },
  {
    "text": "the stack where can your application get slowed down talking to dynamodb",
    "start": "317199",
    "end": "322240"
  },
  {
    "text": "so there's four sources i've got here i'll just breeze through these pretty quick resource availability",
    "start": "322240",
    "end": "327759"
  },
  {
    "text": "then moving down into network behavior what's going on in your application the sdk the os",
    "start": "327759",
    "end": "333199"
  },
  {
    "text": "provision throughput on your table in dynamodb and then this heat skew problem that i was just mentioning",
    "start": "333199",
    "end": "340000"
  },
  {
    "start": "339000",
    "end": "439000"
  },
  {
    "text": "so if your application doesn't have enough resources you're not going to be able to push performance to dynamodb",
    "start": "340000",
    "end": "345280"
  },
  {
    "text": "quick enough or push requests i should say you might get",
    "start": "345280",
    "end": "350720"
  },
  {
    "text": "good performance most of the time but it's those high percentiles you're really not going to get the latency that you want so of course node hardware",
    "start": "350720",
    "end": "356800"
  },
  {
    "text": "comes into this you got to make sure the box is big enough for both your application and all the the work it's doing to talk to dynamodb",
    "start": "356800",
    "end": "364160"
  },
  {
    "text": "you know another facet on the same problem is workload colocation if you stuff too many workloads in the same box",
    "start": "364160",
    "end": "370400"
  },
  {
    "text": "the work the application that you're trying to optimize is not going to be able to move quick enough",
    "start": "370400",
    "end": "375600"
  },
  {
    "text": "if you use a managed language like java we see a lot of customers have trouble with heap size and garbage collection",
    "start": "375600",
    "end": "381840"
  },
  {
    "text": "definitely dial up that heap size it can start hurting you after a point but please play with it and see what",
    "start": "381840",
    "end": "387600"
  },
  {
    "text": "kind of performance you get garbage collection is another aspect of the same coin or side of the",
    "start": "387600",
    "end": "393360"
  },
  {
    "text": "same problem space if you are noticing odd pauses",
    "start": "393360",
    "end": "398479"
  },
  {
    "text": "definitely check out gc you don't need to necessarily understand your garbage collection algorithm just look at your",
    "start": "398479",
    "end": "404000"
  },
  {
    "text": "gc metrics and correlate them with performance problems and see if they line up",
    "start": "404000",
    "end": "409280"
  },
  {
    "text": "gc in particular can throw odd pauses even in metrics so if you're trying to dig into this problem and",
    "start": "409280",
    "end": "415280"
  },
  {
    "text": "you're seeing latency spikes or spikes in a certain metric you might have seen a gc pause while that metric was being",
    "start": "415280",
    "end": "421520"
  },
  {
    "text": "collected it's a nasty little gremlin so make sure that you're accounting for it and finally context switch overhead",
    "start": "421520",
    "end": "427120"
  },
  {
    "text": "we're finding that people are using thread pools more and more they're dialing up these thread pools as their core counts go up that's great but just",
    "start": "427120",
    "end": "433039"
  },
  {
    "text": "like heap size don't go too far because otherwise your cpu is going to spend a lot of time context switching",
    "start": "433039",
    "end": "439840"
  },
  {
    "start": "439000",
    "end": "512000"
  },
  {
    "text": "so moving down the stack into network related behavior this is a grab bag of anything that's network related north of",
    "start": "439840",
    "end": "445840"
  },
  {
    "text": "the dynamodb endpoint in this little figure connection pooling is a huge one make sure you're amortizing the cost of",
    "start": "445840",
    "end": "452319"
  },
  {
    "text": "setting up a connection dynamodb gives consistently single digit millisecond latency setting up a connection is far",
    "start": "452319",
    "end": "458639"
  },
  {
    "text": "more expensive than this so make sure that you amortize the sunk cost across a lot of requests",
    "start": "458639",
    "end": "464720"
  },
  {
    "text": "it's turned on by default in the sdk but make sure it's turned on and there are",
    "start": "464720",
    "end": "470000"
  },
  {
    "text": "other application models that don't map well to connection pooling the classic example is an apache",
    "start": "470000",
    "end": "476960"
  },
  {
    "text": "if you're forking processes to serve user requests when that process gets reaped it's going to throw away those",
    "start": "476960",
    "end": "482400"
  },
  {
    "text": "connections so definitely try and take advantage of this sdk auto request behavior is another",
    "start": "482400",
    "end": "488960"
  },
  {
    "text": "i'll talk a little bit more in detail about this in a minute but the classic example is retrying throttled requests",
    "start": "488960",
    "end": "495440"
  },
  {
    "text": "ssl overhead is another ssl is not free make sure you're accounting for it and then of course round trip time and",
    "start": "495440",
    "end": "502080"
  },
  {
    "text": "packet loss when we all think of latency we're thinking about network fabric problems they do exist but they are just",
    "start": "502080",
    "end": "507280"
  },
  {
    "text": "a piece of this puzzle",
    "start": "507280",
    "end": "510319"
  },
  {
    "start": "512000",
    "end": "561000"
  },
  {
    "text": "so moving down into dynamodb insufficiently provisioned tables look like latency to your application why is",
    "start": "513440",
    "end": "519279"
  },
  {
    "text": "this it's because you hand off to the sdk you say please put this item in dynamodb the sdk will try and go to dynamodb",
    "start": "519279",
    "end": "525760"
  },
  {
    "text": "multiple times it gets bounced back with throttles the default behavior is to retry throttled requests and then it",
    "start": "525760",
    "end": "531519"
  },
  {
    "text": "will finally come back up after three or four round trips that looks like latency to your app because it handed off the request the request just took a while to",
    "start": "531519",
    "end": "538320"
  },
  {
    "text": "come back so we do allow you to go above your provision line for a short period of time we call this feature bursting but",
    "start": "538320",
    "end": "544959"
  },
  {
    "text": "it's for short temporal spikes it's to take the sharp edges off a bursty workload it's not for chronic under",
    "start": "544959",
    "end": "550320"
  },
  {
    "text": "provisioning so if you look at cloudwatch and you see yourself bumping up against that provision throughput line",
    "start": "550320",
    "end": "555519"
  },
  {
    "text": "definitely just dial up and you should see a decrease in your application latency",
    "start": "555519",
    "end": "561360"
  },
  {
    "start": "561000",
    "end": "606000"
  },
  {
    "text": "finally data model and table growth and that's what i'm really here to talk to you about today if you're accessing only a subset of your key space or a subset",
    "start": "561360",
    "end": "568160"
  },
  {
    "text": "of your key space is quite hot relative to the rest of your key space as your table grows this is going to become more",
    "start": "568160",
    "end": "573760"
  },
  {
    "text": "and more apparent because again as we add more partitions you're accessing a",
    "start": "573760",
    "end": "579279"
  },
  {
    "text": "subset of those partitions this will never appear when you have one partition it's because that one partition has a",
    "start": "579279",
    "end": "585040"
  },
  {
    "text": "hundred percent of your throughput it's a small table but as you scale and you access fear and fear of those partitions",
    "start": "585040",
    "end": "591920"
  },
  {
    "text": "what's going to happen is you get throttle responses back but you look at cloud watch and you're nowhere near the line",
    "start": "591920",
    "end": "597440"
  },
  {
    "text": "so this is what i want to talk about today how can we design around this when we're building our tables are we're",
    "start": "597440",
    "end": "603440"
  },
  {
    "text": "thinking about our access patterns so i'm going to dive right into it the first best practice is combining",
    "start": "603440",
    "end": "609839"
  },
  {
    "text": "queryability and uniformity when you do your key selection it's a mouthful but it's a very simple idea",
    "start": "609839",
    "end": "616000"
  },
  {
    "start": "615000",
    "end": "634000"
  },
  {
    "text": "and the toy use case i'm going to use throughout this presentation is webster order processing let's say that you run",
    "start": "616000",
    "end": "621839"
  },
  {
    "text": "a web store and in particular you want to do your order processing on top of dynamodb you like its availability it's",
    "start": "621839",
    "end": "627600"
  },
  {
    "text": "fault tolerance it's speed so you've chosen dynamodb but we've got some problems to kind of work",
    "start": "627600",
    "end": "633040"
  },
  {
    "text": "around so in this example we'll have two toy workloads the right workload is placing",
    "start": "633040",
    "end": "639200"
  },
  {
    "text": "orders in the table just writing items in the table and the read workload is building up a single customer's order",
    "start": "639200",
    "end": "644560"
  },
  {
    "text": "history we've all gone to an online retailer of choice and we wanted to see what we purchased in the",
    "start": "644560",
    "end": "649680"
  },
  {
    "text": "past so that's our archetypal read workload here in the upper right you can see a schema",
    "start": "649680",
    "end": "654800"
  },
  {
    "text": "that satisfies this pretty well it has a hash key of customer id and a range key of timestamp this schema is super easy",
    "start": "654800",
    "end": "661680"
  },
  {
    "text": "to query and paginate the query api in dynamodb requires that you know the hash key in this use case",
    "start": "661680",
    "end": "668399"
  },
  {
    "text": "you will know the hash key because this customer is logged in gone through authentication as part of that you've looked up their customer id",
    "start": "668399",
    "end": "674880"
  },
  {
    "text": "in addition this range key of timestamp lets you sort the results and paginate them as they come back from dynamodb so",
    "start": "674880",
    "end": "680959"
  },
  {
    "text": "you could say give me all the orders going back in time and paginating by a page size of say 10 or 15 or 25 then as",
    "start": "680959",
    "end": "688640"
  },
  {
    "text": "the customer clicks the next page button you re-issue that paginated query to dynamodb re-render the webpage and shove",
    "start": "688640",
    "end": "695600"
  },
  {
    "text": "it back to their browser in addition what's great about this schema is that the read and write heat",
    "start": "695600",
    "end": "701040"
  },
  {
    "text": "is well spread the average customer of yours for your web store is going to place one two",
    "start": "701040",
    "end": "707040"
  },
  {
    "text": "orders a day and they're going to build up their order history once or twice a week a few times perhaps",
    "start": "707040",
    "end": "712639"
  },
  {
    "text": "even the far upper percentile let's say your most power user is like a bulk wholesaler",
    "start": "712639",
    "end": "718959"
  },
  {
    "text": "it's hitting an api it's not hitting the website um and at 9 00 a.m or 5 p.m",
    "start": "718959",
    "end": "724720"
  },
  {
    "text": "eastern they dump 5 10 20 orders on you at the end of their day or the beginning of their week",
    "start": "724720",
    "end": "730959"
  },
  {
    "text": "when this happens and you have this burst of heat to that customer id those items are going to be small this",
    "start": "730959",
    "end": "737040"
  },
  {
    "text": "is text we're talking about it's not large binary data dynamodb now supports 400 kilobyte items",
    "start": "737040",
    "end": "742959"
  },
  {
    "text": "but these are just a few kilobytes so every order is only going to consume a few writes per second so although it's",
    "start": "742959",
    "end": "748720"
  },
  {
    "text": "not strictly uniform it's got enough uniformity that you're going to skate by",
    "start": "748720",
    "end": "754480"
  },
  {
    "start": "754000",
    "end": "794000"
  },
  {
    "text": "so again the theme throughout this talk is that selecting your keys well making sure that heat is well spread will let",
    "start": "754480",
    "end": "760480"
  },
  {
    "text": "you scale with us and to do this you really need to select keys that are both queryable and uniform you need to be",
    "start": "760480",
    "end": "766160"
  },
  {
    "text": "able to access your data in a way that makes sense for your business but you also need to spread those accesses",
    "start": "766160",
    "end": "771680"
  },
  {
    "text": "evenly across the key space and this is important when you're designing high growth tables because that's when this",
    "start": "771680",
    "end": "776959"
  },
  {
    "text": "is really going to start to bite you at the exact moment when you need your database tier to scale and that's when",
    "start": "776959",
    "end": "782320"
  },
  {
    "text": "your business grows",
    "start": "782320",
    "end": "785800"
  },
  {
    "text": "so best practice number two is taking these lessons learned and applying them to indexes",
    "start": "788720",
    "end": "794800"
  },
  {
    "start": "794000",
    "end": "836000"
  },
  {
    "text": "so what if we have an alternate query pattern we want to query the same data but we want to use a different hash and",
    "start": "794800",
    "end": "800079"
  },
  {
    "text": "range key dynamodb has a feature that we introduced last year called global secondary indexes that allow you to do",
    "start": "800079",
    "end": "806000"
  },
  {
    "text": "this so one workload that would or one query pattern that would work really well in this use",
    "start": "806000",
    "end": "811519"
  },
  {
    "text": "case is household id we want to associate multiple customer ids under a single household id and we let a member",
    "start": "811519",
    "end": "817920"
  },
  {
    "text": "of the family look at his or her households purchases going back in time so if the item has the",
    "start": "817920",
    "end": "825360"
  },
  {
    "text": "hash key and the range key for the index dynamodb when you write it to the table will look at that item we'll say yes it",
    "start": "825360",
    "end": "831440"
  },
  {
    "text": "does have everything it needs and will handle the index propagation for you so under the hood the way that this",
    "start": "831440",
    "end": "837199"
  },
  {
    "start": "836000",
    "end": "853000"
  },
  {
    "text": "works is you know you write to the table we look at it we push it to the index asynchronously and then you can run read",
    "start": "837199",
    "end": "843360"
  },
  {
    "text": "clients directly against that index but the interesting thing about this is that global secondary indexes are partitioned",
    "start": "843360",
    "end": "850639"
  },
  {
    "text": "independently from the table so let's look at an anti-pattern that",
    "start": "850639",
    "end": "856320"
  },
  {
    "start": "853000",
    "end": "882000"
  },
  {
    "text": "exposes why this is very important to consider what if we want to query orders from last month we want to do inventory",
    "start": "856320",
    "end": "861760"
  },
  {
    "text": "projection some kind of analytics we might look at month and realize that",
    "start": "861760",
    "end": "866800"
  },
  {
    "text": "that's a terrible key there's only 12 of them in a year january february march but what about day of order we could use",
    "start": "866800",
    "end": "872079"
  },
  {
    "text": "day of order as high cardinality and then we could issue queries for every day and last month to build up this",
    "start": "872079",
    "end": "877279"
  },
  {
    "text": "corpus of data for us to do our analysis with so let's try that",
    "start": "877279",
    "end": "882480"
  },
  {
    "start": "882000",
    "end": "928000"
  },
  {
    "text": "what happens when you do that is that although the right heat on the table itself is well spread because it's keyed",
    "start": "882480",
    "end": "888160"
  },
  {
    "text": "on customer id the heat on the index is terrible it's all concentrated on one partition",
    "start": "888160",
    "end": "893839"
  },
  {
    "text": "because every time you write a new order to the table we propagate it to the index and the hash key changes from",
    "start": "893839",
    "end": "899279"
  },
  {
    "text": "customer id to day of order and all the orders from today are going to land on therefore the same hash key",
    "start": "899279",
    "end": "905920"
  },
  {
    "text": "when this occurs that partition in the index gets hot and so we're going to it's going gonna start throttling and",
    "start": "905920",
    "end": "911920"
  },
  {
    "text": "when we notice it throttling we're gonna have to start throttling you on the table because you can think of this like a pipeline we have to keep the pipeline",
    "start": "911920",
    "end": "918480"
  },
  {
    "text": "moving we can't keep so many balls in the air we can't keep juggling past a point we do have some flex here but not",
    "start": "918480",
    "end": "924800"
  },
  {
    "text": "a whole lot so at that point you're going to start seeing throttling on your table so the takeaway here is that index keys",
    "start": "924800",
    "end": "931040"
  },
  {
    "start": "928000",
    "end": "974000"
  },
  {
    "text": "behave just like table keys the mechanics are identical all the rules are identical and this is important when you're",
    "start": "931040",
    "end": "936800"
  },
  {
    "text": "indexing a high scale table we recently pre-announced online indexing it's the ability to turn on global secondary",
    "start": "936800",
    "end": "943519"
  },
  {
    "text": "indexes for existing tables if you have a high scale table and you've been just waiting to turn on that index that's",
    "start": "943519",
    "end": "949519"
  },
  {
    "text": "great we've worked very very hard to build this feature for you but do be careful when you select your keys",
    "start": "949519",
    "end": "955600"
  },
  {
    "text": "because the right uniformity of the table is actually going to be a min function of the right uniform video on",
    "start": "955600",
    "end": "961920"
  },
  {
    "text": "the table and all of the indexes so the more indexes you bolt onto this thing you need to think about the key",
    "start": "961920",
    "end": "967440"
  },
  {
    "text": "selection or otherwise you're going to see this throttling where it wasn't there before",
    "start": "967440",
    "end": "972959"
  },
  {
    "start": "974000",
    "end": "1014000"
  },
  {
    "text": "so best practice number three is pruning frequently scanned tables so let's say we still have this same workload we",
    "start": "976320",
    "end": "982560"
  },
  {
    "text": "still are trying to get last month's orders and an index didn't work in this use case",
    "start": "982560",
    "end": "988000"
  },
  {
    "text": "so we could just scan the whole table and look at every item and say was this in last month okay well then we'll go do",
    "start": "988000",
    "end": "993680"
  },
  {
    "text": "our analytics on top of it and scan is actually not a dirty word in dynamodb we can scan all your partitions in parallel",
    "start": "993680",
    "end": "1000160"
  },
  {
    "text": "so for wall clock time we can actually make it quite fast but it does get more expensive over time think about it you",
    "start": "1000160",
    "end": "1005920"
  },
  {
    "text": "have a fixed number of needles all the orders in last month and the size of the haystack just keeps growing because you",
    "start": "1005920",
    "end": "1011040"
  },
  {
    "text": "keep adding more and more months data to this table so one naive response to this is we",
    "start": "1011040",
    "end": "1017120"
  },
  {
    "start": "1014000",
    "end": "1064000"
  },
  {
    "text": "could control this table growth with deletion we could look for old orders we could archive them somehow and then we",
    "start": "1017120",
    "end": "1022480"
  },
  {
    "text": "could delete them out of the table so the real takeaway here even though this is a very simple technique is that table",
    "start": "1022480",
    "end": "1027760"
  },
  {
    "text": "growth impacts throughput per key and this is important when you're accumulating infrequently read data because again the use case and the",
    "start": "1027760",
    "end": "1034720"
  },
  {
    "text": "assumptions that dynamodb was built for is that you're accessing all of your hash keys in a roughly uniform manner",
    "start": "1034720",
    "end": "1040798"
  },
  {
    "text": "but if you're storing old data in that table and you're accessing that less frequently you're violating that assumption and we don't care we'll let",
    "start": "1040799",
    "end": "1048319"
  },
  {
    "text": "you continue to do that all day but it will end up biting you as those colder",
    "start": "1048319",
    "end": "1053840"
  },
  {
    "text": "older hash keys accumulate and pile up and dilute the throughput per key on",
    "start": "1053840",
    "end": "1060480"
  },
  {
    "text": "your hot your newer keys your newer orders so there's actually another technique if",
    "start": "1060480",
    "end": "1066880"
  },
  {
    "start": "1064000",
    "end": "1074000"
  },
  {
    "text": "you can make it work for your application and for your model that works even better in this space it's",
    "start": "1066880",
    "end": "1071919"
  },
  {
    "text": "called table rotation now the real problem with deleting items from the client side if any of you have",
    "start": "1071919",
    "end": "1077440"
  },
  {
    "start": "1074000",
    "end": "1199000"
  },
  {
    "text": "done this before is that it actually doubles your write cost you pay once when you write the item and you pay again when you delete it so there's a",
    "start": "1077440",
    "end": "1084160"
  },
  {
    "text": "way to achieve cheaper deletes and scans here and that's called table rotation that's what we call table rotation it's",
    "start": "1084160",
    "end": "1089840"
  },
  {
    "text": "an unofficial term if you have a table for discrete time periods then it gives you a lot more",
    "start": "1089840",
    "end": "1096480"
  },
  {
    "text": "control over the situation in this case we would have one table per month so",
    "start": "1096480",
    "end": "1101760"
  },
  {
    "text": "this gives you three primary benefits the first is that now that scan to look at all of last month's orders is super",
    "start": "1101760",
    "end": "1108000"
  },
  {
    "text": "efficient every item in that table is relevant to the query now the number of needles is equal",
    "start": "1108000",
    "end": "1114480"
  },
  {
    "text": "to the size of the haystack that's awesome second is deleting whole tables has no throughput cost because when you nuke a",
    "start": "1114480",
    "end": "1120160"
  },
  {
    "text": "table we go clean it up in the background you stop paying immediately there's no more this double pay once when you write once when you delete",
    "start": "1120160",
    "end": "1126400"
  },
  {
    "text": "but the third and actually most powerful benefit is that now you can dial up and down every month independently so what's",
    "start": "1126400",
    "end": "1134799"
  },
  {
    "text": "the chance that you're going to write an order in last month's table you might go amend somebody's order but",
    "start": "1134799",
    "end": "1139840"
  },
  {
    "text": "i mean that's going to be pretty rare you could probably drop that rights per second down to one or two per second i",
    "start": "1139840",
    "end": "1145200"
  },
  {
    "text": "mean you can really push that to the floor the other thing you can do is as you accumulate these tables going back",
    "start": "1145200",
    "end": "1150320"
  },
  {
    "text": "in time you can drop their read through put down because you're going to have some customers they're going to want to look",
    "start": "1150320",
    "end": "1156240"
  },
  {
    "text": "at their orders from 2011 but that's a rare customer most of them are going to be looking at this month so that way you",
    "start": "1156240",
    "end": "1162160"
  },
  {
    "text": "can have this month's table be dialed way up as your business grows but step these down over time",
    "start": "1162160",
    "end": "1168799"
  },
  {
    "text": "so the takeaway here is that time series data chunks very well we have customers that chunk by year by",
    "start": "1168799",
    "end": "1175200"
  },
  {
    "text": "month by week by day by hour it's entirely what works for your use case",
    "start": "1175200",
    "end": "1180640"
  },
  {
    "text": "and this is important when you have big growing time series tables and the emphasis here is on growing because",
    "start": "1180640",
    "end": "1186400"
  },
  {
    "text": "again that's when you're in accumulating potentially infrequently read data",
    "start": "1186400",
    "end": "1192799"
  },
  {
    "text": "so the final best practice this is the last one is exporting data with dynamodb streams",
    "start": "1192799",
    "end": "1199440"
  },
  {
    "text": "so recall that we're trying to get all of last month's orders it's kind of an analytics business",
    "start": "1199440",
    "end": "1204480"
  },
  {
    "text": "intelligence type workload so there's two questions we should ask do we need results in real time or does",
    "start": "1204480",
    "end": "1210400"
  },
  {
    "text": "near real time suffice and do we have other queries to consider if so perhaps an alternate data store",
    "start": "1210400",
    "end": "1217039"
  },
  {
    "text": "would be better suited for this particular workload so let's compare dynamodb to say data",
    "start": "1217039",
    "end": "1223919"
  },
  {
    "start": "1221000",
    "end": "1265000"
  },
  {
    "text": "warehousing because this seems like a data warehousing workload at least to me dynamodb is really good at real-time",
    "start": "1223919",
    "end": "1229039"
  },
  {
    "text": "stuff it's very performant has very good random write performance and it's got very good high availability",
    "start": "1229039",
    "end": "1235360"
  },
  {
    "text": "very good fault tolerance data warehousing on the other hand is good at bulk ingestion sequential rights",
    "start": "1235360",
    "end": "1241120"
  },
  {
    "text": "and it's excellent at ad hoc queries and that's really where this particular workload might benefit",
    "start": "1241120",
    "end": "1248480"
  },
  {
    "text": "because we're talking about analytics it would be nice to have an analyst sit down and run queries against this corpus",
    "start": "1248480",
    "end": "1253760"
  },
  {
    "text": "one of the things that i've kind of been reiterating throughout this talk is that it's very important to think crisply",
    "start": "1253760",
    "end": "1259440"
  },
  {
    "text": "about your query patterns when you work with dynamodb but that doesn't quite work here so how do we",
    "start": "1259440",
    "end": "1265440"
  },
  {
    "start": "1265000",
    "end": "1320000"
  },
  {
    "text": "integrate a data warehouse into our dynamodb based ecosystem well until now the way that you would do this is by",
    "start": "1265440",
    "end": "1271520"
  },
  {
    "text": "scanning usually use an emr fleet you'd spin this fleet up they'd scan the whole table they'd push all that data to this",
    "start": "1271520",
    "end": "1277919"
  },
  {
    "text": "data warehouse and then you run your analytics app directly against this data warehouse so this works we have plenty of people",
    "start": "1277919",
    "end": "1284400"
  },
  {
    "text": "doing this every day but there's a couple problems with it the first is that this data warehouse is going to be",
    "start": "1284400",
    "end": "1289919"
  },
  {
    "text": "out of date every time you scan it's fresh but then over time it gets staler and staler and",
    "start": "1289919",
    "end": "1296320"
  },
  {
    "text": "then it's fresh again and it's staler and staler so what can you do if you want fresher data well you scan more frequently but when you dial up the",
    "start": "1296320",
    "end": "1303120"
  },
  {
    "text": "frequency of that scan there's two things that happen one is that it costs more because this scan consumes read",
    "start": "1303120",
    "end": "1308640"
  },
  {
    "text": "capacity the second thing is that the scan is actually less efficient because you're walking the whole table no matter",
    "start": "1308640",
    "end": "1313919"
  },
  {
    "text": "the rate of change of the items in that table so we recently",
    "start": "1313919",
    "end": "1320559"
  },
  {
    "start": "1320000",
    "end": "1410000"
  },
  {
    "text": "pre-announced a new feature it's called dynamodb streams it's available for preview now it will",
    "start": "1320559",
    "end": "1326799"
  },
  {
    "text": "be publicly released soon and the way that it works is that you can turn on dynamodb streams for your",
    "start": "1326799",
    "end": "1333520"
  },
  {
    "text": "table and as updates puts or updates occur or deletes occur to your table",
    "start": "1333520",
    "end": "1339200"
  },
  {
    "text": "these updates are published on a stream and then you can consume this stream and do anything you want with these updates",
    "start": "1339200",
    "end": "1345440"
  },
  {
    "text": "it's a super powerful primitive it's like a swiss army knife so some of the use cases that we see people planning to",
    "start": "1345440",
    "end": "1351440"
  },
  {
    "text": "use it for are cross region replication we actually have a library that will do that elastic search integration we also have",
    "start": "1351440",
    "end": "1357679"
  },
  {
    "text": "a library for that you could do cache updating you could do complex indexing logic that's not currently supported in",
    "start": "1357679",
    "end": "1363120"
  },
  {
    "text": "global secondary indexes you can do in-memory aggregation or you can export this data to an",
    "start": "1363120",
    "end": "1369200"
  },
  {
    "text": "alternate data store so in this particular use case where we're trying to build up this data",
    "start": "1369200",
    "end": "1374400"
  },
  {
    "text": "warehouse that's trailing behind our dynamodb table but minimizing the the gap in freshness we would push it to",
    "start": "1374400",
    "end": "1381440"
  },
  {
    "text": "this data warehouse and again talk straight to that so this is important when you need to bridge to other data stores with",
    "start": "1381440",
    "end": "1387840"
  },
  {
    "text": "dynamodb streams you can really tightly integrate this data warehouse into your ecosystem and",
    "start": "1387840",
    "end": "1393760"
  },
  {
    "text": "there's no more of this lag and this is important not only when you need near real-time data which is a point i've",
    "start": "1393760",
    "end": "1398880"
  },
  {
    "text": "been beating to death but also you need the ad-hoc queries i mean data warehouses are still super useful",
    "start": "1398880",
    "end": "1404400"
  },
  {
    "text": "so you can you can tightly integrate these other data stores into your ecosystem",
    "start": "1404400",
    "end": "1410080"
  },
  {
    "start": "1410000",
    "end": "1414000"
  },
  {
    "text": "so in summary we've talked about some takeaways to unlock scalability with your data model",
    "start": "1410080",
    "end": "1416480"
  },
  {
    "start": "1414000",
    "end": "1470000"
  },
  {
    "text": "one of the things that dynamodb will benefit from your usage of dynamodb and your application will benefit from",
    "start": "1416480",
    "end": "1422480"
  },
  {
    "text": "is thinking about these things at design time you don't need to completely front load it but it's something to keep in the back of your mind as you're building",
    "start": "1422480",
    "end": "1428880"
  },
  {
    "text": "up your your application so select keys based on queryability and uniformity it's really the marriage of",
    "start": "1428880",
    "end": "1434720"
  },
  {
    "text": "these two factors that makes a good key key selection is an art it's not a science",
    "start": "1434720",
    "end": "1440159"
  },
  {
    "text": "but you can think about how you want to get at your data and how that access pattern is going to play out",
    "start": "1440159",
    "end": "1445360"
  },
  {
    "text": "apply those same lessons to indexes remember right uniformity is a min function of",
    "start": "1445360",
    "end": "1451200"
  },
  {
    "text": "the table and the indexes avoid accumulating and frequently accessed data avoid it by either deleting it and",
    "start": "1451200",
    "end": "1458000"
  },
  {
    "text": "archiving it or putting it in another table with table rotation so you can really dial those down over time and use dynamodb streams",
    "start": "1458000",
    "end": "1465200"
  },
  {
    "text": "to do whatever you want but one of the things you can do is export data as it arrives so",
    "start": "1465200",
    "end": "1470720"
  },
  {
    "start": "1470000",
    "end": "1546000"
  },
  {
    "text": "thank you very much i really appreciate the chance to talk to you i'm going to hand over now to brett mccleary with precision exams we will be available for",
    "start": "1470720",
    "end": "1478080"
  },
  {
    "text": "q a after the talk out in the hall thank you",
    "start": "1478080",
    "end": "1483480"
  },
  {
    "text": "all right uh thank you very much ben i i appreciate the opportunity you've given me to just talk a little bit about what",
    "start": "1490960",
    "end": "1497120"
  },
  {
    "text": "we've done as an organization",
    "start": "1497120",
    "end": "1501799"
  },
  {
    "text": "as far as introductions go my name is brett mcclary i'm a vice president of software development at precision exams",
    "start": "1502880",
    "end": "1509200"
  },
  {
    "text": "and what precision exams is is a company that's based in american fork utah and we provide online",
    "start": "1509200",
    "end": "1516320"
  },
  {
    "text": "testing software for high-stakes testing across the united states so our product",
    "start": "1516320",
    "end": "1522159"
  },
  {
    "text": "is made available as a service to the state or the districts so high school",
    "start": "1522159",
    "end": "1527360"
  },
  {
    "text": "students can get in and take exams and get certified in a variety of educational",
    "start": "1527360",
    "end": "1532559"
  },
  {
    "text": "pathways now that's quite a mouthful my opinion is is we're a small company",
    "start": "1532559",
    "end": "1537760"
  },
  {
    "text": "we're extremely innovative and we love working with technologies to solve real world business problems",
    "start": "1537760",
    "end": "1545120"
  },
  {
    "text": "so one of the problems that we came up a few years ago well a couple years ago",
    "start": "1545120",
    "end": "1550799"
  },
  {
    "text": "was what do we do with our our data we have a lot of students coming in taking tests we have exponential growth",
    "start": "1550799",
    "end": "1557360"
  },
  {
    "text": "in our business where do we store this data so what we decided to do was go with amazon dynamodb",
    "start": "1557360",
    "end": "1564320"
  },
  {
    "text": "we we take all of the student assessment data that comes into the app servers we store it in dynamodb and then we have a",
    "start": "1564320",
    "end": "1571360"
  },
  {
    "text": "data warehouse process that runs based on what i've learned in this conference we're going to be changing this up a little bit but we have a data",
    "start": "1571360",
    "end": "1577919"
  },
  {
    "text": "warehouse that runs we pull the data out of dynamodb we transform it and insert it into our mysql database a relational",
    "start": "1577919",
    "end": "1584400"
  },
  {
    "text": "database where we do all of our statistics and test",
    "start": "1584400",
    "end": "1589760"
  },
  {
    "text": "and test metrics that we collect for the students so one of the",
    "start": "1589760",
    "end": "1595200"
  },
  {
    "text": "the important things that we had on our table is why did we go with dynamodb the the answer to this question is really",
    "start": "1595200",
    "end": "1600960"
  },
  {
    "text": "what i'm going to be talking about as ben pointed out the data storage expands based on our",
    "start": "1600960",
    "end": "1607200"
  },
  {
    "text": "needs so testing is interesting there's heat there's a there's peaks and valleys",
    "start": "1607200",
    "end": "1612640"
  },
  {
    "text": "with that particular industry so we need to be able to expand it as we need it",
    "start": "1612640",
    "end": "1617840"
  },
  {
    "text": "we also needed consistent performance under load one thing that was driving me crazy is the more students that would",
    "start": "1617840",
    "end": "1623360"
  },
  {
    "text": "hit our our database the worse our performance got and it was like this this can't happen over over time",
    "start": "1623360",
    "end": "1629679"
  },
  {
    "text": "we didn't want to have any installation i'm done building infrastructure i'm i'm through with that cost and we did",
    "start": "1629679",
    "end": "1635520"
  },
  {
    "text": "look at the overall cost model and we really appreciated what amazon had done with uh",
    "start": "1635520",
    "end": "1641600"
  },
  {
    "text": "with their costs and it fit really well with our business and finally we did a bunch of proof of concepts and it worked",
    "start": "1641600",
    "end": "1647679"
  },
  {
    "text": "really well with our ecosystem we were able to get it into our our our technology stack without a lot of work",
    "start": "1647679",
    "end": "1654159"
  },
  {
    "start": "1649000",
    "end": "1665000"
  },
  {
    "text": "so these are the steps that we took to select dynamodb we found these useful so",
    "start": "1654159",
    "end": "1659600"
  },
  {
    "text": "i wanted to share them with you today so the first thing was to know your data so for us",
    "start": "1659600",
    "end": "1665360"
  },
  {
    "start": "1665000",
    "end": "1688000"
  },
  {
    "text": "we identified our hottest tables which of course was our student assessment tables",
    "start": "1665360",
    "end": "1670480"
  },
  {
    "text": "as they were answering questions we would write and we also had to process",
    "start": "1670480",
    "end": "1675679"
  },
  {
    "text": "stuff on the back end our traffic patterns were very important to us as well we needed to understand our read and",
    "start": "1675679",
    "end": "1682399"
  },
  {
    "text": "write workloads and again we want to make sure that our data size and structure was appropriate for dynamodb",
    "start": "1682399",
    "end": "1688000"
  },
  {
    "start": "1688000",
    "end": "1730000"
  },
  {
    "text": "in the selection so here's a couple of our hot tables i don't want to get too much into our",
    "start": "1688000",
    "end": "1693919"
  },
  {
    "text": "domain but i think you need to understand this to understand the rest of the discussion this is our test packet answer table a",
    "start": "1693919",
    "end": "1700480"
  },
  {
    "text": "test packet id is our unique identifier within our system that associates a particular test",
    "start": "1700480",
    "end": "1706399"
  },
  {
    "text": "to a student and so what we did is we created a hash key on that test packet id now you'll",
    "start": "1706399",
    "end": "1711919"
  },
  {
    "text": "notice that this schema is pretty simple and we kept it that way on purpose we wanted to make it very easy to query and",
    "start": "1711919",
    "end": "1718000"
  },
  {
    "text": "we wanted to make it very fast the other attribute that we have is an",
    "start": "1718000",
    "end": "1723279"
  },
  {
    "text": "answer json what this is is it's a basically a json document that holds all",
    "start": "1723279",
    "end": "1729679"
  },
  {
    "text": "of the answers that a particular student has provided so this is what a record looks like in dynamodb today so this is",
    "start": "1729679",
    "end": "1736320"
  },
  {
    "start": "1730000",
    "end": "1756000"
  },
  {
    "text": "an actual one the ellipses that are there to show that there's additional responses that are in this particular",
    "start": "1736320",
    "end": "1742880"
  },
  {
    "text": "record and it can range between 50 to 100 depending on the particular test",
    "start": "1742880",
    "end": "1749360"
  },
  {
    "text": "so these are pretty big data documents they're on average they're about 10",
    "start": "1749360",
    "end": "1755360"
  },
  {
    "text": "kilobytes now the other hot table was our test packet response this table is written as",
    "start": "1755360",
    "end": "1761919"
  },
  {
    "start": "1756000",
    "end": "1787000"
  },
  {
    "text": "the student answers each question we kept the test packet id as the hash key that's a very good one for us",
    "start": "1761919",
    "end": "1768960"
  },
  {
    "text": "and we introduced a range key with a test packet response id we have to be able to go in and find each individual",
    "start": "1768960",
    "end": "1775360"
  },
  {
    "text": "response that a student has uh answered a question on and then some of the other ones are",
    "start": "1775360",
    "end": "1781679"
  },
  {
    "text": "time stamp post date and then the response json is the actual json string",
    "start": "1781679",
    "end": "1787600"
  },
  {
    "start": "1787000",
    "end": "1799000"
  },
  {
    "text": "this is an example of that packet as you can see it's very small on average it's 195 bytes",
    "start": "1787600",
    "end": "1794720"
  },
  {
    "text": "so this was an excellent candidate for us in dynamodb",
    "start": "1794720",
    "end": "1800320"
  },
  {
    "start": "1799000",
    "end": "1871000"
  },
  {
    "text": "then next was our traffic patterns we have a test packet response",
    "start": "1800320",
    "end": "1805840"
  },
  {
    "text": "table which we've talked a little bit about and this is the workload that's provided when the students answer the",
    "start": "1805840",
    "end": "1810880"
  },
  {
    "text": "questions the peak uh the peak right performance that we needed was four thousand writes per",
    "start": "1810880",
    "end": "1816640"
  },
  {
    "text": "second now it's pretty elastic because the heat on here is unpredictable we couldn't really",
    "start": "1816640",
    "end": "1823919"
  },
  {
    "text": "find out well we didn't really know when it's going to be high and when it's going to be low",
    "start": "1823919",
    "end": "1829440"
  },
  {
    "text": "because that's when the students are answering the questions so we have an elastic provisioning put in place for about two thousand writes",
    "start": "1829440",
    "end": "1835919"
  },
  {
    "text": "per second to four thousand writes per second what the test packet answer our workload",
    "start": "1835919",
    "end": "1841039"
  },
  {
    "text": "was very different it was a read workload that was being pulled from our data warehouse so we had full uh control of this and so",
    "start": "1841039",
    "end": "1848399"
  },
  {
    "text": "we set it at 200 reads per second and that makes a nice consistent heat for us on this particular table the",
    "start": "1848399",
    "end": "1855600"
  },
  {
    "text": "big takeaway if there's something in your process that you can control control it",
    "start": "1855600",
    "end": "1860640"
  },
  {
    "text": "we don't want to spend a lot of money on on this particular piece of our application",
    "start": "1860640",
    "end": "1866559"
  },
  {
    "text": "and the other one is we had dynamic provisioning on those things that are very elastic",
    "start": "1866559",
    "end": "1872080"
  },
  {
    "start": "1871000",
    "end": "1879000"
  },
  {
    "text": "step two performance testing i wanted to make sure the dynamodb did what it said it would do",
    "start": "1872080",
    "end": "1877600"
  },
  {
    "text": "so we went ahead and put together a testing harness for this we have a test architecture which you",
    "start": "1877600",
    "end": "1883679"
  },
  {
    "start": "1879000",
    "end": "1913000"
  },
  {
    "text": "can see is pretty simple we have some load servers and then we also have a measurement server",
    "start": "1883679",
    "end": "1889600"
  },
  {
    "text": "we've done this this is kind of one of our best practices internally we've done it for years",
    "start": "1889600",
    "end": "1895679"
  },
  {
    "text": "i just want to highlight it here because it's really nice to have the load be put on the system by a different servers are",
    "start": "1895679",
    "end": "1902399"
  },
  {
    "text": "actually going to be taking the measurements we did not want to skew our measurement data we didn't want to skew",
    "start": "1902399",
    "end": "1907760"
  },
  {
    "text": "our latency data so we separated the load from the measurement and multiple servers did the job for us",
    "start": "1907760",
    "end": "1914960"
  },
  {
    "start": "1913000",
    "end": "1943000"
  },
  {
    "text": "our objectives with our test software was we wanted to make sure that we had an accurate synthetic workload so we",
    "start": "1914960",
    "end": "1922000"
  },
  {
    "text": "were tired of guessing and we wanted to make be a lot more systematic about it much more scientific",
    "start": "1922000",
    "end": "1928480"
  },
  {
    "text": "so we put together a test software that would provide that for us we had a replay engine again so",
    "start": "1928480",
    "end": "1934559"
  },
  {
    "text": "we could run it over and over and over without any problems and we wanted to see what our realistic models were doing",
    "start": "1934559",
    "end": "1939919"
  },
  {
    "text": "against all of our partitions so as ben mentioned we wanted to make sure that our keys were were widespread",
    "start": "1939919",
    "end": "1946559"
  },
  {
    "start": "1943000",
    "end": "2000000"
  },
  {
    "text": "as we ran these tests we chose to use a framework it's an open source framework called grinder i don't",
    "start": "1946559",
    "end": "1953679"
  },
  {
    "text": "know how many of you are familiar with that but it's basically designed for load and",
    "start": "1953679",
    "end": "1959519"
  },
  {
    "text": "performance testing we like using it because we can write our tests in jython jython is something that if",
    "start": "1959519",
    "end": "1967440"
  },
  {
    "text": "you haven't used it allows you to import java libraries so we we like jython a lot we also run",
    "start": "1967440",
    "end": "1974960"
  },
  {
    "text": "it as a single grinder process with multiple threads and then we allow the grinder framework",
    "start": "1974960",
    "end": "1980399"
  },
  {
    "text": "to capture any of the test metrics so they have some of those built in and then we write a command line utility",
    "start": "1980399",
    "end": "1986880"
  },
  {
    "text": "that goes through and parses those metrics that are saved by grinder so we don't have to continue to export them",
    "start": "1986880",
    "end": "1993360"
  },
  {
    "text": "into excel to do the analysis we can just run the test run our script and we have the information that we want",
    "start": "1993360",
    "end": "2001039"
  },
  {
    "text": "our test harness because we use grinder is also very simple our philosophy is is we don't want a lot",
    "start": "2001039",
    "end": "2006880"
  },
  {
    "text": "of moving parts we want to make sure that our our measurements are accurate and we want nothing to get in the way",
    "start": "2006880",
    "end": "2013279"
  },
  {
    "text": "there so we have grinder we have jython scripts and all of our clients that we",
    "start": "2013279",
    "end": "2018640"
  },
  {
    "text": "have here are actually written in java we know java has better performance than jython again we're looking at latency",
    "start": "2018640",
    "end": "2024960"
  },
  {
    "text": "numbers so we want to make sure that there's no performance issues introduced by the test harness",
    "start": "2024960",
    "end": "2030480"
  },
  {
    "text": "so each one of these clients makes a connection to dynamodb and it's the number of threads that run",
    "start": "2030480",
    "end": "2036320"
  },
  {
    "text": "and the number of requests that each thread makes that creates our synthetic workload against dynamodb for those for",
    "start": "2036320",
    "end": "2043120"
  },
  {
    "text": "those uh to collect those numbers while we were doing this ben mentioned",
    "start": "2043120",
    "end": "2048480"
  },
  {
    "text": "this i'm just going to hit on it again because i think it's really important especially if you're looking at milliseconds and with dynamodb when we",
    "start": "2048480",
    "end": "2055358"
  },
  {
    "text": "were looking at it we wanted to get down to as close as we could to what the actual",
    "start": "2055359",
    "end": "2061839"
  },
  {
    "text": "measurement cycle we make sure that we can understand what the garbage collector is doing heap size again is",
    "start": "2072960",
    "end": "2079040"
  },
  {
    "text": "important i my philosophy is don't starve the jvm but too much might",
    "start": "2079040",
    "end": "2085040"
  },
  {
    "text": "get get in the way so you have to experiment a little bit that and basically monitor the application so",
    "start": "2085040",
    "end": "2091760"
  },
  {
    "text": "garbage collection and heap size will impact your latency numbers as you perform these tests",
    "start": "2091760",
    "end": "2097040"
  },
  {
    "text": "analysis all right everything set up now the fun began so we started to run",
    "start": "2097040",
    "end": "2102880"
  },
  {
    "text": "our tests and uh this is one of my uh favorite slides",
    "start": "2102880",
    "end": "2108400"
  },
  {
    "start": "2103000",
    "end": "2224000"
  },
  {
    "text": "uh it it basically we started our test session and this wasn't the only test",
    "start": "2108400",
    "end": "2113839"
  },
  {
    "text": "session we did we did several because i wanted it repeatable this is just the one that i liked the best",
    "start": "2113839",
    "end": "2120640"
  },
  {
    "text": "we started out with a low provision and this is on the test packet answer table so this is with the larger",
    "start": "2120640",
    "end": "2127119"
  },
  {
    "text": "data records the 10 kilobytes and so we started off at about 300",
    "start": "2127119",
    "end": "2132320"
  },
  {
    "text": "with a provisioned read capacity and then we ran our load testing on our",
    "start": "2132320",
    "end": "2138160"
  },
  {
    "text": "our load servers during this time we let it stabilize for about 15 minutes and",
    "start": "2138160",
    "end": "2143520"
  },
  {
    "text": "then took a measurement then we upped the capacity waited a",
    "start": "2143520",
    "end": "2148720"
  },
  {
    "text": "little bit tuned the the testing client again and started our test again",
    "start": "2148720",
    "end": "2154079"
  },
  {
    "text": "the interesting part about this was um i felt the two things that i put",
    "start": "2154079",
    "end": "2159280"
  },
  {
    "text": "arrows on we saturated one of our load servers so we couldn't we just couldn't provide",
    "start": "2159280",
    "end": "2165520"
  },
  {
    "text": "any more load but i went hey i kind of like that let's take a measurement so we went a whole head and took a measurement there",
    "start": "2165520",
    "end": "2171839"
  },
  {
    "text": "we put another load server in our our uh our bank and then we bumped it up to about uh 5",
    "start": "2171839",
    "end": "2179359"
  },
  {
    "text": "000 reads per second and and then saw what happened now ben mentioned bursting and i just wanted to",
    "start": "2179359",
    "end": "2186400"
  },
  {
    "text": "show you this again it followed the same pattern that ben used it went up and then flat and then",
    "start": "2186400",
    "end": "2192400"
  },
  {
    "text": "came down as it began to throttle on the back end but i couldn't fit it into the the graph",
    "start": "2192400",
    "end": "2197760"
  },
  {
    "text": "so you're just gonna have to trust me on that one but it went up to about 5000 and it",
    "start": "2197760",
    "end": "2203040"
  },
  {
    "text": "stayed there for about five minutes and then it came back down so that is how bursting",
    "start": "2203040",
    "end": "2208720"
  },
  {
    "text": "worked for our test session and during this time i was able to monitor the",
    "start": "2208720",
    "end": "2213839"
  },
  {
    "text": "cloud watch um grasp very closely we did not have any throttling and our get",
    "start": "2213839",
    "end": "2219920"
  },
  {
    "text": "latency was very very consistent so i was all over it during this session",
    "start": "2219920",
    "end": "2225760"
  },
  {
    "start": "2224000",
    "end": "2271000"
  },
  {
    "text": "here are the graphs that came back from our client also the server and a p90",
    "start": "2225760",
    "end": "2232560"
  },
  {
    "text": "so the p90 is the client latency so what i liked about this is it actually was",
    "start": "2232560",
    "end": "2237680"
  },
  {
    "text": "better than i expected i've been looking at p90 graphs for a long time and this i was actually expecting it to be between",
    "start": "2237680",
    "end": "2244640"
  },
  {
    "text": "15 and 12 milliseconds it came in under that consistently the the next one there is the um",
    "start": "2244640",
    "end": "2253200"
  },
  {
    "text": "the average client latency which is the blue one and that fell right in the range that we wanted as well",
    "start": "2253200",
    "end": "2259359"
  },
  {
    "text": "so it was it was right at like 8.5 milliseconds so for our application that",
    "start": "2259359",
    "end": "2265520"
  },
  {
    "text": "was fantastic and then the server side latency was perfect it just followed that that line",
    "start": "2265520",
    "end": "2272480"
  },
  {
    "start": "2271000",
    "end": "2321000"
  },
  {
    "text": "directly some nice surprises so my my background is i've been working",
    "start": "2272480",
    "end": "2278640"
  },
  {
    "text": "in it for quite some time and i hate surprises but i actually",
    "start": "2278640",
    "end": "2284720"
  },
  {
    "text": "liked these one and that's why i'm going to mention them here the api documentation was accurate with",
    "start": "2284720",
    "end": "2290000"
  },
  {
    "text": "regards to dynamodb the sdk client worked as it was as i expected",
    "start": "2290000",
    "end": "2297280"
  },
  {
    "text": "they had solid sample code and also there was some really nice query methods inside of that sdk client that allowed",
    "start": "2297280",
    "end": "2304720"
  },
  {
    "text": "us to get access to our dynamodb very easily like i said we did not want to have a lot of spin up time with any of",
    "start": "2304720",
    "end": "2310880"
  },
  {
    "text": "this technology it's a robust technology with a reasonable learning curve so that's why",
    "start": "2310880",
    "end": "2317200"
  },
  {
    "text": "we went with it in summary these are just a few things to remember",
    "start": "2317200",
    "end": "2324320"
  },
  {
    "text": "understand data and traffic patterns so make sure that as you go ahead and design your dynamodb tables your",
    "start": "2324320",
    "end": "2331440"
  },
  {
    "text": "applications um a lot of the things the best practices that ben mentioned make sure you understand those data and",
    "start": "2331440",
    "end": "2338079"
  },
  {
    "text": "the workloads for each one of those tables capacity provisioning",
    "start": "2338079",
    "end": "2343119"
  },
  {
    "text": "make sure you understand the math associated with that especially if your packets are large",
    "start": "2343119",
    "end": "2348240"
  },
  {
    "text": "your records are large over 4kb and over 1kb for writes make sure",
    "start": "2348240",
    "end": "2354240"
  },
  {
    "text": "you understand how to provision that capacity if you have inexplicable latencies within your app server or your testing",
    "start": "2354240",
    "end": "2361520"
  },
  {
    "text": "harness make sure you investigate the jvm tune it and set it accordingly check",
    "start": "2361520",
    "end": "2367440"
  },
  {
    "text": "the throttling graphs and the performance tests on the back end as well and then also optimize the data schema",
    "start": "2367440",
    "end": "2373920"
  },
  {
    "text": "and the keys so for us we use the test packet id and that was a very good key for us it had",
    "start": "2373920",
    "end": "2380240"
  },
  {
    "text": "wide distribution and while we were doing these tests actually we used real",
    "start": "2380240",
    "end": "2385280"
  },
  {
    "text": "data and we used 10 000 different student records 10 000 different test packet ids to get a good key",
    "start": "2385280",
    "end": "2391760"
  },
  {
    "text": "distribution across all of our partitions so keep the data table structure as simple as you possibly can",
    "start": "2391760",
    "end": "2400720"
  },
  {
    "start": "2399000",
    "end": "2448000"
  },
  {
    "text": "in closing i just want to say that i am very excited to be in this industry i",
    "start": "2400720",
    "end": "2405839"
  },
  {
    "text": "love what i do i love my job and it's neat to have a company this",
    "start": "2405839",
    "end": "2411040"
  },
  {
    "text": "isn't a pitch and they're not paying me to say this but i want to say it anyway because i'm a hard customer",
    "start": "2411040",
    "end": "2416880"
  },
  {
    "text": "i'm very picky on the technology that i choose as you can see i look at it very closely but it's nice to have a company",
    "start": "2416880",
    "end": "2422880"
  },
  {
    "text": "come out and provide services and technologies that actually help me grow",
    "start": "2422880",
    "end": "2428160"
  },
  {
    "text": "my business i don't want to worry about the services i don't want to worry about the infrastructure what i want to do is",
    "start": "2428160",
    "end": "2433839"
  },
  {
    "text": "get more students taking tests so i can put more money in my account and that's really what i want to do and this and",
    "start": "2433839",
    "end": "2440400"
  },
  {
    "text": "amazon helps me to do that especially with dynamodb thank you very much",
    "start": "2440400",
    "end": "2446920"
  }
]
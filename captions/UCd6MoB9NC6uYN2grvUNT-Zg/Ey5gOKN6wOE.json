[
  {
    "start": "0",
    "end": "129000"
  },
  {
    "text": "my name is Paul Armstrong and I'm a Solutions Architect working here out of",
    "start": "30",
    "end": "5430"
  },
  {
    "text": "the UK and in this session today I'm going to talk through how you can make",
    "start": "5430",
    "end": "11429"
  },
  {
    "text": "use of video and in particular focusing on ingesting storing and the challenges",
    "start": "11429",
    "end": "17340"
  },
  {
    "text": "around archiving I'm not going to look at things like mass distribution and we're also going to look at some of the",
    "start": "17340",
    "end": "24269"
  },
  {
    "text": "more advanced use cases of how you can actually do some ML analytics on top of",
    "start": "24269",
    "end": "30449"
  },
  {
    "text": "these types of use cases that we're going to be a couple of demos we will see how they go but the but the",
    "start": "30449",
    "end": "36329"
  },
  {
    "text": "connectivity isn't what I was hoping in terms of the session in terms of the session I am going to be showing some",
    "start": "36329",
    "end": "43200"
  },
  {
    "text": "code I recognize this is a big room but the codes more about showing the sequence of events and the connectivity",
    "start": "43200",
    "end": "49320"
  },
  {
    "text": "of the different services so if anyone does want to touch base in more detail about the code please PLEASE talk to me",
    "start": "49320",
    "end": "56010"
  },
  {
    "text": "afterwards so when you're talking about video ingestion I always want to start",
    "start": "56010",
    "end": "63989"
  },
  {
    "text": "talking to customers about this I go back to our basic pipeline for management of data within the data like",
    "start": "63989",
    "end": "70020"
  },
  {
    "text": "you require a mechanism for how you're going to collect your data how you're",
    "start": "70020",
    "end": "75270"
  },
  {
    "text": "going to store it what processing you're going to do on it what ETL processes you're going to run on it how you're going to consume so",
    "start": "75270",
    "end": "82080"
  },
  {
    "text": "visualize your data this is something that everyone's fairly comfortable with",
    "start": "82080",
    "end": "88380"
  },
  {
    "text": "you do this quite frequently with transactional data we do it with log data but what we're seeing now is more",
    "start": "88380",
    "end": "95700"
  },
  {
    "text": "and more devices coming online where we want to get analytics and capture that useful information out of those data",
    "start": "95700",
    "end": "103140"
  },
  {
    "text": "streams so for example we're talking about video in this session but voice voice is just important you now want to",
    "start": "103140",
    "end": "110130"
  },
  {
    "text": "transcribe voices you want to do sentiment analysis on maybe your contact",
    "start": "110130",
    "end": "115200"
  },
  {
    "text": "center recordings so suddenly what we're really looking for is very very different sources of information to feed",
    "start": "115200",
    "end": "121950"
  },
  {
    "text": "into our data Lake and how we can post that process them now",
    "start": "121950",
    "end": "127969"
  },
  {
    "text": "last year at reinvent we announced Kinesis video streams and one of the",
    "start": "128899",
    "end": "136020"
  },
  {
    "start": "129000",
    "end": "129000"
  },
  {
    "text": "challenges we've been seeing with our customers is when they're running solutions such as CCTV how do you",
    "start": "136020",
    "end": "143340"
  },
  {
    "text": "actually integrate all of your devices and store your CCTV footage at scale",
    "start": "143340",
    "end": "150110"
  },
  {
    "text": "it's really difficult to scale to millions of devices how do you support the different cadency the latency the",
    "start": "150110",
    "end": "157530"
  },
  {
    "text": "different firmwares the different cameras and how to make this into highly scalable highly available storage",
    "start": "157530",
    "end": "163430"
  },
  {
    "text": "something that you're used to using with other AWS services but also you need to",
    "start": "163430",
    "end": "169560"
  },
  {
    "text": "integrate it into the security and you need easy-to-use api's to actually retrieve process and replay video so",
    "start": "169560",
    "end": "177890"
  },
  {
    "text": "Kinesis video streams came the objective of commission Kinesis video streams was",
    "start": "177890",
    "end": "183690"
  },
  {
    "text": "about how can you stream the video from millions of devices make it easy to build these applications and integrate",
    "start": "183690",
    "end": "190500"
  },
  {
    "text": "it in as we we showed on the opening slide with the data light to the analytical tools that you're used to",
    "start": "190500",
    "end": "196709"
  },
  {
    "text": "using now it's got to be secure durable and fully managed so when you look at",
    "start": "196709",
    "end": "205140"
  },
  {
    "start": "203000",
    "end": "203000"
  },
  {
    "text": "the pipeline for Canisius video streams it follows the standard data collection",
    "start": "205140",
    "end": "210390"
  },
  {
    "text": "process you need a producer your producer needs to be able to take the",
    "start": "210390",
    "end": "215579"
  },
  {
    "text": "camera from your device in this case a camera and send it through the Kinesis video stream now this is slightly",
    "start": "215579",
    "end": "222420"
  },
  {
    "text": "different from those of you that used to using Canisius in that the producers are very very much designed for high",
    "start": "222420",
    "end": "229019"
  },
  {
    "text": "throughput so they're very very specialized then you have the Kinesis video stream itself how do you actually consume that",
    "start": "229019",
    "end": "235859"
  },
  {
    "text": "data maybe you need to look consume it in real time maybe you need to store it",
    "start": "235859",
    "end": "241560"
  },
  {
    "text": "and index it and access it securely and then you might need custom applications maybe sharing that data with third",
    "start": "241560",
    "end": "249720"
  },
  {
    "text": "parties so if we start at the beginning of the pipeline and work through",
    "start": "249720",
    "end": "256250"
  },
  {
    "start": "252000",
    "end": "252000"
  },
  {
    "text": "Canisius video streams producer sdk this is all about how can you connect",
    "start": "256250",
    "end": "262590"
  },
  {
    "text": "and stream from different camera sources it's got to be flexible you may already",
    "start": "262590",
    "end": "268560"
  },
  {
    "text": "have thousands and thousands of devices how can you integrate them into the producer SDK it's got to support",
    "start": "268560",
    "end": "275310"
  },
  {
    "text": "out-of-the-box integration with AWS as you would expect for using any of the other api's it's got to be able to put",
    "start": "275310",
    "end": "282629"
  },
  {
    "text": "stream frames or buffered fragments onto the onto the string so it could be that there's a buffered delay it could be",
    "start": "282629",
    "end": "289860"
  },
  {
    "text": "that you're trying to stream in real time but then you want to be able to build those custom integrations using",
    "start": "289860",
    "end": "296190"
  },
  {
    "text": "the tools that you're familiar with and a secure way but still be streaming that video data but on your preferred",
    "start": "296190",
    "end": "303690"
  },
  {
    "text": "transmission scenario it could be one-to-one or it could be that you're passing this into something with where",
    "start": "303690",
    "end": "310020"
  },
  {
    "text": "you've got mass distribution where you're using services such as elemental",
    "start": "310020",
    "end": "315409"
  },
  {
    "start": "315000",
    "end": "315000"
  },
  {
    "text": "so what are your ingestion options well you can stream directly from the camera",
    "start": "315409",
    "end": "321210"
  },
  {
    "text": "and we've got partners such as vivi√≥ tech they're actually now putting drivers and our producers on their",
    "start": "321210",
    "end": "328050"
  },
  {
    "text": "cameras so you can stream directly to Kinesis video streams if you already",
    "start": "328050",
    "end": "333479"
  },
  {
    "text": "have IP cameras what you can do is you can put in place a proxy put in a local",
    "start": "333479",
    "end": "339659"
  },
  {
    "text": "proxy and rather than actually storing the data locally across those cameras you can actually stream it to the video",
    "start": "339659",
    "end": "346500"
  },
  {
    "text": "streams and then don't have it for the long-term durable storage and analytics or you can do some analysis at the edge",
    "start": "346500",
    "end": "353909"
  },
  {
    "text": "so you can look at how can I do the processing and only actually stream data like when I need to so if I have a use",
    "start": "353909",
    "end": "362129"
  },
  {
    "text": "case for example with detecting faces and we're going to explore that later on run that processing on the camera and",
    "start": "362129",
    "end": "367979"
  },
  {
    "text": "only actually pay for your downstream processing when the objects of interest",
    "start": "367979",
    "end": "373610"
  },
  {
    "text": "within the camera frame now Kinesis",
    "start": "373610",
    "end": "379020"
  },
  {
    "text": "video streams it's really important that it transports video data and then let's",
    "start": "379020",
    "end": "384150"
  },
  {
    "text": "work with video data most that this is quite complex you've got to manage your frames you've got to manage your",
    "start": "384150",
    "end": "389520"
  },
  {
    "text": "fragment but also this needs to be durable and so it needs to be able to be",
    "start": "389520",
    "end": "394889"
  },
  {
    "text": "supported in real time and in ad hoc for archiving and the way Canisius video",
    "start": "394889",
    "end": "400410"
  },
  {
    "text": "streams are designed is it's maybe different from people who are used to using other Kinesis variants is that you",
    "start": "400410",
    "end": "407370"
  },
  {
    "text": "have a single producer publishing data to a single Kinesis video stream your",
    "start": "407370",
    "end": "412889"
  },
  {
    "text": "producer has to be a hub have the capability to securely put the data on to the stream and this can be from",
    "start": "412889",
    "end": "418980"
  },
  {
    "text": "multiple hardware devices can be from security cameras which we're focusing a lot on in this talk but it can be body",
    "start": "418980",
    "end": "425310"
  },
  {
    "text": "cameras smart phones various other devices and then you have your consumers",
    "start": "425310",
    "end": "431010"
  },
  {
    "text": "how are you actually going to take the data process it and analyze it off the streams so one of the scenarios that",
    "start": "431010",
    "end": "440100"
  },
  {
    "text": "I've been talking to customers about Eliza I work in the UK with travel and",
    "start": "440100",
    "end": "445169"
  },
  {
    "text": "transport and regularly when there are security incidents they need mechanisms",
    "start": "445169",
    "end": "450540"
  },
  {
    "text": "for how they can securely and quickly she had shared data with the third-party",
    "start": "450540",
    "end": "456360"
  },
  {
    "text": "security services so this is an example of that process where you have your",
    "start": "456360",
    "end": "463140"
  },
  {
    "text": "producer from your camera maybe it's on camera maybe it's for a proxy it's putting that data onto the video stream",
    "start": "463140",
    "end": "469320"
  },
  {
    "text": "and then what we're doing is a very very simple process of actually retrieving that video data from the stream so in",
    "start": "469320",
    "end": "477690"
  },
  {
    "text": "this case we're using HTML and API gateway to pull the lambda to get the data so we'll just take a look at how",
    "start": "477690",
    "end": "484710"
  },
  {
    "text": "this works just to show the simplicity of how quickly you can share this data",
    "start": "484710",
    "end": "491120"
  },
  {
    "text": "apologies for the image but I can only have an approved image of me so we can find any models in the time frame so so",
    "start": "491780",
    "end": "499260"
  },
  {
    "text": "what this is doing here is something that you're familiar with it's doing a just a just a list streams so it's",
    "start": "499260",
    "end": "506039"
  },
  {
    "text": "calling Canisius video streams API and it's actually listing all the streams",
    "start": "506039",
    "end": "511110"
  },
  {
    "text": "I'm authorized to say so you can see that you could authenticate your users by Cognito give them access to via roles",
    "start": "511110",
    "end": "518940"
  },
  {
    "text": "to the streams that they have access to and produce the list so here I've got three streams a deep lens and IP cameras",
    "start": "518940",
    "end": "526360"
  },
  {
    "text": "and a web-camera stream then I'm actually passing in the time and",
    "start": "526360",
    "end": "532329"
  },
  {
    "text": "duration to the stream of the footage that I need so I create an endpoint on",
    "start": "532329",
    "end": "537970"
  },
  {
    "text": "the API and then make the call to that endpoint to retrieve my archive media",
    "start": "537970",
    "end": "543130"
  },
  {
    "text": "and I'm pulling the data from it from the payload and storing the mp4 output",
    "start": "543130",
    "end": "548410"
  },
  {
    "text": "in s3 then with that output stored in s3 I just generate a pre signed URL which",
    "start": "548410",
    "end": "555880"
  },
  {
    "text": "I'm then passing back to the HTML page now you're starting to see how suddenly you've now got your data in s3",
    "start": "555880",
    "end": "563680"
  },
  {
    "text": "and how easy that is to share with third parties you can write custom applications so that third parties could",
    "start": "563680",
    "end": "570399"
  },
  {
    "text": "have direct access to their streams or there are other other approaches so one",
    "start": "570399",
    "end": "578589"
  },
  {
    "text": "of the things that you want to do with video is you want to actually do analysis and maybe you want to start to",
    "start": "578589",
    "end": "585850"
  },
  {
    "text": "get the data insights that are captured in your image collections and in your video collections and we announced back",
    "start": "585850",
    "end": "594430"
  },
  {
    "text": "in 2016 recognition now recognition is really important for doing analysis of",
    "start": "594430",
    "end": "601810"
  },
  {
    "text": "video for of individual frames so we're talking about images in this case objects in scene detection being able to",
    "start": "601810",
    "end": "609970"
  },
  {
    "text": "from an image capture the metadata about what objects are in the scene or what",
    "start": "609970",
    "end": "615310"
  },
  {
    "text": "what what the scene is facing analysis on this talk we're going to focus predominately on facial analysis but",
    "start": "615310",
    "end": "621459"
  },
  {
    "text": "we're looking at what faces are in the frame and can do comparison of faces so",
    "start": "621459",
    "end": "627910"
  },
  {
    "text": "you can actually take the feature sets from faces and do comparisons and do",
    "start": "627910",
    "end": "633279"
  },
  {
    "text": "facial recognition so upload faces and actually do comparisons of those faces",
    "start": "633279",
    "end": "639010"
  },
  {
    "text": "against the facial recognition and some of the newer features that have been added to recognition to those you from",
    "start": "639010",
    "end": "646300"
  },
  {
    "text": "the original announcements is we now have the ability to do celebrity recognition so this is about actually",
    "start": "646300",
    "end": "652329"
  },
  {
    "text": "finding celebrities and tracking celebrities and there's a few use cases where large events this is quite",
    "start": "652329",
    "end": "657970"
  },
  {
    "text": "interesting and of course image moderation having collections of images and looking for",
    "start": "657970",
    "end": "663750"
  },
  {
    "text": "inappropriate images which is really important so celebrity recognition the",
    "start": "663750",
    "end": "671850"
  },
  {
    "text": "way this process works is you upload the image as we've done previously and you get returned back the JSON data showing",
    "start": "671850",
    "end": "678960"
  },
  {
    "text": "you the information on the celebrity face where the face was detected the bounding box and information on the",
    "start": "678960",
    "end": "686160"
  },
  {
    "text": "probability of who the celebrity is and",
    "start": "686160",
    "end": "690740"
  },
  {
    "text": "we have customers that have been using this facility such as c-span in the u.s.",
    "start": "691190",
    "end": "696660"
  },
  {
    "text": "who in three weeks were able to Windex against ninety nine thousand people so",
    "start": "696660",
    "end": "703200"
  },
  {
    "text": "this index was created in a day and it was saving nine thousand hours a year in",
    "start": "703200",
    "end": "708590"
  },
  {
    "text": "curation costs so this was a manually intensive process that could be automated very very quickly just we're",
    "start": "708590",
    "end": "716100"
  },
  {
    "text": "doing frame sampling from no existing video streams and if you look at the architecture you can see that it's very",
    "start": "716100",
    "end": "722940"
  },
  {
    "text": "very straightforward you have your camera encoders you're extracting your stills and once you've extracted your",
    "start": "722940",
    "end": "729240"
  },
  {
    "text": "stills you're putting them in s3 once they're in s/3 s/3 events our own",
    "start": "729240",
    "end": "734850"
  },
  {
    "text": "triggering for downstream processing they're calling recognition and any of",
    "start": "734850",
    "end": "740580"
  },
  {
    "text": "the recognized results are again being stored into s3 where they can be accessed by the end users now this is",
    "start": "740580",
    "end": "747330"
  },
  {
    "text": "one use case but another use case probably that as closer to home is some",
    "start": "747330",
    "end": "753510"
  },
  {
    "text": "of us might be aware that there's a wedding happening in the not-so-distant future and in the Royal Wedding sky have",
    "start": "753510",
    "end": "761670"
  },
  {
    "text": "announced that they're going to be using Canisius video streams and recognition for actually capturing the celebrities",
    "start": "761670",
    "end": "767580"
  },
  {
    "text": "that are appearing in the Royal Wedding so you can on their lives on their live",
    "start": "767580",
    "end": "772680"
  },
  {
    "text": "feed you're actually going to see the names being put forward of known celebrities so they're using that for",
    "start": "772680",
    "end": "779280"
  },
  {
    "text": "the tracking to help enhance that customer experience and their coverage of the royal wedding",
    "start": "779280",
    "end": "785360"
  },
  {
    "text": "now I was going to try and show a demo here of this running but looking at the",
    "start": "785360",
    "end": "790860"
  },
  {
    "text": "way that the Wi-Fi is running I won't I'm not going I'm not brave enough to attempt it but what we were actually",
    "start": "790860",
    "end": "797910"
  },
  {
    "text": "doing was I had I wanted to show the simplicity of actually using the",
    "start": "797910",
    "end": "803130"
  },
  {
    "text": "recognition API so on a single HTML page of a few lines of code what we're doing",
    "start": "803130",
    "end": "810360"
  },
  {
    "text": "is taking a snapshot of a face from that face capturing the metadata in terms of",
    "start": "810360",
    "end": "817589"
  },
  {
    "text": "information about a my mail and my female am I wearing glasses etc and also",
    "start": "817589",
    "end": "824070"
  },
  {
    "text": "I was doing a validation of that image against the stored stored set of images so am I in Amazonia",
    "start": "824070",
    "end": "830610"
  },
  {
    "text": "am i in the collection of people of the staff that are working for AWS and so",
    "start": "830610",
    "end": "836490"
  },
  {
    "text": "this code sounds like it's really complicated but actually it's very very straightforward I know we start with",
    "start": "836490",
    "end": "842880"
  },
  {
    "text": "this to sort of introduce how you would then use recognition to put into your more complex downstream processes so",
    "start": "842880",
    "end": "852360"
  },
  {
    "text": "what's happening well basically all that's happening is on the camera on the",
    "start": "852360",
    "end": "857580"
  },
  {
    "text": "map I was taking an image blob the image blob I was then passing through by the",
    "start": "857580",
    "end": "863339"
  },
  {
    "text": "parameters into recognition detect faces what recognition then does is return",
    "start": "863339",
    "end": "869880"
  },
  {
    "text": "that metadata about the image so you can see it's got the face detail or is the",
    "start": "869880",
    "end": "875070"
  },
  {
    "text": "bounding box on the face what was the age range of the face that was detected other information such as a smile am i",
    "start": "875070",
    "end": "882810"
  },
  {
    "text": "wearing eyeglasses am i wearing sunglasses have I a beard and a mustache and so forth",
    "start": "882810",
    "end": "889430"
  },
  {
    "text": "and then when I'm doing a search against the collection all I'm doing is searching for a face in a known",
    "start": "889650",
    "end": "895890"
  },
  {
    "text": "collection so I pass it a collection ID in this case Amazon and I search the faces by the image again passing in that",
    "start": "895890",
    "end": "902820"
  },
  {
    "text": "blob from the image to see if I find any any records now this is just using the",
    "start": "902820",
    "end": "910580"
  },
  {
    "text": "JavaScript SDK on an HTML page so a single page just on on on the polling",
    "start": "910580",
    "end": "918270"
  },
  {
    "text": "and actually showing the information in real time captured now that's quite",
    "start": "918270",
    "end": "925170"
  },
  {
    "text": "simple but actually that's not very efficient because you're processing continually in this case it's on a 500",
    "start": "925170",
    "end": "932130"
  },
  {
    "text": "millisecond link which is partly why the Wi-Fi is not dealing with it works very well but that's not very efficient",
    "start": "932130",
    "end": "939029"
  },
  {
    "text": "because you're paying for all of those calls to recognition regardless of whether you actually need that",
    "start": "939029",
    "end": "944190"
  },
  {
    "text": "information now there are other are more advanced use cases for recognition where",
    "start": "944190",
    "end": "950850"
  },
  {
    "start": "946000",
    "end": "946000"
  },
  {
    "text": "you start to introduce them into your decision trees and your processing pipelines so most use cases require more",
    "start": "950850",
    "end": "958709"
  },
  {
    "text": "than just capturing basic metadata about your users so you can see that you're",
    "start": "958709",
    "end": "964980"
  },
  {
    "text": "the captain information can trigger downstream events maybe by s3 event",
    "start": "964980",
    "end": "969990"
  },
  {
    "text": "notifications maybe vile aMDA maybe even by a step function and examples of using",
    "start": "969990",
    "end": "976290"
  },
  {
    "text": "dynamodb for storing of that information as well now in in the example that we",
    "start": "976290",
    "end": "981810"
  },
  {
    "text": "have later on with the deep lens i will show how we're sort of bringing all of these downstream processes together but",
    "start": "981810",
    "end": "989220"
  },
  {
    "text": "simple kept news cases though as we touched on as a story with sky is the persons of interest near a celebrity you",
    "start": "989220",
    "end": "996420"
  },
  {
    "text": "can do multi pass motion detection enhancements so you're looking at how do you actually do more intelligence into",
    "start": "996420",
    "end": "1002570"
  },
  {
    "text": "the end devices and we're touched on that bit later on in the closing examples and also you can maybe start to",
    "start": "1002570",
    "end": "1009500"
  },
  {
    "text": "have use cases again from a travel and transport scenario of people may be going into into buildings and then",
    "start": "1009500",
    "end": "1015709"
  },
  {
    "text": "leaving and not not leaving behind possessions this could flag something of",
    "start": "1015709",
    "end": "1021050"
  },
  {
    "text": "interest to the security authorities so when you're",
    "start": "1021050",
    "end": "1027678"
  },
  {
    "text": "talking about these collections what what you're now doing is talking about how do you actually store collections of",
    "start": "1027679",
    "end": "1034400"
  },
  {
    "text": "images that can be processed by a recognition so here's some examples of",
    "start": "1034400",
    "end": "1039829"
  },
  {
    "text": "using the API so we're calling the create collection and we're creating a collection called persons of interest",
    "start": "1039829",
    "end": "1045880"
  },
  {
    "text": "and then all we're doing is calling the recognition API on index faces passing",
    "start": "1045880",
    "end": "1052460"
  },
  {
    "text": "it an image and adding it to that collection ID none of the covers what",
    "start": "1052460",
    "end": "1058130"
  },
  {
    "text": "recognition is doing is processing that image indexing it capturing out all of",
    "start": "1058130",
    "end": "1063440"
  },
  {
    "text": "the features that will then use when you do subsequent comparisons against that collection it's not actually storing the",
    "start": "1063440",
    "end": "1071450"
  },
  {
    "text": "image itself it's the storing metadata about the image and the primary key which is its external identifier and you",
    "start": "1071450",
    "end": "1079309"
  },
  {
    "text": "can see for the recognized celebrities very very simple call you call the recognized celebrities API API and pass",
    "start": "1079309",
    "end": "1087860"
  },
  {
    "text": "in the image and it will give you a return of the level of confidence of a celebrity that's been recognized and as",
    "start": "1087860",
    "end": "1093890"
  },
  {
    "text": "we touched on when we're searching the collections you can see how we're searching faces by the image and",
    "start": "1093890",
    "end": "1099200"
  },
  {
    "text": "searching in the collection ID for the point persons of interest so the",
    "start": "1099200",
    "end": "1107059"
  },
  {
    "start": "1105000",
    "end": "1105000"
  },
  {
    "text": "evolution of this and these were some of the new features that were announced in reinvent last year exam as it Amazon",
    "start": "1107059",
    "end": "1114380"
  },
  {
    "text": "recognition video because the behavior view is very different in front of a",
    "start": "1114380",
    "end": "1120440"
  },
  {
    "text": "still camera to in front of a video traditionally with a camera you stop and",
    "start": "1120440",
    "end": "1125929"
  },
  {
    "text": "you smile and maybe you pose whereas with video it tends to be a lot more natural interaction so again",
    "start": "1125929",
    "end": "1132470"
  },
  {
    "text": "there's the objects in activity detection there's some other interesting features like person Trucking's have",
    "start": "1132470",
    "end": "1138770"
  },
  {
    "text": "been able to track individuals as they're moving through the frames in the video again facial recognition against",
    "start": "1138770",
    "end": "1146299"
  },
  {
    "text": "known collections as we've been talking about and real-time live streaming so at",
    "start": "1146299",
    "end": "1151970"
  },
  {
    "text": "sea now you can start searching for on your real-time streaming so for",
    "start": "1151970",
    "end": "1157250"
  },
  {
    "text": "example if you have people of known interest you can start searching real-time feeds for when they've",
    "start": "1157250",
    "end": "1162560"
  },
  {
    "text": "appeared on cameras again a use case that we've been talking to with travel",
    "start": "1162560",
    "end": "1168380"
  },
  {
    "text": "and transport with working with the security services and of course the unsafe video detection and the celebrity",
    "start": "1168380",
    "end": "1174710"
  },
  {
    "text": "recognition detection but the difference here is what you're now doing is you're running a recognition video stream",
    "start": "1174710",
    "end": "1182120"
  },
  {
    "text": "processor alongside a normal stream a video stream rather than you having to",
    "start": "1182120",
    "end": "1188690"
  },
  {
    "text": "extract the frames and sending the individual frames through to recognition",
    "start": "1188690",
    "end": "1194650"
  },
  {
    "text": "so in this example here you can see that what's happening is the objects have",
    "start": "1194650",
    "end": "1200210"
  },
  {
    "text": "been detected in the frame and the individual people are all being tracked as they move through the frames so what",
    "start": "1200210",
    "end": "1207980"
  },
  {
    "text": "you're now seeing is you've got that frame by frame analysis capturing if the recognition of people and then the",
    "start": "1207980",
    "end": "1214640"
  },
  {
    "text": "recognition of moving of those people through the through the frames so use",
    "start": "1214640",
    "end": "1221390"
  },
  {
    "text": "cases for this you can see that for those of you that may be aware we've",
    "start": "1221390",
    "end": "1226880"
  },
  {
    "text": "launched Amazon go over in Seattle and amazon go is one of our stores where you",
    "start": "1226880",
    "end": "1232220"
  },
  {
    "text": "actually walk in you scan your phone you walk around you pick up the items off",
    "start": "1232220",
    "end": "1237830"
  },
  {
    "text": "the shelf put them in your bag walk out and they're automatically added to your basket and you're charged when you leave",
    "start": "1237830",
    "end": "1244250"
  },
  {
    "text": "the sole and this is what you can see where this technology is coming from in",
    "start": "1244250",
    "end": "1249950"
  },
  {
    "text": "that you're running image arrays in the ceiling to actually deal with the tracking of individuals and also the",
    "start": "1249950",
    "end": "1255770"
  },
  {
    "text": "actions that they're taking within the frames so you can see that there's use cases for CCTV for building entry you",
    "start": "1255770",
    "end": "1262970"
  },
  {
    "text": "can see that one of the use cases that we've been working with is when you've got on building sites making sure that",
    "start": "1262970",
    "end": "1268280"
  },
  {
    "text": "all of the people are actually on the building site they're authorized to be there or authorised to have the relevant",
    "start": "1268280",
    "end": "1274370"
  },
  {
    "text": "safety credentials other interesting ones are for example trespassing on the",
    "start": "1274370",
    "end": "1280580"
  },
  {
    "text": "railway track if you detect a human on a railway track I cause it's most of us",
    "start": "1280580",
    "end": "1285920"
  },
  {
    "text": "who travel by train here in the south know that any impact on the rail network causes significant disruption and",
    "start": "1285920",
    "end": "1293080"
  },
  {
    "text": "actually if you think about being able to detect for trespassers on the railways earlier and to take mitigating",
    "start": "1293080",
    "end": "1301190"
  },
  {
    "text": "action it could help with with reducing some of that disruption we've touched on looking for celebrities and there's lots",
    "start": "1301190",
    "end": "1308000"
  },
  {
    "text": "of interesting use cases now about working out who's at the front door and you actually want to go and answer the",
    "start": "1308000",
    "end": "1313310"
  },
  {
    "text": "front door now so you can see what if you were to take the scenario of who's",
    "start": "1313310",
    "end": "1318740"
  },
  {
    "text": "at the front door you're starting to see a common pattern emerge in terms of all of these use cases what you're seeing is",
    "start": "1318740",
    "end": "1325850"
  },
  {
    "text": "you have a live street camera you have your producer application streaming it to a video stream you may set that video",
    "start": "1325850",
    "end": "1332870"
  },
  {
    "text": "stream to only be archiving for a few hours or you may decide you want to keep it for last 24 hours",
    "start": "1332870",
    "end": "1338810"
  },
  {
    "text": "running out recognition video stream on that continually and sending out alerts",
    "start": "1338810",
    "end": "1344150"
  },
  {
    "text": "so what happens is the recognition video stream detects a known face and then",
    "start": "1344150",
    "end": "1349850"
  },
  {
    "text": "sends out to a traditional Canisius data stream that that face has been detected you can employ this that via lamda and",
    "start": "1349850",
    "end": "1357290"
  },
  {
    "text": "maybe send out an SMS message by yes and s service so when you look at the",
    "start": "1357290",
    "end": "1363560"
  },
  {
    "text": "workflow what are you doing and you're starting to see this is getting repetitive or home.you index the faces",
    "start": "1363560",
    "end": "1370700"
  },
  {
    "text": "and you create a recognition face collection for doing the matching you create your video stream that you're",
    "start": "1370700",
    "end": "1376190"
  },
  {
    "text": "actually going to put your stream onto you create your recognition stream processor and as you can see in that",
    "start": "1376190",
    "end": "1382130"
  },
  {
    "text": "logic on the right what you're doing is you create that stream processor you tell it what your input stream is you",
    "start": "1382130",
    "end": "1389330"
  },
  {
    "text": "tell it what the output stream is where you want to put the results of known matches and you tell it the collection",
    "start": "1389330",
    "end": "1395720"
  },
  {
    "text": "that you're searching against so you can see now how you're you're comparing videos and you've got two stream",
    "start": "1395720",
    "end": "1401360"
  },
  {
    "text": "processors running together and whenever a hit is found it produces JSON similar",
    "start": "1401360",
    "end": "1407120"
  },
  {
    "text": "to that in the bottom right hand corner showing you the search response showing",
    "start": "1407120",
    "end": "1412250"
  },
  {
    "text": "you the detective face again where the bounding box says similarity match and external image ID so you can maybe look",
    "start": "1412250",
    "end": "1419519"
  },
  {
    "text": "up that image from somewhere where you're storing it in s3 so again what's",
    "start": "1419519",
    "end": "1426299"
  },
  {
    "start": "1424000",
    "end": "1424000"
  },
  {
    "text": "the requirements for your application code you need a producer you need your video data generating device and on that",
    "start": "1426299",
    "end": "1433139"
  },
  {
    "text": "you then need to be using your producer library currently the Covidien Kinesis video streams has producer libraries for",
    "start": "1433139",
    "end": "1440339"
  },
  {
    "text": "Java for Android and for C++ and these have been developed all of the time and",
    "start": "1440339",
    "end": "1446009"
  },
  {
    "text": "you can see now that you've got your custom application in this case it's a lambda function running Python and this",
    "start": "1446009",
    "end": "1452219"
  },
  {
    "text": "is triggered by data arriving on the Canisius data stream but that downstream processing is very",
    "start": "1452219",
    "end": "1457619"
  },
  {
    "text": "very similar to the analytics that you're doing today now I was going to",
    "start": "1457619",
    "end": "1463950"
  },
  {
    "text": "show a demo of the deep lens but there is one here but unfortunately we're having trouble with the connectivity so",
    "start": "1463950",
    "end": "1471029"
  },
  {
    "text": "I will walk through how the solutions working and if this time maybe we'll see at the end if we can we can get it",
    "start": "1471029",
    "end": "1477210"
  },
  {
    "text": "connected on so what is deep lens deep lens was something that we announced",
    "start": "1477210",
    "end": "1483029"
  },
  {
    "text": "back in reinvent last year and deep lens is really about helping you start to",
    "start": "1483029",
    "end": "1488669"
  },
  {
    "text": "look at your machine learning and how can you actually start to experiment and deploy your machine learning models to",
    "start": "1488669",
    "end": "1495419"
  },
  {
    "text": "the edge so it's a complete is it just has compute capability of running your",
    "start": "1495419",
    "end": "1501330"
  },
  {
    "text": "deep learning models on the actual camera itself and it can perform inference at the edge so all the use",
    "start": "1501330",
    "end": "1508529"
  },
  {
    "text": "cases we've been talking about to date have all been around capturing how to",
    "start": "1508529",
    "end": "1514529"
  },
  {
    "text": "actually stream data continually in archive and story what if you don't want to do that what if your use case is I",
    "start": "1514529",
    "end": "1521219"
  },
  {
    "text": "only want to transmit data when I've detected a face in the frame so how can",
    "start": "1521219",
    "end": "1527580"
  },
  {
    "text": "you run a model on the 8 on the edge of the device rather than having to send the whole frame to recognition what if I",
    "start": "1527580",
    "end": "1533849"
  },
  {
    "text": "just want to detect a face get that bounding box crop it and then send it 3",
    "start": "1533849",
    "end": "1538859"
  },
  {
    "text": "for downstream processing suddenly I'm only paying for downstream processing",
    "start": "1538859",
    "end": "1543869"
  },
  {
    "text": "when I have an object of interest and then what I'm also doing this in a much",
    "start": "1543869",
    "end": "1548940"
  },
  {
    "text": "more reduce bandwidth so the solution we've",
    "start": "1548940",
    "end": "1555600"
  },
  {
    "start": "1553000",
    "end": "1553000"
  },
  {
    "text": "got here is absolutely is using D plans and what D plans money does as a project",
    "start": "1555600",
    "end": "1562620"
  },
  {
    "text": "is via the console you can create deep lens projects a deep lens project",
    "start": "1562620",
    "end": "1568350"
  },
  {
    "text": "enables you to import your models maybe you've generated something in sage maker in the neighbors need to manage your",
    "start": "1568350",
    "end": "1574950"
  },
  {
    "text": "lambda and it also manages the deployment and configuration of green grass so it manages your certifications",
    "start": "1574950",
    "end": "1582180"
  },
  {
    "text": "and your secure access back to your IOT devices so in the case of the camera we",
    "start": "1582180",
    "end": "1588570"
  },
  {
    "text": "have running here that's unfortunately not connected is it's running green grass on the actual device itself and",
    "start": "1588570",
    "end": "1595440"
  },
  {
    "text": "green grass is running the model to actually track the faces it detects on",
    "start": "1595440",
    "end": "1601680"
  },
  {
    "text": "the frame and when it detects of face it crops it and streams it through for",
    "start": "1601680",
    "end": "1607410"
  },
  {
    "text": "downstream processing and we'll go through the downstream processing as before but you can start to see that all",
    "start": "1607410",
    "end": "1614010"
  },
  {
    "text": "you have here is rather than it using a producer that you could put a producer on the camera and use Kinesis video",
    "start": "1614010",
    "end": "1620010"
  },
  {
    "text": "streams what we have a use case here is what we're trying to do is actually detect a face and if we have a face we",
    "start": "1620010",
    "end": "1626850"
  },
  {
    "text": "want to display that we've detected the face with known information about that face so the way that the this system",
    "start": "1626850",
    "end": "1633720"
  },
  {
    "text": "works is say I walk past the camera it knows me it will display an image I've",
    "start": "1633720",
    "end": "1639480"
  },
  {
    "text": "pre-loaded with my job title welcome and a logo if I'm smiling as I walk past the",
    "start": "1639480",
    "end": "1645210"
  },
  {
    "text": "camera and the other thing that this this example is doing is it's actually doing sentiment analysis so I'm tracking",
    "start": "1645210",
    "end": "1653160"
  },
  {
    "text": "all of the sentiments of all of the faces of the cam that walk past the",
    "start": "1653160",
    "end": "1658380"
  },
  {
    "text": "camera whether they're known or not and then just streaming them through to kibana again very very simple and we've seen",
    "start": "1658380",
    "end": "1664980"
  },
  {
    "text": "lots of use cases for using kibana in this way but maybe not with with sentiment analysis so what's happening",
    "start": "1664980",
    "end": "1672960"
  },
  {
    "start": "1672000",
    "end": "1672000"
  },
  {
    "text": "on the device again we couldn't find a better looking model so it had to be made so so but what's happening on the",
    "start": "1672960",
    "end": "1679560"
  },
  {
    "text": "actual device itself is you can see that the I'm loading into the GPU on the model",
    "start": "1679560",
    "end": "1686220"
  },
  {
    "text": "and on the camera the model then what I'm doing is I'm doing inference so I'm",
    "start": "1686220",
    "end": "1692280"
  },
  {
    "text": "actually doing inference on the edge so I'm capturing the last frame on the actual camera itself and then what I'm",
    "start": "1692280",
    "end": "1699960"
  },
  {
    "text": "doing from that is I'm resizing it so that the input and width and height that",
    "start": "1699960",
    "end": "1705870"
  },
  {
    "text": "the model will support and then I'm doing inference on that actual device itself and what do I get back apologist",
    "start": "1705870",
    "end": "1713160"
  },
  {
    "text": "this is quite small but basically what I get back is a face boundary again now",
    "start": "1713160",
    "end": "1719580"
  },
  {
    "text": "one of the things I found with recognition is if you had to tie to face boundary it wouldn't detect it as a face",
    "start": "1719580",
    "end": "1726660"
  },
  {
    "text": "so I've actually widened the boundary when I have detected a face in the frame before I crop it and send it through to",
    "start": "1726660",
    "end": "1734660"
  },
  {
    "text": "downstream for Canisius and well I'm also doing is having the labels you can",
    "start": "1734660",
    "end": "1740880"
  },
  {
    "text": "see there I put a bounding box around the face so I'm just using open CV put",
    "start": "1740880",
    "end": "1746970"
  },
  {
    "text": "it overlaying that onto the image very simply and storing that on a FIFO stream",
    "start": "1746970",
    "end": "1752010"
  },
  {
    "text": "on the camera so what you can actually see is on the camera itself you it can track all of the known faces and the",
    "start": "1752010",
    "end": "1758850"
  },
  {
    "text": "running and if you talk to if you go down to the innovation hub you can see",
    "start": "1758850",
    "end": "1764070"
  },
  {
    "text": "there's some guys that have got a similar type demo where they're actually doing the coffee cup challenge so I'd",
    "start": "1764070",
    "end": "1769140"
  },
  {
    "text": "recommend going and having a look at that in action so I'm now in a position",
    "start": "1769140",
    "end": "1775559"
  },
  {
    "start": "1773000",
    "end": "1773000"
  },
  {
    "text": "where I have a camera that I I've set up that is only actually sending captured",
    "start": "1775559",
    "end": "1781260"
  },
  {
    "text": "faces for downstream processing and in my use case what I want to do is I",
    "start": "1781260",
    "end": "1786390"
  },
  {
    "text": "actually want to have a display of an approved image with approved information",
    "start": "1786390",
    "end": "1793049"
  },
  {
    "text": "about the individual so in in this case I've got a very simple uploader which is saying I need to know what I'm going to",
    "start": "1793049",
    "end": "1800040"
  },
  {
    "text": "call my external image I need to know what my member name is what's my first language what's my job title and what is",
    "start": "1800040",
    "end": "1807600"
  },
  {
    "text": "the image that I'm actually going to load so it's just a bulk uploader you couldn't have a use case where you allow",
    "start": "1807600",
    "end": "1813120"
  },
  {
    "text": "people to take their own picture and uploads those to the collection but for most of the use cases I've used I",
    "start": "1813120",
    "end": "1819150"
  },
  {
    "text": "wanted to have some control over the pictures that were displayed then all",
    "start": "1819150",
    "end": "1824370"
  },
  {
    "text": "they do is very simply processed this I resize the images to a size that's appropriate for the display that I'm",
    "start": "1824370",
    "end": "1830550"
  },
  {
    "text": "using and I add the images into the collection but the other interesting",
    "start": "1830550",
    "end": "1835890"
  },
  {
    "text": "thing is here as well I'm also now storing in dynamo dB the additional metadata so I've now got a meta store of",
    "start": "1835890",
    "end": "1843690"
  },
  {
    "text": "additional information that's joined to my collection so I can rich much and enrich my display with the information",
    "start": "1843690",
    "end": "1851430"
  },
  {
    "text": "I've stored in my like with my collection so I'm now in a position",
    "start": "1851430",
    "end": "1858960"
  },
  {
    "start": "1856000",
    "end": "1856000"
  },
  {
    "text": "where I have a set of data set of images stored in s3 I have a certain method",
    "start": "1858960",
    "end": "1864690"
  },
  {
    "text": "data which I've stored in dynamo DB and I have a recognition image collection",
    "start": "1864690",
    "end": "1871200"
  },
  {
    "text": "all of which are joined together so now I can process those images from the stream so I'm putting the cropped images",
    "start": "1871200",
    "end": "1878190"
  },
  {
    "text": "onto my Canisius stream and what I'm doing now is just actually taking them off the stream so very very simply",
    "start": "1878190",
    "end": "1885000"
  },
  {
    "text": "running a lambda function using OpenCV taking the image and when I detect an",
    "start": "1885000",
    "end": "1891570"
  },
  {
    "text": "image I'm just calling the search faces by Image Search we've touched on earlier passing the image bytes and determine if",
    "start": "1891570",
    "end": "1898170"
  },
  {
    "text": "I actually get a match the other thing I'm doing is getting the sentiment from",
    "start": "1898170",
    "end": "1905220"
  },
  {
    "text": "the faces the ID tags so this is doing two things this it's if I'm looking to",
    "start": "1905220",
    "end": "1911850"
  },
  {
    "text": "send two elasticsearch all I do is I determine what emotions have been detected and send those across onto",
    "start": "1911850",
    "end": "1919560"
  },
  {
    "text": "firehose in this case I'm using Kinesis firehose because I can just use it to actually put directly into my",
    "start": "1919560",
    "end": "1926460"
  },
  {
    "text": "elasticsearch service which then enables me to do the visualization with kibana",
    "start": "1926460",
    "end": "1933140"
  },
  {
    "text": "and I'm also one of the things that obviously image recognition is in the",
    "start": "1934790",
    "end": "1941790"
  },
  {
    "text": "press a lot at the moment and you have to be very very sensitive about how you're managing and processing and",
    "start": "1941790",
    "end": "1947550"
  },
  {
    "text": "storing of images so in this example the only information that's been stored is",
    "start": "1947550",
    "end": "1953580"
  },
  {
    "text": "the approved information that's been given to me by the user so you've approved to give me basic information",
    "start": "1953580",
    "end": "1960390"
  },
  {
    "text": "about your role and you've approved to give me a photograph interestingly most of the photographs that I get given",
    "start": "1960390",
    "end": "1966480"
  },
  {
    "text": "while I'm running us in demos or of 10 years younger of the individuals which is interesting to see if they still",
    "start": "1966480",
    "end": "1972000"
  },
  {
    "text": "match but the important thing here is the processing is just actually taking the image capturing the information out",
    "start": "1972000",
    "end": "1979170"
  },
  {
    "text": "of the image and then doing the comparison but not storing any of that captured information so in this use case",
    "start": "1979170",
    "end": "1986550"
  },
  {
    "text": "all I'm doing is matching to say does the image have any comparison to something that I've got stored if it",
    "start": "1986550",
    "end": "1993570"
  },
  {
    "text": "does then I'm actually processing it and displaying the resource so my detected",
    "start": "1993570",
    "end": "2002150"
  },
  {
    "start": "2000000",
    "end": "2000000"
  },
  {
    "text": "faces viewer unfortunately because I couldn't run the demo what would happen is as I run in front of the camera well",
    "start": "2002150",
    "end": "2008210"
  },
  {
    "text": "walk in front of the camera the detected faces viewer would pick up recognize my",
    "start": "2008210",
    "end": "2013880"
  },
  {
    "text": "face and show the preloaded image and some information about me and again all",
    "start": "2013880",
    "end": "2019040"
  },
  {
    "text": "I have here is now you're starting to see how this all comes together all this is doing is processing a dynamodb table",
    "start": "2019040",
    "end": "2026809"
  },
  {
    "text": "and all I'm doing with dynamodb is looking for the known faces in the last",
    "start": "2026809",
    "end": "2032510"
  },
  {
    "text": "minute that are distinct and displaying them and returning them to my HTML page",
    "start": "2032510",
    "end": "2038000"
  },
  {
    "text": "now what am i using dynamodb well for a single camera and a single set of faces",
    "start": "2038000",
    "end": "2045950"
  },
  {
    "text": "there's no real you know there's no real loading here but we're talking about how could you scale this up to thousands of",
    "start": "2045950",
    "end": "2052490"
  },
  {
    "text": "devices and using dynamodb for capturing and partitioning based on your",
    "start": "2052490",
    "end": "2059060"
  },
  {
    "text": "collection IDs would mean that you could use the auto scaling capabilities of dynamodb to cost-effectively scale this",
    "start": "2059060",
    "end": "2066290"
  },
  {
    "text": "art as you introduced more cameras so what you can see is well",
    "start": "2066290",
    "end": "2073580"
  },
  {
    "text": "I'm I'm writing it to DynamoDB I'm determining my unique images detected",
    "start": "2073580",
    "end": "2079490"
  },
  {
    "text": "once I've got those unique records I'm just generating a pre signed URL to",
    "start": "2079490",
    "end": "2084740"
  },
  {
    "text": "display those images so again throughout this process and no time we're exposing the data for longer than is necessary so",
    "start": "2084740",
    "end": "2092480"
  },
  {
    "text": "so the pre signed URL is only available what for a brief period of time while",
    "start": "2092480",
    "end": "2097730"
  },
  {
    "text": "the HTML page has loaded up and one of",
    "start": "2097730",
    "end": "2103970"
  },
  {
    "text": "the other things is there is a logo on there that if you happen to be smiling then I was I was show a low girl to say",
    "start": "2103970",
    "end": "2110450"
  },
  {
    "text": "that you've got the company smile so again that's using the sentiment analysis to actually do some processing",
    "start": "2110450",
    "end": "2119140"
  },
  {
    "text": "now with the sentiment analysis what we were doing is we're actually running the",
    "start": "2119350",
    "end": "2125930"
  },
  {
    "start": "2120000",
    "end": "2120000"
  },
  {
    "text": "processing of capturing a set of sentiments from the metadata that's returned and just displaying them as a",
    "start": "2125930",
    "end": "2133070"
  },
  {
    "text": "time series chart it would have been interesting to see what my emotions were while I was trying to set this demo up",
    "start": "2133070",
    "end": "2140060"
  },
  {
    "text": "but what you can see here is some of the emotions I was sharing while I was actually doing similar configuration so",
    "start": "2140060",
    "end": "2146090"
  },
  {
    "text": "you can see I mixed between happiness sadness and confused and I think this is",
    "start": "2146090",
    "end": "2151820"
  },
  {
    "text": "the life of a of any programmer in terms of trying to get their code debugged but what you what you're starting to see",
    "start": "2151820",
    "end": "2158810"
  },
  {
    "text": "is you're now getting some interesting data about real-time processing of",
    "start": "2158810",
    "end": "2163990"
  },
  {
    "text": "sentiment so for example I had trouble getting this camera working but it would",
    "start": "2163990",
    "end": "2169640"
  },
  {
    "text": "have been really interesting to have camera set up all around this auditorium and watch the sentiment in the room in",
    "start": "2169640",
    "end": "2175460"
  },
  {
    "text": "real-time against the talk and at what ports in the talk were people confused",
    "start": "2175460",
    "end": "2180950"
  },
  {
    "text": "sad happy unhappy and you're really starting to get some interesting data about how you can utilize and maximize",
    "start": "2180950",
    "end": "2188410"
  },
  {
    "text": "the customer experience and unfortunately I can't share it because of the connectivity problems but",
    "start": "2188410",
    "end": "2196380"
  },
  {
    "text": "what have we seen here and so we we set up the talk we were talking about we",
    "start": "2196380",
    "end": "2202710"
  },
  {
    "text": "want how do you manage ingestion of video how do you manage the archiving of mid video how do you managing the easily",
    "start": "2202710",
    "end": "2210980"
  },
  {
    "text": "sharing of this information at scale so we've set up a simple HTML page and",
    "start": "2210980",
    "end": "2217049"
  },
  {
    "text": "shown how you can do image recognition processing on the actual devices themselves on the edge but this is an",
    "start": "2217049",
    "end": "2224730"
  },
  {
    "text": "efficient you know you're just polling recognition you've got no logic there and all you're doing is displaying at the output",
    "start": "2224730",
    "end": "2231180"
  },
  {
    "text": "metadata how do you process live video again you have your producer and use",
    "start": "2231180",
    "end": "2237210"
  },
  {
    "text": "your producer to put data through onto your Canisius video stream and then how",
    "start": "2237210",
    "end": "2243269"
  },
  {
    "text": "is your stream process are interacting well you can interact using recognition",
    "start": "2243269",
    "end": "2248849"
  },
  {
    "text": "video to have a stream processor acting on your live video and you can archive",
    "start": "2248849",
    "end": "2254009"
  },
  {
    "text": "and share the video so quite useful use cases and to do this at scale and",
    "start": "2254009",
    "end": "2259220"
  },
  {
    "text": "securely and then the final example was about custom image processing at the",
    "start": "2259220",
    "end": "2266069"
  },
  {
    "text": "edge so here we're running ResNet with SSD on the actual camera itself just to",
    "start": "2266069",
    "end": "2272640"
  },
  {
    "text": "extract image information once we have that those faces they're detected we",
    "start": "2272640",
    "end": "2278339"
  },
  {
    "text": "caught them and stream them for downstream processing now also we're",
    "start": "2278339",
    "end": "2283380"
  },
  {
    "text": "using recognition in this news case but it may be then you will build your own customizations and you will also and",
    "start": "2283380",
    "end": "2290609"
  },
  {
    "text": "potentially you will build other use cases in terms of maybe you want to do",
    "start": "2290609",
    "end": "2295740"
  },
  {
    "text": "unique image object detection and maybe you need to train your own models using tools such as sage maker and again or",
    "start": "2295740",
    "end": "2303210"
  },
  {
    "text": "you can see is that what you'll be doing is you will have your sage maker endpoints and rather than calling",
    "start": "2303210",
    "end": "2308640"
  },
  {
    "text": "recognition your Landers will be calling inference on those endpoints of those sage maker pipelines so what you're",
    "start": "2308640",
    "end": "2315390"
  },
  {
    "text": "starting to build is a set of solutions that you can extend and to end",
    "start": "2315390",
    "end": "2321710"
  },
  {
    "text": "so a few further links well I've tried to do is pull out all of the things that",
    "start": "2321710",
    "end": "2327530"
  },
  {
    "text": "we've talked around in this put in this tour there's an example of the model that we're actually running on the",
    "start": "2327530",
    "end": "2332839"
  },
  {
    "text": "camera just you can see how that hooks into Amex NAT we've got sage maker I",
    "start": "2332839",
    "end": "2338270"
  },
  {
    "text": "would recommend exploring sage maker because the sage makers really interesting for how it can manage the",
    "start": "2338270",
    "end": "2345050"
  },
  {
    "text": "end-to-end delivery of your machine learning pipelines so it so with sage",
    "start": "2345050",
    "end": "2350599"
  },
  {
    "text": "maker it's about solving how do you get your data machine learning models into",
    "start": "2350599",
    "end": "2356869"
  },
  {
    "text": "production and then image classification if you want to do some different image",
    "start": "2356869",
    "end": "2362089"
  },
  {
    "text": "classifications there are some pre-built models that you can have a look at and use within sage maker and of course",
    "start": "2362089",
    "end": "2369020"
  },
  {
    "text": "Canisius video streams deep lens and the elasticsearch service elasticsearch",
    "start": "2369020",
    "end": "2374599"
  },
  {
    "text": "services is more there for completeness because there's nothing new there that's something that's anyone is running the",
    "start": "2374599",
    "end": "2380450"
  },
  {
    "text": "analytics running analytics today is aware of so please unfortunately because",
    "start": "2380450",
    "end": "2388040"
  },
  {
    "text": "I'm not allowed to run lots of cameras and get the stats automatically we do appreciate your feedback so please do",
    "start": "2388040",
    "end": "2395180"
  },
  {
    "text": "complete the assessment surveys in the mobile app afterwards we're a couple of minutes ahead of time because",
    "start": "2395180",
    "end": "2401210"
  },
  {
    "text": "unfortunately I haven't been able to get the demos to work but if there are any questions please come down to the front",
    "start": "2401210",
    "end": "2406549"
  },
  {
    "text": "and I'll be happy to take them install the last five minutes it's a big dream so that so again thank you for listening",
    "start": "2406549",
    "end": "2412849"
  },
  {
    "text": "and I hope this has been useful",
    "start": "2412849",
    "end": "2416319"
  }
]
[
  {
    "text": "so welcome everyone to FSB 305 optimizing payments collections with",
    "start": "0",
    "end": "5250"
  },
  {
    "text": "containers and machine learning my name is Matt Nina and I'm a Solutions Architect with Amazon Web Services and",
    "start": "5250",
    "end": "12030"
  },
  {
    "text": "today I'm joined by Nima Najafi who is a senior manager of data science and model",
    "start": "12030",
    "end": "18720"
  },
  {
    "text": "innovation with Scotiabank and we're here to talk to you a little bit about",
    "start": "18720",
    "end": "24050"
  },
  {
    "text": "Scotiabank story with with containers and machine learning and how they approached problem solving within their",
    "start": "24050",
    "end": "30750"
  },
  {
    "text": "organization a little bit about myself I'm a Solutions Architect that focuses",
    "start": "30750",
    "end": "36420"
  },
  {
    "text": "on financial services in Canada with a technical focus on security and",
    "start": "36420",
    "end": "42719"
  },
  {
    "text": "containers this is my fifth reinvent I've had the privilege of being here as",
    "start": "42719",
    "end": "48899"
  },
  {
    "text": "a customer as a partner and now as as AWS this is also my second year as a",
    "start": "48899",
    "end": "56039"
  },
  {
    "text": "presenter which means that I've learned to turn off my Wi-Fi and there will be no notifications popping up to set the",
    "start": "56039",
    "end": "63840"
  },
  {
    "text": "stage for for today's talk we wanted to take you back to December of last year",
    "start": "63840",
    "end": "69720"
  },
  {
    "text": "so just after reinvent closed we actually launched the CA Central Canadian region and within 90 minutes of",
    "start": "69720",
    "end": "77909"
  },
  {
    "text": "this region going live Scotiabank was actually able to migrate their workloads from from another region into the",
    "start": "77909",
    "end": "85049"
  },
  {
    "text": "Canadian region and be up and running the way that they were able to do that do that is by leveraging containers and",
    "start": "85049",
    "end": "91860"
  },
  {
    "text": "Puppet so that they were able to define infrastructure as code and very quickly",
    "start": "91860",
    "end": "97170"
  },
  {
    "text": "deploy their application and today's talk it's going to take you through how they were able to accomplish that so",
    "start": "97170",
    "end": "104460"
  },
  {
    "text": "what can you expect from this session well we're going to talk about why Scotia Maine started with payments",
    "start": "104460",
    "end": "111090"
  },
  {
    "text": "collection what was it about this that made this a compelling topic for their customers why leverage deep learning what this",
    "start": "111090",
    "end": "118500"
  },
  {
    "text": "meant to in terms of innovation over their existing processes then we're",
    "start": "118500",
    "end": "123750"
  },
  {
    "text": "really going to dive into container based deployment workloads so what are",
    "start": "123750",
    "end": "128789"
  },
  {
    "text": "all the components that that you need in order to deploy your application you containers and then NEMA is actually",
    "start": "128789",
    "end": "135989"
  },
  {
    "text": "gonna take you through the specific deployment pattern that Scotiabank went through and finally we're gonna go",
    "start": "135989",
    "end": "141060"
  },
  {
    "text": "through results so to kick things off I want to talk a little bit about this idea of a flywheel for data so we live",
    "start": "141060",
    "end": "149310"
  },
  {
    "text": "in a world now where we collect lots and lots of data we want to use that data in order to get better analytics with",
    "start": "149310",
    "end": "158400"
  },
  {
    "text": "better analytics allows us to build better products better products leads us",
    "start": "158400",
    "end": "163980"
  },
  {
    "text": "to more users and consequently we've got this this introduction of more and more",
    "start": "163980",
    "end": "169200"
  },
  {
    "text": "data so you know this includes things like clickstream data user activity",
    "start": "169200",
    "end": "175099"
  },
  {
    "text": "purchases but specifically for financial services you've got a tremendous",
    "start": "175099",
    "end": "180510"
  },
  {
    "text": "opportunity to take advantage of this data flywheel effect and actually leverage you know the trillions of data",
    "start": "180510",
    "end": "187379"
  },
  {
    "text": "points that financial services collect everything from transactions to social media interactions that really creates a",
    "start": "187379",
    "end": "193319"
  },
  {
    "text": "goldmine of useful insights we find over year-over-year that the businesses are",
    "start": "193319",
    "end": "200700"
  },
  {
    "text": "driving more value from this once we've got this data now you're going to need a",
    "start": "200700",
    "end": "206250"
  },
  {
    "text": "platform that sort of helps to build this out and this is another interesting area for where AWS starts to come into",
    "start": "206250",
    "end": "213599"
  },
  {
    "text": "the picture because for the first time you're able to really separate out storage from compute so that you can",
    "start": "213599",
    "end": "221370"
  },
  {
    "text": "collect this data decide how you want to ingest it how you want to process it you know whether you're using things like",
    "start": "221370",
    "end": "228620"
  },
  {
    "text": "spark a spark ml4 for setting it up to be able to run machine learning jobs",
    "start": "228620",
    "end": "234329"
  },
  {
    "text": "these tools help you to build better products by understanding what your customers like and what their behaviors",
    "start": "234329",
    "end": "240599"
  },
  {
    "text": "are and the interesting thing for financial services here for the first time now you have the ability to",
    "start": "240599",
    "end": "247430"
  },
  {
    "text": "understand when money is coming into your institution when money is leaving your institution and then correlate that",
    "start": "247430",
    "end": "253440"
  },
  {
    "text": "with social media events so that you're actually able to track life events for",
    "start": "253440",
    "end": "259199"
  },
  {
    "text": "your customers then when you've got a platform that's that's able to help you",
    "start": "259199",
    "end": "265229"
  },
  {
    "text": "build out these and services you have the ability to leverage artificial intelligence to",
    "start": "265229",
    "end": "270450"
  },
  {
    "text": "derive new insights to perform predictions on who you should target with new offers or new improvements to",
    "start": "270450",
    "end": "276540"
  },
  {
    "text": "these services and then finally lead you to pinpoint better services better",
    "start": "276540",
    "end": "283080"
  },
  {
    "text": "product offerings hyper personalized communication leaders in this space are",
    "start": "283080",
    "end": "288540"
  },
  {
    "text": "gonna there they're going to pave the way for years to come and as this data flywheel continues to spin faster",
    "start": "288540",
    "end": "295020"
  },
  {
    "text": "they'll see the gap between them and their competitors grow wider and wider so that's what we're here to talk about",
    "start": "295020",
    "end": "301410"
  },
  {
    "text": "at this point I'd like to hand it over to my colleague Nima to talk about Scotiabank and their begin their story",
    "start": "301410",
    "end": "309090"
  },
  {
    "text": "thank you very much Matt hi my name is Nima I'm working for scotia bank yes I'm",
    "start": "309090",
    "end": "317790"
  },
  {
    "text": "working for scotia bank and I'm gonna give you a brief introduction of who we are at Scotia Bank first in a couple of",
    "start": "317790",
    "end": "324090"
  },
  {
    "text": "slides and then we go further and deep down into into more technical stuff",
    "start": "324090",
    "end": "329510"
  },
  {
    "text": "who's the Scotiabank at Scotia Bank is like any other Bank in Canada or",
    "start": "329510",
    "end": "335160"
  },
  {
    "text": "anywhere else we are the third largest bank when it comes to capital in Canada",
    "start": "335160",
    "end": "340200"
  },
  {
    "text": "we are on top of ten world's strongest Bank according to forbes we are",
    "start": "340200",
    "end": "346740"
  },
  {
    "text": "providing services to North America and Latin America and Caribbean we have over 88,000 almost 90,000",
    "start": "346740",
    "end": "353910"
  },
  {
    "text": "employees and our asset is is 907",
    "start": "353910",
    "end": "359850"
  },
  {
    "text": "billion-dollar according to the report that we have on July 31st of 2016 and we",
    "start": "359850",
    "end": "365400"
  },
  {
    "text": "currently have to need three million customers serving them in in all those",
    "start": "365400",
    "end": "370620"
  },
  {
    "text": "countries that that I mentioned all over the world so what was the problem that",
    "start": "370620",
    "end": "378210"
  },
  {
    "text": "we were solving and what is our our strategy in the bank the problem that we",
    "start": "378210",
    "end": "383460"
  },
  {
    "text": "were trying to solve last year is about credit cards collections and the as you",
    "start": "383460",
    "end": "390870"
  },
  {
    "text": "all know the portfolio is growing everyone is is getting more credit cards and stuff and the balances on the credit",
    "start": "390870",
    "end": "396360"
  },
  {
    "text": "card where we're increasing so we needed to come up with a better strategy to protect our good customers and save as",
    "start": "396360",
    "end": "403960"
  },
  {
    "text": "much money as we can detecting the the collections earlier by",
    "start": "403960",
    "end": "408969"
  },
  {
    "text": "by machine learning techniques and the reason we're doing that is partially the",
    "start": "408969",
    "end": "414490"
  },
  {
    "text": "problem and the other thing is the strategy that we have at the bank we are trying to be as much digital as possible",
    "start": "414490",
    "end": "422439"
  },
  {
    "text": "and this is part of the bank strategy to go to AI to to use as much machine",
    "start": "422439",
    "end": "428229"
  },
  {
    "text": "learning technique techniques as possible to prevent any loss so in the",
    "start": "428229",
    "end": "436569"
  },
  {
    "text": "in the payment collection area we had some some delinquency rates and the the",
    "start": "436569",
    "end": "443529"
  },
  {
    "text": "table that you see is in u.s. dollar it's actually from US banks but Canadian",
    "start": "443529",
    "end": "449349"
  },
  {
    "text": "banks are very very similar the numbers are very similar so as you see the the delinquency rates in different years are",
    "start": "449349",
    "end": "455229"
  },
  {
    "text": "increasing and from from 2016 q2 to 2017",
    "start": "455229",
    "end": "460839"
  },
  {
    "text": "q2 the defaults and delinquency rates went up two percent so that shows you",
    "start": "460839",
    "end": "466750"
  },
  {
    "text": "why we we start this project initially what we had before deep learning a",
    "start": "466750",
    "end": "473849"
  },
  {
    "text": "Scotia Bank were like a lot more man'll stuff less develops we did a lot of",
    "start": "473849",
    "end": "479919"
  },
  {
    "text": "basic models developed internally mostly logistic regression and linear regressions there were no machine",
    "start": "479919",
    "end": "486129"
  },
  {
    "text": "learning involved and with it up with AWS and and the new machine learning",
    "start": "486129",
    "end": "492789"
  },
  {
    "text": "techniques that we use we could we could change that direction a lot of manual",
    "start": "492789",
    "end": "498099"
  },
  {
    "text": "process was happening internally and we we try to use DevOps to to minimize the",
    "start": "498099",
    "end": "504339"
  },
  {
    "text": "number of manual steps in this project the the complete data source preparation",
    "start": "504339",
    "end": "510159"
  },
  {
    "text": "was very time-consuming internally and using these techniques that we used we could we could tackle that as well the",
    "start": "510159",
    "end": "518050"
  },
  {
    "text": "the predictions that we used to have were less accurate and and we could give",
    "start": "518050",
    "end": "524198"
  },
  {
    "text": "a lot better at better accuracy on that as well and of course we created a lot",
    "start": "524199",
    "end": "529990"
  },
  {
    "text": "of is for for the financial industry using these machine learning techniques so",
    "start": "529990",
    "end": "536920"
  },
  {
    "text": "here I'm gonna pass it back to do not about is going to talk about the more technical stuff and then I'll give you a",
    "start": "536920",
    "end": "542980"
  },
  {
    "text": "demo thanks neva so what I really like about Nemeth story there is that there's",
    "start": "542980",
    "end": "550180"
  },
  {
    "text": "two things I mean he broke down his problem set into two discrete components the first was you know an understanding",
    "start": "550180",
    "end": "557199"
  },
  {
    "text": "of their customer base and understand that since 2008 2009 banks have",
    "start": "557199",
    "end": "563290"
  },
  {
    "text": "continued to lend out money that were seeing consumers take on more and more",
    "start": "563290",
    "end": "568660"
  },
  {
    "text": "debt and that the delinquency rates are increasing so there was an opportunity if you could accurately identify who",
    "start": "568660",
    "end": "577209"
  },
  {
    "text": "people were that might have issues paying their bills that you could proactively reach out to them and engage so there was really focused on who their",
    "start": "577209",
    "end": "584889"
  },
  {
    "text": "end customer was as well as the idea that there's an opportunity to quickly experiment and innovate so build out a",
    "start": "584889",
    "end": "592060"
  },
  {
    "text": "new strategy try something look at the feedback and iterate over that result so",
    "start": "592060",
    "end": "598750"
  },
  {
    "text": "that brings us into the advent of deep learning so just out of curiosity how many people are leveraging machine",
    "start": "598750",
    "end": "604899"
  },
  {
    "text": "learning or deep learning within their organizations today I see an interesting",
    "start": "604899",
    "end": "610269"
  },
  {
    "text": "number I mean part of its obscured because of the lights but actually you know a fair representation have started",
    "start": "610269",
    "end": "616209"
  },
  {
    "text": "down this path we're actually seeing this happen for a number of reasons the first of which is the idea of algorithms",
    "start": "616209",
    "end": "623500"
  },
  {
    "text": "here so you know we've deep learning algorithms like convolutional neural",
    "start": "623500",
    "end": "630009"
  },
  {
    "text": "networks where current neural networks are helping us quickly and more easily",
    "start": "630009",
    "end": "635050"
  },
  {
    "text": "solve very tough computing problems you know things like computer vision natural",
    "start": "635050",
    "end": "640180"
  },
  {
    "text": "language processing but in order to do that these these deep learning needs",
    "start": "640180",
    "end": "646509"
  },
  {
    "text": "data and they need a lot of data and so you know again with financial services",
    "start": "646509",
    "end": "652149"
  },
  {
    "text": "with cloud computing it's never been easier to collect and analyze large",
    "start": "652149",
    "end": "657309"
  },
  {
    "text": "volumes of data after you've got to the algorithms get started the data get",
    "start": "657309",
    "end": "663250"
  },
  {
    "text": "started then people turn to is the platform the underlying hardware that that's actually",
    "start": "663250",
    "end": "668470"
  },
  {
    "text": "going to perform this this the the training the the actual returning the",
    "start": "668470",
    "end": "675010"
  },
  {
    "text": "results many people started with compute based instances but found that with CPU",
    "start": "675010",
    "end": "681310"
  },
  {
    "text": "model training time can take you know days or weeks and there was a big push",
    "start": "681310",
    "end": "686440"
  },
  {
    "text": "towards GPU and and further on into FPGAs to help reduce this down into",
    "start": "686440",
    "end": "692620"
  },
  {
    "text": "hours but having access to that specialized hardware is sometimes hard to justify when you don't necessarily know what the",
    "start": "692620",
    "end": "699160"
  },
  {
    "text": "result is going to be the last component here is programming models so how do we",
    "start": "699160",
    "end": "704410"
  },
  {
    "text": "bring deep learning science to our developers how do we how do we make this",
    "start": "704410",
    "end": "711100"
  },
  {
    "text": "easier for people who aren't necessarily data scientists so this is where the advent of things like MX net tensorflow",
    "start": "711100",
    "end": "718000"
  },
  {
    "text": "have greatly simplified this development process and and lead us into interesting new machine learning models and",
    "start": "718000",
    "end": "724570"
  },
  {
    "text": "applications so for the Scotiabank news case they actually develop this on tensorflow AWS is approach to artificial",
    "start": "724570",
    "end": "734530"
  },
  {
    "text": "intelligence has been this idea of democratizing AI so making it easier for",
    "start": "734530",
    "end": "740740"
  },
  {
    "text": "our customers by providing a rich set of AI services platform services right down",
    "start": "740740",
    "end": "748720"
  },
  {
    "text": "through frameworks and underlying infrastructure so we need to kind of walk through the the idea here is at the",
    "start": "748720",
    "end": "756130"
  },
  {
    "text": "top you have managed AI services these are ones where you don't have to run the infrastructure there's already a",
    "start": "756130",
    "end": "763080"
  },
  {
    "text": "solution that's ready to go so these take things like image recognition doing",
    "start": "763080",
    "end": "768990"
  },
  {
    "text": "text-to-speech so but but taking that to the next level understanding the context",
    "start": "768990",
    "end": "774730"
  },
  {
    "text": "of the sentence so that you can create new human-computer interactions with your with your customers Lexx for voice",
    "start": "774730",
    "end": "783550"
  },
  {
    "text": "and and chat understand so the natural language understanding understanding the context of what's being said and being",
    "start": "783550",
    "end": "789160"
  },
  {
    "text": "able to reply to that then to take a down a level you have managed platforms so Amazon machine learning Amazon iam",
    "start": "789160",
    "end": "797290"
  },
  {
    "text": "our spark spark ml this takes away or abstracts the idea of having to run the",
    "start": "797290",
    "end": "802720"
  },
  {
    "text": "underlying infrastructure and gets you focused on what's my application that I want to deploy and the next is down into",
    "start": "802720",
    "end": "809110"
  },
  {
    "text": "AI framework so the people that actually put up their hands how many of you have been responsible for installing these",
    "start": "809110",
    "end": "814690"
  },
  {
    "text": "frameworks but got a couple here this is a huge pain the amount of time that you",
    "start": "814690",
    "end": "822850"
  },
  {
    "text": "spend getting these drivers getting these frameworks installed and ready to go this is where things like the Amazon",
    "start": "822850",
    "end": "828250"
  },
  {
    "text": "machine learning deep learning ami come into play because it's all prepackaged and ready to go and you have multiple",
    "start": "828250",
    "end": "834670"
  },
  {
    "text": "frameworks at your disposal finally the underlying infrastructure so having access to that specialized to",
    "start": "834670",
    "end": "840399"
  },
  {
    "text": "compute that that give you the type of hardware that you're looking for the processing that you're going to be doing the networking components or the the",
    "start": "840399",
    "end": "847690"
  },
  {
    "text": "surrounding bits but that still leaves us this problem of how we going to",
    "start": "847690",
    "end": "854850"
  },
  {
    "text": "develop this across our on-premise environments or cloud environments different application stacks different",
    "start": "854850",
    "end": "861550"
  },
  {
    "text": "hardware deployments you know things don't necessarily match how are we gonna run all these different components well",
    "start": "861550",
    "end": "868329"
  },
  {
    "text": "this is where we get the introduction of containers now some of the the core",
    "start": "868329",
    "end": "874600"
  },
  {
    "text": "benefits for containers are things like reproducible builds so having that that",
    "start": "874600",
    "end": "880480"
  },
  {
    "text": "consistent result that deterministic result every time you go to deploy this whether this is on developers laptop or",
    "start": "880480",
    "end": "888100"
  },
  {
    "text": "running in a production environment as well you have the ability to increase your utilization so actually running",
    "start": "888100",
    "end": "894730"
  },
  {
    "text": "multiple processes getting better use out of the hardware that you're deploying for this you have isolation",
    "start": "894730",
    "end": "900670"
  },
  {
    "text": "and fidelity so this is another area where people want to have security of the individual containers how they're",
    "start": "900670",
    "end": "907269"
  },
  {
    "text": "going to lock those down running diverse sets of application on shared hardware",
    "start": "907269",
    "end": "912540"
  },
  {
    "text": "infrastructure as code easy to deploy these are all the sort of benefits to two containers so at this point I'm",
    "start": "912540",
    "end": "919630"
  },
  {
    "text": "going to take you through what are each of these components that you're going to need for anyone who's worked with docker",
    "start": "919630",
    "end": "927250"
  },
  {
    "text": "before they're gonna know that it's fairly easy to do you docker run image on a single laptop I mean doctors made incredibly great",
    "start": "927250",
    "end": "935410"
  },
  {
    "text": "easy for you for us to spin up different apps and have those isolated from the rest of the operating system however",
    "start": "935410",
    "end": "942400"
  },
  {
    "text": "when we talk about moving at scale this is where it becomes really difficult you",
    "start": "942400",
    "end": "949090"
  },
  {
    "text": "know understanding what to do when a container dies what's that what's that impact to our our job understanding",
    "start": "949090",
    "end": "956380"
  },
  {
    "text": "where to deploy things where how are we gonna create a scheduler where do I wanted to play these pieces what are all",
    "start": "956380",
    "end": "962110"
  },
  {
    "text": "the different components into it this is all taking away from your ultimate application and one of the reasons why",
    "start": "962110",
    "end": "968560"
  },
  {
    "text": "we built ECS or lastic container service so poor",
    "start": "968560",
    "end": "973900"
  },
  {
    "text": "ECS benefits here our cluster management made easy the ability to have flexible",
    "start": "973900",
    "end": "979690"
  },
  {
    "text": "scheduling systems so these can be plugins from external systems where you can define what are the parameters what",
    "start": "979690",
    "end": "986110"
  },
  {
    "text": "are the types of hardware what are the CPU or memory and it will identify where the most logical place to deploy that is",
    "start": "986110",
    "end": "993720"
  },
  {
    "text": "integrated and extensible the idea there being ECS is closely tied into other AWS",
    "start": "993720",
    "end": "1000120"
  },
  {
    "text": "services so when you think about how you're going to be load balancing traffic across multiple instances or you",
    "start": "1000120",
    "end": "1005940"
  },
  {
    "text": "know moving into two security things big advances in ECS with respects to networking and security groups being",
    "start": "1005940",
    "end": "1012810"
  },
  {
    "text": "able to define a security group for an individual container that's separate",
    "start": "1012810",
    "end": "1017970"
  },
  {
    "text": "than the container host so you can lock down the traffic tuned from that that container to just what it requires and",
    "start": "1017970",
    "end": "1025640"
  },
  {
    "text": "lastly the the performance at scale so again that deterministic performance you",
    "start": "1025640",
    "end": "1031110"
  },
  {
    "text": "want to have the the expected result whether you're running that on an individual machine one machine ten",
    "start": "1031110",
    "end": "1037740"
  },
  {
    "text": "machine or hundreds of machines right across the board all of those benefits",
    "start": "1037740",
    "end": "1043410"
  },
  {
    "text": "lead us into things like portability so immutable infrastructure allowing you to",
    "start": "1043410",
    "end": "1049290"
  },
  {
    "text": "have that defined container what it what it looks like and what its purpose is",
    "start": "1049290",
    "end": "1054570"
  },
  {
    "text": "run anywhere flexibility so that you can decompose your application define",
    "start": "1054570",
    "end": "1060450"
  },
  {
    "text": "whether containers need to run together or separate from one another understanding",
    "start": "1060450",
    "end": "1065730"
  },
  {
    "text": "what the underlying cloud infrastructure looks like how they define how they respond to availability zones what what",
    "start": "1065730",
    "end": "1073500"
  },
  {
    "text": "though that those RTO and RPO targets are speed and it's not just the idea of",
    "start": "1073500",
    "end": "1079700"
  },
  {
    "text": "speed to spin up a docker container but also speed to to develop your",
    "start": "1079700",
    "end": "1086580"
  },
  {
    "text": "applications so the idea here is that you can separate out functions for",
    "start": "1086580",
    "end": "1091980"
  },
  {
    "text": "people that are responsible for maintaining an image earlier in the",
    "start": "1091980",
    "end": "1097290"
  },
  {
    "text": "cycle that you can base your image off of or you can deploy your application on top of and then efficient resource",
    "start": "1097290",
    "end": "1104430"
  },
  {
    "text": "utilization really what we're talking about here is the idea that containers are another level of separation so you",
    "start": "1104430",
    "end": "1113430"
  },
  {
    "text": "know we've all been down the road of bare metal then into hypervisor States",
    "start": "1113430",
    "end": "1118500"
  },
  {
    "text": "for emulating Hardware finally down into process level user space isolation where",
    "start": "1118500",
    "end": "1123570"
  },
  {
    "text": "you can now define on a per process basis the amount of memory and CPU that",
    "start": "1123570",
    "end": "1129090"
  },
  {
    "text": "you want to constrain for that all of this leads us to agility and speed to deploy variable now as I mentioned with",
    "start": "1129090",
    "end": "1141860"
  },
  {
    "text": "with this idea of hardware abstraction containers make it really easy to run",
    "start": "1141860",
    "end": "1148500"
  },
  {
    "text": "across an agnostic hardware fleet but what about when you want to have specialized hardware use well you know",
    "start": "1148500",
    "end": "1156300"
  },
  {
    "text": "we want to be able to leverage GPUs in our actual containers the the first",
    "start": "1156300",
    "end": "1161640"
  },
  {
    "text": "approach to this was an idea of taking the Nvidia driver installing it into a",
    "start": "1161640",
    "end": "1167310"
  },
  {
    "text": "container and it need to match the the container host in order to share resources between the container and the",
    "start": "1167310",
    "end": "1173880"
  },
  {
    "text": "container host it was very brittle and so Nvidia actually developed the Nvidia",
    "start": "1173880",
    "end": "1179280"
  },
  {
    "text": "docker command which simplifies the process for exposing devices to a",
    "start": "1179280",
    "end": "1185370"
  },
  {
    "text": "container so now you have specialized hardware at the bottom you have an ami",
    "start": "1185370",
    "end": "1191970"
  },
  {
    "text": "that has your frameworks ready to go and a way of exposing those devices your container allows you to really",
    "start": "1191970",
    "end": "1197260"
  },
  {
    "text": "focus on the application all that's wrapped in a single instance plus the",
    "start": "1197260",
    "end": "1202360"
  },
  {
    "text": "ECS agent now you've got all your orchestration in place so what are the other missing components in order to be",
    "start": "1202360",
    "end": "1208360"
  },
  {
    "text": "effective here well first is container registry you'll hear about what from a",
    "start": "1208360",
    "end": "1215590"
  },
  {
    "text": "financial services perspective why it's important to have a private hosted registry that you control the security",
    "start": "1215590",
    "end": "1221560"
  },
  {
    "text": "of but ECR it gives you a fully managed docker repository makes it easy to",
    "start": "1221560",
    "end": "1227800"
  },
  {
    "text": "migrate to version control to store your images and then have those private to",
    "start": "1227800",
    "end": "1233680"
  },
  {
    "text": "your environment we've got a link to learn more up there but what you really",
    "start": "1233680",
    "end": "1238990"
  },
  {
    "text": "want to know is ok so how do i leverage these components together that takes us into task definitions so for those that",
    "start": "1238990",
    "end": "1248320"
  },
  {
    "text": "aren't familiar task definitions are the way that we define container based workloads on AWS you can see here that",
    "start": "1248320",
    "end": "1256750"
  },
  {
    "text": "we have a descriptor a JSON file here where you can define whether there are",
    "start": "1256750",
    "end": "1263200"
  },
  {
    "text": "multiple containers that need to run together a run separate from one another you can define the resource requirements",
    "start": "1263200",
    "end": "1269920"
  },
  {
    "text": "you can also define things like the image location where do I want to pull the image that's going to be deployed",
    "start": "1269920",
    "end": "1275980"
  },
  {
    "text": "and at a high level you can see all the components that went into the Scotiabank deployment so the idea we have the",
    "start": "1275980",
    "end": "1282400"
  },
  {
    "text": "tensorflow framework we use docker container you use ECR to store those",
    "start": "1282400",
    "end": "1288400"
  },
  {
    "text": "images task definition to define what the workload was going to look like then identified the right GPU instances to do",
    "start": "1288400",
    "end": "1295540"
  },
  {
    "text": "the machine learning and then deployed through ACS so this is this leads us to",
    "start": "1295540",
    "end": "1303340"
  },
  {
    "text": "a reference architecture for actually deploying these different components",
    "start": "1303340",
    "end": "1308730"
  },
  {
    "text": "there's basically a series of commands that you're probably well familiar with doing this in on-premise environments or",
    "start": "1308730",
    "end": "1315430"
  },
  {
    "text": "in cloud environments without containers the idea first of all is to go through your commits so where you're going to",
    "start": "1315430",
    "end": "1321460"
  },
  {
    "text": "store your application code code commit is a service that will do that which is",
    "start": "1321460",
    "end": "1326740"
  },
  {
    "text": "a git compatible code repository service then we have the ability to trigger",
    "start": "1326740",
    "end": "1332049"
  },
  {
    "text": "events so actually have events that understand when a commit is is done they",
    "start": "1332049",
    "end": "1338260"
  },
  {
    "text": "kick off a pipeline in this case Co pipeline understands okay we're going to need to now build an artifact so update",
    "start": "1338260",
    "end": "1345520"
  },
  {
    "text": "our image push that image into ECR and the actual application deployment is",
    "start": "1345520",
    "end": "1350770"
  },
  {
    "text": "done at that point now if you look at step 5 that's when you're actually talking about updating the stack and looking at",
    "start": "1350770",
    "end": "1358090"
  },
  {
    "text": "what you're going to do so in this case we're looking at leveraging cloud formation to say hey there's an update",
    "start": "1358090",
    "end": "1363610"
  },
  {
    "text": "to the image we want you to deploy will define what your rollout looks like how many instances do you want to run at any",
    "start": "1363610",
    "end": "1369610"
  },
  {
    "text": "one time push that as an update which then notifies the ECS service that there",
    "start": "1369610",
    "end": "1375549"
  },
  {
    "text": "is a new image to pull from reaches out into ECR and then deploys across the",
    "start": "1375549",
    "end": "1381159"
  },
  {
    "text": "instances on the side so this gives you the the reference architecture this is this sort of the the the best practices",
    "start": "1381159",
    "end": "1388720"
  },
  {
    "text": "associated with it but what I'm going to do now is hand it back to to Nima to actually take you through what",
    "start": "1388720",
    "end": "1394059"
  },
  {
    "text": "Scotiabank did and how they mapped a similar model to their environment Thank",
    "start": "1394059",
    "end": "1401409"
  },
  {
    "text": "You Mai so before I start the demo I'd like to mention that this project is",
    "start": "1401409",
    "end": "1408000"
  },
  {
    "text": "partially done by our team which is D SMI data science and model innovation and the model development part of it is",
    "start": "1408000",
    "end": "1415600"
  },
  {
    "text": "done by a fin tech company AI company in Canada it's called deep learning so the",
    "start": "1415600",
    "end": "1421240"
  },
  {
    "text": "model development portion of what we did is done jointly by our team and deep learning which you're gonna see on these",
    "start": "1421240",
    "end": "1428020"
  },
  {
    "text": "slides so the things that you see on the left is a server that we have on Prem as",
    "start": "1428020",
    "end": "1435460"
  },
  {
    "text": "Scotiabank we call it the SMI a AWS gateway no we're using github and puppet",
    "start": "1435460",
    "end": "1442960"
  },
  {
    "text": "to deploy our our whole infrastructure to AWS and I'm going to explain why we",
    "start": "1442960",
    "end": "1449529"
  },
  {
    "text": "use puppet and the reasons behind the scene the github Enterprise instance that we have is fully on Prem",
    "start": "1449529",
    "end": "1455740"
  },
  {
    "text": "it's not github calm and the puppet is also on Prem so we have a pipeline internally to deploy",
    "start": "1455740",
    "end": "1462460"
  },
  {
    "text": "- to manage our infrastructure internally on s Koshiba ad Scotiabank and deploy our code to the",
    "start": "1462460",
    "end": "1469840"
  },
  {
    "text": "target servers and we use puppet for that we use the same we leverage the same system to do it on AWS as well so",
    "start": "1469840",
    "end": "1477330"
  },
  {
    "text": "by coding on the SMI gateway node AWS gateway gnome we create three buckets on",
    "start": "1477330",
    "end": "1485130"
  },
  {
    "text": "on AWS three s3 buckets one for the code one for input data and one for the",
    "start": "1485130",
    "end": "1492070"
  },
  {
    "text": "results that we create using our machine learning and we can create our own policies budget policies by just passing",
    "start": "1492070",
    "end": "1498880"
  },
  {
    "text": "a JSON file to the puppet code and we create all those three so here I'm gonna",
    "start": "1498880",
    "end": "1505179"
  },
  {
    "text": "show you how how it works on AWS and how the puppet code looks like it's the the",
    "start": "1505179",
    "end": "1511480"
  },
  {
    "text": "right pane is the AWS console that I have and I have a couple of puppet code with with different things that I'm",
    "start": "1511480",
    "end": "1518950"
  },
  {
    "text": "doing this is the s3 creation as you see the policies are commented out but you can pass the policy this is only for",
    "start": "1518950",
    "end": "1525460"
  },
  {
    "text": "reinvent purposes it's not the actual thing that we did but we passed the right policies to the AWS budget as well",
    "start": "1525460",
    "end": "1532720"
  },
  {
    "text": "with one single command I create puppet apply create s3 buckets it's our code",
    "start": "1532720",
    "end": "1539590"
  },
  {
    "text": "and I run it in debug mode before I run it I do a refresh on the console the s",
    "start": "1539590",
    "end": "1546850"
  },
  {
    "text": "trees are not there yet as you see there's three buckets are not created",
    "start": "1546850",
    "end": "1552640"
  },
  {
    "text": "now I click on it this AWS gateway node is locked down on Prem and we have all",
    "start": "1552640",
    "end": "1559900"
  },
  {
    "text": "the credentials required to create that that cluster and anything that we do on",
    "start": "1559900",
    "end": "1565059"
  },
  {
    "text": "AWS we lock down the the credentials on this box and as you see the three s3",
    "start": "1565059",
    "end": "1571420"
  },
  {
    "text": "buckets are created please simply by by one line of code once we are done with",
    "start": "1571420",
    "end": "1577900"
  },
  {
    "text": "s3 creations we have to push the data that we have on Prem the data that we",
    "start": "1577900",
    "end": "1584700"
  },
  {
    "text": "anonymized we remove the sensitive data from it the credit card numbers the all the sensitive data are mapped to",
    "start": "1584700",
    "end": "1592159"
  },
  {
    "text": "to a data set that we have on Prem we're not pushing that data to AWS we mapped",
    "start": "1592159",
    "end": "1597500"
  },
  {
    "text": "the actual data I mean we anonymize the the sensitive columns and then using the",
    "start": "1597500",
    "end": "1603169"
  },
  {
    "text": "the AWS CLI we push the data to to the s3 input budget that we have and we take",
    "start": "1603169",
    "end": "1611029"
  },
  {
    "text": "care of the encryption as well oh I have to go go back I just clicked it by",
    "start": "1611029",
    "end": "1616220"
  },
  {
    "text": "mistake yeah okay",
    "start": "1616220",
    "end": "1624200"
  },
  {
    "text": "so here as you see the input input bucket is empty and now with one with",
    "start": "1624200",
    "end": "1632389"
  },
  {
    "text": "one single line of code I push the data to AWS and again this is just the sample",
    "start": "1632389",
    "end": "1640789"
  },
  {
    "text": "data it's not the actual data that we use in our in our actual production environment and you see the data box at",
    "start": "1640789",
    "end": "1651799"
  },
  {
    "text": "the input data bucket is now with input data CSV the next thing is to create our",
    "start": "1651799",
    "end": "1659659"
  },
  {
    "text": "own ECR because we cannot as a financial industry Institute we cannot use docker",
    "start": "1659659",
    "end": "1665450"
  },
  {
    "text": "hub for as our registry for our daughter docker images so we used ECR we created",
    "start": "1665450",
    "end": "1671630"
  },
  {
    "text": "our own ECR with the policies that we need using puppet so again this this and",
    "start": "1671630",
    "end": "1677240"
  },
  {
    "text": "all these codes that I'm showing you there already open sourced for you you can you can leverage them after this so",
    "start": "1677240",
    "end": "1683330"
  },
  {
    "text": "here I'm creating the ECR using again one single puppet module that we created",
    "start": "1683330",
    "end": "1691519"
  },
  {
    "text": "in-house we are running puppet apply again as you see and the right pane is",
    "start": "1691519",
    "end": "1698210"
  },
  {
    "text": "showing the ECR that is not great not there yet and after i refresh one more",
    "start": "1698210",
    "end": "1704809"
  },
  {
    "text": "time i need to go to the easy is yes you",
    "start": "1704809",
    "end": "1710059"
  },
  {
    "text": "see that I created the registry it's like my own private registry that deep",
    "start": "1710059",
    "end": "1715580"
  },
  {
    "text": "learning team now can can push their docker images too so now the filter",
    "start": "1715580",
    "end": "1721940"
  },
  {
    "text": "company that I explained they come and they want to create their training training darker images to push to easy",
    "start": "1721940",
    "end": "1729159"
  },
  {
    "text": "art that I allow them to push they can only push they can not delete the darker",
    "start": "1729159",
    "end": "1734559"
  },
  {
    "text": "images from these container registry that I created for them so all the policies are taken care of they only",
    "start": "1734559",
    "end": "1741099"
  },
  {
    "text": "push and they don't have any more visibility we ask them to push the ECR with one single command again this is",
    "start": "1741099",
    "end": "1748359"
  },
  {
    "text": "just another image that I that I pushed in these are the images that I have on that machine with docker images you see",
    "start": "1748359",
    "end": "1755139"
  },
  {
    "text": "the images that are there and then I tag the images and then easily because I already logged into my ECR I can push",
    "start": "1755139",
    "end": "1761889"
  },
  {
    "text": "the image to ECR again it takes like five seconds to push these images to the",
    "start": "1761889",
    "end": "1769599"
  },
  {
    "text": "ECR and once it's done I'm gonna show you",
    "start": "1769599",
    "end": "1775210"
  },
  {
    "text": "the console that had all these images that we need actually the one image that",
    "start": "1775210",
    "end": "1781239"
  },
  {
    "text": "we need is there one you see our this is the thing that I created before this and",
    "start": "1781239",
    "end": "1787029"
  },
  {
    "text": "now I have my machine learning training image there as well so now this this",
    "start": "1787029",
    "end": "1796509"
  },
  {
    "text": "image this container when it runs it has to get the data from my input as three",
    "start": "1796509",
    "end": "1802119"
  },
  {
    "text": "bucket it needs to do the training on it and then it spits out the the the",
    "start": "1802119",
    "end": "1808809"
  },
  {
    "text": "algorithms to think the models that we want to run against the actual data to two different two to one bucket the data",
    "start": "1808809",
    "end": "1816070"
  },
  {
    "text": "bucket and then we rerun it against the actual data and we have the output data",
    "start": "1816070",
    "end": "1821849"
  },
  {
    "text": "so now how it this whole diagram shows",
    "start": "1821849",
    "end": "1827499"
  },
  {
    "text": "what we do when we create the cluster and the cluster creation has multiple",
    "start": "1827499",
    "end": "1833469"
  },
  {
    "text": "steps we create the whole thing the whole infrastructure using puppet the",
    "start": "1833469",
    "end": "1838899"
  },
  {
    "text": "first thing that we do is creating the VP C's and all the configurations we don't allow all the people from all",
    "start": "1838899",
    "end": "1845259"
  },
  {
    "text": "around the world to connect to our ec2 instances we block all the possible ports SSH is blocked HTTP block they",
    "start": "1845259",
    "end": "1851440"
  },
  {
    "text": "should be s as well all the ports are blocked we take care of the security groups there we only allowing IP addresses from",
    "start": "1851440",
    "end": "1857880"
  },
  {
    "text": "within Scotiabank to connect to our instances just in case we are creating the route tables all that using the",
    "start": "1857880",
    "end": "1865559"
  },
  {
    "text": "puppet module and then after we do we take care of that we create our ECS and",
    "start": "1865559",
    "end": "1871679"
  },
  {
    "text": "the cluster ec2 class ec2 instances cluster using the same module and we",
    "start": "1871679",
    "end": "1877620"
  },
  {
    "text": "create our task definitions for docker images we say this docker image is the one that you're gonna run and we also",
    "start": "1877620",
    "end": "1884360"
  },
  {
    "text": "schedule it through the same 1:1 create cluster that PP file which I'm gonna",
    "start": "1884360",
    "end": "1891059"
  },
  {
    "text": "show you next and it's a long video so here I go to",
    "start": "1891059",
    "end": "1898320"
  },
  {
    "text": "the puppet module that is supposed to do that we go to create cluster phoppik",
    "start": "1898320",
    "end": "1904860"
  },
  {
    "text": "nodule and I'm gonna give you a very quick snapshot of what it looks like",
    "start": "1904860",
    "end": "1910970"
  },
  {
    "text": "there's like how which region you want to bring up your cluster what are the IPS that can access it what is the",
    "start": "1913429",
    "end": "1920610"
  },
  {
    "text": "security group that you define what is the image that you are going to take from ECR the image that I just pushed",
    "start": "1920610",
    "end": "1928940"
  },
  {
    "text": "and then I can name it all those things and then I have to say what is the task",
    "start": "1928940",
    "end": "1934980"
  },
  {
    "text": "definition when I want to run it how I want to run it so here I go to the test",
    "start": "1934980",
    "end": "1941580"
  },
  {
    "text": "folder which is a common practice for puppet and then I run the create cluster",
    "start": "1941580",
    "end": "1947750"
  },
  {
    "text": "puppet bound Rose puppet apply is the way that we run it it's only for the",
    "start": "1947750",
    "end": "1953160"
  },
  {
    "text": "demo the actual thing is is managed by puppet master internally and all these",
    "start": "1953160",
    "end": "1959160"
  },
  {
    "text": "things are locked down this is only for the purpose of reinvent that I'm creating this cluster so here the very",
    "start": "1959160",
    "end": "1966179"
  },
  {
    "text": "first thing that I'm doing on the left thing if you can't read the last line it's to create the ec2 V PC I'm creating",
    "start": "1966179",
    "end": "1975270"
  },
  {
    "text": "that V PC before I bring up anything on you in my cluster and that in in the region",
    "start": "1975270",
    "end": "1981450"
  },
  {
    "text": "and in that VP see once the VP see is is there all the security groups now your",
    "start": "1981450",
    "end": "1987570"
  },
  {
    "text": "it is creating the security group now and if if the security group is already created by any other puppet module or I",
    "start": "1987570",
    "end": "1994559"
  },
  {
    "text": "have done it before it just skips it it uses that security group once the security group is done and",
    "start": "1994559",
    "end": "2001299"
  },
  {
    "text": "these are all set with the security we have all the security requirement around",
    "start": "2001299",
    "end": "2006799"
  },
  {
    "text": "this so security came and looked at the code and they're like okay this is good",
    "start": "2006799",
    "end": "2011929"
  },
  {
    "text": "enough you can deploy I create the ec2 V PC Internet gateway as well and there",
    "start": "2011929",
    "end": "2019669"
  },
  {
    "text": "are a table after that as you see and once all of these are done we are good with the security perspective and we we",
    "start": "2019669",
    "end": "2027230"
  },
  {
    "text": "can kind of our our infrastructure is secure enough then we go through the",
    "start": "2027230",
    "end": "2033620"
  },
  {
    "text": "subnet creation and after that we bring up there the ec2 instances we pull the",
    "start": "2033620",
    "end": "2039380"
  },
  {
    "text": "images from from ECR and we start running it by the task definition that we already have in our puppet module so",
    "start": "2039380",
    "end": "2047929"
  },
  {
    "text": "looking at this it's it's almost over easy to be PC subnet is done and now",
    "start": "2047929",
    "end": "2053089"
  },
  {
    "text": "it's going to us East one two to bring up the ec2 instances that I have in this",
    "start": "2053089",
    "end": "2058490"
  },
  {
    "text": "but by changing a common Yama file I only added five instances I think five",
    "start": "2058490",
    "end": "2064128"
  },
  {
    "text": "to to use the ECR in the image that I push to ECR and take",
    "start": "2064129",
    "end": "2069290"
  },
  {
    "text": "it there pull it there and start running it on these on the cluster of five nodes",
    "start": "2069290",
    "end": "2074618"
  },
  {
    "text": "and again in the in the code in my puppet code I can specify what image I",
    "start": "2074619",
    "end": "2080118"
  },
  {
    "text": "want to point to for the for these instances as you see the instances are",
    "start": "2080119",
    "end": "2085429"
  },
  {
    "text": "coming up they serve the purpose of running the model and scoring them against the data that I have on the s3",
    "start": "2085429",
    "end": "2092858"
  },
  {
    "text": "input input bucket one more click I see that they are",
    "start": "2092859",
    "end": "2100220"
  },
  {
    "text": "coming up now and they will be run shortly so with with this we could",
    "start": "2100220",
    "end": "2107180"
  },
  {
    "text": "easily bring up a cluster on any region because I needed to just change one parameter in my llamo code say refer to",
    "start": "2107180",
    "end": "2114500"
  },
  {
    "text": "this I wanted to be in Canada center region and boom the infrastructure is",
    "start": "2114500",
    "end": "2121069"
  },
  {
    "text": "operating that's it so the now these guys are doing all the calculation and",
    "start": "2121069",
    "end": "2127609"
  },
  {
    "text": "everything and push the scores back to the and this is the diagram they took",
    "start": "2127609",
    "end": "2134450"
  },
  {
    "text": "the image from ECR and the input data they ran it and they push the results to",
    "start": "2134450",
    "end": "2140059"
  },
  {
    "text": "another bucket which is if I go to the console and do just a refresh on s3",
    "start": "2140059",
    "end": "2146690"
  },
  {
    "text": "buckets that I have I go to reinvent Scotia output and I have the CSV files",
    "start": "2146690",
    "end": "2154250"
  },
  {
    "text": "already created if I have full access I can download it if not I can simply go",
    "start": "2154250",
    "end": "2160220"
  },
  {
    "text": "to ally and all I get it",
    "start": "2160220",
    "end": "2166480"
  },
  {
    "text": "this is the gateway note that we have I can get it from there",
    "start": "2167109",
    "end": "2174940"
  },
  {
    "text": "and the csv files will be pushed to on-prem and this is the scores of our",
    "start": "2178010",
    "end": "2184490"
  },
  {
    "text": "models if I if I look at it again this is a simplified simplified version of",
    "start": "2184490",
    "end": "2191180"
  },
  {
    "text": "what we actually have but you have the account numbers and the scores created",
    "start": "2191180",
    "end": "2196970"
  },
  {
    "text": "for you so here after this how did we",
    "start": "2196970",
    "end": "2203110"
  },
  {
    "text": "leverage puppet why did we use it first we have the pipeline created already for",
    "start": "2203110",
    "end": "2211310"
  },
  {
    "text": "on-prem purposes we are using we are we are using puppet as our enterprise",
    "start": "2211310",
    "end": "2216470"
  },
  {
    "text": "conflict management tool to manage our infrastructure as well as deploying the",
    "start": "2216470",
    "end": "2224080"
  },
  {
    "text": "applications to target servers so we use the same technique to to use it against",
    "start": "2224080",
    "end": "2231260"
  },
  {
    "text": "AWS instances that we are bringing up that was part of the reason second was that it's is pretty simple to use it was",
    "start": "2231260",
    "end": "2239180"
  },
  {
    "text": "very easy to get the puppet code that we had we we found on puppet Forge and we",
    "start": "2239180",
    "end": "2245600"
  },
  {
    "text": "could just modify it and reuse it the third reason was that there is bunch of",
    "start": "2245600",
    "end": "2251810"
  },
  {
    "text": "open source modules already created by very smart people and they are already there on puppet board and we could",
    "start": "2251810",
    "end": "2258410"
  },
  {
    "text": "leverage them and how did we do it there is three modules technically that we are",
    "start": "2258410",
    "end": "2264440"
  },
  {
    "text": "we are using and these three are open source for you one is AWS puppet module that you can",
    "start": "2264440",
    "end": "2271460"
  },
  {
    "text": "take from from puppet fort today it's there and puppet guys are updating it",
    "start": "2271460",
    "end": "2277220"
  },
  {
    "text": "every day look at number of times it's downloaded you you get a sense of how good it is and people keep rating them",
    "start": "2277220",
    "end": "2284350"
  },
  {
    "text": "so we have that AWS puppet module we created two modules for ourselves which",
    "start": "2284350",
    "end": "2290570"
  },
  {
    "text": "I open sourced for you cloud setup puppet module takes care of the proxy",
    "start": "2290570",
    "end": "2295970"
  },
  {
    "text": "takes care of the security all the credentials AWS access",
    "start": "2295970",
    "end": "2303150"
  },
  {
    "text": "key and secret key you can put it there and create and it takes care of the proxy and everything depending on your",
    "start": "2303150",
    "end": "2309420"
  },
  {
    "text": "organization you can use puppet set up top add module and the third thing that we have is cloud formation all the",
    "start": "2309420",
    "end": "2315810"
  },
  {
    "text": "cluster creation security creation VP sees security groups all that is handled",
    "start": "2315810",
    "end": "2322230"
  },
  {
    "text": "by a cloud formation and in that file you can define tasks you can in that module you can define tasks use use how",
    "start": "2322230",
    "end": "2330240"
  },
  {
    "text": "to create easy are how to create easy ECS cluster how to use s3 how to create",
    "start": "2330240",
    "end": "2336840"
  },
  {
    "text": "s3 how to push to s3 all of that code is under cloud formation puppet module here",
    "start": "2336840",
    "end": "2343920"
  },
  {
    "text": "I'm gonna I just gave you a snapshot snapshot of different pieces of code that we have on the Left I have how to",
    "start": "2343920",
    "end": "2350550"
  },
  {
    "text": "create easy to be PC this is how how easy it is to use the cloud setup puppet",
    "start": "2350550",
    "end": "2357210"
  },
  {
    "text": "module just access key and a secret key you can you can lock it down so no one can see it as well you you see how to",
    "start": "2357210",
    "end": "2364560"
  },
  {
    "text": "create the subnet how to create the cluster how many knows how many ec2 instances you want to create on the mill on the",
    "start": "2364560",
    "end": "2371250"
  },
  {
    "text": "one in the middle and how to define the the tasks and everything on the ones on",
    "start": "2371250",
    "end": "2376560"
  },
  {
    "text": "the top down and sorry on the right side of this with deep learning models what",
    "start": "2376560",
    "end": "2384540"
  },
  {
    "text": "did we achieve previously we had like 20 variables that we could go against and",
    "start": "2384540",
    "end": "2390360"
  },
  {
    "text": "and define our models today using deep learning we're using over 300",
    "start": "2390360",
    "end": "2397340"
  },
  {
    "text": "credit-bureau variables as an input variable for our models so Big Data",
    "start": "2397340",
    "end": "2403290"
  },
  {
    "text": "helped us a lot I mean in using deep learning the the the code that we wrote",
    "start": "2403290",
    "end": "2410400"
  },
  {
    "text": "is not we deep learning team jointly with us the code that they wrote is",
    "start": "2410400",
    "end": "2415590"
  },
  {
    "text": "purely in Python and they're using tensorflow there are a bunch of hyper",
    "start": "2415590",
    "end": "2420930"
  },
  {
    "text": "parameters that they used and they are mentioned all there and we're using grid search and what they did is 10-fold",
    "start": "2420930",
    "end": "2427740"
  },
  {
    "text": "cross-validation where the stratification for the deep deep learning models that",
    "start": "2427740",
    "end": "2433019"
  },
  {
    "text": "table that you see in the top bottom right is how we could actually increase",
    "start": "2433019",
    "end": "2439970"
  },
  {
    "text": "the the scores and how much lift did we actually have at Scotiabank detecting",
    "start": "2439970",
    "end": "2446759"
  },
  {
    "text": "the delinquents delinquencies earlier so November 2014 the lift is about twenty",
    "start": "2446759",
    "end": "2453960"
  },
  {
    "text": "percent in January 15 the lift is about 19 May 15 data that left is about 18",
    "start": "2453960",
    "end": "2462180"
  },
  {
    "text": "percent and August 2015 is about 19 percent so we could improve",
    "start": "2462180",
    "end": "2468180"
  },
  {
    "text": "significantly using this finally I'd",
    "start": "2468180",
    "end": "2474119"
  },
  {
    "text": "like to before I go through the results I'd like to thank to to to a specific",
    "start": "2474119",
    "end": "2479460"
  },
  {
    "text": "people one one of them is year Sohail fair go I had the data science and modern innovation team this year and my",
    "start": "2479460",
    "end": "2487200"
  },
  {
    "text": "colleague Neil Gonzales who was purely responsible for data extraction and",
    "start": "2487200",
    "end": "2494029"
  },
  {
    "text": "working with deep learning team to do the the algorithms and as a result what",
    "start": "2494029",
    "end": "2501059"
  },
  {
    "text": "we did we created orchestrated and terminated all the ec2 instances with",
    "start": "2501059",
    "end": "2506789"
  },
  {
    "text": "container registry ECS container easy to container services and everything that",
    "start": "2506789",
    "end": "2513720"
  },
  {
    "text": "we did we used puppet we synchronize the data that we we have on s3",
    "start": "2513720",
    "end": "2520769"
  },
  {
    "text": "in-house using s3 on AWS and internally",
    "start": "2520769",
    "end": "2526019"
  },
  {
    "text": "we used github and we used git LFS to to push the the data to security we take",
    "start": "2526019",
    "end": "2533309"
  },
  {
    "text": "care of I am roles and everything using JSON passing it to the puppet modules for both s3 buckets and also for the ec2",
    "start": "2533309",
    "end": "2543509"
  },
  {
    "text": "instances that we bring up we give them roles to so those are the only instances",
    "start": "2543509",
    "end": "2549690"
  },
  {
    "text": "that can take the data from input folder input bucket on s3 so no one else even",
    "start": "2549690",
    "end": "2557609"
  },
  {
    "text": "ourselves in fact I created so many dormant s3 buckets on this project and I",
    "start": "2557609",
    "end": "2562890"
  },
  {
    "text": "had to like the Amazon to delete them but nobody can can actually go to our s3",
    "start": "2562890",
    "end": "2569460"
  },
  {
    "text": "bucket instead the only one thing go are the ec2 instances that we bring up on",
    "start": "2569460",
    "end": "2574590"
  },
  {
    "text": "this cluster and we manage that using I am rolls all the applications that we",
    "start": "2574590",
    "end": "2580140"
  },
  {
    "text": "wrote are containerized everything is in docker images and everything is stored",
    "start": "2580140",
    "end": "2585150"
  },
  {
    "text": "on ECR changing the cluster as you saw in the demo it's pretty easy by just",
    "start": "2585150",
    "end": "2592020"
  },
  {
    "text": "changing the parameters and one single line of code we can bring up the whole cluster shut it down pretty easily and",
    "start": "2592020",
    "end": "2598460"
  },
  {
    "text": "we could we could do a rapid development and we can also trace everything that we",
    "start": "2598460",
    "end": "2604770"
  },
  {
    "text": "did because we have all the audit logs and everything it's not in this demo but everything that is that everything that",
    "start": "2604770",
    "end": "2611610"
  },
  {
    "text": "we did was was traceable as well I think I'm done almost I'm gonna hand",
    "start": "2611610",
    "end": "2618960"
  },
  {
    "text": "it back to one more oh there's a success sorry there's a success story we were",
    "start": "2618960",
    "end": "2625920"
  },
  {
    "text": "interviewed by Wall Street Journal after we've done it and our CIO went to this",
    "start": "2625920",
    "end": "2631470"
  },
  {
    "text": "meeting and we were recognized by Wall Street of how we how we could improve",
    "start": "2631470",
    "end": "2637890"
  },
  {
    "text": "the collection strategies for the Bank of Nova Scotia I'm gonna hand it back",
    "start": "2637890",
    "end": "2643050"
  },
  {
    "text": "thank you very much so I think about Neiman just before you",
    "start": "2643050",
    "end": "2648060"
  },
  {
    "text": "go if you had to sort of impart to people two or three things what do you",
    "start": "2648060",
    "end": "2653940"
  },
  {
    "text": "think were the most important parts of this project I think the most important",
    "start": "2653940",
    "end": "2659220"
  },
  {
    "text": "thing is is that it was done the reason that we did it was that it was very",
    "start": "2659220",
    "end": "2664740"
  },
  {
    "text": "simple it was doable and we we could actually really easily use these",
    "start": "2664740",
    "end": "2672930"
  },
  {
    "text": "techniques that we're doing in-house I just just use it for AWS as well so",
    "start": "2672930",
    "end": "2678740"
  },
  {
    "text": "simplicity is one of the key factors why we chose this and second one is that we",
    "start": "2678740",
    "end": "2686250"
  },
  {
    "text": "we were given the freedom to do it and I really appreciate that from the high level management I said",
    "start": "2686250",
    "end": "2692670"
  },
  {
    "text": "yeah we trust you go for it as long as security approved it go for it and I think those",
    "start": "2692670",
    "end": "2698429"
  },
  {
    "text": "two factors were the key ones so I mean if you think back over over the presentation the Scotiabank identified a",
    "start": "2698429",
    "end": "2706229"
  },
  {
    "text": "particular problem area within within their consumer base which was payments",
    "start": "2706229",
    "end": "2711269"
  },
  {
    "text": "collections and delinquency rates was able to demonstrate a market improvement",
    "start": "2711269",
    "end": "2716609"
  },
  {
    "text": "over the existing processes and the way in which they engage their customers they had a platform and orchestration",
    "start": "2716609",
    "end": "2724739"
  },
  {
    "text": "services allowed them to focus on the actual problem that they were trying to solve for had the right hardware had the",
    "start": "2724739",
    "end": "2731579"
  },
  {
    "text": "right security components and able to achieve approval and get the buy-in from their executive sponsors and were able",
    "start": "2731579",
    "end": "2738329"
  },
  {
    "text": "to improve this as Nima mentioned you know single line change deployments will allow them to target any region where",
    "start": "2738329",
    "end": "2745259"
  },
  {
    "text": "they were able to to deploy so the call to action here for those who are here we",
    "start": "2745259",
    "end": "2752399"
  },
  {
    "text": "have available today blog posts that will walk you through exactly how how",
    "start": "2752399",
    "end": "2758459"
  },
  {
    "text": "you can orchestrate gpu-accelerated workloads through ECS we have a workshop that you can you can go through to get",
    "start": "2758459",
    "end": "2765089"
  },
  {
    "text": "hands-on experience with it there's a link to the deep learning ami which has all the frameworks ready to go for you",
    "start": "2765089",
    "end": "2771809"
  },
  {
    "text": "as well Nima as you mentioned has open sourced the puppet modules that we're actually used by Scotiabank and they are",
    "start": "2771809",
    "end": "2777779"
  },
  {
    "text": "available here so we would strongly encourage you to go through these as well if you're interested in learning",
    "start": "2777779",
    "end": "2783749"
  },
  {
    "text": "more about the actual machine learning models that were deployed in this there is another session later this week on",
    "start": "2783749",
    "end": "2790769"
  },
  {
    "text": "Thursday it's Khan 408 we're deep learning we'll be presenting the machine learning components that they deployed",
    "start": "2790769",
    "end": "2796679"
  },
  {
    "text": "for this application so with that I would like to thank you all for coming and thank Nima as well as Suhail and",
    "start": "2796679",
    "end": "2803969"
  },
  {
    "text": "this Scotiabank team for working with us and presenting today and I hope you guys",
    "start": "2803969",
    "end": "2809189"
  },
  {
    "text": "have a fantastic rest of your industry day thank you very much and please remember to complete your",
    "start": "2809189",
    "end": "2815559"
  },
  {
    "text": "evaluation",
    "start": "2815559",
    "end": "2818190"
  }
]
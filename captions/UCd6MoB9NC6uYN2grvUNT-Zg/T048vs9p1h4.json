[
  {
    "text": "Hi, welcome to 'This is My Architecture'.",
    "start": "7542",
    "end": "9689"
  },
  {
    "text": "I'm Yu Hua, I'm here today\nwith Jose from DBS Bank.",
    "start": "9689",
    "end": "12495"
  },
  {
    "text": "Welcome, Jose.",
    "start": "12495",
    "end": "13509"
  },
  {
    "text": "Thanks for having me here.",
    "start": "13509",
    "end": "14747"
  },
  {
    "text": "So, Jose, can you share a bit\nabout DBS Bank with us?",
    "start": "14747",
    "end": "17357"
  },
  {
    "text": "DBS Bank is a leading financial service group\nin Asia.",
    "start": "17357",
    "end": "20858"
  },
  {
    "text": "Nowadays we call ourselves\nthe digital bank of Singapore.",
    "start": "20858",
    "end": "23886"
  },
  {
    "text": "So I know we are here today to talk about\na serverless compute grid use case",
    "start": "23886",
    "end": "26600"
  },
  {
    "text": "within DBS Bank.",
    "start": "26600",
    "end": "28159"
  },
  {
    "text": "Can you share with us more details on that?",
    "start": "28159",
    "end": "30051"
  },
  {
    "text": "Our compute grid is being used to price\nexotic option trades,",
    "start": "30051",
    "end": "35650"
  },
  {
    "text": "which are using the mathematical models\ndeveloped at DBS,",
    "start": "35650",
    "end": "39594"
  },
  {
    "text": "and application\nwhich calls the grid is Murex,",
    "start": "39594",
    "end": "42631"
  },
  {
    "text": "which is\nour main, primary trading application",
    "start": "42631",
    "end": "46749"
  },
  {
    "text": "and risk platform.",
    "start": "46749",
    "end": "48204"
  },
  {
    "text": "So before we dive deeper\ninto the architecture itself,",
    "start": "49222",
    "end": "51593"
  },
  {
    "text": "can you share with us\nwhat was the challenge",
    "start": "51593",
    "end": "53042"
  },
  {
    "text": "that your team was trying to solve?",
    "start": "53042",
    "end": "54055"
  },
  {
    "text": "Okay.",
    "start": "54055",
    "end": "55066"
  },
  {
    "text": "In grid computing cluster,\nwe have two major components,",
    "start": "55066",
    "end": "59097"
  },
  {
    "text": "which is the compute itself,\nand so this compute,",
    "start": "59097",
    "end": "62170"
  },
  {
    "text": "we have migrated from our physical servers",
    "start": "62170",
    "end": "65068"
  },
  {
    "text": "to AWS Cloud in the past, in 2017,",
    "start": "65068",
    "end": "68766"
  },
  {
    "text": "and we were able to save\nalmost 80% of our infra cost.",
    "start": "68766",
    "end": "73812"
  },
  {
    "text": "Now the second component,\nwhich is a grid...",
    "start": "73812",
    "end": "76151"
  },
  {
    "text": "Grid scheduler software,",
    "start": "78106",
    "end": "79764"
  },
  {
    "text": "which is a third party software\nand it is being licensed based",
    "start": "79764",
    "end": "82775"
  },
  {
    "text": "on the number of cores in your cluster.",
    "start": "82775",
    "end": "85432"
  },
  {
    "text": "Now this itself actually limits us\nto scale as in when we need it.",
    "start": "85432",
    "end": "90676"
  },
  {
    "text": "Looking at your architecture,",
    "start": "92378",
    "end": "93378"
  },
  {
    "text": "I see that are\nmultiple Amazon SQS queues being used.",
    "start": "93378",
    "end": "96631"
  },
  {
    "text": "Is there a rationale behind that design?",
    "start": "96631",
    "end": "98653"
  },
  {
    "text": "Yes.",
    "start": "98653",
    "end": "99665"
  },
  {
    "text": "So in Murex application\nwe have multiple types of users,",
    "start": "99665",
    "end": "103938"
  },
  {
    "text": "like high-priority users\nand so what we have done,",
    "start": "103938",
    "end": "107346"
  },
  {
    "text": "we have divided the queues\ninto high, medium, and low.",
    "start": "107346",
    "end": "110423"
  },
  {
    "text": "So that in case, for example,\nlike when the trader makes his submission",
    "start": "110423",
    "end": "116024"
  },
  {
    "text": "to the grid,\nactually it hits the high queue,",
    "start": "116025",
    "end": "120666"
  },
  {
    "text": "and the back office users\nwill be in the medium,",
    "start": "120666",
    "end": "123763"
  },
  {
    "text": "and the batch users\nare actually going to the low queue.",
    "start": "123763",
    "end": "127241"
  },
  {
    "text": "I see that you also have\nmultiple AWS Lambda functions.",
    "start": "127241",
    "end": "130573"
  },
  {
    "text": "Out of curiosity,\nare they the same Lambda functions",
    "start": "130573",
    "end": "132567"
  },
  {
    "text": "or are they different?",
    "start": "132567",
    "end": "133582"
  },
  {
    "text": "Yes, they are same Lambda functions.",
    "start": "133582",
    "end": "135553"
  },
  {
    "text": "So when we started we only had\none Lambda function for multiple queues,",
    "start": "135553",
    "end": "139754"
  },
  {
    "text": "and we found\nthat the performance was not so good.",
    "start": "139754",
    "end": "143046"
  },
  {
    "text": "So what we have done\nis we have divided them,",
    "start": "143046",
    "end": "145528"
  },
  {
    "text": "we just duplicated them as same function,",
    "start": "145528",
    "end": "149775"
  },
  {
    "text": "just to manage our provisioned concurrency.",
    "start": "149775",
    "end": "153181"
  },
  {
    "text": "So by having provisioned concurrency,",
    "start": "153181",
    "end": "155430"
  },
  {
    "text": "for example, if I give\na provisioned concurrency of 300 to high",
    "start": "155430",
    "end": "161137"
  },
  {
    "text": "and 200 to the low,",
    "start": "161137",
    "end": "163021"
  },
  {
    "text": "and then 100 here, then we have almost,",
    "start": "163021",
    "end": "167075"
  },
  {
    "text": "and a buffer of 500, so total 1,000 Lambdas.",
    "start": "167075",
    "end": "169929"
  },
  {
    "text": "I can actually better scale\nfor each of the queues.",
    "start": "169929",
    "end": "173309"
  },
  {
    "text": "So interesting.",
    "start": "173309",
    "end": "174319"
  },
  {
    "text": "So with this design you can maintain\na quality of service",
    "start": "174319",
    "end": "176778"
  },
  {
    "text": "for different groups of users.",
    "start": "176778",
    "end": "177800"
  },
  {
    "text": "Yes, you're right.",
    "start": "177800",
    "end": "179089"
  },
  {
    "text": "You're also using\nmultiple different AWS storage services,",
    "start": "179089",
    "end": "182738"
  },
  {
    "text": "such as Amazon S3 and Amazon EFS.",
    "start": "182738",
    "end": "185375"
  },
  {
    "text": "Can you share with us\nwhat types of data",
    "start": "185375",
    "end": "186701"
  },
  {
    "text": "are you storing in those services?",
    "start": "186701",
    "end": "187705"
  },
  {
    "text": "Okay.",
    "start": "187705",
    "end": "188718"
  },
  {
    "text": "So for the computation we need a input data",
    "start": "188718",
    "end": "192427"
  },
  {
    "text": "which are non-sensitive in their nature,",
    "start": "192427",
    "end": "194081"
  },
  {
    "text": "so we used to save all the data",
    "start": "194081",
    "end": "197390"
  },
  {
    "text": "into the S3 bucket in the beginning,",
    "start": "197390",
    "end": "200233"
  },
  {
    "text": "including the binary,",
    "start": "200233",
    "end": "201748"
  },
  {
    "text": "but you know that whenever the binary\nis actually downloaded into the Lambda,",
    "start": "201748",
    "end": "205975"
  },
  {
    "text": "we found that actually,",
    "start": "205975",
    "end": "208005"
  },
  {
    "text": "the size is not enough",
    "start": "208005",
    "end": "209174"
  },
  {
    "text": "because we have lots of binary\nin financial models,",
    "start": "209174",
    "end": "212345"
  },
  {
    "text": "so what we have chosen is EFS.",
    "start": "212345",
    "end": "214429"
  },
  {
    "text": "So EFS is mounted now in each of our Lambdas",
    "start": "214429",
    "end": "218360"
  },
  {
    "text": "and then we can avoid the cold start\nfor the Lambda itself,",
    "start": "218360",
    "end": "222020"
  },
  {
    "text": "because the binary is mounted\nin the Lambda itself.",
    "start": "222020",
    "end": "224803"
  },
  {
    "text": "So that's interesting.",
    "start": "224803",
    "end": "225846"
  },
  {
    "text": "So now EFS has become\nyour binary repository in some sense.",
    "start": "225846",
    "end": "228668"
  },
  {
    "text": "Yes, you're right.",
    "start": "228668",
    "end": "230231"
  },
  {
    "text": "Can I also assume that the output\nfrom the AWS Lambda functions executions",
    "start": "230231",
    "end": "233954"
  },
  {
    "text": "are being stored in DynamoDB?",
    "start": "233954",
    "end": "235590"
  },
  {
    "text": "Yes.",
    "start": "235591",
    "end": "236624"
  },
  {
    "text": "So DynamoDB we have chosen\nbecause of the throughput,",
    "start": "236624",
    "end": "240327"
  },
  {
    "text": "which it gives\nand it works very well with the Lambda.",
    "start": "240327",
    "end": "242760"
  },
  {
    "text": "So we store our output...",
    "start": "242760",
    "end": "245014"
  },
  {
    "text": "In a DynamoDB,",
    "start": "246924",
    "end": "248536"
  },
  {
    "text": "as well as the status of the function itself,",
    "start": "248536",
    "end": "250773"
  },
  {
    "text": "what has happened to the function, right,",
    "start": "250773",
    "end": "252413"
  },
  {
    "text": "whether it is failed or successful.",
    "start": "252413",
    "end": "254680"
  },
  {
    "text": "So when we request the output actually,\nwe check,",
    "start": "254680",
    "end": "258991"
  },
  {
    "text": "make sure that it is not\na duplicated execution",
    "start": "258991",
    "end": "262618"
  },
  {
    "text": "of the Lambda function.",
    "start": "262618",
    "end": "264770"
  },
  {
    "text": "This is the use of DynamoDB.",
    "start": "264770",
    "end": "266983"
  },
  {
    "text": "That's interesting.",
    "start": "266984",
    "end": "268724"
  },
  {
    "text": "Elasticsearch, are you using it\nfor monitoring purposes?",
    "start": "268724",
    "end": "271744"
  },
  {
    "text": "So yeah.",
    "start": "271744",
    "end": "272828"
  },
  {
    "text": "So Elasticsearch, what we are doing\nis our on-premise logs",
    "start": "272829",
    "end": "276622"
  },
  {
    "text": "and as well as all the AWS logs,",
    "start": "276622",
    "end": "278971"
  },
  {
    "text": "whichever the logs\nare actually coming from the Lambda,",
    "start": "278971",
    "end": "281395"
  },
  {
    "text": "everything is actually aggregated\nat Elasticsearch.",
    "start": "281395",
    "end": "284496"
  },
  {
    "text": "And then which we can use later",
    "start": "284497",
    "end": "286072"
  },
  {
    "text": "for end-to-end monitoring\nof the task computation,",
    "start": "286072",
    "end": "290253"
  },
  {
    "text": "while using Grafana.",
    "start": "290253",
    "end": "291300"
  },
  {
    "text": "Sure.",
    "start": "291300",
    "end": "292681"
  },
  {
    "text": "So, Jose, what are some of the future plans\nyou have for this architecture?",
    "start": "292682",
    "end": "296027"
  },
  {
    "text": "Yes.",
    "start": "296027",
    "end": "297035"
  },
  {
    "text": "So today actually,\nwhen we execute our Lambda,",
    "start": "297035",
    "end": "299738"
  },
  {
    "text": "we are able to execute",
    "start": "299738",
    "end": "302726"
  },
  {
    "text": "3,000 to 4,000 Lambdas per minute,",
    "start": "302726",
    "end": "306435"
  },
  {
    "text": "assuming that the current limit is 1,000,",
    "start": "306435",
    "end": "309207"
  },
  {
    "text": "but we want to enhance this actually further.",
    "start": "309207",
    "end": "311241"
  },
  {
    "text": "So recently AWS has announced",
    "start": "311241",
    "end": "313612"
  },
  {
    "text": "that they have increased the CPU",
    "start": "313612",
    "end": "317273"
  },
  {
    "text": "and memory of the Lambda function itself.",
    "start": "317273",
    "end": "319657"
  },
  {
    "text": "So we want to try micro-batching,",
    "start": "319657",
    "end": "322884"
  },
  {
    "text": "so that one Lambda function",
    "start": "322884",
    "end": "325062"
  },
  {
    "text": "can execute multiple calculations\nin parallel.",
    "start": "325062",
    "end": "328644"
  },
  {
    "text": "So our target is to actually execute",
    "start": "328644",
    "end": "332134"
  },
  {
    "text": "almost 30 to 40 million calculations per day.",
    "start": "332134",
    "end": "335291"
  },
  {
    "text": "So this is very interesting architecture.",
    "start": "336375",
    "end": "338258"
  },
  {
    "text": "Thank you for sharing it with us today.",
    "start": "338258",
    "end": "340185"
  },
  {
    "text": "And I hope you enjoyed it as well.",
    "start": "340185",
    "end": "342111"
  },
  {
    "text": "And thank you for watching\n'This is My Architecture'.",
    "start": "342111",
    "end": "344268"
  }
]
[
  {
    "start": "0",
    "end": "33000"
  },
  {
    "text": "so another key consideration in building",
    "start": "500",
    "end": "4350"
  },
  {
    "text": "a data Lake is we continue to try to add",
    "start": "4350",
    "end": "7849"
  },
  {
    "text": "capabilities to s3 that are really going",
    "start": "7849",
    "end": "11099"
  },
  {
    "text": "to enhance what you can do with your",
    "start": "11099",
    "end": "12750"
  },
  {
    "text": "data so last year the first step in this",
    "start": "12750",
    "end": "16198"
  },
  {
    "text": "was we introduced s3 select and glacier",
    "start": "16199",
    "end": "19380"
  },
  {
    "text": "select where essentially you can start",
    "start": "19380",
    "end": "22230"
  },
  {
    "text": "to access your data in a way that's much",
    "start": "22230",
    "end": "25320"
  },
  {
    "text": "more optimized for analytics and data",
    "start": "25320",
    "end": "27750"
  },
  {
    "text": "Lake style environments than just the",
    "start": "27750",
    "end": "30510"
  },
  {
    "text": "traditional get object and so",
    "start": "30510",
    "end": "34590"
  },
  {
    "start": "33000",
    "end": "93000"
  },
  {
    "text": "essentially the motivation behind",
    "start": "34590",
    "end": "36600"
  },
  {
    "text": "introducing this was if you think about",
    "start": "36600",
    "end": "39690"
  },
  {
    "text": "a lot of analytic tools it's about",
    "start": "39690",
    "end": "41550"
  },
  {
    "text": "scanning large volumes of data to get",
    "start": "41550",
    "end": "44879"
  },
  {
    "text": "specific parts of that data to actually",
    "start": "44879",
    "end": "47250"
  },
  {
    "text": "execute on redshift spectrum which I'll",
    "start": "47250",
    "end": "51300"
  },
  {
    "text": "talk about a little bit more essentially",
    "start": "51300",
    "end": "53789"
  },
  {
    "text": "is one of those scenarios where it's a",
    "start": "53789",
    "end": "55199"
  },
  {
    "text": "data warehouse a lot of data scans",
    "start": "55199",
    "end": "57329"
  },
  {
    "text": "typically involved you would",
    "start": "57329",
    "end": "59789"
  },
  {
    "text": "traditionally load that data into",
    "start": "59789",
    "end": "62329"
  },
  {
    "text": "redshift execute there but with trim you",
    "start": "62329",
    "end": "66180"
  },
  {
    "text": "can now store data in s3 as tables and",
    "start": "66180",
    "end": "70860"
  },
  {
    "text": "scan across those so when people ran",
    "start": "70860",
    "end": "73610"
  },
  {
    "text": "these type of jobs they queried a bunch",
    "start": "73610",
    "end": "77520"
  },
  {
    "text": "of data and into a lot of that data on",
    "start": "77520",
    "end": "80220"
  },
  {
    "text": "the floor after they retrieved it from",
    "start": "80220",
    "end": "82049"
  },
  {
    "text": "s3 so a lot of customers could only",
    "start": "82049",
    "end": "86520"
  },
  {
    "text": "potentially use about 10% of the data",
    "start": "86520",
    "end": "89100"
  },
  {
    "text": "that they would actually retrieve from",
    "start": "89100",
    "end": "91110"
  },
  {
    "text": "s3 at the end of the day and so",
    "start": "91110",
    "end": "94530"
  },
  {
    "start": "93000",
    "end": "163000"
  },
  {
    "text": "essentially what s3 select and glaciers",
    "start": "94530",
    "end": "97500"
  },
  {
    "text": "looked for was what if you could start",
    "start": "97500",
    "end": "101100"
  },
  {
    "text": "to intelligently have the storage layer",
    "start": "101100",
    "end": "103590"
  },
  {
    "text": "based on things like sequel expressions",
    "start": "103590",
    "end": "106820"
  },
  {
    "text": "do the scanning of the data and the",
    "start": "106820",
    "end": "109890"
  },
  {
    "text": "filtering of data in the storage layer",
    "start": "109890",
    "end": "112290"
  },
  {
    "text": "where the data lives and only return the",
    "start": "112290",
    "end": "115140"
  },
  {
    "text": "results that are relevant to those",
    "start": "115140",
    "end": "116790"
  },
  {
    "text": "sequel scans so you could start to do",
    "start": "116790",
    "end": "119250"
  },
  {
    "text": "things like from this object rather than",
    "start": "119250",
    "end": "122250"
  },
  {
    "text": "to a get object have a pushdown where",
    "start": "122250",
    "end": "125909"
  },
  {
    "text": "you could issue a sequel statement",
    "start": "125909",
    "end": "127500"
  },
  {
    "text": "saying select this object",
    "start": "127500",
    "end": "130450"
  },
  {
    "text": "then issue from this object essentially",
    "start": "130450",
    "end": "134050"
  },
  {
    "text": "sequel conditionals where you know maybe",
    "start": "134050",
    "end": "138280"
  },
  {
    "text": "you would say out of this object I only",
    "start": "138280",
    "end": "141010"
  },
  {
    "text": "want the data that is going to be if",
    "start": "141010",
    "end": "143980"
  },
  {
    "text": "it's demographic data you know a user",
    "start": "143980",
    "end": "146830"
  },
  {
    "text": "that is from this IP address or a range",
    "start": "146830",
    "end": "151840"
  },
  {
    "text": "of IP addresses push that down via",
    "start": "151840",
    "end": "154209"
  },
  {
    "text": "sequel statements s3 will perform that",
    "start": "154209",
    "end": "156940"
  },
  {
    "text": "scan only return the results that are",
    "start": "156940",
    "end": "159549"
  },
  {
    "text": "actually needed so if you think about",
    "start": "159549",
    "end": "162069"
  },
  {
    "text": "that that's very different the storage",
    "start": "162069",
    "end": "164680"
  },
  {
    "start": "163000",
    "end": "195000"
  },
  {
    "text": "is now intelligent and so you can start",
    "start": "164680",
    "end": "167290"
  },
  {
    "text": "to do things quicker more",
    "start": "167290",
    "end": "170140"
  },
  {
    "text": "cost-effectively a couple of examples we",
    "start": "170140",
    "end": "172989"
  },
  {
    "text": "had an essay that went and for fun using",
    "start": "172989",
    "end": "176650"
  },
  {
    "text": "lambda wrote a service MapReduce",
    "start": "176650",
    "end": "179650"
  },
  {
    "text": "function using s3 select and comparing",
    "start": "179650",
    "end": "184030"
  },
  {
    "text": "that to what they would do without",
    "start": "184030",
    "end": "185200"
  },
  {
    "text": "select and essentially for a given",
    "start": "185200",
    "end": "189640"
  },
  {
    "text": "function they were able to do a 2x",
    "start": "189640",
    "end": "193150"
  },
  {
    "text": "faster at 1/5 of the cost",
    "start": "193150",
    "end": "196450"
  },
  {
    "start": "195000",
    "end": "231000"
  },
  {
    "text": "another one is with EMR 5.18 which is",
    "start": "196450",
    "end": "200230"
  },
  {
    "text": "relatively new we now have a presto",
    "start": "200230",
    "end": "202870"
  },
  {
    "text": "connector for EMR that leverages s3",
    "start": "202870",
    "end": "205959"
  },
  {
    "text": "select where it essentially will do",
    "start": "205959",
    "end": "207549"
  },
  {
    "text": "predicate push down and use s3 select to",
    "start": "207549",
    "end": "212319"
  },
  {
    "text": "pre-filter data so now if you consider a",
    "start": "212319",
    "end": "215590"
  },
  {
    "text": "job before a job after it can be as much",
    "start": "215590",
    "end": "219130"
  },
  {
    "text": "as 5x faster and you know essentially",
    "start": "219130",
    "end": "222880"
  },
  {
    "text": "two and a half percent the compute for a",
    "start": "222880",
    "end": "226810"
  },
  {
    "text": "given process job which means it's much",
    "start": "226810",
    "end": "228730"
  },
  {
    "text": "more cost-effective and much quicker",
    "start": "228730",
    "end": "233190"
  }
]
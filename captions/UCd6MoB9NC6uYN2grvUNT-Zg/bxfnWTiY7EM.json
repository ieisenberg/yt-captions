[
  {
    "start": "0",
    "end": "23000"
  },
  {
    "text": "welcome thank you for attending the session first one kicking it off feel honored my name is Bart McBride senior",
    "start": "30",
    "end": "6690"
  },
  {
    "text": "software engineer at a capital games EA I'm here with bill whiner the senior vice president of operations at 47",
    "start": "6690",
    "end": "12300"
  },
  {
    "text": "lining and today we're going to share with you how we gather meaningful players for insights using redshift in",
    "start": "12300",
    "end": "18480"
  },
  {
    "text": "AWS so just to break down what you can",
    "start": "18480",
    "end": "24869"
  },
  {
    "start": "23000",
    "end": "23000"
  },
  {
    "text": "expect from this session today I'm going to start off and talk about how we came to our architecture what it's composed of and then we're gonna jump into the",
    "start": "24869",
    "end": "31949"
  },
  {
    "text": "challenges the meat of the the conversation and Bill's going to jump into all the effective patterns that",
    "start": "31949",
    "end": "37469"
  },
  {
    "text": "we've learned for ingesting duplication aggregation really all the main components of having a data ingest",
    "start": "37469",
    "end": "43020"
  },
  {
    "text": "system balancing performance rapid ingest time it just best practices for",
    "start": "43020",
    "end": "48420"
  },
  {
    "text": "schema optimization and format data summaries and importantly how we build redshift solution to ingest 1 billion",
    "start": "48420",
    "end": "55199"
  },
  {
    "text": "records per day pretty exciting stuff long time ago and galaxy far far away",
    "start": "55199",
    "end": "61910"
  },
  {
    "text": "not that far away but in Sacramento California at our studio Capitol games EA we were given the opportunity to",
    "start": "61910",
    "end": "68880"
  },
  {
    "text": "build a Star Wars title on mobile so we were all huge fans and we want to do you",
    "start": "68880",
    "end": "73920"
  },
  {
    "text": "know something that we'd want to play it was a very exciting experience so not only did we want to create a great game",
    "start": "73920",
    "end": "79350"
  },
  {
    "text": "we wanted all of our systems to support that so we looked at our data analytics system at the time and said are we going",
    "start": "79350",
    "end": "84810"
  },
  {
    "text": "to be able to provide the support for our players to really create a great game",
    "start": "84810",
    "end": "90710"
  },
  {
    "text": "so let me give you an idea of what life was before redshift about two years ago it was really just built on external",
    "start": "90710",
    "end": "97439"
  },
  {
    "start": "91000",
    "end": "91000"
  },
  {
    "text": "solution that really had of one size fits all for processing games so we had all the standard key performance",
    "start": "97439",
    "end": "103560"
  },
  {
    "text": "indicators like monetization and retention and you could compare all the games console mobile across the board",
    "start": "103560",
    "end": "109649"
  },
  {
    "text": "but what we lacked was really in-depth understanding of our players abilities to do things like guild and raids things",
    "start": "109649",
    "end": "115950"
  },
  {
    "text": "that were unique to the games that we were building and probably one of the other things I",
    "start": "115950",
    "end": "121320"
  },
  {
    "text": "was really a downfall as it was client driven typically we shift clients or ship clients once every 12 weeks or so",
    "start": "121320",
    "end": "126750"
  },
  {
    "text": "to the market because of all the certification internal and also within Apple and Google so everything was client driven and",
    "start": "126750",
    "end": "132870"
  },
  {
    "text": "that's how long it would take to get in a new hook to the game client so that just wasn't sufficient most of time we've never put the hooks in because by",
    "start": "132870",
    "end": "139110"
  },
  {
    "text": "the time that question you know was immediate it wasn't a media anymore",
    "start": "139110",
    "end": "145130"
  },
  {
    "start": "145000",
    "end": "145000"
  },
  {
    "text": "so here's the vision really what we were looking at to build to support Star Wars",
    "start": "145130",
    "end": "151080"
  },
  {
    "text": "Galaxies of heroes so we want to discover how players were really playing our game to drive better future",
    "start": "151080",
    "end": "156870"
  },
  {
    "text": "development with healthier operations we wanted rapid iteration like I mentioned",
    "start": "156870",
    "end": "162390"
  },
  {
    "text": "we wanted to be able if we had a question put a hook into the system within a day and be able to answer those questions",
    "start": "162390",
    "end": "167810"
  },
  {
    "text": "that's needed to be decoupled from the game server we wanted to ensure that no matter what happened with redshift or",
    "start": "167810",
    "end": "173280"
  },
  {
    "text": "the reporting our players were not impacted it had to have frictionless access to",
    "start": "173280",
    "end": "178710"
  },
  {
    "text": "data we wanted to make sure all our data analysts were able to just jump in without any friction and that it was easily queryable",
    "start": "178710",
    "end": "185090"
  },
  {
    "text": "using something simple like sequel that everyone's familiar with and then wall displays we wanted the whole team to",
    "start": "185090",
    "end": "191670"
  },
  {
    "text": "know exactly where we're at financially that the player features when a new client feature goes out did that raise",
    "start": "191670",
    "end": "198270"
  },
  {
    "text": "the you know the tides or you know that we needed to do more work on them",
    "start": "198270",
    "end": "203959"
  },
  {
    "text": "so now that we've gone over the vision let's talk about the architecture and what was built",
    "start": "204230",
    "end": "210410"
  },
  {
    "text": "so the first part of the architecture is really moving the data from the game clients all the way to the s3 buckets",
    "start": "210410",
    "end": "216000"
  },
  {
    "start": "211000",
    "end": "211000"
  },
  {
    "text": "we're gonna divide into two parts and the next is going to get it from s3 to redshift so the major components of that",
    "start": "216000",
    "end": "221340"
  },
  {
    "text": "are the game clients the game servers Kinesis to push them events through our",
    "start": "221340",
    "end": "227700"
  },
  {
    "text": "s3 workers to pull the advance and push those into the s3 bucket so let's dig into each one of those components into",
    "start": "227700",
    "end": "233610"
  },
  {
    "text": "more detail so the game client its mobile client I",
    "start": "233610",
    "end": "240120"
  },
  {
    "start": "236000",
    "end": "236000"
  },
  {
    "text": "oh s and Android it produces client specific events so when a player goes into the game and say they go from the",
    "start": "240120",
    "end": "246510"
  },
  {
    "text": "main screen into the guild screen we're gonna have a telemetry event for that but we're not going to sit at every single time that happens it'd be very",
    "start": "246510",
    "end": "252330"
  },
  {
    "text": "verbose and chatty so we end up backing up all its events we also persist those events until the server acknowledges",
    "start": "252330",
    "end": "258450"
  },
  {
    "text": "that they got that batch of data the events are information is very important to us so we don't want to lose any so",
    "start": "258450",
    "end": "264870"
  },
  {
    "text": "for an example if the client crashes events will be sent on next session which Bill's gonna dive into what kind",
    "start": "264870",
    "end": "271050"
  },
  {
    "text": "of problems that can cause because the data comes across as anonymous so keep that in mind next step is our game server",
    "start": "271050",
    "end": "278600"
  },
  {
    "start": "277000",
    "end": "277000"
  },
  {
    "text": "it's just a bunch of ec2 instances that we auto-scale behind an elastic load balancer where a Java shop deploy to",
    "start": "278600",
    "end": "286110"
  },
  {
    "text": "Tomcat try to keep it as simple as possible this is where we produce most of our events typically we do server",
    "start": "286110",
    "end": "292950"
  },
  {
    "text": "deployments once a week but if we have a hot question you know we just did released this last Thursday and someone",
    "start": "292950",
    "end": "299520"
  },
  {
    "text": "adds a questions about ships and how they're doing how they're affecting our economy we can jump in within an hour to",
    "start": "299520",
    "end": "305180"
  },
  {
    "text": "have that in production and start to answer those questions so those events are all sent a synchronously to Kinesis",
    "start": "305180",
    "end": "312630"
  },
  {
    "text": "we use an active mq as our broker it's just embedded broker that just runs a",
    "start": "312630",
    "end": "318090"
  },
  {
    "text": "bunch of threads that's doing all of that work that's also persisting everything to disk until Kinesis",
    "start": "318090",
    "end": "323130"
  },
  {
    "text": "actually acknowledges that it's that information like I said the date is very important to us so we'll retry with",
    "start": "323130",
    "end": "330690"
  },
  {
    "text": "exponential back off back off stuff Connexus is down which I'd highly recommend or you know you just can't",
    "start": "330690",
    "end": "336390"
  },
  {
    "text": "reach the host you're having network issues so do the retries fail we'll go to the dead letter Q and",
    "start": "336390",
    "end": "343860"
  },
  {
    "text": "every hour so we'll go through and make sure the dead letter Q is flushed again",
    "start": "343860",
    "end": "349280"
  },
  {
    "start": "349000",
    "end": "349000"
  },
  {
    "text": "so now we got the information on Kinesis we've got a stream that has 10 shards it's partitioned by an event unique",
    "start": "349310",
    "end": "356340"
  },
  {
    "text": "identifier really simple it's 24-hour retention when we first built a system that was",
    "start": "356340",
    "end": "362130"
  },
  {
    "text": "the only choice that you had for Kinesis now I think you can go up to seven days but 24 hours works quite well for us",
    "start": "362130",
    "end": "368240"
  },
  {
    "text": "this provides fault tolerance to the game server like I mentioned in the vision we needed to make sure that when",
    "start": "368240",
    "end": "374130"
  },
  {
    "text": "we do run if we do run a redshift problems and it's Thanksgiving and everyone's you know at home plane that",
    "start": "374130",
    "end": "379440"
  },
  {
    "text": "they don't have to worry about that end of it we can work on that problem separately the game server also batches",
    "start": "379440",
    "end": "384930"
  },
  {
    "text": "all the information into one Kinesis record on every client request and these records are compressed when we send them",
    "start": "384930",
    "end": "391290"
  },
  {
    "text": "across and then finally we've got our s3",
    "start": "391290",
    "end": "397540"
  },
  {
    "start": "395000",
    "end": "395000"
  },
  {
    "text": "Kinesis burger you're chewing on this stream of information that's coming through we deploy to elastic Beanstalk I",
    "start": "397540",
    "end": "403840"
  },
  {
    "text": "believe there's 10 one worker for every shard the first step it has is it decompresses the record the DEP is",
    "start": "403840",
    "end": "411550"
  },
  {
    "text": "transforming the hierarchical JSON structure into a flat structure that easily Maps over to a redshift row and",
    "start": "411550",
    "end": "417790"
  },
  {
    "text": "then we'll do things like patching missing data I mentioned earlier we have some anonymous data we've found certain",
    "start": "417790",
    "end": "423400"
  },
  {
    "text": "tricks that we can plug you know player IDs and to where non-standard attributes",
    "start": "423400",
    "end": "428800"
  },
  {
    "text": "and so we'll patch the data up will also transform some of the data from like a 0 & 1 to a true or false",
    "start": "428800",
    "end": "434580"
  },
  {
    "text": "in addition we filter out unrepairable data sometimes we'll get you know a client timestamp that shows from like",
    "start": "434580",
    "end": "441180"
  },
  {
    "text": "2100 that's never that hasn't happened yet so we'll go through and put them to a separate s3 bucket and then we'll also",
    "start": "441180",
    "end": "448000"
  },
  {
    "text": "have operational metrics using data dogs so we can keep track of how many times that's happening and if we see a high",
    "start": "448000",
    "end": "453490"
  },
  {
    "text": "rate we can investigate it and then we write to s3 flush of s3 when",
    "start": "453490",
    "end": "459220"
  },
  {
    "text": "the thresholds are met so we're looking at number of records size of the buffer or just amount of time so typically we",
    "start": "459220",
    "end": "466390"
  },
  {
    "text": "flush at every 10,000 records and that ends up being about 7.3 Meg's of data",
    "start": "466390",
    "end": "472319"
  },
  {
    "text": "and then finally we're talking about s3 we organized our files by our starting",
    "start": "472920",
    "end": "479140"
  },
  {
    "text": "with a year first and then finally the file name uses the connexxus sequence start and end date to uniquely identify",
    "start": "479140",
    "end": "484870"
  },
  {
    "text": "it this is also compressed and we think of this data as a long term truth we",
    "start": "484870",
    "end": "489990"
  },
  {
    "text": "never go back in and try to change the data of what's happened in the past anything dealing with the next step is",
    "start": "489990",
    "end": "495820"
  },
  {
    "text": "massaging it to what we need for analysts and just to point out it's very",
    "start": "495820",
    "end": "500980"
  },
  {
    "text": "cheap it's such a minor point of our minor part of our budget it's pretty amazing how much data s3 can hold and",
    "start": "500980",
    "end": "507490"
  },
  {
    "text": "how cheap it is so now that we have all the information to s3 we need to be able to query it in",
    "start": "507490",
    "end": "513849"
  },
  {
    "start": "510000",
    "end": "510000"
  },
  {
    "text": "a really easy way as I mentioned before in our vision so now let's talk about getting from s3 to redshift this is",
    "start": "513849",
    "end": "521140"
  },
  {
    "text": "really the high overview graph we use a lot of data pipeline jobs to do a lot of",
    "start": "521140",
    "end": "526360"
  },
  {
    "text": "the orchestration we're using Beanstalk for jobs for duper and analyzing and",
    "start": "526360",
    "end": "532120"
  },
  {
    "text": "then we also have data pipelines for vacuuming and doing some ETL so we're",
    "start": "532120",
    "end": "537430"
  },
  {
    "text": "gonna jump into each one of those components to understand exactly what each one's responsible for",
    "start": "537430",
    "end": "543420"
  },
  {
    "start": "544000",
    "end": "544000"
  },
  {
    "text": "so the ingest data pipeline this is the very first step of going from the s3",
    "start": "544380",
    "end": "549670"
  },
  {
    "text": "files to get them into a table every hour we have a data pipeline job that goes through and just pulls the data",
    "start": "549670",
    "end": "556060"
  },
  {
    "text": "from s3 using that hourly format and does a full copy of those",
    "start": "556060",
    "end": "562030"
  },
  {
    "text": "into can ease into so that's really very fast the copies a",
    "start": "562030",
    "end": "568390"
  },
  {
    "text": "red shift commands it in there it's really simple make sure you monitor for failures in here there's been times where we've not",
    "start": "568390",
    "end": "575410"
  },
  {
    "text": "been able to get a connection to red shift and it's not until sometime later that we find out what that we're missing hours worth of data which is pretty easy",
    "start": "575410",
    "end": "581740"
  },
  {
    "text": "to do when you have a billion records for that day and then something else just to mention on the side here is to",
    "start": "581740",
    "end": "586960"
  },
  {
    "text": "consider manifest driven ingest we went with the hourly one for simplicity but that really just means we can only",
    "start": "586960",
    "end": "593620"
  },
  {
    "text": "ingest data at the at the fastest every hour doing more of a manifest driven ingest we could go even faster so we're",
    "start": "593620",
    "end": "601270"
  },
  {
    "text": "looking at doing that and to give you an overview I've talked about some of the tables I just wanted",
    "start": "601270",
    "end": "606970"
  },
  {
    "start": "603000",
    "end": "603000"
  },
  {
    "text": "to show a diagram of how the data is moving through so we'll mention these tables a couple times",
    "start": "606970",
    "end": "612070"
  },
  {
    "text": "the very first table is our ingest table like I mentioned that's where s3's you know copying all the data into the next",
    "start": "612070",
    "end": "618100"
  },
  {
    "text": "step is going through and D duping itself into the D dupe table in a second I'll mention why we need a D to placate",
    "start": "618100",
    "end": "624100"
  },
  {
    "text": "but that's a very important step there and finally we put into our main fact table our events table it's a rather",
    "start": "624100",
    "end": "630640"
  },
  {
    "text": "large table that I'll also share the the structure of that and then finally we have our ETL that pushes the data into",
    "start": "630640",
    "end": "637420"
  },
  {
    "text": "our aggregates all right so the D duper so Y",
    "start": "637420",
    "end": "643630"
  },
  {
    "text": "deduplicate the easiest way to explain is that a redshift doesn't provide constraints you can actually create the",
    "start": "643630",
    "end": "649810"
  },
  {
    "text": "tables in and specify them and they'll be used by the query optimizer but they don't enforce it so you have to enforce",
    "start": "649810",
    "end": "655780"
  },
  {
    "text": "it yourself by providing this deduplication and then the reason why we'd have to placate events is in many in our systems with them being",
    "start": "655780",
    "end": "662560"
  },
  {
    "text": "distributed many times we're gonna go through and retry an action if we're in doubt of another system gets it I am the server",
    "start": "662560",
    "end": "670250"
  },
  {
    "text": "and it's unsure it doesn't get an acknowledgement from it it's gonna retry so many times will get duplicated from",
    "start": "670250",
    "end": "676550"
  },
  {
    "text": "that not to mention like I mentioned the second ago data pipeline jobs can fail so you want to be able to rerun these",
    "start": "676550",
    "end": "683360"
  },
  {
    "text": "ingest without concerned with having duplicate data or bad data",
    "start": "683360",
    "end": "689589"
  },
  {
    "text": "so our implementation is pretty simple you could go through and just say the whole column is what you uniquely",
    "start": "689680",
    "end": "695540"
  },
  {
    "start": "690000",
    "end": "690000"
  },
  {
    "text": "identify that row but it wouldn't be very performant when we go through and do the deduplication so you really want",
    "start": "695540",
    "end": "701300"
  },
  {
    "text": "to pick you know four or five columns depending on what your data looks like that uniquely identifies it for a row",
    "start": "701300",
    "end": "709720"
  },
  {
    "text": "so our implementation it's a Bienstock web app it's just an individual one it pulls this table the events D dupes and",
    "start": "709720",
    "end": "716570"
  },
  {
    "text": "as soon as it finds data it'll start processing it you can see here the columns that we have on it we've got the",
    "start": "716570",
    "end": "723080"
  },
  {
    "text": "raw VIN timestamp the player identifier the session ID and the session IDs generated every single time a player",
    "start": "723080",
    "end": "729410"
  },
  {
    "text": "logs in so it's unique to that player session and then we have a step which is a sequence number that's incremented for",
    "start": "729410",
    "end": "735380"
  },
  {
    "text": "every single telemetry event that we fire off and then we have the event type which is basically for every type of",
    "start": "735380",
    "end": "742520"
  },
  {
    "text": "event within the system like a battle summary event or a battle summary events a good example",
    "start": "742520",
    "end": "749530"
  },
  {
    "start": "749000",
    "end": "749000"
  },
  {
    "text": "and then I showed you the events table in the previous diagram here's the basic schema for it I'm highlighting the sort",
    "start": "749530",
    "end": "756440"
  },
  {
    "text": "key in the distribution key I'm not going to get into the details of why we chose those but I'll just cuz Bill's",
    "start": "756440",
    "end": "762200"
  },
  {
    "text": "going to get into the details of that in a second here but this distribution key is as a player ID the sort key is using",
    "start": "762200",
    "end": "769280"
  },
  {
    "text": "a series of dates and the player ID and then we also have the event type as I mentioned before like the battle summer",
    "start": "769280",
    "end": "775339"
  },
  {
    "text": "event your standard field for every event such as country a device Network and platform and then the event values",
    "start": "775339",
    "end": "782060"
  },
  {
    "text": "for every event type you can specify that event can choose what kind of data they want to have in there so for battle",
    "start": "782060",
    "end": "787790"
  },
  {
    "text": "summary event event value Wan could be the number of hits within a battle for Star Wars",
    "start": "787790",
    "end": "793630"
  },
  {
    "start": "795000",
    "end": "795000"
  },
  {
    "text": "and now we're on to the mate really making sure it stays performant so we",
    "start": "795040",
    "end": "803120"
  },
  {
    "text": "vacuum and the reason why you'd want a vacuum is that you want to reclaim any unused space that could happen from",
    "start": "803120",
    "end": "809300"
  },
  {
    "text": "updates from deletes and also from inserts and really we only enter we never delete",
    "start": "809300",
    "end": "815620"
  },
  {
    "text": "so this is very important for the next step for analyze so that you can have performant statistics for the query",
    "start": "815620",
    "end": "822350"
  },
  {
    "text": "optimizer we ended up going through and back once a day which balances the time",
    "start": "822350",
    "end": "827600"
  },
  {
    "text": "to vacuum with the quality of the queries the next step we have is analyze which",
    "start": "827600",
    "end": "835730"
  },
  {
    "start": "832000",
    "end": "832000"
  },
  {
    "text": "is also a very important step in this is really needed for the same sort of reason anytime someone's adding or",
    "start": "835730",
    "end": "841010"
  },
  {
    "text": "modifying removing a lot of rows around having the unsorted area that bill is going to get into much more detail in a",
    "start": "841010",
    "end": "846590"
  },
  {
    "text": "second so this occurs every time the table is vacuumed and we also analyze",
    "start": "846590",
    "end": "851600"
  },
  {
    "text": "every for successful d2 per process it's very resource intensive so similar to",
    "start": "851600",
    "end": "857090"
  },
  {
    "text": "the vacuuming you have to make sure you balance the time to do that and also your performance of queries",
    "start": "857090",
    "end": "863110"
  },
  {
    "text": "we get to our ETLs the example I'm going to give here is you predict Lee that's",
    "start": "864190",
    "end": "870110"
  },
  {
    "text": "something very important to track within a game system how long the players stayed in the game so this is a data",
    "start": "870110",
    "end": "876770"
  },
  {
    "text": "pipeline job that triggers many different ETLs many of them have sequence of dependencies for the user",
    "start": "876770",
    "end": "882500"
  },
  {
    "text": "retention one it depends on our user job that keeps a an aggregate of all of our user data its job basically goes through an",
    "start": "882500",
    "end": "889760"
  },
  {
    "text": "upsurge table data into the table looking back a week in case we're missing any of the data that you know",
    "start": "889760",
    "end": "895850"
  },
  {
    "text": "didn't come in do them maybe a game server being down for a day or so an individual one not the whole game to be",
    "start": "895850",
    "end": "901370"
  },
  {
    "text": "clear and so basically the you can also see this orc he's slightly different here",
    "start": "901370",
    "end": "906380"
  },
  {
    "text": "and it's really based on what your query workload looks like so for this one we've got our playwright platform",
    "start": "906380",
    "end": "912770"
  },
  {
    "text": "country and stat 8 and then we also have other data that writes long such as days in the game and revenue",
    "start": "912770",
    "end": "920829"
  },
  {
    "text": "so this was all really really exciting on the left side of this graph too you can see where we soft-launched to",
    "start": "922270",
    "end": "928760"
  },
  {
    "start": "923000",
    "end": "923000"
  },
  {
    "text": "soft-launched in different countries that looks similar to your larger like",
    "start": "928760",
    "end": "933860"
  },
  {
    "text": "north america so you can see if all your KPI is your key performance indicators are meeting you know what you're",
    "start": "933860",
    "end": "939560"
  },
  {
    "text": "expecting so everything went well worldwide launch was november 24th a little more than a year ago we just",
    "start": "939560",
    "end": "945800"
  },
  {
    "text": "celebrated our first anniversary which was exciting but that was a fun week it was over Thanksgiving and to watch a",
    "start": "945800",
    "end": "951350"
  },
  {
    "text": "system like s or having turkey scale up to a billion events and it was just screaming everyone was happy with the",
    "start": "951350",
    "end": "957320"
  },
  {
    "text": "analysis and then what was even cooler about this is typically with games mobile or console you'll have a launch",
    "start": "957320",
    "end": "964640"
  },
  {
    "text": "and then you have this long tail people go on to another game but with the help of you know the Star Wars brand and",
    "start": "964640",
    "end": "970820"
  },
  {
    "text": "people being excited about the force awakens you can see here number of events went up which you can see almost",
    "start": "970820",
    "end": "976190"
  },
  {
    "text": "every other KPI for us went up also so a lot of high-fiving at the office and we",
    "start": "976190",
    "end": "981410"
  },
  {
    "text": "were all very very excited we loved playing the games ourself so in every respect of you know we were succeeding",
    "start": "981410",
    "end": "987560"
  },
  {
    "text": "but there were some challenges and at that time we contacted Amazon and they posed in contact with 47 lining and bill",
    "start": "987560",
    "end": "994970"
  },
  {
    "text": "whiner and he came in and helped us out with some of those challenges and we're in a much better place today so I'll",
    "start": "994970",
    "end": "1001990"
  },
  {
    "text": "hand it over to Bill now thank you Mark okay",
    "start": "1001990",
    "end": "1009089"
  },
  {
    "text": "so as you saw in the previous slide there was a tremendous step function in events coming into the solution and if",
    "start": "1010020",
    "end": "1016480"
  },
  {
    "text": "people have made this type of solution before you'll know how that probably went behind the scenes as Mark pointed",
    "start": "1016480",
    "end": "1022690"
  },
  {
    "text": "out the the solution didn't have a tight coupling to the gameplay but there was definitely some challenges that occurred",
    "start": "1022690",
    "end": "1029339"
  },
  {
    "text": "I'm gonna go over five challenges that we experienced during that post launch",
    "start": "1029339",
    "end": "1034930"
  },
  {
    "text": "window of time I hope to show you the solutions we use for those problems as well as",
    "start": "1034930",
    "end": "1040949"
  },
  {
    "text": "show how these could be relevant are helpful to you let me start by reviewing redshift",
    "start": "1040949",
    "end": "1049500"
  },
  {
    "start": "1045000",
    "end": "1045000"
  },
  {
    "text": "architecture just to get a baseline here so the leader node as most in the room",
    "start": "1049500",
    "end": "1055390"
  },
  {
    "text": "will know is the SQL endpoint for redshift in the into the cluster for",
    "start": "1055390",
    "end": "1061150"
  },
  {
    "text": "this conversation though it's probably most important to understand that the leader node holds the metadata for the",
    "start": "1061150",
    "end": "1066940"
  },
  {
    "text": "tables as well as performs query planning so it plays an important role when dealing with large tables like this",
    "start": "1066940",
    "end": "1073170"
  },
  {
    "text": "it is a clustered approach there for data locality and network transmissions",
    "start": "1073170",
    "end": "1078880"
  },
  {
    "text": "are critical performance attributes that need to be understood and optimized",
    "start": "1078880",
    "end": "1085260"
  },
  {
    "text": "ingestion from s3 as Mark said s3 was definitely the route ea went and that's usually the best route to go of all the",
    "start": "1085260",
    "end": "1092170"
  },
  {
    "text": "options for ingestion and a redshift when you have this size of data it's very very large",
    "start": "1092170",
    "end": "1099030"
  },
  {
    "text": "there are two node families in redshift the ds2 which is storage optimized and",
    "start": "1099030",
    "end": "1104800"
  },
  {
    "text": "the DC one which is compute optimized there was an early choice given their understanding of how much data was gonna",
    "start": "1104800",
    "end": "1111070"
  },
  {
    "text": "be coming into the redshift to go with the ds2 but as it came online they quickly realized just how much compute",
    "start": "1111070",
    "end": "1117070"
  },
  {
    "text": "load there is to ingest that many events and to aggregate the results of that many events on an ongoing basis and",
    "start": "1117070",
    "end": "1123310"
  },
  {
    "text": "ended up very quickly at the DC one family in fact they used a DC one 8xl",
    "start": "1123310",
    "end": "1129340"
  },
  {
    "text": "which has 32 slices per node and that'll be an important statistic coming up here in just a moment so",
    "start": "1129340",
    "end": "1136559"
  },
  {
    "start": "1136000",
    "end": "1136000"
  },
  {
    "text": "as Mark showed to the graph the number events coming in took a step function but other parts of the solution did not",
    "start": "1137430",
    "end": "1144670"
  },
  {
    "text": "react quite as well in the blue is the vacuum time at this point in time it was",
    "start": "1144670",
    "end": "1150040"
  },
  {
    "text": "an hourly run after each ingestion yes 650 minutes is nearly 11 hours at most",
    "start": "1150040",
    "end": "1157150"
  },
  {
    "text": "can understand that didn't work very well a temporary stopgap solution was",
    "start": "1157150",
    "end": "1162250"
  },
  {
    "text": "done at this point to move it to a nightly process in order to be able to run this long in order to produce a",
    "start": "1162250",
    "end": "1169330"
  },
  {
    "text": "vacuum table that was again stopgap simply because you can see from the slope of that blue",
    "start": "1169330",
    "end": "1175390"
  },
  {
    "text": "line it was going to quickly get over one day to vacuum this table to the right of that shortly thereafter",
    "start": "1175390",
    "end": "1181960"
  },
  {
    "text": "the D duplicator started running very very long times it was not successfully",
    "start": "1181960",
    "end": "1187330"
  },
  {
    "text": "completing the analysis to D duplicating the incoming hourly stream we also",
    "start": "1187330",
    "end": "1192610"
  },
  {
    "text": "needed to address this issue quickly in or to keep the data flowing and as you",
    "start": "1192610",
    "end": "1199090"
  },
  {
    "text": "can see by the graphs we got both of these nailed I'll show you how in just a second",
    "start": "1199090",
    "end": "1204780"
  },
  {
    "start": "1204000",
    "end": "1204000"
  },
  {
    "text": "let me understand let me start by helping you understand the goals of sorting and played a huge role into what",
    "start": "1204780",
    "end": "1211990"
  },
  {
    "text": "these problems were all about so sorting is a physical process that actually takes the",
    "start": "1211990",
    "end": "1218770"
  },
  {
    "text": "data based on your sort keys and it'll put the data in rows in that order it's",
    "start": "1218770",
    "end": "1224320"
  },
  {
    "text": "very literal the vacuum process if they aren't initially in that order will be what puts it into that sort order",
    "start": "1224320",
    "end": "1231090"
  },
  {
    "text": "one of the key attributes you're looking to achieve is reduce row scan the our",
    "start": "1231090",
    "end": "1236500"
  },
  {
    "text": "scan as you see up there as well as what we like to call block rejection which is",
    "start": "1236500",
    "end": "1241990"
  },
  {
    "text": "a very similar term and I'll get into that in just a second this is the ability for red shift to prune the",
    "start": "1241990",
    "end": "1247480"
  },
  {
    "text": "number of table blocks that need to be read in order to perform any query if",
    "start": "1247480",
    "end": "1252550"
  },
  {
    "text": "you can optimize against this you can achieved very high performance against very large tables",
    "start": "1252550",
    "end": "1259140"
  },
  {
    "text": "so the sort keys are",
    "start": "1259200",
    "end": "1263610"
  },
  {
    "text": "critical for the vacuum process as I was just explaining they set the end state",
    "start": "1264510",
    "end": "1269980"
  },
  {
    "text": "for a sorted or vacuum table if that is very different than the previous state",
    "start": "1269980",
    "end": "1275500"
  },
  {
    "text": "of the table a long time could occur resulting in graphs like we just saw",
    "start": "1275500",
    "end": "1281880"
  },
  {
    "start": "1281000",
    "end": "1281000"
  },
  {
    "text": "so in choosing a sort key is really important to think about your common",
    "start": "1281910",
    "end": "1287320"
  },
  {
    "text": "query predicate these predicates are what's going to be used to do that block rejection and the",
    "start": "1287320",
    "end": "1293830"
  },
  {
    "text": "block rejections can compare the metadata and the metadata extents are going to be changed changed by the sort",
    "start": "1293830",
    "end": "1299710"
  },
  {
    "text": "keys so lining all these factors up is really important I'll go into this in much more detail in a moment however",
    "start": "1299710",
    "end": "1306580"
  },
  {
    "text": "there is another important attribute that needs to be maintained especially for what's called a time series data",
    "start": "1306580",
    "end": "1312340"
  },
  {
    "text": "table a table that has data added to it over time and that is to make sure that",
    "start": "1312340",
    "end": "1317860"
  },
  {
    "text": "new data which is going to be inserted at the end of your table after vacuumed",
    "start": "1317860",
    "end": "1322870"
  },
  {
    "text": "this remains at the end of your tables and not spread out causing a lot of reordering a very large table",
    "start": "1322870",
    "end": "1330510"
  },
  {
    "text": "further redshift supports to sort key types or methods first is compound",
    "start": "1330510",
    "end": "1336490"
  },
  {
    "text": "fairly straightforward you give it a list of columns to sort the data by it will first sort by the first column",
    "start": "1336490",
    "end": "1342640"
  },
  {
    "text": "column one and then anytime column one is equivalent between two rows it will use column two and if those are",
    "start": "1342640",
    "end": "1349210"
  },
  {
    "text": "equivalent will use column three it's a very hierarchical in order sorting methodology the other method is the",
    "start": "1349210",
    "end": "1355660"
  },
  {
    "text": "interleaved mode that gives a more blended or balanced approach to what data is going to be sorted elsewhere and",
    "start": "1355660",
    "end": "1362050"
  },
  {
    "text": "it can be extremely effective on very large table how tables however it is not",
    "start": "1362050",
    "end": "1367900"
  },
  {
    "text": "really an appropriate choice for time series data that is changing rapidly it's an appropriate choice for very",
    "start": "1367900",
    "end": "1374050"
  },
  {
    "text": "static large data sets so it is not one to be used in this solution",
    "start": "1374050",
    "end": "1380250"
  },
  {
    "start": "1380000",
    "end": "1380000"
  },
  {
    "text": "so looking at some of the documented best practices for time series data it",
    "start": "1380250",
    "end": "1386350"
  },
  {
    "text": "is important to understand about the primary or first listed sort",
    "start": "1386350",
    "end": "1391630"
  },
  {
    "text": "key that's the one we're going to focus in on at this point it wants to be monotonically increasing with the data",
    "start": "1391630",
    "end": "1399100"
  },
  {
    "text": "as it comes into the solution and that's to keep the data at the end of the table post vacuum",
    "start": "1399100",
    "end": "1405060"
  },
  {
    "text": "if you'll think about it you are adding layers or strata to your fact table with",
    "start": "1405060",
    "end": "1410890"
  },
  {
    "text": "each incremental addition or insert into your table you want to preserve these strata as you go through the vacuum or",
    "start": "1410890",
    "end": "1417730"
  },
  {
    "text": "sorting process if this is not done there will be a massive reordering of the table that has to be performed it's",
    "start": "1417730",
    "end": "1423610"
  },
  {
    "text": "going to move a lot of data and moving a lot of data will result in a lot of time",
    "start": "1423610",
    "end": "1429690"
  },
  {
    "text": "burn me so Electronic Arts as Mark was",
    "start": "1429690",
    "end": "1435850"
  },
  {
    "text": "presenting did try to set things up exactly for all",
    "start": "1435850",
    "end": "1441190"
  },
  {
    "text": "these best practices they chose a very appropriate time as far as they",
    "start": "1441190",
    "end": "1446620"
  },
  {
    "text": "understood for the primary sort key vacuums unfortunately did grow very long",
    "start": "1446620",
    "end": "1452230"
  },
  {
    "text": "so what happened so the data arrives on the ingest table",
    "start": "1452230",
    "end": "1461059"
  },
  {
    "start": "1454000",
    "end": "1454000"
  },
  {
    "text": "and wants to be inserted towards the end of the main fact table it actually will be inserted at the end that's the only",
    "start": "1461059",
    "end": "1467120"
  },
  {
    "text": "place redshift can insert data they had used a timestamp of the",
    "start": "1467120",
    "end": "1472700"
  },
  {
    "text": "gameplay event for the primary sort key so as people play an event is created",
    "start": "1472700",
    "end": "1479630"
  },
  {
    "text": "goes through the solution ends up at the end of the table all should be good however they used a timestamp that was",
    "start": "1479630",
    "end": "1487010"
  },
  {
    "text": "driven off of the client systems clock and",
    "start": "1487010",
    "end": "1492820"
  },
  {
    "text": "this client system clock in some extremely rare cases and I mean parts",
    "start": "1492820",
    "end": "1499130"
  },
  {
    "text": "per million level were very wrong I'm not talking hours I'm talking",
    "start": "1499130",
    "end": "1505610"
  },
  {
    "text": "decades wrong these massively out of place events were",
    "start": "1505610",
    "end": "1511789"
  },
  {
    "text": "creating a situation that when vacuum came along a few rows had to migrate from the bottom of the table up to the",
    "start": "1511789",
    "end": "1518299"
  },
  {
    "text": "middle or the beginning redshift needed to open space for them and shift many",
    "start": "1518299",
    "end": "1523610"
  },
  {
    "text": "many millions billions of rows this took a long time as you saw in that chart",
    "start": "1523610",
    "end": "1528620"
  },
  {
    "text": "took 11 hours our most our best understanding for what",
    "start": "1528620",
    "end": "1534500"
  },
  {
    "text": "was going on here is that game players they just like to play games and they",
    "start": "1534500",
    "end": "1539929"
  },
  {
    "text": "thought they could get an edge by changing their system clocks but unfortunately was causing us a significant problem with vacuum",
    "start": "1539929",
    "end": "1546429"
  },
  {
    "text": "so we needed to address these out of position events how did we do this we",
    "start": "1546429",
    "end": "1552139"
  },
  {
    "start": "1550000",
    "end": "1550000"
  },
  {
    "text": "change the primary sort key of the table we change it to one that was",
    "start": "1552139",
    "end": "1557480"
  },
  {
    "text": "corresponding to the Kinesis worker timestamp this was already coming through in the data stream we already knew when it was coming through Kinesis",
    "start": "1557480",
    "end": "1564110"
  },
  {
    "text": "this clock was now under the solutions control these games were eliminated",
    "start": "1564110",
    "end": "1569950"
  },
  {
    "text": "it is really important that when you're dealing with very large time series data",
    "start": "1569950",
    "end": "1575000"
  },
  {
    "text": "that the data stays at the end because you got a massive load of data and you don't want to be removing at all",
    "start": "1575000",
    "end": "1582610"
  },
  {
    "text": "this also shows how important it is to exactly know what's in your data",
    "start": "1582610",
    "end": "1589250"
  },
  {
    "text": "while we're talking a minut number of events were causing a massive vacuuming problem",
    "start": "1589250",
    "end": "1596440"
  },
  {
    "start": "1596000",
    "end": "1596000"
  },
  {
    "text": "so the compound sort key was a fairly simple change to allow us to",
    "start": "1596560",
    "end": "1602410"
  },
  {
    "text": "address the vacuum issue the D duper was a very different problem",
    "start": "1602410",
    "end": "1608960"
  },
  {
    "text": "as and understand exactly what's going on it's best to review sort of best",
    "start": "1608960",
    "end": "1615710"
  },
  {
    "text": "practices around a compound sort key so this is that order list and as this is",
    "start": "1615710",
    "end": "1620900"
  },
  {
    "text": "taking directly from the Amazon documentation you can see it attempts to show that the benefits of secondary non",
    "start": "1620900",
    "end": "1629180"
  },
  {
    "text": "primary sort keys it actually says decrease when quarries depend only on these columns as you saw on Mark's slide",
    "start": "1629180",
    "end": "1636860"
  },
  {
    "text": "the D duplicator needed to look at things as a vent type and step and some of these other columns had",
    "start": "1636860",
    "end": "1643550"
  },
  {
    "text": "nothing to do with when the event came through the Kinesis worker is actually two events coming into the solution that",
    "start": "1643550",
    "end": "1650060"
  },
  {
    "text": "were duplicates were very likely have different Kinesis worker timestamps so it was not appropriate to be looking at",
    "start": "1650060",
    "end": "1656060"
  },
  {
    "text": "it we needed to look at non primary sort Keys primary sort key fixed vacuum now",
    "start": "1656060",
    "end": "1661700"
  },
  {
    "text": "we have a secondary problem it is important also that the secondary sort keys are predicates for your",
    "start": "1661700",
    "end": "1668630"
  },
  {
    "text": "queries that are very common and so in this case we were picking things like event type and step things the D",
    "start": "1668630",
    "end": "1674030"
  },
  {
    "text": "duplicator needed as the secondary sarkis our challenge at this point if the",
    "start": "1674030",
    "end": "1681050"
  },
  {
    "text": "deduplicated will work quicker was to change my insert of May in the last sentence of this slide to a won't",
    "start": "1681050",
    "end": "1689140"
  },
  {
    "text": "compound sorting based on the secondary keys won't decrease performance",
    "start": "1689140",
    "end": "1695320"
  },
  {
    "start": "1695000",
    "end": "1695000"
  },
  {
    "text": "to understand how to do this we need to look a little deeper into zone maps on redshift so zone maps are the one",
    "start": "1695320",
    "end": "1704680"
  },
  {
    "text": "sorry-ass zone or block on redshift is a one megabyte chunk of data per column",
    "start": "1704680",
    "end": "1711500"
  },
  {
    "text": "per table for everything on redshift so these one megabyte blocks of data all",
    "start": "1711500",
    "end": "1717650"
  },
  {
    "text": "have metadata this metadata keeps the min and Max max of the range of that",
    "start": "1717650",
    "end": "1724460"
  },
  {
    "text": "column for that one megabyte this information is known as the zone",
    "start": "1724460",
    "end": "1730220"
  },
  {
    "text": "map for that block of data so when you sort data clearly the rows",
    "start": "1730220",
    "end": "1737450"
  },
  {
    "text": "that get together within that one block are going to change and the maximum extent of the data ranges for that block",
    "start": "1737450",
    "end": "1742970"
  },
  {
    "text": "will be different depending on how you sort the data so we want to think about how can we sort the data to change the",
    "start": "1742970",
    "end": "1749870"
  },
  {
    "text": "metadata the zone map for each of these blocks on these columns that we're very worried about",
    "start": "1749870",
    "end": "1756310"
  },
  {
    "text": "so to think about this attribute of the zone map what we have",
    "start": "1757630",
    "end": "1762950"
  },
  {
    "text": "to do is let's step back to a query that would be running in a quarry that you would run the first thing would happen is the predicate clauses the wares would",
    "start": "1762950",
    "end": "1770180"
  },
  {
    "text": "be compared against metadata for the blocks for those columns this was done",
    "start": "1770180",
    "end": "1775250"
  },
  {
    "text": "by the leader node before any of the massive amount of data is read off the disk for the full extent of the table if",
    "start": "1775250",
    "end": "1780950"
  },
  {
    "text": "it can determine that a block of data is does not need to be read off of disk in",
    "start": "1780950",
    "end": "1786680"
  },
  {
    "text": "order to perform the query it will not read it and this is why at 47 lining we",
    "start": "1786680",
    "end": "1793700"
  },
  {
    "text": "have come to call this block rejection and you want to try and maximize the amount of blocks you can reject on these",
    "start": "1793700",
    "end": "1799970"
  },
  {
    "text": "large tables to minimize the amount of data that needs to be read into the cluster",
    "start": "1799970",
    "end": "1806140"
  },
  {
    "text": "it's also important the data is analyzed analyzed is the command that will update",
    "start": "1806140",
    "end": "1811460"
  },
  {
    "text": "the zone maps if your zone map data is invalid it will not use that information",
    "start": "1811460",
    "end": "1817280"
  },
  {
    "text": "to reject blocks so keeping it regularly analyzed is critically important",
    "start": "1817280",
    "end": "1822730"
  },
  {
    "text": "so how did we get better block rejection using zone maps on these later sort keys",
    "start": "1822730",
    "end": "1829880"
  },
  {
    "text": "for ei I'm gonna have to go to a very super simplified example because there's",
    "start": "1829880",
    "end": "1835730"
  },
  {
    "text": "a lot of moving parts in this but let me attempt to get the the essence across",
    "start": "1835730",
    "end": "1841840"
  },
  {
    "text": "here we go so up here I have a table and",
    "start": "1841840",
    "end": "1847220"
  },
  {
    "start": "1842000",
    "end": "1842000"
  },
  {
    "text": "in this table that has three compound sort keys sort key once or key to sort",
    "start": "1847220",
    "end": "1852860"
  },
  {
    "text": "key three and they're sorted in that order in this table",
    "start": "1852860",
    "end": "1857530"
  },
  {
    "text": "and it literally in that if you look through the data you will see that almost all the work is being done by",
    "start": "1859210",
    "end": "1866000"
  },
  {
    "text": "sort key one this is very similar what was happening at Electronic Arts that Kinesis worker time stamp was doing",
    "start": "1866000",
    "end": "1872480"
  },
  {
    "text": "almost all the work later keys who are not so what's the upshot of this in this super simplified example I've defined a",
    "start": "1872480",
    "end": "1879560"
  },
  {
    "text": "block to no longer be one megabyte of data to be four rows make fits nice on a",
    "start": "1879560",
    "end": "1884570"
  },
  {
    "text": "slide that way so you can see I've on the left of the slide indicated what a block looks like if we're to look at",
    "start": "1884570",
    "end": "1891680"
  },
  {
    "text": "sort key one for block one we can imagine our heads what the zone map",
    "start": "1891680",
    "end": "1897530"
  },
  {
    "text": "might look like for that section of the table it would have a minimum extent of one and a maximum extent of four and",
    "start": "1897530",
    "end": "1904360"
  },
  {
    "text": "going down you would see for block two minimum extent of five maximum of eight very nice they're not overlapping should",
    "start": "1904360",
    "end": "1912500"
  },
  {
    "text": "get good block rejection on that but that's not the ones we were worried about worried about sort key to if we",
    "start": "1912500",
    "end": "1918710"
  },
  {
    "text": "look at block one force or key to we can see we have a minimum extent of four but a maximum or eleven I got a very wide",
    "start": "1918710",
    "end": "1925430"
  },
  {
    "text": "set of metadata for my zone map on this next column",
    "start": "1925430",
    "end": "1932500"
  },
  {
    "text": "what happens is this leads to poor query efficiency when you are just us",
    "start": "1933040",
    "end": "1939340"
  },
  {
    "text": "querying against these other columns you're not using sort key one as your predicate we're using two and three so",
    "start": "1939340",
    "end": "1946490"
  },
  {
    "text": "as an example let's look at a predicate that would be sort key to greater than nine and sort key three less than four",
    "start": "1946490",
    "end": "1955270"
  },
  {
    "text": "simply for my zone map or metadata point of view I can look down here and I can",
    "start": "1955270",
    "end": "1960290"
  },
  {
    "text": "see four sort key to in block one I have a value greater than nine somewhere in the block I got to read that block in",
    "start": "1960290",
    "end": "1966650"
  },
  {
    "text": "from disk and find out if I need to use the rest of it down you go the next block is a fifteen the next block has a",
    "start": "1966650",
    "end": "1972770"
  },
  {
    "text": "ten on sort key three I got a one I got a three I got a two I got a four all",
    "start": "1972770",
    "end": "1978140"
  },
  {
    "text": "these things are matching and creating a situation where I need to read these",
    "start": "1978140",
    "end": "1983210"
  },
  {
    "text": "blocks in more data has to come into the cluster more work has to be done",
    "start": "1983210",
    "end": "1989110"
  },
  {
    "text": "as I mentioned the main issue here is there's too much sorting power in that first sort key I want to smooth it out a",
    "start": "1989159",
    "end": "1997239"
  },
  {
    "start": "1990000",
    "end": "1990000"
  },
  {
    "text": "little bit in order to address this problem let's look at truncating the data for sort keys 1 & 2 so in this",
    "start": "1997239",
    "end": "2005399"
  },
  {
    "text": "simplified example I'm going to take a synthetic column this is an additional column in your data not a replacement of",
    "start": "2005399",
    "end": "2011429"
  },
  {
    "text": "your original sort key so synthetics or key one is the decade of the information",
    "start": "2011429",
    "end": "2016859"
  },
  {
    "text": "on soar key 1 similarly synthetic sort key 2 is the decade of the information",
    "start": "2016859",
    "end": "2021919"
  },
  {
    "text": "for the original sort key 2 in this table I've now sorted by synthetics or",
    "start": "2021919",
    "end": "2027960"
  },
  {
    "text": "key 1 followed by synthetic sort key 2 followed by the original sort key 3",
    "start": "2027960",
    "end": "2034340"
  },
  {
    "text": "what you can see here is all of a sudden I get nice clumping on those later",
    "start": "2034340",
    "end": "2040369"
  },
  {
    "text": "original data points on sort key to in sort key 3 the things I want to write predicates for have started to clump",
    "start": "2040369",
    "end": "2047159"
  },
  {
    "text": "together and give me better information better rejection of what information is in those zones versus my first example",
    "start": "2047159",
    "end": "2054679"
  },
  {
    "text": "it's in this way that we tackled the problem of getting the D duplicator to be faster we needed to truncate the",
    "start": "2054679",
    "end": "2061079"
  },
  {
    "text": "information within the Kinesis worker timestamp so more events had equivalent values for that first sort key",
    "start": "2061079",
    "end": "2070010"
  },
  {
    "text": "however doing this presents a new balance point that needs to be considered so in the picture here let's",
    "start": "2070819",
    "end": "2077940"
  },
  {
    "start": "2071000",
    "end": "2071000"
  },
  {
    "text": "assume I four colored bands on the left is my ingest table where I have brought",
    "start": "2077940",
    "end": "2083158"
  },
  {
    "text": "in four hours worth of information but I am truncating that time stamped to a",
    "start": "2083159",
    "end": "2088378"
  },
  {
    "text": "four hour window so these four hours worth of data will have the equivalent value for this truncated timestamp what",
    "start": "2088379",
    "end": "2097589"
  },
  {
    "text": "that's going to result in is when you vacuumed all those rows have to be interwoven",
    "start": "2097589",
    "end": "2103490"
  },
  {
    "text": "that creates a lot of data movement and a lot of work now as much as we saw on the original problem with those few out",
    "start": "2103490",
    "end": "2110160"
  },
  {
    "text": "of place events but significant work but what this does is it means a lot of",
    "start": "2110160",
    "end": "2115980"
  },
  {
    "text": "events are coming in with exactly the same first sort key value giving more",
    "start": "2115980",
    "end": "2121580"
  },
  {
    "text": "power to those latest sore keys so you're winning on the sort keep our side",
    "start": "2121580",
    "end": "2128150"
  },
  {
    "text": "but vacuum is taking longer and this is the trade-off that needs to be",
    "start": "2128150",
    "end": "2133220"
  },
  {
    "text": "factored in here you have an ingest rate how often I gonna bring data in which is going to term 'information is from my",
    "start": "2133220",
    "end": "2140900"
  },
  {
    "text": "people with their dashboards I got the vacuum time which has to do with how many rows do I have to keep sorting",
    "start": "2140900",
    "end": "2146780"
  },
  {
    "text": "together when I do this as well as the power I'm reserving for those later sort",
    "start": "2146780",
    "end": "2152570"
  },
  {
    "text": "keys and predicates the ones that are being set up to give me information that I need for my actual queries not just",
    "start": "2152570",
    "end": "2159320"
  },
  {
    "text": "keeping the overall table in a roughly sorted way such that the vacuum process",
    "start": "2159320",
    "end": "2164960"
  },
  {
    "text": "doesn't go into the weeds so this balance point is critical and it's",
    "start": "2164960",
    "end": "2170720"
  },
  {
    "text": "a solution independent because it's the other variable coming into this of course is the volume of events coming in",
    "start": "2170720",
    "end": "2176360"
  },
  {
    "text": "at the input side to determine how many of those will fit in a one megabyte block",
    "start": "2176360",
    "end": "2182590"
  },
  {
    "text": "for this game what was decided is to go with a 1-hour ingest with a truncation",
    "start": "2182590",
    "end": "2188540"
  },
  {
    "text": "of one hour that kept vacuum well-behaved those those things match pretty well as I mentioned earlier we",
    "start": "2188540",
    "end": "2195140"
  },
  {
    "text": "use the Kinesis worker time stamp and we were truncating that there were some rough edges there's a little bit hour to",
    "start": "2195140",
    "end": "2201710"
  },
  {
    "text": "hour overlap but that was well within the ability for the solution to vacuum",
    "start": "2201710",
    "end": "2206720"
  },
  {
    "text": "those out and a nightly process and lastly the sorting power came from this",
    "start": "2206720",
    "end": "2213740"
  },
  {
    "text": "level of truncation and the high volume of events coming in meant there was lots of block rejection on these later sort",
    "start": "2213740",
    "end": "2219650"
  },
  {
    "text": "keys these two sort key changes are what was",
    "start": "2219650",
    "end": "2225890"
  },
  {
    "text": "used to address those two very large spikes you saw as the volume increased",
    "start": "2225890",
    "end": "2232690"
  },
  {
    "text": "so what happened next so we get past the two large spikes this",
    "start": "2233710",
    "end": "2238940"
  },
  {
    "text": "is the same chart I showed earlier with an extended time scale out at a time about a month and a half",
    "start": "2238940",
    "end": "2244810"
  },
  {
    "text": "we can see the D duplicator again in purple slowly getting worse as things",
    "start": "2244810",
    "end": "2251690"
  },
  {
    "text": "accumulated there was something creeping in the system was longer a loud issue",
    "start": "2251690",
    "end": "2257270"
  },
  {
    "text": "but a quiet one but still needed to be addressed before this solution was deemed to be fully acceptable",
    "start": "2257270",
    "end": "2264790"
  },
  {
    "text": "these issues were affecting almost every query in the system not just the D duplicator so it was something that",
    "start": "2264790",
    "end": "2271099"
  },
  {
    "text": "needed to be addressed in order to ensure that a whole bunch of work could get done",
    "start": "2271099",
    "end": "2276849"
  },
  {
    "text": "to understand the root cause behind this we need to look at distribution",
    "start": "2276849",
    "end": "2283720"
  },
  {
    "start": "2277000",
    "end": "2277000"
  },
  {
    "text": "the there were many causes for this the biggest was a distribution issue that",
    "start": "2284560",
    "end": "2291140"
  },
  {
    "text": "was subtle looking at distribution you can see there's two main goals you're trying to",
    "start": "2291140",
    "end": "2296570"
  },
  {
    "text": "achieve with distribution the first is to collocate your data within a slice or",
    "start": "2296570",
    "end": "2301670"
  },
  {
    "text": "a node and the reason for that is of course we want to aggregate data or join data it's much faster to get those",
    "start": "2301670",
    "end": "2308240"
  },
  {
    "text": "pieces of data together if they're on the same physical CPU the other one is to",
    "start": "2308240",
    "end": "2316509"
  },
  {
    "text": "distribute the data throughout the cluster in an even way because the",
    "start": "2317170",
    "end": "2323319"
  },
  {
    "text": "distribution of the data determines which CPU or slice within the cluster is",
    "start": "2323319",
    "end": "2328490"
  },
  {
    "text": "actually allocated to do the work on that data so that assignment of initial",
    "start": "2328490",
    "end": "2333560"
  },
  {
    "text": "work is made by your distribution key there are three modes of distribution",
    "start": "2333560",
    "end": "2339980"
  },
  {
    "text": "and redshift shown here distribution by key which is used one of your data columns and its value to determine which",
    "start": "2339980",
    "end": "2346700"
  },
  {
    "text": "slice within the cluster the data belongs to all which is simply to put a",
    "start": "2346700",
    "end": "2352190"
  },
  {
    "text": "copy of all your data for that table on each of the nodes and assign one of the",
    "start": "2352190",
    "end": "2359780"
  },
  {
    "text": "slices to be the owner for performing the work on the data for that slice and the last is even or round-robin it's one",
    "start": "2359780",
    "end": "2367430"
  },
  {
    "text": "that just distributes the data evenly when choosing these you need to look at",
    "start": "2367430",
    "end": "2374480"
  },
  {
    "start": "2371000",
    "end": "2371000"
  },
  {
    "text": "the relative strengths of each of these modes to understand which was the best choice a",
    "start": "2374480",
    "end": "2380619"
  },
  {
    "text": "distribution of all as I said is one that distributes the data on every node it's very useful for",
    "start": "2380619",
    "end": "2388310"
  },
  {
    "text": "dimensional tables especially ones that don't share a common distribution key",
    "start": "2388310",
    "end": "2393380"
  },
  {
    "text": "with your main fact table and prevent large amounts of data network traffic in",
    "start": "2393380",
    "end": "2399050"
  },
  {
    "text": "order to create a join for example the downside of course is your data is replicated so it's going to take up more",
    "start": "2399050",
    "end": "2405020"
  },
  {
    "text": "space on disk so it's only appropriate up to a certain size of table even it is frequently used it's also the",
    "start": "2405020",
    "end": "2413180"
  },
  {
    "text": "default it is very good for making sure your data gets evenly distributed that each slice in your cluster has an",
    "start": "2413180",
    "end": "2420020"
  },
  {
    "text": "equivalent amount of data to work upon the downside with the even distribution of",
    "start": "2420020",
    "end": "2426080"
  },
  {
    "text": "course is it's guaranteeing no locality of different rows so if you aggregate on some field that you have to join there's",
    "start": "2426080",
    "end": "2432200"
  },
  {
    "text": "very likely very high likelihood that data is across the network and a lot of network traffic will be generated by",
    "start": "2432200",
    "end": "2439400"
  },
  {
    "text": "that event key of course is the is the best to use especially as was done with",
    "start": "2439400",
    "end": "2444440"
  },
  {
    "text": "Electronic Arts they were to set the key to be the player ID a vast majority of",
    "start": "2444440",
    "end": "2449450"
  },
  {
    "text": "the aggregations that were done were based on players what is this player doing what are they about how often they",
    "start": "2449450",
    "end": "2455570"
  },
  {
    "text": "get on those kinds of questions so distributing by player mentor all the made sure that all the player data for",
    "start": "2455570",
    "end": "2462200"
  },
  {
    "text": "every player was on a slice and that slice could do all the work to aggregate or join the",
    "start": "2462200",
    "end": "2469240"
  },
  {
    "text": "downside with key is it's up to you now to make sure your data is well distributed throughout the cluster",
    "start": "2469240",
    "end": "2477550"
  },
  {
    "start": "2477000",
    "end": "2477000"
  },
  {
    "text": "it was this last point that got in the way I'm sorry let's deal with one more slide it was best practice as I talked",
    "start": "2477550",
    "end": "2484369"
  },
  {
    "text": "about two important pieces to distribute your work fody form work load uniformly",
    "start": "2484369",
    "end": "2490040"
  },
  {
    "text": "among the nodes of the cluster this was absolutely well done by the",
    "start": "2490040",
    "end": "2496400"
  },
  {
    "text": "player ID selection but you also wanted to reduce the data movement which also",
    "start": "2496400",
    "end": "2503089"
  },
  {
    "text": "should have been well done by the player ID so something went wrong in these selections that was causing a problem",
    "start": "2503089",
    "end": "2509710"
  },
  {
    "start": "2509000",
    "end": "2509000"
  },
  {
    "text": "mark alluded to this earlier which is there was a fairly high percentage of",
    "start": "2509710",
    "end": "2515740"
  },
  {
    "text": "information coming through where the events were marked as unauthenticated or anonymous these were events that were",
    "start": "2515740",
    "end": "2522830"
  },
  {
    "text": "created before player had logged in or a problem in the telemetry system that it wasn't filling in all the necessary",
    "start": "2522830",
    "end": "2528440"
  },
  {
    "text": "information at this early date what happened is roughly three percent",
    "start": "2528440",
    "end": "2535040"
  },
  {
    "text": "of the events at this timeframe had this unauthenticated value for their",
    "start": "2535040",
    "end": "2540590"
  },
  {
    "text": "player ID and since the key that was being used to distribute the information was based on that column all that",
    "start": "2540590",
    "end": "2548150"
  },
  {
    "text": "information piled up on one node that gave us roughly a 20 percent overload on",
    "start": "2548150",
    "end": "2554390"
  },
  {
    "text": "the storage of the node not great probably not awful so initially we didn't notice that how out",
    "start": "2554390",
    "end": "2561530"
  },
  {
    "text": "of skew this table was as we saw the slowdown occur and occur a deeper",
    "start": "2561530",
    "end": "2566750"
  },
  {
    "text": "analysis showed that if looked at by slice by which CPU the data was assigned",
    "start": "2566750",
    "end": "2572480"
  },
  {
    "text": "to there was a 9x additional load on this one CPU this one sleepy Lou CPU is",
    "start": "2572480",
    "end": "2579680"
  },
  {
    "text": "quite overloaded it was taking the longest to return its results and it was causing all sorts of queries even if",
    "start": "2579680",
    "end": "2586339"
  },
  {
    "text": "they weren't dependent upon the events table to slow down so it's really important to understand",
    "start": "2586339",
    "end": "2593420"
  },
  {
    "text": "the full extent of your data know your data is one of the mantras I like to keep saying and in this case a small",
    "start": "2593420",
    "end": "2600020"
  },
  {
    "text": "percentage of events that shared this unauthenticated value created a very large",
    "start": "2600020",
    "end": "2605619"
  },
  {
    "text": "performance issue on the cluster to address the problem what we did was we",
    "start": "2605619",
    "end": "2613099"
  },
  {
    "start": "2609000",
    "end": "2609000"
  },
  {
    "text": "split the data between two tables on authenticated events table and an",
    "start": "2613099",
    "end": "2618349"
  },
  {
    "text": "unauthenticated events table the authenticated events remained on the player ID distribution key this allowed",
    "start": "2618349",
    "end": "2626060"
  },
  {
    "text": "for all those aggregations for all the known players to happen and for the data to be",
    "start": "2626060",
    "end": "2631630"
  },
  {
    "text": "easily and efficiently aggregated the unauthenticated events were",
    "start": "2631630",
    "end": "2638420"
  },
  {
    "text": "partitioned off to a separate table with an even distribution so now they were going to be evenly distributed around",
    "start": "2638420",
    "end": "2644330"
  },
  {
    "text": "the cluster what this meant is no longer we had a distribution problem and most of the",
    "start": "2644330",
    "end": "2651140"
  },
  {
    "text": "aggregation routines were not looking at the unaffiliated events to find out players that they knew those were",
    "start": "2651140",
    "end": "2656240"
  },
  {
    "text": "uninteresting events we replaced the original events table",
    "start": "2656240",
    "end": "2662060"
  },
  {
    "text": "name with a union all view of these two tables that meant no query code needed",
    "start": "2662060",
    "end": "2668780"
  },
  {
    "text": "to be changed it all ran against the view instead of the original table and",
    "start": "2668780",
    "end": "2674000"
  },
  {
    "text": "it ran significantly faster again it is critically important to know your data",
    "start": "2674000",
    "end": "2681010"
  },
  {
    "start": "2681000",
    "end": "2681000"
  },
  {
    "text": "so this was only this was the most significant but not the only reason for that long tail slowed down the D",
    "start": "2682000",
    "end": "2688970"
  },
  {
    "text": "duplicator was also being affected by the fact that the deduplication of events was looking across the entirety",
    "start": "2688970",
    "end": "2695090"
  },
  {
    "text": "of the ever-growing events table in order to find the duplicate event",
    "start": "2695090",
    "end": "2701830"
  },
  {
    "text": "even with a fantastic block rejection on all those secondary sort keys I just",
    "start": "2701830",
    "end": "2707270"
  },
  {
    "text": "talked about that data set was growing and growing and growing day after day",
    "start": "2707270",
    "end": "2712780"
  },
  {
    "text": "what needed to happen is we needed to shrink the amount of data down to a limited time range and this was possible",
    "start": "2712780",
    "end": "2719300"
  },
  {
    "text": "because of this truncated Kinesis worker time we knew based on that field when",
    "start": "2719300",
    "end": "2726320"
  },
  {
    "text": "they came through Kinesis so based on some overly conservative conservative",
    "start": "2726320",
    "end": "2733610"
  },
  {
    "start": "2729000",
    "end": "2729000"
  },
  {
    "text": "analysis we were able to determine three weeks four weeks don't need to look back",
    "start": "2733610",
    "end": "2739160"
  },
  {
    "text": "farther than that to find the duplicate because they are not going to be that far through the through the system I",
    "start": "2739160",
    "end": "2744830"
  },
  {
    "text": "mean to seven Sigma kind of problems we're able to limit it down by this new",
    "start": "2744830",
    "end": "2750650"
  },
  {
    "text": "primary sort key to only look back a few weeks and this allowed a very uniform or",
    "start": "2750650",
    "end": "2758390"
  },
  {
    "text": "static amount of data to come through the deduplication query this made the D",
    "start": "2758390",
    "end": "2764540"
  },
  {
    "text": "duplicator table size invariant before searching the whole table the amount of",
    "start": "2764540",
    "end": "2770240"
  },
  {
    "text": "data it needs to walk through was ever-increasing now it is limited only grows if the number of events per hour",
    "start": "2770240",
    "end": "2776600"
  },
  {
    "text": "grows into the solution",
    "start": "2776600",
    "end": "2780400"
  },
  {
    "start": "2781000",
    "end": "2781000"
  },
  {
    "text": "the other side of this was aggregation the aggregation times are also growing",
    "start": "2782569",
    "end": "2788599"
  },
  {
    "text": "primarily because many of these were also searching through the entire events table for results",
    "start": "2788599",
    "end": "2797028"
  },
  {
    "text": "this made a aggregation process that was also slowing with time even though they were",
    "start": "2798650",
    "end": "2804839"
  },
  {
    "text": "all these player IDs were co-located on the same slice and we're running fast they were dealing with more and more",
    "start": "2804839",
    "end": "2811020"
  },
  {
    "text": "data as the solution went forward these also needed to be found a data",
    "start": "2811020",
    "end": "2817109"
  },
  {
    "text": "table size invariant pattern in order to be",
    "start": "2817109",
    "end": "2823069"
  },
  {
    "text": "stabilized relative to the size of the events table to do this we went to an incremental",
    "start": "2823849",
    "end": "2830549"
  },
  {
    "start": "2828000",
    "end": "2828000"
  },
  {
    "text": "aggregation approach so basically just look at the last few days of information for all your players find their",
    "start": "2830549",
    "end": "2836700"
  },
  {
    "text": "statistics of what they have done over the last few days that's fairly simple that's adding a where clause to your",
    "start": "2836700",
    "end": "2844279"
  },
  {
    "text": "query that was already existed for this aggregation but then the hard part begins how do you take that limited time",
    "start": "2844279",
    "end": "2850770"
  },
  {
    "text": "range piece of information and merge it with your historical aggregate data it",
    "start": "2850770",
    "end": "2856140"
  },
  {
    "text": "doesn't always just magically line up sometimes it adds replaces some other process these can be",
    "start": "2856140",
    "end": "2864930"
  },
  {
    "text": "very complicated sets of querying analysis and optimizations",
    "start": "2864930",
    "end": "2871460"
  },
  {
    "text": "however this is critically important if you do want a solution that's not going to slow down over time you need to think",
    "start": "2871460",
    "end": "2879569"
  },
  {
    "text": "about if you're dealing with time series data is likely to keep growing and",
    "start": "2879569",
    "end": "2884640"
  },
  {
    "text": "growing and growing as more data comes into your solution if you wanted to keep performing at a predictable rate you",
    "start": "2884640",
    "end": "2890520"
  },
  {
    "text": "probably want to think about how do I set up analyses that are more table-size",
    "start": "2890520",
    "end": "2897710"
  },
  {
    "text": "performing invariant there's an additional benefit that comes along with this process now these",
    "start": "2897710",
    "end": "2904619"
  },
  {
    "text": "aggregations no longer look at older events not that these aggregate tables don't",
    "start": "2904619",
    "end": "2911579"
  },
  {
    "text": "have information that go back to the bidding at a time they do you have all the information for all play in the",
    "start": "2911579",
    "end": "2916860"
  },
  {
    "text": "aggregate tables but for the events table you're not scanning those events very often this allows for the ability",
    "start": "2916860",
    "end": "2923520"
  },
  {
    "text": "to do data retirement one of the issues that often comes up when you start putting data into redshift into your",
    "start": "2923520",
    "end": "2929130"
  },
  {
    "text": "warehouse is it gross and it keeps growing as more data is available setting yourself up for ability to",
    "start": "2929130",
    "end": "2935580"
  },
  {
    "text": "retire data is critically important",
    "start": "2935580",
    "end": "2939830"
  },
  {
    "text": "so with that I'd like to turn it back over to mark but just make that point one more time",
    "start": "2941180",
    "end": "2947610"
  },
  {
    "text": "that is critically important to think about how you can make your data solutions keep performing with time",
    "start": "2947610",
    "end": "2956120"
  },
  {
    "text": "so thank you Bill that was awesome it's been great working with Bill we've learned a lot about redshift and that",
    "start": "2961250",
    "end": "2967620"
  },
  {
    "text": "the visions been realized you know we have many events going into the system it's very performant and",
    "start": "2967620",
    "end": "2973640"
  },
  {
    "text": "we're really looking past the vision now what's the next step what do we want to do",
    "start": "2973640",
    "end": "2978710"
  },
  {
    "start": "2978000",
    "end": "2978000"
  },
  {
    "text": "and let's see and then we're also looking at objective AI if you've ever",
    "start": "2978710",
    "end": "2984420"
  },
  {
    "text": "played our game you know if wookies the last person standing and he taunts which",
    "start": "2984420",
    "end": "2989790"
  },
  {
    "text": "is basically just saying hey fight me that's probably about the worst move he can make we can actually pour in all",
    "start": "2989790",
    "end": "2995220"
  },
  {
    "text": "this data and find what would have been a better action to do there with our rules and our AI not being as good as",
    "start": "2995220",
    "end": "3002480"
  },
  {
    "text": "learning from the data of like what is the better move to do to actually win the battle so really we're changing a",
    "start": "3002480",
    "end": "3008060"
  },
  {
    "text": "definite definition of success it's not just about querying the data that we're looking for it's also finding",
    "start": "3008060",
    "end": "3013370"
  },
  {
    "text": "information that's really hard when you have this much data so let's go over the next steps of what",
    "start": "3013370",
    "end": "3020240"
  },
  {
    "text": "we're looking at so bill mentioned that we've got this huge fact table you know billion events",
    "start": "3020240",
    "end": "3026690"
  },
  {
    "start": "3022000",
    "end": "3022000"
  },
  {
    "text": "a day it gets rather large so data retention became really hot topic for us and mostly because of cost expanding our",
    "start": "3026690",
    "end": "3033590"
  },
  {
    "text": "cluster was something that we did it was a cheaper it was an easy way to continue",
    "start": "3033590",
    "end": "3038870"
  },
  {
    "text": "to scale but it just wasn't cost-effective so bills actually helped us with this also it's in place now",
    "start": "3038870",
    "end": "3044000"
  },
  {
    "text": "where we only keep six months worth of data and then we if we want to do lifetime analysis we'll fire up a",
    "start": "3044000",
    "end": "3049850"
  },
  {
    "text": "cluster maintain that one and do analysis on there so we only need that cluster when we're doing the lifetime",
    "start": "3049850",
    "end": "3054920"
  },
  {
    "text": "analysis so that's really helpful and cost-effective I've already mentioned machine learning there's a whole bunch",
    "start": "3054920",
    "end": "3060920"
  },
  {
    "text": "of solutions out there but it's a really hot topic for us right now that we're looking to use also at the time when we built this",
    "start": "3060920",
    "end": "3067880"
  },
  {
    "text": "firehose didn't exist I'm sure many of you guys are familiar with firehose and we're looking at it's doing much of the",
    "start": "3067880",
    "end": "3073759"
  },
  {
    "text": "work and heavy lifting that we're doing already so we're looking at either and being influenced by what it's doing or",
    "start": "3073759",
    "end": "3079039"
  },
  {
    "text": "even replacing some of the components that we have and then finally Kinesis analytics we'd love to have a wall",
    "start": "3079039",
    "end": "3084109"
  },
  {
    "text": "display that shows you a map a global map with you know every single time there's a transaction coming into the",
    "start": "3084109",
    "end": "3089779"
  },
  {
    "text": "system just really neat stuff like that to get real-time information",
    "start": "3089779",
    "end": "3095109"
  },
  {
    "text": "so that concludes the talk today I really hope it helped to share our architecture and also some of the",
    "start": "3096849",
    "end": "3103339"
  },
  {
    "text": "mistakes we made they're very minor but they can be very loud once you have so much data so I hope bills and my",
    "start": "3103339",
    "end": "3109880"
  },
  {
    "text": "presentation helped you get to there and thank you for your time [Applause]",
    "start": "3109880",
    "end": "3121570"
  }
]
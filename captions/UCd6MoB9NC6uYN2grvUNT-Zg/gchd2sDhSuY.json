[
  {
    "text": "hi my name is under rug I'm a VPN AWS I run a handful of our analytic services",
    "start": "799",
    "end": "7080"
  },
  {
    "text": "and our transactional database Services uh the one we'll be talking about today",
    "start": "7080",
    "end": "12240"
  },
  {
    "text": "is Amazon red shift uh specifically Spectrum which we announced today so",
    "start": "12240",
    "end": "17439"
  },
  {
    "text": "what I'll be doing is giving you a point of view on um why we see Spectrum as",
    "start": "17439",
    "end": "24439"
  },
  {
    "text": "necessary how it works and then uh you know just go through some of the uh Det",
    "start": "24439",
    "end": "29960"
  },
  {
    "text": "details around security and things of that cost and things of that nature",
    "start": "29960",
    "end": "35800"
  },
  {
    "text": "okay to start with let's talk about the question of what is big data I mean it's",
    "start": "35800",
    "end": "41800"
  },
  {
    "text": "a term that's used thrown around a lot but it's not one that as far as I can tell has much meaning so what I mean by",
    "start": "41800",
    "end": "49000"
  },
  {
    "text": "Big Data is when your data sets get so big and so diverse that you have to start innovating around how you collect",
    "start": "49000",
    "end": "55840"
  },
  {
    "text": "them how you store them how you process them how you analyze them and how you share them right where the standard",
    "start": "55840",
    "end": "62440"
  },
  {
    "text": "mechanisms that you used before just don't work",
    "start": "62440",
    "end": "66640"
  },
  {
    "text": "anymore it's really never been easier to generate vast amounts of data we have",
    "start": "68560",
    "end": "74840"
  },
  {
    "text": "individual AWS customers who are generating over a pyte a day so that's a",
    "start": "74840",
    "end": "81960"
  },
  {
    "text": "lot now S3 is pretty awesome you can you know store all of that data and out to",
    "start": "81960",
    "end": "89640"
  },
  {
    "text": "ex if you wish so you know that's a good portion of the",
    "start": "89640",
    "end": "95640"
  },
  {
    "text": "stack but how are you going to analyze it it gets really",
    "start": "95640",
    "end": "101680"
  },
  {
    "text": "hard and what that results in is what we call the dark data problem which is that",
    "start": "101680",
    "end": "109640"
  },
  {
    "text": "most data that people generate and data that they store is not available for",
    "start": "109640",
    "end": "115560"
  },
  {
    "text": "analysis and that's really the reason why we started redshift four years ago that we wanted to solve the dark data",
    "start": "115560",
    "end": "121799"
  },
  {
    "text": "problem sure it's I mean it's interesting to move people's existing data warehouses and you know we're interested in those but were even more",
    "start": "121799",
    "end": "128759"
  },
  {
    "text": "interested in the systems that they couldn't move because it was too expensive because it was too slow to add",
    "start": "128759",
    "end": "135040"
  },
  {
    "text": "more data to their data warehouse because they didn't have the people to manage them anymore and that's really",
    "start": "135040",
    "end": "140440"
  },
  {
    "text": "the core of what red shift's all about making uh data warehousing data",
    "start": "140440",
    "end": "145560"
  },
  {
    "text": "analytics faster less expensive and simpler for people to address the dark data problem the problem is that was",
    "start": "145560",
    "end": "154000"
  },
  {
    "text": "fine four years ago you go out to a couple of pedabytes but what are you do now right people's",
    "start": "154000",
    "end": "160000"
  },
  {
    "text": "data just keeps growing and that's what leads to what we",
    "start": "160000",
    "end": "166319"
  },
  {
    "text": "call internally the tyranny of ore so you can use a Hadoop based system and",
    "start": "166319",
    "end": "172560"
  },
  {
    "text": "directly access you know for example Amazon EMR and you'll be able to directly access your data in S3 that's",
    "start": "172560",
    "end": "178959"
  },
  {
    "text": "awesome you can scale out to thousands of nodes you get to use open data formats and whatever popular Big Data",
    "start": "178959",
    "end": "187040"
  },
  {
    "text": "framework you want to use and Beyond those you can basically do anything you want to cat up and you know you can",
    "start": "187040",
    "end": "193239"
  },
  {
    "text": "dream of or cat up or you can use Amazon redshift a",
    "start": "193239",
    "end": "199760"
  },
  {
    "text": "colum data warehouse which gives you the performance of local discs which is a",
    "start": "199760",
    "end": "205360"
  },
  {
    "text": "lot faster than going over a network it has a sophisticated query optimizer",
    "start": "205360",
    "end": "210519"
  },
  {
    "text": "it has data formats that are optimized for doing local join processing it has",
    "start": "210519",
    "end": "216280"
  },
  {
    "text": "far richer SQL and everything from the hardware up",
    "start": "216280",
    "end": "221360"
  },
  {
    "text": "to the interface is optimized for the data warehousing use",
    "start": "221360",
    "end": "227000"
  },
  {
    "text": "case but you have to choose you know which one do you want do you want a or",
    "start": "227439",
    "end": "234599"
  },
  {
    "text": "b I don't want to choose I shouldn't have to choose I want",
    "start": "234599",
    "end": "240040"
  },
  {
    "text": "all of the above I want both sophisticated query",
    "start": "240040",
    "end": "245640"
  },
  {
    "text": "optimization and I want query you know scaleout processing I want super fast",
    "start": "245640",
    "end": "251599"
  },
  {
    "text": "performance and I want the support for open data formats I want the throughput",
    "start": "251599",
    "end": "257479"
  },
  {
    "text": "of local discs and I want the scale of",
    "start": "257479",
    "end": "262799"
  },
  {
    "text": "S3 and I want this all from one engine right so I don't have to go and switch s",
    "start": "264440",
    "end": "270000"
  },
  {
    "text": "between one SQL dialect and another one and deal with all this variations but I",
    "start": "270000",
    "end": "276080"
  },
  {
    "text": "want my data to not be held hostage by that one data processing engine I want it to be available in every data",
    "start": "276080",
    "end": "282479"
  },
  {
    "text": "processing engine because I do lots of things that aren't SQL as well and I want that to be available not just now",
    "start": "282479",
    "end": "289080"
  },
  {
    "text": "but in the future right because things change it's a very Dynamic",
    "start": "289080",
    "end": "294199"
  },
  {
    "text": "space and so if you you know if you like me want these things you're going to be told",
    "start": "294199",
    "end": "300240"
  },
  {
    "text": "hey man you have to choose you know you can't have both you can either do",
    "start": "300240",
    "end": "306520"
  },
  {
    "text": "efficient join processing using a small cluster or you can use large ones that help you scan but if you want to use a",
    "start": "306520",
    "end": "313280"
  },
  {
    "text": "large cluster and do joint processing well that's an end squared problem taking a thousand node and doing a",
    "start": "313280",
    "end": "318919"
  },
  {
    "text": "Shuffle on it that's a million things because everyone has to talk to each other if you want to use an open data",
    "start": "318919",
    "end": "325680"
  },
  {
    "text": "format you can't talk about using having it uh collocated data for the joints",
    "start": "325680",
    "end": "331440"
  },
  {
    "text": "because you know you want to be able to use clusters of different sizes and they're going to be variable and you",
    "start": "331440",
    "end": "336919"
  },
  {
    "text": "can't basically ensure that the data is going to be collocated and avoid the network traffic and you know what query",
    "start": "336919",
    "end": "343360"
  },
  {
    "text": "optimization requires statistics right and how are you going to do statistics for external data it just doesn't make",
    "start": "343360",
    "end": "349440"
  },
  {
    "text": "sense and then they told me it's just physics which really bugs me and you",
    "start": "349440",
    "end": "354880"
  },
  {
    "text": "know the an the thing is is that it's not just physics it's not physics it's not the halting problem it's actually",
    "start": "354880",
    "end": "361960"
  },
  {
    "text": "just engineering now it's a lot of engineering but we've been working on a",
    "start": "361960",
    "end": "367160"
  },
  {
    "text": "lot of engineering here and um so that's what spectrum is basically",
    "start": "367160",
    "end": "373440"
  },
  {
    "text": "Spectrum gives you the ability to use red shift and redshift syntax to run SQL",
    "start": "373440",
    "end": "379479"
  },
  {
    "text": "queries directly against your S3 data using thousands of noes it's fast even that exobyte scale",
    "start": "379479",
    "end": "387160"
  },
  {
    "text": "it's elastic and highly available basically to Regional subservice where the Spectrum nodes uh live in each of",
    "start": "387160",
    "end": "393960"
  },
  {
    "text": "Three A's and you can allocate instances across your A's you can spin up a red",
    "start": "393960",
    "end": "399000"
  },
  {
    "text": "shift cluster to go against Spectrum from any one of the azs in which we",
    "start": "399000",
    "end": "404039"
  },
  {
    "text": "operate it's on demand because um if you're spinning up a lot of resources",
    "start": "404039",
    "end": "409840"
  },
  {
    "text": "you don't want to pay for them all the time you want to pay for them while you're using them you want to pay per query it's highly concurrent so you can",
    "start": "409840",
    "end": "417800"
  },
  {
    "text": "have multiple red shift clusters ACC the same data inside S3 using Spectrum there's no ETL you can query",
    "start": "417800",
    "end": "425599"
  },
  {
    "text": "the data in place in S3 using open data formats without conversion and it's SQL right it's full",
    "start": "425599",
    "end": "433599"
  },
  {
    "text": "amson red shift SQL support no differences whatsoever so let's talk about how we do",
    "start": "433599",
    "end": "440039"
  },
  {
    "text": "all of that and you know break the tyranny of or so let's look at the life of a query",
    "start": "440039",
    "end": "446160"
  },
  {
    "text": "so what you see on this uh graph here is this diagram here is a bi client it's",
    "start": "446160",
    "end": "453599"
  },
  {
    "text": "talking to redshift through a leader node through its SQL endpoint red shift is a clustered",
    "start": "453599",
    "end": "459080"
  },
  {
    "text": "solution so there's a leader node and a set of compute nodes that you provision and you know that's the same",
    "start": "459080",
    "end": "465560"
  },
  {
    "text": "slide I've been using for ages and underneath the covers what you have is also a um now a spectrum cluster which",
    "start": "465560",
    "end": "474960"
  },
  {
    "text": "are a bunch of private VPC managed uh nodes that are available to any red",
    "start": "474960",
    "end": "480919"
  },
  {
    "text": "shift cluster that is Spectrum enabled and those all access S3 underneath the covers they also access uh you know S3",
    "start": "480919",
    "end": "488759"
  },
  {
    "text": "contains data you also need the metadata to understand that data and so it also you know you have a data catalog whether",
    "start": "488759",
    "end": "495720"
  },
  {
    "text": "that's the Athena catalog today or it's the U glue data catalog once glue",
    "start": "495720",
    "end": "501879"
  },
  {
    "text": "launches in a little while or it's your own uh Hive metastore if you happen to have",
    "start": "501879",
    "end": "507759"
  },
  {
    "text": "one so in this case we're going to walk through what happens when you issue a query so you issue a query it goes to",
    "start": "507759",
    "end": "513240"
  },
  {
    "text": "the red shift leader node the query is optimized at the leader node and it's compiled there and",
    "start": "513240",
    "end": "519719"
  },
  {
    "text": "down into C++ and we determine what gets run locally and What needs to go uh to uh",
    "start": "519719",
    "end": "526080"
  },
  {
    "text": "reg Spectrum the query plan is and the code is sent to all of the compute nodes to",
    "start": "526080",
    "end": "533480"
  },
  {
    "text": "execute the compute nodes figure out the partition information from the data catalog and they're able ble to",
    "start": "533480",
    "end": "539760"
  },
  {
    "text": "dynamically prune the partitions based on you know the Run um the parts of the",
    "start": "539760",
    "end": "545360"
  },
  {
    "text": "plan that they've run already and they issue multiple requests",
    "start": "545360",
    "end": "551399"
  },
  {
    "text": "to Spectrum to you know grab files over there spectrum is going to scan your uh",
    "start": "551399",
    "end": "558640"
  },
  {
    "text": "S3 data it pro it runs the projections filters",
    "start": "558640",
    "end": "563839"
  },
  {
    "text": "Aggregates then the final you know partial aggregations group buys and so forth get pulled back back into red",
    "start": "563839",
    "end": "570360"
  },
  {
    "text": "shift where we do joint processing uh because you want to do joint processing against smaller amounts of data uh",
    "start": "570360",
    "end": "577480"
  },
  {
    "text": "smaller cluster sizes then you know you would be a bit excuse me use of in",
    "start": "577480",
    "end": "583600"
  },
  {
    "text": "spectrum and then the result is sent back to the client so pretty simple um so now let's uh run an",
    "start": "583600",
    "end": "592200"
  },
  {
    "text": "analytic query over an xab in S3 so first let's go and build what we mean by",
    "start": "592200",
    "end": "598120"
  },
  {
    "text": "this analytic query so let's imagine that JK Rowling is",
    "start": "598120",
    "end": "603440"
  },
  {
    "text": "about to issue her eighth book in the Harry Potter series right so she sells a lot of books and so I might be a product",
    "start": "603440",
    "end": "610399"
  },
  {
    "text": "manager inside Amazon retail thinking about hey so how many books should I order for the region I'm responsible for",
    "start": "610399",
    "end": "617440"
  },
  {
    "text": "Seattle right and so one way that you might try to understand that is how what",
    "start": "617440",
    "end": "622760"
  },
  {
    "text": "is the progression of Prior book sales for her right",
    "start": "622760",
    "end": "629440"
  },
  {
    "text": "so one thing you would want to know is hey what are the books she's written in the past so I'm going to pick out the",
    "start": "630399",
    "end": "636680"
  },
  {
    "text": "books from uh my products table where the title contains the word Potter and",
    "start": "636680",
    "end": "641839"
  },
  {
    "text": "the author is JK roll so one table two filters then you want to compute the",
    "start": "641839",
    "end": "648560"
  },
  {
    "text": "sales of those books right so you not just the product but you also want to go and look at what how many in for each",
    "start": "648560",
    "end": "655920"
  },
  {
    "text": "order that you got what was the quantity times what was the price and look at that as the sum of sales so now a",
    "start": "655920",
    "end": "661760"
  },
  {
    "text": "suddenly you've got two tables one's in S3 which is because the number of total",
    "start": "661760",
    "end": "667600"
  },
  {
    "text": "customer order item details is actually could be pretty large even if products is small and but you can see that the",
    "start": "667600",
    "end": "674880"
  },
  {
    "text": "syntax is entirely generic right it's just a set of uh list of uh you know s3.",
    "start": "674880",
    "end": "682399"
  },
  {
    "text": "uh table name and we'll come to how I decided to call it S3 there you know two",
    "start": "682399",
    "end": "688720"
  },
  {
    "text": "filters one join a couple of group buys one order buy a limit and an",
    "start": "688720",
    "end": "695160"
  },
  {
    "text": "aggregate the next thing you want to be able to say is hey I'm not interested in her total Book Sales I just want the",
    "start": "695399",
    "end": "700760"
  },
  {
    "text": "first three days because that's my reorder point and I don't want all the books over all time I just want the hard",
    "start": "700760",
    "end": "707000"
  },
  {
    "text": "cover first edition so you might have a set of attributes for each of your",
    "start": "707000",
    "end": "712360"
  },
  {
    "text": "products and you know it might contain something like addition like uh first it might have uh you know the order date is",
    "start": "712360",
    "end": "719880"
  },
  {
    "text": "greater than or equal to the release date and less than or equal to 3 days past the release date right so now we're",
    "start": "719880",
    "end": "726600"
  },
  {
    "text": "up to three tables five filters Two Joints uh three group buys one order by a limit an aggregate a function now and",
    "start": "726600",
    "end": "734639"
  },
  {
    "text": "a couple of casts so it's starting to get complicated right and then you would say like hey",
    "start": "734639",
    "end": "740920"
  },
  {
    "text": "I'm actually just interested in the city of Seattle and so I pick up a regions table and I'll say like okay here's the",
    "start": "740920",
    "end": "747120"
  },
  {
    "text": "country here's the state and here's the region and I want to basically join against the region so I basically in",
    "start": "747120",
    "end": "753320"
  },
  {
    "text": "this you know you can read the thing four tables eight filters three joints four group eyes etc etc so that's kind",
    "start": "753320",
    "end": "760320"
  },
  {
    "text": "of what I mean when I I'm talking about an analytic query so because a lot of people will show you oh I can run over a",
    "start": "760320",
    "end": "767279"
  },
  {
    "text": "petabyte but they're running that uh some trivial query there right and",
    "start": "767279",
    "end": "772440"
  },
  {
    "text": "that's just not useful right they're just doing a scan or maybe a scan and an A but that's not what we do in our",
    "start": "772440",
    "end": "778320"
  },
  {
    "text": "day-to-day lives we run fairly complex stuff and sql's pretty awesome in the fact that you actually can build a",
    "start": "778320",
    "end": "785360"
  },
  {
    "text": "complex query and um you know pretty quickly just as I did here in a few",
    "start": "785360",
    "end": "791320"
  },
  {
    "text": "minutes that actually answer something reasonable but it's got a lot of different operators in it",
    "start": "791320",
    "end": "798600"
  },
  {
    "text": "right so now let's run that query over an exobyte of data because you know",
    "start": "799199",
    "end": "804440"
  },
  {
    "text": "maybe you're not some random U um you know bookstore in Seattle your Amazon we",
    "start": "804440",
    "end": "810760"
  },
  {
    "text": "still sell books right and uh but we'll generate maybe roughly 140 terab of",
    "start": "810760",
    "end": "817240"
  },
  {
    "text": "customer item order detail every day we might have been saving that for the last 20 years and so you know if you sum that",
    "start": "817240",
    "end": "824600"
  },
  {
    "text": "out that's uh 190 million files across 15,000 partitions basically a partition",
    "start": "824600",
    "end": "832000"
  },
  {
    "text": "per day and then there's a partition for USA versus rest of world and so you know",
    "start": "832000",
    "end": "838600"
  },
  {
    "text": "one question you might be asking yourself is hey is an exabyte really a lot of data so you know the answer to",
    "start": "838600",
    "end": "844519"
  },
  {
    "text": "that is yes obviously and to put that into context what uh that would be is",
    "start": "844519",
    "end": "850959"
  },
  {
    "text": "like let's I imagine most of the people in the audience have a smartphone right maybe you've got a pretty decent",
    "start": "850959",
    "end": "856519"
  },
  {
    "text": "smartphone with 32 gigs of uh 32 gigabytes of uh uh disk space on it",
    "start": "856519",
    "end": "863399"
  },
  {
    "text": "right so an exobyte would be enough to store the contents of your smartphone",
    "start": "863399",
    "end": "869240"
  },
  {
    "text": "and 32 million of your closest friends right so a fair bit of",
    "start": "869240",
    "end": "876320"
  },
  {
    "text": "data um so if you want to process that you really need to get a billionfold",
    "start": "876320",
    "end": "884440"
  },
  {
    "text": "reduction in the amount of data that you're processing let me actually start the query",
    "start": "884440",
    "end": "890399"
  },
  {
    "text": "going and um so by the way you know they I wanted to do this query live but they",
    "start": "890399",
    "end": "896160"
  },
  {
    "text": "told me I was insane you know and I should really just do a U video and so",
    "start": "896160",
    "end": "901959"
  },
  {
    "text": "what you're really seeing here is my PowerPoint skills which are weak uh versus my ability to run red shift which",
    "start": "901959",
    "end": "907800"
  },
  {
    "text": "is a little bit stronger you can see at least here the one that I you know did a screen capture of early you know is uh",
    "start": "907800",
    "end": "914720"
  },
  {
    "text": "very much a developer screen which is uh you know because it's white text on the dark background as all developers should",
    "start": "914720",
    "end": "921600"
  },
  {
    "text": "have uh so this is a very uninteresting demo we're basically going to just watch it you know blink for circa 3 minutes",
    "start": "921600",
    "end": "929920"
  },
  {
    "text": "and so and but the point here is is that you really need roughly a billionfold",
    "start": "929920",
    "end": "935519"
  },
  {
    "text": "reduction in the data processed in order to make that work and you know have it returned in the time frame of interest",
    "start": "935519",
    "end": "942920"
  },
  {
    "text": "and so and you know we'd we estimated that running this query using a thousand",
    "start": "942920",
    "end": "948199"
  },
  {
    "text": "node Hive cluster would take over 5 years we mentioned that in the keynote and the way we estimated that was to",
    "start": "948199",
    "end": "954079"
  },
  {
    "text": "take a 20 node hi cluster and 1/1 100th of one day of data 1.4",
    "start": "954079",
    "end": "961399"
  },
  {
    "text": "terabytes and assume it just scales linearly now of course it doesn't scale linearly as you get bigger uh given the",
    "start": "961399",
    "end": "968199"
  },
  {
    "text": "fact that their joins here the shuffles are actually N squared so that's going to be a problem and also there's a point at",
    "start": "968199",
    "end": "975040"
  },
  {
    "text": "which the hash join needs to spill to disk which is going to be a problem and you're going to actually if you run any",
    "start": "975040",
    "end": "981519"
  },
  {
    "text": "data set larger than this and Hive you're going to actually run out of virtual memory which is yet more of a problem so the queral Finish quickly it",
    "start": "981519",
    "end": "988360"
  },
  {
    "text": "just won't return return any data because it'll just return an error but um let's assume all of those problems",
    "start": "988360",
    "end": "993800"
  },
  {
    "text": "were solved it would uh and I was doing the most beneficial possible Assumption",
    "start": "993800",
    "end": "999040"
  },
  {
    "text": "of what hi could do it would take five years so I don't want to wait five years um so let's look at what we're going to",
    "start": "999040",
    "end": "1006079"
  },
  {
    "text": "end up doing in redshift so one thing is is that for this particular data set we get about 5x compression because most of",
    "start": "1006079",
    "end": "1013079"
  },
  {
    "text": "the data in it is text uh there are 50 columns that are inside here we're",
    "start": "1013079",
    "end": "1018360"
  },
  {
    "text": "retrieving about five from S3 so we get a 10x compression there so that's 50",
    "start": "1018360",
    "end": "1023400"
  },
  {
    "text": "total in this case uh Spectrum decided to run um 2500 noes so that's gives me",
    "start": "1023400",
    "end": "1029720"
  },
  {
    "text": "another bit of Advantage there but I'm still quite a bit uh short of the",
    "start": "1029720",
    "end": "1034760"
  },
  {
    "text": "billion that I need I'm barely into the million range and so and the point in",
    "start": "1034760",
    "end": "1041520"
  },
  {
    "text": "this is that if you want to scale you can't just throw bigger hammers at things somewhere along the way you",
    "start": "1041520",
    "end": "1046600"
  },
  {
    "text": "actually have to learn to be smart and so that's the other half of this you know where we're doing the not just",
    "start": "1046600",
    "end": "1053640"
  },
  {
    "text": "throw a lot of resources at something but also start to be intelligent about what we apply and so using red shift you",
    "start": "1053640",
    "end": "1060240"
  },
  {
    "text": "know there's a 2X uh static uh partition elimination that happens because I'm actually asking for data about the US",
    "start": "1060240",
    "end": "1066760"
  },
  {
    "text": "and so I can remove half of the it came back just under 3 minutes",
    "start": "1066760",
    "end": "1072360"
  },
  {
    "text": "here I really think she should send another you know do another book because",
    "start": "1072360",
    "end": "1078000"
  },
  {
    "text": "you can see that the last one is the one that shows up in the top 10 all the time",
    "start": "1078000",
    "end": "1083080"
  },
  {
    "text": "um anyway uh if you're listening JK um",
    "start": "1083080",
    "end": "1088240"
  },
  {
    "text": "so but um the other thing that's happened here is is that um you know dynamic partition elimination is",
    "start": "1088240",
    "end": "1094600"
  },
  {
    "text": "interesting right and what we mean by that is a little bit different than what uh other people do because what we've",
    "start": "1094600",
    "end": "1101240"
  },
  {
    "text": "had to do is run all of the reductions on the local side of the storage uh",
    "start": "1101240",
    "end": "1108520"
  },
  {
    "text": "local discs to figure out hey what are the days that we're interested in so that we can get down to the just the 21",
    "start": "1108520",
    "end": "1114799"
  },
  {
    "text": "that we wanted seven books time 3 days right and so that helped a lot and then",
    "start": "1114799",
    "end": "1120200"
  },
  {
    "text": "of course you know the Cory Optimizer is just better there's actually some other stuff that gives us about um you know",
    "start": "1120200",
    "end": "1126440"
  },
  {
    "text": "10x Beyond this but I don't really want to get into that stuff um so let's keep",
    "start": "1126440",
    "end": "1132679"
  },
  {
    "text": "going so you know you can run this query yourself I have to say it takes a little while to generate an exite of data it's",
    "start": "1132679",
    "end": "1138360"
  },
  {
    "text": "kind of expensive as well but uh you know with the smaller data set that would be",
    "start": "1138360",
    "end": "1143720"
  },
  {
    "text": "fine so as you can see from that uh spectrum is fast so we leverage an",
    "start": "1143720",
    "end": "1149320"
  },
  {
    "text": "advanced cost bait Optimizer we push down the things we can push down into",
    "start": "1149320",
    "end": "1154760"
  },
  {
    "text": "the scale out layer which are projections basically reducing the number of columns we want to go after",
    "start": "1154760",
    "end": "1160880"
  },
  {
    "text": "filters to reduce the number of tupal partial aggregations uh like the one",
    "start": "1160880",
    "end": "1167360"
  },
  {
    "text": "that would have come back here and join reduction to say hey let me reduce the number of things that I can I need to",
    "start": "1167360",
    "end": "1173000"
  },
  {
    "text": "join against upfront so I can just do scans locally against us three so the",
    "start": "1173000",
    "end": "1178480"
  },
  {
    "text": "individual Spectrum nodes don't talk to each other they just talk back up to the cluster uh we've done a lot of",
    "start": "1178480",
    "end": "1185600"
  },
  {
    "text": "investment in Dynamic partition pruning which is a relatively big deal very Innovative work by uh the red shift team",
    "start": "1185600",
    "end": "1193080"
  },
  {
    "text": "to minimize the amount of data you bring back of course we paralized query execution against S3 and then by",
    "start": "1193080",
    "end": "1200080"
  },
  {
    "text": "bringing it back to a smaller cluster we get efficient joint processing because the cluster itself is quite a bit",
    "start": "1200080",
    "end": "1207559"
  },
  {
    "text": "smaller spectrum is also pretty cost effective so what you're paying for spectrum is the cost of your data S3 as",
    "start": "1208760",
    "end": "1215960"
  },
  {
    "text": "you always do the cost of your red shift cluster because that's just up all the time and the instances cost us money and",
    "start": "1215960",
    "end": "1222799"
  },
  {
    "text": "you're paying $5 per terabyte scanned out of S3 and so we're doing our",
    "start": "1222799",
    "end": "1228000"
  },
  {
    "text": "absolute best to reduce that amount through the optimization and um you basically don't",
    "start": "1228000",
    "end": "1234159"
  },
  {
    "text": "have to pay attention to how many nodes we allocate to your query because you're paying the same amount either way you're",
    "start": "1234159",
    "end": "1240200"
  },
  {
    "text": "just paying for the amount of data that transfers whether we're using 200 nodes or 2,000 noes and also it's important to",
    "start": "1240200",
    "end": "1247559"
  },
  {
    "text": "know that you can reduce the amount of terabytes that you're scanning and improve your query performance by",
    "start": "1247559",
    "end": "1252640"
  },
  {
    "text": "partitioning your data so that way we can do partition elimination even dynamically using a columnar data format",
    "start": "1252640",
    "end": "1259840"
  },
  {
    "text": "because we'll just read the uh columns that we need or compressing your data right so each of those reduces and um",
    "start": "1259840",
    "end": "1267880"
  },
  {
    "text": "you know what we do is we charge you for the actual data that we're processing down not some uncompressed un you know",
    "start": "1267880",
    "end": "1274440"
  },
  {
    "text": "uh overall data set sized like others",
    "start": "1274440",
    "end": "1279000"
  },
  {
    "text": "do Spectrum also has all of the basic capabilities of red shift it's an",
    "start": "1279559",
    "end": "1284679"
  },
  {
    "text": "internal component and so if you're familiar with with um you know so you",
    "start": "1284679",
    "end": "1289760"
  },
  {
    "text": "can encrypt your S3 data using server side encryption using KMS Keys all of",
    "start": "1289760",
    "end": "1295000"
  },
  {
    "text": "your red shift data can easily one click be encrypted and that using KMS or Cloud",
    "start": "1295000",
    "end": "1301080"
  },
  {
    "text": "HSM or your on- premise hsms and you know that's all of your data that's basically your temp data your log data",
    "start": "1301080",
    "end": "1308360"
  },
  {
    "text": "your data blocks all of it it's done at a very low level of the system you can enforce SSL to be you know for all of",
    "start": "1308360",
    "end": "1315559"
  },
  {
    "text": "your clients going into the cluster it's perfect forward encryption which if you're not using perfect",
    "start": "1315559",
    "end": "1320919"
  },
  {
    "text": "forward encryption you should um and you're using ecdhe which is what you",
    "start": "1320919",
    "end": "1326400"
  },
  {
    "text": "should be using as well uh the leader node gives you network isolation because the leader node is inside your your",
    "start": "1326400",
    "end": "1333840"
  },
  {
    "text": "customers the customer VPC uh the compute nodes of the inside the red shift cluster are in the private VPC so",
    "start": "1333840",
    "end": "1340120"
  },
  {
    "text": "they're not accessible and they have uh discs on them so we want to make sure that they're privately held we basically",
    "start": "1340120",
    "end": "1346760"
  },
  {
    "text": "uh connect them to the uh leader node and the Spectrum nodes importantly are",
    "start": "1346760",
    "end": "1351799"
  },
  {
    "text": "yet in the third a and that we have access to from the compute nodes but",
    "start": "1351799",
    "end": "1357760"
  },
  {
    "text": "they also store in those State whatsoever which gives you a level of protection so the only thing that's",
    "start": "1357760",
    "end": "1363000"
  },
  {
    "text": "going on there is memory for stuff that is in process being executed um we use SNS uh not uh simple",
    "start": "1363000",
    "end": "1371039"
  },
  {
    "text": "notification service for notifications and alert so you'll find out about them that's really important to people who",
    "start": "1371039",
    "end": "1376880"
  },
  {
    "text": "are interested in compliance all of your API calls modifying your cluster continue to be logged using cloud trail",
    "start": "1376880",
    "end": "1383279"
  },
  {
    "text": "and all of your SQL statements continue to be logged within Amazon red shift itself and you know all of the",
    "start": "1383279",
    "end": "1389120"
  },
  {
    "text": "certifications and compliance that red shift has now sock 123 Hippa baa fed Ram",
    "start": "1389120",
    "end": "1395400"
  },
  {
    "text": "PCI DSS Etc there are more but you know that's a basic list um you know are",
    "start": "1395400",
    "end": "1402159"
  },
  {
    "text": "available to you as well so you know there isn't really again the tyranny of ore within what you have to choose",
    "start": "1402159",
    "end": "1409760"
  },
  {
    "text": "it also uses standard SQL so uh all of the stuff that you'd use for a red shift",
    "start": "1409760",
    "end": "1414919"
  },
  {
    "text": "local query works with Spectrum queries and so that means that if you've got a",
    "start": "1414919",
    "end": "1419960"
  },
  {
    "text": "bi app bi tool that is currently connecting to uh red shift it'll work",
    "start": "1419960",
    "end": "1425640"
  },
  {
    "text": "with Spectrum as well and uh you know it has all of the same complex joints nested queries window functions all that",
    "start": "1425640",
    "end": "1432600"
  },
  {
    "text": "goodness and will continue to as we enhance red shift in the future and uh you can partition your",
    "start": "1432600",
    "end": "1439039"
  },
  {
    "text": "data in S3 with any key you wish there's no restriction on that either so how do",
    "start": "1439039",
    "end": "1444159"
  },
  {
    "text": "I uh get started well you basically have to create an external schema so which is a",
    "start": "1444159",
    "end": "1450360"
  },
  {
    "text": "real relatively standard command so if you just do the defaults it'll connect to the Athena data catalog or you can",
    "start": "1450360",
    "end": "1457760"
  },
  {
    "text": "supply a few you know a URI and connect it to your hive metast store and",
    "start": "1457760",
    "end": "1463679"
  },
  {
    "text": "U then just like anything else with an external schema you query external tables using schema name. table name in",
    "start": "1463679",
    "end": "1471360"
  },
  {
    "text": "U your syntax and the query you saw earlier I had created an external schema called S3 and connected to a catalog",
    "start": "1471360",
    "end": "1479200"
  },
  {
    "text": "which had that table that I referred to uh inside that catalog and so you know",
    "start": "1479200",
    "end": "1485520"
  },
  {
    "text": "how do I get my external tables registered well you can use Athena to do it using U hiveql you can use your own",
    "start": "1485520",
    "end": "1492080"
  },
  {
    "text": "Hive metast store client and just do it as you do it today or we've added create external table syntax to Red shift so",
    "start": "1492080",
    "end": "1499320"
  },
  {
    "text": "you can basically do the syntax to register a table that way and what we do",
    "start": "1499320",
    "end": "1505080"
  },
  {
    "text": "here is we just basically go back to your data catalog and add it there and uhu of course the Syntax for an external",
    "start": "1505080",
    "end": "1512440"
  },
  {
    "text": "table ends up being um the hiveql syntax uh by and large not the red shift syntax",
    "start": "1512440",
    "end": "1519399"
  },
  {
    "text": "but so that's a difference currently we uh support um a",
    "start": "1519399",
    "end": "1528000"
  },
  {
    "text": "number f file formats that are popular orc isn't quite there at launch it'll be",
    "start": "1528000",
    "end": "1533919"
  },
  {
    "text": "coming real soon reject surday are coming real soon uh but we're you know",
    "start": "1533919",
    "end": "1539320"
  },
  {
    "text": "everything else that is on the file format list is there today if you are um",
    "start": "1539320",
    "end": "1545200"
  },
  {
    "text": "if there's something that you don't see on that list uh and you which you want let us know uh similarly with",
    "start": "1545200",
    "end": "1551840"
  },
  {
    "text": "compression we've got gzip Snappy and uh bzip uh lzo is coming again real soon um",
    "start": "1551840",
    "end": "1560120"
  },
  {
    "text": "and uh you know if there's something else you want there let us know um encryption you know you can you have the",
    "start": "1560120",
    "end": "1567159"
  },
  {
    "text": "server side encryption capabilities of S3 uh on the client side doesn't really",
    "start": "1567159",
    "end": "1572360"
  },
  {
    "text": "make sense in this case uh basic list of column types uh you know the ones you'd",
    "start": "1572360",
    "end": "1577600"
  },
  {
    "text": "expect or supported and table types again the ones you would expect or supported nonp partition tables and",
    "start": "1577600",
    "end": "1583679"
  },
  {
    "text": "partition tables we do uh recommend that people",
    "start": "1583679",
    "end": "1588760"
  },
  {
    "text": "consider converting to par and or or and or orc for their uh larger tables um and",
    "start": "1588760",
    "end": "1596760"
  },
  {
    "text": "it's relatively easy to do that you can use the hive create table as select command which basically you know create",
    "start": "1596760",
    "end": "1602360"
  },
  {
    "text": "a table in the converted format stor as parquet as a select from The Source format right so that's relatively easy",
    "start": "1602360",
    "end": "1608960"
  },
  {
    "text": "or you can choose to use spark and it's about 20 lines of P spark code and uh as",
    "start": "1608960",
    "end": "1614559"
  },
  {
    "text": "an example there's a uh link over there which shows that converting a terabyte",
    "start": "1614559",
    "end": "1620720"
  },
  {
    "text": "of text Data reduced to about 130 gabt in parquet format using Snappy and the",
    "start": "1620720",
    "end": "1627159"
  },
  {
    "text": "total cost of the EMR job to do it the onetime cost was five",
    "start": "1627159",
    "end": "1632240"
  },
  {
    "text": "bucks so you may be asking yourself hey Spectrum useful if I don't have an",
    "start": "1632919",
    "end": "1638399"
  },
  {
    "text": "exabyte and I would say well first the answer is yes and so why is the answer",
    "start": "1638399",
    "end": "1644880"
  },
  {
    "text": "yes so one is is that one reason is is that your data is going going to get bigger it may not you know you may be if",
    "start": "1644880",
    "end": "1650360"
  },
  {
    "text": "you're running uh on average data warehousing volumes grow 10x every 5 years so it'll go up a factor of a",
    "start": "1650360",
    "end": "1657559"
  },
  {
    "text": "thousand every 15 years and that's industrywide and uh the average red shift customer doubles their storage",
    "start": "1657559",
    "end": "1664320"
  },
  {
    "text": "every year and you know just because the costs are better and um so that means",
    "start": "1664320",
    "end": "1671840"
  },
  {
    "text": "inside 10 Years it'll go up three orders of magnitude so if you've got a terabyte now in 10 years it'll be a ped",
    "start": "1671840",
    "end": "1679200"
  },
  {
    "text": "right if you've got a petabyte now in 10 years it'll be an exabyte that's a lot",
    "start": "1679200",
    "end": "1684279"
  },
  {
    "text": "and so you know it's very important that you make pick solutions that aren't going to cause you to bump into the",
    "start": "1684279",
    "end": "1689559"
  },
  {
    "text": "ceiling at some point or cause you to have to delete data um but apart from the data volumes",
    "start": "1689559",
    "end": "1696600"
  },
  {
    "text": "growing over time it's also important to know that red shift makes your data analytics much easier because you don't",
    "start": "1696600",
    "end": "1702960"
  },
  {
    "text": "need the same complicated ETL pipelines that you did today right and the data is just in one place and now you can have",
    "start": "1702960",
    "end": "1711279"
  },
  {
    "text": "your various teams maybe you've got someone who wants to use spark ml who's",
    "start": "1711279",
    "end": "1716960"
  },
  {
    "text": "a data scientist maybe you've got somebody who's a data analyst who wants to use uh standard SQL to do complex",
    "start": "1716960",
    "end": "1723600"
  },
  {
    "text": "queries against their data maybe you've got an ad hoc user who comes in every so often uh to you know look at it but you",
    "start": "1723600",
    "end": "1730320"
  },
  {
    "text": "don't really want to allocate a specific solution for them but maybe once a month they look at something so that's where",
    "start": "1730320",
    "end": "1736320"
  },
  {
    "text": "EMR Athena red Shi Spectrum all work well together and you can collaborate",
    "start": "1736320",
    "end": "1741880"
  },
  {
    "text": "right you can start to take your data that your data scientist generates and push it to uh your uh data",
    "start": "1741880",
    "end": "1749360"
  },
  {
    "text": "analyst um and then it also improves availability and concurrency for red shift itself because you can run",
    "start": "1749360",
    "end": "1755320"
  },
  {
    "text": "multiple red shift clusters against common data and you can isolate the jobs with tight slas you know the ones you",
    "start": "1755320",
    "end": "1761640"
  },
  {
    "text": "absolutely need to get done every single day or every single hour from the ones which uh maybe you've got some data",
    "start": "1761640",
    "end": "1769000"
  },
  {
    "text": "science folks who are writing really crazy queries like uh you know I've gotten paged because someone was trying",
    "start": "1769000",
    "end": "1775320"
  },
  {
    "text": "to join a 100 terab table with itself and uh you know ran out of space so",
    "start": "1775320",
    "end": "1783880"
  },
  {
    "text": "things like that happen and so you know you if those happen that's fine but you want to isolate the people who are doing",
    "start": "1783880",
    "end": "1790080"
  },
  {
    "text": "that kind of stuff from the people who are running the bread and butter queries",
    "start": "1790080",
    "end": "1795760"
  },
  {
    "text": "right and so let's spend a minute and talk about the what I view as the emerging analytics",
    "start": "1796159",
    "end": "1802880"
  },
  {
    "text": "architecture so you know I've been in this gig for a while now maybe 20 some",
    "start": "1802880",
    "end": "1808240"
  },
  {
    "text": "years and then when I started uh the machine I'd used may have been a little bit bigger than this computer in front",
    "start": "1808240",
    "end": "1814200"
  },
  {
    "text": "of me here but it wasn't any more powerful it was quite actually quite a bit less powerful and if I wanted to run",
    "start": "1814200",
    "end": "1820480"
  },
  {
    "text": "uh SQL against it I'd you know this machine has storage it has processing it",
    "start": "1820480",
    "end": "1826799"
  },
  {
    "text": "has uh program that run on top of it but now in today you know I can't really",
    "start": "1826799",
    "end": "1832600"
  },
  {
    "text": "scale my data set to fit on this anymore not for anything real I need to run",
    "start": "1832600",
    "end": "1838960"
  },
  {
    "text": "analytics at data center scale and so running analytics at data center scale",
    "start": "1838960",
    "end": "1844519"
  },
  {
    "text": "basically means I need services that you know like the ones from AWS that operate at data center",
    "start": "1844519",
    "end": "1851159"
  },
  {
    "text": "scale and so S3 certainly does right you know you can store pretty much arbitrary",
    "start": "1851159",
    "end": "1857399"
  },
  {
    "text": "amounts of uh stuff in there um the data catalog helps you understand your data",
    "start": "1857399",
    "end": "1863960"
  },
  {
    "text": "inside S3 so you know having your data there doesn't mean anything unless you can understand what it is then you want",
    "start": "1863960",
    "end": "1870080"
  },
  {
    "text": "a bunch of underlying almost OS services that basically operate underneath the",
    "start": "1870080",
    "end": "1875320"
  },
  {
    "text": "scenes and help your system run so in this case that's basically from my perspective serverless compute in our",
    "start": "1875320",
    "end": "1882480"
  },
  {
    "text": "case things like Spectrum things like Lambda things like glue things like Kinesis fire hose which just run when",
    "start": "1882480",
    "end": "1889120"
  },
  {
    "text": "they need to run right you don't really you set it up and then you stop thinking about it they just run after",
    "start": "1889120",
    "end": "1894679"
  },
  {
    "text": "that and then you have your data processing layer which is more interactive it has a pane of glass in",
    "start": "1894679",
    "end": "1900880"
  },
  {
    "text": "front of it and it's more of a session oriented interface and those are things in this case like EMR red shift and",
    "start": "1900880",
    "end": "1907320"
  },
  {
    "text": "Athena right and you know I know a natural question is for people is hey",
    "start": "1907320",
    "end": "1912399"
  },
  {
    "text": "when should I use each and so EMR basically the great thing about EMR is you can do anything you can code up in",
    "start": "1912399",
    "end": "1918639"
  },
  {
    "text": "threee it gives you a lot of flexibility you know red shift you know straight up",
    "start": "1918639",
    "end": "1923799"
  },
  {
    "text": "the your fastest option for SQL processing and Athena gives you interactive queries you don't need to",
    "start": "1923799",
    "end": "1928960"
  },
  {
    "text": "set up anything you just walk up to it and use it and so for different users even inside the same company all of them",
    "start": "1928960",
    "end": "1936120"
  },
  {
    "text": "can make sense so we had um a number of companies",
    "start": "1936120",
    "end": "1943639"
  },
  {
    "text": "that uh helped us preview Richi Spectrum a handful of them are on this Slide the ones that gave us logo rights but I you",
    "start": "1943639",
    "end": "1950760"
  },
  {
    "text": "know I wanted to close the presentation with really thanking them because their time really helped us generate a better",
    "start": "1950760",
    "end": "1957880"
  },
  {
    "text": "product and one that uh both worked and addressed the needs that they felt were most significant so you know I just",
    "start": "1957880",
    "end": "1965600"
  },
  {
    "text": "wanted to thank them for that and also to thank you for showing up and paying attention to this uh presentation and",
    "start": "1965600",
    "end": "1971519"
  },
  {
    "text": "I'm happy to take whatever questions you have and I have a number of the people in the Spectrum team here as well who",
    "start": "1971519",
    "end": "1977440"
  },
  {
    "text": "might be able to go into a level of detail I [Applause]",
    "start": "1977440",
    "end": "1988039"
  },
  {
    "text": "can't any questions yes sir",
    "start": "1988039",
    "end": "1993440"
  },
  {
    "text": "yes so the the question was when Athena when red shift Spectrum uh doesn't",
    "start": "2010000",
    "end": "2017840"
  },
  {
    "text": "Spectrum sort of dominate the use case for uh Athena",
    "start": "2017840",
    "end": "2023840"
  },
  {
    "text": "and the basic answer to that question comes to the uh issue of how much",
    "start": "2023840",
    "end": "2030000"
  },
  {
    "text": "management overhead there is so Athena is fully serverless so you can just hand",
    "start": "2030000",
    "end": "2035559"
  },
  {
    "text": "it to you know all thousand people at your company or however men you have and",
    "start": "2035559",
    "end": "2041320"
  },
  {
    "text": "you know they can use it whenever they wish now there are a subset of those people who need really fast response",
    "start": "2041320",
    "end": "2047039"
  },
  {
    "text": "times and need the you know are writing really complicated queries against",
    "start": "2047039",
    "end": "2052638"
  },
  {
    "text": "really large data in those cases you know you really need something that's going toh be able to process and have",
    "start": "2052639",
    "end": "2060760"
  },
  {
    "text": "you know sort of a commercially production ready query Optimizer and all of the various tricks red shift plays",
    "start": "2060760",
    "end": "2067079"
  },
  {
    "text": "that aren't in atha does that make sense does that make",
    "start": "2067079",
    "end": "2072560"
  },
  {
    "text": "sense so the question was you know just because one server lless it doesn't change my needs does it and I would",
    "start": "2084079",
    "end": "2090280"
  },
  {
    "text": "argue it does right because you might you basically are going to want to put red shift in front of your data analyst",
    "start": "2090280",
    "end": "2095960"
  },
  {
    "text": "not a cren lots and lot of people who do random things on your data you know and so it's you know",
    "start": "2095960",
    "end": "2104880"
  },
  {
    "text": "it's it's a bit more you know you put powerful Tools in front of uh people who you can trust with to use that power and",
    "start": "2104880",
    "end": "2112119"
  },
  {
    "text": "you put you know but you want your data to be accessible to",
    "start": "2112119",
    "end": "2117119"
  },
  {
    "text": "everyone or is it equ could is the Spectrum uses the EMR in the background",
    "start": "2120320",
    "end": "2126240"
  },
  {
    "text": "or no it's that new code so the question was whether Spectrum uses EMR in the background no it's all entirely in that",
    "start": "2126240",
    "end": "2132560"
  },
  {
    "text": "new code and it kind of has to be because uh",
    "start": "2132560",
    "end": "2138400"
  },
  {
    "text": "the um functionality there is actually pretty different because all of the had",
    "start": "2138400",
    "end": "2143920"
  },
  {
    "text": "style functionality does a you know tries to provide the full query and we only want to ship a portion of it and",
    "start": "2143920",
    "end": "2150319"
  },
  {
    "text": "get a portion of the results back um we're doing mapping we're doing reducing we're not doing shuffles if that makes",
    "start": "2150319",
    "end": "2157079"
  },
  {
    "text": "sense so let's take this use case like if you have both aena and Spectra will we have",
    "start": "2157079",
    "end": "2163960"
  },
  {
    "text": "contention on3 when both so the question was will you have contention on S3 if",
    "start": "2163960",
    "end": "2170960"
  },
  {
    "text": "both are uh using Spectrum H or sorry both are both Athena and Spectrum are",
    "start": "2170960",
    "end": "2176319"
  },
  {
    "text": "using S3 I would um so S3 is a regional service it's accessible to a lot of",
    "start": "2176319",
    "end": "2182560"
  },
  {
    "text": "people I think you'd be hard pressed to get uh to overwhelm S3 because you know",
    "start": "2182560",
    "end": "2188440"
  },
  {
    "text": "you basically have a pretty vast number of uh request uh nodes that are",
    "start": "2188440",
    "end": "2195400"
  },
  {
    "text": "processing requests you might end up with hot spots in a particular bucket or",
    "start": "2195400",
    "end": "2200440"
  },
  {
    "text": "something like that but that's really comes down to how you choose to um Place data into buckets which is an important",
    "start": "2200440",
    "end": "2207079"
  },
  {
    "text": "problem but it isn't isolated to Athena or Spectrum or anything like that it's really a question of how much throughput",
    "start": "2207079",
    "end": "2214720"
  },
  {
    "text": "you want to get out of S3 and how to spread that across many uh",
    "start": "2214720",
    "end": "2220920"
  },
  {
    "text": "buckets I have AED cluster but I have a lot",
    "start": "2225319",
    "end": "2230960"
  },
  {
    "text": "of3 scale my yeah so the question was hey I've got",
    "start": "2231880",
    "end": "2238480"
  },
  {
    "text": "a large amount of data in S3 I've got a small red shift cluster um am I going to",
    "start": "2238480",
    "end": "2244119"
  },
  {
    "text": "need to scale red shift up in order to uh be able to work with Spectrum uh so",
    "start": "2244119",
    "end": "2250560"
  },
  {
    "text": "there is a relationship between the size of your red shift cluster and the number",
    "start": "2250560",
    "end": "2255880"
  },
  {
    "text": "of spectrum nodes you can go after but that isn't actually related to the amount of data because what'll happen is",
    "start": "2255880",
    "end": "2261599"
  },
  {
    "text": "we'll basically chunk one passive data then the next pass and the next pass so you could go with a single node if you",
    "start": "2261599",
    "end": "2267240"
  },
  {
    "text": "wanted in that exibit query where we went off against uh 2500 nodes in",
    "start": "2267240",
    "end": "2273520"
  },
  {
    "text": "Spectrum we're using a 20 node 8xl cluster so an 8xl 20 node cluster is",
    "start": "2273520",
    "end": "2280160"
  },
  {
    "text": "basically 160 nodes times 32 cores on each of those nodes so it's not huge but",
    "start": "2280160",
    "end": "2287119"
  },
  {
    "text": "um yeah it's also an exibit you're unlikely to be cing an exibit did the answer makes sense if you",
    "start": "2287119",
    "end": "2294359"
  },
  {
    "text": "want afterwards we can walk you through some of the details question",
    "start": "2294359",
    "end": "2300000"
  },
  {
    "text": "here yes sir uh couple of questions I guess so for the hive comparison did you",
    "start": "2300000",
    "end": "2306520"
  },
  {
    "text": "assume that Hive would didn't do any partition pruning um no I actually assumed Hive",
    "start": "2306520",
    "end": "2313200"
  },
  {
    "text": "did uh lots of pruning I it's just that it Hive has difficulty doing pruning",
    "start": "2313200",
    "end": "2320160"
  },
  {
    "text": "unless it's given an a Rel you know it does dynamic pruning but it does",
    "start": "2320160",
    "end": "2325520"
  },
  {
    "text": "relatively static Dynamic pruning if that makes any sense which I'm sure the answer doesn't but uh you know if you",
    "start": "2325520",
    "end": "2332240"
  },
  {
    "text": "are looking at uh data that's embedded in deep into a join like the one I was doing there where you know you were",
    "start": "2332240",
    "end": "2338680"
  },
  {
    "text": "looking at you know the books by an author the uh first edition books by",
    "start": "2338680",
    "end": "2344520"
  },
  {
    "text": "that author that three joins in and then you're looking for when do those uh what were the dates for those books it's not",
    "start": "2344520",
    "end": "2350839"
  },
  {
    "text": "going to pick that up the only thing it's going to pick up is the regional limitation okay I had a uh different",
    "start": "2350839",
    "end": "2358520"
  },
  {
    "text": "question which is about if joins are not pushed down to S3 there is definitely a",
    "start": "2358520",
    "end": "2363640"
  },
  {
    "text": "relationship between the size of the red shift cluster and whatever queries you can run",
    "start": "2363640",
    "end": "2369880"
  },
  {
    "text": "right so if you if you're trying to like the thing that uh ran out of disc or whatever where I'm trying to do self",
    "start": "2369880",
    "end": "2376119"
  },
  {
    "text": "joints on large tables how would that work yeah so the thing about uh red",
    "start": "2376119",
    "end": "2381480"
  },
  {
    "text": "shift is is that it will at least um run U you know be able to execute something",
    "start": "2381480",
    "end": "2388400"
  },
  {
    "text": "like a hash joint and with a spill to dis on it right which a lot of the Hadoop Frameworks start to falter on",
    "start": "2388400",
    "end": "2395440"
  },
  {
    "text": "including Hive and in particular if you can't fill um the left side of a hash",
    "start": "2395440",
    "end": "2402599"
  },
  {
    "text": "join into memory it actually has a lot of challenges and so the reason we uh",
    "start": "2402599",
    "end": "2407800"
  },
  {
    "text": "ran this against a small data set uh was I mean 1 and a half terabytes is not",
    "start": "2407800",
    "end": "2413960"
  },
  {
    "text": "actually a very small data set but the reason we had to do that is that anything larger run out of",
    "start": "2413960",
    "end": "2419720"
  },
  {
    "text": "memory on the joint all right",
    "start": "2419720",
    "end": "2425920"
  },
  {
    "text": "thanks happy to look at other data if you have it I have a quick one can I use",
    "start": "2425920",
    "end": "2431920"
  },
  {
    "text": "user defined functions uh with this data in S3 so the question was can you use",
    "start": "2431920",
    "end": "2438079"
  },
  {
    "text": "the user defined functions with the data in S3 not at this",
    "start": "2438079",
    "end": "2443000"
  },
  {
    "text": "time so assume that uh we have large amount of Json semistructured data yeah",
    "start": "2444920",
    "end": "2452119"
  },
  {
    "text": "and would it be better to put the data inside the red shift and uh query or",
    "start": "2452119",
    "end": "2459119"
  },
  {
    "text": "have it in S3 and use Spectrum to query it which one would be a faster and a",
    "start": "2459119",
    "end": "2464640"
  },
  {
    "text": "better one so uh the question was about uh how to manage uh semi-structured data formats like Json or for that matter XML",
    "start": "2464640",
    "end": "2472200"
  },
  {
    "text": "Etc so as of now red shift has uh limitations in its uh ability to support",
    "start": "2472200",
    "end": "2479119"
  },
  {
    "text": "uh Json with particularly Json which is uh got uh hierarchical structure in it",
    "start": "2479119",
    "end": "2486160"
  },
  {
    "text": "and so those uh constraints uh continue to fall over into uh uh Spectrum uh",
    "start": "2486160",
    "end": "2492400"
  },
  {
    "text": "because you can't express it uh intelligently so it's something that we're looking at very hard and I'd",
    "start": "2492400",
    "end": "2498960"
  },
  {
    "text": "encourage you to talk with uh the red shift team afterwards on your specific",
    "start": "2498960",
    "end": "2505400"
  },
  {
    "text": "needs so this question is I don't know if it's available with the first release or it's more of a road map thing but as",
    "start": "2505760",
    "end": "2514280"
  },
  {
    "text": "part of the information life cycle management right so is this something thing um you guys are thinking of uh",
    "start": "2514280",
    "end": "2520720"
  },
  {
    "text": "having the hot data which is more frequently used in the red shift and pushing the historical archival data on",
    "start": "2520720",
    "end": "2528280"
  },
  {
    "text": "uh Spectrum yeah that would uh certainly make a lot of sense and would certainly make a lot of sense for us to um help",
    "start": "2528280",
    "end": "2535720"
  },
  {
    "text": "automate and administer that for you so uh that is something we're thinking about quite hard uh it's again not",
    "start": "2535720",
    "end": "2543200"
  },
  {
    "text": "something that we have uh today one thing I'd point out there is is that for",
    "start": "2543200",
    "end": "2549520"
  },
  {
    "text": "your very hottest data you're probably likely to end up with it an S3 because",
    "start": "2549520",
    "end": "2555240"
  },
  {
    "text": "it's very easy to take a kesa stream or a Kafka stream and just deposit a file into S3 whereas you're going to need to",
    "start": "2555240",
    "end": "2562280"
  },
  {
    "text": "microbatch it into red shift so it's almost you know like red hot data is",
    "start": "2562280",
    "end": "2568040"
  },
  {
    "text": "going to end up in S3 all your everyday data is going to end up in red shift and",
    "start": "2568040",
    "end": "2573079"
  },
  {
    "text": "then maybe past a couple of weeks or something past that yeah I was thinking data from the consumption perspective",
    "start": "2573079",
    "end": "2579319"
  },
  {
    "text": "not the ingestion it it all actually depends on what you want to consume right um so like for example let's say",
    "start": "2579319",
    "end": "2585480"
  },
  {
    "text": "you were taking sensor data off of your instances and you were running something like AWS there are times that you're",
    "start": "2585480",
    "end": "2592400"
  },
  {
    "text": "interested in what's happening right this second right and there most of the time you're not you're interested in",
    "start": "2592400",
    "end": "2598000"
  },
  {
    "text": "doing an analytic query over a few weeks and rarely you're interested in trying",
    "start": "2598000",
    "end": "2603240"
  },
  {
    "text": "to do a longitudinal analysis over months or years mhm yeah so one followup",
    "start": "2603240",
    "end": "2609319"
  },
  {
    "text": "uh additional question U uh I'm presuming that it doesn't support",
    "start": "2609319",
    "end": "2615079"
  },
  {
    "text": "secondary indexes uh in the Spectrum uh is that true or that I mean",
    "start": "2615079",
    "end": "2622160"
  },
  {
    "text": "basically we're using open uh data formats which means that you know like something like par you can choose to",
    "start": "2622160",
    "end": "2627880"
  },
  {
    "text": "sort right and you can choose of course to uh have partitioning either on the",
    "start": "2627880",
    "end": "2633000"
  },
  {
    "text": "sort key or on some other key okay and so you can do something like that for sure right and uh you know beyond that",
    "start": "2633000",
    "end": "2640520"
  },
  {
    "text": "you know if you think about it in um analytic environments indices end up",
    "start": "2640520",
    "end": "2646480"
  },
  {
    "text": "being approximately as big or bigger than the base tables and so it sometimes",
    "start": "2646480",
    "end": "2652000"
  },
  {
    "text": "is better just to make them be actually a Flatout copy of the table okay but from the data distribution point of view",
    "start": "2652000",
    "end": "2658720"
  },
  {
    "text": "the optimizer statistics is it like similar whatever uh extensive statistics",
    "start": "2658720",
    "end": "2664440"
  },
  {
    "text": "you get you store uh for the standard red shift is it the same for spectrum or",
    "start": "2664440",
    "end": "2670960"
  },
  {
    "text": "so as of now we don't have the the complete set of Statistics in particular around distribution the things we",
    "start": "2670960",
    "end": "2678119"
  },
  {
    "text": "understand well are the size of the files the number of files things of that nature um you know certainly that'll",
    "start": "2678119",
    "end": "2686319"
  },
  {
    "text": "come one of the things we're looking at is is that I don't know if you're on reinvent I did a talk on glue there and",
    "start": "2686319",
    "end": "2692839"
  },
  {
    "text": "one of the things that comes with glue is a crawling of your uh S three buckets in order to generate a data catalog and",
    "start": "2692839",
    "end": "2700480"
  },
  {
    "text": "you could imagine that once that's out it would make sense for us to generate statistics through that as well all",
    "start": "2700480",
    "end": "2707319"
  },
  {
    "text": "right thank you",
    "start": "2707319",
    "end": "2712359"
  },
  {
    "text": "Mr so the question was whether the $5 per terabyte is the S3 scanning or",
    "start": "2718880",
    "end": "2725760"
  },
  {
    "text": "inclusive of the red shift cluster it's just the red shift uh it's just the scanning so you're going to basically",
    "start": "2725760",
    "end": "2732079"
  },
  {
    "text": "pay for your query your spectrum query and you pay you know the cost of your red shift cluster which you might be",
    "start": "2732079",
    "end": "2738000"
  },
  {
    "text": "able to downsize at this point if your you know cluster is sized to storage rather than",
    "start": "2738000",
    "end": "2744040"
  },
  {
    "text": "compute right but uh it all depends on how much you're actively using it but you know while it's up you know the",
    "start": "2744040",
    "end": "2750160"
  },
  {
    "text": "instan is uh you know consuming resources so that means uh also um uh",
    "start": "2750160",
    "end": "2757680"
  },
  {
    "text": "number of nodes the Spectrum users depends upon your red safety cluster the",
    "start": "2757680",
    "end": "2763040"
  },
  {
    "text": "maximum number of nodes uh depends but not the uh typically uh used number",
    "start": "2763040",
    "end": "2772078"
  },
  {
    "text": "okay I'm sorry I couldn't hear you so the question was are there any",
    "start": "2774440",
    "end": "2780520"
  },
  {
    "text": "limitations on joins or what have you no because we pull that processing upwards",
    "start": "2780520",
    "end": "2786160"
  },
  {
    "text": "into red shift so the limitations are those of red shift",
    "start": "2786160",
    "end": "2792640"
  },
  {
    "text": "right use",
    "start": "2812119",
    "end": "2816119"
  },
  {
    "text": "I think uh to answer that question properly I'll need to understand your workload a little bit better so maybe",
    "start": "2825960",
    "end": "2831960"
  },
  {
    "text": "the sorry the question was should I use dense compute or dense storage with spectrum and really the difference",
    "start": "2831960",
    "end": "2838800"
  },
  {
    "text": "between the two uh comes down to the amount of storage you have uh you know",
    "start": "2838800",
    "end": "2844720"
  },
  {
    "text": "the um CPUs are similar the uh networking is similar the U and the",
    "start": "2844720",
    "end": "2851800"
  },
  {
    "text": "memory is similar and so it really uh is a question of understanding your data",
    "start": "2851800",
    "end": "2857839"
  },
  {
    "text": "set and your workload and figuring out uh what makes better more sense for you",
    "start": "2857839",
    "end": "2862880"
  },
  {
    "text": "and I'm happy to give you a card and talk to you in some detail about that but uh that's probably an offline",
    "start": "2862880",
    "end": "2868119"
  },
  {
    "text": "conversation",
    "start": "2868119",
    "end": "2871119"
  },
  {
    "text": "so um hey uh ocus can you uh remind me again what the",
    "start": "2879800",
    "end": "2886280"
  },
  {
    "text": "maximum number of spectrum nodes you can access from a core is 10 slice 10 per",
    "start": "2886280",
    "end": "2892280"
  },
  {
    "text": "slice okay so for excuse me so it's basically you can",
    "start": "2892280",
    "end": "2898079"
  },
  {
    "text": "concurrently access uh 10 Spectrum nodes per core in U per red shift node so in",
    "start": "2898079",
    "end": "2906280"
  },
  {
    "text": "the case that I was describing earlier in our demo where we were using 20 uh",
    "start": "2906280",
    "end": "2912760"
  },
  {
    "text": "dc18 XL so there are 32 cores on each of them so you can just multiply that out",
    "start": "2912760",
    "end": "2918760"
  },
  {
    "text": "it's 20 * U 32 * 10 it would be the maximum we're actually well under the",
    "start": "2918760",
    "end": "2924359"
  },
  {
    "text": "maximum in this case's the reason for that is so the question",
    "start": "2924359",
    "end": "2931960"
  },
  {
    "text": "was what's the reason for that it's really just networking so uh what it uh really you come down to in all of these",
    "start": "2931960",
    "end": "2938720"
  },
  {
    "text": "things is that uh networking is the core constraint in data once data is placed",
    "start": "2938720",
    "end": "2945880"
  },
  {
    "text": "away from the instance itself and that's actually why red shift uses local diss because the highest throughput option",
    "start": "2945880",
    "end": "2953559"
  },
  {
    "text": "available is local diss right that's PCI based access to uh your controllers and",
    "start": "2953559",
    "end": "2961400"
  },
  {
    "text": "U so uh given that that's the primary constraint then the next thing you look",
    "start": "2961400",
    "end": "2966599"
  },
  {
    "text": "at at is shuffles for joins and things like that and so that argues for having",
    "start": "2966599",
    "end": "2971960"
  },
  {
    "text": "more powerful machines and fewer of them for joints right because uh or",
    "start": "2971960",
    "end": "2978200"
  },
  {
    "text": "collocating your joints as best possible and so then beyond that when you're going to data in S3 you want to pull a",
    "start": "2978200",
    "end": "2984760"
  },
  {
    "text": "lot of channels and the way you pull a lot of channels is you throw a lot of hardware at it right and uh so you know",
    "start": "2984760",
    "end": "2991960"
  },
  {
    "text": "that's why we go to a large number of nodes in Spectrum even from a small smaller much smaller number of uh nodes",
    "start": "2991960",
    "end": "2999880"
  },
  {
    "text": "um in red shift uh so that we can pull down a lot of data in parallel from uh",
    "start": "2999880",
    "end": "3006160"
  },
  {
    "text": "S3 and then do the you know basically the Restriction there whether that's",
    "start": "3006160",
    "end": "3011760"
  },
  {
    "text": "projections or it's uh know filters or whatever it is partial",
    "start": "3011760",
    "end": "3018599"
  },
  {
    "text": "aggregations um what node type is used for spectrum was the question so you",
    "start": "3020599",
    "end": "3025880"
  },
  {
    "text": "we're not getting into that mostly because you know we want to be able to change it and there's but the uh the",
    "start": "3025880",
    "end": "3033119"
  },
  {
    "text": "Crux of the issue is how do you balance um compute memory and",
    "start": "3033119",
    "end": "3041000"
  },
  {
    "text": "network right and so and obviously cost right and so U you know so like you guys",
    "start": "3041000",
    "end": "3049520"
  },
  {
    "text": "we have our choice of a variety of ec2 instances and U we ended up picking one",
    "start": "3049520",
    "end": "3057920"
  },
  {
    "text": "and you know we actually go back and forth on it too so even in the last month we've gone back and forth on",
    "start": "3057920",
    "end": "3065798"
  },
  {
    "text": "it any other questions okay thank you so much for your time",
    "start": "3066200",
    "end": "3072280"
  },
  {
    "text": "[Applause]",
    "start": "3072280",
    "end": "3075709"
  }
]
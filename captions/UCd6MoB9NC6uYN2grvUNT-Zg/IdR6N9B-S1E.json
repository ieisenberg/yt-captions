[
  {
    "text": "hi everyone Sarang good morning welcome",
    "start": "260",
    "end": "6750"
  },
  {
    "text": "to my talk thanks for coming I'm so glad you are here can everybody hear me too high too",
    "start": "6750",
    "end": "14040"
  },
  {
    "text": "low so now imagine it's Friday night of",
    "start": "14040",
    "end": "21210"
  },
  {
    "text": "this week the conference is over you're back at your home ready to relax sitting",
    "start": "21210",
    "end": "28410"
  },
  {
    "text": "on your favorite couch and you start Netflix at least I hope you do so this",
    "start": "28410",
    "end": "36750"
  },
  {
    "text": "is the first screen that you see when you start Netflix the interesting thing",
    "start": "36750",
    "end": "42510"
  },
  {
    "text": "about this screen is it's not Universal or static it's customized to your taste",
    "start": "42510",
    "end": "51289"
  },
  {
    "text": "there are 135 million versions of this screen one for each of our 135 million",
    "start": "51289",
    "end": "58230"
  },
  {
    "text": "customers but this one is mine personalized to my tastes",
    "start": "58230",
    "end": "63359"
  },
  {
    "text": "I do understand it's just filled with crime shows but let's not read anything specific into that moving on so please",
    "start": "63359",
    "end": "74369"
  },
  {
    "text": "raise your hand if you start watch something watching something anything we",
    "start": "74369",
    "end": "79409"
  },
  {
    "text": "didn't say a minute or two after landing in that screen yeah me neither",
    "start": "79409",
    "end": "85520"
  },
  {
    "text": "that's very generalized experience we do spend most of us do spend significant",
    "start": "85520",
    "end": "92220"
  },
  {
    "text": "amount of crime scrolling browsing on that screen trying to pick something to watch and that behavior is actually",
    "start": "92220",
    "end": "100079"
  },
  {
    "text": "relevant to our talk today let's say it's 20 minutes later and you are still",
    "start": "100079",
    "end": "105899"
  },
  {
    "text": "on that screen happens right has happened to me meanwhile our",
    "start": "105899",
    "end": "111560"
  },
  {
    "text": "personalization algorithm are continuously running in cloud so in",
    "start": "111560",
    "end": "116850"
  },
  {
    "text": "those 20 minutes we could have generated a more personalized better fresher",
    "start": "116850",
    "end": "122880"
  },
  {
    "text": "recommendation list for you and if that will happen the question is how do we",
    "start": "122880",
    "end": "129899"
  },
  {
    "text": "get that list in front of you as soon as it's ready how do we let our",
    "start": "129899",
    "end": "135000"
  },
  {
    "text": "application know that a new better recommendation list is ready for it to download in the cloud after the",
    "start": "135000",
    "end": "142470"
  },
  {
    "text": "application has started and rendered that screen push messaging is a perfect",
    "start": "142470",
    "end": "147810"
  },
  {
    "text": "solution for this our older application earlier version used to poll our servers",
    "start": "147810",
    "end": "155459"
  },
  {
    "text": "periodically to see if there are recommendations available that kind of",
    "start": "155459",
    "end": "160709"
  },
  {
    "text": "worked but it was built wasteful and not",
    "start": "160709",
    "end": "166530"
  },
  {
    "text": "that great delivery latency wise what was worst is this two twin goals of",
    "start": "166530",
    "end": "173510"
  },
  {
    "text": "server efficiency and UI freshness were",
    "start": "173510",
    "end": "178799"
  },
  {
    "text": "in direct contradiction with each other if you decrease your polling interval to",
    "start": "178799",
    "end": "184349"
  },
  {
    "text": "get the freshest possible UI you are going to put more loads on your server because you're gonna pull them",
    "start": "184349",
    "end": "189510"
  },
  {
    "text": "frequently and if you decrease the frequency to give some breathing room to your servers here you have freshness",
    "start": "189510",
    "end": "196410"
  },
  {
    "text": "surface now with push messaging our servers just push the new recommendation",
    "start": "196410",
    "end": "202980"
  },
  {
    "text": "list to the client whenever it's ready just as one data point we cut down our",
    "start": "202980",
    "end": "210690"
  },
  {
    "text": "request to our website cluster by 12% when we move our in browser app from",
    "start": "210690",
    "end": "219569"
  },
  {
    "text": "polling to push at more than two million requests per second those 12% add up",
    "start": "219569",
    "end": "226290"
  },
  {
    "text": "really fast so please ignore all push notifications on your mobile for the",
    "start": "226290",
    "end": "232199"
  },
  {
    "text": "next 45 minutes because we are gonna talk about push messaging push notifications are terrible for",
    "start": "232199",
    "end": "238109"
  },
  {
    "text": "conference speakers but background push messages are awesome for applications by",
    "start": "238109",
    "end": "245190"
  },
  {
    "text": "the end of this presentation you would have a very good idea of what is push",
    "start": "245190",
    "end": "250790"
  },
  {
    "text": "how you can build it how you can operate it and what can you do with it",
    "start": "250790",
    "end": "258660"
  },
  {
    "text": "my name is Sushil our Oscar I'm a software engineer at Netflix cloud get",
    "start": "258660",
    "end": "265060"
  },
  {
    "text": "to a team all of the HTTP API traffic that enters our system or our ecosystem",
    "start": "265060",
    "end": "271270"
  },
  {
    "text": "passes through our cloud gateway I have been in at Netflix at around nine years",
    "start": "271270",
    "end": "277690"
  },
  {
    "text": "now working three different teams and still somehow I feel like I'm still just",
    "start": "277690",
    "end": "283419"
  },
  {
    "text": "browsing the list the real show is about to start so let's start with defining what is push and how is it different",
    "start": "283419",
    "end": "291789"
  },
  {
    "text": "from the normal requests response paradigm that we all know and love this",
    "start": "291789",
    "end": "300070"
  },
  {
    "text": "is actually a motivational poster in my local gym so that's why I stopped going there but it this is surprisingly",
    "start": "300070",
    "end": "310360"
  },
  {
    "text": "accurate for our purposes today the definition push is really different in just two ways a there is a persistent",
    "start": "310360",
    "end": "318180"
  },
  {
    "text": "always-on long-lived connection between the client and the server that lasts for",
    "start": "318180",
    "end": "324340"
  },
  {
    "text": "the entirety of the clients lifetime and be the it's the server that initiates",
    "start": "324340",
    "end": "332409"
  },
  {
    "text": "the data transfer something does it really happen on server and then the server pushes the data to the client instead of client requesting it which is",
    "start": "332409",
    "end": "340060"
  },
  {
    "text": "what we are used to we build our own",
    "start": "340060",
    "end": "345759"
  },
  {
    "text": "push messaging system called Zul push to send those background push messages to",
    "start": "345759",
    "end": "351070"
  },
  {
    "text": "our client from our service dual push messages are very similar to the push",
    "start": "351070",
    "end": "357340"
  },
  {
    "text": "notifications or push messages that you get on your mobile except they work",
    "start": "357340",
    "end": "362770"
  },
  {
    "text": "everywhere across all devices wherever our Netflix application notes and that",
    "start": "362770",
    "end": "369610"
  },
  {
    "text": "includes laptops TVs game consoles blu-ray DVD players and mobile to",
    "start": "369610",
    "end": "377710"
  },
  {
    "text": "achieve this cross-platform fit push message azul push messaging users open",
    "start": "377710",
    "end": "385030"
  },
  {
    "text": "and standard web protocols like WebSockets and serve a sentiment the",
    "start": "385030",
    "end": "390130"
  },
  {
    "text": "dual push server it self is open-source to and saleable on github today dual push is not a single",
    "start": "390130",
    "end": "400120"
  },
  {
    "text": "service it's in fact a complete push messaging infrastructure made up of",
    "start": "400120",
    "end": "405220"
  },
  {
    "text": "multiple components first and foremost there are dual push servers they sit on",
    "start": "405220",
    "end": "413020"
  },
  {
    "text": "the network edge and accept incoming connections from clients clients connect",
    "start": "413020",
    "end": "419949"
  },
  {
    "text": "to this will push servers using protocols like web sockets or sse and",
    "start": "419949",
    "end": "426180"
  },
  {
    "text": "once they open that connection they hang on to it for their entire lifetime so these are persistent connections now",
    "start": "426180",
    "end": "434979"
  },
  {
    "text": "because there are multiple clients connected to multiples will push servers we need to keep track of which client is",
    "start": "434979",
    "end": "443710"
  },
  {
    "text": "connected to which zone which server and that's the job of push register on the",
    "start": "443710",
    "end": "452740"
  },
  {
    "text": "backend our push message senders which are our back-end services need a simple",
    "start": "452740",
    "end": "458650"
  },
  {
    "text": "yet robust and high throughput mechanism to send push messages to our client but",
    "start": "458650",
    "end": "465340"
  },
  {
    "text": "our applications don't want to know all these complex details of internal infrastructure what they ideally want is",
    "start": "465340",
    "end": "471940"
  },
  {
    "text": "a single simple one-liner call that lets them push a message to any client given",
    "start": "471940",
    "end": "479020"
  },
  {
    "text": "its ID our sole push library provides them this simple interface by hiding all",
    "start": "479020",
    "end": "485860"
  },
  {
    "text": "these infrastructural details behind a single send message call in internally",
    "start": "485860",
    "end": "494860"
  },
  {
    "text": "send message called takes this message and drops it into Zul push message queue",
    "start": "494860",
    "end": "501659"
  },
  {
    "text": "we use message queue to decouple our push message senders from our push message receivers because it makes it",
    "start": "501659",
    "end": "507969"
  },
  {
    "text": "easy for us to operate them independently and scale them independently also these push queues act",
    "start": "507969",
    "end": "517060"
  },
  {
    "text": "like a buffer they absorb the sudden spike in incoming messages and the let",
    "start": "517060",
    "end": "523510"
  },
  {
    "text": "us withstand where I variation in incoming traffic finally message",
    "start": "523510",
    "end": "532269"
  },
  {
    "text": "processor is the component that ties all of these components together to do that",
    "start": "532269",
    "end": "537309"
  },
  {
    "text": "shall push message delivery it reads some push message from a",
    "start": "537309",
    "end": "542620"
  },
  {
    "text": "message queue it then looks up each push message is addressed to a particular",
    "start": "542620",
    "end": "548259"
  },
  {
    "text": "push client either by customer ID or device ID or a combination of the two it",
    "start": "548259",
    "end": "554079"
  },
  {
    "text": "then looks up that push address in push on history there are two possibilities here either it finds a dual push server",
    "start": "554079",
    "end": "561910"
  },
  {
    "text": "instance IP map to that push address or it doesn't if it finds as well push",
    "start": "561910",
    "end": "567879"
  },
  {
    "text": "server instance which means that but where push client is connected to Dad's",
    "start": "567879",
    "end": "572980"
  },
  {
    "text": "will push server in that case it just directly connects to that dual push",
    "start": "572980",
    "end": "579279"
  },
  {
    "text": "server and delivers the message to that dual push server that will push servers",
    "start": "579279",
    "end": "584860"
  },
  {
    "text": "is guaranteed to have an open connection to the push client and it can send that message down the port it uses to connect",
    "start": "584860",
    "end": "593800"
  },
  {
    "text": "to the push server is available only on 10/20 for internal network and is",
    "start": "593800",
    "end": "600759"
  },
  {
    "text": "guarded by Amazon security groups for obvious reasons you don't want anyone to push messages to your clouds sorry",
    "start": "600759",
    "end": "611379"
  },
  {
    "text": "second private possibility is it doesn't find that clients push address in the",
    "start": "611379",
    "end": "618910"
  },
  {
    "text": "registry it just means that client is not connected or online at that time so",
    "start": "618910",
    "end": "625769"
  },
  {
    "text": "in that case push processor message processor will drop that push message on the flow these are best delivery efforts",
    "start": "625769",
    "end": "634600"
  },
  {
    "text": "not guaranteed delivery now that we have seen how all these push components act",
    "start": "634600",
    "end": "641620"
  },
  {
    "text": "together work together we can dig a little deeper into some of them dual",
    "start": "641620",
    "end": "650050"
  },
  {
    "text": "push server is probably the biggest piece of this whole infrastructure",
    "start": "650050",
    "end": "656009"
  },
  {
    "text": "we'll push cluster in aggregate today handles more than 14 million concurrent",
    "start": "656170",
    "end": "661480"
  },
  {
    "text": "connections at its peak and it's rapidly growing Zul push server is based on our",
    "start": "661480",
    "end": "668649"
  },
  {
    "text": "tool cloud getaway and hence shares its name dual it's a obscure Ghostbusters reference by",
    "start": "668649",
    "end": "675490"
  },
  {
    "text": "the way dual push cloud gateways the one that fronts all",
    "start": "675490",
    "end": "681310"
  },
  {
    "text": "our back-end services and act as the worst proxy plus load balancer plus application gateway it handles millions",
    "start": "681310",
    "end": "688149"
  },
  {
    "text": "of requests per second and it was rewritten recently from ground up to use",
    "start": "688149",
    "end": "694110"
  },
  {
    "text": "non-blocking the sync I so it provided a perfect foundation on which to build or",
    "start": "694110",
    "end": "701170"
  },
  {
    "text": "massively scalable which server which begs the question why do we need a sync",
    "start": "701170",
    "end": "708910"
  },
  {
    "text": "io why normal I wasn't good enough many of you are probably familiar with the",
    "start": "708910",
    "end": "714370"
  },
  {
    "text": "term c 10k challenge the term and the challenge was originally coined in 1999",
    "start": "714370",
    "end": "720519"
  },
  {
    "text": "i believe and it simply states to for wave to be scalable and efficient we",
    "start": "720519",
    "end": "727029"
  },
  {
    "text": "have to be able to handle at least 10,000 concurrent connection at the same",
    "start": "727029",
    "end": "733630"
  },
  {
    "text": "time on a single server this cap of",
    "start": "733630",
    "end": "739510"
  },
  {
    "text": "course the as a time passes we have long since blown past the initial 10,000",
    "start": "739510",
    "end": "744550"
  },
  {
    "text": "number but the name kind of stuck this capability to handle thousands and",
    "start": "744550",
    "end": "751209"
  },
  {
    "text": "thousands of open connection on a single server cheaply and efficiently it's critical for something like Zul push",
    "start": "751209",
    "end": "757779"
  },
  {
    "text": "server which has to handle all these always-on persistent connections millions of them in aggregate the normal",
    "start": "757779",
    "end": "769360"
  },
  {
    "text": "traditional way of handling simultaneous connections in a single process would be",
    "start": "769360",
    "end": "774430"
  },
  {
    "text": "to spawn a new thread for each incoming connection and then that tread can do",
    "start": "774430",
    "end": "779910"
  },
  {
    "text": "blocking read/write operations on that connection it makes up for a very simple",
    "start": "779910",
    "end": "786279"
  },
  {
    "text": "programming model but it doesn't scale too meet sit and case challenge mainly",
    "start": "786279",
    "end": "792860"
  },
  {
    "text": "because you would quickly exhaust your service memory or locating 10030 stats",
    "start": "792860",
    "end": "800089"
  },
  {
    "text": "for those 10,000 tears you're also most likely when your CPU goes down doing",
    "start": "800089",
    "end": "808519"
  },
  {
    "text": "constant context switches between those 10,000 threads so it doesn't scale I",
    "start": "808519",
    "end": "815709"
  },
  {
    "text": "think I who follows a little different model it uses operating system provided",
    "start": "815829",
    "end": "822939"
  },
  {
    "text": "IO multiplexing primitives like KQ or e pole or iocp if you are on Windows to",
    "start": "822939",
    "end": "830509"
  },
  {
    "text": "register read and write callbacks for all the fun connections using a single",
    "start": "830509",
    "end": "835670"
  },
  {
    "text": "thread then onwards any socket or a connection that's ready to I you will",
    "start": "835670",
    "end": "841519"
  },
  {
    "text": "have its ioq rewrite callback invoked using the same single thread so now you",
    "start": "841519",
    "end": "847970"
  },
  {
    "text": "don't need thousands and thousands of threads to handle as many connections",
    "start": "847970",
    "end": "853089"
  },
  {
    "text": "there's a flipside now your application program gets complicated because you are",
    "start": "853089",
    "end": "859420"
  },
  {
    "text": "sharing the single thread you cannot use that thread stack to keep any kind of",
    "start": "859420",
    "end": "867410"
  },
  {
    "text": "state which basically translates you cannot use local variables to keep your state you have to maintain all the state",
    "start": "867410",
    "end": "874009"
  },
  {
    "text": "yourself inside your application program and the typical way of doing it is some kind of a finite state machine so it",
    "start": "874009",
    "end": "880790"
  },
  {
    "text": "does make your program a little more complicated than a normal threaded program we use nettie to do a sync i/o",
    "start": "880790",
    "end": "889519"
  },
  {
    "text": "in Zhu Nettie is this awesome osa open source java library that is being used",
    "start": "889519",
    "end": "897740"
  },
  {
    "text": "by many many popular open source projects like Cassandra and her root so",
    "start": "897740",
    "end": "903860"
  },
  {
    "text": "it's quite very tested and battle-proven they're not going to go into the details",
    "start": "903860",
    "end": "909319"
  },
  {
    "text": "of Nettie programming in this now because topic unto itself but this is to give you abstract from 10,000 feet kind",
    "start": "909319",
    "end": "918980"
  },
  {
    "text": "of view of how a typical Nettie program structure looks those channel inbound and outbound",
    "start": "918980",
    "end": "925430"
  },
  {
    "text": "handlers that you see here are analogous to read and write callbacks that we just",
    "start": "925430",
    "end": "933110"
  },
  {
    "text": "discussed and for example it's very similar in a sense to how not no dodges",
    "start": "933110",
    "end": "939470"
  },
  {
    "text": "for example handles many many connections using a single process and no threats and if you are familiar with",
    "start": "939470",
    "end": "947600"
  },
  {
    "text": "node.js internals you can think of neti as libuv counterpart in the JVM world so",
    "start": "947600",
    "end": "958910"
  },
  {
    "text": "this is a overly simplified depiction of how our Zul push servers native pipeline",
    "start": "958910",
    "end": "964160"
  },
  {
    "text": "looks like even after simplification there are a lot of things going on here but I just want to draw your attention",
    "start": "964160",
    "end": "970879"
  },
  {
    "text": "to really just two things the two highlighted cards get push off Handler and get Porsche registration angular you",
    "start": "970879",
    "end": "980629"
  },
  {
    "text": "can use you can override or extend these calls to plug-in your own custom art and",
    "start": "980629",
    "end": "987250"
  },
  {
    "text": "custom push registration mechanism inside Zul pushed our besides these",
    "start": "987250",
    "end": "995720"
  },
  {
    "text": "calls everything else that you see here HTTP server codec WebSocket server protocol handler all of these are of the",
    "start": "995720",
    "end": "1003100"
  },
  {
    "text": "shelf nettie components or parcels which is great which means nettie is really doing all of the heavy",
    "start": "1003100",
    "end": "1010360"
  },
  {
    "text": "lifting here any client that connects to",
    "start": "1010360",
    "end": "1016629"
  },
  {
    "text": "this will push server has to first identify and authenticate itself before",
    "start": "1016629",
    "end": "1021730"
  },
  {
    "text": "it can start receiving push messages on that connection will let you customize this authentication to suit your need",
    "start": "1021730",
    "end": "1028798"
  },
  {
    "text": "you can extend our push off Handler the",
    "start": "1028799",
    "end": "1034750"
  },
  {
    "text": "best class that we provide and implement its do auto method to do your custom",
    "start": "1034750",
    "end": "1040030"
  },
  {
    "text": "authentication the Duat method receives the original WebSocket connect request",
    "start": "1040030",
    "end": "1045250"
  },
  {
    "text": "as one of its argument so you have full access to all the HTTP headers cookies",
    "start": "1045250",
    "end": "1052360"
  },
  {
    "text": "and request bodies and things like that to do your custom authentication inside that method as we saw push registry is the",
    "start": "1052360",
    "end": "1064870"
  },
  {
    "text": "component that keeps track of which push client is connected to which which server and just as we let you plug in",
    "start": "1064870",
    "end": "1073120"
  },
  {
    "text": "your own custom authentication inside you'll push will let you plug in your",
    "start": "1073120",
    "end": "1078279"
  },
  {
    "text": "data store of your choice as a push registry inside will push the way to do",
    "start": "1078279",
    "end": "1084039"
  },
  {
    "text": "that is to again extend our another base class push registration handler and",
    "start": "1084039",
    "end": "1089649"
  },
  {
    "text": "implement its do register method example",
    "start": "1089649",
    "end": "1094720"
  },
  {
    "text": "here and sorry register client emitter example here is using radius as a",
    "start": "1094720",
    "end": "1101110"
  },
  {
    "text": "backing store for the push register so",
    "start": "1101110",
    "end": "1106389"
  },
  {
    "text": "you can use any data store of your liking still it should have some desired",
    "start": "1106389",
    "end": "1112779"
  },
  {
    "text": "characteristics there is a wish list of the song to get the best possible result it should have low ready latency this is",
    "start": "1112779",
    "end": "1121779"
  },
  {
    "text": "because you write the push registration record really comparatively only once when the client first connects to the",
    "start": "1121779",
    "end": "1129159"
  },
  {
    "text": "push server but you look it up multiple times every time anyone is trying to",
    "start": "1129159",
    "end": "1134710"
  },
  {
    "text": "send a push message to this client so you should prioritize lower latency over",
    "start": "1134710",
    "end": "1144009"
  },
  {
    "text": "low right latency or write throughput the data store should also support some",
    "start": "1144009",
    "end": "1151299"
  },
  {
    "text": "sort of record level TTL or automatic record expires because hole push depends",
    "start": "1151299",
    "end": "1157240"
  },
  {
    "text": "on this data store feature to get rid of phantom stale registration records when",
    "start": "1157240",
    "end": "1163990"
  },
  {
    "text": "the push client cleanly terminates its connection it doesn't shake and says I'm going away our pushes through push",
    "start": "1163990",
    "end": "1171879"
  },
  {
    "text": "server would take care of deleting its push registration from push registry but",
    "start": "1171879",
    "end": "1178090"
  },
  {
    "text": "you cannot rely on every single client cleanly terminating its collection every",
    "start": "1178090",
    "end": "1184509"
  },
  {
    "text": "single time sometimes clients crash sometimes you say oh my crash any of that happening will leave behind",
    "start": "1184509",
    "end": "1192000"
  },
  {
    "text": "inaccurate stale record that we call a phantom registration record inside your push registry and soul push relies on",
    "start": "1192000",
    "end": "1199830"
  },
  {
    "text": "TTL record liability to purge those records automatically besides these two",
    "start": "1199830",
    "end": "1207760"
  },
  {
    "text": "critical features then there are usual suspects for high availability like shouting and replication for fault",
    "start": "1207760",
    "end": "1217630"
  },
  {
    "text": "tolerance given these wish Lee against wish list",
    "start": "1217630",
    "end": "1223540"
  },
  {
    "text": "any of these would be a great choice for your push registry there are probably",
    "start": "1223540",
    "end": "1230410"
  },
  {
    "text": "several more what we use inside Netflix is dynamite",
    "start": "1230410",
    "end": "1236640"
  },
  {
    "text": "it's another open source project from Netflix it takes readies and it meant",
    "start": "1236640",
    "end": "1243880"
  },
  {
    "text": "sit with high availability features like readwrite quorum automatic sharding and crossorigin replication across AWS",
    "start": "1243880",
    "end": "1251920"
  },
  {
    "text": "regions we settled on dynamite for primarily two reasons",
    "start": "1251920",
    "end": "1257410"
  },
  {
    "text": "it has out of box support for cross AWS region replication which is critical in",
    "start": "1257410",
    "end": "1263440"
  },
  {
    "text": "our use case we'll see soon of why and being a project developed inside Netflix",
    "start": "1263440",
    "end": "1269800"
  },
  {
    "text": "it has a top tier one a support available inside Netflix there is a central operation team that manages and",
    "start": "1269800",
    "end": "1276790"
  },
  {
    "text": "monitors and backs up all our animate cluster so it's no brainer for us to rely on their expertise to operate these",
    "start": "1276790",
    "end": "1285010"
  },
  {
    "text": "clusters we almost get it for free",
    "start": "1285010",
    "end": "1289110"
  },
  {
    "text": "finally message processing is a component that handles back-end Message Queuing routing and delivery on behalf",
    "start": "1290550",
    "end": "1298630"
  },
  {
    "text": "of our push message senders we use Kafka",
    "start": "1298630",
    "end": "1304060"
  },
  {
    "text": "message queues for our push message queues that separate our send us from our receivers they decouple them most of",
    "start": "1304060",
    "end": "1313420"
  },
  {
    "text": "our backends push message senders take fire-and-forget approach to message",
    "start": "1313420",
    "end": "1319900"
  },
  {
    "text": "delivery these are they are fine with best effort delivery they put the",
    "start": "1319900",
    "end": "1325040"
  },
  {
    "text": "message in the message queue and they carry on with their life with their work few of them might need to know the final",
    "start": "1325040",
    "end": "1332000"
  },
  {
    "text": "delivery status whether the message actually reached a client or not and those can get to that status by either",
    "start": "1332000",
    "end": "1338600"
  },
  {
    "text": "subscribing to Zul push status queue or they can read it of the higher table in",
    "start": "1338600",
    "end": "1344390"
  },
  {
    "text": "batch mode where we log every single push message delivery Netflix runs in",
    "start": "1344390",
    "end": "1353600"
  },
  {
    "text": "three different AWS regions a back-end service trying to send a push message to",
    "start": "1353600",
    "end": "1361700"
  },
  {
    "text": "a particular client generally has no idea where that client will be connected",
    "start": "1361700",
    "end": "1367070"
  },
  {
    "text": "our push messaging and routing infrastructure takes care of routing",
    "start": "1367070",
    "end": "1372260"
  },
  {
    "text": "that message to the correct region for our message senders we use kafka message",
    "start": "1372260",
    "end": "1379340"
  },
  {
    "text": "PureApplication to go across the region and deliver messages across region in",
    "start": "1379340",
    "end": "1387980"
  },
  {
    "text": "practice we have found we can use a single push message queue partition but single push message queue to deliver all",
    "start": "1387980",
    "end": "1395240"
  },
  {
    "text": "sorts of push messages with all sorts of priorities and still stay within our",
    "start": "1395240",
    "end": "1400700"
  },
  {
    "text": "delivery left and sea budget or SLA but our design allows you to use different",
    "start": "1400700",
    "end": "1407870"
  },
  {
    "text": "push message queues for different priorities you would want to do that if you want to guarantee that priority",
    "start": "1407870",
    "end": "1415640"
  },
  {
    "text": "inversion never happens priority inversion is when a message of higher priority is met to wait behind",
    "start": "1415640",
    "end": "1423260"
  },
  {
    "text": "bunch of messages of lower priority because you are using a single message",
    "start": "1423260",
    "end": "1428330"
  },
  {
    "text": "queue to deliver all of them having different message queues for different priorities guarantees that this will",
    "start": "1428330",
    "end": "1435020"
  },
  {
    "text": "never happen our message processor is",
    "start": "1435020",
    "end": "1440330"
  },
  {
    "text": "built on top of mind T's - is our internal scaleable stream processing",
    "start": "1440330",
    "end": "1447230"
  },
  {
    "text": "engine similar to a patch F link it uses measures container management system to",
    "start": "1447230",
    "end": "1453560"
  },
  {
    "text": "run message processors she makes it very easy for us to spin up new message processor instances quickly",
    "start": "1453560",
    "end": "1460990"
  },
  {
    "text": "if we get more incoming messages in fact",
    "start": "1460990",
    "end": "1466170"
  },
  {
    "text": "Montes actually has out of box feature or support to auto scale number of",
    "start": "1466170",
    "end": "1472180"
  },
  {
    "text": "message processor instances depending upon the backlog in push message queue depending upon how many messages are",
    "start": "1472180",
    "end": "1478720"
  },
  {
    "text": "waiting this feature alone makes it too very easy for us to meet our delivery",
    "start": "1478720",
    "end": "1483760"
  },
  {
    "text": "latency SLA under a wide variety of load and still stay resource efficient so at",
    "start": "1483760",
    "end": "1494530"
  },
  {
    "text": "this point I would like to switch gears a little bit and go over some of the operational lessons that we learned when",
    "start": "1494530",
    "end": "1500980"
  },
  {
    "text": "we started operating will push cluster in production for the first time at",
    "start": "1500980",
    "end": "1506350"
  },
  {
    "text": "Netflix traffic scale till at that point you are mostly used or familiar with",
    "start": "1506350",
    "end": "1512380"
  },
  {
    "text": "operating stateless rest services and Zul push cluster is a different animal a",
    "start": "1512380",
    "end": "1517870"
  },
  {
    "text": "little bit different at least so that required a little TLC tender love and care when we started to operate it for",
    "start": "1517870",
    "end": "1524830"
  },
  {
    "text": "the first time the biggest difference between the normal rest service which is",
    "start": "1524830",
    "end": "1531250"
  },
  {
    "text": "stateless and dual push is those long-lived persistent connections that",
    "start": "1531250",
    "end": "1536740"
  },
  {
    "text": "are maintained by this will push server those connections make those dual push",
    "start": "1536740",
    "end": "1542080"
  },
  {
    "text": "servers stateful long length connections",
    "start": "1542080",
    "end": "1547420"
  },
  {
    "text": "are great for current clients right no argument here because they increase the",
    "start": "1547420",
    "end": "1552670"
  },
  {
    "text": "clients efficiency dramatically the client no longer has to break and make",
    "start": "1552670",
    "end": "1558220"
  },
  {
    "text": "connections constantly like in HTTP world that's why we all rejoiced when",
    "start": "1558220",
    "end": "1563590"
  },
  {
    "text": "WebSockets were finally widely supported and we could get rid of hacks like comet",
    "start": "1563590",
    "end": "1568870"
  },
  {
    "text": "and LAN Poli but the same long-lived",
    "start": "1568870",
    "end": "1575170"
  },
  {
    "text": "connections our headache from point of view of anybody who's operating a server mainly because they make that server",
    "start": "1575170",
    "end": "1583170"
  },
  {
    "text": "stateful and they complicate quick deployments and quick roll backs let's",
    "start": "1583170",
    "end": "1588430"
  },
  {
    "text": "take an example let's say you are trying to fix some critical high urgent bug and you want you deployed a",
    "start": "1588430",
    "end": "1595659"
  },
  {
    "text": "new dual push cluster build with the fix meanwhile you are all push clients in",
    "start": "1595659",
    "end": "1602499"
  },
  {
    "text": "the field are still happily connected to your old cluster these are persistent connections so they open it once and",
    "start": "1602499",
    "end": "1608649"
  },
  {
    "text": "they hang on to it forever so they are not gonna automatically move to your new cluster just because you deployed it you",
    "start": "1608649",
    "end": "1615489"
  },
  {
    "text": "will have to forcefully make them switch to the new cluster by killing your old",
    "start": "1615489",
    "end": "1620919"
  },
  {
    "text": "cluster but if you do that they are all going to switch back to the new cluster",
    "start": "1620919",
    "end": "1626559"
  },
  {
    "text": "at almost like this exact same time giving rise to thundering code so it's a",
    "start": "1626559",
    "end": "1632200"
  },
  {
    "text": "lose-lose scenario thundering herd is when a large number of clients or",
    "start": "1632200",
    "end": "1637929"
  },
  {
    "text": "applications try to connect to the same service at the same exact time it gives",
    "start": "1637929",
    "end": "1643239"
  },
  {
    "text": "rise to a sudden and large spike in incoming traffic that's orders of",
    "start": "1643239",
    "end": "1648609"
  },
  {
    "text": "magnitude higher than your normal steady-state traffic it's one of the things that you have to watch out for",
    "start": "1648609",
    "end": "1655139"
  },
  {
    "text": "when you are trying to design a robust resilient system we found our way out of",
    "start": "1655139",
    "end": "1663669"
  },
  {
    "text": "this pickle by limiting clients connection lifetime we are too close clients connection from",
    "start": "1663669",
    "end": "1673330"
  },
  {
    "text": "suicide after some time and all our clients are coded to reconnect back to",
    "start": "1673330",
    "end": "1680889"
  },
  {
    "text": "our servers whenever they lose a connection so we ought to close the connection from server the client will",
    "start": "1680889",
    "end": "1686889"
  },
  {
    "text": "reconnect back and because of the way how load us round-robin load balancing",
    "start": "1686889",
    "end": "1691989"
  },
  {
    "text": "works that client would typically land on some other server which takes care of",
    "start": "1691989",
    "end": "1697359"
  },
  {
    "text": "the root cause of all the issues a single client being sticky to a single",
    "start": "1697359",
    "end": "1702429"
  },
  {
    "text": "server of course we cannot continuously our frequently break the client",
    "start": "1702429",
    "end": "1708729"
  },
  {
    "text": "connection or to close the connection because then we are smacked back in the HTTP 1.1 world and we get rid of client",
    "start": "1708729",
    "end": "1715539"
  },
  {
    "text": "efficiency so we have carefully balanced this trade-off we are carefully tuned",
    "start": "1715539",
    "end": "1721389"
  },
  {
    "text": "our clients connection time to balance client efficiency that",
    "start": "1721389",
    "end": "1727240"
  },
  {
    "text": "we desire and client stickiness that we are trying to avoid empirically we have",
    "start": "1727240",
    "end": "1732940"
  },
  {
    "text": "found somewhere between 25 to 35 minutes is our sweet spot so for from now",
    "start": "1732940",
    "end": "1740410"
  },
  {
    "text": "onwards I'm gonna assume or we will discuss in terms of 30 minutes of client connection lifetime which kind of gives",
    "start": "1740410",
    "end": "1746410"
  },
  {
    "text": "us best of both words not only we limit",
    "start": "1746410",
    "end": "1757930"
  },
  {
    "text": "our client connections lifetime we also randomize it slightly between client to",
    "start": "1757930",
    "end": "1763660"
  },
  {
    "text": "client and for the same client even whenever it reconnects so many different",
    "start": "1763660",
    "end": "1769690"
  },
  {
    "text": "clients end up with many different connection lifetime for example in this case it would be somewhere between 28 to",
    "start": "1769690",
    "end": "1775480"
  },
  {
    "text": "32 minutes because we will randomize them in plus minus 2 minute boundary",
    "start": "1775480",
    "end": "1780630"
  },
  {
    "text": "this is necessary to give us some defense against a rare but possible",
    "start": "1780630",
    "end": "1786420"
  },
  {
    "text": "event where some network wide blip occurs let's say you're out of flips and",
    "start": "1786420",
    "end": "1793930"
  },
  {
    "text": "you didn't have this randomize connection lifetime so every single client exactly has 30 minutes of",
    "start": "1793930",
    "end": "1799150"
  },
  {
    "text": "connection lifetime in steady state all your clients started at different different times so they are reconnect",
    "start": "1799150",
    "end": "1806290"
  },
  {
    "text": "time out in the next connect is evenly distributed now your outer flips for",
    "start": "1806290",
    "end": "1812170"
  },
  {
    "text": "momentarily so all of those clients are going to lose their connection and they are try to reconnect back and if it was",
    "start": "1812170",
    "end": "1819670"
  },
  {
    "text": "a momentary disruption they are all gonna reconnect back and be successful around similar same time around within a",
    "start": "1819670",
    "end": "1827050"
  },
  {
    "text": "1 or 2 seconds that's a thundering heard and that's a different issue but now we have a bigger issue this network flip",
    "start": "1827050",
    "end": "1833800"
  },
  {
    "text": "has accidentally synchronized they reconnect life boundaries in perpetuity",
    "start": "1833800",
    "end": "1839290"
  },
  {
    "text": "now they are gonna from this point onwards all of your clients cannot drop their connections every 30 minutes and",
    "start": "1839290",
    "end": "1845830"
  },
  {
    "text": "reconnect so now you have the only thing that's worse than thundering herd a recurring thundering good",
    "start": "1845830",
    "end": "1852960"
  },
  {
    "text": "but if you randomize the connection last time every time you will still have that",
    "start": "1853650",
    "end": "1860040"
  },
  {
    "text": "initial thundering had a big spike but now because everyone is connected reconnecting at slightly different time",
    "start": "1860040",
    "end": "1866640"
  },
  {
    "text": "you will get this dampened sinusoidal wave of reconnect speak as the time",
    "start": "1866640",
    "end": "1871650"
  },
  {
    "text": "progresses because as the time progresses with every reconnect a time they are gonna they are reconnect next",
    "start": "1871650",
    "end": "1877230"
  },
  {
    "text": "reconnect is going to drift further and further apart so it's a really cheap",
    "start": "1877230",
    "end": "1882740"
  },
  {
    "text": "implementation wise feature to build in that gives you a really good defense",
    "start": "1882740",
    "end": "1888570"
  },
  {
    "text": "against momentary network destructions",
    "start": "1888570",
    "end": "1893240"
  },
  {
    "text": "this is mostly an extra optimization I know I just said couple sites ago that",
    "start": "1894380",
    "end": "1900690"
  },
  {
    "text": "we close the connection or Auto close the connection from suicide but that's",
    "start": "1900690",
    "end": "1906390"
  },
  {
    "text": "no longer actually accurate in our latest version let us release we flipped",
    "start": "1906390",
    "end": "1912180"
  },
  {
    "text": "it around such that our server now since a special message to our client within",
    "start": "1912180",
    "end": "1917640"
  },
  {
    "text": "the same push channel and ask our client to close the connection from its end I",
    "start": "1917640",
    "end": "1923780"
  },
  {
    "text": "know it sounds about sense the like a roundabout way of doing the same thing but we did that anyway because of the",
    "start": "1923780",
    "end": "1931230"
  },
  {
    "text": "way TCP operates anticipate the party that calls closed on the socket is the",
    "start": "1931230",
    "end": "1938430"
  },
  {
    "text": "party that ends up in what is called PCP time rate state is the last state TCP",
    "start": "1938430",
    "end": "1944100"
  },
  {
    "text": "state in the TCP flow diagram or straight diagram and that TCP time rate state can consume that sockets file",
    "start": "1944100",
    "end": "1952650"
  },
  {
    "text": "descriptor for up to two minutes after the connection is closed because it has to get those retransmitted segments and",
    "start": "1952650",
    "end": "1959280"
  },
  {
    "text": "everything now since our server is the one that's handling these thousands and",
    "start": "1959280",
    "end": "1964710"
  },
  {
    "text": "thousands of open connections simultaneously our server service file descriptors are of precious and scarce",
    "start": "1964710",
    "end": "1971490"
  },
  {
    "text": "commodity by having client close the connections beacon so the client was in",
    "start": "1971490",
    "end": "1977790"
  },
  {
    "text": "time which states so we can so file descriptors on servers there's a flip",
    "start": "1977790",
    "end": "1983370"
  },
  {
    "text": "side to that optimization though once in a while you're going to get a badly implemented by behaving client",
    "start": "1983370",
    "end": "1989929"
  },
  {
    "text": "that does not honor service connection life close connection message to handle",
    "start": "1989929",
    "end": "1997130"
  },
  {
    "text": "such clients we start a timer on server whenever we send there's close connection message and then if the",
    "start": "1997130",
    "end": "2005290"
  },
  {
    "text": "client doesn't comply within a set time limit then we go ahead and forcefully close it from the server side as a last",
    "start": "2005290",
    "end": "2011830"
  },
  {
    "text": "resort so with all these tweaks we took",
    "start": "2011830",
    "end": "2017140"
  },
  {
    "text": "care of the stateful sticky connections problem and for the next task we focused",
    "start": "2017140",
    "end": "2024070"
  },
  {
    "text": "our attention on making our server optimizing our push cluster basically",
    "start": "2024070",
    "end": "2031030"
  },
  {
    "text": "making it efficient our big epiphany here was most of those push connections",
    "start": "2031030",
    "end": "2036850"
  },
  {
    "text": "were idle most of the times so even with large number of push connections our CPU",
    "start": "2036850",
    "end": "2043390"
  },
  {
    "text": "a service CPU or memory wasn't under any particular load encouraged with this",
    "start": "2043390",
    "end": "2049570"
  },
  {
    "text": "insight we picked a really big impatient",
    "start": "2049570",
    "end": "2056230"
  },
  {
    "text": "instance type for our push server we optimized all its specific kernel",
    "start": "2056230",
    "end": "2061600"
  },
  {
    "text": "parameters some of them are for example shown here it's JVM startup options and things like",
    "start": "2061600",
    "end": "2066730"
  },
  {
    "text": "that and we crammed it with as many connections as possible and then one",
    "start": "2066730",
    "end": "2076570"
  },
  {
    "text": "fine morning are not so fine morning actually few of those servers crashed in",
    "start": "2076570",
    "end": "2082388"
  },
  {
    "text": "production and we got a visit from our dear old Finn again that's wondering",
    "start": "2082389",
    "end": "2088929"
  },
  {
    "text": "hard together those couple of servers were carrying something like close to a",
    "start": "2088929",
    "end": "2095230"
  },
  {
    "text": "million connections and when they went down all of them came roaring back you",
    "start": "2095230",
    "end": "2100630"
  },
  {
    "text": "know you have a problem when just couple of servers going down in production can start a stampede in your system so we",
    "start": "2100630",
    "end": "2110320"
  },
  {
    "text": "flipped our wounds we learned from a mistake and for the second time around we went with a Goldilocks strategy now",
    "start": "2110320",
    "end": "2118359"
  },
  {
    "text": "we know that we knew that you don't want to run your server either too hot or too cold so we picked a server",
    "start": "2118359",
    "end": "2126170"
  },
  {
    "text": "size or server instance type Amazon's instance type that was just right for us",
    "start": "2126170",
    "end": "2131830"
  },
  {
    "text": "size wise for Netflix it happens to be the instance M for large is the Amazon",
    "start": "2131830",
    "end": "2138440"
  },
  {
    "text": "instance type with two virtual CPUs and eight gigs of ram and from our squeeze",
    "start": "2138440",
    "end": "2144800"
  },
  {
    "text": "and load testing we have established that we can support eighty-four thousand",
    "start": "2144800",
    "end": "2149960"
  },
  {
    "text": "up to eighty four thousand open connections on that small server reliable and if one or even couple of",
    "start": "2149960",
    "end": "2158300"
  },
  {
    "text": "such instances were to go down single multiple of eighty four thousand",
    "start": "2158300",
    "end": "2164330"
  },
  {
    "text": "reconnects coming back is the size of thundering guard we are comfortable with given our traffic volume that's the size",
    "start": "2164330",
    "end": "2170900"
  },
  {
    "text": "of thundering guard we can easily handle so the real lesson here is you should",
    "start": "2170900",
    "end": "2178550"
  },
  {
    "text": "optimize your push cluster operation from the point of view of total cost not",
    "start": "2178550",
    "end": "2183800"
  },
  {
    "text": "just a push cluster size I know it sounds obvious when stated like that but",
    "start": "2183800",
    "end": "2189349"
  },
  {
    "text": "it wasn't obvious to us initially mainly because we conflated I think efficient",
    "start": "2189349",
    "end": "2195099"
  },
  {
    "text": "cluster operation with lesser number of instances in the reality you want or you",
    "start": "2195099",
    "end": "2203900"
  },
  {
    "text": "should prefer cheaper and more number of cheaper instances compared to few big",
    "start": "2203900",
    "end": "2209540"
  },
  {
    "text": "instances as long as your total cost remains the same and even if you don't",
    "start": "2209540",
    "end": "2216109"
  },
  {
    "text": "have this similar like Netflix price traffic and you are not too worried",
    "start": "2216109",
    "end": "2221240"
  },
  {
    "text": "about rendering code there's another reason you probably should prefer smaller instances over few big instances",
    "start": "2221240",
    "end": "2228020"
  },
  {
    "text": "because with smaller instances you can fit your traffic if you are using auto",
    "start": "2228020",
    "end": "2233180"
  },
  {
    "text": "scaling policies you can fit your traffic more accurately at low traffic smaller instances it's like small square",
    "start": "2233180",
    "end": "2240890"
  },
  {
    "text": "fitting your traffic curves so you get most out of your auto scaling compared",
    "start": "2240890",
    "end": "2247580"
  },
  {
    "text": "to if you one of just one server texture 25% of your traffic then you can't really",
    "start": "2247580",
    "end": "2253339"
  },
  {
    "text": "increase and decrease your push cluster with auto-scaling policies efficiently",
    "start": "2253339",
    "end": "2260200"
  },
  {
    "text": "the next problem we had to solve was how to auto scale our push cluster we just",
    "start": "2260859",
    "end": "2267410"
  },
  {
    "text": "set up think about auto scaling and we do use auto scaling heavily in production to minimize our cost but how",
    "start": "2267410",
    "end": "2275210"
  },
  {
    "text": "do we auto scale push clusters before push in a rest world our go-to strategies were either CPU or request",
    "start": "2275210",
    "end": "2283549"
  },
  {
    "text": "per second both of these basically these are the matrix on which we would autoscaler",
    "start": "2283549",
    "end": "2289160"
  },
  {
    "text": "clusters both of these matrix are surprisingly an effective for push",
    "start": "2289160",
    "end": "2295940"
  },
  {
    "text": "twister because there are persistent connection there are no requests per second to talk about it just once they",
    "start": "2295940",
    "end": "2303829"
  },
  {
    "text": "open the connection and as we have seen CPU is really low even with large number",
    "start": "2303829",
    "end": "2310160"
  },
  {
    "text": "of connections so how do you Auto scale turns out the only real limiting factor",
    "start": "2310160",
    "end": "2318680"
  },
  {
    "text": "for your push cluster or your push server is number of open connections at the same moment so it makes perfect",
    "start": "2318680",
    "end": "2326329"
  },
  {
    "text": "sense to scale your brush cluster by number of average open connections per",
    "start": "2326329",
    "end": "2333680"
  },
  {
    "text": "server thankfully Amazon makes it really easy to auto scale your cluster on any",
    "start": "2333680",
    "end": "2339640"
  },
  {
    "text": "arbitrary metric as long as you can export it as a custom cloud watch metric",
    "start": "2339640",
    "end": "2345589"
  },
  {
    "text": "and that's what we do we export our total number of connections from each server process and we hook up the",
    "start": "2345589",
    "end": "2352219"
  },
  {
    "text": "average of that to our auto scaling policies the last hurdle that we had to",
    "start": "2352219",
    "end": "2360049"
  },
  {
    "text": "cross to get to smooth production operation was to make CL B's or classic",
    "start": "2360049",
    "end": "2366680"
  },
  {
    "text": "load balancers and that Amazon provides play nice with WebSockets",
    "start": "2366680",
    "end": "2372069"
  },
  {
    "text": "CL B's do not understand WebSockets they cannot proxy WebSockets natively whenever a WebSocket client",
    "start": "2372069",
    "end": "2380509"
  },
  {
    "text": "like web browser wants to open a WebSocket connection with the server it sends a special I should EP",
    "start": "2380509",
    "end": "2386560"
  },
  {
    "text": "request called WebSocket upgrade request if the server understands this request",
    "start": "2386560",
    "end": "2391750"
  },
  {
    "text": "it's going to send a special it should respond back which is HTTP status hundred switching protocols and then the",
    "start": "2391750",
    "end": "2399550"
  },
  {
    "text": "server will take this HTTP connection and upgrade it to a persistent WebSocket",
    "start": "2399550",
    "end": "2405070"
  },
  {
    "text": "connection unfortunately CL B's do not understand this initial WebSocket upgrade request",
    "start": "2405070",
    "end": "2411400"
  },
  {
    "text": "so they're treated as any other normal HTTP request so whenever server sends back that",
    "start": "2411400",
    "end": "2418000"
  },
  {
    "text": "hundred switching protocols responds back it CL B's think okay so that should",
    "start": "2418000",
    "end": "2424390"
  },
  {
    "text": "it be request response cycle is over and they terminate the connection so you do a establish WebSocket connection but you",
    "start": "2424390",
    "end": "2430690"
  },
  {
    "text": "cannot have a persistent WebSocket connection through CL B's to your client",
    "start": "2430690",
    "end": "2436680"
  },
  {
    "text": "we worked around this limitation by making our CL B's classic load balancers",
    "start": "2436680",
    "end": "2444060"
  },
  {
    "text": "work as a TCP load balancer so by default CL B's run as they should appear",
    "start": "2444060",
    "end": "2449800"
  },
  {
    "text": "load balancers and do load balancing act layer seven but there is a setting in",
    "start": "2449800",
    "end": "2455050"
  },
  {
    "text": "AWS console that you can enable and put your CL B's and anticipate load balancer",
    "start": "2455050",
    "end": "2460780"
  },
  {
    "text": "mode and if you do that they will do PCP they will do load balancing at layer 4",
    "start": "2460780",
    "end": "2467940"
  },
  {
    "text": "in which they just proxy TCP packets back and forth without trying to",
    "start": "2467940",
    "end": "2473130"
  },
  {
    "text": "understand our past the higher level protocol which is HTTP and since if they",
    "start": "2473130",
    "end": "2478900"
  },
  {
    "text": "are not passing the HTTP anymore it keeps them from mangling the initial WebSocket upgrade requests that they do",
    "start": "2478900",
    "end": "2485230"
  },
  {
    "text": "not understand the good thing about TCP load balancer our CL b is anticipable",
    "start": "2485230",
    "end": "2492490"
  },
  {
    "text": "balancer mode is they can still determine MPLS for you you can still offload your SSL handling your SSL cert",
    "start": "2492490",
    "end": "2499360"
  },
  {
    "text": "management etc to CLP that's running at recipie load balancer not so good thing",
    "start": "2499360",
    "end": "2507880"
  },
  {
    "text": "about WebSockets Nazi Elvis in particular but WebSockets in general is there a particularly vulnerable to CSRF",
    "start": "2507880",
    "end": "2515350"
  },
  {
    "text": "or a cross-site request forgery this is because web browsers do not put WebSocket under the same",
    "start": "2515350",
    "end": "2522650"
  },
  {
    "text": "strict single origin policy as they would put say an AJAX call so you can",
    "start": "2522650",
    "end": "2528980"
  },
  {
    "text": "legitimately open a WebSocket to any random domain out there even if that",
    "start": "2528980",
    "end": "2534319"
  },
  {
    "text": "domain wasn't the document from which the document was downloaded this means",
    "start": "2534319",
    "end": "2539359"
  },
  {
    "text": "your server now has a extra responsibility to check and verify the origin header to secure your your",
    "start": "2539359",
    "end": "2547250"
  },
  {
    "text": "systems from CSRF thankfully Zul pushed our already does that for you the last",
    "start": "2547250",
    "end": "2554630"
  },
  {
    "text": "bit of trouble was how CL bees handled the registering of all instances from",
    "start": "2554630",
    "end": "2563930"
  },
  {
    "text": "whenever you'd be restore all instances from it whenever we deploy a new build",
    "start": "2563930",
    "end": "2569300"
  },
  {
    "text": "new push cluster with D register old push instances from our CL bees because",
    "start": "2569300",
    "end": "2576290"
  },
  {
    "text": "we don't want those old instances to get any new traffic what we ideally want in",
    "start": "2576290",
    "end": "2582920"
  },
  {
    "text": "risk is to happen is for CL bees to not give those old instances any new traffic",
    "start": "2582920",
    "end": "2590240"
  },
  {
    "text": "but let the old connections that are already established on the old instances continue throughout til they're a",
    "start": "2590240",
    "end": "2597920"
  },
  {
    "text": "natural connection lifetime but that's not how she always operate by default as",
    "start": "2597920",
    "end": "2604040"
  },
  {
    "text": "soon as you D register they are going to kill all the connections which is again the invitation for thund'ring code",
    "start": "2604040",
    "end": "2609190"
  },
  {
    "text": "thankfully there is a good news there there's yet another setting in AWS console called connection training that",
    "start": "2609190",
    "end": "2616369"
  },
  {
    "text": "you can log in and you can set enable and set it to high enough timeout value",
    "start": "2616369",
    "end": "2621790"
  },
  {
    "text": "if you do that then CL bees will let the old connections to the out of traffic",
    "start": "2621790",
    "end": "2629030"
  },
  {
    "text": "old instances go on up to that timeout value so all you have to do is set that",
    "start": "2629030",
    "end": "2634310"
  },
  {
    "text": "timeout value of the connection training parameter to a value higher than your",
    "start": "2634310",
    "end": "2639770"
  },
  {
    "text": "maximum connection lifetime 30 minutes that we saw before if you do that then",
    "start": "2639770",
    "end": "2645109"
  },
  {
    "text": "they will automatically disconnect on their own at the end of their connection lifetime and move to the new cluster so",
    "start": "2645109",
    "end": "2652819"
  },
  {
    "text": "you will get gradual shifting of the traffic instead of abrupt thundering herd once you make",
    "start": "2652819",
    "end": "2659539"
  },
  {
    "text": "all of these tricks to your CL bees they will handle lots and lots of WebSockets",
    "start": "2659539",
    "end": "2665359"
  },
  {
    "text": "happily no problem but there is simpler way after - this is",
    "start": "2665359",
    "end": "2674630"
  },
  {
    "text": "like your Mac teacher shows you long division and then then shows you the",
    "start": "2674630",
    "end": "2681289"
  },
  {
    "text": "calculator right so Amazon has come up with a better a newer version of that",
    "start": "2681289",
    "end": "2687440"
  },
  {
    "text": "load balancing infrastructure called application load balancers which are supposed to understand WebSocket",
    "start": "2687440",
    "end": "2693670"
  },
  {
    "text": "protocols natively so they you don't have to make all the squeeze they can actually proxy WebSockets unfortunately",
    "start": "2693670",
    "end": "2701690"
  },
  {
    "text": "elby's came on to scene a little too late for us by that time we had already figured out all these tweaks and we had",
    "start": "2701690",
    "end": "2707900"
  },
  {
    "text": "all this portion Kuster's operating flawlessly behind CL B's so we continued with them but if you are trying to get",
    "start": "2707900",
    "end": "2715009"
  },
  {
    "text": "any WebSocket based deployment today if you are just trying out today I definitely encourage you to give your",
    "start": "2715009",
    "end": "2722450"
  },
  {
    "text": "first try to lbs so let's quickly recap",
    "start": "2722450",
    "end": "2728539"
  },
  {
    "text": "best operational practice for push cluster you want to recycle your connections periodically to get a hang",
    "start": "2728539",
    "end": "2736880"
  },
  {
    "text": "on the sticky connections problem you want to randomize each connections lifetime to have some defense against",
    "start": "2736880",
    "end": "2744470"
  },
  {
    "text": "network wide outage and thundering code you should prefer more number of smaller",
    "start": "2744470",
    "end": "2753529"
  },
  {
    "text": "service service over few big servers again for better thundering herd characteristics if some of the service",
    "start": "2753529",
    "end": "2760759"
  },
  {
    "text": "were to go down you should Auto scale on number of open connections and not on",
    "start": "2760759",
    "end": "2765859"
  },
  {
    "text": "CPUs or RPS as you would normally do and either and use a load balancer that",
    "start": "2765859",
    "end": "2772670"
  },
  {
    "text": "understands WebSocket natively or if you",
    "start": "2772670",
    "end": "2778099"
  },
  {
    "text": "can't for some reason you are stuck behind CLV or something use it in TCP more every rotor balance out there",
    "start": "2778099",
    "end": "2783650"
  },
  {
    "text": "engine xh a proxy CL B has a disappear mode built-in in general so now that you have",
    "start": "2783650",
    "end": "2793259"
  },
  {
    "text": "this push cluster in production its operating the way you want what can you do with it",
    "start": "2793259",
    "end": "2798559"
  },
  {
    "text": "now that we finally have our push hammer in production we are seeing a lot of",
    "start": "2798559",
    "end": "2803849"
  },
  {
    "text": "magnetics our recent Alexa integration",
    "start": "2803849",
    "end": "2809400"
  },
  {
    "text": "is one such good example when user says say Alexa play stranger things what",
    "start": "2809400",
    "end": "2816630"
  },
  {
    "text": "happens is the Alexa or the echo dot sends the users spoken command waveform",
    "start": "2816630",
    "end": "2823559"
  },
  {
    "text": "or a trans file to cloud and the speech recognition actually happens in cloud in",
    "start": "2823559",
    "end": "2829109"
  },
  {
    "text": "Amazon Cloud using Amazon speech recognition service so now we have a synthesized playback command that our",
    "start": "2829109",
    "end": "2835559"
  },
  {
    "text": "application understands but it's in cloud we need a ultra-low latency way to send that command from cloud to the",
    "start": "2835559",
    "end": "2842960"
  },
  {
    "text": "application that's running in that users living room on that users TV push is a",
    "start": "2842960",
    "end": "2849269"
  },
  {
    "text": "perfect solution here our application pooling the cloud would clearly not do because the latency characteristics are",
    "start": "2849269",
    "end": "2855589"
  },
  {
    "text": "unacceptable but with push you can send that command right away to the client",
    "start": "2855589",
    "end": "2861480"
  },
  {
    "text": "and that's what we did our Alexa integration is built on top of Zul push",
    "start": "2861480",
    "end": "2867829"
  },
  {
    "text": "we have even more ambitious plans for our Zul push messaging capability one of",
    "start": "2867829",
    "end": "2874559"
  },
  {
    "text": "it is remote telemetry let's say we have some device in field which is generating",
    "start": "2874559",
    "end": "2881940"
  },
  {
    "text": "a lot of errors and we don't know why we can send a special push message to that device you can target that device now",
    "start": "2881940",
    "end": "2888480"
  },
  {
    "text": "and ask that device to essentially upload all of its state data its diagnostic details its application state",
    "start": "2888480",
    "end": "2895980"
  },
  {
    "text": "to cloud so that we can take a look at it and decide what exactly is bugging",
    "start": "2895980",
    "end": "2902220"
  },
  {
    "text": "that device but let's say with all this",
    "start": "2902220",
    "end": "2907799"
  },
  {
    "text": "extra dolls so we couldn't figure out what's wrong with that device we can always reach to the last and most",
    "start": "2907799",
    "end": "2914400"
  },
  {
    "text": "favorite tool in every software engineers toolbox we can start the",
    "start": "2914400",
    "end": "2919410"
  },
  {
    "text": "application by sending it another message now we can do do it remotely what could go wrong",
    "start": "2919410",
    "end": "2928070"
  },
  {
    "text": "but if something does go wrong at least now we can send your push message saying yes sorry",
    "start": "2928790",
    "end": "2936440"
  },
  {
    "text": "so I've been pleading the case for push for last 40 minutes or so at this point",
    "start": "2939890",
    "end": "2947460"
  },
  {
    "text": "only one last request to make pull all",
    "start": "2947460",
    "end": "2955380"
  },
  {
    "text": "of this that we have discussed so far all of it is up our level today on",
    "start": "2955380",
    "end": "2960420"
  },
  {
    "text": "github and does Netflix OSS ripple in the project soon it even comes with us",
    "start": "2960420",
    "end": "2967650"
  },
  {
    "text": "ready to go toy samples you'll push that you can start and start playing with",
    "start": "2967650",
    "end": "2972810"
  },
  {
    "text": "immediately so give it a try take it for a spin file bugs and if you would be so",
    "start": "2972810",
    "end": "2979530"
  },
  {
    "text": "kind maybe one give us a pull request or two so in conclusion push can make you",
    "start": "2979530",
    "end": "2987859"
  },
  {
    "text": "rich thin and happy",
    "start": "2987859",
    "end": "2994400"
  },
  {
    "text": "thank you [Applause]",
    "start": "2995530",
    "end": "3006630"
  }
]
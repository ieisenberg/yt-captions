[
  {
    "start": "0",
    "end": "64000"
  },
  {
    "text": "all right so good morning everyone happy last day of reinvent hopefully everybody",
    "start": "0",
    "end": "5190"
  },
  {
    "text": "enjoy dead mass last night I thought it was awesome personally my name is Nate wider I'm a principal Solutions",
    "start": "5190",
    "end": "11700"
  },
  {
    "text": "Architect for AWS a quick background on me well first off just to double check",
    "start": "11700",
    "end": "17190"
  },
  {
    "text": "this is the deep dive into ElastiCache so now is the time to double check make sure you're not supposed to be seeing",
    "start": "17190",
    "end": "22410"
  },
  {
    "text": "that cloud ice is HSM talk or something else so my name is nate Wagram a",
    "start": "22410",
    "end": "28019"
  },
  {
    "text": "principal Solutions Architect for AWS at AWS I focus on gaming customers which is",
    "start": "28019",
    "end": "33750"
  },
  {
    "text": "my background I before joining AWS I was actually at Sony Playstation where I",
    "start": "33750",
    "end": "39059"
  },
  {
    "text": "launched a number of games on AWS starting in 2008 and so I joined Amazon",
    "start": "39059",
    "end": "44309"
  },
  {
    "text": "a little over a year ago one of the things I learned from my experience and also from talking with other gaming",
    "start": "44309",
    "end": "49559"
  },
  {
    "text": "companies is the importance of caching the importance of smart caching strategies when you're building a",
    "start": "49559",
    "end": "54660"
  },
  {
    "text": "massive app that can horizontally scale out so in this talk I wanted to share a few things with you so first off I just",
    "start": "54660",
    "end": "66840"
  },
  {
    "start": "64000",
    "end": "64000"
  },
  {
    "text": "wanted to kind of level set now this is a level 300 talk but I think it's good to just make sure that we're all on the",
    "start": "66840",
    "end": "72240"
  },
  {
    "text": "same page with kind of the context of what's happening out there in terms of apps we see in the wild so we can kind",
    "start": "72240",
    "end": "77490"
  },
  {
    "text": "of make sure to all be on this journey together if you will so we'll talk about some of those trends well dive into some",
    "start": "77490",
    "end": "83640"
  },
  {
    "text": "of the properties of ElastiCache specifically which is our managed caching service and then we'll go about",
    "start": "83640",
    "end": "90479"
  },
  {
    "text": "different ways to use caching in your app there's a couple different ways from lazy population to right through we'll",
    "start": "90479",
    "end": "96060"
  },
  {
    "text": "cover those and then we'll talk about scaling up starting small starting with",
    "start": "96060",
    "end": "101340"
  },
  {
    "text": "a few maybe even one node getting out to you're running dozens or hundreds even nodes and we'll talk about how to go",
    "start": "101340",
    "end": "108570"
  },
  {
    "text": "through that process and finally you know we'll do a little memcache versus Redis showdown at the end personally I'm",
    "start": "108570",
    "end": "114509"
  },
  {
    "text": "a big Redis fan coming from gaming it's got some awesome applications for gaming so what kind of talk about pros and cons",
    "start": "114509",
    "end": "120600"
  },
  {
    "text": "Redis versus memcache ElastiCache supports both now as you're probably aware so this is a graph just to kind of",
    "start": "120600",
    "end": "128640"
  },
  {
    "text": "kick it off got from Business Insider that just looks at the growth of different devices",
    "start": "128640",
    "end": "134050"
  },
  {
    "text": "sure this is probably not news to you but it's worth just looking at because to me it rather he drives the point home that you've got all of these different",
    "start": "134050",
    "end": "140290"
  },
  {
    "text": "devices you're seeing not just pcs anymore you're seeing tablets you're seeing mobile we're seeing dozens of",
    "start": "140290",
    "end": "146380"
  },
  {
    "text": "different form factors you have to deal with and so what are the applications or what are the implications rather of",
    "start": "146380",
    "end": "151570"
  },
  {
    "start": "151000",
    "end": "151000"
  },
  {
    "text": "device fragmentation and so the big problem with all these devices you know you've got HTML you've got native apps",
    "start": "151570",
    "end": "158560"
  },
  {
    "text": "you've got JSON API is your toaster wants to talk to your app now right as the presentation is different on all of",
    "start": "158560",
    "end": "164500"
  },
  {
    "text": "these but the data is the same so if you think about what we were doing just maybe three or so or even two years ago",
    "start": "164500",
    "end": "171550"
  },
  {
    "text": "with caching a lot of it was rendering out full or partial pages of HTML that's",
    "start": "171550",
    "end": "176740"
  },
  {
    "text": "still a valid strategy we'll talk about that but you can't just constrain yourself to rendering out HTML views and",
    "start": "176740",
    "end": "183760"
  },
  {
    "text": "stick it into memcache or sticking on the file system anymore because of the fact that you're presenting the data layer and you're",
    "start": "183760",
    "end": "189790"
  },
  {
    "text": "presenting the data natively as well right so you have to have to do something at the data layer we'll talk about strategies there and of course",
    "start": "189790",
    "end": "196930"
  },
  {
    "text": "you're going to be using a CDN for all your static images but that doesn't really help you with stuff like hey",
    "start": "196930",
    "end": "202330"
  },
  {
    "text": "welcome back you know if you think of your standard page you know you go to CNN or whatever nowadays yeah there's",
    "start": "202330",
    "end": "208300"
  },
  {
    "text": "shared content in the middle maybe you can do some caching that applies to everyone but up in the corner is just you so how do you deal with mixing that",
    "start": "208300",
    "end": "214660"
  },
  {
    "text": "in sure these are challenges you guys are all facing as well so compounding",
    "start": "214660",
    "end": "220540"
  },
  {
    "start": "218000",
    "end": "218000"
  },
  {
    "text": "this is all the different queries you're doing right all of the social tie-ins your friends want to see what you're doing you want to see what your friends",
    "start": "220540",
    "end": "226660"
  },
  {
    "text": "are doing all these calls to external API so you're making dozens and dozens of calls whereas just a few years ago",
    "start": "226660",
    "end": "232870"
  },
  {
    "text": "the data was largely coming from your own database and you were able to have a lot of control over it now you've got",
    "start": "232870",
    "end": "238750"
  },
  {
    "text": "latency and other issues that are outside of your control and caching it plays a key part in making sure that",
    "start": "238750",
    "end": "244630"
  },
  {
    "text": "that doesn't translate into a bad user experience it cracks me up all right I",
    "start": "244630",
    "end": "250989"
  },
  {
    "text": "always get updates about look what I had for lunch or I'm sure everybody else does and it just now we have to deal",
    "start": "250989",
    "end": "256120"
  },
  {
    "text": "with that as well and traffic spikes is another one the last one I want to mention in this context and then we'll",
    "start": "256120",
    "end": "261370"
  },
  {
    "start": "259000",
    "end": "259000"
  },
  {
    "text": "move on to kind of the nuts and bolts this is from a guy who does analysis of",
    "start": "261370",
    "end": "267150"
  },
  {
    "text": "social media streams and I thought it was great in the context of caching if you're running a you know even a well",
    "start": "267150",
    "end": "273810"
  },
  {
    "text": "architected app that's got you know database layer that you've tuned there's no way you can deal with the 2,000",
    "start": "273810",
    "end": "279449"
  },
  {
    "text": "percent increase in load in your database tier it's just not possible right I mean stuff is gonna melt so you",
    "start": "279449",
    "end": "284970"
  },
  {
    "text": "have to have a good caching strategy there you have to be involving that in all layers of your app and so let's look",
    "start": "284970",
    "end": "290850"
  },
  {
    "text": "at what that means so when you think about caching it's you know your main",
    "start": "290850",
    "end": "295949"
  },
  {
    "text": "you know what I like to think of as a mindset is that it's not something obviously this authoritative you're getting the data from somewhere else",
    "start": "295949",
    "end": "301979"
  },
  {
    "text": "you're taking it you're making use of it you're stashing it away and making sure that you can effectively use that later",
    "start": "301979",
    "end": "307889"
  },
  {
    "start": "306000",
    "end": "306000"
  },
  {
    "text": "on in your application very simple diagram right that's your standard web",
    "start": "307889",
    "end": "313800"
  },
  {
    "text": "2.0 app you've got your my sequel database you've got these external api's",
    "start": "313800",
    "end": "318870"
  },
  {
    "text": "and then in the context the ballistic ElastiCache memcache these kind of sit",
    "start": "318870",
    "end": "324570"
  },
  {
    "text": "over on the side right there's a couple different layers a couple different ways that people do caching if you're",
    "start": "324570",
    "end": "330960"
  },
  {
    "text": "thinking about where the CDN fits in right that's gonna fit in on that kind of edge as well but when we're talking",
    "start": "330960",
    "end": "336360"
  },
  {
    "text": "about ElastiCache that really kind of hangs off to the side and then sup to your application to have the logic to be",
    "start": "336360",
    "end": "341669"
  },
  {
    "text": "able to put and get keys out of there and make the best use of it so",
    "start": "341669",
    "end": "348479"
  },
  {
    "start": "347000",
    "end": "347000"
  },
  {
    "text": "highlights on the last Akash and if you saw the introduction to ElastiCache or if you've used last Akash this is going to be kind of repeat information but it",
    "start": "348479",
    "end": "355860"
  },
  {
    "text": "is our managed cache service supports memcache or Brennus currently you can launch clusters of nodes you know the",
    "start": "355860",
    "end": "362430"
  },
  {
    "text": "nice thing that the service brings as opposed to you installing memcache your self on ec2 is being able to manage the",
    "start": "362430",
    "end": "370229"
  },
  {
    "text": "configuration that kind of this meta state and then being able to deploy multiple nodes that have the same configuration scale up and scale down",
    "start": "370229",
    "end": "377490"
  },
  {
    "text": "along the same lines and then monitoring alerts again you know you could roll",
    "start": "377490",
    "end": "382770"
  },
  {
    "text": "this yourself if you want to install memcache on ec2 but the nice thing about ElastiCache is that it ties right in to",
    "start": "382770",
    "end": "388349"
  },
  {
    "text": "cloud watch and SNS in order to send you alerts to your phone and you can take action depending on what's happening in",
    "start": "388349",
    "end": "393690"
  },
  {
    "text": "production so quick primer on memcache is all in memory as you're no doubt",
    "start": "393690",
    "end": "399780"
  },
  {
    "start": "396000",
    "end": "396000"
  },
  {
    "text": "aware use a slab allocator it's not something you really have to be that concerned with but you can impress your friends at",
    "start": "399780",
    "end": "405810"
  },
  {
    "text": "parties if they're those kinds of friends say hey you know memcache actually uses a slab allocator oh that",
    "start": "405810",
    "end": "410940"
  },
  {
    "text": "means that allocates and chunks and then internally divides up that memory so it makes it faster to allocate memory",
    "start": "410940",
    "end": "417409"
  },
  {
    "text": "it's multi-threaded can take advantage of multiple cores of course there's no persistence right so you can't rely on",
    "start": "417409",
    "end": "423870"
  },
  {
    "text": "storing it for long-term data and it is kind of a gold standard it's why we started out with ElastiCache supporting",
    "start": "423870",
    "end": "430650"
  },
  {
    "text": "them cache D first so for the next you know a few slides of this talk as we kind of go through some of the details",
    "start": "430650",
    "end": "437090"
  },
  {
    "text": "we're just gonna use memcache as an example just that way we're not talking memcache Redis memcache where's over and",
    "start": "437090",
    "end": "443009"
  },
  {
    "text": "over again so from an elastic ash perspective of the management is basically the same right you're going in",
    "start": "443009",
    "end": "449280"
  },
  {
    "text": "you're deciding which engine you want to use memcache your Redis but the other features such as alerts and",
    "start": "449280",
    "end": "455550"
  },
  {
    "text": "configuration management those are all the same regardless of memcache or Redis",
    "start": "455550",
    "end": "461599"
  },
  {
    "text": "all right cool so if you haven't done it quick walkthrough on firing up an actual cash this is our console this is from a",
    "start": "462319",
    "end": "469800"
  },
  {
    "start": "464000",
    "end": "464000"
  },
  {
    "text": "couple days ago so given how fast our console changes it may look completely different today but we're the purpose of",
    "start": "469800",
    "end": "474810"
  },
  {
    "text": "this talk so you would click on the middle ElastiCache and go in click hey",
    "start": "474810",
    "end": "481710"
  },
  {
    "text": "launched a cache cluster pops up a dialog say give it a name I use the",
    "start": "481710",
    "end": "487380"
  },
  {
    "text": "extremely creative name my cache you probably want to choose a cooler name",
    "start": "487380",
    "end": "492750"
  },
  {
    "text": "and in your real life you know a dev or tests or production have a few different caches just selecting memcache and the",
    "start": "492750",
    "end": "498990"
  },
  {
    "text": "version going to start out with a small node you can always change that later grow it as your app continues to grow",
    "start": "498990",
    "end": "504960"
  },
  {
    "text": "and I'm going to spin up two nodes for the purposes of this talk because I want",
    "start": "504960",
    "end": "510029"
  },
  {
    "text": "to talk about stuff like sharding I want to talk about balancing between multiple nodes how to handle all that stuff and",
    "start": "510029",
    "end": "516198"
  },
  {
    "text": "then the last point I just want to highlight here there's some VPC settings and stuff I didn't cover SNS so this is",
    "start": "516199",
    "end": "524459"
  },
  {
    "text": "my you know one of my personal favorite features about ElastiCache is that it does integrate with SNS and the cool",
    "start": "524459",
    "end": "531089"
  },
  {
    "text": "thing about integrated with SNS that gives you a lot of flexibility so S&S is our simple notification service",
    "start": "531089",
    "end": "536790"
  },
  {
    "text": "as you're probably aware it has the idea Beach of messages and endpoints so you",
    "start": "536790",
    "end": "541829"
  },
  {
    "text": "can send a message into SNS and then you can route it to one or more endpoints in",
    "start": "541829",
    "end": "546959"
  },
  {
    "text": "the simplest example this is usually used to just send you an email saying hey you're seeing a lot of latency or",
    "start": "546959",
    "end": "553050"
  },
  {
    "text": "your city your cache is getting full or something like that but in more complex",
    "start": "553050",
    "end": "558199"
  },
  {
    "text": "kind of situations kind of trickier ones if you will which we'll talk about you can actually connect an SNS topic to sqs",
    "start": "558199",
    "end": "567809"
  },
  {
    "text": "and then you can have ec2 listeners that are listening on to your sqs queue and taking steps like dynamically changing",
    "start": "567809",
    "end": "574319"
  },
  {
    "text": "settings and doing stuff like that so it allows you to build a really kind of cool end-to-end cycle and we'll cover",
    "start": "574319",
    "end": "579389"
  },
  {
    "text": "that towards the end and then launch so",
    "start": "579389",
    "end": "584699"
  },
  {
    "text": "this is what's this once it's up and running takes a few minutes to get up and running it shows up on your dashboard and so if you click here right",
    "start": "584699",
    "end": "591660"
  },
  {
    "text": "on the configuration endpoint you get this pop up and this shows you your two actual nodes so those are the two nodes",
    "start": "591660",
    "end": "597600"
  },
  {
    "text": "that ElastiCache actually allocated for us we're just going to copy those DNS",
    "start": "597600",
    "end": "603149"
  },
  {
    "text": "endpoints we're going to open up our application in this case it's a ruby app",
    "start": "603149",
    "end": "608249"
  },
  {
    "text": "I'm a ruby fan but obviously you can use Python PHP job or whatever else so we're",
    "start": "608249",
    "end": "614189"
  },
  {
    "text": "just going to open up our client and we're literally going to paste those two endpoints in there real simple and then",
    "start": "614189",
    "end": "619199"
  },
  {
    "text": "we can set and get values set delete all the common memcache operations nothing",
    "start": "619199",
    "end": "625379"
  },
  {
    "text": "proprietary about the memcache is running and ElastiCache is just straight memcache anything that you would do with",
    "start": "625379",
    "end": "630720"
  },
  {
    "text": "any other memcache instance you can do with ElastiCache so when you're talking",
    "start": "630720",
    "end": "636480"
  },
  {
    "text": "about multiple nodes what does that look like so we started out with a simple app as you're adding nodes those are all",
    "start": "636480",
    "end": "644009"
  },
  {
    "start": "638000",
    "end": "638000"
  },
  {
    "text": "kind of peers from the application layer it's not a tiered relationship there's",
    "start": "644009",
    "end": "650249"
  },
  {
    "text": "not a balancer between them so your application then has to have the logic in order to actually figure out how to",
    "start": "650249",
    "end": "656759"
  },
  {
    "text": "char it across those nodes so we'll talk about a couple strategies you can use so",
    "start": "656759",
    "end": "663029"
  },
  {
    "start": "662000",
    "end": "662000"
  },
  {
    "text": "kind of the first strategy that a lot of people use which you can find on lots of blogs out there is they build an array of the servers",
    "start": "663029",
    "end": "671350"
  },
  {
    "text": "and then they basically take a hash on the key that you're going to save and",
    "start": "671350",
    "end": "677580"
  },
  {
    "text": "you do a modulo with the length of the server list that's this part right here the idea behind the hash is to inject",
    "start": "677580",
    "end": "684310"
  },
  {
    "text": "some randomness kind of get a better distribution and then the modulo you're going to get back an index right zero or",
    "start": "684310",
    "end": "691090"
  },
  {
    "text": "one that points to which server to use and then from there it's just a simple matter of doing a lookup in the server",
    "start": "691090",
    "end": "697480"
  },
  {
    "text": "list you get back the server and you can directly connect to it and so if you put this in your application code this would",
    "start": "697480",
    "end": "703840"
  },
  {
    "text": "be one easy way to be able to balance between nodes and the thing I want to",
    "start": "703840",
    "end": "710020"
  },
  {
    "text": "point out about this is that you should never ever do this like this is a",
    "start": "710020",
    "end": "715480"
  },
  {
    "text": "terrible way to balance across multiple nodes so why why is it why is it so bad",
    "start": "715480",
    "end": "722290"
  },
  {
    "text": "so the reason why is if you work out the math on it it's actually pretty terrible",
    "start": "722290",
    "end": "727750"
  },
  {
    "text": "what happens is is you upgrade and you keep increasing nodes you take the",
    "start": "727750",
    "end": "733180"
  },
  {
    "text": "number of nodes that you're moving from the number of nodes you're moving to the fraction out of those and that is the",
    "start": "733180",
    "end": "740140"
  },
  {
    "text": "number of keys that you end up actually reshuffling mmm so what does that mean so if you're going from three to four",
    "start": "740140",
    "end": "746170"
  },
  {
    "text": "nodes this would actually reshuffle 75% of your key space so envision what's",
    "start": "746170",
    "end": "752020"
  },
  {
    "text": "happening right you're writing to your database you're getting SNS Alerts it's saying hey watch out cache is filling up",
    "start": "752020",
    "end": "757750"
  },
  {
    "text": "you say hey I've got just the ticket I go into elastic hash I spin up another node I go from three to four nodes all",
    "start": "757750",
    "end": "763240"
  },
  {
    "text": "of a sudden I flushed 75% of my cash and my database there just completely melts",
    "start": "763240",
    "end": "768340"
  },
  {
    "text": "basically the exact opposite of what you want to happen right so luckily there's",
    "start": "768340",
    "end": "774070"
  },
  {
    "text": "a solution smart people smarter than me have figured this out it's called consistent hashing some of you probably aware of",
    "start": "774070",
    "end": "780760"
  },
  {
    "start": "777000",
    "end": "777000"
  },
  {
    "text": "this and the idea behind this is you build a ring you basically pre partition",
    "start": "780760",
    "end": "786340"
  },
  {
    "text": "your key space and you build a ring and then as you add and remove servers if",
    "start": "786340",
    "end": "791380"
  },
  {
    "text": "you look at the color coding up there this is a diagram from bash of site",
    "start": "791380",
    "end": "796570"
  },
  {
    "text": "they've actually got a good little write-up on it so you as you're adding and removing nodes your know your actual ElastiCache nodes would",
    "start": "796570",
    "end": "804310"
  },
  {
    "text": "be going to be populating different parts of that ring okay and there's a",
    "start": "804310",
    "end": "809529"
  },
  {
    "text": "little bit of trickiness there's some math involved etc so this is why a lot of people end up not doing this they end",
    "start": "809529",
    "end": "815170"
  },
  {
    "text": "up saying oh that's a lot of work I'm a game developer I'm a mobile developer I don't have time to do that I'll just do the modulo and move on right I'll come",
    "start": "815170",
    "end": "821170"
  },
  {
    "text": "back to it later and then of course they want to come back to it later you know when things are exploding so the good",
    "start": "821170",
    "end": "827800"
  },
  {
    "text": "news about this is you don't have to do this because people have taken care of it for you and these are examples of all",
    "start": "827800",
    "end": "834730"
  },
  {
    "text": "of these client libraries that actually do consistent hashing for you right so the great news is is that if you're",
    "start": "834730",
    "end": "840250"
  },
  {
    "text": "using the dolly library that I showed you from Ruby if you're using Python look at hash string or memcache ring as",
    "start": "840250",
    "end": "846940"
  },
  {
    "text": "far as I could tell I'm not a Python expert caveat but as far as I could tell through reading the source code the",
    "start": "846940",
    "end": "852790"
  },
  {
    "text": "Python just straight in memcache library doesn't actually do consistent hashing you have to use hash ring or memcache",
    "start": "852790",
    "end": "858790"
  },
  {
    "text": "ring so this is a partial list I'm sure there's a there's out there as well but the point being is find a client library",
    "start": "858790",
    "end": "864550"
  },
  {
    "text": "that does consistent hashing for you and then if you think back to that example I showed you in the Dalek client and just",
    "start": "864550",
    "end": "870790"
  },
  {
    "text": "put your two servers in that list and then the library will take care of doing the consistent hashing for you and all",
    "start": "870790",
    "end": "876490"
  },
  {
    "text": "you need to do is when you add another node have your application be able to pick up that new node we'll talk about",
    "start": "876490",
    "end": "881890"
  },
  {
    "text": "that and let the client library handle the consistent hashing for you don't try to fix it and you'll be in good shape",
    "start": "881890",
    "end": "889440"
  },
  {
    "text": "all right so so far quick recap before we wind off into the weeds bit so we",
    "start": "892050",
    "end": "898900"
  },
  {
    "text": "launched a cluster got the node names put them in our client we talked about charting and",
    "start": "898900",
    "end": "904240"
  },
  {
    "text": "hashing and so now what so let's talk",
    "start": "904240",
    "end": "911500"
  },
  {
    "start": "911000",
    "end": "911000"
  },
  {
    "text": "about what to cache so we say okay we've got it all set up I'm ready to do caching sounds great what do we actually cache and I say everything so I say that",
    "start": "911500",
    "end": "919420"
  },
  {
    "text": "a little tongue-in-cheek but the reality is you have to use multiple different tiers of caching it's not sufficient as",
    "start": "919420",
    "end": "924670"
  },
  {
    "text": "I mentioned earlier just to cache the end HTML or just to cache even partial HTML chunks you need to do stuff at the",
    "start": "924670",
    "end": "931120"
  },
  {
    "text": "data layer you need to doing caching at all tears luckily it's actually fairly straightforward you just",
    "start": "931120",
    "end": "936600"
  },
  {
    "text": "have to kind of get in the habit we'll cover those patterns so I say you know database records data layer full HTML",
    "start": "936600",
    "end": "943320"
  },
  {
    "text": "pages is still good to do I mean don't not do that but it's just not sufficient by itself page fragments",
    "start": "943320",
    "end": "948870"
  },
  {
    "text": "partials you know if you're using rails or something like that partials remote",
    "start": "948870",
    "end": "954030"
  },
  {
    "text": "API calls is another big one so tucking back about the the social",
    "start": "954030",
    "end": "959460"
  },
  {
    "text": "api's you know you may get calls out to Facebook Twitter showing your friends but you probably don't want to do is",
    "start": "959460",
    "end": "965940"
  },
  {
    "text": "every single page load for a person visiting your site make another call out to Facebook just to make sure they",
    "start": "965940",
    "end": "972030"
  },
  {
    "text": "haven't changed their real name right you should be able to cache some of these basic details about a person their",
    "start": "972030",
    "end": "977460"
  },
  {
    "text": "name they're from San Diego or wherever they're from and then use that right instead of TTL on it which will cover a",
    "start": "977460",
    "end": "984240"
  },
  {
    "text": "set of TTL on it and be able to actually leverage the cache for those remote calls as well if you're using Facebook",
    "start": "984240",
    "end": "991170"
  },
  {
    "text": "Twitter etc they pretty much all have documentation where they give guidance on what they recommend in terms of how",
    "start": "991170",
    "end": "996690"
  },
  {
    "text": "long to cache how much they'd like you to cache etc just refer to those Docs follow those practices you know plug it",
    "start": "996690",
    "end": "1002780"
  },
  {
    "text": "into your app it's fairly straightforward but it's just all these kinds of things you just have to integrate when you're building your",
    "start": "1002780",
    "end": "1008000"
  },
  {
    "text": "caching layer you have to take them all into account and so how do you cache it",
    "start": "1008000",
    "end": "1013090"
  },
  {
    "start": "1011000",
    "end": "1011000"
  },
  {
    "text": "so there's several different you know kind of ways and they kind of break down into three different main buckets so",
    "start": "1013090",
    "end": "1020330"
  },
  {
    "text": "lazy population is the most ubiquitous that's essentially you're not populating",
    "start": "1020330",
    "end": "1025760"
  },
  {
    "text": "the cache until you actually have a cache miss your pattern is you've got your application you check the cache",
    "start": "1025760",
    "end": "1032270"
  },
  {
    "text": "cache doesn't have the case you go to the database come back put it in the cache and then",
    "start": "1032270",
    "end": "1037430"
  },
  {
    "text": "you can use it from there on there's also right through a meaning that when you save a record you say hey",
    "start": "1037430",
    "end": "1042589"
  },
  {
    "text": "I'll just write it to cache right now and I know I just updated it so here's the new record in cash and there's pros",
    "start": "1042589",
    "end": "1048620"
  },
  {
    "text": "and cons to both of those we'll look at and then last there's a time to refresh",
    "start": "1048620",
    "end": "1053720"
  },
  {
    "text": "which is you see you have a job maybe running out of cron or something else where you're just every X minutes or so",
    "start": "1053720",
    "end": "1060860"
  },
  {
    "text": "going through and pulling out the top X you know values maybe if you're doing gaming for example some that have",
    "start": "1060860",
    "end": "1068120"
  },
  {
    "text": "a background job just running every five minutes and populating the top 100 leaderboard stuffing that in cash",
    "start": "1068120",
    "end": "1074450"
  },
  {
    "text": "you know crosses all these different records so it's more efficient to have it running on a time two basis look at",
    "start": "1074450",
    "end": "1080150"
  },
  {
    "text": "that pattern as well so starting with",
    "start": "1080150",
    "end": "1086630"
  },
  {
    "start": "1082000",
    "end": "1082000"
  },
  {
    "text": "the lazy population approach this is a simple Python example none of this code",
    "start": "1086630",
    "end": "1092330"
  },
  {
    "text": "is is designed to necessarily be reference code you can feel free to use it but most any major framework rails",
    "start": "1092330",
    "end": "1099350"
  },
  {
    "text": "Django etc has their own adaptor so I would make use of that but it's important to understand how you know",
    "start": "1099350",
    "end": "1104450"
  },
  {
    "text": "what you're actually doing because then it actually makes sense like when you would use this strategy so for this you",
    "start": "1104450",
    "end": "1109790"
  },
  {
    "text": "know our get user call quote unquote we're gonna check the cache if it's empty no we got nothing we're gonna do",
    "start": "1109790",
    "end": "1116330"
  },
  {
    "text": "the actual DB query get that back and we're gonna stuff it into the cache by user ID and then with this example we're",
    "start": "1116330",
    "end": "1124220"
  },
  {
    "text": "returning a record in either case and the reason we do that is then our applications here doesn't have to care",
    "start": "1124220",
    "end": "1129620"
  },
  {
    "text": "whether or not we got it back from cache or got it back from our database directly right we're abstracting that",
    "start": "1129620",
    "end": "1135110"
  },
  {
    "text": "away our app on up doesn't have to care about it so it's a good pattern for being able to just have a piece of",
    "start": "1135110",
    "end": "1141470"
  },
  {
    "text": "abstracted code down at your data layer so later if you want to swap that out for a different strategy then you can",
    "start": "1141470",
    "end": "1146840"
  },
  {
    "text": "change that you don't have to go through and disentangle everywhere where you've got caching code scattered around your application so if you've only got time",
    "start": "1146840",
    "end": "1155480"
  },
  {
    "start": "1155000",
    "end": "1155000"
  },
  {
    "text": "to do one thing if you're pressed for time as we all are I would say just do this ship it and move on and there's a",
    "start": "1155480",
    "end": "1162920"
  },
  {
    "text": "few reasons why I say that and the reason is the big one is most data is",
    "start": "1162920",
    "end": "1168080"
  },
  {
    "text": "never accessed meaning you know you're updating your profile you're updating this you're updating that and most data",
    "start": "1168080",
    "end": "1174830"
  },
  {
    "text": "if you kind of look at it statistically most of the time people are not reading that data so it makes sense to only use",
    "start": "1174830",
    "end": "1180500"
  },
  {
    "text": "your cache memory for stuff that people are actually interested in so by only populating it lazily when somebody",
    "start": "1180500",
    "end": "1186410"
  },
  {
    "text": "actually requests that value then they then your cache remains basically fairly",
    "start": "1186410",
    "end": "1191780"
  },
  {
    "text": "well optimized in terms of data that's important they said it ensures the cache also was filled",
    "start": "1191780",
    "end": "1197790"
  },
  {
    "text": "it's a slight variation actually this is a slightly different point so when",
    "start": "1197790",
    "end": "1203100"
  },
  {
    "text": "you're first launching a cash node that's just a big blank piece of memory you've got nothing in it so if you're",
    "start": "1203100",
    "end": "1209250"
  },
  {
    "text": "not doing lazy population if you're not having your app automatically kind of fill that cache up then when you spin that up you have to have some kind of",
    "start": "1209250",
    "end": "1215550"
  },
  {
    "text": "scripts or some kind of intelligence be able to figure out what to put in there and it's definitely doable and there's",
    "start": "1215550",
    "end": "1220560"
  },
  {
    "text": "reasons you would do that and we'll talk about that but in terms of just keeping it simple it's really nice to just have",
    "start": "1220560",
    "end": "1226050"
  },
  {
    "text": "a baseline layer that you know you just launch a node and it's just going to kind of fill up over time the more and more people are interested in data it's",
    "start": "1226050",
    "end": "1231750"
  },
  {
    "text": "gonna it's gonna wind up in cache and it's kind of just the hands-off slam-dunk approach right and closely",
    "start": "1231750",
    "end": "1238560"
  },
  {
    "text": "related to these is the fact that cache notes fail right and in addition to a cache node that you're manually spinning",
    "start": "1238560",
    "end": "1245340"
  },
  {
    "text": "up a new cache node cache know might just croak you might have to go in and replace it and in that case it will just",
    "start": "1245340",
    "end": "1251070"
  },
  {
    "text": "be lazily filled up as soon as it comes back online and the big downside to this",
    "start": "1251070",
    "end": "1256710"
  },
  {
    "text": "is the cache miss penalty which you're probably aware of but when a person",
    "start": "1256710",
    "end": "1262080"
  },
  {
    "text": "first comes to a site and they've got all these cache misses the page has the potential to look like it loads much",
    "start": "1262080",
    "end": "1268410"
  },
  {
    "text": "more slowly if they're coming out of cache you might have you know few milliseconds delay for each little piece",
    "start": "1268410",
    "end": "1274170"
  },
  {
    "text": "of cache but if you're checking cache and you're saying nope and then you're going back to the database and then you're saying okay and then you're",
    "start": "1274170",
    "end": "1279510"
  },
  {
    "text": "putting in the back in cache right you're basically doing three trips and then that can definitely impact you know",
    "start": "1279510",
    "end": "1284610"
  },
  {
    "text": "if you've got dozens of pieces on the page that you're doing that it can make the page load rather than you know maybe a few hundred milliseconds maybe it's a",
    "start": "1284610",
    "end": "1290850"
  },
  {
    "text": "few seconds now right but that being said it is the best approach for most",
    "start": "1290850",
    "end": "1295890"
  },
  {
    "text": "data just because the slam dunk is simple move on and so when you're doing these strategies start with this and",
    "start": "1295890",
    "end": "1302160"
  },
  {
    "text": "then build up from there so almost kind",
    "start": "1302160",
    "end": "1308130"
  },
  {
    "start": "1304000",
    "end": "1304000"
  },
  {
    "text": "of the reverse idea from lazy population is the idea of a write through cache that is you're making the choice to",
    "start": "1308130",
    "end": "1315630"
  },
  {
    "text": "actually write it to cache you know that the data is fresh you're putting that intelligence into your app so what does that look like in the simplest case",
    "start": "1315630",
    "end": "1321570"
  },
  {
    "text": "you're gonna save a user you do that update statement put it into your database or if you're using DynamoDB you",
    "start": "1321570",
    "end": "1327330"
  },
  {
    "text": "would you know put that key in there you do a set put into the cash we've returned the record",
    "start": "1327330",
    "end": "1332890"
  },
  {
    "text": "and once again your app doesn't care it says all right update this guy's name and then it can be used later on so the",
    "start": "1332890",
    "end": "1341850"
  },
  {
    "start": "1338000",
    "end": "1338000"
  },
  {
    "text": "advantage for right through caching is that it does ensure that your cache is",
    "start": "1341850",
    "end": "1347560"
  },
  {
    "text": "also always current which is not necessarily the case with a lazy approach will talk about TTLs but in the",
    "start": "1347560",
    "end": "1354370"
  },
  {
    "text": "example I showed you earlier you're just sticking something in cache you're not doing anything to expire it because so it's very possible that that data is",
    "start": "1354370",
    "end": "1361150"
  },
  {
    "text": "going to be out-of-date over time alright so there you have to have some kind of strategy for actually expiring that data and moving it out of cache",
    "start": "1361150",
    "end": "1367360"
  },
  {
    "text": "right through cache as sure as you absolutely have the most up-to-date data",
    "start": "1367360",
    "end": "1372780"
  },
  {
    "text": "and then there's also like the kind of nice part about the right penalty versus read penalty meaning if I'm going in if",
    "start": "1374280",
    "end": "1380710"
  },
  {
    "text": "I'm updating my record and I say oh you know I just updated my name I'm gonna expect as a user for the page to load a",
    "start": "1380710",
    "end": "1386230"
  },
  {
    "text": "little slower right like I'm updating data users have this idea that if they're changing something they're",
    "start": "1386230",
    "end": "1391330"
  },
  {
    "text": "actually saving it it could take a minute so that it's kind of a good trade-off there that you're not impacting a random user that comes to",
    "start": "1391330",
    "end": "1397390"
  },
  {
    "text": "your site and is all of a sudden seeing the page load a lot more slowly you're just penalizing the one guy that's actually making the change but it",
    "start": "1397390",
    "end": "1404860"
  },
  {
    "text": "has all the kind of reverse downsides that laziness solves which is that if you scale up then your cache is empty",
    "start": "1404860",
    "end": "1410980"
  },
  {
    "text": "and you also run the possibility to have it just a lot of data nobody cares about",
    "start": "1410980",
    "end": "1417070"
  },
  {
    "text": "cache churn is another way to say it we're just stuffing a whole bunch of data in there nobody's actually accessing it it's just taking up CPU and",
    "start": "1417070",
    "end": "1424120"
  },
  {
    "text": "memory so ultimately you really kind of still need the lazy fetch - all right so",
    "start": "1424120",
    "end": "1429880"
  },
  {
    "text": "it's talking about what was the saying like if you just start with one thing start with this start with that and then",
    "start": "1429880",
    "end": "1435160"
  },
  {
    "text": "build on that you still need the lazy fetch even if you're also doing right through caching so the way to use these",
    "start": "1435160",
    "end": "1440680"
  },
  {
    "text": "together is kind of like a combo move using a gaming term so you want to do",
    "start": "1440680",
    "end": "1446710"
  },
  {
    "start": "1444000",
    "end": "1444000"
  },
  {
    "text": "both right in a perfect world if you have the time and there's a lot of helpers out there in the frameworks",
    "start": "1446710",
    "end": "1451840"
  },
  {
    "text": "nowadays which is great but you want to be able to actually go and you want to be able to save the record and then kind",
    "start": "1451840",
    "end": "1461020"
  },
  {
    "text": "of talking about TTLs which we haven't talked about yet so we're gonna save the record we're",
    "start": "1461020",
    "end": "1466030"
  },
  {
    "text": "gonna get the user instead of so quick detour on TTL s so TTL is just you know",
    "start": "1466030",
    "end": "1472150"
  },
  {
    "text": "how long is that cache key gonna live simple concept so on here we're setting",
    "start": "1472150",
    "end": "1477430"
  },
  {
    "text": "it both when we're saving it and we're getting it back and the idea being is that in either case then the reason why",
    "start": "1477430",
    "end": "1483250"
  },
  {
    "text": "T TL helps us out in both cases is when we save the data we're saying it's going to expire after a certain amount of time",
    "start": "1483250",
    "end": "1489370"
  },
  {
    "text": "even though it is fresh now it might not be fresh later so then our lazy population can pick it up and refill it",
    "start": "1489370",
    "end": "1495460"
  },
  {
    "text": "which also helps in the case that a node goes down and needs to be repopulated right and then on the same token if we",
    "start": "1495460",
    "end": "1502780"
  },
  {
    "text": "actually do a get and the cache is empty because a node has been added or had to been replaced then it's still setting a",
    "start": "1502780",
    "end": "1508540"
  },
  {
    "text": "TTL again so then on a future lazy fetch then we can take advantage of it or on a right through we can also increment that",
    "start": "1508540",
    "end": "1514990"
  },
  {
    "text": "as well so I don't think I have a slide for it but I'll talk a little bit about TTLs there's a couple different",
    "start": "1514990",
    "end": "1521860"
  },
  {
    "text": "strategies for using TTL s one of them as shown here is just to set it to some",
    "start": "1521860",
    "end": "1528430"
  },
  {
    "text": "number of seconds and then the key gets flushed out and then it gets replaced that's a great strategy right nothing",
    "start": "1528430",
    "end": "1534310"
  },
  {
    "text": "wrong with that strategy another way that's like a little more advanced that has its applications most notably for",
    "start": "1534310",
    "end": "1541780"
  },
  {
    "text": "stuff that you kind of want to live for a while is you can set the TTL for a very long period of time okay and this",
    "start": "1541780",
    "end": "1548560"
  },
  {
    "text": "will come into as we talk about time to refresh on the next slide this will probably make more sense you can set the",
    "start": "1548560",
    "end": "1553720"
  },
  {
    "text": "TTL for say a very long period of time if you're talking about a record that maybe spans multiple users okay you say",
    "start": "1553720",
    "end": "1561070"
  },
  {
    "text": "okay top 10 leaderboard what I want to do is I want to set the TTL for you know",
    "start": "1561070",
    "end": "1566370"
  },
  {
    "text": "20 minutes even though I'm running a time to refresh every five minutes I",
    "start": "1566370",
    "end": "1571450"
  },
  {
    "text": "want the TTL to be 20 minutes so I'm going to be replacing the data every five minutes so the TTL might seem",
    "start": "1571450",
    "end": "1576700"
  },
  {
    "text": "extraneous well why would you have the TTL well the advantage of still having that long TTL is to catch application",
    "start": "1576700",
    "end": "1582490"
  },
  {
    "text": "bugs or something that crashes on your side your job ranker process crashes or",
    "start": "1582490",
    "end": "1587530"
  },
  {
    "text": "something else and it's not updating while you still then your cup your cache gets flushed and then the lazy",
    "start": "1587530",
    "end": "1593830"
  },
  {
    "text": "population aspect can actually refill that cache so these are strategies you kind of together and it depends on the different",
    "start": "1593830",
    "end": "1600090"
  },
  {
    "text": "type of data access and they're all kind of there's no one single like only do it",
    "start": "1600090",
    "end": "1605850"
  },
  {
    "text": "this way but through a combination of these different approaches it really helps optimize your cache and this is",
    "start": "1605850",
    "end": "1613110"
  },
  {
    "text": "just showing how it's abstracted away still same as before so last major strategy and then talk a little bit",
    "start": "1613110",
    "end": "1618510"
  },
  {
    "start": "1615000",
    "end": "1615000"
  },
  {
    "text": "about Redis and some other aspects of ElastiCache the time to refresh as I",
    "start": "1618510",
    "end": "1623940"
  },
  {
    "text": "mentioned leaderboard may be your your periodically updating the top hundred people maybe the most interesting news story stuff is trending up stuff that's",
    "start": "1623940",
    "end": "1631020"
  },
  {
    "text": "pending down you know top tweets or something like that it makes the most sense when you're spanning multiple",
    "start": "1631020",
    "end": "1636480"
  },
  {
    "text": "different records right that's kind of one of the key decision points here when you're spanning multiple different records pulling from all these different",
    "start": "1636480",
    "end": "1641880"
  },
  {
    "text": "sources that's a great time to use a timed refresh if you try to do that through lazy population or something",
    "start": "1641880",
    "end": "1648030"
  },
  {
    "text": "like that you're going to really impact a few users or maybe even does those or hundreds of users when they come and",
    "start": "1648030",
    "end": "1653040"
  },
  {
    "text": "that cache is empty and then all of a sudden you're having to make dozens and dozens of calls and rearrange stuff so a",
    "start": "1653040",
    "end": "1658530"
  },
  {
    "text": "timed refresh is definitely a great way to handle that kind of data top and list as I mentioned time intensive processes",
    "start": "1658530",
    "end": "1665970"
  },
  {
    "text": "especially if it's something that takes more than you know a few milliseconds if it's more than a database query if it's",
    "start": "1665970",
    "end": "1672240"
  },
  {
    "text": "actually like a take this and do select an order and etc that's a great candidate for time to refresh as well",
    "start": "1672240",
    "end": "1679490"
  },
  {
    "text": "trending items as I mentioned these are all great strategies and so the point of",
    "start": "1679490",
    "end": "1684630"
  },
  {
    "text": "this being there's just no one silver bullet right I can't give you a slide unfortunately says only do this your",
    "start": "1684630",
    "end": "1689970"
  },
  {
    "text": "caching will be good move on and then you're done it's really a combination of strategies",
    "start": "1689970",
    "end": "1695310"
  },
  {
    "text": "that depends on your data access patterns so with that covered off I want to kind of change gears slightly and",
    "start": "1695310",
    "end": "1701280"
  },
  {
    "text": "talk about another feature of ElastiCache which is monitoring and alerts make sure this doesn't happen to",
    "start": "1701280",
    "end": "1710490"
  },
  {
    "text": "you so as I mentioned monitoring ElastiCache integrates with cloud watch",
    "start": "1710490",
    "end": "1716850"
  },
  {
    "start": "1713000",
    "end": "1713000"
  },
  {
    "text": "cloud watch being our monitoring solution and there's a whole bunch of metrics that ElastiCache is feeding into",
    "start": "1716850",
    "end": "1723990"
  },
  {
    "text": "cloud watch constantly on your hits on your misses etc etc and so what you can",
    "start": "1723990",
    "end": "1730080"
  },
  {
    "text": "do is you can set up alarms on each of those and you can send them via email text you",
    "start": "1730080",
    "end": "1735330"
  },
  {
    "text": "can do programmatic stuff on it which we'll talk about so you could have an alarm that says you know hey based on",
    "start": "1735330",
    "end": "1742140"
  },
  {
    "text": "you know if I get this many cache misses then send me an alert because it probably means something's going wrong I shouldn't be you're having over X",
    "start": "1742140",
    "end": "1748710"
  },
  {
    "text": "percent of cache misses and the plug-in and the cloud watches how you accomplish that so two good ones to look at are",
    "start": "1748710",
    "end": "1756900"
  },
  {
    "text": "memory usage and evictions so memory usage is self-explanatory",
    "start": "1756900",
    "end": "1763400"
  },
  {
    "text": "so memory usage is just how much you're using it's not necessarily a good one to",
    "start": "1763400",
    "end": "1769470"
  },
  {
    "text": "do an alert on and the reason why is both memcache and Redis just expand to",
    "start": "1769470",
    "end": "1775170"
  },
  {
    "text": "fill all available memory like any good software program you know and so if you",
    "start": "1775170",
    "end": "1780660"
  },
  {
    "text": "do an alert and you say hey if memcache is using more than 90% of my memory please let me know it could be a great",
    "start": "1780660",
    "end": "1786480"
  },
  {
    "text": "situation that means a very optimal cache right you're using all your cache memory it's not really something you",
    "start": "1786480",
    "end": "1791850"
  },
  {
    "text": "want to learn on the evictions on the other hand is something that actually",
    "start": "1791850",
    "end": "1796920"
  },
  {
    "text": "says hey me is a process memcache Redis I'm actually out of memory I'm doing my",
    "start": "1796920",
    "end": "1804000"
  },
  {
    "text": "own memory allocation my slab allocate or what have you and I realize now that I don't have space for any more keys so",
    "start": "1804000",
    "end": "1810420"
  },
  {
    "text": "I had to flush a hundred out so evictions is one that is definitely a good idea to keep an eye on now there's",
    "start": "1810420",
    "end": "1817800"
  },
  {
    "text": "some more recent caching strategies actually rails for DHH - made a great",
    "start": "1817800",
    "end": "1822830"
  },
  {
    "text": "kind of blog post about Russian doll caching caching which is essentially",
    "start": "1822830",
    "end": "1828270"
  },
  {
    "text": "embedding as I mentioned there's different tiers right we've been talking about and when you talk about the",
    "start": "1828270",
    "end": "1834030"
  },
  {
    "text": "concept of partials HTML and such the you know challenge there is trying to figure out how that how does the overall",
    "start": "1834030",
    "end": "1840390"
  },
  {
    "text": "page expire right and when you're using Russian doll caching the the idea is",
    "start": "1840390",
    "end": "1846120"
  },
  {
    "text": "that you just don't care about whether or not you have excess stuff in your cache you just kind of keep filling it up and then let memcache flush it out",
    "start": "1846120",
    "end": "1852660"
  },
  {
    "text": "via evictions I think the jury's still out on how that's going to actually perform in production it's actually an",
    "start": "1852660",
    "end": "1859020"
  },
  {
    "text": "interesting strategy and you know the 37signals guys know what they're doing but at the same time",
    "start": "1859020",
    "end": "1865430"
  },
  {
    "text": "anytime you're doing evictions anytime you're doing cleanup then you have a background process is taking away",
    "start": "1865430",
    "end": "1870590"
  },
  {
    "text": "processing right and you can get spikes and latency if that's going through and saying oh you know let me look at the the least recently used the LRU keys let",
    "start": "1870590",
    "end": "1878630"
  },
  {
    "text": "me get those out of memory and so you're going through all this list and then that's taking away cycles that you could be using actually serving your cash so",
    "start": "1878630",
    "end": "1885650"
  },
  {
    "text": "long-winded way of saying evictions if you're using the kind of you know standard for lack of a better term or at",
    "start": "1885650",
    "end": "1892910"
  },
  {
    "text": "least the patterns we've been talking about thus far and then evictions you can probably learn on another fairly low",
    "start": "1892910",
    "end": "1898550"
  },
  {
    "text": "level right you could probably set an alarm on evictions for maybe ten or a hundred that would mean that you're",
    "start": "1898550",
    "end": "1904220"
  },
  {
    "text": "you're out of memory right if you're doing one of these you know Russian doll caching or one of these that actually",
    "start": "1904220",
    "end": "1909560"
  },
  {
    "text": "relies on the evictions that threshold could be higher so it's gonna vary a little bit you know me personally from a",
    "start": "1909560",
    "end": "1916100"
  },
  {
    "text": "gaming perspective Russian doll caching wouldn't have a lot of application if you're not familiar with it just google",
    "start": "1916100",
    "end": "1922700"
  },
  {
    "text": "and you'll be able to find write-ups on it so I would I would if I was setting it up for evictions I would probably set",
    "start": "1922700",
    "end": "1928340"
  },
  {
    "text": "a low level like a hundred if I'm getting a hundred evictions that means something is definitely wrong you send me alert to my email or phone or",
    "start": "1928340",
    "end": "1935090"
  },
  {
    "text": "whatever and we actually have some guidance on our documentation as well",
    "start": "1935090",
    "end": "1940550"
  },
  {
    "text": "these will be up on SlideShare so you'll be able to click on these actual links but that's the title of the article if",
    "start": "1940550",
    "end": "1946430"
  },
  {
    "text": "you just want to search for it as well we actually talked a little bit about each of these and say what are different",
    "start": "1946430",
    "end": "1951470"
  },
  {
    "text": "things to take into account when you're monitoring these so here's what the",
    "start": "1951470",
    "end": "1956990"
  },
  {
    "text": "actual cloud wash console looks like if you haven't seen it for ElastiCache at",
    "start": "1956990",
    "end": "1963800"
  },
  {
    "text": "least what it used to look like we just updated our cloud watch console so what I've done here is I've looked at my I've",
    "start": "1963800",
    "end": "1970010"
  },
  {
    "text": "gone into my my cash my cleverly named cash cluster and I've just selected both",
    "start": "1970010",
    "end": "1975050"
  },
  {
    "text": "of them so I get them both on a graph and what this graph shows is I'm using",
    "start": "1975050",
    "end": "1980120"
  },
  {
    "text": "the dollar client I'm using it with consistent hashing so I just started jamming a whole bunch of keys in there and as you can see the orange and blue",
    "start": "1980120",
    "end": "1987860"
  },
  {
    "text": "lines are pretty much the same which is a good sign that means I'm getting really good distribution across my two",
    "start": "1987860",
    "end": "1993020"
  },
  {
    "text": "nodes because I'm doing that and this shows you know CPU utilization Network bytes out another",
    "start": "1993020",
    "end": "2001299"
  },
  {
    "text": "metrics that are interesting you see that the free Apple memory there is declining she's getting not necessarily a bad thing right filling up your cache",
    "start": "2001299",
    "end": "2007570"
  },
  {
    "text": "memory is a good idea you're making best use of the instance so let's say I want",
    "start": "2007570",
    "end": "2012820"
  },
  {
    "text": "to send a learn on this what I actually do is I click on this view all which takes me to the cloud watch part of it",
    "start": "2012820",
    "end": "2018270"
  },
  {
    "text": "and then this is the create alarm wizard pane thing so first step is to go in",
    "start": "2018270",
    "end": "2026530"
  },
  {
    "text": "here and search for evictions that's what I'm going to trigger off you know I think it's a useful metric and then I",
    "start": "2026530",
    "end": "2032740"
  },
  {
    "text": "could see that it found my cache and have found the metric named evictions click continue",
    "start": "2032740",
    "end": "2039900"
  },
  {
    "text": "give it a name and description just say hey hi if Heike eviction rate and then",
    "start": "2039900",
    "end": "2045220"
  },
  {
    "text": "this is where I actually built the logic in right I say ok if it's greater than or equal to a hundred for five minutes then that means something's going quite",
    "start": "2045220",
    "end": "2051608"
  },
  {
    "text": "wrong with my cache I want to be notified continue to make this happen and then what I do is I subscribe it to",
    "start": "2051609",
    "end": "2060250"
  },
  {
    "text": "an SMS topic so way back when you know slide two or three when I was mentioning firing up the cache cluster I created",
    "start": "2060250",
    "end": "2066398"
  },
  {
    "text": "that SMS topic called cache alerts again very inventive name so my my cache",
    "start": "2066399",
    "end": "2072550"
  },
  {
    "text": "alerts topic then I subscribed this to that topic have to make sure to hit this add action button which is easy to miss",
    "start": "2072550",
    "end": "2079750"
  },
  {
    "text": "and then click continue and this is just a confirmation page and it shows hey yes",
    "start": "2079750",
    "end": "2087429"
  },
  {
    "text": "the metrics that's correct and then create alarm so the nice thing about routing it all to that one SNS",
    "start": "2087429",
    "end": "2093990"
  },
  {
    "text": "actual topic is that I can have one central place where I can route stuff I",
    "start": "2093990",
    "end": "2099130"
  },
  {
    "text": "can route stuff from there to my cell phone etc and then so automatic alerts that ElastiCache automatically sends",
    "start": "2099130",
    "end": "2105220"
  },
  {
    "text": "right in terms of node health issues or something like that or going to that topic stuff that I've set up myself is",
    "start": "2105220",
    "end": "2111220"
  },
  {
    "text": "also going to that topic and then I have one place where I can manage how I want to receive those alerts it's really",
    "start": "2111220",
    "end": "2116440"
  },
  {
    "text": "convenient so we're scaling up scaling down notes",
    "start": "2116440",
    "end": "2122369"
  },
  {
    "text": "adding and removing them I want to talk about how do you actually do no Discovery SMS topic as I mentioned and",
    "start": "2122369",
    "end": "2131809"
  },
  {
    "text": "then you can actually have your app listen for events on that topic you can have your app actually listen to an SMS",
    "start": "2131809",
    "end": "2138960"
  },
  {
    "text": "topic directly or you can do something like have it connected to an sqs queue",
    "start": "2138960",
    "end": "2144150"
  },
  {
    "text": "and have a background ec2 instance that's just listening for events on that queue and then taking action so these",
    "start": "2144150",
    "end": "2150059"
  },
  {
    "text": "two actions are kind of the biggies that means a new cache note has been added means the cache node has been removed",
    "start": "2150059",
    "end": "2156539"
  },
  {
    "text": "so there's situation you know you want to have some programming logic there in order to reconfigure your client app so",
    "start": "2156539",
    "end": "2163289"
  },
  {
    "text": "that that way it can connector or no longer connect to those cache nodes",
    "start": "2163289",
    "end": "2168529"
  },
  {
    "text": "we've configured connections just mention that and then you can of course set up event notifications again that's",
    "start": "2168529",
    "end": "2175200"
  },
  {
    "text": "a link to the documentation give us some more step-by-step here's how to actually set up sqs and SMS alerts and so what",
    "start": "2175200",
    "end": "2182789"
  },
  {
    "text": "does that look like graphically we've got our you know application here we've",
    "start": "2182789",
    "end": "2187799"
  },
  {
    "start": "2184000",
    "end": "2184000"
  },
  {
    "text": "got SMS which is our topic over the side new cache node comes online either because you know I got an alert spun it",
    "start": "2187799",
    "end": "2194250"
  },
  {
    "text": "up or whatever so SMS will actually deliver an alert in this case we're just",
    "start": "2194250",
    "end": "2199440"
  },
  {
    "text": "having the app directly listen to an SMS topic but again you could have an sqs queue and have a different ec2 instance",
    "start": "2199440",
    "end": "2206130"
  },
  {
    "text": "which is a very popular pattern for the sim simplicity of this slide I wanted to kind of like keep it simple so you",
    "start": "2206130",
    "end": "2211980"
  },
  {
    "text": "actually get an alert that says hey node was added and then you can have your app reconfigure say okay cool now I know",
    "start": "2211980",
    "end": "2218490"
  },
  {
    "text": "about this new cash node rinse repeat another note comes online same thing hey new node app reconfigures then it can",
    "start": "2218490",
    "end": "2225450"
  },
  {
    "text": "make use of the new cache what does that look like in code so no doubt of",
    "start": "2225450",
    "end": "2232440"
  },
  {
    "start": "2230000",
    "end": "2230000"
  },
  {
    "text": "discovery if you're using the site so",
    "start": "2232440",
    "end": "2238650"
  },
  {
    "text": "from a manual perspective you can just listen if you're programming and say Ruby or whatever language you can listen",
    "start": "2238650",
    "end": "2244859"
  },
  {
    "text": "for those events and then if you think back to that Ruby dalle example you would just have to have your application",
    "start": "2244859",
    "end": "2250740"
  },
  {
    "text": "code like reread like reinitialize the memcache do another memcache new if you will with a",
    "start": "2250740",
    "end": "2256420"
  },
  {
    "text": "new list of servers but we also support natively the ability for our PHP and",
    "start": "2256420",
    "end": "2261850"
  },
  {
    "text": "Java client libraries are kind of official ElastiCache libraries which are built on common open-source libraries",
    "start": "2261850",
    "end": "2269350"
  },
  {
    "text": "that are out there they just add a little extra functionality we actually support the ability to do auto discovery",
    "start": "2269350",
    "end": "2274360"
  },
  {
    "text": "so when those nodes come up your application can actually dynamically detect them and start using them if",
    "start": "2274360",
    "end": "2280360"
  },
  {
    "text": "you're using Java or PHP I would highly recommend you use the official ElastiCache library or at least evaluate",
    "start": "2280360",
    "end": "2287140"
  },
  {
    "text": "it see if it's going to work for you so encode the sorry wrong button",
    "start": "2287140",
    "end": "2293010"
  },
  {
    "text": "what that looks like is rather than taking the individual nodes when you're",
    "start": "2293010",
    "end": "2299380"
  },
  {
    "text": "configuring your Java or PHP library rather than taking the individual nodes you grab the configuration endpoint if",
    "start": "2299380",
    "end": "2306190"
  },
  {
    "text": "you look at the dashboard that's the one in the upper right hand corner that we clicked on to get that pop up rather",
    "start": "2306190",
    "end": "2312640"
  },
  {
    "text": "than clicking on it and then taking the DNS points will actually use that thing that we would click on copy paste that",
    "start": "2312640",
    "end": "2318270"
  },
  {
    "text": "and we're creating the actual memcache client we set up dynamic client mode",
    "start": "2318270",
    "end": "2325300"
  },
  {
    "text": "this is a PHP example obviously it says okay yes you're doing dynamic discovery I'm giving you the endpoint and then",
    "start": "2325300",
    "end": "2333070"
  },
  {
    "text": "from there on sorry glossed over that you adds you add the server which is",
    "start": "2333070",
    "end": "2338170"
  },
  {
    "text": "just that server endpoint the same thing I already talked about that's what the code looks like and then from there on you just set and get keys and literally",
    "start": "2338170",
    "end": "2345310"
  },
  {
    "text": "that's all you have to do the PHP client will detect when you add and remove nodes so it's very powerful very",
    "start": "2345310",
    "end": "2351730"
  },
  {
    "text": "convenient if you're not using PHP or Java then you would do just listening for those SNS events reconfiguring your",
    "start": "2351730",
    "end": "2358870"
  },
  {
    "text": "list of servers and you know reloading that handle to memcache all right so",
    "start": "2358870",
    "end": "2364180"
  },
  {
    "text": "that's kind of elastic cache functionality as a whole I want to talk about Redis with my favorite topic stay for the end so how does it compare to",
    "start": "2364180",
    "end": "2371140"
  },
  {
    "text": "memcache it's also in memory right it's got more advanced datatypes rather than",
    "start": "2371140",
    "end": "2376750"
  },
  {
    "text": "just set and get you can do stuff like lists you can do stuff like sorted sets which is really interesting for gaming",
    "start": "2376750",
    "end": "2382930"
  },
  {
    "text": "it's actually a set that it's pre sorted in real time so you can get a top 10 leaderboard and",
    "start": "2382930",
    "end": "2388630"
  },
  {
    "text": "I'll show you an example of that it's also got atomic operations on all of these data types which is the most",
    "start": "2388630",
    "end": "2394270"
  },
  {
    "text": "powerful part about it so if you think about the common case when you want to just add people to a list if you're",
    "start": "2394270",
    "end": "2402490"
  },
  {
    "text": "using a relational database you can get a little tricky right you have to do some certain locking to make sure you know different people aren't getting on",
    "start": "2402490",
    "end": "2407920"
  },
  {
    "text": "a list of cetera gets a little bit database intensive it can you know make",
    "start": "2407920",
    "end": "2413170"
  },
  {
    "text": "your database unhappy with Redis it's just these simple data types got a list you can just pop people onto that list",
    "start": "2413170",
    "end": "2419650"
  },
  {
    "text": "push them off like you would a data structure that was in memory it is single threaded so it doesn't have the",
    "start": "2419650",
    "end": "2427030"
  },
  {
    "text": "advantage to be able to take advantage of multiple cores like memcache Dita's doesn't make a huge impact in a lot of",
    "start": "2427030",
    "end": "2433690"
  },
  {
    "text": "real world users but there's something to be aware of because when you're talking from a monitoring perspective and we cover that in that link I showed",
    "start": "2433690",
    "end": "2439870"
  },
  {
    "text": "you about monitoring ElastiCache you'll see very different CPU performance out of memcache and Redis so it's something",
    "start": "2439870",
    "end": "2447280"
  },
  {
    "text": "that on memcache might look okay it could be a problem on Redis and vice-versa so that's that's covered in that link if you and again a few search",
    "start": "2447280",
    "end": "2454120"
  },
  {
    "text": "borders just called ElastiCache what what metrics should I monitor and it",
    "start": "2454120",
    "end": "2459490"
  },
  {
    "text": "does have persistence which is cool unlike memcache and it has the ability to do read replicas so here's an example",
    "start": "2459490",
    "end": "2467890"
  },
  {
    "start": "2467000",
    "end": "2467000"
  },
  {
    "text": "of leaderboards something you can't do with memcache so you can just add people to a sorted",
    "start": "2467890",
    "end": "2474850"
  },
  {
    "text": "set which is kind of like a pre sorted hash almost and you give it a numeric",
    "start": "2474850",
    "end": "2481240"
  },
  {
    "text": "value integer whatever and then you give it the key value and then when you do a",
    "start": "2481240",
    "end": "2486460"
  },
  {
    "text": "Redis operation ozzie rev-range is the technical actual operation you do it'll",
    "start": "2486460",
    "end": "2491710"
  },
  {
    "text": "give you that pre-sorted is sorted in real time it's a it's amazingly powerful if you're talking about hey give me",
    "start": "2491710",
    "end": "2497140"
  },
  {
    "text": "alert or give me a not alerts but the most recent events the people are doing give me an event stream give me stuff",
    "start": "2497140",
    "end": "2503680"
  },
  {
    "text": "that's trending give me the top hundred people there's a lot of power in this and that you can give a rank directly",
    "start": "2503680",
    "end": "2509470"
  },
  {
    "text": "for a person as well how's that translate to code and kind of in our",
    "start": "2509470",
    "end": "2514990"
  },
  {
    "start": "2511000",
    "end": "2511000"
  },
  {
    "text": "going back to our canonical example of saving a user we want to actually he just got a new score so we want to",
    "start": "2514990",
    "end": "2521210"
  },
  {
    "text": "update his score in the leaderboard that contacts Redis V ElastiCache get the",
    "start": "2521210",
    "end": "2527090"
  },
  {
    "text": "rank Z Rev rank plus 1 because 0 bounded then we can save a whole bunch of values",
    "start": "2527090",
    "end": "2533180"
  },
  {
    "text": "and we can get the rank for Barry so it's pretty cool if you're using Vettes already you're probably thinking yep I",
    "start": "2533180",
    "end": "2539060"
  },
  {
    "text": "know that and that's awesome if you haven't used Redis there's lots of applications for this highly recommend you check it out so Redis has the unique capability",
    "start": "2539060",
    "end": "2546860"
  },
  {
    "start": "2545000",
    "end": "2545000"
  },
  {
    "text": "within ElastiCache to do read replicas that memcache doesn't so when you",
    "start": "2546860",
    "end": "2553430"
  },
  {
    "text": "actually configure a Redis anode and ElastiCache you can set up a replication",
    "start": "2553430",
    "end": "2558740"
  },
  {
    "text": "group and that's what this shows and what that does with in elastic caches",
    "start": "2558740",
    "end": "2564050"
  },
  {
    "text": "that will actually replicate your data then from your main dear secondary node your replica and then if something fails",
    "start": "2564050",
    "end": "2570860"
  },
  {
    "text": "you can make use of the replicas so you haven't up to date copy of your data at least reasonably",
    "start": "2570860",
    "end": "2576470"
  },
  {
    "text": "up-to-date is a synchronous that's just the way Redis replication works similar to my sequel replication is asynchronous",
    "start": "2576470",
    "end": "2582440"
  },
  {
    "text": "so it's not a strict to guarantee that you're going to be up to date but you'll be pretty close and it's much better",
    "start": "2582440",
    "end": "2588500"
  },
  {
    "text": "than starting with a totally blank cache which is what would happen if you have a memcache node fail and if you really",
    "start": "2588500",
    "end": "2594619"
  },
  {
    "text": "want to get optimized II about the whole thing right you can set it up so all your rights go to your main node and all your reads come off there's a lot of",
    "start": "2594619",
    "end": "2601700"
  },
  {
    "text": "caveats there if you've ever tried to do this your data is always going to be just a little bit out of date sort of work for some data like if",
    "start": "2601700",
    "end": "2608330"
  },
  {
    "text": "you've got your top 10 leaderboards or whatever that would work here because maybe you're only refreshing it every five minutes if you're talking about hey",
    "start": "2608330",
    "end": "2614869"
  },
  {
    "text": "I want to get my up-to-date position in something probably not the best to do this because you're going to be a little bit out of date as a person goes page to",
    "start": "2614869",
    "end": "2621680"
  },
  {
    "text": "page through your app or through your website or whatever they're gonna get different data it could be a little confusing and so a few more topics here",
    "start": "2621680",
    "end": "2632440"
  },
  {
    "start": "2628000",
    "end": "2628000"
  },
  {
    "text": "reddish Arden it's the same concept of memcache we talked about earlier right is that consistent hashing distributed",
    "start": "2632440",
    "end": "2639890"
  },
  {
    "text": "across check your client library just make sure it supports it a lot of them do huge but in blinking red you cannot",
    "start": "2639890",
    "end": "2649550"
  },
  {
    "text": "shard those more advanced data types and Retta system possible it's the limitation of Redis",
    "start": "2649550",
    "end": "2655110"
  },
  {
    "text": "the reason why is because in order to do this real time in memory sorting you",
    "start": "2655110",
    "end": "2661020"
  },
  {
    "text": "need the entire thing in one in-memory structure right you can't do an in-memory sort across multiple nodes",
    "start": "2661020",
    "end": "2667050"
  },
  {
    "text": "right seam seems to make sense so when you talk about stuff like lists sorted",
    "start": "2667050",
    "end": "2673830"
  },
  {
    "text": "sets etc you're going to wind up instead of this very sharded horizontally just kind of automatic approach you need to",
    "start": "2673830",
    "end": "2679770"
  },
  {
    "text": "take a little bit more thoughtful approach and you're gonna have to start splitting things up by actual usage by",
    "start": "2679770",
    "end": "2687780"
  },
  {
    "text": "what they're actually trying to do and that's kind of our big anti pattern to this talk which is having dedicated",
    "start": "2687780",
    "end": "2694380"
  },
  {
    "start": "2690000",
    "end": "2690000"
  },
  {
    "text": "notes for different purposes when you're using reddit you would spawn multiple",
    "start": "2694380",
    "end": "2700290"
  },
  {
    "text": "nodes in that same pattern I showed but then rather than just spreading everything across them all you're gonna",
    "start": "2700290",
    "end": "2705900"
  },
  {
    "text": "need to have your application use them for different features so you might have one node that just does your leaderboards that way you can sort them",
    "start": "2705900",
    "end": "2712680"
  },
  {
    "text": "all in memory you're gonna have another node that maybe does all your counters the number of people that are in game or than other people that are on a given",
    "start": "2712680",
    "end": "2718800"
  },
  {
    "text": "site what-have-you those are all on one node anything where you have to do those kinds of operations on a single",
    "start": "2718800",
    "end": "2724290"
  },
  {
    "text": "structure they need to live on the same node now for any of the key value stuff you absolutely can still shard it across",
    "start": "2724290",
    "end": "2731220"
  },
  {
    "text": "so if you just said hey I just want to go all-in on reddit I don't want to manage memcache and Redis and do memcache for some stuff and Redis for",
    "start": "2731220",
    "end": "2737850"
  },
  {
    "text": "the other which completely makes sense a lot of people do that if they're using registers just use Redis for everything so you can absolutely spread across your",
    "start": "2737850",
    "end": "2744990"
  },
  {
    "text": "kind of standard key value stuff which is basically identical between memcache and Redis nowadays you can do TTLs you",
    "start": "2744990",
    "end": "2751500"
  },
  {
    "text": "can do set and get and conditionals all that stuff is basically identical so you can show that kind of stuff but not",
    "start": "2751500",
    "end": "2757020"
  },
  {
    "text": "those more advanced data structures where you're relying on sorting where you're relying on it for example",
    "start": "2757020",
    "end": "2762030"
  },
  {
    "text": "enforcing uniqueness which is what Redis sets do they force you know uniqueness for example so what is the dedicated",
    "start": "2762030",
    "end": "2770160"
  },
  {
    "text": "Redis node concept anti-pattern look like so we're adding more cache nodes",
    "start": "2770160",
    "end": "2776280"
  },
  {
    "text": "kind of look similar to the memcache example but rather than those being you",
    "start": "2776280",
    "end": "2782490"
  },
  {
    "text": "know you can see at the bottom some of you in the back might not see it just rather than those be just all the same we're gonna dedicate",
    "start": "2782490",
    "end": "2789299"
  },
  {
    "text": "those in our app code to say hey this is just for leaderboards this is just for counters and then either any of these can then be put in a",
    "start": "2789299",
    "end": "2797280"
  },
  {
    "text": "replication group as well right so if you can imagine this replication group being on all three of those main nodes",
    "start": "2797280",
    "end": "2802559"
  },
  {
    "text": "you can have essentially different vertical slices of stuff you're doing with your application each with a master",
    "start": "2802559",
    "end": "2808680"
  },
  {
    "text": "and a replica and it's great I mean it's a great way to have that data there have it fresh have it available also wrapping",
    "start": "2808680",
    "end": "2815819"
  },
  {
    "text": "up and hopefully have a few minutes here for questions so caching is good do",
    "start": "2815819",
    "end": "2822839"
  },
  {
    "start": "2821000",
    "end": "2821000"
  },
  {
    "text": "caching right really getting really good at it is difficult there's no silver",
    "start": "2822839",
    "end": "2827849"
  },
  {
    "text": "bullet there's no any one thing you can do hopefully this gives you some ideas some insights and different patterns you",
    "start": "2827849",
    "end": "2834210"
  },
  {
    "text": "can use mix-and-match ElastiCache helps with the deployment aspects of it",
    "start": "2834210",
    "end": "2840480"
  },
  {
    "text": "simplifies a lot of that alerting you're still going to have to take steps to then make use of good caching strategies",
    "start": "2840480",
    "end": "2845490"
  },
  {
    "text": "and try to share some of those with you today we support memcache your Redis out of the box and then keep an eye on this",
    "start": "2845490",
    "end": "2852720"
  },
  {
    "text": "space we're definitely looking at really doing some cool things with caching and along those lines as I'm sure you've",
    "start": "2852720",
    "end": "2858210"
  },
  {
    "text": "heard ad nauseam at this point we're a very customer centric company sincerely we thrive on customer feedback so if",
    "start": "2858210",
    "end": "2865410"
  },
  {
    "text": "you're doing a lot of caching you have feedback your Redis fan and you want to give us input we'd love to hear it what",
    "start": "2865410",
    "end": "2870480"
  },
  {
    "text": "you'd like from ElastiCache going forward all right cool Thanks that's my",
    "start": "2870480",
    "end": "2875790"
  },
  {
    "text": "talk",
    "start": "2875790",
    "end": "2877849"
  },
  {
    "text": "so we got a few minutes for questions try to see over the blaring lights here",
    "start": "2881950",
    "end": "2888510"
  },
  {
    "text": "yes I'm the front persistance oh sure",
    "start": "2888510",
    "end": "2897520"
  },
  {
    "text": "so the question was talked about persistence for Redis how does Redis implement persistence yeah kind of failed to mention that so there's two",
    "start": "2897520",
    "end": "2903940"
  },
  {
    "text": "different strategies that Redis does for persistence one of them is called our DB",
    "start": "2903940",
    "end": "2909880"
  },
  {
    "text": "or BG save there was the original one essentially what that is is that on a time interval say every 60 seconds or",
    "start": "2909880",
    "end": "2916030"
  },
  {
    "text": "three minutes whatever you configure it just takes whatever is in memory and snapshots it to disk okay the other",
    "start": "2916030",
    "end": "2923770"
  },
  {
    "text": "strategy is called AOF or append only file that came later and what that does",
    "start": "2923770",
    "end": "2929170"
  },
  {
    "text": "is it's much more like a database redo log that is every single thing that you put into Redis it actually writes to",
    "start": "2929170",
    "end": "2934390"
  },
  {
    "text": "disk so that way you have a full log of the transactions AOF is what ElastiCache",
    "start": "2934390",
    "end": "2939940"
  },
  {
    "text": "implements if you're doing it on your own you would have the choice of doing either one a AOF offers a little bit",
    "start": "2939940",
    "end": "2945070"
  },
  {
    "text": "better resilience you don't have a time window where you when you can lose data so those are the two strategies that the",
    "start": "2945070",
    "end": "2951730"
  },
  {
    "text": "Redis uses yeah question",
    "start": "2951730",
    "end": "2956070"
  },
  {
    "text": "yeah good question so the question was given that memcache is multi-threaded and Redis a single-threaded how does it",
    "start": "2962270",
    "end": "2969450"
  },
  {
    "text": "impact the types of instances you might choose for either engine it is a great question if you look at I think the",
    "start": "2969450",
    "end": "2975570"
  },
  {
    "text": "driving factor for instance selection at least currently with the way that the platform works with ElastiCache is",
    "start": "2975570",
    "end": "2981570"
  },
  {
    "text": "really going to be the amount of memory that's available on an instance is figuring out like how much memory you actually need on a given instance",
    "start": "2981570",
    "end": "2987450"
  },
  {
    "text": "specifically for Redis so if even if you're trying to say okay well I don't need four CPUs for example but I need",
    "start": "2987450",
    "end": "2994110"
  },
  {
    "text": "you know 200 gigs or whatever of memory you're gonna kind of be bound you know we have a good amount you know a good",
    "start": "2994110",
    "end": "2999750"
  },
  {
    "text": "variety to choose from but at some point if you need to fit an entire you know 10 million people in one memory image you're kind of just gonna have to go",
    "start": "2999750",
    "end": "3006140"
  },
  {
    "text": "with that biggest instance so in an instance selection for memcache you can kind of just engage it based on what you",
    "start": "3006140",
    "end": "3012500"
  },
  {
    "text": "want fewer nodes or more nodes and how much you want to scale in or scale out so that's kind of the decision point",
    "start": "3012500",
    "end": "3017840"
  },
  {
    "text": "there with Redis it's gonna be bound on how much data how much space do you need for your data so yeah question that is a",
    "start": "3017840",
    "end": "3033500"
  },
  {
    "text": "good question honestly I do not know the answer to and the reason why I don't know the answer to that is actually ElastiCache takes care of managing that",
    "start": "3033500",
    "end": "3039860"
  },
  {
    "text": "for you I don't know if under the hood if it's using EBS or if it's using ephemeral with snapshots s3 you know both of them",
    "start": "3039860",
    "end": "3045620"
  },
  {
    "text": "work well I don't know what it's actually doing yeah it takes care of managing the persistence for you so",
    "start": "3045620",
    "end": "3051040"
  },
  {
    "text": "other questions yes I'm back",
    "start": "3051040",
    "end": "3055810"
  },
  {
    "text": "now yeah a good question so the question is since you can't shard the advanced types with Redis how do you handle the",
    "start": "3062280",
    "end": "3069220"
  },
  {
    "text": "case when it's actually filling up so really your only option and this is not you know I think with ElastiCache is",
    "start": "3069220",
    "end": "3075100"
  },
  {
    "text": "just you know the way memory works is to go to a bigger instance at that point and so you can go through ElastiCache",
    "start": "3075100",
    "end": "3080170"
  },
  {
    "text": "where you can allocate a new instance that would be larger and then it would be a matter of actually populating that data i don't know offhand whether you",
    "start": "3080170",
    "end": "3087310"
  },
  {
    "text": "know whether or not you can mix and match right now I know that there's new innovation we're looking to push in that place in terms of being able to make",
    "start": "3087310",
    "end": "3092830"
  },
  {
    "text": "that more seamless for you but right now the procedure would be to do a bigger instance and then essentially move over",
    "start": "3092830",
    "end": "3098590"
  },
  {
    "text": "to it that's your solution yeah",
    "start": "3098590",
    "end": "3102870"
  },
  {
    "text": "right yes so the question is if you want to use Redis in both ways if you want to both have the big single memory image",
    "start": "3111710",
    "end": "3117930"
  },
  {
    "text": "for some of your stuff but also do the shard of key value just so you're only have one Tek how would you set it up yeah if it were me I would do just",
    "start": "3117930",
    "end": "3124890"
  },
  {
    "text": "separate nodes of maybe a smaller instance type for all the key value stuff and just shard it across those and",
    "start": "3124890",
    "end": "3130620"
  },
  {
    "text": "then have a separate you know one or two or have many end nodes you need handle the big structures that you can't shard",
    "start": "3130620",
    "end": "3136620"
  },
  {
    "text": "out yeah I wouldn't try to mix them and match them on the same instance I would keep those two separate yeah question",
    "start": "3136620",
    "end": "3143450"
  },
  {
    "text": "yeah great question so currently the way it works is that each node is going to replicate independently so it would be",
    "start": "3152930",
    "end": "3159770"
  },
  {
    "text": "possible that you would have slightly different stuff in the replicas of a given piece of time again if you're following that pattern and you're doing",
    "start": "3159770",
    "end": "3165470"
  },
  {
    "text": "the lazy population and all that kind of stuff when you're talking about starting those the key value space that that use",
    "start": "3165470",
    "end": "3171650"
  },
  {
    "text": "case then that'll just kind of work itself out in the case that you have to fail over to a replica okay you've",
    "start": "3171650",
    "end": "3178130"
  },
  {
    "text": "probably got time for one last question all right yeah across a Z yeah in terms",
    "start": "3178130",
    "end": "3188420"
  },
  {
    "text": "of the replicas in terms of right so so",
    "start": "3188420",
    "end": "3195830"
  },
  {
    "text": "ElastiCache is very similar to RDS in the relational database service and then it you know helps the management aspect",
    "start": "3195830",
    "end": "3202490"
  },
  {
    "text": "but ultimately you're deploying a node in a given availability zone so when you're deploying it you can choose which availability zone or zones to push your",
    "start": "3202490",
    "end": "3209150"
  },
  {
    "text": "different nodes in but yeah that's not it's not like dynamodb which is a fully managed service up at that layer where",
    "start": "3209150",
    "end": "3215180"
  },
  {
    "text": "it's kind of a black box this is more a convenient way to manage that but you're still choosing where to push your cache nodes so I think that's all the time for",
    "start": "3215180",
    "end": "3221900"
  },
  {
    "text": "general questions feel free to grab me though after thanks a lot appreciate it",
    "start": "3221900",
    "end": "3226750"
  },
  {
    "text": "good",
    "start": "3229000",
    "end": "3232000"
  }
]
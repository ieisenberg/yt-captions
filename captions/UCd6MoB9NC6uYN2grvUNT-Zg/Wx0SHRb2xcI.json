[
  {
    "start": "0",
    "end": "86000"
  },
  {
    "text": "all right welcome to the micro service and service observability talk everybody",
    "start": "0",
    "end": "5670"
  },
  {
    "text": "thanks for showing up my name is clay Smith I'm a developer advocate in New Relic and really excited to be talking",
    "start": "5670",
    "end": "11849"
  },
  {
    "text": "about this especially with the announcements this morning around faregates and cabrillo days for ECS a",
    "start": "11849",
    "end": "19470"
  },
  {
    "text": "new relic if you don't know us we have a number of different solutions for monitoring and having Analects around",
    "start": "19470",
    "end": "25260"
  },
  {
    "text": "solutions that run on the cloud or on prim and because of that we've been talking to a lot of our customers the",
    "start": "25260",
    "end": "31410"
  },
  {
    "text": "past year and a half and we've seen a massive amount of interest in serverless compute technology specifically AWS",
    "start": "31410",
    "end": "39030"
  },
  {
    "text": "lambda and the the purpose or the inspiration behind this talk was we've",
    "start": "39030",
    "end": "44550"
  },
  {
    "text": "seen this pattern over and over again that as people move to service computing",
    "start": "44550",
    "end": "49890"
  },
  {
    "text": "architectures the focus for this talk later will be specifically lambda but just in general a lot of the assumptions",
    "start": "49890",
    "end": "57210"
  },
  {
    "text": "and best practices in playbooks for monitoring those workloads in those serverless compute environments it does",
    "start": "57210",
    "end": "63420"
  },
  {
    "text": "change and with that in mind this talk really tries get into that a bit and",
    "start": "63420",
    "end": "68909"
  },
  {
    "text": "we'll wrap up with the lambda case study we were running headless chrome and a",
    "start": "68909",
    "end": "74580"
  },
  {
    "text": "Miss lambda and learned some interesting performance things around that and then Marcus Ervin will join us the end for",
    "start": "74580",
    "end": "80460"
  },
  {
    "text": "Q&A on a recent recent project his team just launched in production sort of jump",
    "start": "80460",
    "end": "87710"
  },
  {
    "start": "86000",
    "end": "148000"
  },
  {
    "text": "right in observability has been discussed a lot especially if you follow",
    "start": "87710",
    "end": "94049"
  },
  {
    "text": "the monitoring people on twitter the clearest definition and I and why I think it is important is that it gets to",
    "start": "94049",
    "end": "100979"
  },
  {
    "text": "an idea that's not necessarily monitoring but it's a good conversation starter and specifically it has this",
    "start": "100979",
    "end": "107759"
  },
  {
    "text": "focus on how well do we understand the workloads that we're running in the cloud or on prim from the work they do",
    "start": "107759",
    "end": "114479"
  },
  {
    "text": "and how good is that and can we make it better to ultimately make the systems we",
    "start": "114479",
    "end": "119790"
  },
  {
    "text": "build a design better as well and so observability whether you like the term or not or just want to call it",
    "start": "119790",
    "end": "125640"
  },
  {
    "text": "monitoring that's not necessarily the the key point or takeaway but I think it's a really important discussion",
    "start": "125640",
    "end": "130979"
  },
  {
    "text": "especially as we look these new software architectures like lambda or consider or try and build some",
    "start": "130979",
    "end": "137910"
  },
  {
    "text": "sort of next generation system so observability I think is really nice for at least starting the conversation",
    "start": "137910",
    "end": "143700"
  },
  {
    "text": "around how well do you understand what's actually going on in these environments",
    "start": "143700",
    "end": "148850"
  },
  {
    "start": "148000",
    "end": "196000"
  },
  {
    "text": "related and I think also really important is this idea of instrumentation so we have workloads",
    "start": "148850",
    "end": "155160"
  },
  {
    "text": "running in some service whether it's a traditional VM or something next-generation like far gate how do we",
    "start": "155160",
    "end": "161970"
  },
  {
    "text": "understand what that code is actually doing when it's actually responding to an active request and instrumentation",
    "start": "161970",
    "end": "168120"
  },
  {
    "text": "not a new idea at all but it just gets this idea of what events we want to",
    "start": "168120",
    "end": "173220"
  },
  {
    "text": "measure in code to understand what that code is actually doing in production responding to a real request and so",
    "start": "173220",
    "end": "180090"
  },
  {
    "text": "these this idea of observability and instrumentation I think it's coming up a lot more especially when we talk about",
    "start": "180090",
    "end": "186810"
  },
  {
    "text": "lambda and have container orchestration systems because it gets two really important ideas of actually",
    "start": "186810",
    "end": "192840"
  },
  {
    "text": "understanding what's going on in the first place the agenda for this talk and",
    "start": "192840",
    "end": "198870"
  },
  {
    "start": "196000",
    "end": "244000"
  },
  {
    "text": "where we'll go where we're gonna go here the first bit is really a discussion of",
    "start": "198870",
    "end": "204720"
  },
  {
    "text": "a lot of the architectures we see different customers moving to since this is a server list track talk a lot of",
    "start": "204720",
    "end": "212010"
  },
  {
    "text": "that should be familiar we will go then into kind of the role",
    "start": "212010",
    "end": "218310"
  },
  {
    "text": "different data types play in understanding new architectures and potentially how that's different from older legacy architectures we'll end up",
    "start": "218310",
    "end": "225540"
  },
  {
    "text": "with some just kind of higher level requirements and then from there and this is kind of the more fun part we're",
    "start": "225540",
    "end": "231989"
  },
  {
    "text": "actually going to try and put some of those in practice looking at a large lambda function and then lastly we'll be",
    "start": "231989",
    "end": "238320"
  },
  {
    "text": "talking with with Marcus with a QA and there'll be time for audience questions at the end too so stay tuned at the this",
    "start": "238320",
    "end": "247230"
  },
  {
    "start": "244000",
    "end": "341000"
  },
  {
    "text": "talk the AWS reinvent talks of get prepared for all speakers pretty long in",
    "start": "247230",
    "end": "253440"
  },
  {
    "text": "advance so in the spring of this year there was a little bit of a side project of trying to understand the history of",
    "start": "253440",
    "end": "260100"
  },
  {
    "text": "monitoring are kind of where we came from and it turns out that all of the IBM system/360 manuals have actually",
    "start": "260100",
    "end": "266220"
  },
  {
    "text": "been and or online and so the really interesting question was well how has",
    "start": "266220",
    "end": "271370"
  },
  {
    "text": "monitoring changed from the late 60s when you were wearing a lab coat looking at a mainframe and surprisingly two",
    "start": "271370",
    "end": "278099"
  },
  {
    "text": "things stuck out that are mostly the same at least kind of in practice one you want to have visibility into in the",
    "start": "278099",
    "end": "286949"
  },
  {
    "text": "different execution paths so the mainframe does something you want to know what happens along different paths",
    "start": "286949",
    "end": "292560"
  },
  {
    "text": "that's still true today and then in the event of a failure IBM system/360 would",
    "start": "292560",
    "end": "297840"
  },
  {
    "text": "actually print out the entire contents of memory for debugging and so this idea of a stack trace or understanding the",
    "start": "297840",
    "end": "304680"
  },
  {
    "text": "state of the program when it failed that's also true too there was some patch card stuff that we",
    "start": "304680",
    "end": "309870"
  },
  {
    "text": "obviously no longer use though so yes the workplace has changed we don't to",
    "start": "309870",
    "end": "315210"
  },
  {
    "text": "wear lab coats anymore but the architectures themselves have obviously",
    "start": "315210",
    "end": "320610"
  },
  {
    "text": "evolved very quickly - we're looking at things on mobile edge computing IOT /",
    "start": "320610",
    "end": "326610"
  },
  {
    "text": "the keynotes announcements today but I think that same desire or that same necessity as an operator or developer to",
    "start": "326610",
    "end": "334349"
  },
  {
    "text": "know what the state of the program is during its execution that still is the same many years later one of the most",
    "start": "334349",
    "end": "344250"
  },
  {
    "start": "341000",
    "end": "399000"
  },
  {
    "text": "common patterns we've seen our customers migrates here the past few years is it's",
    "start": "344250",
    "end": "351060"
  },
  {
    "text": "not a surprising one for anyone here it's this idea of taking a very large monolithic application we see a lot of",
    "start": "351060",
    "end": "357840"
  },
  {
    "text": "these written in Java and you're gonna break into parts and in different ways into either SOA or micro services what",
    "start": "357840",
    "end": "366479"
  },
  {
    "text": "gets really interesting though especially with the growth and different AWS managed services is that as you",
    "start": "366479",
    "end": "372840"
  },
  {
    "text": "decompose a monolith into different micro services a lot of those components might just be fully managed AWS services",
    "start": "372840",
    "end": "380330"
  },
  {
    "text": "different AI tools things like in Candido and I think that's really",
    "start": "380330",
    "end": "385409"
  },
  {
    "text": "interesting because even though you might be running your own code that code is now interacting with AWS managed",
    "start": "385409",
    "end": "392279"
  },
  {
    "text": "services and the monitoring or visibility requirements are slightly different when you're looking at those",
    "start": "392279",
    "end": "398279"
  },
  {
    "text": "interactions the other the other thing that's pretty",
    "start": "398279",
    "end": "403890"
  },
  {
    "start": "399000",
    "end": "451000"
  },
  {
    "text": "interesting too is that we see more customers deploying to more than one",
    "start": "403890",
    "end": "409290"
  },
  {
    "text": "80's region not necessarily a super surprising trends but we recently did just last week a study of everyone using",
    "start": "409290",
    "end": "417060"
  },
  {
    "text": "our alias lambda integration and we found that generally people that were using lambda different accounts that",
    "start": "417060",
    "end": "423480"
  },
  {
    "text": "we're using lambda functions that were monitored with new relic were deployed in a single AWS region but there was a",
    "start": "423480",
    "end": "429300"
  },
  {
    "text": "really interesting percentage of accounts that were deployed in many many regions slightly less than 1% a single",
    "start": "429300",
    "end": "437730"
  },
  {
    "text": "account we're running lambdas in around nine different AWS regions so it's really I",
    "start": "437730",
    "end": "443669"
  },
  {
    "text": "think opening up some really fascinating use cases around people running code and multiple regions around the world for",
    "start": "443669",
    "end": "449910"
  },
  {
    "text": "different reasons and lastly with the improvements we've seen recently to",
    "start": "449910",
    "end": "456060"
  },
  {
    "start": "451000",
    "end": "478000"
  },
  {
    "text": "lambda at edge we can now run more complex workloads directly on the edge",
    "start": "456060",
    "end": "461190"
  },
  {
    "text": "in lambda functions the compute is it getting physically closer to customers",
    "start": "461190",
    "end": "466500"
  },
  {
    "text": "and obviously IOT is kind of an extension of that as well so globally distributed it's getting closer to",
    "start": "466500",
    "end": "472950"
  },
  {
    "text": "customers and we're having more components to play with the switch to SOA or micro services on top of all that",
    "start": "472950",
    "end": "481370"
  },
  {
    "start": "478000",
    "end": "533000"
  },
  {
    "text": "the compute workloads themselves are fairly short-lived we new relic monitors",
    "start": "481370",
    "end": "490320"
  },
  {
    "text": "docker containers and we did a study in early spring of this year of what's the",
    "start": "490320",
    "end": "495870"
  },
  {
    "text": "lifetime of those containers so how long does the docker container actually stick around this is the distribution sorry",
    "start": "495870",
    "end": "501870"
  },
  {
    "text": "for the lack of labels on the graph but it's from one to 100 minutes in 1 minute buckets and you can see here from this",
    "start": "501870",
    "end": "508740"
  },
  {
    "text": "this heavy the distribution is is very",
    "start": "508740",
    "end": "513839"
  },
  {
    "text": "short-lived so the median is around a couple of minutes and that's really interesting because as people move to",
    "start": "513839",
    "end": "520800"
  },
  {
    "text": "these new environments they're not necessarily doing this not necessarily lifting and shifting in the existing",
    "start": "520800",
    "end": "526980"
  },
  {
    "text": "application architecture and do a large container it's scaling up and down and those containers are very short-lived",
    "start": "526980",
    "end": "532500"
  },
  {
    "text": "so kind of interesting there all-in-all more people tell us or say something",
    "start": "532500",
    "end": "539519"
  },
  {
    "start": "533000",
    "end": "569000"
  },
  {
    "text": "along the lines that they're running something that resembles or looks a lot like a very complex distributed system",
    "start": "539519",
    "end": "544800"
  },
  {
    "text": "this is just the service map service maps or diagrams of relationships",
    "start": "544800",
    "end": "550199"
  },
  {
    "text": "between services are always good for defending how complex your distributed system is Netflix probably has the most",
    "start": "550199",
    "end": "556769"
  },
  {
    "text": "famous one I think they call it the Deathstar diagram this is a much simpler one but I guess is the same idea that we",
    "start": "556769",
    "end": "562709"
  },
  {
    "text": "have a simple web application here that has a database and as a mobile web app but the number of components continues",
    "start": "562709",
    "end": "568290"
  },
  {
    "text": "to grow I think the good news here and",
    "start": "568290",
    "end": "574410"
  },
  {
    "start": "569000",
    "end": "642000"
  },
  {
    "text": "historically we tend to get better at operating in these kinds of environments it's not a hopeless situation people",
    "start": "574410",
    "end": "582329"
  },
  {
    "text": "there there certainly challenges in building and designing and operating software that's globally distributed in",
    "start": "582329",
    "end": "587850"
  },
  {
    "text": "ephemeral components using hybrid architectures but generally we know that",
    "start": "587850",
    "end": "593189"
  },
  {
    "text": "we do get better at it over time and I think a really key part of that and one thing that helps a lot is having data to",
    "start": "593189",
    "end": "599939"
  },
  {
    "text": "actually help through that process and the technical reasons aren't necessarily all that's surprising obviously having",
    "start": "599939",
    "end": "607680"
  },
  {
    "text": "good data and visibility helps with debugging and troubleshooting just like IBM system/360 knowing the state of the",
    "start": "607680",
    "end": "613889"
  },
  {
    "text": "program when it fails pretty useful much earlier in the process before you're",
    "start": "613889",
    "end": "619529"
  },
  {
    "text": "even writing a line of code having data to validate designs so based on previous",
    "start": "619529",
    "end": "625439"
  },
  {
    "text": "systems using that operational data to inform the design of next generation or new systems what actually works what",
    "start": "625439",
    "end": "631589"
  },
  {
    "text": "should we build reducing defects caching the issues before they become a serious",
    "start": "631589",
    "end": "638189"
  },
  {
    "text": "problem and ultimately for the business using all that to move faster and that's",
    "start": "638189",
    "end": "644939"
  },
  {
    "start": "642000",
    "end": "664000"
  },
  {
    "text": "moving faster gets in this idea of cultural shifts and that's some how can",
    "start": "644939",
    "end": "650220"
  },
  {
    "text": "the data actually help people work together on a team and the one thing we hear a lot about and this is very",
    "start": "650220",
    "end": "656370"
  },
  {
    "text": "related to DevOps there's this idea of building transparency across teams having that shared reference points",
    "start": "656370",
    "end": "662660"
  },
  {
    "text": "especially when the components are fairly complex and moving to this model where decisions",
    "start": "662660",
    "end": "667730"
  },
  {
    "start": "664000",
    "end": "713000"
  },
  {
    "text": "are data informed and not necessarily driven by guessing or kind of picking the newest trendy framework one thing",
    "start": "667730",
    "end": "676130"
  },
  {
    "text": "that's really important I think for people in practitioner roles is the ability to have freedom to experiment try new architectures try new ways of",
    "start": "676130",
    "end": "683420"
  },
  {
    "text": "doing things but not necessarily being prevented from doing that because there's some you know",
    "start": "683420",
    "end": "689360"
  },
  {
    "text": "white paper that's it insists that there must be there must be a single process for doing it correctly and lastly we get",
    "start": "689360",
    "end": "697130"
  },
  {
    "text": "to the kind of more of the post-mortem situations where when things do break that's it's not necessarily the fault of",
    "start": "697130",
    "end": "705140"
  },
  {
    "text": "one individual or one change it's a complex system there's there's really no no blame that can be associated with one",
    "start": "705140",
    "end": "712310"
  },
  {
    "text": "person so between all that I think we get to this idea in order to get to that",
    "start": "712310",
    "end": "717860"
  },
  {
    "start": "713000",
    "end": "733000"
  },
  {
    "text": "good data in order to actually understand what these workloads are doing regardless of whether they run in",
    "start": "717860",
    "end": "723050"
  },
  {
    "text": "lambda or kubernetes cluster how do we actually understand what it's doing and",
    "start": "723050",
    "end": "729380"
  },
  {
    "text": "I think instrumentation is a really key part of that the the really interesting",
    "start": "729380",
    "end": "736490"
  },
  {
    "start": "733000",
    "end": "780000"
  },
  {
    "text": "question and and the thing that I've been working on especially with a double slam de the past years so is you know",
    "start": "736490",
    "end": "745250"
  },
  {
    "text": "assuming we believe that data is important I think that's that's a good",
    "start": "745250",
    "end": "750920"
  },
  {
    "text": "place to start and that instrumentation that helps us get better visibility into workloads as they run in new things specifically in",
    "start": "750920",
    "end": "758630"
  },
  {
    "text": "the Animas lambda environments or with different emerging micro service",
    "start": "758630",
    "end": "764360"
  },
  {
    "text": "architectures Fargate obviously is the newest one as of this morning how do we actually make that code",
    "start": "764360",
    "end": "771350"
  },
  {
    "text": "observer bill observable how do we actually know what it does and and how it works we've kind of broken it down",
    "start": "771350",
    "end": "778400"
  },
  {
    "text": "into three different requirements and the first one of course is that's there",
    "start": "778400",
    "end": "783770"
  },
  {
    "start": "780000",
    "end": "865000"
  },
  {
    "text": "are different data types available for these different systems and logging is",
    "start": "783770",
    "end": "788870"
  },
  {
    "text": "great metrics are great traces are useful but over reliance on one we find",
    "start": "788870",
    "end": "795110"
  },
  {
    "text": "typically misses some opportunities and actually understanding how the system works a good example would be metrics so if",
    "start": "795110",
    "end": "801680"
  },
  {
    "text": "you want to answer the question is my response time slower this week or last week metrics are great for answering",
    "start": "801680",
    "end": "808220"
  },
  {
    "text": "that question you have a Vince with the measurements over some time series and you can answer that pretty easily if",
    "start": "808220",
    "end": "813410"
  },
  {
    "text": "you're measuring response time in the first place logs of course the raw human readable machine data useful for debugging so if",
    "start": "813410",
    "end": "820939"
  },
  {
    "text": "the database won't start on a server you'll inevitably be looking at logs and traces and traces I think are especially",
    "start": "820939",
    "end": "828350"
  },
  {
    "text": "interesting with lambda and different micro service architectures because they're actually establishing a",
    "start": "828350",
    "end": "834050"
  },
  {
    "text": "relationship between events on different systems so it can answer things like what are the dependencies or even for a",
    "start": "834050",
    "end": "840740"
  },
  {
    "text": "single request for a single service what's the breakdown in time between different methods and different external",
    "start": "840740",
    "end": "846829"
  },
  {
    "text": "calls and I think the combination of all three of those some people have called",
    "start": "846829",
    "end": "852560"
  },
  {
    "text": "these the the three golden data types observer ability I think using all three",
    "start": "852560",
    "end": "859040"
  },
  {
    "text": "in deciding which what the balance is between the three can be really useful in understanding what's actually",
    "start": "859040",
    "end": "864410"
  },
  {
    "text": "happening the difficulty of course is that if you have a new modern micro",
    "start": "864410",
    "end": "871519"
  },
  {
    "start": "865000",
    "end": "913000"
  },
  {
    "text": "service you built from scratch with this mindset in mind with this mindset you",
    "start": "871519",
    "end": "876589"
  },
  {
    "text": "might have really good observability into a single service but obviously it's more than just back in components",
    "start": "876589",
    "end": "883009"
  },
  {
    "text": "especially as we look at things like edge computing and eventually IOT so you",
    "start": "883009",
    "end": "888170"
  },
  {
    "text": "have mobile and browser applications talking to multiple applications they might be running in different containers or different operating systems inside an",
    "start": "888170",
    "end": "894920"
  },
  {
    "text": "ec2 instance and in that intern is probably interacting with lots of different AWS managed services so having",
    "start": "894920",
    "end": "903199"
  },
  {
    "text": "visibility into only one of these components doesn't really tell the entire story so it's having full",
    "start": "903199",
    "end": "909800"
  },
  {
    "text": "coverage of all of those different components together and the last thing",
    "start": "909800",
    "end": "915290"
  },
  {
    "start": "913000",
    "end": "977000"
  },
  {
    "text": "and this is this is kind of interesting too because there's this perception that",
    "start": "915290",
    "end": "920870"
  },
  {
    "text": "that's instrumentation manual instrumentation especially getting full",
    "start": "920870",
    "end": "926809"
  },
  {
    "text": "coverage across a large team in different offices around the world is",
    "start": "926809",
    "end": "932390"
  },
  {
    "text": "very slow process and it's hard to get there and it requires a lot of tedious work and in some say in some cases if",
    "start": "932390",
    "end": "939590"
  },
  {
    "text": "the service is old enough perhaps the expert on that service you would like visibility into no longer",
    "start": "939590",
    "end": "944930"
  },
  {
    "text": "works in the company or has moved on or been promoted to a new project we do hear that a lot so there's this idea I",
    "start": "944930",
    "end": "951080"
  },
  {
    "text": "think this has related this this practice of observability that's instrumentation should be built in to",
    "start": "951080",
    "end": "958190"
  },
  {
    "text": "everything you run and build and some of our largest customers in the relative actually started experiment with this",
    "start": "958190",
    "end": "964640"
  },
  {
    "text": "idea and created dedicated observability engineering teams which is an interesting way to kind of make this a",
    "start": "964640",
    "end": "970820"
  },
  {
    "text": "practice company-wide so across those three things I think it's it's a good",
    "start": "970820",
    "end": "979070"
  },
  {
    "start": "977000",
    "end": "1038000"
  },
  {
    "text": "it's a good point to kind of pivot to a nub use lambda itself so I've talked a",
    "start": "979070",
    "end": "985100"
  },
  {
    "text": "lot about a lot at this point around you know metrics logs traces observability",
    "start": "985100",
    "end": "991040"
  },
  {
    "text": "of how that works why that matters I think it's important to actually back",
    "start": "991040",
    "end": "997070"
  },
  {
    "text": "that up with with an example here and a team is lambda is a specifically interesting one because of the",
    "start": "997070",
    "end": "1004180"
  },
  {
    "text": "constraints of the runtime environment and because abs manages the infrastructure the lambda runs on a lot",
    "start": "1004180",
    "end": "1011110"
  },
  {
    "text": "of the practices we have for servers don't necessarily apply directly to lambda we can't really look at host CPU",
    "start": "1011110",
    "end": "1017440"
  },
  {
    "text": "percentage for a lambda function running of on the internal lambda service for example so what does that actually look",
    "start": "1017440",
    "end": "1024250"
  },
  {
    "text": "like Amazon provides some observability",
    "start": "1024250",
    "end": "1030510"
  },
  {
    "text": "automatically obviously a set of cloud watch metrics and logs if you log it to",
    "start": "1030510",
    "end": "1035890"
  },
  {
    "text": "a lambda function it'll appear in cloud watch and the metrics specifically there",
    "start": "1035890",
    "end": "1043150"
  },
  {
    "start": "1038000",
    "end": "1072000"
  },
  {
    "text": "there's a different sets depending on the service we've got invitations and",
    "start": "1043150",
    "end": "1048670"
  },
  {
    "text": "duration and throttles the one we'll be focusing on for this case study specifically is duration the lambda",
    "start": "1048670",
    "end": "1056500"
  },
  {
    "text": "function is a fairly large a fairly large one it's it's running headless Chrome as I said earlier so what we're",
    "start": "1056500",
    "end": "1063670"
  },
  {
    "text": "really interested in is making sure the duration is is fast the function is very fast and it",
    "start": "1063670",
    "end": "1069790"
  },
  {
    "text": "runs quickly obviously for billing reasons the other thing and I guess this",
    "start": "1069790",
    "end": "1075550"
  },
  {
    "start": "1072000",
    "end": "1110000"
  },
  {
    "text": "week at reinvent it would be celebrating it's it's your anniversary is of course a WS s a Tobias x-ray which is which is",
    "start": "1075550",
    "end": "1085120"
  },
  {
    "text": "a service provided by a POS that allows you to trace requests between different",
    "start": "1085120",
    "end": "1090190"
  },
  {
    "text": "a Tobias magnetic components the really interesting thing about x-ray and the really useful thing if you're going down",
    "start": "1090190",
    "end": "1095800"
  },
  {
    "text": "the path of debugging a Tobias lamda performance is x-ray when enabled for lamda actually exposes some really",
    "start": "1095800",
    "end": "1102850"
  },
  {
    "text": "interesting internal details that you can't actually observe from the perspective of your application code",
    "start": "1102850",
    "end": "1108730"
  },
  {
    "text": "running in lamda and the really big one and the really interesting one is this",
    "start": "1108730",
    "end": "1113980"
  },
  {
    "start": "1110000",
    "end": "1203000"
  },
  {
    "text": "idea of cold starts in a Tobias lambda functions so we talk about Amos lamda",
    "start": "1113980",
    "end": "1119830"
  },
  {
    "text": "performance there's been a lot written about this if you go to server list conferences there's always a cold start",
    "start": "1119830",
    "end": "1126280"
  },
  {
    "text": "talk but the really nice thing is if you enable x-ray for lambda function you",
    "start": "1126280",
    "end": "1132610"
  },
  {
    "text": "actually see how much time is spent in the internal lamda service so when the internal amber service actually receives",
    "start": "1132610",
    "end": "1138670"
  },
  {
    "text": "the request and then when your function actually starts executing and so if you",
    "start": "1138670",
    "end": "1143830"
  },
  {
    "text": "look at these this table there's the a torus lamda and a nativist lambda function if you compare the difference",
    "start": "1143830",
    "end": "1150460"
  },
  {
    "text": "between the two you can actually measure a cold start time and by that I mean the latency between when the internal aw",
    "start": "1150460",
    "end": "1156910"
  },
  {
    "text": "lambdas service receives the request to invoke your function and then when your code actually starts running and so",
    "start": "1156910",
    "end": "1164440"
  },
  {
    "text": "there's some internal setup obviously the has to be done to create the environment to run your function code",
    "start": "1164440",
    "end": "1169740"
  },
  {
    "text": "really interesting and available visually in v8 of your slammed sorry in",
    "start": "1169740",
    "end": "1176230"
  },
  {
    "text": "the AWS x-ray UI if we run this same function again it looks slightly",
    "start": "1176230",
    "end": "1182560"
  },
  {
    "text": "different you notice there's no large difference between the internal lamda service and your function and that's",
    "start": "1182560",
    "end": "1188830"
  },
  {
    "text": "because it's a warm start so there's no set-up time and your function initialization code doesn't have to run",
    "start": "1188830",
    "end": "1194500"
  },
  {
    "text": "either so it was essentially looking at this x-ray trace data they wanted to ask a lot of questions",
    "start": "1194500",
    "end": "1201169"
  },
  {
    "text": "around performance of this lambda function and specifically we know that we have different numbers in a trace and",
    "start": "1201169",
    "end": "1208639"
  },
  {
    "start": "1203000",
    "end": "1245000"
  },
  {
    "text": "a trace happens at a particular time so if we aggregate the traces and we know what time the numbers in those traces",
    "start": "1208639",
    "end": "1214340"
  },
  {
    "text": "happened we can ultimately turn those traces into metrics and we can answer a couple of really interesting performance",
    "start": "1214340",
    "end": "1220220"
  },
  {
    "text": "questions that before the x-ray integration existed you really put an answer very easily at all and",
    "start": "1220220",
    "end": "1225919"
  },
  {
    "text": "specifically the really big one and the important one is where's time actually",
    "start": "1225919",
    "end": "1231139"
  },
  {
    "text": "being spending the function but more importantly especially if you're wondering if cold starts are impacting",
    "start": "1231139",
    "end": "1236179"
  },
  {
    "text": "your performance is that an issue at all our cold starts actually impacting the",
    "start": "1236179",
    "end": "1241399"
  },
  {
    "text": "way people interact with the function and of course understanding that over time not surprisingly to actually pull",
    "start": "1241399",
    "end": "1248509"
  },
  {
    "text": "data out of x-ray there's an API and like almost every very service this code is on github there's a Atos Amazon Cloud",
    "start": "1248509",
    "end": "1256549"
  },
  {
    "text": "watch scheduled event it pulls data from the x-ray API every few minutes and it sends it to new relics events event",
    "start": "1256549",
    "end": "1262370"
  },
  {
    "text": "database insights for further analytics and so after we've pulled in the trace",
    "start": "1262370",
    "end": "1267440"
  },
  {
    "text": "data over a 24-hour period for our lambda function that's running headless chrome we're actually gonna be able to",
    "start": "1267440",
    "end": "1272929"
  },
  {
    "text": "see what that looks like and actually kind of answer some of these questions we had around performance and if we",
    "start": "1272929",
    "end": "1279889"
  },
  {
    "text": "actually look at the data and we write a few queries around it we see a couple of interesting things right off the bat",
    "start": "1279889",
    "end": "1285429"
  },
  {
    "start": "1280000",
    "end": "1495000"
  },
  {
    "text": "first of all the lambda function itself the the first graph here it's on a scale",
    "start": "1285429",
    "end": "1292190"
  },
  {
    "text": "of zero to five seconds so our lambda function is obviously much much slower than the internal lambda service it's",
    "start": "1292190",
    "end": "1297889"
  },
  {
    "text": "not surprisingly you know kudos to the lambda engineering team the lander service is frequently very very fast in",
    "start": "1297889",
    "end": "1304669"
  },
  {
    "text": "this case most the time is spent in your function itself or in this function",
    "start": "1304669",
    "end": "1310009"
  },
  {
    "text": "from there we can answer that we can ask the question we know how often cold",
    "start": "1310009",
    "end": "1315620"
  },
  {
    "text": "starts happen whenever this functions vocht over of 24 hour period does that",
    "start": "1315620",
    "end": "1321799"
  },
  {
    "text": "happen very frequently are we actually hitting performance issues with the lambda function and if we look at the",
    "start": "1321799",
    "end": "1327440"
  },
  {
    "text": "number of initializations that are nonzero so this is the number of finish from traces that actually have a cold",
    "start": "1327440",
    "end": "1334530"
  },
  {
    "text": "start happening it's very very low so for this lambda function thousands of invitations cold starts only happened",
    "start": "1334530",
    "end": "1341130"
  },
  {
    "text": "around one and a half percent of all all requests we can then look into the timing information so for those one and",
    "start": "1341130",
    "end": "1348330"
  },
  {
    "text": "a half percent of functioning vacations that actually did have a cold start how long did it take to actually initialize",
    "start": "1348330",
    "end": "1354090"
  },
  {
    "text": "my code so my my code that I'm responsible for and the lambda function and if we graph that over the same time",
    "start": "1354090",
    "end": "1360270"
  },
  {
    "text": "period we see two peaks one around 200 milliseconds and one around 500 milliseconds but the interesting thing",
    "start": "1360270",
    "end": "1366150"
  },
  {
    "text": "about that and why we've gone so deep into how long that takes is we wanted to answer the question you",
    "start": "1366150",
    "end": "1371460"
  },
  {
    "text": "know in some cases this lambda function my code takes up to five seconds - and it to actually run is that five second",
    "start": "1371460",
    "end": "1379710"
  },
  {
    "text": "duration actually being significantly impacted by say Mike's my code slowly initializing and because it's only",
    "start": "1379710",
    "end": "1386280"
  },
  {
    "text": "taking 200 or 500 milliseconds in the worst case we can say it's it's fairly unlikely",
    "start": "1386280",
    "end": "1393500"
  },
  {
    "text": "so looking at that and kind of looking at that analysis like well if we want to",
    "start": "1393600",
    "end": "1399120"
  },
  {
    "text": "optimize the performance of the code running the lambda function it's not cold starts it's not the internal lambda",
    "start": "1399120",
    "end": "1404340"
  },
  {
    "text": "service it's it's our function code itself and because it's the Chrome binary so an application that was",
    "start": "1404340",
    "end": "1410970"
  },
  {
    "text": "ultimately written to run on desktops the question was well maybe it's under provisioned with memory and it turns out",
    "start": "1410970",
    "end": "1417510"
  },
  {
    "text": "if we run the same analysis again so we look at the distribution of duration for for the function code it does not",
    "start": "1417510",
    "end": "1425700"
  },
  {
    "text": "surprisingly get faster if we give it more memory so just over a gigabyte of memory from 768 megabytes it does get",
    "start": "1425700",
    "end": "1432420"
  },
  {
    "text": "faster you see the the distribution shift to the the left there this gets to",
    "start": "1432420",
    "end": "1437970"
  },
  {
    "text": "a really counterintuitive and really interesting point though by increasing",
    "start": "1437970",
    "end": "1443340"
  },
  {
    "text": "the memory the lambda function this actually decreased our bill so because an abuse lambdas build in 100",
    "start": "1443340",
    "end": "1449370"
  },
  {
    "text": "millisecond increments we made the function faster by giving it more memory but we made the function fast basically",
    "start": "1449370",
    "end": "1456390"
  },
  {
    "text": "the function got so much faster that it lowered the bill because it was just executing work more quickly so it's it's",
    "start": "1456390",
    "end": "1462930"
  },
  {
    "text": "this kind of counterintuitive point that wasn't it all clear to me when I was first kind",
    "start": "1462930",
    "end": "1467970"
  },
  {
    "text": "of working with lambda that more resources more memory it doesn't necessarily mean your bill will get",
    "start": "1467970",
    "end": "1474480"
  },
  {
    "text": "higher if your code actually executes much faster it's likely your bill will go down so a really really interesting",
    "start": "1474480",
    "end": "1482549"
  },
  {
    "text": "point around performance tuning and because it impacts your bill I think it also underscores for for complex",
    "start": "1482549",
    "end": "1489120"
  },
  {
    "text": "functions that run a lot potentially a lot of cost savings there as well to kind of do this tuning in the first",
    "start": "1489120",
    "end": "1494340"
  },
  {
    "text": "place um I want to kind of wrap that up with a few just a few high-level lessons",
    "start": "1494340",
    "end": "1501929"
  },
  {
    "start": "1495000",
    "end": "1560000"
  },
  {
    "text": "and then we'll jump into Q&A with Marcus but I think you know from this case",
    "start": "1501929",
    "end": "1508289"
  },
  {
    "text": "study we were able to at least explore some of these ideas with real data that",
    "start": "1508289",
    "end": "1515240"
  },
  {
    "text": "instrumentation whether it was custom instrumentation we built with our server list stuff that pulled in x-ray traces",
    "start": "1515240",
    "end": "1521820"
  },
  {
    "text": "and then data analytics or what's built in with x-ray it was looking at different metrics different trace data",
    "start": "1521820",
    "end": "1528990"
  },
  {
    "text": "and also logs during development to figure out what was actually happening and then once all that was in place we",
    "start": "1528990",
    "end": "1536100"
  },
  {
    "text": "put it into a solution that allowed us to really explore that we did not know going in or putting the data in what",
    "start": "1536100",
    "end": "1543210"
  },
  {
    "text": "exactly we wanted to know from the data it was only after we explored it that this kind of insight came out in the",
    "start": "1543210",
    "end": "1548520"
  },
  {
    "text": "first place so it's that it's that um that's tradition of going from observability to having the",
    "start": "1548520",
    "end": "1553529"
  },
  {
    "text": "instrumentation to actually being able to answer and explore interesting questions and from there I think well",
    "start": "1553529",
    "end": "1559559"
  },
  {
    "text": "we'll invite Marcus Irvin up from Scripps Networks and we'll be discussing his recent endeavor Solyndra project",
    "start": "1559559",
    "end": "1566610"
  },
  {
    "start": "1560000",
    "end": "2298000"
  },
  {
    "text": "will give Marcus a hands",
    "start": "1566610",
    "end": "1569570"
  },
  {
    "text": "yeah thanks Fergus yeah absolutely so",
    "start": "1572300",
    "end": "1577560"
  },
  {
    "text": "Marcus I know you just recently been successfully deployed to production a",
    "start": "1577560",
    "end": "1584100"
  },
  {
    "text": "fairly large Avery slammed her projects I was curious though just what what are you currently working on and you know",
    "start": "1584100",
    "end": "1590760"
  },
  {
    "text": "what do you do with scripts yeah sure so like I said I work at Scripps Networks might not be familiar with Scripps",
    "start": "1590760",
    "end": "1598200"
  },
  {
    "text": "Networks be I'm sure you're familiar with our brains we own Food Network HGTV Travel Channel juniors kitchen and a few",
    "start": "1598200",
    "end": "1604650"
  },
  {
    "text": "other things I'm an architect and I manage a team that builds focused on",
    "start": "1604650",
    "end": "1611130"
  },
  {
    "text": "KPIs for a long time that was really focused on building and api's for our mobile applications the last couple of",
    "start": "1611130",
    "end": "1618810"
  },
  {
    "text": "years we've sort of branched out we were [Music] boys and facebook Messenger BOTS and etc",
    "start": "1618810",
    "end": "1625560"
  },
  {
    "text": "etc and from there we started to leverage the work that we did on mobile and kind of started building more of a",
    "start": "1625560",
    "end": "1631530"
  },
  {
    "text": "micro service architecture to some to be able to share some of some you know what we do that's great that's so how long",
    "start": "1631530",
    "end": "1638010"
  },
  {
    "text": "have you been using Amazon Web Services scripts we've been using him for Pella",
    "start": "1638010",
    "end": "1643470"
  },
  {
    "text": "about five or six years and I've been using it for a little bit longer than that all right and so tell me about like",
    "start": "1643470",
    "end": "1649320"
  },
  {
    "text": "your your very first lambda project I know you just implemented a fairly large",
    "start": "1649320",
    "end": "1654420"
  },
  {
    "text": "system but kind of how did you get started yeah the first time I use lambda was a couple years ago we were we were",
    "start": "1654420",
    "end": "1660960"
  },
  {
    "text": "building a new version of our food network what will happen and we were",
    "start": "1660960",
    "end": "1667650"
  },
  {
    "text": "using API gateway and we needed to do some custom authorization and EPA gateway supports using lambda 2 to do",
    "start": "1667650",
    "end": "1675090"
  },
  {
    "text": "authorization every request and I was though the first time over use land it was super successful all right and",
    "start": "1675090",
    "end": "1680760"
  },
  {
    "text": "it's kind of fast forward to the past several months you've been working on a fairly new service can you kind of",
    "start": "1680760",
    "end": "1687929"
  },
  {
    "text": "describe what it does and what were some of the reasons you decided to kind of use server lists for this new service",
    "start": "1687929",
    "end": "1694020"
  },
  {
    "text": "sure so it's it's it's actually an old service called called rusty box it's been around for I think going on ten",
    "start": "1694020",
    "end": "1701250"
  },
  {
    "text": "years or so it was it was built and maintained by a third-party vendor for a",
    "start": "1701250",
    "end": "1706890"
  },
  {
    "text": "long time and it's the service that reduced on cross for mobile apps but also across the websites for saving and",
    "start": "1706890",
    "end": "1712350"
  },
  {
    "text": "allowing users to view their saved recipes so pretty simple in concept but",
    "start": "1712350",
    "end": "1718290"
  },
  {
    "text": "we decided that we want to bring this in-house it was a service it was really important to us",
    "start": "1718290",
    "end": "1723809"
  },
  {
    "text": "it was maintained by a third-party vendor so it was hard for us to get changes made sure we had a lot of enhancements that we wanted to make it",
    "start": "1723809",
    "end": "1729690"
  },
  {
    "text": "is we're exploring new platforms who wanted to to show to be able to enhance",
    "start": "1729690",
    "end": "1735600"
  },
  {
    "text": "it so we we thought this could be a good candidate for first server listens you",
    "start": "1735600",
    "end": "1740700"
  },
  {
    "text": "know and his course it's relatively simple and so we started doing some PLC's around it the recipe box service",
    "start": "1740700",
    "end": "1753679"
  },
  {
    "text": "you know how'd you decide to build this and what did the initial architecture look like yeah sure so we uh like I said",
    "start": "1753679",
    "end": "1761940"
  },
  {
    "text": "there was an existing restaurant service so we wanted to stand up the new recipe box in parallel and rather than do a",
    "start": "1761940",
    "end": "1769980"
  },
  {
    "text": "sort of a big bang migration we wanted to move over apps gradually from the old service to the new service so we it's",
    "start": "1769980",
    "end": "1777450"
  },
  {
    "text": "running in parallel and then they would keep it in sync which has a lot of complexity to us so at the core it's",
    "start": "1777450",
    "end": "1783900"
  },
  {
    "text": "your fuel and as an API gateway and some dynamodb tables but the parts that are keeping on sync at a little bit of",
    "start": "1783900",
    "end": "1789750"
  },
  {
    "text": "complexity so we have asked us queues we have lambdas processing messages from the ask",
    "start": "1789750",
    "end": "1795059"
  },
  {
    "text": "you ask you is we have a step function that we use to do the migration it's",
    "start": "1795059",
    "end": "1803730"
  },
  {
    "text": "really interesting about step functions for the migration and a mission they were running in parallel to so I mean",
    "start": "1803730",
    "end": "1808770"
  },
  {
    "text": "what was the process like and we were talking earlier it's now fully in",
    "start": "1808770",
    "end": "1813870"
  },
  {
    "text": "production is that is that correct it's folding production I think we haven't moved all of our consumers over to it yet so we have a sort of a mix of",
    "start": "1813870",
    "end": "1820200"
  },
  {
    "text": "consumers using the old service and the new service yeah and so that's I think that rollouts pretty interesting - so how'd you how",
    "start": "1820200",
    "end": "1826950"
  },
  {
    "text": "did you verify that things working and make sure that it was kind of ready to go yes so we decided to do it this way",
    "start": "1826950",
    "end": "1842179"
  },
  {
    "text": "for a few diversions one is we didn't want to have to do a sort of a big vein release and Kortney amongst a bunch of",
    "start": "1842179",
    "end": "1849059"
  },
  {
    "text": "different teams and then and then the other thing is this is why we must to do",
    "start": "1849059",
    "end": "1854820"
  },
  {
    "text": "migration sort of on demand so as users access the nude new rusty bolts were able to run that step function - to",
    "start": "1854820",
    "end": "1862530"
  },
  {
    "text": "migrate users over as they're seen so we don't have to kind of take on the big migration that's great how long did the",
    "start": "1862530",
    "end": "1870809"
  },
  {
    "text": "rollout take yeah so we really built this service and got it into production",
    "start": "1870809",
    "end": "1876720"
  },
  {
    "text": "for mobile apps in about six months all right so a lot of people have discussed",
    "start": "1876720",
    "end": "1884190"
  },
  {
    "text": "different strategies around local for lambda and you know there's been a lot of chatter about this I was kind of",
    "start": "1884190",
    "end": "1891179"
  },
  {
    "text": "really curious you know how your team managed local development of these functions especially because you're talking about sqs who use step functions",
    "start": "1891179",
    "end": "1898740"
  },
  {
    "text": "lambda functions those are necessarily available for you on your local environment yeah no it's it's just tricky I think as",
    "start": "1898740",
    "end": "1905909"
  },
  {
    "text": "an industry we're still we're still figuring this out but for us we found that that most of our JavaScript we had",
    "start": "1905909",
    "end": "1912210"
  },
  {
    "text": "as kind of separate packages that weren't necessarily in lambda then our lambdas were fair",
    "start": "1912210",
    "end": "1917639"
  },
  {
    "text": "small as far as just coming out that calling out to the JavaScript so we were able to execute then the JavaScript",
    "start": "1917639",
    "end": "1922709"
  },
  {
    "text": "that's this is the database or maybe put messages and queues kind of actually keep that locally just against services",
    "start": "1922709",
    "end": "1929839"
  },
  {
    "text": "and as far as lambdas go and we use all of our lambdas are written in JavaScript",
    "start": "1929839",
    "end": "1935429"
  },
  {
    "text": "and as far as just a function that you can technically run locally whether it's",
    "start": "1935429",
    "end": "1942149"
  },
  {
    "text": "AWS services or not and then also with lambda it's really easy and quick to do",
    "start": "1942149",
    "end": "1947729"
  },
  {
    "text": "deploy so it doesn't take to one person tested in the cloud that's great um you",
    "start": "1947729",
    "end": "1953879"
  },
  {
    "text": "know part of getting to production two is obviously testing as well so you know",
    "start": "1953879",
    "end": "1959279"
  },
  {
    "text": "you mentioned it's it's easy to kind of run the function locally because just a JavaScript function but how do you test",
    "start": "1959279",
    "end": "1965519"
  },
  {
    "text": "before you actually do those frequent deploys yeah so we you know we do a lot",
    "start": "1965519",
    "end": "1971339"
  },
  {
    "text": "of unit testing with just the standard JavaScript unit testing frameworks but I",
    "start": "1971339",
    "end": "1977399"
  },
  {
    "text": "found with with lambda and with serverless that there's so much integration worked at that really you",
    "start": "1977399",
    "end": "1985229"
  },
  {
    "text": "end up with a lot more or you should end up with a lot more integration tests than maybe a traditional apps so I think",
    "start": "1985229",
    "end": "1990659"
  },
  {
    "text": "that's what we really focused on is writing tests that not only just kind of mock out all the wait a bit services but",
    "start": "1990659",
    "end": "1996659"
  },
  {
    "text": "one against either this that's great are you using the function tacky or versioning we are not using",
    "start": "1996659",
    "end": "2005309"
  },
  {
    "text": "function technical version well we are we are tagging tell unary functions we tagged all of our functions are deployed",
    "start": "2005309",
    "end": "2011820"
  },
  {
    "text": "using confirmation and we tagged all of our cloud formations with the application with the environment that's",
    "start": "2011820",
    "end": "2021059"
  },
  {
    "text": "this and you know you mentioned deploying using cloud formation is that something that's done manually or using",
    "start": "2021059",
    "end": "2026940"
  },
  {
    "text": "a CI CD pipeline yeah so we've been using confirmation for all of our",
    "start": "2026940",
    "end": "2032009"
  },
  {
    "text": "applications for for at least a few years and yes we have a lot of automation already around CloudFormation",
    "start": "2032009",
    "end": "2037759"
  },
  {
    "text": "mostly mostly wood what else is the",
    "start": "2037759",
    "end": "2046049"
  },
  {
    "text": "Jenkins pipeline responsible for so yeah every time we we deploy our code to",
    "start": "2046049",
    "end": "2051089"
  },
  {
    "text": "master or really any branch Jenkins picks it up runs the tests and then for master it'll go ahead and and when the",
    "start": "2051089",
    "end": "2057658"
  },
  {
    "text": "integration tests and deployed in the production that's great so now that",
    "start": "2057659",
    "end": "2063839"
  },
  {
    "text": "we're in production the obvious question is how do you monitor it yeah yeah great",
    "start": "2063839",
    "end": "2069720"
  },
  {
    "text": "question give this as I think it's still another area that the industry is still figuring out that Julius maybe it may be",
    "start": "2069720",
    "end": "2075270"
  },
  {
    "text": "lagging it will be on but beginning there and you talked about all the interesting things thinks just now",
    "start": "2075270",
    "end": "2080520"
  },
  {
    "text": "probably the the thing that's been most useful to us is we have our application",
    "start": "2080520",
    "end": "2086429"
  },
  {
    "text": "has about I think around 15 years or so lambdas and each of those lambdas is",
    "start": "2086429",
    "end": "2092460"
  },
  {
    "text": "riding along stick to cloud watch logs and how do we how do we get to those logs to do doing sort of diagnosing so",
    "start": "2092460",
    "end": "2099480"
  },
  {
    "text": "probably the most important thing for us is to get those logs into a log aggregation service we use scalar but he",
    "start": "2099480",
    "end": "2105480"
  },
  {
    "text": "use zoom logic or even a relic stack so that's probably the main thing we also",
    "start": "2105480",
    "end": "2110520"
  },
  {
    "text": "use these new relic new relics infrastructure service up holes on all the",
    "start": "2110520",
    "end": "2116140"
  },
  {
    "text": "I've watched metrics and wasn't to know reliquary kids uni dashboards and dual",
    "start": "2116140",
    "end": "2122560"
  },
  {
    "text": "ordered me there or whether you can used to used to doing later on with x-ray a little bit but we haven't done a whole",
    "start": "2122560",
    "end": "2129160"
  },
  {
    "text": "lot these are my experience that still has a little bit a little bit to go but it's definitely a promising promising",
    "start": "2129160",
    "end": "2135220"
  },
  {
    "text": "service and alerting as well so um you know how do you configure alerts or what",
    "start": "2135220",
    "end": "2142240"
  },
  {
    "text": "ultimately wakes you up when it comes to lamda you know luckily we've been lucky that we haven't had any major major",
    "start": "2142240",
    "end": "2147880"
  },
  {
    "text": "production issues since what since we launched but we do have of course the morning set up we have learning in a few",
    "start": "2147880",
    "end": "2153280"
  },
  {
    "text": "different places still we have I mentioned over let's go to scaler so we do have some learning therefore when our",
    "start": "2153280",
    "end": "2160210"
  },
  {
    "text": "log starts showing a lot of errors which triggered inside you relic where we already have a lot of our other",
    "start": "2160210",
    "end": "2166690"
  },
  {
    "text": "applications configured how we do that's",
    "start": "2166690",
    "end": "2178600"
  },
  {
    "text": "great well I was kind of curious um especially since it's reinvent there's a big focus on kind of the future of",
    "start": "2178600",
    "end": "2186700"
  },
  {
    "text": "server lists I think we can all look forward to foreigners keynote tomorrow but I'm curious are you evaluating",
    "start": "2186700",
    "end": "2193840"
  },
  {
    "text": "server list now for other systems to and kind of why or why not yeah I mean I",
    "start": "2193840",
    "end": "2199240"
  },
  {
    "text": "think I think my team is definitely bit by this by the serverless bug I think",
    "start": "2199240",
    "end": "2204490"
  },
  {
    "text": "the question for us now will be not rather like weather service is a good fits like whether it's not a good fit fit for us so we've already started a",
    "start": "2204490",
    "end": "2211990"
  },
  {
    "text": "couple of other small services that were that we're doing that's great what's",
    "start": "2211990",
    "end": "2221020"
  },
  {
    "text": "your high level process for determining something was depending whether something is a good fit or not a good",
    "start": "2221020",
    "end": "2226150"
  },
  {
    "text": "fit I think for us you know it would be if if we needed to use a lot of them",
    "start": "2226150",
    "end": "2233140"
  },
  {
    "text": "just sort of existing code for some reason that wouldn't be necessary remember on our land our team has a lot of a lot of",
    "start": "2233140",
    "end": "2241760"
  },
  {
    "text": "history with using ruby which isn't yet supported on lambda so there could be",
    "start": "2241760",
    "end": "2248510"
  },
  {
    "text": "some some use cases there but yeah well I mean that's I think that brings up an",
    "start": "2248510",
    "end": "2254450"
  },
  {
    "text": "interesting question too if any database lambda PMS or the roof what's what would",
    "start": "2254450",
    "end": "2259880"
  },
  {
    "text": "what would you like to see or what's on your kind of lambda wish list for the next few years yeah well I mentioned I'd love to see",
    "start": "2259880",
    "end": "2265610"
  },
  {
    "text": "some some some other language support uh I love JavaScript and that's a that's a it's a good language we have a lot of a",
    "start": "2265610",
    "end": "2271070"
  },
  {
    "text": "lot of history with Ruby that would be a great language I think go is a an obvious obvious choice there I mentioned",
    "start": "2271070",
    "end": "2277520"
  },
  {
    "text": "earlier that we we do a lot with with sqs rescue s and lambda integrations a little a little wonky there's not a good",
    "start": "2277520",
    "end": "2285410"
  },
  {
    "text": "event being triggered with messages",
    "start": "2285410",
    "end": "2288730"
  },
  {
    "text": "that's great I think at this point we have a few minutes left for just general audience Q&A we've got two people with",
    "start": "2296740",
    "end": "2305000"
  },
  {
    "start": "2298000",
    "end": "2317000"
  },
  {
    "text": "microphones that are they're happy to run around if you raise your hand if you have any questions for Marcus about",
    "start": "2305000",
    "end": "2312050"
  },
  {
    "text": "lambda or or about service what we're happy to answer you see if anyone has",
    "start": "2312050",
    "end": "2318710"
  },
  {
    "start": "2317000",
    "end": "2323000"
  },
  {
    "text": "any questions we're not what are you looking for next year in service what are your predictions for 2018 well I think I think we're gonna see a lot more",
    "start": "2318710",
    "end": "2326000"
  },
  {
    "start": "2323000",
    "end": "2354000"
  },
  {
    "text": "more tooling a lot of vendors adding more and more support I think because I",
    "start": "2326000",
    "end": "2331190"
  },
  {
    "text": "think we're still sort of lagging behind there other things I'm excited to see",
    "start": "2331190",
    "end": "2337100"
  },
  {
    "text": "what gets announced tomorrow so we probably see some cool stuff that comes out of that",
    "start": "2337100",
    "end": "2342850"
  },
  {
    "text": "that's great any any other questions oh I think I see ends here I was wondering",
    "start": "2344210",
    "end": "2354789"
  },
  {
    "start": "2354000",
    "end": "2373000"
  },
  {
    "text": "you talked about the distributors architecture but what if you had build",
    "start": "2354789",
    "end": "2360440"
  },
  {
    "text": "your big application without serverless what would you expect to have been a",
    "start": "2360440",
    "end": "2367640"
  },
  {
    "text": "difficulty for this service or maybe in costs the difference what is the",
    "start": "2367640",
    "end": "2375470"
  },
  {
    "start": "2373000",
    "end": "2385000"
  },
  {
    "text": "difference do you think if you had built your big surface without serverless yeah",
    "start": "2375470",
    "end": "2385250"
  },
  {
    "start": "2385000",
    "end": "2407000"
  },
  {
    "text": "I think we're definitely seeing you know it's kind of hard to compare but I think we're definitely seeing cost savings I mean our lambda costs are way cheaper",
    "start": "2385250",
    "end": "2392119"
  },
  {
    "text": "than you know you see two instances would have been you know we're using DynamoDB which can be expensive do you",
    "start": "2392119",
    "end": "2403789"
  },
  {
    "text": "think there's there's cost savings that we're seeing also I think there's a one",
    "start": "2403789",
    "end": "2409490"
  },
  {
    "start": "2407000",
    "end": "2424000"
  },
  {
    "text": "thing I noticed what services you have a lot less code I'm always kind of surprised like sometimes how little code",
    "start": "2409490",
    "end": "2414589"
  },
  {
    "text": "we have making use of setting the AWS services to do yeah I was curious I've",
    "start": "2414589",
    "end": "2426799"
  },
  {
    "text": "got quite a bit of experience writing land of functions and service applications and one of the things that",
    "start": "2426799",
    "end": "2432980"
  },
  {
    "text": "we've run into quite a bit is kind of what what logging framework to use we",
    "start": "2432980",
    "end": "2438770"
  },
  {
    "text": "use JavaScript to and you know there's a plethora of different logging SDKs that",
    "start": "2438770",
    "end": "2445490"
  },
  {
    "text": "you can use but the concern has always been even with you know tree shaking and",
    "start": "2445490",
    "end": "2450829"
  },
  {
    "text": "stuff like that getting some code bloat into your functions so we've kind of stripped that stuff out and and just use",
    "start": "2450829",
    "end": "2457640"
  },
  {
    "text": "a vanilla you know logging pattern so I'm just curious to know if on your team",
    "start": "2457640",
    "end": "2464660"
  },
  {
    "text": "you've established any sort of like best practices or standards around how you log and instrument your code yeah so so",
    "start": "2464660",
    "end": "2473599"
  },
  {
    "start": "2472000",
    "end": "2504000"
  },
  {
    "text": "we're using I don't remember the package is a fairly lightweight package that basically does",
    "start": "2473599",
    "end": "2479750"
  },
  {
    "text": "your logging in the which is a simple JSON log but then you could also set up",
    "start": "2479750",
    "end": "2484880"
  },
  {
    "text": "sort of beginning some metadata that you want attached to each log message so that's kind of nice at the beginning of you know at the event we could say that",
    "start": "2484880",
    "end": "2492620"
  },
  {
    "text": "this is a user ID an invocation idea then add those to the Jeanette so that",
    "start": "2492620",
    "end": "2497660"
  },
  {
    "text": "it's not quite bulleted with all of your log messages your log messages can be just Pacific four doors no is it okay to",
    "start": "2497660",
    "end": "2505670"
  },
  {
    "start": "2504000",
    "end": "2627000"
  },
  {
    "text": "ask you a question claim sure okay so I'm just the observability that we have",
    "start": "2505670",
    "end": "2512270"
  },
  {
    "text": "now with x-ray and your relic and other tools it seems a little well I don't it",
    "start": "2512270",
    "end": "2519620"
  },
  {
    "text": "seems a little basic to me sorry to say that it feels like needs a lot more",
    "start": "2519620",
    "end": "2525140"
  },
  {
    "text": "features and a lot more depth and I'm just wondering is that gonna come from new relic or maybe from AWS and what are",
    "start": "2525140",
    "end": "2532010"
  },
  {
    "text": "some of the key features that you think are gonna come down the pipe yeah no that's that's an excellent question",
    "start": "2532010",
    "end": "2537410"
  },
  {
    "text": "and I think my my initial response is this is a this is a conversation we're",
    "start": "2537410",
    "end": "2543500"
  },
  {
    "text": "deeply interested in having with customers like yourself we think you know we agree that we're early on this",
    "start": "2543500",
    "end": "2551270"
  },
  {
    "text": "kind of journey to serverless and we want to get greater observability I think everyone agrees on that",
    "start": "2551270",
    "end": "2556640"
  },
  {
    "text": "but we're really curious and actually we're currently interviewing a lot of our customers to essentially discover",
    "start": "2556640",
    "end": "2561980"
  },
  {
    "text": "what's what's on everyone's wish list and so it's it's a conversation we'd like to have and in terms of you relic",
    "start": "2561980",
    "end": "2568100"
  },
  {
    "text": "it's it's something we definitely wanna be a part of do you think yeah the - I",
    "start": "2568100",
    "end": "2575900"
  },
  {
    "text": "think tooling is definitely kind of lagging or not where it needs to be but I do think with server lists there's so",
    "start": "2575900",
    "end": "2582380"
  },
  {
    "text": "many more metrics that are available through college even though they're hard to consume under the juice work well",
    "start": "2582380",
    "end": "2587660"
  },
  {
    "text": "right now but as far as food observability standpoint serverless i think it's really really had us like",
    "start": "2587660",
    "end": "2594980"
  },
  {
    "text": "sort of traditional applications some what's what's possible all right I think",
    "start": "2594980",
    "end": "2604220"
  },
  {
    "text": "I think that's it in terms of questions or it's everyone uh alright well hey",
    "start": "2604220",
    "end": "2614030"
  },
  {
    "text": "thank you very much and thanks again for mark yes [Applause]",
    "start": "2614030",
    "end": "2625670"
  }
]
[
  {
    "start": "0",
    "end": "73000"
  },
  {
    "text": "hello everybody my name is latina phone i'm a senior product manager at amazon ec2 it's really great to see everybody",
    "start": "0",
    "end": "6660"
  },
  {
    "text": "here it's really exciting to see how many people are interested in learning more about how to run massively parallel computer intensive workloads in AWS",
    "start": "6660",
    "end": "14089"
  },
  {
    "text": "compute performance is critical application for the performance of an application so today we're going to talk",
    "start": "14089",
    "end": "19830"
  },
  {
    "text": "about how to accelerate your application using our accelerations together with me",
    "start": "19830",
    "end": "25320"
  },
  {
    "text": "up one juhani director and unban field and oliver Kulasekara CEO and co-founder",
    "start": "25320",
    "end": "30960"
  },
  {
    "text": "at ng codec they'll be with me on the stage shared experience moving workloads to how accelerators in it to a TBS as",
    "start": "30960",
    "end": "38730"
  },
  {
    "text": "many of you have already noticed yesterday in Anna's keynote we just announced the preview of our first FPGA",
    "start": "38730",
    "end": "44460"
  },
  {
    "text": "product f1 instance this is the force accelerated computing instance we have introduced so if you're interested in",
    "start": "44460",
    "end": "50129"
  },
  {
    "text": "you can sign up online for preview in this session I would like to give you an",
    "start": "50129",
    "end": "55469"
  },
  {
    "text": "overview of what is how acceleration talk about the how acceleration on AWS provide some example use cases of how",
    "start": "55469",
    "end": "62219"
  },
  {
    "text": "acceleration and discuss how to choose the right how accelerator at the end of the session I'll conclude by sharing",
    "start": "62219",
    "end": "67920"
  },
  {
    "text": "some of our best practices when using p 2 and a half one instances when we talk",
    "start": "67920",
    "end": "73650"
  },
  {
    "start": "73000",
    "end": "73000"
  },
  {
    "text": "about computing tensive workloads for example virtual reality when you have just stitch multiple things together or",
    "start": "73650",
    "end": "79860"
  },
  {
    "text": "fluid dynamics we need to simulate movement of liquids using thousands of millions of particles or genomics when",
    "start": "79860",
    "end": "86189"
  },
  {
    "text": "you want to match along DNA sequence with the template your first reaction is probably let me get a lot of CPUs in the",
    "start": "86189",
    "end": "93900"
  },
  {
    "text": "immobile yes you have multiple ways of doing it for batch workloads you may create large spot fleets of c-4",
    "start": "93900",
    "end": "99240"
  },
  {
    "text": "instances or maybe c5 next year spot instances really good give you some very good characteristic it gives you a very",
    "start": "99240",
    "end": "106380"
  },
  {
    "text": "effective way of running hundreds of instances we need to quickly scale out your workload there a lot of features",
    "start": "106380",
    "end": "112229"
  },
  {
    "text": "you can leverage you do spots for example you can set the bit price to control budget you can use spot fleet to",
    "start": "112229",
    "end": "117869"
  },
  {
    "text": "manage a poor Spock capacities or you can use spot blog for defined duration wear clothes what spot is a great way",
    "start": "117869",
    "end": "125130"
  },
  {
    "text": "for getting a lot of CPU power I think we can do better there are many motivations to accelerate your workloads",
    "start": "125130",
    "end": "131550"
  },
  {
    "text": "and let let us look at one the first one is some workloads are practically impossible to run on cpu",
    "start": "131550",
    "end": "138310"
  },
  {
    "text": "only you can probably take weeks for example if you want to train a large deeply deep neural network models you",
    "start": "138310",
    "end": "144610"
  },
  {
    "text": "can probably take weeks months or even years when running on pure ions purely on GPUs the second one is you want to",
    "start": "144610",
    "end": "150970"
  },
  {
    "text": "reduce the execution latency for example real-time speech recognition you don't want you to talk to application and I",
    "start": "150970",
    "end": "156910"
  },
  {
    "text": "give you a response 30 seconds later and third motivation is that you want to optimize for price performance for",
    "start": "156910",
    "end": "163120"
  },
  {
    "text": "example molecule dynamics when you want to screen as many molecules as possible for drug discovery we use a limited",
    "start": "163120",
    "end": "169540"
  },
  {
    "text": "budget so we believe there is a way to solve all these problems that is using highway acceleration so what is how",
    "start": "169540",
    "end": "177250"
  },
  {
    "start": "176000",
    "end": "176000"
  },
  {
    "text": "acceleration how accelerations used of specialized hardware we call it how",
    "start": "177250",
    "end": "182560"
  },
  {
    "text": "accelerators to perform some functions more efficiently than its software running on cpus how acceleration is not",
    "start": "182560",
    "end": "189370"
  },
  {
    "text": "really a new concept in 1980s intel introduced intel 8087 which a",
    "start": "189370",
    "end": "194620"
  },
  {
    "text": "floating-point core processor of the 8086 lines of cpus nowadays they're much",
    "start": "194620",
    "end": "200800"
  },
  {
    "text": "more how accelerators available on the market can I have GPUs for rendering",
    "start": "200800",
    "end": "205870"
  },
  {
    "text": "graphics you can have other how accelerators to encrypt network traffic speak speed up file compression or even",
    "start": "205870",
    "end": "212770"
  },
  {
    "text": "you can accelerate Bitcoin mining using our accelerators so although these jobs can be done on software running on cpus",
    "start": "212770",
    "end": "219959"
  },
  {
    "text": "how accelerators are available that you can do it much more faster and much more efficiently in how accelerators the Nano",
    "start": "219959",
    "end": "229540"
  },
  {
    "text": "geelong like to draw between CPU and how accelerators is Swiss Army knife vs. Xizor's CPUs like Swiss Army knife it's",
    "start": "229540",
    "end": "237880"
  },
  {
    "text": "very versatile it can do a lot of things for example you can do integer calculations floating-point calculations",
    "start": "237880",
    "end": "243670"
  },
  {
    "text": "logical operations control flow many many basically all the compute workloads",
    "start": "243670",
    "end": "250300"
  },
  {
    "text": "you can work you can have run on CPUs just like Swiss Army knife you can cut papers open bottles where can the",
    "start": "250300",
    "end": "256570"
  },
  {
    "text": "screwdrivers you may even use switch I'm gonna have to cut a tree if you want Howie accelerators on the other hand are",
    "start": "256570",
    "end": "262450"
  },
  {
    "text": "like X slicers you can only do a limited set of work for example X slices can",
    "start": "262450",
    "end": "267640"
  },
  {
    "text": "only why sex it may occasionally use it to slice mushrooms but he definitely cannot",
    "start": "267640",
    "end": "273130"
  },
  {
    "text": "use the cutter tree however if you want to cut eggs every day like hundreds eggs",
    "start": "273130",
    "end": "278410"
  },
  {
    "text": "every day like a SATA chef it's much more efficient using X slicers then you",
    "start": "278410",
    "end": "283780"
  },
  {
    "text": "can Swiss Army knives to compute a job so the same applies to how acceleration vs cpu for these repetitive compute",
    "start": "283780",
    "end": "290770"
  },
  {
    "text": "intensive workloads such as matrix operations on Monte Carlo simulations some of our customers are able to use",
    "start": "290770",
    "end": "297400"
  },
  {
    "text": "how accelerators speed up your workload by seventy eight times compared to running workloads on cpu and that's very",
    "start": "297400",
    "end": "303940"
  },
  {
    "text": "impressive so although there's a lot of how accelerators on market the two types",
    "start": "303940",
    "end": "310120"
  },
  {
    "start": "305000",
    "end": "305000"
  },
  {
    "text": "of satyrs that are widely available and what we used that is GPU in FPGA with",
    "start": "310120",
    "end": "316480"
  },
  {
    "text": "development of hpc and deep learning GPU is now at the center stage of accelerated computing it's no longer",
    "start": "316480",
    "end": "322990"
  },
  {
    "text": "just for graphics can use for a wide range of compute intensive workloads so why GPU is so popular we believe that is",
    "start": "322990",
    "end": "330880"
  },
  {
    "text": "for several reasons first one GPUs are very widely available it's available to high scale at high scale to application",
    "start": "330880",
    "end": "337540"
  },
  {
    "text": "developers worldwide basically all your laptops or pcs had a GPU inside be it from Nvidia AMD or intel you don't have",
    "start": "337540",
    "end": "345370"
  },
  {
    "text": "to move mountains just to get access to one GPU secondly enables high degree of data parallelism so in one GPU you can",
    "start": "345370",
    "end": "353560"
  },
  {
    "text": "probably have thousands of parallel processing course while you CPU can probably just get 20 or 30 course and in",
    "start": "353560",
    "end": "361180"
  },
  {
    "text": "GPU there is very good characteristic which called SIMD single instruction multiple data it can run a single",
    "start": "361180",
    "end": "367600"
  },
  {
    "text": "instruction on a lot of multiple data's to speed up the workload and its",
    "start": "367600",
    "end": "373450"
  },
  {
    "text": "redesigned for high floating-point Harris mystic because GPU started to support graphics workloads which all",
    "start": "373450",
    "end": "380380"
  },
  {
    "text": "about us floating-point performance and there is there are a lot of consistent",
    "start": "380380",
    "end": "386410"
  },
  {
    "text": "well document set of API is for example Buddha and opencl a lot of people are",
    "start": "386410",
    "end": "391479"
  },
  {
    "text": "using using these api's to develop applications in create a good ecosystem and a positive feedback loop so that",
    "start": "391479",
    "end": "398020"
  },
  {
    "text": "these api is are currently supported by a wide range of ISVs and and open-source frameworks around the",
    "start": "398020",
    "end": "404020"
  },
  {
    "text": "world so some people may ask we already have large application that's running on",
    "start": "404020",
    "end": "410110"
  },
  {
    "text": "CP use would it take a lot longer it from CPU to GPU one beauty of GPU is",
    "start": "410110",
    "end": "418750"
  },
  {
    "text": "that allows you to optimize some cocotte mostly inner loops for example as shown",
    "start": "418750",
    "end": "423909"
  },
  {
    "text": "on the screen that's probably maybe ten percent or five percent of the code for",
    "start": "423909",
    "end": "429729"
  },
  {
    "text": "GP optimization and you can get multiple times speedup you can keep the rest as this most of the coding on applications",
    "start": "429729",
    "end": "436210"
  },
  {
    "text": "probably open in the file drawer some graphs draw a button on the screen or maybe handling network traffic handling",
    "start": "436210",
    "end": "442990"
  },
  {
    "text": "errors through some logical control flows these operations do not really",
    "start": "442990",
    "end": "448419"
  },
  {
    "text": "benefit from GPUs all you need to do is just to optimize the inner loops for example matrix operations and Monte",
    "start": "448419",
    "end": "455440"
  },
  {
    "text": "Carlo simulations and offload these most time-consuming parts of your applications to GPUs you can use minimal",
    "start": "455440",
    "end": "462340"
  },
  {
    "text": "investment get maximum return fpgas on the other hand provide you some",
    "start": "462340",
    "end": "468849"
  },
  {
    "text": "additional benefits for example allows you make custom hardware for specific algorithms there's no instruction sets",
    "start": "468849",
    "end": "475330"
  },
  {
    "text": "or data structure defining FPGA so you can define your own for example if you want to run an application that the",
    "start": "475330",
    "end": "481360"
  },
  {
    "text": "algorithm works best with 15 bits you cannot do in CPU or GPU but you can",
    "start": "481360",
    "end": "487270"
  },
  {
    "text": "easily do an FPGA if you want to create your own up code no problem an FPGA is a",
    "start": "487270",
    "end": "493150"
  },
  {
    "text": "reprogrammable hardware which gives you flexibility to reconfigure the gates to suit your needs you can live upgrade",
    "start": "493150",
    "end": "499270"
  },
  {
    "text": "these algorithms in FPGA you don't have to refabricate a chip which is very expensive which is a very expensive",
    "start": "499270",
    "end": "505330"
  },
  {
    "text": "process fpga also support the concept of dataflow programming you input the data",
    "start": "505330",
    "end": "511750"
  },
  {
    "text": "on one side push it to a series of gates and then you can get the result on the other side unlike GPU which is good for",
    "start": "511750",
    "end": "518500"
  },
  {
    "text": "independence dream calculations for fpga you can really have applications let us",
    "start": "518500",
    "end": "523948"
  },
  {
    "text": "that requires high interdependence between threads this is something that you can't achieve easily in GPU an FPGA",
    "start": "523949",
    "end": "531310"
  },
  {
    "text": "also offers a large local memory and high memory bandwidth so with all these benefits you will be able to",
    "start": "531310",
    "end": "537120"
  },
  {
    "text": "run a workload much faster and much more cost effectively so let me join marriage",
    "start": "537120",
    "end": "542850"
  },
  {
    "start": "541000",
    "end": "541000"
  },
  {
    "text": "between GPU and fpga that's usually how I like to compare and contrast contrast",
    "start": "542850",
    "end": "548340"
  },
  {
    "text": "them so for GPU it's really like highway you can have multiple lanes each link",
    "start": "548340",
    "end": "553710"
  },
  {
    "text": "accommodates lines cars these cars are driving their own lanes unless you you want to switch lanes and there's no",
    "start": "553710",
    "end": "559920"
  },
  {
    "text": "interdependencies you can you can / you can bypass the other cars it's not a problem at toll booths each line has its",
    "start": "559920",
    "end": "566190"
  },
  {
    "text": "own operation which is kleptos and everybody has to pay toast and there's only one operation you can increase the",
    "start": "566190",
    "end": "573270"
  },
  {
    "text": "throughput by easily adding more lanes FPGA is more like assembly lines you",
    "start": "573270",
    "end": "579240"
  },
  {
    "text": "input the raw materials on one side and you can configure assembly line based on the algorithms but any given moment you",
    "start": "579240",
    "end": "585270"
  },
  {
    "text": "can have multiple operations a motive stage of the data just like in Toyota assembly line you can have somebody",
    "start": "585270",
    "end": "590850"
  },
  {
    "text": "installing the engine can have somebody installing the wheels at the same time no problem you can of course make FPJ",
    "start": "590850",
    "end": "597330"
  },
  {
    "text": "data parallel but you're not required to do so so in a SS we are offering both",
    "start": "597330",
    "end": "603720"
  },
  {
    "text": "type of accelerators we started our Saturday compute instance family back in 2010 when we introduced EG one instance",
    "start": "603720",
    "end": "611220"
  },
  {
    "text": "with a pair of nvidia tesla m 2050 Fermi GPUs Lync 2013 we upgraded cg1 to g2",
    "start": "611220",
    "end": "618060"
  },
  {
    "text": "instance with immediate k 520 GPUs I believe some of you may still be running",
    "start": "618060",
    "end": "623400"
  },
  {
    "text": "your workloads on g two instances you can also run you can run direct x opengl",
    "start": "623400",
    "end": "631350"
  },
  {
    "text": "code and opencl code on g2 we just launched p2 instance with Amelia kad",
    "start": "631350",
    "end": "636750"
  },
  {
    "text": "GPUs back in September this year actually September end of September Peter instance supports up to 16 GPS in",
    "start": "636750",
    "end": "643980"
  },
  {
    "text": "one single instance and it supposed to be direct so GPUs can talk to each other without going through CPUs on the FPGA",
    "start": "643980",
    "end": "651090"
  },
  {
    "text": "side we just announced the preview of f1 instance yesterday which was up to 8",
    "start": "651090",
    "end": "657060"
  },
  {
    "text": "silex fpgas and we continue innovating we want to really bring the best how",
    "start": "657060",
    "end": "662100"
  },
  {
    "text": "accelerators just to satisfy your needs so what why should you choose",
    "start": "662100",
    "end": "668490"
  },
  {
    "text": "acceleration is so a device provides you a lot of cloud benefits first of all",
    "start": "668490",
    "end": "673830"
  },
  {
    "text": "it's easy to use easy to instance allows you to developers ISVs and any users to",
    "start": "673830",
    "end": "679649"
  },
  {
    "text": "quickly develop and run your application you can start using gpus in fpgas within minutes you can literally just have a",
    "start": "679649",
    "end": "685980"
  },
  {
    "text": "credit card sign-up account and you can start using g to p2 or f1 secondly its",
    "start": "685980",
    "end": "691560"
  },
  {
    "text": "flexibility we allows you to select whatever multiple types of how",
    "start": "691560",
    "end": "697620"
  },
  {
    "text": "accelerators operating systems programming language based on a needs if you want to use direct you wants cuda on",
    "start": "697620",
    "end": "705149"
  },
  {
    "text": "p2 today and want to switch FPGA tomorrow no problem you don't have to buy any of these chips you just want you",
    "start": "705149",
    "end": "711779"
  },
  {
    "text": "can just start instance on ets he also had have the options to run from one is",
    "start": "711779",
    "end": "717209"
  },
  {
    "text": "one accelerators up to 16 accelerators in one single host a third one is",
    "start": "717209",
    "end": "722310"
  },
  {
    "text": "scalability your application can skips being our resource on demand within minutes we have a massive infrastructure",
    "start": "722310",
    "end": "728730"
  },
  {
    "text": "back in eight arrests and you have access to compute resource where you need them this is very beneficial once",
    "start": "728730",
    "end": "734160"
  },
  {
    "text": "when you want to run batch processing work loads such as deep learning trainings well needs massive computer",
    "start": "734160",
    "end": "739529"
  },
  {
    "text": "resource for short period of time the last one is cost effectiveness instead",
    "start": "739529",
    "end": "745260"
  },
  {
    "text": "of buying our own GPUs you can you can you can get peter enters on demand in North Virginia for ninety cents per hour",
    "start": "745260",
    "end": "751649"
  },
  {
    "text": "and you can you spot instances to access your our spare ec2 capacities at very",
    "start": "751649",
    "end": "757529"
  },
  {
    "text": "low cost it also by reserve instance to guarantee that you have the enough capacity when you need them and receive",
    "start": "757529",
    "end": "763500"
  },
  {
    "text": "a lot of discount on fpga development",
    "start": "763500",
    "end": "768600"
  },
  {
    "text": "has historically a very huge undertaking if you come from w backgrounds you're probably remember the days when you have",
    "start": "768600",
    "end": "774240"
  },
  {
    "text": "to get development boards plug into a computer and install a lot of tools to program these fpga boards the lot of",
    "start": "774240",
    "end": "781529"
  },
  {
    "text": "cell works you need to do before you can even write the first line of fpga code we simplify this process of fpga",
    "start": "781529",
    "end": "788760"
  },
  {
    "text": "development and handled all the undifferentiated heavy lifting for you we provide you Howard development kit",
    "start": "788760",
    "end": "794550"
  },
  {
    "text": "which helps you develop your how acceleration very quickly the Howard development kit we call hdk into",
    "start": "794550",
    "end": "801670"
  },
  {
    "text": "code samples compile scripts debug interface and many other tools that you need to develop FPGA code for f1",
    "start": "801670",
    "end": "807700"
  },
  {
    "text": "instance you can use hdk either in 80 s provided army or you are your on-premise",
    "start": "807700",
    "end": "813790"
  },
  {
    "text": "development environment we also have FPGA developer me for free on the airbase marketplace the f the developer",
    "start": "813790",
    "end": "820750"
  },
  {
    "text": "arm includes a prepackaged to development environment with scripts and tools for simulated fpga design",
    "start": "820750",
    "end": "826830"
  },
  {
    "text": "compiling codes and build a registering your AFI which is which stands for amazon fpga image you can deploy the",
    "start": "826830",
    "end": "834280"
  },
  {
    "text": "fpga developer army on amazon ec2 instance and provision the resource you need when you write and test your fpga",
    "start": "834280",
    "end": "840940"
  },
  {
    "text": "instance so i want to talk a little bit",
    "start": "840940",
    "end": "846220"
  },
  {
    "text": "about or the use cases that we we think that are suitable for how accelerations",
    "start": "846220",
    "end": "852480"
  },
  {
    "text": "for GPU its particular good for machine learning engineering simulations financial simulations virtual reality",
    "start": "852480",
    "end": "859030"
  },
  {
    "text": "in-memory database rendering transcoding as some of you may some of you may have noticed yesterday that we have verizon",
    "start": "859030",
    "end": "865480"
  },
  {
    "text": "on stage talk about running virtual reality workload on GPUs for fpga with",
    "start": "865480",
    "end": "870850"
  },
  {
    "text": "mainly targeting genomics security analyst and a little analytics big data",
    "start": "870850",
    "end": "876490"
  },
  {
    "text": "analytics in search video encoding financial simulation cryptography data compression and chip simulation",
    "start": "876490",
    "end": "883300"
  },
  {
    "text": "acceleration so for machine learning deep learning techniques such as",
    "start": "883300",
    "end": "888550"
  },
  {
    "start": "885000",
    "end": "885000"
  },
  {
    "text": "convolutional neural network requires a lot of floating-point calculations you need to extract features and multiple",
    "start": "888550",
    "end": "894160"
  },
  {
    "text": "layers and these operations are easily parallelizable so it's a very great candidate for accelerated computing as",
    "start": "894160",
    "end": "900670"
  },
  {
    "text": "you can see from the flow diagram are of deep learning don't believe engineering",
    "start": "900670",
    "end": "908920"
  },
  {
    "start": "907000",
    "end": "907000"
  },
  {
    "text": "simulation will be also very great candidates we have a customer later which provides simulation software and",
    "start": "908920",
    "end": "915940"
  },
  {
    "text": "you can see they are simulating the fluids movement using a particle-based",
    "start": "915940",
    "end": "921310"
  },
  {
    "text": "simulations and they actually get very good results they said they're able to leverage the massive amount of aggregate",
    "start": "921310",
    "end": "928210"
  },
  {
    "text": "GPU memory and double precision floating point performance in p2 instance in a",
    "start": "928210",
    "end": "933490"
  },
  {
    "text": "single note and significant reduce customer simulation times and reduce the cost of",
    "start": "933490",
    "end": "939170"
  },
  {
    "text": "running the large simulations so far we have discussed two use cases of GPUs now",
    "start": "939170",
    "end": "945949"
  },
  {
    "text": "allowed to invite poooound jahani to share his experience using GPU to accelerate financial risk simulation we",
    "start": "945949",
    "end": "952310"
  },
  {
    "text": "honest director at on Benefield he's the head of past wise risk management products that include financial models",
    "start": "952310",
    "end": "958579"
  },
  {
    "text": "and software's that run on high-performance GPU computing grid welcome thanks Lady Anne for the great",
    "start": "958579",
    "end": "969170"
  },
  {
    "text": "introduction and thank you everyone for spending the time with us really excited about presenting our use cases to you so",
    "start": "969170",
    "end": "976250"
  },
  {
    "text": "I'll get right to the material so we've",
    "start": "976250",
    "end": "982010"
  },
  {
    "start": "979000",
    "end": "979000"
  },
  {
    "text": "been early adopters of GPU since 2010 what I'll be sharing with user",
    "start": "982010",
    "end": "987529"
  },
  {
    "text": "experiences with accelerated hardware for computational finance especially",
    "start": "987529",
    "end": "993709"
  },
  {
    "text": "GPUs in the life insurance industry so what is path wise path lies currently as",
    "start": "993709",
    "end": "999589"
  },
  {
    "text": "the fastest and most scalable financial risk management solution for insurance",
    "start": "999589",
    "end": "1005050"
  },
  {
    "text": "companies and the computational capabilities that GPUs have been able to",
    "start": "1005050",
    "end": "1010779"
  },
  {
    "text": "offer us we've been able to migrate a lot of clients from traditional legacy",
    "start": "1010779",
    "end": "1016329"
  },
  {
    "text": "systems that were cpu-based and they've been seeing improvements in the order of 50 to 300 x so if you want to put in",
    "start": "1016329",
    "end": "1023649"
  },
  {
    "text": "perspective 300 x means reducing runtime from two weeks down to an hour so that's",
    "start": "1023649",
    "end": "1029230"
  },
  {
    "text": "a say quite impressive and also our platform is a complete risk management",
    "start": "1029230",
    "end": "1035620"
  },
  {
    "text": "solution so what our clients are normally doing is they're using a lot of disjoint siloed systems and they",
    "start": "1035620",
    "end": "1042548"
  },
  {
    "text": "actually migrate to pathways and now they have one high performance system",
    "start": "1042549",
    "end": "1048308"
  },
  {
    "text": "that can actually do everything for them reporting capital calculations reserve calculations hedging risk management do",
    "start": "1048309",
    "end": "1054669"
  },
  {
    "text": "you name it it's basically one complete solution for further needs and its GPU",
    "start": "1054669",
    "end": "1060220"
  },
  {
    "text": "powered and we'll discuss how we're thinking of using FPGAs",
    "start": "1060220",
    "end": "1066230"
  },
  {
    "text": "in the coming months and so basically at",
    "start": "1066230",
    "end": "1071990"
  },
  {
    "text": "a broad level many of the compute intensive calculations that are done in finance it can be categorized into two",
    "start": "1071990",
    "end": "1079100"
  },
  {
    "text": "different buckets well this is our categorization other people might",
    "start": "1079100",
    "end": "1085490"
  },
  {
    "text": "actually categorize them differently but we this maps into how pathways actually",
    "start": "1085490",
    "end": "1091250"
  },
  {
    "text": "treats this calculation so we have a set of calculations that are deterministic these are mostly closed form",
    "start": "1091250",
    "end": "1098169"
  },
  {
    "text": "calculations if you're familiar with like option price things the black-scholes formula you know it's a",
    "start": "1098169",
    "end": "1103429"
  },
  {
    "text": "closed-form formula and so you can",
    "start": "1103429",
    "end": "1108980"
  },
  {
    "text": "actually using data parallelism you can actually run thousands of these calculations in in parallel and also",
    "start": "1108980",
    "end": "1116890"
  },
  {
    "text": "pricing simple instruments like vanilla interest rate swaps which are not",
    "start": "1116890",
    "end": "1123040"
  },
  {
    "text": "sarcastic in nature they can also be done so we can actually send a job calculates I don't know a million",
    "start": "1123040",
    "end": "1129620"
  },
  {
    "text": "different interest rate swaps for me you send it to GP and the GPUs perfectly",
    "start": "1129620",
    "end": "1134780"
  },
  {
    "text": "well suited for these guys of calculations and then the other category are the monte carlo simulations that",
    "start": "1134780",
    "end": "1140000"
  },
  {
    "text": "guess everyone's familiar with so these are done for stochastic calculations where there's a random elements and this",
    "start": "1140000",
    "end": "1147740"
  },
  {
    "text": "is used for pricing exotic options completed options where i'm not going to",
    "start": "1147740",
    "end": "1152900"
  },
  {
    "text": "get into detail but and also complex insurance products that don't have any",
    "start": "1152900",
    "end": "1158090"
  },
  {
    "text": "closed form solution you have to basically solve a partial differential equation stochastic differential",
    "start": "1158090",
    "end": "1163400"
  },
  {
    "text": "equation and there is no way to calculate this in a there's no closed-form formula for this and also",
    "start": "1163400",
    "end": "1168679"
  },
  {
    "text": "this other major problem that's a lot of life insurance companies are facing it's",
    "start": "1168679",
    "end": "1175040"
  },
  {
    "text": "called the su casa con su casa calculations these are basically as you know Monte Carlo simulations are already",
    "start": "1175040",
    "end": "1180980"
  },
  {
    "text": "hard enough so these are stochastic on stochastic calculations are Monte Carlo",
    "start": "1180980",
    "end": "1186919"
  },
  {
    "start": "1182000",
    "end": "1182000"
  },
  {
    "text": "simulations inside other Monte Carlo simulations so you can imagine how complicated that can get being able to",
    "start": "1186919",
    "end": "1194590"
  },
  {
    "text": "handle such a calculation in a risk management software is already quite a big accomplishment",
    "start": "1194590",
    "end": "1199820"
  },
  {
    "text": "a lot of solutions cannot to do this a lot of approximations that are made least squares montecarlo that kind of",
    "start": "1199820",
    "end": "1206570"
  },
  {
    "text": "stuff but that's beyond the scope of this talk then being able to do such a",
    "start": "1206570",
    "end": "1211670"
  },
  {
    "text": "calculation in a realistic amount of time or accept amount of time that will",
    "start": "1211670",
    "end": "1216770"
  },
  {
    "text": "be like the holy grail for the life insurance business here i'm just going",
    "start": "1216770",
    "end": "1221780"
  },
  {
    "text": "to outline briefly what kind of what some magnitude of the problem we're dealing with we're doing a Monte Carlo",
    "start": "1221780",
    "end": "1228860"
  },
  {
    "text": "simulation projection over 30 years so monthly projection time steps or monthly so 12 times 30 about strangers 60 time",
    "start": "1228860",
    "end": "1235850"
  },
  {
    "text": "steps that's the horizontal axis we have an outer loop for montr√©al simulation so",
    "start": "1235850",
    "end": "1243200"
  },
  {
    "text": "those are like a thousand scenarios say thousand scenarios and then each of these thousand scenarios that each time",
    "start": "1243200",
    "end": "1249440"
  },
  {
    "text": "points we're doing another inner loop calculations so there's another model",
    "start": "1249440",
    "end": "1255560"
  },
  {
    "text": "calculation happening there so typically sometimes we use like 5000 scenarios for that to get actually till the exact",
    "start": "1255560",
    "end": "1262310"
  },
  {
    "text": "value um you see this number 30 shocks shocks are actually used first in",
    "start": "1262310",
    "end": "1268640"
  },
  {
    "text": "sensitivity analysis so we're actually calculating finance finite difference",
    "start": "1268640",
    "end": "1273700"
  },
  {
    "text": "you're using sensitivities using finance finite difference methods so these are basically calculating what our product",
    "start": "1273700",
    "end": "1282530"
  },
  {
    "text": "what sensitivity is to movements in the markets stock market goes up and down interest rates go up and down volatility",
    "start": "1282530",
    "end": "1289280"
  },
  {
    "text": "goes up and down we're trying to determine what's the sensitivity so we have to use like a finance find out different message for that we use like",
    "start": "1289280",
    "end": "1295880"
  },
  {
    "text": "shocks up and chalks down so we get like a two-sided find out different so that it provides a more accurate result so if",
    "start": "1295880",
    "end": "1302750"
  },
  {
    "text": "you add this all up together you'll see there's fifty four billion valuations that need to be done for for it and this",
    "start": "1302750",
    "end": "1309650"
  },
  {
    "text": "is just for one policy so these are not 54 billion instructions or calculations",
    "start": "1309650",
    "end": "1316550"
  },
  {
    "text": "these are evaluations and each valuation we're calculating laps and mortality these are actual models that are used to",
    "start": "1316550",
    "end": "1323360"
  },
  {
    "text": "determine whether a policyholder wants to stick with the product or once you leave or god forbid the policyholder",
    "start": "1323360",
    "end": "1329060"
  },
  {
    "text": "passes away also we're using stochastic differential",
    "start": "1329060",
    "end": "1334820"
  },
  {
    "text": "equations and su casa processes to calculate how the indices the stock indices are moving how the interest",
    "start": "1334820",
    "end": "1341420"
  },
  {
    "text": "rates are moving so there's a lot of ink calculations going on in the background as you can see and multiply that by 100",
    "start": "1341420",
    "end": "1350660"
  },
  {
    "text": "thousand or 1 million policies you'll see like what kind of what what's the scale of the problem really is so",
    "start": "1350660",
    "end": "1359830"
  },
  {
    "text": "obviously you can't use CPUs for this and basically we have a limited number",
    "start": "1359830",
    "end": "1367070"
  },
  {
    "text": "of cores and they're not well-suited for parallel calculations so what is good",
    "start": "1367070",
    "end": "1372710"
  },
  {
    "text": "obviously if you look at Flint sticks taxonomy of different architectures the",
    "start": "1372710",
    "end": "1378020"
  },
  {
    "text": "simdi single instruction multiple data here we have an architecture with a note your large number of cores fast memory",
    "start": "1378020",
    "end": "1384350"
  },
  {
    "text": "bandwidth and so allows us to calculate thousands of paths scenarios in parallel",
    "start": "1384350",
    "end": "1390740"
  },
  {
    "text": "and so basically you're you run the same",
    "start": "1390740",
    "end": "1395870"
  },
  {
    "text": "instructions but on different source data and now modern GPUs like and videos",
    "start": "1395870",
    "end": "1402290"
  },
  {
    "text": "latest families they're taking that one step further for the same T architecture",
    "start": "1402290",
    "end": "1407360"
  },
  {
    "text": "so basically what they try to do is basically emulate am md multiple",
    "start": "1407360",
    "end": "1412820"
  },
  {
    "text": "instruction multiple data architecture in a single instruction multiple data",
    "start": "1412820",
    "end": "1417940"
  },
  {
    "text": "architecture so now it has all the benefits of simdi and on top of that we have like we can do achieve higher level",
    "start": "1417940",
    "end": "1425299"
  },
  {
    "text": "of parallelization through multiple flow paths so we didn't start with GPUs I",
    "start": "1425299",
    "end": "1436880"
  },
  {
    "text": "joined the company in 2010 our group started in 2008 so back then our",
    "start": "1436880",
    "end": "1443690"
  },
  {
    "text": "software developers were using the cell processor so that's the processor that",
    "start": "1443690",
    "end": "1450370"
  },
  {
    "text": "was used in the PlayStation 3 if you remember develop our sony toshiba an IBM",
    "start": "1450370",
    "end": "1455630"
  },
  {
    "text": "and but then abruptly they was discontinued in 2009 without giving any",
    "start": "1455630",
    "end": "1461690"
  },
  {
    "text": "reasons so personally fortunately i haven't had experience program that talking to her",
    "start": "1461690",
    "end": "1467450"
  },
  {
    "text": "or software developers they said it was extremely difficult to program was a nightmare they weren't too happy about",
    "start": "1467450",
    "end": "1472790"
  },
  {
    "text": "it and well disadvantages was specialized hardware extremely difficult",
    "start": "1472790",
    "end": "1478100"
  },
  {
    "text": "to program and completely certainly discontinued on then and the other hand we have GPS they're nice commodities in",
    "start": "1478100",
    "end": "1484940"
  },
  {
    "text": "hardware widely available they've been used for federal as long as I remember",
    "start": "1484940",
    "end": "1490100"
  },
  {
    "text": "like on every PC has every laptop every phone everything has a GPU in it so it's",
    "start": "1490100",
    "end": "1496400"
  },
  {
    "text": "proven technology and it's great that",
    "start": "1496400",
    "end": "1501620"
  },
  {
    "text": "Nvidia is providing such great supports their CUDA platform really happy about",
    "start": "1501620",
    "end": "1507920"
  },
  {
    "text": "using that it's and they're constantly improving it they're coming up with new families latest one the Pascal family",
    "start": "1507920",
    "end": "1515810"
  },
  {
    "text": "that was introduced early this year every generation they're doubling the performance so and the other thing is we",
    "start": "1515810",
    "end": "1523970"
  },
  {
    "text": "did some initial benchmarking on GPUs back in 2010 it was the sea 2050 the",
    "start": "1523970",
    "end": "1532100"
  },
  {
    "text": "same ones that Layton mentioned that were in the CG one instances that amazon had and we actually saw like 150 fold",
    "start": "1532100",
    "end": "1540350"
  },
  {
    "text": "improvements using the sea to 2050s versus the best and fastest Xeon",
    "start": "1540350",
    "end": "1546290"
  },
  {
    "text": "processors back then so that was basically a obvious choice for a seagull with GPUs and all the great thing is",
    "start": "1546290",
    "end": "1553400"
  },
  {
    "text": "that we get GPUs they're widely available on Amazon AWS so these are the",
    "start": "1553400",
    "end": "1560030"
  },
  {
    "text": "so mixed you fees though clear favorite for us right now and this basically",
    "start": "1560030",
    "end": "1565730"
  },
  {
    "text": "there's a life slide so you're wondering how there's our system use like how many",
    "start": "1565730",
    "end": "1572480"
  },
  {
    "text": "software engineers that you need these models are constantly changing you're coming up with new strategies for risk",
    "start": "1572480",
    "end": "1579050"
  },
  {
    "text": "management or you're coming up with new requirements new reports whole bunch of new calculations your happening so",
    "start": "1579050",
    "end": "1585760"
  },
  {
    "text": "what's needed a lot of actuaries that use the systems are not software",
    "start": "1585760",
    "end": "1590780"
  },
  {
    "text": "developers the quantitative analysts they might be more familiar with",
    "start": "1590780",
    "end": "1596630"
  },
  {
    "text": "software development but the great thing is that all the business logic everything all",
    "start": "1596630",
    "end": "1601909"
  },
  {
    "text": "the models are actually implemented in the spreadsheet like interface so if you know how to use excel you know how to",
    "start": "1601909",
    "end": "1608210"
  },
  {
    "text": "use our tools so we've developed her own domain specific language the pathways",
    "start": "1608210",
    "end": "1613250"
  },
  {
    "text": "modeling language so all the logic is actually implementing is there and they're basically simple constructs like",
    "start": "1613250",
    "end": "1618830"
  },
  {
    "text": "min max if average some stuff that everyone is familiar with from Excel so",
    "start": "1618830",
    "end": "1625220"
  },
  {
    "text": "that's how the logic is actually implemented and with the press of a button the logic is actually converted",
    "start": "1625220",
    "end": "1633860"
  },
  {
    "text": "into CUDA and you can actually deploy to you to grid and you can see that our",
    "start": "1633860",
    "end": "1641620"
  },
  {
    "text": "modeling language is nicely isolated from all the lower layers so it can",
    "start": "1641620",
    "end": "1649279"
  },
  {
    "text": "actually talk to cuda we can actually run it on NVIDIA GPUs you can generate",
    "start": "1649279",
    "end": "1654710"
  },
  {
    "text": "opencl code running on GPUs our CPUs and we're actually working on supporting",
    "start": "1654710",
    "end": "1661970"
  },
  {
    "text": "FPGAs right now so that can be done or you either using open CL or using a tool",
    "start": "1661970",
    "end": "1667250"
  },
  {
    "text": "that converts the logic into HDL and we're actually very excited about the announcement yesterday that's going to",
    "start": "1667250",
    "end": "1673659"
  },
  {
    "text": "make things much easier for us to support FPGAs uh I worked at alterra",
    "start": "1673659",
    "end": "1679129"
  },
  {
    "text": "FPGA company for seven years myself and I know how gruesome it is to get a fpga",
    "start": "1679129",
    "end": "1685159"
  },
  {
    "text": "cards working and now Amazon's doing all the work for us so really happy about that and that's going to simplify our",
    "start": "1685159",
    "end": "1691309"
  },
  {
    "text": "roadmap for FBG supports quite a bit and so thank you very much for your time and",
    "start": "1691309",
    "end": "1696379"
  },
  {
    "text": "this concludes my part thank [Applause]",
    "start": "1696379",
    "end": "1704809"
  },
  {
    "text": "alright thank you thank you very much Boyan for sharing the 150 times speedup",
    "start": "1709460",
    "end": "1715049"
  },
  {
    "text": "is truly impressive it's great to see that also a PWM l can run on both gpus",
    "start": "1715049",
    "end": "1720630"
  },
  {
    "text": "nav fpgas demonstrate that similar similar to GPU FPJ can also have high",
    "start": "1720630",
    "end": "1727230"
  },
  {
    "text": "potential and very what use cases in accelerated computing one of our focus area of fpga is video encoding now I'd",
    "start": "1727230",
    "end": "1735030"
  },
  {
    "text": "like to turn it over to Oliver gunasekara see your co-founder of ng codec to talk about using cloud FPGA",
    "start": "1735030",
    "end": "1741360"
  },
  {
    "text": "acceleration for live video encoding Oliver has 20 years of mobile experience have been responsible for arms mobile",
    "start": "1741360",
    "end": "1748110"
  },
  {
    "text": "activities starting 1995 he spent 12 years with arm serving as a VP for corporate biz dev and ma until 2007 para",
    "start": "1748110",
    "end": "1756870"
  },
  {
    "text": "to co-founding ng codec in 2012 it was a business development consultant to number of mobile startups the OS",
    "start": "1756870",
    "end": "1763160"
  },
  {
    "text": "security Imogen and battery areas Oliver please",
    "start": "1763160",
    "end": "1769190"
  },
  {
    "text": "great well it's super exciting to be here and thank you too to Amazon for",
    "start": "1773100",
    "end": "1778410"
  },
  {
    "text": "this opportunity our team has been working extremely hard to to really",
    "start": "1778410",
    "end": "1784530"
  },
  {
    "text": "bring together fpgas and the cloud and I'm really excited to actually try and",
    "start": "1784530",
    "end": "1790860"
  },
  {
    "text": "attempt a live demo of an f1 instance in a few minutes so let me move forward by",
    "start": "1790860",
    "end": "1797220"
  },
  {
    "text": "giving you a little bit of background on our company we're a small company we're a start-up were about 15 people we were",
    "start": "1797220",
    "end": "1804870"
  },
  {
    "text": "founded about four years ago primarily from a small Super Angel and xilinx so",
    "start": "1804870",
    "end": "1812100"
  },
  {
    "text": "xilinx is the company that makes the FPGAs they're the market leader and they're the ones that we're",
    "start": "1812100",
    "end": "1818700"
  },
  {
    "text": "demonstrating an amazon has deployed on the f1 instance our technology is really",
    "start": "1818700",
    "end": "1824460"
  },
  {
    "text": "around low latency video encoding specifically the next generation which",
    "start": "1824460",
    "end": "1829770"
  },
  {
    "text": "is called h.265 which can half the bit rate for the same quality as h.264 so",
    "start": "1829770",
    "end": "1838020"
  },
  {
    "text": "it's pretty compelling we have a set about 15 people we have a lot of experience of designing hardware and",
    "start": "1838020",
    "end": "1845549"
  },
  {
    "text": "specifically video and we have some patterns and we're based in sunnyvale so",
    "start": "1845549",
    "end": "1851730"
  },
  {
    "start": "1851000",
    "end": "1851000"
  },
  {
    "text": "first of all I wanted to set the stage for the problem the problem we see is",
    "start": "1851730",
    "end": "1856919"
  },
  {
    "text": "that there is a massive tsunami coming to video workloads and it's coming",
    "start": "1856919",
    "end": "1862679"
  },
  {
    "text": "because of basically three things the first thing is that everyone is consuming vastly more video than they",
    "start": "1862679",
    "end": "1870059"
  },
  {
    "text": "did in the past you know everyone is is streaming video live video looking at",
    "start": "1870059",
    "end": "1876030"
  },
  {
    "text": "things people don't want to read they want to watch a video and and so the growth is just massive Cisco estimates",
    "start": "1876030",
    "end": "1882299"
  },
  {
    "text": "that video is growing at about thirty one percent compound Lee every year",
    "start": "1882299",
    "end": "1887730"
  },
  {
    "text": "that's a massive massive amount of video that is just being consumed and has to be encoded and analyzed and delivered",
    "start": "1887730",
    "end": "1895980"
  },
  {
    "text": "and that's a problem because it's growing so far secondly everybody wants higher quality video people want video",
    "start": "1895980",
    "end": "1903960"
  },
  {
    "text": "not a standard death not even an HD f high definition they",
    "start": "1903960",
    "end": "1910019"
  },
  {
    "text": "want ultra high definition they want 4k they want 10 bits they want HDR they",
    "start": "1910019",
    "end": "1915929"
  },
  {
    "text": "want high frame rate they want white color graphic color gamma they want really super high quality they want 360",
    "start": "1915929",
    "end": "1922980"
  },
  {
    "text": "video they want VR they want AK this again is putting massive demands on",
    "start": "1922980",
    "end": "1928499"
  },
  {
    "text": "infrastructure that needs to encode and process all of that video thirdly",
    "start": "1928499",
    "end": "1934259"
  },
  {
    "text": "because the amount the video is increasing and the quality is increasing",
    "start": "1934259",
    "end": "1939509"
  },
  {
    "text": "we have to do something about the compression because if we use the legacy",
    "start": "1939509",
    "end": "1944899"
  },
  {
    "text": "h.264 which everyone uses today it's over 12 years old it's just not",
    "start": "1944899",
    "end": "1950429"
  },
  {
    "text": "efficient we can with this new standard that was ratified a few years ago half",
    "start": "1950429",
    "end": "1956249"
  },
  {
    "text": "the bit rate for the same quality but there's a caveat it needs up to 10 times",
    "start": "1956249",
    "end": "1963899"
  },
  {
    "text": "more compute to achieve that half the bitrate so you need ten times more cpus",
    "start": "1963899",
    "end": "1969570"
  },
  {
    "text": "at the same resolution and frame rate as you did for h.264 so you put all these",
    "start": "1969570",
    "end": "1976080"
  },
  {
    "text": "free together and we think existing infrastructure is completely overloaded and and so the message is we need a new",
    "start": "1976080",
    "end": "1984749"
  },
  {
    "text": "accelerator we cannot do this on CPUs and GPUs we just cannot keep up and so",
    "start": "1984749",
    "end": "1991559"
  },
  {
    "text": "we think FPGAs are the right approach now what I wanted to do was kind of",
    "start": "1991559",
    "end": "1997169"
  },
  {
    "start": "1992000",
    "end": "1992000"
  },
  {
    "text": "position them at a high level of where we think they fit on the range between",
    "start": "1997169",
    "end": "2002570"
  },
  {
    "text": "CPUs and custom accelerators or a 6 and so on my axes on the bottom I'm showing",
    "start": "2002570",
    "end": "2009470"
  },
  {
    "text": "how efficient is an implementation how fast it is how much power consumption",
    "start": "2009470",
    "end": "2016700"
  },
  {
    "text": "does it take and so obviously to the right you have a custom a cig like the chip that is in your smartphone that's",
    "start": "2016700",
    "end": "2024019"
  },
  {
    "text": "super efficient it has amazing performance super low power but it was",
    "start": "2024019",
    "end": "2029210"
  },
  {
    "text": "designed three years before you got it in your pocket and it's fixed it cannot be changed it they commit that the masks",
    "start": "2029210",
    "end": "2036289"
  },
  {
    "text": "and it gets made so on the flexibility and ease of use it's really really tough and difficult",
    "start": "2036289",
    "end": "2042590"
  },
  {
    "text": "so it's the worst but it has the most efficiency so it's great for consumer products like smartphones on the other",
    "start": "2042590",
    "end": "2049908"
  },
  {
    "text": "extreme is we have the classic CPU the CPU ultimate flexibility everyone loves",
    "start": "2049909",
    "end": "2055820"
  },
  {
    "text": "that we can run code on it any language very very efficient very mature but from",
    "start": "2055820",
    "end": "2061520"
  },
  {
    "text": "a performance and power consumption many orders of magnitude less efficient in",
    "start": "2061520",
    "end": "2066940"
  },
  {
    "text": "the middle is GPUs GPUs are a little bit better than CPUs maybe an order of",
    "start": "2066940",
    "end": "2074990"
  },
  {
    "text": "magnitude better but not two or three or four orders of magnitude but a little",
    "start": "2074990",
    "end": "2081320"
  },
  {
    "text": "bit harder to program you have to use khuda aur opencl you have to describe your parallel data structures you have",
    "start": "2081320",
    "end": "2088429"
  },
  {
    "text": "to also work with the CPU because GPUs on their own typically don't work it's a cpu GPU combined solution because you",
    "start": "2088429",
    "end": "2096320"
  },
  {
    "text": "have to make decisions but definitely more efficient but the new area is FPGAs",
    "start": "2096320",
    "end": "2103390"
  },
  {
    "text": "FPGAs have much more performance in our view an order of magnitude more",
    "start": "2103390",
    "end": "2109280"
  },
  {
    "text": "performance than GPUs because we can program them at the gate level we can",
    "start": "2109280",
    "end": "2114560"
  },
  {
    "text": "actually wire them up differently based on the design as opposed to running software which is what runs on the cpu",
    "start": "2114560",
    "end": "2121160"
  },
  {
    "text": "and GPU but they are harder to program you have to use what's called RTL or use",
    "start": "2121160",
    "end": "2130730"
  },
  {
    "text": "a tool that generates RTL so it's a little bit more complex you have to understand EE and hardware design so",
    "start": "2130730",
    "end": "2138170"
  },
  {
    "text": "they're definitely harder to use but they are Phil programmable meaning you can download a new image each time and",
    "start": "2138170",
    "end": "2146030"
  },
  {
    "text": "change it so they're definitely a lot more flexible and so we think for cloud",
    "start": "2146030",
    "end": "2151880"
  },
  {
    "text": "accelerations specifically for video fpgas make the most sense so what I'd",
    "start": "2151880",
    "end": "2159410"
  },
  {
    "text": "like to do now is actually go to a live demo now this is pretty risky I must say",
    "start": "2159410",
    "end": "2167900"
  },
  {
    "text": "because we are the first people to use the f1 instant",
    "start": "2167900",
    "end": "2173690"
  },
  {
    "text": "and we only got access to the f1 instance actually on Monday we started",
    "start": "2173690",
    "end": "2181430"
  },
  {
    "text": "this project three weeks ago and so monday 5 p.m. we got the first access to",
    "start": "2181430",
    "end": "2188030"
  },
  {
    "text": "the f1 instance now we have had massive support from and we switched the video",
    "start": "2188030",
    "end": "2198350"
  },
  {
    "text": "yeah so it's working so what what we're seeing here is the video that is coming",
    "start": "2198350",
    "end": "2204080"
  },
  {
    "text": "live from this smartphone it's being sent to amazon's data center we are",
    "start": "2204080",
    "end": "2213230"
  },
  {
    "text": "decoding the video on the cpu and then we are sending the decoded video to the",
    "start": "2213230",
    "end": "2219470"
  },
  {
    "text": "f1 instance we're running our encoder h.265 so we're converting the h.264 to",
    "start": "2219470",
    "end": "2226270"
  },
  {
    "text": "h.265 were half the bitrate and then we're streaming it back to the computer",
    "start": "2226270",
    "end": "2232670"
  },
  {
    "text": "here and we're doing all of that live now on the internet there's quite a bit",
    "start": "2232670",
    "end": "2238580"
  },
  {
    "text": "of latency we still have some optimizations to do I would say that",
    "start": "2238580",
    "end": "2244010"
  },
  {
    "text": "this is really a moonshot the the team has been working incredibly hard and not only our team we've had great support",
    "start": "2244010",
    "end": "2251480"
  },
  {
    "text": "from the Amazon folks in in Austin and you know we we were working over",
    "start": "2251480",
    "end": "2257660"
  },
  {
    "text": "thanksgiving in the office but so were they so we were having calls on on the",
    "start": "2257660",
    "end": "2263570"
  },
  {
    "text": "friday for instance of thanksgiving with the amazon team to get all of this done so massive massive amount of effort that",
    "start": "2263570",
    "end": "2272480"
  },
  {
    "text": "has gone in to pull this off in three weeks but it's live it's working we're using the f1 instance to basically half",
    "start": "2272480",
    "end": "2279830"
  },
  {
    "text": "the bitrate so really happy that that worked it was touch and go whether",
    "start": "2279830",
    "end": "2285680"
  },
  {
    "text": "whether we would but super happy about this and again this is a world first i",
    "start": "2285680",
    "end": "2291740"
  },
  {
    "text": "think were the first people to use the f1 instance anywhere on the planet so as an external company so really really",
    "start": "2291740",
    "end": "2298910"
  },
  {
    "text": "happy so let me switch back to the slides and let me sum up",
    "start": "2298910",
    "end": "2304120"
  },
  {
    "text": "okay so this this was the demo that I just showed you so the live stream went",
    "start": "2308160",
    "end": "2313960"
  },
  {
    "text": "from the iphone in h.264 and five megabits into the Amazon f one instance",
    "start": "2313960",
    "end": "2319329"
  },
  {
    "text": "where it was decoded initially and then re-encoded with our encoder to h.265 and",
    "start": "2319329",
    "end": "2325690"
  },
  {
    "text": "then streamed back to the PC on the desk and the key here is that we are having",
    "start": "2325690",
    "end": "2332589"
  },
  {
    "text": "the bitrate so yeah great that that worked first first as I said this is",
    "start": "2332589",
    "end": "2338559"
  },
  {
    "text": "like no one else has ever used the f1 right now okay so let me summarize from",
    "start": "2338559",
    "end": "2345430"
  },
  {
    "text": "a specific point of view how we see FPGAs cpus and gpus fitting together for",
    "start": "2345430",
    "end": "2355210"
  },
  {
    "text": "video encoding so obviously when you talk about video quality for live you're",
    "start": "2355210",
    "end": "2362950"
  },
  {
    "text": "constrained because with a live use case you have to be able to process that within your frame rate and so you cannot",
    "start": "2362950",
    "end": "2371519"
  },
  {
    "text": "use every single instance that you can afford you have real constraints and so",
    "start": "2371519",
    "end": "2378460"
  },
  {
    "text": "the reality is that if you use say x265 which is the open source codec for cpus",
    "start": "2378460",
    "end": "2384999"
  },
  {
    "text": "you have to run with a preset that is fast that doesn't offer great quality it",
    "start": "2384999",
    "end": "2391480"
  },
  {
    "text": "offers quality broadly similar to h.264 in its high quality setting but if you",
    "start": "2391480",
    "end": "2399609"
  },
  {
    "text": "use GPUs you can achieve higher quality and so some folks do that and of course",
    "start": "2399609",
    "end": "2407380"
  },
  {
    "text": "with our FPGA we can also achieve extremely high quality for live but when",
    "start": "2407380",
    "end": "2413559"
  },
  {
    "text": "it comes to latency again software has quite a bit of an overhead but with GPUs",
    "start": "2413559",
    "end": "2420190"
  },
  {
    "text": "there's even more overhead because you have to split the design between CPU and GPU but with an FPGA we can do ultra-low",
    "start": "2420190",
    "end": "2427480"
  },
  {
    "text": "latency not shown here because we haven't tuned it but ultimately we can get down to subframe levels of latency",
    "start": "2427480",
    "end": "2434920"
  },
  {
    "text": "both encode and decode and and so when you talk about the cost because we need less resources we",
    "start": "2434920",
    "end": "2442000"
  },
  {
    "text": "believe the fpgas will be considerably lower costs than using gpus or CPUs now",
    "start": "2442000",
    "end": "2448930"
  },
  {
    "text": "the caveat is you know we have worked on building our encoder over the last 18",
    "start": "2448930",
    "end": "2454630"
  },
  {
    "text": "months so we had it running in an FPGA and we ported it into the f1 instance so",
    "start": "2454630",
    "end": "2460630"
  },
  {
    "text": "it takes quite a large effort to get this up and running but once it's there we plan to have it available in the",
    "start": "2460630",
    "end": "2467290"
  },
  {
    "text": "amazon marketplace for for people to make use of so just to summarize we did",
    "start": "2467290",
    "end": "2474280"
  },
  {
    "text": "this port in three weeks were the first people to do it teams have worked round the clock I'm really really happy and",
    "start": "2474280",
    "end": "2482410"
  },
  {
    "text": "amazed that we we pulled it off we got amazing support from from amazon as well",
    "start": "2482410",
    "end": "2487630"
  },
  {
    "text": "we believe a single f1 instance will be able to do 4k 30 and we can put their up",
    "start": "2487630",
    "end": "2494230"
  },
  {
    "text": "to eight of these FPGAs available and so we can chain them together to go to",
    "start": "2494230",
    "end": "2499240"
  },
  {
    "text": "higher quality like AK or 360 video as needed we believe that we can have",
    "start": "2499240",
    "end": "2505450"
  },
  {
    "text": "significantly higher video quality meaning at a certain bit rate we will have substantially higher quality or",
    "start": "2505450",
    "end": "2511540"
  },
  {
    "text": "need lower bit rate than other encoders and remember the encoder is up to each vendor so no two encoders are the same",
    "start": "2511540",
    "end": "2518920"
  },
  {
    "text": "it's only the decoders that are standardized and then finally ultra-low latency allows us to enable brand new",
    "start": "2518920",
    "end": "2526599"
  },
  {
    "text": "use cases and this is my last slide so an example of a brand new use case is",
    "start": "2526599",
    "end": "2532119"
  },
  {
    "text": "what we call cloud virtual reality augmented reality now in cloud virtual",
    "start": "2532119",
    "end": "2538750"
  },
  {
    "text": "reality the actual computing the game or the AR or the VR experience the whole",
    "start": "2538750",
    "end": "2544630"
  },
  {
    "text": "graphics all runs in the cloud and you just deliver a ultra-low latency video",
    "start": "2544630",
    "end": "2550119"
  },
  {
    "text": "feed back to the consumer now it needs a low latency network right to the end",
    "start": "2550119",
    "end": "2555849"
  },
  {
    "text": "consumer it needs a located network data",
    "start": "2555849",
    "end": "2561130"
  },
  {
    "text": "center that is not geographically too far away because we do have the speed of light issues but if you can achieve that",
    "start": "2561130",
    "end": "2567790"
  },
  {
    "text": "you can ultimately have Optimus rift game experience on a",
    "start": "2567790",
    "end": "2573250"
  },
  {
    "text": "hundred-dollar hmd and just pay per use as you use it in the cloud and we think",
    "start": "2573250",
    "end": "2579550"
  },
  {
    "text": "that's going to be game changing because it will also mean much lower power consumption and in the future of AR we",
    "start": "2579550",
    "end": "2586210"
  },
  {
    "text": "think you'll be able to have an AR experience where you use the whole AWS supercomputer to drive the AR and yet",
    "start": "2586210",
    "end": "2593860"
  },
  {
    "text": "you have a very low cost low power consumption head mounted device that just enables the future so that's all I",
    "start": "2593860",
    "end": "2601570"
  },
  {
    "text": "have here thank you again for the opportunity super excited and let me hand back thank you alright thank you",
    "start": "2601570",
    "end": "2618400"
  },
  {
    "text": "very much for Oliver for the nice presentation it's actually the first public demo of f1 instance I've ever",
    "start": "2618400",
    "end": "2623440"
  },
  {
    "text": "seen alright so we've now seen a lot of use cases of using highway accelerations",
    "start": "2623440",
    "end": "2629110"
  },
  {
    "text": "I want to expect we want to identify what is the right how accelerator for a",
    "start": "2629110",
    "end": "2634360"
  },
  {
    "text": "use case on the other hand we also make sure that we can get most out of from these accelerators so with that I'd like",
    "start": "2634360",
    "end": "2641080"
  },
  {
    "text": "to share some best practices when we use p2 + f1 instances first of all we",
    "start": "2641080",
    "end": "2647980"
  },
  {
    "text": "provide a lot of armies prepackaged machine image so for example if you want",
    "start": "2647980",
    "end": "2653110"
  },
  {
    "text": "to run a deep learning workloads the best arm you can find on a Tobias is the address deep learning army after we",
    "start": "2653110",
    "end": "2659800"
  },
  {
    "text": "launched p 2 i've received a lot of customer questions around how can i best start using PT for deep learning we have",
    "start": "2659800",
    "end": "2667420"
  },
  {
    "text": "to install and video drivers we have to install cuda we have to install cudn n after you install MX net tensorflow",
    "start": "2667420",
    "end": "2673320"
  },
  {
    "text": "torch all these frameworks so the deep learning are be packaged all these",
    "start": "2673320",
    "end": "2678640"
  },
  {
    "text": "software's into one place so you don't need to go through all these manual",
    "start": "2678640",
    "end": "2683890"
  },
  {
    "text": "steps we just launched instance with this army and you could go the second army I want to talk about is FPGA",
    "start": "2683890",
    "end": "2689830"
  },
  {
    "text": "they've def developer army so it gives you a lot of love tues to simplify development on fpgas so FPGA f1 is not",
    "start": "2689830",
    "end": "2698200"
  },
  {
    "text": "in preview if you sign up we'll get back to you on on getting previewing instance",
    "start": "2698200",
    "end": "2704740"
  },
  {
    "text": "also like to talk about some general system tuning tuning tips first of all we recommend keeping linux kernel",
    "start": "2704740",
    "end": "2711740"
  },
  {
    "start": "2705000",
    "end": "2705000"
  },
  {
    "text": "up-to-date at least 3 10 or buff we have customers running on Colonel 22 x",
    "start": "2711740",
    "end": "2718070"
  },
  {
    "text": "version and once they upgrade they see a 30-percent to forty percent performance increase but just by changing the",
    "start": "2718070",
    "end": "2724160"
  },
  {
    "text": "Colonel's if you really care about network performance would like to use we like you you to use enhanced networking",
    "start": "2724160",
    "end": "2730730"
  },
  {
    "text": "or elastic network adapter for best network performance and you can use placement groups to achieve the maximum",
    "start": "2730730",
    "end": "2736400"
  },
  {
    "text": "network bandwidth within the cluster of instances these are all bubbly available",
    "start": "2736400",
    "end": "2741430"
  },
  {
    "text": "in UC too and if you if your application pull a clock posted plug very frequently",
    "start": "2741430",
    "end": "2748820"
  },
  {
    "text": "we recommend using TSE cluck cluck sauce and because for p2 + f1 instances we",
    "start": "2748820",
    "end": "2755180"
  },
  {
    "text": "have large large memory in the host you can fully utilize the host member to",
    "start": "2755180",
    "end": "2760430"
  },
  {
    "text": "catch hot data so you don't have to put data as code in EBS or in SS three you",
    "start": "2760430",
    "end": "2766190"
  },
  {
    "text": "can just put all this data if they fit in in the host memory and then amazon linux is fully optimized for p2 + f1",
    "start": "2766190",
    "end": "2774050"
  },
  {
    "text": "instances oh and we strongly recommend you using Amazon Linux and there's some",
    "start": "2774050",
    "end": "2779660"
  },
  {
    "start": "2779000",
    "end": "2779000"
  },
  {
    "text": "nvidia driver settings for p2 instances for example a lot of people migrate",
    "start": "2779660",
    "end": "2784850"
  },
  {
    "text": "their workload from g2 to p2 and they don't upgrade the GPU drivers so for p2",
    "start": "2784850",
    "end": "2790670"
  },
  {
    "text": "to perform you really need in video driver at minimum of 25 35 29 9 or above",
    "start": "2790670",
    "end": "2797210"
  },
  {
    "text": "to use the GPU direct capabilities and you also want to enable persistence",
    "start": "2797210",
    "end": "2802700"
  },
  {
    "text": "modes by running envidia SMI command if you if you observe if you don't run this",
    "start": "2802700",
    "end": "2808220"
  },
  {
    "text": "command you'll probably observe a long delay when we when type this command because the driver has to initialize",
    "start": "2808220",
    "end": "2813920"
  },
  {
    "text": "itself and then you can set the clock speed at maximum frequency you can also",
    "start": "2813920",
    "end": "2819770"
  },
  {
    "text": "enable disable turbo for burst performance or high consistency all of these can be done through envidia SMI",
    "start": "2819770",
    "end": "2825770"
  },
  {
    "text": "command and what I like to talk about data transfer between memory and CPU and",
    "start": "2825770",
    "end": "2831770"
  },
  {
    "start": "2828000",
    "end": "2828000"
  },
  {
    "text": "GPUs basically a mem copy is a must do for almost virtually or applique",
    "start": "2831770",
    "end": "2836940"
  },
  {
    "text": "and you really want to minimize the number of data minimize data transfer",
    "start": "2836940",
    "end": "2842490"
  },
  {
    "text": "between host membrane GPUs because pcie bandwidth is lower than local memory bandwidth and you want to make sure that",
    "start": "2842490",
    "end": "2849540"
  },
  {
    "text": "the data is memory local to the processor and we recommend both copy",
    "start": "2849540",
    "end": "2856170"
  },
  {
    "text": "before processing so because each CUDA mem copy has overheads and if we have a",
    "start": "2856170",
    "end": "2862280"
  },
  {
    "text": "two-dimensional three-dimensional array you can use cooler mem copy 2d or 3d when covering hard n dimensional arrays",
    "start": "2862280",
    "end": "2868589"
  },
  {
    "text": "instead of using a loop to any use CUDA mem copy and then it's much you get much",
    "start": "2868589",
    "end": "2877170"
  },
  {
    "text": "better performance if you transfer from pink host memory to GPU and it's faster",
    "start": "2877170",
    "end": "2882300"
  },
  {
    "text": "than transfer from payable host memory so this is example the benchmark results",
    "start": "2882300",
    "end": "2889800"
  },
  {
    "text": "if we copy 128 mega mega bytes of data from host memory to a GPU memory if we",
    "start": "2889800",
    "end": "2897000"
  },
  {
    "text": "just cop into one coded map copy call it takes about twenty two milliseconds if",
    "start": "2897000",
    "end": "2902190"
  },
  {
    "text": "we divide it into 32,000 chunks it takes you almost 18 1 milli seconds so that is",
    "start": "2902190",
    "end": "2910109"
  },
  {
    "text": "because for each code of mem copy there's overheads and this examples show",
    "start": "2910109",
    "end": "2917640"
  },
  {
    "text": "use that to copy memory from the Penal from pinked host memory to pick and from",
    "start": "2917640",
    "end": "2926010"
  },
  {
    "text": "payable host memory two GPUs so the memory band was you see approximately",
    "start": "2926010",
    "end": "2932010"
  },
  {
    "text": "about fifteen to twenty percent difference if you if you copy from paint",
    "start": "2932010",
    "end": "2937470"
  },
  {
    "text": "memory two GPUs and the last thing won't",
    "start": "2937470",
    "end": "2943200"
  },
  {
    "text": "talk about is GP direct so p2 instance very good features that enables GPU",
    "start": "2943200",
    "end": "2948270"
  },
  {
    "text": "peer-to-peer communications you can use high-speed DMA transfers to copy method copy data between memories of two GPUs",
    "start": "2948270",
    "end": "2955079"
  },
  {
    "text": "by using coded mem copy p ro Coulomb mcat be pure async depending on whether you want a blocking core non-blocking",
    "start": "2955079",
    "end": "2961020"
  },
  {
    "text": "call and it provides numerous tile access to memory on other GPUs from within the coup de coeur knows so this",
    "start": "2961020",
    "end": "2967230"
  },
  {
    "text": "is a very good feature if you want to run deep learning or hype freak hpc workloads",
    "start": "2967230",
    "end": "2972680"
  },
  {
    "text": "using p two instances with that now we have reached the end of session really",
    "start": "2972680",
    "end": "2978650"
  },
  {
    "text": "appreciate being here that I'm glad that we can talk a little bit more about how acceleration its use cases and best",
    "start": "2978650",
    "end": "2984530"
  },
  {
    "text": "practices I hope can take some of the information home and think about what are the workloads you can migrate from",
    "start": "2984530",
    "end": "2990440"
  },
  {
    "text": "cpu to GPU we've got a lot of easy to documentation and i'll be available to",
    "start": "2990440",
    "end": "2996110"
  },
  {
    "text": "answer your questions after the session so thank you very much [Applause]",
    "start": "2996110",
    "end": "3006569"
  }
]
[
  {
    "start": "0",
    "end": "99000"
  },
  {
    "text": "okay awesome hoping for the best always",
    "start": "1190",
    "end": "6509"
  },
  {
    "text": "helped me I don't know if that's the essence of this presentation welcome",
    "start": "6509",
    "end": "12000"
  },
  {
    "text": "here to migrating massive databases to",
    "start": "12000",
    "end": "17369"
  },
  {
    "text": "the cloud session my name is Aaron Chester I'm the product manager for the",
    "start": "17369",
    "end": "22800"
  },
  {
    "text": "AWS database migration service and the AWS schema conversion tool and we have a",
    "start": "22800",
    "end": "29849"
  },
  {
    "text": "packed agenda we're going to review a few services AWS services that would",
    "start": "29849",
    "end": "37100"
  },
  {
    "text": "basically help you migrate databases and data warehouses to the cloud we'll see a",
    "start": "37100",
    "end": "46200"
  },
  {
    "text": "demo by our to distinguish database engineer sitting here in front of me",
    "start": "46200",
    "end": "51780"
  },
  {
    "text": "Arun and Ramya and no family name because I didn't get",
    "start": "51780",
    "end": "57120"
  },
  {
    "text": "it right and then we have the great honor of having David Yahalom is the CTO",
    "start": "57120",
    "end": "63809"
  },
  {
    "text": "of nya Tech and he's gonna present something new that we just launched this",
    "start": "63809",
    "end": "70500"
  },
  {
    "text": "week which is a document it's a migration playbook on how to migrate an",
    "start": "70500",
    "end": "77970"
  },
  {
    "text": "Oracle database to Postgres so we have a packed agenda",
    "start": "77970",
    "end": "83030"
  },
  {
    "text": "let's start by the way we'll take questions after the demo couple of",
    "start": "83030",
    "end": "89970"
  },
  {
    "text": "questions and then questions at the end of the of the session I just hope I'm",
    "start": "89970",
    "end": "95729"
  },
  {
    "text": "not here alone when the session ends so if you're here you've probably started",
    "start": "95729",
    "end": "103619"
  },
  {
    "text": "the journey to AWS a journey with AWS to AWS and or you're thinking about this",
    "start": "103619",
    "end": "114240"
  },
  {
    "text": "journey and you're questioning where do I start",
    "start": "114240",
    "end": "119850"
  },
  {
    "text": "where do I start this journey how do I start moving to AWS how quickly can I",
    "start": "119850",
    "end": "125939"
  },
  {
    "text": "move to AWS how can i leverage this opportunity of moving to AWS",
    "start": "125939",
    "end": "133160"
  },
  {
    "text": "Andrey architecting or remodeling izing or modernizing my databases my data base",
    "start": "133160",
    "end": "141200"
  },
  {
    "text": "layers my applications we are here to answer these questions or try to answer",
    "start": "141200",
    "end": "149480"
  },
  {
    "text": "these questions and a little bit more to additional questions that we'll be",
    "start": "149480",
    "end": "155090"
  },
  {
    "text": "answering today is what happens if I have a huge database few terabytes of",
    "start": "155090",
    "end": "163550"
  },
  {
    "text": "data base what happens if I need to move off commercial databases to an open",
    "start": "163550",
    "end": "170900"
  },
  {
    "text": "source based one this presentation hopefully will cover or give you some",
    "start": "170900",
    "end": "177790"
  },
  {
    "text": "direction of how to start this journey and I apologize this is a wide room it's",
    "start": "177790",
    "end": "183710"
  },
  {
    "text": "not so I in between here but I'll do my",
    "start": "183710",
    "end": "189200"
  },
  {
    "text": "best to cover all of you so we're gonna talk initially discuss two services that",
    "start": "189200",
    "end": "196820"
  },
  {
    "start": "191000",
    "end": "311000"
  },
  {
    "text": "I am the product manager for there are two services that are in one house one",
    "start": "196820",
    "end": "202730"
  },
  {
    "text": "under one roof the database migration service I'll either call it the database migration",
    "start": "202730",
    "end": "208910"
  },
  {
    "text": "service or DMS it's a service it's an AWS service you can consume it through",
    "start": "208910",
    "end": "216050"
  },
  {
    "text": "the AWS console or through the API and the service helps you to securely",
    "start": "216050",
    "end": "224060"
  },
  {
    "text": "migrate your data to AWS your data bases and your data warehouses to AWS the",
    "start": "224060",
    "end": "232250"
  },
  {
    "text": "other tool is a unique tool for AWS it's the schema conversion tool or I might",
    "start": "232250",
    "end": "238400"
  },
  {
    "text": "refer to it as SCT and the schema conversion tool is a tool that you",
    "start": "238400",
    "end": "244850"
  },
  {
    "text": "download from our website I think it's the only downloadable solution today you",
    "start": "244850",
    "end": "253100"
  },
  {
    "text": "download you can install it locally and you run it locally needless to say the",
    "start": "253100",
    "end": "258560"
  },
  {
    "text": "cost is zero and it can convert your",
    "start": "258560",
    "end": "263720"
  },
  {
    "text": "schema your database and that a warehouse schema from commercial databases to open",
    "start": "263720",
    "end": "272250"
  },
  {
    "text": "source databases and we'll go over an additional features that they have that",
    "start": "272250",
    "end": "278040"
  },
  {
    "text": "we have with the schema conversion tool so far we're very proud of this number we've migrated 45,000 databases and",
    "start": "278040",
    "end": "289130"
  },
  {
    "text": "Counting this is an official AWS number and I think it makes it one of the more",
    "start": "289130",
    "end": "296790"
  },
  {
    "text": "active migration service on the planet and every time I say the planet my",
    "start": "296790",
    "end": "301800"
  },
  {
    "text": "manager corrects many say the universe so we're good that either way all right",
    "start": "301800",
    "end": "307770"
  },
  {
    "text": "so let's start let's jump in into the database migration service so our core",
    "start": "307770",
    "end": "317430"
  },
  {
    "start": "311000",
    "end": "475000"
  },
  {
    "text": "beliefs in AWS in general but specifically in the database migration",
    "start": "317430",
    "end": "324630"
  },
  {
    "text": "service is called DB freedom we want to allow you the freedom to do whatever you",
    "start": "324630",
    "end": "331380"
  },
  {
    "text": "want with the database layer or the data warehouse there this is why we enable",
    "start": "331380",
    "end": "338820"
  },
  {
    "text": "the move from commercial to open source but we also we enable the move from aw",
    "start": "338820",
    "end": "349230"
  },
  {
    "text": "from on-premise to AWS but we also",
    "start": "349230",
    "end": "355340"
  },
  {
    "text": "enable the move from AWS outside okay so",
    "start": "355340",
    "end": "362040"
  },
  {
    "text": "if you're not feeling comfortable with what you get you think it's not fitting",
    "start": "362040",
    "end": "367080"
  },
  {
    "text": "your needs you think whatever reason it there is we do support migration up what",
    "start": "367080",
    "end": "374130"
  },
  {
    "text": "we do not support is migration between an on-premise and an on-premise database",
    "start": "374130",
    "end": "380540"
  },
  {
    "text": "the main reason is first it's possible",
    "start": "380540",
    "end": "386100"
  },
  {
    "text": "through the product itself it's not supported through the License Agreement okay and the reason is that and I'm not",
    "start": "386100",
    "end": "396540"
  },
  {
    "text": "sure how many raise of hands if you've heard about DMS",
    "start": "396540",
    "end": "403310"
  },
  {
    "text": "okay and use the DMS okay so we are",
    "start": "403310",
    "end": "409020"
  },
  {
    "text": "narrowing down SC t if you've used s city okay so we're good percentage here the",
    "start": "409020",
    "end": "419460"
  },
  {
    "text": "cost of DMS is relatively low you can migrate a terabyte of data for sometimes",
    "start": "419460",
    "end": "430190"
  },
  {
    "text": "for $3 if you compare it to a competitive solution it's nothing what",
    "start": "430190",
    "end": "437640"
  },
  {
    "text": "we did did do an launch a couple of weeks ago actually a month already time",
    "start": "437640",
    "end": "444690"
  },
  {
    "text": "is they're flying when you're having fun is that DMS the usage of DMS the",
    "start": "444690",
    "end": "452160"
  },
  {
    "text": "migration service itself is free for migrations to Aurora dynamo and redshift",
    "start": "452160",
    "end": "460640"
  },
  {
    "text": "okay so if your target is Aurora both of them by the way dynamo DB or a redshift",
    "start": "460640",
    "end": "471090"
  },
  {
    "text": "it's free so what do we do which use",
    "start": "471090",
    "end": "477450"
  },
  {
    "start": "475000",
    "end": "671000"
  },
  {
    "text": "cases do we support in DMS the product is easy to use but it supports many many",
    "start": "477450",
    "end": "486240"
  },
  {
    "text": "complex use cases okay so you can use the product in many many way the list",
    "start": "486240",
    "end": "493650"
  },
  {
    "text": "that I have here is a list of a number of most common use cases for example DMS",
    "start": "493650",
    "end": "501600"
  },
  {
    "text": "and we'll show how it works helps you migrate business critical application",
    "start": "501600",
    "end": "507150"
  },
  {
    "text": "because it's it allows minimal downtime it gets the two databases in sync before",
    "start": "507150",
    "end": "513270"
  },
  {
    "text": "you switch you can use the MS to migrate from classic to V PC or data warehouse",
    "start": "513270",
    "end": "523110"
  },
  {
    "text": "to Amazon redshift you can archive all",
    "start": "523110",
    "end": "528660"
  },
  {
    "text": "data the MS is a logical replication engine it it reads and can manipulate the data",
    "start": "528660",
    "end": "536010"
  },
  {
    "text": "to some extent so if you have a database for example of 3 terabytes and only 1",
    "start": "536010",
    "end": "542790"
  },
  {
    "text": "terabyte is active you can use DMS to send the active information to one",
    "start": "542790",
    "end": "549930"
  },
  {
    "text": "database and the archived information to s3 bucket and from there pick it up to",
    "start": "549930",
    "end": "556800"
  },
  {
    "text": "glacier or whatever your your choices",
    "start": "556800",
    "end": "563330"
  },
  {
    "text": "upgrade minor versions or skip a minor version if my sequel 5 5 2 5 7 a common",
    "start": "563330",
    "end": "572490"
  },
  {
    "text": "use case consolidate charts into Aurora since Aurora supports 64 terabyte it's",
    "start": "572490",
    "end": "581520"
  },
  {
    "text": "now big enough to hold the entire usually many shards of my sequel so or",
    "start": "581520",
    "end": "589250"
  },
  {
    "text": "Postgres so now you can use the MS to consolidate those shards another very",
    "start": "589250",
    "end": "597810"
  },
  {
    "text": "common use case is offload data for",
    "start": "597810",
    "end": "603660"
  },
  {
    "text": "analytics in the cloud so sometimes you replicate data between a commercial",
    "start": "603660",
    "end": "611010"
  },
  {
    "text": "database and open source database and redshift or s3 for data leaks a very",
    "start": "611010",
    "end": "617040"
  },
  {
    "text": "common use case that we see with DMS and the last one is since we support MongoDB",
    "start": "617040",
    "end": "625920"
  },
  {
    "text": "as a source and dynamo as a serve as a DynamoDB as a target you can migrate",
    "start": "625920",
    "end": "631440"
  },
  {
    "text": "data from to diagram or from Oracle or any other supported",
    "start": "631440",
    "end": "637680"
  },
  {
    "text": "environment and this is the list of the sources that that we support to dynamo",
    "start": "637680",
    "end": "644250"
  },
  {
    "text": "or from to any of the supported targets as you can see our list of",
    "start": "644250",
    "end": "653160"
  },
  {
    "text": "sources and targets are not one-to-one but we are working to enable as many",
    "start": "653160",
    "end": "662370"
  },
  {
    "text": "sources to be as many targets and versa okay okay",
    "start": "662370",
    "end": "670010"
  },
  {
    "text": "so let's move on now we are talking about the schema conversion tool again",
    "start": "670010",
    "end": "675330"
  },
  {
    "start": "671000",
    "end": "838000"
  },
  {
    "text": "it's a downloadable tool that you can download from our website install it on",
    "start": "675330",
    "end": "680880"
  },
  {
    "text": "your local machine and use it what does the schema conversion tool do does it",
    "start": "680880",
    "end": "690060"
  },
  {
    "text": "helps you convert your schema it basically scans your schema and your",
    "start": "690060",
    "end": "696540"
  },
  {
    "text": "schema object and gives you a good view",
    "start": "696540",
    "end": "702000"
  },
  {
    "text": "of what is possible and what requires",
    "start": "702000",
    "end": "708510"
  },
  {
    "text": "some efforts to convert same for data",
    "start": "708510",
    "end": "714750"
  },
  {
    "text": "warehouses so you'll see in the next slide or one of the next slides the list",
    "start": "714750",
    "end": "722250"
  },
  {
    "text": "of supported data warehouses it can also that's a common questions",
    "start": "722250",
    "end": "728760"
  },
  {
    "text": "that I get because migrating databases usually requires migrating or",
    "start": "728760",
    "end": "735390"
  },
  {
    "text": "modernizing some code in the application usually more than some code of the",
    "start": "735390",
    "end": "741480"
  },
  {
    "text": "application it can scan your your code identify sequel statements embedded in",
    "start": "741480",
    "end": "749160"
  },
  {
    "text": "the code and attempt to convert those",
    "start": "749160",
    "end": "753800"
  },
  {
    "text": "okay it can also give you a good",
    "start": "755300",
    "end": "760980"
  },
  {
    "text": "understanding I mentioned it a good understanding of the type of efforts you",
    "start": "760980",
    "end": "769500"
  },
  {
    "text": "will need in order to convert your schema but it can also evaluate your",
    "start": "769500",
    "end": "775230"
  },
  {
    "text": "current license so if you are paying to Oracle or sequel server for an in Oracle",
    "start": "775230",
    "end": "783930"
  },
  {
    "text": "the Enterprise Edition which I'm assuming most of you are and you're not",
    "start": "783930",
    "end": "790530"
  },
  {
    "text": "using the features for the enterprise addition it can give you an assessment of that but",
    "start": "790530",
    "end": "801040"
  },
  {
    "text": "if you're also thinking about moving from oracle on-premise to RDS oracle or",
    "start": "801040",
    "end": "809170"
  },
  {
    "text": "the s4 oracle then it can also give you the changes you need to make for moving",
    "start": "809170",
    "end": "817410"
  },
  {
    "text": "the last thing that I'll mention about SCT in this slide is that it can only",
    "start": "817410",
    "end": "822670"
  },
  {
    "text": "also copy or schema in your schema objects okay so if you are moving homogeneous migration meaning like to",
    "start": "822670",
    "end": "831279"
  },
  {
    "text": "like same database it can copy or a schema as well",
    "start": "831279",
    "end": "836970"
  },
  {
    "start": "838000",
    "end": "886000"
  },
  {
    "text": "okay so database migration is a process",
    "start": "838079",
    "end": "843670"
  },
  {
    "text": "it's a process that is we obviously simplified it a lot but it's it will",
    "start": "843670",
    "end": "852370"
  },
  {
    "text": "focus here on the two-step process the first one is I go through the assessment",
    "start": "852370",
    "end": "860529"
  },
  {
    "text": "I connect SCT the schema conversion tool to my database and I evaluate what I",
    "start": "860529",
    "end": "870610"
  },
  {
    "text": "have and what needs to be done in order to move I can try to convert it I can",
    "start": "870610",
    "end": "879490"
  },
  {
    "text": "copy depends on what what is that I'm trying to achieve the second step is",
    "start": "879490",
    "end": "886990"
  },
  {
    "text": "that I'm using DMS to move the data okay so SCT again is the tool that",
    "start": "886990",
    "end": "896879"
  },
  {
    "text": "evaluates and assesses and gives you a good view and converts as much as as it",
    "start": "896879",
    "end": "903790"
  },
  {
    "text": "can and DMS moves the data wants the target schema is ready now when you",
    "start": "903790",
    "end": "915970"
  },
  {
    "text": "start this journey and I get this all the time is where do I",
    "start": "915970",
    "end": "923089"
  },
  {
    "text": "start I have 500 600 applications",
    "start": "923089",
    "end": "928250"
  },
  {
    "text": "sorry databases that's a good state sometimes they are like 3,000 5,000 I",
    "start": "928250",
    "end": "933709"
  },
  {
    "text": "don't know where to start and usually these databases don't look the same like that completely different the",
    "start": "933709",
    "end": "940070"
  },
  {
    "text": "environment the schema the object in SE T in the schema conversion tool we have",
    "start": "940070",
    "end": "947779"
  },
  {
    "text": "the migration assessment what is the migration assessment I connect SCT to",
    "start": "947779",
    "end": "953300"
  },
  {
    "text": "the source database and I press SS the",
    "start": "953300",
    "end": "958339"
  },
  {
    "text": "assessment gives me a good report a good",
    "start": "958339",
    "end": "964399"
  },
  {
    "text": "indications or it's not a good report it's a good indication of the difficulty",
    "start": "964399",
    "end": "969949"
  },
  {
    "text": "for my gray or converting my source to",
    "start": "969949",
    "end": "975920"
  },
  {
    "text": "the different options that I have in this case just if you can see the",
    "start": "975920",
    "end": "983510"
  },
  {
    "text": "database object conversion to Amazon or Ora now sorry I can do it on all four",
    "start": "983510",
    "end": "989980"
  },
  {
    "text": "screen so I'll do it here and there but it can it gives you the same assessment",
    "start": "989980",
    "end": "997579"
  },
  {
    "text": "in the same report for converting this Oracle to my sequel converting this",
    "start": "997579",
    "end": "1004779"
  },
  {
    "text": "Oracle to Postgres converting this Oracle to Aurora my sequel and",
    "start": "1004779",
    "end": "1009970"
  },
  {
    "text": "converting this to Aurora Postgres and also what it will require to migrate",
    "start": "1009970",
    "end": "1016480"
  },
  {
    "text": "from Oracle to Oracle same report it gives you kind of it goes object by",
    "start": "1016480",
    "end": "1026770"
  },
  {
    "text": "object and tells you how many the green represents that I can automatically",
    "start": "1026770",
    "end": "1034298"
  },
  {
    "text": "convert and the schema conversion tool will convert for you gray requires some",
    "start": "1034299",
    "end": "1041938"
  },
  {
    "text": "difficulties of conversion and the red requires manual hello I'd say a lot but",
    "start": "1041939",
    "end": "1051220"
  },
  {
    "text": "requires manual efforts for example sequences are not supported in my sequel",
    "start": "1051220",
    "end": "1059320"
  },
  {
    "text": "but they are supported in Oracle so you'll have to convert your sequences",
    "start": "1059320",
    "end": "1065650"
  },
  {
    "text": "however it also gives you instructions",
    "start": "1065650",
    "end": "1070960"
  },
  {
    "text": "of how to do it okay so we're not leaving you in the dark I know it's it gives you a good in the",
    "start": "1070960",
    "end": "1080309"
  },
  {
    "text": "calls out the object and what is the",
    "start": "1080309",
    "end": "1086500"
  },
  {
    "text": "recommended action now when David goes on stage he will go over a more detailed",
    "start": "1086500",
    "end": "1094890"
  },
  {
    "text": "instruction step by step migration instruction so that's the schema",
    "start": "1094890",
    "end": "1101679"
  },
  {
    "text": "conversion - this is the starting point this is the starting point for evaluating what I have and how do I what",
    "start": "1101679",
    "end": "1108520"
  },
  {
    "text": "are the efforts to migrate what are the efforts to convert or modernize if I if I want to okay another capability that",
    "start": "1108520",
    "end": "1122620"
  },
  {
    "start": "1120000",
    "end": "1222000"
  },
  {
    "text": "we have an SCT is are the data extractors so locally on your machines",
    "start": "1122620",
    "end": "1130120"
  },
  {
    "text": "if you have a cluster of data warehouse yesterday I met a customer was 250",
    "start": "1130120",
    "end": "1138130"
  },
  {
    "text": "sequel servers you can download these extractors from the SCT install them on",
    "start": "1138130",
    "end": "1146740"
  },
  {
    "text": "your clusters extract the data from these five supported environments or it",
    "start": "1146740",
    "end": "1154210"
  },
  {
    "text": "should be six I don't know we're missing one we were missing the sequel server I apologize green plum Vertica Oracle Tara",
    "start": "1154210",
    "end": "1162520"
  },
  {
    "text": "data and the netezza SCT optimizes the",
    "start": "1162520",
    "end": "1167830"
  },
  {
    "text": "file and optimizes them for redshift and",
    "start": "1167830",
    "end": "1174539"
  },
  {
    "text": "pushes them to an s3 bucket in AWS and",
    "start": "1174539",
    "end": "1181679"
  },
  {
    "text": "then with a copy command we pick it up into redshift",
    "start": "1181679",
    "end": "1188010"
  },
  {
    "text": "okay so that's another capability that the SCT has so we have the assessment",
    "start": "1188010",
    "end": "1193450"
  },
  {
    "text": "report we have the license evaluation we have the conversion capability but we",
    "start": "1193450",
    "end": "1200050"
  },
  {
    "text": "also have the we have the scanning of the code and converting the embedded",
    "start": "1200050",
    "end": "1206860"
  },
  {
    "text": "sequels and we also have those data extractors and in a second you'll see",
    "start": "1206860",
    "end": "1212860"
  },
  {
    "text": "that there's a new capability that we've recently added to migrate again large",
    "start": "1212860",
    "end": "1217990"
  },
  {
    "text": "databases and they eat aware houses so I",
    "start": "1217990",
    "end": "1223410"
  },
  {
    "start": "1222000",
    "end": "1394000"
  },
  {
    "text": "spoke about moving databases I spoke about converting and schemas now I'm",
    "start": "1223410",
    "end": "1234309"
  },
  {
    "text": "gonna cover a little bit about the AWS",
    "start": "1234309",
    "end": "1240309"
  },
  {
    "text": "snowball how many of you have heard about the snowball okay so that's better",
    "start": "1240309",
    "end": "1246340"
  },
  {
    "text": "than the MS in a city where we're doing good here when an upward trajectory here",
    "start": "1246340",
    "end": "1252160"
  },
  {
    "text": "good so AWS snowball petabyte scale data",
    "start": "1252160",
    "end": "1261750"
  },
  {
    "text": "transfer transport solution it's pretty heavy guys now this is empty imagine",
    "start": "1261750",
    "end": "1269470"
  },
  {
    "text": "what happens when it has data inside and the guys here had to carry it with the",
    "start": "1269470",
    "end": "1275980"
  },
  {
    "text": "mile-and-a-half from the entrance to MGM so this is it what we have done is we've",
    "start": "1275980",
    "end": "1284320"
  },
  {
    "text": "released just I'm not carrying it all the way there",
    "start": "1284320",
    "end": "1290700"
  },
  {
    "text": "we've released an integration between aw",
    "start": "1290700",
    "end": "1297660"
  },
  {
    "text": "DMS and snowball and snowball is by the",
    "start": "1297660",
    "end": "1306940"
  },
  {
    "text": "okay we fixed it to terabyte sorry I forgot that we fixed it snowball the",
    "start": "1306940",
    "end": "1312160"
  },
  {
    "text": "rule of thumb when using snowball is when it takes you over a week to move",
    "start": "1312160",
    "end": "1320230"
  },
  {
    "text": "data from your premises to AWS on your",
    "start": "1320230",
    "end": "1326649"
  },
  {
    "text": "spare network capacity then we recommend using snowball now you can push as many",
    "start": "1326649",
    "end": "1335950"
  },
  {
    "text": "terabytes as you want over the network obviously sometimes you'll even choke it",
    "start": "1335950",
    "end": "1342570"
  },
  {
    "text": "sometimes you're an isolated region like we recently visited South America where",
    "start": "1342570",
    "end": "1350970"
  },
  {
    "text": "Network goes through Miami",
    "start": "1350970",
    "end": "1355980"
  },
  {
    "text": "sometimes network is bad sometimes the files are too big so again",
    "start": "1356460",
    "end": "1365980"
  },
  {
    "text": "our rule of thumb is that when it takes more than a week to migrate your data to",
    "start": "1365980",
    "end": "1375510"
  },
  {
    "text": "AWS then consider snowball as a no as an",
    "start": "1375510",
    "end": "1383950"
  },
  {
    "text": "option that's in case the snowball",
    "start": "1383950",
    "end": "1391539"
  },
  {
    "text": "doesn't show up have you seen this one",
    "start": "1391539",
    "end": "1397750"
  },
  {
    "text": "last years okay so if you're really serious about it this is where you need",
    "start": "1397750",
    "end": "1403600"
  },
  {
    "text": "to get but true story the logo police",
    "start": "1403600",
    "end": "1411029"
  },
  {
    "text": "since we changed the logo since last year they wanted me to change the logo on the slide and I said ok but so but",
    "start": "1411029",
    "end": "1421210"
  },
  {
    "text": "couldn't figure out the secrets of Photoshop so anyway",
    "start": "1421210",
    "end": "1432059"
  },
  {
    "text": "DMS and snowball what does it give me first of all five terabytes or more it's",
    "start": "1433560",
    "end": "1441660"
  },
  {
    "text": "usually five days in a good network conditions might be worthwhile you know",
    "start": "1441660",
    "end": "1450000"
  },
  {
    "text": "integrating or using snowball if you",
    "start": "1450000",
    "end": "1456000"
  },
  {
    "text": "have many databases maybe not large ones but you have 300 databases different sizes maybe it's",
    "start": "1456000",
    "end": "1467460"
  },
  {
    "text": "better to use snowball a cup maybe a couple of snowballs when you have slow",
    "start": "1467460",
    "end": "1473520"
  },
  {
    "text": "Network when you don't want to choke the network and the last one is sometimes",
    "start": "1473520",
    "end": "1482400"
  },
  {
    "text": "there are security concerns you know there compliances that requires",
    "start": "1482400",
    "end": "1489420"
  },
  {
    "text": "that do not allow you to move data through an AWS service we don't do it",
    "start": "1489420",
    "end": "1499530"
  },
  {
    "text": "you push the snowball and send it to AWS",
    "start": "1499530",
    "end": "1506940"
  },
  {
    "text": "and we upload the data so these are just",
    "start": "1506940",
    "end": "1511950"
  },
  {
    "text": "the common use cases but again if you're isolated if you have multiple occasions",
    "start": "1511950",
    "end": "1520520"
  },
  {
    "text": "many many good reasons that for use the combination let me explain how it works",
    "start": "1520640",
    "end": "1530520"
  },
  {
    "start": "1527000",
    "end": "1541000"
  },
  {
    "text": "okay because I spoke about the combination and I want to speak about the how it works so you understand later",
    "start": "1530520",
    "end": "1538590"
  },
  {
    "text": "what you're also going to see in the demo so I said that we support near zero",
    "start": "1538590",
    "end": "1546780"
  },
  {
    "start": "1541000",
    "end": "1684000"
  },
  {
    "text": "down downtime you used to call it down tie and at zero downtime but we change it to near zero because the switching of",
    "start": "1546780",
    "end": "1554940"
  },
  {
    "text": "the dns also requires some downtime so in this view I",
    "start": "1554940",
    "end": "1562560"
  },
  {
    "text": "have my application users connected to a database that is not on AWS premises",
    "start": "1562560",
    "end": "1569570"
  },
  {
    "text": "happily working on the database and I start our application instance our",
    "start": "1569570",
    "end": "1576180"
  },
  {
    "text": "replication instance are basically an easy to machines that you can choose the",
    "start": "1576180",
    "end": "1581310"
  },
  {
    "text": "instances that you want to use based on the volume based on the based on the i/o",
    "start": "1581310",
    "end": "1588950"
  },
  {
    "text": "many different parameters you start the",
    "start": "1588950",
    "end": "1594540"
  },
  {
    "text": "migration replication the DMS replication you connect okay you connect",
    "start": "1594540",
    "end": "1603050"
  },
  {
    "text": "between the two databases then what happens is that we start you select",
    "start": "1603050",
    "end": "1610890"
  },
  {
    "text": "sorry you select the schema the tables the schemas the databases again the MS",
    "start": "1610890",
    "end": "1618390"
  },
  {
    "text": "is a logical replication meaning that you can choose tables choose data choose",
    "start": "1618390",
    "end": "1624510"
  },
  {
    "text": "columns choose you can manipulate the data that's moving then you move the",
    "start": "1624510",
    "end": "1632880"
  },
  {
    "text": "full load so you move whatever is currently in your database and when that",
    "start": "1632880",
    "end": "1637980"
  },
  {
    "text": "is done you move all the changes that happened while the database was moving",
    "start": "1637980",
    "end": "1645210"
  },
  {
    "text": "so this change data capture once these two databases are in full sync you can",
    "start": "1645210",
    "end": "1653490"
  },
  {
    "text": "switch the DNS and have your users run",
    "start": "1653490",
    "end": "1659760"
  },
  {
    "text": "on the new database now this is true for",
    "start": "1659760",
    "end": "1666030"
  },
  {
    "text": "homogeneous migrations and heterogeneous migrations meaning that I can do it from",
    "start": "1666030",
    "end": "1672860"
  },
  {
    "text": "databases for example my sequel to my sequel or I can do it from sequel server",
    "start": "1672860",
    "end": "1678780"
  },
  {
    "text": "to post quests ok now regarding the",
    "start": "1678780",
    "end": "1685230"
  },
  {
    "start": "1684000",
    "end": "1731000"
  },
  {
    "text": "change data capture there is no agent installed it's not",
    "start": "1685230",
    "end": "1692170"
  },
  {
    "text": "intrusive we leverage the bin logs their",
    "start": "1692170",
    "end": "1697630"
  },
  {
    "text": "transaction logs we call the native API of the specific database okay so once",
    "start": "1697630",
    "end": "1707350"
  },
  {
    "text": "the transaction once the database starts loading through DMS we start collecting",
    "start": "1707350",
    "end": "1716260"
  },
  {
    "text": "all these changes and applying them once the database is migrated until these two",
    "start": "1716260",
    "end": "1724210"
  },
  {
    "text": "are in full sync again so that's the",
    "start": "1724210",
    "end": "1730360"
  },
  {
    "text": "basics of DMS now how does the DMS work with snowball because this is an",
    "start": "1730360",
    "end": "1737230"
  },
  {
    "start": "1731000",
    "end": "1778000"
  },
  {
    "text": "appliance and on-premise appliance that you order from UPS so in this setting I",
    "start": "1737230",
    "end": "1743830"
  },
  {
    "text": "have a database and a snowball and I",
    "start": "1743830",
    "end": "1749440"
  },
  {
    "text": "have an Amazon bucket that I set up my DMS instance and my target database so",
    "start": "1749440",
    "end": "1757810"
  },
  {
    "text": "what happens here so first of all I initiate a local replication agent from",
    "start": "1757810",
    "end": "1764800"
  },
  {
    "text": "is city so this is a new capability that we've added in a city you now have a",
    "start": "1764800",
    "end": "1771070"
  },
  {
    "text": "local agent a local replication agent the to install locally on premises you",
    "start": "1771070",
    "end": "1778930"
  },
  {
    "text": "connect all the pieces so you connect the local replication to the source database to snowball to the s3 bucket",
    "start": "1778930",
    "end": "1787660"
  },
  {
    "text": "and through the DMS through the to the target database your show will show it",
    "start": "1787660",
    "end": "1794410"
  },
  {
    "text": "in the demo and now you move the full load of the database whatever size it is",
    "start": "1794410",
    "end": "1801370"
  },
  {
    "text": "you move it to the snowball locally what happens in the meantime is that we're",
    "start": "1801370",
    "end": "1807190"
  },
  {
    "text": "starting to copy all the changes to the",
    "start": "1807190",
    "end": "1812410"
  },
  {
    "text": "s3 bucket the blue line represents the CDC ok so while I'm uploading the data",
    "start": "1812410",
    "end": "1818320"
  },
  {
    "text": "to my snowball changes keep happening and I being copied to the s3 bucket I'm done",
    "start": "1818320",
    "end": "1826720"
  },
  {
    "text": "I'm disconnecting now look at my beautiful graphics you want to see it",
    "start": "1826720",
    "end": "1834520"
  },
  {
    "text": "again now shipped to the AWS AWS connects the",
    "start": "1834520",
    "end": "1843549"
  },
  {
    "text": "snowball to the data center and the off",
    "start": "1843549",
    "end": "1848679"
  },
  {
    "text": "the full load starts downloading into",
    "start": "1848679",
    "end": "1853990"
  },
  {
    "text": "the source database to the story the target database okay once we've",
    "start": "1853990",
    "end": "1859600"
  },
  {
    "text": "downloaded the snowball Porsche portion",
    "start": "1859600",
    "end": "1865390"
  },
  {
    "text": "we're now starting to copy all the CDC changes thank you",
    "start": "1865390",
    "end": "1872559"
  },
  {
    "text": "we worked very hard on it",
    "start": "1872559",
    "end": "1876059"
  },
  {
    "text": "now you can do multiple to multiple okay you can take many databases on one",
    "start": "1880320",
    "end": "1888130"
  },
  {
    "text": "snowball again 90 terabytes is the capacity you can order as many snowballs",
    "start": "1888130",
    "end": "1894700"
  },
  {
    "text": "as you want and I'm not sure about that but you can enough snowballs and move",
    "start": "1894700",
    "end": "1903700"
  },
  {
    "text": "the data to different targets okay so it doesn't need to be one-to-one and with",
    "start": "1903700",
    "end": "1911890"
  },
  {
    "text": "that I would like to invite my fellow database engineers Arun and Ramya to",
    "start": "1911890",
    "end": "1919840"
  },
  {
    "text": "give you the short demo that we prepared",
    "start": "1919840",
    "end": "1925380"
  },
  {
    "text": "thanks Ron all right hello hello everyone my name",
    "start": "1927179",
    "end": "1933559"
  },
  {
    "text": "is Erin and I currently work as a database engineer with the DMS team at AWS today we are going to see a quick",
    "start": "1933559",
    "end": "1941659"
  },
  {
    "text": "demo on how to migrate a multi terabyte Oracle database from an on-premises data center into a Roda Postgres in AWS so",
    "start": "1941659",
    "end": "1950240"
  },
  {
    "text": "before I start off with the demo that's exactly what we are going to do we are",
    "start": "1950240",
    "end": "1955309"
  },
  {
    "text": "going to use the newly launched snowball integration or DMS and show you what",
    "start": "1955309",
    "end": "1961879"
  },
  {
    "text": "what what steps to take and what we did in order to migrate that multi data by database from Oracle into our Roda",
    "start": "1961879",
    "end": "1968870"
  },
  {
    "text": "Postgres so before I show you the demo I'm gonna walk you quickly through the",
    "start": "1968870",
    "end": "1975200"
  },
  {
    "start": "1970000",
    "end": "2300000"
  },
  {
    "text": "steps we took in order to achieve that first we are do snowball appliance from the ablest console we then set up a",
    "start": "1975200",
    "end": "1982549"
  },
  {
    "text": "snowball in the source data center we then configure and install the local DMS",
    "start": "1982549",
    "end": "1988730"
  },
  {
    "text": "application agent which is the new capability in SE d that Erin talked about we then use the schema conversion",
    "start": "1988730",
    "end": "1995149"
  },
  {
    "text": "tool to convert the schema from the Oracle source to the Aurora Post Chris sequel target this is going to migrate",
    "start": "1995149",
    "end": "2001570"
  },
  {
    "text": "all these secondary objects the data table structures and everything like that then we create and start a couple",
    "start": "2001570",
    "end": "2008830"
  },
  {
    "text": "of tasks one is a local task which is going to migrate data into the snowball appliance that task is also going to",
    "start": "2008830",
    "end": "2014710"
  },
  {
    "text": "take care of migrating changes into an s3 bucket in in parallel and we also create a remote replication task which",
    "start": "2014710",
    "end": "2021820"
  },
  {
    "text": "is going to start off once the bulk load data from the snowball appliance is available in s3 so that it's going to",
    "start": "2021820",
    "end": "2028720"
  },
  {
    "text": "keep the Aurora post Chris target sequel was a sequel target in complete sync sync with the Oracle source once that is",
    "start": "2028720",
    "end": "2036460"
  },
  {
    "text": "done we turn off the snowball we send it to AWS and we ingest the data into Amazon s3 we check the status of the",
    "start": "2036460",
    "end": "2043960"
  },
  {
    "text": "remote task 1 the bulk load data is available in s3 and then validate and test points the Autorama post quest",
    "start": "2043960",
    "end": "2049868"
  },
  {
    "text": "sequel target is in complete sync with the source so as you know migrating a multi terabyte database could take a lot",
    "start": "2049869",
    "end": "2056829"
  },
  {
    "text": "of time and it could take actually days as well so what we've done as part of",
    "start": "2056829",
    "end": "2063220"
  },
  {
    "text": "this demo is we shot a video showing through showing you through all the important steps that we took in order to migrate that multi",
    "start": "2063220",
    "end": "2069700"
  },
  {
    "text": "database database I was talking about so I'm gonna run you through a part of the video and then I'm gonna invite my",
    "start": "2069700",
    "end": "2075158"
  },
  {
    "text": "colleague Romney R to go ahead with completing the demo so let's see what",
    "start": "2075159",
    "end": "2080290"
  },
  {
    "text": "what goes on here so the like like we saw in the demo steps there the first",
    "start": "2080290",
    "end": "2086080"
  },
  {
    "text": "step is to order a snowball appliance we",
    "start": "2086080",
    "end": "2092679"
  },
  {
    "text": "are currently on the ADA based console go to the snowball console create a new",
    "start": "2092679",
    "end": "2097960"
  },
  {
    "text": "job to import data into Amazon s3 you",
    "start": "2097960",
    "end": "2106150"
  },
  {
    "text": "given all the relevant information so that the snowball is shipped to the right place",
    "start": "2106150",
    "end": "2111269"
  },
  {
    "text": "once that is done you give the job a name and you choose a snowball edge appliance which is compatible with the",
    "start": "2120580",
    "end": "2126890"
  },
  {
    "text": "local replication agent you choose an existing bucket or create a new bucket",
    "start": "2126890",
    "end": "2132260"
  },
  {
    "text": "for the injection job once the snowball bulked it is available in AWS and you",
    "start": "2132260",
    "end": "2138170"
  },
  {
    "text": "also create or select an I am role which gives appropriate privileges to bulk",
    "start": "2138170",
    "end": "2143630"
  },
  {
    "text": "load the data and in the s3 bucket",
    "start": "2143630",
    "end": "2147609"
  },
  {
    "text": "once that is done you quickly set if you",
    "start": "2153220",
    "end": "2159430"
  },
  {
    "text": "want to send notifications at appropriate statuses we've seen various snowball is that you could do that as well and the next one is that a view",
    "start": "2159430",
    "end": "2166990"
  },
  {
    "text": "screen you review through all your selected options make sure you've you've selected them right put in the right",
    "start": "2166990",
    "end": "2172480"
  },
  {
    "text": "shipping address and request for the snowball",
    "start": "2172480",
    "end": "2178349"
  },
  {
    "text": "once that is done a job is created you could view the job details to get a",
    "start": "2184680",
    "end": "2192540"
  },
  {
    "text": "quick summary and the way you interact",
    "start": "2192540",
    "end": "2197730"
  },
  {
    "text": "with the snowball is you use a snowball client which is a command-line tool you could start downloading that in parallel",
    "start": "2197730",
    "end": "2203730"
  },
  {
    "text": "as well we'll see in a bit a bit as to why this noble client is required",
    "start": "2203730",
    "end": "2212030"
  },
  {
    "text": "all the commands we are going to perform are documented and the next step is to just wait for the snowball to be shipped",
    "start": "2220539",
    "end": "2227259"
  },
  {
    "text": "from UPS you get the shipment and then",
    "start": "2227259",
    "end": "2234609"
  },
  {
    "text": "you set off to set up the snowball in your source data center where the Oracle database is present so for the purposes",
    "start": "2234609",
    "end": "2242140"
  },
  {
    "text": "of the demo we are using our partners on-premises data center we bring it in",
    "start": "2242140",
    "end": "2248109"
  },
  {
    "text": "to the data center",
    "start": "2248109",
    "end": "2250798"
  },
  {
    "text": "we plug it to power and then connected to a network within the data center to start setting it up",
    "start": "2258600",
    "end": "2266180"
  },
  {
    "text": "and once that is done you power it on",
    "start": "2280010",
    "end": "2285609"
  },
  {
    "text": "and given this is an snowball edge it's going to assign an IP address to itself as well so that's pretty much what you",
    "start": "2287060",
    "end": "2294020"
  },
  {
    "text": "need to do to set it up for use now that",
    "start": "2294020",
    "end": "2300920"
  },
  {
    "start": "2300000",
    "end": "2368000"
  },
  {
    "text": "the snowball appliance is available in the data center the next step is to install the snowball client and we need",
    "start": "2300920",
    "end": "2307610"
  },
  {
    "text": "to do a couple of steps to unlock it and make it ready for use before we go ahead and use it at the local replication",
    "start": "2307610",
    "end": "2313790"
  },
  {
    "text": "agent for the migration so let's let's look at how we install the snowball client on the machine you go to the ATM",
    "start": "2313790",
    "end": "2321020"
  },
  {
    "text": "list console again you check the status of your snowball so it says it's",
    "start": "2321020",
    "end": "2327680"
  },
  {
    "text": "delivered to you which means you have the snowball up and running set it up in your data center you download a couple",
    "start": "2327680",
    "end": "2334970"
  },
  {
    "text": "of things you copy the client unlock code and download a manifest file which helps you authenticate into the snowball",
    "start": "2334970",
    "end": "2340520"
  },
  {
    "text": "appliance and not unlock it",
    "start": "2340520",
    "end": "2344110"
  },
  {
    "text": "at this step we are just going to make sure the snowball our client has downloaded",
    "start": "2348569",
    "end": "2355699"
  },
  {
    "text": "and once that is downloaded you install the snowball client on an on-premises",
    "start": "2361890",
    "end": "2367200"
  },
  {
    "text": "machine go into the terminal and that's the command you use to unlock the",
    "start": "2367200",
    "end": "2372690"
  },
  {
    "start": "2368000",
    "end": "2436000"
  },
  {
    "text": "snowball appliance you check the status to make sure the unlock status is set to",
    "start": "2372690",
    "end": "2378269"
  },
  {
    "text": "success and then retrieve the credentials for the snowball appliance to use it in a",
    "start": "2378269",
    "end": "2383759"
  },
  {
    "text": "local replication task at a later stage the next step is to install the local DMS agent and configure it this is a",
    "start": "2383759",
    "end": "2389910"
  },
  {
    "text": "very simple process you download it you install it like any other rpm and",
    "start": "2389910",
    "end": "2395809"
  },
  {
    "text": "configure it using a pre-configured script you setup the password and the",
    "start": "2395809",
    "end": "2403079"
  },
  {
    "text": "port number and that's about it and then you check to make sure the process is up and running at this point I'd like to",
    "start": "2403079",
    "end": "2411509"
  },
  {
    "text": "invite my colleague to continue with the demo and take it from there thanks I'm Romney akashic I'm also a",
    "start": "2411509",
    "end": "2423930"
  },
  {
    "text": "database engineer on the database migration service team let's continue with the demo and now we look at how to",
    "start": "2423930",
    "end": "2431130"
  },
  {
    "text": "create tasks using schema conversion tool",
    "start": "2431130",
    "end": "2435380"
  },
  {
    "start": "2436000",
    "end": "2512000"
  },
  {
    "text": "we are now in the schema conversion tool and the first step is to set up an AWS profile use your secret key and access",
    "start": "2441530",
    "end": "2448670"
  },
  {
    "text": "key that has access to all your resources we then test the connection to the s3 bucket that we'll be using and",
    "start": "2448670",
    "end": "2454850"
  },
  {
    "text": "storing the files in now that the test is successful we go ahead and create a",
    "start": "2454850",
    "end": "2461150"
  },
  {
    "text": "new project to migrate from Oracle to Amazon Aurora Posterous we are now",
    "start": "2461150",
    "end": "2468260"
  },
  {
    "text": "testing testing the connections to the source and target database once the",
    "start": "2468260",
    "end": "2477020"
  },
  {
    "text": "connections are successful the next step is to select and convert the schema in",
    "start": "2477020",
    "end": "2485090"
  },
  {
    "text": "this demo where we are converting the data for extractors schema",
    "start": "2485090",
    "end": "2491530"
  },
  {
    "text": "once the schema is converted we go ahead and apply it to the target database",
    "start": "2495510",
    "end": "2501319"
  },
  {
    "text": "at this point we have all the tables in the source present in the target database and we are ready to start the",
    "start": "2503200",
    "end": "2509020"
  },
  {
    "text": "migration but before we start the",
    "start": "2509020",
    "end": "2514839"
  },
  {
    "start": "2512000",
    "end": "2650000"
  },
  {
    "text": "migration let's just look at the number of rows that we are migrating and the tables that we are migrating from Oracle",
    "start": "2514839",
    "end": "2520869"
  },
  {
    "text": "to Aurora Postgres",
    "start": "2520869",
    "end": "2524010"
  },
  {
    "text": "we have a bunch of tables but for the purpose of this demo we are migrating line order underscore zero which has 75",
    "start": "2527809",
    "end": "2535289"
  },
  {
    "text": "million rows now we are back in the AWS schema conversion tool Aaron spoke about",
    "start": "2535289",
    "end": "2544920"
  },
  {
    "text": "the agent that he configured in the previous step we are now going to register that in the schema conversion",
    "start": "2544920",
    "end": "2550470"
  },
  {
    "text": "tool once the agent is registered we wait for it to become active and now we",
    "start": "2550470",
    "end": "2557400"
  },
  {
    "text": "can go ahead and create the tasks when you click on create local and TMS task",
    "start": "2557400",
    "end": "2564390"
  },
  {
    "text": "sed creates two tasks for us here we",
    "start": "2564390",
    "end": "2570839"
  },
  {
    "text": "give the snoball credentials that we got from the snoball client in the previous step again",
    "start": "2570839",
    "end": "2577640"
  },
  {
    "text": "now you can see on the screen that there are two tasks there's one main task and",
    "start": "2586850",
    "end": "2591950"
  },
  {
    "text": "there are two subtasks the first task is the local local task and the second one",
    "start": "2591950",
    "end": "2597260"
  },
  {
    "text": "is the remote DMUs task in this step we are testing the connections to all our",
    "start": "2597260",
    "end": "2602600"
  },
  {
    "text": "resources once the task validation is passed we can go ahead and begin the",
    "start": "2602600",
    "end": "2608990"
  },
  {
    "text": "tasks so the local task copies the data from",
    "start": "2608990",
    "end": "2615540"
  },
  {
    "text": "your source database to your snowball and also copies all the changes from your source database to s3 and once the",
    "start": "2615540",
    "end": "2624160"
  },
  {
    "text": "files are there in s3 after the snowball goes back to AWS that's when the remote task starts copying the data from s3 to",
    "start": "2624160",
    "end": "2630970"
  },
  {
    "text": "your target",
    "start": "2630970",
    "end": "2633510"
  },
  {
    "text": "as you can see on the screen the local task has now started and it is copying data from your source database from our",
    "start": "2637450",
    "end": "2644079"
  },
  {
    "text": "source database to snowball once the",
    "start": "2644079",
    "end": "2651849"
  },
  {
    "start": "2650000",
    "end": "2708000"
  },
  {
    "text": "files are in snowball it's ready to be shipped back to AWS",
    "start": "2651849",
    "end": "2656730"
  },
  {
    "text": "to get the snowball ready to ship it back to AWS we power of the snowball as",
    "start": "2660910",
    "end": "2668410"
  },
  {
    "text": "soon as the snowball a stone turned off the Kindle will light up with the UPS shipping label and the next step is to",
    "start": "2668410",
    "end": "2676570"
  },
  {
    "text": "just drop it off at your at a nearest UPS store",
    "start": "2676570",
    "end": "2681840"
  },
  {
    "text": "in the steppe we are just shipping there's no wall back to UPS",
    "start": "2696810",
    "end": "2703020"
  },
  {
    "text": "and one wanted me to make the joke about the snowball being heavier but you already made that one so I have nothing",
    "start": "2704850",
    "end": "2710940"
  },
  {
    "start": "2708000",
    "end": "2811000"
  },
  {
    "text": "here so now the snowball is in transit",
    "start": "2710940",
    "end": "2717510"
  },
  {
    "text": "and they're going to make some changes on the Oracle database the table line",
    "start": "2717510",
    "end": "2722580"
  },
  {
    "text": "order underscore zero and we later see that it will make its way to the target database",
    "start": "2722580",
    "end": "2729560"
  },
  {
    "text": "so we inserted thousand rows to the line order underscore one database table",
    "start": "2730950",
    "end": "2736890"
  },
  {
    "text": "sorry",
    "start": "2736890",
    "end": "2739190"
  },
  {
    "text": "here we are going to check the status of the snowball whether it has arrived at",
    "start": "2742330",
    "end": "2747400"
  },
  {
    "text": "AWS or not you're back in the AWS console and we navigated to the snowball",
    "start": "2747400",
    "end": "2752920"
  },
  {
    "text": "tab looking at my job I can see that it's still in transit to aid abuse when",
    "start": "2752920",
    "end": "2761200"
  },
  {
    "text": "we click on it there's a button for track now that will tell us when the snowball will be delivered to AWS",
    "start": "2761200",
    "end": "2769530"
  },
  {
    "text": "so it says that it'll be delivered the next day after I checked",
    "start": "2777839",
    "end": "2783680"
  },
  {
    "text": "so fast forwarding to the next day again going back to the snowball tab see that",
    "start": "2786610",
    "end": "2792400"
  },
  {
    "text": "the snowball is now at AWS once the",
    "start": "2792400",
    "end": "2797420"
  },
  {
    "text": "snowball arrives at AWS the data import will begin soon and it's typically the next business day",
    "start": "2797420",
    "end": "2803890"
  },
  {
    "start": "2811000",
    "end": "2842000"
  },
  {
    "text": "once the files are uploaded from snowball to s3 we can verify that they",
    "start": "2812010",
    "end": "2817420"
  },
  {
    "text": "are present in our s3 bucket by running commands from our AWS CLI",
    "start": "2817420",
    "end": "2823980"
  },
  {
    "text": "yeah in the screen all these files contain the data from the bulk load that",
    "start": "2827490",
    "end": "2834700"
  },
  {
    "text": "we did from Oracle database to snowball",
    "start": "2834700",
    "end": "2839250"
  },
  {
    "text": "next we'll check for the files that were generated based on the thousand rows that we inserted in our Oracle source",
    "start": "2843170",
    "end": "2850230"
  },
  {
    "text": "table",
    "start": "2850230",
    "end": "2852588"
  },
  {
    "start": "2859000",
    "end": "2919000"
  },
  {
    "text": "now that all the files are in s3 the DMS remote tasks picks up all the files and",
    "start": "2860489",
    "end": "2866229"
  },
  {
    "text": "then starts inserting them to the target database",
    "start": "2866229",
    "end": "2870390"
  },
  {
    "text": "we are back in the schema conversion tool now and you can see that both the",
    "start": "2874190",
    "end": "2879829"
  },
  {
    "text": "remote and the local tasks have completed successfully so the main task shows hundred-person that means our",
    "start": "2879829",
    "end": "2886099"
  },
  {
    "text": "migration is done we can now go ahead and validate the number of rows on the",
    "start": "2886099",
    "end": "2891410"
  },
  {
    "text": "target database and verify that it matches our source database so this is",
    "start": "2891410",
    "end": "2902479"
  },
  {
    "text": "the this is the target Aurora Postgres database and we can see that the count of the line order",
    "start": "2902479",
    "end": "2908599"
  },
  {
    "text": "underscore zero matches the count of the source Oracle database",
    "start": "2908599",
    "end": "2914410"
  },
  {
    "text": "that's it for the demo this is how DMS was integrated with snowball and hand it",
    "start": "2919810",
    "end": "2924970"
  },
  {
    "text": "off to around now thank you guys worked",
    "start": "2924970",
    "end": "2931570"
  },
  {
    "text": "very hard for this demo the alternative was to keep you here for five days and",
    "start": "2931570",
    "end": "2937270"
  },
  {
    "text": "watch the entire process but yeah by the way did you notice the guy that was",
    "start": "2937270",
    "end": "2943450"
  },
  {
    "text": "packing the snowball and then they grew hair when he shipped it to UPS you",
    "start": "2943450",
    "end": "2949090"
  },
  {
    "text": "notice that I'm gonna try it I'm gonna try all right yeah well I apparently I",
    "start": "2949090",
    "end": "2956290"
  },
  {
    "text": "spoke to for too long so we will take questions at the end so I'll David I'll",
    "start": "2956290",
    "end": "2962800"
  },
  {
    "text": "invite David here to cover the Oracle to Aurora cookbook and then we'll take",
    "start": "2962800",
    "end": "2970720"
  },
  {
    "text": "questions at the end with their microphones you two today yeah microphones here no I was a clicker",
    "start": "2970720",
    "end": "2988240"
  },
  {
    "text": "I think sorry so hey everyone I'm David I'm the CTO of",
    "start": "2988240",
    "end": "2993280"
  },
  {
    "text": "neurotic we are a data based consulting company based in Silicon Valley and we specialize in database migrations",
    "start": "2993280",
    "end": "2999690"
  },
  {
    "text": "specifically hitter genus database migrations moving from commercial to open-source platforms moving from Oracle",
    "start": "2999690",
    "end": "3006600"
  },
  {
    "text": "sequel Server db2 to Aurora RDS with my sequel or podcast compatibility in",
    "start": "3006600",
    "end": "3013350"
  },
  {
    "text": "Amazon so for the past few months my team and I have been working together with Amazon",
    "start": "3013350",
    "end": "3019920"
  },
  {
    "text": "to create a really really cool project it's the Oracle to Amazon Aurora",
    "start": "3019920",
    "end": "3027950"
  },
  {
    "text": "migration cookbook or playbook it's essentially a guide that can help",
    "start": "3027950",
    "end": "3033810"
  },
  {
    "text": "customers and organizations who are looking into performing heterogeneous",
    "start": "3033810",
    "end": "3039630"
  },
  {
    "text": "migrations where you switch database engines for example Oracle to Amazon Aurora Postgres and help them with the",
    "start": "3039630",
    "end": "3046650"
  },
  {
    "text": "process now mentioned in this presentation that",
    "start": "3046650",
    "end": "3051680"
  },
  {
    "start": "3047000",
    "end": "3143000"
  },
  {
    "text": "amazon you saw a demo has a really amazing tool an awesome tool called SCT schema conversion tool it's a great tool",
    "start": "3051680",
    "end": "3058040"
  },
  {
    "text": "that can help you migrate to schema it does do to automate the task of migrating schema objects procedures",
    "start": "3058040",
    "end": "3064190"
  },
  {
    "text": "functions tables indexes whatever you can migrate automatically from your source database engine to your target",
    "start": "3064190",
    "end": "3071210"
  },
  {
    "text": "database engine however migration projects et Regina's database migration",
    "start": "3071210",
    "end": "3077450"
  },
  {
    "text": "projects always require some extensive human of manual human intervention",
    "start": "3077450",
    "end": "3083120"
  },
  {
    "text": "that's because when you migrate when you think about migrating an Oracle database for example to Amazon or Ora Postgres",
    "start": "3083120",
    "end": "3090230"
  },
  {
    "text": "you probably are using a lot of special Oracle features when Oracle you know is a great database it has a lot of",
    "start": "3090230",
    "end": "3096290"
  },
  {
    "text": "features and and functionality built into the database itself so when you're",
    "start": "3096290",
    "end": "3101810"
  },
  {
    "text": "using all of those you know very sophisticated very advanced Oracle features differ allocations for example",
    "start": "3101810",
    "end": "3107720"
  },
  {
    "text": "you might be using Oracle advanced queuing you might be using gold engage map using encryption you might using a",
    "start": "3107720",
    "end": "3113120"
  },
  {
    "text": "data guard rack XML DB JSON storage result cache partitioning all of those",
    "start": "3113120",
    "end": "3118280"
  },
  {
    "text": "great features now some of them many of them can be converted automatically",
    "start": "3118280",
    "end": "3123770"
  },
  {
    "text": "using a CT so that's the place you should start with do the schema assessment and do the automatic conversion but some of them requires the",
    "start": "3123770",
    "end": "3132050"
  },
  {
    "text": "manual touch of a DBA and as ill as a DBA myself as an Oracle DBA myself I'm proud to say that I'm not out of the job",
    "start": "3132050",
    "end": "3138110"
  },
  {
    "text": "just yet so what we try to do in this in this document which is basically 350",
    "start": "3138110",
    "end": "3145790"
  },
  {
    "text": "page documents so might as well call it a book is to provide you with the guide",
    "start": "3145790",
    "end": "3151730"
  },
  {
    "text": "that shows you how you can combine the core functionality that Postgres",
    "start": "3151730",
    "end": "3157010"
  },
  {
    "text": "provides in terms of the building support for Postgres functions that can provide equivalents to certain Oracle",
    "start": "3157010",
    "end": "3163760"
  },
  {
    "text": "features but also wherever possible to leverage the AWS centric features the",
    "start": "3163760",
    "end": "3170630"
  },
  {
    "text": "AWS ecosystem to extend native capabilities that exist in hospice or",
    "start": "3170630",
    "end": "3177290"
  },
  {
    "text": "more specifically in Aurora Postgres so this document which you can by the way it was launched this week at Winn",
    "start": "3177290",
    "end": "3183680"
  },
  {
    "text": "and you can download it you can go to the DMS page at in AWS go to the getting",
    "start": "3183680",
    "end": "3189980"
  },
  {
    "text": "started section and from there you can find a link a link for to their document so what this document what is play will",
    "start": "3189980",
    "end": "3196849"
  },
  {
    "text": "cookbook what this migration guide will help you with is basically with feature",
    "start": "3196849",
    "end": "3202160"
  },
  {
    "start": "3201000",
    "end": "3490000"
  },
  {
    "text": "by feature comparison between Oracle features and their equivalent post",
    "start": "3202160",
    "end": "3208069"
  },
  {
    "text": "quests and Aurora features so for example let's talk about table",
    "start": "3208069",
    "end": "3213500"
  },
  {
    "text": "partitioning table partitioning in Oracle is completely different than what is currently available in Postgres 9.6",
    "start": "3213500",
    "end": "3220700"
  },
  {
    "text": "and in post post and added which was just recently made available in opal II",
    "start": "3220700",
    "end": "3225800"
  },
  {
    "text": "soon will be available as part of Aurora as well add a declarative partitioning",
    "start": "3225800",
    "end": "3230809"
  },
  {
    "text": "scene tech support but process 9.6 handles partitioning completely different than Oracle so automatic",
    "start": "3230809",
    "end": "3237589"
  },
  {
    "text": "conversions of all your partition tables will not always be possible you might need to restructure some of those things",
    "start": "3237589",
    "end": "3243859"
  },
  {
    "text": "so this database migration playbook covers for example partitioning shows you the oracle syntax for various",
    "start": "3243859",
    "end": "3250640"
  },
  {
    "text": "partitioning mechanism methods interval partitioning range partitioning hash partitioning and what is the best",
    "start": "3250640",
    "end": "3256609"
  },
  {
    "text": "comparable TM equivalent you can achieve in Postgres but it also goes beyond that it",
    "start": "3256609",
    "end": "3262910"
  },
  {
    "text": "discusses features such as Oracle RAC oracle data guard oracle json storage maybe you're storing jason's new",
    "start": "3262910",
    "end": "3268730"
  },
  {
    "text": "document and processing them oracle advanced queueing features that are built into oracle where you might need",
    "start": "3268730",
    "end": "3274309"
  },
  {
    "text": "to leverage certain amazon ecosystem components in order to achieve feature parity for example in about 30 minutes",
    "start": "3274309",
    "end": "3282530"
  },
  {
    "text": "i'm supposed to be a definition so which i'm hoping to have another presentation",
    "start": "3282530",
    "end": "3287750"
  },
  {
    "text": "so I'm not sure if Amazon is working on a teleportation service because if you are I want access to the preview please",
    "start": "3287750",
    "end": "3293359"
  },
  {
    "text": "because 30 minutes to definition is going to be challenging I can skip leg day at the gym tomorrow I guess so for",
    "start": "3293359",
    "end": "3300319"
  },
  {
    "text": "example in 30 minutes I'm doing a lecture where I'm showing how you can do migrations from Oracle 2 or a post quest",
    "start": "3300319",
    "end": "3305510"
  },
  {
    "text": "and one of the features I'm demoing is that say you have an Oracle database using Oracle advanced queuing basically",
    "start": "3305510",
    "end": "3312109"
  },
  {
    "text": "it's a it's a feature in Oracle a great feature which allows you to use your database as a service bus you can in queue in the queue mess",
    "start": "3312109",
    "end": "3317550"
  },
  {
    "text": "just a synchronously it's really fantastic Pospisil doesn't have something that's that's comparable",
    "start": "3317550",
    "end": "3322560"
  },
  {
    "text": "natively however so from that perspective you might say so well we can't migrate because or Postgres",
    "start": "3322560",
    "end": "3329220"
  },
  {
    "text": "doesn't provide a queuing service built into the database so if you were migrating to Postgres on Prem for",
    "start": "3329220",
    "end": "3334470"
  },
  {
    "text": "example you might be in a difficult in a difficult spot you might be in a gem but if you're migrating to Aurora",
    "start": "3334470",
    "end": "3339900"
  },
  {
    "text": "Postgres well then Amazon you can use the Amazon ecosystem amazon has sqs",
    "start": "3339900",
    "end": "3344910"
  },
  {
    "text": "simple to services so using lambda functions you can actually create a lambda function that will link encode in",
    "start": "3344910",
    "end": "3352230"
  },
  {
    "text": "Q and E QD messages from the sqs and then from or or invoke the lambda function so this is one of the so this",
    "start": "3352230",
    "end": "3358830"
  },
  {
    "text": "is one of them instructions I'm doing in my next presentation and some of the in these these types of topics are what we",
    "start": "3358830",
    "end": "3365190"
  },
  {
    "text": "are covering in the player book itself so again it's a great document it's meant to be by the way a living document this is just the first release we've",
    "start": "3365190",
    "end": "3372090"
  },
  {
    "text": "been walking for a few months 350 pages and we're just getting started but this is just the first release we're gonna",
    "start": "3372090",
    "end": "3377550"
  },
  {
    "text": "continue and expand it as more features are made available in both Postgres and",
    "start": "3377550",
    "end": "3382740"
  },
  {
    "text": "Aurora and in Amazon we try to take some of our we do a lot of database migrations history genus database",
    "start": "3382740",
    "end": "3389310"
  },
  {
    "text": "migration so we try to kind of leverage our best practices and our expertise and put it into the into the playbook as",
    "start": "3389310",
    "end": "3396060"
  },
  {
    "text": "well so as we learn new things from our customers as we kind of try and see how we can reach certain feature parities",
    "start": "3396060",
    "end": "3402480"
  },
  {
    "text": "between Oracle and or our prospects we'll add this to the document so it's very worthwhile to when once you",
    "start": "3402480",
    "end": "3407700"
  },
  {
    "text": "download it and again and and read it and go through it keep an eye for updated versions there",
    "start": "3407700",
    "end": "3413670"
  },
  {
    "text": "should be released you know at a relatively rapid pace so this is the migration playbook it's basically meant",
    "start": "3413670",
    "end": "3420480"
  },
  {
    "text": "to show you how you can oh I see that some of the slide didn't survive the keynote to PowerPoint presentation that smoothly but you know what we can do so",
    "start": "3420480",
    "end": "3427980"
  },
  {
    "text": "anyway the migration playbook isn't meant to replace DMS versus NS City of course of course not",
    "start": "3427980",
    "end": "3433200"
  },
  {
    "text": "SC T will converge the scheme automatically whatever can be done automatically DMS will copy your data the playbook you can use for the manual",
    "start": "3433200",
    "end": "3440310"
  },
  {
    "text": "touch-up manual interventions that will be required but also if your database",
    "start": "3440310",
    "end": "3447870"
  },
  {
    "text": "administrators want to learn Postgres they they're you know they're amazing",
    "start": "3447870",
    "end": "3454140"
  },
  {
    "text": "Oracle expert and they want to learn Postgres so they can use the migration playbook as a guide to see how certain",
    "start": "3454140",
    "end": "3461250"
  },
  {
    "text": "things and functionality that are used to do in Oracle what is the equivalent",
    "start": "3461250",
    "end": "3466740"
  },
  {
    "text": "in process including by the way some operational things such as what's the equivalent to the Oracle alert log where",
    "start": "3466740",
    "end": "3472050"
  },
  {
    "text": "can you see you're running Aurora how can you find them you know errors in the database or or warning messages how to",
    "start": "3472050",
    "end": "3478080"
  },
  {
    "text": "accomplish that how you can set up alerting and stuff like that so this is the migration playbook I really hope that you'll find it useful it's been a",
    "start": "3478080",
    "end": "3485010"
  },
  {
    "text": "labor of love for us for the past three months and we'll keep going to update it as new features are made available ok",
    "start": "3485010",
    "end": "3491370"
  },
  {
    "start": "3490000",
    "end": "3589000"
  },
  {
    "text": "thank you very much awesome teleportation device lovely and we have",
    "start": "3491370",
    "end": "3500010"
  },
  {
    "text": "like minute I think so yes better",
    "start": "3500010",
    "end": "3506220"
  },
  {
    "text": "playbook no no you have to go to AWS slash DMS",
    "start": "3506220",
    "end": "3513290"
  },
  {
    "text": "press the getting started it's hidden we hit it really good we did an awesome job",
    "start": "3513290",
    "end": "3519720"
  },
  {
    "text": "hiding it and only those that can find it can use it you know it's a measure of",
    "start": "3519720",
    "end": "3525120"
  },
  {
    "text": "I know I'm joking it will improve a location you just wanted to get it out as for reinvent and going through the",
    "start": "3525120",
    "end": "3532620"
  },
  {
    "text": "marketing machine is a little bit more yes please",
    "start": "3532620",
    "end": "3538550"
  },
  {
    "text": "Laak meaning changes to the schemas yeah we do not it's all documented but there",
    "start": "3542410",
    "end": "3550570"
  },
  {
    "text": "are limitations on which schema object we can replicate okay not all of them",
    "start": "3550570",
    "end": "3560560"
  },
  {
    "text": "are replicated but you don't again sorry",
    "start": "3560560",
    "end": "3565900"
  },
  {
    "text": "you don't know you'll need to lock it there are again some changes that will",
    "start": "3565900",
    "end": "3570940"
  },
  {
    "text": "not replicate anyway but they are all documented you know it's based on the",
    "start": "3570940",
    "end": "3576430"
  },
  {
    "text": "source database and I see here signs that I have to be out so I'll we're out",
    "start": "3576430",
    "end": "3583630"
  },
  {
    "text": "will be out outside taking additional questions okay thank you guys",
    "start": "3583630",
    "end": "3590190"
  }
]
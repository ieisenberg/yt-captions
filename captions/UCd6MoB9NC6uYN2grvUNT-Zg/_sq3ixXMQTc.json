[
  {
    "text": "- Welcome to \"Back To Basics\".",
    "start": "6600",
    "end": "8460"
  },
  {
    "text": "In this episode, we\nwill discuss the basics",
    "start": "8460",
    "end": "11040"
  },
  {
    "text": "of Retrieval-Augmented Generation,\nor RAG, in generative AI.",
    "start": "11040",
    "end": "14913"
  },
  {
    "text": "As interest in large language\nmodels, or LLMs, increases,",
    "start": "15930",
    "end": "19890"
  },
  {
    "text": "developers are exploring ways\nto harness their potential.",
    "start": "19890",
    "end": "23880"
  },
  {
    "text": "However, pre-trained LLMs might\nnot perform optimally right",
    "start": "23880",
    "end": "28140"
  },
  {
    "text": "out of the box for your business needs.",
    "start": "28140",
    "end": "30362"
  },
  {
    "text": "You may need to decide between\nusing model fine-tuning,",
    "start": "31230",
    "end": "34380"
  },
  {
    "text": "a process where a pre-trained\nmodel is further trained",
    "start": "34380",
    "end": "37410"
  },
  {
    "text": "on a new dataset",
    "start": "37410",
    "end": "38700"
  },
  {
    "text": "without starting from scratch",
    "start": "38700",
    "end": "40590"
  },
  {
    "text": "or Retrieval-Augmented Generation",
    "start": "40590",
    "end": "42600"
  },
  {
    "text": "to enhance the performance.",
    "start": "42600",
    "end": "44910"
  },
  {
    "text": "In this episode, we\nwill explore what RAG is",
    "start": "44910",
    "end": "48180"
  },
  {
    "text": "and a pattern to implement RAG",
    "start": "48180",
    "end": "50160"
  },
  {
    "text": "using Amazon Bedrock foundation models",
    "start": "50160",
    "end": "52530"
  },
  {
    "text": "and other AWS Services.",
    "start": "52530",
    "end": "54392"
  },
  {
    "text": "RAG can be particularly useful\nin developing applications,",
    "start": "55410",
    "end": "59310"
  },
  {
    "text": "like Q&A chat bots that securely interact",
    "start": "59310",
    "end": "62280"
  },
  {
    "text": "with your internal knowledge basis",
    "start": "62280",
    "end": "64290"
  },
  {
    "text": "or enterprise data sources.",
    "start": "64290",
    "end": "66840"
  },
  {
    "text": "Such an approach is more suitable",
    "start": "66840",
    "end": "69149"
  },
  {
    "text": "compared to out-of-the-box LLMs,",
    "start": "69150",
    "end": "71400"
  },
  {
    "text": "which may lack your\nenterprise-specific knowledge.",
    "start": "71400",
    "end": "74223"
  },
  {
    "text": "Let's dive into understanding",
    "start": "75300",
    "end": "77130"
  },
  {
    "text": "what Retrieval-Augmented Generation is.",
    "start": "77130",
    "end": "79950"
  },
  {
    "text": "Retrieval-Augmented Generation",
    "start": "79950",
    "end": "82049"
  },
  {
    "text": "helps to retrieve data from\noutside a foundation model",
    "start": "82050",
    "end": "85440"
  },
  {
    "text": "and augment your prompts,",
    "start": "85440",
    "end": "87090"
  },
  {
    "text": "which is a natural language text",
    "start": "87090",
    "end": "89130"
  },
  {
    "text": "that requests the LLM to\nperform a specific task",
    "start": "89130",
    "end": "92520"
  },
  {
    "text": "by adding the relevant\nretrieved data in context.",
    "start": "92520",
    "end": "96420"
  },
  {
    "text": "It is composed of three components:",
    "start": "96420",
    "end": "98729"
  },
  {
    "text": "retrieval, augmentation, and generation.",
    "start": "98730",
    "end": "101910"
  },
  {
    "text": "Upon receiving a user query,",
    "start": "101910",
    "end": "103950"
  },
  {
    "text": "relevant content is retrieved\nfrom external knowledge basis",
    "start": "103950",
    "end": "107250"
  },
  {
    "text": "or other data sources based\non the specifics of the query.",
    "start": "107250",
    "end": "111210"
  },
  {
    "text": "The retrieved contextual information",
    "start": "111210",
    "end": "113340"
  },
  {
    "text": "is then appended to the\noriginal user query,",
    "start": "113340",
    "end": "116189"
  },
  {
    "text": "creating an augmented query",
    "start": "116190",
    "end": "117690"
  },
  {
    "text": "to serve as the input\nto the foundation model.",
    "start": "117690",
    "end": "120450"
  },
  {
    "text": "The foundation model\nthen generates a response",
    "start": "120450",
    "end": "123390"
  },
  {
    "text": "based on the augmented query.",
    "start": "123390",
    "end": "125820"
  },
  {
    "text": "With this high-level flow,",
    "start": "125820",
    "end": "127350"
  },
  {
    "text": "now let's cover a few\ndifferent types of retrieval",
    "start": "127350",
    "end": "130110"
  },
  {
    "text": "and see where RAG fits in.",
    "start": "130110",
    "end": "132060"
  },
  {
    "text": "The three typical types of retrieval",
    "start": "132060",
    "end": "133890"
  },
  {
    "text": "consist of, first, rule-based,",
    "start": "133890",
    "end": "136830"
  },
  {
    "text": "in which the model\nfetches unstructured data,",
    "start": "136830",
    "end": "139560"
  },
  {
    "text": "such as documents and thus\nkeyword-based searches.",
    "start": "139560",
    "end": "143340"
  },
  {
    "text": "Second, transaction-based,",
    "start": "143340",
    "end": "145620"
  },
  {
    "text": "where transactional data is\nretrieved from a database",
    "start": "145620",
    "end": "148860"
  },
  {
    "text": "or an API.",
    "start": "148860",
    "end": "150300"
  },
  {
    "text": "And third, semantic-based,",
    "start": "150300",
    "end": "152640"
  },
  {
    "text": "where the model retrieves\nrelevant documents",
    "start": "152640",
    "end": "155100"
  },
  {
    "text": "based on text embeddings.",
    "start": "155100",
    "end": "157080"
  },
  {
    "text": "This is where the RAG\nmodel is most applicable.",
    "start": "157080",
    "end": "160230"
  },
  {
    "text": "First, let's further define embedding",
    "start": "160230",
    "end": "162989"
  },
  {
    "text": "and its relevance when implementing RAG.",
    "start": "162990",
    "end": "165273"
  },
  {
    "text": "Embedding refers to transforming data,",
    "start": "166200",
    "end": "168660"
  },
  {
    "text": "like text, images, audio,",
    "start": "168660",
    "end": "171000"
  },
  {
    "text": "into numerical representation",
    "start": "171000",
    "end": "172920"
  },
  {
    "text": "in a high-dimensional vector space",
    "start": "172920",
    "end": "175020"
  },
  {
    "text": "using machine learning algorithms.",
    "start": "175020",
    "end": "177123"
  },
  {
    "text": "This allows understanding semantics,",
    "start": "178350",
    "end": "181140"
  },
  {
    "text": "learning complex patterns,",
    "start": "181140",
    "end": "182850"
  },
  {
    "text": "and using the vector representation",
    "start": "182850",
    "end": "184980"
  },
  {
    "text": "for applications like\nsearch, classification,",
    "start": "184980",
    "end": "188250"
  },
  {
    "text": "and natural language processing.",
    "start": "188250",
    "end": "190770"
  },
  {
    "text": "Let's take a deeper look at\nan end-to-end RAG architecture",
    "start": "190770",
    "end": "194040"
  },
  {
    "text": "leveraging AWS Services.",
    "start": "194040",
    "end": "196170"
  },
  {
    "text": "First, you start with the selection",
    "start": "196170",
    "end": "198300"
  },
  {
    "text": "of a large language model.",
    "start": "198300",
    "end": "200160"
  },
  {
    "text": "Some considerations to\nkeep in mind are use cases,",
    "start": "200160",
    "end": "203490"
  },
  {
    "text": "context length, hosting,\ntraining data if applicable,",
    "start": "203490",
    "end": "207540"
  },
  {
    "text": "customization, and license agreements.",
    "start": "207540",
    "end": "210329"
  },
  {
    "text": "For this, you can use Amazon Bedrock,",
    "start": "210330",
    "end": "213210"
  },
  {
    "text": "which is a fully managed service",
    "start": "213210",
    "end": "214890"
  },
  {
    "text": "that offers a choice of\nhigh-performing foundation models",
    "start": "214890",
    "end": "218490"
  },
  {
    "text": "from leading AI companies\nvia a single API.",
    "start": "218490",
    "end": "221670"
  },
  {
    "text": "Along with a broad set of capabilities,",
    "start": "221670",
    "end": "224220"
  },
  {
    "text": "you need to build generative\nAI applications with security,",
    "start": "224220",
    "end": "228090"
  },
  {
    "text": "privacy, and responsible.",
    "start": "228090",
    "end": "230489"
  },
  {
    "text": "Now, with the LLM selection in place,",
    "start": "230490",
    "end": "232890"
  },
  {
    "text": "you will start with\nidentifying your knowledge base",
    "start": "232890",
    "end": "235770"
  },
  {
    "text": "and converting them into\nembeddings for a vector store.",
    "start": "235770",
    "end": "239700"
  },
  {
    "text": "For embedding models,",
    "start": "239700",
    "end": "241140"
  },
  {
    "text": "factors such as max input size, latency,",
    "start": "241140",
    "end": "244740"
  },
  {
    "text": "output embedding size, ease of hosting,",
    "start": "244740",
    "end": "247680"
  },
  {
    "text": "and accuracy are crucial considerations.",
    "start": "247680",
    "end": "250680"
  },
  {
    "text": "When considering embedding models,",
    "start": "250680",
    "end": "252750"
  },
  {
    "text": "your options include\nAmazon Titan Embeddings,",
    "start": "252750",
    "end": "255900"
  },
  {
    "text": "Cohere Embed, and other embedding models.",
    "start": "255900",
    "end": "259079"
  },
  {
    "text": "For your query,",
    "start": "259080",
    "end": "260280"
  },
  {
    "text": "generate the embeddings of the query",
    "start": "260280",
    "end": "262410"
  },
  {
    "text": "using the same embedding model.",
    "start": "262410",
    "end": "264630"
  },
  {
    "text": "Next are the vector databases,",
    "start": "264630",
    "end": "267060"
  },
  {
    "text": "which provide you the ability\nto store and retrieve vectors",
    "start": "267060",
    "end": "270660"
  },
  {
    "text": "as high-dimensional points.",
    "start": "270660",
    "end": "272820"
  },
  {
    "text": "With this, you can index\nvectors generated by embeddings",
    "start": "272820",
    "end": "276300"
  },
  {
    "text": "into a vector database.",
    "start": "276300",
    "end": "278190"
  },
  {
    "text": "When evaluating options,",
    "start": "278190",
    "end": "280140"
  },
  {
    "text": "consider the nature of\ndata sources and formats,",
    "start": "280140",
    "end": "283170"
  },
  {
    "text": "dimensions,",
    "start": "283170",
    "end": "284190"
  },
  {
    "text": "the choice between fully-managed services",
    "start": "284190",
    "end": "286260"
  },
  {
    "text": "and self-managed,",
    "start": "286260",
    "end": "287640"
  },
  {
    "text": "development complexity, and scalability.",
    "start": "287640",
    "end": "290553"
  },
  {
    "text": "Available vector store options",
    "start": "291510",
    "end": "293160"
  },
  {
    "text": "include Vector Engine for\nAmazon OpenSearch, AWS Kendra,",
    "start": "293160",
    "end": "297480"
  },
  {
    "text": "and Aurora pgvector store.",
    "start": "297480",
    "end": "299790"
  },
  {
    "text": "Now, let's talk about orchestration",
    "start": "299790",
    "end": "301950"
  },
  {
    "text": "for all of these components.",
    "start": "301950",
    "end": "304140"
  },
  {
    "text": "Some available options",
    "start": "304140",
    "end": "305730"
  },
  {
    "text": "are Amazon Bedrock\nKnowledge Base and Agents,",
    "start": "305730",
    "end": "308820"
  },
  {
    "text": "LangChain, LlamaIndex, Step Functions,",
    "start": "308820",
    "end": "312090"
  },
  {
    "text": "as well as other open-source solutions.",
    "start": "312090",
    "end": "314553"
  },
  {
    "text": "In this episode, we\ndiscussed the basics of RAG",
    "start": "315390",
    "end": "318810"
  },
  {
    "text": "and reference patterns for implementation.",
    "start": "318810",
    "end": "321720"
  },
  {
    "text": "We covered the basics around embeddings",
    "start": "321720",
    "end": "323970"
  },
  {
    "text": "and why it is important\nwhen implementing RAG",
    "start": "323970",
    "end": "326610"
  },
  {
    "text": "in your applications.",
    "start": "326610",
    "end": "328289"
  },
  {
    "text": "Finally, we saw an end-to-end architecture",
    "start": "328290",
    "end": "331170"
  },
  {
    "text": "using AWS Services,",
    "start": "331170",
    "end": "332790"
  },
  {
    "text": "including Amazon Bedrock.",
    "start": "332790",
    "end": "334950"
  },
  {
    "text": "Check out the links in\nthe description below",
    "start": "334950",
    "end": "337080"
  },
  {
    "text": "for more details.",
    "start": "337080",
    "end": "338490"
  },
  {
    "text": "Thank you for watching \"Back to Basics\".",
    "start": "338490",
    "end": "340289"
  },
  {
    "text": "See you next time.",
    "start": "340290",
    "end": "341790"
  }
]
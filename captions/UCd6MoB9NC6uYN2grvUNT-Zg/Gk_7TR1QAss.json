[
  {
    "text": "hello everyone if you're here in the right place we're talking about Amazon",
    "start": "30",
    "end": "5640"
  },
  {
    "text": "ECR and we're gonna do a deep dive on image optimization now just to get",
    "start": "5640",
    "end": "12210"
  },
  {
    "text": "started what to expect in this session so we're gonna go over sort of how docker images are built so you can",
    "start": "12210",
    "end": "18930"
  },
  {
    "text": "really understand and make better educated decisions on optimizing your own image builds I'm gonna serve a fair",
    "start": "18930",
    "end": "24630"
  },
  {
    "text": "amount of familiarity since as a 400 level talk with docker and ECR and ECS I'm gonna have a lot of like content in",
    "start": "24630",
    "end": "31260"
  },
  {
    "text": "my slides here I'm gonna make sure that I go through so you can see a little bit but these slides are also gonna be",
    "start": "31260",
    "end": "36360"
  },
  {
    "text": "available afterwards so you can sort of step through all the commands and follow through again so really the goal is to",
    "start": "36360",
    "end": "42329"
  },
  {
    "text": "sort of educate you here and see how docker images are built composed so and how the registry API works we're also",
    "start": "42329",
    "end": "49530"
  },
  {
    "text": "gonna talk a little bit about CI CD best practices and then mouths gonna come up here to talk a little bit about EDC our",
    "start": "49530",
    "end": "55530"
  },
  {
    "text": "learnings and best practices that they have at Pinterest so a little bit about",
    "start": "55530",
    "end": "60690"
  },
  {
    "text": "me I work for AWS in the ec2 container registry I've been at Amazon for over 10",
    "start": "60690",
    "end": "66270"
  },
  {
    "text": "years and I've worked on a lot of different teams I worked on the retail marketplace team Amazon local Amazon",
    "start": "66270",
    "end": "72420"
  },
  {
    "text": "restaurants and then I've been with ec2 for about two years now I really like sort of understanding how things work",
    "start": "72420",
    "end": "78780"
  },
  {
    "text": "taking apart putting them back together and so I'm also really passionate about containers and sort of what they allow",
    "start": "78780",
    "end": "84659"
  },
  {
    "text": "for developers and and what what they allow you to do and I've worked on the container registry since that launch so",
    "start": "84659",
    "end": "90990"
  },
  {
    "text": "I have a pretty good understanding and a low-level understanding of how it actually all fits together now if you're",
    "start": "90990",
    "end": "98220"
  },
  {
    "text": "not familiar Amazon ec2 container mat registry is a fully managed highly available and secure docker compatible",
    "start": "98220",
    "end": "104909"
  },
  {
    "text": "container registry it allows you to sort of drop in with your existing docker commands you're doing docker pushes and",
    "start": "104909",
    "end": "110520"
  },
  {
    "text": "pulls it all implements the API so you don't have to worry about it but it's also available we're in nine different",
    "start": "110520",
    "end": "116790"
  },
  {
    "text": "regions today and also integrates with things like I am and resource policies so that we can secure and really lock",
    "start": "116790",
    "end": "123119"
  },
  {
    "text": "things down we also provide cloud trail integration and number the others so really is a docker docker registry",
    "start": "123119",
    "end": "129690"
  },
  {
    "text": "that's designed to work best with AWS now a lot of the tips that I'm gonna",
    "start": "129690",
    "end": "134950"
  },
  {
    "text": "give today while they're true for most most registries and most container images these are will also so our hold",
    "start": "134950",
    "end": "141700"
  },
  {
    "text": "true for ECR so we'll talk a little bit about how docker images are constructed",
    "start": "141700",
    "end": "148510"
  },
  {
    "text": "and how they work so first up docker images themselves are packaged application code binaries and",
    "start": "148510",
    "end": "156760"
  },
  {
    "text": "they really basically provide you a portable way of having your build software go to production so one of the",
    "start": "156760",
    "end": "162160"
  },
  {
    "text": "common problems that a lot of customers have had before and software developers have had for a long time is making sure that that reproducible build you had on",
    "start": "162160",
    "end": "168700"
  },
  {
    "text": "your desktop works in production even down to sort of complex build systems that have had before in the past even",
    "start": "168700",
    "end": "175150"
  },
  {
    "text": "things like you know LD library path and shared dependencies can cause a lot of problems and even down in sort of a lot",
    "start": "175150",
    "end": "182080"
  },
  {
    "text": "of modern teams we end up having you know multiple languages implemented on the same host multiple like dependent",
    "start": "182080",
    "end": "188500"
  },
  {
    "text": "libraries different SSL versions even down to G Lib C now docker allows you to build portable images that can actually",
    "start": "188500",
    "end": "194890"
  },
  {
    "text": "go from from a hosts Base hosted base host without having to worry about those",
    "start": "194890",
    "end": "199989"
  },
  {
    "text": "you know exactly what happened in development and what you had is exactly what you have in production so docker",
    "start": "199989",
    "end": "207820"
  },
  {
    "text": "images themselves are actually comprised of layers layers are immutable they're",
    "start": "207820",
    "end": "213850"
  },
  {
    "text": "read-only they actually hold both file data and configuration data for each each part that makes up an image in this",
    "start": "213850",
    "end": "221079"
  },
  {
    "text": "case this is a hello reinvent example it's tagged latest and you can see that it has three layers now each layer",
    "start": "221079",
    "end": "227769"
  },
  {
    "text": "because of Dockers Union filesystem will override the contents of the previous at runtime so if you have a file in the top",
    "start": "227769",
    "end": "234070"
  },
  {
    "text": "and the top layer the next layer below it if it has the same file it'll override that file and use it instead this is sort of what allows you to sort",
    "start": "234070",
    "end": "240970"
  },
  {
    "text": "of build and compose those to create that image now a running container is a",
    "start": "240970",
    "end": "247180"
  },
  {
    "text": "docker image that's being executed that has a container layer that's read/write this actually holds the container data",
    "start": "247180",
    "end": "252640"
  },
  {
    "text": "at runtime and then when it exits you can either save that the intermediate layer or have it cleaned up now and this",
    "start": "252640",
    "end": "259000"
  },
  {
    "text": "is actually how docker images themselves are built inside docker though so you run a blank image you go ahead and you",
    "start": "259000",
    "end": "265900"
  },
  {
    "text": "execute some code it saves that readwrite file system with a content-addressable hash and then it",
    "start": "265900",
    "end": "271990"
  },
  {
    "text": "adds it to the layer so we can see later as we go through some build examples when you're actually building you're",
    "start": "271990",
    "end": "277600"
  },
  {
    "text": "just using containers but using this directly would be kind of cumbersome so",
    "start": "277600",
    "end": "283479"
  },
  {
    "text": "the docker file syntax is what really allows you to sort of express your image in a nice clean format you can see that",
    "start": "283479",
    "end": "291610"
  },
  {
    "text": "more or less a lot of the lines in a docker file can usually correspond to a",
    "start": "291610",
    "end": "296919"
  },
  {
    "text": "layer one or more layers so in this case we have an Alpine layer which is a base layer this is a Linux base image that",
    "start": "296919",
    "end": "304150"
  },
  {
    "text": "we're starting from it only has a single layer so it's one but you could think that this if this points to say a tab",
    "start": "304150",
    "end": "309490"
  },
  {
    "text": "unto image or a language specific version like Java or Ruby that actually",
    "start": "309490",
    "end": "315039"
  },
  {
    "text": "I might have multiple layers I have a maintainer line here and a command line as well so looking at that a little",
    "start": "315039",
    "end": "322389"
  },
  {
    "text": "closer again we have a from from build that we have we have a maintainer line which just is putting metadata about who",
    "start": "322389",
    "end": "328360"
  },
  {
    "text": "sort of who owns and runs this and manages this image for other developers to see and then we have an actual command in this case is just echoing",
    "start": "328360",
    "end": "334900"
  },
  {
    "text": "hello reinvent now when we actually run our docker build command we can sort of",
    "start": "334900",
    "end": "341349"
  },
  {
    "text": "look at that output and see what's happening we can see that it's running from alpine it's adding the extra maintainer it's removing the",
    "start": "341349",
    "end": "347710"
  },
  {
    "text": "intermediate container after it runs as run is setting up the command for hello reinvent and running it again now each",
    "start": "347710",
    "end": "353409"
  },
  {
    "text": "of those cases it's running those intermediate and intermediate containers and then cleaning up afterwards and that's sort of important those those",
    "start": "353409",
    "end": "359889"
  },
  {
    "text": "those temporary read/write layers are then removed and you have basically your image built that you can push anywhere",
    "start": "359889",
    "end": "365620"
  },
  {
    "text": "you want now we can actually use the docker history command to inspect that",
    "start": "365620",
    "end": "370900"
  },
  {
    "text": "image so you can see this actually goes from top to bottom it's actually set it's backwards from what the layer of",
    "start": "370900",
    "end": "376840"
  },
  {
    "text": "the order has been built but you can see the bottom layer actually has the add file and that's a form egg layer that",
    "start": "376840",
    "end": "382360"
  },
  {
    "text": "there's a very you know Alpine is a very lightweight small Linux distribution as a base and then we have the maintainer",
    "start": "382360",
    "end": "387940"
  },
  {
    "text": "line and then the command line now you'll notice that while the base layer is four Meg's the size is for each of",
    "start": "387940",
    "end": "394389"
  },
  {
    "text": "the the other config layers are actually zero bytes since there isn't any filesystem data",
    "start": "394389",
    "end": "399620"
  },
  {
    "text": "needs it to be required for those they're just configuration it actually isn't preserved along with it so they end up being empty what we call empty",
    "start": "399620",
    "end": "405380"
  },
  {
    "text": "layers we'll see a little bit more about that later so we can also look at our",
    "start": "405380",
    "end": "411440"
  },
  {
    "text": "history for alpine and we can see it's actually the same as the top layer that we had before it's the same immutable",
    "start": "411440",
    "end": "417200"
  },
  {
    "text": "thing so if I can have something it's based off of an existing image that's actually the exact same history so if I",
    "start": "417200",
    "end": "423410"
  },
  {
    "text": "base all of my images off of say Alpine I know that that common layer can be used across different images on my host",
    "start": "423410",
    "end": "429290"
  },
  {
    "text": "when I pull in production so coming up with a common base layer that you're using for all of your container instances if they follow us in a similar",
    "start": "429290",
    "end": "436070"
  },
  {
    "text": "pattern or stack can actually help make a lot of portability and production but it may depend on your varying workloads",
    "start": "436070",
    "end": "441380"
  },
  {
    "text": "because you may have different teams that have different dependencies and needs and rely on different distributions now if we want to make a",
    "start": "441380",
    "end": "449540"
  },
  {
    "text": "code change we can go ahead and we've made a change to our docker file in this case we're just adding some hearts to",
    "start": "449540",
    "end": "454730"
  },
  {
    "text": "our echo command and we're gonna rebuild now we'll notice in this particular case it was actually able to use the build",
    "start": "454730",
    "end": "461390"
  },
  {
    "text": "cache so here we can see that rather than running the intermediate container saving the state and exiting it's",
    "start": "461390",
    "end": "468020"
  },
  {
    "text": "actually going to use that cache layer so docker this case notice that the maintainer line hadn't been changed was",
    "start": "468020",
    "end": "475040"
  },
  {
    "text": "able to not have to execute that command initialize another container really sort of understanding and optimizing how",
    "start": "475040",
    "end": "480740"
  },
  {
    "text": "build caches are used are really gonna help you in your build in CI CD systems in this particular case our command did",
    "start": "480740",
    "end": "487460"
  },
  {
    "text": "change so notice that that's invalidated has to rerun that build layer and it",
    "start": "487460",
    "end": "493760"
  },
  {
    "text": "runs it there so now that we have a kind of a basic understanding of images we",
    "start": "493760",
    "end": "499760"
  },
  {
    "text": "can talk about how we can actually improve on some image builds we're gonna go through a couple examples here just to get started so first this is a simple",
    "start": "499760",
    "end": "509390"
  },
  {
    "text": "Ruby application we're picking Ruby to 3 it has some gem file dependencies we're gonna go ahead and bundle those up and",
    "start": "509390",
    "end": "515719"
  },
  {
    "text": "then add our application code now the first thing we noticed is that we're setting Ruby 2.3 you really want to sort",
    "start": "515720",
    "end": "521870"
  },
  {
    "text": "of isolate down a specific base package version because if you just say Ruby latest it could be that one developer is",
    "start": "521870",
    "end": "527780"
  },
  {
    "text": "running a build on one desktop and other developers running it in the CI system it ends up grabbing a different version",
    "start": "527780",
    "end": "532910"
  },
  {
    "text": "Rubi so I would even recommend going further than this and actually pinpointing down to a specific patch version or minor version just to keep",
    "start": "532910",
    "end": "539570"
  },
  {
    "text": "consistency the next thing is we're adding our gem file and our gem file lock and in a ruby application all of",
    "start": "539570",
    "end": "545540"
  },
  {
    "text": "your dependencies were defined ahead of time so your gem file while it has the high level dependencies the gem file",
    "start": "545540",
    "end": "551600"
  },
  {
    "text": "lock has all of your fully resolved downstream dependencies so that way if I build my image regardless of wearing I'm",
    "start": "551600",
    "end": "558020"
  },
  {
    "text": "I'm building it I'm getting the exact same gems installed I'm adding my source code after that and then I'm running my",
    "start": "558020",
    "end": "563480"
  },
  {
    "text": "simple hello looking at our gem file we just have a colorized gem so we're just",
    "start": "563480",
    "end": "569180"
  },
  {
    "text": "using a simple gem here the gem file lock will actually at sort of build time and checking into your source code will",
    "start": "569180",
    "end": "575450"
  },
  {
    "text": "actually have the very specific version of colorize looking at our source code",
    "start": "575450",
    "end": "580700"
  },
  {
    "text": "we're just gonna sort of say hello world but we're gonna give it a little more Flair this time we're gonna give it some colors and we're using the colorized gem",
    "start": "580700",
    "end": "586160"
  },
  {
    "text": "to give us some some fun ASCII now going through our build step in our container",
    "start": "586160",
    "end": "591470"
  },
  {
    "text": "we can see that it's actually adding our gem file lock it's doing our bundle install and it's doing that bundle",
    "start": "591470",
    "end": "596720"
  },
  {
    "text": "install in the container instead of on my host it's actually going down gonna go down to Ruby gems download my gems",
    "start": "596720",
    "end": "602440"
  },
  {
    "text": "and build that build those into the build cache so we can see in the user local bundle is actually where it's",
    "start": "602440",
    "end": "608660"
  },
  {
    "text": "stored inside that container image and then later it adds my application code",
    "start": "608660",
    "end": "614860"
  },
  {
    "text": "we can see that again it's gonna remove the intermediate containers as it's being built",
    "start": "614860",
    "end": "619930"
  },
  {
    "text": "there's the add for our source code and if we actually run it we can see we finally get some nice colorized output",
    "start": "619930",
    "end": "627340"
  },
  {
    "text": "let's say we want to make a code change in this particular case we want to add some more hearts again to our ASCII",
    "start": "627340",
    "end": "633140"
  },
  {
    "text": "output and so we've made that code and change down there at the bottom and we have but we haven't changed any of our",
    "start": "633140",
    "end": "638450"
  },
  {
    "text": "gem dependencies none of our build dependencies have really changed we rerun our build and we can see in this",
    "start": "638450",
    "end": "643640"
  },
  {
    "text": "case it's actually able to cache the gem file lock and the bundle install which means I didn't have to redownload gems",
    "start": "643640",
    "end": "649190"
  },
  {
    "text": "from my from my build instance now this is a tip really here of just separating those build time form your actual like",
    "start": "649190",
    "end": "655010"
  },
  {
    "text": "your actual build basically on your actual application code most teams end up having a lot more change of their",
    "start": "655010",
    "end": "662180"
  },
  {
    "text": "application code than they do on their build dependencies so being able to really sort of separate these will allow you to sort of Optim on those build build caches and because",
    "start": "662180",
    "end": "670970"
  },
  {
    "text": "our code is actually changed in this particular case is gonna have to rerun but it only has to rerun on that last layer you run our hello reinvent again",
    "start": "670970",
    "end": "678739"
  },
  {
    "text": "this time we get our hearts in nice color and so the the takeaways here that",
    "start": "678739",
    "end": "685189"
  },
  {
    "text": "I really want you to count go away with is seeking two specific versions of base layers allow to give stability from",
    "start": "685189",
    "end": "690379"
  },
  {
    "text": "developer to developer and give you consistent builds it also means that at deployment time you if you sort of opt",
    "start": "690379",
    "end": "696559"
  },
  {
    "text": "into those new versions of save your base layer like brewery for example you know that if you're moving from say two",
    "start": "696559",
    "end": "702619"
  },
  {
    "text": "three two two two two four two three oh you know and that's gonna happen and that means only those new layer base",
    "start": "702619",
    "end": "708199"
  },
  {
    "text": "layers are gonna be deployed at that particular point in time most deployments are gonna be fairly small because they're just adding your Ruby",
    "start": "708199",
    "end": "713389"
  },
  {
    "text": "code that's changed so separating your application code from its dependencies really helps you sort of optimize what",
    "start": "713389",
    "end": "719419"
  },
  {
    "text": "you're actually building and deploying so next up we're gonna walk through a",
    "start": "719419",
    "end": "725329"
  },
  {
    "text": "bit of a go example in this particular case again I'm gonna try to pick a specific version we're using go one",
    "start": "725329",
    "end": "730759"
  },
  {
    "text": "seven but you could get more specific down there to a minor version we're gonna actually add our source code and run our go build inside of our container",
    "start": "730759",
    "end": "738819"
  },
  {
    "text": "or actually go code is just gonna say a hello world again not something super crazy exciting but I'm sure your",
    "start": "738819",
    "end": "744679"
  },
  {
    "text": "applications are gonna be a little bit more advanced and in this case we're actually going to go ahead and building",
    "start": "744679",
    "end": "750739"
  },
  {
    "text": "our container now when we run our actual application we get our hello so we know",
    "start": "750739",
    "end": "756980"
  },
  {
    "text": "it works and let's look at our actual images output so this is kind of surprising go is a compiled language and",
    "start": "756980",
    "end": "765259"
  },
  {
    "text": "so you should have a really small binary at the end of this but we actually end up having a six hundred seventy four megabyte layer or image and that's kind",
    "start": "765259",
    "end": "772489"
  },
  {
    "text": "of surprising because you know it seems that we'd be able to have a binary much smaller than that and it seems like a lot to sort of build and push all the",
    "start": "772489",
    "end": "778610"
  },
  {
    "text": "way out to production so we can go back to our history command and actually inspect and see sort of what happened",
    "start": "778610",
    "end": "784160"
  },
  {
    "text": "here and in this particular case we're gonna run our history command and going to see all these layers that are coming",
    "start": "784160",
    "end": "789350"
  },
  {
    "text": "from so this all comes from the go 1.7 base layer and so all of the things that are above and again these these go sort",
    "start": "789350",
    "end": "797239"
  },
  {
    "text": "of top to bottom or everything that you sort of brought in is a part of the go 1.7 and we can see we",
    "start": "797239",
    "end": "803329"
  },
  {
    "text": "first have these apt-get updates and nap get installs and that's actually getting all the build essentials that are required for NGO itself to be compiled",
    "start": "803329",
    "end": "809740"
  },
  {
    "text": "then we actually have all of the girls that go source code downloaded which is another two hundred Meg's and then we",
    "start": "809740",
    "end": "815389"
  },
  {
    "text": "finally have our binary after all of those builds so our binary itself was less than two Meg's well we have all of",
    "start": "815389",
    "end": "821060"
  },
  {
    "text": "these other things that are required for that particular container so this is sort of the next sort of tip that I'd",
    "start": "821060",
    "end": "826790"
  },
  {
    "text": "like to sort of provide you is really sort of understanding that you know what at runtime you don't necessarily need",
    "start": "826790",
    "end": "831980"
  },
  {
    "text": "everything that you need at build time and while build isolation is great you really need to sort of figure out a way",
    "start": "831980",
    "end": "837019"
  },
  {
    "text": "of isolating these two and the way that I would recommend in the way that we've used a TCS as well is actually isolating",
    "start": "837019",
    "end": "843889"
  },
  {
    "text": "build versus runtime containers our agent itself builds in this format so which is fully open source and you can",
    "start": "843889",
    "end": "850009"
  },
  {
    "text": "check it out as well so looking at our this is going to be our build container",
    "start": "850009",
    "end": "855319"
  },
  {
    "text": "looks similar from before except where we have a volume mount and we then copy our binary instead of actually running",
    "start": "855319",
    "end": "861560"
  },
  {
    "text": "it so we're using a volume mount to then sort of copy what we need are artifacts out you can imagine if this was another",
    "start": "861560",
    "end": "868579"
  },
  {
    "text": "application you could do the same weather whatever kind of resources even if it was say compressed gzipped",
    "start": "868579",
    "end": "874029"
  },
  {
    "text": "JavaScript or whatever resources your artifact so your application needs at production time so our build container",
    "start": "874029",
    "end": "881269"
  },
  {
    "text": "or a runtime container here is actually pretty small it has from scratch which isn't actually an empty base image it",
    "start": "881269",
    "end": "887120"
  },
  {
    "text": "has nothing in it and we're adding our binary and then we're just running it so it only contains that our binary needs",
    "start": "887120",
    "end": "892189"
  },
  {
    "text": "at runtime it's a static build that's it so we're gonna rerun our build which looks like we had before it actually",
    "start": "892189",
    "end": "898670"
  },
  {
    "text": "builds in our build time container and we'll notice the differences here is we're adding a volume and the actual",
    "start": "898670",
    "end": "906230"
  },
  {
    "text": "command a copy is to copy the actual the actual binary out of the image so now we",
    "start": "906230",
    "end": "912380"
  },
  {
    "text": "can actually copy that artifact out by doing a docker run so we're doing a volume out locally we're running the",
    "start": "912380",
    "end": "918230"
  },
  {
    "text": "container and all we're really doing is saying oh let's take this binary from inside this container and copy it out and then lastly now we're running our",
    "start": "918230",
    "end": "926509"
  },
  {
    "text": "runtime container we're actually gonna go ahead just add that binary now the great thing as well here is we're we're still getting that build",
    "start": "926509",
    "end": "932839"
  },
  {
    "text": "level of isolation which means I could actually be on a host that doesn't even have NGO installed I can run a nice sanitized build and then I",
    "start": "932839",
    "end": "939290"
  },
  {
    "text": "can add all of my artifacts to a separate container that's run dat is pushed at runtime so we know it still",
    "start": "939290",
    "end": "944930"
  },
  {
    "text": "works we've rerun our command we get our hello reinvent but now we're only down to less",
    "start": "944930",
    "end": "950660"
  },
  {
    "text": "than two Meg's in our lair and we only have two we have two layers and we only have one minute or two Meg's for our",
    "start": "950660",
    "end": "956540"
  },
  {
    "text": "actual binary application so now instead of every single deploy having to flow that entire stack I've got a much much",
    "start": "956540",
    "end": "962270"
  },
  {
    "text": "smaller binary that's really gonna make things a lot better at both your CI system having to push all the way up to",
    "start": "962270",
    "end": "967610"
  },
  {
    "text": "your registry as well as download from the registry as well at deployment time we've got that again two Meg's there so",
    "start": "967610",
    "end": "977150"
  },
  {
    "text": "the overall tips here is just trying to figure out what you actually need at runtime versus what you need it build time you know again docker provides a",
    "start": "977150",
    "end": "984680"
  },
  {
    "text": "great level of build isolation so you can sure that you've got that portable images and they're they're very much isolated from those dependencies but",
    "start": "984680",
    "end": "991460"
  },
  {
    "text": "separating out that from your build and runtime container is actually gonna improve your improve your pull and push",
    "start": "991460",
    "end": "996710"
  },
  {
    "text": "times and there are applications where like this is a static example where you",
    "start": "996710",
    "end": "1001900"
  },
  {
    "text": "know you have a binary which could work cool for any sort of statically compiled language but dynamic languages work for",
    "start": "1001900",
    "end": "1007450"
  },
  {
    "text": "this as well if you have a rail stack for example you might want to package up all your JavaScript or image assets or",
    "start": "1007450",
    "end": "1013120"
  },
  {
    "text": "your CSS at sets you don't necessarily need that compression to be that that sort of JavaScript engine to come with",
    "start": "1013120",
    "end": "1018730"
  },
  {
    "text": "you at runtime you could actually separate it out at Build time and then just package those up for serving later",
    "start": "1018730",
    "end": "1025410"
  },
  {
    "text": "so these are some of the advanced tips that I don't have an unfortunately have enough time to cover today but I'll",
    "start": "1025410",
    "end": "1031150"
  },
  {
    "text": "leave with you is sort of a bit of a homework assignment so the first thing is you can build your own base images it's actually quite easy base images are",
    "start": "1031150",
    "end": "1038500"
  },
  {
    "text": "what we saw before we're sort of using Alpine we used to go now you could have a normal docker image that gets built",
    "start": "1038500",
    "end": "1044920"
  },
  {
    "text": "but you could also sort of create your own base layer by creating a local tar ball and then importing it this can be",
    "start": "1044920",
    "end": "1050320"
  },
  {
    "text": "really good if you have want to set a common base layer for your entire company if like EF say a base distribution with common packages that",
    "start": "1050320",
    "end": "1056830"
  },
  {
    "text": "you know everyone is going to use you're kind of trying to unify that stack across things and that'll mean that if you know that that base layer is pushed",
    "start": "1056830",
    "end": "1062710"
  },
  {
    "text": "across all of your build fleet it's gonna make things much better and on top of that",
    "start": "1062710",
    "end": "1068230"
  },
  {
    "text": "and dr. 1:13 now this is in the RC so it will when when dr. 113 goes goes",
    "start": "1068230",
    "end": "1074170"
  },
  {
    "text": "finalized there's actually a squashed layer there's a squash command now so that allows you to sort of take multiple",
    "start": "1074170",
    "end": "1080140"
  },
  {
    "text": "of those sort of smaller layers and squash them bound to a single layer to reduce overhead of having to do lots of smaller pulls now you'll have to be",
    "start": "1080140",
    "end": "1086740"
  },
  {
    "text": "careful with this because you could invalid end up in validating those other layers there are cases in which k if",
    "start": "1086740",
    "end": "1092590"
  },
  {
    "text": "you're then taking all of your base layers for your base image and adding your application code you're squashing it to a single one now you're pulling",
    "start": "1092590",
    "end": "1098140"
  },
  {
    "text": "the entire image every single time so you can't really take advantage of that layer level caching on your deployment",
    "start": "1098140",
    "end": "1103510"
  },
  {
    "text": "host so now that we have an idea of how we can sort of build and optimize our",
    "start": "1103510",
    "end": "1109330"
  },
  {
    "text": "images we'll talk a little bit how the docker registry v2 API works again ECR",
    "start": "1109330",
    "end": "1114820"
  },
  {
    "text": "understands and responds and works with this ECR this api so if we understand how this API actually works between the",
    "start": "1114820",
    "end": "1121450"
  },
  {
    "text": "docker engine in our registry we can actually then look at how optimizing our layers and images can actually improve",
    "start": "1121450",
    "end": "1128790"
  },
  {
    "text": "so the first thing is pulling an image and we do a docker pull you provide a registry you or I you know in this",
    "start": "1128790",
    "end": "1134980"
  },
  {
    "text": "particular case for for ECR you're gonna use your your specific registry URL and",
    "start": "1134980",
    "end": "1140860"
  },
  {
    "text": "you know because you can provide this URL with others it's unique to your account you provide your image name in",
    "start": "1140860",
    "end": "1146200"
  },
  {
    "text": "your tag now so the docker daemon when you tell this the commands gonna hit the daemon and Damons gonna say well first",
    "start": "1146200",
    "end": "1151870"
  },
  {
    "text": "we need to fetch this image of this particular tag and for each layer I don't happen to have on the host I need to go ahead and download it so",
    "start": "1151870",
    "end": "1159310"
  },
  {
    "text": "translating that to HTTP calls it does an HTTP GET 4 /b - image and a manifest",
    "start": "1159310",
    "end": "1164320"
  },
  {
    "text": "tag and then for each layer that doesn't have locally it's a get B - image - a Bob's digest so this is really important",
    "start": "1164320",
    "end": "1171490"
  },
  {
    "text": "so if I already have a layer on my host I don't actually have to download it if I've already cached that sort of base",
    "start": "1171490",
    "end": "1176500"
  },
  {
    "text": "you know if I'm using Alpine if I've already cast that base alpine image on every single one of my my hosts of my",
    "start": "1176500",
    "end": "1181930"
  },
  {
    "text": "UCS bleed I don't actually have to download that base layer anymore and I'm just deploying the latest bit of my",
    "start": "1181930",
    "end": "1187000"
  },
  {
    "text": "application code and really kind of like tuning in con tuning in those will sort",
    "start": "1187000",
    "end": "1192010"
  },
  {
    "text": "of really help your deployments go much much faster oh and as a quick note on",
    "start": "1192010",
    "end": "1197410"
  },
  {
    "text": "docker 110 and above it actually pulls these layers in parallel so something just sort of lookout as well",
    "start": "1197410",
    "end": "1203559"
  },
  {
    "text": "sort of upgrading at least to that version will give you an idea so that means it can pull those layers concurrently you'll still be stuck for",
    "start": "1203559",
    "end": "1210190"
  },
  {
    "text": "the longest layer so if you have for some people for some reason you have one very very large layer you're still going to wait on that last layer to pull",
    "start": "1210190",
    "end": "1216279"
  },
  {
    "text": "before it can actually start running but again being able to pull lots of small layers concurrently helps quite a bit",
    "start": "1216279",
    "end": "1223409"
  },
  {
    "text": "now pushing an image is exactly the opposite we're gonna do a docker push register URL you have locally image name",
    "start": "1223409",
    "end": "1229570"
  },
  {
    "text": "and tag but the doctor Damon has to do a little bit more work here for each layered has to see does that layer exist",
    "start": "1229570",
    "end": "1235329"
  },
  {
    "text": "already on the reg registry and if it does if it doesn't that it needs to initiate a layer upload send the actual data and then set set that is complete",
    "start": "1235329",
    "end": "1242289"
  },
  {
    "text": "and when all those layers are done it needs to sort of push the manifest saying that the layers are complete",
    "start": "1242289",
    "end": "1249029"
  },
  {
    "text": "translating this to the API perspective we can see it's just doing a head check it's doing a post to initialize the",
    "start": "1249029",
    "end": "1254950"
  },
  {
    "text": "upload is doing a patch to actually send though that binary contents for the layer and then it's doing a put to",
    "start": "1254950",
    "end": "1260409"
  },
  {
    "text": "finalize each individual layer now again from docker 110 and above it can",
    "start": "1260409",
    "end": "1265570"
  },
  {
    "text": "actually paralyze these uploads and kind of speed things up so now we're gonna we",
    "start": "1265570",
    "end": "1272469"
  },
  {
    "text": "a we have an image that's actually been pushed we're gonna actually or we have an image that we understand how the API is work we're actually go through a",
    "start": "1272469",
    "end": "1278259"
  },
  {
    "text": "whole push scenario with sort of ECR here and see how it works now we're gonna first we need to sort of get a",
    "start": "1278259",
    "end": "1284049"
  },
  {
    "text": "temporary set of credentials that we can use to work with ECR we're gonna go ahead and get an authorization token and",
    "start": "1284049",
    "end": "1289629"
  },
  {
    "text": "then we can actually get the that out of the result data here as well as getting the endpoint that we want to talk to I'm",
    "start": "1289629",
    "end": "1296409"
  },
  {
    "text": "gonna use a little bit of JQ here to do some of the the JavaScript parsing now I",
    "start": "1296409",
    "end": "1302019"
  },
  {
    "text": "want to fetch out my username and password that token that we had before was actually just a base64 encoded",
    "start": "1302019",
    "end": "1307629"
  },
  {
    "text": "username and temporary password this is comes back in an HTTP digest format",
    "start": "1307629",
    "end": "1312700"
  },
  {
    "text": "which is normally sent back and forth but for our purposes we want to separate that because we're doing a doc or login",
    "start": "1312700",
    "end": "1317940"
  },
  {
    "text": "we use a docker login we provide that username and password to re see our URL that we saved before and you know pivot",
    "start": "1317940",
    "end": "1325269"
  },
  {
    "text": "because this is probably a little bit more cumbersome to do on a regular basis this is actually what the ecr's get login command does under the scenes so",
    "start": "1325269",
    "end": "1332259"
  },
  {
    "text": "you can actually go to the CLI open source and see it pretty much does same thing except for as written in",
    "start": "1332259",
    "end": "1337340"
  },
  {
    "text": "Python instead of bash and basic C for - D this is what it is on your Mac so if",
    "start": "1337340",
    "end": "1343010"
  },
  {
    "text": "you're running on Linux I think it's a lowercase D so now we're gonna go ahead and create a repository here on ECR so",
    "start": "1343010",
    "end": "1350630"
  },
  {
    "text": "we're gonna go ahead and create our holo we're gonna go back to our original example that we had before that we had built we're gonna save off that image",
    "start": "1350630",
    "end": "1356480"
  },
  {
    "text": "URI so we know exactly what URL a URI to sort of provide when we're actually gonna tag our image and once you're done",
    "start": "1356480",
    "end": "1363380"
  },
  {
    "text": "this exercise I'd say you can go back and delete that repository we provide a force command this is just so if you're",
    "start": "1363380",
    "end": "1368900"
  },
  {
    "text": "doing a repository and you have images that you haven't deleted we sort of don't let you unless you pass the forest it's really just sort of a safety",
    "start": "1368900",
    "end": "1374930"
  },
  {
    "text": "mechanism to make things a little bit easier now pushing an image we're gonna go ahead and tag that hello back to our",
    "start": "1374930",
    "end": "1382010"
  },
  {
    "text": "image URI and just do a push now that we have that image push we can see well",
    "start": "1382010",
    "end": "1388220"
  },
  {
    "text": "what does that manifest actually look like so we can actually do a curl here with that username and password it's",
    "start": "1388220",
    "end": "1393830"
  },
  {
    "text": "gonna set the HTTP digest on the request go back to our URL we're gonna go back to that manifest latest so that's hello",
    "start": "1393830",
    "end": "1400730"
  },
  {
    "text": "is the the image name and latest is the tag we're gonna save that back out to a JSON file so we can use it later we can",
    "start": "1400730",
    "end": "1407690"
  },
  {
    "text": "start to see the beginning of this JSON file and that's all an image really is it's just a JSON file with data it's",
    "start": "1407690",
    "end": "1413960"
  },
  {
    "text": "gonna store the in this particular case that's showing its schema one currently ECR supports a manifest schema one we're",
    "start": "1413960",
    "end": "1420980"
  },
  {
    "text": "gonna be supporting schema tuned very shortly you can see that this has our image name and our tag inside of it as",
    "start": "1420980",
    "end": "1426830"
  },
  {
    "text": "well as the architecture next through the file you can actually see the blob sums so those are actually refer back to",
    "start": "1426830",
    "end": "1433880"
  },
  {
    "text": "those tars that we saw before those those those bought those blobs and you'll actually notice that the top two",
    "start": "1433880",
    "end": "1439220"
  },
  {
    "text": "actually have the same number this a 3e d 9 5 c AE is actually an empty layer so",
    "start": "1439220",
    "end": "1445880"
  },
  {
    "text": "there's no actual content it's nicer than empty tartar GZ and the last one",
    "start": "1445880",
    "end": "1451130"
  },
  {
    "text": "itself is our Alpine layer so that was our config and run command that we saw before this is sort of how you could see",
    "start": "1451130",
    "end": "1456860"
  },
  {
    "text": "what they are now in newer version of the docker again the schema - it actually removes these config layers and",
    "start": "1456860",
    "end": "1463070"
  },
  {
    "text": "changes the configuration to a separate layer itself that holds all of that data but schema 1 is still preserved here",
    "start": "1463070",
    "end": "1469390"
  },
  {
    "text": "now this is definitely hard to read but looking at the history we can see this",
    "start": "1469390",
    "end": "1474410"
  },
  {
    "text": "v1 compatibility so now we're actually gonna see the docker container config for every single layer now this is JSON",
    "start": "1474410",
    "end": "1481250"
  },
  {
    "text": "inside of JSON but you can usually parse this out if you kind of want to see what's going on or if you squint really",
    "start": "1481250",
    "end": "1486290"
  },
  {
    "text": "really hard but this is our last layer that actually did our echo echo hello world and also because it's the final",
    "start": "1486290",
    "end": "1491570"
  },
  {
    "text": "layer it has all the runtime configuration that your container needs so is that sure you know your environment variable is your path",
    "start": "1491570",
    "end": "1497120"
  },
  {
    "text": "whether or not you have a TTY this is all your runtime configuration just sort of stored in the image and you'll also",
    "start": "1497120",
    "end": "1503630"
  },
  {
    "text": "notice that it has if you can see it from here we probably see it in the next slide a little bit better there we go so",
    "start": "1503630",
    "end": "1509630"
  },
  {
    "text": "these are the other two layers the maintainer line is the first one we see on the top there it's a little easier to understand slightly you can see that it",
    "start": "1509630",
    "end": "1517130"
  },
  {
    "text": "has this container config line see that commands maintainer line there it has my name so that's actually how the docker",
    "start": "1517130",
    "end": "1522950"
  },
  {
    "text": "history command can actually look back to that manifest and see how each layer was built so you actually go back to manifest and say like well where did",
    "start": "1522950",
    "end": "1529220"
  },
  {
    "text": "this come from and in this particular case all it does is add a config line that says my author is my name and it's",
    "start": "1529220",
    "end": "1535640"
  },
  {
    "text": "a throwaway layer because it's just a config base layer the last layer we can see here doesn't have any configuration",
    "start": "1535640",
    "end": "1541340"
  },
  {
    "text": "other than showing the container config on how it was built and that's because our Alpine layer is just is just the",
    "start": "1541340",
    "end": "1547430"
  },
  {
    "text": "actual Alpine binary that we need to actually run our base image now lastly",
    "start": "1547430",
    "end": "1554510"
  },
  {
    "text": "we have a signature here in schema 1 signatures can be added inside of the the manifest file the actual this means",
    "start": "1554510",
    "end": "1562310"
  },
  {
    "text": "that the signed manifest is a part of there is all in here and later versions of docker that schema is actually that",
    "start": "1562310",
    "end": "1568070"
  },
  {
    "text": "signature is actually brought outside the manifest which is a little bit nicer and it's moved into notary so now that",
    "start": "1568070",
    "end": "1575090"
  },
  {
    "text": "we have our manifest file save let's go ahead and download the layers we're gonna use a little bit more JQ which is",
    "start": "1575090",
    "end": "1580490"
  },
  {
    "text": "pretty much my helper for most things I'm gonna pipe that out to a file and then we're gonna do some curl with some",
    "start": "1580490",
    "end": "1586730"
  },
  {
    "text": "X args and we're gonna keep download each one of those layers if you give a - P and a number come in - you can",
    "start": "1586730",
    "end": "1593270"
  },
  {
    "text": "paralyze download pro pro x args to anyone but the - shell here is also",
    "start": "1593270",
    "end": "1598520"
  },
  {
    "text": "important because that's actually get allowing us to follow redirects so from ECR we actually provide",
    "start": "1598520",
    "end": "1603950"
  },
  {
    "text": "pre-signed urls down to docker so it can download your images directly from s3 this ensures that you get the best",
    "start": "1603950",
    "end": "1609710"
  },
  {
    "text": "performance because at this point you're going directly to s3 to actually download everything and we're saving",
    "start": "1609710",
    "end": "1615410"
  },
  {
    "text": "those blobs of disk and again we're providing our credentials the way we did before now looking at our layers you",
    "start": "1615410",
    "end": "1621410"
  },
  {
    "text": "only actually have two that downloaded because two or two are the same or that empty layer and we have our two point",
    "start": "1621410",
    "end": "1626720"
  },
  {
    "text": "two Meg's because these were actually gzipped as well and we can actually just look at them man if you want to you can",
    "start": "1626720",
    "end": "1633500"
  },
  {
    "text": "just untie them this is there's not a lot of magic here this is just UNIX so you can actually see that I'm not gonna",
    "start": "1633500",
    "end": "1639800"
  },
  {
    "text": "show you the entire contents of Alpine that might be a little boring but we can see that we have the busybox binary and",
    "start": "1639800",
    "end": "1645890"
  },
  {
    "text": "we have a bunch of symlinks that's just because it's a small distro so I've used this trick quite a bit when I look at a layer and it's way bigger than what I",
    "start": "1645890",
    "end": "1652550"
  },
  {
    "text": "expected so I'll download it I'll extract it I'll see actually what's inside and say oh I didn't actually",
    "start": "1652550",
    "end": "1657680"
  },
  {
    "text": "realize that simple command was adding so much so much to my actual runtime layer and our empty layer is in fact an",
    "start": "1657680",
    "end": "1666110"
  },
  {
    "text": "empty layer there's nothing in it it's just it's just a little four kilobyte empty tar.gz again at least with the newer versions",
    "start": "1666110",
    "end": "1673910"
  },
  {
    "text": "this isn't actually sort of transferred but usually on your host this is cache pretty quickly it's only pulled down once so I can get that that empty layer",
    "start": "1673910",
    "end": "1683350"
  },
  {
    "text": "so the takeaways now that we kind of understand how our api's work is that",
    "start": "1683350",
    "end": "1688550"
  },
  {
    "text": "really reducing your number of layers means this reduces the number of uploads and downloads that you have and reducing",
    "start": "1688550",
    "end": "1694430"
  },
  {
    "text": "the actual contents reduces that upload download time and every single time you minimize those layer changes themselves",
    "start": "1694430",
    "end": "1700400"
  },
  {
    "text": "we can actually reduce and faster deployments so you know if that one last smaller layer is the only thing you've",
    "start": "1700400",
    "end": "1705500"
  },
  {
    "text": "changed your application and you're deploying very very frequently in your CI system you're gonna get much faster deployment if you just spend a little",
    "start": "1705500",
    "end": "1711620"
  },
  {
    "text": "bit of time going through your docker images and figuring out what's going on in there so talking of CI CD so going",
    "start": "1711620",
    "end": "1720470"
  },
  {
    "text": "through a little bit of the best practices here we're gonna sort of talk about some some tips that we've learned from talking to a lot of our customers",
    "start": "1720470",
    "end": "1726940"
  },
  {
    "text": "the first thing is come up with a good tagging scheme a lot of customers might use latest or stable or prod one of the",
    "start": "1726940",
    "end": "1734570"
  },
  {
    "text": "problems with that is it mean is really hard to sort of stage out your changes so if I'm using stable and I'm",
    "start": "1734570",
    "end": "1739940"
  },
  {
    "text": "using ECS it may sort of just go ahead and start using that in my task definition so we really recommend as a",
    "start": "1739940",
    "end": "1745880"
  },
  {
    "text": "part of your build system creating a logical sort of version for every single build that you make and ideally if you",
    "start": "1745880",
    "end": "1751250"
  },
  {
    "text": "can tie it back to your artifacts then you can sort of trace that all the way through your production system so you drag it back to your source code or",
    "start": "1751250",
    "end": "1757280"
  },
  {
    "text": "maybe your Jenkins build and done a fire you can know where that actual artifact came from and that means you can",
    "start": "1757280",
    "end": "1762830"
  },
  {
    "text": "actually stagger your deployments so if you're using ECS we'd recommend creating a new task definition and your family",
    "start": "1762830",
    "end": "1768110"
  },
  {
    "text": "updating your service definition and then allowing that to sort of gradually roll out and if you're really interested in Bluegreen deployments then we",
    "start": "1768110",
    "end": "1774110"
  },
  {
    "text": "recommend is creating a second service with the new task definition and using you'll be creating a new creating a new",
    "start": "1774110",
    "end": "1780260"
  },
  {
    "text": "alb and then using route 53 to wait over so the CI CD tips that we really have",
    "start": "1780260",
    "end": "1786620"
  },
  {
    "text": "here is the build caches that we mentioned before so not having to rerun the bundle install means that we can",
    "start": "1786620",
    "end": "1792740"
  },
  {
    "text": "actually take advantage of that here so being able to sort of rerun in the same build house means you're actually gonna",
    "start": "1792740",
    "end": "1798740"
  },
  {
    "text": "take advantage of what was already on that host before you don't have to redownload those gems every single time and of course reducing your builds to",
    "start": "1798740",
    "end": "1805070"
  },
  {
    "text": "image image sizes is gonna actually and reduce number layers is gonna actually reduce that much you have to transfer",
    "start": "1805070",
    "end": "1810290"
  },
  {
    "text": "back up to ECR and of course we are in nine regions today so building and",
    "start": "1810290",
    "end": "1815330"
  },
  {
    "text": "pushing in the same region as possible is actually gonna make things much much much better that way you don't have to",
    "start": "1815330",
    "end": "1820730"
  },
  {
    "text": "nee do any sort of cross region pushes so next up we're gonna have mal come up",
    "start": "1820730",
    "end": "1826460"
  },
  {
    "text": "here and he's gonna talk a little bit about ECR and their usage at Pinterest",
    "start": "1826460",
    "end": "1831880"
  },
  {
    "text": "thanks thanks Scott",
    "start": "1831880",
    "end": "1835930"
  },
  {
    "text": "they make my speaker first of all a",
    "start": "1839630",
    "end": "1851210"
  },
  {
    "text": "little bit about me my name is Malkin",
    "start": "1851210",
    "end": "1856320"
  },
  {
    "text": "I'm working for Pinterest at the site reliability engineer I came from a",
    "start": "1856320",
    "end": "1864270"
  },
  {
    "text": "background of a traditional enterprise software developer in Oracle database",
    "start": "1864270",
    "end": "1870360"
  },
  {
    "text": "and Java Aggieland for years then I became a performance engineer you",
    "start": "1870360",
    "end": "1876210"
  },
  {
    "text": "know SAS company two years ago I switched to to the SAE row and I'm",
    "start": "1876210",
    "end": "1885420"
  },
  {
    "text": "excited about cloud and container technologies I'm focusing on putting",
    "start": "1885420",
    "end": "1892740"
  },
  {
    "text": "things into containers inside join the Pinterest today I'm very happy to have",
    "start": "1892740",
    "end": "1899070"
  },
  {
    "text": "the chance to share share you about a few stories and the tips and the lessons",
    "start": "1899070",
    "end": "1905790"
  },
  {
    "text": "we learned at Pinterest when running container in AWS for people hasn't heard",
    "start": "1905790",
    "end": "1915990"
  },
  {
    "text": "Pinterest we are the catalog of ideas or wrong the word user use Pinterest",
    "start": "1915990",
    "end": "1923780"
  },
  {
    "text": "website or apps to share and discover various ideas of their interests and",
    "start": "1923780",
    "end": "1932730"
  },
  {
    "text": "often get inspired by amazing ideas to do something awesome in their real lives",
    "start": "1932730",
    "end": "1939600"
  },
  {
    "text": "and recently we achieved 100 mini 100",
    "start": "1939600",
    "end": "1945270"
  },
  {
    "text": "meeting weekly active users and half of them from outside of the United States",
    "start": "1945270",
    "end": "1952460"
  },
  {
    "text": "so these are very big milestones for us you can also see we have a tremendous",
    "start": "1952460",
    "end": "1960390"
  },
  {
    "text": "amount of data like pins pause of many",
    "start": "1960390",
    "end": "1965700"
  },
  {
    "text": "users we store all of them in AWS",
    "start": "1965700",
    "end": "1970919"
  },
  {
    "text": "yeah a little bit history is Pinterest was built on top of a SS since it was",
    "start": "1970919",
    "end": "1978669"
  },
  {
    "text": "built at 2010 now we grow a lot of",
    "start": "1978669",
    "end": "1986139"
  },
  {
    "text": "course and Nara day we are running tens of thousands ec2 instances and also we",
    "start": "1986139",
    "end": "1992980"
  },
  {
    "text": "have over 100 petabyte data in s3 which",
    "start": "1992980",
    "end": "1999549"
  },
  {
    "text": "cannot even be packed into one snow mobile check ok yeah so when I talking",
    "start": "1999549",
    "end": "2012360"
  },
  {
    "text": "about containers actually I often means daughter yeah I expect many audience",
    "start": "2012360",
    "end": "2021419"
  },
  {
    "text": "here already know some information about",
    "start": "2021419",
    "end": "2026519"
  },
  {
    "text": "Dockers so I won't elaborate meting",
    "start": "2026519",
    "end": "2031759"
  },
  {
    "text": "benefits of talker here so well",
    "start": "2031759",
    "end": "2037590"
  },
  {
    "text": "explained at Pinterest the major reason for us to attempt ring talker from the",
    "start": "2037590",
    "end": "2046019"
  },
  {
    "text": "beginning of this year is because we found docker is a better tool to build",
    "start": "2046019",
    "end": "2054960"
  },
  {
    "text": "cheap and wrong services for internal Pinterest services in a much much more",
    "start": "2054960",
    "end": "2062490"
  },
  {
    "text": "reliable way that's what advert I",
    "start": "2062490",
    "end": "2067819"
  },
  {
    "text": "advocate advertised by the docker company but to be honest it's true",
    "start": "2067819",
    "end": "2074368"
  },
  {
    "text": "because the experienced experienced docker build it's very helpful for",
    "start": "2074369",
    "end": "2083540"
  },
  {
    "text": "developers I think so far the docker",
    "start": "2083540",
    "end": "2089790"
  },
  {
    "text": "image probably is a best format for everyone every developers to build and",
    "start": "2089790",
    "end": "2095790"
  },
  {
    "text": "ship their services and wrong in anywhere it's innovation which disrupted many",
    "start": "2095790",
    "end": "2105000"
  },
  {
    "text": "many traditional tools for example apt-get or configuration to like power",
    "start": "2105000",
    "end": "2112530"
  },
  {
    "text": "pair or other things sorry if you are a puppy lover but yeah that's my opinion",
    "start": "2112530",
    "end": "2120980"
  },
  {
    "text": "Pinterest actually is a heavy user of puppet for instance profiling and and",
    "start": "2120980",
    "end": "2132260"
  },
  {
    "text": "there's a service configuration it played a big role in Pinterest growth",
    "start": "2132260",
    "end": "2139260"
  },
  {
    "text": "turnout however we also accumulated many",
    "start": "2139260",
    "end": "2147560"
  },
  {
    "text": "many issues because we have a big share the puppy repo for everything which now",
    "start": "2147770",
    "end": "2155940"
  },
  {
    "text": "becomes kind of cranky and cosmetic",
    "start": "2155940",
    "end": "2161160"
  },
  {
    "text": "issues from time to time so talker fortunately address the issues very well",
    "start": "2161160",
    "end": "2168650"
  },
  {
    "text": "because it packages the dependencies into image as much as possible hence its",
    "start": "2168650",
    "end": "2175589"
  },
  {
    "text": "minimalized minimized the risk of provisioning and the configuration on",
    "start": "2175589",
    "end": "2180780"
  },
  {
    "text": "the host so first thing when I started to working on docker in Pinterest is to",
    "start": "2180780",
    "end": "2189060"
  },
  {
    "text": "find our reliable registration solution we picked SAR because several reasons",
    "start": "2189060",
    "end": "2196440"
  },
  {
    "text": "the first one is I don't want to run or maintain our own registry and because",
    "start": "2196440",
    "end": "2205800"
  },
  {
    "text": "it's take our efforts to run into stable and reliable and the keep it upgraded to",
    "start": "2205800",
    "end": "2212730"
  },
  {
    "text": "back where the compatible with docker client and so I trust in the best and",
    "start": "2212730",
    "end": "2219570"
  },
  {
    "text": "just like we trust other services in AWS the second reason is it's fast its",
    "start": "2219570",
    "end": "2225990"
  },
  {
    "text": "performance because it ever has provide you know maybe the fastest access pass",
    "start": "2225990",
    "end": "2232560"
  },
  {
    "text": "for the ECR and the third reason is reliable scalable as Scott mentioned earlier and",
    "start": "2232560",
    "end": "2241829"
  },
  {
    "text": "the dr. poore actually use URL to",
    "start": "2241829",
    "end": "2247410"
  },
  {
    "text": "directly pour layers from s3 and s3 we are very familiar when we trustees it's",
    "start": "2247410",
    "end": "2254849"
  },
  {
    "text": "no doubt reliable and and scalable we did have a small issues at the beginning",
    "start": "2254849",
    "end": "2260730"
  },
  {
    "text": "when we use the VCR which is related to the gate token and request but I will do",
    "start": "2260730",
    "end": "2267480"
  },
  {
    "text": "the update quickly with the LMS kind of support so it's knowing issue anymore",
    "start": "2267480",
    "end": "2273859"
  },
  {
    "text": "then the fuel usage I'd like to share",
    "start": "2273859",
    "end": "2279869"
  },
  {
    "text": "with you is firstly in Pinterest we have many development instance in is a tool",
    "start": "2279869",
    "end": "2288059"
  },
  {
    "text": "basically each developer in Pinterest has ec2 instances which count contains",
    "start": "2288059",
    "end": "2293999"
  },
  {
    "text": "all the dependency a and basically each developer can run a local locally",
    "start": "2293999",
    "end": "2301440"
  },
  {
    "text": "Pinterest website and their dev instances it was comfy goodbye puppet",
    "start": "2301440",
    "end": "2308329"
  },
  {
    "text": "but yeah as I mentioned the puppy has so many scenes together and it's fragile",
    "start": "2308329",
    "end": "2314940"
  },
  {
    "text": "it's broken all the time so we did one scene which impact many developer which",
    "start": "2314940",
    "end": "2323880"
  },
  {
    "text": "is we put all the developers to every environment into the docker image and so",
    "start": "2323880",
    "end": "2329309"
  },
  {
    "text": "now we have a hundreds of TB incidence wronging daughter Angie and developer",
    "start": "2329309",
    "end": "2335730"
  },
  {
    "text": "use docker daily the second usage is the",
    "start": "2335730",
    "end": "2340769"
  },
  {
    "text": "Jenkins we have hundreds of also Jenkins slaves to build the docker image test",
    "start": "2340769",
    "end": "2346440"
  },
  {
    "text": "docker image and also push image tech image the server usage is Mac some",
    "start": "2346440",
    "end": "2356999"
  },
  {
    "text": "developer well us make docker for Mac and do some testing or development on",
    "start": "2356999",
    "end": "2363839"
  },
  {
    "text": "their laptop it's totally fun to work with and the first one is the missus we have",
    "start": "2363839",
    "end": "2370720"
  },
  {
    "text": "a few missiles Craster's running some sparks streaming jobs together with of",
    "start": "2370720",
    "end": "2376720"
  },
  {
    "text": "you other scenes because of Miss has offered talk her integration to run the",
    "start": "2376720",
    "end": "2384460"
  },
  {
    "text": "container based on dr. image and the way like the doctor image so we tried the",
    "start": "2384460",
    "end": "2389500"
  },
  {
    "text": "integration ways that you see are and it works quite quite well and we can run",
    "start": "2389500",
    "end": "2394570"
  },
  {
    "text": "multiple version of spark binary using docker image pretty well it's a better",
    "start": "2394570",
    "end": "2402040"
  },
  {
    "text": "way to to do the instance configuration and the last one and the neck to mention",
    "start": "2402040",
    "end": "2410290"
  },
  {
    "text": "is we have also several docker eyes that the services are running in production",
    "start": "2410290",
    "end": "2415470"
  },
  {
    "text": "they are in smaller scale just thousands of nodes but they worked pretty well we",
    "start": "2415470",
    "end": "2424090"
  },
  {
    "text": "use in-house deployment tool which is called telephone and it's also open",
    "start": "2424090",
    "end": "2430750"
  },
  {
    "text": "sourced and github basically teletran allows you to write some shell script to",
    "start": "2430750",
    "end": "2439210"
  },
  {
    "text": "to to deploy a service which sounds like",
    "start": "2439210",
    "end": "2445240"
  },
  {
    "text": "a little big step back from the configuration management to neck puppet",
    "start": "2445240",
    "end": "2451390"
  },
  {
    "text": "but actually we found it's a better way to deploy container because the shell",
    "start": "2451390",
    "end": "2459220"
  },
  {
    "text": "script is only service based thick it's not a shared configuration repo for",
    "start": "2459220",
    "end": "2465730"
  },
  {
    "text": "every scene the isolation it's provided is much much better for micro services and so we're",
    "start": "2465730",
    "end": "2472869"
  },
  {
    "text": "using the telephone to configure the host and then use docker command to run",
    "start": "2472869",
    "end": "2479859"
  },
  {
    "text": "container for these services next this",
    "start": "2479859",
    "end": "2487119"
  },
  {
    "text": "is a sneak peek of our repository and the Jenkins job directory",
    "start": "2487119",
    "end": "2494800"
  },
  {
    "text": "we building house currently actually we have over 20 image",
    "start": "2494800",
    "end": "2502009"
  },
  {
    "text": "repo and we use Jenkins to build and and",
    "start": "2502009",
    "end": "2508160"
  },
  {
    "text": "the test and tag them push image into easy our and we have a producing house",
    "start": "2508160",
    "end": "2514579"
  },
  {
    "text": "which is only Jenkins can push image onto ECR and the developer should not",
    "start": "2514579",
    "end": "2521779"
  },
  {
    "text": "push image from their laptop or their be instances because they could mess it up",
    "start": "2521779",
    "end": "2527299"
  },
  {
    "text": "even you give get commit ID as a tag for",
    "start": "2527299",
    "end": "2532940"
  },
  {
    "text": "the image it can still be override about someone if you don't know where and we",
    "start": "2532940",
    "end": "2541849"
  },
  {
    "text": "have the github and not gear hub git repo in turn a git repo integration with",
    "start": "2541849",
    "end": "2548119"
  },
  {
    "text": "Jenkins so developer have a commit or poor",
    "start": "2548119",
    "end": "2553250"
  },
  {
    "text": "request can be can trigger or Jenkins job in a continuous integration way yeah",
    "start": "2553250",
    "end": "2562130"
  },
  {
    "text": "it works pretty well and in Jenkins we actually just just use plan shell script to",
    "start": "2562130",
    "end": "2572319"
  },
  {
    "text": "invoke the docker commands to build some image and also we have some project use",
    "start": "2572319",
    "end": "2580250"
  },
  {
    "text": "make file to manage the image building by invoking the docker commands either",
    "start": "2580250",
    "end": "2587690"
  },
  {
    "text": "way works and okay even we have very",
    "start": "2587690",
    "end": "2595220"
  },
  {
    "text": "good experience about docker and we think it will help Pinterest in the",
    "start": "2595220",
    "end": "2602029"
  },
  {
    "text": "future we did hit some talker issues at Pinterest the issues are mostly related",
    "start": "2602029",
    "end": "2609890"
  },
  {
    "text": "to the storage driver or owning file systems used by the docker engine for",
    "start": "2609890",
    "end": "2621559"
  },
  {
    "text": "example the AFS one which is a pretty slippery at the early days we tried",
    "start": "2621559",
    "end": "2632000"
  },
  {
    "text": "we use kernels 3.18 at a time by default he is a ufs storage driver and it caused",
    "start": "2632000",
    "end": "2644000"
  },
  {
    "text": "the issue which container cannot be stopped because it took become a zombie",
    "start": "2644000",
    "end": "2649490"
  },
  {
    "text": "process on the host and it's hard to fix even restart of docker engine then we we",
    "start": "2649490",
    "end": "2659590"
  },
  {
    "text": "then we tried other alternative storage",
    "start": "2659590",
    "end": "2664880"
  },
  {
    "text": "drivers for example BFS which is which was also a lot good because it can",
    "start": "2664880",
    "end": "2671060"
  },
  {
    "text": "create huge it can occupy huge space on",
    "start": "2671060",
    "end": "2676670"
  },
  {
    "text": "the body docker folder when you build a simple image so it's nothing if it's not",
    "start": "2676670",
    "end": "2683900"
  },
  {
    "text": "efficient to use at all then we switch to a UF overlays overlay and storage",
    "start": "2683900",
    "end": "2694250"
  },
  {
    "text": "driver but we found overlay a also has problem but the problem actually a",
    "start": "2694250",
    "end": "2703000"
  },
  {
    "text": "pretty easy to resolve by upgrading the kernel version to the to a newer one for",
    "start": "2703000",
    "end": "2710480"
  },
  {
    "text": "example peepin store fails issue which blocked our Python project for a while",
    "start": "2710480",
    "end": "2718220"
  },
  {
    "text": "but we found the kernel 4.5 actually",
    "start": "2718220",
    "end": "2723290"
  },
  {
    "text": "resolved it perfectly and all similarly the overly fair system with unique",
    "start": "2723290",
    "end": "2729140"
  },
  {
    "text": "Stormin sake file which is what hidden kernel 4.7 and also back ported to",
    "start": "2729140",
    "end": "2736120"
  },
  {
    "text": "kernel 4.4 so yeah so now we are using",
    "start": "2736120",
    "end": "2747070"
  },
  {
    "text": "the overlay storage driver and we upgraded our current versions along the",
    "start": "2747070",
    "end": "2754310"
  },
  {
    "text": "way several times to 4.8 now which is pretty new and also we upgraded toker",
    "start": "2754310",
    "end": "2762440"
  },
  {
    "text": "engine many times from one point seven to one point and",
    "start": "2762440",
    "end": "2768260"
  },
  {
    "text": "twelve points three now so to be honest",
    "start": "2768260",
    "end": "2774080"
  },
  {
    "text": "we didn't really test the device mapper the FS or btrfs some other storage",
    "start": "2774080",
    "end": "2781880"
  },
  {
    "text": "drivers but we think overlay works fast and that's good so a few tips first one",
    "start": "2781880",
    "end": "2797000"
  },
  {
    "text": "is the storage driver actually is very important for the still a bit stable",
    "start": "2797000",
    "end": "2803240"
  },
  {
    "text": "penalty of your or talker or services but you you you may hit problem",
    "start": "2803240",
    "end": "2813100"
  },
  {
    "text": "fortunately and the the talker community is very very hot so you probably want to",
    "start": "2813100",
    "end": "2821030"
  },
  {
    "text": "be the first one to hit issue you you hit somebody maybe already opened the",
    "start": "2821030",
    "end": "2828290"
  },
  {
    "text": "issue on the github and somebody figure out work wrong or the new version of",
    "start": "2828290",
    "end": "2835130"
  },
  {
    "text": "kernel can perfectly resolve the issue actually there's a case what we experienced every issue a hit has found",
    "start": "2835130",
    "end": "2843290"
  },
  {
    "text": "on github and we can easily find our solution so it's not blocking as long as",
    "start": "2843290",
    "end": "2848300"
  },
  {
    "text": "you can and working on all of these issues we will stick with overlay in",
    "start": "2848300",
    "end": "2856280"
  },
  {
    "text": "Pinterest and the way we we heard overlaid to well be the future or",
    "start": "2856280",
    "end": "2864050"
  },
  {
    "text": "default storage driver for docker engine but we found is not as stable as overly",
    "start": "2864050",
    "end": "2873440"
  },
  {
    "text": "yet so yeah I mentioned a little bit we",
    "start": "2873440",
    "end": "2880670"
  },
  {
    "text": "are we're running the kernel version 4.0 in-house you know we we we didn't found",
    "start": "2880670",
    "end": "2888800"
  },
  {
    "text": "any problem we upgrade the color version actually I think it's amazing because",
    "start": "2888800",
    "end": "2896650"
  },
  {
    "text": "the genius work has been done by Linux and a large community of the kernel",
    "start": "2896650",
    "end": "2903350"
  },
  {
    "text": "development team so the kernel upgrade actually is pretty a low-risk and it can",
    "start": "2903350",
    "end": "2914000"
  },
  {
    "text": "bring a lot of benefits to you not only the bug fix but also some new features",
    "start": "2914000",
    "end": "2919790"
  },
  {
    "text": "such as EBP f-for profiling performance issue or something and which is awesome",
    "start": "2919790",
    "end": "2926600"
  },
  {
    "text": "so we recommend your tools to use the newest kernel as much as possible and",
    "start": "2926600",
    "end": "2932900"
  },
  {
    "text": "the way we we don't suggest to upgrade docker engine in place because we found",
    "start": "2932900",
    "end": "2940730"
  },
  {
    "text": "the proper engine and upgrading welke or your running containers on hosts which",
    "start": "2940730",
    "end": "2946670"
  },
  {
    "text": "probably not acceptable and also it might change some of default options for",
    "start": "2946670",
    "end": "2952040"
  },
  {
    "text": "the engine then also you may not want her so we pick the top engine into ami",
    "start": "2952040",
    "end": "2959630"
  },
  {
    "text": "and the way tests do AMI and feel to have instance for a while and switch am",
    "start": "2959630",
    "end": "2966410"
  },
  {
    "text": "I to to the picker picker scope then",
    "start": "2966410",
    "end": "2974230"
  },
  {
    "text": "yeah to be honest we use the docker engine basically as an image to ship our",
    "start": "2974230",
    "end": "2980600"
  },
  {
    "text": "binary we are not using some fancy overlay network or some other advanced",
    "start": "2980600",
    "end": "2987230"
  },
  {
    "text": "future which docker engine won't provide we just use docker engine as a",
    "start": "2987230",
    "end": "2994180"
  },
  {
    "text": "minimalized way and in that way actually we found the newer version of the her",
    "start": "2994180",
    "end": "3000340"
  },
  {
    "text": "engine is better because it's fixed issues and has a better support better",
    "start": "3000340",
    "end": "3006640"
  },
  {
    "text": "integration with the New York Ernest and",
    "start": "3006640",
    "end": "3011880"
  },
  {
    "text": "another story a little creature is maybe special for Pinterest because Pinterest",
    "start": "3011880",
    "end": "3021070"
  },
  {
    "text": "internally run many micro services but for historical reason we still keep",
    "start": "3021070",
    "end": "3026410"
  },
  {
    "text": "maintaining for major milania's repos recent Python Java or C++ : and",
    "start": "3026410",
    "end": "3034750"
  },
  {
    "text": "each repo has tons of dependencies it's",
    "start": "3034750",
    "end": "3040390"
  },
  {
    "text": "not a problem for production because as Scott mentioned the practice you use a",
    "start": "3040390",
    "end": "3047320"
  },
  {
    "text": "runtime image which could be very very small to only have the binary and the",
    "start": "3047320",
    "end": "3053650"
  },
  {
    "text": "wrong time dependency we use that way too to be able to the wrong time and",
    "start": "3053650",
    "end": "3059190"
  },
  {
    "text": "image but for the building image if you want to install all the dependency into",
    "start": "3059190",
    "end": "3066040"
  },
  {
    "text": "a building image it might take a long time at the beginning I created a",
    "start": "3066040",
    "end": "3072070"
  },
  {
    "text": "building image for our Python repo which has a lot of cheap package dependency",
    "start": "3072070",
    "end": "3077470"
  },
  {
    "text": "and also that the BIM package dependency inside it the image became 5 gigabytes",
    "start": "3077470",
    "end": "3085350"
  },
  {
    "text": "that's huge and you need to take 30 minutes to build so and because the",
    "start": "3085350",
    "end": "3095830"
  },
  {
    "text": "model repo the dependency can't be changed by any developer revenue you",
    "start": "3095830",
    "end": "3101710"
  },
  {
    "text": "don't know it causes a lot of complaints because other developers heads to",
    "start": "3101710",
    "end": "3107710"
  },
  {
    "text": "rebuild the image wait until 13 minutes it's a huge waste so we have to take out",
    "start": "3107710",
    "end": "3115900"
  },
  {
    "text": "this problem special problem for the military pol III plan and Python",
    "start": "3115900",
    "end": "3124300"
  },
  {
    "text": "packaged into a little bit because it doesn't have a good way to track the",
    "start": "3124300",
    "end": "3130630"
  },
  {
    "text": "dependency like maven or something that's better but anyway we have to",
    "start": "3130630",
    "end": "3137050"
  },
  {
    "text": "tackle this problem and we used some trick the principle you split the bigger",
    "start": "3137050",
    "end": "3143320"
  },
  {
    "text": "image in one giant bigger image into smaller or building image and the way we",
    "start": "3143320",
    "end": "3150790"
  },
  {
    "text": "move the nest changed base image into our parent image for for other child",
    "start": "3150790",
    "end": "3157000"
  },
  {
    "text": "image and we use make file to manage the build order of them and we use",
    "start": "3157000",
    "end": "3163630"
  },
  {
    "text": "special way to tag the image uses a check sums out dependencies so we have a",
    "start": "3163630",
    "end": "3170830"
  },
  {
    "text": "script script to calculate the checks and only the checks unchanged it can't it well poor or build the image locally",
    "start": "3170830",
    "end": "3179590"
  },
  {
    "text": "in that way we reduce to the build time most of all so most of them from in to",
    "start": "3179590",
    "end": "3185770"
  },
  {
    "text": "three minutes so it's okay for developer now and we are looking for and other",
    "start": "3185770",
    "end": "3192130"
  },
  {
    "text": "features which you will be offered by docker 1.13 which is the option called",
    "start": "3192130",
    "end": "3198610"
  },
  {
    "text": "cash from so it can look up some cash from remote place rather than the local",
    "start": "3198610",
    "end": "3206190"
  },
  {
    "text": "local host which is awesome I think probably we can average it by building",
    "start": "3206190",
    "end": "3212890"
  },
  {
    "text": "some cash image in remote and all the developers can benefit from it",
    "start": "3212890",
    "end": "3218980"
  },
  {
    "text": "because it can prove from from other place and okay that's a issue we hit",
    "start": "3218980",
    "end": "3229450"
  },
  {
    "text": "with ECI to the beginning so we are we were rate limited which is unfortunate",
    "start": "3229450",
    "end": "3239140"
  },
  {
    "text": "and when we got a great limited basically all the instances cannot to",
    "start": "3239140",
    "end": "3245440"
  },
  {
    "text": "the docker build or docker polish poor so that's that's a separate issue",
    "start": "3245440",
    "end": "3250660"
  },
  {
    "text": "actually but yeah with the help of a",
    "start": "3250660",
    "end": "3255700"
  },
  {
    "text": "double support we we no doubt course which is a shell script which keep",
    "start": "3255700",
    "end": "3263230"
  },
  {
    "text": "running the AWS ECR get logging you know infinite loop so we're starting",
    "start": "3263230",
    "end": "3272080"
  },
  {
    "text": "there and fortunately from the crowd tail we can found out the sauce",
    "start": "3272080",
    "end": "3277950"
  },
  {
    "text": "identified the instance and and the cured share script then we got it",
    "start": "3277950",
    "end": "3284440"
  },
  {
    "text": "resolved soon after his waste wage to Krong script running on every host to",
    "start": "3284440",
    "end": "3292810"
  },
  {
    "text": "execute this command and don't allow people to X could this get logging command Ed",
    "start": "3292810",
    "end": "3299770"
  },
  {
    "text": "Hochuli we also leverage environment variable called docker underscore config",
    "start": "3299770",
    "end": "3305760"
  },
  {
    "text": "to make every host share one configuration file which which get",
    "start": "3305760",
    "end": "3312970"
  },
  {
    "text": "computed by the Quran script so it works and prevent the issue happen again but",
    "start": "3312970",
    "end": "3321640"
  },
  {
    "text": "later we found I found another tool which is open sourced by universe",
    "start": "3321640",
    "end": "3326650"
  },
  {
    "text": "Debs which is a great tool builded derived from the docker credential helper",
    "start": "3326650",
    "end": "3334829"
  },
  {
    "text": "basically to provide binary artifacts to",
    "start": "3334829",
    "end": "3341680"
  },
  {
    "text": "be invoked by docker engine and Hockley whenever dhaka ninja need to talk to a",
    "start": "3341680",
    "end": "3347799"
  },
  {
    "text": "private registry so yeah the tool is",
    "start": "3347799",
    "end": "3353020"
  },
  {
    "text": "built it is written : and build a very tiny binary if you drop the Teddy binary",
    "start": "3353020",
    "end": "3359020"
  },
  {
    "text": "into the user being folder and the config toker conflict or JSON file to",
    "start": "3359020",
    "end": "3366790"
  },
  {
    "text": "use it then it will work like a charm it also has the token cached and so it",
    "start": "3366790",
    "end": "3375010"
  },
  {
    "text": "won't invoke too many requests to the ECR and and once in to notice is you",
    "start": "3375010",
    "end": "3387670"
  },
  {
    "text": "have to put your your own URL into the",
    "start": "3387670",
    "end": "3393130"
  },
  {
    "text": "company code or JSON file otherwise the Tokra engine won't be able to fund fund",
    "start": "3393130",
    "end": "3399819"
  },
  {
    "text": "as a parent image in SAR if you use docker command docker build command and",
    "start": "3399819",
    "end": "3405730"
  },
  {
    "text": "which is an imitation of the dr. Anjali but yeah it's easy to work around next",
    "start": "3405730",
    "end": "3413940"
  },
  {
    "text": "is a little bit experience with the missus integration so before the basis",
    "start": "3413940",
    "end": "3423640"
  },
  {
    "text": "version 1.0 it's provided URIs parameter",
    "start": "3423640",
    "end": "3428740"
  },
  {
    "text": "you can specify in your mirror marisol task definition and in in that",
    "start": "3428740",
    "end": "3435400"
  },
  {
    "text": "parameter you can point Tov L which have your token configuration credentials in",
    "start": "3435400",
    "end": "3442390"
  },
  {
    "text": "yet then in that way Merson and measures can talk to the private ECR very well and the since",
    "start": "3442390",
    "end": "3451210"
  },
  {
    "text": "mixes one version 1.0 we have the talker - config options which with that config",
    "start": "3451210",
    "end": "3458980"
  },
  {
    "text": "on each basis agent you don't need to specify the URIs parameter for each task",
    "start": "3458980",
    "end": "3466140"
  },
  {
    "text": "yeah and another interesting things I'd like to mention is the unified container",
    "start": "3466140",
    "end": "3474370"
  },
  {
    "text": "rider which is missus community is",
    "start": "3474370",
    "end": "3480730"
  },
  {
    "text": "actively working on basically the basis unified container Iser kin-por image",
    "start": "3480730",
    "end": "3489700"
  },
  {
    "text": "from the east are without docker demon it's a bold move but I'm pretty excited",
    "start": "3489700",
    "end": "3497410"
  },
  {
    "text": "about that because you don't own you you you only need one agent on the host",
    "start": "3497410",
    "end": "3503980"
  },
  {
    "text": "which is missus agent you don't need install docker engineer mode but you can also you can still benefit from from the",
    "start": "3503980",
    "end": "3512170"
  },
  {
    "text": "immunity in immutable artifacts from the",
    "start": "3512170",
    "end": "3518740"
  },
  {
    "text": "docker image that's a good thing and actually I wish you see as agent",
    "start": "3518740",
    "end": "3525100"
  },
  {
    "text": "probably can suppose that similar scenes in the future okay yes that's all maybe",
    "start": "3525100",
    "end": "3533530"
  },
  {
    "text": "final comments in Pinterest obviously our docker role is just started we",
    "start": "3533530",
    "end": "3541000"
  },
  {
    "text": "haven't really work on the orchestration for example the SAS integration or all",
    "start": "3541000",
    "end": "3548110"
  },
  {
    "text": "kinds of or scheduling issues or deploying multiple multiple containers",
    "start": "3548110",
    "end": "3554700"
  },
  {
    "text": "at once using ports all these",
    "start": "3554700",
    "end": "3560849"
  },
  {
    "text": "issues are interesting and we'd like to tackle but yeah there's a next step for",
    "start": "3561590",
    "end": "3569130"
  },
  {
    "text": "us so finally thanks for your attending and I'm very happy here to share our",
    "start": "3569130",
    "end": "3577500"
  },
  {
    "text": "story and obviously I'm already run out of time I'm sorry and so if you have",
    "start": "3577500",
    "end": "3584430"
  },
  {
    "text": "questions I am happy to answer it off the stage thank you [Applause]",
    "start": "3584430",
    "end": "3594169"
  }
]
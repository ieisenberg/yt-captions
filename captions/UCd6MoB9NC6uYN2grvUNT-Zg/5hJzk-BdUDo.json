[
  {
    "text": "- Ermin, I see you're drinking coffee.",
    "start": "965",
    "end": "3060"
  },
  {
    "text": "Is that a good brew?",
    "start": "3060",
    "end": "4720"
  },
  {
    "text": "- Let me tell you what good brew is.",
    "start": "4720",
    "end": "6450"
  },
  {
    "text": "Let me tell you about AWS Glue DataBrew.",
    "start": "6450",
    "end": "9228"
  },
  {
    "text": "Do you know that companies\nspend as much as 80% time",
    "start": "9228",
    "end": "12599"
  },
  {
    "text": "to prepare data?",
    "start": "12600",
    "end": "13860"
  },
  {
    "text": "Data preparation is time consuming.",
    "start": "13860",
    "end": "16000"
  },
  {
    "text": "It is expensive, and it is\na very much manual process.",
    "start": "16000",
    "end": "19777"
  },
  {
    "text": "My name is Ermin Dzinic.",
    "start": "19777",
    "end": "20823"
  },
  {
    "text": "- My name is Aleena Yunus.",
    "start": "20823",
    "end": "22710"
  },
  {
    "text": "In this video, we will introduce you",
    "start": "22710",
    "end": "24410"
  },
  {
    "text": "to the basics of AWS Glue DataBrew.",
    "start": "24410",
    "end": "27550"
  },
  {
    "text": "We'll talk about what DataBrew\nis, its core components,",
    "start": "27550",
    "end": "30490"
  },
  {
    "text": "and then focus on its\ndata lineage feature.",
    "start": "30490",
    "end": "33329"
  },
  {
    "text": "At the end, we will also\npresent a hands-on demo.",
    "start": "33330",
    "end": "36040"
  },
  {
    "text": "So let's get started.",
    "start": "36040",
    "end": "37923"
  },
  {
    "text": "- AWS Glue DataBrew is a\nserverless, visual data",
    "start": "37923",
    "end": "41610"
  },
  {
    "text": "preparation tool that makes it easy",
    "start": "41610",
    "end": "43500"
  },
  {
    "text": "for data analysts and data scientists",
    "start": "43500",
    "end": "45790"
  },
  {
    "text": "to prepare data with an\ninteractive visual interface",
    "start": "45790",
    "end": "49469"
  },
  {
    "text": "without writing code.",
    "start": "49469",
    "end": "51399"
  },
  {
    "text": "With DataBrew, you can easily visualize,",
    "start": "51399",
    "end": "54109"
  },
  {
    "text": "clean, and normalize terabytes\nand even petabytes of data",
    "start": "54110",
    "end": "58180"
  },
  {
    "text": "directly from your data lake,\ndata warehouses and databases.",
    "start": "58180",
    "end": "61533"
  },
  {
    "text": "With AWS Glue DataBrew, you can get data",
    "start": "62490",
    "end": "65129"
  },
  {
    "text": "from various data sources like Amazon S3.",
    "start": "65130",
    "end": "68770"
  },
  {
    "text": "You can get it from relational\ndatabases, like Amazon RDS.",
    "start": "68770",
    "end": "72899"
  },
  {
    "text": "Your local files like CSV",
    "start": "72900",
    "end": "75120"
  },
  {
    "text": "or from AWS Glue Data Catalog map sources.",
    "start": "75120",
    "end": "78830"
  },
  {
    "text": "For input data, AWS Glue DataBrew supports",
    "start": "78830",
    "end": "82020"
  },
  {
    "text": "commonly used file\nformats such as CSV, JSON,",
    "start": "82020",
    "end": "86117"
  },
  {
    "text": "Apache Parquet and Excel sheets.",
    "start": "86117",
    "end": "88793"
  },
  {
    "text": "Once you import data\ninto AWS Glue DataBrew,",
    "start": "89700",
    "end": "93710"
  },
  {
    "text": "you can explore, understand your data",
    "start": "93710",
    "end": "96080"
  },
  {
    "text": "and then transform it as you wish.",
    "start": "96080",
    "end": "98890"
  },
  {
    "text": "The interactive data preparation\nworkspace in DataBrew",
    "start": "98890",
    "end": "102070"
  },
  {
    "text": "is called project.",
    "start": "102070",
    "end": "103133"
  },
  {
    "text": "Within the project, you can\ngroup multiple transformations",
    "start": "108198",
    "end": "111369"
  },
  {
    "text": "together, save them as recipe.",
    "start": "111370",
    "end": "113403"
  },
  {
    "text": "And then apply the recipes directly",
    "start": "119670",
    "end": "122250"
  },
  {
    "text": "to the newly incoming data.",
    "start": "122250",
    "end": "124033"
  },
  {
    "text": "You can choose from over\n250 building transformations",
    "start": "125670",
    "end": "129310"
  },
  {
    "text": "to combine, pivot, and transpose data",
    "start": "129310",
    "end": "131950"
  },
  {
    "text": "without writing code.",
    "start": "131950",
    "end": "133340"
  },
  {
    "text": "For complex informations,\nDataBrew provides",
    "start": "133340",
    "end": "136160"
  },
  {
    "text": "advanced machine learning techniques",
    "start": "136160",
    "end": "137660"
  },
  {
    "text": "such as NLP, natural language processing.",
    "start": "137660",
    "end": "141000"
  },
  {
    "text": "After that, you can run the\njob to transform the data",
    "start": "141000",
    "end": "144450"
  },
  {
    "text": "according to the recipe\nscript you just built.",
    "start": "144450",
    "end": "147032"
  },
  {
    "text": "And then you can output the data",
    "start": "154610",
    "end": "157020"
  },
  {
    "text": "to the location of your wish.",
    "start": "157020",
    "end": "158963"
  },
  {
    "text": "That could be machine learning model.",
    "start": "160570",
    "end": "162523"
  },
  {
    "text": "It could be S3 bucket.",
    "start": "163400",
    "end": "165150"
  },
  {
    "text": "It could even be Amazon QuickSight",
    "start": "165150",
    "end": "167269"
  },
  {
    "text": "to make great dashboards\nfor your customers.",
    "start": "167270",
    "end": "169720"
  },
  {
    "text": "For output data, AWS Glue\nDataBrew supports CSV values,",
    "start": "169720",
    "end": "174691"
  },
  {
    "text": "JSON, Apache Parquet, Apache\nArrow, and Apache Arch.",
    "start": "174691",
    "end": "178763"
  },
  {
    "text": "- Now onto data lineage.",
    "start": "180050",
    "end": "181920"
  },
  {
    "text": "DataBrew tracks your data\nin a visual interface",
    "start": "181920",
    "end": "184700"
  },
  {
    "text": "to determine its origin\ncalled data lineage.",
    "start": "184700",
    "end": "187739"
  },
  {
    "text": "This view shows you how the data flows",
    "start": "187740",
    "end": "189780"
  },
  {
    "text": "through different entities\nfrom where it originally came.",
    "start": "189780",
    "end": "193040"
  },
  {
    "text": "You can see its origin,",
    "start": "193040",
    "end": "194610"
  },
  {
    "text": "other entities it was influenced by,",
    "start": "194610",
    "end": "196910"
  },
  {
    "text": "what happened to it over\ntime and where it was stored.",
    "start": "196910",
    "end": "200370"
  },
  {
    "text": "This allows for data analysts\nto capture the relationship",
    "start": "200370",
    "end": "203250"
  },
  {
    "text": "between the different data sources,",
    "start": "203250",
    "end": "205790"
  },
  {
    "text": "how data gets transformed, converged,",
    "start": "205790",
    "end": "208260"
  },
  {
    "text": "its upstream dependencies\nand its downstream usage.",
    "start": "208260",
    "end": "212239"
  },
  {
    "text": "Moreover, it allows to trace\nindirect sources of error.",
    "start": "212240",
    "end": "215663"
  },
  {
    "text": "All right, now that we've\ngone over the basic concepts",
    "start": "216520",
    "end": "219430"
  },
  {
    "text": "of Glue DataBrew and data lineage,",
    "start": "219430",
    "end": "221879"
  },
  {
    "text": "we'll now move over to a demo",
    "start": "221880",
    "end": "223880"
  },
  {
    "text": "to see how this works in practice.",
    "start": "223880",
    "end": "225683"
  },
  {
    "text": "For the purpose of this demo,",
    "start": "226970",
    "end": "228330"
  },
  {
    "text": "we have a fictional retail\ncompany called Octatank.",
    "start": "228330",
    "end": "232240"
  },
  {
    "text": "Octatank sells pet products online.",
    "start": "232240",
    "end": "234730"
  },
  {
    "text": "They want to find out which\nproduct is not in demand",
    "start": "234730",
    "end": "237190"
  },
  {
    "text": "in which area, and target them to increase",
    "start": "237190",
    "end": "239670"
  },
  {
    "text": "awareness and product sales.",
    "start": "239670",
    "end": "241830"
  },
  {
    "text": "The data analyst team is fairly new.",
    "start": "241830",
    "end": "244690"
  },
  {
    "text": "They want tooling that\ndoesn't require them",
    "start": "244690",
    "end": "246500"
  },
  {
    "text": "to code and manage infra.",
    "start": "246500",
    "end": "248630"
  },
  {
    "text": "Additionally, they want to\nbe able to track data flow,",
    "start": "248630",
    "end": "251260"
  },
  {
    "text": "so that it is easy to trace\nerrors along the pipeline.",
    "start": "251260",
    "end": "254183"
  },
  {
    "text": "Let's take a look at how\nOctatank can use Glue DataBrew",
    "start": "255140",
    "end": "257928"
  },
  {
    "text": "to identify zip codes\nwhere specific products",
    "start": "257928",
    "end": "260950"
  },
  {
    "text": "are not fairing well.",
    "start": "260950",
    "end": "262900"
  },
  {
    "text": "We have three kinds of datasets.",
    "start": "262900",
    "end": "264790"
  },
  {
    "text": "The sales dataset in Amazon S3.",
    "start": "264790",
    "end": "266783"
  },
  {
    "text": "This contains information about\nthe product that was sold,",
    "start": "271363",
    "end": "274060"
  },
  {
    "text": "the quantity of the product,",
    "start": "274060",
    "end": "275190"
  },
  {
    "text": "as well as the customer, who bought it.",
    "start": "275190",
    "end": "277650"
  },
  {
    "text": "The other two datasets are\ncustomer and product datasets.",
    "start": "277650",
    "end": "281110"
  },
  {
    "text": "The customer dataset is\nresiding in Amazon RDS,",
    "start": "281110",
    "end": "284199"
  },
  {
    "text": "Relational Database Service.",
    "start": "284200",
    "end": "285843"
  },
  {
    "text": "We have it extracted as a\nGlue Data Catalog Table,",
    "start": "290290",
    "end": "293170"
  },
  {
    "text": "which acts as a metadata table,",
    "start": "293170",
    "end": "294860"
  },
  {
    "text": "containing references to the data in RDS.",
    "start": "294860",
    "end": "298289"
  },
  {
    "text": "Finally, we have the product\ndata that exists as a CSV file",
    "start": "298290",
    "end": "301460"
  },
  {
    "text": "on our local machine.",
    "start": "301460",
    "end": "302623"
  },
  {
    "text": "We'll be joining and\ntransforming all of these",
    "start": "307200",
    "end": "309330"
  },
  {
    "text": "in Glue DataBrew, and then\nfinally outputting them",
    "start": "309330",
    "end": "313353"
  },
  {
    "text": "to an S3 bucket.",
    "start": "316960",
    "end": "318063"
  },
  {
    "text": "Now let's move on to the demo.",
    "start": "319940",
    "end": "322070"
  },
  {
    "text": "In the services search bar type DataBrew,",
    "start": "322070",
    "end": "324550"
  },
  {
    "text": "click on AWS Glue DataBrew.",
    "start": "324550",
    "end": "326979"
  },
  {
    "text": "And this will take you to its console.",
    "start": "326980",
    "end": "328930"
  },
  {
    "text": "On your left side, you\nhave all the components",
    "start": "328930",
    "end": "330800"
  },
  {
    "text": "we discussed earlier.",
    "start": "330800",
    "end": "331973"
  },
  {
    "text": "Click on Create Project, and\ngive it a meaningful name.",
    "start": "333180",
    "end": "336182"
  },
  {
    "text": "A recipe as you can see\nis automatically created.",
    "start": "338160",
    "end": "341571"
  },
  {
    "text": "Now let's move on and create\na new dataset, give it a name.",
    "start": "341571",
    "end": "346571"
  },
  {
    "text": "This will be the dataset\nthat will correspond",
    "start": "347600",
    "end": "349710"
  },
  {
    "text": "to the sales dataset.",
    "start": "349710",
    "end": "351173"
  },
  {
    "text": "And within it, we have the CS.CSV file.",
    "start": "352040",
    "end": "354763"
  },
  {
    "text": "Keep the rest as default and\nscroll down to permissions,",
    "start": "356050",
    "end": "358849"
  },
  {
    "text": "select the appropriate role,\nand click on Create Project.",
    "start": "360480",
    "end": "363883"
  },
  {
    "text": "Now you can visualize",
    "start": "366340",
    "end": "367440"
  },
  {
    "text": "all the different columns of the dataset.",
    "start": "367440",
    "end": "369490"
  },
  {
    "text": "Let's take a look at the data\nlineage tab on the top right.",
    "start": "370580",
    "end": "373689"
  },
  {
    "text": "Here we can see that CS.CSV was\nloaded as a dataset from S3.",
    "start": "373690",
    "end": "378220"
  },
  {
    "text": "It is part of a project,",
    "start": "378220",
    "end": "379340"
  },
  {
    "text": "which has a recipe attached to a it.",
    "start": "379340",
    "end": "381460"
  },
  {
    "text": "We will populate this in a bit.",
    "start": "381460",
    "end": "383850"
  },
  {
    "text": "Switching over to the CloudTrail view,",
    "start": "383850",
    "end": "385600"
  },
  {
    "text": "We can also see an audit\ntrail of the different actions",
    "start": "385600",
    "end": "388060"
  },
  {
    "text": "that were performed on a resource,",
    "start": "388060",
    "end": "389950"
  },
  {
    "text": "the time at which they took place,",
    "start": "389950",
    "end": "391720"
  },
  {
    "text": "and the user that performed them.",
    "start": "391720",
    "end": "393863"
  },
  {
    "text": "In order to develop a recipe,",
    "start": "395440",
    "end": "396930"
  },
  {
    "text": "let's head back to the project view.",
    "start": "396930",
    "end": "399050"
  },
  {
    "text": "The next step is to join customer data",
    "start": "399050",
    "end": "401139"
  },
  {
    "text": "with the sales dataset.",
    "start": "401140",
    "end": "403070"
  },
  {
    "text": "Click on Join on the top menu,",
    "start": "403070",
    "end": "405080"
  },
  {
    "text": "and you will be now\nable to create a dataset",
    "start": "405080",
    "end": "408030"
  },
  {
    "text": "from the Glue data\ncatalog for customer data.",
    "start": "408030",
    "end": "410563"
  },
  {
    "text": "Give it a name.",
    "start": "411420",
    "end": "412363"
  },
  {
    "text": "Select Data Catalog RDS tables",
    "start": "415240",
    "end": "418110"
  },
  {
    "text": "and then click on Octatank customer DB",
    "start": "418110",
    "end": "420990"
  },
  {
    "text": "and select customer table.",
    "start": "420990",
    "end": "422802"
  },
  {
    "text": "Click on Create dataset, click on Next.",
    "start": "424520",
    "end": "428233"
  },
  {
    "text": "Next again.",
    "start": "431330",
    "end": "432302"
  },
  {
    "text": "From this screen, select customer ID",
    "start": "434000",
    "end": "437010"
  },
  {
    "text": "and also customer ID from table B",
    "start": "437900",
    "end": "440090"
  },
  {
    "text": "and create an inner join,",
    "start": "440090",
    "end": "441740"
  },
  {
    "text": "while only selecting zip from the table B.",
    "start": "441740",
    "end": "445250"
  },
  {
    "text": "Click on finish.",
    "start": "445250",
    "end": "446283"
  },
  {
    "text": "Now we have to create another\njoin with product data.",
    "start": "449750",
    "end": "452580"
  },
  {
    "text": "We will achieve that by repeating\nsimilar steps as before.",
    "start": "452580",
    "end": "455810"
  },
  {
    "text": "Starting off by creating a new\ndataset and giving it a name.",
    "start": "455810",
    "end": "458810"
  },
  {
    "text": "Selecting CSV upload as an option.",
    "start": "468090",
    "end": "470313"
  },
  {
    "text": "Then storing it in an S3 destination.",
    "start": "473050",
    "end": "475533"
  },
  {
    "text": "Click on Create dataset.",
    "start": "482560",
    "end": "483993"
  },
  {
    "text": "Here, you can preview the data.",
    "start": "486320",
    "end": "488093"
  },
  {
    "text": "For the columns to join on,",
    "start": "491690",
    "end": "493160"
  },
  {
    "text": "this time we will select\nproduct ID and product key.",
    "start": "493160",
    "end": "496313"
  },
  {
    "text": "So we select those here.",
    "start": "497380",
    "end": "498993"
  },
  {
    "text": "And this time from the product table,",
    "start": "501870",
    "end": "503360"
  },
  {
    "text": "we only select product type.",
    "start": "503360",
    "end": "504962"
  },
  {
    "text": "Now Octatank has all the data",
    "start": "509260",
    "end": "510960"
  },
  {
    "text": "they need to calculate total\nsales by zip and product type.",
    "start": "510960",
    "end": "515360"
  },
  {
    "text": "At the penultimate step,",
    "start": "515360",
    "end": "516969"
  },
  {
    "text": "we'll remove all the\nunnecessary columns like TXN",
    "start": "516970",
    "end": "519939"
  },
  {
    "text": "or transaction number,\ncustomer ID, and quantity.",
    "start": "519940",
    "end": "523233"
  },
  {
    "text": "To finish off the recipe, we\nneed to identify total sales,",
    "start": "527580",
    "end": "530680"
  },
  {
    "text": "by product ID, zip, and product type.",
    "start": "530680",
    "end": "533770"
  },
  {
    "text": "For that, we create a grouping.",
    "start": "533770",
    "end": "535393"
  },
  {
    "text": "So now we choose product\nID, zip, product type",
    "start": "536630",
    "end": "539050"
  },
  {
    "text": "and total sales as the column names",
    "start": "539050",
    "end": "541050"
  },
  {
    "text": "and choose aggregate functions.",
    "start": "541050",
    "end": "542813"
  },
  {
    "text": "For total sales, the aggregate\nfunction would be sum.",
    "start": "544180",
    "end": "546830"
  },
  {
    "text": "Click on finish.",
    "start": "547890",
    "end": "549053"
  },
  {
    "text": "Now that we have all\nthe steps in our recipe,",
    "start": "552890",
    "end": "554870"
  },
  {
    "text": "we will go ahead and publish this version.",
    "start": "554870",
    "end": "557143"
  },
  {
    "text": "After publishing the version,\nwe will run a job on it,",
    "start": "558300",
    "end": "560899"
  },
  {
    "text": "which will apply the whole recipe",
    "start": "560900",
    "end": "562734"
  },
  {
    "text": "in the entire dataset in\npersisting the transform data.",
    "start": "562734",
    "end": "566600"
  },
  {
    "text": "So in order to do that,\nlet's create a job.",
    "start": "566600",
    "end": "568923"
  },
  {
    "text": "We will give it a name.",
    "start": "570870",
    "end": "572073"
  },
  {
    "text": "You need to provide an\noutput location for the job.",
    "start": "577599",
    "end": "580130"
  },
  {
    "text": "And for that, we can select\nan S3 destination here.",
    "start": "580130",
    "end": "583053"
  },
  {
    "text": "Select a role from the role name dropdown.",
    "start": "585010",
    "end": "587563"
  },
  {
    "text": "And then finally create and run job.",
    "start": "589460",
    "end": "591913"
  },
  {
    "text": "After the job is run successfully,",
    "start": "592880",
    "end": "594610"
  },
  {
    "text": "we can take a look at the data flow",
    "start": "594610",
    "end": "596390"
  },
  {
    "text": "and see how the lineage has changed,",
    "start": "596390",
    "end": "598400"
  },
  {
    "text": "with more datasets and a\ndestination being added.",
    "start": "598400",
    "end": "601840"
  },
  {
    "text": "Note that this is the\nlineage for this project.",
    "start": "601840",
    "end": "604070"
  },
  {
    "text": "And similarly, you can look at lineage",
    "start": "604070",
    "end": "605910"
  },
  {
    "text": "for each one of the datasets as well.",
    "start": "605910",
    "end": "607793"
  },
  {
    "text": "- Now we understood what\nDataBrew is and what it can do,",
    "start": "608640",
    "end": "612380"
  },
  {
    "text": "let's see where it fits.",
    "start": "612380",
    "end": "613890"
  },
  {
    "text": "Customer ask me, \"Ermin, we\nhave so many services in AWS.",
    "start": "613890",
    "end": "618373"
  },
  {
    "text": "We already have AWS Glue Studio.",
    "start": "618373",
    "end": "620839"
  },
  {
    "text": "We have SageMaker Data Wrangler.",
    "start": "620840",
    "end": "622700"
  },
  {
    "text": "Now you come to me with AWS Glue DataBrew.",
    "start": "622700",
    "end": "625540"
  },
  {
    "text": "What is the right tool for the job?\"",
    "start": "625540",
    "end": "627769"
  },
  {
    "text": "So let's look at this small\ndiagram to help you here.",
    "start": "627770",
    "end": "630780"
  },
  {
    "text": "If you're focusing more\non running ETL jobs,",
    "start": "630780",
    "end": "634636"
  },
  {
    "text": "ongoing moving data between\nvarious data sources,",
    "start": "634636",
    "end": "638000"
  },
  {
    "text": "you should use AWS Glue or Glue Studio.",
    "start": "638000",
    "end": "642010"
  },
  {
    "text": "This is something your data\nengineers are going to use.",
    "start": "642010",
    "end": "645270"
  },
  {
    "text": "If you're preparing data\nfor machine learning,",
    "start": "645270",
    "end": "647560"
  },
  {
    "text": "and you would like to explore data",
    "start": "647560",
    "end": "649740"
  },
  {
    "text": "then use SageMaker Data Wrangler.",
    "start": "649740",
    "end": "653870"
  },
  {
    "text": "This is something your data\nscientists are going to use,",
    "start": "653870",
    "end": "657260"
  },
  {
    "text": "but for your data analysts\nwho are there to explore,",
    "start": "657260",
    "end": "660850"
  },
  {
    "text": "understand, and prepare\ndata for reporting,",
    "start": "660850",
    "end": "663470"
  },
  {
    "text": "use AWS Glue DataBrew.",
    "start": "663470",
    "end": "666410"
  },
  {
    "text": "Of course there is an\noverlapping scenarios,",
    "start": "666410",
    "end": "669199"
  },
  {
    "text": "where you can use different tools",
    "start": "669200",
    "end": "670940"
  },
  {
    "text": "to accomplish the same tasks.",
    "start": "670940",
    "end": "672840"
  },
  {
    "text": "For example, data transformation",
    "start": "672840",
    "end": "675260"
  },
  {
    "text": "you can use Glue Studio and DataBrew.",
    "start": "675260",
    "end": "678030"
  },
  {
    "text": "For data exploration,",
    "start": "678030",
    "end": "679420"
  },
  {
    "text": "you can use both DataBrew\nor Data Wrangler.",
    "start": "679420",
    "end": "683160"
  },
  {
    "text": "I hope this diagram helps you",
    "start": "683160",
    "end": "685170"
  },
  {
    "text": "to select the right tool for the job.",
    "start": "685170",
    "end": "687073"
  },
  {
    "text": "- Cool. Let's summarize now.",
    "start": "687950",
    "end": "690060"
  },
  {
    "text": "We discussed Glue DataBrew",
    "start": "690060",
    "end": "691620"
  },
  {
    "text": "and looked at its data\nlineage feature in detail.",
    "start": "691620",
    "end": "694360"
  },
  {
    "text": "In the demo, we saw how\nOctatank's data science team",
    "start": "694360",
    "end": "697325"
  },
  {
    "text": "can use this to have a no-code\ntool to perform analysis",
    "start": "697325",
    "end": "701070"
  },
  {
    "text": "while keeping track of the lineage.",
    "start": "701070",
    "end": "703300"
  },
  {
    "text": "So that's it from our side.",
    "start": "703300",
    "end": "705029"
  },
  {
    "text": "Now it's time for you to\ntry it out on your own.",
    "start": "705030",
    "end": "707800"
  },
  {
    "text": "Trust me, it's going to stick like glue.",
    "start": "707800",
    "end": "710620"
  },
  {
    "text": "- Bye bye.\n- Bye.",
    "start": "710620",
    "end": "711779"
  }
]